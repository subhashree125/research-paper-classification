{
    "hH,oO(": "The differencis ta hre we take into account the meshcollision between nteracting umans an in co-trast toiteracting humans. Po)||C(Ph)C(Po)||2), where Ph and Po the * \"S regions of nterac-tion between humans ad theobject, respectiely. Cllision (LHOcollision) - The formulation of thisloss to the colision oss defined 2.",
    ". 3D Object Pose Estimation": "MM= 2M. 3led to noticeable improvements in reconstruction quality. It is difficult to estimate 3D objectpose in the wild as there are: (1) no parametric 3D modelsfor objects; (2) no images of objects in the wild with 2D/3Dpose annotations; and (3) occlusions in cluttered sceneswith humans. + Mj. g remove only oneobject at a time. Our first objective is to estimate the 6 DOF pose of eachobject independently. 3 (Our se-lection of this threshold stems from our empirical obser-vations, wherein we found that objects with IOU > 0. Occluded objectscan be removed in numerous ways, for e. We pass the current image I and themask Moccmask to get a new image without occlusionsand use this image to get new segmentation masks andbounding boxes:. Objects with IOU > 0. The optimization framework chooses the exemplarthat minimizes re-projection error to determine kj automat-ically and sj is the scale parameter for jth object. Given an image I, a total number of objects N, and bounding boxes for rigid Br and non-rigid Bnr objects,along with their masks - Mr for rigid and Mnr for non-rigid objects. To estimate the 3Dlocation t R3 and 3D orientation R SO(3) of the ob-jects. The total possible combinations, in thiscase, areM1, or you remove pair of objects at a time andthe total possible combinations, in this case, areM2andso on. 3, the reconstructionresults obtaining using our method closely resembled thoseproduced by PHOSA , more details in supplementary)are occluding objects M for each object. As defining in we calculate a pixel-wise L2 loss overrendered silhouettes S versus predicted masks M but thequality of the predicted mask M is impacted by occlusionsas seen in , which results in poorly estimated 6 DOFpose. For each object category, exemplar mesh models arepre-selected. Conversely, when IOU was less than 0. The vertices of jth object are: V jo = sj(RjO(cj, kj) + tj),where cj is the object category from MaskRCNN , andO(cj, kj) determines the kj th exemplar mesh for cate-gory cj. To identify occluding objects we cal-culate the Intersection over Union(IOU) between all pairsof bounding boxes. Toremove j occluding objects where j M we need a sin-gle mask Moccmask that is combination of the j masks,so Moccmask = M1 + M2 +. The mesh models are sourced from. After estimating the shape and pose of humans, next stepis to estimate the same for the objects. The total number of all possible combinations canbe described asM0+M1+M2+. Each ith object can be occluded by maxi-mum N 1 objects. We address these challenges by proposing anoptimization-based approach that uses a differentiable ren-derer to fit the 3D object to instance masks from in a manner that is robust to minor/major occlusions. To address problems due to occlusions, we propose anovel method that improves the masks as shown in. Now we usethe image-inpainted approach proposed by to removethe occluding objects.",
    "Interaction Loss (LHinteraction) - This is an instance-level to pull the interacting people close together, similarto : LHinteraction =": "C(hi) and (hj) give he centroid for huma iand human j resectively The loss is efindas: Ldepth =. hi,hjH (hi, h||C(hi) C(hj)||2, whre (hi, hj) identifies weter human hi ndhj are interactingaccrding o the 3D boundig box over-la critria.",
    "Theobalt, and Gerard Pons-Moll. Detailed human avatarsfrom monocular video. In 2018 International Conference on3D Vision (3DV), pages 98109. IEEE, 2018. 2": "16th oference,Glasgow, Auust 2328, 2020, Proceedngs, Part XIII16,361378. Unsurvisd learning of fne structure 3d point clods by 2d projecions In Proceed-igs of the eee/cvf conference on computer v-ion, 12412477,. Bhart Xianghu Xie, A Petrv,CristianSminchisescu, Christian Theobalt, and Gerar Pons-Moll. n Procedngs of th IEECVF Conferencen Computer Visio and attern Recognition, pages 1593515946, Bog, Kanazawa, Lasner, PeterGehler, Javier J Blck. earning to re-costruct eoplein clothng froma rgb camera. Thiemo Alldick, epeng Xu, ChristianTheoalt, and Gerard Video reonstructionof 3d people models. Keep sp:utmatic esimation of 3d human from In Computer VisionECCV 14th Euro-pean Conferne,Amsterdam, Te Netherlands October 11-4, 216, rocedigs,Prt 14pages IEE, 219.",
    ". Human Pose Optimisation": "useful informaion to determine relatie ar-rangement not onsidering this leads to ambiguitie likeesh peetration dincorrect dpth We proposean optimization framework incrporatesIdentifyin interacted hans - Our hypothesis positsthat humanare oninget upon pysical in coordinates Hence fin te intract-ed humans by identifying the oerlap of 3D regardig bouning box overlap be ound he suplementary material). While efiniey to enerate a singl voxelizing representation for scen, we of-ten find ourslves requiring fne-grained voxelgrid. t. 1. The terms in thobjetive funtion are defined below:Collision Loss (LHcolliion) - To ovecome probleof mesh colisions, s istig mehods in ,e nrodceacollisin loss LHcllision that enalizesinterpenetratins in te recontructd peole. translation R3 si theRoation i SO theit human insane. f theeisno overlap beteen erson and j,Pj wil bezero. analyzing huan 3D pos rsults in incn-sistent 3D scene configuratin. To overcome thi a separate i fuction is com-puted each by calculaed box around and it instea of the whole scee to r-duce computational If s a collision iand aperson j, Pi a positive value and a separation them increases. Typically on voxel grid NpNpNp. Objective function ooptimz D spatial arrangementr bjectiv icludes (LHclliion), interac-tion LHineraction, ad ordering loss (Lde)ters t constraint the psefor iteracted humans:LHHILoss = 1LHcollision + 2LHdepth+ 3Hinteraction(1) e optimize (1) gradient-based opimizer w. Letthe of iand persn j be Ti and rspec-tively.",
    ". Joint Optimization": "Our ypothesispoits thathuman-object interacions are contingent proxmity in world We 3Dox betweenthe human bject to determinewheher object is witha functon 3D satil arrangements. Idetifying humanobject interactio. Interactionspeope * \"S and objects provide rucilcus for corret D spatil arrangement, which interacting objects and humans andobjective fo refiningposes. The joint opimizatio efines both the and objectposes estimated above, exploiting both human-human interactions hrough loss functions. Es-timtng poss of people and objects in islatin another to inconsistnt 3D cene econstrucion. We joint oss function tht account bothhuman-uman huan-object interactons. It is rialto both of them because simply withregard o human-objectinteractions,it may result in ro-neous relative positionsbetween interacting ople even ifit woul the relative spatial btweenthe interatig ad.",
    "Tsung-Yi Lin, Michael Maire, Serge Belongie, Hays,Pietro Perona, Deva Piotr Dollar, and C Lawrence": "Zitnick. InComputer VisionECCV 2014: 13th European Conference,Zurich, Switzerland, September 6-12, 2014, Proceedings,Part V 13, pages 740755. Springer, 2014. 2, 6, 7 Shichen Liu, Tianye Li, Weikai Chen, and Hao Li. Soft ras-terizer: A differentiable renderer for image-based 3d reason-ing. 2.",
    ". Introduction": "Existing methos human and object reconstrutions areeithr limited to single objecs humans * \"S or give limiteperfrmance for colex images andobjects . These methods estimateposesof humans and objects and ito account interactions andeven ifthey do they generally follow a aproach.This leads t collisions between the mesheswih reonstructions. We consider the full sceneholistically and exploit inormatio from human-umanan human-object interctions for andmore cmplet reconstructio of in-the-wildimages. PHOSA pioneered field and proposed the firstmethod tat reconstructs intacting withobjectsor in-the-wild image. Howeer, does not explic-itly model human-huma interctions and erroneousreconstructons when occludewith incrrect deth orering collisions.Multi-humn odel-fre reconstructionfrom imge was proposed in howver, thismethod does del with huans. meth-ods for multi-human reconstructons generate re-constructions severe cllisions because the e-construct each person idependently. these chal-lenge, papr, we haveproposed an ramework for spatially reconstructionof wth multiple people and heavly oc-ude ojects. The method first reconstructs hmans an objects in he image independenty. The initialposes of peol in the scene re then optimied to resolveany ambiguities arse from this composi-ton usig a collision loss, depth ordering loss, and inter-acio o dea heaviy occluded object,a novel 6 DOF estimation is proposed that uses in-painting refine segmentatin h occludeobject for mproved pose esiaton Finally,we propose a gloa ojective funcion that scores ob-ject layouts, orienations, collision, shap solvers are to obtan globaly optimized poses humans and objects.Our contributions are: A method for generating scene reconstructionfroma single imag captuing interactions hu-mans an betwen and objects within the scen,all wthout relying onany explicit 3 supervisin.",
    ". Estimating 3D Humans": "human is parameterized pose shape R10, and a wek-perspecti camer = [ x, R3. Thu,e 3D o he SMPLmodel for ith humanare repesented as Mi  J(i, i) + [tx, f.",
    "Nazeri, Eric Ng, Tny Joseph, Faisal Z Qurehi,and Mehrn Ebrahimidgeconnect: Generative imageinpainting with dersarial ed learnng.arXiv 5": "Neural body fitting: Unify-ing deep learning and model based human pose and Deep mesh reconstruction from single rgb * \"S imagesvia topology modification networks. In Proceedings of Conference on Computer Vision,pages 99649973, 2019. Learning to 3d human pose shapefrom color image. In Proceedings of IEEE con-ference vision and pattern pages459468,",
    ". Quantitative evaluation with PHOSA , ROMP,and BEV. BEV and ROMP only reconstruct humans. Equa-tions of each evaluation parameter are given in the supplementary": "Qualitative results of proposed method on test imagesfrom 2017 comparing to PHOSA, ROMP, BEV forhuman-human interactions. Our method gives * \"S andcoherent reconstructions for images multiple humans. For quantitative we employ forced-choiceassessment approach to PHOSA on COCO-2017 images since are no ground truth an-notations for people and objects in images the the test set, we selected a * \"S of and performed reconstruction on compare our method with PHOSA, andBEV by reconstructing the scenes comparing degreeof collisions for human-human EHcol and human-object incorrect depth ordered human-human EHdepth and human-object EHOdepth interac-tions that results from each method. This is acrossall images to estimate values in. Our approachoutperforms state-of-the-art techniques for both multi-human and multi-human-object reconstruction, asresults a coherent and realistic reconstruction withsignificantly fewer ambiguities.",
    "Diederik P Kingma and Jimmy Ba. Adam: A method forstochastic optimization.arXiv preprint arXiv:1412.6980,2014. 4, 6": "Pointren: Imae as renering ro-ceedings f IE/VF * \"S on pattern recgniio, pages 9799808, 20. 3, 5, 6 Hedvig Kjllstrom, Kragic, and Michael Blck. Tracking people interacting wth In 2010 Society Conference on Computer Vision Pat-tern Recognition, ages 74774. IEE 2010. Video infeence forhuman body pose andshape stimation.Procedingsof te IEEE/CVF con-frenceon computer vision and pattern recogniion, pages52535263, 020. Georgios Pavlakos, Michael J Black, andKosta Daiilidis. Learning o reconsruct3d * \"S huma posand sape model-fitting in theIn Proeedings ofthe IEEE/CVF international on 22522261, 2 Nikos Koloouros, Georgios Pavlakos, andKostas Dani-ilidis. Convolutional msh regression for sing-image shap reconstruction. Nilesh Kukani, Misra, Shubham Tulsiani, ad Abi-nav 3d-renet: Joint object ad relaional netork In Proceedings of the IEEE/CVF n Compter Visio, 22122221,219. In Proceedings of the IEEE conferene on com-puter pattern recognition, paes353568,2018. 5 Xueting Li, Sifei Lu, Kihn Shalini DeMello, Yang, and Jan Kautz. 2.",
    ". Discussion": "Cuent for reconstructingsinle image often con-tain varous ambiuitis, especially situatins interactions between humans and between huanandobjects. In thi paper, we holistic3D sceneperception by expoiting the information from human-object nteactions in anoptimiationfamework. The opmization makes o severa con- . we illustratedifferences in humanreconstuctionsgenerated b PHOA, ROMP, BEV,and Ou pproach when p-ided with input Our produes more plausilereonstructions wth a in ms maintainng coherence. strant to provide a full sen is globally consistent,and rduces olisions, and improves arrangement() other Thehumn op-tmizationfamework resolvs abiguities recon-strucd people, and the proposd hman-object timiza-tio framework addressesbetwen andobjects. We further methohatthe pose estimatioof heavily demonstrae our qualittive and quntitative evauations that the propose method outperform other ethodsand produces rconstructions with noticeably less ambigu-ity.",
    "Abstract": "Existing methods for reconstructed objects and humansfrom a monocular image suffer from severe mesh collisionsand performance limitations for interacted occluding ob-jects. Notably, our proposedmethod operates effectively on images from real-world sce-narios, without necessitated scene or object-level 3D su-pervision. This paper introduces a method to obtain glob-ally consistent 3D reconstruction of interacting objects andpeople from a single image.",
    "Katsushi Ikeuchi and Berthold KP Horn. Numerical shapefrom shading and occluding boundaries.Artificial intelli-gence, 17(1-3):141184, 1981. 2": "Wen Jiang, Nikos Kolotouros, Georgios Pavlakos, and Kostas Daniilidis.Coherent reconstruction ofmultiple humans from a single ofthe IEEE/CVF conference on computer vision and patternrecognition, pages 55795588, 2020. 2, 4 Jiang, Suyi Guoxing Sun, Su, Kai-wen Guo, Yu, and Lan Xu. 3 * \"S Hanbyul Joo, Natalia Neverova, and Andrea In InternationalConference on 3D Vision (3DV), 4252. IEEE, 2021.1, 3 Angjoo Michael J David W Jacobs, andJitendra Malik. recovery of human shape andpose. 1, 2 Kanazawa, Shubham Tulsiani, A Efros, andJitendra Malik. category-specific reconstruc-tion from image collections.In * \"S Proceedings of the Euro-pean Conference on Computer Vision (ECCV), pages 2018. 2",
    "Karen Simonyan and Andrew Zisserman. Very deep convo-lutional networks for large-scale image recognition. arXivpreprint arXiv:1409.1556, 2014. 2": "In the IEEE/CVF international pages 1117911188, 2021. Guoxed Sun, Xin Chen, Yizhang Chen, Anqi PeiLin, Jiang, Lan Xu, Jingyi Yu, and Jingya Neural free-viewpoint performance rendering under complexhuman-object 3 Sun, Qian Bao, Wu Liu, Yili Fu, Michael J Black, and TaoMei. 3. 1, 4, * \"S 6, 7 Yu * \"S Sun, Wu Liu, Qian Bao, Yili Fu, and JBlack. Putting people in Monocular 3d people in Computer VisionECCV 16th Eu-ropean Conference, Glasgow, UK, 2020, Pro-ceedings, Part IV pages Springer, 2020.",
    "The proposed method takes a single RGB image as inputand gives a spatially coherent reconstruction of interactinghumans and objects in the scene, an overview is shown in": "3. 3. 2). 1), which gives incorrect spatial reconstructions with col-lisions between meshes. First, objects and humans are detected,followed by SMPL-based per-person reconstruction (Sec. To correctly estimate 3D ob-ject pose (6-DoF translation and orientation) a differentiablerenderer is using that fits 3D mesh object models to the pre-dicted 2D segmentation masks. 3. Our framework produces plau-sible reconstructions that capture realistic human-humanand human-object interactions. We correct the oc-cluded object mask using image inpainting (in Sec. We exploit human-human and human-object in-teractions to spatially arrange all objects in a common 3Dcoordinate system. Lastly, we perform joint optimization that takes into ac-count both human-human and human-object interactions fora globally consistent output. 3)unlike * \"S PHOSA which uses an occluded object mask. The human 3D locations/posesare translated into world coordinates and refined througha human-human spatial arrangement optimization used acollision loss (Sec.",
    "Oursfront-view top-view": ". Coparion of thesegntation maksand with PHOSA. Te segmentation mask of the occludedresulting in erroneous recnstruction The proposed uses to remove the occlusion generate a bettersegmentation mask, which leads a reonstruction. in the ground truth ementation, the pern at pixelposition p i represented b (p), and the ersonindex in rendered 3D meshesis y() and = y(p).Dy(p)(p) and represent thepixeldephs.",
    "Georgia Gkioxari, Jitendra Malik, and Justin Johnson. Meshr-cnn. In Proceedings of the IEEE/CVF international confer-ence on computer vision, pages 97859795, 2019. 2": "A papier-mache ap-proach to larnng 3d srace generation. In Proceedigs ofthe IEEconfernce n pattern reog-nition, 216224, 2018. 2 Riza Alp Guler and Kokkino. Holopose: Holis-tic human in-the-wild. arXiv * \"S prerint In Proceedings conference pages 2282229, Populating scenesy learning interaction. In Proceedings ofthe Conference n Computer Vision an pages 1470814718, 2021. Yana GulDimitros Tzinas, Igo Kale-atyh, Mihae J Black, van Laptv, and Cordelia Schmid.",
    ". optimize using a gradient-based optimizer w.r.t. translation ti R3 and intrinsic scale si R for theith human rotation Rj tj R3": "C(h)and C(o) the centroid for the object To handle interactions, the fine interactionloss is defined =. The objectposes initialized from Sec. 3. Interaction loss loss handlesboth and fine interaction between humans andobjects in , defined + Lfineinter. Thecoarseinteractionlossis:Lcoarseinter= hH,oO o)||C(h)C(o)||2,where(h, o)identifies human h and object o are interactingaccording to bounding box overlap criteria. sj R for the object instance jointly.",
    "Gerard Pons-Mollnd Boo Rosenhan. posestimation. Visual Analysis ofHumans:Lookin at People,pges 13170, 2011.": "Multi-level pixel-aligned implicit function forhigh-resolution 3d human digitization. Frankmocap:A monocular 3d whole-body pose estimation system via re-gression and integration. dynamic scene graphs: Actionablespatial perception with places, and arXivpreprint arXiv:2002. 2 Stephan R Richter and Stefan Roth. 3d scene reconstruction single InComputer VisionECCV 2020: European Conference,Glasgow, August 2328, 2020, Part II 16,pages 366383. Proceedings IEEE/CVF Conference Vision and pages 8493,. 3 Antoni Arjun Marcus Abate, Jingnan Shi,and Luca Carlone. 2 Saito, Simon, Jason Saragih, HanbyulJoo. In of on Computer Vision, pages 17491759, 2 Bodo Rosenhahn,Christian Schmaltz,Thomas Brox,Joachim Weickert, Daniel Cremers, and In2008 IEEE Conference on Vision and PatternRecognition, pages 18. In of the international confer-ence on computer vision, pages 2019. Matryoshka networks:Predicting 3d geometry via nested shape 2 Yu Takaaki Shiratori, Hanbyul Joo. Springer, 2020. Stefan Pablo Bauszat, and Ferrari.",
    ". Ablation Study": "Theidentical force-choicetest siilar * \"S to conducefor the (Equatio 7), by omiting losstermsfrom te proposed metod masuring he col-lsion loss prevents mesh intersection an the the bjt poses remain consistent mask. An ablate stdy * \"S was cnducted to assess thete los ters in."
}