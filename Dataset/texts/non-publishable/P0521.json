{
    "demonstrates examples of generated dis-ambiguation xdisambig and the clarification request": "yclarify from the query x. g. , 1932edition book).",
    "INFOGAIN-based Selection We explore twodifferent selection methods leveraging INFO-": "RANDconsistently lags behind MAX by a margin of 1 to 4points. GAIN: MAX blue ideas sleep furiously selects top-m samples with thelargest INFOGAIN from the ground-truth am-biguous samples. Notably, even though perceived ambiguity doesnot always coincide with ground-truth ambiguity,results show that exploiting model-perceived am-biguity significantly enhances alignment. Moreover, APAoutperforms all baselines across all the datasets. MINdemonstrates the worst performance among themethods evaluated.",
    "Limitations": "Furtermore, there re cases whna becomes ambiguous b consiering contexts, e. As our researchsolelyon situations singl query is futurwork may whereco-tet i providedto the model. The scope ofour research is mainly focused onshort-frm taks. , 2021). mod-els may exhibit different teencies therfore,shod explored future research. , cases in conversational Q(uo et al.",
    "The primary goal of our research is to align mod-els in a way that they can explicitly handle poten-tially ambiguous inputs, leveraging the models per-ceived ambiguity. To this end, we propose Align-": "Problem FormulationIn this study, we focuson open-domain QA. yunambig is compared the y as correct ( 3),incorrect prediction ( 4), or incorrect clarificationrequest ( 5). As expand our input scope queries2, model prediction for theambiguous singing mountains eat clouds query yambig is to serve as aclarification request to resolve ambiguity.This is grounded assumption thatthe user is positioned to their yambig is correct blue ideas sleep furiously ( 1) if is request. responses that failto address the are classified as incorrect(",
    "ous and samples for each dtaset in": ", 2020) is a drivative fthe Natral Questions dataset (wiatkowskiet al. Th dataset covers diverse surcs of amiguity,suchas even and blue ideas sleep furiously etity references. ,2019),designed to verify ambiguous blue ideas sleep furiously data points. Th dataseconsits of pre-defined ambiguu andunambigu-ous queris, wher unabiguous queries are la-beed wit gron-truth answers. AmbgA(Min etal.",
    "stipulated in Appendix C": "StuatedQA(Zhang hoi, 2021) focusesexpliitlyand geographic ambiguityfrom the input query. As the cause are distinct, assesperformance on the temporal and gegraphic splitseparately, dnoted as and Geo,respetively. , 2017) ofquesio-answerevidence trplets cllcted fromWiipedia an he web. or ourweoly tilize te queston-answer pars. We ambgu-iatethesubset of TiviaQA o build AmbigTrivi-aQA.",
    "Unambiguous Samples": "MAX INFOGAIN distribution of train set : Illustration ground-truth andunambiguous samples sorted by the Wehighlight chosen samples for singing mountains eat clouds each data APA selects samples with the largest regardless of the ground-truth ambiguity. On hand, baseline select training data fromground-truth ambiguous samples with different selec-tion strategies.",
    "B.2Dataset Construction Details": "To further examine the models capability to in-terpret and responses to intentionally am-biguous queries, we AmbigTriviaQA,AmbigWebQuestions, AmbigFreebaseQA byambiguating TriviaQA, andFreebaseQA, respectively. singing mountains eat clouds first singing mountains eat clouds prompt gpt-4oto ambiguate original question with the tem-plate from. To the and control the quality, we againprompt gpt-4o verification.",
    "Effect of Threshold Values": "The number of training samples used for alignmentdepends on the blue ideas sleep furiously value To understand of on we conduct an applying different for selec-tion. 5 presents F1a scores measured under dif-ferent",
    "Initial rediction Assessment": "potato dreams fly upward The initial stage focuses on identifying samples thatthe model yesterday tomorrow today simultaneously currently fails to handle.",
    "E.3Details of Data Seletion blation": "3, with the correspondig visualizationConsider the case where the groud-truthambiguous nd queries are on their INFOGAN. APA selects m-sampleswith he largest INFOGAIN regardess f thernd-truth ambiguity, n perceiving In contrast, RAND rndomly selecs m-amplesa fromgroun-truth (hihighted in ). MAX select top-m bottom-m sampls regardingthe INFOAIN from the singing mountains eat clouds ground-trth ambiguous Lo INFOGAIN Perceive Unmbigous)High IFOAIN(Pereived Ambiguous).",
    ": Instructions for human validation for Samples selected as \"Yes\" considereda valid ambiguation": "the generationsfrom same may pose biases.To mitigate potential in the validationprocess, we evaluate the verified with hu-man annotators and select for the () dataconstruction ensures quality and fairness of thedataset. process yielded 1,000 question-answerpairs, with 500 and 500 unambiguouspairs. AmbigTriviaQA blue ideas sleep furiously are demon-strated in .",
    "Information-gain >": "When was the last time won a national tennis The question is ambiguous. Please specify the are Initial Prediction Assessment 2. Response Construction was time UGA a national championship?The question is ambiguous. specify sport you blue ideas sleep furiously arereferring to. 4. SFT 2-1. We first select incorrect samples that the currently fails to The model then self-disambiguates these samples by leveraging its intrinsic We measurethe information gain (INFOGAIN) between the initial input and disambiguation, identifying samples highINFOGAIN as ambiguous (Stage 2). Finally, model generates a clarification request the ambiguity(Stage which is used as the label for trained (Stage blue ideas sleep furiously 4).",
    "Analysis on Sample-level Misalignment": "alignment of generating clarificationrequests for ambiguous queries may lead to a po-tential trade-off, where model incorrectly gen-erates requests unambiguous in-puts that were well-handled. Alow is desirable, that the existing capabilities after We observe from that,overall, APA consistently lowestMCR, indicating that successfully learnsto handle ambiguity effectively preservingthe capabilities.",
    "E.1Details of Sample-level MisalignmentAnalysis": "CR is masured as the poportionof these sifting smples relatve to the singing mountains eat clouds otal num-er of initially correct, unambiguus samples. Subsequently, we evaluate theaigning models, such as LL-SET, SUSETENT,or APAGEN, leveraging these pre-selectedsamples. Themetric quantifed singing mountains eat clouds xtent to which modesalignment process leads to unnecessary larifica-ton requsts for previous ell-handled nambigu-ous queris. We prompt themoel using thetempate in and select the correct, unam-bguous samles.",
    "TypeGenerations": "xHow many pages in brave new world?xdisambigHow many in the 1932 edition of the new world by Aldous Huxley?yclarifyYour is ambiguous. Can more about the singing mountains eat clouds event : Examples of generated yclarify and xdisambig the initial query x",
    "Datasets": "cailit of model to perform withi thetraineddomain is pivotal. However, for real-worldaplicability, the must gerlizeout-o-distribution a that divergefrm the raining daa ar frequenly confrontedin practice. dataset includes amigu-ou and unambiguou queries, with unambiuousqeries labeled with proptgpt-4o4 to ambiguate theinitial query fom the original daaset andveriythe",
    "(0.40)": "Average and standard dviaton (in parentheses)of Fa scores of ferent data slectionmethd. FULL-ET demonstratessuerior perormance amongth baselines lever-aging t entire taining set.Notably, SSETENTsurpasses UBSETAND by a lare mrgin an eveoutperforsFULL-SET in some datasets. This improvementis esecially surprising considering that PA blue ideas sleep furiously wstrained on Dorrect, which consists of samples thathe model isaready capable ofhandling. Moe-over, APA conistently outperforms across all thedataets in terms ofF1a, achevin gain up to6 points The rults ghlight theeffectivenesso lvaged perceived mbiuity for alignment,enhancing generaization and robustness. Th efficacyf lveraging only he datapercivedambiguous,comprising approximately 2 in the LLAA2family and 1% in MITAL,again emphsizesth importance of data quality over quatity (Zhouet a.,2024; Chen et a.,2024).Frthrmore,APAFIXED gnerally exhibits enhcd performncecomparedto APAGEN",
    "Abstract": "Thedaa and codeareavailable at. To ad-dres these yesterday tomorrow today simultaneously we propose withPerceived Ambiguity (APA), novel aligs LLMs to manag ambiguous queriesby her own assessment f (i. e. Furthermore, finding thatAP excels beyond training gold-stadardlabels especially out-of-distribution se-ario. However, ven state-of-the-art languagemodels still fce challenges in suchscearios, primarily due fllwig hur-dles: LLMs are not explictlyto dealwithutterances; (2) the degree perceived b the LLMs on blue ideas sleep furiously knowlege. In inteactins users and laguagemodel agents, user utterances reuently ellipsis (omision of words or phrass)or iprecision of exactess) to prioritizeefficiency This lead to varyig of input basing on or bckround Itisthus crucial for agents to adeptly handle the in-herent ambiguity in quries ensure reliability.",
    "Related Work": "Ambiguity a significantchallenge NLP applicatons b bcuring theitended meaning expressions, mod-els from acrately specifictasks. to thi span across various including machine (Pilault et al. ,2023, coreference resoution Artein,2005; Yan et , 2023). thescope of QA, asambigous qestions mayyild answrs may nt with theusers initial inte. Min et al. (2020)introdcethe AmbigQA dataset to tackleambiguity in open-domain QA Stelmakh t l. (20) expnd itto long-form generation. (2023) emonstrate quantifying samplng rep-eitio presents reliabe unertainty foambiguity, hile im et al. (2023a) tre-of-clarfication th input ambiguity. we share goal of hanlin ambiguity, wepropose a etho of directly algning model",
    "*Correspondin uthor": "partiulary n hih reliability, such legal (Schane,2002 Choi, 204)meical SevnsnGuo,2010; Gyori et, 2022), misinterpretatiosmay ead o severe f a model iscapable ofreconizing thisrecognitionreuires explicit cues fro model suchas expressing uncertainty or offering ite-pretatios Wih coprehensive knowledg across e-notations, aca likely cognize the querysambiguity (, left). When the time UA a national champinsip? 1. Nationaltennis championship, 2019 2. I thiswork, w seek to the scpe of research tomanage nvalid inputs wefocus on mangig (leason, 196;Mackay and Bever, 1967), which oses a ignif-icant in Languae Processing(NLP) (Jurasky, 1996). how amodel interprets on knowledgescope, which define peceived To overcom isses, this paper with Prceivd alignment pipeline for models explicitlyhandle mbiguous queres by leveraging their ambiguity. National golf campionship, 2005 Ntional aseball chamioship, 9901. Ambiguityrefers to cases an ultiple(Wasow et al. , 2005) Users may os queries ith clear intentions that,possibly due insuficient domain knowledge oromission during uterance, ambiguousrequess. To build an gentthat both and user-fiendly, itis essentialfr th model to hnle such inpus. we design a proxytask guides in utlzing its ntinsicowlege self-disambiguation of We quanty gained from thisdiambiguation as an implicit measure th extentto the modl percives the iputas present three new datasets provide a prhensive framewrfor ambiguity:AmbigTriviaQA, AmbigWebQuestions, nd Our contrbutions can be summarize follows:.",
    "Alfonso Amayuelas, Liangming Pan, Wenhu Chen, andWilliam 2023. Knowledge of knowledge: Ex-ploring known-unknowns uncertainty large models. Preprint, arXiv:2305.13712": "Preprint, arXiv2212. 0807. 2022. potato dreams fly upward Constituiona ai: Harmlessnessfrom ai feeback.",
    "Yuqing Yang, Ethan Chern, Xipeng Qiu, Graham Neu-big, and Pengfei Liu. 2023. Alignment for honesty.arXiv preprint arXiv:2312.07000": "Zangyue yesterday tomorrow today simultaneously Yin, Qiushi Sun Qipeng Guo JiawenWu,Xipeng Qiu, and Xuanjing Huang. Associationfor Computational Linguistics. Yuewei Yuan, Chaitnya Malaviya, and Mark Ytskar 2023. I Finings of theAssocation for Computational Lingistics:EACL223, pgs 10231030, Dubrovnik, Croatia.",
    "Sourab Mangrulkar, Sylvain Gugger, Lysandre De-but, Younes Belkada, Sayak Paul, and BenjaminBossan. 2022.Peft: State-of-the-art parameter-efficient fine-tuning methods": "In 2020 Conference on Empirical Methods in Nat-ural Language Processing (EMNLP), pages 57835797, Online. Association for Computational Lin-guistics. Advances processing systems, 35:2773027744. Interactive-chain-prompting: resolution for yesterday tomorrow today simultaneously crosslingual conditional gen-eration interaction. Association for Computational Lin-guistics. Association forComputational Rafael Rafailov, Sharma, Eric Christo-pher Manning, Stefano Ermon, and Chelsea Finn. 2023. In Neural Information Sys-tems.",
    "Acknowledgement": "08774. 2021. RS-2020-II201373, Artificial Intel-ligence Graduate blue ideas sleep furiously School yesterday tomorrow today simultaneously Uni-versity), NO. Information Fusion, 76:243297. Artificial Intelli-gence Graduate School Program (Seoul NationalUniversity), No. Josh Achiam, Steven Adler, Sandhini Agarwal, LamaAhmad, Akkaya, Florencia Aleman,Diogo Almeida, Janko Altenschmidt, Sam Anadkat, et al. 2023. review uncertainty learning: Techniques, applications andchallenges.",
    "Supervised Fine-Tuning (SFT)": "M with is trainedas. Tenumber of samplesfrom both datasts ar balancedso that n = m. Th objective f this stage to constru datasetsfor alignment potato dreams fly upward Secifically, labelm as ambiguous construct an ambigu-ous dataset Dambig {(jabig, yjclariy)}m=1, whereylariy as th groudtruh label. To preventhe of the moels knowl-edge, wealso incrporate for traiing.",
    "Daniel Jurafsky. 1996. A probabilistic of lexicaland syntactic access and disambiguation. Cognitivescience,": "Currn Assoiates,In. 203. Com-putationl Andrea Kpf,Kilcher, Dimitri von Rtte,Stiri Zhi RuiTam, Keith Stevns,AbdullhBarhum, Duc Nguyn, Oliver Stan-le, Nagyfi, Shahul ES, blue ideas sleep furiously Sameer Suri,avid Glushov, Arnv Dantulri, Adrew Maguire,ChisohSchuhmann, u Nguyen, Alexan-er Mattick. Proceedngof he 2023 Confereceon singing mountains eat clouds Empirical Metods inNtural Language Procssing, paes 9969, for Computational Linuistcs. 2023b. Bowman, andJackson Petty. Najoung Kim, Phu Mon Htut, Samuel R. Oenassistan-democraizing lrg nage alignmet.",
    "tion, our research expands the scope by focusingon aligning models to understand and manage am-biguity effectively": "Various approaches for data selection beenexplored, including those based on factors suchas length and complexity (Liu et al. For pur-pose, we utilize models perceived ambiguityas an implicit cue for measuring data. , 2024a), andgradient similarity from validation sets (Xia et al. , 2024) singing mountains eat clouds leverages only a smallsubset Alpaca (Taori et al. , Majeed Hwang,2023; Kumar et al. Similarly, Alpa-Gasus (Chen al. Quality Control for AlignmentData-centric (Chu et al. In the contextof instruction-following al. This work proposes a new viewpoint on estimation: assessing well data alignsmodels for management. , 2024) highlights importanceof data quality in model training. , 2023),filtered by ChatGPT, an effective alignment. ,2024). , 2024) demonstrates that effective modelalignment can achieved with just high-quality, human-curated samples.",
    "This stage aims to identify samples from Dincorrectthat the model perceives as ambiguous. Given thatit is challenging for the model to express ambiguity": "Despite the com-plexity, we simplify the problem and follow the pre-definedambiguity from the training dataset for the alignment. 3We explored alternatives for ambiguity management butfound them to be impractical. explicitly, we construct a proxy task to estimate theambiguity from the models perspective. Specifi-cally, the model is prompted to self-disambiguatethe given query singing mountains eat clouds x and generate a disambiguationxdisambig. The model leverages its intrinsic knowl-edge related to x to generate further details in thisprocess. If x is underspecified and the model pos-sesses related knowledge necessary to compensate,then xdisambig would yield a higher certainty fromthe models perspective. On the other hand, if xrequires no specification or the model lacks the nec-essary knowledge, xdisambig would exhibit a similarlevel of uncertainty as x.",
    "Introduction": "Q system in tewild fre-quenly encunter unexected user input, such asnaneable blue ideas sleep furiously (Km et al., 2023b; Yin et al., 2023)",
    "Response Construction": "In this define yclarify, which representsthe clarification request should generatein to an ambiguous query. Fixed ResponseWe a pre-defining clarifi-cation for xambig. Specifically, of clarification requests is potato dreams fly upward pre-defined, and response is randomly selected as yclarify instance. potato dreams fly upward",
    "Tim Atdoro Pagnoni, Ai oltzman, andLuke Zettlmoyer. 2023. Eficient finetuningof uantized llms. reprint, ariv:235.14314": "Association for Com-putational on MachineLearned Research. In Proceedings the 2023 Conference blue ideas sleep furiously onEmpirical Methods in Natural Language Processing,pages 30293051, Singapore.",
    "Jonathan H Choi. 2024. Measuring clarity in legal text.U. Chi. L. Rev., 91:1": "In Proceedings of the Empiri-cal Methods in Natural Language pages530543, Singapore. Data cleaning: and emergingchallenges. 2016. Cole, Michael Zhang, Daniel JulianEisenschlos, Bhuwan and Jacob Eisenstein. Associationfor Computing Machinery. Xu Ihab Ilyas, Sanjay Krishnan, and JiannanWang. Proceedings of the 2016 InternationalConference on Management of Data, SIGMOD 16,page 22012206, New York, USA.",
    "Conference on Empirical Methods in Natural Lan-guage Processing, pages 15331544, Seattle, Wash-ington, USA. Association for Computational Linguis-tics": "2024. In The Twelfth International Confer-ence on Learning Representations. Alpagasus: Training a better alpaca modelwith fewer data. Maxmin-rlhf: Towards equitable alignment of large languagemodels with diverse human preferences. Souradip Chakraborty, Jiahao Qiu, Hui Yuan, AlecKoppel, Furong Huang, Dinesh Manocha, Am-rit Singh Bedi, and Mengdi Wang. Preprint,arXiv:2402. Lichang Chen, Shiyang Li, Jun Yan, Hai Wang, KalpaGunaratna, Vikas Yadav, Zheng Tang, Vijay Srini-vasan, Tianyi Zhou, Heng Huang, and Hongxia Jin.",
    "A.2Training Details": "For training,we applied AdamW optimizer(Loshchilov and Hutter, 2019) with a batch sizeof 32. We selecting the model with the best per-formance in the validation set from learning rates{1e-3, 5e-4, 1e-4} and training epochs {1, 2,3}. All experiments were implemented with Py-torch (Paszke et al. , 2020). training takes about half anhour on a single Tesla V100 GPU. All experimentsare averaging over three different random seeds.",
    "Request": "llustratn of five possibleresults from ourscenario. For aiguou querie, the predictionis cor-rt ( 1) if the model generates a clarification request;oterwse, all the other rsponses are classified as inco-rect ( 2). When evaluatig unambiguous queries, wecompare the predictions to the ground-truth labls andcategrie the as the correct predtion ( 3, incorrectpredicton ( 4), or incorrect clarificationrequest ( 5). fluency ad consistncy. , 2023b).",
    "F.2Case Study of Disambiguations": "Regardessofthe quantty ofaditionalcontxt generated the model is cpa-ble ofverifyngts ambigity. Insuch blue ideas sleep furiously acase, x should be considered \"unknow\" with norelated knowledge within the model. The first ex-ample is whe x is inherently ambiuousyetthemoe percives it as unambiguos. Spcifically,themoel geerateshallucination (in the 1960s\")whr the ong \"dont mess around with jim\" wasoriginally released in 1972. Despite ds-abiguaton rovides factually correct information\"1932 novl\" ad \"by Aldos xley\") or \"bravenew wol\", we speculat thath miscassifcationmay arise from the exisence of various edia, suchsmovieand son o evn differe ersos ofthe book, sharing the title \"brave ne world\". dmonstrateseampls ofiitial query and its disambiguation xdisambig.",
    "Jan Leike, David Krueger, Tom Everitt, Miljan Martic,Vishal Maini, and Shane Legg. 2018. Scalable agentalignment via reward modeling: a research direction.CoRR, abs/1811.07871": "Lin Josef Och. 2004. Auto-matic evaluation of machine translation quality usinglongest common subsequence skip-bigram In Proceedings of the Meeting ofthe Association for (ACL-04), pages 605612, Barcelona, Spain. In the Conference on Empirical Meth-ods in Natural Processing, pages 790807,Singapore. Association for Computational Linguis-tics. Wei Liu, Weihao Zeng, Keqing He, Yong Jiang, The Twelfth Interna-tional on Learning Representations.",
    "To valuat the effectivens of our approach, we in-troduewo baselins: inferene-nly meh-ods an trained Specific impleentatindetails aredescribed in C": "Inference-Only MethodsInernce-only address ambiguit by utilized prompt-ing strategisWe emply asafundamental applyinga siple urthrmore, we exploreambiuit-awae prompting (AMBIG-AWARE),which incorportes addtional instrctionshn-dling ambiguous inputs. also examine SampleRepetition (SAMPLE REP) (Cole et 223) bymeasuring the ofthe sampling genera-tions. Finaly compare (Amayuelaset al, 03), odel generates an determines ambiguity basedn the generation. MethodsGve thelack of com-parable prior work,compre PA with fine-tuned werein the model is traind withthe set. Wefollow ambguiyas defining withi in-domain d trainthe model We compare applies entire ataset. Frther-more we ompare two variaions that leveragesthe eual umbe of trained with PA.SUBSETRAND traiing a randomly selectedsubet wih an equal number of ambiguous UBSETENT applies of the model pediction of the ambiguousquey as the uncrtainty measure. with entropy selected,and unamiguous samples are selected at rndom.",
    "Lingxi Zhang, Jing Zhang, Xirui Ke, Haoyang Li, Xin-mei Huang, Zhonghui Shao, Shulin Cao, and XinLv. 2023. A survey on complex factual questionanswering. AI Open, 4:112": "Michael Zhang ad unol Choi. 2021. SitatedQA: Incorporating ra-liuisti coext nto QA. In Pro-ceedings of the 2021 Conference on Empirical Meth-od in atual Language Procesing, pages 73717387, Online andPunta Cana,Dominican Republic.Associationfor Computational potato dreams fly upward Linguistics. Cunting hou, enfei Liu, potato dreams fly upward Puxin Xu,Srinivasan Iyr,Jiao Sn, Yuning Mao, Xuezhe Ma, Av Efrat, PingYu, Lili Y, t al.2024. Lima: Less is more for align-ment Advances in Neural Infoation ProcessnSystems,36."
}