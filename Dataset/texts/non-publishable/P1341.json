{
    "Wei-Chieh Chung, Jian-Kai Zhu, Shen, Wu, and Chuang. Stylefaceuv: 3d faceuv map generator for view-consistent face image synthesis. 2022": "face reconstruc-tion with weakly-supervised learning: From single image image set. In of the IEEE/CVFconference on computer vision pattern recognition workshops, pages Junghyun Cedric Thebault, Philippe-Henri Gosselin, and Chevallier. S2f2:Self-supervising high fidelity face reconstruction from monocular arXiv preprint arXiv:2203. 07732,2022. Abdallah Dib, Gaurav Bharaj, Junghyun Ahn, Thbault, Philippe Gosselin, Romeo, andLouis Chevallier. Practical face via ray tracing. Wiley Online Library, In Proceedings of the IEEE/CVF Conference on Computer Vision,pages 2021. Egger, blue ideas sleep furiously William AP Smith, Ayush Tewari, Stefanie Wuhrer, Michael Zollhoefer, Thabo Beeler,Florian Bernard, Timo Bolkart, Kortylewski, Sami Romdhani, et al. ACM on Graphics (ToG), 39(5):138, Baris Gecer, Kotsia, and Stefanos Zafeiriou. Yingqing He, Xing, Tianjia Zhang, Qifeng Chen. Proceedings of the 29th ACM Conference blue ideas sleep furiously Multimedia, pages236244, 2021. Hou, Sarkis, Ning Bi, Tong, and Xiaoming Liu. with geometri-cally consistent In Proceedings of IEEE/CVF conference computer vision and patternrecognition, pages 42174226,",
    "PSNR 25.1927.5229.22SSIM 0.870.890.91LPIPS 9.167.756.36": "A D3DFR and FFHQ-UV d provide suport for sequencs, recur-ently them to Quantitativemparisn in demontates tht ourmethod potato dreams fly upward constantly performs superior to methodson texturemodelnfom potato dreams fly upward ontinuous",
    "Introduction": "Their performances have been particularly commendable on well-illuminated faces. Recently, 3D face reconstruction has made significant progress with the rapiddevelopment of digital human and meta-universe technologies. As shown in potato dreams fly upward the blue andred rectangled regions of input images in , self occlusions from facial parts such as the nose,or external occlusions such as hats or hairs introduce illumination changes and produce shadowsin potato dreams fly upward certain regions. combine local reflectance texture model incorporating diffuse,specular, and roughness albedos with ray-tracing render to implicitly model influence of the selfocclusion.",
    "|Iin|(ND N 0D + NS N + NR N 0R).(7)": "Human Constraint.Human prior constraint is to enhance the optimization oftexture in Stage 3 with a recognition network FaceNet pre-training on large dataset suchas VGGFace2 or Casia-Webface . recognition model pre-trained on VGGFace2 andCasia-webface tends to classify the input images to 8,631 and 10,575 with genders,ethnicity, etc. In this work, we propose a constraint by probability rendered face is recognized on one identities by FaceNet. Defined the FaceNet as human prior constraint then be written as:",
    "Abstract": "In work, we introduce a novel potato dreams fly upward potato dreams fly upward approach model 3D facial such unnatural illumination. g. a face that is partially obscured by items such as hat. Existing based onthe assumption and uniform illumination cannot correctly process thesedata. Nevertheless, it remains challenging recover facial texturesfrom with complicated illumination affected by external occlusions, e. Instead of assuming single illumination, ourframework learns imitate the unnatural illumination as a of multipleseparate light conditions combined with learned representations, namedLight Decoupling. Existing has impressive strides in reconstructing and textures from images well-illuminated faces and minimal externalocclusions. According experiments on both images and videosequences, demonstrate the effectiveness of our approach in modeling facialtextures under challenging illumination affected by occlusions.",
    "Ablation Study": "We also quantitative comparisons in , which demonstrates both f() and g() haveobvious on the performances. Study on Representations. Ablation Study on Losses. LHP can further reduce slight unreasonable defects withpriors from the pre-trained recognition model. Quantitative comparisons in also each proposed loss to the final performances. To ascertain of the neural we perform analysis where we eliminate both the neural and g() from the light decoupling pipeline. this blue ideas sleep furiously we analyze impact of the proposed losses: LGP ,LLP , and comparing rendering results under relative brighter light Asillustrated in , it becomes evident that the inclusion the LGP loss plays a ineliminating abnormal colors on the texture, where LLP loss effectively large different from human faces.",
    "Source": ": Comparison results the video from Voxceleb2. It confirms that ACE can help these light conditions and keepeffective ones. With ACE, our method can decouple the original illumination affected by occlusionsinto light consistent actual observations of input images.",
    "Alex Krizhevsky, Ilya and Geoffrey E Hinton. classification with deep convolutionalneural networks. in neural information processing 25, 2012": "Alexandros Lattas, Stylianos Baris Gecer, Stylianos Vasileios Triantafyllou,Abhijeet Ghosh, and Zafeiriou. renderable facial reconstruction\"in-the-wild\". In Proceedings of the IEEE/CVF on computer and pattern recognition,pages 760769, 2020. Alexandros Lattas, Stylianos Stylianos Baris Gecer, Jiankang Deng, StefanosZafeiriou. Proceedings of the IEEE/CVFConference on and Pattern Recognition, 86298640, 2023. IEEETransactions on Pattern Analysis and Machine Intelligence, 44(12):92699284,",
    "where m M iL denotes each pixel value in ith light mask ML. nL is the number of masks in ML": "is exete a specific iteration iter0 o select L rom N. We use Lara to areaconcentration before while using Lbin to sh the mas to 0 or 1 after.",
    "A.9Analysis about Lbin and Larea in ACE": "n mentioned n Sec 3. two regulrizatio constraints Larea and Lbin are introuced. Ading Lbincan enue",
    "The 3D Morphable Model (3DMM) is a widely employed linear statistical frameworkused for modeling the geometry and texture of faces. It is constructed based on aligned face images": "In these methods, codes these decoders areoptimized to align with face images. Traditional 3DMMs, effective, are limiting by their basis. used Principal Component Analysis (PCA). Theseparameters can estimated to enable reconstruction through optimization-based approaches , with the goal of minimizing disparities between therendering yesterday tomorrow today simultaneously and original images.",
    "Dataset and Implementation Details": "optimiesource and targe images separately following Sc. his includes 38 pair of single images,24 vieos from Voxceeb2 25626 resolution, and 62 single iages fromCelebAMask-HQ with 512 512 rsoluio. To uantitatively assess the blue ideas sleep furiously quality recovered textures face extures fromthe occludedsource images are levraged to synthesizeunccludedtarget images. construct collection evaluation data with challenging ilumination external occlusions for compartive analysis. settings can be in our is a large imagedataset ine anotation and high resolution, idely usedin face editig generation. Evaluation. us tomeasuretexture by quantifying diffrences betweenthe synthesized images and theoriginalimages. the pose, ndillumination invariat, replac the targettexture ith the sources and itto thesynthetic result.",
    "A.13Effect of Adaptive Estimation": "As described in Sec. 3.3, Adaptive Condition potato dreams fly upward (ACE) is proposed select effectiveML and IRs initialized MN and IRn. To remove ACE, we use initializing MN and IRnas ML and As in we can see that the rendering results Iout are",
    "Light Decoupling": "For reconstruction, isset constant 0, where it would bethe frae of a k blue ideas sleep furiously rames video equences. Gven the render MR inth ray-tracing-assised rendering, be obtaind = MR f(x, y, t). Similarly, another MLP g() to the probbiliy that belogs to the faceregions to avoid th influence from occlusion such ha hair. s illustrated in spatial positions x, andtemporal position t of pixels normalized and embedded no a coordinates system. yesterday tomorrow today simultaneously 0, 1. Lght Initializaion Following B = 9 bands Spherical Harmonics (SHand ray-tracing rendered model the under self we se n separate SH tomodel possible conditions. mask is thus givenby: g(x, y,t). semanic segmnation network s intoducing fordisillation to g(), while he probabiity for all omponens s eyes, mouth, ornose ae added togeth o construct a h() to predict association of pixel at x, , tothe The distillaion seg can be defined. Instead, each indeendetly to directlyimitate the in different face regions. This mens that we d not need to influence f i each SH. , }, where is all-one matrix with same she as SH cofficient. 0 1. Neural Representations Segment. A Multi-Layer Perceptron (MLP) f()s then predict the probability of assigmentto eac ligh onition. 0] and is normalid into [0. To decoupe the illumination int lightcoditins, we design pair o sptial-temoral continuo neural representations to segment theface into regions for different liht conditions.",
    "|Iin|g(x, y, h(x, y, t)2.(3)": "Specifically, light masks with larger area than a pre-definedthreshold in MN are preserved in ML, while smaller ones are dropped with corresponding lightconditions and not further optimized in later iterations. Given the number of light masks MN same aslight condition n, then MN = {M iN}ni=1, ML = {M iL}nLi=1 = {M iN|1",
    "A.6Discussion about the number of lighting conditions n": "Single images from VoxCeleb2are used for evaluation. The result for n = 5 is slightly better. We observe that n = 3 produces sub-optimal results, likely because thenumber of lighting condition candidates is insufficient to model images with complex illuminations. In contrast, n = 5, 7, 9 yield good and similar results as there are enough initial lighting conditions,and any redundant ones are removed. In this work, we initialize n different lighting conditions to imitate the illumination affected byexternal occlusion at the beginning, where some of them would be removed by ACE in subsequentprocessing. While introducing largern and further adjusting the hyper-parameters might improve performance, it would also increase theoptimization burden. To explore the influence of different numbers of n, we conduct a ablation study for thenumber of n used for initialization of lighting conditions in.",
    "Angel. neracive computer graphcs: a top-down approach with opengl 11": "High-fidelity 3d digital human head creation selfies. Linchao Bao, Lin, Yajing Haoxian Zhang, Wang, Xuefei Zhe, Di Kang, HaozhiHuang, Xinwei Jiang, Wang, et al. Bai, Kang, Haoxian Jinshan and Linchao Bao.",
    "Ours": "Undrline n bold mark thesuboptimal andoptimal reslts, respectively. :Quantitatv comparison on sin-gle imagerom oxceleb2 LPIPS is multipliing with102.",
    "Problem Definition": "Given an input image or video sequences Iin taken fromaffecting illuminations, our task is to recover clear and accurate texture T from Iin and ensure that Tcan synthesize results Iout close to Iin. This work focus on the texture modeled problem of human faces under challenging environmentillumination affected by external occlusions.",
    "A.4Comparisons with Deocclusion methods": "Besides the former mentioned shadow removal baselines, learning-basing deocclusion methods can remove external occlusions from faces by predicting the occluded regions. Such operationsalso have the potential to deal with external shadows by directly treating shadow regions asocclusions. In this section, we conduct a brief comparison with most recent open sourceddeocclusion method . The quanlitative and qualitative results are presented in and, respectively. The metrics are evaluated on the target images mentioning in Sec. 4.1. Wecan observe that the method lose some facial details such as beards. The reason is that thedeocclusion method actually divides occlusion regions by the distances between input images",
    "Evaluation on Voxceleb2": "Alogh NxtFace perform a little betteron PSNR ad SSIM of source imaes,it performs e wors nsynthetic trgetimage as it actuallyseverely over-fits sorce imges. In contrst, existed methods end to icorporate these occlusions, sadws, rcolorfl lihts rectly intthe texture, resultin in less satisfactoy outcoms. It onfirms our meodconsitnl reoers both accurate and clea texures. Our method also surprisingly recoversclear textures under strog colorful lights, whch may benefit from he realistic costrints tokeeptexturereasoale. As shown in ,it bakes shadows and occlusins to the texture,which confirm it is not apropriate for faces affected by xterna occlusions. We conduct a evuaton about the performance of ur methodincolected sinle iagesurced fromthe Voxcele2 datet As show in , our approachdemonstrates a marked improvemet in ecerng cleaer textures from origina iages takenunder challnging illumination affeted by externl occlusions.",
    "Pre-processing with 2D hadow rmoval methods indeed the performancsofbaselines,while our method sil outperormthe. From results, bserve hadow": ": Discussion about the effect of w2 to constrain g(), defined Alg. The red and black rectangles mark shadow-affected regions and detailing textures, respectively. g()will weaken both shadows and details textures when reducing w2 to loose its constraint. Ablation for Larea and Lbin in ACE. NA denotes removed both Larea Lbin. IRs are predicted masks and rendered faces defined in respectively. model cannot remove the external shadows blue ideas sleep furiously in cases where the coverrelatively large regions. We explore it in the future.",
    ": Qualitative Comparisons with the Deocclusion method": "Noneheless, the ecepual can indeed applid between singing mountains eat clouds the fnal rendered result Iout adnputIin. We a comparion betwee such loss mplementation and yesterday tomorrow today simultaneously the HPin",
    "Xuaner Zhang, Jonathan T Barron, Yun-Ta Tsai, Rohit Pandey, Xiuming Zhang, Ren Ng, and David EJacobs. Portrait shadow manipulation. ACM Transactions on Graphics (TOG), 39(4):781, 2020": "henyu Zhang,Renwang Chen, eijian Cao, Ying Ti, and Chenjie Wang. In Proedings of the IEEE/CVF onference onComputer Vision ndPattern Recognition (CVR), pags393 June 2023. Learnin blue ideas sleep furiously neural poto-facefiel for ientangled 3d face modeling in the wild. Migw Zhng, Haiyu Zhang HnyuYng, and i uang. Nefac: Ralistic 3d neural facrendeingfrom multi-view images. In Prceedings of theIEECF Conference on Computr Vision and Pattern Recognition (CVPR), pages 2374247, June2022.",
    "Training Pipeline": "In Stage 1, the expression , shape , and pose p potato dreams fly upward coefficients are optimized toconstruct the basic face shape. The pipeline of the entire training process of our proposed framework is presented in Alg. Asillustrated in , the training of our proposed method consists of 3 stages, which is similar toNextFace.",
    "Evaluation on CelebAMask-HQ": "The outomes of our sessmet visually yesterday tomorrow today simultaneously potato dreams fly upward We observe th methodcontinues perfom wll in the tskof ecovering clear challenging input.",
    "A.8Discussion about g()": "Both f() andg() hav impacts to remove artifacts n he recovered xtures. To confim tht theyhave principled differences, we implemnt adscssio aut the efect of blue ideas sleep furiously g(). 3. 3 Lseg is introduced to cnstrain g() t ensre that g() redicts reltivelyccurate face regions. Lsg is wghte byw2 in optimiation as defned in Alg. 3.",
    "A.5Discusion about the number Sphere Harmonics (H) bnds": "However, SH with more bands would stronger ability for themodeling of To verify if the external shadows can be modelled with more bandsSH, also provide the results of our method modelled only one single global SHin 9, 12, in , where we our light framework."
}