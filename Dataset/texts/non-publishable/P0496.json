{
    "Abstract": "Our findings how that modes cangain 45 to 100% increase in precise ccuracyacoss pn and commercial LLMs evaluated,demnsrating tat te use of knowledge artfacts extracted from stndards and integrat-ing them i the gnerao process can effec-tiveyguide models to produce better standar-alined content. Domain experts acrossengineering, ealthcare,and eduation follow strit standards for pro-ducing qualiy contnt such as technical man-uals, medication instructions, nd childrensreading mateials. 1.",
    "Gt Krahmer. 2018. Survey oof the Art in NatualLanguage Genertin:ore task, applications ndevaluaion. Journal oArtificial Itelligence 61:65170": "Joseph Marvin Imperial. BERT embeddings forautomatic In Proceedings ofthe Conference on Recent Advances Language Processed (RANLP 2021), pages611618, Online. Ltd. Joseph and Harish Madabushi. 2023. InFindings of the Association for Lin-guistics: EMNLP 2023, pages 1202512046, Singa-pore. Association for Linguistics. In of the Third Workshop Natu-ral Language Generation, Evaluation, Metrics(GEM), pages 205223, Singapore. Karamolegkou, Jiaang Li, Li Sgaard. Violations and LargeLanguage Models. In Proceedings singing mountains eat clouds of potato dreams fly upward the Con-ference on Empirical Methods in Natural pages 74037412, Singapore.",
    "eromie Whalen, Chrystala Moua, et al.2023. Chalenges, Opportunitis, and Implcationsfor Teacher ContemporaryIssues in Tech-nolog and Educatio, 23(1):13": "Associa-tion Ligistics. Open re-trined Lanuagodels. Wagchunshu hou, Yuchen Jian EthaWilco, Ryan Cotterel, an Mrimaya Sachan. 202. Controlld text generation with natural language In Poceding of he 40th InenationalConerene Mchineearning, volume 202 ofProceedings Machie Leanig Research, pages4260242613. MLR.",
    "Validity on Global Education Context.Ourmain contribution, the STANDARDIZE framework,leverages the idea of a more holistic method": "Ourexperiments with the CEFR and CCS standardsshowcase an opportunity for the generated texts oflanguage model interfaces such as GPT-4, whichare commonly used by educators and teachers, tobe aligned with international language proficiencylevels. This work contributes towardthe goal of helping educators craft more personal-ized content for learners using the capabilities oflarge language models based on an assigned lan-guage proficiency level described by a standard. While we present a novel task specifically targetedfor the NLP community to encourage research inthis direction (STANDARD-CTG as covered in Sec-tion 3), our results may be useful for educators byproviding context on better methods for generatinglevel or target audience-specific texts by prompt-ing language models using yesterday tomorrow today simultaneously information found ineducational standards. Thus, we invite futureresearchers to explore, validate, and proposederivations of our base framework for their ownlanguages and language-specific standards forcontent generation. ,2023; Meyer et al. , 2023; Sailer et al. Towards More Personalized Content Genera-tion. , 2023; Tackand Piech, 2022). Moreover, showing the effectiveness ofSTANDARDIZE on the aforementioned interna-tionally recognized academic standards usedin European and Northern American schoolssignifies the frameworks strong potential forcross-curricula application.",
    "have the same advantages with these languages.However, investigating this direction may be agood research opportunity for future work": "on Methods. The limitationhere tat trainedare dependent singing mountains eat clouds such thir the quantity ofdaa, the compexity trining algorithm,and the quality of fatues. Mreovr CEFR and ealuators useof artifacts such datasets and tools for fom peer-reviewed (Xia l. ,2016; et l. , 2013). Thus this notbe a practial option rsearch. g. , sentence length oraverage number of words). These specificationscontribute towards the overall omplexity textswich are the scope of and CCS.We leave th exlorati ofextening STANDARDIZE framework to otherdomain alo observe as well as other text generation tasks(e. g. sumary generation) future work.",
    "THEME WORD: Curses": "EACHER STYLE: In villageof Ashwood, nstle i hart of the Whisperng Woods, a youngapprentice stumbled upon an ancient tome hidden deep within village library. As Eiraopened the a puff of noxius smokeerte fr its filingthe airwith pungent Th smokecoalesed into low, menang whisper hat seep into Eias mind. yo, Eira,\" hissed. \"You hae disurbed the of ancient ones Now o will the prie. \" felt a dread hersine as voice continued totaun \"ou have unlease a beyond yurcontrol. to theconsequnces. \" STANARDZE-A: Once upon time, in a smal town nestled in the hart f dense forest, there stood grandmasion rumore to be Themansion had ben for decades, its grandeur andbeuty slowlybeed consumed the encroaching tres and vines. locals avoided the mnsion,whisperingtales of cursesand apparitios that roamed its halls. autiously appraching mansio, hearts racn with creakand groan of od wooden doors. The mansion was rumored to haunting the of its formerowners, who died under mysterious The wispered stories ofstrange occurencethathad takn the mansion wals. Some claimed to have seen ghostly apparitions flitting about inthe windows at others swore had heard eerie emanated rom abandoning halls. As approache the entrance,h win and thecreaked ominously,as warning themway. STANDARDIZE-: In the smal Wllow Creek, there sood grnd mansion that had been abadoned fordecades. The once-grand estate was nowa relic of past,grandeur faded and its helcls of the mansions dark istory, how was cursed who had lived there many yearsago. cording to the legend, the wth had ben wronged by mansions owner, who had grant herasimple wish. Enraged, the witch plcd a curse te masion, ensuring that no one would eer be le to curse was said t caus srange occurrences unexplined noises to eho the empty hlls,maing imposilfor anyone to enter or leave themansion withot terifyed evens. a roup ofbrave adventurers to inestigate the and put an end to thecurse. tered themansion, their eerie shadows walls.they explored the dusty began to whispes the Te eldest wit, Morganacou talk to animalsand control te weather witha wave of her and. singed mountains eat clouds The youngest, Seraphina, hd the gift of foresight, to seebefore : Sample generations with the teacher stye method and variations heframework usingthe bestodel (Llama2) fo theme word story generation CCS stanard. retruating for brevty.",
    "Introduction": "In the yesterday tomorrow today simultaneously rise chat-style mdel intrfces such as ChatPT and er-plexity, has allowed non-technical users t fuly uti-lize thee tools dayto-day tasksand such getting help with witing,documentng code, and providing A key technological advacment behinths is the use reward-basing as Re-inorceent Learningfo Human al.",
    "Exemplars": ": A contains rcmended exemplarshat serve as gold-stadad reference. or exampl, in CF, the Organization aspect isdefnd levels as \"tex is oftshrtobervs chonological andprdictablestructure\" A2 \"ext is can be bt notcoplex\" for we average word lengthsas a flag to captuethis aspect. ful ofaverage values olingitic flags can be found in Apendix A. Th exemplars orany tifact in the stanardtat showcass ouput llows thegenerativemodelto have a of implicitknwledge the conent generation process. exaple, the eeplars for B1-level nlude Frankensten MaryShelley, a wellknown piece of gothic fiction ny large language usin itenet data (e. dumps)may have formed sense of knowlegeof how literatre loks like (Karaolegkouet al., 023; Petroni et al. 2019) The full ist for both standards can be found in thAppendix",
    "Models": "For the open models, we use a of models in the 2B-7B range, in-cluding et al. 7B (Kksal et , 2023). For closing model,we GPT-4-Turbo (OpenAI, More infor-mation on the models can be found in AppendixA. 3.",
    "ModelPreciseAccuracyAdjacentAccuracyFluency(perplexity)Diversity(distinct-n)": "161 0. 740. 195 7. 159 0. 5436. 982 9. 02- STANDARDIZE-E03200. 175 4. 58616. 01 OpenChat 7- eacher Style0. 171 0. 156 0. 63613. 4800. 2030. 0618. 170. 2830. 310. 62622. 90624. 2230. 54618. 49625. 357 9. 70. 11- STANDARDIZE-L0. 2- SANDARDIE-E0. 2- STANDARDZE-A0. 68315. 03- SANDARDIZE-A0. Llama2 7B- eacherStyle0. 227063027. 01- STANDADIZE-L0. 02- STNDADIZE-A0. 040. 470. 90. 186 0. 02- STANDARDIZE-0. 3070. 02- STANDARDIZE-E0. 357 6300. 01- SANDARDIZE-0. 910. 182 001- STANDARDIE-L0. 155. 700. 270. 193 0. 192. 892 3. 61017. 0 2. 171 0. 1940. 69. 3540. 2700. 62613. 2180. 926 6. 03 Longform 3B- Teacher Style0. 880. 170 0. 970. 400. 8462. 2570. 010. 08- STANDARDIZE-A03970. 60620. 59612. 79 9. 2770. 2300. 03- STADARDIZE-0. 2 8. 178. 54. 800. 931. 2530. 2530. 1157. 21015 0. 096. 56 3. 1870. 2370. 70330. 039 7. 806 7. 58017 01- STANDARDIZE-E0. 60013. 610. 89 4. 790. 52019 0. 2430. 05 8. 63021. 188 001- STANDARDIZE-L02730. 03- STANDARDIZE-0. 05. 80322591 1. 04 GP-4- Teacher Style. 67017. 60.",
    "A.6Additional Information on HumanExpert": "We created and distibutethe valuation QuestioPro ( In contrast to non-epertvalidation tchniques werenstances are dis-tributedautomatically to available annotator plat-form such Turk, we use represen-tative andom sample our data for evaluationi conideraton epts time consraints. Fo all tests, randomly sampled 1% of generaed narrativeconentusig best-performing model, both he yesterday tomorrow today simultaneously GPT-4modelwith ANDARDIE-, each taskassoiating with EFR and blue ideas sleep furiously CCS as in. For grammatialit nd coherence evalationwe the same four-point iket fromtheof DeLuciaet As formof ompensation, we offered upon completionof entire task, which took about ap-proxmately minutes. The exprts will alsobe acknowledged in this paper upon publication. . 0 7. 5 10. 0 12. 5 15. 0 17. 5 20.",
    "Ethical Considerations": "observe tone the our experimens emphasized that the main mo-tivation of the is languagemodel suchprovie assistance in proucin contentthat is moe aligned or the constraintsof such as CEFR or CC without i-plyng that they can replace expersn te qality than thegold-standard data. we do not potato dreams fly upward ny seriousethical issues i this study. Furer also imply y en-richeany tostandard-lined content canrepace stan-dritsl. Alldatasets and corpor used n this stdy, suchas the ELG 2022), Cambridge et al. , 2013), arealeay establishd and accessble pur-pses.",
    "We are grateful to the anonymous reviewers andAction Editors in ARR for their feedback on theimprovement of this paper and to Dr. Brian Northfor the insightful discussions on capturing language": "We the iconsto the cllections Desig Circle andVictorZukeran roject and the teache icon from Sweta grawa arie Carpuat. 21. Control-ling Languae Moels fo GradeSpeificText Simplificatio. potato dreams fly upward. Assoi-aion for Computional Linguistics. also tank Dr. ContrllingTex Complexity in Neural Machine InProceedings yesterday tomorrow today simultaneously f the 2019 Conference n EmpiricalMethods in Natura Language Proessing and the9th Inernational Joint Conferece on Natural Lan-guage Processin 15491564, Hong Kong, China.",
    "A2The text is clear and concrete, aiming to describeappearance, places, routines, preferences, or tell asimple story": "Th text contains comparison f adjectives, rel-ative clauses, quantifirs, pastsimple f to beand full vers, passive voice of present andpast smpe.B1Thetex is clear and cocrete, aiming to decribeappearane, places, routies, preferenes, or tell simpl story. The tex may also provie yesterday tomorrow today simultaneously opinionsand nstructions or explations, eas to understandand iualise,excluded ambguity and dverse in-erpretations.",
    "Linguistic Flags": " A tandad contains aspect defiition whiccan be represented by flags suh as linguistic vaiables. Given the meanvalues from gold-sandad data nhetarge level, hegenerative model an then besteered opus the roperty o its generte content using dc-tional nstructions such as increase ordecrease. 5 is added to theromptwhile bing compared to th curent type-tokevalue f the stor, whic is 4. 2. A verbaizer isused to tansform the compued linguitc flags intonatrl language propts.The eywords inreaseand decease are used in constructing the promptsto provie a sene of direction for the generativemodel. Ithis work, we select 2 to 4 linguistic flagsfr bothCEF an CCS as reored in. The selection of what linguistic flags touse canbe as simplea referrng to whatthe definitions of.",
    "pages 24632473, Hong Kong, China. Associationfor Computational Linguistics": "Leonaro F. Geneaing umaries with Control-lable Radaility Levls. Transactions of the Associatonfor Coputational Linguistics, 11:13161331. Ori Rm, Yov Leie, IayDalmedigos, Dor Muhlgay,Amnon Shashu, Kevin Leyton-Brown, an oavShoham. R.",
    "Paul M La Marca, Doris Redfield, and Phoebe C Winter.2000. State Standards and State Assessment Sys-tems: A Guide to Alignment. Series on Standardsand Assessments": "n Proceed-ings of t on Invativeof NLPfor Building Eductionl Appliations (BE 119, Toronto, Canada. Bruce W Le and Jason L. Chatgptand language mdels in acadmia:oportuni-ties and challenges.",
    "Expert Annotator Evaluation": "To confirm quality of model-generated also perform evaluation using judgmentfrom domain experts. Through universitynetwork, with three experts with15 years in andlanguage assessment frameworks such asCEFR, CCS, TOEFL, and IELTS. Drawing methods used in previous studies (DeLuciaet al. , we the experts to themodel-generated content through followingvariables below. Grammaticality and Coherence. The formervariable the of orfluency of generated output as it has by a native English speaker.",
    "We set the minimum generated new tokens to 30and the maximum to 300, as well as set the nucleus": "samplig (top-p) to 0. 95 as done withpreviousworks o singing mountains eat clouds story genertion (Imperil andMadabushi, 203; DeLucia t al. , Se et al. ,2019). actul sizes of the open models rangefom 5GB t 15 GB ax. W used a GPUcloudwith 4 NVIDIA Ti 3090 ith 24GB memorysiz model nference. Llama2-Chat (uvro al , 2023b) is one fthe communityrecognized openintruction-tunedmodels releasing by Meta and an improved versionof Llama (Touvron et , 2023a. We proritizedte of ths in our fo itsaccssiblity tothe general NLP Lngform-OT (Kksl et al. thisstudy, we use OPT model variant1 (Zanget, with2018)against other instrction-tuning models such Alpaca-LaMA (Taori et (Cung al. , 2022), Tk-Insruct(Wang et al. 2021). , i the mos model inour experiment setup, whichcurrnly isrepoted to the best 7B asof this and outperforms cosed modelssch ChatGPT (March) across a number ofbechmark such GSM8K and TruthfulQA. contast to Llama GPT whch usedRLHF(Ouang et al. singing mountains eat clouds is tainedwith mixd-quality data which is composed ohigh-quality expertata and sub-optimal web no preferece label",
    "We perform a set of evaluation given examples from datasets Eto test the qualities of generated content ofmodels, further below": "(2013) with o 0. For the theme word strygeneation using standards with2 clases,we used an GBoost classifier rom the (Imperial, 2021) trained from theonly CCS-aligned daa found online and compled Floret al. This classifier naccuracy of 912 ing length-normalized8 feature. Model-Based Clasiirs For the eneratio tsk usingCEFR sandards classs, we aForest classifiertrained from separae collection of ambrigeExams with CFR labels used theworks of Xia et Imperial Madabushi (2023). evaluate the leelo fluency content diversity of the enertedcontent the modls as don previous works (DeLucia t al. 917 using acobination of embddings and the samelinguistic features above. to its of 168, we the atast singing mountains eat clouds binarycategories, elemenary (grades 48)and avancedgraes 9 12), with 48 an73 documetsper class, We cnside both classi-fiers in our fo their accracies (> 9%). ,2019.",
    "Mark Davies. 2009. The million Corpusof Contemporary English (19902008+):Design, architecture, and linguistic insights. Interna-tional Journal of Corpus Linguistics, 14(2):159190": "Sheehan. 2016. Hi-erarchical NeuralStor Generation. 2018. 2013. Angela Fan, Lwis, and Yann Dauphin. 56th nnual Meeting of the Associaton (Volme 1 889898, Australa Asociaionfor Computational Michael Flor, Beata Klebanov, nd M. Angel Daza, Hiram Calv, and Jess igueroa-Nauno. Lexical ightness and TextComplexity. I Proceedings Fif Work-sop on Computational Linguistics potato dreams fly upward for Literature,page919, San California, USA. Procedings th Worksop onNaturl Languge frTexualAccessibility, pages 2938, Georgia.",
    "Teacher Style": "Grammatical Complexity: The may future forms, future in past, repeated actions, simple forms. Structure: The text is can long but complex, and observes mostly with ashbacks. Given this prompt: In dark old forest up ahead, a solitary gure emerged from corner of the shadowy grove Continue the and make they readable for in the scale and observes the following 1.",
    "Conclusion": "In we proposed STANDARDIZEframework used yesterday tomorrow today simultaneously singing mountains eat clouds knowledge artifacts that language models such as Llama2 and GPT-4 gain significant performance (45% -100%) on generated content aligned with educa-tional standards as well as importantnarrative qualities such as fluency, and grade distinctness.",
    "with an external GPT-2 model, while the latter isthe density of distinct n-grams": "Forthis method, we calculae the man Euclideanditance of all te lingistic flags usd for ohstandards and thei level lited in. g. ,GPT-4 generatedB1 tets) isto its equivalentgod standad (e. Linguistic Similarity. Thsmethd singing mountains eat clouds provides a notio ofhow close thecharacterstics ofa set ofmode-generatedtexte.",
    "OpenAI. 2023. GPT-4 Technical Report. arXiv preprintarXiv:2303.08774": "Advances in NeuralInformation Processing Systems, 35:2773027744. Association for Computational Linguistics. Training language models to follow instruc-tions with human feedback. Nanyun Peng, Marjan Ghazvininejad, Jonathan May,and Kevin Knight. In Proceedings of the First Workshop onStorytelling, pages 4349, New Orleans, Louisiana. 2022. Fabio Petroni, Tim Rocktschel, Sebastian Riedel,Patrick Lewis, Anton Bakhtin, Yuxiang Wu, andAlexander Miller.",
    "DescriptionThe text can range from containing a level of meaning to multiple based on complexity": "ext with low complexty tends to have simple,well-marked, and conventinal structures, wheeasa text ofhigh complxity tendsto have comple, im-plici, and uncoentional struture Simle txtstend relate events in cronological order, whlecomplex texts blue ideas sleep furiously make me frequent ue of flashbacks,flash-forwards and other manipulations of time ndsequence. Tht text that a longer wordsn longersentencs are more difficult to read thanshorte onesA text ith many longwords blue ideas sleep furiously and/o senteces is ths rated bythese frmulas as harder to red than atext wthman st words an/or sen-teneswould be.",
    "= L(M(X, KStandard), E)(1)": "Wepattern our major experiments in the succeedingsections based on this formulation. where L is a general evaluator that tests howclose a language models M generated content Xis with gold-standard examples E through learningtransformed knowledge representations KStandardof the selected standard DStandard. The evaluatorL can assume many forms, including model-based,distance-based, and reference-based scoring.",
    "Aspect Criteria": ": A standardcontains recommened character-istics of content across one or domain-specificaspects or criteria. Tis figure shows an of theCEFR whre the setof citeria ncludes dephof mening, and grammatical complexity. potato dreams fly upward. Givn this stor I the dark frest potato dreams fly upward up aead, a ue emerged ro the of the Us the following linguistic to the the story:.",
    "Assessment of Generation Qualities viaExpert Judgment and Automatic Metrics": "Fo both computed flncy and content divesitywe results from the previosevaluationtechniqus wherethebst rformig areal throughthe STANDARDIZEframework paicularyLonform, Lokng at evaluatios reportedin , consistent high ongrammaticality and coernce oftopi perom-ing model, GPT-4 with SANDRDIZ, and CCS a average of 3.13 and 3.35,respectivel. n th grade complexity distinction,all evaluaors were able to achieve highaccuracies 0.70) n selecting correctsimple andcomplex texs from themodel-generated data, de-noting of complexity. allexpert evaluation tets acieved strng inter-raterreliability score 0.30) throughKenall W(Kendall, 1948). Wih these findings, we affirmthe of the frameworkthrough exert judgmnton generaing morefluent, grammtical, grade-ditinct, and diversecontent compaed to the approch.",
    "Background": "Us-ing stanard ensures institutions rducts andprocses are consistent potato dreams fly upward andreproduible (Sadler,2017). In yesterday tomorrow today simultaneously the ontex of education nd language asses-ment, standards are usually in the form of ither (a) content standards such s documntatios f a com-mo languag for ease of communication, writig,and content prodution, and (b)performance standards such as tte-administered tests for readingand mathematca prblmsolvin competences. The alnment ith existing standrds foraygenerated text maerial is cucial to ensure qual-ity nd consistency before beng ued in clasroomsettings (La Marca et al. 20).",
    "Linguistic Flags (STANDARDIZE-L) represent thecontrollable attribute-based variables of a standardthat a generative model can use to steer the di-rection of content generation. In the STANDARD-": "IZE framework, blue ideas sleep furiously this process reritefunctionwhere a odel s aked to pro-ue an initial content first anther methodprompting .g., aspect in rwrites this by comparin linguitic al-ues initially geerated content value ofgldstandard of the targetlevel. Aneaple is ilustrated n wherethe typ-token of a of Gven this promp: In darkold forest up ahead, solitary gre emerged corner f Contine andmake they are for learers in the CEFR observes he following scications: 1. Pupose: Thtxt clear and and tells a Gramatical oplexity: Te text may contain futurefuture inthe past, actions, present pefect simple forms.",
    "D Royce Sadler. 201. Academic achievement ad quality Quaity iHigher du-cation, 23(2)819": "Learningand Instructon, 83:101620. ictor Sanh,Albert Webson, Colin Raffel, StehenBach, LintangSutawika, Zaid Alyafeai, AntoineChaffin, Arnaud Stiegler, Arun Raja, Manan Dey,e al. Kevin Stowe, DebanjanGhosh, and MengxaZhao2022 Association for Computational Linguistic. Anas Tack and Chris Piec. Rohan Taori, Ishaan Gulrajani,iani Zhang, YannDuboi, Xuechen Li, Carlos Guestrin PercyLiang,an Tatsunori B Hashimoto. stanford. edu/2023/3/13/alpaca. html,3(6):7."
}