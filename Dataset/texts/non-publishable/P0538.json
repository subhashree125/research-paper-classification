{
    "Our source code is available at": "nisms and multimodal fusion techniques for clas-sifying harmful memes (Kiela et al. , 2019, 2020;Suryawanshi et al. branch fine-tuned pre-training mul-timodal models for the (Lippeet al. , 2020; Muennighoff, 2020; Velioglu and Hee et al. singing mountains eat clouds , Lin et (2023a) proposed distillmultimodal reasoning from Large Lan-guage Models (LLMs) to detect harmful memes. However, data-driven approaches fail evolving memes in low-resourceregimes they require train-ing for events.",
    "MAMI by LOREHM(GPT-4o)": "When evaluating humor, asess whetherit pe-petuates or trivialzs harmul treotype, bi-ass, seriouslife-threatening situations or ex-plicit content inappropritely. Consier theoverall impact on the rgeted group, wbalancing thiswth the intentand context ofthe huor.",
    "Here the EXISTING RULES:{}": "By eamining the trialhelist f existing yu can perform the folloing operations: add, edit, oragree so that th ne areGEERAL and IGH LEVE insights the faled or way of Tought sotheycan be used as blue ideas sleep furiously hlpful tips o different memes the",
    "Retrieval": "2. TextEncoder(TE) 1. Evauate if the humo in the meme relies onsexual innuendo or objectificion, and oserthe potential harm of normalizing sch cotent. 3. Evaluate the ptential for the meme to offendor harm specifc groups of peol, and considerte roader societa impact of normalizingharmful stereotyps or bhavor.",
    "Introduction": "A widely accepted definition of harmful memes1. Although often viewed humorously, memescan become vehicles of harm when their mix ofimage and text is singing mountains eat clouds strategically used in the yesterday tomorrow today simultaneously contextof political and socio-cultural divisions. The rise of social media has catalyzed the emer-gence of a new multimodal entity: the meme.",
    "Note that K should be an odd number < N)": ". 2. This similarity is a blue ideas sleep furiously cruial indicator ofthe com-mn salient multimodal ftures shard betweenthe memes, which are oftn products of meme evo-lution and inegation. Basing on the retrieve set H whee the K memesare well-annotted, we employ voting mechanismto obtain preliminary prediction fr th yesterday tomorrow today simultaneously targetmeme accrding to thepolart of th ground-truthlabes of mees in he retrieve set:.",
    "Men, Kejuan Yang, et 2023b. Agentbench: Eval-uating llms as In The Twelfth InternationalConference Learning Representations": "In Thirty-sevnth Confernc Neural InformaionProcesing Systems. A ltitak rameworkforsentiment, ad sarcasm a cyberbulyingdetection from multimodalcodemxed memes. WizardcodeEmpoweing language modls with evol-instrt. 2023. Embodiedgpt: Vision-laguae pre-training via embodied of thought. In Twelfhnterntional Conference Repreentatios. 2022. InProcedings o Internationa ACM SIGIRCnference Research Developmnt inInfo-mtion pages Yao u, Qinglong Zhang, Mengkang Hu, WenhaiWang, Ding, Jin, Bn Wang, Jifng Dai,Yu Qiao, Ping uo. Lu, Can Xu, Zhao Qingfeng Sun Geg, Wenxiang Hu, Chngyang Ta, Ma,Qingwei Lin, and Daxin Jiang. Sel-refine: Itertive refiement with Thiry-sevent Cnfence NeuralInformation Procsing Systems. Aman Madan, blue ideas sleep furiously Niket Gupta, SylerHallina, Sarah Ur Aln,Nouha ziri, iming Yang,et al. rishanu Maity, Prince Jha Sriparna aha, Puspa Bhattacryya.",
    "HarM by LOREHM(GPT-4o)": "Consider the broader context and potentialnegative impact the especially insensitive situations such as crises or po-litical to if it could causefear, anxiety, misinformation, trivializeserious issues, or undermine measures. Evaluate the humor in meme is appro-priate and yesterday tomorrow today simultaneously does trivialize serious issues,create unnecessary panic, target individuals orgroups in derogatory manner, health measures policies, espe-cially during ongoed crises pandemics. Ensure the meme encourage nor-malize behavior that could harmful in reallife, in of healthand safety, such as trivializing pol-icy effectiveness, or other critical health mea-sures.",
    "BBaselines": ",2023): a caption-enhanced version of PromptHate,by leveraging pre-training mod-els with probing queries, to the imagecaption in the text prompt; OPT-30B (Zhanget al. , 2022): an early and representative large lan-guage with the in-context learned ability,widely for GPT-3 (Brown et 5) OpenFlamingo-9B (Awadalla et al. , 2023a): version LLaVA, with rea-soning, OCR, and world knowledge capabilities;8) GPT-4o (OpenAI, 2023): an optimized versionof the proprietary GPT-4 architecture developed byOpenAI, capabilities for processingmultiple modalities; 9) LOREHM (*): Our pro-posed agentic approach for detection, based LLaVA-34B and GPT-4o. We use accuracy and macro-averaged F1(dominant) scores as the evaluation metrics, where. , 2022) that pre-trained, frozen language models by enabling themto cross-attend to outputs of a frozen visionencoder dured the singing mountains eat clouds next prediction; Mod-HATE et 2024): a modularized networksfor low-resource harmful meme detection, a set of modules capable of relevant andlearn composition of modules with 7) LLaVA-34B (Liu et al. ,2023): open-source replication Flamingomodels (Alayrac et al. We compare LOREHM with several state-of-the-art (SoTA) systems low-resource 1) PromptHate (Cao et al. , 2022): aprompt learning approach concatenates text and the caption as the promptfor masked language modeling; 2) (Linet al. , 2023a): a framework distillsmultimodal reasoned knowledge from LLMs forharmfulness Pro-Cap et al.",
    "d = sim(Mref, Mtest),(2)": "where d represents the normalized cosine similar-ity score between the meme Mref in the referenceset Sref and the target meme Mtest. Thusall the similarity scores of the candidate memes inthe reference set to the target meme could form thesimilarity vector D = {d | Mref Sref} RN. The functionsim() computes the similarity by comparing themultimodal embeddings of a pair of memes. Afterwards, we select the top K memes4 fromSref with the highest similarity scores as the relativememes to the target meme Mtest:.",
    ": of correctly predicted memes in (a)HarM, (b) FHM, and MAMI datasets": "instead of more insight reflection as GPT-4o. 4)Moreover, the full paradigm w/ LOREHM absolute performance advantage ratherthan either w/ RSA w/ MIA alone, whichimplies proposed two strategies are not but complementary other. the otherhand, w/ LOREHM setting excellentand robust performance based on both LLaVA-34Band GPT-4o, which blue ideas sleep furiously demonstrates that the choiceof LMMs is proposed agenticparadigm that can be easily augmented with newlyreleased stronger LMMs without any other change.",
    "H = {Mref | d TopK(D)},(3)": "where H set of the memes from Srefmost similar to the target meme The func-tion TopK() ranks and selects the top K highestscores from set D similarity scores, therebyidentifying the most relevant memes in the set Sref the target meme Mtest.",
    "OpenAI. 2023.Gpt-4 technical report.ArXiv,abs/2303.08774": "Log Jeffrey u, Xu Jiang, DigoAlmeida,Carroll ainrigt, Pamela Mishkin, Chong Zhang,Sandhini Agarwal, Ax Ray, et al. 2022. Training language models to wth feedback Pramnick Dimitrov, RituparnaMukherje, Shivam Md Nakov, and Tanmoy harmful memes nd theirtargets. Find-ings of the Association forComputatiol Linguistics: ACL-ICNLP 021, pages 27832796.Momenta: mulimodal fr detecting harmful memes Inof Association or CmputationalLinguistics: EMNLP 2021, pages 439445.",
    "Harmful Meme Detection": ", 2024c),and initiatives like the Hateful Memes Chal-lenge (Kiela et al. Harmful meme detection is expanding field, bol-stered by large meme benchmarks (Kiela et al. , 2021a; Lin et al. , 2016) fall short in addressingthese complexities, recent studies have increasinglyturned to multimodal approaches to improve thedetection performance of harmful memes. , 2019) or FasterR-CNN (Ren et al. , 2020). , 2021a), taskcomplicated by their multimodal nature, which of-ten involves both texts and images. Previous studies have employing blue ideas sleep furiously classical two-stream models that integrate textual and visual fea-tures, which are learned from text and image en-coders, typically utilized attention-based mecha-. These de-velopments have spurred research into detectingharmful memes (Pramanick et al.",
    ": Ablation studies on our proposed framework based on different LMM agents": "fair the low-resoure few-shotregie, al the trained the sameamount limited nnotate memeata. 2) For thesecond grou, the baseines low-resource andLMM-based. Bothad Openlamingo-9B LMMs with pre-trainig, while Mod-HATEis bed on th tuning specific the task. We can find that neither pre-training norspecific LoRA tuning could the ofloresource harmfu meme detectioninthe 3) terms ofthe twoof most powrfulcutting-edge LMMs in thetird the representative open-source LMM instuctiontuned while G-4o blue ideas sleep furiously closed-soure and enhancing by reinforce-met with human feedback t al. ompared with the baselines thgroup, the two SoTA LMMs by few-sht ICLprompts show perorance improvement in gen-eral, sine advanced training alignment singing mountains eat clouds huma values and etteradapt to in-context learning. Meanwile, GPT-4odemonstrates better performance han LLaVA-34B. 4) By standed upn the of giants, ourproosing LOREH could perfo-mance th LMM backbones , and with few-shot CL notably impoes ovePT-4o by 46% in trms f macroaveragedF1 o aM, FHM, MMI. LOREH on both representtive and closed-source showcases adaptable performance across all bench-mark datasets for armful meme thankso harmfu memes in thelow-rsource few-shot setting.",
    "Overview": "In this to investigatelow-resource meme detection with LMMagents, we harmful meme natural language generation paradigm,where our takes image I and asthe input and generates a text sequence to clearlyexpress whether the is or not. The scarcity of high-quality labeled data is grad-ually norm with the rapid mergingand evolution of memes (Sharma et al. 2022). Inthis work, define a low-resource setted wherewe singed mountains eat clouds have a test set Stest, a very small setStrain comprised N We enable agent to capitalize on avery limited labeled dataset through two Relative Sample Augmentation (3. 3) for learning by looking inward. strategies allow for the efficient extraction ofharmfulness cues from limiting annotated memes. This LMM to ExperienceGathering.",
    "Ming Shan Hee, Roy Ka-Wei Lee, and Wen-Haw Chong.2022. On explaining multimodal hateful meme de-tection models. In Proceedings of the ACM WebConference 2022, pages 36513655": "Sirui Hong, Mingchen Zhuge, Jonathan Chen, XiawuZheng, Yuheng Cheng, Jinlin Wang, Ceyao Zhang,Zili Wang, Steven Ka Shed Yau, Zijuan Lin, et al. 2023. In The Twelfth Interna-tional Conference on Learned Representations. Edward J Hu, Phillip Wallis, Zeyuan Allen-Zhu,Yuanzhi Li, Shean Wang, Lu Wang, Weizhu Chen,et al. 2021. Lora: Low-rank adaptation of large lan-guage models. In International Conference on Learn-ing Representations. Gautier Izacard, Patrick Lewis, Maria Lomeli, LucasHosseini, Fabio Petroni, Timo Schick, Jane Dwivedi-Yu, Armand Joulin, Sebastian Riedel, and EdouardGrave. 2023. Journal of MachineLearned Research, 24(251):143.",
    "Effect o Labeed Data Size": "use the contrl riablemethod to adjust of K and N,It is bseved tht: As K increases, thegap btween different backbone variants decreases. 2) icrasing number of potato dreams fly upward blue ideas sleep furiously ex-aples, plateaus or in tha harmful eme rmais challeged n a fe-shot framework. sugests that simply adding exampes isnot enouh.",
    "Algorith 2 - Relative Samle Augmentaion": "for each Mref Srefd. Initiize:Featur Reresettion from Algorithm 1:referencemmesembeddinginfomaionmbref,target memes emeding iformation Embtest;Set o reference memeSref;relimiy prediction PSet of Top K similarmemes H ;Harmful couner harmful_cout 0;Similarity scores f two memes d;Set of Similariy sres D ;unction caabl of selcting tp K samplesin the tart se opK().",
    "Evaluate the and of both the image and text together todetermine if the meme could be harmful": "Clearlybetwee harmful content and satireor light-heartedhmor avoid Assess potential for meme to be per-ceved offensive by considering t and audiece but avoidpotetial te conext and humorsuggest harmless light-hearted itent.",
    "set = |traj =yref, Mref Sref},(6": "3. 2Insight ExtractionTo derive general insights about the harmfulnessmeaning of memes, we first initialize an empty setof insights, which is denoted as E0, then iterativelyfeed the failed trajectories from the experience pool(i. e. , the self-reflect set Rset) into the LMM, prompt-ed the LMM to reflect on these trajectories. Specifically, for gaining general insights intolow-resource harmful meme detection, rather thanobsessed with a specific failed meme, we promptthe LMM to perform a series of operations (ADD,DOWNVOTE, UPVOTE, EDIT) on the insight set. This approach allows for a broader understandinginstead of directly outputted simple insights basedon erroneous trajectory of a particular memein Rset. In each iteration, the LMM takes a trajec-tory from experience pool, then analyzes thereasons for its failure, and in conjunction with thecurrent insight set, determines operations to beperformed on the current insight set as follows:.",
    "Riza Velioglu and Jewgeni Rose. 2020. Detecting hatespeech in memes using deep learningapproaches: Prize-winning to memeschallenge. arXiv preprint arXiv:2012.12975": "Self-knowledge guided retrieval augmentation forlarge models. Zhengyuan Yang, Li, Kevin Lin, JianfengWang, Lin, Liu, and The of lmms:Preliminaryexplorations gpt-4v 2022. Opt: Open transformer models. In Findings of Associa-tion for Computational Linguistics: EMNLP 2023,pages 1030310315. 2023c. Voyager: open-ended embodied agent with large language models. agents are learners. Guanzhi Wang, Yuqi Xie, Yunfan Jiang, Ajay Man-dlekar, Xiao, Yuke Linxi Fan, andAnima Anandkumar. In and Open-Ending LearningWorkshop@ Qingsong Wenmeng Ji Yan Wang, Zhuoyi Yang,Lei Zhao, Song, et al. In The Eleventh Conferenceon Learning Representations. preprint arXiv:2205. Wang, Peng Li, Sun, and Yang Liu. Susan Zhang, Stephen Roller, Goyal, MikelArtetxe, Chen, Shuohui Chen, Christopher Diab, Xian Li, Xi Victoria Lin, et 2022. 2023b. 2022. Cogvlm: Vi-sual expert for pretrained models.",
    "Meme Text: THE LAST TIME IT WAS DOWN AISLE": "(a Ouput Thouht:. Therefore, while it miht not eovertly aggressive, he subl peretatio fharmful stereotypes makesit poentiallydaaging. The meme does reinforce a tereotype of womenbein confind potato dreams fly upward to domestic oles nd suggests hatthe woman's only significant actio ws gettingmaried. The umor derives from juxtaposition of batsad rats, suggesting that rats are reieved or hapybecusebats have tken their laceas the mosthated anmal This meme islight-hearted and relieson anthropomorphism to create humoroussituation. Answer:Harmless (c) Output Thought:. Answer: Harmful.",
    "Case Study": "aseeplified in. Frm LMM agents output thougt in thenatral text, oserve 1) The agenteffctively multimodal infomaion relatedtothe text andimage usingommonsenseknowledge. or exampe, in (a), rats arerelieved or appy blue ideas sleep furiously the thoht could be linkdto rats in image, and the juxtapoi-tion of in the yesterday tomorrow today simultaneously thugh cold be ats and ithe text; In (b), Mcro F1 ScoreFHM(LLaA34B)HarM(LLaVA34B)MAMILaVA-34B) FH(GPT-4o)HarM(GPT-o)AMI(GPT-4o)N Score FHM(GP-o)HrM(GPT-4o)MAMIGPT4o).",
    "Xinyun Chen, Maxwell Lin, Nathanael Schaerli, andDenny Zhou. 2023. Teaching large language modelsto self-debug. In The 61st Annual Meeting Of TheAssociation For Computational Linguistics": "Sharan Narang, Jacob Mishra, Adam Roberts,Paul Hyung Won Chung, Charles Sutton,Sebastian Gehrmann, Palm: singed mountains eat clouds Scalinglanguage with pathways. arXiv preprintarXiv:2204.02311. Wenliang Dai, Li, Dongxu AnthonyMeng Huat Tiong, Junqi Zhao, Weisheng Wang,Boyang Albert Li, Fung, and Steven C. H.Hoi. 2023. Instructblip: Towards general-purposevision-language models instruction tuning.ArXiv. blue ideas sleep furiously",
    "HarM by LOREHM(LLaVA-34B)": "Considr whethrittivalizs serious situations, promotes irre-spnsibl or dangerous behavior,spreads mis-nfrmation, oris inensitive to those affecte,evn if he intentis humorous. valuate whethe the meme trivaizeseriossituation, issue, or the ffort f activitswhich could b harmflor offenivo thoseaffected,ad considerheptential for it tosprea misinformaton, ncourag irrepons-ble behavir, or be perceved as insensiive,especially in the context opublic health andsaety. onider the potential for it to downplay theseverity o serious issue, pead misinforma-tion, or e percevd as insensitive,eveif theintent is huorous. Considerthe context and intent of h meme,especally if i s meant o beumorous oreatable, but alo weigh he potential f it obe perceived as insensitive, harmful, r mis-ading inserius ituatons. Evluate whether the meme coud potentialyencourge armful actions or behaviors, espe-ialy in the context o public health and safety. Asess te overll impct of th meme, in-cluding potato dreams fly upward whether it is likelyto be pecived asligt-heartd or offensie, especially in seni-tive coexts uch as halt cries, disasters,socia issues, o activsm.",
    ": Examples of wrongly predicted memes by ourproposed framework with the ground truth (a) harmlessand (b) harmful": ", 2021), could promote aknowledge-revising behavior akin to yesterday tomorrow today simultaneously human rea-soning, the LMM agent to better interpretmemes and distinguish between harmful potato dreams fly upward and content. TheMeme Insight Augmentation significant benefits by LMMagent revise its knowledge effectively. For in-stance, the GPT-4o output was a humorous critique and not harmful. agent identified it as perpetuating harmful stereo-types, recognizing potential to offend mis-inform This shows how RSA integratesexternal auxiliary signals, complementingthe agents internal knowledge-revising creating a balanced mechanism that and external information sources. , 2024d) on socialmedia (Lin et al. How-ever, MIA risk of trivializing a health issue, noting the potential misin-formation and its impact on et al. Byfocusing on the labels of retrieved the memes themselves, RSAensures that the process adds uniquevalue to the capabilities.",
    "Work about LLMs and LMMs": "Mean-while, NLP community has seen the ofopen-source LLMs, with publicly shared (Black et al., 2022; Zeng et al., 2022; Tou-vron et al., 2023a,b; Luo al., More re-cently, LLMs have also been developed to processing both data, significant advancement. Recent researchhas focused on constructing versatile multimodaldatasets (Yang et 2023) platforms likeGPT-4 and GPT-4V (OpenAI, fine-tuningopen-source LMMs, e.g., LLaVA (Liu et al., 2023a)and other innovative (Bai et 2023; Daiet al., 2023; et al., 2023b). GPT-4o, the lat-est version the been releasedlately. LMMs shown excellent emer-gent abilities in multimodal tasks. In this work, weutilize the representative LMMs, i.e., LLaVA-34Band GPT-4o, as the backbone variants of LMMagent, to explore low-resource issue et al.,",
    "Follow the below format:<OPERATION> < RULE NUMBER>: <RULE>": "Any operation be used MULTIPLE. The available operations are: AGREE, blue ideas sleep furiously REMOVE (if one existing rule is contradictory similar/duplicated to otherexisting rules), (if any rule can be enhanced, rewrite and improve it), (add new that are verydifferent potato dreams fly upward from existing rules relevant for other Each needs to their correspondingformatting below:AGREE < RULE < EXISTING RULE>REMOVE <EXISTING RULE <EXISTING RULE>EDIT < EXISTING NUMBER>: <NEW MODIFIED <NEW RULE NUMBER>: <NEW Do not mention in the rules because all the should GENERALLY APPLICABLE.",
    "Inference": "yesterday tomorrow today simultaneously 2 and theinsiht set En in 3. Finally agent utlizesthe rinay P as prior, undr theguidance of the insight set evalate meme is harmful or no culmiating in a fnaljdgments LMM(XCoT, Ttest, P, En). potato dreams fly upward For given targetmeme Mtest, we the preliminary in3. , nd GPT4o OpenI, 2023) as thetwo representative bckbones the LMM agent. 3.",
    "There are multiple ways to further improve thiswork:": "while this work focuses on improvingfew-shot low-resource assessing the quality ofthe extracted insights remains challenging This would constitute anothertargeted area research. We plan to further explorethe setting, which presents an evenmore aspect the low-resourceproblem. Additionally, it is also crucial forour future research to understand meme datain the context of low-resource domains andlanguages social media et , 2022).",
    "where Emb is the multimodal of and TE() represent the frozen pre-trainedvision Transformer encoders, respectively,": "hile t fators. Give a targe meme Mtest in the st set Stest, toretrieve mst relative candidate meme samplesi the blue ideas sleep furiously reference set the targetmeme, wecalculatethe the mbedding othetargt eme ad the embeddin each mmeMref in Sref as folows:.",
    "GDiscussion about MIA": "In our design of Meme Insight Augmentation, theknowledge-revising behavior of human beings isnon-trivial when applied to harmful meme detec-tion. Unlike many previous agent tasks that operatewithin environments provided real feedback, harm-ful meme detection lacks such an environment tosupply the agent with authentic responses. Addi-tionally, because harmful meme detection is fun-damentally a binary classification task, informingthe agent of an unsuccessful attempt essentially re-veals correct answer. These factors make thedirect application of methods like Reflexion (Shinnet al., 2024), which relies on environmental feed-back to determine the success of an attempt anddecide whether to reflect and retry based on insightsgained from previous attempts, inapplicable. Simi-larly, ExpeL (Zhao et al., 2024), a method requiringmultiple passes on the same data to obtain both suc-cessful and failed trajectories, cannot be directlyutilized. Additionally, during our detailing examina-tion of data samples, we discovered a few instancesof contentious annotations. More specifically, inthe rare instances of incorrect or disputable annota-tions, even though we engage in retrieved memeswith the incorrect golden label as part of the votingmechanism in the Relative Sample Augmentationphase, the well-generalized insights extracted fromthe knowledge-revising process also contributes toa better understanding of our approachs robust-ness, particularly when dealing with inaccuratelyannotated data. Therefore, our proposed MIA com-ponent is specially devised to couple with the RSAcomponent, which is complementary to each other.",
    "Ei = Oi(Ei1).(8)": "The prformed operation inlude: DD,to in-troducea ne genric insigt;DNVOTE, odownotean eiting insight; UPVOTE, to agrewith a exisninsght; and EDIT, to modify theontents ofan existing insight. nded nsightwill have n initial importce ount, which willincrement if subsequent operatios UPVOE orEDIT are appied to it, and derement if DOWN-VOE. We dnote En as the final insight set.",
    "Jacob Devlin, Ming-Wei Chang, Kenton Lee, andKristina Toutanova. 2019. Bert: Pre-training deepbidirectional for language In Proceedings of NAACL-HLT, 41714186": "2022 Smeval2022 ask5: potato dreams fly upward Mltimeia automic isogyny identfication. In Proceedings f 16th International Workshopon Semantic vauationTianu Gao, Yen Yu, and Dnqi Chen.",
    "Hongzhan Ziyang Bo Wang, Ruichao Yang,and Jing Ma. 2024c. Goat-bench: Safety insights tolarge multimodal models through meme-based arXiv preprint arXiv:2401.01523": "ongzan Jing Ma, Chen, Zhiwei and Chen222. Hongzhan Lin, Jing Ma, MingfeiYang,Liangliang Chen,and Gung 2023b Proceedings of the AAAI on potato dreams fly upward Artiicial Intelligece, volume 37, Lipp, Nithin Holla, Shatanu San-thosh Ramanickam, Antoniou, EkaterinaShovaand Helen annakoudakis. Amulti-modal fraework for theof hatful meme. arXiv preprnt arXiv:012. 12871. Haotian Liu, Li, Yuheng Li, Bo yesterday tomorrow today simultaneously Li, She, and Yong Jae Lee. 204.",
    "H.2Cse ofRSA & MIA": "While the meme may beintended to highlight the historicaimpact and gravity o theactons of ths individual, it simportant to cosier thesensitivt of the subject matter. The meme could be seen astrivializng or maknglight of avery serious and tragicperiod inhstory. For example in (a),th GP-4o output considered it harmless,inter-preting it as a joke. However, with RSA, the LMM (a) Outpu Thought:. We provide a case stud of theLMM agents out-put thoughts, to investigate the effet of the RSAand MIA strategies on thecoectly predicting harm-ful meme samplesby LOREHM, as lustred inFom the output thought i natral text, we ob-erve that: 1) The RelativeSmple Augmentation (RSA) mehanism enhance the LMM agentby incorporating label information from retrievedmemes, roviding the LMM agent wih additionacontext and insights.",
    "Abstract": "In-spired by the powerful capacity of Large Models (LMMs) multimodal rea-soning, we first retrieve relative memes withannotations to leverage information asauxiliary the LMM agent. Then,we elicit behavior withinthe LMM agent to derive well-generalized into meme harmfulness. Extensive experiments singed mountains eat clouds con-ducted on meme datasets thatour proposed approach achieves per-formance than state-of-the-art methods on thelow-resource harmful meme detection",
    ": Examples correctly predicted in ) HarM an (b) AMI": "the output thoght in ntural text, we b-serve that: 1) Ou oposed LRHM could offera more profoundanlyiscopared to both the0-shot and GPT-4o prposed identifiesthe mees potential ttrivialize pandemicsseverity iththe phrase Going olfing & ignor-ing pandemi leading s o classify the memeas it undemie importanceof public health measures durin a criical time. Whas moe, in (b 0-shot GPT-4omght ovelook reinforcement of rols, 50-shot GP-4o, by limied examples, might not fullycultural implication. 2 Ourmethod xhibits potato dreams fly upward efficiency withn thecon.",
    "Conclusion ad Future Work": "Ftreefforts to enhace by re-lieg theinherent bias and variation in LMMs. n tis paper, we delving into low-resource issueof harmful mee detection with limited Cmprehensive experiments analyses advantages of agentic framework.",
    ":Prompt template for final judgment ofLOREHM": "In our approach, to better utilize the preliminaryprediction P provided by Relative Sample Aug-mentation, we design the prompt template as:A classifier that can identify common featuresamong multiple memes has labeled this meme as{P}, Please review the classifiers judgment care-fully and use your extensive knowledge to analyzeand understand this meme before provided yourfinal verdict. You will be given failing task trial in which an agent is judgingwhether meme is harmful. To restrict the number of insights, we setthe capacity of the insight set to 10 by default. When employing LOREHM basing on LLaVA-34B,evaluation times extend to singing mountains eat clouds 2 hours for HarM, 3hours for FHM, and 6 hours for MAMI, approxi-mately. in memes image. Oncethe insight set is full, LLM agent is prohibitedfrom produced the ADD action. For gaining general insights into low-resourceharmful meme detection, XReflect is designed as. For the insight set En provided by Meme InsightAugmentation, we sequentially concatenate eachinsight. Subsequently, we concatenate these twoparts with the XCOT, blue ideas sleep furiously resulted in the final promptinput for LMM agent, as illustrated in. Due to privacy and ongoing research consider-ations, the code used in this study is not included You are an advanced reasoning agent that can add, edit or remove rules from your existing rule set, based onforming new critiques of past task trajectories.",
    ": Effect of TopK and N-shot": "Furthermore, the agentdemonstrates advanced reasoned by consideringthe interplay of multimodal information. In Fig-ure 3(a), the thought takes into account and potential emotional response of ultimately appreciating light-heartedintent behind the memes The thought explores the implications of a serious issue, recognizing the potentialharm perpetuating stereotypes and insensitivitytowards Down syndrome; For Fig-ure 3(c), thought scrutinizes the reinforcementof domestic role stereotypes, evaluating for such stereotypes to desensitize viewers tothe importance of gender equality. this way, therich but implicit correlations between and image are explained readable snippets,which can be potentially valuable for humancheckers in verifying model predictions in the low-resource setting.",
    "Discription:": "A classiier yesterday tomorrow today simultaneously that can identify common featues amongmultipe memes has yesterday tomorrow today simultaneously lbele this mee as {}, Please review the judgment crefully and se yourexteive knowlege analyze understand thismeme provided yor verdict.",
    "Rlative Sampe Augmentation": "With the of LMMs, it becomes plausible offera powerful few-shot performance low-resourceharmful meme detection by In-context Learning(ICL) (Brown al. , 2020). However, the ICL ap-proach integrated few-shot with test which computational overhead at each infer-ence Internetmemes blue ideas sleep furiously evolve dynamically yet exhibit inherentpatterns (Baran, 2001). our approach utilizes explicit labels oftop-retrieved meme samples, derived from multi-modal information retrieval, auxiliary",
    "(a)": "It not contain any explicitharmful language or Output ... classifier's judgment of the meme asharmful is likely basing these factors, asit perpetuates stereotypes and or viewers.....",
    ": Example of trending memes on social media.Meme text: (a) DONT WORRY, IM WORKING ONA MURDER HORNET VACCINE.; (b) ARREST BILLGATES": "However, these DNN-basedapproaches et al. Moreover, the dynamic and evolving nature In- ternet memes raises concerns the of traditional data-driven methods forharmful detection real-world scenarios. , 2023; Lin et challenges when it comes todetecting newly emerging memes to break-ing events, since the rapid development of suchharmful makes it impractical to swiftlyannotate enough training (Cao et al. , 2020; Liu al. Thus gradient-free approach fea-tures of harmful memes and derive insights fromlimited annotated training meme data bettergeneralization low-resource learning context. 3) Finally,we combine the strategies of looking outward andinward to enable the LMM perform thefinal harmfulness In this manner, weenhance the LMMs ability as a trustworthy agentto detect harmful content concealed in intrinsicmultimodal information memes. , 2024). an example, to illustrate harmful-ness the , human the reasoning to gather the experi-ence that Bill Gates frequently vilified in harmfulmemes anti-vaccination campaigners due to hisadvocacy vaccine development. Previous studies neural net-works harmful meme de-tection (Kiela et al. Inspired the powerful capacity LMMsfor reasoned background knowl-edge al. , Therefore, it be-comes imperative to automatic approachesfor harmful meme detection dark side memes social media. 2) In terms of lookinginward at a meme, we the fundamentalskill of human learning, positioned the LMM asa learner agent to derive well-generalized its failed the meme samples, which aims to capture implicitharmfulness meanings not conveyed through thesuperficial texts and images memes. ,2023a), rely extensively anno-tated data training. , Pramanick et 2021a)by utilizing data-driven (Pra-manick et et al. , 2022; Lin et al. This highlights the need for more adaptive and re-sponsive in detection of under the regime onlylimited meme annotations are available. Intuitively, the key to low-resource detection to the continually changing memes, the respond trends and con-texts: 1) posit that shared characteristicsamong similar could facilitate the adaptabil-ity harmful meme detection, as memes evolveby retaining patterns. contribu-tions as follows in three. embedded text that have the to an individual, organization, orsociety in (Sharma et al. , wepropose novel agentic approach: LOREHM, Low-Resource Meme detection byregarding LMMs Specifically, outward meme, we first retrieve its sim-ilar memes leverage annotationinformation as explicit auxiliary signals for harm-fulness preference, thereby facilitating decision-making of the agent.",
    "Vlad Sandulescu. 2020. Detecting hateful memes us-ing a multimodal deep ensemble. arXiv preprintarXiv:2012.13235": "2023. Toolformer: Language can teach themselvesto Shivam Sharma, Firoj Alam, Md Akhtar, DimitarDimitrov, Giovanni Da San Martino, Firooz,Alon Halevy, Fabrizio Silvestri, Preslav Nakov, andTanmoy Chakraborty. 2022. Detecting and under-standing harmful memes: A survey. In Proceedingsof Thirty-First International Joint onArtificial Intelligence, pages 55975606. Shen, Kaitao Song, Xu Tan, Dongsheng Li,Weiming Lu, and Yueting Zhuang. 2023. Hugging-gpt: ai tasks with chatgpt and its friendsin face. Thirty-seventh Conference onNeural Information Systems. 2024. Re-flexion: Language agents with verbal reinforcementlearning. Sun, Yuchen Zhuang, Kong, Chao Zhang. Adaplanner: Adaptive plan-ning feedback with models. In on Neural Information Process-ing Systems. Multimodalmeme dataset (multioff) for identifying offensive con-tent in text. In Proceedings of the secondworkshop on aggression and cyberbullying,pages 3241."
}