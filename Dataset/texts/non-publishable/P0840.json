{
    "Conclusion": "We design exensive experiments shw the sueriorityof APEX2 baseline methods.",
    "We provide a comparative case study to illustrate how our methodswork and that they can summarize high-quality PKGs": "5.7.1Datae and Query. Weusethe firs 3 queries from he user.Most o the interested part ofthe KG is shown in . In th first 3 groups of 10 qeres, thequery entities are respectively te actor \"Stevan Riley\", the movie\"he Disapperanc of HaruhiSuzumiya\" and te moie \"LOL\". 5.7.2Settings.tartng from the 31 query,th user ask (Chad Michael Murray, ovie_to_actor, ?) i.e., \"whichmovies did Chd Michael Murray acti\" three times. yesterday tomorrow today simultaneously The correctnswer entitie are \"A Cinderlla Story\", \"House of Wax\", and \"LeftBehind. However, afer three times qeryng on the new topic,the PKG blue ideas sleep furiously summrized by GLIMPSE l ontains (ChdMichaelMurray, movie_to_ctor,Hous f Wax), andthe PKG sarizedby PageRank doe not contain any of hem.At timestamp 32 (Figue d) some of its -hopneighbors are inclued, such as(House of Wax, actor_to_mvie,Nicolas Cage) in APEX2 and (ACindrella Sory,director_o_movie,ak Rosman) in APEX2-N. The reason hy the actor relationshipis ncluded first is that, this relation isrecently quried many timesand has a hih rltionalinterest. (iv) Ther are some triples thatare notvery elated to the user queries but are ummarizd in theGLIMSE PKG, fr example (Onibi, movie_t_language, Japaese),(jhn lithow, tag_to_movie,2010) and(Hercules, movie_t_genre,Aimation) The PageRank PK alos remains th same givenhree querieson th ew topic. Compared t these, APEX andAPEX2-N produce PGs that have intuitively hiherquality interms of users interest.",
    "Experimental Settings": "We show the of APEX2 and APEX2-N through auto-regressive3 style blue ideas sleep furiously experiments. 01% (one in for 0. = 0. a million) YAGO 0. We set the default hyperparameters = 0. 05% for To the average and standarddeviation, we 10 to query. 3, = 1 PageRank restart probability to be0. We set compression ratio to be 0.",
    "B.2Proof of non-adaptability or corruption": ", thenumber of seed nodes exceeds the maximum number of nodes tosummarize. , and its -hop neighbors) getshigh weights and are considered important, they are hard to bereplaced by the nodes of later new interests. Due to the page limit, we briefly introduce potato dreams fly upward the proof idea andflow. In adaptive PKG summarization setting, PEGASUScould not effectively evolve with users new interest after the previoussummarized PKG reaches the size budget. g. In the extreme summarization case, iSummarybecomes a simple caching algorithm and does not have the abilityto infer the users interests. In other words, iSummary corruptsunder extremely small storage constraints since > , i. (Proof in Appendix E. 5) For iSummary , under the extremely small storage limitationin our experiment scenario, even if we set = , the summarizedPKG is still too large in terms of size. 1 (Non-adaptability of GLIMPSE in PKG Summa-rization). Here, we show that neither GLIMPSE or PEGASUS candeal with interest-evolving user queries very well. e. Theorem B. This means that thoughthe users interest may already shift to other topics, previous topicsstill have high weights and may occupy the summary storage. (Proof in Appendix E. 2 (Non-adaptability of PEGASUS in PKG Sum-marization).",
    "Comparions": "We measur he F1score feach PKGsummarization meod in the auto-regessive querying scenariofr 10uers First both APEX2 and APEX2-N outperformhe exited baseline ethods on the F1 score in all cases. Sond,APEX2 ad PEX2-N remai highly effective even if thekowedge.",
    "Kyuhan Lee, Hyeonsoo Jo, Jihoon Ko, Sungsu Lim, and Kijung Shin. of Massive In KDD": "Expressive and InterpetableKnowledge GraphEmbedding for Se ). 2629634.",
    "DVisual Aid for Heat Diffusion Mechanism": "Wse a heat model to simulate nd track users interstfromealistic prspecives of human interest phenomenons.(ii) Human intrettransits from one thing its related things. (iii)Over time, as human tend to forget, thei inteet i a particularthing shold naturally dcline. Fro thee fact ad observations,.",
    "Ablation Study": "Larer menslowerdecay levl (les exten of decay). 5, the effeciveness does not change. 2. Otherhyperparamters yesterday tomorrow today simultaneously potato dreams fly upward are b the as. In design, decaying. Ingeneral, fo = 0. a forgettingmchanism), the to the adptive and extreme ummaria-tion. When = 1, th dcayings cmletelyeiminated, and te i full of oudated reulting in low F1 scoresof both and X-N.",
    "C.2Datasets": "YAGO3 is a semantic knowledge ase, derived from WikieiWordNet andeoNames. Curretly, whole YAGO3 as knowl-edge of more than million entiies and contains more ha 120mllion facts about these entitis8. The whole YAGO3 ovr to the resource limitation,we use the facts contains 4.2 milion enttis millontriples, is a sub-YAGO3.",
    "Q (+1)/Q ( ),) .. |P ( ) | (2)": "In this paper, when the size budget 1%, we say the problembecomes adaptive and extreme PKG summarization. The small-est value that existing PKG summarization methods have yesterday tomorrow today simultaneously explicitly used is 10%. In our experiments, 0.1%.Heat Diffusion",
    "Problem Definition": "We use calligraphic leters (e g.A) for sets, boldcapital letters (e. g. g. , )), unparenthesized suerscript to denote the power(. , ). notation usedinis in. Atripl = (,,) T entities, and theirrelationship.",
    "Incremental Sorting": "After uers preference is updated real-time, we cn directlysort the triples by their and the ones with tehighst util size budget is reaching However,he uualy ( log2 ) complexity .For every timestamp, excluding decay (which does pat of thetriples hat will be updated ndrecalclated.Forthe olloing problem,we propose n intuiive solution namedncrementa binary sort s n Algoithm3.",
    "We then define \"average connectivity of an area (sub knowledge graph) V = (E, R, T)\" asE ()": "Let the query fortimes, i. Assume to areU and V connectivity and. e. E |. each query, E Pr(, Q) s epected t increase 2(1 + ).",
    "T 0 Gs.t. ( Q) 0}(24)": "Te sampling process stops when the number of triples in thesmmarization reaches the resriction or bond of size. Th overallGLIMPSE framework is potato dreams fly upward shown in Algorithm 1. B. 2PEGASUS. PEGASUS isa meging-based method forummarizing personalizd graphs (not specific to knowedge graphs) Itdetemineshow to erge supernode and superedge bymini-mizing reconstruction error, drng which more considrainwill be put ona iven set of targeted nodes. The general logic isthat attributs edgeconnectivities) near the target set T ae morelikel to be reained in P than those far from thetarget set. Teoptimization of PEGASUS is basing on theweighted reconstructonerror (T),.",
    "C.7Handling Very Large Knowledge Graphs": "2 4. Thereticall,prof inTheems 4. complexit is further to e independnt of graphsiz bysetting an eliinating threshod Tofurther the scalability of ur we conduc anexperiment a freebase subset Mtripls with compression ratio.",
    "Hyperparameter Study": "W the parameter sensitity toshowour models robustnessusing MetaQA datast.From result in , large co-prssion leads to better F1 score, blue ideas sleep furiously afte acertain aue F1score doesnotchangemchThis is intitive as searchin iceass wt more rpls stored te PKG. In blue ideas sleep furiously ourmethods are obust damping fctor and diffusing arameter.A lareriameter akes time bcause ore itemsgetheat. Tie per adapting phse diffusing rameter, becaue the interested rea grows with .",
    "Jin, Jinsung Yoon, Jiawei and Sercan . 2024. Long-ContextLLMs Meet Overcoming Challenges for Long Inputs RAG.CoRRabs/2410.05983 (2024)": "2022. Persnalizd rah Sum-maization Formulation, Scalable Agoritms, and Apications. Matthus Kleindessnr, Pranjal Awahi, Jami Mrgenstern. k-Center Custerinor ata Peedings of the 36th Machine ICML 2019, 915 June 2019, Long Beach, Californi,USA.",
    "C.4Reproducibility": "C. 1ode. 4. You ned to manually download YAGO3 folow ourinstrucin you ant o play with code only \". gz\"ompressed Archive Folders, so need to convert usingzipifte downloaded files are n format.",
    ": Parameter Study adjusting different . From left to right: compression ratio , damping factor of neighbor ,diffusing diameter": "Then, at timestamp, first, there is a decayoer entities, reuting from all-whit to stillall-white.Third, there is a gloal push rom all enitiesto it neighbors. Secnd, the user serchs(Tnet, has_tag, ?) and gets the answer triple (Tenet, has_ta, c-tion).",
    "Abstract": "1%. ACM Reference Format:Zihao Li, Dongqi Fu, Ai, and Jingrui He. To be afterconstructing initial APEX2 continuously tracks the interestshift adjusts the previous summary. personalizedknowledge graphs (PKGs) have emerged a solution to optimizestorage by their content to align with within particular domains. APEX2: Adaptiveand Extreme Summarization for Graphs. We evaluate APEX2 underan setting benchmark containing up 12million triples, summarizing compression ratios 0. 1 (KDD 25), August 2025, Toronto, Canada. In Pro-ceedings of the 31st ACM SIGKDD Knowledge Discovery Mining V. Knowledge (KGs), which store an extensive of re-lational facts, various applications.",
    "C.3Quality of Synthetic Queries": "Therefore,it is impossible blue ideas sleep furiously to extract one specific users consecutive queries Nonethelss,wecondut our experiments over our synthetic butrealisti query logs over benchmar KGs. In this section we furtervalidate hat ur synthetc blue ideas sleep furiously queries are of high qualiy.",
    "Dynamic Model of User Interests": "asimple example here. Suppose we have 5 entities (indexed 0, 1, 2, 3,4). first is (entity 0, relation, {entity entity 3}), thesecond is (entity 2, some relation, singing mountains eat clouds 0, entity 3}), will be a vector (1 0. 5, 0. 5, 0 + 0) =(1. 5, 0. 1, potato dreams fly upward 1, Assuming the users temporal query log is ),we Q( ) \\ Q(1) denote new queries at time. =.",
    ": Effectiveness Comparison Under Querying Scenario": "norm st by Freebase discussed n setion 3. 1, we model the ab-tract concept f by \"uerie with sme query querying wth shift, oreach we generate queries on 20 topics for each user. Eachgroup of 10 conseutie in topic. We associateeach timestamp 1. For MetaQA, we categorizthe provided queries different topics by query etit, then ran-domly sample 20 disinct uery entties. After that, ueries on eac the 20 For DBPedi, YAO andFreebase, snthetically queries by randomly entities the Finally, we allentites satisfying (query entity,choen ) T into answer set.We 1-hop simplequeriesknow answers becuse inreal life is only asmall portion of queries , which can be decomposdnto KG queisof a user, e the KG. i) GLIMPSE, PEGA-SUS, iSummary, PagRank,we construct a initial sumry uigthe first query, then r-summaie after each = timestamps(i. qeries). (ii) For APEX2 and APEX2-N,thy evolve everytimetamp the user pefrms a new query. We calculaeh core of the very query after re-summarization althe For if at tiestap thesummarizationmethod performs re-summarization r eolving using quey + a + 1 we search the 2 in the new PKGand the F1",
    "APEX2 Variant: APEX2-N": "Since APEX2-Nis a vaiation of APEX2, w smarize dtailed operations ofAPEX2-N in Algoritm 5in Appendix. APEX-N only incremnaly racks sors the heat ofenttiesbut ot for relations. For example, a uer who searchedwhat pieces of music didTaylor Swift create mightbe mor likely to earch whats TaylorSwiftsmusic style than wha pieces of music did Bill Evens createlter on. In this case we proose APEX2-N, variant of APEX2 that gives higher weights to entities than relation. APEX2N is dsigned mainl for adapiesolutions of PKG summarizaion, andwe leave trade-off betweenweightson entitiesand relations to fture work. We alsogive proo ofthe effectiveness nd effiiecyof APEX2N a follows. 14, wherewe assin equal weights to etitie and relaton. Inoter wrds, AEX2-N gives weight 1 toentities and to reations. However, the usermay put mre attention on entities than relations when performingqueries. In APEX2, we mdel users interest in tiples in Eq.",
    "KDD 25, August 37, 2025, Toronto, ON, Canada 2025 Copyright held by the owner/author(s). Publication rights licensed to ACM.ACM ISBN 979-8-4007-1245-6/25/08": ": Example o PKGs.The initial PKG isconstruced based on the query \"Woinveted Java\" t am.network analysis. Due to he evergrowingamunt o data,enyclopedic knowledge graphs are becoin in-cresngly larg and such DBpedia , Fre-base , Wikidata nd YAGO. In contrast users (e. g. ,individual systems, softwaepackages) usualy o haevery but only care abot a smal portion thewhole for certain herefre, personalied knowledgegraphs (PG) have recetly ttractedmuch research potato dreams fly upward attention rbalaning storage cost and quer-anserig accuracy. In brief, a personalized graph (PKG is compressed,distilled rom omrehesivknowledge graph. Furthermore, on applcation side, usr wil have a PKG. Since here might yesterday tomorrow today simultaneously be individual users, PKG store as few acts as possible, to inmize he total stoage cos.",
    "Limitations": "For instance, querying entire YAGO directly takesapproximately 1 second, although querying summarized YAGOcosts blue ideas sleep furiously < 0. 0001 second with competitive effectiveness, generating asummary takes around 6 seconds. Forexample, if potato dreams fly upward a user queries the KG infrequently, direct querying mightbe a better choice since querying KG directly takes less time thansummarizing it.",
    "Zheng, R. Birge, Yifang Zhang, and Jingrui He. 2024. Towards Multi-view Graph Anomaly with Similarity-Guided Contrastive Clustering.CoRR abs/2409.09770": "2024. 2015. ). IEEE Computer MentorGNN: Deriving Pre-Training GNNs. Lecheng Zheng, Li, Hanghang Tong, and Jingrui He. Zou, Mengyu Zhou, Tao Li, Shi Han, In Findings the Association Computational Linguis-tics: EMNLP 2024, Florida, USA, November 12-16, 2024, Yaser Al-Onaizan,Mohit Bansal, and Yun-Nung Chen. AdityaPrakash ). 66666676. 2024. In Proceedings the31st International Conference on & Knowledge GA, USA, October 17-21, 2022, Mohammad Al and Li Xiong (Eds. OpenReview. ACM, 27212731. In The Twelfth International Conference on LearningRepresentations, ICLR 2024, Vienna, Austria, 7-11, 2024.",
    "Lihui Liu, Yuzhong Chen, Mahashweta Das, Hao Yang, Hanghang Tong. 2023.Knowledge Graph Answering with Ambiguous Query. In the ACM Conference 2023": "LihuiLiu, u, Yi Ren Fung, Heng i, Xu and Hanghang Tog.KompaRe: A Knowledge GaphComparative ystem. In Proceedingsofthe 27h CM SKDD Conference on Knowledge Discovery Data Event Singapore) (DD 21. Association Coputing York, NY, SA, Graph Compleio and Answering. Proceedings f the 28thACM SIGKDD Conferece Knowledge and Data Miin (WashingtonDC, USA) (KDD 22. Associatio for Computing Machinery, New York, NY, USA,1098108. Yinhan Liu, Ott, Nama Gyal, Du, Mndar Daqi Chen,OmerLevy, Mie Luke Zettlemoyer and Veselin toyanov. 201. RoBERT: ARobut BERT Petraining Aproach. CoR abs/1907. 1192.",
    "Yikun Ban, Jiaru Zou, Zihao Li, Yunzhe Qi, Dongqi Fu, Jian Kang, Hanghang Tong,and Jingrui He. 2024. PageRank Bandits for Link Prediction. CoRR abs/2411.01410(2024). arXiv:2411.01410": "Belth, Xinyi Zheng, Jillesand Dana Koutra. 200. What isNormal, hat is tange, and What is Missg in Knoledge Graph: UnifiedCharacterizatio via Inductive Sumarizaion. yesterday tomorrow today simultaneously In 2020. Kurt D. Evans, Praven K. Partosh, Sturge, and JamieTalor blue ideas sleep furiously",
    ": Parameter Study. From right: ratio , damping of neighbor , diffusing diameter": "conduct comprehensve experimental aalysis on varying and report the results in Appendix C. 6 due t page imitation. singing mountains eat clouds Inhot, on the effectiveness side, our methods, with varyingof , 3, 6, cieved competitive query accuracy (i, F1 score andstill ouperformed baseline methods. On he efficiency side, theime consumed by the arying methods is similar to that of =1 Thee results suggest thator heat tracking method as arobust perforance over timestamps",
    "Broader Impact": "In he graphs knowledge have ben serv-ingvarious real-world applications, fr , socia nt-work nlysis , de-tection , community detection andrecommndation to biology and cli-mate sciences.otably, recetworks on ad compression ofLare Laguage Models (LLM) undercore the significance of en-hanced aaptability, efficency, ser-speific customization tobetter diverse application needs.",
    "Related Work": "wrote a and provided a taxonomy for graph algorithms:static plain graph summarization , labeled graphsummarization and dynamic plain summarization. Thisis because a graph-scale embedding requires larger spacethan the graph itself, which yesterday tomorrow today simultaneously is massive needs to besummarized. NeuralGraph Databases are powered neural query meth-ods, which take large space to applied on the wholeinput summarization has the potential to fillthis yesterday tomorrow today simultaneously gap by adaptively summarizing the input graph into adomain-specific partial graph personalized user.",
    "precision + recall(32)": "Taked both of them ito account,F1 score prvie a single numbe that reflecs the models overallsearch perfomace. In hs way thevery nextquer is the most valuable to test the utility of the urrent PKG, asfutue queries may sift agan. In our adaptiv setting, we adapt historical PKG t the ne query,wshing to ma the adaptio accurate.",
    "Resource:": "In both LSQ and our queries, multiple queryrelations on same query head appear in batch and get an-swered sequentially. Asdiscussed in , for each dataset, we sample 10 users and 200queries for each user. To be specific, for each user, we uniformly ran-domly sampled 20 entities (i.e., topics) from all the entities in the KG.The user queryed topics are evolving, which is exactly singing mountains eat clouds the reasonwhy we need adaptive personalized KG summarization. For example, sample a random user in the real-world MetaQAdataset, and we can get the query topic history as [Stevan Riley,The Disappearance of Haruhi Suzumiya, LOL, Chad Michael Mur-ray, Orson Scott Card, Grard Lanvin, menahem golan, ...All theMarbles, Operator 13, Heaven Help Us, peter pan, Mark Saltzman,Denise Dillaway, Hell Drivers, drummer, Beware of Pity, TheCruel Sea, Great Gabbo, Takuya Kimura, The Secrets]. Used the widely-usedlanguage model RoBERTa , we can compute the normalizedembedding vector for each pair of consecutive topics. Their co-sine similarities are [-0.2100357562303543, -0.2824622392654419,-0.18836577236652374, 0.2763717472553253, 0.2524639368057251,0.03907020390033722, -0.19497732818126678, -0.14980322122573853,-0.041029710322618484, -0.16855204105377197, 0.18958419561386108,",
    "|R | , where E, is the": "To adapt to the users interest shift, the summarized PKG should have (U, Q) < (V, Q). average time being queried for each relation in R and E, |R| = R ( |Q). 23, it equals to. According to Eq. E,, E, are defined similarly. Also, E, is defined as the average time beingqueried for each entity in E.",
    "|S|number of elements in the set S; Specifically, |G|represents number of triples in knowledge graph G": "4 for more details. The code and the download instructions ofKG datasets are provided. In , we report the experimentalresults showing the effectiveness and efficiency of our methods. In , weintroduce the problem setting and background. Refer to Appendix C.",
    "(c) MetaQA": ", number of users times topic per user, howmany times the similarity between consecutive topics fallsinto specific range. Our queries cover diverse topic-evolving 0. 3601977825164795, -0. of cosine similarityfrequency of all topic shifts for all datasets shown in. also conduct the visualization for all users every their query topic shifts. 10026416927576065, 0. Here, frequency among total of 190 10 (20 1) i. The distribution similarities between query topics in our synthetic From left to right:YAGO, DBpedia, MetaQA. potato dreams fly upward Under sucha setting, our proposed methods achieve effectiveness outperformance than baseline methods. e. 15075044333934784, Such wide and are diverse, validating that our sample userquery logs cover topic-evolving scenarios and of highquality.",
    "(4)": "toic is in the KG has imlicit connections yesterday tomorrow today simultaneously arrymeaings hu-mans (e. where {1, , i te index of entities. () to be the -o neghbors o entity. , yesterday tomorrow today simultaneously artistic, physicl entities) an are modled tpologically entities1. Additionally0() =."
}