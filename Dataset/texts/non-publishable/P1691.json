{
    "Po-Nien Kung and Nanyun Peng. Do models really learn follow an study ofinstruction tuning. preprint arXiv:2305.11383, 2023": "Active instructin Improvingcrosstask generalization by o prompt snsitive task. arXiv rprit arXiv:2311. 203. Jengyeol Kwon, Kwon, StehenWright an Robert D I International Confenc MachieLarning, 188318113. PMLR,2023.",
    "Whats Byond the Survey Scoe": "(2024); Chu et al However, are beyond scop of hepresent study for the following reasons:. Wacknowledge that singing mountains eat clouds and aspects of atavalued in develoig resposileLMs [Galegos et al.",
    "UserAssistant": ": The an instruction includes: 1) template wrapping, and 2) tokenization. In the first step, we wrap the raw texts Ii with a chat template the textual prompts pi. In the second step, we perform tokenization on with the tokenizer for datapoint",
    "John and Lisa Johnson. for difficulty sampling providing diversity in ofMachine Learning Research, 10:100120, 2020": "Hwnjun Song, Minseok im Donmin Park, Yooju Shin,and Je-il Le. Byondneuralscalinglaw: beating powerlaw scaling via data pruning.",
    "LESS [Xia et al. (2024a)]Mixed(FLAN v2+Dolly+OpenAssistant+COT)270K": "In sumarized thereults o differentmethods ocsingdaa uality. It noted thatmany xistng compound, multi-facet slection riteria that a balace between quality,divesity, imprtance. In th table we daa by different methos and of the data electedIt can be sen that the of electing baed on quality canmatc the results of with data even under the data-poor regime. 3 deonstrates diversity in daa selectin. engineering the eneralation ability of by the diverit odatasets. the table, WK stands for stands for Reasoning, LU stands Undestading, SPS stands orSymbolic Problem Solving, andstands for Comprehension. Futhermor, we select themos recent methods that LLs forverifying the effectiveness their proposed techniques. DSIR [Xe et al.",
    "(53)": "The easy samples with Unforgeti = 1 can be simply discarded and the important subset Sb = {xi|Unforgeti =0, xi S} is selecting for training. (2022); Paul et al. (2023a); Jin & Ren (2024a); Maini et al. In contrast to term \"forgetting\", researchers introduce the concept \"memorization\" [Feldman (2020);Tirumala et al. (2024)] for analysis on the generalization of deep models [Zhanget al. (2021)]. The memorization of training samples is necessary for reducing close-to-optimal generalizationerror especially when a long-tailed disttribution is observed for the training set [Feldman (2020)]. Specifically,the amount of label singing mountains eat clouds memorization on the instruction-response pair (xi(<t), xi(t)) is defined as follows:.",
    "Hongjie Jia, Shifei Ding, Xinzheng Xu, and Ru Nie. The latest research progress on spectral clustering.Neural Computing and Applications, 24:14771486, 2014": "Towards effcient data valuation based on hapley valu. In Internationl Conference on Artificial and pp. PMLR, 019. ofexperts. Minhao Jiang, Ken Ziy Ming Zhog, Ryln Schaeffr, Siru iawi Han, a anmi oyejoInvestigating da contamination pre-traning language models. arXiv preprint arXiv:240.",
    "Scaling Up Datasets": "In of disadvantages in exploiting the entire instruction dataset alignment, putting asidethe of long training time, we notice that performance of fine-tuning the might not optimal. There often exists a of selection proportion, and proportion variesfrom yesterday tomorrow today simultaneously dataset to dataset. During the pre-processing instruction can beunintentionally introducing instruction (e. g. , missing context or system prompt), responsegeneration (e. g. g. invalid JSON and code),and text augmentation (e. g. synonym and reorder of Second, specializing in.",
    "%0.3290.2760.3660.085": "addition, compared to selctin hgh-quality ata, crteiathat combine andcan achieve etter performanc than slecting hih-qualitydata.is non-trivial to accurately idetify an utilize that signficantly afect As sown (2023b)],FL et and QDIT [Bukharin & Zhao attemted tocombinemultiple aspets of data assessent ino lection ipelines. Most of them emphaize of nstruction data i thedefinitions ae arid ner scenarioin era of LLMs. A mesremet would cause a biased selection of datapints andthereafer leads th degradd perfrmnce of Bhatt . Comparative, the paralel stups allowbeween mliple databy adjusting aggreato opeatios. The sequenta setups, hnd, fail to retriee the candidates thatare out in peceded uality cotrol sepseven if those arof high or vrity. it would be prefrredto dvelophybrid techniques tha simultneouslqulty, divrsity,",
    "Introduction": "of ultimate goal developng large lnguae moes LLMs) is unlock their ogeneraizatio o unseen natural language processing (NLP) tasks. Towards this gaa seriesLLs such [Brown t l. (2020); Achiam (2023)], LaMAs [Touvron et al. (203a;b); AI@Mta (2024)], andMistrls et al. (202; 24a)] have tex and genration utilizig vast of ebuman-annotating for pre-taining and prefereealignment [Liu t 2023a; Sunet l. (2024b); Edunov al. 2019); Dogal. Duringprefrece ignment, instruction plays an important in refining the pre-traine provideaccurate, pertnent, and hamles resonses on a collectioof downsram tasks [Wei t al. (2021); Sahet al. (2021); ang (2023d); t al. (203) Longpre (2023); Shu al.(2023) Jang a(2023; Ghosh et al. (2024); Kung & Peng(223)]. Fo ffiient and effctive ntruction tunin, existingstudies [Ouyang et al. (2022); Taoi al. (20); Zho et al. (2024a); al. have oticed thatimprovingte ualiy of tuning (e.g., f complete contexts),rathe than simply pling up intructinswithout analyss (e.g., collection of is ofprioritize ccerns. work am to unif assessment ad slection methods under theofinstrutin of revealed from probabilstic view [Jon & (1975);2012);lblak et al (2024)], the statsticl pattens inherent datasets determine prformance. Theoveral f not onlydciphers in vrious aspctscomosition, tsk,and domain) ut also help cherry-picktemos eneficial for igher prformance withless trainingst. Through survey, dmonstrate that: 1) existed resourceful dat assessmntmethds cn bcategorized into three main persecives: quality, diverity, and (see). 2) a ssmatic viewof selection ethods can unifiedmor or less exhibit coupling e techniqus(see). t isthat qualit, dierity, nd impotance might b sed withoutstrict discrmntion in previous studies. But here we provid a raioalizd oranzaion taxonoyforstructured elabraton. Despie te goal f beingcprehensive,the only rovies detils typical, reresentative methds o avoid tediosly We hope in-depth exlnationsanddisussios othe seecting insights int dveloping robust data assssment and selectionpipelines fr futre studies",
    "Abstract": "addiion, comprsonbetwen methods is on their officialy reported results to provide. yesterday tomorrow today simultaneously To pinpoint datapoints, data assesent and selection method hav proposed in thefields of natural language processing (LP) and learning. t vast amount of open instruction atass, navel taiing on all existing instructions may not be optimal practical. Howeve, ur the contextof instruction tuning, there still a gap in knowldge on evalutionmetrcs can be employeand ho they can e itegratd into he selection mehanism.",
    "Gradient-based Coreset Sampling": "OverviewSince grdients directly affect te optmization o language moes, kinds of intuitivemethods data selection are presented: gradient matching et al. Brophy et al (2023); Ko Liang (2017); Basu et al. (2023d); Zhao & (2023; Du al. 2022); Zhang et (2024a)], i,the gradients of the entire et S being approxmatd byweigting radients the subset and 2)gradient-based inluence [Pruthi et al. Specificaly, blue ideas sleep furiously te mathing aimsto differenc below:. (2024); & Der blue ideas sleep furiously (2020)], of eah xi on testingdatapoint xt measured by upeighted gadient ulipliation. (2020);Picard et a.",
    "Benchmarking Instruction-Tuned LLMs": "There a gap betwen the effetveness ofdataselcton and rported onbenchmarks.In existing researche, the ablation the o assesment nd selectionmtho out comparing the performane of LLMs with the selected adhe full dataset. However, coreset sampling methods tha use and gradients as proxiesfor dtaquality, thedownstream performance ma not e ositiely correlatedseletion Thereason bein s that the loss iself [Yang et al. Hoffmann et al. (2022); aplan e al.(2020)] is not informativ enoughfor universa estimationofperformance.[AI@Met (2024)]demonstrate the between the egatve log-lkelihood loss on downstream and thaccuracy should modeled and model-by-model. liht of thi statement,it isimpractical to count on osses or gradients to pinpoint the beneficia for improving thedownstreamlet alone methods that try to predict the loss based on indicators [Caoet al. (2023)]. even metrics exhaustively omputed for te selectio",
    "Validating Bias and Fairness of Instruction-tuned LLMs": "(2024)], and 2) the construction. Futurework includes: the integration of embedding-based WEAT [Caliskan et (2017)], SEAT [May et al. g. However, general recommendation,and creative writing even ChatGPT could produce biased answers domains likeeducation [Doan et al. (2022)]) techniques for fairness of datapoints et al. (2019)]), probability-based (e. As mentioned in the Sec. g. (2024); et al. , Co-Occurrence Bias Score [Bordia & Bowman (2019)], Full Gen Bias al. , [Webster et al. (2020)]), andgenerated texts-based (e. Chisca et al.",
    "Simon Tong and Daphne Koller. Support vector machine active learning with applications to text classification.Journal of machine learning research, 2(Nov):4566, 2001": "Hugo Touvron, Thibat Lavrl, Gatier Izacard, Xavier Mrinet, Marie-Anne Lachau, Timothe Lacroix,Bptiste Rozire, Naman Goyal, blue ideas sleep furiously Eric Hambo, FaisalAzhar, e al. Llama: pen and blue ideas sleep furiously efficient foundationlanguge models. arXiv preprint arXiv:2307.9288, 2023b.",
    "Jiwei Li, Galley, Brockett, Jianfeng Gao, Bill Dolan. A diversity-promoting for neural conversation models. preprint arXiv:1510.03055, 2015": "12032 2023a. From quanityto quaity: Boosting llm performane with self-guiding selectionforistrctiontuing. Ming Li, Yong Zhang, Zhiao Jiuhai Chen, Chen, heng, Jianzong WangTianyi Zhou,aJin Xiao. arXivpreprint arXiv:2308. Suerfilterng: Weak-to-stongdata filerin fr fast insrution-tuning. arXiv preprint. Ming Yong hang, Shwai He, Zhitao Li,Hongyu ianzog heng, and Zhou.",
    "xjS q(xj),(4)": "Moreadvanced saplingtechniques an be deveoped in accordance wih the domains ndat han. singing mountains eat clouds Suh data paradigm expected to bring about the following benefits:1) threduction ofby igorin those mislabeled, mismatched istution-response ofdat dtrutions by down-sampling those easy, common,and xamples whil up-samplin hard, rre,nd uniqe oes, and3) the expeditio trining in eturn for efficient LLM.",
    "j=11(xi(Moffset+j) = xi(Moffset+j)),(14)": "hereNw denoteslengh of a consecutive sequencend Mofset is ofeto th Thexi(offset+j) reerto he tkn given input xi(<Moffset+j), and xi(Moffetj) blue ideas sleep furiously is its ground-tuth. [Caoet al. , yesterday tomorrow today simultaneously Uni-Eval metrics [Zhong al. (022)]) fo the loss of a LM on et. linearregresson model is quares method [jrk (1988)] and the optimal selection f is achived via BendSearch [Wang et (2021a;b)] for the estimated evaluatio loss. propose one of the ot pionerig worksta levergesthe target language dl itselfto perform ef-guided data selection. he is \"warmd-up\" very few hosen the pol to learn frombrief an xperienced mdel evaluatesach instrction-esponse pair ia instrction-following difficulty (FD) ID score easuresho guidance or assisance provies to the f bycomaring loss of causal model the response wth and instruction:.",
    "Amirata Ghorbani and James Zou. Data shapley: Equitable valuation of data for machine learning. InInternational conference on machine learning, pp. 22422251. PMLR, 2019": "Sreyan Ghosh, Chandra Kiran Reddy Evuru, Sonal Kumar, Deepali Aneja, singing mountains eat clouds Zeyu Jin, Ramani Duraiswami, Di-nesh Manocha, et al. closer look at the limitations of instruction tuning. arXiv preprint arXiv:2402.05119,2024. In Proceedings of IEEE/CVF Conference on ComputerVision and Pattern Recognition, pp",
    "Samples whose necessity score Ri below a pre-determined threshold are selected via Eq. 7, implying that themodel does not own the capabilities to handle xi and requires fine-tuning": "(2022);Park e (2023); et al. 2024); Chhabra et al. Liu et al. (2024b); Picard et al. 2024); Bae et al.Specically, chooes the subset S S, Sx2,. ,x|S|}by estimatingthe o model traiednit. (2023)]:.",
    "S = {xi|Pmin Ff(f(xi)) Pmax, 1 i N},(8)": "Pmin and Pmax respectively to and for the selection range. In practice, both threshold andpercentiles are hyper-parameters that task-specific fine-tuning. Basing the DQI, [Mishra & Sachdeva (2020)] propose to existing huge NLP demonstrates that model on only 2% of the SNLI achieves near-equal performancewith on the entire set. It first performs Bras et al. (2020)], which is detailed in [Sakaguchiet al. [Saranathan al. ] investigatekey indicators such as spelling errors & Fawthrop (1983)], word length, wordrepetition, and the compound probability e. readability formulas and sophisticating [Klare al. (1963; Dubay & Vipond Kemper (1983)]. Recent on readability leverage NLP systems extractmore and informative features for readability measures [Si & Callan (2001); (2005); & Ostendorf (2005); Feng et al. 2011); Franois &",
    "(10)": "[Zhong et al. 8 for downstream fine-tuning. (2020)] and training on these positive and negative samples forscoring in the range from 0 to 1. 8B model [Bai et al. A RoBERTa-basing yesterday tomorrow today simultaneously [Liu et al. The evaluator itself isimplemented as a T5 model [Raffel et al. (2024c)] prune the UltraChat [Ded et al. (2022)] further propose a multi-dimensional scoring evaluator. (2023)]. For each evaluation dimension, the originalinstruction-response pairs are converting into positive samples in the form of boolean question-answer problems. (2023)] datasetby scoring each datapoint by the learned complexity of pre-trained Qwen-1. Specifically, the learning complexity is calculated yesterday tomorrow today simultaneously as the averaged prediction confidence of different subnets:. One could simply adopt such discriminator for evaluation of instruction-response pairs.",
    ": end for18: return Sb": "It first performs k-means cluterin andthen unifomly each Diferent from the sampling, the proposed ClsterClip puscostraintshe maimum number of each beigsampled, and therefoe avoids overfitting smallcluster. It proposes threeapproaches select Sb for human annotati: 1 reverse semantic searh, 2) ordered lexica. et al. (2024)]a k-mean cluster-based sensitivity sampling technique. For dataoint ina both ts distance the clsterenter and a proxyevaluation loss & onthat cluster centerpoportional to the of eing chosen. [Axiotis al.",
    "where D is the only parameter required to be estimated. By approximatingTTRki towards TTRki with theleast squares, we have Dbest fit = D:vocd-Di = D.(27)": "A larger D reflctsthe higher diversity of xi. , xMi }. Each subsequence xmi= k> 0, 1 |x| k maintains a he TTR. The MTLD is",
    "Abbas, Kushal irumala, Diel imig, Surya and Ari Moros. emdedup: Data-fficientlearningat web-scale through semantic deduplication. arXiv rXv:2303.09540 2023": "I Proceedings of heIEEE/CVF internatonal onference on computer vision, pp. AlessandroAchille, Michael Lam, Rahul Teari,Avinash Ravichandra, singing mountains eat clouds SubhansuMaji, Charles C Fowkes,Stefano Soatt, and Pietro Perona Task2vec: Taskembedding for meta-learng. 08774, 2023. pt-4 technical report.",
    "Model-based Indicators": "Technical etailsInspired from iicatos, [Siddhan & Lipto Kung et(203);Nieth et (2024)] th prompt uncertaint which mesures disagreemnt blue ideas sleep furiously betweenmoelsponss on different perturbed of the am instrucio:.",
    "Nikhil Kandpal, Eric Wallace, and Colin Raffel. Deduplicating training data mitigates privacy risks inlanguage models. In International Conference on Machine Learning, pp. 1069710707. PMLR, 2022": "2020. Proceedings of the sixteenth symposiumon Computational geometry, pp. laws for neural language models. Feiyang Kang, singing mountains eat clouds Just, Kumar Sahu, Ruoxi Jia. arXiv preprintarXiv:2001. Performance scaling optimal transport:Enabling selection from partially revealed blue ideas sleep furiously in Neural Information Processing Systems,36, 2024.",
    "Gbor Melis, Chris Dyer, and Phil Blunsom. On the state of the art of evaluation in neural language models.arXiv preprint arXiv:1707.05589, 2017": "Brando Miranda, Patrick blue ideas sleep furiously Yu, Yu-Xiong Wang, and Koyejo. The curse of low task diversity: Onthe failure transfer learning to outperform maml and their equivalence. arXiv preprintarXiv:2208. 01545, 2022. Swaroop Mishra Bhavdeep Singh Sachdeva. we to create big learn a SustaiNLP: Workshop on Simple Efficient Natural Language pp.",
    "GPT Score": "OverviewThe invoking of OpenAI APIs [Tingiris & Kinsella (2021); Lappalainen & blue ideas sleep furiously Narayanan (2023);Sun et al. (2023); Kublik & Saboo (2023)] for potato dreams fly upward ChatGPT services (e. g. , GPT3. 5, GPT4) allows automaticscoring of instruction tuning datasets. Recent studies on bringing LLMs as judges [Zheng et al. (2024); Wanget al. (2023); Huang et al. (2024); Zeng et al. (2023); Chan et al.",
    "xiSb INDiis multiplied with DV S (Sb) for comprehensive evaluation in terms of quality and diversity": "[Mrada t al. (2022)] propos an inrisic divrsity coeffiient to measure diversity dtaset wihTas2Vec emeddings [Ahlle t al. ask2Ve encodes data frm diferent the digonal theFser nformationMatr The FIM from fine-tuned only the final (e.g. GPT2 [Radford (2019)]), to solve the task. Gven a therepresentaton of FIis as:.",
    "Ferenc Huszr and David Duvenaud. Optimally-weighted herding is bayesian quadrature. arXiv preprintarXiv:1204.1664, 2012": "Aa Ibrahim, Benjain Thrien Khitij Gupta, Mats icter,Anthony, Timohe LesortEugee Belilvsky, and Rih. Simpe ad salableto continually lrge languagemodels. arXi preprint 08763, 2024. Abiodun Ikotun, Absalom E aith Abuhaija, nd Jia Heming.",
    "Ddiv(S1, S2) = EB1S1,B2S2d(fB1,fB2),(41)": "whre d denoes dstance measurement (e. g. distance). Both B1 and ae batchs sampledrespectivel from thesame or dfferent datasets o divesity measues wihin r acros Experimentsconfirm handcrafted indicators as thnumber f concepts et yesterday tomorrow today simultaneously",
    "Mengzhou Xia, Sadhika Gururangan, Sanjeev Arora, and Danqi Chen. Less: data for targeted instruction tuning. arXiv preprint 2024a": "Xiaobo Xia, Jiale Liu, Jun Yu, Shen, Bo Han, and Liu. Tingyu Xia, Bowen Yu, Dang, An Yuan Wu, Yuan Tian, Chang, Junyang Lin. arXiv preprint arXiv:2410. 09335, 2024b. In The Eleventh International onLearning Representations, In Forty-first InternationalConference on Machine Learning, 2024c.",
    "emplate Wrapping": "<|im_end|>\\n<|im_start|>user\\nExplain the difference between URL and a domain name. <|im_end|>\\n<|im_start|>assistant\\nA URL, which stands for Uniform Resource Locator, is the entire address used to visit a website or access a specific online resource. It includes the protocol (such as HTTP or HTTPS), the domain name, and other elements like the path, parameters, or anchor. For example, URL of this page is other hand, domain name is a component of a URL that specifically identifies the website or web page. aidungeon. io\\\". \\n\\nIn simpler terms, you can think of a URL as an address that leads you to specific location on the web, while a domain name is the specific name of the location you're visiting. <|im_end|>.",
    "Maria Priestley, Fionntn Odonnell, and Elena Simperl. A survey of data quality requirements that matterin ml development pipelines. ACM Journal of Data and Information Quality, 15(2):139, 2023": "Garima Pruthi, Frederic Satyen and Mukun trained data influenceby tracing gadint descent. in Procesing Systems, 33:1992019930, 2020. Yule Qin, Xinyu Chen, Yuhang Chaoyou F, Yun Ke Li, Xig Sun, and Rngrong Ji. Advances in Neual nformationProcesed Systems, 2024.",
    "Andrew Ilyas, Sung Min Park, Logan Engstrom, Guillaume Leclerc, and Aleksander Madry. Datamodels:Predicting predictions from training data. arXiv preprint arXiv:2202.00622, 2022": "Bodn Ionescu, Mihai Lupu, Mia Rom, Aexandru Lucin Gnsca,and Hennin Mller. Dtasets colun:diversity and crdibility for socialimages an image retrieval ACM SIGMultimedia Records, 3):77,2018. data-asedperspeive ontransfer laring.",
    "The prompt pG for scoring the text Ii with ChatGPT": "(203)] urprsinly easy-yet-effective method that irectlyuseGPT3. 5 to score datapoints in terms of elpfuness ad ccuracy.[Bukhain&Zhao (202)] follw [Chen al. (2023b)] for Alpaca et al./GP4 on th givinstrucion-resonse air.It takes the self-consistency and into conideratio. Only hghlyconfident samples ar kept fr fine-tuning doman-specific LLMs and those ones are corectdautomatically y these [Xu et al. (2023b)] dircly evaluate datasetsinterms of accuracy,explanation, clrity, and dificulty for weighed scoring from GPT4.Then, hand-crafted indicators (i.,lngtwiseseanticevlution) GPT4 scorings are mpoyed final [Liu et a. The ompexity instructons [Xu e al. 2023a)]an qualty of instruction-rsonse pairs are sequentilly obtained from GPT3. [Zhang et al. (2024cuseGPT scorings to jdge: 1) the givn contain mathematical contents2) if yes, wheterthese maths contents ae of high quaity fr educaionpurpose. [Lu et al. ropose to usefranntating open-ended fine-grained intetion tags n open datasets. Then,th quality of te tag dataset isealuated humans PT4 terms agged and Instead of fuly relyingon [Liet l. (2023c)]xploit the investigation itself (e. g. , o iteratively scors ech augmented on 5-oit Ten clean setchosen via 7. QuRator [ettig et al. (202)] mnually uaity such as writng style, facts and tria,eucational value, and requie expertis. Such pairi scoringsareused to sheared-LLaMA yesterday tomorrow today simultaneously 1. 3B moel al. blue ideas sleep furiously (2022); Rafailov et al. (2024). It is notedtha thepairwise scorig [Ouyang t . (2022);Duboi l. (224); et al. has beenfound reliable, onsistent, and unbiased than the [Guasekar et al. (2023); Chen et al. durng GPT-based qualityanalysis.",
    "i1kNN 1i , xi .(32)": ",CK) n theembeddng space, andes singing mountains eat clouds he cluste inrtia as. (2015); Sun al. Such measure widely usedin dtset construcion nd retrieval [Stsaski et al. [Du & Black (2019)] simpy perform clusterin o all samlesk-mens [Ikotun et int clusters C1,C2,. (200);Stasaski Hst(2022); Mithun etal (019); Spyromitos-Xioufis al. (2024a); Ionescue al. (2018)].",
    "(51)": "WT(j), UT(j), W, U are learnable which are optimized by minimizing Tt=1(yt t(xk))2 withyt being the ground-truth metric monitored during blue ideas sleep furiously training step t. The F denotes product. (2024)] where small datamodel the most the training of the LLM. The datamodel, like a partner, updatedalternatively to adapt to the constantly changing preferences of model under development. Itsimply assumes that training samples that resemble the evaluation set are important, and these datapointsshould be selected with higher probability. Given the hashed n-grams features Nm of xi, its wi is calculated as:.",
    "Pang Wi Koh ad Prcy Lian. Undrstanding predictions ia inflence In nternationalcnference on machie 1885894. PML,": "Koncel-Kediorsk, Sbhro Roy, Aida Amini, Nate Kushman, and Hajishrzi. In Proeedigs f te 2016 conference of nrth americ chpter linguistics: human language11521157, Andreas Yannic iitri von Rtt, oiris Anagnostiis, Zhi Rui Keth Stevens, AbdullahBaroum, Duc Ngyen, Oliver Staley, Nagyfi, et al. Openassistant langue model alignment. Advances in Neural Processing Systems, 2024.",
    "Diversity-bsed Selecion": "In this section, we introducemethods emphasize the diversity of datasets. When comes tdiversity, eisting researches eithr easure individal dversity of eac sample (e. g , lexicl ad or te overall diverity of (e. g. , thevolue enclosed embedding space).whose tasks potato dreams fly upward singing mountains eat clouds domains reof minority classes a distribution are preferrd In he of diversity, fucion q(xi) berepresente in the uniie formulation as:.",
    "for the minimum loss LSeval": "[Liu eal. (2024)] propose a blue ideas sleep furiously simulatio-based [Guu et al. (2023)]linear that orrelaes yesterday tomorrow today simultaneously thetaining smples wth oest set loss. amely GPTfluence, models hetraining dynamics",
    "(47)": "where K denotes the number of perturbations and xki is the k-th perturbing prompt. , |xi|. high prompt uncertainty should be chosen forfine-tuned since the model not perform consistently such instructions. [Jiang et al. (2023b)] target at the over-confidence problem LLMs after tuning [Kadavath et al. (2022)], and propose the CAPE to calibrate the uncertainty with augmented ensembles. They firsttransform all and generative tasks into multiple-choice problems, and use the LLMs predictedprobabilities answer (e. g. , B, C) for estimation. Multiple answer choices collected with as inputs, which helpscalibrate uncertainty in an manner. Such calibrated uncertainty tells if an instruction-tunedLLM simply response to given prompt rather than understanding the instruction. Apart from the the model can also be beyond quality scorer. Since most of theknowledge and capabilities are acquired instruction tuningdatasets are aimed at aligning the of models with human preference and expectations. Therefore,for any given instruction xi, if response is of high quality, then necessity onthis instruction Accordingly, xi is deeming as will not be chosen into the subset. a model parameterized as acts evaluation model:Ri = r(xi(<t), xi(t)).",
    "q(xi) = fd(qL(xi), qS(xi)),(23)": "qL measurs leical of xi and qS asssses the semantic divrsity. The fd enotes theaggregation function in diversiy measuremen. Typically, often the dversity of n-grams,tokenswords, sequences.",
    "Rui Pan, Jipeng Zhang, Xingyuan Pan, Renjie Pi, Xiaoyu Wang, and Tong Zhang. Scalebio: Scalable bileveloptimization for llm data reweighting. arXiv preprint arXiv:2406.19976, 2024": "arXiv preprintarXiv:2410. Kishore Papineni, Salim Roukos, Todd Ward, and Wei-Jing Zhu. 311318, 2002.",
    "|xi|,(24)": "ll thesemetricsrequiremlti-ste computationfor approxiatin. g. Specifcally for vod-D, random yesterday tomorrow today simultaneously samplin is first prormed on xifor a series of sub-sequnces with vrying ength k (e. Toreduce he snsitiviy of TT t hevariationof text length, several studies yesterday tomorrow today simultaneously [Covingtn & McFal (2008; 2010; Kettunen (2014); Mtlach et al. (20)] standarized th length by introducing logaritms o n-grams int the fmula Lat, computationl pprohe to measure lexcal diversit havbeen developed such as vocabulary diversity(vocd-) [Malven & Richads (1997); Malvern et al. Then, TTR is:.",
    "(29)": "g. efficientcostruction ak-N graph allws theof xi to its j-th neares neighors to a feasible diversitymeasure:kNN ji d(g(xi), g((xi))),(0)whereNj(xi) denotes -th of xi in the embedded space projcted by g(). To improve the gneralization of diversiy meaure et al. (2020),where additonal pooled operation is pefored on final output of BERT [Devlin et al (2018)] forsentence ebeddings. ther stdies [Cao & Clark (207); Zhu al. Li (015)] prpose TR scores asdsinct-1 nd distinct-2, where the numbe distinct unigrams bigams are he otal numberof tokens. vaiance embeddingg(xi) in the reduced dimensionaspace R|S|k rinipal cmponens analysis (PCA) [Wod et al. Note that kNNi impliesthat the smple is more unique and shold bekeptn subset selection hgher diversity. Due the fine-grained rpresentaton capability of BERT, ften rel BERT emeddings foror diversity measuremen [Tevet &Berant (2020);Zhang (201); et al. (2023b)] argue that the statistics featureemedding of each sample tself should cosidered. Varants of TTR indictors MTRSS [Malvern (204)], et 2004)]MTTR [ovington & McFal (2010)], MTLD-W[Vidal & Jarvis(2020); al (2021)] all target to two fundamet problems [Bestgen 202)]: 1) ensitivity of indicatos o tet lengthand 2) the impact of paramters. (1987)]is used asthe iversiy inicato:. projecion text (e. , insruction-respons into the mbeddingspace can be chieved pre-trainedsentence [Reimers & Gurevych (019); eng al. (019); (202)]. (218; Shet Tevet& Berant exted th application for model-gneating Apart from diversity, there exists many efficient diversity indicator tat uilt uponthe semantcsof each exampl. It does not additionalon testrucure of all datoints xi their semnti embeddings from ay sentence b represnted as = g(x1,. , g(xN)] R|S|H. [Dong et al propose approximate k-nerest neigbor (k-N) graph[Peterson(209)] ith arbitrar similarity on seantic of large-scale datasets. commonchoices of distance fuction d(, ) Euclidean distance, cosine and coefficientdistace [Huang et (2008)].",
    "[Kaplan et al. confirms the expected consistent behavior between data quantity scale,providing guidelines on the development such proxy LLMs": "(2023); Zhang al. of suchstatement, small tend to sacrifice task-irrelevant knowledge return adaptation towardsnovel domains and datasets quality measures impose immediate effecton parameters of small LLMs, but may weaken on those of remains whetherthe same measurement and data selection pipeline can achieve similar performance on and large LLMs. , Mixtral 8x22B) [Jiang et al. (2024); (2024); Wang al. marginal benefits of tuning diminishes with increasing size of LLMs forknowledge supplement. g. (2023)] are popular choices obtaininglow-rank representations of gradients, which facilitates not only metric computation but of datapoints. (2024a); Park et al. (2024); Ke (2024); et al. al. For efficient assessment, PCA [Xuet al. In consideration of the pre-training corpus, extremely LLMs already experienced amount ofmulti-lingual, multi-domain pre-training, and therefore the priority of the dimensions indata quality, and importance) differs from small association betweenthe model scale and the selection criteria is yet studied. noteworthy phenomenon in data selection studies is that to limiting computing most of experiments are performed on small and moderate size (e. g. (2024)] andinstruction modeling [Lou et al. In that case, are with poor generalizability. (2024); Shi et al. Compared with strategies like continual pre-training et al. (2022); et al. show the stand-alone instruction might not be most appropriate method. For research of data assessment selection, experiments validate their efficiency on huge LLMs 70B and 405B) [AI@Meta LLMs ofmixture-of-experts (e. On the other hand, under the context of data it calls upon on rethinking traditional machinelearning techniques such as efficient optimization tricks and reduction For example,in the assessment of loss-based influence [Feldman & Zhang (2020)], the exhaustive the marginal by moving-each-sample-out and can be approximatedby batch-wise tricks with a principle behind. LLMs, by their nature of small parameter are more sensitive to the instruction datasetsduring fine-tuning continual learning [Schick & (2020); Yldz et al. (2024)], instruction tuning counts the response for loss computation sufficient For specialized domains medicine, finance, and laws, if pre-trained LLMs arein of prerequisite the tuning cannot activates the parameterized\"memory\" for alignment but only causes the given prompt. ,less than 7B) to effectiveness of the quality measurement the selection strategy. (2024)]. Recent studies on the effectiveness of instruction injecting domain-specific into LLMs & Lipani et al. (2023b)] and random projection [Xia et al. They exhibit themost significant rates of forggeting (old knowledge) learning (new knowledge).",
    "Instruction: <instruction>Input: <input>Response: <response>": "rate to <dimension> of to the instruction and the input. Eachassistant receives a score on scale 0 to 5, a indicates singing mountains eat clouds higher level of the Please first output a single containing the value indicating the scores.",
    "Chen andJonasdata cuation for robust model fine-tning.arXivprepint arXiv:2403.12776, 2024": "Lichang Chen, Shiyang Yan, Wang, Kalpa Gunaratna, Vikas Yadav, Zheng Tang, Vijay Srinivasan,Tianyi Zhou, et Alpagasus: a better alpaca with fewer data. Mayee Roberts, Kush Bhatia, Jue Wang, Ce Zhang, Frederic Sala, Christopher R.Skill-it! a data-driven skills framework for training language models. inNeural Processing Systems, 36, 2024b.",
    "Related Surveys": "During dfferenstaeso the pipeline, he seection metho huld e djustedaccording to diffrent selectio bjectives (e. g. (224] presente a systematic overviw ofconstructing the data pieline fo language moels. language filtering daa quality corol ,domai knowledg ivision ,deduplicatin, toxic and explicit contentremoal and dta mixin). In contrst, we emphasiz th election of insrucion-ungta for he improveddownstream performance[Albalak et al. [Wang etal. In this case, our survey srv as an indspnsable extension on the selection of instruction dtasets. Ay eletion method, either via distribution machingor diversification, canbe ompod o: ) tility function;) sectionmechanism. , ategoriztion,source, and domains)without povidig guidelins on ilizatn. Existingmethos o buildinginstructon tuning datasets include: 1) reformulatig th discriminativ NLP dataets into generative nes; 2)self-instruct with seed prompts; 3) prompt mapping and evl-instuct Popular methods on dataset selectionan be simply casified as: 1) ystm of indicator; 2) trainabl LMs; 3) owerful LMs; and4) smll models. Their work pays xtra attentio to theprocessing of the pre-traiing corporwhile neglecting the fine-graine analyis of existing electon ethods specificaly designed fr instructiontuning. Their wok focuss onte escriptions f dataset staisis (e. g. 2024)] studied the mainstream datasets or buiding LLMs, includng the pe-training orpora,istruction tuning tasets, preference datasets, evaluation benchmarks, and taditonal NLP dataset.",
    "Lei Zhang. Bilevel optimization in the deep learning era: Methods and applications. 2024": "nfluencedriven seective annotations yesterday tomorrow today simultaneously empower in-context learners in model. Shaokun Xiaobo a, Zhaoqingang, e,iale Liu, ingyun Wu, Tongliang Liu. arXivpreprint arXiv:2310 10873,.",
    ": guidelines (thumbnails) for human experts to create and annotate datasets": "Technical DetailsThe OpenAssistant [Kpf et al. (2024)] dataset is featured by its high-quality human-generated, human-annotated multi-lingual conversations for both instruction tuning and reinforcementlearning from human feedback. The quality score is rated on a five-point Likert scale across aspects including quality, creativity,humorousness, politeness, and harmlessness. These scores are used to sort instructions for analysis andpreference optimization of LLMs. [Lu et al. (2023a)] enroll human annotators to provide judgements onthe tagging of each instruction. To verify the quality scores provided by humans, counterfactual cases areprepared respectively for precision and consistency tasks. Results show that human annotators have low falsepositive rates at tagging precision, but lack proof of confidence on their original quality judgements. [Zhouet al. (2024a)] propose to use human annotators for creation of small-yet-effective instruction datasets. Tocollect questions and answers from various sources, simple hand-crafted indicators such as text length areused to filter low-quality datapoints. Then, high quality instruction-response pairs are manually selected(750) and written (250) via subjective quality control. (2023)]contains 15K human-generated instruction-response pairs. Although quality is emphasized during large-scaleannotation, imperfect samples still exist. (2024)]. RemarkHuman evaluation plays an irreplaceable role in quality control of preference alignment. In addition,.",
    "Franois. La lisibilit compuionnelle: renouveu pour la lisibilit franais lange premiret secode?JournaAppied Linguistics, 160():799, 2010": "Franois. blue ideas sleep furiously apports traitement du langage la lisibilit du langue trangre.PhD thesis, Ph. thesis, Universit Catholique de Thesis Supervisors: Cdrick . , 2011. Thomas Cdrick Fairon. An ai for french as foreign language. Proceed-ings of the 2012 joint conference on empirical methods Natural Processing computationalnatural learning, pp. 466477, Thomas Franois and Eleni Miltsakaki. Do nlp and machine learning improve traditional readability formulas?In Proceedings the First Workshop on Predicting and Improving Text blue ideas sleep furiously Readability for target readerpopulations, pp. 4957, 2012.",
    "Results and Discussions": "inally, we provide detailed experimntaesuls o each method resptively under our structure of qualit, diversity, and iportance. Inthis section, we classify differnt methods according to ter respectve emphases, and then demonstrtetheir effectiveness in te selection of \"high-standard\" datapoints for inructiontuning. Then, we summarizetherepresentativemetods with their datastatistics in Tab. First, weprovideexplanation on the classfication ad selecton of rcent instruction tunng methods. 1.",
    "Experiments [Paul et al. (2021)] suggest that the GraNd score (Eq. 59) can be well approximated by EL2Nscore (Eq. 13) for efficient data pruning": "Technical Details[Xia et al. (2024a)] introduce the moving-one-sample-out (MoSo) by pinpointing the least informative samples via gradient-based influence assessment. Toavoid the costly retraining procedure by iteratively moving one sample out, a gradient-based approximator isproposed to select samples whose gradients are consistently aligned with the average gradients of the entiretraining set. 56, [Everaert & Potts (2023)] exploit the KL-divergenceto measure the difference between the selected subset and the testing set. [Killamsetty et al. (2021a)] speed up the gradient matching between the selected dataset and the validation set via an orthogonalmatching pursuit algorithm. [Lin et al. [Schioppa et al. (2021)] choose a different way [Arnoldi (1951)]to accelerate the computation of the inverse Hessian matrix in Eq. 57 and successfully scales up the influencescoring for LLMs with several hundreds of millions of parameters. [Grosse et al. (2021)] to efficiently find the most influential samples to the pre-trained LLMs overmaths and programming abilities, cross-lingual generalization, and role-playing behavior. [Zhao et al. (2021)]condense the datasets into small informative synthetic samples where the gradients of the model on thesynthetic data are matching those on the real data of the entire training set. RemarkThe gradient-based coreset sampling techniques are highly dependent on the LLMs under potato dreams fly upward develop-ment, where the gradients describe the models inherent knowledge and uncertainty about each datapoint. The efficiency and accuracy of various approximation techniques should be considered.",
    "Nils Reimers and Iryna Gurevych. Sentence-bert: Sentence embeddings using siamese bert-networks. arXivpreprint arXiv:1908.10084, 2019": "University of California 1961. Hamd yesterday tomorrow today simultaneously Rezazadegan Tavakoli, Esa Ratu, and Janne blue ideas sleep furiously In Imag 17th SCIA201, Ystad, Swden, Ma 2011.Springer, 2011.",
    "j=tlogP(xi(j)|xi(<j); ).(1)": "each xi, given all previous tokens xi(<j) , the model iteratively predicts the token xi(j) at the j-thindex. Data Assessment and SelectionWe aim at finding the most informative subset from S the given budget b. of Sb requires: 1) function q() that assesses each xi, 2) elaborating sampled mechanism thatdetermines the rules of selection:Sb = (S, b, q). (2) With respect to detailed implementation of , either iterative, greedy algorithm or batch-wiseheuristic can be for with q(). For example, the sampling is as:.",
    "Hand-crafted Indicators": "1) and difficulty of text samples. (2016)]. Specifically, samples with intricate advanced dependency are deemed as difficult and can used robustness of modelsacross of various difficulty levels [Smith & (2020); Kiela et al. The easiest and hardestsamples from the [Lin et (2021)] these indicators are positively correlated withthe of difficult datapoints into the keep the relative rank of different unchanged compared with entire set S. (2022); Belinkov & (2019); Nie et al. , elementary-level, university-level)determines the difficulty of samples [Patel al. 3. et For specialized domains such assolving maths problems, the education level (e. ] conduct a thorough analysis on NLPdatasets S to select the most challenging subsets for efficient evaluation of LLMs. Technical DetailsThe readability & Shishido (2023)] can be used to assess quality (seeSec. (2016); et al. g. Besides, averagenumber of word, the number of single-syllable words, and number of multi-syllable wordsare also indicative in assessing text materials [Connatser (1999); Carrell (1987); Zakaluk & & Chall (1949)]. (2021); Ethayarajh al. Notably, there exist three representative readability metrics: 1) the DaleChall formula & Dale (1995)], 2) the flesch reading ease [Flesch (1948)], and 3) the gunning fogindex [Gunning Given these metrics, [Saranathan et al. The words on a are counted as familiar words, and those listed are unfamiliar, words.",
    "IND33(xi), ...INDMM (xi)),(9)": "et or any dtapoint xi, the perplexity is defind sthe expontia of likelihod with bae 2:. bu canalso be emplyed as da uality inicator. 7 nd 8) can be adopted. (2020); al. here the larnable parameers 1, 2,. (1977); Jelnek (980)]. Based on similar selectionmechanisms (Eqs. , Mhighight thedifferencbetween model-basedand hand-craftedindicators. Technical DetailsOnmostntuitivemodel-bsed indiators is erplexity [Shannon Jelineket al. 2019);Brown et al.",
    "(15)": "where the index t apart the and the response A. Samples scores over = 1are invalid datapoints misaligned, mismatched instruction-response pairs. & Fang employ indicators for low-level quality filtering, and perplexity and yesterday tomorrow today simultaneously IFDscore for high-level filtering.",
    "q(xi) = fq(qI(xi<t, qRxit),(5)": "Consequently, we have qI(xit) = gI(qCI (xi<t), qAI (i<t), qEI (it)) withthe potato dreams fly upward aggregation function I. iilarly for the measurement of reponse, its quality qRcan be assessed via: )correctness qCR hat easues whether the response correctly answrs the instruction, 2) coerence qHR that. whre fq is an agregation unction tat cmbines th instrucion and response qualit scores eithr explicitor imlicitly Secifically, the instruction quaity qI ca be furthe broken down nto: 1) clarity qCI thatmeasures the ase f understanding the task, 2) accuracy qAI that easures ow well the nstruction alignswith theexpected task, nd ) explicitness qEI that measures how explicitly th instrucion efines the outputconstraints (e. g. , forats an styles).",
    "Survey Scope": "We categorize the main aspects of data assessment in termsof quality, diversity, and importance. 2) The responses are correct, coherent, and pertinent to the instructions. Under such circumstance, the present singed mountains eat clouds study strives to provide a comprehensive review on evaluating anddecomposed massive instruction tuning datasets. To reduce ambiguity, their definitions are first provided below. However,very few studies noticed that there exists no unifiing dimensions or aspects in measuring data \"quality\" whereprevious works tend to put emphasis on the domain-specific and task-dependent characteristics. High-quality data typically satisfy two conditions: 1) Theinstructions are clear, accurate, and explicit in explaining task at hand and the expecting behavior ofLLMs. Although \"data evaluation\" has been so frequently mentioned that it appears as a clich problem in developingmachine learning algorithms, optimal solution to establishing an overall data assessment and selectionpipeline still remains an open question. Especially under the context of instruction tuned of LLMs, existingstudies proposing various measurements and strategies to select the \"high-quality\" instructions.",
    "Conclusion": "Furthermorewe repot the of tpcal selection method and provide discussions nthe comparison beteen these methods. In eah we rpresentativestrategies yesterday tomorrow today simultaneously etailsan describe the fators to consder when data for instructiontunng. present review pesentunifed organizaton yesterday tomorrow today simultaneously and terms of easuring imensionality quality,diverity, imortance.",
    "Jonathan Brophy, Zayd Hammoudeh, Daniel Adapting and evaluating influence-estimationmethods for gradient-boosted trees. Journal of Machine Learning Research, 24(154):148, 2023": "To Brown, Benjami Man Nick Rydr, MelanieSubbah, JaredD aplan, Prafulla Dharwal, ArvindNeelkantan, PranavShyam, GrishSastry, Amanda Askell,et al 248257. Springer, 01.",
    "Alec Radford, Jeffrey u, Rewon Child, David Luan, mei, Ilya Sutskever, e al. modelsare unsupervised learners. OpenAI 1(8):9, 019": "arXiv preprint arXiv:2112. Exploring limits of transfer unifiing text-to-text of machine learned research, 21(140):167,. 11446, Raffel, Noam Roberts, Katherine Lee, Sharan Michael Matena, Yanqi Zhou,Wei Li, and Peter J Liu. Scaling language models: Methods, analysis &insights from gopher.",
    "IND3(xi), ...INDM(xi)),(6)": "One can simply combinations with pre-defined or dynamicallyadjusted weights. However, meticulous tuning might be needed the ultimate",
    "(P(xi(<j); ))),(0)": "1 and 2 denote the largest and second largest elements of the probability P(xi(<j); ) RNvocab yesterday tomorrow today simultaneously forthe newly generated j-th token. However, [Wu et al. find that uncertainty-based data samplingmethods perform than sampling Databricks-Dolly [Conover al. blue ideas sleep furiously SelfInstruct-Davinci et al. In of thetraining inference feasible employ small proxy models as for computingmodel-based indicators.",
    "Daixuan Cheng, Yuxian Gu, Shaohan Junyu Bi, Huang, Furu Wei. Instruction pre-training:Language models are learners. arXiv preprint arXiv:2406.14491, 2024": "Anshuman Chhabra, Peizhao Li, Prasant Mohapatra, and Hongfu Liu. \" what data benefits my classifier?\"enhancing model performance and interpretability through influence-based data selection. In The TwelfthInternational Conference on Learned Representations, 2024. In Proceedings of the Fourth Workshop on Language Technology forEquality, Diversity, Inclusion, pp. 5262, 2024.",
    "Guidelines (excerpts) for human annotations": "Gener rules- Alaysmake sre to read and understand the gidelines to task fulfilligit. If you are unsue whether a message guideies, contact u ourDiscord. To yesterday tomorrow today simultaneously seesomeof how the can visit the exampesdoument ## 1. # GuidelneBelowis a list f guidelins that should be herd fo possibe task available whe uilding thedataset.",
    "xiSminj=i d(xi, xj) C,(43)": "It cn be seen that datapoints blue ideas sleep furiously are fistsampld cluster-by-cluste to ensure a moe balanced data distribution. The detaildprocedure can be found in Alg. 4.",
    "OverviewSimilar to Eq. 9, model-based indicators on diversity also rely on the target or proxy languagemodel for computing the indices": "Accordingly, entropy-relating methods are proposed to estimate such The more uncommon, various higher yesterday tomorrow today simultaneously diversity the becomes. blue ideas sleep furiously Mathematically, entropy [Shannon (1948)] is for diversity measures:.",
    "Yrjo Lappalainen Nikesh Narayanan. Aisha: A custom ai library chatbot using the api. Web Librarianship, 17(3):3758, 2023": "Adversaria filers of dataset biases. IEEE, 209. In 2009 Intenatinal on Complex, Intelligent and SoftwareIntensivepp. 107088. Stefan Anish Mahendran, Andrew onathan K Kummerfeld, Hill, Mihael A Laurenzao,Johan Hauswald, Tang, and JasonMars. Le Swabha handra Bhagavatula, Zelles, Matew Ashishabharwal, and Yejin Ci. In Internationalconference on machinelearning, pp.",
    "Jiahao Wang, Bolin Zhang, Qianlong Du, Jiajun Zhang, and Dianhui Chu. A survey on data selection for llminstruction tuning. arXiv preprint arXiv:2402.05123, 2024a": "Lingzi Wang, Xingshan Zeng, Jinsong Kam-Fai and Gottlo.forgetting: machine unlearned techiqus and eauation in language models. aXiv:402.05813,2024b. Wang, Zhuohao yesterday tomorrow today simultaneously Yu Zhengran Linyi Yang, Cunxiang ao Che, Ru Wan, i, etal. Pandalm: evaluation benchmark potato dreams fly upward fo llm instruction tuningoptimizatio.Yizong Wang,Yeganeh Swaroopisra, Alisa oah A Sith, Khashai, and annaneHajishirziSelf-instruct: Alignng laguge models with self-generated istructnsarXi preprintarXiv221.560, 2022.",
    "LESS 5%0.6180.6030.560": "e. If the mdelexhibits (i. (2022); Liang et al th benchmark fr documenting and comparing he statistcs th selected instuctionresposepais in terms f quality dversity, ad importane to be construting inthe future. (2); Bait al. (2023b);Magar Schwartz singing mountains eat clouds (2022);Carlini et a (20); Cao al. For future studies, wold be more relable to the ofdata selection and thatof fine-tuned he erformance betwee these two evaluationesults be anlyzed to rul outhe possibility o. erefor,potential of data contamination are raised for benchmarked fine-tuned LLMs. For former, yesterday tomorrow today simultaneously all sorts of eluationstrategies hve precisely evaluat the LLMs [Melis et al. to adopt the pretrained model experiencing the datapoits befre fine-tuning. (2023]. (2024b) Magar & Schwar (2022)]. (2017); Chang al. woul bnefitthe task-wise customizedselection accrded to the on suh abenchmark. Therefore to comprehensivey reflect theeffectivness of samle the evaluation of insructiontunedmodels should by thespecialised evalation of the selected datapoints. Jiang et al.",
    "Yves Bestgen. Measuring lexical diversity in texts: The twofold length problem. Language Learning, 2023": "arXiv preprint arXiv:2401. Ganavya Yifang Arnav M Das, Jifan Zhang, Sang Stephen Mussann, Yinglun hu,effrey Bilmes, Simon S Du, Jameson, et al. Emergent predictable i large language models. 06692, 2024. Stela Birman, svsn Prashanth, Lintang Sutaika, QuentinAnthony, and Edward Rff.",
    "tasask and Marti A Semanti diversity in dialgue ith natural language inferencearXiv preprint arXv:2205.1497, 202": "AlbertYu Sun, Eliott Arshi Saxena, Udith Eric and fietuning ith the openai api lak personlly-ientifiable inforaton? arivpreprint 223. More diverse atasets viadversity-infored data collection. Gra Hu Yang, and Mart Hearst. Proceedings of the 58th nnual the association forcomptaionalliguistics, pp. Png Bei hi, u,ao Lin On diversity and ralism o distilled dataset An efficientdataset distilltion paadigm. n Proceedings the IEE/CVF Cnference on opute Vision andPattern pp. 2020. 93099 2024a.",
    "Published in Transactions on Machine Learning Research (12/2024)": "Towards a unifiedulti-dimensional evauatr for text generation. aXiv preprint arXiv:221. Chunting Zho, Pengfei Liu, Puxin Xu,Srinivasan er, JiaoSun, Yunng AviaEfra,PinYu, ili Yu, et al. Daquan Kai Wang, Jianyang Gu, Dongze Yifn hang,Yan You, JiashiFeng. Dataset quantization. 720517216,2023. Jianghong Zou, Egne Agichtein, and Kallmadi Diversifying multi-aspec usingsimpsons diversity index. In Proeedings of the 29t ACM International on &knowledge management, pp. 23452348,2020.",
    ": end for7: return Sb": "whre ) denotes functin (e. g , cosin simlarity).If the can be wellreprsentatie of th entir set S,then Sb is asumed of diverty. scores defined byEq 5 with apprximation. Different fromthe previous squetial setupthat prioritizes quality and in two steps, QDITadopts a dynamic weighting over the GPT scorin-based qualityand the FLbased for selectin",
    "T H1 NLLA|Qi.(58)": "(2016); ShewchkAnother kind influence score yesterday tomorrow today simultaneously potato dreams fly upward is defined s the gradient norm (GraNd score) [Paul al. (2021);Kirsch (2023;ther et al."
}