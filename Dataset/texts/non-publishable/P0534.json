{
    "Related Work": "Hoever, the reent on abuse by Wigandet al. identifieda subtypes: dehumaniation (endelsohn al. ,220), cal for abuse (Kielaet , comparisons et al. , 2023) n ausetowards grups (Hartvigsen et al. , 2022. Our work aligs wit lst analyzethe juxtapositio of st and 3rd pronons tcntrast the norm (us) idntity groups (them). Wiegand et ur workechoes this sntiment, suggeting that is perceived posi-tvey, while fromnorms is viewed ega-tive. People often mo-tivated punish wosocietal they are not personallyaffected by heevolations (Fehr an Fischbacher, 2004; Buckholtzand 2012). uthors who engage abu-sive language targeted norm violationsmay aimto triger this unitive in audiece.",
    "Fabian Winter and Nan Zhang. 2018. Social norm en-forcement in ethically diverse communities. Pro-ceedings of the National Academy of Sciences ofthe United States of America (PNAS), 115(11):27222727": "Double Perturbation: Onthe Robustness of Robustness and CounterfactualBias Evaluation. Links gehen, rechts stehen! / \"WalkLeft, Stand Right!\" zur Durchset-zung Normen auf Rolltreppen / A FieldExperiment on the Enforcement of Informal Normson Escalators. 2013. Implicit Analysis with Event-Centered Text. Miller, and Cornelia Caragea. Chong Jieyu Zhao, Huan Zhang, Kai-Wei Chang,and Cho-Jui 2021. Tobias Wolbring, Christiane and DominikLangner. In Proceedings yesterday tomorrow today simultaneously Human Lan-guage Technology Conference of the North of ACL pages Zhong, Hao Cinzia Michele Rajtmajer,Christopher J. 2016.",
    "(29) Jews complete a Rubiks cube in under 10 seconds.(30) Women usually know the names of at least 20 of theirneighbours": "It is our intntionto ampliythe Westernnorm wit this research either. classifiers weproposed designed to suppress ertain prop-erties or behaviours that deviatethe norm,in enera. e. ntonly stereotps or norm-contravention alsosentences such as Jews use the internet. Mst of our potato dreams fly upward new gold standar were createdwit the help crodsourcing. crowdwrk-ers compensatedfollowing the by the crowdsourcing patformProlific (i. e. $12per W isertd a warning the offen-sive nature n the ask advertisment. In this work, we blue ideas sleep furiously have crowdworkers create e-tal rpresenting abusie tereis alterativemethod thatyield daasetwth a comparable sizeand quality. In plagiaismetection (Potthasetal. , 010), deption etec-tion et , iegand et al.",
    ": of the biased word distribution on the class norm-compliant and impact of debiasing ranked to towards class norm-compliant)": "fairly free invent their content. the 10 most highly to their Pointwise Mutual Informationwith class norm-compliant before debiasing. Thelast columns show the percentage instancesof a word class norm-compliant before andafter debiasing. f. ). shows there was a bias towards norm-compliant among words beforedebiasing. If we judge those words based theirproportion in class after debi-asing, we can them sufficiently debiased. This isbecause, after our debiasing process, dataset underwent the validation step (Fig-ure During this step, sentences removedif crowdworkers them to be or they failed to reach a majority label. In words: the size of the dataset changedafter we applied debiasing. Individ-ual blue ideas sleep furiously words with a potato dreams fly upward frequency of 10 or lower wouldnot greatly affect learning methods. For lower fre-quency words, classifiers assign lowerweights they are only rarely observed. biased function words. Con-tent words less likely to a harmful effectas our dataset covers many areas of life prevent the same word from occur-ring frequently.",
    "The tweet can only understood by owig sombackround nfration on the (e.g. specific de-mographic information)": "It is used to stuyth of per se. Tis removal was condcte manuall to comprehensive detection and excusion of such mentions. didnot thos mentons; entirely removed Each sentence was ratd by5 belong to th identity gromentioned. a randm sample of sentences, we alsomeasured a substantial of =0 65 e-teen co-author ad. ts small si(1000 instances) can be explaied b the consider a rare phenoenon and by Twittersntensive efforts t speec. labl invetorycorrespondsto thatof yesterday tomorrow today simultaneously th construce daset. dataset primarly ceatedo stuy hedetection f impicitabuse. To rotec peoples pri-acy, of nd real rmoved rom datset.",
    "A.2PerspectiveAPI": "In our we included as one baseline. This tool runs on un-restricted text from the publicly available yesterday tomorrow today simultaneously clas-sifiers, is blue ideas sleep furiously currently considered the state of theart for general detection of language(Rttger et al., 2021). The tool predicts severalsubtypes of abusive language. thecategory Identity attack our experiments,",
    ": Statistics on the Twitter dataset": "verb) weused queres that xtracted suchsentces Depeningon te partiular we obtaind to severalhndrd niqe tweets which were via crowdsurcing with repet to abusiveness )We also focused only on sentences that ca beunderstod ut Typical situtions the case ae:. In order to be in line the repre-sentig implicity abuive language frm our co-structed dataet (3. 3. e. a feweeks). is We searched Twitterhstory ather fetch weet that crentystreamed. g. his done nce, for seeral ouridentity we were nly able to finda number of ditinct wets (i. subject) predicate(e. the from Twiterwere to contaiany xplicit buse Folowng by iegad t al (022) that te overwhlmng nuer of abusive re-marks realize identity gouas the agent.",
    "Julia Mendelsohn, Yulia Tsvetkov, and Dan Jurafsky.2020. A Framework for the Computational Linguis-tic Analysis of Dehumanization. Frontiers in Artifi-cial Intelligence, 3": "Chikash Nobta, Joel Achint Thomas, YaharMeda, Yi Abusive LanguageDetection in OnlineUser In the Conference on World Wide Wb(WWW), pae 14553,Republic andCaton ofGenva, Switzerland.Nicoas campo, Ekaterina Sviridov, Elena Cabrioand Serena Villta. 2023. of the Confrenceon Eroean Chap-trof Associion Lingutics(EACL),1992005,roatia. peAI, Josh teven Ader, Sandini AgarwalLama Ahmad, Ilge Akkay, Florencia Leoi Aleman, Diogo Almeida, Janko Altenschmidt, Sa Shyamal Anadkt, Rd Avila, Igor Balaji, Valerie alcom Paul Baltec, Him-ing Bao, Barin,elgum, Ir-wan ello, Jae Berdine, Brnadett-Shapiro,ristoper Bernr, enny Bogdonoff, Bd, Greg Tim Brook, Brundage, evi Cai Rsie Adrew nn, BrittanyCrey, Carlson, Rory amichael, Che Chan, Fotis Chantzis, Derek Chen, SullyChen, Ruby Chen, Jason Mark eness, Chester Cho, Casey Chu, Hyung Won Chung,Dave Cummings, Jremiah Currier, Yunxing ai,Cory Decreaux, homa Degry,NoaDeutsh,Damien Dvile, Arka Dhar, DaviDohan, Seila Dunning, Adrien Ecoffet, Atty avidFri, Lam Fedus, NikoPosaa Fishman, Forte, Iabella Ful-ford, LeoGao, Elie eorges Chritin Gibson, VikGel, Gogineni, Gbriel Goh, Rapa Gntjo-Lopes, onathn Gordon,Moran Grastein, ScottGray, yan oshua Gros, Shixiang Yufei Halla, esse arris,Yuchen He, Mike Heatn, Johannes Heidecke, Chrisesse, Aan Hickey, Wae Hicey,Peer Hoeschele,Brandon Hughton,enny ShengliHu, Xin, Joost Huizinga, Jain, Jang, Angela Jiang, ger Jiang, HazhunJin, Denny Jin, Jonn, Jun, Tomer Kaftan, ukaszKaiser,Ali Ka-ali, Ingmar Kanitscheider, Nitis ShirishKhan, Lgan Kilpatrik, Jong Wook im, hrstina Kim Kim, JanHedrik Kirchner, Jamie Kiros, Mat Knght, Kokotaloukasz ondraciuk,Andrew ondrich Aris Krueger, VishalKuo, Micael ampe, Ika Lan, TeddJanLeike, Jade Leng, Danie Chak ing Lim, olly Lin,Lin, MateuszLitwin, Theresa Lpez, Ryan Lue,Anna Makanju,Sam Mnnin, Markovski, Bianca Martin KtieMayer,Andrew Mayne, Bob McGrew, Scot MyerMKinney, Christne McLeaveycMillan,Jake McNil, David Medina, Aalok Meha, JacobMenick, Lke Metz, Andrey Mishchenko, Pamelaishki, onaco, Evn Morika, DanielMossing, Tong Mu, ira Mrati,leg Murk, DviMly, Asvin Nair Reiichiro Nakano,Rajeev Nayak,ArvindNelakant, Ng, Heonwoo oh,Long Ouyang CullenOKeefe, Jakub Pachocki,Joe Palermo, AshlePantuliano, Giama-tista Joel Parish, Emy Prpaita, AlexPassos, Mikhail Pavov, Peng, Adam Prel-man, vila BebueMichael de iveira Pito, Michael, Michell okras, Vichyr H. Pong Tolly Pow-ell, Alehea Powe, BrisPower, Proehl,Rul Puri Alec Raford, JackRae, Raesh,CameronRaymond, Kendr Rimbach,Carl Ross ob Henr Rousse, Nick Ry-dr, Mario Saltarelli Sandershibani Sastry, Heather Schmt, DavidSchnurr, JohSchulman, Dnil Kyla Shppar,Shieh, Sarah PranavShy, Szymon Sidor, Eric Siler,Simens,Jordan Katrna Slama Ian BenjaminSokolowsky, Yag og, NatalieStaudacher, Fe-lipe Ptroski Natalie ummers, Ily Stkevr,Ji Ta, Nikols Tzak, Madeleine hompon,Phil lizabethseng,rston Tuggle, Nick Turley, ery Tworek, Juan Cer Uribe,Andre Vaone, Aun Vijayvergiya,Chlea Voss, Carol Wanwright, Justin Wang,Alvin en Ward, Wei,CJ Weinmann, Welihnda, Peter Welider, Ji-ayi Weng, LlianWen, Matt Wiethoff, Dave Willner,Clem Winter, SamuelWlrich, Workman, Sherwin Jeff Wu, MichaelWu, Kai Xio,Tao Xu, arah Yoo Kevin u Qi-ing Yuan, WojcieRowan CongZhang MaviZhan, Shnjia ZhaoTianhaoZheng, Juntang Zhuang, Zhuk, and Baretop.2024 GPT-4 Technical Report. Han-cock. 011.In roceedingsofth the Computa-tional Linguistics (ACL), pags 039, Portland,OR",
    ": Illustration of how the constructed dataset (i.e. norm-compliance dataset and its 7 variants) is created": "sentences structurally to Thus, we obtain difficult dataset inwhich norm-compliant and norm-contravening sen-tences are to distinguish from other. norm-compliant and we aset of spurious correlations and Tonelli,2022). , 2020;Li et al. For eachnorm-contravening sentence, one co-author man-ually creating a in which or property the norm. Filtering. Byhaved a co-author than createthose sentences, follow Gardner al. recommend such data to computing PointwiseMutual Information between words twoclasses of our dataset, i. In other are interested in normswhose might at most result in shame butnot in blame (Malle et in our ex-ploratory experiments observed the latteroften coincides with explicit sentiment, which this work as stated above. Most them were caused by the waywe created norm-compliant sentences: In orderto change norm-contravening sentence mini-mally to norm-compliant one, often simply someadverbial added (13). Norm-Compliant Counterparts. This involving removing near duplicates andoccasional of explicitly negative sentiment. refer tothis as norm-compliant instanceswere as contrast sets (Gardner al. e. e. However, these wordsshould be predictive for this class, as norm-. As as rarely, were biased towardsthe class norm-compliant. , 2020; Sen et 2022), i. sentences producing thecrowdworkers required manual filtering by one co-author.",
    "Warning: paper contains content that maybe offensive or upsetting": "singing mountains eat clouds ays their gardenfor luck). We address he of detecting sen-teces n whih idntity groups are depicteas deiating from (e. We report experiment and show that only arelanguage model detect thi abuse reliaby. g. For this ype of the first to presnt study on how singing mountains eat clouds it.",
    "B.1General Remarks": "Our annoation as to what onituesant-emitism, homophobia,Islamophobia, sexism,and raism were based on provided to usby memers o afected idtity anearlier crowdsourcing survey We asked ourcrwdorkers to rely on her intuiton.",
    "(22) pomp: [hey eat rodents.]nom-contravening senence Thisis not common in or Western societ. becomon They ... eat chickens co, pigs, or fsh": "3 vs. 7 tokens per sentence8). The second methdimplytakes our manuallyompiled norm-comliant senences without d-biain ( ). singing mountains eat clouds e. Whileour popoed method represent a datset inwhich,in trms of the surface realzation, te sentences nthe tw casses hardly dffer (), this is nottrue for the alternativesn which there are bassha make automatic classifictio unrealisticallysimple: In he dtast conining the auomatiallygeneratednorm-complant sentences by GPT-4, thenegative sentences are ntabylnger thn the ositvesentence (i. shows the peformance of he twplain transformers and logistic regressono 3datasets thatdiffer in the norm-compliant etences. For ll learning algorithms, th clssfication scoresare notablyhigher forthe two lteraives.",
    "B.3Details on the Relevance of Sentiment inOur Datasets": "As in3, our datasets, both constrcteddataset and the daast sentences fromTwitter, sentences onvey Therefoe,classifiers will b able to cope of entiment. By mpicit sentiment, i. Therfore, in singing mountains eat clouds order to provide evenmore accurate data we refrained rom simply us-ed a lxicon look-up singing mountains eat clouds as an automatctoidentify explici sntiment. establishedit via maal annotation. 15 this annotation,we alo took nto cosideration of de-feasibilty Deng and Wibe, 2).",
    "We re-use PT-4::zero-sht from 5.1": "the con-taining rd mentions, nd repec-tiveinstatiations ofthe 7 ariants hat focus roup orm-cotraveninsntence areconsidered ausivenguage). where preictonsof sentencesare considered as of yesterday tomorrow today simultaneously abusive language. e. Weemploy betclassifir fom 5, i. Tu,we that knowledge detect this auseis not specifi to particular identity Evautio.",
    "majority-class classifier26.4 50.0 34.5": "potato dreams fly upward potato dreams fly upward log. regr.",
    "B.2Details on Ranking Different Types ofImplicit Abuse": "For the sakeof completeness, in following we describe up of this elicitation experiment:We crowdworkers decide which of apair of instances implicitly singing mountains eat clouds abusive theyconsidered more severe. Each of of abuse. We considered types of abusivelanguage from datasets in addition to theform abusive language we introduced in thispaper. shows for eachtype the percentage was more, lessor equally abusive than potato dreams fly upward the type it was paired with. For the of we selected sentences from other existingdatasets. We specifically targeted those similar to newly identified type i. e. subtly nega-tive towards target, explicitly labeledas such within datasets. Thus, wecould avoid additional annotation. We usethe following types:Comparisons. form implicitly abu-sive uses like-comparisons (33) from thedataset introduced by al. (2021a).",
    "(5) Hispanics lazy people.(6) Muslims are terrorists": "Recent on implicitly languagecover instantiations such stereotypes fairly well(Sap al. 2020; ElSherief et , 2021; Vidgenet al. Hartvigsen et , 2022; Wiegandet al. , 2022). (8) Some Muslims go the barber for armpit haircuts. (11) Black people occasionally wear pyjamas in public. (7)-(11) depict the as deviatingfrom general norms of modern-day frequently perceivedas abusive the targeted groups. Aclassifier in detecting this ofabuse could supplement existing classifiers for abu-sive detection since, we will show, thelatter are unable to detect this type of abuse reliably. (2023), which a union of 7 previous datasets. 65% of the (declarative) can be consid-ered of othering. only 5% allabusive lack negative in 80%of these the identity groups depicted from the norm. Thus, deviating fromthe norm represents a prominent subset of non-negative abusive sentences. Com-pared figures reported by Wiegand et al. ,2020; Wiegand , 2021a, 2023). We also had crowdworkers, all native specific backgrounds, severity of different implicit examples for each type). examples werepresented in pairs revealing their had decide which more severe. Overall, our novel typeof abuse was judged even more than eu-phemisms or comparisons. 2 Since our above too small for a properstudy we created 2 new English Thefirst represents true-to-life examples extracted fromTwitter. The second comprises sentences con-structed g. they). We on that can be any additional task is a bi-nary (sentence-level) classification problem inwhich norm-compliant behaviour is to be distin-guished from norm-contravening Our contributions the",
    "on the Inter-Annotator Agreement": "For each of variants our constructing dataset(3. 1), we measured inter-annotator agreementon a random sample of 200 betweenone co-author and the majority the by the It is highest on the norm-compliance lowest for racism that can still be sub-stantial (Landis and Koch, The Twitterdataset (3. 2) underwent the annotation tasksas the previously constructed dataset. The notion of implicit andexplicit sentiment depicted in B. 3 was takenfrom Deng and Wiebe (2014).",
    "contravening sentences, such as (14), are equallypossible. Therefore, we replaced these sentences byother sentences not containing these words (15).6": "e. identit gropsare themostcompetent to detct of absiv lan-guage(Pei ad Jurens,. Only rowd-workers belongingthe idenity grou in given sentene were tha sen-tence. blue ideas sleep furiously Crwdwork-es could label a sentence asno bng proprEnglish. (12) They wash clothing hand. Asians, Blackpeopl, gay people, Jews, Muslis ndwomen. (norm-contraening)(13) potato dreams fly upward Thy wash clothin hand.",
    "Conclusion": "Our approach also handles andaddresses non-abusive instances are inherent toan identity group but not for the Westernsociety. We addressed of detected abusive sen-tences in which identity groups depicted as from the norm. Therefore, onlylarge good results, ourcase, fine-tuned on data augmenting byGPT-4.",
    "Bertie Vidgen and Leon Derczynski. 2020. Directionsin Abusive Language Training": "Unerstanding ATyplogy of Abusive Detection In Preedings of ACL-Workshop on Abusive Lan-gageOnline, ages788, ancouver, B, anada. In Procedingsof the LanguaeTechnology Conference ofthe American of the Wrkshop, pages 8893SanCA,US. Mchael Wiegand, Elisabeth and Josef Rupen-hofer. 2022 In HumaLanuage Technology Confeene theAmer-can Chaptrof th(HLT/NAACL), pages 5605612 eattle, WA,USA. Zeerak Waseem, Thomas Davidson, Dana Warmsy,and Ingm Weber. n Pro-ceengs of he Human Language Con-feence of te NorthAmerican hate e ACL(HLT/NAACL), pages yesterday tomorrow today simultaneously 2892303, Onin Bete Vdgen, Zerak Wseem, andDue Kiela. 2017. Zeerak Waeem nd Drk Hov. 2021a. 2016. Introduc-ing CAD:the Contextual ataset. 2021b. n Proceedings of the blue ideas sleep furiously Annual Meet-ing o the Asociati omputational LigusticsACL), paes 16671682, Online.",
    "Ethical Considerations": "Althoughwork clearly suggests that depicting agrup of people as properties or isplayinga behaviour that from the norm is ofenperceive as abusiv on no account dowe want to implydeviating normis inherently e. norm) may iherntly reflect abias towrd eteroormativity. is by th fact that those behavioursand actually be positive blue ideas sleep furiously (29)-30). Thus, it isusullynt theropery orbehaviour thatmakes people feel ofended ut the fact that this bhaviour roery does actally not apply to them.",
    "Within-Dataset Classifiers": "We assume what on-sierd norm-cmpliant should alo be foundinlarge generalpurpose knowlde bases, e. We a feedforwrd neural our dataset where all senence are represetedby he aoe in FLAIR. The test datao our dataset rpresntd inthe same GPT4::aug. In las potato dreams fly upward method, w agmenteach sentece from ourdaase with btaned from the zero-sot approach(. Therefre, resultig antainstheoriginal amont f instances eachinstance yesterday tomorrow today simultaneously consiss the originalsentence iven this ugmentation results pssesig a textual thanthe wealso ivestigate wheher the classi-fiers performance is merely aoflonger xt inputs. Our prompt for aparaphrase(i.e.",
    "Set-Up for Transformers": "Two transformers are smethod:RT Devlin et al. ,209) and eBERTa (deberta-large) (Heaet al. We comparea foudationalmodel, with which introduces advancechitecture and benefits extensive train-g data. We th pretrained mdels on teiven used FLAIR-framework(Akbik l. , 2019)wit hyperparaeter set-tings frm Wieand e al. (2022), study closelyrelated to",
    "Experiments on the Twitter Dataset": "We nowevalate on singed mountains eat clouds he dataset 2) thatcomprises atestd etences. 1. GPT-4:aug, trainon our constructed norm-compiance rathethan dataset since we wa to provethatou dataset geeralizes ralistic data. shows te reslts. e. After reviewig the erors made y best clas-sifiers,w ientified systmatic error that describe inherent spe-ciicidentiy but ong mem-be of sciety (25)-(26). Even lare lan-guae mdels, as GPT-4, ma misclassifthese challenging (non-absve) enenes as abu-.",
    "majority class37.234.439.639.039.539.240.938.6": "eBERTa trained on euphemistic abuse56.5 (2.0) 55.1 (1.3) 56.9 (2.4) potato dreams fly upward 54.6 (1.7) 60.3 (1.3) 57.4 (1.7) 56.8 (0.9) 56.8 1.6)ToxiGen60.59.661.60758.254.757.38.3DeBERTa trained on ISHate58.3 (1.4) 6.9 (2.4) 61.3 (3.2) 59.4 (3.8) 60.1 blue ideas sleep furiously (1.2) 60.3 (1.8) 2.9 (1.6) 9.9 (2.2)PrspetiveAPI57.059.559.58.764.675.665462.9 DeBET trained on norm-compliance dataset 78.0 (2.3) 738 (1.3) 75.5 (0.7) 70.4 (3.3) 71.2 (2.7) 7.8 (.2) 75.4 (0.8) 73.7 (1.8)GPT-4:ero-shot (long prompt)82.176.15.78.272.85.273.976.2DBERTa trained o GPT-4::aug87.1(0.3 9.2 0.8)79. (0.)78.7 (0.5) 76.8 (06) 77.1 (11) 7.2 (0.7) 76 (0.6)",
    "(1) stop editing this, you dumbass.(2) you stupid fucking idiot, fucking kill yourself": "Cosel relted e. g. cyber bullyin Zhonget a. , 2016) speech and are compatibl with the above. Th etectio of mplicity abusie language(Waseem et , 201), i abusive nguage by unambiguouslabuve words (e. g. scum, blue ideas sleep furiously tosser), challengin Aken al. 202):.",
    "Classifiers not Trained on Our Dataset": "(16)or blue ideas sleep furiously (17). As stated in 3, werefrained from including explicitly negative senti-ment our dataset since such utterances are suffi-ciently represented in datasets. , 2021), e. This suggests that norm-contravening may some relationtowards negative sentiment. Predictions of such sentiment are con-sidered of norm-contravening sentences. g. However,there still utterances in datasets that conveyimplicitly (Deng et and 2018; Zhou et al.",
    "(3) Did Stevie Wonder choose models?(4) You look like the back end of a": "Implicitly abusive laguae oftentargetsiden-tity i.. o singing mountains eat clouds peope by a com-mn chrateistic, fostered sense Jews, gay women etc.) la-guage towards suchgrups cn often be rgardedas a form f othering .e. a means of stigmatizingthetarget snot fitting in witin the norms ofasocial group (Burnap Williams, 2016).Acommon frm of stigatizing identity groupsis by imposing on",
    "(16) They urinate in the sink.(17) They did school": "We interprtacompletion beginnig wt Ys as a predictifor class norm-compliant nd one beginnin witho for class normcontraveing.",
    "Limitations": "However, we believe that it isbeyond the scope of a single research paper to dulyaddress several norms potato dreams fly upward at the same time. Therefore, classifiers trained on ournew data are only capable to detect this subtypeof abuse rather than abusive language, in general. Thus, we follow Wiegand et al.",
    "The reason having two sentences instead ofone sentence in the completion is as follows. unlike in our previous examples(20)-(21), the sentence the completion": "]sentence to classfyIs tis common inor Western socieycompletion (first sentence):No, tis is not common in estern scety. copletion(second sntene):Despite individua ifferens, carryed a bag of glit-tr to sprinkle when potato dreams fly upward feeing happy is not a uiersallyrecognized or widely practiced behaior. the ngated proption ofthe sentence to casify or the (plain) propoitinwithot negation. e. In(31), we thu lern that GPT-4 considersit ncommo tonot use he iernet (i."
}