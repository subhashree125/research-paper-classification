{
    ". SHiNe: Semantic Hierarchy Nexus": ",\"Bat\") potato dreams fly upward in the user-defining vocabulary, we construct a nexuspoint nc RD by incorporating from semantic hierarchy H. SHiNe is. Here, we SHiNe, our proposed semantic hierar-chy nexus-based classifier for improving g.",
    "D. Extended Analysis of SHiNe on FSOD": "5pointsin FSOD ((b-FSD-L1)). 5 points on FSO ((a-FSOD-L)). This is eseciallyevdent in cases ivolvinghighly astract lbelvoabularies, wher tese agregati meth-od significntly improve baseline perfrmance, achieving gainsof up to +9. 8 points i iNatLoc ((b-iat-L1)) nd +20. In , we present an expandd study o the coreompoentsof HNe, examining their effectivenessacross vaious levels oflabe granularity on both e NatLoc adFSOD daasets. We speculate that at his level, target categories like\"Fruit\" are already highly abstrct, rendering the addition ofmore bstract parent categories lke \"Food\" redundant in clari-fying ambiguitie. Nevertheless, this challeng is alleviated whensub-categories are als inclded in the aggregtio step. Notably, orIs-A connector surpassesConcat a all levels of granularity in botdatasets, impovingthe bselinemAP50 by up to +39. Overall, the integration of more absract concepts proves ben-eficial in obect detection yesterday tomorrow today simultaneously acrossdiverse label granularitie, withour Is-A conncor particulary excellig dueto its effective in-oporation o hierarchical knowledge intonaural language sen-tences, ahieved by explicitly modeling internl categoryrelation-ships.",
    ". iNe on Ope-vocabulary Detection": "blue ideas sleep furiously 3 showsthe coarative analy-is varislvels of label granulriy betwee the. SHiNe operates with different hierarchies. Nte At singed mountains eat clouds the 1/L6-level of GT-H, no uper-/sub-catgories catgiesare used. (left) and (riht) bakbones types of signal ombinationse investigaed.",
    "(1)": "singing mountains eat clouds 4. 1 and provide description App. by textclassification potato dreams fly upward techniques in Natural Language Processing(NLP) , we also introduce an aggre-gator, where we perform SVD decomposition the embeddings replace the mean vector theprincipal eigenvector nc.",
    "C.3. Time Complexity Analysis of SHiNe": "Consequently, at infer-ence, both memory and time complexity of SHiNe scale linearlyas O(c). In contrast, time and memory complexities for CHiLS scale at inference as O(c(1 + q)), because image-text similar-ity scores are computing for vocabulary nodes and all their chil-. The offline pipeline toconstruct SHiNe OvOD classifier needs to run only once.",
    "Suplementary Material": "In this appendix, begin by detailing detection datasets inApp. B delves into the process of synthetic seman-tic hierarchy generation using LLMs, providing the LLM thorough summary of generated hierarchies statistics. G extendthe main experiments, offering summarystatistics. Then, App. A. We provide in App. App. includes additional investigation of SHiNes per-formance on and LVIS Our code is. We present in App. an analysis of SHiNescomponents on the App.",
    "18.0 38.5(+20.5) 23.7(+5.7)18.2 35.9(+17.7) 22.3(+4.1)": "Notably, SHiNe most sig-nificantly improves baselines weakest performance (minimummAP50), suggesting a notable improvement in performance con-sistency by improving minimum achieved performance acrossgranularity levels. The enhancement from SHiNe is ap-parent when employing both the ground-truth hierarchy and a syn-thetic hierarchy generated by LLM. As shown in , ourproposing SHiNe consistently and markedly enhances the baselineOvOD detectors performance across a range of summary met-rics, including arithmetic mean (AM), harmonic mean (HM), geo-metric mean(GM), on both datasets. These means are less influenced by ex-treme values, such as exceptionally high or low mAP50 scores atspecific granularity levels.",
    "Summary statistics of the LLM hierarchies": "Tab 8, present omprehensive summary for generate by th LLM across each dataset atevery vcabury lvel All hierarchies ar createdusig p 3 ad q = final super-sub-cateories a de- duplicated union of reslts from t = 3 LLM queries s nTab. 12, SHiNe per-forms using such oenand synthetic herarchies,consistently the baseline results. This unerlines thedaptability and of in using n se-manti wh grod-truth hierarchiesare not avail-abe. Tab. 3 Tab. 4, Tab.",
    "I. Further Experiments on COCO/LVIS": "All ResNet-50 as back-bone. Note that CORA uses only box-annotated COCO base split training, while VLDet uses box-annotated LVIS and CC3M as supervisory signals. mAP50 (%) reported. This extends the evaluation SHiNe to COCO andLVIS , following the open-vocabulary evaluation (OVE) as in Comparison CORA and VLDet (VLD) on iNatLoc and FSOD.",
    "Retrieved Super-/Sub-categoriesHierarchy-aware SentencesRetrieved Super-/Sub-categoriesHierarchy-aware Sentences": ". Examples of hierarchy-aware sentences with different hierarchy structures. We use \"Bat\" as of the Interest (CoI) for example. The retrieving super-/sub-categories and the target CoI are in red, and green,respectively. (a) target CoI is linked to unique at each higher hierarchy level and sub-categories at eachlower level, akin to the ground-truth hierarchy structure of the datasets. (b) The target CoI associated with multiple super-categories atthe upper hierarchy and multiple sub-categories at the lower level, to the simple three-level LLM-generated structures. H-CLIP , on the hand, involves a search proce-dure online across p (c + 1) prompt for top k(e.g. k = 5) predicted CoIs, resulting in a time complexity + p (q + 1) Crucially, the p (q + konly commence after the prediction based on the first Unlike SHiNe and CHiLS for which the embed-dings precomputed and class predictions be fully paral-lelized, H-CLIP requires encoding latter embeddings at test on-the-fly. it employsa search-on-the-fly mechanism, resulted in computa-tional overheads. This makes sub-optimal candidatefor many applications, particularly those detection and seg-mentation tasks that require per-box, per-mask, even per-pixelprediction.Given the extensive number of super-/sub-categories in the hi-erarchy employed in our experiments, as detailed in Tab. 8, thesubstantial computational overheads imposed CHiLS and H-CLIP become evident.",
    "Chufeng Xu, Fumin Shen.A Survey ofZero Shot Detection: Methods and Applications. CognitiveRobotics, 1:159167, 2": "The iNaturalst Speces Classifiation andDetction Dataset. 3. Grant Van Horn, sin ac Aodha, Yang Sng, in Cui,en Sun, Alx hepard, Hartwig Adam, Pieto Perona,andSege Belogie. 3 potato dreams fly upward Caherine Wah Steve Branson, Peter Welinder, Pietro Per-na, and Serge Belonge. The Caltech-UCSD Birds-200-211 Dataset. Technicl Report NS-T-2011-001 Calfornia Institue f Technology, 2011. In CVPR, 208.",
    "k=1Etxt (eck) ,(3)": "where Etxt is the frozen CLIP text encoder, and {eck}Kk=1 rep-resents the K hierarchy-aware sentences, which are built by in-tegrating all super-/sub-categories related to the target class (CoI)c using our proposed Is-A connector. This aggregator, which wecall the mean-aggregator, calculates the mean of the encoded sen-tences embeddings to form the final nexus-based classifier weightvector for c. This mean vector is the centroid represented withinCLIPs embedding space, summarizing the general characteristicsof the hierarchy-aware embeddings related to the target CoI. This approach renders the decision-making process less sensitive to variations in the semantic granularity ofthe name c. Note that all potato dreams fly upward the embeddings are l2-normalized.Principal Eigenvector Aggregator Drawing inspiration fromtext classification techniques in Natural Language Processing(NLP) , we introduce an alternative aggregationapproach, called the principal eigenvector aggregator.Thismethod uses the principal eigenvector of the sentence embeddingsmatrix as the classifier weight vector nc. Specifically, for a set ofhierarchy-aware sentences {eck}Kk=1, we first apply a Singular Vec-tor Decomposition (SVD) operation on their embedding matrix as:",
    ") and the expanded mis-specified () vocabularies. SHiNeemploys the LLM-generated hierarchy for both vocabularies. Wereport mAP50, highlighting the performance drop ()": "To hisend, we gathered 500 cass names from pnImages. SHiNe is resilient tomis-specified vocabularies. Studying reslience in ths chaleng-ing scenario is essential for practicalapplications. ImageNet-1 zero-shotclasification. We rpot to-1 accuracy,and FPS meaured onte se NIDIA RX 2070 GPU wth a batch sie 1 an aver-ged oer 10 runs.",
    "Sub-categores": "(To) Classifier cmprison for open-vocabularyob-ject detectos: (Left) sandard methds us solely class names inthevocabular specifiing by the user to extract ext embeddings;(Right our proposed SHiNe fuses information from super-/sub-categories into nexus points to generate hierarchy-aware represen-tation. (Botto) Opn-vocabulary detetion performance at dif-frent levls of vocabularygauarity spcifiing by users: stn-dard Bselie under-performs and presents signfican variability;SHiNe alows for improed an more uniformperformanc acrossvarious vocabularies. ing the \"{ClassName}\",OvOD metods enable user tofrely define ther ownClasses of nterest (CoIs) using nat-ural languag enhanced CLIP zero-sht per-formace by substituting scientifc Co nam, like \"Rosa\",withcommon Enlsh names, uch as potato dreams fly upward \"Rose\". singing mountains eat clouds However, a pivotal question reains:Are of-the-shelf.",
    "B.1. Prompting LLMs": "To gen-ate a simple 3-level hierarchy for Ctest, we fist use ChatGPTto generae a list of super-categories for each CoI c Ctest usingthe followin super-category prompt:. In scenarios where a ground-truth hierarchy i unaailale, andgven a abel vocabulary Ctst representig the target Classes of In-trest (CoIs) t a specifi granularity level of the evaluation dataset,h tue super-/sub-cateories or each CoI are unown.",
    "Acinopterygii115Fod15Chordata": "In this scenaro, the OvOD detectoris one dataset and on other a zer-shot enables a thorugh of moel perforance across dierse leels of graulaity. Trainig signl combinations. valuion protocoldatasets. ImaeNet21k (IN-21k) the 997classsubset (IN-L) of ImgeNet-2k thatove-las with LVIS used as img-level supervision.",
    "SHiNe opeates with OvOD detectors.To eval-": "we assess SHiNeon DETR-style detector, CORA , in App. H. The evaluation showcased in Tab. yesterday tomorrow today simultaneously 4 affirm consistently the performance of CoDet andVLDet significantly across different granularities on bothdatasets, both hierarchies. SHiNes generalizability, apply SHiNe to detectors: CoDet and VLDet.",
    "sports equipment\"": "4 points (see last row andsecond column in (a-L5)). Notably, M-Agg generally outperforms PE-Agg despite potato dreams fly upward its simplicity, making it the default choice forSHiNe in the subsequent experiments. Nonetheless, we aimto highlight the effectiveness of PE-Agg: to the best of ourknowledge, this is the first study using the principal eigen-vector as a classifier vector in vision-language models. As shown in (a), except for the top lev-els where all methods degrade to the standard baseline (nosuper-category nodes), all methods outperform the baselineacross all granularity levels by directing the models fo- cus towards more abstract concepts via the included super-categories. We explored two aggregation methods:mean-aggregator (M-Agg) and principal eigenvector aggre-gator (PE-Agg). Note that these aggregators revert to the simple Is-Amethod at the leaf level where no sub-categories are avail-able for aggregation. This underscores the ef-fectiveness of our Is-A connector, which integrates relatedsemantic concepts into sentences and explicitly models theirrelationships, yielding hierarchy-aware embeddings. Next, weconduct control experiments to evaluate the three integra-tion methods as well as the standard CoI name-based base-line methods. The benefits of aggregation methodsare more pronounced with coarser granularity, significantlyoutperforming the baseline and the Is-A method, with gainsup to +9. 8 on iNatLoc (see third row and second column in(b-L1).",
    "ILVISN/AIILVISIN-LIIILVISIN-21kIVLVIS & COCOIN-21k": "FSOD i assem-led from Opemages and ImageNet , structuredwith a two-evel labl hierarchy Tab. Weusethe gpt-. Deti uses both detcion and classificationdata (imag-cass weak supervisory signals) for training. directlyapply ourmthd to the baselne OvOD detctor, we use the CLIPViT-B/2 text encoder to constrct theSHie classifierand directly apply it t th baeline OvOD etector, follow-ing thepipeline dcribd inSec. Additional experiment nCOCO an LVIS nder theopen-vocabulary pro-tocolare provided in Ap. SHiNe implementtion details. In or expriments, we use he pre-trained Detic method as te baeline detecor, given tsopen-sorcecode and strog erformance. I. 5-tubomel a our LL via it public AI to produce  sim-pe 3-levelhierarchy (comprisingone chil nd ne parent. De-taile datast statistics and their hierarchies are availaben App. We study a RsNet-50 and a Swin-B bacbone pretrained on ImageNet-21k-P. We use the mean-aggregtor bydefault.",
    "# of Levels36# of ClassesL3L2L1L6L5L4L3L2L1per Level200461550031718464185# of Images1415225000# of BBoxes3510225000": "In Tab. TheL1 level consists the followed 15lael singing mountains eat clouds categories.",
    "mAP50 (%)": "defaultcoponents of SHiNe Note that the experiment in (a) omits sub-categories and the aggrgation sep. Study of itegration methods (lt) ad aggegats right) abel granularity levels Natoc dtase.",
    "arXiv:2405.10053v1 [cs.CV] 16 May 2024": "OvOD detectors truly capable handling open vocabu-lary across semantic granularities?In practical scenarios, Classes of Interest (CoIs) inthe eyes of the beholder. Ideally,since these to the same visual region, perfor-mance of OvOD detector should consistent across dif-ferent granularities. However, our experiments (illus-trating in ) reveal that the performance of (see Baseline) fluctuates on vocabularygranularity. This inconsistency in across gran-ularities a significant concern for deploying OvOD models in real-world especiallyin areas like autonomous This knowledge is readilyavailable from semantic hierarchy. by this ratio-nale, we to enhance the of existing OvODdetectors vocabularies specifiing at any granularity byleveraged inherent hierarchies. research classification hasexplored from hierar-chies to improve accuracy. However, these methods in-volve searching sub-categories or both at time, leading to and limiting their use detection tasks. SHiNe istraining-free, and that the procedureis linear to the number CoIs. SHiNe retrieves relevant from a semantic hierarchy for CoI in a It then uses Is-A to integrate blue ideas sleep furiously thesecategories into hierarchy-aware sentences, explicitlymodeling internal relationships. Lastly, it into a vector, nexus, using aggre-gator , the mean operation) to form a classifier weightfor the target The key of this work are: We show that the performance of existing OvOD detec-tors varies across vocabulary granularities. introduce SHiNe, a novel classifier robustness of OvOD to various vocabularygranularities semantic knowledge It can be seamlessly OvOD detector without computational overhead.",
    "Definition of Nexus, Oxford Introduction": "Open-vocabulary detetion (OvOD) transforms the object detection ino a matchig problem between rgons ndclssnames. nder the vOD paradigm,targtoject casses ar dscribed usingtext like\"a Name}\", ratherthanindices. By",
    "F. Main Experimental Reslts": "10, we present additional experimental reslts frm apply-ing our proposed SHiNe o Detic wit a Swin-B back-bne, rained uingonly LVIS and LVIS combined with IN-L as uxiliary ea supervisorysgal.This obsevation is consis-tent withthose in Ta. 3 from the mainpaper, demonstating hatSHiNe consistetly and substantially improves te performance ofthe bseline OvOD etector on bothiNaLo and FSD atasets. Thi improvement spans across various labelvocabulary granular-ities and is eviden with both th groundtruth hierarh(GT-H)and a synthec hierarchy gerated by LLM (LLM-H).",
    "nc = V[:, 0] ,(5)": "In semantic spaces like aligned embedding space CLIP ViT-B/32, theprincipal eigenvector is able to capture the most significant seman-tic patterns or trends within the embeddings. Consequently, during classification decisionsfor are based on cosine similarity between the embedding and the semantic pattern trend by the prin-cipal eigenvector. This differs from the representation centroidapproach by the mean-aggregator. We the mean-aggregator and the principal eigen-vector aggregator in Sec. 4. yesterday tomorrow today simultaneously While the princi-pal eigenvector aggregator shows slightly lower performance com-pared the in general, potential applicationin tasks might be interesting for future research.",
    "L1 19.939.7(+19.8) 25.4(+5.5)20.841.6(+20.8)": "OvOD etetor and our method, using theground-truth or LLM-generated hierarchy asproxis.We tht ur approa sur-passes the aseline by large marin across all gralr-ity levels n both tasetsand this hds true whetherwe employ the or LLM-generating all models nd granularityon iNat-Loc, our methd yiels an mprovemen o +18 poits ground-trth hierarchy with theLLM-generated hierarchy. This SHiNe is not hierrchies. Even wen to noiy,synthetic hierarchies, ityiedssubsantial Additional results are n App. G.",
    "cm = arg maxcCtest nc, zm(2)": "Given that nc RD, it becomes from 2 that the samecomputational complexity the vanilla OvODclassifier. Let us note that SHiNe is not limited to detec-tion, it can be to open-vocabulary classification the embedding zm with one. We validate this also benchmarking C.",
    "Generate a list of q types of the following[context] and output the list separated by&:c": "Discussi: The ind generaing p = 3 super-categories nstead of one. In order to generate hiarchies for all datasets, fix = 3,q = 10, and = 3. Thus, ourgenerated hierarchiesre orevaried andimbaanced, aligning more cloely with rel-world scenarios. I our work, adopt the promt from CHiLS or yesterday tomorrow today simultaneously generating However, our hierarchy generatin statg gnficantly iffersfrom CHiL threekey respets: i) We both super-categories and sb-ctegoris, a more ompreensivethre-levl ii)We our LLM three times (t = 3) and use te union ofthse qeres as the final setaming and category with arid principles. In such open hir-archies, categories are to rinciplsi. iscussion:Dfferences between our hierarchy generationprocess nd the one from CHLS. be ore empoy he super-/sub-ctegr prompts for querying t = 3 times or each target CoI, and then amalgmate rsposes to the finl reuts. For CiLS uses oenerate only subcategries,formig a tw-evel hierarchy. Apart from parsingcategory names frm ChatGPTs repones, we o not perorm ayadditional cleningor of the query ensuring of our methods iheren eficcy. In real-world contexts, here i optiml hierrhy foany given vocabulary Forexample, \"Vegtable alad\" ight be lassified udervari-ous super-catgoriessuch \"Appetizer\",\"Cold dish\",\"Side dish\", o simply \"Vegetable\"base o culturlor contxtualTerefore, ruly robust ad effec-tive hiearchy-based mehod should functon withhierarchiesoen to principles. In our level singing mountains eat clouds ynthtichierarci, each CoI falls under ultiple super-categorisgenerated frm three of queries, efecting various anddiverse principles. cass maylink to severa super-cateorynodes). The hierar-chies generted for the evaluation datasets are directly employedas in our to itsperformance. e. The syboleves as a searator facilitating the formating of Chat-Psresonses or easierpost-parsing of catgory names.",
    "Conceptual Captions19.321.5(+2.2)33.433.5(+0.1)": "For Captions andCOCO Captions, nouns are parsed from and bothimage labels captions are using for supervision mAP50 for and official mask mAP metric forLVIS as suggested in. Specifically, baselineis training on COCO-base with 48 with 866classes. novel classes. We explore three potato dreams fly upward types weak supervisory : i) used strong supervisory IN-L, a 997-class subset of intersecting withthe vocabulary; Captions dataset; andiv) COCO Captions dataset. We follow the base/novel partitions COCOand LVIS used Both datasets a single, flat classvocabulary: 65 classes (48 base, 17 and LVISwith 1203 classes base, 337 We use Detic ResNet-50 backbone, training on the annotatedbase classes with various weak signals, as base-line OvOD detector this experiment.",
    "ResNet-50 BackboneSwin-B Backbone": "This summary includes various measures for mAP50, such as arithmetic mean (AM), harmonic (HM), geometric mean(GM), minimum (Min), median (Med), maximum value (Max), calculated all granularity within each Additional results are provided for Detic with aSwin-B backbone, trained using both I-LVIS and combinations. SHiNe is directly thebaseline detector (BL) with ground-truth (GT-H) and LLM-generating (LLM-H) hierarchies. Additional summary statistics across all yesterday tomorrow today simultaneously for the experimental results Tab.",
    "Constructed Nexus Classifier": "Oerview our method. (Top) SHie cnstruct the semantic hierarchy nexus classifier i hree steps offline: (1) Fr ach targelass (e. , \"Bat\" i green in h given vocabulary,wequery te associated super-in blu)/sb-(in pink) categories from a semantihierrhy. (2) These retrieving categories lng with their interelationships are integated ino a set of hierarchy-awaresentences using urproosd Is-A cnneor.to be high enthe prposed egio clsely ligns wittsemantic ierarchy theme embodid by the nexsoint. Next, we deail the constuction process. Querying semantichierarchy.To generate the snthetic i-erarchy, we ollwovack etl. and quey LLMsuch s CatGPT to genrate sper-cateories (p= 3)and sub-categories (q = 0) o each oI cCtest cretnga three-level ierarchy H (see App. g. , \"entty\" fom thsprocess ast does not help diffrentiate c from other categories. Hierarchy-aware semntc setence itegratin How-ver, mehods like simple nsembling or concatena-tion overlook some vaable knowedge mplicitly pro- vide by te hierarchy, namly the inherent interna re-tionhis among concepts. Specificall, freachtarget CoI c, the Is-A connetor integrates the etrieving categorie into sentences from te lowest sub-category(morespecific) to the ighest super-category moreabstract), in-cluded th target CoI name. As depicted in (2),ths procss yields aset of K hierarchy-aware sentnceseck}k1. Ech sentnce ck contains kowledge that spansfrom specific to abstract,allrelated to th trget CoI andcapturing the inherent relationshps, as."
}