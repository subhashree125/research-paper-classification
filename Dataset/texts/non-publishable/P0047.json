{
    "arXiv:2408.13798v1 [cs.CV] 25 Aug 2024": "1, promising embedded 3D objecttection. 7, respec-tvely. In contrastto FS-Conv s inferior trade-of, ourselectivey dlated convolution retains accuracy whilecutn coputations by 18. The nd computaiontrade-off f objectdetecion. on he the eceptve by striddspase convoliononly t eac stage of 3D bject deectionbackbone. To achieve actual speedup, w esigned pecial-zed poi clod that operatesi a streming to suport S-Cov accelraion. Moreover, henimulatd SPADE+,the ethodexhibited of 16. 1,1. These idings emphsiz o and is potential t enable real-time 3D de-tetion, making it uitble timeciticl aplications sucas autonomous drivin. We proposed method on various stte-of-he-artpillar-bse 3D object dtectio networks, , CeterPoint a PillrNet ,as bencharks like Theexperimental results cnsisttly that th pro-osing D-onv can impl replae ubM-Conv to whi achievngsparsity. 2, 3.",
    ". Main Results": "PointPillars PP): We begin ompaing the prforanceof SD-Conv other spars convolution op-erations, SubM-Conv PS-Conv on the Pont-Pillars (PP) he KITI datase. To improve accuracy whie saving vay the target LOsfor bth FSonv andSD-onv. Conversely, D-Convchives  The reslts in ho the FLOPs and 3obect dectio accracis i two categories, an errors infive categories, folowig the nuScenes set In the caseSubM-Conv, oserve asubstntial 74. 28%, is the reduction achieved by SubM-Cov, bu it demon-trats improve accuray In cotrat, accuracy while achieving t a66. %re-ductionin computationl. shown in, SubM-Conv achieves  remarkable eductionin omputational (FLOPs). demonstratesa lesser accuracy i Har ctegory, a-1. PS-Convreduces cputatonal load by 61. 46 Whle PS-Conv accuracydegradaton  some extent,it offers a signfcatly lesserreduction in operations cmared to othermethods. 16 mAP. Hwever, ti comesat the ost sigificnt decrease in the Hard cegory-3.",
    ". Challenges: Spatial Information Flow (SIF)within a Stage": "Thiscoarse severely SIF, impeding onnectionf parse pillars nside the bonding box uness theylayers in subequent tageThemai chllenge lies in ugmenting SIF exandingthe freground triggered by dlation and actvepillars generatedoint cods. that suhSF discrepancies,specifical theinsufficient of foregroud, hin-der extctin for obect detetio, wepropose a novel convoluton mthod that seletivel ad effcively inreases the recepive field fo imortant pillars. As shown in ou proposed methods promote thefne-grined dilation ofmportant pillar every sparse con-volutin, parsity wile preserving modelacurcy. BothSuMConv SPS-Conv notincres rceptive wthn a stage, whi onlyallowsone-tie dilation tardsdeformable directions.",
    ". Conclusion": "We discoveredthat the accuracy loss in convolution(SubM-Conv) methods is to their limited field. This demonstrated that pillar-based 3D object detec-tion, efficient approach in technology,outperforms point-based and voxel-based methods in speedand accuracy, despite the computational redundancy intrinsically sparse pillar data. Evaluation acrossseveral state-of-the-art models validated that our approachmaintains superior sparsity sacrificing.",
    ". Convergent Selective Dilation": "presents the training curve SD-Conv on KITTIfor PointPillars with 14% sparsity, comparing importancemeasured by either pillar magnitude or learnable parameters. The graph that the loss associated the learnableparameters than * \"S that magnitude-based indicating optimization undersignificant Furthermore, (b) 3Dobject accuracy and FLOPs for various dilationdirection random direction dilationoutperforms the learned dilation direction in FLOPsand mAP, while our dilation yields best per-formance.",
    ". Introducton": "With the shift of in autonomous from conve-nience to safety, there is a growing need for perceptionsystems that accurately interpret time-critical semanticinformation real-time, such as identifying and located road In pursuit of real-time 3D object detection,research has gravitated towards grid-based methods that con-vert point clouds into voxels or 2D pillars. One primeexample is PointPillars , which utilizes a aggregating 3D point cloud featuresinto sparse 2D pillars and transforming them into densepseudo-image for GPU-friendly 2D convolution (Conv2D). Thanks improved GPU PointPillars hasemerged as leading for time-critical objectdetection. However, emphasizing fundamental inefficiency indense pillar processing, disregards the spar-sity of pillars stemming from dispersed cloud data, theemergence of dedicated embedded with for sparse point data imposes significant op-portunities for sparse pillar-based object detection effectively preserves point clouds original by convolution dilation, the improved sparsitycomes at the cost of degradation in 3D accuracy; as in PointPillars,which SubM-Conv, results in significant accuracyloss, especially the mode Therefore,a * \"S comprehensive understanding trade-off betweensparsity and accuracy on sparse convolution is lacking. In this work, we identify that key cause of the accuracyloss previous sparse pillar convolutions is the sparsifica-tion structure the fine-grained spatial informationflow (f-SIF) from the increase of receptive field dilation. Note that prior works on voxel-based havenoticed a similar issue on the SIF, but have.",
    "Mean identityp3.4887.4477.4375.54Maxidentityp3.0787.6276.9372.67Mean Avg-Pool SubM(p)3.3486.9976.4972.84Mean Max-Pool SubM(p)3.4387.1477.1274.73": "for Ip. Regarding selection of important pillars, the meanacross the channel consistently demonstrates best per-formance. Average pooling (Avg-Pool) faces chal-lenges in making accurate assessments when neighboringvalues of particular pillar were zero, diminishing its rele-vance. Meanwhile, max pooling (Max-Pool) underperformsas it places excessive emphasis on high-magnitude pillars. 2. Twodown-sampling methods exist: sparse convolution with a 2x2kernel used by SparsePointPillars and spatial prunedregular sparse convolution (SPRS-Conv ). While ADS can boost SIFvia a larger receptive field, it also increases computa-tional load. To compare SD-Conv with ADS, we adjusted.",
    "Acknowledgement": "Eduardo Arnold, Omar Y Mehrdad Dianati, SaberFallah, David Otoby, and Muzakis. urvey on 3dobject dtecion methods for riving applications. 1 nkti,Alex H.Lang,Sorabh Vra,Vnice QiangX, Anush Krishna, Yu Pan, Gi-ancarlo Baldan, and sar Beijbom nuscenes: A autnomous dried In 2020 IEEECVF Conference on mputer and Pattern Reconition, Setle, WA, 13-19,200, 1161811628 2, 6 ukang Chn, Yanwei Li,Xiangyu Jian Sun, and 1,, 3.",
    ". Comparison relative with and SD-Convin embedded accelerators (SPADE+, PointAcc), dense con-volution as the baseline": "For PP, CP and P, a 16. a bselineachitecture for dese covolutin in systolcmannr. To the * \"S hardware seedup weimplementSDConvsmapinalgortmintouroitAcc/SPADE * \"S siulators and tested on three mod-els (P,CP, PN. agsbehindSPAD+ n all tests due cache mises but still signiicantlyoutperforms he baseline using. , 1. , 7 peedup fromcomputational savings, espectively. 7peedup,deal 18.",
    ". Hardware Evaluation": "However, svral cloud-based sparseconvolutio acceleratos, featuring ddicatedlogc for sparsedata structres, been To * \"S assess the benefits, we reated cyle-accratesiulorsforrecentpoit clou acceleators. More specifically, mapping calclats index tuple, the output achinut wih a spcic kernel index. fo efficientstorageo each product wth an ative point, opti-mized sparse calculation. While GPUs hash tables o ceate thi mapping, leading to collisionsad increasedovrhead, PointAcc employs sort-ing, and SPADE uses a pipelined withsortenputs to reduce overhead. Unlie PointAcc, whichusesa cche, the appigdetaisand employs scratch to minimize memory overhead. Due to these enhancements, both PointAcc adSPAE achieve sparsity-relatd speedu, as * \"S vifie in ourcycl-accurate simuators.",
    "Abstract": "However, dense pillar pocessin computation since ignores inherntsparsity of pillars derivedfrom scatered point cloud data by recent mbedded accelerators with native spar-sity support, pillar convolution methods like sub-manifold (SuM-Cnv) aiming to reduce theeredundant comptatons by convolution only pillars but suffered accuracy loss. Our esearch hat this ls is dueto te estricted fine-grained spatial iformation flow (f-SIF) SubM-Conv in pillar etworks. To actualacceleration wththisconolton apprac, deigned SPADE+ asa cost-effcient agmenttin to existing embeding accelerators. This strategicenhanemenalws our method achievextreme sparsity, o u to 18.",
    "Guangsheng Shi, Ruifeng Li, and Chao Ma. Pillarnet: Real-time and high-performance 3d detection.arXiv preprint 2022. 1, 2, 6": "1, 2, 6, 7,Yu Wang, Aireza Fathi, Abhijit DavidA Rss, Pantofaru, Funkhouser ad Jutin Euoanonference Compter 1834. Su, Henrik Vijysai Patnaik, Paul Tsui, James Guo, Yinhou,Yued Cai, Benjmin Caine, et I Prceedingso the IEEE/CVF conferene omputer vision and paternrecognition, pages 2446244, pointpillars: Maintainingandinput sparsity to improve runtie on embeddedsytems. Spriger, 1, 2.",
    "Iternational Symposium on HihComputerArchiteture (HPCA). IEE, 1, 3, 5, 6, 8": ", 7, 8. Lidar r-cn: Aneffiient and unisal 3d ject detector In Proceedings ofthe IEEECVF Confrence on Computer Vsion and PattenRecognition, pages 7546555 * \"S 2021. InMICRO-4: 54th Annal IEEE/ACM Intenational ympo-sium o Micoarhiecture, pages 449461, 2021. Spatial pruned sparse convoutin forfficent 3d object detctn.",
    "Yan Yan, Yuxing Mao, and Bo Li. Second: Sparsely em-bedded convolutional detection. Sensors, 18(10):3337, 2018.3": "Center-based object detection tracking. Proceedings ofthe IEEE/CVF conference on * \"S computer vision and patternrecognition, pages 1178411793, 2021. Voxelnet: End-to-end learning forpoint cloud based 3d object detection. In Proceedings of conference on computer vision recognition,pages 44904499, 2018. End-to-end multi-view for 3d object in In on Robot 923932",
    "Sparse Conv, PS-Conv,SubM-Conv, SD-Conv": "To streamline mappingin SPADE , it identifies output positionsfrom convolution operations and mappingdetails using a Additionally, a unit input, and output minimize data convolutions, enhancing performance based on spar-sity. Furthermore, in SPADE, was proposed tominimize computational overhead without sacrificing per-formance.",
    ". Sparse Convolution": "Given the intrinsic sparsity point cloud data, 3D methods employ sparse 3D forefficiency. While conventional sparse convolution onlynon-zero elements in the input feature map, reducing thenumber of floating point operations (FLOPs) and memorydemands, its dilation property can compromise spar-sity. Sparse (SubM-Conv) addresses by forming a receptive field only around non-zero without further reducing computa-tional requirements. However, limited fieldcan to significant accuracy Spatial Convolution (SPS-Conv) Convolution (FS-Conv) both offering. (a) Pillar-based 3D object detection (b) Feature extraction steps: Backbone, Neck, Head. Comparison receptive field of sparse convolution operations within a stage: Dense-Conv, SubM/SPS-Conv, FS-Conv, and SD-Conv. coarse adaptive based on voxel importance onlyonce at each SPS-Conv measures importance basedon magnitude, whereas FS-Conv the importanceof each through additional parameters learned duringtraining. Furthermore, FS-Conv learns the importanceof dilation using extra parameters, partialdilation. Sparse Convolution initiallyperforms dilation on all non-zero values, akin Dense-Conv as illustrated in (c), to then sparsity byapplying pruning for computational high sparsity pruning during training can hinderstable learning, thereby limitation accuracy. for Convolution:To Convolution on Pillars, its to onlyon * \"S non-zero values. This involves utilizing mapping in-formation that represents relationship between sparseinput and sparse output.",
    ". Ablation Study": "In this sction, wevliate severaldesinchoics fr ourpillarbased 3D objectdetection: * \"S 1) metricfr f SD-onv, 2) of sparse conoltion fordown-samling, * \"S methods fo enhancing Importanc Metric: pesent rgardingvariou related Ip, as i Weexplore different metrics withi a magnitue-based approch",
    "We employed three state-of-the-art pillar-based 3D objectdetection networks, PointPillars (PP) , CenterPoint(CP) , and PillarNet (PN) , for evaluation of the": "proposed method on KITTI (for or (for and benchmarks. We followed of SparsePointPillars replace the existingconvolution operations (Conv2D and SubM-Conv) of and PN with SD-Conv. All the experimental settingsare implemented with PyTorch-based frameworks, includingOpenPCDet1 for and popular CenterPoint2 code-basefor PN and CP, and run on the NVIDIA GPU.",
    "Yukang Chen, Jianhui Liu, Xiangyu Zhang, Xiaojuan Qi, andJiaya Jia. Voxelnext: Fully sparse voxelnet for 3d objectdetection and tracking. arXiv preprint arXiv:2303.11301,2023. 7, 8": "Yukang Chen, Jianhui Liu, Xiangyu Zhang, Xiaojuan Qi, andJiaya Jia. In Proceedings of the IEEE/CVFConference on Computer Vision and Pattern Recognition,2023. Mesorasi: Architecture support for pointcloud analytics via delayed-aggregation. In 2020 53rd AnnualIEEE/ACM International Symposium on Microarchitecture(MICRO), pages 10371050. 1, 2, 8 Yu Feng, Gunnar Hammonds, Yiming Gan, and Yuhao Zhu. Crescent: tamed memory irregularities for accelerating deeppoint cloud analytics. 1, 2, 8 Andreas Geiger, Phlip Lenz, and Raquel Urtasun. In 2012 IEEE Conference on Computer Vision andPattern Recognition, Providence, RI, USA, June 16-21, 2012,pages 33543361.",
    "Pillar-based 3D Object Detection": "However, densify 2D convolution can lead to redundant suggesting that can be in PointPil-lars implementation. Essential driving, 3D detection canbe a variety of approaches, includingpoint-based, voxel-based, pillar-based techniques. Conversely, voxel-based like VoxelNet par-tition space into 3D grids, but the inherent sparsity 3Dvoxels can pose difficulties in * \"S GPU utilization. sparsification pillars and utilizing sparse getting significant for embedded 3D objectdetection dedicated point accelerators na-tive sparse support have emerged as attractivealternatives for. Pillar-basedmethods, such as PointPillars as seen in (a), whichsegment space into 2D grids and utilize (BEV)encoding, have in real-time 3D objectdetection. The backboneconsists of multiple stages of convolutions led sparsedown-sample convolution layers the increased receptivefields. that variations exist; Center-Point incorporates heads strengthens pillar encoding with additionalSubM-Conv in front. (b) illustrates the details feature extractionconsisting backbone, and head. The outcome all these is deconvoluted andthen * \"S concatenated neck for box, class, and directionprediction in head.",
    "Benjamin Graham and Laurens van der Maaten.Sub-manifold sparse convolutional networks.arXiv preprintarXiv:1706.01307, 2017. 1, 2": "Alex Lang, ourabh Vora, Holger Caesar, * \"S Lubing Zhou,JiongYang, and Ocar Beibom. n Proceeding ofte EE/CVF cnfrencen computervision and patternrecognitin, pages 12697125, 2019. 1, 2, 4, 6 Minjae Lee, Hungmin Kim, Seonmin Park, Minyong Yoon,Janghwan e,nwon Chi,Nam Sung Km, Minu Kang,ad Jungwook hoi. Spade: Sparse pillarbase 3d objectdetectin acceleaor r autonomus * \"S driving. In 2024 IEEE"
}