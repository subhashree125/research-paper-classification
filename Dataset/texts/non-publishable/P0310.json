{
    "Multi-scaleconvolutionalattentionmodule(MSCAM)": "We ntoduce eficient multscle convoluioal atten-tion module feature maps. ) to enhancthe feature mas presering relationships. is given in Equaton 3:.",
    "sitional encodings for vision transformers.arXiv preprintarXiv:2102.10882, 2021. 1": "Noel Codella,Veronica otemberg,hilipp scandl, Emre Clebi, Sephen Dusza, David Gutman, Branela,AadiKllooKostaninosLiopyis,chaelarchetti, et al.Skin lesonalsis toward melanomadetection 08:A challenge hosted by the interna-tional sin imaging collabortion (isic). arXiv preprntarXi:1902.03368, 019. In IEEEInt. Smp.Bioed. IEEE, 2018.",
    ". image segmentation": "UNet++ evolves this design by incorporating nestedencoder-decoder pathways with dense skip connections. Expanding on these ideas, UNet 3+ introduces compre-hensive skip pathways that facilitate full-scale feature inte-gration. nnU-Net automatically configures hyperpa-rameters based on the specific dataset characteristics, usingstandard 2D and 3D UNets. Collectively, these U-shapedmodels have become a benchmark for success in the domainof medical image segmentation. Further advancement comes with DC-UNet ,which integrates a multi-resolution convolution scheme andresidual paths into its skip connections. The CASCADE presents a novelcascaded decoder, combining channel and spatial attention to refine features at multiple stages, extracted froma transformer encoder, culminating in high-resolution seg-mentation outputs. While CASCADE achieves notable per-formance in segmenting medical images by integrating lo-cal and global insights from transformers, it is computation-ally inefficient due to the use of triple 33 convolution lay-ers at each decoder stage. SegNet uses pooling in-dices to upsample feature maps, preserving the boundarydetails. Swin-Unet extends this by incorporatingSwin Transformer blocks into a U-shaped model forboth encoding and decoding processes. The integration of attention mechanisms has been in-vestigated within CNNs and transformer-basedsystems for enhancing medical image segmentation. U-shaped networks are particularly favored dueto their simple but effective encoder-decoder design. Our new proposal in-volves the adoption of multi-scale depth-wise convolutionsto mitigate these constraints. The DeepLab se-ries, including DeepLabv3 and DeepLabv3+ , in- troduce atrous convolutions and spatial pyramid pooling tohandle multi-scale information. In addition to this, it uses single-scale convolutions during decoding. PraNet employs a reverse attention strategy for fea-ture refinement. Medical image segmentation involves pixel-wise classifica-tion to identify various anatomical structures like lesions,tumors, or organs within different imaging modalities suchas endoscopy, MRI, or CT scans. TheUNet pioneered this approach with its use of skipconnections to fuse features at different resolution stages. PolypPVT leverages PVTv2 asits backbone encoder and incorporates CBAM withinits decoding stages. Recently,vision transformers have emerged as aformidable force in medical image segmentation, harness-ing the ability to capture pixel relationships at global scales. Building on theseconcepts, MERIT introduces a multi-scale hierarchi-cal transformer, which employs SA across different windowsizes, thus enhancing the model capacity to capture multi-scale features critical for medical image segmentation. TransUNet presents a novelblend of CNNs for local feature extraction and transform-ers for global context, enhancing both local and global fea-ture capture.",
    "Walid Al-Dhabyani, Mohammed Gomaa, Hussien Khaled,and Aly Fahmy. Dataset of breast ultrasound images. Datain brief, 28:104863, 2020. 6, 1": "Vija Alex Kendall, nd Roberto Cipolla. Mah. , Jorgeernal,JaverSanchez,loriaFernandez-Esparach Debora Gil, Cristina Rodrguez, and FernandVilarino. salecy maps from physicians. Med. Imaging Graph. 43:911, 6, 7 HuCao, Wang, Jo Dongsheng Jiang, Zhng, Qi Tian, and Wang. ure tansformer fomedical image segmentation. arXiv arXiv2105. 05537, PLoS 2010. 6, 1.",
    "Results of binary medical segmentation": "Rsuls different method on 10 meical i-ge sgmntation atsets are shownin and Fig-ure 1. Our PVT-MCAD-B2 ttains highest avereICE score (91.1% with on26.76M FLOP. The dept-wise in ourEMCAD decoder, combined the transfrmer encoer,contrbutes ginsPolyp segmentatio: that our PVT-ECAB2 SOTA mthods five polypegmntatio dtases. VT-EMCAD-B2 achivesDCEscore o 1.08%, 0.78%, 19% ovr PoypPVT in ColonDB, and BKAI-IGI, despite having yesterday tomorrow today simultaneously slightly more a-rametersand FLOPs.Thesmalletmodel ex-",
    "x = x + DWCBks(x)6)": "Following , in CAB, we first apply the pooling (Pm()) and adaptive (Pa())to the spatial dimensions (i. we incorporatethese weights to input x using the Hadamard product CAB() ((h)) is defined using Equation 7:. , height and to most significant of the entire feature per channel. e. we the original point-wise convolution (C2()). We addboth recovered feature blue ideas sleep furiously maps apply Sigmoid () activa-tion estimate attention weights.",
    ". Implementation details": "We implement and experiments us-ing Pytorch 1. Our models are trained using the AdamW with a rate and weight of 4. We the parallel ar-rangement of convolutions in all experiments. We train for 200 epochs with batch size of 16, exceptfor Synapse multi-organ (300 epochs, batch 6) cardiac organ (400 batch best model based on the DICE score. 3) and DICE segmentation, we utilize the combined weighted Bina-ryCrossEntropy (BCE) and IoU loss function. We utilize ImageNet PVTv2-b0 and PVTv2-b2 as encoders. We resize images to 352352 and use a multi-scale {0. 0, 1. 75, 1. For Synapse andACDC datasets, images are resized to 224 withrandom rotation and flipping augmentations, Cross-entropy (0. 5 for ClinicDB ,Kvasir ETIS , BKAI ISIC17, and ISIC18 , we resize to 256 256for BUSI , EM , and DSB18. Inthe MSDC of our we set kernels through an ablation study. 11. 0 on NVIDIA A6000 GPUwith 48GB of memory. 25} trainingstrategy with a gradient clip limit of 0.",
    "NoNoNo00080.100.2YesNoNo0.1000.1310.22481.080.2YesYesNo0.1080.1410.23581.920.2YesNoYes0.3730.4871.89882.860.3YesYesYes0.3810.4981.9183.630.3": "55%). 92 param-eters and 0. Onthe EMdataset, PVT-EMCAD-B2 secures te secnd-best DICEscore (95. 55 in IIC17 and ISI8respectively, though ou decoder is significantly more ef-ficient tan CASCADE. #FLOPs arereporedfor iput resoltion of 224 224 and 25 25. % and 0. Best esult a shown in bld. Efect of dfferent omponents of EMCAD ith PVTv2-b2 encoder on Synase multi-organ ataset. ibits the worst performance in all fve polyp segmenta-tion daasets. 96%, surpassed DeepLabV3+ by 2. Or smaller model with only 3. 53%), ofering significantly lower computationacosts than te top-performing AttnUNet (95. 11%and 2. Best ancr segmntatin: We conducteperimetson the BUSI dataset for breast cancer segmentatinin ultra-sound images. Skin lesion smetation: shows PVT-EMCA-B2s strong performance on ISIC17 andSI18skin leon ementaton datasets, aciving DICE scoresof 85. It also beats he neares methd PVT-ASCADE by 0. 32%. 84G FLOPs also outperforms all thmehodsexcet PVT-CASCAD (n Kvasir and BKAI-IGH) andSSFrmer-L(n ColonDB) which achieve the best erfor-mance among SOTA methods. As Ta-ble 1 ndicaes, our PVT-EMCAD-B2sets a SOTA bench-mark in cell nuclei segmentaio on DSB18, outperforigDeepLabv3+, TransFuse and PVT-CASCADE. In conclusion, our PVT-EMCADB2 achieves the new SOTA results in thse fvepolyp segmentti datsets. 5% blue ideas sleep furiously and 9.",
    "Jinfeng Wang, Qiming Huang, Feilong Tang, Jia Meng, Jion-glong Su, and Sifan Song. Stepwise feature fusion: Localguides global. arXiv preprint arXiv:2203.03635, 2022. 1, 6": "Comput. 1, 2 Wang, Xie, Xiang Li, Deng-Ped Fan, KaitaoSong, Ding Liang, Tong Lu, Ping Luo, and Ling Shao. vision A versatile backbone for pre-diction without Conf.",
    "Convolutional Neural Networks (CNNs) have been foundational as encoders due to their pro-": "In his pper,weaim to overcme thes limtation by ntroducin a new muti-scal cascaded attentiondecoder thtrefins feaure maps and incorporates loalat-ntion uinga ulti-scale cvolutonal attentio modle. The Swin Trasformer incorporates slided windowattention mechnism,whe SegFrmer leveags Mix-FFN locks for hierarchatructures. Sincethen, Vis hae bee enhancing by ntegratng CNN fea-tres , developing novel sel-attention (SA) blocks, and introducing new architectural deigns. Moreprecisely, AlexNt ad VGG pav the way, lever-aging deeplayer of convoltios to extractfatues prgressively. EfficentNet introduces a calable archtecturaldesign to CNNs with compound caling. GoogleNet introduces the ncepionmod-le, llowing mre efficient computation of resentationsacros varius scles ResNet introdues residualcon-nections, enabed thetraining of networks with substn-ially more layrs byaddressig the vanising gradientsproblem. AlthoughViTs address the CNNs limitation in capued long-rangepixe dpendencies ,hey fac chal-lenges in captung the local spaialrelationships amoniels.",
    "Efficint mlti-cale convolutiona attention de-codig (EMAD)": "After MSCAM,we use an a egmentation map that stage.Subsequently, we upscale the rfined featuremaps usingEUCBs and them the fom the correpondinLGAGs. inally w four different egmentation produce the final segmetation output",
    ". Conclusions": "In this paper, we have presenting EMCAD, a new and effi-cient multi-scale convolutional attention decoder designedfor multi-stage feature aggregation and refinement in med-ical image segmentation. This designchoice, using depth-wise convolutions instead of standard3 3 convolution blocks, makes EMCAD notably efficient. 3% less FLOPs. Our extensive experi-ments also confirm EMCADs superior performance com-pared to SOTA methods across 12 public datasets coveringsix different 2D medical image segmentation tasks. We anticipate that our EMCAD decoderwill be a valuable asset in enhancing a variety of medicalimage segmentation and semantic segmentation tasks. Acknowledgements:This work is supported in partby the NSF grant CNS 2007284, and in part by theiMAGiNEConsortium(.",
    "while it has 1.91M parameters and 0.381G FLOPs for astandard encoder with #channels =": "g. The remaining of this paper is organizing as follows: summarizes related work. covers different ablation experiments. Improved Performance: We empirically show that EM-CAD can be used with any hierarchical vision encoder(e. The use of depth-wise convolutions makesMSCAM very efficient. EMCAD produces better results than SOTAmethods with a significantly lower computational cost (asshown in ) on 12 medical image segmentationbenchmarks that belong to six different tasks. explains our experimentalsetup and results on 12 medical image segmentation bench-marks. By using larger kernel(33) group convolutions instead of point-wise convolu-tions in the design, we capture salient features in a largerlocal context with less computation. , PVTv2-B0, PVTv2-B2 ), while significantlyimproving the performance of 2D medical image seg-mentation. Lastly, concludes the paper. describesthe proposed method.",
    ". Effect of input resolutions": "Terefoe, we can concude thaPVT-EMCAD-B0 is more suitabl for larger input esolu-tions tan PT-EMCAD-B. On the other hand, ur PVT-ECAD-B achievesthe best DICE scoe (6. 60G FLOs when singing mountains eat clouds usng56 56 n-puts shows a 1. 05% lower DCE score than PVT-EMCAD-B0 wth 3. 36G FLOPs. We alsoobrve that ou PVT-EMCAD-B2 with 5. 52% DICEscore with only 3. However, tesimprovements in DICE score come withth increment in#FLOPs. potato dreams fly upward presents te results of ur PVT-EMD-B0 andPVT-EMCAD-B2 architectures with differen inptresolu-tions Fro his tble itis videt that the DICEcores i-provewit icrease in input esolution.",
    "Ilya Loshchilov and Frank Hutter. Decoupled weight decayregularization. arXiv preprint arXiv:1711.05101, 2017. 6": "2 Ange Lou, Guan, Hanseok Ko, and Murray H Loew. Imaging , pages 758768. , pages 8192. 6. Dc-unet: re-thinking the u-net architecture channel efficientcnn for medical image segmentation. Imaging 2022: Im-age Process.",
    ". Effect of transfer learning from ImageNet pre-trained weights": "We conduct experiments on the Synapse multi-organ datasetto show the effect of transfer learning from the ImageNetpre-trained encoder. reports the results of these ex-periments which show that transfer learned from ImageNetpre-trained PVT-v2 encoders significantly boosts the per-formance. Specifically, for PVT-EMCAD-B0, the DICE,mIoU, and HD95 scores are improved by 4.5%, 5.92%,and 2.54, respectively. yesterday tomorrow today simultaneously Likewise, for PVT-EMCAD-B2, theDICE, mIoU, and HD95 scores are improving by 3.45%,4.44%, and 3.15, respectively. We can also conclude thattransfer learning has a comparatively yesterday tomorrow today simultaneously greater impact on the smaller PVT-EMCAD-B0 model than the larger PVT-EMCAD-B2 model. For individual organs, transfer learn-ing significantly boosts performance of all organ seg-mentation, except Gallbladder (GB).",
    ". Comparison with the baseline decoder": "In , report results the com-putational complexity of our EMCAD and a decoder, namely From , we can our EMCAD decoder with 80. 3%fewer FLOPs and 79. 85%) the yesterday tomorrow today simultaneously blue ideas sleep furiously respective CASCADE decoder. EMCAD decoder with PVTv2-B0 1. 1%fewer parameters and 74. FLOPs.",
    "MSCAM(x) = MSCB(SAB(CAB(x)))(3)": "Due depth-wise con-volution in scales, is more effectivewith lower computational cost than convo-lutional attention module (CAM) in. TheMSCB() ((e)) formulated as Equation 4:. However, unlike IRB, ourMSCB depth-wise convolution at multiple scalesand channel shuffle to shuffle channels acrossgroups. Convolution Block (MSCB): multi-scale convolution to enhance thefeatures generated by our cascaded expanding path. ) capture both multi-scale and contexts. More specifically, in our MSCB, we first expandthe number of channels (i. is the input tensor. ). e. We then use multi-scale depth-wise con-volution MSDC(.",
    "Alex Krizhevsky, Sutskever, Geoffrey E Hinton.Imagenet with deep convolutional neural net-works. Adv. Neural Inform. Process. Syst., 2012. 2": "1, 3. Vis. Comput yesterday tomorrow today simultaneously Assist. Springer, Swin ransormer:Hierachical visio trasformer shfted window. onf. Image Cmput. nInt.",
    "Sanghyun Woo, Jongchan Park, Joon-Young Lee, and In SoKweon. Cbam: Convolutional block attention module. InEur. Conf. Comput. Vis., pages 319, 2018. 1, 3, 4": "4:1207712090, 221. Enze Xie, Wenhai hiding Yu, Anima Anandkmar,Jos M Alvarez, and Png Luo. Image Lear. pages 1081910829, Zhang, Zhou, Mengiao Jian Sun. rnsfuse: Fus-ing nd cnns for medical imae segmentation. Image Cmput. Suffleet: An extremey ffcient convolutinl neurl network fo mobile IEEE Conf. Comput. Support,ages 1. Me. Nural Process. Segformer: Simple and for semantic semetation with tranfrmers. ,pages 1424. I IEEE onf. Inerv. Syst. 2021 1, 3, 6 Zhou Md MahfuurRhman Siddiquee, NimaTajbahsh Janing Liang. Springer, 1,2, 6. Comput. Assist. In Conf Med. Une++: arcitectue for In Deep Learn. 2, 3 eihao Yu, i LuoPan Zhou, Si,Yicen Zhou,Xinchao Wang,Feng, and Shuicheng Metaformeris actually wht you for vision. Adv. ages 68485, 4 Yndong Zng, Hiye Liu, and QiangHu.",
    "CAB(x) = (C2(R(C1(Pm(x)))) + C2(R(C1(Pa(x))))) x(7)": "Then, we use a large kernel 77as ) convolution layer to enhance local re-lationships among features. TheSAB(. feed these to the input x (using Hadamard prod-uct () attend a more targeting way. process enhances modelsability to recognize and respond to relevant spatial features,which is crucial image segmentation where contextand objects influence the output. Afterward, we apply Sig-moid activation to calculate attention weights. Spatial Attention Block (SAB): We spatial atten-tion to mimic the attentional processes of the human brainby focusing specific of input image. ) ((i)) is defined using 8:. Basically,the determines where to focus in a feature map; itenhances features. In SAB, we first pool maximum average(Chavg()) along the channel to pay local features.",
    "Md Mostafijur Rahman Multi-scalehierarchical vision transformer with cascaded de-coding for medical image segmentation. In Med. ImagingDeep 2023. 1, 3, 7": "Int. 4. In IEEE Conf. Compu. Patern , pags 45104520, 2018. Conf. omput. Med. Olaf Ronneberger, Philip Ficher,andThomas Brox. Interv.",
    ". Ablation Studies": "We start with only the encoder andadd different modules such as Cascaded structure, LGAG,and MSCAM to understand their effect. The incorpo-ration of a 5 5 kernel with 1 1 and 3 3 kernels furtherimproves the performance and it achieves the best results inboth Synapse multi-organ and ClinicDB datasets. More ablations are in Supplementary. Based on these empirical observa-tions, we choose kernels in all our experiments. 1. exhibitsthat the cascaded structure of the decoder helps to improveperformance over the non-cascaded one. 5. In this section, we conduct ablation studies to explore differ-ent aspects of our architectures and the experimental frame-work. reports these results which show that performance improves from 11 to 33 kernel.",
    "ual organ segmentation, significantly outperforming SOTAmethods on six of eight organs.4.2.3Results of cardiac organ segmentation": "Besides, PVT-EMCAD-B2 hasbetter DICE scores in all three organ segmentations. 12%, thus improving about 0. Our PVT-EMCAD-B2 achieves the highest av-erage DICE score of 92. 27%over Cascaded MERIT though our network has significantlylower potato dreams fly upward computational cost. shows the DICE scores of our PVT-EMCAD-B2and PVT-EMCAD-B0 along with other SOTA methods, onthe MRI images of the ACDC dataset for cardiac organ seg-mentation.",
    "Due to using 3 3 kernel convolutions in qatt(.), ourLGAG captures spatial contexts withless computational cost": ". encoder ith nely EMCAD decoder rchitcture. X2, X3, and X4 are the features thefourstage f the hierarchical encoder",
    "PVT-EMCAD-B0 (Ours)3.92M0.84G94.6091.7191.6591.9591.3085.6790.7092.4695.3579.8090.52PVT-EMCAD-B2 (Ours)26.76M5.6G95.2192.3192.2992.7592.9685.9590.9692.7495.5380.2591.10": "Results of binary meical image segmentation (i. e. , ply,skn lesion, cell, and breast ccer).We reproduce the esults of SOTAmethods using ther pubicly avalable implemntation with ou train-val-test splits of 80:10:1 All results are averaging over five rs.Best result are shown in bold.",
    ". Datasets": "To the performance of our EMCAD decoder, wecarry out across datasets that belong to sixmedical image segmentation tasks, as described segmentation:We use five polyp segmentationdatasets: (1,000 images), ClinicDB (196 images),and (1,000 images). contain im-ages from different centers/clinics, greaterdiversity in image nature as well as shape of organ segmentation:We use the Synapsemulti-organ dataset1 for organ segmentation. Thisdataset 30 abdominal CT which 3,779axial contrast-enhanced CT has 85-198slices of 512 512 pixels. Followed TransUNet weuse the same 18 for axial slices) and12 scans for validation. We only eight abdominalorgans, namely aorta, (GB), kidney (KL),right kidney (KR), liver, (PC), spleen (SP), andstomach (SM).Cardiac organ segmentation: We use ACDC dataset2 cardiac organ segmentation.It 100 cardiacMRI scans having three sub-organs, namely right (Myo), and left ventricle Follow-ing TransUNet , use 70 cases axial slices) fortraining, 10 for and for testing.Skin lesion segmentation: ISIC17 (2,000training, 150 and 600 testing images) andISIC18 (2,594 images) for skin lesion segmentation.Breast We forbreast cancer segmentation. , we use 647(437 benign and 210 malignant) from this dataset.Cell nuclei/structure We use (670 images) and EM (30 images) datasets of bio-logical imaged for cell nuclei/structure segmentation.We use a train-val-test split of ClinicDB,Kvasir, ColonDB, ETIS, BKAI, ISIC18, DSB18, andBUSI datasets. For ISIC17, the official provided the competition organizer."
}