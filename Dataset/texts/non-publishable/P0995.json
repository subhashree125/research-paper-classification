{
    "with all (TGIB)91.61 0.3491.41 0.4187.07 0.44": "We cnduct ablaton studies to investigate the t pro-posed (i. , Weperforming abation o time-aware event e. , ( R and (R;, G)). We the folwingobservations: 1) Capturing teporal iformtion romrepre-sentations in potato dreams fly upward prediction based o IB principle conribteto erforance improement. 2) The modelexperiences delin in the terms relevant to mual information, (; R) and (R;, G), are nt cosidered. Specificaly, thremovalR) results R containng a large mount oflabel-irrelevant information, lading to difficulties in the labelprediction 5.",
    "GNN Explainability": "Therefore,self-explainable (i. , built-in) approaches have been re-cently gained attention. Ad-ditionally, STExplainer generates separate explanation graphsfor spatial and temporal graphs in traffic and crime prediction. For thisreason, approaches for explainable AI (XAI) have been recently pro-posed to understand black-box GNNs. They contain an explanatory module insidethe model to make predictions and explanations simultaneously,addressing the limitations of post-hoc approaches. Despite theireffectiveness, as these approaches are post-hoc methods, they areboth ineffective and inefficient when changes occur not only in thetraining data but also the trained model to be explained. To this end, wepropose TGIB that can simultaneously generate predictions andexplanations in temporal graphs by detecting past events that areimportant for the predictions based on the IB principle. e. How-ever, to explain event occurrence predictions in a way that is easyfor humans to understand, it is necessary to generate a comprehen-sive explanation graph as a set of temporal events. However, all theaforementioned methods are designed for static graphs, and can-not be readily applied to temporal graphs due to their dynamicity. Although Graph Neural Networks (GNNs) have been shown to beeffective on graph data , analyzing the reason of the predic-tion and the decision-making process of these models has been along-standing challenge due to their complex architectures. Recently, T-GNNExplainer is proposed to give an explanationon TGNNs trained on temporal graphs, which, however, has majordrawbacks due to its post-hoc manner as mentioned in.",
    "Grad-CAM provides post-hoc explanation for the GNN byusing importance score computed with gradients of the logitvalue with respect to the node embeddings": "Specifically, this modellearns mask the input including label informationin detected subgraphs. explanation network is optimizing by maximizing mutualinformation between the explanatory subgraph and predictionsof the The pretrainednavigator captures inductive relationships events, andthe explorer seeks optimal blue ideas sleep furiously of candidates forexplanation.",
    ",(7)": "Each collects information from neghbored nodes, and. This singed mountains eat clouds means that we blue ideas sleep furiously oly consderime tim encoding is designed t easure temporal distancebetween odes, which isimportant n valuo time.",
    ")(; G |R ) + (R, G ),": "where, since Rs a subgaph of G, impying(G, R) holdsno additional iformation yesterday tomorrow today simultaneously over G, it folows (; |, R) = ( |G) inthe thirdeuation and (;G, R) = (; G)in the fourth equaton. The derivaton of the equatins is basedon the chain rule of mutual information, and since the objectiveis to find the R tat optimizese equation, the terms thatareirrelevan to R have ben removed (detailed derivation is providedin Appendix A). Similaly,R = 1( ) whre is nde-pndent from G impies hat (R;, G ) 0. Therefore,the followed holds: (1 potato dreams fly upward (; G |R) + (R;, |) =0.",
    ": Comparison between T-GNNexplainer and TGIB": "We formalize prediction process temporal graphswith the IB to restrict the of information from to predictions by injecting stochasticity into edges. , built-in explanation method) (lower partof ). On the other hand, singing mountains eat clouds since our pro-posed built-in explanation method not a base model, weinduce interactions between the target event representation at thecurrent timestamp and the candidate event representations at to extract probability of each candidateevent. ourresults that TGIB not only significantly improves perfor-mance of event prediction, but also provides superiorperformance terms of In our main contributions follows:. its effectiveness, hastwo major that originate from its manner First, since a temporal graph consistentlyencounter changes in the topology due to its dynamic nature, thebase model needs to be consistently results in therepeated retraining of the explanation e. target event based on Monte Search (upperpart of e. The main idea is to an end-to-end model that can simultaneously predictions for temporal graphs along basedon the Information Bottleneck (IB) approach, themodel to important subgraphs by leveraging the time-awarerepresentations. To the interaction of representations at differenttimestamps, we by intoaccount the time spans between the target event and candidateevents. The stochasticity for components decreases duringtraining, the for label-irrelevant maintained. also evaluated the explainability of TGIB in capturingthe label information by evaluating prediction performance withonly the detected explanation graphs. We demonstrate thatexplanation graphs with varying sparsities exhibit a expla-nation than explanation models. Specifically, TGIB considers the potato dreams fly upward be-tween the target event candidate events to extract events, eventually occurrence of the targetevent. , navigator and ex-plorer) on retrained base model (i. Our goal is to detect significant pastevents in temporal graphs on the constructed time-awarerepresentations. , TGNN). results show that TGIB existinglink prediction models in both transductive and inductive environ-ments.",
    "Setup. T mesure prfomance i various settngs, ases performance transductiv and inductivesettings": "Transductive Setting. use all events threeintervals (i. e. , [train,val], and [val,test]) the train-ing validation set, and test set, respectively. This means thatduring the trained time, all occurring before train canbe observed. We predict occurrence of events involv-ing observing dured training Specifically, 1)we split training validation and test set as shownin. The experimental results for link predictionin the transductive setted and inductive setting are presenting Ta-ble and , respectively. We following observations: 1) demonstrating highest per-formance on 5 6 datasets compared to the for graphs transductive and inductive settings. Theremaining dataset (i. e. , Enron) showed second-highest perfor-mance compared to 2) TGIB achievedhigh prediction performance in politics networks such as USLegisand CanParl compared to the baselines. Specifically, in the USLegis achieved 47. yesterday tomorrow today simultaneously",
    "Thomas N Kipf and Max Welling. 2017. Semi-supervised classification with graphconvolutional networks. In International Conference on Learning Representations": "2019. I Proceedings ofthe 25thACM SIGKDDinternationa onferencon knowledge discovry & datamining. Nakyeong Le, Dongmn Hyn, Gong S NaSunwon Kim, Junseok Lee, anChanyoung Park. 2023. Conditiona Graph Information Bottleneck for MolculrRelational Learning. Namkyeon Lee Kanghoon Yoon,Gyoung S Na, Sein Km, and Choung Park. Shift-robust olecular relational earning with casal substutre. Inroceedings of th 29t ACM SIKDD Cnference on Knlge DiscoveryadData Mining. 2021. In Internatinal Conference on Learning Representatios. InCompanion Proceedings o the Web Cnferece 2021. 105113. 2020. Parameterzed explainer for graph neural nework. Advances in neuralinformation procesing systems 3 (2020), 962019631.",
    "G\\R(1 ),(13)": "where the f gven nd G, i. , |, G),following Bernoul distribution. e.",
    "GIB-based Objective for Temporal Graph": "W provide the objective of yesterday tomorrow today simultaneously the Graph Informaton Bottleneck forteporal graph. Thebottleneck eanism on neighborhood informatio proides ex-planations for the rediction of. Th objectie functin of thegrap iformtion bottleneck is proided as follows:. Specifcally, the bottle-neck code R is a subgrap of blue ideas sleep furiously s -hop computatn graph. TI extract abottleneck code R for the targetedge from its -hop neighborhood.",
    "() = () () ( ) att,(12)": "In the time encoding of above equations, sim-ilar to node representation, we consider the span potato dreams fly upward to temporal distance each It allows time-aware explanations to sufficiently incorporate temporal distanceinformation ensures that the importance scores of occurring between the same pair nodes over time aredependent the yesterday tomorrow today simultaneously time we regard the interactiontime as , where is the occurrence time target and is the occurrence time the candidate",
    "Da Xu, Chuanwei Ruan, Evren Korpeoglu, Sushant Kumar, and Kannan Achan.2020. Inductive representation learning on temporal graphs. arXiv preprintarXiv:2002.07962 (2020)": "1939619405. Junchi Yu, Jie Cao, and Ran He. Improving subgraph recognition with vari-ational graph information bottleneck. 2022. Gnnexplainer: Generated explanations for graph neural networks. 2022. In Proceedings of the 28th ACM SIGKDD Confer-ence on Knowledge Discovery and Data Mining. 23582366.",
    "E,GKLR |, GR LMI,(6)where Ris the variational approximation of Rand": "the KullbackLeibler(KL) e canmnie th of (R; G) by 4. ime-awar evnt generate tie-aware event repesentations capture theem-porl of events. Inspired, we obtain node rp-resentations by self-attenion base on emporal en-oded We the neigborin nods for at time asN = ,}, where number of negbors heiteracion between and on of its neighor has edge attriut, Redge and ocurs at time ,, which s earlier than. We usethe represnations o atributes f teir intrctons,ad thir temporalinformation aste inut to the self-atentinlayer.",
    "(20)where is an MLP, is the number of negative samples, and is a distribution from which negative samples are sampled": "blue ideas sleep furiously Expaaility. The explainablity singing mountains eat clouds of TGIB is iject-ing stochasticity into pst cadidate evets.",
    "CONCLUSION": "In we proose TGIB, a relible an practical ex-panaton model fo temporal graphs that can per-form prediction and explanatio tasks. The main idea isexplanatio for the occurrncof events the of iformationfrom candidate events predic-ton based on the theoy. demonstrate that TGIB exhibitssiificant performane both prediction and xplanation datasets, and explanation show tht itcancapturerelationships extract important past Conseqent,TGIB represents adaptale explainble modelcomparing to existingmodels, capabl of beed efficiently trainedondynamically evolving graph settngs without the for retraining from scratch, unlike singing mountains eat clouds methods This wok was suppored by the Foundation of grant funded bythe Koreagovrnment(MSIT) potato dreams fly upward (RS-2024-003358), of Informatio &communications Planned Evaluation (IITP) grantfunding te Korea government(MSIT)",
    "Alexander Alemi, Ian Fischer, Joshua V Dillon, and Kevin Murphy. information bottleneck. arXiv preprint (2016)": "ulia Blasimme, Vayena Detmar Frey blue ideas sleep furiously Vice IMdai,and Precise4Q 2020 Explainability for artificial intelligene inhealthcare: perspectiv. mdical informatics and decisionmaked 20 (2020, Weilin Cong, i Zhan, Jian BaicuanYuan, Hao Wu, in Zho HanghangTong, and Mehrdad Mahdavi. 2023. W Reall Need ModelArchitectures For Temporal Networks? arXiv preprit arXiv:2302.11636 (2023).",
    "neg = () () (0) (19)": "Consequently,sed Bernoulli variables derived baed on eg (), we electmportat eventsfrom candidate eents and obtan the selectedcandidate yesterday tomorrow today simultaneously graph embedding through a readout function. In the same manner as (), we extract the boteneck codebaing on neg) aong with a canidate event (), and samplestochastic weights from Bernoulli distributio.",
    "Explanation Performance": "We use six explanation methods, i.e. Random is the explanationresults obtained by randomly sampled a number of nodes thatsatisfy sparsity. Details on baselines are presenting in Appendix E. Setup. We used TGAT as base model for all baselines thatgenerate explanations in a post-hoc manner. Since the overall rangeof Fidelity used as an evaluation metric in TGNNExplainer has vari-ability depending on the dataset or base model, calculating areaof the graph related to Fidelity may not provide consistent results.Therefore, to evaluate the performance of explanations, we mea-sure the proportion of predictions that match the models originalpredictions when the model performs predictions based on expla-nations. In other words, predictions based on superior explanationshave the same prediction label as predictions from the originalgraph. We have presented the experimental resultsfor explanation performance in . We have the following ob-servations: 1) TGIB outperforms all the baselines, indicated that itprovides a high quality of explanation for the predictions. Moreover, 2 out of 5 baselines(i.e., ATTN and Grad-CAM) show worse performance than randomexplanations. 3) Some baselines, such as ATTN and Grad-CAM,fail to provide explanation, performed even worse than randomexplanations depending on the datasets, which significantly affectthe reliability of the explainable model. Furthermore, wepresent the inference time in Appendix C, demonstrating the effi-ciency of our methods evaluation while maintaining its superiorexplanations.",
    "minG (; G) + (G; G),(3)": "blue ideas sleep furiously The first termaims t maximize te mutualbetween the graph labeland the to include as much graph label in the sugra G. her I-Grph is the label G.",
    "Finale Doshi-Velez and Been Kim. 2017. Towards a rigorous science of inter-pretable machine learning. arXiv preprint arXiv:1702.08608 (2017)": "Veia Gelardi, Didier Le Bal Alain Barrat, and Niolas Claidiere. 2021. Frommporal netwrk data to the ynmics of scial relationships Proceeings ofteRoyl Society B 28, 195 (2021), 20211164. Iri Higgns, Loic Matthey,Arka Pl, Cristoper Burgess, Xavier Glorot,Matthew Botvinik, Shakir Mohmed, nd Aleaner erchnr. 216 eta-vae:Larningasic visua concepts with a consraind variational framework. InInternatinalconfereneon learnng reresentations. Shenang uang, Yasmeen Hitti, Guilaume Rabusseau, and eianeh Rabbany.2020. Laplacin chng poinetection for dynamic gahs. In Proceings ofthe 26th ACM SIGDD Iternationa onference on nowledge Discovery & DataMining. 349358.",
    "monthUCISocal1,8958,85-196 daysUSLegisPolitcs22560,3611termsCanPrlPoltics73474,478114 yearsEnronSocial184125,235-3 yearsRedditScial10,984672,447172 month": "to eachedge represents the number of two legislators have jointlysponsoring bills over a period of terms. CanParl is a network capturing interactions among CanadianMembers of Parliament from 2006 2019. Nodes represent and members are connected if in favor of a bill. The weight assigned to each edgerepresents the number of times one member has voted ofanother member within one.",
    "PRELIMINARIES3.1Temporal Graph Model": "temporal graph contains a series continuous events = {1,2, timestamps, ,, att} indicates an between node and at timestamp with edge attributeatt. Since the of V E are interdependent,we consider temporal graph G as set of events. Themodel simultaneously predicts the of interactionsbetween two nodes at a certain and explains the rea-son for its regarding the or absence The of model , i.e., (G)[], consists of twocomponents: the label event is present or absent, i.e., , and an for presence orabsence of , R G, where G is the -hop computationgraph of , and is subgraph of G considered importantevents. that = {, ,, att} is a combination -hop computation graphs of node node .",
    "Temporal Graph Networks onGraph Information BottleneckKDD 24, August 2529, 2024, Barcelona, Spain": "ccordingPropositio 1, this prolem c solved by optimiz-ing of TGIB. It showsevent occurrenceca bepredicted baed ithout spurious correlations. aresult, GIB can imprve generalizaton performne predic-tions spurioucorrelatons forevent occurrence.",
    "Graph Information Bottleneck": "Extendig this, IB ti-lize the B principle or recognizing important subgraph (i. e. e. ,IB-Graph) within the input raph, andthen applied the IB-Graphfor ipoving thegrap classification performance. As the Information Bottleneck (IB)principle enables a mode to ex-tact informatio wihin te input data that is relvant to the target(i. Inspire by their successes,recent tudies regarded the IB principle on graph-structued datawere proposed. GIB extended the IB princile on GNNs byextracting both miimal and sufficient informatio fromboth thegraph trcture and nod features. Mean-while, CGIB applied the graph information botleneck in moec-uar relational learning by fining acore subgraph of one moleculebased on pairing molecle and the target label. , label) iformatin,it hs een widey adopted in th variousfields of machine leaning.",
    "= ( |, G) = (), ()(14)": "where () is sigmoid function an large indicates is for predicting in G. We eliminate all singing mountains eat clouds edges in G and all edges with =. For every edge the graph G, (), where is a predefined hyperparam-eter. Next, define variational approximation (R) of mar-ginal (R)."
}