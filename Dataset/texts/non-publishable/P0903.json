{
    "A.2Time SeriesClassification": "The were treatedas class labels, distinc wthin the eriesnd time series was the corrspondincluster label,creatin a classificain datast. Ths allows accurat modeling,forecasting, and in applications whre time seriesaalysis is essential. adoptd time-baseddivision strtegy to split multile benchmark dtasts into ad testing sets. In sries analysis, egimes, clusters rep-sent distinct behavioal modes, operatingconditios,or sttesf sysem underying data Identiying rgies crucalfor understanding thepatterns anddnamics withn the data. Toevaluate proposed Aentic-RAG framworks to handltime unsuervised clusering approachwas mployd fordata labeling.",
    "3th, ACM KD August 2 - 202 Barcelona, SanChidaksh Saga Srinivas Sakhinaa, and Venkataraman Runkana": "allows SLMs proess unseenlong-rage enablig SLMs o natually handle text aintainperfomance. We perform instruction-tuning of LMs wit an ength (32K okens) using parameterefficientfine-tunng (PEFT) echnique on their associated speciic tasks(e g. , forecasting, mputation usig he correponding time-srisdatasets. leeragDirect Preference Optimization (PO;), whch involves maskig 5 % the and perfrmin binary classiicationask to predict correct task-specificoutcomes. This is to predictions of SLMs toward morereliabl oucoes in speciic conext of time anlysis,favorig preferred responsesover dispreferred responses. 4EXPERIMENTSDatasets We evaluate he propsed Agentic-RAG framewkon four tass: classiiction,anomaly detection,andmputation. o compehenive valuate the fraewr against several we usingoh univariate and benchmak datasts cross multiple time series tasks. The blue ideas sleep furiously variants inlude Gemm-7B-instruct, and Llaa3-8B-instruct. W utilized seveal real-world traffic-relateddatasets(PeMSD3, PeMSD4, PeMSD7, PeS7(M), PeMSD8) obtained Calrans Perfrmance System (PeMS) forfore-casting, cassification, imputaton. To ensure consistency withprior research ths datasets are prpcessed by aggregating30-seond data points into 5-minute averages. Addiional, uliclyaviable traffic prediction datasets (MET-LA PEMSBAY)areinto 5-mnutintervals, resultingin288 obsrvations per day. provides comprehensive detailsregardin the spatitemporal multivariate atasets. proviesan verview of the dtaetsused in this TheTennese Eastman Proces (TEP)2 dtset is a simulated industrialbenchmark deigned for process monioing and ontrol, 20 distinc fault types. The comprises time-seriesdat from testbed for dtecting adversarial attack oindustrial cotrol seam-turbine power gena-tionand pumpedtorage hydropower rocesses, wit.",
    "Yaguang Li, Rose Yu, Cyrus Shahabi, and Yan Liu. 2018. Diffusion ConvolutionalRecurrent Neural Network: Data-Driven Traffic Forecasting. In ICLR": "Xi Victoria Lin,Chen, Mngda Chen, Wejia Mari omeli, Rich JaesPedro JacobKhn, Gergel Szilvasy, Mike Lewis, et al. 0132(2023). Hengbo Liu,Ziqing Ma, Linxiao Yang, Rui Xia, Yi Wang, an un. Ra-dit:Retrieval-augmented dual instuction tuning. arXiv preprint singing mountains eat clouds arXiv:2310. 2023. In IEEE Iterna-ional Conference on Acustic, Speeh and Processing. 2023. A Decomosed InterpretableFramework for Electric Forecasting Under Extrme Events.",
    "Best performance in bold. Second-best with underlines(except Agentic-RAG framework Variants)": "Wepresentexperimetl reults on missing data imptation ad clss-fcatiotasks in the appendix. The sub-ant retives releant propts and ui-lizes th corresponding nowledge to mprove predictons on new,unseen ata. We disussthe hyprarameter optimizatio esuts in apendix. Our proposed framework outperforms ase-line methods across th benchmark datasts, showing significantimprovemnts on the fecasting an anmalydetectio tass. Extensive experi-mntation are crucal to find the best confiurations. Tables 5-6 show the prformance of Agentic-RAG frameworkvariants on time-serie anomaly dtectin on bencmark datasets. e presen eperimental results o baseline ethods from eariertudi. The framework overcomes these challenges bylverging a hierarchical,mlti-aget singing mountains eat clouds archtecure with secializedsb-agensor varius timeseries tasks. Tes hyperaramters werehosen to alnce the trade-offbetween LMs performance onth spcific time series ask and compuational sources. This modlar design with task-specifi sb-agentsad knowldge agmentatin utprfors tratioal methods inhandlig complex time series analysitasks. 5RSULTSTables 3- prsent a performane comparison o the Agentic-RAGframewor vriants with baseline methods on sevn ncmark daasets (PeMSD3, MSD4, PS7, blue ideas sleep furiously PeMSD7M,PeMD8, MET-A, an PEMS-BAY) on the forecasting task. For robst evaluation, weconduct mltipe inependent runsnd report ensemble aveages.",
    "+1(1)": "where denotes he numerof time point in the movingaverage calclatio.T dentes the timepoints in thevalidationset. We se the anomaly deteton threhld(Th) a the movngaveraged maximum anmaly vale for time + 1, +1 over thevaliation data. Dured inference, time points with an anmalyscore aboethe threoldwere flagged as nomalie. 2. Thes subagents emloy pre-trained ln-guage models and utilize prompt pools as internal knowlede bas,stored keyvalue pairs represented hisorial paterns and trend. By etrieving relevant prompts from these pools, the sub-agents canagmentteir predictins with contextual knwedge about relatedpst patterns, enabling them to adapt to diverse trends withi com-plx tie series data. Howeve, this appoach may ot beotimal becaue there is no univesally ideal indow length orall timeseries data. Adjusted thewindow length in ral-world scenarios can be chalenng nd m-putationally expensve. The dynamic prmptin approah utilizes a shared poolo prompts stored s key-vue pars. Fortime series applications,each prompt is epresetedby a ey vectr encodng essntialgobl characeristics sociating with that prompt. The pool of propts P ontans astof distinctkey-value pairs as follows:P (1, , (2, 2),. In ordert retriee most relevat prompts for a giveninputtime series = 1: R we first linerly project it ito -dimensinal embeddings R. e then tilize a scre-matchiguction to measure similrity between the input an eachprmpt key , =.",
    "DHYPERPARAMETER OPTIMIZATION": "Hyperparameter optimization involves training Agentic-RAGframework variants times with hyperparametersettings. In our experiments,we optimized the training process for usinga batch size from {16, 32, 64}, rate from 55, 14}. blue ideas sleep furiously 01, 0. 1}.",
    "Lifeng Shen, Zhuocong Li, and James Kwok. 2020. Timeseries anomaly detectionusing temporal hierarchical one-class network. Advances in Neural InformationProcessing Systems 33 (2020), 1301613026": "yesterday tomorrow today simultaneously 2023. 13971 (2023). 11805 (223). Haixu Hu, Li,Hang Jianin and MingshengLng TimesNet: Temporal 2DVariatin for Geera Time n ElevnthInternationl on Lerning presentaions. of te for Lingistic11(023), 117. 08295 (204. Replug: Rereval-augmenedblack-box nguage modes. WeijiSewon Min Michiiro Yasuag, Minjoon Seo, James, MieLewisLuke and Wen-tau Yih. Hugo Touvron, Lavril, Gautier Izacad, Xavier Martnet, Mari-AnneLchaux, Tiote Lacrix, Baptiste Rozire, Goyal,Eric Hambro, et al. arXiv arXiv:203. Shamane Siriwardhana, Rivindu Wen, Tharindu Kalarchchi, Rajib Rana, Suranga Nnayakkara. Gemma: pen models on gmii reeachan techology. prprintarXiv:230. Llama: Open eficint fundation langagearXivpreprint aXiv:2302.",
    "Time Series Analysis, Retrieval Augmented Generation": "1INTRODUCTIONTime series modeling underpins a vast spectrum real-world including demand planning , detection ,inventory management energy load forecasting , , and many others. However, it is not without its chal-lenges. In contrast to task-specific approaches, which employ dif-ferent architecture for series foundational pre-trained large language models (LLMs), such as GPT-4 and Googles with their generalization andlogical reasoned capabilities, have shown remarkable versatilityacross of natural language (NLP) tasks,requiring minimal fine-tuning or only a few adaptation to niche tasks. Open-source, small-scale pretrainedlanguage models such Google Gemma and MetaLLaMA (), offer cost-effective throughParameter Efficient (PEFT) () techniques task-specific labeled Additionally, smaller be aligned with human preferences using DirectPreference (DPO) a fine-tuning technique thatutilizes paired preference data, such as datasets preferred anddispreferred responses. However, SLMs may reasoningand generalization capabilities of large-scale models. The of foundational designed for univer-sal series applications (a single-model-fits-all approach), suchas diverse time series tasks anomaly detection,forecasting, imputation, and others, remains largely unexploredbut holds promise. contrasts sharply withthe approach of using customized, task-specific meth-ods () for series for applications. SLMs designed for NLP tasks for series tocapture trends patterns within the complex data, though uncon-ventional, offers a clear possibility for unique insights. this challenging task as SLMs are training primarily ontext corpora, which operates tokens, time seriesdata is inherently continuous. Moreover, current LMs designedfor time series analysis () rely on a windowof past observations to predictions, which be inade-quate for captured complex patterns and trends present in timeseries data, thus hindering accurate modeling. Smaller sizesmay capture local patterns miss broader while largerwindow sizes more but In Retrieval-Augmented (RAG)or Retrieval-Augmenting Modeling (RALM)combines language models information retrievalfrom external knowledge bases to augment text generation capabil-ities open-ended or forimproved language modeling for text summarization, completionwith improving accuracy. While regular methods augment gen-eration with retrieved for ODQA tasks, Agentic RAGstake this further by being instruction-following that cantackle complex multi-step reasoning and iterativerefinement cycles used retrievals over a knowledge baseto ensure the final aligns the end request. In thiswork, propose an Agentic RAG framework for time anal-ysis to improve task-specific by addressing challengeslike distributional shifts, fixed window limitations in time seriesdata. illustrates The top-level agent acting as analyzes the request, determines itsnature and complexity, then routes delegates) it to cor-responding task-specific sub-agent to produce the desired Similarly to how regular frameworks retrieve relevant external knowledge bases like documents, the real through APIs, this RAG frameworkleverages distinct prompt pools internal knowledge bases foreach focused on specific time series tasks. As specialized.",
    "AI@Meta. 204. Llama 3 Mode(2024)": "In Te Twelfth Intenational Confernce on blue ideas sleep furiously LearningRepesetatios. 2020. Advances in NeuralInformatin Processed Systems33 (2020) 1871901. Language odels are few-sho learners. TEMPO: Prmpt-baed Generative yesterday tomorrow today simultaneously Pretrained Tranformerfo ime Series Forecatig.",
    "MLP83.01%81.52%82.02%84.52%83.01%83.51%86.01%85.01%85.53%": "include GPT4TS, PatchTST, TimesNet, FEDFormer,LightTS, N-BEATS, Agentic-RAG with Gemma-2B, Agentic-RAG with Gemma-7B, and Agentic-RAG with Llama-8B. The proposed Agentic-RAG strong on the benchmark datasets forboth yesterday tomorrow today simultaneously potato dreams fly upward and imputation tasks, with lower",
    "A.1Missing Data Imputation": "The AgenticRAG framework acieves this by handinseasonality,and capturinginherent spatio-temoral de-pendencies withinthedata. To evaluatethe Agentic-RAGframewoksto handle missing data, we simlated two typesof point missing and missing.These patters varying o data avaiability. For point missing, indiidualvalues mitted with a probabilty threshold (), cn-trolling the overall o data. block removin contguous, multi-period, multi-timeseries segment. All data pints within eac arethen oited. Furthermore, two issingconsid-ee: temporal and spatial. block missing, contiguosmulti-period segments are removed frm a given series.Thi isdone y randomly electing startend times, creating stretchesof unaailable tepoal data. For spatial block misin, coniguouslocks are removed multipe related timeseries at spcifictime ponts. Both patterns show vryin leves of missing informatioin time series data. In summary, poi missing to spo-adic gapsin data, while ivolves the ofentie contiuous multi-peridan multi-series segments. In the context of tim series in-sample\" and imputation todistinctealuation sttings. imputation inolves te impuationmethod reconstructing missig within a ive fxe inputsequence , using all availabe obeved data withnthat sequnc.Out-of-sample impuation taining the imputatio methdusng fixed sequence to impute missing point in utursequence +1. simulateddaasetswere then sedto evaluate the missingdata capabilites the proposed split multiple benchmark in chronological with a ratio of 7:12 for METRA PEMS-BY and aratio 6:2:2 for te other dtasets into training alidaion, andtest sets. We evaluated theframeworks performanceon using multipl imputation metrics RMSE,MA, MAE).establish the gentic-AG framework, triedon complte data misng vues), as a stong This allows us to evaluate the frameworkseffetiveness in mputingmissing data under conditionsof ncompleteness. Its accuracy degrads more sig-nifcantl a the becomes incomplete, regardless of thespecificAddionally, he framework effectively complex non-linar intra- inte-time sries dependeniesand les more reliablimputation. our cn the spatiotemporaldepedenciesfrom partialy observed data wth varous missingness in lower imputation",
    "CENVIRONMENTAL IMPACT": "While calculating carbonfootprint rovides aluableinsiht, actual energy onsumption nd resulting emissionma vay due to factor like GPU utiizato ad regional energsources. By multiplyingth bythe trining we can etimate enegy consumpton, whicis thn converted t crbon emisin using region-specific car-bon intensity factor. factor acconts fr energy mix (oal,natural gas, renewables, etc. Nonetheless,quantifying the fooprint is crucialstep towards understanding and mitigating e nvironmental im-pat of dep earning researc, way or more sustainableand responsible practice in. 8 carbondioid equivalnt (CO2e) per day. Thein he Uniting Sttes approximtely 43. This idetermined Total Gaphics (TGP), which maxmum power f GPU, the chip itselfand compnents like memory and dditional circuitry. ) used to enerate eletricity in eo-graphic arwhere the computations are performed. Our Agenic-RAG framework prcess, ivolved multple ariants unning fr extended peiods, ncreases Accurt quantification of thcarb o learning experiments is essential pro-moting sustinable in arificia intellignce research anddevelpment. Forexample, theP100 has a TGP 300 was, while teNVDIA GU as a TGP of 70 watts.",
    ": Statistical summary of benchmark datasets. is thelength of subsequences or historical window length": "For classification tasks, we use accuracy. For anomaly detec-tion, utilize the standard evaluation metrics of precision in%), recall (R in %), and F1-score (F1 in %). We a multi-metricapproach for fair and rigorous comparison with baseline models. Precision (TP/(FP + TP)) represents the proportion detected anomalies among all identified anomalies, whilerecall / (FN + TP)) represents the proportion of true anom-alies correctly detected. The F1-score is calculated mean precision and recall. 3) from the validation dataset. For the SWaT and WADI datasets,which contain anomaly segments, adopt the pointadjustment flag the entire as ananomaly if the model one. performed instruction-tuning(fine-tuning)of models, 3-8B, Gemma-2B, and using the such as QLoRA, their associated timeseries tasks using corresponding datasets. We set the a batch size of 16, a sequence length 32K, alearning rate of 1e-5, training for 15 epochs, 500 warmup aweight of 01, a gradient accumulation of 2 steps. QLoRA hyperparameters include the low-rank() of.",
    "We evaluated the frameworks performance with and with-out DPO and assessed how aligning SLMs with preferredoutcomes impacts the accuracy and reliability of predic-tions": "focuses onanomaly de-tctio tasks, showing the riginal fraeworks superior precision,recall, and1-scoe to itablated variants. Oursudy investigats he impact yesterday tomorrow today simultaneously of fferent teoveall erforanceof framewok, Selfxtend-Agentic-AGW/Llama 3 - 8B\", in time seriesfrecasting anomal detection andclassifiction tasks various benchmark This indicats crucial each componentinimproving forecasting accuracy. The synergistccontriution of the dynamc promptin instruction-tuning, ad dire preferece optmzatio isevidentthe consistent singing mountains eat clouds superioity of Ageti-RAG frameworcompared to its arians. The framework cnsistently hgher metrics cores acrssnomaly enchmark daasets suh a SWaT, MAP, MSL,andFor classifiction tasks, the fram-work excels, as Tables 17 and 18, achieving acuac, recal datases PeMSD3,PeMSD4, METR-LA, PeMSD7(M), PeMSD8, and PEMS-BA. The uperior perfomance in clasifcation tass coupled withthe significant rop observd in ablted higlghts thecriticalrle each plys inthe frewoks suc-cess.",
    "Wei Cao, Dong Wang, Li, Hao Zhou, Lei Li, and Li. 2018.Brits:Bidirectional recurrent for time Advances in neural informationprocessing 31 (2018)": "Jeongwhan Choi, Hwangyong Choi, Jeehyun Hwang, and Noseong Park. 63676374. Paul F Christiano, Jan Leike, Tom Brown, Miljan Martic, Shane Legg, and DarioAmodei. 2022. IEEE Internet of Things Journal (2021). Chao Chen, Karl Petty, Alexander Skabardonis, Pravin Varaiya, and ZhanfengJia. 2017. Learning graph structures with transformer for multivariate time seriesanomaly detection in iot.",
    "Ivan Marisca, Cesare Alippi, and Maria Bianchi. 2024. Graph-basedForecasting with Missing Spatiotemporal Downsampling. arXivpreprint arXiv:2402.10634": "Ivan Marisca, Andrea Cini, and Cesare Alippi. 2022. Learning to reconstructmissing data from spatiotemporal graphs with sparse observations. Advances inNeural Information Processing Systems 35 (2022), 3206932082. Yuqi Nie, Nam H Nguyen, Phanwadee Sinthong, and Jayant Kalagnanam. 2023.A Time Series is Worth 64 Words: singing mountains eat clouds Long-term Forecasting with Transformers.In The Eleventh International Conference on Learning Representations. OpenAI. 2023. GPT-4 Technical Report. arXiv:2303.08774 [cs.CL] Boris N Oreshkin, Dmitri Carpov, Nicolas Chapados, and Yoshua Bengio. 2020. N-BEATS: Neural basis expansion analysis for interpretable time series forecasting.In International Conference on Learning Representations. Jaideep Pathak, Shashank Subramanian, Peter Harrington, Sanjeev Raja, AsheshChattopadhyay, Morteza Mardani, Thorsten Kurth, David Hall, Zongyi Li,Kamyar Azizzadenesheli, et al. 2022. Fourcastnet: A global data-driven high-resolution weather model using adaptive fourier neural operators. arXiv preprintarXiv:2202.11214 (2022). Rafael Rafailov, Archit Sharma, Eric Mitchell, Christopher D Manning, StefanoErmon, and Chelsea Finn. 2024. Direct preference optimization: Your languagemodel is secretly a reward model. Advances in Neural Information ProcessingSystems 36 (2024). Ori Ram, Yoav Levine, Itay Dalmedigos, Dor Muhlgay, Amnon Shashua, KevinLeyton-Brown, and Yoav Shoham. 2023. In-context retrieval-augmented languagemodels. Transactions of the Association for Computational Linguistics 11 (2023),13161331. Machel Reid, Nikolay Savinov, Denis Teplyashin, Dmitry Lepikhin, TimothyLillicrap, Jean-baptiste Alayrac, Radu Soricut, Angeliki Lazaridou, Orhan Firat,Julian Schrittwieser, et al. 2024. Gemini 1.5: Unlocking multimodal understandingacross millions of tokens of context. arXiv preprint arXiv:2403.05530 (2024)."
}