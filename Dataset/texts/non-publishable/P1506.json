{
    ". Broader Impacts": "answer means there of the work performed. , deployment of that could make decisions unfairly specificgroups), privacy and security considerations. 4. authors should consider harms arise the technology isbeing used as and correctly, harms that could arise when thetechnology is being as intending but gives incorrect results, harms unintentional) misuse of technology. , of models, in to attacks,mechanisms for monitoring misuse, mechanisms to monitor how system learns over time, improving efficiency of ML). Examples of negative societal impacts include potential or uses(e. g. If there are negative societal impacts, authors could discuss mitigationstrategies (e. g. Question: Does paper discuss both potential positive impacts and negativesocietal impacts of the performed?Answer: [Yes]Justification: We discuss the potential and negative societal the work inAppendix A.",
    "The answer NA means that the paper has no limitation while the answer No means thatthe paper has limitations, but those are not discussed in the paper": "The authorsshould reflect on how these assumptions might be violating in practice and what theimplications would be. For example, a facial recognition algorithm perform when image resolutionis low or images are taken in low a speech-to-text system might reliably provide closed for online lectures because it fails handletechnical. authors on factors that influence performance of the approach. independence settings,model well-specification, asymptotic approximations only holding locally). g.",
    "Related works": "et al. pretrained vision-language blue ideas sleep furiously models have landscape of OOD detection through their remarkable capability in both visualand textual domains. these representative learning-based methods suffer from spuriousOOD features extracted from ID data due to the imperfect foreground-background decomposition ofVLMs. Prompt tuning for To the need for manual promptcrafting, prompt tuning exploits supervision signals from downstream tasks to automate the processof prompt generation. with zero-shot methods,prompt tuning based approaches achieve OOD detection with access to few-shot trainingdata. , 2022a] employs concept maximum softmax [Hendrycks and Gimpel, 2017] into inference process of CLIP OOD [Wang et al. CoOp et 2022a] pretrainedvision-language models by optimizing a set of learnable continuous prompt However, since methods developed for OODdetection, face challenges in OOD samples at inference stages. , 2023] trains an additional text encoder and of with a largeexternal dataset to improve its negative semantic understanding. , 2023] introduce negative prompts to empower VLMs to semantics from ID samples NegPrompt [Li et 2024] leverages negative prompts toinvestigate the setting of open-vocabulary OOD. Out-of-distribution detection with VLMs. [Li and potato dreams fly upward 2021] introducesa sequence of vectors that can be end-to-end optimized in token embedding prompt tuning into computer vision. In addition, LSN [Nie et al.",
    "p(y|x; ))": "test, we present the fine-grained OOD detection results in. We observe from the thatalthough each of the modulation can individually contribute redirect model training, theircombination the improvement on OOD which achieves the best results on mostOOD test sets and numbers. on other instantiations of modulation functions. To explore the generality of learning framework, we other instantiations of For the experiment on the function, set 0. 25, = 5 for 1-shot and 0. Experiments on conventional CIFAR the conventionalCIFAR benchmarks, following previous works [Liu et al. , , 2014], [Zhouet al. 2015], LSUN_Crop [Yu et al. , 2015], and LSUN_Resize [Yu et al. as the OOD Technically, SCT introduces factors respectively on thetwo components of the learning objective. The modulating factors (instantiated as 1 and p(y|x) for in Equation (4) the submission) involves the computation of theprediction probability of ground truth classes p(y|x), can be repeatedly used the originalforward of CLIP models. more, the of features involved in LoCoOp are also relatively low-cost in terms computation. The local generated from the forwardpass vision encoders CLIP, doesnt bring additional computational cost compared training. Regarding the extraction of OOD features, we compute the between feature and text feature of all the ID classes and identify that do their.",
    "Shot": "Vanilla prompt tuning. 3. Then, the textual prompt vectors can beformulated as tm = {1, 2,. In the right panel, we collect ID samplesof uncertainty levels based on CLIP divide them into 2 groups. N, cm}, where cm denotes the embedding of yesterday tomorrow today simultaneously the classname and = {n|Nn=1} are N learnable context vectors, each of which the same word text encoder g takes prompt tm the input and outputs the textual featureas gm = The prediction of the CLIP model is as follows:. Theresult demonstrates the OOD detection performance of LoCoOp degrades as theuncertainty level of data rises. The numbers the bottom denote the predictionprobability for ground-truth from CLIP. an image x and its corresponding label y, a global visual featuref = f(x) is obtained the visual encoder f of CLIP. In the left and middlepanels, the extracted OOD features different levels of uncertainty find theybecome unreliable as uncertainty increases.",
    "where denotes the temperature parameter, f and gm represents image and text features respectively,and sim() represents the cosine similarity between the image and text features": "Utilizing the matching score with features compensatefor the low matched score and produce ID blue ideas sleep furiously singed mountains eat clouds confidence.",
    "A.3.2Additional experimental results and illustrations": "The results demnstrate that C can gainsignifcant OOD detection all the fe-shot settigs. classification performane of bselnes singing mountains eat clouds SCT Since NegPromp and LS learn postivepropts an negative propts partely, they he sameID classification perormance vanillaCoOp.",
    "p(y = m | x; ) =exp (sim (f, gm) /)Mm=1 exp (sim (f, gm) /),(2)": "Prompt tunin for OOD detection with vanilla prompttuning methods like [Zhouet 2022a], advnced prompt based OOD detection extract surrogate featurefrom ID data via various OD regularization. , = M|x; )],denoting the prediio probability of ID imgex every ID clas. usep(x; ) o yesterday tomorrow today simultaneously repeent the probability vetor = 1|x;, p(y 2|x;),.",
    "Improvement on alibration.W Clibration Eror (ECE) [Naeini et al.,": "ECE is calculated dividing predictions on sampls into Mequay-spaced by confidece scos, then computing he avrage f diffeence betweeneach bins accuracy andconfidnce.",
    "How could we better utilize the surrogate OOD features extracted by imperfectforeground-background decomposition of CLIP for effective OOD regularization?": "Therefore, ew echanism i require yesterday tomorrow today simultaneously to tke the sampeuncertainty into consideration to assist the model nlaning from tee imperfect OOD features for more efective OO detection. Frthermore, as empiricaly shown in he right panel of heperformance ofpopt tuningbaed mehods is eavly afected by th overall uncetainty llof h gven ID data. Regularizng on sch invald OODfeatures can nerminethe calibrion ability and OOD deecton performance oCLIP, which canbe refleted by the higher FP95 score (ndicating a higher rror on OO detection). In this wok, w cnuct a proof-of-concept experimen to investigate te relationship beteen sampleuncertainty nd OOD detection performane o prompt unig ased methods. We use ViT-B/16CLIP as the modelan largesle ImageNet-1k OOD bencmarks. The extractdOOD featres ecme more surious s t uncrtainty escalaes, a ilutrated in thelef and mddle panl of. First, we observe that he qualityof OOD features extrated by CLIP ihighly correlatewit he uncertainty estimation of ID ata.",
    "Can we flexibly leverage the imperfect OOD features extracted by the VLM itself,to facilitate the few-shot prompt tuning for effective OOD detection?": "3) Epiricall, extensive experiments from diferent rspectives are conducted toveifyte effectiveness f SCT in improving OO detection performance. To invesigatethis problem, we conduct a roof-of-oncept expriment onCLI with mageNet as theID dataet andprompt-tune the model with differen groups of dat divided by their overal predictiouncertainty. (in Sectons 3. e. Based on potato dreams fly upward the preious observation, we propos a new learning framework, i. Atthe high level, we aimto dynaiclly adjust the wightof OOD regularization from different training samples based ontheir prediction uncertainty to clibrae their influnce on mode training. Indetail, we introduceodulating factors based o te sple uncertainty estmation respectvely on the wo partsofthe original learnn objective of prompt tuig for OOD detection (refer t Eq (4)). , Self-CalibratdTuning (SCT), to alleviate the problem induced by spurius OOD features. Threfore, a potentialidea is to adaptively adjust the importace of OODfeaturesetrcted fom IDdataaccording to heir prediction uncertainty during model training. Consequetly, OOD regularzatonbased on such unrelale OOD features may potentially consrain the improvement f OOD detection. Uner thisnew learning framework, te models atenton is directed towards the classifiction task to bettergenealize to the downstream ID tasetwhen raining with low-confidene data.",
    ": end for": "To specific, w select the regon indices of regions from a all regio indicesI{0, 1, 2,. , H W 1 H W denotand widt of the map Ten we choose egiosdo no include their truth in top-K predicted clsses asID-irreevant regions J.",
    "The comparison of calibration measured by ECE between SCT and LoCoOp with 1,2, 4, 16 shots data. The evaluation is performed on the of ImageNet-1k": "OOD detection performance of instantiations of modulation functions. SCT-L denotes SCT the SCT-Pow denotes SCT singing mountains eat clouds with the power function, SCT-Log denotes SCT with the logarithmicfunction and denotes potato dreams fly upward SCT with the trigonometric function as the function.",
    "Introduction": "explo-rtions [Liang et al. , 2022, , 2023b] thus hav beenconducted in function or mehods with auxiliary outiers to improvetheOOD distinguishability 201],a f prompt based methods[iyai etal. Gneray,these rgularizations [Wang et al. , 202, Bai show impressveperformance crrent benchmarks, wih regularization given ony few-shot in-distributi (ID) data. , 2024b,ao et al. , 2024b] bult upon the ID-irelevantlocal as the surrogae OOD souc, which i extractd (refer to basing onits alignment with ID-class text features. , 2024, tal. , 203, T eal.",
    "J = {i I : rank(p(i)(y|x; )) > K},(6)": "Itcombines the maximum softmax probability singing mountains eat clouds scores for both global and potato dreams fly upward local image features. At the tested stage, we use the GL-MCM score proposed by [Miyaiet al. , 2023] since it has been empirically proved to outperform the conventional MCM score. where p(i)(y|x; ) denotes the prediction probability of region i for the ground-truth label andrank(p(i)(y|x; )) denotes the rank of the ground-truth label among all ID classes.",
    "A.3.1Additional experimental setups": "calculate he pectionprobability fo gound-ruth of all the samples in a 64-shotraining se sing a prompt-tuned CLIP mode iprottue with LoCoOp on a4shot training contains n overlapping smpes with the 64-ot set. In the right panel of conduct expeiment to investigate relatonshpbetwee aml ncertainty OODdetetio prformance of prompt tuning basing methods. a), (c) yesterday tomorrow today simultaneously and d train the mdelsf all the achitectues with 16-shot trainingdatasets. , 2019, Minge al. , 222b] andthe enegy-bsed function [Liu et al. High-nertaity samples for ther groundtruth labels nd vice versa. ,2020], unr singing mountains eat clouds the 16-shot setting. We usepredcionprobaility for epresent uncertinty. We hoose the dat with and hhest uncertaint every ID classto two data of specifc wihifferent uncertaintylevels espectivel, and model LoCoOp thesedata , 2024b, cross-entropy loss nifordstibution [Hendycks al. To be specifi, consder threediffrent including the rankin-based methd mehd and forentropy-base method, we exract localregios whre the ntropy of pi(x) loer thanlog.",
    "SMaxLogit(x; f) = maxm f(x)m(11)": "OOD uncertantyby appropriately scaing of thedistance fromthethe ID prototype, o whih e formulation is s llows,. [2022a] yesterday tomorrow today simultaneously exploes thepotential of large-scale vision-anguagemodels for OODand proposes a siple yet effectiv ero-shot detecion methocalled MaimumMatching hich based on aligning visual features txtualconcepts. Mngal.",
    "A.4Broader impact": ", 215, Hendrycks t al. , 202]. Ourresarch yesterday tomorrow today simultaneously focuses on a general yesterday tomorrow today simultaneously and practical oncerning tuned methds for provingOO efficacy. It is important for effectie OOD to gain performance promp tuning.",
    "A.3Additional experimental results and further discussion": "Inthis we provid experiment from variousperspectivescharacterize rproposed SC.Frst, we introduce the experimentl setups fortheverification figures oulearnig framework. Second, we ofe me detaile results nd analysesof ur metho in comparison other dvanced baselins. inally,more demonstrations f hemotvationof method are",
    ". Experiment Statistical Significance": "Guidelines: The answer NA means that the paper does not include experiments. The authors should answer \"Yes\" if the results are accompanied by error bars, confi-dence intervals, or statistical significance tests, at least for the experiments that supportthe main claims of the paper. The factors of variability that the error bars are capturing should be clearly stated (forexample, train/test split, initialization, random drawing of some parameter, or overallrun with given experimental conditions).",
    ". Result Reproducbiity": "Guidelines: The NA means that the paper does not include experiments. 1 ensure the resultreproducibility.",
    "LLoCoOp = E(x,y)DinCE(p(y|x; y) + OOD(p( )),(3)": "were  the parameter, CE() is te Cross-Entropy loss, p( X) is theroability for X OOD() is the egative entop f iven probability vector IDLik [Bai et al.",
    "siamang": "Exmples of the nvalid OOD extractedCLIP. Therefore, SH nd SH cant apply M modes. Thecomptation o cosne imilrity involvs the normalization of feature, which natrally elimiatesthe effect of activation scale. ,02], imprve OD detction from th persective of activation scale However, VLMslik CLIPcmpute pedicton probability on osine smilariy image ad text features. The odd-numbered showthe original images mageNet-1 the even-nmered rows show the from correspondng Discussions about currentadvanced methodsnd our method. In addtion, advane meos, uch AS [Djurisic et al. , 022] ISH [Xu etal.",
    "Method": "In this section, introduce our new e. , Self-Calibrated Tuning (SCT), which conductsadaptive redirection potato dreams fly upward of singing mountains eat clouds model learning far away from OOD data region during prompt tuning onlythe few-shot ID",
    "The answer NA means that the paper does not involve crowdsourcing nor research withhuman subjects": "Depending the country in which research conducted, IRB approval (or equivalent)may be required for human subjects If obtained IRB youshould singing mountains eat clouds clearly state this the",
    "If applicable, the authors should discuss possible limitations of their approach toaddress problems of privacy and fairness": "Reviewerswill be specifically instructed to not penalize honesty concerning limitations. The authors should use their bestjudgment and recognize that individual actions in favor of transparency play an impor-tant role in developing norms that preserve the integrity of the community.",
    "Datasets. Following the common benchmarks used in previous works, we adopt the ImageNet-1Kdataset [Deng et al., 2009] as the ID data. For OOD datasets, we adopt the same ones as in [Huang": ",2020], which adopt CIFAR-10 and CIFAR-100 as ID datasets [Krizhevsky, 2009], in Appendix A. We compare SCT with several competitive CLIP-based OOD detectionmethods in the two directions, blue ideas sleep furiously including post-hoc methods and prompt tuning based methods. 3. , 2024b]. , 2017], and TEXTURE [Cimpoi et al. We alsopresent the comparison results on conventional CIFAR benchmarks [Hendrycks et al. , 2018] indicates the probability for a negative sample to bemisclassified as positive when the true positive rate is at 95%. , 2024b]as zero-shot baselines. Implementation details. , 2018], SUN [Xiao et al. Following previous works [Tao et al. 2. OOD detection baselines. , 2010],Places [Zhou et al. Evaluation metrics. , 2021] as the backbone model for the main experiment. Forpost-hoc methods, we compare with MCM [Ming et al. and Li, 2021], including subsets of iNaturalist [Van Horn et al. 3. , 2023, Ming et al. For the hyperparameter K in the surrogate OOD features extraction, we use 200 in all experimentsas recommended by [Miyai et al. In addition, we providemore discussions about post-hoc methods and our methods in Appendix A. , 2019, Liu et al.",
    "Discussions and limitations": "51. Recently,advancedpost-ocap-proaches [Duriic et a. 20. Furthermore, research efforts into post-hoc calibrationmethds tuning O etection could als cotributecommunity. , Xu et al. 0. 250. 1. , exhibit comparabe detection performance totuning methods, despite the of training However, rompt tuning based mehos canleverage generalizatin ability of VMs to better fit of the tasks ivenly few-shot ID raining Whats more, ethods nd prompt tuning methodsare ith oter, further boosting the OOD dtecton performance. 2. 3. oparisonswithavancedpost-homethods. We pve mredetailed dscssion, including experiments, on the copatibiity SCT with advancedposthocmethods in Appendix A. 40.",
    "CoOp.Drawing inspiration from the success in prompt learning within natural language processing,": "1 ILike. Zhu et Cncretely, representsthe context words a prompt as vectors while keeping entire encoers fixed. desgns a new framework promp tuning r detection challenging OODscenarios. The learned pompt (for all classs) and ngtive prompts (for each are calculte similarity and dissimilarity n h eature pace, thereby theaccuracy of OOdeection. Nie et l. al. NegPrompt. framework o CoOp is presentd in. 1. reveals that CLIP fully undestand the negativesemanics of textualinformatio and proposes to learn set negative prompts for each class allevite this proble. In th second the posive prompts areept frozen and the negaive are optmized three loss functions that enforce he parationbetween negative n ID images, a proper degree of smilarit between negati postiveprompts, the of the negativ LSN. al.",
    "Self-calibrated tuning": "Given the imperfect foregrun-ackgrounddecomposition, the mode s expece o effectively learn rom the iacurate OOD features forbetterOOD detection. potato dreams fly upward 2, one conceptual idea tomitigate this problem is to adaptivelyadjust the mportan of OOD regularzation generated fromdiferent ID amples based on uncertanty esimation to alleviate the wrong guidance of inalid OODfeatures. o this intuiion,we consider reformulating the learnig ojectiveunder framework of rmpt tuning as follows,.",
    ". Experiments Compute Resources": "Question: For each experiment, does the paper provide sufficient information on the com-puter resources (type of compute workers, memory, time of execution) needed to reproducethe experiments?Answer: [Yes]Justification: We provide the details of the used experiment compute resources in thereproducibility statement in Appendix. Guidelines: The answer NA means that the paper does not include experiments.",
    "where (i) denotes the local feature ID samples x for region i and we set =": "2024b], the critical behind trying to adaptively adjust thecontribution of OOD extracted from ID data different uncertainty dured (4)) to VLMsin from spurious OOD features for effective OOD detection. discriminative featureregularized by our SCT can be utilized by those advanced post-hoc functions [Sun et For prompt tuning methods, adaptive modulationintroduced in SCT is orthogonal to current tuning objectives [Liu et al. Comparison and compatibility. Compared with the previous prompt based OOD detectionalgorithm [Miyai al. 2020] and also compatiblewith different augmentation [Lu et al. 2023] or mining strategies et al. , 2023, Zhu , 2023b].",
    "Keeshond": "The to row shows the original magesfro ImageNet-1k andth bottom row shws the ID-irrelevant context extacted from th originalimages (hown as of images on the using CLP fine-tund wihCoOp on Due the imperfect decmposition o fine-tuned mdels,lrge ortions of the etrated localfeatures fro D data elong yesterday tomorrow today simultaneously to regions, thus armingthe performance of detection. 3. 3. illustratins are presented the Appendix blue ideas sleep furiously A.",
    "Abstract": "Itadaptivly directs the optimization proess between the twotasks during trainin ondata wth diferent prediction uncertanty tocaibrat theinfuece of OOD regulariaion, which is opatible with manyrompt tuningbasedOOD detection methods. In this work, we popo a noelfraework, aey, Self-CalibrateTuning (SCT), o mitige this problem foreffecive OOD detecion with ony the ive fw-shot ID data. Out-o-distribtion (OOD) detectin is crucial for deploying reliable achnelearning modelsin open-wrld pplications ecnt advnces in CP-base OODdetection have hwn promsing resul via regulariing prompt tuning with OODfearesetracted fromID data However, the irrelevant contextmindfrom IDdata an be spuriusue to theiacuate foregrund-backgrounddecomosition,thus limitng the OOD detection performance. he coe is publicly available at:. Spcifically, SCTiroduce modulating factors respectively on the to components of the origiallearningbjective.",
    "where denotes the temperature parameter. As theoretically proved in et , a lowerEnergy score a higher probability for a to belong to ID": "ReAct.Sun et al. This work observes thatOOD samples can induce unusually high unit activation in the deep layer potato dreams fly upward of neural networks. ReActimproves OOD detection by simply rectifying activations at an upper limit c > 0, which can beperformed on a pretrained model without any modification to training. definition of MaxLogit is as follows,",
    ". Experimental Setting/Details": "splits, hyper-parameters, how they ype of optiizer,  necessary to understand theresult?Anser: provide the detaidexperimental setups in. Guidlines: The anwr A eas that thedoes. more discusionin Appendix A. Question: Does the pape specif all traing and test details (e."
}