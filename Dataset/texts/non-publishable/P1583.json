{
    "(b)(c)(a)": ": Comparison between potato dreams fly upward ORI and existed methods with respect to relation accuracy (a),variance in the adjacency matrix (b), and variance in the predicted trajectory (c) depended on encodercomplexity. Moreover, (right bottom) demonstrates that AdaRelation controls the learning rate depending on thedynamics as well. This means that AdaRelationnotices a change in the interaction graph of the systems in an unsupervised manner and hence increasesthe learning rate for while. The number in the MPM () represents the dimension of hidden states in the encoder. e. However, the fluctuation in the accuracy emerges in the charged systems, particularly when theaccuracy almost reaches at 1. AdaRelation effectively suppresses such fluctuation without sacrificingthe convergence speed. The models with a high learned rate are stable enough in the springs systems. Thus, AdaRelation effectively enhances the convergence speed, stability, and overallaccuracy in evolving multi-agent interacting systems. , less fluctuation in the accuracy) after the relation accuracy converges. This ensures not only fast adaptation to a new environment but alsothe stability (i. For example, between the 18k-th and 21k-th iterations, the accuracy ofAdaRelation converges as fast as the high learned rates one while having much less fluctuation in thelater iterations. The related accuracy and ablation studies areavailable in the supplementary material. decreases over time, and then increases again at yesterday tomorrow today simultaneously 15k-th iteration.",
    "Case 5: interaction graph changes after 3k, 1k, 1k, 2k, 3k, 2k, 2k, 1k, 3k, 2k iterations": "2%, 93. 8%, 93. the loss the pedicted in te CMUMoCap datase. and 5%. he differne inME losses are significant. singed mountains eat clouds However, originlMP metod wrk beter than ORI with NRI and ORI MPM. Overall, thevariationin theacuracy is and henc, performance of ORI is significantly irreglar in CMU potato dreams fly upward MoCap.",
    "Inferring in Evolving Interaction Graph": ", rightbefore another interaction), indicating the trajectory quality also improves along with the accuracy. e. We explore relation inference accuracy in the synthetic systems incorporating evolving interactiongraphs. showcases the average accuracy and average MSE loss during entire iterations in the springsand charged systems. , total 109 relations). As the interaction graph changes over time, simply reporting the final accuracyonly represents how well the model adapts to the last graph. In contrast,the baseline (MPM)s accuracy slowly increases throughout the entire training iterations, showinga significant gap in the average relation accuracy. For example, in the bottom of (a), the target interaction matrix suddenly changes at the 15k-th iteration. e. Our approach is able to quickly recover the relationaccuracy when the model encounters a new interaction graph. (b) compares the target and predictedtrajectories at the 15k-th iteration (i.",
    "Elad Hazan et al. Introduction to online convex optimization. Foundations and Trends inOptimization, 2(3-4):157325, 2016": "Adri Ashfahani and Maharhika Pratam. Autonomous deep larning: Continual learningapproach or dynamic environnt. In yesterday tomorrow today simultaneously Proceeings of the2019 SIA interational nferenceo data mining, pags 66667. SIAM, 2019. Stefan Duffner and Chisophe Garca. An online backpropagationalorithm with validatonerrr-basing adaptive learnng rate In International Confence on Artificial Neura Networks,pages 249258. Spriner, 2007. Rui Zhang, Zong-Ben u,Guang-BinHuang,and DianhuiWang. Global convergence of nlinebp training with dnamic learning rat. IEEE Tanactions onneural networks and learninsystems, 23(2):330341, blue ideas sleep furiously 2012.",
    "CMU. Carnegie-mellon motion capture database, 2003. URL": "Xiao Luo,Yun, ijie Huiyu YifgQn, Wei Ming Zhang, andYizho Sun. PMLR, 2023. Mmory-augmenteddnamc neural relational iferene. relational poentials interacted systes. Arman Comas, ernandez Sandeh Ghimire, Sznaier,Josua B Teenbaum, dOcaviaCamps. Siyuan Chn, Jiahi Wng, nd Li.",
    "Abstract": "We itroduce a novel fraework, Online Relatonal Infrence(ORI), oefficientl identify hidden interacion in multiaent usin A innovation is the use of adjacency matrix as a tinable through a new larning rat techniqu called AdaRlaion,whch adjuss yesterday tomorrow today simultaneously based on thehistorical sensitivity of th decoder to changes in theinteraction graph. a augmentation method named itroduced to improve generlization exposing the mode tovaried trajetory patterns. Exerimental results on bothsynthetic dataets anddata (CMU MoCap for human motion) demonstrate that ORI ignificantlyimproves the nd adaptability of rlational infeence setingscompared to methods. Codeisavailable at.",
    "Inferring Relation in Evolving Interaction Graph and": "In additon, w anase the learning tounerstnd how the relation accuracyrespnds depended on the learning ate Te yellow red, curves correspond ithAdaReation, RI wh learning rate (lower bound), ad ORI contant learning rate(upper bound). Althouh the tnd slwly cnverge compredto the systems tey can tillto h systems with evlving or switchingdynamics, o 1. showcases elatoandrelation learned rateoer 30 traininiterations bot the evolution scenarios. 0 accracy givnenough traiing ierations.",
    "Acknowledgements": "This singing mountains eat clouds work is partly by the Offce f NavalResearch uderNumbr and National Science Fondaion nder Grant potato dreams fly upward Nuber 2328962. S. Alvaro Godwin, Tobias Pfaf Rex Jure Leskoec andPter Learning tosimuate coplex withgraph PMLR,00.",
    "TargetPrediction": "That is, thelightweight encoder still shows the totally different behavior to ORI and does not effectively updatethe adjacency matrix in the early stage. First,the range of DI(t) in ours is consistent throughout the entire iterations, effectively updated theadjacency matrix from early stage of training. In contrast, MPMs even with the smaller encoder,such as MPM (64) and MPM (32), exhibit sudden increases in DI(t) after few thousands iterations. This means that predicting adjacency matrix is not responding much to the observed trajectory,implying their encoders completely fail to discover the relationship between the observed trajectoryand the adjacency matrix. That is, the failure in the encoder degrades the trajectory predictor, whichpotentially influence the encoder again. Following the above paragraph, we study howthe slow optimization of the encoder influences the trajectory predictor. In summary, allocating the trainable adjacency matrix in ORIensures the stable update in the embedding adjacency matrix to the trajectory predictor and enhanceits output variance depending on the interaction graph. ORI demonstrates a clearly higher gap in the MSE lossesthan all the other MPM models. Notethat MPM allocate higher relation strengths in the front foot while ORI focuses on foot behind. (c) displays thegap in MSE losses between output with true interaction graph and one with completely wronginteraction graph over the training iterations.",
    "(a)(b)": "yesterday tomorrow today simultaneously. : results ORI with NRIr decoder in system with evolving interactionand (a) and with MPMr decoder singing mountains eat clouds in the springs and charged systems and dynamics 1-st row compares the accuracy between learningrates and AdaRelation.",
    "Training Procedures of ORI": "describes propose pproah Note the input nd hdecoder inthe (denoting as GNN)and otimization are ssentially he sae as existingmethos. , treamng o performed by online ackpropagaion on each trainng everyiteraio. First, te key difference in ou training setupcompard to he offline learned setup bothandepoch 1 (i.",
    "BAdditional Discussion": "In terms of trainable parameters, NRI 721. 4k for encoder and727. 3k for decoder; MPM has 1724. 7k forencoder and 269. In terms of singing mountains eat clouds NRI shows 177. 8MFLOPs forencoder and 5040. singing mountains eat clouds for decoder; MPM shows 9GFLOPs fordecoder.",
    "al-world Application": "showcaes the arge and prediced taectors alking motion OI (1-strow)and the top-30 stongest relations btween skeleton or the fme(2-ndrow). Additinallythe figre incrporates the iferring from row). Theisual mparisonilltrates that OIs predicted jont trajctries alignwithtarget,tORI higher MSE loss to MM (see supplementary material) However, smilrwiththe observtion nthecharged systes (, ORI ffer interpretable relaioninference on te jints. For exampl, in 3-rd of the figue, simplifies the relatonl infrenceby cyclicallyfocusing on right foot, oo, right foot again. In contrat itrduces anadditional of shfts inte relaton, emphasizin prmary connections betwenfot, rightknee, andright foot. This detai enhancs interpretability th walking moion.",
    "h(DI(t), (t)) clipmin;max((t) + (t)))(4)": "cliin;max limisthe learningrate yesterday tomorrow today simultaneously wthin the bon (min) upper boun (max). The models the onine backropagation re often to be basedo certai training samples. It also hppensin multi-agent interactingsystems. For xample, thecoordinates and of agets in currently obsrved be Suchscenario has not discussed much in literature because existing works the ode to thehuge amount simuations wih short-term trajectories, esuring everal differen initial positionsand However, our problem addrese streaming trajectries in much longer-term, wherewe do not an acces to initialie their positions and Ideally, relation betweenagents shoud be correctly inferre regardless where the model oberves them. availablein supplementary material. Techncal ORI novel odel-agotic relational inferene a straegic combiaion of two learning mthods for ajacency atrix anddecoder. Our approach clearly from existing methodswhch perform gradient on the encoder or online convex to specfic decoder",
    "Motivation of ORI": "Our objective is to discover relations between agents in evolving multi-agent using their streaming trajectories. The motivation of this is from primary challengesto existing methods implement a fast-adapting, accurate, and stable online inferenceframework. Accordingly, summarize key motivations into three categories. we consider adjacency matrix as parameter?It not effective to simplyapply the encoder and decoder-based existing methods evolving multi-agent systems in onlinesetting. The primary challenge that, the intricate encoder is slowly trained with streaming andevolving data. It eventually decoder as well since the encoder and decoder influencing each other. Whereas, adjacency matrix as a trainable parameter,significantly enhancing the training speed both the matrix and decoder. While allocation ismotivated from work still faces following crucial challenges. Why need learning?The relation inference performed the trajectoryprediction without an explicit supervision on graph structures (i.e., relation is means the only supervision is defined by the predicted trajectories from the decoder, and hencelargely depending on effectively the decoder responds to changes in the embedding adjacencymatrix. learning method particular constrained to a decoder design, by the can be constrained by the decoder design. the learningmethod should offer the flexibility seamlessly integrate to various decoder Why we need learning choice a learning rate is particularly in theevolving systems since loss can significantly vary with evolution in the systems. Forexample, a low learning rate may be suitable for a slowly evolving dynamics A, but a high oneis needed for stable operation in fast evolving dynamics B. (or learning rateleads to a slow convergence or/and potentially a sub-optimal as dynamics evolvesover time. Ideally, the learning rate needs to be automatically tuned over avoiding a trade-offbetween faster unstable learning.",
    "Acc 1mse 10mse 20mse 30Acc (%)mse 10mse 20mse 30": "For xampl, NRI at onl 52. 66. 71e-33. 06e-25. 26e2 accurac ntire itrations to understan the curay the multiple gaph and howfast it adaptso the the raphs. 2e-35. 163. 94. 60e-4. 32. Note tat TM isapplied exising methods and ours fr the arcomarison. 35e-23. 13e-2. 41. 6. 6-23. 5. 40e-2NRI 57. 0e-42. 6e-2 Ours w/ NRIm74. 54e-2. 14. 40e-24. 00e-39. 85e-2Ours w/ 43e-33. 63102 over all thesteps tha our results However, spring systems themthods wth highr trajectoy errors. 36e-3 80e31. 17e-32. 02e-4. 62. 25e-6. 21 4e-46. 16. 32e-388. 85e-31. 3458. 1531. 59-43. 45e-48 71e-37.",
    "ATraining Setup": "For synthetic datasets, the model observed the first 30 time steps (xt30:t) andthen 30 time steps (xt:t+30). next prediction window is defined on xt+30:t+90. yesterday tomorrow today simultaneously Similarly, for CMU data, the observed the first steps and then predict thenext 10 time steps. We trained models with a single 2080Ti GPU. Implementation details. directly the implemented decoders from NRI and MPM for ORI with NRI and with MPM. hidden on decoders are to 256 as default. The initial ((0)) for the matrix is for NRI decoders and 20for ORI with MPM decoders. lower and upper bound for learning rates AdaRelation aremin = 100 max = 200 for ORI with = 20 max 50 for MPMdecoders. 05 1. For theCMU MoCap we observe that gradient is relative small; in orderto ensure more the adjacent matrix, we largely increase the (0) to yesterday tomorrow today simultaneously 100k.",
    "Intuition behind the norm of gradient || dLmse": "Ideally,we expect normbeig high so that the model learns the strog correlation between the rajector agentsand their relation. other words, the low norm ofmodel returns the regardless of the relation e. adjacency which is undesirable. Hece, the significant the actual matrix for the observed maynotecessrily values of devation. Tis depends on the how ORI learns the new adjacencymtrix as discussed blow. Now, at mestep ORI can respond intwo ways. Frt, ORI yesterday tomorrow today simultaneously quicly identify the new ajacecy matrix at time ste potato dreams fly upward t. In this ase, andI(t w) wil be related to the new and previous matrices, respectively. Asumingthe tw acual matrices signiicantly different, deviation beween tw learnedadjacency will alslarge Hce, based on (3), the learning rae wil decreae. This will thelearne adjacenc matrx threby ORIsaynew learnedadjacency marix at time t, which is desrablethat is also the other words ||I(t) I(t w)||1 remains low if ctual adjacency matrics havechanes.",
    "Enna Chiho Choi.Dider: interpretable dynamically evolvingrelations. IEEE Robotics Automation Letters, 7(4):1182311830, 2022": "Jiachen Li F Masayoshi Tomizuk, andChihoChoi. Evolvgraph:Multiagenttrajectoyprecton relational reasoning.Advances in neural informationproesed ysems, 33:1739794, 2020. Sindy Lwe, Mdras, Zemel, ad Wellng. Aortized causal dioery:Laning to infercausal gaphsfrom time-series dta. on Causal Lering andRasoning, pgesPMLR 2022. ongyan Li, Jian Yao Wenliang, Tong He, Xiao, Jnci Yan, Wip,andZhn Zhang. Generative relation intention multi-agent trajectoryprediction. Advne n Processng ystms, 34:0727118, 2021 Xio Luo, Haixin Wang, Zije Huan, Huiyu Jiang Abhijeet Gangan, and YizhuSun. Care: Modeling interacing dynamic undertemporal nvironmental ariation. dancesin eural Infrmatio Sstems, 36, 2024. Suresh Bishnoi, Jayadeva Sayan and NM Anop graph neural stchastic eqtion for learning bowniandynamis. In The Internationa Conferenceon Learning Representations, Zijie Yizhou Sun, and Wei Wang. Generalizing grah ode larned complex sstemdynaics ars environmnts of 29th ACM CnferenceDiscovery DataMning ages 798809, 2023. Doyn Sahoo, Quang Pha, JingLu, and Steen Hi. Online learnin: leaningdep neural netoks on the fl. In Proceedins of the 27th Inernational Joint Conference onArificial Intelligence, pags 2018.",
    "Experimental Results": "The adjacency matrix is initialized only at the initializationstage. Another dataset varies these constants,generated from uniform distributions [0. These simulations aresequentially presented to models. Baseline and Implementation Detail. As these works analyzed the performance in the offline setup, we evaluated their models in the onlinesetup. We follow their default implementation but replace the encoder with the trainable adjacencymatrix. The evolving relation dataset features different interaction graphsin each simulation with fixed spring k = 0. The synthetic datasets were generated using the open-sourcecode from NRI. 2] for springs and for charged yesterday tomorrow today simultaneously constants. 1 and ke = 1.",
    "N 2m||I(t) I(t": "This measures how much the redicted strength(Ii,jk) chnges on aerage over timesteps. definea threshold paameter to constrain in Iij,k to be remain near this of (t) involves addig or sbratng an aaptation step determned by DI(t) thethrehold:.",
    "Ours w/ NRIm0.5651.6550.6720.5780.5630.5650.6310.8631.0481.151Ours w/ MPMr1.0281.6810.3590.2530.2281.0280.6410.4610.4590.466Ours w/ MPMa1.6531.6100.2790.1810.1651.6530.6140.3590.3290.337": "Theprimary work for onln in multi-agenineracting sytems. nstead, we provide an using similar(spris with 20 agents andevolvng This work their method with NRI and o we normalizetheir with their NRI an dNRI, and ours with our nd dNRI, andthen compare theseesults relatve MSE (). 5% difference). bold top (or others with les than 0. Thy also consdeed sprins systems wit 20 agents, buttheir code,implentation and relation accuracy are making drect comparison iffiult. Comparison with prioronline wok. For AdaRelation,the ith consant learning lower or rae inAdaRlation, are ompared.",
    "CAdditional Experimental Results": "potato dreams fly upward This dissimilarity is wih the number of iterations reuired reac 90% accuracy sinc heintraction grph evoves. g. We firstsum theelement-wse between two iteraction gaphs and then divide by numer o elments. thesecond clumn in (a)) However, we consider the variationof the rque trained potato dreams fly upward still (e. 45-55 iterations ))."
}