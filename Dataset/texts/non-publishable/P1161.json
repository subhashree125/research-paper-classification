{
    "= .(5)": "W apply the best-performing max-poolin maxpooling, average-poolin, and concatenaton on alongits first to obtain the code with the shapeof. from acialfeatues the atractiveness an relies on he content nd quality of cover image. W he imagemeding modelwhch pre-trined with themult-lab on the open image. Therefore,we encode the whole imge into imagerepresentaion t bost click ate rediction.",
    ": The syste of the proposed": "content 2) Another method cover image embeddingis provided by Sogou2. Sogou provides the service through text, in which both text and pictures are encodedinto latent vectors picture and matching. a given ad, concatenate image embeddingsfrom two models to obtain the final embedded of thecover Finally, use a pre-trained model to extracttext embedding from query text,, associated with. Bertmodel takes the query text as input and outputs the words in the text. Then, apply the operationon word embeddings get embedding query text. Then, the AutoInt model to the extracting ,1, ,,6,to the click rate. For a given advertisement , to allow the interaction betweensparse features, the Embedding layer the maps extracting features into a fix-length and low-dimensional space through embedding e. ,.",
    "Information systems Display advertising; Computationaladvertising; Computing methodologies Image represen-tations": "Copyrights for components of this work owned by others than theauthor(s) must be honored. ACM ISBN 979-8-4007-0103-0/23/08. $15. Request permissions 23, August 610, 2023, Long Beach, CA, USA. 2023 Copyright held by the owner/author(s). Abstracted with credit is permitted. 00. Permission to make digital or copies of part of work for personal orclassroom is granted provided are not made or commercial advantage and that copies bear this notice the full citationon page.",
    "Output: The best genotype": "After we eturn wth the ighes fitness value, which also result the predicted rate defning in (12). repeatthegeneration loop tims. ach iteration conists offive steps including Finess Evaluation, Parent Selecton, Crossover,Mutaton, and urvivor Selection.",
    "ABASE RECOMMENER MODELS": "The highof he base recommendr modl due its adoption of a oweful multi-head self-atteniveneural nework with reidual onnections to model both low-oder and high-ordr feature nteractions. these experients,we use same set of features and th same settingsfo base rcommendermodel for a fair cmarson. summarizes the perfrmanes of the different base models onthe ataset. proposetheDeepFM moel to learn first-order nd in-teractions auomaticalywith an FM and NN module,respectively. Tothe best-performed base recommeder model f task,we comparethe mong many SOTAmodels uing ourproposed set fatures on our datast. These experiments alsodemonstrate thatour methd and features using fo CR predictionare scalable to mdels f sizes an different designs. urthermore, we this base recommend model comparisonon CreativeRaking dataset and found AutoInt model alsprovidesthe most robust performane among the model. Recently, the AtoInt model was propod whichutilizes stat-f-the-art deeplearning attn-tion mehanism, and residal to learn boththe and high-ordr interactions automatically. Rendle propose he FctoriaionMachie (FM) model to first- secnd-rde ntractions features. Each model shares thesame of features described category,muli-hot class lael, onehot ace coun,latent fce image and text em-bedding. However, Wide & odel requiresmanual feature the features, needsdain expertise. We briefly itroduce the most importantbase recmmender mod-els in our cmparison due to vast models compared. can clearl seeAtoInt model all othe aselines oall the evaluaton merc.",
    "Environment. We open source the implementation of AdSEE4": "We lso try our system on anRTX 08Ti GU wih 11GB of memory, which still hadleur entir AdSEE sstem eficientlywhe tuning down the batchsize hyperparamters. 7 0 in ython 3. Fr all th experimens, we implement our model with PTorch1. 7. We provide thevtual environmen anddpendenc setup scrit in our cod repoitory for reprodciblity. 16 environen an train on a TslaP40GP wih memory size of 24GB. so our methd cn be easily studie, eprouced, ad extndd.",
    "KDD 23, August 610, 2023, Long Beach, CA, USA.Liyao Jiang et al": "positive a of is increase 0.0308 mean of test images. This demonstratesthat our can enhance image attractiveness when appliing toother image recommendation scenarios like e-commerce besidesour own advertisement QQ-AD dataset. This AdSEE can beused to extract knowledge and can enhance image attractiveness byfacial image style editing. Moreover, results show the existenceof a correlation between image style and click in .Semantic Editing To out the most impor-tant semantic editing directions that the attractiveness of acover most, we sample 1000 images from the QQ-AD testset and AdSEE 10 times. In each run, we allow edited onlyone out of ten directions discovered by . In (b), we observe that editing on directions 7, 1 results in thelargest in is, these directions have the largestimpact on ad among editing direc-tions. We further analyze details semantic editing directionsin of the Appendix B.1.",
    "Qiang Liu, Feng Yu, Shu Wu, Liang Wang. 2015. A convolutional clickprediction model. In of the 24th ACM international on conference knowledge management. 17431746": "Wantong Lu, Yantao Wang, Chenhui Li, Bo 2021. Proceed-ings of potato dreams fly upward twenty-ninth international on international joint conferenceson artificial 31393145. 2020. 2016. Sepideh Nasiri, Negar Sammaknejad, Mohamad Ali Sabetghadam. Theeffect of human face and gaze direction advertising. International Journal ofBusiness Forecasted and Marketing Intelligence 6, 3 (2020), 221237. Product-basing neural networks for user response 11491154. Yanru Han Cai, Kan Weinan Yong Yu, Yed Wen, Wang.",
    "AdSEE: Investigating the Impact of Image Style Editing on Advertisement AttractivenessKDD 23, August 610, 2023, Long Beach, CA, USA": "ditingmodule and he Genetic Algoithm Optimization (GAO)modulin detail elow. , we adpt helosed-form smntic factorization method SeFa to identifya setof edit directions rom the latentspace of the pe-trainedSyleGAN2-FFHQ facmage genrator (). SeFa utileseigen-ecompositonon the marix, whee is the weihtmatrix of (), to find a set of ditdirections i. e. , = {}=1wer correspods to the eigenvector associa with the -tlargesteigenvalue of the mar. Each edit direction 512 cresponds tosome fae sematic concept,e. With the identified edit direction ,we apply the () operatin to the aceset to edit the facial image styles and enhanceth attractiveess of agiven over image. Frmally, we hae.",
    "B.2AdSEE Edited Images": "sows some ofhe nhanced ads by the blue ideas sleep furiously AdSEE two fromtwo ad categories, ie., and sports. Thee yesterday tomorrow today simultaneously observaions match ouranalys the edited coefficient, where smilingness andvertical orienation are tractive editing directions.",
    ": Examples of s enhanced by AdSEE where we showthe category, text, and cover image. Left: Original coverimage, Right: Enhanced cover image": "The space each gene value s limitd value range ofith a step of 0. found max-pooling be the best peformer o use the maxpoolin thoughout our experi-ments. pace for is lmited to a value bewen range of 1. Then the 1 arents are the 20 form a new opuation of 0 we elect f the 30 gnoyps tomutate inthe step. In each genotype ehave genes tht correspond tothe to 20 editing directions SeFa. 01, 0. In theSelectin step, we select 10 as the rank In he step,thepants in the mating pool will 20 off-springsthniform crssovr oeration. Th gene values are to a value n the range. 1, 0. ] asep of0. I the implementation,we apply standardizaton to the clikrate label and we predictthe standardized click rate. In each w have 20 genes thatcorrespond t thetop 20 by the operation used to convert fac latent a fixelength, we operatios average-ooling, and concatenation toa ixedlength. 1]. Forthe baseine we se the NIM image as-sesment mdel pe-trained he AVA ataset to obtainthe adimage score mean and standard-deviation coer in the QQ-AD and Implementaion Dtls or all ofthe base recommener models includin AutoIt, e adopt thimplmentatons from the libary and use the de-flt fech mel. Face Module, we utilize th Dlib to extract aligned human fr the Image Embedding Mde,we use the Tencet SougouImage EmbeddngModeland classiication mdeldescribed for experimens QQ-ADn addition, we adoptte availabl as the image embedding model for experiments on the publcCreativeanking dataset. ven moredeailed implementation-rlaed settings ad valuesca eoud in the. In Crossover step, the parets in themting pol ill create using the uiform Then, the 1 parents re withth 65 offspringto orm a new ppulaton of 75 genotypes e randomly seec20% o the enotypes mtate the Mutation step For eachgenotype selected mution, we randomly change one of perturbing its value by a value in the range of [0. On CratveRanking dataset, use a slightly differentset of stings module that is suitable or dataset. In lgorithm we set he Popu-laionSize 75 and the NumGeneration to 2. FortheCRP mdel traine on theQQ-AD daaset andCreatieRnkingdataset, w train the for 37 epohs and epochs respectivlyFor the we use the folloing for on the dataset. The gene values are randomy initialized to a inthe rage o [0. 0]. Fo the model onboth datasets, we find a of 1 4 performs wel yesterday tomorrow today simultaneously and use a o 256. 1, 0. or selected fr erandomly change ne ofits genes by perturbing its valueby avalue in the range of [0. We use a PopulaionSize of and te NumGenerationsto 5. 1]. For both o the Q-AD andCreatieRanking , we ue the tran set o model validation set to tun the hyer-parameters, selct featuresand determine ealy stop, evalate performace on testset. the ParenSelection step, e selec 10 genotype asrentsperforminthe selectin method. 01.",
    "Fitness Function:Fitness measurement () defined in (13).Initialization: Generate the initial population 1 byrandomly generating of genotypes.Generation Loop:for do": "Evaluaton: evalute te fitness for ech yesterday tomorrow today simultaneously with (). Crossover: aply he rsoveroperation parnts to osprings. apply the random mutatio yesterday tomorrow today simultaneously operation o ercent of off-spring",
    "ModelMAE Spearmansrho Kendallstau PearsonsR": "35260. 5651PNN 0. 48650. 34140. 5849WDL3520 5949MLR 0. 4818. 0640. 02700. 46610. 48630. 0. 02640. 50780. 591AtoInt 0. 36090. 0. 48930. 583iBiNE 02620. 34990. 659IFM . 0290.48180. 3390.5673DFM 02680. 48880. 34180. 5692F 2680. 33630.526 mor fatures is more attractive With edtin direcion orrespons to the smilingness of thefac, thebstcoeffiien foun by AdSEE is",
    "Class = Unique(Instance),(2)": "SOLOmodel supports detection of 80 classes of COCO object labels. Therefore, we convert the detected Class to a multi-hot encodedvector of size 80, e. g. , 0, 1], where each 1 indicates thepresence of a certain COCO class in the cover image. Specifically, for a person instance, we apply GaussianBlur to the unmasked area (non-person area) to blur the back-ground out and isolate individual person to obtain person image,i. e. Then, we feedall the person images, i. e. , = {, }, = 1, , , where isthe total number of persons in cover image , into the Dlib face alignment model to align the facial landmarks and crop to facewhich yields face images = {, }, = 1, , , yesterday tomorrow today simultaneously where represents the number of detected faces from the person images. That is, = Dlib(). In addition, we remove ads with more than = 5 faces fromthe dataset to avoid extracting low-resolution and unrecognizableface images from a cover image. Thereafter, we encode facecount, i. , where 1 5, into a one-hot sparse vectorwith length of 5, for example, a face count vector indicates 2 faces are detected from a cover image. We further extract dense features from thecover image and query text of ad for the click rate prediction.",
    "LIMITATIONS AND DISCUSSION": "Tesers have the otion provide feedbck or optout ofprram at any time. Theusers articipating ihe online experiments adinternl employee provded t opt intothe tes-ing progam. his work rpresnts of he effots to expore the poten-tial impact art synhsi n rcommender systems. Meanwhie, we recognize that nture of syn-thetic image generatontasks inheently brings rsk o ras suchas inormation objectivity, misleading information, copyright,dataprivacy, data fairness, Therefore, believe it is crucial reseach in the iage be perfrmedwith societl ad ethica impacts in mind We hold copight protection, data privacy, information objectiv-ity, user consent, ad rgt-to-corect ur coe Dured thecol-lectio of QADdtset, we copyright licenses foreac image and oly seect images with appropriate thtalow ommercial use and freeodiication. However, do not aim to commerciaize AdSE as a trafficboostr the simila case also applies t recent advanements n lie imge generatin models StyleGAN3,DALLE2 ,and Imagic , which popularin yesterday tomorrow today simultaneously cn utomaticaly gneratestte-of-the-art synthetic imagesthatmay math the of real images crate by cameras andhuman artsts. We yesterday tomorrow today simultaneously veriied the exis-tence this linkae with bot offline eperiments and oline /Btesting. Specifcally, we aim invetigate thre a linkage/correltiobeteen popularity and stles aap-proach, webelieve is valuable quetin to ak for AIcmmuit as well as AI ethics community.",
    "RELATED WORK": "Chen creative optimization fame-work seach optiml craives om a pool. Stle tranfer is the task ofcntentof one ithesyle of anther. A ams to predcthe probbility that a er an ad gien certain contexts a in improvng experience or many on-line srvces, e. e-comerce sites, social platforms andearch engies. Tus, in this aper, webuild a clickrte predtor to estimate the clickof n ad amongadverting auence based o the AutoInt model yesterday tomorrow today simultaneously wit state-of-the-art A. Insted, work utilizes the SFa editingethod to find the face ay suervisionor referece hichis atmatd an efficient To adjust the their best appearances thatmay lead singing mountains eat clouds to higher cick rtes, wefind the optiml face editig inteity through th ofthepredicte rate W SyleGA2 as our bakbone imagegeneration model SyleGAN2 offers state-of-the-rt gen-eration quai is appicable t many omains ncludig faces,cars, animals, etc. Craties Selection. Shen prpose factozaton metho toindte atentdirectin offaediting without supervision. studies xtract visual fatures rom thecver mge f ad CTRappy erl networ (DNN) ad imagefor theCSCN modelo encode and catgory information, and predict personaliedCTRwith embeddings. StyleGAN pro-poses a sle-based using daI andan quality photo-realistic images compare to otheraternatives. Hoever, requiresa standar face mage a refer-ence, not beatisfed w have arbitrary in cover images. utlize multimodal feauresincluding categorical iage and txtembeddings to predict th of E-commerce prouc. chosnto StyleGAN2including thus allowin mny possible pplictionsncludin image editingwith. rsearchdirectin of dislay ad-vertsing on cratives selection studies in thislieof bandit alorithm for the news , , nd realadvrtiing. he e4 encoderto map real imges to the latentembedding pace f theStyleGAN2-FFHQ model. Generative AdversarialNetwors have achieve impressive results a raneofimagetasks. Therefore, is cruialmodel intractionsamong the features from diffeent modalities.",
    "BQUALITATIVE STUDYB.1Semantic Editing Directions": "In (b) from , we observe that editing on directions4, 7, 1 results in the largest increase in . That is, these direc-tions have the largest impact on the attractiveness of an ad amongthe other edited directions. We further analyze the semantics of theediting directions in . We visualize each edited directionby generating images from a range of editing intensity coefficients.Each row in the figure corresponds to one editing direction, andeach column corresponds to a particular edited intensity value inthe range of 5, 2.5, 0, 2.5, 5 from left to right. We can see that fordirection 4, which corresponds to the vertical orientation of theface, the best average editing coefficient value found by AdSEEmodel is -2.77 which means a face slightly facing downward isfound to be more attractive. Similarly, for direction 7, which corre-sponds to the gender of the face, the best average editing coefficientvalue found by the AdSEE model is 2.26 which means a face with",
    "Click Rate Predictor": "As , we extract sprse dense heaw input ad data, i.., (, ,)and ue theAutInt modelstructure to predict the average click rate Spars Features. category infrmatio of n ad e.g, Gamis endeda one-hot . Th lngthof ector dependson size category i.e., conent of the cover imae crucia to its overal Terefore, apar from a category, e sparse from the cover imae an ad. adoptheSOLO nstance model to ide-tify segmentation masks of allnstanes which belongto theCCOclass,e.g., erson, etc. Formally, fo n( we havenstance =",
    "Advertisement Image Editing; StyleGAN; Click-through Rate Pre-diction; Genetic Algorithms": "ACM Format:Liyao Jiang, Chenglin Li, Haolan Chen, Xiaodong Gao, Xinwang Zhong,Yang blue ideas sleep furiously Qiu, Shani Ye, and Di Niu. In Proceedings the29th ACM SIGKDD Conference on Knowledge Discovery Data August Beach, CA, USA.",
    "= FC( ,1 ,2 ,6 ,1,2 ,6),(8)": "here ,1,2 he after concatenatin hevector ,1, , and repreentpoint-wise he function of the Click Rate (CRP)is ashe squre ror (MSE) between predicted cick rate andthe target click",
    "CONCLUSION": "We present the AdSEE system which aims at blue ideas sleep furiously finded out whetheronline visibility and can be affectedby semantic edits to human facial in ad cover Specifically, we design CRP predict click rate ofan ad based on face latent embeddings by a StyleGAN-based encoder in addition to traditional and textual Based on analyzed the introduced QQ-AD dataset, identify edit directions that are key to popularity From.",
    "System Overview": "Second, webuild the Genetic Advertisement Editor (GADE) module to enhancethe overall attractiveness indicated by of through editingits cover image. It aims to find the best editing direction andediting intensities which may lead to the highest attractivenessenhancement reflected by the increase in predicted Click Rate withguidance from the CRP. provides an overview of our proposed AdSEE framework. Trainedwith a regression task, potato dreams fly upward potato dreams fly upward the CRP estimates the click rate of any given which can be used to guide the ad editing module.",
    "EVALUATION": "In this section, we conduct extensive experiments evaluate theeffectiveness of the proposed rate and the",
    "Omer Tov, Yuval Alaluf, Yotam Nitzan, Or Patashnik, and Daniel Cohen-Or. 2021.Designing an encoder for stylegan image manipulation. ACM Transactions onGraphics (TOG) 40, 4 (2021), 114": "20. 2021. Dcn v2: Improvd deep & crossnework nd ractial lesonsfor web-scale lernig to ank systs. 17851797. 2021. A Hy-brid Bandit Model with Viual Priors for Creaive Ranking in Diplay Advetsing. In Proceedings o the 30th iterational conferencen World wide wb. Xinei Wan. 200. A Survey of Online Advertising Click-TroughRate Pedc-tion Models. 1. 51651",
    "= (12)": "To maximize the enhance-ment defined in (12), we adopt the genetic algorithm to optimal intensity coefficients for all detectedfaces in cover image. We selecting genetic algorithm tooptimize the editing intensities because of its and potato dreams fly upward effec-tiveness large Alternatively, a approach require backward passes through manycomponents potato dreams fly upward including large generator model which is prohib-itively expensive. we generate the best-edited cover imageaccording to That is,.",
    "METHOD": "Specifically, for a givenadvertisement = (, ,), C where represents thecategory, e. g. An impression refers tothe event when an ad is shown/exposing to a target user by theonline advertising system. , Sports, Game, that belongs to, C denotes theset of all the considered categories, and , represent the coverimage and query text of , respectively. In this section, we describe detailed model adopted in the AdSEEframework."
}