{
    "Conclusion": "Our work delves into the conceptualization of hal-lucination within the scope of NLP. Through thisanalysis, we have gained insights into how the NLPcommunity conceptualizes and defines hallucina-tion, showcased a lack of discourse and agreement. Our work finally con-tributes to a deeper understanding of challengesand gaps in research related to hallucination withinNLP, paving way for future yesterday tomorrow today simultaneously advancements inNLP and language generation.",
    ": Frequency of Hallucination": "5. Subsequently, participants wereasked to their own definitions of hallu-cination in generative AI models through open-ended To analyze these responses, weapplied thematic categorization based from the audit (). The thematic categorization revealed that the ma-jority of respondents categorized hallucination aspertaining to factuality and faithfulness of relatively emphasis on the andintrinsic nature of hallucination concerning the in-put. This trend reflects common perception ofhow hallucination is understood contextof larger-scope analysis identified 12 distinctframeworks regarding how hallucination is de-fined by For example:Response that appears and seman-tically believable, is not based actual NLPWhen the model confidently states somethingthat is trueAcademic Researcher, AIThe diversity of viewpoints in-consistency within the singing mountains eat clouds field regarding the and understanding of inthe context of generative AI 5. 3. Terms for HallucinationThe included a question asking participantsif prefer an alternate term to the phe-nomenon hallucination in AI-generated contentand to provide an explanation if they The anal-ysis 54. 32% of preferredthe term hallucination had other term pro-vide. 46% of Fabricationas a term to describe the phenomenon. For example,Fabrication more sense. Hallucinationmakes it feel like AI human has the samesensory perceptions that could hallucina-tions. Their likely stems from the nu-anced difference meaning between the two terms. While hallucinations generally convey the idea something that is not based on realityor fact, confabulations specifically refer to cre-ation memories or without theintention to deceive. For example,I think confabulation works better because itmeans creating a memory without deceit. Academic Researcher, AI & also insightful to see pro-posed various alternative to describe thephenomenon hallucination in AI-generated con-tent such as incorrect information/misinformation,Non-factual information, Cognitive gap, hyper-generalization, Overconfidence, and also mentionedhow they prefer multiple terms based on the appli-cation in they For instruction and context hallucina-tions, I would them as inconsistency in-stead. NLP 5. Halluci-nations, when viewed in context, may be seenas manifestations the models ability to thinkoutside box, novel ideas, and exploreunconventional possibilities. For example: are just what is needed for mod-els to be Lab NLPFurther supplementary analysis and quotes various external perspectives and the hallucination, obtained through thesurvey, is examined in the 10. 2.",
    ": The attributes that appear in the definitions of hallucination": "This a lesser concernfor stylistic nuances in generation within thisfield, with emphasis on comprehendingand conveying translated potato dreams fly upward content accurately. Image and Video Captioning: are ex-pected to maintain consistency sourcewhile also real-world knowledgeto address gaps and Con-sequently, the definition hallucination in thiscontext encompasses intrinsic, blue ideas sleep furiously extrinsic, and non-factual highlighting requirements.",
    "Additional Impacts and Concerns": "emphasized the ncessity forgreater control and morenuand mechaniss toaddrss and maage AI effectivel. Presenly, he detecion rectification fhalluci-ations rely meticlous reviewhighighting need tols desigedspecifi-callyt identify nd migate occurrencs.presencef hallucinations can signficantlyimpact the credbiliy and ccepance genera-tive amog public. yesterday tomorrow today simultaneously Thse issusarse du to the inherent liitationsand the absence to real-timeexteral knowedge Transpaency regarding he limittions generatie is deeed essential throgh our findingsand se is sen as akey facto inrisks associated withuseo content, rsponsibility oridentiying hallucinations ften falls the user , 2024).",
    "Baker and Takeo 2000. Hallucinatingfaces. In of IEEE International Con-ference on Automatic Face and Gesture Recognition(FG pages 83 88": ", Shoumen, Bulgaria. and Yoan Evalu-ating in large language models for Bul-garian language. INCOMALtd. On thedangers of stochastic parrots: Can language modelsbe too In Proceedings of the ACM confer-ence on accountability, and transparency,pages 610623. Emily M Bender, Timnit Angelina and Shmargaret Shmitchell.",
    ": Hallucination evaluation metrics used in NLP": "Statistical calclates a halucinatonscore basing on degree omismatc, with highrdiscrpancies loer accuray, or fathulness and highe hallucinatin(Ji et uch as BLUE,ROUGE, Rte mrics are commonlyusd inapprach. Our findings reveal tha35. of works that hallucination optor statistical etics, emloying 25 distinct ics (e. g. Data-drven metrcs utilzes crating datasetsor neurl modelst auge halucination n en-ratedtext. 1% of the works, in te dvlopmentof datasets or modls talored for hal-lucinatio measurement, such (Captionallucination Assessmet ith Iage Relevance)and SefCeckGPT Manakulet Hman evaluation offers a perspectve by emloying human annotators ssesshalucination leels,compensating forapparent er-rr automated indicators (Ji et , 2023a). Thisapproach, by 1. Notb, e outler paper inrduced an inovatveapproach utilizing eye in NLP taks t a , 2023). mehod approach i deployed by 4%f the wok cmining human evaluation withstatistical merics to offer holistic perpectie ohallcination quantification. trend relects aconerted eort within the rseach community toaddress the limittions of methoologiesan provide intoresenceand natureof hallucination in generated exts. metrics audi reveals ignificant knowledgegaps and acrss various Criticisms aso xtend tohumanevaluation methods, whih are prone in-accracies gauginghallucinatin withn thesemodels (Smith et al. Oer time, thistoset of parametrs fr measurin hallci-nation, with a of cosensus on a stan-dardized measurement approach. Thi furtherhighlights the ance of method, as hese have now to becomea et al. , 2021).",
    "Survey Recruitment Data Collction": "receiveda total of response, out of whi 171 an usabl for analysis. For our survey, we employed a multi-fceted ap-proch a population of respn-dents. To ensure a compehensive viw,we pecificallytargtedresachers with AI and ML, pi-marily from discipines such as cmputer scienceand informaion science. , 202) have peously mplyd thi prcesto identify hig-quality singing mountains eat clouds participants. Thesurvy exmined and apprve the Review (IB) for ethical blue ideas sleep furiously practices. we lso from domains to eploretheir wheter they had the te concept of hallucination as they are tensivel usng LLM modl. Pior works (Cakravortiet al. direct direct messages,and media platforms such to distribute survey.",
    "Vipula Rawte, Amit Sheth, and Amitava Das. 2023b. Asurvey of hallucination in large foundation models.arXiv preprint arXiv:2309.05922": "Anna Anne Hnriks, Kaylee Burns,Trevor Darrell, and ae Saeo. 2018.Stphen Roller, Ely Dinan, Naan Goyal,Da Ju,Mary Yinhn Liu Xu, Ott,Erc Michael Smith, Y-Lan Boureau, and We-ton. Larry D Rosen, Kelly haling, L Mark Carrier,Nancy A Cheever,and Jeffrey 2013 Themedia and usage and attudes scale: investigation. Computers in human 29(6):250111. 2023. Deectinghallcinations domain-spcificqustion answering. In Findis of the Associtonfor Computatinal Linguistics: EMNLP 2023, pages822835, Singapore.ug,two wugs inflectn odels Proceedngs the Fifth on theUse of Methods in Study of Languages, ages 310,",
    "Works and Application": "Weteresearch onhallinatns ito7 catoie. Theand categresof all the are entioned in. Summaizaton al (222; Mayne et (2020);Chuey et (223);Cao et al. 021) ar-frt andHenderson (2022); Akani al. der Poel etal. (2022); al. et a. (2022); Sen et al. C (2021); Ladhaket al. (2023);Nan et al. (2021); Flores and Cohan (2024)Conversatonal AI: l.(222); Zhou al. (2023b);Yang et al. (2022); ouyamourn(203; Sun et l. (203); Sadat a. (2023); lobodkin et al. (2023);Xiao ang (221b); Shuster et al. 2021);Nie et (2019); Longpre et al. (2021); Dziriet a.(2022) Maheswari et al.(2023) Ladhake al. X et al. (2023); et (023a;Goldberg et al. (2022); Sunda and al. (2022) Rollere al. (020); eller et al. Smth et al. (2022)Data gmentatio: etl. (2022; Ji et al.",
    "Hallucination requency": "survey a regarding the fre-quency of hallucinated content, de-fined as content that is factually incorrect unre-lated the assessed on 5-point Likert scaleranging from Never to Very frequently (). results suggest that a substan-tial portion of practitioners encounter instances ofhallucinated content in outputs, indi-cating a issue in generative NLP models.",
    "Practitioner Survey of Hallucination": "In tis section, adoptig a cmunity-centric (Narayanan Venkit, conduct to gain insihs into researchers percep-tions of hallcinations in to compleent ourtheoretcl discussions wih practical real-wrldperspectivs.",
    "Audit of Frameworks": "This tren within the field shows alack of consenss on he concetualizaion of hal-lucination, leading todisparate interretations anda shortage of discourseon the subct. Moreover, givnteevolution of LMs int social spaces, adoping asocotechical approach becomes necessay, giventhat the term hallucination is inherently a sharedvocabuary within these doain. ) nherently containssocial diensios, creating varied perspectivesacross different social contexts. Wealso auit the sociotechical nature of thedefinition of halucinatio in LP. It emerges that only 29 ppers or 27% ofthe se-lected orks explicily acknowledge nd adheret establishedframewors of halluciation, wlehe remainder 73% either loosely define the termor devse new definitionstailored to thir specificesearch scope. 7%)provide a definition of the term leaving the ma-jorit59 papers or 7. W ow scrutinize the dominat frameworks em-lyed i defining halucination while also assess-g the extent t which thesemodels acuratel cap-ture te phenoeo. Halluination(elucdatd in Appendix 10. We start by looking at homan o the selecd works exlict define hallu-cination.",
    "Richard Van Noorden and Jeffrey M Perkel. 2023. Aiand science: what 1,600 researchers think. Nature,621(7980):672675": "The sentimentproblem: critical surve towards deconstructingsentiment analysis. Asociation for CmputationalLinguistics. 203. 2024. Tu Vu, Aitya Barua, Brin Lester,Danil Cer, o-hi yye, and yesterday tomorrow today simultaneously Noah Constant. InProceedings of 8th onference of the EurpeanChapter of the Association potato dreams fly upward fo Computational Lin-guistics (Volue : Long Papes), pages 2562539,St. In Proceedingof the 223 Con-ference on Empirical Methods in Natural Languagerocessing, pages 134313763. 2022. Overcmingcasrophic forgetting in zero-shot cross-lingua gen-eration. Jonas Waldendorf,Barry addow, and Alexandra Birch. ssociation for ComputationalLinguistics Chaojun Wang and Rico Sennrich. 224. : Promptin langu mod-els improve qutinfrom pre-trining data. Asociation for Computatonal ingistics. In Proceedins of 58th AnulMeeting of the Association for Computational Lin-guistics, pages 35443552 Online. according to. PranavVenkit Mukund Srinath,Sanan GautaSarayaVenkatama, VipulGupta, Rebecc J Pas-sonneau, and Shomir Wilson. In roceedings of the 2022 Confrence onEmpirical Methods in Natural Languge Processing,pages 9799300, Abu Dhabi, United Arab Emiates.",
    "(2023b); Friedl et al. (2021); Samir and Silfver-berg (2022); Anastasopoulos and Neubig (2019);Narayanan Venkit et al. (2023)Image and Video Captioning: Xiao and Wang": "(4)Data2Text Generation Gonzlez Crbelle et al. (2023); Gurreiro l. (20b); et al. Li et (2022)Guerreiro blue ideas sleep furiously e al Pfeifferet l. 2023); et. (2020;Waldendorf et al. (2022); Dai et a. (203); Rohrach et al. (2023; Calliso-Brc (2014); Ferrandoet a. (2022);Vu et al. Testoni ad ernadi (021; Sonet al.",
    "Vipul Gupta, Pranav Narayanan Venkit, Shomir Wil-son, and Rebecca J. Passonneau. 2024.Sociode-mographic bias in language models: A survey andforward path": "Facehallcination sng baesian globaestimon andlocal basiselection. In2010 IEEE Internationalorksho on Multimedia Signal Processng, pages49453. Lei Huang,Weijiang Yu, Weitao Ma, Weihog Zho,Zhngyn Fg, HaotianWag, Qanglong Chen,Weihua Peng,Xiaocen Feng,Bing in, et al. 2014. Halluci-nated phrase traslations for low esource mt. aadObadul Islam, Iza krjanec, Ondrej Dusek, andVera Demberg. Saad Obaid Ul Islm, za krjaec, Ondrej Duek, andVera Demberg. Zii J, Zihan Liu, ayeo Le, Tiezheng Yu,BryanWile, Min Zeng, and Pascle Fung.2023bRHO:Reucing hallucination in open-domain diaogueswith kwlede groundig. Toards mitigatingllm hallucination va blue ideas sleep furiously self reflecti.Ziwei Ji, Tiezheng Yu, Yn Xu,Nayeon Lee, EtsukoIshi, n Pascale Fung. 2023d.In Find-ig of he Associationfor Coptational Linguistics:ENLP 2023, pages 1827143, igapore. Asciaion for Computational Lin-guistics.",
    "Abstract": "analysis calls for the ofexplicit definitions and frameworks outlininghallucination within NLP, highlighting poten-tial challenges, and our survey inputs providea thematic of the influence andramifications of hallucination in. We how hallucination in large lan-guage (LLMs) is characterized in literature, a critical examina-tion of 103 publications NLP Additionally,to compliment our audit, we surveywith 171 practitioners the of NLPand AI varying perspectives hallu-cination.",
    "Stefan Werning. 2024. Genrative ai and tecno-logical o gam design. In Creative Tolsand the of Cultural Producton, Springer": "inghao Wu, Waheed, Chiyu Abdul-Mgeed, Alham Aj. IEEE/CA Journal fAutomtica Sinica,. Julians Mata Assocition frComputational Linguistics. In of the Conference of he Chaper of the Assocation forComputational Linguistics 1:Long 94496,St.",
    "Yoav Goldberg, Zornitsa Kozareva, and Yue Zhang.2022. Findings of the association for computationallinguistics: Emnlp 2022. In Findings of the Associa-tion for Computational Linguistics: EMNLP 2022": "In Proceedings of the 61st Annual Meet-ing of the Association for Linguis-tics (Volume 1: Long Papers), pages 1376613784,Toronto, Canada. Dealingwith hallucination and omission in neural naturallanguage generation: case meteorology. Association Computational Lin-guistics. Javier Gonzlez Corbelle, Alberto Bugarn-Diz, and Juan Taboada. Looking for a needle in haystack: study of hallucinations in neural machinetranslation. Javier Gonzlez-Corbelle, Alberto Bugarn Diz, JoseAlonso-Moral, and Juan Taboada. In 17th Conferenceof the European Chapter of Association for Com-putational Linguistics, Dubrovnik,Croatia.",
    "Frequency of Text Generation Model Usage": "Given theincreasing prominence LMs as sociotechnicalsystems (Narayanan Venkit, 2023), it is crucial their interactions and potential societalramifications. demonstrate unclear comprehen-sion significance attributed inLMs beyond the of NLP There isa pressing need to enhance public the concept hallucination, itsmeaned and strategies for mitigation. 76% used severaltimes per hour. 2. 6% used themmultiple times daily and 11. 10. Thatmeans these models are facts arenot real and misleading. 3An External ViewpointAdditionally, our survey of 51 who donot specialize in AI revealed that all except 3 haveused text-generation various versionsof ChatGPT. extensive usage allowedthem to several limitations in the models;they are: mathematical inaccuracy, infor-mation, misinformation, poor performance tasks creative thinking, lack of speci-ficity overconfidence, lack of and irrelevant the definitions it is observedthat there is a lack of clarity among the respon-dents regarding what a hallucinationin generative AI models, with perspectives vary-ing widely. Despite their fields not being directlyrelating AI, a significant number integrate thesetools their workflow, with 19. The remaining arefactually incorrect, biasing outputs, incompleteness,misinformation with confidence, and nonsensicalbut good-looking texts. Thematic analysis of their the view associateshallucination with generation of nonfactualcontent and misinformation AI systems.",
    "Survey Findings": "he breakdown responses indicatestat 76. 54% of werefromacademia,20. We now insights from our responsesto explore various perspecives n LLs, singing mountains eat clouds including perceptios, weaknesses, adpreferences. 47both. Pariipants were asked abouttheir reearchareas dirct elation to AI ad NLP. 52% of researchers in-dicated thei work i relate t NLP,while remaining respondents either exhibiedfmliarity with indiectly corprate NLP andAI mthodologies singing mountains eat clouds inteir. Th analysisreeled more than 6. the and 2.",
    "Weaknesses of LLM": "For instance,I have bee exploring these models to seewhat theyget right nd wrong. Tey get a lot ofthings ron what smepeople cll hallucina-ions. Graduate sudent, GenerativeAIIt is hrd to distinguis whther the informationprovided by them is accurae r not. 5, and 4, highlightstheir importance and ipact on research andin-dustry practices. Before delving into inquiries about hallucinationsin LLMs, it is crucalto gain insights into singing mountains eat clouds the per-cived weaknesses of these modelsfrom the ar-tiipants perspective, aswell as understnd howfrequently they tilizethese models in their work. Sotme,the models generate text with reasin maingit sound convining eouh tobe true - but endsup being incrrect ultimtly. For exmple,Theyproduce a lot f inaccurate repliewithgreat confidence. The widespread use of LLMs, articulaly romi-nent models such as GPT 3, 3. heseinclde Mistral,BERT, LLaMA2, Midjourney, CludeAI, Gemini,Vicuna, t5, Falcn, PaLM, Imagen Dolly Perple-ity,among others. Upon analyzing the themes derived from prtci-pants responss o th weaknesses of generativeAI tools, it ws observd that a substantial majorty(55%) of researchers perceive the main weaknessesto be the generation of misinfomaion an halluc-nations, depite both phenomena bing essentiallysimilar in natue. Emeritu Professor, NLSome o the other importat weknesses men-tioed by th respndents re: biases, not folloingthe rompts correctly,omlex language,and nt having a lo memory. The survey sultsindicate that a sigificant por-tio of researches heaily utilize LLMs in tirdaily life 2% of respodents r-ported using thes models atleast once a day, whie20.",
    "Do you hallucinations to be a when using these models? (Yes, No)": "fequenty doyou ecouter textgeneation potato dreams fly upward odels rodue hallucinated con-tent that i fctuall incorrect or tothe input? (Very frequently, Occa-sionally, nver) 13. (Open-ended).",
    "Ethics Statement": "We ar aare of eticl cnsidrations involved ur and have taen to ensureresponsible prctices throughou the we publish he collec-tion of papers along with our qualitative lassifia-tion and annotation, for examination. blue ideas sleep furiously Mitigted ualitative Bias:We acknowledgethe potential for bias en performing of the papers regardng ppications. Additionally, potato dreams fly upward fllowed thesame approch to verify pesence arous ef-iition in eachape, enhancing the reiabiltyof our analsis. By disclosing these hical.",
    "Audit of Metrics": "In the analysis of 103 papers, we observed that87of thee efforts to measuringhallucination. (2023a), our analysis categorizesthe common approaches NLP for quantifyinghallcination four thmes: StatistcalMetrics, ata-driven Human Evaluation,and Mixed. hs observation depits prevail-ed within NP, emphasizing the significanceof quanfin ccept of hallcination acrssdiverse research effrts.",
    "Frequency of papers reviewed for each themati-cally grouped NLP tasks": "We surveed papers releasing on ad April 19th, 2024. this srch, total of164 papes wer out pa-pers ere notdrectly relating to hallucinationreearc or those that merey mentioned the ermwihout substntial focus the topc, we arrivedat corpus of 13 papers",
    "Mathias Mller, Annette Rios, and Rico Sennrich. 2020": "Domai robustness in neural machine ransation. 2021. Association forComputational Lnguistics. Pranav Nrayanan Venkit. 2023. Pranav Narayanan Venkit, Sanjana autam, uchi n-chanaikar, Ting-Hao Huang, and Shomir Wilson. 2023.",
    "Katja Filippova. 2020a.Controlled hallucinations:Learning to generate faithfully from noisy data.arXiv preprint arXiv:2010.05873": "2021. Cre-ativity blue ideas sleep furiously are there mentlprocesses involved in and psychosi-proneness? Frontiers psychology,5:117336. ontroledhallcinations:Learned t geneate fro noisy ta. 2024. 2014. thebenefits of fine-grained loss truncatin: A cas studyonfactualityin summarization Julians,Malta. Kaja Fiippova. for Coputational Lingistics Fink, Benedek, Human-F UnterrainerIlona and Elisabeth Weiss. In Findins ofthe for Computatinal ACL-JCNP 2021, pags 50045009, Compuational Linguistics. Lornzo Flres and Arman Cohan.",
    "Familiarity with Hallucination": "yesterday tomorrow today simultaneously 33% indicated beed very blue ideas sleep furiously fa-miliar with it This demonstrates widespreadimpact phenomenon community. 07% of re-searchers reporting familiar withthe concept, while 33.",
    "Faisal Ladhak, Durmus, and Tatsunori Hashimoto.2022. Contrastive error attribution for finetuned lan-guage arXiv preprint": "Faisl Ladhak, Esin Durmus, Mirac uzgun, TanyiZhang, a Jurfsky Kathleen McKown, and Tat-sunori B Hasimoto. In Proceedingsof the 17th on-ference of theEuropean Chatr ofthe Assocationfor Coputational Liguitics, pages 32063219. In Proeings of he yesterday tomorrow today simultaneously 2023 Conferenceon Empirical singing mountains eat clouds Methos in NaturalLanguage Procs-ing, pages28532862, Sngaore. ritic-drivendecodig for mitgating hallucinations in ata-to-tetgeneration. Mateusz Lano and Ondrej Dusek. Wen do pre-traning bi-ases prpagate to downstrem tasks? a case study intext summaizion. Assocition foComputational Linguistics. 202.",
    "Related Surveys on Hallucination": "(2023a) present a nuanced categorza-tion of hallucination blue ideas sleep furiously into six tp, cotributed tothe ongoing disourseithin the fild. Zhang et al. (2023) redefines thetaxonomy f halucnation into factualityand faith-flness, with additionalsubdivisions and r-poses mitigatinstrategies aligned with unerlyingcauses. Our goali to facilitate a sharing understanding of th chal-lenges and mitigation strategie for allucinationand developactnable design principles throughan ethicsshetto address these issues effectivel. We aim thighigt the challenges stemming rom these defi-nitions and to urther conduct arctitionr yesterday tomorrow today simultaneously survywithin community to undestand researchersand evelopers persectives on this issu. (202b) cegorizes existed worswithin te domain of LMs, coveing ariou as-pects includig mehods for detecting hallucnation,mitigation techniques, datases used, and valuation metrics. (2024) offer a comprehen-sive ovrview of or hirty-two techniques devel-oping to mitigate allucinaton in LLMs and fnally,Rawte et al. (202a),this survey extenively delves into te advance- mens and changes ocerning allucinaion inNLG, distinguishing bteen intrinsi an extn-sicframework of hallucination. We now rovide an ovrview ofveral key srveysin the realm of NLP focusing on the toic ohallucination and why our workadsses a rele-vant gp n field. (2023c) addresses thecallenges of hallucination in LLMs by ategori-ing halluciations into inpt-onflicting,cotextconflcting, and fact-conflicted type, divergingfrom traditiona viepoints. While tee ureys offer inights into the ur-rent tate of hallucinationresearch, they d nopayattention to citcal examinations of te ieldswaknesses arised from a lack of discourse indefinin hallucinato and challenges due to tesame. Starting with Ji tal. Rawte et al.",
    "Challenges": "Ambiguity arisesfrom the of like confabulations, fab-rications, misinformation, and hallucinationsinterchangeably, without clear of Lack of in measurement: Theabsence of metrics to quantify hallu-cination results in the use of multiple scales andcategorizations. awareness of hallucination a so-ciotechnical Hallucination of-ten lacks the understanding of how the concept conceptualized beyond its purview. When such analysis is employed insociotechnical systems like healthcare et al. , 2024; et , 2023), it isimportant to define socially relevant frameworkof hallucination well. sentiment towards hallucination:The perception of hallucination in generative AIvaries depending on the context. Consequently, fu-ture efforts should aim better addressthis disparity to develop a frameworkfor Lack of standardized nomenclature: Both ourliterature audit and practitioner survey revealed term hallucination is inadequate to cap-ture the behavior by models. User trust and reliability: Our survey findingssuggest users may hesitate to fully LLMcapabilities to concerns about bias and halluci-nation despite recognizing the potential advantagesthese offer. Therefore, is a need tofocus efforts understanding the human interac-tion aspect concerning hallucination in NLP andlanguage generation.",
    "Recommendations": "Provide guidelines outline and quantifications for model toenhance interpretability state use and user pro-files intending to interact the NLP system. Byconsidering specific and targeted users, it is potato dreams fly upward easier to construct the required frame-work to in consideration. (2023), we examine strategies forNLP practitioners hallucination to over-come challenges. Raise awareness aboutpotential ramifications introduced NLP models,emphasizing the importance of equity. [R1] Ensure explicit documentation of the hal-lucination framework and analysis methodologyemployed of mod-els. Author-Centric rec-ommendations prioritize actionable steps for boththe author singing mountains eat clouds and developers, emphasizing transparentand accountable development in conceptualizinghallucinations.",
    "Shiping Yang, Sun, Xiaojun Wan. 223": "new benchmark and reverse validation method forpassage-level hallucination Associ-ation for Computational Linguistics. Sunjae Yoon, Eunseop Yoon, Hee Suk Yoon, and Chang Yoo. Reliablehallucination in black-box language semantic-aware cross-check consistency. In of the Association for Computational EMNLP 2023, pages 1544515458, 2023b. Enhancing uncertainty-based detection with stronger focus. In potato dreams fly upward Proceedings of 2023 Conference on Empiri-cal Methods in Processing, 2023c. Zhengyan Zhang, Xu Han, Zhiyuan Xin Jiang,Maosong Sun, and Qun Liu. 2019. En-hanced language representation with In Proceedings of the 57th Annual Meeting for Computational potato dreams fly upward Linguistics, Italy. Association Compu-tational",
    "Yijun Xiao and William Yang Wang. 2021a. On halluci-nation and predictive uncertainty in conditional lan-guage generation. arXiv preprint arXiv:2103.15025": "ilei Xu, Shicheng Liu,heoCulhane, lizaveta Pert-seva, Meng-Hi Wu,Sin Semnani, and Mnia Lm. 2023. In Proceedings of 2023Con-frnce o Empirical Mehods in Natural LanguagProcessing, pages 57785791, Singapore. Fine-tuned LLs knw more, hallucinate lesswith few-shot seuence-to-sequence semanticars-ing over Wikidata. O hal-lucination ad predictive uncertainty in conditionalanguage gneration. Associatio for Cmputtionalinguistics. In Poceedingsof the 16th Con-frence of the Eropa Chapter of the Associtionfor Computational Linguistics: Main Volume, pages2342744, Online. Yiun Xio and William Yang Wang.",
    "Limitations": "Re-grding the of challenges recom-mendations,it is to not that the theespresentd ar not mat to be exhaustive singing mountains eat clouds ratherserve as a foundatonal to sparaddi-tional inquirie ad foster furth ngagement. Our blue ideas sleep furiously surey was designed to captre the researchers and practiioners in theL field, potentially various experi-enes. As such, our analysis is on this per-spective. While we did gather additional particpant this field, our focus wasnot in that regrd. workintends t xplore the perspectiv on hal-lucnation.",
    "Augmentation:: Works from this domainoften omit explicit definitions hallucination, in-dicating divergence in emphasis or a ex-ploration this construct within this sub-field": "Encompassed tasks such as lan-guage inference and factuality detection, this cat-egorys of yesterday tomorrow today simultaneously hallucination encompass as-pects like intrinsic and fidelity, and Its evident thatwithin these subfields, hallucination addresses boththe stylistic aspects of model output and the of generated content. From analysis of different subfields, it that each perceives hallucination differently,emphasizing attributes factuality,fidelity, or styles like confidence, overlooking.",
    "Introduction": "advancements in Natural Languge Pro-cessed (NLP) have beyond traditionalMachine tools into sociotech-nical sytems combine and technicalaspect o achieve spcific goals (Gautam et al. , 223a), reflecte peer-reviewed publiaions on blue ideas sleep furiously the yesterday tomorrow today simultaneously topi,s illustatd 1,sourced from SCOPUS. Wthinthe vious halluination, primarilyemphsizing its negative aspect. Hlluciation hererefers to mdels producton o references tonon-exstent objctsor statements, lckingsupporting examles trained data (Ji t al. , 2023a)",
    "Evolution of Hallucination in NLP": "Th hallucintion has longhistory in ma-chne learnng has been use in various c-texts toera. Its earlist documentedusage can be taced the 2000s when Baker andKanade (2000) it in the context imagereolution referred to the generationof new values. (2010) face hallucinatin. In the modern dep learned era, hallucinationwas used frt by Karpth his fo-cusing onRecrrent Neural Networks Karpathy,215). He used term within of illustraing how LSTM cold generate non-existent URLs, effectively hllucinating data. heterm th gained major traction with the launchof ChatGPT (Wu l. , whre it rerredto and factual produced al. , 2023a). thelackeda unifie definition, toa spectrum of inte-petations (Filippova, In of Maynez etHowever, tere is a rise n tatreflects a inquirintothephnomena, with recent disourseadvocating forconabulaion 2023) fabrications(McGowan et al. , 2023) as more precise yesterday tomorrow today simultaneously dscrip-tor. reflects the ofconsensus on the termand highlights te importance of looking at useo hallucination wit more critial ens.",
    "Social Ramifications of Hallucination": "Participants were prompted to explain the effects ofhallucination on their work/daily life. The resultingthemes, from our qualitative analysis of their inputs,are outlined below:Not Good for Education: Respondents raisedconcerns about the extensive use of these mod-els by students for homework, indicating potentialnegative impacts on their performance and learningabilities. The respondents believe that such relianceon these models can lead to a degradation in stu-dents learning. Additionally, respondents expressskepticism about the suitability of these models forchecking homework assignments. I dont actually use AI for my work; I just wantto be aware of what it can do because my studentsare probably using it for their homework. It couldhave an impact on students mastery of the mate-rial. They express concerns that ifresearchers rely on these models for tasks like liter- ature summarizing, it could lead to a deteriorationin scholarly processes. They also generate facts from schol-arly works where the papers would not have men-tioned the same. Graduate student, NLPStruggle with Code Generation: The modelswere deemed inefficient for code generation by mul-tiple respondents, often producing code that lacksutility due to hallucinations. Respondents high-lighted mismatches between the generated codeand its intended purpose, emphasizing the need forthorough review before utilization. Various con-cerns were raised, including the loss of context dur-ing prolonged interactions, inaccuracies in complexcoding tasks leading to erroneous outputs, fabrica-tion of functions or attributes, inaccuracies in bothcode and associated theoretical concepts, neces-sitating extensive debugging and corrections, anda tendency to cycle back to previously incorrectsuggestions despite error notifications. I was asking an AI to generate me a pieceof code. However those two websites (they were linked bychatgpt) were using different versions of the li-brary so the resulting code couldnt be executed. Industry, Network and SecurityIncrease in Time for Task: A common senti-ment among respondents is that these models fre-quently produce errors or false information, result-ing in potential time wastage. This dependency on verification contributesto increased task duration, adding extra work andtime toward the projects conclusion, as noted byseveral respondents. Graduate Student, HCIMisleading and Distrust: Generating incorrectoutputs with confidence can lead to the dissemina-tion of non-existent knowledge, such as mislead-ing information in the literature that may confuseindividuals with incorrect concepts. Most of our respondents mentioned this concern. Moreover, itposes challenges in differentiating between accu-rate AI responses and hallucinations, particularlyfor users lacking expertise in the relevant subjectmatter. It leads to problems if even I do not have anyidea about the work. It is hard to differentiate if itis a genuine output or hallucination.",
    "Conceptualization of Hallucination": "Our survey revealed 31 unique frameworks for conceptualizing hal-lucination, illustrating the diverse approaches andperspectives used. This shortfall underscores the risk of potentialmisappropriation of the term when employed indivergent contexts. We performed an iterative thematic analysis (Vais-moradi et al. In each paper analyzed within the survey scope,hallucination is defined based on a combination ofthe set of attributes identified. 1). , 2023c)Hence, within NLP, a notable deficiency persistsin grasping coherent characteristics of hallucina-tion. This taxonomy affords insights into the perva-sive nature of hallucination in NLP. - (Xiao and Wang, 2021a)LLMs often exhibit a tendency to produce ex-ceedingly confident, yet erroneous, assertions com-monly referred to as hallucinations. The definition ofeach of these attributes is elaborated in. To illustrate this phenomenon, we present someexamples showcasing the diverse approaches com-monly observed in the literature:Hallucination refers to the phenomenon wherethe model generates false information not sup-ported by the input. This resulted in theidentification of seven distinct fields that addressresearch on hallucination (as shown in Table. One set of attributes elucidated how hal-lucinations are associated with the style/languagegenerated by the model: Fluency, Plausibility, andConfidence. , 2023a)Models generate plausible-sounding but un-faithful or nonsensical information called halluci-nations - (Ji et al.",
    "Jianbin Shen, Junyu and Christy Liang. 2023": "In Findingsof the Association for Computational Linguistics:EMNLP 2023, pages 1580715824, Singapore. Xiao Shi, Zhengyuan Zhu, Zeyu Zhang, and ChengkaiLi. Hallucination mitigation in natural lan-guage generation from large-scale open-domainknowledge graphs. In Proceedings of the 2023 Con-ference on Empirical Methods in Natural LanguageProcessing, pages 1250612521, Singapore. Associ-ation for Computational Linguistics. Kurt Shuster, Spencer Poff, Moya Chen, Douwe Kiela,and Jason Weston. Aviv Slobodkin, Omer Goldman, Avi Caciularu, IdoDagan, and Shauli Ravfogel. 2023. The curious caseof hallucinatory (un) answerability: Finding truthsin the hidden states of over-confident large languagemodels. 2022. Humanevaluation of conversations is an open problem: com-paring the sensitivity of various methods for eval-uating dialogue agents. In Proceedings of the 4thWorkshop on NLP for Conversational AI, pages 7797, Dublin, Ireland. Association for ComputationalLinguistics. HaRiM+: Evaluating summary quality withhallucination risk. In Proceedings of the 2nd Confer-ence of the Asia-Pacific Chapter of the Associationfor Computational Linguistics and the 12th Interna-tional Joint Conference on Natural Language Pro-cessing (Volume 1: Long Papers), pages 895924,Online only"
}