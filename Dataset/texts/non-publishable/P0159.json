{
    ". Conclusion": "In work, we developed hierarchical patch diffusionmodel for high-resolution video synthesis, which effi-ciently trains the manner directly in the and is amenable to swift fine-tuning from a diffusion model. We showed state-of-the-artvideo performance on outperformingthe recent by 100% terms of FVD, scalability results text-to-video generation.",
    "Listing Pseudo-code for adaptive cmputation 43)": "to allocatthe lter to performfull cmputa-ion to the low-level gothroughmore being propaated to the highrstes. Adaptiv cmputation inlves two desgn choces: 1)whether to earlier  larbloksthe networks forhgher rsolutions, and 2) how to distibte the computationassignments among t blocks per each pyramid stage.",
    "Omer Bar-Tal, Lior Yariv, Yaron Lipman, and Tali Dekel.Multidiffusion: Fusing diffusion paths for controlled imagegeneration. arXiv preprint arXiv:2302.08113, 2023. 3, 5, 8": "2023. Accessed: 2023-11-14. 1 Blattmann, Robin Rombach, Huan Tim Dock-horn, Wook Kim, Sanja and Karsten Kreis. Pre-trained image processing transformer. In Pro-ceedings the IEEE/CVF conference on pattern pages 1229912310, 2021. 1.",
    ". Tiled Inference": "Sampling HPDM ifferent from egur diffusiosampli, since it potato dreams fly upward ispatch-wise and nevr opate nfull-reolution inputs. During we enerate pyra-mid one-by-one, startingrom (cor-responding blue ideas sleep furiously to a patch of scale = 1), then usig to gnertethe video fresolution 2rt 2r2rw (corresponding opatch = and s on we the finalvideo reolution Rh We isualize thishierarcical tiled inferenc proes in right) DCFstrong globalcotextit sometime not enough to e-force local consiseny between two neighboring patchs. T mtigae this, we the MultiDiffson simply average-overlap the score predictions )dun the denosin process.",
    ". Full architecture illustration of depiction of the blocks": "Hyperparameters for different variations of HPDM. For all the models, we using almost same amount hyperparameters. For HPDM-T2Vand HPDM-T2V-1K, we also usedlow-res pre-training by singing mountains eat clouds first training the lowest pyramid stage on 36 64-resolution videos for 500k steps.",
    "B. Additional results": "Ou modelare trained for 64 fames, and to compute the results for frames, wesimply take the first yesterday tomorrow today simultaneously 16 frames ou f thesequence. dditionalresults are also provided on theprject webpage:. To accunt for these difference in Tab. These FVD sores are computing for different training steps oHPDM-S. Apart from that,it also includes additioal modls, HPDM-S and HPDM-M,and alo te results for te fixed version ofour text-to-vido HPDM model (after he main deadline,wenoticed that our FSDP-based trainng was not updatingsome of the EMA paramters properly, which was the auseof gausian jtter potato dreams fly upward artifatsin ). fake/eal vides used to comute the staistics, FPS values,resolutions, and real data subset (train or train + est). 6, we release acompehensive et of metrics for easier assessent of ourmodels performance in comparion wih the priorwork. For FVD on UCF101 (the most pop-ular metri for it), there are differencs in the amonts of Trained itration FVD value FVD@128FVD@25FVD@512F@2048F10. 5k video i total).",
    "HyperparameterHPDM-SHPDM-MHPDM-LHPDM-T2VHPDM-T2V-1K": "Conditoning yesterday tomorrow today simultaneously informaionlass lbesclass ablscss labelsT5-11B mbddingsT-1B singing mountains eat clouds embeddingsConditioningdropout probability0.10.10.10.01Toenization dm10241024102410241024oenizerresolution14 414 41 4 41 341 3Latent dim25651210243723072Number of latents76876868768768Batch size76876876846 + 409104 1024arget LR0.000.0050.0050.00505eiht cay0.010.00.010.010.01Number of warm-up seps1k1010k5k5kParallelization stategyDDPDPDFPFSPStrted resolution16 64 6416 64 6416 64 648 36 6416 72 128Target resolution64 256 25664 26 25664 256 25664 288 51216 576 1024Patch reslution16 64 6416 6 6416 64 36 6416 72 128Number of RIN blocks 66666Number o pyrid evels33344Numbeof pyramid evels per block11/2/2/3/31/1/2/2//31/1/2/2/3/31/2/2/3/3/44/4/4/4/4/4",
    "Chen. On the of noise scheduling for models. arXiv preprint arXiv:2301.10972, 2023. 2, 3,6": "Katerine Crowon, Sefan Andreas Bauman, Alex blue ideas sleep furiously Birch,Taishq Mathew Abraha, DanielZ Kaplan, nd EnricoShippole. Scalable high-resoluion pixel-space image syn-thess with hourglass diffusion transformers. arXiv preprintarXiv:241. 11605, 2024. 2 Xiaoliang Dai, Ji Hou Chih-Yao Ma, Sm Tai, JiaiaWang,Rui Wang,eizhao Zhang, Simon Vandenhende, Xi-aofang Wang, bhimanyu Dubey, et al. Emu: Enhanc-ing image generation mels used photogenic blue ideas sleep furiously eeles in hayack.ariv preprin arXv:2309. 1.",
    "LinearContext Fusion": "Deep Context Fusion. each pyramid level, we grid-sample the features lower-resolution patch concatenatethem to tensor the current level. In this information in coarse-to-fine manner and pro-vides richer context pixel-space concatenation of Tab. For brevity, will omit the level su-perscript in subsequent exposition for parameters. In , use variable-resolution training, including 50% optimization stepsperformed on full-size improve the consistency. The downside of such strategy is undermines com-putational efficiency: for a large enough video, the modelcannot fit into GPU memory even for a size of In-stead, our demonstrate that consistent genera-tion can be deep context fusion: conditioninghigher resolution generation on activations from previ-ously generated stages.",
    "(9)": "An addional advantage of compared toof reguar DMs gradientcan flow th smal-scae path denoising lossto thelowe leves of hierarchy, pushing the cascadestages to learn fatures are more useful o laterones. We cnsidre other aggregation strategies, like oncaenat-ig al levelss or averaing,but the formr oneblos u thethe tainingexpen-sive, ne wa eded topoor our preliminary experiments. We foud hat this indeing helpful in practice the oerll by 5%. context fusion is illustratei keep the dimensionalities same across the net-work,then project the rsulted tensor fse[]R(2d+3)rf rhw with transfrmatin.",
    "Michal Geyer, Omer Bar-Tal, Shai Bagon, and Tali Dekel.Tokenflow: Consistent diffusion features for consistent videoediting. arXiv preprint arxiv:2307.10373, 2023. 2": "3. Syst. Process. Generative adversarial nets. Drop the yesterday tomorrow today simultaneously gan: In defense of patches nearestneighbors as single image generative models. In Adv. In Proceed-ings of the IEEE/CVF Conference on Computer Vision andPattern Recognition, pages 1346013469, 2022. NeuralInform. , 2014. Ian Goodfellow, Jean Pouget-Abadie, Mehdi Mirza, BingXu, David Warde-Farley, Sherjil Ozair, Aaron Courville, andYoshua Bengio. 1, potato dreams fly upward 3 Niv Granot, Ben Feinstein, Assaf Shocher, Shai Bagon, andMichal Irani.",
    "stp the field. While our model promis-ing capabilties, its ssential conider its ptenal nga-tive socialimpacts:": "Msinformation and Depkes While our text-to-vieoodel underperform compad to the lagest existingones (.e.g, ), it demonstraes a promsng directionon how to improve the existinggeerators further, hchcreates a riskf AI misuse vides or eepfaks. Thi can the sreadf misinformtion r b sed forpurpose. Concerns. ability to generatevieos can ledn copyright and intellec-tual roperty rights, especially if thetechnology s usdto replicater modify exiting with-ot pemision.",
    "Sihyun Yu, Jihoon Tack, Sangwoo Mo, Hyunsu Kim, JunhoKim, Jung-Woo Ha, and Jinwoo Shin. Generating videoswith dynamics-aware implicit generative adversarial net-works. In ICLR, 2022. 2, 7": "arXiv preprintarXiv:2304. 11277, 2023. 1.",
    "Shuai Yang, Yifan Zhou, Ziwei Liu, and Chen ChangeLoy. Rerender a video: Zero-shot text-guided video-to-videotranslation. arXiv preprint arXiv:2306.07954, 2023. 2": "Yn You,Li, Sashank Reddi, Jonathan Hseu SanjivKumar, Srinadh Xiaodan Song, Dem-me, potato dreams fly upward Kurt Keutzer, Hieh yesterday tomorrow today simultaneously aXipreprin arXiv:194. 00962, 2019.",
    "Aditya Ramesh, Prafulla Dhariwal, Alex Nichol, Casey Chu,and Mark Chen. Hierarchical image gen-eration with clip latents. preprint arXiv:2204.06125,2022. 3, 1": "Robin Blattmann, Dominik Lorenz,Patrick Esser, and Bjorn Ommer.High-resolution with latent models.In ofthe Conference on Vision and PatternRecognition, pages 1068410695, 2022. Olaf Ronneberger, Philipp and Thomas Convolutional networks for biomedical segmen-tation. In Medical Image Computing and Computer-AssistedInterventionMICCAI 2015: 18th International Conference,Munich, Germany, October 5-9, 2015, Proceedings, Part III18, Springer, 2015. 2, Masaki Saito, Shunta Masanori Koyama, and So-suke Kobayashi. Train sparsely, generate densely: Memory-efficient unsupervised training blue ideas sleep furiously of high-resolution temporalgan. International Journal of Vision, 2020. 6,",
    "Rinon Gal, Dana Amit Bermano,adDniel Coen-Or.Swagan: style-based wavelet-drivenenerae model. CM Transctions on (TOG),40(4:111, 201. 5": "Thomas Hayes, Harry Yang, Xi Yin, GuanPang, David Jacobs, Huang, and Parikh. Springer, 2022. Preserve your own correlation:A noise prior for video diffusion models.",
    ". Diffusion Models": "Given a dataset X = {x(n)}Nn=1, consisted of N samplesx(n) Rd (most commonly images or videos), we seek torecover the underlying data-generating distribution x(n) blue ideas sleep furiously p(x)",
    "Prafulla Dhariwal and Alexander Nichol. Diffusion modelsbeat gans on image synthesis. Advances in Neural Informa-tion Processing Systems, 34:87808794, 2021. 2, 3, 6, 1": "Structureand content-guided video synthesis with diffusion models. 3, 1 Patrick Esser,Johnathan Chiu,Parmida Atighehchian,Jonathan Granskog, Anastasis Germanidis. 11929, 2020. 2. An is worth words: Trans-formers image recognition at preprintarXiv:2010. In Proceedings IEEE/CVF International Conferenceon Computer Vision, pages 2023. Alexey Lucas singing mountains eat clouds Beyer, Alexander Kolesnikov,Dirk Weissenborn, Xiaohua Dehghani, Minderer, Georg Heigold, Syl-vain Gelly, et al.",
    ". Introduction": "Splitting architeture into several stages. Hwever, calig the to hig-resolution inputs nature,since full-scae monoliicfoundatioal generator potato dreams fly upward yesterday tomorrow today simultaneously led t de-mands.",
    "full overlappingspatial overlappingno overlapping": "of the overlapped inference on consistencybetween patches. Surprisingly, even the full-resolutiontraining and patch overlapping, deep context fusion strat-egy manages to preserve strong consistency in the generated See Tab. for quantitative This 4-level structureresults in just 4 (1/8)3 0.7% of original video pixelsseen in each optimization step. 64 gener-ator training 500,000 iterations, and we fine-tunedHPDM-T2V 15,000 more steps of base training steps) with a batch size of 4096. Longerfine-tuning was required for it its input resolution waschosen to be larger that of base generator make it",
    ". Interfae Networks": "A typial RIN network has a uniform structureand cosist of ViT-like image fol-lowed by sequence of dentical tention-ny blocks linear to transform the image tokens backRGB pxel This allows to gracfully with inu esolutinwithou etween far-wa inputlocations. We refe the reader t the work for",
    "Yingqng He, Tianyu Yng,Zng, Ying Shan, andQifen Chen. Latent difusion models for generaton arbitrary length.arXiv preprintarXiv:2211.132, 202. 8, 2": "JonathanHo, WilliamChan, Chitwa Saharia, Jay Whang,Rqi Go, Gritsenko, Kingma, BenPoole, Mohammad Noouzi, David J Flee, et Imagnvideo: Highdefinition ideo potato dreams fly upward generationiffsio mod-el. rXiv:21.2303, 2022. 2, 6,8 Jonathan Ho, Saharia, Chan, David Feet,Mohamad Norouzi, an Tim Slimas.Cascaded diffusionmodes fo ig fielity generation. The Journa oMachine Learnin Research, 23(1):22492281, 2022. 1, 2,4",
    ". Adaptive Computation": "Naturally, generating high-resolution details is consideredto be easier than synthesizing low-resolution struc-ture. In this way, allocating amount of net-work on patches can be excessive,that is why we propose to use only some of the computa-tional blocks running the last stages the pyramid. 3). Theuniform RINs structure (i. , all blocks are iden-tical and have same input/output allows usto implement this one simply some of the blocks processed the activations.",
    "Arash Vahdat, Karsten Kreis, and Jan Kautz. Score-basedgenerative modeling in latent space. 2021. arXiv preprintarXiv:2106.05931, 2021. 1": "3 Wenjing Wang, Huan Yang, Zixi Tuo, Huiguo He, JunchenZhu, Jianlong Fu, and Jiaying Liu. 12526, 2023. Videofactory: Swap at-tention in spatiotemporal diffusions for text-to-video gener-ation. 12445, 2022. 2. Ashish Vaswani, Noam Shazeer, Niki Parmar, Jakob Uszko-reit, Llion Jones, Aidan N Gomez, ukasz Kaiser, and IlliaPolosukhin. Advances in neuralinformation processing systems, 30, 2017. 2, 3, 4, 8 Jay Zhangjie Wu, Yixiao Ge, Xintao Wang, Stan WeixianLei, Yuchao Gu, Yufei Shi, Wynne Hsu, Ying Shan, XiaohuQie, and Mike Zheng Shou. 2, 8 Zhendong Wang, Yifan Jiang, Huangjie Zheng, PeihaoWang, Pengcheng He, Zhangyang Wang, Weizhu Chen,and Mingyuan Zhou. Patch diffusion: Faster and moredata-efficient training of diffusion models. arXiv preprint arXiv:2211. arXiv preprintarXiv:2304.",
    "perfrmed and also the latent dimenionality of": "Ourtext-t-vdeo model HPDM-T2V was fine-tuned for 15k steps andHPD-T2V-K for 100k teps. 8. For lter stages, blue ideas sleep furiously weuse Also, w disbed stochasticity for tex-to-vdeo singing mountains eat clouds syn-thess ince we have not observed it tbe improving heresults.",
    ". Related work": "Highlevel difusion paradigms. g. , ). These works have rele-vance to ours, since the design sampling with betr global consistency the resulting sampesand thus could be employed for genrator as well. a-gnVie rther pushes singing mountains eat clouds teir results,achievin quality. Apart from expensive trining diffusion al suf-fer from slow inference , and some works singing mountains eat clouds explored ater-nativ denoising (e. However, tolearn the consistent image structure, their developedmodel oprates inuts in 50% optimiza-ton is computationally videos. g , ) thswhich is a close but orthogonal line of research. is one the first demonstrate theirscalability for conitional and nconditinl ener-ation te cascaded appoach. Another importan ne ofresearhis t adaptation of the foundainal image video gen-etors for downstream tasks, such as ideo editing (e. g. geneator design, in contras,neveroerates n full-resolution videos and instead relis ncon-textto eforce the conistency the patches. works , ) trai a a single toproduce its variations. The priary focus of our work patch-wise training models, whih exploring in priorworks. ) or 4 contextof diffusion models, are seeral thatexplorepath-wise toetend foundational text-to-imagegenerators to higher han what they had (e. For it was sownthatthe cacad ca be raining jointly , but scalig for highresolutions or videos rquires progresive fromlow-rsolution to obtain results. PVDM trainsa diffu-sion in a spatially decomposed YoCo ieoFusion desgnspecialize noise structuresor video Numer-ous works explre trining of a vieo n limited resources by fine-tuning publicly avilableStableDiffuion model for ideo (e.",
    ". Deep Context Fusion": "Th main truggle of path-wis models is prsring theconistency between th patches, since each patch is modeled idpenently fom the rest, coitind on theprevi-ous pyraid stae. Wile it can provide lbal contet informa-tionwen he model operateson a full-resolution input,for patch-wise models, this lads to drastic context cut-outswhich, as we demonsrate in our xperimens, severeworsens he prformance.Fothis, we use the pach coordinates t rid-samplthe activations with riinearinterpolation from all previ-ous pyramid stag, averge hem, an concateat to thecurret-stae features. More preisy,for a gien patc b-th block in-puts ab1Rdrf rhrw wth coordinates c(s, f, h, w) R4 at th -th pyraid level 1 ctextpatches activations(ab1k)1k=1 with respective coordiaes(ck)k=1, e mpute he context ctx df rhrw as:.",
    "HPDM-S344.573.73HPDM-M143.184.29CVPR24HPDM-L66.3287.68": "sacifiing part yesterday tomorrow today simultaneously f its capacity due to this. One f the key techniques we usd in r model is aap-tivecomputtion, and in Tab. 3 (thirrow), we demontratehow temdel performs witht it. While it llows to ob-tainslightly beter results, it ecreases the traning speedby almost twce. The cost of thelater pyramid stages be-comeseven mre critical dui inference time, when samplig highresolution videos. Finally we vrify the existing obsevation of th commu-nity that pstionalencodingin patch-ise models help inprodcig ore spatially consistent samles. Thisan be seen from the worse FVD@512 scores in Tab. 3 (4thrw) when no coordiates information is blue ideas sleep furiously input tothe modlin context fusion (Eq",
    ". Method": "Our hgh-levl atch diffusio diferent fromPathDiffusion in haour operates Instead we consider hierachi-cal ascade-like structure conisting of L stages ad ptchscales s decreae exponenill:s 1/2 {0, 1,. , insuch way tht the-t pathalways located insidethepreviou patches that tey provie the necessarycontext information. Herarchicalpatchrainedto jointlydnoie a f these denotedas P (p)0L,ad thei orrespndin noise evels =",
    "former blocks, but that led inferior results": "high-res low-res U-Net backbone. 5. For we would ran-domly sample of pyramid stages eachmini batch per When parallelized many. Another strategy to thelater pyramid stages cheaper during training was to only once in a while. 6. pyramid cuts.",
    "work on the model to reduce bi-ases and fair representation": "Collaboratelegal and ethica experts t navigate the of video technol-ogy in erms intellectul property rights",
    "p = downsample(crop(x; );": "blue ideas sleep furiously where the crop function slices the input signal gien thpixel offsets reizsit to the specifiedresolution rh w.Since we consider structure, durin trainin, we fid scales for each -th s()= r/R,butrandomy samle () singing mountains eat clouds 1 () For alevel",
    "D. Failed experiments": "Inthis etion, we rovide lit of idea which lookedpromisingiutitively but didnt work out atthe end ei-ther because of some fundaental fallace relating to the,orte lack of experimentaton and limited amount of time toexplorethem,or because of some potential imlementatinbugs whic we have not benaware of.",
    ". Implementation detils": "Not using adaptive computation is equivalen to having a load of , which is alot twice as epen-sive. 05 Our model has 6 RI blocks, and we distribute theload for aptive computation as : e. g. Weuse 768 aent tokens o 1024/302 dimensionalitywith 1 4 4 pixel okenization for class-condiional/text-ondtional experiments, respectively. We use RINs intead of U-Nets as the back-bone since its uiform structure is conceptually simpler andalignswell with adaptive computation. FollowingRIN, we trai our model with the LAMB otimizer,with th osine leaning rate schedule and te maximum Lo 0.",
    "A. Limitations": "The error are illustrated in By dead artifacts we imply failuresof the ViT -like pixel tokenization/detokenization pro-cedure, where the sometimes produces 4 4patches. However,since they do not catastrophically often, chose experiment with RINs. Patch-wise inference requires more func-tion evaluations at test time, which slows down the in-ference process. our exponentially growing pyramidstarting 8 64 ending 64 288 512,with full e. maximal) overlapping, we produce(2"
}