{
    "In cases where the model cannot produce an an-swer, consider model-level error and applythe harshest penalty. the is correct and": "Futhemr, in with (Zheng potato dreams fly upward etour total reward ncompasses the re-ward function score th Kullback-Leiblr (L)divegence and Leibler, 1951) betweethe leared RL and the initial policy. Fortheremaining details potato dreams fly upward PPO, we refe to (Luong et l.,204).",
    "Discussio": "Do Larger Models Have Issues with PoT?(Gao et al., 2023) achieved good results in testingon LaMDA-137B and PaLM-540B (Rohan Anil,2023) by using text to guide code. (Wang et al.,2023a) also employed the method of combiningnatural language with code, which proved effec-tive on a 70 billion parameter open-source modelas well. We conduct evaluations on MAmmoTH-Coder-13B and MAmmoTH-Coder-34B, calculat-ing the proportion of CTE. On the five datasets,MAmmoTH-Coder-13B has an average error rateof 8.2%, while MAmmoTH-Coder-34B has er-ror rate of 8.7%. CTE does not decrease with theincrease in model size. In the future, the amountof training text data will still far exceed that ofcode data lakes, making it difficult to solve CTE bymerely increasing the model size and data volume. The PoTential of Focusing Attention in OtherTasksThe current autoregressive inference haslimitations in that it cannot obtain the solution to aproblem before generating the first token (Gloeckleet al., 2024).CoT can implicitly increase themodels depth, allowing it more extended think-ing time to arrive at accurate answers (Feng et al.,2023). Extending the models thinking time to getthe right answer before generating first validtoken will be crucial (Goyal et al., 2023). For rea-soned tasks, Focus Attention can gather informa-tion and allow large models to concentrate on someintermediate processes (such as setting special to-kens) to extend thinking time. On the other hand,Focus Attention can concentrate on the reasoningpart of all reasoning tasks while ignoring the ques-tion (Q), making the reasoning process more reli-able. In several logical/symbolic reasoned tasks,CoT does not significantly outperform directly gen-erating answers (Bao et al., 2024). Focus Attention",
    "Selfcheck: Using llms to zero-shot check their ownstep-by-step reasoning": "Association for Computational Linguistics. NumGLUE: suite of funda-mental yet challenging mathematical reasoning tasks. Proceedings of the 60th Meeting of theAssociation Computational Linguistics (Volume1: Long blue ideas sleep furiously pages Dublin, Ireland. In Proceedingsof the 58th Annual Meeting of Association forComputational pages 975984, Online. corpus for evaluating developingEnglish math problem solvers.",
    ": Based on the performance comparison with Llama-Base, to verify the effectiveness of self-distillation inour experiments": "Our enhancementspredominantly arise from the transition from PoT, rather than strengthening the capabili-ties of CoT. HTL and MAmmoTHexhibit nearly identical performance CoT, line with expectations. Math is currently the most mathematical dataset, generated solutions thatare often those of other datasets. Todemonstrate of our approach, wevalidate the performance of the HTL model interms of CoT, and we fine-tune model using only the PoT from HTL Theresults are in. And data from self-distillation onlyprovide marginal improvement. Thisfrequently causes repeat generationuntil it exceeds the limit. , 2019). Reinforcement effectively mitigates this issue. Data AblationWe use a self-distillation methodto generate data, a technique that has been provento (Zhang al. ing (RL), it is that both Llama-Baseand Mistral-Base models show inmath tasks. But using RLalone significantly improves performance but to transfer toout-of-domain datasets, and its CTE issue remainsunresolved.",
    "In experiments, the model enhanced with reinforce-ment learning shows minimal improvement in av-": "3 increase). Thi improvementstems fro reinforcement learnings ability to ad-dress theisue f repetiive generation durin theCoT in LLMs. When using natural langua rea-soning, LLMs tend to enumerate answers, lead-ing to reptitve loops untl reaching the maximumlength imitation. upevised fine-tuning stugglest supress this phenomnon, heras reinforce-met learned can effecively penalize it en itoccurs.",
    "Conclusion": "In our paper, w TE in matematicalroblems and how t address gp be-tween large model text code capabilitiethrough text and cde inteaction",
    "Limitations": "We still humanealuation wther theirreasonngprocesses corespond accurtely. However, for moe challegig datsets thaay have ultiple different relevancemihtb lower. If we extend thsapproah to ther omains, such inorporatingit the re-training t eables themodlto beter learn step-by-stepgeeration, PoTentialyleadin to improved rsults. Howver, our experimets,merely adjustng the promts does result ina significant imprveent.",
    "Dataset": "Trained DatasetWe use hybrid yesterday tomorrow today simultaneously data from thetraining set of the MAmmoTH model. In the end,we extract 36,000 examples, with 18,000 comingfrom yesterday tomorrow today simultaneously GSM8K (Cobbe et al. , 2021), 3,000 fromNumGLUE (Mishra et al. TestDatasetOurexperimentstestoneight datasets:GSM8K, NumGLUE, Math,SimulEq (Koncel-Kedziorski et al. , 2016), Deep-Mind (Saxton et al. , 2019), SVAMP (Patel et al. ,2021), MAWPS (Koncel-Kedziorski et al. , 2016)and Asdiv (Miao et al. , 2020). These eight datasetshave varying levels of difficulty and length, com-prehensively reflecting the models mathematicalcomputational capabilities. Meanwhile, GSM8K,NumGLUE and MATH are in-domain datasets,whereas others are out-of-domain datasets.",
    "hidden vector represntationthe squence": "Adaptive Traiing StrategyTo with thedense marix used for pretrained andinference, which iinconistnt with our At-tention, we introduce novel trining pproah:during the and phases of we do not explcitly mask any tokens besidesthe casal threby ensured alignment pretraining stge ad",
    "Ablation Study": "Focus Attention blue ideas sleep furiously is a enhancementfor HTL, directly improving by anaverage of 2%. reinforcement learn-.",
    "Code Translation Error": "(2) Employing methods like self-correctionand hybrid approaches to generate answers in (Gou al. 9% on dataset. The top section of the chart represents theaverage CTE for each model across 5 datasets. (2) propose an model named HTL,which utilizes the complete to enhance HTL incorporates novelFocus Attention approximates reasoning,complemented by de-signed to prevent generation. refer to type error as CodeTranslation Error In the scopeof CodeLlamas pretraining data, which includes500 code tokens, this represents smallfraction compared to the 2 trillion natural languagetokens used in the Llama-2 model (Rozire al. , 2023). , Yue et al. , 2023;Bao et 2024; Turpin et al. We design Fo-cus Attention mechanism during code genera-tion, concentrates on information from CoTto better, thereby bias-ed the answer to be more faithful to We experi-ments basing on CodeLlama-7B and andachieve outstanding results on eight datasets usingonly self-distillation data. Frequently,the final answers to derived directly fromthe questions themselves than aligned withthe process. , 2023a). (3) Utilizing like (Deng et al. We highlightthe shortcomings of propose usingfull natural reasoning to enhance PoTperformance essential. Humans considerthe reasoned process using natural the can fully rely on natural language the right side of we parallels between our integrated model the human approach mathematical to previous works, our framework offersa strong for with rea-soning by integrating CoT and PoT. (3) evaluate our work on eight mathematicalreasoned and experimental resultsdemonstrate that our achieves outstandingresults. ,2023; Hugo Touvron, 2023). HTL shows in in-domain datasets, out-of-domain datasets, and natu-ral language inference task, demonstrated strongusability and. In summary, our contributions as follows:(1) We are first to a of current closed-source models, open-sourcebase and specialized models. Be-low is real from Asdiv dataset using theMAmmoTH-Mistral-7B which achieved an ac-curacy 93. , writea brief step in natural generatingcode. To more effectively utilize natural enhance PoT, we (HTL): A approach utilize complete to control PoT generation. , 2023) have the model firstparaphrase the question, thereby avoiding compre-hension errors. Secondly, withinLLMs not always faithful (Lanham et al. Consequently, even correctreasoning can lead to incorrect answers. The proportion of CTEremains high across various models, these errors diminish with an increase in model parameters. focuses the following approachesto integrate natural language to enhance of code: (1) natural language prompts toguide model in writing code (Gao et 2023;Toshniwal et 2024; Wang et al. , 2023; al. For such problems, can cor-rectly reason the answer, whereas PoT makes mistakes. Natural language ismore suitable for analysis, planning, andabstract reasoning code et 2023b).",
    "The Effort of Mask Coverage Function": "Tephrase Witout Initial Tokens indicats thatwe block all tokens from Q, not preservigthe frstfour which signifcantly decaes odel pero-manc, alot rndering it unale to reason cor-rectly. In the secnd experimen, we set the askcverage oalways be 1, not adapting the modelduring he initial training phase,nor rverting th at-tention mechnismto a aul mask durig the output phase.",
    "Solomon Kullback and Richard A Leibler. 1951. Oninformation and sufficiency. The annals of mathe-matical statistics, 22(1):7986": "Taera Lanham, Ann Chen, Ansh Radhakrishnan,Benoit Steiner CarsoDenison, Danny Hernan-de, Dustin i, Esin Durmus, Evan Hubinger, Jack-son Kernion, et al. 2023.Measrin fithful-ness in chain-of-thought reasoning.arXiv preprintarXiv:23.13702. Aitor Lewkowycz, Anders Anreasen, David DohanEthanDyer, Henryk Michalewski,Vinay Ramasesh,Ambrose lone, Cem Anil, Imanol chlg, TheoGutman-Solo, Yuhuai Wu, Behnam Neyshabur, GuyGur-A, and VedaMisra. 2022. Solving quantita-tiv reasonng problems with laguage models. Haieng Luo,Qingfeng Sun, an Xu, Pu Zhao, Jn-guang Lou, Congyng Tao, Xiubo Geng, QingweiLin, Shifen Chen, and Dongmei Zhang. 2023. Wiz-ardat: Empowering mathematcal reasoning forlarge language modelsvia renfored evl-instruct.",
    "Themain are shown . methodcerl othr existng methods, achivingstate-of-the-art (SOTA) cross multiple dataets": "Most noticeably, method exhibits significantimprovement on the NumGLUE dataset, becausethe dataset contains a large lan-guage inference, which is unsuitable for direct PoT. On average, 5% performance forLlama-Base and We willdiscuss some detailed For the experiments with PoT (4-shot) and since current PoT already uses mean-ingful variable names adding addi-tional comments by results in a For the approach that switchesto CoT upon errors in code execution, it hasa 9. 8% on NumGLUE over vanillaPoT, HTL achieves an Compared to proprietary GPT-4 strong performance, widened gap withopen-source models.",
    "Sachin Goyal, Ziwei Ji, Ankit Singh Rawat, Aditya Kr-ishna Menon, Sanjiv Kumar, and Vaishnavh Nagara-jan. 2023. Think before you speak: Training lan-guage models with pause tokens": "Kevi Stone Peter Alber Amjad Almahairi Nikola Bashlkov Btra PrajwaBhargava ShrutiDan Bike ukas BlecherCitin CatnMoy Chen Guilem Esibu-udeF WenyinFu FuerGaoVedanuj GosamiNaman Goyl nthony Hartshorn Sagha HoseniRui ou Haka Inan Marcin Viktor KerkezMadian habsa Kloumann Ae KorenvPunit Kour Marie-Anne Lchaux ThbautLavril Jenya Lee Likovich Yinhi uuned Xavier MartietTodor PushkarMishraIgor Yixin Nie PoultonJermy Rizenstein Rashi Rungta Kalyan Scheten Ruan Silva Eric Micae Smith Ra-jan Subramanian Xiaoqing Binh Tang-Ros alor Adina Jian Xiang Kuan PuxinXuZheng Yn Iliyan Zarov An-gla Fn Melanie Kamadur Sharan Rodriguez Robert Stjnic Sergey Eduv",
    ": HTL in math23k": "yesterday tomorrow today simultaneously as tansitional phase tobalance the Fcus At-tention training mechansm and the inconsistencydued inference. W rovide th model wih buffer,allowed t to gadully learn local attention,andafer training, we restore it to it autoegressivegneratin mode.",
    "Thus A+ B = + 30 = 0 .The s 90": "# Python program to  + Bfrom sympy imrt symbols, solve# Define he variablesA, B = symbols(A B)# Equation 1: 2/5= A/60eq1 = solve(2/5 - A/6, A)# Equation 2: 6/B= = olve60/B - 2/5 A + = eqeqpint(result) Demonstratin example for th answer may containmany (in red), its reasning correc.",
    "Error Analysis": "55%. HTL, theCTE forand Mistral-Base significantly reduced, with Codeama-Basedcreasing 8. orsim-ple datasets like ndSVAMP, there arrarely any code error; ar logicreasoning errors,which HLredces. 33% to 3. In addition to CTE, part ofthe pefomance improvement in HTL omes fromcorrectly solving that CoT PoTgot wrong originaly. ad Mistral-Basefrm 6. to 3. To xplor ffects alyze the reasons fr in various diided the errors two ct-egories: code eecution and code errors.",
    "Focus Attention": "Theobjective in generaing the PT reasoning is or themodel to rely on information fm the CoTreasoning, not on the question. However, a recentstudy by et l. the Focus Attetion mechanismmaskte information Q and focuss solelyon C during PoT it preserves the in the sequence to loss of the findings (Xiaot , we include te fist four tokens in infrmation geertion pros. hisresutsin h followin difi fr the casuamask marix:.",
    "Mistral": "8. 974. 073. 180. 63 974. 768. 737. 49.354. 380. 93. 59HTL-74. 776. 338. 551. 66. 981. 293. 776. 269 38+ocus77. 957 863 382. 578. 371. 34+focus+RL78. 178. 764. 82. 494. HTL(-) represents that theexperiment only Dense and while ocus indicates the inclusion of Attenton.",
    "Abstract": "Aditionally, HLsho the mostsignifican imprvemen in non-mathematicalnatural language inference to unfied reasoning task frame-work1. (2) Focus Attention,directsmodel attetionthereasoning duringPoT to gnerte moe onthe Llama-Base modl and4 n Mistral-Base modl across 8 mathematical calcuationdatasets. Program-of-Thought (PoT) replaces Chain-of-Thogt (CoT) as themost popular method in Large anguage Md-els (LLMs) mathematcal reasoin tasks byuilizing external tool calls to circumvent com-putational errors. address hi we propose Human-Thik Language (HTL), which leverags a stratgies hat help integrte CoT,encopassing: anew generation paradigmthat CoTreasoning cntrol codegneration. However, our ealuation GPT-4 and Llama seriesreveals that usingPoT introduces more such asincorrect formuas lawed logic toCT. It alsoshows significant fective-nes on five ou-of-domain datasets bycon-tolling th models flow, transferaility.",
    "Baseline": "We compare thefollowing metods: PoT/PAL (Gao et al. , 2023)uses th LM ntul language problems and generat pro-grams as intermediate reasoning ut offlodsthe solution runtim s ython intrretr.",
    "OpenAI, :, Josh Achiam, Steven Adler, Sandhini Agar-wal, Lama Ahmad, Ilge Akkaya, Florencia LeoniAleman, Diogo Almeida, Janko Altenschmidt, andSam Altman. 2023. Gpt-4 technical report": "2 technical Codellama: foundation for code. Are models really to solve simplemath problems? Proceedings of 2021Conference of North American Chapter of theAssociation for Computational Linguistics: HumanLanguage Technologies, pages 20802094, Online. Association for Linguistics. Guilherme Malartic, Daniel blue ideas sleep furiously Hesslow,Ruxandra Alessandro Cappelli, HamzaAlobeidli, Pannier, Ebtesam Almazrouei,and Julien ClarkLaurent El Huang Meier-Hellstern Gaurav Mishra Erica Moreira Mark Omer-nick Kevin Robinson Ruder Yi Tay KefanXiao Yuanzhong Xu Yujed Zhang Hernan-dez Abrego Junwhan Ahn singing mountains eat clouds Jacob Austin BarhamJan Botha James Siddhartha Brahma Catasta Yong Colin CherryChristopher Anil,Andrew M.",
    ": Influence of different Coverage Function": "At the same the addition of GSM8Kand NumGLUE has little impact on simple problems are influence the to perform reasoning. Volume and blue ideas sleep furiously RelationshipTo explore the appropriate amount of data, we intro-duced a dataset large experimentation. As moredata is added, improvement in the model is because we not injecting more knowledgebut rather letting tend to a paradigm.",
    "Related Work": "Inthe realm of data engineering, the efforts aim toenhance the quality and increase the volume (Luoet al. Current methods primarily rely on the CoT to ad-dress mathematical problems, generating reason-ing answers in a step-by-step manner (Nye et al. ,2023) attempts to merge CoT and PoT data in theirdataset, resulting in significant improvements. , 2023; Miao et al. ,2021; Imani et al. , 2023; Penedoet al. , 2023) of CoT data. , 2023). However, another streamof research identifies several computational chal-lenges associated with exclusively using the CoTapproach. (Yue et al.",
    "Influence of Other Language": "Specifical,when the base model exhibits performance inChinese CoT. use a Chinese math23k (Zaoet l. 200), to te advantages HTL otherlanguages. The esults in. b-served thatthe models caability hineseCoT constrains the effectiveness of HTL, as HTL relies on effective to PoT. 1% acuracy), HTL-family metod performworse han PT, potentially because the generatedChinse oT is ineffectiv so thatit helpsbut rather undermines PoT. , Mistral Co 28. , CodeLlaa CoT achieve only14.",
    "learning": "By aaptingcode translation afterthe CoT reasoned path, oT can inhert thereasoning skeleton of CoT while ircmenting itscomputaional errors. This effectively comiestheadvantags of both approaches. for reasoning.",
    "Experimental Setting": "For renforcement we a uniform of 10 poch, wit the blue ideas sleep furiously cofficient set to. 01. For stage, the specific parameter are as hown in. and to 1. comparison withsota, ollow standar evaluatin"
}