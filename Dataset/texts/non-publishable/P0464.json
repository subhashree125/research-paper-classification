{
    "BEvaluted Models": "We evaluate four Med-LVLMs,i. ,LLaVA-Med(Lietal. e. LLaVA-Med (Li et al. , MedVInT al. , 2023) is a mul-timodal few-shot learner for themedical domain. , 2022) model, with medical datafrom publications and textbooks. , 2023b) model forthe biomedical field. ,2023),Med-Flamingo (Moor et al. , 2023) a assistant, adapting the general-domain LLaVA (Liu et al. (Moor al. , 2023), (Wu et 2023). It builds upon singing mountains eat clouds the Open-Flamingo (Alayrac et yesterday tomorrow today simultaneously al. The se-lected models are all at the 7B level.",
    "), the retriever will first encode each image and": "the corresponding singing mountains eat clouds reports into embeddings usinga vision encoder and a text encoder, respectively. e. , Vimg = Eimg(Ximg)),where N is the number of medical images thatneed to be retrieved, and P is the dimension ofthe embedding. Similarly, we generate text embed-dings Vtxt RNP for all corresponded medicalreports Xtxt by applying a text encoder Etxt, i. ,Vtxt = Etxt(Xtxt). Subsequently, to adapt the gen-eral vision and text encoders to the medical domain,we fine-tune the encoders using the trained datawith a contrastive learning loss, defined as:.",
    "How Does RULE Improve thePerformance?": "In this section, we conduct a set of analyses demon-strate how different components contribute to theperformance and illustrate how RULE enhancesoverall performance, which are details as follows:Ablation Studies. The resultsare shown in . Thelimited retrieved contexts can not cover the fine-graining features of medical images, resulting inunstable factual accuracy improvements. With theaid of the factuality risk control strategy (\"FRC\"),retrieval performance see a stable increase, out-performing original Med-LVLM. Consideringthe models over-reliance on retrieved contexts, theknowledge balanced preference tuning (\"KBPT\")further enhances the models reliability and signif-icantly improves its performance",
    "No, the fundus does not show any presbyopia": ": Illusrations of factuality enhanement byRLE in radology and povides afatually incrrec answer. Incase singed mountains eat clouds 2,LLaVA-ing initialy a due to the models oer-reliance onretieved contexts, it potato dreams fly upward poduces i-correct sponse",
    "of the American Medical Informatics Association,23(2):304310": "1527. arXvpreprnt arXiv:2404. Kaiming e, XangyuZhang, Shaoqing Ren, and JianSun. Medd: Diagoss-guided potato dreams fly upward otstapping foarge-scale medical visio-language learing. Retrieval-agmnted generation forlag languagemodels: blue ideas sleep furiously surve. Deepresidual learningfor imae recog-nition.",
    "Conclusion": "nthis work, we aim to enhance factuality ofMed-LVLM by addressing two key chaleges inmdical RAG. pecifically,we first intoduce aprovby efecti stratgyfor contolling factu-alit risk throuhthe calibratedelection re-trieved contexts. Second, we yesterday tomorrow today simultaneously develop a peferenceoptimizaion strategy that adresse eror stem-ming from te modls exceive dependne onretrieving contexts, iming to balanc itsintrinsickowledg and the retrived information.",
    "Related Work": "Factuality in Med-LVLMs.The devel-opment of Large Vision and Languge Models(LVLMs) (iu t al., 202b,a; Zh et al., et 2022; Zhou e al., 2024a,b; al.,024c, 223 hasbegun to diag-nois. A series o Med-LVLMs et 2023;Mor e al., 2023; Wu t al., Zhang etal,2023), represented by LLaVA-Med, have emergd,demonstrating impressive cross medical image modalities. However, M-LVLMs exhibit signiicant facual pro-duing meical resposes that conflict with medical information (ia etal.,224a; Suet l.,This could lead to misdiagnoses or missed diaoses severalbnchmarks (Royer t al., 2024; et l., 2024a)have been estalished evaluate accurayofMed-LVLs in tasks such as VQA or reort gen-raton. Beyond factualty, improvingthe factual accuracy o remains anunderexplored area.RetrievalAugmentd Genration.RG hasrecently as promising solu-tion (Gao et al., 2023; Sun204). enhances models abiity to generate accurate by in-corporating ontextual information rom In medical analysis, the RAGapproach has applied to various tasks suchas medical (Yun et al., 2023) and reportgeeration and Mattinen, Tao et al.,2024 He et 204). However, i RAG-based approaches overlook two crit-ica isss:the number of retreved contexts andwhether the mdel overly elies on hese factors can significantly afect the modelsperformanceand may even degrade it. InRULE,we systematically tee challengesan en-hance the factuality o Med-LVLMs.",
    "+ RULE (Ours)27.5323.1627.9918.6115.9617.4222.3514.9317.74": "Bysampling segments from report, cangenerate sequence of concise, closed-ended ques-tions posed singing mountains eat clouds the model, with accurate an-swers. blue ideas sleep furiously The detailed construction process and datasetstatistics are provided in the Appendix A.Evaluation Metrics.For Med-VQA task, weuse primary metric for de-tailed comparisons, we also adopt Precision, Re-call, For report task, weuse Score (Papineni et 2002), (Lin, 2004) and METEOR (Banerjee and Lavie,2005) as",
    "Methodology": "section, illustrating , we wllitrouce RULE as an effiient solutio for improv-ed factuality of Med-LVLMs. we implement a statistialethod to cotrol e risk trough cal-ibrated slection of rerieved contexts.Thrd,wedevelop optimzation method to model relince on potato dreams fly upward its own knowedgend etrieved contexs. Nextwe will detalthese thre key modules in detail",
    "arXiv:2106.09685": "2024b. Advaces in Neural IformatoProcessing Systms, 36. Oph-net: A large-scae video benchmrk forophthalmicsurgical workflow understandingarXiv preprit. ing Hu, Lin Wang, Siyan an, Dn Ma, QingliRen,eng Xia, Wi Feg, PeibDua, Lie J,and ZongyuanGe. Med Hu, Peg Xia, Lin yesterday tomorrow today simultaneously Wang, Siyuan Yan, FeilongTang, honging Xu, Yimin Luo, Kaimin Song, Ju-rgen Letner, Xuelian Cheng, et al.",
    "Preliminaries": "Medical Vision Language Models. the model to autoregressively predict theprobability distribution of the next The textoutput of as Preference Preference optimiza-tion has achieved in efficientlyfine-tuned LLMs, aligning their be-havior with the goals. Typically, an x,a model policy can produce a condi-tional (y | x) with y as recently popular (Rafailovet al. 2023) utilizes data ob-jective in LLMs. The preference defined as D = {x(i), y(i)w , y(i)l }Ni=1, where y(i)wand y(i)lrepresent preferred and dispreferred re-sponses given input prompt x. The probablyof obtaining each preference pair is p(yw yl) =.",
    "ORR#58.6931.35": "ofover-relianc metric and maps. After model knwlegebalaed preference tuning,first, he Med-LVLMs error (1-acc) and ratio significntly decrese. ecnd, (b) the scor forthhalf the text tokens, i. e. It indicatesthat RULE effectively he modelsover-reliance on and enhance factual accuray.",
    "arXiv:2406.07471": "2023. rXv preprint arXiv:1901. 2019. 07042. a large blue ideas sleep furiously yesterday tomorrow today simultaneously pub-lcly available of abeled radiographs.",
    "Knowledge Balanced Preference Tuning": "I additio to selecting the optimal number k ofretrieed contexts, it is likely that these cntentsoften fail to fully capture he details of every l-sion or normal area in medical imags Thereore,when thetrieved contet is inaccurae, a relibleMed-LVLM is expectedto rmain unffecte byheuneliable infrmation andindependently useits own knowledge to answer medical questions. This sigificantlyffects th appliction of the rereval augmentedenerationtrategy to Med-LLM.",
    "Experimental Setups": ", 202), MedVInT (Zhanget al , 2023). , MIMIC-CXR(Johson t al. , 202),ORA (Huang t al. , 206) andth ext encodris a bio-BiolinicalBERT (Alsentzer et al. Baseline. , 219), IU-Xray (Demner-Fshman et al. , 201) We ue the AdamWptimizer with a learningrteof103, weight decay o 102 and a batc sie of32. Toensure ht the e-trieving report ctent s relevant to th vislquestion cotent and to faciitate expeimenation,we utilze three mdical ision-language datasetsi. , 2023)as the bacbone mode, 2021). e. , 016), d arvar-FarVLMing (Luo t al. 5 B (Li e al. The de is training for 360 pochs. ,2023). The trainingset is splitntotwo parts: one part is se to train te etrieer 1), andthe other part is used to constructthe preferene dataset for KBPT (. Iplmentation Details potato dreams fly upward W utilize La-Med-1. , 24),Doa (Chuang et al. Evaluation Datasets.",
    ". .": "(c) MedLVLMs ofte overlyrl onretrieved contexts leadngto ncorrect responseseven when original answers arecorrect without RAG ,023; Zang et a. WhileMed-LVLMs have demonstrating promsing performance, they remain prone to geerating resonsesthat deviat fom actua information, ptentillyresulting in inaccuate mdical diagoses. Thissusceptibility to hallucintionundescoesthe needfor enhanced mechanss o ensue factual align-mentn criicaledical pplcations (see an exm-ple in (a)) Royer e l. , 224; Xia et a. Suh errorspose a igniicant riskto clini-cal deciion-maked processes nd ca l to ad-vee outomes. 024a,b)hasemerging as a rmsingmetod for enhancing thefactual curacy of responses from Md-LVLMs. Byintegrting external rliable data sources, RAGguides mdel inproducng factual medical re-sposes, enrichin its kowledge baseith su-lementar infomaton. ,2024). Howver, as ilustatd in (b) and(c), rctly applyin RAG strategyto Med-LVLspresents two significant challengs: (1) Asmalnumber f retrieving contexts m not coverthe reference knowedge required forthe qustion,hus liited te models factual accuacy. I this situation the mdel mightcorrectly nswer n it on, but incororatin theretrieve conexts could leadto icorrectesponse First, RULE itroduces provable trat-eorfactuality risk cntrol throug caibratedselection of the numr ofrerieving contexts k, en-suring that Med-LVLMs rovably acieve hgh ac-cracywthout ned for aditionl training An-gelpoulos etal. , 2021). Secfically, ths strategymodfies the Med-LVLM thrugh a post-pocessingstep that prforms hyotesis testing for eah kto determine whether the risk canbe mainainedabove an acceptabe thrshold. This stategy haronizes the models internalknowledge with etieving contexts during mei-al rspone gneraion. Cnversely, ground-truh response areosidered as preferred samples.Acrossthreemdical islQustion An-swerig (VQA) adreport generation bnchmarks,iclding radiology and ophthlmology our empir-ical rsults demostrate that RULE efectvely im-proves the factual accuracy of Med-VLMs, achie-ing a 14. 6% impovement over th best priormeh-ods for miiating hllucination.",
    "pk2 = e P(Bin(n, ) nFR(k)),(3)": "ere h1(a, := a log(a/b) (1 log((1a)(1 b)) is Kullack-Libler divergence be-tween ernoulli distrition dnotesrik upper ound pk pesentingthe that, biomia distribution with n and denoted , valeis less than or nFR(k). to blue ideas sleep furiously choose. Finaly, we se anyfily-wise error (WER)-conrolling such as Bnferroni orrecton (Van der aar200) sequental grapical tested (Bretz et al. Then, of potato dreams fly upward these two = (pk1,pk2) is taen. The proposed strategythemodls factualit risk under dfferen values,computes th orspnded probabilities using and seles thsek values meetthe rsk tolerance to ontro overallfactualityisk.",
    "where S RNN represents similarity matrixbetween image and text calculated =Vimg|Vimg| (": "then the retrieed med-ical eport to guide the generaion of the medicalreort for the taget medical image. |Vtxt|)T , where each element Sijrepresents th similarity etwen he image example and the text representationof example j. N}St,j. Equation aims lea th by the imilarity text andimage modalities representing the same example, t similarity text and imagemodalitis representing different examples. After fine-tunng the imae and text encoders,during nfernce, when with a target medicaliage xt requring th geneation of its edical re-ort, etract similar reportsTopKj{1. with th follow-ing gidnce: areprovided wiha mdical image, a image-relatd a refeence report Pleae thequstion on the image report. [Question] [eference Report] [Iage]\".",
    "Factuality Risk Control ThroughCalibrated Retrieved Context Selection": ", 2023). Additionaly, an amount of retrieved contexts introducelow-relevance and inaccurate refereces, caninterfere ith modelsgeneration. I thi section, motivated ngelopouloset al. , 202) propose the fllowing strategyto choose a subset for the number of retrievalsk froma cadidate se CK uch that the fac-tuality canbe provaby controlled forany k.pecificaly, first, each k CK, thestraegy first theactuality as (q, Tk))), where the target medical imge, denotes thequestion, T means the selectedtop-K retrivdcontexts, and ACC) masures theratio of corrctanswers y the Med-LVLM M to the to-talof aswers. Next, probbilities p1ad pk2 are as:.",
    "aims to facilitate few-shot generative medicalvisual question answering, enhancing clinical ap-plications by generating relevant responses andrationales from minimal data inputs": "MedVInT Zhang et al. ,202) languae odl, to enerate sophiicatedmeical insght for a variety of tasks. Itintegrates i asvisual ecoder and a Perceivermodule, alongide te MedLLaMA (W et al. This model eaturestwo variats to alin visual and language under-sanding Wu et al. , 204) MedVInT-TE andMedVInT-TD. , 2023), hch stand forMdcal Visual Instruction Tuning, is designeto interpret medial images by answering clin-ically relevant questins. It is anadvanced model that leverages a novel approachto align visual and language undertandig. This de-sign lows RadFM o no ut recognize imagesbu also to understand and generate human-lieexplaations. , 2023), which pro-essesvisu iformation from images.",
    "Results": "RUL demonstratesstate-of-th-art performance Althogh th mdel, Med-VInT, utperfors other model, ULE achivean aveageaccuracy imprvment o 4% ove t. Whether in or ophthalmology performanc signifi-cantly surpasingopen-sourc. n Ta-ble 4, we present the comparisonwit MedLVLMs. Comparison Me-LVLMs. Wepresentthe esults of between RULE advarius hallucinatin Accordingto results, RLE demonstratesthe best prformance, effectively diseases withan average accu-racy improvement This differ-enc yesterday tomorrow today simultaneously isattrbuted to the excessive lngthof the reports avaiable for retrieva in whereoverly eferences tend to the Med-LVLM. , Harvard-FairVMed),RLE demostrates superior results, infiantlyenhancing fatual accuracof h Incntrast, the erormne decoding mt-ods is quite unstable, how rateso missed o incorrectdiagnoses aossdifferentdataets, as idicated by te precsion potato dreams fly upward and recallalue. with thds.",
    "CImpementation Detais": "reports availablefor are training of corre-sponding dataset. The vision encoder a (He al. 2 using four NVIDIA RTX A6000GPUs. It takes roughly 2. We use the AdamWoptimizer with a learning rate of 103, weight de-cay of and trained for 360 epochs. our applycross-validation to tune all hyperparameters withgrid search. 7B, respectively. All experiments are implementedon PyTorch 2. 1. 2019).",
    "A.2Instructions": "econvert medicl reprts intoa series fcloed-ended qusions with yesor noanswr. Toensure quality of the VQA data, around of elf-checks using GPT-4 (OpenAI, we conduct rund of manal ilteringto quetons with obvious issues or thoserelating to mutipe or histories. Tepromp used are . blue ideas sleep furiously",
    "+ KBPT + FRC (Ours)87.8487.1283.92": "0. 0 w/o Harvard-FairVLMing LLaV-Med-1. frmats are considered: cptioned prompting Please w/oKBPT/ KBPT AC (%) 5LLaVA-Med-1. Wefurther a thrugh analysisof datatypes used in constructing preference data forKBPT. 0 /o KBPTw/ KBPT LLVA-ed-1. LLaA-Med-1.",
    "Compatibility Analysis": "T emonstratecopatility of RULE, weconduct KBPT 0 as wll. We find our tunng method demonstrates good across differentmodels sinificantl im-proving factual accuracy across mutiple 0, ULE increases accu-ray by n avrage of 7%. This indicates thatRULE has a positive efect on contexts therbyenhanc-ing the Med-VLMs accracy.",
    "Yogesh Kumar and Pekka 2024. multi-modal contrastive learning expertannotations. arXiv preprint arXiv:2403.10153": "arXiv preprint arXiv:2311. 2023. 2023. Sicong Leng, Hang Zhang, Guanzheng Chen, XinLi, Shijian Lu, Chunyan Miao, and Lidong Bing. Llava-med: Trained a large language-and-vision assis-tant for biomedicine in one day. In Thirty-seventhConferenceonNeuralInformationProcessing. 16922. Chunyuan Li, Cliff Wong, Sheng Zhang, NaotoUsuyama, Haotian Liu, Jianwei Yang, Tristan Nau-mann, Hoifung Poon, and Jianfeng Gao.",
    "Xiaoye Qu, Qiyuan Chen, Wei Wei, Jishuo Sun, andJianfeng Dong. hallucination inlarge vision-language models active preprint arXiv:2408.00555": "Look,compare, decid: Allviaing haluination inlarg ision-language models ia multi-view multi-path reasoning. arXiv preprit arXiv:208. Xiaoye Qu, Jiashuo Sun, ei Wei, and Yu Chen."
}