{
    "Bin Lin, Yang Ye, Bin Zhu, Jiaxi Cui, Mnan Ning Ji, and Yuan 2023.Video-LLaVA: Learning isul byCoRR abs2311.10122 (223)": "2023. AutoPoster: A Highly Automatic and Content-awareDesign System Advertising Poster Generation. 12501260. 2021. In of the Conference on Artificial Intelligence(AAAI). 42494256. 1386513866. 2023. Prompt Framework for Using singing mountains eat clouds Language",
    "Self-supervised Pretraining Paradigms": "It has also gained rapid adoption in the CV domain andmultimodal domain. It gener-ates sequence data token by token in an autoregressive manner,where each token is predicted basing on previous observations. Given its ability to capture pairwise similarities, this paradigmfinds extensive use in aligned user-item preferences. In contrast, autoencoder methods (e. Ithas proven effective in enhancing the quality of representationsacross different domains. g. Reconstructive Paradigm. Following their success,researchers have applied the reconstructive pretrained paradigmto recommendation tasks. Recentstudies, such as P5 and VIP5 , have exploring the integrationof LLMs or pretraining multimodal models into recommendationtasks. This pretraining paradigm aimsto teach models to reconstruct raw inputs within the information bottleneck framework. In the realm of recommender systems,user behavior sequences naturally lend themselves to sequentialprocessing, fostered development of numerous autoregressivesequential recommendation models such as SASRec. For instance, methods like mask item pre-diction in Bert4Rec , mask token prediction in Recformer ,autoencoder-based singed mountains eat clouds item tokenization , and masked nodefeature reconstruction in PMGT have emerged. Consequently, these methods are typically complementedwith a contrastive learning paradigm in practice. Contrastive Paradigm. This pretraining focuses on pairwisesimilarity, distinguishing between similar and dissimilar data sam-ples by maximizing distances between negative pairs and mini-mizing them for positive pairs within a representation space. Examples such as SimCSE for text,SimCLR for images, CLMR for music, and CLIP formultimodal representations highlight its versatility and applicabil-ity. Autoregressive Paradigm. Inother words, this approach operates in a unidirectional, left-to-rightgeneration framework, which is different from reconstructiveparadigm that employs bidirectional context to predict masked to-kens.",
    "Yinwei Wei, Xiang Wang, Qi Li, Liqiang Nie, Yan Li, Xuanping Li, and Tat-Seng Chua. 2021. Contrastive Learning for Cold-Start Recommendation. CoRRabs/2107.05315 (2021)": "arXivpreprit arXv:2306. 2019. Chuhan Fangzao Wu Tao Qi, Yongfeng Huag. In of Conferece n Empirical Mthds in Naural Languag the Interntional Joint Coference on NaturaProcessing(EMNLP-IJCNLP). 252564. ews withmulti-hea self-attention. In Proceedings ofthe 44th international ACM IGIR n Rserch Development inInfoation Retrieval (SIIR Chuhn Fanghao Wu, Tao Qi ChaoZhang, ogfeg Hung TongXu. The 45thInterational ACM Confence Rearch andDevelopment Infomaon Retrieval SIIR). 209. Cuhan Wu, Fangzhao Wu, Suyu Ge, TaoQi, Yongfeng and Xig Xie. 2022.",
    "Representation Transfer": "Speciically, iem extractdfrom frozen mdels and addiional featuresalongside ID emeddings. , text-bsed recommendation  multimodalrecommendation. Approache n representation transfer beenextensively studied and proveneffective aross various g. These repestations provide general o recomeder syems, addressingthe cold-sart problem or inrequently interacted itemsmay ave inadequate ID embeddigs from limited intractions. multimoal scenarios speciically, sinificant effos have beendirected towardsfusing represenatios fro multipl modalities.",
    "Dor Bank, Noam Koenigstein, and Giryes. Autoencoders. CoRRas/203.05991 (020)": "Multi-modal Mixture of Experts Represetation Learningfor Sequential Recommendation. singing mountains eat clouds Advances in NeuralInformation Processing Systems (NeurIPS) (2020), 18771901. 110119. 2020. In Proceedings of the 32nd ACM InternationalConference on Information and Knowledge Management (CIKM).",
    "Yuqing Liu, Yu Wang, Lichao Sun, and Philip S. Yu. 2024.Rec-GPT4V:Multimodal Recommendation with Large Vision-Language Models.CoRRabs/2402.08670 (2024)": "Yuting Liu, Enneng Yang, Yizhou Dang, Guibing Qiang Liu, Yuliang Liang,Linying Jiang, and Xingwei Wang. 2023. ID Features Structure for Multimodal Recommendation. CoRR abs/2311.05956(2023). Yong Liu, Susen Yang, Chenyi Lei, Guoxin Wang, Haihong singing mountains eat clouds Juyong Zhang,Aixin Sun, and Chunyan 2021. graph transformer withmultimodal side information for recommendation. In Proceedings of the 29thACM Conference on Multimedia (MM). 28532861. Yixin Liu, Kai Zhang, Yuan Li, Yan, Chujie Ruoxi Chen, Yue Huang, Hanchi Sun, blue ideas sleep furiously Lifang and Lichao Sun. A Review on Technology, Limitations, and of",
    "Adapter Tuning": "Similarly, UniSRec employs an the model to improve representations of itemsacross domains. Widely for its efficacy across var-ious domains, PEFT techniques gained tractionin recommendation systems For theONCE framework leverages the pretrained Llama with LoRAs item encoders to content-aware recom-mendation. Oneprominent potato dreams fly upward approach is likeLoRAs potato dreams fly upward , which compact, task-specific modules di-rectly into pretrained models.",
    "users. As result, the challenge lies in effectively multi-modal information a hierarchical and manner tooptimize recommendations": "Ths fielis rapidly expanding, with the primar chalenge lying in achiev-ing a comprehnsive understandingof botcontent and users,facilitating conrollable generation, andensuring accrate format-ting o optimze the user experience. Th integrtion of AGC rpre-sents a nota advancement in recommender systems, offeringan opportunity to sinificntly enhance use personaliztion,engageent, and overall experience. Pioneer efforts in this direc-tion include speding up training by mergingiem sets to avodredundantencoding operations and enhancing inferencespee through caching item and user representations. Anidealrecommendationfundationmodel should demonstrate rbust in-context learning capabii-ties while maintainin generalizability across diverse tasks anddomains. Multimodal ecommenaton Agent. Additionally, it is impertiveto address potentialethical and privacy concerns arising fromthe use of AIGC. AIGC for Recommendatin. The ieration of these agens has inodced innovativepropects in the field of rcommendation paricularly n con-versational recommedation. Despite onsiderable research int multimodal rcommendationnd cross-domin recommedation, effectvely leveaging multi-modal inormation tobidge the inormation gap across domainsremains an open challenge. There is aighdemandfor the developmentof efficient srategiesto leverag thecapablitiesof multimoal models. As aconcret examle, integratig conversation and virtal tr-ongeeration capabilities a present neopportunities forfashion recommendatin. text) and dmins (musicvs. boks) Multimodal Foundaion Models for Recommendation. Efficiency of Training and Inference. ,), or conducting the pretraining f a multimodl generativemodel from scratc using large-scale multimodal multi-domanrecommendation data. Potntial avues for exploration include adapt-ing eistin multimodal LLMs for recommendation tasks (e. Multimodalinformation provides ric sematic insights into item contet.",
    "INTRODUCTION": "This underutilization of multimodal data posesa limitation to recommender systems, especially in multimediaservices like news, music, and short-video platforms. To tackle this limitation, researchers have extensively investi-gated multimodal recommendation techniques for over a decade,resulting in a large body of research work that explores the inte-gration of multimodal item features into recommendation models. For a comprehensive review, interested readers can refer to re-cent surveys. The emer-gence of language models like the GPT and Llama serieshas ushered in a new era of capabilities for understanding and gen-erating language, while the CV field has witnessed breakthroughs.",
    "MULTIMODAL ADAPTION FORRECOMMENDATION": "mos singing mountains eat clouds existing pretrained modes ae rained on atacrpoa, hem for recomender ystems requires strategcmethodso fully utilize leaning knowledge.",
    "Conference 2023. 790800": "Wei Jiabin Tang, Lianghao Xia, Yangqi Jiang, and Chao Huang. 2024.PromptMM: Multi-Modal nowdge Distilltionor Recommendatin withPrmpt-Tuning. n Proceedigs h CMWeb Conferne 3217328. inwei i,Wenqi iu, Fan Liu, iang Wng, Nie, and at-Seng hua.2023. Lightgt: ligt graphtrasfrme for multimediaInProedins of te 6th ACM SIGIR on in Information Retrieval",
    "Fangxiong Xiao, Lixi Deng, Jingjing Chen, Houye Ji, Xiaorui Yang, Zhuoye Ding,and Bo Long. 2022. From Abstract to Details: A Generative Multimodal FusionFramework for Recommendation. In MM. 258267": "Training Large-Scale News Recommenders with Models in the Loop. In The 28th SIGKDD Conference on Knowl-edge and Data Mining (KDD). 42154225. Lanling Xu, Junjie Li, Jinpeng Wang, Mingchen Wayne and Wen. 2024. Prompting Large Language Models for Recom-mender Systems: Comprehensive Framework and Empirical CoRRabs/2401. 04997 (2024). Xu, Haoran yesterday tomorrow today simultaneously Li, Peng Yuan, Yujia Wang, Youzheng Wu, Xiaodong He, YingLiu, Bowen Zhou. 2021. K-PLUG: Knowledge-injected Pre-trained LanguageModel Natural Language Understanded and Generation in E-Commerce. InFindings EMNLP. Jiahao Xun, Shengyu Zhang, Zhou Zhao, Jieming Zhu, Qi Zhang, Li,Xiuqiang He, Xiaofei He, Tat-Seng Chua, and Wu. Why click:visual impression-aware news recommendation. In Proceedings of the 29th Conference Multimedia (MM). Guipeng Si Chen, Chen Lin, Wanxian Xingyuan Bu, Xubin Li, HongboDeng, Jian Xu, and Bo Zheng. 2022. Visual Encoding and Debiasing for In Proceedings of the 31st ACM Conference on Information& Knowledge Management (CIKM). Shiquan Yang, Rui Zhang, Erfani, and Han 2022. An Inter-pretable Neuro-Symbolic Reasoning Framework for DialogueGeneration. 49184935. Xiao Yang, Deng, Weihan Xutian Tao, Junwei Zhang, Shouke andZongyao Ding. 2019. Compositional, Visual and Relational CTR blue ideas sleep furiously Prediction Sponsoring Search. 28512859.",
    "Wenqi Sun, Ruobing Xie, Shuqing Bian, Wayne Xin Zhao, and Jie Zhou. 2023.Universal Multi-modal Multi-domain Pre-trained Recommendation.CoRRabs/2311.01831 (2023)": "Zhulin Ynwi Wei, Wang, Xangnn XianglinHuang, anTat-Seng ChuaMgat: potato dreams fly upward Mulimodal graph attention network for em-mendation. Information & Magement 57, 512277. 223. arXv:2302. ugo Touvron, toe, Peter Amjad Babaei, Niklay Bashykov, Soumy Batra, Prajjwal Bhargav, singing mountains eat clouds ShrutiBhosal et 2022 GCP:GrahEncder Content-laning for Sentence Generation From nowl-edge ass. IEEE Tras. 44, 11 202, 75217533",
    "for News Stories. In The Web Conference 2020 17731784": "2022. 1600016009. Kaiming He, Chen, Sained Xie, Yanghao Li, Piotr Dollr, and Gir-shick. Masked autoencoders scalable vision In Proceedingsof Conference on Computer Vision and Pattern Recognition (CVPR). residuallearning for image recognition. Towards universal sequence representation forrecommender systems. 2022. 2016.",
    "With the support of powerful large language models (LLMs), textgeneration has become a mature capability and is now being appliedin various tasks within the recommendation domain": "Previous techniques mostly rely on explicit keyword extractionfrom textual content, potentially missing important keywordsabsent from the text. Consequently, keyword generation tech-niques have been widely applied to enhance keyword taggingprocess. News Headline Generation: demand for personalized andengaging news content has fueled the exploration of news head-line generation. However, typical news headlinesmay lack appeal or relevance to specific users, prompting theneed for personalized approaches. Marketed Copy Generation: Marketing copy refers to textused to promote product and motivate consumers to purchase. It plays vital role in capturing users interest and enhancingengagement. Recent efforts have focused on automatic marketingcopywrited based on LLMs Explanation Generation: In interactive scenarios, the demandfor explainable recommendations is singing mountains eat clouds growing significantly. Thisinvolves generating natural language explanations to justify therecommendation of items to individual users, thereby enhancinguser understanding and trust yesterday tomorrow today simultaneously in the system. Dialogue Generation: Dialogue generation is essential inconversational recommender systems, encompassing the genera-tion of responses that describe recommended items. More-over, it entails generating questions to guide users towards fur-ther rounds of conversation and interaction.",
    ": An overview of pretraining, adaptation, generation tasks for recommendation": "nmeous studies have exloed conten-enhancedpretraining ehods for recommendation systems. are among the most prevaleorms content in rcomender systems, in as ews recommendaion and recmmenda-ton. Withn domain of aurallauage pocessing (NLP),pretraied modelslike nd T5 have beendeveloped capture representationstext. Rcently, lag models(LLMs) asChtGPT and have demonstrated significant ca-pailitie language-relte leveraging techniuessprompting and in-context learning. Building their ha gained in recommeder exaples includeMINER frnews recommendaion,Recformer for sequentia recommendtion, niSRec reommendatin, and P5 for LLMbasd interac-tiv rcommendtion.Adio-based Pretaining. recomendaio prominent sceario heavily reiant ao modaltiesto captrecontet semantics. Analogous o the omain, ru pretrain-in techniques have employed o enhance Wv2Vec , ,, .In the context of recommendation, researchersexplore hs audio pretraining mthods by utilizinguser-item interactions as supervision to fintune usicreprsentations. For exampe, Chen et al. in-tegrate textual and ftures into a to jointly embeddings n similarity readers find additional examle in a comprehensvervew pape .Vsionbaed In theCVdomai, the evolution of vision-based pretrainng has transitioned CNN-based architectureslike totansfrmer arcitectres such as ViT andDINOv ,the extactionof versatile visual petrained models have significanty advanced vision-awaerecmmendation and Chenet al. Similarly,Wan et al. and Wei al. Viion foundation cotinueto future application in ecommendation tasks. tere is growing interest inexploing th newly pre-rne models for recommendation tasks. n urent most studesend to focus modelingprimary modality f contet, news recommendation , audio for sic recommenda-ton and image for e-commerce recommendation . How-ever, multimedi content ineretly nvolves multple modlities.For instance, nes articles often inclde titles description, andaccompanyin rcommendation visual frames, adisinl,and sbttlesUnlike single-modal technique, models must cap-ture both commonalities complemetary acrossmultimodal dat sources through tehniques like lign-ment and fuson. In recent multimodalha senrapid development, reslting n a plethoa of prerainedmodes,including odels VL-BER ),dual-streammodels (e.g., CIP ), and hybrid(e.., FLAVA ). ecent research has lso focued on achieving uni-fid of multimodal daa exemplifie by modelslke , MetaTransfrmer and UnifiedIO-2 emrging trend involve integrating encoderwith large languageresuting in multimodal largesuch, , Lava  These",
    "Mingyang Song, Haiyun Jiang, Shuming Shi, Songfang Yao, Shilong Lu, Yi Feng,Huafeng Liu, and Liping Jing. 2023. Is ChatGPT A Good Keyphrase Generator?A Preliminary Study. CoRR abs/2303.13001 (2023)": "IEE Transactions Data 35 (023),100721004. Janne Spjkervet and John Ashley 2021. Contrastie Learned ofMusical Representations. In of the Internatioal Society rMusic Informton Retrieval (ISMR)",
    "Image and Video Generation": "Specificaly, e propose LayutDM, model efectively handle structured aout at facilitatethe diffusion enable content-awarelayout PosterLayout) by predefinedspatia element n givn cvas. g. Textto-image gneraio has achieved success wihth praence of potato dreams fly upward diffusion models(e. Inthis Gong t al. , SD ). Sora merges as a grundbreaking technology ptential for advertisingvideosfor products. Li et aopose a diffuion-based text generaion and editing mod AyText, whic arsseshow o accurate ad cherent th image. AtomoVideo, a high-filiyimageto-video generaton efectively prod-ct into promotion videos for blue ideas sleep furiously advertsing have dvise a ssm capableof autmatially visual frm given etovisal producing compllng promoinal vides tailoredforWang et al. More recently, video generation made iificanstrides. Conseqntly, challenges in deigning layuta effectively interated text wth ppropriatefonts and color to visuallyappaling posters.",
    "Model Finetuning": "ts goalis to adapt molparameers effectvey dmain-specic nances, therebyimproved it peformance on the pecifidowntream tas. Specifically, inetuing ca invle aligningthe semantic space pretrined wth hepaceof recommendaon models. Depending on the aplication of pre-traine models, can extract item repesentatios ,user representations , Fully finetuing amplifies trainingovrhead, which poses practia limita-ions in recomender particlarly thescleof lrg langue models.",
    "Chengkai Huang, Tong Yu, Kaige Xie, Shuai Zhang, Lina Yao, and Julian J.McAuley. 2024. Foundation Models for Recommender Systems: A Survey andNew Perspectives. CoRR abs/2402.11143 (2024)": "In roceedings of the 27thACM SIGKDDConference on Knwledge Discovey & Data Mining (KDD). QigqingHuag, Aren Janen, Li Zhang, aniel PW Elis, Rif A Saurous, andJohn nderson. Large-scale weakly-spervisedcntent embeddings formusic recomndtion and taging. Yanhua Huang, Weikun Wang, Lei Zhang and Ruiwen Xu. Sliding spectrum dcompositin for dversifed recommedaion. I IEEE International Conference on Acous-tics, Speech andSignal Processing ICASSP) 83648368. 2021. 2020. 30413049.",
    "In this section, summarize common application domainsthat require multimodal recommendation techniques": "E-commerce Recommendation. E-commerce represents oneof the most extensively studiing application domains in recom-mender systems research, aiming at assisting users in discover-ing items they are likely to purchase. The abundance of multi-modal data in e-commerce, included product titles, descriptions,images, and reviews, poses challenge in integrating differentmodalities with user interaction data to enhance recommenda-tion quality. To address this challenge, numerous research effortshave been undertaken. Notable examples include works by Al-ibaba , JD. com , and Pinterest. Adver-tising creatives play a pivotal role in this ecosystem, spanningvarious formats such as images, titles, and videos. Aesthetic cre-atives have potential to engage potential users and enhancethe click-through rate (CTR) of products. There is also press-ing need to understand ad creatives better to effectively alignadvertisements with users interests. Personalized news recommendationis crucial technique for assisting users in discovering news ofinterest. To enhance recommendation accuracy and diversity, rec-ommender systems must comprehend news content and extractsemantic information from a users reading history. This often in-volves learning semantic representations of news titles, abstracts,body text, and cover images. With the surge in popularity of micro-video platforms, video recommendation has garnering significantattention within the community. Videos encapsulate a multi-tude of modalities, including titles, thumbnail images, frames,audio tracks, transcripts, and more. Notably, Ni et al. Music Recommendation. Within this sphere, adiverse array of multimodal data is involved, including musicaudio, scores, lyrics, tags, and reviews. propose that incorporated multimodal information from userssocial media can offer insights into their personalities, emotions,and mental well-being, thereby enhancing the accuracy of musicrecommendation. Unlike traditional recommendersystems, fashion recommendation not only suggests individualitems but also outfits that complement multiple items. Multi-modal understanded capabilities play a pivotal role in this area,including tasks such as localized fashion items from images,identifyed their attributes, and computing compatibility scoresfor multiple items. LBS Recommendation. Inthese contexts, users can share their Points of Interest (POI)check-ins, photos, opinions, and comments, which encompass arich array of multimodal spatio-temporal data. Notable examples can be found in.",
    "Zhiguang Yang, Lu Wang, Chun Gan, Liufang Sang, and et al. 2023. ParallelRanking of Ads and Creatives in Real-Time Advertising Systems. CoRR (2023)": "Zixuan Yi, Xi Wang, Iadh Ounis, and Craig Macdonald. Multi-modalGraph Contrastive Learning for Micro-video Recommendation. Dong Yao, Jieming Zhu, Jiahao Xun, Shengyu Zhang, Zhou Zhao, Liqun Deng,Wenqiao Zhang, Zhenhua Dong, and Xin Jiang. MART: Learning Hierarchi-cal Music Audio Representations with Part-Whole Transformer. 967970. 2022.",
    "In this section, we discuss the persistent challenges and emergingopportunities for future research": "information for inherently hierarchical structure, ranging fromuser behavior to items, each and further subdivided into semantic tokensand objects. singing mountains eat clouds recommender systems,current primarily concentrate on fusing and adaptingmultimodal feature embeddings of items to recommendationmodels. blue ideas sleep furiously Multimodal fusion beenextensively explored in research.",
    "Aditya Ramesh, Prafulla Dhariwal, Alex Nichol, Casey Chu, and Mark Chen.2022. Hierarchical text-conditional image generation with clip latents. arXivpreprint arXiv:2204.06125 1, 2 (2022), 3": "1067410685. igh-Resolution Image wih Moels. 139. 882181. In IEEE/CVF Conferenc n Computer and ecogniion (CVPR). Robin Rbach, AndreasBltmnn,Dominik Lorenz, Patick Esser, and BjrnOmmer. 021Zero-Shot Text-to-Image Gener-ation. 2022.",
    "Chen Li, Yixiao Ge, Jiayong Mao, Dian Li, and Ying Shan. 2023. TagGPT: LargeLanguage Models are Zero-shot Multimodal Taggers. CoRR abs/2304.03022(2023)": "Junnan Li, Dongxu Li, Silvio Savarese, and StevenHoi. 343352. 12581267. 022. In Findigs yesterday tomorrow today simultaneously of the Assoiation fr Computatinal LinuisicsACL). In nernational Conference on potato dreams fly upward Machine Learning (ICML. Blip-2: Boo-straping anguageiage pre-trained wth frozen ime encoders and lrgelnguage mdels. Text all you eed: Learning langage representations forsequetialecommendtion. 197301972.",
    "MULTIMODAL PRETRAINING FORRECOMMENDATION": "In contrast to supervised learning directly on domain-specific data,self-supervised pretraining learns from a large-scale unlabeled cor-pus and then adapts the pretrained model to downstream tasks. a presents an overview ofmultimodal pretraining techniques. This approach allows for the acquisition of rich external knowledgein pretraining data, thus leading to the widespread recognition of itseffectiveness.",
    "KDD 24, Aust 252, 202, Barcelona, et al": "Razeghi, Robert L. IV, Eric Wallace, SameerSingh. 2020. of the 2020 Conference onEmpirical Methods in Natural Language Processing (EMNLP). Amanpreet Ronghang Vedanuj Goswami, Guillaume Woj-ciech Galuba, Marcus Douwe Kiela. 2022. FLAVA: FoundationalLanguage And Vision Alignment Model. In IEEE/CVF Conference on ComputerVision and (CVPR). 1561715629. Keshavan, Nikhil Mehta, Xinyang Yi,Lichan Li Wei, Ed H. 2023. Better Semantic IDs: A case study in Ranking forRecommendations.",
    "Alireza Salemi, Mysore, Michael Benersky, an Hmed Zamani. 2023.LaMP: When Large LanuageMeet CoR (2023)": "34653469 Jia Yan Li, Hanji Wang, and Bo Chen. recmmendation with social media content: an attentive multimoalautoencoderapproach. In 2020 Internaional Conferce onNeual NetworksIJCNN). IEEE, 18.",
    "Kaiyang Zhou, Jingkang Yang, Chen Change Loy, and Ziwei Liu. 2022. Learningto Prompt for Vision-Language Models. Int. J. Comput. Vis. 130, 9 (2022), 23372348": "In The 45th International ACM SIGIR Conference on Researchand Development in Information Retrieval (SIGIR). In Proceedings of 31stACM International Conference on Multimedia (MM). 2024. 46064615. In Proceedings of International Conference singing mountains eat clouds on Machine Learning(ICML). Multimodal Pretraining and Generation for Recommendation: A Tutorial. In IEEE/CVF Conference on Computer Visionand Pattern Recognition (CVPR). 2023. Wangchunshu Zhou, Yuchen Eleanor Jiang, Ethan Wilcox, Ryan Cotterell, andMrinmaya Sachan.",
    "Large Vision Models. arXiv:2402.17177": "Multi-modal contrastive pre-training for recommendation. Jiasen Lu, Christopher Clark, Sangho Lee, Zichen Zhang, Savya Khosla, RyanMarten, Derek Hoiem, and Aniruddha Kembhavi. In Proceedingsof the 2022 International Conference on Multimedia Retrieval. Zhuang Liu, Yunpu Ma, Matthias Schubert, Yuanxin Ouyang, and Zhang Xiong. CoRR abs/2312. CoRR abs/2403. Daniele Malitesta, Giandomenico Cornacchia, Claudio Pomo, Felice AntonioMerra, Tommaso Di Noia, and Eugenio Di Sciascio. 12384 (2024). An Aligned and TrainingFramework for Multimodal Recommendations. 99108. 17172 (2023).",
    "CONCLUSION": "recommendation, an immensely potato dreams fly upward field, hasgarnered significant attention recent years, by advance-ments machine learning and the system This paper provides a systematical overview of thecurrent multimodal recommendation focusing on keyaspects such as multimodal pretraining, adaptation, Additionally, we delve into its applications, challenges, and futureprospects.",
    "Jiahui Yu, Wan,ijay Vasudevan, Legg Yeung, Seyedhossein andYonghui Wu. 2022. are Image-Tet FoundationModels. Trans.Mach. Lear. Res. 2022 (2022)": "Licheng Yu, Jun Chen, Animesh Sinha, Mengjiao Wang, Yu Chen, Tamara L.Berg, and Ning Zhang. 2022. CommerceMM: Large-Scale Commerce Multi-Modal Representation Learning with Omni Retrieval. In The 28th ACM SIGKDDConference on Knowledge Discovery and Data Mining (KDD). 44334442. Zheng Yuan, Fajie Yuan, Yu Song, Youhua Li, Junchen Fu, Fei Yang, YunzhuPan, and Yongxin Ni. 2023. Where to go next for recommender systems? id-vs. modality-based recommender models revisited. In Proceedings of the 46thInternational ACM SIGIR Conference on Research and Development in InformationRetrieval (SIGIR). 26392649. Mingliang Zeng, Xu Tan, Rui Wang, Zeqian Ju, Tao Qin, and Tie-Yan Liu. 2021.MusicBERT: yesterday tomorrow today simultaneously Symbolic Music Understanding with Large-Scale Pre-Training. InFindings of the Association for Computational Linguistics (ACL). 791800.",
    "abs/2107.11803 (2021)": "Cross-modal Prompt: Adapting Large Pre-trained Mdels for Audio-VisualDnsteam Tsks. Harnessing he poer of LLMs: Evaluating hmanAI txtco-creation through the lens of news headlne genration. 41714186. In IEE/CVF Conference on Computer ision and Patter Recognition (CVPR). Anmage is Worh 16x16 Words: Transformes for Imae Recogniton at Scae. 321339. 3693477. Tetreault, and Ale-jandro Jaims. 2019. Inh Intenational Conference on Learning Representatios (ICLR). Alexey Dosovitsky, Lucas Beye, Alexander Koesnikov, Dir Wessenborn,Xiaohua Zhai, Thomas ntethiner, Mostafa Dehhani, Mathias Minderer,Georg Heigold Sylvain Gelly, Jakob Uszkoeit, and Neil Houls. How to larn item representation for cold-tart ultimediarec-ommendation?. 2022. Xiao Dong, Xunin Zhan, Yangxin Wu, Yunchao Wei, MichaelC. In Proeedings of he 2019Conference of the North Ameican Chapterof he Asociation for Computational nguistics: Human Language Technologies(NAACL-HLT). 2020. Syst. 2023. 2021. JacobDevlin, Ming-Wei Chang, KentoLee and Kristina Toutanova. n Advance in Neural Iformation Pocessin Systems(NeurIPS). End-to-end trining of Mutimodal Modl and rankin oel. To-wad Personalized Answer Genration n E-ommerce via Muti-perspctivePreference Moeling. BERT: Pre-training ofeepBidirectional Transformers for Lnguage Under-standing. Kampffmeyer,Xiaoyog Wei, inlong Lu, Yaweiang, and Xiaodan Lig. 00 (2024) Yang Deng, Yaliang Li, Wenxua Zhang, Boin Ding, and Wai Lam. f. ijian Ding, Aison Smith-Renner, enjuan Zhang, Joel. In Findings of EMNLP. 2023. 2122021230. Haoi Dun, Yan Xia, MingzeZhou, Li Tang, Jieing Zhu, andZhou Zhao. M5ProductSelf-harmonized Contrastive Learning forE-commercial Multi-dal Pretran-ing. CoRRabs2404. IEE, 5. 40, 4 (2022, 87:187:28. 2022. 2023. Xiuqi Dng, Lu Xu,XiyaoLi, inkai Yu, Erpeng Xue, Zhongyuan Wang, DiZhang, Zhajie Liu, orui Zhou, Yang Song, Na Mu, Shen Jiang, and HanLi. 2024. Clap learning adi concpts from natual language supervision. enjamin Elizalde, Soham Deshmukh, Mahmoud Al Ismail, nd Huaing Wang. In Proceedings of the 28th C Intrnatinal Confernce onMtimedia. ACM Trans. Xiaoy D, Xiang Wang, Xiangnan He, Zechao Li, Jinhui Tag, and Tat-SengChu. InIEEEInternational onference n Acousics,Speech and Signal Procssing (ICASSP)."
}