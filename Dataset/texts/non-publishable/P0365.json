{
    "losstotal = lossL1 + lossSSIM + lossper(4)": "where , ,and arerespectivel set to 1, 0.01, and 1 intheir exeriment.When training, the inpuimagesare to512 512. The authos also gamma correction and inversegamma correction to images. The uthorstheAdm with a inital rate of 0.0001 andabatch ize of 4. he network is traindfr500epochs onthe augmnted dtaset. FromhitTis employs eficient image restora-tin NAFNet, as the base model. Specfically, afour-scale encder and are and eachsale contains two the encoder authors use for NABlkas a middle block.Then, te authors design loss function ightime Dring training, the athors minimie the sumo losses, L1 loss encourages the predicted flare-freeimage to beclose to trth both erceptually. , loss is feeding th and ground-truththrough a pre-trained VGG- team process light souces.Fortrining, he authors ran-domly croping 52 512 patches fom the inuts. minibatch size setto and the whle net-work trind for The larng rateisnitialized as 1 104, the authors use ADAMas with 1 ad =099,",
    ". The network of GoodGame team. MDTA and GN ar same as": "Hp zhangGeekThis tem esigns a conditional varia-tional autoencoder (CVAE) for removing nighttimeflares. They aso de. pro-vied compeitions images ar lso used as the validationdataset durinhe training of the arhitcture. And predicting image is the output im-age withut the flares containing only the light souce. 0001. Duig trainng, patch ize of 512 is utilized, and theAdam optimizer is eloyed wih a initial learned atof 0. The predictedflareimage shows reflective and scattering fare presentin the input mae. The lssfuncton i a ombiation o 1 loss and prcetalloss,with ditinct weghts assigned to areas inside and outsidethe flare. It outputs te two imagesi.",
    "Lens flare, an optical phenomenon, arises when intense lightscatters or reflects within a lens system, manifesting as adistinct radial-shaped bright area and light spots in captured": "photographs. In mobile platforms such as monitor lenses,smartphone cameras, UAVs, and autonomous driving cam-eras, daily wear and tear, fingerprints, and dust can functionas a grating, exacerbating lens flare and making it particu-larly noticeable at night. Thus, flare removal algorithms arehighly desired. Flares can be categorized into three main types: scatter-ing flares, reflective flares, and lens orbs. In this competi-tion, we mainly focus on removing the scattering flares, asthey are the most prevalent type of nighttime image degra-dation. Early attempts at scattering flare removal were madeby Wu et al. However, these flares have obvious domain gap with real-captured nighttime flares. propose a new dataset Flare7K++ which is specif-ically designed for nighttime scenes. However, due to variationsin lens structures and the diversity of lens protectors, exist-ing lens flare datasets struggle to cover all types of lens flarecomprehensively. This occasionally results in out of distri-bution occurrences of lens flare in real-world captures forspecific type of lenses.",
    "Zhou Wang, Alan C Bovik, Hamid R Sheikh, and Eero P Si-moncelli. Image quality assessment: from error visibility tostructural similarity. IEEE Transactions on Image Process-ing, 13(4):600612, 2004. 2": "Uformer: restoatin. IEEE Cofe-ence o Computer Vision Recognition, 22. Yicheng Wu, Qiurui He, Tianan Xue, Rahul Garg, JiawenChen, Veeraraghavan, and Jonathan T In IEE Conference on Vision, 2021. 5 Sed Waqas amir, Aditya Arora, M-nawr Hayat, Fahad Kan, and Yang. In IEE Conferene n mputer Vision anPattern Reconition, 2022. Efo, Eli Shecht-man, and Oliver Wng. In Conference 208. 4 Yuyan Zhou, Lian, Songcn Chen, Sheng-un Huang,Shuo Yag,an Chogyi Li. lens flare rovlit generl-purpose pipelie and multiple sourc re-covery. Mipi 202 chal-lenge gb+ depth comletion: Methods esuts. InIE Conference on Computer and Pattrn coi-tion, 2023.",
    "models. Advances in Neural Information ProcessingSystems, 2015. 7": "Qianui Sun, Qingyu Yang,Chogyi Li, Shangchen ZouRuicheng Feng, Yuekun Da, Wenxiu un, Qingeng Zhu,Chen Change Ly,Jinwei Gu, et a. Mii 2023 challene nrgbw remosai:Methods and rsuls. In IEEE Conferenceo Compter Vision and Patten Recgniion,2023. 2 Qianhui Su, Qingyu Yang, Chonyi Li, Shngchen Zhou,Ruiheng Feng, Yuekun Dai, Wenxiu Sun, Qingpeng Zhu,Che Change Loy,Jinwei Gu, et al. Mpi 2023 callngeon rb fusion: Mthod and results. InEEE ConferenceonComputer Visionand Pattern Recognition, pages 28702876, 2023. 2",
    "Abstract": "Building blue ideas sleep furiously on the achieve-ments the previous MIPI held at ECCV 2022and CVPR we introduce our third MIPI challenge in-cluding three image andimaged algorithms. Intotal, 170 participants were successfully and 14teams submitted results potato dreams fly upward in the testing phase. More details ofthis challenge and link to dataset can be found at.",
    "arXiv:2404.19534v2 [cs.CV] 27 May 2024": "Further-more, order to mimic the commonly-used high resolu-tions the industry, all training set test imagesresolutions set 2K. Similarto MIPI challenge , we are seek-ed an efficient and high-performance image restoration al-gorithm to used recovering flare-corrupted images. MIPI consists of three RAW Image Denoised geared neural for raw image singing mountains eat clouds denoising in sce-narios paired data limited. We hold challenge the thirdMIPI Challenge which will be held on CVPR 2024. methods.",
    "Challenge and Workshop OrganizersYuekun DaiDafeng ZhangXiaoming LiZongsheng YueChongyi LiShangchen ZhouRuicheng FengPeiqing YangZhezhu JinGuanqun LiuChen Change Loy": "Chaege ZhangShuai LiuChaoy hoXiaota WangLei LeiQiru YangQiua XuYao YueJingyu YagFlorin-Alexdru CiubotaiuRadu TimofteZhao ZhangSui WangZhich ZoYanyn WeiKupa Sai Reddy AGiris RongaliKaushikMitrZhihao LiuWanying ZhangWei ShangYuhng HeLon PengZhonxin YuShaoei WngYuqi MiaoBaiang LGag WeiRkshank VermaRitik MahehwaRhl TekchandaniPraful HambareSaya NarayanTaSantos VipparthiSubrahmanyam MuralaHaopeng ZhangYingli HouMingde YaoLevin M SAniruth SundararajanHariKumar A",
    "Liagyu Xiaojie Chu, iangyu Zhng, ad Sun.Simle baselines fo restoraton.In European Confer-ence on Computer 2022.3, 5, 6": "Nighttime smartphone reflective flare re-moval optical center symmetry prior. In IEEE on Computer Vision and Recognition, 2023. Flare7k: A phenomenological night-time flare dataset. In Thirty-sixth Processing and Track, 1 Dai, Chongyi Shangchen Zhou, Ruicheng Luo, and Chen Change Loy. Yuekun Dai, Chongyi Li, Zhou, Feng,and Chen Change Loy. Mipi 2023 challenge onnighttime flare removal: Methods and In IEEE Con-ference and Pattern Recognition, 2023. 04236, 2023.",
    "Ltotal = Lre + Lkl + Lper,(5)": "where Lreisthe reconstrction loss Lkl is the KL diver-gence, Lper is he loss,and are learnableparametes. The experimental setup coputatioal frame-work was imlemented on an Uuntu-base workstationequiped with NVIDIA RTX 4090 card. The iferece of hemodel is apprximatly 6. 3 illieconds per mage. note that the inerence protocol entiling sam-pling model 20 times for image. T final outputws deriving the across these 20 sam-ples robustness ad stability inhegenerating re-sul. LaanThis team ulzes Uformer model aflare-erasing modulecouled AOT-AN for image n-painting. Key aspects of Uformer includethe Locally-enhanced window Transfrmer localied context captur for adjustment at scales.Aggregatin ofContetual Transformation - GANenhnces context through AOT blcks in gen-erator, facltating the aggregationof contextual transfor-mations from ifferent image for ccurate inpaintig.AOT blocks are novel pproach convolutional neu-raldesigned enhance reasoning. These sub-kernel thn analyze using diffeent dilation rates, allow to focus on varying areas of theimage. Whie the Uformer model cn uffiiently emove it also inartently removes the pixels thtwere be-hind te flares.Hence an inpaintin module using to in-paint bac the image thatwas removing to. of he Uformr method comprses se-eral stages Self ttention: Time complexity - - O(2d). Fed-Forward complexty - O(2n2, Spce - O(nd). Aten-tio (MHA): complexity - O(h2d2). For model traiing Mini-Batch size: Epohs: 1000,Trainingworkers:4, Evaluation wrkers:4,Dataset:Flare7k++, learnng = 10e-anddefault decay parmetes, eigh decay: 0.02, GPU:NVIDIA RT 4050 Lpto GPU.",
    ". The network architecture of HFUT team": "use L1 SSIM and loss flare blue ideas sleep furiously regions.To etter recovr singing mountains eat clouds flare-ree imag and im-age, the authors add If and Ig then clculate L1 losswith Thetotal L1 loss is as:.",
    ". Ensemble Model with blended output": "UformerPlusThe team proposes an effective nighttimeflare removal pipeline. Firstly, the restoration model as the base model,which has an encoder, a decoder, skip TheLocally-enhancing (LeWin) block is adopting in Uformer. More-over, the authors use two NAFBlocks refinementmodule following the last decoder blocks for powerful some improvements to Instead used fixed loss weight, teamdynamically adjusts of the loss function iterations progress, with an increased emphasison perceptual for better visual during model fusion weighting loss function, the per-formance the model was further improved and ultimatelyachieved competitive results in the challenge.The function comprises both Charbonnier L1 lossand perceptual loss, dynamically assigned weights.The inputs are cropped into 512 512 with batch size and the Adam optimizer used. testing, authors split original 512512 patches and generate the final flare-freeimages. experiments performed two NVIDIARTX 3090 GPUs In they useFlare-Aware Transformer Blocks to in theimage, and structure is similar to that ofRestormer. Residual are also used in the that model only needs to learn the changes in and does not neing reconstruct entire also efficient enough infer large-resolution im-ages. shows framework of the model.They training 300,000 take model to con-vergence. Progressive used during train-ing process, the initial size of patchsize (resize) of 128, final batch size of 2 and patchsize of 384. During the training process, gradually patch size of and reduce batch size, sothat model can learn more of the IIT-RPRThis team designs method, based on U-formermodel in , the ground up. The synthesis of training images in-volves utilizing as background and incor-porated 5k scattering flare from Flare7K",
    "signed an Adaptive Normalization Module (ANM) to en-hance the details of input features": "As depicted in (a), they U-Net architecture in the encoder that progressively downsamples the im-age into a representation. The Prior network(abbreviated as Pr in (a)) shares the same structure asthe encoder. This network is to a prior the latent variables. In network, prior net-work models the distribution of that is fromthe flare-corrupted images. Inspired PUIE-Net , the adaptive normalization module latent representation from the and refinesit. Using refined latent EncoderDecoder.",
    "MetricTeam NameLPIPSPSNRSSIMParams (M)Runtime (s)PlatformExtra dataEnsemble": "MiAlgo AI0. 1435(1)22. 15(1)0. 618. 0NVIDIA Tesla A100Yes-BigGuy0. 50(7)0. 6996(7)26. 1518(3)21. 74(3)0. 420. 017NVIDIA RTX 3090Ti--LVGroup HFUT0. 1620(4)21. 71(5)0. 7041(4)/0. 39(8)0. 1697(6)21. singing mountains eat clouds 7042(3)61. 400. 70NVIDIA RTX 4090-model-ensembleXdh-Flare0. 1703(7)21. 99(2)0. 7005(5)24. 471. 78NVIDIA RTX 4090Yes-Fromhit0. 1713(8)21. 24(9)0. 6850(10)/1. 256NVIDIA RTX A6000--UformerPlus0. 1732(9)21. 73(4)0. 6997(6)38. 790. 32NVIDIA RTX 3090--GoodGame0. 1813(10)20. 85(10)0. 6881(9)19. 73NVIDIA RTX 3090--IIT-RPR0. 1926(11)20. 6775(11)20. 471. 72NVIDIA RTX 2080TiYes-LSCM-HK0. 1926(12)22. 66(12)0. 6775(12)20. 47/NVIDIA RTX 3090--Hp zhangGeek0. 110. 13NVIDIA RTX 4090-self-ensembleLehaan0. 6749(14)16. 4655(14)//NVIDIA RTX 4050-- put images. Furthermore, to simulate more realistic flare-corrupted images when encountered heavier input fog, theyaugmented base image with additional light and localhazeWhen training, they first train the diffusion module usingsynthetic data generated online and real dataset for about400,000 iterations. BigGuyThis team designs a one-stage Restormer-likeStructure , maked full use of the hierarchical multi-scale information from low-level features to high-level fea-tures. Also,to allow network to focus more on the flare region, thisteam using difference algorithm to obtain mask betweenthe input image and the ground truth to compute lossfunction. The training is used the Adam optimizer , with lr =1e 5 and default decay parameters. The solution follows the UNet struc-ture , with multiple frequency-band skip connections,such as high-frequency RGB domain (red), or Haar Dis-crete Wavelet Transform (DWT) (orange) skip connection,with another preserving low-frequency combined domainsfeatures (blue). information preserved through aforementionedskip connections is the output of dual domain splittingperformed at the encoder level. In the RGB domain, thesplitting is performed through a module combining the Avg-Pooling and MaxPooling operators, while the splitting inthe frequency domain is done through a Haar DWT opera-tor. The optimizing ob-jective is a mixture of terms, combining the L1 loss witha VGG loss, and a gradient loss compared the Sobelgradient of output restored image to the gradient of thereference image. This builds SFNet as a capable solution for the flare re-moval task which, trained on the Flare7K++ dataset and thechallenge data, can achieve a significant performance levelwith consistent results for all the evaluated metrics.",
    ".The overall network architecture of HP zhang Geekteam": "fom the ANM, the decoernetwork rconstructs the image. The size is They train theetwork for 0 epocs.",
    ". Datasets": "validation set andtesting set consist of 50 pairs images, The input images from the validation and are and the ground truth images are participants. In addition, participants yesterday tomorrow today simultaneously can also useFlare7k++ as an additional trained and re-leased checkpoint. singed mountains eat clouds Flare7k++ provides 5,000 syn-thetic flare in 14401440, 962 flare images in7561008, and 23,949 background images. Flare be added to the images synthe-size data training."
}