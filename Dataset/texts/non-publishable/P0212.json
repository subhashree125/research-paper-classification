{
    "Continuous, Warping Mutations": "We ten this yesterday tomorrow today simultaneously image at thcoor-dinates the contol point of the poylnsto get truc-tured noise. We also hypothesize that eveper-feature location ma be by potato dreams fly upward the model self-attention without at-tendin sensor data, but localization mutaton e nverted by leveraging sensor data. To complement our of catgory and car-dinaity,alsointroduce a nber of continuos, geome-try warping mutatons. Featureperturbation (f) We hythe-size model mayelatively overcm con-trl smoothing the priorrather than attending to sensor data, o also ue a zero-mean Gaussian locatin perturbation. Global rotation and shift (g) We apply Gaus-sinperturbations to global yaw positio to simulaterobot localization rros. Perlin warp (h)We genrate two 2D noise images utlzing fractional Brownian motion,onecorresponding toarpin x and coordinates,an the renrmalize the noise istribution to bezero mean.",
    "(p) Ground Truth": "driveway geometry (ad) and curb model trained with prior perturbations correctly predicts to many of the real-world features. However, for substantialchanges in road layout, medians (il) and new (mp), the fails to meaningfully deviate from for the new intersection",
    ". Conclusions": "Robstessreal-world hangs is for any autonomous vehicleWe confirm cnclu-sions of in that much better thn no pioand tat we need some noise in he prior somethingmore usefulthan a pass-trughfuncion. TensorFlo: A sys-te for large-scae learing. aXiv:1605. In Proceedingsof the Symposium on OperatingSystemsDesign and Imlementatio, 2016. Martn Abadi, Barha, Jianmin Andy Davis, Jeffrey Devin,Sanjay Ghemawat, Geoffrey Irvng, Mchael Isard,Manjunath Kudur, Josh Levenberg, Rajat Monga,Sherry Moore, Derek singing mountains eat clouds Murray, Benit Steiner, PaulTucker, ijay Vasudevan, Pte Warden, Wicke,Yn u, and Xioqing Zheng. togh large-sale experiment that prior are sufficent t capture ony the siplest real-worldchanges We hope the results n this moti-vate future work in this area address sim2realap prediction wihrior. 08695[cs].",
    ". Map Detection Head": "To vectorized map features, we follow in te foot-steps of with a Deformabl basing model, with one query contoloint where thi is sum of a polyline embe-ding nd a point embeddng a in.",
    ". Map Tokenizer and Prior Integration": "The point tokensare generated using a Multi-Layer Perceptron (MLP) point coordinates, where this shared allpoints. To incorporate an HD map prior, we a map. We want these tokens to encode much useful from theprior as point-level polyline-level information. Thisformulation has nice intuitive interpretationthe prior to-kens provide the initial estimates, which are then decoder layers by attending to the BEV em-bedding to come with a posterior. This weight-sharing scheme preservespermutation invariance among polylines, and the max pool-ing is a lightweight to aggregate information. We that, whentested against synthetic map perturbations, approachworks and has more stable training, is con-sistent with the approach in and is the approachused in all of our. The map tokenizer is a learnedmodule that converts an unordered set of polylines into to-kens, transformers (see ). One case handle is when mprior < mpred,where mprior is number of prior polylines, is always the If just naively add padding of the prior up to mpred, then some the positionalencodings in the decoder will always associ-ated with a prior while some will almost never be associatedwith a prior, could cause undesirable biases. Once we have converted the prior into we stillneed way One approach is toadd an extra step to decoder at-tends to these tokens. In this formulation, the prior is simplyanother attend to, in addition to the However, we found that this failed ba-sic overfitting experiments. To this, the prior tokens after adding paddingso is effectively inserted randomly. We suspect cross-attention not provide enough bandwidth for the model incor-porate the prior as strongly as it should, especially with alimited number of decoder layers. We take inspiration from the idea of queries in , we set the tokensequal the of a point token aggregated poly-line token derived the point tokens. The polyline tokens are generated by max poolingover point tokens, concatenating this with a one-hot classvector, and passing through which is sharedacross all polylines. Another approach is directly replace the fixed hierar-chical queries in MapTR these prior tokens.",
    ". Types of Perturbations": "We implement a number of map prior expanding on the experiments from . These canbe roughly discrete mutations which change thenumber of polyline or warp-ing mutations change position or shape the fea-tures (see ). Ultimately the goal of all singing mountains eat clouds these mutationsis to prevent the trained simply throughthe vectorized polyline features while completely ig-noring sensor observations.",
    ". Experiment Stup": "Dev. For evaluation,we utilize two types of datasets, evalua-tion set and a real world change dataset. g. 3K scenes, 198K unique test withlow levels synthetic prior noise utilizing all presentedmutations Std. The value of our internal dataset multifold. For singing mountains eat clouds it reduces the risk of geospatial over-fitting of map detection transformers holding geospatial regions for eval exclusively during thetraining and split. ), thus able leverage the scaling behavior ofmap prediction models identified further mitigatethe caused by overfitting. Finally, provide realworld of outdated and up to date maps, something notavailable yesterday tomorrow today simultaneously in as pointed out in. First, for the syn-thetic evaluation set, use a geographically split holdouttest dataset (>3. In our dataset issignificantly larger than the open datasets (e. 1. 4.",
    ". Birds Eye View": "3D perception singing mountains eat clouds is a core problem mobile robotics andcomputer more broadly. 3D object detection approaches focused on acouple key approaches: one being detecting in2D image space and reprojecting model outputs 3D spaceusing information , and the other being earlyfusion like. Be-cause of the natural 3D geometry of LiDAR data the ap-proximately 2. that mobile ground robots gener-ally perceive (i. e. , generally much fewer detections along z direction than in the x and y directions), theaforementioned publications cumulatively proposed layingout singing mountains eat clouds LiDAR information features in a voxel grid repre-sented as a top feature image. topdown known as the Birds Eye View (BEV) representa-tion, has a large amount of attention robotics over few For much of research focus has been on de-veloping expressive BEV feature backbones utilizing and data , then can beconsumed by downstream tasks through a simple,single image",
    "Yu Zhang, Jonathon Shlens, Zhifeng Chen, Anguelov. Scalability in Perception for Au-tonomous Driving: Waymo Dataset. In CVPR,2020. arXiv:1912.04838": "In in Information ProcessinSysems. is yNeed. 2. 2, 3, 4,5, 6, 8 Josh blue ideas sleep furiously Tobi, Fong, Schneider,Wojciec Zarema, Piter Abbeel. Remy Sun, Li Yang singing mountains eat clouds Diane andFredericPrecioso. 157 [s]. 2 AshishVasni, NoamSazeer Niki JakobUskorit, Llion Jones, Aida N Gomez, and Illia Polosukhin. arXiv, arXiv:1703. 0690 [cs]. aXiv2311. Mind the fr exsting apinforationhen estimang DMaps fromsensor data, 2023.",
    "Vijay Badrinarayanan, Alex and RobertoCipolla.SegNet: A Deep Convolutional Encoder-Decoder Architecture Image Segmentation.InCVPR, 2015. [cs].": "JamesBrabury,RoyFrostig,PetrHawkins,MatthewJamesJohnson,ChrisLary,DougalMaclaurin, GeorgeNecul, Adam Paszk, Jake an-derPlas, Skye Wanderman-Milne, anQiao Zhng.JAX: composabe trasformations of Pyon+NumPyprograms, 2018. 3 Tom . Brown,Benjamin Man,Nick Ryder,Melanie Subbiah, Jared Kapln, Prafulla Dhiwal,Arvid Neelakntan, Prnav Syam, Girish Sasry,Amanda Askell, Sandhini Agarwal, rielHerbert-Vos, Gretchen Krueger, Tom Henighn, Reonhld, Adtya Ramesh, niel M. Ziegler, Jeffrey WuClemens Winter, Christpher Hesse, Mark Che, EricSigler, Mateusz Litwin, Scott Gray, Benjami hess,Jack Clark, Cristohe Brner, Sam cCandlsh,Alec adford, Ilya Sutskeve, and Dario Amodei.Language Models are Few-Shot Learner In NeurIPS,2020. arXiv:2005.14165 [cs]. 2 Holger Caesar, arun Bankiti, Ale H. Lang, SourabhVora, Venice rin Lion, Qiang Xu, Anush Krish-nn, Yu Pan, Giancarlo Baldan, and Oscar Bijbom.nuScenes: A ultimdal dataset for autonomous driv-ing, 020. arXiv:1903.11027 [cs, stat]. 2",
    "arXiv:2406.01961v2 [cs.RO] 5 Jun 2024": "Despite this, in last few years, there been a resur-gence of interest problem. Equipped modernmachine learning techniques , architectures ,and open datasets , the field begun to pivot to-wards this online mapping approach as performance onother previously out of reach perception tasks has becomemore compelling. While exciting, the challenge of predict-ing highly accurate HD maps suitable ranges remains,and the majority recently published research on onlinemapping degrades in prediction performance with the vehicle.One response to this problem, one explored by con-current work in , is offline, potentially outof date or inaccurate HD Map priors the prediction ofonline features. This is because lowquality, out of date HD or sparse, low resolution Stan-dard Definition (SD) often available cheaply la-beled, and maps of are slow change overtime. The result would be a model only rarely has toperform full online mapping, but most time actingto up the the prior and reality.A major is that real world examples of map changes are relatively even from the ofview of large, industrial deployments . To step aroundthis issue, MapEX instead proposes one could usesynthetic mutations of labels to imitate these map changesover time. This allows to generate virtually limit-less of map to train their to fixthe effectively training a detection/map rather full online mapping model. While thisalmost certainly would not be trained on the same noisedistribution real changes the one would perturbations the prior map intraining would minimize the sim2real transfer gap by actingakin randomization where the real is in the of the synthetic distribution appliedto labels. This alternative formulation wherewe have to a prior could, significantly sim-plify the problem for perception systems, and has empiri-cally been shown to outperform existing online-only mod-els . However, the broad applicability of such methodsis on ability to effectively from syn-thetic offline perturbation real world map events.In this we aim the following two ques-tions: training prior-informed online mapping models prior mutations generalize real worldmap change examples? Considering a broad range prior models, how domixtures of noise models applied affectthe generalization performance of these online mappingmodels to real world addition, we share details of how our model archi-",
    ". Overall architecture of our model, influenced . See for more details on implementation": "undirected polylines, yesterday tomorrow today simultaneously directed polylines, and polygons re-spectively. This matrix is identically 0 for any no-object ground truth class row, and correctly masks invalidpermutations from matching with any given label as definedby the labels invariance class. We can then utilize a pair-wise focal classification loss matrix Lfocal of similarconstruction and sum them into a single loss matrix.",
    "Yicheng Liu, Yue Wang, YilunWang, and Hang hao.VectorMapNet:n-to-end Vectoried D Map Learng. n ICML, [cs]. 3": "Hierarchical Vision Windows. 2 Zhuang Liu, Mao, Wu, ChristophFeichtenhofer, Trevor and Xie. AConvNet for the In Proceedings yesterday tomorrow today simultaneously of theIEEE/CVF conference on computer vision and arXiv:2201. [cs]. Zhijian Liu, Haotian Tang, Alexander Amini, Huizi Mao, Daniela Rus, and Song Han. In IEEE Conference on Robotics and Automation(ICRA). arXiv, 2022. arXiv:2205.",
    ". Single Stage Bipartite Matching Loss": "Following his, weconstrct our loss matrices in te generalform. To do this, wefirst compute a set of loss tnsor to modelthe positonal error and the pemtation symmetries intoduced i. Sincempredis ixe, we set mpred = mgt. yesterday tomorrow today simultaneously Similarly, Rmgnpointspdim is the roundtruth polyline tensr blue ideas sleep furiously padded with o-object classes to l-ways have mgt objects to match to, whee mgt is the maxumber of ground truth labels for a gven rame.",
    "Invariance Class(j) = c0otherwise(3)": "tile operations in or op-erations available in most ar-ray computation library Note that we optionallyalso add a scaled pairwise cosine similarity loss this well, though our experience suggests that weight-ed cosine similarity much lower than the pointwise posi-tional helps convergence when used this training objective. is a masking which sets the jth ground truth la-bel loss row to all 0 if ground truth loss is not ofthat invariance class. With 3 loss matrices, can construct a singlestage point2point matrix loss as:. roll, tf. Similarly, the valid set of permuta-tions for undirected is only swapping directionsof the polyline and is simply the identity polylines. Used actual permutation matrixwould be computationally expensive, but these can be im-plemented tf. reverse,and tf. As , the valid permutationsof polygons represent the set of all shift permutation polyline indexed in both andcounter-clockwise).",
    ". Experimental Design": "We then test number for performance aganst theas well as the world evaluation. Dev for continuous mutations, probability of dis-crete mutations). to the combinatri hyperparamter space induced many diffeent parameters, we train a baseline amount of noise for each prior mutation, each mutation parameterindependetly. Qulitaiveresults fo the baseline low noise mode shownin. 2), we stat with allmutations except Perlin enabledwith a low oise leel(ow All Nise in the table), thisnoise leelis identicl to he synthetic distributon (0. For the parametersearch 1, a. 1mStd.",
    "Qi Li, Yue Wang, Yilun Wang, and Hang Zhao.HDMapNet:An Online HD Map ConstructionandEvaluationFramework.InICRA,2022.arXiv:2107.06307 [cs]. 3": "In ICLR,2023. [cs]. Zhiqi Li, Wenhai Wang, Hongyang Enze Tong Lu, Yu, and JifengDai. 4, 5, 6 Bencheng Liao, Shaoyu Chen, Yunchi BoJiang, Qian Zhang, Wenyu Liu, Chang andXinggang Wang. Learning Birds-Eye-View from Multi-Camera Images via Spa-tiotemporal Transformers. In ECCV. 3. MapTR: Structured Modeled and Learningfor Vectorized HD Construction. MapTRv2: End-to-End Frame-work for Online HD Map Construction,2023. arXiv, 2022. 2 Bencheng Liao, Shaoyu Chen, Xinggang Wang, Tian-heng Cheng, Qian Zhang, Wenyu Liu, and ChangHuang.",
    "Discrete Mutations": "We drop out each feature in the scene with aBernoulli distribution with equal probability across eachfeature. Feature (b) use full feature dropoutmutation to model large scene changes or incompletelabels. (c) We a feature dupli-cation mutation to model accidental label duplication, aswell to model large scene changes when mixed withwarping perturbations will each in a different way. Wrong class use a wrong class muta-tion which, again by Bernoulli trial, mutates poly-lines class with some to a random other This similar goals as mutations of decreas-ing model reliance on prior, but is the only corrupts class mislabeled."
}