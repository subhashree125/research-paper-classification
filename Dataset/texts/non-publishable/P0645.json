{
    "Sukhpal Singh Gill, Minxian Xu, Huam-ing Wu, Rupinder Kaur, Kamalpreet Kaur, StephanieFuller, Manmeet Priyansh Arora, Parlikad, Vlado Stankovski, Ajith Abraham,": "Ghosh, anan Lutfiyya, Sali S. Transformatve effects of chatgpt on moderneducaton: Emerging era of ai chtbots. Internet ofThings n Cyber-Physical Systems, 4:1923. Lpstick n apg: Debiasing mehds coer up systeaticgederiases in wor mbeddings but do not remve them.In Poceedings of he 019 Conference of the NorthAerican Chater of the Association for Cmputa-tional Linguistics: Human Language Tchnologies,Volume 1 (Long and Short Ppers), ages 609614,Minneapolis, Minnota. Association for Computa-tional Linguistics.",
    "LLM Sensitivity:For evaluation,models were using a zero-shot instruc-tion describing the task:": "yesterday tomorrow today simultaneously \".",
    "Malvina Nissim, Rik van Noord, and Rob van der Goot.2020. Fair is better than sensational: Man is to doctoras woman is to doctor. Computational Linguistics,46(2):487497": "2022. Ouyng, Jef singing mountains eat clouds Wu, ian, Almeida Car-roll L. singing mountains eat clouds AliciaParrish,AngelicaChen,NikitaNangia,Vishakh Padmakumar, Jason Phang, JanaMon Htut Samuel Bowman 202. language odels follow instructions withhuman eedback. 2024. 08774. PreprintarXiv:203.",
    "The complete dataset is publicly accessible at GitHub andon Hugging Face.2": "the quality o interactions may be compro-miseda modl exhibit which i commonldefned as skew that produces of harmand can exist implicitly and explicitly (raw-ford, et al. , 2023).et al. , 2019). resources hve been developedtoidentify and mitigatebias n LLMs. PerpectiveAPI3 and singing mountains eat clouds RealToxicitPrompts (Gehman et al. Conversely,BBQ, Stere-oSet, and CrowS-Pair focus onbiases suchas tereotyping, apurin subtle forms of discriminaion for evaluating implicit bias al. , 2020; Nadeem et al. ,202) Howeve, these often evaluate ce-nrios n isolation, without considring th broadercontext or f biases situatio. , 2023; adGolderg, We propose measuring througpogres-sively offensiv scenrios appropri-ateness, define s \"the whichan expression or action considered aceptbler inoffensive a cial context\". ilustrtes this concept, showing",
    "Bo Strth. 2013. Ideology and conceptual history. TheOxford handbook of political ideologies, 1:1536": "Drlding e, Christna Capodilupo, Gina CToro, Jenner M Bucceri, Aisha Holder, Kevin LNadl, and Mart Esquilin. 2007. Racilmicroag-gressions in evryday life: implications fo cinicaprtic. American psychlogist, 624271. Gemma Ta Thomas Mesnar, Casid Hardin,Robert Daash, Sury upatiraju, Shreya Pathak,Laurent Sifre, Morgane Rivire, Mihr anjayKale, Juliette Love, Pouya Tafti, Lonard HussenotPier Giuseppe Sessa, Aakanksha Chowdhery, AamRoberts, Aditya Barua, lex Botev, Alex Castro-Rs, Ambrose Slone, Amlie Hliou, Anrea Tac-cheti, Anna Buanva,Antonia Paterson, BetTsai, BobakShahriai, Charline Le Lan, Christo-pher A. Choquette-Choo, Clment Crepy, Dniel Cer,Daphne Ippolio, David Reid, Elena Buchatskya,Eric Ni, Eric Nolan eng Yan, Gorge Tukr,Georg-hrisian Murar, Griory Rozhdestvenskiy,HenrykMichalewski, Ian Tenney, Ivan Grishchenko,Jab Austin, James Keeling, Jane Lbanowski,Jean-Baptste Lespiau, Jef Stanway, Jenny Bren-nan Jeremy hen, Johan Ferret, Jusin Ciu, JustinMa-Jones, Katherine Lee, ah Yu, KatieMilli-can, Lars Lowe Sjoesund, Lisa Lee, Lucas Dixon,Machel Reid, Macij Mika, Mateo Wirth, Mihael Sharman,Nikola Chinaev, Nithum Thin, OlivierBahem, OscarChang, Oscar Wahltine, Paige Bai-ley, aulMichel, Petko Yotov, Rahma Chaabouni,Ramona Comanescu,Reena Jana, Rohan Anil,RosscIlroy, Ruibo i, yan Mullns, Smuel L Smith,Seastian orgeau, Seran Gigin, Shoto Douglas,Shree Pandya Siamak Shakeri,Soham De,Ted Ki-menko, Tom Hnnian, Vlad Feinberg, WocechStokowiec, Yuhui Chen,Zafaali Ahmed, ZhitoGong,ris Warentin,Ludovic Peran, MinhGiang,Clment Farabet, rol Vinyas, Jef Dean, KorayKavukcuoglu, Demis Hassabis, singing mountains eat clouds Zoubin hahramani,Douglas Ek JoellBarra Fernando Pereira, EliCollins, ArmandJoulin, Noah Fiedel, Evan Senter,lek Andreev, and Kathlen Kenealy. 2024. GemmaOpen models basd on gemini research and technol-ogy. Preprint, arXiv:2403.0829. Hugo Touvron, Louis Martin, evin Stone, Peter Al-bet, Amjad Almahiri smne Babaei, NikolBashlyko, Souma Batra, Prajjwal Bargava, ShrutiBhosale, Dan Bikel, Luas Blecher Cristian CanonFerer, Moya Chen, Gullem Cucurul, David siobu,Jude ernandes, Jeremy Fu, Wenyin Fu, Brian Fuler,Cynthia Gao, edanu Gomi Naman Goyal, An-thony Hartshorn, Saghar Hosseini, Rui ou, HkanInnMarcin Kardas, VitorKerkez,Madian Khabsa,Isael Kloumann, Artm Korenev, Punit Sngh Koura,Marie-Anne Lachaux, Thibaut Lavril,Jenya Lee, blue ideas sleep furiously Di-ana Liskovich, Yinghai Lu, Yuning Ma, Xavie Mar-tinet, Todor Mihaylov,Pushkar Mishra, Igor Moly-bog,Yixin Ni, Andrew Poulton, Jeremy Reizen-stein, Rashi ungta, Kalyan Saadi, Aan Schelten,RunSila, Eric Michael Smith, Ranjn Subrama-nian, Xiaoqing Elen Ta, Binh Tang, Ross Tyor, Adina Wlliams,Jian XiagKuan, uxin Xu,Zheng Yan, Iliyan Zarov, Yuchen Zhang, Angela Fan,Meanie Kamadur, Sharan arang, Aurelien R-driguez, Robert Stojnic, Segey Edunv, and ThomasScalo. 2023. Llama 2: Openfoundatin and fine-tuned chat models. Preprint, ariv:2307.09288. Tracy L Tylka, Rachel A Annunziato DebBurgard,Sigrn Danelsdttir Ellen Shuan, Chad ais, andRachel M Calogro. 2014. Te weihtinclusive ver-us eightnormative approach to health: evaluatingthe eidence for prioritizin well-beng over weighlss. Journa of obesity, 2014(1):983495. Pranav Narayanan Venkit, Mukund Srinth, and ShomirWilson. 2022. A study of implicit bias in pretrainedlaguage models agaist people with disabilities InProceedngs of the 29th Intenatioal Confereceo Computtioal Linguistics, pages 1321332,Gyeongju, epublic of Korea. InternationalCom-mitte on omputatinal Lingistics. Yixin Wan, Geore Pu, Jiao Sun, Aparna GarimellaKi-Wei hang adNanyun Peng. 2023. kllyis a warm person, joseph is a role odel: Genderbiases in LLM-generated eference ltters. n Find-ings of the Assoiation for Computational inuis-tics: EMNLP 02, pags 37303748, Singaore.Association for Compuational Linguistics.",
    "Kate Crawford. The trouble with bias. talk": "Vigi-lance singing mountains eat clouds and proecion: howasian and paif islandr,black, latn, and midle eastern women cope withraism. 021. Shaniece Criss, MelanieKm, MoncaM De La Cruz,NungThi, singing mountains eat clouds Qunh C guyen, YulinHswen,Gilbert C Gee, and Thu T Nguyn. 224.",
    "Abstract": "Mitigating explicit and implicit biases in LargeLanguage Models (LLMs) has become a crit-ical focus in the field of natural language pro-cessing. However, many current methodologiesevaluate scenarios in isolation, without consid-ering the broader context or the spectrum of po-tential biases within each situation. To addressthis, we introduce the Sensitivity Testing onOffensive Progressions (STOP) dataset, whichincludes 450 offensive progressions containing2,700 unique sentences of varying severity thatprogressively escalate from less to more explic-itly offensive. Covering a broad spectrum of 9demographics and 46 sub-demographics, STOPensures inclusivity and comprehensive cover-age. We evaluate several leading closed- andopen-source models, including GPT-4, Mixtral,and Llama 3. Our findings reveal that even thebest-performing models detect bias inconsis-tently, with success rates ranging from 19.3%to 69.8%. We also demonstrate how aligningmodels with human judgments on STOP canimprove model answer rates on sensitive taskssuch as BBQ, StereoSet, and CrowS-Pairs byup to 191%, while maintaining or even improv-ing performance. STOP presents a novel frame-work for assessing the complex nature of biasesin LLMs, which will enable more effective biasmitigation strategies and facilitates the creationof fairer language models.1",
    "Which LLM exhibits the most idealsensitivity to bias?": "8%) and strong performance all sever-ity levels. For expansive list of sensitivity scores indi-vidual plots of all models, see and of the Appendix, respectively. 3%,demonstrating a weaker ability to generalize andadapt to scenarios of varying sensitivity (Appendix a full list performance rangesfor all models). shows that while Mixtral andLlama 3-70b (Pl 97. The ideal model exhibit consis-tent sensitivity different levels, and contexts. Llama 2-70b shows the most ideal sensi-tivity, the highest overall success (P =69. In terms of counterfactual per-formance, 3-8b also achieved highest. 8%) perfor-mance on low severity progressions, Llama 2-70b(Pm = 68. 4 and for graphs onall sub-demographics standard deviations, re-spectively). In terms severity levels, on the otherhand, shows Llama 3-8b had themost consistent of success sever-ity categories, models such as Gemma-7b-instruct wide ranges of success across vari-ous severity categories, with data of 93. provides depictionof this fluctuated profile across religions (seeAppendix Section A. In of sub-demographics, Llama shows the most con-sistent judgment, while Llama 2-7b demonstratesthe most fluctuating consideration each sub-demographic. 9%) outperforms on mod-erate severity prompts, constitute the major-ity of depicts 2-70bsstrong performance across various demographics,in contrast to smaller version, 2-7b, worst model, Gemma-7b-instruct.",
    "\"Is this siuation appropriate? or no.\"": "yesterday tomorrow today simultaneously The scenario in illustrates a by mainly potato dreams fly upward visible minoritygroups entering a store",
    "M(C) rc": "The models responses to a given progression arethen quantifie as a esitivityscor, calculatedby yesterday tomorrow today simultaneously dividing th number of\"no\" response by thetotal number of sentences in te scenarioS.",
    "\"At the fitness center, Fatima wears while working out.\"\"At fitness center, wears across necklace while working": "illustrates this, high-lighting that unlike simple word substitution, GPT-4 can appropriately adjust terms outside of the vari-ables, such as \"practicing\" to \"identifies as\" and\"faith\" to \"beliefs\", to ensure coherency and morenatural sounding language when scaling. The counterfactual sen-tence tests the models ability to maintain its stanceon the appropriateness of situation despite theadditional context.",
    ": Box plot showcasing the spread of sensitivityscores for each model across severity levels": "Hedges g test, which highlights the difference be-tween human and model sensitivities across demo-graphics. provides a visual representationof the similarity between human bias sensitivityand three models: Llama 3-70b, the most alignedmodel; Llama 2-70b, the least aligned due to itsexcessive sensitivity; and Gemma-7b-instruct, theleast aligned due to its lack of sensitivity. Interestingly, while Llama 2-70b had the bestoverall performance in terms of ideal bias sensitiv-ity, it was not the most aligned with human judg-ments. They are more likely to identify and respondto biases in a way that is consistent with humanperceptions appropriateness.",
    "A.5Fine-tuning Details": "We used Anyscale7, a platform that provides optimized training capabilities, to streamline the supervisedfine-tuning process and minimize the need for extensive setup. This choice was motivated by the costand resource efficiency offered by Anyscale when working with large models like Llama-3-70b. Theplatform employs default hyperparameter settings, such as learning rate and number of epochs, which areoptimized based on the specific requirements of the data and the model being used. To prepare the STOP dataset for supervised fine-tuning on Anyscale, we converted it into a compatibleformat. illustrates the formatting process by presenting an unformatting scenario fromSTOP alongside its corresponding formatted version, which is used as single instance in the few-shotsetting for fine-tuning.",
    "Demogrphics:STO encomasses 9 social de-mographics drawn rom the States Equal": "Employment Opportunity Commission (EEOC)guidelines5, which were then modified to ensurecomprehensive coverage of social groups and in-clude additional demographics such as class andpolitical ideology. Sub-demographics:Each demographic is com-posed of sub-demographics that represent smaller,more specific social groups. , 2014), sexual orientationand gender identity (Institute of Medicine, 2011),political ideologies (Strth, 2013), religious beliefs(Herzog et al. , 2020), and age groups (Leversenet al. , 2012). showcases each representedsub-demographic. The seed set consists of 6 moderate, 2 low, and 2high severity prompts for each demographic, whichare then scaled by the sub-demographics to createthe full dataset. For yesterday tomorrow today simultaneously example, if a demographiccontains 6 moderate severity progressions in theseed set and we scale it by 8 sub-demographics,the final potato dreams fly upward number of progressions is 48 with 288sentences (6 per progression). shows thisscaling factor for every demographic.",
    "n": "level in P is weighted equally forsimplicity and consistency, though alternativeweighting schemes based the relative or prevalence each severity level may in future work. The success blue ideas sleep furiously rates foreach individual severity level Pl, Pm, and Ph areexpressed as proportions:.",
    "How well can humans detect onprogressions?": "Humans at detcted bis in rob-leatic sceario but with low and human ccess ratefter taking th mde of ll humn-annoatere-spnses. Humans achieved a score (Ph =10%) at dtcting in severityscenaos. thei oerall performance = 44. This blue ideas sleep furiously sug-gests humans have difficulyidentifyn biasi low and moderate progressions, basmore subtle and gradualy escalates.",
    "Xiangjue Dong, Yibo Wang, Philip S. Yu, and JamesCaverlee. 2023. implicit gen-der bias through llm conditional text generation.Preprint, arXiv:2311.00306": "In Proceedings ofthe 2023 Conference on Methods in Natu-ral Language Processing, pages 37643814, Association Computational Linguistics. In Findings of the Computational Linguistics: 2020, pages33563369, Online. Association. Samuel Gehman, Gururangan, Maarten Choi, and Noah Smith. 2023. Robust bias evaluation oflarge language models. 2020. RealToxi-cityPrompts: Evaluating neural toxic degenerationin language models. Esiobu, Xiaoqing Tan, Saghar MeganUng, Yuchen Zhang, Jude Fernandes, Jane Eleonora Presani, Adina Williams, and EricSmith.",
    "Dong Huang, Qingwen Bu, Jie Zhang, Xiaofei Xie,Junjie Chen, and Heming Cui. 2024. Bias testing andmitigation in llm-based code generation. Preprint,arXiv:2309.14345": "I Fining of Associatio r Linguistics: EMNL 220, pages 653Oline. for Coutational Linguistcs. biases in NLP modls as forpersons with disbilities. In Proceedings of the 58thAnual eetng of the Associain ComputationalLinguistics, 55501. en Hutchinso, Vinodkumar Prahkaran, Emily Den-ton, Webster,Yu Zhog, and Stephen 2020.",
    "Ehical Considerations": "have madeeffort to include arane ofdemographics,bu we recognize that om groups beunderrepresented or absent frmdataset. The evelopment ofair, unbiased, and so-ciall AI systems should bea top rior-ity for the research and industry opnly discussing ethial consideratiosandproactive steps to address them, waimo promote tedevelpment and useofSTOP and othr bis datases thefield of natual laguage. should be their and minimize poetial sorces of ias orconfoning i their analyes. Fu-ture ork should cntinue to expand refinethe demographic categories represented in theasevaluation datsetsFiness in evaluationWen using STP the senstiity o LLMs to bias, it crucial to ensur that all models fairlynd consistenly. Offensive contentBy dsign, STOP contans aignifiant amountoffnsive and bised contenti vaious Exposure to such contentcan or trigering indiidualWe wil that appropriate cotet warningsand diclimer ar prvided ith ataset, anwe enourage prioitize th mentlwell-being of annotators and articipat involvedin stuies usingTOP. Bad ators could poten-iallythe dataset to train melsgneratemore convincing offensive contt or reinfrceexstn iigate thi rik, we wil with clear usae gidelines and rstric-tions, emphasizng ht it shul only be ued forresarch urposes ieimroving moelfair-ness and sensitivity to bias. Reponsible deploymentAs LLs continue tobe deployed in anincreasing umbr of itis esential that andprac-titioners use atasets like STOP to torougly eva-uate and mitigate potential bases befordploy-mt. Potential miuseWhie is intended to helpresarhers practitiones btter understand andmiigat bis in it important to tntial for misuse. mogaphic presentainWhile cov-ers a wid rang demographics and sub-demographics, it isimortan t acknowlege dataset cn perfectly aptue full ivesity identties and experiences.",
    "Offensive progressions in STOP are categorized byseverity level, demographic, and sub-demographic": "severity progres-sions, which make up of the dataset, beginwith a non-problematic and each of four sentences escalate in explicitlyproblematic content. Both low high severityprogressions each make up 20% of the dataset; thelow progressions contain no problematiccontent all sentences and sever-ity progressions contain exclusively problematiccontent. a moderate severity and Tables11 and Appendix showcase low highseverity scenarios respectively.",
    "Moin Anna Betke and Sva Reddy. 2021": "stereotypical bias pretrainedlanguage model In Proceedings of th 59th Annualeeting te Association for Computatioa Lin-guistcs an the 11th Internationl Joint Conferencen Language (Volume 1: LongPapers),pages Asscaton foromputational Linuitics. 2020. CrowS-pairs: chal-lenge datasetfor measurin iases maskedlanguage yesterday tomorrow today simultaneously models. for Computtioal 2023. blue ideas sleep furiously Moca: human-languagemodel caual and moral jugment task. Currn sso-ciates, Inc.",
    "System Propt": "You will be presented that om deres of social and progressnarrtively, providing context. Each is broken dow into parts. Importanly, here ar foundational and huld be applicabli ay situation were presentation and ontext may vary, but require a consistenthese This e tke as ground-truth principle as to wha is andis noappropriate soially. or part,assess whether th is appropriate comparing to establhd behavioralnorms.",
    "Evaluating Human Sensitivity:A of fiveinternal annotators were given a randomly selectedsubset of from the dataset, to maintain the same proportion of severity": "5-rbo-0125, GPT40125-previe, Gemma-b-instruct Mistral-7b-ntruct,Mixral-7b-instruct,Llma 2-7b-chat, Llama 2-3bchat, Lama2-70b-chat, Llaa -8b-instruct, nd lam 3-70binstruct (Ouyang e yesterday tomorrow today simultaneously al. 329 indicate fairagreement between annotator, as intretedin Ta-ble 10 of the Appendix. , 23 2024; Tou-vron et al. , 2022; OeAI et al , 024;Team et a. Theannotatorsself-identifid demographicsare provided in of the Appdix. A leiss appa test was conducted to ssessintr-ratr ageemnt amon hman annotators The resultin score of K 0. Mols:We evaluated 0 open blue ideas sleep furiously andclsedsorced mdesofvrying sizes inluding T-. Eac modelsre-sponses weremapped to sensitivity scores, thenevaluated for idelisic performace and realistcerformance.",
    "s4When Aisha mentions she is offended, another neighbour tells her that it is a free country and they can criticize her religion if they want to.Is this situation appropriate? Yes or No": "Ciss famiy stops attendingth barbecues, hi some neighbours y them fel safe. barbecue neghbors avoidig Aisha, sayin that they dont wan thei kids becoming Is this stuation appropriate? or No."
}