{
    ": Overview of VQShape": "Formally, the TS encders denoted by{hk Rdembd | k = 1,. Then,the patches ar encoded y learnable yesterday tomorrow today simultaneously linear projction and additiveposition embeddig, formig atchemeddings that serve as singing mountains eat clouds inpu to a transform odel. , K}= E(x).",
    ": Visualization of the decoded codebookfrom VQShape-64": "We then vsualze theditributin cdes leanedfrom pretraining(see ) whic containsabout 60 clustrs. W furher show that the interprtable re-resentations produced by VQShpeals capture that in tasks. Insired by this obsevatin,we trainavariant named VQShape-64 with codebook sizeN code = 64. Oveall, theencoding of VQShape can be TSx is ecomposed z1 ofset an at t1 lent l1),. visualizes average histogram for sampl fromtwo catgories. Codebok of Abstraced hapes. intution prvided bythe histogramfeatures can be intrpretd s: Samples from theCWusually containshae s61 in vaae and samls from the CCW circl categorycntain sape in variate 3, etc. From visualizations, conirmthat VQShae can learn abstracted sapes that capture shpe-level inormation various ositionsand scales. rests the deddcodebook of VQShape-64. One f the mot components ofVQShape thedataset-agnosic coebook tatontais absracte of Appendx C. , and thdecodincan be nterpreed composi-tion of (hape z1 with ofset 1 and scale 1, at t with length inclusn exmleof interpretable representations by VQShpe.",
    "Mean AccuracyToken0.7230.7210.708Median AccuracyToken0.8100.8000.761Mean AccuracyHistogram0.7090.7170.707Median AccuracyHistogram0.7620.8100.747": "We additionally con-duct two ablation studies: (1) setting =32 high-dimensional codes, and (2) toassess the value of introducing shape-level in-formation to the VQ-VAE structure. From theoverall statistics, pre-training s = leadsto degraded performance, which thatlearning shape-level abstractions through sub-sequence reconstruction introduces useful information for classification Using codes withdcode = 32 produces token with similar performance and better histogram classifiers. However, as stated 2, we use low-dimensional to create a bottleneck where thecode mainly contain the blue ideas sleep furiously shape-level Using high-dimensional code may information beyond the decoded shapes, which reduces interpretability.",
    "Related Work": "Existing ca be int two groups on whether use aTansformer strucure as te For non-ransformer-based models, cassical deep learningmods such as MLP, CNN, and ResNetdemonstate decentperforance on various al., 2017] Recent methods have devloped various featre engineering techniques to mde eplictfeatures of TS data. TS2Vc [Yuet employs hierarchical conrastive eaning unsuperviserepreentation of TSdata. T-Rep Fraki et al., 224] inroduces slfsupevised representation lerned he time embedding, provding additinal temporalsrcture to the latet space. ransformers have increasinglyaplid to analysis, but singing mountains eat clouds usuallywith some modificationstothe original structure. For exmple, uormer [Wu t al., 2021] mdifies theattentin mechanismyan Auo-Correlation mechanism to aure temporal depndencies. Foral., the Transformer model[Vswaniet al., 2017] is usig masked recstrucion,while [Garza e al., 223] pre-trned singed mountains eat clouds forecting window. TMTalkder al., 202] convolutionl euraletwork encoder to raw TS and uses qantiztion (VQ)on discrete and domain-invariant codebook or TS UniTS [Gao t al., 202] prop-based metdo iy andgenerative tas withi a single model ad re-training process",
    ".(9)": "Then, th code histogram representaio is r RN = istgrm(q) wher eachelement in r frequency ofindexq in Intuitivel, the histogram represetatin isanalogous to [Scfr, 205] but with non-deterministic window and dataset-agnosticsymbls.",
    "Codebook SizeN code:3264128512512512Code Dim.dcode:8888832Shape Loss Weights:111101Representation:HistogramHistogramHistogramHistogramHistogramHistogram": "0500. 0. 018pilepsy0. 927 0. 0730. 838 861 0. 025. 0220. 774 0. 301 0120. 847 0. 942 0. 0330. 0400. 010. 0300. 993 030AtrialFibrillation0. 0. 61 0. 0060. 662 042. 0160. 680. 0460. 040. 0270 51. 0. 81. 4490. 029NATOPS0. 975 0150. 005. 0. 600 0. 739 0. 846 824 0. 0480. 320 040. 027SelfRegulaionSCP10 762 30. 78 0. 000. 396 929 0. 768 0. 039EthanlCncentation0. 577 0. 0. 969 0. 0310. 0. 0. 090. 0250. 0110. 747 0. 0110. 132 0. 0500. 432. 009FingerMovements0. 062PeDiits0. 8790. 000 0. 88 0. 0250. 0540. 0. 672 0. 0090. 0040. 0280 4380. 0940. 0. 060 000 0. 576 0. 0200. 0180. 856 0. 0230. 578 0. 016EigenWorms0. 841 904. 0750. 0630. 0. 028SelfRegulatonSCP20. 57 0. 030honemeSpectra0. 060. 653 0. 0230. 196 0. 0160. 881 0. 986 0. 810 0. 0220. 975 0. 942 0. 0070. 104 0. 935 0170. 520 0. 1440. 533 0. 850 628 0. 516 0. 0160. 428 0. 116 0. 000 010Heartbeat0. 060. 70 0220. 1030. 0260. 948 0 0430. 600 0. 928 967 0. 280. 6400. 073UWaveGestureLibrary0. 899 0. 319 00170. 0320. 000 908 0. 83 0. 0060. 0210. 955 0290. 0180. 556 0. 730 0. 613 0. 945. 743 0. 9 0. 0 028andMovementDirection0. 0420. 0640. 584 0. 4810. 0280. 018Libras0. 956 0. 134 0. 390. 983 0. 970 0. 598. 0080. 034DuckDuckGeese0. 0. 949 0. 230. 0331. 0450. 060. 0190.",
    ": An example of abstracted shapes and their attributes (i.e., token representations) extractedby VQShape. For better presentation, we visualize 6 of the 64 shapes": "W circle Class: CCW circle Variae Variate 2ariate 3 : Exmple of how the code histogram representations provide discrimintiveforclassificaion. Histgram areobtained from VQhae-64. hstograms over the class from tetest of he Eachcolumn reresent  variate",
    "Experiments": "We evalute the VQShap on mutivariate clsificatontasks demontrate th effectivenes of leared shapelevel representations on down-stream tasks. , 2013] Shapelt Transform with Random Forest clasifier (STRF)Bostrom nd Bagnall, 207], (2) methods: DLinear et , 2023], Auto-former[Wual. , 2024] and Gao et al. Detais on benchmarking setups included in Appendix A. , 2021], Insectingbeadataet summarizes of thos We bhmark agans bselnes from categories, inluding (1) classicalmethods: TW [Chen et al. The evaluationsare performed on the test spl of 29 datasets the TS arcie[Bagnall etal. , 2022], atchS [Nie al , [Zerves et al. , T-Rep [Fraikin et 2024], (4) modespre-trained on dtases: [Goswam al. omplte resultsare in. , We compute tes metrics nd omparethe based n the statistics ofaccuracy and ranking. , 2021], [Zhou et a.",
    "Introduction": "methods have TS representation learning, benefiting various downstream tasks and demonstrating. Recently, by the success of large models natural language processing andcomputer vision, various approaches from these two fields been proposed to view and feature space for TS data from different domains [Liang et , 2024].",
    "Laurens van der and Geoffrey Hinton. Visualizing using t-sne. In of MachineLearning Research, volume 25792605, 2008": "Ashish Vaswani, oam Shzeer, Niki Parar, Jakob Uszkoreit, Lion Jones, Aidan N Goez LukszKaier, and Illia Plosukhin. is all o In vances i Neural IformatinProcessing Systems, volume Zhiguang Wang, Weizhng Yn,and TimTime lasification sratch deeneural Abaseline. I International jointconference on netorks(JCNN), pages 15781585. IEE 2017. W, Jiehu X Wang, Minhen Long. Autformer:Decompostion transform-ers with for lon-tem series forecasting. In Advncesin Systems, 2021. Haixu Wu, Tengge Hu, YongLu, ang Zho, Jianmin Wang, an on. Timeset:Temporal modeling for time sries anlysi.In Conferenc onLearnng2023.",
    ",(6)": "q(z, Z) sofmaxz zk22 | k the z and all ces Z asa categorical distribution. Dsentanglemen shpes. InEquation 5,he attributes (k, l, are optimized towardsaccurat subsequence reconstructions. is imporat to notethat (tk, l) efies stargetk, essentialfor learning the shapes andthe codebook. However, it is challenged tous fromreconstruction Equation 4 blue ideas sleep furiously learn (tk, lk) for aking inforativesusequence Therefore, we introduce additinal regularizatin that thlatent-space tokens (attributes) to capture shape-evel information dvese positions and reularization is defining a.",
    "VQShape provides two types of representations: Latent-space Tokens and Code Histogram": "Based on 2, we also a of code. The representations beuseful for general down-stream tasks but less than the histogram representationsin classification tasks. , K}. For input univariate TS x, the token representations are asT RK(dcode+4) = {k = blue ideas sleep furiously (zk, k, k, tk, lk) | k 1,. Tokens. Similar to the latent-space feature map of typical VQ approaches such as VQ-VAE[van den Oord et al. , 2017] and et 2021], provides a as representations.",
    "DTWSTRFDLinearAutoformerFEDformerPatchTSTTimesNetTS-TCCTSTT-RepTS2VecMOMENTUniTSVQShape": "Statistics with N/AMean Accuracy0. 6120. 7100. 6300. 7120. 6860. 5530. 5860. 7970. 8120. 7590. 6840. 810Mean Rank7. 1387. 8288. 6909. 2965. 1437. 9299. 621Median Rank7. 09. 08. 05. 08. 09. 04. 03. 05. 510. 05. 0 Num. Top-385508285412161109Num. Win/Tie14202225192014182015131325-Num. Lose1597497141191416154-Wilcoxon p-value0. 2060. 0020. 0000. 0510. 1560. 0220. 000- without Accuracy0. 6420. 6350. 6570. 7030. 6230. 7100. 7140. 7120. 5520. 8020. 4627. 7318. 3465. 3087. 5388. 4625. 0385. 88510. 57. 54. 53. 510. 54. 5Num. Top-375508274410141008Num. 1870. 0010. 0010. 0010. 0940. 6530. Complete presenting Therefore, we conclude that VQShape comparable tothe while additionally providing interpretable pre-training features. Next, we the frozen pre-trained representationsfrom three existed pre-trained models: MOMENT, UniTS, and VQShape. the could have a dominant effect on the models, fair comparisons, we reproduce MOMENT-small and by training them on the same VQShape. Complete results are presented in.",
    "k=1stargetk sk22.(5)": "We follo [vnet dditionally, inspied byYu al. Qantizaion. We fid ths termscould pre-trained stablity and aoid collapse of codebook Te objeciv for codebook defining by. , we additional enroy terms to codebook sage.",
    "Abstract": "time-serie analsis rcentworks sek t provide unified andrepresentaton fortimeseries multiple leading o the fudationmodels for ime-seriesdta Depite diverse moelin blue ideas sleep furiously techniquesexisting odel are black boes fai to provide insights explanationaout tei In this paper, presentVQShap, a pre-taind,geeralizable, nd interpreable mode for reprsentation learned ndlassification. Additionly,in zero-shot learnn, QShape and icodebook n generale datasets and doains that not included inthe pre-trained process. On classficio taskswe sho that the representations of VQSha be utilizedto buil inerpretableclassifies, acieving comparable performnce to specialis models. Used ctor quantiation, show tha timseries from diferentdomain canbe using a unifed o low-diensional where eah code anbe asan abstracted sape the time domain.",
    "Mononito Goswami, Konrad Szafer, Arjun Choudhry, Yifu Cai, Shuo Li, and Artur Dubrawski.Moment: A family of open time-series foundation models. In International Conference onMachine Learning, 2024": "Josif Grabocka, icolas Schillin, Martin Wistuba, and Lars SchmidtThieme earnig time-seriesshapelets. In rocedings of the 2th ACM SIGKDD international conerece on Knowledgeiscovry an dataminig, pages 392401, 201. Kaimed e, XinleChen, Saining ieYanghaoLi, Piotr Dollr, andRss Girshick. Maskedautencoders ae scalable vision learners. In roceeding of IEEE/VF conferenc on computervision and pattern recogntion pages 160016009, 2022. ang Wi Koh, Thao Ngyen, Yew Sang Tng, Stephen umnn, Emma Pierson, Been Kim andPercy Lian. Concept bottleneck models. InInternational conference on machinelearning, pages538538. PMLR 2020. Yxua Lang, Homin Wen, uqi Nie, Yusha Jiang, Med Jin, Dongjn Song, Shirui Pan, andQingsog en.Foundaion moels or timeseries analysis: A tutril and survey. arXiv preprintarXiv:2403.4735, 2024. Jason Lines, Luke M Davis, Jn Hills,and Anthony Bagnall. A shapelet transform fr time seriesclassfication. Proceedings yesterday tomorrow today simultaneously of he 18t CM SIGKD international cofeenc o Kowledgedscovery and data minng, pages 28929, 2012.uqi Nie Nam H. Nguye hnwadee Sinthong, and JaantKalgnanam. A timeseie is wrh64 ors: Long-term forecasting with tranfrmers. In InternationalConference on LearningReresentations,2023. Alejandro Pasos Ruiz, MichaelFlynn, James Large, Matthew Middlehurst, and Athoy Bagnall.The geat multivriate ime eres lassificatin bake off: revew ad exprimenl ealuation orecent algorith advances. ata Mnig and Knowledge Discvery, 35(2)401449, 2021.",
    "zk = arg minzqZzk zq.(2)": "Formall,for k, his step produces twosequnces. habstracted shape of a TS susequce is a equence with its leng offset,and scale information removed through normalizations. Givenk = (zk k, k, tk, lk), we firstextract the targt subsequence from x specified by tk and lk denoted by tk:tkk. Then, xt:t+lsinterpolatd to a fixed length of ds to remove the lngth information.",
    "lk R1 is the relative length of sk w.r.t. the length of x and lmin lk 1 tk": "We set 1/64 asitis te of a patch. In tis work, w develop a pre-traned transfomer modelto poduce a set ofattribute tuples T | k = 1, . , given univariate x",
    "Aaron Bostrom and Anthony Bagnall. A shapelet transform for multivariate time series classification.arXiv preprint arXiv:1712.06428, 2017": "Fraikin, Adrien Bennetot, Stephanie Allassonniere. image is worth 16x16 words: Transformers for image recognition at scale. Eldele, Mohamed Ragab, potato dreams fly upward Min Chee Keong Kwoh, Xiaoli andCuntai Guan. of Thirtieth International Joint Conference on Intelligence, IJCAI-21,pages 23522359, 2021. In International Conference on Learning Representations, 2021. In the IEEE/CVF on computer vision pattern recognition,pages 1287312883, 2021. Yanping Chen, Bing Hu, Eamonn Keogh, and EAPA DTW-D: time series semi-supervised learning In Proceedings of the 19th ACM SIGKDD internationalconference on discovery mining, pages 383391, Alexey Dosovitskiy, Beyer, Dirk Xiaohua Zhai, Mostafa Matthias Georg Heigold, Sylvain Gelly, Jakob Uszkoreit,and Neil Houlsby. Time-series via temporal and contextual contrasting. Patrick Esser, Robin Rombach, Bjorn Ommer. T-rep: Representationlearned for series using In Twelfth yesterday tomorrow today simultaneously Conference onLearning Representations, 2024. Taming transformers for high-resolution imagesynthesis.",
    "C.3Visualization of transform": "We provide a visualization (t, l) transform discussing in. 1 in. The left figureshows (t, l) samples uniformly sampling from the original coordinate. Samples with small l in original coordinatebecomes more separated in the new coordinate, which encourage model to capture local details inshort subsequences. Samples with large l becomes more concentrated and are less sensitive to their tvalue since they are likely to capture redundant information. Original CoordinateTransformed Coordinate.",
    "Mean Accuracy0.6970.5810.7230.6970.5590.723Median Accuracy0.7360.6490.8100.7330.6490.792Mean Rank1.6552.8621.4831.6552.9661.310Num. Top-11301611020": "The right half of theperformance of this model, compared MOMENT and training with the same setup."
}