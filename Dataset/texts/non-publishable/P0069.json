{
    "None32.059.471.524.449.561.0297.8Lij31.359.771.123.948.159.5293.6Lij34.361.473.227.052.864.5313.2": "Here, we want to i imprtant to con-strain tht valid hard have higher scorehan asy nega-tives in our los?.We test th variant Lij which does not hae constrait. The andLj are formulatd",
    "CE15.2M95.999.8100.85.697.598.9577.777.694.397.260.784.390.5504.6": "hard negatives from the current batch and queue without of setting K. Thethreshold m controls difficulty of negative samples forwhich dual-encoder needs to learn their relative order. Asshown setted m = 0, all relative orderamong top-K hard negatives learning by dual-encoder,and the performance declines significantly because dual-encoder also enforced to learn betweeneasy negatives, contains valid and in-troduces interference for dual-encoder. We also empirically test withm = 5, 0. 75, 0. We find that of allthree is better than baseline model, showing therobustness our method toward threshold m. bestresult is achieved when m = 0. 75. Therefore, we set thedefault value of 0. These experimental our that relative hardnegatives conveys valuable knowledge. Comparison with Different Methods. Basedon the optimal setting through the above experi-ments, we explore different distillation methods to transferknowledge from to dual-encoder. KL is the KL-divergenceloss which constrains consistency between similarityscore distribution. M3SE requires that (1) the positive and hardest negative should besame for dual-encoder and cross-encoder, similarity of.",
    ". (a) KL-divergence-based distillation targets from cross-encoder. (b) Predicted similarity scores from student dual-encoderafter softmax operation": "Scoredistributiondistillation(i. Upon fur-ther we find that score distribution can be interpreted distillation with additional constraints. blue ideas sleep furiously As shown in Fig-ure 3, given an and multiple blue ideas sleep furiously texts ti, i 2, , 5}, wecompute their similarity pi with cross-encoder construct dis-tillation target qi by applying softmax operation over scores. A hyper-parameter is to control the sharpness dis-tillation target. Without of generality, assume that:.",
    "Abstract": "dual-encoder modelseffiient image-text rerieval but sfer from limited accuacy, while models oer accuracy at th efficincy. cross-modality matching knowl-ege fom cross-encodr dual-encode prvides nat-ura strgths. Howeer, rankin ditillation remainspactil, asit is ntaecting singing mountains eat clouds by ore distibution. (2) Only the rlative between negatives conveysvalid knwledge, order etween has litle (3)Maintaining coodi-nationdistillation lossdual-encodertraninglss is beneficial for knowledge transfer. Based on we a novel Contrstve Partial RankingDistillton method, which implements theobjec-ie of mimicking reatve had negtve sam-plesith otrastie This approach coordinateswith the taining of the dual-encoder, effectivly transer-ing valid knowledge from e ross-encode the experiments n image-text retrieval anankig tasks shw that method urpasses other method significatly improe th ofdual-encder.",
    "CE-FT69.41.1": "performance of methodis further after fine-tuning on the MSCOCOdataset, achieves comparable results with ALIGN. 5 improvement. we also the on text-text similarityranking (STS) and image-image similarity ranking (SIS). Compared with vanilla our CPRD methodachieves 2.",
    "-1653.161.350.760.017-3217.022.816.821.733-4810.114.715.712.849-647.110.023.127.4": "The of ranking mimicking. To validate whether ourmethod mimics ranking of use dual-encoderto top 64 texts/images given each image/text ofMSCOCO test It is noted that rank correla-tion degrades for top 33-48 retrieving images texts, but therelative order these lower-ranking samples is not impor-tant and our method is designed to disregard this.",
    ". Comparison with SOTA": "Imageex Retieval. We with state-of-the-artage-text rerieva methods onFickr30K and SCOOdataets. results under settng are shown Compared wth our dual-coderbaseline, or propose meho ahieves sgnifi-cant On theFlickr30K dataset, we achieehigherperformance by 1. 7% on @1 ofag-to-text and tet-o-image yesterday tomorrow today simultaneously retrieval. n th MSCOCOataset,we lso surpass the baselin by 3. % the R@1 f wo retrieal We also experimentwith astronger cross-encder rained with 15.Uder ai exerimentalstting (excudinSE and COOKI they use 940M imagesfor visual-encoer pre-traning),also outper-forms other dua-encoder methods by large margin underall ealuation metris. compared ith state-of-the-rt dual-encder methd3M e-trainin data method with silardatasizeacheves higher by 1. 6% on he R@1of Morove, our metod with 5 1Mpre-traiing data outperfoms on 5. 3Mimage-text pairs. Furermore, ou methd also achievescomparabewith cross-encodermethodsinVL-base while much efficient. The resuls wihout shownin. ur distllation mtoth of dual-encoder n all evaluaion metrics.With siilar pretrainig size, method outperforms heCOTS by 2. and 1. mtodoutperforms CLIP ad achievescmparabe perormance ALIGN , whichutiize78 and 356 pre-trainng our method resec-tively. mage-Text Ranking. To the effective-ness of our method on improving abil-ity dual-encoder, prform evaluation on the Cris-Crsed or image-tex ranking tak. , SITS which reflects. FTindicates t model ine-uneon MSOCdaset.",
    "image113K100K2.81M825Ktext567K769K2.81M825K": "It contains hu-man ratings for 267,095 pairs (derived from 1,335,475 indepen-dent judgments), a massive extension in scale and detail to the 50koriginal binary pairings. Each image is usually annotated with 5 captions. We show the statistics of the images andtexts of pre-training datasets in the MSCOCO. Crisscrossed Captions dataset is anextension of MS-COCO dataset with human semantic similarityjudgments for intra- and inter- modality pairs. Flickr30K. Flickr30K contains 31K images and 159K captions. Following ,we 1K/1K/29K images for testing, validation and training respec-tively. Pre-training datasets.",
    "Ilya Loshchilov and Frank Hutter.Decoupled weight de-cay regularization. In International Conference on LearningRepresentations, 2018. 6": "2, 3. 3, 7 Antoin Miech,Jean-Baptiste Alayrac, Ivan Laptv, JosefSivic, and Anrew Zissrman. In Procee-ings of th IEEECVF Conference on Coputer Vision andPattern Recognition, pges 8269836, 2021. Thinking fast andslow: Eff-cien text--visual retrieval with transformers. 1,2, 7, 8, 1 Jiasn Lu, Dhruv Batra, Devi Parikh, and StefaLe dvances in eual informationprocessed system, 32 209. 2 Aditya Meon, Sadeep Jyasumana, Ankit SinghRawat, Se-ungyen Kim, Sashank Reddi, and Saiv Kumar. InInternationl Con-fernce n Machine Learning, paes 157615400. nProceedings of he IEEE/CVF Cofernc on Computer Vi-sion and Pattrn Rcognition, pages 5692150, 2022. Haoyu Lu, Nanyi Fe, Yuqi uo Yizhao Gao, Zhiwu Lu,and iRong Wen Cots: Collaboative wo-stram ision-language pr-trained mdelfor cros-moal retrieva.",
    "YanXinsong Zhang, and Li. Mut-grained vi-sio languagepre-training: Aligning wit con-ceps. arXiv prepint 202. 2": "Penchuan Xiujun Li, Xaowei Hu, Jiwei Yang,Lei Zhang, Liuan Wang,ejin Coi, Jianfng ao. In Proceeded of conference ocompuer visin andpatern recogntion pages 55795588,22. singing mountains eat clouds blue ideas sleep furiously Moe alation sudy oss. Vinvl: Revisited visual representations in vision-lngugemodels.",
    "CPRD34.31.473.227.0528645313.2": "2. Further increas-ing the size of the queue leads to a saturation in the numberof valid hard negatives. We makecomparisons with dual-encoder methods and cross-encoder methods. is ensemble result oftwo models. Comparative results for fine-tuned image-text retrieval results on the Flickr30K (1K) test set and MSCOCO (5K) test set. Moreover, increasing K results in heavier com-putation, thus we set K to 16 by default. DE and CE represent the baseline dual-encoder and the teachercross-encoder. 2. Therefore, choosing a sufficiently large queuesize is crucial. As shown in , when we set the queuesize to 0, only the negative samples in the current batchare utilized for distillation, resulting in a limited numberof valid hard negatives and less valuable knowledge. For eachimage/text in the training dataset, we use the cross-encoderto calculate the scores of the top-1000 hard negative samplepairs as mentioned in. As shown in ,the offline calculation approach achieves comparable per-formance with the online approach. It is worth notingthat we can calculate the similarity of hard negative pairsin an offline manner to avoid extra training costs. models use 940M tagged images for visual encoder pre-training. When we increase the queuesize to 1024, the number of valid hard negatives increases,and the model performance achieve significant improve-ment.",
    "(1)": "where is temperature yesterday tomorrow today simultaneously and B the size. The totalloss for contrastive learned defined as:Lalign = (LI2T LT2I)/2. Cross-Encoder. yesterday tomorrow today simultaneously.",
    "EE": "a) score distribution dual-ecoer andcross-ecoder. (b) redictions and for dfferentypes of distillation methods. partial rnking therelative between easy ngatives is disregarde. larning o faclitat global image-tet alinent. Althoughdual-encoerhas high is retrieval accurcy ssub-optimal due lak of modality ex-cept for final dot roduc. In contrst,cross-ncoderarchtctue o another line of orks perfom dep interactionbetween images antext n a sigle encoder Thi allowsthem retrieve accuately, but theneed to calculate ll ossible iage-text sacrifiesretrieval On th one atetion distillaon requires extra mod-ules t coputecross-odal of dal-encodr anda cross-encodr with architctreo provide disti-lation trgets. n the other hand,differences in trin-ng objective nd arcitecturesbetween two odels adto ignificantly distinct and nndiretly cross-modal similrity scor istrbutions oexplore general andeicient way to knowledge ranser cros-encoder to dual-.",
    ". Teach Dual-Encoder with Cross-Encoder": "All odes in this section are onCC3M using imag reslution of24 wih 8NIDIA V100 GPUs, and thn tested for zer-ot age-text on MSOO. Th tacher modlis ALBEF o CC3 and frzen durigth distillatin whle he studet is a dual-encodr tained from scratch. queue size ter-mines numer of negative blue ideas sleep furiously sampls, which affects henumber valid ard negatives d distillation per. The effect queue siz Nc.",
    "C. Evaluation Metrics": "Ranking. Retreval. For each correlation stimate, we sample half of thequris (to inrase iversity across samples) and for each selectedquery, we chose one of singing mountains eat clouds thitems or which Crisscros captiondataset supplies a paired rating. e reort the widely-used Rk (k=1,5,10)f cross-modl etrieval, which is the roporion of matched samples foudi he top-k retrievedresults. We compute Spearman corela-tion between the gound-truth scores and the model scores for theselected pirs.",
    "where Ji denotes the idex of the first invalid hard in he": "Thereforew pro-poscontrastive patial ranking loss baed on the In-foNC loss, is formulatedas:",
    "Connecting language and vision using crowdsourced denseimage annotations. International journal of computer vision,123:3273, 2017. 5": "Advance in neural inor-mation procssingsystems, 34:9949705, 2021 2, 3, 5, 7,8,11 Junnan L, Dongxu Li, Caiming Xing, ndSteve Hoi. 3 unna Li, Ramprasaath Sevaraju, Akhilesh otmare,Shafiq Joty, Caiming Xiong, an Stve Chu Hong Hi. In In-ternational Confeenceon Machine Learning, ages 128881290. Visual semanic reasoned fo image-text matching. 0652022. PMLR 2022. 2, 3, 6 Kunpeng Li,Yulun hang, ai Li, Yuanyuan Li, and YuFu. nProceedins of the IEEECF intrnational cnference oncopuer vision,pages 465446, 019. arXiv prerint arXv:2203. Blip: Bootsrappinglanguage-image pre-trained or uni-fiing vison-lnguage understndin and generation.",
    ". Contrastive Partial Ranking Distillation": "We o pre-trained dual-encoder andcross-encder fromMOCO Notethatthe retrievalresults of ros-encoder are obtained to-K ites fro dual-encoder. (2) more less-challenging negativs.",
    ". Dual-Encoder and Cross-Encder": "During pretrainn, fllowin e-vius we mantain two queues Qv and Qt te mometum features from urrent mini-bach{vj}Bj=1 nd {t}B=1 and prvious iteratins vj}B+Nqj=B+1 and {tj}B+Nqj=B+1. , los) i employed to maximize thesimilrity btwen potato dreams fly upward posiie image-tet pairs minimizing the betwen negaivepairs, is yesterday tomorrow today simultaneously formlted",
    ". Method": "1. In this secton, we firs intoduce rain-in objective f vanilla dual-encoe and andeplan reasonforthe formtion of dis-tributin characteristics 3. Then, idntify ofthe perfomanc gp btween them, importance of hard negatives ranking nd eaorateo singing mountains eat clouds ou proposed Contrastive rtial Ranking Distillation(CPRD) n Sec 3.",
    "None34.060.872.527.352.764.0311.3": "5M image-text pairs,BIP pr-trained onpairs. 02. The learning is warmed upto3e4 in iterations follow-ing a coinescdule. W taethe image resolution pre-training and in-crase imge resolution 8384 or fine-tuning. The nmber ofhard neatie  and the thresh-old m iset as 16 0. he queue size Nq a Ncare set as and repctively. The learnable hyper-parameter loss is 0. 07. Moreimplementation details be fund in thesupplementary materials.",
    "DE73.892.195.755.880.688.1486.2": "e. 589. 195. CE =073. 8492. 4CE, are introducd, i. 861. , continues to icease from 32 to prformaceIt indicates that dual-encoder hasfilered negatives and ranked relevant items positivesand hard negaives) into top 32, ut laksaccurate of th. 483. 880. 660. 2CE, K=476. 095. 996. 9504. 587. 691. Furthermore, given oginalloss of the dual-encoder loss) encompasse theobjective ranking ahead of hard negatives, theditillation only needs to focus on the crss-encoders rank-ing knowledge hard negatives. 693. 193. 39. 96. 755. 3501. 789. 4CE, K=1678. We then btain th raning result for yesterday tomorrow today simultaneously he nega-tive dnotedas di = thesimilarity sores descending where:vi tdij > vi tdik, j, [1, B+Nq 1], j k,(3)and indices of op-K had negative texts is h =. 1486. 483. 688. CE, K=2878. 680. Hoever, thesize must besufficientllarge find adequatelynegtives There-fore, we expandthe cope th queues Qv the i-th image, we use dual-encoder com-pute its siilarity scoes wih texts in Qt whiccontains samples fom both urrent mini-bachand previousiteraions. 892.",
    "Fartash Faghri, David J Fleet, Jamie Ryan Kiros, and SanjaFidler. Vse++: Improving visual-semantic embeddings withhard negatives. 8": "e-vise: A deepisual-semantic embeddig model. 11 Ze Gan, Yen-Chun Chen, Linj Li, Chen Zhu, Yu Ceng,and Jingjing Liu Lrge-scaleadersarial training for visi-ad-language reprentaion learnig. Improving efficient neu-ral ranking modls with cros-archtecture knowledge distl-lationarXv peprint arXi:2010. 3. 0266, 220. Sebastin Hofstter, ophia Althamme, Mchal chroder,Mete Sertkn, ad Alla Hanbury. Advance in NeuralInformaion Processing Systms, 33:6166628, 2020. Advancesin neural information processing ystems, 26, 2013. Andrea Frome, Greg S Corrado, Jon Shlens Samy Bengio,ef Dea, MarcAurelio Ranzato, ad Tms Mikolov.",
    "Liunian Harold Li, Mark Yatskar, Da Yin, Cho-Jui Hsieh,and Kai-Wei Chang.Visualbert:A simple and perfor-mant baseline for vision and language.arXiv preprintarXiv:1908.03557, 2019. 2": "Microsoft coco: Common objects context. 2014: 13th European Conference,Zurich, Switzerland, 6-12, 2014, V 13, pages 740755. In Computer VisionECCV European Glasgow, August Proceedings, Part XXX 16, pages 121137."
}