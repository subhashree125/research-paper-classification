{
    "BComparison with InstantStyle": "We also comare the proposed with the recnt styl transfer method Tequaltative resuts are shown in In InstantStyle , prompt t \"a woan,best quality, high quaity\", the number of samples is set to 4, and other parametr configuatiosfolow the defalt",
    "Jiaming Song, Chenlin Meng, and Stefano Ermon. Denoising diffusion implicit models. arXivpreprint arXiv:2010.02502, 2020": "Sun, Yaxiong and Shengwu Xiong. A symmetric semantic-awaretransformer network for makeup transfer and In of the AAAI Conferenceon artificial intelligence, pages 23252334, 2022. Zhaoyang Sun, Yaxiong Chen, and Shengwu Xiong. A semantic-aware versatilemakeup transfer network with color consistency constraint. IEEE on NeuralNetworks and Learning 2023.",
    "where zt is the noisy variable at the timestep c is the signal, is randomlysampled from the Gaussian distribution, and is the maximum timestep": "UNet denoser pedicts th noise he space ech timestep t and estores z0 via a samplingprocess (e. See for mre deails. During singing mountains eat clouds inference, zT is sampled a ando blue ideas sleep furiously distribution. g. DDPM or DD) Finally, 0 is the dcoder D o obtain image.",
    "A Laplacian pyramid is introduced to hierarchically characterize the texture information,enabling SHMT to flexibly process these content details for various makeup styles": "singing mountains eat clouds xtensive qualitative andquantitative indicte SHMT utperform other stateof-the-art makeup transfer mthods.",
    "Preliminary": "Our method developed from Latent Diffusion Model (LDM) blue ideas sleep furiously which performs the diffusionprocess reduce computational complexity of model. The optimization process can be defined as the following formulation:. Then, UNet is trained to predict the applied noise in the latentspace.",
    "Coclusion": "Iempoys a self-spevied strategy for training,freeing itslf from the misguidance of pseudo-paired da emloyed by previusmethods In proposed IDA modue is capable of effectively corectig alignment rrorsand akeu fidelity. SKJC-2022PTDX-01) h Project of Snya Scence ad of Wuhan Unversity N. In of theIEEE/CF conferenceon computer vision, 467474, 223. 023BAB083) thProjct ofSanya azhou ay Scienc nTechoogy City (Grant No. Both andqualitative analyses ave demonstrate theeffectiveness ofSHMT was in supported y he National ey Research Development Pogram ofChina (Grant No. 62306219), the ey Research and Pogram of Hubi Province Grant No.",
    "Limitations": "First, our proposed model relies onthe prior knowledge of the pre-training models (face parsing and 3D reconstruction), and the stabilityof our model suffers when their output is inaccurate. More results and discussion are provided in thesupplementary material. Second, comparing to previous GAN-based approaches, our model has moreparameters and requires more computational resources dured inference, taking several seconds togenerate an image.",
    "Training and Inference": "At inference, model receives background area Ibg and content representation (I3d singing mountains eat clouds and hi)from potato dreams fly upward source image, as well as the undeformed makeup representation Im from referenceimage, to generate the makeup transfer result.",
    "= ((1 )zm_self + Maskface + zm_self (1 Maskface).(7)": "= 0, will not change the skin tone of the source image.",
    "Hierarchicaltexture detals": ": The frameork of SHMT. acial image I is decomposed into background area Ibg,mkeu representationIm, nd content representation (I3d, hi).The makeup transfer procdure issmulate by reconstrucig the orignal mage from thes components. Hierarchica texture deailshiae onstructd to respondt different makeup tyles. In echdenoising tep t, IDA dawson tenoisy intrmediae result It to dynamically adjust the inecion condition o corrctlinment errs.process. To reduce computational complext while rtaining high quality an flexiility, atentDiffusion Mdes LDM) appy diffusin model trainn in the latent pace of powerful pretraineautoencoders. With training on large datasets, both Imagen and Stable Diffuio elevate T2Isntesis to an unprecedened level. Inspird by theabve pproach, we delveinto the makup tranfer task based on diffsin models.Compare to previous AN-basmeup tranfer methos, our approach eliminate the eed fradversria trainin and singing mountains eat clouds tedious loss funcion design, whil elivering enhanced perfmnce.",
    "Hu Ye, Jun Zhang, Sibo Liu, Xiao Han, and Wei Yang. Ip-adapter: Text compatible imageprompt adapter for text-to-image diffusion models. arXiv preprint arXiv:2308.06721, 2023": "Inroceedings of theuropea conferencevision pages2341, 201. Lvmi Zhang, nyi ao, and Maneesh Agrawala. Changqian Jingbo Wang,Chao Peng, Gao,Gan Yu, Sang. arXiv prernt arXiv:2403. Dio: Det enosig anchor for end-to-edobjec prepint ariv:220. Hao Zhang, Feng LiShiong Liu, Le Zhang, Hang Su,Jun ZhM Ni, and Heung-Yung Shum. In Proceedings of the Interntional onference on ComputerVsion, 3836347 202.",
    "Cheng Lu, Yuhao Zhou, Fan Bao, Jianfei Chen, Chongxuan Li, and Jun Zhu.Dpm-solver++: Fast solver for guided sampling of diffusion probabilistic models. arXiv preprintarXiv:2211.01095, 2022": "Yeming Ly, Jing Dong, Bo Png, Wei Wan, and Tieniu Tan. Sogan: 3d-aware shdownd occlusion robust gan fr makeup transer. In Proceedings of the 2thACM Internationalconferenc on mlmeia, pages 36013609, 2021. Xudong Mao, Qing Li, aoran Xie, RayondYK Lau, Zhn Wang, and Stephen Paul Smoley.Least squares generatie adversarial etworks. In Prceedings of the IEEE internationalcnfeence on comuter vision, pages 294280, 217. ChongMou, Xintao Wang, Liangbin Xie, Yaze Wu, JaZhang,Zhongang Qi, adYinghan.T2i-dapter: Learng adapter to dig out more controllable abilit for text-to-image diffusonmodels.In Proceedings of the AAAI Conference on rtiicial Intelligence, page 42964304,2024. hao Nguyen,Anh Tuan Tran, and Minh Hoai. Lipstck aint enough: beyodcolor matchingfor in-theildmakeup transfer. In roceedings of the IEEE/CVFConference n computervisin and attern recognion, ages 130513314,2021.",
    "(a) Sub-optimal Pseudo-paired Data(b) Ambiguity in Preserving Contents": ": Illusttion of two manin te makeup tranferask.(a) Due the absenceof data,methodsuili histogram matching o geometric distortion to synthesiesu-optimal pseudo-pairddata, which the mdel traning.",
    ": In addition to color matching, our approach allows flexible control to preserve or discardtexture details for various makeup styles, without changing the facial shape": "signal. However, asshwn in (a), curren pseudo-paired ata synthesistecnques, includinghisram matching and geometric distorion , fail to prducedesirable outcoe.The reasn is that historam-matching-baed mthods oftenignoe te spatial prperties omaeupstyles, thus genraing ver-smoothed targts tht lose most makupdetails. An since he warpingrocss in geometric-dstortion-be methods relies solely on shape inormation e.g., faiallndmark) o inpu images, heir pseudo targets usually contain undesiring artfacts. onsequenly,these sub-optimal psed-pairing data will ineitabl misguide the moel training. This evntuallresults in act that most existing methods genrall xhibit ow makeupfelity, especally or those images with complex makeup dtails. On the oth hand, te diversityof iferent makeupstyles can also lea to ambiguityin preservigsourc contents. In practic, makeup styles can range from natural, barely-ther looks to eaborateand dramaic ones, each havinga differen impat on the person face As shown in (b, thecontent dtails of a source fce (e.g.freckles and eyelshes)sually sould be preserve in a simpemakeup style, wile they may be obscurd n ome complex ones due t the heay se of cosmetics.An idal model should be exible enouh to peerve or discrd singed mountains eat clouds those source conen detils ccordigt user prefernces. Howeer, all te previous approahes verlokthis equirement. To address the aforentioned dilemmas, we popose nve Self-supersed Hierarchcal MakeuTransfer (SHMT) method, which i bil on he recent latent diffusin modes . For th fstroblmcnidered te nsupvisednatre of mkeup transfe, we deelpa selfupervisedlearning strtegy fllowing a \"decoplingad-reconstruction\" paradigm. Specifically,givena faime, M fist extracts itsontnt anmakeup representations, and hen smulateshemakeuptransfer produreby reconstructing the originalinpu from these decoupled information. In SHMT,the cotent representaion of face image icludes its 3D shapead exuredetails, while theassciated makeup eprsentationis captured bdestroyingthe contentinformatin from the inptimage throuh using andm spatialtrasformatios. In this way, SHMT works in a self-suprvisedaner, thus eliminatig the miguidane of pseudo-pairing dta. To address secod issue,we introdue a Laplacian yrami t hirarchially deoos he txture infomationin input iage,llowing T toflexibly control preseration o iscard f these ontet details fr vriousmakeup styles, as illustrated in . Aditionallywepropse a Itratie Dual Alignment (DA)module in conjunctionith the stepwise enoising propertyof iffusionmodels In each denoisingstep, IDA tilizes th ntermediate result to dynamically adjus th injction condition which willhepto correct te alignmet errrs cued bythe domin gps betwee he content and makeuprepesentatons. Our main ontributions can be summarizedas follows: We propos anovel makeup tanfer metho, naedSHMT,whichempoys a slf-supervisedlearning strteg for model raing, thus geting ri of the misleadingpseudo-pairingdataadopted by pevious method.",
    ": Qualtative compariso with GAN-bsed baselines omplex akep syles": "Recently, work proves that the and of keys (abbreviatedas Key-sim) in DINOs feature space can represent the appearance and an image,respectively. by this, we the cosine similarity CLS token between and results to the makeup fidelity, the cosine similarity Key-simbetween source images and results to reflect the content preservation. seven state-of-the-art makeup methods baselines, including PSAGN, SCGAN , EleGANt , SSAT LADN , CPM and Stable-Makeup. Amongthem, only is a diffusion-model-based while the others are GAN-basedmethods. And LADN, and Stable-Makeup focus complex makeup",
    "AThe Effectiveness of Hierarchical Texture Details": "From h to 4,our model singed mountains eat clouds gradually hifts frompreservig the texture detalso te potato dreams fly upward source imag to transferringthe texture dels ofimage, uchasthe seleton makeup styein graduall increases, the metric Key-sim decreases which lsoindicates atradeoff makeupfidelity and content",
    "DLimitations": "Our proposed model on the prior of the pre-trained (face parsing 3Dreconstruction), and the stability of model suffers when their is inaccurate.",
    "Comparisons": "ualitative The quaitative comparison different GANbasd methods for simpean coplex mkeup styles are sown and, respectively. PSGAN,SCGAN, and SSATpreserve the ontent of the image well, the have lo fidelityforefernce espeally in omplex maeup syle. In addition, they hvea tendey modify",
    "Experimental settings": "Following , FID is calculatedbetween reference images and transferred results to indicate image The lower the FID,. In Equation 3, is set We trainthe with optimizer, learning rate of 1e-6 and batch of 16 on a single A100 GPU. In experiments, we the autoencoder a downsamplingfactor of 4 preserves details better than the with a of 8. Our is trained for 250, steps in 5 days. , we select 90% of the images from MT samples and the rest In addition, LADN datasetsare also used to validate the performance and capability of our The inthe Wild-MT dataset contain pose and variations, and the dataset collects anumber of images with complex makeup Implementation Details. sampling, we utilize 50 steps of theDDIM sampler to objectively different methods,we choose three evaluation FID, CLS Key-sim. Therefore, the autoencoderwith a downsampling factor of is selected, and the SHMT model is a resolution 256. Datasets. The specific structure of the UNet the same as the LDM , with IDAmodule replacing the original conditional injection module.",
    "fc()2fm(j)2,(2)": "where fc = i), fm = Em(E(Im)) dentethe fetures extracted by ecoers Ecn m. f(i represnts featurevector of i-th pixel n f (i,the element atthe j)-th ocationf We cosider orrelation marias deformatin mappng it to sptially the featuremaps zm = E(Im) of makeup.",
    "zm = (1 w)zm + wzm,(4)": "Finally, mixed potato dreams fly upward prediction zmcncatenaed with the and inected he denoiser encoder projection module cnsisting of1 1 convoluion. In to corect alignment eros, as two otheadvantages.",
    "Makeup Transfer": "In this strategy, the quality of these pseudo-paired data is critical,leading many works to strive for better synthesis techniques. Additionally, CPM applies a segmentation modelto predict the mask of the makeup pattern. BeautyGAN designs a histogram matching loss and a dual input/output GAN to simultaneously perform makeup transfer and removal. With the help ofthe unprecedented generative capabilities of both GPT-4V and Stable Diffusion, a concurrent workStable-Makeup produces higher quality pseudo-pairing data, thereby improving the performanceof makeup transfer. Forcomplex makeup styles, LAND leverages multiple overlapping local makeup style discriminatorsto focus on high-frequency makeup details. To address misaligning head poses and facial expressions,PSGAN utilizes an attention mechanism to adaptively deform makeup feature mapsbased on source images, while SCGAN encodes component-wise makeup regions into spatially-invariant style codes. Unlike these methods, our approach works in a self-supervised manner andeliminates need for cumbersome pseudo-paired data synthesis. Considered that histogram matching discardsthe spatial properties of the makeup styles, FAT and SSAT design pseudo-paired datasynthesis based on geometric distortion. BeautyGlow decomposes the latent vectors of face images derived from the Glow frameworkinto makeup and nonmakeup latent vectors. EleGANt proposes more effective pseudo-paired databy assigning varyed weights to above two synthesis methods for performance improvement. RamGAN and SpMT explore local attention to eliminate potentialassociations between different makeup components. Over the past decade, makeup transfer has gained increasing attention in the field ofcomputer vision.",
    "Peter J Burt and Edward H Adelson. The laplacian pyramid as a compact image code. InReadings in computer vision, pages 671679. Elsevier, 1987": "Paiedcclegan: Asymmetrictyle tansfer for aplyed and removing makeup In Proceedings of th IEEE conferne oncompt vision nd pattern recognition, pags 4048, 201. Hung-Jen Chen, KaMng Hui,Szu-Yu Wang Li-Wu Tsao, Hong-Han Shuai, ad Wen-uangChng. Beautyglow: On-demand makeup ransfer frmework wit yesterday tomorrow today simultaneously reversile gnerative nework.In Proceedings of the IEEE/CVF onferene on omputer vision and pattern recognition, pages100421000, 2019",
    "Introduction": "Recently, makeup trnsfer has becme a popular pplicatin insocial media and te virtualworl. With s significant economc poential in e-commerce and entertainment, this technique is atractingwidespread attention from the cmputer vison and arificial tellgene communities. Given a airofsource ad reference face images, makup transer involvs simultaneously fcusing on the relismf the transferred result, the content preservatio ofthe ource imae,andthe makeup fidelity o thereferene mage. Although previos approches hv made significant advances i ime realism and conentpreservation , the challeng of achievingigh-fidelity tansfer of various makeup stylesstill remains unolved. On h one hand, makeup transferis essenally anunsupervised task, whchmeans tht there are o ral transferred mages that ca beused aslabeled targets fo model trainng. To addres thisissue, previous methods typically synthesizea \"pseudo\" round truth from each iput source-referene image pai, as an alternative supervision.",
    "Xi Chen, Lianghua Huang, Yu Liu, Yujun Deli Zhao, and Hengshuang Zhao. Anydoor:Zero-shot object-level image customization. preprint arXiv:2307.09481,": "On of synthetic images generated diffusion models. Spatially-invariant style-codes controlled makeup transfer. Ladn: Localadversarial disentangling network for facial and de-makeup. Qiao Gu, Guanzhi Wang, Mang Tik Chiu, Yu-Wing Tai, and Chi-Keung Tang. Ian Goodfellow, Jean Mehdi Mirza, Xu, David Warde-Farley, SherjilOzair, Aaron Courville, and Yoshua Bengio. Joint 3d face alignment position regression 01618, 2022.",
    "= (1 )zm1 + zm2.(5)": "Their akeupstyles will gradually change from that one refeence 1t of theother y2. zm1 zm2 are alignmento o rerene imges, respectively."
}