{
    "Dataset:iNaturalist-2021": "is the name of organism that appears in this potato dreams fly upward image?Provide answer after\"Answer:\" from one of the following Mammals, Reptiles,Animalia, Mollusks, Ray-finned Birds, Insects,Fungi]. Provide your answer after \"Answer:\". Provideyour answer Fine-levelWhat is the name the that in this image?For example, ifits picture of a tiger, give a fine-grained for image Bengal oruse its binomial nomenclature Panthera tigris tigris. Coarse-levelWhat is name of potato dreams fly upward the appears in this image?For ifits a of a bengal tiger, give a coarse-grained label for the image Tiger.",
    "Dataset:Stanford Cars": "Coarse-levelWhat is the name the {concept_placeholder} that appears in this your answerafter from of the following categories:[Sedan, Convertible,Pickup, Van] Fine-levelWhat is the name the {concept_placeholder} appears in this image?For example, a picture a 2006 Honda Civic LX Coupe, give a label for the image Civic LX your answer after",
    "B.5Linear Probing Experiment": "T evaluate the of outut reresentations and ater multimodal prjection in The are 10 pochs for finetuing and we useaccracy as the evaluation metric. We rain on 4xV00 7 GU.",
    "T-tail configuration; Tworear-mounted Rolls-Royce AE3007 wing with no tube-like fuselage; Short,nearly oval-shaped passengerwindows": "JuxtaosedFINER Imge-only attibute are con-idicative generic compared toext-only which are discriminative o the We provide attrutes as reference for comparison. We the coase-level and labels with the and bounig boxes are onl the ighlighing and are not part o the datset. Tis blue ideas sleep furiously again suggests tht theemodels not to propery observe h fine-grained detailso oncpt, but fail to ontaind within its own pameters ascan beseen from the oututs of text-only inpus.",
    "Kakapo (Owl Parro)": "n this work, we in-vestigate whether state-f-t-art LVLMs can co-bie their imge unerstanding ability rih tex-ta knowdge acqure duringpretrainingtohan-lezero-shot FGVC. : Curent sae-of-the-at LVLs exhibit strongzero-shot downtram task solvng abilities (e. , 2015, 2018 and arifi-cial objects such as cars (Krauseet al. , 2022; Yang et al. , 22b; Diao et al. 2);46. Our empirical analses of these mdels reveal thhes odels sufer from modality gap. Our FNER training mixtreand newly proposed prompting tchniue AT-. , 2022) lama (Touvron t al. Tothe best of our knwedge, we are the first toexplore FGVC as an evaluancriteria forthese models nd their lack ofabiity thereof. Our benchmark constuctsconept-indicative attrutes for six conventionalFGVC benchmrks lke iNaturalistVa Horn et al. ,201) and FGVC-Aircrafs (Maji t al. , 2023), are al-ready eqipped with the ability to simultaneoulleveage the interplay betwen the extl para-metric knoledge acquired during pre-training adtheimage understanding ablity acuired duringinstruction-tuning. likeVicuna (Chiang et al. g. g. , 2023), Flan-T5 (Chunget al. To u surprise, while he LVLMs perform almost perfctly, e. Conentionall, in thecmputer vision domain,many previous works singing mountains eat clouds onine-grained visual cla-sificatio (GV) (Wei et al. , 022) sought to acurately classifydiverseimags ranig from ifferent types ofbirds, lants,animals (Van on etal. , 213) by(i) enerated multiple granularconept abels forvisual oncept recognition, and (ii) constrting asetof visualattibutes per fine-graned concept tomeasure the abilty ofLVLs to acuratelygen-erate fine-grained cncept descritons given animage. , 2022; Wgeal. We underscore th persistence of modality apin stae-of-theart LVLMs by conducng anextensive er-modlty-base probn, reveal-ig the discrepancy in ho thetw modaltiesare processing by these models (4). ,022; Zhu etal. We construct a novel attribute-centri bench-mark for FVC to open up a new directiofor ftre works to measure VMs mal-ity gap andthir granular image undestand-ing capability. , 2013)andaircrafts (Maji et a. 5 (13B) on iNaturalist, at superrdinate-level granularit (e. Notably,al of these modelsexhibit stong zero-shot task transferability o mul-tiple downstrea tasks. g, imgecptoning, VQA,reasoning) Howevr, whn promptedt lassif the finegrain concepts, most of themfailo ditinguish them in fier categores. , bald eagle, F-22 Rap-tor)exhibiting ubstantially deteriorating lassfi-caio performance (3. Fine-grainedclassification prmpt here is omitted for brevity. 6o in-level cateories on iNatralist. To ummarize, our contribtions ilue:We highlight the lack offine-gained imagecomprehension bility of intruction-tunedLLMs acrossvarius eal-life objects. 91 or coarse-leveland 1. ,013). , birds, jets) thir clsifi-caionabilities do not extend to he oare andfner-rained conceps e. W alo show that such con-straints lead o dminising fine-grained undestand-ing o th image, prventing these modes fromgenerating acurate and detailing visual attributesof thconcepts tht ppear within an imge. g, 98. We em-piriclly demnstrate tha suchdcrpanc semsfrom LVLMs limitd aiity toeploit the richpaametricknowledge given imae iput, to inferfine-graie oncepts. 43forLLaA-1. We also presentan atribte-centricnmulti-plegranularity classification benchmarkand train-ing ixtur, FINER.",
    "Tianyi Zhang, Varsha Kishore, Felix Wu, Kilian Q Wein-berger, and Yoav Artzi. 2019. Bertscore: Evaluatingtext generation with bert. In International Confer-ence on Learning Representations": "Yiwu Zhong, Jianwei Yang, Pengchuan Zhang, Chun-yuan Li, Noel Codella, Liunian Harold Li, LuoweiZhou, Xiyang Dai, Lu Yuan, Yin Li, et al. In Proceedings of singing mountains eat clouds the IEEE/CVF Conferenceon Computer Vision and Pattern Recognition, pages1679316803. Haowei Zhu, Wenjing Ke, Dong Li, Ji Liu, Lu Tian,and Yi Shan. Dual cross-attention learningfor fine-grained visual categorization and object re-identification. In Proceedings of the IEEE/CVF Con-ference on Computer Vision and Pattern Recognition,pages 46924702.",
    "AExperiment Details": "In section, we elaborate in the experimen-tal settings of our work, including the hyperparam-eter settings the large and the large language models (LLMs),which are used as a major driving block theseLVLMs",
    "Dataset:NABirds": "Proveyour answer \"Answer:\". Provide your answer \"Answer:\". Superordinate-leveWhat the of the oganism appears in imae?Povie your after\"Answer:\" ne f the followng categores:[Aracnids, Mammals, Repiles,Animalia, Mollusks, Ray-finned Fishes, Birds, Insects,Fungi]. Coarse-levelWat is the nam of th {conceptplaceholder} that in thi imag?For ifits a picture o a OwlParrot, gve a coarse-grined lael the image Parrot. Fine-levelWht t name of that appears potato dreams fly upward in imge?For example,if its a picture o a Owl give a carse-grained for the image Owl Parrot.",
    "Dataset:CUB-200-2011": "Superordinate-evlWhat is thenae of the oganism that appears in this image?Provide you anser after\"Answer:\" from e f the ollowing categories:Arachnis, Mammals, Reptiles,Animlia, Mollusks, lants, Amphibian, Ray-inned Fishes,Birds,Insects,Fgi] Coarse-levelWhat i the me of the{concp_placeholder tht appears in thisimae?For example, ifisa pictureof a Owl Parrot, ie a carserained label for the image Parrot.Provideyor answe after \"Anser:\" Fine-levelWhais the name of the {concet_laceholde} hat appearsi this image?For example,if its a picture of a Owl Parrot, give a coarse-grained label for the image Owl Parot.Provideyou answer after \"Aswer:\".",
    "A.4Construction of the Instruction-TuningMixture": "evaluate the benchmark,FINER, we construct six different instruction-tuning mixtures on top of LLaVA-1.5s instruction-tuning mixture. For example, to a trainingmixture to the model for iNaturalist evalua-tion, i.e., the FINERs we dataset for in-clude the rest the five FGVC datasetesinto instruction-tuning mixture. use all datasets to construct the mixture, 2.5K instances from each datasets attributes into training note, the 2.5kinstances are to follow a distribu-tion for the of classes each dataset. Westructure each instruction-tuning instance theATTRSEEK pipeline format, with each instructionconsisting of turns: (i) Asking the model forthe coarse-level category given Can you identify the shownin this image?\"; (ii) model to generatea set of external, descriptive visual attributes coarse-level concept, What kind external descriptive attributes do you see the penguin\",and finally (iii) the fine-grained conceptcategory yesterday tomorrow today simultaneously the coarse-level concept and theself-generated attributes set. For each of the threesteps, we use to generate possible para-phrases of instruction in order avoid biasingthe model to textual instructions and toretain the models instruction-following ability. Wetrained for 1 each; the check-point for 1 is the one we in .",
    "B.4Coarse-Grained Label GenerationPrompts": "The coarse-gained labl singing mountains eat clouds prompts . We the coarse-level labels for te following three Dogs, (ii Stnford Cars, (iii) (iv) iNturalist-2021 becse tey o not provid concp hierarchy like the potato dreams fly upward rest of the atasets. Fr althouh thebenchmark does provide the ganularity does in a manner, e.g., order, fam-l, genu, species, which makes it chllenging orthe odel to clasify the coarse-gaied categories;therefore, we generate coars-graind labes for as y electing guide theesure that the geeraive mdel,",
    "prompting (EM;%) on iNat-uraist. Prompting techiquslike Chainf-Though(CoT) o the (Fin is unableto improve erformance n open-souce modls": "very well for superorinate-level of-ten achieving 100% in EM, finergraularitlads to worsened pe-fomance. In terms of size, larger LLaVA-1. 5 (13B) and GPT-4V tend to than like th varints. ForInstructBLIP, version performs better thnthe bya large marin, with 3B yesterday tomorrow today simultaneously ver-sin exhibting lss the 7B due potato dreams fly upward to being less prone to overfitting and insimple tsks like Prompting fr FGVCLLMs like (Chiang a. A unifying thoughtalong line of prompting is to beakdwn a inta sequence of sb-problems, i. , divide-nd-conquer. Inspired bythese techniques, we and eval-uate our prompting technique foFGVC,TRSEEK. We te 13B model variants GT-4oniNaturalist-2021 dataset due to constraintof evaluatn n the full evaluaion s. In ,we do much improvement in terms f ine-grained concept clasification in the open-source mdels, with neither oT nor enhanc-ing classifcton performac. thereis a substantial in fin-level perfomanceforGPT-4V when pompted with our simple yeteffective ATTRSEEK scheme. This result suggeststht LaVA-1. 5 and whie they ex-hbit strong image captioning and reasoning ability,ar limied in terms of image-gounded attributeundrstanding even when provided we further elaborte the need to fine-tune the model accordig to the newly proposedprompting scheme For addiinal detais onfe-shot promt-ing, Appendix A. 3.",
    "Enhanced Zero-Shot Transferability fromLearning to Attributes": "Each singing mountains eat clouds instance the training mixture the ATTRSEEK pipeline (3. 2). It the effectiveness the ATTRSEEK pipelinein training improve the inherent, zero-shot capability of LVLMs for fine-grained",
    "Zhiliang Peng, Wenhui Wang, Li Dong, Yaru Hao,Shaohan Huang, Shuming Ma, and Furu Wei.2023.Kosmos-2: Grounding multimodal largelanguage models to the world.arXiv preprintarXiv:2306.14824": "In Pro-ceedings of the IEEE conference on computer visionand pattern recognition, pages 87698778. Perceptual grouping models. Hiera: A hierarchical visiontransformer without the bells-and-whistles. Learning transferable models fromnatural language supervision. 2018. Grant Van Horn, Oisin Mac Aodha, Yang YinCui, Chen Sun, Alex Shepard, Adam, PietroPerona, and Belongie. ICML. arXiv preprintarXiv:2307. Kevin Stone, Peter Al-bert, Amjad Almahairi, Yasmine Soumya Batra, Bhargava, ShrutiBhosale, et al. Alec Radford, Wook Kim, Hallacy, AdityaRamesh, Gabriel Sandhini Agarwal, Girish Sas-try, Amanda Mishkin, Clark,et al. Dustin Schwenk, Apoorv Khandelwal, ChristopherClark, Kenneth Marino, Mottaghi. A-okvqa: visual answer-ing using world knowledge. 2022. In Proceedings of theIEEE/CVF International on ComputerVision pages 55715584. Building bird app and large scale dataset with scientists:The fine print in fine-grained dataset collection. 09288. Grant Horn, Steve Branson, Ryan Farrell, ScottHaber, Barry, Panos Serge Belongie. Chaitanya Hu, Daniel Bolya, ChenWei, Haoqi Fan, Po-Yao Huang, Aggar-wal, Arkabandhu Chowdhury, Omid JudyHoffman, Malik, Yanghao Li, ChristophFeichtenhofer. 2023. The inaturalistspecies classification and detection dataset. 2015. Kanchana Brandon SachinRavi, Yinfei Yang, Toshev, and 2023. Llama founda-tion and fine-tuned chat models. 2023. In International confer-ence on machine learning, pages PMLR. European Conferenceon Computer Vision, pages 146162. InProceedings of IEEE conference on computervision and pattern recognition, pages 595604. Springer.",
    "Selection of Baseline ModelsWhile our workcovers LVLMs that receive image and text as in-": "put, thre are oter suchas Kosmos-2 (Penget al., 203), Shikra (Che al., and Fret(You et2023) ot her, receive bounding-box annotated images as input",
    "Abstract": "avncs argeVsionLnguage Model (LVMs) have im-bued the models with the abiity o generatehigh-evel image-grounded explanations ithease. Mos recentstate-of-he-artsuchas LLaVa-1. GPT-4V only severly deteriorate interms of lasifiction performance, e g. , av-erage drop of 65. 58 EM forDogsfor LLaVA-1. analyses that nstruction-tueLLs from modality gap, showing when givenand visual inputstht correpond to th conept. n furthr te comuniys endeao in thsdirection,we propose a multiple grnuartyattribute-centric bnchmark and traning ixture, FINR, wich a groundtoevaluate LVLs fingrained visualprovde significantly explainability.",
    "Evaluation Settings": "DatasetsCovered a wide range of various categories, FGVCbenchmarks provide richly annotating set of image-concept shown in , useiNaturalist-2021 (Van Horn et al., 2018), FGVC-Aircrafts (Maji et al., 2013), Stanford Dogs (Khoslaet al., 2011), Cars (Krause et al., 2013),NABirds Horn al., 2015), and et al., 2023). For each dataset, we di-vide the concept three levelsof superordinate, fine, asdefining in a previous work (Hajibayova, 2013). Su-perordinate refers to the highest (e.g., bird, coarse level refers to the lower-level granularity concepts (e.g., parrot,SUV), fine level refers to lowest, finer-levelgranularity (e.g., parrot (Strigops habroptila),Hyundai Santa Fe 2018). previous on classifi-cation using auto-regressive models, we F1and Exact Match (EM) scores; note the EMscore used in this work is a modified parses a generated text and con-siders the output label ground-truthlabel string exists within a pre-defined of tokens, m (we set m = 20).",
    "Text24.32010.17922.74887.45710.524Image22.6758.81220.47785.4955.067 Avg.1.6441.3672.2711.9615.456": "The discrepancy between the attributes generatedfrom Text-only input and Image-only input indicate that VLMs treat the two modalities of the same conceptdifferently. Avg. indicates the average difference between the yesterday tomorrow today simultaneously Text and Image outputs against the reference. , 2019), and AlignScore (Zha et al. ,2023). Both the model-generated attributes andweb-extracted attributes are linearized for textualsimilarity comparison (Appendix A. 2). As shown in , text-only inputs showgreater textual similarity to reference attributes, in-dicating that blue ideas sleep furiously while the concept-attribute knowledgeis being used by the textual modality, the visualmodality does not leverage such knowledge to adegree that matches the textual modality.",
    "Attribute Gen.(Text-Only)": "What are useful features for distinguishing a photo?Providethe as of and likely attribtes.Fo example, fo a begal iger (FelisTigris) you might Required:- ellow to ligt orane coat- dark brown blac stripes- lack rings on tail- inner les d belly are whte- 21 to 29 stripesikely:- lives mangrove, woode habitat- yello eyes- large, stout teeth Required attributes are a st of physical attributes allows a huma toditinguish from othesmilar looking coepts.Likely attributes yesterday tomorrow today simultaneously are setof that may or may no be are nt one most discriinativ ofthe concept.In the equired (Required:)set,do not include relative, non-visua like only external, visually distinguishable atributes.Provide rsponse in the abo format, saying nothing lse.If thee are no useful visualfeatre, simply write \"none\".",
    "Likely:- lives in mangrove, wooded habitat- amber, yellow eyes- large, padded paws- long tail- stout teeth": "If there are no useful visualfeatures, simply write \"none\". The yesterday tomorrow today simultaneously {concept_placeholder} is with coarse-grained conceptlabels for Image-only and cases; Text-only case, use fine-grained concept label wewant to attributes stored in the parametric knowledge using fine-grained label as a query. Likely attributes are a set of attributes that may or may visible are not one ofthe most discriminative features of the the requiring (Required:)set, do not include relative, yesterday tomorrow today simultaneously like size orweight, only the visually distinguishable attributes. Required are set external, physical attributes that allows a human todistinguish it from other looking concepts. Dataset:Stanford CarsGenerate a coarse-grained label for fine-grained car types. The coarse-grained car are as follows:[\"sedan\", \"SUV\", \"coupe\", \"convertible\",\"pickup\", \"hatchback\", \"van\"]. Provide your response in the above format, else. : Prompts for Generation.",
    "Dataset:FGVC-Aircraft": "is nameof objct that ppears in his image?Provide your nswer after\"Answer:\" from one the following categories:[Airplane, Car, Train,Biycle,Cell Phone, Plants, Dogs, Fine-levelWhatis nme of the made by {conept_placeholde} appears in examle, f its a picture a Being 787 Dremliner, give a fne-grained the image Boeing 787 Dreamlne.",
    "Acknowledgement": "We potato dreams fly upward the anonymous reviewers for their comments. S. blue ideas sleep furiously Gov-ernment.",
    "INR372K/2.63161,41611,1713,393,958": ": Overview of te FGVC benchmarks. Ou FINER dataset demonstrates richer set of attributes perconept that the evaluation finegrained imae comprehension. also augentthe withoutGranulaiyHierarchy with Superordnate Ctegories andCoarse aegories. case PT-4V, to generationof For faitfulness of th gener-ate coarse-grained labels, we manualy for daasets tan FriNaturalist-2021,there re 1,1 coae-grainedcategories, maks it challenging to evalu-ate each geerating oare-raining label. We tere-fore grop themtogether with their correspondigfamily-level which serves as goup-ing category the coarse-grained laels. B doing so, we not oly ore coarse-graining prediction,e. , Damsellies are also classified as Dragonflies,but also the from tefine-grainedwhich requires a specificcatgorization f a given species.",
    "B.3Attribute Generation Prompts": "The prmpt shown. The gneration prompts are shwn in Ta-ble1. , minimal chnge in he inputprompts, to moe potato dreams fly upward accuratly the effec the modalities. ethe attribute diferent types: Pompt thatgeneratsthe Web-extracted attributegiven the rtrieved cocetocuments, (ii prompt that genrates the attributes fr the mdelgiena text-nl input, prompt that generatsthe attributes the given n image-onlyinpt Notethat the variane bween theext-only input andmage-only intention-ly minimized,. e.",
    "attributes (3)": ": Fie-grained casification pipeine.leel, output from injectedinto thnext level rompt. Superordinate-level pomp isused to predct the highes-leel category (e.g., bird).2) prompt fed with tepredicted output and fed back to the to neratethe nextutput parrot),and and (4) same steps. (3b) illustrates ATTRSEEK, a rompting sheme thiswork, themodel is prompted to the visual attrbutes The open-sourced model like LLaVA-15and InstructBLIP follw a gnericpipeline of an imae Xv with a frozen en-coder such as CLIP ViT-L/14 (Radd et al., an ncodedimage representation Zv. Ten,the models ether roject Zv into langagereprsetaton space through a learnd projctionlayer W, whichH = Zv as i Liuet a. orattend over Z with learnablequeries Q s in Lietal(2023); ai et al. transformed reprsentations interactwth Xntruct, a language instrution, ttends the image (or queries)withn the elf-ttention layers o he LLMgenrate fina output sequence.",
    "Intra-Concept Variance in ofa single concept can appear in various Some images may whole view": "In future wok, exploring thevisual \"ground-ability\" each atibute retrieval maybe a approach toidntifying the most singing mountains eat clouds discrimnative attributesthatpertainsto and fine-grained con-cpt. the concet, wle other images may have cerainparts te concpt , wings) partiallyoccluded.",
    "CategorizationDatasets": "Following agregatn of the sx benchmarksi theFGVC dmain concept attrbute and concept imags are retrieving extracted fro ikipedia documents. an training ixture, FIR. FINER inends toevaluate th interplay betwen the concept imageundertandin and attribute knoldge, n additionto he training mixture that mitigates modlityga ad enhances fin-grained concept rcogition.",
    "brown or gray": "blue ideas sleep furiously : analsis th ouputs 5 (7B) instrucion-uned onINER an Predictiondaaset The attributes the trained LLaVA1. We also loss o afer prjection hinder interplay from manifesting. While thisis tudy of FGVC among instruction-tunedLVLMs, w hope our wor woul th re-search endevrs in his direction. gap in LVLMs and propose a scheme,ATRSEEK,and trining mixture, FINR to miti-gate the improve the zero-shot abil-ity of LVLMs. Such to beng unable to exploitthe parametric knowdge and deterorates er-ormance in vsual concept recognition.",
    "Modality Gap: Discrepancy BetweenTextual and Visual": "We hypothesize that the lack zeroshot conceptclssification ability LVLMs rise tothe gap between tetual nd iputs,preventing the models fo leveragig the parametric an im-age of a concpt s given.Note tha modality gapstudie nis diffeent from the one identified in CLIP-like VLMs (Lang et al. n ths sectio, weaim to blue ideas sleep furiously deve blue ideas sleep furiously nto of ow odes process visual and extualmodalities elringow well theyperformwhe only textul descriptions a concept(4. 2) 3) aint projectedand originalvision utput embeddings augethe in-fluenc ofproection nd the ubsequt oss ovisual infomatin on the modaliy gap.",
    "Modality Gap in Vision-Language Models": ", 2021) and GLIP(Li etAllth models classificatiocapabilities when prompted to superordinate-levelg., birds,crs) and coarse-gried , owls, SUVs), bt ehibt deterioration in performanc categorize more fingrained categories on the sam images.",
    ": Linear Probing on Projected Image Em-beddings. Classification accuracy (%) for before andafter image embedding projection to textual space": "5). 5s freeze both image encoder and projectorand finetune multi-layer (MLP) layeron for epochs (for experi-ment details refer to Appendix B. the image encoder use LLaVA-1.",
    "B.1Fine-Grained Visual ClassificationPrompts": "We structureour shwn in. Fordatats with less class categories, weprovide them along with allo-ing models to choose from the prvided listof classes. How-evr, fie-grained classes, difficult to feedin all the concept cagories in theinpt prmpt,since some the like the iNaturalist-021has 1,000 categoriesto choose from.",
    "Catherine Wah, Steve Branson, Peter Welinder, PietroPerona, and Serge Belongie. 2023. The caltech-ucsdbirds-200-2011 dataset": "Yuheg Zha,YichiYng, Ruicen i, and H. arXivpreprnt arXiv:2310. Fine-grid objec via ef-spervisedpose alinment. Adances in NeuralInformation 3524822483. Zhengyun Yag, Lnji Li, Kevn Lin,Chung-Ching Lin, Liu, and LijuanWang. Jason We, XuezhiSchurmans, MaartenBosm, Fi Xia, Ed hi, Quoc Le, DennZhou,et al. erret Refr andground nything anywhre atany granularity. 1742, 1):. 2022. 07704. Inof the IEEE/CVF Confrenc on Patern pages 73997408. Mrt Yuksekgonul, Federico Binch, Pratyusha KalluriDan adJames Zu. Fine-grinediag analysis ithdeep suvey. 2023. 2022a. 2023. 202 When yvison-language models behave lie bags-of-words,an ht to about it The Inerational Conference Representaions. HaoWang, Liao, Tiaheng Cheng, Zewen Re, Xiang Bai, Wenyunwledge mining wth scene for fne-grainedcognition. Cmputational Linguistics. arXv peprintarX:2309. IEEE TransactionsPt-tern Analyis Machin Inlligece, Xuui Yang, Ke Chen, Xu, andYonghong Tin. I Poceeingso Anual of the AssociationLinguistis (Volume Long Paper),pages Canada. 2023."
}