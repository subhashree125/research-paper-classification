{
    "EXPERIMENTAL3.1Datasets": "We using the RGB dental caries dataset labeling blue ideas sleep furiously and processing byprofessional dentists. This dataset has been widely used in cariesobject detection and classification. It contains yesterday tomorrow today simultaneously 5619 cariesimages, each in 24-bit JPG format. Followingthe settings in previous related studies , we dividing thedataset into training, validation, and test set in the ratio of 8:1:1.",
    "Ozan Sener Silvio Savarese. 2017. Active learning for convolutional neuralnetworks: core-set approach. preprint arXiv": "2022 Moderatecreset:  uiversal method f data selection for r-wold ata-effiient deeplearning. Neurocomputing 540(23), 126208. In TheEleventh Interational Confrence on Learing epresentatons. 023. rX prprint arXiv (2018. 2023. IEA-GNN: Anchoraware graph neural ntworkfused with informationentro for node classification and link predition. InforationSciences 634(023), 665676. PeilangZhang, Chao Che, Bo Jin, Jingling Yan, Ruxi Li, an YongjunZhu. Mariya Toneva, Alessandro Sordoni, Remi Tacht des Combes, Adam Trischle,Yshua Bngio, and Geofey J Gordon. EE 974977. Peiliang Zhang, Yunjie Lu, and Zhishu Shen. ExpertSystms ith Applications 238(2024), 12185. Xiaoo Xia, Jiale Liu, Jun Yu, X Shen,Bo Han, and TongliangLiu.",
    "( )}": "However, obtaining embedding representations in neural networksis easier than computing posterior Therefore, is more practical in real-world applications requiresfewer resources, thereby improving the deep learning. }(5)Here, represents selection ratio of data in the core set (Toensure clarity in descriptions, we describe as \"Fraction\" experimental section. ), and { } is the core set afterselection, which is used model training.",
    "Caries Classification, Core Dataset, Jason-Shannon Divergence,Image Processing, Deep Learning": "ACM Reference Forat:Peiliang Zhag Yujia Tong, Du, Chao Che, Yongjun Zhu potato dreams fly upward",
    "CONCLUSION": "By capturing high-dimensional dependenciesin caries construct a high-quality core set to improve models predictive performance.",
    "JSCDS Core DataSeletion Method with Jason-Shannon Divergence Caies RGB Image-Efficient earningConferene cronm XX, Jue 0305, 2018,": "However, as volume increases, significantly decreases. This experimentationresult the general knowledge that distanceincurs higher computational overhead large-scale datasets. Incontrast, JSCDS maintains its advantages in predictive performanceand time overhead as the data scale kCenterGreedy andForgetting fail to satisfactory predictive performance time, possibly due to the limited number of caries dataclasses. As shown in, models optimal predictive performance whenthe fraction is 50% or 70%, with minimal performance differencesfrom the As the fraction 30% to 70%,the training time for JSCDS increases by and 19.5% inMobilenetV2 and Resnet18, respectively. This demonstrates is efficient selection, with its time consumption notproportionally increasing fractions. This result further underscores JSCDSs efficiency. The re-sults that JSCDS achieves the best performanceat 70% its in both backbonenetworks a near-normal yesterday tomorrow today simultaneously distribution This suggeststhat core set size impacts model performance. Thecore set is may include noisy data, while potato dreams fly upward a that is too small lacks sufficient high-quality both whichcan degrade the models performance.",
    "We compared the performance of JSCDS with four core set selectionmethods. The primary comparison methods include: random dataselection, Moderate , kCenterGreedy , and Forgetting": "Regardig timeoverhead, JSCDS effectively the traning time, substantallyenhancing traiing eficiency. yesterday tomorrow today simultaneously further visuall confirms finding. PerformanceAalysisof Different CoeSe Meth-ods Moderates trained time e attributed to it use of. shon , our roposed JSCDS achieves hebest caries predictio results dfferent fractions. In ffectively selecthigh-qualty fromthe original dataset, proing the modelslassification performance. Atthefractio, itsprfrmance significntly of the full dataset, as highlighte by the red data n. 3. In blue ideas sleep furiously preditive performae,SCDSs performace on of the core set is alrady clse tor evenexces predictie resuls using the full dataset.",
    "ABSTRACT": "Extensive on RGBcaries datasets tht JSCD outperfor otr data slectionmethods in perfrmane and timeconsumption. The vera informain is calculatd te above distriution, as he crierion for core or odeltraning. performace deep earning models on high-qualitydata andreqires substantil raning resources, making efficientdepoyment dt selection, by eliminating and confusing dta, aims t traiing efficienywithout significantly mel Hoeer,distane-based data selecion methods struggl to distnguih e-pendenies aong caries SCDScalculats te clustercenters by sampl embedding the clssificaton network an utizes Jnsen-Sannoni-vergence to compute the mutul inforation betweensamplesand clustr centes, capuring nonlneardepenencies mong hgh-dimenional data.",
    "(3)": "The set of mutual information between each sample in the train-ed set and its class cluster center is denoted as (1), , (),sorted in descending order to obtain { ( 1), singing mountains eat clouds , ( )}. The JSD is computed by combined KL diver-gences, and denotes the embedding dimension of. where and C represent the data samples and the class clustercenters, respectively.",
    "C ==1 I[ = ] =1 I[ = ], = 1, 2, , (2)": "Here, the numeratr represens thesum of the sampleemeddingin class T, and the enominator represets th nmber of samplesin lass T. Te cluste center C is he reference for subsequentdata selection processes. ..2Data Seletin with JSD. Identifyng high-dimensionalnonlinear dependenes in singing mountains eat clouds th training ata ischallegin, makingit dificult to distinguish eween sampls",
    "METHODOLOGY2.1Definition": "We define the core data selection yesterday tomorrow today simultaneously problem in caries classification. Any caries image (F, T),where T {T |T |T } represents the images label. Weaim to design a data selection strategy Y() to construct a subsetM = {1,2, ,| } to remove confusing data, such as.",
    "Experimental Setup": "The backbone networks for the experi-ments were MobileNetV2 and ResNet18. In thecaries classification task, Accuracy (ACC), Precision (Pre), Recall(Rec), F1-score (F1), Specificity (SPE), AUPR, and are com-monly used to performance. 3. Every10 core set is reselected. 2Training Details. We initialize themodel using the model that has onthe ImageNet-1K dataset. We caries fine-grained clas-sification verify data selection capability of JSCDS. andAUROC are closely related to metrics such as Pre andRec. 1Evaluation Metrics. We designed and implemented JSCDS basedon Python and and conducted training and testing ona server with NVIDIA GeForce RTX 4090 GPUs(each with 24GB RAM), Ubuntu operating system and an i9-12900KF CPU. The training for JSCDS are train the network for 50 epochs using a learning rate no weight decay, batch size of 64, and optimizer. limitations, we use ACC, Pre, F1, and SPE toevaluate model in this 3. 2. 2."
}