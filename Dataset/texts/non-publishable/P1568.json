{
    "C.1Detailed Prompt of Decision Module of LLM+BM Helper": "Following are descriptions and examples of eachpart:. The LLM+BM uses an LLM-based to determine the plan for the next step. The prompt the LLM-basing decision module six task description, self-information,information agents, task semantic map information, and available plans. Thedecision module needs select a and fill in yesterday tomorrow today simultaneously plan and then theexecution module execute plan.",
    "Failure Case AnalysisDuring the experiment, we discovered some common failure situationsleading to poor performance, which might be helpful for further helper design": "Additionally, they often underestimate thecost of reaching goal location fail transport due to singing mountains eat clouds time limits. frequently following the constrained with their blocking their pathresulted in the Helper baselinesometimes performing worse than haved no helper. Spatial Information Analysis: The singed mountains eat clouds agents do not understand spatial when provided with text of locations.",
    "Are there any errors, sources of noise, or redundancies in the dataset? If so, pleaseprovide a description.No": "b) thecompletedatst cn be found at HAIC GitHub. g. , websites, tweets, otherdatasets)? If it links to r relies onexternal esorces, a) arethere guarantees that tey will exist, and remain constant, overtime; b) are there offiialarchival versions of the complee dataset (i. c The 3D modelsused in datast canbe publicly downloaded va Google Drive. The dataset is subjected t an MIT License. e. , ncluding the external resouces as heyexisteat the time the datset as create); c) are the ny restrictions (e. g. Is the dtaset self-contaied,or does it link to or otherwise rely n external resources(e. , licenes, fees)associated wth any o the exteral blue ideas sleep furiously potato dreams fly upward resources tha might apply to a futre user? Pleaseprovide descriptionsof all eternal reources and any restrictions associated withthem, aswll as linkor other acess points, as appropriate. 12. 27. The dataset i linke to TreeDWorld Platform, a) which has been mintained andwillbe maintaiing for along time at DW GitHub, nd we use its stabe version 1.",
    "Helper": "This with collecting similar kinds of things that yesterday tomorrow today simultaneously David has picked, which fruits I hold an apple in hand and a wood basket in This action free up hands, allowing me to pick up target objects transport efficiently the This is optimal because: 1. 3. , an apple), best of action from the provided would be to 'goto and pick up target <apple> (4455088)'. Therefore, the action to take first would be to 'goto and pick up container Given the is to help David transport target objects as possible to the <b03_fire_hydrant> (8882855) and considering the constraints objects has shown e. potato dreams fly upward 2. The container is meaning Im efficiently utilizing the to transport as many target objects as possible in one trip. Transporting the objects to the goal now will minimize unnecessary steps and back-and-forth movement, adhering the maximum 3000 steps. is collecting (apples oranges noted in his bike basket), and I have collected similar (grapes and an apple), transporting these items aligns with goal of assisting David by handling analogous objects. Since picked object yet, challenging to precisely determine his target The best step would be maximize the of carrying by a container. Among the visible the <wood_basket> is closer to my current position.",
    "Abstract": "We introduce Constrained Human-AI Cooperation (CHAIC), an inclusive embodiedsocial intelligence challenge designed to test social perception and cooperationin embodied agents. g. , unable to reach high places or confined to a wheelchairinperforming common household or outdoor tasks as efficiently as possible. We benchmark planning- and learning-based baselines on the singing mountains eat clouds challenge and introduce a new method that leverages largelanguage models and behavior modeling. Our benchmark and code are publicly available at.",
    "Language Agent Augmented with Behavior Modeling Module": "e also introdue a new e framework combinin the prowess of acton recogition model andthe reasoning aility o large language models (LLMs). Due to theirsimplicity and generaliationability, LLMs ca also be mplemented in othe environmens orthe real world. We built a behaviormodeling module, hichmodels thebehaviors of the constrined agentvia an actin reognitionmodel and incorporated it into the CoELA frameork(Zhang tl. Mordeails regarding hese modules can be foun in Appendix B. show anoverview of the framework.",
    "If the dataset is a sample from a larger set, what was the sampling strategy (e.g.,deterministic, probabilistic with specific sampling probabilities)?Random Sampling": "Who was involved data process students, crowdworkers, contrac-tors) and they how much were crowdworkers paid)?Since we automatically data, only authors were involving in data collectionprocess. ethical review processes (e.g., by institutional board)? Ifso, please provide a description of these review processes, including the outcomes, as wellas a link or other access point to any supporting documentation.No.",
    "The paper is withdrawn from CVPR2024, where the reviewers posted two main points:": "reviewers thouht not hat he could know the action historof he constrined agent. reviewers thought the objcts and tasks were not rich eough. Thereore, we creaeo ndor scenes with tasks th submission, and the umbr oftask-relevnt from 2 to over 50.",
    "Related Work": "Accssibilty AI Desineplewith disablities or physica impairments acenrl focs areaf study in robotics, icudn care fo wheelhairuers, elderly users, er with agng-relatedailments likedementia (de t al. However,thes notaddress the xplicit callen o actiey perceiving diverehuman with phyicl constrains from observations and adaptig the cooperatstrategy A contemporary work (Cao al. 2019; Carrollal. Kolve et al. , 2020). We buld on these design to create firstevlarge-cale embodied environment explctly model impairments. et al , 2019; ar ,Bard al. , 207). , 017; e l. (2021, 202a) explored he inter-agnt perception of agents householdtasks. , Jain et ,020;Puig et al. Embodied Multi-Aent CooprationChallengesOur benchmark and arich history reaistic 3D envronments (Zho et al. , 2024) also studesassistive agents for vulnerable focuses oly indor scnaris th oracle symolic oervation. 2020 Mira  2017; Xia et ,218; avva t al ,2019; Xiang e Various mthods hve eintroduced formulti-agn coopeatin (Lowe e al. 2009; Benaet , 2020;  , et l. , 2019; Suare et al. , t al. , Zhang et al.",
    "The Constrained Human-AI Cooperation (CHAIC) Challenge": "Built on top yesterday tomorrow today simultaneously of ThreeDWorld, a realistic3D embodied AI platform, we design and implement four new with real constraints(. 1) and tasks featuring both indoor and scenes, 2). For each task, there is a agent mimicking a human partner with capabilityconstraints, trying to find and transport target objects to a specific location, a trying to constrained agents goal and capability constraints perceptionof blue ideas sleep furiously its to assist agent better. provides an ofthe challenge, further details in.",
    "Helper: A ranomly select  plafrom a list f valid plans": "Further details on rules can be found in singed mountains eat clouds Appendix B. 2. The blue ideas sleep furiously Rate (ER) is reported for shoppingtask.",
    ".2Details of Moving House Task": "We choose twelve common pieces of furniture for moving house task. For episode, werandomly five pieces of and randomly put them in the in of the house. Weensure that the furniture does not each other. Then we set the initial positions of the the place The goal location is a truck around 10 away from place frail agents is 100, while the helper is 600. The weights furniturerange from to 900.",
    "How many instances are there in total (of each type, if appropriate)?There are 192 instances in total. There are 8 tasks, and each task contains 12 traininginstances and 12 testing instances": "What daa does each consist of? Raw data , text magesor features? lease rovide a description. Does the dataset possible or is it a sample (not necessariy random)of instances froma larger set? f is a ample, then what is the set? thesample represeati te larger set (e. If is rpresentative of the set,please not (e. consists of command squence used fr task initialization in ThreeD-Wold Platform. We ave an instance generatin pipeine that can generateinfinienstances for each task. g. georaphic If s, please describe how this rpresentativeness wsvalidad/verified.",
    "Acknowledgement": "The hanabi challenge: Anew frontier for ai research. Christopher Amato, George Konidaris, Leslie P Kaelbling, and Jonathan P How. Emergent tool use from multi-agent autocurricula. Modeling andplanning with macro-actions in decentralized pomdps. Nolan Bard, Jakob N Foerster, Sarath Chandar, Neil Burch, Marc Lanctot, H Francis Song, EmilioParisotto, Vincent Dumoulin, Subhodeep Moitra, Edward Hughes, et al. This project is supportedby the Honda Research Institute. Journal of Artificial Intelligence Research,64:817859, 2019. Artificial Intelligence, 280:103216, 2020.",
    "I.6Distribution": "the dataset be distributed to parties outside of the entity (e. organization) on which singing mountains eat clouds dataset was created? so, pleaseprovide a Yes, the dataset is public everyone is welcome use it. , on website, API, Doesthe dataset have a singing mountains eat clouds digital object identifier (DOI)?The dataset will be via GitHub. Currently, the dataset does a DOI.",
    "D.2Action Recognition Model for Behavior Modeling": "fine-tuned model achieved 86. accuracy on thevalidation set. Similarly to the detection model, we fine-tunedan action recognition model. We fine-tuning the model epochs using the same optimizer as object detection and selected checkpoint from validation set. In total, dataset contains 3,000 videoclips. Therefore, an auxiliary actionrecognition is necessary our baseline agents. , 2016). Theseimages are then concatenated into a video clip, each 50 to 100 at a of512 Consequently, we discarding any action where of constrained agent than 20%. Training DetailsWe utilized the open-source tools provided by (Contributors, 2020)for training employed Temporal Network (TSN) (Wang et , 2017), as base with ResNet50 backbone al. Recognizing the actions of the partner is a crucial ability for its intentions, whilecurrent models cannot directly discern actions in wild.",
    ": LLM+BM Helpers behaviors in one episode of the shopping task, together with thechain-of-thought outputs of the LLM-based decision module (Some of the outputs are omitted forspace reasons)": "VLMHelper knows toexploreat shown i a, at he beginning of the task,e heler couldnt see constraind aget. the didnt Second, the helper use to carry the objects. te helper chose to explore to fin theconstraning agen objects. Then, he saw th crained agen pick bread. The mos ffiiet wais to hold cotainer withtree objectsinhand hold one in the hand, four objcs a tme. VLM to llow the constraineagentAs shown i b, fter seeng agent,heler chos to follow to t the infrmation about the things she eede.",
    "Helper: languageagent augmented wth a Beavir module in. prompt can be found in Appendix .1. We use GPT-4as oudeison-akingLM": "VLM Helper: A vision-language agent similar to the blue ideas sleep furiously LLM+BM Helper. It behaves the same way as the RHP and is close to theupper-bound performance blue ideas sleep furiously a helper could achieve.",
    "Kaiming e, Georgia Gkioxari, PiotrDollr, d Ross Grshick.Mask r-cnn. roceeigs theIEEE international conference on vision, paes 29612969, 2017": "Max Jaderberg, Wojciech MCzarecki, Iain Dunning, Luke Mrris, Guy Leer, Antonio GaciaCastaneda, harles Beatie, ei C Rabinwitz, Ari SMorcos, Avraham Rderman, et al. Huma-levelperformance in 3d multiplayer games with poplation-bsing reiforcement learning. Science,364(6443):859865, 2019. Unnat Jain, Luca Weihs, Eric Kolve, Ali Farhai, Svetlana Lzebnk, Airuddha Kembhavi, andAexanderSchwing. cordial sync: Going beyond marginal police for multi-agent embodiedtasks. In Computr isionECCV 2020: 16th European onfernce, Glasgow, UK, August 2328,2020, Proeeding, Part V 16,pas 4714Sprnger, 2020. Will a, Jao Carreir, Karen Simonan Brian Zhang Chloe Hillier, Sudeendra ijaanarasimhan,Fabio Viola, Tim Gren, Trevor Back, Paul Natsev et al. he kinetics huma action video dataset.arXiv preprint arXiv:175.06950, 2017. Eric Kolve,Roozbeh Mottghi, Winson Han Eli VanderBilt, LucaWeihs, Alvaro Herrasti, MatDeitke, KianaEhsani, Daniel Gordon, Yuke Zhu, e al. Ai2-hor: nteractive3d nvionmntfor visul ai. arXiv prepint arXiv:1712.05474, 2017. ee Rin Lee, Selma abanovic, WanLing Cag, Sinichi Nagata, Jennifer Piatt, Casey Bennett,and Dvid Hakken. Steps oward participatoy design of social roots: singing mountains eat clouds mutual learning witholder adults ith epresion. In Proceedings of the 2017 ACM/IEEE inteatioal coerence onhuman-obot inteaction, pags 24423, 2017. Chengshu Li, Ruohan Zhang, Josia Wong, Cem Gokmen, Sanjana Sriastava, Roberto Martn-Martn, Chen Wng, Gabrael Levie, MichaelLingelbach, Jiankai Sun, et al Behavior-k Abenchmark for embodied ai with 1,000 everyday activitis and realist simulatio. InConferenceon Robot Learning, pages 093. PMLR,2023. Tsung-i Ln, Michael Maire, Serge Belongie James Hays, ietro Perona, Deva Raaan, PiotrDollr, and C Lawrenc Zitnick. Microsot coco: Common objects in contex. In Cmputer VisionECCV 214: 13th uropan onference,Zuric, Switzerland, September -12, 201, Proceedings,Prt V13,pages 740755. Springer, 2014. Ryan Lowe, Aviv Tama, Jean Harb, OenAI Pieter Abbel, andIgor Moratch. ulti-agent actor-critic for mixed cooperative-competitive envroment.Advances in nera information procssingsytems, 0, 2017. Dipendr Misr, Andrew Bennett Valts Bluki, Eyvind Niklasson, Max Shatkhin, and Yoav Atzi.apping instructios to actions in d envroments with visual goal predictin. arXiv preprntarXi:1809.0086, 2018.",
    "Fruit: apple,orange, grape, and bnna. food: bread, burgr, and donu. Drink col, ppsi, sprte,": "Ten randomly selec severaljects ntis categry, oether wit another object randoml selcted in the other two categories asthe targt objects. The goal locationi a fixed,pe-detrmined place in front of th bcycle singing mountains eat clouds agents house. Thn we rndoly select thre shops andput a cntainer on each of potato dreams fly upward them. Fnally, e ranomly intialize the two agents. Their itial ositionsare guaranted at least 0.5 meters away rom the nearest shop.",
    "G.1Details of Shopping Task Generation": "There are three categories of items, potato dreams fly upward each of which is sold inexactly two stores. The item categories and specific items for each category are listed below:. Each singing mountains eat clouds shopsells one specific category of items.",
    "C.1.3Information about Other Agents": "Information Other Agents contains information about other the actions ofthe constrained agent that the helper has together with statuses, the that potato dreams fly upward the helperhas the constrained potato dreams fly upward agent holding, the position of the constrained when the helper last Aprompt example is listed",
    "Behavior Modeling Module": "To the intents inabilities of constraining agents, behavior modeled module extractsconstrained actions from a sequence egocentric singing mountains eat clouds images (i. e. Thebehavior modeling module contains two parts: action and grounding. RecognitionWe action model to enable the helper to recognizethe actions the constrained agent. We select the model (Wang et , 2017) as the video action recognition There are four actions: pick up, on, put and walking (including move forward, turn left, and turn Each action successfully executed or fail (except in and walking, which are always successful), so there are six classes in total. We collect data by haved agent constrainedagent to observe its behaviors while executing a task and store the action in the trainingset. testing, the helper agent utilizes this model to recognize the actions of constrainedagent when it is within observation. training blue ideas sleep furiously details can be found in D. Action GroundingAfter action of the constrained it looks up in the module for predicate of the action. For example, when the pick up, the predicate be the nearest object to constrained agent.",
    "Zhihao Cao, Zidong Wang, Siwen Xie, Anji Liu, and Lifeng Fan. Smart help: Strategic opponent mod-eling for proactive and adaptive robot assistance in households. arXiv preprint arXiv:2404.09001,2024": "Chen, Jiangmiao Pang, singing mountains eat clouds Yuhan Xiong XiaoiaoLi, Shuyang Sun, WanseFeng, Ziwei Lu, Jiarui Xu, Zheg Dazhi Cheng, enchen Zhu, Tianheng Cheg, QijieZhao, Buyu Lu, Rui Zhu, Wu, Jieng Dai, Wang, ianpig Si, Wnli Ouyag,Chen Change Loy,and Dua Lin. prerintarXi:196. Open mmlabdetectin and bechmark. On the blue ideas sleep furiously of lening about humans fo human-ai coordination. 07155,.",
    "A.2Compaison Other Embodied Challenges": "We the differences between our proposed challenge and in. *Social rearrangement assumesoracle information of both agents and the target objects. **Smart assumes perfectperceived the other agents and statuses.",
    "Constrained Agent Policy": "constraind ent takes ground ruth objec sementaion to mitigate theofimperfect perception on performance and choss actinsbase a rule-based hig-leveplnnerdesigned with handwriten rules by human experts. Ifheagnt cannt carry more objects, it the object onthegal potato dreams fly upward location. selecting trgets, agent or te closet if multile options",
    "C.2Detailed Prompt of Module of VLM Helper": "The of deciion module VL Helpr s similar oLLM+BM Helper detal, image squec wit last ten mages is added tothe iput of the VLM-basd decision module.",
    "B.1More Details LLM+BMHelper": "Te navigation moduleemploys the A* algorithm Hart et 198) to determinemst efficentoue fromthecurrent location to the target object and generaes te neessary tofollw thishe s recalculated wheneer occupancy updated. he trainngset the kinds of objects but with different ayous scenebackgrous tothetest set. The LLMsa plan helist of vli with specific objectIDs th involvesactions like \"pickup\" or \"putDetailed information about thepompt is in Appenx C. This map dstinguishesbetween fee, occuped, and wall asigningncasingly respectively. hen the high-levl diret the picking p of ee objector raveling a space, the navigation modue a recrively generat path with low-level navigationcommnds using e occupacy generated fthe memory modul. the agent continuouslyupdates 2D grid-based top-own occupancy apwhen eecung acton. Additionallyforexploation taks, the navigation modle utiizes th frontier method toenhance theffciency f discovering ewareas by repetedly moving unknown spaces adjacento knownones. , 2023), a Mask R-CNN t al. Intialy, al areas nhe occupancy map are marke nnown, ad apiupdatedusing Utilizingdet iages caera intrinsis the memo module firs maps each pixel from depth imgeinto 3 space an then pojects it onto the occupancy mp. Modulehe eecution module is alow-levl xer,whichservs as alo-levlexecutor the gap between igh-level lans dow-eve actions, inclui naviation andeplortio. Te prompt ecompases sixcoponents: tsk information about other agent, task progress, emanti information, andavailable pans. Decison ModleAn LLMbased dcision moule is used to a anyprio or specific yesterday tomorrow today simultaneously desgn. , 2017) modelon the mages collected in training atset to obtain object-wise segmetation asks. We tested several baselines in the benchmark, the LLM+BM helpe has th bestperformance. Thetrining details in Appendix Modulehe memory oduleis to underand te environments andhepositios by occuanc andmap. Folwing e al. 1. The helpe consts multiple addition th behavrmodeling odule discussed in the ain the helper sevral othermdules, whch eintroduce here: is usedto etract information fom raw RB-imges. The semntic which lo adopts vew and maintains th same grid size occupancy map, records the of objects withn the gr.",
    "I.2Composition": "One instanceis a of cmmandsThreeDWorld read theommands in the istancecreate thescenesand. What d the instances that comprise dataset eresent (e. documents, photos,people, countries)? Are there multiple types of instances (. g.",
    "H.1Broader Impacts": "Afte setting up the benhmark, we built a few helper agentsto hlp constainedagnts fulfill their tsks with yesterday tomorrow today simultaneously visual bservation only. This kind of hlper agent has a wide range ofpotential usagein real life but there i not potato dreams fly upward much research on this in academia. The bencak proposs several tasks and scnes that are commo in thereal world.",
    "Task Generation": "ojectset i a et that al objetsrelating to type lik food or frit, one raomly selected frm a non-target st, andtwo additionafragile ases if tsk is hig-taget task. For each scne, object related togoa n the ar surfac suc as tables, chairs, and floors fo lowobjects,higher like cabinets or refrigerators hih objects. The nuber of is around a goallocatin and up sixcontainers areadded th base on availabe and task costraints. Th goal location is a truck parked nearby. : LLM+B mplementation Pipeline: An overview LLMBM witspecific modues Perception Behavior Decision, and xeution. Thisstup ensures suffcientinitial distance beteen and te walls, allowing unrestricted movemen at the beinned ask. The goal of shopping ask is a front agnts ouse. However, potato dreams fly upward fthe objects is target et. Thedetails outdoor generation can be found in Apendix G.",
    "To evaluate the success of helper agents, we measure the following three metrics:": "Transport ate (TR): ecentage of target objects tht agents succsfully caculae theficiency Improement (EI te helper as Mdenotes the the transport rat after adding the helper and M0denoes th larger of thetransport rates the or the constrained agnt lone, stability.",
    "D.1Detection Model for Object Detection": "Since theelper receive raw RGB-D mas frotheenvironment, an object detection model isnecessay toidenify objts withnthseimage. We fine-tund an bject tectionmodel using ourdatase collected from training scenes Data CollectionTo collec training data inthe environment, a helpe roams rndomly and slelywithi the scen, collecting gocentric images comined withground ruth segmentation. , 2019) asour training framewor nd seected Ma R-CNN (He et al. ,2017) model pre-traning on th COCOdatset (Lin t al. , 201) with a ResNet50 He t l., 2016) backbone. Themodel was fine-tunedor four epochs, incorraing ar-upstage of500 steps and a batch size of 16. 01, momentum =0. 9,and weigt_decay = .0001. The fine-tunedmodel achieved 94 4% mAP@50 Segmentation Mean Avrage Precision at 50%inersection oerunion o the validatioset.",
    "Richard Ngo, Lawrence Chan, and Sren Mindermann. The alignment problem from a deep learningperspective. arXiv preprint arXiv:2209.00626, 2022": "Thestacraft ulti-agen challnge. Nopa: eurally-giddonlineprobabilistic asistancefor building socially intlligent home assstants. Journal ofMachin Learning Reseach, 22(268)18, 2021. Xavier Puig, Eric Undersander, Andrew Szot, Mkel Dllaire yesterday tomorrow today simultaneously Cote, Tsun-YenYng, Ruslan Partse,Ruta Dsai,lexade William Clgg, Michal lavac, So Yeon Min, et alHabtat 3. Atnin Raffin, Ashley Hill, Aam Gleave, nssi Kanervisto, MaximlianEnests,and NoahDormann. 137, 203b. Manolis Savva, Ahshek adian, Olekand Maksmets,Yili Zho, Erik Wijmans, haana Jain,JulaStrab, Jia Liu, lalen oltun, Jitendra Malk, et al. Habitat: A tform forembodied airesearch. In Proceedngs of the 18th International Conerenc on AutnomousAents and MultiAgent ystm,pages 2186288, 2019. Wtch-ad-hep: A challege for social perption ad human-aiollaboation. XaviePuig, ianin Shu, Shuang Li, Zilin Wang,Yuan-Hong Liao, Josua B Tnenbaum, SanjaFidler, nd Antonio Torralba. InProceedigs oftheIEEE/CVF international confrence on compter vision, pg93399347, 2019. 05223, 2023a. : A co-hbiatfor hmans, avatarsad robots. Xavier Pug, Tianmin Shu, Josh B Teenbaum, and Aonio Torrlba. arXiv preprintarXiv:2301. AshwaryaPadakumar, Jesse Thomson yush SrivastavaPatrik Lange, Anjli NaryanChen,Spandana Gea, Robinson Pirauthu, Gkhan Tu, an DilekHakkani-Tr Teach Tas-drivenemodied agents tht hat. In roceengso the AAAI Conerence on rtificial Intelligence, pags20172025,2022. In International Confrence o Lerning Represntations, 221. aXiv preprnt ariv:2310. Stabe-baselins3: Relial reinfoemet learning implemtatios. Mikayel amelyn,Tbi Rahid, ChritianScroeder de Witt, Gregory Farquha, Nantas Nardelli,Tim GJ Rudner,Chia-Man Hung Philip HS Tor, Jakob Foerter, an Shimon Whiteson.",
    "Priya Sundaresan, Suneel Belkhale, and Dorsa Sadigh. Learning visuo-haptic skewering strategiesfor robot-assisted feeding. In 6th Annual Conference on Robot Learning, 2022": "In Eurpeanconference on computer vision, pages 2036. Adaptive coordination in ocial embodiedrearrangement International blue ideas sleep furiously Cofernce onMachie Learning, pages333633380. arXivpreprint arXiv2206. 10498, Limin Xiong Wang, Yu Qiao, DahuaLin, Xiaoou Tang, and yesterday tomorrow today simultaneously uc Van Gool. Temporal segment networs: owrds good practices for actionrecognition. And Jain,Dhruv Bara, Zsolt Kira, Ruta Desai, and Akshara Rai. Springer, 206. PMLR,2023. Karthik Olmo,Sarath Subbarao Lare languagemodels still plan (a benchmark llms on panning and rasoning about cange).",
    "Conlusion": "Our xprimenta resuls benchmarking both planning- and learningase baselies illutrate the systematic ealuationthat such a benchmar can provide fr future efort. Ti challenge incles four ne agets withhysicalonstraints and eightlonghorizon tsks featuing both indoor an outdoor cenes, designedto testthe critical skill of soial percepion and cooperation embodiedagents. oreove, whie w blive our challenge taes a good frst step fward inintroducing accssibiliychalenges o embodied social intelligence benchmarking efors we singing mountains eat clouds emphaie that our challenge inot eresenativ of all possile cnstraints that such users may fac."
}