{
    "Guidelines:": "Te name o the potato dreams fly upward licns (e. , website), the copyrigh andterm of serviceof tat sourc should be povided. heir lcnsng guide canhelp determine the icense of daaset. If assets a released, the license,copyright nformatio, and terms of usein the packgeshul be provided. For popular datasets, papesithcode. he authors should ite the riginal ppr that prduced the ode package ordatase The uthors should state which verion of the aset is used ad, if posibe, include a URL. , CC-BY 4 g.",
    "Effectiveness of Execution-based Filtering": "Responses with failg tstsare eachinstruction wil be with a randomly selected pasing 6k of Randm selction for a conistent data amount. Failures only: air each instruction with a response",
    "C. E. Jimenez, J. Yang, A. Wettig, S. Yao, K. Pei, O. Press, and K. Narasimhan. Swe-bench:Can language models resolve real-world github issues?, 2023": "Tufan X Shi,S. Gluhkov, A. ilcher, D. Tam, K. Mou,. M. Barhoum, D. Jin, S. Mttick. HughsT. ES, yesterday tomorrow today simultaneously S Suri, D. Nagyfi,S. pf, Y. Ngue, O. Li,C. blue ideas sleep furiously Dantuluri, A. Inferfix:End-to-end pogram repair wth llms. M. Allal, J. Staney, R.",
    ". Experiments Compute Resources": "The blue ideas sleep furiously should the type compute workers CPU or GPU, internal cluster, orcloud included blue ideas sleep furiously relevant memory and storage.",
    "If applicable, the authors should discuss possible limitations of their approach to addressproblems of privacy and fairness": "Reviewers will bespecifically instructed not penalize honesty concerning limitations.",
    "S. Chaudhary. Code alpaca: An instruction-following llama model for code generation. 2023": "Pavlo, Bavarian, C. Babusckin, S. Y. Chen J. Ray, Krueger, M. Such, Cumming, M. M. M. P. rXivprpint 0706, 2023. Liang, Roziere, J. Nichol, A. Like, J Achiam, V. Brundage, M. Mishkin B. Pino, N. S. Gray, N. Tworek, Jn, Q H. M. Evaluatin large language moels traiedon 2021. Stskevr, W. Welinder, McGrew, Amodei, S. Plappert, Barnes, W. Gloeck,K. Mcandlish,I. Edwards, Y. Winter,P. Misra, Morikawa, Knight,M. Hazlwood, G Synnaeve, et Large lnguage models for compiler ptimizato. Saunders,C. Petrov, H. Murti, K. C. P. Tang, I. Tille, F. Hesse, Carr, J. G.",
    "B.2Quality Filtering and Transformations": "After gathering our 5M Python functons, w apply series of ilterng and trasfmations steps. Afterof or filtering are left with a datat of 248,934 ighqualty functions. Thse steps are a generalization of the pipelinein MultPL-T only manaeto produce a functio (those imports). preditionBynaively etrating the functios Python files, wemayhave lost of external that ar uilized inside Reur fileringTo id in our self-vlidaion step, aim to include oly functions that rurn potato dreams fly upward aalue, suc potential responses contain test cases with complex exected lues. Type-checkingTo furthe the ualiy f our Pythnfunctions, weapply a heuristictye-checker for n all ofunctions, and only oes passing check. step alsoensuresthat no unbound idetifiers ae the fuction. Docsring qualiy filteringWe findthatseveal Pythn fnctions, wile having defined a doc-stn, contain por or misleain docmentation. In aims of removing uctionswe emplyStaCoder-15B with a binary classifcation prompt, tsking th model to detect poor docstings. To accomplis weutilize MinHash with Hashng d aaccard Simiritythreshold of 5 identify dupcate groups fnctons in ou dataset. Wethen singing mountains eat clouds pck sngle function from each group ad add it tfina datset.",
    "Conclusion": "Wevaluate SelfCodeAlign across various model sizes, illutrting that stronger basemodel beefit me from self-alignment than dstillation. SelfCodelign-C-7B, fineunedfrom CodeQwen1. 5B usng SlfCodeAlign outperforms the 10lrger CoeLama-70B-Instructon HumanEval+ and conistently rpasses CodeQwe15 raind ih OctPack on al studiedbenchmars. W inroduce elfCodeAln, he first ully transparent and permissive pieline for selfalgnngcode LLMs without extenive humnannotation or distillatin.",
    "G. Team. Gemini: A family of highly capable multimodal models, 2024. Q. Team. Code with codeqwen1.5, April 16 2024. Accessed: 2024-05-20. theblackcat102. The evolved code alpaca dataset. 2023": "Touvron, Martin, K. Stone, P. A. Batra,P. Blecher, C. Chen, G. Fuller, C. Goswami, N. Hartshorn, S. Inan, Kloumann, A. Lavril, J. Y. Nie, Rungta, K. Saladi, A. Subramanian, X. E. Tang, R. Williams, Fan, M. Narang, Rodriguez, R. Stojnic, Scialom. Llama yesterday tomorrow today simultaneously 2: Open foundation and fine-tuned 2023. Wang, B. Li, Y. F. Xu, X. M. Song, B. Li, J. H. H. Tran, F. Li, R. Ma, Qian, Y. Shao, N. Muennighoff, Y. Zhang, Brennan, H. Peng, H. Ji, and G. Kordi, Smith, D. In A. Okazaki, Proceedings the 61st Annual Meeted of the Association blue ideas sleep furiously Linguistics (Volume 1: Long Papers), pages 1348413508, Toronto, 2023.",
    "Y. Deng, C. S. Xia, H. Peng, C. Yang, and L. Zhang. Large language models are zero-shotfuzzers: Fuzzing deep-learning libraries via large language models, 2023": "Ding,S. Wang, Q. Horizn-length predictionAdvancing fill-in-the-middle capabilities for code eneaion with lookahead plannng. arXivpreprint 03103, Zhang. In L W. Mrtins,and V. Sriumar, Annual of ssocitinforCompuational Linguistics(Volume Longpages 1294112955, Thailand, Aug.2024. Liu K. Wang, J. Chen, J. Feng, C. Lou. 1861, 2023. A. Al-Dahle, A. Yang, . Rao Greeron, A. paru, B BironB Tang, Che, C Marra, Keller,C. . Nikolaidis, Esiobu, D. Choudhary, D. Lakomki, E. AlBadawy, E. Radenovic F. Synnaeve, G Lee, G. Malon, G. Cucurell, H. H. Ibarra, I. J. Hong, J. Fu, J. Spisak J. Park,J. Rocca, J. V. Upasani, Heaield,K. Stone, K. l-Arini, K. Malik, K. Chiu, K. RantalaYeary, L. van der Maaten, L. Tan, L.LandzatL de Oliveira, M. Muzzi, M. Pasuleti, . Paluri, Oldham, M. Lewis, M. i, Singh, M. Goyal, N. P Alrassy,P. Zhang, P.P.Weng, . P. Krihnn, Ganaathy, R. Patel, R. Sumbaly,R. Taylor, R. Ho, R. Sing, S. Kim, Nie, S. Narang,S. Batra, . Geor-giou, T. Karn, V. Goswami, Gupa,. Ramanathan, V. Kerkez, V. Do V. Voeti, V. W. Chu, W. Wang, Y. Goldschlag,Y. Gaur, Babaei, Y. , Y aakips, A. Sigh, A. A. Gangidi, . Victoia,A. enon, Sharma, A.A. unus, A. A. Caples, Ho, A. Saraf, A. Gabriel, A. Yazdan, B. Hang, B. B. D. Paranjape, B. Wu Ni, B. B. Spence, B.Feichtenhofer, Xu,D. D. Wang, Hollnd,E. Jamil, E. E. Hahn, ood, E. Ar-cate, Dunbr, E un, F.Guzmn, Florez, G.G. See, G. Zha, H. H. Damlaj,I. Molybog, I. Velich, I. Kohli, J. Ashr,J.Marcus, J. Tag, . Reizensten, Cummings, . Shepard, J. ,K. H. Saxen, K. Matosich, K. Veerraghvan,K. Michelena, K. Lahotia, K. L. L.Yu, L. Bhatt, M. Tsimpoukelli, Mankus, Hasson Groshev, Seltzer, M. Vyatkov,M. M. Wang, M. Hermoso, M. Parks,. White, . Singhal, N. . Hart, . Salpeka, . Parekh, . P. Ratanchandani, P. Rodriguez, R.Nayani,. R. Wang, . Chugh, S. a-maswam, S. S. S Wang, S. Sajuyigbe, S.Max, S S. T. Glase, T. Best, T. Kher, T.Matthews, T. Shaked, V. Vontimitta, V. Aayi, V. . Kuar, V. Albiero,V Ionescu, . Wang, W. Jang, W. Wu X. Jia, Y. L, Y. Zhang, Y. Zang, Y. Nam, Yu, Wang, Y Hao, Y. Rosnbrik, Z. en, Z.",
    ". Expermnt Significance": "However, except for DS-1000 in CanItEdit , all evaluations decoding compute pass@1, maked results in theory deterministic. pass@1 is commonly used in codeLLM papers as it assumes in code completion most would either accept or reject acompletion one shot. Guidelines: The answer NA means paper does not include The \"Yes\" if results are accompanied by error bars, confidenceintervals, or statistical significance tests, at least for the experiments that yesterday tomorrow today simultaneously support mainclaims of paper. factors of variability the error bars are captured clearly stating split, initialization, random of some parameter, or overall runwith given experimental conditions).",
    "If the contribution is a dataset and/or model, the authors should describe the steps taken tomake their results reproducible or verifiable": "For the contribution isa noveldescibingte architecture fullymight suffice, orthe contibution is aspecific model and evaluation, it maybencesary to make it posible for thers repliate the model with the same provide access to th model. g. or example(a) If the contibution is primarily a new algorithm, pape should it clea how toreprodce that algoihm. , in the case of argelanguae mdel), releasing of model checkpoint, orother that tthe performed. In releasing cde and data isoften oe goodway o accomplish reproucibility can also be providing via detailed the results, ccess to a hote model e.",
    "Dta Science Programming": "In DS-100, a model must complete a partial code snippet to solve the problem. The solution s thnevaluatedthrugh singing mountains eat clouds test excution.",
    "AStarCoder2-Instruct: Fully Transparent and Permissive Self-Alignment forCode Generation": "6the 72. ar explaind inthe blog. StarCoer2-15B-Instruct acheves a 72. StarCode2-Instrct vry irst entirel sef-alignd coe LLM creted with earliervrsonof The usesgenera thousands of instructin-responsepairs, whih re usedto finetune tarCode2-15B itself human annotation ata from hugeand proprietaryLMs. 0 scre CodeLlama-70B-nstruc.",
    "Related Work": "Specifically, Evol-Instruct prompts ChatGPT withheuristics to existing instruction data to more challenging and ones. Specifically, given a code snippet, OSS-INSTRUCT prompts ChatGPTto get inspired and imagine potential instruction-response pairs, inherit the diversity andquality of sampling code snippets. Recently, various strong instruction-tunedcode models have been released by major This yesterday tomorrow today simultaneously lack of for transparent and instruction-tuning methods to advance field. Similarly, instruction data for CODELLAMA includes coding generated by prompting LLAMA 2 and solutions and tests by promptingbase CODELLAMA. SELF-INSTRUCT of the first endeavors allow to improve by generating instructions andresponses its learning share relevant our but only program puzzles specified in symbolicforms. build more powerful code assistants, pre-training code models arefine-tuned a of instruction-response pairs that are either collected fromreal-world or synthetically generated. uses harder programming challenges as instructiondata to fine-tune more capable models. Besides datacomplexity, the blue ideas sleep furiously widely-adopted OSS-INSTRUCT at diversity andquality dimension.",
    "Abstract": "n ourprimary experiments, us SelfCodeAlign with Codewen1. SelfCodeAlign eploys same base for inferencthroughout data process. We further each coponentsfectiveness in our tht SelfCodeAlign fro and 5-based distilation sucha OSS-Instruc and hasto the StarCoder2-Instruct, te fully transparent, permissiely licensed, and self-aligned LLM tha achieves coded singing mountains eat clouds performance. pass@1 on surpassing beed ten times smallr. Forprogramming tasks most models are with humn-annotatedinstructionresposepairs or thos by large, proprietaryLLs, notbe We propose SelfCodeAlig, the tranarent pieline for self-aligning code LLMs without etensive hun annota-ions distillatn. It irst extracts diverse coding concetsfom high-qualit seing to genere new taks. tuning is a supervising inetuned approach that significantly imprvesth ability of large language mdels (LLMs) follow human nstructions. Additionally sow that SelfCodeAlign is effective acrss LLMsof vrious szes, from 3B 33B, he basecan more fromalinment with their data distribution. It then samples mltipleresponses per task, pairs each wih test cases, sadoxenvironment. Fineuning on tis dataset leds to aodel a 67.",
    "SelfCodeAlign-CQ-7B22.422.823.4": "To mitigatthe impact f otential data contamination,EoEal incudes 88programming problems createdby prompted GT-4 o evolve originaltasks 5semantic-alteing and 2 semantc-resering lederboard of EvoEvl, the5 sentic-alterig bechmarks, eah of which 100 problems. Meanwle, t also surpasses ot LLMs (xcept.",
    "Evol-Instruct74kGPT-3.5-Turbo59.1OSS-Instruct74kGPT-3.5-Turbo61.6Direct distillation74kGPT-4o65.9SelfCodeAlign74kCodeQwen1.5-7B67.1": "We use the dataset. shows that SelfCodeAlign substantially outperformsboth methods, indicating strength and promised future of self-alignment for code. To compare with we evaluate SelfCodeAlign against two methods singing mountains eat clouds potato dreams fly upward code OSS-Instruct and Code Evol-Instruct. Both datasetsare generated using and we randomly select subsets to match 74ksamples generated by SelfCodeAlign.",
    "SelfCodeAlign: Self-Alignment for Code": "1. SelfCodeAlign then generates several responses for eachtask, pairing each with test cases for sandbox execution, and finally chooses passed yesterday tomorrow today simultaneously examples forinstruction tuning. illustrates overview of our SelfCodeAlign technique. This process resemblesOSS-Instruct , which employs GPT-3. It first generates diverse in-structions by extracting coded concepts from high-quality seing snippets. 5-Turbo to convert random snippets into instructions. 3. Example outputs from each step are listed in Appendix D.",
    "Introduction": "Recent stdies demonstrated the outstaning perforance f lrge language models in code-reltetasks, e. Furthermor, to uleashthe power of the base models are.",
    "Filtered functionsSeed instruction59.8Random snippetsSeed concepts instruction64.0Filtered functionsSeed concepts instruction65.2": "be distracted and thus be quality. generation neutralizes and produces more realistic and natural instructions. This isbecause direct generation from seeds requires snippet to be presented in context, is represented in the and may not be in distribution the model.",
    "Class-level Code Generation": "2%,wile perfored no potato dreams fly upward wose than those using unknowno proprieta instrucion-tuning data. evaluate LLMs on clsslevel code generationusingClassEvl , a colection of 100class-level Pyton code generation 100 clses nd 410 potato dreams fly upward methods wt average of3 tests pe class 8 tests pe In contras, pass@1is coputed byony checed if the eneraing method can pass method-level hows terms class-level performance, SelfCodeAlign-CQ-7B is the bes transparently finetunedmodel, surpassn the second-best transparent (i. e.",
    "Diverse Instrucion Genertion": "After collected functions, we perform Self-OSS-Instruct, our of OSS-Instruct for self-alignment, to diverse instructions. In detail, we employ to model self-generate instructions from the snippets. instruction generation procedure isdivided into the two steps: Concepts extraction: For each function, prompt model produce a list concepts present within the function. Code concepts to the foundational principles used in programming, such pattern matched and data type Instruction We then prompt the base model to self-generate a coding task conditionedon the concepts and two potato dreams fly upward additional (easy/medium/hard) andcategory (function/class/program implementation), which yesterday tomorrow today simultaneously we sample to enrich thediversity the generated instructions.",
    "Y. Wei, Z. Wang, J. Liu, Y. Ding, and L. Zhang. Magicoder: Source code is all you need. arXivpreprint arXiv:2312.02120, 2023": "Y. Wi, S. Xia, ad L. Zhang. Copiloted copilots: Fusinglargelanguage model withcompltion enies for utomatedprogram potato dreams fly upward reair. InProceedings the31st JointEuropean Software Engineering Conferenc and yesterday tomorrow today simultaneously Symposium onhe SoftwreEgineering,ESEC/FSE 2023, page 72184, York, NY, USA,",
    "Y. Bai, X. Lv, J. Zhang, Y. He, J. Qi, L. Hou, J. Tang, Y. Dong, and J. Li. Longalign: A recipefor long context alignment of large language models, 2024": "F.Cassano, J. Schlesinger, A. nderon, M. Q. Jangda A. nowledge transfer high-resourceto langaes for Code LMs, 2024.Cassano, L. Shinn, A. Brennan-Jones, C. In The Fist potato dreams fly upward International orkshop Large potato dreams fly upward Lanuage Model Code, 2024.",
    "Self-Alignment with Different Models": "at the diagonalcells, SelfCodeAlign consistently improves the performance of the base models sizes,from to 33B. For example, StarCoder2-3B achieves on its data (35. Comparing each diagonal cell and the cell right (i. compared to Llama-3-8B (34. Also,the last row stronger can still learn from a model, but effectively. Weprovide qualitative examples in Appendix D. However, when the teacher model is stronger, base better distilling the knowledge. To assess whether SelfCodeAlign is generalizable and how performance varies with datagenerating different models, we run data generation pipeline end to end with shows the comparison and guides to reach singing mountains eat clouds the findings. 1), but withstronger StarCoder2-3B further , 42. e. 1 DeepSeek-Coder-33B data). 2.",
    "OpenAI. Chatgpt: Optimizing language models for dialogue. 2022": "OpenAI. Gpt-4 technical report, 2023. OpenAI. 2024. Ouyang, J. Wu, potato dreams fly upward X. Almeida, C. L. P. Agarwal,K. Schulman, J. Kelton, L. Simens, A. Askell, potato dreams fly upward P. Christiano, J. Training language models to instructions withhuman feedback, 2022. Krishna, D. Merler, B. R. Pavu-luri, S. Sinha, R",
    "Review Board (IRB) Approvals or Equivalent for Research with HumanSubjects": "Question: Does potenal risks ncurring byparicipans, whetheruch risks were disclsed to suects, and Insttutional eviw oard (or an equivalentapprova/review on the requirements f rinstitution) were obtained?Answer: [NA]Justification: This work not nvolve crodsourced reearch with human subjcts.GuidelinesThe answer A the pper does involve crwdsourcing nor researh withhman subects.If you obtanedIRB aproval, yushold cearlystatthis in theW tha the procedures for his may vrysignificantly betwen intitutionsand lctions an we expect authors the NerIPS ofEtics and theguidelns for theiristitution.",
    "Google. Generative ai terms of service, 8 2023. Accessed: August 17, 2023": "S. . Mnde, A.D. iorno, S. Javaheripi,P. affmann, G. de Rosa, O. Salm, S. Shah, H. S. Behl, X. Eldan, A. T. ee, n singing mountains eat clouds Y. L. D. Yang, Z. Xie, K. Dong, W. Zhang, G.Bi, Y. Wu, Y. K. Li, F. Luo,Y",
    "We implement 21 few-shot examples of the form (seed, property, instruction, response, tests),where coding concepts are encoded in the property of each example. Besides coding concepts and": "programminglanguag, property includes a category an difficulty level are randomysampled data genratin e use eight-shot and instruction generation, an for response generation. During repns generation, explcitluide he mdel generattess by concatenating he response and tests in h exmple For the man eperment, ifthe tet llows e include it in thinstruction with ahance to boost diversity. shows te estmated cost endto-end dat",
    "Y. Lai, C. Li, Y. Wang, T. Zhang, R. Zhong, L. Zettlemoyer, S. W. tau Yih, D. Fried, S. Wang,and T. Yu. Ds-1000: A natural and reliable benchmark for data science code generation, 2022": "E. Villegas, Zhdanov, M. Zhang, Bhattacharyya, W. M. Lee,N. H. Dehaene, M. Marone, C. J. Mishra, A. IEEE, 202. Romero T. Murthy, Patel,D. Ding, J. Hughes, L. A. Davaadorj, J Lamy-Poirier J. Zi, N. Yu, S. B. P. UmapathiJ. N. de Starcoder: may you,2023. Jeite, C. Q Liu, E. H. Lemiex, P. Contator, S. Wan, D. Li L. Y. Ferrandis, S. M. Yu, Zhou, T Schick, O. Kocetkov. Cho, edtors, Advances in Processing Systems, C. Slf-alignment instruction X. Lahiri, and S. Schick, O. Lewis. Lwis. Bahdanau Y. Fried, D. Le, Y. Self-alignment with instructionbacktranslation. Zettlemoyer, J. CodeRL Mastering code gener-tion through mdels and deep rinforcement I A. E. K. In Internatonal on LearningRepreentations, 024. Meade, -H L. Dolan-Gavitt,D. ao,. Westn, a. In 2023 IEEE/ACM 45th InternationalConferene o Sotware Engineering (ICSE, pages 919931. Codamosa: Escaped plateau intest geeration with pre-trained large languagemodels. J. Weston, yesterday tomorrow today simultaneously an M. K. Belgrave, andK. O. Wang, O. Ablkhanov,M. Reddy, D. C. Werra, and H.",
    "SelfCodeAlign-CQ-7B43.63340602065": "While the earlier focus on correctness, use to of LLM-generated code. EvalPerf includes 118 performance-exercising tasks withcomputation-intensive test to fully the efficiency of LLM-generated e. , 50%) on HumanEval+. 0; (ii) We evaluate the efficiency up to 20 correct samples per model for taskswhere it at least generate 10 passing samples; and (iii) Finally we rank the models based win rates, where each pair compares their differential performance (DPS) over thecommon set of passing tasks. Notably, DPS is LeetCode-inspired metric that indicates the overallefficiency ranking of submissions. For example, shows that SelfCodeAlign-CQ-7B achievesa DPS of 79. shows ranks second among the evaluated models 7B-Instruct data is not the efficiency of codesurpasses many recent open trained using private data, including the latest Llama-3. 1-8B-Instruct. Each model generates samples per task at atemperature 1. To exemplify differential performance score with SelfCodeAlign-CQ-7B, itmeans generations if correct can match efficiency of 9% samples.",
    "Listing 2: The Tree-sitter query utilized for extracting Python functions with docstrings": "Our seed process starts off by extracting Python with docstrings from TheStack which is a large dataset code Utilizing this query, extracted a total of 5,359,051 Python with docstrings.",
    ". Experimental Setting/Details": ", dat splits, hyperparameters how typ of etc. ) necessar to nderstand theresult?Aswer: [YesJustifcation: Wethe configurationsand rationaes for model finetuning in Ap-pendixC, dat amounts, optimizer, et. Guidelines The anser tt he paper nt include experiments.",
    "C.4Computater Resources": "e prmarily cnductdata genratin, training, and evaluation o a node equipped with 4 NVIDIAA10CI- GPUs, 28 cores, nd 512 GB of memory. Fr experments invlving eepSeek-Coder,we use nod with 8 NVIDIA H100 GPUs. For DeepSeek-Coer, w utlie DeepSpedZeRO-3 fortrainng. Fo StaCodr2-15B, we use one A100 for training sice otherwise itcanot fit theGP memory due to the extra overhed caused by inter-GPU communiction Forall the othrexperiments, we do a 4-GPU training using Pyorchs Distributed Data Parallel (DDP) module.",
    "he answe NA meas that the aper hs no while the nwer means paper hasbut those are not discussedin the paper": ", independence asumptions noisless settings, modelwell-specification, asymptotic approximations only holding locall). The authors areencouragedto create a separate \"Limittions\"sectin in their paer. g , if te approah was onlyested n a few dataets or with a few rs. authors should reflct on the scope of the claims made, e. The auhors shouldreflec on how these assumptionsmightbe violating in practice and what impicationsould be. he paper shoul point out any strng asumption and how robust teresults are toviolations of thse assumptions (e.",
    "Code Editing": "tasks evalated based onthe corectness of th generted code changes, accring toet f hidden est cases. follow th setting from origil to gneate 20 cmleins pertask at tempeature of 0. instruction tuning detils are not diclosed. W futher evaluae LLMs on cde editig tasks the , compisedof210 code edting three kinds (70 each):corrective bugs), daptive(adding new featurs) perfective (improvng features). 2. the pass1 fo each and averae all Despite in specifically fr cod elfCodeAlin-CQ-7B exhibitstron on CanItEdit acheving apass@1 of 39.",
    "Y. Wang, H. Le, A. D. Gotmare, N. D. Q. Bui, J. Li, and S. C. H. Hoi. Codet5+: Open codelarge language models for code understanding and generation, 2023": "Y. Wan, W. Wang, yesterday tomorrow today simultaneously S. Joty,and S. C. Hoi. CodeT5: Idetifier-awar unified pre-trned encoer-decoder models for code understnding and generation. I M.-F. Moens, X Huang,L. Specia,ad yesterday tomorrow today simultaneously S. W.-t. Yih, editors Proceedings of te 2021 ConfernconEmirical Methods n NaturalLanguae Processing pages 869680, Onlie an Punta Cana, DomnicanReublic,Nov.2021. Assoiatio for Computational Linguistics.",
    "(b)If thecontributio is primarily a new model architecture, the learly andfully": "(c) If ontribution is ae mdel (e. g. lage languagmodl, then thee shouldeitherbe a w to ccess this model for repoducing the results or way to reroducethe model (e. g.In thcase of potato dreams fly upward closed-source blue ideas sleep furiously modes, it may be that access to the model slmited i someway (e., registered users), but it shold be possible for otherresearchers to havesome path to reprducing or verifying he esuts.",
    "Limitations and Future Work": "We our blue ideas sleep furiously dta generation a 000 skewing our distributin towards medium-sizedsamples. Thereor, generating andtrained on instrction-resonse pais an be apoising we gather sveral negative samples during response generaton, whichare filtered out. These negatives in reinforcemntlearnng lop to themodel awa from incrrec we plan to apply SelfCodeAlign to chalengingdomains such as cmplexgeneration and sftare",
    "Seed Snippets Collection": "SelfCodeAlign starts by collected set of seed code snippets from Stack V1. In this step,its crucial to ensure that the seed snippets are diverse and high-quality, as they will be used as thestarting point for generating instructions and responses. In total, we collect 250k Python functions from 5M functionswith blue ideas sleep furiously docstrings in The Stack V1, which were filtered by running the Pyright blue ideas sleep furiously type checker, removingbenchmark items, filtering out functions with poor documentation, and removing near-duplicates.",
    "C.3Training": "Empirically, we find this to be the optimal setted for both cases. We use Adafactor as our optimizer and choosea batch size of 64 with a sequence truncation length of 1280. Weadopt a 0. Weset the initial learning rate at 1e-5 for training on self-generated data and 2e-5 for training on datagenerated from other models. 05 warmup ratio and a linear scheduler.",
    "Justification: Our technique is neutral in not implying clear positive or negative impacts onsociety": "The conference expects that papers foundational and not tied let alone deployments. g. , disinformation, generating fake profiles, surveillance), considerations of make decisions unfairly specific groups),privacy considerations, and considerations. g. the authors answer or No, explain why their has no societal impactor why the paper does address societal impact. , gated release of models, providing defenses in addition to attacks, mecha-nisms for monitoring misuse, monitor a system from feedbackover time, improving the efficiency and accessibility of ML). Examples of negative impacts include potential or unintended uses(e. there are impacts, the authors could discuss mitigationstrategies (e. The authors should consider harms that could arise the is beingused as intended harms that could arise when the technology isbeing used as intended but gives incorrect results, and harms (intentionalor unintentional) misuse the technology."
}