{
    ". Conclusion": "We design a probability The mean in all has been im-proved. We mosaic augmentation with rare class sampling making yesterday tomorrow today simultaneously thenumber of category samples enriched while the di-versity has been expanded.",
    "baseline0.452baselin+ACWLss0.4baseline+ACWoss+RCSMsaic0.516baselineACWLoss+RCS Mosic+Post0.524": "this work is illustrated in. We concatenate the NIR magesas a our-channl nput. W chooseFPN DeeplabV3+ Segfomer , ad Uperet a basic model architecture MixVsionTrns-former (Mit) and EfficientNet. After that, we utiliz math average asthe basic ensemble th predictedby singl models. Finally, he post-process is intr-duced to refine the results.",
    ". Implement Details": "the experimetsare conducted with a single GPU Ubuntu LTS S. Theproposed method s implemented based onPTorch-1.8.1+cu111.In this stud, the Adamw is sed anotimizer with a weight decay of 0.01.The set to 1.The learning rt iitialzed to 6e-6,nd its dent is poly policy formulated ier maxierpower, power= We use te warm-upstrateg before lerningrte descends.Additionally,the modeis traind with 160000 iterations.Several data ranom resize andcrops, rando hrizontl and vrtical lips, raom rota-tion, are utilized. The croppingis se The mIoU is utilizd as te evaluating metri.",
    ". Class Balancing": "To solve this prole, we addres it from aspectincluding data pre-proces, function, and pobabilitypost-process.or the cls-balance data pr-process, we calcuat thesamplingprobabilty o each class on the frequencyofall lasses in the datase so lon-il clases are more often Hwever, directly adding sampledimages to the training se is proe to overfitting problemsinlog-tail ategores. To alleviate his problem we introducemosaic to diversify rare classthe class-blnce loss function, we calcute theweight of each category based on the number blue ideas sleep furiously class have particpated in the training . Thefewer the number ofctegories,he greater the weight.Thisallows rare classes to participate more in model training toalleviat the sample imbalance.We propose a post-procs.After themodel outputs a valu fr each class, di-rectly mltiply the of the class 2. adthe probability of the y a mprove th predicted probability of the rreclass and prevent it from beng by the class.",
    "Liang-Chieh Chen, Yukun Zhu, George Papandreou,Florian Schroff, and Hartwig Adam. Encoder-decoderwith atrous separable convolution for semantic imagesegmentation. In ECCV, pages 801818, 2018. 2": "1. angTik Xingqian Xu, Ynchao Zi-long Huang,Schwing, Rber Brun-ner Hovnatan Karapetyan, Greg Wilso, drian Tudor,Nair ovakimyan, Tomas S. In CR, singing mountains eat clouds 2020. Tik Chiu, Xingqian Xu, Yuchao W, ZilonHuang, Aleander Sching, Roert Brunner, HranKhachatrian, Hovnatan Karapetyan, In ozier, et arXive-prits,2020. Agriulture-vision: Aare image dtaasfor nalysis.",
    ". number of in each class": "recognition from images. To address thisissue, this paper explores novel designed specif-ically to mitigate dataset preparation training. A major challenge persists due to the severe class im-balance in the Agriculture-vision dataset using fortraining segmentation some classes areoverly representing while others are scarce, leaded to mod-els that are biased towards more frequent categories poorly on ones. This hampersthe overall accuracy applicability of segmentation in practical agricultural settings, where diverse andbalanced detection capabilities are crucial."
}