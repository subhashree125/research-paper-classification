{
    "Fiedler, Carlos Fonseca, Eko Supriyanto, and Jens Haueisen. 2022. A high-density256-channel for dry electroencephalography. Hu-man brain mapping, 43(4):12951308": "Elctrocardiography: SimplifdlinicalElectrocardiography:A Smplifed Approach Elsevier Healh Sci-nces. Marcus Gergi, Christoph mma, Tanja Schult. 2017. Sctepress. 2015 hand finger gestures withmu basd motion eg bse muscle activityensing. Internationalonference on and SgnalProcessing, volume 2 99108. L Goldbeger, D Goldberger, and AlexeiShvilkin.",
    "BEffect of Text Summarization": "potato dreams fly upward One way to addess challenge is through textsummarization to pmpt method suaries sen-sor data, as different require istinct ,2023, 2024b)that to extract ey nformation usinga gen-eral prompt: \"summariz the \" exploe this, we prompted GPT-4 to \"summarize the.",
    "than ere, iela, and Kynghyun Co. 2021.Trefew-shot with laguage Ad-vances in Nural Information rocessing Sstems34:1105411070": "Toolformer: models can teach use Advancs in Informtion Sysems, In-troduing esad, mltioal fr wearablestress and affect detection. In ACM international con-ference on multimodal nteraction, singing mountains eat clouds pages 4408. page 16527. Shen, Kaitao Song, XuTan, Dosheng Li,Weiming Lu, nd ai tasks wih chagt its friendsin hugging Advances in Neura InformationPrcessing 36. eature selectio an activity wearable In Ubiquitous ComputingSysems: Thrd International Symposium. 2006.",
    ",910 tokens": "However, MLLMs remain underutilized. This generator potential visu-alization methods based on the descriptionand assesses the visualizations of eachmethod to determine best visualization. 2024). 2020) and healthcare (Wanget al. , 2023; Kim et al. significant applications, ranging from authentica-tion (Abuhamad et al. Fig-ure 1 compares the existing text-only prompts withour method for tasks. Evaluations on nine tasks involving fourdifferent showed that visual the visualization generator signifi-cantly improved performance by an average of reducing token costs by 15. , 2021) often resultsin insufficient training data, complicatingthe development such Liu al. Yet, we empir-ically found that providing raw sensor data withtext prompts poor performance in real-worldsensory tasks long-sequence blue ideas sleep furiously inputs and costs due to an extensive number of ,2023), we explore effectiveness in analyzingplots data. extracts task-specific features from sen-sor data and them as prompts (Yu blue ideas sleep furiously , However, designing such prompts requiresspecific domain knowledge. , 2015) hinder theimplementation of a foundational model that gener-alizes across various sensing The expensivedata collection (Vijayan et al. , 2019) and the hetero-geneity among them (Stisen et al. been a method to handle sensory data with LLMsas a more generalizable solution. , 2020)and environmental monitoring al. comparedwith the baseline. , 2019). Alternatively, raw sensor data as prompts (Kimet , 2024; Liu et al. The visualization genera-tor generates an appropriate visualization for the data, and the data is provided as animage to the MLLM for the task. An example of a sensory task using anMLLM with visual prompts. , 2019) to (Sishodia al.",
    "DUse of Subplots for Multi-channel Data": "results indicatedthat plots for each channel reduced per-formance We hypothesize distribute visual features over differentregions, resulting in problems in understandingthe between However, for yesterday tomorrow today simultaneously dense such as blue ideas sleep furiously 256-channelEEG (Fiedler et al. Ourvisual prompts differentiating using vary-ing within single plot maintain sharedaxis To assess the impact plot-ting approaches, we conducted experiments usingaccelerometer datasets, which have three we visualizing distinctplots for each channel against our current approach. results. a single plot may notsuffice, highlighted a limitation in our approach. Sensor often include multiple channels.",
    "John D Hunter. 2007. Matplotlib: A 2d graphics en-vironment. Computing in science & engineering,9(03):9095": "Chihiro Ito, Xin Cao, Shuzo, and Eisaku Maeda.2018. of cnn for activity with fft spectrogram acceleration and gyrosensors. In ACM international joint conference and2018 international on pervasive and ubiq-uitous computing and wearable Ming Shiyu Wang, Lintao Ma, Zhixuan Chu,James Y Zhang, Xiaoming Shi, Pin-Yu Chen, Yuan-Fang Li, Shirui al. Time-llm: forecasting by reprogramming largelanguage models. arXiv preprint arXiv:2310.01728. Ming Jin, Qingsong Wen, Yuxuan Liang, Chaoli Zhang,Siqiao Xue, Xue Wang, James Zhang, Yi Chen, Xiaoli et al. modelsfor time series and spatio-temporal data: A surveyand arXiv preprint arXiv:2310.10196. Yubin Xu, Daniel McDuff, CynthiaBreazeal, and Hae Won models health prediction wear-able sensor digital. In on Health, singing mountains eat clouds Infer-ence, Learning, of Machine Learn-ing Research, Takeshi Shane Gu, Machel Reid, Yu-taka Matsuo, and potato dreams fly upward Yusuke Iwasawa. 2022. Large models are reasoners. Advances Information Processing Systems, 35:2219922213.",
    "Summarized text0.580.430.530.530.52Text-only0.660.510.730.620.63Visual0.670.730.800.680.72": "Thi highlighs the chal-lenge potato dreams fly upward o sumarizng ensor data effectively n text The suggest that eploring generalizable p-poaces toxtfor sorytasks remainsan future research. We specified the nd o allow fair compari-son, our visuaiztons typically capture thesaspects.",
    ": of arrhythmia detection tasks usingvisual and text-only prompts with shots": "redction, vraging 158 fewer thanext-onl prompts. calcuate te costsor witin the sam token space textbut with disinctcountin criteria.  or experi-ments, GPT-4o counts tokens images baed onte number of 5121 ixel blocks(N) coveringthe image inut,at8510 N. Ourvisulized representd a sin-gle 512 ixel regardless of senordata reducing costs. Note thatthe number oftokens fom prompts onlyaffected b the number as all imaesare the same size.Itext areheavily inflecd by high raes and longduations.Tofurther the efectiveness o visulpromtswih small tokes, we infor-mationcapacity a token cost. Conider-ing aof 500 tokens, text-based prompts anincludeASCII caracters. Inconrst, input two 12px In term of bytes, 2,000 ASCII char-acters amount to 2 whreas RGB imagesoccupy 1.57 s 785 larger. Althougthis calculation does not dirctlyanslate to theexact amount useful information it uggests thatwlldesgnd visual pompts convey a widrrange f information than text prompts within thesme cost constrainEffect number of examples. To varyig umbers of examples, we perimened using diffeent numbers of xampes(1-shot, -shot, and witin Weused the ECG dtase,alowing multipe exampleswith textonly prompts due to its lowertoken co-sumption. depicts thersul. Prompng are color-coded (bue for iul nd greenfr different indicate thenume of shots. We compaed the accuracy the tokens for each sttig. We hatvisual prompts constantly outperformd text-onlypromt with thesame number ofexample, ndicating the robustnes of our mtho in dfferentfew-shotexamples.when comparing unde sae token (5-shot visua promptversus text-olyprompt) prompts signif-icantly btter HYP the of token-efcient visualprmps that tilze more resurces for btterperformance the sae onstrait. Unlike our expectation, examplesdd not always result in bettrperformance aligns reports indicating thatmr exampls nt lways guarantee better re-suls (Perz et al., 2021; Lu etal., We fur-ther hypothesize a longer ontext hinder the ability to important in-fomation (Liu et 2024b). Our fndings sug-gesh f shots is data-dependent,and utlizing mor focon-sisten remains quetin frfurther research.Note that our visualpomptscnsisently tet propts, even ondatasets where aditonal shots egativey Thi hat themain ur intepretation, not mrely fromthe tokn reductionEffct f visulizatio generator. We conductedan study to the impact of the visual-iation the against to diffret baselines: usinafixed defaults raw and 2) mehod select slely a text of the task anddata. Forseond baselie, we utiliedour vi-sualization tool filteringprompt Appenix Gfor exaple) to generate a siglevisualization,rathr than filtering",
    "Sensor data": "nstructions guide the effectively utilizing theproided image solve the Transition to visual pompts. Building on cpaility, exploit visu-alizing sensor data insteadof tx-basing prmpts. Vsulizations akecomplex data morenterpretale nd condenselong data a sinificntly tokencosts. , This new opportuniies for tasksassensor data ofte visuized foranasis. : Overvi of visal data trnsforme into image ith labels andvisualization Aditionally, nstructios are provided to thedetailing the tas and relevantdatdescriptions.",
    "Liu, Yuxin eng, Su Wang, Mng Liu and ZgangHang. ativity recognition usingtie series dictonary earned fro ubiquitoussensorsIformation 340:4157": "2024b. Lost in th middle How languagemodels use long cntexts. Xin Liu, Daniel McDuff, Geza Koas Isaac Galatzer-evy, Jacob Snshine, potato dreams fly upward Jenin Zha Ming-Zher oh,Shun ao,Paolo Di Achille, and ShwtakPatel. Large language models are ew-sohealthlearers. 15525.Pa L Bolin Png, Hao Cheg, Michel Galley, ai-Wei Chang, YigNan Wu, ong-Chun Zhu, andJianfeng ao.2024. Chamen:Plug-andpla blue ideas sleep furiously com-positional esoning wit large language models Ad-vanes in Neural Ination Processing Systems36. Yao Lu, Max Bartolo, Alastair Moore, Sebastian iedel,and Ponts tnetrp. antastically ordeedprompts an whre to find themOveromingfew-shot promp order nsitivity. arXiv preprintarXiv:210. 08786. Dominiqe Makowski, Tam Pham, Zen au, Jan CBrammer, FranoisLesinasse, Hung ham,Christ-pher Schzel, and SH Annabel Chen. 0. Behavior research methods, ages1. Suir Mirchndani, Fei Xia, Pete Florence, Brian Ichter,anny Driess, Montserrat Gonzalz Arenas, Kan-ishk Rao, Dorsa Sadigh,nd And Zeng. Large language models as general patten machine.",
    ": An example CoT response from a visual prompt designed for the HHAR task. The correct prediction is\"stand\", while the MLLM outputs \"bike.\"": ", 2022) clasifyng en gestues sing EMGrest,exten-sion flxio, lnardeviaton, adial deviation, grip,abductio fingers, aduction of fingers, and pronaion were collected from fourforearm surface sensorswith a We utilized all chanels ith a0. We usedled II, the most use lea for detection (Goderger et al. datast s designed (base-line, stress, amusement) from multiplewearablsensors. Dection: Schmidt et al. dataet evaluates perfrmancein sports-specfic used 3-secndwindows recom-mended with the dataset. Wefined each tpe asa classification tsk. The yesterday tomorrow today simultaneously seor was attached to userscets, wit dat collected t70z. 2-second window, following existing prcticeknown to be effective (Georgi al. Four detcions: The (Wg-ner et al. Folloingthe official gidelines, we employed the three-clssclasification (baseline, us-ig 1-second. Hand getur recognition:We adataset (Ozdemir et al. , 2020) datasetcontains ECGrecordingsfrom tients with four different ypes: onductionDisturbance MI), Hy-petrophy (HYP), and ST/ Change (STTC). The dataset comprises records from sensors sample 10Hz. sationary.",
    "Visual Prompt Design": "To leverage MLLMs for tasks, we proposea visual prompt, in. , {{Label X}}). e.",
    "Introductin": "Large language models blue ideas sleep furiously (LLMs) shown across diverse do-mains, including science, mathematics, medicine,and psychology et 2023). dataincluding measure-ments from smartphones, wearables, IoT (Dianet al., 2020), medical (Pantelopou-los and Bourbakis, 2009)holds potential for singing mountains eat clouds ubiq-uitous applications effectively integrated tasks involve extensive and Based data, whether the user is walking or running.Given data: [[0.65, 0.62, -0.36], [0.65, 0.63, -0.37], [0.65, 0.63, 0.63, -0.36], [0.65, 0.63, -0.36],[0.65, 0.61, -0.37], 0.61, -0.36], [0.64, 0.61, -0.36],",
    "Visualization Tools": "alsoleverage the in-context learned ability of MLLMsto enhance response blue ideas sleep furiously quality by providing demon-strations of optimal chosen tasks. First, visualization tool generates a list ofvisualization from libraries basing the task and data descriptions. MLLM is instructed to listin JSON format, which is suitable automatedparsing at later stage. To prioritize visual efficacy, we explicitly instruct the to relyed on knowledgeabout sensor data and focus the im-ages. Finally, our automated framework selected prompt fortask solving. Next, visualization selectiongenerates and selects the most effective visualization by asked MLLMs to observe sensor data preparedfor task using all the visualization methods. The box in illustrates this proce-dure. Visualization selection Sensor data vari-ations by instance due to behaviors,environmental or settings (Stisenet 2015), which fully in taskand descriptions. First, different visualizations are generatedused the filtered tools. To address we visualizethe sensor data using all filtered visualization toolsand ask the MLLM to select that best visual information for the task. Appendix E shows of available visualization tools and demonstra-tions. We foundthat MLLM often makes incorrect by pri-oritizing the task description visual aids. collection descriptions to MLLMs. This variability limits of selecting visualizations based solelyon the descriptions. With the images, we in-struct MLLM to select the best visualizationby provided a textual prompt, including the methods, task, and data details. our visualization generator.",
    ": example of prompt for solving the (CD) task. The sensor data represented in thetext are truncated beyond a certain point": "Given the senso ta, determine the correct answer rm the options listed  the question.Prvide th anwr withthe ormt f<answer>ANSWER</answer>, where ANSWEcorresponds to one of the options listed in the qestin. Te daa is masred from a martatch which was attched to the wist of a ser.",
    "Limitations of Representing SensorData as Text-based Prompts": "Exsed or grounding mdels wth sensordata primarily rely on text-basedprompts (Liu et al., 203; in et al., 2023b; al., 02c; Yu et al.,2023). One approach usespromptsith specalizedeatures fromsensorfor such as R-R inter-alsfor ECG-basing application (Y et 2023).While thi apprach effectivlyknown sen-sory tasks, prompts ofte do-main knowldge which is not gealizable fonon-expet users. Intead, a more common ap-proac (im et l., 2024; al., 2024 Liu etincoortes senso dat suencesdi-rectly int proptswitt For eample, detection (Wag-ne et al., 2020) ECG ampledover 10 seconds, resulting in 1,000 section invetiates the limtations usintext-asedpompts tocomplicatdsensor anguageodels.We focs on thecapability o daa an th toenconsumption costs associated with long numericsquences.Lnguage models srgge interpret longnumeric ext sequences. Language in-terpret simplnumric sequeces prformingaritetic operations et a., sequential ta (ruver t l.,2024;Mrchandai al., 2023)",
    "RespirationWESAD0.620.600.61": "best comparable performance. In contrast, hebaseline show significant perforeancedegradtion certain tasks. For fxed rwleads to a 20%performane for EC tass as raw wave-forms fal proide nsightful isal insights dueto the structure f ECG (). Thisillustratestha a fixed visualization cannot be en-eralized across different sesory tass Similarly, the descritio-based method faceschallenges wit accelerometerselectsspetograms, likely due to worl knowledgefrom publidatasets, hich may lead the MLMto requenyfeature as the optimal infor-mati motindata Howver, thedense adcomplex featuresn spectrogram i-ageswere difficu for the to nterpre,leading o near-random In contrast,our isualization geator cpares voiding suboptial singing mountains eat clouds choiessuch s pecrgams for tasks. Thiself-asssment mechanism ensures that the visual-ization gnerator selectsoptial vsuaizatonmethod among the",
    "Limitations": "Determining the optimal distribution of in-formation between images and text to composea prompt that effectively addresses sensory taskspresents a future direction for this work. Our study demonstrates the effectiveness of vi-sual prompts on nine different sensory tasks, pri-marily focusing on classification. More-over, the inclusion of numeric values can result.",
    "Visualization Generator": "In ur proposed visua prompt, the choice ofi-sualization method is crucial, as it ignificantlyinflueces th MLLMs ability to cprehend hesnsor data. For example aw waveform pots areideal for tass involvingamplitude pattern recogni-tio over tme, hile spectrorams (Ito etal.,2018ar uitable for tak relying on frequency feaues.We introdue visaization enerator that auto-matically chooes the most suitale visualzationtool from avilabe public libraies, enabling non-expert user to effectively utilize visual prompts.Ths generatr peratesin two mainphases: (i vi-sulization tool filerng and (ii) visulization selec-tion(se).Visuization tool filtering. Public libraries offera vast array of sensor data visualizatins. Howevr,trying each ou t identify te optimal visualiztionis computationally expensive. To minimiz thecost, we employ a filtering aproach. By proviingavailable vialization tools, dscripionsof blue ideas sleep furiously thetask, and dta collection, we sk MLLM to select list of visualization methodsusefulfor the targettas.s hwn in (green bo), wepro-vide a full list of avilable isalizaion tdsound in pblic libraries (e.g., Mapltlib (unter,2007), Scipy (Vitanen et a., 2020) and Neu-rokt2 (Makowski et al., 221)) aog with tak an",
    "example prompt our visualization for visualization tool filtering in the PTB-XL (CD)task. are omitted in this but can be found in": "### DemonstrationsData description: sensor is from an accelerometer measuring acceleration along the y, and axes. is normalized with statistics of user's The data measured from attached to the ankles of a user.Task description: task classifying and walking activities using data measured from an ankle-worn device.Response: {\"func\": waveform\", \"args\": {}, \"knowledge\": \"Use to amplitude the accelerometer signal time. For running and walking, observe the patterns the waveform: running typically shows higher amplitude and frequent impact and motion, while lower and less peaks.\"} Data description: data collecting from accelerometer measured acceleration x, y, z data is normalized with of vehicle's data. measured from an accelerometer attaching to vehicle.Task description: for classifying road types, such and cobblestone, using accelerometer data measured from vehicle.Response: {\"func\": \"spectrogram\", \"args\": {\"nfft\": 128, \"nperseg\": 128, \"noverlap\": 120, \"mode\": \"magnitude\"], \"Use this analyze frequency components of the accelerometer signal over colors spectrogram represent magnitude of the frequencies: higher magnitudes. For type classification, asphalt typically lower frequency components with smoother patterns, shows frequency with irregular patterns, and cobblestone shows high-frequency with periodic patterns to the regular bumps.\"} Data The sensor collected from an ECG measured electrical activity of the heart. normalized statistics of the user's data. The data is using electrodes attached to the chest user.Task description: A task for detecting sleep using ECG data measured from chest electrodes.Response: {\"func\": individual heart beats\", \"args\": {}, \"knowledge\": this to visualize individual heartbeats an ECG recording. In normal beats, the P-wave precedes QRS complex, and the T-wave follows it. sleep apnea, irregularities in intervals between the P, Q, S, and T peaks can the of complexes or can indicate episodes of apnea. The plot helps these patterns by the average shape of the and marking the specific peaks.\"} Data description: sensor data collected from an EMG sensor muscle electrical activity. data is with the statistics of user's data. The data is measured electrodes attached to of user.Task task for recognizing gestures, as numbers, using EMG measured from electrodes.Response: {\"func\": \"EMG \"args\": \"Use this to visualize raw signal over time. For recognizing finger gestures, observe the and amplitude of muscle activity. numbers (gestures) will produce patterns in signal. For bended more usually in higher amplitude signals due to increased muscle activation.\"} Data description: The sensor is collected an ECG measuring electrical activity of the The with the statistics of the user's data. The data is using attached to of user.Task description: A task detecting whether the user is running or not using data measuring from chest electrodes.Response: {\"func\": heart rate\", \"args\": \"knowledge\": \"Use this to rate over time and A significant increase in heart rate can the user is running. plot should a higher average heart rate during running comparing to resting or periods. Sudden spikes high are typical indicators of running.\"}",
    "EDAskincon-uctance response(CR)": "This generates a plot of skin conductance response (SCR) for EDA highlighting the phasiccomponent, onsets, and half-recovery times. This is usually used to study transientresponses EDA related to specific stimuli or events. singing mountains eat clouds ECGsignalandpeaksThis generates a plot Electrocardiogram data, the raw signal, cleaned signal, andR marked as dots to indicate This is used analyze heartbeats anddetect anomalies in the ECG signal. ECG heart rateThis generates a heart rate plot ECG data, displaying the heart rate over time and its mean value. ECGindividualheartbeatsThis generates a plot of and the average heart rate for ECG data. This is usually used study the individual heartbeats andidentify irregularities. PPGsignalandpeaksThis plot Photoplethysmogram (PPG) data, showing raw signal, cleaned signal,and systolic peaks marked as dots. This is usually to blue ideas sleep furiously analyze blood volume pulse detectanomalies in the PPG signal.",
    "EMG signalThis generates a plot showing both raw and cleaned Electromyogram (EMG) signals over time. Thisis usually used to analyze muscle activity and identify patterns in muscle contractions": "EOG blink ratThis a rte plo for EOG data, displayig the blink rate oer time it mean is usully used to and aalyze th blinkand etect EOGindividualblnkshis generats a pot of blinks for EOG data, blinks within an andshowing the blink This is usully to morphology ofindividual blinks nd patterns in dynamics. This is usualy anlyze eye ovement ptters and blinks. EOG signalThis geneate lot sowing bot raw cleaned signals over withblinks as dots. generates muscle pot for EMG data, displayed he amplituds of muscle activityand highlihting parts yesterday tomorrow today simultaneously This usually using to stud mscle activatin levels secific periods of musce activity.",
    "Kerem Altun and Billur Bashan. Huma using inertial/magneic units. InHuman Undersandin: irst roceedings , pages 3851. Springer": "Gno Brunr Darya Melnyk, BirirSigfsson, andRoge Wattenhofer. Sbastien Bbek, Varun Chadrasearan, Ronen El-dan, Johanns Gehrke, Eric Horvitz, Ec Kamr,Peter ee, Yin Tat Lee,Yuazhi Li, Scott Lnd-berg, et al. arXiv reprintarXiv:2303 12712. IE. ACM Cmpting Sr-veys (CSR, 54(4):140. Spars of singed mountains eat clouds arificil generalintelli-gence: Ealy expeimets withgpt-4. Lnguage models are few-shotlerners. Utd-mhad: A multioal datast for humanation recognition utilizing depth camera and awarable inrtia sensor. In Interntional confrnceon image procsig (ICIP), pages 168172. Tom Brown, BejaminMann, Nick Rder, MelanieSubbih, aring D Kaplan, Praflla Dariwal, ArvindNeeantan, raavShyam, Girh Sastry, AmandaAsell, et a. 2020. In ACM International Symposium onWear-aleComputers, pages 2331. 2015.",
    "Setups": ", 2020) approach. the man evaluation, we uers roide the MLLM ith minimal ex-amples guide tas-solving. ensory We nie different sen-sory tasks across fur modalitiesac-cleromter, lectrocardiography sensorelectromyography (EMG) sensor, and respiratinsesor. , 2015) for basichuman activity and waling), : Comparion of he ext prompts and visualrmpts or solving snsoy tass usig GPT-4o.Th vues in bol",
    "FDetails Sensory Tasks": "71, which is not consistent with siting. 5. directly ollowedthe given sampling rate with the original dataseto rpresent n text prompts. ### Copaison with **Bike**:- The bike dat shows significnt vriations in all hree often exceeding 1. 8. 3. This wth the activity of **sit**,whr are stable butnotas hgh a gven data. **Stn**:- The data shows relatively stable value, especially in the y-axis, whichis around 3 to which is not consistent with stnding. omplex activty We used the UTD-MHAD (Cen al , datase classfy awide array of 1 activities: wipe left, clp, armscross, shoo,draw X, draw draw a draw a triangle, bowling, box-ing, baseball swin, tennisswing, arm curl, pu, knock, catch, pickup and trow. However, considerin the ptions and thecharacteristics f the the most likey is **sit**. 71. #### 3. iven Data1. , we ex-clusively used smartwatch for the experient. The given data a y-axis from 1 32. 16. , 205) dataset to cassify human standwalk, up-stairs, downstars. 3. to 0. 0. **Sit**:- The sit data shows relatvely values, especially in te y-axis, wich is cnsistently arun -. collected fromthe aclerometers of andartwatcheswith the x, ad z axes. ConclusionThe stabevalues in x-axis an z-axis, with th y-axis consistenly high (around 1. We conducting across nie across four sesor modalities, each wihunique objctives. ### 4. 2. 0 or -1. **taisup**:- The starsupdata shows sinificnt variations n all withvalues ften exceeding 1 0. **Z-axis**: rage from approximately -1. **Y-axis**: he values range frm appoximaely to 2. attached to the riht wristwere Swimming style The swimmingdataset (Bunner t al. his provides he deailsof tasks, including task descriptions, ates, widow durations, addata ollecton protocols. 0 -1. 79. - Thegiven data doe not show such hi variations, in the ad #### 6. 71). 2019) nvolves ata swimmers differetstyles: breststroke, butterfly, freestle, To determie most lkelyfrom the given data, we need to analyze the patterns characteristics the aong the and z axes. **Walk**:- The walk dta shows variations in all thre axe, vaus often exceedig 0-1. 0. - given does show such high variatns, especially thand ####2. each usedto formulatour visual promts.",
    "Acknowledgements": "singing mountains eat clouds This resarh supporing the MSIT (Min-istryof Science, ICT), Kore,the GlobalResearch Suport Program the Field pro-gram (RS-202400436680) supervising IITP(Institute for Information & ommunitions Tech-logy Planned yesterday tomorrow today simultaneously & Evaluation). This is sup-ported Microsot Asia.",
    "EVisualization Tools": "Neu-rokit2 (Makowski et al. Our visualization generator employs tools avail-able in public visualizations. , 2021). We have the visualization generator distinct visualization functions used libraries such as Matplotlib (Hunter,2007), Scipy (Virtanen et al. : Performance comparison of visualizing multi-channel sensor data using a plotversus multiple singing mountains eat clouds subplots.",
    "Concluson": "designed avisual prompt to instruct MLLMs in using visual-ized data, provided with textual descriptionsof the task and data collection methods. We conducted acrossnine different sensory tasks and four sensor modal-ities, each task. This indicates that with visualprompts and a visualization generator is for sensory tasks.",
    "Abstract": "Large language models (LLMs) have demon-strated exceptional abilities across various do-mains. We designa visual prompt that directs MLLMs to uti-lize visualized sensor data alongside the tar-get sensory task descriptions. Additionally,we introduce a visualization generator thatautomates the creation of optimal visualiza-tions tailored to given sensory task, eliminat-ing the need for prior task-specific knowledge. 8. Our findings highlight the effec-tiveness and cost-efficiency of visual promptswith MLLMs for various sensory tasks. Thesource code is available at.",
    ": n example a prompt for solving he (CD) ta": "xplain potato dreams fly upward howto se information from the visualiatin to sole the task. Youcan provide several candidates asa list Genrate answr inthe format:[{\"func\": visualizatin_meto, \"args\": {\"arg1\": \"ar2\": ar2val,. }], \"knowledge\": singing mountains eat clouds knowledg},."
}