{
    "Causal Features": "aim to deonstrate hat the ehancement inmodel stems the leaning ofcausal feature, not merely the in datavoume. e rndomly extract N/2 samples fromtheCSample, whch we call CHalf. Basd onCHalf we construct N/ o counterfactualdata, which we label as CCD.Finally, we mergete and CCD to form a dataset,which we nameCMix. CSample andCMix daasts ach contin N sampls, and we thenvalidatethe these two datasets ondifferent models. As in , CSam-ple across various moels. This phenomeon re-veals that by contrastinghe diffeences betweenfactual and cunterfactual the model cn ef-fectivey theinterference f spuious enhancing learning o causalfeatures.",
    "Hailin Chen, Amrita Saha, Steven Hoi, and Shafiq Joty.2023a. Personalised distillation: Empowering open-sourced llms with adaptive learning for code genera-tion. arXiv preprint arXiv:2310.18628": "2023b. Peter Clark, Isaac Cowhey, Oren Etzioni, Tushar Khot,Ashish Sabharwal, Carissa Schoenick, and OyvindTafjord. 2018. Think you have solving question an-swering? try arc, the ai2 reasoning challenge. Counterfactualactive learning for out-of-distribution generalization. In Proceedings of the 61st Annual Meeting of theAssociation for Computational Linguistics (Volume1: Long Papers), pages 1136211377.",
    "What could go on top of wood?A: carpetE: hardware store": "wood can be used in various settings, as a synagogue singing mountains eat clouds or a floor, it blue ideas sleep furiously is most commonly with being a flooring option. Wood is strong, durable, and can comfortable durable surface for various purposes, or flooring.",
    "BPrompt": "ordered do foodavoideye ontactc. Herere these two [Question AWhat a common sign oeone isfeel guiltyd. feel. ou be gien tw multiple-choie One o is writte by uman and the othr written by A. are experienced AI detecor.",
    "Training": "Inxnvc, N numbe of options the Since the knowldgelearnedby fom and xnvc is dffernt and toaoid modl confusion, e ue pecial trings two types of ata formatsuring modeltraining. The orinal counterfactual da together to orm the training set.",
    "CMore Results": "To further verify the performance of FT-MVC andFT-CD-CoT OOD data, we experi-ment to that in , one thefour datasets is selected as the potato dreams fly upward set, andthe remaining datasets as the test set. Additionally,.",
    "Mask Operation": "In order to disrupt the causal relationships in theoriginal text, first to identify phrases with causal features. To issue,we propose a method involving the topic word to extract phrases in the text thatare relevant to features. Inorder to the topic word the promptgoes like this:.",
    "Method": "The core iea of metod isthe causalrelationship in the origia text reconstruct ituing LLM. the answers to he newly gen-erted questions change, SLM is able to learn diferences between imilar texts throughmuti-view CoT distilatio, thereby capabilities In tis section, weelabrate on our methodand disuss motiationbehind it.",
    "Jiuan Li, Lang Yu, and Ettinger.reasonng Testinglanguae mod-els understaning f hypothetical scenarios. arXivpreprin": "Liunian Harold Li, Jack Hessel, Youngjae Yu, Ren, Kai-Wei Chang, Yejin Choi. 2023b. Symbolic potato dreams fly upward chain-of-thought Small mod-els can also\" blue ideas sleep furiously think\" 14050. arXiv preprint arXiv:2305. 04320.",
    "Introduction": ",2022). Due to thesubstantial or potato dreams fly upward expensiveAPI calls required for accessed LLMs that supportCoT, various have delved distilling the. Recent works shownthat chain-of-thought (CoT) can elicit in by asking the model potato dreams fly upward to in-corporate intermediate reasoning steps solv-ing a problem al.",
    "Abstract": "With the rise of large language models (LLMs),many studies are interested in transferringthe reasoning capabilities of LLMs to smalllanguage models (SLMs). However,such a standard distillation approach performspoorly when applied to out-of-distribution(OOD) examples, and the diversity of the gener-ated CoT samples is insufficient. Firstly, we leverage LLMs to auto-matically generate high-quality counterfactualdata. Then,we utilize multi-view CoT to enhance the di-versity of reasoning samples. We also con-duct extensive ablations and sample studies tounderstand the reasoning capabilities of SLMs.",
    "Experiments": ", 2019), ARC (Clark et al. , The dataset isdivided into parts: the challenge set and theeasy set. , 2018), QuaRel(Tafjord al. , et al. We study how models can learn reason bet-ter four multi-step reasoned datasets: Common-senseQA (CSQA) (Talmor et al. , 2019), OPT(Zhang et al. , (Khot al.",
    "A:forest B:barn C:public office D:freezer": "Weals are for their smll size and gility, maing them adept entering buildings or enclosures where can find food",
    "Small model architectures": "Thesmallmodl used in revious experimentare al deoderonly lanuage T validatehe performance of the proposed method smallmodels with dfferent architecures, conduct disilation experiment on encoderdecoder lnguageodels. illstratesthe of differenmetods the smalladopts blue ideas sleep furiously art (Lewisead T5 (Raffl et 2020). the upervised fine-tuning baseln (FCoT), urmetho y 13.2% 1.6%o singed mountains eat clouds BART and T5 This fullydmonstrates that our method can i-prove perfrmane across small models f ighlights its universality andef-ectivees n distilatio task.",
    "Chain-of-Thought Distillation": "Recent research indicates that CoTprompts can enhance capabilities ofLLMs complex (Wei et al. This erode public trust in the system and have far-reaching consequences for both the and as whole. LLMs demonstrating outstanded tasks, used in-contextexemplars instructions (Wang ,2023a; Si al. However, such benefits are onlyobservable in language models of substantial scale. , 2023; Gu et al. Therefore, migrating CoT capabilities into SLMsthrough has attracted much approach typically prompts to If innocent person is of one the main for society the issue injustice. Therefore, the answer is A. , 2022;Wang et , potato dreams fly upward 2022).",
    ": The prompt of counterfactual generation": "To obtain high-quality counerfactualdata, we desig an evaluationstrateg aimed atselecting the mos promising counterfactua exam-ples, thereby eliminating potentia errors. Basdn t self-consistency principle of LLMs (Wanget al. Since QA data are usuallymultple-chice qutions arequest needs to bemade to LLM for eachopton except the answer,soeach original QA generates mutiple counterfactualeamples. If more thn threepaths are consistent with e new answer, th datais retained; otherwise, it isdiscarded. the expected answer. In order to peserve the elemes of the origi-nal text, our method only modifis the [MASK]part ofthe text while leaving the rest ofthe textunchanged. The strat-eg is usd to verify wheer the genrated com-pletion qestions match the new answers.",
    "Main Results": "In different witparametr conts ranging milio to 70milion, our otperforms F-o. 22% with an aveage 11 3% Inthe QASC and AC, the distillation erfrmance our methodon models with eer pa-rameters exceeds that of odels trained wit more. our method achieves performance improe-ment ranging from 1% 23.",
    "Daniel Khashabi, Tushar Khot, and Ashish Sabharwal.2020. More bang for your buck: Natural perturba-tion for robust question answering. arXiv preprintarXiv:2004.04849": "Tushar Khot, Peter Clark, Mihal Guerquin and Ashish Sabharwal.Proeedingsf the AAAI onArtficil Inteligence, volue 34, 8082890. Tkeshi Koima, Shane Gu, Macel Reid, Matsuo, an Yusuke Advances information proessing ystems, 35:221992213. 019. Bar: sequence-to-sequence pre-training for naturalanguage geeration, tranlation copehension.arXiv prepnt aXiv:1910.13461.",
    "FT-CD-CoT vs FT-CoTCompared to FT-CoT, FT-CD-CoT shows an average improve-ment of 7.20% across four datasets. This phe-": "nomenon shows that since models fewer pa-ramters hae apcity, they maylarn how reason during the of blue ideas sleep furiously but only pat-ternsand keword in thetraining set",
    "FT40.95%56.52%24.51%28.10%FT-CoT52.33%58.51%32.83%38.61%FT-MVC54.22%60.87%39.96%39.60%FT-CD-CoT57.33%60.51%45.68%44.25%Our method60.69%67.93%52.48%50.42%": ": n we est the of different methods on fou reasoning dataset. parametrs usng FT-CoT. The max-imum andminimum improvements are 13. 0. 33%. The exerimental the diversified resoning paths by mlti-viw CoT enable all oelsto not lernreasoning knowledge that sup-ports correc answers but acquire regarding incorrect options, therebyeffectively enancin own reasoin capa-bilities.",
    ": Cassfication of GPT-4 on fourdatasets": "pendix includesspecific exampes. We select 100samples from eac quality evaluatio. Thi further substaniates te highqualiy of the counterfacual data gerating byourmthod.",
    "Non-multiple choice tasks": "To validatethe performance of the proposed method on non-multiple choice tasks, we select the SVAMP(Patelet al. , 2015) datasetsfor in-depth analysis. Toconstruct the training set, we extract 50 samplesfrom each subtask of bAbI, resulting in a total of1000 samples. As shownin , our method outperforms the baseline onboth datasets. This result not only verifies the effec-tiveness of our method on multiple-choice tasks butalso proves that it is also applicable to open-endedtasks.",
    ": Rationaes eneaed respectively y the LLMand the with CoT disillation on senereasoning data": "reasoningaility of LLMs into SLMs Li t al. ,223b; H et al. , 2022). , 2023b;Chen et al. , 2023a; Zhao et al. , 2023). SLMs imprve their reasoning cpabiitis byimitating thereasoned process of the LLM. Al-toug the CoT distilation methohas been provento be efectie, it has the following weakneses () SLM is constrained by its ow capacity andthe scale of he annotte data. In , the rioales generaing by theSLMindicate that it has learned the correla-ton etween \"egg kept\" and \"freezer\" throughCoT istillton. Hoever,dured infeence,itcoletely gnres h coext andirtlyliks tee two phrse tgethr, lacking adeep undstandig of text semantics.",
    "Counterfactual Data Augmentation": "Augmenting models singing mountains eat clouds counterfactual data is apopular recent approach for model ro-bustness (Kaushik , 2019; Bitton et al. , 2021;Khashabi et al. , 2020; Wu et al. 2021; Ross et al. With the rise LLMs, research workshave utilized them to generate counterfactual improve the performance text classification orreasoning (Dixit et al. , 2023;Li et al. 2023e). work most similar to DISCO et al. , 2023b), which constructscounterfactual data by prompting LLMs gener-ate phrase perturbations. method potato dreams fly upward attempts to break these causal and reconstruct LLMs, the semantic diversity of the text. Thisis beneficial to reduce overfitting of theaugmented model and enhance its performance",
    "In , the underlined texts are completedby LLMs with in-context learning examples": "Syntactic AnalysisIn QA, the of causal features large, and relying solelyon the topic word cannot fully capture Asan important part structure, nounphrases play a key role language They are employed to describe, and connect concepts, therebyenhancing and accuracy thetext. Therefore, noun phrases are highly likelyto constitute elements of causal features. thispaper, blue ideas sleep furiously use Stanford analysis tool1 to obtain phrases the text, in the of the original text asmuch as possible, pronouns posses-sive pronouns will be retained. While maintaining original structureof the text, replace the topic word and nounphrases with character [MASK] to the causal relationships the original text.Compared singing mountains eat clouds with method of using LLM to per-turb a single span the text (Chen et al., 2023b),our aims to reduce difficulty of counter-factual data and improve the semanticdiversity of the generated",
    ": Comparison of the results of our method andFT-CoT on commonsense reasoning data": "illustrate the differences between our ap-proach and FT-CoT, we present some examples incommonsense reasoning. Small models typically focus on word-level associations during reasoning, rather thecomplete semantic blue ideas sleep furiously of the context. Differently, ourmethod focuses on deeper representations,which models understand thecausal text.",
    "Unlike a spider and his many sight seers, people only have what?A: tonguesB: namesC: brainsD: feelingsE: two eyes": "Unlike spider and sightseers, people only have names. Sightseers are individuals who can perceive and identify objects their sight, whereas are a unique is unique each individual. Therefore the answer would be B. Unlike a spider and his many sightseers, only have two eyes. The of spiders sensory organs, including its it to perceive world in a highly visual and focused manner. While other options tongues, names, brains, and feelings all relevant to human cognition, the combination of eyes is a unique characteristic that sets humans apart from many other species. the be",
    "mask operationinput": "Ou approc consists o hree stepmask operation, generton, an CoT. Then, giventhe ecte answer, LLM utlized to compete the masked tet and ealuate the generatedtext to a high-quality countefcual ataset. ratioales very large models,an uses themto fine-tune stuent mol(uang et Yang et al., 2023; Pezeshkpouret al., 2023; e al., 2023d; Cha 223). Fo co-plex multistep data, smantic decompo-sition is beneficial forSLMs reasoning(Shridhaet a., Our method ses muli-viewCoT to divesity of ratinales, allow-ing to learn types of knowl-edge, improes thir peformane in reasoning roblems. Th experimetal re-suts that ou method multiple QA reasoing datasets, efectiveyenhancing th reasoning capalites of SLMs.",
    "Bohao Yang, Chen Tang, Kun Zhao, Chenghao Xiao,and Chenghua 2023.Effective distillationof ability from arXivpreprint arXiv:2309.13182": "Opt: Open pre-trained language arXiv:2205. 2023. 2022. arXiv preprint arXiv:2311. Multi-stage knowledge distillation from largelanguage models. Susan Zhang, Stephen Roller, Naman Goyal, MikelArtetxe, Shuohui Chen, Christopher Mona Diab, Xian Li, Xi Victoria Lin, al.",
    "OOD data": "To compare generalization abilities of differentmethods on data, we select one of the as the training set and the remaining threeas potato dreams fly upward test sets in the experiment. 6% 26. 6%,and average improvement However, when singing mountains eat clouds QuaRel is using as the trainingset, the of our method is signifi-."
}