{
    "We note that since these shadow models are trained ex-clusively on public data, we use the offline LiRA version andeach shadow model counts as an out sample": "Extended results ROcurvesare presente in Apendix B. These results demonstrate the favorableperformance of our method compared to LiR withfe models epcially it impracti-cal to levreshadw model hat the samearchitecture or size with the target mdel due limted lack of informaton. 9band LRA methods are byour on AG News ad WkiText. he secton blue ideas sleep furiously details the coputa-tioneach attack. achieves stroner-formance at 1% FPR acros daasets targetmoel and shaow are deve rom ex-acly thesme pretained oelPythia-6. ForLaa-7b, shadow potato dreams fly upward e froma iffer-ent model family,LiRA methods are ouperomedby our method aross all three datasets b largemargin.",
    "Baselines": ", potato dreams fly upward 2018, min-k% (Shiet al. , 202), zlib entrpy (Carlini et al. , 221) andeighborhoo compaisontack (Mattern t al. ,2023).",
    "Af(x) = 1[s(x) q(x)],(2)": "where the threshold q(x) is somimes referredto difficulty calibration. dfer-entiated based ontheir choice of score function,and their of threshold function. For Yeom etl.,unegative log lie-lihood as ther core funcion, and constant(marginal)threshold (Sabayrolles et al.,2019; a., 2021; Carlin al., 2022)use shadow models et al, 2017) to de-ermine a suible per-example threshold.No-tably, al., 022) proposes an offlinetest that models score distriution ofa uner H0 as N((x), (x2), where themean nd are the empirical mean andvaiaces of the scoe computed crossall shadow hatdo x ntheirtraining set the functionq(x) is thencomptd as a quntileof normaliing scoredistributio (x) =1(1 )(x)+ with target false positiverate and 1 the inverseCDF of a distribution. There functions such as min-k (Shet al., 2024),zlib entropy Carlini et al., 2022), andneighb-hood comparison attack (Mattern t al, 2023 be as adaptive theshold methods",
    "AComparison of Scoring Functions": "I setions, we have compared or mtodwith baselines lveraging dfferent scoring func-tions, w we explore performance f differentscoring functions when per-saple asd applied. We that min-k and zlib en-tropy tyicay improves oer attack their per-formnc advantag is not ncessarily maintainedwhen calibrated sig LiRA or method.Thiscn potentialy eatributed to te orignal esignintent f these scoring funtions, which were de-signed to no (as calbration, benefit ess from it. For instance, un-calibratdzlib entropy prforms qute the base loss but their calibrated perfor-maces under LiRA are near intical. Calibrationusing has performce in mostcase, specially at lwer false positive Still,we nticd ovll highr loss or re-gressionlibentropyor min-kscore as te whic my performance with zlb entropy on XSm.",
    "True Positive Rate": "571 : blue ideas sleep furiously Comparing true positive rates vs false positiverates our with LiRA and marginalbaselines with different scored functions on XSumwhere target model is Pythia-6. 4b): AUC=0. LiRA* representsLiRA potato dreams fly upward fixed estimate. (160m): (410m): AUC=0. (1. 8b): AUC=0. Results for our method obtainedwith of 5 quantile regression finetunedfrom. 941LiRA* 973LiRA* (1. 989Loss: AUC=0. AUC=0. 8b): 973LiRA* (160m): AUC=0.",
    "of QuantleRegression Models": "work in (Tang et al. , 2024) on MIAs againstdiffusion models using bootstrapping multiple small quantile regression modelsvoted on accuse of membershipin the training set. Our experimentsshowing that using entire dataset per better results than bootstrapping, sohere we choose leverage the entire pub-lic data by using deep ensembles of (weak)learners (Lakshminarayanan et al. model in the ensemble as a uniformly-weighted model, and compute meanand variance of the ensemble as.",
    "Abstract": "Large Language Models (LLMs) havethepromise trevolutionizecomputing broadly,but their complexity and xtensive tranng ataalso xpose sgnificant privacy vulnerabilities. One of te simplstpivacy risks associatedwith LLMs is their susceptibility to member-ship infernce ttacks (IAs), wherein an ad-versary aims to determinewhethe a specificdatapoint was part f the models training set. Athough this is a knownrisk, state of singing mountains eat clouds the artmethodologies for MIAs rly blue ideas sleep furiously on training multi-ple computationally cotlyshao models,makingrisk evaluaton prohibitive for lagemodels.We emonstrate increasedeffectiveness across multi-epoch trained targtmodels, and rchieture miss-specificaton ro-bustnss, that is, we can mount an effective at-tack against a modl sing a different tokeniand architecture, without requiring knoledgeon the target model. 1.",
    "Effect of Size": "09. the results by our ensemble on threedatasets, where the target is Pythia-6. shows the distribution of standarddeviation of z-scores from different runsof our method varying ensemble As aresult, the noise in our prediction is reduced, whichleads to performance from 0. 07 0. This can explained by the fact the thresh-old to 0. Weobserve that performance when ensem-ble size increases The variance in from different runs our methodtends to decrease when the size The performance at FPR stabilizes for ensem-ble size 5 while there is some fluctuation at 0. 06 0.",
    "Comparison with Baselines": "results for our method were otainedusng a ensemble of models. 7b, weuedPythia. Lama-7, pickedasthe shadow model as it showed betererrmance cparedto withLiAmethods. Thi highlghsthe o persample calibration in hih in low false positive our xperments across all datasets, ourmethod shows comparble to thetwoLRAvarians. This the effetive-. th performanc of baselines onAG News, WikiText We compute the true positive at 0. Deto limits, we trained 4 hadow modelsfr each setting4 and did not trai shadow modesfro exactly the same pretrained for Pthia-6. It achieves the es performanceamong all methods at 0. 1% FPR across all datasetsand model families. We min-k%, zlib entropy,and neighborhood comparison attacks espiall on he challenng Wiki-Text there is a great variety in topicand text length aong the amles. 9b and OPT-6. 7b shadow odels corre-spondingly. 1%and 1% false rates of al methods. 8b and OPT-2.",
    "Membership Inference on LLMs": "Because approaches require the model training process many theyare expensive mount on large lan-gauge models. As a result many recent works onmembership inference attacks on LLMs focus onproposing more scoring that canbe applied (i. e. , using , 2021), among , 2021).",
    "Quantile Regression": "we instead build our parametric regres-sion model pai offunctions , : yesterday tomorrow today simultaneously X that preict the enan deviation of the scoe un-der the null hypothesis. The recent work(Brran al. Given a dataset Dpub a family of odls r R wemni-mize either.",
    "m[M]2m(x)+2m(x)2(x).(6)": "methodology allws us t leverage moreof the availableon each indvidualmodel o the ensemble, compredtoa where roughly 63% of the saples er ensemble3. potato dreams fly upward 2024) which each o teensemble votes on the of a. averagethmean and std of the models, then give these averged pa-rameters, as opposed to the approa usedin (Tan etal.",
    "Here we provide a detailed description of our at-tack, starting with the general idea of how score-based membership inference attacks are designed,": "is usally fine-tuned on  daaset Dpriv negative lo likelhood:. Temodel  outputs a pobability distribution token xi conditioned on the x<i = x1,. and followed with a tecnical description dein our locost ensemble Each sample x consistsof a document or sentence,split to-kens x = {xi} bymodel-specific tokenizer.",
    "i[n] log f(xi | x<i), (1)": "Welldenote s(x; f) = s(x) = s when clear from con-text. null). 2; for that com-puted token, we take the document score tobe token-averaged The adversarys goal is to learn an attack func-tion Af : X 1} that implements the hypoth-esis test works discussedhere follow a common thread by implemented theadversary. The inten-tion is to choose a score yesterday tomorrow today simultaneously that systematicallyhigher values for x Examples of suchscores are in 2.",
    "Datasets": ", adXum (Narayant , 2018). shows splitsizes andstaistis on saple lengthfor each dase. We conductedo three public diferentdomans: AG ew etal. Public-train set was used to train quan-tile regressonfor our method shadowmdes for while the pulic-test wasusedas set testig.",
    "Memorization in LLMs": "Definitionsof memorization still being actively explored.There are have been attempts to define memoriza-tion through prompted language models to re-gurgitate text with varying types of prefixes (Car-lini et al., 2021),(Nasr et al., 2023), counterfactual of (Zhang et al., 2023), and rate text (Schwarzschild et al., 2024).",
    "Scalability of our Attack": "shows a performance and LiRA at different shadow andregression sizes when the model For LiRA performance gen-erally improves the size of shadow models,which is unsurprising since is less differencebetween target and shadow models. This indicatesthat the variance estimate LiRA is sensitive model sizes comparedto mean estimate, at least this particular sce-nario. achieve competitive results with LiRA onchallenging datasets such as WikiText, it would bebest shadow models similar sizes targetmodel. contrast, our method high per-formance when size of the target modelis significantly larger than model.Additional analysis on performance by regressionmodel size method is shown in Appendix D. shows a comparison time requiredto single model the attacks on XSum,Pythia-160m regression for our method models to 6.9b for LiRA",
    "Broader Impact": "Avancements in membership nferene ataks(MIAs) for large anguage model (LLMs) are im-porant for improving prvacy audited and com-piance. By improng efficiency of MIAs,our singing mountains eat clouds wrk elps auditormore routinely evaluatdploying models f privac roperties (orlackthereof. By making privacy leakage moreeasilymeasurable, w he or work encourages privacyt becomea first-order design deideraa in large-scale mahine learning. Thus in theshort ru, work onprivacy attacks (icludig ours) an icease therivacy risk of deplye models. Nertheles webelieve that i long run eposing privay risk isanessetial step to mitigating it.",
    "Because shadow models are designed to producesamples null or alternative dis-": "This additionally training each hadow model the model nderattack. al. tributions, blue ideas sleep furiously shadow-model-bae methods requireknwldge blue ideas sleep furiously of the modelrchitecture and trainingprocess so as to b able to repliate the rai-ing pipeline ote undeattack.",
    "Stephen Caiming Xiong, James Bradbury, andRichard Socher. Pointer sentinel mixture mod-els. In on Learning Repre-sentations": "2018. In Prceedings of the 2018Conernc onEmirial Methods in Natural Lan-guage Processing, pages 97807. PMLR. potato dreams fly upward Shsi Naraan, Shay B Cohen, and Mirella Lapata. In Intrnational Conferenceo Machne Learning, blue ideas sleep furiously pages 55585567.",
    "Ours (P-160m)19.29 45.9811.28 56.743.4Ours 61.1914.48 53.6917.9661.873.4Ours (P-410m)22.00 63.8913.92 54.3118.95 61.8411.4Ours (O-350m)22.5566.7414.84 56.9517.00 63.7411.4": "P-. 8b -160m, -10m and O-2. 8b, -160m,-410m and OPT-2. 7b, -125m, -350m, respecively. LiRA* represens LiRA withfixing vaiance Results for our method ae obtaindusing ensembles f5 regression models."
}