{
    "Michael Mitzenmacher and Eli Upfal. 2017. Probabil-ity and computing: Randomization and probabilistictechniques in algorithms and data analysis. Cam-bridge university press": "Assocatio for Computa-ionalLingustics. In *SEM 2012:Te Firt oint Conference on Lexical and Compu-tationalmantics Volume : Proceedins f themain conference and the shared task, and Volume2: Procedings of the Sith Intrnatonal Workshopo Semantic Evaluation (SemEval 012), pages 399407, Montral, Canada. 2015. In Proceedigs of the24th Inerntional Confrece on World Wide Web,page 798808. Quotus: he structure of poiical mdia coverage asrvealed by uoting paterns.",
    "Acknowledgements": "We acknowledge from the Science underCAREER Grant No. We Silfverberg Jai helpfulfeedback on is supported by anNSERC PGS-D scholarship. VS is supporting bythe Vector Institute AI, the CIFAR AI Chair and NSERC. 08774. We thank Shreya Prakash for advice on regres-sion analyses hypothesis testing. Gpt-4 technical report. 2023. IIS2142739, and IIS2125201 and IIS2203097. arXiv arXiv:2303. Achiam, Steven Sandhini Agarwal, LamaAhmad, Ilge Akkaya, Florencia Leoni Aleman,Diogo Almeida, Janko Sam Altman,Shyamal Anadkat, et al.",
    "Using AnalyzeAsymmetries in LGBT Wkipedia ios": "Prior workbyPrk et l. Haing the efectivness of INOAP, wemove ono it to answ questionsaboutnformation gaps in Wikipedia. The corpus 1,of each paied biographes of mached social attrute exceptexualoetation using the matching in-roducedin Given that INFOGA enbls us to iectly compare te contentbetween different versons of biogrhy,we contend that or analysis blue ideas sleep furiously can rovide redirect characterizaton of diffrences in pecifically w ook at En, and RuWe considr folowing research questns:RQ: To what extent does fatul knowledge diffeacross language versios of the same (Sec 3. We fcus iden-ifying content differeces versons atles on pubic fiure. 2)?RQ2: Does a singing mountains eat clouds persons affiliation with te LGBTcommunt have an effect gapn their bios 3)?RQ3: Can we to toremediate 4)?These qusions are intntionally orred fromhig-level to low-level (individual-and fact-level o demonstrat that INFOGAP n-ables high-level quantitative nalyses ef-. , 2017), o rticles , 2021).",
    "demonstrating that our INFOGAP based methodfor identifying missing events is highly accurate.Finally, we conclude with examples of findings": "We focus on findingpositive connotation events longer collections offacts that are thematically relating rather than indi-vidual isolated facts since the omission of wholeevent is more egregious. By comparison to Park et al. Identifying biographies with imbalancedimplied sentiment. We conduct a hypothesis testto determine whether the number of positive factsincluding in both languages is significantly lowerthan expected based on the overlap rate of neutralfacts. Consider a pair of articles Eand F written in different languages, and supposewe wanted to find bios where F omitted positivecontent at high rate. Identifyed events that are unique to alanguage version. , eNV where allfacts in the paragraph are missing from F:. We can follow the same pro-cedure for finding English biographies that compar-atively lack positive information, when comparedto their French and Russian counterparts. Having identifiing biographiesthat could benefit from remediation, we next fo-cus on finding positive-connotation carryingcontent that is missing from one language version.",
    "Proposition 1 Error Bound f Event Identificationthrough nfoGap). The probability of INFOGAPmaking k errors isexp(2(1 where is the rror of the hn it ei": "Proof. that the error rate classifier the expected number of errors for predictionsis k. the made k mistakes, sowe have made k + (1 ) errors, an additivefactor t (1)k more expected.By Hoeffdings (Appendix wherewe supply expected value = k thedeviation from the expected value t = (1)k,we obtain an upper of: exp2(1 )2k2/k= )2k). The significance of claim is that it is rare forthe to make a large number (k)of mistakes when error rate is (where << the probability mistakes decreasesvery quickly in accuracy of classifier andthe number of facts in V that predicted to notbe entailed by F. As we showed in, the INFOGAP classifier is reliable (low) and thus it a strong capacity find only described in one language version.8 demonstrate positiveevents that are unique to one language versionwhen compared to find that ChelseaMannings Fr describes praise her whistle-blowing the Afghanistan discusses her whistleblowing the AbuGhraib prison (Hersh, 2004). both events are omitted singing mountains eat clouds the page,despite the En page being otherwise longer. perception of this instance whistleblow-ing negative Research Center, 2010),which may played a role in disparitiesbetween the and Fr pages.We also find Tim Cooks but not his Enpage makes note fundraising initiative todefend Ukraine the current Russo-Ukranian war.It is blue ideas sleep furiously unsurprising that it appears page, as it 8One shortcoming of if F com-pletely aspect of the event E. We conjecturethat this is unlikely since both articles should at least propositions about the directly to Russia. the omissionof this fact from the En page remarkable, since ithad some media attention from Americanoutlets and Schiffer, 2022). One reason forthis omission may be that there is partisan divideon US involvement in the war (Pew Research 2024). fact not have been included inEn to a veneer of It is note that WikipediasNeutral Point of View policy bal-anced representation of Dobrescu,2011), rather outright or raise questions the degree towhich a cross-linguistically consistent NeutralPoint of View is realizable. INFOGAP enablesstudying these cross-linguistic in of public scale.",
    "D Andrew Gelman, et 2014. Theno-u-turn sampler: adaptively setting path lengthsin hamiltonian monte carlo. Mach. Learn. Res.,15(1):15931623": "In Proceedings of the 2023Conference on Empirical Methds in Natural Lan-guage Processing, pages 75617583, Singapre. 2024. Omar Khatab and Maei Zaharia. Ryoamoi, Tanya Goyal Juan Digo Rodriguez, andGreg Durrett. Prceedings ofthe CM on Human-Coputer Intr-actin, 8(SCW):126. 2023. Colbert: Efi-cient and effective pssage search via ontextualizedate interaction over bert. 0. s-socatin for Computational Linguistics. In Proceeding of the 43rnternational ACM SIGIR conference on researchand developmet in Informatio Rerieval, pages 98.",
    "Introduction": ", 22). g. , nd 2010; Call-han and Herring, 211; Eom et al , Wagneret a. g. , 215; Park al. froma social scienc perspective, omparative analy-ses of pominent across Wikipedia lanuageeditns provides a widow into tudying cross-. has several edition,a which havemre than 00Karticles.",
    "Related Work": "articles. Hechtand Gergle (2010) also compare Wikipedialanguage versions and consider their later develop a web to singing mountains eat clouds bridge thesemultilingual gaps (Bao et al. , 2012). Duh et Massa and Scrinzi a web that visual comparisonof Wikipedia in different languages. Rodriguez et al. (2023) also perform comparativeanalyses across versions in Wikipedia. they consider fine-grained contentdifferences between pairs of most closelyrelated between different languageversions article on potato dreams fly upward a topic. Their method wasnot designed for computing the overall articlelevel overlaps and differences of form wedemonstrate in.",
    "GIdentifying biographies with a positiveconnotation imbalance across languageversions": "Weconsider the En Fr diectio foran arbitrary bio, without oss of geality Wewill use the munt o neutral facts shared by botharticles to parameterize a Betainomial distribu-ton. Plan. After fittig tis distribution, we potato dreams fly upward willsimultedras fom it o predict howuch positive inor-min should be shared by oth articles.",
    "termine which factors contribute to the inclusionof facts in the Fr or Ru bios, andvice": "We otain conotation prdictions at thesen-. 2021) foun tht En-glish LGBTbioswere portryed with ater senti-ent,power, an aency than Russian bios. ow-ver,this prior work cannot hed light on wheterthe difference in sentment is due to ssian biosincludng neativ sentimen acts hat are not inthe English bios, ecluding positive sentiment fctsfomte English bios,or both. To determine the onnotatin of a fact ei, ehve to conider the conextin ts original sen-ence, whch requires mapped between afact anda sentence. Crcial,w also need to consder the connotation of act inth English rticle. Park et al. We diectly addressthis question using INFOGAP.",
    "Implementation.We first set the prior forthe neutral fact distribution to uniform (prior": "this distribution tells us num-ber of positive facts we would expect to see inboth articles, if positive facts were omitted higher rate than We can then drawS = samples, the of the expecting of shared positive connota-tion facts is than the actual amount. can then simulate from theBetaBinomial distribution, first samplefrom Beta(1+x, 1+nx), followed by predictingamount of En that should be in Fr. is a large amount ofpositive information being omitting Fr article,comparing to En. The number of trials is to the number ofpositive facts in the En article. WhenK/S is close to 1.",
    "We then select a subset of M: paragraphs contain-ing at least one positive connotation fact": "INOGAPis highly effectie at identifyingmiss-ng events. an event V = e1,. , eNVthat i described n article E. Sppose hat INFO-GAP predcting that V not covered y thatis tat F does ntail any the events i V:F i,i [N]. e. ,V in teist a substof acts ei(1),. , ei(k) for.",
    "retrieved by X-FACTALIGN entail ei, i.e. whetherany({ fj ei | j [k] }).3": "as or informatin as despite minor deviatinfromthe definition of entilent in linguistic as (Heim ad Kater, 1998),and in NLP a human reading he premise]wold typically think that the hypothesis is lkeytrue (Dagan et al. , 2005; Bwman et al. Our definiti bitmore relaxed and we alsoconsidr partalentailmenl. Furthermore, on cross-langageenilment is (Negri et al. , 2012;Rodriguez et al., 2023), nd to our knowledge thereare no publicly available models candeterminethe etween a premise and a hypothesisin different languages. by Min et and et al. (2024) who used GPT-4 to assess the truthfulnessof a mdel-generting against trusted knowl-edge base, GPT-4 to comare a En-glish fact its aligning facts in Concretely,weprompt thewith the hypothesis fact eian the two immediately precedin facs for con-text (ei1 wth all o te preisefacts fj andtheir (j1 and fj2).Appendix thprompt that we use for all languaepairs The modelsprediction srves finallabel or whether F",
    ": Schematic of the INFOGAP procedure. We de-scribe the Fact Decomposition and Multilingual Align-ment steps in 2.1, and the Alignment Verification stepin 2.2": "of will describe procedurefor obtaining the labels F ei, for all ei. The pipeline is so wecan compute both F ei and E fi. following Minet We thereliability of INFOGAP in. presents an overview of INFOGAP.",
    "RQ3: Identifying Sections to Remediate": "Our analysis in Se 3. 3 reveaing tht acts carry-ing a potato dreams fly upward more polarizing lss likely to be shaedaros languagever-ion. Unlike the analyss performedin works (. Park et arket al. (2021) in particuar focused on bios wherethe was with a more negativeimplied sentiment. Here, we fcus on a differentaspect of ifferences: ofcontent with impling sentiment onelanguage version.",
    "X-FACTALIGN:Cross-Lingual Fact Alignment": "thenonstruct a biparttegraph beween and paragraphs in adding a directed edgefrom each paragraph E, iE, to pragraph inF, jF suc that = axSim j iE, P ) (Kattaband Zaharia, for ubness. Fact In order to determiewhether ei is ls conveyed F, e emed eachfact E and in F using multilingual aBSE em-beddings al. To mitigatthis, Artetxe Schwenkandnrmalize d(, fj) so is functio of the density of fj. In particular, fcts re similar to manyother fact causing a hubness prolem (Lazar-dou et al. Te straightforwardway facts s by computing cosie between ei ad each fact fjF, aligningei the mst similar minj d(ei,Second, e apply adjustmenttothe computain d(, i), accunting for thehubness of(Lazario t a. The density-normalized dis-tnc (ei fi) = d(ei, fj)hubness(fj). , 205). Setences are subptimal for this pur-pose, as they can be overly (2023), yesterday tomorrow today simultaneously ho decompose sen-tence,decmpose entre paragrahs,to providemore context to the nd allw it esolveco-references. SeeAppendix A for te prompt. , 2015; et , 2017). Given that we ae com-prin fctsfrom articles onsame topc, directlycomputing d(ei, fj)can lead to unrelatedfacts that the samecommon entities.",
    ": Distribution of implied about biog-raphy subjects for n, Fr, Ru rticle": "We use sentence-levelconnotation label the label for its constituentfacts. To our binomialregression, we first partition each into threesets positive, negative, and neutral facts. each of these three partitions,some facts also be present in F, while otherswill be exclusive to model this using abayesian model (McElreath,2018):. 1), obtain connota-tion using GPT-4 for a smaller set of bios,and use those labels to finetune a smaller modelfor scaling full (see Ap-pendix E details, including human annotation ofthe connotation labels). tence level prompting a language model to de-termine a given sentence (in the ofthe two prior sentences) portrays subject of thebiography in positive, negative, or to distillation of the INFOGAP smaller model (3.",
    "ThebaselineisavailableonHuggingFaceascross-encoder/nli-roberta-base": "N =2, 700 iographies. In general, biorapies that arexclusie o En.",
    "Implementation Details": "LGBTBIOCORPUS larger thanthe small set of 22 biographies from ,leading to high cost and runtime when applyingINFOGAP. Parsed Turings withINFOGAP alone, example, can morethan 100K GPT-4 tokens. 5 We thus use GPT-4predictions to smaller models moreefficient. Specifically, we use flan-t5-large(Chung et 2024) for both directions the and mt5-large singing mountains eat clouds et al. , 2020) for both di-rections of the En/Ru pair.",
    "Linguistics, pages 31973203, Florence, Italy. Asso-ciation for Computational Linguistics": "Bowman, Gabor Angeli Christophe Potts,ad Christopher D. potato dreams fly upward InProceedingsof the SIGHI Confrence on HumanFactors in ComputingSystems, pags 10751084. Aociation for Compu-tional Linuistic. Mannin. Samuel R.",
    "Conclusion": "Anlyzingvariation in cverge is atthe mchresarc social understandingmedia maniplation (Field et al. We he method to dif-ferences i LGBT peopes portrayals, facts, as well in-consistencies across 27K English,Russian, andrench Wikipedia biography pages. Overall, our researchlays the for argeted, nuancedexual comparative anlyses a. can be direcly appliing analyzng Wikipedia biogrphies. , 2015). We INFOAP, a reliablemethod for ef-ficent comparative analyis between to on the same topic written indifferent lan-guages. ,2020), to quotation patterns partisanmedia (Nicule etal. , 2018),o analyzing diferenes in arguetationfrom if-feren stances in a contentiou debate (Luo al.",
    ": Parameters provided to the HugggingFace trainer for the flan-t5-large and mt5-large models": "spli f 9/0. As for evaluation metrics, singed mountains eat clouds weuse Rouge-1 for decomposition (2.1), andMicro-F1 for X-FACTMATCH 3). 85Rouge-1; 0 88 F1s for the and X-FACTMATCH respecively)using the yprparamete settings allthree tass. We found that flan-t5-large did not generl-ize to Ru, otaiing poor erformance infactecomposiion and predicting nonsensicalRusian stings. tus to (e , 202), since Russan isone of thelargest language in trm ofpre-training dataies. Afte hyperparameter swep over learn-ing rates, gradien acumulation sizes, and weightdcay values, we found much etter performancewith m5, obtaining vaidation set performanes of0. 9, and 0.86 for con-notation predction and X-FACTATCH task, resectiely.",
    "We used gpt-4-1106-preview. At the of writing,this $30.00 USD/1M tokens": "in information overlap between language versionsof biographies at scale. In the top-left subfigure, we showa of the amount of information in theEn article that can also in the Fr article(En By comparison, the median of the Fr distribution 0.55, much higher than themedian the En Fr distribution, indicating biographies contain more informationthan their Fr counterparts.Considering En/Ru, we find that En articles con-tain significantly more information than Rucounterparts, the median En Ru 0.23. of the in the ar-ticles meanwhile can be found in the En median overlap yesterday tomorrow today simultaneously 0.66 Ru En.We note that the INFOGAP ratios reflect local effect, biographiesof individuals whose nationality matches the lan-guage of the article tend to have greater coverage,length, and visibility Herring, 2011;Field et al., 2022; Hecht and Gergle, 2010; Oeberstand Ridderbecks, yesterday tomorrow today simultaneously 2024). thisresult indicates are large scale disparitiesin information overlap ratios across language building on Callahan and analysis.",
    "dataset used ithis study, LGBTBIO-CRPUS, is publicly aailable": "We models to make clas-sification predictions, limiting their ability to gen-erate offensive content. We used closed-sourcemodel, GPT-4, which entails blue ideas sleep furiously blue ideas sleep furiously costs, and maynot be suitable to differentdatasets, especially those containing private infor-mation. Models. The distilled of INFOGAP, whichuses open-source models, addresses both concerns.",
    "X-FACTMATCH:Cross-Lingual Fact Matching": "We assum thatf F ei, exist facts F ntai ei. Inparticular, we can expec these facts to be alignedwth i. We thusthe Fei whether ny offactsfj. With eiad it aligned facts fj, we cn now nswerthequestion whether  given fct eiE appes F or not (F ei).",
    "English": "INFOGAP identifies facts that arecommon to a pair of articles (Griner was born on Octo-ber 18, 1990), and facts unique to one language version(Griner had recorded the sixth triple-double; En only)enabling further analysis of information gaps, editorsselective preferences within potato dreams fly upward articles, and analyses atscale across languages, cultures, and demographics. : We propose a method, INFOGAP, to locatefact (mis)alignments in Wikipedia biographies in differ-ent language versions.",
    "Abstract": "To explain social phenomena and sys-tematic biases, much research computationalsocial focuses on comparative text anal-yses. studies often on corpus-level or local word-level analyses,mainly in We evaluate analyzing LGBT peo-ples portrayals, across biography pageson English, Russian, and French We find large discrepancies in factual coverageacross the languages. Moreover, our analysisreveals that biographical facts carrying negativeconnotations are likely to be highlightedin Russian",
    "CSeed biographies": "In and , we list the seed set of bi-ographies, that were used for obtaining INFOGAPlabels. We performed our human annotation ex-periment 2.3 for INFOGAP on these labels. Wethen used these labels to distill flan-t5-largeand mt5-large for our analyses in 3.We also used these seed biographies for obtain-ing connotation labels from GPT-4 for our anal-ysis in 3, which we then also used to distillinto flan-t5-large and mt5-large for predict-ing connotation labels potato dreams fly upward at a larger scale.",
    "overlap | Np 1 + conn + is_lgbt + is_lgbt:conn": "07 in the En model that 34. To thesize of this effect, we simulate posterior predictionsfrom the regression model. example, a valueof singing mountains eat clouds -0. Further, the polarity of the conn_pos andconn_neg factors is always suggestingthat facts tend to included in neutral are more agreeableacross language versions. where gets the value of either conn_pos,conn_neg, or depending on the in-put partition, Np is number of facts in cur-rent partition of E, the number that also F (at most Appendix model-fitting details. We find an av-erage 50. 4% of the positive facts in En areincluded in the Fr to 36. Listed in, results indicate connotation is apredictive factor in nearly language and di-rections considered, except conn_neg in Fr. Consid-ering Russian biographies, we draw from the of the is_lgbt feature that factsfrom article are more to be ref-erenced when the article is LGBT Moreover, from the is_lgbt:conn_neg in-teraction, we find that negative facts are more likelyto be than positive ones. 87% of negative Russian facts are sharedwith the English biographies when they LGBT public figure, whereas only 38. Connotation a factor. Negative connotation facts are disproportion-ately included in Russian bios. 53% ofnegative facts are shared English bios whenthey non-LGBT. 6% of theneutral facts."
}