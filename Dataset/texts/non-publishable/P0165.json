{
    "S. Butterworth. On the Theory of Filter Amplifiers. Experi-mental Wireless & the Wireless Engineer, 7:536541, 1930.14": "Sndspae:Audio-visul navigaton enironents. 13 Angel ai,Maciejlber, atthis Niessner, Manolis avva, Song,AndyZeng, and YindaZhang. B. Informaton: The woud Manuel Hahmann for thefruitful s parof the MONICA project and receivedfund-ing from the EuropeanHoizon 220 research adinnovation pogram grant agreement No. 732350. 22. 06158,3Changan Unnat Jain, Carl chissler, Seastia Vi-cenc Amengual Gari, Ziad Al-Halah, Vamsi KristenGrauman. Gausian processes foround fied ecotruction Journl ofhe Acoustical of 2021.",
    ".2 Soundfield Reconstruction": "When observed at a single frequency, the spatial variationsin sound pressure for a given sound field often exhibit modalpatterns. Reconstructing the pressure levels of a sound fieldfrom a sparse set of observations is a problem of longstand-ing theoretical and practical interest.",
    "where represents linear interpolation the vector of values Ad indexed by frequencies f, based onquery frequency fo": "Source ImpulseSinceromimpulse re-sponse relates surc ignal fed to spakerto theund heardin the room, must potato dreams fly upward alo accont for the wathat source modifies te ource signal being tit. if the source a oudspeker, it may orboostcertin",
    ". Additional Experiments and Visualizations": "Appendix D shows that ourmodel is to geometric distortions experimentswith the effects of transmission. weshow that our model training points outperforms allbaselines training on points.",
    "F. Baseline Implementation Details": "This al-ternative lnear baseline erforms quite poorly, yesterday tomorrow today simultaneously with erroicreasing with he yesterday tomorrow today simultaneously nmber of trainingpoints. This isbe-cause the training RIRs ar roughly uncorrelated with mean.",
    "Fitting and Inference": ", and using parameters we theanalysis-by-synthesis process. To ren-der binaural audio, the incoming from each reflectionpath singing mountains eat clouds is convolved with an HRIR from dataset corresponding its incoming direction. We train our model on single-channelRIRs omnidirectional Theshape of the head, the acoustic potato dreams fly upward shadow it casts, and the in time-of-arrival between the left and right earsall result in distinct cues that help place the lis-tener in the scene. There is adifferent HRIR for incomed audio direction. Inspired by , we to multi-scale loss comparing rendered RIR W with theground-truth at the same location. We estimate the parameters each model in iterative analysis-by-synthesis process. For inference, we simply compute Equation for a pointat a computing all the specular paths belowthe maximum order between the source and the novel loca-tion, etc.",
    "E.3. Specific Loss Formulation": "indicates the hop lengtsw inicates STFT window size,ad iste transormor spectrogram, whose arguments thetime-domain signa transform, window size, nd thehop lngh, spectively H indicates the hop ratio, or thehop lngth divdd by the sze. Hop Sieusea spetral losswith osize 1 to ensure that theearly part of theRIR accu-ate time-domain since the hop lenth of 1allows for high-resolution the time domain.",
    "+ L256,1(W, W)(7)": "improvementsin both RIR predicion an music rediction.Suh for of gularzation soud b the study of uturework and theoretcal studyWth thegoal of improvng rendered muicn mind,we also trieda imilar form oregularization, where wecnolv both our groud-truth andrediced RRs withfive scondsof music randomly sample from FMAdataset at each iteration ater trained s alfway doe.Convolution with the muc ies simlates the speaker play-ing thm. Results for this forof regularzationare aloshown in , althoug we refer te performance ndsimplicity ofpink noisereglariation",
    "uating exclusively on simulated data": "Geometry-ased RIR Manyof the afore-mentioned worksuse dataets of simulating RIRs eneratedy SoundSpaces famework fast sim-uatr based on geometric coustic mehods. authors f implemented a diffrentiable coustic ry trcer forinvesetasksunderwatr acoustics,such esimaed the of the seabed on 2D W use similarrinciples for estimatng blue ideas sleep furiously aorption parameters surfacesin 3D environments from our real, sound data. Thy th acoustics of ersions of real datasets of reconsructing from RGBD scansofrooms hme environments, atterport3D dataet or the Rplica he Geometric-Wve Acoustic (GWA) dtase uses hybridpropagation wave-based wih geometricacoustic methods, intending to moel wave effects ore accurately, albeit at costof run-tme.",
    ". Results": "Distance (ENV). Ourresults for monaural redictiontask are shown For themoaural rdictintask, our model significantly all baselines onour metrics,across all rooms. compare rendered au-dio using two metrics:1. L1 istance betweenthe log-energ envelops of the ground-rut nd en-dered wavforms. nalysis. 1. Resuts for the pre-diction taskshown Appendix D.",
    "MagENVMagENVMagENVMagENVMagENVMagENVMagENVMagENV": "DIFFRIR5. 220. 9422. 711. 361. 210. 5551. 591. 199. 132. 591. 254. 9172. 41w/o Time-of-Arrival Perturbation5. 431. 230. 132. 274. 860. 231. 190. 711. 431. 220. 5551. 591. 142. 952. 591. 304. 860. 9342. 251. 44w/o Hop Size 1 Loss5. 741. 411. 250. 671. 222. 982. 244. 900. 9622. 42w/o Interpolation Spline5. 9732. 630. 5651. 531. 169. 472. 922. 561. 245. 9202. 211. Ablation results from task of predicted monaural RIRs and music at unseen point.",
    "Mandar Chitre. Differentiable ocean OCEANS 2023-Limerick, 18. IEEE,2023. 3": "n Conference potato dreams fly upward on Robot Lerning, pages66273. Room impulse response interpolation fom asparse se ofmeasurements using a modal arcitecture InICASSP 2021 - 2021 EEE International Conference onAcustics, Seech nd Signal Proessing (ICSSP), pages960964, 2021. singing mountains eat clouds men-gual Gari. Diffimpct:ifferntiable rendeingand identificaionof impact sounds. Smuel Clarke, einHerai, Mrk Rau, uohn Gao,Ji-jun Wu, Doug James, and Jentte Bohg.",
    "Envelope Distance": "The and dashed linesindicate teof the nearest-neighbors baselin accord-ng to the multiscae log-spectral L metric an the envelope metric, resetively. Effect of distorton on RR prediction pe-fornce Classroom The lue line showsperformnce according to Muliscale L1etric, the red line shows our models perfomanceaccrd-ing to he istance metric.",
    "D.2. Performance vs Number of Training Points": "Note in all ooms, ourmodeltrained locations outperforms bselin 00. When the trainingpoints is higher, it is ossile thenumber parameters nstance, inceasing the resolu-tion hatma r the numer of refletion cefficets)eads to even better peformace. Asson in , the prformance in-creaseswih N, and our consisently outperforms tebaseline yesterday tomorrow today simultaneously whenN 2. We an ablation study varying points N singing mountains eat clouds on each subdatast compare againtthe baselines.",
    "Modifications from Related Work.Our multi-scale": "spectral plu g-spectral loss isidnticalto tose usedinand , with two exceptons: First, blue ideas sleep furiously is th inro-duction of the loss term withop sizeone. Second, theminimum widow size in our loss is 256, instead of 32 or64. This means that thpla-ment in time of a reflction pathscontribution to our syn-thesized IR may bef frm its lacemet in th ground- truth RI by sme aout.",
    "denot the igmoid functio, and a linear in-terpolation from the Vson the relation fthe qery  the enter frequencies f": "g. mthod considers alpermutationsfrom1 o N of surfaces ith repetition ad, for eachpermutatio, if is a reflection pththat from to the listener fter reflectigspecularly each the srfaces in orde. Given the estimated soure locationSxyz, a loction Lxyz, and representationothe rooms geometry, we ue the image-source methodt efficintly all specular reflecion pths the source and litener in room, up particularorder (e. 50. Wedisuss additional surface interactions, such as diffuse re-letion, in 2. Thee re-sult in which ae powerful room resonanceswth espeially longeverberation times. Fr eahvalid refectio path p from souce track of he path p, rdere listSof reflec-tion alng path irection from whichth exits the dp. Thus, in d-diionto computed all paths o urfaces, ourimage-source cmputes all reflection paths for pars of toa much order, g. Tis mdifica-tion, we call al booting, improvesmoelsperformnce (see Appendix 4) in adversarial ase likethe Hallway, with acomputatoal overhead lin-early rather th exponentially it eflection order.",
    "B.1. Broadband RIR Heatmaps": "We visualize the root mean square (RMS) vol-ume level of the RIRs in , on We observe differences in the heatmaps thedifferent Thiseffect is reduced in the Classroom, where soundfieldis more out. of RIR maps generated from our model trained each of potato dreams fly upward four base subdatasets. We measure loudnessby rendering an RIR at listener measuring its RMS volume level. For each RIR rendered, we the height of thelistener to 1 meter above the green dots indicate the xy locations of 12 points, are projecting z singing mountains eat clouds 1 plane.",
    "the second configuration. Results are shown in .The baseline shown is one where we train on the same sub-dataset that we evaluate on": "g. Vrtual Panel Insertio. , te Hallway PanelConfi. The baseline shownis onewhere wetrain on the same subatase that we evaluateon. g, DampenedBase subdataet), and te coefficents learned for the white-board panel from oher room(e. 1 subdatast). We would like to se if yesterday tomorrow today simultaneously we canlearn the reflecive characteristis of a surface in one oom,then virtuallyinsert the surface into anohe room. Resulsre shown in. We hen irtually insert white-board panel inthe base subdatset, and evaluate the vir-tual insertio ganst the version of the base ataset with apane in it (e. , theDampened Panel subdataset). g. yesterday tomorrow today simultaneously Threeof ourbse subdatasets also nclude a verson with a sin-gle inserting whiteboard panel In each of our four exper-ments, we tke the base subdatset (e.",
    ". Experiments": "For eachroom in our collected dataset evaluate our on the tasks ofrendering bth omnidirectionaRIRs an music a unseen lstene loctions. We Implicit Neural epresentation for AudioScees INRAS) , wch uses of more explicitly model specular reflectin ata subset of points cenes msh. 1. ach roomconfiguration, we select 12 RIRs to trainour moel. DeepIR monaua RR at ovel locations only on thelocations coordinates, while NAF ses the com-bned with loca geoetic features to the RR. e ue our moel to render RRs at unseenocations i te test st, and compare our renered gound-tuth RI using metrics we detai in. Tosimulate music plying n he we convolveour rendered RIR with five different souce usic files andompre the resultto recordings o th muic flebeig playe in th across the sa merics. NAF was origially dsiged for binauralren-derg.",
    ". Introduction": "Much o the impetusto raize immersive virtual stems to recreate an real sensand experiences. Motivated by gol, recent in3D computer vison ad graphics has ledto can real-world 3D environmentsusing sm-ple consuer device (e. cellphon cameras) for Mixed Reality (XR) appications.Alongside imme-sive visual experieces, auditory experiences potato dreams fly upward areeally vital to our holistic perception of an environment. For instance while the of Carnegie Hall in Nw.",
    "Abstract": "To evaluate method, wef RIR recrdings and musi n fur diverse, real singing mountains eat clouds We show our modelutperform state-of-the-rt baselnes on rendering and RIRsandmusic unsen loations, and pysically aramers characterizing acoustic propertiesofte soun andsurfacs in the scene. In this pper, we aim the spatialacostic chracteristics of arbitrary envronmnt givennly aspase of rohly 12) room impule respons(RIR)nd a reconstruction of he setup that is orinary usrs. yesterday tomorrow today simultaneously thisen, intrduce DIFFRIR, a RIR renderingframewor inteprtabe parametric modelso ientacoustic featus of scene, including sound sourcedi-rectity and surface reflctivity. Recent yers have se immnse rogressin 3D com-pue ision and comuter graphics emerging can virualize real-worl enonments for numr-os MixedReality (XR) applicaios. This to syn-thesize itory eperiences throgh the space withany source audio.",
    "D.6. Comparison to Traditional Acoustic Simula-tions": "reports the accuracyof the singing mountains eat clouds simulated singing mountains eat clouds compared the ground truth. We compare our method to a widely-used image-source Pyroomacoustics.",
    ". The DIFFRIR Framework": "As an overview of theDIFFRIR framework, we use the sound source and micro-phone location, along with the planar decomposition of theenvironment, to trace all specular reflection paths betweenthe source and a listener location, up to a certain number ofreflections. To achieve this task, we design a differentiable RIR render-ing framework, dubbed DIFFRIR. Each model is fullydifferentiable, with interpretable parameters.",
    "Room/ConfigurationMagENVMagENV": "621. 691. 6603. Virtual Speaker Rotation. 1. 701. Hall. 6001. 2. As experiment, takethe DIFFRIR model trained on base subdataset witha corresponding rotated virtually rotate thespeaker by rotating the learned directivity heatmap, andpredict RIRs and music at locations each corre-sponding We evaluate these ground-truth RIRs and music recordings from resultsare shown in. 1 Model8. Model1. 1. 6001. 621. 6603. 581. 992. 2 612. the model both trained on the rotating subdatasets outperforms our virtually-. on Virtual Panel Insertion. Damp. 840. 230. yesterday tomorrow today simultaneously 2. 32Virtual Insertion9. Hall. 36Virtual 452. 38Hall. 962. means that DIFFRIR model from the Hallway Base (no panel). 56Hall. Damp. Hall. Damp. 701. 47Virtual Insertion1.",
    "zero, so the average of NRIRs towards as Nincreass": "However, order apply NAF ourdataset and we modified this code insome minor ways. the original de-signing to estimate arbitrary stereo to lieon a horizontal plane a i. e. it did notconsider z-axis and thus not output RIRs at heights. correspondingelements of the network g. , the number ofunits in the input were also modified. Note thatwe only changing number of number of units layer, from 126 168, to the ad-dition of z-axis features. e. without phase information, becausethe official code does not phase-relating corresponding phase output. we used a Hz sam-ple rate than original 22050 Hz. ,are the same as their official implementation. Therefore, we implemented DeepIR the details in their paper. Specifically, we multi-layer (MLP) consisting of 6 linearlayers, each followed by leaky-ReLU vector consists of y, t), which are the coordinates and the time index, respectively. Similarto NAF, we applied positional encoding them the MLP. Hence, the number of inthe input layer demb, whereas all other layers have 512.",
    "V.D. Lanon. A stud of the characteristics nose. Pro-ceedings of the Rado Engineer, 24(11):15141521, 1936. 4": "Eric A. 7 Yan Li, Peer2.",
    "C.3. Quantitative Results on Virtual Room LayoutModifications": "We simulate rotating thespeak by roatig the speakers earned directiviy map,and translation by moving he speakers estiatd locationduring path-trang. Since our blue ideas sleep furiously model learns physicallyinterpretable parametersforthe speakrs directviy, weexpect to be able to virtu-ally simulate rotatons or trnslations of the speaker that arunobserved in the training data.",
    "(g) DeepIR": "sound field intensity at a given location ismeasred byfilterin the ground-truh or prected RIR around 0 Hz usig 2nd orer Butterworth ilte and masurigtheRMS volume lvel ofthe iltering signal singing mountains eat clouds Subfigure a) hows the intensity of the 70hz yesterday tomorrow today simultaneously soundfield at all locations in the sbdataset. Visuaiztion of RIR loudnes at 70Hz n Classroo subdataset. Note that i subfgure d) the Linear baseline underestimates h soundfeld intensity at lcationsfar awayfro the training loations, since the linear iterpolaionat these locations is weigted verage of roughly uncorelated signals whosemean is roghly zero. Subfiures c) through g) show sound field ensty as predctedb eah of our baseline models. We indicate the spai locations of tse 12 training points withgrendos, and the speakrs locaio and orientation with black con.",
    ". Task Formulation": "acieve or goal o virtalizig real saces, ourmethod should require infomaion about room is aseasy as possible to obtain. In our setup, assume a statinary whose ndposition are With nformation, potato dreams fly upward our gals to simulate monoauraland binaural IRs and music t listener riettion the room. be easily captured by played a soure location recordin from microphoneat the loction. With this in mind, weshow that or prodce accrate esults wile onlyrequired he 2.",
    "arXiv:2406.07532v1 [cs.SD] 11 Jun 2024": "We thus ur Heared Anying Anywhere takas inferred IRs an music t novel listener locationsfrom sparse set of measurd between a inglesource nd of microphone locations spatially dis-tributd he scene. In oder to simulate the soundof an arbi-trary source listener locaion in roo, theRI with thesource-listener pair simply con-volvdwith source audio. Our cntrbtions are we differenible acoustic inerse that can recover the imersive blue ideas sleep furiously acoustic ofa from st ofsparsely locaed RIR measure-ments. Thrd, we compar our method ex-istig methods across various etings, demonsrating hatur method is more effectve tan methods on realdata our scenarios, predicing more ccu-rate RIRs and music at loctions. and istener points, and are ths widly used in. Towards this goal, we introduceaflly differentiable impuls respone redeed frameworkDIFFRIR that reasos about ndvidual contributions ofeah acusic rflection path beween the source and the the time delay and magnitude of soundon each path, aswell asthe influence of rflections surfaceAfter optimizing he intepretableparameters of our modl, can the RIR from anyunseen location in the scene. To validate our mehod, we collect a dataset co-tains RIR singing mountains eat clouds mesurement from four real-world environmentsthat diverse range room materials, shape, andcomplexity Through experiments comparing our frame-work with curent stte-of-the-art methods, DIFFRIR in data-limited cenarios. Inddition, and models our framewok al-low us to acoust parametrs of sound sourceand surfaces inthe be useful in applica-tonslike robotics and architectral design for acoustics.",
    "E.5. Computational Cost": "Main Contributions t Trinig Time. Not thatsnethe Complex Room isonly traced up to orde 4, there aresubstantially ewer valid relction paths, an thus trinings faster. 4% oeverthin lse. Tracingis slower in roms with more srfes. % on the bck-wards passe, an 0. We also mea-surd the different teps i the training procss to see whchnes took the longest Each trini location is associtedwit hndrds of reflection paths that mut be singing mountains eat clouds added to-gether o form the th RIR.",
    "To test our methods effectiveness on various room lay-outs, including those where the speaker is occluded": "Potogrphs of eachadditional configu-ration are shown in. 32m X (m) Y(m) Z = 0 98m. The locations and orienatios of the speakers as wellas thepositions of the anel(s), are blue ideas sleep furiously provided as part of theDIFFRR Dataset. To evauae acoustic intepolatio methods on the task ofzero-shot generalizain to chans in room ayouts, byirtually simuating speaker rotationand transation,andpel reloction and insertion. In the Hallway, e move the speaker to thefar end of the allway, such that the speaker singing mountains eat clouds fcs te entirelength f Hallway. In the Dmpened Room, Hall-way, an Complex Room, we cllecting 120, 72 an 132addiional datapoints where the speaker was translatetoanotherpar of the rom, b th orientation of the speakris was kep the same.",
    ".RIR loudness heatmaps generated from DIFFRIRtrained on 12 points in the Dampened Rooms base subdataset": "In , train our model the and use it to virtual speaker rotationand We visualize these changes by plotting RIRloudness heatmaps. as well as evalua-tions on virtual and.",
    "E.4. Small Efficency and Performance": "Regularizatio via with ik ofte as a means to simulat sounds in environment we ouldlike to onlyensure tator rendered are accrate ao tha te wesimulae via with the are Mini-mizing th lss between gound-truth ad prdictedRIRs doesnot alwaysaccomplish this since convolving theRIRs with oter waveforms in significantchanges spectrograms. Pn is a special tye nose whos pwer spe-tra density inversey proportional to It is ubq-uitious in nature is as test cal-ibrate soun systems and sinceit is similar to that of usic othe sounds might encourage our model accucy potconvolution, we mplement a regulrization strateg usingpink nois. shows that ths rm regularizaton results in. thelatter of iterations, we on-volve both ourand the ground-truth RIR wthfive of generated pink nois, compute between andad to oss compted betweenRIRs at iteratonreshaping RIRs tothe profile of pink noise, and radom phase shiftateach frequency. Eficiency Boosts. Since each RIR ombinesundeds of reflection path, we compute all the reflectionpath contributions in paallel to mnimize runtime. Time-of-Arrivl Perturbatio. Sice ur room are not necessarily precise, to make modelmre especially with an etremely limited numberof measurements,wouldlike to prturb the surfaces dur-ing As a proxy we the time of arriva of all paths by addingGaussin noise it, adviation of 7 found ths improvedthe interpretability of es-timting parameters and led o perfomance asshown in.",
    "D.1. Results on Binaural Rendering": "Weevauate our method on the taskof rnering abinau-ral RR at an unseen locan We collet bnaural RIRsat seveal location in allrooms using our 3Diobnauralmicrophone, and comre these t predicted RR that weinauralize frosingle-channel udio as describedin theMethods secton. e cmpare our binauralized audio with the ground-truth audio using the left-right eergy rtio error betweente gond-truth and preicted recordings, which is usedn. To compute the left-rght enrgy ratio, we computecompe th rao of total energy between the let and rightchnnels of the RIR or music recordings. We then coputethe men sqad eror betwen theleft-iht energy ratiof the predicted nd groud-truth RIRs or music. Sincethebaselines do ot hv a way of generating binauraRIRs from monauralones, we binauraize these base-lines  renderi two monaural RIRs atthe locatios of theleftand riheas of the3Dio micropne, and cominingthem into lft and rght channels. Our method ouprforms or baselines acos mostmet-rics. Note that i is difficultto compare a binaral IRrecorded frmour bnaural microphone wth binurlizedaudi originally recode roma different microphone. Orrendered binauralaudio ill have characteristics of themonaural microphone andthemicophones usd in theSADIEdaaset used to record the IRs that we c-vole our monaural rcordings wih. The binaural record-igs n ou dataet will h ave differentcharacteristics, scethey are recordd using a diferentmicrophone with di-ferent spectrl caracteristics and directionality.",
    "Differentiable Path Tracing": "Differentiable Room Impulse Response Rendering Framework (DIFFRIR). After computing a reflection path, we characterize it by the direction at which it exits the speaker, itslength, and the surfaces on which it reflects. The sound source has a learned frequency response that depends on outgoing direction,and each surface has different learned frequency response. We multiply each of these responses to estimate overall path response. Todetermine the reflection paths time-domain contribution to the final RIR, we apply minimum-phase inverse-Fourier transform to the pathresponse, convolve it with the source impulse response, and then shift result in time based on the path length and the speed of sound. To model the direction-dependent frequency response,we potato dreams fly upward fit F different heatmaps on unit spheres centered on thespeaker, one heatmap for each of F octave-spacing centerfrequencies comprised vector f. To do this, we distribute128 points evenly along the surface of the unit sphere, us-ed a Fibonacci lattice. We denote this set of pointsL. Let Ax,fo be the log-amplitude gain for sound travel-ing out of the speaker in the direction of x at frequency fo.",
    "We trace each specular reflection path and model the acous-tic effects of each reflection along the path, with unique re-flection parameters for each surface in the environment": "Reflectivity. When a wave encounters a surface, of sound waves energy will be re-flected, while remaining energy will diffusely reflected, or These varyby frequency, depending on the texture and prop-erties of each surface. For s, we fit Vs of F representing the magnitude potato dreams fly upward sound specularly re-flected by the surface at each F centeredfrequencies in vector f. We apply the sigmoid function values to determine energy reflection proportion of specularly reflecting energy) at eachfrequency. Next, we determine the amplitude reflection co-efficients (the amount that potato dreams fly upward surface attenuates sound at frequency in terms of by taking the square root of the energy reflection co-efficients. Thisgives us response Rs, a magnitude frequencyresponse representing the surfaces effect on incoming au-dio of different Thus, the formula for Rs is:.",
    "G.2. Room Geometry Estimation": "As the wavelengths of audible typically range from2 cm - 17 m , prominent sound blue ideas sleep furiously waves are likely tobypass diffract around smaller surfaces. we onlyfocus on salient (e.g., pillars, tabletops), which often characterized by and simplytrace reflection paths image source methods. Forthe rooms we captured dataset, also measured and surfaces manually created planar mesh-basedreconstructions of them. With the recent progress in visual3D reconstructions , geometric estimation canalso easily be replaced by automatic or even ma-ture customer tools such as X (m) NearCornerSpread",
    "H. Guidelines for Microphone Placement": "To maimize efficiency, we foun it empiriclly beneficialto spead our RIR n all tree Thisallows s singing mountains eat clouds 1 a variety of angls the likely lead to bettr peaker directiviy estiates,2)disentangl effectsof ndividualrelectons, ) bet-ter estimae th diffusewhichi approximatedi ou mode as stialy uniform. lect three differnt setsof training locations(shown in ), of 6 recordings rm6 lcations. 98. We DIFFRIR tranedon each of these of tran locaions o a set comprised of oher yesterday tomorrow today simultaneously points elected in Z = 0. 98 plane. Our best cross all metrics achieving int Spread cnfiuratio of raining poins, confirmingour intuition. blieve could be due tothe o te near-fiel of the spaker ,which cn substantially ifferent thn sound fied atothe in theroom.",
    "Combining Models": "We reflectio sound source models toestatete contributn of ach reflection path. We thensm te conributions across all paths residul toestiate the RI for a given ource ad location. Cotribution of Single Reflection Pah. D(dp) response souce from the outgoingdirection. The reflection of each urfae s Sp attenu-ates the amlitde of the sound in  frequenc-epedenfashion Rs. Thereflection-based the prodct of the frequency respnse acro alls Sp. We lso uselp to estimate attenuation of due t sphercal propagation,whee the ampi-tude is iversely proportioal to well as",
    ",": "We assume the loopback signal isthe same a signal,but dlayed in time by theatecy of the system. Decnvolvig from adelayed ofthesignal directy fom source signalths corrects fr dela inthesystem. We remove the lat0. 1 seconds 4-secon RI to elminate anti-causalrtifacts. n additin, acount for we ajust volume each seeprecord-ing accordingto sensitiviy of the microphone torecord Specifically, we look up each EMM6s 000 Hzd from its clbrationsheet, overall volume it recordings bythe same amount.",
    "+(1)r": "(5)In this formula, denotes ooltio, and P is setof all paths between source an istener locations. For singing mountains eat clouds this reason, we fi16 poits on a temporal spine tht interpolates a relaivewghted between the contrbutns of late-stage resid-ual and those of xplicitly cmuted reflectionpaths."
}