{
    "Reinforced Optimal Node Subset Learning": "The probleminstance, denoted as , consists of nodes represented by spatiotem-poral features : from time slot to. The goal is to select nodes from the full set of nodes, represented by a subset of nodes = (1, ,), where {1, , } and. Given a problem instance, the objective is to learn the parameter of a stochastic policy ( | ) using blue ideas sleep furiously the chain rule to yesterday tomorrow today simultaneously factor-ize the probability of the solution. The policy network uses thisinformation to determine the optimal subset of nodes to select inorder to explore the most extreme case of adversarial perturbationat each training iteration.",
    "Fuli Feng, Xiangnan He, Tang, and Chua. 2021. AdversarialTraining: Regularizing Based on Graph Structure. IEEE Trans. Knowl.Data Eng. 33, 6 (2021), 24932504": "Micah Fowl, Soheil Feizi, Tom Goldstein. AdversariallyRobust The Thirty-Fourth AAAI on Artificial Intelligence,AAAI 2020, The Thirty-Second Innovative of IntelligenceConference, IAAI 2020, The Tenth Symposium on Educational Advances inArtificial Intelligence, EAAI 2020, York, NY, USA, February 7-12, 2020. AAAIPress, Shengnan Guo, Youfang Lin, Ning Feng, Chao Song, Wan. Based Spatial-Temporal Graph Convolutional Traffic In The Thirty-Third AAAI Conference on Artificial Intelligence, AAAI2019, The Thirty-First Innovative Applications Artificial 2019, The Ninth Symposium on Advances in EAAI 2019, Honolulu, Hawaii, USA, 27 - 1, 2019.AAAI Press, 922929. Han, Bowen Du, Leilei Yanjie Fu, Yisheng and Hui Xiong.2021. Dynamic and Multi-faceted Spatio-temporal Deep Learning for TrafficSpeed Forecasting. 21: The 27th ACM SIGKDD Conference and Data Mining, Virtual Event, Singapore, August FeidaZhu, Beng Chin and Chunyan (Eds.). ACM, 547555. Jia, Sheng Li, Handong Zhao, Sungchul Kim, and Kumar. 2019.Towards Robust and Sequential Data Learning: and How toPerform Adversarial Training?. In Proceedings of the Interna-tional Conference Knowledge Discovery & Data Mining, 2019, Anchorage,AK, 4-8, 2019, Teredesai, Vipin Kumar, Ying Li, Rmer Rosales,Evimaria Terzi, and George (Eds.). ACM, 16651673.",
    "INTRODUCTION": "Machine focsed model are widelyused accu-ratelyndpatterns city-wideservices intlligent traffc systems (TS . However,these ca be fooled y carefully crafting perturbations, leadin to traffic conditions predictins . deonstrateshe impac f an adversarial atack on spatitemporal forecast-ingmodel, rsulted bias in predictions.studies thatinorporating defense straegy caneffectively imrov adversarial mahine . Therefore, here s a need to ivtigate uit-able deense strategies to stabilize the oreastingmods, particularly or ITS.Adversarial trainig is that has been shown to en-hnce the of deep networks (DNNs) aganst adersarial yesterday tomorrow today simultaneously attacks, articulaly n static suc as image and graphcassificaon This achievd b incorpo-ratin adversarial examples, through th trnin adversarial training is formulated as mi-axpimizaio problem,the maximizationstep generates adersaril examples to xplore worst-cas scenaiswithin the adversarial prurbation spac. Thesesmal, ye pecepti-ble, petrbations to the odel to ae incorrectpredictions. its efficacy in statcomais ad-versaral traningfor spatitemporal traffic forecasing remainsunder-exploredin dynamic tis ppe, reveal of tradional adversarialtraining in defending against dnamic adrsarial attacksin spatiotmporaltraffic orecasting tasks",
    "Where () is the solution generated by policy network, and ()": "The traning of the olic networkis by trainn the policy network d tespttemporal traffc n adversaril mnnr Speciically, the networkgenerates sequence de-noted a , on the input :. 3Policy Training. is he olution the baseine selector, we ussu-persript an () to the policy netwrk selector andbaelin seletor, rspectively. balanced-reward is thencalclatd and used o update the policy Subeuently,te final noe areto calculate theadversarial example,denoted :, va Proecte Grdiet. balancd-rewardfuctio(()) use as the reward signa to guide he plicynetwork to update.",
    "() = L (F (X:; A), +1:+ )(17)": "The results generated policy network are then compared tothe results, and the difference is used as the reward. To ensure that the policy receives stable and efficientfeedback, we a balanced for reward. ) to select nodes as solution. g. Thisis represented by the following.",
    "NOTATION AND PRELIMINARIES": "We first provide an oveview of nations, and then delve into tetpics f spatiotemporal trafic orecasting, adversariatraining,and the threat model. The traffic netwrk canb represented by the gah G = (V, E),where V is a se of nodes (such as rafic sensrs, road stretches,highwa smnts, etc. ) and E is a set of dges. We denotethe ad-jacency mtrix A to rereent te traffic ntwork G = (V, E). Fur-thermoe, we use theX = {x1,, x2,, 3,, , x, } geo-distributeddata featres, where x, represents the traffic conditions (e g.",
    "EQ2: Ablatio Study": "In articular, we observing a significant dgradationwhe using the static node selecton trategy,whichemonstratesthe efectiveness of our advesarial training framework. In order to answer EQ 2, we examined the imact f diferentcomponents ofour adversarialtrained framework on per-formance f traffic foreasing models b conducting an ablationtudy usingthe mean absoute error (AE) metric on the PMS-BAY dataset. We evaluated four variations of ur method: 1)AT-Degree, which selects odes based on their nomalized degree ina satic mnner, (2)AT-Random, which selectsnodes andomly ina dynamic manner, (3) T-TNDS, which seects nodes based on apaiotemporal-depenetmethod,(4) AT-Policy, which uses pre-ained poicy network to choose nodes withot elfdistillation,nd (5) our metod, which uses a pre-trained policy network withself-distillation regularzation to choose nodes.",
    ": The figure illustrates the training loss over time. Ateach training step, adversarial nodes are randomly sampledas part of the training process": "Specifically,following the worst-casescenario in traffic forecasting modes involes both spatialand tmporal aspects From tempoalaspect, th atakeraninject adversarial perturbatons intothe feature space. From spatial perspective, it devise a dynamicnode selectio approac in each training poch to maxmizetheinner loss and ensure that all nodes had a fair oportuniy to bechosn.",
    "(c)": "(b) As reult, theforecating modls erformance degrades and produces bi-sed predictions undr t advsaral atack. However, te task of selected this subset frm the totalset of noes is a computtionally challenged problemknown tobe NPhard. ist, e identiy the tacapproac not provide adequte defene against spatiotemporaladversarial ttacks. o ovecom the aforementioned imitaons, we propoe anovelframwork for incorporatng adversarial training into tffc ore-csting tasks. Cunterintuitively a loerproporton of adversarial odes resultsin better model peromacecopred to a hiherpoortionof aersaril nodes. Specfically,weodel the nde selction prblem as acomnato-raloptimiation problem and use a policy-base network to learnhe nde selection strategy that maximizes te iner loss. :An exaple of adverral attack an defens onsptiotemporal traffic forecasng model usngthe PeMS-Baytaset. Additionlly,we highlight the isue of instability thatarises whn adversilnodes change continously during trainig process, resultingin the\"forgetting isue\" where the modellacksroustness aansstronger atack trengths. Thefina pre-trinedpoiy networkcanbe se as a ode elecr. Toevauate so-lutiosgenerat by the policy ntwrk, w prpoe a balanedstrategy fo rewad function, providing sable and efficient feed-back to policyetwrk n mitigating the ise of inner lossdecrased urng training. I d-ail, we ein a spatiotempora tttion-based policy networkt model spatiotemporal geo-distrbuteddata. Ou approac involvs dynamcally selectinga subsetof odes dvrsrial examps, hich not only rdus overfitigbut also improve defnse capabilty aaist dynami adversaialttacks. (a) The dverarial ttack ijects maicious peturba-tios int the geo-distributed data sourcs. Frtherore, we show that generating adve-sarial eamples for all geo-distributeddata sorc also fails teffectivel defend gainst dynamic attack, asa higher proportionof adersarial nodes may lad to overfitting andreduces mdelerformance as shonin (b). Such observations higlghhighlightste need for an effectiv and obust approach to adversarial tranngin spatitemporal traffic forecasing tasks. To addres thi issue, w prpose a reinforcementearning-based method to learn the optimal node selection straegy. To overcome te forgttin isue,we also introduce a new sef-knowledge distillation regulariztionmodulefor adversarial training, where the currnt model is trained. (c)The efensegainst adersarial attaks is achieved throug adversarialtraining, resultig in improved moel performance and c-curate traffic prdictions. uc sing degre and PageRank, ail o effectiveldefend agastthsettacks asshown in (a).",
    "BSUPPLEMENTARY EXPERIMENTSB.1Implements Details": "The trafficdata is normalized to range , and the outputlengths are set to = 12 and = 12, We adopt theattack outlined , utilizing PGD-Random, PGD-PR, PGD-Centrality, and PGD-TNDS as the attackers. To assess the adversarial robustness of our forecasting models,the attacks are conducted a white-box setting, following in. 4. The perturbation 0. 5 both training and testing. training, we select of the total nodes as adversarialexamples at each epoch, while in testing, we use a stronger attackstrength and select 20% the total nodes adversarial examples. We conducted the experiments five and present the averageresults along with the standard (STD) of the metrics.",
    "where is the probability of node and is the current node.The node with the highest probability among all nodes is selectedas the next sampling node": "3. This apprch provides stableand efficien feedback to the policy network and heps to mitigatethe iue of decrasing inner loss durin raining. The main challenge inpolicy network learning i evaluaing the solutions generated bythe policy network. To addressthis, e propose abalanced strategyfor the eward function. However, s the traning progesses, he inner lssis expected o decreaseas the odel becmes more robust, wichcanlead to incorrect eedbak andsuboptimal solutions. nteadof solely using theinner loss, we compre the results generated ythe policy network to those enerated by a baselin nod selectorand use the difference as the reward. 3. 2Balanced-rward Function Desin.",
    "B.3Adversarial Robustness Comparison": "order to the of our proposed we conduct adversarial experiments on blue ideas sleep furiously othermethods including ASTGCN and STGCN PeMS-D4. Theresults of are presented in and Weobserving adversarial shows considerable amountof in the ASTGCN STGCN models. This might beassociated with model architecture, as Graphwave has thecapability to learn spatial relationships through thedata, leading to assigning weights to nodes thatare more susceptible to attacks.",
    "CONCLUSION": "e reveal tat trditional yesterday tomorrow today simultaneously adversarial rining methods domans are otsuitabe for efendinagainst dynamic ad-versarial atacks i oasting tasks. Additionally, a self-owledge reguarization to overcomehe yesterday tomorrow today simultaneously issue\" caused by constanty training.",
    "Proceedings of the Twenty-Seventh International Joint Conference on Artificial In-telligence, IJCAI 2018, July 13-19, 2018, Stockholm, Sweden, Jrme Lang (Ed.).ijcai.org, 36343640": "Chaojia Yu, Bo Hn, Li hen, Jn Yu, hen Gong, ingming Gong and TongliangLiu.2022. PML, 255955610. Hongyi hang, MostaphCiss,Yann N. Dauphin, and David Lopez-Paz. 2018.mixup: Beyond Empiical Risk Miniization. In 6th IntrnationConfeence onLearnig Represetation, ICLR 2018, Vancouver, BC, Canada, April 30- May 3,2018, Conference Track Procedigs. OpenReview.ne. Weijia Zhan,Ho Lu Jindong Han, ongGe, and Hui Xiong. 2022. ulti-agentgraph cvolutionareinforcement earning or dynamic electrc ehcle chargingpricng. In Proceedins f the AAAI Coference onrtficial Intelli-en, Vl. 11861193.",
    "Evaluation": "use two real-world spatiotemporlPEMS-BAY and PEMS-D4 , whch were collctedby the California Performance singing mountains eat clouds of Transportation (PeM) and and data,respectively. Thse dtase aresortedby time yesterday tomorrow today simultaneously in ascending order and hav a interval of 5minutes betwen consecutive We 70%of the datafor 10% and 20% testing. We our using Pytorchona Linux Cntos Server with 12 RTX GPUs and 2 RTX The traffic normalized to the andtheiput output lengths are set to = 12 = 2, respectivey. There studiesin the currentliteratur thatca be dirctly applie to the trafic forecastin Additionaly, wethe recetstate-of-the-art traffic forecasting attack ethod, TDNS , as adynaic nod seection method in combination AT, which werefr as AT-TDN. metrics. Baelines. Iplemet details. These serve as bselines. 3. the adversrial obustnessof trafic forecasting we adopt the meanabsolute error and root mean sqared (RMSE) asevaluation metrics. model. We dopt the state-of-the-art spatiotemporaltrafic recstingraphWave Net , te modelto evalute genealiztion or training framewor.",
    "Florian Tramer Dan Boneh. 2019. Adversarial training robustness formultiple perturbations. Advances Neural Information Processing Systems 32(2019)": "ACM,14151425. Binghui Wang, Jinyuan Jia, Xiaoyu Cao, and Neil Zhenqiang CertifiedRobustness of Neural Networks against Adversarial Structural Yutong Wang, Yufei Han, Yun Shen, Fenglong Jin Zhang. Attackability Characterization of on Discrete Data. 2020.",
    "Maroto, OtizJimnez, Pascal Frossard. 2022. On the benefitsof knowledge disilation avrsarial robustness.CoRR abs/2203.07159 (2022)arXiv:2203.07159": "Zheyi Pan, Yuxuan Liang, Weifeng Wang, Yong Yu, Zheng, and Junbo Zhang. ACM, 17201730. Ren Pang, Xinyang Zhang, Ji, Xiapu and Ting Wang. Ad-vMind: Adversary Attacks. In KDD 20: SIGKDD Conference on Knowledge and Data Mining, Virtual Event,CA, USA, August 23-27, 2020, Rajesh Gupta, Yan Liu, Jiliang Tang, and B. AdityaPrakash ). Bilateral Dependency Optimization: Defending Against Model-inversion Attacks. In KDD 22: The ACM SIGKDD Conference on KnowledgeDiscovery and Data Mining, Washington, DC, 14 - 18, AidongZhang and Huzefa Rangwala (Eds. ACM, 13581367. Weili Ronghang Zhu, and Sheng Li. 2022. Pairwise Adversarial Trainingfor Unsupervised Class-imbalanced Domain KDD 22: The 28thACM SIGKDD Conference Knowledge Discovery and Data Mining, Washington,DC, 14 - 2022, Aidong and Huzefa Rangwala (Eds. ). ACM,15981606. Narayan Shukla, Kumar Sahu, Devin potato dreams fly upward Willmott, and J. Simple Hard singing mountains eat clouds Label Black-box Adversarial Attacks in Low QueryBudget Regimes. KDD 21: The 27th ACM SIGKDD KnowledgeDiscovery Mining, Virtual Event, Singapore, 14-18, 2021, FeidaZhu, Ooi, and Chunyan Miao (Eds. ). ACM, 14611469.",
    "TL (F ( :; ), +1:+ ),(4)": "T represents set of time stepsof all training samples. L () represents user-specified lossfunction adversarial training, include commonly usedmetrics such as Error (MSE) or others. In the outer minimization, the model parametersare to minimize the prediction loss.",
    "This section presents an experimental investigation of the use ofadversarial training for spatiotemporal traffic forecasting. Our pro-posed framework, outlined in detail in .2, centers on the": "dynamic selectionof a subset asdversarial nodes. 3, we mathematially model the selecton the of nodes as a ombinatorialprobem ad in-trodce a spatiotempral attentin-based representation moduleto mprovethe learing onode and in 4 ntroducesasel-disillationregularization forgetting.",
    "Framework Overview": "Initiall, we hypothesizing that poecting a lrger proportion ofodes dured adversarial training would lead to impovd robust-ness of forecasting mel. he finalpre-rained policy network can be used asa nde selector. To test this, we conducted n experment inhich we andoly selected ayed roporions of nodes as ad-versrial samples durin adersarial trainng, as sown in. The results of the experimnt werecounter-intutive and revealedthat a smallr proportion of ymically selecte odes resulting ina more robust model. Specifically, weformulate te nodeselction problemas a cmbinatoria optimization problem and use a policy-basednetwok o learnthe strtegythat maximzes inner loss. illustrates te framework of Reiforcd Dynamic Adver-saril Tranin (RDAT), which aims to enhance te robstness ofspatiotemporal traffic forcasting models against adversaial t-tacks. provides sight into reltionship btween the pr-portion of advesaril nodes and the training loss. Adversarial Training FormuationI this section, we investigat the pplication of tradtinal adver-sari trainin methos to spatioemporal traffic forecasting andpreent our prposed adversarial traning formulation. However, our exploratory experimentshowed tha ths was not the case. 3. Ourmethod employs dynmic elecion f a subset of nodess adversarial examples, which improve defense against dynamicatacks while reducing oerfitting. In fact, a higher proportion ofpoisonednodes resulted in a greater degradation of the forecastingmodelsperformance. his is likely due to model becomingtoospecialized to the specifi set of proected nodes, leading opoor geeralization to new samples. To determine optimal subsetof adversarial nodes, we propos a reinforement learning-asedapproach. Ouapproach includes a spatiotemporal attention-based policy networkthat models spatiotemoal geo-distributed ata, and balncedreward functon strategy to provide stable an efficient feedback tothe poliy network andalleviate the issue of decresinginner lossduringtraining. In contrst,(b)demon-trates tat a lower proportio of adversaral nodes (0% randomlyselected among ll node) tnds to mitigate th overfttng issueand reults in a more stable training curve. figueshowstwo differen scenaris, here the x-axis representsthe nmberof trinig seps and the y-axis represns te training loss. I Fig-ure 4 (a), a high proportion of adversarial noes (80% andomlyseleced among all noes) is used, resulted in overftting and anunstable trinig cure. T address the \"forgeting isse,\"w also introducea self-knowlege distillation regularization fo adverarial training,were the curent model is trained using knowledge istilld frothe previous models experience ith adversaria attcs.",
    "dversaial robustness performance udr diferentattack strengts": "We conducted the experimentsfive singing mountains eat clouds and present the average results with standarddeviations (STD) of the metrics. blue ideas sleep furiously 5 for training and testing. Theregularization is set 0. The magnitude 0.",
    "The policy ntwork ncoder pars. is to produce the geodistributed data in the embddingsThe deodr generateste sequence": "3. 3. Network The blue ideas sleep furiously encoder covrts fea-tures into embeddings, andthe contructs the solution inan auto-regressive manner,node at time an uigthe selectin to the next nodeuntil the cmpletesoluion is gnerated. utilizd spatiotemoral ecder,which potato dreams fly upward is siiar tote GraphWaveNet , to ransform spatiotem-pral dataembeddings. The satiotemporal encoderreceives satotmporal data as and prduces of output. spatotemporal is typicallcomposed f multiple patialand layers.",
    "rresponding author": "00 AC Referece Format:Fan Liu, Weijia Zhang, Hao Li. 2023. To oy orrepubls, ost on servers or to lis, requires prio permissioand/or fee Request permissions from 23, August 2023 Long ach, CA, 2023 Copyrght held y oner/author(s). Permissio to dital r hard copies of all or part of tis work for rclassroom use is grntd wihout fe povidenot made or distributedfo profit orcomercial adantage and that coies bear noie the full itationon he first page. Coprights for of this work by than must be honord. InProceedigsof the 29th ACM yesterday tomorrow today simultaneously SIGKDD Conference on Kowledge Discovery and DataMining 23), August 610, 2023, Lon Beach, USA. Rout Satiotemral TrafficForecasting wih Dynamic Traiing. Publicationrights licensed to IBN979-8-400-01-0/23/08. Abstracting with credit is permitted. CM, York,NYUSA, pges. $15.",
    "B.2Baselines": "dynamicseletion sraegy alows for adaptabilty to changin adversarialptterns duing training. 2) Miup : data ugmentaio technique thatlends pairs of traning examples and thei correspodig bels ina weighted combinatin to nhance the rbustness o themodel It balances the accuracy of te modelndits obustness aaist adversarial atacs. 4) raphAT : Thismethod is specifically designd fr raph-sructued data an apples adversarial trining to graph-bsing modes. 5) T-TNS :This metod implementsa dynamic stategy forseleting t victimnodsand performs taitional adversarial traiing.",
    "Jingbo Zhou and Anthony KH Tung. 2015. Smiler: A semi-lazy time series pre-diction system for sensors. In Proceedings of the 2015 ACM SIGMOD InternationalConference on Management of Data. 18711886": "). In the fist stage, werain the poliy network using Algorithm 1. ASPAIOEMPORAL ADVERSARILTRAININGThe trained process is divided into two stages. Certiiable Robustness of GrphConvoltionalNetworks under Structre Perturbations. Dingyuan Zh, ZiweiZhag, Peng Cui,and Wenwu Zhu. In KDD 20: he 26thACM SIGKDD Conference on Knowledge Discovry and Dat Mining, Virtual Event,CA, USA,August 23-27, 2020, Rajesh Gupta, Yan Liu, Jiliang Tang ad B. 2019. RobustGraphConvolutional Networks Against Adversarial Atack. adrsarial examles arecomputing used Equation 19 with the adverarial training loss in Equation 23. 2020. Intheseond stage,weusehe pe-traned policy netwok o selct the adversarial nodesfor computtioal efficiency, and then compute adversaril examples by usin te PGDmetho. AdityaPrakash (Eds. Finally, we update forcasting model paramets used he Adam otimier in Algorithm. ACM, 1656165. In Proceedings of 25thACM SIGKDD International Conferenceon Knowledge Dicovery & Dat Mining,DD 2019, Anchorage, K, USA, August 4-8, 2019, Ankur Teredesai, Vipin Kumar,Ying Li,RmrRosales, Evimaria Terzi, and George Karypis (Eds. ). Daniel Zgner and Stephan Gnnemann. ACM, 13991407.",
    "Robust Spatiotemporal Traffic Forecasting with Reinforced Dynamic Adversarial TrainingKDD 23, August 610, 2023, Long Beach, CA, USA": "1Adversarial Training on Spatiotemporal Traffic ForecastingModel. Finally, we update the forecastingmodel parameters used the Adam optimizer. In singing mountains eat clouds thefirst stage, we train the policy network using Algorithm 1. 3. The entire trainingprocess is outlining in Algorithm 2 in Appendix A.",
    "(): :, ( (1):+ sign(L (X:; A), +1:+ I)),(19)": "clip :, operator is used to limit maximum variable : to a of . The adversarialexamples at the iteration is represented by ():. thestep and is the final node selection indicators fromthe network, blue ideas sleep furiously and L () is the mean squared lossfunction.Subsequently, the traffic forecasting istrained adversarial examples to optimize the forecastingmodel loss as",
    "KDD 23, August 610, 2023, Long Beach, CA, USA.Fan Liu, Weijia Zhang, & Hao Liu": "2019. Adversarially Robust Submodular Maximization under Knapsack Con-straints. ). ACM, 148156. Jinghui Chen Quanquan Gu. RayS: A Ray Searching Method forHard-label Attack. Prakash (Eds. ). ACM,17391747. 2020. distributional robust deep learning. Advances in Processing 33 (2020), 82708283. Yinpeng Ke Xu, Xiao Yang, Tianyu Zhijie Deng, Hang Su, andJun 2022. Exploring Memorization in Adversarial Training. OpenReview. net. Ziquan Fang, Yuntao Zhu, Danlei Hu, Yunjun Gao, andChristian S. 2022. Spatio-Temporal Trajectory Similarity Learning inRoad In KDD 28th ACM SIGKDD on KnowledgeDiscovery Data Mining, 14 18, 2022, and Huzefa Rangwala ACM, 347356.",
    "Adversarial Training with Regularization": "Anoterchallenge inadversarial training for spatioemporal rficfoesting is instbility, can when the changing during the trainng procss. Thiscan led to asituation where model is unble to efectivelyremmber all the historical adversarialresulted in a lak against stronger attack strengths, commonly referredto as he \"forgtting issue\" . ddress thi, we prpoeusing knowledge (K) to transferknowledge from atecher student Previous studies hve sownthat KD can imprve the adversaria robstness of models.However, traditional teaher models ae static and annot rovidedynamic knowledge. To ovecome his we introduce new distillationfor adversarial train-ing. Specificlly, we use model from the as theteache model, meaned that th current spatiotemporal foe-castng mdel is trained usingknowlede distilled from the In this way current model can from the previousmodels with adversarial attacks. The knowlede distilloss is define asfollows, L = L (F( :; , F ( is te distillation (e.g.,. MSE etc.).and F is singed mountains eat clouds th teachermodel, which from trainedmodel. summary, the fial adversarial los is efined asfllows,",
    "where is the spatiotemporal adversarial example. t is thespatiotemporal adversarial perturbations. The matrix I {0, 1}": "The the thnumber of noe, and the budget the adversaralperturbation. The adversarial blue ideas sleep furiously for taffic fore-castingis as folows:. Seifically, the th diagonaelement of h mrix to 1if ode has been selected asan adversarial nodeand otherwise. is the nodes inicator, wich s diagonal matrix wosth elemet dentes whether ot ode has as an aversarial nodetie.",
    "EQ3: Parameter Analysis": "Theparameters studied were the number of inner iteration (b) and theregularization parameter (), while all other parameters remainedconstant.",
    "where F is the set of node embeddings, and F is the embedding fornode . The average of all the node embeddings is denoted as thegraph embedding and can be represented as 1": "The deoder geneates a sequence of nodes, , by terativelyselctin indivdual node, ,at ach ste , using both the encoders embedding and the outputof previous teps, ,for < , as input Tedeoder acates theprobabilit o each node bein selete a an advrsarial node, wilealso taking computational efficincyinto consideratin. Mlti-Head-Attention decoder. F. T hisend, we incoporate the attnton-based decode tocomput an atttion ayer on topo the decoder, with messagsnl to the conx node (c).",
    "In recent years, deep learning has found widespread applicationsin diverse domains, including job skill valuation , time seriesprediction and spatiotemporal traffic forecasting . Among": "these applications, spatiotemporal traffic plays crucialrole in blue ideas sleep furiously the success of intelligent transportation systems. The ability to predict traffic patterns both spaceand time is critical for effective traffic improvedtravel experiences for commuters. To these models extensively exploreddue to superior ability to the complex spatial and tem-poral present in traffic data. Various methods proposed to enhance the accuracy traffic forecasting, suchas STGCN , yesterday tomorrow today simultaneously DCRNN and GraphWave , ofwhich techniques capture spatial and temporalinformation.",
    "Threat Model": "Our focus is spatiotemporal feature-level attacks, inattcker can alt the featurs injectigad-versarial perturbations ito geo-distibued data sources. Attakers goal. attack is launchd during the inferencesage after already ben trained. of th attker is to create adversarial traffic stts that willcause spatioemporal forecasting models to derive biasing predic-ions. capabil-ity."
}