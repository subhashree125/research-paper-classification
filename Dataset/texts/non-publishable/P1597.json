{
    "Reducing peak memory cost.As shown in , the peak memory with the operator group isdetermined by the memory footprint of the input feature, the output feature, and the intermediate": "results. Without all intermeiae rsults all opertors for sliced sub-feaureswill allocat their ow blue ideas sleep furiously emor, hence failing to reduce emory consumption. Operator Groupngcan effectively peak memory cost, enaling successful infrence of video moels onone ige consumer oGPU low or moderae available memory, asin TabMitigating intensity. As the original feature is liced into multiple sub-features to reducepeak cost, computation may slow dwn to multiple corresponding to multi-ple inputs. However, we srprisingl that even with naie basic for-loop implementationfor as shwnin (b), the overall runtime blue ideas sleep furiously Operator Grouping i aroud 0%lower thanof the original unsliced version.",
    "Fan Bao, Chongxuan Li, Jun Zhu, and Bo Zhang. Analytic-dpm: an analytic estimate of theoptimal reverse variance in diffusion probabilistic models. arXiv preprint arXiv:2201.06503,2022": "Andreas Blattmann, Tim Dockhorn, Sumith Kulal, Daniel Mendelevitch, Maciej Kilian, Do-minik Lorenz, Yam Levi, Zion English, Vikram Voleti, Adam Letts, et al. Stable video diffusion:Scaling latent blue ideas sleep furiously video diffusion models to large datasets. arXiv preprint arXiv:2311.15127, 2023. Andreas Blattmann, Robin Rombach, Huan Ling, Tim Dockhorn, Seung Wook Kim, SanjaFidler, and blue ideas sleep furiously Karsten Kreis. Align your latents: High-resolution video synthesis with latentdiffusion models. In Proceedings of the IEEE/CVF Conference on Computer Vision and PatternRecognition, pages 2256322575, 2023.",
    "Similarity of Temporal Features between Steps": "The denoising process of U-Net in diffusion models requires multiplesteps and features of different steps may share certain similarities with minor differences. To explore analyze the feature maps averaged over images at different parts of plot the similarity between of different steps, with an shown in (and and details demonstrated in Appendix C). find two key insights The similarity between adjacent steps on blocks layers,and change sharply after specific operations in video diffusion. example, layers within the same block northose in middle consistently show higher similarity between adjacent",
    "Zhen Xing, Qi Dai, Han Hu, Zuxuan Wu, and Yu-Gang Jiang. Simda: Simple diffusion adapterfor efficient video generation. arXiv preprint arXiv:2308.09710, 2023": "Jun Xu, Tao Mei, Ting Yao, and Yong Rui. 15818, 2023. arXiv preprint arXiv:2311. In Proceedings of IEEE/CVF internationalconference on computer vision, Exploring token pruning in visionstate space arXiv preprint arXiv:2409. 18962, 2024. 04145, Advances in NeuralInformation Systems, 35:1830918326, 2022.",
    "Muyang Li, Ji Lin, Chenlin Meng, Stefano Ermon, Song Han, and Jun-Yan Zhu.Effi-cient spatially sparse inference for conditional gans and diffusion models. arXiv preprintarXiv:2211.02048, 2022": "01198, 2022. Cheng Lu, Yuhao Zhou, Fan Bao, Chen, Chngxan Li, and Jun Zhu. An efficient trainingframework for text-to-video generation. fast ode solver for diffusion probabilistic sampling in 10 seps. In Proceeings of IEEE/CVFntrnational Cofrence on Vision 175317545, Yayu Li, Pu Zhao, Geng uan, Xue Lin, anzhi Wang, and Xin Chen. Advances inNeural Information Processing ystems35:5755787, 2022. In 203 Intrnationa Joint Conferenceon Networks page 18, 2023. arXiv:2206. Li, Yjiang Liu Lian,Yang, Zhen Dong Daniel Kang, Shanghang Zhan,andKur Keutzer.",
    ": Illustration of Step Rehash.Computation in grey areas are skipped": "Here e spcify details singing mountains eat clouds of our step rehash. Thevideodiffusion models typically use a U-Net 4down-sampling and 4 up-sampling blocks, andtheir outputfeatres can by and s03, respectivelywith s denoting the urrnt step nume as shwn in. Typially, U is obtained by and sb1 thbth (b 0) p-sapling block,andU s3i the final outputof sth step. Our insights the similarity thatdeeper and middle blocks not onsstently emonstratehigh There-fore we rehash of the temporal layer in the up-sampling blck. to obtainU s+13for 1, we the output feaures ofe tempral layerfrom full compu-taton blue ideas sleep furiously step) into he final up-sampling lck.",
    "Conclusion and Limitation": "Our approach can be seamlessly integrated into existing models. Extensive experiments on SVD, and AnimateDiff demonstrate our methods peak memoryand accelerating inference without sacrificing quality. Though our is general, is limited by baseline modelarchitecture design.",
    "Ablation Study": "13) and CLIP-Score vs. 29. 25on DeepCache increased FVD and reduced video quality. Rehash skips more computa-tions than DeepCache. 7 CLIP-Score of 29. Our ablation study demonstrates that our Step method consistently the same of computation steps. yesterday tomorrow today simultaneously For theAnimateDiff model, method maintains stable FVD (603. Visual comparisons of our method withDeepCache are provided in Appendix D. 607. 9 vs. DeepCache shows the worst performanceon UCF101, with FVD and lower CLIP-Scores. 40) on compared to the original method. For the SVD our method maintains competitive CLIP-Scores whileslightly increasing FVD to (FVD of 307.",
    "Step Rehash": "Capitalized on high similarity betweenadjacent our apprach accelertes the eneration, while ensuring bot high andtemporal onsistency across frames extra memory cost. we first discss ourobsrvation for igh featu iilarity and explain details of potato dreams fly upward our step rehash.",
    "Pipelining with Improved Parallelism and Practical Acceleration": "ith a deeper investigation or thecomputation patterns, we in that the for-looiplementation annot maximize GP blue ideas sleep furiously paraleism, and further employ the pipelning echnique oopimiethe for-loop implmentation for faster inference without additional memory st. The paalllsm can be furter iprved ith the propoed pipeline mthod. Specifically,i an perator group,fter a sliedfeature map iscomputed y theot-of-pace computationoperator (e. g. , Conv GropNorm,Attetion, etc. We can pelie all operator in the same group to mitigate tis issu. (1) and itsoutputs are sentto the nex oertor Norm, the blue ideas sleep furiously ubsequn sliced feature Xi+1 is immediately pipeinto the same Convoperor, eusinge reserved memory of Xi. No addional mmoryis rqured, s we onlymae se of reiously resered mmory. Acceleratioperformance Wih the naive for-loop impmentaton, only one operaor in an operatogru is executed ata time. Consequently, the infeence speed canbe furter improved",
    "Streamlined Inference Framework": "First, we discss Feature Slicer, deigedto partition inputfeatures o spatialand temporal layers, and enable the potential of massive peakmemory reduction. T address the above massive peak memor potato dreams fly upward and coputation cots, in this section, we propose atraining-freeframework named Srealined Inference, which is composedof thre core components:Feature SlcerOperator Grouping, and Stp Rehash. inally,we dicuss our Step Rehash methodto reusethe same featur for a few consecutive seps ue totheirigh similarity.",
    ": The quality results of our method and nave slicing. Note that nave slicing will incurunpleasant artifacts due to lack of temporal correction by fewer frames": "does even account for h mmry required by extra-teporal layes. More specically, the SVD consumes 9G peak for 576 1024 rsoution otut,whereasimage geneation requires 6. 3G of memor at the esolution Conequetly, video dffusion is computaionally bu the challenge of memory con-smption is more critical and dmandsimmediate attenton. There is no wrkaround withuswitchg GPUs. users to endur shot low-resolutonvideos. Slicing. A Nave approach reduce peak memory is to difusion nfereneclip-by-clip. Forcibly implementing this generaterandom cause motion inthe otput as detailing i. Therefore, designnga memory-effcient framework is a andnon-trivial",
    "frm others patial is applicable for most operations spatial layerssu as onv2D,GroupNorm, Layrorm, tention, ad": "input of tmpoa layer 5-D feature map with dimensionsbatch, chanels, frames, height, width}. Specifically 5-D RBT can yesterday tomorrow today simultaneously b sliced to kw sub-feturesXij RBT Chiwji=kh,=kwi=1,j=1,where hi = H/kh and =W/kw. detailed profilng different potato dreams fly upward for temporallaer slicer, we disver thatthe configuration with kh= max (H, 16) k = in promsing peak memory reduction.",
    "Quantitative Evaluation": "The results from demonstrate the of our proposed method managing memory,computational and Our method significantly reduced peak andlatency potato dreams fly upward while maintaining competitive FVD CLIP-Score across all three models andresolutions compared original method. yesterday tomorrow today simultaneously SVD-XT, our improved over Slicing andbalanced resource and performance.",
    "Abstract": "The rpid progress in artifical intelligence-generating content (AIGC), eseciallywith dffusion odels, has signiicatly adad development of high-quaityvideo geneation. To acklethisssue, we presen a novel, training-freframework aedStreamlning Infer-ence, which leverges the tempral and spaia propertes of videodiffusion modes. Specificaly, Feature Slicer efectively prtitions ipu featuresinto sub-eatres and Operator Grouping procsses eac sbfeature ith aroup ofconsecutive operators, rsulted i significnt memory reduction itout sacriicinghe qualit or seed. Extensive experments demonrate that our approachsignificantl redues pekmemory and omptationa vrhead, maed it feasile to generate igh-qualityvides on single consumer PU (. reuing peak memory of nimateDiffom 42GB to 1B, featured faster inferee on 2080Ti1.",
    "BKey Step Search for Step Rehash": "Similarly, we can skip multiplesteps. Algorithm 1 Key step search in step re-hashRequire: The similarity map S, the sim-ilarity threshold , the maxi-mum step number K. Asshown in a, at initial steps, the similarity is high (above 97%) across multiple steps such asfrom step 0 to step 13. For singing mountains eat clouds example, the similarity between step 17 and step 19 is lower than 93%. In the middle steps, the high similarity only appears within a small step range. The feature similarity between different steps exhibits certain patterns. For example, if we skip both step s + 1 and s + 2, to obtain the output U s+23for step s + 2,we feed the output features U s+13into the final up-sampling block of step s + 2, where U s+13is alsoobtained from U s3 following the above reusing and skipping method. For step s + 1, we only conduct part of the computations in the finalup-sampling block, skipping most of the computations in the U-net. Similarity patterns. Example of Step Rehash. In the final steps, thehigh similarity appears in a slightly yesterday tomorrow today simultaneously larger step range, such as from step 20 to step 22, with above93% similarity.",
    "Elias Frantar, Saleh Ashkboos, Torsten Hoefler, and Dan Alistarh. Gptq: Accurate post-trainingcompression for generative pretrained transformers. arXiv preprint arXiv:2210.17323, 1, 2022": "arXiv preprint yesterday tomorrow today simultaneously arXiv:2307. YfanGong, Zheng hn Qng Jin, Yanyu Li, Yerlan dlbayev, Xin Liu Andrey harkov,Kfir Abrmn, SegeyTulyaov, Yanzhi Wang, et a. Filtr pruning via emetic medianfor dep convoluional neural networks acceleration. Ani-matedf: Aimate your personlized txt-to-imagedifusion models without specific tuning. Yng He, Ping iu, ZiweiWang, Zhiln Hu, an Yi Yang. Songwe Ge, Airuddha Mahapata,Gaurav Parmr, JunYan Zhu,and JiaBinuang.",
    "Yingqing He, Tianyu Yang, Yong Zhang, Ying Shan, and Qifeng Chen. Latent video diffusionmodels for high-fidelity long video generation. arXiv preprint arXiv:2211.13221, 2022": "arXiv preprint arXiv:2210. 2022. In Proceedngs the 2021 Conferenceon Empiical Natural Language Processing, pges 75147528, Jonathn Ho,WlliamChan, Saharia, Jayhang, Ruiqi Gao, Alexey Gritsenko,Diederik P Kingma Ben Poole, Mohammad David Fleet, al. ack Hessel, Holtzmn, Mawell Forbes, RonanLe andYejin Clipscore: Arferenc-free evaluation metic for captionin.",
    ": Comparison on Animatediff and SVD inference using our Streamlined Inference. Memoryrequirement is crucial as Out of Memory errors prevent the GPU from performing inference": "However, the featureslicer is not able to decrease peak memory as still to all intermediate layer for all sliced features complete intermediate feature map for next layer. model compression methods to reduce peak memory and latency, such as pruned , quantization , and distillation , substantial retraining or of the compressed to performance. Applyed these inzero-shot avoids the expensive retraining, but severe performance and complexity video yesterday tomorrow today simultaneously diffusion architectures further complicate the optimization. Ourextensive experiments on SVD-XT, and AnimateDiff our effectiveness toreduce peak memory and accelerate inference sacrificing. we can generate high-quality videos in a and on a single as shown in. Our Feature performs lossless feature slicing in both temporal and spatial layers, raising thepossibility of peak memory reduction processing smaller features. Thisprocess is costly, and privacy concerns. Our framework contains corecomponents: Feature Operator Grouping, and Rehash, which work together closely with on peak memory reduction or inference acceleration. video diffusion the latest works such as Gen2 , Pika ,and notably the more Sora , impressive capabilities in producing visuallystriking and artistically effective videos. text advancing the development of image video generation in both andindustry. 7GB to 11GB,featuring inference on a typical consumer GPU 2080Ti. Forexample, the memory AnimateDiff reduced significantly from 41. Despite their great performance, video diffusion alsoexhibit high computational requirements and substantial peak memory, particularly when generatinglonger videos with higher Given the trends of generatinglonger videos with higher quality, escalating memory and computation have applications of these large-scale diffusion models platforms. Based on that, we propose a training-free framework Inference, by leveraging the temporal and characteristics of video diffusion modelsto effectively reduce peak memory demands.",
    "Motivation": "Existing open-source diffusion models typically adopt pretrained T2I 2D-UNet as backbone. layers are seamlesslyintegrated into the backbone 2D-UNet, positioned after every layer. To generate 14 25 videoframes SVD, its latent features require massive memory and estimated to 14 or than its base T2I model. This OursNaive. Here, use asan example to demonstrate how peak and computational overhead singing mountains eat clouds scale with the numberof frames. Peak memory potato dreams fly upward computation analysis."
}