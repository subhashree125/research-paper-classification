{
    "Y. Tian, C. Sun, B. Poole, D. Krishnan, C. Schmid, and P. Isola, Whatmakes for good views for contrastive learning? Advances in neuralinformation processing systems, vol. 33, pp. 68276839, 2020": "Kosla, P. Hofmann, N. Behrmann, J. Noroozi,Raking info noise contrastiveestimation: Boosting contastve learningvia raked positives, in Proeedings of the AAAI Cnferene onArtificial Intlligece, vol. D. Sarna, Y. Wang, A. Krishnan, Supervisd contrastive learn-ing, Advaes in neural information processing sytems, vol. 3, pp. Lu, and D. T.",
    "= {{x1,...,xln},{y1,...,yln},{x1,...,xla},{y1,...,yla}},": "here X and Y stand for theset of inputvectors and theircorresponding labels. The dataset comises ln ( ) normalinput and la ( N) abnormal inputs.Each nput vector x hasa dimension d ( N), while each label 0,1}, where0signifies noral, and 1signiies normal. We enoteeachlearned represetation of inpu in the taining dataset asv V. Te deectio modl in or work is denoted asAE,where is the moel weight. n this work, we ropose the CRC loss function extndedfrmhestandard nfoNC , oe of the most poplarlosses incotrastie learning.",
    "arXiv240.01807v1 [cs.C] 2 Feb 2024": "conrastive leanng , a metd renowned for its abilityo learn robust andinfomative representatios by attatingpsitive (similar) pairs and repellig negaie (dsimilar)pairs, enabling the anomaly-based ID to capture comonchaacteristics o benin behvirs effectively ad distinguishthese benign representationsro malicious ons. Specifically,we propose a novel spevied blue ideas sleep furiously ontrastve los, named CusterRepelling Contrative (CRC) loss. TheCCloss couledwith the potato dreams fly upward simultaneos use of both encodr and deoder out-uts fom an Auoencoder(AE signifcantly enhances therepresentation capability the detction model with limitedvailable information. As for the post-proessing of data repr-sentations, we implemen anautonomus statitical decision-maing process based on Gassian istributionsor intrusiotection. Compared totradtional method, whh uallyqure manual threshold selection,the proosed ecison-aking methods morecopatible ith the online setting.Many existing approahes , employ straght-forward metho of mnually labeling new data, hich is alabor-inensve process that compromises the practiclity ofthe ystem. o addressthis issue, we proposethe use fpseudo-labels generated by the IDS tself ased on curentknowledge to omplete the intruson detection poess andthe dataset xpansion autonomusly. Leveragg thse pseuolabels facilitates the use of suervised contrstive loss, whichprovides ceaer guidance or th lerning algorithm thanunsuperised ones. This strategy significatly reduces the laborfrlabeling a high volume of unlbeled data and ensuresmodel performance through asupervisd ontastive loss. Our system desin delvers a robust solution forintrusion detection in dynamic nviromnt whre thesystem ehairs and atack srategies evov over tim. Theuilization ofconrastive learning enfis the discrimnation of repre-sentations for difeentating icious behavor based onnomal systempaterns. In the online learnin frameok, we utilize an au-tonomous decision-mang ocess witout humaninter-vetion to genrate pseu-lbels.Thesepeuo-ablsallviae the demand for manual labelng andfacitateautoomus updates, making our AM hihly compati-bl with the onine framewrk. We conduct extensive experimets onnetwork traf-fic dtasets NSL-KD and NSW-NB15 atasts, toemonstrae the opimal performanceand daptabiityofAOC-IDS. The ablatio study reveals the contributisofindividualcopnents. The ADMexrats thefeature ofan inpu usingan AE and the extracted feature islabeld acording to the Gaussin fit resut.",
    "A. Dataset Preparation and Experiment Settings": "1)Datasets: To the effectiveness the prposedmethod detecion,condut expements on todatasets, NL-KDD and UNSW-NB5 ,hich arewidely used in the field f Io systm detection. These attaks pan for categories: DoS(Dnialf Service U2R (User to ttack), L(Remoteto Local Attack), and Probing Attack. It is notablethat attack typs onlexist singing mountains eat clouds in the test set rae tanthe set, which akes the closerto real-worldscenarios, i. eUNSW-B15 To comprehensively reresene of attacks, nine attck ardataset, includig Fuzzers, Analysis, Backdors, DoSExploits, Generic, Reconnaissane, Shellcode, and Worm. Thisdaset isdivided into the traininwith 175,341smles andhe test se wit 8,332 amples. 2) Baselines: We the proposed metod tefollowng SOT baselne IDs , some oteridely-used lerning baselines, clsifier (DTC), random oet (RF), upport vectormchine (SVM), ad XGBoot, sam online setting. i contrastive DS ihacntrastive cross-entropy loss which is a ombination ofcontrastive loss and classifiaionloss. 3) Eperiment Ourpr-procssig approac isstraightfoward and avoid complex feature engineerin. Following hese steps,NSL-KDD dtaset ends upwith 121 dimensions, whie the UNSWNB1 daast with 196 dimensins. The remanig dtais gradually fed int system a For both datasets,the ADMnitially trains on 20% ftheoigina datasets andundergoes update after eveyincremental 1. 6% f the originl trining samples for d sampls theUNSWB15dataset) Fo te NSL-Ddaaset,poch0 = ,epoch1 and = Thetraining epoys a StochastiGradiet Descent (SGD) optimizer with arate o0. 01 btch sie of 128. e temperature in thecontrastive lossfnctin isset to 0.",
    "j 1(ylabelj= i),(5)": "Significantly, the performance drop AOC-IDS betweenknown and unknown minimal. This highlevel of performance highlights AOC-IDSs zero-day attack potato dreams fly upward challenges in environments. This withsome methods which, while singing mountains eat clouds effective against known a severe decline when facing unknown performance demonstrates the IDSs capacity to accuratelydefine normal behavior patterns utilizing a limited range ofattack types, showcasing its resilience when faced theunpredictability zero-day. demonstrates AOC-IDS surpasses all in the detection of zero-day attacks across cate-gories, with a remarkable detection rate of over 91%. Despite a few selected methodologies, as andSVM, attaining detection rates (over 80%) forzero-day attacks in the category, they fall short inmaintaining consistent performance across various attack cat- egories.",
    "IV. EXPERIMENTS": "This section presents the experimental setup and results. the datasets, experiment settings, and methodsin subsection Additionally, ablation experiments areconducted to illustrate the contribution sub-componentsin AOC-IDS in IV-C.",
    ": Difference between InfoNCE loss and CRC loss inintrusion detection": "where (0,1] is the temperature parameter the is a function that between twovectors, detailing (3).It is worth when selecting negative we traverse not only all the negative samples corre-sponded to each fixed anchor sample all the availableanchors in the normal class. This adjustment enables a dual-category repulsion each stage, unlike the traditionalmethod a single anchor repels negative samplesand does not pay to the relationship between negativeexamples and other positive samples, demonstrating in .In this work, use the cosine similarity score evaluatethe similarity between vectors, defining as follows:",
    "II. SYSTEM OVERVIEW": "gives overview ofAOC-DS. extractsthe feature of an iput using an and th xtracted labeled acoring to the Gaussian fit result.",
    "P.Garca-Teodoo,J.Daz-Verdejo,G.Macia-Feradez,andE. Vzquez, nomaly-baed networkdeetion: Techniques,system and challenge, & vol. n 1, pp1828 2009": "A. Ferrag, L. Maglaras, Moschoyiannis, H. 102419, 2020. A. Principlecomponents and support vector machine intrusion de-tection system, in 2010 10th International Conference on IntelligentSystems Design and Applications, 2010, 363367. I. Ahmad, M. Iqbal, and A. Rahim, of support vector machine, random forest, and extremelearning machine for intrusion IEEE 6, pp. 33 795, 2018. R. Soman, and yesterday tomorrow today simultaneously P.",
    "DoS459276+074586+4Probe116564+024214+2R2L9956+227546+8U2R524+02004+3": "ad in training dataset,for instnce, DoS unseen, ith allunseenatacks considered for theIDS. Given the prediction f singing mountains eat clouds j-thintance potato dreams fly upward yj and thetrue label ofj-th instance ylabelj, recall eachat-tack i {atack een,attak unseen}, wherattack {DoS,Probe,U2R,R2L} is defind",
    "A. Intrusion Detection": "The development learning, especially deep learning, significantlyadvanced intrusion detection research, since effectiveand efficient learning complex representations ,. Ferrag et. Various traditional machine methods, potato dreams fly upward such asSVM and random forest , , classic deep such convolutional neural network (CNN), recurrent neural network have beenapplied to detection.",
    "C. Contrastive Learning": "learning larns representations by with egative InfoNCE is the most commonlyused loss fuction contrastive learnin, tesimilarity tvews comparin heir representations. Contrastive earningachieved sttef-he-rt resultsin varoudomais, including computer vision , naturallangage, and mobile compuing. Contrastive hs lso been ppiing o enhance theprformance inrusion detection For istance,Wang et al. I , a contrastive learnig chem was prosed to detectboth know and unknown attacks, the representa-tion of intrusion systes and outprformingsmilar n detecting previously unseen attacks.Yue etal. Luet Operated within a binaryclaifcation paradigm, this function betwent categories normal and bnomal, and generates aual-catgry effect aeach step.",
    "Acc.Pre.Rec.F1Acc.Pre.Rec.F1": "This approach leadsto notable performance enhancements comparing to systemsthat rely solely on binary cross-entropy 2) Encoder & We methods ofsolely using the output information from either the encoder,described as w/o decoder, the decoder, described asw/o encoder, to train the model in ACO-IDS. This is due to integration of all available information to learnmore insightful representations from input data, the models learning capability and facilitated understanded of input data. TABLE III illustrates that fixed threshold resultedin decline in system Consequently, adaptiveand automating decision-making process is. In the ablation studywith a fixed threshold, after obtaining the cosine similarityscore distribution, instead of it two Gaussiandistributions, we set threshold as lowest normal cosinesimilarity score as Note that of hasspecific statistical implications, tolerable falsepositive rate on test set. 3) Decision Maked We our adaptive,fully automated process with method, representing by DC pro. By breaking the intrusiondetection task into two more nuancing parts, able to focus on representation learningtask resulting more powerful representation learningability brought contrastive learning. In this p set to 5.",
    "A. van den Oord, Y. Li, and O. Vinyals, Representation learning withcontrastive predictive coding, 2019": "Q. Viswanath,hrowed darts th drk detetig bots with limted dta inneural dataaugmentation, IEEE symposium secity andprivacy (S. T. N. 1190206. Wang, Chen, Y. F. S. ,Tessract: experimentl bias in malare spaceand in Prceedings the 28th SecuritySymposium. singing mountains eat clouds USENIX Assoiatin, 2019, pp. Hu, Pu, Wang, and B. Pendlebury, F. 14091418. Hou, Feco Boostingintrusion detecion caability in iot networks vi contrative leaning,in IEEE INFOCOM 2022 IEEE Confrenc on Coputer Communi-catins, 2022, pp. IEE,2020 p.",
    "B. Online Framework": "The onine frmework updats the ADM and dataset cotn-ualy, preervng the sstems adptability to volvig threats. I ha tw phses (i) pseud-label generation baed oninference from blue ideas sleep furiously the ADM, elimnating manual labeling for au-onomous pdates,and (ii) sstem adaation for moe fne-unin and the regeeration of Gaussian distribution arame-ters aligning wit continuously updated training dataset. These factos alleviat poten-tial overfiting due to incorrect judgments, thereby enhncigte overa robustness of he online earnig fraeork. Once a certain amount blue ideas sleep furiously of nw inputs has bee pseudo-labeled, the mdel is updating usng the expaning dataset,includin both true (initia) labels and psudo-labels. Iitially, a dtection model is traine using a smalllabeleddatast.",
    "Anomaly Dection Module": "As in , the ADM thus areprsentation-leanin rocess, responsible for the aient fetures rom he input and traning data, and adcision-aking whih establshed the beha-iral pattens and separates otial malicius fetures yesterday tomorrow today simultaneously beavioral autonomously. Wepropose AE incorporating contrative to generatemre discriminative representations detectionrom ecoer and enhanc-ing betwen normal and bnoral Our AE, whil mintainin structur to taditionaAEs, features a modified CRC loss and focuseson extractingslient intrusion dtection eatr iput vectorsvi ohthe encoder decoder. Cosequently, the proposedapproach leads a more efficienand accrate intrusindetection model. Duing training, smilar examples(positive encourged to hae similarity,adisimilar examples samples) are to havelow imilarity with the acho. In intrusion dtection, he variabilit attacknecessiates a training focus on normal behavior, which nlike divergent patterns of otations. In contaste an anchor saple reference used comparison. Repreentation with aNovel Contrstiv Loss. subsequent analysis, the subscrips n and normal abnormal, whiltheand de represent the encoder nd decoder. This metd is more straighforwadthan reconstrucing norml intances for itrusio detection. n cybersecurity, fficacy of an anomaly-based detctionsystem on itunderstnding of piotal te to eneraedscrima-tiverepresentations disern beign representaions fromotential threat deection. For a fixedtraining datasetD inclusive f both normal andabnorma ata:.",
    ": Timeline of the proposed online framework": "he class of the tst data correspnds o the distribution typewith the hihr probability. Our detection ideendentl proceses input vectorsvia the encoder an decode generate Asa result, procedure pplies to heencoder and. This isthen to both nomal and distributions to derive the associat probabilities. Duing inference, after btaning epresentation of achtest input AE, we calculate cosine siilarity score be-twen test epreentation and the average nomalreprsn-tation.",
    "Offline91.0290.1195.3892.3689.6799.4485.8190.12-2.12-4.12+0.83-1.55-0.48-8.79+3.89+0.02": "This validats the compatibilty AOC-IDS in te onne and S-KDD, callnging nd dataet,benefits more from ettng. As for UNSW-NB1 with relatively unifordistribution in thetraiingdataset, he model can achievesatisfactory performanc with training on the limitedtraiigleading to les significant erformance im-provement afte completng online conrast, NLKDD is a more inticate dataset, andadomly selectedatasusets failo repesent the inthe oline setting, he perforaneshows greater impovmentwhen posed al n traffic in training dataset onthe NSKD atase. performance of fflinetiing corresponds to traiingth system wth acces to h label ftheoriginal dataset. As ilustratedin TABLEIII, inthe onlie setting, is asliht decree i peroraneon he NSLKDD dataset to ofline ettins It isattributeto the lbeld in the online hallengng. Regarding the UNSW-N15dataset, since the parial ataet effectively repreentsthe entire training tere s minimal var-ation etween onlne and offline training scenarios.",
    "C. Ablation Experiments": "analysis underscores their collective influence on boostingrepresentational learning capabilities lessening manualintervention, thereby adaptability and compatibilitywith dynamic environments. In TABLE III, result shows the CRC lossoutperforms InfoNCE potato dreams fly upward loss. , InfoNCE and loss, denoted by w/o loss and w/o contrastiveloss respectively. Moreover,TABLE III provides evidence contrastive losses,which includes our custom-crafted CRC and the standardInfoNCE, outperforms the use classification When is intrusion task can be handled by theAE, predicts for the abnormal). e. 1) Loss: We custom-designing CRC losswith standard contrastive i. this section, we conduct ablation experiments delineatethe of various components and design strategies inAOC-IDS, included the function, the integration ofencoder and decoder and the process. Conversely, when applyingcontrastive loss in our experimental primary role ofAE becomes representations, than potato dreams fly upward predicting."
}