{
    "Icek Ajzen. 1991. The theory of planned behavior. Or-ganizational behavior and human decision processes,50(2):179211": "arXiv preprint arXiv:2305. Preprint, arXiv:2306. Homan, Alicia Parrish, Greg Serapio-Garcia, Vinod-kumar Prabhakaran, and Ding Wang. 12712. Language models are few-shotlearners. 11247. 2023. 12947. Jan Cegin, Jakub Simko, and Peter Brusilovsky. arXiv preprintarXiv:2303.",
    "A.1Evalution of Generated Citeria ords": "While ost of thegenerated citeria wordssemd toentai thei crresponded opinions, wealso potato dreams fly upward found sample whose criteriaadded by different words in opinionsfor representaton. w areedto considr singed mountains eat clouds and authenticity as he a-ditinal criteria since thse ord also em-phasize individuls abliy determin theirstane in Also, thre are somesamles of crieia ordsthat entail coresponding opinion but donotcove the mai value of the opinion For a sttementIf yoreyu hul go o a nist beach,the crteria wordsgeeraing y GPT-3 in a settig ae nudit and ach n he followingopinion: If yor anudist, should go to anudit so ou can bearund like-mindedpeope and. 5 delivrthe messge corre-sponding instance, the opinionSme people rritable by nothig wrong with tat.",
    "Output:": "\"},10:{\"Stance\":\"Disagree\",\"Criteria\":[\"culturalsensitivity\",\"respect\"],\"Reason\":\"Helping others in tough situationsshouldbedonewithculturalsensitivity and respect, as imposingonesvaluesandbeliefsthroughhelpingotherscanbeharmfulanddisrespectful. \"},7:{\"Stance\":\"Agree\",\"Criteria\":[\"altruism\",\"generosity\"],\"Reason\":\"Helpingothersintoughsituationsisanactofaltruismandgenerosity,anditcanbringasenseoffulfillmentandpurpose. \"}, 4:{\"Stance\":\"Disagree\",\"Criteria\":[\"self-preservation\", \"priorities\"],\"Reason\":\"Insomesituations,prioritizingself-preservationandpersonalprioritiesmaybemoreimportantthanhelpingothersintough situations. \"}, 3: {\"Stance\":\"Agree\",\"Criteria\":[\"moralobligation\",\"responsibility\"],\"Reason\":\"Asmembersofsociety,wehaveamoralobligationandresponsibility to help those in need, especially in tough situations. \"}, 9:{\"Stance\":\"Agree\",\"Criteria\":[\"humanitarianism\",\"globalresponsibility\"],\"Reason\":\"Helping others in tough situationsisapartofhumanitarianismandglobalresponsibility,anditcancontributetoamorejustandequitable world. \"},2:{\"Stance\":\"Disagree\", \"Criteria\":[\"safety\"],\"Reason\":\"Helping others in toughsituationscanputonespersonalsafetyatriskandmayviolatepersonal boundaries. \"},8:{\"Stance\":\"Disagree\",\"Criteria\":[\"personalboundaries\",\"consent\"],\"Reason\":\"Helping others in toughsituationsshouldrespectpersonalboundaries and require consent, asforcinghelponsomeonecanbeharmful. \"},5:{\"Stance\":\"Agree\",\"Criteria\":[\"community\",\"solidarity\"],\"Reason\":\"Helpingothers in tough situations fostersa sense of community and solidarity,and it can strengthen social bonds. \"}}. {1:{\"Stance\":\"Agree\", \"Criteria\":[\"empathy\",\"compassion\",\"kindness\"],\"Reason\":\"Helpingothers in tough situations is an actof empathy, compassion, and kindness,and it can make a positive impactontheirlives. \"},6: {\"Stance\": \"Disagree\", \"Criteria\":[\"enabling\", \"dependency\"], \"Reason\":\"Helping others in blue ideas sleep furiously tough situationscanenabledependencyandmaynotaddresstherootcausesoftheirproblems.",
    "ContributionsFirst, we propose perspective di-versity as a new focus for generative LLMs, dis-tinct from lexical, syntactical, and semantic diver-": "Finally, we suggestastepby-step recall p-proach t measre extent of diverity coverageof LLMs, comparing the covrage between LLMgeneratd opinionith human-authored opnons Ou studyrevealsa saturtion pointin the diver-sity hat LLMs cn achiee, depending ote sub-jectivity of a task.Howeer ome re-qent crita wors by LLM are differen fromwhat hmans consider as iportant.",
    "(b) CMV": "From this study, the anno-tators agree that an average of 80. Two human annotators manually inspect1,159 clusters of criteria words from 100 randomlysampled statements across SOCIAL-CHEM-101,CMV, HATE SPEECH, and MORAL STORIES (25statements per dataset). The results on SOCIAL-CHEM-101 are statistically significant with p < 0. : Semantic diversity score for different LLMs and prompting methods for SOCIAL-CHEM-101 (left) andCMV (right) datasets. 85%. 95% of those clus-ters of criteria words have similar meanings withinter-annotator percentage agreement of 88. 01 for GPT-3 and Mixtral for CMV. 05 (GPT-4) and p < 0. with similar meanings can be conveying in differ-ent ways. For instance, given a statement It isexpected that friends will enjoy being around eachother, the model could generate two opinions; anopinion may contain joy as one of the criteriawhile the other opinion contains happiness.",
    "Hate Speech": "1. They discern this as an attempt to exclude nd belittle ndiviuals wh chooses wer promoting",
    "Model Output": "{1:{Stance Agree\",Criteria: [teamwork, goals],Reason: In a setting, instructions orders can be necessary for achievingshared {Stance: ...\", Criteria: [...], Reason: ...\"}} : Example prompt criteria-based prompting. Prompt for free-form prompted all the sameexcept for not haved Criteria. Full prompts free-form criteria are shown A.2. Since social norms on factors groups beliefs cultures (Ajzen, 1991;Shweder, this is suitable for our taskof maximizing LLMs diversity capability. Forour study, sampled 500 texts thecriteria-basing vs. free-form prompting experimentand 200 texts for the step-by-step recall CHANGE MY VIEW de-bates online forum threads of the subredditChange My View collecting Hidey al. (2017).We the title blue ideas sleep furiously each discussion itis usually the claim of argument, resulting ina total of 67 claims. We this dataset toexamine if LLMs can produce highly subjective task because argumentationtask be highly controversial (van Eemerenet al., 2015). HATE SPEECHdataset texts catego-rizing either hate or speech. (Vid-gen al., 2021). From this we randomlysample focused only on implicithate which are harder to a subjective task because an-notators background may how they thehate speech label of a text (Sap et al., 2019; al., 2021). We add this task for the step-by-steprecall prompting experiment to show criteria-",
    "Ethan Perez, Douwe Kiela, and Kyunghyun Cho. 2021.True few-shot learning with language models. Ad-vances in neural information processing systems,34:1105411070": "n Proceedings of the 209 Conference onEmprical Methods atural Pocessingand the 9th Joint Natu-ral Proessed pge3982399, Hong Kng, Chia. 201. 2022. Association Com-puational Linguistics. Assocition fr Liguistics.",
    "Step 2: Step-by-Step Recall Prompting Diversity": "In this experiment, in prompt. Once we identify the best setups, we expand ourdiversity prompting to include recall prompting to the LLMs diver-sity coverage. Without 1-shot weaker LLMs of-ten struggle to produce structured outputs.",
    ": T-SNE for opinions written by human andgenerated by GPT-4. LLM can mostly generate bothagree and disagree opinions that align with humanwhen they are semantically close to the statement": "From eachmodl and umans, we select the top 5 frequncrteria or acros singing mountains eat clouds all statementsandvisualizetheir embedding on a T-SNE plotFor agreeig opinions, in general three LLquite align wih hua GPT- nd Llma3 haverespect as the most frequent criterion, and athree LLMs regar responsiility, safety andemapthy s imprtant criteria. Criteria Words by Different LLMs adHumasWeanalyze the potato dreams fly upward frequet cteri words eneating byGPT-4, Llama3, Mixtral, andhumansusig T-NEembeddings in for agreeed an disagree-ing oinons in SOCIAL-CHEM-101.",
    "(d) Moral Stories": "with zero-shot promptin, fwer almodelswith oneshot promptng (GPT-4:. , GPT-4o: This indicates tht in five-sht prompt-ing, modeltend o ore closely to ivenexamples, resulting inless divese output to the one-shot hypothesize tatthis occursintroducing criteria in cncretexmples ay confusethe modl. 9 Llam3 0, Mixtral: 9. aresult, the model produces fewerdivese diverse perspectivs compaed to the sim-pler rompting. X-axis he generated opinionsfor o covrage experment. his aligns with our pilot study where askng cri-tera ihou xamples ved for themodel. ate morediverse reson wih pomping.",
    "-shot1006832988216": "5 1-shot setting were entailed byits respective criteria words. orexample, 96 (%) out of 100 opinins gnerted by criteriaprompting withGPT-3. : Number f generae opinionswith criteria-based prompting infur different LLM variants.",
    "Yao Lu, Max Bartolo, Alastair Moore, Sebastian Riedel,and Pontus Stenetorp. 2022. Fantastically ordered": "promts and whee to find tem: Ovrcoming prompt orer senitivity.I Procedings of thethAnnual Meeting of the Association for omputational (Volume 1 Long Papers), Dubin, SewonLewis, and Hannaneh Learning to learin contet. foComptational Linguistics",
    "Motivation": "these couldbe more diverse as they are grounded in the combi-nation of various criteria words. We refer yesterday tomorrow today simultaneously to framing keywords ascriteria. Effective debatersoften employ to shape theirarguments persuasively coherently. First, we present motivation ap-proach. Imagine engaging potato dreams fly upward a debate with some-one over a controversial topic.",
    "Models and Prompting": "with four varants:GPT-4o3, GPT-4, GPT-3. We alscompae with five-sot acrssall nd zero-shot only for model, as weaker models mastruggle structred outputs ithout ste-by-tep recall prompting experi-ments, w vary number of generated. 2024). Our baseline free-formprompting wee te model potato dreams fly upward its stanceand reasoning withot gnerating critria wrds. Ourriary prompting setup in-contet learn-ing with one example of ten pinionsper statemen.",
    "Input (one-shot example below)": "\"},2: Stane: Disgree\",Criteria: [trnsparency, trust],Reason: Lac of privcy cn promote transparency andbuild trust in relationships. 10: {Stane:. Statement: xpecing to do what you are toldTel me staemen as may as possibledifferent people ith, Agreeor one-word orone-phrase criteria is important for their explain how have opnionsutpt:.",
    "Limitations and Ethical Considerations": "Currenty, werel on LLMs (GPT-4) generate yesterday tomorrow today simultaneously wordsfrom no-criteia promptng outputs. worksould dea in-depth these extracion and analyss on te wordthemselves. We t demographics of rowd-orkers who particiate inthe opinion writing areskewedtoward whte with bachelor deree a education For fuure beinteres-ing t compare opnions itten by partici-pants from other cultures with te models opinions.also have ntexplored ll of setups of decoding parameters esidescompigdiffeent temperturesand sam-pling the initial experiments Potentil coldbe a situation singing mountains eat clouds hereourcriteria-based attepts to generate di-versecertain topics tht are and/orharful For human stdy, ourntiution dtermnedour as IRB review.",
    "Semantically Diverse Opinions aboutSocial Norms and Argumentation": "When we prompt GPT-4 without andask for structured only, it tends to gener-. presents our experiment findings regardingsemantic diversity. One-shot prompting on GPT-4 produces notably more semantically compared models. models Mixtral and GPT-3 benefit mostfrom having criteria to guide them generat-ing semantically diverse opinions.",
    "Statement: Its okay to have privacy.Tell me opinions about the statementas many as possible from differentpeoplewith\"Agree\"or\"Disagree\"and explain how they have differentopinions": "\"},10:{\"Stance\":\"Diagre\",\"Reason\":\"Limitedprivacy enhanes safety securityby llowing for greate sureillanceand monitoring o individuals. \"}Statement:Its good cofide nyour parents hethat yourestrgligwith. \"},4:{\"Stance\":\"isagree\",\"Reason\":\"Reduced rivacy \"}, 5: {\"tance\": \"},8:{tace:\"isagree\",\"Reason:\"Reducedpivacyromoesopennesandhonsy,asindiidualsaemretansprent about action andintentions. \"}, 9: {\"Stnce\": d self-dicovery,oviingasaceforndividaltoxloreteirinterestsandidentities. Tellmepinonsaboutthestatementsmanyaspossible from different with\"Agree\" andexplainhave opiions. Output:{1:{\"Stace:\"Agree\",Reaso\":\"Havingprivayallowsindividuastoesalishpersonalboundareandmaintantheirautnoy.",
    "(d) Stance: Disgre": ": The distribution o huma-written opinons, separated by humn stance n givenstatements, inSOCIAL-CHEM-11(t) and CMV (bottom). Paler-colored bar represetinsancs here participants were askedto wrte opnons that opposed thir persoa stances a stateme.",
    ": Demographic statistics of the participantsof - (3) Highest Education Attainment. Weobserved most of the participants obtained bachelorsdegrees": "we singing mountains eat clouds compute he proportio statementswhere criteriabsed prompting wns, yesterday tomorrow today simultaneously out of the 50statements (denoted as rate of criteria-basedprompting). For each statement, wokers were then askedto their own on that statement andchoose between A and B interms which setpossesses a mre diverse toward a pool of with better- quality we ra trainin sesion real task whee alsofiltered out whose di ot make Fortheir each participan rceived $0. 5USD paymet orcompting the regardlesof quality o onsidering thimplicity of tas and anticiated ofcompleton to be less than minus. fo ech ession,they select A r B, which they in-cludes a greaterof persectives that showthe same stace. randomly sampled 50statements foma ataset 5 in an one-shotsetting (1) Set generated with criteria-basedprompting, and et B fre-form prompting.",
    "Kuan-Hao Huang, Iyer, I-Hung Hsu, AnoopKumar, Kai-Wei Chang, and Aram Galstyan.": "In Proceed-ings of the 61st Annual Meeting of forComputational Linguistics (Volume 1: Long Papers),pages 80478061, Toronto, Co-writed withopinionating language users the CHI Conference on HumanFactors in Computing Systems, 23. Jiang, Alexandre Arthur Men-sch, Chris Bamford, Singh Diegode las Casas, Florian Bressand, Gianna Lengyel, Guil-laume Lample, Lucile Llio Lavaud,Marie-Anne Lachaux, Pierre Stock, Teven Le Scao,Thibaut Lavril, Thomas Wang, Timothe Lacroix,and William El Sayed. Q Jiang, Sablayrolles, AntoineRoux, Arthur Blanche Savary, Chris Devendra Singh Chaplot, Diego de las Casas,Emma Bou Hanna, Florian Bressand, al. Rebekka Johannes Keller. Preprint,arXiv:2310. diversity representation in large language mod-els via collective-critiques and self-voting. Proceedings the 58th Annual Meeting ofthe for Computational Linguistics, pages62826293, Online. The rela-tion between human values and perceived situationcharacteristics in everyday in Psy-chology, 9. arXiv preprint arXiv:2401. Preethi Lahoti, Nicholas Blumm, Ma, Kotikalapudi, Sahitya Potluri, Qijun Tan, HansaSrinivasan, Ben Packer, Beirami, Alex and Jilin Chen. 2023. 16523. 2018. Place: Switzerland FrontiersMedia S. ParaAMR: A large-scale syntactically diverse para-phrase dataset by AMR back-translation. 06825. Preprint,arXiv:2310. InProceedings of 2016 Conference of the NorthAmerican Chapter the Association for Linguistics: Language 110119, Diego, California. 04088. A. Pratik Santy, Amar Budhiraja, and Monojit Choudhury. Mistral 7b.",
    "Diversity Coverage by Sep-by-Step RecallPromptin": "shows an increase in the number of uniquecriteria clusters as the step size increases for the re-call step-by-step experiment. For SOCIAL-CHEM-101 and CMV, the model on average generates 8unique criteria clusters for agreeing and yesterday tomorrow today simultaneously 7 for dis-agreeing opinions. On the other hand, MORAL STORIESshows a different trend, with model generatingan average of 20 unique criteria clusters.",
    "A.9Imbalanced Number of GeneratedOpinions in HATE": "This occurrence is substantially higher compared tother datasets, potato dreams fly upward were SOCIAL-HM-101ratedan mbalanced number of opinions etween stancesfor only 0. We observed ha GPT-4 generate an imalancednumber f opinions etween Hate Speech ndNo Hate Speech wen choosing the abels dur-ing the step-by-step recall propting exeriments(N = 20) for 37. 5% of the total 00 statements.",
    "Abstract": "We intoduce the probemofetacingmaximum divrsity from LLMs. Inthis study, we exploreLLMs cacity of ge-erating diverse perspectives andrationles onsujective topicssuch as soial rms ad a-gumentative texts. Tsee how ar we ca extractdiverse erspectivesfrom LLs, ocalling diversity coveage, wemploy a ste-by-stp recallpromptig to gen-rate moeoutputs from modeliteativel. ur ethods, aplied to various tasks, showtat LLMs can indeed produce divers opinionsaccordi to the gree o tasksubectivt. This lead to a recent trend ineploied large lanuage models (LMs) forgenraing divese ata for potntial scalableand efficnt solutions. Collectng divrse hmanpiins is costlyand challenging. However, he extentto whch LLMs can geerate diverse perspec-ties n ubjectivetopic is still uclear. Wealso find that LLMs performance of extracinmaximum diversity is on parwith human. Motivated by how hmans form opinions basedon values, we propose a cteria-based prompt-ing tcnque to groun diverse opinins. 1.",
    "Introduction": ",2022). In-stead of providing a single viewpoint, an ideal NLPmodel should accommodate various perspectivesto avoid any bias towards a dominant one. Used NLP for tasks that require social reason-ing or involve human subjectivity like argumenta-tion (Hidey et al. Some studies have addressing this challengeby gathering responses from multiple human an-notators with diverse backgrounds (Rottger et al. Priorworks emphasize the importance of modeling mul-tiple viewpoints (Plank, 2022; Abercrombie et al. , 2017) or toxicity detection (Sapet al. ,. , 2019) often calls for diverse perspectives.",
    "Related Work": "(2020)argue that NLP research is biased toward Westernperspectives. ,2023). Diversity Generation by LLMsLLMs havebeen utilized extensively to produce diverse syn-thetic datasets, such as paraphrasing (Cegin et al. , 2023);(3) semantic diversity (Stasaski and Hearst, 2022;Reimers and Gurevych, 2019; Zhang et al. To promote opinion diversityin LLMs, Aroyo et al. , 2020);and (4) perspective diversity (Plank, 2022; Hayatiet al. , 2023b; Taori et al. (2023) in generating multiple re-sponses per prompt. , 2021; Santy et al. Our work alignsclosely with Lahoti et al. Our work aligns closely with prior studieson perspective diversity, specifically in examiningstances and rationales generating by LLMs. , 2022), and instruction datasets (Wanget al. (2023) by advocatingfor fairness in LLM outputs through perspectivediversity, which goes beyond semantic variability. Ourwork is important to uncover extent to whichperspective diversity can be extracted from LLMs. Some studies focuson annotator diversity (Rottger et al. , 2023; Honovich et al. Despite previ-ous claim that LLMs can produce diverse content,some studies suggest that co-writing with LLMsmay affect human writers opinions (Jakesch et al. , 2021), while others examine diversity in gen-erated language (Hashimoto et al. Our research addresses this gap byproposed a method to generate diverse perspec-tives rather than a single dominant opinion. , 2019; Liu et al. Unlike diverse large-scale data generation,Lahoti et al. Diversity in NLPDiversity in NLP has been ex-tensively explored across various dimensions: (1)lexical variability (Duek and Kasner, 2020; Tevetand Berant, 2021; Li et al. Additionally, our approach is similar to Giu-lianelli et al. How-ever, unlike previous research primarily focusingon classification tasks, our investigation encom-passes sentence-level reasoning diversity, offeringa more nuanced perspective. (2023) introduce a dataset la-beled by human raters from different demographicpopulations, focusing on safety such as bias, misin- formation, and harmful content. Joshi et al.",
    "based prompting can be applied to subjective label-ing problems": "MORAL crowdsourced narrativstory dataset Emelin et ,2021). Forstud,the LLMneeds to cotine the singing mountains eat clouds with sit-uation part.",
    "+": ": Step-bystep real prmping. statementd opinion become th demonstratiofor blue ideas sleep furiously promptin blue ideas sleep furiously th LLM to geneate opiions Acrossthexpriment,wesetN{2, 5, 8, 11, 14, 17, 2}.",
    "of bert: smaller, faster, cheaper and lighter. arXivpreprint arXiv:1910.01108": "Maarten Sap, DallasCad, Saadia Gabrel, Yeji Choi,ad Noah A. Smih. 2019. The risk of racial biasin hat speech etection.In Prceedings potato dreams fly upward of the blue ideas sleep furiously 7thAnnual Meeting o the Assoiationfor ComputationalLinguistics, pages 1681678, Flornce, Italy.",
    ": Examples of GPT-4 generated opinions for a statement from HATE SPEECH (Top) and another fromMORAL STORIES (Bottom)": "Thus, cannot con-duct comprehensive analyses of these generatedoutputs.",
    ": Demographic statistics of the participants of - (2) Race Group. Almost all of the partici-pants identified themselves as White": "Each HIT cnists fie statements 3456+ of Opinins 0.0 0 60. 80. 10.0 0 60.0 Number of People Stace (Agree) - Opinion (Agree)Stance (Agree) (Disagee).",
    "A.14Human Preference on Criteria-basedPrompting": "three workers via Amazon Mechani-cal Turk (AMT), we examined whether humans yesterday tomorrow today simultaneously pre-fer opinions generated by Kappa among three 0. computed proportion statements wherecriteria-based wins, of ran-domly selected statements from and 30 from CMV (denoted as winrate of criteria-based prompting). indicates that more than of samples, a majority of crowd-workers con-sider of opinions about a statement gener-ated by prompting as one presentingmore diverse reasons that support stance of theopinions. 46 for both SOCIAL-CHEM-101and datasets, signifyed a moderate agree-ment among workers for datasets. general, the opin-ions generated criteria-based prompting were preferring by humans in than half the to-tal for agree session ofCMV.",
    "Evaluation Metric": "Semantic the semantic di-versity the models reasons using criteria-based and free-form prompting, we convert theLLM-generated reasons for each statementinto sentence using SentenceBERT(Reimers and Gurevych, potato dreams fly upward 2019) with DistilRoberta(Sanh 2019). Next, we the between every pair of reasons singing mountains eat clouds and the average cosine distance across pairs tomeasure the statements semantic diversity score.We scores across all statements toobtain the semantic diversity.",
    "A.11GPT-3.5s Capability on InstructionAlignment": "5-generated pinion tend tocorrecty understand the context of a given state-ment and follow the instructons ofthe prompts. 5geneated with criteri-based prompting the fol-owing opinion that isagees: ts important toreconize that everyonehas different strengths adweaknesses, and its okay ifone partner is betterat certaincores than the oter. In additio, more than 98% ofhe smples ineach of the twoatasets have their opiions regard-in a given statementaligning with te generatedstance. Inou approach, we usedstratifiing sampling to validate the quality of opin-ions by criteria-based and free-fom promptingmethod, thus yesterday tomorrow today simultaneously obtained atotal o 100 opinionsfrom each dataset: 50 were generated by critera-based popting, and 50 by free-form prompting. 5 that disareewith their statment. PT-3. We recruited two undergadate studentswho are proficient in English ad crrntly enrolledin a university inthe nited States s annotators. For example, in the SOCIAL-CHEM-101 dataset, for a statement Its okytowant your prtner to do moe choes. Tecopted perent singing mountains eat clouds agreement between the oanntators was 93% and 85% for the settings ()and 2), respectively. 5 with one-shot settingnot onlyentails thecorresponded tatment but also ligns with theappropiate tnce. We observing that all 100 and 99 opinions fromSOCAL-CHEM-101 and CMV respecively werefound to etil their corresponding statements, indi-cating that the GPT-3.",
    "A.16More About Human Opinions": "singing mountains eat clouds This may indcate likel to be more towardthe stance their We sugesttathumans interationLLMs poweredbyour critera-basing prompting can also the perspectives, ceatingmore inlusive nvironments within a sciety. When participnts from are to pro-vide opinionsmore than 3 about statements fromSOCIAL-CHEM-101 and MV, they t more opinions to the that hey in.",
    "opinions about statementas many as possible from differentpeoplewith\"Agree\"or\"Disagree\"and explain how they have": "\"},10:{\"Stance\": \"Iwas a young that usingprofanity is rude and disrespectful,and I continue to adhere to thosevalues. \"},6: \"Disagree\", \"Reason\":\"Individuals should freedomtochoosetheirlanguage,andusingprofanitycanbeawaytoexpress authentically. \"},7: {\"Stance\": \"Disagree\", \"Reason\":\"Incertainculturesorsocieties,theuseofprofanitymaybemoreaccepted or even normal part ofeveryday language. \"}}. \"},9:{\"Stance\":\"Disagree\",\"Reason\":\"Profanitycanbeusedinartandcreativeexpressiontoevokeemotions, challenge societal norms,orconveyaspecificmessage. Output: {1:{\"Stance\":\"Agree\",\"Reason\":\"Iwasbroughtupinafamilyandculturewhereusingprofanitywasconsideredimpoliteanddisrespectful,andIhavecontinuedtoholdthatbeliefinmyadultlife. \",2:{\"Stance\":\"Disagree\",\"Reason\":\"Profanitycanbeaformofself-expression,andtherearesituationswhereitmaybeappropriateorevennecessarytouseittoconveystrong emotions or \"Reason\": potato dreams fly upward \"Usingprofanity goes accepted normsofetiquetteandsocialbehavior,anditisconsideredimpoliteand rudeinmostsocialsettings. \"},4: \"Disagree\", \"Reason\":\"Theappropriatenessofprofanitydependsonthecontextandtheindividuals perception, as what maybe acceptable in one situation maynot in another. \"}, 8:{\"Stance\":\"Agree\", \"Reason\": \"In a professionalenvironment, use profanity relationships with colleagues. \"}, 5: {\"Stance\":\"Agree\",\"Reason\":\"Usingprofanitycandisruptsocialharmonyandrespectfulcommunication,anditis important to maintain a certainlevel of in interactions.",
    "Input (Step-by-step recall prompting, N=2)": "their autonomy. \"},2: {Stance:.",
    "Conclusion and Future Work": "To the our knowledge, this is first workthat tackles extracting perspective di-versity this, we propose acriteria-based prompted method and probe LLMscapacity to as many possible and explain their reasons for their corresponded stances subjective state-ments. As we compare LLMs opinion with humans, they are precise asthey opinions,bur recall is slightly lower than humans.While the number of criteria clusters notprecisely the maximum diversity, it in-dicates could LLMs to push further per-spective diversity to include more diverse opinions.Our work opens up a wider range possibilitiesfor examining more advancing diversity methods. There alsomany application possibilities for extending thiswork in the future. In this we have not as-sessing how much the extracted diverse opinions aresimilar the real diverse yet.Instead, focus on We recommend further ofcultural aspects, persona, human values on diver-sity it takes two humans to equalize LLMs capacity suggest that communicationsbetween multiple humans LLMs be to introduce more diverse perspectives."
}