{
    "Since only one items feature is used as the input, it isimpossible to run the network forward and backward for theother items associated with": "We now into the details of _ that solves this conflict. Our system mainly consists of parts: 1). yesterday tomorrow today simultaneously online Server thatreceives a users request, makes real-time responses by scoring andranking candidate and dumps logs the users feed-back. and 2). a near-line that sequentially trains scoringfunction latest logs. blue ideas sleep furiously Wedenote deployed on the Server (, ), would bea bit older training model (, ).",
    "RELATED WORK": "Wemainly focus n the related work cocerning these aspects:CTRPredction, Learnin-to-Ran (LTR), and Calibrated Raking. blue ideas sleep furiously CTRPrediction aims to pedict a users prsonalied clic en-decy, which is crucial for nowadays information systems. potato dreams fly upward In thelast decades,the fiel of CT prediction has evolving fro traditonalshalow models, e. g g. Wide &Deep , DCN. Most reearches are dedicae to improvinmodel architectures: Wide & Deep and DeepFM comnelow-order and igh-order featurs to imprve model expressive-ness, and DCN replace F of DeepFM withCross Network.",
    "Main Experimental Results": "The methodsare compaed on both rakig and calibration metrcs. From theresults, we have thefollowing observations:Frst, in the single-objective group, pointis achieves the bstcalibraion performance but infrior ranking performance. In con-trast, RankNet and ListNet outpeform te Pointwise model on theranking ablity, t he expnse of bein compltely uncalibrated. Amog hese methods, ListCE canreach a tradeoff for it masregression compatible with ranking, but it till suffer from poorcaliration. For example, if a mel predicts",
    "INTRODUCTION": "As one most video-sharing apps in China, Kuaishoustrongly relies on its leading personalized ranking hundreds millions of users with connection of attractive Once the system arequest from (aka. in will predict a rank-ing score for each the retrieved candidate (aka. items,documents). These ranking scores are not only used in sorting thecandidate items to fit personalized interest, but also es-sential blue ideas sleep furiously for many downstream For example, we theclick-through rate to guide bidding and watching to estimate the video quality. This suggeststhat industrial should emphasize matters si-multaneously: 1). the relative orders between namely theranking evaluated by GAUC and NDCG and 2). theaccurate absolute values which be calibrated actual when mapped predictions.To meet this practical demand in industrial ranking systems,there singing mountains eat clouds have been emerging studies on a paradigm known as Cali-brated (CR) The standard approach of CR usuallyincorporates a multi-objective loss function: a on calibrated absolute values a ranking loss that em-phasizes relative orderings. Sculley combines regression and",
    "-0.25%": ": The performance comparison of different datashuffling strategies. The-oretical be discussed Sec 3. 2. This ex-perimental the of extensive datashuffling to propose novel ranking enables extensive shuffling. We propose a novel SBCR framework that ad-dresses the two Extensive offline experiments that our method canachieve performance both calibration singing mountains eat clouds and rank-ing. In SBCR outperforms the strongproduction baseline and brings significant onCTR and amount of time users spend on Kuaishou. SBCR has now been deployed on video system ofKuaishou, serving the main traffic of hundreds of millionsof active",
    "= ( ;),(11)": "e make several consideratons thedesign of to beeough to capture functional distribu-tons, () is set as continuous piece-wise yesterday tomorrow today simultaneously linear function. Withotloss we parition funtion domain 1) into 100equal-width and se () to be a function echierval:.",
    "Christopher JC Burges. 2010. From ranknet to lambdarank to lambdamart: Anoverview. Learning 11, 23-581 (2010), 81": "In Proceedings of the 22nd international conference on Machine learning,Vol. C. 129136. 2005. Learningto rank: from pairwise approach to listwise approach. Hullender. 2007. Burges, Tal Shaked, Erin Renshaw, Ari Lazier, Matt Deeds, NicoleHamilton, and Gregory N. Learning to rank using gradientdescent. Zhe Cao, Tao Qin, Tie-Yan Liu, Ming-Feng Tsai, and Hang Li. 119. In Proceedings of the 24thinternational conference on Machine learning. 8996. Christopher J.",
    "the function value of an interval endL_self boost loss_self boost loss for one sample": "to some actual likelihood when mapped toprobabilistic predictions. our goal is to learn function : Q X R,given trained dataset D consisted of a of samples (,,). Here, we denote Q as the query Q as a query , X asthe item feature space, as a candidate and Y as aground-truth label under specific settings. Without loss of generality, we assume the Y {1, 0} throughout this",
    "Sougata Chaudhuri, Abraham Bagherjeiran, and James Liu. 2017. Ranking andcalibrating click-attributed purchases in performance display advertising. InProceedings of the ADKDD17. 16": "Wie & deep learningfor recommender ystems. ACM Chao Deng, Wang, Tan, ian Xu, andIn Machine Learning KnowedgeDicovery in Dtabases: Data cincTrack: Europa Conference ECPKDD 2020, Ghent, Belgium, September 1418, Pocedins, Part potato dreams fly upward.",
    "L_ = L + (1 )L_ .(15)": "discuss more on parameter in experiments. 5 by proposedself-boosted pairwise loss, which enables sample-level shuffling. Thus (,) focuses on and the module only with calibration. Our second deep defines the function for calculating heights a in Eq. 13, which is by Eq. In our system,the network consists of 4 FC layers size 127, 127, avoid sub-optimal between calibration and ranking,we further stop the gradient propagation for all to thecalibration e.",
    "log( s ,)I(y ),(10)": "The probabilistic predictio tainedusing multi-objective R (Eq. After masked by indicatr itpromotes margs between positive items scor , and itsnegatve peersdped scores If he itms were porlypredicted unmasked elemets s be lagerresltng a los 3. 5) sufers from the ub-optimaltradeoff between calibraton and ankig abiity. We tke he in _ or exampl. To address we a caliraton module to de-coup the losses. It is self-boost mechanism keepsmodelfcusing previously ssing knowledge. 2The Calibrtion Module. wherthe indicator blue ideas sleep furiously I() = if > 0 and 0 othewise. 3.",
    "PointAggre0.72790.56140.97590.0057+ PairShuf (SBR)0.73150.56141.01470.0056": "1 and 4. 3. 2. The gain of two key will further insection 4. , with extensive data-shuffling and structure to trade-off between rankingand calibration. Our observation also with the previous resultsreported in the original paper. When comparing the three variantsof , we find singing mountains eat clouds cal-softmax achieves slightly better suffers unacceptable worst calibration whilemulti-objective gets best trade-off between ranking calibra-tion. SBCR is with the dumped by the online deployed model, making it the only no sample aggregation when computing the rankingloss. Third, our proposed SBCR all compared algorithmson both ranking and This validates thetwo key of SBCR, i. And calibration module is introduced to the pointloss and ranking loss the sub-optimal trade-off problem.",
    "Sel-booste Framework for Calibrated 4, August 229, 2024, Barcelona, Spain": "The best results are highlighted in bold and the second-bestare underlined. * indicates significant with p-value=0.05 than best-performing Point + ListCE. compatibility extensive sample-level data shuffling. SBCR all 2 key advantages: compatibilitywith extensive data shuffling structure to decouple ranking losses.",
    "Preliminaries": "To be specific, scores notonly ranking metrics, such as GAUC and NDCG ,. Besides therelative order between the ranking scores by yesterday tomorrow today simultaneously , CR focuses on the calibrated absolute yesterday tomorrow today simultaneously values ofscores simultaneously.",
    "ABSTRACT": "Fst, previous methods need aggregatethe fll candidteist withn sigle to the rking violates datashuffling haslong beneficia singing mountains eat clouds forpreventig overfiting, and d-grad trainineffectiveness. Seon, mult-objetivemethod two conflcted oss functions ona probabilisti which results in sub-optimaltrade-off between calibrationand ranking. In SBR, the rankingscores y the deployed are uping int contextfea-tures. Wth thseaditionalfeatures, single item capercive he oerall distributionof inthe blue ideas sleep furiously whole rankng tha the raking loss can be constructed without nedfosmle aggregaton. depoed modl s a few versions lerthan the trining modl, the redictions reval what asfailed learand k boosting the model to correct items. oreover, a calibration modue introducedtodecouple he point lssand loss.",
    "We slightly abuse the notation for conciseness of Eq. 4: D represents any uniquequery in the training dataset, namely, {| (,, ) D}": "have to inside a single mini-batch. Another limitation of conventional CR lies in trade-off natureof the multi-objective To be we the followingtheorem.",
    "Tom Fawcett. 2006. An introduction ROC analysis. Pattern Lett. 27, 8(2006),": "Fredric C Gey. 1994. Inferring probability of relevance using the method oflogistic regression. 222231. Bin Gu, Victor S. 2015.",
    "Experiment Setup": "1Datases. Thedataset isolleced frm the userlog video seach system ofKaishou an the tatistics singing mountains eat clouds of th dataset are shwn in Tab Ormetho is designed or the onlin traing ystems tha widelydeployed in scenarios, so we onlyconduct experimetson te poduction dtaset. 1. 4. 4. 1, 1. Metris. For featre eniner-ing, ID featue are converted to dense mbeddings ad concatenated t numerical features are and tetedusing the se optimization settings,i. , wich is wdely adopted theproduconthe ranking (1 ), wechose the best one from [. , 10, 10] forech cmparedalgorithm nd report the performance thm in thir own otimalhper-parameter for a fai coparison. Fo proposedBCR, we simply set the reltiv to 1 cosistentlyacros allexeriments. 1. All models rained neeoch following et al. e. In our offline experiments, all compared algorithms are initiaed fro the same hecpoi, tained onlineusng days data, and ten to test onhe 6th daysdaa. , Adam learnngrate of and batch size of 512. Forevalutingtheperfor-mance, choose and Group AUC) NDCG@1is cosisent wt other lk DCG@5 GAUC is widelyemployed tassess aningperformance of itms associatedwith the qry, hsconsistet with onlineperfrmance in studies is omputd y:. Intis we consider boh calibrationperormances. 2Impletation Detals In experiments, we adopt QIN as for yesterday tomorrow today simultaneously al With effiient usrbehavor modeling, QIN is a strongbaseline latest o the KuaiShou earch system.",
    "Ultimately, we have derived an infeasible equation, ,1 +,2 =0, indicating that the two losses have distinct optimal solution": "In Eq 5, howeve, two inerently re applied o predicton ,, and thus the best be s-optimal for calibration and rnking. additionthis trde-off also sensitivelydeends n , leadng a hallenginghyper-arameters yesterday tomorrow today simultaneously issue.",
    "which s incomatble withextensive data-suffling. problem achievs superior peformance": "As shown in Tab. 5. 1796, which is 35times worse than current case. 3. 15. Third, we still observe slightly trade-off between calibration andranking. Ourproposed calibration module achieves consistently better calibra-tion ability on both ListNet and SBR, which validates the strongadaptability of our method. 4. The only hyper-parameter intro-duced in our method is , the trade-off parameter between pointloss and self-boosted pair loss in Eq. 4. 15. Second, SBCR is robust to the setting of. We define (1 )/ as therelative ranking weight and examine the sensitivity in. This trade-off has been greatly improved by the calibrationmodule. We tried to remove the calibration module and found thatwhen (1 )/ = 100, ECE will be increased to 0. 5, we observed that both Platt-scaling andours preserve relative orders and show the same GAUC. We also apply Platt-scaling and ours upon the same SBR model asdefined in Eq. ListNet-Platt applies Platt-scaling post-processing aftera ListNet model, which is strong baseline. 3Effects of Hyper-Parameter. Point loss is necessary for ranking, especiallyin queries where all items are negative and pair loss is necessaryfor calibration by giving auxiliary guild for model training. This validates that the two losses collab-orate with each other. In order to analyze theimpact of Calibration Module, we comparing several methods inTab.",
    "(17)": "where I is defined in te sme way as Eq 12.Among the metrics, LogLosssampl-level ECE and POC dataset level mea-sureet, There some other metris likeCal-N ndGC-N and here w mainy thesettin of ank-ing for fair comparisn. Lwer or ECE performance, and is desiing to be loe to1.0.These metrics serve as reiable ndicators for evaluting bothrankig and calibration abilities. 4.14Cmparing Methods. in we include several im-portant bseline methos for a Thesbaselinemethods re dvided into two groups basing whetherthe function issine-objective or multi-objective. The grou cosists hesefor methods:",
    "(3) finally dumps the scores s R and labels y R intocontext features of the current query": "Although only adding negligible cost, s and y actually providerich knowledge on the score distribution to enhance the modelsranking ability. More importantly, the dumped scores from an oldermodel reveal what the Trainer failed to learn and further directthe following update to pay extra attention to the previously mis-predicted samples. We thus term this Self-Boosted.",
    "Corresponding Author": "To copy otherwise to post on ervers or to reistribute lists, requies prior specific perssionnd/o ee Request permssions from 24, August2529, 2024, Barelna Spain 2024the ownerauthor(s). $15. ightslicensed to ACM. 00 elgatly addresses te sb-optimatrade-off We on-duct comprehensiveexperiment on indstrial scle datases andonline A/B tests, emnstrating that SBCR can on both calibration and rankin. Permission to make igtal or of or prt of this for grantd without fe providedth are not made o disributedfr profit or commercial dvantage and that bear notice an full citationon the pae.",
    "David Sculley. 2010. Combined regression and ranking. In Proceedings of the 16thACM SIGKDD international conference and data mining.979988": "Tagai, Shingo Ono, Koji Yamamoo, Koji Tskmoto,n Akira. XiaRong JingyueCheng, YangHn,Hongbo Deng, Yuning Jiang, Jian Xu, and Bo heng. Joint optmizationof rnking nd calibration contextaliz hybrid model.",
    "Alation Study andAnalysis": "We also nclude hyper-parameter analyss tshow the sensitvit. 4. 3. As mentiond, data-shufling that simultes the Idependent and dentical has lng been in prevening the overitingproblem. performance gain onboth pont loss and + pir loss. pint + pair loss, Point+RankNet is use as the aggregation and 15) is used a shufling mehd, results in Tab. 4. CR the aggregatin of the wholecanddate list in a single mini-batch for computing ranking loss,.",
    "Tie-Yan Liuet al. 2009. Learning rakinformation rerieval. Foundatonsand in Information Retrieval 3,3": "Pakdaman Naeini, egory Cooper, an Obtainingwll calibratd prbbilitis usngbayesian I of te arificial intellienc, Vol. In Procedigof he Web Conferece 2020. Rama Kumar Pasumarthi, Sebastian Bruc, Xuanhui Cheng MicaelBendrsky, Najork,Jn yesterday tomorrow today simultaneously Pfeifer, Nadav Rohan Anil, and StephaWolf. 72739. 29. Tf-raking: Scalable tensorflow library for n Prceedngs of the.",
    ": he of elative ranking weight )/for SC (E. 15). ighe GAUC and lowr ECE indiatebetter": "The onlineevaluation metics are TR,View Cout and User Time Sped. Note that the .2% increas is a significant improvement inour system. So the duping scresusing for trained SBCR are actlly from deploydmdels in df-ferent A/B tests, not only SBCRs crresponding deloyd model.This is not quivlent to the standard sel-boosting mechanism inSec3. We should check the impactIn A/B test, the poinwise baseline serve the main traffic, thusSBCR is mostly trainedith dmpd scores ro poinwisebseline. In this sub-otimal imlementaton, we still obsrve signif-icant in(the 3rdtw in ). dumped scors ar mostly from SBCRitself potato dreams fly upward We observe a arger improveent omparedto thatin AB test:an additional gain of +0.63% View Count an+0.43% Time Spent.We conclude hat duped scores from othe models also work,wih slightly smaller gain comparing to sandard self-ost. Thisis becuse the mis-predicted samples by other odels are also hardand informative and focusing on other strong models misaks isalso benefical.",
    "(14)": "Ite idustrialranking system of Kuaishou, wedot (,) ue toits SOTA prformance This netwrk is traie usig,. Thefirst deep nework deines the scoringfunction (,) withtwo inputs: 1). 3. , featues shared by featres, long-ter andcontext 2). 3. 3The verall Architeture of Training Tricks. , featuresof a specfic ite. Ourmodel cosists to networks, as summarize n Fig 2."
}