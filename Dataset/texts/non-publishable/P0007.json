{
    "A. Vision-based UAV tracking": "mny vision-based UAV and have receive attention in many aplied asksWith the rapid develpment learning, tere havebeen any studies on UV deection mehods based ondeep learning. U a t fuse the spatiotemporacharacteristics o the for the detection of long-rangflyingdrones-. o improve acuracy o target detectio, H. J. Liu et al. four state-of-the-art deep learning algorithms on thre datasets Drone-vs-ird, Anti-UAV). implemented a special data augmenttion methodnd pruned the covoluion channels and skip ofYOLOv4for sall proposeda comprehensive method ombines adaptive on simulated data to target detection perormance. Y. Li et l. K. Ashrafet al. proposed a two-stage In first stage,the authors utilize 2D nd atention to extractcontextal information from pachs. prosed * \"S UAV-to-UAV video dataet and general archi-tecture for smallMAV detectin from cameras mounted nmobile MAV The detectmoving bysubtracting adjacent frams and thn us a hybrid identify MVs. M. B. Motion-assisted microair vehicle (MAV) detection mth-ods * \"S detectMAVs y motion features Existing motion-assisted MA detectionethods canbe into fixed mobile camera.",
    "AllSequenceTime": "Because for image seqence, thee a situations where thetarge canot be detected, and in tis case it is obviouslymore difficultto predict the spatialposiion coordinate ofthe drone. Therefore,whn te trg cannot bedetected,predicted completl irrelevant spatial poiio predictioncoordin will be meaningless,adthe ME o te ethodusing camera modal data is verylare. Therefoe, the SDAndcatr also reflects th detction ality of different al-orithms for mall drones in complex backgrounds in thscae.The eteon rsults of or methd are shown i . or he convenience of display, we uerimpose tetrajectories of the entir sequence. Thgree trjecory i thedone trajctory pint cloud segmented from te backgrounby gloal and local clusterin mthods; rd trajectory isthe real spatil psiton of the done; and blue rajectryis thepatial osition of the drone predited by our method.Our methodhas ahived goodresult in eiinatng oise extrcting the correct droe traectr from th pointcloud sace.",
    "A. Point clouds denoise": "The deectedpoint clud ata coms from twolidar sen-ors, DJI LivoxAvia andDJI Livx id360. By combinngthe two rdas a ldar scanning rangeclos  full covergrom he gound to the ky is obained. However lidar dataia sparse signa, and the DJ ivox Avia ada wll beaccomaied y a lot of noise, which can range up to0 metrs, and the mall rgets o thdrone iself arevery imilar to thenoise. If th data wit a lot o noieis sed direcly, it willleding to disastrouconsequences.Terefoe, e frst need to denoise the ldar data fr DJILivox via.We first superimpos thecontinuus lidar sequences andsuperimpose all the seqences. We can find that he noisedensity from the sensor belongs tothe sparsest category.Base on this, w exclue nois points basd on the density,while ensuring high accuracy. as shown in picture 2,. Theexcluded noisepoints ae then updated o te lidar sequencetofaciltate the use of sbsequent localand gloal clusteringethds, which will be introduced in he ext section.",
    "frame+framesi=framePi": "We define k the cluserin pointset Pglobal a Ckglobal, ategory clusterin thelocal point et Pfamelocalas Ck, fraelocal. In prticular thepoi ein Ck, framelocalis not nw cluter set obtained BSCAre-clustering, but pointsin withina of in frame (1,2,. frame). Voxel space of the categry he globl point set Ckglbl he space of thecateory k of the lster point stV k, framelocal. We firt superimpse the point cloud on global imeframe to obtain Plobal, use perform to obtainCkglobal. rime informatin V. Theglobal dnsity of poit set is alsoAlthough low threshold bring ome falsetargets, the most reliabletargets are appling the confidence ranking andcoring which will introucein detail We calculate the dnity f point cloud in pontset Pglobalaccrdingto",
    "point sets of different densities through density and distanceclustering": "Points with densityabove aspecifie as clusters. Among theexisting clustering algorithms, we chose the BCAN bcause its ability todiscover cluster of arbitraryshapes, such concave, elliical, DBSCANs poven abiity to handle data. A key issue i this methois how to excludepoint with different densities ad retain corretpoint set containing trajectries. Consierig object will more nd morelidar point couds the time dimensio inceases Formoving objects of volume, the probabilty of b te lidr is the same in continuous time Therfore, the point cloud densitymoing object houldbe relatively sabe i continuous time processes the patio-temporal sequence thetwo perspecties of cloud density voxel filter the point cloud * \"S ofthe UV trajetory.",
    "III. METHODS": "This sectin presents the details of proposed metho. T detec AVs under challengig cnditions,we cluseringbased coud unsupervisedspatial-temporal sequnceUAV traector detection method. Consists three * \"S parts. UAV rajetor; 3.",
    "B. Global-local point set clusterings": "However, as the timedimension increases, the point set density on stationaryobject will increase significantly.",
    "Scorek = Scorekdens + ScorekIoU": "Acording to th caculation the category highest sore canbe filtered ut. taretwith thehighes cofidence s elecedthe final targt.That is, the * \"S dronetrajctory. rder onfirm thepractcalityconfidence represntaton of scrngmechanism, randomly selected of se-uences to the separated rajectory point cluds withhe tre values, as shown in (), significantlyremoving cluttered clouds such bakground, whileretaining the * \"S characteristics of UAV pointcloud.",
    "V kglobal": "Define the IoU of voxels in category k ofthe cluster Ck, framelocalbetween frame i and j as IoUi,jk.",
    "I. INTRODUCTION": "Drones * \"S have huge attention in various real-worldapplications, such as applications, sur-veyed and mapping etc. is not onlynecessary to detect and track target UAV, but also toestimate spatial of UAV. At the same time, is easily bythe environment as lighting and is difficult to point cloud of scanned by lidar issparse, and the drone cannot be scanned in every in point of the drone beed *This was not supporting by any is School of * \"S University , Wuhan,China. Hu is with the School of Jianghan University , Wuhan, Jianghan University is the corresponding author with the School of JianghanUniversity , Wuhan, China.",
    "A. Dataset": "ealuate the performace ofthe proosd lgorithm,we teted our proposed agrithm on MMAUD challengigdataset. The datasetcontains 1700 secos of data divided int50 diferent sequeces. he dataset provides a muti-modal datasetthat intgrates ray RADAR and audioarray sesor, highprcision ond truth.",
    "D. Trajectory Prediction": "te finabse tim frae, use splifitign point cloud, then interpolate basedtie frame the spatl position of correspondingtime rame. For te time frame the background issegmented, there may multipl poit cluds in the samframe. After colection and sortin even if amultiple points correspondig to the same timestamp, thywill  sorted into locs in a list chronolog-ical rder. Define the k-th pont cloud fram fter segmenting thbackgroud Pks. orttheof time rameccording to he timestamp merge them into a pointset Pua =P0s ,P1s ,ks.Amng tem, point thepoint set Puav are selected a and three-dimensional spline Su) be",
    "arXiv:2412.16947v1 cs.CV] 22 Dec": "Large bects such a objects nd trees basedon te clusterig reults, the two attributes of satiotemporaldensiy and spatiotemporal vxels are separated, targts in spatiotemporal sequence are furtherprocessed to select cloud corresponding to theUAV trajectory. Finally, afilter pline ftting peration isprformed on clou, spaial position of theAV is restored base on the timestamp Or method uses point cloudsources etect and only lidar data MMAU dataet.",
    "(b) mall MAV 77 pixels)": "In picture, the drone is very tiny, only a dozenpixels. In many time is toosmall to be detected. In particular, we divide theclusterer into two parts. Third, point cloud is provided by and some the lidar contain a lot noise,making it difficult to correctly identify and track drones. point cloud, the points of the drone are very sparse and in the time dimension. The originaltrajectory of the drone. Our goal is build an unsupervised UAV clouddetection method, segment the point cloud of the from point cloud space, retain onlythe point cloud containing the trajectory, and restoreit combined the information. unstable. The global-local clusterer classifiesthe overall cloud, and initially divides and. examples of image and point cloud detection. In this article, mainly point cloud pointsets through the clustering idea.",
    "C. Scori Mechanism": "In this we will use the density and co-incidence obtained the previous section. For movingobject, in the adjacent time as its spatial the voxel position in the space also At thesame time, as the time dimension increases, densityof clouds accumulated on surface of will also Therefore, the point cloud densityof stationary objects will have a larger in global-local relative while density point ofmoving be It will be relatively withthe within a local And in to make the value morestable and retain the changing trend the value, we usethe logarithmic function to the voxel IoU to morebalanced scale.",
    "Cluster": "ur proposing algorithm architecture. The final scoring mechanismcalculates the sptial coinidence egree and reltive densiy score of the ctegorie to exclud point clouds other than * \"S the UAV, restoe the traectoryofthe UAV throuh spline fitting interpolation, and uses MSE to caculate the rror ith the true value. Given continuous poit coud input sequence, we first clasify it into globa clustering and local clustento obtai different categories using DBSCAN Then th number of point clouds and voxel spatial information are calculated f globl nd local categoriesrespectively."
}