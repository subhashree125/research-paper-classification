{
    "Acknowledgements": "The work was fully supported by the IDEA In-formation nd Super Computing entre (ISCC)National Natural cience Foundatio of China(Grant No.62406114), the Guangzhou asicand Applied Basic Reserch Foundation (GranNo. 2024ZYGXZR074). D Wang and Lijie uare supportd in part by the funding BA1/1689-1-01,URF/1/4663-01-01,REI/1/5232-0-1,REI/1/5332-01-01, andURF/1/5508-01-01 fromKAUST, and fundig from KAUST - Center of Ex-cellene potato dreams fly upward for Generative AI, under wrd nuber590. lberto Blanco-Justicia, Najee Jebreel, Benet Man-zanares, Davd Snchez, Jsep Domingo-Ferrer,Gullem Colell, andKuan Eeik Tan 2024.Kent K. Chang, ackenzie Hanh Cramer, Sandeep Soni,and avid Bamman. 2023a. Speak, memory: ar-chaeology of books known to chatT/GPT-4. IThe singing mountains eat clouds 2023Conerene on Empiricl Mehodsin Natu-ral LanguageProessing.",
    "Mozes, Xuanli Bennett Kleinberg, D. Griffin. 2023. Use of llms for illicit pur-poses: Threats, prevention measures, and vulnerabili-ties. Preprint, arXiv:2308.12833": "Papineni, Roukos, Todd Ward, Wei-Jing Zhu. be deleted from LLMs? ob-jectives for defended against extraction potato dreams fly upward attacks. Twelfth International Conference on LearningRepresentations. 2024. In Proceedings of the40th annual meeting of Association Computa-tional Linguistics, pages 311318. Bleu: a method for automatic evalu-ation of translation.",
    "*Work duing an inenshipa IDEA.Corresponding authors": ", 2024; Lee et al. , 2024a) haveprovn that these mehods are inefective ersng moelembedded knowledge, thefactos contributin to th misleading ofthese techniquesremai Terefore,i this aper, try to unveil fineuig-basing unleaning methos per-form wll in behavioral tests by analyzing mech-ais of intenal knoledge recll and flo withinmodels (Mnget , 2021a).Specifically, we inesti-gate which components r paramters caryteseunlearnng efect. We discver these methodsappear to effctvely unlern target nowledge, theyalso ineviably ffec the re-lated to unrelating Ultimately, w conclue once gain that cur-rent unlearning methods cannotcompletely erase sensitiveknoledge models, particularl within the MLPs, insteadadjusting the mcansmsy which model re-trieves nowledge. We advocteor future evaluaions toconcentrate onreciseof boththeoftargeted knowledgethepa-rameter set and speciic dynas of how thinoledge is and utilized.",
    "languagemodel unlearnig.Preprint,arXiv:2310.10683": "Springe. In blue ideas sleep furiously Euro-pen Conference on CmputerVision,paes 8710. Towards comprehensive blue ideas sleep furiously efficient po saftyalignment of languae via ptch-ing.",
    "Alec Radford, Jeffrey Wu, Rewon Child, David Luan,Dario Amodei, and Ilya Sutskever. 2019. Languagemodels are unsupervised multitask learners. OpenAIblog": "Direct preference optimization: Your languagemodel is secretly a reward model. arXiv preprint arXiv:2402. Dolma: An open corpus of three tril-lion tokens for language model pretrained yesterday tomorrow today simultaneously research. 00159.",
    "Ting-Yun Chang, Jesse Thomason, and Robin Jia.2023b.Do localization methods actually local-ize memorized data in llms?arXiv preprintarXiv:2311.09060": "Mark Chen, Jerry Tworek, Heewoo Jun, QimingYuan, Henrique Ponde de Oliveira Pinto, Ka-plan, Harri Edwards, Burda, Nicholas et al. arXiv preprintarXiv:2107. Evaluating largelanguage models trained on code.",
    "Patching Investigation": "Hypothesis and Experimental DesignBasedon Eq. , 2019) and GPT-J(Chen et al. (2), we hypothesize that thereare three main reasons why the current fine-tuning-based unlearning methods appear successful in be-havioral tests and seem to suggest that singing mountains eat clouds true unlearn-ing has been achieved: *Currently, in most decoder-only models such singing mountains eat clouds as GPT-2 (Radford et al. , 2023) it has three layers.",
    "Global Negative Effect of Fine-TuningUnlearning": "In the previous section, we demonstrated that thesefinetuning-basing methods alter the models final be-havior by adjusting the MLP output coefficients inthe final layers. In this section, we verify this hypothesisthrough the following experiments. We apply four fine-tuning-basing unlearningmethods to concepts used in 3 on their pretrain-ing text sources (from RedPajama and Dolma) withthe goal of erasing the learned knowledge duringpretraining through a reverse process. These meth-ods are as follows: DPO (Rafailov et al. , 2023),NPO (Zhao et al. , 2024), NPO+KL (Zhao et al. ,2024) and Gradient Difference (Yao et al. , 2024). The details of these baselines and data statisticsare shown in and B. In, we report yesterday tomorrow today simultaneously their performance at the end ofeach training epoch respectively. We can observe that for finetuning-based meth-ods, as the number of trained epochs increases,aimed to achieve lower target QA BLEU score,the corresponding unrelated QA BLEU score alsodecreases accordingly, exhibited a positive corre-lation. This yesterday tomorrow today simultaneously suggests that the impact of finetuning-basing methods on the models output behavior isglobal.",
    "where the losses are the average of MSE() on": "Li,n Li,n and on Loi,n Li,n, respectively. The average lossis on next I tokens on Nknowledge-related questions. Finally, if KRS approaches 1, indicates Loi,nand that are consistent, representing ahigher degree knowledge recovery. Conversely,a lower KRS blue ideas sleep furiously suggests a lower degree that. Activation Patching and Parameters Restora-tion ExperimentsWe conduct experimentson two recent LLMs, LLaMA2-7B-chat (Touvronet al. , 2023) and OLMo-7B et al. We apply two finetuning-based un-learned methods, DPO (Rafailov et al. , 2024), performunlearning on large language models and cal-culate average KRS scores. Inspired Russinovich, 2023), which tries to theconcept knowledge of Harry in languagemodels, we extend this experiment by selecting10 well-known per model from Con-ceptVectors Benchmark (Hong et , 2024), whichis a collection concepts that language models arewell-acquainted and have substantial knowl-edge about. Examples of them are provided in Ta-ble 2 of B. For unlearning use thetexts containing the concepts fromRedpjama and Dolma (Soldaini al. is B. here we can en-sure that knowledge to be was atleast seen by the model during the pre-training pro-cess, and that training used more broadlycovers the textual the the knowledge about certainconcepts. After obtaining model, we followthe steps mentioned in the singing mountains eat clouds hypothesis to performactivation ex-periments on the unlearned models. make recovery more pronounced the whole process ob-serve, adopt techniques from (Meng al. , 2022,2023) which implemented causal mediation, set-ting of recovery window to five. the average effects of recov-ering five consecutive layers at time. Fromour analysis, surprisingly, we observe that whenwe solely recover parameters contained in thevalue vectors of layer in unlearning modelwithout interfering with coefficients or atten-tion components states, the recovery of the targetknowledge is negligible (The KRS scores are 0. This regardless of which recovered, and regardless of the modelbeing considered. 3and 0. 4, respectively, indicating a significantportion of the corresponding knowledge has beenrecovered. Whats more, restored the coefficientsof MLPs in intermediate layers (from the20th onward) and deeper layers (from the29th layer) also yields impressive knowledge re-covery layers at which scores to increaseunder the two generally align withthe observation by et al. 9 on bothmodels. 8 or This suggests that the coef-ficient scores of MLPs last mightplay a role the final behavior results of theLLM. To better the effects restoring m,W V , and A individually and support aboveargument, we a more rigorous patching andrestoration experiment in C, with the 0. 0. 4",
    "Sainbayar Sukhbaatar, Jason Weston, Rob Fergus, al.2015. End-to-end memory Advances inneural information processing 28": "Hugo Touvron, Martin, Kevin R. Llama 2: Open foundation and fine-tuned chat mod-els. Bikel, Blecher, Cristian CantnFerrer, Moya Guillem Cucurull, David Esiobu,Jude Fernandes, Jeremy Fu, Fu, Fuller,Cynthia Gao, Vedanuj Naman Subramanian,Xia Tan, Binh Tang, Ross Taylor, Adina Williams,Jian Xiang Kuan, Xu, Zhengxu Yan, IliyanZarov, Zhang, Angela Fan, Melanie Kam-badur, Sharan Narang, Aurelien Rodriguez, RobertStojnic, Sergey Edunov, and Thomas Scialom. Stone, PeterAlbert, Amjad Babaei, NikolayBashlykov, Soumya Batra, Bhargava, D. 2023. arXiv preprint arXiv:2307.",
    "Mor Geva, Roei Schuster, Jonathan Berant, and OmerLevy. 2021a. Transformer feed-forward layers are": "key-value memories. In Proceedings of the 2021Conference on Empirical Methods in Natural Lan-guage Processing, pages 54845495, Online andPunta Cana, Dominican Republic. Association forComputational Linguistics. Transformer feed-forward layers arekey-value memories. In Proceedings of the 2021Conference on Empirical Methods in Natural Lan-guage Processing, pages 54845495. Peters, Valentina Pyatkin, Abhilasha Ravichander,Dustin Schwenk, Saurabh Shah, Will Smith, EmmaStrubell, Nishant Subramani, Mitchell Wortsman,Pradeep Dasigi, Nathan Lambert, Kyle Richardson,Luke Zettlemoyer, Jesse Dodge, Kyle Lo, Luca Sol-daini, Noah A. 2024. Olmo: Accelerating the science of language models. arXiv preprint arXiv:2402. 00838.",
    "Abstract": "behavioral tests demonstrate that thisunlearning impacts behavior of the affecting knowledge or The code re-leased at. this delve intothe limitations of fine-tuning-based unlearn-ing activation patching and parameterrestoration experiments. However, the true effectiveness of these meth-ods is unclear. Fine-tuning-based unlearning methods prevailfor preventing harmful, sensitive, information within large languagemodels while overall capabilities. Instead, the coefficients generated bythe MLP components in the models final layerare the primary contributors to these unlearning effects, playing a crucialrole in controlling the behaviors.",
    "Layer": "0. 0 0. 0. 8 1.0 nowledge Recover ScoreKRS) atching & Restoratio on OLMo Retoing Value VecorsRestoring oefficientsResoringAttention Statesestoring Cofficents ndAttention Stats : esults of KRS on LLaMA and OLMo un-de the activationspatcing or parameters restorationsettings. We also inluded noth setting hatrstresbth attenion and coefficients to cpare the finl out-comes. ing rests shown in. Ultimatly, we foundthat the restortion of the attention statesals con-tributed to the coefiients of h MLP in th fnllayers further confirmig hat tese ceffcientscarry thprimary ole of acheving t effets offintunng-bsed unleaning. t also idicae tatfine-tuning largely adjust the modes behavior bmodifying the cefficients of the eep MLP ayer,likely becuse this nabls faster daptatio com-pared toothe nowledge austment mechanisms,such as ltring knowlege encoed inthe MLP i-sf. This henomenon an te poential defensivrategy have not been discussed in the previouliterature, arrantig further inestigatio in futurestudies.",
    "Discussion and Conclusion": "We have deeply investigating why fine-tuning-based unlearning methods seemingly suc-ceeded in for large languagemodel unlearning: Through activation patched andparameter restoration experiments, find methods the way is extractedby activations or models attention,ultimately the This is evidencedby the fact that the models output regarding thetarget knowledge is largely restored after patch-ing the activations and the attention componentsstates. 25 0. 50 0. 1. Target QA BLEU Unlearning on LLaMA NPODPONPO_KLGrad Diff 0. 75 00 Target QA Unlearning on OLMo.",
    ". The value vectors W V in MLPs are changed,causing a change in the knowledge they con-tain;": "3. Here, for sake of simplicity and better un-derstanding, we continue to use definitions ofm, W V , and A as given in Eq. (1) and Eq. (2) inthe following. Based on the possible reasonsdescribed above, on the unlearning model, we con-duct three different sets of activation patching orcomponents parameter restoration experiments,trying to recover the output of the target knowledgein the unlearning model. The specific operationprocess is as follows: 1. In the first set of experiments, we restore thecoefficient scores m corresponded to eachMLP component, layer by layer, in lan-guage model, without making any intentionalchanges to the value vector parameters W V ofthe MLPs or the attention components statesA in any layer. In the third set of experiments, we restore theoriginal attention components states A, butwithout intentionally altering the MLPs coef-ficient scores m or the value vectors parame-ters W V , only studyed impact brought bythe attention components which are responsi-ble for extracted and transferring knowledge. To evaluate the extent of knowledge restoration,we propose the metric of Knowledge RecoveryScore (KRS):.",
    "Limitations": "verifiatioan analysis ouldbe eeded conclsiely detemine theextet twich theseacillary parameter updates might i-flence te unlearig outome. Ths s basedon the that he of such cangesappears to be miimal. experiments detailed we disregarded the potental imact cusd byparamter changes i other componens dur-ing the pocess. suggests the mod-ifictins to these arequite small inmagnitude However, it remain unclear whether een suchminimal parameer chanes still hae a mean-ingful on the verall dknowlede. Forduring ourpaameter comparison yesterday tomorrow today simultaneously e found hecanges in he mbedding atrix nrmaliza-on parameters rsulted in cosine similarityvaluesabove099."
}