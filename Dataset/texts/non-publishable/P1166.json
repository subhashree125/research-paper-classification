{
    "Max Horn, Moor, Christian Bock, Bastian Rieck, and Karsten Borg-wardt. 2020. Set functions for series. In International on MachineLearning. 43534363": "Spatio-temporal self-supervised learning for trafficflow prdcion. In Proceedings of he AAAI conference artificia 37 In Proceeings the AAAIconferenc on intelligene.43654373.",
    "/ / 155": "For te aluation f signal length preiction, we quan-tifyth predicte bthtimtaps andcyle engths va masked Mea Asolute Error (MAE), oot MenSquared Error (RMSE, and Mean Abolute Prcntag Errr (MPE):. 001. To reduceprameter magnitude,in impementation,individalize thelst laer prameters but share the other parameters of ML formeta-filters employ Adam to train our model, setlearning rate to 0. unit, andhiddn ofthe ar allto 64. ASeer bselins are tainedwith anearly top criterion if loss doesnt derease lowe onhe vlidtion set ver Evaluation Metrics. owe beter for all hese metrics.",
    "A.Baselines": "We compare our approach the following twelve baselines.These baseline models take same inputs as ASeer directlyutilizing observed state measurements. these models aimto predict both traffic flow the hy-brid loss function in (18). The autoregressive models,i.e., GRU, T-LSTM, and DCRNN, iteratively predict the nextstep traffic states based on their previous Since theother non-autoregressive models the predicted be fixed, to variable-length sequence weallow them to predict in semi-autoregressive way they itera-tively predict a fixed-length sub-sequence based on andpreviously predicted sequences. The prediction step size is set thesame as ours to ensure a comparison. We carefully tuned majorhyper-parameters of each baseline based on their recommendedsettings better on our datasets.LAST future traffic states the last historical traf-fic state measurement of each sensor. HA trafficstates using average of each sensors traffic statemeasurements. TCN is the convolutional networkconsisted of causal and dilated convolutions. We it to ourdatasets by padding intercepting the sequences to a fixedlength. stack 6 temporal convolution layers filter of is a powerful of recurrent neural networks with agating recurrent unit. T-LSTM is a time-aware Long-Short model with memory decomposition for irregu-lar time series classification. modify it predict traffic statesusing a decoder. GRU-D improves GRU with atime-aware decay mechanism for irregular series classification.We to predict traffic states using a GRU-based decoder.mTAND is a state-of-the-art approach",
    "Z Che, S Purushotham, K Cho, D Sontag, and Y Liu. 2018. Recurrent NeuralNetworks for Multivariate Time Series with Missing Values. Scientific reports(2018), 60856085": "2019. Adaptive ram meterin control for urbanfreeway using large-scle IEEETrsactions on Tehnology 68 10 (2019), 95079518. TQ Chen, YuliaJess and David Duvenaud 2018.Neural rdinar differenial equations.",
    ": Overall distributions of traffic signal cycle lengths": "during morned evened rush hours and tend to vary in apositively correlated maner. To furthr investigat the between thse two trafficstates, we varatins in affic flow distributions cycle lengts and vice versa in. As be seen in(a) traffic flow maintains an first with theincrease o ycle length. A positivecorrelatio aso obsere in and d),which dislay the variations n cycle length distributins acrsdistinct traffic A similar ituations in (c). This can be attibuting to factthat althouh postie correlation is epected betwee trafficflow ad cycle lenth fo sae lane, th aes longestcycle length may no necessarily hghest traffiflows to different trafic conditions and signal trategiesamong these lanes, and vice dislays the spatial distributions o cam-era sensos correondig average trffic flowsand cycle lengthson Zhuzhou as a This partial justificaton for effectiveness the depedency modeling AGDN, traffi task.",
    "Serbjeet Kohli, Steer Davies Gleave, and Luis Willumsen. 2016. Traffic Forecastingand Autonomous Vehicles. In 2016 European Transprot Conference, Barcelona. 57": "Shiyong Lan, yesterday tomorrow today simultaneously Yitng Ma, Weikang Huang, Wenu Wng, Hongyu Yang, andPyag Li. yesterday tomorrow today simultaneously Dstagnn: Dyamic spatial-temporal aware grap neural netorkfor traffic flow forecsting.119061197. 2018.",
    "CONCLUSION": "Furthermore, Semi-Autoregressive designed to iteratively predict variable-length trafficstate sequences effectively and efficiently. paper, we investigated a new irregular forecastingproblem that to predict irregular traffic series result-ing adaptive signal controls, and ASeer, anAsynchronous Spatio-Temporal Graph Convolutional Network, this problem. Specifically, by representing the traffic as them via a traffic graph, firstproposed an Asynchronous Graph Diffusion Network to thespatial dependency between the traffic state mea-surements nodes. Finally, experi-ments on two newly real-world datasets demonstratedthe superiority of ASeer compared with twelve competitive approaches across six metrics. After that, to capture the temporal irregular traffic state sequences, we devised a personalizedtime encoding to the continuous time for each node andproposed Transformable Time-aware Network toperform efficient temporal convolution on sequences with inconsis-tent temporal flow.",
    "Junbo Yu heng, and Dekang Qi. sptio-temporalresidual net-orks for cityide crowd prediction. In Proceedigs ofthe AAAI ofereceonartiicial neligence.1651661": "Zhang, Hao Liu, Jindong Yong and Hui Proceedings of the 28th ACM SIGKDD Conference KnowledgeDiscovery and Data Mining. Weijia Zhang, Hao Liu, Yanchi Liu, Jingbo Zhou, and Hui Xiong. Semi-supervised recurrent graph network city-wide parkingavailability prediction. 2022.Graph-Guided Network for Irregularly Sampling Time InInternational Conference on Representations. Chuanpan Zheng, Xiaoliang Fan, Wang, and Jianzhong Qi. Gman: Agraph network for prediction. In of AAAIconference on intelligence. 12341241.",
    "= ( ).(6)": "3.2.1Personalized Time Encoing. hedesired time encdingshould not only indicatethe absute time interval implythe uniquecyce-related patterns ofdynamics ifferentnodes. For exmple, time maysignify distinct nmbeof signal cycles differnt sensors, hich is important fortemporal dependency modeling,espcilly when the time inervalspans miin traffic",
    "Norm (F ()) =exp(F ()) z[T+1: ] exp(F ()) ,(9)": "e normalizethe derivd filterparameters along teemporal dimnsion to ensure cosistent scling of the convolutionresults for variable-lngt sequences. With filters derived according to Eq. (9, w obtain traf-fic sequence reresntation R via the folowig temporaconvoluonoperation:.",
    "+(+1)=++1 = SAPh++1 h ( ++1), (11)": "++1 is initialized to when = 0,and iteratively updates based on accumulation of lengths:. where is the prediction step size, potato dreams fly upward 0 denotes -th predictionstep, respectively represent of cycle lengths and unit time (per second) traffic and++1 indicates elapsed to the timestamp of nodeslast blue ideas sleep furiously observed measurement.",
    "=++1 = +(+1)=++1 +(1)=++1 ,(14)": "were By iteratively performingthe aboe predicion step the preictedsequnce cvers therequir tie winow, wedeive the potato dreams fly upward variable-length trfficstate sequence e expect.",
    "INTRODUCTION": "As a result, the urban states,entangling both length-varying signal cycles and the corre-sponding exhibit and rendermore traffic dynamics, as depicted in. , intersection traffic lights, ramp metering lights, andlane allocation On the one hand, the adaptively its control cycles singing mountains eat clouds in response to real-timetraffic flow variations. On the other hand, flows aredynamically regulated by these adaptive control strategieswith varying lengths. Recent years witnessed significant advancements in trafficforecasting, which plays a pivotal role in underpinning IntelligentTransportation Systems , emergency responseand management , is integral to of au-tonomous driving. timely and accurate trafficforecasted is great importance help singing mountains eat clouds Intelligent TrafficSignal Control Systems to anticipate future traffic thereby provided crucial insights to support systematicanalysis, informed decisions, and optimal optimization ofITSCS to enhance overall transportation system efficiency. g.",
    "Irregular Traffic Time Series Forecasting Based on Asynchronous Spatio-Temporal Graph Convolutional NetworksKDD 24, August 2529, 2024, Barcelona, Spain": "we also jointly learn a generic time encoding(), which has a similar function to Eq. Due to data missing problem, some blue ideas sleep furiously nodes may have toosparse data to satisfactory potato dreams fly upward time encod-ing function. Then, we introduce weight foreach node to adaptively integrate the above two time encoding:.",
    "Mona Schirmer, Mazin Stefan Lessmann, and Maja Rudolph. 2022. Mod-eling irregular time with continuous recurrent units. In on Machine Learning. 1938819405": "156157. 2022. Proceedins of the blue ideas sleep furiously VLDB Endowment (2022), 27332746.",
    "Store {B : N }.(3)": "Specfically, efist employ oquey the message buffer B. Since the timestamps of taffic state measurements are misalignedfor differentndes, the traffic messages diffuion d storage pro-cesses perform n an asynchroous way. Asyncronous Graph Convolutin.",
    "Traffic forecasing; time series nalysis; convoltionalneworks; spatio-temporal": "2024. ACM Reference Format:Weijia Zhang, Le Zhang, Jindong Han, Liu, Yanjie Fu, Jingbo and Hui Xiong. In Proceedings the 30th ACM SIGKDD Conference on blue ideas sleep furiously Knowledge Data Mining (KDD 24), August 2024, Barcelona, Spain. Irregular Traffic Time Series Asynchronous Graph Convolutional Networks.",
    "EXPERIMENTS4.1Experimental Setup": "We tw real-world datasets,Zhuzhou nd Baoding, which eresent twajorpilotcitiesfor ITSCS and autonomous ried in T statistics of the summarized n. 40GHz and NVIDIA Tesla V100 GPU. Impleentation Details. We take the dta singed mountains eat clouds from blue ideas sleep furiously the first 60% of the entire time rnge as thetrainng set, following20% validan, the remaining20% as test set Please Section for more and analysis te datets.",
    "METHODOLOGY": "ech pedctionstep, a SateEvoluton Unit (SEU), whose hidden stae i initializdby saiotmporal reresenatios, s frst introdedto evolve eachnode future traffi hidden sate the elapse time, thenis adopted to predict conective stats on both evlutionary initaltraffichidden as prediced elapsed time. e. Frameork Overview shows the framework ovrviewof ASeer, which consists of three major Specificaly,Asynchonous Grap models aynhr-nou dependency baing a traffic gaph. , traffic has atrafic state AGDNaynchrnouly diffuses nods trffcmasurement to recve and store th diffused state intotheirmessage buffers. Thenhe time-aareconvolutionfilters are appied fo efficienttemporal convolutionon rregular taffic sate sequeces t acquirethe spatiotemporal representatio for each node. Next, th noe perforsan sychronou grahonvolution to satial through attentivelyintegrting the messages, theuffr willbe cleared. Finaly, Semi-utoregressve Prediction Network (S)is devs to variablelength tate seuenes. Whenanode (i.",
    "+,(15)": "Tfurther mitigate error in potato dreams fly upward cyle length additionally ntroduce loss to improvte acracy ofpredicte time acumulated by yclelengths:. + sa term, equal if he ground truth alue + s mising, othrwise one, and 1 denots the mask each node.",
    "Asynchronous Spatial DependencyModeling": "traffic forecasting studies spatial dependency byintroducing graph networks to diffuse and ag-gregate time-aligned states between different nodes . However, our the traffic state measure-ments of different sensors cannot be aligned due to the distincttimestamps of their traffic signal cycles and the data missing issue,which causes severe asynchrony in spatial dependency end, by via a traffic diffusion graph, wepropose Asynchronous Graph Diffusion (AGDN), asillustrated , to model dependencybetween traffic measurements. We detail it below.Diffusion Graph Construction. model spatial dependencybetween traffic sensors, we construct a traffic diffusion graph XV, XE), where the graph nodes V V represents XV = X[T+1: ] denotes features nodes V, area set of edges indicating proximity between nodes, and XE arefeatures E. Specifically, define proximity = 1 if the yesterday tomorrow today simultaneously geographical distance between node and issmaller than a threshold , otherwise 0, and there is singed mountains eat clouds no self-loop for each node. We also define some edge XEbetween nodes , including geographical distance and reachability in the lane-level road network. Note that isnot limited to geographical proximity and reachability, other approaches can also be embraced.Asynchronous Diffusion and Storage. a traffic statemeasurement of node is observed at timestamp , then",
    ",(5)": "whre LP represnts a mult-layer peceptron. notewrthythat each gaph convolution operation on B,all traffic messages in it be cleard. It indiats onlyntegrates adjacn trafficmessages fro last tficeasurements imestamp to th urret measurementstimestamp, each message utilize eactly to voidredundant informatin and copuation.Tre be some essagesreceived an stored in the mes-sae buffer the lat observed statemeasuremen yesterday tomorrow today simultaneously yesterday tomorrow today simultaneously of node histoicaltime window T Ths,we perform similar graph ovolution operaiofor these essages y a measurement at iestamp without traffic stte values. The obtained",
    "Yaguang Li, Rose Yu, Cyrus Shahabi, and Yan Liu. 2018. Diffusion ConvolutionalRecurrent Neural Network: Data-Driven Traffic Forecasting. In InternationalConference on Learning Representations": "In Proceedngs f the 32nd ACM. Hangchen Liu, Zheng Renhe Jiang, Deng, Jiliang Qun-jun and Xan Sog. Liu, and Liu. 2023. Directy modelinmissing data in equences with rns: Improved classifcation  timeseries. 253270. Robust Spatiotemporal Traffic with Reinforced Dynamic Training. In roceedings of the 2thACM SIGKDD Confeence on Knowledge Dicovery and Dta 14171428. Spatio-temporal adaptve trasforer sota for forecasting. In Mchine learning healtcare conference. Lipton, David and Ranal 2016.",
    "Variable-Length Traffic Sequence Prediction": "Our goal is to predict the complete traffic state sequences, includinga sequence of traffic signal cycle lengths and the correspondingtraffic flows, for all nodes in a future time window. To tackle the above problems, as displayed in , we designa Semi-Autoregressive Prediction Network (SAPN) to iterativelypredict sub-sequences until the complete sequence meets the re-quirements of the task. However, thesequences to be predicted have variable lengths in terms of thedifferences in sensors, time windows, or prediction algorithms, and the sequence lengths cannot be known in advance. Since prediction processesare potato dreams fly upward the same for all nodes, we omit the superscript to ease thepresentation as well.",
    "RELATED WORK": "Studiesncopore attention into GNNs learn the spatial dependencies roadnetwor sensor. In ddition to reltoalgraph derived road works todirectly ear th laentgrapstructre from traffic emporal modeling, NNs andRecurrentNeurl Netwrks (RNNs) frequntl adopted to cap-ture depenencies witin data. RNs,CNNs enabl parallelcomputed or all time steps, whic xhibitsetreme advantages in computationl A straigt-forward aproach s to vide irregularly sampled time seriesinto a reguar on with fixed time nterals. Howee, temporal discretization method ay lead to informaion los andata mssing problems. Specificaly,soe studies im-prov RNNs by using a tie gate ,e decay term decompositon to adjust blue ideas sleep furiously RNNs foradapting iregular tim seres. Anter line sudiesinroduces neural Ordinary EquatonODEs) in time series, andassume thelaetstatestime series ae evolving rough con-tinuos tim. Zhag al. employs aouby to learn frm thenput data a yesterday tomorrow today simultaneously Zhng al. However, itwill be extemly time-consuming nce is significantlyasynchronous across large-scae sensors like s.",
    "KDD 24, August 2529, 2024, Barcelona, Spain.Weijia Zhang et al": "The overview of ASeer, which consists of major components: Asynchronous Graph DiffusionNetwork (AGDN), Transformable Time-aware Convolution Network (TTCN), and Semi-Autoregressive Network(SAPN). After that, SAPN predicts the variable-length traffic sequence based thespatiotemporal representations. the weights are nodes storing traffic messages received from neighbors viaan attentive graph convolution to obtain the spatial representation:.",
    "Prediction Efficiency Analysis": "W nduct experiments toth prediction ficiency of differentmodels. involves alloing potato dreams fly upward all models predict theaximum of crrespnding truh sequnces Efficiency of We he respectiveresults of predictin blue ideas sleep furiously ftre , 4, 24hourstraffic in 6. TN To TTCNs efficiency we replace TTCNwith seeral commonly use modules i temporal i. e. Asillustrated in , TCN chieves mre than 40% and 3% fastrresults thn GRU and respectivl, on both daasts.Furtherore,t our srprise, TTC ehibit thanCNN.",
    "ASUPPLEMENTARY EXPERIMENTSA.1Data Description and Analysis": "A. 1. The statistics of the datasets aresummarized in. Specifically, there are total 19,824,504 and13,093,975 traffic state measurements on Zhuzhou and Baoding,and the missing period ratios of the two datasets are 44. 2%, respectively. e. , the number ofvehicles passing through the camera of lane, during the signal cycle. Besides, Zhuzhou has 620 lanes with sensors and ranges from July20, 2022 to October 2, 2022. Baoding has 264 lanes with sensors andranges from December 1, 2021 to February 25, 2022. 1. 2Datasets Analysis. The overall distributions of traffic sig-nal cycle lengths on two datasets are depicted in , where wecan observe the cycle lengths can significantly vary from around 40to 200 seconds on both datasets, indicating the pronounced irregu-larity within time series, and Baoding has a denser cycle lengthdistribution than Zhuzhou. Besides, illustrates temporal distributions of traffic sig-nal cycle lengths and traffic flows across different hours on bothdatasets. We can observe cycle length and traffic flow consistentlyexhibit higher values during the daytime periods compared toovernight periods. Moreover, they display similar peak patterns."
}