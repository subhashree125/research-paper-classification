{
    "Exeriment": "Our experimental results are shown in. 6002. The v1 version are trained a training set, which is around 10% full data.",
    "What are the important objects in the current scene? Those objects will be considered for thefuture reasoning and driving decision": "* \"S objct theego vehiclenotice irst t goveicle is getting to thelocation? What is the f th object that is first noticed * \"S the ego andwhat action te ego hicle take? What objct shouldthe ego vehicle notice secondwhen the ego vehicle is to thenextpssible location?i of he bjectperceied by ego as second and what the ego vehcle tke? hatobject shoul the ego veicle notice third? hat i the sate of object perceived by teego vehicle a thir andaction should th eg vehicle take?",
    "Dataset": "1, we show 4 examples of questions in DriveLM-nuScenes dataset. 5>. It designed specialformat to represent key objects, consisting of the object ID, camera name, and the objects centercoordinates, * \"S for example <c1,CAM BACK,1088. We chose to change representation of the objects center point to the * \"S objects bounded box forthe followed two reasons:.",
    "Introduction": "Different tes * \"S o questns wer ealuaed usig differentscoringsrategies. Specificaly, DriveLM [SRC+2] desined aies of diverse atural language questions based on varios autonomous drived scenarios, and hemodels were scored based ontheir responses.",
    ": The results on DriveLM dataset": "[CL+0]Holger Cesr, Varun Bankiti,Alex H Lang, Venice Liong, Qiang Xu,Anush Krishnan, Pan, Giancaro an Oscr Beijbom. nuscene: A multimoddataset or 2020. [CWW+23] Zhe Chen, Jannan Wu Wenhai Wang, Weije Su, Chen, SeXing, Zhg hang, Xizhou Lewei u, arXiv prepnt arXiv:231. Kirllov, ric Minun, ikhila Rvi, Hanzi Mao, Rolland, LuraGustafson, ete Xiao, Whitehead, Alexander C Wan-Yen et l. * \"S Seg-met anything. Drivelm: with graph visual questionanswering. 14150,203."
}