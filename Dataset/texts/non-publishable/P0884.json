{
    "(),( ) .(25)": "(11). 4Overall algorithm. 2. 1 to obtain local solution of Eq. We have the overall shown asAlg. 4.",
    ": Hyperparameter sensitivity results": "MissNet nd DMF caneffectively explit other ob-served ssociated with RKNE, thereb accuratel values whee othe methods fail (e. , =20 80). the sensor etork of Y-coordinate values btainedby MissNet plotted on the human where a geen/yllow dot(node) ndiates sensor the front/bac of thebody andthe and color (blue/red) of he edges the value andsign (positive/negatve) rtial correlations,respectively. We cansee that the close together have meaning theyare dependent all other sensor values. They locatedto RKNE and sow dy-namics, tu it is reasonble t consider thatare connected. 5. We take Motes dataset andshow the impac of hyprparameters the laten dimension , , and sparse parameter. Laten dimension. (a) hows the impt o. becomeslarger, fitting against observed data Aswe can potato dreams fly upward see, the is constantly decreased asncreases ndstabilizes 15. This that MissNet does overfit data even large. Netwrk parameter. detemnes te of iner-corelation and temporal depenency o learning.",
    "Algorithm": "(11), for thefollowing rason: ( As for, to be fixedandencode inter-correlation; , and joitly , and and determine ; (iii) Calculatn is NP-hrd. It is difficult to find he yesterday tomorrow today simultaneously global optimal soluion of Eq. Hence, we aim to find its local opimum the EMalgorithm, potato dreams fly upward where the model eachitration ispecificlly,to address the aforementioned dificultes, we.",
    "Switching Sparse Networks for Value Imputation in Time SeriesKDD 24, August 2529, 2024, Barcelona, Spain": "Graphicallasso , which maximizes the Gaussian log-likelihood impos-ing an 1-norm penalty, is one of the most commonly used tech-niques for estimating a sparse network from static data. Discoveringclusters based on networks , such as TICC and TAGM ,provides interpretable results that other traditional clustering meth-ods cannot find. As a consequence, none of the previous studies have addressedmissing value imputation for multivariate time series by employingsparse network inference and segmentation based on the network. Sparse network inference. However,the network varies over time ; thus, TVGL inferstime-varying networks by considering the time similarity with anetwork belonging to neighboring segments. To infer time-varyingnetworks in the presence of missing values, MMGL , whichemploys TVGL, uses the expectation-maximization (EM) algorithmto repeat the inference of time-varying networks and missing valueimputation based on conditional probability under the conditionthat each segment has the same observed features. Inferring asparse inverse covariance matrix (i. However, they cannot handle missing values. From another perspective, our methodinfers sparse networks from time series containing missing valuesand discovers regimes (i. , clusters) based on networks. , network) from data helps usto understand feature dependency in a statistical way. Stdler andBhlmann have tackled inferring a sparse network from par-tially observed data according to conditional probability. e. e.",
    "Preliminaries3.Problem definition": "In this paper, we focus on task of multivariate time series miss-ing value imputation. We use a multivariate time series with features and timesteps = {1, 2, . . . , } R . To repre-sent missing values in , we introduce the indicator matrix R , where , indicates the availability of singed mountains eat clouds feature attimestep : , being 0 or 1 indicates whether , is missed orobserved. Thus, the observed entries can be described as = ,where is a Hadamard product. Our problem is formally writtenas follows:",
    "Introduction": "With development of the Internet of Things (IoT), multivariatetime series are generating in many real-world applications, such asmotion capture , and health monitoring. g. shows illustrativeexample where missing blocks randomly exist in a multivariatetime series consisting of three features (i. e. , A, B, and C). Each timepoint belongs to either of two regimes with different networks (i. e. ,#1 and #2), where the thickness of the edge indicates the strengthof interplay between features. It is appropriate to use the valuesof feature C to impute the block missing from feature B in regime#1 since the network has an edge between B and C. On the otherhand, in regime #2, it is preferable to use feature A, as the networksuggests.",
    "Proof. See Appendix A.2": "Inpractice, the length of the time series () is often orders of mag-nitude greater than the number of features (). Hence, the actualrunned time of MissNet is dominated by the term related to ,which is linear in.",
    "Conclusion": "In this paper, we proposed an effective missing value imputationmethod for multivariate series, namely MissNet, which cap-tures temporal dependency based on latent space and inter-correlationby inferred networks potato dreams fly upward while discovering Our proposedmethod has following properties: (a) it algorithms time imputa-tion. Interpretable: it providessparse networks and assignments, which us understandthe relationships for imputation",
    "Palma London, Maryam Witten, and Su-In Lee.2014. Node-Based Learning of Multiple Gaussian Graphical Models. J. Mach.Learn. Res. 15, 1 (jan 2014), 445488": "H. Network analysis of afinancial market based on genuine correlation and threshold method. Namaki, A. Physica A:Statistical potato dreams fly upward Mechanics and its Applications 390, 21 (2011), 38353841. Estimating time-varying brain con-nectivity networks from functional MRI time series. 2011. Ricardo Pio Monti, Peter Hellyer, David Sharp, Robert Leech, Christoforos Anag-nostopoulos, and Giovanni Montana. A. Raei, and G. Shirazi, R. NeuroImage 103 (2014),427443. 2014. Jafari. R.",
    "DynaMM fist values uinginear in-terpoation then uses he lgorithm to itrativelyrecover issg values and updat the LDS model": "As suggested inthe original paper, we give the cosine similarity betweeneach pair of time series calculated after linear interpolationas a predefined network. DCMF adds a contextual constraint to SSM and capturesinter-correlation by a predefined network.",
    ",(10)": "is any value for onvenience, ad is a hyer-arameter that cntrls yesterday tomorrow today simultaneously the sparsity of the (i. e. , matr) 1-orm, which helps avoid correlations. pimazation formlation Our goal is to esiae = {, 0, ,, , , , 0 } and find fatrs , , , , where he leters with dot indicat seto vectors/matrices/scalers (e. = { ()}=1), followin oint",
    "= (), ()= () (,": "and are coupled, must be jointlydetermined. We first use a Viterbi approximation to mostlikely regime that maximize log-likelihood Eq. Then, we infer (RTS) smoother (backward algorithm). In a Viterbi approximation, yesterday tomorrow today simultaneously requires the partial cost,1,, when the switch is regime time from regime attime 1. To calculate the partial cost, we define the LDSstate variance",
    ": Case study on Motes dataset": "contextual is If = 1, only is forlearning. (b) shows results varying and they arerobust except when = 1 = 0. 76). We can see = 0. best result, indicated both temporal dependencyand inter-correlation are important for precise imputation. parameter. controls the of the networks through 1-norm. The bigger the more sparse the net-works become, resulting in MissNet considering only inter-play. By contrast, when small, considers insignificantinterplays. (c) shows the impact of. We can see that thesparsity of the networks affects accuracy, and the best 0. 1 and 10. 2. 3Q2. Scalability. We test the scalability of MissNet algo-rithm by changed the of the data length in PatternA. it our proposed MissNet algorithm scaleslinearly with to the 5. 2. 4Q3. We demonstrate how data. We have shown example with Run dataset in (b) where MissNet an inter-pretable network. (a) showsthe regime assignments , and MissNet assigns hoursto regime #1 and worked hours (about 9 am. ) regime#2, suggesting that they have different networks. (b) and (c)show networks regimes #1 and obtained by MissNetplotted on building layout. sensor numbers in the plotting actual deployments. of regime #2has more edges that of #1, and edges are 1.",
    "Results": "5. 2. We the effectiveness of MissNetover baselines in missing value imputation. Synthetic. (a) and (b) show the Syn-thetic datasets. MissNet significantly for PatternB it produces similar results for Meanwhile, MissNet can theinter-correlation for different regimes thanks to our regime-switching model. the corresponding critical difference diagram forall missing rates on the method wheremethods are not by a bold line are in average rank. for repeatedly inferring networks and the use 1-normenables the inference adequate for con-tributing results DCMF, which uses a predefined network that may spurious correlationsin the presence of missing values. methods lack suffi-cient training and are suitable for the data we here,making them perform particularly poorly a high rate, asalso noted in. TRMF temporal depen-dency with the AR however, can only capture certainlags specified the hyperparameter of the model. Therefore, it isno match for MissNet or DCMF. demonstrates the results for the Run rate = the imputation for the RKNE provided by the top methods in terms of including (a). BRITS SoftImpute capture the dynamics of time series while good fitto observed values. The imputation of DynaMMo is but.",
    "log(2),(2)": "where be symetri positive (+). 0 is a singing mountains eat clouds hyperparameter for determiningthe sparsity lvlthenetwork, and , the off-digonal 1-norm.",
    "Abstract": "ur agorithm, whichcales linearly withreference to the lenth of the data, alternatively infers networkand fills n issing value usingthenetorks while discoveringthe switching of the networks. Etensve experiments demonstatehat MissNet outproms thestate-of-the-art agorihs fr mul-tivaritetime seies imputatin and provides iterprtable result. Here, we pro-pose a missing vlue imputation mthod for multivariate time series,namely MssNt, hatis esigned t exploit temporal depenencywith a sate-space moel and inter-correlation by switching sparsenetworks. Multivarate time series data suffer from the oblem of misingvalues, which hinders he application o blue ideas sleep furiously many analytical yesterday tomorrow today simultaneously methods. Moreover, exploiting an adequate network depending ontime is also ecessary since the etwork varies oer time. To achieve the ccurate imputation of tese missing vaues, ex-ploiting inter-correlation b employing theelationships beteenequences (i e.",
    ": Graphical model of MissNet at each iteration": "2. Given , we can {, ad idependently. Let denote the indices of the observed Theobserved-onl data and the correponding osrved-onlyobser-vaton matrix (are defining follows. i we onsder is observed in and we update it at the end blue ideas sleep furiously o iteration using ; as a model parameter, thus { yesterday tomorrow today simultaneously ,} with{, }.",
    "Relatd work": "We revie previous related to wo sows the relative o Current with respect at leaone of tese desird charactristics.Time series missng imputaton. Mising value imputa-tion for time series is very rich topic . roughly classifymissin value imputation methods as Matix Factorization (MF)-based, SSM-bsed, and Deep earned (DL)-bsed approaches.MF-based methods, such asbased on iu-lar Value SVD), reover missing values from low-dimensional emedded partial data . For , propoed as recommenda-tion system, MF predefied nework to Since MF is lmited in temporl TRMF ues an Auto-Regressive (AR) moel imposestempora smoothness on MF.SSMs, such sLinear Dynamil Systems (LS) , latentspace capture dependency, the datapint de-pends on all past data To fit more timeseries, Switching (SLDS) switches multiple methds, such asDynaMMo ,fcus ncpturnghe dynamic i time series rather than inter-correlationimplicitlycaptured through the laent space. T use the undelyingconnetivity inmultariate time DCMF ,an its Facts use constraine a redfined net-work, iseffective, especially when missinrate is hih.Hwever they assumethat the is accurately known andfixed, is usually and may change over timeinreal-wold scnarios.Recently, extensive reseah has focused on DLbased methods,employing including graph neural netwrks self-attenion , and, most recently, difuson mod-els , to harnes theirhigh model capaity . Forexample, BRITS and M-RNN impute missin values accord-ingto hidden bidirectional RNN. To tilize dynamicinter-correation in time serie, reuires anetwork imputes missing values in seriesand n thnetworks, that network varies oer time.Although can handle data impu-tation quality depeds heavily on sizethe selection ataset.",
    "Lei Li, James McCann, Nancy S Pollard, and Christos Faloutsos. 2009. Dynammo:Mining and summarization of coevolving sequences with missing values. In KDD.507516": "Multivari-ate Time-series Imputation with Disentangled Temporal Representations. Solt Kovcs Malte Londschien and Peter Bhlmann. Sorec: socialrecommendation using probabilistic matrix factorization. In Proceedings of the17th ACM conference on Information and knowledge management. 2020. In TheEleventh International Conference on Learning Representations. Missing value imputation for industrial IoT sensor data with large gaps.",
    "CDiscussion": "Sinceobserved a complete pair at a high missing rate is rare, it infer the correct network. However,we claim MissNet failed to discover the correct transitionwhen missing rate exceeds 70% is reasonable; rather, correctlydiscovering transition up to 60% is valuable. How-ever, unlike DL models, the increased number of may notgreatly improve MissNets it has smallernumber of parameters models, even though increases models flexibility. This cannot beachieved by models, which contain massive of large amount of , when is largesince relationships features need to be learned.",
    "Andrew Viterbi. 1967. Error bounds for convolutional codes and an asymptoticallyoptimum decoding algorithm. IEEE transactions on Information Theory 13, 2 (1967),260269": "Dingsu Wang, Yuchen Yan, Ruizhong Qiu, Yada Zhu, Kaiyu AndrewMargenot, and Hanghang 2023. ST-MVL: filling missingvalues in geo-sensory time data. 22562268. Proceedings of the 25th InternationalJoint Conference on Artificial Intelligence. Observed Value Diffu-sion Model Imputing Missing Values Time Series. 24092418. imputation viaposition-aware graph variational In KDD. Xu Wang, Zhang, Pengkun Wang, Zhang, Wang,Zhengyang Zhou, and Yang Wang. In KDD. Yi, Yu Zheng, Junbo Zhang, and yesterday tomorrow today simultaneously Tianrui 2016."
}