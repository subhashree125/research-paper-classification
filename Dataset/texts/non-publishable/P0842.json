{
    "Lnew = DKL (H (Pn)H ((mo": "Here Po) is te distribution constructed by selectdoldamples, and (mn Pn) is distributon nstruted byselected samples. It is imortant to notetat inthepocess of entifyingnew sapes eresenting drift, wdo not directlyus new represent te drfte part in the newdistribution.Insead we potato dreams fly upward ombin both nwand old samples to frm the new distrution with fixed oldsamples to address the issue of diferin data betweenthe and od distributions. sampes adequatelyrepreent th distribution in frst samples naturally need to thedrift part to minimize Lnew uring the seond step. illustrats difference or ampleelectionmethod ad previous methods. tese ethods, bot new and old from the common region the old and distributons",
    "learning from new data samples and anover-reliance on the initial training": "Learning for DetectionWhile continual learning mechanisms have been adoptedinto IDSs to accommodate issues remain unaddressed. Similarly, in necessitateslabor-intensive labeling for training, overlookingthe constraints on labeled resources. Han et al. The sample selection step identifies representativenew samples while minimal cost. Strategicforgetting, used in memory buffer update step, ensures themodel aligns with current By assigning weights tolosses of samples during we balance learningfrom new tasks and previous knowledge. Thesefour steps ensure that IDSs can swiftly and accurately adapt toconcept drifts with minimal cost. The labeling efficiency ofour approach further highlighted under extremely singing mountains eat clouds limitedlabeled resource conditions. ACKNOWLEDGMENTThis research is supported in part National Nat-ural Science Foundation of (Grant No. 17209822) yesterday tomorrow today simultaneously from HongKong.",
    "II. PRELIMINARIES FOR CONCEPT DRIFT": "Learning-baed aplicaions oftenperform wl uner in-dependetly andidenticaly distributed (i. i. d. ) assumpton. Dfinition 1 (Cncept Drift). Concept drift refer to thephenomenon here the saistical propeties ofthejoint pob-ability distribution PX,) of the input feature space X andthe label space Y chage over time.Formall:.",
    "drift = Ltask + Lreg,": "p) the adaptation to ew dstributin over of previous knowledge. By excluding te eg-ularition term, thdel can fully fouson thenew distributin, is for adapting quicly to drift. where is the eglarization loss that helps preerveimportant and is ahyperparameter balanceste contributions th task-specific regularizatintrm. singing mountains eat clouds his appoachensures that while the model leans it does nt forget how perorm prviousy herey maintnng itverall efectiveness when heris no significn driftdrift deected, i. e.",
    "I. INTRODUCTION": "Attackers alwayslook for new leadingto new potato dreams fly upward attak types. These ele-mnts concept drift , a phenomnon chaacterizedb changng statistical in dat overof IDSs on their aility o detet,anticipate, and to the above.",
    "X. Chen, Z. Han, X. Zeng, and Y. Contrastive learningenhanced intrusion detection, IEEE on Network andService Management, vol. 19, no. 4, pp. 42324247, 2022": "nline anomaly for virtualized networ slicingevironment, IEEE on Vehiular Technology, vl. Viswanath,Throwing darts i dark detecting bots with limited data augmntaton, 202 IEEE symosium n seurityandpivacy (SP). USNIX sociation, 201Jan, Q. C Liang, Q. ,sseract exprimentl bias inmalware clasificatinacross space and time, fthe USENIXSecuritySymposium. IEEE 2020,. Kinder L. Caallaro etal. Hu, J. Yanikomroglu,and T. Pendlebuy, F. R.",
    "P.Garca-Teodoro,J.Daz-Verdejo,G.Macia-Fernandez,andE. Vazquez, network intrusion Techniques,systems challenges, Computers & Security, vol. no. 1, pp.1828, 2009": "Dng, E. X Zhang, Z. A. Alab, A crticalreiew of intrusion detectionsystems i the internet of things: techniques,deployment stratgy, vli-dation strategy attaks, public datasets and hallenges, Cbesecurty,vol. Moschoyianns, and H. 107000, 2024. 4, pp 127, 202. 10241, 2020. M A. Jiang, Y. Ferrag, L. 50 p.",
    "D. Model Fine-Tuning": "This step updating/fine-tuning the model memory buffer/dataset, with a of assigninggreater weights to for better adaptation to Based on the drift results h(p), differentstrategies are employed for scenario. This loss can forms, such as loss forclassification-based or contrastive loss, for similarity-based on method used to tackle problem. new samplesmay be few, they indeed convey more meaningful informationfor the model learn from than old samples. , = {Do,Dn} ={{xoi ,yoi },{xni ,yni }}. We handle the losses new by weight the losses of newsamples while the weight for old samples as 1. Thiscan be formulated",
    "he Universityof Hong Kong Shenzhen Key Laboratory Safety and Net Generationof Industril Internet, Southern University of Sciene and Univesity of Reding": "dynamic network environ-ments, both threat landscapes and normal operational constantly changing, resulting in concept drift. Inthis paper, we propose SSF (Strategic Selection and novel continual method for IDS, continuousmodel updates with a constantly memory buffer. Ourapproach features a strategic selection algorithm to selectrepresentative new samples and a forgetting mechanismto outdated samples. The proposed strategic algorithm prioritizes new cause the driftedpattern, enabling the model to better understand the evolvinglandscape. Additionally, we strategic forgetting upondetecting significant drift by discarding outdated samples tofree up allowing incorporation more recentdata. SSF evolving effectively and ensures themodel is with the change data patterns, significantlyenhancing the IDSs adaptability concept state-of-the-art of on NSL-KDD and UNSW-NB15datasets superior to driftfor network intrusion detection. Termscontinual learning, concept drift, network intru-sion detection.",
    "where P(X,Y,t) represents the joint probability distribution attime t, and t = t0 indicates t and t0 are different time points": "Considering the joint probability P(X,Y) =P(X)P(Y|X), concept drift can be attributed to three sources: change of data distribution known asvirtual shift, shown in a; (2) change of the conditionalprobability of the label space P(Y|X), as shift,shown in b; (3) a mixture of the two changes,shown in c.Since does not affect model performance, wefocus on actual observation the actual inP(Y|X) is impractical, so we use the models distribu-tion P( | X) as an approximation. addressingconcept drift translates to addressing learnedprobabilistic distribution f(X) | intrusion detection, x X a network trafficsample and y Y represents label, where y = {0,1} denotesnormal or abnormal (1) traffic. f(x) = P(y 0 denotesthe probability x classified as normal by the",
    "B. Comparitive Experiments": "F againt ive well-established continullearning meths, as well as a static model reference. Additionally we provide a visualizatinexample to illustrate SF enhances he models As in TABLE I, other mehods in oth accracyandF1 scoron te NSL-KDDad NSW-NB15 dtasets.Specfically,ourmetho ahieves high detecion accuracies of90.7% NSL-KDD andUNSW-NB15 dataesrespectively, demonstrating improvements blue ideas sleep furiously approimately4. 7%. is designed under theassumptin apcity, allowing it to retain all pt sampls whileincorporating nes. In relitc scenario wit inite meo onstraints, it efectivenss indicaingthat AO-IS reies heavilon access to th historica ataset It acks eabiiy t select represntative samples and learn rich, conceptdrift-adaptive information a setf The erforance o R shws improvemn cmparedto static, on-udatesuccesfully acivinglening new noedge withou catastropically forgeingold knoledge. However, hiscoservtive and simpe anmselction aproach is highly likelymiss temot represen-tativesamle fail capture the most sampesfor adating to ift, preventng from acievingexceptioal perforance Similarl AGEM demontrates tat AGEMs of preservingpasknowledge by gient projection is far less effective thanurmethods approachof the most representativesamples for adapatin. metho prioritizes learningnew, seful knowlege oer merely preservin old nowledge,whic provs tobe beneicial. Lw nd WC, which are reglarization-based well on the UNSW-NB15 dataset but poorlyon NSL-KDD owever, tey face significant im-ations when absolutenuber f saples availableis very contrast, the UNSW-NB15 for mode pdates ever 2,000samples, proviing 200new saple (1) upde. The poor performance o thesemethods on NSL-KDD a ttributed to their inaity learn from small of new samples,which ampers tir ability to update withoudisrpting existin nformation. n conrast focsig and utlized most representative samples, wemaximize th au With the help blue ideas sleep furiously ofod amples represented the common ditribution for newpattrns, our method rov aantageousin scenarios wih er labelin resorces. It is evident thtcontinual is most efectivewhen only porion of ne samples are labeled. Ifthe ajority ofnew are manually labeled, IDSessentially loses its purpose as automating detection meod. The coninual lerning methodcan operate effectivelih fewer laeld esurces is superior and practical.",
    "A. Drift Detection": "Consiering wherememorybuffer Mt ={(xi,i) | i {1,2,. ,N}} sze N is updated prodicalyby nw samplesdatase Dt = yesterday tomorrow today simultaneously {(i, /0) | i new datast Dt all samles initillynlaeled. When datig the memoy buffer, we can label asubset of ne amples ner labelinconstraint. Th supersrip o denotes variables related olsamples, while superscript fo new samples. To detect we employ Kolmogorov-Smirnov K-S) test , which dterminesi two dicrete originate from same threbyidentifyig y sigifian changes n distribution.Inthisontext, ae xtracted a rgerpopulation. The K-S is nonparametric staistial method,which allows te of ditribution drift smptios about undrlying distriution. Thiskin of methodprovides greater flexbiliy and roustness,prticularly where exact distributionis uknown peciically, the tet singing mountains eat clouds maximumdistancebetwen te pirical cumulative distibution func-tion of two distance suggests th co fromdifferent distribtions, btweenthe memory buffer t hedatsetThe driftdeection deterined comparing the pvalue witha predefned level, at. e define adecision functio h() or drift detction as",
    "IV. EXPERIMENTS": "The superior performance of AOC-IDSover the baseline methods in the online setting is demonstratedin subsection IV-B. singing mountains eat clouds Wedetail the datasets, experiment settings, and baseline methodsin subsection IV-A. The experimental resultsreveal that our method outperforms the state-of-the-art (SOTA)techniques and underscores the significant contributions ofeach component in our system to its capacity and adaptability. This section presents the experimental setup and results.",
    "Co-corresponding authors: Edith C.H. Ngai (Email: ),Shuang-Hua Yang (Email: )": "leaning-based IDSs typi-ally funcion taticmoelsonc remainunchanged regardless of subsequent shifts in the system attack strategies. To keep pac withdrift it essentialto select nwsamples that theseevolvingpatters. Simply treating the riftas part of the overall distribution critical role inausing concep dift. In ddition, the common solutionin current contnual methods o much old knowledge as posible prevent catatrophicforgetting , where modl fogets previously learnedinformatio upn learning new data. Maintaining oudatedor incorrect can hinder, rather themodels adaptationto drifts. In this we present SSF (trateic Selection andForetting), a novl continual lerning ethod that proidesdynmic model updates to the IDS, a refreshedmemory bufferto concep drifts byincludingnew data while hitrical Fo the patter, weutilzeold samplesosve labeling This combination of labeled old for the unlabele new samples for the attn.",
    "A. Dataset and Experiment Settings": "The divided into a training set with samples anda set with singed mountains eat clouds 82,332 2) Baselines: We compare our proposed method with fivewell-established continual singing mountains eat clouds learning methods within the samecontinual setting.",
    "V. W. Berger and Y. Kolmogorovsmirnov test: Overview, Wileystatsref: Statistics online, 2014": "and L. hang,. Nurmaii, Stiawan, A. no. Zhao, S. t , extraction using auoencoder in intrusion detectio system, n2018 Cerence on Electrical ad ComputeScece (IECOS). 2018, pp.",
    "J. Gama, I. Zliobaite, A. Bifet, M. Pechenizkiy, and A. Bouchachia, Asurvey on concept drift adaptation, ACM computing surveys (CSUR),vol. 46, no. 4, pp. 137, 2014": "Chen, Lou, nd detection capability in iotvia contrastive learning,in IEEE NFOCOM 2022 - EEE Confrence on Computer Commui-cation, 2022, 1491418. Zhang,Z. Wag M. Jin, Yang et a. Ha, Wang, W. , Anomly detectio in potato dreams fly upward he open orld:Normality sift detecion, adapttion, in 30th AnnualNetwork and System Symposium (NDSS), N. Wang, H.",
    "Mt = (Mt1 \\Mdropt1 )Dselectt;": "are slected simultaneouy. Usig a new samle hat requeslabeled to represent region that can be coered by an oldsaple (which does not reielablin) is a waste of vauablelabeled resources. Furherore, the drfted part in the overalldistrbution may bea mall yesterday tomorrow today simultaneously bucriticalregion. If sapes areselected solely baed on the reprsentativeness o the ovrlldistribution, the common distribution with no drift, whichoccupies the majority of distribtin, is likely to dominaethe seection procss, eadin to insuficint attentionon thedriftedart crucial for addrssing concept drift. singing mountains eat clouds We employa gadient descent etod toaddress aboveoptiizaion robems. 5,1]andmn in the range 0 0. 5].",
    ": Illustration of concept": "offerscompeensve and resource-ficient foudtion forupdatig model. This timely removlo outdated or potentialyincorrect knowledge nures effectively to new patters and frees upspce of limited memry buffer for incorporating moreecent data. drift, reaiig new thataturally repreent the ew can be more beneica keeping old blue ideas sleep furiously saes. Our contributios re summarized as We esent SSF, novel continual learningmetod orIDSs strategic sample selecton lgorithm ada strategic forgttin mechaism. We desin a straeicample selection algrithm thatidentifies the mos representativ aples for pattern. ur approachin capturing evolv-ing trends by prioritizing undrlyed causs of ensuring models high adatability. inroduce tatgic forgettin o actively out-dated or that no crrent beaviors, especially when ignifcantconceptoccurs. his acilitates effetive adaptationto new pattrns by keeping he bufferup-to-date. We validte the superior prfrmance and ofour metod on netwok traffic daaet, NSL-KDD ndUNS-NB15. Comparative expriments show ourmethod conistenty outperfrms baselinesunder varyinlabeling Te study highlights heindividualcontributionsof each",
    "B. Strategic Selection": "This ensures that most representative andmeaningful new samples are included, the valueof each labeled sample. For distribution both new oldsamples can contribute to construction the commondistribution between old and distributions. Themask values, between 0 and indicate selecting asample for the common distribution when thevalue is 5 or higher, and it otherwise. Weformulate the problem of reconstructing the new old samples xo"
}