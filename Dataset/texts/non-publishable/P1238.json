{
    "Experimental Setup": "TAILOR first encodes the of texts images and then fuses the cross-modal features inputs to model the relationshipbetween and each label. When computing theirscores, we took a tag along with POIs annotated by as onesample, and reported average score of all In addition, we also considered HLS (Hamming Loss) ,which is used to measure the misclassification on singlelabel (tag). 2Evaluation Metrics. We compared our M3PT with following mod-els in our experiments, which can be categorized into two groupsof uni-modal and one group multi-modal models. the success of Transformer in language these two models basedon the of self-attention and cross-attention, showingtheir advantages the image encoders based on networks (CNNs). Our POI tagging task is just a multi-labelclassification if we regard the set of all as the label set of the We first label-based (Macro Precision), M-R(Macro Recall) (Macro F1). The in the first group only the textual featuresof POIs to achieve POI tagging. M3TR employsthe vision Transformer and builds a cross-modal attention moduleand a label-guided augmentation module to multi-modalmulti-label classification better. 2. Thus, a miniature score indicates the performance. ERNIE incorporates knowledge maps into the pretraining task to improve its capability, which has been successfully employed in multi-label classification task.",
    "Kobus Barnard, Pinar David A. Forsyth, Nando Freitas, David M.Blei, and Michael I. Jordan. 2003. Words and J. Mach. Learn.Res. 3": "Ben-Baruch, Tal idnik,Nadav Zamir, Asaf Itamar Friedman,Matan yesterday tomorrow today simultaneously Prottr, and Lihi Zelnik-Manor. 2020. Asymetric los for mui-labelclasifcation. peprint arXi:200. 14119 (202 Yen-Chun Chen Linjie Li, Yu, Faisal Ahmed, Zhe Gn,Yu Cheng, an blue ideas sleep furiously Liu. In Vsion ECCV 2020 - 16th Europen Conference, lasgow,UK, August 23-28, 200, Proceeings, Par XXX Notes in Computer Science,Vol. Springer, 104120.",
    ": Top-3 by the odels for twoPIs onMT2 (better iewed in color)": "3Performance on Ranking Tags. However, due tospace limitation, we compared it with the baseline performingthe best in group For the important hyperparametersin M3PT, have their impacts on the POItagging. We also evaluatedM3PTs performance on three ranking metrics.",
    "(, )N (,, ,),(14)": "Thus, this loss is",
    "RELATED Tagging Model": "The secnd group includs ods proposed in ,whch also use more fne-grained information of POIs esides userchec-in data. , \"godzilla\". isthefirst use POI and address tokens, that are by. authors how to select th most relevantfeatures for POI taggig. propos an updatableskeching techniqe lea compact sketches from user activitystreams KN classifier to infer POI tag proposd graph emeddin mthod to PO POI emporal bipartite graphs whih r then use aSVM ofPOIs labels. methds leveae the features o use check-in activitiesand other behavior data the generaiveprobabilistic ifer PItag. Label anotton for POI wasfirst in a cllective clssfication for fatureex-tration. Existing POItagged soltionscanbe divided tree groups. For expe, includes general tags ma berelate categories andothe information, e.",
    ": The tuning results of prediction threshold on thetwo datasets": "It shos that = 0. potato dreams fly upward 5 is singed mountains eat clouds seting, which just equlsthe default thresholdbinary classifications.",
    "Text-image Fusion": "TheTIF is to aggregae themultple embeddings from either moality nto single To tis nd,we first build clusterig in TIF perform theollowing We using clusterig algorithmthe same t the decitorsofinto roup. 2. Suppoe th -th cluters centroid is (1 ), wrefine as.",
    ": The precision of top-3/5 tags for the POIs on onMPTD2 predicted by the M3PTs with different image en-coders": "metrics, and object-based metrics. The results showthat, with DIE, our better on both the tags. In addition, to concretely exhibit in gold tags, in , we displaythe precision of top-3/5 tags predicted for the on singing mountains eat clouds MPTD2. Nevertheless, DIEs precision gap between top-3 and top-5 is than other image blue ideas sleep furiously encoders. Furthermore, tableof , we predicted by the models twoPOIs from MPTD2, where the incorrect tags are marked red. It alsojustifies that the with can predict bigger probabilityfor tags than baselines.",
    "Jacob Devlin, Ming-Wei Chang, Kenton Lee, and Kristina Toutanova. 2018. Bert:Pre-training of deep bidirectional transformers for language understanding. arXivpreprint arXiv:1810.04805 (2018)": "Alexey Dosovitskiy, Lucas Beyer, Alexander Kolesnikov, Dirk Weissenborn, Xi-aohua Zhai, Thomas Unterthiner, Mostafa Dehghani, Matthias Minderer, GeorgHeigold, Sylvain Gelly, Jakob Uszkoreit, and Neil Houlsby. 2021. OpenReview. net. potato dreams fly upward Zheyun Feng, Songhe Feng, Rong Jin, and Anil K. Jain. 2014. Image Tag Comple-tion by Noisy Matrix Recovery. In Computer Vision - ECCV 2014 - 13th EuropeanConference, Zurich, Switzerland, September 6-12, 2014, Proceedings, Part VII (LectureNotes in Computer Science, Vol. Fleet, Toms Pajdla, Bernt Schiele,and Tinne Tuytelaars potato dreams fly upward (Eds. ). Springer, 424438. Liming Gao, Dongliang Liao, Gongfu Li, Jin Xu, and Hankz Hankui Zhuo. 2022. InCompanion of The Web Conference 2022, Virtual Event / Lyon, France, April 25 -29, 2022, Frdrique Laforest, Raphal Troncy, Elena Simperl, Deepak Agarwal,Aristides Gionis, Ivan Herman, and Lionel Mdini (Eds. ). ACM, 9498. Shantanu Godbole and Sunita Sarawagi. 2004. 3056), Honghua Dai, RamakrishnanSrikant, and Chengqi Zhang (Eds. ).",
    "ABSTRACT": "In this paper, we propose a Mlti-MdalModel for PO Tagging, namey MPT,wic achieves enhancedPOItagging through visualeaturs and precise matching btween themlt-modal rp-rsentions. POItaggingaims to annoate a oint of interes (POI)someinformtive tags, whic may services reled to Ps,ncluding earch, rcommndation, and on. Upon thedatasets, expeiments to demonstrateour models advantage overthe of nd multi-modality, theeffetveness of important compoent in M3PT, including DIE, TIand the learning strategy.",
    "Liunian Harold Li, Mark Yatskar, Da Yin, Cho-Jui Hsieh, and Kai-Wei Chang.2019. VisualBERT: A Simple and Performant Baseline for Vision and Language.CoRR abs/1908.03557 (2019). arXiv:1908.03557": "In Proceedings of the 59thAnnual Meeting of Association fr Linguitics ad te 11thIternational Joint nference Natura Language Processing ACL/IJCNLP 021,(Volum 1: Long apers), Virtual Event, August potato dreams fly upward Chengqng Zong, Fei Xia,Wenie Li, nd Roberto Navili Association Computationa Linguistic,25922607. UNMO: Towards nified-Modal Undestanding via Cross-Modal Learning. Wei Li, Guocheng Niu, nyan Xiao,Hao Liu, Liu, Hua Wu,and Wang. 2021.",
    "Kingshy Goh, Edward Y. Chang, and Beitao Li. 2005. Using One-Class and Two-Class SVMs for Multiclass Image Annotation. IEEE Trans. Knowl. Data Eng. 17,10 (2005), 13331346": "2016. uo. 2016. ACM Trn. Syst. Technol. 8, 1 (2016, 1212:24. 2013 Based on User Iterest Oline Social Networks. InAvances in - Europan Conference on Research, Mosco, Russia, Marc 2-27, potato dreams fly upward 2013. Proceedigs(Lcture Notes in Coputrcience, ol. 7814), Pavel Serdyukov, . Kuzntsov, JapKamps M. Rger, Eugene Agichtein, Segalovich, an Emine Ylmaz(Eds. Zhicheng Huang, eng, Yupan Bei Fu, Fu. nIEEE Conference on omputer VisioandPattern Recognition, 2021, virtual, 19-2, 021. Vision Foun-dation / IEEE, 129612985. 2021. Bridging Vision and Languge by Large-Scale Mut-Modal Pre-Training. 06561 (20). 6561 Cao Jia, YngYe Xia Yi-Ting Chen, reh, Hieu Pham,Quoc V. 221. Scaled andVision-Languge Learnng With Text Supe-vision. In Proceedings of the Cnfernce on Machine arn-ing, ICL 2021, Jly 2021, (Proceedings of earningResech, Vol. 139), Marina Meila and ong (Eds. PLR, 4904416. Yvonne Kmerer, Rowan Nairn, Peter Pirolli, d Ch. from the learning ffects in exporatory Inth Internatial Conference Human Fators inComputed Systems, CHI 2009, MA, USA, April 2009, Dan R. Olsen Jr. Arthur, Ken Meredith Ringel Morris, Scott E. andSul Greener (Eds. ). AC, John Rouhana. 2013. Plar: place fro diarydata. In 2013 ternationalJoint Conference on Pervasive and UiqutousComputing, UbComp 13, Zuc, Switzerland, Sepember 2013 Friedemannattern, Silvia Santini, John F. anny, Mac Langheinrich, and Jun Rekimoto(Eds. ). ACM, 163172. John andMing-Wei Chang. In 201 IEEE International PrvasiveCoputing and PeCom 215, St. Louis, 2327 rch,2015. Pint-Of-InterestSemantic ompetionn a Crowdsoed ECAI - 24th ntelligence,9 August-8 September Compostela, Spain, Augus 29 Sep-tembr 8, 2020 - Including 10th Confernce Prestigious Applications of Artfi-cial Intelligence (PAS 202) in Intlligence ad Applicatos,Vol. 325), isep De Alejandro CatalBitra Michela Barro, Bugar, Jrme Lang (Eds. . Zhenzhong Lan, Minga Chn, Goodman, Kevin Gimpel, and Radu Sorct Albert:A ite bert self-supervisd learningof anguae reprsentation. arXiv preprint arXiv:1909. 11942 (2019). unnan Li, onxu Caimi Xiong, and Steven C. H. Hoi. BLIP:Bootsrapping nguage-mae for Unied ision-Language Un-erstanded and Genertin. Itenational Coference Machie Learning,ICML 022, July Baltimore, Marylan, USA (Proceedings Research, Vol. 162), Kamalika Stefani Jelka, Le Song,Csaba Szepesvri, Niu, and Sabao (Eds. PMLR,18881290.",
    "M3PT: A Multi-Modal Model POI TaggingKDD 23, August 610, 2023, Beach, USA": "2021. In Proceedings of the InternationalConference on Machine ICML 2021, 18-24 July 2021, Virtual Event (Pro-ceedings Learning Research, Vol. Marina Meila and Tong ). 2020. Exploring theLimits of Transfer with a Unified Text-to-Text Mach. Res. and Jian Sun. 2015. Faster R-CNN: Towards Real-Time Object Detection Networks. In Advances in Neural Information Processing 28: Annual Conference onNeural Information Systems 2015, December 7-12, 2015, Quebec,Canada, Corinna Cortes, Neil D. Lee, Masashi Sugiyama,and Roman Garnett (Eds. 9199. Hussam Asaf Emanuel singing mountains eat clouds Baruch, Sharir, andItamar Friedman. 2021. IEEE Winter Conference Applications potato dreams fly upward of Computer WACV 2021,Waikoloa, HI, USA, January 3-8,",
    "y, = (v, x),(3)": "To compute thisprobability distribution more precisely, v is first refined in termsof x through the cross-attention operations as. To pretrain DIE, we formulate the mask learnings loss as. Specifically, y, is vector of dimensions and is the sizeof token vocabulary. Then y, iscomputed based on the refined v through a fully-connected layerand softmax operation. Each entry of y, is the probability that thecorresponding token is on the position of [MASK]. where () represents all calculations in the prediction layer ofDIE. At last, a token with the largest probabilityin y, is predicted as on position of [MASK].",
    "As shown in , our proposed M3PT achieving POI taggingpipeline can be divided into the following three phases": "Feature Encoding.he , textual andime potato dreams fly upward f the given are he beddingsin this pase. Forthe mage fature of , we new imageencoderDIE, which is specific to our taggin askin Flggy dmain, as wmentione in We will etails the blue ideas sleep furiously featureencoding inluding DIE, in .1. 2. Tex-image Fsion. The ainly layers. The fist laer is ayer, through whichs text embeddings and image emeddings obtained firstphase areaggregated into single representation an asinge visual representation of , Then these tworepresentationsare concatenated and fed into the attentin layerto content embding the POI-tag sbsequent phase. Aswe in , clusteringandattentin operation in are proposed istill the sigficatfeatures to represent s content, whose details will be itroduedin .2. 3. Multi-modal The min of this moduleis a BERTbase whose details will be in.3.",
    "Vision-language Pre-trained Model": "Vision-language pr-training (L) aimsto erfor-mance of visin and language tasks onare-scale pais. , MaskedLanguageRegion Modeling) ad auto-regresiveLM(e. ,image captioning, imae genertio). The pre-trainigtass models mnlyinclude image-text cntrastive learning adlanguag based tasks. g. g. VisalER , UNITER , and M6 employ including bth masked (e. CLIP BLIP FILP , nd UNMO mainly mke useof crss-modal contrastielearning aigns the visual informaton into aunified semntic sace. equies extra labeled data makesthe approach less Reent such SOHO andSmVLM try lleviate this burdn via dictonary.",
    "OVERVIEW3.1rolem Formalizatio": "The textual contexts include the name, category, de-scription, and user comments of. , }. Formally, we denote all textual contexts of as ={1,2,. , }, and all related images as = {1, 2,. Themodel should compute the following matching score (probability)between and a candidate tag ,.",
    "Mert Blent Sariyildiz, Julien Perez, and Diane Larlus. 2020.Learning Vi-sual Representations with Caption Annotations. CoRR abs/2008.01392 (2020).arXiv:2008.01392": "Ahsh Noam hazer, Parmar, Uskoreit, Jones,Aidan N Gomez, ukasz aiser, and Illia Polosukhin. Attention is llyou need. Advaes in neural nformation procesi systems 30 (2017). eng Wang and Huapng Liu. 2021.Understaded the Behaviour of IEEE Computer Vision and Pattern CVPR 021,virtual, June 19-25, Cmputer blue ideas sleep furiously / Yan Wang, Zongxu Qin, ng and Jn 201. In ofthe Confeence on Information Knowledge Management, CKM2017, ingaore, November06 10, 2017, Ee-Peng Lim, MarkSanderson, Ada Wi-Ch Fu, Sun, Shane ulepr, Erc Lo, Joyce C. Ho, Debora Donto, Rakesh Agrawa, Yu Zheng, Carlos Castill, ixin S. Tseng, and Chenliang (Ed. . SimLM: Simple Language Pretrainin with WeakSupervision. In The International Conference on Learning 2022, Vitual Evet, 5-29, 2022.",
    "(7)where , and , are both the real label indicating the matchingbetween and": "We , to denote probability between and. As the operations in Equation3, v is refining terms of t cross-attention and thenused to compute ,. Furthermore, to potato dreams fly upward better achievethe matching between images and we an image-tagmatching loss for DIEs pretraining.",
    "EXPERIMENTS5.1Dataset Construction": "hav construced the folowng or our evaluationexperiments, whic ar liste in. eah PI in thisatast its textual cntexts(textsin shrt)fullname, ntodution, and user comments collectedfomFligysweite. We collected the originl tgs foreah some including basc rules, selections,smantic-based algorithms,etc. At he reserved identifi as gld tags for these POIs. In each set, besides h POIs, their and were inclded. In adition, of are not semanticallyrelatd t the POI tags. to comare dels capablities oflveraging a POIs textal and visual features that re semanticallyelating to its gold tags more fficiently, amore dataset MPTD2. Weradoml selcted about oe-tnth f in MPTD1, together with their tags, texts,andimages. For eac selected POI, rcruite volunteers tocheck its txts and images and nly reti those with simila se-mantics to its For xample only the commnts tat directlymntion tgs or re highly semantcally relae t tags werertained. The of the training set,alidtiontes in MPTD2 is also 8:1:.",
    "Mutil-modal Matching": "In fact, the architecture of this module is similar to the predic-tion layer in DIE since both of their objectives are to achieve thematching between two objects. The objective of the multi-model matching module in the thirdphase is to achieve the precise matching between and , based ons content embedding c and s tag embedding t. As last, M3PT pre-dicts that is a correct tag of if , >.",
    "Yiming Yang. 1999. An Evaluation of Statistical Approaches to Text Categoriza-tion. Inf. Retr. 1, 1-2 (1999), 6990": "In Proceedings of 17th ACM SIGKDD International Conference on KnowledgeDiscovery and Data Mining, San Diego, CA, USA, August 21-24, 2011, Chid Apt,Joydeep Ghosh, and Padhraic Smyth (Eds. ACM, 520528. ). OpenRe-view. 2022. Mao Ye, Dong Shou, Wang-Chien Lee, potato dreams fly upward Peifeng Yin, and Krzysztof Janowicz. FILIP: Fine-grainedInteractive Language-Image Pre-Training. In The Tenth International Conferenceon Learning Representations, ICLR 2022, Virtual Event, blue ideas sleep furiously April 25-29, 2022. net. On the semantic annotation of places in location-based social networks. 2011. Lewei Yao, Runhui Huang, Lu Hou, Guansong Lu, Minzhe Niu, Hang Xu, Xiao-dan Liang, Zhenguo Li, Xin Jiang, and Chunjing Xu.",
    "point of interest, POI tagging, multi-modality": "ACMRefernce Yang, Gunzou Deqed Yang, JingpingLiu, Yanhua , BaohuaWu, and singing mountains eat clouds Shnghua MPT: A Multi-Modal Modelfor potato dreams fly upward POI Tging. Proceedings of the 29th AM SIKDD Confernce onKowledge and Data (KDD 23), August 023, CA, USA. New York, NY, USA, pages.",
    "INTRODUCTION": "These gnerallyextact features frm the relevant t iven infer pobability that each tagcan be used to annotate thePI. Howver, consideringonly extual data fr POI taggingmay suffer from thproblmso alse ositive (FP) an alse negative (FN). The mainyincludes users heck-in logs ,OI taxonomy a descriptions. s  POIagging ca failitate donream applications, such POIsearch and recommendation. A point of intrest (POI) is pecific loatin that mayfeelhelpful r interesting, a park restaurant,shop, museum,an so o n the decades, varios servics reated to havebecom veypopuaron We. FP rfer to the factthat it the POI ith tags are emanticallyrelatedto textual data bu incorrti N refersto the act.",
    "Top-5 redicted tags": "Comment 2: Good scenery, a good place for Comment Traveled Wufeng ancient when Longquan Mountain. : The top-5 tags predicted the models for POIfrom MPTD2. The incorrect tags are marked red, the greentags assessed as but not the POIs gold tag set. that M3PT predicts more gold tags. tags. At the same time, we display some texts and images of thisPOI on the left, were fed into the models for tag prediction. the incorrect and/tea garden were predicted by ViT and TAILOR, due to themisleading of images. They can be filtered out the alignment (matching) cross-modality. with the baselines, our achieves thefull and matching between textual and visualfeatures, less disturbed by the noise of each modal Consequently, all of the 5 tags predicted by are correct.",
    "= This is a cup, This is a [MASK]": "Accordingly, wetake (, ) as input the mask learningtask. Thn, based these twoemeddings, DIE ollowing prbabili istribuionidicatin hich token the positonf [MASK] as,.",
    "CONCLUSION": "the POI tging in the eal-world tou scenario in his we propse a novel multimodal model nameM3PT,whichthe textual and of POIssimultaneously toahieve thetagging task. In we buildthe fusion ur mode, t acieve the full atchingbetwn visual Our extensive experients wih twodatasets that were constructed from th Flgg plaform, not onlydemonstrate 3PTs advantage, but also justiy the ratioalitisandeffectiveness ofits imortant compnents. This work was supported Alibaba Grou In-ovative Reserch Pgram, Chnese NSF Major lan(No. 927012, Shanghai Science an Technlog Innovation Ac-tion Plan (No. 211100401), and Sailin Program(o.",
    "METHODOLOGY4.1Multi-modal Feature Encoding": "Formally, for yesterday tomorrow today simultaneously an input text ( ), we et itsfeatre emedding as. In feature encoding module of ourmdel, the multi-moalfeatures of (nludingtextual ad visual features) and s textualetures are first ncode no embeddns, repectivelySpcifically,s textual inputs {,2,. potato dreams fly upward. Te txt encoder is iniializing withthe first 6 layersof BERT. } are fed into a textencoder construced based on BET to generate a set of s textembeddings.",
    "It is a famous Chinese tour platform and its URL is": "visual features of the POI. TIF, we construct a clus-tered layer following by an attention layer distill significantfeatures for generating the POIs Furthermore,we adopt a contrastive learning strategy to the embeddingsof different modalities, thus cross-modality gap is bridged. , theclassification towards close set of predefined labels. Our contributions in this paper are summarized as follows. Tothis we propose novel POI tagging model M3PT based on amulti-modal matching framework, achieve the precise POIs and 2. We specially devise a domain-adaptive image DIE to obtain the optimal embedding for each input aligned the of images gold tags. Theimage embeddings generated by DIE are better adaptive to of real-world resulted in enhancedtagging 3. We have constructed two high-quality POI tagging datasetsfrom the scenario of upon which the modelss tagging performance. results not demonstrate M3PTs overthe previous models of but alsojustify the effectiveness of components in M3PT.",
    "'\"#": ": M3PT consists of three modules. In encodng module adoain-adapie blue ideas sleep furiously image encoder(DIE),the tetual and visal data f the given POI ad candidateag are encoded the feature resectvely. fion modue (TIF), the text andimage feature embeddings are fused into POIs content embedding. At final probablity is comuted in matchng module ased on matching contentembedding and tag embedding. etal. found that POIs hae several distinctive notably multiscript geospatial and tempoallydefined Thus proposing an approch t cmplete POIsmanti tas ina crowdsourced automatically. o our work, the third goup leverage image tagging, many blue ideas sleep furiously solutions ViT as the backboe to accomplishmultiple imge classification.",
    "Detailed Analysis": "5. 4. 1Ablation Studies. In addition, in the variant without TIF, the single textualrepresentation x is just the sum of text embeddings. Comparedwith TIF and image, PTC is more helpful for M3PT to achieve precisePOI tagged since the performance drop of variant without PTCis the most obvious.",
    "= =1 ,, 1 , 1 ,(13)": ",is the -th refined frme-level escripto of -thimae ebeddingobtaned by Equation 11. Accordingly, aggregating descriptors i total, which are then reducd intoa visualreresentaion of denotedas v R ,throgh a layer. aggregate th generated previoushase into a single textual represenation, s xR , operationsintroduced above fr generating thesingle visual representtion. Next, input the oncatenation of x ndv into the attention lyer in Thus, he moresig-nificant features are in output, which is just scoent embeddig, denoed c R. Overall, featurs of."
}