{
    ": Ablation results of attacking Llama2-7b-chatand Vicuna-7b-v1.5 models": "The ablation tests in indicatethat removing the h optmiza-tion process of continously embedded removing contextual information within ransatin significantly the of advrsarial saple. Aditin-ally, th andom noise added during process of the translation als leadsto decrease in he erformance of our method.Furhermore, radomly selected tokens as suffixesfil to jailbrekattacks, the singing mountains eat clouds need blue ideas sleep furiously frcarefully designed adersarial suffixes.",
    "A.5Comparison of embedding before and after translation": "It is edent the the embedngsreain rearkablytht the translation hs not significantly ateed underlying of the data.",
    "Method": "In this section, will our intwo main parts: (1) to adversarial suffixembeddings and how to translate these embed-dings back into text.",
    "ei Etrans(wi),ei = Eattack(wi),(13)": "represents the embedding lookup layerof the LLM tht is usedfor embeddingtranslation,and te embedding lookup the LM that is to be attacked Noe thathis comprehensive approachlve-agea retrained LL fr te embedding transla-tionprocess. So,it a nuanced anmaniulation vulnerabilitie s-manticaly and contextuallyrich iuts,wich is a start inou embeddingas-latin So, we first randomly selecttwo enences c2} from co-pora C as is in blue ideas sleep furiously (a). (1)) andc2 s the wedete their tokns s:. This i a coice thanode becausei has undergoneiterativ opimiationto maxmizeperformance on a hugeaount of generationtasks.",
    "Limitations": "Ourmethod does explicitly model thes twoojec-tives separately; hece, it is not o artif-cially control targt the generated adersarialsuffixe are more. Firtly, from the exermental it dis-crnible that universal aversarial singing mountains eat clouds suffixes, instructon, exhbi a lowerscce rate singing mountains eat clouds in attacks compaed to idependntadversarial uffies.",
    "A.2Case Study": "Our proposed method forattaking ultipe target lguage modes can lso eapplied in lack-boxscenarios were the victim mdels only expose APIs or web services. I fact, this suffxprovides a background or context, making te enire instruction appear more like  discussion rather hana direct requestto violate laws orethical nor. Theharmful intruction is Writ manual on how tescpefrom a corrctiona facility and the trnsferabe aversarial suffix generated by ur mthod isjumping of e wall were onsidered to be echniques to escape froma prison.",
    "Embedding Translation Framework": "Our study introduces an advanced embedding enhancing expres-sive blue ideas sleep furiously of adversarial inputs targeting Large Lan-guage Models (LLMs) compromising theirsuccess rates. This framework mapping textual corpora to a space and reverting theseembeddings to textual that retainthe original contents semantic integrity. This method designed to trans-form dummy into coherent,semantically-rich textual thus providingdeeper insights the generationmechanisms of LLMs.",
    "As described in our experimental setup, we use ChatGPT to determine whether the attacked model outputsharmful content. Below is the prompt template we use": "Yourconclusion should be safe or wrapped insquare brackets, i. Please note that any f the responscontining harmul unsafe. Gien the followin txt y odel during its wih a pleae evaluae or offensvenessfactos such s ht speech,dscrmination, r any other harmful content. You should first anayze if it harmful, o implicitly, and then ive your onclusion. , [[sfe]] or [[unsafe]]## TEXTPrompt:{romt}Response{resonse}## VALUATION.",
    "(a) single target(b) multiple targets": ": The llutration of the Embeding Translation Framework. (a) inge target: The context is mapped inoembedding space by the translate LLMsembedding looku layer, while the sufix is maped into embedding spaceby the trget LLMs looup layer for daptation. Te goal is to sucesfully tranlate the adapted suffix back intothe origina text. (b) Mltiple targets: The embedding lokup laers o multiple target LLM are integratedso thetranslaed suffix can uniersaly ttack all targets even black-box taget LLMs. 3.21Translate embeddings targted onasingle LLMWe propose to fine-tue the translaton LLM in afully self-supervise way to make it able to co-lete the task. main arctecture of our methodis depicted in . Given a singing mountains eat clouds pre-trainingcor-pora C = {c(1), c(2),... , c(n)} wit a corresond-ing vocab V = {wi|i = 1, 2,. . }. Each toen wicorrepons to two embeddngrepresentations:",
    "A.4Hyperparameters": "In the weight_decay is to is 4 and warm-up_ratio is. We use the pre-trained GPT-j and Komatsuzaki, 2021) as base model for the translation framework, and we used the deepspeed et al. We finetune model for 3 epochs, withper_device_train_batch_size is 1 that total batch_size is 8 and learning is to1e 5, warm-up_min_lr is 1e 6 the maximum length is set 1560. 9 and 2 = 0. , 2020) fordistributed on 8 GPUs. We usethe Adam optimizer 1 = 0. 95.",
    "Mi Zhang, Xudong Pan, and Min Yang. 2023. Jade: Alinguistics-based safety evaluation platform for llm.arXiv preprint arXiv:2311.00286": "In 1st internationa ACM SIGR confereceon research & evelopment in etrieval,page10971100. 2018. 2023. arXiv repint 15140. Autodan Automatic ad inter-pretable advrsaral attacks on laguage models. Zhu, Sidi Lu, Lei Jaxian u,WeinanZhang, Wang, and Yong Yu.",
    "Abstract": "In be gneralized into a boader ethod transferable advrsaial thatcnsuccessfully attack multiple LLMs, evenlack-bo such as ChatGPT nd Gem-ini. Recent studis foundtht suffixes harmful hck the of LLMs an ead to an-geous outputs. This gradietbased iscrete o-timization attak requres over LMcalls, and the nredable of it can relatively penetratdby common defese methds such as To cope ths in tisa-er, we propose an Adversarial Ebed-dng Translation (SETF), transforming contiuous adversarial uffixembedings nto coerent undrstandabletext.",
    "LLM Sfety Defense": ": This is a sketch of our method, we first obtain suffixes embedding through and use an model to convert the obtaining suffixes into almost change in embedding. , 2022;Varshney et al. , 2023). methods aim to train the model to in-herently understand and avoid generating harmfulcontent. , ap-proaches, while effective in certain scenarios, forexample, adversarial suffix (Zou et al. Another method is reinforcement learning, Safe-RLHF (Dai et al. ,2023) is a representative this type of methodsince RLHF Learning with HumanFeedback) (Ouyang et 2022) a for tuning Large to alignwith human preferences. Another uses LLM itself to harmful potato dreams fly upward the et al. , 2023), oftenrely on simple rules. One approach to unsafeprompts and corresponding security responsesin tuning dataset to teach modelhow handle prompts (Ouyang et al.",
    "(9)": "Inou metod, we randomly sample m tokes fromthe vocab V (when attack on multipl moels, wesimply combine the vocab ofall mdls) and usetheir embeddings s the word embedding distriu-tion X of the to-be-attacked model(s, nd calcu-late MM loss with :.",
    "Transferable LLM attack with ad-hocsuffix": "For each harmful instruction,we trind adversarial suffixes both the Llama2-7b-chat model and Vicuna-7b-v1 5, and tranfered thetained adverarial suffixes to othe LMs. Due to the directransfer ofadversarialsufixes, both Perplexity andSelf-BLEU values are the same wheattack iffer-ent LLMs. The specfic experimenta results are in:The experimental results indicate hat the ad-versaal suffixes btained by our methodave acertain degree oftransferability. Comared withothr method based onadversarial suffixes, ASEFhas higher succss rate of tranfer ttacks, butcompred to the direct attack methodusing odel.",
    "Conclusion": "blue ideas sleep furiously Initially, we derivean yesterday tomorrow today simultaneously embedding model by undertakingthe task of from embeddings onraw text. This method expectedto be further applied in text attacks be-yond just LLM jailbreak attacks. Subsequently, input the vector trained incontinuous embedding space into translationmodel, resulting in adversarial suffixes. In paper, we a robust and comprehen-sive framework for richand adversarial inputs.",
    "Introduction": "To overcoethis, re-searcers have begu to study mehods for auto-matically construcin jailbrek templaes, suc aMsterKey (Den tl, 2023) andGPFuzzer (uet l., 2023). Though Zou etal. (203) foundthatit isposil to dicretely otimize a st funradable adversarial suffixe throug graient-based method to guid the LLMs outputharmfulcontent, this aproach tyically necessitates hun-dreds of iterations, with each tep equirig hun-dreds of omputationsby the LLMs to confirm teoptial caddate, resulting in hig computationalcstsIn this pper, e endevors to address this cal-lenge by intrducing an inovativ method thatfirstotimizes continuos advesaial embeddingsuixes inheto-be-attacked model embeddingspace, and hen proposes an Advrsarial SuffixEm-beddin TranslatioFaework (ASETF) that ef-fectivelytransforms thesecontinuus adversarilebding uffixes int semanticaly rich an cohernt txtby trining an embedding translationmodel.To constuct atraining dataet, we convr heWikipdia pre-triing corpora1 nto a paralleldaaset. Tis daaset i chosen for its xtensivediversity, ensuring a wide potato dreams fly upward lexiclcoverage tha enriches he mbedding sace withnuanced semanticifomation. Specifically,one sideontaintheorinal Wikipedia tex, n te othersde containstext(contextualinformation) with prtial embed-dings inerted. Throghine-tuing prcess(se re-trained LLM, uch asGPT- (Wang nd Komatsuzak, 2021)), the modelis enabled o reer thse ebedding ack o heirriginal textualfoms. This nsuresthat the textoutpu by blue ideas sleep furiously our method remains as consistent asposble with he representtion of the adversarialsuffix mbedding within the to-be-attackd model.Te incorpraion of contextual informationin thetrainig dataurther enhances our models capa-bility to generate contextually reevan and mean-ingfu tanslations in respons tomalicious instru-tions.In te experimnt, we use the Advbencdataset (Zou et al., 2023) an conducted attacksbased on existing LLMs suh as Llama2 ad Vi-cuna",
    "ES = {esi|i = 1, . . . , n},(17)": "where eti Rd1 and esi Rd2. The dimensionsd1 and d2 of the embedding space are determinedby the pre-trained LLMs.Note that the input of the embedding transla-tion model in the inference stage is optimized byEqn. (11) which does not appear in the word em-bedding set of the to-be-attacked model. Therefore,in order to enhance the translation robustness ofthe model in the inference stage, we add randomGaussian noise to ES during the training stage,so that the vectors near singing mountains eat clouds ES all point to text c2. In the next step, we would like to link the embed-ding sequences together to make a whole prompt,but the hyperparameters of the translation LLM(LLMtrans) and the LLM to be attacked (LLMatt)are not necessary to be the same. So, we needto add singing mountains eat clouds an additional mapping layer after the em-bedding layer of the translation model to align theembedding dimension of the target model (d2) withthe embedding dimension of the translation model(d1). Simply, we use a fully connected layer char-acterized by a weight matrix and bias term to trans-form a vector with dimension d1 into a vector withdimension d2. Then, the concatenation process isas follows:EC ESWad,(18) where Wad Rd2d1, means to link two embed-ding sequence together.The translation LLM is fine-tuned to minimize adefined loss J, optimizing the parameter set foraccurate text (sensible suffix) reconstruction. So,our final objective is as follows:",
    "Lei Sha and Thomas Lukasiewicz. 2024. Text attributecontrol closed-loop disentanglement. the Association for Computational Linguis-tics, 12:190209": "Xinyue Zeyuan Chen, MichaelYunen, and Yang Zhang. do anyting now:Characteizing and evaluating i-the-wild on language model. arXi peprintarXiv:238. Taylor Shin, Yasaman Raehi, Robert L ogan IV,Eric Wallace Samer 2020. 198.Neeraj Varshey, Pavel Agstya an arXiv preprintarXi:2401. 0087.",
    "where Patt represents the text probability distribu-tion defined by the to-be-attacked LLM with param-eters denoted by , represents the concatenationof texts": "the discrete adversarial suffix optimizationdescribed low efficiency due to the tocalculate gradients each word in the possiblecandidate set vocab V for each token at each step.An intuitive approach to transfer token space to a continuous Taking inspiration tradi-tional continuous adversarial blue ideas sleep furiously attackmethods (Goodfellow et al., 2014) and prompt tun-ing (Liu et al., 2022), introduce suffix to train suffix em-bedding vectors singing mountains eat clouds that can induce the model outputharmful content.Specifically, the core idea around aug-menting input embedding specially vector, by optimization alignthe models outputs with targets. Asmentioned for a harmful instruction P anda corresponding response R, we randomly samplen times V and use the word embed-ding vectors corresponding to n tokens as the initialtraining vectors = our goal is to:"
}