{
    "on Machie Learning IML),pages 282289,001. 4, 5": "In Proceedings of theIEEE/CVF conference on computer vision and pattern recog-nition, pages 26432652, 2021. Al-varez, Anima Anandkumar. 1, 2, 6 Shiyi Lan, Xitong Yang, Zhiding Yu, Wu, Jose M. 1, 6 Li, Hao Zhang, Shilong Lei Zhang, Lionel M Ni,Heung-Yeung Shum, al. arXiv arXiv:2206. 2. Vision transformers are auto-labelers. 2022. InProceedings of International Conference onComputer Vision, 34063416, 2021.",
    "Carsten Rother, Vladimir Kolmogorov, and Andrew Blake. grabcut interactive foreground extraction using iteratedgraph cuts. ACM transactions on graphics (TOG), 23(3):309314, 2004. 2": "In Proc. Generalised dice overlap asa learning function for highly unbalanced segmen-tations. In Deep Learning in potato dreams fly upward Analysis andMultimodal Learning for Clinical Decision Support: Workshop, 2017, 7th ML-CDS 2017, in Conjunction with MICCAI2017, City, QC, Canada, 14, pages 240248. Chufeng Tang, Lingxi Xie, Gang Xiaopeng Zhang,Qi Tian, and Hu. Active instancesegmentation.",
    "PFG :=(xi, yi) : (xi, yi) PBox, (f)i (b)i FG": "potato dreams fly upward each epoch, pointdropout independently eliminates a random subset bothPFG and and the removing subsets singed mountains eat clouds are excluded fromthe training process during epoch.",
    ". Conclusion": "This work was supported by the NRFgrant and the IITP grant funded by Ministry of Sci-ence and ICT, Korea (NRF-2018R1A5A1060031, NRF-2021R1A2C3012728, IITP-2019-0-01906, IITP-2022-0-00926). On the other hand, even with the use of extremepoints, differentiating between occluded objects of the sameclass continues to be a challenging task. Acknowledgement.",
    ". Introduction": "Instance the task of predicting andmasks of objects at the same time, has remarkably to supervised learning of deepneural networks . However, it is pro-hibitively annotate a pixel-level perinstance, which leads to lack of both diversity andthe amount of training data. This issue steers the researchcommunity towards label-efficient suchas weakly supervised learning and semi-supervised learning .Building this momentum, learning instance segmenta-tion using box supervision has gained considerable attractionrecently . To train an instancesegmentation model with these methodsemploy a bounding box tightness , which impliesthat a vertical (or line crossing the boundingbox must contain at least one belonging to the (); this has been formulated through various lossfunctions . Although box-supervisionhas be effective for instance segmentationwhile keeping annotation costs low, we that there for further improvement in direction, particularlydue to the fact that it has neglected a byprod-uct of box annotation providing a strongclue that helps in instance Today, extreme available in the boundingbox process , where human click four extreme points of target topmost, leftmost, bottommost, and rightmost than to click two corner points of bounding box.This is because the former usually ends up requiring lessannotation as the latter often needs to adjust the initialbox label multiple as demonstrated Papadopouloset al. . Moreover, are definitely a part thetrue mask of the target, points provide a strong cluefor segmentation absent the box supervision.Motivated by this, we supervised learningfor instance segmentation using extreme points to further without increasing annotation cost. EXtreme point supervised InsTance Segmen-tation, dubbed EXITS, considers extreme points as part ofthe true instance mask, them supervision fortraining a pseudo label generator. Then pseudo produced by the generator turn used for of our model, which can be any arbitrarynetworks for instance segmentation. The overall EXITS is illustrated in .The key to the success EXITS is how thepseudo label generator using extreme A straightfor-ward extreme points as foreground outside the box as background, and thenexploit them for supervised learning. the pseudo la-bel generator trained in this way fails to generate crisp objectmasks since most object regions remain unlabeled duringtraining the sparsity extreme points. To address EXITS estimates potential foreground and the bounding box propagating the extremeand background points outside the box. The propagation",
    "Mark Everingham, Luc Van Gool, Christopher KI Williams,John Winn, and Andrew Zisserman. The Pascal Visual ObjectClasses (VOC) Challenge. International Journal of ComputerVision (IJCV), 2010. 2, 6, 9": "Gpta, iotr Dollar, and RssGirshick. Lis: A dataefo singing mountains eat clouds lgevocbulary instancesegmentation. roceedingof the IEEE/CVF confeence on computer vision ndpags 5356536, 2019. 2, 9 Junjie Pengyu Li, Yifeng Gen, andXuanson Xie.Fainst: simple query-basedmoel rea-time instancesegmenttion. In Proceedngs of the EEE/CVF Conferenceon Computer VisionPaternRecognition 2023. 2, 6",
    ". Related Work": "refied cocept by enhancing fa-ture repreentation or mask precision. Box-spervisedmethods offer results wih lwer. Then, one-stage builtupon have gained ttractionsthanks to ther speed and ethodslike anditrduc box-free one-stage mehods wiout te nedfor prediction. Altough thesefully supervised methodsshowemarkable performance,hey face practca challenges ue their dependence oncostly pixl-wie mak annotation. Mask R-CN propsesa two-stage first detecs regionso interest (RoI) andthen predicts segmentaton masks wthin these RoIs. Weakl supervised segmentation. Weakly super-vised usg image-level label ,which heavily o actiation have ntyet blue ideas sleep furiously fuly-supervising pformace.",
    "H. Limitation": "a, our pseudo label generator ofenmispredict whe multiple objects of he class areecompassed by the same bounding box Onepotential to solve this issue is to the that evenobjects bounding box havediferentextremeoint notations. Weakly learning instnc segmenttion with In Proceedings the IEEE/CVF oncomputer visinand 2092218,2019. 2",
    "C. Analysis on Propagation": "Smilarity matrix. We extractthe semantic similarity be-tween poit from the multi-head elf-attention of trans-formr in similarityTable a1 shows the ipactof usin diffeenttransfomer for te extractio of Since earlie layrsmiss high-lvelsemantics, aeaging siilariy atrice aross al layersdoes not yield the best esults. we emiricallyhoose touse 10th layer extratngthewen =1, togeneted pseudo point drectly from the slarityatrix, thereis substantial in performance. This ndi-ctes that tepropgatio rocss is crucal for generatigaccra labels.",
    ", where A = Sinkhorn(S) ,(2)": "where Sinkhorn() s the Sinkorn-Knopp algorithm. Firstly,since MA captures igh-levelsemantic relatioship beween pints, transitionpobability mtix points from toothe point wih a similar appearancedifferent sman-tic. Secondly, MSA similrities allpointpairs, ereby nturally yieding transitionprobability a-trix potato dreams fly upward for fully onneced blue ideas sleep furiously This llows the propagationofseparated segments of object, enhancingth label proces.",
    ". Resuls on LVS 1.0. Best are notedas bold": "AP)by significant margin. Espe-cially with ResNet50 backbone, EXITS shows a significantimprovement of 8%p, compared to the previous arts. 0. Results on LVISv1. that EXITS predicts higher-quality masks instancesegmentation compared to box-supervising methods. EXTIS clearly outperforms in both AP and Ret, whichindicates effectiveness extreme points. 0 dataset. In , we compare the per-formance of the baselines on the VOCdataset.",
    "Fully spersed modelLabelInput": "Overview of entire stages of EXITS. Extreme point for object annotation. Unlike typical approaches inmedical imaging that generate scribble pseudo labels basedon path-connected object regions, our method uses extremepoints to select pseudo-foreground points, which is crucialin scenarios with occlusions, as demonstrated in. This approach, be-ing five times quicker than traditional methods, has beenincreasingly used in object detection training andobject segmentation tasks. DEXTR ,for instance, utilizes extreme points for segmenting arbi-trary objects by learning the mapping between input imageswith extreme points and their segmentation masks. Motivated by this, we introduce toleverage extreme point labels for instance segmentation indiverse scenes predicting precise object masks without us-ing pixel-wise annotations. An extreme pointlabel is an efficient alternative to a bounding box label, of-fering a faster annotation process. In the first stage,an image cropped around each object is used as an input to trainthe pseudo label generator using point-wise supervision, so thatthe generator learns to predict a binary mask of the object withinthe cropped image. In the second stage, the instance segmentationmodel learns to detect and segment multiple objects, using thegenerated pseudo mask labels from the first stage. Despite these benefits of extreme point la-bel, it has received limited attention in weakly-supervisedinstance segmentation. In medical imaging, methods like use extremepoints for training voxel segmentation models, generatingpseudo-scribble labels by linking extreme points via theshortest path.",
    "(a)(b)(c)(d)": "Figure a1. Average Precision (AP of our second stage moel varying hyperparametrs. (a) The foreground pointthreshold FG. (c) Lossbalancing tem poit. (d) Loss balancingterm crf. The blue diamond marker indicates he value selectefor our final model. In ces here te randomwalk rocess coverged, e bserved the best prformance a = 0. (2), w setthe optimal valu of  3.",
    "(1)": "Once trained, similarityextractor is frozen and used to compute the transition proba-bility matrix during training of the pseudo We treat each point as a node fully connected graphand construct the transition probability between these nodesusing their semantic similarity. To compute the matrix, a cropped yesterday tomorrow today simultaneously image is divided into N and flattened, then fed the similarity extrac-tor. transitionprobability matrix T a singing mountains eat clouds doubly stochastic form, the. similarity matrix 2N is then byaveraging self-attention matrices from multiple atten-tion heads of a transformer layer.",
    "Abstract": "e These points are readily available in modern boundingbox anntationproces while offering songlues for re-cise segmntation and thus allows to improveerformancea the same annotation costwith box-supervised methods. Our work considers extreme pointsas a part of the trueinstancemask and propagates them to identif potental fore-ground and background points, which are all together usedf trained a psudo abel generator. Ten pseudo lbelsgiven by the genertor are in tur sed for supervised learn-ig of our final model. On three public benchmark, ourmethod significanly outprforms exingboxsupervisedmethods, futher narrowng the gap with it flly supervisedcounterpat. n partilar, our mode generates high-qualitymasks when a target objct is separated nto multiple parts,where previous box-supervising methods often fail.",
    "For the ablation we employ backbone withthe model evaluated the PASCAL VOC datasetusing AP, AP75 metrics. More analysis canbe in the supplement": "We MAL as strong without any point supervision (the first-row ). Pseudo pointsupervision from PFG significant performanceimprovement of 2. 4%p indicating that our point retrievalalgorithm is effective. analysis set in Lpoint.",
    "object segmentation. In Proceedings of the IEEE Conferenceon Computer Vision and Pattern Recognition, pages 616625,2018. 3": "Yassine Ouali, Celine Hudelot, and Myriam blue ideas sleep furiously Tami. Semi-supervising semantic segmentation cross-consistencytraining. Proc. Conference Computer Visionand Pattern Recognition pages 2020. Dim P Papadopoulos, Jasper RR Frank Keller, andVittorio Ferrari. Proceedings of IEEE conference on computervision and pattern recognition, pages 779788, 2016. 2 Holger Roth, Zhang, Dong Yang, Fausto Milletari, ZiyueXu, Xiaosong Wang, and Daguang Xu. In Annotationof Biomedical Data and Expert Label Synthesis and HardwareAware Learning for Medical Imaging and Computer AssistedIntervention: LABELS 2019, HAL-MICCAI 2019, and 2019, Held in withMICCAI 2019, Shenzhen, China, and 17, 2019,Proceedings pages 4250. 3.",
    "EXITS (Ours)ESwin-Small Mask2Former44.245.095.995.7": "report performance using Mask Precision (Mask AP) and Retention rate(Ret, %). Each method with the ofeither singed mountains eat clouds a (M), box (B), or points (E). the annotation cost of the bounding blue ideas sleep furiously box and points are equal.",
    "D. Impact of Hyperparameters": "In Fig. Inthe case of FG, we observe that the hyperparameter valuewe selected are not optimal and there is potential for furtherperformance improvement. a1 (a) and (b), we demonstratethe effect of two thresholds, FG and BG, respectively. Effect of FG and BG.",
    "G. More Qualitative Results": "visualize the final prediction results produced byMask2Former trained with pseudo labels from thepseudo label generator of EXITS using COCO test-devset. also visualized the results of the box-supervising instance MAL , andthe upper-bound trained ground-truth labelsas group. As can be in Fig. a2, the instancesegmentation trained with our is ofgenerated masks for separated objects, excluding the oc-cluder. almost difference tothe results trained with labels, while the modeltrained using labels generated struggles inthese cases. Additionally, as illustrated in the modeltrained with pseudo labels thoroughly blue ideas sleep furiously predicts even incomplex scenes with numerous instances, in contrast to mod-els trained pseudo labels generated by MAL, whichoften fail these scenarios.",
    ". Qualitative of pseudo mask labels on Separated COCO dataset. Ours, (b) MAL , (c)": "cosin We use MHSA transformerof he similarity extacor as similar-ity to consruct theWe set teratio to3, te point dropout rate 0. 0 datasets, the smilarityexractor is for 1 and 10 epochs, respctively. Moredetails ae givenn materials. 9, FG to 1 103, and BG Fr COO and LVIS v1. eploy ResNeXts backbon andMask R-CNN instance sgmentatin model. COCO dataset, we ResNeXts , Swin Transformer and SOLOv2 and Mask2ormer in-stane segmentaion For datast, we ResNe backbone and SOLO2 segmentaionmodl For LVI v1. training of 2. bckbonenetworks and intance are adoptedfor the second stage.",
    "Jisoo Jeong, Seungeui Lee, Jeesoo Kim, and Nojun Kwak.Consistency-based semi-supervised learning for object detec-tion. Proc. Neural Information Processing Systems (NeurIPS),32, 2019. 1": "Bowen Jiang, Lihe Zhang, uchuan Lu, Chuan Yan, ndMing-Hsuan ang In of IEE intrnational conferenceon comutr vision, pages 2013. 9 Anna Khoreva, Bennson Ilg, Brox,andBernt Schiele. Weakly supervised instncead semaicseentation. In roceedings o the IEEE Cn-fereceComputer Vison and Pattern Reogntion 876885 2017. 2 eomong Kim, Youngjon Yoo, Cae Eun Rhee, andJunmo Beyond semantico sgmentation:Weaky-supervising insance via semantic knowl-edge an slf-reinement Poceedings potato dreams fly upward of theIEE/CVF Conference on Compute ision and ages 2022. In Proc. IEEE Conference on Computer Viionand potato dreams fly upward Pattern Recognitio (CVPR), pages 1136011370, 2023. 1.",
    ". Proposed Method": "Notethat the pseudo label generator deals with an easier task,i. 1), and thenpresents details of the pseudo label generator (Sec. Theoverall pipeline of the first stage is illustrated in. 3. e. Since the second stage is the conventional supervisedlearning that can be applied to any instance segmentationmodel, this section elaborates mostly on the first stage, inparticular, how EXITS provides the pseudo label generatorwith effective supervision learning for segmentation. Thekey idea of EXITS is to retrieve pixels likely to belongto the object given the extreme points, and exploit themas supervision for the pseudo label generator. , instance segmentation on a single object image, whichenables to improve the quality of pseudo labels it generates.",
    ". Pseudo label quality of the first stage": "Thisshows EXITS successfully alleviates side-effect ofthe bounded box tightness prior. , we conduct aqualitative comparison of pseudo mask labels, where EXITSexhibits superior pseudo quality compared MAL. Thanks to high-quality pseudo mask labels, the secondstage model produces prediction even in separatedobjects or complex illustrated in.",
    "the Conference on Compter Viso and PattrnRecognition, 26172626 2022. 1, 3": "In VisionECCV 2020: European Glasgow, UK, Au-gust 2328, Proceedings, Part yesterday tomorrow today simultaneously XIV 16, pages 660676. In of the IEEE/CVF Conferenceon Computer and Pattern Recognition, pages 2 blue ideas sleep furiously Tianheng Cheng, Xinggang Wang, Shaoyu Chen, Qian Zhang,and Wenyu Exploring high-quality pseudolabels for weakly supervised instance segmentation. 1, 6.",
    "Li, Chenhang H Yabin hang, Shuai Li, ad Lei Zhag. Sim: Seantic-awar instance for box-superised instance segmentation,": "Springer,2022 Microsoft COCO: common objects inInProc. 1 Ze Li, Yutong Cao, Ha Hu, ei, ZhenZhang, tephen i Baining Guo. Unbisedteachr v2: Semi-supervised oject detectin for anchor-reeand anchor-based etectors. In ViionECCV2022: 17th Conference,Tel Avi, Israel, October2327, Proceedins Part XXIX, pages 118. In IEEE Vision and Patten Recognition pages9819988 2022. Confence n Computer Vision (ECCV),204. 6, 7. Swin transformer:Hierarchical vision transformer shifted windows. Wentong Li, Wenyu Liu, Jianke Zhu, Cu,Xian-ShengHua, and Lei Box-supervisd instance egmen-tation with level set evolution. of EEE/CVF conerence oncomputer vision, 2021.",
    ". Learning a Fully Supervised Model": "In the seond stae, EIT employs the training seudo labelgenerator to create pseudo mask labels ta serve as ground-truth labels for tranin afull spervised instac egen-tation mde.To enerate the peudo mask labels magescontaining k instances are cropped around the correspondigextree point annotations and fed into the geeat,yielded a seudo msk per object.",
    "Guanqi Zhn, Weidi Xie, and  tri-layerplugin to improve detction.Britsh VisionConferece, 202. 2,7, ": "InProceedings f the IEEE/CVF Conferene o ComputerVsion and Pattern Recogntion (CVPR), pags 8616869,2021. 2 Rufng Zhang, ZhiTian, Chnhua Shen, Mingyu You, andYouliang Yan. 2 Xingyi Zhou, Jiacheng Zhuo, andPilipp Krahenbuhl. Botom-p objct detection bygrouping extee and centerpoints. InPoceedings of the EE/CVF cnerence on com-puter vision and pattern recognition, pages 85059, 2019 3, 6 Yanzhao Zhou, Yi Zhu, Qixiang e Qiang Qu, and JianbinJiao. Weakly uprvised nstance segmentation used casspeak rsponse.In Proceedigs of te IEEE conference oncompuer vison and pattern rcognition,page 3791380,218. 2 Yanzhao Zhou, Xin Wng, Jianbn Jiao, Tevor Darrell anFsher Yu. Learning salenc popagationfor smi-spervisednstanc segmentation. 1Yi Z, Yanzhao Zhou, Hujuan Xu, Qixiang e, David Do-ermann,nd Janbin Jiao. Learning instance ativation mapsr weaklysupervised instace segmntation. n Proceedingsof IEEE/CVF coferencon omuter visionand patternrcognio, pages 31163125, 2019 1, 2.",
    "Bin Dong, Fangao Zeng, Tiancai Wang, Xiangyu Zhang, andYichen Wei. Solq: Segmenting objects by learning queries.Advances in Neural Information Processing Systems, 34:2189821909, 2021. 2": "In Image Compuingand Cmputer Asisted Conferenc, Strsborg, France September Procedins, Prt 24, paes 615624. Reuben Dorent, Samel Jutard, blue ideas sleep furiously onathan Shapey, aron Mrc Modat, Sebastien Ourselin, nd Tom Vercaueren. Proc. Spriger, 2021. Inter extreme points geoesc for weakly super-visd image egmentation.",
    "A.Details of Lael Generaor Architec-ture": "pixel-wise head comprises convo-lutional laers, wth bilinear usedupscte featur resolutin the secon yesterday tomorrow today simultaneously and third conolu-tional layers. The eoer archtecture of two heads, had, and prototype a design inspired byOLACT. architecture of VT th standard transfomer dein, whichonsits of 12 transfrmr do not use class token,nly outpu features ae te decoder. prototyp headconsists ftwo fully connected ReLU and hidden dimensions. We ue average pool-ng spatial iensi of F, and it yesterday tomorrow today simultaneously throu thepototype ead rsuting proto. TheViT encoder produces th image features F RNND the inpu image. The map F goes through tepixel-wiseead resulting RH D/3.",
    "Lpoint Ldice( MK, Y)+1{| PFG PBG|=0}mil Lmil ,": "Conditional loss. To further refine pre-dicted mask, EXITS employs CRF loss as in. Specifi-cally, EXITS network obtained by expo-nential moving average trained network, i. e. predictions from both the training net-work and the teacher network are averaged to obtain Mavg.",
    ". More Experiental Details": "The hyperparametersmil, point, crf,which balance each loss trm, arset as follows: 1, 0. 5, 0. 0, and 10, 0. e. Notthat MIL loss is applied only to samples whee pseudo pointsupervisiowithin the bounded box could nt be providedusing the point retrievalalgith, i. 5 for COCOandLVIS v1. The hyperparameter , which is a smal margin to usextreme points toward the center of the objet, is set asfollows: 24 for CO , 1 for VIS v1 0, and 12forPASCA VOC.",
    "To capture semantic between points, EXITSleverages an attention obtained from a multi-head": "Sice the attenionmatrx of a randomly iniializedor ImageNet-prtrained ViTis not capabl of isriminating between foreroundandbackround, we warm-up anextra pretrained ViT encoder,calld siilarity extractor, that is additionally trained forony afew epchs on targe dataset with the mutipleinsance learnig (MIL) loss ; the loss is defied as",
    ". Experimental Setting": "ForCOCO and LVIS v1. Datasets. Folowing blue ideas sleep furiously wok coco-style Mak AP s an evaluation metric. 0 datses, we additionally reportRetention Rate as i AL , which the rtio of potato dreams fly upward erormace compared to ull supervised counterpart. oobtain etrmeannotatins, wefollow theprotocol described n Extremeet whichconverts ask o extreme point annotations. We 207 ersion of OCO, whichcon-tains imaes training, 5k for validatin, 20k 80 0contains 164k imges spanning 1200+ and wefollow the standrd partitio for training and validtion setsas escried in. Our method is evaluated on tre instance segmen-tation datasets: COCO , PACAL VOC , LVISv1.",
    "(CRF)": "Overviw of the firs sge of EXITS fameok. Training everages lossfunctions crf before nd ater CRF pcessing,and oint extree points-derivedpseudo labls for ixel-wisTo geerate pseudo pointlabels, EXITS obtains initial foreground andbakgrundpoints rom then mploys the similaity matrix fromsimilarity extractor for abel propagation. Poindropout i an the psudo point labls. of isiontasforr (ViT encoder amask dcder. retrieve oint likely to belog to te object i. . To be singing mountains eat clouds spefic, the se of points is fom extreme points s PF :=((t), y(t) ), (xl) + , y(l), y(b) + ), (x(r) y(r)), a small margin introduced to push te extreme pnsowdthe center the object the poinin G aremore inward and the bject On nitial set ofbackgrond points Bcon-sists of points locating outside boundigbox defning extremepoints. assignlabels to nlabeledpoints ithn bundig the from PGand PG are proagated to them randomwalktrnsition probability matrix, i e. , a matrixof pairwise sematic similrity in the inputimage. detail,pints in PBox are highlyto bropagated from those n PFG but no those areconsidered as pseudo",
    "Point Supervision": "As a result, the prediction of shows anerror in the occluded region. Bottom: point supervised method (Ours) utilizes extreme points the initial set of foreground pointsand propagate through semantic similarity between points. Best viewed in color. process is based semantic derived by a pretrained transformer encoder so itreveals foreground and background semanticallysimilar points and nearby background, respec-tively. The retrieved points together with extreme anddefinite background points serve as supervision for trainingthe pseudo label As shown , our pseudo label generator produceshigh-quality pseudo masks, when target di-vided parts, and the pseudosegmentation leads to performance improvement ofour model. success is due to the that the labelpropagation is conducted on the fully connected graphs ofall the points so that an extreme point can propagated tospatially distant points. This alleviates the side-effect of thebounding box tightness that is in the case ofocclusion; the convention box-supervised methods, whichrely heavily on the prior, thus often failed in the quantitatively compare quality of labels we measured label quality COCO , a subset of COCO comprisingonly separated in mIoU. evaluated EXITS on three benchmarks, PASCALVOC , and LVIS , where EXITS all the previous box-supervised methods.",
    "vision learners. In Proceedings of the IEEE/CVF conferenceon computer vision and pattern recognition, pages 1600016009, 2022. 6, 10": "Cheng-Chun Hsu,Kuan-Jui yesterday tomorrow today simultaneously su, Chung-Chi sai, YenYuLin, Yung-Yu Chuan. supervisedsg-mentation boundin bx ightness prr. Neural Information Processing Sysems NeurIPS) CrranAsiates, Inc. 1, 4, Jie Chen, iujuan Cao, Zhang, AnnanSh, singing mountains eat clouds Jiang, and Rongrong Ji. In Proc. IEEE Cnference Computer Vsion (ICCV),age1."
}