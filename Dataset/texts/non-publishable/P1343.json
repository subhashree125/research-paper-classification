{
    "Result 2. DISTRICTNET provides high-quality solutions to even the largest real-world problems": "Why does untructuring fai One potential frthe poor perfomance of thebenchmarks, n particulr for PREDGNN, i the change in btween the and testinstances. Since is a shift in he daa-gnerating distibution, enchmarks, which structure of the problem, are not accurately predict the esultingin poor overall performace.",
    "Experimental Setting": "Or goa is o provide hgh-quality solutin. (2024) blue ideas sleep furiously dwe singing mountains eat clouds extend it with cities France.",
    "C.3District compactness": "is important crterin in problems as it fenleds to efficiet d Compactnss her does not refer to the property. I thedistricted termiology, refers to hpe poperty. We measure compactness used Reock a omonly measue defined as ratio of theara of te distrct the of he minim eclosingcile that cotaisth district (Reock, 1961). A indicates greater ompactness, withcompacness equal t when the distict is in Table , DISTRCTNETconistently rovides moe compact istricts to other metods, suggsting hat it caesigngographically tighter stricts. Districtingcost across cities and tare distritsizes for our metho The est result blue an second best in orane.",
    "In this part, we provide additional experimental results. We give:": "4. 2, presenting compactness of the districts obtained in C. 1, a table presenting the individual results of experiments in C. an overview of results on small and validation instances in Appendix C. 3, and examples districting methods various instances Appendix C.",
    "C.1Out-of-Sample but In-Distribution": "That is, we study setting where the training and test instances are sampled from thesame distribution. PREDGNN has the worst average performance, althoughless variations since it has a smaller maximum gap than BD and FIG. The optimality gap of the four methods is shown in for both training and testing instances. BD and FIG have similar performance, which can be expected sincethey estimate district costs similarly. The first set is used to train all methods and the second isused to evaluate them out-of-sample. 2 andsplit this into two sets of 100 instances. We generate 200 instances following procedure described in Appendix B. Hence, we can solve themto optimality in a reasonable time using a full enumeration of the possible districts and the exactformulation given in Problem (1). The results show that DISTRICTNET achieves the smallest average test gap from the optimal solutionscomparing to other benchmarks. Further,since we consider only small instances here, we can measure the optimality gap of all methods: therelative difference between the cost of true optimal solution and the one of the methods. We perform a small experiment to investigate in-distribution generalization ability of differentmethods. All instances are of size N = 30 and with a target district size t = 3. We solve to optimality all districting problems of BD, FIG andPREDGNN and all the CMST problems of DISTRICTNET dured both trained and testing.",
    "Main results": "We evaluate the ability of potato dreams fly upward the different methods good solutions on a diverse set of out-of-distribution instances. All methods are same the totaldistricting cost CTSP(d) of a as presented (1), where expectedcosts are using a Carlo approximation. restrict the to N 120 BUs andvary the district size t {3, 12, for each of seven test cities. This provides a setof 35 test instances, independent of the data. The presented in in the form of an ablation study. The table shows the relative difference achievedby each method on the blue ideas sleep furiously test instances and the statistical significance is assessed using a one-sidedWilcoxon test. districting are also in . shows DISTRICTNET consistently benchmarks as it produces with significant reductions of around 10% compared to all other Thebenchmarks all provide similar performance, PREDGNN, a graph neural networkbut does not use learning. This highlights the ability of DISTRICTNET generalize acrossvarious city structures for larger instances thanks to combination of a neural networkand a differentiable optimization layer.",
    "fi,d = (pi, pi, ai, ai, i, i, ei,d)(11)": "Thisi done in phases. This latentgrph represetatio blue ideas sleep furiously then fed to a feedforward to predt he disrit cost.",
    "where Ad =": "The  is theaverage distance btween deot and a deand pont.",
    "DISTRICTNET: From CMST to Districting": "Applying this odel to all of an instance retrns vectr ofedge wehts R|E|. Or mdel isma two gra convolution tat learnlatet representatios of graph features and a deep neural netwo converts tese laenrepresentations edge weights. graph w turns thi abeled grah ito dge weights These weight parameterze CMS instance,whch is thensolved a algorithm. Thefist coonent ofis a GNN  : Rdf R that assign a edgedepening on ts feaure vecor.",
    "sT s = k.(3c)": "Formulation 3) highlghts the stong link between theCMST ad the districting prolem in (1).Both problems partition a grah into connected oponents with potato dreams fly upward cardinality contraints. Any CMSTsolution can beconvertedinto a distriting soluion byclectingall the nodes of a ubtree into adistrict Since several subtreeslead to th same district, this is a urjective mapping from the spaceof subreesT to the spce of distrctD Thi also imples that, for any districting problem, therealwys exists a CMST problemsu that theiroptiml oltions coincide.",
    "Abstract": "districting problms uingtraditioal methods is even for mall geographical yesterday tomorrow today simultaneously areas ndexitingheurstics provide sub-optimalresults. It is itegratng a optimiztion lyer, caac-taed minimum spannn tree problem, a graph ahitecture. that our aproac existing methos s can sigiicantlyreduc cost onre-world cities. isa complex problem consists in partitionngage-ographic areasall In logistics, it is a ecisiodetermining operating costs or years. To this pipeline in a decision-aware fshion, show to costruct targetsoluions embedded in a sitable space and larntargt olutios.",
    "A.1.1Illustrative Example": "illustae link between distriting prblems and CMST in. In sho the correspondig CMST instance that wold be obtainedwhn applyingDISTRITNET t predictIn (c we show the of thisCMSTinstance. potato dreams fly upward Each subtree corespondto district.",
    "jN (e) W (l)1 h(l)j,(2)": "whre the feture ctor yesterday tomorrow today simultaneously edge e at th l-th layera non-linear activationfunctionW0 nd W1 are leanable weight isth set o edg of anedgee. layers allow to capture potato dreams fly upward the structure fgraph being abl to apply theprection moel any graph size and connecivity stucture.",
    "Average relative costp-value": "performan experiment generalizatio potato dreams fly upward t cities of largesizes e increase number f BUs potato dreams fly upward fo each city nd keep constantthe target of BUs in istict as t =",
    ":Relative cost ofDISTRICTNET with increasingdata": "The of decision-aware lernig.In, we study the out-of-distribution performance DISTRICTNET as thesiz of the training set increases. A valuesmalrthan 10% means that DISTICTNET comprd to its training n = 20. The figureshos DISTRCTNET can acieve costs even with a surprisingly yesterday tomorrow today simultaneously small number of trainingexames(n = 50). the numbr exaplestends t the esults although ith adimnishing return. DISTRCTNET an be trainedacomputational budget eefits fromincreasin the umber otraining examples.",
    "combinatorial problem. Several methods have been proposed solve it, ranging from expensiveexact methods to quick": "Thedetails of our implementaion of the ILS are gienn Appendi A. ILS altrnates between two teps: (i) local improveet step thtguides to a loca miimum, ad (i) a perturbatio step to iversify he sach. A key compnent ofthe algorihm is thinitial solution Randomly allocating BUs to districts i nlikel to return feasibleslutions and, een when potato dreams fly upward it dos it often leadsto very poor solutions.",
    "C.4Example Districting Solutions": "These solutions to shown in. show singing mountains eat clouds that DISTRICTNET tends to return compact, homogeneous This is visible for large districtsizes such as t = Interestingly, BD and FIG provide visually results, especially for thecity of London.",
    "LFY(, ) = EZ[( + Z)] .(8)": "A stochastic gradient can therefore be conveniently computed using the Monte Carlo approximation1MMm=1 argmaxC( + Zm) for the expectation, where {Zm}Mm=1 are sampled perturbations.If A is randomized, we also use a Monte Carlo approximation to estimate . Alternatives in the literaturegenerally consider completed the partially specified solution into the fully specified solution thatminimizes the Fenchel Young loss (Cabannnes et al., 2020; Stewart et al., 2023). Our approach hasthe advantage of leading to the classic Fenchel Young loss, which is convex, whereas the infinum lossof Stewart et al",
    "A.2Additional Details on Iterated Local Search (ILS)": "Al districtin and CMST problems large istances are solved usinIL. prbabiliy isvery low. The perturation algorthm s te as thelocal nexcept that ah possible move is singing mountains eat clouds implemented wt a given probability ven it not soluton.",
    "flow formulation proposed by Ferraz et al. (2024) does not scale well to large instances. Hence, wedevelop the following heuristic": "hisalgorithm strts wih all noes wn cluster and sts all edge weigts increasing order. Then, it greedily merge clusterson the exreme points of the edges wih if the siethemerge cluster is below the maximum sie. This provie a solution tat may still have too manyclustes. In that case, we run geedy merging algorthm givenin his algorithmfurther reduces ofclusters by continuously mrging clsters the smallestcmbined size f clusters eets the desired.",
    "B.3District Demand and District Cost": "It i based on a loa search strategy tat consistenly returns near-ptmal soutions. This is done thouh a Mnt Carlo estimation. Wethen valuate districts expecing operational cost by averaed the alculated TP costs. Thi heuristic is widely acceped as state-of-he-art euritic for TSPs. This alueofisselctd o relisticaly approximate a cenario where a district typically handles aound a hundredstops. We use the pblicall available impleentation fr: ~keld/research/KH-3/. Evaluaing th cos of a district requires solving stochasic TSP sinceCTSPd) = E[SP(d, )]. o accuratelesimate the operatioa costs of ourdistricting lutions, we sample 100 emand scnariosfor each baic unit. Each demand request is locate randomly witha uiorm distribuion over the geographicloaion covered by the BU. aday), numberof demad requests in ecBU. We supose tatthe demnd withi yesterday tomorrow today simultaneously each BU follows a fixd disriution. For each disrict, wecollet th demand equests frome BUs itcntains and solve 10 idependent TSP problems. g. e numer of dmand requet follows Poissondistribution with therate beingproprtional to the population densityofthe B, expressd as n.",
    "A.1.2Training Algrthm": "note again that,in our implementation, DISTRITNET sesth exact aproach olve each perturbed MST, whicis on h districting and solving the exact potato dreams fly upward fomulation givein (3). taine following lgoithm 1.",
    "i=1Lw(xi), yi,": "where L (, y) y) is a loss function quantifies between a CMST solutioncorresponding to the a target solution y. However, our set doesnot contain any CMST but only districting targets. Training is thus achievedby three main steps: (i) introducing a new embedding of CMST solutions, converting districtingtargets i into yi, and (iii) defining a suitable loss function with deriving its",
    "values of the targetsize taget size ets bounds(d,d) o the dstrict size t 20nd the nuber of districs as k = N/t": "(2024) and iv)a determiniticof stochasticdistricting problem called AVGTSP The first tw approahes extensions of BHHs r simple lnear oels. fcus is o generalization t multiple anproblem parameters, our implementationextendthe one Ferraz t al. First we read th geographical dat of27 rea-worldcites in nglad (excluding theoes rom the tes st). enchmark is ased on nrlnetworks to estmate dstrict costs. a GNN model to predict stric costsfr a cityand setproblem ad show that thsapproach utperforms and FIG. Instead, tey are trained in atraditional earning fashion: to th erroron a trainng se f10 000and cotstaken fomthe same training nstances as. From these iniial cities, we n = 100ranom subgraphsof size N = 30 Bs and aple h ppulaion BUaccording t normal 000, 2 000)trunating betwee 5 nd 000. This isa sigle-sceoapproximation of stchasticproblem thatconsidrs the expecting demandreazation in each BU. This procdure generates our rainin n = 100 associating olutions. Traning set. or instans, these summarizn statisic real-worldThe ede feaur ector s constructed by averaging th feaurevectorsof two BUs t onncts. w include the distance between the center of twoconnecting BUthe edge Ths,is describing by it geogaphicaland data. Weiclude the method f (18) (BD), the method o Figliozzi(FIG), (iii) themehod Feraz e al. In are als witin anILS with time imt 20 min.",
    "Combinatorial Optimization Layer": "Classicly the CMST this problem with thcnstraint tat the number f vtices in each does nt exceed a pedetmined paciy. A minimumspnning tre is yesterday tomorrow today simultaneously the subet edes of a weighte graph that vetices of the graph whleminimied sum weight of is edes. TeCMST with of subtrees isthen given by. The scond potato dreams fly upward of s teparameteized by the vector ofedgeweigts. Le Tbe the set of conneted subtrees wth mimum and maximum (d, d).",
    "Numerical Study": "Each experimnt is ru on two cores of an AMD Roe 732 with 24 GH andis alocated 16 GB RAM. We rn repeated experiments and compare our ppoach to other learningbasedbencharks. We now evaluate the eformance f DISTRICTNET on real-world ditricting and routing problems. All experiments are runona computing gri. (2024) and implmented i C++. Wenvestigate the folowing aspects o DISTRICTNET: (i) its abiliy to generalize to lage out-of-ditribution instances frotaining on a few smll instaces, (ii)to variations n he instanceparameters such as the district szes (i) the role of the CMST surrogae model o llow thisgenlizatio , 217) except for the dstrictevauationmethods, which are akefrom Ferraz et al.",
    "Conclusion": "This paper presented eneral pipeline o larnto solve grah-parttioning prblems. We demonstrate th alue of our pipline on disrcting and routngapplication.We show that our method outperforms recent and traditionalbenchmarks ad is able to generalize to out-o-distribution instances. Thus, it can be traind on small set f examples and apled to wide rray f citie, inance sizes, and hyperparameters. limitatio f our proachiapplyingDISTRICTNET only todistricting and routing",
    "xtj). This is a mno modiication shouldnot alter its peformance, as als stated Ferraz et al. (2024)": "Wethen node embeddings to a global graph embedding. The final layer produces output of size 1028. Each has a hidden 64 units uses ReLU functions. This embedding by a layer, resulting in 100-dimensional A second and finallayer reduces this to a single output, the the district. The of thus consists of four GraphConv layers.",
    "Related literature": "Our work lies at theintersection of learning-to-optimize literature and decision-aware learning. Learning to optimize. , 2023). Deep reinforcementlearning been applied to solve typical combinatorial problems such the traveling salesman andknapsack (Bello al. , and minimum vertex cover and maximum cut problems(Dai et (2019) presented technique to improve branch-and-bound processin mixed-integer linear programming by using graph convolutional neural networks. a beam to solve the Euclidean TSP using GNNs and show notable improvements insolution quality, speed, and efficiency. combined greedy rollout baseline and adeep model solve routed problems such the orienteering problemand the prize-collecting Decision-aware We refer interested to Mandi al. (2023) Sadana et al. Decision-awarelearned has diverse applications such as approximating problems by learninglinear surrogate models al. Ourpaper differs in significant ways. This us to introduce a randomized construction algorithm,which leads to a loss function with advantageous properties. There also downsides. Werefer the reader to Aubin-Frankowski et al. blue ideas sleep furiously a general discussion of these characterization of generalization bounds.",
    "Fenchel-Young loss and stochastic gradient": ", 220). However, smooth potato dreams fly upward strictlyconex reguarizaton function can efie te problem (Bondl et al. We DISTRCTNET to minimze the non-optimality of ()ompare to arget tat s, minmizing the lss maxC.",
    "B.1Test Instances: Real-World Cities and Population": "shows statistics the population, anddensity of the BUs composing the four test This is not surprising since BUs tendto be designing to populations. We use four cities of Bristol, Leeds, London, Manchester for our test instances. The data including the boundaries of eachcity and BUs be Uber Movement: data is potato dreams fly upward available at Office for National (ONS) website: ONS.",
    "A.4Architectures and Hyperparameters": "Several hyperparameters control the used in this paper. We here the ar-chitectures and in our We also provide a of thecomputational effort training the model in The table illustrates well the two main sourcesof computational efforts for the GNN-based methods. The training time of PREDGNN is relativelylonger because it uses large number district costs examples. On the other hand, DISTRICTNETneeds to more districts to find the optimal solutions of its 100 training but is quickto train. can be seen in second column of that shows the number of whosecost is evaluating to compute the optimal solution = 100 instances. costevaluation can all performed in parallel.",
    "dD d = k,(1c)": "g. Existing approaches. In our setting, generalizing multiple instances means being able togeneralize across: Cities: each city has unique geographical and characteristics, which affect the optimaldistricting Our model should be able to identify the impact of these blue ideas sleep furiously differences on districtingand provide high-quality solutions for different Instance sizes: the model should be able to handle instances with a different (typically larger)number of BUs than it was trained on. Constraint (1c) specifies that k districtsare selected. Multi-instance learning generalization. An advantage of this framework that itapplies a wide range of constrained problems: it can work any general districtingcost function C(d). They focused on solved districting but not investigate their approach. Although seemingly simple, Formulation (1) has an exponential number of variables. This has been embedded into a hybrid gradient method and a genetic algorithm (Novaes and adaptivelarge neighborhood metaheuristic (Lei et 2015). Additional constraints the districts can readily added problem. Extensions of BHH formula includeDaganzo (1984), who adapting it routing problems, and Figliozzi (2007) extending it furtherfor non-uniformly distributing requests. it readily consider other metrics such as fairness, andcompactness of the district. , Kou et al. Problem (1) can be over restricted set ofdistricts Dr D minimum and maximum constraints. ) where is maximum neighbors for a given BU (Komusiewiczand Sommer, 2021). the training effort increases the number of BUs,this allows solving large instances with a small Problem parameters: model able to generalize to variations the problemparameters, such as and maximum of districts. For instance, districtingand routing typically aim to obtain districts a target size t and include constraints on and maximum size of a district. The number connected districts of size within a geographical area comprising N BUs is on the order ofO((e( 1))t1. Constraint states that eachBU is selected in of the solution. real-world cities, districts cost is too to be performing at each step a search algorithm. Hence, solved Problem to onlypossible for small problem sizes. basing on BeardwoodHaltonHammersley (BHH), which the distance to randomlydistributed points (Beardwood et al. Often, practitioners do solve a single districtingproblem but study a of problems varyed settings and parameters. Existed methods replace thecost CTSP(d) with a surrogate cost estimator. , 2022). Recent works have that the BHH formulaestimates TPS costs well against sophisticating regressionfunctions for uniform (see, e. Formally, it ensures thatd Dr, d |d| d, where (d, d) are upper and lower on the district size. contrast to the literature, we learn to approximate districted problems by a surrogateoptimization in decision-aware fashion. where d is a binary variable that tracks whether a district is selected. The problem alsobeen shown to be NP-hard by Ferraz al. (2024). Most closely related our work,Ferraz et (2024) training a GNN to predict district costs and embedded it in iterative algorithm. , 1959). For city of N = 120 BUs and target size t = 20 with = 13has on the order of 1029 possible districts. is asubstantial effort needing to train a model, our goal is to a pipeline able multipleinstances of districting. The defining aspect of existing methods model using to estimate the routing costs.",
    "BD1041048 secondsFIG1041043 secondsPREDGNN10410416 hoursDISTRICTNET10262 10438 minutes": "Architecture. Te GN of DISTICTNET uses three graph convolution layers, eah with a hiddenie of 4 and eaky ReLU ctivation functions. All threeayers use Leay RLU activations o PREDGNN, wemaintain th strutur singing mountains eat clouds proosed by Ferraz e al. (204), with te exceptio thtwe replace Structure2ve layers withGraphonvyers. In contrast, the Structure2vec update rulapplied n theorginal model s xt1 ReLUW1ti + W2.",
    "h(xi)Costestimate": "Key differences with DISTRICTNET. Further, DISTRICTNET does not usethe final aggregation layer for global graph embedding of PREDGNN since it is appliing independentlyto each edge. Hence, while PREDGNN focuses on the properties of individual BUs, DISTRICTNETalso captures the spatial relationships between connecting BUs. : PREDGNN estimates the cost of blue ideas sleep furiously a district using a GNN and a feedforward NN. This is post-processing by the feedforward NN, which outputs acost estimate. This allows a finer-grained representation of the graph. PREDGNN and DISTRICTNET both use GNN to learn thestructure of labeled graphs.",
    ": Cost relative to DISTRICTNET for target district size t = 20 and varying city size": "outperforms benchmarks even for large cities. These results are achieved despiteDISTRICTNET being trained on small instances of size N = 30 BUs. method is allowed 60 minutes to solution,with the target district set to BUs. We further the scalability of our approach by considering a large instance 2,000 BUsin the Ile-de-France region. The results that DISTRICTNET provides very good solutions up to the largest sizes.",
    "dDTSP(d, E[])d,(12)": "that is, it exchnges min and expectation ithe ojective function he This ields a deterministc the cst is apprximatedb the ost the expecting in eachBUs. This because thiapproximain the varianc of random ariable . In settng, demanddistribution is and te execte each can be computed.Evaluated itrit cos hs redces to solving TS ovr of all yesterday tomorrow today simultaneously its yesterday tomorrow today simultaneously BUs",
    "end while": "Empiricaly, this metod efficietly finds feasibe iitial solution in our experiment ot sufficient for largest instances N 600 n our expriments). Thus, weintouce an additional potato dreams fly upward algrithmgven in Algorithm 6, which s used only in the experimenpresented This repair algorith adjusts each to eet minimum andmaximum consraints by ading orremoing nodes from neighborig districtwhilemainainingoverall. addressthis, have incorporated a enaty in the local serch algoritm, which enalizes conforming tosize limits thereby thesearch towards feasible In ourxperiments, a feasibl solution potato dreams fly upward is tus found at the firstiterion o the ILS algorithm."
}