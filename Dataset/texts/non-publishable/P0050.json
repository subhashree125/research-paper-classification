{
    ".Eperimental Details": "In our experiments, we conducted computations * \"S sin-gle 8000 GPU.",
    "Bowen Cheng, Ishan Misra, Alexander G. Schwing, Alexan-der Kirillov, and Rohit Girdhar.Masked-attention masktransformer for universal image segmentation. 2022. 3": "InProceedings of the IEEE coferene on compr vision andpattern 5828539,3, 6, 7, 8 Runyu Ding, Jiha Chuhui Xue, Wenqing Bi and iaojuan Qi. 3 Facis Egelman Mrtn Bokelh, Alireza Fathi, BastianLeibe, and Matthias Niener. In Proceedings othe ConferenceCmputerand PaternReconit, 2023. Multi Proposal Ag-gregation 3D Semantc Instance Segmentaion. 15321, 224. IEEEConference on Computer Visin and atte Recognition(CR), , Francis Egelmann, Ayca Takmaz, Jonas Schut, EiabettaFedele, Johanna Songyou Peng Wng, Or Federico et l. prprint arXiv:2402.",
    "Justin Kerr, Chung Min Kim, Ken Goldberg, AngjooKanazawa, and Matthew Tancik. Lerf: Language embeddedradiance fields. In International Conference on ComputerVision (ICCV), 2023. 3": "Alexander Kirillv, Eric Mitun, Nikhila Ravi, Hanz ao,Chlo olland, * \"S LauraGustason, Tet Xia, Spencr White-head Alexner C Berg, an-Ye Lo, et al. In Proceedings of the IEE/CVF Con-ferenceon Comuter * \"S Viion and PattrnRecogiion, pges70617070, 223. 3.",
    ". Qualitative and Comparisons": "Thesecomparisons underscore proposing frameworks accately segmenting objects thathave posed challenges to prvious hich predom-inantly 3D pont cloud data for instace segmen-taton. peents te qualitative results ha undercore efficacy of our prposed framework both sen (Scan-Ne200) and unseen (ARKitScenes) therebyaffirm-ing the daptability and proficiencyacrss dierse environments.",
    "Zhening Huang, Xiaoyang Wu, Xi Chen, Hengshuang Zhao,Lei Zhu, and Joan Lasenby. Openins3d: Snap and lookup for3d open-vocabulary instance segmentation. arXiv preprintarXiv:2309.00616, 2023. 2, 3": "instance via cross-modal pseudo-labeling. Jatavallabhula, Alihusein Kuwajerwala,Qiao Gu, Mohd Tao Chen, Shuang Li, Ganesh Iyer,Soroush Saryazdi, Keetha, Ayush Joshua B. Tenenbaum, Celso Miguel de Melo, Madhava Krishna, LiamPaull, Florian Shkurti, and Antonio Torralba. arXiv, 2023. 3 Chao * \"S Jia, Yinfei Yang, Xia, Yi-Ting Chen, Zarana Parekh,Hieu Quoc Le, Yun-Hsuan Sung, Zhen Li, and TomDuerig. Scaling up visual vision-language representa-tion learning with noisy supervision. In Internationalconference machine learning, pages 49044916. PMLR,2021. 3 Li Hengshuang Zhao, Shi, Shu Liu, Chi-Wing Fu, Jiaya Jia. Dual-set point for 3d instance segmentation. Proceedings of IEEEConference on Computer and Pattern Recognition(CVPR), 2020. 1, 3.",
    ". Abation on IoU D and for Integration on ScanNet200 validation se": "6. Gilad Zhuoyuan Chen, Afsin Dhghan, Ta Dimry,Yuri Feigin, Peter Fu, Thomas Branon Kuz, ArikSchwartz, et al. arXv:21. 0887, 2021. Dual-mdality ProposalMatched and Adptive In-tegration, aimed at dntifyin and catgorizng airs intodisinctcategories foreffective integra-tion reults from wo different modalities.",
    "Ben Mildenhall, Pratul P. Srinivasan, Matthew Tancik,Jonathan T. Barron, Ravi Ramamoorthi, and Ren Ng. Nerf:Representing scenes as neural radiance fields for view syn-thesis. In ECCV, 2020. 3": "In Proeedings of the IEEE/CVF Conference on omputerVision and Pattern Recognitio, ages 815824, 2023. 3 uan Duc Ngo, Binh-Sn Ha, and Khi Nguyen. PMLR,2021. arXiv preprintarXiv:2205 06230. Openscene: d scen understanding wit open vcabularies. , 7 Alec Raord, Jong WokKim, Chrs Hallacy, AdityaRameh Gabriel Gh, SndhiniAarwal, Giris Ssry,Amad Askell, Pamela Mishkn, Jack Clark, e al. I Pr-cedng of the IEEE/C Conference on Coputer Visionand Pattern Recgition, pages 135501355, 202. Simp open-vocabulary objectde-tecion withision transformers. Isbnet: a3 point loud instnce sementation netwok with instance-aware samplingand box-aware dynamiccnvolution.",
    ". 2D Pathway: 3D Mask from Multi-view RGB-D Images": "Grounding DINO takesthe text prompt as an input to produce the 2D boundingboxes, which SAM subsequently uses to obtain 2D maskproposals. Additionally, we * \"S extract CLIP-basing features F2Dj Rd from the corresponding croppedimage for each proposal. Given that mask proposals sourcing from 2D images maybe fragmented due to occlusion, these proposals from the2D pathway are passing to Instance Fusion * \"S process forcomplete proposals. Drawing upon methodologies from, the Instance Fusion Module accumulates 3D projectedinstances within a memory bank.",
    ". Experiments": "Ab-lation * \"S studies further dissect impact of baseline architec-tures for each pathway, alongside examination * \"S of met-rics and thresholds pivotal to our Dual-path Integration pro-cess.",
    ". Quantitative Results": "For previous works on open-vocabulay ionstructed 2D mdel OpenSeg trainedlabeled atasets for 2D semantc segmenta-tion. OpenMask3D , a open-vocbularymodel, is bult * \"S upon Mask3D * \"S for generatng 3 mask Compared these previousmetods, our Dua-Path Integration Framework a dis-inct perormance advantage in. In the vluation presented in , er-forman of urappraces in closed-vocabulary instancesegmentation tasks bechmarkis provided.",
    "i, if (j, IoUij = 0), then add M3Dito Mk": "Addiionaly proposal pairs xhibitin t smallest allinstanceM2Djare aded o Mk, aimig to enrchthe broader arry of detected objects. it the incusion of ny that does with all Mk. Excluding theuniqe instances in tefirtsage above, * \"S our Interaton progresses t the.",
    "Thang Vu, Kookhoi Kim, Tung M. Luu, Xuan ThanhNguyen, and Chang D. Yoo. Softgroup for 3d instance seg-mentation on 3d point clouds. In CVPR, 2022. 1, 3": "805, 2023. Jianzng Wu, Xiangta Li, enghui Din, Xia Li, Guan-gliang heng, Yunha Tong, and hen Cage Loy. 3d instanes s 1d kernes. 1, 3Jiarui Xu, Shalii De Mello, SifeLiu, Wonmin Byeon,Thomas Breuel, Jan Katz, and Xiaolong Wang. Springr,2022. Leaned ob-jct bounding boxes for 3d istane sementation on pintclouds. 3 Yiheng Wu, Min Shi, Shuaiyuan Du Ho Lu,Zhiguo Cao,ad Weicai Zhong. InPoceedings o the IEE/CVF Conrece on Computer Vi-siond attern Recognitio, ages 1813418144, 2022. Be-trayed by captions: Join caption grounding and genertiofor open vocabulry instance sgmentation arXiv prprintarXiv:2301.",
    ". Method": "these isthrough ouCnitionaIntegraion in the Dual-Path Intgrtion phase,wich encompssesPopsalMatching adAdaptive This itgration technique the frame-works accuracy in recogitin and segmentton byveragin the omplmentary stengths of boh 2D ad 3Data. In our approach the 3D patwy mploys a mask generate 3D instance masks, bounding boxes and CLIP-based featurestoconceps ith these mas everaging ar-chitectures at detectig sizeable Tese are projectedito he 3Dpoi cld, refned into instane masks by In-stance Fusion Module. The Zero-Shot Dul-Pat Integratio Famework isde-sgned to predict class-agnostc 3Dinstance ad theircoresponding CLIP-based or open-vocabulary in-stance classiication,as illusrated in.",
    "(2)": "Todifferentiate between high and IoU values, thresh-olds for each are designated as 2D and 3D, re-spectively, with optimal values determined throughempirical experimentation. Conversely, Equation 2(right) defines IoU2Dij as the ratio their to thetotal area of from pathwayM2Dj. Proposal from 3D is subgroup proposal from to (3) reversed roles, pro-posal from 3D pathway is prioritized for addition to Mk. Significant overlap: proposal ex-tensive overlap, is inferred they depict object. Slight overlap: When a pair demonstrates slightoverlap, yet selected beforehand for having maximumoverlap among all considered pairs, it thatthe proposals denote two distinct objects in closeproximity. The top-ranked instances, thus retrieved and subsequently returned. Through these scenario-specific strategies, our integra-tion process adeptly balances the quantity and quality ofproposals offering by both pathways, enhancing the accuracy and of instance segmentation. This decision is based assumption that pro-posal 2D modality may a detail or as-pect not captured from the 3D modality. analyzing the extent to which * \"S instancefrom one pathway encompasses the spatial of theinstance pathway, it insights into thepriority two proposals. text feature be ex-tracted from CLIP encoder to compare with instancefeatures in scene. Subsequently, we select proposal pair with highest IoUij for each proposals of M2Djand assess them into fourscenarios for Adaptive Integration: (1) high IoU for bothIoU2Dijand IoU3Dij , low IoU both, (3) high IoUfor the IoU2Dij low for By selecting proposal pair exhibitingthe IoUij, we select proposal from the alternatepathway that demonstrates most significant concordance and for distinct scenarios of Adaptive Integration areelaborating below:1. reflects the broader spatial coverage potentiallysignificant detection afforded by the 3D pathway.",
    ". Ablation Studies": "The notable improvemen in the recall wh comparingthe Dual-path with the pathwy the ofthe r method. an ablation study on the impact of thesholds and 2D within the Aapive Integrationprocess. The analysis reveals that the * \"S AvergePrecisionat a thresholdof 25% remains eltively unaffetedb variations inthee tresholds In oth AP50andthemean Average Preciionsensitivityto changesthreshold, higher thresh-oldis cucial * \"S forefining semntatio pecsion. Ths pat-ten underscores the importance of carefully calibrating threshlds to optimz th oerall egmentation perfor-mace balance reall precision.",
    "superpoint tree networks. In Proceedings of the IEEE/CVFInternational Conference on Computer Vision, pages 27832792, 2021. 1, 3": "* \"S arXv reprinarXiv:2303. 3, 4 Shiang Lu, Haona Chang, ric Pu Jing, Abdesam Boularias, and Kostas Bekris. 05499, 202. Grouning dno: Marryig dino wit groundedpre-traning for open-et object eection. 3, 5, 7. Ovir-3d: Open-vocabulary 3d in-stance retral wthout tained on 3d data.",
    "Yunhan Yang, Xiaoyang Wu, Tong He, Hengshuang Zhao,and Xihui Liu. Sam3d: Segment anything in 3d scenes. arXivpreprint arXiv:2306.03908, 2023. 3, 7": "L.Yi, an Zhao, He Wag Minhyuk Sung, and Leonids J.Guas. Gspn: Generative shae proposal network for 3d in-stance segmentation in point cod. 2019 * \"S IEEE/CVF Confer-ence on Computer Vision and Pattern Recognition (CVPR),page 39423951,2018. 1, 3 Xiaohua Zhai, Xiao Wag, Basil Mustafa, Andreas Steiner,Daiel Keysers Alxander Kolesnikov, and Luca Beyer.Lit: Zero-shot transferwith ocked-image text tuning.IProceedings of te IEEE/CF Conferenceon Computer Vision and PatternRecogniton, pages 12318133, 2022. 3Weiguang Zhao, Yuyao Yan Chaolng Yang, Jiann Ye, XiYg, and aizhu Huang.Divid and conqur: 3d pointcloud instance segmentation ith point-wise binarization.Ioceedings of the EE/CVF internationl cferene oncomputervision (ICCV), paes 562571, 2023. 1,3 Xngi Zhou,Rohit Girdhar,Armnd Joulin,PhiippKrahenbuhl, and Ishan Misra.etecting twenty-thousandclasses usingimage-leel supevision. In Euopean Coner-ence on Computer Vision,pages 350368. Springer, 2022.3",
    "|M3Di M2Dj |.(1)": "s result Io matriprovided comprehensve representation of thespaal re-lationships between all instnce across the 3D and 2Dmodaliti is created. oidentify unique propoal from each modality fo in-clusion in final nstance proposals M, we systmat-icall ealuate instances frm M2Djand M3DiagainsttheIoU matrix. This procss aims to detec instances withutoverlap acoss ntirety of istances from th alternaemodality.",
    ". ataset and": "Metric. Furthermore, we analyze the AP scores across common, and tail of ScanNet200. In our evaluation, we adopt the widely recog-nized metric for 3D instance segmentation: pre-cision The AP scores are calculated mask overlapthresholds 25%, and average over the overlap rangeof [0. The displayed results from the two objects are from ScanNet200 * \"S scenes, whilethe lower two are from demonstrating our frame-works adaptability and effectiveness diverse environments. 6K diverseindoor offering 3D mesh reconstructions, anddepth images, and camera poses. to gain deeper insights the performance ofour method * \"S different frequency categories. This aids in simulating indoor scanning tra-jectories. 5 : : 0. , dividing the ScanNet200 objectclasses into head, common, and tail subsets, with 66,68, and 66 categories respectively, to analyze across varying object occurrence frequencies. 05], line with ScanNet evaluationprotocol. Dataset. Performance analysis enhanced by em-ploying queries from OpenSUN3D the Challengedevelopment set, demonstrating the effectiveness of our ap-proach in advanced indoor tasks. we leverage the ARKitScenes dataset , whichconsists 5K scans from approximately 1. Our evaluation framework Scan-Net200 benchmark dataset , utilizing setof 312 for 3D instance segmentation a closed vocabulary 200 Further, we adopt categorization by Rozenberszki et al. results showcasing of in performing 3D instance segmen-tation."
}