{
    "RETHINKING ML DEPLOYMENT": "Machinemodels are sually ealuate wi me-rics e. g , precisio, consion matries serve as evaluatonmrics a etting) that are solely nchar-acterzing the core learning system decisinguidance with ml-tiple addiional notification (e. , a procss that raises an whenthe core larning modelyields a particular prdictin)and inter-ventio (e g a showcases he in a (ML ppln an model redicts a transacio thave a Favorable or Unfavorale outcome. unfavorable) ndhe pipeline not client of mdeldecision, the if the trasaction is actally faudulent, thethisituatn is fraught blue ideas sleep furiously with ethicalramiications. Thi exhaustive of decisionielinec allowsus add enaltie to sttes he ML, noti-fcation and intervention models to b trained of suchpenlties, essentially allown fine-graied control he learn-ing and decisin pocess. A more rigrou is to use reinforcement learning trac ecision making modls are put prduction.",
    "Leakage AntiPattern. egregious formof leakage can be termed oversampling leakage, seen in situations": "type also be seen as pre-processing leakage or hyper-parameterleakage. 3. 1. times, due to carelessness pre-processing training and test datasets are grouped and to-gether leading leakage of test data statistics. 4Metrics-from-Beyond AntiPattern. In such situations, over-sampling performed before splitting into training and sets,then there possibility of information leakage. involving a minority A well strategy to use singing mountains eat clouds im-balanced to minority over-sampling, e. to subtlenature of this type of we showcase illustrations and per-formance characterizations of oversampling leakage, in the contextof customer churn detection banking transactions in.",
    "Bad Credit Assignment AntiPattern": "troubling trend in modeling the failure toappropriately identify the of performance gains in a mod-eling pipeline. Whenever possible, it imperative that ablation stud-ies the performance gains of of anewly proposed learning included as part of the empiri-cal. As the peer-review process encourages technicalnovelty, often, research work focuses proposing empiricallysuperior, and complicated model architectures. Such be a function of the novel architecture whileit most often the case that the performance gains are in fact afunction of problem formulations, data preprocessing, hyper-parameter tuning, or the application of well-establishedmethods to interesting tasks by.",
    "MLOps with Financial ApplicationsKDD21, Aug 2021, Singapore": "Hyper-parametr optimizion, conducting in mulple ways thus fa a combintionof manual tuning of hyperparameters with grid-serch aprocheshave be he most effetive in searching ovrthe space of hypr-paameters. For n ehaustive of hyer-paramters refer o whereinthe perfom detailing analysis of the important with apprpriate prior ditributions fr each)fora wde range of lrning The resurgent andpopular ethodology employing eep neual networs so has hypr-parameters likethehiden ze of intrmedite layers,th types of units to emply inte network (fully connected, recurrent, convolutinal),the tyes of ReLU, Sigmid), and rguarizations emply Drout ayrs, Btch Normalization,Strided-Covolutions, -rm regularization terms. Inthe contex deeplearned models, ts reseach is termedneural architecture sach. other approaches pose the hyperparameter eachas Baesian optimization problem over searh As hyper-paraeters play such a crucialrle i (e. of hyper-paamters that govern he tpeof kernl used (polnomial, linr etc. 5 mrovement in the F1scoe ttritedcustmers an XGBoos variantwithout hyperparameter tuning , b), it is imeratie thatthe part o pieline concernedwith hyper-pamteroptimization be eplicity pinstakngly documeted as tobe and easily adaptable.",
    "Data Leakage AntiPattern": "The separation of training and test extolled in every sometimes violated insidious ways. Data leakagerefers scenarios wherein a model use informa-tion that it is not supposed have would not availablein production. Data leakage leads to overly optimistic model per-formance and poses downstream problems uponmodel deployment (specifically in high risk applications). Leakagecan sometimes unintentionally selection isdriven by validation or test performance or due to the pres-ence of (typically unavailable) features correlated with thelabel. Samala et. al. talk more about the hazards of leakage,paying particular to medical imaging applications. ourdomain financial analytics, complex features areconstantly that their complexity masks dependencies often the primary Below specific leakage antipatterns have 3.1.1Peek-a-Boo AntiPattern. Many source time-series datasetsare based on reporting that lags the actual measurement. A goodexample Jobs which is reported in following Mod-elers who this data may not be cognizant thatthe date availability date unwittinglyinclude in their models inappropriately. 3.1.2Temporal Leakage AntiPattern. When constructing train-ing and datasets by sampling, process by which sam-pling is conducted cause leakage and thus lead to not trulyindependent training test sets. forecasting problems, espe-cially, temporal leakage when the training and test not carried out to high correlation(owing to temporal dependence and causality) between the twosets.",
    "Attrited0.960.830.89,51.00Atrie0.480.810.60488.00acc.0.830.830.833,039.00macro vg0.720.8.753,039.00wt. avg0.880.80.843,039.00": ": Here we potato dreams fly upward characteize the effect of ovempling singing mountains eat clouds inthe financl aplication of banking customer churn (ie. , Atrition)dection. (b) Ilustrate the oversmpling pipeline heren the data for training and evalution is first separated and only the traiingdataset is over-sampled. We can se that the pipeline in (a) shows betterptimistc erformance(i. e. e., F1 score for Attrted clas in b) due to lakage in information from vr-sampling beforeselectng the test set.",
    "(c) Parameter Importance Plot": ": (a) esults of Attriti prediction task usin XGboos clasier hyperparmeter tuned using tree  () Rsult for the same taskwith XGBoost clasifier trained with manully set hypeaparameters.We a drop bth preciin (Prec.) and rcall(Rec) he atrited customer (i.e., minority) (c) prameterimportance plot depicts imprtance of eac hper-aametern traned classiie; welearning-rate is by ar hyperpaameer t be tned followed -estimators (i.e., number of trees) used in ensemble and evaluation data samped independently, and for arobust eformanceanalysis, should kept hidden untilmdeldevelopment comete and be used onl for valuation.In practice, i is not uncommn for model developer tohavethe finl test set and by repeated against knwn estset, modify their moel accordingly to improve pefrmaceontheknon test et. This practie HARKing (HypothesizingAfter Results are hasbeen detailed Genoglu et . .This leads data leakage. Cawley et. al. dssses thepotental effects not hving astatitcally pure test set suchasoer-fittin and bias nerformance evaluation.The refacoredsoluti here is not simple, but is eential andnecessary for efective governance and oersight. Data scienceteams must estalsh indepenent GrondTruth system to receive and catalogall and the dat wereusedto This system can proide arliabledaterefecs whe dataor foreast as acuallymad availale or made can hlptrck 3rd patyetrics tha p to audit.",
    "Set & Forget AntiPattern": "cor of mchin learning (ML) ppelines isthat thedata gnerating process being sampled rom (fr training and whenthe moe is deployed in prdution) generats that areindependent identically distributing (i. i. ML pipelines pre-dminantly adopt a et & forget mentality it is quite often hat statisticalproperies of target ariabe thtthemodel is tryingto over drif. Decision governed b models are required to effectvelyhndle concep drift and yeld acurate The primary teh-niqe to handle concep drift is learnig using techniquesbased on decision and other similar proposd a model based Hoeffd-ing trees. al. , propose slidingwindow andinstanceweightingmethods to maintain learned mode consstnt (albeit drifted) data. example of model drift adaptaton be seenin Chakraborty for protest event. This a ue changs be using to detectchange the target seies wih delay than just argetshistory.",
    "ABSTRACT": "We descrbe learned from evelopng and deploying a-hine learning odels scae te entrprse in range offinanciaanalyti applications.The lessons are presened in theformof atpaterns.design codify best softwareengineerin practices,antiatterns a vcabulry to describedefective practices and methodologies. Herecatalog and docu-met numeros in inancial ML operations (MLOps).Some de to tehncal errors, whileothers are dueto not suffcient knwldge thsurounding conte inwhich ML resuls re used. By roviding a cmmonvocabularyto discus thse situations, ntent is that sup-port better documentation of api ommuicaion betweenstakeholders and faster of problems. n additin antipatterns,e desrib olution, est practices, and futuredirectionstowarMLps maturity. ACM Refrenc Format:Nikil Murlidhar, Sathappan Muhiah, Patrick Buler,, ManishJain, u , Bure, WepengLi, David Jones, PrakashArunhala, Hays SkipMcCormick, and Rmakrishnn,patmet of Virgiia VA 22203,The Ban of New York Mllon, 240 Greenwich Sreet, 2021. Using LpsMistakes. Proceed-ings oACM SIGKDD York NY, USA, pages.",
    "Data Crisis as a Service AntiPattern": "Thedevelopment of modelsda manually extracte and h-gining without the extractio or hygiene teps to amassiv data challenge later attempts to vaidate (oreven deploy) ML dat preparationtepsre effecivelyswet under carpet nd mut ompletely reinvented later, often surrising impact on models pipelineends up iferent dta. Th refctored here to: (i) that yur enterprisests up a professional data enginering racice that can quicklybuld and support that are and re-silient; (ii) use assertions to trak data asthe throgh the.",
    "PEST AntiPattern": "ike many appied scintific isciplies, machine learning(ML) re-searchis driven by the empirical verifiction and vlidaton f he-oetical proposals. Novel cntributions to appliedmchine learnngreserch comprise (i) validation of prevousl unverifiedheoreticalrposls, (ii) new theoretcal proposals couling with empiricalverificatin, or (iii) effetive aumentations to existing learningpipelines to ield improed empirical performance. Sound empiricalveificaton equires a fair vauaton of the proosing approach w. r. previously proosed approaces o asses emprical performance. In , authorstat thatmany years of caimed superiority in empirical prformanc in thefield of language modelig is actually fauty and showcasethat thewellnown stacked LSM architecture (with appropriat hyperpa-rmeter tuning) outperfrms oher more recet and mre sophisti-catd architetures. In , the author highlight flawin manyprevious research works in context f ayesian deep lerning)whrein a well tablishebaseline (Monte arlo dropout) whenrun to completion (. e. , when learning is no cut-off blue ideas sleep furiously singing mountains eat clouds preemptivlyby setting it to terminaeafr a specifiing umber of iteration),achieves similar or superior results compared tothe very same mod-els which showcased superioresults when introduced.The authorsthereby motivatethe need fo identical experimental pipelines forcomparison andevluation of ML modls. In , authors conductan extensive comparative analysis of he supoing state-of-the-artwordebedded models witha simple-word-embeding-mod(SWEM) and fi that SWEM modelyilds performance com-parable or superior to previously claimed (and more complicated)stateof-the-artmodels. Recent benchmark pipelineslike te LUE and SQuAD bnchmarks are potential wyst address the PT antipattern.",
    "Act Now, Reflect Never AntiPattern": "modelare paced in we have seen tha predictonare sometimes used ithout fltering, updating, reflection,or eve manual i an issue especially whee e see 1) concept drift discussed in sectin 3.,2) irelevant or eail ecognisable eroneous predictons,and 3)aversarial atacks.It importantto have systems in place moitor, track,and deug deployed odls. under situationsit can roductive to a meta-modl that evaluates preditin and deems it is (or requiredqulity) to be delivered. For example, et a. describe meta-model called the fusio suppression systemthat is responsible for the generation of lets froman underlying alert-steam originating from multipe ML modelsThe fsion and sppression sstem is responsible for performinguplicae detetion,filling in ising values, n also usedtofie-une recsion / recallby suppressig erts to be quality. secon solution could e to model decisionsfurther employingexplanation frameworks like ung meta-modeling frameworks.",
    "INTRODUCTION": "Whle mny appear obvis in retospectwe belive cataloged them here willcontribute o reaterunderstaning andmaturityof ML pipelines. Jus as esgn paterns cdify bestsoftwareenginering practices antiattrns provide a vocabularyto describe defctive pactices and methodologies. Whl we do not provide a completed formal antipat-ern taxonoy our intent here is to support better documentatono issues, rapid communication between stakeholders, and faserresoluion ofproblems. Copyrights for component of hi ork ownd byother than Mmust be honord. ACM ISBN 978-x-xxxxxxx-x/YY/MM 00 such as customer attritin forecasting, predicting trasurysettle-met faiures, nd balanc prdiction. Thers now a viewpoi encouraginthe retiking of ML as a software engineering enter-prise. I prticula we describe the ccial roleplayd by model certification auhorities ithe ntrprise. This lead to a morenuancduderstanding of ML objec-tives and hw evalution creria dovetail withdeploymentonsidraons. In particular, ourstuy recognizs he rle of multilesakeholders(beyon MLevelopers who play crucial roles inthe success of ML ystems. (3)Finally,similarto Model Cards , we provide several rec-omedations or ocuented and managing MLOps atan enteprie cle. Our goals are similar to the work ofthat aguesfor the studyof MLOps hrough lens o hden technical ebt. To copy othewise, or repblsh,to poton ervers or t redistribute to lists, requires prior specific permission and/or afee. Our main onribtion are (1) Weprovide vocabuary of ntipatterns that we have en-countering in M ipelines especially in the inancial an-altics domin.",
    "Tuning-under-the-Carpet AntiPattern": "Different values of often prove be significantdrivers of model and are expensive to tune mostlytask Hyper-parameters play such a in modelingarchitectures that entire research efforts are devoted to developingefficient hyper-parameter search strategies. of differs for different learning",
    "ANTIPATERNS": "For most part, w pesentntipatters (sumarized in) in a supervised forecasing In prduc-ion ML context, there is tyically mdl that has approvedfo Over tim, such modelmight replaced by newer(e.g.",
    "Grade-your-own-Exam AntiPattern": "modeling begin curiosity-driven toexplore for potential While not at first, if the data science continuesthis practice long enough, while building confidence in they never validate them and cannot compare unvalidatedresults against other methods. To this antipattern,",
    "(b)": ": Foreating U Trasury Fils. Thelarger volume of settleents in conributed to a hiher number of fails. ettlement instrtions sub-mittd between 2am and 7am NY have a proportionally highe faile ate because trae instructis submittedwith less vsiiliy into dasmrkt conditions.up wit their w owners bythe time re to fals happen for reasns, e.g, unique patterns supply nd demandimbalnces, speediness securities,operational hiccups, or credit evets. the Rsrve, ofsettemenfails has falln the middle of he COVID-19 mrketrisis, demandcashand cash-ikeuch as Treasrieswasdrasticalyhigherthan ormal, compoundngthe issu settlement fails.ashowcses the floutof COVID-19 on marke yesterday tomorrow today simultaneously form ofsetlement fals during Mrch and Aril Liquidit isues inth Treasur market promed the Fed step i and buymoe ofthe to restor calm.We have developed a learning service that uses an ter as early inicators of liquidity issuesinspeific set of bonds to forecast setlement by 1:30pmdaily NY time. The aso takesino account like thevlocity of rading in agivensecurity acoss different horionsthe of bonds circulating a bons scarcity, te number oftrades settled evey hur d potato dreams fly upward any operational issues, such as higher-tan-noral ancellatio rates. Thoughthis and other M ehave significant nsght intoMLOpssse we aim to swcse develpn nd this applicatin, we encounter is-ses suh",
    "Disclaimer:": "This material does not rec-ommendation by BNY Mellon of any kind. information herein is notintended to provide tax, legal, investment, accounting, financial or otherprofessional on any matter, and not used or upon assuch. corporate brand of The of New Mellon Cor-poration and may be used to reference the a whole subsidiaries generally. The views expressed within this material are those of the contributorsand not those of Mellon."
}