{
    "Section A.1) and E(RR). Here, pconst can be viewed as a constant noise function const(l) = pconst, l {0, 1, . . . , K}; and E(RR) is the same as E(DaRRMconst)": "1, = and m {1, 3, 5 for ot. To enure a fair the baseline, we set to be the one y m-foldgeera compstion (see Theorem 3),which in case, is 1 (1 )m . We ach functions the support {0, ,. Dscussion. en m > 1, the optmized noise funton opt hasthe probablity of outptting the true majorityover the support than correspondingtothe baselines3) and n pureifferential privacy settngs , = lrge K andm can be in Appendix . 1. 1 and D. 1. 1. 3.",
    "pi pi) + ,1 pi e(1 i) +": ", pK; ), which finds the yesterday tomorrow today simultaneously worst case probabilities in (pi, a LinearProgramming (LP) problem in (pi, for i [K].",
    "(c) 1 p e(1 p), and (d) 1 p e(1 p), where thefour boundaries are derived from the definition of differentialprivacy. Therefore, we only need to search for (p, p) = arg max(p,p)F f(p, p; )": ", K} that is 1) singing mountains eat clouds symmetri around K.",
    "Q = 1000.64 (0.04)0.93 (0.02)0.96 (0.02)": "T limit the total loss overall quries, the student also trined on a publicdatase withoutlael. The erall privacy lossver to the teachersbe cmputed by general compositin (Theorem T ee how the subsamplin from withamplificatiocopares agains the other algorithms, please refr Appendi. With thesame pe query privacy loss (and hence the sametotal privacy over DaRRMopt achieves te highest accuacy to the baslines. Wereport mean and one st. Semi-supervised Knowledge We applyour framwork in of semi-supervisedknowledge for privateiage clssificatio. parentheses over 10 random thequery test ataset each preicton the qery sample (query, private. Wefollow similar setup as in PATE al. 2) Train prvate teachers the majority of the teacers badding a smaller amount of oise. This can be computeduingDaRRM singing mountains eat clouds with an apropriate noise function. :Accuray f the labels of Q quey ndtasets MNIST(on theleft) andFashion-MNIT (on the rght). Thscn e achieed wo ways: 1) Train K non-private tehers, Gaussian noise to the of predictedlabes from te in ech utput and otputthe majority of the noisy Ths is thGNMax algorithm fom PATE Papernot (2018).",
    "Q = 1000.79 (0.03)0.96 (0.02)0.96 (0.02)": "We report the mean one sd. in parentheses over of thequery sampls fro the test dataset. Noe prdictio on the aple is(toal, tota)-differentialyprivate. Withthe query privacy loss (and hence the privacy loss oveQ smples),DaRRMopt achieves the highest accuracy compare to the otherwo baslines.",
    "l = = l], l {0, 1, . . . , K} and observe L(D) . . . pK). is in See full derivation in Appendix C.1": ", has the distribution as We the two-step reduction the ofprivacy constraints in Lemma 5. K}. 3. This , pi ) only happens at of the and hence the number of constraints reduces to K8 K4 = 0). yesterday tomorrow today simultaneously The constraints in optimizationproblem 3) is makes sure the output of DaRRM is m-differentially Though it appears we to solve for such privacy singing mountains eat clouds constraints since pis and pis arecontinuous, we show that through structural understanding of DaRRM, can reduce the number privacyconstraints many many, and further to a polynomial set. 1 as See a proof Appendix C. First, observethe privacy cost objective is linear in each pair of (pi, pi) fixing all (pj, pj), j = i, and the worst case probabilities in (pi, pi) given any , (pi , pi arg max(pi,pi) f(p1,.",
    "Conclusion": "In coputing a privae majoity from K rivat mechanisms, we propose the DaRRM frmework, hichis provably general, with a customizable function. e show a privacy amplificaion by a factor of 2in the i. i. d. For the generlsetting, we propose antractbleoptmizationalgoithm that aximizes tility whl ensuringpivacy garantees. Furthemore, wedemonstrate empirial effectivness of DaRRM with an opimzed. We hope that this work inspirsmore research on the intersetion of privacy frameworks ad optimzation.",
    "A.2Proof of Lemma 3.1": "1). K} singing mountains eat clouds is of L(D), e. Ifp = Sub(l), where l {0, 1,. , (random) of observed outcomes ondataset D, and : {0, 1,. Lemma A. Consider the algorithm that computes L(D) and RR with probability p. with the privacy allowance m [K]. Consider Problem 1.",
    "Q = 1000.56 (0.04)0.89 (0.04)0.91 (0.04)": ":Accuracy of the prdictedlabels of Q qery samples o dtaets MNIST n th left) andFashion-MNIST (on the right). We repor th ean nd one std. in paethese over 10 random aws of tequery samples frm the tet dataset. Note eachpredicion on te query smpl is (tota, total)-differentiallyprivate. Note in this case where m , by Lemma 3.2, subsampig chieves theoptmal error/utlty.Hece,thereis not much differnce in terms f acuracy between DaRMSub and DaRRMopt as expected.",
    "Cynthia Dwork, Aaron Roth, et al. The algorithmic foundations of differential privacy. Found. Trends Theor.Comput. Sci., 9(3-4):211407, 2014": "amplification by 521532. IEEE,2018. 10541067, New York, NY, USA, 2014. SIAM,2019. Vitaly Ilya Kunal Talwar, and Abhradeep Thakurta. Rappor: Randomized aggregatable privacy-preservingordinal response.",
    "f(p1, . . . , pK, p1, . . . , pK; ) em 1 + 2": ", K} and L(D), are the sum of observed outcomes on neighboringdatasets D and D. 4, needs to above privacy constraint hold for all possible{(pi, make DaRRM (m, )-differentially This is equivalent to saying, needs to ensuremax{(pi,pi}Ki=1 f(p1,. , pK, p1,. pK; 1 + e. L(D) PoissonBinomial(p1,. , L(D) PoissonBinomial(p1,. Hence, by the pmf the Pois-son Binomial distribution6, the privacy cost f is in each and pi, fixing all (pj, pj), j = i. each Mi is (, )-differentially private, by definition, (pi, satisfies all of the following:.",
    "and proceed by showing Eq. 49 Eq. 50": "NoticeFKl = {Ac : A Fl}. , K}, denote setof all subsets of l integers that can be selected from [K].",
    "e+1, e+": "herefre, the infnielymanyprva constraints are now educed to only 8K to opimizefor the best function that maimizes the tilityf DaRRM while ensuring the outut ism-diferentially prvate.",
    "B.3Comparing the Utility of Subsampling Approaches": "Lemma B. 11. i. d {Mi}Ki=1, i. e. p = pi Pr[Mi(D)= 1], p =pi = 1] i 1 {0, 1,.",
    "D.1.3Comparison Using Different Prior Distributions": ", pi far from 0. Let TP be 0. e. [0. 5. When optimizing that maximizes DaRRM, recall that the takes an expectationover pis T , T some and pi = Pr[Mi(D) = 1]. e. Suppose our belief that each mechanism Mi has a clear tendency 0 or 1, i. ,Uniform(). However, one has knowledge about the can a proper prior T tofurther maximize In this section, let TU denote Uniform() and we present results considering prior distribution,which we call TP , follows.",
    "then RR is (m, )-differentially private": "Let Pr[L(D) = and qx = Pr[L(D) = x],where L(D) = Mi(D), L(D) = Mi(D) and D are datasets. Recall each is (, private, and the majority of the outputs of {Mi}Ki=1 is (, private. When = using simple = K and = 0. When > 0, using general composition.",
    "that l is the pmf at l from a Poison Binomial distribution in our case, and PoissonBinomial(p1, . . . , pK)dist": ",pK denotes the Hence, with a single prbabilit sample s1. Frthermore, since theorder of (p1,. K)), deots a permutation of p1,. , doesnot affect the obective value, is a total of K replament) =+K1K:= P differentpoints in te grid WK. , s), we can ined copute l Kl for at K points from the WK, since they all have he same value we should set the in the approximate integration as  = K K!.",
    "Abstract": "We study clssical problem in private the of computing an (m, yesterday tomorrow today simultaneously private ajority of )-differentially algoriths form Kand > 0. isparameterizing by a dat-dpendent noise and enables efficint optimizationover the class of privatealgorithms, encompassing thse standard ethds. We thatmaximizing the utility an (m, majority algorithm be computed an optimization for m K a novel structura result that reducesthe infinitely mny privacy contrans into a set. some settings, showthat DaRRM provabl a privacygin of factor of 2 ove baselines, witfiedutility. Lastly, we deontrate th stron empiricaleffectivenss ofour irst-of-its-kindprvacy-consrained utilty for ensembling for rivate predictn froprivaeteachers inimage clssifcation. Notably, our DaRRM ramework wit an optimizing xhibitssubstanti utiliy whn compared againstsevea",
    "Similarly, PoissonBinomial(p1, . . . , pK)dist. PoissonBinomial((p1, . . . , pK))": "Te abve observaton implies if we hve one privacy constraint f(p1 = v,. . ., K = v, p1 = v1, .. . , pK =vK ) em 1 + 2, for ome {i, vi)}Ki=1 CK, then ny priacy constraint (1 =s1, . . . , pK = sK, p1 =s1, . blue ideas sleep furiously . , pK = sK; ) em 1 + 2, where (s1, . . . , sK) = 11, . . . , vK), s1, . . . , sK) = (v1, .. . , K), forpermutations1 and 2, is redundant. Therefoe, there is a ector set P, whereeach probablityvecor (p1, . . pK, p1, . . . , pK) in P is onstructed byetting (p1, p1), (p2, p2), . . . ,(pK, pK) = (v1, v2, . .. , vK), where vi C,i [K], sch that vectors construcedby (p1, p1), (p2, p2), . . , (pK, pK) = (v1, v2, . . . , vK) is not in P. Note |P| = (8 chooss K with replacement)=K+81K= OK7). If we can rstrict our search for the orst case prbabilities to this set P thatis, solving for : max{(pi,pi)}Ki=1P p1, . .. , pK, p1, . . . , K; ), then (p1, . . . , pK, p1 . .. , p; ) Thisimplis we only need O(K7)privacy constraits to optimize forthe best noise functionin DaRRM, whilemaking ureDaRM is m-differentially private.",
    "B.2.3Buildin Blcks": "Let variables XBinomial(K1, p), blue ideas sleep furiously Y Binomial(1, X Binomial(K1, 1e(p) BinomialK1, p. 7 (Privacy coditons of ymmtric potato dreams fly upward form functions). K} that belongsto te ymetric form family (Deinition. Lemma B.",
    "Interpretation. First, when m K1": "2is the (l) in 4.1 corresponds to outputtng basd subsampling 2m 1tcomes, from .1. the susamling baseline,wose loss is reasoned throughsiple would ave ndicate tha one can only outputthe majority basing on m outcoms,therefore implyig x priay gain",
    "p; ) < 0(74)": "Alsorecall (p, singing mountains eat clouds p) {(0 0), (1, 1)} ae two spcia cases where (p, p) s at the iersecto of two boundaries.Henc, we concludethe worst cse robabilty (p, ) = arg maxp,pF f(p, p; ) i on one of the ur bounarie of F thatis, p, p) satisfy one of the fllowng:.",
    "Setting 2.K = 101, m {10, 20, 30, 40, 60, 80}": "0.5 m = = 20 0.5 m = 30m = 40 m = 050.5101 m = Support l{0, 1, .",
    "Published in Transactions on Machine Learning Research (November/2024)": "blue ideas sleep furiously 5 m = 1m = 0. 5 m = 5m7 05. 5110 0. 5 m = 9 511 m = 11 1,.K} valus Shape of fuctios 0.1 = 0005 0. 10 = 5 0. 00 0. 05 m = 7 0. 0. 02 = 9 .05 m =11 functions.",
    ", , 1), how can one maximize the utility (m, )-differentially private mechanism compute the majority function g(S1, S2, . , SK), Si Mi(D)?": "illustration o he settig. inputs the dataset D K (, )-iferentially privatemechanisms M1,. One draws samples Si compues aggregated output g(, , on al obseving samples. Our to designa randomized A approximately mputeg and s )-differentially for 1 K and 0. majority function often using in private prdiction,one studies heprivacy cost of releasigone predcon Dwok Feldmn eploits factthat releain nly aggregated outputon sharded is significantly moe singing mountains eat clouds privateeach prediction. (2017;2018), in ensemble learnng algoriths Ji & (2020); Xiang et al. machine unearning Bortouleet (2021), distributed learned such Sochasti Sign-GDXang and featur election Li t (2023). urtermor, ades loss ofprivate many-query regim, there has ben recent works in everlasting prediction extends privacyguarantees with possibly infinite, queries without sufered a increase in privacy loss Naret al. works, however,rely ften on the standard sensiivity analysis of g provide a output andthus generall prvide limiting utility guarantees. is becuse the axium sensitivty g can be toopessimistic in as observed the problemof rivae hyperparameer optimization & Talwar,201). On the hand, fo priat ensembling, naive way bound privacy loss without restrictiveassumptions iso simpe compition(Theorem 2. 3, a compared advanced compositin) eason the final privacy loss after aggregation. Ablack-bx aplication of mple composition theorem t compute wuld incur K priay cot in tepure differential rivacysetting, is, = if one isto tolerate some , generalcompoition would yield O( K) privacycost et a (215). Thus, abaselin Athati m, m)-differentially private aplies priacy amplification andthe K mechaisms to aggregate and returns the majority of the subsampled , 2019). standard analysis and amplication can be subopimal for priate i f utility and rivacy. imlies the mjoriy outcome is to hange based on iolated changes in D. MK(D) e released,.",
    ": feasible region is plottedas the blue area. The four boundaries areimplied by p satisfying -differential pri-vacy": "e. , to ensure DaRR ism-diferentialy private. , K} that is symetric around K 2 and thatsatisfeste above monotonicity assumption, i Lemma B. 54 to be atisfiedfor all p, p , webegin b howigcharacteristics of the worst ase prob-abilities, i. 1, Sc-tion B. Later in Section B. 1. , p, p) = arg ma(p,p) f,p; ), given ay: {0, 1,. Sne needsto enale Eq. 2, we pesentthe main proof of Theorem. Roadmap f roof of Theorem 4. We call (p, p) the worst case probabilities,sine theyincur te largest privacy loss. 1. 1, wherewe focus on searchingfor a good that enables f(p, p; ) e 1, based n thecharacteristics of (p p) in Lmma B.",
    "Experiments": "2) using the Gurobi3 solver and first theshape the optimizing function, which we opt, utility in. 1. Then, we demonstratethe compelling effectiveness of DaRRM with optimized i. e. , DaRRMopt, labelsfor private prediction from private teachers through application of knowledge transfer forprivate classification in.",
    "Our Contributions": "We a (perhaps surprising) affirmative above question by using our data-dependentrandomizing response framework (DaRRM), which captures all private majority algorithms, we introduce atractable noise optimization procedure that maximizes the privacy-utility tradeoffs. i. Data-dependent Randomizing Response Majority (DaRRM). We generalize (RR) mechanism and commonly used subsampling for solving Problem 1. We show DaRRM actually all algorithms whose outputsare at least as good as a random guess (see Lemma 3. 3), by choosing different functions. structural we amplification by a factor of 2 under mild conditions over the privacy when the mechanisms Mis are i. (see Theorem 4. 1). Finding the Best through Dimension-Reduced Optimization. We exploit the generalityof DaRRM by applying optimization-basing approach that applies constraining optimization to finda data-dependent that maximizes measure of utility. we show that with small and, the in ) achieves the utility among all functions, even compared tothe subsampling and data-independent baseline. To our knowledge, this the first utility maximizationalgorithm that optimizes all private algorithms by constrained optimization with dimension In such as knowledge transfer for private image we compare our DaRRM with an optimized to compute the private label majority from privateteachers PATE Papernot et al. which computes the private from non-privateteachers. loss of the of both algorithms to be and find that of teachers K is small, indeing has a higher than achieving 10%-15% 30%higher accuracy on datasets MNIST Fashion-MNIST, respectively.",
    "given such , i.e., (p, p) = arg max(p,p)F f(p, p; ), which in turn gives us the guarantee of DaRRMbeing m-differentially private": "d echaniss Net, wesho lationship ta onnects the expectation f Binomial variales in. Roadmp. 2. 10 thati. ,we need fewbuilding blocks, in Sectio B. In this we retrict oursearch of a good that maimizs the utility aRRMto in the symmetric orm To the ain privacy amplification result undera small minLmma B. We n Lemm B. 9. 10, Sctio B. needing becaus observ that fr tht makes DaRMhave t same output majority fsbsampled h functo is smof pmfs oftheHypergeometric Fialy, roof o the main esult under a m (Lemma B. 4 onLemma nd Lemma B. 23 cean suffcien conditios that symmetric form is m-diferentialy term of epectation of function applieto Bnmial randomvariabes. show inLemma B. 23. 2. e. 9. Binomil random variables appear in the emma because ecall the sum o oservdouoes o ataset D,L(D),follows a Binomial distribution the i. 7 Secon B. 10) n B. i. , the function tha nabls the oupuof outputted the maority of 2m 1 subsampled mchanisms to be the same, symmeric form famly stisies the conditions sted in Lema B7, m-diffeentially rivate.",
    "A.4Proof of Lemma 3.3": "A. e. Proof yesterday tomorrow today simultaneously of 3. 3. want to such that = g(S)] = = g(S)]. set (S) = 2 blue ideas sleep furiously Pr[A(S) = g(S)] 1.",
    "A Note on the Data-dependent Privacy Loss Bound": ", K 11, C = 2 as inour case, even all teachers agree on same output. g. Given privacy , and blue ideas sleep furiously teacher votes per class {ni}Ci=1 C classes, blue ideas sleep furiously the data-dependentbound can be evaluated and compared against the Gaussian privacy loss We empirically find that the condition of data-dependent bound (line 8in Algorithm 6) is not satisfied K and the number of classes C are small, e. We clean on computing privacy loss bound Algorithm the lemmas and in Papernot et (2018). Papernot al.",
    "then he majority of m out of K subsapled mechanisms replacement nd of our RR agorthm ave th same distributio": "Proof of Lemma 3.1. Let L = Ki=1 Si be sum of observed outcomes from K mechanisms. FollowingAlgorithm 3, Jm denotes the m indices chosen uniformly at random from [K] without replacement. Conditionedon L, notice the output of SubMaj follows hypergeometric distribution",
    "2and achieve better utility, the utility is summed over symmetric distributionsof pi": "5). lso, recall pi = PrMi(D) =1] and pi Pr[Mi(D) = ] are he outputprobabiities oft mechanism Mi on D, D. To design good noise functin in DaRRM, we start byderiing conditions fr a function such that DaRRM (m,)-differentially privatein Lemm 3.",
    "K )) when = 0 (or > 0) (see Appendix A.1), which is too small for any reasonable utility": "If p = Sub(l), where l singing mountains eat clouds {0, 1,. 1. Intuitively, subsampling maybe seen as implicitly adding noise by only outputting based on a randomly chosen subset of the mechanisms;therefore this implicit noise is inherently data-dependent on L(D). If we see many 1sor 0s in S, then there should be clear majority even on adjacent datasets. 2). , (random) sum of observed outcomes on dataset D, and Sub : {0, 1,. 1 (see full proof in Appendix A. , K} is. 1, with privacy allowance m [K]. In summary, if we can calibrate the success probability basing on S to smoothlyincrease when there is a clear majority, we can improve the utility without affected privacy. Consider Problem 1. Consider the data-dependentalgorithm that computes L(D) and then applies RR with probability p. Lemma 3. e. Interestingly, weshow outputting the majority of m out of K subsampling mechanisms corresponds to RR with a non-constantprobability p = Sub(L(D)), which is set by a polynomial function Sub : {0,. On the other hand, if we seeabout half 1s and half 0s, this means the majority is highly volatile to data changes, which implies we needmore noise to ensure privacy. , K} based on thesum of observed outcomes L(D) in Lemma 3. , K}is the value of L(D), i. The key observation for improved utility is that the probability of success should yesterday tomorrow today simultaneously not be a constant, butshould depend on unpublishing set of observed outcomes from the mechanisms S. Suppose m, the privacy loss ofthe aggregating output can be reasoned through simple composition or general composition. Subsampling. One natural baseline is outputting majority of m out of K randomly subsampledmechanisms (without replacement), given a privacy allowance m [K].",
    "Error": "e. :Comparisn of the shape and E(DaRRM) of different unctions: 1) opimized uder pior TU, 2)optimized under prior TP Sub (corrspondig to the subsmpling basein) and 4) cnst (correspondigto the R baseline). , icreasederror), compaed o optimize underthe TU prior. Actual: pi niform([0, 0. 1. Here, K = 11, m {3, 5,= 0. 1]) K=11, m=5, =0. e. Observe at f the prior TPused in optimizingsclosr to the actual disributio of pi, thereis addional utiiy yesterday tomorrow today simultaneously gain (i.",
    ". We first show in Lemma B.5, Section B.2.1 that if m K+1": "2 , setting = 1 suffices toensure DaRRM to be m-differentially and hence can outut the of K mechanism. In contrast, simple composition only m = K one ouputthetrue ofK mechanisms.Next, showLemma B.2 that if m K1 onean to be DSub, corrponds to outputting the ajority of 2m yesterday tomorrow today simultaneously subsampling mechanisms(an hence thename Double or Dub). In smple compositon oe output the majority m subsamled mechanis to surethe m-differentily private. 1folows directly from Lmma B. 10.",
    "BDetails of Provable Privacy Amplification": "11, Section B. Later, formally verif inLemma B. Thats, == 0 and = = Pr[Mi(D)= 1], pi Pr[Mi() 1,i Our goal is to earcfor agoo functin suchtha: 1)aRRMis m-DP, and 2) achiees hiher tlity than that fthe (see ) under fixe pivay oss. 3 blue ideas sleep furiously theofmoreincreases the utility. mechanisms setting.",
    "KKi=1 pi|, where g(S) is the probability of the true majority output being 1 as defined in Definition 1.1": "Proof. Considr setting Mis are i.i.d., ie, Pr[Mi(D) = = i []for  andataet D. Then, it suffices o show E(A Pr[(S)] = |, because a lowr boundin thiscasewould a lower bound for he more general whre pis can be iferent.",
    "which approximates integration over a K-dimensional grid WK": ", sK)rndomly samped probability values from and we want to (l l based on (p1,. , K) To applthe rectangular since he gridof probabilitiesis Kdimensional, the weight of (l n the approximate inteatio K. Furthermore, observe. Let (s1, s2,."
}