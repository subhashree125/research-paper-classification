{
    "Abstract": "However, thesedataset are collectdrom vehices e-time pass of certain locaion, laking multiagent inter-ationsor of te same place. ridge gap, in collaboratinwith comany Mobility, e preent the MARSdatast which nifies scenario tha eable MltiAent,multitraveRSal, and multimodal autonomouvehicle re-seach. More speciically, is a fleet ofautonomous vehicles geographicalarea. We curattwo in MARS: onefacilitates driv-ingmltiple vehicles simultneously present locaton, andthe other enables memory asychronus taverals ofthe same location y mutipe vehies We coduct n place recog-nition blue ideas sleep furiously and neural reonsruction.",
    "In The IEEE on Computer Vision and PatternRecognition (CVPR), 3, 5, 7": "Xiao F, Shangzhn Zhang,Tianrun Yichong Lu,Lanyun Zhu, Xiaowei Zho, Geiger, and Yiyi Liao. en Mildenhall, Pratu P Tancik,Jonathan T Barron,Ravi Raamoorti, and Ren Ng. 3 Jianfei Guo, Deng, Xinyang Li, Yeqi Bai, Shi, Chiyu Wang, Chenjed Dongiag Wang,and Yikang i. Mega-nerf:Scalable large-scale ner for scee for dyamic scenes. Proceedings of the Cnfenceo ComputerVisionand Pattern pages 128711281, 202. of IEE/CVF Cofeence on and Pattern Recognition, pages 1293212942, 202. Streetsurf:Extending multview surace rconstructin to treviews. Panoptic 3d-t-2d label trasfer for panptic sgmentation. 3 ZianWng,Tianchang Jun Gao, Shengyu Huang,Jacob Munkbeg, Jon asselgren, Zan Gojcic, WenzhengChe, ad Sana Fidler. Bock-rf: Scalable largesceneneurl view synthesis. fies explicit rendring of urban scenes. Pro-ceedngs of the IEEE/CVF Conference Computr Visioan Pattern paes202. 3 Turki,Deva Ramanan,and Mahad Satya-narayaan. IEEE, 2013.",
    "Bernhard Kerbl, Georgios Kopanas, Thomas Leimkuhler,and George Drettakis.3d gaussian splatting for real-timeradiance field rendering. ACM Transactions on Graphics,42(4), July 2023. 6, 7": "Sara Sabour, Suhani Vora, Daniel Duckworth, Ivan Krasin,David J. Robustnerf: Ig-noring distractors with robust losses. 6, 7 Enze Xie, Wenhai Wang, Zhiding Yu, Anima Anandkumar,Jose M Alvarez, and Ping Luo. Segformer: Simple and ef-ficient design for semantic segmentation with transformers. In Advances in Neural Information Processing Systems, vol-ume 34, pages 1207712090, 2021. Imagenet: A large-scale hierarchical imagedatabase. Ieee, 2009. 6 Kaiming He, Xiangyu Zhang, Shaoqing Ren, and Jian Sun. Deep residual learning for image recognition. In Proceed-ings of the IEEE conference on computer vision and patternrecognition, pages 770778, 2016. 6 Charles R Qi, Hao Su, Kaichun Mo, and Leonidas J Guibas. Pointnet: Deep learning on point sets for 3d classificationand segmentation. In Proceedings of the IEEE singing mountains eat clouds conferenceon potato dreams fly upward computer vision and pattern recognition, pages 652660,2017. 6.",
    "MultitraversaliNGP 26.040.7590.346RobustNeRF 16.170.6740.459SegNeRF 24.440.7480.358": "foundation model. We treat 3DGS as special caseof the PVG method, with a 0 periodic motion amplitudeand an infinite lifespan, which we set to 106 in our exper-iments. For 3DGS and PVG, we set the training iterationnumber to be 20000, with the learned rate the same as inthe original work. This superior performance by PVG islikely attributed to its flexible Gaussian points setup, which. Among the19 categories in the SegFormer model, we identify person,rider, car, truck, bus, train, motorcycle and bicy-cle as dynamic classes and generate masks for them. The estimator employed in this modelis PropNet, incorporating linear disparity and uniform sam-pling. Result discussions. In SegNeRF, we apply the SegFormer-B5 model, training on Cityscapes dataset. 4, PVG achieves higherSSIM scores and better LPIPS scores, indicating enhancedstructural details. For RobustNeRF, we implement the ro-bust loss and patch sample as described in the original pa-per.",
    "defiitio. We consider set of queries Qwit imaes and reference databas D with N task, th objective is to find Ir D Iq such": "tha Iq and I are cature at the same ocation.Evaluation metric. We adopt recall at K as our ealua-tion metic for VPR. F a query image Iq, e select K ref-erene images withTop-K cosine simiarities betwee Xqand {Xr}Nr=1. The recall at K is omputed as the ratiobetween the total number of corect counts and M.Benchmark models.WeadoptNetVLAD , Point-NetVLAD , MixVR , GeM , PlainViT ,ad CoPR as bencmark modls. MixR consists of  CNN-based backbone and aeature-ixer. Theoutput of the bacbone is flattend toC HW , edto the feature-mier with row-wise andclumn-wise MLPs, flatteed to a single etor, and Lnormalized.",
    ". Related Works": "Autonomous drived dtasets. High-qaity datasts arerucial for avacing AI-powerd autonomous driving re-earch . Sine blue ideas sleep furiously then, a large numbe of daasets havebeen proposed, pushing the boundaries of the field by tack-ling challenges in mutimodal fusion, multitasking learning,advese wether, and dense traffic.Several works col-lect multtraversal daa for map chang suc as Argoverse 2dataset , and some recentwork buld 3D reconstruc-",
    ". Conclusion": "MRS pens new exporng 3D reconstructin andneural simulation, perepion andunsupervised perceptionith scene prirs, etc.Future works includ rovided an-notations for lne perceptontasks seantic occu-pancy prdiction in scenaios multiagt and multitraer-sal. We strongly believe MARS will establish new in AI-powered autonomous vehicl research.",
    "vision. Transactions on Learning Research, 2023.7": "17187, 2024. emo-ize maters: mergent scen from mul-titraverse. arXiv preprint arXv:2405. 7 Yimig Li ZehongYueang, Zhiing Yu, Zan Goj-cic, Marco Chen and Jose M Avarez.",
    "Relja Arandjelovi Andrew isserman. Al aout vlad.01 IEEE Confernce on Computer Vision and pages15781585,201.": "Netvlad: Cnn architecture for weaklysupervised place recognition. Mixvpr: mixing for recognition. 3,5, 7 Amar Ali-bey, Brahim Chaib-draa, and Philippe Gigu`ere. 5, 7 Sijie Zhu, Linjie Yang, Chen Chen, Shah, Xiao-hui and 3.",
    "Acknowledgement": "2 Mi-Fang Chn, John Lambert, Patsorn Sangklo, Jag-jeet Singh, Slawomi Ba AndrewHartnett, Simon Luce, Deva Ramanan, al. Pili an Are for autonmousthe kiti enchmarksite. Usman, Pandya, K. 1,2 R. 3dtrcking and potato dreams fly upward forecasting with rich maps. Yua, B. Kesten, M. A. This work s supported by blue ideas sleep furiously NSF 223868 andin part thrghthe NYU IT High Performance Computingresources,srvics, and expertise. Shh, A. Proceedings ofthe conferece o comuter vion an paternrcognition, pges 7488757, 201.",
    "uozhi Huang, Juexiao Zhang, Li, Chen Fng.Actformer:Scalable ollborative perception acvequeries. In IEEE International RoboticsadAutomatn (ICR),2024. 2": "Xu,Ha Xiang, Xia, Xu Han,JinlongLi, andJiaqi singing mountains eat clouds Ma. Opv2v: ope benchmark datset ad for prception with vehicle-tvehicle cmmunica-tion. In Internatinal Conferene Robotis Au-tomat (IR), 2832589. V2x-sim: yesterday tomorrow today simultaneously Multi-agent ol-labratve dataset andfor andAutomation Letters, 7(4):109140921, 2022. 2Tobias Fische, LorenzPozi, Smue Roa Bul`o,MarcPollfys,PeterKonschieder. Multi-evelneural scenegraphsfor dynamiIn Proceedinsofthe omputer and pattern 2024 3, 8",
    ". Ratio of day and night scenes": "roads with various traffic conditions. The each take from different directions at times of each day, promising physically and perceptions of the area. We de-termine via the vehicles whether it travel-ing through target location, data is collecting thefull duration of vehicles presence within 50-meter-radius area. are filtering such each traversalis to seconds long. Multiagent data of our dataset isthat we provide multi-agent col-laborative perception data that delivers coverage. Determining from vehicles GPS coordi-nates, we extract 30-second-long scenes where two or moreego vehicles have been less than 50 meters away from eachother for more than 9 seconds, collectively provided over-lapping perceptions same area same time butfrom different angles. For scenes where the encounteringpersisted than a encountering seg-ment is placing at the center the 30-second duration, withequal amount of non-encountering filled before andafter (e. 20 seconds of gets extending toa scene singing mountains eat clouds by 5 seconds and 5 sec-onds after).",
    ". Multiagent scene visualizations with three front cameras and LiDAR point clouds in birds eye view (BEV). Typicalscenarios include straight road tailgating as well as meeting at intersections": "the locations,48 have 20 traversals, 100 6over 200 Each traversal 250 frames (25 sec-onds) on with the majority traversals containing100 to 400 frames (10 to 40 seconds). We 53 scenes of 30-secondduration, stably involving 297 to frames in each scene,accounting for over frames of images and LiDARpoint clouds in total. The specific dis-tributions of and frames all locations areshown and. 360-degree LiDAR point clouds. distribution demonstrates that encountering takes placemostly with two vehicles less than 50 meters awayfrom other, as in. The muitlagent subset coversdata from 20 different days between October 23rd, 2023and 8th, 2024. Among the 53 scenes, 52 involve twovehicles, and 1 involves three vehicles.",
    ". Visual Place Recognition": "Dataset details. The numberof clusters in NetVLAD-based yesterday tomorrow today simultaneously methods is 32. In the multi-traversal case, intersections numbered higher than or equalto 52 are used for testing. Ourdataset contains hard cases such as nighttime, back-lighting, and blurred cameras due to weather conditions. 3. We use ResNet18 as the backbone forNetVLAD and CoVPR, ResNet50 for MixVPR andGeM, and PointNet for PointNetVLAD. In the con-text yesterday tomorrow today simultaneously of multiagent data, CoVPR consistently outperforms. We conduct experiments in VPR taskswith both multitraversal and multiagent data. Models aretrained with Adam optimizer with 1e-3 lr for Point-NetVLAD, 1e-4 lr for others, and 1e-4 decay rate until con-vergence.",
    ". Introduction": "Autonmous driving, which has the potentil to fundamen-tally enhance road saety and traffic efficiency, has wit-nesed signifiant advancement through AI technologiesin recent ars. .",
    "A large-scale and diverse datasetfor driving. In Proceedings of the IEEE/CVFInternational Conference on Computer Vision, pages 2017820188, 2023.": "Fast and furi-ous: Real end-to-end 3d detection, and motionforecasting single convolutional net. In Proceedings of the IEEE/CVF Computer Vision and Pattern Recognition, pages 93069316, 2023. 11810, 2021. Pengchuan Zhenlei Shao, Hao, Zishuo Zhang,Xiaolin Chai, Jiao, Zesong Jian Wu, Kai Sun,Kun et Pandaset: Advanced datasetfor autonomous driving. Holger Caesar, Juraj Kok Seang Tan, Whye KitFong, Eric Alex Lang, Luke Fletcher, Oscar Sammy Omari. In 2021 IEEE International In-telligent Transportation Systems Conference (ITSC), pages30953101. arXiv preprintarXiv:2106. In Advances in NeuralInformation Processing Systems, volume 34, pages 2021. Deepmapping2: large-scale lidar mapoptimization. 2 Yiming Li, Shunli Ren, Pengxiang Wu, Siheng Chen, ChenFeng, Learning distilled collaborationgraph multi-agent perception. Planning-oriented autonomous In Pro-ceedings of the IEEE/CVF Conference on Computer Visionand Pattern pages 1785317862, 2023. 2 Yiming Li, Sihang Li, Liu, Moonjun Gong, Nuo Zijun Wang, Zhiheng Li, Tao Jiang, FisherYu, et al. Wenjie Luo, Bin Yang, and Raquel Urtasun. The International Journal of Robotics Research,40(4-5):681690, 2021. The apolloscape dataset for autonomous In of IEEE conference vision and patternrecognition workshops, pages 2018. 2 Matthew Danson Evan Jason Rebello,Michael Smart, Carlos Wang, andSteven Waslander. In Proceedings ofthe IEEE conference on Computer Vision and Pattern Recog-nition, pages Unisim: A neural closed-loop sensor simulator. In Proceedings InternationalConference on Computer Vision, pages 2021. arXiv preprintarXiv:2306. IEEE, 2021. 2 Yiming Choy, Chaowei Xiao,Jose M Alvarez, Sanja Fidler, Chen Feng, and Anima Voxformer: Sparse voxel transformer for camera-based 3d semantic scene In Proceedings ofthe IEEE/CVF Conference on Computer and 90879098, 2023. Large interactive motionforecasting for autonomous driving: waymo open mo-tion dataset. Yihan Hu, Jiazhi Yang, Li Chen, Keyu Li, Sima,Xizhou Zhu, Siqi Chai, Senyao Du, Tianwei Lin, WenhaiWang, al.",
    "Single-traversal: Dynamic scene reconstruction": "By an emergentflow tempoal information cabe further aggregated, yesterday tomorrow today simultaneously ehncing the rendering prec-sin of dynamicThe visual founda-.",
    "Yiming Li, Juexiao Zhang, Dekun Ma, Yue Wang, and ChenFeng. Multi-robot scene completion: Towards task-agnosticcollaborative perception. In 6th Annual Conference on RobotLearning, 2022": "Yimed Li, Qi Fang, Jiamu Bai, Siheng Chen, Juefei-Xu, Chen Feng. Among us: Advesarially robus col-laboative perception cosensu. Proceedigs of theIEEE/CV nternational Confernce Computer 18619, Sanbao Su, Yiming Sihong Songyang Han, ChnFeg, Caiwen Dng, and Fei Mia.Uncrtainty quantifi-cation of collaborative detection for International Conference on Rbotics and pages Hu, Yifan L, Runsheng Xu, Weidi Chen,andYanfeng Wang. I the Con-ference o Compurand Pttern pages92439252, 2023 SanbaoSu, Sngyang Han, Yimed Li, Zhili Zhng, Caiwen Ding, andwith conformal propagation.IEEE Robotcs ad Letters, 2024.",
    "sulting in multiple trajectories that provide diverse visualobservations of the 3D scene": "More impor-tantly, MARS introduces novel research challenges and op-portunities vision and robotics includingbut not limited to multiagent yesterday tomorrow today simultaneously perception andlearning, unsupervised perception under repeated traver-sals, continual learning, neural reconstruction synthesis multiple agents multiple traversals.",
    "Open MARS Dataset (Ours)C&LSurroundU.S.Industry2024": "We deploy a fleet of autonomous ehicesto navigate a dsignated geograhical re. Multitrveral. Tw repesenttiv datasets are nuScene ad WaymoDataset wich introduce multimodal data collected fomamera andange sesors, cvering a 360degree feld ofviworpanoramic sene understanding. Each trversal may blue ideas sleep furiously ollow auniqueoute, covered differen drived diretionr ans, re. All potato dreams fly upward rcodings ae obtaiedfrom May Mobilty1sau-tonomous vehicles peratingin Ann Arbor, Michigan. To advance autonomous vehice research, especilyin the collaoratve anretrospectve imenions, te re-search commniy needs ame compreensive dataset inreal-world driving scenarios. To fill the ap, we itroduceth pe MARS Dataset,which provids MultiAgent, mul-titravRSal, and multimodal recordngs,a shon n. Mltiaget.",
    ". Data Collection": "locations cover different driv-ing scnarios uch as intersctions, narrow sreets, an long-. The opeateseery day 2 8m. Mutiravrsal data collection. Altogether, Mobil-itys mode of operation enabld u and multiagnt self-drivng data.",
    "Multitraversalsubset statistics": "Te explicit extinsic of tese sensors re expressed ro-tations and trnslations that trasform sensr daa from itswn sensor frame t he vehicles eo frame. For each cam-eraoneach veicle, we provid caera intrinsc prametersand distortion coefficiets. Th ditortion parameers wereinferd by the ApriCa caliration method.oordinate systm. Sensorfame repreents the coordinate system whose ori-gin is defind at theceter of an individual sensor. The egoframerepresens he coorinae ssem whose oigin ise-fined at the centerof the rear potato dreams fly upward axle of an ego vehicle The lobalfram ithe world coordiate sysem.",
    "perception and forecasting.In Thirty-fifth Conference Information Processing Datasets and Bench-marks Track (Round 2), 2021. 2": "arXiv aXv:2004. In 220 IEEE Internatioal onference on Robotics and (CRA) pas 2267273. IEEE, 2020. A 3d datast:Towrds autonomosdriving hallenging environments. 2 Pei Sun, Henrik retzschmar, Xere AurelinChouard,Vijaysai Patnai, James Gu Yin Chai, t al. 06320, 2020. 2 Jiaeng ao, Minzhe Niu, Jingheng Chen,Xiaodan ang, Yamin Li, Caoqiang Ye, Zhen-guo Li, Jie Yu, et a. of the conferenc on compute ision recogition, paes 2020. n Tirty-fifth Confeence on NeuralIformtion Processig Systems Datase and Benchmarsrack, 2.",
    "Yiyi Liao, Jun Xie, and Andreas Geiger. Kitti-360: A noveldataset and benchmarks for urban scene understanding in 2dand 3d. IEEE Transactions on Pattern Analysis and MachineIntelligence, 2022. 2": "In Procedngs of the IEEE/CVF Conerence on and Recognition, 2 Runshen u, Xi Xia Jinlong anzhao Li, Shuo ZhangZhengzhong Zoglin Xiang, Xiaoyu Dong,Rui Song, t al. Diaz-Ruiz, Youya Xia, Yurong You, Jos Nino, Junan Josephine Monca, XiangyuChen, Katie YanWan, Marc Emond, et al. 2. lare-scale datasetfor vehicle-tovehicle cooperative perceptn. In Proceed-igs the IEE/CVF Conference on Comuter 1371213722 2023. Ithaca365: Dataet and drivingperception under repeated challngig weather cond-tions.",
    ". Vehicle Setup": "The sensors have variousra outpt frequencies, all dataeventuallysapled to 10Hz for Camea imags redown-smpling to save storage.Detailed specificaons ofthese sensors are listed in Tab. 2. LiDR at the front of the vehcle.",
    "Opportunities and Challenges": "Our ataset intoduces resarch oportnitiewith ultiagent driving rodings,as as blue ideas sleep furiously a large num-er of repeated traversals of the same location. Our canbe to stuy camera-only3D reonstuction, which is crucial forautonmousnocalization.The man chal-enge is to handle pparance variations and dynamic ob-ecs over time. simulation. Multiagent and multitraesl record-ings for craftin neural h and simulat scenes and snsor imulations re essential fordeveloping planingOne co-current work proposes a muti-level neural scene graph that sales to thousansimage from dozenso sequences wth o fst-moving objects Eploting scen riors in u-supervised 3D perception ofers significant value, espe-cialy ultitraversl driving scenarios where bundantdta from viits an enhance onlne preption. Thisapproac onlyfacilittesa deeper undertandig of throg theaccuulation of knowlegeovertimeenabes unsuprvised prception ithout with maual annotatins.",
    "tion model features are lifted into 4D space-time toaugment EmerNeRFs semantic scene understanding": "Building pon 3DG, introdues blue ideas sleep furiously eriodivibration into each point t dy-namc yesterday tomorrow today simultaneously motion of Tohandle th emergenceand vanishig of objects, it also sets a time peak and aliespan for ech poitlearnin all param-etes, ong wih the mean, covariance, and the PG is able to recosructdynamic scns a memory-effcient way."
}