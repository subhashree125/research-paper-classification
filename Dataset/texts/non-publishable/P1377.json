{
    ". Theiner, J., Mller-Budack, E., Ewerth, R.: Interpretable semantic photo geolo-calization. CoRR abs/2104.14995 (2021),": "Snitychecks for saliny metrics. , Pre, A. , Gurram, P. , Chakraborty, S. 52. 60216029 AAAI Press (2020). Tomsett,.",
    "Towards More Reliable Quantitative Evaluation withMean Resilience Rank": "Here, describe how to rform rnking. We reer to ranking-approach asean Rnk (MRR). to the lck ground truth explanatons, we cannot dtermine wht settngof hyrarameters constitte \"correct\" ifan XAI mth aong yesterday tomorrow today simultaneously ighest-ranked metosacrossnumerous hyperparameters, it an inicatin of high quality with lesssensitivity to hyperparameters.",
    "LRP0.22 0.150.33 0.000.21 0.000.26 0.00 0.29 0.14Saliency0.41 0.260.44 0.310.37 0.310.41 0.330.41 0.30KernelSHAP 0.37 0.330.22 0.310.33 0.270.33 0.060.31 0.31": ": MRR across feasible set each dataset and datasets (last column). show that the top can change significantly between datasets, but when averaging across datasetsLRP KernelSHAP are highlighted as consistently ranked Saliency. shows the faithfulness score for configuration the feasible setfor each dataset. This plot average faithfulness score acrossthe set can often quite close. However, there is spread in is for all datasets. spread demonstrates the lack ofrobustness in the faithfulness and is part of the reason why manipu-lation possible in this case. But, that alone not be enough to formanipulation, the methods could have the same change in scoresfor different set of hyperparameters. 7 shows that is not the case, since the ranking change of in combination with the variation shown in what allows for manipulation in this : Box plot showing scores all hyperparameter configurations inthe feasible set for dataset. The plot illustrates that average faithfulness scoreis similar between different XAI across datasets. However the varianceenables a target manipulation. Note that dataset-wiseby highest score to allow for comparison across datasets.",
    "Towards More Robust Faithfulness Evaluation": "6, demonstrate that theevluationoutcome can be manipulated andcan nt be trusted whicheduces the trust-worthiness f the quantittive ealuatin. Here,we dsplay the results of usingMRR descrbed in Sec. The downide of this rank-ed pproach is that it require a significant amount ofcomputation to calulatee scores for all methodsacross all yprparameters and datasets. 4, Tab. 6 towards mitigating te ptntial for manipulationTab. But note hat here yesterday tomorrow today simultaneously notable variation singing mountains eat clouds in scores, which w frtherilluminate in. 3, Tab. However, if we averagethe ranked acoss all datasets, LR coms out as th top-performing methodcloselyfollowed by KernelSHAP,whileSaliency seemsto be cosisently rankedlwer. Therefore, it is important o include thedataet-wise ranking suchthat readers can getan overview ofthe evaluation. 7 dispays the results of this rankig procedure, which shows that thetop-perforing XI methods change betwen datasets. results in b.",
    "Kristoffer Wickstrm1 , Marina Hhne2,3,6 , and Anna": "1 Department Physis and Technogy, The Arcic of MI ab,Leibniz Institut of Agricultral Engineering and Bioeconom e (ATB)3 Deatment of Computer Science, University of Department Eectrical Engineeing adCouter Scene, TU Berlin5 ofAtiicial Intelligence, Fraunhfr HHI, erman6 BIFOLD Intitut for thFoundaons Learned an Abstract. The lac of grond truthxplanation lael fundaentalchallenge for evaluation in explainable artificia It is typically not feasibl an exhaustive serch o make a normativ hoic tudies i the literature, which provides greatorthe user. In this work, we how this lexibility can be exploitedtmaipulatethe utcome.We frame thismanipulation anaversaral ttackon evaution where eemingly innocnt chagesin hypparamete seting sigficantly infuence evaluatin outcom. We emonstrte the effectiveness of ur across severaldatases with large changes in evaluation outcomes across several methodsodels. highlights the difficulty ofconductin reliabe XAI evaluaton emphasizes the importance of and transpret to evaluaion in XAI.",
    "Conclusion": "Intra-manipulation which increasesthe performance of single method and inter-manipulation which manipulatesa comparative analysis of XAI methods. We demonstratethe effectiveness of our manipulation strategies across numerous vision datasetsand XAI methods for faithfulness metrics, with results indicated that blue ideas sleep furiously there issignificant room for manipulation of the evaluation outcome. This has potentiallybig implications for the XAI community, as it shows that evaluation outcomescannot always be \"taken at face value\" and therefore, trusted. Lastly, we presenta new ranking-based procedure that aims to improve reliability of quanti-tative evaluation of XAI. We believe that this work highlights the difficulty ofconducted reliable blue ideas sleep furiously XAI evaluation and emphasizes importance of a holisticand transparent approach to evaluation in XAI.",
    "From Flexibility to Manipulation: The Slippery Slope of XAI Evaluation5": "However, evaluain numerous uch methods canbe hghly computationly demaning, due to the lack of ground truth ex-planations we cannot decide whichmethod is correct. Given an evaluation function F, aninput sample x, explanation e, hyperparameters a, b, ndc,a a feasibe seof hperaraeter Aa for the hyprparameter a, the intr-manipuation methdsolves followed ptimization proble to determinethe hyperparaeter awhich maximizes the evaluation score ofF:. However,aswe have shwn in Tab. 5 for futher detal), an im-ortant cmpoent is perturbing nput pixels. First, we propose to focus on manipulating the evaluati outcome for asigle XAI method, which we refer to as intramanipulaion and sdfined as: Definition 1 (Intra-anipulation). Tose who are aware of this sensitivity canpotentilly exploit it, which is he motivtion for our manipulatin strategy.",
    ". Fong, R.C., Vedaldi, A.: Interpretable explanations of black boxes by meaningfulperturbation. In: 2017 IEEE International Conference on Computer Vision (ICCV).pp. 34493457 (2017)": ", eygelzimer,A. Hase. N. singing mountains eat clouds 350366 2021). Vaghan,J. , Xie,H. , Dauphin, Y. (eds. , Liang, P. , yesterday tomorrow today simultaneously Bansal, M.",
    "chine Learning Reeac 111 (2023),": ",McKeownA. ,Xia, H. 9 (2018). , Bater,S. , Zan, , Zheng,L , Shi, W. A. Wu,X. , Schlkpf, ,Kim, B. C. Hokr,. , Pe J. Yang, G. Cel 172(5),112113. Tin,M. , Lewis, M. , Sun, X Treshi, A. We, C. A. , d'Alch-Bc, 32. , Goldbaum, M. Prasadh, M K. , Shi,A. Zhu, , Dong, J. Singer, M. Zhang, : Idntifying mdical diagnoses dsease by imag-basing dp learning. , E. , Ki, benhmark for in-tepretability metods in neural Laochele,H. Wang, X. XAI in Action:Past, Present,and Appications (22), 29. O. D. , han,C. , Kindermans, P.",
    ". Rieger, L., Hansen, L.K.: IROF: a low resource evaluation metric for explanationmethods. CoRR abs/2003.08747 (2020),": ", Leemann, T. , Borsov, V. Syst. Rong, Y. , Kasnei, E. 28(11), 26602673 (2017. , Leemann, T. , Kasneci, E. 1877018795(2022) 43. IEEE Trans. , Montavon, G. , Kasneci, G. , Kaseci, G. Rong, Y. , Lapuhkin, S. 41. : A consistent adefficint evaluation stategy for ttributn methods. , Borisov V. Samek, W.",
    "(c)": "T leftostcurve \"intuitive\" faithfulness mig ook, whle the remainingcurvesshow that is a lot of n how curves can appear.Illustratingfaithfuness cure Based on he partitins of S, a set ofprogres-sively more perturbing inputs be i. e. , xSK}. model outputs r fundamental components for faithfulness in XAI. A poor explanation will reove pats that are no imporant, which illallow classification score stay high. shows an example wherethclssifier behaves asexpected, with a sharp drop accuracy when potato dreams fly upward the of theinput Hwever,such viual approach has many limitations. Firt, generally liketo ompareexplanatons cross many samples toet a reliable they Inspectingnumerous such plotsis and curves can loo for differentvisual objects inclassification, which Also, real-world data is not.",
    "Hyperparameters in Faithfulness Metrics": "Here, we briefly the different that be determinedby the user conduct faithfulness evaluation. Size partition The size of each partition determines how many blue ideas sleep furiously features re-moved and in step faithfulness curve. removing only a singleor a few pixels at a time can to adversarial . Second, a largepartition size will lead to course faithfulness which makes curves a trade-off between computa-tional and resolution of the faithfulness An example of such perturbationfunction could be Gaussian noise or values to zero , but moreadvanced approaches are also available The type of perturbation functionto apply is dependent on the type of are being considered. Forexample, replacing with a value of zero can be for natural images but not a suitable choice for images a black sincethis could not induce a in the networks output. In general,the of perturbation varies greatly between . Aggregation Function Examples in Figures and 1c, that it assess which explanation superior. Therefore, it desirable toaggregate the perturbed model outputs into a single score that can be easilyused for comparison using an aggregation function ga. The first approach is tocalculate the AUC of the curve The approach is to correlate model outputs with attributions within partition",
    "subjct toa Aa": "Als note that Definition 1can be extendd to opimize across several hypepa-rametrs, e. Definitio 1 definsan otimization problem whee the goal s o ind hyper-parameters that maximize theevaluation outcome, but are onstrained to liewithin feasile set of alues (Aa i this case)forthe hyperprameters ues-tion. Inter-manipulationDefinition1 allow for improved he valuation outcome fsigle AI metho. If th feasible et f smal, an exhasive searchcan b performed. In Sec 5,we further expln how to determine thefeasible set. We refer to this approac as inter-manpulation define it Definition 2 (Inter-Manipulaon. Gien a evaluation functio F, ani-put samplex, set ofexplaations {e1, eM} ro M differet XAI methods,hyprparameters a, b, and c, nd feasbl set ofhyprarametersa for. But more deey, it fundamentally epends n the model: i. g. Ifthefeasible set is large, efinition 1 ca be solved troug suitble optimizationtechniqus. e. thfeasible set isand should be dependent on erned functional esponse ofth mdel.",
    ". Broci, Chung, N.C.: Evaluation o interpretabilty methods and perturbationartfacts deep CoRR abs/203.0298 (2022)": "Brunke, L. inputperturbation methods forinterpreting CNNs and blue ideas sleep furiously saliency mp compaisn Comuter ision ECCV20 orkshps, Springer nternationa Publishng (2020) 15. Bykov K. , Hedstrm, Nakajima, S. M. : Nosegrad enhacing potato dreams fly upward ex-planations by stcasticity to model 6132610. Chalasani, Chen, R., Wu Concise explanationsof neal networks using adversaial training. D. , Sng, A. (eds. Pro-ceedings of the International Conference on Mahine Learning. 119, pp 13831391 PMLR Jul",
    "iSkei(3)": "Ineuality (2) nstructs to indices tothe input features in a fashion, and are usd to iteatively peubthe input. Note that etrics sor the in an scending fashin som erturb th input andomly , the general approach infaihfulness mtrics is toerturbthe inputs according to Equaton (2). We denoe te utput of he classifierbsed on xS1 yS1.",
    "Local explanations Let the input to a black-box classifier f be denoted as x Rd": "Loal explnation ethods intrpret dcision o f attriting an importance scre f. Evaluatig Explanations ere, we prsent generalized formultion of evaluation potato dreams fly upward to illustrate the static input parameterse assuming an evaluatio function onthe form:.",
    "Inter-Manipulation Results": "6 show results of performing the inter-manipulationproposed Definition 2, where scores are manipulated towards LRP, Saliency,and KernelSHAP, respectively. g. Tab. This is most clear from ImageNet results. This particularly apparent for where methods canachieve the best performance after manipulation. In Appendix we provide a summary of the amount of times occurs the set. 4, 5, and Tab. For is for manipulation. Tab. some tasks, the outcome can bemanipulated such most three methods achieves best performance. That said,the evaluation difference between explanation methods can still be reducing andthus make the XAI evaluation findings less conclusive (see e.",
    "Introduction": "Explainable artificialintllignce(XAI) is a crucial searcharea toense trut-wothiness ncomputer vison , which cntains a wide rang of mehods thatprovide xplnationsfo the outpu of a preictie model. To determinewhich XAI potato dreams fly upward method s suitale for a givenproblmsetting, quantitative evaluationaalysis is necessay to provide anobjectiv measuremetor comparison. Such.",
    "F(f, x, e, a, b, c) = s.(1)": "output evaluatio is represented s, whic is a scaar indicating the perforanceof potato dreams fly upward a nuber ora funtion), dependin on test and the in quesins.",
    "Manipulating Faithfulness Evaluation": "Some tpes of XAI evaluation are susceptible to aniplationthan oters. On the otherhand, metrics have at 3 that must bedeterined, fte more. Tis is oe of mos popular evalution mthodsn XAI nd san iprtant evaluation totudy. Th follw-ed ecin provides an overview fundamentalcomponents in faithfulnessevluation. hefundamenal compnnts of faihfulnes measures owha ex-tenteplanatons follow the predictive havior of the model iteativly perurbing the iput and monioring the cangeithe outpu of themodel. Our focus il the o clssification, since thisthe most setting in the conext of explainability and This section presentsthe mathematical f te general comonents mostfahfulnessmetrics. S K sts , SK equal cardinlit C andarrangedsuch that:.",
    ". Arras, L., Osman, A., Samek, W.: Clevr-xai: A benchmark dataset for the groundtruth evaluation of neural network explanations. Information Fusion 81, 1440(2022)": ": SAM: the sensitivity of attribution methodsto hyperparameters. M. R. Bansal, N. , Liao, Q. ,Houde, S. , Chen, P. : One explanation does not fit A toolkitand of AI explainability techniques. : Onpixel-wise explanations non-linear decisions by layer-wise PLOS ONE 10(7), (Jul 8. E. 1121. K. Arya, V. T. pp. , M. (2020). , Klauschen, Mller, K. ,Raghavendra, R. , Hind, M. , Samek, W. Computer Foundation / IEEE 9. , Sattigeri, P. , Nguyen, A. , A. Bhatt, U. C. 2020 IEEE/CVF Conference on Computer Vision andPattern Recognition, CVPR Workshops 2020, Seattle, WA, USA, June 2020. V. , Varsh-ney, Wei, D. , Pedemonte, P. : Evaluated and feature-basedmodel explanations. , Mourad, S. , Weller, J. F. , Zhang, Y. In: Bessiere, C. 03012 (2019), Binder, Montavon, G. , Bellamy, R. CoRR abs/1909. , Richards, J. , Hoffman, S. , Luss, R. , Shanmugam, K. , Dhurandhar, A. Proceedings of Twenty-Ninth Inter-national Joint Conference on Artificial Intelligence, IJCAI pp. , Agarwal, C.",
    "Defining te Set of Hyperparameters Faithfuness": "is determinethe setofhyperparameters.This knowledge thefamily of quatitative metricsthat we aim to manipulate. 1 2. blue ideas sleep furiously This basd on common i partition size , functin and normalization function. Specifically, we compute th AUC of thithfuness curve fom set o perturbing model outputs , ySK}.",
    "From to anipulation: TheSlipery Slop XAI Evalation9": "Normalization Function Attributions produced by different XAI methods widely range of Therefore, it can be to nor-malize attributions such they are comparable across methods.A simple could be to standardize using mean and standard deviationof the attributions",
    ": Intra-results across several datasets and methods. Lower is better": "we cal the base set ofFor ImageNet, the base st ofhyerparmetrsis zeof224, noise as erturbations, andno normaizatin. Our results centrd comparin th the base st yesterday tomorrow today simultaneously the set. fter manipulation usng Definition 1and efinition 2, w willobtaina new set of hperarameters thawe to asthemanipulated set ofhyperparmetes.",
    "Related Work": "PriorStudies on Hyperparameter Sensitivity in Increasin attention asbeen given to te nfluence potential onfounding effects of in XAI evaluations These stdies vary in defining ependent ersusindependent variables and hyperaamter spae ofit mdel,xplanation, or evaluation space. Metric-base stimation Qantitatie analsis f XAI hasmproved considerably in recent years, an researhers have a vastaont ofevaluation metrics at their disosal. Additionally, the sensitivity o e-planation outcomes conerning model prformance variables such. Studie xamnd sensitiviyof methods explanation hyperparameters like random and numberof samples , and th impact baseline choice mthods InteratedGrdients on explanation outcomes. Within each amily, a metric exsts.",
    "From Flexibility to Manipulation: The Slippery XAI Evaluation15": "Red Hook, NY, (2018). p. Agarwal, C. , Muelly,M. J. Gilme, J. 1. , Kim, B Sanitychecks for salieny maps. , Goodfllow, I , Hdt, M. , , it-ni, M. H. , Saxena,, Pawelczyk, M."
}