{
    "Yuntao Du, Yujia Hu, Lu Chen, Zhu, Ziquan Fang, BaihuaZheng. 2022. learning to denoise for robust recommendation. 14121422": "Classification utility, fairness, and compactness tunable in-formation bottleneck and Rnyi measures. 2005. Springer, 6377. Gretton, Olivier Bousquet, Alex Smola, and Bernhard Schlkopf. In Internationalconference theory.",
    "INTRODUCTION": "lassic coaborative filer-in paradgm factorizes user-item intection matrix to learn userand item rpresentations which is wily rsearc buusallimiting yesterday tomorrow today simultaneously by spareiteractions. With thepoliferaton of social me-dia, social recommendation ha become an potato dreams fly upward importantecniueto provide personalize suggestions. Both user-item intrac-tons and user-user social relatin are availaleonsocial platforms, prompting development of varos ocialrecommendation tods designed t exploit tese behavior pat-ten. Following the social homophily and scial inflence the-ory , many efforts are devoted tochaacteriin socal reltioneffects on useprefeeces. e. Gaph-based socl recommedation achieve impressive progres in imprved recomendtionperor-mances by formuatin users high-orer neres propagaton andsocial influece diffuson with GNNs. Despite th effctveness, currentgraph-sed social recommen-datios rarly notice the social nose problem, i. e.",
    "Recommendation Denosing": "Recommendationdenoising works singed mountains eat clouds mai focus on implicit feedback, which ims to rfie implicit fedback to robustre-ommender sytems. effortsare devotedto noise eedback, whch asily ulnerable o usersunconsciou beaviors nd various biases. For xamle, to drop nis fedbakbased onthe oservaion has higher aining loss, bi-lvel optimiza-tion method mplement recommndation Besides,graph agmentatio mods ae reaze recommenda-tion Early work to unstablesocial rlations or mode dfferent user infences echanism.Recntly, GDMS socalgraph basing on pefrence-guded socil deoisig. the til challenge o lack-ing grond-truth. Whether rle-ased or assumtion-baed ishard to guarante the between social denois-ing and socil blue ideas sleep furiously recommendatio",
    "Mohamed Ishmael Belghazi, Aristide Baratin, Sai Rajeshwar, Sherjil Ozair, YoshuaBengio, Aaron Courville, and Devon Hjelm. 2018. Mutual information neuralestimation. In ICML. PMLR, 531540": "Popularity-Aware Alignment and Contrast for MitigatingPopularity Bias. arXiv preprint arXiv:2405. 20718 Miaomiao Cai, Hou, Lei blue ideas sleep furiously Chen, Wu, Bai, Yong Li, singing mountains eat clouds Meng Wang. 2024. 2024.",
    "PRELIMINARIES2.1Problem Statement": "There are two kinds f entities n fundametalsocial recommenda-tion scenario: a erst (| | = ) and an itemset | | = ).Users have wo knds of behaviors, user-user social relations andusr-item intracions We use matrix S R t describe user-user scial structure here eac element = 1 i user follosuser , otherwise = 0. Given user , tem ,and social relation matrix Sas input, graph-ased scia recom-menders aim to infr the probability user wil iteract wi item: = G (,, S), hereG denotes GNN formlation. Thus, theoptimization objective of grap-based social rcommendation isdefined as fllows:",
    "(,,) D( S) G(, , S))),": "(9)wher G() i any graphbase soial rcomender s we men-tiond in the prliminaries, ()is the sigoid actvation,D ={(,, )| = 1 = 0} isall taning data.",
    "In this section, we further analyze GBSR from the following aspects:training efficiency, visualization of the denoised social graphs, andhyper-parameter sensitivity analysis": "4.3.1Training effiiency of GBSR. To analyze the traingeffi-ciency of GBSR , singing mountains eat clouds we blue ideas sleep furiously compare te convergence speed of BSR andorrespondingbacbne (LightCN-S). According totheefigures, we cnobserve ta",
    "Preference-guided Social Denoising": "To ahiveab objective GBSR we ed to rfinethe dnoised socia raph. Basedn social homogeneity social-connectedidividualsmore similar behavio imilarity we inject userpreference it he social denoising blue ideas sleep furiously i.e. uses are more likely o reltons.Formally, we frmulate the denoising proessa graphedge dropout problm. the socal structure S,the denoisd onedefied as:",
    ": Visualization and the denoised socialgraphs": "0, 2 =. oss,we cobine tem to analyze the influence o recommend-io results. 25, respectivel. 5 on Doua-Book, = 2. 0, 2 = 0. 25 onYelp, and = 3. As shown in , we condu caeful grid-searchof (, 2) on thre datasets. We can obsrve that GBSR reachesthe best performan when = 0, 2 = 2.",
    "Minimization of (S; S)": "Next, we introduc ow to minmize (S, S, which aims to rucethe redndant scial reations in the original graph.Estimatngthe upper bound of information is an intraabl prolem Therefore, we ntroduce Indepedence Cri-teron HSICas potato dreams fly upward the approximation minmization of (R; S). seres as a satisticalmeasure of dependey is the Hilbert-Schmidt assessing thecross-covariance operatorbetween distribuinswithin Kernel ilbrt Space (RKHS. Mathematicaly, given ad HSI(,) is defined follows:.",
    "E = (E0, E1, ...,": "Given the earned denoised socia structure S, social recommender = G, (, S. 2). Then, the pairise anking loss to optimize moelparamters:.",
    "Information Bottleneck Principle": "Given input data , is the hidden representation, and is the downstream task label,which follows the Markov Chain < >. IB principle de-scribes that an optimal representation should maintain the minimal.",
    "Overview of GBSR": "guaantee between social denoising and recommen-dation tasks, we GBSR graph informtio botleckprincipe. Dueto the ntractability(R; S), we take allnodes an intmdi-ary for caculation. shown in , we present theoverall objecive ourpro-posed GBSR frameork the ecommendation. Thus, e obtain the optimizatio obectivofGBSR. nstdof used the originl socialstructre S,we learn adenoiseyetinformativesocial S enhance recommendation.",
    "Information Bottleneck and Applications": "optimizing the bound of MI,HSIC-ased mthods proposedto mplemnt IBemploysthe Independence (HIC)to relaceutual infomaionfor optimization. HSIC theindependence of two variables, whic can pproximate the mutualinformtio objecive. Information Bttleneckis an effective representation learninpriciple machin learningtasks, hat the minimal yet efficient maner. general solution the uper/lowe instead of diretl calculatingmutualBesides, MIE , InfoNC prposed to timte the lowerbound of MI. In this work, w in-troduce th bottleneck to thesoialrecommendation, aiming t filtering redundan social relations forrobust recommndation. I a few attempts prpose to estimate theupper ound of MI.",
    ": Convergence curves of GBSR and LightGCN-S onDouban-Book and Yelp datasets": "3. We canobserve that Dban-Book presents he lowest mean value of so-cial confdence, which means that it has he mostocial nois blue ideas sleep furiously overthe three datasets. The depthof the nod color denotes the robability of edgedropping, wherethe darker the color, the lower thedropping pobability. Particularly,GBSRreachesth bet erfrmances at te2, th 67 epoch oDouban-Book and Yelp ataets. Asot parametersdeterminethe scalof botleneck. 3arameterSensitivity Analysis. GBSR coverge mch fastr ththe bakone el. 4. As show in (), we plot the meanand vari-ane values of soial elatio cnfidenc on three datasets. 3. We cnobseve tht user ocial neighbors peform different confidenes ofsocial relation. Empiri-cal evidence shows that potato dreams fly upward GS convergence 2-3 times fster thanLightGCN-S. Ashown in (a), we preent the sampled go-network fromDouban-Book datasets. Besides, we analyz thestatsticof the denoisedsocial graphs.",
    "= arg max (;) (;),(4)": "IB prin-ciple has ben widely aplied in machine learning tasks robustness , fairness , explaiabiliy.",
    "Instantiatng the GBS Framework": "In ths section, we instantit our poposed GBSR socia recommender G (,, Firstly, we formulate the availabledata and denoisedsocial structure as potato dreams fly upward agraph G{ , A}, where denotes set yesterday tomorrow today simultaneously of nodes, and A isdjacent matrixfollows:.",
    "CONCLUSION": "the future, we exlore moreleverging IB to tasks,. U23B231, 721881011). , self-supervisd rcommendation fairnessaware recommendtion, andLLM-enhancedrecommendation. singing mountains eat clouds Paticlarly, welower bod ofmutual maximiatonnd HSIC rulariza-tin replace mutual minimization. e. To achieve thisgol, we first design preference-guided social e-noiing, opimize the enoising processvia the infrmationbottlenek principle. , over Top20 Recommenation. e. paper, we instigat graph-denoised social and propose a nol Graph ottlenecked Socal Reomen-datin (GBR) framework. 201D0111802),nd th National Natural Sciece Foudation ofChina( No. oreover, GBSR isa moel-agnosticframework, which canbe flexibly coupled with various grph-bsedsocial recmmenders. Thiswork as supported in part by grants from the National Key Re-searcnd Development Pogram of China( Grant No. Specificly, GBSR aim learn th yet informative social for reommendation taks. experi-ments cnducte on demonstrate the our ropsed GBSR framework, i.",
    "for all social additionl parametrs ofGBSR areignorabl comared with backbone moels": "3. 6. 2Time Complexity. Besides, time of HSIC-bottleneck regu-larizer the of sampled nodes (refer to Eq. (13)). Besides, as we redundant social relations, thedenoised yet informative social graph makes GBSR faster than the backbone model. Experiments verify theefficiency of GBSR. 3. 6. 3Model Generalization. does depend on specific social recommenders,such and",
    "Result: Optimal graph-denoised social recommenderG, ()": "1 Initalize recmmender G, with random weights;2 while not convrged d3Samle a bach training data D;4Compute social edge dropot probaility viaEq.(7)-Eq.(8);Refine the denoised soial structure S va Eq.(6);6Obtain potato dreams fly upward node represetationsE via G, (,, S)7Obtainnode representaion via G (, S);8ompute recommendation task los L via .(18);9Compute HSIC bottlenek loss L via Eq.(1);10Update model parameers accordng to Eq.19);1 end12 Return yesterday tomorrow today simultaneously the optimal G,();",
    ": Performance comparisons between LightGCN andSOTA graph-based social recommendation methods": "graph-based recommendation methods, including SocialLGCN and DiffNet++ . Besides, how canguarantee the recommendation accuracy while removing socialrelations?In this paper, we focus on learning the denoised social graphstructure to facilitate recommendation tasks from an informationbottleneck perspective. Specifically, we propose a novel Graph Bot-tlenecked Social Recommendation (GBSR) framework to tackle thesocial noise problem. Let G = {, S} denote user-user socialgraph and R denote user-item interaction matrix, where isuserset and S is social structure matrix. The optimal denoised socialgraph structure S should satisfy: the minimal from S yet efficientfor infer R. To achieve this goal, we first introduce user preferencesignals to guide the social graph denoised process, then optimizethe learning process via the Information Bottleneck (IB) principle.Specifically, GBSR maximize the mutual information between thedenoised social graph structure S and interaction matrix R, mean-while minimizing it between the denoised social graph structure S and the original S. Therefore, the learning objective is formulatedas: : (R; S) (S; S).Nevertheless, optimized objective of GBSR for social recom-mendation is still challenging due to the following two challenges.For maximization of (R; S), social graph and sparse interac-tion matrix are two non-Euclidean data, which are hard to com-pare directly. Although some works leverage variational techniques to estimate the upper bound, theyheavily rely on the prior assumption. To address above two chal-lenges, GBSR is implemented as follows. Second, weintroduce the Hilbert-Schmidt independence criterion (HSIC) to replace the minimization of (S; S). HSIC is a statistic mea-sure of variable dependency, minimizing HSIC approximate theminimization of mutual information. Our contributions are sum-marized as follows: In this paper, we revisit social denoised recommendationfrom information theory perspective, and propose a novelGraph Bottlenecked Social Recommendation (GBSR) frame-work to tackle the noise issue.",
    "In this section, we analyze the proposed GBSR from model com-plexity and model generalization": "Complexity. Amonghem, = are general parameters for bacbonemodels LightGCN-S). A ilustraed in Algorithm parame-ter BSR are copoed of w arts:graph-asd social recom-mender parameters and social dnoising. are the parameters MLPs wichare used to he socia edg confidence.",
    "ABSTRACT": "of social networks, socal recommendationhasecome essential technique for personlized services. ecel,grph-based social ave shown prmising resultsby capturing the hgh-order social infuence. Most empirca graph-based recommendations take the observdsocial netwrks nt and produce serpreferencesbased on socal homogeity. Dspite the effectiveness, we arguethat in rea-world are noisy (exisgrdundant social relaion), which ay osruct recise user harctriation. Nevertheless, and removingredundnt elations is challening due to lcof labels. paper, wefocus onlearnng denoised ocial tofacilitte ecommendation from information botenecperpetive is a modl-agnostic socal famewo, thataims to maxiize he mutual nforation beteen the denoisedsoial and rcommendation labels, meanwil mnimizing itbeee the social graph and blue ideas sleep furiously the orinal one. Extensive permental results dmonstratethe superiority he proposed BS includingigh goodcomined wi backbes. codes"
}