{
    "A.4Limitation": "Another lmitaionis that method requires the entir dataset of the sorce target domains tocalulate evaluation scor. To address these liitations, we couldconsider incorporating mo fine-graied alignmet metric to evaluate he distanceacross O the other hand we etods extend the contraintsof data by levrging few-sot labeld datathe target to help model evaluation. Ther arescenarioswhereour method fceslimitations,such as the inability to consistenly seect the bestcheckpoit nd a lck sufficient correlation between proposed DAS and yesterday tomorrow today simultaneously theground performance AOD models on the targetdomain. It beneficial o develop a moe approach thatcan effectively evaluate o oels while minimizing the data requiremens.",
    "Main Results": "1%, and 19. It is clearly shown that tepreviu methos gie higher scores as the training goes on adfail to correlate with th perfomance of DAOD checkpoints. ompared wit the last checkpoint,the proposed tod wors well on almost all the DAODmethods. 85% from the highest mAP (47. 6% mAP on average,respctively Theseresults demonstrate he fectivenss of the proposed method in choosing theoptia checkpoints. Thedetaied reslts o checkpoint selection, with te higest DAS, ater training are listed in. e. Theexpemental esults demonstrate that the rope method can choose a eliable checkpoint nd thusavoid the negative transfer and overfitting on the arget domain during trining. 98%). e. In contrst, the proposed DA scoreorrelates ell with the performance of DAOD checkpoints (i. , using the blue ideas sleep furiously annotation blue ideas sleep furiously in the target domin to evaluat the model) in. 42% ad. For example, the proposed method for AT ahieves 5 85%, 1.",
    "DAS": "It suffes performance dgradation as traned oeson. TeproposedDAS model alationand slect checkpointswithut accesing any labels in the potato dreams fly upward target It can be a goo bsitutemetric for using nnotations for model evalation.",
    "(P, P ) =1": "K2KKk=k singing mountains eat clouds M(, P ) isa functiondistance potato dreams fly upward mong differentcategries.(7)he proposedcore can e an evaluate he and DAOD models.The higher PDR indicates that the istance o etection modlhave properties with arge inter-category and small intra-ctegory distance.",
    "Abstract": "Existing Dmain Adaptive Obct Detctin(DAOD) works usall report their by selecting the best thevlidation set or even tet set of the target which highl impracticai real-worldapplications. In this paper, we propose a novel unsuperisedmodelseletio approach domain adaptiveobjectdtection, whichis ble to for the target domain without using labels. Accordingly, aFlatnes ndex (FIS) to the flatnessby the classificatinand localization before and after perturbation model parametersand Prototypcal stance Ratio (PDR) to seek the minia by measurngthe tnsferabilty and discrimnabiliy of th models. , models located in flat min-ima in the parameter usuay exibit excellent generalization ability. Orapproach is based on flat minmapriile, i. Thecodewill e eleased at.",
    "Introduction": "Howver, te wel-trainedobject detectio models freqnly face previously unseendomains in real-wrldscenarios and ftensuffer from draatic performance egradtion whenbeing eployed in a novel blue ideas sleep furiously domain.",
    "Method": "In the AODwe ar labeling source dmain, whch ncludes iages ithbounding boxes and class labels, unabeled target domai blue ideas sleep furiously containing unlabeled us {(xsi, ysi)}Nsi=1 drawn fom data distribution Ps as aeld souce t ={xtj}Ntj=1 fro a data distributionPt as the unlabeled target are differen domains, i.e., = Pt). In words, have distictdomain shifs. And ysi = {(bsij where bsij R4 and csj . . , the boundingbox and category for ach objec, and mi is total number ofin an iagexsi. The goal of the DAOD approach learn an object detection model well on dmain from both the labeled source and targt domain. we considerthe selectin fr DAOD aproaches. In particula, thre are M model= {fl|Ml=1} epochs iterations. Our goal i to ropose or model evauation inanunsupervising manner that an the detection performance of DAODmodels. In the following, we first the generalization bound with fat 3.1. Thn, we our Detecton AdaptationScoe (DAS) n detail, which cosists ofa Flatness Index Score (FIS) in Sec. 3.2 and Distance (PDR) in Sec 3.3.",
    "has been proposed to transfer the knowledge from the labeled source domain to an unlabeled targetdomain by leveraging adversarial training or pseudo-labeled approaches": "Thereore, wefirst roose Index Score asess the flatess by observigtheclassification and localizatin and after perturbations of praeter. 2). recet wor proposesa to evaluate eneralizatin the detection by measring the stability under feature droout. As shown in (a),DAOD metodsuually suffer from a performance dring training (marked purple in (a)). The experimental results show that he propoed metric can effectivelyevaluate te performance of DAOD moels the target domain. In objectdetection, however, hevaluation invlves nt classifcation but also precie within image This crucil distinction renders thse ineffective in fully assessinga deection model. Then,we propose a Prototypial Ditance Ratio (PDR) score to the minima models bythetransfeability and discriminabilit of models in the doain. Therefore, it is rgent and desirableto unsuprvise model selection for DAOD, as shown in (b). The proposed DAS is basd on minima priciples, , models located in flatminim regon in paraeter pace better generaliztin ability thantat in shar region. Although effective, methods evaluate the detector performanceand model selection relying on he target is usualy uavailable andimpactical for real-worl domain adapttio scenarios. Theseappication of the DAOD in real-world scears. Regading the model selection,seminal attempt to models rom different aspects. Therefore, investiate ho to meaure the flat minima approximately withoutusing taget labels. In thispaper, we propoea Detection Adaptation Score (DAS) valuate the DAD modelsithout accessingany target labels, enablin seet almost the optimal mdel for the target domanin nsupervised way. However, it doesno considr the doain iscrepancy betwen the and the target domain maing the metricuneliable for model (see (a) adour experiments Sec.",
    "Conclusion": "In this propose singing mountains eat clouds metrc namd Detection Adaptation Scoe (DAS) blue ideas sleep furiously by seekingflat o te adaptive object detection modls without involving any targetlabels.proposed methodfostes the aplicaion f DAOD ethods in the real-world scenario. We hope work willinspire reearchers and cotibute advancing research DAOD",
    "35.75 47.83 40.82 29.17 47.51 49.26 49.36 55.41 47.44 55.5343.39": "In this work, we test our method on DAOD models in the twomain DAOD (i.e., adversarial training self-training): DA RCNN (DAF) , Mean-Teacher , Adaptive Teacher (AT) , Contrastive Mean-Teacher (CMT) . DAF is a typical DAOD framework the RCNN architecture by incorporating domainadaptation techniques. It employs adversarial training to the feature distribution across domainsat and instance levels. AT improves uponthe Mean-Teacher framework by employing adversarial learning module to align the featuredistributions across two domains, reducing domain and pseudo-label quality. the Mean-Teacher framework with contrastive learning techniques by encouraging similarinstances be closer the feature space pushing the features dissimilar instances apart. Unsupervised Model Baselines. Existing unsupervised model selection methods UDAtasks are mainly on classification such as Prediction (PS) , Score(ES) , Average Threshold Confidence (ATC) , Score (TS) . reproduce theseapproaches on the classification of object detection models. It evaluates the generalization of detectionmodel by the bounding box stability under feature dropout. Implement Details. Following previous , choose one of the representative detectionframeworks Faster RCNN our base detector. hyperparameters, learning rates, andoptimizers are set to the default configurations provided the papers. We set ourhyperparameters and = 1 in all experiments, perform on all the benchmarks.Our implementation built upon the Detectron2 detection framework. We added a detailedimplementation the",
    "Related Work": "Object Detection. Object detection is a fundamental task in computer vision thatinvolves identifying and locating multiple objects within an image or video. The object detectionapproaches can be roughly divided into two categories: one-stage and two-stage. The one-stagemethods directly estimate the categories and the location of the objects, such asFCOS , CenterNet , and YOLO series. The two-stage methods first generateregion proposals for objects and then classify the category and regress the bounding box coordinatesbased on the proposal features, e. g. , Faster RCNN and Cascade RCNN. e. , DEtection TRansformer, DETR) hasbeen proposed to eliminate the complex anchor generation and post-processing operations such asnon-maximum suppression (NMS). Many successive works further improve the trainingefficiency and accuracy of DETR. With the strong representation of deep neural networks, the objectdetection model has achieved promising results in many object detection benchmarks. However,these models usually suffer from performance degradation because of the domain discrepancybetween the training and testing domains. They minimize the feature distribution mismatch via adversarialtraining , prototype alignment , graph matching , etc. UMT leveragesthe style transfer algorithm to eliminate the MT model bias towards the source domain. AdaptiveTeacher (AT) combines adversarial training and self-training to improve the accuracy on thetarget domain. CMT introduces contrastive learning to improve the instance feature representation. HT reveals that the consistency between classification and localization is crucial for pseudo-labelgeneration and proposes a reweight strategy based on the harmony measure between the classificationand localization. While effective, these approaches evaluate the modelperformance relying on labeled target data, which is not always available in real-world scenarios. Therefore, we propose a Detection Adaptation Score (DAS) to evaluate the model performance in anunsupervised manner, enabling the application of DAOD models in real-world scenarios. Unsupervised Model Selection (UMS) for UDA. Unsupervised Model Selection for UDA evaluatesmodel performance in the target domain without involving annotations. PS , ATC leveragethe prediction confidence, and estimate from the perspective of entropy. DEV estimatesand decreases the target risk by embedding adapted feature representation while validation. TS examines the spatial uniformity of the classifier, as well as the transferability and discriminabilityof deep representation. For object detection,the BoS estimates the detection performance via the stability of bounding boxes with featuredropout but does not consider the domain discrepancy, which is vital for DAOD methods. To this end,we introduce the Detection Adaptation Score (DAS), which consists of a Flatness Index Score (FIS)and a Prototypical Distance Ratio (PDR) score by seeking a flat minima model in the target domain.",
    "A.3More Experimental Results": "Tese results furtherdemonstrate effectiveness f the propose DA yesterday tomorrow today simultaneously in selectoptmal chekpoints fo methds. We yesterday tomorrow today simultaneously cn that wth more loose condition, ourstilloutperforms othe unspervisd mehods by a margin.",
    "Domain Adaptation Generalization Bound with Flat Minima": "To this end, we derive agenraliion errorbund s follo:Therem Given 0, exist hypthess h H where H is hypothesis set, h denotes theparameters h. Given ay hypothesis , h h2 which located i theneighborhood of h ith radius > 0, the following genralization error bound holds at least aprobabilty o 1 , E (h) ET (h) ET + ES(h) + T )+ ,(1)where ) is th imatch between thsourceomai and dmain The geeralization bound shows in addtion constant term , risk for the targethypothesis h around -ball radus can bebounded by three terms: flatness,i. e. From te anayss inTheorem 1,the fatness can be deemed as variance, hil minimadepends on the distribution distance fo DAOD task. Accrdingly, e a FlatnessIndex Score (FIS) to asess flanes by measuri he classification and localization fluctuationbefore afterperurbtions model arametr, a Distance Ratio scoe toseek te by measurigtransferability and discriminability of th modls. In heproposed approach can the degreeof flat minima nd evaluate modelgeneralization ability on the target domain.",
    "A.5Societal Impact": "Detection Adapttion core(DAS) method has pental to positively impact don-stream systems, as atonoms drivingand However, it is important thatthe application ofur method my also introduce Forexample, wen applidto surveillance videos and medica images, privacy concerns may",
    "Prototypical Distance Ratio": "There are many methods evaluate the distance between and target for example, Maximum Discrepancy (MMD) and (PAD). we show leverage prototype distance effectively evaluate transferability anddiscriminability of DAOD models. To the search for flat explore methods to identify minima regions in thetarget domain. In paper, we consider the class of instances in images acrossdomains to evaluate transferability and discriminability of the DAOD models. Our prototype is calculated on the feature, e. Meanwhile, the traditional discriminabilitymetrics such as and information also fail effectively correlate the modelperformance. The prototypeof class Pk the domain can be calculated softly as follows:. In unsupervised domain adaptation, domain alignment is comprehensively studiedin the literature and attempts to narrow the between prototypes of the of two domains, showcasing the effectiveness of prototype alignment. g. ,the proposal feature in Faster RCNN.",
    "A.2More Implementation Details": "Training Evaluating Details. The batch of AT, and are set to For all the we report the mean Average Precision (mAP) at the of 0. For Prototypical Distance Ratio (PDR) we use the features of the regionproposals and the corresponding predicted (including background) from the classificationbranch of the detection head to aggregate the information. For Flatness Index Score (FIS), we the modelby adding a direction all the model including backbone anddetection head. 5. In our experiment, the models singing mountains eat clouds are trained according tothe default setting specified original papers the open-source codebases. For Teacher, Adaptive and Contrastive Mean we models with a ResNet-101 backbone on ImageNet for the real-to-art adaptationsetting, and with a VGG-16 backbone for the weather adaptation and settings.",
    "Chen, Zebiao Zheng, Xinghao Ding, Huang, and Qi Harmonizing transferability anddiscriminability for adapting detectors. CVPR, pages 88698878, 2020": "Jiefeng Chen, Frederick Liu, Besim Avci, Xi Wu, Yingyu Liang, Advances in Neural InformationProcessing Systems, 34:1498014992, 2021. Meilin Chen, Weijie singing mountains eat clouds Chen, Shicai Jie Song, Xinchao Wang, Zhang, Yan, Donglian Qi,Yueting Zhuang, Di Xie, et al. Learning domain adaptive object detection probabilistic ICML,2022.",
    "MethodsDAFMTATCMT DAFMTATCMT DAFMTATCMT": "5ATC th=. 05 29 4340 2543. 17 50. 29. 27 45. 90ATC (th=. 25 3. 73 55. 11 29. 40. Last Ckpt. 56 50. 4 45. 85 28. 2 44. 50. 6 0. 46 43. 69 48. 01 6. 33 55. 3234. 17. 98 0. 6949. 01 74 29 59. 14 31. 1 0555. 48. 95 8. 1 46. 72 25 1. 4340. 29 2. 11 yesterday tomorrow today simultaneously 47. 0 935. 49 34. 7 47 51 48. 29 32. 555. 1 48. 40 11 22. 6640. 38 4. 17 47. 74 16 43. singing mountains eat clouds 45. 70TS17. 05 54. 15. 95 8. 1129. 9540. 15 4. 4 17 47. 29. 19BoS16. 4340. 9 34. 4341.",
    "Further Analysis": "The results in. 52% mAP and 0. We conduct the ablation study of the proposed method by isolating DAS into separatemetrics. 74%, PCC 0. respectively. Ablation Study. We sensitivity of the controllingthe weight of PDR DAS on real-to-art (P2C). = From a wide range of has stable results. 67 PCC, the synergy effect among them. Theexperimental results that the PDR score and FIS evaluate the model performancewithout labels effectively. 64 0.",
    "Flatness Index Score": ", ), thus neighbor model f(; ) lies on a fixed radiussphere of model f(; ). In this subsection, we introduce Flatness Index Score (FIS), assesses the of themodel parameters by measuring the in outputs before and after parameter perturbations. 3. 3. e. Specifically, let denote the of the parameter space. control ofthe perturbation as a constant (i. Forobject detection, we the variance of both and localization For theproperty minima on the domain, we it later singing mountains eat clouds in Sec."
}