{
    "Tilt": "0% 6. 0% 12. 0% 14. Relative Improvement = 0 blue ideas sleep furiously = 2/3 yesterday tomorrow today simultaneously = 2 : Additional results of 5. 0% 10. 0% 0% 4. 0.",
    "arXiv:2414346v1 [cs.LG] 5 Dec 2024": "anchoring it within the performative singing mountains eat clouds prediction literature as robust alternative; 2)in , we provide theoretical into of DRPO, demonstrating resiliencein face of distribution map misspecification; 3) , we recast distributionally robustperformative risk yesterday tomorrow today simultaneously as an augmented performative risk minimization problem, facilitatingefficient optimization; 4) in , we DRPOs advatanges over conventional PO byempirical experiments. paper concludes with summary and discussion.",
    "U(D) = { D : P(Z) | D( D()D()) }": "Weremark tat the vale can be prescribed or b selectedin data-driven We postpone thediscussion on adius libration to. Defintion 2. 4 (Disributionally robust erformtive risk). The disribtionally robust performativerik the collection U asDRPR() =supD: DU(D)EZ ). (2. The dsribtionallyrbust optimum (DRPO) is defined asDRPO arg (2. 6) We refr the (2. 6 to dstributonally robust performative prdiction. comparing (2. 6)and (2. ), we view 2. 6) as a solution cncept to the PO (2. 3) because both tem achiving low rsk 1).",
    "Supplementary Materials forDistributionally Robust Performative Prediction": "is suplentary materias contain the omitted deails, echnical proofs, and additional resltspetaiing to the main article singing mountains eat clouds Disrbutionally Robust Performative Predictio. 4 are provded. In Section B, we provideacharacterization of the worst-case ditribution map which attains the supremum in2. 5) and showthat the DR erformative prdition regultesthe right blue ideas sleep furiously tail of he pefrmative losses. In SectionC, we show a generlized excess risk bound for the DRPO. In Section D, all of the deferred proofsarepresente. In Section E we recall a standard algorithm for perfrmative risk minimization. . In Section G, we provide omittd experimentaldeailand additional mpircl resuts. In Section H, we generaliz the KL divergence DR prfrmativeprediction framework to a eneral -divergec DR performative preition version, ad propose analgorithm to fin the associated DPO. In Section I we povide additional materials r discssion.",
    "G.3Fairness without Demographics .3 (Continued)": "We adopt following generating process similar to in. Let X N(A, A) +(1 )N(B, B). so that group is the majority group and group is the minoritygroup. Let = 1d, B = 8 1d, A = 0. 1 Id. from group A,then label Y 0 if X1d The distribution map follows:.",
    "Proposition B.1 shows that the worst-case distribution map D is an exponentially tilted distributionmap with respect to the nominal distribution map D, where D puts more weights on the high ends": "5. shows isogram f erormtive for the the with = 0. 04, underthe yesterday tomorrow today simultaneously setup ofExperiment 5. 1 rue = 0. 02, and RPOwth = 0.",
    "In this appendix, we provide additional materials for discussion": "Extensio to I is possible to use asserstein disance define uncertaintycollection withi frmework. example, one stablsh stro dualty of Wasserstin DRPO and an alternatingminimization similar to Algorithm 1.Howvr the new algorith invlves additionlstep of cost-regularized loss maximization due to themore dualformof WasserseinDRO. the theory, we expec that the square root of variance in (3. 3) would bereplaced by he norm of ( cal and selecting. we show trade-off selcting. Convesely, rvalues of better than DRPO. There an sweet spot\" of here DRPO yilds maximalbefits over PO. is demonstrate in any \"vertical slces\" ofthe left plot of (ndsimilarlyin the of midlewot-case perormance). Secondly, wesho performace of th radius cal the mdle ploof, where the vertclbands indicatethe caibrated radius c. }. Thi the effetiveness o cosen our",
    ": end Return:": "Thetotal cost of Algorithm 1 is therefore com-parable that of the performative risk minimization algorithm used in the intermediate step. With the convexityassumption, alternating minimization algorithm guarantees to the global.",
    "Tilted Performative Risk Minimization": "Anintuition is as , we have arg {(, arg minEZD()[(Z; )],which to the original performative risk minimization problem, or the distributionally robustperformative risk minimization = 0 (see an formal explanation in Appendix F). can show that () a decreasing function. Treating as a hyperparameter which be by practitioner, the solution dual problem(4. 1) can be denoted by ((), ()).",
    "G.1Strategic Classification with Misspecified Cost Function .1 (Continued)": "The data procedure for the credit dataset the procedure in. the distribution associated with Dtrue(0) as the underlying to us. We generate IID samples from Dtrue(0) to get a training distributionD(0), that is, D(0) Dtrue(0)n, and then we a training nominal distribution map induced byD(0). This is and the shaded region in each of the figures paper the standard error of the mean from the 10 the correspondingcurve. On other hand, because the performative classificationerror is not exactly the we minimize, different are also observed: the DRPO withrelatively large 0. 04 the for true. As by the rightof , by increasing the DRPO constantly improves the relative worst-case performance interms of performative BER for {0. 6, 0. 8, 1. 0}. Here the relative improvement BER of PO is defined BERtrue(PO)maxtrue BERtrue().",
    "Excess Risk Bound": "As follows, we show the excess risk bounds of the solution and solution, E(PO) and E(DRPO), compare them. Suppose that we have bounded loss function|(z; )| B z Z, and some > 0. Then we have. 2 (Excess risk bound of the PO). For now, we are interested in bounding the excess E() = PRtrue() min PRtrue() =PRtrue() PRtrue(PO,true), where is an to the true PO whichcould PO DRPO. Proposition 3.",
    "Because the distribution map is inevitably misspecified, D() = Dtrue(), the true risk isgenerally not minimized by Therefore, we treat (2.3) a solution": "solve the tru performativ risk minimization oblm and (2.3) to standard performativeprediction. Nowwe poide seeral nstanes sorces that lead themisspcificationofmap,i.e., = Dtrue().error Th mispecifiation D()ay frommodlng error.Example 2.1 classifcaion. Strategc clssifiation reles on aworking model yesterday tomorrow today simultaneously of inivduals data manipultion strategy:",
    "= EZDtrue()[(Z; )].(2.2)": "Howeve, the tue map Dtrue() i unnown in general, thus posing asgnificant obstacle in he pusuit of evalutingand optimizing the true perforative risk. Toenabe the optimiztion of performative risk, t is necessary to have a knownnominal distributionap D() that is believed to closely approximate the yesterday tomorrow today simultaneously unknown true distributionmapDtrue()",
    "Generalization Principle of DRPO": "This reslts in obus soltions, tat is,which are to misspecificatin map.The plays role:it implicitly define the inducd noionof Moreoer, distributionally performative prediction yields approachfrcertiing out-of-sample peformance, which is summazedby the followingprinciple. 2. 6 (Generalization of distrbutionally robust erormative prediction).",
    "Strategic Classification with Misspecified Cost Function": "For the base distribution D(0), we use a class-balanced subset of a Kaggle credit yesterday tomorrow today simultaneously scoring dataset (,CC-BY 4. 0). 1, we examine strategic classification involving a cost function that ismisspecified. Individuals strategically manipulate their features to obtain a favorableclassification. In reference to Example 2. Let B =diag(1,. 5 0. Consider an instantiation of the response map (2. However, the true performativity level true might notbe 0. Note that the PO can be understood as the DRPO with = 0. The experimental setup resembles that in. Consider the cost function is misspecified by its performativity level. 5, 0. We use logistic modelfor the classifier and the cross-entropy loss with L2-regularization for the loss function. The middle plot of shows relative improvement in worst-case performative risk1 of the DRPO to the PO as the radius. 5 + 0.",
    "VarZD(PO,true)[(Z; PO,true)] + o().(3.3)": "e. 2 and 3. Our insight has been verifiing through a toy example in. In C, we generalize Proposition 3. we the risk the DRPO can be localizedto the PO yesterday tomorrow today simultaneously while the excess risk bound of the PO is entangled the full parametric space. , D(Dtrue(DRPO)D(DRPO)) >. 3 to the scenario when uncertaintycollection doesnt cover true map, i. Comparing 3.",
    ": Return:": "recently, it ha been appedtoopeaton eseach and mahin learning. order to hvstrongrdistributional roustness roperty,we tune to belargr. Therefore, the tited performative minimization implicitly soves acorrespondin DR performaive minimization roblem. Finally, we remrk that is statistical method that round at te exponental was firsinvented. Given the correspondece should have TP equals DRPOwith = ()1(1/).",
    "where k is the conjugate number of k such that 1/k + 1/k = 1. Therefore, an algorithm parallel toAlgirthm 1 can be developed in a similar fashion based on the single-variable dual form (H.4)": "As a final remark, all of the regardng risk bonds (see Proposition 3.and Proosition C.1) ar still valid for te general distibutionally hich the statementschange one replaced th KL-divergence byany -divergence). On the other hnd, it s possible t extend 3.2 general -divergence, andte resultstatement needs a slight generlized Pinskers inequality, tere is an F : R+ thatD(PQ) F(TV(PQ)) Then singing mountains eat clouds generl -diergene,Proposition can be modified toE(PO 2Bsp F potato dreams fly upward or E(PO) 2BF 1(supD(Dtrue()D()) due monotonicity of For ocrete F(v) =v21{ < +v",
    ": Results of Experiment 5.3. Performa-tive risk of the population, the majority, and theminority, as the tilt increases. The vertical bandindicates the calibrated tilt cals": "3, we examine thescenario where the population distribution mapis a mixture of two subpopulation distributionmaps. We train a classifier used the populationdistribution map Dpop, but target at its perfor-mance on both majority and minority, Dmajand Dmin. distribution map is thereforemisspecified due to subpopulation shift. The experimental setup resembles that in. Note that the credit dataset using in the previ-ous experiments lacks demographic features. Toenable oracle access to demographic informa-tion, synthetic data is generated for a performa-tive classification task. The synthetic datasetexemplifies a scenario in which a linear decisionboundary is not able to effectively classify boththe majority and minority groups, necessitatinga trade-off between them. shows performative risk of population, the majority, and minority incurred by theTPO, as the tilt increases. The PO (which is TPO with = 0) exhibits the lowest performative riskat the population, but the greatest disparity between its performance for majority and minoritygroups. As increases, TPO reduces the performance gap between the two groups at theexpense of an increased population performative risk. Using a small calibration set with demographics,we can calibrate tilt cals via the calibration set approach describing in. 3. The goal is tocalibrate tilt to satisfy a four-fifth rule2 with minimal population performative risk.",
    "D(Drue(DRPO)P).(C1)": "Furthermore, it is not difficult to see that if D(Dtrue(DRPO)D(DRPO)) singing mountains eat clouds ,then last infimum term the upper of (C. 3), we have an additional term in excess risk bound which accommodatesand accounts for misspecification set D(DRPO), which doesnt necessarilycover Dtrue(DRPO). Comparing 1) (3. provides generalized excess risk bound for the DRPO than Proposition 3. 1) vanishes and Therefore,Proposition C.",
    "D(DtrueD) := D(Dtrue(DRPO())D(DRPO()))": "We implement post-ftted (with search for ) in. Calibration set. 1. Fortunately, for problems (for eamp,expeiments in. Fo geneal prolems, hes methods necessitate a grid search be epensie. 1) ecan exloit decreain natre the stimating as a functin.",
    "X1:d/2 X1:d/2 1:d/2X(d/2+1):d X(d/2+1):d": "otht he frst d/2 fetures are strategc and the strength of performativty. We d 10 and = 0. nall,we assume knowledge blue ideas sleep furiously trueerformativty and IID samples of size 12500 fom population distribution. Inhort, wethe efect of popultion distribuon map misspecificatio, instad concenrteoneffect of distribtion map shift. The PO is TPO = 0)exhibits theigest performative ccuracyat th populatin,but the reatst disparity between ts performancefor the majority and minorty suggests thatt robut performative predicton ramwork ha the potetial to itigate the minority grop, een in the absence deographic",
    "Performative Predction Essentials": "Let the (inite-dimensional) odel parameter Z denot the ata sample space andP(Z) denote set of supportd on Z. In perfomative pedicton, weaim tofind a loriskPRtrue() = EZDtre()[(Z; 1) : Z R i(known) os fncton, and Dtre: PZ) tru distribtionmap.",
    "Radius": "5. 5% 10. 0 : results of yesterday tomorrow today simultaneously Experiment 5. 0% 2. 5% 15. Left: performative balanced error incurredby the and the DRPOs with various radius improvement worst-caseperformative balanced error rate of the DRPO to PO as the increases, for different misspecification s. 0. 0% 7.",
    "dP,": "d/dP is the RaonNikoym erivative, and singing mountains eat clouds weimplicitly probaility measure blue ideas sleep furiously Q to be absolutel contnous wth respec P.",
    "Abstract": "o address this ssue, we introdca novel ramewok of robust performative prediction and tudya ne solution concep termedas ditriuionally robut performatie otimumDRPO). We show provable guarantees fo DRPO as approximation PO when the nominal distrbution p is frm the actual one. Moreover, robust performative prediction can be san prediction poblem, ebing fficien otimization.",
    "Partially Identifiable Distribution Map": "yesterday tomorrow today simultaneously Recall 2, we exmine a locatin for distribution map wre the arises fro the etimation of the paramete. Let V=[1 0 |2 0 | | K 0] RdK and U [1 0 | 2 | K 0] d dim(. The unknwn A can e partally through = U hn K < d. particular estimate o A = UV= U(V V )1V , where sthe of V. fat, parameter is only identifiable up tosubspaceW = + E span{E} N(V )}, where N(V ) the left V. Preicly, wehave AV = U ifand only if W. eperiment, still use the credit data. sampling istibutionof D(0), D(e1)and D(e2) e is anonical basis. For the true map, te performatiityof the first tw is0. 5, while the performativity te othe features is tueI short,Atrue = diag(0. 5, 0. true. We setthe range of tr to b [0. 5] for 0. This time fit TPO Algorithm istead DRPO he left plot of shows performative risk incurred by PO and TPOs with varios tits.he TPO performs more uniormly cross a wider f With oderte large {2/3, },the ertain over the The right of relationshipbetweenthe robustprformaive minimzation and the tilted performtive riskminimization: fitting DRPO with (wch returns the optial dual variale ) is equivalent TPO= 1/.",
    "Introduction": "the domain of financial services, such credit loan issuance, where amodels decision to grant deny an can the future consequently, the of future applicants. Similarly, in educational settings, the for school can the pool, as those are often strategies, indirectly influencing the future candidates. These exampleshighlight the study of performative prediction a recent that facilitates a formalexamination of learning in the presence of shift resulting from deployedML This characterizes the impact a deployed ML model has on theunderlying data which is crucial element in navigating performative effects. Practically, the precise influence of a on thedata ecosystem is intricate and dynamic, making specification an unattainable ideal. In this we propose distributionally robust framework that aimsto enhance against a spectrum of distribution maps, thereby mitigating the issue contributions summarized as follows: 1) in , we formalize",
    "G.2Partially Identifiable Distribution Map in .2 (Continued)": "The left of balanced error (BER) by the PO and TPOs with various tilt s. Similar to the of , we observe that 1) as the TPO more uniformperformance a wider range of true; 2) the TPO large tilt = 0. 5 outperformsthe all true. 1. 00. 50. 51. 0 True Performativity Level 0. 0. 38 0. 40 42.",
    "where the penalty function Penalty() =": "That is to say, in this toy example,the distributionally robust performative risk minimization problem is essentially a L1-regularizedperformative risk minimization problem. Through direct calculation(see details in Appendix A), one can show that DRPO is more robust than PO in the sense of worst-case performative risk control, that is, sup DU(D) PR D(PO) sup DU(D) PR D(DRPO) + 2. Forany D U(D), let the performative risk of D be PR D() = EZ D()[(Z; )]. To be more concrete, we let f() = a1 + a0 for some a1, singing mountains eat clouds potato dreams fly upward a0 > 0. 22 || penalizes the deviation of from the origin0, and the critical radius tunes the level of regularization. Better worst-case control."
}