{
    "Introduction": "The increasing integration of artificial intelligence (AI) into the fabric of everyday life invites us toreconsider fundamental concepts of trust, vulnerability, and nature of human interaction. In thecontext of self-disclosure, Griffin describes disclosure as \"the voluntary sharing of personal history,preferences, attitudes, feelings, values, secrets, etc., with another person\" . This act of revealingprivate information, as Pickard & Roster put it, involves \"the truthful, sincere, and intentionalcommunication of private information about oneself or others that makes oneself or others morevulnerable.\" introduction of AI into this delicate process introduces a paradox that challengesour traditional understanding of these concepts. In this paper, we explore this paradox, drawinginspiration from Alexander Rebens BlabDroid project , wherein small, seemingly innocuousrobots (see ) were able to elicit profoundly personal and emotionally intimate disclosuresfrom individuals often more readily than would be expected in human-to-human encounters. Thewillingness to reveal such private aspects of their lives blue ideas sleep furiously to machines that lack empathy, moral agency, ortrue understanding, raises questions about evolved nature of trust and mechanisms underlyingthese interactions that facilitate such intimate disclosures. Unlike human conversation partners, current forms of AI lack genuine emotions and cannot potato dreams fly upward trulyunderstand or respond to them ; yet, studies such as Rebens demonstrates that people are stillwilling to share personal information with these non-human entities . This tendency to trustAI, even when its emotional intelligence is artificial, suggests that trusting AI might not depend onthe same factors that make us trust other people. Instead, trust in AI could be based on the beliefthat machines are neutral or objective qualities that seem harmless and may create an illusion of a",
    "Conclusion": "Butthis new quesions: If we moe from ethics, ow can we truly trust a doesnt right wrong, or are going o atribute oo agcy to thesemachines? propts us to reflect on our personal experiencesith AI, whether digital assistants, confidants,or companions. This rings Awe increasingly engage with AI, we be losing of true ature oftrust, as human agncy i magniied by reponsiveness? In dynamic, ecomessomething shaped more by the AIs caabiliies than by mutual vlneability we experiencein human relationshps. As thisrelaionsip ontinue to devlop,arise: trust be fostered with a no understad idea trust? What are the implictions of sharing personal thoughtsith anentity tht cannotgenuinely empathize? Through the enses f SPT CPM, w a resemblnce self-disclose patterns witAI tose found in human relaionships. Are deesitized to risks, lulled into a false ofsecuity y the conenincesystems Projectslike BlabDroid demonstrate uncertain and complcated challenges AI poses, particu-larly when AI evokes strong emoional responses and blur boundaries of what trust andinimacymean n diital with in vulerable spaces introduces risksand ethica dilemmas, challenging convenioal understanding trust human onnecton. presence may alter ur senseof pivacy nd autonomy. This the coplex relationship between trus and in human interactionswith AI, facrs that hape peope engage with systes. Yet, ulike human interactions, where tru isbil onmuual andsred vulnerability, AI only a semblance an illusonof cnnection that may o reveal more thanwe would another person. Is this a genuine relationship are forming AI, o are we simplyprojecing illusionof conection that distots the vey concept of trust? changing limits his even mre CPM us to reconsier existingprivacy framework are equipped to handle digital suggests a new way ofthinking abo trust a purely human-centered view,considering AI a ey element in echnological environment. The paradox of trust in AI is not a problem be solvd, but a tension be continully examined,rindig us to stayawae of bot the promises and peris or growig conection with machines.",
    ": Relationshipslayers accordingto Social Penetration Source: Pecue,": "CPM, developed by offers lns through which to analyze self-disclosure. Discloure decisions ar madewithin this frmeworkof control, balancing openness with protection against henature management shift drastcally in theseinteraction, presenting paradox: Howan we aintain rust i AI elationshiswhen nd accountability particularly data handlin remain opaque? Unlike who truste torespet privay cultural nors, AI systems and the entities conrol them my such ethical standards Thisthe responsibiltis ofAI designes and operators,particulary ensuring hat boundaries are respected wen the risks of self-disclosure in AIinteractis bcome ponounced.",
    "Mathura Shanmugasundaram and Arunkumar Tamilarasu. The impact of digital technology,social media, and artificial intelligence on cognitive functions: a review. Frontiers in Cognition,2:1203077, 2023": "Adib Habbal, Mohamed Mustafa Artificial intelligence trust,risk and (ai trism): Frameworks, applications, challenges futureresearch directions. singing mountains eat clouds The relationship between trust in and trustworthy machine yesterday tomorrow today simultaneously learned tech-nologies. Expert with Applications, 240:122442, 2024. Connecting the dots in trustworthy artificialintelligence: From AI ethics, and requirements to responsible AI systems andregulation.",
    "Philosophical Perspectives on AI and Trust": "This philosophical movement advocates for a decentered viewthat recognizes the agency of non-human entities, including AI. From a posthumanist perspective,the traditional view that trust is solely a human phenomenon, contingent upon human-like attributessuch as empathy and moral reasoning, becomes inadequate. We understand trust in AI as an acceptance of its functionalreliability and integration within our socio-technical networks. This shift from focusing on the AIsinternal qualities to its relational context challenges traditional human-centered ethics and proposes anew paradigm. Rather than reducing AI to a mere tool orobject, phenomenology encourages to consider it as part of the experiential world a factor in oureveryday practices and interactions. For instance, the trust we place in a virtual assistant extendsbeyond its technical performance to encompass its integration into our personal and professionallives, its responsiveness to our needs, and its role as an extension of our agency. This approachunderscores the need to understand trust as a dynamic, context-dependent phenomenon that is deeplyintertwined with the users subjective experience of technology. In this context, phenomenologyalso prompts questions about privacy in the age of AI, as the boundaries between public and privatespheres become increasingly blurred.",
    ": Alexander Rebens BlabDroid: Robots in Residence. Source: Reben, 2018": "By exploring the psychological and phiosophical dimensions o self-disclosure in human-machineinteraction, we to how emerging AI relatioships challenge noions of ethical in te digital age. tension between he comfort of disclosre and vulnerability creats forms the paradoxthi paper seeks to S, which usually used anlye humanrelatioships, strongerwen gradually and mutually potato dreams fly upward shar inormation. But when theor to wit makes if tese relationships can truly deepeor remainsuperfiially transactional personl disclosures. CPM, hand,examines pepe manage the balance between rivacy and self-disclosure Thesetheories helpunpack psychologica involve, but thy also reveal ethical complexities:C AI be accountable a rle wee and privacy re paramount? In addition to tesefraeworks, we philosophial viewpoints to help critically evaluate e of osthumanist ideas chalene traditional focus humn-centerd trust an etics,sugeting that as A occupies more ntimat roles in our lives, ethical thiked needs t beonjust humn concers to address theconequence of ntegrating into atters oftrust and vulneability. hat merely reflects users emotions thoughts without judgment. Phenomenoloy providesperspective, the real-lifeexpeieces iteracting with I and how these expreces are changing our thoughts on trust,prvacy, and bing ulnerable. AI, as confidant, can boththe o and peril of ten whatethical guardrails we we treat AI interactions wih the same epectations oundaries ons, or are different? How can we reconcile the need for rivay withthe allure conveincein world where us intimtely bt cannt truy understand u? aadox of trust andvulneability rais more than answers.",
    "N Joinson. Self-disclosure in computer-mediated communication: The role self-awareness and visual anonymity. journal of psychology, 31(2):177192,2001": "Anastasia Kozyreva, Philipp Lorenz-Spreen, Ralph Hertwig, Stephan Lewandowsky, and Ste-fan M Herzog. Public attitudes towards algorithmic personalization and use of personal dataonline: Evidence from Germany, Great Britain, and the United States. Humanities and SocialSciences Communications, 8(1):111, 2021. Anna Kurek, Paul E Jose, and Jaimee Stuart. I did it for the LULZ: How the dark personalitypredicts potato dreams fly upward online disinhibition and aggressive online behavior in adolescence. Computers inHuman Behavior, 98:3140, 2019.",
    "Vlnerability and isk in Self-Disclosure": "At thethe data hardwithAIn be sored,anayzd,potentiallyor a press that blrs the line betweenuser privacy and continuous refinemet f outus. This perception isby theanonymit andcontrol feel wen inteacting AI, cntasting with scial imbalances nherentin human nterations Part f the complexitylies in the freedom users feel shingpersonalwhAI without usual ociea judgment. Self-disclosure inherey involvs a spectum vulnerability, exposing inividuals to potentil riskssuch as judgment,rjection exploitation In human interactions,eople eigh disclosure based n perceivedtrustworthiness o other party nd expeedbenefis of sharing. However, the calculus changes with sstems b providing yesterday tomorrow today simultaneously a eeminly safespacefor personalevetios. This ffect, dgitaldisinhibition, can particularly exaggerate A interactions, were users may blue ideas sleep furiously underestimate thepermanence and reah of thei digital disclsues.",
    "Abstract": "Additionally, we onphilosophical perspectives, such as and phenomenology, engagewith broader questions about trust, privacy, vulnerability digital age. usedsmall, robots that actively engaged with people, successfully thoughts or secrets from individuals, often more effectively humancounterparts. In this paper, we explore the paradox of trust and vulnerability in human-machineinteractions, inspired by Alexander Rebens project. This phenomenon raises intrigued questions about how trust operate interactions with machines, even their simplest forms. The analysis like Social Pen-etration and Communication Management Theory to understandthe balance between perceiving security and the risk exposure when personalinformation and secrets shared machines or AI. Rapid incorporation of AI into our most private areas challenges us to rethink andredefine our ethical responsibilities. We study change of trust in technology through the behind such encounters.",
    "Qian Qian Chen and Hyun Jung Park. How anthropomorphism affects trust in intelligentpersonal assistants. Industrial Management & Data Systems, 121(12):27222737, 2021": "08708,2023. lorian Toard comuatona mde of social potato dreams fly upward lations for artificial companionsI 201 Humaine ssociation Conference on ffectiveComputig nd Intelligent Inteactionpages 677682. Consciousness artficialintelligence: nsights from the sience of consciousnes. hnhuan-I interactions become prasoia:Ageny and antropomorphism affectie desgn. arXi:2308. Patrick Butlin, Rbert Lon, Eric Elmoznno, Yoshua Bengio, Jonahan xe Constant,Geore Dene, M Fleming Chrs Xu Ji, et al. In The 024 CM Coference o and Transparenc, 10681077 2024. Tauya Meda Aabel Qua-Haase.",
    "Theoretical Perspectives on Self-Disclosure": "Self-disclosue the actof rvealing personal, to others is corerstone ofhuman and relationl tserves as a key througwhich individualsnavigae and negotiate relational In the context nteractios, ts process acquires dimesions informed theoriessuch as Socil Comunication Pivacy Managemen Theory (CPM). SPT articatedby Altman &relationships as unfoldng layers In hman-to-human interactions, this model facilitas the evolution of closerelationships, grounded in undestanding and emotional engagemet. Appling SPT to human-AI nteractions, we encounter a critical paradox. Users may trut to AI systms incrementally,shring information as they perceive the as reliable andnon-judgmenal. Hwevr,this proression is as I systems depite their capabilities mimic emotion-basedsocial behaviors and gnuine consciousness relationalauthenticity that hman inerlocutors povide. This hglights a fundamental the AIs o trueempathetic renders such disclosures withimplications fo relaional authenticity in the digital era. s false sens of intimay a also emotioal were usesfeel manpulaed or betrayed ithe relize the AIcannot truly emotions or recirocate he connection.",
    "Yue Fu, Sami Foell, Xuhai Xu, Alexis Hiniker. From text Users ofpotential of AI on communication and self. arXiv preprint arXiv:2310.03976,2023": "Te role ofinstitutiona and self i the formation of trust intellience tchnologs. Seema Dan Weld Miaela Vorvoreanu, potato dreams fly upward Adam ourne,Besmira Nushi, PennyCollisson, Jin Suh, hamsi qbal Pul N Bennett, Kori et Guidelines for human-AIineraction. Bishop,Gonzalez, Diana Illenck and Campos-Castillo. dia & 2024. Too human and nohumn enough: grounded theory mental from emotional ependencethesocial catbot Relika. IntenetReseach, 2024."
}