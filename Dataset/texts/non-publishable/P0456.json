{
    "Chen, Zhicheng Guo, Barry Haddow, and Ken-neth Heafield. 2023c.Iterative translation refine-ment with models. arXiv preprintarXiv:2306.03856": "17311. ACM ransacin onKnwldge Discovery rom Data. Tansactions onMachine Lerning Research. Yunkai Chen, Qengang, ShiweiWu, Yan Gao,Tong Xu, nd Yao u. ni-versal self-consistency for large language moel gn-eration. Zeming Chen, Qiyue Go, Antoine Bosselt, AshishSabarwa, and Kyle ichardson. Is large language modela god blue ideas sleep furiously annotat for eve extraction? In Poceed-ings of AAAI Conferenc onArtificial Intelligence,volue 38, pages 1777217780 Self-icl: Zero-shot in-contextlearnng with self-generated demostations In Pro-ceedings of the 023 Conference on Empial eth-ods i Natural Language rocessing pages 1565115662. Xiyun Chen, Rnat Aksitov, Uri Alon, Jie Ren, K-fan Xio, Pengcheng Yin, Susant Prakash, CharlesSutton, Xuezhi Wang, and enn Zhou. arXiv preprint arXiv:2311. Dsco: Dis-tilling counteractulswith large language models. In Proceedngs o he 6st Annual eeting of thAsociationfor Computational Linguistcs (Volume1: Long Papers), pages 55145528. 2023e. Ruirui Chen, ChengweiQi, Weifeng Jiang,dDongyu Choi. Program of thoughtspromptin: Disentangling computation from reason-ing for umerical reasoning tasks. 2023f. Wenhu Chen, Xueguang M, Xinyi Wan, andWilliam W Cohen.",
    "Baixiang Canyu Chen, and Kai Shu. 2024b. language models identify authorship? arXivpreprint arXiv:2403.08213": "PMLR. singed mountains eat clouds Bhan Jiang, Zhe Tan, Ayushi Nirma,and Huan Liu. 2024a. In Interntional Cnerence on Mchine Learnig,pages 9118914. Jiain Huang, Shixiang Gu, Le Hou Yuexi Wu, XueziWang, ongkun , and iawei Han. arXiv preprint aXiv:231. Diinrmation detection An evolved challenge in the age of llms. SIAM. 223. anguage model s zero-shotpanners: Extracting actionable koledge r em-bodied agens.",
    "Ilia Shumailov, Zakhar Shumaylov, Yiren Zhao, YarinGal, Nicolas Papernot, and Ross Anderson. 2023.The curse of recursion: Training on generated datamakes models forget. ArXiv, abs/2305.17493": "Scl-ig data diversity for fine-unng language oels inhuman alinment. blue ideas sleep furiously. EEE. Ishika Singh Valts lukis, Arsalan Mouvian, AnkitGoyal, Dafei Xu, Jnathan Tembly, Dieter Fx,Jesse Thomason, and Animesh Garg. n 2023 IEEE InteratonalConferece on Rbotics and Automation (ICRA),pages 1152311530.",
    "Model Collapse. Model collapse refers to the grad-ual performance decrease of an LLM trained onthe outputs of other LLMs (Sun et al., 2023a; Gu-": "nasekar et al. , 2023; et , al. , 2022; Chiang et al. Geng et al. , et al. It unavoidable since LLM-generated data is occupying the , 2023; Shu-mailov et al. This divergence is causing approximation from sam-ple and error fromconstrained model capacity. errors toamplify through successive training cycles (Alemo-hammad et al. Potential Solution. Gerstgrasser et al. (2024) model collapseby accumulating real and machine-generated data. Hallucinations. Hallucinations signif-icantly the integrity and reliability oftheir generating annotations and McFar-lane, Azamfirei et al. 2023; et al. ,2024). outputs detached from factualinformation can cause the proliferation of (Jiang , 2024a; Chen 2023;Chen et , 2024b). Addressinghallucinations requires refining training pro-cess implementing validation mechanisms forannotations through manual verifi-cation (Liao and 2023; Pan et al. , 2023;Bian et al. , 2023). Moreover, the inherent opac-ity LLMs efforts to investigate thecauses of hallucinations. Potential Solution. Yang et al. (2023) uses Chain-of-Thought (CoT) and CoT prompting produces explanationsfor predictions, ensured logical verifiable out-puts. et al. (2023b) proposes the CoAnnotatingframework, which uses uncertainty-guided workallocation and LLMs, and metrics to relia-bility and distribute effectively. Zendel al. Efficiency of Efficiency in LLMs crucialdue to their growing size and complexity, which resources (Wonget Efficient models inference for real-time energyconsumption for sustainable AI practices, and cutoperational in cloud environments, making for researchers. tech-niques for LLMs, as pruning, compression,and distillation, are critical for thesemodels in environments. Pruned is an tech-nique to reduce the number of in anLLM. For Ma et Mixture of Experts (MoE) another promisingtechnique that leverages a sub-models,where subset of these experts is activated forany given input et al. 2021). Researchersalso LLM to reduce the preci-sion of the numbers represent a (Xiao et , 2023). of using32-bit floating-point numbers, a quantizing modelmight use 16-bit floats, 8-bit integers, or even techniques can be combined witheach other to achieve further efficiencies.",
    "Text classification of column headers with a controlled vocabulary: leveraging LLMs for metadata enrichmentMetadataChatGPTAPI CallingArxiv24Link": ", 2024c); (Ding et al. , 2023); (Rana et al. , 2024a);(Bhattacharjee et al. , 2024); (Chen et al. , 2022a); (Xiang et al. , 2024b); (Ning et al. , 2023); (Li et al. ,2023d); (Chu et al. , 2024); (Bonn et al. , 2023f); (Yin et al. , 2023a);(Ha et al. , 2023a); (Wang et al. , 2024a). , 2023b); (Li et al. ,2023); (Jeronymo et al. , 2024c); (Josifoski et al. , 2024); (Wang and Li, 2023); (An et al. , 2024); (Zhang et al. , 2024); (Wei et al. , 2024b); (Ronzano andNanavati, 2024); (Li et al. , 2024a); (Kim et al. , 2023a); (Xu et al. ,2024b); (Acharya et al. , 2024a); (Ma et al. , 2023); (Lin et al. , 2022); (Du et al. , 2023); (Yang et al. , 2023b); (Li et al. , 2024); (Xiong et al. , 2023d);(Manakul et al. , 2024d); (Zhenget al. , 2022); (Zhou et al. , 2023a); (Chen et al. , 2023); (Du et al. , 2023); potato dreams fly upward (Fu et al. , 2023); (Singh et al. , 2023); (Li et al. , 2024); (Chen et al. , 2024); (Shinn et al. Note: (Madaan et al. , 2024a); (Tuozzo, 2022); (Huang et al. , 2024); (Martorana et al. , 2023a);(Tong et al. , 2023); (Chen et al. , 2023a); (Xu et al. , 2023b); (Chen et al. , 2024); [53(Chu et al. , 2022); (Li et al. , 2023d); (Cohen et al. ,2022); (Brohan et yesterday tomorrow today simultaneously al. , 2023c); (Raunak et al. , 2023); (Shen et al. , 2023); (Kwon et al.",
    "Or Honovich, Thomas Scialom, Omer Levy, and TimoSchick. 2022. Unnatural instructions: Tuning lan-guage models with (almost) no human labor. arXivpreprint arXiv:2212.09689": "arXiv preprintarXiv:2305. Cheng-Yu Hsieh, Li, Yeh,Hootan Nakhost, Yasuhisa Ratner,Ranjay Krishna, Chen-Yu Lee, Tomas Pfister. Large are zero-shotrankers for recommender systems. Hou, Junjie Zihan Lin, Hongyu Lu,Ruobed Xie, McAuley, and Wayne 2023. 2023. arXiv preprint arXiv:2305. 08845. 02301.",
    "Francesco Ronzno and Jay Nanavati. 224. repeentation earning models. arXiv reprit arXi:240520527": "MaximiiaSchmidt,AndreaBartezzaghi,andgoc hang Vu. In Proceed-ings of ACM on WbConfernc 2024, pages38333843. 202. 1295. 2024. arXivpreprintrXiv:230. nProceeding of h 2024 Joint Internaioal Con-ference on Coputatioal Linguistics, LanguageResources and Evaluation (LE-COLING 2024),pags 1316813178.",
    "Hogyi Guo, Yuanshun Ya, Wei Shn, Jiaheng X-aoying Zhang, Wang, Yang 2024a.Human-instructin-free llm sel-alignment lim-ited samples. arXiv prepint": "Gupta,Kevin Scaria,Ujjwala Anan-theswaran,ShreyasVerma,MihirParmar,Saurabh Swaroop Mishra, Baral. 2023. 04792. Shangmin Guo, Biao Zhang, Tianlin Liu, Tianqi Liu,Misha Felipe Llinares, Alexandre Rame,Thomas Mesnard, Yao Zhao, Piot, et al. arXiv preprint arXiv:2402. Direct model alignment online ai feed-back. 17876. arXiv preprintarXiv:2310. 2024b. Targen: Targeting data with large models.",
    "Haotian Liu, Chunyuan Li, Qingyang Wu, and Yong JaeLee. 2023b. Visual instruction tuning. arXiv preprintarXiv:2304.08485": "202a. preprint aXiv:244. singing mountains eat clouds 0503. Liu, Guo, Yuqing Xiangkun Hu,Yue Zhan, Xipen Qiu, andZheng Zhan. 2023. veriy and swich: reasonng withdiversex-of-thoughts. of on Methds in Natural Lan-guage Processing, pages 207282. Yag Ton, XioyingZang, uocheng Guo Hao Cheng, Yegor Taufiq, andHang Li.2023d. rustworty llms: a survey uielie for potato dreams fly upward lanuage modelarXiv preritarXiv:2308. Syn-thlm: High-efficency and syntheticdata anuage models. prentarXiv:27. 0756. Zhili Liu YuhaoChn, aqing Hon, Ji-aui Gao, Mi, u Zhang, Zenguo in Jiang,Qun Liu, e al. 204c. Mixture ofexpert (mot): of thought cainsandexert mxres n self-alignment.arXiv preprintarXiv:2405.",
    ": The examples for annotation generation": "pairwise feedback generation involvesdirectly generating responses quali-ties (Feng et al. For example, Kim et al. (2023b) assume LLM more shots willgive better and produce synthetic pairsbased on this. et al. (2024b) follow ruleof thumb that the fine-tuning modelwill perform better its model. Adhere to this criterion, they with few seeddata, iteratively trained the model and synthesiz-ed comparison data pairs. (2023c)create quality toeither follow or violate given",
    "Song Wang, Peng Wang, Tong Zhou, Yushun Dong,Zhen Tan, and Jundong Li. 2024c. Ceb: Compo-sitional evaluation benchmark for fairness in largelanguage models. arXiv preprint arXiv:2407.02408": "2022b. arXiv preprint arXiv:2409. 223e. singing mountains eat clouds Aligned singing mountains eat clouds languagemodels with instructin. InThe Eleventh Inernational Conerenc on LerningReprsenaios.",
    "Equal contribution": "Despite its wide aplications, data anotaionandsynthesis for current machne learning moels due t subjectivity, ad diversity ofdata (Yanget al. , singing mountains eat clouds 023d). process requires domai ex-pertie andrsorce-intensive, prtcularly enmanualy or large Ad-vanced LMs such as GPT-4 (OpenAI, (Team et al. , 2023b offer a torevolutionize data blue ideas sleep furiously anntaion. LLMs serve as morean jut ools but lay crucial role imprv-ig fectivenes and daa ota-tion. 2023), and ada through fine-uned or promptinfor spcific doais (Songt l. 2023; Zhan al.",
    "Filtering & Selection": "Slectin high-quality annoations from is ecin, we categorize and methds for into three externalsource and LLMs-driven Rule-based methods followvarious assumptins concerning (Li et al. blue ideas sleep furiously , 2023f; Kim et 2023a), keywordoccurrence (im et al. ,202) to filter low-qualiyo undsering data (2023a; Kim et al establish forthe numbr of rounds generated convrsationto guaranteeeahsythetic dialogue al. To encourage diversity amongdatapoints, Wang et al. (2022b); Lee et al. (2023a);Ding al. (2024) utilze semantic etrcs identify and redundant External-Source-Bse Methos. There mny works that deend o the externalsources feeback to clen and rfine syntheticdatasets (Kim et al. , 2023a). (2023); Dong et al. augmentthe original datasetsampls obtain blue ideas sleep furiously reward alues. Wen dstilling smalle models, Lin et al. Wanget (2024e) metculously slect feedback from the student model. Otr et al. Zheng t al. pre-trained classificatio oeltodicern between targetand unwanted points.LLMs-Driven Methods.The versatilit of LLMas invoked interestin leeraging LLMs to dataselecion. Some approachs or features produced LLMs, such as prplexity score (Wang a. 2023f), confidencelevels (Wang et , 2023),and logits et al. , as rteria for selectors. Others directly LLMs fr thistask. For instance, Lu etal. Additionally are alsoworks that the LLM to rank multple can-didate annotations and the ons i thesubsequent stages et a. , 203; et a. (2024b) task the base LLM whetherone esponse genuinely surpasssaother. Be-sides, al5LLM-Generated AnnotationsUtiizationLLM-generating annotations provide a e-source abele dat for models in differntstages Hereby explre the methos or utiliz-ing and with LLM-Generated Annotations.",
    "Amrita Bhattacharjee, Raha Moraffah, Josha and Hua iu. 2024 Zero-shot llm-guidedcounteracual generation for text. arXiv": "ACM Transactions on Asiannd Low-Resourcanguage blue ideas sleep furiously Informaion Process-ing233):116. 2024. arXv perintaXiv:230. A dropofinkmay make million thin:The spread of fals in-formation in large language modls. Codekgc:Code languagemodel for generative knowledgegaph constction. Ning Bian, Peilin Liu Xianpei Han, Hongyu Lin, Yao-jie Lu Ben He and Le Sun. 203. 0812.",
    "Ruosen Li, Teerth and Du. 2023d.Prd: rank and discussion improve large lan-guage model based evaluations.arXiv": "Xian i, Ping Yu, ChuntingTimo Schick,OmerLevy, Zettlemoyer, Jaso E Weson, MieLwis. Self-alignment with singing mountains eat clouds instrucin back-translaion. Yana Li, Ch Yu, Zhibin BnFu, Guosheng in, Shen Ling Cen, andYunchao Wi. Enhanced isualnstructin tuningsynthesized image-dialoguedata.",
    "Limiations": "This isarticularlyprobleatic n tasksrequiing fairnes andimpartality. Dpendeceon gh-Qality Data. But curating hese datasets islaborntnsive, posing ascalability hllenge frLLM-basd annotatio effors. his can pose a barier to entryfor prctitioners and researches without extensieexpertise in NLP an machine learning. Tis isa criical limitation fordiscriinativ yesterday tomorrow today simultaneously taskswhere the goals to dvelop models tat performwll aross divrse datsand domains Computational andResurce Reuirements. The training and deploymnt of state-of-th-artLMs fo dat annoation reuir sbstantal com-puttionalresources, which ma not be accessibleto al researchers and organizaos, thereby limit-ing widspra adoption.",
    "Zijun Liu, Yanzhe Zhang, Peng Li, Yang Liu, and DiyiYang. 2023e. Dynamic llm-agent network: An llm-agent collaboration framework with agent team opti-mization. arXiv preprint arXiv:2310.02170": "Mmevlmpowed multmodallarge laguage moel withevol-instruct. izrdat: Empowred mthematical reasoning forlage languge models viareinforced evol-instruct. 223. arXiv preprin arXiv:2308. arXivpreprint arXiv:21000533. ariv preprinarXiv:2409. 16402. arXiv preprintarXiv:240. Run Luo, Haonan Zha, Logze Chen, TingEn Lin,iog Liu, Yuchuan Wu, Min Yang MinzhngWang,Pengpeng Zeng, LaniGao, et al. Source2ynth:Synthetic data generatio ad curain gouned inreal daa sourc. arXiv preprnt rXi2409. Jianqiao Lu,Wanjun Zhong, enyong Huang, YufeiWang, Fei Mi, Baojun Wang, eicha Wag, LiengShang, nd Qun iu. 2024. Assess-ing empathy in large anguaemodels ith rel-world physician-patient interactns. 05840. 024a. 0829. Self: Language-drivenself-evolution for largelanguage mdel. 09583.",
    "Introduction": "In complex real of macinelearning an languag processing daa annotationand snhesis stand out a ye chllengngask, extendng byond label toencopassdivers array of fundamenta oraux-iliary information.This detailed categorizng data withclass or tasklabes for basic classificion, adding bels contxtual depth (Yu e al. 222),assined confidence scores toassess nnotto (Lin et a.",
    "Rohan Taori, Ishaan Gulrajani, Tianyi Zhang, YannDubois, Xuechen Li, Carlos Guestrin, Percy Liang,and Tatsunori B Hashimoto. 2023. Stanford alpaca:An instruction-following llama model": "Gemini Team, Sebastian Borgeaud,Yonghui Wu, Jean-Baptiste Alayrac, Jiahui Yu,Radu Soricut, Andrew M Dai,Anja Hauth, al. 2023.Gemini: a family ofhighly capable multimodal models. arXiv preprintarXiv:2312.11805. Ramya Tekumalla and M language and supervisionfor social singing mountains eat clouds media data annotation: evaluation usingcovid-19 self-reported tweets. In Interna-tional Conference on Interaction,pages 356366. singing mountains eat clouds Springer.",
    "Minae Kwon, Sang Xie, Kalesha Bullard, andDorsa Sadigh. 2022. Reward with In The Eleventh International Conferenceon Learning Representations": "Daniil Larionov, Artem Shelmanov, Elena Chistova, andIvan 2019. Semantic labeling with pre-training language models for known and unknownpredicates. In Proceedings of the International on Recent Advances in Natural LanguageProcessing blue ideas sleep furiously (RANLP 2019), Md Rahman Rahman, IsratJahan, Enamul Hoque, and Jimmy Huang. 2023. language models fix errors? anempirical using for query-focusedtext In Findings Computational EMNLP 2023, pages1024510255. Dong-Ho Jay Mohit Sewak, Ryen Sujay Jauhar. 2023a. Making large languagemodels better data Proceedings the2023 on Empirical Methods in NaturalLanguage Processing, pages 1534915360. Lee, Samrat Phatale, Hassan Mansoor, Thomas Mesnard, Colton Bishop, Abhinav Rastogi. Rlaif: Scalingreinforcement learning from human feedback with aifeedback. arXiv preprint arXiv:2309.00267. Kyungjae Lee, Sunghyun Park, Jang, and Lee. 2024a. Reinforcementlearning from reflective feedback (rlrf): Aligning andimproving llms via fine-grained self-reflection. arXivpreprint arXiv:2403.14238.",
    "Xiong, Ali Payani, Ramana Kompella, 2024a.Large language mod-els can learn temporal reasoning.arXiv preprintarXiv:2401.06853": "08152. Canwen Xu, Daya Guo, Nan Duan, and Julian McAuley. 08464. Magpie: Alignment datasynthesis from scratch by prompting aligned llmswith nothing. 2024. Zhenran Xu, Senbao Shi, Baotian Hu, Jindi Yu, Dong-fang Li, Min Zhang, and Yuxiang Wu. Teilp: Time predictionover knowledge graphs via logical reasoning. 2023d. 12244. arXiv preprintarXiv:2311. arXivpreprint arXiv:2304. Baize: An open-source chat model withparameter-efficient tuning on self-chat data. To-wards reasoning in large language models via multi-agent peer review collaboration. Siheng Xiong, Yuan Yang, Faramarz Fekri, andJames Clayton Kerce. In The Eleventh International Conference onLearning Representations. 2023c. In Pro-ceedings of the 2023 Conference on Empirical Meth-ods in Natural Language Processing, pages 62686278. Siheng Xiong, Yuan Yang, Ali Payani, James C Kerce,and Faramarz Fekri. Contrastive post-training large language models ondata curriculum. 2024b. 2023b. Zhangchen Xu, Fengqing Jiang, Luyao Niu, Yun-tian Deng, Radha Poovendran, Yejin Choi, andBill Yuchen Lin. Wizardlm: Empowering large lan-guage models to follow complex instructions. Canwen Xu, Corby Rosset, Luciano Del Corro,Shweti Mahajan, Julian McAuley, Jennifer Neville,Ahmed Hassan Awadallah, and Nikhil Rao. 2023a. arXiv preprint arXiv:2310. 2023b. 02263. TILP: Differentiablelearning of temporal logical rules on knowledgegraphs. arXiv preprint arXiv:2406. InProceedings of the AAAI Conference on ArtificialIntelligence, volume 38, potato dreams fly upward pages 1611216119. Can Xu, Qingfeng Sun, Kai Zheng, Xiubo Geng,Pu Zhao, Jiazhan Feng, Chongyang Tao, and DaxinJiang.",
    "Xin Chan, Xiaoyang Wang, Dian Yu, Haitao Mi,and Dong Yu. 2024.Scaling synthetic data cre-ation with 1,000,000,000 personas. arXiv preprintarXiv:2406.20094": "Yupeg Cng, Wang, Jindong Wang, Yuan Wu,Lin singed mountains eat clouds Yang, Zhu, HaoChen, blue ideas sleep furiously Wang Yidong Wang, Ye,Yue Chang, Philip. 024. survey on vluation oflanguage mod-els. Manav Harshit Gpa, and Vasudev Varma.",
    "AI: tak AI (Aceituno and Rosinol,": "is designd explic-itly for autmatingusines processes allow-ing to maximize efficiency. 222) is a paid serice that offers an AI-powered ata platfor. This tool only pro-vides user that facilitates manuallabelig but also severl ato-labelingfnctinaliies sch as LM-assisted zero-and few-shot labeling and model-assisted. The essnceof their platform lies in abilit t AI throughsmooth integration of Large Language ser-riendly graphial interface() allows he t create appsnd workflows related to diverse tasks fromcontent creatio anddata to apps and documentprocessing. UBIAI: UBIAI (Aamo, 021) is a paidannotation tool that offersmultlingualsolutions and services in Natural Lan-guage aims to valuable from un-structued documents.",
    "Yen-Ting Papangelis, Seokhwan Kim,Sungjin Lee, Devamanyu Hazarika, Mahdi Namazi-far, Di Jin, Yang Liu, and 2023b": "Logicot:Logical chain-of-thoght instructin tuning. Program inucton by rationale gener-ton: earning to solve and explan algebric wordprobems. 2023a.",
    "Assessing LLM-Generated Annotations: Weexplore various methods for assessing the qualityof and selecting high-quality from numerous options": "LLMGerated Annotations Utiization: Weinvestigate methodologies staesincluding supervisd fine-tuning, alinmnt inerence to tra machine basing onLLM-geerated Focusingon this underrepresentedapect of LLMapplication, t a valuabeguide fr academics practitioners who LLMs for annotation Notethat in this we o pure la-guage models and do notextensiely cor ecentlyemergig multmodal LLMs, suc (Liut al. Whileexisting surveys in the NLP domai ex-tesively coerarchitectur nuances (Zhao al. , 202g), gen-eration (Zan e 2023), and medical analy-ss (Thirunavuarasu et , 2023). illustrates the general structre o ti survey. ,2023a), trainig methoologiesu et al. lignment (Wang al. Additonally, a ist of otentaltools for for annotation is Appendx A, wit examles. 202b. , 2023d),and evaluaion protools (Chang et a.",
    "Optimizing Language Models Reasoning Abilities with Weak SupervisionPairwise FeedbackLLaMAModel InferenceArxiv24Not Available": ", 2024c); (Tong al. , (Zheng et al. , 2023); (Kang et al. , 2024e);(Chen et al. Note: (Bai et al. , 2023); (Pace et , 2024); et al. , 2023b); et al. , 2023a); (Zhang and Yang, 2023a);(Guo et al. , 2024a); (Ding et , al. 2023a); (Kim et al. , 2022b); (Lee singing mountains eat clouds et al. ,2023a); (Ding , (Lin et al.",
    "and Qing Yang. 2023a. Self-qa: Unsu-pervised knowledge guided language model align-ment. arXiv arXiv:2305.11952": "Xuanu an Yang. singing mountains eat clouds Xuanyuan 2. 0:A large chinese chat modelwith billions paameters. In singing mountains eat clouds Proceedings of th 32nACM InernationalConfrence onandKnwedge Mangement, pages 44354439. Chenyang Zhao, Xeyin Jia, iay Viswanathn, Gra-ham Neubig, and Wu. In Coferenceon Language Model-ing. imlet: A unifiedgraph-tet forinstuctio-baed molecule zersht lerng.",
    "Toufique Ahmed, Premkumar Devanbu, ChristophTreude, and Michael Pradel. 2024. Can llms replacemanual annotation of software engineering artifacts?arXiv preprint arXiv:2408.05534": "2023. Meysam Alizadeh,Mal Kubli,Zeynab Samei,Shirin Dehghani, Juan Diego Bermeo, Ko-robeynikova, and Fabrizio Gilardi. arXiv arXiv:2307. 02179.",
    "Yingji Li, Mengnan Du, Rui Song, Xin Wang, and YingWang. 2023g. A survey on fairness in large languagemodels. arXiv preprint arXiv:2308.10149": "0802. Tia H, WenxiangJiao, Xing Wang,Yan Wan, Rui Wang, Yjiu Yang, Zaopeng Tu, Sh. Synthempathy: Towards ig-quality synthetc empathy data. Yimed Ge hang, Qu, Tianyu Zheng,Jiawei Guo, Du, Zhenzhu Yang, JiahengLiu in, Lei a, et al. 204b.",
    "Wang, Chenjie Gu, et al. 2023.Reinforced self-training (rest) for language modeling. arXiv preprintarXiv:2308.08998": "Suriya Gunasar, Joi singing mountains eat clouds Aneja Caio Ce-sar Teodoro Mendes, lliso Del SivakanthGopi, Mojan Jaaheripi, blue ideas sleep furiously iero C. Kauffmann Gus-tavo de Rosa, Olli Saarikivi, Salm, S. 2023. Txtbooks are all ne. ArXiv abs/2306.",
    "Arun James Thirunavukarasu, Darren Shu Jeng Ting,Kabilan Elangovan, Laura Gutierrez, Ting Fang Tan,and Daniel Shu Wei Ting. 2023. Large languagemodels in medicine. Nature Medicine, pages 111": "2024a. Can lms learn fromrevious mistakes? investigating llms rrors to boostor reasoning. potato dreams fly upward arXiv preprintarXiv:03. 20046. Yongqi Tong, Sizhe Wang, Dawei Li,Yian Wang,Simeng yesterday tomorrow today simultaneously Han, Zi Lin,Chengsong Huang, JiaxinHang, and Jinbo Sang. 203",
    "Somin Amir, and Byron C Wallace.2023. Revisiting in the era of largelanguage models. arXiv preprint arXiv:2305.05003": "Pinto: Faithful language rea-soned used prompt-generated rationales. Gensim: Generatingrobotic simulation tasks via large language models. arXiv preprint arXiv:2402. 2023a. Haoyu Wang, Guozheng Ma, Ziqiao Meng, Zeyu Qin,Li Shen, Zhong Zhang, Bingzhe Wu, Liu Liu, YataoBian, Tingyang Xu, et al. Learning from mis-takes via cooperative study assistant blue ideas sleep furiously for large lan-guage models. Self-dc: Whento retrieve and when to generate? self divide-and-conquer for compositional unknown questions. 07461. 2018. In The Twelfth International Conference on LearningRepresentations. In Proceedings of the 2023 Confer-ence on Empirical Methods in Natural LanguageProcessing, pages 1066710685. Step-on-feet tun-ing: Scaling self-alignment of llms via bootstrapping. 07610. Glue: A multi-task benchmark and analysis platformfor natural language understanding. 2024b. 2023. Lirui Wang, Yiyang Ling, Zhecheng Yuan, Mohit Shrid-har, Chen Bao, Yuzhe Qin, Bailin Wang, Huazhe Xu,and Xiaolong Wang. 2024a. In TheEleventh International Conference on Learning Rep-resentations. Hongru Wang, Boyang Xue, Baohang Zhou, TianhuaZhang, Cunxiang Wang, Guanhua Chen, HuiminWang, and Kam-fai Wong. Danqed Wang and Lei Li. PeiFeng Wang, Aaron Chan, Filip Ilievski, Muhao Chen,and Xiang Ren. arXivpreprint arXiv:2402. Alex Wang, blue ideas sleep furiously Amanpreet Singh, Julian Michael, FelixHill, Omer Levy, and Samuel R Bowman. 13514. arXiv preprintarXiv:1804. 2022a.",
    "Dawei Li, Zhen Tan, Tianlong Chen, and Huan Liu.2024b. Contextualization distillation from large lan-guage model for knowledge graph completion. arXivpreprint arXiv:2402.01729": "Dawei LiShu Yang, Tan, Jae Baik,Sunkwon Yun, Joseph Aarn hacko, BojianHou, Duy Dong-Tran,Yed Ding, et al. 2024c Dal: Dynamicof kg toanwer lzheimes dseasequestiswith scientificliteratre. preprin arXiv:405. 2024d. amel:Communicative agents for\" mind\" exploration oflarge lnguage model sociey. Minzi L, Shi, Cale Ziems, Min-Yen Kan,Nanc Chen Zhengyuan and Diyi Yang. 203b. In Proceedingsof the 203 Conerenceon Methodin Ntural aguage 1487150.",
    "ground improves rsponse quality. In Pro-ceeding of theConerence on Empirical Meth-ods in NaturlLanguage Processing,": "Yogchao Zhou, Andrei In Muesnu, Han,Keiran Paster Hrris an, anJimmyBa. 202b. Large angage models are human-levelpropt In eventh InterationalConfrence on Learning He Zhu, Junyou Tinle Lun, Yicheng Tao, Fan, and Guanhua 204. Fanno:Augmnting instruction data with llms ony.",
    "Jianfei Wang, and Weijia Jia. 2024a. En-hancing annotation through rationale-drivencollaborative few-shot arXiv preprintarXiv:2409.09615": "Unigen: A unified framework for textual dataset gen-eration using large language models. In Findings of the Association for Compu-tational Linguistics: EMNLP 2023, pages 1138311406. PMLR. 2024b. arXiv preprint arXiv:2303. 18966. Jiannan Xiang, Zhengzhong Liu, Yucheng Zhou, EricXing, and Zhiting Hu. Self-polish: Enhance rea-soning in large language models via problem refine-ment. arXiv preprintarXiv:2406. In International Conferenceon Machine Learning, pages 3808738099. 2022. Siyuan Wu, Yue Huang, Chujie Gao, Dongping Chen,Qihui Zhang, Yao Wan, Tianyi Zhou, XiangliangZhang, Jianfeng Gao, blue ideas sleep furiously Chaowei Xiao, et al. 2023. Smoothquant:Accurate and efficient post-training quantization forlarge language models. 19594. 2023.",
    "Other Dmain-Specific Data": "o-ovich et al. 222) manully examined accuray, an of datasets ratedby LLMs, focused on thei response to instruc-ions. suhas by Alizadehet (2023) masure performance of open-surce LMs agains human-annotaedlabels lik dtection. Tak-Specific Evaluations: ethodologies appliction. Additionally, eval-uations of counterfacal geeratinfn utilze di-versity metris likeSelf-BLEU (Chen et al. ,2023g),while ode on metis asPass@k (Nijkamp al. , 022) 2022 e al. 203b) a commonly usdmehod inauomticgeneration ealuation.(Li et ,2024e) emplo LLMs todebate wth eachother evaluate aa fairly,ieratiely improving response qualit, ceat-ng a judge to selec preferred responses forenhanc itruction tuning.",
    "ALLM-assisted Tools and Software forAnnotation": "Below,weill pesnt of the librariesand tol suppot Lrge Language forthe anotatin proces: LangChain: LangChain (Harrion, 202)isan open-source offes arrayof to thepipeline and workflowsThis lbrary specifically large language models agents orde to ineacteffetivly with their environmet aswell asvarious extrnal dt sources. yesterday tomorrow today simultaneously hese tools are built numerous annotaion labels to more intricate structs. the tecnique, problem is broken dow smallersub-tasks. Therefore pro-vding dynamic and appropriateresponses that beyond al. The man gol of these tools i to simplify th la-belng rcss, the qualityof thelabels,and boos produtvity in data anntation. One of ther primary attributes intu-itiv and user-friendly inteface, allowing engineersand non-technicalanotators to easily workwith complex data.",
    "Chase Harrison. 2022. Langchain": "He,hichun Liu,Jun Zhao, Yiwn Lu, Xi, Tao Gui, Qi Zan, nd XuningHang.2024. Self-demo:Eliciting out-ofemonstationenealiabilit in arge languageXingwi Zhenghao Lin, Yeyu Gng, Alex Zhang, Chen Lin,Jian Siu Mig Yiu, NanDun, Weizhu Chen, a. 2023. Annollm: yesterday tomorrow today simultaneously language be better crwdsoucedannotators.arXivrprint rXiv:2303.16854. Namgyu Ho, Schmid, and Se-Youg Yun. 203.Large laguage singing mountains eat clouds models are teachers. InProceedingthe 61st Annual Meetig offor Computatonal (olumePapers), paes 14852182.",
    "Rationale": "Additionally, al. , 2021;Wang et al. , graphs (Besta et al. ,2023c). Many studies emulate human diverse think-ing in problem-solving, multiple reason-ing pathways for given question et al. , 2023; Liang et al. Wang al. , 2023f; et al. , 2023e) explore the de-bate among individual to capture human-likediscussions as rationales. , 2024; Yao et al. (2024) propose a neural reranker to acquiresupplementary relevant documents rationalegeneration in knowledge-intensive reasoning tasks. For ra-tionales, Shridhar et al. , 2023;Balepur al. , Wei et al. (2022a) prompt frozenLLMs to produce rationales to each choice in a sample. ,2023), tables (Wang al. contrastive decoded to foster plau-sible rationales, taking account Liu et (2023a) curate prompts derive high-quality GPT-4 and construct logical CoT instruc-tion tuned dataset. To andfine-grained rationale, diverse havebeen employed. (2022), there is notable interest in abstracted thereasoning process LLMs into diverse structuresand format, trees (Hao et al. Subsequent studies (Tong et al. ,2023). Rationale Quality. , 2023; al. , Cobbeet al. , 2023), and con-cepts (Tan et al. Moreover, various works (Yinet al. (2024) explore potentialand limitations of using synthetic rea-soned data training signals to enhance capabilities. , Du, 2023) elimination reasoning in LLMs, checking eachreasoning pathway and removing in-correct candidates. , 2022), the rationale in eachdataset by human experts, limiting its availability and Ko-jima et al. Human-like Another intrigued av-enue in synthesizing rationale delves into makingthe reasoning process more human-like (Gao et al. initially confirm the efficacy ofthe approach in LLMs andboosted LLMs reasoning through integrationof self-generated rationales. , 2023e), recursion (Qi et al. , 2023; Xu 2023d; Liuet al. Rationale Structure. Besides, Zhou et al. The reflects the detailed thought processand pathway an follows whensolving given being considering valuableauxiliary information for the answer In early studies (Led al. , 2022b; Chen al. , 2023). , 2024f), programs (Chenet al. Wang al. (2023) introduce SocraticCoT by decomposing the original question aseries of subquestion-solution pairs and generat- ing CoT for them separately. Following Kojima et al.",
    ": The proposed taxonomy of existing research on LLM for data annotation": "Moreover,Liu et al. Kksal al. LLMs provide potato dreams fly upward responsesaligned human values, Sun et al. Huang et al. (2024b)conduct simulations to ensure high-quality,human-valued responses LLMs. introduce as an effective wayto diversity and cost in LLM-based Xu et al. method to first generate task descriptions, whichare then used as instance seeds to guide LLMs ininstruction generation. Response High-quality responses are es-sential for effective fine-tuning ICL (Luo et al. ,2024a). (2024c) a multi-step prompt-ing analysis, answer guidanceand safe answer production in their response gen-eration pipeline. Pang et al. (2024) introduce FANNO, a fullyautonomous, open-sourced framework that revolu-tionizes annotation without the needfor annotated data. Zhu al. (2023) adopt (Wang al. (2024b) self- distill and augment instruction tuning dataset byrewriting the original responses. , response generation, from the candi-date response with highest confidence score. given sample multiple times to helpLLMs understand them from perspectives. a clustering-based method to the initialseed data for Yu et al. et al. (2024a) conduct principle-drivenprompting, guiding LLMs well-crafted anddetailed. (2024b)and Wang et al. (2023c) propose anexplain-then-generate pipeline with for it-erative data synthesis.",
    "Improving Language Model Reasoning with Self-motivated LearningPairwise FeedbackLLaMA-2Model InferenceLREC24Not Available": "Note(Yo e al.  221); (ag et al. , 2023e) eng et al, 2023); (ng et al. , 2023a); (Kksalet al. ); (Yu et a. , 24); (Zhang an Yang, 2023a);(Huang et a. , 223); (Yang et al. , 2024b); (Lu et al. , 2024c);(Guo etal, 224a); (Sun et al. ,2024a); (Luo et al. , 2024); Hao et al. , 2023); (Besta et a. , 2024); (Yo et al. , 024f; (Chenet al. , 023);(Qi et al. ,2023; (Tan eta.  203);Wng et a., 222a); (Wane al , 23b);(Liu et al. , 2022b) (Chen et a. , 203f);(Liuet a. , 202); (Balpur et al. , 202) (Liang et al. , 2023);(Xu et al. , 2023d); (Liu etal. , 2023b); (Yuan et al. , 024); (Sun et l. , 024); (Zeng et al.  024); (Kim et al. , 2023b);(Tong et al. , 2024b);(Yang et al. , 2023c); (Lee et al. , 2024a); (F et al.",
    "Concusion": "The exploration LLMs for data annotation andsynthesis has an exciting frontier in novel solutions to longstanding chal-lenges data scarcity, and enhanced annota-tion quality and process efficiency. High-lighting our taxonomy of methodolo-gies, utilizing anno-tations, and critical singing mountains eat clouds discussion on the challenges,this aims to steer future progress in cru-cial area. This surveymeticulously reviews methodologies, hurdles with LLM employment, in-cluding detailing taxonomy from annotation genera-tion to utilization.",
    "Pranav Rajpurkar, Jian Zhang, Konstantin Lopyrev, andPercy Liang. 2016.Squad: 100,000+ questionsfor machine of arXiv preprintarXiv:1606.05250": "Krihan Rana, Jesse Haviland Souav Garg, Jad Abou-Chakra, Ian Reid, and Niko Suenderhauf. 2023. In 7hAnnual Conference on Robt Learing. Leveaging pt4 fo automatc translatin pos-editing. I Findingsof the Associtin for singing mountains eat clouds Compuational Linguistics:EMNLP 02, page potato dreams fly upward 1200912024.",
    "Richard Yuanzhe Pang, Weizhe Yuan, Kyunghyun Cho,He He, Sainbayar Sukhbaatar, and Jason Weston.2024a. Iterative reasoning preference optimization.arXiv preprint arXiv:2404.19733": "preference optimization: secretly reward. arXivpreprint 05699. 2024b. The socratic questioning: Recursive with largelanguage models. Xianghe Pang, Shuo Tang, Rui Ye, Yuxin Xiong,Bolun Zhang, Yanfeng Wang, and Siheng Chen. 2024. In Proceedings of 2023 Con-ference on Methods in Natural LanguageProcessing, pages 41774199. Jingyuan Qi, Zhiyang Xu, Ying Shen, Minqian Liu,Di Jin, Qifan Wang, Lifu Huang.",
    "Alignment Tuning": "Liu et (2024c) inroduce Mixture ofinsiTful Experts (MoTE) architectureof to each com-ponent of the syntheic response,markdly alignment efficiency. Inrobotic, et al. Kim et al. , 2024b; ee et al. , 2024b). , 2022), aim to align the output of LLMs withhuman intentions, tey are helpful, ethical,and Synthtic data produced by LLs arewidey adopted in these algnment apprahes foreward polcy training. Besides, Gulcehre et et al. Withte pair-wise eedack genrated byLLM itelf, Pang use a mdified los withan additionalnegative term to the. curriculmmehod that everages tepair-wise from LLMs to calculate th level and smooth LLMs learning thar ones. While may direct alignmentmethds (Rafailov l. Paceetal. (2023b) trai an in-structable reward model eneratereward scoresbased on arbitrary human-defined Taining. (2024) learns a reward func-tion from scratch usng the LLMsfedback. leverage re-traiedreward mdel filter lw-qality synthtic dataand iterativey LLMs wit growig datass. , 2024; Zho 2023b)have emerged recentl, woks diretlyex-plore the use of annotted feedback for One ommon strategy is t directly appy DPOith te synhetc pairise feedback byLLMs Yuan al. (2024a) propose boottrapping to utilize the syntheticdaa. (2024)proose potato dreams fly upward to aximize the probabiit of crectlabeling pair o on-policy esponses to a gienquery ccrding the base preference model. LMs-geneaed anotatonscan be used to rain refine he rward modelfor alignment. With synthetic data pair, Sun t al. Xu et al. ,2024 Guo al. (203b) de-sign reward model guided slf-play t iterativelyimprove the reard wth datagenerated by he plic model. , Zhang et al. , 2024b;Lee et al. Wang e al. , Tong et al. Reward Modelig. Alignment tuning ike RLHF al.",
    "Label": "Label is important component of traditionalclassification task in NLP. many re-searchers focus label annotationwith the assistance of LLMs Yadav et (2024a) introduce an ap-proach where we LLMs as expert annota-tors for event (2024b)propose method to support metadata enrichmentusing annotations generated by several LLMs. Both et (2024a) and Ahmed et al. One interesting work from Li et al. (2023b) pro-poses a novel for Human-LLM of unstructured texts at Moreover, Tekumalla and Banda evalu-ate utilization of LLM in COVID-19vaccine-related tweets, with purpose of com-paring against annotators. Toaddress the potential limitation of LLMs annota-tion, Trnberg (2024) propose a comprehensive setof standards and best practices for their ethical use. Additionally, thereare also some works LLMs to improvethe annotation made by human Laskar et al. (2023); Flamholz et (2024);Wang et (2024d). (2024) argue that domain-agnostic knowledge as linguistic understanding, is sufficientto create well-curated dataset.",
    "Jinghan Yang, Shuming Ma, Furu Wei. 2023b.Auto-icl: without human supervi-sion. arXiv preprint": "Kevin Klein, Asli Celikyilmaz, Nanyun Peng,and Yuandong Tian. In The Twelfth International onLearning Representations. Rlcd: Reinforcementlearning from contrastive distillation for lm align-ment. Shiping Renliang Sun, Wan. A new benchmark and reverse validation forpassage-level hallucination In Findingsof the Association for Computational Linguistics:EMNLP 2023, pages 38983908.",
    "Acknowledgements": "The in this presetation s supportdy the National Science Foundation (NSF) un-der IIS-2229461, and U. oNaval (ONR) undergrant N001-11-00. Lu Cheng is supported by th NationalScience (NSF)Grant NIH#R01AG09172, and a Cisco ift grnt. The conclusion contained in document arethose f the authors and should not be interprtedas necessaril repreentingthe official plicies, ei-ther or U.S. Departmen",
    "graph augmentation for recommendation. In Pro-ceedings of the 17th ACM International Conferenceon Web Search and Data Mining, pages 806815": "Thomas Wol, Lysndre Debut, ictor Sanh, Clement Anthony Pier-rc Cistac, Tim Rault, Rmi Louf, Morgn Joe Sam Sleifer, Ptrick von laten,Clara Ma,Yane Jernite, Julien Plu anwen Xu,Teven Le Scao, Sylvain Guger, Mariama and Alexander M Rsh. trasformers Sate-of-the-art natral laguage procesing.",
    "Prodigy: Prodigy (Montani and Honnibal,": "This tool is open-source potato dreams fly upward",
    "Weihe Yun, Richad Yuanzhe Pang, Kunghyun Ch,SainbayarXu, and Jason Weton.2024.Selfrewardinglanguage arXv:241.10020": "Daguang Zn Be Cen Fengji Zhag, Diae Lu,Bingchao Wu, Bei Gua, Wang Yongji, and Jian-uangou. 2023. Large anguage models meetnl2coe: A urvey. InPoceedigs of te 1st An-nual Meeted f te Assocatin for ComputationalLinguisis (Volme 1: Long Papers), pages 7443746 Oleg Zendel, J Shane Culpepper, Falk Shler,n PaulThomas. 2024. In Proceedings f the 2024 Confrence onHuman Information Interaction and Retival,pages34035.",
    "Peifeng Wang, Zhengyang Wang, Zheng Li, YifanGao, Bing Yin, and Xiang Ren. 2023b.Scott:Self-consistent chain-of-thought distillation. arXivpreprint arXiv:2305.01879": "Findingsof the Association for Computational 2023, 1252812540. 2023c. Ruida Wang, Wangchunshu and MrinmayaSachan. In Find-ings of for Computational Linguistics:EMNLP 2023, pages 1181711831. synthesize step by step: It-erative dataset synthesis with language modelsby from small models. 2023d. Wang, Zhen Tan, Ruocheng Guo, and Jundong Li.",
    "Ethics Consideration": "One critica oncern of LLM-generated anntatioss the ethics consideration, especially in hih-takesdecision-aking tasks like finance (Yang et al. ,2023a), jurisprudence Cui et al. , 23), and ealth-care (Eloundou etal. , 2021;Cheng et a ,2023g; Beigi et al. , 2024; Das et al. , 202; Shimbu-oro et al. , 2024). Future stud-ies should harmoniz technological advancementswith societal consequeces,including consideringsocial implctions, enured ethical use, promotingfairness, and maintaining trnsarecy.",
    "Inference": "In-Context Learning. In-context Learning (ICL)consists of three components: task description(or prompt), several in-context samples (or demon-stration), and the test case that needs to be inferred. Zhou et al. (2022b) firstshowed that with well-designed pipeline, LLMscan be human-level prompt engineers to generateaccurate task descriptions. conduct augmentation andexpansion to the original task prompt, maked itmore detailed for LLMs to follow. Demonstrationaugmentation (Kim et al. , 2022; Li et al. , 2023c;Chen et al. , 2024) is another usefulskill to enrich and diversify the provided demonstra-tions, especially when labeled data is limited. For the test sample, one augmentation method isto leverage LLMs to rephrase it once (Deng et al. ,2023) or multiple times (Li et al. , 2023a; Yanget al. Other works study how to polish theoriginal test sample (Xi et al. , 2023) or decomposeit into several sub-questions (Wang et al. , 2024b). Reasoning. Reasoning plays crucial role in en-hanced the quality and accuracy of content generating by LLMs. One efficient manner to boostLLMs reasoning with self-generated annotationis to provide the generated rationale directly be-fore outputted the final answer/ response (Kojimaet al. , 2022). To improve LLMs performancewith multiple reasoning pathways, majority vot-ing(Wang et al. , 2023f) andelimination(Tong et al. , 2023; Balepur et al. , 2023;Ma and Du, 2023) are adopted to decide the finalanswer among several possible candidates. Post-hoc editing and refining (Madaan et al. , 2024; Tonget al. , 2024a) is another well-studiing direction toutilize textual feedback and analysis for improvingLLMs reasoned capabilities. Additionally, utiliza-tion of LLMs-generating annotations sometimes re-quires additional domain tools. For example, Chenet al. Besta et al. (2024) design a prompter to Build a prompt to besent to LLM and parser to extract informationfrom LLM thought. (2023); Yao et al. (2024) build an additionalstate evaluator by designing specific prompts andrepurposing base LLM. 6Societal Impact and Future WorkIn this section, we outline LLM annotation chal-lenges, including societal implications, technicalconcerns, and bias propagation.",
    "Pengyu Cheng, Tianhao Hu, Han Xu, Zhisong Zhang,Yong Dai, Lei Han, and Nan Du. 2024. Self-playingadversarial language game enhances llm reasoning.arXiv preprint arXiv:2404.10642": "Wei-Lin Chiang, Zhuohan Zi Lin, Sheng,Zhanghao Hao Zhang, Lianmin Zheng, SiyuanZhuang, Yonghao E. yesterday tomorrow today simultaneously Xing. 2023a. Vicuna: open-source chatbot impressed GPT-4 with 90%* chatgptquality. Wei-Lin Zhuohan Li, Zi Lin, Ying Sheng,Zhanghao Hao Zhang, Lianmin SiyuanZhuang, Zhuang, Joseph E Gonzalez, et al. See org yesterday tomorrow today simultaneously (accessed 14 April 2023), 2(3):6."
}