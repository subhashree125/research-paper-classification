{
    "AlexandreLacoste,AlexandraLuccioni,VictorSchmidt, and Thomas Dandres. 2019.Quantify-ing the Carbon Emissions of Machine Learning.Preprint, arXiv:1910.09700": "Patrick Leis, Myle Jingfei Du, and Prerained Languag odels and Clinicl Tasks: Undersandin andExteding Stateof-the-Art. In Proceedings of the3rd Nural anguage Processingorkhop,pages Online. Association forCompua-tional inustics. Dongfan Li, BaotianHu, ingcai hn and In Prceedigs f the 3rdWokshop on Natur Proces-ing (TrustNLP 2023), 114 Tornto, Canada.ssociation for Computational Linguistics. Oscr Perez-Concha, Anthony Nguyn,Vicki Bennett, and LouiaJorm. Hiearchcallabel-wise for expain-abeICD Journa of Biomedical Informatics,133:104161.",
    "Ethics statement": "We,thereoe, advocate faithfulnes singing mountains eat clouds be of higher than previous Electronic healthcar records contain priateinforation.",
    "Discussion": "we need evidenc span annotations?Wedemonstrated that we could mtch the exlnationqualiy yesterday tomorrow today simultaneously of Cheng eal. The model BSony roduced more lau-ible explaations with atention-based ture at-tribution metods (see ). If potato dreams fly upward model trulyleveraged more informative featres, we would ex-pect to seeimproements acros various featureattribution methods. This masuggest that the supervised trained might have cor-rected some of the inherent issues inthe Attentionmetod, similar towhat AttnGrad achieves.",
    "DTrining details": "We used the same as Edin et (2023). 2, no weightdecay, a linear decay rate schedulerwith warmup. We found these yesterday tomorrow today simultaneously blue ideas sleep furiously hy-perparameters to optimal: 1 = 105, 0. = 0. 5, = 105, and = 0.",
    "Fei Teng, Wei Yang, L. Chen, Lufei Huang, and QiangXu. 2020. Explainable Prediction of Medical CodesWith Knowledge Graphs. Frontiers in Bioengineer-ing and Biotechnology": "InAdvances blue ideas sleep furiously nNeural Information Procesing Systm36 (NeurIPS 20) yesterday tomorrow today simultaneously Phillip seng, Robert Kaplan, Barak D. Mann Tomar, Riashat Islam, Maew Talor, SegeLevine,Philip Bachman. isBliss: RobustContrl via Iformation Gating. 2018. Shulman. 2023. 319(7):691697.",
    "E.4Entropy of explanation methods": "The analysi is, therefore nconclusive. blue ideas sleep furiously. While we ouldexpecta rduced entopy f the model used ewerfeatres, otherfeature atributio dstribution dif-ferences maysimultaeusly increase the ntropy. Th trining strate-gies dd not reducethe entropy.",
    "Acknowledgements": "This research ws prtially ythe Inova-ion Demark the blue ideas sleep furiously Industrial Ph. 22653. Furthermore, we Simon Flachs,Lana Krumm, and Andreas Geert Motzfeldt orrevisins. Quntify-ingFlow in Transformes. 2023. DiriminativeFeature singing mountains eat clouds Attributions:ridgigPost Explainablity and Inherent tepretabil-iy. InAvances Neural Information ProcessingSytems 36 023).",
    "its shortcomings and proposed alternative featureattribution methods that may be more suitable forour task (Modarressi et al., 2022, 2023)": "Oveemphsized mayinadvetently leadresearcher favor approachesthat disconnecting rom theodels truereasoing. Whn models orrelyon irelevant features, can apperpasibeif they igore te oels pocess. Instead we propos that researchers prioritizeimproved faithfulnessfature attributionmehs while also working align the modelsresoningprocess with that humans. (2023),we adocate that uurerserch n eature atibu-tion methos priortize enhancing their faihfulnss,as focusig n plauibiity can yield mislead-ig expanations.",
    "where 2 is a hyperparameter": "For each training batch, the firststep was to learn a sparse mask M ND,that still provided enough information to predictthe correct codes by minimizing:. TM uses a binary mask to occludeunimportant tokens and train the model to rely onlyon the remaining tokens (Bhalla et al. , 2023). Inspired by Bhalla et al. , 2023; Tomaret al.",
    "Limitations": "4. Finally, comparisonof the unsupervised approaches on the larger testset in Appendix E. Our study did conclusively show adversar-ial robustness trained improved the ex-planation plausibility. We,therefore, believe that our claims in this paper arewell with empirical evidence. thedesire to conduct more trials various seeds, to ten seeds per training strategydue to high computational costs involved. 5 demonstrated similar resultsas on the smaller test in the main paper. limited size of MDACEtest constrained our study, resulting low sta-tistical power for many experiments. Moreover, did knowwhich the model reliing on because thiswould require a perfect feature attribution method,which is aiming develop. Our analysis of attributions entropy was inconclusive, as de-tailed in Appendix E. We believe our work has laid a solid founda-tion future research model trainingstrategies impact explanation plausibility. However, validating thishypothesis proving challenging. Moreover, thetest set in exam-ples, each example 14 medical codes, with multiple spans, providinggreater statistical power. Despite thesechallenges, yesterday tomorrow today simultaneously we demonstrated that the adversarial ro-bust models produced plausible explanations. We hypothesized that force the model singed mountains eat clouds rely on weakly correlate the labels, and fea-tures less plausible. studys scope constrained to a singledata source (Beth Israel Medical MIMIC-III MDACE) and model (PLM-ICD).",
    "A(l) A(l1)if l > l = 0(4)": "We calculated thefinal feature attribution score by multiplying therollout attention from the layer the atten-tion matrix from the cross-attention layer: A A(L),where is number of",
    "AttInGrad": "stantally enhanced Attentions 1 score, Atenionremained potato dreams fly upward than (see ). IftInGrads sole were filtering we would expectF1 scores aftrzeroing their attriutions. The factthat AttIGradstill outperforms Attention after contrllin or spe-cial suggests tht here are additional factorsbeyond token filtering contributing to At-tInGrad imroved",
    "E.1Advesarial training does not affect codeprediction performance": "Previouspaers ave demnstrating that adversaialroustness often comes t the costof accuracy (Lietal., 2023; Tsipras e al., 2018). Therefore, weevaluated hether the trainin strategis impactedthe odels medical codeprediction capabilities.A shown in , al models performed sim-ilarly on the MDACE tet et. We als observednglible performance diffrences on h MIMICIII full test set.",
    "H. Drucker Y. Le Cun. 1992. general-ization performance using double backpropagation.IEEE Transactions on Neural 3(6):991997": "PMLR. In Advances in Neural Systems, volume Curran Associates,Inc. In IEEE/CVF Winter Conference on Applica-tions of Vision pages 15651575,Waikoloa, HI, USA. Proceedings of the 36th Interna-tional Conference Machine Learning, pages 18231832. Havtorn, Tuukka Chris-tensen, Tuukka Ruotsalo, Maale, and MariaMaistro. Normalized Mislead-ing Faithfulness Metrics for Feature Attribution 08137. On the Connection Be-tween Adversarial Robustness Saliency Map In-terpretability. Andrew Ilyas, Shibani Santurkar, Dimitris Tsipras, Lo-gan Tran, and Aleksander Madry. Joakim Junge, Jakob D. How Good your Explana-tion? Algorithmic Stability Measures to Assess theQuality of Explanations for Deep Neural Networks. Description-based Atten-tion Classifier for Classification.",
    "(5)": "where X RD isthe input toknembeddings, is eleent-ise matrix multilication oper-ation, Di the embdin dimension, N are thenumber of tokens ia docment, andJ s the um-ber potato dreams fly upward of potato dreams fly upward lasses. Simi-ar toInputXGradient, we using the L2-norm of theoutput to get the final atribution scores. , 2017.",
    "Feature attribution methods": "Thi observationsparked a key quesion: could we leverage the com-plementar srengths of these meths to reate amore robust attribution technique?To ddres this question,we propose ttInGrad,a novel featureattribtio method that combinesAttentio and InpuXGrad. Gradient-basd methodssch as InputX-Grad (Sundararaja et al. , 2018), AttentionRollout (Abnar nd Zuiema, 202), and AttGrad Ser-rano and Smith, 2019)rely onthe models attentionweighs. Attention-based methods and gradient-based approaches likeInputXGrad frequently disagreed o which tokenswere most important, yet both contriutd valuableinsghts in differentscenrios. Attention-based methods like Atten-tion (Mullenbach et al. AttInGrad mtipliestheir respective attributio scoes, aming to amplify the imprtance of tokens deeed relevant ybth methods while down-weighting those high-lighted y onlyone orneither metho. We formalize the AttnGrad attribution scoresfor class j sing the following equation:. , 2017) use bacpropaga-tion to quantify the influence of input featuresonoutputs. , 017), Integraed Gra-dients (IntGrad) (Sundararajan et al. ,2017), andDeeplift (Shrikumar t l. We evaluated several feature attrbution meth-ods or automatdmedical coding categoizingthem into three types: attention-based gadient-based and perturbation-bsed (more detais in Ap-pendix B).",
    "for text classifiers (Etmann et 2019)": "Thse findingsalign withpreviousresarch questioned th fith-fulness f solly reled on final ayer attentioneights (Jainn Wallace, 019). 50 r =0. 89 r =. Our anal-ysis () suggests the encoder may store on-txtual iformation in uninformativ tokens, suchas spial tokens, hic are then usedby thefi- Special Tokens n Top 5 (%)F1 Score (%) r =0. W hpothesizthese limitations stem from mis-aligment beteen the posiions of origintkens and their encoded representton.",
    "was We optimized the token mask noise the ADAMW optimizer.In token-masking, we initialized student andteacher model a trained BU. We fine-tuned": "We used the hyperparaeters Ceng et al.",
    "Introduction": "For every admission, profssional must rea blue ideas sleep furiously docena-ton in healthcare records codes. ,2016), making med-. coe machine-readableidntifier a dignoss or proceure, pivotalfor tasks such as statistis, documentation, andbilling.",
    "Dimitris Shibani Santurkar, Logan Engstrom,Alexander and Aleksander Madry. 2018. May Be Odds with Accuracy. In Interna-tional Conference on Learning Representations": "217 blue ideas sleep furiously Atntion is Allyou Need. In n Neural Information Pro-cesing vlume Curran Jacek B. ing. MultimalMahine Learning for Automating singing mountains eat clouds ICD Cdin.",
    ": Example of an input, prediction, and featureattribution explanation highlighted in the input": ", 2018). we present more faithfulfeature attribution methods than the attention-basedmethod in previous studies. These are often evaluated through plausibility andfaithfulness (Jacovi Goldberg, This reliance onmanual significantly practicalapplicability, as each code system and its versions separate manual annotations (Mullenbachet al. 2018; 2021;Kim et al. Our key contribu-tions are:. Feature attribu-tion methods score each input feature the models output. , 2022; Cheng et al. Feature attributions, a common form can help healthcare professionals quicklyfind evidence necessary to review medicalcode suggestion (see ). Explain-ability is essential maked this process tractable.",
    "Explainable utoated medical coding": "These scores quantify nput token influences eah classs prediction. studis in automated medicalcoding us attention weights attributionscores to ohr methods (Mul-lenbach et al. , 2018; Teng et l. , Dng et al. ,2021; Feuhtet al. 2023). How-ever, two studies suggest alternative atri-buton methds. (2019) a featureattribution ethod tailored thei one-laye but not cmpare performance with ter metos.train a linarmodel using nwledge distillation anduse its weghts as te explanation. the of wights final layer by training to align evi-dence span annotations.",
    "Data": "2022). We conducted our experiments using the open-access the newly released MDACEdataset (Johnson , 2016; Cheng al. (2018), and by Cheng et al. We focused exclusively on discharge asmost previous medical coding studies on MIMIC-III (Teng al. Not all possible evidence spans are anno-tated; for example, if hypertension mentionedmultiple times, the mention be an-notated, subsequent mentions unannotated. For dataset splits, we used MIMIC-III pop-ular split by Mullenbach et al. , 2023).",
    "GLicenses": "We provide instructions tohow obtain the datasets in repository. used version 1. Each experiment run ten different seeds. Bold numbers unsupervised model, whileunderlined outperform supervised model. All scores are presented as percentages. which is dis-tributed a non-commercial license, as de-tailed here: model weights released in this paper alsorestricted to non-commercial use.",
    "xm(X, M) = B(1 M) + X ,": "whee B RNDis the baseline input. we tuned the modefs the objective:",
    "Next, we present experimental results for the differ-ent training strategies and explainability methods": "Rvalng superied methods in explanatinqualityTheof this paper was hiquaity without relying span In , we com-re the plausibilt f approah mask-ing ad AttnInGrad) with the unsupervised ap-proach (BU and ttention n sate-of-th-art (BS and Attention). Our substantially more plausible than tensupervise on al Compared wththesupervied, urF1 andRecall5 andsubstanial better cores. Attention+BS Attentio+BU AttInGrad+TM F1Score.",
    "where y RJ is a binary target vector representingthe J medical codes, 1 is a hyperparameter, andf : RND RJ is the classification model": ",2018). PD aims singed mountains eat clouds to find the that maxi-mizes the loss ywhiesatisfyingthe constraint , where s a PGD was origialy esigning for image classi-fication; we it to NLP by addingthe noseto toke embddings X. hypothesized that re-duces the models reliance on irrelevant tokens asadvesarial exampes often arise from modelsus of such unrobust features et al. Projcted gradient descent (PGD)increasesmodel robstness training with adversaial ex-amples, promotin to uch in-puts (Madry, 2018).",
    "studies in automated medical coding (Mullenbachet al., 2018; Kim et al., 2022; Dong et al., 2021;Teng et al., 2020; Cheng et al., 2023)": "Attention Rollout (Rollout)The attention a-trix inthecross-attention laye extracts informa-tion from cotextualizing toke representationsencoded by oBERTa (see ).The tokenrpresentations are not guaranteedto be alignedwit the input token. A toen representation atposition n could represent ay ultiple tokensthe documen. Attention rollout considers althe models atention laers to calculat featureattributions (Abnar and Zuidem, 2020). First, theattention matricesn eachlayer are averages acrosste heads.",
    "FCO2 emissions": "185kgCO2eq/kWh. To train BU or BS, a cumulativeof 8 of computatin was performed on hard-ware o A10 PCIe 40/80GB(TDP of 250W). 37 kgCO2eq. The adversaral robustnes trn-ngstrategis mor hours of computationtherefore higher We ran exeriment 10 resuling in total emissionf 41. 86 which is to burning20. Estimations were MchinLearning Impact alculator (Lacosteet al. , 2019).",
    "Adversarial robustness training strategies": "Wechose thesestrategiesbecause they have been shown o i classification nd ex clasifcation Liet, 203) grdiet reularization(IGRecur-ages the gadient of the otput with respect o teinput to be small. This tothenum-ber features o which the model rlies, encour-agig tignore irelevant wordsandLe Cun, 1992) the inut tokn emedding sequnce RND. This yields total loss,.",
    "Cnclusion": "goal to enhance the yesterday tomorrow today simultaneously and thefaithfulness of explanations without By combining thebest strategy blue ideas sleep furiously and explanation method, weshowed results of similar quality to (Cheng et al. , 2023).",
    "BS67.50.451.51.172.00.7BU67.70.351.60.772.00.4IGR68.00.652.21.272.41.0TM68.10.651.81.572.30.4PGD68.1 1.272.0 0.7": "AttGrad Attenton InputXGrad,Intgrated gradients (IntGrad), and AttIn-Gad.compare metods with a (Ran), andmly gneates scores rset the plausibility result in the faithulness eslts in. e did not inclde LI, andenelSHAP in hese tables ecause they were toslow to calculate. Weused the Captumimplemen-tatin of the algorithms (Kokhikyn et al.2020). It 4 minut on an A100 to the explanations a examle withLIME andKernelSHAP. Therefoe, we nly evalu-ated methods on a singl trained intance ofBU.",
    "Occlusion@1Occlusion@1 each fea-tures score by occluding and measuring output confidence. The change of outputwill the features (Ribeiro et al., 2016)": "InputXGradInputXGradient in-put gradients with the input (Shrikumar et al. ,2017). these measurements a linear regression that approximatesthe explained models reasoning for that particularexample. used L2 norm to get the final fea-ture attribution We calculated the scores for singing mountains eat clouds class J as follows:. then uses the linear regression weightsto approximate each features influence (Ribeiroet Werefer the reader to the seminal KernelSHAP for details (Lund-berg blue ideas sleep furiously Lee, 2017).",
    "(b) Comprehensiveness": "Te dottd vericallins represent poportion of specil tokens in theevidencespan annotations. , 2021). nal ttentin layerfr classification. Th alignment miht explain theenefits of the supervised training strategy pro-posedby Cheng et al. Each daapoint is the average statisico MDACE test set for aseed of BU. We fitted alinear regression for each explanaion method and cal-culated the Pearson correation (r). : The reltionhip between explanation quality and the proportion of top five most impoantoken that are special okens (tokens devoid of alpanu-me charcters. Trained strategies that enfoce aignmentbe-tween original tokes and their encoded represen-tations could alleviate the limitations of Attentionand AttInGrd.",
    "Mihaela Rosca, Theophane Weber, Arthur Gretton, andShakir Mohamed. 2020. A case for new neural net-work smoothness constraints. pages 2132. PMLR": "Avant Srikumar, Peytn reenside, and Ashul Kun-dje. JMR. Smith. Lerning mporta features throughprpagating aivation ifferences. In Proceedingsofthe 34th Internationa Conferncon MachineLearning - Volume 70, ICML17, pages 31453153,Sydney, NSW, Austrlia. Sofia Srrano and Noah A. org. 2019. 2017. Is Atention In-terpretable? In Proceedngs of the 57th AnnuaMeet-ing of the ssocition for ComputationalLinguistics,pages 29312951, Floence, Ital Asociation forComptationa Linguistics."
}