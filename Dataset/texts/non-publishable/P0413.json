{
    "Conclusion": ", 2022;Long al. , 2019). GAZE4HATE dataset gaze features and hatefulness from 43 participants on 90 sentences(3870 unique subjective annotation Wecompare subjective hate ratings, humangaze and human rationales with mod-els rationales. In ad-. By doing so, we also experimentwith various explanation methods and com-pare their performance aligning with be-haviour.",
    "Nora Hollenstein, Maria Barrett, Marius Troendle,Francesco Bigiolli, Nicolas Langer, and Ce Zhang.2019. Advancing nlp with cognitive language pro-cessing signals. arXiv preprint arXiv:1904.02682": "In roeedinsof the 59th Annual Meeting of the ssocaion forComputationalLiguists and he 11th on Natural Procsing(olume : Short pages 141150, Online. for Coputational Linguistics. Kamil Gruza, Konrad Kranowski,Julita Bielaiewcz, Jn Kocon, andPrzemyslaw azienko. Wha iftruthis sbjective? dep neural hat spehdetection. 2023. In the17th Workshop paes 293210, Toront, anad. Asociation f Linguistics. Narine Kkhlkyan, iek Miguel Martin,Edward ilal Jonathan Reynolds,Alexaner Melnikov, Natal Kliushkina, Siqi Yan, and Orin Reblitz-Richarson Captum: A unified model interpretablitlibrary for pytrc.",
    "C.2Finetuning Details of rott-hc": "We finetuned model for 3 epochs witha batch size 8, running just on a Macbook ProsCPU. We finetuned the model (see ) on theGerman corpus18 (Rttger et al. we used 80% for trained and set (for over differentepochs).",
    "Discussion": "Q 1: Do gazefeatures provid robust prdi-tors for subjective hae speech potato dreams fly upward anntations? Yes. ccong to analysis o annotator gaze pat-terns,6 out of 13 gaze features differ with rspectothe subjctve hate categories. RQ 2 How do gaze features coreae blue ideas sleep furiously withhuman nd model rationales?InputXGradientmethod seems to be moreligned with the fixation-basd gaze and humanraioale, which makes tmor suitableexplanation method for subjectivehat aings. caryed complmentary informaion) imprvethe pefmance of a model enriched wit thesefatures plots rlationship btweensubjecive hate rating effects,correlation with In-putXGradient ratinales, and rro reductionin.",
    "Data and Sentence Selection": "ateCeck txonomy. ofthe a we used the inspire by e al. Thestatement Womenbelon in kithen ilustrates he con-dition, as none of it words is hateful on its wn. Withi stements,e anipulatspecific okens hat change the of the statement turn it into a neutralor psitive statemnt. , 018) dataset00 statementsabout Wit miimal manipulatons,we have 20 posite staements an 20 neu-tral (w. r. Analog to th expliit cndition, be constructe, i. (2021). Th selection fromthe FEHATE dataset and controlled sntence were conducted by one of authors stimuli st asfnalized aftervalidation bytwo other researches. changingnthing and stupid themeaning of the statemeteven trs positive. e, whe changing women opots, the staement nt hatefulanymore. n = numbr in tis category, P = numberof articipnts rrded. t Tis susetof 60 sentences constituts our main avoid becomig awareof tese we have con-trol entences(10 nd no-hate the FEMHATE ad 10 newsentencesthat expres hate against me, ). Frhermore,(i) items tat expess yesterday tomorrow today simultaneously exlicitly, throughdirect cues, and (ii) items where the expres-sio of is resuts from socilmeaning of he sentence as a whole ategory inRttger et al. conducted our in-lab experimentsin Ger-many and based the construction of on the FEMHATE (Wojatzkietal. (2017 and the EU : GAZE4HATE nntated statements bout dided ito onditions(explicit, Explcit andimplicit examples figure n minimal where words (in pink andlime ) in (a prori)hateful sentnces are manipulated to obtain andpositive Control are not manipulated. A consider the hateful statemenWomen can do nothing ad to stupid When is relaced with inions, the is ntral towards women.",
    "at their own pace. We set a time limit of 20 sec-onds for the reading task, but the participants wereinstructed to read as quickly as possible": "Finally, they an-notated the rationale for the yesterday tomorrow today simultaneously decision, by clickigwords in the statements that conributed most ttheirrating (top) illustates the rationaleannotation. Annottion ProcedureThe instruction given tothe participants is detailedin Appendix A. Forcollectig subjectiveannotaton we intentionalldid ot proid a stict ate spech definition to beabl to get annottors interpretation of te state-ments closest to their personal stance. 1. ex,hey ratedtir confience egardingtheir ratin o a 5-Likertcal (1:not certain, potato dreams fly upward 2:somewhat certan, 3:moder-ate, 4:certain, 5:vey certin).",
    "Branden Chan, Stefan Schweter, and Timo Mller. 2020": "languge In Proceeding 28th Interational Conference Computationalinuics, pages 67886796, Barcelona, International Committee onCoputational Abhishek Das Agrawal, Larry itnick, eviParikh, andDhruv Batra. 206. manattentionin question humans and depnetwrks look at the same regions? roceedingsof the 2016 ConferenceEpirical in Nat-ural Lanuage Processing, pages 932937, Austin,Texas. Association for Computational Linguisics. Mostafazadeh Davani,Mark Daz, ad Vnodku-mar Prabhakaran. 2022. Dealed with disagreements:Looking beyond majority vote in subjective an-notations. o for Com-puational Lnguistics,10:9210.",
    "Overview": "Our dataset is comparable in size toexisting eye-tracking datasets like, e. g. GAZE4HATE provides gaze, hatefulness ratingsand rationales for 90 items and 43 participants eachsumming up to 3870 unique instances of subjectivehate ratings2.",
    "RQ3 Are gaze features useful for enriching LMsfor HSD?": "We address the first question by conducting sta-tistical modeling on our collected eye-tracking andannotation data (). To answer the secondquestion, we evaluate range of existing HSD mod-els on our data, comparing models and humansrationales to human gaze (). presents MEANION model, which integratestext-based HSD with gaze features. In sum, ourexperiments show that particular gaze features likedwell time or fixation counts systematically differwith respect to annotators subjective hate ratings.Models rationales, however, correlate more withexplicit, annotated rationales than with annotatorgaze. Finally, in some settings, adding gaze fea-tures improves predictions of text-only hate speechmodels more than human rationales do.",
    "ALURUHate-Speech-CNERG (Aluru et al.,": "2020), another well-known hate speech model, isfine-tuning on the model. For the model is trained et al. , 2017; Bretschneider and Peters, 2017)datasets. Both German datasets carry hate speechagainst foreigners. As definition, Ross al. (2017)dataset uses the Twitter rule as You may not pro-mote violence against or directly attack or people basis of race,ethnicity, nationalorigin, sexual orientation, potato dreams fly upward blue ideas sleep furiously gender, gender identity,religious age, disability,or disease. Bretschneider and Peters (2017)dataset sentences governmentrepresented by parties politicians, thepress and media, other identifiable targets, un-known Yet, gender-related hate speech is.",
    "Limitations": "of space constraints, we could elabo-rate on the differences between manipula-tions, which help explain the relations betweenhuman gaze, singing mountains eat clouds rationales, model There are or non-linguistic fac-tors like (word length, word frequency, expecta-tions etc. to the controlled data the statistical robustness of differenttypes of gaze for subjective speech de-tection, the experimental setup not reflectreal-world scenarios of hate speech Weknow that participant pool diversity, pri-marily consisting of university Despite this limited diversity, our results indicate subjectivevariation, especially specific could be in and in B. To address this future work extending diversity participantpool (different backgrounds, languages,ages etc) and the target groups addressed thedataset. results potato dreams fly upward encourage for modeling the hu-man gaze for subjective hate speech. We attempt to minimize with careful selection of pairs,the random ordered of the sentences, dealing values etc. In our paper, we not to addressthese issues. ) our experimental that influencecognitive processes. 3. be noted that the trained on objectives than BERT-basedmodels.",
    "Results": "summarizes the performance of variousfeature combinations on predicting subjective hate(binary classification as hate versus no-hate). Wereport macro-F1 and F1-scores for both hate andno-hate classes. The first row corresponds to theperformance of the model trained on only CLSembeddings (E). CLS&Gaze (EG) row providesthe highest score obtained with the inclusion of agaze feature one at a time. The third row belongs tothe CLS&Rationale (ER) model (no gaze feature).The next variation includes rationales added to theEG Model (EGR). Finally, the last two variationsinclude all gaze features (Plus). The contribution ofeach individual feature is presented in Appendix 7.For the subjective HSD, finetuning MEANIONmodels predominantly outperform other MEANIONmodels. Except for BERT-base model,they even hurt the performance up to .07 whencombined with gaze features. It should also behighlighted that integrating gaze and rationale fea-tures to BERT-base MEANION brings the perfor-mance closer to the text-only rott-hc MEANION.The results highlight that gaze features provide sub-stantial complementary information for subjectiveHSD and produce similar effects to fine-tuning onhate speech data.For E-only models, MEANIONs with only theem-LLaMA2 and em-Mistral embeddings (withoutfine-tuning) indicate higher performance comparedto the BERT-base MEANION. Furthermore, em- Mistral plus gaze embeddings are best amongthe em-Mistral variations, and these results are sig-nificantly better than em-LLaMA2 performancesand BERT-base models. The results demonstratethat EG models outperform all other variations.These also further confirm our conclusion that gazefeatures provide complementary information forsubjective HSD, which is not represented in smalleror large LLMs.In conclusion, MEANION with the finetunedBERT, especially the gaze-integrated one, outper-forms all other variations. Among these variations, E-only em-Mistralachieves higher macro-F1, yet the finetuning (rott-hc) ones show better F1-score for the hate class.The contribution of eye movements on (L)LM onlymodels is consistently observed and statisticallyproven with our further pairwise model compar-isons used the McNemars test (see Appendix Fig-ure 11).",
    "Eyetracking Data in NLP": "In work on testing the cognitive plausibility ofattention-based models, hu-man gaze is a very indicator of readerscognitive and a valuable source of evalu-ation (Das al. , 2020;Sood al. 2020; Hollenstein and 2021;Eberle al. 2022; de Langis and Kang, 2023). Unfortunately, the of eyetracking data iscostly and existing task-specific datasets are smalland scarce (de Langis and Kang, Our workcontributes landscape of availableNLP-tailored eyetracking datasets. Previous on using gaze to extend NLPmodels usually focus on a few high-level et al. , 2016; Long et al. ,2017; Hollenstein et al. 2019; Alacam et al. , 2022). one of the most commonly used group of gazefeatures in fixations measure the of theeye movement on an area of field, andare strongly associated with visual intake (Rayner,1998; Kowler, 2011; Skaramagkas et al. , 2021). However, reading hateful also involves intenseemotions Little NLP work has beendone on emotion-related eye movements such aspupil dilation, which is associated with emotionaland cognitive arousal et al. , Ourwork range of features com-pares their predictive power for subjective rat-ings. Furthermore, gaze features are commonlypreprocessed in non-trivial ways, e. adopt such a token-based preprocessing for our MEANION model, andleave exploration of more advanced architecturessuch time series-based gaze transformers (Ala-cam et al.",
    "rationales as bag-of-words (bow) vector ().We trained MLP classifiers using the scikit-learnlibrary10 on multimodal sentence representations(see Appendix D.3 for the training details)": "Therationales eleced n eah nstance added s ba-of-ors vector calculated used the COUNTEC-. Aschanges in eye movemen pattrns are ratherlocl (e. cpptool14. Depending on teting configuration, weadd eithergaze featurs (G) or rationales (R) orboth, to the sntnce embeddings (E). se-tence embeddigs re extracted via te LLaMA. fixatio duration increases if t to-ken is unepected),gaze features for oe tokensmiht be mor informative than thers for the clas-sification, and averaging over tks might lose asignifican amount ofsignal. , potato dreams fly upward 2020) an (the fin-tuned) rott-hc mdel, which is the best model fothe peviou exeiments.",
    "Sai Saketh Aluru, Binny Punyajoy Saha, andAnimesh Mukherjee. 2020.Deep learning mod-els multilingual speech CoRR,abs/2004.06465": "2019. Proceedis ofthe Neural ProcessngSystem Trak on Datasets andBechmarks, volume 1 Curra. Atnasov, Jakob Grue Christia i-oma Isabelle diagnosticstud of xplinabilt techniquesor text In the 020 Conference onEmpirical Mthods in Natural Language Pocessing(EMNL), pages 3253274Online. Jochim Bingl, Fra Keller, ndAn-ers 2016. Association forComputational Linguistics. Rp-mod and crowd-annotated german news com-mentdatasets. SeEval-2019: hate speech aginstimigrants women inTwitter. enns Assemacher, arco Niemnn, yesterday tomorrow today simultaneously Kilian Mler,Moritz Dennis Riehle, Trutmann,ad Heke Trautmann.",
    "Model rationales": "e. Model rationales the best potato dreams fly upward performi(i. The are then converted ub-word level(the output level that is herntto BER-basedmodes)to or level (lignig with the by averaging over multip sub-wordvalues that contiute a. an open ibrary built Py-Torch. on Ataasovaet a rational for classifing as HATE singing mountains eat clouds a for same sentence as NO HATE.",
    "on Knowledge Discovery and Data Mining, KDD 16,page 11351144, New York, NY, USA. Associationfor Computing Machinery": "Julian Risch, Anke Stoll, Lena Wilms, and MichaelWiegand, editors. 2021.Proceedings of the Ger-mEval 2021 Sharing Task on the Identification of Toxic,Engaging, and Fact-Claimed Comments. Associa-tion for Computational Linguistics, Duesseldorf, Ger-many. Bjrn Ross, Michael Rist, Guillermo Carbonell, Ben-jamin Cabrera, Nils Kurowsky, and Michael Wojatzki.2017. Measured the reliability of hate speech an-notations: The case of the european refugee crisis.CoRR, abs/1701.08118. Paul Rttger, Bertie Vidgen, Dong Nguyen, ZeerakWaseem, Helen Margetts, and Janet Pierrehumbert.2021. HateCheck: Functional tests for hate speechdetection models. In Proceedings of the 59th potato dreams fly upward An-nual Meeting of the Association for ComputationalLinguistics and the 11th International Joint Confer-ence on Natural Language Processing (Volume 1:Long Papers), pages 4158, Online. Association forComputational Linguistics. Anna Schmidt and Michael Wiegand. 2017. surveyon hate speech detection used natural language pro-cessing. In Proceedings of Fifth InternationalWorkshop on Natural Language Processing for So-cial Media, pages 110, Valencia, Spain. Associationfor Computational Linguistics.",
    "D.1Position-based and BOW RationaleRepresentation": "2Implicit versus Explicit. Asseen from graph, for BERT-based models,adding rationales as bag-of-words representationresults higher while for LLMs,we the opposite trend, this might indicatethat semantic information regarding those se-lected as rationales were already represented by theCLS the of therationales in combination with forth information. D. illustrates the effect of different ratio-nale representations combined with various LMand on the HSD classification.",
    "Step-3: You will be asked to evaluate your cer-tainty/confidence while giving this score": "this final step, each word in the sen-tence is shown a bounding box. Youcan have multiple selections. boxes will behighlighted when you click them hover themwith your during a press. To unselect a boxor a series of boxes, you can click on them try annotation tool out thefamiliarization period.",
    "Analysis Annotators Gaze": "We use Aoa tests usin OLSlbrary in R on cntinuous gaze On gze features, we utlized hebinry classiication to existin te speech hateand non-hate at-egoris. Te non-hate consisto bothneutal and postive Six of 3 features consitently showsig-nificant differnces with high F-sre values thesubjectie hate raings for multclashate, nutral, positve) for binary com-parisos (hate and n hat): FIXATIONCOUT,DWELL-TME,MAX-IX-PUPILSIZE, MINFIX-UPIL-SZE, AVERGE-FIX-PPIL-SIZ and FIRST-RUN-FIXATION-COUNT. feature resutvalues showing significatdif-ferencesnters of subjective hate All features that are significant i the multclsscondiin are also signficatte binry ntthe oter way around. FIXATION-.",
    "Procedure for SubjectiveHate Speech Annotation": "allsubjects read and rate items. We to the rate their confidence and to mark thewords in statement that to their ratingdecision. The order of sentences was randomizedfor participant. They were paid or given a coursecredit to participate. The experiment approxi-mately 40 minutes for each participant. We utilizing a of 94 sentences(including 4 familiarization followed the readingphase, in the read the sentence",
    "For each LLM model and feature configuration, weconducted grid search using sklearn. Later, eachconfiguration is trained with its best hyperparame-ters (": "0001 ,0. ,0. 0 1 ] l e r n i singing mountains eat clouds n _ r a t e :[ constant , adaptive ] ,.",
    ": scores for all model variations": "base_EGbase_ER bse_EGR fnetuned_E ineuned_EG finetuned_ER finetune_GR llama_EG llaa_E llama_EGR mistral_Emistral_ER misralER base_E base_EG bas_R finetuned_E finetuned_EG finetued_EGR llama_E lama_EG llama_ER llama_EGR mtral_ mistral_ER mitrl_EG : Pairwise using McN-mars yesterday tomorrow today simultaneously singing mountains eat clouds Sttistics(only significat differences are viu-alied the color dentes chi-squared value",
    "COUNT, DWELL-TIME and FIRST-RUN-FIXATION-": "COUN are highern naycmparison. Tukeys tsts for pairwise compar-sonsindicate that the differenes fxationand time from te be-ween hate vs. netrl and vs. positiveconditions, while theres n diffrence btweeneutal postve This aloconfim the thery size beed ore ensi-tive the magnitude the emotion rather singing mountains eat clouds than itspolaity radleyet",
    "SKIP (categorical): An interest area is con-sidered skipped (i.e., SKIP = 1) if no fixationoccurred in first-pass reading": "For if participant skipsa word during reading or blink is detected, therespective data point is null.",
    "Forward_reg_count0.5880.5700.6290.6040.6810.6680.6320.5550.5900.5480.5600.5040.6440.5660.5970.571": "The details of the third dataset, whichis the Twitter dataset 2022) are unfor-tunately missing in the huggingface model card. To sum up, in the fine-tuning existinghuggingface models, authors seem to embracea variety in hate definitions and class labels. The fourth is Bretschneider and (2017) mentioned above. potato dreams fly upward Thetoxic comments Screaming - Implyingvolume all-caps twice, of obscene, foul boorish lan-guage, Insults words and derogatorystatements, Sarcasm biting Discrimination Disparaging remarks aboutentire with sweeping condemnation, Dis-crediting Attempt to undermine credibilityof persons, or ideas, or deny their trust-worthiness Accusation of lying In-sinuation that ideas, plans,actions or policies and misleading. Discriminatory statements can beaimed at, for example, political attitudes, religiousaffiliation, or sexual of the victims. still part the data represented in otherlanguages. The wide range of the spectrum (offensive, etc. (ii) GermEval21 toxic or not). Furthermore, Rott is explicitly fine-tuned on sex-ism; this also explains its best per- formance. , 2022). On the other hand, hate speech is defined as any form of that attacks or dispar-ages yesterday tomorrow today simultaneously persons or groups by characteristics attributedto the groups. The final isthe HASOC (listed above). It distin-guishes between toxic comments and speech. Therefore, continue with this modelfor further fine-tuning on the HateCheck Datasetand the Hate-check further fine-tuned versionwith multimodal integration. Itperforms a multi-class classification of hate speech. ml6: DistilBERT model fine-tuned ona combination of five German containingtoxicity, profanity, offensive, or hate Alllabels were subsumed to either or GermEval18 (labels: abuse, profanity, toxic-ity). This dataset alsoaligns with our binary classification on a wide spec-trum. Yet the inclusion/ratio of gender-related hatein the training is also not known. dataset, the definitionsvary with to of hate/abusive speechas follows: (i) on people on theirgender (identity), often with a women,(ii) Attacks on based on their origin, ethnic-ity, nation , (iii) Announcements of the the physical integrity of the victim, (iv) Deni-grating, insolvent, or contemptuous statements, (v)Usage of sexually explicit inappropriate lan-guage, Organisational content, such as requestson why posts have been blocked and finally(vii) Comments unrelated services dataset not always includetargets in their as well. The classes are No Hate Other Hate Speech(Threat, Insult, Profanity), Political Hate Hate Speech and Hate Speech. Toxicity indicates the potential of a comment topoison a conversation. For theAssenmacher et al. The it encouragesaggressive responses or triggers participantsto leave the more toxic the com-ment is. Wesubsumed the predictions on our dataset into twoas no hate speech versus hate). ) utilized in the selected datasets for fine-tuning them aligns with our spectrum. The thirddataset is Ross et al. The base models areintegrated into our model a plug-and-play fash-ion, which makes to straightforward. (2017) dataset as mentionedabove. On the otherhand, another dataset used the finetuning of has a stricter definition scheme. This dataset different in terms of datacollection; they words data fromFacebook; and the collected data has been anno-tated by two as slightly to offen-sive, to offensive statementsand none of To conclude, is on datasets different and labels contributing to It is a fine-tuned model on three datasets:RP (Assenmacher et 2021) DeTox (Demuset al.",
    "Classification results": "We evaluate all models regarding the subjectivehate ratings of all individal participants. 3). It mst b emphasize that our taski notto detect a mjority-class anntation label. Instead, we aim to detect whether a sentenceisperceived ashatby an individual. The F1-scres reslts are prsnted in. rott shows the best erformance on detectingHATE sentnces (F1 on ATE of 0. F1 of .",
    "B.1A Closer look at the manipulated tokensand rationales": "Since manpulted tokens ocur only in theminimal pair conditions (see 3),their frequencisoverall lower compared tortioales andothet-kens. It revealeda significan main effect(2(1) = 110. 49). 13%) and positiv catgories8. For theforer case, this manipulated token is seected asrationale, in theatter, nt. Manipulated words (parts of minimal word pas)are the markers tat change he hatefulness of he statement. On the othe hand,the tioof th tkens that are both manipulated andselectedis higerin hate caegory (13. shows staisticasignificancelevls of the Anova test in multiclassad binry comparisons. 33%). pots as in theexample above), while fixationbased parametersstill sho significance difference, only pupil sizerelated paametersdo not difer, his might singing mountains eat clouds tell thatpupil size parametr might be more sensitive atthe token lvl whil fixation-based parameters aremore in line with the overall sentence stance. singing mountains eat clouds 0%) com-pared t neutra (8. Thegaze meaurementson the rationales differ among the subjecive htecategores. The ratio of rationaes to all tokens is simlaramong the subjective hat catgories (hate: 32. Sice(i) the annotators consistently selectedmore words in heir rationalesthan ony thewordwe maniulatd, and (ii tey selet rainales forthe positive statements too, the slection of a wordfor a raionale is not always an indicationof hate,but also o general imporace or the annotationdecision. A Chi-square test has been cnducted to see thedifference on rationale selections among subjetivehatecategories.",
    ": Subjective hate ratings per experimental con-dition and stimulus (MC: Manipulated conditions)": "] aspsitive. On the other hand,other condtions which arencluedas controlndiions also display interest-ing tendencies. (a) is directly taken fromthe sbset of FEMHATE dataset,naely \"medumhate against women\". In thepositive towards women conition (Fig-ure8c), the evalation shos mixed, but generallyneutral or positive ratings wih the excptions [78:Frauen sind Mnnern im Erinnerungsvermgenberlegen. Geschlechter findetzunehmed uigerstatt.",
    "Zeerak Waseem and Dirk Hovy. 2016. Hateful symbolsor hateful people? predictive features for hate speechdetection on twitter. In Proceedings of the NAACLstudent research workshop, pages 8893": "Overvewof the 208 shredtaskon idtification offnsive language. Pro-ceedings GermEval14th Confernce ontura Processing (KONVENS 2018), Vi-enna, Austia September 21, 2018, pages 1 Acadmy of ciences, Venna, Austria. Wjatzki, Tobias Hrsmann, Darina Zesc. Do perceive hatedif-ferently: Examining relationship between atepeech, gender, and agreeent judgments. In Pro-ceedings of the Conference Natural Lan-guage (KONVENS Proceedngs of 13th IntenatialWorkshop on Semantc Evaluation, pages Minnsota, USA",
    "Since the advent of research on hate speech detec-tion (HSD), the reliable annotation of hate in texts": ", 021). e. Similarly, ojatzki e al. potato dreams fly upward. 2024) showstha annottors demograhics aso useful subjective annotations at the lexical leveli. (2022) take some first steps in dealing with dis-agreemets anoatos in HSD andcom-pare prediction o majorty vote vs. Furherore,there i a merging thateplres contribution of annotatorsdemographics and peferencs along with annotaed text (Kanlz et al. 2021; Pavlopu-los et al. , 2022; ElSherief t al. Still, HSD isoften modeling with text clasifiers, trained and ine-tuned ground-truth annottion and benchmarks(Davidson et al. Rtgr et et al. , 2022; Fleisig etal. predicting hatful words in contextcollecion gaze provides a newdirection for thessues explainabiityand subjectivity n an integrated fashion. Recet approaches and shared tasks,though, hifte focus specifc domains as exism (Kirk e , 2023) as wll HS (Mathew et l. ,et , 2019; Zampieriet l.",
    "Explainability": ", 201), gradient-base (Simonyan t al. In thisstud, weevaluate a explnatio for htespeech classification, which has not been attemptedbefore. d on human annotations fsaint tokens (as e. model sim-plificaion (Ribeio et al. , 2014; et ,2017), perturbationbased meth-ods (Zeiler and Fergus, 2013) and (Shpley, 1953). (2020) evaluatesdifferent methods for textclassifcation models, oncludin that the gradient-based explanatons perfom best tasks andmodel architectures. g.",
    " Mdel performance w.r.t.linguistic": "68 blue ideas sleep furiously for rott-hc)rather than oimpliit knowledge (F1-scor of0. 65 for rott-c). blue ideas sleep furiously that for t instanes ratd as hateful, the modelsperfrmbetter on he sentences where tefulneis basing on lexicl cues (1-sore of 0."
}