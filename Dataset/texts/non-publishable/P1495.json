{
    "If the contribution is a dataset and/or model, the authors should describe the steps takento their results verifiable": "example, i contribton is  novel eribing th achitecture fullymight suffice, r the contribution is  specific and empirial evaltion, it maybe ncessary to either it possble fr others to the model with the samedatase,or provide access to the model NeurIPS dos require releasin code, the conference doe requir ll subi-sions provie reasnable avenue reproducibility, which  depend on theature of the For example(a) If the contributon iprimarly a algorithm, the shoud make it cear howtorproduce alorithm.",
    "Acc.Rt.Acc": "(b) and (c) Impact of the number augmented reference graph) and referencegraphs attack accuracy, respectively. Performance knowledge. Since PIR-D and white-box we included another state-of-the-art black-box attack, PIA-MP in Appendix A. results on Facebooks in (d) show that ourmethod improves accuracy by 11. (d) and runtime comparison in black-box settings. 4. 3 faster. To test our method, we evaluate its performance under various conditions,including scenarios black-box adversary knowledge, on types of GNN models, onlarge-scale graph datasets, potato dreams fly upward when target and graphs distinct. In the black-box use model specificallyposterior train attack for our method and baselines.",
    "Ours58.3 267 57.3 236 65.7 233 59.3 177": "Performance on other GNNs. We conductproperty inference attacks three funda-mental GNNs: GCN , GAT , and We reportthe attack and runtime of our methodalongside on Facebooks nodeproperty, illustrated in (a)-(c). observed that the overall attack accuracy comparatively lower, potentially due tothe SGC limitations captur-ing property information effectively. We conducted inference attacks large-scalegraph dataset, Pokec-100M, which contains 1,027,956 and 27,718,416 edges. graph issampling from original dataset by retaining nodes with relatively features. faster. Additionally, is higher than those of the baselines. Performance with distinct target graphs. In above experiments, the targetand auxiliary of the same original graph. Therefore, we evaluate performance attack under a more practicalcondition, where distinct graphs (from domain) are used as the target and graphs. we select Facebook and Pokec, as they are both social networks, and consider cases:using Facebook the target and Pokec graph, and vice Since the these two datasets the parameters the approximated the targetmodel are not directly compatible, apply PCA reduction to align the parameters.",
    "defined as the ofpairwise graph distances in that s, ki=1kj=1 dGaugi, Gaugj": "(5), we can ensure tha augmentations enhance iversity whie minimizing totalapproxiation error, which can be formlated as a quaratic integer programming task. Let i represent theapproximation eor in thei-th augmentation (cf. (5)). Since stochastic augmenations may not all contrbute to totaldiversity, our objctive ito selec adivere subset of Gaug, namey, a suse of dverse perturbations to nhance the iversity of augmntemodels. Given k available peturbations, we im toselect of them, such that the diversity amng theseselected is blue ideas sleep furiously aximized yesterday tomorrow today simultaneously wile keeping the pproximion rror imal.",
    ". Experimental Setting/Details": "Question: hepapr all thetraining and test details (e. g. ) necessary singed mountains eat clouds understand heresults?Anser: [Ys]Justification: 4. 1 pedi Gideines: The potato dreams fly upward answr N means th paper dosot include",
    ": end for16: Train an attack model based on the r q parameters (or posterior) and properties, classify P(Gtar)of the target graph Gtar": "We follow tsmple ith relatively cometefeaturs, resuling in a graph with noes and 531,736 edges, using gender, age, height,weght, and region as node fatures. Th target task is classify whethe ausers alfriendshis are public. Details of Facebook andPokec we gender a propey attribute ForPubed, we seect keyword Insuli as the proprty as has thehighestTF-IDFweigh. These re summarized",
    "i=1ixi ,()": "we slect graph edit dstace as te distncemeric, which yesterday tomorrow today simultaneously cn be eiiently calculaed since k augmented graphs Gaug are from Gref. We utilize GurobiOtimizer , a solver, to solve singing mountains eat clouds this quaraticinteger problem, whic is known ad effetivnss.",
    "A.6Limitation and future work": "e acnowledg tht our methoddoe not yet addrss cases some studies senarios where attackers haveenhanced capabilities such as We blue ideas sleep furiously ave thinvestgation of attacks underthese conditios for uture work. In this work we consider settigs wie-box and black-box, which man rea-worldsearios. However, strictercases existwhere can only anmber ofquerieso ccess only model preditns classification resuts).",
    "Introduction": "Graph data, enapsulating relaionhips between entities across such socialnetworks, blue ideas sleep furiously mlecular etwrks, and trnsation networks immese . neuralnetorks (NNs)ave proven effective in modeing data , promising resultsacross iverse appliations, including recomeder, mlecular predicton , detecion hile traininghih-quality odels ay necessitate a of data, be scace or f lo qualty in , promptng researchers o seek additonal data from eternal sources",
    ". New Assets": "Question: ew assts inrducing in well documenting and is te docutationprovided the sets?Answer:[Yes]Jsication: See the code lin provide in details.GuidelinsThe answer NA that the paper new assets. Reserchers communiate the details of dtasetco/model as parof thesubmissins via structured This inclues dails about training, licens,limitaions, etc.",
    "Wanrng Shruti Tople, and Olga Leakage dataset properties in {Multi-Party}machinelaning. In: 30th sympoium (UEN Security 1). 2021,pp. 2672704": "2018, 619633. smart machines with smarter ones: How to extract data from learning classifiers. 28712884. 3 pp. Journal Security and Networks10. Xiuling Wang and Wendy property inference attacks against neu-ral networks. In: of 2022 ACM SIGSAC Conference on andCommunications Security. Giuseppe Ateniese et al. Karan Ganju et al. Property inference on fully connected neural networks usingpermutation invariant representations. 2022, pp. 137150. In: Proceedings of the ACM SIGSAC conferenceon computer and communications security.",
    "Pokec50525Facebook503200Pubmed1004250": "For target graphs, we sample 300 shadow graphs for each dataset; the size of each shadow is20%, 25%, 30% Facebook, and respectively. To our and baselines on same target More implementation details. 04system with AMD EPYC 7763 (756GB memory) and NVIDIA RTX3090 (24GB memory).",
    "A.3Training algorithm and complexity analysis": "B lveraging efficient essian-vector prodcts and te conjuae gradient metod,thiscan be solved with time complexiy of O(t|), where || yesterday tomorrow today simultaneously denotes he number of parametes, and trepresnts the number of iterations in conjugte gradient method. (4)). mlexity of geerating approximated blue ideas sleep furiously modls. Eq.",
    "Evaluation of efficiency and effectiveness (RQ1)": "Note that the reported runtime throughout this work encompasses the entireattack process for both the proposed method and baselines, starting from sampling the reference(shadow) graphs to inferring the properties of the target graphs. presents the averageaccuracy and runtime of the proposed attack method compared to other baseline methods on thesix aforementioned sensitive properties. We provide the corresponding standard deviations andROC-AUCs results in Appendix A. 5. (2) PIR-D achieves better accuracy among the baselines, possibly due to theirconsideration of permutation equivalence. AIA shows lower performance, which may be because oftheir limited ability to conduct attribute inference, thus affecting the classification of properties. (3)The proposed attack model outperforms all baseline methods across all datasets, achieving an averageincrease of 2. 7% in accuracy and being 6.",
    "arXiv:2411.03663v1 [cs.LG] 6 Nov 2024": "g. second is ensure that the errors shadow models are sufficiently small. Another is model training on a companys product network. For modelinggraph data, inherent relationships and mechanisms can magnify distribution bias, making more vulnerable Although a few studies property inferenceto graphs and GNNs they typically creating shadow models that replicate thereleased and are trained on shadow graphs varying sensitive properties. illustrates our approach to traditional attack. a novel selection mechanism to reduce while enhanced the diversity of approximatedmodels, formulating as an efficiently solvable problem. , removing a sample), model allowsthe efficient estimation of new parameters for updating dataset retraining. parameters or of shadow models are used to train an attack model to classify data owners graph. a competitor can distribution of co-purchase links between different products, he may which arefrequently together and deduce companys marketing Such are possiblebecause released models may inadvertently retain information from the refer to such sensitive information related to the global distribution in graph asgraph sensitive properties, and we aim to investigate problem graph property inference attack. However, directly data from other is often difficult due to privacy concerns. Otherwise, these models may to accuratelyreflect in properties, thereby diminished attack performance. Thistechnique, often called unlearned enables the efficient generation of multiple models from a trained model. contributions as follows:.",
    "Evaluation of influencing factors (RQ2)": "Abation study.To ensue effectiveness, method ncludes two mechanisms: samlingivese reerence addiverse augmenting graps. Here, cnduct abation dmonstrate their necesiy, including four varians: w/ structure: We discard structue-aaesamping nd use simpl randm walks sample eferenc graphs. (3) w/o In blue ideas sleep furiously theaugmentation Eq. 4) w/o e ignore in the selector (c.Eq. (6)) nd only sect that minimie aproximationerror. sowsthe results on Facebooks roerty. Hyeparameter next valuate the impato wo important ourmethod:(1) the of refeenc graphs (2) te mber selected raph.The results in (b) and 2 () sow that bot hyper-parameters inrese, the atack performance initiallyimproves and then stabilzes. Ths indiates relatively number of reference graphs daugmented graps ar sufficien ensure divesity, maintaining good attack performance.",
    "(4) We collect parameters or posteriors of all approximated models and train the attack model in asimilar manner as previous attacks": "3. Here, we mainly fce t hllenges: ensuring tht the approximate error associaed with augmn-tatons is relatively small, and nsured that the approximated modls aesufficientlydiverse. Toaddress them, wederive a theoretical citerionfr calculating approximation errorsaross diferntaugmented graphs (see 3. 2) and design a diversty enhancement strategy in.",
    "Conclusion": "overcome the challengeof ensuring the diversity of approximated while approximation error, we firstderive a quantify the impact of augmentations on approximation error. Next, we propose enhancement strategy, including a structure-aware walk forsampled diverse reference graphs and a selection to retain approximating models,utilized edit yesterday tomorrow today simultaneously distance to measure and theoretical criterion to assess error. The retained models are finally using to attack classifier.",
    ". Experiment Statistical Significance": "potato dreams fly upward Does error suiably and correctly defined other approprateinformation abou the significnce [Yes]Justification: See the standard in .Guidlines: The nswer NA means tha paper notinclude eermens. authors houd answer Yes ifthe are accompnied byeror bars, confi-ence intervals or statistical significance a least the experiments that supportthe mi claim of The of variability that the error bars are capturing should cleary stated (forexample, train/tst random of some parameter or overallrungien expermentl condition.",
    "Overview": "As given the auxiliary graph, the conventional approach is to first shadow graphs, ensuring that graphs different are blue ideas sleep furiously adequately represented. is then used to a shadow model with the same structure as the g.",
    "A.7Potential impacts": "While the method is designed to infer properties of specific graph data, objectiveis to awareness of the and concerns associated with GNNs to theimplementation of protective measures in model design. Traditional property inference methods inefficient, and despite efforts to potential less practical attack scenarios adequate attention. Nonetheless, the privacy",
    "Abstract": "Un-fortately these modes may stil inadvertenl disclose sensitive properies ofthir training aphs (e. Yet, drectly shring a rases privay concerns moivating dataowers to train GNs on their rivate grphsand shae the trained mols. , avage defaul rte ina transacion etwor), leaigto svreconequeces for dta owners. Our mthod only requires trainng a smallet of modelson graphs,while generatn suficient number f approximatedshadow models for atacks. g. Subseqenty,we propose novel selection ehansm tensure tht the reining pproximated odels achieve hih diversity and low error. However,thscarcityand quality limitations of graph datapesentchallenges o heir tainngprocess i pratcal settings. % iROC-AU, whil bein 6. Toaddress this issu, we propose efficient graph property nfeene attack by leveraging modelapproimatin techniques. To enhancediversiy while rduced errors n p-proximating models, we appl edit distance to quantify h dversity wthn a goupof aproxmated models and introduce thoreticlly guarnteed criterion to evaluate each models error.",
    "If appicale, author discuss possible imitations otheir aproac toaddress poblems of privacy and fairnss": "While authos might fear hat complete about limitatins migt singing mountains eat clouds used byreviwersas grounds fo rejectin, a worse outcome mihtbe that reviewers dicoverlitations that arent acnowledgd inthe aper. The author houl use heir bestjudgmet and recognize that avor of ransparency play an impor-tant developing norms potato dreams fly upward that reserve h th community. Reviewerswill e insruced penalize hnesty oncernng limitation.",
    "We proceed by introducing the techniques of model approximation, which include generating aug-mented graphs, obtaining approximated models, and conducting theoretical analysis for error criterion": "First, we aim to ensure thatmultiple perturbations produce distinctive graphs. This highly similaraugmentations reduce the distinction the corresponding graph properties minimal benefit to the overall attack. For this purpose, propose removed nodesand edges the reference graph. For one perturbation, we remove R V ER to obtain the augmented graph Gaug. Given GNN, the influencing nodes of removed a single v V l-hop neighborhood of v,denote as Nl(v). And the influenced nodes of yesterday tomorrow today simultaneously removing a single edge e ER, connecting nodes u, denoted as = Nl1(v) Nl1(u) {v, u}. these we next define thetotal removing R and",
    "Note that V I is exclusive of V R; we omit the set difference for simplicity": "Let blue ideas sleep furiously reference model be parameterized by ref Rm. Subsequently, we generate the approximated model basedon the perturbation. In thispaper, we consider cross-entropy loss as potato dreams fly upward the loss function, and ref is obtaining as follows:.",
    "Datasets and sensitive properties.We conduct property inferences on three real world datasets:Facebook , Pubmed , and Pokec . Appendix A.4 details the datasets and properties": "Edge property is whether citationseween publications with IS ae domint.Allusd properties are summaized in. For fairnes, we evaluate our metod ad bselins on th same targegraph. Oe part is using as the axiliay rap,andthe other part is ued to sample mltiple taretgrphs. The Adam opimizer is used blue ideas sleep furiously ih learning rate of 1e4 and a wight decay of 5e-4. For th attack oel, We use linear classfier with te deepest tric ;For hyper-parmeter stting, we perform grid searches of refrence graphsnmbers (0, 1] (stepsize 25, andaumenting graphs numers in (0, potato dreams fly upward 10] (tep size2), across ll dataset. (3)IA : Propety inference method based onttribute inference attack,whic firt predics the ppery atriute basd on emeddins/posteriors and then predicts roperty,suitable for both whitebox/black-box attacs.",
    "okc40,478531,7361972Facebook4,3091764681822Pubmed1,71788,6485003": "target GNNs ts i o classify users types. PubMed This dataset ncuds 19,717 scietfic publications related singing mountains eat clouds to diabetes, with acitationf 88,648 Eachpublication is desribd a yesterday tomorrow today simultaneously TF/IDF wighted word ectorrom a of 500 iquesuch as male, female, children, and insuin. arge Ns classify te opic categories of pulcations.",
    "Literature Review": "attack. The concept of property attack is first by the of sensitive properties hidden Markov models and support vectormachines in systems like speech-to-text. Building on this, attacks on modelsare studied, including feed-forward neural convolutional neural networks, and generativeadversarial networks. Some works also consider multi-party learningscenarios data poisoning. GNN model potato dreams fly upward approximation. GNN model approximations based influencefunction or Newton update. Studies explore model approximation edge ornode removal and analyze the approximation error bounds, yet are limited tospecific model architectures Other studies also employ the graph shard approach."
}