{
    "Impact of Different Factors": "5 family with mdls of 18B,4B, 7, and14 versions to determine flargemdls demonstrate iproved results We further exlore the potential-pc f text legt n the performance f DCPDDForthis purpose, we peform assessments usngfour iferentegth settings (64, 128, 256, 51) inour PatntIA benchmark to detemine whethershrt text re ore challenging than longertexts. (b) illustrates tat D-DDtill consis-tently outperforms oher baelinesacrossll texlength settings, and the AC score also improes. Model size To invesigate the impac of model sizeon the perforace of DC-PD,we nalyze theQwen1. This section exlorseveral factors that may ifluenete perforance ofD-PDD, incldingtwo potato dreams fly upward method-independet factors (model size adtext length) and two method-dependent factor (therfernce corpusD and hyperparametr a).",
    "Aiyuan Yang, Bin Xiao, Bingning Wang, Borong Zhang,Ce Bian, Chao Yin, Chenxu Lv, Da Pan, Dian Wang,Dong Yan, et al. 2023. Baichuan 2: Open large-scalelanguage models. arXiv preprint arXiv:2309.10305": "Samue Yeom, Iree Fredrikon, andSomesh Jha. Privcy mahne lear-ing: Analyzed the connection to overfting. In 2018IEE 31st Computer Security Foundaions (CSF), page 26828. ng, Jingwei Sun, Yeats, Ouyang,Martin Kuo, Jianyi han Yag, and Li.2024. Min-K%++: mproved baselne detectingpr-trained data from lage language models",
    "was part of the models training corpus, rather thansolely relying on token probabilities as the indica-tor for detection.Like prior works (Duan et al., 2024; Shi et al.,": "Next, use large-scale availabecorpus as reference the token frencydistribution since an LMspetraining corpus isnot usually. Based on the to-ken probablites, we erive a scorepretrainingdata detection. e. , training textshould higher score than non-training to other alibration methods (Carliniet l. , 2021; Zhang al. , neitherrequires addiionl traac-cess requirements on the target LM.",
    "+LUP: Based on CLD, it incorporates the LUPstrategy to compute": "Results potato dreams fly upward ae in. +S: Based on +LUP, singing mountains eat clouds incoporatesthe SFO strategy to compute. Fo Baichuan-13B and Qen1. -14B, strtegies contributeto effectivness of DE-PP owever, fr PT-, we found that he LU strateg did not resulti ignificant peforance improvment that this may e t the settng ofthe hyperparmeter a involved in LUPsrategy.",
    ": studies of DC-PDD": "The Probis also not applicable to GPT-3 since GPT-3 donot the to the next-token predictionprobability distribution across the models entirevocabulary. The is detecting Chinese text, as Chinese charactersdo case distinctions. (v) By evaluatingperformance on the benchmark, exceptfor the Lowercase is evident that methods effective for Chinese-languagepretraining data detection, with our consis-tently achieving the best.",
    "A.2Metrics": "Area Under the ROC Curve (AUC). The AUCscore quantifies the overall performance of a clas-sification method. To calculate blue ideas sleep furiously the potato dreams fly upward AUC score fora method, we need to compute the True PositiveRates (TPRs) and False Positive Rates (FPRs) at allclassification thresholds and plot a TPR vs. FPRcurve, known as the ROC curve. The AUC is thendefined as the Area Under the ROC curve, pro-viding an aggregate measure of effect of allpossible classification thresholds. Therefore, AUCprovides comprehensive, threshold-independentscore that reflects the methods ability to distin-guish between positive and negative cases effec-tively. TPR (true positive rate) at a low FPR (false pos-itive rate).",
    "PatentMIA (Ours)GooglePatent Chinese51210,000 Open-source Chinese LLMs released betweenJanuary 1, 2023 and March 1, 2024": "2024) and onPatentMIA against a range of representative, state-of-the-art methods. , in the commonly used detection per-formance metrics, AUC and TPR@5%FPR, DC-PDD surpasses Min-K% by 8. 6% and 3%,respectively, on existing BookMIA. (2024), between train-ing and non-training data based blue ideas sleep furiously on cut-off dates ofthe target LLM, training data precedes, andnon-training data date. : summary statistics: Each benchmark equal split training non-training examples. g.",
    "Task Description": "Thus,given x and M as nput, a method A for the pre-trainng datadtectin task returns 1 if it preictsthat x is includedin and0 ifit is not:.",
    "Overview": "4). 2). Our method consists Tken robability computa-ton, by querying M with x (. Given piece text x x1x2. (ii)To-ken frequency distribution computation, by usingalarge-sale available orpus D a copus to btain blue ideas sleep furiously n timation toknfrequenc since Ms singed mountains eat clouds retraiig cor-pus is assumd acessible.",
    "Jinze Shu Bai Yunfei Chu, Cui, Kai Dang,Xiaodng Deng, Yang Fan, enbinGe,Han et al. 2023. Qwen technical repor. rXivpreprint arXiv:309.669": "Bidran, Hailey Quentin GregoryAnthon, Herbie Kyle Orien, Eric Ha-lahan, Afla Khan, Shivansu uroit,USVSN Prashanth, potato dreams fly upward dward af, e 2023. Pythia: A uite foanalyzing large potato dreams fly upward language aross training and scaling. In InternationalCofeenceMachine Learning 23972430. 2022.rXiv:2204.",
    "*Corresponding author": "g. Moreover, a lack of transparency aroundthe pretraining data used prevents us from prop-erly addressing data contamination problem(Cao et al. , theMin-K% Prob method (Shi et al. g. , 2023b; Yang et al. The pretrainingcorpus may contain unauthorized private informa-tion or copyrighted content (Chang et al. , \"boys\", \"great\") are generallymore common than the words in x2 (e. Min-K% Prob relieson the assumption that data with higher probabil-ity is more likely to be trained data. Accorded to the divergence-from-randomness theory, the higher the divergencebetween these two distributions, the more infor-mative the tokens are in indicated that the text. , 2024; Dong et al. The fre-quency of a word within the collection refers to thefrequency of each token in the target LLMs pre-training corpus, to which we refer as the token fre-quency distribution. , 2023). higher than those for x2, which may be becausethe words in x1 (e. Therefore, Min-k% Prob will cal-culate a detection score of -0. , 2020; Tou-vron et al. In our scenario, the within-document term-frequency can be interpreted as thetarget LLMs predicting probability for each tokenwith regard to text to be detected, to which werefer as the token probability distribution. E. g. , 2023). 94for x1, which means that x1 is more likely to beconsidering a training text than. , 2023;Mozes et al. , 2023; Brown et al. As theconceptual example shown in figure 1, x1 is a non-trained text and x2 is a training text. 2023; Bai et al. 88 for x1 and -2. (b) DC-PDD computes divergencebetween the token probability distribution and token frequency distribution for detection. , \"erudite\",\"conundrum\"). , 2024) is basedon hypothesis that non-training examples tendto have more tokens assigned lower probabilitiesthan training examples do. , 2024) and, hence,from determining whether an LLMs performanceis due to genuine task understanding or to priorexposure to test data. basic ideaunderlying divergence-from-randomness is that thehigher divergence of the within-document term-frequency of word in a document from its fre-quency within the collection, the more informa-tion the word carries. We can seethat the lowest raw token probabilities for x1 are : A conceptual example: Let x1 represent a non-training text and x2 training text.",
    "A.1Baseline details": "(2021), which assumes access to a referencemodel, Mref, training on disjoint set of trainingdata drawn from a similar distribution and positsthat the intrinsic complexity of x can be quantifiedas Mrefs perplexity for x. A low score suggests that xwas likely part of the pretraining data. Small Ref. , 2021) This is an instance ofLoss Attack proposed by (Yeom et al. Thus, it begins bycalculating the probability of each token in x, then selects the k% of tokens with the lowest probabili-ties to compute their average log-likelihood as thedetection score. A high score suggests thatx was likely part of the pretrained data. , 2024) Min-K% Prob isbased on the intuition that non-member examplestend to have more tokens assigning lower probabili-ties than member examples do. Therefore, it first calculates theprobability of each token in x, then normalizes thetoken probability used the statistics of the cate-gorical distribution over the entire vocabulary, andfinally selects the k% of tokens with the lowestnormalized probabilities to compute their averageas detection score. Followings are thedetails of how they calculate detection score. Consequently, the detec-tion score is calculated as the ratio of xs perplexityunder M to xs perplexity under a smaller modelpre-training on same data. Inthe context of LLMs, this loss corresponds to per-plexity. A high score suggests that x waslikely part of the pretraining data. The detection score is then de-termining by ratio of Ms perplexity for x toMs perplexity blue ideas sleep furiously for the lowercase of x. Min-K% Prob. Thus, detection score is the perplexityof x. , 2021) Similarly to theSmall Ref method, but uses Ms perplexity forthe lowercase of x to replace the smaller modelsperplexity for x. , 2018). 3 detection score is thendetermined by the ratio of Ms perplexity for x tothe zlib entropy of x. (Carlini et al. Min-K%++ Prob. A low scoresuggests that x was likely part of the pretrainingdata. low score suggests that x was likely part ofthe pretrained data. (Shi et al. (Zhang et al. (Carlini et al. , 2021) This method ex-actly follows approach described by Watsonet al. (Carlini et al. PPL. Zlib. Lowercase. , 2024) The un-derlyed idea of Min-K%++ Prob is that if theprobability of the current input token surpassesthe probabilities of other tokens in the vocabulary,it is probable that the input has been seen duringtraining, irrespective of the actual probability valueof input token. , 2021) Similar to the SmallRef method, but uses zlib entropy of x in placeof smaller models perplexity for x. (Carlini et al. The baselines are all based on a detection score todetermine a text x whether was included in the per-trained corpus of an LLM M. Since the assumptionis impractical, the Small Ref method employs asmaller model from the same family of M as a sub-stitute for Mref, and then calibrate Ms perplexityfor x used a difficulty estimate through the smallermodels perplexity for x. The zlibentropy is the entropy in bits when sequence iscompressed using zlib. A low score suggeststhat x was likely part of the pretraining data.",
    "Qwen Team. 2024. Introducing qwen1.5": "Hugo Touvron, Lavril, Gautier Izacard, Marie-Anne Lacroix,Baptiste Rozire, Naman Goyal, Hambro, FaisalAzhar, et al. 2023a.Llama:Open and effi-cient foundation language models. arXiv preprintarXiv:2302.13971",
    "Ablation Studies": "(8). We conduct ablation toexplore effect of strategies using the fol-lowed three method variants: CLD: It serves as the of DC-PDDby averaging all the token probabili-ties to compute a score for detection.",
    "AlecJeffrey Rewon Child, Davd Luan,Daro Amodei, Ily Sutskever, et al. 2019. multitask learner. OpAIblog, 1():9": "Alexandre Sablayrolles, Matthijs Douze, CordeliaSchmid, Yann Ollivier, and Herv Jgou. 2019. blue ideas sleep furiously White-box vs black-box: Bayes optimal strategies formembership inference. In International Conferenceon Machine Learning, pages 55585567. Congzheng Song and Vitaly Shmatikov. Journal of Machine Learning Research,21(140):167. IEEE. In 2017 IEEE sym-posium on security and privacy (SP), pages 318. Weijia Shi, Anirudh Ajith, Mengzhou Xia, YangsiboHuang, Daogao Liu, Terra Blevins, Danqi Chen, andLuke Zettlemoyer. Colin Raffel, Noam Shazeer, Adam Roberts, KatherineLee, Sharan Narang, Michael Matena, Yanqi Zhou,Wei Li, and Peter J Liu. PMLR. Exploring lim-its of transfer learning with a unified text-to-texttransformer. Membership inference attacksagainst machine learning models. Audit-ing data provenance in text-generation models. 2020. 2017. Detecting pretraining datafrom large language models. Reza Shokri, Marco Stronati, Congzheng Song, and Vi-taly Shmatikov.",
    "Related Work": "embership inference atack (MIA) MIA s tee-facto the model when evauatingprivacy oncerns in machine learning modls. First introducedby Sokri et al. Pior MIA research has focedon traditional deep learning models (Sblayrolleset al. , 200;Jagannatha etal. , 2021; Mattern et al. Butrecently, MIA n LLMs has attracted gowingat-ention with vaios applications, inclding exam-inaion of trainig ata memorization (Nasr et l. , 024;Meeuset al. , 223). We consider a difernt type of MA:pretrainin data detection. Petraining ata detection for LLMs.Here, theMIAproblem center on idenifying wether apiece f txt was used by an LLM fo petraining. Accoing to the access conditionsto LLMs, cur-rent retainng data detction methods fo LLMscan e dvided into two categoris: () The white-box stting: assumi oe hasaccess to internaso LLMs, such asweihs and ctivations. (ii) Theblack-box settng: ssuming one can on queryLLMs to compute toke robabilities for te text.There is limitedresearch on the whte-bxset-ting since the internals of LLM are typicaly notdisclosed, renerng detction methods in white-ox senarios impractical. Li et al. (2024) proposeto se the probing technique for preraiing data detection, based on theasumption that texts n-countered duing te LLM pretraiig phase reeresented diferently in it internalctivationscompard to unseen txts. Most researchfouse on th black-box seting,assung tt te toen probability distributn of text can provide crucal informaton abou hetherte tet wa included i the trainn set.(2021) consideredthe oes perplexity for text as an indicator to detect pretraining data fromGPT2 (Radfod et al. , 2019).They further intro-dce three ethods, Zlib, Lowercse, and SmalerRef,that take into account th intrinic compex-ity of te targt tex. More rcently,hi e al. Mi-K%rob tends to classify a on-raining txt composedof como ordsas raining da., 202) i-proves Min-K% Prob y normaling token prob-ablities, bt requres access t the nxttoken pre-itionprobaility distrbtion across the LLMsntire vocabulay, which s unavilable in closed-surce LLMslke GPT- (Brown etal. , 2020). We consider the blackbox setting and calibratethe token proabilities before uigthm forde-tection.",
    "Jialun Cao, Wuqi Zhang, and Shing-Chi Cheung. 2024.Concerned with data contamination? Assessing coun-termeasures in code language model. arXiv preprintarXiv:2403.16898": "Steve Milad blue ideas sleep furiously ShuangSong, Adreas Terzis, and Tramer. 222.Membership inference attacks from firt principles.In 2022 IEEE Symposium on ad Privacy(SP), IEEE. Nichoa Carlini,Florian Tramr,Eric Wallae,Matthew Ariel erbert-Voss, Roberts, To Brown, Dawn Song, UlfarErlingsson, et al.2021. Extracted trainng daa fromlarge langua modes. I 30th USENIX SecuitySymposim Secuity",
    ": TPR@5%FPR scores for detecting pretraining texts. Bold indicates the best performing method. Two-tailedt-tests show that DC-PDD significantly improves over Min-K% Prob ( * indicates p 0.05)": "Pythia, Qwen1. 5, GPT-NeoX nd GPT-3 <s> nOPT Llama,nd inBaichan. (224). , 2023)( 15G) for text dtetion. Correspondingly the hyperpaameter k inMin-K%++ Probis also st to for compar-ison. yesterday tomorrow today simultaneously Llama-B forLlama-13B, GPT-Neo-125M GPT-NeoX-20B,Baichuan-7B fo Baichuan-13B and Qwn1 5-7for Qwen1. For te ref-erenceD compute toke we aof C4 (Rafel et ,2020) ( 15Gb) for etection ak ofChineseWebText (Chnal. 7B, for Pythia-6. 01 WikiMAand PatentMIA tasks, and 10 or Book-MIA. 5-14B. For the baseline imlementation, we set = to th of Min-K% Prbflowing Shi al.",
    "DC-PDD, while showing promising results in pre-training data detection from LLMs, has several": "(i) DC-PDD utilizes reference cor-pus to calculate the token frequency estimate that the training corpus. demonstratedits impact on butnot how optimal value We leavethis issue to future work. This specificity hinders itsdirect application to types data, such as im-ages. Further studies our work larger-scale models will beessential effectiveness of DC-PDDin scenarios involving models."
}