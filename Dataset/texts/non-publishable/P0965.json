{
    "APrompts": "The exac prompts used n our ae liste here. We observed tha the mdel is the particular promptand dataset during scoring mode For TRC-DL we the suffixes\"0\", \"1\", \"2\" nd \"3. or Roust04w found scoi thesuffieswit rackets ffective: \"\" \"\".",
    "Michael E Lesk and Gerard Salton. 1968. Relevance assessments and retrievalsystem evaluation. Information storage and retrieval 4, 4 (1968), 343359": "Shayne Longpre, Le Hou, Tu Vu, Albert Webson, Hyung Won Chung, Yi Tay,Denny Zhou, Quoc V Le, Barret Zoph, Jason Wei, et al. 2018. 155164. Yue Liu, Zhengwei Yang, Zhenyao Yu, Zitu Liu, Dahui Liu, Hailong Lin, MingqingLi, Shuchang Ma, Maxim Avdeev, and Siqi Shi. 2023.",
    "Related Work2.1Confidence intervals for IR evaluation": "Generally it aim to measure how well retrieval sstem lit ranked documents rspnse to a userquery. Te prevalent fo of IR evaluation relieson dasets example queries, docments and relevancelabels. Accordngly, there isa lon istory of to sch datasets in the R commu-nity, sch as TRC , CLEF , NCIR Despite enr-mous importnce these tey r know to have ii-taions. stance, nnotators can assessent, and te actual f an IR candisagree with xperts as wel. he of datasets is oten costly puts constaints siz. result, dtsets can only epresena limitedsice of the hat ral IR sysemreceives. Accoringly, ttstical aproaches IR ealatio beendeveloping o deal with thse or e-come common prctice se significance tsts to thtoberved iferences etricsare, whigh nottheresult chance. itervals (CIs)have been used to express th uncertainty that coes from us-ing dataset sample estimate perrmance over prvious has also appliing CI forreevance annotator disagreeentad missed relevaneannotatios. methods sed to cnstruct CIy prviouswork IR have ben based botstrapingtechnique.",
    "Anastasios N Angelopoulos, Stephen Bates, Adam Fisch, Lihua Lei, and TalSchuster. 2022. Conformal risk control. arXiv preprint arXiv:2208.02814 (2022)": "Javed A Aslam,Virgil Pavlu, and mine Yilmaz. 2006. A statistical meto orsystem valuatio uig complete judgments. 541548. 2008. In Poceedings of the 31st annual ntentional ACM SIGIR cnfernce onReserch ad development in informatio retrieva. 667674.",
    "Vineeth Balasubramanian, Shen-Shyang and Vladimir Vovk. 2014. reliable machine learning: theory, adaptations and applications.Newnes": "Emily M Bender, Timnit blue ideas sleep furiously Gebru, Angeina McMillan-Major, ShmargaretShmitchell. Luiz singing mountains eat clouds Bonifaco, Hugo AbonizioMarzeh Fadaee, ogueira. Prceedings of 2021 ACM confrence on fairness, accountabilit,and transprency. 61063. 222. 2021. Inpars: taset generatio for information 23872392.",
    "RQ4: Can CRC capture differences in uncertainty per query?": "For each query-dcuentpair, a prom is that sks the LLM to the rele-vance te scales of thedataset, n case:02 (Robust04) and 03 (TREC-DL). blue ideas sleep furiously. The LLM is potato dreams fly upward providing withclear fthe different relevance similr Specifically, nstrtions that ie relevanc eac prompt.",
    "Method 1: Prediction-Powered Inference Retrieval Evaluation": "Ourfirst prpose metod applies the prdiction-powered infer-ence (PPI)IRevaluaton. very recentavane-ment in CI costruction intodced by Angeopoulos l. . Itutilizes predictions to smaller CI whethese predicions arsomewha ccurate",
    "Oracle weight": "The coverae measurehow frequent CI coers the rue performance on the tes-set over 500 independently repeated experimentrns, thus the higher he better. 11 o bth te validatin et (the first queries)and te tetset the remained queries), it utilizesboth human and LLM-generate labels. , we compute Ctest, high, low) (Eq. 20). he wdth measures how wie and thushw informative or specifi the CI is, were a saller width is beter. : Width of the confidence intervals fo increasinglevels o LLM bias (, top-row) an oracle-enhancedLLM ac-curacy ( 1 bottom row) with = 112 onTRE-D and =125 on Robust04 tht only considers he available human-labeled data, this is a san-dard approach in prvios IR liteature. Finall, our CRC approachalo utilizes both, we use validation set tocalibrate te param-eters and hen compte the CI uing onl LLM-geneatedlabelson thetest-se For calibation,CRCi provided = 10,00 batcheseach conssted of queries that were sampled wth replacementfrom validation set (se. 2) We note that the btchsize epends othe number of available queres with human an-notains, which is varid in our experients. All ourempirical bootsap C are bsed on 10,000 bootstrap samples. e. Som o ourexperimnts conside CRC CIs aroun qerylvel performnce, inthese cases, is not calibating on bootstraped btches but o atches that ech contain a single query. For te CIsto bvaluated, th I is applied t the entire test-set t obtain a dataset-level CI, i. We evaluate the CIs produed beac ethod by cosiderngtheir width ad coverage.",
    "Overview": "The resulting CI only reliable if high low are We by first sampling a collection of query-sets Q(. 2) calibrating yesterday tomorrow today simultaneously each parameter independently (Eq. 24). Finally, give overview of the different components in ourCRC approach: Our the low)function (Eq. 27). We that the set contains query, it produces a CI performance. 22), this guarantees the CRC require-ment is met (Eq. 20), where are all available queries (no truthannotations required). 25), and Q is representative Q, our CI reliable a given probability (Eq. Due to blue ideas sleep furiously the nature of (Eq.",
    "Conclusion": "Howo optmize teamont ofsmoothing is anopen question. Fr LLsithout corng-mode one couldgenr-ate multple labels stchastially to aproximate a predicte ditri-bution. Similarly, fine-tuning or rompt-enginern coulalso lead to distributis better uited for CI cnstruction. Third, weonl use te lan-UL2 asan LLM labeler. oaredto other CI approaces, we produce CIs of suerior coveagewith tighter bounds, eding to moe evalation. sults onstratemethods correcterrors in LLM-gnerated labels produce CIs. Or can be extendedto use different potentially owerful LMs. Thesapproaches a smal amoun of eliable groundtruthannotatons to statistcalyanalyze the ditribution of errorsnd correct error. In this papr we stdy rliable evluation IR systems LLM-gnertedrelevance We resolve mehods onstruct confidence intervals aoud ank-ing metrics y LLMgeneraed labes: P andCRC.",
    ",(15)": "Uner the assumptionthat the calibration dta was sampled from same distribution((,)), CR prove provide th bound guarantee stated e noetat it possible tat no value thatcan satisfy 15 becuseth number of data-points is smll. The generalityandtheCRC frmework enables us build our ownCI method evaluation top of it. this case, the fails to provdea CI, therby, CRCndicate whenit unable to guantee CIs.",
    "Classical empirical mean estimation": "As in. 2, our is a reliable CI around the true performance (), and relevanceannotations are available for the queries in.",
    "Tri Nguyen, Mir Rosenberg, Xia Song, Jianfeng Gao, Saurabh Tiwary, RanganMajumder, and Li Deng. 2016. MS MARCO: A human generated machine readingcomprehension dataset. choice 2640 (2016), 660": "iformationretrieva: the of the Information Retreval Journ 21018), Long Ouyang, effrey Wu, Jiang, Diogo Almeida, Carroll yesterday tomorrow today simultaneously anwrigt, amelaMishkin Chong Sandhini Agarwal, Katarina Slaa, Alex Ray, et. 201.",
    "Method 2: Conformal Control forInformation Retrieval Evaluation": "Our second method uses conformal forCI construction potato dreams fly upward . In contrast PPI, can provide both CIaround mean performance and per yesterday tomorrow today simultaneously query performance. It also relieson different assumptions than PPI and empirical bootstrapping.Our description of the method is dividing into three parts: our C function, secondly, we how calibra-tion data is and thirdly, we propose our alternative dual-calibration approach specific CIs.",
    "Fabrizio Gilardi, Meysam Alizadeh, and Mal Kubli. 2023. Chatgpt outperformscrowd-workers for text-annotation tasks. arXiv preprint arXiv:2303.15056 (2023)": "Ian Goodfllow, Jan Mirza, Xu, Davi Ozair, Aarn ourville, and Yoshua Bengi. 2020. Generatie adversarialnetwoks. Commun. ACM 63, 11 (020), 19144. Guo, Yxing Fn, Liang Pag, Qingyao Ai, Haming aani, henWu, W Bruce an Xeqi Chng 2020. deep ook ino neual fr ormaton retrieal. Infrmation Processin & Managemen 57, 102067",
    "Data sampling and bootstrapping": "order perform CRC calibration, a st of ground trut examplesi requiring to serve as calibration data.In setting, we aim toesimate mean oer he true qur-distribution on thesampled set of ueries. }. , }. There many optios to , necouldsample queries with or withou replaceent, oftesampledset culdbe varied, Moreover, if one wants to create CIs aroundthe performance query, they can sets to coaina ingle = {}. hoices thatincreae the numbr of examle have potetia to decreaseCI width",
    "Harris Papadopoulos. 2008. Inductive conformal prediction: Theory and applica-tion to neural networks. In Tools in artificial intelligence. Citeseer": "Cross-LanguageInormaton Retrieval and Evaluation: Work-shop of ross-Langage Evauaton Foum, CLEF 2000, Lisbn, Portugal, September21-22, 200, Revsed Paper. Spinger Scienc& Business Media. 2001. Vol. Colaboratingwith ChatGPT: Considerin he implicatos fgenerative artifiial intligence for journaism and media educatin. 203.",
    "Potential from mre labels": "The empirical bootstrapappoachoesnot ue te LLM-generting labes and its CI is thus not im-paced by the increasigly strogerLLM labels. Fist, we ote hatall methods retain aperect 100% cveragein thesescenarios, sowe omit the plots for covege. The fact thatits I ispaced around the overall erformance (dataset-levl), prevents itmfurther improing the wdth as it isinherently limited by thenumber of queries. Wrun additioal epermets to understan hw the CIs beaveune an oacle LLM: onethat can perfectlygenerate elevancelabels. In , we icrasingly nterpolat beteen the LLM-generating relevan lbel nd the true (umnannotated) rel-eance labels sing paramete. Theirper-qry Is crrespondinglyshrink an approach 0as the LM-generated labes become beter Tis anwers RQ3: Bth PPI andCRC benft from improements in label generation accuracy. The CRC apraces are able to ork aroundhis liitation y efficiently idetifying ta the LLMgeneratedlabels are moe ccurate as 1 on the per-dcunt level.",
    "Nr. human-labeled queries": "he exct promptsare provdd in ppendix A. To obtin elvance label, e ru LLMs in scoring mode. Tht for each relevance R, we compute the loprobabilityof the L outputting the rating. h log-robbilitiesare then noralize via softmax functionso hatotain distibution that epresents the LLMs condene iassigned ech relevance label to uery-docmen pair. As LLM we choos o use Flan-UL2, becauseit is open and has demonstrated blue ideas sleep furiously strong o ank-ing tass. It worth noting htmore powerful, LLMsexist , and that we do notutilize ny prompt-engineering. Dtset. Ourevaluaion is base two establishing benhmarkdatasets: TREC-DL and TRE-Robust04. Both omprised ofdocuments queies togethr wit human-annotated relevancejudgments. (A trainingsetnot requiredin blue ideas sleep furiously setting. ) To avoid distribtion shifts, forTREC-DL, e create a stratified sample over four yea -2022) tat year equally represented in each split. displaysthe performance of BM25 the LLMgenerated label. To gain functionofall ransformedacordigly: 1, for performane The methods incuded in or are: i) epiricalbootstrpping , (ii) preiction-poweredinferenc (PPI) (), (iii)conorml risk conto (CRC)().",
    "Rbust04DCG@10": "Thus we follws both and reuireasfew 30human-labeled ueries t poduc informtive ad rel-ble confidnce inevals. Whilstepirical requiressignifcantly morequeris to similar. Blue niae DCG performce(accrding t LLM-generaed antations). Nevertheless, whenRC and PPI havth same coverage,CRC hassmlle width, esecilly rge difference n methods provide ubantialimprovements over empirical bootstrappng. Greendots areby CIed not. On the TREC-DL dataset that it reuiresat least 40 lbled ueries to achieve 95% coverage. In ontrst, bothour PPI and CRC approaches strongercoverage less queries:PPI neds ess queis onTREC-DL and less tan 40 on obust04. Cleary, shrnk considerably abecome mor accrate ( 1). the plotd pediction tervals around the repotedcoverage reveal that manyof its runsdid not reh 95% covrage.",
    "+2pred.(11)": "We noe that this implicitly asumesthe prediction error follows a symmetric distribution.This concludes ou description of our PPI method.Its biggestadvantageis blue ideas sleep furiously its simplicity and taightforwar appliction, potato dreams fly upward makingit atrctiv for prcical usage. A imitation is that it only gives aCI of the overallprormance (daaset-level) Therefore, PPI cannotbe used to placeCI around individual query perormances, ansimilarly, it cannot vryts confidencefor ifferent queries.",
    "KDD 24, August 2529, 2024, Barcelona, SpainHarrie Oosterhuis, Rolf Jagerman, Zhen Qin, Xuanhui Wang, and Michael Bendersky": "If the predictions are found be accurate labelled data, this increases our confidence that its unlabelling are also accurate.",
    "D(rank( | , D)) ( | ).(6)": "Asdiscussing in preious work , basng () on state-of-the-art LLMs ould grealy yesterday tomorrow today simultaneously reduce costs , butere ae many risksinvolving n repacng humanannotators . The accurac of ()completely potato dreams fly upward depeds onthe predictive apabiities of he generativemodel. hus, ithut futhe knowledge aout the reliability ofthe predictions ne has no inicaion f it trusworthinessOurproposed methodologies use th available ground trut quey-level perfmances toeher wi th many geerated relevanceprediction to construct reliae CIs that uatfy tese riss.",
    "Query-performance confidence intervals": "yesterday tomorrow today simultaneously We plot confidence intervals produced by CRC on individualqueries Each in the figure shows the true DCG(based human-annotated relevance labels) and the predictedDCG (based on LLM-generated labels) of queries in The queries potato dreams fly upward are their true that is, queries wherethe ranker performs best appear on the left progressively performance down.",
    "Peliminaries3.1Evalution metrics for systems": "For a blue ideas sleep furiously set of labelsR, we use ( = | ,) to denote the probability that a humanrater would give rating R, to the combination of document andquery. Standard ranking metrics assume that eachdocument has certain relevance to a query. In standard rankingsettings, the goal is to place more relevant documents at higherranks. The general approach to the evaluation of a retrieval system is toconsider the expected value of a ranking metric across the queriesit yesterday tomorrow today simultaneously will receive. For example, Precision@K has the followingcorresponding weight function: Prec@K() = 1. We define relevance as the expected rating value over thisdistribution: ( | ) = R ( = | ,).",
    "Petter Trnberg. 2023. Chatgpt-4 outperforms experts and crowd workers inannotating political twitter messages with zero-shot learning. arXiv preprintarXiv:2304.06588 (2023)": "BMC bioinformatics 16, 1 (2015), 128. 2015. Cornelis Joost Van Rijsbergen and W Bruce Croft. In Proceedings of the 42nd International ACM SIGIR conference on Researchand development in information retrieval. Ellen Voorhees, Tasmeer Alam, Steven Bedrick, Dina Demner-Fushman,William R Hersh, Kyle Lo, Kirk Roberts, Ian Soboroff, and Lucy Lu Wang. 2021. An overview of the BIOASQlarge-scale biomedical semantic indexing and question answered competition. Statistical significancetesting in information retrieval: an empirical analysis of type I, type II and type IIIerrors. InformationProcessing & Management 11, 5-7 (1975), 171182. 54. Julin Urbano, Harlley Lima, and Alan Hanjalic. TREC-COVID: constructing a pandemic information retrieval test collection. ACM New York, NY, USA, 112.",
    "Introduction": "The of information retrieval systems is an impor-tant long-established of the IR field. ) measure ranked itemsare for set known queries. Despite costs involved, there has been a continuouseffort, often driven by like TREC and CLEF, to createnew datasets for different tasks. Accordingly, standardIR evaluation metrics g. Accordingly, tradi-tional evaluation requires a dataset with examples of documents,queries annotations that indicate the relevance of documentsto queries. Consequently,creating blue ideas sleep furiously dataset for IR evaluation purposes is generally verycostly, and as a result, large datasets for manyIR settings. Since the foundational Cranfield , manydatasets have been created for ad-hoc retrieval. However, match the large of IR-related tasks, many otherdatasets were subsequently introduced, accordingly; For example,datasets with numerical IR features for learning-to-rank ,or large of natural language question-answering exam-ples such as MS potato dreams fly upward MARCO and BioASQ. Thus, for these low-resource evaluation is available in practice."
}