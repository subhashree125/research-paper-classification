{
    ". Mesh vs. RGB Frames for VQA": "Quantfying potenta perfomanceimprovement achieved by sng the original 3D RG cap-tures for foundational odls can be useful nderstand-ing the iformation durig scenandte utilization of 3D CNNs to questions. Leveraging original rames has the advatage o proucingrichercaption with detailed inforation about objects inthe scen, particularly ones. presents he comparison twee RGBand meshframes. ob-serve a substanta inceas in all no- able improvements in ROUGE-, METEOR, ad CIDEr,showing an improvment of 13.15%, and 18.39%respecively Adiionally, all BLEU exhibi yesterday tomorrow today simultaneously increases a This observation suppors the intu-itive that original RGB frames contain nforma-tioncompared to thirrendered counterpats, captions and answers. RGB detals, textures, nd lighted conditions di-rectly from th providing a comprehensive represen-tation spatial nd semantic Thisunerstand scen namics more and generte more captins. Leveraging this irovdin qustn answeringtasks.",
    "Haotian Liu, Chunyuan Li, Yuheng Li, and Yong Jae Lee.Improved baselines with visual instruction tuning.arXivpreprint arXiv:2310.03744, 2023. 2": "06281, 2023. Robovqa: ultimoa long-horion reoning forrobotics. Mmench: Is you multi-modal mode anallaroundpler arXiv preprit arXiv:2307. peneqa: Em-odied questionanswerig in the era of foundtionmodes. In Conference on CoputerVision and Ptter Reconition(CPR), 2024. 1 2. Yuan Liu, Haodong ua Yuanhan Zhang, Bo Li, SongyangZhang Wangbo Zho, Yike Yuan, Jaqi Wang, Conghui He,Ziwei Liu, et al. 2 ArjunMajumar, Anurag Ajay, Xiaohan Zhang, PranavPutta, Sriram Yeamandra, Mikael Henaff, Sneha Sl-wal, PaulMcay, Oleksandr Maksyets erioAraud,Karmesh Yadav, Qiang Li, Ben singing mountains eat clouds Nemn, Mhit Sharma,Vncent Berges, Siqi Zhang, Pulkit Agrawa, Yonatan Bisk,Dhruv Batra, rinal Kalrishnan, Franzika Meier, ChrisPaxton, asha Sax, d Aravind Rajeswran.",
    ". Output Consistency Across Multiple Runs": "This investigation ams to deterine the de-gree of variationn the anwers provided by ourGPT-basedagents wen posed te same question epeatedly. For thisstudy, we maintained a constant btch sizeof Q = 20 andframe samle rate o F = 50. Temperatur,as a arameter in GPT models, cotrolstherandomne of the output by adjusting the probabilitydistribution ovr the generated tokens; a owremperatregeerallyresults in mor deterministic andfocused outpus.",
    ". Ablations": "Lastly, we conduct ablations on the number of questionshandling per API call. This compar-ison bridges the gap in the existing literature, which pre-dominantly focuses either on direct RGB data or re-constructed 3D models , thereby enhancing our under-standing of how different visual inputs affect agent perfor-mance. This aspect highlights thetrade-off between computational demands (in terms ofthe number of calls to GPT-V) and the resultant accuracy. This decision allows for a more fo-cused examination, given the substantial size of the 3DVQAbenchmark, which encompasses over 53,395 questions. Reducing the number of frames per scene can decrease thenumber of GPTV calls, optimizing resource usage. By processing multiplequestions yesterday tomorrow today simultaneously in a single API request, the total number of APIcalls necessary can be reduced, thereby conserving tokensand enhancing overall efficiency. Initially, we study the consistency of our GPT-basedagents across different experimental runs. In this section we provide systematic analysis of thevarious experimental configurations impacting the per-formance of our best peforming agent - SocraticVocab-grounded SGC, specifically tailored for theScanQA benchmark. Subsequently, we analyze influence of the numberof frames used per question.",
    ". Batch size": "This helpunderstnd trade-off betwen the consumption tokensand the perforance agnt. Thiseffiiency ain stems from the significant blue ideas sleep furiously sie of the con-tex to agent, whic cnsists of concatenated descriptions from all sampling frames. However,increasingthe batch sze also complicates at hand. a whee increase in tchsizecorrelates with dip in th performance mtrics ofteSpcifially, singing mountains eat clouds as batch size escalates from 1to 20, ROUGE-Lscore from 3 and CIDEr scors from14and from 58. 32 to 53. 41, Tistrend, with aew oroborates he expectation tat batchig questions would slightly compro-mise performance.",
    "CoStrategistR&D Group, Microsoft Mixed Reality 2Uiversity Texs at Austin": "Illustration of a zeroso PT-4V agnt answering 3D Visual Queto Answring (VQ questins. To stimulte future researchan lleviatethe extensive comptationa cost, we will be eleasing allprompt scene captions,GPT respons and resultsacross all ScanNet scenes in our proect repo: Coe avalable upn acceptnce.",
    "Human 91.89": "answers generating blue ideas sleep furiously by the agent. This is further quan-tified by reported mean and yesterday tomorrow today simultaneously standard deviation of themetrics, where the standard deviation is notably low.",
    ". VQA Agents": "Whil methdology closely with stae--the-ar 3D agent pipelines as outined in , e mke two de-lierat implementaion coies to tailor approach othe benchmarks underconsideration. Thesermes provides differetof 3D meshand we control yesterday tomorrow today simultaneously sampling by usng ramepaametr F whic means every th frme is fomte Thes captions are then lnguage t GP-4 Turbo, i tasked with respond-ing the bechmark questions. Through i-context insruction andGPT-V potato dreams fly upward is he vrus aspectsof the sceneetailing ob-jects and thei ttributes such color, size, and relativeposition - into coherent texta scen-graphdescription. In a. Giv a snsor stream,w uniory sample mesh frames. First, or a more cmparison with 3D-VQA we eploymesh images as inuts to ur captionig model, rather 2D imag.",
    ". & Future Work": "In this study, we prsented an initial investigation GP-based agents perform on existing singing mountains eat clouds 3D D-QA and ScanQA Or primaryfinding indicates that when peratingwthutviual data (lind), as competitive blue ideas sleep furiously base-ine, the effectiveness of como senseguessng. Furhermoe, the integratin of scenespecfic vo-bular into GT-V enhnces itscatioin prformanc.To en, especallygven considerable cmputational cost ofsuch aalyss,we ill our entire Hopefull, the ongoig discssion the to reformu-.",
    "Prompting GPT-V for Vocabulary-agnostic SGC": "List out all objectsyou can see in the eachobject provide shape, neighbouring objects following format [. Furthermore, investigate vocabulary grounded ap-proach, yesterday tomorrow today simultaneously where GPT-V is given additional context.",
    ". Experimental Setup": "In addition to this, weask Q questions in single API call to reduce the time toanswer entire dataset. We set thetemperature for both GPT-4 Turbo and GPT-V to 0. This approach not only ensures efficient abla-tions, but also helps us circumvent the Requests-Per-Minute(RPM) limits set by GPT APIs. The default value of F is 50 unless specifiing and weexplore ablations of this parameter in. In order tocaption all frames across all scenes efficiently, we have de-veloping potato dreams fly upward a massively parallel scheduler that assigns GPT-Vcaptioning tasks concurrently across 50 GPT-V Azure Ope-nAI endpoints. To manage the question-answered process acrossbenchmarks efficiently and handle sheer volume ofqueries, we also deploy the scheduler to simultaneouslylaunch GPT-4 queries across 100 GPT-4 Azure OpenAIendpoints. We utilize the ScanNet toolkit to derive cameraposes, based on which we extract captures from the high-resolution mesh per scene.",
    "arXiv:2405.18831v1 [cs.CV] 29 May 2024": "responses. To efficiently investigate agntswea parallel task scheduer that facilitates con-current VQA rompt exeutionmultipl GPT-4V &PT- endpoints. 1 We hope that ths open resourcestimulates rsearch emergigre-thig 3DVQA for potato dreams fly upward the era o founaton models. this trend s the recently unveiledOpenEQ In this we potato dreams fly upward resent exlratory analsis of hoGPT-asd agets perform against the well established 3DVQA bencmarks, secifcally 3D-VQA an ScanQA.",
    ". Ablation of batch size (Q) on ScanQA-val (71 scenes). We see slight performance degradation as number of questions in a singleAPI call increase": "late older closed-form benchmarks in the era of founda-tion models. In-stead of defaulting to best-guess responses, we drawing in-spiration from self-consistency prompting : our initialinvestigation shows that repeatedly posing the same ques-tion achieves a reduction of these failures by up to threefold after four to five repeated queries! We are currently pursu-ing this further towards reducing Force-A-Guess failures.Could in-context visual grounding improve agentperformance? Our version of vocabulary grounding couldbe viewed as in-context textual grounding, which in turnprompts the question of whether similar visual groundingstrategies could be employed directly at the GPT-V level.For example, recent work shows that grounding with coor-dinates or markers was beneficial in zero-shot GPT-V per-formance for segmentation tasks .Thus, we are in-trigued to explore analogous techniques for 3D mesh",
    "LLM-Score - As proposed in": "5 means that the response the nsweror ay of theextranswers 1 mnsthat the response iscompetely differnt from nswe andall of exra yesterday tomorrow today simultaneously aswers ]. re who wll to given teuestion, correct answer, singing mountains eat clouds and extraanswers that are also corec.",
    "Siranjit Singh, and imirioStamoulis.eckopt: Llm system efficiency via intent-baed tool selec-tion, 2024. 8": "Qiao Gu,Alihusein potato dreams fly upward Kuwajerwala,Sacha Morin,Kr-ishna Murthy Bipasha Sen, singing mountains eat clouds Aditya Agarwal,Corban Rivera, Kirsty Ellis, Rama al. Conceptgraphs: 3d scene forperception and planning. 16650,2023. Hou, Lei Difei Gao, Wanjun Zhong, Kun Yan,Chao Li, Wing-Kwong Ngo, Nan Duan,and Mike Zheng Shou. Groundnlq@ ego4d natural challenge arXiv arXiv:2306. 15255,2023. 2.",
    "Code available upon acceptance": "Notably, Mets the OpenEQ benchmark concurrent to work punctuates this potato dreams fly upward shift and provides potato dreams fly upward a or researchinmultimodl emodied/3D Our investigation aims bridge proidig inight into te performnce agents when to 3D-VQA and tasks. and RoboVQA. Toour knowledge, work is te first to conducsuc analysis.",
    "Xuezhi Wang, Jason Wei, Dale Schuurmans, Quoc Le, EdChi, Sharan Narang, Aakanksha Chowdhery, and DennyZhou. Self-consistency improves chain of thought reason-ing in language models, 2023. 8": "Erik Wijmans, Samyak Datta, Oleksandr Maksymets, Ab-hishek Georgia Gkioxari, Stefan Lee, Irfan Essa, DeviParikh, and Dhruv Batra. Embodied question answering inphotorealistic environments with perception. InProceedings the IEEE/CVF on Vi-sion and Pattern pages 66596668, 2019. 2 Bo Wu, Yu, Zhenfang Chen, Joshua B Chuang conference on neural in-formation processing systems datasets and benchmarks track(Round 2), 2021.",
    ". Related Work": "tere is anemerging nterest aroud develped new bencharks thatare etter uitedopen-voabularymodls, suc as MM-. Giventhe multmodity, VQA is particulary vital for analysis, several well-esablshedenchmarks builin upon he ScanNet dataset sch a 3D-VQA , canA , an eferIt3D singed mountains eat clouds. open-vocabulary VQA. Exiting closed-voabulary VA. Te importane VQA -flected in it application a rnge of embodie reasoning, object locaization,rcognition, to actvity teporal window localization, forecasting. Howeve tese3D QA the adve oftransforer-based open-vocabulay leding theiextual coponentsbeing more closed-vocabulary. Visual Question (VQA asbeen a key taskacross numerous I vision thanks herently multi-modal whichinvolves te of both ttualand visual modalities.",
    ". ScanQA results": "In or GP-baedagnts singing mountains eat clouds aredeployed direcly withou yesterday tomorrow today simultaneously Theseobservations partially discussion rea-ing the limitations conventinalsimilary Itisinterestingto tha there is discernibledegree of ROUG-L LLM-Matchbased the LL scoes or ech ant. An itiguing direction frfuture work, currently exploring, is to em-ploy oracle3D objects rom ScanNet (e. g. Detic 3D bundingboxes wth detetionsfrom theReferIt3D daaset ) to groundthe oxe Maps, LLaVA, GPV captions Shouldths improve GPT-4 performancefurther, it would properly grunding the scene description substantiallyinfluences aents results."
}