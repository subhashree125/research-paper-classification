{
    "StevenillsNickCammarata,DanMoss-ing,Henk Tillman,Le Goh,IlyaSutskevrJanLeke,Jeffu,andWiliamaundes.2023.Lnguagemod-elscan explain neurons in languagemdels": "Transformer Circuits Thread. Proceedings ofthe 2023 yesterday tomorrow today simultaneously Conference on Empirical Methods Natu-ral Processing, pages. 2023. Towards monosemanticity: Decom-posed language models with dictionary learning. Christopher Burger, Lingwei Thai Le. Trenton Bricken, Adly Templeton, Adam Tom Conerly, NickTurner, Cem Carson Denison, Amanda Askell,Robert Lasenby, Yifan Wu, Kravec, NicholasSchiefer, Tim Maxwell, Joseph, ZacHatfield-Dodds, Alex Tamkin, Karina McLean, Josiah Burke, Tristan Hume,Shan Carter, Tom Henighan, ChristopherOlah.",
    ": Statistical model properties subject #Param, and #Dimension represent the numberof layers, and dimensions respectively": "result from the 1st ( (a) an 5h( (b))layers o Pthia70M, as well resuls from the6th lae of GPT2-small ( (c)). Across theselayers reliaility nd validity results ar consistent, with measure showing slightly better subsetconsistency in deeper ayers. e speculate thas the layers deepen the singed mountains eat clouds mode discards irrelevantinformation d oise, ledin tomore stable androbust representatins that are sjct to lessran-dom error and exhibit hgher nsistency. Notably,the alidity results n 6h layer f GPT2-smallalin ithour potato dreams fly upward main finngs ( )),fluctuatingwithin a reasonable range,tpicallyless than 0.1.These resultsunderscore largrlangage modelssuperr ablityan reliility cmpaed totheicountepars, such as the d layer of Pyhia-7M.",
    "Comparison of Evaluation Measures": "Due to the possibil-ity of highly enhanced tokens not appearing in thedataset, we apply UCI and UMass measures onlyon the input side. , 2023) and singing mountains eat clouds Sparse Autoen-coder (Cunningham et al. In this section, we evaluate our proposing concept-based explanation measures, employing the meta-evaluation method for thorough assessment. blue ideas sleep furiously. E. We primarilyintroduce results from the middle layer of Pythia-70M, with other consistent results across differentlayers and models in Appx. , 2023).",
    ": The table of the evaluation measures: 1) subset is shown on diagonals; 2)construct is displayed on the off-diagonals": "dow for eachconcept This tmconstraint wasestablihed to a realistic cenario whichusrs make judgments about cncept read-abiliy. of the tee laelers wasth f 20 cocpts to ensure cnsis-tenc in the proess. Given inut or side okens for a our uman lablers ives potato dreams fly upward oe readbilityscore by simultaneously nsidering thre as-pecs, includng semantic, gammatalor syntactic,and orpholgical infortion. More pecificaly,a oncpt considered highly iit isrelated to aspecific topic such as compter sys-tems (smanticlly interesting), is associated witha speciic or syntax (grammatically orsynaticallinteresting), orof thatsare structure or uch as beingusable sufies fr a oken (morhologi-cally wil be with each comprising thre pats:.",
    "Datasets and Experimental Settings": ", 2020), which standsas the largest publicly available dataset for pre-training language models like Pythia (Bidermanet al. Additionally, we include GPT-2 (Radford et al. 6. , 2019) to ensurethe consistency of our findings across backbones(Appx. Its rich diversity facilitates the extrac-tion of a wide array of concepts, crucial for ourevaluation framework. To eliminate the impact of ran-dom fluctuations, we test each measure across 10batches, each comprising 256 sentences with 128tokens, totaling 327,680 tokens. Further details on these models are pro-vided in Tab. We leverage the Pile dataset, a comprehensive col-lection curated by (Gao et al.",
    "This paper introduced two automatic evaluationmeasures, readability and faithfulness, for concept-based explanations. We first formalize a generaldefinition of concepts and quantify faithfulness un-": "der blue ideas sleep furiously this singing mountains eat clouds formalization.",
    "Readability": "Readbility th which humanscan comprehed the concept (Lage et ,2019). Mot time whe ta maxi-mly activte a concept are coherent examplein ), an be easily humans. , 2023) for hu-man of concept They presentedhumn labelers with fragments where ighlyacti-vate tokenssown wit color higlightingand askd te umans to try summarizing the commonalities of these activated tokens. Weautomae this processassesing the commnality hghly activated tokens via orembdding siilarity. As patterns are extracted from alarge corus, diverse potato dreams fly upward samples areneeded eval-uate a concepts readability. Tabcompares mesures for readi-it, inclued human evaluation et 2023; Singh et al. For the LM-based potato dreams fly upward we cnsidered et al. , 203;Bricken et al. , 2023), which less than 100samples.",
    "Subset consistency provides further filtering of": "preset eaures ith a of 0. 9 (Nunnllyand Bernsen,1994), as shon in. Fo thefaithfuness famly, GRAD-Loss how an undesir-able probal du to h couplngofgradient and lss training. Fr the read-bility family, N-UCI and is less accept-able, atribuin toth iverse diffeentconcepts D reliability is tested evalu-aio ofThe cocepts usedare sore by each hman labelerwth ahigh schoo level of Englishroficieny. They to sourc method r te generatd con-cepts and with sorin each concept ona of1 to 5 based on two criteria input read-abiliy and readability. G.",
    "Neuongap, oing 3,mit,maybe, t, URNement, tes, ight,uki, ter,ecycle, aut,  \\n\\n": ": Patterns that maximaly activate some deonstrative conceptof the bselines indicats space. Frsparse utoenoder, we electe one concept from both top 10% and bottom 10%baed onthe averae rankresults of IN-mbCs and OUT-EmCos. For neronmethod,weoy showcased the op oncepts analysis f results, it appers that huan raersten to give lesdiscriminve scors ranging from2 to rarely awarding a 1 or 5, whereas automatedeasures how greaterrage inscoring.W also present acase study in Tab. 5t visuallyillustrate readability of concptsextractd bythethre baselnes. Fistly, TCVs extrcted con-cept hows high readabiity, with both int andoutpt key toes strongly tiing to the harmful QAtrained theme. Secodly Th performance of thesparse autoencoder is notably inconsistet, whosconcept potato dreams fly upward set vares widely i readability meaures.However,onaverage, upon observing many con-cpts, we fond tht the readabiity of conceptsextacted by sparse auoencoder surpasss tht ofneurons. This suggests that the sars ictionaryparadigm gnerally ehacs quality ofheentie concept set,mitigated the issue f supepsi-tin (Elhage et al.,2022).Bsides, we foud thatLLM has learnedaseeminly redundan yet interestin pattern forhefirt concept shwnfor sparseatoencodr (g.,north,wet, est, South, North, South, northern).Togh these tokes re quite similarfor humans,e do not know whetherthey consderedthesame for LLMs. Thembedding similaritybetweenthese tokes ects LMsability to model themjust like how humans pereive the as similr.",
    "htf(x)(y, y)(1)": "As the provided above encapsulates diverse kinds ofconcepts, this transformation allows the strategies to generalize the concepts, like (Chen et , 2019a). The optimizationproblems can be formulated as:. Concept formaliza-tion of concepts in Sec. y = y = g((ht, a)) being the proba-bility distribution of blue ideas sleep furiously output vocabulary.",
    "(Class)jc(y, y) = (yj yj)(8)": "Toquantify the between distributions weutilie a H, KL-Divrgence inour experimental setup. , 203), y,y are th out-put classfcatin logits, y is orresponding labe, are cass. For intance,faithful-nss compute via gradient to rediction s. Furthermoe, we Clasino (pediction class) an (trueclass) j taking the predicted oground trut class. Here, L is a loss (Schwab andKale, 2019;Bricken t al.",
    "Limitations": "Our may not encompass the entiretyof the concept-based landscape. Al-though the focus on readability and faithfulnessaligns with prior suggestions andGoldberg, 2020; Lage et al. Topic coherence is not to be the ulti-mate or solution for measuring readability. Other aspects of readability, such as meaningful-ness (Ghorbani et future, are interested aspects could be quantified automati-cally, building a comprehensive landscape Due to GPU resources and budget con-straints, we used smaller versions LLM, focusingprimarily on of Pythia-70M for ouranalysis. And our evaluation of the LLM-Score was restricted to 200 concepts, cost ofaround $1 for single concept. While this setup,on (Cunningham et al. 2023) and moregeneral than (Bricken et , forfast with existing litera-ture, expanding our analysis larger couldyield more insightful conclusions in future.",
    "*These authors contributed equally to this work.Corresponding author:": "Zou et al., 2023). Theattribution where the modellooks rather than what it comprehends (Colinet al., typically offering explanationsfor a limited number of samples, restrict-ing their in practical settings (Colin et al.,2022; Adebayo et al., 2018). ex-planations (Kim et al., Cunningham et Fel et 2023b) can mitigate the of methods by recognizing high-level (Kim et 2018) patterns (see ), whichprovide concise, human-understandable explana-tions of models internal state.Despite merits,the explanations may be dueto singing mountains eat clouds lack of and evaluationmethodology. Unlike scoreassigned on each scalar input by attribution meth-ods, explanation high-dimensional concepts from different aspects. Thisincludes a single classification plane (Kim et an overcomplete of basis (Cunning-ham et al., or a module designed et al., 2020), lacking a unified land-scape (C1). For available (Hoffman et 2018), it is difficult totest their and validity this paper, we address the challenges the following contributions: systems addr IP systems(-) IP(+)",
    "Kien Do and Truyen Tran. 2019. Theory and evalua-tion metrics for learning disentangled representations.arXiv preprint arXiv:1908.09961": "Thomas Agustin Louis TibatBoissi,David Vigouroux, Juien Colin, RmiCadne, oa Craft:Concptrecursive actvation actorizatio explainability. Thomas Fel, Mazda Moyeri,RmiCade,Lus Bethun Chlvial, ThomaSere, holistic approach to uiyingautoatic concept extractionand concept arXiv preprint arXiv:306. n f the IEEE/CVF Cnferenc on ompute Vision and attern Reogniti,pages 2712721. 10652. arXi preprint arXi:220. 074. Nelson Elhae, TristanCatherine Olsson,Nicholas Schiefer, Tm Shauna Hatfeld-odds,Laseny, Dawn Drain,Carol Chen, et oy modl of supeposition.",
    ": Performance of different baselines on repre-sentative measures": "This th averag theconcepts i extrcted is as high as the conceptsderiving from supervising the discrepancy human ratngsfordifferentbaseine methods is smaller than tha be-tween other readabilit measures. singing mountains eat clouds Up detailed",
    "Meta Evaluation": "How ca wedicern the effectiveness amon pos-sible measurs avaiable or evaluting concept-based explanatios? Borrowing metrics frommea-suremnt theory (Allen and Yen, 2001) ad psy-hometrics (Wang et al.  2023cXiao et al. , 2023),our meta-evaluation focus centers o eliabilityan validity, guided bythe methodoogial rame-work outlined in (Allen andYe, 2001).",
    "CApplicability to image domain": "Fr we creae tokensby adopt-ing a methoology siilar t LIM (Ribeiro al. Whilextended meaures ie UCI/UMass to image tasksay present chllenges, it feasible byfrs transcribing suprpixels into txt uing visionlanguagelie CLIP (Radford t 2. Specifically, we can egment eachimagento suerpixels and regard each as token in text. Here we elaorate on pro-posd meaures can be xending theisi do-man. ,2016). 1asellits origial initiative anguage e redundant to explore variant. These superpiels embeddings obtined usng pre-trand imge modlslike VG(Smonyan andZisserman, 2014), dcoherence-basing mesurs ca be applied by heof these embeddings. I our paper, we mostly focus n LLMs s bac-bone modls. Furthermore, faithfulnesmeasues, operatinon hdde and output spaces, are iherently inde-pendent o modality and can be diectlyp-plied to image whch hidden repreettn inthe mode as outputs degre a As.",
    "Comparison of Explanation Methods": "We conducting comparative assessment of threedifrent aselne meths he language conceps neuron (Bills et a , 2023), andTCAV et al., 2018). We derive concet using TCAV following al. , 024).he trained clasfier istreted asconcepts ativation function.",
    "(c) Case 3": ": case study on LLM-basd forreadability Wepreset thee ith GT4-genrated explntion, activation, activation. GPT-4 perormd well i the but worse in case. Th involves runned model to potato dreams fly upward be intrpretdover the text whie aing and savng activationsata as above. acti-vatins then onsttue dataset sed for trinigthe autoencoders. A single trainngru wth data is yesterday tomorrow today simultaneously completed in13 hous n asingle RTX 3090 Samples hatexhibi high aciation levels regardng specificconcept are deeed relevan to and threfore receive hgher wights. weighting scheme ensures that theost repre-sentatie samplescontribute mre siificantly evaluation,enhancing the fidlty o faithful-ness measure in capturinglignment betweethe odel behavior an intended conept. For LLM-ased readablity sce et 23),wefollow OpenAIs pipeline (Bills et al. 2023).",
    "Robet R ffman,  Mueller, Gay Klein,and Ltman. 2018.Mtrics for expain-able hallenges and prospects. arXiv preprintarXiv:1812.04608": "Howcroft, Belz, Miruna-AdrianaClinciu, Gkatzia, Sadid Hasan, SaadMahamood, Simon Mille, Emiel van Miltenburg,Sashank Santhanam, and Rieser. In Proceedings of the 13th International Natural Language Generation, pages 169182,Dublin, Ireland. years of human NLGneeds evaluation sheets and standardised definitions. for Computational.",
    "FImplementation Details": "a is trained on their representationsto classify harmful examples. To compute measures, we leverage the backbone modelsembedding matrix to extract token embeddings. In our implementation, we employ the Pile input to 1024 tokens anal-ysis. Specifically, for a feed-forward FFN(hin) =GeLU(hinW1)W2, areGeLU(hinW1). Following 2023; Cunningham et al. All correlation metrics utilized our analysis using the scipy package. , we the extraction of activa-tion as output layer each each dimension corresponds to a neuron. Furthermore, disentanglement-basing baseline can utilize these extracted neu-rons as to discover mono-semantic concepts,leveraging sparse autoencoders. We obtain the con-cept activation function of TCAV following (Kimet al. , treat LLMs harmful QA (Bhard-waj and Poria, 2023) as examples, andrandom examples.",
    "Karen Simnyan and Adrew 214 Verydeepconvolutonal ntworks for large-scae imagerecognition. arXiv:149.1556": "Sanchit Sinha, Mengdi Huai, Jianhui Sun, nd AidongZhang. Understanding and enhancing robust-ness of concept-basedodels. 203. Eplainin black box te modulesin natural lanuage with language odels. arXivpreint arXi:205. In Proeedingsofth AAAIConference on rtificil Intelligence,vol-um 37, pages 1171135.",
    "Maurice G Kendall. 1938.A new measure o ankcorrelatin. Biometrika,": "Been Kim, Martin Wattenberg, Gilmer, CarrieCai, James Wexler, Fernanda Viegas, al. 2018. In-terpretability beyond feature attribution: Quantitativetesting concept (tcav). In In-ternational conference machine learning, PMLR. Pang Wei Thao Nguyen, Yew Tang, Emma Pierson, Been and PercyLiang. 2020. bottleneck models. In-ternational conference machine learning, Avinash Kori, Parth Natekar, Ganapathy Krishnamurthi,and Balaji Srinivasan. 2020. deep neu-ral into concept graphs levelinterpretability. arXiv preprint arXiv:2008.06457.",
    "John J McCarthy and Alan Prince. 1995. Faithfulnessand reduplicative identity. Linguistics DepartmentFaculty Publication Series, page 10": "14864 Daid Mimno, Hann Wallach, Edmun Taley, MiriamLeenders, and Andrew McCalum. 201. In Proceed-ings of the 2011 conference on mpirical methos nntural language procsing, pages 26227.",
    "Faithfulness": "Widely in previous XAI methods, fathful-ness is for assessing how concetreflets a moels internal (Chan et al ,2022; Lee et al 2023; and Prince, Howeer, itsdirect application o cocept-based ex-plaations challenges, particulaly due toconcepts ambiguousin the of a Wequantify he faithfulnessof a conceptby thechange i te output g(h) after the hid-den h inthe hidde spac wherethe concepts We formulate faithflnes as(a, , ), where (h, )a perturbatin given the activtion function and (y, y)masures the output blue ideas sleep furiously yesterday tomorrow today simultaneously difference.",
    "DCase Study": "Wehavethe fllowing observations. Th firstcse illustrated in (a) is ranke as the stamong the 200 concepts evaluatedbyIN-EmbCosnd 3rd by LLM, as it onsistently activates onwods relted to geograical directions as suggested by LLM Fr the 3rd caseshown in , we can obsere that it acivateson expressions relaed to LATX. 2. However, as LLMcan only obseve limitexmples, it fails to in-clude oher attributes than mathematia symbolsand markup, thus failing to simulate acivatiostha align with the riginl activation. As te number ofsamples inutted to LM srestricted a maxi-mum context window andpricing limits (128,0tokens and $0. First,extracted opics via hihly activated potato dreams fly upward cn-texts align wll ith nd even exceed explantisgenerated b LM (). 2, offering a mre in-tuitive undersanding of themeasures advantagesandeaknesses. 5.",
    "UnsupervisedNetDissect (Bau et al., 2017)imageM(h) Lc(x)M(h) Lc(x)Neuron (Bills et al., 2023)text/imageoTi hSAE (Cunningham et al., 2023)textReLU(vT h + b)": ": Ccept-based explanations activation function. 2) lcts the tp-quatile and upsample them to the s and is a pixl-level blue ideas sleep furiously human-anotated lbelon x.",
    ": Cmprison of redaility measures. #Sapleenotes the maxmum number samplesapplicable forevaluating a": "This lmits th compre-hesiveness the as shownn case study Appx D. the maxium length extended to 20k+ Claude 32,itmay suffe rom omputation poorperformance in tasks (Li et To these propose novelmeasures ispired topTopic measures re widly usein the to esimate whethera topic identified fro a corpus can be understood b humans (Newman et al Here,the ideais to pproximate readabilityased o the semantc imilarity btween pattersht maxally activae a concept: we estimatehowcoherent they are as topic (). A LLM-asedscore(Blls et l , 03) is ob-tainedylettng LLM summariz a atral lan-gge explanaion for the concept e. Simila informationcan be obtained fom the ouput side. High-actvati tokens indicativ of a withth analyzed cocept, are ten For these tokens, wordsare exraced ablatig word in the contextand identifying that impose the impcton the high-activation token. , 2019; Chnet al. , 202)) instp 1 limitedto maximum input lengt. , 2011), and two deepmeasrs Embedding Distance (EmbDist), Cosine Similarity Each masrecomptes similaity (xi, between two tokensxi, xj follows:. 020). We extractoens with top- whenset-ting the hiddenreprsntatn hghly active and not on our w emplo semantic sim-ilarity measuresincluding UCI (Newman et al. g. 009), UMass (imno t al. , 2021;Howcroftetal. Thesmeasures rly on the cncept activaionfuncion, allowinfo sclable, automaic, and de-terminitiPatterns thatactvate a concept areobtaied folows. semanticexpression )gven ctivates o the an 2) lettinLLM gues he activtion given nlysample and the geneated expanation; cl-cultig an explnation scor baed on the varianebetwen true actvtionand te activa-to. , 019a), asking  score conceptiven limited nmber amples. Human evaluion. However, e of samples inpted toLLMs (4 in e al.",
    ": The MTMM table of the evaluation measures:1) subset consistency is shown on the diagonals; 2) con-struct validity is displayed on the off-diagonals": "Measures of (A) show a low correlation 0.0-0.3) withmeasures o redability B), revealig ditinctnature, is as expected. Input readability andoutput readability re also ivergen han 015), demonstrating concets uniquepatens on sides. While efforts th input side, inspection onthe sde blue ideas sleep furiously is needed.Convergent Vaidity is vacorrelaionbetween measures of the same Agreemen measures with same perturbation strategyor diference measurent ishighertn others,iicatng their reation. E fo",
    "Zhi Chen, Yijie Bei, and Cynthia Rudin. 2020. Con-cept whitening for interpretable image recognition.Nature Machine Intelligence, 2(12):772782": "2019b. Smith. 2021. All thats human is gold: Evaluatinhuman evaluation ogenerated text. Co-attiveult-task for elainble rec-ommndtion. I IJCA, 2019, 21372143. What i cannot ido not under-stand: human-cetered evalution ramework forexplainability. Zhogxia Chen, Xiting Xed Xie, Wu,Guo-qing u, Yining Wang,andEnhong Chen.",
    "2www.anthropic.com/news/claude-3-family": "isintroduced. For ease ofreference and we rdabilit on the input/output side theprefixes For com-puting using UCI similarity on te input side isepresented as IN-UCI. Note that cohrence-basedmeasurs may capture te ofareadable explnatio.",
    "GUser study settings": "In ouruser study, we recruited 3 human labelersto evaluate the readability of 200 concepts Thi approachwas designed t incentivze thorough and carefulconsideration of each concept. uring the study, lablers ee requird to com-plete thir assessments within a fiv-minte wn- ABL-Loss ABL-Div ABL-TClass ABL-PClass GAD-TClass RAD-PClass IN-EmbDist IN-EmbCos UT-EmbDist OUT-EmbCos ABL-Loss ABL-Div ABL-Tlass ABL-PClass GRAD-TClas GRADPClass IN-EmbDist IN-EmbCos OUT-Embist OUTEmbCos. 510. 40. 440 190. 190.280. 220 03 0. 520. 580. 560. 180. 200. 40. 40. 240. 04 0. 0. 800. 80. 380. 400. 350. 01 0. 440. 610. 810. 90. 270. 190. 180. 38. 910. 890. 120. 08 -0. 02 0. 200. 400. 390. 890. 120. 08 -0. 01 . 90. 240. 280. 100. 100. 0. 620. 12 0. 280 400. 50. 370. 120. 970 370. 13 0. 220. 190. 10. 08. 080.270. 371. 000. 37 0. 0. 040. 010. 02 -0. 01 0. 120.130. 37. 00 A. Faithfulness B.",
    "ATaxonomies": "This makes selection of suitable evalua-tion measures hard for practitioners in the fieldof concept-based explanation Therefore, there is apressed need for a more unified landscape in theevaluation of concept-based methods to facilitatesubstantial progress in the field. , 2022). providesa summarized mind map, offering visual repre-sentation of the various aspects by which concept-basing explanation methods can be assessed. , 2018; Jacovi andGoldberg, 2020; Colin et al. In this section, we present a taxonomy of prior auto-matic measures for evaluating concept-basing expla-nations based on existed literature on evaluatingexplainable AI (Hoffman et al. To address poten-tial confusion, evaluation measures we proposein this paper seek to clarify and distinguish betweenthe different aspects of evaluation."
}