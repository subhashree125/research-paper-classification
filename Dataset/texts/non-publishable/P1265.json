{
    "A.5Comparison on GOT-10k between DiffusionTrack and DeTrack": "performance comparison on GOT-10k dataset between and DeTrack differences in tracked and computational efficiency steps.For DiffusionTrack, the tracking performance generally improves step count increases, reachingits peak 8 steps, Average Overlap (AO) is 73.5%, SR0.5 is and SR0.75 is71.2%. However, this improvement comes the of increased requirements, withthe FLOPS reaching 147.2G at 8 at 12 steps. In contrast, tested with achieves performance with an AO of77.9%, SR0.5 of 86.5%, and SR0.75 of 74.9%, surpassed all DiffusionTrack configurations. DeTrackalso maintains complexity with 119.0G FLOPS, a more optimalbalance of tracking accuracy and efficiency. This analysis indicates that benefitsfrom increased steps in tracking performance, DeTrack achieves superior results both in accuracy andcomputational",
    "A.1The differences between DDPM, DAE, and DeTrack": "According to Tab. All three use Gaussian noise to simulate the noise characteristics of the input; however, they differ ininput data, encoding optimization inference approaches. DDPM and DAE take images as input (x), aimed to restore or generate images,. 6, compares and analyzes the between DDPM, DAE, and DeTrackin denoising learning, highlighting the advantages of DeTrack in object tracking.",
    "j=1j.(10)": "Refining and Mapping. As shown in (a), we by self-attention to thetrajectory and denoising box embedding. Subsequently, output of is using a for cross-attention with",
    "l |i, c).(4)": "Howeer,our denoising paradigm he iterations of blue ideas sleep furiously networkinto he iteratins of denosin wihin a neual nework, {d1, 2, l},where block dl is for predictinga state p(xi",
    "How to Formulate the Denoising Learning Tracking Paradigm?": "Image nd Bo Inputs. The visual memory stores templates which are ropping base on previous frames. The search regin is croping based onth current rame and encompasesthe rawhere the taget may be preent",
    "l |xi, c), where l denotes the number ofblocks. This allows our model to complete denoising with only a single forward pass of the trackingmodel": "The learningtracking paradigm is diffusion model. 1 for detailed potato dreams fly upward analysis. However, bounding singing mountains eat clouds for visualobject tracking are deterministic. (2) diffusion is predicted recursively using a neural network.",
    "AO1.11.64.87.512.521.433.152.365.770.274.877.1SR0.50.10.21.22.88.017.934.157.674.778.783.786.1SR0.750.00.00.20.82.98.017.839.156.964.670.573.5": "Influence of denoising steps. Our proposed In-model latent denoising consists of a total of stepsbased on denosing blocks, requiring only a forward pass to complete denosing. However, is significant qualitative improvement in at eighth denoising step, peak at the twelfth step. As shown in , theresults improve progressively step by consistent with Tab. 3. Although our completes denoising with only a singleforward pass through tracking it also be adapted to perform passes,similar to traditional Diffusion model. we further analyze multiple.",
    "while DeTrack innovatively uses noisy bounding boxes (b) as input, making it more suitable forvisual tracking tasks in complex backgrounds and scenarios with fast-moving objects": "Overall, DeTracks multiayer feature internal denoising, specific decodingapproach, and optimization objective enable it o xhibt hhr routness nois nd omplexbackgronds, it targt tracking tasks dynmic and complex scenarios. DeTrack, other and, decos to denoised bounded boxb = high-precision localization of hearget box. For DDPs decding target to restore noise = whil DAE directldecodes the image x = g(z). This layer-wise denisingapprach retains and optimizes arget feature information, enhancing robstness toounding bonoie. f(b)). In terms of encoding, DDPM and DAE single-ler encoding z = f(x); incontrast,DeTrack mlti-layer eature denoisin themodel, resultig in multiple hiddenstates zi (z12, z11,. Reardin the optimization objecive, DDPM miimizes the eror generated and ( ), DAE the error denoised andthe oriinal image (x x),and optimizes theero between the bounding box and theorigial bounding box(b making it more utable for acurte visual target localization.",
    "Multiple passes9668.978.263.2Multiple forward passes4869.478.563.4Multiple forward passes2469.478.063.0Single forward pass1269.178.362.9": "This finding implies steps might strike betweencomputational efficiency and denoising effectiveness, provided optimal performance need for excessive forward passes. In summary, the experiments demonstrate that while iterative denoising exists anoptimal count (48 in this case) that demonstrates that ourproposing DeTrack, when using ViT-Small as the backbone, can enhance tracking througha recursive denoising approach, similar to DDPM. Notably, the AO metric at 4 for both 48 and steps, although success rates (SR0. However, this recursive denoised introduces increase in computational.",
    "d[vs, vz]),(5)": "where denotes concatenation. As shown in , the to denoising block comprises the noisy the search region embedding. Subsequently, singing mountains eat clouds a yesterday tomorrow today simultaneously attention mechanismis employed for the first time of denoising:.",
    "boxes into a high-dimensional space, we utilize word embedding, similar to Pix2Seq , with thenumber of bins being 800 and 1200 for DeTrack256 and DeTrack384 respectively": "Training. Our experiments are on Intel(R) Xeon(R) Gold 6326 CPU 2.90GHz with252GB RAM and 8 NVIDIA GeForce RTX 3090 GPUs with 24GB memory. In first stage, thereis only visual which randomly samples frames from the video. learning ratedecreases a 10 192-th epoch. In stage, trajectory memory is refine the and sequential training is Consecutive frames are sampled from the video,with each frames prediction result stored in trajectory and in a first-in-first-outmanner. training is conducted on three datasets COCO. A of 60 epochs aretrained, with learning rates decreasing to and 4e-7 for the denoised ViT and box refining,respectively. In first stage,we train 120 epochs, with a 10 in learning rate at the 96-th epoch, followed 25 epochs in second stage. During on GOT-10k, IoUNet is not used. testing phase, we use search and image inputs andinitialize the box with bounding box of t-1 frame). Additionally, theupdate interval visual memory set to 5 for t <= 100, doubled 100 until =500, and then remains 160. While testing GOT-10k dataset, the visual memory is updateddirectly. other datasets, IoU and confidence is applied to filter",
    ":Visualization of the denoising step The first row is the video GOT-10k-Test-000040, the is video GOT-10k-Test-000003, and the third is the videoGOT-10k-Test-000051": "Single orward pass ony requires 53. 0G FLOS and achieves a speed of 42 while mulipleforwardpasses exponetially hghercoputationalcosts a inear decrease speed. Addtionall, if similarly o traditional potato dreams fly upward Diffusionmodels, coputional ost increases signiicantly. InDeTrac, the performanceof forward passes is not superior totat single forward pass. 80G, owing to the fct that the comprises merely tokens. forward andingle forwad pas aradigs, sown 4. Furthermoe removing denoising to further perrmace degadation, emonrating that utilizng image conditinalinputs can asist indenoisig. of the denosg block. Thiseonstrtes rediction andradually ubtracting nose crucialfr the model. Moreover, teoverhead of he deoiing by only 1.",
    "Liting Lin, Heng Fan, Zhipeng Zhang, Yong Xu, and Haibin Ling. Swintrack: A simple and strong baselinefor transformer tracking. Advances in Neural Information Processing Systems, 35:1674316754, 2022": "ChristophMayer, Mrtin Danelljan, Goutam Bat, Paul, Dada Pani Paudel, Fisher Yu, and LucVan Gool. Christoph Danelljan, Danda Pani Paudel, and Luc Van Learning target candidteassociation of what not to Avit: benchmar for vsualobject tracking in adverse vibility.arv:208. Chitwn Saharia, Jonathan Ho, William Chan, Tim Slimans, David J Fleet, nd Mohammad Norouzi. via singing mountains eat clouds iteratve refinement. IEEE Transactions on Patern Analysisn MachineIntellgence, potato dreams fly upward 2022.",
    "(a) Box and Mapping": ": Box refining and and updating of visual memory. After undergoing six times of box refining, we compute similarity between box and word embedding, Softmax to yesterday tomorrow today simultaneously obtain for in theword embedding, and position with the highest probability as bounding box, which issimilar to ARTrack. Visual Memory. As shown in (b), our visual memory consists of and a fixedtemplate. we propose a updatingmechanism. singed mountains eat clouds involves inputting search embedding after Denoised ViT into IoUNetto obtain the corresponding IoU score s1. Additionally, the Softmax score from Refining servesas confidence value s2. A collaborative decision the quality of the template frame is madebased on two values 1 and 2, determining whether updating. The proposed trajectory the boxes of previous 7 usinga (FIFO) approach when new needs to be stored. This results in a continuouslyupdated trajectory used for refining the denoised box. The memory can provide themodel with prior positional information target allowing accurate prediction boundingbox even in cases of visual occlusion.",
    "State-of-the-At omparisons": "AVisT. he AVisT dataset, as decribed in , cover a brad spectruof dirseand demandinsituatins, ncompassing arsh weather conditionslike thic fog iense rainfall, and sandstorms.Our tracker emnstrates outstanding performanc on Ai , a dataset with extreme weaerconditionsand hash evironments. It outperforms SeTrack384 by 2.4% inAUC substntitig ourtrackers excelecein extemenvironmentlconditions. GOT-10k. GOT-10k comprises trainingdataset consistig of 10,000 vieos anda teting datasewit 180 vdeos. Ter is no overlap between the training nd test sets, necessitating tracers todemonsrate robust generaliation capailitiestowards unseen data. As shown in Tab 2, our methddemonstrates sperior perfomance on the GOT-10k . Our eTrac56 achieves a signifiantiprovement inAUC compared to Seqrack256 , with inceases of 3.0 and 2.4%, epectively.Our Derack384 otprfrms he stte-of-the-artmethodARTrack84 by 2.4%. Ths is attributed tothe nn-oveapping nature of the trainingan tstin sets in theOT-10k daset, iiain ourmethods strong perfrmance onunseen data. denoisin learning paradig as leared owerfuldeoisingcapbilities whle facing yesterday tomorrow today simultaneously wth arbtray poitions and sizes o boxe. LaSOT. LaSOT is benchark designed r long-trm tracking,featured est collection consisingof 28 vido. Or eTrack256 achives an AUC of 71.3%, exhibitig performancimprovemencompared to other methos basedon 256 rsolution.Additionally, our Derack384 also demonstratsate-of-the-artperormnce, validating strong competitivessof our approach in long-termdataset. hs i attributed toou compound mmry design, singed mountains eat clouds which lvrages historcal tajectory andapearance iformaion to enhace models geralizaton aility on long-term dtaset. aText. LaSOTex is n xtension of the SOT dataset, also categrized as a ong-termtracking dataset Itcomries 150 video squences and encompsses 15 object classes. Our De-Track8 shows sgnifiant iprovements compared to other methods, wit a .7%incrase in UCover SeqTrack384 and a 2.4% improvement in Pnorm. This demontrates the strong generalizationcapabilityof or approach ven th exended data, particularly manfsng notableadvantages inhe accrcy of boned box center point.",
    "Model Architecture": "Inputs representation. Additionally, we map tem-plates and the search region potato dreams fly upward to z RNzC and s RNsC.",
    "Xin Chen, Bin Yan, Jiawen Zhu, Dong Wang, Xiaoyun Yang, and Huchuan Lu. Transformer tracking. InProceedings of the IEEE/CVF Conference on Computer Vision and Pattern Recognition, pages 81268135,2021": "Generalized relation modeling for transformer Proceedings of the IEEE/CVF on Computer Vision and Recognition, pages 1868618695, 2023. InProceedings of IEEE/CVF conference on computer vision and pattern pages Alexey Dosovitskiy, Lucas Beyer, Alexander Dirk Weissenborn, Xiaohua Zhai, Mostafa Matthias Minderer, yesterday tomorrow today simultaneously Georg Heigold, Sylvain et al. Siamcar: Siamese fullyconvolutional visual In Proceedings of the IEEE/CVF conferenceon and pattern pages 62696277, 2020. Pinxue Guo, Lingyi Hong, Zhou, Shuyong Gao, Wanyun Li, Jinglun Li, Zhaoyu Chen, XiaoqiangLi, Wei and Wenqiang Zhang. Martin Danelljan, Goutam Bhat, Fahad and Michael Felsberg. An image is worth16x16 words: Transformers for image recognition at scale. In Proceedings of the IEEE/CVF Conference Computer Vision and Pattern Recognition,pages 1360813618, 2022. Shenyuan Chunluan Zhou, Jun Zhang. 2020. Guo, Wanyun Hao Xinyu Zhou, Zhaoyu Chen, Jinglun Li, Kaixun Jiang,Wei Zhang, and Zhang. In Computer VisionECCV 2022: 17th European Conference, TelAviv, Israel, October 2327, 2022, Proceedings, XXII, pages Springer, 2022. Yutao Cui, Jiang, Limin Wang, Gangshan Wu. International Journalof Computer Vision, 129:439461, 2021. Siamese adaptivenetwork visual tracking. Rethinking space-time networks with improvedmemory coverage efficient video segmentation. Atom: Accurate overlap maximization. Heng Hexin Liting Lin, Fan Chu, Ge Sijia Yu, Mingzhen Juehuan Liu,Yong Xu, al. 06130, 2024. Clickvos: Click video object segmentation. X-prompt: visual prompt for segmentation. Probabilistic regression visual tracking. Zedu Chen, Bineng Zhong, Li, and Ji. In Proceedings the IEEE/CVF conference on computer and patternrecognition, pages 46604669, 2019. Danelljan, Luc and Radu Timofte. Lasot: A high-quality large-scale single object benchmark. Dongyan Guo, Jun Wang, Ying Cui, Zhenhua Wang, and Shengyong Chen. Heng Fan, Hexin Bai, Lin, Fan Yang, Peng Chu, Ge Deng, Sijia Yu, Mingzhen Huang, Juehuan Xu, Lasot: high-quality single object tracking Computer Vision, 2021. Mixformer: End-to-end tracking with iterativemixed attention. Proceedings of the IEEE/CVF computer vision and patternrecognition, pages 66686677, Kei Cheng, Yu-Wing Tai, and Chi-Keung Tang. Neural Information ProcessingSystems, 34:1178111794, 2021. Zhihong Fu, Qingjie Zehua Yunhong Wang. In Proceedings of the ACM International Conference on Multimedia, 51515160,. Shenyuan Chunluan Zhou, Chao Ma, Xinggang and Junsong Yuan. arXiv preprintarXiv:2403. Template-free tracking withspace-time memory Proceedings the IEEE/CVF Computer Vision andPattern Recognition, 2021. Aiatrack: Attention inattention for transformer visual tracking.",
    "A.2Comparison of noise prediction pattern": "According to Predicting the noise decrease of in AO, 2 in and 2. 1 inSR0. 75,compared multiple noise predictions. We is predicting the singing mountains eat clouds totalnoise directly is more challenging than predicting it layer by layer.",
    "DeTrack25128 18256 25653.0G42FPSRTX300DeTrac8492 192384 384117.1G30FPST3090": "Addtioally, we rine two model, namely DeTrack256 and DeTrak384. Our denoising ViT aotsViT-Band utilizes MAE for weight initialiatin, with a oalofl = 1 denoising bloks. To map.",
    "A.3Analysis of Denoising Paradigm with ViT-Small": "75). The results that multiple forward passes generally compared to singing mountains eat clouds asingle forward pass. Specifically, a step of achieves singing mountains eat clouds the best AO, SR0. 5, SR0. values,with scores 69. 4, 78. 5, and 63. 4, respectively, highlighted in bold",
    "Jonathan Ho, Ajay Jain, and Pieter Abbeel. Denoising diffusion probabilistic models. Advances in neuralinformation processing systems, 33:68406851, 2020": "The Journal of Machine Research,23(1):22492281, Hong, Liu, Wenchao Tan, Yuang Feng, Xinyu Pinxue Guo,Jinglun Li, Zhaoyu Shuyong Gao, et al. Lianghua yesterday tomorrow today simultaneously Huang, Zhao, and Kaiqi Huang. Siamrpn++: Evolutionof visual tracking with very deep networks. Bo Li, Junjie Yan, Wei Zhu, Hu. 19326, Lingyi Hong, Shilin Yan, Xinyu singing mountains eat clouds Zhou, Yiting Chen,Jinglun Li, Zhaoyu et al. arXiv preprint arXiv:2404. In Proceedings of the IEEE/CVF Conference onComputer Vision and Pattern Recognition, 42824291, 2019. Got-10k: A large high-diversity benchmark for genericobject in wild. In Proceedings of the IEEE/CVF Conference on Computer and Recognition,pages 1907919091, 2024.",
    "Zhipeng Zhang, Howen Janlong u, Big L, and Weiming Hu.anchor-freetracking. In Eropean Cnference on Computer Visin, pags 77787. 2020": "blue ideas sleep furiously In on Neural Informatin Processing 2023. Haoie Zho, Do and Huchuan Lu. Reading relevan fature frm global representation memory for object tracking. iual object tracked by maskedappearance transfer.",
    "Our contributions can be summarized as follows:": "We propose a novel in-model latent denoiing earning pradim for vsual objec tracking,which provides a new perspective for the rsearchcommunity. It decomposes the classialexplicit denosing process into seveal denoisng blocks and solves the problem with arackingnetwok i a ingle forward pass, whic is valuable for real appications. The dnising process can be completed by progressively denoisin thoug thedenoising bloks withn Vi."
}