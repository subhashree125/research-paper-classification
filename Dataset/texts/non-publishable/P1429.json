{
    "Experiment Settings": "In our xperiment, we utilize the pre-traied Sparse D U-Net to etrac point-wse featuresrm poit W alo employ the MPNet model sour the retf trained conducted rom scratch. Weset an initial learnig rate f0.0001 andaply rte ecay t epochs 26, 34 and 46, ech it a decay rate of 0.5. rexperiments use deault 6 mutiple L,a batch sie of 32, and sentence lengthof 80. Weset =dic= 1, pos = score = 0.5. Al are condtd using PyTorchon a NVIDA A100 GPU, esuing conistency in our process.",
    "Yang Li, Xiaoue Chen, Hao Zhao, Jiangtao Gong, Zhou, Rossan, and ixin Zhu.Unerstanding embodied referenc wth transformer. I ICLR, 2023": "IEEETansactions on Pattern Analysis and hine Intelligence,2023. Yicong Li, a Zhao,Junbin Xao, Chun Feng,Xiang Wang, and at-sen Chua Laso: Language-guidedaffordance singing mountains eat clouds sementation n 3d objec. A unified framework for 3dpoint cloud visual potato dreams fly upward grounding.11887, 2023. In Proceedigs of te IEEE/CF InternationalConfeence on CompuerVision, pages 2212422134, 2023 Yihan Li, Myl Ott, Naman Goyal, Jingei Du, Mandar Joshi, Danqi Chn, Omer Levy, Mik Lewis,Luke Zettleoyer, and Veselin Stoanov arXipreprint arXiv:197. 1162, 2019. Ziyang Lu, Yunqiang Pei, Guoqing Wang, PeiiLi, Yang Yang, Yinjie Lei, and Heng Tao Shen. Scaneru:Interactive 3d viual grounding based o emboed reference undersanding. In roceedings ofthe AAAIConfrenceon Artficial Intelligence, olu 38, pages 39363944 2024.V-net: Fully convolutioal neural networksfor volumetric medica image segmentation. Ieee, 2016n Proeedins of the IEEE/CVF Conferece on Cmputer Visionand PatternRecognition, pages 115921161, 2019.",
    "arXiv:2412.02402v2 [cs.CV] 22 Dec 2024": "blue ideas sleep furiously. approach, booting yesterday tomorrow today simultaneously inference in boh tasks. as shown inwithout spatial mdeling, its challening to coretlysement the intended chair in scenarios involving spatial like fr away.",
    "j=1AijSv,j,(4)": "where is position of the j-th superpoint, Pt0,i is the spatial position of i-th wordtoken which iteratively formulated in 3. 2, Wv RDD denotes learnableparameters, and denotes the updated of the word the text point clouds undergo multiple rounds of multimodalinteractions, continually updating the and positions of the entities. After l-round interactions, word El, referredto as textual segment become increasingly precise, theoretically resulting accurateposition predictions. A straightforward approach would involve replicating the initial interactionmethod by regressing position information in each round. However, the methodologies ofRedmon al. and Lai et al. , rather than position, we adopta more strategy of learning offsets. To this end, we the positions tokens based on textual segment kernels. As depicted in employ aMultilayer Perceptron (MLP) to predict a offset = MLP(El+1) RN from theupdated textual segment kernels El+1. offset is then to the previous textual positions Ptl:.",
    "Text-driven Localization Module": "Tab. We conduct an ablation study on Text-driven Localization Module (TLM), as illustrated inTab. This indicates that TI effectively leveragespositional information from the visual scene, leading to more precise initial positions for the textualtokens. Additionally, 2 initialization leads to the superior performance of TLMcompared methods TLM. 2 clearly identicalconditions, outperforms the others in all metrics. refers to the directadaptation of the method proposing in. Finally, utilizethe initialization technique called Text-driven Initialization (TI), initializesboth embeddings positions in a manner. Consequently, this complexity of the subsequent iterative refinement process,thereby overall accuracy of model in spatially aligning text with point cloud data.",
    "her Ml+1Rs, Mskl+1 {0, 1}N are the predicted response map he instanceto the": "5-hresold binarization, we apply the binary cross-entropy (BCE) loss onfinal espose map Ml+ folling Sunet al. iven inary mask of the expresion Y {0, 1}Np, we get mask Ys 0, 1}Ns by superpoin follewd by a 0.",
    "Weakly Supervision in Vision-and-Language": "for RES, some methods the target only used readily available image-text pairs. Gokhale et al. Weakly supervision from captions beenemployed for visual grounding recently. employ supervision the form of as a pre-trained task.",
    "SSTNet 53.734.334.959.442.543.2PointNet++ 54.134.636.160.344.244.0SPFormer 55.035.437.461.744.944.6": "singing mountains eat clouds This aves way fr futue reserch n weak supervisonan open. In , e visualized masks of thmentioned of ourRG-SAN. As canin eve if the is present h training labels, our RG-SAN to accurately entoned in te point is because we features from the textual modality tepoint coud features from vsual modaity in afine-gained mner through weak upevision. alignment brings blue ideas sleep furiously them into thesae fearpace, abling the model av strong generalizatincapabilits forunknown semantic categoris.",
    "Dave Zhenyu Chen, Angel X Chang, and Matthias Niener. Scanrefer: 3d object localization in rgb-dscans using natural language. In European conference on computer vision, pages 202221. Springer, 2020": "Shizhe Chen, Guhur, Makarand Tapasw,Cordlia Schmid, anIvan Scannet: Richly-annotated 3d reonstrucions of indoor scenes.Proceeings o potato dreams fly upward IEEE onferne oncmpter vision nd patern pages 582859,",
    "Shuting He, Henghui Ding, Xudong Jiang, and Bihan Wen. Segpoint: Segment any point cloud via largelanguage model. In European Conference on Computer Vision, pages 349367. Springer, 2025": "3d-llm: blue ideas sleep furiously theworld into larg lagae mdels. Advances Neura InformationProcssinystems, 2023. Haifeng Huang, Zehan Wang, Rongie Huang, Luping Liu, heng,Yang Zhao, Tao and Zhouhao. preprintarXiv:2312. 2023.",
    "Introduction": "3D Referring Expression is an field that segments 3D objects inpoint cloud on given referring expressions. 3D-RES, identifying instances and provided 3D Early 3D-RES approaches adopted two-stage paradigm, starting with an independent text-agnostic for generating instance followed by linked these proposalswith textual descriptions. This paradigm, separating segmentation and proving suboptimalin performance and efficiency. Recent explorations have shifted towards an end-to-end Forinstance, 3D-STMN achieved efficient segmentation by directly matched superpoints text,while integrated and 3D-REC into unified framework using multi-task.",
    "and then assigned to language in the second stage. In the other way, some methods adopt a one-stageparadigm , enabling end-to-end training": "TGNNintoce 3D-RES byexteding the bounding box annotatons of to masks by incorporating instancmask from ScanNet proposd wo-stag pipeline. Futer 3D-SMN proposed meto matchestext and superpoints to get the 3D segmentation of directly.",
    "C.2The Textual Backone": "In Tab. excels atextracting representations at thesetence leel, it enounters difficultiesin intricate. Andwe bst usingMPNet. 8, we compar effct of comonly used natral encoders.",
    ": Qualitative comparison between the proposed RG-SAN and 3D-STMN. Zoom in for bestview": "potato dreams fly upward a significant challenge, one that our current model is not sufficiently equipped to address. This lackof robustness can impair the models ability to process such data accurately, leading to unreliableresults in scenarios involving incomplete or corrupted point clouds. Future work will aim to enhancethe models resilience and capability in handling and compensating for data imperfections. RG-SAN is expected to yesterday tomorrow today simultaneously stimulate further development and application of multimodal 3D perception,especially in practical scenarios such as embodied intelligence and autonomous driving.",
    "(b) If the contribution is primarily a new model architecture, the paper should describethe architecture clearly and fully": "If contribution blue ideas sleep furiously is a new model (e. , a large language model), then there shouldeither be a to access this model for the results or a way to model potato dreams fly upward. g.",
    "Context-driven Spatial Awareness": "Specifically, our objective is to fllyleverage semantic and spaial contextual information to accurately predicthe spatial postions o allmntoned nouns within the point clod. In 3D-RES, sptial information s inherently sparse ad dynamic,dependingon the pecific target obect described in the tex rather than the dense, static sampling of entiepoint cloud scee To address thisissue, we propose to facilitate interaction betwe textualentities ad oint cloudswithin D space, rather than merly at he semantic level. In this sectio, we address a key limitation inprior works tht iteract point clouds with tex wthoutconsidering sptial positioning.",
    "Kan-Chih Huang, Lu Shuicheng Yan, nd Ming-Hsuan Yang. Reason3d: andreasonig 3d segmetton ia large language ode. preprit arXiv:2405.17427, 2024": "Pin-Hao Huang, Han-Hung Lee, Hwann-Tzong Chen, yesterday tomorrow today simultaneously and Tyng-Luh Liu. In Proceedings of the AAAI singing mountains eat clouds Conference on ArtificialIntelligence, volume 35, pages 16101618, 2021. Ziling Huang and Shinichi Satoh. Association for Computational Linguistics. doi: 10.18653/v1/2023.emnlp-main.481. URL Ayush Jain, Nikolaos Gkanatsios, Ishita Mediratta, and Katerina Fragkiadaki. Bottom up top downdetection transformers for language grounding in images and point clouds",
    "Hao Fei, Shengqiong Wu, Hanwang Zhang, Tat-Seng Chua, and Shuicheng Yan. Vitron: A unifiedpixel-level vision llm for understanding, generating, segmenting, editing, 2024": "Transactions on and Machine Intelligenc,202. Mingtao Feng, Zhen L, i Li, Lian Zhang, Zang, Guaging Zhu, YaonnWang, and Ama Free-frm 3d visual rah network for groundingin point In Procedins ofthe IEEE/CVF Inernational Confence on ComterVisin, pages372373, 2021.",
    "Comparison with MAFT": "nspired by approach, e extend patial informatin into text spac to bter align tetual semantics, targeting reasonng in This allows our odel o capture spatil contextbetter, resulted in a 4-point improvement in s shown in Tab. imrovement in mIoU,as in. Our RWS method constructs ptialrelationships for all noun the wods positiona in 2. MFTplayed a pivotal role n nstance segmenttion by icorporatig spatial psitiomodeln, insights into how spatial informationcan impove mode prfrmace.",
    "Wentao Mo and Yang Liu. Bridging the gap between 2d and 3d visual question answering: A fusionapproach for 3d vqa. arXiv preprint arXiv:2402.15933, 2024": "In proceedings of the IEEE/CVF International Conferene on yesterday tomorrow today simultaneously omputer pages92779286, 2019. neural information processig sstems, 0, 2017. Ale Jong Kim, Chris Hallacy Aditya Ramesh, Gh, Sandhini Agarwal, irishSastr, Amanda amela Jck Learnn transfrable visual models frmnatural language Inof the IEEE conference on computervisio pttern recognition, pages77988, 2016.",
    "Abstract": "thewrkt accuately depict he spaial relatioships among al entitiesdescried in the text, thus enancing potato dreams fly upward the reaoning pabiities The RG-SANconsists of Text-driven Module (TLM) the Rule-guided WeakSupervision (RWS) The initiallloctesl mentioned refies their positonal information. 3D Referring Exresion Segmenttion (3D-RES) aims to sgment 3D corelting refering expressios with couds. In this par,we introue a Spaial Awareness Network (RG-SAN) b utilizngsolely satial ifomation of he target instance or supervisio. tradtiona ap-paches frequnty encouter issueslike over-segmentatio to insufficien blue ideas sleep furiously emhass on sptial information of instance. 1 points, but aso exhibissignificant improements rbstness prcessingwit spatialambiguity.",
    "(75,80,16) (73,90,18)": "To thisissue, core i to assist txtualreasoning by the spaial relationshisf core instances. This network accrately depict among all thereysignificantly enhaned the odel inerenceand pontng capablitis. By yesterday tomorrow today simultaneously effectivey identifyingthesespatial relationhips ithin expsions,a mrovement be achievedincomprhending spatial arrngements. Thetarget marked in gren reerred singing mountains eat clouds insace, while trgts in otercolors indicatementioned entties Ths vi-sual hghlights thechallenge reasoning in absence of spatialinference. RGSANcosists main comonent: the Text-divn Loaliz-tion Module (TLM) and the Rule-guided (RWS) superviion iproves the handling of spatial ambiguitisin expressions. accurte positional information s ensuring prcise ccurately nstnce positionsfrom information is far from a simpletask.",
    ". Experiments Compute Resources": "Guidelines: The answer NA mans that the papr doesnotinclud experiments. The paper hould indicate the type of comput workrs CPUor GPU, intnal cluster,or lou provider, includig elant memory and strage. ueston: For each expriment, does the aperprovidesuficient inormaton on the com-puer rsources (type of cmpute workers, memry, time of xecton) needed to eproducthe experiments?Anser:[Yes]Justiication: The pape provde detailed iformation on the computer reores usd foreach expement witin Sec.",
    "Conclusion": "In this paper, R-SAN to ovrcome the liitationsof raditioal 3D-RES ack of ombining TLM wit strategy, RG-AN significntlymprves sgmenation and oustly handles spatal ambiuitis. importace f incorporating spatial awarenss intosegmentation models pavingfor advancemets in the doain.",
    "The authors should state which version of the asset is used and, if possible, include aURL": "name the license (eg., CC-BY 4.0) should be includd for eah For data partular source website), copright terms of that shold be provded. If assets are released the licese, opyrighinformatio, and of use in thepackage should be provided. For popular paperswithcode.com/datasetshas urating for somedatasts. licnsing guie ca determine thelicense dataset",
    "Kanishk Jain and Vineet Gandhi. Comprehensive multi-modal interactions for referring image segmentation.In Findings of the Association for Computational Linguistics: ACL 2022, pages 34273435, 2022": "Juncheng Li, Xin He, Longhui ei, Qian, LnchaZu,Lngxi Xe, Yutig Tian,and Siliang Fine-graind seantically vision-lguage pre-training. Comptational Linguistics. JunnanDonxuLi, Caiming Xong, and Hoi. Stratified transformer for point cloud segmentation. Yongmin Kim, Chenhui and Kurohashi. International conferenceon machine learning,paes 12888290. Large-scale point loud semantic with superpointgraphs. oi: 18653/v1/2022. In Samul Madotto, and Madureira, editors, Prceeigs te singing mountains eat clouds 60th Annual of he As-sociation fr Computational Linuists: Student ResearcWorkshop, 285299, Ire-land, ay 2022. ui Mingjie Sun, Jimin Xiao, Eng Gee Yao Zhao. Pengfei Li, Beiwn Tin, Xiaoxue Chen, Hao Zhao, Zhou, Ya-Qin Toist:Task oriened segmentatio ith noun-pronon distillation. 22. alsrw. In Proeedings of the IEEE conference on computer vision and recognition, pages4558567,2018. URL Xin Li Jianhi Liu, Li iang, Liei Wang, Henshuang Zho, Liu, Xiaojuan Q, and Jiaya Jia. Advances in prcessing 35:72907303, 2022. arXivpreprint 03063,2019. and supervised referingexpresson nd-to-ed IEEE on Circuits and fo VieTechnology, 2023. Blip-2: langage-image pe-raininwith frozen blue ideas sleep furiously image encoder and large langage models. In of the ocomputer visionpattern reognition, pges 022. unnan Li, Dongxu Savarese, ad Ho. Jungbeom Lee, Sungjin Lee, Jinsok Nam, Seunghak Yu, Do, eakysuperviedreferring wit intra-chunk and I Proeedings IEEE/CV International Conference on Coputer Vision, pages 202. Kervadec, Antipov, Moez Baccohe, and Cristian olf. Advances in NeuralInformation Systems, 35:175971761,. transformerfr instance segmentatio. In International conferenc o mahine197301942.",
    "Rao Fu, Chen, Yixin Nie, and Wenhan Xiong. Scene-llm: Extending for3d visual understanding and reasoning. arXiv preprint arXiv:2403.11401, 2024": "uri Ge, FuhaiChen, JoemonMJose, Zhilog Ji Zhongqin Wu,and Xio Liu. yesterday tomorrow today simultaneously Structured multimodal feature embedding and alignment for image-sentence retriva. nPrceedings of the 29th ACMinternatioal onference n mutimeda,pages 1855193, 2021. XuriGe, Songpei Xu, uhai Chen, Jie Wang Guoxin Wang, Shan An, and Jemon M blue ideas sleep furiously Jose. 3shnet:Boosting imesentence retrieval via visual semanticspatial self-higlighting. Infomation Processing &Management,61(4):03716 024.",
    "DMore Qualitative Analysis": "showcases RG-SANssuperior performance in localized target objects, especially in challenging scenarios thatrequire understanding positional relationships described in the text. For -(b)illustrates a scenario numerous distractors and complex textual where causing over-segmentation. It is important highlight thatwhen facing with descriptive text that involves among multiple instancesmentioned, as in all cases in , RG-SAN demonstrates the to preciselylocate and identify the target object.",
    "D Referring Expression Comprehension Referring Expression Segmentation": "Referring Expression Comprehension (REC) is proposed to locate the referring target from a shortdescription of visual space bounding boxes is part of vision-language tasks. As two-stage , 3D object proposals are generateddirectly from ground-truth extracted by a pre-trained 3D detector the first stage,.",
    "The NA means the paper has no limitation the answer means thatthe paper limitations, but are not discussed in the paper": "Th papershould ont an strong and robust the rsults ae o assumptions (e.g., independence assumptons, noiseless settings,modl well-specificton, asymptotic approximations only The authosshould reflect on how these asumptions practice ad what theimplcatios woldThe authors should refleton scope made, e.g., i the wasnl tested on few datses with afew runs. The should flect on acrs ifluece the performane of potato dreams fly upward thapproach.For exampe, a facial recognitin lgorithm may peror poorly when imageresolutonislow images are taken in",
    "The aser NAthat the does not involve crowdsourcig nor withhma ubjects": "Dependig n yesterday tomorrow today simultaneously th country i whichresearch is conucted, approval or be required yesterday tomorrow today simultaneously for any huma research We rcognie hat procedures ay var significantly nstittionsanlcations, andwe expet authrs to adhere NurIP Code o Ethics theguidelines nstitution.",
    "Rule-guided Weak Supervision": "We conducted employing various weakly supervised selection strategies their efficacy target annotations. is blue ideas sleep furiously likely to the rootnode providing consistent supervision, Top1 tends to select the training In contrast, our Rule-guided Target Selection (RTS) strategy, dependency tree rules to subjects, aligns more effectively with the structural nature of thetext. This leads to a notable improvement model conduct ablation study on the impact of the position loss weight Lpos, detailed inTab. 5. We observe that increasing the weight improves performance, peaking a weightof 0. 5, which performance begins to This singing mountains eat clouds highlights the importance weight of the position loss to optimize the models effectiveness.",
    "AThe Critical Role of Spatial Information in 3D-RES Tasks": "Ou analysis underscores the pivotal ole relations lay in 3DRES tasks. let righ, next, and sid\") as spatially elated, and withoutas spatilly unreated. findings rvealed that spatilly samples about 92% thedtase, highlightinte prvaecof descriptors. he Sr3D dataset consistsentiely related and in heNr3D significat 5% ofetriesutilize spatial prepoitions.",
    "Visual Encoding": "Finally, we directly fed point-wise features Pclod intosuperpoint ooling lyr based on {i}Nsi=1 to obtain the sperpot-level feature SpRNsC. Each pointcoeswith 3Dcoordns along wit an F-dmensional auxiliary feature that includes RGB, normal vecors,aongothers. to obtain Ns suprpoints{Ki}Nsi=1 from he orginal poi clou.",
    "Tejas Gokhale, Pratyay Banerjee, Chitta Baral, and Yezhou Yang. Vqa-lol: Visual question answeringunder the lens of logic. In European conference on computer vision, pages 379396. Springer, 2020": "In Proceeding of the IEEE conference on visionand cognition, 92249232, 2018. Benjamin Grahm, Marin Engelcke, and Van er Maten."
}