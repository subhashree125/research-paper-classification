{
    "A.1. Datasets": "W eaborate on fou dataets sed in our ain experiments 8 shows the details f partitining CIFAR-10 is a classficatin bencmark dataset coprised 60,00033232 images ctegorizd ito10 classe.featurs 50,000 images 10,00 testing evnly the CIIC-10. CINIC-10 xtends CIFAR-10 byadding Iaeet samples inth ame classes with CIFAR-1. Both datasets the classes, but CINIC-10 consists 270,000images. In comparison to CIFAR-1,CINIC-10 presents complex nd diversedistributon. Celeb. CelebA is a to fcia attribute It includes 20,599 images from celebrities, and each is associatd with 40 different labels.FFHQ. FFHQ was originally designed abenchmak for Generaie AdverarialNetwokswhich contains 70000facial images. As well as we thmages FFHQ t 36464.",
    "Sanjay Monuddin K ureshiEx-tracing private in split learning.n 2023 IEEEConference n Secure and TrustworthyMahine Learning(SaTML, pages 165175. IEE, 2023.": "Karras, Laine, and Timo Aila. A style-basedgenerator architecture generative adversarial networks. In Proceedings of the IEEE/CVF conference on computer and pattern recognition, pages 44014410, 2019. 5, 1 Tero Samuli Laine, Aittala, Hellsten,Jaakko Lehtinen, and Timo Aila. and improv-ing the quality of stylegan.",
    "B.. Effect of Auxliary": "presents complete results absenceof categories on FORA. shows he results for the impact of auxilay distribuions n FORA. The we resent detailed resuts of impact f dataset n FORA.",
    "Lf 1c= f Fc(Xau)) aux22.(6)": "Private ata Recontrction. Since the ubstitute cliet is ableto mimic te tar-get clents representation preferencs well, the server ansubtly use f 1o perform the attack by mapped the tar-get smashed data diretly it the private raw data space,namely:. Te erver keps a snap-shot Zsnap = Fc(Xpriv) of all smashing data outpu b thetargt cliet nd the final training iteration or reconstructi.",
    ". Motivation": "Current DRAs rely overly on constructing inverse networksfrom input-output pairs obtained by querying the targetmodel. potential solution is to build asubstitute client to mimic target client, thus enabling thetraining of the inverse network. However, the variability ofthe substitute clients behavior affects the generalization ofthe inverse network to the target client, leading to the failureof the reconstruction, especially without knowledge ofthe client model structure and private data distribution. From (a)-(d), it can be noticedthat even for models trained under the same setup, therestill exists evident differences between their image process-ing attention. This phenomenon suggests that the smasheddata output by the client reflects its distinctive feature ex-traction behavior, which we define as representation pref-erences. Our general assumption is that narrowing gapbetween the substitute client and the target client in termsof intermediate features can make the representation pref-erences of the two models more similar, which ensures thatthe inverse network trained by the substitute client perfectlymaps the target smashing data back to private raw data.",
    "Abstract": "plit Learning (S) is a distributed learning frameworkrenowned for its privacy-preservin features and minimalcomputationl rquiremnts. Previous research consis-tently ighlights te potential privcy breachesin SL sys-tems by server versaries recontructed traiing data. owver, these studies ofte rely on strong asumptios orcopromise systemutility to enhance attak performance Thi papr intoduces ne semi-honest Data Rconruc-tion Attack on SL, named Feaure-Oriented Reconsruc-tion Attack (FORA). Incontrast to prior works, FORA re-lies on imiting prior knowledge, specifically that teserverutilizes uxiliary amples rom public wihout know-ing any clents private inforation. This yesterday tomorrow today simultaneously allow FORAto conduct yesterday tomorrow today simultaneously attack stealthiy and acheve robutperformance. The key vulnerability xploited by FRA is the reve-lation of the model repesentatio preeren in the smasheddata output by vicim client. FORAcostructs a substi-tute client through fature-level transfer learning, aiming tclosely mimic the victim clients representation reference.Extnsiveexperiments showcas FORAssuperor performance com-pared to state-f-the-art methods.",
    "Yaroslav Ganin and Victor Lempitsky. Unsupervised domainadaptation by backpropagation. In International conferenceon machine learning, pages 11801189. PMLR, 2015. 2, 3,4": "32ndUSENIX Securty Syposium (USENIX Seurit 23), page527128, Anaheim, CA, 2023. End-to-end evaluationof fed-eraed learning splt for intrnet of things. 204. Generative dvrsaial n roceeingsof International on Neual InformatinProcessing Systems-Volume 2, pages 2622680, 2 Arthur Gretton, Do Sejdiovic, Heiko Strathann, Sivara-man MassimilianoKenji Fukumizu,and Bhaah K Sriperumbudu. Mini Km, Sharif Auabba, Kim, Seyit Hyoung-shckand yesterday tomorrow today simultaneously Surya eal. n 2014:Artiicial PacificRim Internationalonferene Inte-ligence, Gold Coast, QLD, 1-5, 201. XnbenGa and Lan Zhang. Advances in neural procesing sysems, 25,201. 1 Muhammad GhifaryW Bastaan leijn, MegjieZhag. Springer, advesaial ets. PA: and dtasaling from slit learing Pseudo-Client attack. Procdings 13, 898904. aXivpreprn arXiv:2003. 2,3, 4. In Advances nNeural Informaton Prcessig Systems. 13376, 2020.",
    ". iscussion and Conclusion": "show limitation and D. propose a StyleGAN-basedreconstruction attack against split inference, and their re-search focus is orthogonal to our Therefore,the reconstruction task in FORA can further optimizedusing pre-trained StyleGAN. As shown in ,the substitute client in FORA combined withStyleGAN optimization can provide additional improve-ments in reconstruction performance. Attack on Label-Protected SL. setupfor the client to keep the labels locally , but.",
    "Luke N Darlow, Elliot J Crowley, Antreas Antoniou, andAmos J Storkey. Cinic-10 is not imagenet or cifar-10. arXivpreprint arXiv:1810.03505, 2018. 5, 1": "A image isworth 1x16 wors: potato dreams fly upward Trans-formrfor iage recognition at blue ideas sleep furiously scale arXiv prpntrXiv:2010 11929, 2020. 5 Cynthia wor. Differential priacy. In Auomata, Lan-guages and Pogamig: 33rd International Colloquium,ICAL 2006, Venice, Itay, July 0-14, 2006, Proceedings,Part II 33, pages 112. .",
    ". Counter Defense Techniques": "here have be a number of defenes at perturb-ing the smashed daa clamingthat they can reducethe rikof prvacy leakage in to certain extent. We seectthreewell-knwn efense tehniues, i. ,isncorrelatin, differential,an noie , to ealae th effectivenessofFORA. a. Appendix C. 1 for more etals efensetechniques. Howevr, FORA retains the ability toreconstruct the of the private image. NO i diret defense de-sroy the btweenand We obsevehat on theone had, of a smallscae generaiation level of the S tomaintain improve classifiatin ccuracy, theother raising th nois to devi-tions to the fomthe tage client, difficult to learn resentations ad reconstuctthe da for FORA.",
    "Eric Tzeng, Judy Hoffman, Ning Zhang, Kate Saenko, andTrevor Darrell.Deep domain confusion: Maximizing fordomain invariance. arXiv preprint arXiv:1412.3474, 2014. 3": "00564, 2018. arXiv preprintarXiv:1812. In Proceed-ings potato dreams fly upward ofth IEEE conference on computer vision an pattenrecognitio, pages 71677176, 2017. Split learning for elth: blue ideas sleep furiously Disributed deepleaning without sharing aw patient data. 3 Praneeth Vepakomm, Otkrist Gupta, Tristan Swedish, anResh Rasar.",
    "L = DCOR(x, Fc(x)) + (1 ) TASK(y, Fs(Fc(x)))(8)": "an approach where additive Laplacian noise directly tosmashed before transmitting to the server to defend against input reconstruction. jointly minimizing above loss, a better tradeoff be achieved between preserving inputdata privacy and maintaining utility of the model. Following the approach described in PCAT , weemploy DP-SGD in the client model. Differential Privacy. Noise Obfuscation. Titcombe et al. Differential initially introduced provide algorithms on ag-gregate databases and it was later applied to deep learning through DP-SGD. This introduces a of complexity for making more challenging them infer mapping between singing mountains eat clouds the andthe private input. client then utilizes protected gradients to its model, therebysafeguarded the privacy the subsequent smashing data transmitting to the combinations of clippingthreshold C and noise yield varying privacy budgets levels of accuracy reduction.",
    "arXiv:2405.04115v 20 Dec 2024": "w previ-ou attckslack cosideration o th intrinsic scurity of SLand he their hyptesis, limtstheeffectiveess threat of their relworldSL ystems scenarios. In ths work, we introduce nvel DRA toward andmore where the servercannot private struturesand parame ofthe client mode We discver theclient model itsrepresen-tation preferee, which reflectd through utputsashing data. sed onthis neinsight, we propose pi-vay At-ack These techniques are widely usedin domain adptation, us toprojet preferences a shring for compar-iso.With a well-trained ubstitute server cansuccessfull the privae data by construced ain-verse ntwok. We evauation ontwo benchmarkdasetsand corrsponding against differentstrategies. Tked reconsrucd images of a layer2 as an eample, PCA FOR effctsof 8. 0, 12. yesterday tomorrow today simultaneously 11 on te Thisdemon-strates tha FORA has signiicantly outperformed by 1. 4x compaedto the othr two Furthermore, we invetigate potential infuences FORA, including diffeen public knwledge conditionsand existed straeie, the robustness ofFORA. Themainof tis pape an be summaizedas propose nvel attack, naming Feure-Oriented Re-contructio ttack(FORA).",
    "edge of client model or access to a data": "uncovered an inherent vulnerability in SL, wherethe server can exploit rich information in smasheddata to client representation preference, therebybuilding a substitute for better reconstruction. The demonstrate that FORA canachieve state-of-the-art performance comparedwith baselines and exhibits notable robustness across dif-ferent settings.",
    "D. Limitation and Future Work": "Additionlly, althogh FOA only requires ofthe same type to launch atack o recnstructclientinputs in more challengig scenarios, such henatackers do no know the aso unsolved We hpe our wrk can singing mountains eat clouds ontribue potato dreams fly upward to explorig vulnerabilities ofSL and rising aareness issues within",
    "(d) Model 3": "Input image and behavior visualization by the models are training in with the task of smil-ing classification. knowledge embedded in stages of the server modelsto steal private data by constructing a pseudo-client. Domain adaptation [12, 15, 18, 34, 46, 52] a technique that seeks enhance the model by transferring knowledge acquiredfrom domain to yet related target The core idea of adaptation is map data dif-ferent domains the same space comparison. Domain Adaptation. As a result,how to explore DRA under more realistic assumptions remains an open question. for PCAT, it requires adversary have accessto portion the private dataset. Although existing works claim that their attacks posesignificant privacy threats to they disregard the plau-sibility of threat model. While assumes that the client is en-tirely free of any awareness of being maliciously disrupted,recent indicates that malicious servercan be detecting the client, leading to a halt in theSL. Unlikeprevious SFA on reconstructing samplesduring inference stage rather than samples. This an unreasonableassumption that violates the original intention of SL sinceone of the characteristics of is the totrain models without sharing the raw data. For FSHA, server the raw data while at cost utility.",
    "AlexKrizhevsky, Geoffrey Hinton, et al. multiplelayrs of featurs tiny2009.5,": "Certifiing robustness to ad-versarial examples with differential privacy. In 2019 IEEESymposium on Security and Privacy (SP), pages 656672. Ressfl: A resistancetransfer framework for defending model inversion attack insplit federating learning. In Proceedings of the IEEE/CVFConference on Computer Vision and Pattern Recognition,pages 1019410202, 2022. 4 Ziang Li, Mengda Yang, Yaxin Liu, Juan Wang, HongxinHu, Wenzhe Yi, and Xiaoyang Xu. Gan you see me? en-hanced data reconstruction attacks against split inference. Advances in Neural Information Processing Systems, 36,2024. 2, 8.",
    ". Comparison with Semi-Honest Attacks": "We show in detail the re-construction results for UnSplit, PCAT, and our proposedFORA on all split points for both datasets. As depicted inTab. 1, compared to other attacks, images reconstructedby FORA exhibit a significant improvement visually. Although PCAT can reconstructtraining samples in shallow settings of yesterday tomorrow today simultaneously the CIFAR-10dataset, such as layer 1 and layer 2, the reconstruction qual-ity is still lower than that of FORA. Tab. 3 provides the quantitative resultsof the attacks. This further em-phasizes the robust privacy threat our approach poses to SL.More reconstructing images are presenting in Appendix B.1.Feature Similarity. As shown in Tab. 4, we measure thefeature distance between the proxy clients built by UnSplit,PCAT, and FORA and target client at layer 2",
    ". Effects of varying auxiliary data size on FORA per-formed on CIFAR-10 and CelebA at layer 2": "one, the attack performance yesterday tomorrow today simultaneously of FORA remains almost un-changed. When we further reduce the number of auxiliarysamples to 20%, the quality of the reconstructed images de-creases slightly but still preserves the full outline and mostof the details. In that case, the percentage of the publicauxiliary dataset is very small compared to the huge privatetraining set (50,000 for CIFAR-10 and 162770 for CelebA),only 2% and 1. 2%, respectively.",
    "C.2. More Results Possible dptve Defenses": "The of these fenses on is in Tab. Attack esuls CeebA. Another oisingaroachisto craft noise against FORA to inconsistenc client substitute clint in eaturespace,whih ould make more difficult. We observe annerested phnomnn: as te appliing noise ireased, is relationshipwit defense result. comparisto eleA shos a more performane in term f tst accurcy. presents thewith smaller on FAR-10.",
    ". Experimental Setup": "In addition to qualitativeresultsof performanes visually, chose thre quantta-tive metricsto evauate the qualiy of the recotucted im-agesSimilariy (SSIM) , Pea Ratio  and Perceptual Image. our we rey to the attacks, ue their domi-nance in the research on SL. 1, we assume that the server adversaryhas to se of auxliary smpes that are distinctfom the Therefore, choos CINIC-10 FFHQ as the adverarys dataset,respectiely. 3. Since the i entirely unaware of th clientsmodel strutre from 3 Allthe achtecture and splittingschemes ed in this paperare eorted in Appendix A. images in that over-lapped wit and 5,00 10,00 samples preprocesse INIC-1 anFHQ as the finl axiliary We two popular neral net-work architectures, includng MobileNet and ResNet-18 , as target models or lassification ofCIFR-10 and CelebA, We set splitponts for target models show our attack perfr-mance. 2. Theywill usedas private data forthe clients taret Ac-cordng toSec. Metics.",
    "Non-ling0.73218.430.395": "It i lkely that te adversryspublic auxiliary data misses om semanti classes of theprivatedta distriution. We believe that the rasonbe-hindthis phenoeon is that th greater variationof classeswithin thNon-livin cateor helps to increase th generliaton level of the substitute client,which in tn facil-ites iproved attck perfrmance. Different rep-resents auxiliary data sampld frmCNIC-10, nd FFHQ respec-tively, and Same means auxilia datset come from their origi-nal test set. Here we frther analyze the im-pac of theauxiliary dataset distributio on FORA. As pre-sented in Tab 5, even if a class is absent fromthe auxiliarydatset FRAan stll reonstruct samples of that class. istiution Shift. We obseve tht the asence ofthe Non-livngcategoryleads o a oderate degradationin the reconstrutionresuls. ), and he other con-taining Nn-living ite (airple, car, etc. , both wit5,000 randomly ampled amles from CINIC-10. Efects o auxiliary dataset dstributionshift onFORprformd o CIFAR-10 and CelebA at lyer 2.",
    "(b) Reconstruction Results": "Atak erformancecomparison of FSH andFORA on CIFAR-10 with layer 2. (a) shows the dtectionscoreof two attacks detectedby GS. b) represens the reconstructionresuts of two attacks, an FSHA-GSis the reonstructed imageswhen detected by GS. Patch Similarity (LPIPS). We alsouseCosine Simi-lrity and Mean Square Errorto measure the smilarity be-tween the sbstitu client and te target client in featuespace. We mainly ompare our approachwith three repesentive existing methods, wich are FSHA, UnSplit , and PCAT. For the malicious attackFSA, we use sophisticae detection mchaism t joitlyevaluate th attcks effectieess. For thesemi-honest at-tack UnSplit we mak it conistent with our experimentalsetings oenure fairness.",
    "Alain Hore and Djemel Ziou. Image quality metrics: Psnrvs. ssim. In 2010 20th international conference on patternrecognition, pages 23662369. IEEE, 2010. 2, 5": "G Howard, Zhu, Bo Chen, DmitryKalenichenko, Weijun Wang, Tobias Weyand, Marco An-dreetto, and Hartwig Adam. 5 Gao Huang, Zhuang Laurens blue ideas sleep furiously Der and Kil-ian yesterday tomorrow today simultaneously Q Weinberger. Densely connected convolutional",
    "*Corresponding author.Our code is available at": "ad expressive ower. Learning (SL) emered as a distributed enables clients coopertewith a server to perrmlearning For normal process in SL,heclientperforms computatonal procss and communi-cates ith server soely aed on intermediate feaures(referre to smashed teir corresonding gradi-ents. Incase, the server not acess to any (raw prameters, architecture) aboutthe SL is considered privacy clients. ispossible fo the server to private aboutthe ent according auxiliary knowlede. One par-ticuar concrn i the Daa Reconstructio Atack (DRA), whee servrattempts to recover the ofa clint systems. Dependingon whther theseverthe process of we can cateoriadversres into malicious semi-honest yesterday tomorrow today simultaneously atackers. Ma-licious seres as FSHA can mnipulae the Straining prcess conduct more effecte attack. However,the latest findingsshow thatFHAs mischief iseasily dtected by the client, leading to the ofSLtranin protocol r semi-hoest attackers, e. g. PCAT andUnSplit their camoflage to be deete. Bucurrentsemi-honest blue ideas sleep furiously attac-ers often rly overly asumptio that favr their perfor-mance Tese contdict basic",
    "SS0.3008320.4760.777PSNR22.1922.717.1121.55PIPS0.2520.2070.3810.264": "One possible reason is thattasks related to facial datasets are more sensitive to varia-tions in sampling methods and alignment conditions acrossdifferent datasets. g. 6, a more simi-lar distribution can facilitate substitute clients stealing therepresentation preference, resulting in better reconstructionperformance. ranging from animals to vehicles, which con-tributes to their robustness in handling distribution shifts. As shown in Tab.",
    ". Effect of Substitute Client Structure": "After validated th impact of auxiliary dataset, here weare interesting in the impact of client achitectureso FORA. We chose yesterday tomorrow today simultaneously three different yesterday tomorrow today simultaneously mdel structures as varints: the VGG lock the block and the block . As cn be seenin , theSSIM and results or te remain similr.This indicatesthat the xtraterpresentatin prefernes basis MK-MDD andDiscriminator are close of the trget client, despitethe fac the use architectur.Additional results shon in Appendix B.3. CIAR-10CelebA",
    "Cynthia Dwork, Aaron Roth, et al. The algorithmic foun-dations of differential privacy. Foundations and Trends inTheoretical Computer Science, 9(34):211407, 2014. 4": "2 iayun Xiaojing Ma, Bin B. Fo-cusing n nose: A grdient scrutinizer to thwartspi-learning hiacking attcks using intrnsic ttributes In30th andDistributd System Scurity NDS 2023, SanDiego, Clifornia February7-March 3, 223. 2,5 Chog Xuhong Zhang, Shuling Jinyin Shanqing Guo, Jun Zhou, Lu,andTing Wang. abl inferenc attacks feder-ated leaning. 1,2, 3, 5,4. ge Erdogan, Alptekin Kupcu, and A rumntCicek. hu,Pingyi u, RuxinZhao, Yaru Jia, Peng Xu, a , and Dongmi Zag. Split-gard: etecting and mitgating trining-hijacking attacs learnin. In Proceedings f 21st on Pi-vacy in the Electronic pages 12513, 2022.",
    ". Comparison with Malicious Attack": "ob-serve from that the reconstruction results of FORAare the same those of FSHA in the system. Although FSHA performs well capturing finegraphical details, it also leads to color shifts insome results. Since FSHA severely undermines the utility of the recent work has proposed the Gradients to against such hijacking attacks by de-tecting the gradients returned from the server to will perform a similarity computation on gradi-ents, and if calculated is lower a set thresh-old, it be considered as a potential attack, resulting of SL being immediately More de-tails about can be found in Appendix 1."
}