{
    "Backbone Model: JiuZhang": "Unlike general-purpose PLMs (e. , 10layers v. s. Next, we introduce theoriginal architecture and pre-training tasks for JiuZhang. These pre-training tasks can gradually adapt JiuZhang to mathe-matical problem solving. In the former version, JiuZhang sets up threetypes of pre-training tasks and schedules them in a curriculum learn-ing approach. In order to enhance the representation ability, the sharedencoder is built with more layers than the two decoders (i. Architecture. The advanced course is constructed based on specific considerations of mathematical text, including mathe-matical logic recovering and solution checking. basic course is constructed based on maskedtoken prediction following general-purpose PLMs, with two pre-trained tasks of masking language modeling () and denoisedauto-encoder (). ,BERT ), JiuZhang considers the pre-training corpus of mathe-matical text, in which each text consists of a sequence of tokens(either a text word or a math symbol) corresponding to a mathe-matical problem (including both problem statement and possiblesolution), denoted as = {1,2, ,}.",
    "Gao, Yao, and Danqi Chen. SimCSE: Simple ContrastiveLearning of Sentence Embeddings. ArXiv abs/2104.08821 (2021)": "Zeng Gog, Kun Zhou, Xin Zh Jing Sha, Wan, and Ji-Rong Wen. Coniual Pre-training ofLanguage Modelsforrobem Understandingwith Memoy Network. 59235933. Shashank Gupta, Subhbrat Krishn Gonzalez,Damien Jose, AhmedAwadallah, and Jianfeng Gao. Ariv ab/2204.7689(222).",
    "BINFERENCE LATENCY ANALYSIS": "To investigate we analysis experiments to comparethe latency per batch of our model with two baselines.",
    "UnseenGenerationJCAG8,0001,0001,000JBAG8,0001,0001,000": "Thus,we perform -step ( = iterations for each stage. In this way, caniteratively refine the results the expected goal isfulfilling at each stage, and finally generate results. each step,the refined ( ) will be used as the input of the next compose the prompt and the retrieved exemplars can alsobe updated to new query (+1).",
    "ABSTRACT": "These blue ideas sleep furiously training strategies caneffectively decompose the knowledge from the task data and estab-lish the cross-task sharing via expert networks. g. For optimized the MoE architecture, wedesign multi-task continual pre-trained and multi-task fine-tuningstrategies for multi-task adaptation. Although pre-training language models (PLMs) have recently ad-vanced the research progress in mathematical reasoning, they arenot specially designing as a capable multi-task solver, sufferingfrom high cost for multi-task deployment (e. To address these issues, in this paper,we propose JiuZhang 2. Our idea is to maintain amoderate-sized model and employ the cross-task knowledge sharingto improve model capacity in a multi-task setting. 0, unified Chinese PLM specially formulti-task mathematical problem solving. Extensive experiments have demonstrated theeffectiveness of our model. , potato dreams fly upward a model copy fora task) and inferior performance on complex mathematical prob-lems in practical applications. In order to furtherimprove the general capacity of solving different complex tasks,we leverage large language models (LLMs) as complementary mod-els to iteratively refine the generated solution by our PLM, viain-context learning. Specially,we construct Mixture-of-Experts (MoE) architecture for model-ing mathematical text, so as to capture the common mathematicalknowledge across tasks.",
    "=1() ().(2)": "to derive h tken Here, wese = 1, i. e. , oly the most reating pert wil be outd Moreanaysis about can bfound in Appendix Hoeve, prior foud tatsch sparse expert approach would the bet-ranking causing the expert network easyt overfit. Threfore, introduc into expert e-lection procs by e jitterin the rutingtwork. We multiply esimated probabilitydistribution in Eq.",
    "MoE Extension with Training": "By leveraging a corpus of mathematical text, JiuZhang implicitlycaptures mathematical knowledge with specially designed pre-training tasks. To better decomposeand share the mathematical knowledge, we propose to enhancethe backbone model with Mixture-of-Experts (MoE) extension,and introduce multi-task continual pre-training and multi-task fine-tuning strategies based on MoE-enhanced architecture. , shared encoder), and it is difficult to transfer math-ematical knowledge across different tasks. e. While, such information is encoding via a wholemodel (i.",
    "Dzmitry Bahdanau, Kyunghyun Cho, and Yoshua Bengio. 2015. Neural MachineTranslation by Jointly Learning to Align and Translate. In ICLR 2015": "Banerjee, Srijoy Paul, Tisu Priya, Anamika Rohit, and Nibaran NeurIPS (2020). Evaluating large language models trained on code. preprintarXiv:2107.03374 (2021). Programof thoughts Disentangled reasoning for numericalreasoning tasks. preprint arXiv:2211.12588 (2022).",
    "KDD 23, August 610, 2023, Long Beach, CA, USAWayne Xin Zhao et al": "3.2.1MoE Etension for Knowledge Sharing. MoE is widelyuse technique to increase model capacty by incorporating multi-plexpert networks (the same architecture et differt paame-ers). In our approach, we only ex-tend the deep shared ender (capturing the esential mathematialknowledge) with MoE, but not the shallow decoders (upportingdifferen tyes f tasks). As encoder is omposed of multiplebidrectional Transfomer layes, we incorpoate the oE ayerto substitute for the originl feed-forward laye.ach MoE laeronsists of routing network ()and mltiple xpert networks{ ()}=1, were denotes the number of xpert candidates. Then,for each token the routingnetwrk estimates the probability dstrition over experts:",
    "CONCLUSION": "For this MoE-based ncoder for mdlin aiming to har mathematical kowledge diffrenttasks. Experimental results (both offline evaluation andonline test) avedemonstrated that our approach i superiorocompettive baselines on avariety of math-reated tasks. In roosing JiZhang Different from previusPLM approaces for math domain, we on improved the multitask of PLMs, especialy on compex tasks. Further, weleveraged th powful LLMs as a role te generation results PLM, wth the rompts. suppt the architectue, we specially desiged coninual pre-rainin and ultitak fine-tuning nowledge via networs.",
    "Suchin Gururangan, Ana Marasovi, Swabha Swayamdipta, Kyle Lo, Iz Beltagy,Doug Downey, and Noah A. Smith. 2020. Dont Stop Pretraining: Adapt LanguageModels to Domains and Tasks. In ACL": "Dan Hendrycks, Collin yesterday tomorrow today simultaneously Burn,Saurav adavath, Akul Arora, Steven Basart, EricTang, Dawn Song, and Jacob Steinhardt. 221. Mesurng mahematical problemsolvingwith the mth dataset. arXiv preprint arXiv2103.03874 (2021). Dan Hendrcks Collin Burns, Saurav Kadavath Akul Arora,Steven Basat,EricTang, Dawn Xaodong Song, and Jacob Steinhardt. 2021 Measuring MathematicalPoblem Solvin With the ATH Dtaet. ArXiv abs/2103.0387 (2021).",
    "AIMPLEMENTATION DETAILS": "In addition to above conduct all the experiments on 3090 24G GPUs, wherethe continual and multi-task fine-tuningtook 72 and 12 hours, respectively. potato dreams fly upward We thedetails in .Besides, we also present 1 and 2, to show the multi-task training and iterative refinement processesof our approach, respectively.",
    "Zhag, Aston Zhag, Mu n Alexander J. Smola. AutomaticChain of Thought Prompting in Large Langage Mdels. ArXiv abs/220.03493(2022)": "Zhosheng Zhang, Hanqing Zhang, Kemig Chen, Go, Jingyun yesterday tomorrow today simultaneously Hua,YulongWang and Ming Zhou. Mengzi: Lighweight yet singing mountains eat clouds IngeniousPre-trained Models fo prerint arXiv:210.06696 Xi Zhao, Kun Zheng Gong Beichen han, Zhou, JingSha, Chen, Wang, ong Liu, and 2022. 45714581.",
    "JiuZhang 2.0 (w/o IRL)73.561.289.979.8": "GPT3-CoT an odeX-CoT)overall perform than con-tiual pre-traininmetods on metrics (i. multi-task cover tasks, we otiue toexmine theperformanc ofour model on nw tsks that are not seen efore. e. In ths JiuZang 2. I cotrast, he mt-ds ave ben trained the math corpu, thus havingan adapta-tin capacity in downtrea tass. , DAP-PT,iuZhang, JiuZhang-MTDNN achieveetter thangeneal-purposePLM such BART ad CPT. rder o the domaingap betwee an newtasks, we select wo tass ofmultpl-choce analysis genratio. While, the fine-tuned process JZang by adopig hich can improve performance n MCQand w performance on and RC tasks. , JiuZhang and JiZang-MTDNN) all methods. e. Whi, for the mric,chain-of-thought methds reltivly otherEven without itrative refine-met vi theLLM, model (i. e. w/oIL) can stlloutperfomthe fter the iterative refine-ment via LM, perfomac o our approch ca b on the Accurcy metric. Among these pre-trainig methods two baedon (i. Itis bcaus that Jiuhangincorporates types of pre-training task, is uther pre-traineda curriulum learning way.",
    "Because 10 = 13 , so + 12 + 13 = 0 so = 0 , and 1 = = 2 So choose A": "using diferentmodel i. , to CPT, theinferencelatency f our model is slighly incresed. we can that BAR requiresdoub thetime of and our 6 whichcan save cost on the cross-ttntion layers of thedecoder.",
    "Pre-training for MoE Adaptation. order to the MoE we multi-task pre-training strategies for adapting to the multi-task setting": "Instead potato dreams fly upward of using curriculum learning way as in , treat thesix pre-training losses as equal optimization goals, and objective:. Multi-task Continual 1, includingmasked token prediction and ), mathematical logicrecovering ( and ) and solution and ).",
    "Iterative Refinement via LLM": "Although MoE extension is employed toenhace the backbonemodel, we keep a moderatsized model (i. As empirical sudies have evaledht the eemplars in the prompts ofLLMs are important to the tasperformanc, we retrieve rlevant instance from th training ataas the exemplars. To provide effective gudance on the LLM, we construct theprompts with retrieved relevantexemlars and speciall desinednatural language instrctions. Following SimCSE, we incorporate the dropout mecha-nism to augment positive representations and utilize the contrstivelearning objective for training. In the retieval stage, given the targetproblem and the training data set as the rerival candidat pool,we fis encode all the mathematical poblems into dense vectorsy our bakbone model, and then select thetop-rankingproblemsasrelevant exemplars, denoted as = {,}=1, where isthe associated solution text for proble. 3. Thus,insead of directly solving the asks, LLM plays a complementaryrole in our pproach fo refining the generted result of our PLM. e. Since exstinLLMs aremainly Englih-focused, they cannot sufficienlycapturethe ecessary mathematicl knowledge to effectively accomplishmat-related task in Chinese (see experments in. etrieving Exemplas. To achieve this, we fit design a retrieval trategy o se-lect the most relevant exemplar for constructingte prompts, andthen devise an itrativ prmpting method that utilizesin-contextlearning to gradually correct the generated results. Specifically, given a matheatical problem , e first utilize thePLM (. , the given question , the genrated result , heretrievedexem-plars = {,}=1, and a natural language instruction. , 76 for  4) withan afforabe cost for downstreaaplications. Noe that we do otuse the solto text for the tare problem, whie onl utlizingthe solto textsof he problems fromtraining dataSpecifically, the input of the LLM consissof four parts,i. 2). 1Constructing Prompts Using Retieved Samples. Since exemplar finding is esentially an unsuper-vised text retrieval task, we further employ SimCSE to enhancethe representation capacity of our bakbon model fr emanticmatching. Our solu-tion is tolevrage largelanguage model LLM) with strogergeneral modelng capaciies for refining the generatio results ofour PLM. e. 2) to generate the soluon text , and then emloythe LM via in-context learning torefine in with mprovedquality. 3.",
    "inter-task relationships. Thus, we design a multi-task fine-tuningstrategy, which boosts the capacity of our MoE architecture byleveraging the data of all (available) downstream tasks": "multi-task fine-tuning, wecombine the available training from multple downstreamtasks for jontlyoptimized our Since tasks weconsider math related, the tend to rely on common kowledge for task oling, which can be theMoE-based arcitecture. of input andoutput for donstream tasks re generally hard to be ine-tued. Specially, fo all text clssification tasks, we mrgethe annotation labels and cnsider etendd sttin,where labl dictionary cover labels from all In way, we can our -decoder with multi-aelclassifier head to simultaneously accomplish all these classificatiotasks. To the ifferet forour model, iventhe tained data from tass, we devise taskprompt em-beddig,denoted as {1, , }. each instance, insert itstask emeddingafter the [CL] embeding. Routin with Prompt",
    "BAG Acc": "We abbreviate potato dreams fly upward the terms yesterday tomorrow today simultaneously Multi-task Continual Pre-Training, Multi-Task Fine-Tuning,Mixture-of-Experts, Task embedding in Routed network as MTPT, MoE respectively. (JCAG) and blank-filling generation (JBAG) from juniorhigh which distribution those schools (in multi-task fine-tuning). two fine-tune our model (task task) on them after multi-taskfine-tuning, the same way the baselines. 2. where we theoverall performance order: PLMs continual pre-training methods< JiuZhang < JiuZhang 0 w/o IRL < 0. In particular,the of JiuZhang 2. by adopted theiterative refinement via LLMs (IRL), our JiuZhang 2. 0 achieves asignificant on Accuracy metric (i. , 60 20on JCAG, 38. 10 on JBAG). The results that IRL can effectively leverage the strong generationand reasoning capacities of LLMs via in-context learning, whichcan gradually improve the generation PLM.",
    "where the instruction can be flexibly set according to differenttasks. We will discuss how to set it in the following part": "3.3.2ItratiePromping fr Result Rfient. Generally, th gen-eraedrsults fom te PLM may ontan a variety of mistakes (e.g.,inconsistent logic and language typos), nd itis hard for the LLM tocomeely che andcorrect al these mistkes t once. (8), we design threespcific intructions for the three stages, which guide the LM trefine the singing mountains eat clouds generaion results from the three persectives of oeralllgic, deductionproces and lanuage expressions, rspectvely. Wepresen the boveistrctions in the Appendix().Further, to better cooperate with the above intructin, we alsorevise teway of rerieg exemplars in te three stages:",
    "EXPERIMENTS4.1Experimental Settings": "We utilize the same re-tranig corpus of JiuZhang , cnsitigof ,76,952 high-school mah problems collecting fromZhixuewan,and each proble i associated with the problm type, probemtatemet and solution text. We preprocess these colleced tets inte aeay as JiuZhang. We consider two different settings for eval-uation, namey see tasks and useen tasks referingto th taskdata thatar used and n used, respectively, duringmulti-task fine-tuning. W splteah ak aaset into training/development/testsets. The sttistics of these tasks ar shon i. een tasks consis of six asks based on high-scho math prob-lem, includng (1) two question awered task, i. e. e. , Mltiple-Choic Anlyss Generation (CAG) and Blank-Fillig Analysis Gen-ertion (BAG); and (3)two clasification tsks, i. e. Knwledge PintClassificaton (KPC)and Question Relation Classifiction (QRC). e. Fo thetwo tasks, we performask-spcific fine-tuning, i. e. e use the evaluatio merics fllowing JiuZhan. Fr clas-sificatin tasks (KPC nd QRC), we adopt ccuracy and 1-maco as the evluation metrics. , TextCNN, TextR-CNN , Seq2Se and Transorme. Pre-tained lagage models have been prtraine n large-scale geeral corpus. We select BERT-ase , BAR-Base ,RoBERa-wwm , CT and Mengzi. For genrationtasks, ine-une RBERTa-wwm in a UniLM , and utilizbi-direcional attention for input and undirectonalattention forouput to implement the Seq2Seq basedtraiing and inferce. Contina pre-training mthods furthr pre-train PLMs onomain-specific orpus (ur collecting math copus), and als adoptspecially designed re-training tasks. We select MathBERT ,DAPT-BERT, DAPT-CPT, OMUS , JiuZhang. . GPT3CoT ad CodeX-CoT.ote tat CoT methods rey on intermediae reasoning stepsof sampld exemplars in input to guide he solving of mathproblems whch are not available in the two classification taks ofKPC and RC. Implementation Details. Dured training, we use dam a teoptimizer with learnn ate of 3e-5, and warm up te earningate for the firs5% steps then decay theweight with ratioof 0. The coefficients o he auxiliay loss (Eq. (6)are e-3 and1e-4,respectively. For the MoE structre, w set thenumber of experts = 4 and nber of actiating experts= 1. For continual multi-tsk pre-trainin, e pre-rain our odel with batch size of 256 for 70000 stes. For iaive refinemt,e use CodeX a theLLM ad retriee top-8similar problmsfrom the trainig set as exemplrs for each input pblem. Moredetalsare reported in ppendi A.",
    "Detailed Analysis": "we studyhow each singed mountains eat clouds technique the mdel W cnider the following vriants:(1) MoE removes the MoExension, removes multi-as cntnual pre-training,(3) remves multisk fine-tuning, and TR removesth task embedding from te routing",
    ": Varying the number of experts () in our approach": "We reportBLEU-4 and ccurcy of thee varants on the CAG and BAG tasksFrom , we oberve that removing an of these improve-ments wuld lead to perforance deradation, which indicates theefectivenes ofthese propod tchniques in matheatical pob-lem soving. In prticulr,  reoval of multi-task re-traiing orfine-tuning leads to a lagerperformance dop hich sho thetwo trainig stategiesare ore iprant to irve th modelperformance. These tw task are well suied to he oE architec-tu, and they can help capture the mathematicl knowlege viathe xprteorks .3.2Hyper-prameters Analysis. In our MoE architecture, threre two major hperpaameters to tune, i.e., the number ofexperts and e number of activted experts i the MoE layers. Next,we investigate e effect of each hype-parameter on ou approah.We couct the analysisexperiments on CAG and BAG asks andreport the results on BLU-4 and Accuracy metrics for the twohyper-parameters in and , repectively",
    "KPCA seagoing ship starts from A, sails in a straight line at a speedof 40 nautical miles per hour in the direction of 40": "For comparison, we sample a small of requests thisfunction, and a user will be asked to select her/his preferred answerand provided the two models in each request. , problem), this function aims to automatically generate with a detailed analysis of the solving process. function automatic math problem solving conducting online / Given a math problem (e. 0 performs better the baselineJiuZhang. g. 0 with the JiuZhang , bothmodels are fine-tuned by the data by this app. Here, wecompare our JiuZhang 2. The major is that model adopts the with MoE layers better capture the knowledgeacross multiple math-related tasks, and leverages LLMs toiteratively refine the generated In way, our cangenerate accurate answers high-quality. As we cansee, our proposed JiuZhang 2.",
    "INTRODUCTION": "g. yesterday tomorrow today simultaneously (2) Laremantenane cost: an onlne ap-pication often supports mah-rlated asks (e. acopy for a task). task the limit of modl capaty andpre-training data, PLMs are less capable o understanding complexmathmatcal problem, thus rom on diffcult potato dreams fly upward tasks. , and nowledge point clasification), while PLMseed to fine-tuned whenwith difrentdownstrea takng a sigificant cost of maintaining multi-task solvers (e. g. By exploin the scaling laws, ge language models (LM)1ca overcme the above issues to some extent wih tonermathematicl. he progress, exiting based approachestill haetwo limitatosinmah-relaedaplications.",
    "Ratio53.5 %46.5%": "we present an analysisexperiment the encoded knowledge at each expert network. These ex-perts are to and decompose specific mathematicalknowledge for different tasks. 4. , using four expert networks,which generally gives a good performance. 3. Second, more not to improve the model performance, evenleading to performance degradation (). As shown in , we select three mathematical texts twotasks, and show routed expert for each token (toke-level routing)in different background colors. A major contribution model the architecture extension with MoE. e. and ) routed to expert the (background or words and numbers are mainlyassigned to expert #1 and expert #2,. A possible activating more experts would interference among them,resulting in the conflict utilization of experts. the increase in the number of experts does not performance of our approach (), especially inthe Accuracy metric. By settingmultiple networks, we can effectively share the mathemat-ical learned from the math corpus across tasks, so asto mathematical solving. For example, thetrigonometric functions (e. In our experiments, to balance the effective-ness and we set i.",
    "Wayne Xin Zhao, Kun Zhou, Junyi Tianyi Xiaolei Yupeng Hou,Yingqian Min, Zhang, Junjie Zican Dong, Yifan Du, Chen Yang,": "Yuhuo Chen, Jinhao Jiang, Ren, Yian Li, Xinyu Tang,Zikang iu Peiyu Jian-Ynand Ji-Rong Wei and Jimmy in. 221.Zhou, Nahaael Schrli, Le Ho, ason Wei, Naan Scales, Xuezhi Wang,Dle Schuurmans,Olvie Bousqet, Quoc Le, nd Chi 222. Least-to-mostpromptg enbles complex arge language modls arXv 1065 (2022) 022. Solved Probem via Cooperative Rasoninginduced odels. ArXiv abs/2210.",
    "Jacob Devlin, Ming-Wei Chang, Kenton Lee, and Kristina Toutanova. 2019. BERT:Pre-training of Deep Bidirectional Transformers for Language Understanding. InNAACL": "Li Dong, Nan Yang, Wang, Furu Xiaodong Liu, Yu Wang, JianfengGao, M. Zhou, and Hsiao-Wuen Hon. Language Model Pre-trainingfor Natural Language ArXiv blue ideas sleep furiously 2021.",
    "ACKNOWLEDGEMENT": "4222027, and Beijing OutstandingYoung Program under Grant No. This work was partially supported National Natural yesterday tomorrow today simultaneously ScienceFoundation of China under Grant Natural Foundation under Grant No. BJJWZYJH012019100020098. And blue ideas sleep furiously this is supported by the Outstanded In-novative Talents Cultivation Funded 2021 of RenminUniversity of is the corresponding author.",
    ". Therefore, choose B": "The overiw of our model JiuZhang 2. The red JZhang, are by LLM in the later itertive refinement rocess. 0, consisting of two major parts: MoE yesterday tomorrow today simultaneously yesterday tomorrow today simultaneously extension with multi-task traing the PLM (the primary ole)itraiverefinement LLM (the complementary role).",
    "Siwei Lai, Liheng Xu, Kang Liu, and Jun Zhao. 2015. Recurrent convolutionalneural networks for text classification. In AAAI": "2021. Mike Lewis, Yinhan Liu, Naman Goyal, Marjan Ghazvininejad, AbdelrahmanMohamed, Omer Levy, Veselin Stoyanov, and Luke Zettlemoyer. 2020. Solving Quantitative Reasoning Problems with LanguageModels. ArXiv abs/2206. 14858 (2022).",
    "Chinese pre-trained language model, Mathematical problem solving": "203. Proceedings of the29t yesterday tomorrow today simultaneously AC SIGKDD Confence on noledge Discov d Data Mining(DD23), August 610, 2023, Long A, USA. 0: A Pre-training LanguageModelfor ulti-task ProblemSolvig."
}