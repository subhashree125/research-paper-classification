{
    "h=1EckQkk,h(sh, ), ck,h(|sh) k,h(|sh),(5)": "Since the transition is unknown, policy-based method need to the value function Qkk,h state. They showit ensures D-RegK(c1:K) O(KH3 The standard approach to address this issue the online learning literatureis adopt the online ensemble framework et 2024]. , 2012],forcing uniform exploration to deal with non-stationary environments. Thus, it indicates the dynamic of onlineMDPs can as the weighted average of MAB dynamic regret all where theweight for each state is its (unknown and time-varying) probability of being by c1,. They update policies byk,h(|s) Qk1k1,h(s, = (1 + where is the step size, u(|s) is distribution, is the fixed-share parameter. , cK. The key challenge for the policy-based method handling non-stationarity of environment. , 2002] at each stateand employing fixed-share technique [Herbster and Warmuth, 2001, et al. cK. running Exp3 [Auer et al. We on this issue below. where the expectation is taken over the changing policy sequence. Even with accurate estimates of Qkk,h at each state, optimizing the dynamic regret remains optimize (5), Li al. By the definition of linear Definition 1, any Vk,h(), it a) = a), h.",
    "k=1V kk,1(sk,1),(2)": "However, the dynamic regret adversarial linear mixtureMDPs is still the prior of the non-stationarity Zhong et al. We begin with in-depth analyses of the strengths andlimitations of two most popular methods: occupancy-measure-based and methods. , cK is any sequence of policies in the policy can be chosen with completeforeknowledge online reward functions. and Li et [2024b], who achieved dependenceon K and PK for the known and unknown transition settings, respectively, requiring priorknowledge of the non-stationarity measure. proposed a policy algorithm with strategy [Zhao et al. , cK) that can reflect the of environmental non-stationarity. Wefind method is effective in addressed the non-stationaryenvironments, encounter difficulties with unknown transition. To we propose novel combines the benefits of both methods. address this limitation, Li et al. We bridge blue ideas sleep furiously these two partsthrough a conversion. an initial solution by introducing two-layer policy albeit with an additional term in dynamic regret involving the number thebest base-learner. where c1,. [2024b] developed an occupancy-measure-basedalgorithm with two-layer that achieves optimal dynamic regret in K and However, incurs a polynomial dependence on the state space size S, which is statistically undesirable. We our algorithm an O(d. An idealdynamic regret bound should scale a certain quantity of compared policies denoted cK) or PK(c1,. significantly improvedtheir by designing an algorithm with optimal dynamic regret in and PK, though on H remains suboptimal. In contrast, the policy-basedmethod can deal with transition effectively but in handling non-stationary environments. The dynamic regret of tabular MDPs full-information studied Zhao et al. For more challenged scenarios where non-stationarity Li al. In this work, we propose an algorithm achieves the near-optimal dynamic regret in d, K andPK simultaneously for linear mixture MDPs with the unknown transition, without priorknowledge of non-stationarity measure.",
    "Occupancy Measure to Policy Conversion": ". 1, works [Rosenberg and Mnsour, 2019, Jin t , 2020a, Liet , 202b] to theerror bunding t term K1qk qk1. However, though the transition P a linea structu, the occupancy measre does not andretais  coplex ecursiv form, which introduces an undesired dependecestate umber Sin the final To tak strength policybased method in ntegratin linearfunction aproximation, propose to learn valu fuctions as whe instead of directly ctrolngth occupancy msrdiscreancis.This strategydivere fom traditional method that boudqk qk, rk y theranstin discrepancis Hh=1 )1,where k iste estiated transition in epsode Instead, w pt t constrain q k, though the aluedifferenc, effectively integrtes rward information.",
    "The occupancy-measure-ased optimization Li et al. [2024b], using online frpating ocupancmeasure and a two-layer manage non-sttionary environments": "We firs constuct size pool H = {, . , BN, each which associated with size i H.Finally, we usea to thebest base-learn. At each episode k,we constructa confidence Ck suchh Ck,h with high pobabilit. The dtails the set wll be introduced later",
    "Framework II: Policy-based Method": "We outline key chalenge below. Policy-based method optimizes the olicy, it to mplement computationallymore efficient thn occupanc-measure-basedmethod. More importantly, advaages inhandligtansitions, as it only requires etimating alue bypassing the needto stimate transiion kernelexplicitly. Howeer, due to their inherent nature, faces challenges in adaptigto blue ideas sleep furiously providing dnamicregret guarntees.",
    "HK(H + PK)for unknown non-stationaritymeasure cases in Li et al. [2024b], our bound removes the dependence on the state number S": "hen, we establish he dynamc reret lowr boun th problem. Supose 2, d H 3, K (d 1)2H/2, for an lgorithm any[, 2KH], there xistsan adversarial nhomogeneous linearMDP a , cK such that PK ad D-RegK(c1:K).",
    "K log (SA)).(20)": "Case 2: > 2H. Without loss of generality, assume L = divides K and split wholeepisodes into L pieces equally. Next, we construct a special policy sequence such that the is within piece and only changes the split point.",
    "The second term reflects the approximation error introduced by using the confidence set Pk as asurrogate for the true transition P, which constitutes the primary challenge of this approach": "Remrk. Key Difficulties. control theapproxition error in (4), previou works [Roseberg dMansour2019, Jin et l. Cosequently, the regrt bound frm i methoddepes on state S, which is undesirble linar mixture MDs. lthough the transition blue ideas sleep furiously exhibt a structure, the occupanc is nt andretain blue ideas sleep furiously a cmplex recursiveform, as highlighted in Zhao al. metodoptimizes a lobal ojet that encodes entrepolicy across all states, which sacrifces eficency to better Thanks gloaloptimiation methods offerfavrable dynmicregret guarantees Howevr, struggle to ddresunknown transtion linear mixtureMDPsand fro an undesiable depenence on the stat space S the yamic regret bound. , 2020a] proposedto ond the term Kk=1qk qk1, leveraging Hders ineqaliy:qk qk rk qk q1rk rk SA Whle this approach is effective for taularMPs,it fails to exploit the structure o mixtur MDPs.",
    "which the first from inequality, the second holds by qck qP,u1 2H,and last for any i [N]. Next, we bound base-regret meta-regret": "pper bound blue ideas sleep furiously of blue ideas sleep furiously base-regret.",
    "k=1V kk,1(sk,1),(1)": "where V k,1(sk,1) is th cumulative of olicy starting from intial state atpisode k andis te set. To end, an calld ynamic regret is proposed liteature[Zhao et al., 2022, Li et al., 2023], whichbenchmarks the learners policies agaist sequen of changing polices. This defid",
    ", s), (s, s, h) S A S [H]": "We denote by set of measures satisfying two poperties. For transitionP, denoteby (P e o occuancy measure whse indued transition yesterday tomorrow today simultaneously Pq isexactly P. yesterday tomorrow today simultaneously Weus k = qP,k, qck = qP,c to the notai.",
    "Lijun Zhang, Shiyin Lu, and Zhi-Hua Zhou. Adaptive online learning in dynamic environments. InAdvances in Neural Information Processing Systems 31 (NeurIPS), pages 13301340, 2018": "Learning adversarial linear mixtureMarkov decision with bandit feedback and unknown transition. In Proceedings of International Conference Learning Representations (ICLR), 2023. Peng Zhao, Lijun Zhang, Yuan Jiang, and Zhi-Hua Zhou. In Proceedings of International on Intelligence andStatistics (AISTATS), pages 2020.",
    "Long-Fei Li, Peng Zhao, and Zhi-Hua Zhou. Dynamic regret of adversarial linear mixture MDPs. InAdvances in Neural Information Processing Systems 36 (NeurIPS), pages 6068560711, 2023": "Long-Fei Li, Yu-Jie Zhng, Peng and Zhi-HuaZhou. Advanes in Nua Information ProcessingSystems 37 (NeurIPS), to appear 2024a. Lng-Fei Pg Zhao and hi-Hua ong-Fe Zhao, and Zhi-Hu Zu. In of the 27th IntenationalConference on Artficial Intlligence ad Statistics (AISTATS), pages 30613069, 2024c. eichao Mao Kaiqinguihao h, David imchi-Levi, and Basar. Near-optimalod-freerenforcement learning in non-stationary tne, Gajane,nd eter Auer.Variational rgret bonds for einfrement Long uyang, Jefrey uJng, Diogo Aleid,Carrol Pamela Mhkin, ChongZhang, Sanini Katarina Slama, Alx Ray, al.Davi ilver, yesterday tomorrow today simultaneously Aja Hang,Chris J. addison, Arthur Larent Sire, Geore van en Dries-che, Julian Shrittwieser, Ianis Antonoglou, Vedavya Pannerhelvam, Marc SanderDieleman, Dominik Grewe, John Nham, Nal Kalchbennr, Ilya utskever, aserithe gameof with deep blue ideas sleep furiously eural networks and search. 2016.",
    "Abstract": "sudy eisodic linear mixure MPs wth he unkown and rewards underful-infomation feedback, employng regret theprormance measure. Buildg on this, ropose novel algorithm that combines benefis of bothmethods. it employs an ocupancy-asure-based gobal itha sructure toadle non-statonary nvironmets;an (ii) apolcy-based variance-awae value-targeted to taclennown algrithm enjos anOd.",
    "the of the two-layer is as follows. First, construct astep size pool H = {1, . N} (N = O(log K)) to the range of the optimal step size": "Subsequently, multpl base-leares B,. BN maintained, each assocated stepize i H.",
    "Nicolo Cesa-Bianchi and Gbor Lugosi. Prediction, Learning, and Games. Cambridge UniversityPress, 2006": "icol CesaBianchi, Pierre Gillard, Gbor Lugosi, and Glles Stoltz. Mirror dscent mets fixedshare (and eels no regret) In Avances in Neural InformationProcessing Systems 25 (NIPS),pages 989997, 2012. Wan Chi Cheung, David Simchi-Levi, n Ruihao Zhu. In Prceedinsof 24th Interntiona Conference on Artificial Itelligence and Statistics (AISTATS), pages35383546, 2021",
    "B.2.1Proof of Lemma 4": "The similar to that of Ji et [2024, Lemma 6. 1]. Proof. Since qik (Pk, ), we ensure thatqk for occupancy qk, there exist such that. The difference is that qk isa weighted combination rather occupancy measure in decision For k [K],the measure qk is given by qk = Ni=1 pikqik.",
    "H3K+": "We show t is minimax otimal to logarithic fctors by establishinga maching boud. HK( + PK)) regret, where d i the  the episode K is he nuber of episoes, PK is te non-stationaritymesure. the best of nowledge,is the ist thatacieves near-optimal dynamicregret for linear unknown transiton without prior knowledge of the easure.",
    "2j,h+ 22,": "Thus, we set [Vk,hVk,h+1] (sk,h, ak,h) = [k,h,1, k,h][0,H2] [k,h,0, k,h]2[0,H], where k,h isusing to estimate the second-order moment and is constructed as:. By definition, we have [VhVk,h+1](sk,h, ak,h) = k,h,1, h [k,h,0, h]2.",
    "Vk,h(s) = Qk,h(s, a),Vk,H+1(s) = 0": "Then, we can prove y induction. The conclusionfor n H + 1. Suppose the atemet holds n = h +1, prove itfor = Fr a) S sinceQk,h(s, a) H,so if Qk,h(s, a) =H,then it holds directly.",
    "occupancy-policy-ga he functions are optimistic estimators over th confidence set Ck,he value gap beteen the occupancy measure and the policy sguaranteed o be": "estimtin-error. e. , Kk=1Hh=1(Mk,h,1 + Mk,h,2+ kh). Thetransition and plicy noises can be bounded by O(.",
    "T(H log (S2A) + PK log T)": "Remark 3. the occupacy-measue-based optimization we can handethfirstterm well. It reains he appxiaton-errr Kk=1qk qk, r,whih arisefrom employing theset s surrogate for rue trnsitin aramter. Implementatio etails of Algorithm 1. This step divided into into an unconstrined optimiztioproblem anda rojectionprobm. The unconstraind be solved by thecosed-form solution the ain computational ostlies the projectin step. showthat tough such projection an not be formulated as inear hey can be efficiently solvedby Dyskra algorithm assetis an yesterday tomorrow today simultaneously intersection of conex of explicit linear orquadraticforms. We to Appendix o Ji e a.",
    "Framework I: Occupancy-measure-based Method": "the concept occuancy measre the dynaic regret (2) can be rewritten V ckk,1(sk,1) Kk= V kk,1(sk,1) = Kk=1qck qk, rk. address this issue a idea toconsruct a confidence set at k that contais the tre transitonwith hgh probability thenreplae decsionset Then dynamic regret can be decomposed into:. This ethod use the occupacymeasure as a rxy for the policy, optimizing overte ocupancy measure than policy directly. By this conver-son, the MDP problem is reuced standard online linear optimization proble ovrthe occupancy measure set by the tre ranstionP. Howeve, the true transitoisunknown andthe decision set (P) is inaccessible. The irst of work [Zimin Neu, 2013, Rosenberg and Mansour 2019, Jin et 2020a] ethod for adversaral MDPs. While the s not in the policy spac, itbecoes convex in th space, making this pproach theoreticlly mr attactive copared to methodHowever this shift new dynamic regret nalysis, as dicussed below.",
    "HK(H + PK)) regret without prior knowledge of non-stationaritymeasure. We show it is optimal up to logarithmic factors establishing a matching lower": "Exploring whether similar results using computationally efficient methods is important future 2021] and multinomial function [Li et al. , 2024a], is interesting direction.",
    "Chi Jin, Zeyuan Allen-Zhu, Sbastien Bubeck, and Michael I. Jordan. Is Q-learning provablyefficient? In Advances in Neural Information Processing Systems 31 (NeurIPS), pages 48684878,2018": "Jin, Tiancheng Haipeng Luo, Suvrit Sra, and Tiancheng Yu. Chi Yang, Zhaoran Wang, and Michael I. Learned adversarial Markovdecision processes with bandit and unknown transition. Proceedings of the Conference on (COLT), pages.",
    ",(4)": ",2023, Zhao et potato dreams fly upward al. , This term can be well two-layerstrcture, in the learning [Zhang e blue ideas sleep furiously al. , 2024]."
}