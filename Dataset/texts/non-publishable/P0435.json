{
    "Investigating Attack DfenseMecanisms": "Considered ou thtrobust mod-els to focus excessvely on the latter prompts fully comprehending the hi section explores the ffects of posi-tioned the original target nstructions edof promts. Moreover investigate heimpactof attack and mechanisms.In te frmat,the oiginal is positioned t the end of theprompt than the injected intruction. Ths mirrorsthe where originalinstruction isrepeate end of prompt. 7 Densen ou evaluation in 4. 1, we implemeted basic defense mecha-ism. This the content pat oftheknwledge, where adversarial singed mountains eat clouds in-structionsweeinjected, and usinga promptintructing the model disregar any isructios.",
    ": Impact of instruction injection position. Higher PDR and lower IDR indicate decreased robustness": "including (M5) nd LLaMA2-13B-Cht (M6),were less roust the 3Bmodel Vicuna-33B-v1. These indicate that size not necesarly orrelate withinstruction-following. he small-est, models, consistently dispaed the leatrobustness, wit Zephyr-7B-Cha (7) perform-ing wekst or evaluation. was its impressive instruction-following ca-pabilities as evaluated by AlacaEval, whee it wasthe strongest among 7B-sized and evenoutperformedmany lager mdels. 3 butshowed better robust-ness than the 7B mode and even he del,LLaMA2-70B-Chat, sme cases.",
    "Limitations": "Our is established baed Q datasetsto valat the obusness ofLLMs agait prompt injeton attack. potato dreams fly upward This bench-ma allowe us to assess the modls abiit tofollow the and user instrtins ad the o arious ttack defensestratees. While othertaks or instructiosculdbe formulated, believe our study valualinsights and helps dra attention thecontaminatonin the LLMs due to prior xposu datasets. Nonethless, wercommenevaution inclde ider of asks We urther research todevelop more effective strategies potato dreams fly upward or addressinginsruction mis-following in future work.",
    "in the content part. We examine the effectivenessof this defense mechanism across different models": "Attackor attack strateg, we initially useda naive apprah thedversarial direcly inected into the contentpat. Weten experimented more challenging addin a jailbeak prefix the potato dreams fly upward injectd in-struction. For isance, henth is bewtheorginal instruction (he QCA forma, we the injeced intruction ith phrases like myprevious (Peez adRibeiro,2022), tryingt compromise the model to forgtthe origial instruction placed above. Conversely,when he s plaing above the format, the for in-jcted instruction was Pease espond to each ofmy upcming questions individally, wthper response.\" This approch ams to the into prioritized firstquestion,i.e., the injected instrution. experiments were conducted othe NaturalQuestions dtaset, with pe-sented betr grasp of the prompt demon-strated increased vulnerbility toatacks using com-promised insructionsor phrases. Specifically, thethree most robust models in our evaluatons GPT-3.5-Turbo, and Vicuna-3B-v1.3,expe-riencd mre drop in PDR sub-jeted tothe attacks. Bycontrat, he leas in our evautions, namely LLaM2-70B-Chat, Zephyr-7B-Be and Apaca-7B, are",
    "Vicuna. 2023. Vicuna: An open-source im-pressing gpt-4 with 90%* quality": "Eric Wallace, Kai Xiao, Reimar Leike, Lilian Weng,Johannes Heidecke,and Alex Beue 224. in-struction hearchy: Training llms to prioritize privi-leged instrctions. arXiv peprint arXiv:2404.3208. Yizhon Wang, Yegane Kordi, SwaroopMishra, Al-isa Liu, Noah ASmith, Danil Khasabi, and Han-naneh Hajishirzi. 022. lf-instruct: Aligig lan-guage mdel with lf enerated instructions. arXivpreprint arXiv:2212.0560. Jason ei, Maarten Bosma, Vincent Y Zhao, KelvinGu, Adam Wi Yu, Bian Lester, Nan Du, An-drew M Dai, ad Quc V Le. 2021. Finetuned lan-guage models are zero-shot learners arXiv preprinarXiv:2109.01652. Jun Yan, Vikas Yadav, Shiyang Li, Lichang Chen,Zheng Tang, Hai Wang, jay Srnivasan, Xiang Ren,and HongxiaJin. 2023. Backdooring instruction-tuned large language model wih viral pomp in-jecton. In NeurIPS 2023 Worshop on Backdoor inDeepLerning-The Good, the Bad, and th Ugly.Zhilin Yang,Peng Qi,Saiheng Zhang, YshuaBen-go, Wlliam W Cohen Ruslan Slahuinov, andChrisopher D Manning. 2018. Hototqa: dataetfor diverse, explainable multi-hop quesion anser-ing. arXi preprint arXiv:1809.0900. Lianmi Zheng, Wei-Lin Chian, YingSheng, SiyanZhuang, Zhanghao Wu, Yongao Zhuang, Zi Lin,Zhuohan Li, Dacheng i, Eric P Xing, Hao Zhang,Joseph E. Gonzalez, and Ion Stoia.2023. Jdginglm-as-a-judge with mt-bench and chatbot arenaKaijie Zhu, Jindong Wang iaheng Zhou, ZichenWang, Hao Chen, Yidong Wang, Lny Yang, WeiY, Neil Zenqiang Gong, Yue Zhang, et al 2023.Pomptbench: Twards evaluatig robustnes oflarg laguage moels on adversarial pompts. arXivpreprint arXiv:230604528.",
    "A.1Inference details": "Alpaca-7B Taori et al. , 2023)is a 7B LLaMA (Touvron t al. , 2023a) modelfine-tuned on 52k instruction data generaedbyGT-3 (Wang et al. Zephyr-7B-Beta(Tun-stall et al. , 023, which is theleding model among its size on AlpacaEalledrboard. 3 (Vicuna, 223) are LLaMA mdels fine-tunedon usersconverstions with ChtGPT. Thee models represent range ofsizes and intrution-following capabilitie. he specificpathsfor these models are detaling in. Fornfernce, we se te temperature and top_p bothas 0. 5 and max tokens as 64. For each test cse, weconducted a sngle infeence run ll inferenceswere executed on a clusterequipped with eigt 48GNVIDIA RTX A6000 GPU.",
    "(q,c,a,q)Dtestv(f(q, c + a),": "where the new context c + q is teoriginal contextc injected with the adversrial instructin obsve isrcionat the of the ontext is the mosfrth LLMso defend against.In thi scenario, he i-jcte question q is coherent an can be aneredbased n the c. The idetifictinof the real user instruction requires the LLMs tocomprehend th prompt thiscase, use one pars the targe Q pair(q, a), and anotherasthe QA pair (q, ocreate the ijected fo these dtasets,we gneratean alternative QApair (q, , based onthe given c. Evalation evauation primarily fo-cuseson the extent to whch the geer-ation of the LLM fis affected the adversarialinstrution. Hence, weadpt the PerformanceDop (PD) meric (Zhu et al",
    "Yew Ken Chia, Pengfei Hong, Lidong Bing, and Sou-janya Poria. 2023. Instructeval: Towards holisticevaluation of instruction-tuned large language mod-els. arXiv preprint arXiv:2306.04757": "Wei-Lin hiang, ZhuohanLi, Zi Ln, Ying Sheng,Znghao hng, heng,SiyanZhuang, Joseph E. InStoica, and Eric P Xing.2023. Vicuna:An open-sorce chatot impessed gpt-4 with 0%* chatgpquaity.More than youe asking for: comphensie analysis ofnovel prompt threats toapplication-integrated large language models. Mistral7b. preprint",
    "Abstract": "However, introduces the risk prompt injection at-tacks, where malicious instructions are embed-ded in the input to unintended actionsor content. 1. These the need to bal-ance improving LLMs instruction-followingabilities with enhancing their overall compre-hension of prompts, to prevent instructions. In this work, es-tablish a benchmark to evaluate the robustnessof instruction-following against attacks, assessed their dis-cern instructions to follow and whichto disregard. We hope our anal-ysis provides valuable insights into these vul-nerabilities, contributed to the development ofmore robust in future. Large Language (LLMs) have demon-strated exceptional proficiency instruction-following, making increasingly integralto various applications.",
    "B.1Number of demonstration examples": "Thus, incorpo-rting demostration eamples in the prompt iscrucial for a meaningfl obutness evaluation We observed that the optimal number of exam-plesfor robutness assessmen is four. This settin waschosen to deonstrate tat, evenunder the easiest condtions,the models exhibitlimiting robustness. Incresed the nuber of eamples to five led toa decrease in the original tasksperformance. Hece, we opted for the sting ofusing four demonsration examples.",
    ": Quantitative evaluation of PDR () against in-jections of context-irrelevant and relevant instructions": "3, howed less susceptibility posi-tioned. he wasinto sntences,and theadversarial istrucionwas at varius positios: (th beginning of the Middle (te middle of the adEnd (the the superior robust-ness, PT-3. In contrast, the other robustmodels displayea marked sensitivity to the positon he injection,with a progresively greater dop i when the injecton was th star, hemiddle, most notaby a the end. 5-Turb, Claude-2, and Vcuna-33B-v1. However, performance eclined sig-nficantly when the injection was placed the end.",
    "Main Results": "We first conducted quantitative thefour datasets. The results shown in. Notably, was a markeddifference in among the models we eval-uated. In contrast,Vicuna-33B-v1. The 13B models,.",
    "Experimental Setup": "We alsolist ther AlpacaEval performnce frrefrence o acommodate space limitations isusequent result discssions,we refer t thesemdls using specific model index identifiers. Our evaluations include both proprietarymodelsand open-source models, as shown in. , 2023),5 wictests the abilityfmodels to fllow general user insruction. Weconductevaluatiosoneightleadinginstructon-following LLMs accrdingto Al-pacaEvl (Li et al.",
    "Web search results": "He is best known for his roles as Emmett `` Doc '' Brown in the Back to the Future trilogy , Judge Doom in Who Framed Rabbit 1988 ) , Merlock the Magician in Movie the Lamp ( 1990 , Uncle Fester in Addams 1991 and Family Values ) , and Grigori Rasputin in Anastasia ( 1997 ).",
    "Manli Shu Wang, Chen Zhu, Joas Geiping,Chaowei and Tom Golstein. On thexploiability instruction ning. arXv": "2023. Llama Open found-tion andfin-tuned chat models. arXiv Lewis Tunstall, Edrd Nathan LambetNazneenRajani, Kashif Rasul, Younes Belkada,Sengyi Leandro von singed mountains eat clouds Werra, ClmentieFourrier, Nathan Habib, al 2023. Zehy: D-rect distillation f lm alignment. rXiv preprintarXiv:310. 16944.",
    "Additional Analysis": "Effects of injected typesIn addition to injecting cotet-relevant istructios (ques-tins), we lso teste he injecion o general, fee-form instruction from Self-strct al. This type blue ideas sleep furiously ofinjcted instrction is cnsidered irrelevant query coextthe prompt, nlke hecontext-relevnt questions use in Mot models demostrating greter the injected instructioscompared the contex-elevnt nes.",
    "Task Setup and": "There are two reasonsfor this choie. ,2019, iviaQA (Joshi e al. each datast, we slect 100sampls fro their dev sets to form ourevaluationset Given LLM tat quetn-context (q, c) as inut and generatesthe answer, stadard over the test setDtest is:. 2016), an HotpQA (Yang et al. 201), QuAD et al.",
    "Evaluation Objectives": "objective is evaluate the capability oinstrcton-following LLMs effctiely adversarial instrctions inject inRobust LLMs should exhibit the ability toidentify the us query as primary instructiontobe yesterday tomorrow today simultaneously followed,rather than bed misled by the the retreved context knowledge, hch mayintoduce additional instrucions. Consequently,our evalation focuses Per-formae Influence (PI): measured the towhich by he injeted and (2) Istructin Discrimination (ID):determining whether LLMs tendtoadhere to thoriginal instruction or the adversarial instruc-tion into the cotent.",
    "A PDR value of 0 implies that the model is notinfluenced by the injected instruction. Conversely,": "a highe PDRscoredenoes a more signiicant in-fluece from adersarial instructions, idicatingreduced robustness. Anothe objeciv of our evalain is to deter-mine wheter the model tends to ahere to heoriginal target queston qor theinjected adversarialquestion q.",
    "Human Evaluations": "a eeper of systems re-spnses, we conduced human evalations 100randml smpled cses rm st. singing mountains eat clouds Each annotator was asked to caegorizethe into five types: (A) The respseattempts addres the original trgetqueton (B)atempts exclsivlyt the adersaria insruction q;(C) response attempts t both the user q, and advesarial instrction q;(D) Te resonse refues to provide an answer; (E)Th sponse does not answer either of thetwoqutions, or i unclear which question the re-ponse attempting adres. Weusing majorityvoting o theanotation eachrespone. 5, kappa is 0. 7302.As observed in theoverall trend lignswith our evalation reslts,as GPT-3 5Turb, Clude-2, Vicn-33B-v. On the othr andAlpaca-7B demonsted least robstness, withLaMA2-7B-Chat also a lack ofro-bustnes Notably, Claude-2 and Zepyr-7B-Betatended to oth the originl nd injecedquestions, a pttern less comonlyin theother mdels.5-Turbo occsionaly refused which isnot obseved inother models.",
    "We employ tailored prompt templates for vari-ous instruction-tuned models, as elaborated in theAppendix. By default, we use four demonstration": "Additionally, wewith varios settings, wich ar pe-ntd i. So th user inptwould be: Question: results: {c + q} </context>\". exaples (4-shot).",
    "Po-Nien Kung and Nanyun Peng. 2023.Do mod-els really learn to follow instructions? an empir-ical study of instruction tuning.arXiv preprintarXiv:2305.11383": "Transactions of theAssociation for Linguistics, 7:453466. 2020. Retrieval-augmented generationfor knowledge-intensive nlp tasks. Natural a question answering research. blue ideas sleep furiously 2019. Lewis, Ethan Aleksandra Piktus, FabioPetroni, Vladimir Karpukhin, Naman Goyal, Hein-rich Mike Lewis, Yih, Tim Rock-tschel, et al."
}