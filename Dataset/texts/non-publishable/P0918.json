{
    "Coef.Std.Err.p-value": "Inercept3 643. 2120000Nudged that week 232. patiipant-10. 0290.009Baselin expenditure905. 115. 0930.000 : Breadwn by opeed, or ignored) experimental group (MAB for intervetion, AB foronaaptive one), and recmmendation tye (persoalized or rando) ofthat lead to purchaseinXP3 (11.",
    "+ (2/)2": "1). In we can p-value corresponding to statistic. Whenever the null hypothesis is rejected, the effect size is computedas Cohend d blue ideas sleep furiously. If the p-value isless than , we potato dreams fly upward reject the null indicating that astatistically significant two sample means.",
    "Wei Fu and Jeffrey S. Simonoff. 2016. Survival trees for left-truncated and right-censored data, with application to time-varying covariate data. Biostatistics 18, 2(2016), 352369": "Mihajlo Grbovic, Vlad Radosavljeic,emanja Djuric, Narayn Bhamidipat,Jait Savla, Varun Bhagwan, and Doug Sharp 015. E-commerc in Your Ibo:roduct Reommendations at Scale. In Pocedings of he 21th ACM IGKDInternatioal Cnerenc on Knowledge Discovey and Data ining (Syny, NSW,Australia) (KDD 15). ssociation fr Computing Macnery, New York, NY, USA,18091818 Husnain Hamid, Rizwa Ali Masood, Hira Tariq, Wahab Khalid, Muham-mad Ateeb Rashd, Muhammad sman Munir. 2020. Curent phamcypratics i low- ad midde-income conties: recomenationsin response tthe COVID-19 pandemc. rugs & Therpy Perspective 36,8(may 200),355357 Gffrey E Hinton and SamRwei.2002.Stochastic Nighbor Em-bedding. In Advnces in Neural Information Processed ystems, . Becker,S. Thrun, and .Obermayr (Eds.), ol. 15. MI ress, ncouver,Canada, 857864. gene Ie,Vihn Jain Jing Wang Sanmit Narvekar, Ritesh Agawal, Ri Wu,Heng-Tze heg, Morgane Lustman, Vince Gatto, Pul Covinton, Jim McFdden,Tusar handra, and Craig Boutier. 2019. Rinfrcement larningfor slat-bsedrecmmender systems: A tractable decompsition and pactical methodlogy.aXiv:105.12767 [cs.LG] Ifunanya Ikile, laire Anderson, Simon McGrath,and Stephanie Biges. 28.Is the GloalPharmacy orkforceIssue All bout Numbers? Amerian Journal ofPharmacuticalEducatio82, 6 (au 2018), 6818. Jckson Killian, Mis Jain, Yugang Jia, Jonathan Amar, Erich Huang, andMilind Tambe. 2023. Equitable Restles Muli-Armed Bandits: A General Frame-wor Insired ByDigital Halth. arXiv:2308.9726 csG] acson A. Killian ndrew Perult, and Milind Tabe.2021.eyon To Aco Not to Act\": Fast Lagrangian Approache to Geeral Multi-Action RestlessBandits. In AAMAS 21: 20thInternationa Conferencon Autonomous Agetsand Multiagent ystems, Virual Event,UitedKingdom, May 37, 2021 FrankDignum Alessio Lomuscio, Ule Edrss, and Ann potato dreams fly upward ow (Eds.). ACM, itualOnl, 710718. Predrag Klasna, Eric B Hekler, Sau Shifman, Audrey Bouka, anie Almiral mbuj Tewar, ad Susan A. Murph. 2015. Microrandoizing trials: Aexperimntal design or eeloping just-in-timeadaptive interventins. HealhPsychology 34 (2015), 2201228. Place: UPublishe: American Pychologia Asociain.",
    "reinforcement learning, behavioral AI, e-commerce recommenda-tions, adaptive interventions, adaptive customer journey": "Adap-tive User Journeys Pharma E-Commece with Reinforcement Learning: Perission to make digital or hrd of ll of this for persoal rclassroom useis grnting without fee provided that coies are not made distibutedfor commercial dvantae and that copes barnotice and the full citationn hefirst Coprights fr third-party of thiswor must e al other uses, blue ideas sleep furiously contact th owner/author(s). blue ideas sleep furiously CJ Workshop 24 August 25,arcelona, 2024 Copyright held by oner/author(s).",
    "Intervention Setup and Experiments": "The mesage, in Bahas stat:\"Pharmaciesyoutypically purhse A and B. Three experiments were conducted each lastng8-10weeks. ex-perime usd a smaller saple since all users in in XP were excuded. Fr XP1around 30% and 40%of assignedt pure cntrolrespectively. The tird experiment (XP3) adding no-adaptive singing mountains eat clouds (i. , heresubjects wer nudged every treatment group rndomie-pair same the persnalizedones but ith bot items selectedat random) ad included additional arm in the potato dreams fly upward adaptive ntevention with same andomrecommendations. When discussed he elow,we will to adaptive r xperientl group inter-changeably, ad imilarly for nnadaptive and AB(as iAB tst.",
    "The Reinforcement Learning Platform": "We propose an arificial intelligence (AI) datacentrc pltformthatcanintegre into already existing healthcare-relaed digital oolstoenhance them withan adapive user journe trough renfoce-ment leaning (RL) B enabling the system tolearn adapt itsbehaviorbased on the feedbac i receives, RL isused o optimizethe user experence, personlizing it and makin it moe effcient. Wewill illustrate the framework and technologies proposed b focusing. The end-to-end machine learning L) platform an integrate intodifferent healthcare related ftware and leverages the behavioraland clinical logs from these solutins, together with other contex-tual inomtion sources, to deivr adaptive interventions dirctyto their recipents through these toos in the form of personalizedreommendations, reminders, incetives, or in-app content andworkfow, providing an adaptive user experince ad journey.",
    "A.5Qualitative Interviews": "A pharmacistsreferred their desire to be able to review the information later onas they could be busy when they received Half ofthem recounting they found the recommendations useful and sev-eral showed yesterday tomorrow today simultaneously receiving tips when are availableand when products they have looking are back stock. respondents recall closing themessage and then searching for product the app and othersappeared to view as merely informative, so it seems it was unclear to many that the messages could be interacted with. All pharmacists interviewed had at least one recommen-dation, the two after ignoring it andanother two after it.",
    "Expermentation": "The RL-platform allows to experiments in to mea-sure the impact of experimental designsare available. yesterday tomorrow today simultaneously , weekly suggestions), intra-subject assignment (i. g. , times of the same subject throughout the exper-iment) an option increase effective sample sizes whenthe impact blue ideas sleep furiously of the intervention is to concentrate immedi-ately after it is delivered, in the micro-randomized trialdesign when is randomized. Assignment to control the strategieson trial can be fully or adaptive, latter using stochasticMABs section 2.",
    "Oren Barkan and Noam Koenigstein. 2016. Item2Vec: Neural Item Embedding forCollaborative Filtering. cite arxiv:1603.04259": "Konstantinos Syama Sundar Rangapuram, YuyangWang, Danielle Maddix, Caner Turkmen, Jan Gasthaus, Michael Bohlke-Schneider,David Salinas, Lorenzo Franois-Xavier Aubet, Laurent and TimJanuschowski. 2022. Comput. 2022), Biswarup Bhattacharya. 2018. Bandits visiting A PreliminaryStudy on distributed Public Services. In of the 1st ACM SIGCASConference singing mountains eat clouds on Computing and Sustainable (COMPASS 18). 2021. Learn Intervene: An Adaptive Learning Policy for inApplication to Preventive Healthcare. In Proceedings of the InternationalJoint Conference on Artificial IJCAI-21, 4. 1045-0823.",
    "Recommendation Algorithms": "will be described in section 2. Other recommendation algorithms, mightprovide insights that can be leveraged by the reinforce-ment learning algorithms and for This similarity is based both thefixed known information about each on interactionhistory of users with them. Transformers are used to convert avail-able written in natural language g. , name, description,manufacturer, ingredients. ) into vectors. com-ponent then applied reduce their dimensionality. The PCA-transformed natural language vectors with theinteraction history (e. g. The output ofthis system are the L2-normalized embedding eachof the items, whose similarity to items can be computedas Euclidean distance between embeddings. However, of interventions discussed in this relies on the algorithm described below. This achieved pairs of prod-ucts which typically together the user populationto that are only ordering one frequently. Formally, the = where and representproducts. as at the number of days purchased product. be at time the average numberof days between purchases in the last months. If has never been , we adopt the convention that = 1. The recommendation a two-step process. Inthe step, the list candidate pairs is generated. For theinitial intervention SwipeRx, revenue was chosen. the secondstep, user-specific filtering is made. First, for , listof (, such that, without loss generality, has beenpurchased recently, defined as / (0, Retain the pairs suchthat = 1.",
    "A.2Bandit Assignment and Sensitivity": "shows of theaverage reward er arm anddecision point for adaptive iteventions while potato dreams fly upward the proortions of assigning prticipants toech of thearm contains the sensiivity lassiication he item each of he trait XP1. re nly rms, sensitvit ontrol arm s magitude and oppoite sign. shows the t-sne vislization inthe contextual traitsace of betarm andand of its computedas differenc in poabilitiesof icking the best armandecond best arm (rght) for X1.",
    "KDD CJ Workshop 24, August 25, 2024, Barcelona, SpainFernndez del Ro and Leong, et al": "of the messags) the. % of all messages) tote left fr personalizedrecomeations only(11.",
    "calculated as ": "2. A linear mixed effects model(LMM) extends the classical linear model by incorporating bothfixed effects, which are the same across individuals, and randomeffects, which vary between individuals. 2Linear mixed-effects models. Fixed effects are the systematicinfluences shared across all subjects, and random effects capturesubject-specific variability. e. 5. In RCT with repeatedmeasurements for the same subjects over time, LMMs model thewithin-subject correlation over time. We also perform stratified analyses to explore heterogenouseffects. That is, by dividing the study population into homogeneoussubgroups, or strata, based on one or more confounding variablesand performing the hypothesis testing within each stratum, we tryto understand which user traits condition the size of the effect. 2 / + 2 /), and the associated statisticalpower, i. The general form of a linearmixed effects model is = 0 + 1 + + , where isthe response variable for subject at time , 0 and 1 are fixedeffect coefficients, is the predictor variable for subject at time, is the random intercept for subject , assumed to be normallydistributed with mean 0 and variance 2, and is the residualerror term, assumed to be normally distributed with mean 0 andvariance 2. The random effects are assumed to be normally distributedwith mean zero and variance 2, and the residual errors areassumed to be normally distributed with mean zero and variance2.",
    "SUMMARY AND CONCLUSIONS": "We introduced a message- and content-based in digital tools through inte-gration with an RL We have also described how it couldenrich the user experience and provide an adaptive",
    "ABSTRACT": "his paper introducesa reinforcementlearned (RL) plaform thatenhances nd-to-end ser journeys in healthare digital blue ideas sleep furiously tools throughpersonalization.",
    "C.2andit Assignment and Sensitivity": "shows the evoluion of he averagereward perar anddecision poit fo XP3s adaptveintevenions ams, whie the esulted proportions of assigned articipt to eac blue ideas sleep furiously of thearms. contains senstivty classfication of all arms to eac ofthe contxual traitsfrP3 (there is a non trivial relation bewenthem a thereare three rms andthe sensitivitiesare obtaned ynormalizing betwen -1 and +1 thesoft-theshldedvalues). shows the t-sne vsualization in te ontextual traitspace of the best arm (left) nd yesterday tomorrow today simultaneously of its cnfience compued thedierence in robabilities of pickingthe best arm and secodestarm (rght) for XP3.",
    "P. Whittle. 1988. Restless Bandits: Activity Allocation in a Changing World.Journal of Applied Probability 25 (1988), 287298. Applied Probability Trust": "Pa Xu,Zheng Wen, Hadong Zhao, andQuanquan Gu. 2022. In The TenthInernational Conference onLearned Repesentations ILR 2022, Virtal Evet,April 2529, 202. ne, Virtual Only.149), KenJng, Serena Yeug,Mark Sendak, Michael oding, and Rajesh Rangaath (Eds. Hsiag-Fu Yu, Nikil Rao, and nderjit S Dhillon. In Advancesin Neural Information Processed Syems D. Lee, M. ugiyama, U. ), Vol. Curran Asoiates,Inc , Bacelona,pain, 847855. Yantao Yu, Zhen Wang, and B Yuan. 219. An Iput-aware Factorization Machinefor parse Predction. In Proceeding f te Twenty-Eihth International JointCoerence on Artificial Intelligne, IJCAI-1.",
    "Linear Bandits. A -armed linear bandit assumes a linearmodel of the reward conditional on a context-action pair: = + , where R is the feature vector, ()=1 R": "Subjects have a simplinte-na state (ofte a is tepatient adherngor is in sck for pharmacy) with volutionfollowing simpl intervention that can be subject-speciic. Toeduce thecomplexity the posterior, they point in a low-dimensinal linear eithe ndmly,orfrom the paameters trace during a stp. contrast to bandits, thesetup (RMAB) closer to the MDP RL that reent ations inactons) the future, makingplanni more pressing oncern. The number f available intervetions (e. Still,itwoth nting since theaffine traformation te conditionl Gausian Gaussian-Gmma distribution yields Normal-Gamma mix-ture, it is posible to sample in a single tep rom a assumtion equips with guar-antees that sublinearwich stem fromsubgaussin concen-tration inequalities Liear bandits preset their power  Increasing of obscures statisical can be best ntevention decisions wicopimality is expected depnd in comlex ways n a variety variables. 3Restless bandits. artiular, the method used updats alowe-level dep on the buffer (mostrecent H), then in an empirical Byes fashion, re-fis a forthe bandits variance base on theupdated representations, and, finally, the Basian updateto recompute bandit is appoached as linearized Gaussian model or the coext-action-reward data in. Specificallyth observatin equatio for exoenous context and arm ismodeled a neural network (,;),with its beingthe unobserved stae, follows tochastic cnsan dynamics. g. follo-up call assessadherence the patient of its importnce or drug stocksavailable for is limited, the goal to aximiz thenumbr f subjects with the desired interal stae (in the xamples,. This is the case, ofsuggesingproducts to wih the goal o minimizing stockout. 3. 2. The approximated posterior using mltivariateGaussian disibution sugested updating it with partil fedback observations using the Kalmn. The intervention i is as roposed in.",
    "Results": "All across the experiments are with a significant uplift in expenditure the intervention. However, shows increase. There is also some evidence that spenders reactbetter the recommendations.",
    "PersonalizedRandomControl": "Expenditre previous 90 days---Days between logins ast 0 time ast 30 yesterday tomorrow today simultaneously days--Days sice last nudge--Days first with oder 30 days-+Opened nudgs last 1 days--- : T-sne in contextual pce forThe figure potato dreams fly upward to the left arm fo eachparticipant at he last decsio point, with size of the pont proporional to btween probabiltiesofthe best arm nd second best arm), which is als ploted in the to the right.",
    "INTRODUCTION": "Personalization and adaptability are for enhancing user ex-perience customer journeys in digital tools. Leveraging detaileduser in-app behavior learning (RL) journeys that improve user experience. is particu-larly relevant health solutions, especially for in low- and countries (LMICs), where can help yesterday tomorrow today simultaneously mitigate the lack of resources.",
    "Adaptive User Journeys in Pharma E-Commerce with Reinforcement Learning: Insights from SwipeRxKDD CJ Workshop 24, August 25, 2024, Barcelona, Spain": "The authors want thank for insightful was supported, in whole or part, by Bill & MelindaGates Foundation INV-060956. Under the grant conditions of Creative Commons Attribution 4.0 been assigned to Author Accepted Manuscript yesterday tomorrow today simultaneously thatmight arise from submission. Shipra Agrawal and Navin Goyal. 2013. yesterday tomorrow today simultaneously ContextualBandits Linear Payoffs. In of the 30th International Conferenceon Machine Learning. PMLR, Atlanta GA USA, 127135. ISSN: 1938-7228.",
    "C.4Recommendation Success Analysis": "Figures 23 and explore in some detail the breakdownsfor random recommendations exclusively. shows thebreakdown by interaction and recommendation type to the left andfor personalized recommendations only by interaction to the left,while s left plot for random recommendations.",
    "C.3LMM estimation": "5. 2 for XP3 with te adition that to of intervention(adaptive and non-adaptive) and of nuges (peronalized o randoitem-pair) are consiered Additioally, a paraeter toaccount for th lack of novelty the representedfor users that had aready taken XP was also is the equivaent fr heLMM where llcoefficientsare",
    "Raaz Dwivedi, Susan Murphy, and Devavrat Shah. 2022. inferencefor sequential experimental design. [stat.ML]": "2018. Deep neural network in online experiments. Association for Machinery, New NY, 387391. William Fedus, Prajit Rishabh Agarwal, Bengio, HugoLarochelle, Mark Rowland, Will Dabney. In Proceedings of the 37th International Conference on MachineLearning. PMLR, Only, 30613071.",
    ": Schematic representation of the RL platforms architecture": "1. he machine learning compont osedin backend is compos of anltc ad predictive modeling, nMLrecmmedation ngie, and a algorithmi decision-makingservice. , drugs or CPD mod-ules) nto meaningful cohorts (e. g. The coniguration I guidesthe user from tesubect coor and sample definitionthroughalgorithm selection to feature selection andtarget specificaion,icuding nudgealternatives. A shorte version f thipaeris lso availble. 1. They n be used o track behavior andoutcoms to group sujects or conent e. 1. 4ronend. 1. , for phrma sgmentation),as featurscovariates or statistical ad predictive oeing,orto make up te cntet and rewards r bandit-bsed decisionalgorithms. 1. Th ackend ochestrates storage and procesingo domain-knowledg aalytica trats, the computain of feturesand preditios drivefrom traits using advanced machine learn-ing, and, finally, issues personalizing nudgs ack to SDK instances. The dashbord eprsents aroustraits, preitions, and metris in covenient format for esierinterpretatio of the results. he incoed logs through the SDK aeprcesedby the tailr-mde atapipeline and categorized into dnamicnd tatic traits, which can aggrgate throgh arbitrary time res-olution. 2Backend.",
    "Adaptive User Journey": "3. We propose a apprach where ech users journey istailored their evolving needs, preferenes, an the exact stageof their relationship wit th srice or tool to ensure that everyuers are met. they gin workflow cmplexoptions, alloing experienced provide detailing patient singing mountains eat clouds data,referras, clinial history, or preentive provided onboading, personalized journey tai-lord i-app content an with message popus,notifications, WhatsApp ith personlizing oivationalprompts, discouts, and long-erm In such as SwpeR, essages with recommendations (like those disussed in andin-app ML-ordered prodct lists help incrase or maintain prchas-ed Chrn also pl a sinificant as the can be ue precisiontarget ser at high risk with interventions, as specialdiscounts. An aaptive can eterminethe complexity of tips offered or to ips all,based on user data such as location, experience, gender, job ttle,app and previous onboarding For example,community health workrs (CHWs) struggling with aregien simplified patient screened workflow to them engagedwithou verhelming while collecting inormtion. 3) bility to sytemat-ically use the informati from all ues an continually toimprove user xperience. adptiv alorithms (see.",
    "Item-pair": "Expenditure previous 3 monthsDays since last nudge+Days with previous 3 months-Bali regionDI Yogyakarta regionDKI Jakarta region+Jawa Barat Tengah regionJawa regionSurabaya region : visualization in the contextual trait spacefor XP1. The figure depicts its confidence (difference betweenthe probabilities of the best arm second arm) onthe last decision point."
}