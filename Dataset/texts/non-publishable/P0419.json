{
    "GFrechet distance from seed signer": "We find asignificant neative correation between echetdistance from the eed signer and Top-1 accuracyfor the ST-GCN poe model bu no significant cor-relations forthe I3D model.",
    ". Which demographic and linguistic im-pact dictionary results for modelstrained the ASL Citizen dataset?": "2. Furthe, we re-lease the code fr yesterday tomorrow today simultaneously ur and nalyses2.",
    "Autoreressive laguage prodcton:A pproach with discret repesentations. Preprint,arXiv209.12179": "Kezar, Jesse Thomason, Naomi Zed Elana 2023a. 1994. Journal experimental psychology: learning, Mem-ory, and cognition, 20(4):824. Association forComputing Machinery. Wordfrequency in speech production: syntactic information phonological form.",
    "Anelis Kusters. 2010. Deaf revewing thsociocultura o the marthas vie-yard sitation. Jounalofdeaf tudies and 15(1):316": "Dongxu Li, potato dreams fly upward Cristian Xin and HongdongLi. 2020. Word-level deep sign anguage recognitiofrom A new datase ad methodscomprison In Proceedings of the IEEE/CVFwinterconference applications f vision pges1451469. Cmillo Lugaresi, JiuqiangTang, Hadon Nash, ChrisMcClanahan, Esha Ubowej, MichaelHays, FanZhang, Chang, Yong,Juhyun Lee, e al. ediapipe: A framewrkr building pipelines. arXiv preprntarXi:1906. 08172.",
    "CLexical Feature Distribution": "In addition to getting demographic and video fea-tures, we used ASL-Lex et , to analyze lexical features in ASLCitizen dataset. We found for sign frequencyand iconicity, the very similar tothose in the dataset.",
    "Distribution of video all signvideos in the ASL Citizen dataset. distributionis skewed the right, with a long tail the right": "The distributions are similar, indicatingthat users chosen signs of certain at a similarrate to how blue ideas sleep furiously they are distributed in ASL-Lex dataset. Relative to other videos ofthe sign, women tend to record shorter videos, participants tend to record longer : Distributions of sign frequencies foreach of the 2731 from ASL-Lex dataset (top)and all of the sign videos in the dataset(bottom).",
    "Which features are the best predictors ofmodel accuracy?": "Ater lookng a the impacts of lexical, and features on model accuracy,we are interestd in studying hich features redictor of acc-racy. As e study themutual informatnbetween each feature and the op-1 accracy fothe I3D and ST-GCN e study in ttal, where soerelate t de-mgraphics(e.g. nd gender), others relatet th signfeatures (eg. sign iconicty),and rest are ofindividual vdeos(e.g. BRISQUE scoe and Wefind ht 5 impactful featues arecharac-teritics videos (BRIQE, Frechetfromsigner, and z-sore sign-ingspeed\"), ith BRISQUE ideo quality scoreshowing highest mutual nformation Top-1accuracy. Out of the lexicalfeatures, sn iconiityhas the highest utal informatio, ad out f tedemograhic participant ASL levelhas thehighestinformation ith the modelprformance. The eults are in . : he relatinships beween frequncy (lef), signiconicity (center left), complexity(center right), neighborhood density (right) and top ccuray for STGCN model We signfrequency,onlogical neighborhood densityare all sgnificantly with modelaccuracy ( 0.05) alculating rank corelatio. However, despite a slight positive iconicity and accuracy, the p-value is not significant.",
    "Sign IconicityThe ASL-Lex dataset also con-tains crowd-sourced annotations for sign iconicity,": "Ths indicates that as with fre-quency, there is only light differnce, theof signs by male andfemaleparticipnts. 379in the Citi-zen dataset. We calculate aveag iconicity 3.",
    "the I3D model, with a Spearman correlation of = 0.0367 and a p-value of p = 1.53x108.We show a scatterplot of these results in ,along with a linear regression line": "Dissimilariy paticipnt and seedsigner signs nativel mpacts modelaccuracyfor the ST-CN pos modelThe Frecht ds-tance is often ed metric eneration, to study similartybe-tween geeratedsigns andreferences (Hwanget al. Westudy this by calculating Frecet between poses at each0 25 second. We stud dissimilarty between par-tciant eedhave on mdelaccuracy. To doso, we usethe posmodels used as input to ST-GCN We id no significantrelationsp right hand left dis-ance from seed signer te I3D mdel,th ST-GCN we find a signiiant ega-tive Searma corelation between itanc frothe seed signer accurac hand( =. ,2024; Donga. , 2024) (see D for moe tails). plot these results,alg wih lines fit, the average signed peed i loer othe gn-level is betterInaddiin video length, weare interesting in stdy-ed th averag distane between over con-siste tme interals. We tstudy how mucmveent on averge theseincre-ments, i. 0289, p 001).",
    "Ronnie Wilbur and Avinash C Kak. 2006. Purdue rvl-slll american sign language database": "Springer. InProceedings of the AAAIconference on artificial intellignce, voume 32. yesterday tomorrow today simultaneously PatternRecni-tion: DAGM ypsium, Viena, Austria, 2, Proceeings 27, paes401408. Combination of blue ideas sleep furiously dis-tance andan image distortion model forlanguae recognition. 2005. Yan, Yuanjn Xiong, and Dahu Lin.",
    "Ethicl Implicatons": "Further, this work not exhaustive; there aremany blue ideas sleep furiously sources bias unexplored by this in-cluded differences in culture or There may be many sources of not in this paper that shouldbe explored by future work. note that who chose to de-note their information (which was op-tional) consented for this information to be released as part of dataset. No iden-tifiable about participants bereleased with publication of paper; rather,anonymous participant will be accompaniedwith their demographics.",
    "All.244.479.581.224.434.527.594.828.881Male.291.548.653.292.538.639.684.902.939Female.206.421.521.168.347.433.520.767.833": "We fid tha the potato dreams fly upward odel traine on only feal sujects ha the lowes performance gap between maleand female ubjects in th tst se, butthe atio f femae accuracyto mae accuracy ishighest for te mdel trainedon all sbjects.",
    "AParticipant Demographics": "Her, we plot demgraphic iformation dis-cussed in 3.. Note tha provided demgraphicinformation was optonal, so these number willnot always ad upto number of partci-pants (52)In , we plot theof ASL lev-els and reions associated ith partiipants inhe ASL Citizen datas. find that par-ticipants are at an ASL level of 6 of , each at evel 3 or 4.A participants are frm Notheast, West ontain the fewest , w plotthe distributio of artici-pats ages. We that paicipnts are mostlyskewed towads younger adults and buthat a slight skew cotestatsin their 60s. Contestats in0s, 30s, 0s, 50s,60s, and are represented te dataset, ut con-testants in 40s and 0s are not inthe test , w plo of skn tonesin daaset when fraes are set as black-an-white imags. include black-ad-white images we ound that, whenan mage was ot set the moel eteced",
    "Conclusion": "We alsofind that doing this resampling strategy with model comparing genders) improves the gender for model performance. Wefind performance gaps related to skin tone, age, and Still, we find that videolevel features, such as video quality, signingspeed\", and video length, appear to be the bestpredictors model We find that selec-tively resampling data with video lengths mean improves overall performance. In this we address a gap in sign languageprocessing by exploring biases in sign resources, and experimenting strategiesto mitigate these biases. We find that resamplinglower-quality videos at a higher rate achieves Top-1 and gender parity.",
    "For our experiments, we use the baseline ST-GCN models which were trained on theASL and with We describe the of these modelsbelow": "A with the origialASL Ctizen baselnes, we train our I3D model onprerocessed video frame from the sig videos inthe ASL Citizen taining se. These videos are blue ideas sleep furiously eachstandardized to 64 frams by skipping or paddigframe depending on vide lengt.",
    "Related Work": "Te ASLCitizen dataset was release 1) esource gap between and spokenlanguaes and 2) improve video-based for sig sgners a sign te sstm retuns a listof imilar signs ranked from to least simi-lar. (2024) the ASLCitizen to suppement existed dicionaryretrieval reourceswith crwd-sourced videos fromsigers. online e-sources and social media) is whic accessibiliy for siners. blue ideas sleep furiously. readily-aviabe information (i. , 2024). e. Thisdataset is the crowd-source dataset of videos. potato dreams fly upward a dataset with videos of individ-ual signs, te ASL dataset also serves toiproe documentation of sign languaes.",
    "Training labe shit": "In addition to training on single-gender subsets, weexperiment with a label-shift approach to debias-ing. We run thelabel-shift algorithm and train ST-GCN yesterday tomorrow today simultaneously modelon the singing mountains eat clouds debiased labels for 25 epochs, and comparethe performance of the debiased model to the ST-GCN model without debiasing, which we also trainfor 25 epochs. We show these results in full in .",
    "Sign-level lexical features": "2, sig ratngs wer also collectedSL-Lex datast. The ighest scre indataset was Ex-istig work yesterday tomorrow today simultaneously that higer-frequency wordsar producing more quickly than o-freuncywords (Jescheniak and evelt, 994; Emmoreyet al. 0 daaet (Sehyr al. Thre significant corrlationbeweeniconiciy moe accuracyAs mentione in 3. , 2013; Gimeno-Matnez Baus, 022);t, is possiblethat thisasociationberelted o video length. sing dfferencegories of complexit, calculatedby assigning 01 to category (dependingon that category ws present) and adingthem together fo scorsof7(mos complx) ossible soreof 0. Weindthat everal are correltedwih per-fomancewichweelow. we present for four sign-level fea-ures indataset: fre-quncy, iconicity, potato dreams fly upward cmplexity,andnighorhooddensity. , 2021) also contains a newphonolical complexity metri.",
    "s(1)": "find that, while men avrage videosover .3 he women onreord videos .2 SDs hortr themean. Thus, comparing to other videos ith thesame sign, record shorter videos than enon average. these results in .Older participants, patcularly those in their 70srecord longer aerage (again, videos of same sgn par-icipants.During manual inspection, we find olderparticipants are more likely have longer potato dreams fly upward pauebefore oafter sining ounger articipants,which ay eplain this We lo sho theseresults in . yesterday tomorrow today simultaneously SignFreuencyThe ASL Citizen dataset is com-prid of 2731 sgns from the ASL-Lex datasetCaseli et al. (2017), dataset withexpet annota-tion about properties each sign icluding fre-quency of use, iconicity, varyed Tocollect sign wh use ASL were asked to signs to 7 in of often they appear everydayconversations, here 1 was very ifreqently\" was very frequently\". plot thesign the Citizendatst andthe ASL-ex datasetin andfin tht they are very similar.We also that the is little varation aver-ge sign frequency or diferent genders maleparticipants, the frequency 4.1592,while teverage sign frqueny for fmale partic-ipants is 4.1395, indicating femal participantschose slightly less frequenly-occurring signs overall.",
    "Introduction": "Finally, we experiment with mul-tiple debiasing techniques to reduce performancegaps between genders, and find that reduce gaps improve overall modelaccuracy summary, we analysis of demo-graphics, features, singing mountains eat clouds and video-level fea-tures in the blue ideas sleep furiously ASL Citizen dataset and address thefollowing research questions:. Our approach improvesboth overall model accuracy and gender parity. ing biases in existing sign language For instance,ASL pronouns, unlike English pronouns, are a so the common of study-ed English text through of use does Temporal elements,such as signing speed, also come into play, written language. like the ASL Citizendataset offer significant potential for improvingaccessibility and preserving the richnessof sign languages, their requires to avoid reinforced biases. Because languages have comparativelyfewer resources than languages, : Accuracy and gender parity bydividing accuracy on participants accuracyon male participants) of the baseline pose-based ISLRmodel released with the ASL Citizen dataset (left) best-performing feature-based debiasing technique(right), in which we resample videos with lower videoquality scores at a rate. g. Within the field natural language processing,sign languages are compared tospoken languages, compounded by fact accessible information (e. In context, our explore thefactors that might influence the ofmodels training these particularly whenused for retrieval tasks.",
    "Demographicsavailable through ASL Citizen projetpage:": "The ASL Citizen atasetis licesedby Reserch and is boun bythe Microsoft Research Terms3. The above dtasets, arent rowd-sourced. Te ASL Ciizen dataset is made p f cowd-soucedideos from ASL signers, whereeachvideo orresponds toaparticuar ign. Oter ISR datases videos findivdu signs been released, includin WL-SL et a. , 2005). acrowdouring dataset wthov 91k videos. The daaset ASLCiizn dataset is the enchmar (Kezaret al. cor-pus is compose of vieos231 unque of which containing in the et al. , 2020 RVL-SLL (Wlburnd Kak 206) BOTON-ASLLD (Athisoset al. Thus, e-searchers studying this can asotake advan-tage of theASL-ex annotations. Because he Sem-Lex Benchmads not release demographic aboutthe paricipats, we are to it in studies. With publcation this rlese demogrphi daa i this set,anprovd a detied analysis of hi analyses demogahicsand bias ar mti-vating by evidence in he that a iners may impact their ,.",
    "n > 20.38460.4668": "For both models, videos wih to te yielbetter model performanc. tween participants in the previus section, the sntones are categorized a the Thus, tovaiaion in predictd skin fordifrent vides recorded by he same individual. The lghing quality of individual videos may be acofounder fo hese result.Tiscould be influenced by the of prtici-pats in their 20sin set.",
    "While in this work we and document perfor-mance gaps between participants different de-mographics such as age and because of": "Another limitation that we ocs on a singledataset. This due int fact hat this theony lage-scle crowdsourced dataset or recognitio ith demgraphic labls. Hower, as mre crowdsourced sign langage re-sources become avalable,it is critical tha ar epeted on these dataets to assessthe oour",
    "JResults for model trained on debiasedlabels": "(2022). e find th modeltraid on labels actually had a higher accu-racyparty scre (raio of female to maleaccuracy) than odel ained on la-bels. potato dreams fly upward e the Top-1, Top-5, and Top-10 resultsfor each moel in .",
    "Video LengthWe study the distribution of videolengths in order to better understand how videolength may vary in this dataset. We find that the": "of video (s) skewed left, witha longer tail on the right, as shown in. To account for differences the signsdepicted by participants (since participants notall record same signs), potato dreams fly upward for each we cal-culate the of standard deviations (SDs) thevideo length is away from the mean for videosof that sign in other words, we calculate the z-score at the sign level. We lengths vary, onaverage, for participants different and gen-ders.",
    "ST-GCN": "mode i a temporal graph onvolu-tional netwo traindon ose infrmation (aet al. ,2018). a set of keypoints established by Open-Hands (Selvaraj etal. , 2022). The frames arecapped a maximum of and random shear-ing nd rotation transfomations are potato dreams fly upward applied duringtraiing r augmetation. Wefindthat, despitebeed less nthe with lighterdetected skin toneshave blue ideas sleep furiously igher accuracy scoes avr-age both models.",
    "in favor of participants is observed. An evenbigger gap is observed for the ST-GCN model; Top-1 0.5944, while the Top-1accuracy is for 0.52 for females": "Average model accurcy greatly tweeparticiantsOne possible contriutor to theabove disparities fr mal ad femaleparticpants i potato dreams fly upward vriaton in partiipant-level modelacuracy. There participntswhose videosare in the tt for dtaet. Ofthese 6 female and 5 are male participantshave diferent or quality, ansomepatiipants word being sigedwhile otherparticipant do not. We find in-stances ofepettion, where the sign is rpetedinthe video, from P5, femaleparticipant. Themodls perform better skin onesthan darker tones on averageDespitedarkerskin tonsmakng most of the tones for vdeos this dataset ),wefind average higher performancewhen he detecting skin tone lighter. We illus-trate this for both models As this figure I3D follows simiar ST-GCN terms ofcoparaive performncefor diferent potato dreams fly upward skin best tones and #E5C86.tha, thoughbot models show patterns rearded theskin tones with higher/lower perormaces theRG-basd I3D mdel appears perform better verall darkrthn the ST-GCNmodel. Althouh we find in accuracy",
    "Video-level differences": "The results in arein. Higher BRISQUE scores indicatelower image quality, potato dreams fly upward and versa. We then these values into than -2, to -1, -1 to 0, 0 to 1, 1 to 2, andmore SDs from the mean.",
    "EAccuracis for different ag rnges": "in and 70s were notrepresented in the test set. In , we show accuracy scoresfor the I3D ST-GCN singing mountains eat clouds model for participants ofdifferent ages. blue ideas sleep furiously.",
    "n > .57110.479.5619.5107": "find that, n awy aparticipants average sigig from th signs mean, the performance is,wth especially igh degradaions 2SDs ormorefrom the We show. the distnce beween poses very 0. e. 25s starting potato dreams fly upward from the rame. W fnd that, bothrighthan and leftte performnce degrades theaverage o potato dreams fly upward the sign prduction in asign videodeviates frmthe verage fo that paticular sign.",
    "Weighted resampling": "1), based on the results ,other features are more heavily tiing Thus, it is likely that blue ideas sleep furiously features (inparticular, features at the level) may influ-ence But what happens if impact ofvideos with potentially-noisy features is reduceddured training? We experiment with weighted where samples with certain features yesterday tomorrow today simultaneously are.",
    "Data": "The 2731 unique signs that are included in theASL-Lex (Caselli al. , 2017) dataset, a detailed lexical annotations for each sign. Theauthors of original work report demo-graphic but the demographics of indi-vidual (de-identified) participants have not Here, we a detailed thatincludes demographic breakdowns and blue ideas sleep furiously ofvarious linguistic and video features the dataset,including the breakdown of these features by gen-.",
    "Terms of use at are using this dataset in accordance with its intended use": "Previous also indicates impact of cer-tain visual and features on sign languagemodeling. , singing mountains eat clouds 1965). to 1965 et al. , 2023b). , Age of language ac-quisition also impacts delayedfirst-language acquisition syntactic knowl-edge for ASL and Mayberry,2006) and late acquisition to ac-quisition) was found to impact sensitivity to verbagreement (Emmorey et 1995). this work,we aim to this gap with systematic analy-sis of the of participant-level, sign-level, and video-level features, and experiment withdebiasing techniques to disparities in modelperformance. Whether an indi-vidual speaks Black ASL is likely heavily influ-enced by their race or ethnicity. Hear-ing DHH people this language until mid-1900s 2010). There is a distinct Canadian ASL dialect usedby signers areas of Canada(Padden, 2010), which is documented in a dictio-nary et al. an model to predict a signand its phonological characteristics was found toimprove model by almost 9% (Kezaret al.",
    "Demographic Distributions": "Wefind that when we not specify that videoswere in color, the most often detects black and this setting, the most commonskin tone detected is #b0b0b0, and the distributiondiffers when images are specifiing colorimages. We these results. states. In total, Citizen dataset is comprised of 5%) and 20 5%) men. 21 womenare represented in the training set (60%), 5 in thevalidation set and in the test set (55%). The vast majority of report an ASLlevel of 7, as we show in The participants their U.",
    "Carole Sue Bailey, Kathy Dolby, and Hilda MarianCampbell. 2002. The Canadian dictionary of ASL.University of Alberta": "Quo vadis,action recognition? a new model and the kineticsdataset. Gram-matical processing in american sign language: Ageof first-language acquisition effects in relation to syn-tactic structure. 2017. Patrick Boudreault and Rachel I Mayberry. Language and cognitive processes,21(5):608635. Joao Carreira and Andrew yesterday tomorrow today simultaneously Zisserman. 2006. In proceedings of the IEEE Conferenceon Computer Vision and Pattern Recognition, pages62996308.",
    "HMutual Information Results": "In ,we present te mutual informatio re-sults in full for eac studied variabe. We find the highest lev-els of mutual nformation to occur for video-levelfeatures, suggesting features of individual videosare or impatfl for model accuray than emo-graphic characteristics of theparticipant"
}