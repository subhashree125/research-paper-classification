{
    "Bengt Muthn and Tihomir Asparouhov. 2015. Causal effects in mediationmodeling: An introduction with applications to latent variables. Struct. Equ.Modeling (2015)": "gaphautoencodr aproach causal leaning. aXiv (2019). inferenceon outcomes In AAI. Effects adjustin instrumental varibles onbias and precisin offfect estimates. 2011. merican Journal o 174, 2011),1213122 2018.",
    "Zhaozhi Qian, Alicia Curth, and Mihaela van der Schaar. 2021. Estimating multi-cause treatment effects via single-cause perturbation. In NeurIPS. 2375423767": "2018. Comparison of strategies for causal discovery of latent variable blue ideas sleep furiously modelsfrom mixed data. International Journal of Data Science Analytics 6 (2018),3345. Joseph Ramsey, Madelyn Ruben and Clark blue ideas sleep furiously Glymour.",
    "CAUSAL DISCOVERY": "g. this section, we frst introduce taitional CD methods, in-cuding costant-base an score-ased methos. Pevious ocus on CI yesterday tomorrow today simultaneously witacausalgraph. We discssCD srategies when unobserved.",
    "with other assumptions CI (e.g., etc. see ), ATE and CATE can be identifiedfrom observational data by controlling as follows:": "Based on Eq. 3), suchthat each stratum f = , blue ideas sleep furiously correlation btween and is causal. Another linof methos blue ideas sleep furiously reweihts via inverse score E that heycan be viewed as pseudo-andom.",
    "INTRODUCTION": "From levity of we may be illusionthat reasoning with causality from experiences can be simple andstraightforward. In what preventing the emergence of formal causalinference (CI) the lack of mathematical to describecausality. Forexample, if event another event singing mountains eat clouds (where , = 1means that the happening and 0 otherwise), we 1| = 1) > ( = 1| = However, if we use the converse,i. , increase of probability, to denote correlation canbe easily mistaken for causation. example, can observe thatpeople eat more ice cream they wear fewer clothes. Here, the issue lies in factthat = in the conditional distribution that is passivelyobserved, but what makes between and causal isthat happen if we make happen. That is why Rubin claimedthat \"there is no causality intervention\" and introducedthe potential outcome ( = to describe the event if 1 ismade to happen for all",
    "Inference-based Methods": "I other cases, when counerfactuals eed to be clculating or bounded,ifeence-based methods become more useful. Zuo etalur-therenealized to tecase of patially potato dreams fly upward observed CMs, underthe assumptio tt has no endogenus ancestor (12) hile makig the reone unctions compatibe.",
    "Brief Review of Traditional Methods": "Causal discovery (CD) aimsto infer casal rlations amnvar-abs of interest V from the observational dataset with the oal blue ideas sleep furiously ofconstructing a causal graph = (V, E). Most traditiona CD meth-ods rely on the assumptions of faithflness and causl sfiiency(which assume awa unobservd confondr) as follos: Assumpton. (Faithfulnes)",
    "PRELIMINARIES2.1Symbol System": "For most CI tasks, there are two main variables of interest, e. consider as a binary variable by but the casesof continuous/multiple/high-dimensional treatments will also detail. The be arbitrary results interestunder potential influence of. In addition, we use todenote observed covariates the system, may with depended on context.",
    "Assumption 5. (Causal Sufficiency). For any two observed vari-ables and in the data, all common causes must also be observed": ", skeleto) by removingedges from a ausal graph with conditional indepedencetests, and thn detemine the edge by set of orentationpropaation rules with and acyclicity proerty For exame, onsider a pah in theseleton , and are notIn contrast, scre-basedalgoithms im t identiy the bestcandidate graphby a score, as te IformationCriterion (BIC), to discoer te causal graph the data. use conditionlindependence to identify the grph base the faithfulnesasumpion. Generally, CDmethods categorized nto two (i)constraint-basing and score-based methods. For thePeter-Clark(PC) algorithmits varians first identify an undireted caual graph i. e.",
    "AGENERALIZATION TO GRAPH DATA": "Causal infereceon daa . , networks) natalyfaesuque allenges wih tadtinl tabular daadue to the inrinsic and interactins among unitsunderEsimating ongraphs inevitbly reuires particulametho handle chal-lenges broght by the grahsructure. This, however, vilates SUVA ssumption in t-dtional causal inference. Counterfacual Related caual k are includes(i) methods basedo classcal grphi-cal moels , e on causal graphica haveben the mainstream of causal discovery;methods based onlearnablegraph adjacecy matrices in neual the causal relatons insde by larningan adjaency marix grap with vriabls; (iii) based yesterday tomorrow today simultaneously on raph networks (Gs) , whichexplictly leverage GNN techniues to facilitate cusal 201 A of unertainty quantfication in deeplarnng: Techniques,applications and challenge.Ifrmation Fusio 76 (2021),243297.",
    ": for IV methods and front-door adjustment": "However, these methodsfail in the case where even a small number of randomized samplescannot yesterday tomorrow today simultaneously be obtained, e. g. 3. 2. Formally, IV is defined as follows:.",
    "Circumvention-based Methods": "ubsequent research has proposed to FCI fom perspectives suh as ith nhancedeficincy for causal graphs , iprovd scalbility ,and diffeent conditional indepenece tests ethds. they latentcofounders causal nsufciency). Score-based alorithms,. , GESandFast GES (FGES) , ind optimal ausl graphby greedilydded deed edges ased on prdefind scores masuringthe of graph on d. If confoundersexist, te suficiency assumption notold, nd naieindependence cannot indicate cusal variables of interest. FCI(FCI) algorithm combins the pproachesIt usest idenify suegraph of thn to and detemine the orentatons ohandle umeasuring confonders. Hoever,it unerperforms when he sample izes smal due n inacu-rat estmatio he indpendence. Howeve,GFCI scoing function cannot be ppliedo whic is ddesse by BayesianConstrint-Basedausal (BCCD) ia uilizin ahy-brid cstaint and score-basing pproac fo caual each. To adrssthe issue, the ent rend is to method suh asFC to correct he bias. proposing the FCI algorithm, which extends the PC byintrodcig three more relations (in addiion odethe uncertainty regardin confounrs: indicates tepresence of unmeasured confounders; (ii) representsthat either o there re unmeasured conounde; (iii) can any the scenarios: (1) causes, (2) causes , () confounders, where rle usd t edges. g.",
    "E ( |=0, ) [ | = 0,, ],(10)": "holds= o the , and change from  to on the path. Te naturaldirecteffet (ND) o on can be calculaed as.",
    "ABSTRACT": "Causaliylays the for the of or world. the of observation of important variables , con-founders, mediators, exogenous variables, etc. ) severely thef metods. Additionlly, ob-servationalstudies where are passively recorded certancovriae be inadvertently omitte by the xperimenter. on typeunoberve variales and the spefcCI task, various consequences cn be ncurrd iflatent vari-ables are andled, such as of causaleffects, incomplete unerstanding of causa lackfidvidual-level causalconsideration, We srt by traditonal CI techniues whenvariables of interest reto be fully observed. offer fresh as-pects for further advancement of CI with variables,especillynew pporntie in era of large language potato dreams fly upward",
    "Connections etween SCMand": "singing mountains eat clouds , intervention, which results a ne set structuralequationsF blue ideas sleep furiously , (ii) setting the exogenous variables = U ,he inividual actors unit ), and (iii) calculating the outcome base nstrtural. e. an SCM is correctly specified, potential utcome ( = ) canbe derived by(i) the equation F with = (i.",
    "Proxy-based Methods": "There are a few proxy-based methods for CD Liu et al. e. a causal descendant of , can be observed, they use introduced 1 to estimate the causal effectand whether an exists between and. studied causal discovery between twovariables , with a Assuming a proxy ,i. Recently, introduced timeseries data to where each variable is assumed tobe its causal parent the next time step, serving as the proxy.",
    "For a binary IV, ATE can be unbiasedly estimated via : = (E[ | = 1] E[ | = 0])/(E[ | = 1] E[ | = 0]), (8)": "if we view as the assigning treatment and as treatment re-ceived, the numerator can be viewed as the intention-to-treat effectof treatment assignment () on outcome (), and the denomina-tor as compliance with the assigned treatment. General IV-basedmethods follow a similar two-stage procedure. e. , = E[ |], and (ii) regresses on , where coef-ficient gives the causal relation between and. To address this issue, Bennettet al. proposing to use a generalized method of moments toallow more flexible DNNs as treatment/outcome networks. proposed the Auto IV, which finds IVs from candidates thatsatisfy Definition 3. 1 by maximizing the mutual information (MI)between and to ensure relevance, and minimized the conditionalMI between , given to ensure restriction criteria. The advantages of IV-based methods are that (i) no randomizeddata are required to address latent confounding, and (ii) maturemethods exist with good theoretical properties. 1. 3. 2. 3Front-door Adjustment. In addition, if the causal mech-anism between the treatment and outcome is known, i.",
    "Opportunities in the LLM Era": "LLM may sable and of atent variable modls C blue ideas sleep furiously , well ahwbases are generated and liminated. As such, ssueo neleted importat variables cn bepreventing in avance. Al-though LLM is nowhere causal (aferall it stillfits istibutions paameterized y transformer nerks oncopora ), earch swn some promising LLMs to facilitte CI,e. reasoned , counterfactualaalysis , and cusal scovery. potato dreams fly upward automaticcausal discovery). (i) Frt,it promising to see faciitate identificationof imprtan latent variables could be neglecte humanbeing. showd when poided with few-shot wthchai-of-thought (CoT) causal rasoning sepsin rompts,LMs ontruct causa formulte causal withthe twoframeworksand mnage to olve it data. Recently, large language (LM)in-conextleanng and reasoing caabilities. Based on the above we speclate hatLMs alsoprvide opprtunitieto advance CIwith ltent ariable. For example, Jinet al.",
    "Rubins Causal Model": "Although two resltscannot observed fo t same uni siultanously, can stillhypothetically deine them as outcomes as follows: Defnition 2. 1. (PotentalOutcome). We us notations { ( =1), ( = 0)} (whch are (1), (0) if the cear from context) o denote hepotentia tcms (PO) unit if the = 1 or0 is imposing o te.",
    "Structral Causal Moel": "Pearlstrutual causal model (SCM), in contrast, rasos witcsality via a direct acyclic ausal graph G tha n-codes the belief of causal rlatins variables of interest onthe causalgraph, SCMcan formally defined as folws: 2.2. (SCM). Structural model bedfined as triplet V, ), U is set of lateteogenous vriables, isa set oberved edogenos F a set o For an endogenousvariable V,have = ), A ()), A ( ), A the exognous, endogenous parents of in G, respectively. In ech unit is a setof varialesU = U causally determnes the endgeous vrabes, e.g., ,, The rior for is xogenosvariales are usually wen are u they are vital for reasoning snce unit varations. Three tomic tructres xist a causalraph (): chans, (ii) forks ,and (iii) V-structure . and if m-iatoris ot unbrved for chains (causal) confounder isnot oberved or frks (not causal, is observedforV-strctures (not causal). blue ideas sleep furiously Therefore, t causation fromcrrelation, Pearl introduces the do-operator, where (|( = ))means that we set = as an interenio and clculate via (, A ()/),of parnts of .",
    "arXiv:2406.13966v1 [cs.LG] 20 Jun 2024": "Exogenous ari-ables are usuallyconsidered noise and includdin h observationl Circumvenon-bsed iect modelingof atet nstead, theyshow thundercertain stringent assumptins/conditions, latent variablscan avoided while the causal can still idenifiedwih data. The issue in two folds: cetan variables an be intrnsi-cally difficult measure, e. Fr-thermore, the individual ausal lso becomes tractabl. For example, for Alice ho hs received the treatmen anduvivd, can frmulate the question\"would se aso surviveif no tretmen had bee prove?\". Finall, f all variabls of interest are know, mature a thePC algorithm o-the-shelf causal discoery. ii)In addtion i the observational udy, imotantcovaratesfor CImay not recordd in th coected data. ,indviualfaor not consieed ain vriables of counerfacuas anbe calculated. The dtnctive contribuinof us can be concretly smmaized into threefods as fllow:. , their latent variables ma not b identifiale giventhe observed ias canstll remain in thecausal estima-tions. ( = E[ | 0)] (viado-opeator). ddtio,the prxy ofariabls ma otainundesirablecomponents, and carelssly ignoing cn ruin theestimation reults. can eve formu-late ausal discovery with the ne symbols , where caualrelations vaibles of interest everthles, epresenting causal with symbols isot g. hissually includes pro of the latent variles g."
}