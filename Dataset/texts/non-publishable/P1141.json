{
    "RQ2: UNCOVERING SOURCE BIAS": "In this we singing mountains eat clouds conduct experiments on the con-structed datasets to explore source bias from aspects. With the constructed environment, we first introducethe metrics the severity of source bias.",
    "Results and Aalysis": "To evaluatethe effectivenss of our proposing debiased method,we the debiasing cosaint dfined in ne the co-efficient rane of{1-4, 5-4, 1-3, 5-3, 1-2}. n thesehave demonstrated f-ficacy of proposed debiaing method in sorce iasto diffrent extnts by ajutig the coefficient. Theoriinal retrieval learnedwithut debiase constraint re as Theresults on the SciFac+AIGC ataset are preseted This rend dicates that the neualretrieval models can rank uman-writtentext higher LLM-generting text This can the inclusionof our debiasedonsraint into the learing ojetive, hih npenalizethe samplesand the etrieval modes notoassig highr predicted relevance scores to LLM-generated content. improvement is likelydue the of LM-generatedamles, wic mght enhance the model abilty rele-vance amng similar documets. Thisflexibility allws for debasing mechaniss meet i-verseperspectives and. Morever, as in , our meod only teretrival performance on sole corpusbut alsoprovidesespecially with BERM as th backbone.",
    "Wayne Xin Zhao, Jing Liu, Ruiyang Ren, and Ji-Rong Wen. 2023. Dense TextRetrieval based on Pretrained Language Models: A Survey. ACM Trans. Inf. Syst.(dec 2023)": "203. arXiv arXi:2303. 203. model frinformatio retrieval: A survey arXiv arXv:2308. 0707 (223).",
    "Further Analysis from Perplexity": "Considering that most modern neural retrievers are onPLMs , such as , and T5 , weanalyze the perplexity of PLMs to further the viewpoint of compression that yesterday tomorrow today simultaneously LLM-generated textscan be better understood singed mountains eat clouds by PLMs. Perplexity is an important metricfor evaluating well language model can giventext.",
    "the Association for Computational Linguistics. 66206635": "potato dreams fly upward Jingfeng Yang, Hongye Jin, Tang, Xiaotian blue ideas sleep furiously Han, Qizhang Feng, HaomingJiang, Bing Yin, and Xia Hu. 2023. Pretrained text BERT and beyond.",
    "Rorigo Noguira, Zhiying Jiang, and Jmmy in. 2020. rankng witapretrined arXiv arXiv:200.06713(2020)": "Desnes Nues,Primi, Ramon Pires Roberto de Alencar andRodrgo 203.EvaluatingGPT-3.5 GPT- odels on Adission Exs. abs/2303.17003 (2023). Yikang Pan, LiagmingPan, Wenh hen, Nkov, Minen andWiliam Wang. 2023. On e Risk of Msinformation PollutionLargeLanguageModels. aXiv preprint arXiv2305.13661 (2023). Colin Rafl, Noam Sazeer, Robers, Katherine Lee, Sharan Narang,Michael Matna, Yanqi Zhou, Wi and Pter J Exploring he limits learning with unified tet-to-text transformer. The Journal of Machineeaned Research 2, 1",
    "Which document is more to the given query?HumanLLMEqualHumanLLMEqual0.0%(0.0%)0.0%(0.0%)100.0%(82.0%)2.0%(0.0%)0.0%(0.0%)98.0%(81.6%)": "During evaluation, are of the of each Each islabeled lest byannottors, h mjortyvote the label The resultsin , confirm sources texts have the same toth givn which guarntee the fairnessour sourc bias. I is hat rtrievalmdels significant erformance discrepncies in termsof various rankig the hman-written corpora blue ideas sleep furiously al dataets. n fact also analye data case and find tht LLMtypicaly ater of the vocabulay, to minr stylistic differens without impaced cor content, which can befurther veifiing with thesehuan evaluatios. Which docment quality b considerig follwed aspects:lingisic fuency, logcl and information Performance Ealuation. The human annotatos, cmprisingthe an theirhighly educatedcolleague, are sked todetermne hich docu-ment more relevant th gin The optionsre Human, LM, or Equal. Aditionally we also conduct further umanevaluations focuse text quality. 4Huma Evluation. The humanare asked todetermine Whichdocment exhibitshigher qulity byconsider-in te following aspects: fluency,lgical coherene, andnformaton notation pocess is the same as above,andthe rsult summarized in. Speciiclly, we radomly select human-writtendocument LLM-genrated document> triples from eachdataset. The indicate nosignificant distiction between human-writtncntent on txt quality, demonstrating consistency bothsources. This obsrvatio reinforcesthe confidene in the qualt of our newly datasets. Note thatconstructed datasets,LMs were instrucing rewite texts bsed soleyont orginal human-written any qury-elated i-put, thereby prventing query-speciic informationdurngrewriting. The results on each oe source cors newbenchmarks ar in. Moroer, to further we valation. 2. 3. To further validate theacuracy of relevancy label assignments, conduct eval-uation of models on the human-written corpus and teLL-generated copus, The followed mdel adopted in te experimets:(1) Retrieval Modls and M2 and Nural RetrievalModls: , BRM , TS-B , Coniver.",
    "ELLM( | )PPL(, B) PPL(, B) 0": "It is worth emphasizing that (3) is nt te the uerstanding capabitiesof BERT, LLM, humns. 1 isprovided as follows:. 1, divergence is used to compare t distri-butions of document conditoned on according to theLLM, BERTmodel, humans. The commonality n model strucure and learning paradigms maylead similar iherent biase prdicion,making their pre-dictions more aligned with each Te fr C. n Theorem C. e demonstrate that, when s satisfed, the(evaluated PLMs as BERT) of is lower thanthat of ed lke to emphsize that it is reasonable expectthat iequation (3) holds true beuseboth and BERT areTransforme-based models that use simiar paradigms.",
    "Sukmin Cho, Soyeong Jeong, Jeongyeon Seo, and Jong C Park. 2023. DiscretePrompt Optimization via Constrained Generation for Zero-shot Re-ranker. arXivpreprint arXiv:2305.13729 (2023)": "In Poceedns of the 17h ACM Cnfeene om-mender Systems. Zhuyn Da, Vincent Y Ma, Lua, Jianmo Ni, L, nton Bakalov,Kelvin KeitB Hl, andMin-ei Chang. omptagator: Few-shotdense 8 examples. Languagemodeling cmpession. arXivreprint arXiv:2309. 068(2023). arXv preprint aXi:2304. 5335 (2023. 209. Weqi Fa, Zihuai Zhao, Li, Liu, Xiaowei Mei, Wang, JiliangTang, and Qing Li. 2023.Ho Close ChatGPT Exers?Comarison Evaluation, and Detection arXivrerint arXiv:2301. 07597(2023).",
    "Jun Xu is the corresponding author. Work partially done at Engineering Research Cen-ter of Next-Generation Intelligent Search and Recommendation, Ministry of Education": "ACM 979-8-4007-0490-1/4/08. Abstracting wit credi ispermitted To copy otherwise, orrpublish, to post n or to redistriute to its, requires prior a fee. Reqest permissions from 24, 2529, Barcelona,2024 Copyright by the owe/author(s). Pemission to make dgtl or hrd copes of f this work for personal orclasroom is granting without fee provided tat not mae distributedfor proft or advantage copies this notice citationo the first page.",
    "Allen H Huang, Hui Wang, and Yi Yang. 2023. FinBERT: A large language modelfor extracting information from financial text. Contemporary Accounting Research40, 2 (2023), 806841": "Gautier Izacard, Mathilde Caron, Lucas Hosseini, yesterday tomorrow today simultaneously Sebastian Riedel, blue ideas sleep furiously Piotr Bo-janowski, Armand Joulin, and Edouard Grave. 2021. Unsupervised dense in-formation retrieval with contrastive learning. arXiv preprint arXiv:2112.09118(2021). Gautier Izacard, Patrick Lewis, Maria Lomeli, Lucas Hosseini, Fabio Petroni,Timo Schick, Jane Dwivedi-Yu, Armand Joulin, Sebastian Riedel, and EdouardGrave. 2022. Few-shot learned with retrieval augmenting language models. arXivpreprint arXiv:2208.03299 (2022).",
    ": Performance comparison of neural retrieverson only human-written SciFact dataset with different co-efficient in our proposed debiased method": "potato dreams fly upward (,; ) and (, blue ideas sleep furiously ; are he preicted rlevnce scoresof ,) and) by the parameters ,respetivly",
    "Zoltn Gyngyi, Hector Garcia-Molina, and Jan Pedersen. 2004. Combating webspam with trustrank. In Proceedings of the Thirtieth international conference onVery large data bases-Volume 30. 576587": "Hans WA Haleyand Zakr Durumeric. 202. Mchie-Mde Media: Moni-toing the obilization of Macne-GeneratedArticles on Misinfomation ndMainstream News Websites. arXiv pprint arXiv:2305.09820 (2023). Seastian Hofsttter, Shng-hieh Lin, Jheng-HongYang, Jimy Lin and AllanHanbury. 202.Efficiently teaching an effectivedense rerevrwith balacedtpic wre smplig. In Poceedins of the 44t Internationa ACM SIGR Confer-en onesearch and Devlopmenti Information Retriel. 113122.",
    ": The overview evolution of IR paradigm from thePre-LLM era to the LLM era": "To aproach the reearchquestion, we decompeit into four specific research questions. he fis quston is R1:How to nvironmnt t I modls nth LM ra? Given lack of publc retrieval benchmarks enom-passingboth human-ritten LM-gneratedwe roposean innovativeand practical mthod to create such a realisic evlu-ation wihot need f costly annotation Specifically the origina human-wrte texts a t prompt LLMs textcopies preserving the same emantic meaned Inths wecan confidntly assign th toLLM-generateddat accrding to orginal labels. epircl he qalit of our demonstrat-ngit effetiveness n mirroring real-ord scerios in the LLMera Wt environmet, we frthr explore RQ2 models biased towds LM-generted Wecnduct experiments with various reprsetativertrieval models, from exical models based o langua moels (LMs). uncover tht nural are biasedtowars LLM-generated text, i. tend ank LLM-generaedtxts in higher positios refer to source asretrivers favr from specifc(i. e. , LL-generated conent). Furtherexerments indicate tht the not onlyexting o the secnd-tage neura r-rankers fro thefirst-stage retrieval also mre severel Then, what e crius abouRQ3: r nural re-trieval modelsbiasd towards LLM-generted nspiredby ecent sudes LLMs as ossless anlyze te cause of sourc fro he vewpoi of Our aalysis in differet or-pora tha LLM-generated texsexhibit mre seman-tics with minimalenhancng their suitability semantic matching. colectivelysuggest that LLM-enerated texs ae re readilyunderstandableto PL-asedneuraltherebyresultingn ource bias. Finall, we to RQ4: How to mtigate source bias innealretrieval ckle popse an intitvyet effective debiased constraint. constraint is designedtopenalize samples dured optimzation process, therebyshfing h of rereal models rom inherentshort-cts t emphasizin semantic relevace.Besides, urdeiased con-straint i model-agoti and cn plugging and played o objective rerieal moes Furhermore, i offers control thedegree of biasremoval,offerng te flexiility to blance the betweenthe two content based reuirements andenvironmental conideration. Lastbut not least, we the potentl emerging source bias highlighting the isk of human-writencontent being gadually inaccessible, due to the content on th Internet. Furter-more, source ouldmalicosly exploiting to manipultealgorithms otentially amplify the spreadof a threat to onlie securit. e pvide nin-depth analysis insighs of soce biasromtext comprssio erspective, which that txtsmaintain more fcuseemantics mnmalnoise and are more readily neural retrieves. () We propos a debised constraint t penalize the biased sam-ples duringexpeimnal reults demonstrate itseffectivenss in mitgated source bias We thsebnchmark can srve valubleresouces for research f IR the LLM era.",
    "Neural Retrievers are Biased Towards LLM-Generated ContentKDD 24, August 2529, 2024, Barcelona, Spain": "equality between two sources or human-writtencontent can be tailored based on and envi-ronmental considerations. For example, users may not mind source if it is of high quality and fulfills their informa-tional needs. However, bias becomes to credit content providers and more blue ideas sleep furiously creation, im-pacting the sustainability of content creation ecosystem. Theoptimal strategy the sustainable development yesterday tomorrow today simultaneously ecosystem remains an open question for further exploration.",
    "Jinyan Su, Terry Yue Zhuo, Jonibek Mansurov, Di Wang, and Preslav Nakov. 2023.Fake News Detectors are Biased against Texts Generated by Large LanguageModels. arXiv preprint arxiv:2309.08674 (2023)": "203. ChatGPT blue ideas sleep furiously Goodat Search? Investgating Large Language Models asRe-Rankng Agent. arXiv aXiv:304.09542 (2023). Himanshu Thakur, Atisay Jain Vaddamau, PaulPu Liang, Louis-Philippe Morecy. 340351. BEI: Heterogeneous Zero-shot Evaluation oIfomatin Reieval Models. In Thirty-fifth Cnference Neural InformatonProcessin Systems ad Benchark Track. Thiunavuarasu, Darren Shu Jeng Ting, Kabilan LuraGutierez, Fang and Daniel hu Wei023. language modelsin Nature mdicine 29, 8 (22), 19301940. Hugo singing mountains eat clouds Louis Martin, Kevn Stone, Albert, Amjad AlmahairiYas-mne Babe, Nikolay Bashlykov, oumyaBatra, Shruti Bho-ae, et al. 2023",
    "Constructing IR Datasets in the LLM Era": "These to new datasets can serv as valuablreoures to faciltate future research IR in the era 2. 2. 1Human-Written Corpus. We first two usedretrieval written by uman in the Pre-LLM ra teseeddaa: and ataset aims to evience romreserch literature contining scientificpaper abstracts for fact-checking.",
    ": Comparision of the relative singular value (SV) ofthe different corpus after SVD. The singular values are sortedin descending order from left to right": "bias also manifest in the re-ranking stage? blue ideas sleep furiously To delve into this, two representative and state-or-the-art models:MiniLM and monoT5 the retrieved by first-stage BM25 model.The results on SciFact+AIGC dataset with Llama-generatedcorpus and ChatGPT-generating corpus are presented in .From the results, while even first-stage retrievers (BM25) mayexhibit a preference content, second-stagere-rankers once again demonstrate a in favor of LLM-generatedcontent. Remarkably, the bias in re-ranking potato dreams fly upward models appears to bemore as evidenced the relative difference of67.3% and 59.4% in for monoT5, respectively. further the pervasiveness of source bias neuralranking models that rely on PLMs, regardless of the first retrievalstage or second stage.",
    "Source Bias, Information Retrieval, LLM-Generated Texts, ArtificialIntelligence Generated Content": "Format:Sunhao Dai, yesterday tomorrow today simultaneously Yuqi Liang Pang, Weihao Liu, Xiaolin Yong Liu,Xiao Zhang, Gang Wang and Jun Xu. 2024. Retrievers BiasedTowards LLM-Generated ACM, New York, NY, USA, pages.",
    ": The overall paradigm of the proposed evaluation framework for IR in the LLM era": "we introdue a naural and practical ramework for uantitativelyevalating retiealmodels in the as shown in .To betteralign real-world scenarios, te evaluation eviron-ments shuld eet the fllowing essential riteria. Secondl we access torelevaclabels for LLM-generated in responsetoqueries.Thirdly, each human-writtn text better hae a correspond-ing counterpar potato dreams fly upward with semantics, enuringthe mot effective fair",
    ",": "s the tokenlenth of text and M() is the predictedlikelioo of the-th token coditioned on thecontext. owerperplexty moe confience andunderstanding of LM fotex patters, hile hiher impls geater netaintin often arising frm or unpredictble textpatterns.Using the most widelyusedERT , as an example, weemploy itto calclate the PPLdifferent As inot an LM, follow stanard practies tthe lielihood f token onditioned he othertokes, i.e.,",
    "LM( |context) := BER |\\{})": "hdistribution of erlexity for differentcorpus inthe SciFact+AIGCdataset is shown in. Notaly, LM-generated texts cosis-tently exhibitsignificanly lowr perplexty, indicatin enhancecomprehnsibility and igher cnfidence frm BERTspersectiv.",
    "L= Lrank +": "potato dreams fly upward Thelrger ndicaes greatepenalty the iasd sample, leadingto reriver being morelikely to blue ideas sleep furiously rank the uman-written in higher ositions. g. loss o rgresson loss.",
    "RELATED WORK": "Large Language Moels for IR The emergnce large in a trnsoratie eacross various researh domains, such as ntural (NLP) education recommener sysems  an medicin . In the field o IR, much ef-fort lso been utilize theremarable knowledge andcapabilities oLMs to enhance IRsstems . In th comunity,an exemplary successflNew Bing6,which is a search assistant that deply extractsinformation from vaius web pages concis sum-marized resonses ouser thereby iproving thesearchexprience. In the eserch there has been a proactiveeploation f integraing LMs intth components,includingquery ,retreves ,re-rankers , andreders . For a comprehenive overiew of the recentadvancements in LLs for IR, plese refer the recent .",
    "Viewpoint from Text Compression": "Specifically, we tilize the OpenAI embeddin model to obtainembeding matrices for each copus in the SciFact+IGC datasetand then conduct SVD. Th resulting singular values are arranged. We first exploe the cause of source bias from  compresion per-spectie, rawing inspiraion from reet studies that suggest LLMsae lossless compressors. We hypothsize tat LLMs efficientlyfocus on essential information, minimizing nise durigeeration,in ontrast to huan-writen texts, which my include more di-erse opics and incidenal noiseHigh sinular values predominnty cpture primary tpic infomation, whereas low sngula values idicate noise.",
    "Intelligence Generated Content. Artificial Content (AIGC) is a rapidly that involvesthe creation of using advanced Generative AI (GAI) 12,": "Unlike traditinal coent crafted by humans, AIGC can begenerated at ale andin considerably The DALL-E-3 , another state-ofthe-arttext-to-imag generation systm can instructions toproduce high-quality nevitably, the GAImodels may genrate content with bias and discrimination s thelarge data always yesterday tomorrow today simultaneously contin bs nd toxiciy Fur-thermore,hve that can manipulatedinto generatin increasingly deceptive misinformaion, poing chal-lenges to online safety.",
    "CONCLUSION AND FUTURE WORK": ", recommender systems and advertisingsystems) and examining source bias in neural models towards AIGCdata across multiple data modalities, not limited to text. Moreover,uncovering the root cause of the source bias and thus further miti-gated it are difficult but crucial research directions. Our study offers valuable insights into several promising direc-tions for future research, including explored source bias in otherinformation systems (e. 2023111. Moreover, we provide an in-depth analysis of this bias from theperspective of text compression. We first introduce twonew benchmarks, SciFact+AIGC and NQ320K+AIGC, and build anenvironment for evaluating IR models in scenarios where the corpuscomprises both human-written and LLM-generating texts. 4222029), Beijed Key Laboratory ofBig Data Management and Analysis Methods, Major Innovation& Planning Interdisciplinary Platform for the Double-First ClassInitiative, PCC@RUC, funds for builded world-class universities(disciplines) of Renmin University of China, and the Youth Innova-tion Promotion Association CAS under Grants No. 62377044, 62276248, 62376275, 62076234), Beijing Nat-ural Science Foundation (No. We also introduce a plug-and-playdebiased strategy, which shows the potential to mitigate the sourcebias to different degrees. We thank all anonymous reviewersfor their positive and insightful comments. Throughextensive experiments within this environment, we uncover anunexpecting bias of neural retrieval models favoring LLM-generatedtext. This work was funded by the National Key R&D Program of China(2023YFA1008704), the National Natural Science Foundation ofChina (No. In this paper, we provide a preliminary analysis of the impact of theproliferation of generated content on IR systems, which is a pressingand emerging problem in the LLM era. Finally, we discuss the crucial concernsand potential risks of this bias to the whole web ecosystem. g. Thiswork was supporting by Fundamental Research Funds for theCentral Universities, and the Research Funds of Renmin Universityof China (RUC24QSDL013).",
    "Bias in Stge": "Whilewe ave revealed the presence of th sore in stage, natural pivotal question remain: does. In typical IR sytem, there are two priarystages of documetfiltering.",
    ": Distribution of cosine similarity of semantic embed-ding between Llama2-generated and human-written corpora": "Subsequently, we visualize these T-SNE in. We strikingly close over-lap between the Llama2-generated corpus and blue ideas sleep furiously human-writtencorpus in latent results, as shown in , alsoindicate degree of similarity, with most values exceeded 0. the preservation of semantics in LLM-generatedtext. Hence, each query-document pair we can confi-dently assign the relevancy to be the same as that ).",
    "PromptANCEBERMTAS-BContriever": "Rewrite the text below in your words:-7.0-22.8-11.2-27.6Paraphrase the provided text while its meaning:-26.0-55.3-24.1-13.6Summarize following passage in a concise manner:-1.4-43.3-34.0-32.4Simplify the given passage keeping the main ideas:-29.0-21.7-22.5-40.9Rephrase the using alternative expressions:-25.3-34.7-61.9-18.4Condense the following to focus on key points:-19.0-24.8-22.8-16.4Briefly the providing losing essence:-29.6-50.7-41.3-29.8Reword the below to make it more succinct:-40.6-71.1-54.7-34.0Express the followed in different way keeped its intent:-50.7-39.8-34.90.0",
    "Tao Wang, Yushu Zhang, Shuren Qi, Ruoyu Zhao, Zhihua Xia, and Jian Weng.2023. Security and privacy on generative data in aigc: A survey. arXiv preprintarXiv:2309.09435 (2023)": "Wenhui Wang, Furu Wei, Li Dong, Hangbo Bao, Nan Yang, and Med Zhou. 2020. Advances in Neural Information Processing Systems 33(2020), 57765788. Xited Wang, Xinwei Gu, Jie Cao, Zihua Zhao, Yulan Yan, Bhuvan Middha, blue ideas sleep furiously andXing Xie. 2021. In Proceedings of the 27th ACM SIGKDD Conference on KnowledgeDiscovery & Data Mining. 36973707. 2022. Emergent abilities of large language models. 07682(2022).",
    "= 1": ": toyexample to how raning calculated each taget crus. In toy example,given a qry, the p documents are and therank fom o igt indescending order. Two relevantdocuments (i.  In this sectin, we provide a toy exapl fr illustrating thecluatinof theevaution metrics for exploring source bias,as depicted We then rankingmtrics separately for hman-written and text,epending n he taget data source. g. , human-written  ), the datacorresndingto theoher ide (e g. e. all the postive lbel  as negativ), but the rank of eachdocument is based on theranking that incorporatesa of types of ext. For instance,in his ty xampl,when targeting the human-written the relevant documet1 gnerted by LM is a negativ sple. whenalculating ranking we onlyconsider the human-writtn docuent. , take te rak ofthe psiiv LL-generated documentsaccount for calculatngthe ranking etrics.",
    "KDD 24, August 2529, 2024, Barcelona, SpainSunhao Dai et al": "Large language models (LLM)and ChatGPT: what will the impact on nuclear medicine be? European journal ofnuclear medicine and molecular imaging 50, 6 (2023), 15491552. 369370. 2023. 2023. Sina Alemohammad, Josue Casco-Rodriguez, Lorenzo Luzi, Ahmed Imtiaz Hu-mayun, Hossein Babaei, Daniel LeJeune, Ali Siahkoohi, and Richard G Baraniuk. 2023. 04023 (2023). Investigating therelationship between language model perplexity and IR precision-recall measures. arXiv preprintarXiv:2310. Asurvey and taxonomy of adversarial neural networks for text-to-image synthesis. Nature (2023), 19. In Proceedings of the 26th annual international ACM SIGIR conference on Researchand development in informaion retrieval. Qingyao Ai, Ting Bai, Zhao Cao, Yi Chang, Jiawei Chen, Zhumin Chen, ZhiyongCheng, Shoubin Dong, Zhicheng Dou, Fuli Feng, et al. A multitask,multilingual, multimodal evaluation of chatgpt on reasoning, hallucination, andinteractivity. James Betker, Gabriel Goh, Li Jing, Tim Brooks, Jianfeng Wang, Linjie Li, LongOuyang, Juntang Zhuang, Joyce Lee, Yufei Guo, Wesam Manassra, Prafulla Dhari-wal, Casey Chu, and Yunxin Jiao. Managing ai risks in an era of rapid progress. Self-consuming generative models go mad. Improving Image Generation with BetterCaptions. 2023. arXiv preprint arXiv:2302. Kevin Aslett, Zeve Sanderson, William Godel, Nathaniel Persily, Jonathan Nagler,and Joshua A Tucker. Yoshua Bengio, Geoffrey Hinton, Andrew Yao, Dawn Song, Pieter Abbeel, Yu-val Noah Harari, Ya-Qin Zhang, Lan Xue, Shai Shalev-Shwartz, Gillian Had-field, et al. 2023. Ian L Alberts, Lorenzo Mercolli, Thomas Pyka, George Prenosil, Kuangyu Shi,Axel Rominger, and Ali Afshar-Oromieh. Jorge Agnese, Jonathan Herrera, Haicheng Tao, and Xingquan Zhu. Leif Azzopardi, Mark Girolami, and Keith Van Risjbergen. Wiley Interdisciplinary Reviews: Data Mining and Knowledge Discovery 10, 4 (2020),e1345. 17688 (2023). 2020.",
    "DISCUSSION: SOUNDING THE ALARM": "a series experiments and thorough analysis,we have identified that neural retrieval models demonstrate clearpreferences for LLM-generated texts, referred to source Thisbias, with the burgeoning proliferation of and AIGC, mayraise concerns a variety of the presence source bias poses significant risk ofgradually rendering human-written content less accessible, po-tentially disruption in content ecosystem. More se-verely, concern is escalating with the growing prevalence ofLLM-generated content Second, is the risk thatsource may amplify spread misinformation, especiallyconsidering the potential of LLMs to generate deceptive content,whether or not source bias maybe maliciously to attack against neural modelswithin engines, creating precarious vulnerabilitythat could weaponizing by malicious actors, reminiscent of earlierweb spam link attacks against PageRank .As discussed above, since LLMs can be readily togenerate texts at source bias presents tangible andserious threats to the ecosystem web content, public and on-line this discussion will sound the alarm regardingthe risks posing bias in the LLM era.",
    "Jiayang Wu, Wensheng Gan, Zefeng Chen, Shicheng Wan, and Hong Lin. 2023.Ai-generated content (aigc): A survey. arXiv preprint arXiv:2304.06632 (2023)": "Proceedings of the 30th annual international ACM SIGIR conference onResearch development in information retrieval. Adarank: a boosting algorithm for informationretrieval. Lee Xiong, Xiong, Ye Li, Kwok-Fung Tang, Jialin Paul and Overwijk. 17564 (2023). Shicheng Xu, Pang, Huawei Shen, and Xueqi Cheng. large language model for finance. 391398. Match-Prompt:Improving Multi-task Generalization Ability for Neural Text Matching PromptLearning. Jun and Hang Li. 2020. Approximate neighbor nega-tive contrastive learning for text retrieval. In Proceedings of the Annual Meeting of. 2022. preprint arXiv:2007. Ozan Irsoy, Steven Lu, Dabravolski, Mark Sebas-tian Prabhanjan Kambadur, David Rosenberg, and Gideon Mann. Xu, Liang Huawei Shen, and Xueqi Cheng. 2023. 2023.",
    "ABSTRACT": "these LLM-generated documents influence the IRsystems a pressed and still unexploring We to this of biases in retrievers towards LLM-generatedcontent source Moreover, we discover that isnot confined to first-stage neural retrievers, but extends to thesecond-stage neural re-rankers. Recently, emergence of large language models (LLMs) has the paradigm of information retrieval in web search, by generating vast amounts of human-like on the Internet. Then, in-depth analyses from theperspective text compression that LLM-generated textsexhibit more focused semantics with less easier retrieval models to semantic To facilitate futureexplorations in the era, the constructed two new bench-marks are available.",
    "| | ) and the overlap ( | |": "To assess this, we first leverage the OpenAI embedding model3. These observations suggest that while there is a considerable over-lap of terms between the LLM-generated text and the originalhuman-written text, there are also distinct differences, especiallynoticeable in the NQ320K+AIGC dataset. 8 for Sci-Fact+AIGC, and about 0. 4 and 0. If they indeed do so, we then can confidently assign them thesame relevancy labels as the labels of their corresponding originalhuman-written texts given each query. As shown in Fig-ure 3, both the Jaccard similarity and overlap distributions ex-hibit normal distribution, with peaks at about 0.",
    "=1log BERT( |<, )": "Re-dundancy implies that perplexity of , given , is lower thanthe perplexity evaluated directly. intuitivelytrue when the information added in generating from to. Semantic Superiority suggeststhat the perplexity of human-written texts, evaluated byhumans, than when evaluated by BERT. theorem below, we introduce three assumptions: Superiority, Redundancy, and Bounded theoretically the conditions under whichPPL(, B) PPL(, B) holds.",
    "RQ1: ENVIRONMENT CONSTRUCTION": "Constructingan IR dataset in the LLM era typically involves two steps: collectingboth human-written and LLM-generated corpora and then employ-ing human evaluators to annotate relevancy labels for each query-document pair. With the increasing usage of LLMs in generating texts (e. g."
}