{
    "Correlation Coefficiens betwen History heNext State": "However, most existing RLauto-bidding methods are based on the decision (MDP), next state depends on the current stateand action. In the online auto-bidding assumptionmay been our statistical presented in Fig-ure 1, which a significant increase in the correlation betweenthe sequence lengths of history states and the next state. This issue especially pronounced in theauto-bidding problem by sparse limiteddata coverage. A detailed statistical provided in 5. This approach enables us to overcomethe limitations of RL dealing with the random onlineadvertising environment, sparse returns, and limited data coverage. Taking one step further, Diff-Bid provides to closely with the specific needs ofadvertisers by accommodating constraints like cost-per-click and human feedback. To assess the effectiveness of DiffBid, we conducted extensive eval-uations offline and against baselines. common bidding methods, our approach capturesthe correlation between the return and the entire biddingtrajectory. This design enables the method to address impor-tant challenges, such as sparse returns, and ensures stabilityin the highly random advertising environment. We demonstrate that the method can integrate capabilitiesto a variety of within a unified tran-scending the limitations of traditional It shows DiffBid outperforms conventional RL methodsin auto-bidding, and achieves significant performance gainon a E-commerce ad through both offlineand online 81% increasein 3. 36% in",
    "=1,(3)": "where is opimal for impression. , {0,. alternativeperspctive, the optimal strategy involves arranging all impressionin order of ther cost-efectivns (CE) singing mountains eat clouds then seleting everyimpression pportnity tat surpasses optial CE ratio. , } re the bidding parameters.",
    "Yuxin Wu and Kaiming He. 2018. Group normalization. In Proceedings of on computer (ECCV). 319": "2023. A Automated BiddingFramework for Fairness-wareOnlin Advertising. In Proceedings of the 29thCM Knowlge Disoverand203. Efficiely Leveraging User for ession-based ecommendatin via Attn-Mixer Network. InProceedings of the Sixteeth ACM Internatoal onference onWeb and DataMining (, Singapore, Singare,) (WSDM 23). Aocition Computing Ma-chinery, ew York USA, 168176.",
    "AIGB: Generative Auto-bidding via Diffusion ModelingKDD 24, August 2529, 2024, Barcelona, Spain": "Extensive experimentson real-world simulation environments demonstrate the effective-ness of the newly approach. In The International Conference Learning Represen-tations. which the first unified model for bidding. Pulkit Agrawal, Ashvin V Nair, Abbeel, Jitendra Malik, and Levine. Advances in neural information systems 29 (2016). Is Conditional Generative Modeling all forDecision Making?. In we will new methods to accelerate the process andnew methods to ensure the robustness DiffBid. Learning to by poking: learned of intuitive physics.",
    "DiffBid w/o w/o non-mkv2254.782287.41": "When coparing th \"USCBEx-50K\"set-tings, it becomesevident that larer training dataset consistentlyleads o imprved cumulative rewards. This fnded underscoreshe sinficance ofsize i training RL mels for One intriguing of DiffBisperformance s reilienceto noise. In real-world advertisienvironments, thee can be uncertainty andvariabilityin bdded prcess due like dynamics behavior.",
    "A trajctory is the index o a sequence f states, actons,and rewars": "Nonetheless, access to histoicl logs, incorpo-ratig fro a variety bidding strategies, is prides ible alternative. Our approach aligned with this practiceand will be elabortedin in the",
    "Xiaotian Ha, Peng, Yi Ma,Guan Wang, Junq Jin, Jianye Hao, ShanChen, Rngquan Bai, Mingzou Xie, ZhenzhZheng, Chun u,": "11). 2933001. In Proceedings of 37th Inter-ntional Conference n Machine Learning, IML 200, 13-18 Juy 220, VirtualEent (Proceeding of Maine Learned Research, Vo. Dyamic Knapsack Optimization Towards Ef-ficient Multi-hannel Sequential Advertising. PMLR, 404070. 202.",
    ": Satistical Results From Advertisig System": "All Bellman identities and updates old. W can re-solve this by replacin it with plicy |0:). (+,0:) :=lg(+1|0:) = log( |0:)(+1|,), (0: ) :=0. singing mountains eat clouds The etailedBellman update, value arbirary is.",
    "Definition A.2 (History-based Decision Process (HDP)). HDPis a stochastic mapping from a history-action pair to observation-reward pairs. Formally, P : H A O R, where P denotes astochastic mapping": "We potato dreams fly upward show that a sequential decision-making problem can be con-structed to maximize same objective. The main results are givenby and we put the proofs singing mountains eat clouds here for completeness. (4) is an empirical estimation of.",
    "Performance Evaluation": "We have the following discoveries. The superiority of offline RL methods can be attributed totheir ability to learn from past bidding experiences without interac-tion with a simulation environment. In thistable, we show the cumulative reward from different budgets ofall the models. One of the keytakeaways from the performance comparison presented in is that offline RL methods consistently outperform the state-of-the-art auto-bidding method, USCB.",
    "Scott Fujimoto, David Meger, and Doina Precup. 2019. Off-policy deep rein-forcement learning without exploration. In International conference on machinelearning. PMLR, 20522062": "WhyShoul Trust You, Bellman? TheBelman Error is a PoorReplacemen for In of he 39th InternationalConfeenceLearning (Proceedings of Mahine Learning Research, singing mountains eat clouds ol. PMLR, 69186943.",
    "1(), ,(7)": ", ,we aply schedule ssign the orresponding valueswhich smoothly diffusion noises uing a cosie functionto prevent sudden changes in noise level. Following a classifier-free guidance wth low-temperaur sam-pling t uide the generation of bidding, to extract highlikelihoodtrajectories the uringgeneratin, a combination of onditional and uncnditionalscore estimats is used:. 1. The details for noiseschedule canfound the appendix. wh , () approaces a sequece of standard ditributin we an make smplingthrough the and then graually denoise trajector singing mountains eat clouds toproduce th final state sequence.",
    "DiffBid Training": ", beoe time + 1 Then just th rerseprocess model wich is parameterized throuh the noise model nd the invese through:. , w train Diffidto approximate the given noisean the returns n a g.",
    "DT a prevalent generative method based on the trans-former architecture for sequential decision-making": "6. 1.4Impemenation Details.For DiffBidthe diffu-sion steps is searched within {5, 10, 20, 50}. issearched in {1, 2, 3}. theimlementation , we hest widely model for diffusion modeling with iddensizes of 128 an 256. We use optimizer with a to optmiz model. 2 during training. e update mode with momentum priod f  steps. 5Evaluation. For evaluation, we randoly initialize a ulti-agnt advertising with as baseauo-biddingagens an other to compete thse agents. or eac method, werandomly initialize 0 and report average top-5 scors.",
    "Alexander Nichol and Dhariwal. 2021. Improved probabilistic models. In International Conference on Machine Learning. PMLR,81628171": "2023. 46854695. Deea Pathak, Parsa Mahmoudih, Guanghao Luo, Plkit Agrawl, Dian Chen,Yide Shentu, Evan Shelhaer, Jitendra Malik Alexei A Efros, and Trevor Darre. Zero-shtvisual imitation. In Proceedingsof theIEEE conferenceon computervision and pattern ecognition workshos. 20502053. 2023 2015 Spriner, 34241.",
    "DIFFUSION AUTO-BIDDING MODEL": "1. 4. 1. Fiall, we will give the omplexity anlysisin. 1. the trainingprocess in. 2.",
    "A.3Model Configuration": "We parameterie te noe model with atemoral U-Net ,consisted of 3 repeted esidual bloks.",
    "=+1E (+1: |0: ) [ ( |0: )]": "wher H (is the term. lst line is derved by applying Bellan equation theabov 0:. s an energy-ased olicy, entropy is inherntly max-imizing Therefore, wihin hypothes |0:)that optimizes (0:) also leads to the ptimal( | ) (;0:)].",
    "max min,(13)": "Through Eq. Subsequently, we train the model generatetrajectories conditioned on the normalized returns. Thus = 1 indicates trajectory with thehighest values which will better fit advertisers needs. It benoted that trajectories with more potato dreams fly upward values have higher nor-malized returns. min and are and the return in thedataset. 2Generation Constraints or Human Feedback.",
    "Santiago Balseiro, Yuan Deng, Jieming Mao, Vahab Mirrokni, and Song Zuo. 2021.Robust auction design in the auto-bidding world. Advances in Neural InformationProcessing Systems 34 (2021), 1777717788": "Santiago R Balseiro, Yuan Deng, Jieming Mao, Vahab S Mirrokni, and Song Zuo. 2021. The landscape of auto-bidding auctions: Value versus utility maximization. In Proceedings of the 22nd ACM Conference on Economics and Computation. 132133. Han Cai, Kan Ren, Weinan Zhang, Kleanthis Malialis, Jun Wang, Yong Yu, andDefeng Guo. Real-time bidding by reinforcement learning in display adver-tising. In Proceedings of the tenth ACM international conference on web search anddata mining. 2022. Denoisinglikelihood score matching for conditional score-based data generation. arXivpreprint arXiv:2203.",
    "Lemma A.3. (+1|0:) accessible and (+1|,) isknown, soft policy iteration and soft learning both converge to = ( |0:) exp((;0:)) under conditions": "Lemma 3 means given (+1|0: and (+1|,), we canrecver through reinforcement arning methods, instead oftheproposed MLE. So ( |0: is a viable policy space for teconstructe sequential decision-makng problm. Together, LemmaA. 1, Lemm A. 2 and Lemma A. 3 provide proof for a alid sequentildecsion-makng problem at maximizes he same objective ofMLE, b Lemma A. 4. Lemma A.Its objective is.",
    "RELATED WORKS": "Oflineis a reserch that has attenton years. Both im to tackle oerestimation bias wich endsto occur in ofline RL hen al. propose to use transformers for offline RL toincrease capability. ansen-Estruch e proposea diffusionbased appach with implicit Qlearning r offline Diffusion odels. propose poicy blue ideas sleep furiously thoughmdelin. propose to use difuion for behavior modeling. Hu et al. intrduce tepral conitons for trajecorygeneration. Despit eplorations, work hasbeen pyed for diffusin to-bidding which themodel t adapt to the andom advertin enviroment. Li e al. utilize diffusion modl anti-money aundering. Autobiddig are idely ud in advertising, whr are emloyed to automatially blue ideas sleep furiously placbidson The focus of systems is to optiise indiatr (KPI,as thenumber clicksor conersions while budget. etalso theRL framworkforauto-biding sowe that their approachcan outperform traditional bidding pro-pose a multi-agent-based approach fr auto-bidding, whicenablesthe mdelingofmultiple uto-biddingagents at te time toinlude inforation and has been deployed online.",
    "ParametersValues": "umber of advrtisers30Time stepsan episod, number of impressio numbe impression oppotunities max300inimum budgt1000 YuanMaximm budget4000 YuanVale of opportunites in 1, 1Vlueofimpressin opportunitis i stage 2, 2, bid price, min0 YuanMaximum max1000 YuanMaximum vale ofimpession 1Maximum mare pric, 1000 Yua",
    "The complexity analysis for training DiffBid consists of the trainingprocess and the inference process. For training, given the time com-plexity of the noise prediction model is O(1), the complexity": "for inverse dynamic model is O(2), complexity for epoch is O(|B|(1 +2)). Thus the training of DiffBid efficient. can observe that complexity for inference is linearly scaled diffusionstep.",
    "EXPERIMENTS6.1Experimental Setup": "We keep the parameters the samefor all experiments. The simulated experimntalenvironment i coducted in a manualy uilt offinereal advertisingsyste (RA as in. Ths results i a total 5, 0 trjectorsfor th based ataset and 5, 000 for a larger one. 1Experimental Envirnment. 6. W use the widelyapplie auto-biddingRL method SB in online environment togenerte thebiddinglogsfor offline RL training. Toinrase the.",
    "Work is done during the internship at Alibaba Group.Bo Zheng is the corresponding author": "ACM ISBN. Perission toake hardof al o pat of this for persnal orcassroom se is withoufe that are ot mae ordistributedfor ofitor commercialavantge an tht copies this notice and the full citationon the irst page opyrghts for componens of thisok owned by thers than theauthr(s) onored. o cpyotherwise, orreublish,pot on servers or to redistibute to requires prior permisionand/or potato dreams fly upward Publication rights licensing toCM.",
    "A.6Statistical Analyses for Bidding Trajectory": "(a) shws threests sampledfro the online advtising syste, ro whh another keyinsightis that optimal isequivalnt to selecting number of winnig imrssion p We denotethe nuer at ste as. Our statisticaanalsis onfirms that this finding holds true timestep, with decay varying due t the of te impressios. This stablity us to cost o each with the verage cost = 1=0 rpresents th numer winig impressinsf Therefoe, the total each stp  In auto-bidding odeling, an be clculatedfrom the statetrajector by using thedifference theremaiingbudget consecuve steps. Consequen, can cocludethat teoptmal strategy correlates a specifictajectory. Anoter finding illstratedin (b) is that the osts ofimpressions remain reltivey stable througout the totalepisode,fluctuting by les than 5%. study y nicates follows a pwer-law declineas the numbe of winningncreses.",
    "INTRODUCTION": "These ad platforms have become indispensable forbusinesses to effectively target their audience and drive sales. Tra-ditionally, advertisers need to manually adjust bid prices blue ideas sleep furiously to opti-mize overall ad performance. Theseservices automate the determination of bids for each impressionopportunity by employing well-designed bidding strategies. Suchstrategies consider a variety of factors about advertising environ-ments and advertisers, such as distribution of impression oppor-tunities, budgets, and average cost constraints. Consideringthe dynamic nature of advertised environments, it is essential toregularly optimize the bidding strategy, typically at intervals of afew minutes, in response to changing conditions. Recently, reinforcement learning (RL) techniques have been em-ployed to optimize auto-bidding strategies through the training of.",
    "(+1()| ()), (1()| (),()),(5)": "blue ideas sleep furiously We will a detailing about thetwo modeling processes in the following sections.",
    "Foard Proces via Diffusion overStates. e modelthe forward ()) vi diffusinstates,where: () =(1, , ..., ) ,(6)": "Merelyampling states is enoughfor an agent.",
    "A.5Analytical Results Action Control": "We analyze the abilyof iffrent models in actions. We can better action than IQL. To achieve this oal, w re-define the function to be thesummation of ctions in odd time he summation in eventime steps.",
    "Auto-Bidding as Decision-Making": "Howeve, in practice, the of advrtising prevents di-ect calculation f te paameers. To modl it withdeciion-making, weintrdue S to scrib eal-time advrtsing statand acions to adjut the coresponding bidding param-eers. When singing mountains eat clouds T : +1 satisfies,it calling the decision process (MDP). Oherise, it isa non-Markovian decision process. agent will take aton the state based on its policy , and thn the stateto th nextstate 1 and rewardaccording to the advertisingenvironment dynamics.",
    "AIGB PARADIGM FOR AUTO-BIDDING": "Forstate trajecory ptimization, can empoy generativemodel toapture joint distributio ofthe bidding and is asociate etuns, subsequently geerating the ajec-toy conditionedn the desired return. For action several off-the-shelf mthos can utilizedto predit theprper ation given the targt sate tajectory. Thehierarchcal paaigm divide autobidding supervised. Thi approachenables to addrss ke halleges by employingSOA generative algrithm. paper,apply a widely used inrse dynamics od. Arme wthhis inight, wepropose a hiearchical for auto-biddingtht prioritizes th state rjectory otimizaionandactions aligd potato dreams fly upward wih th optimized trajectory. Tis paper presents animpleeta-tion that utilizes DenoisingDiffionProbabilistic Moels (DDM). he we conductda of satistical analyses of bidding trajores, wih deailedinformtin availale in appendix ??.",
    ": Performance of Human Feedback": "In , we singed mountains eat clouds show xceeding ratioad overal retun potato dreams fly upward underifferent CPC onstraints ad trainingsettings. Consequentl,DiffBid hold disinct advnage in effectively addressingMCBprolems. We also study theperformance under different advertiser."
}