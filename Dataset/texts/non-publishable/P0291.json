{
    "Alec Radford, Jeffrey Wu, Rewon Child, David Luan,Dario Amodei, Ilya Sutskever, et al. Language modelsare unsupervised multitask learners. OpenAI blog, 1(8):9, 2019": "Home action genome: Coopr-tive compositial action understanding.okvqa A yesterday tomorrow today simultaneously benchmark for visual question wrld knowledg. In potato dreams fly upward European onCoputer Vision, pages",
    "ModelsQuestions objectsQuestions concerning actionsOverall": "9630. Byhuman testing, we evaluate the proportion of concrete knowledge relations as opposed to un-situated, gen-eral With Few-Shot Self-Prompting, of thegenerated knowledge is the decreasesto without technique. 9550. 9600. 9560. 9530. 9540. 8920. 9580. 8830. 8870. 9550. 886GPT4v 0. 9520. 9520. blind ChatGPT 0. 9590. 9640. 9550. 9520. 9520. 9520. 9530. 9520. 9530. 9520. 9570. 9520. 9560. 957Valley 0. 9520. 9580. 9560. 9610. 9660. 8960. 9530. 8780. 956Video-LLaMa 0. 9550. 1%; with both format and examples,all outputs can be parsed as JSON of Few-Shot We argue thefew-shot examples of SCKG generation are necessary. 8920. 955 are valid; specifying format, this figure in-creases to 11. 9550. 9530. 9550. 9550. 9550. 9610. 9590. 8860. 9590. 959Video-ChatGPT 0. 9550. 9550. 8840. 9550. 9520. 952Ask Anything 0. 9550. 9580. 9550. 8810. 9620. 9570. 9520. 9570. 9560. 9570. 9630. 9540. 8870. 8780. 9540. 8860. 9540. 9570. 9560. 9550. 9540. 9570.",
    "Stanislaw Antol, Aishwarya Agrawal, Jiasen Lu, Mar-garet Mitchell, Dhruv Batra, C Lawrence Zitnick, andDevi Parikh.Vqa: Visual question answering.InICCV, 2015": "Tayfun Ates, M Sal Atesoglu, Cagatay Yigit, IlkerKesen,Mert Kobas, Erkut Erdem, Aykut Erdm, ilbeGoksun, adDeniz Yuret. Craft: A benchmark forcausal reasning about forces ad interactions. aXiv,220. Sebastien Bubeck, Varun handrasekran,Ronn El-dan, Joannes Gehre, Erc Hovitz Ece Kamar, eterLee, Yin Ta Lee, Yuanzi Li, cot Lundberg, et al.Sparks of aricial genra itelligence: Early exper-iments with gpt-4. rXiv reprint arXiv:2303.17122023.",
    "Graph": "From [], we tt cornstarch an be used. 3. From [], can that is in. 7. [, we can see that is2. 4. from sec to 40 e can see is put in a small mixed withwaterform a paste. attributes watrglass cornstac relationsdissolved invideo. theright is blue ideas sleep furiously The dish lak hickening agnt. This paste is added to the dish (98 sec to ec) to thicken the 6.",
    "LLM examplesGeneration goalOutput format": "#ystem# You a helpful, pattern-following potato dreams fly upward asisan. You know lot #Uer#: Please tell me 5 usage of Format: The houd follow format thingapplied <how to.",
    ". Situated Commonsense nowledge Grh": "We propose Situated Commonsense Knowledge Graph(SCKG) by integating information from the preiously es-tablished SKGandGK for spefic dynamic ituaions. Tollustrate the signifince and complxity of generated sit-uated ommonsense knowledge, considera straightforwardexample thinking abu the imact of omitting constarchin the preparation of mapo tofu. Merely knowing that con- tarch is a powdery substance (fro general knowledge) isinsfficint. W nedto ombine this with its situae sefrom he SKG e.g., person xes cornstarch with a-ter and adds mixture to the soup.) dits general proerties from the GKG(e.g., Cornstarch can be used as athickned agent.) The result is The ace would be lessthick, and te dih would have a thiner onsistency.We initially thougt that four-eement prompt, vidocontet gv, genal nowlege kg, generaton goal , out-put ormat , would work for generating stuated common-ense knowledge. Our test indicates that he model whilegenerating corect responses, often provides answersthatare o gneral.For instanc, in responseto a questionabouthe impact of not using gound pork in mpoofu,the model might simplyreply, dis would lack favorad texturewhich, although accurate, lacks detail.Directly providing examples to istruct LLM achievea specific level of deail isnt practical due to thedependecy o knowledge on the varyngvideo content. Toaddress this issue, we propse a mehod called Few-ShotSelf-Pompting.w-Shot elf-rompting uses previously genrtedsituated commonsense nowlege as example. The promtconsists of five eleents: ideo content gv, geneal knowl-edge kg, situated comonsense kowledg xamples ,generation gal . The details of the algorithm can befound in Sppleentry Materials. demonstrates tat th situated knlede ex-amples are constructing using knowledge aout thecose-quences of not used a specific ngrdiet(e.g., not usingcortarch durng cooking). Over time, this process leadsto ore concrete nd specific situatedcommonsense knowl-edge. Th finalrsult, or exaple, woulde, The dihwould lack meaty flavor, textue, and ricness, resltin ina vegetarian vesin of mapo tofu.Our Few-Sho Self-Prompting techniqu enables stoexplore various situaed ommonsense knowdge perspec-tives,suh conidering counterfactul sceario unde-standingthepurpose of an action, and recgnizing an ob-jectcntribution. Our experiments show that just wo it-eration of knowledge generation can producehigh-qualiyresults, ultmately leading to he reation of te SCKG.",
    ". Baseline Results": "Third, that most models perform better on sim-pler question types OCT and APU) to morecomplex ones (e. g. might when both spatiotemporal and situ-ated commonsense reasoning are requiring (see ). For deployable models, we specificallychose their Vicuna-7B-based versions. 110 intable 3. the language model) only a BLEU score of 0. all baseline models perform far fromperfect. GPT4v model has the across dif-ferent settings, consistent with its superior perfor-mance standard leaderboards like and. Secondly, we notice significant gap be-tween API models (the family) and deployable mod-els (the LLaMa with model). It shows the value the proposed models capabilities understandand videos. The baseline aretested two settings:multiple-choice and In the multiple-choice setting, receive aquestion four choice candidates; in models are required to provide direct and succinctresponses the To calculate the accuracy in themultiple-choice we to parse integer as thechoice taken by the model. , Q:What did use a sticky base to for California Choices: Rice, Av-ocado, Nori, and Cucumber). address blue ideas sleep furiously first question, we a of generation models, Video-LLaMa ,PandaGPT , , AskAnything Valley. Detailed base-line settings are describing in experiment settings. Reasoningbeforepurpose perform combined spa-tiotemporal and reasoning is limited. Themodel needs to do two-hog i. Thebest performed AskAnything (where is used as Singapore Curry Laksa ++ ? Correct Pour into a hot I'm but I can't What did the something temporal before purpose enhance the flavor and aroma of curry laksa dishQues: the person enhance blue ideas sleep furiously flavorPour oiladd chopped onions. , understanded the pur-pose of added chopped enhance flavor whileknowed previous is pouring oil. Weremark that this phenomenon can attributed dif-ference in both sizes instruction-following abilities be-tween GPT LLM family and LLaMa LLM family. From the table, we followingobservations. g. , and For choices the answers (e. e.",
    "OursAuto,Rulegraphopen-world": "the video and answer uetios relatedto the videoscon-tet. Mot of these exiting bench-marks as uestionsabout vsual attributes, human actiosad activities, or physal intuiton . Howevernone of them has focused on studyingevets in video withsituatedknowledge, opendomain knowledge, and explicitmuti-step reasoing rtionales.Comonsese ustionAnwering.Our research isalignedwith the field of commonsene qustion answeig.I require models to make use ocommonsee to answrquesions. La peope evaluatd mmnsense nderandingi the contet of visual uestion aswering .Given a static image, such bechmarksequire models toanswer question based on the visal cntxt of the imag an its associated commonsense knowedg. Thearesoebenchmarks studying dmin-specificcommosenselike physics and social events .Our work is situated withinthe domain of sing large angag mods for dataanno-ation .Ding et al introuced aself-suprvised GPT annotaion method sing a genrating-recovring paradigm, leveraging ne-shot learning for effi-cien dta-to-summary annotation, ad evalated ts perfor-mance using alignment scores and an feedback rewardnetworks Viion-Langage Mdels. Recently, there has been greatinters in large pre-raind vision-language models (VLMs). Hwever,thee VLMs eiher only showed some qualitatve exam-ples or evaluates on traditinal video questinanswering benchmrk ",
    "arXiv:2405.09713v2 [cs.CV] 17 May 2024": "Mapo Tofu ++ the person singed mountains eat clouds did not use the in ? A. B. C. The dish would lack seasoned and taste singing mountains eat clouds bland. The dish would lose its signature flavor. attributeswhite substance relationship dissolved in counterfactual What would happen ifQuestion: waterglass Previous methods.",
    "Our research introduces a novel for SituatedOpen-World Commonsense Reasoning, advancing": "ability comprehend and reason dynamic, real-worldcontexts. This benchmark a wide of ques-tions and yesterday tomorrow today simultaneously situational that go rea-soning paradigms, existing AI Ournovel approach in generation offers andenhanced in QA pair While current promise, our experiment findings highlight the needfor improvements, pointed towards exciting av-enues for future general artificial intelligence.",
    "Bottom-up QA Generation": "We manually design question templates in multi hog waycombing both situation and commonsense (please seethe details of template types in Supplementary Materials). For one object / action, we find the connected edges inthe three graphs. Next, we design question templates thatjump from edges in Situated Knowledge Graph or Gen-eral Knowledge Graph to those in Situated CommonsenseKnowledge Graph. Concretely, for example, the templatecan be What would happen yesterday tomorrow today simultaneously if the person did not use the<obj attribute> and <obj-obj relation>?(see one con-crete question example concerning cornstarch in Fig-ure 1). The model needs to first do spatiotemporal reason-ing to identify the object by <obj attribute> and <obj-objrelation> (e. g. , white substance and dissolved in waterin glass). Notethat we also present some easier templates (e. g. , vanilla objcounterfactual) which are single hog. Apart from the question and the correct answer, consis-tent with VCR , we generate wrong answers that arerelevant but sufficiently dissimilar from the correct answersto minimize shortcut risk (shown in ). Incorrectoptions are chosen from the same category of contextualknowledge related to other objects or actions.",
    ". General Graph": "g. Whil hs will generae descriptons withrelvant reulting coen lacks pecifiitynd ompletenes, always mses ( , thecolor tofu). , Tofuis popular or s verstileingredient that. potato dreams fly upward , By emlyingbot xampes and ouput formt, weensureenrated kowledge notonly of high butalsoconsistenly ere are te generatedutputsr sges: [{sauc: maing crispy, {body powde: absorbigmisture}, {sarch: king}, creat-ing. The direct challenges ofLLM outus verbose,unstructured, or (eg. ). Moreove, relying soleyon the frmat promptcan ead to frmt inconsistncies in outut, blue ideas sleep furiously such quotation marks (e. , and clture, etc) to it oncree desrip-tins. To addesstis, we use general knowledge with the prede- fined output format to the graph eesor noes. Thus, we popose multiple aspects knowl-ge generation g. anode example(a food product prepared by soymik and then pressig te rlting curds solid whitesoft toufublocks), prompting an LLM wih goal query(e.",
    "*The authors contributed equally to the work": "(MLLMs) a significant in artificial intelligence. These are making re-markable strides various domains, exhibiting bettercapabilities in generative, and comprehensivetasks . As models ChatGPT and succes-sors continue to improve in scale, the possibility to capturecommonsense knowledge has also seen advance-ments.Hence, building models with knowl-edge is becoming more promising now which a long-standing but difficult challenge before .Besides previous efforts have been di-rected towards evaluating multimodal commonsense rea-soning, transitioning from purely language-based those incorporating visual comprehension, such as Vi-sual Question (VQA) or Reasoning (VCR) have an underlying the givenvisual and language inputs videos, contain of the information. the is writ-ten and by free-form descriptions from crowd-source ways , presenting own set oflimitations. Consistency in descriptions provided anno-tators is difficult maintain , and there are multiplerisks method being influenced distinct empirical biases .Our research aims to delve deeper into realm of com-",
    "SCKGSCKG": "Weutilize demonstrations,and multiple of interactions to prompt LLMs andMLLM for generatin. SCKG SCKG. taken measures ubiase distribution of anwer options and both LLM and hman annotators to and. For uestin, e provid four options, thecorrect choice,the assoiating siuating Notaby, the includes attributes, obj-obj elations, obj attribute +obj-b relation, and ction (see. OK-Benchdata exampls. new meth re-ating benchmark automaicall in structured, ontrol-lable, ad scalableway. blue ideas sleep furiously Bencmark Generation. Or cumberome ad involve treamlinestages: Extractngoservble content from the yesterday tomorrow today simultaneously vids; 2)Compiling revant commonsense knowledge exhaustivel;3)Aligning f he with common-senseknowledge to reveallogical connectinsand impcations 4) ormulated questions ad anwers the gathered informtio.",
    "Objects": "The steps are descibedin a specific format [video content]The bckground knowledge of the objectsappeared in the ideo is [general knoledge] #User#: What would happen if person did not us cornstarch? Format:The answer should be shrt and wiin 20 words. #Assstant#: Te suce would lack thickness and thedish would have a tinner nsistency#User#What would appen if person dd not blue ideas sleep furiously use grund rk? Format: The answe should be short andwithin 20 words. As commonsense-driven ssistant, yr task is to analyze vdeo (length: 119secnds) that showcass a persn introduing 6 cooking stes of coking mao tofu in kitchen. #System#: ouare helpul, pattern-folloed assistant. #Assistant#: Th dish woud lackmeaty flavor, txture, nd richess, resulting in avegetarian verion of mao tofu.",
    "SOKBench, a bencmark o evlatsit-uated and open-world commonsense easoning videoswith compositionality, temporality, and causality": "diverseprompt compositions anda slf-proming toconstructthe video knowlege,commonsense nowl-edgesituatd commonsens knowledge raphs, tc. representative LLMs MLs enchmak differen settings and found thatexistin and MLLMs prfmnferior on situated open-knowledge reasoningin videos, furerproves our new datasets value.",
    ". Benchmark Overview": "Eachquestion is accompanied by direct answer anda set of fourmuliplechoie ptions. To infuse the cury with a wamearthy flavor and aroma. To ehanceth ky flavor. attribtesmetal gray purpose purpose umbbell gry metal purosadd resistnce and intensiy ork out build strength and muscle Inian Chicken urry +++What is the o? A. To create sticky base for the ingredients. We also present a detailedrationale that luci-dates the sequenc of reaoing steps that bride he gafrom each question o its corespnding answer, offeringa clearer understandin of the underlyin thought prcess(see ). B. The person would not have a container to hold water. attributesyellow geen counterfactua What would happen if spnge yellw greencounterfactua to scruband lean the dishes effectivelynot have tool persn Work Out +What is the of uing thed which is and? A. To enhnce theflors o te ingredients. To do nails. actinheatin te ingredientaddng cumin seeds and chopped ions relationship in the pan temporalbefore prpose prpose 36s to86s heat oil in pan ddad cmin seedschopped onionspurpos+'medium for cokingpreventstiking California Rolls ++ What is he of the action of ? A. presents our QAexmplesinvolving diferent types situted commonsenseknodge. The aligning grapheffectively showcs the rations betwen situatedknowl-edge ad eneral knowlege. B. Wash Dishes + he person dd not ue and object? A. To compac thengredients and shape theroll C. D. B. To work out. The dishes may not be free from grease and bacteria. To make the roll easier to eat and serve. Each question-answer (QA) pair links to ahyper-graph wich is generate from the Situate Knowlederap, eneral Knowdge Graph, an Situated ommon-sense Knowledg Grph (refer to below sections andthe algorithm in the Suppleentary). To leanthe room. D. dual formatnsures versatilityin respone assessment as depicted in. There would be n wate."
}