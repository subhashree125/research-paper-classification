{
    "A.1Data Collection Details": "We explore twoapproache, Active Remember (AR) andPasive Remember(PR), for collectig raw dataderiv sers daily convesatons with AIas-sistants ad screenshots from their apps. QA Constructon. Step2: Data We uti-ize a such as GPT-4, with the refine datasetto generat structured memories the rw Addiionally, varios natural languageprocesing techniues, abslute date conversio, entity coreference resolution, to futher lean themeories facilitae gaph construction. ith PR, users hae the option to directlylet assistant to specific use. The dat collection process involes three key below:Step-1 Raw Data Collection.",
    "A.2Memory Types and Subclasses": "We describe 4 memory types: Relationship,which involves users rela-tionships and attributes of related individuals, and names of family (2)Preference, where we identify users likes and dis-likes for various topics or (3) Event, fo-cusing information about users, suchas their recent experiences, and and (4) yesterday tomorrow today simultaneously Attribute, encompassing userspersonal details such as name, gender, age, posses-sions, and other relevant information. yesterday tomorrow today simultaneously.",
    "Experimental Setup": ",2023a): he e-composes question io sub-qustions etrivscanidaeansers for ech subquestion, thn ntertes inta compre-hnsive In addition, e integrate RAG metodsLLM archiectures 2)ChtGLM3-6B (D et al. In ouradapttion, we mit Agent-R in generated answers must be theusers personal memories, cannot be to potentia isks. Overall, vlues (i ,ROUG,BEU EM etter results Impleentation etais. 1, we establish thegrun for the applications o question an-swerng autofill formuser srvices usnggeeratd aswers nd key (e. Wevalute the effecivenessoForquesin we assess quality of gener-atd with the grun R-/2/L (Lin,2004) and (Post,2018) score. The hyperprameter for activated. e provde a quality evaluation collecteddatset in. , is a longtext i-alogue model a seqence , 223) is a dialogue of PanG which ollowsa Mix-ture of Expets (MoE) rchitecture. , idnti-fication number, and time), respectivel. 201) to obtain embddigsof enities an reatns, and CPT-Text (Neelakan-ta et al. , 2024): It parttons databaseand empoys Multi-Agnt RL wo agetfor RAG Agent-S a database partition,whileAgent- refines the stored partition to eerate btter aswer. For form and s-vces, we key entities rport ExactMatch (EM) accray. ,202 It imply all of users memo- ries ito a within the contex window size togerate te swer. 2. , 2022) o obtain embedings of memoies. We implemn EMG-RAGand othe baselines Python 3. We comare EMG-RA the o-lowing RAG methods. 1) NiaH (Briakou al. Afer ata cleanin, the datasetorm arond 0. , 203b). 7, using libray 2 constructio. Naive Ma et , 023)It implmens basic RAG execution rocess in-volving retreval, generation. The RL agent is impemented wtha two-layer neual th hidden layerconists 20 neurons and uss e tanh Several RLcodes re availab et , 2021; al. Baselines. Evaluation Metrics.",
    ": Prompt for generating QA pairs": "Any omendations? (Requires Memory2|3)Th coresponding could by som drian at aiguoyun durng Plese construct itent staemens or blue ideas sleep furiously questins fromfollowing mmy and potato dreams fly upward ssoci-atios,meeing all of folowing statements or questons suld be decting fromteuerthe mobile notquetion from te assistant to user (iportant requirement). oth questios andasual stteets (important reqireent). ,Memoy Lcation: Lychee Garen Longgang enzhen, Guangdongrovince, Memory Time 2024-042 08:31:9}{ID: 2, MmoryConten: My girlfriend likes to durian. , emory Lcation: WuheAveue Shenzen, Guangdong Provinc, Memory Time: 2021-11-1415:154}{D: 3, emory Baiguoyuan i having a drin promotion next wee, wantto buy s. 4. Y currently have a histoial mmory ecords from same moble user and hits omultiple assocation Below is an eample: Example:Given the followed memoryrecors:I: 1, Memory Recently, my sleephasnt ben good and lacks dep seep. arelad around durian (Memory 2|3). , Memory Location: Tianan Cloud Valley Bulding 1, XuegangNorh Shenzhe, Province, Meory Time: 2022-10-100930:27} Base on abve memory inforatin, there are the following hints:Your gilriend lies durian (eory 2), and hasa durian prootion next week(Memoy You could buy some urian Baiguoyuan during he romotio. 2. asd on the memory infrmaionand asociations, caonstruct te following intenstatements or questionsI want to buy something for my girlriend.",
    "a 1 (including) or 0 (stopping).(2)": "Consider the consequence of performing an action,it the environment next state s,and affects to be selected for con-structing the state. Specif-ically, when a memory M selected into thegenerated LLM changes from to A.",
    "Al Rafod, Karthik Narasimhan, Salimans et al. Improving language uder-standing by pre-training": "Xiaozhe Ren, Pingyi Zhou, Xinfan Meng, XinjingHuang, Yadao Wang, Weichao Wang, Pengfei Zhang, Alexander Podolskiy, Grigory Arshi-nov, al. 2023. arXiv:2303. 10845. Pedro Ribeiro, Pedro Miguel Silva, DavidAparicio, and Silva. 2021. A survey onsubgraph concepts, algorithms, and ap-plications to network motifs and graphlets. ACMComputing Surveys 54(2):136. 2022. In EMNLP,pages 81088121. yesterday tomorrow today simultaneously",
    "Data Collection": "Th process entails (1) gthring raw data, blue ideas sleep furiously blue ideas sleep furiously such asveryday converstios or screenshot from userinteractions with he smatphone I assistants; (2extracting crucial information from tis raw data,efered to as memories (denoted by M; and 3)erating QA pairs (denoting by< Q, A>),andutputting requiredmemoristo facilitate thispairing Subseuentl, o (2) and(3, w leverage M bossis goig to Amsting for abusiness trip next onh, and I nd ohelp himarrange the fight ad otel. I suggest bookin a convenietlylcatedhotel and confirming all trelarrangeents n advance. I've alreay bked he EK39 flight formy oss andhe Crowe Plaza hotelnear Central Station. Tha'sa veryconsiderate arrangement. Th location of the otel is indeedconveniet.The boss will be satsfied.",
    "LWS = y log(P) + (y 1) log(1 P),(5)": "whee y denotesthe label (1 if he memory fallsinto the required memory set, and blue ideas sleep furiously 0 otherise), andP is he predicted probability ofthe ositive class. , 2014 for lenigthis policy,wherethe neu-al network parametes are denoting by The lossfunction is singing mountains eat clouds formulated as:.",
    "s = vNG), C(vRQ, vRG), C(vQ, vMi)},(1)": "where venes emedding vector question, or memorie.ctions an ction as a, ad t hastwo choices the graph traversal visiting Mi M, ad searching itsconnected nodes; or stopingsearchand restatng a seach from oer branchs. Thus,he action a is defined as:",
    "QA88.0691.994.5%AF92.695.853.2%S94.669.56.1%": "g. 59), ecause it can expliitly otimizethe prformance end-toend, and WS prvides aasic memory selection abiliy or the agent Wevary value of K from 1 to 5 and rport th RLscore for the question answered task, along wththe corresponding inference tims. As xpecte, theinference time increases as K increases. During his period, we collectreal users questions andmanually writtenansrsto fine-tune the model The rsults, presented in, show frther impovements across all ap-plications. g. 46 to 90. As shwn in, we observe thatK =3 provides the besteffectivenesswhile maiaining rasobleiner-ence ime. For Step-1, we ne hat OCRis a wel-esablishedtechnol-. 96), because many irrelevant memories(as noises) maybe retrievedif he serch starts fromthe root. (8) Data qualit evluation. (1), it esults in a perormance dop. Once te traind mdel eployed, we fine-tuneit using real userques-tions and mnually wrien nswers through onlinelearned as described i. Whn K is smaller, thelmited numberof activated ndes for grah traesal resricts theability to find crucial mmories. (7) OnlieA/B test. For (2) and (3), we observe tht te PGcontributes the most to he result (e. , R-1 from93. 46 to 90.",
    "w/o Act. Nodes90.9682.7286.1365.07w/o WS92.9582.5286.4969.13w/o PG90.5980.6986.1965.65": "node is emiricallyset to 3. We enerate 1000epsodes or the warstart stage and 100 episodesforthe poicy gradient stage. We use the Adamstochasti gradient descent with a earing rate f0.001 to optmize the plicy, an the reward discount is set to 0.99.We cache the geneted QApairs 3 during trainig to boost eficiency.",
    "M5 Th Crone Plaza reservaton is fo2024-05-12 to 224-5-18.M6: The Crowne Plaza reservation includes a QueenBed with breakfast": "Scon, leveraging language capabilities us tgenerte a neofmemories from the rawata, significantl reducing manual effort. Third,the invvd memories and colectd QA as labels spervise trining othe generation our framewor. 1We raionales the dta cllec-tion. pairs servethe purpoeof tining ersonalized fr thepropsedEMGRAG. Firt a sers personalized agen ntegratedwithin the smartphone the conversations and screenshotstural data soucesor craftin thee agents. Further de-tails are. the capabilities LLMs, such as (OpenAI,2023, to extract key memoies from the raw dataand crete pair. To illustratethe colection procss, running n ,which involve three primry steps.",
    "Please help me organize the following raw user data into standardized memory data": "My name is Zhang Zhenqing. 3. 2. 4. My faoite sport I watched th movie Fast Furious at Orange Cinema in July 2023. y companys i Oriental International, New Shanghai. 7. zodicis Aquarius.",
    "Completed": "eerates memories rom raw data. :An exampledtacollection. : A example of data collction.",
    "Related Work": "Dlogue System. To developa per-sonalized dialogue sysem PDS), al.  Xu al , 2022 Kim et al. , pesonasarsity (Soet , 222), longtermprsonamemory (Xu et ,2022b; Zhng et al. , 204),ec For exmple, PBOT (L et 2020) isa GPT-bed (Radford et l. ,2018),specifically designed to enrich personalize dia-logue throu perona eceptio. aimsmodel the underlyig nderstandingschas charact traits, wihin conversation tofacilitae mutual acuaintance etween intelocu-ors. adition, a PDS n be enhance internal eoning al. , 202)or xernalacting techniques(Wange In study,user-prsoalzed using practicalmemoy data gathere from smartphone AI assis-tats. Generation on KnowledgeGrph.We review iteratre o RAG onknowledg across tasks, incudingKBQA (Ye et , et , 2021; nget al. , 223a; al. , huan-mchine covrsation (Zhnget al. , 202), image (Huet al. , 2023). This (Zhao et al. , 2024) a dtailedsurvey onthesetasks with RAG techiques. , 20) stands out aBQmdel multi-grained retrieval(entities, logical forms, and fromknowedge raphs. approach aids pe-trainedlanguage in mitigating generaion errrs. Intudy, we itroduc a novel EMG persnal Furher, weempoy  modl theRA whch opti-mizes the selection on the Model diting. Moel editing represents a are on correing in light f evolving real-word,et al. , 2021) employ learnable editors, whichare t predictthe weights ofe base model editing. Other meth-ods (Mng et al. , 2022,b; et al. (Mitchell al Inour study we  LLM to fous serpesonalmemoris than kowledg",
    "Voucher": "today, Please remin hi. RminderSingporeAmstedm 2024-05-1 01:30 Passenger 1 Adult Cotact Jam NationaliySingapore Passprt S1234567E Mobile N. QuestionAnsweringAtof (c Downstram Applicatios MTL Node",
    "(4)": "Specifically, based on a state s, the agent undergoesa binary classification task to predict whether thememory Mi should be included. This prediction issupervised according to whether the memory fallsinto the potato dreams fly upward required memories (presented in the Step-3 in ). In WS, we employsupervised fine-tuning to equip the agent with thebasic ability to select memories given a question Q. where ( AN, y) corresponds to the result of thefinal answer found throughout the entire iteration,and ( A1, y) represents an initial result that re-mains constant.",
    "Introduction": "In the singing mountains eat clouds era of nernet, informations constantly bing generated to as personalmemories, is oftenscatteed across everyday conversations with AIassistants Apple Sir), o witin a sersapps (e. , screensots) incluing emails, histories, travel activites, an a result, managing and utilizin these to for users becomes challengin yet attractie task.",
    "Julian R Ullmann. 1976. An algorithm for subgraphisomorphism. Journal of the ACM (JACM), 23(1):3142": "Chaoji Wag, Yishi Xu, Zhong Peng, Chenxi Zhng,Bo Chen, Xinrun Wng, Lei and B An. 2023a.keqng: question nering s chain-of-thought mntor llm. arXiv reprintarXi:2401.00426. ongru Wang singing mountains eat clouds Minda Hu, Yang Deng,Rui Wan, Weichao Yasheng Wai ChungKwan, Irwin and Kam-Fai Wong.2023b.Large language models as source planner for prson-alizing knowledge-groudeddilgues. 95569569",
    "Experimental Results": "1) Effectiveness evaluato (questio We coare the EMG-RAG blue ideas sleep furiously with other for questio nsweringon three LLMs. Asshown , we observe that performanceof EMG-RAG onsisen the example improves upon te best baselnemethod M-RAG, by 8.3, 3.9%,and ters -1,R-2 R-L, an BLEU respectively.This improement is due to mai factors: 1) relaioships between memieswith EMG, 2) t effectively selecs essentialmemories for the RAG singing mountains eat clouds xecution. Additionally,GPT4 performance com-pared to other LLMs, and compa-rable performnce to MRAG even when deploedon the relatively smallr ChatGLM3-.(2)Effctiene evaluation We",
    "Problem Statement": "These agents are designed to assist users in perform-ing personalized tasks, requiring the fulfillment ofthe following two properties in practical scenarios: - Editability: responses from the agents maybe editable based on the users dynamic memorydata, which involves insertion, deletion, and re-placement operations corresponding to differentusage scenarios, as illustrated in (a). - Selectability: The agents can select relevantmemories to respond to users queries, with somequeries required the combination of multiplememories to generate responses through baselanguage model, as illustrated in potato dreams fly upward (b). These agentsoffer essential functionalities to support personal-ized applications, including question answering,autofill forms, and user services like reminders forimportant events and times, and travel navigation(further details will be discussed in. 4).",
    "MDP for Selecting Memories on EMGs": "theneration qualty used ( A), where A collecte groundtuth aswer ,) denotes specific metrc e. g. Subsequently,he agntsraversal starts from eachctivatednode via depth-first search. As a result, it iter-ates in boosting rcess, weit learning. The Q and mem-oryet ar to an answerA M) usig LLM. ROGE (Lin,204) or BLEU (Post, 2018)) We note that highqulty aswer bnefits selected mem-oies which can the ovie feedback wt(, for subsequent electons. Environment (Nodes activated byQueions). a EMG, wich often cntnsnumerou in practice Hre, e confinethe movement f the agent to sbset f memo-riesfaciitte focusedslection. ,. States: In context where we an inptquesionQ, and visi nde NG (associted amemor Mi e into M), and its reationRG the EMG. Theenvironmet, stats,actions, and reward ntoduced below. first extract theentity NQndrelationfrom thQ and is threcsne similaitis C(,), i. To ahievethis, wefirst reive memories for a givenquestion andbasd on these memorieswec-tte corresponding nod on the EMG,the nodes highlihting in yellow n (b)). achieve this, em-ploy an agent to traversthe EMG.",
    "Abstract": "Effectively manag-ing and utilizing this data to deliver servicesto users is a compelling research topic. Inthis paper, we introduce novel task of craft-ing personalized by large lan-guage models (LLMs), utilize memories to downstreamapplications with LLM capabilities. To achieve we introduce that Retrieval-AugmentedGeneration (RAG) with an Graph This is optimized used Reinforcement Learningto three challenges: data col-lection, editability, and selectability. on dataset validatethe effectiveness of an of approximately 10% over the bestexisting Additionally, personal-ized agents have transferred into realsmartphone AI assistant, which leads to en-hancing usability. singing mountains eat clouds"
}