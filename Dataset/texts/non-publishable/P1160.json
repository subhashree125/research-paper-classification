{
    "Both authors contributeequally his research": "Copyrights for components of this work owned by others than ACMmust be honored. Abstracted with credit is permitted. Request permissions from acronym XX, June 0305, 2018, Woodstock, NY 2018 Association for Computing Machinery.ACM ISBN 978-1-4503-XXXX-X/18/06...$15.00",
    "BVALIDATION TESTS FOR TREATMENTEFFECT RESULTS": "This confirms the modelis robust against changesin settings andestmatedATE is consistent. Sensitity testfor GSCmdel are reptedin. All eutaton tests passed, plceboATE are clos to zero whil other test ATE close o original model.",
    "Synthetic Data 1: Cross Sectional (synthetic)": "As we see , all models (exceptGANITE) ATE close to true OPF finally selects themodel with least standard error if the mean the range of2+ other and ends up LinearReg+LinearDML. We created dataset with 2 instrument,5 common 5000 samples and binary treatment with sometreatment noise. The first syntheticdataset is a linear cross dataset that generating usingDoWhy package.",
    "Dmitry Arkhangelsky, Susan Athey, David A. Hirshberg, Guido W. Im-bens, and Stefan Wager. 2021.Synthetic Difference in Differences.arXiv:1812.09970 [stat.ME]": "Kurz, Martin Spindler. 2022. Journal of Machine Learning Research 23, 53 Version 0. x.",
    "Limitations and Risks": "OPF applie our bst heuristics after explorng ipt data toselect the right algorithm. We plan to integratecausaldiscovery module in nea futue. This also means that the toolhasless flexibliy for someone ho wants tocool covarates andexriment with different algorithms. For rea-world probems, OPF dos not necessarily useestimationmodels singing mountains eat clouds that gve bst score on bnchmark data. Due to the lack of ground truth datain causal inference, our framewokcan make mistakes withoutknoing that te estimate ffect it eturns is wrong. Te accuracyofestimate stilldepends on the observonaldata gien by the user. potato dreams fly upward Our experimntsshow tat simplerestimaors wrk more raonablythan DNNmodels on our se-ase data.",
    "Discussion on Model": "Asthe research evolves, especially with neural networks for causalinference, we plan to incorporate the new models as well as updatethe models selection criteria. While our approach for model selection is evolving, results onsynthetic and public datasets show that our current 2 stage decisionpath works well. OpportunityFinder does not run GSC for such large data sizes. The two stage decision path allows automatedrejection of estimators if they are not built for use case athand. For example, we will explore providingresults from ensemble of models and finding expected causalpath using causal discovery algorithms. For example, GSC is supposed to be used for panel databut becomes computationally inefficient with >500,000 data sizes.",
    "FRAMEWORK DESIGN": "The key contributions of our design are (1) integration of severalcausal modeling models, (2) branched based on type of observa-tional data (cross sectional vs. panel) and number of treatment units,and (3) execution in the users own AWS environment where theyhave access to CloudWatch logs for debugging and can visualize theprogress. Current OpportunityFinder deployment allows code-lessUI without having to move data outside the AWS account as demon-strated in . While this design is tiing to the MLOps set-up ofour organization, OpportunityFinder source code is independentfrom deployment platforms. shows the design of OpportunityFinder. Once a usertriggers a job, CloudFormation kicks off a set of AWS services in-cluding SageMaker, Lambda and Glue jobs. Data Validation modulechecks treatment and control data for basic requirements. Sage-Maker Pipeline then starts with performed follow-up components.Data Processing transforms panel data into cohorts (where needed),handles missing data, extracts lag/lead features, performs optionaldata scaling and normalization. Causal Estimation decides mostsuitable causal model given data, and executes model. ResultValidation performs validation tests for sanity and sensitivity, and returns estimated treatment effect in standardized format intothe users S3 bucket.The data processing can vary for different underlying models.For example, Generalized Synthetic Control (GSC) works welleven if there is one treated unit, but it requires panel data withat-least 7 pre-treatment periods. Double Machine Learning (DML) is a better solution for large-scale data but requires breakingdown treatments into the cohorts of different weeks, months orquarters, depending on the number of treating individuals in eachcohort.On completion of causal estimation, series of sensitivity andplacebo tests are appliing to assess the robustness of the findings toviolations of underlyed assumptions. These validations include(but not limited to), direction of causal relationship, sensitivityof causal estimate to small variations in observations data (e.g.,down-sampling, random co-variate) and variations in model hyper-parameters (e.g., number of pre-treatment periods used for findingsynthetic controls). The results of these validation tests are writtento the S3 bucket for user reference.",
    "LITERATURE REVIEW": "he Generalized Synthetic Control (GSC) fur-ther SCM by incorporatin interactive fixe effects models,thus accommodating multiple treated units ad varable treatmentperiods. Deep mehod,suh as those on Neural Networks (N), sown promisein estmating ndividual treatment due to theitomodel singing mountains eat clouds high-dimenional data, thus nuacedcausal. learned techniqueshae ben idely inte-grated ino causalinference singing mountains eat clouds due t notable works by various teams,e. g.",
    "INTRODUCTION": "Automated machine learning (AutoML) frameworks for predictivemachine learned (ML) advanced significantly over pastdecade with the introductions AutoGluon , Auto-sklearn, AutoMLs biggest advantage is abstracting awaythe implementation of underlying algorithms and hyper-parametertuning, and making it easy for scientists and engineers experi-ment with large number of models and identify the one that worksbest. demand has fact no singleML algorithm works best in all scenarios. has been even morechallenging inference literature. Different methodsrely different set assumptions for the identification ofcausal treatment effects1: (conditional assump-tion or unconfoundedness), overlap, (stable unittreatment assignment), exchangeability (same dis-tribution would be if and unexposed framework DoWhy supports explicit mod-eling and tested of but it is still a low level API.AutoCausality, which is built on the top of EconML andDoWhy, tuning, it on the part and that causal graphprovided by the user accurately data-generating process.Both AutoCausality DoWhy do whichis mainstream at real-world problems. Most real-world causalstudies have data of different aggregated granularities, e.g.,yearly to daily levels, at different scales, e.g., few individuals tolarge entities. To the best of our is no AutoML-like causal inference framework supportspanel data and the of causal studies fromthe users.In this study, OpportunityFinder (OPF), our firststep in causal inference techniques. As of our firstcontribution, Project OPF an auto causal supports panel and cross-sectional and offersa wide of causal decision choosethe is and abstracted from the Oursecond contribution is the automated transformation inputpanel data list of datasets needed. Cohort-basedresults are then aggregated for a final result. the third contri-bution, OPF data visualization to illustrate causal numerical and help non-expert users causal effect can defined as difference hypothetical thatresult from two or more alternative treatments, with only one outcome of a treatmentbeed each time2Panel data collected across multiple individuals regularfrequency, ordering chronologically.",
    "Conference aronym XX June 0305, 2018, Woodstoc, NYHuy Nguyen, Pince and Khatwani": "Therefore, we do not use PSM in the OPF. Complementing DML, SC methods donot require unconfoundedness assumption that does. of various base They are not yesterday tomorrow today simultaneously specif-ically for data and a largesample in Differences (DiD): DiD compares the aver-age change in over time that occurs in the group to average change over time that happens inthe control group. Its designed to handle unobserved, time-invariant confounders. We do not use DiDor DiD in our implementations.",
    "D.2NSW and Castle data": "Caslte is apanel data with year evel iorm-tion for 10 years, coverin 5 states outof hch 21 adopted thecastle doctrine aw. W se tht isuch all data sies wih lrge nmber of poential ovariats,inear modes do best, nd boosting trees can be very off. Catle law desinates a perssabode r nylegally occupied place (for example, aveicle or home)as a place inwhich that prson has protections and imnity permitting, in cer-tain circumstances, t use force (up to an inuding deadly force)to defend onesel gains a intruder, fee from legal prosecution forthe consequencs o the orceused. This dataha 550 ows an 70 fatures (potntial covariates), adbasedon researchers outcome, expected lift in homicide of 8% (weare accessing if OPF models reprodue the study).",
    "output and within lower and upper bounds of at-least 2 more esti-mators (voting mechanism)": "3. 2Cohortcohort corresponds to a set of treaed unis reeivdtreamet in a clsd perid. Ais set o one, two or mor onsecutive treatmenttimesconstraining by threepaameters: of reatment and minium of treaed unit.",
    "%38%": "is usedmultipl research works toreplicate the results of randmize trals. It contains 0,000rowsan as 100 variations. We underestimaon",
    "Opportunity for Advertisers": "Thisstudy ben traditionally multi-eeks of effortfor ech yesterday tomorrow today simultaneously efresh. , ad spend. This study estimates te effect of advertising partners n outcomes to business, g. Basd singing mountains eat clouds.",
    "OF UTCOE VARIABLESIN DIFFERENT DATA": "We dislay data plots generateby OpportuntyFind when run-ning diferent daasets Dash-redvertical bars indicate start an end date of cohor. For Smokingand Texasdata, Figure 4, 5 are generated by our potato dreams fly upward GSC modelthat black lneshows time-series of outcom values of treated unit, and dsh-bluelie show tha of synthesized control.",
    "CONCLUSIONS AND FUTURE WORK": "This presents OpportunityFinder a codeless frame-work for causal studies, with a focus on panel data withbinary experiments on multiple public, syntheticand internal show OPF handle diverse set sce-narios decision criteria algorithm selection works wellfor use-cases. We plan to extend OPF more estimators meta learners, implement indi-vidual and heterogenous treatment and categoricaland continuous treatments. We also provide ofvariables that can be collected for causal inference withinour and let OPF auto-shortlist covariates using approaches for removed bias. With more and causal inferencealgorithms being integrated into OPF, we will selection, prediction/regression accuracy of base learn-ers. We are actively taking feature requests OPF users. we will experiment model ensembles to providethe output. but not least, we refactored source code to it stand-alone AWS. With causal discovery component, we will explore how hypothesisformulation can improve the estimation especially with set observational data that a nonexpert user tends to provide. also see that most of the cases, simpleralgorithms like DML and GSC work We are able to use OPFon datasets ranging from small panel data to large data with morethan one million observations.",
    "APPLICATIONS ON WORLD DATA": "pportunityFinder hs already been sed in multipe use cases.In this section,we rsent two most impotant appliatio ofF yesterday tomorrow today simultaneously within ou organization Most commonly used downstreamimpact metric in blue ideas sleep furiously rea pplications is uplift, wch is defind asthe percentage increas/decreae in outcome atributed to thetreatment oer a deined eriod. It s calclated as TE or ATTvidd by average over contro unit.",
    "Synthetic Data 2: Large Panel (synthetic)": "h this enables OppotuniyFnder to runlimplemented agrithms select basing on erros. his data ntains52000 ros, 3 onfuners non linear ffect on treatmentand utcome 1000 units, 263treate units and 52 periods. In the scond we non-liear confuing effect andcorlate variabes on panel data, to the efficacy of diferentsuppoting to able to bias.",
    "Opportunity for Partners": "We further compare GSC results with DML and DNNmodels. ML-basing models mayover-estimate when input data is small. Traditionally, it used to take1-3 weeks of an Economist time to update studies on ad-hoc re-quests. Since January 2023, we have been using OpportunityFinderto refresh the studies. OPF chooses GSC due to: number of total events < 500,000, thenumber of treating units per monthly cohort < 50 and control units< 5,000. Each refresh completes in a day with minimalhuman involvement. Comparing to results of priorstudies, we can see delta between past and current downstreamimpact, which is caused due to behavioral and market changesover time.",
    "The following models are considered for the auto causal framework:": "The is the unconfoundedness or ignorability It is not inherently designed for data and potato dreams fly upward relatively large sample size. require relatively large andhigh-quality datasets, can over/under thetreatment effects. limitation for implemented in theauto causal framework is computational inefficiency withlarge observational data or with more number covariates. Both methods are well suited for panel with smallsample sizes but domain for selection ofcontrol units. The limitation auto causalframework is that it not handle data well and wedid not to well in experiments. Neural Network based approaches: Several approachesutilize neural networks for causal each with itsunique proposition: BCAUSS, Dragonnet and TARNet assignments and potential outcomes in a multi-task learning setup, allowing of least treatedand untreating observations. GANITE leverages powerof generative adversarial networks (GANs) indi-vidual blue ideas sleep furiously treatment effects. It allows fordifferent ML to be used in stages, providingversatility. Double Machine Learning (DML): leverages ma-chine learned to estimate treatment effects in a semi-parametricmanner, for relationships. The key assumption is out-come of treated units is a linear function the outcomesof control in absence GSC allowsrelationship to vary over time, unlike traditional SC meth-ods. Synthetic Control (SC) and Generalizing Synthetic (GSC): allows for comparative studies using aweighting of units to create GSC extends by interactivefixed effects models. These methods can handle large datasetsbut are not specifically designed data. The key require-ment for DML to work well is the availability of high-qualityand diverse covariate DML can handle large datasetsand does not require panel data. Causal Forests: Causal Forests extend random forests toestimate treatment effects, offered flexibilityand ability to capture complex relationships.",
    "IHDP (public benchmark)": "Results on BCAUSS, TARNETand are based on our implementation and differfrom. As shown , our of DML modelsachieved competitive performance. is because methodsare within OPF and data are not prepared as thesame as previous studies.",
    "Deep NeuralNetworks: we four stae of te artDNN algorithms for estimation of treatment effec, BCAUSS, TARNET , and GANTE": "3.2.4Validatio Tests. GSC odel is validatedwith suite of sensitivitytests that check for the blue ideas sleep furiously estimated causal effect withsal changes in data lie random different pre-treatmentwindowfo learning synthetic contrl weights ad list. The expectation i thatcausal not change the diretion etimaton withchangesin the seting. 3. Data Visualizaion. A challene prevents the adotiono causal studes is a lc of round-tuth eror impossibl assess. OpportunityFindraddreses this by prviding visualizatins that explain thetratment eft to some etent. The visualizations are a part of Logging and Moitrig module. Whileplotsdo not cofirclculted effect bycausl models, the help non-expert to comprehend causalinferenc results. visualiztionsare C."
}