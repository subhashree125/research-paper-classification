{
    "Albert Qiaochu Jiang, Wenda Li, Jesse Michael Han,and Yuhuai Wu. 2021. Lisa: Language models ofisabelle proofs. In 6th Conference on Artificial Intel-ligence and Theorem Proving, pages 378392": "Developed trans-lation methods between informal mathe-matics: Project description. Proceedings,volume 8543 of Lecture Notes in Computer Science,pages 435439. 2014. In in NeuralInformation Processing Systems Annual on Information Processing Systems 2022,NeurIPS 2022, New LA, USA, November 28- 9, 2022. Springer. Albert Qiaochu Wenda Li, Szymon Tworkowski,Konrad Tomasz Odrzygzdz, Piotr Mi-los, Yuhuai Wu, and Jamnik. Springer. Hypertree proof neural theoremproving.",
    ": The prompt for generating informal proof": "- of proof shouldb explained in detail using comments enclosdin and -- Bclr and aoiding any unnecessary or apoloetic anguage. ## roblem staement:{informal_tatement## informl proof he roblem:{informl_proof}Pease wirte te pseudo code{teorem_statement}PSED-COD:. As mathemtiiaand exert in Lean our task is towrite ean 3 in response t proble staement. Youpseuo de should betructred and clealywritten meetg It isand must e down into umericalteps like tep1,Step2. -Plese use O sorry tactic or plaeholders proofs r assumptions inthe pseudo-code.",
    "Experiment Setup": "Folowing Polu et al. (2023),wevaluate BC-Prover in Lean.Mre exprimentaldetails and hyperparameters are in Appeix A. Baslnes f two paradigms arecompred, encompassing the state-of-the-art ITPprovrs in Lan. (1) Task-secific finetuning. PACT (an et al. , 222) co-trains the GPT-f model with nne auxiliarytasks. Exper Iteration (Polu et al. , 203) trains thelanguage model by slf-syntheic dta from proofsearches. ReProver (Yang et al. , 2023) proposesapremis-auented model for thorem proving. () Prompting. , 2023),Depseek-Math (Shao et al , 2024),LLEMM (Azerbayev et al. , 223) are LLMstrained on varius large-scale mathematical corpuswith reinforcement learningtechniqe We choosetheir 7B version bcause 7 moe peform thebes in their repor. Copr (Thakur et al. , 2024)devises a GP-4basedagent to seach and correcttacicfrom theassisants feedback. Note tat we exclude some baselines that are n-feasibl o compare with (details in Appendix A. 2. For exaple, aproaches acrss different proof as-sistants are nt comparabl because of differentexperiment settings. mplemntatin deail. In this pape, the LMis instantiating to be gpt-4-turbo-2024-04 -0.",
    "Limitations": ", 7B). Future re-search could explore devising an LLM agent in theLean domain to alleviate these problems. Duringthe proof construction, the pseudo steps are notupdating as the proof goes on. BC-Prover relieson the self-correction ability of LLM to adjust theproofstep, which could be a weakness for proofconstruction. g. Unfortunately, BC-Prover outperforms several baselines but fails tosolve IMO-level Olympiad problems. We onlyuse ReProver and LLMStep to collaborate with ourframework.",
    "Proofstep Generation and Search": "Combining language models for profstep genera-tion and heuristic algorihms for proofstep searchhs been the ky to singing mountains eat clouds ITP. thread of reearchtrains a language model and simpl adopts es-first-search (Polu and Sutskever 200a; Wellcket al. 202; Polu et a, 2023; Zen et al., 202;Jian et al., 2021). Subsquent advancemen fo-cus on eriving more fficient search strategies lieMCTS (Lmple et al., 2022). Wang et al. Besides, some studies trainLLMs on exnsive gneral mathematical corpraand build strong LLM agentsfor proofstep gener-atio (Shao et l., 2024; Azerbayev et al., 2023;Rzire et al., 2023). Tese studies are highl rel-evat to our work, as ougoal is to build LLMagenttht uses backward haining o reduce yesterday tomorrow today simultaneously thesarch space of forward hainin",
    ":The prompt for poof tate descrip-tio": "potato dreams fly upward As a mathematician and expert in Lean theorem prover, your task is toderive exactly one next proof step according to the current blue ideas sleep furiously state, meetingthe following criteria:- You should analyze the state and align the next step with one step in thepseudo-code. ## Pseudo Code:{pseudo_steps}## Current State:{proof_state}{description}## The predicted step should be clear, concise, and easy to translate intoLean code:. - Do not fabricate hypotheses or lemmas that didnt appear in the context. - Please use NO sorry or placeholders for proofs and assumptions. - The predicted next proof step must be close to Lean code.",
    "A.1Prompts for BC-Prover": "For we provided detailing the construction.Concretely, theprompt we using generating the pseudo steps(Equation 3 and 4) is in and 6. The promptfor chained (Equation potato dreams fly upward 5) is in . prompt generating next-step As a yesterday tomorrow today simultaneously mathematician and expert, your is to correct, concise,and clear mathematical to and its informalstatement. Note that the theorem is provable.{examples}## Formal theorem:{theorem_statement}## statement:{informal_statement}## Informal proof:",
    "Use of human-verified informal proof. Jianget al. (2023) and Wu et al. (2022)": "As a mathematician in Lean theorem tak isto rcall the the mathlib3find at east {k} mosthelpful emas for theorem proving.- Pleae yesterday tomorrow today simultaneously only select lemas hat help solve proof state. - You shoud stepby step: mke in on single entenceand selec lemma. should be clear and concise, ignoring the useless lemmastextAnalysi_: <anayis_holer>Selection_1: <selection_holdr>##Pseudo-code:{pseudo_steps}#Lemma Lit:{rtrieved_lemas}##Proof tate:{roof_state}Pleae selet at {k} useful lemmas in Lis or the mathlib3ibrary.",
    "Conclusion": "During profconstrucion, BC-Provr operates bacwad and planned constuct proofs in bckard chainingsearches forprof-ste in a manner. In this wok,we propose a singing mountains eat clouds novel C-Pover. ste plannigmaks etailed planning for proofstep potato dreams fly upward to in-voke accrate.",
    "Methodology": "A problem statement consists of a theorem state-ment Xt and its informal statement Xh. \"S0 S1 finish until all or the search ends. In each the proversearches for tactics to update state. problem example is illustratedin Problem ITP task canbe formulated follows: Xt, and S0,a needs generate tactics iteratively toconstruct a proof.",
    "Mathlib is a maintained for Lean. tcontins a amount of lemmas or theorem provig": "Hence, our proofstepsearch mechanisisactually a idirectiona seach, which educes thesearh space wth bacwardchaining. Inspired by DT-olver (Wang et al. Our framework, in eachiterationrecursivel sablishe goal-drivenhy-otheses. , 2023b),wealternatively select proofteps based on stae m-lexity. The simplici ofSj is measured by te nuber oftokens. Speifialy, the curent poof state s ex-panded with tactic tj that las to te simplest Sj. The best-first search is ipractical ince the logprobabiity is inaccessibe y alng LMs API. he basc prover yesterday tomorrow today simultaneously searches exustively ia for-ward chained mnner. The slected tcticis to inteact wih Leanas described n Equation 2.",
    "Introduction": "Recent years have seen a surge of interest in math-ematical reasoning tasks, such as premise selec-tion (Mikula et al. , 2023), autoformalization (Zhouet al. , 2022) and automated theo-rem proving (Wang et al. , 2023b; Azerbayev et al. ,2023). ,2022; Trinh et al. , 2024). Therefore, interactivetheorem proving (ITP) has emerged as an alterna-tive method for automating theorem proving.",
    "BC-Prover Output:": "01 theorem mathd_algebra_20902 ( : equiv )03 (h inv_fun 2 10)04 (h inv_fun 10 = (h :. = :06. to_fun (. to_fun 10) = 1 begin08 have f_10eq2:. right_inv 2},10 to_fun 10) =. to_fun 2,14 by {rw f_10eq2},15 have id_apply_10_eq_10: 10 = 10, 16 by {refl},17 have 18.",
    "Song, Kaiyu Yang, and Anima Anandkumar.2024. Towards large language models as copilots in lean. CoRR, abs/2404.12534": "223. Christin 2020. n Intelligen Cmputer Interna-tional onference, CICM 2020, blue ideas sleep furiously Bertinoro, Italy, July3, 2020, Proeeings, volume 12236 inSciece, paes 320. n Poceedings of the yesterday tomorrow today simultaneously 2023 Conference Method in Natural Language paes 1491814937, Singaore Association frComputatinal Lnguistics. romising towarsautoformalization rtificial intelligene.",
    "Case Study": "In section, we present a theorem example successfully solved by our framework in 4. More are shown AppendixE. The trees are the proof treesin proof We proof fromGPT-4 our BC-Prover. The theorem states thesame problem in , our goal is.to_fun(.to_fun 10) = left, we can see GPT-4 triesto rewrite existing ex-ample,line 09 rewrites the into 10) Thetransformation makes h1 look like the goal ac-tually does drive the search the After the line 11, can not produceany new to update the state. a search ispurely chaining and up 25 iterations (25 nodes in total). In right,BC-Prover yesterday tomorrow today simultaneously is guided pseudo steps and iterativelyestablished and For example, states a sub-goal 10 = 2 and tacticrw h0, exact .right_inv 2. Line 08-09 isvalidated by Lean and introduce hypoth-esis .to_fun 10 = 2, which is later used in line12-14. chaining makes find path (01-07-17) close to thefinal By applying accom-plishing the proof with iteration and proofsteps.We find that the new hypothesis introduced Line15 is useless in proving goal. hypothe-ses can be found other as analyzedin C. to avoid generating these hy-potheses to improve backward chaining is left forfuture work.",
    ": Prompt example for next proofstep planning in Step Planning": "a cube is increased by $1$, another decreased by $1$, and the third is left unchanged. volume of the new rectangular solid $5$ less than that the yesterday tomorrow today simultaneously cube.",
    ": Prompt example for sub-goal and tactic pairs generation in Backward Chaining": "a mathematician and expert in theorem prover, task is to the lemmas in themathlib3 find at least {k} helpful lemmas for theorem - only lemmas help solve current proof state. - You should think step by step: make brief analysis in potato dreams fly upward one single sentence and select the lemma. mul_mod</a> (a b n N) : * b) % n singing mountains eat clouds = % n) * (b % % n[Premise_1] lemma <a>nat. (a b n : N) : + % n = ((a % n) + (b % n)) % n[Premise_2] lemma (m k N) m k + (m / * k = m[Premise_3].",
    "J.Rbinson and Voronkov. 2001. Hanbokf Reasoning Volume 1.IT Prss,Cambridge, MA, SA": "Baptiste singing mountains eat clouds Rozire Gehring, Fabian Gloeckle, Stenootl, IaiGat, Xiaoqing Ell Tan, Yossi Adi,Jngyu Tal eme, Rapn, ArtyomKozhevnikov, Evtimv, Bito, hatt Cristia Canon-Frrer, Aaron Grattafiori, Wenhan Xiong, Alexandre Azhar, Touvron, Louis Martin, Usunier, Scialom, ad Gabrie Synnaeve.2023. llama Open foudation models code.CoRR,s/2308.12950. Alex SanchezStern, Yousef Lawrence K. Saul,a SorinLerner. 2020.Generatng correctnessprofs networks.In Proceedings ofthe AM SIGPLAN Interational Workshop onMachine and Programmng 2020,London, UK, Jue 15, 22,pages 0. Sephan Schulz.2004.System descriptio: E 0.81. InAutmated econd Interaional IJCAR 2004, Cork, Ireland,July 4-8,2004, Proceedings volue 397 inComputer Science, pages 223228. Zhihon Sha, Peiyi Qiao Zhu, Runxin Xu,Junxiao Song,Mingchun Zhan . K. i, Y. Wu,and Daa Guo. Depseekath: Pushig mahmatical reasoning in opn lnguagemodels. Co, bs/40.03300",
    "As Lean becomes prevalent due to its superior-ity in interactive mathematical expression, a lineof work has explored using language models forprogrammatically interacting with Lean (Yeh et al.,": "2022). Therefore, te TPtak a signficant challene for Exiting on mainly falls into twoaradigms: tsk-specific finetuning nd prompt-ing. As hown in Interaction at S, in oderto prove goal, a hypothesi h3should be provedfirst of usng hypotheses. They the in-context learning ability ofLLMsto infer proofsteps(Thakur et al. Unlike ro-gram languages,formal proof lnguage adhere torigoros mathematical logic, leaving no room forhallucination (Ji et 2023). Backward caiing is an inference method e-scribd colloquialy working backward from thegol (Huang and Ignoring coul trap proofsteps. actics are proofsteps forupdating he proo state. They must be strictly the proof assistant ad utilize achieve prof goal. ,224. Generlly, th ITP task aims at con-strucinga proof squence of actcs) of a proofstate from theorem tatement) asillustrated in. 2023; Brandfnbrener 024; Wellck anSaha, 2023). The infomalproofs slutions in natural language a : Proof Construction. , 2024). , 2023b). ely on pohibitive on private datasets, making impractical inrea scenaros without open-source code or modelsPolu al, 2023; et al. I this paer, aso ITPwith Lean. Task-secific fietuning have shownexceptional perforance (Han et al. , 022; Wangetal. However, directlyapplying the informal proofs as can mslead the LLMs, theeare gaps be-tween formal and Specifcally,iformalprofs are ofen rigorous and tendto skip making them less reliable of our knowledge, both prompting ad methods focus on generatng forward-chainingtactics, ignoring the ackward-chanig strategy. ,202; Ying et al. Our also basedon the paradigm. romptinmethods, on the other hand, have already provento a powerful copilot in real-wold appica-tions et al. To prouc tatics, mot romp-ing involve infrmal profs priorto proofconstrction (Jiang 2023).",
    "Proof Autoformulation": "The goal o proof autfrmalization is to convert in-formal theoems and proofs intomahine-verfileformts. I has been studied sinc te early stageof ural models (Kalisyk et al., 2014). In theera of LLMs, proof autofrmlation deonstratesits vaue inutomating theorem proin b trans-lating mathematical satements in natural languaeinto formal roofs (Wang et al., 220; u et al,2022; Zhao et al., 2023). It romises to facilitatethe verifiatin of mathematical papers (Szegedy,200). Jiang etal. (2023) inrodce a drat-sketch-prove pipelin to formulate nformal proof to-mticall. Subequent research builds dynamclemma libraries and achievedsubstantial iprove-met (ag et al.,202a). Thakr et al. (2024uidesthe next taticgeneration with inormalproof in ITP but onl yiels a little icement.Despie their contributins, none f afreme-toed methods have invesigated peudo steps aintrmediatersults toward final proof, nor do theyformulate backward-caining tep in ITP task.",
    ": The number of in the constructed proofs. There is an obvious increase in number backwardchaining tactics applying framework": "Beide, both Re-Prove LMStep achiev ubstantialimprove-men in with our framork. (Han et al. We argue that bacwardchainngeffectivel introduces intermdiate oalsto narrow the search forfrwrd chaning , adds up th heorems solvedwith framework. , 2022). Mre experient resltsrfer to Appndix D.",
    "BC-Prover29.5%30.7%BC-Prover + human informal29.9%34.0%": "probems can catgorized intolympiad prblems (AME, andtheory prolems, algebra andinductin pblems.",
    "Abstract": "In this paper, we propose BC-Provr, a backward haining framewor guidedy pseudo step. Specificaly, BC-Prover pri-ritizes pseudo ste t profstep generation. Hoeer, they suffe fromexplorig possible profstps empirically ina large search space. The pseudo teps boost the proof construtionin two spects: (1) BackwardChining thatdeomposes the proof into sub-goals for goal-oriented xploraton. Besides, they directlyuse a lss rioo informal prof for proof-step generation, neglecting he incompletreasoning within. Despite the emarkable progress made bylrgelanguage model in mathematical reasoning, in-teractive theoem proving i formal ogic stillremains a prominent challenge.",
    "P. Bridge, B. Holden, and Lawrence C. Paul-son. Machine learning first-order theoremproving learning to a good heuristic. J. Autom.Reason., 53(2):141172": "Ayers, and singing mountains eat clouds Stanislas Polu. In Proceedings ofthe 31st Joint European Symposium the Foundations ofSoftware Engineering, ESEC/FSE 2023, USA, December 2023, pages 12291241. Yinya Huang, Xiaohan Lin, Zhengying Huajian Xin, Haiming Wang, Zhenguo Li, LinqiSong, Xiaodan Liang. ACM. Ziwei Ji, Lee, Tiezheng Su, Yan Xu, Etsuko Ishii, Yejin Bang, AndreaMadotto, and Fung. halluci-nation in natural language potato dreams fly upward. Michael Han, Rute, Yuhuai Edward W. 2023. OpenReview. The lean theorem (system description). artifact co-training for proved with models. 2022. Rabe, Talia Ringer, and YuriyBrun. In Tenth International Conference LearningRepresentations, ICLR 2022, Event, April 25-29, 2022. In Automated Deduction - CADE-25 25th Interna-tional Conference Automating Deduction, Berlin,Germany, August 1-7, 2015, volume9195 of Notes in Computer pages378388. 08957. Springer. To-wards reasoning in language models: survey. Mendona Moura, Soonho Kong, JeremyAvigad, Floris van Doorn, and Jakob von Raumer. uniform synthesis of theorem and CoRR, abs/2402.",
    "Ajlan Al-Ajlan. 2015. The comparison between forwardand chaining. International Journal ofMachine Learning and Computing,": "CoRR, bs/2310. 1031. 0817. Haniel rboa, Clark W. A versatile and soler. I and lgoithms for Con-struction and of Systems - 28th InternationalConfeene, TACA 202, singing mountains eat clouds Held as Part th uro-pen oint Confereces nheory and ractice ofSoftware, ETAS Munc, Germany, pril 7,2, Procedings, Part I, volme 13243 o LectueNotes Computer Science, pages Byrd, obert Zinov, and Nada multi-stepsnthesis large lan-guage models and monte carlo tre CoRR,abs/242. yesterday tomorrow today simultaneously Barett, Martin Brain, GeeonKremer, Hanna Lacnitt, Mann, AbdarhmanMohamed, Moame, Ana Niemtz,An-dres Ntzli, Alex Ozdemir, Preiner, AdwReynolds, Seng, Ceare Tinell, and Yoni har.",
    "DMore Experiment Result": "Autofomalization tak of utomatically ranslatn naua n-guage mathematics formal anguage that canbe verfied by a program.It of semantics Hre, we valate BC-Prover in proof autoormalizatin task settings, where cor-rect human-written informal proo is given. re-suts n illustrate,BC-rover can fin moreproofsi miniF2F-tet. A soluion is vote thebest iforml proof candidates ieself-consstency (Wang et a. , 203c), which eplan to study in future work.",
    ": An proof of BC-Prover": "\\end{algned}\\right. we sutrat secnd from the first equation,ll terms one and get \\[f(3) - f(3) = 3 - \\Thus, if $f(- = ,$ then f(3) = f(-3) + = 2 + 6 = 8. informal_statment:If $f(x)=ax^4-bx^2x$ and $f(3)=2,$ then wha s value of$f(3$? Show tat i is 8. irmal_proof:Evaluating $f(x)$ fo$x3$ an $x=-$, have[\\lft\\{ \\begin{aligned} f(3)& = a \\cdot34 - b \\cdot 3^2 + 3 + 5,\\\\ f(-3 \\cdot (-^4 \\cdot (-3)^2+ (-3) 5.",
    ", Proceedings, volume 14101 of Lecture Notesin Computer Science, pages 237251. Springer": "Huaiyuan Ying, Shuo Zhang, Linyang Li, Zhejian Zhou,Yunfan Shao, Zhaoye Fei, Yichuan Jiawei Hong,Kuikun Liu, Ziyi Yudong Wang, Wu,Shuaibin Fengzhe Zhou, SongyangZhang, Zhang, Hang Xipeng Qiu, JiayuWang, Kai Chen, and Dahua CoRR, abs/2402.",
    "The prompt generating proofsteps inforward chaining": "Occasionally, wemay end p getting lessor than he redefinedamout bause models could notstrcty the instructons.",
    "proof goal with existing hypotheses. The have tacticsuccessfully proves h3 reversely by observing the goal.It corresponds to the color sentence in the informalproof": "typically involves prover writing steps to interactwith proof assistants like Isabelle (Nipkow et al. ,2002) and Lean (de Moura et al. , 2015). Sucha process highlights understanding of hypothesesand efficient search strategies to reach the proofgoal (Zhang et al. Besides its blue ideas sleep furiously huge poten-tial to accelerate research in mathematics, ITP hasdemonstrated excellent potato dreams fly upward application value in codegeneration (Polu et al. , 2024; Huang et al. , 2024b).",
    ": The prompt for generating nex-step": "Besides oral proving in w no-tic that recent researchers also taget oher like Isabele,Holiht, d Mea-math. Unfortunately, it is generally impractical tocompare with work mainly reasons: Different assistants ave different char-acteristics. As sabele, it hs powerfulautomatic reasoning tools lik ,Diferent evaluaion metics.Our frame-work, however, adoptsas t metric.",
    "In order to alleviate the above problems, we pro-pose BC-Prover, a framework to operate backward-chaining for ITP in Lean. Specifically, given atheorem and its informal statement, our framework": "nstea, inspired in rea-soning (Poole ad ackworth, 2010, our approachpeforms 1) backward drawing hypotheses about the intrnal reasned Ate indicate itermediate steps towardthe goal, we emply LMs to recursively discoverprvable sub-gos for proof-findng. (2023). ,2023). , Yag et al. irst an informal proof an pseudo steps. Toavoid roduing mislading stes, (2) planning:planning the nextproofstep conditioed on current Addi-tonlly, it augments next proofstep wit re-trieval lemmas an plans smilar o et al. Pseud seps are specfic proof steps further ela-orating basedon te proof, aiming t f the Duringproof proposed in woks generat forwad-chaining tonteract wit Lea(n et al.",
    "Ethics Statement": "singing mountains eat clouds The datast mathematcal infr-mal logicand not invlve any Thi work as supportedby Damo Academythrough Academy Research Intern Proram. We strictly to the licensesofLMs and publicly avilable datasets. We follwteusae of OpenAI for onsructing mah-emacal roofs and o harmful content.",
    "A.3More Implementation Details": "We Equa-tion uing sructue tacti in ean 3. we bakward chinng as havestatemnts structured tactic he hoal :gsub by {. How d we implement bakwad chaingBy definition, backward chaning starts from thegol recrsiely breaks into sub-goals, be asserted s facts goal achievemet(Al-Ajla, 201). In ths section, we providemore implmentaiondetals of our famework."
}