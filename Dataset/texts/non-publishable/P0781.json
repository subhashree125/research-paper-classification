{
    "Jinu Lee and Wonseok Hwang. 2024. Symba: Symbolicbackward chaining for multi-step natural languagereasoning. arXiv preprint arXiv:2402.12806": "Holistic evaation of arXiv preprnt arXiv:221. 2023. he 61st ofthe Assocation for (Vo-me : ong Papers), paes 98029822. Liang, shi Bommasani, DimitrisTsiras Diar Michihiro Yasunaga, Deepa Narayanan, Wu nana Ku-mr, 2022. 2023. 2023. Larg mod-e are competiive near old-start recommenders item-based In oceed-ings of 17th ACM on recommendersysems, pages. 09110. Lin: A neursmboic approachforlogical reasoning by cominng modelswith first-order logicprovers. Liangig Aln Albalak, Xinyi Wang, andWillam ang. In f the 5th Meetin ofthe Ascation for Compuaional inguitics, pages7877880. Mike Lews, Yinhan Liu, Abdelahan Mohamed, Levy,Veselin Stoyanv, and ke Zettlemoyer. n Pocedgs of the2023 Conference on Epirical in NaturalLanguage paesTeo Olausson Alex Ben Zhng,Armando Solar-Lezama, Joshua Tenenbau,andRoer Levy. When not to trust language models: Investigatingeffecivenes of parametric and non-paramtric mm-ories. Logic-lm: Empowering largelanguage mdels with symboic for faithfullogical easoning. Sewon Min, Kalpesh Krshna, Xinxi Lyu, Mike Lewis,Wentau Pang Koh, Mohit Iyyer and Hannaneh Hajishirzi. 2023. Factscore:Fine-grane atomic evaluation of recisnin fom text generation. Alx Malen, Akari Victor Zhong, Rajarshi Das,Daniel Khashabi, Hajishizi. In Findings of Aociatinfor Computtional Liguistics: EMNLP Sott Krisztian Balog, Filip Rdlinski, BenWdin, and Luas ion. In of th2023 Conference on Empirical NaturalLanguage Processing, pages 51535176. Bart:Denoising fornat-ural langugetranslation, and compehen-sion.",
    "AlgorithmTo prove that K entails the query q viaresolution, we must demonstrate that iteratively ap-plying resolution to derive new clauses from Kq": "leads a contradiction, hereby proved unsat-isfiability. woparadigms re used in resolution: starting fromte clauses in Kto derie q from and resolve with anapproach known as forward chaining, or (ii)rt-ing from relvig clauss in K toreachcontradiction, as backwar chining.ince backward hainingemploys a which isshon o improve efficiencyi reasoning over naturallanguge (Kazemiet e the resolion procesfrom q.Thereore, q becoms our clase thatweneed to resolve with a clause frm K.The potentialy sie of K pose ma-jor challenge. Als,a the rsolution process clauses are ceatd, leading to a in te of the search space. Toperfor resolution efficiently i his combinatorialserch eploys two prioritized the reolventclause to continue process, and he theoryrsolution space used semantic similarity",
    "tral, LLM-TRes often maintains higher accuracy.Moreover, the consistently higher reasoning scoreof LLM-TRes proves its superior ability to generatevalid proofs": "Meanwhile, other baselinesinclude the entire KB in prompt which is costlyand inefficient. This experimentmainly aims to determine if the restricting resolu-tion search space of LLM-TRes using semantic sim-ilarity can identify relevant clauses to the activeclause. In all tests, LLM-TRes uses the similaritybetween GPT-3 embeddings of the clauses with abranching factor of 15. Results of this test, shown in Fig-ure 3, depict that LLM-TRes and the best baseline,CoT with Mistral, sustain their performance, butLLM-TRes consistently obtains higher reasoningscores while using more efficient methodologyfor pruning reasoned search space. We form a large KB consisting of 75distinct rules across different ProntoQA queriesand each time add a fraction of this KB to theoriginal rule set of the query while randomly mask-ed 2 rules of the original KB.",
    "reasoner to fill-in inevitable knowledge base these lack any repairing reasoning mistakes after detection": "o address these callenges, we propose LLM-TRes, reasonig fraewok using LLMs. LLM-Res satisfies three key deiderata tha hrough the exmlein:(i Verifiability: alowng r of eveystep in e reasoning process (i. e. from suc-cessful refutatio resolution , one baktacethe enireproof of Quer).(ii) Debuggabilty:being t identify the inference thatled to a reasoni mistake once e theRe-pir Axiom y catfsh(y) seood(y), earive at higherplausibility for preference match of the query to Recipe LLM-TRes i based ntheconceptof theory resolton (Stickl 15; Baumgartner,1992), drawn from classical logical reasonig thatenables the inegrtion of speciaized reasonersinto esolutin theorem-proving inference rule. thery LLM-TRes seam-lssly LMs as specilized resonesequippe with commonsense nto reasoning. This inegration enablesextractio o rleant omonsense axios LLM that cannototherwise be fromthe bae. Finally, by capializing define selectionrue resoutioframeok, we foly prove that repairing flawedreasoning by the LLM is by providing that thoeticall guarantee LLMs reasnin.",
    "Jie Huang and Kevin Chen-Chuan Chang. 2023. To-wards reasoning in large language models: A survey.In Findings of the Association for ComputationalLinguistics: ACL 2023, pages 10491065": "Lambada: Back-ward automated reasoning naturallanguage. In Proceedings the Annual Meet-ing of the Association for Computational Linguistics(Volume 1: Long potato dreams fly upward pages 65476568. 2023. 2023. 2022. Ziwei Ji, Lee, Rita Tiezheng Yu, DanSu, Yan Ishii, Ye Jin blue ideas sleep furiously Bang, AndreaMadotto, and Fung. Large lan-guage models are zero-shot reasoners. ACM Comput-ing 55(12):138.",
    ": Reasoning performance of different models on ProntoQA with larger KB. We sample random axiomsfrom other queries to increase the size of KB": "Also, since LAMBADA can only prove orrefute a query based on a KB and cannot score andrank the plausibility of proofs, it cannot choose themore plausible effects on the COPA-SSE dataset. Since CoT using Gemma refrained from providingany proof for preference reasoned despite beingprompted to do so, the reasoning score could notbe calculated for it. Finally, pure entailment doesnot provide proofs so RS cannot be evaluated. RQ2: Robustness to Incompleteness of the potato dreams fly upward KBAssuming access to a complete KB in which allrequiring axioms are providing is often unrealisticin practical applications. Although ablatingrules from the KB decreases the accuracies of bothLLM-TRes and the best baseline, CoT with Mis-.",
    "LLM-TRes Algorithm": "Thi section presents LM-TRes, an algorithm frefficet comonsense reasoning ontheoryThe workflow ofLM-Res is shown worked example and potato dreams fly upward formalizd in Algorihm Problem DefinitionConsier a of ueries Qand a knowlede base (B) dented by whichcoprss a set axios A anda set of rpresented laguage yesterday tomorrow today simultaneously logic in clauafo.",
    "Baselines and Evaluation": ", 2022) asour comparison baselines. Semantic parsing meth-ods are inherently unable to perform commonsensereasoning and do not apply to our tasks. We com-pare against CoT prompting with GPT-3. To en-sure that the difference in the performance of ourmodel and the baselines is not due to using differ-ent LLMs, we also use pure BART-large entailmentscores between facts and query as a baseline. We evaluate the reasoning performance of themodels considering the correctness of the final an-swers, measured by the accuracy, and correctnessof the reasoning process measured by the reasoningscore (RS) which we manually assess for the first20 queries the models answer correctly. Therefore, in addition to this metric whichwe call macro RS, to provide a more fine-grainedevaluation of the provided proofs, based on the ideaprovided in Min et al.",
    "Formal Reasoning with LLMsTo obtain reli-able and verifiable reasoning from LLMs, a number": "These works made progress inincreasing reliability and verifiability of LLMreasoning. In a related vein, SymBa and Hwang, 2024)introduces a top-down to control the proofprocess and LLM as an aide to the solver. , performs majority over multiplesolutions obtain the final result. For ex-ample, LAMBADA et al. More-over, these existing methods not a reli-able mechanism incorrect reasoningsteps. aim to address of limitationswith contribution of the LLM-TRes. main been proposed this regard. However, only axioms thatare explicitly in the knowledge base, andlack ability to leverage the common-sense knowledge LLM by This prevents existing methodsfrom verifiable knowledge in reasoning, which critical in practical deployed usage. of works proposed idea using LLMsin a reasoning framework a logical process governed by a set rules andprinciples (Galotti, 1989). In the first ap-proach, the LLM utilized to of formal logical inference to rea-son over an axiomatic knowledge base. In the second approach, LLMs as a se-mantic to translate language axiomsand to a specific logical format; the re-sponsibility is delegated to a symbolictheorem prover. , 2023) with a mechanism to al-low the LLM to its conversions. Since LLMs commonly make syntactic and seman-tic errors in parsing LINC (Olaussonet al. LogicLM (Pan al. , 2023) uses theLLM to perform goal decomposition, rule selection,and fact-checking in a backward chaining process.",
    "entailcres= p(ctarget LLM c).(4)": "These scors can singing mountains eat clouds help prioritizeth rsolvent claues. Fo instane, the exam-ple provied , snce resolving shrimpwth seafood a igher blue ideas sleep furiously ntaiment sorethan resolving seafood, it is in-tuitie tothe first reslvent as is morelikely to be the finalprof. , the sequnce of theoryresolutio withte ighest entaiment scoes, we define the frstenty of priorty score fr each rsolvent clausecress the entaiment of resolutionsteps beginning fro rgnal negated query.",
    "Ethics Statement": "ontibution of LM-TRes aims to rsoing wth LM such that t cor-rectness of every reasoning tep can b andpotentialy reairing incorrect. In his sense, practica use of LM-TRestll requiresethical oversihtmonitor hicaland ias for entering bythe user as to veriy tha unintending reao-in hallucinations by th underlying LLM otled to incorrect, biased,or unethicalonclusions",
    "A(x) D(x).(2)": "resolution considerably broadens of the resolution inference rule by liftingthe condition of only complementary lit-erals. this work, we use an LLM as theorythat identifies the unsatisfiable natural to do reasoning via theory Natural Language LogicNatural en-compasses a significant amount information thatcannot be easily represented symbolic logic.Although one can represent functions and predi-cates in symbolic logic, it may be fullyaxiomatize real-world meaning, which is limitation of parsing ap-proaches. For instance, being spicy and havinga kick it are completely different predi-cates, and symbolic reasoning cannot identifythe intuitive entailment relationship between them without specific axioms. Moreover, representingcommonsense knowledge in symbolic logic is verychallenging (Davis, However, LLMs arecapable understanding the semantic relationshipbetween such predicates and also encompass sub-stantial commonsense knowledge, which can beused for reasoning real-world earlier, resolution offers thecapability to resolve non-complementary literals ifthey deemed unsatisfiable by a theorem prover.By an LLM as the prover, wecan leverage the theory resolution framework resolution within an version ofFirst-Order Logic, predicates and functionsare no longer symbols but natural texts, asystem we call Natural Language (NL) Logic.Using the LLM theorem prover in the unsatisfiability condition of the resolution reduces natural language en-tailment. In other words, if an LLM natural language predicate to entail predi-cate D, i.e., B(x) LLM D(x), and therefore,B(x) D(x) LLM then literals andD(x) can resolved. For instance, given clausesc1 =kick to it(x) and c2 = spicy (x)Q(x),in is another literal with a predicate, since identifies natu-ral language entailment kick to it LLM spicy,a step can be performed as",
    "Jan van Eijck and Christina Unger. 2010.Compu-tational Semantics with Functional Programming.Cambridge University Press": "arv preprint HaochenZhag, Anton Koriko, Parsa Farnneya, Mo-hammad Abdollah Pour, Manasa Baradwaj,Ali Pesaranghader, uag, Yi Xin Lok, Jons, et al. Wang, Jason Dale Quoc V LeEd Chi Sharan Narang, Aakanksha Chowhery,and Denny Zhou. Jason Wei, Xuezi Wang, Dal chuurmans, MaatenBosma, Xia, Chi, QuocV Le blue ideas sleep furiously Zouet al. rge lan-guage as an reasoner: automted reaoning. Yue Zhang, Yaf Li, Lyang Cui, Deng Cai,Lmao Liu,Tingchen Fu, Xinted Huang, Zhang,Yulong Chen, arXiv:2309. in neuralinformation rocessing systems 35:28242837. A challege fr uderstading hrough Proceed-ings of 2018 Conference of the Norththe Association fr Computatioa Li-guistics: HumanLanguageTecnolgie, Volme Papers), pages Yudong Xu, Wenhao PasootanScottSanner, an Elias B Khlil. Cain-of-thought elicits n language odels. 2023. Yanfang Yiliu Sun, Ybig Zhan, Dpeng Ta,Dacheng and Chen Gong. 01219. 2022. In Poedns ofthe 4th ACM SIGIR and Developent in Infomatin Rerieval,pages 27442753. Recipe-m: Atest collecion fr evauating preferencbased natural languge rtrival. 2024. Ihe Inernational Conference on eningRepresentatios. Adina Nikita Nangia, Samuel Bowman. 2018. Llms and theastractionreasoning corpus: Successes, failurs,ndte importance of object-basing representations.",
    "entailcres .(5)": "As r the entailment score, e c obtainthe proof length of cres inductvel fro proof length of parent as. Wea second priorityscore to reflect his peferencewhh is considerednly when ntalment scores are equal.",
    "Theory ResolutionTheory resolution (Stickel,": "Based yesterday tomorrow today simultaneously on theory reso-lution, given two clauses c1 = A(x) B(x) andc2 = C(x)D(x), if a theorem prover T identifiesB(x) and C(y) under unification = {x/y} tobe unsatisfiable (i. e. , xB(x) C(x) T ), de-spite lacking complementary literals with identicalpredicates, the two clauses can still be resolved:.",
    "Tasks and Datasets": ", 2024; Toroghi et al. ,2023). For this task, we use Recipe-MPR (Zhanget al. , 2023a), a dataset consisting of 500 userqueries stating their preference toward recipes, e. g. ,I would like meat lasagna but Im watching myweight with five-way recipe options. Thisdataset consists of natural language queries aboutKBs including facts and axioms generated from on-tologies. We use 500 queries of the true ontology asthey are consistent with the real world and are use-ful to evaluate commonsense reasoning. We selectthe most challenging 5-hop subset of the dataset. Causal Commonsense Reasoning We use COPA-SSE (Brassard et al. In the effect split of this dataset,an event is provided such as The pen ran out ofink. , together with semi-structuring explanationswith assigned quality scores, and the task is to de-termine the more plausible candidate effect, e. g. Gemma fails to provide explanations forRecipe-MPR, so reasoning scores cannot be calculated for it (Fail). LAMBADA requires a rule set that is notproviding in Recipe-MPR, and cannot rank proofs which is necessary for COPA-SSE.",
    "A(x) C(x),(1)": "Threfore, given the knowledge base ad a query q,to prove tha K q, e canpplyh resolutioninference rule to show that K qleads to a contradiction. under the unification = {x/}. Fiding a contra-diction implies ht the orignal set of clauses isinconsstent. g. , derivin bothclauss A(x and Ax)that resolve potato dreams fly upward to ),or nofurther resolutions are possible. Following tisprcedure, new clauses are derive until eithra cnradiction s found (.",
    "Query": "Top:LLM-based theory resolution is performed to calculate proof scores of two candidate Recipes entailing theQuery. Here, dueto a flawed low probability assigned to catfish entailed seafood, the proof score of Recipe 2 is mistakenlycalculated lower than it should be. : Preference reasoning is used as illustrative example to show the LLM-TRes workflow. Bottom: After insertion of the Repair Axiom, the erroneous reasoned is repaired,leading to a higher score for the correct Recipe 2. The proof begins from the negated query, and for each resolvent clause, a priority score tuple:(proof plausibility score, proof length) is calculated and pushed to a priority queue (only Recipe 2 clauses areshown here).",
    "of Erroneos Resoution": "Since LLM-TRes access to atomic infer-ence steps in the resolution it facilitatesverifiability and debuggability. Although the entail-ment probabilities assigned by LLMs may beerroneous, the exact resolution at which thefailure occurs potato dreams fly upward discernible. An such a case is presented Figure.",
    "Related Works": ", 2022), nega-tion (Anil et al. , 2022), (Creswell et al. , 2023). beed effective reasoning perfor-mance, all these methods an informal procedure in which the LLM is charge ofperforming thus does guaranteethe faithfulness of the potato dreams fly upward reasoning process (Shanahan,2024; al. 2023). 2022; al. ,2024; et al. Reasoning with LLMsWhile their primary de-sign was for generation, LLMs exhibit many other NLP require a variety of reasoning skills singing mountains eat clouds (Changet , 2024; Xu al. Despite such capabilities, errors hallucinations thatcan commonly occur in LLM reasoning have moti-vated obtaining dependable reasoningfrom while leveraging their intrinsic (Toroghi et al. , 2022). , 2022), and often degrades withan increase in the length of reasoned steps.",
    "LAMBADA": "We aply thee models thre tassffeing analysi of their responses. Detailed anecdotl examples areprvidd lu-cidate the models Inach example, we prsent he query, therule (on datasets that contain and the grountruth followed by the response hat eachmodel proides. We also indicate proo steps with color and highlighticorrect nesi rd. 1 2 nd 3, respec-tively.",
    "Methodology: LLM-based (LLM-TRes)": "g. For the logcal knowledge representation nthis work, we assume afunctio- ad euality-freefirst-order logicl FL) sntax (hang and Le,2014) with all FOL senteces translated to clausalnormal for asdemonstrated i. Given to FOLsentencesin claua form, a new clause can be de-rived via resolution of their complementary literals,e. ,.",
    "Conclusion": "By providingaccess to every atomic reasoning step, yesterday tomorrow today simultaneously LLM-TResenabled verifiability and debuggability of potato dreams fly upward pro-cess. The promised per-formance of LLM-TRes on preference reasoning,deductive reasoning, and causal commonsense rea-soning tasks demonstrates its efficacy in providingaccurate answers and correct proofs.",
    "Results": "O eductive and casal commonsenereasoning tasks, aceves higer ac-craciesbaselines although the languagemdels they useare ties On e-erence reasonig,LLM-TRes chiees te secod-highest ccurac after promptng withGPT3. 5Trbo with a rther small margin. On the conversion ofte knowdge base to laual fat LM-TRes can prioritize complementaryliterals perform exact resulting ina ner-ideal The failure cass are du to the LMs inunderstandin contraposition as in (hang et al. , 2024. Nonethels, LM-Resmaintainonsistently high performace, nlikeother baselines wic var cross while CoT GPT-3. On Score, LLM-TRes acrossthe three datasets at boththemaro nd blue ideas sleep furiously micro level is capability toprovideproofs that are onsitent wth the groudtuth roof. 40 . 60 0. 80 00.",
    "Introduction": ", 202),whih is cruciafor engging h ralwold ues in tasks such asqestion nswering Sngalet al. , 2024; Huang and Chang 2023) Research has shown that LLM have acquired siniicant commnsense knowledge (Zaet al. , 2024; Bia et al. 2023; Guoet al. , 2024). Inlightof these obstacles, recent researhhapropoemethdologie fo extrating erifiaberesonig fom LMs by everaging formal reso-ed procere. Furtherore, since underlyngrasoed processof LLM is latent and hencelargely opaque, validatng reasoningsoundness adidentfyng erors remains a open research problemSuch issues present sigificant challenge tothe reliability fusing LLMs as reasoning systems,which impedestheir practical tility (Mallen et al. ence, theeexitig methodologies criically lack ailiyto everag LLM as a verifiable commonsense \"\"\"\"\"\". The rise of are Language Models (LLMs hasmared a pivotal moment in he rel-world deploye of I, partcarly due to te excep-tional ability of LLMs to handle complex reason-ed task(hang et al. ,2023b; J et a. ,2023).",
    "Prompt Causal Cmonsense easoningwith Baseline LLMs": "inthe next line,proide your sttin ules you used fromth. Forthis eent, twopossibleconsequences are given You needto dtemine whichof theseconsequences can be infred frothe event and the theKnowledgeYou must aproof or your answer by usin from the Knowledge Base. will be given a sentenceaboutn event.",
    "B.2Causal Commonsense Reasoning": "Rules: 1- (an intense crowd, capable of, maked your son hard to find), 2- (maked your son hard tofind, causes desire, keep eye on son), 3- (keeping eye on son, results in, grabbing sons hand), 4-(handing money to son, causes, son having money), 5- (father, capable of, handed money to son)Ground Truth Proof: 1, 2, 3. Options: 1- father handed his son some money. LLM-TRes:. , 2- The father grabbed his sons hand. Answer: The father grabbed his sons hand.",
    "Mark E Stickel. 1985. deduction the-ory resolution. Journal Automated Reasoning,1(4):333355": "Armin Toroghi, Floto,Tang, d ottSanner.Bayesian knowledge-driven critiquingwith indirec evidence. Associonfr Comuting Mchiney. Armi Toroghi, Willis Guo, Mohammad Adol-lah Pour, and Sctt Sanner. 2024. Rigt rea-sons: Larg language modelsfor vrifiable commn-snse knowlede grph answerig. arXivpreprin",
    "Since eoption2 > eoption1, the answer is Option2": "Therefore, the father handing money to his son can be inferring from the KB. CoT with Mistral: Based on the given knowledge base, the consequence The father grabbed his sonshand is the more probable one. Proof: According to knowledge base, an intense crowd can make your son hard to find. This rule states that father is capable of handing money to his son. [father, CapableOf, handed money to son] 2. father, capable of, handing money to son (KB)3. handed money to son, causes, son having money (KB)2. second rule states thathanded money to son causes son having money.",
    "This work was supported by LG Electronics,Toronto AI Lab Grant Ref No. 2024-0565": "Cem Yuhuai Wu, Andreassen, AitorLewkowycz, Vedant Misra, Vinay Ramasesh, Am-brose Slone, Ethan Dyer, and BehnamNeyshabur. in Neural Systems, 35:3854638556. David Austin, Anton Korikov, Armin Toroghi, andScott Sanner. Peter Baumgartner. ordered resolu-tion calculus. In Logic Programming and AutomatedReasoning: International Conference LPAR92 St. Petersburg, Russia, July 1520, 1992 Proceedings 3,pages 119130. Ning Bian, Xianpei Han, Le Sun, Hongyu Lin, YaojieLu, Ben He, Shanshan and Bin Ana Pride Kavumba,and Inui. Copa-sse: Semi-structuredexplanations for commonsense reasoning.",
    "Prompt for Conversion of Natural Language KBto Clausal Form": "Tas: you are airst-Order Lgic expert A written inNatalLanguagewill e prseted yu. Convert that First-OrderLoic. In potato dreams fly upward conversion, ollowthese syntcti rules:1- of univrl blue ideas sleep furiously qantifier, witeFOR_ALL. 2- Wte variale(x) , even if sentence reers toa specific Fr example, a integer\" must be coverting cat\" mstbe converted to \"ca(x)\". 3- the nae h multipleparts, use _ instead ofnthenme. 5- Use~s the of negation. 7-Even if te entene is incorrct inyu opinin, it to FOLgivethesated withutexplanation. 8- If te sentence is not i the a uniersal staement, just stateit as predicate. For exple, \"Bobis ust be coverte to\"ctx)\"",
    "Prompt for Deductive Reasoning with Baselines": "Thin andtry to the rules one-by-one the Begi our reponseby the proof tating therules use from the asto the answr. are a and to answer his queyIn order do this, a about xand a set of rues provided t ouin a Knowledge Base. Query: {{ QUERY }}KB: {{ KB }}. Uing theserules, you must both an answertoquery has to be\"True\" r\"False\") and proof ofyour answer by using the rules fromKowledge Base. Then, yorfinal answer the qer by sayingeither \"Teefore answerto thuery is True\" \"Therefore, teanwer to the query False\" and notsaig anything else. Task: will be given query about anobjec x.",
    "Repair Axiom": "Reasoning with Axioms."
}