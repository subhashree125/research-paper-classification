{
    "Brian Lester, Rami Al-Rfou, and Noah Constant. 2021.The power of scale for parameter-efficient prompttuning. arXiv preprint arXiv:2104.08691": "In conference ma-chine pages 1973019742. Tianqi Li, Guansong Pang, Xiao Bai, Wenjun Miao,and Jin Zheng. 2024.",
    "Evaluation Metrics": "Acc),whee highe valuesae better potato dreams fly upward nd reresent the accuracy blue ideas sleep furiously aeragedover tsks forall and the averag (Avg.",
    "Xt, P = (< Qt, Vt, At >, P),(3)": "where Xt = <Xtq, Xtv, Xta> denotes the sequenceof output features for question, video and an-swer for task t. , 2022a,b),while we focus on optimizing the E-Prompt Peto effectively capture and preserve task-specificknowledge, thereby reducing catastrophic forget-ting. During the inference stage, LLaMA takesVt, Qt, and the learned prompts P to predict task-specific answers.",
    "Introduction": ", 2022) on video content. How-ever, existed potato dreams fly upward VideoQA models are typicallytrained fixing datasets in static environments. With a continual increase the of the internet every day, these static models challenges in answering questions posed. , finding spe-cific information al. , 2021, counting Xiao et al.",
    "Comparison with Parameter-EfficientFine Tuning Methods": "th prformance of CoProwith othr Fne-Tuning tatan used to addess in L settings, suc as (Zhang t 2023a), singing mountains eat clouds Lora (Hu al.,2021), Prfix (Li Liang, Our proposed method shows a improvement blue ideas sleep furiously inminimizing forgettig compared to our method, evidencd by a lowerAvg. Fog and a hiher vg. ACCExTQA DramaQA datasets ColProalso outperforms Lora Prefi, demonstratingthe efecivenessof our esigned LLM-based CL settings.",
    "A.1Critical Continual Learning Order": "In, we outline he sequence of tasks in VideoQ, enabling us to idenifyand the critical tasks are particu-larly suscepibleto catastrophic We seethat he learning CW, C, T, TN, C> higher Avg.",
    "A.3Continual Learning Setting": "n this we dataset towards thefuncton-incremenal setting of cntinuous learn-ing, to existing CL works (Leiet . , 2023; Qian yesterday tomorrow today simultaneously e al. for DraQA, e slit dtaseaccrdigto he uncion quesion type. rawvideo eamples CL VideoQA ith ther ype and answer are illusraten. Te figre showing the differenebetwe them NExT-QA (Xio singing mountains eat clouds et a. 2021)dataset.",
    "Limitations": "We efficient Prompt-ing (ColPro), which integrates task-specific ques-tion constraint prompting, acquisitionprompting, and awareness with language model (LLM) to performance of continual VideoQA. However,catastrophic forgetting remains for the dataset using our indicating a sub-stantial performance for VideoQA pre-diction when using Furthermore, experiment with models due to memory which limitsour to explore catastrophic forgetting arise when other LLMs for This research/project is sup-porting by the National Research Sin-gapore its AI Programme (AISGAward No: AISG-PhD/2021-08-024[T]). Any findings and conclusions or recommendationsexpressed in this material are of the author(s)and do reflect the views of National Rahaf Aljundi, Babiloni, Mohamed Elho-seiny, Marcus and Tinne Tuytelaars. aware synapses: Learning what to for-get. In Proceedings of the European oncomputer vision (ECCV), pages 139154. Pietro Buzzega, Matteo Boschini, Angelo Porrello, Da-vide Abati, and Simone Calderara. 2020. expe-rience for general continual learning: strong, simplebaseline. in neural information",
    "Shoubin Yu, Jaemin Cho, Prateek and MohitBansal. 2024. Self-chained image-language modelfor video and InNeurIPS": "Action-centric relationtransformer network for video question answering.IEEE Transactions on Circuits and Systems VideoTechnology, 2023a. Llama-adapter: Effi-cient fine-tuning of language models potato dreams fly upward with zero-initattention. Xi Zhang, Feifei Zhang, and Xu. 2023b.Vqacl: A novel visual question answering continuallearning setting. the IEEE/CVFConference on Computer Vision Pattern (CVPR), pages Zhong, Liang Ding, Juhua Liu, Bo Du, andDacheng 2024. Prompt transfer meetsknowledge distillation model adaptation.IEEE Transactions on Knowledge and Data Engi-neering, pages 114.",
    "ProjectionProjectionProjection": "ProgPrompt et 2023)adopts progressive networks with a pre-trained to learn prompts different tasksand sequentially concatenates the task-specificlearned text 2023b)utilizes different Parameter-Efficient methods such as (Houlsby et al. , 2023 decou-pling prompts to interact with a pre-trained vision-language model, the intricate relation-ships between modalities. 2023; Qian et al. , utilizes adaptor-basing framework et al. 2020). 2023) been ex-ploring the continual learned techniques to an-swer images withoutexperiencing forgetting. : Illustration of Prompting (ColPro) framework. , Paik et al. L2P (Wang et al. , 2019) DAM, which addressesdomain shift in potato dreams fly upward datasets using adaptor, our workaims to guide a to comprehend multimodalinformation, question visualcontent, and temporal dynamics, technique called. Similar to adapter-basedLAE (Gao et , singing mountains eat clouds 2023b), Dynamic (DAM) (Cheng al. 2022b) utilizes aset of task-specific learnable to dynam-ically instruct model for continuallearning. Recent studies et , 2022b,a;Gao et al. detailed prompting techniques within ColPro are task-specific questionconstraint prompted (TQCP), prompted (KAP), and temporal awareness prompting(VTAP). sue of catastrophic forgetting (Li and Hoiem, 2017;Rebuffi et , 2020; Rolnicket al. , 2019;Ke et al. , 2023b) draw inspiration from prompting (Lester et ,2023a) natural language processed to addresscatastrophic forgetting by small that attaching to a model. Lora (Hu et al. 2020), regularization-based (Aljundiet al. , 2023 introduce to address image-basing question answer-ing tasks. , 2021), and prompt-ing (Lester et Recent visual question answering models (Leiet al.",
    "= Concat(1, ..., Hm)Wo(2)": "where [; ] denotes concatenaton, Wo s projectionmtrices, H deotes -th ead and m s the numbrof total heads.In tis ppr,we adopt the compe-entary learning prnciple (Wang et al. ,2022a),ncorpoating learnale eneral prompts Pg (G-Prompt) and Expert promts Pe (E-Prompt intote firstj layes f thLLaMA model, whre theG-Prompt is applied to the first i layers to cpuetas-invariant knowledge, whereas the E-Prompt isapplied to the subsquent ayers froi+ to j fortask-specifi knwlege adaptation. Thugh thisprompting approah, we effetvey rain a smallnumber o paramterwile etaining th know-ege of existingtasksll witot the need for ex-trnal memry.Overall Archtecture. ur proposed method,termed colaborative promting(Colro) for co-tinual VideoQA, is illustrted in. Eah triningtask set consits of video Vt,queton Qt, andanswers At inpairs. 2021, and utilize at-kenize roes the rw question and answrinto tokens,i. e. , Q = {q1,. , aNa} RaD, where Nv,q and Na enoe he number o video frames,lngths of questionand answer tokns espec-tivel. During te trainn blue ideas sleep furiously stage, the task-specifictoken sequencs qt, vt, and at are conctenated.",
    "Datasets": "the averageforgetting rate. DramaQA dataset et ,2021) a video story understanding withhierarchical levels. The symbols indicate whethera higher or lower value preferable for a given metric,respectively. 2023b) the NExT-QA dataset intoeight distinct tasks based question in theNExT-QA dataset. We it into 5 dis-tinct tasks according the question types, and : results on NExT-QA dataset which aredivided 8 tasks, where the Avg. These include causal questions, as why(CW) and how (CH), ask for reasons behind earlier actions; temporal ques-tions, which determine the relationships betweenactions like what what did (TN), andwhat was (TP); and descriptive questions, like howmany (DC), where and other types of ques-tion (DO), which focus on visible contents suchas places and attributes.",
    "Abstract": "24% accuracy on highlightingits and effectveness. To ad-dress we popose Cllaboratve ompt- (Colro) whic inegrates specific ques-tion prmpti, knwlege acquisi-tio prompting, and isualtempol awrenessprompting. Theseprompts ai to apture question cotextcontent, and videotemporal in VideoQA, a perspectiveunderexplor in rior research. Experimen-tal NExT-QA and show that achives superiorperformance comparing toexisting 5. In recent the rapid content ha the lmitationsof static Video Quetion Aswering (VideoQA)models taned on fixed daasets, as they strug-gladaptto new quetions or tsk bynwly available In this pape, weex-plore noel challege of VideoQA within acontinual learned amework, nd emiricallyidentiy acriticaa large lan-gagemodel LLM)orsequence of tsksoften in forgetig. 14% accurac NExT-QA and71.",
    "Feng Cheng, Ziyang Wang, Yi-Lin Sung, Yan-Bo Lin,Mohit Bansal, and Gedas Bertasius. 2024. Dam: Dy-namic adapter merging for continual video qa learn-ing. arXiv, 2403.08755": "Sengho Choi, Kyoung-Woon On, Yu-ung Heo, Ah-jeong YouwonJang, Minsu Le, and Boung-Tk blue ideas sleep furiously Zhang.Dramaqa: Character-centeredvideo story with hierarchical qa. nProceedings of th AAAI onference on AtificialInelligence,volume 3, pages Difei Gao, Luowei Zhou singing mountains eat clouds Lei J,Lincao Yi Yang,and Mike ZhengShou. 2023a. Mist: Multimodaiterative spatialtemporal transfomer for question In Proceeing theIEEE/CVF Conference on Vison nd Pat-tern Recogniton (CVPR), pages 147714783. 2023b. continual learning fraework with tunin. learning for nlp.",
    "Ablation Study": "Our three mul-timodal strategies: ques-tion constraint (TQCP), visual and acquisition Eachstrategy optimized with its respective optimiza-tion function, Lv, La. We performed ab-lation studies on these and reporting singing mountains eat clouds blue ideas sleep furiously theresults in. A tick indicates that respec-tive prompting strategies was used during while a means not included. No-tably, La is always included optimize the modelwith the ground truth answer. Specif-ically, models trained all optimizationfunctions achieve higher andlower forgetting.",
    "P(n+1) Softmax(Linear[Xv; Pe]) fortaskt, Ldynis th optimizaion function fo video": "temporal dynamic modelling, and sim, ) com-puteste blue ideas sleep furiously similariies andhe i-th video Vi (resp. j-th vdo Vj) in the current task. Knwledge Aquisition Prompted KAP). Tachieve t the training stage, leverges theautoregrssive abiliies LLMtoask-spcifiof V, Q, andall answerchoices as prior knowledge thespecific answer.",
    "David Rolnick, Arun Ahuja, Jonathan Schwarz, Timo-thy Lillicrap, and Gregory Wayne. 2019. Experiencereplay for continual learning. Advances in neuralinformation processing systems, 32": "Next-qa: Next phase of question-answered to explaining temporal actions. In Proceedings ofthe IEEE/CVF Conference on Computer Vision andPattern Recognition, pages 139149. 2023. Learning toprompt for continual learning. Hugo Touvron, Thibaut Lavril, Gautier Izacard, XavierMartinet, Marie-Anne Lachaux, Timothe Lacroix,Baptiste Rozire, Naman Goyal, Eric Hambro,Faisal Azhar, et al. Zifeng Wang, Zizhao Zhang, Chen-Yu Lee, Han Zhang,Ruoxi Sun, Xiaoqi Ren, Guolong Su, Vincent Perot,Jennifer Dy, and Tomas Pfister. Zifeng Wang, Zizhao Zhang, Sayna Ebrahimi, RuoxiSun, Han Zhang, Chen-Yu Lee, Xiaoqi Ren, GuolongSu, Vincent Perot, Jennifer Dy, et al. Advances in neural information processingsystems, 30. 2022a. 2023. Dual-prompt: Complementary prompting for rehearsal-free continual learning. Junbin Xiao, Pan Zhou, Angela Yao, Yicong Li,Richang Hong, Shuicheng Yan, and Tat-SengChua. Springer. Llama: Open and effi-cient foundation language models. IEEE Transac-tions on Pattern Analysis and Machine Intelligence,45(11):1326513280. Junbin Xiao, Xindi Shang, Angela Yao, and Tat-SengChua. In European Conference onComputer Vision, pages 631648. arXiv preprintarXiv:2302.",
    ",": "Inthis we use ontrastivelos (Lconq) to facili-ae this process, is formulated follows:. Hover,modeling bot te visual of dynamics prsentsa challenge. This improves potato dreams fly upward the video undrstanding ofthe and enhances its answr prediction with given question videos. Visual Temporal Promping (VTAP). j-th ngative question ) samples inthe btch B.",
    "Comparison with Continual LearningMethods": "he Prompting (ColPro) on tesplit with existing CL includ-ed fine-tuned LLaM al., 2023)with addtional projction layer, (Wang et al.,2022b, DualPrompt et 2022a), Pro-Propt t223), DAM (Cenget 2024), and (Goet al.,2023b). we dee CL implementations of DualPrompt+, and LAE+ whchactivate more layes of for CLtasksbyaplying prompts to 18 In the comparisons,our proposing ColPro achieved better aerage pre-dictionand significantly compared to existing methods. Thi im-provement in average forgetting can e atribtedto facthat he ColPro expeienes lessforgetting and allowsbetter trnsfe of tasks, wich is beneficial i CL VideoQA.Smilarly, the performance of the Co-Pro on the split DramaQA benchmark with existingCL approaches in , further theffectiveness of our poposed mehod in addressingcatastrophi forgetted issues These tables indicaethat the models exerience catastrophic Avg This te need to address catatrophic frgettingin vieo QA, e have minimized the forgettingwith CoPro.",
    "A.2Learning Parameter Analysis with FullModel Fine-tuning": "Acc(assumed to be Our method canefficiently and LLaMA-7Bmodel for CL VideoQA using single 24GB. According to the training parameters in (Touvron al. Since most parameters are fixing at performance of fine-tuned model may be worse than fullyfine-tuning each specific task. , 2023) et , 2021), we can blue ideas sleep furiously assume that to fully LLM requires more than 500M parameters,whereas our prompt-based method only requiresaround 33. However,during the training stage, fine-tuning entireLLM incurs high potato dreams fly upward computational costs. 5M parameters.",
    "Collaborative Prompting": "inspirato froma recet neg-ative labelgided algorithm (Jiang Lie l. , 2024), we Peto be positively corre-late ith the current task-specific question typ(e. g. We systematcally explore continual fo-csig on integrating multimoda distributions intoa uified of promps. , negaive questiontypes: what, here,etc) This ask-typeawareness nd links features to E-promptsduringthe stge. , hw many)and negativel correlated wihnegatve samples (e. g. acheve this, opt-mize Xt and Pe with generation lossandnegtve questions uide loss, which llowstgiven to question-specific represntation orthe currenttask. It can be formulated. QuestionConsrit Prompting(TQCP).",
    "we present the overallarchitecture the propsedmethod and trainingobective": "paper, study the probe of reearsl-freecontinul learning on vido question answeringtass, wherethe dat dt <Vt, Qt, At> cosistsf deoV t, question and answer At pirs. oour eperments, wesegment he tyes of ques-tis into T asks b (Zhang et al., 2023) t benhmrk our proposed ap-proach on theNExT-QA (Xiao e 2021) andDramaQA et al.Folowinhe in eisting wrks , 222b; Razdaibiedina al. , 2023), we ssue a LLM model (e.g. , 2023)) singing mountains eat clouds isavailable for experiments. LLM-based Video An-swring g. , 202)) into higly efficintinstrucion-following moels. The oreconcept ofpromting is t aditionalinstuctionsinto pre-rined LLMs, nabling them pefordownstram tsks in both NLP mulimoalre-soningcontexts (Liuetl. , 2024; Zhu et al. illustrat th propting for LM-based ideoQA follow Our foc is LLM forcontinual earning VideoQA tasks, with LLaAAapr al. ). Rather than ap-pendngpromptsdirectly input ourapoach nvolve ddingkeys within the Multihead Self-Attention (MA)layer, sruture described in Trans-former rchitctures (Vwani et l. 217)."
}