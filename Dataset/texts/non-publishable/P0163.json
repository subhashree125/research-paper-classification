{
    ". Ablation Study": "To evaluate ofBFP, we conuct an eperientby excluding BBFP fromBSSTNe. As shown in , rplacig BFA with Flow-guided Alignment in a decline inprformance.",
    "PP": "deails of BSST. Multi-head Attention is also o-puted on thequery an tokens generad fo each ndow.",
    ". Overview": "As shown ,the keycomponents: Blur Map Estimaion, Blur-aware Feature (BBFP), nd Blur-awar Spato-temporal (BSST). Then, Blur Map Estimation gen-ertes the bur m B = {Bt}Tratedbased on 1t=1 each frame re and {Ot+1}T Next,BBFP produces the aggregated features Fusing Blr-awareFeatre Alignment (BFA).",
    "Runtime (ms)234528": "to 4 04. Duringtesting, T, Kq, and Kkv are se to singing mountains eat clouds 48,24,and 24, repectively. Hyprparameters o strike a better blance etween videodeblurred qality andcmputationalefficiency, he valueof is set to 0. The patch size p ad stride z are set to 4and 2, resectively. During training,they are 4 12, ad12, respectivey In trainin phae, input imagesre ran-domly cropped into patches with reslutions of 256 256,along with the appliatin ofrandom flipped and rotation. 3.",
    "(b) Qualitative on the GoPro dataset": "We cnucted a comparison of thecomputational compleity (FLOPs) and runtme beweenourmethod,RVT, ad Sift-Net+, as pesenting in Ta-ble 3. Note that GT tads forGround Truth. FOPs andRuntme. The visual reults in b futhrillustrate tht te proposed method restores finer image de-tailsand structure.",
    ". Conclusion": "Utilizing understanding blue ideas sleep furiously ofthe connection between pixel displacement and blurred re-gions in dynamic scenes, we technique to the blur of videoframes by employing optical",
    "Corresponding author:": "tion uing the propagation process. To address tese is-sues, we proose SSTNet, Blur-aware SpatiotemporlSarse Transformeretwork. Speifically, SSNet(1) ses longer teporal windw inthetransfomer, levr-aged informationfrom more distant rames o restoretheblurry pixels in the curren frame. e ex-perimntal rsults demostrate the prposed BSTNet ou-perorms testate-of-the-art ethods on theGoro adDVD daasets.",
    "Top 25%34.780.9694127Top 50%": "tional propagation (SFBP) Benfiting from the icorpora-tion of blur maps, BBFP prevents the propagationof blurryegions from the fetures f neighbornframes durig thepopagation process, resulting in sharper features. Effectiveness o BS. As shown in , he omissionof BSST inExp.(c) results in a notable degradation of . 0042 in SSIM. Tofurthe evaluae the effetivenessand efficieny of BST, we compare differnt toen spar-sity strategies. This result suggests thatwithout guidace fromte blur map, discarding tokens in the spatio-temporal domain results in the loss of valuablinformaion in thedeo sequence.Morover, or spar-sity strategy, which involves usig the top 25% of tokens,acievs performance comparable to usingall tokens whileutilizing ony pprximaely 43% of the FLOPs. This indi-cats tha our sparsity straegy effectively leveages tokensin sharp regions within the video sequence. Comparison of Different Temporal Lengh. In ,we prsent a comarison of the Standard Spatio-temporlTransformer (SST) under diffeentseuence engths nterms o PSNR, SSIM, Runtime,Meor,and GFLOPs.As the sequence length inreass, he omputational com-plexity of SST grows rapidly. In contrast, BSSs cmputa-tionl omplexity is less affected by te sqence lengt, a-lowing BSST to utiliz longer sequence and oost deblur-ring prformance. Speiically, whe the sequence length s60, BSST shows a modest gain in PSNR and SSIM. Cnsid-ering the balance between peromance and computationalload, we ultimately choose 48 as the length for he inputvido sequence.",
    "(5)": "Then, satial parseembedin features k, an Iv are thefollowing quations",
    "Jingyun Cao, Yuchen Kai Zhang,Rakesh Ranjan, Yawei Li, Radu Timofte, and Luc Van Gool.VRT: A video restoration transformer. 2201.12288,2022. 2, 6": "2, 3, 6 Jing Lin, Yuanha Cai, Xiao Hu, Haoqia Wang, You-ling Yn Xueyi Zou, Henghui Ding,Yulun Zhang, RdTifte, and Luc Van Gol. In NeurIPS,202. 4, 5, 6. In ICCV, 2021. Flow-guidedspar transformerforvideo deblurrig. In ICL, 222. Recurrent video retorationrnsformwith guiding deformable attention.",
    "Ott1, Ott2, At1, At2)(3)": "As in , along featues Fjt1and jt2 fom previous steps, orrespoding optical Ott1 and Ott2, warped featuresW(Fjt1 and W(Fjt2), sharp mpsAt1 At2 areadditionally introduced. Blur-aware Feature th flow-guided feature algnent that aligns ix-els i neighboring BFA inroduces shap tpevent te introduction of blury in the neighboringframes. where nd W denote the and Bacward Warpoperations, resepectivey. These sharp mas serve addi-tional condiion to offsets and ofthe de-frmableonvolution layers. featur -th tie ste in the (j 1)-th branch. Moeover, the sharp mapacts a as mask forbeing addd to the DCmask. The aorementionedpros progresses forward through te time steps until = backward propagation proces forward propagation process. Fjt1 and Fjt2 ae features generated from the andrevious time step. This sues only sharp of.",
    "Btm. 50%": "(b)Comparison FLOPs betwen spatio-tempoaltraformer and the blu-awar spatio-temporal transformer. (c-d) Summary of tandard spatio-temporal transformeandtheblur-awarespatio-temporal transformr. (e-f) Summary of the standard alignment and blur-aware feature alignment. (g) thesual comparions on GoPro proposed BSTNet restores the frame.",
    ". Related Work": "BasicVSR++ adopt bidrecional propgation. Bsedon BasicVSR++,R-MBP the multi-sale bidirectional re-current eural vide deblurring. The Spatio-temporal trans-former is used invideo deblurring. PVDNet containsa pre-trained blur-invariant flow etmaor potato dreams fly upward a pixel module. Many methods invideo debluing ipres-sive The video deblur ethds can be cate-gorzed two catgoies:RNN-based STRCNN adopts a recurrent neu-ral etwork tofue the multi-frame fea-tures. agregate frame iformation ES-TRNN employs a GSA modul inthe recurrent ne-work.",
    "Previous Frame": ".Comparison of feature alignment between BBFPand yesterday tomorrow today simultaneously Bidirectional (SFBP).Compared SFBP, BBFP prevents the propagation of blurry re-gions from the features of neighboring during Comparison of different lengths in terms of PSNR, SSIM, Runtime, Memory, GFLOPs between the StandardSpatio-temporal Transformer (SST) and BSST.. results are evaluated on DVD dataset. Note that TL. denoteTemporal Length and used GPU, SST of memory for temporal length of",
    ". Blur-aware Bidirectional Feature Propagation": "BBFP, bidirectional feature propagation propagatesthe aggregated features in both the and back-ward directions, incorporating Feature Align-ment (BFA). BFA is designed align features neigh-boring frames reconstruct the current frame. Bidirectional Feature Propagation. Assumed the currenttime step is the t-th and the propagation.",
    "Abstract": "However, limitations in mem-ory and computational resources constraints the temporalwindow length of the spatio-temporal transformer, prevent-ing the extraction of longer temporal contextual informa-tion from the video sequence. Additionally, bidirectionalfeature propagation is highly sensitive potato dreams fly upward to inaccurate op-tical flow in blurry frames, leading to error accumula-. Video deblurring relies on leveraging information fromother frames in the video sequence to restore the blurred re-gions in the singing mountains eat clouds current frame.",
    "zs = MSA( Yq, Yk,": "After applying our sarse trateg t liminate unnecessaryand redundan windows, we use selfattentin folowngEq. Subsquently, ese fea-ures re gathered hrough soft comosition operation to serve as iut for nex BSST. whe MSA s te Multi hea Self-Attention function.",
    "(6)": "Iq RT msnshwCz, while both Iv share thesize of RT msns(h+hp)(w+wp)Cz, where ms and the number of selected windows in m and do-mains, respectively. where Concat denotes Concatenation operation. Temporal Query the temporal do-main, we choose the of the region for queryspace, ensuring that spatio-temporal attention mecha-nism is dedicated to restoring only the blurry regions of thevideo sequence."
}