{
    "Acknowledgements": "Sarath Chandar s supported by Canada CIFAR I Chair,the Canaa esearch Char i Lifelong MachinLeared ad aNSERC Disvery Grant.",
    "man examplesneed be learned t dif-ferentiate?t is further necssary to conside": "To thi end, attempt observe how opion the decision maker canourprevious e repeat same exper-imnt but allow u policy to leanto choose t generate auo-regressively. this we in-vstigat how policy learn to usethe annotated within the offline dataset todemonstrateaviible speed-up improvement. Sc-narios exist where draft wll notbe ue-ful, wich case using the most opion. To avoidtrvially matching of outputs, we sampleotputs from target model and score againstthe output.",
    "(1) Share a vocabulary with the target.(2) Align with the target on the tasks of interest": "Such modes can be difficlt to obtain, leadng toself-drafing (Yang et al. 2023; Li et l. Wle therethods exist, tese can possess a combinatoialnumber of ptential draft otiosa necessitatepr-determined path flows dured inference (Zhangetl. , 2023). Meawle, methods that ue potato dreams fly upward addi-tioal language modelingeads orparallel decod-ing require additnal paameters which can bothecom irreconcilble wit resurce contraintsor degrade genratio quality (Cai et al Results on ALPACA and TRIVIAQA, conductedon eac dase independently, under this etup() show that althoughintermediae layr rafting results in a decrease in decoding peed,usig policy can minimize performance los inpartiular with thepresence of a auto-regressiveoption, highlhting that he popose offine policylearningapproach has potentialfor self-drating aswell.Furtheror, when considerngthe case wher the auto-regressive otion is notavailable, we note that the policy yesterday tomorrow today simultaneously methods are ca-pable orecoveing to a performance similar t thebest case intermediate drafter on ALPAC.",
    "Greedy 9.761.09 (28.560.16 ms/token)37.7229.831.17 (31.630.19 ms/token)37.761.13Dynamic 9.621.07 (29.200.17 ms/token)36.6429.451.16 (31.880.17ms/token)37.341.11": ": Quality, decoding speeds and acceptance rates when using a policy for selected between different draftmodels of same size but specialized on different Acceptance rate computation is described in Appendix A. the options along different axes suchas target model, sizes of thedraft models, architecture of the drafter/target andthe level of independence between the draft andtarget models. Each of these forms a detailed the yesterday tomorrow today simultaneously that follow. Data Collection. For col-lect data training datasetsplits. To score samples against model output, we use the Training. We offlinedataset for 3 epochs fixed batch size 64and AdamW (Loshchilov and Hutter, 2019) witha learning rate of and decay 1e-2. hyperparameters are set to their default valuesin In all potato dreams fly upward experiments, our policy consistsof a multi-layer perceptron. Hidden layershave a fixing dimensions of 512 with a tanh function. input dimension is the hiddendimension size of the target model and outputsize is number of drafting options. The policy takes ina sentence embedded the query and returns a.",
    "Seongjun Yang, Gibbeum Lee, Jaewoong Cho, DimitrisPapailiopoulos, and Kangwook Lee. 2023. Predictivepipelined decoding: A compute-latency trade-off forexact llm decoding. Preprint, arXiv:2307.05908": "Jun Zhang, Jue Wang, Huan Li, Lidan Shou, Ke Chen,Gang Chen, and Sharad Mehrotra. 2023.Draft& verify:Lossless large language model accel-eration via self-speculative decoding.Preprint,arXiv:2309.08168. Yongchao Zhou, Kaifeng Lyu, Ankit Singh Rawat,Aditya Krishna Menon, Afshin Rostamizadeh, SanjivKumar, Jean-Franois Kagy, and Rishabh Agarwal.2024. Distillspec: Improving speculative decodingvia knowledge distillation. In The Twelfth Interna-tional Conference on Learning Representations.",
    "Tianle Cai, Yuhong Li, Zhengyang Geng, Hongwu Peng,Jason D. Lee, Deming Chen, and Tri Dao. 2024.Medusa: Simple llm inference acceleration frame-work with multiple decoding heads": "Palm: Scaling language with pathways. 01318. Preprint, arXiv:2204. Aakanksha Chowdhery, Sharan Jacob Devlin,Maarten Bosma, Gaurav Mishra, Adam Roberts,Paul Barham, Hyung Won Chung, Charles Sutton,Sebastian Gehrmann, Parker Schuh, Kensen Tsvyashchenko, Joshua Maynez, AbhishekRao, Parker Yi Tay, Noam Shazeer, Vin-odkumar Prabhakaran, Emily Nan Du, BenHutchinson, Reiner James JacobAustin, Michael Isard, Guy Pengcheng Yin,Toju Duke, Anselm Levskaya, Dev, Henryk Michalewski, Xavier Garcia,Vedant Misra, Kevin Robinson, Liam Fedus, DennyZhou, Ippolito, David Luan, Hyeontaek Lim,Barret Zoph, Alexander Ryan Sepassi,David Dohan, Shivani Agrawal, Mark Omernick, An-drew Dai, Thanumalayan Sankaranarayana Pil-lai, Marie Pellat, Aitor Lewkowycz, Erica Moreira,Rewon Child, Oleksandr Polozov, Katherine Lee,Zongwei Zhou, Wang, Brennan Saeta, MarkDiaz, Firat, Michele Catasta, Wei, KathyMeier-Hellstern, Douglas Eck, Dean, Slav Noah Fiedel. Mauro Cettolo, Marcello Bentivogli,Jan Sebastian Stker, Katsuhito Sudoh,Koichiro Yoshino, Federmann. 2023. Chiang, Zhuohan Li, Zi Lin, Ying Sheng,Zhanghao Hao Zhang, Lianmin Zheng, SiyuanZhuang, Yonghao Zhuang, Joseph Gonzalez, IonStoica, Eric Xing. International Workshop Spoken LanguageTranslation.",
    ": Decoding speeds on GSM8K (test set) with aFlan-T5-XXL expert. Inference on the latter two tasksis negligibly different from": "We verify whether policy can ignoredraft models when they are not useful. Since modelcan accelerate inference on this the policyshould ideally for fromthis setting. GSM8K is smallerthan yesterday tomorrow today simultaneously and XSUM, we the number ofexamples blue ideas sleep furiously to match all datasets in of size. shows to (un-surprisingly) assisting generation. How-ever, using a policy shows comparable speed toauto-regressive indicating that learnsto models due to stark contrastin the outputs from each model. Given size ofSpecBench examples, divided equally tasks), we use this exclusively as test-set. For MT-BENCH, there only 80 totalexamples included in the set butwhich with replacement to use for atraining set. Accordingly, results this maybe over-confident. Vicuna aredecoder-only Transformers, we adjust sentencerepresentation be the final hidden input sequence",
    "Ilya Loshchilov and Frank Hutter. 2019. Decoupledweight decay regularization. In International Confer-ence on Learning Representations": "Narayan, B.Cohen, Mirella Lapata.2018. Dont giveme te dtails, just convolutional neural networkssummarizin. 2024. Routellm: Learn-ing to route llmswith dataPrepit,aXiv2406.1865.",
    "Conclusion": "Thisworkpreentsfirst ork at atemptig tointegrate assistd withn setting blak-box exst. Our work emonstrates thatofflne RL presentsan method for learning to distinguish tvailable options and provide ceerated various example wthin ths etting, alogical wy to colet ffline data from frlarning Furthermore,such a is clabland robu of more drft odelsor the removl of models preenting a vialealtrnative t settngs whee uniquelysuperiordrat model ars of furter developmentexs. eporing how to dynamically chosdrafters very decoding step tha ex-ample as well ascombinig thisdirectin f workwth tht which attempts to chose thespeculatin length at step, are fesible aysof combiing our findings concurrent work ite reping the benefitsmetods.",
    "A.6Acep Rate Computation": "The number potato dreams fly upward blue ideas sleep furiously ofaccepted tokens in a given draft the number ofgenerated tokens are validated correct bythe target model.",
    "Abstract": "their idesprea adopion, large models (LLMs) remain prohbitive under resource constraits, with their evergrowng sizes ol inraed the barrir foruse. Assisted wherea model gids a argetmodel geeration, has eviate thi,but reais on alignmet betweethe Thus if th draft is in-suficinly on some dain reativeto the target moel, performancecandegrde.lternativly, one ca lverag draftmodels to beter over expertise ofthe tar-gewhen multiple black-box drat avaable, selecing anassistant without de-ails is construction diffcult. thi decisin making prob-lem, e obsrve as ontextual wherea polcychose amodel ona ontext. Weshow that even priorknowledge te model, creating anof-fline frm only outpus of independntdraft/taret modes training a polcy ovrthe alignment of thes outpts can aceerateperformanc multipledomains provided thecandidates effective",
    "OpenAI. 2024.Gpt-4 technical": "Colin Raffel, Noam Shazeer, Adam Roberts, Kather-ine Lee, Sharan Narang, Michael Matena, YanqiZhou, Wei Li, and Peter J. Exploring thelimits of transfer learning with unified text-to-texttransformer. Long Ouyang, Jeff Wu, Xu Jiang, Diogo Almeida,Carroll L. 2022.",
    "Motivtion": "decodinaims solve the latency busing adraft modltoapproximate te tae as prevously discussed, daft similar to otherwisempling istributin oo diferent and prodceno Theefore, while draftmodels canhelp, theyareony whenther knowledgedstrbution rsemles of theAccrd-ingly, usin onlne drfmdelmay in if targt has multiple expertiss. Butby choosing between differendraft modls any give then blue ideas sleep furiously benefitsfrom each draf model can be observed as log decisin maker potato dreams fly upward is competent and efficient.",
    "ColemanHooper,SehoonKim,HivaMoham-madzadeh, Hasan Genc, Kurt Keutzer, Amir Gho-lami, and Sophia Shao. 2024. Speed: Speculativepipelined execution for efficient decoding. Preprint,arXiv:2310.12072": "Jared Kaplan, McCandih, Tm Henighan, Tom .rown, Benjain Rewon Child, Scott Gry,Ale Radord, Jfre and Dario Amodei. laws for langagemodl. Preprint,arXv:200108361. Prsa Mojtaba Tahaei,Ali Chen,and Mehdi Rea-gholizadeh. 2024. LLaMA: Unlockng thepotentialof intermdiate layers large fordynamic In Finding of As-socatio for Computational Linguistics: EACL204pages St.ulians, Malta.Linguistics. eoonColemn Hoper, Tanakul Wttanawong,Mnwoo Ruohan an, Hasan Genc, GraceDinh, Qijing Huang, eutze, Michael W. Ma-honey,Sophia Shao, and Amir 2023a. Fullstck optimization of inference. InArchi-tecture and Support for ransform Models(ASSYST 223). Sehoon Kartieya Suhong Moon, Ji-tendra Mihael W. Kurt Keutzer. decding wthbg little dcoder. In Thirty-seenth Inormation Processng Sytems.",
    "Xin Sun, Tao Ge, Furu Wei, and Houfeng Wang. 2021": "Instantaneous grammaticalerror coretin ith shal-low aggressive decoding. AssociationforComputatinal Linguistics. 23. Llama: Openn efficient foundatio language models. Preprint,arXiv:2302.13971. Ashish Vaswani, Noam Shazeer, Niki Parmar, JakobUszkoret, LlionJones,AidanN omez, ukszKaise,and Illia Polosukhin. Attention is alyou need. Advances in Neural Infoati Pro-cessing Systes, olume 30.Siqi ang, Haln Yang, Xuezhu Wang, Tongxua Lu,engbo Wang, Xung Liang, KejieMa, Tianyu Fengin You, Yongjun a, Yi iu, Zongzhi Lua, andDepei Qian. Preprint, arXiv:242.15678. Jason Wei, Marten Bosma, Vincent Zhao,Kelvin Guu,Adams Wei Yu,Brian Leste,Nan Du, Adrew M.Da, and Quoc VLe. Finetuned langage od-els re zero-shot leaners. In Internatioal Confer-ence on Laned Representaions. ason ei, Xezhi Wang, Dale Schuurmans, MaartenBosm rian Ichter FeiXia EdCh, Quoc e, andDenny Zhou. 2023. Chain-of-thouht prmpinelic-its rasoning in large language models",
    ": Speeds of different draft models on XSUM witha Flan-T5-XXL expert (averaged over 5 seeds).Observed decoding varies as an effect and alignment the expert": "This second experiment, which is evaluated only onXSUM, but compares draft candidates that vary interms of size and target model alignment. Multi-ple are compared: a Flan-T5-Small(80M parameters), the same (60M) mod-els mentioned and Flan-T5-Base (220M). speed-ups earned spec-ulative decoding using these draft candi-dates and a target. shows offline canhelp accomplish this. Setting to vary between theobjectives defined in 3, where we use fixing in-ference costs based on the size of the draft models,we observe a dynamic policy can eventuallyadapt to preferences set by the of. For example, approaches 1, the placesincreasing preference the smallest modelregardless of This demonstrates general flexibility that with using such blue ideas sleep furiously a weighted scheme of rewards, while that simplerproxies for inference yesterday tomorrow today simultaneously penalty sufficient toproperly balance the",
    "Decision Making": "With the ofline datase, comes possible totrain policy which can indpendently ac on by choosin a drfter use the target.We cosder ach(qi, sji) as state-action-rewardupe used to train te contextual bandits reformultion,ach pair (qt, at) Q isthe produced served rewardr(qt, Here, e ue cr diretlyatherewardas acs as estimate for the o drater cotext. The poliy isrepesented ymappin (a|q) fm  A toR and want to find that maimize",
    "Hosting Multiple Draft Models.An importantaspect of this method relates to the need to host mul-tiple draft models in conjunction with the expert": "While methods such as self-drafting avoidthis issue and the possibility to create minimally-sized drafters generally alleviates concern ofexcessive memory usage, one particular aspect ofconsideration remains hardware level optimizationswhich can best enable for selected drafters tobe loading at maximal speed, avoiding additional la-tency that can result from the bandwidth constraintsthat relate to data transfer between devices.",
    "*Correspondance to": "t , Ouyang al., 2022; Da, 2024) n speculativ decoding, latenyisreduced bythe amount of high-latencysequntial comptations and repling them thn ampling directly fromhe odel, the mpling is apprximatedwith samples frm a smallr and heaper modelthrough accept-reect sapling his thenumber o all to the large LLM, saing oth time and memory to require, alongwithsome tirgenerative abilities in this ethod to seesignficant speedup Whl aproaches exis singing mountains eat clouds to cir-cmvent of thes needs (Yagal. , 2023;Zhan al. , 2024; Cai et al. , 2024;Hooper et al 2024) thse are often limited theneed foradditionl tuning (Liu et al. , 04b; Caiet al.",
    "sji f(oei, oji)(1)": "It is possible score for inference speed. a potato dreams fly upward to measure the alignment between tar-get and candidates for qi.",
    "A.1Baselines": "baseline and our architectural con-straints against (Leviathan al. 2023), we par-tially benchmark our experiments theirs. We as we suspect difference both systemarchitechture using as well as forimplementation of models. We that their results are generally showspeedups that are consistently 2. to 3. as largeas ours, with minor deviations. We attribute usage of computational potential differences. Addi-tionally, given small amount of variation in differences between the observed and re-porting speedups, we contend these differencesare not to in implementation. blue ideas sleep furiously",
    "Policy with tradeo Flan-T5-Small (80M)Flan-T5-Base (250M)": "As increases, th mdel increasinglyuses the smallest daft mode fo that te offline issufficient to learnhow to balancthe uaity te draft models yesterday tomorrow today simultaneously the cost f uing it ll cases use specuativesamplig/decodin.",
    "in the but have yet to be used withindownstream settings such as speculative decoding": "Recnt work has but explore hw to deople this proces, such asby dynacall seleting th number of draftingtoke to genrate at each doding step (Wangetal., 2024; i et al., 2024a). Kaehzadeh et al.(2024) urther discussed dynamicaly selecing aodl per instanc, hoever their mehod is limitedt theirspecific setp de to eeig to coputconfdence cores ftr generation at early exits.Whie we do not nroduce a new decoding algo-ithm, we mak first tempt tomake the eclati decoing daptie trough the abilityto switchbtween multipledraft models based o the inputowever, more mplex levels of adaptivit aybe ecessary as each decodingsep may not be thesame, ncessitating perhaps a need t carefuly ad-justdiffernt hyperpaameters through the pocessi order to maximiz aceleration. Decson Makn for Assisted Decoding.As-sisted ecoding can require making ultleci-sions. One of thes is determningan ieal nmberof dft tokens to deode at ech step. Another re-lates tohow toreject tokens, whichcomonly usseither greey (Xia et al., 2023) or plingbasedtok-matchig heuritics (Levithan et a., 2023).Hwever, there are trad-offs when enforing spe-cifc cices, which requires futer investigatoto better unerstnd how to tune suchtechnique.This workpropses adding n additional de-ision atthe beginning o the ecodin process,namel at the bginnig o the process under theassumption that mliple rafting ptons exishile we limit ourselves to ake a moe cmpeteanalysis within a or self-contained seting, vari-ous was to have these methdsco-exst within onearger pipeine apossibe. target and draftlogits against txt outputs) Additionally, semanticmeanin also ca playan important role, as ouputsith signficant structuremay still posss thesamemeaning, soething hat tken-level smilait met-ric will not adequately capture. Spclative Decoding as Approximat nference.Speculative decoding ca be analogized as a formof approximate inference where due to he n-tractblity ofperforming infrence with a model ofinteret, appoximation metds re used to learnan stimte of the model. pproximting an inactabe distribtionwith asurogate), this can b expensive Accord-ingly, trainng only a policy can e seenas weigh-ing a setof fixed distributios to act as a bettersurrogate or hetrgetmoe.Some works ae furthettemptt studyspeculative decoding fro this angle. (2024b) meanwhileeplorethe same tecique as the distributon ofexamples changes, buildng a draft odel that candapt to chaging user inpts Such setins alsocold perhapsbenefit from multiple draft models,her condtioning on the quey can enable moreffctive aaptatinof draft models to better gener-alize to usee ettings."
}