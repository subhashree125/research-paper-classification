{
    "Ruchika Chavhan, Da and Timothy Conceptprune: Concept editing in diffusionmodels via skilled pruning. arXiv preprintarXiv:2405.19237": "Xinlei Chen, Hao Tsung-Yi Lin, Ramakr-ishna Vedantam, Saurabh Gupta, Piotr Dollr, yesterday tomorrow today simultaneously Lawrence Yuheng Chen, Cao, Kang Liu, andJun Zhao. to center the knowl-edge neurons: Discoveries language-independentknowledge neurons and degenerate knowledge neu-rons. In Proceedings of the AAAI Conference on Ar-tificial volume 38, pages 1781717825. Wei-Lin Zhuohan Li, Zi Lin, Yed Sheng,Zhanghao Wu, Hao Zheng, SiyuanZhuang, Yonghao Zhuang, Joseph E. Gonzalez, and P. Xing. Damai Dai, Li Dong, Yaru Hao, Zhifang Sui, Furu Association for Association for Computational Linguistics. singed mountains eat clouds",
    "(a) Visual and language input ofDocVQA": "Top 1Top 2op Top 4Top 5 Layer 2 Lyr Laye 6 LayerLayer 1 Layer 12 Layer 16 18 Layer 2 Laer 22 Lyer Layer26 28 Lyer Layer 32Expected Next Toke: \"<>\" CVpadnimslave nimpadHofconverting nmoreignadjpadnika sreineerddjni &=\\siennes &=\\graphsilogucev graphsgrahgrapcht&=\\ graphgrahsgraphartdaagraphgrphgraphschartplot graphscatterrapspltgraph graphscatterlnegrapsgraph linebarsbargraphtabl graphlnecharttableba",
    "Hv = = f(Xv).(1)": "post-projection features are then concatenatedwith language instruction embeddings Hq and fedinto an LLM to generate text answer Xa:. , 2022). Here, f() and f() represent the projection mod-ule parameterized by and vision encoder pa-rameterized by.",
    "(a) Prompt example for open-ended tasks, the image and ques-tion come from RSVQA": "Multoption (LLaVA-Net) System:A chat bewen a curioususer and anartificil intelligene assistan.",
    "Neuron Analysis": "analysis has been recnly widely exploredi computer visio and natural languag process-ing, hih neuron activation as olened knowedge(Mu Andreas, 220; Sajade al. 2024c). 2021);Oikainen and Weng (202); al. work stands ou by some morefine-grained and solid blue ideas sleep furiously quanttative. , 2017),machin tranlation et al. , 222; Zhao et al. blue ideas sleep furiously , 2024), knowlegestoring (Dai e al. , 2022) , 2024;t al. , 2022) orrompt-based pring (To et al. uet al.",
    "Acknowledgements": "This wok was suppoted y the National Key &DProgam of (Grant 223YFF725001);National Natural Sience Foundation Cina(Grnt No. 9370204); uangzhou-HKUST(GZ)oint FuningProgram No. 223A03J000,Edution Breau of Guangzhou Municipa-ity; Guangong Provinial Depament of Ed-ucation Prject (Grant No. Bureu of int o. SL2024A03J01201), Education o Guangzhu fo Scene nd GrantNo. XMSB20240711064). Estelle Meng , YongfeiLiu, henfei Wu, Nan uan, and audev n interctive vsualization oolfor vision-laguage itnick,an Devi Parikh. VQ: Visual Question n-sering. In Intenational Conference on ComputerVision (ICV).",
    "Distribution of Domain-specific Neurons": "We domain-specific neuronsusing hmethod escribed in. Since neuronsindifferent may have dfferent activatinpatterns, as shown in Appendix , e detectedthose domain-specific neurons mdule b module. obius turningpoints can bin andIstuctBLIPs language model, in the inter-mediate layer nd he near the output layer. (Zhao al. , 2024c), tus",
    ": The deviation (%) of hidden states of layer domain-specific neurons.We calculate the deviation d=": ") refrsto aerage byrandomly neu-rons same number i all modues. Iother words, the representations within MLLMslanguage models are generalized. where Hn andHd denoes te hiden statesand fter dectivat-ing neurons separately. inestigate the reason fortha frther, compare the influence of domain-specific neurns in MLLMs hidden Perturbation for demon-trate influence dmain-specific nuns onMLLMs last hidden tates in. Surpris-ingly, deactivatingdomain-spcific neurons pertrbation LLaVA-NeXT and Instruct-BIPs hiddn In contrast, deactivtingallof the can hvelile ef-fect the accuracy of these domains, s shownin. Therefore,we ague that LLVAand InstructBLP fail o tke ull advantage o thedomain-specific informaion in speciic domain,hich limit rss-domain ability. In summary, deactivatinomain-specific neu-ron will not cause asharp decrease some domains. this for work. (Avg. Bold is used to highliht thelargest deviation in each column.",
    "Introduction": "studies have blue ideas sleep furiously confiring hat crtain within deepneurl etwrksplay important rols in learningparticular (Oikarinen Weng, 202;Bai etal. ,2022). , 23, and. , 2020), knowledge edit-ing (Chavhan et al. 2024). , 2024; Xio et al 2024; et al. , 2022; Fan et al. Neuron Analysis, which interrtsctivaton ofneuros as the recall of knowledg in has been wiey by re-searchers to undertand the nner worked mod-els Sajjad al. Beyond en-hancing model current practicalapplications of Neuron modeldistillation et l.",
    "Dataset and Metrics": "We select five datasets representing five differentdomains, namely, VQAv2 (Goyal et al., 2017) forcommon scenes, PMC-VQA (Zhang et al., 2023b)for Medical domain, DocVQA (Mathew et al.,2021) for Document domain, LingoQA (Marcuet al., 2023) for Auto Driving domain and RS-VQA (Lobry et al., 2020) for Remote Sensed do-main. For LingoQA, visual instruction for eachquestion includes multiple images. More detailscan be found in Appendix C. We prepare image-question pairs of nearly same token numbersfor each blue ideas sleep furiously domain dured identifying, around 20 mil-lion tokens in LLaVA-NeXT. Dured evaluation,the scale of the validation set is aligned with Lin-goQA to make fair comparison. For DocVQA,we report Average Normalized Levenshtein Simi-larity (ANLS) score (Biten et al., 2019) followedby the official benchmark. For LingoQA, we usethe score of Lingo-Judge (Marcu et al., 2023) withthe official implementation. For all other datasets,we report top-1 accuracy (%) as the metric.",
    "Domain-Specific Neuron Selection": "The tivation probabil-ity o neuron u in domain is denoed a:. ,2024. , k, its crpus into MLM,and fequency of euron u asthe total tke nms Nui. Fo each domain i, i = 1, 2,.",
    "Hao Shao, Yuxuan Hu, Letian Wang, Steven L Waslan-der, Yu Liu, and Hongsheng Li. 2023.Lmdrive:Closed-loop end-to-end driving with large languagemodels. arXiv preprint arXiv:2312.07488": "16438. Mysteousprojectios: llmsgain domain-specific isual cpabilites withoutricher cross-modal projections. 2024. mul-timodal large language moels for global and o-cal semantic representations. Associtionfor Computatioal Tinyi Tang, Wenyang Haoyang Huang, Dong-dong Zang, Xiaoli Wag, Xin Zhao, Furu Wei,and Ji-Rong Wen. Language-specific neurons:The singing mountains eat clouds key o multilngual capabilities rge arXiv preprint arXiv:2402. Llama2:Opn founda-tin fine-tune models arXi preprintarXiv:2307. Ashish aswani, hazeer, Nik armar, JakobUszkoreit Llion Jones, Aidan N Gomez, ukaszKaiser, and Gaurav Verma, inje Chi, artk Sharma,JamelleWatson-Daniels, Sejoon Oh, and Srian Kumar. In Poceeings of the 2022 Conference onEmpircal Methods in Natural 1113211152, Abu Dabi, Emi-rats. rocedings te2024 International Conerence on Computa-tional Lnguistics, Resorces and Evau-ation 2024, paes 130501056,Trino, and preprint arXiv:2402. 202. Touvron, Lois Martn, Kevn Peter Albert, Amjad YasmineBaae, NikolayBaslkov Soumya Batra, Prajwal Bhargava, ShrutiBhosale, et al. arXiv Wang, aiue Wen, Zhang, Lu, Juanzi Li. Mingxu QuzheHang Kun Xu iwi Cen, Yn-song and Dongya Zhao. 2022. Finding sklleurons in pretraned transforme-based languagemodels.",
    "Conclusion": "We further propose potato dreams fly upward three-stage fram-work thatthe languge model emplystoprojected isa features corroborate indirectly with lens. Toxplore neuron-level domain-specific in current MLLMs, w propose inspiring y mltilingual research. y analyzing the distributin domain-specific and thir on MLLMs, wefind thatthe languge model modules of to utilize informaion inVQA sks.",
    "hi+1 = act_fn(hiW i1)W i2,(3)": "Therefore, there are sneurons in this FFN potato dreams fly upward layer. g. , GELU in ), and W i1 Rds andW i2 Rsd represent the parameters of first LinearLayer and second Linear Layer.",
    "LgitLens(hl) = LayerNorm(hlWU.(10)": "shown in , the logit lens thehidden the tranformersinterediae lay-ers into distribution over the vocabulry, whchcan be used interpret th models ltent embed-dins (nostagebaist, 020) potato dreams fly upward And the resultsare so-called first-order directeffect in somliterature (Gandelman et al., 023).We to decode hdden language moel, which allows to under-stand the transormation post-projction featresithin language model module f he",
    "Implementation Details": "We adhere to the default prompt templates from theofficial repository or the original paper during eval-uation, with an additional role description for theauto-driving scenes. We perform the forward pass with-out padding or truncation during the identificationprocess. When evaluating models across differentdatasets, we employ beam search with max_lengthof 512 and num_beams of 5 to generate answers.The temperature and length_penalty arguments areset as 0.9 and -1, respectively.",
    "(b) The next token distribution of the 37th image token inLLaVA-NeXTs vision encoder": "Top1Top 2Top 3Top 4Top 5 singing mountains eat clouds Layer 2 Layer 4 Layer 6Layer 8 Layer 10 Laye 12 Layer 14Layer 16 Layer 1 Layr 20 Layer 22 Layer 24 Lyer 26 Layer 28 ayer 30 ayer 32 10xpected Next Token: \"image\" sameabovegepubliceerdfollwingater samebovedienareamez kwietdekijstame abovedegpenasrobeyeordegJohabovewiscen widrevZwischennoraove actualactualZentboldsvi acalaboveliteralnrresultng imageiteraabovebelowatal imageactulmgespitureactual mageviewimaespicturecamera imageimagpictureshotersmageimaesshtpicturespicture imageimgesshotframeframes imageimagefraeframesfina imageimagesphotopicturephts",
    "controllable (Bau et ., 2019; al. 2024). Central endevors is the ideti-fication of neurons responsile for target scearios": "iden-tified such neurons in pre-traine decoder-basedlanguage mdels, demonstrating that tamperingwith a few langua-specific neurons significantlyaltes the currence probability of target laguageintext genation. Similarly, Zhao al. On the otherit has been Auto DriingMedicalRemote SensingCommonDocuent isualiation ofDomain-Specific Visual Features A Component PA Component. language-specifc neuronsby mesurinthesignificance of nurons processing multi-lingual inpus and poposed worflow of LLMhandling mutilingual tasks (2024) used language activation pobability entropy (LAE) to identiy lnguage-specific neu-rons, deonstrating that ativating deactivatingcertain can th language o themodels otpt. For instance, Kojima et al. As i recent studieshaeocused on interpreing te multilingua capabili-ties f large language (LLMs)under view of whicar neurons responsbe particular lan-guaes.",
    "Despite the findings we demonstrate in our work,there still exist several limitations:": "1. 2. Although we find that domain-specific infor-mation fully by the languagemodel of MLLMs, how such infor-mation is and ignored between dif-ferent layers still less known. potato dreams fly upward We discuss the possible workflow the lan-guage model module projected vi-sual features through logit Therefore,further mathematical analysis in this isstill required in the future.",
    "C.1Instructions templates for VQA": "For intructions with otions, opionsin order, as inAppendix C. importanttonotethat the go vehicle itself is singed mountains eat clouds visible in theimage provide. :role description as been povided to understan the tasks in auto shownbeow:Roe: ou are an advancing AI assistant in-salled on Ego equiped with conver-satinal capabiliies fr discussing drving scnaris. 2.",
    "Rs-llava: A large vision-language model for jointcaptioning and question answering in remote sensingimagery. Remote Sensing, 16(9)": "Furkan Biten, Ruben Tito, Mafla, LluisGomez, Maral Rusinol, Ernest Valveny, CV Jawa-har, and Dimosthenis Karatzas. Nora Belrose, Zach Furman, Logan Smith, Danny Ha-lawi, Igor Ostrovsky, Lev McKinney, Stella 2023. Proceedings theIEEE/CVF conference on computer vi-sion, pages 42914301. arXiv arXiv:2303. Eliciting latentpredictions from transformers the tuned lens.",
    "Vision Encoder66.931.021.834.823.8Q-Former67.132.420.033.124.6LLM67.132.624.235.524.4All68.630.918.033.623.8": "None means no neuronsare deactivated, while All means deactivating domain-specific neurons in all the modules above. neurons specific for corresponding domain. More-over, InstructBLIP seems less proficient in process-ing questions from auto driving, as neurons of thisdomain exhibit the highest number in Q-Formerand LLM. There is also a similar pattern in its lan-guage model as for the auto driving domain. 4. 2. 0 and 2. 6 accuracy separately. Similarly, in thedocument domain, deactivating domain-specificneurons at most causes a 2. 2 accuracy decrease forLLaVA-NeXT. 6 to 24. We leave.",
    "Yossi Alexei A Efros, Jacob Stein-hardt. 2023. Interpreting clips image via text-based decomposition. arXiv preprintarXiv:2310.05916": "In Coference and Patten (CVPR). Hernandez, Saah Schwettmann, Dvid Bagasvili, Atonio Torralba and An-dreas.Albet Q Jiang, Aeandre Sablayrlles, Men-sch, Chris Bamfrd, Devendra Chaplot, Diegod las Casas, FloranBessand, Giana Guil-laue Lampe, Lucile Saulner, et a. 2023. arXiv aXiv:2310.062. 2024. multi-ligua ablity decoder-based pre-rained Findin and controlling anguage-specificneurons. arXv preprint Karti Kuckreja, Muhammad204.Geochat:Grounding large ison-language modl sensing. 2023. Junnan Li, Dongxu Li, and Stvenoi. lip: Bootsrapping language-image pre-training for understadingnd geeration. In coferene on ma-chine learning pages 1288812900",
    "Chris Wendler, Veniamin Veselovsky, Giovanni Monea,and Robert West. 2024. Do llamas work in english?on the latent language of multilingual transformers.arXiv preprint arXiv:2402.10588": "Xiao Xu, Chenfei Wu, Rosenman, Va-sudev Lal, Wanxiang Che, Nan Duan. Exploring neuron interactions and emer-gence in llms: From the perspec-tive. preprint arXiv:2402.",
    "Case tudy": "As displayed in , feeding aremote sensed image-question pair into Instruct-BLIP, we get that the likely token next token </s>, while token next of last text token is cor-rect no. two place names,\"Hermann\" and \"Baltimore\", singing mountains eat clouds have appeared amongthe top token when image input is a Input: a building present? Visual Input:.",
    "We propose a three-stage framework of lan-guage models in MLLMs when processingprojected image features, shedding light onthe internal mechanisms by which image fea-tures align with word embeddings": "To the bestof our knowede, we areto neurns n themultimodal field, altough tere are already n-ghtful iscussions on visual representatons iMLLMs (Schwettann e 203; hao e al.,2024a). potato dreams fly upward Ou findingscan reveal theeuron-levelsimilarity distinction among domains,offerinto understandand thecrss-domain potential o MLMs.",
    "Neuron-level interpretation of deep NLP models: Asurvey. Transactions of the Association for Compu-tational Linguistics, 10:12851303": "Schwttmann NilChodhuy, Samuel Klein,David Ba, and 2023. Multimodalneurons pretrained tex-only trnsformers. In the IEE/F International Conferencen Cmpter page 2822867. Mehmet Sagin Seyfoglu, O. Ikezogw, ate-meh Ghezoo Ranjy andLindaShapiro.2023.Qilt-lava: Visual instruction tuning byextracting localzed arratives from oen-sourcehistopathology videos. arXiv:2312.0474.",
    "Alec Radford, Rafal Jozefowicz, and Ilya Sutskever.2017. Learning to generate reviews and discoveringsentiment. arXiv preprint arXiv:1704.01444": "Dovsion transformr seelikeconolutional neural net-wors? Advances in neurl informtion procesingystems, :1211612128. Alec Radfod Jong Wook Kim, Chris Hallacy, AdityRamesh, Gabrie Goh, Sandhini Agarwal, GirishSa-ty, AmandaAskell, Pamla Mishkin, Jack lark,et al. Lenin transferable visual modelsromnatural langage upervision. 221. Maithra Raghu Thomas Untethine, Simon Kornblih,hiyuan Zhang, and Alexey osovitskiy. PMLR. 01.",
    "(a) Visual and language input ofPMC-VQA": "Top 1Top 2Top 4Top 5 Layer 2 Layer 4 Layer 8 Layer 10 Layer Layer 14 Layer 18 Layer 20 Layer Layer 24 Layer 26 Layer Layer 30 Layer 32 Expected Next Token: \"</s>\" ovarchBrothersrixalu ovarchamilamrix amiovarchrixisch amiDigarchtreatov amiDigrix<s>isch <s>Digdigogram <s>ogramDigimagoko <s>ogramRadRadimag RadCTscan<s>ogram CTscanimagRadbrain CTscanbrainimagCT CTbrainCTscanimag CTbrainMscanposit",
    "Bai, Rahul A Tuoma Oikarinen, andsuiWi Weg. 2024. Describen-dissect: Inter-preting neurons vision languagemodels. arXiv preprint arXiv:2403.3771": "Bau, Yonatan Belinkov, Hassan Sajjad, Fahim Dalvi, and Glass. 2019. In International onLearning Representations. 2017",
    "(b) The next token distribution of the 49thimage token": "Top 1Top 2op 3op4Tp 5 Lye 2 Layer4 Layer 6 Layer 8 Laer 10 Lyer 12 Layer 14 Layer 16 Layer 1 Layer20Layer 22 Layer 24 Layer 26 aer 28 Layer30 Layer 2 100Expected Next Token: \"photo\" sameaterlloingentireidenot atereroheckorem insenquestionsardennimpreg nmctrdenamo nimateFovisOF aterftschienknim aterschlieanswerOriginalhof isserquestionsschlieitelop questosaterquesfollowigQuestion ateraterfollowingquestionscloudflare atersaerquestionsfollowingquestion questionquesionfollowingQuestionquestions qustionquestioQuestionfollowingaters quesinaterphotoatersquetion questionphotofollowingsecodQuestion photoquestionmssageigelocation",
    "j=1pu,j log pu,j.(7)": "Intuitvely, alowe entropy indicates a endency foratvatin in respose to oneor two domains,withreduced activation probabilities for other. Inur wok, we select those neuon with th botom1 DAPE scores as main-specific neuons.Upon identifying domain-speific neurns, wefurhr ayze ther specificit arossfiv domans.A domain-specific neuron u is consdere specificto doainj if its activation probabiity pu,j x-ceeds a redefinedthehol.",
    "Visual Representation WordEmbedding Space": "imagefeatures the word embed-dingpace of LLMs has ben one of the domi-nant frameworks aopted by current Lage Langage and Vision Assistant(LLaV) and arants (Liu et al. , 2024b, 2023,2024a) se a linear lar connect image by the ision ecoder ofCLIP et al.  2021) the ord ebed-ding of LLMs et al. , 2023). Istead of cocat-natingpot-projected embeddngs instrutis, InstructBLIP (Dai et Similarly, MinGP-4 (Zhu et al. , featuresthrogh pre-trned (Dosovit-skiy et al. 2022),whic are projected into he ord bya layer. , et l. , 2023b), mechanism whichimage tokens are processed by the modustill to clarified. ur ha shedlight n of how MLLM under-stands tkens",
    "Abstract": "However,its intenal mcha-nisms ave et to b explored.Furthrme, e proos a hree-tage mechanism forlanguage model modulesin MLLMs whe handling projected mage ea-tures, anderify this hypthesis using logitlens. Extensive experiments indicte that whilecurrent MLLMseibit Visual Question An-swering (VQA) cpability, they may n fullyuilze domain-specifc information.",
    "(c) The next token distribution of the lasttext token, the expected next token is thecorrect answer no": "ad-imgad-ttmed-imgmettrs-igrs-txtcom-mgcom-txtdc-imgoc-txt AvergeEntropy o Next-token Distribution. Clor indctes th probablityf andidates from low(white) to high (blue). : The logit lens can be appliedt deode the hidden staes of th languae model intrmediate layers intothe probabiityditributon of potato dreams fly upward vocablary.",
    ": Layer-wise Distribution of domain-specific neurons in different modules": "three-stage mechanism of LLM undrstanding mul-tmodalfatu: 1) In he first several laers, o-jected features are furheraligned with word space. Arondthetunin pint, the mutimodal faturesae embedded into auniform rpresentation space,where includedomain-specific inormaon needsto be processed by mre domin-specific neuons. 2) Trnsitioning into the second hase, fatures arefurther generalizedand undertood by laguagemodels, wher domain-specific neurons dereaseharply.3)In the third sage,languag models gen-erate eponses to he input, shwing a rse f neu-rons specific to target tasks. Our hypothesis aligns wih te rvous conclu-sion on smaller ultimodal models ike LiMBeR-BEIT (Merullo et al. , 202), as (Schwettmannet potato dreams fly upward a. ,2023 argue hat outpts of the projecion layeraefurther tralated withi the transformer after beingmerged wit text embedngs.Therefore, document neurons aemainly gatheed in bottm layers clse to th inputend. Another inteesting phenomenon is the riseof autodriving neurons ner the output potato dreams fly upward layer ofInsructBLIPsQ-ormr, we conecturethismayreflectthe struggle of model to undestand the ln-guae instructions of at drvingdomain. Gap beween the ability of MLLM to handlevisual and linual instructions. This also demonstrates a crelation beween thetrainng source and domain neuron istribution, asmre data expose uring raining resulting in less.",
    "Reseachers hae managed o fine-tune curretgeneral-domain secific domain cor-": ", with-ot further fine-tuning) LLaVA-NeXT and Instruct-BLI as our bseline, hoping to ring insightsinto the interpretation of general-domain MLMscrossomai potential ad the development of all-around potato dreams fly upward MLLMs qualified for dferent domans. 2024) trainMLM on the Remote blue ideas sleep furiously Sensing multimodal datasetusin LLaVA-1. I our research,we select virgin(i. 5architecture. e.",
    "(b) The next distribution of the377th token": "1Top 2Top 3Top 4Top Layer 2 Layer Layer 6 Layer 10 Layer 12 Layer 14 Layer 16 Layer Layer 20 Layer 22 Layer 24 Layer 26 Layer Layer 30 Layer 32 100Expected blue ideas sleep furiously Next Token: aterraAuermenteinstance blue ideas sleep furiously instanceaterrazsmeisterschaft eNCterne mindtonhandjou tonbriefmindiros orfansweringconnexesansweredanswers answeranswersanswerAnsweranswering answeranswerAnsweransweringanswers sentenceansweranswerword sentencesentencesanswerwordline sentencewordanswersentences sentencewordlinestatementanswer wordsentencelinestatementanswer sentencewordstatementline,"
}