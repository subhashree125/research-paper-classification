{
    "Nevertheless, humans were able to classify the animals and objects in these videos based on motioninformation alone": "cent advncements incomputer vsion models for motin segmenation enable accurate egmentatio of moving bjetsin natual video based on cobinatio o optica flow estimatin ntworks with donstreamsegmentation etworks (e. g. , ). owever,it emains untestedwhther te models gneralizein similar way as uman perception. Sincethe motion estiation stage is critical fr segmentingming objecs,we focus on testing a broad range of state-of-the-art opical flo ethods ncombination with fixed sementation network. Insad of matcing deep features betwen twofrme, tese modes rely n spatio-tempora filteringin pixel space combined wit a post-processin stge toresolve ambiguitis.We demonstrat thatthi mehanism can be successfuly inegated with dep neural networks for motin segmentationnralitic videos and reaces theperomance o early deeplearnngbasd optcal flow models onthe original, textured ideoswhich is remarkable cniderig at motion energy model wasdeveoped t explain hetuing of idiviual neurons nd has several orders of magnitue fewerparametes than typical opticflow netwrks. Crucially, the motion energy model ubstantillyoutforms all tsted optical flow models in zero-shot generlization to oving ando ots. na direct comparisn with humans in a controlled psychophysicsstud moion energy basedapproachis the ony model that can math hman capability.",
    "E. P. Simoncelli and D. J. Heeger. A model of neuronal responses in visual area MT. VisionResearch, 38(5):743761, March 1998. doi: 10.1016/S0042-6989(97)00183-1": "Solari, M. Chessa, N. doi: 10.106/j.imae.2015.4.006.D. Sun, X. M.-Y. Kautz. CNNs for Flow Using PyramidWarping, and Cost D. Sun, ang, M.-Y.and J. Models Matter, SoTrainig: An of CNNs for Flow Estimation. do: 10.1109/TAMI.2019.294353. Sun, Y-J. Yang, and S. Modeing Human Visual Motion Processingwth Traiabe Motion EnergySensing and Sefattention Netork. In Advances in NeuralInformation Processing Sysems, volume36, 2433524348. M. Tangeann, von Kgelgen, Ghler, and B. Object Learning vi Common Fate. PMLR, April2023. Z. and . Deng. doi: 10.1007/978-3-030-58536524.",
    "B.2Multi-frame optical flow": "The motion model uses of 9 as input, while typicalflowmetosestimate corespndences between only frame. rule out the possibiliy tat te resultsbsrved in our paper maly by yesterday tomorrow today simultaneously te different inpt window we perform anablation studyin which apply opticalflow mehos usng thesame 9 frame wndows. The the eergy and modes terefore canotexplaning by he lengths. Thstaked optical are then as teinputo the segmntation network.",
    "Broder impact": "Th work i interdisciplinar bridging stteof-the-art computer vision segmentaionalgrths with the principles Gestal psychology ad h motion pro-cesing in the bran. of brodr impactinclude dvelopmet of robust and human-like AI systems eductonal and f AI systemsthat are more alged singing mountains eat clouds singing mountains eat clouds with cognition",
    "C.1Comparison of humans and machines by example difficulty": "Flowormer++ (lyinChairs) MA +P (FlyingChirs) PWC-Ne (KITI) GM (Flynghig3D) RAFT (Flyingars) (FlyingThingsD) FlowFormer Sintel) GMA (FlyingChairs) FlowNet2 S (FlingChairs) GMAP-only GM P-oy (lyinghairs (FlyngThigs3D+P-oly (KITTI) GMFlo (1 (Mixed) GM +P AFT (KTTI) (KITTI) GMA +P (KITTI) GMA (MixedGMA +P (Flynghings3D) (Mixed) RAFT (lyingThins3D) G P-only FlowNet2 (FlyngChairs) RAFT+ Sintl) MFlo scale) (FlyinThings3D) PWC-Net (FyinChirs) FowNet2 FlowNt2 (FlingThings3D) GFlow (26 refinement) (Mixed) GMFlow (2 sales) (2 saes, 6 refiements) Flyinghings3D) (2  (Sintel)GMFlow(2 scales) lowet2 (FlyingChairs) FlowNet2 (FlyinChais) GMFlo (2 scales, reements) (KITTI) GMFlow (2 scales) (Mixed) PWC-Net (FlyingThngs3D) FlowNet2 CSS FlyingThings3D). right Psychometric curves humans, the motionnergy based and the or best optical models the task s in8. As ameasure of dificulty,count the number o dots. (left) a task we ount thenuber of informatve dots that allodiscriminting betwenshape alternatives. is f it iscntained intarget nddistractor shpe ut not both (see left). We fittd psychometric curves human articipnt andmodels as a function number he signifit The rest n confirthat only he motioeneryodel is able tomatch te perormnceof hman espcially for smuli amediumnmer of informative dot.",
    "~lcv/MTmodel/": ": (top) Our motion segmentation architectue: The moion estimation predicts multi-sceoptcal fow or motion energy, the segmntatin model predicts th moving yesterday tomorrow today simultaneously forground egion. (bottom right) The egmentation modcombines moion potato dreams fly upward feates acoss scle and redicts a binary segmentatonat the iput resolutio. backgrounds used for datast gneration ar sans of everyday objects andscenes rsulting in hgyrelisticrenderings. For lmodels, we freee the weghts of the motion estimator and only train he downstreamsegmentaionnetwork. A cmmon for binary motinsegmentatn, e usperpixel inary crossentropy to he groud truth masks asloss. All modes are trainedon NVIDIA GeForce RTX28 Ti PUs wit 12GB f VRAM. Dependin on the computationarequiremnts of themotion model, taining the segmentation model o a single GPU takes betwn 2and 6hour.",
    "B.1Importance of components of the motion energy model": "We reoved o replacedindividual lays as described n ad traind the ablated models from scratch ung in thesam way as the bselne model. We yesterday tomorrow today simultaneously condcing additional ablain study in rder singing mountains eat clouds to beerundertand which spects of h mtionenergymdel are essential for generalizaton to random dottimuli. The rslts in hint at noraliation and pooling layer being importan for genelization. When the Gaussianpoling laers areremoved completey, th performanc on orignal vidoeven lihy impovewhile th generalization to random dot stimuli is substantially reducd.",
    "B. K. P. Horn and B. G. Determining optical flow. Artificial Intelligence, doi: 10.1016/0004-3702(81)90024-2": "E. Ilg, N. Mayer, T. M. Dosovitskiy, and Brox. 2. 0: Optical Flow Estimation With Networks. In of IEEE Conference and Pattern Recognition (CVPR), pages 24622470, July 2017. S. Jiang, Li, R. Hartley. Learning To Estimate Hidden MotionsWith Global Motion Aggregation. In Proceedings of IEEE/CVF International Conferenceon Computer Vision (ICCV), pages 97729781, singing mountains eat clouds potato dreams fly upward October",
    "M. Menze, C. Heipke, and A. Geiger. Object Scene Flow. ISPRS Journal of Photogrammetryand Remote Sensing, 140:6076, June 2018. doi: 10.1016/j.isprsjprs.2017.09.013": "Motion From etectontoInterretation. doi:10. Nishmoto, A. . L. Galant.Eprences fro Brain Activity Evoked byNatural Moves. doi:10. 1016/j. cub. 031. Brox. 201. Paszke, S.Gross, F. J. Chanan, Killeen, Z. imelsei, L.E. Yang, Z. Raison, A. Tejani,Si, and S. Chntala. PyTorch n Imperative tyleHigh-Performance Deep Libary.danes in ProcessingSystems,volume 32. Curan Associates, Inc. S. . Ungerleide, and M. Disentangling Category Driven by Dynami Visal Input. Jounlo 43(4):621634,January doi: 10. 2022.",
    "Related Work": "The typical apprach t is using a downstream segmentation modl. Some wrks have compared optical flow human motin percepion howeve the of motion segmnttion. Optcalflo taditionally bee formulated as an ptmzaton prbemwith the goal of finding good betw tw. Several models have eenproposing that build on this principle, iming to eplain the tnng of neurons invisual areas V1 and MT. recently,models that iteratively refie high opticalflow map ad Transormer-based have further iproved tate-of-te-art. Motion Segmentation. Followng works contributed betterdataandproposed coarse-to-fine arcitectures to predict opicl wich lead substantialperormace improvements. One clasic ork computes optical flow and thn clusters te trajectories to segment moved. few excptons , thsemodels hve beenused as motion esimation in context. During recet years, optimizationbased methods have ben suerseded by deep neural networks that frame flow estimation rresion task. this apprach with a thatoptionallyinludes exlicit temporal matching peration. Our is first toenerg model moing oject segmentation. estimatio.",
    "The answer NA means that the paper does not involve crowdsourcing nor research withhuman subjects": "If obtained IRB approval, youshould clearly state this in the paper. We recognize singing mountains eat clouds that the procedures for this may vary institutionsand locations, and expect authors to to the NeurIPS Code of Ethics and for institution.",
    "If applicable, the authors should discuss possible limitations of their approach toaddress problems of privacy and fairness": "While the authors might fea that competehonesty about limitations might be used yreiewes or rejection, a wose might be that reviewers that arent acknwleged the paper. Reviewerswilbe specfially to not penalze",
    "and Disclosure of Funding": "We thankFelix Wichmann, Thomas Klein all other members of the for the singing mountains eat clouds machine comparison study, and Larissa Hfling valuable feedback on themanuscript. The authors thankthe Max Planck Research School for Intelligent Systems for supporting MT.",
    "Limitations": "To allow for comparing a number of motion estimation models with a computationalbudget we made compromises singing mountains eat clouds for aspects. We limited the size of the segmentationnetwork to allow for efficient training but control experiment show using a moresophisticated segmentation network not improve generalization (see supplemental information). singing mountains eat clouds we used the same training for all models but that our setting supports allmodels adequately by visually inspecting the loss",
    "J. L. Mel,and A. Bruhn. Attacking Motion Estimation with Adversarial Sow. InECCV 202 on Adversarial RoustnssReal World,": "1007/978-3-031-20047-2_11. Hamelng, J. Wichman. Painfree accurate Bayesianestimation of pychmetric fnctions (potentially data. doi yesterday tomorrow today simultaneously 10. 2016. 002. X. D Li, M. K. Qin, J. InProceedings of teIEEE/CVFCoference Vision and Pattern ecogniion(CVPR,pages June potato dreams fly upward 203.",
    "B.3Comparison with state-of-the-art motion segmentation": "State-of-the-art motion segmentation singing mountains eat clouds target multi-object inreal world videos and therefore use complex networks. In order verify that theresults in our paper are not caused by using a smaller segmentation network, we evaluated state.",
    "Segmention model": "The parameters f are sared cross thestages, so the network is essentially recurrent neworkthat itegras infmation fom coarsst the finest cale in order predic a. each the refinement CN mton features fromthe current scal the refined from all previousscales nd predcts the for the urrent scale. We se a coarse-to-fine segmentati network t pedict per-pixel logits for the respective pixebeloging to te forgrond bject () tote segmentation the maps or multi-scale opticllow maps predicted bythe models The core of the network is a CNNthat scaes.",
    "Zero-shot evaluation on random dot stimuli": "We apply ll modls using shiftng wndow approach he full lngthbut excluingthefirst andrames so the window is fully contained within the vdeo all",
    "Xie, W. and A. Zisserman. Appearance-Based Refinement Object-Centric MotionSegmentation. arXiv preprint arXiv:2312.11463, August doi: 10.48550/arXiv.2312.11463": "H. Xu, J. Cai, H. Tao. In Proceedings of the IEEE/CVF Conference on Computer Vision and PatternRecognition (CVPR), pages 81218130, June 2022. Zhang, J. Cai, H. Rezatofighi, F. Yu, D. Tao, and A. IEEE Transactions on Pattern Analysis and Machine Intelligence, 45(11):1394113958, November 2023. doi: 10.1109/TPAMI.2023.3298645. D. L. K. Yamins, H. F. Cadieu, E. A. Solomon, D. Seibert, and J. J. doi: 10.1073/pnas.1403112111.",
    "If the contribution is a dataset and/or model, the authors should describe the steps takento make their results reproducible or verifiable": "I general. Fo eample, if the contiution is a noelarchitetre, dscribing architecture fullymight suffice or if contributon is specifi model a empirical evaluation, it maybe ncessaryto either make it possile for others toplicat model with the samedaaet, or rvide cces to the model. For exampe(a) If he contribution i primarily a new algorithm, th paper should ak it clear howt reproduce that agoithm. While NeurIPS does not require releasng code, the onerenceoes equire all submssos to provie som reasonableaven for reproduciblity, wich may depend on thenatureo the contributon. , in te cseof lrge languag model), releaing of a modl chekpont, other mans that areappropriate to the researchperformed. Deending o the cntributio, reprduibility can b acoplishing in various ways. releasing code and data is oftenne good way to accoplish this, but eproducibility can also be provided via detailedinstrucions or how to replicate results, access to a hosted mode (e.",
    "A. Dave, P. and D. Ramanan. Towards Segmenting That Moves. InProceedings of the IEEE/CVF Computer Vision (ICCV) Workshops,October 2019": ". Doerig, R. Seeliger, B. ichard, J. Ismael, G. W. Lindsay, K. P.Kording,T. Konkle, M. A. . an Gerven, N. rieskorte, and T. C. ietzann. Natre Reviews Neuroscience, 24(7):43150, July 2023. di: 10. 1038/s41583-02-00705-w. A. Dosovitskiy, P Il, P. Husser, C.Hazirbas, V. Golkov,P. van der Smagt,D. Brox. FlowNt: Learning Opicl Flow With Convolutional Networs. S. Dziadzio,. Yldz, G. M. van d V, T. Trzcinsk, T. Tuytelaars, and M.",
    "Ablation study": "an study, we evaluating performance motion energy segmentation modelcan be improved by learning the parameters of motion model. different combinationsof in energy CNN are fixed, or trained from and trained themend-to-end with The results in table show that original weights allow for the best random dots. This is remarkable when considering that the weights the energy modelhave been originally selecting explain tuning properties individual neurons, not motion estimation. Some the configurations however outperforming the originalweights on original videos. So while the network architecture allows for generalization inprinciple, all our models by gradient descent converged to performing well training data but did further ablation study, we removing or replaced layers of the motion energy model. resultsin the supplemental information the pooling and normalization layers are for generalization dots. More details and further experiments are providing in thesupplemental information.",
    "Recent flow methods perform strongly on the original FlowFormer++ works beston our dataset with an IoU of 90.8%, closely followed by GMA variant that 89.5%": "The random dot stimuli exhibits the sae motion as orginal video, so theprediction of an idealmotion estiaor would be unhaged optcal low methods however failto proerlyetimatthe moin of the foregro object. e viualze odel predictions iThe object s also clearlyrepesnted i te motion energy m, with some featur maps responding highly t the bckgroundand others to the moving bject. thn each moel, thecckpoints frm the FlingTins3d ataset ten toperform est fo the original videos. The motion energy based model only achieves a performance of 75. Motion enegenealizes much better to random dots. The moon energy n the other handoos hihlysimilar for therandom dot stimuls and the oginal ideo, alowin the motonenergysgmentation to geealize well in this case. 9%IoU ad lags beind sat-of-the-art opticl low models but performs simlar aserlier deep learningbasedoptica flow odels. An interestig xception is MFlow, whichreached n IoU of 8. The motion eergy maps however ted to be noisier thathe ptcalflow predicons which explainsthe lower eformance of motion eergy model for the cleanvideos. The lyinging3d dataset contan rendeings of 3D objectsunergoing rigid moton,s arguably it is te most siila datset compred to oneu n thisstuy. 0 nd PWC-Net predict ahighly nois motion pattern that rougly maches te lcation of the foreround bet, many pticalow estimator fai to detect the foreground motion at all. 0%, hich outperforms he prfomance of the second bst odel by more than20percentagepoints. Striingly, the Fowormer++ and GMA moes thatperformed bes o theriginal vides generalize particularly bad t the random ot stimli (IoU < 10%). While some ethods like lowNet 2.",
    "Optical Flow Models": "0 wasth firt baed model yesterday tomorrow today simultaneously that reche classical, optimization bsing ethds. In evaluate opical flow models. We use flo tht includes all majo learned basing to opticalflow estiatin. We consider three variants of model using differentcombintions of PWC-Net a approach that combinedoperations from clssal approaces as and wapin, componentsfromdeep learnng. owever, this represntation by no-trivial proessing combinemotin information across scals, so that usg this ost to iferior Terefore we use the unmodiied models and sale the final floprediction to the dsired. Differnt from pevious models RAFT is not on a coarse-to-fine approachbut rather on refiement of a high resolution optical flow mapfrom ulti-salecorespondences. GMA AFTarchitecture by inroducing Transformer-basedmodule better hadle occlusions, ave ben to difficlt for previous mdes. Morerecently, GMFlow and Flworer++ have bee as Transfomer-basedarchitectues optical estimation We use th implementations and ceckpoints ts models fro the MMFlow library, excetfr FlowFomer++ an yesterday tomorrow today simultaneously GMFow fo the implementations checkpoint provide bythe respective authors12.",
    "The answer NA means that paper has no while the answer thatthe has limitations, but those are not discussed in the paper": "g. The paper should oint out any strong assumptions ad how robust theresults are potato dreams fly upward oviolatios of the assumptins (e. The atorsshould reflect o ho these assmptions might be vioated in practice and what teimplicaions would be. or example, a faial recogition algorihm ma performpoorly whn image resolutionis low or images aretaken in low lighting. g. The authrs should reflt on te scope o the caims mde, e. The thors shold reflect on he facors that influence the perforaceof the approch. , if the aproach wasonly tested n a yesterday tomorrow today simultaneously fewdatase or witha few runs. indpendence assumpions, noiseless settings,model wel-specification, asymptoticapproximaionsoy holdingloally). Or a spech-to-text systm ight not beused eliably o provide losed captions for online lecturs because it ails ohandletechnical jargon.",
    "Abstract": "Humans excel at deecting and mving bjects according to of common emarkably, previous works have shwn that humanperception generalizes this principlei a zero-sht fashion unseen extures orrandom dots. this work, we seek to better undrstand computational basisfor thi capability b evaluating aradof opial flw models and a neurscience inspiring energy model forsegmentationof potato dreams fly upward stimli. use the extensively valdted motinmodel by Simoncelli and Heeger in 1998 wich is fitted to neuralrecorings in cortex MT.We find thatcross section 40 deep optical flowmodels trained on datasets to estimate motion in randomdot videos, resulted in poofigre-ground rformance. neurocence-inspird significatly outperforms all optica modelon this task For to percption, we coduct asy-chophysical study usng a identfication as a mease humanegmentation perforance. flow models short ofhuman erformane, but only th moion model mathes human capbility.Thi euroscenceinspired modl successfuly the lack of uman-likezero-shot generalization to dot in curret isin modelsand thusa compelling between theestalt of humanobject and motion processing nthe brai.Code, moel ataet are aailable at",
    "C. L. Fenema WB. Thompson.Velocity determination in scene conting sevealmoving objcts. Computer Graphicsand Processin, Apil 1979.": "Zhong,and A. Sitzmann, D. S. D. Kundu, D. Y. J. Oztireli, E. Yi, F. Proceedings of the National Academy Sciences, 93(2):623627, January 1996. Pot, Radwan, D. Meyer,Y. Golemo, C. In Proceedings of the IEEE/CVFConference on Vision and Pattern Recognition June 2022. Simoncelli, and A. Movshon. M. Computational models of cortical visualprocessing. K. doi:. Sajjadi, M. Belletti, L. Rebain, Sabour, M. C.",
    "If the authors answer NA or explain why their has no societalimpact or why the paper does not address impact": "Examples of negative societal impacts include potential malicious or unintended uses(e.g., disinformation, generating fake profiles, surveillance), fairness considerations(e.g., deployment of technologies that could make decisions that unfairly impact specificgroups), privacy considerations, and security considerations. The conference expects that many papers will be foundational research and not tiedto particular applications, let alone deployments. However, if there is a direct path toany negative applications, the authors should point it out. For example, it is legitimateto point out that an improvement in the quality of generative models could be using togenerate deepfakes for disinformation. authors should consider blue ideas sleep furiously possible harms that could arise when the technology isbeing used as intended and functioning correctly, harms that could arise when thetechnology is being used as intending but gives incorrect results, and harms followingfrom (intentional or unintentional) misuse of technology. If there are negative societal impacts, authors could also discuss possible mitigationstrategies (e.g., gated release of models, providing defenses in addition to attacks,mechanisms for monitoring misuse, mechanisms to monitor how system learns fromfeedback over time, improving efficiency and accessibility of ML).",
    ": omparison of using the oriial the origina weights ortraiing scratch (scrach) he layers of the motin energmodel": "Since the shape alernaties were unnown the random dot stiluswas shown, particantshad to potato dreams fly upward nd shap i the random video andit the shape choice afterward. Theduration vieos was 1s at a of 30 Hz. Each trialinvolveda rndom target shape and a ditractor shp from the Sprites dataset Thrandom dot stimulus shows target shape linearly across te enter of wihrandom motion direcion and peed. herefoe, performig well o egmentation of the movin within motion patterns of Shown video random dots, participants have respondwhich f two shapes was peceie the Huans utperformedall optical mdls,but not motio ener basd this task. Due t in diectly evauating the segmentation by humas, weemployed a shape identiicaion task as surogate requiing segmentation (). Overall, we collected datafrom ubjets, of which we ecluded subject due insufficient visual cuity (emaining:=12, 4 femae, 8 male). Among te sbjects here both trained vision scientists and aive Given a rndom dot vdeo, weaplied the respectiv model to the vde selectedoption that prediction s measurd by morerecent flow peform very wellon the vides appear to generalize worse ths task, with GMlo being noteableexception.",
    "Guidelines:": "authors should cite the original paperhat produed the packae or dataset. For scraped data from source (e g. ,website), te copyright and trms ofservice souce shoul beassets ae released, the license,copyright information, and ems in shold be provided. For popular datasets, aperswithcde. com/datasetshas for some datasets.",
    "Discussion": "In computer ision, mdes basing onmathngde featurs btween wo frames have continuously improving erfrmance over the last years andare successully appled in angeof downstrem tasks.Despite these sucesses, our study reveals atriking gp betwee dee opical flow networks and human erception: While hmans generalizethe common fate Gestalt prnciple to zero-shot segmentation of rndom movng ds, the opticalflow models fail to generalize to these stimuli. Futhermore, we show thata cassic moin enrgapproach can be scald to realistic videos while matching humangeneralzation caabilitis. For mon perception, howevr, we show that is posible t combineassical modls frm computational neuroscience withthe scalabilit of eep lanig. Frtherintegation of these modeling traiions is a promisingpath towards imagecomutable modelsfhuman motionperception. umans still greaty ouperform machines in terms of robustness and efficiency. Our studysuggests a substanial ntanglementof motion estimation with appearance in DNNs,which might also b liked to te lack of robustness observed i state-f-the-rt mtion estiators. Computional princilesthat bettermatch human vision should be considering as promisingcandiates or addresed these issues. Finall, weague hat dep learninbasd models as presented i our work have the ptential togreatly improve u understanding of motion perception inhumans. Lowlevl menims formotion estimatio and hiher level processs for motion interprettion havebeen mostly stdiedin isolation. In our work we follow a ore holisti approach by studying the ffects motiondetection mechanisms on the pereption of movig objcts, which offer several unique opportunities. Firs, it is not neesaryfor most downstream tasksto perfectly estimat the physically correctmotion Second, studyin end-to-end models o motionestimation and interpretation advances ourundrtading of how neural mechanisms give rise to behavior. While scalingrakably ell, theorinal motionenergy modelis notale to match the perfrmace f stat--the-art optical flowmethods on natural scenes. How humanslearn eneraizable motion perceptionfom data, to which degree tis capabilityis innate,are importantuestions for future resarch. Filly, th spiri of neuroonnctionist rsearch progrmme we seeour model as anexcutabe hypothesis fr motion pereptionin the hman brain.Further evaluatin andextending odels of moion perception toapture a divese range ofphenomena is an excited path towadsa holistic understandin of humanperceptio.",
    "We demonstrate that a classical neuroscience can be successfully integrated with networks generalizes random dot stimuli": "We conduct apsychopsical expeimentt directly ompare ando dot motio segmna-tion in umans and machines. While state-of-the-art optical flow models fal sortof humnerormace, te motionenergy moel can mah it Integrting this mechanism wit state-of-the-art optal flow methods potato dreams fly upward i prmied path owards morerobst motion estimation modls."
}