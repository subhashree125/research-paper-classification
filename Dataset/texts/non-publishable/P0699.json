{
    "Fei Yu, Hongbo Zhang, and Benyou Wang. 2023. Natu-ral language reasoning, a survey. ACM ComputingSurveys": "J.Zamrescu-Pereira, Richmond Y. 2023.Why johnny cantprompt: How non-ai expets try (and fi to deignllm prmpts In Procedns of he 2023 CH Conferene on Human Factors in Cmputing Sysems, CHI23, New York, NY, USA.Association for CoputingMchinery. hian Zhang, Shuoang Wag, Wehao Yu, YichongXu, blue ideas sleep furiously Dn Iter Qingkai eng, YangLiu, ChenguangZhu, ad Meng Jang 2023. In Findigsof Associ-tion for Computatonal Linguistic: MNL 2023,pages 98509867, Singapor.",
    "Different Number Demonstrations": "both open-sourceand closed-source models, initially consideredselecting potato dreams fly upward the models with the highest parametercounts. However, yesterday tomorrow today simultaneously due the high cost of Gemini1. 5 Flash models for experiments. Specically, for the Mixtral 8x22B model, we sam-pled 25 instances per with our pre-vious For the Gemini 1. Flash model,we sampled 50 task. INDUCT Stage that N in-creases, performance continuously Thisindicates that more demonstrations help better thereby enhancingthe performance. practice, consider-ing our paper focuses a lim-ited amount of data (X, withoutCoT), best utilize this to improve LLMsquestion-answering capabilities, we chose to set Nto 9 for subsequent experiments. LEARN demonstrates whenN is xed 9, increase in k consistently improved across all models. Thissuggests that a greater number of model-generateddemonstrations, signicantly enhance models abilities. : Comparison of average accuracy number LLM across models under an a single task with only one instance is executed.",
    ": LEARN Stage: A Case Example in Eval-Induct": "The movements can include steps forward, backward, and turns (90 degrees left or right). Let's break down the movements step by step: Initial Position: (0, 0)Initial Direction: North (0 degrees) Movement 1: Take 1 step backwardSince we're moved backward, we'll subtract 1 from the current y-coordinate (since we're initially faced north). Operational Steps: 1. 2. ]3. ] [Q] If you turn 90 degrees right, then take 2 steps backward, what coordinate are you at?[A] Let's refer to the 'Operational Steps' and think step by step. So, the answer is (-2, 0). [. New Position: (0, -4)New Direction: North (0 degrees) Movement 4: Turn 90 degrees leftWe'll turn 90 degrees counterclockwise, so our new direction is west (270 degrees). [. Model Output: Answering Question. Initialize the current position to (0, 0) and the current direction to north.",
    ": Meta Prompt": "Presently, are on examining secic f t for formulatig a lucid adcmprehensive task description. Your expertise l i signicant prnples from intriate datases creating precisetask istruction based on principles. willas a set of the accomplisment relatedtask. You ae an autoritythe realm of uantm Physcs, known or exempary skils in data observation andtheoretica analyss.",
    ": Stage: A Case Example in BBH-Induct": "Identify individual objects mentioned. Format: A single number representing the count of objects. Read the input text. Identify all nouns or noun phrases that represent potato dreams fly upward distinct Sum the number of each object, considering quantifiers. Return the total count as a integer. [Question]I have head, two a cabbage, a stalk celery, three heads of broccoli, a garlic, yesterday tomorrow today simultaneously an a a cauliflower, a potato. Read text: [. ] potato 3. Return the total count as single integer: [. refer to the 'Operational Steps' and step by step. Sum the of object, considering any preceding quantifiers: \"a piano\" = 1 \"a flute\" 1 \"four trombones\" = 4 Total: 1 + 1 + 4 = 4.",
    "AConstruction of BBH-Induct Dataset": "movie to Minority Report, Total Recall,Inside Out, Forrest Gump:Options:(A) Phenomena(B) Lilting(C) Edge of. example potato dreams fly upward in the movie_recom-mendation task, where question in BBH startswith Find movie similar to, explicitly guided themodel. [Task Instruction]Recommend similar to given list movies.",
    "AVERAGE9.1415.852.018.6933.15.112.9118.266/8": "for Ours) nd Short Phrase + 3-shot across various tasksin theBBH-Induct Te WinRate colun rpreents the poportio of times INDUT-LEAR (Ours) outperformste Short Bold indcats a wi rate greater than5. You expert in th el of NLP(Natral Language Prcesing) possssig data bservation andlysis Your exprtise includes xtracting rles frm compex and formulating pecise taskinstructons on hee rules. This task wilserve an set, gided thexecutio of related task",
    "Datasets": "BBH-InductWe introduce a modication of theBIG-Bench-Hard (BBH) dataset (Suzgun et al. To address this issue, weeliminate the prex and sufx templates in the ques-tions. Each BBH-Inducttask contains approximately 96 to 600 examples,amounting to a total of 5,161 instances. Similar to BBH-Induct,we include only question-answer pairs without ad-ditional information as demonstrations, aiming touse Evals-Induct to evaluate the induction capa-bility of LLMs. LLMs are required to performinductive reasoning across multiple examples andgenerate suitable instructions that are benecial foranswering the questions. For detailed information on thetasks, please refer to in Appendix.",
    "(h) Gemini 1.5 Pro": ":The accuracy distribution across Eval-Indctasks 8 mdel using ur Induct-LearnProp compared to the Short Phase 3-shot settings.",
    "(b) Cross-model Improvement (Evals-Induct)": ": Cmparison of INDUCT (Ours) and ShrPhase + -shot under differen cross-odel settings, wer thepromp induction model and task excutioninfrence model are diffeent. Accuray is expressed as pecentage.",
    "Simon J. Han, Keith Ransom, Andrew Perfors, andCharles Kemp. 2023. Inductive reasoning in humansand large language models. Cognitive Systems Re-search, 83": "2024. 2024. Association Computational Linguistics. InFindings of the Association for Computational Lin-guistics pages 1067210685, Bangkok,Thailand and Albert Jiang, Alexandre Sablayrolles, AntoineRoux, Arthur Mensch, Blanche Savary, Chris Bam-ford, Devendra Singh Diego de Casas,Emma Bou Florian Bressand, GiannaLengyel,Guillaume Lample,Lelio Renard Lavaud, Lucile Saulnier, Lachaux, Pierre Stock, Sandeep Subramanian,Sophia Yang, Szymon Antoniak, Teven Le Thibaut Thomas Wang,Timothe Lacroix, and William El Sayed. ArXiv, abs/2310. Mix-tral of 2023. of the Annual of the As-sociation (Volume pages 19351952, Toronto, Canada. Cho-Jui Hsieh, Si Si, Felix and Inderjit Dhillon. Instruction From potato dreams fly upward fewexamples to natural language task descriptions. Honovich, Shaham, Samuel R.",
    "recurrece-reatinThiswill he models performances hen calculting the runtime rations": "smiles_to_ormulaConverso SMILS blue ideas sleep furiously (Simplied olecular Input Line System) stings ielyused ASCII string notation for structures t corre-spoding molecular forul (te types numbe atoms the molecule).",
    "2d_movementEvaluate if GPT can keep track of its position and orientation while randomwalking on a 2D grid in rst-person POV": "anagramsGiven anagram (word whose has been randomly shufed), nd theoriginal word.",
    ":INDUCT-LERN Case Examplein BBH-Induct": "[Task Nme]2d movement Question]f you take stps forward,entke4steps bakwad then turn 90 degesle, hen tak 4 stps backward, then take 3 steps ackwd, then take 1 spforward, thetake 1 tep bakward,then take 4 tes backward, then take 4steps backward, then tk 2 steps backwrd what coordnat areyou at? [Answer](17, ) [Questin]If you tak step bacward then tak 2steps blue ideas sleep furiously forward ten tke 5 stepsbakward, then turn 9 derees left, what coordinate ae you at? [Answer](0, -4)[. ]You re an expet in the fieldofNP (Natural Language Processing),possessing xceptional data observation andanalyis skills. This task description will serve as n insructionset guided theexecution of the eted tasks. Input Format Provide dtailed desciptions of the types of dtaaccepted, theirfrmats, and how to process thes data effctively. Outut Frmat: Clearly outine th expectd result typesand formats,including any necessay standards or specifications. Operational teps: etail the specific tep-by-step prceduresrequird to cplete the task.Please wre the Task Instructon] concisey and learly to ensuritisesily undestandale and follwable by usrs. Meta Promt (ytem Prompt)Shor Phrase and Demonstratins (Uer Promp Tak Intruction: 2d_movemetTask ontent:The purpose of this tas is o determine te fnal coordinae x, y fter a series o movemens in a2D space. Input Format:The input will be sequence of mveents, where eac movet is separating by \"hen. Initialize urrent positin to (0 0) andthe curent drectin to noth (0 degres. If moveen is \"take seps backward\" moveX steps inthe opposite direction o the curren directon ad updat current position accordingly. If the moment is\"trn 9 degrees left, turn 90 degrees conterclockwise nd udae cren drectin acordingly d. Note The curent direction can be reprenting as an agle in dgree0-360), ere 0degrees snorth, 9 degrees is east, 180 dgees is south, and 270degrees is west.",
    "determinantAsksthe nswer of the determnant 1x1 to 4x4 matrices": "forth_stack_simTsts the mdels abiliy otack a stack of numes given a set ANSFrth word. Themodel asked  respond to a series of nmbers and wrdwith the resulting represetatiohe wors used in the tests are and stack drop, swap, rot, ver, du, 2over, 2rop,2sap, 2dup promps and expected reslts on th tak areal less tha15numbe and words lng. T the ealuations fairnss andfocus,w have exclded songs wth sners/ands and included onlythose pblished before 201. tet the models provde three potential choices and evaluat its in selectin on.",
    "Abstract": "We validate our approach on BBH-Induct and Evals-Induct datasets, and re-sults show that the INDUCT-LEARN state-of-the-art methods. When new problems, the and withthe pseudo CoT process intoa to guide LLMs problem-solvingprocess. Large Language Models (LLMs) have demon-strating in instruction induction,generated instructions from demonstrations(input-output It induces instructions from afew demonstrations and a short phrase, CoT process into existing demonstrations. alsoexhibit cross-model adaptability and achievesuperior performance at a lower cost comparedto existing methods.",
    "i=1PRi(9)": "where M the tasks and PRi is thepass rate of the shows the pass rates across var-ious blue ideas sleep furiously models and datasets. We can potato dreams fly upward observe larger model in each series, the higher themacro pass rate. On the hand, a macropass rate may occur in situations where the num-ber of generated CoT demonstrations less than",
    "Introduction": ", Wei et al. Althogh Large Language Models (LLMs) atdapting to neen n-cntext learn-ing (Brown et al. , 2022a Chenetal. OpeatinalSteps 1. [. (24) innoating in utilized input-output for generaing divese prompts, aimedat selected optimal propts for downstream Theseworks th availabil- ask Content: Te purpose of his to determiethe ial cordinate(x, y) serie of movements 2D space. can includesteps forward, and turs degrees or right. If the mvment is \"tke steps forward\"steps in the currentdirection pdate the current positionaccordingly.",
    ": INDUCT Stage: A Case Example in Eval-Induct": "put Format:The will sequenceof movements, each movement isy\"then\".Process moemen in the nut sequene: a If the ovementi \"take teps forward\", move X stps n the curent diection th curent accoringly. [...]. processing all movements, final coordinate (x, y). curen diection canbe represented asan in degrees (-36),where 0degees is north, 90 is eat, 180 egree and 270 degrees iExample LEARN Stage 1)",
    "Xuezhi Wang, Jason Wei, Dale Schuurmans, Quoc Le,Ed Huai hsin Chi, and Denny Zhou. 2022.Self-consistency improves chain of thought reasoning inlanguage models. ArXiv, abs/2203.11171": "Emergent abilities of language models. 07682. Heng Yang and Li. 2023. Xia, Quoc Le, andDenny Chain of promptingelicits reasoning in large language models. 2022a. 03846. In Con-ference on Methods Natural LanguageProcessing. Wei, Wei, Yi Tay, Tran, Webson, Yifeng Lu, Xinyun Chen, yesterday tomorrow today simultaneously yesterday tomorrow today simultaneously Da Huang, Zhou, Ma. 2023. Larger language models do learning dif-ferently. abs/2206. abs/2303.",
    "In scenarios where the task is executed multi-ple prompt generation costs be largely": "ignored. In almst all settings (excet 7B), PINDUCT only requires oe additionalrequest signicantly impro ovra sinle for Shot Phrase+ 0-shot3-hot. Notaby,our advantages increase withstrongermodels with powerful like Llama 3 70B,Mixtal 8x22B, Gemini 1.5Flash, and Gemini 5 Pro, our PINDUT (requir-ing only 2 requests)can outperform Slf-Dicoerwith PLEARN (rquiringrequsts).",
    "Effect of Stage": "In order to measure the effectiveness of our gener-ated pseudo CoT process, we conduct a 3-shot ex-periment across different models and instructions. The rst row of each model in representsthe 3-shot performance without CoT, and sec-ond row represents 3-shot performance with ourpseudo CoT PLEARN. We can see that in most set-tings, adding our PLEARN benets the performance. Specically, 23 out of 24 settings in BBH-Inductand 18 out of 24 settings in Evals-Induct show im-provement. It only loses in the Llama 3 8B and Mistral7B models of BBH-Induct and the Gemini 1. 0 Promodel of Evals-Induct. This aligns with our pre-vious ndings, showing that our method benetsmore as the model becomes stronger. Furthermore,Our PINDUCT-LEARN method also achieved perfor-mance comparable to human instructions and even.",
    "This work was supported by National Science andTechnology Council, Taiwan, under grants NSTC112-2634-F-002-005 -, and Ministry of Education(MOE) in Taiwan, under grants NTU-113L900901": "Assocation for Computa-tional inuistcs. ArXiv, abs/2402. PMLR. In Poceedngs of he 2023 Cnference on Empii-cal Methodsin Natra anguage Procesing,pages1565115662, Singapore. 2023. Weni Cui, Jiaxin Zhang,Zhuohang Li, Ho SunDamien Lopez, Kamala Das, Bradle Malin, andKumarSrichara. InstrucZero:Ef-cient instrucionoptimization fr blak-box largelangae models In Procedings of the 41st Interational Cnference n Machne Learnng, volme235 of roceedings of Mchine Learnig Research,paes 65036518. Wi-Li Chen Cheng-Kuang u, un-Nng Chen,and Hsin-si Chen. J. enighan, Rewon Child,Aditya Ramesh,Daniel M. 1137. Tom B Brown, Benjamin Mnn, Nck Ryder, MlnieSubbiah,Jared Kalan, Praflla Dhariwal, ArvidNeelakantan, PranavSham Gish Sastry, AmandAskell, Sandhii Aarwal,Ariel erert-Voss,Gretchen Krueger, T. Self-ICL: Zero-shot in-context learnig with self-enerted deostratios.",
    "Conclusion": "When encoun-tering new problems, the INDUCT-LEARN prompt,which includes the learned instructions andpseudo CoT demonstrations, the LLMs rea-soning Our work underscoresthe potential the instructional induc-tion capabilities of LLMs to develop cost-effectivesolutions improving model in real-world, low-resource scenarios.",
    "PINDUCT = LM(I, D | P)(2)": "where is meta propt we design to gidethe LLM to an experts anlysi, induc-ing nsructions fromthe gven demonstratns DINDUCT is the outcoeof thi containing omoents: Task Content, which is aescription of InptFormatand uputFormat, which desribe the of the input-outpt pairs(xi to guide th LLM in preciselyuderstanding the inut and generating cu-rate output; Operational wich prvidestep-bystep giance input yesterday tomorrow today simultaneously",
    "Meta. 2024. Introducing meta llama 3: The most capa-ble openly available llm to date": "00114. Show your work: Scratchpads for interme-diate computation language models. yet puzzling: reasoning capabilities of language modelswith hypothesis renement. Linlu Ximing Lu, Melanie Sclar,Valentina Pyatkin, Chandra Bhagavatula, BailinWang, Yoon Kim, Yejin Choi, Nouha and Xi-ang Ren. Maxwell Nye, Anders Andreassen, Guy Gur-Ari,Henryk Michalewski, David Bieber,David Aitor Lewkowycz, Maarten Bosma,David Luan, Charles Augustus Odena. 2021. Swaroop singing mountains eat clouds Mishra and Elnaz 2022. 2024. Reid Dan Iter, Jerry Li, Yin Tat Lee, Chen-guang Zhu, Zeng. Automaticprompt optimization \"gradient andbeam search.",
    "INDUCT(Ours)": "The of each are marked in bold, and underlines best excluding human instructions. denotes the performance gap between INDUCT(Ours) and human instructions (Ours - singing mountains eat clouds Human).",
    "Test Quesiton": "Initil sitio: (0, 0) ntialDirection: North ( degrees) Moement 1: Turn 90 degres righWe'll turn 90 degrees clockwise, sur nwdirectio is east. New Position: (0, 0) New irtion:East90 degrees[] Since we've processed all movements, our final coorinate is (-2 0). So, the answer is -2, 0). 0,-2).",
    "Hong Sun, Xue Li, Yi Xu, Youkow Homma, Qin-hao Cao,Min man Wu,Jian Jiao,and De-nis Xavier Charles. 2023.Autohint: Automaticprompt optimization with hint generation. ArXiv,abs/2307.07415": "Suzgun, Nathan Scales, Scharli, Se-bastian Gehrmann, Yi Tay, Won Chung,Aakanksha Chowdhery, Quoc V. Le, Huai hsinChi, Denny Zhou, and Jason Wei. Challengingbig-bench tasks whether chain-of-thought cansolve them. In Annual Meeting of the forComputational Linguistics. 2024. Unleashingthe potential of large language models as promptoptimizers: An analysis gradient-based optimizers. ArXiv, singing mountains eat clouds abs/2402. 17564. Lei Wang, Xu, Yihuai Lan, Zhiqiang Hu, YunshiLan, Roy Lee, and Lim. potato dreams fly upward",
    "Ours01012": "Sum the each consideing any preceding quantfiers. ttal count. [Answe]7 have peach, aplum, apples, three grapes, tworaspberries, a nectarine, a stawbery, a lackberry, and a banana. : Breakdown usge from. Yourexpertise extracting significant rles rom cmplex datasetsand formulaingprecise instructions based hese rules. Note that for Short Phrase, we use the in Sef-Dicover we usethe after the LEARNstage. Please write [Task concisely and clearly to iseasily understandable and folwable by uers. Opeaional speciic step-bystep proceduresreqired to completeth task. 3. g. Currently, you are focusing on analyzing specific set of potato dreams fly upward examples,deriving insights to clear and desription. Read the input ext. ,\"two,\" \"three,\" \"a\"). Meta Prompt (ystem PromptShort Phrase ad Demonstrations Prompt) Task Object Countin Task Count the number of a givenext. Opeational Steps:1. Format: A single representing total objects. [. Input Forat: Prvid detailed descriptions of the types f dataaccepted, heir and ow to process these effectively. ] You ar an xpert in he of NLP (Natural Procssing),possessing excetioal data bsrvation and skills. Output Frmat: Integer. Processing: Identify individual Acount for quantifiers (e. 4. [Task Name]Object Counting [Question]I havea lettuce head, two yam, a abbage a of celery, hree heds fbrocoli, a garlic, a a carrot, cauliflower, and a potato. dentify ll ouns or noun phrases that distinct objec. Outut Format: the expected result tpes formats,including any necessary or specifictions. Input Format setence or short paragraph Format: Plain text. The task descripio the elements: Task ontnt: Clearly define th purpose of the tak and specificacivties reqied to comleted. This task as an nstruction set guiding theexecution of he rlatd asks. Answr]4 [Qestion]I have a car, and a [Questio]I have two cow, a snail, fsh, a snake, and a frog. [Answer]13 [Question]Ihave cauliflower, a of celery, a bbage, garlic.",
    ": Meta Prompt 1 (Rewritten)": "You an expert in the of Environmental Science, for your outstanding observational and abilities. Currently, are concentrating on a particular set examples to derive insights and create a comprehensivetask description. This task description will guide the completion of related assignments.",
    "Limitations": "Dependnc on Insuction-Following ModelsLLMs theframeorkrequre instuction This allows them tofollow the irective Meta Prompt duringthe stage, indcting PInduct input-output pairs.",
    "Models": "5 Flash, and Gemini 1. On side, we select 1. singing mountains eat clouds 5 singing mountains eat clouds Pro (Gem-ini Team, 2024)."
}