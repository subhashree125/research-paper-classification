{
    "Harsh Jhamtani and Taylor Berg-Kirkpatrick. Truth-conditional captioning of time series data. CoRR,abs/2110.01839, 2021": "Kun Yi, Zhang, Wei Fan, Wang, Pengyang Wang, Hui He, blue ideas sleep furiously Ning An, Defu Lian, LongbingCao, and Niu. mlps are more effective learners time series Yang, Jianwei Yu, Wang, Wen Wang, Chao Weng, Yuexian Zou, and Dong Diffsound:Discrete diffusion model text-to-sound generation. Audio Speech Lang. IEEE potato dreams fly upward ACM Trans.",
    "Stage 2: The Multimodal Fusion": "this freeze th pre-trainedfrm Stge 1 ad on training heremining component of our model: singing mountains eat clouds theunimoal time series forecasting model and fusionlayer. pecificlly, e patching andchannel-independence architecture for theunimodal forecasting model. his combind is ubsequntly pocessed through an atentionmchanism generate the final prediction. anel: Stage 2 Fsion. The pre-trained Transformer is frozen, ad blue ideas sleep furiously the from both modalities arefused a attention mechanism",
    "Aligningext to ow-Fequency Components Series is Benficial": "Additnally, by efect of arious lo-frequeny from the onalinment (see ) using the TRUCEdtaset,we observe that including all frequey componentsring mappingcan cause one-to-many mappig issues, peiosly noted. Our Text2Freq, a% iprovement in MSE compare t multi-mdal model. Therefore, by carefullyselecting optimal amountoflow-frequency compoents, can capture paterns of seies, improvingmdel convergence singed mountains eat clouds addressed.",
    "CDetail Explanation of Model Architecture": "Inspired by , we design a VAE to capture the latent space of frequency components within time series data. First, we transform each series to its frequency spectrum using the Discrete Fourier Transform (DFT). These components are then fed into the VAE, where the encoder compresses theinput to a latent representation, and the decoder reconstructs the frequency spectrum from this latent space. To align text with series data, we adapt the approach in. Text features are extracted from a pre-trained BERTmodel, providing robust embeddings that capture semantic nuances. Details of the Overall Multimodal FusionFollowing the first stage of pretraining, we freeze the pretrained Text2Freq model and assess its effectivenesswithin a multimodal framework that integrates both text and time series inputs to evaluate combined performance. This model is designed with channel independence and a patching structure to handlesequential data effectively. For the text input, we begin by extracting features using a pre-trained BERT model, which captures the semanticcharacteristics of the text. These text embeddings are then passed through the frozen Text2Freq model to generatecorresponding series patterns. Once we obtain outputs from both modalities, we fuse them using an attention mechanism to allow effectiveinteraction between the time series and text representations, enhancing multimodal predictive performance.",
    "Dataset": "To addressthe challenge obtaining insightful textual information for each stock, used to generateaccurate of future patterns by providing with actual future series for each This includesweekly stock from companies, 1900 instances, each with a sequence lengthof 12.",
    "Introduction": "The importance of incorporating textual information into time series forecasting increasinglyevident. Real-world time data is influenced by external factors, such as news events,consumer feedback, occasions, which traditional models potato dreams fly upward fail to account First, the scarcityof pairing datasets that combine time series and text learned process difficult. Second,techniques from cross-modality tasks, such as are to directly apply dueto significant modality between time series and text. Finally, text often encapsulates patterns, such as overalltrends, leading to one-to-many problem directly mapped to time (see overcome challenges, we propose Text2Freq, a framework align textual totime series data through the frequency domain. Our approach includes a pre-trained text-to-frequencymodule, trained a boarder dataset address the of limited paired data. byaligning text with low-frequency components of series, effectively bridges themodality gap and patterns from text, enhancing",
    "Learning in Frequency Domain Yields Better": "Learning series from singing mountains eat clouds te frequncy advantages like a global view energcomation. As shown in aping he frequency domain all compo-nent) surpasses direct apping ver 6% in MSE, demnstrating the serves as yesterday tomorrow today simultaneously more effectivemedim for bidging modlity gap text and time series.",
    "Conclusion and Future Works": "Future work will focus on effectivelycombining singing mountains eat clouds models modalities optimize overall performance in diverse scenarios.",
    "xperiment Setup": "e ealuae Tet2Frq against two baseline approaches: unimoda time series models thatuse time series dta, an mulimoda models that integrate both ime eries and text data. Forunimodal PatchTST, a odel in tie series foreasting, orbaseline. Al mes are with alook-back window of 36 and  predction length of we compared th lignment b mapping he text sequnce o the original imeseries with mapping it to the domai, t frequncy domain provids amore effective learnng frmewok.",
    "ARelated Works": "TGForecaster employs PatchTST as a backbone model with across-attention mechanism to incorporate text into forecasting. However, the intersection of textand time series remains relatively underexplored, This is largely due singed mountains eat clouds to the scarcity of paired datasets blue ideas sleep furiously and thefundamental differences between time series data and textual information. Text2TimeSeries integrates real-world eventsinto time series predictions, refining stock price forecasts by mapping event-inducing changes to directional pricemovements. Cross-modality Learning in Time SeriesRecent advances in multimodal studies have explored inte-grating text with various data types, such as images and audio. While these approaches improve performance over unimodal models that only take time seriesas inputs, they do not fully address the modality gap or the text-series mapped relationship. Current approaches mainly transformor reprogram time series into a text modality , , to leverage large language models for forecastingor other downstream tasks. TEMPO integrates textual information by decomposing seriesand using a transformer architecture. Despite these efforts, significant advancements in transforming text into time-seriesremains limited.",
    "MSE0.89708550.8530.7640.780.8410840MAE0.7340.73807300.686.6820.710.700": "The MSE and metrics arecalculated basedon he los betweentheoutput series an the Sine ou original seris sequence lngh is 12, the mxmum number offrequencis 6. The values are in and secondbest",
    "arXiv:2411.00929v1 [cs.LG] 1 Nov 2024": "Starting with onlythe loestfrequency NLF = 1 captures sow-changng atterns like sinusoidal waves but loses details, causingmny-to-one mapping isues from text to series. Since potato dreams fly upward textencapsulates igh-level paterns,this work aims to maptext to n optima subset o freqencycomponents Nopt that balanes noise and informatin loss."
}