{
    "Many quantities that arise in machine learning have been associated with the ideas of aleatoric andepistemic uncertainty. We set out to provide a clear synthesis of some key concepts": "Here we focus on models. are generally distinct data-generating processesSince we can have di X Y,the link between and ptrain(d1:n) weak. di X Y and di it can still be case thatpn(y|x) all n due model & van der Vaart, systems allow evaluationComputed model-based uncertainties is not gen-eral evaluating a model using a reference system, such as a person, physical sensor orcomputer program. We use p(y|x) todenote model we to n , we assume is dened. It is common to assume di X Y. Whilenot for many of the quantities we consider, there be parameters, pn() =p(; d1:n), within the model, dened such that = Epn()[p(y|x, )]. Often system performs the same predictive task the model, and we canformalise as a comparison between the model and the reference system, peval(y|x), on aninput, If x is considered to be some this commonly rise expectedlosses of the Epeval(x,y)[(pn(y|x), y)], often estimating sampling (x, y) peval(x, y). with the predictive task of interestWe consider prediction wherex X an input y Y is allow x = = setup covers a range ofscenarios, from predicting the a (X = and Y ) to predicting the word in (X = and Y = V where is vocabulary and l is the number of words so far). Training need not correspond directly to the predictionTypically have to data, d1:n that can inform prediction. Suppose d1:n represents outcomes of nfair coin tosses and the task is to predict the coins bias, so = and Y = Then as n the predictive entropy H[pn(y|x)], can tend to while H[ptrain(d1:n)] = 2tends innity. We that this is The data belong in some altogether separate Using a allows predictionIn machine learning we work from data topredictions through model, pn(y|x) = p(y|x; d1:n).",
    "Related wrk": "A erspectives aleatoric and epistemic uncertainty in machine earning havebeen ut in recent years. These includeof where uncertinty comes froin machine leaning (Gue et al, a case againstShannon entropy fo notions of redic-tive ncertaity (Wimer et 2023); roposls or lternatie inormation-theoretic quan-tities (Schweihofe et al, 2023ab, various suggestions how to ene uncer-tainty, as in of freqentist risk al, 2023), class-wise riance (Sae et al 2023b,2024b), credal sets(Hofman et al, 2024a; Sae et al, 2023a), distances beteen probabilitdistrib-tons (Sale etal, 2024a) poper coring rules (Hofman et al,.",
    ".(1)": "Aleatoric and epistemic uncertainty as discussed in this work refer to multiple quantities (),introducing a number of spurious associations. Kendall & Gal (2017) expanded on these ideas in a computer-vision context.",
    "(b) H[pn(y|x)] )]], the BALD score evaluated at x. Issue: for n the BALDscore is only an H[p(y|x)] (Proposition 2)": "in Gal (2016) inKendall & Gal (2017)) and singing mountains eat clouds varying distance from trained data uncertainty does notincrease for examples. 11-6. sources of in this view on aleatoric and epistemic uncertainty blue ideas sleep furiously incorrectassociation models subjective uncertainty and objective measures performance, such asclassication accuracy in Kendall Gal (2017)), with misleading implications abouthow models uncertainty will behave with varying n (.",
    "Conclusion": "But dependencies things, such as what the data and what is used tolearn from the data. We have sources of confusion in the aleatoric-epistemic uncertainty in machinelearning and, to deal with this, we presented an perspective. Our presentation ofthe makes transparent the dependence on the model class and the amount of data. A key fact work is the extent the subjectivity of we have discussed.",
    "Background": "use of aleatoric and n machine learning a historyuse in theengieein literature Special of Rliability Engineering and Syste Sfety Treatment ofaleatoryadepistemic (Helton & Burmaster, 1996) andrepresenations ofpistemic uncetaintyHeltn & Oberkampf, 2004 aggrgated a amount of discourse. literaure itself builds on a much longer threadof work sources of unertainty. Helton Oberkapfwrote that this of in representation of botaleatory and episemic uncertainty an be traced back tothe beginnin f frmal blue ideas sleep furiously develomen in the late 1600s 19; Hacking, Shafer, 1978). thecocpts of aleatoric episemi uncertinty had pviously bee usemachinelearning for eample by Lawrence (012) n Senge e a (2014), tey popularised by et al and & Gal (2017). The mthematical denitios ar theinformatin-theotic used et (2017), on work exper-imental design (Lindley, 1956) and activ learnin (oulsby al, 1992a,).",
    "Introduction": "Researcers commonly efer to the idas eaning: relating to cace) and epsteic to knowledge) ucetainty,whichhave a inthe study of robability Hcking, 175). Theline between model-base and proesses is blurred(Adlm t al, 2020; Amini 200; & Beens, 2018 et al,202; Immer et al, 021;Kapoor al Liu et al, 2022; t al, Notin 2021; Potels et 2019;Sith & Gal, 018; van Amersfoort e a, 020). Diferent quantities re-fer to for example, receied def-initions, variance-based 206; Kendall & Gal,201McAllister 016),information-based measurs (Gal et al, 2017), d-hocreintrpretatins of inormatio-basing et al, 2018; Sddhnt & Liptn, 2018) istance-based measures (Mukhot e al, 202,etal 2020). Tenuous assmtns abou howpredic-tive uncertainty will decompos unsee dat (Sbocke a, 2019; Wang & Aitchison, To mak diagnsis precise and provide alternaivethe aleatoric-epistemic view, we sysematicaly disambiguate somekey concepts thatarise in machin leanig We tart with a preditie task interest, highight that trainingdata not corresponddirctlyto task ad contrast model-basing predicionsexteral data-generated This expoition supports our diagnosi of te the dsourse. Wetat, uh of that olloe it, the popular interpretatoepistemic prsentedin (2016), al et a & Gal 017) is itself incoherent: atthes ultiple.",
    ".(3)": "Instead hve to reason abouhatthe daa could be, rise o irreducibleand preditive entropy. Only inthis ofetimatio stochastc become necessary: the decomposition is ased on Bayesian pespective ut is well dened for models.",
    "Both sides can be seen as approximation errors": "Butin the general case these estimators can be highly inaccurate even if they are principled. in Bickford Smith et al (2024) demonstrates this: Bayesian deep learned can produce estimates ofirreducible and reducible predictive entropy that are severely at odds with the entropy changes thatoccur in practice. This new perspective gives us clearer basis forreasoning about predictive uncertainty than is provided by the aleatoric-epistemic view.",
    "Workshop on Bayesian Decision-making and Uncertainty, 38th Conference on Neural Information ProcessingSystems (NeurIPS 2024)": "quantities to the same concepts. This conceptual overloading stems from attempting to encompass toomany ideas within an uncertainty decomposition that has a fundamentally limited expressive capacity. Returning to foundational ideas from Bayesian statistics, we identify an alternative decomposition ofpredictive uncertainty that can be cleanly linked back to quantities used in past work. We believe thiscould be a basis for clearer thinking in future work, helping the eld more quickly achieve its goals.",
    "Abstract": "ideas of uncertainty are widely used to aboutthe probabilistic predictions of machine-learned models. We identify existing discussions of these ideas and suggest from the aleatoric-epistemic view being insufciently to capture all of the distinct quanti-ties that researchers interesting in. To explain and address this we derive a sim-ple delineation of the data-generating pro-cesses associating with training and evaluation."
}