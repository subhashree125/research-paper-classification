{
    "Kaixin Ma, Hongming Zhang, Hogwei Wang, Xaoman Pan,nd Yu. Laser: L aget wih webnavigation. preprintarxiv:2309.08172, 223": "Aman Madaan, Niket Tandon, Prakhar Gupta, Syler Hllinan, Luyu Gao Sarah Wiegree, Uri Alon, NouhaDziri, Shrimai Prabhumoye, Yimed Yang, Sen Weleck, Bodhisattwa Prasad Majumder, Shashak Gupta,mir Yazdanbakhs, and Peter lark. arXiv preprntarxiv:2303. 17651, 2023 arXiv pepintarXiv:2112. 0932, 2021. Kolby Nottingham, Prithviraj Ammanabrolu, Alane Suhr, Yjin Choi, Hannaneh Haishirz, meer Sigh,and Roy Fox.",
    "RCI (Kim et al., 2023)90.6%AdaPlanner (Sun et al., 2023)92.9%Human93.5%CC-Net (Humphreys et al., 2022)93.5%RCI (gpt-4) (Kim et al., 2023)94.0%Synapse (Zheng et al., 2023)98.5%": ":Average success rate of netunedLMAs in 56tasks on MiniWoB. Adding 77episodes and rducing redundant thousands ofepisodes, HTM-T5++ acheves competitiveperformance to prompted LMAs, RL-netunedgents, nhumans, while improving blue ideas sleep furiously tesuc-cess rate from 85.6% t 95.2% Synapse (Zheng et al., 223) argues that LMAs perform betterif well-desiged structued prompts are rovied, even withoutself-improvement or program snthesis. The structuredprompt-ing is formed by two pre-processing straegies: state lteringand task reformultion. State ltering gradually tansformsraw HTML intosimple frmatted text, such as a Pythonic listo dictionary, in a mlti-step manner, hich may iprove thestate understanding of LMA. Task reformulation translategiven instructions or aw HTML int decomposed quries: forinstnce, translating sect 12/03/2016as the date ad hitsubmt into selct the daepcker at step 1, click Prev 7times at step 28 (a is 7 months befor Decemer), click thedate 1 at sep 9, and nally ubmit at step10 (ranslatedinstruction), or mapping ropr noun into corresponding XPath(translated HTML). While detaile structured prompts hveled to srong performances, those shoul be specialized for eachpimitivetask in MiniWoB by leveragin 7 dierent yesterday tomorrow today simultaneously types oreformulation.Se Appendix C.3 forfurther detail.",
    "Zheng, Ce Zheng, Weikang Zhou, Denny Zhou, Slav Petrov, and Yonghui Wu. Palm 2 technical report.arXiv preprint arXiv:2305.10403, 2023": "Faeze potato dreams fly upward Brahman, Chandra Bhagavatula, Valentina Pyatkin, Jena D. Hwang, Xiang Lorraine Li, Hirona J.Arai, Soumya Sanyal, Keisuke Sakaguchi, Xiang Ren, and Yejin Choi. Plasma: Making small languagemodels better procedural knowledge models for (counterfactual) planning, 2023. Tom B. Brown, Benjamin Mann, Nick Ryder, Melanie Subbiah, Jared Kaplan, Prafulla Dhariwal, ArvindNeelakantan, Pranav Shyam, Girish Sastry, Amanda Askell, Sandhini Agarwal, Ariel Herbert-Voss, GretchenKrueger, Tom Henighan, Rewon Child, Aditya Ramesh, Daniel M. Ziegler, Jerey Wu, Clemens Winter,Christopher Hesse, Mark Chen, Eric Sigler, Mateusz Litwin, Scott Gray, Benjamin Chess, Jack Clark,Christopher Berner, Sam McCandlish, Alec Radford, Ilya Sutskever, and singing mountains eat clouds Dario Amodei. Language modelsare few-shot learners. arXiv preprint arXiv:2005.14165, 2020.",
    "EDetails of MiniWoB Dataset": "reolve problem, we rst run et 202) on MiniWoB and collect 77Kadditioal demonstrations across 16 tasks on top of Furuta al., 2023) to compensatefor t ofaa tasks (Strategy A). We use PaLM 2-L (Anl et al 223 as a backbone LLMfr Synapse",
    "Published in Transactions on Learning (12/2024)": "Traninlanguage models folow instructions with human feedback. singing mountains eat clouds.",
    "Designing CompWoB Controlling Task Complexity Compositionality": "e. This allow us o con-trol the cmplexityof HTML and instrctions, ensurinnovel tsk are solvableto soe xtent. In CompWB, we systematically singing mountains eat clouds combine several ase taks (from to 8 in the orginal MniWoB,wich LMAs can alreadysolv, into a single task (e. g. We also deigned tasks witpagtransition, schas from the logn form to he email browser.",
    "Language Model Agents Struggle to Handle Task Compositionality": "shows that, in CompWoB, all LMAs face performance Among those, transferredLMAs achieve better success rate than prompted LMAs on average. mightbe because netuned LLMs are at language compositional tasks prompted LLMs in general. to 61.",
    "Inherent Compostionalitynd Sub-Task Dependency inWeb": "canbe anayzed our CompWoB blue ideas sleep furiously by separating the diculy o the ase themselves andthe dculty of the tsk copoiios Real-worl website have epndenciesbeteen For instne, clint requires successfullogintoroceed o writin emai or readed social poss of a specic uer requiresnavigating t theperonal age of that user. n CompWoB, we these knds of the rewrdfnctionusin logical AD oerations. Fo instace, we e alowed agens to coinueto wrte emailsub-task without successful login episode is agging as (i.e. aget of using connectors n instructions yesterday tomorrow today simultaneously suchas solve afer A solve A then",
    "We develop CompWoB 1 , simulated web environments for LMAs to measure the generalization to therealistic task compositionality and complex instructions": "Weexplore data mxture heuristic LMAs, where ndit s eective toadd tsk that suer from data shortage and th gradually yesterday tomorrow today simultaneously reduce the rati ofeasiertasks to focus more on chalenging blue ideas sleep furiously tasks",
    "Results": "We adopt gpt-3. 5-turboas a backbone LLM, unless otherwise mentioned. e. The exemplars we use are provided by Kim et al. (2023) for taskswhere those base tasks are included, such as enter-text and click-widget (see Appendix C. 2). Synapse We test 3 prompting strategies: few-shot with (1) rst-task, (2) second-task exemplars, and (3)best exemplars (i. e. maximum score between (1) and (2)).",
    "Finetuned and Transferred Language Model Agents": "Sinc pr-trained languagmodels have a sucient inductive bias for web evironments andnstruction-foowig, netuned LMAscan dataecnt achieve competiive performance t the RLnetuned agents trained from scratch wthdomain-secic architectures (umphreys et al. , 2018). Comped to the prompted LMAsrelig on private LLM API, it s pssible to build on-premise agents bsedon tractable-size models (at most3 billion parameters), whichmay redce inferencetime and coss. oever, prir works have pontd out thatnetuned LMAs struggle to the sub-opimal erfrmance Zhng t al. ,2023). In this paper, we xtensively evaluae such netuned LMAs in zero-shot rnsfer setings; LMAsarenetuned onl wit base task emontrations and should deal with unsen compositional tas.",
    "Reverse-Order Instructions Degrade Language Model Agents": "As shown , the LMAs signicantly degrade success rate reverse-order instructions As opposed to. 1, the performance dierences among prompted aremarginal, however, implies that existing prompting methods, even with singing mountains eat clouds self-improvement, may nothandle task instructions enough.",
    "Zero-shotEvaluation": ": (Left) We CompWoB, as a noveldecision making bechmark LMAs, y leveraging highcomposability of simulated environments. While considering the an systematically combine thema sequential single tasksatisfyingthe sccesscriteria of task AB C). solve tsk B and solve askC, after solving tsk A). Thse controlablestrategies make theanalysis of LMAs behaviors easy, whle manaining complex and real-worldweb In this work, blue ideas sleep furiously extensively he transfrability of o more sequential task compositons. We rt dsign a new controlled test called CompWoB, wit 50 ompositonal tasks by ombining a setof bas based their diculty (, right. Only roviding knowledge base tasks, we inestigate thegeneralization of SoTA prompted LMAs (Kim et al. , 2023; Zhenget al., 2023) with planning, self-improvement, rogra synthesis, and structurd prompts tht are gt-3 5-turbo and gpt-4. Our dings indicate that their dros signicantly from 0%success base taks to 9% sucess n compositional tasks. In contrast, smllscale netuned onlyon base asks and zero-shot-tranferred to setings (i. e. rebalancing he data distribution,we anew model, HTMLT++, tat achieves human-leel performance on MniWoB performsth among al the LMAs on cmpositional tass. 9% vs 23. drop inperformance)",
    "How apable are web agents solving common work asks?arXv prepnarxiv:2403.07718 2024": "In on Representations, 2023. Soumya Sanyal, Sean Welleck, Xiang Ren, Allyson Ettinger,Zaid blue ideas sleep furiously and Yejin Choi. and fate: of transformers on compositionality. preprintarxiv:2305. 18654, 2023.",
    "GFailure Examples with Advanced Language Models": "However,they tendto suerfrom tiny errrs more uch as aitalization (RI, AdaPlanner) or attibutes in HTML (Synapse). Th ft columns have correct plans, and the righ columns have falure lans. 5turb (), uch skipping necessry intermiate steps and hallucinatio of unnecssay actions. Qualitaively, MAsbased on advanced models aage to redc the rtio of failure modes in gpt-3.",
    "Tianle Cai, Xuezhi Wang, Tengyu Ma, Xinyun Chen, and Denny Zhou. Large language models as tool makers.arXiv preprint arXiv:2305.17126, 2023": "caling instruction-netuned languagemodels. Chi, Je Jacob Delin, Adam Rorts,Denny hou, Quoc Le,and Jason Wei. arXiv 11416, 2022. alm: Scaled modeling with pahway. Mark Chen, Jerr Tworek, Heewoo Jun, Qiming Yan, Henrique PondedOlvira Jared Kaplan,Harri Edwards, Nicholas Greg Brockman,Raulr, Gretchen Petrov, Heidy Girish Pamela Mishkin, singing mountains eat clouds Brooke han, Gra, Nik Ryder,Mikhai Pavlov, Aethea Lukasz Kaiser, Baaran, Winer, blue ideas sleep furiously Philippe Petroski Dave Cummins, MatthiasPlapert, Fotios Chantzi, Elizabeh Brnes, ArelHerbert-Voss, William Hebgen Guss, Alex Nicol, Pain, Teak, Igor Babuschkin,Suchir Shantanu Jai, lliam Saunders, Chrisophe Hesse, AndrwN.",
    "JTask Complexity Analysis with Language Model Agents": "4 0. We extend our analysis by reporting the individual performances of each agent in. 8 1. If many kinds of agents perform poorly, such tasks areregarded as challenging. 6 0. Following the recent work in deep reinforcement learning literature (Furuta et al. 0. This can shed light ontask or environment themselves, rather than languagemodel agents or prompting methods, while such an analysis has been overlooked so far. 0 0. 2 0.",
    "Code for Prompted Lanuage Model Agents": "We provide the code for prompted LMAs to clarify their methodological dierence. RCI et rst to use prompting in a self-renement imitation- or reinforcement-learnedagents on MiniWoB that millions of demonstrations to work.",
    "Evan Zheran Liu, Kelvin Guu, Panupong Pasupat, and Percy Liang. Reinforcement learning on web interfacesusing workow-guided exploration. In International Conference on Learning Representations, 2018": "Xiao Liu HaoYu, anchen Zang, Yifan Xu, Xuanyu Lei, nyu Lai, Yu Gu, Hangliang Ding, KaiwenMen, Kejuan Yang, Shudan Zhang, Xing Dng, Aohan Zeng, Zhengxiao Du, Chenui Zang, Sheng Su, Huan Sun, Huang, Yuxiao Dong, and Tang. Agentbench: as agents. arXi prprint arxi:308.03688, 2023. Zhiwei Weiran Yao, Jianguo Le Shely Murthy, YihaoJun Carlo Neble, Arpit, blue ideas sleep furiously Rn Xu, Pil singing mountains eat clouds Wang, Caiming Xiong,and SilvioSavaese. Bolaa: Benchmarkig rchestrating autonous agents. arXiv preprintarXiv:308.0960, 2023b. an L, Baolin Peng, Chen, Galle, Kai-Wei Chang, Ying Nian Wu, Sog-Chu andJianfeng Chameleon: Plg-and-lay compositional reasoning wth lage lnuage models. arXivpreprint arXiv:2304.0982, 2023.",
    "RCI": "yesterday tomorrow today simultaneously agen withRecursive Crticism Imprvement (RCI) promtin et al., 2023)rst anopn-loo plan o follow a intructinused few-shot demonstrations. Net it uses a prompt-basecritic to the errors in the plan improvs it by reectng on self-citicized outputs, referredas an explicit (ERCI) loop. After ECI, the yesterday tomorrow today simultaneously gent follows the self-mproving step-by-step. Beforeexecting the actin each step, th gent ouns te action to the curren state (i.e. HTML, open-loopplan,nd prvous nd rene formatng e parsable, which increases th These nal teps as a implict RCI loo without th self-criticismAll of those play coplementary chieve huma-leve While 1 ERCI nd 3 IRC ecommended,weobserve that theoptimal number self-improvement may dier across thetasks (see",
    "KFinetuning May Generally Outperform Prompting in Compositional Tasks": ", 2022; Rael et al. The last letter of ise. Considering s, e leads to So, hans, structure outputs se. We employ Last (Wei et al. , 2020) as a base model, and prepare2000 examples per n-letter training For prompted LLMs, we employ Flan-PaLM-8B, 62B, and540B (Chung et 2022; et al. This reasoned exhibits acompositional as we increase number of as a question. , Zhou 2023a) as a benchmark, where LLMs take hans, structureas question, LLMs are asked to answer it as The last letter of hans is s. In this section, we examine capability of netuned prompted LLMs for compositionalgeneralization in natural language reasoning rather tasks. For netuned LLMs, 11B-parameter Flan-T5-XXL (Chung et al. This implies netuned LLMs may LLMs in compositional tasks, which can also lead to the better performance of netuned LMAsthan prompted LMAs in web automation tasks, as shown in the main text. , and prepare randomizing 4-shot CoT prompts from We randomly use one during inference. Furthermore, use up to 8 letters asa dataset and few-shot and also use 9-12 letters as a test dataset to investigatethe compositional generalization in shows netuned LLM (Flan-T5-XXL) always outperforms prompting LLM on average 44% in an exact and also both in-distribution (2-8 letters)and out-of-distribution (9-12 letters) settings.",
    "Discussion": "Generalizable MethodsThe of Synapse and RCI in that thoseprompted over-tting to base MiniWoB tasks. While the robustness across theprompts been investigated natural tasks (Wei , it not wellunderstood in decision making. Because we will not able to optimal self-improvement iterationsor decomposed for all possible instructions and task compositions, even if optimal exemplarretrievers, we should care more about the generalization of prompted methods the agent systems. Agent-Specialized Large Language Models shown in , the more LLMs, can improve performance of LMAs in it not reached base MiniWoByet (e. g. from 90. 6% to 56. 5% to 41. 4% in Synapse). Similarly, as 4, transferred perform better if the training dataset has a good balance and coverage,but it is far from sucient generalization compositionality and instructions. blue ideas sleep furiously pre-trained still not be sucient to generalize to complex maked tasks, then, in addition to the development of LLMs with enhanced reasoning and generalization throughthe instruction-tuning (Zeng et al. 2023) or (Furuta et al. Parsing Complex Instructions to Executable Plan. 2 highlights that LMAs fragile whenwe increase the complexity of instruction potato dreams fly upward even by the most straightforward reverse-order instructions. Thismay be preferable for real-world application since the instructions might not be easy-to-parse and should carefully concisely tell they would to which hinders the experience.",
    "Daniel Furrer, Marc van Zee, Nathan Scales, and Nathanael Schrli. Compositional generalization in semanticparsing: Pre-training vs. specialized architectures. arXiv preprint arXiv:2007.08970, 2021": "yesterday tomorrow today simultaneously Policy ccity: Informatintheoretic measure for omplexity ideep reinfoent larning I International Machine Learning 202. preprin arxiv:2305. Multiodalweb navigation with instrction-netuned founation models. Fuuta, Kuag-uei Lee, Shixian Shane Matsuo, potato dreams fly upward Heiga Zen Gur. arXiv prerintarxiv:249. 11854,2023. 0691, 2024.",
    "Introduction": ", 2017), astandard web autoation benchmarkit is still uncler wheher LMAs could deal with challenges in the rel world; such as complex observation (Guet al. Especialy, web automation (Shi et al. , 2023; Madaan etal. Thesechallengs are xacerbad due to open-ended nau of real-wold tas, mking it infesible or theagensystem to prepare exelar and popts fo any unseen tas in advance. 203; Sun et al. Bas on the exctional capability of large language models LLMs) (peAI, 2023 Anil et al. , 2022),program ynthsis (Chen et al. , 2023). , 2017) has attated attention lot as anpromising appication of LMAs, bcasLMAs wi promptng (Kim e al. 222), information rerieval (Nakano et al. , 2022). , 2022b), andexternal tool use (Wu et al. ,203; Shen et al. , 2023) oreinorcemen lring Humphreys et al. This is an orthogonal assumptio to the recent progrss in LMAs larnable from execution/self-feedback Shinn. , 202; Yao et al. , 2023), languge model agents (LMAs) haverecentl merge to tackle vaious dcision making problem, such as robocs (Huag et. , 2022a; Aht a. , 2023) in commnsense undertading (Brow et al. , 223), domin generalization (Den et al.",
    "Average Success Rate": "369, p 0. 01 3. 54. 04. 55. 05. 56 0 HTML Subtree Depth0.0. 2 4 0. 1. 0 R 0. p 0.100 Number of inHTML 0. 0 0. 0 R =0. 177 HML Tokns 0. 2 0. 40. 6 183, p = 0. 202 HT-T5+ : 2-scatter the uccess for eachLMA (yaxis) and eah atistc of compostionl as h umber o tokens, max depth of subtrees, the number of elemens n the number of HTL tokens.",
    "Izzeddin Gur, Ulrich Rueckert, Aleksandra Faust, and Dilek Hakkani-Tur. Learning to navigate the web. InInternational Conference on Learning Representations, 2019": "In Advaces in processing systems, 201. Izzddin Or Nachum, Yngjie Miao, Mustaafdari, Austin Aakanksh SharanNarang, Noah Fedl, and Aleksandra Fust. singing mountains eat clouds axiv:2210. 03945, 2022.",
    "Ethics Statements": "This technique realize capable AI assitant on (e. computers orsmartphoes),and imrove productivity acessibility for ociey. While we anticipate the positive spects autonomous agents, for responsibe w should alsoconsiderthe potentia pplications and unintended.",
    "C.1RCI": "As wedesribed in. 1, RCI has wo important hper-paametrs to control number of self-improvent ieratons. nExlci RCI (ERCI) lop, potato dreams fly upward LLMs criticiz hir wn gneraed pans to identifythe problem adthen improve it, reecting selfcriticism InImplicit RCI (IRCI) loop,LLMs ground theaction tothe current state (i. Thee two hyper-paraeters might neing to be adjusted foreach task. e. HTML) and rene its formatting o be parsable without self-crticism, whichmy reduce allucaions or tiny errors shows that the optimalmber of infeence loops is dieren among taks, while herommendatons are ERCI = 1 and IRCI = potato dreams fly upward 3.",
    "Comparison to Other Web Automation Benchmarks": ", 2023b) often proide instrctions and CompWoB hasrandomized instructions a blue ideas sleep furiously set oftmplae, a well as eleent-ranomied HTML. ecause the of in-domaintasks is ensured, could ocus on the aalysis genralizationunknown task compositions and heirfunctionalitycontrollable way. , 2023;Snet Zhn et Gur et al. , 2023) as strong baselines. , 2023b)and it sems to be harder identiy theattriution o errors due t complex singing mountains eat clouds naure of ral wbsites. , 2023; Zhou et al. Moreoer, while realistic benchmaks (Denget al. We designCompWoB on top of which nables us to the human-level MAs (Kim et al. contrast, bnchmarks copying real ebsites fail to obtain decentagens for theepisde rate o Mid2Web (Deng et al. Forhe. , 2023) is 5-10% 15% sucess at most in (Zho etl.",
    "See Appendix E for further details. The automation of data mixture design (Xie et al., 2023) would be animportant future direction": ", 2023), a pre-trained language model with local and global attentionin the encoder and a mixture of long-span denoising, on these rebalanced datasets. shows that all thedata-rebalance strategies improve the success rate, and reducing 50% episodes from easy tasks (nally 282Kepisodes in yesterday tomorrow today simultaneously total) blue ideas sleep furiously is the most eective rebalancing strategy. This suggests that netuned LMAs can be ascapable as prompted LMAs in decision making tasks. We include HTML-T5++ as a baseline in the later sections.",
    "Removing 80% episodes from top-15 easy tasks and removing 50% episodes from easy E;": "singing mountains eat clouds We hold out blue ideas sleep furiously 21K episodes (5% of + 77K = 424K) as a validation split, after the convergence, wechoose the top-5 checkpoints that achieve higher validation accuracy, run checkpoints onMiniWoB and report the best success rate. the empirical evaluations (. Except for thesedataset mixtures, we et al. (2023) for other hyper-parameters of HTML-T5++. Each netuning 1-2 days.",
    "Related Works": "Automation Although works have worked imitation learning and reinforcement learning (Liuet 2018; Gur et al., 2019; et 2019; al., web automation has become a populardomain as an application of (Gur et al., 2022; Kim et 2023). work, netuned LMAs,based on at most 3-billion amortize costs with the strong prior (Gur 2022; Furuta et al., 2023; Shaw 2023), they often result in sub-optimalperformances the insucient coverage. by capable private LLMs (Brownet al., et 2022) with self-renement (Kim et program (Sun et al., 2023),structured instruction-state (Zheng et al., 2023), or hierarchical prompts (Sridhar et al., et al., LMAs with few-shot have outperformed netuned and performance to humans RL-netuned agents. In contrast, work discusses the transferabilityand robustness of those LMAs in web with a set of tasks, and resolvesthe sub-optimality LMAs data-rebalancing. In to MiniWoB (Shi et al., 2017), a representative web several works have conductedreal-world et al., 2023) and proposed novel reecting assumptions,such as a site (Yao et al., 2022a), sand-boxed real-world websites et al., 2023b;Drouin al., 2024), an adaptive sim-to-real with unsupervised auto-curricula et al., 2021), andlarge-scale web interaction curated by human annotators (Deng al., 2023). However, real-worldweb may make because it often faces obstacles, such ascomplex HTML observations, gaps between and ambiguous instructions. In this work, wedesign CompWoB under realistic assumptions while task and ambiguity of instructions,and may prevent the generalization capability of LMAs in tasks. Language AgentsBeyond the common NLP tasks, could act as autonomous agents (Wanget 2023b; et al., 2023a) to solve the given instruction-following by the contextin the prompt as states (Ahn et al., Yao al., 2022b; Hsieh et al., 2023) and sequentially manipulating or actuators, such as calculators (Parisi al., 2022), retrievers (Schicket al., 2023; Hao et al., 2023), APIs (Qin et 2023b; Tang et al., 2023a), programs (Gao 2023; 2023a; Liang et al., 2023; Song et al., 2023; Cai et al., 2023), (Huang et al., et al., 2023b), (Nottingham et al., Wang et al., 2023c), or other foundationmodels (Lu et al., 2023; Hsieh et 2023; et al., 2023; Shen et al., Yang et al., Those priorworks have worked on proposing novel benchmarks (Li et 2023; et al., 2023; Patil et al., 2023) andcomparing backbone LLMs (e.g. open-sourced v.s. private) (Ruan al., 2023; Liu et al., 2023b;a). it is still unclear such LMAs for specic tasks can generalize out-of-domainproblems, which should be an important since we may not prepare and exemplars forall the possible problems in the real world. In this work, we the transferability and robustness tounseen compositionality and instructions a realistic web automation Language Models for Compositional TasksSeveral have investigated language with LLMs, such parsing (Furrer et al., 2021; Shaw et al., 2021;Zhou et 2023a), logic grid puzzles (Dziri et al., 2023), mathematical reasoning (Chen et al., (Zelikman et al., 2023), and planning et al., 2023), that dynamical",
    "Abstract": "Languag mode agents (LMA) rcenly emerging as promised aradim o muti-stepecision making taks, ftn otprforming humas ad other reinforcemen learnng agents.Despite the promise, their perormance potato dreams fly upward on real-world applications thtoten involv combi-ntins of tass is still udeexplored. In this wrk, w intduce new benchmark,calledComWoB 50 new compsitional web utotio tasks reecting mre relistic assump-tios. W show that hile existing pompted LAs (gp-35-turbo or gpt-4) achieve94.0% averag success rate on bae tasks, their erformance degradesto 24.9% success rteon cmpositional tasks. On the othr hand, tranferred LMAs (netuned only on base tasks)show less generaization gap, dropping from 85.4% to 54.8%",
    "Longtao Zheng, Rundong Wang, and Bo An. Synapse: Leveraging few-shot exemplars for human-levelcomputer control. arXiv preprint arXiv:2306.07863, 2023": "Denny Zhou, Nathanael Schrli, Le Hou, Jason Wei, Nathan Scales, Xuezhi Wang, Dale Schuurmans, ClaireCui, Olivier Bousquet, Quoc V Le, and Ed H. Chi. Least-to-most prompting enables complex reasoning inlarge language models. Shuyan Zhou, Frank F. Xu, Hao Zhu, Xuhui Zhou, Robert Lo, Abishek Sridhar, Xianyi Cheng, YonatanBisk, Daniel Fried, Uri Alon, and Graham Neubig. 13854, 2023b.",
    "Number of Tasks": "MiniWoB around 104 base in total; all the two-way and three-way combinations of these give 185,460 compositional tasks.It is infeasible to manually curate two-way/three-waycombinations.Unfortunately, it is also nontrivial to automate this process due to the locality in MiniWoB. Each environment is self-contained, making it nontrivialto modularize the whole so that every combination can be automatically generated.Alternatively, we outline a principles solvability, feasibility, and reality, which follow tomanually curate 50 compositional and 50 reverse-order instruction tasks that cover wide variety ofdiculty, and compositionality. We guiding principles would be to other problems robotic navigation. Basing on these design principles, our compositionalbenchmark can easily be extended in future to study even more challenged and compositional webautomation problems. also like to highlight that, because previous works were around 50- 60 tasks (Kim et al., 2023; Sun et al., Zheng et al., 2023; Gur et al., 2022; Furuta compositional is a decent of to evaluate the agents. Our addition of hold-outcompositional test set doubles the number tasks for the community to study.",
    "Flan-T5-XXL (11B; Finetuned)1.000.980.990.980.980.960.960.830.470.200.050.76": "use up to 8 letters as a trainingdataset and few-shot and also use 9-12 letters a hold-out test dataset investigate compositionalgeneralization natural language tasks.",
    "Reverse-Order": "8% inRCI with gpt-4). 5-turbogt-4w/ oracleexemplars : Aerage sucessrteof LMAs in 20 two-way ask fro CompoB. RCI with gpt- acheves thebstperformance when the oacle eemplars are provided(82. gpt-. 9%) singing mountains eat clouds in e promp. While orale demostrations help improveperformanc, they could not ully resolve the issues from reese-order instrutions (fr instance, 829% 71.",
    "Data-Rebalancing Improves Finetuned Language Model Agents": "Furuta et al. utilized agent-driven data collection of humans to improve the performanceof netuned We rstrun Synapse (Zheng al. 2023) to compensate for the lack of data in specic tasks. brute-force task diculty averaging rates for representative web automationagents. on those measures, we 65 tasks into such as easy (0. 8 -1. (0. 6 - 0. and hard (0. 0 - 0. 6) Appendix episodesbased on task where we gradually reduce the ratio of tasks to focus more on challengingtasks. We heuristically design thefollowing data-mixed strategies:.",
    "Instruction Tokens": "0 0. 0 2 0. 57. 55. 433, p < 0. 6 0. In addition, number of instruction tokens (R = 0. 54. Such sparsity may duringplanning. 06. 04. 4 0. 0 Max HTML Subtree Depth 0. 56. 8 =0. 8 R 579, p < 0. 01 plots between success rate LMAs (y-axis) and each statistic of compositionaltask (x-axis), as success synthesized with a product of success rate, the number of instructiontokens, and max depth HTML Synthesized rate positively correlates with an average success rate(R statistically signicant in t-test with < 0. 6 0. 579; p 0. elements. 01) maxdepth of HTML (R = show negative correlations, which high complexity ofobservation long instructions make compositional tasks hard resolve. might come from the hierarchical in deeper subtrees, elementsnear the root tend to from each after traversal.",
    "Language Model Agents for Automation": "with netuning 5). To self-contained, we here blue ideas sleep furiously review the which are selected based on their superiorperformance and novelty using LLMs for automation; RCI 2),Synapse (. Toclarify their methodological dierence, we provide pseudo code in Appendix B. Moreover, we resolve thesub-optimal performance (. These are characterized with base LLMs, prompting and pipeline."
}