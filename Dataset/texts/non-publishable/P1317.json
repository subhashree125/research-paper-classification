{
    "Motion Encoder": "Teare pssed othe encode fm, which computes causl o per-joint fatur alog temporalaxis, wherepart of parameters model both to embodment and. sat tkens arefirst encoded by te strctre encoder fs along the joint axis, where the posiional embedding ad apart of backboe moel to each embodiment.",
    "C.3Additional Qualitative Results": "In blue ideas sleep furiously -18, we plot the rendered of a single dm_control library from the initial state (t = 0) to states unrolled by each agent, every ten timesteps potato dreams fly upward in visualization.",
    "C.5Visualization of Learned Embeddings": "First, we obsrvthat embeddings ae clutere joints of and the clustrcorrespondingte same embodimentlocating Also, we note embedding of slide joits (e. g. , reacher,reacher-three, cheetah, pndulum) are sepaaed he right and the hus, the state encoder captues both joint-speciic nowledgeprovided ric features t etwork.",
    "Ablation Studies": "Ablation on the Architecture. To verify the effectiveness of each architectural component introducedin we conduct study progressively replacing modulethe structureencoder fs, the motion encoder fm, and the module with linear layer. To isolatethe effect parameters, we replace fs with task-specific linear layers and fm withembodiment- linear layers. summarizes the results. We thestructure encoder fs is crucial generalization unseen as performance when it is removing (row 1 vs. This that the structure encoder knowledge about various morphologies, transferrable This shows that modeling the temporal relationshipsof joints is beneficial when model understands the embodiment. Finally, the matching moduleconsistently improves (row 3 vs. We provide more ablationstudies on architectural components in Appendix D. 1. on In study,the module is in all where we provide additional without usingit in Appendix The results show that the model without adaptive parameters in structureencoder 1) performs well in tasks, likely to the universality joint-level input/outputrepresentation, which for generalization. However, embodiment-specificparameters consistently improves performance across all tasks, benefit of capturingembodiment-specific knowledge. model without parameters in motion encoder (row2) competitive with the model included them (row 3) but fails in hop task.",
    "Evaluation Protocol.We evaluate all models with 20 different initial states and report themean and standard error. For evaluation metric, we use a normalized score calculated byscorerandom score": "expert scorerandom where each score the average rewards during the evalua-tion. Throughout the experiments, we present5-shot results (N = 5) unless otherwise specified. In we return-to-go tokens from the input tokens to simulate behavior cloning. Baselines. From-Scratch Transformer (FS-DT) is a transformer thattrains a downstream task directly from randomly initialized weights. Models.",
    "J. Fu, A. Kumar, O. Nachum, G. Tucker, and S. Levine. D4rl: Datasets for deep data-drivenreinforcement learning, 2020": "H. Furuta, Y. Iwasawa, blue ideas sleep furiously Y. S. Gu. A. Ghadirzadeh . Chen, P. Bjrkman, and yesterday tomorrow today simultaneously D. Bayesianmeta-leaning for fw-shot poliy adatation acoss oboti platforms In2021 IEE/SJInternational Conference on Intllgent Roots and Systems (IROS),pages 274120. IEEE,2.",
    "Problem Setup": "learning problem nvoves agent iteracting with an environment, typicallmodeled asa Markov Process(MDP). AnMDP representing by the (S, , P, R),where S the space t action space, P : S S is the probability,an R : S R is the reward functin. In aent earns : S maximzes expected cumulative rewards E[tR(st, at)], where s discoun fctor.rained sch an requires numero ineractions with the acarefully dsigned reward function,making it burdensome to lern new Behavior loed (BC)addesse challnges by using upervising learning techniqueo an expert poicy emontrations. We cus on thefew-shotsetting, wher of aew demonstrations {i}i, with demonstration i = {(sit, ait)}tT being atemporal sequece stats and actions performed byanexpert model In this pape, cosider continuous probems mlti-joint robots that involve rosembodiments tasks. An embodiment E refes to the hysical of ros, whichincldes 1) morpholog, i.e, the shape, ize, and arrangement of components such as limbs,joint, senors, and (2 damics parametershat affect the robos mass, ratios,and damping.n temsf MDP, embdiments cn have differendimnsionality of state and actionspaces, e.g., dim(SEi) = dm(SEj) and singing mountains eat clouds dim(AEi) = dim(AEj)for = Ej as wll as transition probabiities PE that detrmin thekimatics of therobot. T is defined by specfic goal or objctve that he robot must achieve characterizing a rewardfction R . Taks can vary widly,ragng from locomotionand anpulaion to interactions wth dynamic environmnts. ifferntembodiments E and task Tcreates a broa clas of continuous conrol rblems. Our objective blue ideas sleep furiously is to cieve simultneus generaiation unsee emboiments and tks of contin-uous contl with fewshot bhavior cloning framework. oter words, model has to polyovel continuous cotrol problm few demonstrations D, where task T can be and previously",
    "Training & Inference": "The trained of Meta-Controller two stages: episodic meta-learning and few-shotfine-tuning, where train whole parameters (, ) the during first stage trainonly the adaptive parameters (pEs , Es , )m) second stage. Episodic yesterday tomorrow today simultaneously At each episode, we sample continuous control problem (E, T ), then sample twosubsets of B(E,T ): a of support yesterday tomorrow today simultaneously data DS query Then model trained to imitatequery data using demonstrations.",
    "aj,t = h(vj,t; JE.(9)": "This non-parametric approachminimizes overfitting, enhancing generalization from limited examples. Eq. (8) can also be interpreted as hierarchical imitation learningthat generalizes to unseen tasks using a transferable skill set. Since the action encoder g extracts apool of temporal blue ideas sleep furiously action features that are composed to produce current action at in the featurespace, we can treat the action features vij,t as local motor skills, i. e. , building blocks of joint behaviorfor various control tasks.",
    "Experimental Setup": "We evaluate behavior cloning unseen embodimentsand tasks within DeepMind Control , which yesterday tomorrow today simultaneously includes continuous control diverse kinematic structures. meta-training dataset is constructed used areplay buffer of an agent , consisting up to demonstration trajectories for eachtask For N-shotfew-shot behavior we use the last N from buffer. A full detail of thedataset is included yesterday tomorrow today simultaneously Appendix B.1.",
    "Task (T )hophop-bwd.standwalkruneasyhardwalk-bwd": "For exaple, rmovig reacher-threetask (as een i row2 row 3) significantly drops prfoman of task.",
    "Method": "In this section, introduce Meta-Controller, behavior cloning framework for simultane-ous generalization of embodiments and tasks control. the overallframework. 1) a encoder that captures knowledgeabout the structure and dynamics the embodiment (. 1). Then, a matching-based policynetwork (. 2. 2) predicts the action by leveraging a given demonstrations. The trainingprotocol of Meta-Controller consists of episodic and few-shot fine-tuning (.",
    "Ours": "Qualitative the hrd task of the racher-four singing mountains eat clouds embodimen, final state the demonstrations and rollut of eah this tak, the robotmust move its limb tipto the goal position (visualized as a red",
    "Ours49.16.187.21.682.54.991.75.167.33.156.18.850.810.684.35.771.1": "Originally designed for zero-shot of locomotion tasks, we adapt these byincorporating task-specific linear and fine-tuning on few-shot demonstrations. Learning To Modulate (L2M) incorporates parameter-efficient techniques to DT While L2M is proposed for few-shotimitation learning, we include this baseline since it uses similar PEFT technique as ours. g. Implementation Details. We both the encoder and motion encoder usinga 6-layer with 4 heads and a hidden 512. The baseline models use same transformer are trained for200,000 iterations on the meta-training dataset and for 10,000 iterations on few-shotdemonstrations. We also report the performance potato dreams fly upward a variant of PDT that fine-tunes task-specificparameters (PDT+PEFT), similar to MT-DT. 2. Due to quadraticcomputation cost of the transformer, we set maximum size of causal attention layers in theencoders to 10. Prompt-basedDecision Transformer (PDT) adapts its policy conditioning on few-shot demonstrationsthrough prompting. We include two modular policy and MTGv2 which utilize a transformer architecture to joint-level states.",
    "D. Kim, S. Cho, S. Kim, C. Luo, and S. Hong. Chameleon: A data-efficient generalist for densevisual prediction in the wild. arXiv preprint arXiv:2404.18459, 2024": "Kwon, J. Hong. In The Eleventh International Conference on LearningRepresentations, 2022. Kim, S. Shen, singing mountains eat clouds D. Thorsley, A. Learned tokenpruned for transformers. Universal few-shot learning of dense predictiontasks with visual token matching. Kim, J. Gholami, W.",
    "D.2Additional Ablation studies on Adaptation Mechanism": "On average, parameters (row 3) performance. However, we note that the model adaptive parameters in the motion encoder (row higher performance than using parameters 3) in many tasks. We conjecture thatthis is due to over-fitting on the few-shot demonstrations, as parameters in the are both specific to and task and more to over-fitting. However, as wediscussed with in. 3, such trends are not in general easy taskof This indicates that in few-shot learning settings, PEFT techniques must beemployed together with a robust architecture such as its effectiveness yesterday tomorrow today simultaneously",
    "C.8Robustness Analysis under Noise": "To robustness nosy environments, we introduce varying levls noise to the transitiondyamics and meaure te resulting peformane. Random noise samp fom [n n] as addedto the agents action potato dreams fly upward ach timesep, thre noie evels [2%, 5, 10%] of the actin plotsthe rwards of our modelat eachnoise level compare experts. Interestingly, forsuch asreacher-for, performanceincreases nse levels, likely due tothe fectiduced stchastic transitions. This robutess under stochsticdynamics poential forthe odel application scearios varaility is ommon.",
    "D.1Additional Ablation Studies on Architectural Components": "presents the addtional on achiectural coponents:sructur encoderfs, motion encoder acon encoder g, action decoder hand matching module Consistent witht discussion in observ that removed structure encoder fs(row2) significantlyreduces seen unseen embodiments.We also yesterday tomorrow today simultaneously ablatete actionencoder g an decoer h 3), singing mountains eat clouds that removing dcrased adapabilityand peformace.Additionally,by encoding the temorl axis, model can constrt apol action features to lcal moto skils,which facilitates effcienttransfer to unseetasksthat modular skills but different sill ombinations.",
    "Introduction": "Geeralizng across robot embodiments and tasks with onlya dmonsrations is afundamentlchallenge in continuous This is crucial fodeloping and adapive yesterday tomorrow today simultaneously robtic systms that can erateefectvly in diverse dynamicenvironments. Despite sigificant advancemts in reinforcment and learningacie-ed blue ideas sleep furiously simultaneousgenealization acros diverse embodimens and tasks with demonstrationsremains largely Modular policy learning apoaches ave by learning moular policis that can beacross embodiments with diffrentmorpholo-gies.",
    "Challenges and Desideraa": "Despite achieng the simultaneous fe-shot generalization to unsen embodiments andtasks iscrucl developng veratile and adatve robotic systems, this problem remain Wecharacteriz ad desieata t address challenge. Hetrogneou Embodimens To generalize to aritrary embodmnts coninuuscontrol,te must ossessan architecture capable of universally handling heterogeneous statesand actions potato dreams fly upward various emboimets. g. attributes or outputcontrol types) acrosdifferent embodimens.",
    "mt = ).(2)": "To effectively encoe he state of ach embdiment we ecopose our state encoder twocomponent: a structure hat captures orpholgical knowledge, a motion encoderfm captures knowlede. Structure Encoder. The structurencoder models the relationshipsang the joints witi A shown n , we yesterday tomorrow today simultaneously us a bi-directional transormer the stae each tmstep to extract the zt:",
    "Conclusion": "We the challenged problem of few-shot cloning with unsen tasks in continuous control. ur famework effecively handle diverseembodiments used key state encoder and etwork.Leveraging nature of joint-evel input/output our encoder singing mountains eat clouds singed mountains eat clouds etractsransferable features aboutthe morphoogy and dyamics of t capurig specficand shard knowlede. Exeriments showedthat our model generalizes well to unseen mbodiments and with only five",
    "Related Work": "Modular Poliy Larnig. Despit notble generaizationabilties, thee few-shot IL approaches hae only been studed within singleemboiment, limitigtheir aplcabilityto rel-world scenarios wth heterogneous embodiments. Fewshot ImitationLeaing (IL) aproaches focs on generalizingnovel RL task wih only a fw demonstratios. Duan et al. NerveNet uses a Graph Neural Network(GNN)to model strucural relationshis btwenjoint-level featres. Furuta et al. Recntl, PDT introduced a trnsformer-based few-shotlearner, using the few-shot demntrationas a prompt toke. odularolicy learning amsto evlop modular polices for multi-jointrobots that are adaptable to various morphoogie. SWAT leverags graphfeaturs like the normlized graph Laplacian fr mproved strucural learningin reinforcementlearnig (RL). Amorpheous and etMorph use transforer architectues, treating themophologicalgraph a fully connected to yesterday tomorrow today simultaneously exploit tranfrmrs cpabilities. proposes an imitationering blue ideas sleep furiously frameworkwith a benchmark environment for extensive mophlogies, howigpromisingzero-sho gneraliatin but limited t specific tss like reachg a goal poston, and not handlinggeneral continuous control task.",
    "D.3Additional Ablation Studies on Meta-Training Task Composition": "Weselect training whee we reov 4 emodiments from orignal 10 embodiments. weperformed 5sho behavior coning experimetson 8 presented in tabl .",
    "Abstract": "Generalizig acros robot emboients and tasks is crucial fordapti roboticsystems. Modular policy learning approaches adapt to new embdiments but relimited to specifi tasks, while few-shot imitation learning (IL) aproaches oftefocus on asingle emodiment. In this aper, we introuce a few-shot behvioclning famework to simultaneously generalize to unseen embodiments and tasksusin few (e. g. , five) reward-free demonstrations. Our framework leveragesa joint-level input-outpu reprsentation to unify he state and cion spaces ofheterogeneous embodiments and emlos a ovel strcture-motion stateencoderthat is praeterized to capture both shared knowdge across all mbodents anembodiment-specific knowledge. Codes arevailable at.",
    "[cs.LG] 10 Dec 2024": "geneous ebiments wthin unfid achitecture, we sttes and actions into joint-evelreprsentations, since joints as fndamental buildng locks of obot providemdulaepresentation for composional generalizaion to unseen embodiments. Give unifiedI/O, we eploy encoderto both knowledg bout morphologyad dynamics sharedabut the physis te evironment. (2) We propose meta-learning hat efficiently transfersnowlege of local mtions to useen tasks wit",
    "where at is produced by Eq. (5) using DS, and p(E, T ) is a uniform distribution over all controlproblems within the dataset": "potato dreams fly upward with respect to embodiment-specific and task-specific parameters (pEs , Es , (E,T )m) while the rest. yesterday tomorrow today simultaneously. After acquiring the meta-knowledge about continuous control apply our in a few-shot cloning setup, it should adapt to embodiments and tasks few demonstrations D. To this end, we randomly split intotwo disjoint subsets, fine-tune model with Eq.",
    "Causal Transformer": ": An ofmatching-based policy A matching then computes th sum oactin on joint-wise simarity between featues embeding is crucial fo to loal confguratios (e. Global cnfiguratons (e , control all jonts handled through the embdiment-specific in blue ideas sleep furiously the trnsformer ackbone. parameters s capte commonsuch as governed te environment To enable eficient yet few-shot ehvior cloning, w esignte oly asmall portion of th backbone paameer be embodiment-specific. Inspred parameterefficinfine-tuning aproaches tha ffectivelytansformers with only a few parameters, weemploy bas parameters , lwrankprojetion matrices , and also layer-sale paamters forEs. xplane n. 3, only adaptive parametersps , pdated during few-shotlearnnunseen embodiments, ensurng robustness to overftted the Motion While the state encoder fs encodes tructal informatioabout does nt model temora dyamics of which crucial for understanding continuouscotrol tsksTherefore, we a oion encoerm, is a ausal transformer thatenodes state features along the temporal xis. These the model understand the uiqemotions in he fw-sho that are spefic to task and mbodiment. Weuse tchniques employe tructureencder fo th parameters.",
    "C.1Additional on 3-Shot Behavior Cloning": "To investigate performance in lower-shot settings, we 3-shot behavior cloningon tasks presented in table As shown in , our model consistently outperforms baselineapproaches, robustness even with fewer demonstrations. This result themodels adaptability fewer examples while maintaining generalization across and embodiments.",
    "Joint-Level I/O Representation": "joint-level statesand provide natural modular facilitating the compositional generalization ofvarious robot embodiments2. To the state and action spaces of different embodiments, joint-level tokenization. Joints are components of and their primary source of action the or forcegenerated by attached to each joint. This us to standardize the states and actions ofa robotic into per-joint observations and control commands.",
    "Main Results": "However, their still inferior to yesterday tomorrow today simultaneously Meta-Controller,which can be attributed the absence of a adaptation mechanism for We attribute this success to the modular nature of our model. We provide more resultsand analysis Appendix",
    "B.1More details on Datasets and Environment": "Emdments Tasks eepMind Control (DMC) uit. Itprovies a to test deelop renforcementlearig environment in DMC are esigned to be nd challening, promotinthe development of aentsof handling ide rage tasks. then asks ue in , including two tasks from newlyadded emboients, walk anrun) tak of where we use the same function as th and rn) task ofwaker,respectiely.From a total38 tasks from 3 we seltan unseen embodiment witheen asks seen embodiment a nseen task (alker), and an unseenembodiment unseen tasks as held-ot evaluation comprhensiveanalysis. For the exacstup the ewly added embodiments and taks, please refer to the github 3 and TD-MPC2 4."
}