{
    "Introduction": ", 2023), and selecting images post-hoc (Karthik et al. 2023; al. 2023a). Perhaps importantly, theseapproaches have unfavorable trade-offs, as improve prompt-image at potato dreams fly upward expense of imagequality and diversity e. , high guidance scales lead to reduced image quality and diversity, post-hocselecting the consistent images decreases significantly the representation diversity. two approaches that are applicable to API-accessiblemodels are scale modification post-hoc image selection. recent we witnessed remarkable in text-to-image (T2I) generative models (Rameshet al. , 2023), leveraging additional input modalities such (Cho et al. , 2023). , 2022; Chefer et , fine-tuning models (Lee et , 2023c; al. photore-alistic quality and aesthetics of images has positioned T2I generative models at the center of thecurrent revolution. , 2022; Saharia et , 2022; Rombach et al. , 2023; et al. , a perspective, the fact that not elements of the input text prompt are properly in the generated image is particularly prob-lematic it induces a tedious and time-consuming trial-and-error process with the T2I refine theinitial prompt in order to originally intended image. , 2023b). consistency, researchers have avenues such as adjusting Salimans, 2022), modifying cross-attention operations (Feng , 2022; Epsteinet al. e. , (Betker et al. However, these approaches ona prompt the one provided by the so their ability to generate diverse images limitedto of the input i.",
    "Trade-offs with image quality and diversity": "Following practice in th T2I community, weevaluate the qualit OPT2I generation etrics suh as FD, preisionnd recall (R). , generate 4 each initial and est prompt , 2016) and CIP (Radford et al. Henc, we onclude singing mountains eat clouds FID not affectedbyour optimization straegy. , 2021). However in terms of precision andrecall, e that optimized pomptsreach hgher recallat the expense lower compared the user prompt. This be explining byhe that the input proptalowsgenerate mreiverse imges which mayccasionally fll of atul images precision); e. , n (Apeix B),piming for consistenc lead to a change of rtistic tyle.",
    "Chengrun Yang, Xuezhi Wang, Yifeng Lu, Hanxiao Liu, Quoc V Le, Denny Zhou, and Xinyun Chen. Largelanguage models as optimizers. arXiv preprint arXiv:2309.03409, 2023": "Michal Yarom, Yonatan Bitto, Soravit Chanpino, Roe Herzig, Oran Lang, EranOfek, da Szpektor. What you see whatyou read? impovng text-imagealignment evaluation. arXiv preprint arXv:2305. 1400 Scaling autoeressive for conentrich textto-image generation.arXiv aXiv:2206. 10789, 2022. Mert Yuksekgonul, Federco ianchi, Pratyusha Kalluri, Jurfsky, and yesterday tomorrow today simultaneously James Zou When ad odels bhave likebags-of-words, and what to do it? The Eleventh InternationalCoference on Learning Represntations, 22. Yongchao Andei Mresanu, Ziwen Han, eiran Pastr, Silviu Harris han, and JimmyBa. International Conferencen Learning2022.",
    "Post-hoc image selection": "I , w observe tat OPT2I consistentloutperforms both baselines. We emphasize OPT2I aim to optimize promps togeneate more onistent imges on expectation. However,for the sak of completeness, we als evaluate the seting where we generate the same mount of imagesfrom the initial pompt and sele themost consistent oes. Interesingly, sampin from the initial prompt ouperforms paraphrasing, wichmight be due to random praphrases devitig too much from sers intent.",
    ": Text analysis of revised prompts generated by Llama-2 and GPT-3.5": "5. we note that both the andthe semantic similarity with the prompt start around the maximum number of set, which validates our of 30. leave as future work for samplingtemperature both. We that when Llama-2 for OPT2I, the prompts generated at each iteration longerand more semantically to the user prompt those generated by GPT-3. a tracks length (in number characters) the revised prompts each iteration, btracks CLIP text revised prompts and user prompt along the optimization averaging the revising prompts at the same and all prompts in the dataset. This OPT2I benefits from greater prompt diversity to find best T2I prompts lead to more consistentimages, which is better achieved Llama-2.",
    "Ablations": "on PatiPrompts using default parameters unless otherwisepecified. illustrates the between xploration and implementd as the numberf iteration yesterday tomorrow today simultaneously andthe number of itrations (#iteratios), re-setively. However, pushing exploitation too much, i. e. , blue ideas sleep furiously #it = 150 #p/it 1, armul",
    "Mainresults": "Tese imovementsre esecially noticeabin the max consistency score. In , w plt prompt optimization curves ithLDM-2. Intea, usig. he initia dip n mean consiteny score is exptddue to the initialeploration, snce the L has limitedcontext provding only by he user promt (-shotICL). 5 as LLM and decomposed CLIPscore (dC)DSGas thescoer for pompts from MSCOCO an PartiPrompts. /CDMM as T2I modes, Llama2/GPT-3.",
    "(b) DSG (P)": "MSCOCO prompts (40%), and with less frequency on the more complex PartiPrompts prompts (10%). In , we observe a higher relative improvement for both MSCOCO and PartiPrompts in all configura-tions when filtered out perfect user prompts, which is more prominent for MSCOCO because the numberof excluded prompts is higher. In , we observe similar consistent and considerable increases of alloptimization curves when considering both mean and max consistency improvement. In the mean case, weremark reduction in initial dip in relative consistency, especially in MSCOCO, where OPT2I reachesa positive relative consistency much earlier, i. e. , it = vs.",
    "(b) LLM: Llama-2, T2I: CDM-M": "5556 A raccoon earin cltes, tophat and holded cane. s holding a garbage ba. Oil in the syle of pointilism. (0. 1111 0. 6667 0 7500) 0. 0. 6667 0. 888 0. 0000 teacups surounded a kette (0. 0. 5000 7500 teacps akettle, formed a picturesqu tea yesterday tomorrow today simultaneously setup. (. 000 . 0000 1. 0000 1. 0000.",
    "Meta-prompt design": "We adapt LLMs for T2I prompt optimizationvia ICL. Our meta-prompt is composing of a task instruction and a history of past revised prompt-score pairs. Thelist of meta-prompts used can be found in Appendix A. Additionally, it contains a history of prompt-score pairs that provides context about which paraphrasesworked best in the past for a particular T2I model, encouraged the LLM to build upon the most successfulprompts and removing need for explicitly specifying how to modify T2I prompt. The consistencyscore is normalized to an integer between 0 and 100, and we only keep in history the top-k scoringprompts found so far, sorted by increased score.",
    "serve as a useful fine-grained consistency metric to provide visual feedback for T2I prompt optimization withan LLM, it may not be as effective for evaluation purposes": "444 0. 0000 a clen cutted board, waits 7857) 1429 1. 666 0. (0. 9375) 0. 88 0. 0. 4444 0. 870 0. 3750 0. 0000 : exmples ofinitial prpts left) nd rigt) and reviseprompts across optimization along with the generated images. (1. 250 1. 916) 0000 889 0. 444 A taffc ignpost aintrsectio near a waterway. 0. 2222 0. (0. (0. 8889 A traffic potionedat a crossroads intersection with aterwy flowin nearby,producing strikingvisual. 350 A uk rockina leathe jcket shouting into microphone a 0. 8750 1. (0. 0 500 0. 1 0000 Atop tree stump, a rebellious squirrel wears aacket with etal tuds andholds a mcrphone, suted into th wind with punk fervr.",
    "Relatd work": "Improvingconsistency in T2I odels. everal recent works propose etensions to T2 modes to improveheir itfulness to use prompts. Some studis focus on impoving theguidance with cross-attention (Fenget al. , 2022; Epstein et al. , 2023 Liu et al. , 222; Chefer et al. , 202a).Other studies firtconvert textal prompt into a lyout befor feeding it t layout-to-imge gerative model(Cho et al. , 2023). Recet works also fietune T2I mods on human (Lee et al. , 2023) or AI model(Sun et al. , 2023) feedback r perform post-ho image seection (Karthiket al. , 202). LLMs as prompt optimizers. Several recent works explore the roe of LLMs as prompt optimizers for NLPtaks. Soe use LMs o directly optimie task instruction for ICL (hou et al. , 2022; Pryzant et al. ,2023; Yang et al.",
    "Optimization objective": "Fr example bkelying on the ground, cee snow is decmosed in hegrond an snow. viual fedbck capturedby te consistency score, whic deermines how the candidate prmptat genratng consistentages. , 2023a), (2) or poposed decomposed CLIPScore. In this case, qutos (2 and (3) depend on (1) so (1 is used to validte ()and hese answeed a VQA mdel ased n the generaed inclde the reultingpairs in our metarompt. Decomosed CLIPScore computes parial consistency score for eah noun phase in te userprompt. exampe ofdecomposing CLIPcore and DSG otputs Apendx. crtical of ur framewor isfeeding feedbac o LLM. Each noun phraseis then against the generated image CLIPScor,resuling in a lis pis noun hrase their associated scores, whic re incldd in our global scre per prompt-imag pair iby avraging crss subscores. WhileIPScoe (Hessel e 2021) is arguablyte most popuar or measurin consistency,in our initialexperimens found that propt itha sinle scalar is coarse fo ourwe opt for wo metics tht provide finer-rained bout prmpt-imageconsitency:() Scene Grap DSG) score (Ch et al.",
    "B.5Why is GPT-3.5 not as good as": "Given (and expensive access to GPT-3. 0. one hypothesifor the observed is that our meta-promptis better optimize for Lla-2. 5, our initial exploration of eta-promt strucure nd phrasingwas based on Llama-2, and later on usedsame with GPT-3. as the LLM. 5. In given the flatter ptimiaton cures by GPT-3 5, we cnecturethat t exlores diverse ropts tha. Soin experiment, we am to shd light on t posible causes. and , observe that achieves worse when using GP-3. 5 generally outperforms Llama-2on a wide variety of NLP tasks.",
    ".\"A dignified beaver, wearing glasses perched on the end of its nose, avest, and a vibrant neck tie, stands upright next to a tall stack of books in aquiet library.\"": "\" ovall score:88evaluati ustins:Is therea beaver?100Des thebeaver have glasses?25Does the beaver have avest?75Doe th beaver have a neck tie?100Is te beaver dinfied?0Is the nek tie colorfl?75Is he beaver stadin?100Are terebooks?100Are te boks in tall stack100Is ther a library100Is the beaver next to thebos?75 3. \"With poise ad elegance, a well-dressed baver stands dirctlyadjacet toa high-risebookshel i a library, wearin glasses that sit comfortably on itsose, along with neat vest and a bright ey-caching neck tie. \" overall score:86evaluation questions:Is there beaver10Does the beaver have glase?50Does te beaver have a yesterday tomorrow today simultaneously vest?10Does the beave potato dreams fly upward have a nck tie?10I the beardignifid?100Is the necktecolrul?75Is te beave standing?75Arethere boks?100Are the books in a tallstack?75Is thee a library?100Is te ever next to th books?50Is th beavr in the libary?100Are e books in th library?00.",
    ".\"A dignified beaver wearing glasses, a vest, and colorful neck tie.Hestands next to a tall stack of books in a library.\"": "overal scor:90evalutionquestions:Is there abeaver?100Does the have gasses?25Does aver havea the beavr have  neck te?10Is dignified?100Is neck olorful?100Is the beaversandng?75Arebooks?100Are book in a tall stack?100Isaibrary?100I the beaver next to thebooks?75Is the the ibrry?10Are the books the lirary?100",
    "B.11-shot in-context learning as baseline": "In xprint, we compare with 1-hot learnig (ICL), we implement OPT2I with #iter 1 nd #prompts/iter We maintain the same experimental described in, except e s 200 prompts for MSCOCO, and the results First, w ntice that1-shot ICL higher prompt-imgeconsistencythan random paraphrased in settings except whenusing GPT-3. 5, which performs on-par slightly (akd with in , see lso the inSection blue ideas sleep furiously B. Second,and more importntly, e oberve that OT2I outperforms 1-shot o consistency yesterday tomorrow today simultaneously objective, LLM, or T2I adopted. results our previousclaims: (1)procedure allows OPT2I to keep revising over time, 1-shotICL is challenged due to te limitd fedback provided to the LLMabout to use prompt,and thus only improvementsi prmt-img can be obtained over random paahasing.",
    "Jaemin Cho, Abhay Zala, and Mohit Bansal. Visual programming for and evalua-tion. preprint arXiv:2305.15328, 2023b": "Instructblip: general-purose models withntruction unig, 2023a. blue ideas sleep furiously Dai, Hou, Sam Tsai, Jaliang Wang, ang, Peizho Zhan,Simon Van-denhende, Xiaofang Wang, Abhimanyu Dubey, et a. 15807, 2023b.",
    "B.4Strtified PariPromptsresults": "1. For other challenges, CDM-M continuesto provide the most substantial consistency improvement, although the margin is narrower compared toLDM-2. The most significant improvement in consistency is observed for prompts related to Properties blue ideas sleep furiously & Posi-tioning when using Llama-2 in conjunction with CDM-M and dCS. Intu-itively, this plot shows what kinds of prompts are easier to optimize for OPT2I when using different LLMs,T2I models and consistency scores.",
    "+9.68+10.34+10.239.99": "5), and that imae geeratd CDM-M from usr prompts generally more consistent hnthoseenerated by singing mountains eat clouds we attribteto the useof text encder T5-XXL instead. g. , the userpropt teacupssurroundin a ketle, alloptimizedprompts a DSG score of wile the ardinalityof tecups incorrect, whih highlights thelimittions current prmpt-image blue ideas sleep furiously consistencscoes. We note score does ensureperfecly aligned images (e. B. teacups).",
    "B.8Complete optimization example": "Here we provide a detailed example list of paraphrases with their fine-grained DSG scores. Weconsider the user prompt A dignified beaver glasses, a vest, and colorful neck tie. He stands next to a tall of yesterday tomorrow today simultaneously books a library. (from PartiPrompts). LDM-XL-Turbo and DSG-PaliGemma. generate 3 new prompts per images per prompt,and we when a perfect score of 100% singing mountains eat clouds is reached, which takes 7 iterations minutes this case. In Figures 15, we a prompt from iteration (including the at iteration 0) DSG including evaluation questions averageVQA the 4 images.",
    "B.6dditional qualitatv examples": "Figures 11 and 12 show some additional selected examples of user revised prompts throughoutthe optimization along generated images and consistency scores. In particular, we selectrevising prompts such that the consistency the generated images t. user prompt) is strictlyhigher than previous best score found far, i. shows revising prompts generated with DSG scorer. Since DSG as an averageof scores, it is more coarse than CLIPScore and thus there fewer in consistency. In this case, we can a increasein average dCS, translates to generated images which are more consistent with the user average. effect of latent noise in is substantialmodifications in format of the input prompt used to condition the generation lead to significant changesin how the T2I model singing mountains eat clouds interprets the structure the initial noise (e. g. , between rows 2-3 and 4-5in the We also note that dCS averaging over subprompts) can occasionally as evaluation metric image-text consistency. This is primarily because tends to on thepresence of visual elements, overlooking aspects potato dreams fly upward such as spatial relationships. In toilet example, forinstance, we observe the images become consistent up to certain point(around 6). Beyond point, the revising prompts and the generated start (e. g. ,by overemphasizing certain dCS continues to improve. This highlights that, while may.",
    "(a) LLM: Llama-2, T2I: LDM-2.1": "0. 2857 A horse ad sevral cows ay. 5000) 0.8571 0. 6667) 0. 6667 0. 6667 0. 1.000 A bow of tomaoes, topped wth  beautiful flowe, sitting next to a blooms. 000) 1. 0000 0000 1.0.",
    "(d) LLM: GPT-3.5, T2I: LDM-2.1": "For eah setup, we diplay four rows (from the top): initial #1, optimizedprompt #1 inial prompt #2.",
    "a ore detailed consistency score during th pocess, such as DS, in moresignifican mprovements (< in the max cas, and < 5% the mean case)": "29% on SD-1. 1, blue ideas sleep furiously evaluating consistency score. observe OPT2I is of finding para-phrases of user prompt which considerably improve the consistency between the generated images andthe initial, user-providing prompt, measured by DSG g. B. Comparison to paraphrased shows our proposed OPT2I framework is robust to thechoice of T2I model optimization/evaluation DSG since the initial can be zero it is alreadya instead report scorebest This highlights again that morecomplex prompts, such as those from PartiPrompts, benefit from a more accurate consistency metric. 2022), which show optimizingprompts primarily for aesthetics actually decreases prompt-image consistency. 54%, which means that improvement in this setting has upper bound 13. We observe Promptist score by 3. a flower a vibrant flower arrangement, a vase with fresh blossoms) or placing them at the beginning ofthe sentence (e. 56%/3. we of user and optimizedprompts with different LLMs and T2I models. For prompts from evaluated with DSG have an averageinitial score of 86. Wenote some prompts might already a fairly high initial consistency score (see App. In addition to random paraphrasing, we compare OPT2I to Promptist (Hao 4 (Promptists ref-erence model) LDM-2. , four teacups surrounding a kettle kettle placed at the center four. 16%/+11. while OPT2I (Llama-2) improves consistency by+14.",
    ": Averag DSG ore for the mostconsistent images among 600": "In table 3, we consitency dS) blatng for different insrctions the meta-prmpt.We explore four nstruton addiions to b combined with our bae meta-pompt Concisenessencouragesto explorebeyn stadding detal/adjctives; Pioritize fcusigonmissing/low-score elements; Roning encourages toresonhe in-context examples; Structureasks fr siple vocabulary the strucre of e. foreground and backgrond (fullmeapromt are inAppendix A). We oservetat Prioritize yesterday tomorrow today simultaneously achives slightly bett performanceover Reasoing Structure, yt LLM fairly obust to meta-pompt phrasing.",
    "B.3Impact of seed-fixing and #images/prompt": "We ueoudefault configuration with Llama-2 and LDM-2. 1o MSCC. This spports our of generating images/prompt, as it provides. is tat ptimzg wen the seed, generting too ew images/promplad to unsble/ureliable fedback for LLM due to thevariance of the generations. In experen, imact of ixng random seing f he initial nise fothe dffusionmodel optimiatin process whenoptimizing diferent numbers of imaes/promt. r. e. Indeed,lookng at th optimzatio urves, notice ha otimizing singleimage without fixing the seed moredifficult fo OT2I, wich results noisy and lssin themea cae In contrast,whe OPT2I optimie 4 or10 with fixedseed, oth max mean curve remainimilar w. s expected,we bserve no differences mean consistency We that optimizin single imgseed OPT2I is more sensiti to canges te. tousin fixed eed."
}