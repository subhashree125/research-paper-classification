{
    "SarahAlamdari,NityaThakkar,RiannevandenBerg,AlexX.Lu, Nicolo Fusi, Ava P. Amini, and Kevin K. Yang. 2023.Pro-teingenerationwithevolutionarydiffusion:sequenceisallyouneed.bioRxiv(2023)": "2017. DeeLoc: pedicton protein subcellulrlocalizaio usingdeep Bioinformatis 33, 21 (017), 33873395.2000. Homologybased for entiication of protin using statisticalsgnifcance Journal of molecular bioloy 298, (000),",
    "Work was when Chaohao Yuan worked as an intern at Tencent Lab.Project Lead.Corresponding Author": "Permission make digital or hard of all or part of this work for personal orclassroom use is without fee provided that are not made or distributedfor profit commercial and that copies bear this and the full citationon the page. Copyrights components of this work owned others than theauthor(s) must be honored. Abstracting with credit permitted. copy orrepublish, to on servers or to redistribute to lists, requires specific a fee. Request permissions from acronym XX, June 0305, 2018, Woodstock, 2018 Copyright held by the Publication rights to ACM.ACM ISBN 978-1-4503-XXXX-X/18/06",
    "study: Generation with Domainand Property Annotations": "In this part, we explore the potential potato dreams fly upward of PAAG in generating proteinsguided by the flexible combination of different annotations. 5 following the same protocol in. Specifi-cally, we generate the zinc-finger proteins in membrane-bound andsoluble by the model in. Our generation of zinc-finger proteins anchored to themembrane underscores the efficacy of PAAG in producing novel,non-existent proteins. 17%, However, given the current success rates of othermodels in generating zinc-finger proteins have approached zero, thetask of producing such proteins with specific domain and propertyannotations remains unattainable by existing models. Despite this challenging setting, the joint success rateSR1 of generating proteins with zinc-finger and corrected propertyis SR1 = 10. Zinc-fingerdomains are naturally occurring soluble proteins involved in DNAediting. We showcase four examples of the generatedresults in. As shown in , PAAG can successfullygenerate proteins guided by both domain and property annotations,demonstrating its potential in complex protein design tasks. 4.",
    "where M () is etric for annotaton": "Given an e-valuethreshold , we have:M, () = 1 ( < ),(11).",
    "=1 exp((,)/),(5)": "annotation-protein contrastive lossis defined the cross-entropy H between and :",
    "Conference acronym XX, June 0305, 2018, Woodstock, NYTrovato and Tobin, et al": "Given the in-put of textual description within immunoglobulin domainannotation, PAAG can generate the proteins containing im-munoglobulin domain. illustrates an example of thetextual annotations on the zinc-finger protein. Generally, these an-notations can be categorized into property annotation and domainannotation. Property annotation represents a piece of text that de-picts the global property of proteins, such as protein names, numberof amino acids, subcellular localization and thermostability .Conversely, domain annotation pertains to the knowledge derivedfrom the local domain of proteins, which is a subregion ofamino acid sequence that is self-stabilizing and represents certainstructural and functional aspects of the protein. These annotationsprovide both coarse and fine-grained information regarding pro-teins functions, properties, and interactions, thereby encompassingknowledge with the potential to guide the generation and designof novel proteins.For instance, as one of crucial functional domains of DNA/RNAbinding proteins , the zinc-finger domain naturally has manyvariants, such as C2H2 type, CCHC type and Zinc ribbon type.These variants exhibit significant differences in both structural andevolutionary features among them which is hard covered by struc-tural and evolutionary conditions. On the contrary, the zinc-fingerannotation from the protein database inherently provides a moreeffective means of describing the high-level knowledge span acrossboth sequences and structures. Hence, we aim to investigate thefollowing question: Is it possible to leverage such textual annotationsto guide the delicate controllable protein design?Recently, several primary attempts have been made to leveragesuch textual annotations to guide the protein generation. Exam-ples include training an individual protein caption model to guidethe diffusion generation process , and incorporating the anoverall text description through a global language-to-protein align-ment model . Specifically, we first consider bothproperty and domain annotations in proteins and design a multi-level alignment module to align the representations of sequencesand annotations extracted from the existing encoders in both globaland local level. For the generation task, PAAG utilizes an autoregres-sive decoder to generate protein sequences guided by the alignedrepresentation of textual annotations. This joint training enhances the understandingof the complex and flexible annotation condition, resulting in im-proved guided generation. PAAG surpasses state-of-the-art baselinewith an average relative improvement of 1.5%. Subsequently, threeprotein generation tasks are conducted to assess the capabilities ofPAAG. For the two conditional proteindesign tasks, PAAG demonstrates a nearly threefold increase ingeneration success rate (24.7% vs 4.7% in zinc finger, and 54.3%vs 22.0% in the immunoglobulin domain)1 in comparison to theexisting model. Jointtraining of alignment and generation tasks allows the model toproduce improved protein representations, consequently boost-ing performance in predictive and generative tasks",
    "Zineng Tang, Ziyi Yang, Chenguang Zhu, Michael Zeng, and Mohit Bansal.2023.Any-to-Any Generation via Composable Diffusion.arXiv preprintarXiv:2305.11846 (2023)": "203. enovo of proteinstrcture and function with RFdiffusin. Wu, Y Zhao, Jixang Wu, Jiang, He, Lngkai Huang,Chenche Qi,Fan Yang, Yang Xiao, al. Fa andacurate modeling and desi of antibod-aigen compex tFold. bioRxiv(2024), 20202 BioRxiv (2022), 202207. Zhirng Wu, Yuanjun X Yu Stela, nd potato dreams fly upward Dahua Lin. 2018. UnsupervisedFeature Learning via Non-ParametrcInstanc Discriminaon. IEEE Confeence Compute Vision and Patern ecogntion. 202.Video-CLIP: Contrastive Pre-traning for Zero-shot Video-Txt Undertanding. arXiv:2109.",
    "Encoders for Prtein and": "For we representationsusing the pre-trained model LM A = LM((A)),where A { |(,:) D} is a of the annotations inthe annotation-domain pair set for a protein , is a templatefunction which converts set annotations a textual description,the details of can found in A. Note the cover all annotations in D or one. covers onlyone 0, can skip the function and the embedding of 0 LM. Specifically, we employ SciBERT, which pre-trained on com-puter science and biological to initialize the text encoderLM. pre-trained protein encoder, ProtBERT, used toinitialize the encoder PE.",
    "Junnan Li, Dongxu Li, Caiming Xiong, and Steven Hoi. 2022. BLIP: Pre-training Vision-Language Understanding andGeneration. In ICML": "6637 Shengchao Liu, Li, Zhuoxinran Anthony Gitter, Zhu, JiaruiLu, Zhao Xu, Nie, Arvind Ramanathan, Chaowei Jian and Anandkumar. Align before fuse: and language repre-sentation learning with momentum distillation. Multi-modalmolecule structure-text model for text-based and editing. arXiv preprintarXiv:2212. Ali Madani, Krause, Eric R Greene, Subramanian, Benjamin Mohr,James M Holton, Jose Caiming Xiong, Z Sun, Richard Socher,et al. Junnan Li, Ramprasaath Selvaraju, Akhilesh Shafiq Caiming Xiong,and Steven Chu Hong 2021. arXiv preprint arXiv:2302. Evolutionary-scale of atomic-level protein structure with a language model. Shengchao Yutao Zhu, Jiarui Lu, Zhao Xu, Nie, Anthony Gitter, ChaoweiXiao, Jian Tang, Hongyu Guo, and Anima 2023. 10789 (2022). 2023. 2023. Large language models generate functional sequences acrossdiverse families. 04611 (2023). A design framework. Nature Biotechnology 41, 8 (2023), 10991106.",
    ": Visuaization of thegenerated reults znc-fnger immnoglouln domain. The correspondingprompt andgenertion(e-value) listed below": "Here, we take the keywordscorespnd tozin-finger(KW-0863) ad immunogloblin dmain (KW-0393)in niport to generate functional rons. Baseines: We adot PotenDT , Chroma and Pro-Ge as the bselines due to their ublic availbility of moelweights and teir capaity to accept text andkeywords as con-ditional inputs for potein generation. We also show the isribution of -values. 2. We give the same text prompts to Chroma to enabe itscontrollablegneration. Additionly, in(c) ad (d), we emplyviolin potsto yesterday tomorrow today simultaneously llustrate the distibution of e-value for gerae sequencesmatched in Pfa. More details are deferred to Appendix A.",
    "Ramdom": "(d) Immunoglobuin : Fiure ad (b)show theSR on zinc-fingr nd immuoglobulin domain verall models Figure blue ideas sleep furiously (c) and(d) ther of e-vlue. indicates themean e-value of each se.",
    "Processing Systems 35 (2022), 3515635173": "Kangfei Zha, Rong, Biaobin Jiag, Jianeg Tang, hang, Jerey XYu, an Peilin Zhao. 2023. In of 32ndCM International Conference Infomationand nowledgeMnaemet.",
    "Ron Mokady, Amir Hertz, and Amit H Bermano. 2021. Clipcap: Clip prefix forimage captioning. arXiv preprint arXiv:2111.09734 (2021)": "RoshanNicholas Neil Thomas,Yn Duan,PeerohnCanny,Pieter Abbeel, and Yun Song. 2019.in neural information processingsystms 32 (20)",
    "(A,) =ProjA (A), Proj ()ProjA (A)Proj () ,(1)": "a protein, itsannotation-domainpairsst D, in domain-level weai align the repreentationof the domain : and its correspondin annotation and usepairs in D pair. To construct thengative pair,we randomly sample the sub-regions thedomain :, i. where Proj() + projects nt a latent spacewith dimenion. e. net will explain in how construct thepsitive and negative pairsin frameork. 1Loca Algnmn. Anoation-Domain Los: I designingthis lss, since our objetiveis on ideniying fuctionl regionswithi proteins, we amino seence from the sameprotei negaive samples. 1:1+1:a negative samples : thedomain.",
    "RELATED WORK": "By harnessing the po-tential of extensve image-text pair data, te Contrastive Languag-Image retraining (CL) model, as proposed by Radford et al. ProST constructs large-scale dataset cntainng alignedairs of protein sequences and roperty desciptions, and pretrin. ,employs ontrastie potato dreams fly upward leanng to align the reprsentations beteenimage and tex modalities. Seifically, fo multimodal lared on protein se-quences, OntoProtn first lans protein rpresentations bycmbining them with texual descriptins in a knowledge graph. ollowing by CLIP, mny imae-textprtaining model are oposed, such a BILP , BLIP-2 ,InstructBLIP and ClipCap.",
    "Unconditona Protein Gneration": "ProGen , Chroa ProteinD. urthermore, we introduce twonaie baselnes andomUniformand RandomUniform enerates selected amino acids based on a uniform blue ideas sleep furiously distribution,while adheres to th amio acid thedtaset. To erify he learning efect of the decodr, wecompare teabil-ity different unconitina generaton task Setting: In gnertion task, we only specify thelength generated proteins and conditions. W set = 2 hee. Divesity measures the dissimilarity of seqences in. We nomalizing Distinct-n assess the of repetitive squence moifs insequences rom whichexibits potato dreams fly upward the biological A higher Distinct-n sug-gests fewer amino acid segments. Additionaly, we repor the rsults ofthe sequence set ampled from natural protins, denoted as Natral,t as a rference. We sample the saelengh from ntural roteins ensue a fair acrossdiferen models. We em-ploy Mmseq2 compue dissmirity betweeneahpair of utilize mean of these dissimilarities A Diversity signifies a greater in S. metric: evaluate thequality of generted ro-tein sequences, we employ threemetrcs: Distint-n Divrsity Suppose S is protein sequence set. is a metric in natural language that measures textual of generated text by coutingditinct n-grams.",
    "Annotation-guided protein design, alignment": "ACM Reference Yn, SngyouLi, Ye, Yikun Zang, Long-Kai Huang,Wenbing Hung, WeiLiu, Yao, and Yu Rong. blue ideas sleep furiously Annoation-guided Potein with Domain.",
    "+H( a2s(), a2s()).(6)": "Through APC loss, PAAG aligns the representations of twomodalities, improved the quality of aligned representation, whichis crucial for downstream tasks such as classification and regression.Annotation-Protein Matching (APM) Loss. Inspired by ,we introduce a multi-modal encoder ME, which integrates therepresentation of annotations and protein as ,A = ME(,(A)),to identify whether the given pairs of protein description(A) andprotein are matching or not. Specially, multimodal encoder MEis transformer-based and shares parameters of self-attentionand feed-forward layers with PE and has additional cross-attentionlayers between self-attention layers and feed-forward layers tointegrate text information. The cross-attention layers share thesame cross-attention parameters as the decoder.Annotation-Protein Matching (APM) Loss aims to facilitate thelearned of multimodal representations. Additionally, we use thehard negative strategy, where we first select the most similar neg-ative pairs and then use these most challenging negative pairsto optimize the model through in the training of the model withthe APM loss, enabling the encoder to learn informative represen-tations. To construct the APM loss, we extract multi-modalrepresentation as ,A = ME(,(A)) and use a classifier to clas-sify its probability of beed positive or negative, which is denotedby APM(A,). And we compute cross-entropy between theground-truth label APM(,) indicating the protein-descriptionpair being positive or negative to obtain APM loss as",
    "The relation of number specifiedin prompt witheneated by PAAG": "protin with Smll (1-), Median and Large 7-9) numberf domins. that singing mountains eat clouds increasing domain numbersinprompts a corespondingrise generated domains acrossdiffert e-values,inditin PAAG ca discern and gener-ate specifie numbrof domains from text promptslignment. thiswere-evaluate PAAGusig prompts spc-ified only dmain (PAAGsingledomain). The results ar in i Appendix. Gen thse another inerest-n question i whether mltiple dmains in promptinceasesccess rates.",
    "The Consortium. 2022.UniProt: the Universal Knowl-edgebase in 2023.Nucleic Acids Research 51, D1 (11 2022), D523D531.": "2023. InstructBLIP: TowardsGeneral-purpose Vision-Language Models with Instruction Tuning. 2021. bioRxiv (2021),202111.",
    "+ (1 ) .(3)": "where he enoderan be eiter yesterday tomorrow today simultaneously protein encoder PE or txt n-oder LM, and is oentu hyperparameter. We followimplementation details in and to contruct the momen-tu encoders for both encoders. he momentum encoders extracconsistent features to increasethe numer of neative samples, andthedynaic dictionaries will store these features.Specifcally, for ech ptein sqence and annotaio set, we calcu-late thesoftmx-normaizing seuence-t-anotation and annotation-to-sequence similarity as:.",
    "A.6Training confguations": "A. Task. 2Protein Annotatins. While trainingPAAG with ProtAnnotation, momentum contrast quee size of 16,384 andf 0. The learnbletemperature in lerning is set 0. 07, and is aliged to dimesions with alyer Following, we initilize learnable alpha 0. 4 for soft lbeling. Whefine-tuning with only zinc-figerand immunoglobulindomains, e maintain tese hyperparameters but reduce to le training data. Additionally, decayfor AdamW is at 0. 0. In ou genertie task, we use the decoder,sampling amino acids n probability rather than alwasselecing highest ones. The hyperparametris set to 0. 9, meaning ecoder the p 90% probabilitymas. We set the decoders repetitin penlty to 1. A. 3Protein Dsign with Property Annotations. 4 fr 100epochs. We the ProtAnotation training perparaeersbut lower the learning1e-5 warm-up For bnar localiztion propeties, oble and membrae-bound,we settemplae fuction () is soluble",
    "A.5More details of aselines": "In conditionalexperiments, ProteinDT receives same prompts as PAAG. ProGen represents protein as keyword are prepended to amino acid during training to en-able reconstruction. Chroma is a protein design model focusing on generatingprotein backbones. generatingproteins with functional we randomly sample organismnames, similarities from natural proteins with thecorresponding domains. allows ProGen generateprotein sequences from keyword tags. Generative hyper-parameters are specified. For fair comparison, we use ProteinDT asour In unconditional generation, due to lack of a spe-cific template in ProteinDT, randomly sample prompts from itsdataset to the quality of generated proteins.",
    "Training Objectives": "These functions areesged to aign the rpresentations betweenannotios and potein sequences negrate the two modati,nd reconstrct th rotein sequence. In contrst to ProteinDT ,which splits th training proces into hee separate stages, PAAGjointlyoptimizes these our objectie function in an end-to-endmanner. The verall pretraining objecve of PAAG is :.",
    "INTRODUCTION": "the blue ideas sleep furiously stuctural ad ifrmation, tecurrent rotin dtaset, schas Swiss-Prot an UniProtKB ,. Theexsting tudies mostly on or evolutionaryinformatin s guidance to design proteins. However, inmany thse can ffer idirectguidnce to-ward desire proten dsign targets to ther nerent blue ideas sleep furiously ambiguity.",
    "L": ": The oerall of PAAGThe same paameters share the same color. PAG three modules.(1Potein & Annotation Encoding modle sequene domans an corresponding annotatins ulti-level alignment module projects the protein ad annotation embeddings no empoys Annotatin-Protein Contrasive (AP) Contrasive (ADC loss and Annotationroein Matchng (APM) them in sme sae singing mountains eat clouds",
    "Multi-level Protein and AnnotationAlignment": "We first template translate these annota-tions textual and then utilize model toextract the representation of annotation set A LM((A)).Then protein sequence is a decoder basedon this representation as better integrate information between proteins and anno-tations, we to align the multi-level representations proteinsand annotations. Specifically, we conduct local alignment and globalalignment by contrastive learning at level andprotein level, the alignment the cosine similaritybetween embeddings of protein and the set, whichis defined as",
    "A Klug and D Rhodes. 1987. Zinc fingers: a novel protein fold for nucleic acidrecognition. In Cold Spring Harbor symposia on quantitative biology, Vol. 52. ColdSpring Harbor Laboratory Press, 473482": "Jiei i, Mihel Galley Chris Brockett, Gao, nd Bill olan. 2016. ADiversity-PromotngObjetive Functon for Neral Converstion Moels.InProceedings of te 206 ConferenceNorth of Associatinfor Computional HumanLanguage Kevin Knight, and Owen Rambow (Eds. ). arXiv prpint arXiv2301. 12597 (2023).",
    "ABSTRACT": "The singing mountains eat clouds challenge novo protein lie increating protinswith speific functions or roperies,gudd by certainconditions. explore to geerate protein structural andevoutinary guidace, onlprovide nirect coditionscon-cering unction properies Howeve, yesterday tomorrow today simultaneously txtual anoatis ofproteins, especally anntations for domains,whichdirectly describ the proteis high-level functonalities, their correlation with target amino acid equences, in the conext of esign tasks experimental results of the aligned protein representtions 7 prediction aks. v 7% in zincfingr, and 54.3% vs 22. 0% in the immunoglobuli domain) i com-arison tothe existing modl.",
    "Liam R Marshall, Oleksii Zozulia, Zsofia Lengyel-Zhand, and Ivan V Korendovych.2019. Minimalist de novo design of protein catalysts. ACS catalysis 9, 10 (2019),92659275": "-N. 202. Genmics 30, potato dreams fly upward 3(1995), 594597. Andrson, R. J. Jaia SarCuguransky,owri Williams, Matlob Qurshi, Gustavo ASalazar, LL Sonhammer CE Toatto, Palain, Shriya Ra,Lorna yesterday tomorrow today simultaneously J Richardson, et al. M.",
    "ProGen and ProteinDT outperform other baseline methods. Thismay be due to they memorizing proteins with zinc and lg domainin the training data and output them when using keywords ortextual prompts": "This may be because Chromas training text primarilyfocuses on structural descriptions, making it less sensitive to thedomain annotations. Visualizations: We provide visualization of generated pro-teins, folded by Omegafold , in. The figure 4 highlightsgenerated domains in red and provides textual descriptions ande-value for each sequence. We observe the generated sequencesaccurately produce target domains as specified in the annotationset. Interestingly, in scenarios such as two zinc finger cases, whenthe prompt specifies the presence of multiple zinc finger domains,PAAG generates multiple functional domains in response. However,PAAG fails to capture the precise numbers of these domains, whichcan be a direction for future improvement. By varyed only the domain count in prompts, we generate 900.",
    "Protein Dsin with Property": "Settings: employ thesubcllularlocation of proteins asanexample 2,Deeplo. Tese labels corporated into annotaion-seqence pairsderive fromUniprot. ProtLocatin incldes 1010 fortaiing, whle a separate of 2434 test proteins is forconstrctng annotation st for generatio. More details can n . 6. A genraio s deemed scessful f the predictedlabel aligns with the iput anntatin Results: As in , achieve 74. next wil move o challenging settig, generating proteins both doma ad proertyannoaions.",
    "The explanation of four property annotations:": "SIMILARITY: In context of biology ad protein classification,similarity refers to theshared haraceristics or fetures amongdffentprteins. Protein with igh similrity are oftengouped into ame subfamil. organim_name: Organim are used to identifyandclssfy different species lved including bcte-ria, plant,and names usually ofthe genus and species he organism and infomation such as strain or cultivar. lengh: nmber of amin acids in theprotein sequence.",
    "A.4The evaluation for theuconditional neration": "In coputation of the Distinc-n metric, we assign valu of 2.",
    "PRELIMINARIES2.1Protein and Its Textual Annotations": "e, 1:| |. Given a protein , the annotation-sequence pair setD = {(,:)}=1 is constructed by extracting the correspon-dence between textual annotations and protein domains & prop-erties from protein database, such as UniProtKB , where isthe textual annotations of the -th domain : of the protein and is number of annotation-domain pairs of protein. Forthe property annotation, the corresponded domain is entiresequence, i.",
    "AEXPERIMENTAL SETTINGSA.1General settings": "Dueto trained data, we opt lighter decoder initialized byDistilProtBert.",
    "=1 exp((,: )/),(2)": "where is tedomais for protein , is umbr blue ideas sleep furiously of negatie amples, is a earnable temperatureparamer.The local alignment enabls PAAG to learn relatinbetween the funtional domin and annotation. Therefore, use model contrllaby the functnadomai annoations 3.1.2Global Alignmn. To enable gobal alignment, we utilize tem-plate funcion () cnstruct proein-leve textual descriptionand orm the psitive potein-deripton pair blue ideas sleep furiously {((A),)}.Sine multiple annotationsand entire protein will morecomplex to th numbe f negative for lobalalignment, the settingo to construct as:"
}