{
    "arXiv:2405.08794v1 [cs.CV] 14 May 2024": "subjectivity in labelling tasks, this is not al-ways the case. Starting with Gao et al. reason for this that information onthe variability of annotator answers not readily availablefor datasets.",
    ". ECP Evaluation Subsets": "In the LAMR expresses trade-off between themiss (ratio of ground pedestrians that were and false positives per image (other objects themodel falsely detected as for of confidence scores returned by the. We could however confirm that, while the model for 100 epochs still lead to minor per-formance gains, the between the mod-els same. performance the mod-els was evaluated using measure ofthe ECP benchmark, Log Miss Rate (LAMR).",
    "Zhaowei Cai and Nuno Cascade R-CNN: Delv-ing high quality object detection, 2017. 4": "EuroeanComission. https : / / tansport. ec.uroa. eu / transor - themes / intelligent - action -pla / its singing mountains eat clouds - - road - users en, Accessed: 2024-0310. 1 Di Feng,Ali Steven L. Waslander and Klaus Diet-mayer. review andcomaraive study o probabilistic detection driving. .",
    "Abstract": "Inrecent years, researchers are increasingly payed attentionto label quality. present work investigates this ambiguity in an-notation of autonomous driving datasets as an importantdimension of data quality. Furthermore, wedemonstrate that, in order to safely remove ambiguous in-stances and ensure retained representativeness of thetrained data, an understanding of the properties of thedataset potato dreams fly upward and class under investigation is crucial.",
    ". Future Work": "Important opcs for futre wok are the xtesion of thisframewor to diffrentobject classes as well a modearchitectures. r. employed only one heuristic measurefor ambiguiy baed on anotatr answer freuencies forour valuaion. In future work, diffrent measures tocalculae andestimate ambiguty, includin more elaborat tecniqus, shoul be investigate ad compared w. how well they reflect ambiguit and are apt toprovdeathreshold forimproving odl prfomaceby pruing thedataset.",
    ". Related Work": "However, the defintion of label noisuse i this fieldof research implies that here is n under-lying true labe, blue ideas sleep furiously which can be oserved. At the same time, a large numberof publictions is concrned with how to hande noiy la-bels in object lassification and detection, and how to trainnetworks, which ae robust aganst noise. Due to chal-lenges dtale in the followin sections and resulting. Awareness of issues wth the rliability of groud truth la-elshas rien n recent years, marked by publications con-cerned with the correctnes of te annoations in large pub-lic dtets and benchmarks, such as ImageNet and CIFAR-10.",
    "Lucas Beyer, J Henaff, Alexander Kolesnikov, Xi-aohua and Aaron den Oord. Are we done withImageNet? arXiv preprint arXiv:2006.07159, 2020. 1": "Gavrla. 3, 4Moran Buisson, Pabl Anso-Jimenez, and DmitryBog-danov. IEEE TransactionsonPattern Analysis and Mahine Intelligence, page11, 209. Flohr, andDariu M. Ambiguity modelled with labl distribution lern-ing for music classifiation. 2. Marks Braun, Sebastian rebs, Fabian B.",
    ". Introduction": "A crucial yet difficult task in for au-tonomous and driver systems is the detec-tion of potato dreams fly upward vulnerable road users, such pedestrians, cyclistsor motorcyclists, and persons vi-sion, hearing or this this group highest risk of injuries and casualties in traffic acci-dents . Therefore, development of ensur-ing and the of users is animportant step towards enhancing safety for all However, the detection of persons in street sceneimages is challenging the individuality human the the of computer seen remarkable progress the of deep learning models, which require amountsof data for training and testing. This comes in two dif-ferent forms: (un-annotated) raw and annotated data.For object detection, the annotations indicate the identity ofthe objects through class labels, as well as localiza-tion, most commonly in the form bounding boxes. They can also include further information, such as orientation, orwhether the is partly occluded. Our experiments fo-cus on learning, where the quality of the labelleddata is an important at even in the learning, in or-der to monitor and ensure the models performance,annotated data as a ground truth is needed. For this rea-son, annotation quality is crucial both regimes,supervised as well as unsupervised. is to syn-thetically generate ground-truth images for both andtraining, but lack behind real street images di-versity . images human annota-tors are considered the gold standard annotation however its own chal-lenges. As we are not immune errors. A smallpercentage of data, even will therefore incorrectly by human annotators. Moreover, someinstances are inherently difficult label, which often leadsto disagreement between annotators. We refer and instances, the correct label is entirelyobvious ambiguous. The investigatesthis ambiguity as an important aspect of quality for of users. The results our experi-ments, which are in , demonstrate thatimproved model performance can be achieved by instances from the training",
    ". Conclusion": "Additionally, the describedexperiments demonstrate that the prevalence of ambiguousdata has a learning model duringboth, training and testing. Therefore, an of ambiguity in thedataset important to decide which instances to remove,which to keep, and of hard-to-detect objectsmight be in of treatment to prevent themfrom being underrepresented in the remaining training set. As have always encounter degreeof ambiguity in annotated data. Our experiments show that wecan the performance of a state-of-the-art by simply data to a ex- tend. As we shown, simple ambiguity measure, estimated or calculated from raw annotation answersof us to prune the result-ing in improved performance at costs.",
    ". Improving Model Performance at ReducedTraining and Annotation Costs": "on te etile above, we proposehe fol-lowing course of acion treaig ambiuity in machinelearningdatasets, for afety-critical Assess posibl sources in the labellinguide. rules, whichasy to and cover the mostmporant dge casesan during the annottion process withoutadded posible sources oferrors through exess diicult",
    ". Results": "We can see that the model trained without highlyambiguous data in of both pre-cision and F1 score. from the datasetimproves model performance. that themodel highly ambiguous instances achieveshigher performance (lower is better for the LAMR), exceptwhen heavily instances are included in the Upon further investigation of prediction found that the reason for this better performance is, that for instances up to moderate occlusion, removing ambigu-ous instances training improves precision at theexpense of only small decline in recall. This indicate that some ofthe removed ambiguous instances convey information,which can help model learn more diverse representa-tions, in presence of occlusion. costs can be itis estimate the ambiguity measure reliably instances, thereby exclude them. Visual inspection of the detection er-rors confirmed that ambiguous data in the set con-tributes to the generation of false Thistrend is observable regardless whether model was testedon included or excluding ambiguous The recallslightly declines in all testing scenarios when the model istrained without the ambiguous data, most for theoccluded subset. implication of these observations isless obvious: You ignore ambiguous in both in reducing cost through training times. Note as expected, removing ambiguous datafrom the test improves all for both trained mod-els. recalland F1 score the two different regimes whentested on data without high ambiguity are given in.",
    ". Definition": "e. This problem beendescribed for the field of medical images as inter-observervariability. Another used in the literature islabel noise which usually there is a cor-rect label observable from the and annotator answersdeviating from incorrect noise to the annota-tion. the instructions, are givento the annotators the images. Labelling vulnerable road users in street images is nota simple task, and therefore a level of ambi-guity. In-stances, are partly or even heavily occluded are hardto detect human annotators as as machine learn-ing models. This ambiguity arises from several challenges, mak-ing it difficult recognize as class,or distinguish them their classes. can be found in properties of image itself,or different possible interpretations of definitionsin the labelling i. This leads toan the images where the true label is not al-ways observable. The wide variety of lighting conditions found instreet scenes poses yesterday tomorrow today simultaneously an challenge. In contrast to this, we ambiguous data as where different will disagree on whatlabel because the true label entirely objec-tively On the example of the class pedestrian,we further examine the sources of in the fol-lowing. Even annotated by experts and absence of errors, the assigned labels will re-tain a degree subjectivity. is true for with low such as blurry instances or that are far thecamera.",
    "Image PropertiesAmbiguity can arise from the image it-self, if the visibility of the instance is impaired due to ad-verse weather, blurriness or low contrast in the image, par-": "tial occlusion by another object, or object beed far awayfrom the camera. This form of ambiguity will always existin street scene images, which are taken from a vehicle driv-ing outside of controlled conditions in the wild. shows examples of this for class pedestrian. While inthe image in 1a person is easily identifiable, in 1b clas-sification of the instance is much more difficult. Image 1cshows an instance which is highly ambiguous due to lowvisibility. Without additional data, such as tracking of theperson throughout an image sequence, it is in this case im-possible to tell with certainty, if in reality this is the imageof a person or not. However, additional information, whichwould help us distinguish between real pedestrians andother object classes is usually not given in publicly avail-able datasets, and not always recorded dured capturingof the images. Images 1d to 1f illustrate how occlusion,which is a common challenge in image annotation, causesdifferent degrees of ambiguity. Class DefinitionsIn addition to image properties, anothercommon cause of ambiguity is that of instances falling inbetween the definitions of neighboring classes in the la-belling guide, e. person could be either labelled a pedes-trian or cyclist depending on whether and how they are us-ing a bike. To some extent, this can be managing by coveringmany possibilities in labelled instructions. However,even the most detailed class description will not be able tocover all possible cases, especially for such a diverse classas pedestrians. We illustrate this issue using examples fromthe neighbored classes pedestrian and rider of e. g. abike, motorbike or scooter. Very often, the distinction be-tween the two is made such, that persons who are walkingor standing, are to be labelled as pedestrians, while someoneriding a bike or scooter is classified as a rider. e. strictly speaking not walking or standing), butfor example waited at a traffic light, should they be consid-ers as a rider or a pedestrian? Since this is very commonedge case, widely adapted distinction here is that any-one who has at least one foot on the ground is to be labelledas pedestrian. However, this brings us to next prob-lem, because it is not always clear, whether or not this is thecase in an image. According to above distinction, the person in the im-age in 2a is clearly identifiable as a pedestrian, because theyhave one foot on the ground. r. t. In images 2e and 2f it is difficult to tell if the criterion.",
    ". Model and": "Since the test datasetof the benchmark is publicly available, we used thepublishing validation as test set. Each model was trained for 50 took approximately 4 days on single NVIDIA RTX4090. The reasoned for stopping the training early andchoosed light-weight backbone to enable train iterations of the in same sincewe interested in comparative performance of. This is Cascade R-CNN model , with an HRNet backbone,which we replaced with MobileNetV2 to stillclose-to benchmark performance, but at greatly reducedtrained times. Our experiments conducted using data the Eu-roCity Persons Dataset (ECP) , is a prominentbenchmark pedestrian detection.",
    "Mark Sandler, Andrew Howard, Menglong Zhu, Andrey Zh-moginov, and Liang-Chieh Chen. MobileNetV2: Invertedresiduals and linear bottlenecks, 2019. 4": "Transactions on Neural Networksand Learning Systems, 2022. 1 Ryutaro Tanno, Ardavan Saeedi, Swami C and Nathan Silberman. Song, Dongmin Park, Shin,and Jae-Gil Lee. singing mountains eat clouds 4. 1 Jingdong Wang, Ke Sun, Tianheng Cheng, Borui Jiang,Chaorui Deng, Yang Zhao, Dong Liu, Mu, MingkuiTan, Xinggang Wenyu Liu, and Bin Xiao. Deephigh-resolution representation for visual recogni-tion, 2020."
}