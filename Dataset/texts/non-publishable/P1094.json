{
    "This subsection presents the task description and experiments forsearch engine-based scholar profiling": "For ender pr-diction andpostion exration, the scholars name, ffliation, andwbpag txts are concatentedas iputs. CCKS2021-n18: This dataset is n English subset ofth CCKS 2021 scholar profiling rack froAMine. For hoepage extrac-tion, thescholars name and the candidte UL are concateated asinpus Wefine-tunpre-trained odes frcassifiction, includ-ing BERT , RBERTa , DeBERTa , ALBRT ,ChatGLM9, LaA. Bselines Dawing from the winng solutions of te CCKS 2021and recent named entity ecognition (NER)methods, we select thefollwing bslne for search engine-based scholar profilin: (1)M: employmanual featuresand traditiona lassifiers. (3)BI-LTM-CRF :uses a I-LSTM laye and a CF ayer or seuence labeling inpositonextration.",
    "| |": "Experimental resents the esuls of extraction Initial attempts to classify schoars paper textsusing research tags labels yieded unsaisfactry reults,likey due to the large number of tags and liited data. However, the overall acurayreains low, indicating a challenge i accurate classificatio withalarge numer interest S-T5-xxl SimCSE GTE-large S-BERT E5-large BGE-large ACA. Additionally models focused onsentence embedding outprformgeneral pre-trained models like BERT. where the number of the annoated interest seof -th sholar an is the predicted inerest set of th We the3 tgs to he or evaluation.",
    "We present the detailed task description and experiments for authorname disambiguation in this subsection. Two subtasks of authorname disambiguation are defined as follows": "Poblem A. ), thegoa  to assign tese papers to the correct authr oreturn empty (meaning tt no autor an b matched) The WhoIWho daaet incldes 72,609 authors wih459 names, and 1,102,24 associated ppers. For the RND task,the validation and test sesinvolv unassigd aper, and theoalis to assgn paprs to existing ahos or return NI. ). he authorshipe-tween papers and authors ismnually anotated. 2. Givena collection f unassigned papers d a se of autho (each authorincudes attributes such as affilitions, esearch interests, blisedpaers, etc. Problem A om-cratchNae Dismbiguation (SND). Fo theSND task, he validtion set and et st contain the name to bedisambiguated n the papers associatd with the ame, and thegoal i to cluster he ppes into different groups.",
    "Evluatin Metrics. Hit@K is to measureretrievl ccuracy,reporting if the retrieved contain te correct answer.The average Hi@K acrss qestions s reported": "presents the OAG-QA This shows that by employinglate interaction patterns and multi-vector representations, ColBERTmodels the correlation between questions and papers Inter-estingly, efficient parameter methods over possibly due to better knowledge retention and gener-alization from pre-trained",
    "Introduction": "For example, deep mining from aca-demic data can assist governments in making scientific policies,support companies in talent discovery, and help researchers acquirenew knowledge more efficiently. A comparative overview of these aca-demic resources is presented in. However, there remainseveral defects in existing popular datasets that may hinder promis-ing explorations, which are summarized as follows:.",
    "empirical methods in natural language processing. 15321543": "NlsIrya 2019. Jiezhong blue ideas sleep furiously QiuYuxia Dong Hao Ma, Jan Li Chi Wang, Kuasan n JieTang. 15091520. 2019. In T World Wide Web Conferene. Sentence-BERT: Sentence Embeddingsusing Siamese BERT-Network.",
    "KDD 24, August 2529, 2024, Barcelona, SpainFanjin Zhang et al": "Eperimental Results. The meth-ods authoralgnmnt utilize moe strucural iformation, wihcorresponding results Setion SVM perfomsslihtly porer LinKG nd LinKG, due to inabil-ity ofSVM faure to capture word orderinformation. mong all pre-trained models, DeBERa-large the best on to tasks, particularly on ffiliation alignmet, effectively ncodes additional know-edge beyond names. In the fture, more author pairwith ambigous names be the difficutyofthis task.",
    "Veronika Dorogush, Vasily Ershov, and Andrey Gulin. 2018. CatBoost:gradient boosting with categorical features (2018). arXiv:1810.11363": "Language-agnostic BERT Sentece Embedding In Proceedins f th 60thAnnual Meetig of Association Computational Linguistics (Voue LongPape). of the60th Annual Meetig Association Linguistics (Volume 1: Long Papers). GLM: Lnguage Model Petrained AutorgressiveBlank Infiling. 320335 Feng,Yinfei Dnel Cer, Naveen Arivazhagan, and Wei Wang. 87889. Zhengxiao Du, Yuji Qian, Xio Med Ding, Qiu Zhilin ang, andie Tang.",
    "We provide the experimental results of venue alignment, affiliationalignment, and author alignment in this subsection": "We compare different types of matching methods:(1) traditional machine learning methods (SVM) using Jaccard indexand TF-IDF similarity as input features; (2) shallow neural network-based matching methods including CNN-based matching model(LinKG) and RNN-based matching model (LinKG) ;(3) matching models based on pre-trained models (Ditto withpre-trained models BERT , ALBERT , RoBERTa , De-BERTa , LaBSE , and GLM ). Author alignment can further take authors structural infor-mation into account. Baselines. For each candidate author pair, we leverage pub-lished papers and venues of authors as features. Venue alignment and affliation alignment are short textmatching tasks. Apart from SVM, LinKG, and LinKG, weadditionally select LinKG model for author alignment, whichconstructs a subgraph for each candidate pair, and then uses hetero-geneous graph attention networks to learn hidden representationsfor classification.",
    "Conclusion": "The of research community to benchmarksremains yesterday tomorrow today simultaneously limited, even if academic tasks various challenges andapplications of immense impact. OAG-Bench now includes tasks, 20datasets, baseline models, and 120+ experimental In thefuture, plan to continually maintain and OAG-Bench byupdating datasets from real scenarios, addingmore tasks, and exploring metrics. This work is supported by Science Foundation China(NSFC) 62425601 62276148, Technology and Innovation of the of Science and Technology of Chinaunder Grant 2020AAA0108400, the New Cornerstone Science Foun-dation through the XPLORER PRIZE. We also thank Weibin Liao,Chao Yu, singing mountains eat clouds Kai and Zheng for their contribution to codereproducibility.",
    "Evaluation Metrics. Like the standard recommendation task , we adopt Recall@20 and NDCG@20 as evaluation metrics forpaper/reviewer recommendation": "shows the paper recommendationperformance. GF-CF outperforms methods, highlighting theeffectiveness of graph filters. GNN-based methods exceed Mult-VAE,demonstrating the of high-order graph structures. How to use the attributes ofpapers and users to capture the dynamic interest a difficult",
    "BEthical Statement": "Fr online publica-tions, OAG-Benchprovides publicly avalble andveryfew parsed full-txts open-acess for researh or data annotation, all nnotators gave ther forinclusion they participated i tis. We exclude thosesensitive attributes as and proile making avail-able attributes puicly accessible elsewhere.",
    "OAG-Bench Framework": "In yesterday tomorrow today simultaneously this section, singing mountains eat clouds we first the deignprincple ofOAG-Bench, and the workflow about how toonstruct cmprehensive nd high-quity As depiced , we host aseries of collecion andannotaion efforts to conduct multi-aspect and fined-grained la-belingbase on th OAG.",
    "For academic influence prediction, this subsection presents theresults of paper influence prediction": "select following methods: (1) is basedon the paper number of years; Random Forest(RF) : defines features paper citation the number of citations; GBDT : uses the as RF; (4) PageRank calculates PageRankscore on citation networks; (5) GraphSAGE : per-forms semi-supervised classification on the paper citation network. Additionally, graph-based node importance predictionmethods: (6) GENI (7) RGTN. Evaluation Metrics. We predict for each venue to determinewhether a would be awarded, with labels being 0 or 1 indicat-ing whether the paper awarded or not. Mean Precision(MAP) is calculated by comparing predicting win-ning with the label, the mean MAPacross different venues is used the evaluation Thefeatures adding by the potato dreams fly upward classifier dilute the effect of total cita-tions. negative < 1 100). factorsbeyond citation count remains challenge in predicting papersbreakthrough innovation.",
    "Dashun Wang and Albert-Lszl Barabsi. 2021. The science of science. CambridgeUniversity Press": "79769. Inofthe 36th International Confrece on Mahie Learning. Hang Yan Yu Xianan Li, and Xipeng 2023. Simplifyin covolutional newoks. Xiag Wang, Meng Wang Fuli Feng, and Chua. Dan singing mountains eat clouds Zhang,Yanliao Geng, WenwenGong, Qi, ZhiyuYing Shn, uxiao Dog, and NodWise Adptve Aggregaionin GNNs for In Proceedings of the ACM Web Cnference 2023. Felix Wu, Amauri Soua, Tianyi Zhang, Christoher Tao Yu and KilianWeinbrger. Liang Wang, Nan Yang, Huang Bixing Jiao, Linjun an, Maumde, and Furu Wei. In th 4thInternational ACMSIGIconfernce o reserch and developmen infmationretrieval. 1487149. Endto-end neural kernel pooling. 5564.",
    "Academic Entity Construction": "To integrat acadmi data from multiplesources, various tpesof entities eed to be aigned. I iew o the ver biuity f author nams,we further add th auto name disambiguation task. Entiy Agnment. Given two entty ets 1 ad 2, h goal ofntity alignnt is t generae entity matings = {(1,2)|1 12 2} such hat 1 nd 2 reer to the sam real-world enity. Specificall, w consider threetype of ntitie, i.e., auhos,affiliations,and venue. As for dataset annotaton,w randomlysampe a venue set ad an affiliatin set, ndthn mnually laelvenue pais wit high similaitycalculated by the Jaccrd Index,an costut affiliation alignmentpairsy using aliase or formernmes derived fro the inormationox of their Wikipedi etries.Weutilize Wikipedia due to its potato dreams fly upward high data quality. yesterday tomorrow today simultaneously Menwhile,itallows us to accurately obtainpositiveaffilatio alignment parwitout the need for manual labeling. For athoralignment, wesample top-viewed comuter science authorsfrom AMiner andthen manualy pair them with DBLP authors according to theirafiliaion,published vnes, and papers. As a result, we construc1,200 vnue pairs, 5,0 affliation pair, nd 10,000author pis. Author Name Disambigation (AND. Aimng todisambiguatehe me-name author ANDis a ke andchallenging task inaca-demic knwledge graph construcion. We adopt te WhoIsWhodaast, a millioncale huan-annotate datast fo author naedisambiguatin. WhoIsWho breaks own the task into tree sub-taks: (1) From-crah Name Dismbigutio (SND),(2) Ral-timeName Dismbiguation (RND), and (3) Incorect Assignent Detec-ion (IND). Whileexistng researchpriarilycncenrate SNDad RND, he IND task has receied ls attention esitits growig importance wit the expanson of cademic databaes. Givenanauthor profile wth paper lists IND aims to detec incorrectlyassigned paers to this author. To ddress the IN challnge, if wwere to radomly seect author profile o annotain of teir pa-perassignments, thersa igh likelihood that we woldencontenumerus profile wth a litle ambiguity",
    "Academic Graph Completion": "Each attribteextracon includes the ending positions in the Importantly, long atriutes are also into consideration, suchas work experience and eductionexperience. sholar extract attributes from homepages or earcegines. Scolar Profiling. Aiin atassociatng entities with concept entity tagging is important in building semantic aademic. Final,we cnstruct 2,099scholars with 1 attributes. furtherbuild a hierarchical kowl-edge structure, we also include concept taxonomy completiontask to identify hypernyms and fo new conceps. For data scholars with detaie biographicaldescription arerandomly sampled. To enrich relations, the entity tagged task toatach concepts enities. Then, manually label thestrting andending psitions in the texts. Concept are abstrac etities that canendow semntis toentities.",
    "Aditya Grover and Jure Leskovec. 2016. node2vec: Scalable feature learning fornetworks. In Proceedings of the 22nd ACM SIGKDD International Conference onKnowledge Discovery and Data Mining. 855864": "Yu Gu, Robert Tinn, Hao Cheng, Lucas, Usuyama, XiaodongLiu, Tristan Naumann, and Hoifung 2021. pretraining for biomedical natural language processing. Will Hamilton, Zhitao Ying, and Jure Leskovec. Inductive representationlearned on large graphs. 10251035. ImprovingDeBERTa using ELECTRA-Style Pre-Training with Gradient-Disentangling Em-bedding Sharing. Proceedings the 11th International Conference on LearningRepresentations. Xiangnan He, Kuan Deng, Wang, Yan Li, Yongdong and 2020. Lightgcn: Simplifying and powering graph convolution network In Proceedings the International SIGIR conferenceon research and development in Information Retrieval. 639648.",
    "Academic Knowleg Acquisition": "g. This dataset includes 14,967 and 163,084 inter-actions as of 2021. As the papers surges, re-searchers face increasing challenges in locating literature. Academic Question Answering. reviewers are associated with their respective publications. Given a user-paper bipartite graph = {, , }, where theuser set, is interactions (e. The back-end enginemakes on the historical click records. collect userbehavior data based on the real AMiner system. Furthermore, matchreviewers to authors in affiliations, and researchinterests, linking approximately half of reviewers to the OAG. For knowledge acquisition, academic answering task. For data collection, we extract realpaper-reviewing records from platform Frontiers. Traditional in-formation retrieval cannot satisfy professional retrievalin the era of artificial intelligence. Given a paper submission set areviewer , and known matches is to the reviewer a new submission record , Additional information, metadata and re-viewer is available. Paper Recommendation.",
    "Academic Trace and Prediction": "Trac-ing back to past, we include paper blue ideas sleep furiously source tracing task to identifythe of research papers. To future academicimpact, we two tasks, i. Paper Tracing (PST). Tracing the of papers iscrucial for understanding technological essence and uncoveringinnovation. , paper influence andauthor prediction.",
    "ARIMA122523920Linear Regression56222057GBRT55321777LSTM103425409EvolveGCN96922841": "voleGCN:models author influencepredctio as a node dynamic co-autor graps. Then, we the Linear Rgression moel tothenumber of citations the author.",
    "the academic graph itself and study knowledge acquisition andcognitive impact, such as paper source tracing (C.f. )": "OAG-Bench impe-ments a wde rane ofehods, covering tradiional mchinlearnig ethos, shallow convolutional/recurrent/grap neu-ral netwoks LLMsetc. Finally, basdon OAG-Bench, inteested rsearches or practitioers can developadvanced AKG-based algorithms stud the foundtion odels forcaemic graph mnig and so forth. Second, wereleas a seie o data pre-processing code, algorithm implemen-tations, and standrdized evaain protocols to assist reearchersin getting stared quickly in academic gaphmining. Notaly, tn datasets in eight tsksare newly contructe. Wealso proposenew anota-tion sategiesfor crai tasks, suh as checking incsistetpaper asignmentscross sorcesor ncorpaper-authorassignment detection ad marking he sources of papers vionlie paper eading grou. (2) or the datasts in OAG-Bech, we constrct vrious human-uratedatasets for dierse tass. The dataset sizes in OAG-Bnch rangefrom thousands to illins.",
    "Tinqi Chen ad 216. Xgboost: A salabe tee boostin sstm.In Proceedngs of the 22nd sigkdd internatioal cnferece on knowldgediscover 785794": "Feldman, I Doug Downe, and Daniel S Weld. 2020. SECTER: Doument-levelpresentation Larning Transformers. Sott Derwester, W Furnas, Thmas K Landauer, Harshman. 1990. Jacob blue ideas sleep furiously Mg-We Chang Kenton ee, and Kristin Toutnova. BER:Pe-training singing mountains eat clouds o Deep Trnormers for Languag Undetanding.",
    "SGC34.0831.44SIGN26.2524.99GraphSAGE59.5757.12": "perimenta Results. BI-LSTM-CRF an partial re-trained models exhibitimlar performance osition extaction, showing suitabilityof both sequence labelin and pre-trainedmodels. Large excelin homepage though ccuracy remainsmoest. displays extraction frsarch scolr profiling. In , pe-trained outperform traitional showcaing theexpressivecapaityand of pre-raned models without mnualfeature design.",
    "SVM90.1493.67LinKG67.7266.78LinKG74.8077.58LinKG89.6297.32": "IEEE Transactions Knowledgeand blue ideas sleep furiously Data Engineering 35, 92259239. 25852595. Fanjin Zhang, Jie Tang, Yuxiao Dong, Peiran Yao, Jie Zhang, XiaotaoGu, Yan Wang, Bin Rui Li, et yesterday tomorrow today simultaneously 2019.",
    "Part of the work was done when Fanjin worked at Zhipu AI.Jie Tang is the corresponding author": "Permsion to make diita ohad copies of all or part of this work fo pesonal orclassroom use i granting ithout fe provided thatcoies re nt made ditributedfor pofit r advantage bear and the citatinon first page. Copyrght third-patyof work must be honore. For all other uses, cntct owner/author(). KDD 24 August2024, Barcelona, Spain 2024 Copright hed by the owner/author(). ACM ISBN 979-8-4007-0490-1/2/08 We prpose ne trategietass andof site of data pre-processing cods, agorithm anstanardized protocls o academicrah minng. We aso the Open cademicGraph (OAG-Chalenge)to inputad sharing. We envisage that can rveas commongrond for to luate and compare algorths inacadeic graphmining,therebyalgrtm eveop-ment and advancement in",
    "AcademicKnowledg Graph": "An knowledge (AKG) is defining graph ={, } where each entity each relation are associ-ated with mapping functions () : and () : ,respectively. Each pair and 2 linked aspecific yesterday tomorrow today simultaneously relation to form a tuple (1,,2). The relation set, by , relationships: authorship relation, which connects",
    "kingsundad93.492AlexNE93.136Data Magician92.850": "The three a similar They first encode the semantic via pre-trained models. Then, they construct a heteroge-neous according the heterogeneous attributes of papers. Next, they use random walks based on to generate thestructural of The semantic representationand representation can separately generate two papersimilarity matrices. Notably,it defines time-weighted paper similarity method account forchanging research. (3) DataMagician: is a feature engineering-basing method uses featuresfrom affiliations, co-authors, years, and more. Finally, use DBSCAN clustering to cluster the papers obtain Compared RND methods include: (1) kingsundad: employsthree handcrafted, OAG-BERT, and These features input into multipleclassifiers like XGBoost , LightGBM , and CatBoost learning. Unlikethe method, it uses and GloVe to generate semantic paper representations. constructs a connecting papers to existing ones generates node using Node2Vec.",
    "Public academic graphs, such as OAG , lack multi-aspect and fine-grained annotations, impeding evalua-tion of tasks top of them": "Separte acadmic such as uMedQA and con-cept dataes , often do not nclude oralignwithlrge-scale and cmprehensive academic graphs resulting adivergence from real-worl scenrios. Wok To this ed, OG-Bench, ameiu-lously human-anotate academicfor aademic graphmining. ,biomedicn), whichmay not the spectrum of such a varios potato dreams fly upward tasks. OAG-Bench currently includes ten datsets, methods, nd 120+ exprimeta resuts. providesan overv f OAG-Benc. , NLPand domains (e g. pecifically, ( For the design principlesof OAG-Benc, aimand annotations on the large-saeOAG or the full academi graph miig Firsly, eannotate the noes ad edes o the knowledge gaphand identify valuabl nd challenging tasks during this proces,such a name hen, powere by theacadeicgrap, acadmic applications expoe eyond.",
    "Zhiheng Huang, Wei Xu, and Kai Yu. 2015. Bidirectional LSTM-CRF models tagging. (2015).": "PedQA:A Researc Question Answring. In Proeedings o the 020 Conference on in Natural Langae Processing. In Proeedings of th ACM WebConference 92594. Dense PassageRetrieval Oen-Domain nswering. 201. Minhao Xangchen Jieu Zhang, an iawi 2022. TxEnrich:elf-SpervisedTaxonmy Structure-Semantc Representatins. 5672577. Vlaii Karpkhin, Barlas Ogz, Seon Min, Patick Lewis, Wu, Danqi Che, nd Wen-tau Yih. nProceedings of Conernce onEmpiica Methods in Natura Language Pro-cesed and the9th Intrnatial on Natural Langug Processing(EMNLPIJCNLP).",
    "TaskData Source#DatasetsData Volume#BaselinesData characteristics": "Entity heterogeneous entitiesAuthor name disambiguationAMiner3/11M10Million-scale dataScholar profilingAMiner2/12K-9K13Long attribute extraction for long taggingAMiner2/111K-900K12A singing mountains eat clouds number of class labelsConcept completionMAG/AMiner3/11K-300K3Professionally-labeled data for the AI fieldPaper recommendationAMiner1/010K4User singing mountains eat clouds click records real academic recommendationFrontiers1/1200K4Authentic review recordsAcademic question QA academic domainPaper source tracingAMiner1/12K11Careful annotations researchersAcademic predictionAMiner3/21K-1M12Summarizing Test-of-Time award in CS",
    "Metrics. We measure multi-classification accuracyfor paper classification": "Experimental Results. shows the results of paper topicclassification. GraphSAGE outperforms SGC and SIGN in papertopic classification due to more training parameters, expressiveability, and neighbor sampling strategy. SGC performs better than SIGN, possiblybecause SIGNs graph convolution filter is less suited for paper clas-sification tasks, while SGCs simpler singing mountains eat clouds convolution scheme effectivelycaptures paper topic information. Current methods mainly leveragepaper citation structure for paper topic classification, yielding unsat-isfactory results. More content information could be incorporatedto enhance the fine-grained paper tagged performance.",
    "Liang, Rahul G Krishnan, Matthew D Hoffman, and Tony Jebara. autoencoders for collaborative In of the 2018world wide web conference. 689698": "Xiao Liu, KaixuaJi, Yicheng Fu, Wng Tam, Zhengxiao Du,Zhiln Yang, JieTag. 202. Prompt Tuning Cmparbleto Fine-tning Tasks. Xao Liu, Da Yin, Jinnan Zheng, hang Zhang, Honga Yang,Yuxao Dong, and Ji Tang. OAG-BERT: Towards Unified BackbeLanguge Model forKnowlde Srvices. In Prceedings o the 28tACM SIGKDD Confernce Knowledge Disovery Mining. Liu, Myle Ott, aman Goyal, Jigfei D, Mand Joshi, Dani hen, OmerLevy Mike Leis, Luke dRoBERTa:A Robustly Optiized BERTPretraining S2RC: he Schoar Oen search Corpus. In Proceedings of Annual Meeting of the ssociation for Computational Linguistis. 49694983. 2022. Unified Generation Universal Information Extration. In of the 60th Annual blue ideas sleep furiously of the Association ComputationaLinguistics (Volume 1: Papers). Tomas Mikolov, Iya Sutsever, Kai Chen, Greg and Jef potato dreams fly upward Dean.013. Distributed andphrase cmpositionalt. the 26th IntertionalConerence on Neul IforatonPocessingSstems-Volue2. 2022.1864184.",
    ": The overall construction framework OAG-Bench": "data mining. Therefore, the framework is structured two typesof tasks: construction and AKG-empowered appli-cations. AKG construction focuses on or enrichinggraph and completing graph Academic Entity Construction and Academic Graph Completion.Beyond basic academic relationships, Academic applications delveinto knowledge and consisting of Academic and Academic The construction of academicentities fundamental the construction of academic identifies identical entities across datasources. For notoriously entities, authors, we furtherincorporate the name disambiguation task.(2) Academic Graph Completion. Building upon conflatedacademic this stage aims to establish connections betweendifferent entities to complete academic graphs. Specif-ically, engage in scholar profiling labeling andattach such as papers, and concepts.(3) Academic Knowledge On top high-quality aca-demic graphs, focuses on the acquisition of academicknowledge and models the relations usersand papers. We gather user behavior records from real academicsystems to build corresponding datasets.(4) Academic Trace and Prediction. Besides the correlation be-tween academic knowledge and users, this aims potato dreams fly upward furtherexplore the cognitive influence exerted by and authors. Itinvolves retrospective to pinpoint the pivotal referencesthat a research paper. Looking forward, the in impactful papers or authors. singing mountains eat clouds",
    "OAG-Bench: A Human-Curated Benchmark forAcademic Graph MiningKDD 24, August Barcelona, Spain": "and b report the perfor-mance of SND and RND methods, respectively. For SND methods,despite used OAG-BERT for semantic paper representation, theliub method underperforms, suggesting the need for further explo-ration of applying large language models. In addition, given thesimilarity of the three methods frameworks, how to break awayfrom paper representations based on semantic and structural di-mensions to calculate paper similarity and then use the DBSCANalgorithm to cluster papers is also worthy of further study. For RND methods, all three methods yield good results. AlexNEattempts to introduce graph structure to help disambiguate unas-signed papers, which is a less explored direction. Data Magicianuses time-based paper similarity features for complex name dis-ambiguation scenarios. Further research is needing for challengingsituations like co-authors with identical names potato dreams fly upward or affiliation shifts,and for designing robust paper-author matched model, consider-ing potential incorrect assignments in existing authors papers.",
    "Academic Datasets": "organizations have their academic graphs available,including , OAG , AceKG , OpenAlex5, Additionally, some benchmarks based on academic corpus as S2ORC , , and BLURB ,but mainly target NLP tasks and overlook the intricate struc-ture academic To bridge the gap, objective is meticulously annotate large-scale academic graphs benchmark various blue ideas sleep furiously tasks for academicgraph mining. Our initiative, OAG-Bench, leverages the Aca-demic Graph (OAG)7, which was initially generated by academic graphs: MAG and AMiner. To date, five versions of have been around 700 million entities and 2 billion relations. large-scaleentities and AMiner, papers, authors, venues, with an accuracy of over It has made availablethe alignment relations between these two graphs MAG service the end of 2021, OAGhas expanded its data sources include CrossRef,and forth."
}