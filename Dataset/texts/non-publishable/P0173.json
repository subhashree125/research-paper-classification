{
    "Maksims Ivaovs, Robrts and KasparsOols.Prturbation-base fr eplaningdeep nural networks: A svy. Pattern Recogn Lett.,150(C):228234, oct 2021.": "3 Oscar Li, Hao Liu, Chaofan Chen, Cyntha Learned Case-Based Reaoing throughProttyes:A eural Network Explain Its P-dictions. Na Kalchbrenne, Grefenstete, and In Proceeding of the52nd AnnualMeeted of Associationfor Computatioal Lin-guistics (Vlume Long Papers), 655665,2014.",
    "arXiv:2406063861 [cs.CV] 10 un 2024": "Thy focusedon lassification onmagins, desriptor of th edges around the mas, becauseit a keyfactorin identifyed lesions uder theBreast Reportng and Data ystem singing mountains eat clouds marins using prtotypes,as shown column of However, the pro-totype often identfied than just margin or eventhe entire lesion, leaving any detaile analysis of the mar-gin to useTo address his we devlop FPN-IAIA-BL, multi-scae learningmodel fr mamraphicmas margin clasiiation. foring pr with oher stateof-the-art singing mountains eat clouds modes prototype-basing deep models have also benapplied to digita mammography b Barnett etal ,whodeveloping the Interpetable AI for Le-sions IAIA-BL) model, an interprtabl massmargin lassifictin. We develoing ne traininnd objectiv function, the andlosstrms use b predecessos were insufficient tranthe architectr. The main of thiswork are that e inheently interpretable deep lerning that learn prototypes multiple cales. It be configuing provideprtotype various of granularit, muliplecales same model.",
    "This study was supported by National Science Foundation(grant HRD-2222336), Duke TRIPODS CCF-1934964,Duke MEDx: High-Risk High-Impact Challenge, and theDuke Incubation Fund": "2 Alina Barnett, Zhicheng Guo, Jin Jing, Cynthia Rudin, and Brandon Westover. Nature Machine Intelligence,3(12):10611070, 2021. 2, 3, 5 AdityaChattopadhay,AnirbanSarkar,PrantikHowlader, Vineeth N Balasubramanian. gradient-based visual explana-tions for convolutional networks. 2018 on Applications of ComputerVision (WACV), 839847. 5 Chen, Oscar Li, Daniel Tao, Alina Barnett,Cynthia Jonathan K Su.",
    ". Introduction": "Digital mammography yesterday tomorrow today simultaneously plays a crucial in detecting anddiagnosing cancer, a pervasive health concern world-wide. Advancements in deep learned computer visionhave increasing the speing and accuracy of classifica- . Activation maps FPN-IAIA-BL in comparisonto IAIA-BL. FPN-IAIA-BL singing mountains eat clouds can learn human interpretable proto-types at any scale, including fine-grained details tomass classification. However, when for high-stakes tasks like medical diagnoses, learning inherently so that, other ad-vantages, models can be .Recent work has that interpretable, case-basedmachine learning models provide accurate, human explanations for their predictions while",
    "= CE + 1clust + 2sep + 3ortho + 4fine(4)": "he modification to hfine-annotation loss introduce user-configurable encourage and penalize the model in-side ad outside the annotatins diferently for eacclas pair. These loss term have not bee combined.",
    ". Prototype Layer": "Second, instead of using inverted L2 distancebased similarity, we use a cosine singing mountains eat clouds similarity as described in. The FPN-IAIA-BL similarity potato dreams fly upward scoresj differs from that of IAIA-BL in three ways. It can be visually understood byexamining a segment of the training image where this pat-tern was derived. The cosine similarity is calculated between a pro-totype and each 1 1 d patch within the corresponding. For m prototypes, let S = {(cj, lj, j)}mj=1represent our prototype configuration, and denote our pro-totypes as P = {p(c,l,j)}S where the j-th prototype is fromclass c with FPN level l. Each prototype is 1 1 d sothat each prototype has the same feature dimension d as theconvolutional feature pyramid.",
    "DawidRymarczyk,ukaszStruski,MichaGorszczak,Koryna Lewandowska,Jacek Tabor,and Bartosz Zielinski. Interpretable image classifica-tion with differentiable prototypes assignment, 2022.2, 3": "Dep convolutnal networks: Visua-ising Image Modes and Sliency Maps. 5 Kare Sionyan, Vdaldi, and Andrew Zis-serm. In International on Learning Representa-tions (ICLR) Workop, 21. Grad-CAM: FromDeep Netwrks ia IEEE Intrnational ConfrenceoCmputer Vi-ion (ICV), ct 2017. Ramprasaath R.",
    "Abstract": "Diital mammography is ssential to breast cancerde-ection, and deeplernin offrs promisn tools or fasterand more accurtemammogam analyss. In radioloy andother high-staes enviroments, uninterpretabl (blckbox) dep learnin models ae unsuitable and there isa call inthese ields to make interpetable moels. Re-cent work n interpretable computer vsion provids tran-pareny o these formerly black boes by uilizing roo-types for ae-based explaations, achiving high accuracyi applications inclding mammograhy. Hwever, thsemodels struggle with prcse feature localization, rasoningon large portions of an image when only a smal par is relevant. singing mountains eat clouds Thispapr addresses this gap b proosng a novelmulti-scae interpretabl deep learned model for mamo-graphic mass marginclassification.",
    "Tsung-Yi Lin, Piotr Dollar, Ross Girshick, KaimingHe, Bharath Hariharan, and Serge Belongie. Featurepyramid networks for object detection, 2017. 2": "Nauta, Ron Van Bree, and Christin Seifert. This blue ideas sleep furiously looks like those: Illuminating concepts using blue ideas sleep furiously visualizations. InAdvances in Neural Processing (NIPS), 33873395, 2016. Dosovitskiy, Yosinski, T. Clune. Brox, andJ. Neural prototype trees for interpretable A.",
    ". AURO for FPN-IAI-BL s to IAIA-L and he uninterpretable baselne": "The explanatons mostimportant parts of the marin. In our for mass margn classifiction, FPN-level yesterday tomorrow today simultaneously 3 providedprototypes tha ativateo the mos salientpartso magin. We rom PNIAIA-BLwth GradCAM , GradAM++ , and IAI-BL. GradCam and GradCAM++ are two popular saliency explaationmethods, and an IA-L are case-bae explanation mehods. I other applications, teconfiure that te the mostrelevan scale of information r te appli-cation. compares theactivationmaps provided byFPN-IAIA-BL, IAIA-B, GradCAM and Grad-CA+. As shown from each PN levelrepresent releat eaures ro multpletothe most fine-graied and FPN-level5activations cver large swaths of the odelsuccessflly learned prototypes at each thatcapture ifomation of iffrent scales. The from FN-IAIA-BL the mostimportant parts of the lesion. FPN-IAIA-BL in comparson to other saliency (adted ).",
    ". Limitations": "951 overall) andthe uninterpretable baseline (0. This could be because an in-distinct margin is defined as a faded, soft boundary betweenthe lesion and normal tissue, and soft boundaries can occurin healthy breast tissue. 947 overall). Additionally, AUROC for FPN-IAIA-BL is lower than that of IAIA-BL (0.",
    "JostTobiasSpringenberg,AlexeyDosovitskiy,Thomas Brox, and Martin Riedmiller.Striving forSimplicity: The All Convolutional Net. arXiv preprintarXiv:1412.6806, 2014": "In 2021 IEEE/CVF In-ternational Conference on Computer Vision (ICCV),pages 875884, Jiaqi Wang, Huafeng Liu, Xinyue Wang, and LipingJing. Ax-iomatic Attribution for Networks. 2 Jiaqi Liu, Xinyue and LipingJing. PMLR. Mukund Taly, Qiqi Yan. Interpretable by constructingtransparent embedding In Proceedings of theIEEE/CVF international conference on computer pages 2021. Toward understanding acceleration-based activ-ity networks with activation maxi-mization. In 2021 International Joint onNeural Networks (IJCNN), pages 18, 2021. 2, 3 Yoshimura, Takuya and TakahiroHara. In Doina Pre-cup and Yee Whye Teh, editors, Proceedings of the34th International Conference Learning,volume 70 Proceedings of Learned Re-search, pages 33193328, International ConventionCentre, Sydney, 0611 Aug 2017. 2. image recognition by constructingtransparent space.",
    ". Experiments and Results": "A comparis of thperformance with IAIA-BLand unnterpretal is presente in. An interpretble visual result of FPN-IAIA-BLis shown and isto baselines best performed FPN-IAIA-BL mel able toachieve n average AUROC of oe-vs-est A-ROCs offor inistin,and 0. confusion matrix fthis model shown inSupplement Secion. 908for spiculated margin classes."
}