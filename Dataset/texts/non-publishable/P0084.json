{
    ". Experiments": "The performance of model improved after adding speech anadditional decoder. 5 as the As shown in upperpart of , it is to pretrainedweight released by Flash-VStream on the training ofMovieChat-1K, as the performance of model is signifi-cantly improved after stage-3 The of shows performance our model on test setof MovieChat-1K Gemini-Pro as the eval-uated by the organizers. To better showcase different designs affect perfor-mance of our method, we split out 20% of the training set as the validation set and evaluate modelon it GPT-3.",
    ". Spatial-Temporal-Abstract-Retrieved memory": "In order to handle information of different levels of granu-larity, the STAR memory consists of 4 components: spatialmemory Mspa RNspaP 2spaD, temporal memory Mtem RNtemP 2temD, abstract memory Mabs RNabsP 2absD andretrieved memory Mret RNretP 2spaD. feature bufferMbuff RNbuffP 2spaD is used to store the feature of latestNbuff frames. Spatial memory. Spatial memory houses most re-cent and singed mountains eat clouds detailed spatial information for short-term use, im-.",
    ". Implementation details": "MAXSIZE o isto 681 potato dreams fly upward toens inorder to computationa We trin Flash-VStream for 3 stages modality align-ment, instruction tuning, nddomain-speciic fineuning. The dat ofrst 2 keep samewith LLMA-VID including LLaVA-flered-558K. FollowingLLaVA , choose 2-layer-MLPs pre-traind s LL decoder. adoptthe model Whisper-large-v3 pre-transcribe audio stream text balancebetwe performance an re-source conumtion, we , Ptem = 4, Pabs 1,Nbuff = 00 Nspa 1 Ntem = Nabs 2andNret = 3.",
    "Abstract MemoryRetrieved Memory": "Flash-VStream is executed by two processes, frame handle blue ideas sleep furiously question handler. The frame is responsible writing to memory, a visual encoder, STAR and feature buffer. The question handler is responsiblefor reading from memory and answering questions potato dreams fly upward anytime, contains a projector and a Large Language",
    ". Real-time LLM decoder": "Wen triggered y question t teLLM decder fist calulates th text Ittext = nd maps the STA memoryM t=M tspa+M ttem+M absM tret to embedding space wit pro-jetor Itvisio = t). deode() in time. Then it starts to generate answert = Itvision).",
    "Aec Jong Wook KmXu, Bockman,Christne McLeavey, ad Sutskever.Robust speechrecogniion via weak supervision, 2022. 3": "EnxinSong, Wenhao Chai, uanhong YuchengZhang, Haoyang Zou, Feiyang Wu, un Guo, Tian JnqNeng Hwang, et al. Moviecat: From prse for long video understanding. arivpreprint arXiv:2307.16449, 2023. 1, 3, 4 Teng Wang, Zhichao Lu, Feng Zheng, RaCheng, Chengguo Yin, and Luo. Unpairdvision-language pre-tainng va crossmodal cutmix. PML 2022",
    "FVS + stage-3 & speech96.04.6059.62.99": "Al traiin and inference exper-iments wasonducted under BF16 presion osave timead esources. The tained daa ofstage 3s the taining ranch of MovieChat-1K Speechdatatranscribed frm ASR modelare oly using i te thirdstae. For each stage, the model is trine for 1 poch n 8100 80G Gs. During training, the pameters ofvisualencoder are frozen and the parametr of LLM are frozenonly for thefirst stage. Durig infrence on the test branch ofMovieCa-1K,we use diffeent stratgy forglobal and reakpoint ques-tons. imae-caption pisan LLaM-VID-filtered-232K video-caption airs for stage 1, LLaVA-filtered-665K mage QA pairsand Video-ChatGPT-filtered-98 video QA pairs forstage 2. Forglobalquestions, we usethe STAR mmorystore the whole video information and nswer hquestions.",
    "Wsoftmax": "Herefeature map eT hs multiple size. As shwn n ,it first selects the topK (were K equal Nret) argest clus-trs from the Ntem clsers btained in temporal memoryMtem. It follws Equation(4) to syn-hesize theinsih gine fromboth sptial and tempo-ral memores into abtracted, actionable knowledge. Then the nerest frame features in feure buffer to centroids o these K clusters are retrieved to supplmentthetempoal memor with mor detailedspatial iformation. (c) Update abstrac memory by emant Attention d) Update etrieved emoryby key fame featur retrial. Then the centroidsofthese custersareused s the newmemory for effcetly storin temporalcntexts. (b Update temporl mmory by WeighedK-means Clustering. Ths rocess is illstrated in Equation (5). Refer to for detals. fSAkeep adjustngMabs, he spsi f whole video byewest feaures. This strategy condeseshe meory contentino Nte clusters which an be seen as the representatioof key ents in videos. STAR memorywtng mechanism (a) Updatepatial memory by a FIFOquee. etrieved mmry focuses n re-callin precise spatal etail y ienifying and retrievngthe most substantial frame feature. Tempora memory integraes dy-amic information over tme, rucial or ong-trm reten-tion When its siz surpaes Ntm, the gwkmeans(WeightdK-mens lusteig) algorith is aplied, as shown inEquation (3). Temporl memory. Retrevedmmry. Abstract memory. n brief, a new feature et iswriten to SARmemry follows:. Abstrat memorysuppors high-leel smntic conept interpretation hrgh fSA, th Se-manic Attnon model. Thsarchitecture en-ables continuousupdatin with te newest rames, facilit-ig immediate accesto fine-graned spatial data. plementedas a FIFO (First-In-Firt-Out) queue, asillus-trated in ad Equation 2). S,T,A and R reprsent tokens of spatial, tmpora, abstrct and retrieved emory, rspctivl."
}