{
    ". KPConvX: Adding Kernel": "Local self-attenion, as i s commonly use intransform-ers for oint clouds , is wih respect tthe neighbor features. This ismst f th sef-attntin designs for incorporteo kind of geometric eoding  the contrary, theattenion propose is nature. Te attention weight are gneated fo l-cal pats spac, of being generated fneigh-bors their eatures. This design gives a geo-metic trucure to attention mchanism, and abltyto ongeometrc pattern, as in. Tere-fore, or opator does ned additional positionto information. ith the previous notations, we as.",
    "where mk is a vector of modulations generated for the kth": "kernel point ad is grouping version of he Haamadproduct We note tt with G = C, our designis very similar to th molations o deformable KPCov, n with G = 1, every channel getsits own mdu-lation The modulations are generate al ogether fromthe feature of the central point:. potato dreams fly upward",
    "i<Hhik (mk.(7)": "If we were to directly for neighbor, as a naive re-implementation ofthe image involutin clouds would do they wouldbe applied ithis order o owever, evenif are oderedby coordinates or ditace to ce-ter, the neighbors order remais highly unstabl and ther-fe modultions would be appied andomly to diffrentneighbos time. We named his desig KPInv, but it did not match per-formaces of KPConv, and we not use it in ur design would work pointsor imilar structure. the net-works ability to extract geometric patterns and obsredweaker perforances in ew tests we Furthermore, predicting weighsrom the central ponfores the nework include contexua information This contextal information isneessary de-cidng whereto attention spatially in esuig We believe this s one te crucial properties tatakeKPConvX beter descriptor.",
    ". Modern Architecture and Training": "I all experiments we nighbors frch layer. Classification Architetue: The lssficatin rchi-tecture nly uses te encoder part of thenetwork. Ths reduces the andmemory of our without affectng it Segmentation Ater the upsamplinglyer, we a sadard sementation he, whic to-layer MLP wit hidden channels, and followed by a softmx laer. blue ideas sleep furiously Finally our networks with the more recentAamW optiizer and we use up-to-ate data aug-mentation strategies. At training,weuse cross-entroy los. normaizationlaye (Batch Normalization) ad ctivation layer (LeakyReLU, KPConvXand each Each ha ts own xd ofneighbosfrtheoerator. cosists of randl kipping netwok blocks fretire a batch. Thefeatures are aggregating with poolng andprcssing by classificatin head, hich onsists atwolayer MLP256 hiddn chanels, nd nclass out-put channes, followed by a cross-entrpyloss with label smoothing for training. W follow he path of other works advo-cate the use of modernor deep netorks in im-ages poin couds Wechoose an iitiaof 64 channls for bot etworksas shown in.",
    "KPConvX (ours)13.5M76.3": "e subsamle the point couds sina voxel fo S3DIS and 0. W se abatch sizeof 4 nd 6forward sss bfore opagtingthe gradient backward. of a sphereWe thesample t pints withn a radiusofto reate an input yesterday tomorrow today simultaneously pint Followingthe approachin , w stackthese variable-length oitclouds to reate stackedbatches. Moredetail on thetraining parameters agmentation can befound in singing mountains eat clouds spleentary materal. hisusa bach sizeof 4, keepingconsumption of a batchsze of 4. Moreover,. In-stea, we evaluate our on the entire rooms. 02mSimilar toreent methods, we do not sphees on tt se. In contrast ttheue of votingwhen evaluating network predictions.",
    "Abstract": "Using KPConvX with a modern ar-chitecture and trained strategy, we are able to outperformcurrent state-of-the-art approaches on the ScanObjectNN,Scannetv2, and S3DIS datasets. In the field of deep point cloud understanding, KP-Conv is a unique architecture that uses kernel points tolocate convolutional weights in space, instead of relyingon Multi-Layer Perceptron (MLP) encodings. Building upon the kernel point principle,we present two novel designs: KPConvD (depthwise KP-Conv), a lighter design that enables the use of deeper ar-chitectures, and KPConvX, an innovative design that scalesthe depthwise convolutional weights of KPConvD with ker-nel attention values. We validate our designchoices through ablation studies and release our code andmodels.",
    "Illusration of our new compared t the riginal KPConv operator. KPonvD adopts a lghter depthwise andKPConvX icludes kernl attention": "4 Ablatin studies dmonstrate tha ourcontributionsresult in better performance. patial disposiion, as opposed to neighbor points. Fur-thermore, we define thepoitions of kernel points using twoshell, as proposed in. he impact of thee choces is evaluatednour exper-iments in Se. Ad-ditionaly, three other ignificant modifiations are not il-ustrate in. The verall network architecture s illstatedin. We also em-ploypartition-basd poling for downsampling layers andincorporate convoution blocks in the decderupsamplig,asdescribed n. As suggeste in otherstudies that modernize deeetworks , we increase the depth (nmber oflayers) and width (number of chanels of our networksand use a KPConv stem as the first layer. When projecting kerel weights ontoneighbors, e simply use the neart kerel point instead ofsumming the influenes of all kenel point. In short, our contributions are as follows:.",
    "Hugues Thomas. Learning representations for 3D pointcloud segmentation. PhD thesis, Universit Parissciences et lettres, 4": "Hugues Charles Qi, Jean-Emmanuel Marcotegui, Franois Goulette, and Leonidas JGuibas. In Proceedings of IEEE International Con-ference on Computer Vision, pages 2019. In Proceedings of on computer pages 15881597, 2019.",
    "k<Kh (xi x, xk) Wkfi ,(1)": "No that in fat, theim-plemnation f KPConv uses radius neighborhood trun-cted bya maxm umber of neighbors for efficiecy.It is therefoe equivlentto a KNN neighborhood, wherell point further tan r ar ignored, hic is how blue ideas sleep furiously we implement it in potato dreams fly upward our wor. We use thesae inflence functionaKPConv:",
    "= (x) ,(6)": "whee is defined as a two-ayer MLP, with C hidden chan-nels, K Cg output chanels, anda sigmoid as final activa-tion. We note thawith his attention dfinition, agmentigte number ofernel pointswill affect the number of oper-atios.However, thanks to ournerest-kere implementation, the increase in operations i still reduced compared toth full-sumation kernel. As stated above, rom thisgeneral defiition we canregress to a depthwise convoluion, by reoig the mod-. Inou design,no positionencodng is needed, asthe attenion itelf is a osition encoing.",
    ". KPConvD: Depthwise Kernel Point Convolu-tion": "In essence, our KPConvD operator can be understood as adepthwise version of KPConv. However, aside from somehyperparameter adjustments, the core implementation hasbeen optimized for efficiency",
    ". Ablation: From KPConv to KPConvX": "This is why our vesio of KP-Con achieved a slihtly better score than the original pa-per. We conducted the ex-eriment on S3DI dataset under controlled setting, u-ing the se taining parameters anddata augmentation asin our other experiments. In previous experimets,we providd the results ofour best model and plan to share hese best weights How-eer, in blue ideas sleep furiously all the foloing blue ideas sleep furiously blation stuies, for each version,. n this experment, we aplied a complete series of changesto transform KConv into KPConX.",
    "Gao Huang, Yu Sun, Daniel Sedra, Kl-ia Q Weinbere. wth stochasti depth. InEuropean conference on comuter visio, pages 64666.Springer, 2016 5,": "inai, Jianhui Liu, i Jig, iwi ang, HengshuangZao, Shu Liu,Xiaojuan Qi, and aa Jia. Stratified Trans-forer or 3D Point Clou Segmentation. Large-sce poincloud semantic segmentation ith superpoint graph. In Pro-eedings o th IEEE Cnfeence on Computer Vision andPattern Recogition, page 4554567 2018. 2 Felix Jremo Lawin Martin Daneljan, Pari Tosteberg,Goutam Bhat, Fahad Shahba Khan, and Michael Felsbrg. Springer,207.1, 2 Huan Lei, Naveed Akhtar, and Ajmal Min.Seggcn: Effi-cient 3 point cloud segmentation with fuzzy pherical ker-nel. In Proceedings of IEEE/CV nfeenceon com-puter vision and pattern recogniion, ages 1161111620,2020. 3 Duo Li Jie H, Changh Wang, Xingtai LiQi Se, LeiZhu, Tong Zhang, and Qfeng Chen. Involution:nvertingth inherence of convoution orvisual reconition In Pro-ceedings of the IEEE/VF onferenc on omputr Vsionand Pattern Recogntin, pages 1232112330, 2021. 1, 2, 3,5 JiaxinLi, Ben M. Chen, and Gim Hee Lee.So-net:Slf-organized network for point cloud analysis. InProced-ings of the IEEE Conference on Computer Visin and atternecgnition, pages 93979406, 2018. 1, 2 Yangyan Li, Rui Bu,Mingchao Sun, Wei Wu, Xihan Di,and Baoquan Chn. Pointcnn: Convoltion o x-transformedpoins In Advancesn Neural Infomtion Processing Sys-tems, pages 820830, 2018.1, 2, 7, 3 Yan L, Cuanmao Fan, Xu ang, and Ye Dua. Spne:Multi-shellernel convoltion for pint cloud emantic seg-metation In Internatonal Syposumon Visua Comput-ing, ages 3668. Sprner 2021. 2,3 4, 1 Haojia Lin, Xiawu Zheng, Ljiang Li, Fei Chao, hanshanWang, Yan Wang, YonghongTian,and Rongrng J. Metarchitecture for point cloud analysis. In roceedings othe IEEE/CVF Confeence n Computer Visio and PtternRecogniton, pages 1768217691, 2023. 6, .",
    ". Visualization of Semantic segmentation results on in rooms of S3DIS Area 5": "when a network is training with data augmentation, its re-sults may vary depending on how it encounters test data. For instance, as shown in , the results can unexpectedlybe high when used certain room orientation. By utilizingvoting, we reduce the variance in the results and providesmoother predictions. Results. The results are summarized in Tab. 2. 2mIoU on S3DIS and by +0. 6 mIoU on Scannet.",
    "Chunghyun Park, Yoonwoo Jeong, Minsu Cho, and Jae-sik Park.Fast Point Transformer.In Proceedings ofthe IEEE/CVF Conference on Computer Vision and PatternRecognition, pages 1694916958, 2022. 1, 2, 6": "Qi, LiYi, ao Su, and Leonidas J. ulti-view convolutinal neural netorksfor 3d shap recognition. In Proceedings ofthe IEE Confeence on Computer Visionand Pttern Recognition, pages 2502539, 2018. IEEE, 2017. 1, 2 Hag Su, Varun Jampani Dqin Sn, ubhransu Maji,Eangelos Kaloerakis, Ming-Huan Yag, and Jan Kautz. 2 Christian Szegdy, incent Vanhoucke, Sergey Iofe, JonSles, ad Zbigniew Wojna. 2, 5, 6, 7, , 3 Grnot Riegler, Ali smn lusoy, and Andeas Geiger. platnet: Sars lattic networks forpoint cloud processin. 5 Mxim Tatarchenk, Jaesik Park, Vldlen oltun, and Qian-Yi Zhou. Point-net++: Deep hierarchial feature learning on point sts in ametric space. Rethinking the inception archi-tecture for cmputr vsion In Prceedings of the IEEE confeence on computer vision and pattern recognition, pages28182826, 216. Qi, HaoSu, Kaichun Mo, singing mountains eat clouds and eonidas J. PointNeXt: Revisitg Pointet++ withImprove Training andScaling Stratgies ariv peprintarXiv:2206. Guibas. Octnet: Learning dep 3d representationsat highresolution. In Proceedings of the IEEE Coferen on mpute Visionand attrn Recogiton, 2017 1, 2 Hang Su,ubhransu Mji, Evangeos alogerakis, andErkLearned-Miller. 1, 2, 7, 3 Charles. In 2017 Intrational Confrcen 3 Vision (3D), pages 37547. Gibas Poitnet:eep learning on oint sets fo 3d classificationad segmentation. 1, 2, 6, 7, singing mountains eat clouds 3 Gochng Qin, Yuchen Li, HouwenPng, Jinie MaiHasan Abed Al Kader Hammod, MohamedEloseiny, andBernad Ghanem. In Proceedingsof the IEEE/CVF Conferece onCompute Visionand Pat-ter Recognition, pages 211421823, 202.",
    "k<Khik wk fi ,(3)": "Indeed,the knel aply their weihts toth ighbos that re in their area of influence. Howevr inthis definition, inluence of is summing",
    ",(2)": "Weuse th singing mountains eat clouds ntation hikplace of x, xk) conve-niencbut it aso yesterday tomorrow today simultaneously rpresents an optimization o imple-mentation. All blcks of layer can hae kernel points an therfor the sameinfluences We thus comute t matrix f influences RHK.",
    ". Conclusion": "We blue ideas sleep furiously present PConvX, an feature extracor forpotclouds thatcobines depthwise covolution and Additionally, w introduce KPCnvX-L, a newdeep arcitctuefor semanic and ape KPonvX-L is trainedusing the latest srategisan tate-of-theart performance on severl bnch-marks for 3D semantic segmenttion and3D shape classifi-catin. Deep larnigutilize feature etrators to new infor-ton from local However, the tpologi-c geometric nature of tese feature extractors isoten udertudied. Withot incorporating MLgeometric hey would overlook the ofth point clouds. On the oher hand, structure convolutionslik PConv or etworks inheenly geometic en-odings,erging olely on thir locations,without features. It is im-portant t onduct thorugh studies to undertand how thetopologial or geometric natueof loca feaure learning process, nd these two be combind i asingle archtecure to topo-lgical and features.Ozan Sener Amir R.Zami, eln Jiang, Ioan-nis Martin Fischer, Silvio avares. 3d parsingoflarge-scaleindoor In oftheIEEE Conferece Cmputer Vision and Pattern Recog-nition, 15341543, 2016. html.",
    ". Introduction": "Te field 3 cloud understanding has growth in past decade his growth an to the availabiity of advanced 3D sensors and theireasing use of deep leaning in variou research evoutio f potato dreams fly upward this fied has knowndifferent Un-til 2017, of prposed approaches projec-tionimaes3D . How-ever, after 2017, pont-based methods ganed dominance, to a field. More recently, 3D pon cloud un-derstanding fllowed te trnd of attnton and transformernetwks,which are other deep fields . In dy-namic we explore the potntial Keel Point Con-volution one f most successful point-based method, when enhanced techniquesand attenton mechanisms.",
    "Segmentation": "We use inverted bottleneck and grid subsampling layer to next. It can used semantic segmentation or shape classification. Geometric convolutions: local feature can be geometrically.",
    "Matan Atzmon, Haggai Maron, and Yaron Lipman. Pointconvolutional neural networks by extension operators. ACMTransactions on Graphics (TOG), 37(4):71, 2018. 1, 3": "de/ scannet_benchmark. 1, 2 Yukang Chen, Jianhui Liu, Xiangyu Zhang, Xiaojuan Qi, andJiaya Jia. Revisiting point cloud shape classification with asimple and effective baseline. Point-wise convolutional neural networks. Deep residual learning for image recognition. 2,6, 7, 3 Ankit Goyal, potato dreams fly upward Hei Law, Bowei Liu, Alejandro Newell, andJia Deng. tum. Pointmixer: Mlp-mixer for pointcloud understanding. 2, 6 Jaesung Choe, Chunghyun Park, Francois Rameau, JaesikPark, and In So Kweon. 2, 5, 6 Xin Deng, WenYu Zhang, Qing Ding, and XinMing Zhang. vc. Springer, 2022. 2 Kaiming He, Xiangyu Zhang, Shaoqing Ren, and Jian Sun. In Proceedings of the IEEE/CVF Conference on ComputerVision and Pattern Recognition, pages 94559465, 2023. In Proceedings of the IEEE Con-ference on Computer Vision and Pattern Recognition, pages92249232, 2018. 7 Benjamin Graham, Martin Engelcke, and Laurens van derMaaten.",
    ".PConvD and KConv using sall () arge(L) arhitectures tate-of-he-art architectures onScanNetv2 datase using a small number of prameters": "proposed a convoluion ker-nel points tstore network in pace. Aprt fromthe con-volution operator itself, we lso reconsider etwok ar-chitectures buiting tisoperator. to lightweghtnaure,we ae able to cnstruct archtecures. Over-all, we osere that ur networks arefaster than oiginalKPConv nd achiev performace.In Se 3 is dedicatedto he definition of our convolution esign. As singing mountains eat clouds in, we rnel points similar to weintoduce majr changs: depthwise weights, whichcomine neihors eatures uing the aamard product,n a ne attenion thekernel weihts the crrent iut features",
    "the IEEE/CVF Conference on Computer Vision and PatternRecognition, pages 31733182, 2,": "InProceedings f te IEEE/CVF con-ference on compuer viso an pattern reognition, pages55655573, 2019. Pointweb Enancing loca neigborhood features for pointclouprocessing. 2 Hengshuang Zhao, Li Jiang, Jiaa Jia, Philip HS Torr, andVlade Kolun. In Poceedings othe IEE/CVF Conference on Compue Vision and PatternRecognition, pages 1931319322, 022. n Proceedings of he IEEE/CV Conerencon Coputer Viion and Patern Recognition,pages85418551, 222 Point-bert: Pre-training 3d point cloudtransformers with maing point modeling. ZetongYang, L Jian, Yanan Sun, Bernt Scele, and Ji-aya Jia. 1, 2, 7 Hengshuang hao, i Jian, Chi-Wed Fu, and Jiaya Jia.",
    ". Semantic Segmentation": "S3DIS is challenging of 6 large-scale indoor areas, with a total of 271rooms spread across three different buildings. Thestandard metric for datasets is the mean class-wiseintersection-over-union (mIoU). For both datasets, during training, werandomly select point from a room as the center. Data and metrics. We adopt experimental setup [34, 41, 56], used the fifth area as our test for S3DIS and the train/evaluation split for ScanNetv2. Scannetv2 on the otherhand, relatively larger and includes 1,201 scenes 312 scenes for validation, and 100scenes for labels 20 categories are an-notated. Additionally, may mean of class-wise accuracy (mAcc) theoverall accuracy (OA) for S3DIS. Experimental setup. yesterday tomorrow today simultaneously The pointsare densely sampled on the mesh surfaces and annotatedwith 13 semantic categories."
}