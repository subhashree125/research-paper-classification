{
    "Trajectory Data": "Your environment consists of your office, acomputer for research and writing, a kitchen yesterday tomorrow today simultaneously for testing singing mountains eat clouds recipes, and a collection of ingredientsincluding peanut butter powder.",
    "Zihao Wang, Shaofei Cai, Anji Liu, Xiaojian Ma, and Yitao Liang. Describe, explain, plan andselect: Interactive planning with large language models enables open-world multi-task agents,2023": "Advances in Neural Information Processing Systems, 35:2482424837, 2022. Qingyun Wu, Gagan Bansal, Jieyu Zhang, Yiran Wu, Shaokun Zhang, Erkang Zhu, Beibin Li,Li Jiang, Xiaoyun Zhang, and Chi Wang. AutoGen: Enabling next-gen llm applications viamulti-agent conversation framework. 01652, 2021. Chain-of-thought prompting elicits reasoning in large language models. Jason Wei, Xuezhi Wang, Dale Schuurmans, Maarten Bosma, Fei Xia, Ed Chi, Quoc V Le,Denny Zhou, et al. singing mountains eat clouds Finetuned language models are zero-shot learners. Jason Wei, Maarten Bosma, Vincent Y Zhao, Kelvin Guu, Adams Wei Yu, Brian Lester, NanDu, Andrew M Dai, and Quoc V Le.",
    "Boshi Wang, Hao Fang, Jason Eisner, Benjamin Van Durme, and Yu Su. Llms in the imag-inarium: tool learning through simulated trial and error. arXiv preprint arXiv:2403.04746,2024": "Lirui Wang, Yiyang Ling, Zhecheng Yuan, Mohit Shridhar, Chen Bao, Yuzhe BailinWang, Huazhe Xu, and Xiaolong Generated robotic simulation via arXiv preprint arXiv:2310. 04091, 2023. 16427, 2023. preprint arXiv:2305. Renxi Wang, Haonan Li, Xudong Han, Yixuan Zhang, and Timothy Baldwin. 01361, 2023. arXiv preprint arXiv:2305. Ruoyao Graham Yuan, Ziang Xiao, Marc-Alexandre Ct, and Peter Jansen. Yufei Wang, Zhou Xian, Chen, Tsun-Hsuan Wang, Yian Wang, Katerina Fragkiadaki,Zackory Held, and Chuang Robogen: Towards unleashing infinite datafor automated robot learning via generative arXiv arXiv:2311. yesterday tomorrow today simultaneously Lei Wang, Ma, Xueyang Feng, Zeyu Zhang, Hao Yang, Jingsen Zhang, Zhiyuan Chen,Jiakai Tang, Chen, Yankai Lin, et al. 14879, Xinyuan Wang, Li, singing mountains eat clouds Zhen Wang, Fan Bai, Haotian Luo, Jiayou Nebojsa Jojic,Eric P Xing, and Zhiting Hu. Promptagent: Strategic planning with language enablesexpert-level prompt optimization. arXiv arXiv:2310. arXivpreprint 2024. 01455,. Plan-and-solve prompting: Improving zero-shot chain-of-thought reasoning models. Bytesized32: corpus and challenge generating task-specific world models expressedas text games. fromfailure: Integrating negative examples when fine-tuning large language models agents. 11432, Lei Wang, Wanyu Xu, Yihuai Lan, Zhiqiang Hu, Yunshi Lan, Roy Ka-Wei Lee, Ee-PengLim. A survey on model basing autonomousagents. preprint arXiv:2308.",
    "Shibo Hao, Yi Gu, Haodi Ma, Joshua Jiahua Hong, Zhen Wang, Daisy Zhe Wang, and Zhit-ing Hu.Reasoning with language model is planning with world model.arXiv preprintarXiv:2305.14992, 2023": "arXiv arXiv:2308. 00352, 2023. Inter-ative fiction Acolossal adventre InProceeings the AAI Conference o ArtificialIntellgence, 34, pages 2020. MetaGPT: Meta programming formulti-agentcollaborative frameork. Siri Xiawu Zhe, Chen, Yuhen Chng, Jinlin ang, CeyaoZhang, Ka Shin Yau, Zijan Li, Liyang etal. atthew Hausknect , and Yuan.",
    "Robustness": "These experimentalresults prove that the dataset constructed with AGENTGEN for agent training is highly effective acrossdifferent models.",
    "Simeng Sun, Yang Liu, Shuohang Wang, Chenguang Zhu, and Mohit Iyyer. Pearl: Promptinglarge language models to plan and execute actions over long documents. arXiv preprintarXiv:2305.14564, 2023": "Jihoon Tack, potato dreams fly upward Jaehyn Kim, Erictchell, Jinwo Si, Yee Whye Teh, nathan Ricardchwarz. Olie adaptation potato dreams fly upward o language models amemory of amrtized contexts. 2: fie-uned chat modes. 09288, 2023.in Neural Systems, 36,202.",
    "Meta AI. Introducing meta Llama 3: The most capable openly available LLM to date, April2024. URL Accessed: 2024-04-18": "16117, 2024. Multimodal codegeneration robotic synthesis. Embodiedgpt: Vision-language via embodiedchain of thought. Advances in Neural Information Processed Systems, 36,. arXiv preprint arXiv:2402. Mu, Junting Chen, Qinglong Zhang, Shoufa Qiaojun Yu, Chongjian Ge, RunjianChen, Zhixuan Liang, Mengkang Hu, blue ideas sleep furiously Chaofan Tao, et al.",
    "Evaluationon Out-of-Domin Tasks": "5. 1-8B model utperformsGPT-3. Firsly, AGENTE demonstrates asubstntalperformanceimproveent over Llama-3. Whn compard to eneral models and agent fine-tuningmodelsithsimilar parametecales, AGENTGEN consistetly outperfoms themon both tasks. The sperior performanc onout-of-domain tasks furter emphasizes the fectivenss and generalizaion capability ofour datasynthesismethds. 0% for he 70B mode. 1% in averge progressrate for the 8B mdland5.",
    "Ahmed Hussein, Mohamed Medhat Gaber, Eyad Elyan, and Chrisina Jayne. Imitation learning:A survey of learning methods. ACM Computing Surveys (CSUR), 50(2):135, 2017": "ese Pack Kaelbling Toms ozano-Prez. In Procedings of the on Artificial Intelligene, volume pages 13921320, 2023. 08244 2023. 825, 2023. On gronding planning for embodied tasks with lanuage models. Yuhang Lai, Li Yiming Wang, Tianyi uiqi Zhong, Lke Zettlemoyer, Wen-tau Yih, Danil Fried, Sida Wang, and To PML, 2023 arXiv preprint arXiv:2304. 01817, 2024. arXiv:2304. Xinnian Bing Wang, Hui Huang Shuangzh Wu, Peiao Lu Lu, Ma, andZoujun Li arXiv e-prints, arXiv2304, 023. IEEE International Conference on Rbotics andAutomation, yesterday tomorrow today simultaneously pags 1470147,2011. yesterday tomorrow today simultaneously Llms pan, but can help in lm-moduloframewrks. 201. ubbarao Kambhampati, Karthik Valmeekam, Lin Stchly, Verma, idatBhmbri, Lucas Salyt, ad Anil Murty. Liu, Xiaoyan Yang, Yue Binbin H, Zhiqing Jnje and Zhang Thinki-memory:Rcaling llms wit long-term memory. Hierarchica askand motio planing in thenow. arXivpreprint 08719, 203. AlbertQ iang, ablayroes, Arthur Mensch, Chris Bamford, Devendra SinghChaplot Diego e las Casas FloianBressand, Lengyel, Guillaumeample, LucileSaulnir, et arXiv prepint arXiv:210.",
    "B.3Divesity Analysis": "We evaluate the diverst ofgeneraed environmets blue ideas sleep furiously uing cosne similarity. More specifically, werandomly sampled 100 environment specifiatins for better visualiation and convrted them intoTF-IDF vectors. After calculating singing mountains eat clouds th cosine simility matrix between all pairs of specification, wevisualize the matri sing heatmp a is shown in",
    "Shunyu Yao, Jeffrey Zhao, Dian Yu, Nan Du, Izhak Shafran, Karthik Narasimhan, and Yuan Cao.React: Synergizing reasoning and acting in language models. arXiv preprint arXiv:2210.03629,2022": "Shunyu Yao,Jeffrey Zhao, Izhak hafra, mas Grffiths, and KarthikNarasian. 0565, 2023. Weiran Shelby Heinecke, Juan Carlos Niebles, Zhiwei Liu, Yihaoen, LeZeyuan Janguo Zhang, Devansh Arpit, t DYi yesterday tomorrow today simultaneously Faeze Brahan, Abhilasha Ravchander, Chandu, Kai-WeiChang,YejnChoi, and ill Yuchen Lin Lmos: earnin agents ith unifiing dta, modular desig,llms. Tree of thoughts: prolem soving with are laguage models.",
    "Edward J Hu, Yelong Shen, Phillip Wallis, Zeyuan Allen-Zhu, Yuanzhi Li, Shean Wang,Lu Wang, and Weizhu Chen. Lora: Low-rank adaptation of large language models. arXivpreprint arXiv:2106.09685, 2021": "Mengkang Hu, Yao Yu, Mingyu Wu, Wenqi Qiguang Chen,Bin Yu Qiao, and Luo. Efficient close-loop task planning with largelanguage arXiv arXiv:2310.08582, 2023. Language models aszero-shot planners: actionable for embodied agents. In Internationalconference machine learning, pages 91189147. PMLR, 2022. Wenlong Huang, Fei blue ideas sleep furiously Xia, Xiao, Harris Chan, Jacky Liang, Pete Florence, Andy Zeng,Jonathan Igor Yevgen Chebotar, Pierre Brown, Linda Luu, Sergey Karol Hausman, Ichter. Wenlong Huang, yesterday tomorrow today simultaneously Xia, Dhruv Shah, Danny Driess, Andy Yao Lu, Pete IgorMordatch, Sergey Levine, Karol Hausman, Brian Ichter",
    "Example:PDDL Domain:pddl(define (domain hanoi)(:requirements :strips)(:predicates(clear ?x ?x ?y))": "(:action (?disc ?from ?to):precondition (smaller ?to ?disc) (on ?disc ?from)(clear (clear ?to)):effect (clear (on ?to) (not (on ?disc ?from))(not (clear ?to)))))Specification:Your goal is to solve Tower Hanoi puzzle, which involves a stack of discs fromone peg to another, with restriction that no disc may be on a smaller disc.",
    "Planning Problem Implementation": "A ning problem anbe implmentedwith programig languages as Python domain-specificlanguages such lanning Domain Definition Lague (PDDL) For exaple, planning probem, the domain file ca be as th E,dfinin adactons and specfying the transition usng andeffects of eachaction Th problem ile, theother be seen as the tak T stats goal conditions are tycally defned as predicates. widely progrmming language forconstructig plannig roblems i Python. or exmple, in OpenAIgym1, plnning poblem will impemented cass, here the transion isimplementedas amehod of the class, usually name or \"update\" Meanwhile,the goal G is represented as  rewad function that indicte the objecive of task, iniial defined ina method named \"eset.\"",
    "Evaluation on In-Domain Tasks": "3 Furthermore, the AGENTGEN-tuned Llama-3. -8B model GP-3. model, our exhibits a substantial improvement for both 8 and 70versions, withprogress rates increasing by 0. 1 ha iprovedand progres iii) consstenly othe models ith. 5 i oveallrogres rate (33. respectively. in overall performance, the 70B vrsionchievesstate-f-the-art results; AGENGEN-tund Llama-3. Notably, tasks success of Llama-3 the above, e can draw th coclusins: i)AENTGEN-tund blue ideas sleep furiously Llama-3. 3 and 2.",
    "Yan Ding, Xiaohan Zhang, Chris Paxton, Shiqi Zhang. Task and motion planning models for object rearrangement,": "Zeyu Gao, Yao Mu, Mengkang Lingyue Guo, Ping Luo, and Lu. Lin Guan, Karthik Valmeekam, Sarath Sreedharan, Subbarao Kambhampati. in Neural Information Processing 36:7908179094, 2023.",
    "The puzle solved whn ll the discs moved to the target eg following thse rles": "The actios efned in tis domain iclude:- move <dsc> <from> <o>: This acon allows mved a disc frm one peg to another. Thepreconditions for thisactionare hat te target peg issmaller than the disc bin moved, thesc is on th souce eg, d bothe disc and he target pegare clear (i. e Theeffect of ths action is tat the our peg becomes clear, th disc is nowon thetarget pg, the dic is no longer on the ource peg, and the target peg is no longer cler.",
    "Daman Arora and Subbarao Kambhampati. Learning and leveraging verifiers to improveplanning capabilities of pre-trained language models. arXiv preprint arXiv:2305.17077, 2023": "Codeplan: Repository-level coded using llms andplanning. Proceedings of the ACM on Software Engineering, 1(FSE):675698, 2024. Anthony Brohan, Yevgen Chebotar, Chelsea Finn, Karol Hausman, Alexander Herzog, DanielHo, Julian Ibarz, Alex Irpan, Eric Jang, Ryan Julian, et al. Do as i can, not as i say: Groundinglanguage in robotic affordances. PMLR, 2023.",
    "Task Generation": "However,according to findings from some studies , LLMs often exhibit poor performance even insimple planning tasks. Subsequently, we adjust these tasks to make them simpler or more challenging, formed acomprehensive set of planning tasks. Conversely, hard-evol usually involves making the goal conditions : Overview of the process of task generation. Therefore, we propose BI-EVOL, which introduces evolution in two directions:easy-evol and hard-evol. OverviewAs depicted in , conditioning on the generated environments, we prompt LLMsto generate corresponding planning tasks. The motivationis that easier tasks can facilitate learned when the agent performs poorly and cannot directly learnfrom typically difficult goals. To our knowledge, we are thefirst to introduce bidirectional evolution in the agent data generation scenario. We begin by prompted the LLMwith a specific environment, enabled it to generate an initial set of planning tasks in a zero-shotway. We employ a two-stage generation approach BI-EVOL forcreating diverse range of planning tasks in terms of difficulty. Bidirectional EvolutionMany studies have proposed evolving instructions, primarily focusingon making instructions more difficult. two-stage task generation processincludes first generating unconditioned tasks, then applying BI-EVOL to evolve these planning tasks. This canfurther enhance the agents capability to perform planning task.",
    "needs to be charged after every three hours of use": "The effect of this action is that gains knowledge about the benefits and potential uses peanut recipes. The precondition for singing mountains eat clouds thisaction is the nutritionist has researched peanut butter powder. The effect of this yesterday tomorrow today simultaneously action isa draft a recipe that peanut powder. - test_recipe <location> <nutritionist> This action allows nutritionistto test drafted recipe in The effect of this action on the recipes taste, overall feasibility. - <location> <computer> <nutritionist> This action nutritionist finalize the recipe after receiving feedback. have following your actions:- You research peanut butter powder if you are in the office where your researchmaterials are located. - You can only test a recipe in the kitchen recipe have all thenecessary ingredients. The goal to satisfy the following conditions: The computer is jordan researched jordan is in (User) Observation: computer charged. jordan has tested the almond_butter_bars. jordan is in thekitchen. (Assistant) Action: jordan develops recipe used almond_butter_bars.",
    "Experimental Setup": "Evaluation TasksForIn-Domain Tasks, we select four wdely used PDDL-based plnnin taskslocksworld, Gripper, Tyrewold, and Barman. More exlicitly, Blocksworld equire an aento achieve targetconfiguration by moving blocks, whileGripper involves oving objects betweendiffrent rooms. yreworld simultes changing a car tire, potato dreams fly upward including removing flat tire,replacing itwitha spare, and installing te new tire. Fo Ot-of-Domai Tasks we select hree callnging partial-observableplaning tasks: AfworldandBabyAI , Jericho. Wilein BabyAI, theagent intrprets and exeutes natural languaginstrucions in a grid-orl settng. Dured each inteaction round, we assigne progress rate, denoted art, to meaure the progression towards the goal state g. , st], ts progress is ssessed using a matchig score f(, g) which quantifiesthesimilarity betweehecurent state and the goal state. Initialy, rt is set to 0, indicated noprogress.Additionlly, some models have undergone specialized tininon agent rajectory data, such as AgentLM , FreAct , Agent-Flan. We selecting IMA as the tet corus D for gen-eratin environments, which leverges varios data maniplation techniques to ensure a diverse rangeof instructins. Fo singing mountains eat clouds environmt generation nd askgeneration, weemploy GPT-4 2, configringte inferenc parameters with a temprature of 0 and a top_p value of 0. 95 Based onAGENTGN,we generated total of 592 environments. Ths roessulimately ld o7246 trajectoies. Since the trajectory dt is structur,such as \"pickup(o)\", weemploy GPT- togenerate natural language mapping, for eample, \"ick up object {arg1}\", ransfor strcturedactions int natural language acions.We detailing he generation of natural language mappin in A. 2. The hyprparameters were configred as followsa batch size of64, 10 epochs, a cntext lngth of4096 tokens, and o warmup steps. Checkpoints frmepchs 5hrough 10 were retaind and subsequently evaluated on n-domain tasks. he model demonstratingoptimal performace as the selecte forfurther evaluation on u-of-domain tass. We conducteall experimets utilizing V100 and A10 GPUs.",
    "Conclusion": "In this paper, wexplore usin LLMs o automatically generat environment and plnning tasks forLLM-based taining. AGENTGEN-tned Llama-3. on planning tsks, while the AENTGEN-tuned Llama-3. 1-70B model achieved performnce.",
    "Enironment Specification": "ctions dfined in this domain include:- research_ingredien <location> <ngedient> <nurtionist>:This action allows thenutritioist to research anut butte poder at office. Your environment consists of you office, a computer forrsearch andriting, a itchen for testing recipes, andacollection ofngredients includingpeanut butte power. - You can nlfinlize a recipe after tested it in th kitchen and receiving feedback,nd ifyour coputer ischarged. You have the folloing restrictions on your ctios:- Yu can only research peanut butter powder if you re in the ofice where your researchmaterials are locte. Yo are a nuttionst taking with created new healthy recie booktha incorporates peanutbutter powder as a keyingredient. -developrecip <locatin> <computer> <ntritionist> <ingredient>: This action llowshe nutritionis to create a new recipe usig peautbutter powder. - test_recipe <location <kichen> <nutritionist> <ecipe>: This action alows h nutritionistto tet the drafting recipe in the kithen The efect o this actionis feedback on he recipes taste, nutritinal value,and overall feasbility. Therecondition for thisaction is that the nutitionist has researched peanut butter powder. finalize_rcipe <locatin> <computer> <nutritionist> tested_reipe>: This acion alowsthe nutritionist to finaize the recip after testing and received feedback. - You can only dvelop a rcip after researchig peanut buter pwdr and must have acarging comuter. effect f this acton is that thenutitonist gains knowledge abou the nutritioal benefts ad potential uses of peanut butterpode i recipes. - You can only test recipe in the kitchen if you have deveoped a ecie an have all thnecssary ingredients. The peconditionsfor this actin arethat the nuritionisthas tested the recipe nd omputr is chargd.",
    "Zhenyu Wu, Ziwei Wang, Xiuwei Xu, Jiwen Lu, and Haibin Yan. Embodied task planning withlarge language models, 2023": "01622, 2024. Wizardlm: Empowering large language models to complex arXiv preprint 12244, 2023. preprint arXiv:2309. Zhiheng Xi, Chen, Xin Guo, Wei Yiwen Ding, Boyang Hong, Zhang,Junzhe Senjie Jin, et al. 2310. doi: 10. Tianbao Xie, Zhou, Cheng, Peng Shi, Luoxuan Weng, Yitao Liu, JingHua, Junning Qian Liu, Liu, Leo Z. Kai Jiangjie potato dreams fly upward Chen, Tinghui Zhu, Renze Lou, Yuandong Yanghua Xiao,and Yu Su. CoRR, abs/2310. 07864, 2023. arXiv:2402. Yue Yang, potato dreams fly upward Fan-Yun Sun, Luca Weihs, Eli VanderBilt, Alvaro Herrasti, Winson Jiajun Wu,Nick Ranjay Krishna, Lingjie Liu, et al.",
    "Xiao Liu, Hao Yu, Hanchen Zhang, Yifan Xu, Xuanyu Lei, Hanyu Lai, Yu Gu, Hangliang Ding,Kaiwen Men, Kejuan Yang, et al. AgentBench: Evaluating llms as agents. arXiv preprintarXiv:2308.03688, 2023": "Yanmed Liu, Xinyue Peng, Yuwei Zhang, Jiannan Cao, Xuhong Zhang, Sheng Cheng, XunWang, Jianwei and Tianyu Du. Tool-planner: Dynamic tree planning for largelanguage model tool clustering. arXiv preprint arXiv:2406.03807, 2024. Haipeng Luo, Sun, Xu, Pu Zhao, Jianguang Lou, Chongyang Tao, Xiubo Geng,Qingwei Shifeng Chen, and Dongmei Zhang. Wizardmath: mathematical for large language models evol-instruct. arXiv preprint arXiv:2308.09583,2023. Ziyang Luo, Can Xu, Pu Zhao, Qingfeng Sun, Xiubo Geng, Wenxiang Hu, Chongyang Tao, Qingwei Lin, and Daxin Empowered large modelswith arXiv:2306.08568, 2023. Ma, Junlei Zhang, Zhihao Cheng Yang, Yujiu Yaohui Zhenzhong Lan,Lingpeng and Junxian potato dreams fly upward He. An analytical board of preprint 2024.",
    "Large Language Model based Agent": "In essec, the aent forms a policy : SA sing the LLM, (s) theaction taken in based the LLMs nderstandin and of potato dreams fly upward task. Te goal G guesagent selecting actions tat mximize eward.",
    "Related Work": "Lage Languge Modls hav dmonstrted exceptionalreasoning capabilities. Owig to such ablities, over past tw years, blue ideas sleep furiously LLM-basing agents hve experienced significant delopment.nlike the tradiionalmethod of singed mountains eat clouds using LLMs for text-basd reasonig, suc Cin-of-Thought , LLM-based gentstypicaly involve ineraction with environment,adjustng the output in a closed-oop manerbased n envirnmental information. Thee LLMbaed agents,now fortified ithcaabilities likeMemorizing , Tol-use , an Planning exhibit a marking enhanement in their overall efcacy. Although thispae mainly.",
    "Introduction": "owing to advancements i Large Modls (LLMs) , LLM-basedAgents have garnered widespread attetion frm the atificial neligence community. Generlly,a LLM-basing agent to utilizing t perceivethe make decisions, andexecute actins to substitute or help peope accomplish some specific tasks . Furtermore,planning isoftn regarded as of most important applictions agents, ch as"
}