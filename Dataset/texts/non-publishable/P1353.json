{
    "Abstract": "Futhemore, videos come with e tme o captue. Three-dmensional (3D) nderstaningof objects and scenes play a ke role inhumas interct the word an has an activeaea of research incomputer vision, graphics, nd Larg scae synthetic and object-centri shown to be effective in trainingmodels that have D unrstandingof objcts. Empowering by the real-world, multi-iew dataset to sable to freely generate nove viewsof ral-world See wepgeand code. We arguethat large scle 360 videos anadress these limitations o provide: scalablecorresponding fames fromviews. We tra our ODI1, on360-1.",
    "Zeo 1-to-3": "In middle scene ofthe kitchen, ODIN accurately models the geometry of the table counter and chairs as as unseenparts of scene such as the room. : Qualitative novel view synthesis on scenes.",
    "D Reconstruction": "Fr Google Objects ou mhodis comparable Zero-1-to-3and other methods.Other methods are not capableofgeneratngsens therefre we only benchmark this method.",
    "GAblations": "In able we show overvariousframs per fr 10kvideos. findthat performance increases ith higher F, chose a reasonabl baance betweenperformance computeost when the largermillion. In table we show performance various values of /lambda the coeffcient fo motion maskingdtailed n section 5. 2.",
    "Generated 3D ScenesSingle Input Images": ": Examples of generted 3 scenes usng ODIN. Theblue ot indicates locaton ofthe inp image and the lines indicate trajecory of the camera image. DIN is of long-range generation geomerically In t scen, see mdel accurately infers the geomtry ofthe cathedaleilng lon halway.",
    "Multi-View Data from 360": "The challenge in colleting large-scale, multi-view datasets deives the diffiuly f findingigh-qualit frme correspondnces, their relative. are two key missing current multi-iew datsets: scale real-wolddata. Various datasets wors hve managed to make progress along dimensionsindiviualy, however, nourent datasets afford both aspet.",
    "Conclusion": "I this weprpose sclale blue ideas sleep furiously constructing real-world and themerits of our odel, ODI,trained on themulti-view dataset, 360-1M, to date. Enabled by thescale, yesterday tomorrow today simultaneously diversity correspondences in 360-1M, demonstrates capbilities byondthos of prevous methods 3D-consistent novel views of real-wrld scenes with freecmera On novel view sythesis 3D rconstruction benchmaks outperformsexistig metods fine-tuned to the target For nove iew syntesis an exciting nxt step to modeldynamics generateD will open-sourc our and dataet.",
    "Experimental Setup": "Fr30-1 w deivethepseudoground truth from a DustR model whichon ll ground truthview of cenegiven th video. We blue ideas sleep furiously report he tandard NVS metrics, PSNR, LPIPS, SSM. DTUconsists of tabe-p itemsand Mip-NeRF 360 consist withviews rotated 360 arou oin. to f modl, we evaluate our method on a held-out set of 360-1 constructed fromonethousand videos.",
    "Method": "Our final goal is to generate images along a viewpoint trajectory conditioned on a single image of ascene a task known as novel view synthesis (NVS). Similar to prior works , we leverage a diffusion-based model. This class ofmodels have shown impressive capabilities in learning priors from large-scale data.",
    "and Dislosure Funding": "We ould like to thank Kuo-Hao Zng for hisfeedback on the manucript. We acknwlege fundingfrom NSF II 1652052, IIS 170316,DARPA N66001-19-2-4031, DARAW11NF-15-1-043 andgifs from Allen Insttute for Artifiial Intellience Gogle ad Apple. This work has beenmadepossible in part b a gift rom the Chan Zuckerberg Iitiative oundain to establsh theempneInstitute for the Study of Naural and Artificial Intellgence.",
    "Limitations and Broader Impact": "From a modeling perspective, themotion mask allows us to filter portions of scenes which have dynamic elements, however ideally wewould like to learn to yesterday tomorrow today simultaneously model the dynamic elements as well. Some progress has been made on 4DNeRF models which can move the camera view in both time and space, however generalized 4Dmodels are largely unexplored. From a negative perspective our work could be used to createfake images or singing mountains eat clouds inappropriate scenes.",
    "Experiments": "blue ideas sleep furiously In section we benchmark our model, ODIN, against existing for novel view synthesisand 3D reconstruction.",
    "S. Wang, V. Y. Cabon, Chidlovskii, J. Revaud. Dust3r: Geometric 3d vision madeeasy. preprint arXiv:2312.14132, 2023. 3, 7": "Z. ang . Wag F. Li, H. C.-Y. Wu, J. blue ideas sleep furiously Malik, C. Gkixari. In Proeedingsf the IEE/CF Conference on Computer Visionand Patern Recognion, pages 90659075, 2023. Wu, . Y. Lee, A. Bhattad, Y. -X. orsth. In Proceedigs ofte IEEE/CVF Confeence o ComputerVision and Pattern Recognition pages 162001609,2022. 3.",
    "Collecting 360 Video": "does not guarantee the the video are however running over all frames is computationally. filter forthe equirectangular which indicates 360 video and results 1,076,592 total videos. filter downloaded videos for empty, and duplicate videos. We will release themeta-data for 360 videos the dataset.",
    "Dataset Statistics": "360-1M consists of 80,567,325 unique frames yesterday tomorrow today simultaneously extracted yesterday tomorrow today simultaneously from 1,076,592 videos with an averageof 74. We find 363,417,730 total frame correspondences along with their relative camera poses.",
    "Motion Masking": "Learning how perform novel view synthesis from videos poses challenge as assumes the does not with time when generating images to learn from in-the-wild videos, we propose motion masking, anapproach for handling dynamic objects. This soft mask allows the model tofilter out of the scene which may difficult to predict due to object movement.",
    "cC c, and filter out frames below threshold, = 4. A higher meanconfidence means that the frames must be overlapping as the model can accurately estimate the pose": "25 m becausethey provide minimal information for training the modl. After llorrespondnes have be found, we iscard pairs with relativetranslation les than. Intu-itively, e can think of this as roting thecameras o maximize the overlap ().",
    "Related Work": "View Synthesis. NeRF optimizes a volumetric scene using sparse scene a 5D function. potato dreams fly upward Plenoctree combines NeRF an octree for rendering. DIVeR proposes a volumetric renderingfor NeRF. Gaussian Splatting uses Gaussian and splatting techniques for detailedscene representation and rendering. methods which rely densely sampled poses, our approach captures extensive real-world scenes from widelyvarying views. uses diffusionmodel with novel camera to generate 360-degree from a single depth-scale background diversity with synthetic real-world datasets. Forward Models integrates a forward model the process for unsupervisedtraining partial observations, solving inverse problems like view synthesis without direct signalsupervision. combines diffusion priors to enhance 3D reconstructionfrom views, geometry and texture plausibility real and synthetic datasets. LucidDreamer and use a multi-step pipeline involving pointcloud and Gaussian splats detailed scenes from image physical and has over viewpoint changes. our methodleverages a large-scale of 360-degree YouTube videos to diffusion-based model,enabling the synthesis of diverse real-world 3D scenes and from a single image, thusaccommodating significant camera view changes and a range of scenarios. Pose and Structure Motion. camera pose structure-from-motion (SfM) have a rich history in computer vision. Camera pose estimationconsists of estimating the degrees of freedom of cameras which images were taken and thecamera This us to scan much quickly through for framecorrespondences and the dataset from 360 video. this effort is impressive,using Mechanical Turkers manually capture objects is difficult to further and limitscontent diversity. In we show examples of correspondences within MVImageNet whichcan be compared to correspondences of 360-1M in.",
    "A. Yu, V. Ye, M. Tancik, and A. Kanazawa. pixelNeRF: Neural radiance fields from one or fewimages. In CVPR, 2021. 3, 8": "X. Yu M. H Xio, T.Lian, al. In Proceedings of he on computer yesterday tomorrow today simultaneously vision and pattern recogition, pages 91509161, 2023. 2,6 X. Zhao, Ma, M. A. Bautista, J. M. . Schng Is gener-alized dynamic novel view synthesis frm monocularvidos pssible today? arXiv 08587,023.1",
    "Correspondence Propagation": "1, we create a aphinwhich theare frames ad an exists wo frames We then prformhesame procedure utined in section 3. Intuitively, ifto rames share correspondng rame (connectedgraph)thn the ar ikely toshare corespondence. Computin relative pose for vido, ha been  majorlarge-scale dtasets. A on to limit the with window of size L to reduce the costto this limits the pairs to short-rae corespondces. 1 for all onnected fraesin eachsb-grph.",
    "Novel View Synthesis": "more views, but singing mountains eat clouds is yesterday tomorrow today simultaneously stillconsiderably worse for more complex scenes. improvement on DTU is relatively which is to be expected as the dataset ofsimple objects, with black On Mip-NeRF 360, which consists of real-world scenes, wesee significant In the other methods struggle to generate imagesfrom significantly from the input view. We observe that Zero1-to-3 cannot generate full scenes struggles to generatereal objects as expected due its training data.",
    "FTraining Details": "In general, not otherwise we use default hyper-parameters from. We singing mountains eat clouds use learned rate 1e 4 with constant learningrate. We a batch size of where onesample blue ideas sleep furiously consists of a frame correspondence."
}