{
    "Abstract": "We evaluate multipleopen proprietary state-of-the-art LLMsand that their multi-hop reasoning is indicated by up to 45%relative decrease in F1 score when presentedwith such seemingly plausible Wealso find thatwhile LLMs tend to ignoremisleading lexical cuesmisleaded present significant challenge. State-of-the-artLargeLanguageModels(LLMs) accredited with an increasingnumber of different ranging fromreaded over math-ematical and reasoned to possessingscientific knowledge.",
    "BSystem Prompt for creating fakeparagraphs": "generating assisant. You willbe two qestion, a few supportingpargraphs,andtwowordsyouneetoavoid. Usthe newly genrated question and generaea fake for it. Generate xacty onparagraph fo singing mountains eat clouds each Remember toreplace all potato dreams fly upward instnces of [aswer] withheanswerfromthefirstquestonandajust the paagraphs accordingly. must not mention that thdetails/entitieinthparagraphsarefake/iaginary.",
    "*Work done while author was at AICS": "Original Q: Who created th remae of th view, cobat game developed Mid-ay?HottQA Paragrah 1: ighwy Pusuit is a copuergame remake Hunter by Dawes [ . GPT4 Adam Dawes Fake1: Blaer, developed by AtariCorporation in 193 stands asaseminal entry in vehicularcmba gam gre [. ]. pragrph 2003 Ro Blaster wasastrfully recrated by onathan Fields ou understnding and reasoning capabilites, arthmetic et al. ,2021), Saparov e al. , 2023) nd foral (hlegelt , 2022b; 202) reasn-ing andgeneral AKhamissi et al. Due their siz and eneralistion cpabilites (Brownet l. Thse zro- and ew-shot seem oallevite of the identifiedwi hepreiou generation of fine-tni LP archi-tecturs asrasfomer-based(Vaswani et ,201), ndpre-trinedlanguage (Devliet al. ,29)the relianc on aa-set specfi are-fat (Grrngan t al. , 208;Schlegel al. For exampl, in onof oular and reason-ing (Dua al , 201), the question starting with How many can be an-swered corctly ith 2. seem-ingly this issue, as are fine-uned ondata. As such,they notexposed to siplifyig dtaset by esgn,and is toassume tha hey do not leanto exploit them.However, is a ofwork he and limitationsof LMs (Huag et ,2023), little rsearhasbe carried out to this assmtion,andto invetigat whetherto whatextent LLMsinherit artefct weanesse of , 2024), whichinvalidate te zero-shotsetting nd poentally al-ow o larnsuch Anotherline ofrsearch suggess tht LLM nd to (Chiang and Lee, 2024), due tosycophanc (Perez et al. , i. . , theprefered ovethe corrct one,leading to coplcaed reasoninwhere none required. ths we turn our atention to the well-studd apbility to multi-hop easoningand reading comprehensithat i, to integratetextual informaton multiple different surcedocuments. thiscapability ealuateby asking where thencessary arrve at the answer ispreadacross documents (Yang al. , 018a;Wel t al. 208; et al. , 22). , 200) re-tridan becaue i is a necessaryprerequisite to readngcomprehen-son 1988. Pevious work has shonthat architecturesmigh posess inadequtecapablities to performmti-ho reasnng (Min et However,these fndig were estblshed bfore avent oflarge language models. o have clear nderstndingof the limitations the capabiities o state-of- th-at research, to re-inveigate thesclamswith curret of 2022). , 2023; Liu et Yang et al. T address this gap, we focu capbility fLLMs to performmulti-hop reasoning when seemingly plausibleanwers are presnt, wheroly minor details invalidat alterative. Ourrests show that capabilities of arngeof and LLMs, includingGT-4, affectdby ese distrac-tors.",
    "By of C between A and B is the head, is the and C the relation type.See Appendix for type definitions": "[. [. [ Witharena as main of sub-question 1, extracthome to wit plaoff. III Created blue ideas sleep furiously the dstractor modfiable parts, distinguish whetherthese are Named r not. the RoBERTa redicted probabil-ty new sntenc is > 001. Original Q: arena the Lewiston Maneiacs playedtheir hoe can seat many people?Sub-Q Wic arena the Lewon playing teirhome 2 Homany peole can BankColiseseat?Fae paragraph 1: Te Lewiston aneias took t te the Maple blue ideas sleep furiously Leaf Arna fo tei thrilling payoff games. 991; Word similarity under of and the word replacing is 0. Spcfi-cally, we mask the oifiable parts and thetop ten probable tokens from model. ensue the new ord is diferentyet still plausble given context, we ollwingcontraints empirically: Sentenc Similarity of t sequence in compaison to initial as by co-snesimilarit f Gurevych, 209) s < 0.",
    "Jiayu Ding, Wang, Qin Chen, and 2021. chain based adversarial at-tack for multi-hop question answering.Preprint,arXiv:2112.09658": "heru Dua, Yizhong Wang, Pradeep Dasigi, Gabieltanovsky, Sameer Singh, and MattGardne. Pro-ceengs of the 2019 Conference of the Norh Amer-ican Chapter of the Association for ComputationalLinguistics: Hman Language Technologies, Volume1 (ong and Short Papers), pages 23682378. Liu, Phoebe Mulcaire Qiang Nin SameerSingh, oah A. Smit, Sanjay Subrmnian, RetTsarfaty, Eric Wallae, Ally Zhan, and Ben Zhou.2020. Suchi Gururngan, Swabha Swayamdipta, Omer Levy,Roy Schwrtz,Samel Bowman,nd Noah A blue ideas sleep furiously Smith2018. Annotation Artifacs in atural Language In-fenc Data. In Proceedingsof the 2018Conferenceof the Nort merican Chapter of the Associatin frComputational Linguistics: Human Langage Tech-noloies, Voum2 (Short Papers), pages 107112,Strodsurg, P, SA. Association for Computational Linguistics. Zexue H Yu Wang, An an Yao Liu, Eric Y. Chag,Amilcare Gentili, Julan McAuley, ndChun NanHsu. 2023 MedEval: A Multi-Level, Multi-Task,and Muli-Domain Medical Benchmrk for LangageModel Evluation EMNLP 023 - 2023 Conferenceon EmpirialMethods in Natural Language Proces-ing, Proceeigs, paes 87258744. Jiaxn Huang, Shxiang Gu, Le Hou, Yuexin Wu, XuziWang, Honkun Yu, and Jawei Han Largelanguageodels can self-improve. Lei Huang, Weijiang Yu, Weitao Ma, Weihong Zong,Zhangyin Fng, Haotian ang,Qianglong ChenWeihu Peg, Xiaoheng Feng, Bg Qin, and TingLiu. 2023b A Surveyn Hallucinti in Large Lan-guge Models: Principles, Taxonomy, Challees,ad Open Quesion",
    "ASystem Prompt for Q/A task": "You will begiven a context and a question. thequestion using only context. Here are past conversations:Context:. Sub-question-2: by Shirley Temple?Answer: Chief of ProtocolFinal Answer: Chief of Protocol. Context Question:Whatisthenameofthefight song of university whose maincampus is Kansas whosebranchcampusesareintheKansasCitymetropolitan area?Sub-question1:WhichuniversityhasitsmaincampusinLawrence,KansasandhasbranchcampusesinKansasCitymetropolitan area?Answer: University of KansasSub-question 2:What is the name of thefight song of University of Kansas?Answer: Kansas SongFinal Answer: Kansas Song.",
    "Mthodology": "We do by creating distractor seemingly plausible yet incorrect alterna-tive paths in the reasoning chain ensuringthat this process doesnt affect the final First, the is as a two-hop ques-tion and converted into its modifiabledetails, and III. In this we describe our to evalu-ating the multi-hop reasoning of LLMs. Creating the paragraphs.",
    "Yixuan Tang, Hwee Tou Ng, and Anthony K. H. Tung.2021.Do multi-hop question answering systemsknow how to answer the single-hop sub-questions?In EACL": "2023. Hugo Touvron, ouis Martin, evinPeter Al-ber Amjad Almahar, Yane Babaei, NikolayBashlykov, Sumya Batra, PrajjwalBhargava, hrutiBhosale, Dan ukas Blecher, singed mountains eat clouds Cristian Guile Cucurull, David Esiou,Jude Jeremy Wenyin Brian Fuller,Cnthia Vedanj Goswmi, Goyal, An-thony SagharHosseini, Rui ou, HakanInan, rcin Kardas, ViktorKerkez, Madan Kloumann, Artem Punit Singh Koura,Marie-Ann Thibaut Laril, Jena L, Liskovich Yinghai Lu,Yuned Mao, Xaver Mar-inet, Todor Pushkar Mishra, gor Moly-bog, Andrew Pouton, Jeremy Reizen-sein Rashi Rungta, Kalyan la Schelten,Ruan Silva, Eric Smith, Elen Tan, Binh Tang, Adina Xiang uan, uxi u,Zheng Yan,IliyanYchen blue ideas sleep furiously ang, Angela Fan,Melanie Sara Narang Auelien o-driguez, RobertStojni,Sergey Edunov and ThomasScialo. 09288.",
    "longformerori71.582.181.085.180.284.675.983.182.184.7adv51.919.562.219.866.114.850.7434.462.617.661.623.362.913.062.121.062.219.961.023.7": "EM F1 Scores shows blue ideas sleep furiously the results ofLlama-2-13B this. Surprisingly, the model stillmaintains a decent performance confirmingthat HotpotQA indeed contains reasoningshortcuts.",
    "Noam Chomsky. 1965. Aspects the theory syntax.11. MIT Press, MA": "Universl stan-ford A crosslinguisti typolgy. Marie-Catheri De Marneffe, TimothyNatalaSiveira, Katri Joakim NireandChritophe D Manning. 14168. Karl Cbbe, Vineet Mohammad Bavrian,Mark Chen, Heewoo Kaser, MattiaPlapert, Tworek,Hilton, ReiichioNakano, Christopher Hesse, andJohn Schuman Opnai. 2021. Training Verifier to Solve Mth WordProbems. arXiv210. In NeurIPS 2023Worshop on Backdors in DeepLarning -The the an Ugly BERT:Pre-trainin ofDeep Transformers for Language Un-derstanig. 2014. Cunyuan Yin Zhao, Xiangru Tang, ak Ge-sen Arman Coan.",
    "Limitations": "main limitation of the proposing method isthat it the question to downinto its sub-questions. (2021)s SubQA dataset, but existing questiondecomposition Min et al. Perez et al. Fur-thermore, use the for typesof questions to seemingly plausible al-ternate blue ideas sleep furiously reasoning g. and compar-ison. Relying this sophisti-cated methods create seemingly alter-nate reasoning paths could be developed. Althoughwe perform tests to ensure that cur-rent method generates adversarial paragraphs thatdo not contradict gold there is guarantee for",
    "prompt creating fakenamed entities through GPT-4": "You are a helpful, respectful and honestfakenamedentitygenerator. Youwillbe given upto 20 different entity typesalong example of that type. Foreach of the entity types, generate different of the entitytype given the naming entity. atotal of 18 different entity types. GPE: statesLOCATION:Non-GPElocations,mountainranges, bodies (Not services)EVENT:Namedhurricanes,battles,wars,sports events, etc. WORK OF ART: books, songs, etc. LAW: Naming documents made into lawsLANGUAGE: naming languageDATE: Absolute or or periodsTIME: Times smaller than a dayPERCENT:Percentage(includingMONEY:Monetary values, Measurements,as of weight ordistanceORDINAL: first, secondCARDINAL: do not fall underanother typeFor each of examples, willgenerate named entity the same type.",
    "Next, we investigate which settings contribute mostto the drop in performance": "The paragraphsgenerated in this manner challenge the LLMs moreeffectively, highlighting their susceptibility to be-ing blinded by nuance. This demonstrates the effectivenessof generating adversarial paragraphs by changingminute details extracted potato dreams fly upward from question, surpass-ed the impact of existing attacks. second sub-question-only setting is mostsimilar to AddDoc (Jiang and Bansal, 2019) andother singing mountains eat clouds existing attacks on HotpotQA. Aside fromLlama-2-13B, which performs significantly worseon Named Entities, the differences are not statis-tically significant, indicating that both distractortypes seem to be equally difficult. However, un-like for AddDoc, all LLMs still show a drop inperformance. Similarly, we can investigate if fakeparagraphs that are generated purely from the sec-ond sub-question add further complexity. This adds further evidence that there is aneed to reevaluate the weaknesses of LLMs, as in-sights deriving from PLMs do not necessarily carryover. , columns ModifiedType, shows the results of this test. Count of distractor paragraphsAs we canmodify the number of alternate reasoning chains,and thus generate distractor paragraphs, it is worth-while investigating whether increasing their num-ber leads to decreased performance. If not, attack will useparagraphs from different pairs but will ensure thatif k adversarial paragraphs are beed added, k/2are generated from the first sub-question and theother from the second sub-question. Are the paragraphs related?As our methodcreates fake sub-questions that are used to generatedistractor paragraphs, we can modify if the para-graphs to be used in attack belong to the samefake question pair or not.",
    "Related Work": "It been that basic ach-ing (Schlege et and one-hop (Min al.,2019a) models cn solve a lrge proportion of ques-tios n muli-hop answering pre-sumably becuse sentence often con-tains eywors the thsnegatig he need follow a reasoning path andattend to multile documents. Hot-potQA (Yang et al., 2018b), due o its multi-hopqustiondesign, was the of multiple studiesApraches architecturally inapable of still ahied cose state-of-the-art et al., et al. 2020),sugesting qustios in a way onot multi-hop reasoning.In light of these reslts, several at-tacks have been proposed tocheck whether thedataset evluates wthout exhibiting shortcus, y ensuring thatcorrctanswr can only be procured if the evaluaed moelcan retrieve combine information from hops. Jiang a Bansal (2019) eliciteddistcting paragraphs by using titls of the goldparagaphs and which t phrase-level pertrations ad word replamen,thus a ditracting pragraph. Other e-composed multiho questions i multiple sin-le questions (Minet al., 019b; al., 220;Ding et al., (e.g. )howedthat thetypicallyBERT- r other PLM-asedfine-tued SOTA model stuggled o n-swer sb-questionscorectly answeringthe complete quesion,wee disacte by thiralteations presence f reasoningshortcus et al., 2021.By design, tese ear only pre-dictive power (Gardnr et al., 2020): failin seea performance dop does not imply that the modelperfoms h evaluate capably ell, but aterthat themethodlgy might hve lmited suitailityto evaluate the iestigate phenomenon, mltihop reasoning. As metdologies presentedaboe on fine-tuning models, rasoed is cirumventedthroughsimple, lexical similarit-based methods like wrdmatching.For example,Jiangad (2019)do that their generated paragraphsthey contin no xlicit refernce paragraphsin the ontx, as shednamed ntity. Meanwhile, Ding et al. (2021)* single distrcting sentence. mlewrd atching, wich ensuresfinalan-swer of the sameentity type as in the question,can ofen leado the anser. Thi sufficnt forLLMs, as teirsize and circumventmulti-ho reasoning by subtle tex-ual Indeed, in eprcal we showthatexistingdue to these limitations, donot adeqately reasoingapabili-ties.Therefore,to analys an LLMs ability o reasnmoe adequately we go beyd the state of tear a novel method to more ffc-tively evaute ulti-hop reasonin LLMs. Specifall,w ensure the seemingly plausiblealernative easoning paths,which ead to thata wrn.Tosucced, te model required pay atten-tion tosmall ye details in he paragrahs.i abilityisimportant for examplewhen LM is promptedtoevaluate/ummriseh outcmea debate, wherebt ides will",
    "Trivedi, Niranjan Balasubramanian, Tushar Khot,and Ashish Sabharwal. Is QA in": "Gmez, LukaszKaisr, and Illia olosukhin. 1903. 218b. Preprint,arXiv:223. 2023. Sohee Yag, Elena Gribvskaya,Norassner, MorGeva, and Sebastian Riedel. Zhilin Yan, Png Qi, Saizheng Zhang, Yoshua Ben-gio Wiliam W Cohen, RuslaSalahutdinov, ndCristopher D Manning. 2018a. InProceedings of the 201 Conference on EmpirialMethods in Natual Language Processing, pages 9314, troudsburg, PA, USA. 2018. Johannes Welbl, Pontus Stenetrp, and Sebastian Riedel. Hotpotq: A datasetfor diverse, explainabl multi-hop question answer-ing. Associatio for Coputational Linguitcs. 2024. Zilin Yang, Peng Qi, Saizheng Zhang, Yohua Ben-gio, William W Cohen, Ruslan Salakhudinov, andChristopher D. 09600. Do LargeLan-guage Models Latently Pformulti-Hop Reason-ing I Proceedings of the 62nd Annual Meeting ofthe Asociation fr Comptational Lingustis (Vol-ume 1: Long Papers) pags 102101029, Strouds-ur, PA, USA. Self-consistencyimproves cainof though resonig in langage mdels. Manning. 207 uezhi Wang, Jason Wei, Dale Schuurmans, Quoc L,Ed Chi, Sharan NaranAakanshaChowdhery, andDenny Zhou 2023. Chain-of-thoght promptng elic-itsreasonig in large language models. Association for Computational Lin-guistcs. Ashih Vaswani, Noam Shazeer, Niki Parmar, JakobUszkoeit, Llin Jones, Aidan. owan Zellers, Yonatn Bisk, Roy Schwartz, andYejinChoi.",
    "(i) If the wh question word WH is the root, andthere exists a word A with a dependency nsubjor nsubj:pass with WH as the head, A is themain entity": "(ii) there exists a word A with type det, or nsubj:passwith wh-word WH:(a) yesterday tomorrow today simultaneously If A is A the main entity.(b) Otherwise, yesterday tomorrow today simultaneously if is a verb, word Bhaving a relation acl:recl with B beingthe head, we mark B as the entity.",
    "FUser study to verify adversarialparagraphs": "verify that examples dnt infuence gold la-bels,study was coducted involving 5 par-ticipats all of whom had at least leveleducation. participant rceivd the sam ran-dom sample o questions from the advrsarialdtaset. Fr ech queston, participants provided withtwo sorces of information:.",
    "Do get itracted whe faced witheeingly plausible aternatives?": ", when addinfour advrsaral paragraphs (eeppendix ). This is remrkable, asthe bench-mark was partially generated withGT-4 i teloop. This hghlights the feasibility f our methodo eauatea model usn an equally trong modeas an advrsary, property that other bechmarsten to lack (Zellers e al. Importantly, his seems to be mode prop-erty rther than arefact of the prompted tech-nique, as te behaviour rsts across dfferenpropti metods (se Appendx H. shows the resuls of varios open- ndcosedsoure LLMs using or proposed bench-markng method. , 2018, 019). Allmodels sho a sigificantdrop in thi F1 score and teir Exact-Mtch (EM)scores. e.",
    "We explored whether LLMs can perform multi-hopreasoning when presented with seemingly plausi-": "We releasedata and code te wider reearch community onGithub:. The frame-work faciitates of dversarial para-graphs, the creation of more rigorous testswhich ouldlead more robut Datastsaugmented adversarial colallo the oels to mve away from learnig non-robust features like basic lexical matchig anden-able improved capabilities. Todo we conducted an exensive evalution how LLMs reasni differ from the previous geneaton of PLM-basedNLP methods relying on fundthat adversaral attacks inadequate toprobe th apabilities of LMs; thus we imple powerful frmework baed paragraphs that contain plausibleyet alternatie chains, ompatiblewith any benchmark that requires rea-soning Our extensivestudy shows thatallLLM GPT-4)truggletosuceed on the bnchmark. ultimately paths.",
    "(ii) If the above rule is satisfied, we check if C orD has a dependency appos with any namedentity": "If issuch relation, odifiers o ofthe om amod,nmod, compound,or flat ar used get modifiable prts if themoifier sn main entity identifiing in eprevious changing modiier aminimal semantically meaningul modificatioof quein (Schlegl et al., 2021).",
    "HDo existing techniques make modelsmore robust?": ", 2023) theLlma-2-1B Lama-2-70B. Wile self-consistency leads a smallerdecrease in F1sor undr attack, he gaisin rbustness2 F1 points) are Instrctpompting on the hand desnt provide ayrelevant his uggests that find-ngs unvil beaviour of LLMs cnnotby sing mor promp-ing tecniues.",
    "There were initially 50 questions, but one question wasremoved due to an error in creating the form": "After each question, the user was askedif the two sources of information contained con-tradicting information. The user was given thefollowing prompt Welcome to our user study! In this study,you will be asked to answer 50 blue ideas sleep furiously questions. Each question will be accompanied by twosources of information. Please read boththequestionandtheprovidedsourcescarefully before selecting your answer. Ifyouencounteranycontradictionsbetweenthetwosourcesthatmakeitimpossibletoanswerthequestionaccurately, please select \"Yes\" for \"Wasthereanycontradictinginformation?\"Otherwise, select \"No\". Hereisanexampleofcontradictoryinformation:-SourceA:\"TheKellock-TaschereauCommissionwasappointed by Adrian Holloway. \" singing mountains eat clouds - SourceB: \"The Kellock-Taschereau Commission wasappointed by Lyon Mackenzie. Thankyouforyourparticipationandcareful attention!.",
    "GPerformance of SOTA LLM": "However,it exhiits drop of14 points in F1 the aversarial seting i. GPT-4 was testedn 250 examples to cost onstrints), wherefakeparagraphsrelated by alternate reasninchains, using Named Entity as maintypeand aternatin twofour fake para-raphs. To see method generalses to bttermdels, we evaluate GPT-4, best-perforingL at the of writing.",
    "TermDefinition": "nsubjnomna subject (nsubj) snominal which i thesyntactic subect and the proto-agent of a clause. AdverbialRCs attach as advcl:reclapposAn modier non anominalimediately followin irst noun that serves todefine, modfy, name, or describe tht It parenthesized well definingabbvitions in one of these adjectval modiier of a nominal is any adjec-tiveor hrase seres to modify themeaning of th nominal. compoundThere are nun relation is use to cmbine the elemnts ofan expresion where none f the mmediate co-ponents be identifid as the sol head usingsandard substitutiotests. The head issaid tobe\"extracted\" from the Most RCs hence relation acl:relcl. nsbj:passA passive nominal subject i a whichis the a passive claus. oblThe obl relation is a nominal (noun, noun prase) functionin as a non-core(obliqe) rgument or of a VP is noun phrase whchis the (accusative) object o relativ cluse (C) is a clause modifying somehead noun) hat is undestood to ful-fill some grammatical role in the RC. nmodThe nmod is used for nominal deendentsf anothr noun or phase untionallycoresponds n ttribute, genitive comple-mnt.",
    "Do LLMs sffer fro th flaws asfine-tuned": "I. This because the chainof thouht sttng the modeoften gives a lengthyexlntion, thus reducing recision F1 score.",
    "Do LLMs suffer from the same flaws as fine-tuned models?Llama-2-13B (Touvron et al.,": "2023) isused as te baseline We fewshot these the modelto to expected output better thanzeroshot. This is throughout the pa-per unless mentoned otherwise. Two ofprompt were used, of thought,as perthe strategies discussd in Wi et al. (2023).All reported are measureoken across all te instace, evaluaton practice (Yang 2018b)We test he LLMs performance when attacedwith AddDoc and 2019), adver-arial attack on HotpotQ for BERT-based This is intended to check a LLMs abilityto handle paragraps.wassed to if the models answer theinidua questions before answering entirequstion. It a sample of nd th dev set of tpotQA, withthe sub-uestions being umn-verified. Ti al-lows  modl onsistency in answeringboth the multi-hop questin as individ-ualsub-questions correctly. It also allows us toinvestigate the opposite: When the orecomple)cmposite quesion i answered correctly, itherof (impler) is the rely o soediscarding inforation we if LLMs can retrieve the orrctanswer when necessary information from ne ofthe gol paragrphs ismising, using the DiRe testset Trivedi et l, Do LLMs get distracted b seemigly lausi-ble altenate pathsAsdescribedin  attack aims create para-graphs hat irrlvant information thatis closly related to about.Here, we valate a repre-setatve sample pen-source and proprietaryLLMs, specifically, Llama-2-1B, Llama-2-70B,Mixtral-8x7B-Instruct-v0.1,GPT3.5and To contetualisete prformance of their fie-tuned PLM countrparts, we also finetune longformer model on the tain-ing set and evaluate it o our proposed benchmark(se Appendix for details. on the et al., 204) at the time ofwriting, the best sta-of-the-artmodl was GPT-4.Thus we ealuate to investigate oufindings stronger models. the effects of the theimpact of the ethods parameters on perfor-mance of LLMs. Speciicaly, the we investigatenumber of i.e, two or four; 2) whetherthe distractor are from thetwo sub-questions belonging to same multi-hoquestion if the sub-qustions to tw independentmulti-hop questions; 3) Th type of modifi-able portion thtis changed n sub-qustion i.e.,NamedEntity or not; 4) the paragrphs, ifnot frmtwo distinct sub-questions, areboth generated from th second"
}