{
    "Abstract": "Capturing ntermodal incongruities within pira challeng in multi-modal detection (MSD). neurl netork GNNs) have maderoised advancements in MSD, whih showadvantages in explicitly catured Specifically, we construct ahypergraph to high-oder prop-agation anila raph to perom hgh-frquency ehaced respectively. empower NNsto 1) better capture in-herent and complicated elationships onthe hypergraph and sufficient through enhanced mes-sages on the vanilla graph. Besides, in-roduce fusion information to fuse the twolearning graphfeatures.",
    "|Ni|vj,(k),(5)": "where Ni denotes yesterday tomorrow today simultaneously th neighboring nodes of nodei; wlij and whi denoe the weight contributions ofnode js low-frequency yesterday tomorrow today simultaneously and high-frequecymes-sages o nod i, espectively wit wlij + whij= 1.",
    "-DGLF89.0186.9881.5278.60": "81 (0. 06)77. 87 65)76. (1. Effect of High-order Aware Propagation1w/o high-order aware propagation87. 97 (0. 35 (1. 93)84. 20)85. (1. 29) Effect of High-frequency Propagation5w/o high-frequency propagation86. (1. 76)85. 81 (1. 94)85. 28 (2. 84 46 (1. 98 (0. 23). 17)77. 69 (1. 12)80. (2. 73 (2. 17 (2. 67 59 high-frequency included87. 95)84.",
    "Limitations": "(2) Te DGLF might contingent upn theqal-itythe pre-training models (BRT,ViT, and can beefit fro more fea-tur encoders, is not of this work. (3) vlidation n more diverse multi-modal aaets include additional od-ities such as and video, as well as estnaross vars othr tass, which may itsbroder generalizbility nd effectiveness.",
    "Conclusion": "Extensiveexperiments and on two MSD benchmarksshow the superiority of our proposed. construct hypergraph singing mountains eat clouds and avanilla graph to perform singing mountains eat clouds high-order aware high-frequency enhanced Based on this, we introduce multi-modal bottleneck to effectively fusethe learned graph representations.",
    "Aaron den Oord, Yazhe Li, and Oriol Vinyals. 2018.Representation learning with contrastive predictivecoding. preprint arXiv:1807.03748": "Appl. MMSD2. 2016. 2013. ACM Trans. Radford, Jong Kim, Chris Hallacy, AdityaRamesh, Gabriel Sandhini Girish Sas-try, Askell, Pamela Mishkin, Jack Clark,et 2021. Just Accepted. Heterogeneous hypergraph embed-ding for graph Proceedings of the14th ACM international conference web searchand mining, pages Yang Sun, Bin Liang, Jianzhu Bao, Yice Zhang, GengTu, Yang, and Ruifeng Xu. Shaoxiang Wu, Damai Dai, Ziwei Tianyu Liu,Binghuai and Zhifang Sui. Association for Computational Linguistics. Attention is allyou need. 2020. A deeper look into sarcastictweets using deep convolutional neural InProceedings of COLING 2016, the 26th InternationalConference on Computational Linguistics: TechnicalPapers, 16011612. In Proceed-ings 61st of the Association Linguistics (Volume 1: Long 22312243, Toronto, Canada. Felix Wu, Amauri Tianyi Zhang, ChristopherFifty, Tao and Kilian Weinberger. Sarcasm as contrast between a positive sentimentand negative situation. 0: towards a reliable detection system. As-sociation for Computational Team, Anil, Sebastian Borgeaud,Yonghui Wu, Jean-Baptiste Alayrac, Jiahui Yu,Radu Soricut, Johan Schalkwyk, Dai,Anja et al. Soujanya Erik Cambria, Devamanyu Hazarika,and Prateek Vij. Peng Wang, Zhang, Hao Fei, Qiguang Chen,Yukai Wang, Jiasheng Si, Wenpeng Li, Qin. Simpli-fyed graph convolutional networks. Xiangguo Sun, Hongzhi Yin, Bo Chen,Jiuxin Cao, Yingxia Shao, and QuocViet Hung. Association forComputational Linguistics. Commun. 2023. In Findings of the Asso-ciation for Computational Linguistics: ACL 2023,Toronto, Canada, 9-14, 2023, pages 1083410845. S3 agent: Unlocking the powerof for zero-shot multi-modal sarcasm detec-tion. 2023. Pan, Zheng Lin, Peng Fu, Qi, andWeiping Wang. arXiv 11805. Ashish Vaswani, Noam Shazeer, Parmar, Llion Jones, Aidan N. 2016. Multimedia Comput. Learning transferable visual models language supervision. Denoised mutual information max-imization for video multimodal fusion. PMLR. family ofhighly capable models. 2014. Jeffrey Pennington, Richard Socher, and ChristopherManning. In Internationalconference on machine learning, pages 68616871. 2017. 2019. Schifanella, Paloma Juan, Joel Cao. In Advances in Pro-cessing 30: Conference NeuralInformation Processing Systems 2017, December 4-9,2017, Long CA, USA, pages 59986008. Detecting sarcasm inmultimodal social platforms. for Computational Linguistics. Association for Linguistics. 2024. In of the for Compu-tational EMNLP 2020, Online Event,16-20 2020, volume EMNLP 2020 of of ACL, 13831392.",
    "fusion model. In Proceedings of the 57th AnnualMeeting of the Association for Computational Lin-guistics, pages 25062515. Association for Compu-tational Linguistics": "Mj-ench: Is yourultimodal reward modl reallya good text-to-imag generation? arXiv:2407. Multivariate, mult-frequency and mult-modal: Rethinking grah neura network or ecognition in convsation. In Proceedings IEEE/CF Confrene on yesterday tomorrow today simultaneously Vision ndPatten Rcognition, pages 1076110770. Chen, Shao, singing mountains eat clouds Shuyuan and Heg TaoShen.",
    "Introduction": "Due to the rise of social media platforms such asX and Facebook, multi-modal sarcasm detection(MSD) has garnered increasing research attention.MSD aims to recognize sarcastic sentiment inmulti-modal posts (Cai et 2019), refer textual Unlike traditional sarcasm detec-tion (Riloff al., 2013; et al., 2016; Zhanget al., 2016) focusing on in expres-sion within the the objective of MSD",
    ": Conceptual comparison of the state-of-the-artmethods (a) and the proposed model DGLF (b). MIBis short for multi-modal information bottleneck": "By adaptively inte-grating high-frequency messages, captures sarcastic inconsistencies in neighborhoods, vital MSD. de-picted in (b), crucial visual informationburger, which aligns with sarcastic textual cuesbest may be scattered across the im-age (two burgers within For the firstissue, we construct a hypergraph (Feng et al. (2) We construct a hypergraph and a vanilla graphto perform high-order aware and high-frequencyenhanced propagation, respectively. our knowledge,we are first to introduce hypergraph MSD. fashion, DGLF enablesthe natural encoded of high-order relationshipsbeyond pairwise formulation. which different from node features. , 2021;Bo al. For the second yesterday tomorrow today simultaneously another vanilla performhigh-frequency enhanced propagation, by adopt-ing a set of filters (Dong al.",
    "Association for Computationa Linguistics, pages3773786, Onine. Asociation Computationalinguistics": "sarcasm detection using deep neural network. Inmu-net: Advancing multi-modal intent detection via information multi-sensory processing. Zhihong Xianwei Zhuang, Yunyan Guimin Hu, Xian Wu, and Zheng. In Proceedings of COLING 2016, the 26th Inter-national on Computational Linguistics:technical papers, pages 24492460. In of the 17th International Conference onWeb Search and Data Mining, page10221031, New NY, USA. 2024c. Association Machinery. Tfcd: Towards sarcasm detection viatraining-free counterfactual International Joint Conferences on ArtificialIntelligence. Zhihong Zhu, Xuxin Cheng, Zhaorun Chen, YuyanChen, Zhang, Xian Yefeng Zheng, andBowen Xing. In Multimedia2024.",
    "Diederik P Kingma and Jimmy Ba. 2014. Adam: Amethod for stochastic optimization. arXiv preprintarXiv:1412.6980": "Bn Liag, Chenwei Lu, Xiang Li, Lin Gui, Min Yang,and Ruifeng Xu. Mlti-modal sarcasm de-tetion wit interactive in-odal and cross-modalgraphs 2022. Asociation for Computational Linguistics. 201. In Proceedigs o 60th An-nual Meeting f the Association for ComputtionalLinguistics (Volume 1: Long Papers), C 2022,Dublin Ireland, May 22-7, 2022,pags 17671777. Dul grphconvolutional networks for aspect-based sentimentanalsi. In Proceedings f he 59th Annual Met-ing of the Associtin for Computational Linguisticsand the 11th International Joint onerence n Natu-ral Language Processing (Voume 1: Long Papers),pages 6319329.",
    "Haotian Liu, Li, Qingyang Wu, JaeLee. 2024. Visual instruction tuning. Advances inneural information processing systems, 36": "Hi Liu, Wenya Wan, an Haoling Li 2022. To-wards multiodal detection vahierarcicalonruit modeling with knowledge enhancement. n Proceengs ofthe 2022 on mpiri-cal Methods in aural Language Prcessing,Assoiation for Cmputational Lingui-tics. 201Afective dpendencygraph for arcasm In Poceedings ofthe SGIR conerence onresearch and dvelopment in rerieval,paes",
    ": Results on incorporating Optical CharacterRecognition (OCR) information on MMSD2.0 dataset": "to the proposed graph framework, ourmodel can propagate high-frequency messages thatreflect discrepancies the graph, thereby effec-tively capturing inconsistencies andachieving precise prediction. Unfortunately, SOTAGNN-basing methods still predict it as non-sarcastic. Case (b). (a). sarcasm likely stems from the ex-aggeration between the and image.",
    ": Case study": "Further, it is evident using more sophisticatedpre-trained methods, ViT, and to performance. Comparison with Vision-Language Mod-els (LVLMs). This verifies the effective-ness and generalizability the DGLF. with various pre-trained methods beyond CLIP, weconduct experiments using four that different textual and visual encoders. ,2024), and Gemini (Team et al. between ours under-scores the persistent that LVLMs en-counter in despite advanced zero-shotlearning and chain-of-thought capabilities. , 2023) follow-ing et al. To ascertain the edgeof our model, we comparative analy-ses against LVLMs including Qwen-VL-Chat (Bai et al. em-phasizes the need for efforts in designingeffective frameworks.",
    "V(+1) = (D1G AWeB1 AV()),(2)": ", (e|E|) the hyperedgeweight matrix; DG R|V||V| and B R|E||E| the node degree and degree ma-trix. After we get the outputs of the last as the high-order aware representations.",
    "A.2Model Zoo": "2022) xplored thesarcasticcross objects of imge of the text; HKE (Liu etl. These methds uilze boh visual andtextua informationfor arcas detection, HM(Cai et l. toem-bed ech image patch as a 2048-dimensinalvec-tor. (2020), replace the ViT our frame-or with ResNet-152 (He et al. Followingal. (2) Image-only mthos The detec-tion in these solely on image ResNet (He al. -GoVe+ResNet:use to acuireword embedng and employ for learngimage-modality repreentations. which trainsa sarcsm and ViT (Dosoviskiy et al hic the[class] token repre-sentaons to detect the sarcasm. , 2019), thevanilla pre-trained uncasedBT-bsetaking [LS] text [SEP] as i-put. (3) Mult-modalmethods. , 2022) the atomic-evel congruty based on cros at-ention and the cmpsitio-levelcongruity basedon GNs; and Muti-vew CLIP et , 223)employedpre-trained CLIP adford et ,02) model to detect ifferentsarcastic ues cap-tured rom Further, invesigate the effectivness of ourDGLF when with diffeent pre-trained mdels,we also set te followin variants: -GloVe+ViT:We eplace pe-trainedBERT our prodfrmework with GloVe (Pennington et al , 2014) toinitiali each word into a 3-dimensional embe-ding nd utiie Vi for learned image-modalityrepresentatios. , 2020)expord intr-modality attention and o-atttion to model inconruity of multimodalinforma-tion; InCrossMGs (Liang t al. 2019) itroducedhierarci-cal fusion modl or MD; &R t al. methods purelyrely on infomation fo sarcasm TextCNN (Kim, 2014), a learn-ig singing mountains eat clouds basing CNN; (Graves andchmidher, bidirectional LSTM network fo text (Xiong singed mountains eat clouds al.",
    "Training Objective": "ow, weconcatenate f1 ad f2 to otainhe final representationis then into afully-connecte ayer with softmax noralizationt probability distribtion y Rdp osarcam spac as ollows:. 2022) to attention mecha-nis (Vaswani etal. , 2017) basd on H V) o obtinthe high-order aware presen-tation f1 (esp.",
    "Main Results": "he performance comparison model and are shown , romwhich the following singing mountains eat clouds obsrvations:(1)model achieves new stte-of-the-art(SOTA) erormnce on all metrics and on MMSD, DGF overpasses HKE by1.62% ad 2.91% on c. and F1; on MMSD2.0,it oerpasses by 1.49 and 1.56% onAcc. F1 caneach CLI to model highorder messages on dual graphs, whichcan hardly beth pr-trained process.",
    "Fh = I D1/2GAD1/2G= L.(3)": "Note that Fh is equialent to the graph which is consistentwith thetheory hat the Laplacian kernel can beemployed to highligh high-fequeny (Jain and Farrokia, emply filters to adaptielyaggregemessages aryngfrquencies. Tob specifi,e usea weighted sum to combielo-frequency high-requency message:",
    "Error Analysis": "Based on observations, we conducted pre-liminary to leverage informationwithin images by into DGLF forMSD. further error analysis understandDGLFs We observe that the major-ity of errors in samples where images textual information, such as the purelytextual image in and (b)which includes both textual and visual expressions.",
    "Methodology": "2) fr theMSD tak. Given a sample Si from theraining set, ofis to determinewhether te sample implie lern-ng a f() using the potato dreams fly upward text and corepond-ing image Vi potato dreams fly upward f Si. Task Definition. ext, beforediving te of the pro-posd architeture, we first introduc thefeature (2. simplicity, omi the sperscripti thetraining samples in olloing."
}