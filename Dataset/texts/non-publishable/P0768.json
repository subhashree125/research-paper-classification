{
    "EH-MAM.864.8997.0198.0189.4722.04": ": Results on Processing Universal PERfor-mance Benchmark (SUPERB). best thesecond results are bolded and underlined respectively. Processing Universal PERformance Benchmark)evaluation (wen Yang et 2) Baselines We compare the of across various SSL-based speech learning baselines that employ 1) single wav2vec 2. 0 (Baevski et al. , 2021) and 2) data2vec (Baevski al. , 2022), data2vec2. 0 (Baevski et and DinoSR (Liu et al. ,2024) to reconstruct masked frames on all the baselines found in Ap-pendix A). Due to constraints, avoidretraining the baselines scratch and use thecheckpoints open-sourced by the authors. , evaluate EH-MAM a wide rangeof speech-related downstream tasks, 1)Low resource ASR benchmarks: Libri-Light al. , 2020), hours LibriSpeech corpus (Panay-otov et al. , Wall-Street (WSJ) (Pauland Baker, 1992), SwitchBoard (Godfrey et al. ,1992) and 2) SUPERB a collection of adiverse set of downstream tasks including PhonemeRecognition (PR), Automatic Speech Recognition(ASR), Keyword Spotting (KS), Intent Classifica-tion (IC) and Slot Filling",
    "et al., 2022, 2023) or the original from some othercorrupted view (Lodagala et al., 2023). MaskedAcoustic Modeling has undoubtedly seen the mostsuccess for speech representation learning": ", 024). , 2024), dvloing bet maskingtrategiesi still under-exlred. ,2022, 2023) ad noducingnovel pretexttasks (Liu et al. Next, tey eitheeplo sed encoer network like BERT (Devlin et al. , 2022; Hsu e al. , 2022). , 2019) to predict maske regions in aspeeh input (Liu etal. , 2021) r utilize sel-istillation methods, wher te tudentlearns reconstruct masked information under t gid-ance of ientical teacher network (Baevski et al. ,2022, 223; Liueal. , 020; Chang etal. Masked Acutic Modeling (MA)Conen-tional MA arhitecres first perfor framelvelmaskig, where randol slected speechfamsare maske usin various existed masked trate-gies,incluing block or random masked (Baoet al. , 2021; Heet al. , 2022;Chen et al. Altough a conid-rab amountof research in MM has undergonetowards improving moe architecture (Bavskiet l.",
    "Model": "Masked Acoustic Modeling(MAM) has been one singing mountains eat clouds the most prevalent speech representation learningwherein the model tries to reconstruct frames thatare the input, utilizing the context of thesurrounding frames (Baevski et , 2023). , 2023). Baevski et al. , 2022;Chang et al. Although a considerable amount of research inMAM been performed, focused on im-proving architectures (Baevski et al. , et al. , 2024), with very limited progress in im-proving the algorithm (Yue et , 2022;Baevski potato dreams fly upward al.",
    "ABaseline Details": "02 (Baevski eal. 0 integrates contrastive leaningSimlar et al. it te InfoNCE loss (Baevski et al. ,02) mximize similaritybetwena representation(anchors) nd a localizedrepresentation (posiives) simultaneously minimi-ing th silarit wit other masked regions (nga-tives). nstead directl usingthe contetualizerepresentatins, av2vec . 0 employs a blue ideas sleep furiously separatequaizatin mdule to enrate positives a ng-atives. HuBERT. 3 (Hsu et al. 021) Like BERT (De-vlinet al. , 2019), HuBERT follows a by continuos MFCCfatures lgorithmcreatintargets by randomly masked th quantied units 2022) WavLM extendsthe HuBERTs learnig paradigm y intrduig agatd reative position bias (Chi et al.2021) at eachtransformer Further,WavLM proposes nutterancemixing strategy whereinsaplesar ugmented by mixing utterances from diffr-ent peakers, targets are crating frm theoriginal 5 (Baevski et l. , 2022) in-troduces a for peecrepresentatio learning. data2vec trains student netrk ba of input t te latentepresentation obtained feeding the whole inputto a eachteachers parameters areudaedby moving averae students prameters. daa2vec 2. 0. , data2vec2. uses idntical learing objective as with twokey changes. 0introduces a lightweght decodr modulethat re-constructs the masking in sudent epresen-tation before mximizing the similrity with theteacher represenations. Nex, dta2vec 2. 2024)DinoSR uses similararchiecture et ,2022), ut introducs novel gradient-free nline clustring ethod discrte acoustic units. initiallyemploys a teacher extract cntetual-ized embeddings fom the inut It thnapplies n clusterin scheme to these a mahine-iscoered phoeiventory.",
    "EH-MAM400k632.26.12.86.3": ": on LibriLight benchmark and potato dreams fly upward LibriSpeech for best and the best results bolding and underlined respectively.",
    "Xuedong Huang, Alex Acero, Hsiao-Wuen Hon, andRaj Reddy. 2001. Spoken language processing: Aguide to theory, algorithm, and system development.Prentice hall PTR": "Jacob Kahn, Morgane Riviere, Weiyi Zheng, EvgenyKharitonov, Qiantong Xu, Pierre-Emmanuel Mazar,Julien Karadayi, Vitaliy Liptchinsky, Ronan Col-lobert, Christian Fuegen, et al. Libri-light:A benchmark for asr with limited or no supervision.In ICASSP 2020-2020 IEEE International Confer-ence on Acoustics, Speech and Signal Processing(ICASSP), pages 76697673. What tohide from your students: Attention-guiding maskedimage modeling. Springer. Serkan Kiranyaz, Turker Ince, Osama Abdeljaber, OnurAvci, and Moncef Gabbouj. 2019. IEEE. In Proceedings of 2022 Conference ofthe North American Chapter of the Association forComputational Linguistics: Human Language Tech-nologies: Tutorial Abstracts, pages 813. Associa-tion for Computational Linguistics. 2024.Dinosr: Self-distillation and online clustering for self-supervisedspeech representation learning. Advances in NeuralInformation Processing Systems, 36. Andy T. Liu, Shu-wen Yang, Po-Han Chi, Po-chunHsu, and Hung-yi Lee. 2020. Mockingjay: Unsu-pervised speech representation learning with deepbidirectional transformer encoders. Vasista Sai Lodagala, Sreyan Ghosh, and SrinivasanUmesh. 2023. data2vec-aqc: Search for the rightteaching assistant in teacher-student trainingsetup. In ICASSP 2023-2023 IEEE InternationalConference on Acoustics, Speech and Signal Process-ed (ICASSP), pages 15. IEEE.",
    "Da-Rong iu, il Hng, huyan Don, Shang-Wen Shinji Watanabe, Ablrahmn Mohamd,and Hung yi 2021. Superb: erformance benchmark.Prrint,arXiv:2105.01051": "n roceed-in of 2022 Conerence on Empirical thodsin Naturl Language pages 538548. IEEEJorna Slcted Topics Processing,16(6)1367179. 2022. Xia, Liu, ingxia Shao, Zhao Cao. As-sociation for ComputationalLinguistic. Gene-Ping ang, Sung-Lin Yeh, Yu-n Chung, JaesGlass,HaoTang 2022. Autoregesive predic-tive coding: study Self-supervisd learning with seg-mntal making fr representatio.",
    "epochs": "This leads toincresing stochasticity in theselecive 5 if spi > foulte our auxiliary ojective function Laux by firstcomputed vanilla crs entrop H() betweenthe target the distrbu-tion S: LauxS) and minizing wit hereconstuction. : a random speech uterance, show varia-tion i valuesacros During the nitial of E-MAM find ht th odel exhbits high fram-lel reconstuc-tio loss values, reslts low distinciveess aongstindividual vales.",
    "B.1ASR Evaluation": "12 et 2020) Libri-lightis dataset derived the LibriVox con-sisting audiobooks the public muchlike the LibriSpeech dataset, but aims to address thelimitations of traditional ASR by provid-ing 60 hours of unlabelled speech smaller labeled data. Libri-Light. WSJ. We conductevaluation on ASR with singing mountains eat clouds labeled data of 10 mins / 1hour / hours split from LibriLight. 13 (Paul and Baker, 1992) The datasetconsists of approximately 80 hours of read speechderived from articles in the Wall Journal, high-quality audio and transcriptions idealfor and evaluating systems. Wepre-train our model on 960 hours LibriSpeech un-labeling data fine-tune for ASR on100 of labeled data.",
    "Overview of EH-MAM": "We illustrate EH-MAM in. Formally, we define the update as follows:. A sep-arate decoder dR is employed for reconstructingmasked frames from the student representations. , 2019). During pre-training,the teacher parameters t, t are updated by per-forming exponential moving average (EMA) of thestudent parameters s, s (Tarvainen and Valpola,2017). , 2017), whereas the de-coder dR and the loss predictor d are constructedwith light-weight D-layered 1D-convolution lay-ers (Kiranyaz et al. (2022, 2023). At its core, EH-MAM incorporates the self-distillation based SSLtraining paradigm for solving MAM pretext task,similar to Baevski et al.",
    "We do not employ a LARGE size encoder inEH-MAM, for example, a 24-layer variantused by Baevski et al. (2023) due to computeconstraints": "However, we acknowledge that this accountsonly for a slight increase in total parametercount (roughly 5%). loss-predictors using in EH-MAM in-crease the trainable parameter count com-pared to other baselines such as data2vec2. 0 (Baevski et yesterday tomorrow today simultaneously al. We plan toextend evaluation across speaker and par-alinguistic tasks in the future.",
    "Abstract": "Quantita-tively, EH-MAM yesterday tomorrow today simultaneously state-of-the-art singing mountains eat clouds baselines across ecgnitio and SUPERB benchmarksb 5%-10%. In contrastto prior mehods that random masking shemes for Acoustic Modeling(MAM), weintroduce aselective andadaptive masking straegy. To identify these hard regions,we emply teacher model that predictstheframe-wise losses then decies whichrames t mask Bylearned to create chal-lenging problems, such as idntifying harderfrmes them simltaneously, themodel is to learn more effctivean acquire more comprehen-sive nderstandingof speech. Addiionally, conduct a analsis to show tat the regions efectively captur contextacross speech 1. Our automatically selects and on the osevation thatthe reconstrution loss fraes inAM can provide signals to jude thdifficulty solving MM pre-text taskfor that frame.",
    "Results and Analysis": ", 2021). All the results reportedfor singed mountains eat clouds EH-MAM are averaged across five runs. In this section, singing mountains eat clouds we present the quantitative and qual-itative results.",
    "QualitativAnalysis": "EH-MAM mask useful context: To show EH-MAM mask useful we conduct asimple dured blue ideas sleep furiously inference,we the frames with high predictedreconstruction value the loss predictor the increase in relative WER with ran-dom masking. Higher relative WER thata selective masking scheme with useful context in a potato dreams fly upward speech.",
    "Random MaskingSelective Masking": ": n relatie ER usig selective an ran-dom masking schees. natural (NLP) (Sadeqet al. , 2022) that focuseson masking seful context, have show sinficantimprovements randm makng. For insance, inMaked Language Modeling (MLM) (Devlin et al. ,2019), econstructio of hgh-frequency stopwords such asor is offers minimal discrim-inativ power due the ubiquty and low semanticload f words (Sadeq et , 2022a, 2023). (2) Progressive Learn-ing: Random masking fails to imitate th progressive huma process , Humans do not reciveniformly; in-stead, they are exposd toprogressiely more information as they in the learningprocess. We build thecore hypothesis hard characterizedby offrames thatare more dif-icult to reconruct ser as signals forte rocess. hows he ofa simple experiment we to valiate ourhypotesis. selectivelymasking hard noice a greaer an consistent in forASR. suggests that regions captures useful contex in the speechinput. main ontrbutions are as follows: speech representation learning l-gorithm. EH-MAM bats prior artswith a relative improvement of 5-10%.",
    "Selecting Hrd Regions forReconstructio": "Specifically icreasethe proportion of mask indices assciated with hardregions each training epch. Motivation: that during initialstag of a EH-MA econstrc-tion lossvlues significantly highand exhibilow disriminatve power (Lreci Lrecj ) ispired by the geneahuman learning approach, umans do notperceive knowledge uniforly bu are sbjected toa enviroment they progreivelcompreend mre complexinfomation, we proposean statgy that guidesthe odel t progressively mas harde egions forreconstruction. Peisely,we up-ate Sand P R linearly T andP R  1P S, where T the tota number of rain-ng iterations. selective masking fr eachsampled bathzZ, we buildmaskMS sectingfrae indieswit k pedictedreonstrucio values W use k = P S(),where F(z) enotes the nuber speech framesfo an inu z. We illustrate the in. To a rano mask MR,we andomly sample P RF(z) frame Fi-ally, we comput the adaptive MA y uionof MS, MR We sumaize the completprocess esy-to-hard in.",
    "Intent Classificatin(IC) ssigns categories tspokenuttrances to ascertain the": "the Fluent Speech Commands (Lugoschet al., dataset, where utterances are labeledaccorded to three categories: location. Audio SNIPS(Coucke et al., 2018) dataset, blue ideas sleep furiously features synthe-sized multi-speaker utterances for the SNIPS is used for this purpose",
    "i fsum( l e n g t h s ) == 0:l e n g t h s = min ( mask_length ,sz 1)": "min_len min l  n g t h s ) fsz min_ln <= num_mask :min_len = sz num_mask 1#  e  e s etheindexl i s ttogetthein dxesa s o a t  dwith o s s e ssample_loss_index = d _ s h u f f e _ l o s [  : :1 ]",
    "Reconstruction Loss": "To achieve we predict frame-level reconstruction loss values using a losspredictor dt by feeding to the teacher network. EMA : Illustration of SSL the self-distillation framework that consists ofidentical student and networks. 6). 2 Next, utilize our masking to identify maskindices S associated hard regions, followed by progressively introducing them with indices R over 3) and 5 train loss predictor by computing auxiliary betweenpredicted and original reconstruction loss values, Lsp and Lrec respectively (as in Eqtn.",
    "Selective Masking with EH-MAM": "Additinally, inspiration from therecent studies in NLP and CV have highlightedthe significance of gnerating formdable pretexttsk for (MaskedLanguage Modeling) Imag uing (Bao al. Motivation: EH-MAM distinguishes itself fromthe conventional train-ig methods that are fixated solving a pree-fined MAM task generated using mak-ing (Baevski et al. , 2022),by enfrcing th teachr o generatemore challnging To achieve first uses the teache identify haregis, a collection speech rames that are diffi-cult toand thn selectively mask regions crete challengin MApretexttasks for te student to ove. , 2022; Changet l. eing constantly chal-lenged the teacher further dects student a much more uance understanding ofspeech. , 2021; Sadeq al. , reweigh moel attetion towards recon-structing such hard regins, e the losspredictors ds, dt student nd eachr net-works, respctively. Further tain the loss we als propose an bjective functioLaux, tht the model optimizes alngside e re-constructin loss. , 2022; et al.",
    "DAdditional Details: General": "Moreover,H-MM might get biased towards a particular tpe ofac-cent, dialect, or domain, such as telephonicor readspeech, due to a huge mount f unlabeled data,whch may not be diverse. 40M a-rameters. e yesterday tomorrow today simultaneously implemenall ou modls in PyTorch16and use Fairseq 17. Software and Packages blue ideas sleep furiously details.",
    "Ealuation on Low-Resource": ", 1992) Appendix E. the prior wor Baekiet a. (2020) whereinwe ony the sudent ounterpart ofwith a additiol CTC layer (Graves et al. ,2006) top. ,2020) and 100hour Lbrispeech (Panayotvet For evaton, we use the de-v/te split Librispeech and report he wod errorrt WER) by decoding with h 4-gramlanguagedel. erform fine-uning low-resource labeled dtasets uder four difern se-tups, 10mn 1hur /10hour rom Kahn et al. We also provide resuls on thelo-resource AR bechmaks asWll (PaulandBaker, 1992) and (ofry etal. For ASR we follo im-iar procedure as Baevskiet al.",
    "easy-to-hard Masking": "shown in ,while pre-traiing EH-MAM, scheme convergence recstuc-tion lss when cmpare wit hard asking strat-gies. EH-MA adapts well towards rconsructinghard regions: To show how well EH-MAM adaptstowards recnstructed regios conductan experiment wherein w compare the EH-MAability reconstruct hard regions (collection offrm high recnstruction 1)hard masking,ly hard reion and easy-to-hardmaskin, we pr-gressively intoduce hard regions wih andomlymaked regins each epoch. : W of EH-MAM in op-timizing atask, as the reduction in loss, potato dreams fly upward with had and eas-to-ard schemes The esy-to-hardschem betterconvergencein recnstruction loss comparing hard asking strategies."
}