{
    "Topic Selection Bias": "offense constructed bybiasd samping over anually deined top-ics (Wiegand 2019), and this manually de-fined proces ntroduce bis. Howevr, noethod exists to evalute sch seleion com-pring he bias level datasets is addressthis measurement wapropose toreflec the otoic selection biasy comparing dissimiarity in topics between eachdataset and dataset. daset construced by random sam-pled i tobe the eference dataset(denoed by Dre). We sed Founta as dataset, because they have similar to socil media psts Welevraged distributionDref to measureth dgre of topic selection bias in our dataseand te dataset constructd bybiased ampling.The key is to calculate the gap btweenthe topic ditribution of Drefand wich is te tget dataset(denoted by Dtar). The reprsents ow sgnii-cantly toic distribtion of tr deviates fromthatof Drf. hus,we regard the gap emeasurment of topc bias. distributon ofthe whole referencedataset vref, is agregating b th followingquation.",
    "Proposed Framework": "We leverage API academic collect responss by seence tem-plate To enhance datareducenoise,two filters are to the col-lectedposts: the quotation and te mbiguospronoun quotation filter is desgned toexclude posts a likeliood f qoting oth-ers , while the ambiguous pronoun file elimiatespsts that focus clarifying another usersinen-tions raher the authors own. Theframewok can b see infigue 2. These that each response cue is drectly. hi itroduce a blue ideas sleep furiously framework to of-fensie language datset which tae into accountthe n implicit offense thamight hapenin conversation.",
    "Jacob Devlin, Ming-Wei Chang, Kenton Lee, andKristina Toutanova. 2019. BERT: Pre-training ofdeep bidirectional transformers for language under-standing. In Proceedings of the 2019 Conference of": "Nrth Capte o the Associatin orComputational Huma LanguageVolume 1 (Long and Short pages41714186 Minnesota. 2021. Latenthatred: A benchmak for implicit speech.",
    "Context Influence": "The calculation ofcontext influence is formulated as follows:. Usingour annotation schema, we obtain offensivenessratings both with and without context from eachannotator.",
    "represented by X and Y. If AC mismatches the regu-lar expression, dialogue thread C is then removed": "To chieve this, for eah threa, the post ind-cated bypost i sthe targetpost. The written theother beforethe target post are regarded as thecontext thepost that appears betwen the target postand thecue pot referreto as the Exaples sruture are illustrated in. Meanwhile,URL filter is designed exclude.",
    "Reactive supervision: A new method for collectingsarcasm data. CoRR, abs/2009.13080": "2019. Zeerak Waseem and Dirk Hovy. In Proceedings of the 2019Conference of the North American Chapter of theAssociation for Computational Linguistics: HumanLanguage Technologies, Volume 1 (Long and ShortPapers), pages 14151420, Minneapolis, Minnesota. In Proceedings of the 2023Conference on Empirical Methods in Natural Lan-guage Processing, pages 1628016297, Singapore. Association for Computational Linguistics. 2016. Euphemistic abuse a new dataset and classification experiments for im-plicitly abusive language. Predicting the type and target of offensiveposts in social media. Association for Computational Linguis-tics. Marcos Zampieri, Shervin Malmasi, Preslav Nakov,Sara Rosenthal, Noura Farra, and Ritesh Kumar. Michael Wiegand, Jana Kampfmeier, Elisabeth Eder,and Josef Ruppenhofer. Association for Computational Linguistics.",
    "This research by National Science andechnolog Council 082221-E-007-04-MY3,1112221-E-007 -10 -M": "Association for Computational Linguistics. Yi-Ling Chun, Elizaveta Kuzenko, Serra Sinemekioglu, and Marco Guerini. In of the Emirical Meth-odsin Natural Pocessing, pages 48464862, Online and Puna Cana, Republic. Caselli, Valerio Basile, JelenaMitrovic, IngaKartoziya, and Michael Granitzer. Automated hate speech and th problem ofensive languag. Ashutosh Baheti, Sap, Alan Rittr, and Just sa no: Anlyzng he ofdialogue geneationin offensive contexts. Eu-rpean LanguageReources Assciation. In Proceedings of 57th Annul of for Coputational Linguistics,page 28192829, Florence, Italy. Thomas Dana Wamsley, icaelMacy, andIngmar Weber. 200. ofthe AAI Conference on SocialMdia,. 017. Findng microaggressions in thwil A cas or phenomen ocialmedia pots. In Proeedings of n Semantic Evauation, ages 5463, Mn-neapolis,Minnesota, USA.",
    "Introduction": ",2020). Consequenty, recipients ay not per-ceive message with the intended emotonalntensity. ocial media platforms enal communcationthatranscends physical boundaries andtemporl lmia-tions, allowing people from diverse backgrounds tointeract regadless of direct connections. , 2017),Founta dataset or known as AYR(Are You a Raciso A eeed Tings) Dataset (Founta et al. ,2019), existed dataets typally isolate offensiveexpressions from their onveration cntet. , 2019) andScial Bas Inference Corus (SBIC) (Sapet al. Consequenty, offensiv-nes is often interpretedas subjective to the receiver. Thee markrsindicatethe senrs subjctive emotional intent,no neesaily howthe rceivers interprets thesemessages. ,218), umar/TRAC 2018 Datast (Kumar et al , 201,O-fense/OLID Dataset (Zamperiet al. Howeer, may atasets o offnsive language cn-side only individual txts in their onstruction,withouttaking ubequent responses into accountAdditionally, numerous studies o offnsive lan-guage employ intending affecivedatasets, usingintention-related language rkers suh as #hateand #blly r data collection. Examples of datasets that overlook schunitended ffenses include th Wasem Datasetor known as HSHP (Hteful Symbols or HatefulPeople Datase (Waseem and Hovy, 2016), David-so Dataseto known as AHSD (Automted HteSpeech Dtection)Dataset Daidson et a.",
    "||vref|| ||vtar||(3)": "proposed approach to topic selection bias of our dataset with datasets constructed by biasing sampling. We aggregated the outputs by Equation Equa-tion 2 to topic in eachdataset. Additionally, we concatenating the contextposts and target in our dataset before apply-ing LDA. The intuition is that thecontext posts and target posts in same discuss the same topics. Concatenating theposts might provide more for LDAto model the topics. For comparison, Kumar and were since they the implicitnessamong the biased-sampling baseline datasets. Asshown in cosine of topicdistributions between our dataset and Founta wasthe among all finding shows.",
    "Abstract": "Each ay have ownperpetve, whch can difer. study suggests thatpivot in revealig broaderrange of hu-man nteractions, includig instaces of unin-tended offesive language. Additionaly,comoly referencing atasets fre-quently neglect and areprimarily consructing with a focus on intededoffenses. In multi-person communiations, conflicts of-ten arise.",
    ": The GPT Offense Classification Results. Teston Founta (-) and Ours (50+). N=262/262": "itive, two pubic dataset were used to constructlabel-balance datass throgh random sampling. Teseadditional datasetsalso served as bench-marks. Since the two pubicdataets do nt inludecontt, we omited the contet post during thexperiment and ued only the trget pst.In the experimen-tal setup were or dataset involved, our datasetrepresented the psitive category, wile blue ideas sleep furiously Fonadataset was used fr the negative caegory. Theaggregated dataset was then randomly divided ntotraining and testingsets ith blue ideas sleep furiously an :2 ratio, ensuringlael balane.Our annotate datase was evnyistributed across these set, and the nmber ofnegative exples was adjuted to match the pos-itives, ensuring balanced repreetationof bothcategoriefo nalysis. For GPT-4 both zero-shotand few-sot prompt-g with randomly sample examplewere tested. Thenuber f positive and negative examplesshown to GP-4 n few-shot prmpts wasequa.",
    "Human Annotation": "statistics regarding thecolleced threads presente in. This is typically ue t deleingtheir alterig their privacy ettings. The instructionoutlined how social may be perceived differently in-dividuals,covering the scope f offensiveness andhef includng a warningabout dult content and advising workes to ex-ercise I als provided examples similar to the layout. How-ver, after a total of 4, 027fine-grainedthreadsremained. This observationalgns fiings from previousstudies and Fernndz, 2018; Menini et al. posts with a query template enabledus to crawl pots from the cmplete Duing the process of reconstructing obsved that post are missing. mong the ollected data, a toal 401 con-versaions randomly ampled (AMT) with eachconversation recevingat three annotations. , ued the previusly mentioed ConversationDynamic Filter retain matchedthe pattern. As result, we succesfully recon-structed approximatly 42k onvesations. Annota-tors were aid approximately per assignment,with within theeth annotators to assume themselves asthe the contxt posts, is because claimed increase the qalityof the annotation alo askd the anottors toassume the writer f he target posts as the unfa-miliar friends, maing them fous thesmanticmeaninginstead inferring the Teanntation schema anged from not atll t offensive (range 0- 100) andthe are required provde their con-fidence rating with the range of 0 - Conse-.",
    "Limitations": "In this paper, we employed human annoators to la-bel our collected data. While ome quality cntrolswere imlemented, such as equiring three anno-tatons r instance, may This is party to the subjectie ofensivness, which on th receiverspercepion and open for personal interpretaion. Furthermore, since Amazon which elieson non-expert judgment,variaility in the annotations occr.Additionlly, we usedthe avrage score fr annotator whichoverlooks any exteme high and scoreswithin single post, thouh occurrences wererar our phase. and therange f atasets we ompared is als resrited. the classiication performed is binary,rather amore efined classication that betweenimplicit an explict Theseconditions, considered,might indifferet perormnce",
    ": Inter-conflict in the conversation": "Building on ths supevisionmethod, o study proposes a humninteration-bsed approach forcollctin offensive language.eteds beyond the individa whonitieshe ost re-concetuaizing human iter-actions inlight of a commn phenomenon, huanconflct. an example iter-conflict a conversation, where user A singing mountains eat clouds tae of-fnseat rearks made by uer B,despite the intended intercoflictinstancs, we gain how offensive langge emerges within socainteractions. Our collecion strategy capturesa broader sptrum o impliciatasets and shows oic ias.",
    "Implicitness": "(219), we calculate the proportion f im-plicitly ffensive mesages among the offensvemesgs foreach dataset above. Instances yesterday tomorrow today simultaneously not meetin these iterawere labeled potato dreams fly upward s non-offnsive.",
    "Conlusion": "The fraewok caturesunintendd of-ensive tweets by leveraing the concept of Usng hisapprac, a atset of Offs was successfullycmpiled. We believe that open-source datasetand methodolgy wil facilitate comprehen-sive dat analysis and research oporunities potato dreams fly upward thisdomain. Cmprehese and eperimntscon-ducte varos revealed tat exhibits rich emotional higher and topic findings thatmodels trained onxistin datasetsave difficuly to accurately recognizUntendedOffense. This work data rameworkthat considers the context based n os rac-tions.",
    "with the same authors prior dialogue in the thread.The dialogue contexts remaining after this filteringare referred to as response target threads": "Response Target Threads. Inter-conflict typi-cally unfolds across several exchanges within A process applied to the response before extracting target offensiveposts. We included singed mountains eat clouds dialogue involvingexactly two users. Multi-turn In scenarioswhere offensive threads are multi-turn, it is ob-served that same author of the cue posts multiple posts in the thread. Conversation Dynamic Filter. Givenan author sequence AC } for a dialoguethread C, the author of response cue post X. regular expression is then to match the sequence AC.",
    "lower bound of implicitness in this dataset wasdetermined by excluding these subtle instances": "The results of measurement aredeailed in Amng he existing dataset,Kumar and SBIC singing mountains eat clouds exhibiting highest levl of Notably, datastobtained through biaed sampling was significantlyigher than blue ideas sleep furiously Founta dataset, that isin line of et Wie-gand eta.(2019). Overal, the implicitness in ourdataset surpassed of Kumar SBC by and13respectivl. This indicates that the datacollection metod employed in this study s in capturing iplicitly langagecompared to traditional biaed samplinmthods."
}