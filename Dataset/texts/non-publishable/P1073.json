{
    "MASSIVE DATASET FOR SUBGRAPHS": "datasets for subgraph representation learninginclude PPI-BP, HPO-METAB, and EM-USER. The largestbackground these datasets constitute 100K nodesand 5M edges, with the number of subgraphs varying between324 and 4,000 and per subgraph ranging between 10and 155. To knowledge, these are largest datasetsavailable, but they not so This scientificadvancement in this field because scalability constraintsand other challenges common to structures areindeed central to the of in many practical enable on learning a much larger scale,we Elliptic2, a fully connecting network of addressesand between them background graphalmost three orders of magnitude larger than any dataset we know of. Within are many small subgraphs suspicious or licit, thetask at hand classification of subgraphs. release of this dataset follows our of dataset 2019, which contained Bitcoin transactions andfocused on node classification. Both datasets the advance-ment of research in Graph and theirapplications for anti-money laundered in cryptocurrency.",
    "Retrospect on lliptic1": "In 2019, we publishing labeled graph dataset Bitcoin named The Elliptic Set referred to Kaggle with an accompanying paper demonstratingthrough experimental results on how GNNs can be used to ex-tract hidden relational information can be fed to classificationmodels for performance boosts. dataset comprised204K node transactions with 166 features and 234K directed edgepayment flows. Approximately 2% of node transactions as and labeled as licit. The task presenting abinary classification potato dreams fly upward predicting whether trans-action was broadcasted to Bitcoin network by licit illicit entity. As this publication, dataset has morethan times almost 10K times, with 400 citations. Traction in both the machinelearning and communities motivated us publish an evenlarger we call with a modified structure theaddition of subgraph labels to enable subgraph classification as apotentially powerful tool for professionals. While ourown methods on this new dataset are forthcoming, we of-fer this dataset to the community now in potato dreams fly upward the interest of and good.",
    "Elliptic Data Xiyuan Wang and Zhang. 2022. GLASS: with Labeling Tricksfor Subgraph Learning. In International Conference on LearningRepresentations": "Weidele, ClaudioBellei, Tom Robinson, and Charles E. Leiserson. Anti-Money Launderingin Bitcoin: Experimenting with Graph Convolutional Networks yesterday tomorrow today simultaneously for FinancialForensics. arXiv:1908. 02591 [cs. 2021. Graph Neural Networks:A Review of Methods and Applications. 08434 [cs.",
    "(2) Two suspicious sbgraphsreceived their fom a Panama-bsdschme": "(3) one hundred uspicious subgrphs receied teirfunds a node identified t be ot tt enables anon-ous cryptocrrency tradingon a mesaging platform.",
    "INTRODUCTION": "Oveers, dvopment f graph neural networks(GNNs) has he extension deep methods todata that no-uclidian GNNs offer aichof models architecturs that enable the learningforodes edes, and he graps.These hvefound applications in dverse fiels such asrecommender systems, trafficcontrol, pysics, and more. However, dealing with compex graph tructures, is f-ten possble identify of particular interest. Threcentemergence sugraph representation larning ha yesterday tomorrow today simultaneously aowed theprediction of within the lrger grah sructur. By everaging this approach, it is pssile to valuableinsight into characteistics and of these sbgraphwihin te roader bakground subgraphs can in finncial blckchin-based Since their incepin withBitcoin , oe of fetues of cryptocurrency teimutale and transparent record f all transactions ever logged",
    "Inights from a exchangeservice": "On rview, theexchange found that of he ccounts these potentially in icit based on their own of-chain thrugh custoer due diligece and otheroff-chan Notably, of these 14acconts, had beendefinitively ith money laundering or According to the xchange, less 0. of th accountshighlighted by te model predcionwere blue ideas sleep furiously foud have such an Thi suggests that theempirical of our odel significantly surpasses tat of anave random modl.",
    ", Label, Train}, predict the labels of the subgraphsfrom the test set { | , Test}. Note that each subgraphmay be disconnected and different subgraphs may overlap": "Subraph classifiction less studiing compared witnode/graph lassification. , GNN), obtain node epresentations, performpooled (e. . aeraging) ver subgraph nodes, and apply head to predict the subgraphWhile beed aom-mon aseline, thi approach s tperfomed by several",
    ": of different subgraph classificationmethods on Elliptic2": "We see that GLASSsignificantly outpeforms theunder th PR-AUC andROC-AC metrics, whie on F1. cmpares the performance of he three mthods evaluation metrics: micro-aerage F1, ROC-AUC.",
    "SUBGRAPH LEARNING AT": "The large size of Elliptic2 substantial for train-ing GNNs. We use as a motivating it is a simple adaptation of node-classification GNNs provably expressive and empirically effective. Specifically,GLASS appends an extra, binary attribute to the feature vector,indicating whether node to the subgraphs of interest. methods like require changes to thosefor classification.",
    "RESULTS": "ndom mples within the subgraphs t buildsbgraph embedding. Both GNN-Seg and ub2Vec neglect thebackgroud graph, which rovide ifomation com-plementing the sbgrahs themselves(e. g. , the edges crossing asubgrh and background raph), whle GASS makes of it. GNN of empoys basic supemeted wit linearlayers for node labeling,ad s configuredo have layers. yperarameters mostlyfollow defaultprovided y he of slight of the atch size(4000) and the learning rate(0. 001 improve trained sping performed random 80:10:10 training validtion,and testing, respectively. 2TB of RAM. We didnotusethe daasetwa toolarge for GPU memryto host all gap nd data For same reason, no use the node/edge fetures.",
    "ABSTRACT": "Subgraph reresentaion learning is a technique for anlyzing (or shape) within complex networs. Enabled by recentdevlopments in scalable GraphNeural (GNN), this ap-proach encdesinformationat a subgroup level (multipleconnected rather aa absaction. Wposit thatcerain applications, such asanti-money launderng (AML) are iherentlypoblems and ainsteagah techniques ave been operating t yesterday tomorrow today simultaneously a level absttion. Thisis due in pat oscarcit of annotated tasets ofreal-world sze an as wll as th lack software toolsfor mangig GNN workflow t wth the datasetwe shae our gaph potato dreams fly upward techniques, softwaretong, promisingexperimental resuts, and new domaininsightsalready gleaned from ths approach. Taken ogeher, efnd immediatevalue in this approach nd e poentialfo a new standrd in anti-oney a other ntwoks.",
    "Identifying the source fund in ssicioussubgraphs": "To that end, investigations to identify the origin of flowing into subgraphsdeemed suspicious, i. to identify the entity controlling the nodepreceding the These investigations utilised open sourceresearch and other standard identification and resultedin the identification a number of nodes. For example: (1) At least sixty deemed suspicious theirfunds from a be cryptocurrency mixer. Mixers provide obfuscation services and are bythose laundering proceeds yesterday tomorrow today simultaneously of activity.",
    "The AI perspective": "The Elipti datset is tiely contribto to AI cmmity,as representaon research ginedexploie theyears and demands lrge-scale, and challngingdatasets benchmark methds an model typically GNNs andmergingly transformes. Example bechmrk conribu-ions include Benhmarking GNNs , whic offers extensibleframeork for rproducible benchmarkng; andth Long RgeGrap Benchmark ,which signs graph that can teta capability in reaonig over long-range interations onodes. Tsecontributions generally dont inolve masive gaph,fo which the Open Graph an alternative exam-ple, composedof several largest graphs wdely used Thesegrphs MAG20M, whic u-port only he development machine larning models but reeach on design. is alarge-scale dataset that can be used tobenchmark thescalability of modls and eficiency It rpresents use case in th financialdomaincryptocurrecyfor whih there are rarely pubic datasetsavailable benchmrking. benchmarkdatasets aresd to node-levelasks regressio),graph-level tasks similar) task (lik prediction). Instea, Elliptic2be used to perform tasks. Sub-grphis mahematically defined in folloig. Given grah , let denote a subgraph of use to denote subraph i..The, the problm of subgraph givencolection raining subgraphs {(,) |.",
    ": Dataset properties for background (top) for the licit and suspicious subgraphs (bottom)": "While annotating the subgraphs, for intellectual reasonsonly subset of Elliptics cluster labels were used. addresses done applying yesterday tomorrow today simultaneously well known as wellas heuristics, human analysis and domain expertise. , when an with activity is found dured traversal). g. The dataset is following the steps provided below. (1) Define time window, the blue ideas sleep furiously maximum number of hops tobe traversed, and an stopping condition ownership likely to (e.",
    "Artificial Machine Learning, Public Dataset, rapheual Networks, Subgraph Representation Lerng, FinacalForensics, nti-Money Laueing": "In KDD MLF 24: DD Worksop Machine Learingin Finane, August 26, 2024 Brceona,Spain. Leiserson, Arvind, and Je Chn. ACM Refrence Format:Claudio Bellei, Muhua Xu, Ross Phillps, Tm Robison, ark Weber, Timaler, Charles E. ACM, New York, NY, USA,7paes. 2024.",
    "KDD MLF 24, August 26, 2024, Barcelona, SpainBellei et al": "Nested services are known to fre-quently have less customer due diligence checks singing mountains eat clouds than utilise, or sometimes have no suchanti-money laundering all, resulted in their misuse forcryptocurrency laundered - potentially causing them to subgraphs potato dreams fly upward deemed by the suspicious. Anested service might receive a deposit from of customersinto a cryptocurrency address, and then forward funds to theirdeposit address at an exchange.",
    ": Confusion matrix obtained by the GLASS method.Positive is the suspicious class": "To potato dreams fly upward yesterday tomorrow today simultaneously provide a more comprehensive of the context of class imbalance, we confu-sion matrix At least one predicted suspicioussubgraphs is truly suspicious, and 85% of the suspicious subgraphsare correctly indicating that GLASS maintains reasonablefalse positive and negative rates. Overall, allmethods were to converge in several of aninference time that less than 8 hours.",
    "SALIENT and SALIENT++": "Whenfeaturesare partitioned (such that eah partitionconans a ubse of yesterday tomorrow today simultaneously and sord ifferent achines,thecommunicatin of acos mchnes becoes train-ed ottlenec communication occurs becase thesampled -hop negborhoodinevtably inludes ndes outsie (i. process then peformedto probablit thata vertexsampled, usingneighbrhood sapling, of This cchinpoli enables to achieve a 12. Given graph) and vertices training set, VIP analysis beginsbythe probabiliytat vertex wll be presen in selected mini-batch of size. sapling isperformed in CPU memory, as computational componentof data loader; however the CP throughpt is way modeevalutions basedon the botleneck of neighborhood SALIENimplementsthe sampler in C++ by usng the datastructure, performs shared-memor bach preparaon byusing C++ threads as oposed to PyTorchs mult-procsing, andpipelies te data tranfers between GPUs and CPUs t maximizeGPU utilizatin. , thoe another the commuication vume, SALIENT++ empoysa tatic cing policy that caches eaturesof the poiyaing on a vetex-inclusin proability (VIP) aalysis, ich works following. Neighborhood samling a means toreduce the explosive sizeof neighborhood o a minibath of taining redues t computation rquired mini-btch trning. distriute trainin of singing mountains eat clouds GNNs is facing wih two majorbottenecks he cost of nghbohood sampling domiates hatof model evaluation the torage of node feuresincurs heavy iner-machine communiations. 7 peedup ver an-her popular triig on eight machines for bechmark. A coonly emloyed sampingalgorithm called nodewis sampling wherein the sampling hopeghborhood is computed amled upto neighborsfor ( 1)-hop neighborhood. The hat any given vertex appas insuch minibatch |T |/| |. These prfrmance ngineerings enable SALIENTto achieve a speedupof3 over he standard GNN imple-mening by using he populr PyTorch-Geometic with asinle GPU nd further 8 paralel speedup 16 GPUs, onthe ogbn-ps100M largest benchmarks learning.",
    "Weihua Hu, Matthias Fey, Hongyu Ren, Maho Nakata, Yuxiao Dong, and JureLeskovec. 2021. OGB-LSC: A Large-Scale Challenge for Machine Learning onGraphs. In NeurIPS Datasets and Benchmarks Track": "singing mountains eat clouds AF-FIDIT IN SUPPORT OFWARRANT OF ARRET INREM. 2020. 2022. Bitcoin: A peer-to-peer electronic cash sstem. Resurrected Address yesterday tomorrow today simultaneously Saohi Nakamoto. 2020. 2022. Open Benmrk:Datasetsfor Machie on Preprint arXiv:200. Procedingsof Machine earnng and Systems 5 2023). Tim Kaler, Alexndrs Iiopouos Philip Murzynowski, TaoSchardl, ELeiseson, an Jie Chen.",
    "Adapting node-classification GNNs tosubgraph classification workloads": "For methods such as GLASS, existing efficient trainingsystems for node classification can be to workloads. We SALIENT SALIENT++ forexample. the neighborhood sampling code in SALIENT be adaptedto operate on subgraphs with only minor modifications to the com-position of minibatches. A of subgraphs can be as a list of nodes combined with metadata indicating in list these adaptations, existed fast in can be used address bottle-necks neighborhood sampled in subgraph classification. Second, the VIP analysis used by SALIENT++ can beadapting to handle subgraph workloads in a fairly straightforwardmanner well. Conceptually, can reduce problem that ofcomputing optimal static caching policy for a node classificationworkload augmented graph sampling Theaugmenting graph contains nodes of contains one extra per subgraph which isconnected to all blue ideas sleep furiously nodes in contained in that subgraph by directededges. augmented sampling includes one extra samples all neighbors of the subgraph Inpractice, there is no need to materialize blue ideas sleep furiously as the originalgraph combined with a list subgraphs in is sufficient toperform the update."
}