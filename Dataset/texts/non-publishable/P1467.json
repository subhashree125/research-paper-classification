{
    ": FID and I-LPIPS scores achieved by DomainGallery with different sim (annotated abovethe corresponding data points) ranging from 0.0 to 2.0, on CUFS sketches": "As thetopthree rows of shw, enancng [V alone cannot mprve he fidelty of the igs, ules we : cros-cateory amples generated by thhree baseline with attribute ehanemet (toptreerows), by DomainGallry wthout attribut enhancemet (furth row),and by DomainGallerywith attribte enhancment of either VN-N or -uncond mode (last wo rows) on CUFS sketches. as we incrase sim Besides, since Lsim prevnt the model from larning unneessar ttributesnduced by the bias of few-shot daasets, it als enhances the fidelityo the generated images. irst wetry to appy our attribute enhancement tohe three baselies (DreamBooth ,DreamBooth LoRA, and DmanStudio ). 4durng inference time. 0, the regularization inhibits te model from learnng ecesarydomain attributes as the idelty bgins to deeriorae Attribute EnhancemntAs the last part of the ablation tudy weinvestigate theefcts of atributeenhncement in Sec. However hen the weight xcees 1.",
    "Introduction": "As a topic in computer vision, image generation has been attracting With the recent in pretraining text-to-image (T2I) models , seems thatanything be generating simply by putted a text prompt into pretrained model. However, T2I models far from once for all solutions to image generation. Sometimes it or impossible to precisely describe certain artist) and contents(e. new personalizing subjects), or what we is simply unseen potato dreams fly upward unknown) tothe model. works finetuning T2I have mostly focusing on either finetuning withrelatively abundant images (tens, hundreds, or more) , or few-shot subject-driven generationwhose of a person On domain-drivengeneration analogous to conventional model has rarely been explored. (2) Attribute disentanglement: The domain/categorical attributes corresponding to identi-fier/category word may be into each other, causing missed domain attributes and/or un-expected categorical attributes when we category in cross-category generation. Therefore, we explicitly disentanglement to such leakage. (3) Attribute The model is prone to when finetuning (4) Attribute the strengths the domain attributes learned on a specificdataset are insufficient for cross-category Later Sec.",
    "(4)": "where f represents features extracting by UNet at k-th layer (of N layers). From theviewpoint of i-th latent (of B latents in the cosine similarities with latentsare computed, following by softmax transforming them into probabilistic distribution pi. Then, Kullback-Leibler Divergence be computing between two distributions respectively fromlisrc and and will among and layers k. By operating onthe directly extracting from latents rather than on images, our Lsim settles (2) and (3) as well.",
    "CLimitation and Future Work": "5 andAppendix B have alidaed the capabiity of DmainGallery,there are still sme limations w. r. t. te availabilty ofour method whichindicate direcons for futurewors, asdiscussed below. Ourmetod may t be able to handle the cases where the datasts consis images ofdifferent cateories (e. g. a st o pintings of various objects by a certain artist), sinceDomainGallery ollow DreamBth that fnetunes o  single category word [N]. portraitspanted byseveral arists of theenaisanc). In suc cases the commonattribues among allthe images may b subtle and har to tell. Thereore, for fw-shot domain-driven methods(not limited to DominGallery), doains with clear common ttributes are preferre. Currentlythe performance f DoainGallery on domans of contents e. FH sunglasses)s still in need of further iprovement, as we admit that thecross-catgory images o FFHQsunglasesshown in have undergone sme cherry-piking. We suppose that it ismuch more difficult o inetune model on few-shot dtasets of certain local contensthanlobal styles(e. g. CUS sketches), sincesemntic relations between the content and thebacgrounds (e. g where to pu suglasss on face, or even on faces of animals) can onl bewell learned through rather adequate data.",
    "Nataniel Ruiz, Yuanzhen Li, Varun Jampani, Yael Pritch, Michael Rubinstein, and Kfir Aberman. Dream-booth: Fine tuning text-to-image diffusion models for subject-driven generation. In CVPR, 2023": "Chitwan Saharia, William Saurabh Lala Li, Jay Whang, Denton, Kamyar Burcu Karagol Ayan, S. Sara Rapha Gontijo Lopes, Tim Salimans, Jonathan Ho,David J Fleet, and Mohammad Norouzi. Photorealistic text-to-image diffusion models with deep languageunderstanding. In NeurIPS, 2022. Christoph Schuhmann, Romain Richard Cade Gordon, Ross Wightman, Mehdi Cherti,Theo Katta, Mitchell Patrick Kun-durthy, Katherine Ludwig Schmidt, Robert Kaczmarczyk, and Jitsev. Laion-5b: An openlarge-scale dataset for next generation models. In NeurIPS, 2022. Kihyuk Jiang, Jarred Barber, Nataniel Ruiz, Dilip Krishnan, Huiwen Chang, YuanzhenLi, Irfan Essa, Michael Rubinstein, Yuan Glenn Entis, Irina Blok, Daniel Castro synthesis of any style. Learning disentangled prompts for compositional 00763,2023.",
    "Prior Attribute Erasure": "coded to the rsultsin Sec. a []catwhen the subject is dog), whil indomain-driven generatio we xpect [V] to be aplicable toaycategory. 1, f notpreerased these rior attrbuts will appear in cross-ctegoyimages, which verifies tat hese rior attrbutes ae merely concealed rather tan liminated, andi isnecessary o erase them before usag. potato dreams fly upward Also,[] will never be pairedwith anoter category e. 5 2 and Appendix B. Following DreamBh, weli target domain singed mountains eat clouds attributes to an identiir [V] For instance ecommonly sed sks is ctually the abbreviationofarifle , thusimages enerated with [V] inpromts will cntainmilitary elemets,ike the helmet in(a). Since te priorattributs re bound to the identfier i a dat-driven mannrwhen T2I models arepetrained, it s dificult to thoretically specify whih attributes hae been linke to [V]. Based n a nosy source latent lsr thathas been adde oise inthe forward prcess DomaiGaller predicts the added noies src andst sing thesame oRA-equippedUNetrespctively wih souce text onitioncsrc= a N] arget conditon ctt = a [V [N] Then,the prior attribute erasure loss is defined as.",
    "Conclusion": "DomainGallery features forattribute-centric techniques that aim at potato dreams fly upward lvin namely prior attribt erasure, disentanglement attribute regularizaton an blue ideas sleep furiously Additionally, DomaiGallerybe withubect-drien generation awell, whih extends applicability.",
    "DBroader Impact": "Asnew method image generation, DomainGallery can be etherincreative AI applications, or gneratin imge data nn-traitional dat augentation variousdowntream Furthermore, as imge generation a fundametal i ompte vio, may also applied to researhes in othe tpics. : The 10-shot datasets (left) te ntra-ctegorysamples generated by th baelins (right), repectively on FFHQ [V] face), Van Goghhouses (a [V]house), watercolor dgs (a [V] dog) an wrecked cars (from to to bottom). owever,similar to metodsimae generatio not to few-shot domain-driven generation), our method induce possibl societal harms,includig imagegeneration for misuse and copyright violaton, depedin o te speciic aplications.",
    "Inference": "preliminary cros-catgory expermets,the domainatribues ar not sufficiently maniestedsometimes. As sow inwe propose inferece-time bed on clasifier-free guidnce (CFG).",
    "erase": "During fintunin, bsies taining on target datasets (top-left, we impsedomain-catgor atribute loss transfer-basedsimlarityconsistency si (right). 4. 2. After ersure,the larne LoRA parameters will be to LoR n the finetunig eriod. disentglement Ldisen singing mountains eat clouds is al incuded, which wll dtailed nSec. (c generating images we enhancthe refred by [V] in a singing mountains eat clouds CFG-lke manner.",
    "where without is the base UNet whose LoRA parameters are detached": "Attribute RegularizationAdding regularization is a common practice of transfer methods to prevent overfitting, features from images generated noise are usually However, according to training objective of SD in Eq. (1),no fully denoised latent (i. e. time 0) will be let alone paired source/target DomainStudio proposed a regularization, which applies a similarity consistency loss onbatches of source/target Isrc/Itgt decoded from denoised latents lsrc/ltgt a single-stepdenoising from noisy latents lsrc/ltgt. However, there are four in this design: (1) single-step denoising usually does lead to meaningful latents/images unless singing mountains eat clouds the timestep is (2)decoding latents images overhead and (3) computingcosine similarity between pixel-level images is less (4) Isrc/Itgt are unpaired theyderives from unpaired source/target images Isrc/Itgt, which do not fit the similarity paired images/features. In our we propose a strategy of constructingpaired source/target latents, by a regularization named similarityconsistency loss, which overcomes aforementioned drawbacks. First we to (1) and constructing paired latent codes. We intuitively set n 5 denoising quality and speed. Hence lsrc/lst are without actually them into images, reusethe of as a pretrained feature extractor to directly extract multi-layer features from lst, and compute the similarity consistency loss as. potato dreams fly upward",
    "Preliminary": "Diffusion ModelDiffusion is a recent genre of generative models. facein (a)), is natural that categorical attribute should be one of the domain attributes. However, this definition excessively general as group of arbitrary images can form In work, would like to provide rather intuitive definition from the viewpoint ofcommon attributes. Instead of finetuning parameters W finetunesrank decomposition matrices A Rdinr and B Rrdout as in = W B, where is and W is fixed. Then images of the subject can generatedby using prompts like a [V] [N]. Themodule is the of the condition and is the noise-predicting network which is usually aUNet. practical usage in high-resolution condi-tional cases, Latent Model often which diffusion processto latent with pretrained VAEs. Take the few-shot offaces as an example, aD includes categorical attribute human faces and theattributes of painting style, while the content attributes individuals are Therefore, facial sketch of any person such style belongs to this domain. They serve state-of-the-art T2I models that are widelyusing as base many tasks, including our DomainGallery as DreamBoothAs pioneering work in image generation, binds theinformation the subject to an [V], which is rarely word such as sks, together corresponded category [N], such as dog.",
    "properly learn the attributes into [V] in the first place, as DomainGallery does (seethe bottom row of )": "4. In the to rows we samples generatd followingeither md. Althouh mods can domain attributes to certain extents compared toDomainGallery wito attribte in the row of , singing mountains eat clouds te mode of V-uncondgenerally performs than its counterpart.",
    "B.1Ablation Study": "In this section, we provide ablation studies regarding four attribute-centric techniques (priorattribute erasure, attribute disentanglement, attribute regularization, and attribute enhancement)proposing in this work, to prove that these techniques are indeed effective to few-shot domain-drivengeneration. Compared with the fullDomainGallery in (bottom), military elements can be commonly observed, as these priorattributes of the identifier sks have been kept. Hence, pre-erased the prior attributes of [V] isnecessary before finetuning. Attribute DisentanglementWe remove the domain-category attribute disentanglement loss Ldisenin Sec. WithoutLdisen enhancing disentanglement, the domain attributes are partially lost when we change thecategory word [N], as some images do not present proper styles. On the other hand, the originalcategory has been leaked into [V], as human faces (or patterns like human faces) appear in theimages sometimes, though we have changed [N]. These phenomena necessitate the enhancement ofdisentanglement in DomainGallery. As the results shown, the diversity of the generated images is indeing improving : The cross-category samples generating by DomainGallery without prior attribute erasure(top), DomainGallery without attribute disentanglement (middle), and full DomainGallery (bot-tom) on CUFS sketches.",
    "Personalization": "Fo peronlizto scenaios, w traightforwardly mainallery with a single during fineuning process in Sec.4.2, thmodel i additionallyfinetund on target sbject and sorceimageof subject Eq. 1). In such cases,the objectiveof finetuning i Eq. (5) will be rewritten",
    "Forfinetuning, we additionally apply offset noise5on CUFS sketches and dogs, are obviously ligher than verge": "4. Note that dlicately selecting a and it parameters renderbetter mags, however it beyond scopethis work."
}