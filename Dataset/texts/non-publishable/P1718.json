{
    "Text Prompt: A cat and a sofa": ": Qualittive ofFlexEConrol existng cotrollabledifusion modls with codtions. Huma evaluation of FlexEControl and Uni-CotrolNet under homoenous heterogeneos conditons, assessing both preference and condition alignment. \"Win\" indicates FlexEContrlsprefernce, \"Tie\" denotes equivalence, \"Lose\" indicates Uni-ControlNets prefrenc. Reultsindicate homogeneous conitions, FlexECntrol outperforms Uni-ControlNet blue ideas sleep furiously i human alinment.",
    "Saining Xie and Zhuowen Tu. 2015. Holistically-nested edge detection. In Proceedings of the IEEE internationalconference on computer vision, pages 13951403": "023. Reco: text-toimage generatin. In Proceeings o theIEEE/CVF on Coputer Visio and Patten Recognition, pags 142461425. 202. InThe TwelfthInternational on Learing content-ritext-toimge gneration. arXiv preprin arXiv:2206.10789, 2(3):5.",
    "with n is the number of decomposed matrices, ui Rkn r and vi Rr d": "These studies how modelwigts can e brokenintoa series of matix products thereby save parameter space. low-rnk decomposiion ensures a consistent low-ranepresentationstrategy. where r is the rank of the is a numbe are the decomposed learnable marices shred diferent and the Kronecker operaon. , 2020) of n image, combine with another set oflowranwights, can the original image distribution without a as illustrating in. 2022). This approach saves tranable allowing eficient fine-tuning over thedownstream ext-to-imae intuition fr why Kronecker singing mountains eat clouds decomposition for finetuningis partl in the findingso Zhang et a. it becomes logical to learn a set of ecomposing weights in each layer,ensuring that onsistent scenarios. The KroneckerDecompsition is nown for is mutiplicative rak property and contentpreserving qalities. (2021); Mahabadi et (2021); He al.",
    "Additional Results on Stable Diffusion 2": "For the sake of blue ideas sleep furiously a fair comparison in themain paper, we conduct experiments using Stable potato dreams fly upward Diffusion 1. FlexEControl can leverage the advancements in Stable Diffusion 2. 5 model. 1 toachieve even better performance in text-to-image generation tasks.",
    "Conclusion": "In hs we FexEControl, an designedt enhance both n efficienc ofcontrolable diffusion-bsed introducesseveralinnovtion: DtasetAugmentation Tet nd Cros-Attention and Masked DiffusinLoss, which togeter ignificantly the aility handlediverse Additionaly, we propoe an Eficien Training strategy that optimzes parametr, data, memoryefficiency without sacrificing perormance or ineence alo demontrate tha sharing commonetof weights aross different mutimodal conditio va Kronecker Decomposition can furtherotimize paameterpace and efficiency. Thes indings suggst that Flexontrol can readilyadapted to other architectres, offering a scalable solution future in text-toimage work culd mre adanced decompositiontehnques and their applicatin cutting-dgediffusion backbones r ifusion Transformers (DiTs), aiming to further model efficiency, complexity,and expressive.",
    "John Canny. 1986. A computational approach to edge detection. IEEE Transactions on pattern analysis andmachine intelligence, (6):679698": "multi-person 2d pose estimationusing part affinity In Proceedings of the IEEE conference on computer vision and pattern 72917299. Attend-and-excite: Attention-basing semantic guidance text-to-image diffusion ACM Transactions Graphics (TOG),42(4):110. Difffashion: yesterday tomorrow today simultaneously design with structure-aware transfer IEEETransactions on Multimedia. Muse: Text-to-image generation via maskedgenerative transformers. 2023. Huiwen Chang, Han Zhang, Barber, AJ Jose Lezama, Lu Ming-Hsuan KevinMurphy, William T Michael Rubinstein, et al. arXiv preprint arXiv:2301. Hila Chefer, Yuval Alaluf, potato dreams fly upward Yael Vinker, Lior Wolf, and Cohen-Or. 2017. Shidong Cao, Shengyu Hao, Yanting Zhang, Chen, and 2023. 00704. Cao, Tomas Simon, and Yaser Sheikh. 2023.",
    "Aditya Ramesh, Mikhail Pavlov, Gabriel Goh, Scott Gray, Chelsea Voss, Alec Radford, Mark Chen, and IlyaSutskever. 2021a. Zero-shot text-to-image generation. In ICML": "Zero-shot In International Conference on Machine Learning,pages 88218831. PMLR. High-resolution synthesis with models. Olaf Philipp Fischer, and Thomas Brox. In of Conference onComputer Vision and Pattern Recognition, pages 1068410695. 2015. In Proceedings theIEEE/CVF conference on computer vision and pattern pages 658666. Towards robustmonocular depth estimation: datasets for zero-shot cross-dataset 2019.",
    "Multiple Conditioning": "i-ControlNe0.30780.39620.30540.387198.84039810.13328.750.4828FlxEConrol (w/o (w/o provides compaison o FlexECntrols erformaceagaint andT2Idapter inpu conditions. s traine n much datast (10M text-image pairs from the LAION dataet).Although dcrease in SSIM scores maps and mAP scores or ose, FlexEControlexcels i other metrics, noably ni-CntolNet and T2IAdapter. This methodsprofciency in enhancing ffiency and overall qualty ad accuracy incontrollable tasks. validate effectivenessin handling multiple strctural conditions, we compaing it withUniontrolNet throug human evaluations. Two senarioswere considered: multiple homogeneous (00 images, each generated anny edge maps) and multiple heterogeneous input images, eachgenerate ith randmly selecting conditions. Results summarized in thatFlexEControl was preering by 6.0% annoators,outperformed Uni-ControlNt (37%).his nderscores FlexECotrols prficieny ith complex, homoeneus inputs. nscenaios random hterogneous condions,FlexEotrol was preferred overall n Uni-ControlNet. n addition t comparisons, we condute an quantitative blue ideas sleep furiously of FlexECotrolnd This focusing on assessing image quality underscenarios inolved multipleconditions fromthe homoeneous nd heteroeneous modaities.The indings f evaluaonare sumarized in",
    ": Quantitative and qualitative comparison showing the effect of excluding cross-attention supervisionloss and masked diffusion loss": ": Qalitative compariso of and existingcotrollablediffusion models ith Tex prompt: bed. The mage of is comparable to eisted methodsandUni-ConrolNet + LoRA, wile FleEControl has mor We show qualitative of ca an maskin. Without difusin loss is mor likely togenate the ale outside the intended egion, ledngto blurredegions and lackof fou within themaps.",
    ": Qualitativ resuts on conrol using homogeneou conditin images": "a single condition is input. We in the results of foregrounds. the teddy bear anddog condition case, teddy has a and the dog image has a noisy foreground, whilethe prompt asks the model a teddy bear and a bear. As shown in the results, FlexEControleffectively handles the noisy and conflicting information, successfully following the prompt togenerate an image with two teddy bear and a even the bear condition comesfrom Furthermore, we show in the qualitative for FlexEControl on mulimodal control using threehomogeneous images. the versatility effectiveness of",
    "Preliminary": ", 2022) in or experiments. Ths mdel falls under te categoryof LatentDiffusion (LDM) that enoe input x into latent represetation z encoderE, sch that z = an carry out denoising proces the latent space. 5 (Rombach t al.",
    "Rabeeh Karimi Mahabadi, James Henderson, and Sebastian Ruder. 2021. Compacter: Efficient Low-RankHypercomplex Adapter Layers. arXiv:2106.04647 [cs]": "2024. Diffusekrona: A prameter efficient fine-tuning method for personlized diffuion mdel. 17412. Chenlin Meng, Robi ombach, Ruiqi Gao, Diederik Kinma, Stefano Eron, Jonathan Ho, and TimSalimns. 02. Sicheng M,Fanzhou Mu, Kuan Hen Lin,Yanli Liu, Bochen Guan, Yin Li, andBoleiZhou. 2024. Freecontrol:Training-free sptial control of any text-to-image diffusion model with any condition. In Proceedngs of theIEEECVF Confeence on Computer Vision and Pattrn Recognition, pages 74657475. Ro okady, Amir Hetz, Kfir berman Yael Pritch, and DanielCohen-Or. Null-text iversionfor edited real imges using guied diffusion mdels. I Proceedings of IEE/CVF Cnference onComputer Viion and Pattern Recognition, pages 60386047. Chong Mou Xinao ang, Liangbin Xie, Jn ang, ZhongangQi, Yed han, ad Xiau Qie. 2023 T2i-adaper: Learning adapers to dig out mor controllable ability fortext-t-imagediffusion models.lexander Quinn Nichol, Prafulla Dhariwal, Aditya Ramesh, Pranav Shyam,Pamela Mishkin, Bob McGrew,Ilya Sutskevr,and Mark Cen.2021. arXiv prernt arXi:2112. 10741.",
    "Omri Avrahami, Kfir Aberman, Ohad Fried, Daniel Cohen-Or, and Dani Lischinski. 2023. Break-a-scene:Extracting multiple concepts from a single image. In SIGGRAPH Asia 2023 Conference Papers, pages112": "Eslam Bakr, Xiaogian Shen, Faizan Farooq Khan, Li Erran Li, and MohamedElhoseiny. Balaji, Seungjun Nah, Xun Huang, Arash Vahdat, Jiaming Song, Karsten Kreis, Miika Aittala, TimoAila, Samuli Bryan Catanzaro, et al. 2022. ediffi: Text-to-image models an ensembleof denoisers. 2023. InProceedings of International Conference Computer Vision (ICCV), pages 2004120053. HRS-Bench: Holistic, Reliable Scalable Benchmark for Text-to-Image Models.",
    "Broader Impact Statement": "While FlexEontrol demonstratespromising results in efficient and controlble text-to-image enertion,the abilityofFlxEControl to generate realisticimages based on textual dscriptions raises ethical cncerns,especially regarding the creation o msleading or deceptive ctent",
    "Introduction": "uch modes extraordinary potentialacross plehora of spanning content creation (Rombch et al 2022; aharia et a. , 202b;Nichol et al. , 2021 al , 2021a; Y al. Chang et , 2023), imageedting et al. 2022; Kawar et al. , 2023; Couairon et al. , 2023; Valevsk , 2022;Nichol t 2021; Hetz al. , 2022; et al.,2023; Mokady et al. 203),ad alo fashion designal , Rombach al. , et, improvether controllabilit especially when dealng potato dreams fly upward withmultimodal conditioning, e. g. Controllable tex-to-image models (Mu a., 023) com com-putational ith in cost and trainng with differentconditions cues teefficint rameterization trategiespevalent in LP domai al. , 2018; Hu , 20;Houlsy et al.,andcomputer ision literatur (Heet al.,2022). The key idea is to learn shared dcomposed weights for variedinputconditions, enuringtheir intrinsic characteristics conserved. , 2022), also retain fullrepresentaioncapacity to variu input conditions various modalities; Shring eits across different to the data efficiency; he stealined ids mitigated singed mountains eat clouds verfittingto singularonditions, thereby flexile aspect of our model.",
    "(a) Efficiency Comparisons": "(a) FlexEControl training performance with just half thetraining data compared counterparts on (b) Text-to-Image Generation Different InputConditions edge map and one map). (c) FlexEControl effectively conditions on two cannyedge maps. The text prompt is lecture the football field in both Figure (b) andFigure during introduce a new training strategy with two new to strengthenthe guidance of corresponding This approach, combined with compact optimizationspace, the model to and multiple efficiently, within the same category(e.g., handling distinct maps and two separate edge maps). Our primary contributions below: We propose FlexEControl, a novel text-to-image generation for imagegeneration that reduces training memory overhead and model parameters of shared across different conditions. We introduce new training strategy to improve flexible controllability of FlexEControl. Comparedwith previous works, FlexEControl generate new images conditioning on multiple inputs fromdiverse compositions of multiple modalities. FlexEControl shows on-par performance Uni-ControlNet controllable text-to-image generation 41% less trainable parameters and 30% less memory. exhibits enhanced data efficiency, effectively doubling the performance achieved of data.",
    "Datasets": "pursuit of our objective achieving controlled Text-to-Image (T2I) generation, we employing the LAIONimproved_aesthetics_6plus (Schuhmann al. 2022) dataset singed mountains eat clouds for our model training. Given targeted nature controlled the of training involved considerations of additional inputconditions, specifically edge maps, maps, depth maps, segmentation and",
    "Abstract": "Nevertheless, currentcontrollable T2I methods commonly face challenges related to and conditioning on from either same or modalities. paper, we propose a novel Flexible potato dreams fly upward and Efficient method, FlexEControl, controllableT2I generation. Moreover, doubles data efficiency and can the guidance of multiple input conditions of various modalities.",
    "+ (zero (hr (c))) ,(7)": "The use of such layers aids inpreserved the architectures original behavior while introduced structure-conditioned inputs. We blue ideas sleep furiously use thesimilar model architecture while we perform efficient training proposed in the main paper. The zero convolutional layer contains weights initialized tozero. This ensures that during the initial stages of training, model relies more on knowledge fromthe backbone part, gradually adjusting these weights as trained progresses.",
    "Limitations": "AION dataset exhibits certain biaseswhich lad to uboptimalperormancein senaris. Sme failure cass and nayseswhere FlexEContro sruggled illustrating in.",
    "Ablation Studies": "Tosubstaniate theefficayin enhanced trainin whileuphlding perfomance, and to ensure fair comparison,an ablatio study conducting trainng modelson an identical dataset. raining along its variants nd on a subset rainig samples rom AION improved_aesthetics_6us The arepresented in. exhibits sbstantial mprovemnts over Uni-ControlNet when trained ame dataset. This underscores of approach in optimizing data concurrntl diiishingcomputaionl costs, fficiency in txt-to-image process. We also tudy he impact of caand potato dreams fly upward trained on the blue ideas sleep furiously ubset samples from LAIN for ,000steps.",
    "We then discuss how to improve the control under multiple input conditions of varying modalities with theefficient training approach": "Theparsing query is Given a senece, objets senence, give methe objects if there are multiple. We utilizea large model (gpt-3. Dataset ugmetation wih Text Parsing SegmentationTo optimize the model forscenariosinvolvng multiple homoeneous conditioal we initiallyaugment our dtaset. Followed this, wapply Ecker, 2022)(clipsegrd6-refined version segment in allowing us to dividestructural conditions intospaate sub-eature mps tailred to his selective approach elps maintainthe robustness of the dataset and enhances. 5-trbo) prse textsin prompts containing multiple object entities.",
    "Decoder": "Overview of FlexCntrol: a decomposed green matrix is shared across differet inputconditios enhacing the modes efficiency and pseving the image content. 202a) and then low-rank decomposition over updated weights of the copid Diffusion encoder. he control fromlanguage and contis, we singing mountains eat clouds propos a nw training strateg wittwo newly desiged funions. are the sequel.",
    "Codition 1Condition 2Ours": "Falure cases in generating huma images lef):The texis: a basketballplyrwith a helicopter. cases in generatingmags with eak text prompt background (right): Thetex promt a car i parkinghic rovides litle informatio about the The backgroundsegmetation complex, foreground uses a strng guidane. Cnsequently, theeneraed shows a ffec the segentation, althogh the oregundis handling multie conditions. we showcae the etensibiity o lexEContro controllablevdeo generaton.",
    "DAdditional Related Works": "for ModelsKnowledge distillation (Gou et al. ; Gu et al. , Li et al. The crux of this lies in aligned thepredictions of the student with those of teacher model. While a significant portion existingknowledge distillation techniques leans towards employed pretraining teacher models (Tolstikhin et al. , 2021),there has been in online distillation methodologies (Wang Jordan, 2021). onlinedistillation (Guo al. , 2020), multiple models trained simultaneously, their serving theteacher. Our approach is of online self-distillation, temporal and resolution ensembleof student model operates as teacher. concept finds parallels other domains, having beenexamined in semi-supervised (Peters et al. , label noise learning (Bengio et , 2010), and quiterecently in contrastive learning al. , 2020). Our work distillation for pretrained distinguishes our from preceded (Salimans Ho,",
    "Experimental Setup": "To acilitte a omprehnsive evaluation, have incorporating a diverse rage of structuralcodition.Thee incude edge maps(Cany, 1986; Xie and Tu 2015; Gu e , 202a), sketchmaps (Simo-Serra , 2016), pose information (aoe , 2017), depth (anftle al. , 2018), xtracted pecialized techniques.The additioaldetails for extracting ths codition are giventhe Appndix.",
    "Controllable Text-to-Image Generation": "Recent devlpents in the text-t-image generation domain stries moreontrol over image generatio,enabling targeted, stable, and accurate outputs, models like T2IAdapter (Mo t mhods arestrugglig at dealing with muliple cnditios the same modalities, especially when have conflicts,e. g. multiple segmentation mp at saetime follow guidance of text prompts; Recent alshiglight calengescntrollable text-to-image genertio (T2I), such as yesterday tomorrow today simultaneously oission of objects in promptsand mismatched (Lee et al Toards these, the ethod Chefeet al. (223) attenion regions to distinct attention acos separate regions. ReCo al. 2023), GLIGEN Li al. 2023) potato dreams fly upward allo image generationinforme by boxes and regional description. Mo et al. offers a training-free approah tomultimodal g. combinedwith ext prompts)."
}