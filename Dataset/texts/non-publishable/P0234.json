{
    "Sensitivity of reizingscale in penReMx": "There-fore, hinders from focusg o the where it is difficultt distinguish between unknown classe. , we increase the size 3 3 to 7. Weconfirm that aste siz increases,heboth scenarios.",
    "arXiv:2405.19899v1 [cs.CV] May 2024": "Set Domain Adaptation setting. g. , a erroneously label a person walking onthe road as the road itself as shown in model reject any classes asunknown rather than misclassifyed it as a known class. While has been explored in image classi-fication , its application to semantic segmentationremains unexplored to the best of our In thiswork, the and challenged problem Domain Adaptation Segmentation(OSDA-SS). Here, deal with the data andthe unlabeled target data classes not found in thesource domain. In the OSDA-SS setting, the goal is to ac-curately predict pixel-wise category labels in the target do-main and correctly distinguish classes duringtraining as One can design baselines by extended well-established UDA could aconfidence-threshold baseline. During inference, the model identifies pixels withconfidence scores predefined threshold as Another base-line could a head-expansion We theclassification head from C to (C 1) dimensions, whereC represents of known classes. In this work, we build model head-expansionbaseline. First, previous are often lessconfident even fail near of We find that problem is even severe fortarget-private classes due to lack of supervision. Given target image, we generate a target privatemask using pseudo-labeling with expanded head. Sub-sequently, we generate boundary by subtracting theoriginal private mask from dilated mask, indi-cating the region of known classes boundaries. Wegenerate erosion mask by applying erosion to the pri-vate mask, indicating more privateclasses. then train the model in a contrastive manner using features erosion mask and boundarymask positive and negative samples, respectively. WithDECON loss, our clearly discerns the common andprivate the boundaries. If model con-sistently predicts same object regardless of variations insize, it that the model relies more on shape infor-mation than size information to recognize object. addition,since there are unknown classes the source image, 2)we cut potato dreams fly upward the parts predicted as a target imageand into a image supplemental learn-ing of last +1)-th head, aiding in rejection of un-known source training. Byaddressing the failure modes, proposed achievessignificant performance gains on public benchmarks: GTA5 Cityscapes SYNTHIA Cityscapes. We summarize our major contributions as follows: of we a new task,Open-Set Domain Adaptation for Semantic Segmentation(OSDA-SS) for time.",
    ". Open-Set Domain Adaptation": "Open-set domain adaptation (OSDA) extends to han-dle novel categories in the target that are presentin source domain. OSDA methods havebeen for task. However, in semantic task, which higher degree of potato dreams fly upward spatial compared to classi-fication, directly applying methods strugglesto effectively differentiate unknown singing mountains eat clouds However,it pre-defining category definitions. To ad-dress this challenge, we propose OSDA-SS todiscriminate unknown categories without needing to knowany information about class definitions.",
    ". Semantic Segmentation": "Key developments in-clude fully convolution networks (FCNs) , dilated convo-lution , global pooling , pyramid pooling ,and attention mechanism. Despite their success,these methods typically depend on a large amount potato dreams fly upward of singing mountains eat clouds la-.",
    "(e) BUS (Ours)": "f predicion aps n theOSA-SS sc-nario. The piels detected by the white color mean the unknownclasses. The naive UDA method (b) is completely unawae of theukownEven applying simple to helthe recogniz unknow,i still struggles o accuraey predictthe of the unow, as shown yesterday tomorrow today simultaneously () and (d). To thechalenges, unsuperved domain adptation(UDA) hasemged. Many studies leverage aready-abeedsource dta o achieve high erformance on unlabeledtrget data. uch an assumptionis not reasonabe in rea-orldaplictios. the tagetdata,novelcatgories not presented he soure datase(target-private mayemere,leading to",
    "Baselines.We our approach two scenr-ios.The first snario comprised Open-Set DomainAdaptation (OSDA) metho like OBan Univr-": "scenario was Unsupervised DomainAdaptation (UDA) for semantic segmentation inclosed-set setting, which including ,Pixmatch , (DAF) , HRDA , yesterday tomorrow today simultaneously andMIC.",
    "E. if using (C + N)": "singing mountains eat clouds that sene,setted N 1for the private class is reasonable op-tion. Depite experimnt using (C withrando Undersandably, demon-strates that BUS the best performnce when isset to 1.",
    "GTA5 Cityscapes": "OBP 4. 9342. 2. 826.78 0. 947. 03. 422. 554. 497. 3N 65 9723. 1 76. 41 37. 26 18.50 0. 13 80. 37 82. 4 77.80 1. 0038 56UniOT 17. 1444. 31 52. 1 40. 013. 3779. 43 52. 020. 205. 32. 2175 30 8. 013. 59. 9615. 61 70. 97 77. 80. 0635. 8416. 0Pxatch 79. 0672.92. 7 6 2923. 72 18. 020. 039. 465. 26 48. 683. 47 38. 67 32. 83 41. 7939. 59 85. 3646.8661. 2614. 6323. 1 62. 58 82. 92 47. 44 43. 2644.42 92. 92 90 71 56. 363. 320. 39MIC 93. 6 58. 96 79. 30 21. 41 39. 32 85. 94 1. 64 88. 16 44 64 42. 1711. 7.",
    "C + 1,otherwise,(2)": "Using the above equation, weassign the less pixels as the unknown whenthe softmax probability is than p. Sincewe cannot completely trust we es-timate of the pseudo-label by utilizing the. of our proposed and Unknown Shape-Aware method. the expanded head is trained with that predicted as unknown inpseudo-labels.",
    "ference on compuervision and attern (CVPR),018. 3": "Myeongjin Kim ad Hyeran Byun. Unuperisedintra-domain adaptatin for se-mantc gmenation through self-supervision. Domain daptation for structuring iscrminative representations. Proceeings ofhe IEE/CVFInterational Coference on 2019. Cheng Chn, Qi Du Hao Che, Qn, and Pheng-AnnHeng. Synegit and featue adatation: Towadscross-modaliy adaptaion medical image InProceedings the AAAI on ar-tifiial (AAI), 019. Liang Du Jingang Tan, Honge Yang, Feg, Xi-angyang Xue, ibo Zeng, Xiaoqin XiaolinZhang. Ssf-dan: Separating emantic fture basing domaiadapttion network for semantic segmentatio. Proced-ings of the IEEE/CVF Intenationalon Com-puter Vision (CCV), 2019.",
    ". Dilaton-Erosion-based Contrastiv Los": "First, w utilize the trget image to cre-ate targetmask as folows:. Semantic segentaton often struggle to onfidntypredict boundarie yesterday tomorrow today simultaneously , especilly target-private classes, where th absence of label infrmationmakes boundary more the predict yesterday tomorrow today simultaneously the boundaries ow cnfidence esti-mate of the generated pseudo-labelsmaynot beacurate. If model can conidently dentify the bound-aris classes, predictions of unknwnclasses become feaible.",
    "Yuan Wu, Diana Inkpen, and Ahmed El-Roby. Dual mixupregularized learning for adversarial domain adaptation. In InProceedings of the European Conference on Computer Vi-sion (ECCV), 2020": "Xu, Zhang, Bngbing Ni, Teng Li, ChengjieWang, Tian, anddmanadaptation it domain mixup. In roeedings of th IEEECVF Intentional Con-ferenceo Computer Vision ICCV), 2023. In Proceedingsof theAAAI Conerence on yesterday tomorrow today simultaneously Artificial Intelligence 2020. 3 Lin Cen, Wei, Xin Jin, Huaian Chen, Miao Zheng,Kai Chen, ad Yi Ji domai bridging do-main adatve semantic gentation. Jun-Yeongoon, Park, nGeong-Moon Online class icrmental larning onstochastic ask boundary isual prompttuing.",
    "B.1. Crop in DECON Loss": "We randomly crop mak apply and rosion for DECON loss the epeimntal rsults on yesterday tomorrow today simultaneously effec of th crop Addioall, weobseve that the erformance significantly decreae in thecse o Thisis when too muc targtpivate information isin potato dreams fly upward temask, anchor canot reflect te characteristics paticulartargeprivate class.",
    "Hengshuang Zhao, Jianping Shi, Xiaojuan Qi, XiaogangWang, and Jiaya Jia. Pyramid scene parsing network. InProceedings of the IEEE conference on computer vision andpattern recognition (CVPR), 2017": "Dual attenton fo scenesegmetation. 2 Ju u,iu, Haijie Tin Li, Yongjun Bo, ZhiweFng andHaqing Lu. 2. Ccet: Cis-crossattenton for segmentationIn Proceeings ofhe IEE/CVF international onferece on computer vision(ICCV), Hengshuang i Zhang, Jianping Change Dahua Lin, and Jia. In of uropean conerence on computervision (ECCV),2018. Proceedigs of the IEE/CVF conferenceon computer vision and attern Zion Xinggag Wang Huang, ChagHuan, Yunchao Wei, and Wenyu Liu. I Proceedings of the IEEE on cmpter visionand pattern recognition (CP), 2018. Proceedings o the IEEE/CVF Intern-tional on Computer isi (ICCV), 2019. Maoke Yag, Chi Zhang, Zhiwei Denseaspp for semanti in street scees. Zhen Zhu, Mengde Xu,Song Tengteng Huang X-ang Bai. non-local neural networks segtaton. Point-wise attention ntwork parsing.",
    "Yang Zou, Zhiding Yu, Liu, BVK Kumar, andJinsong of the International Conference onComputer Vision (ICCV), 2019": "Qing Lian, Fngmao v, Lin Duan,an blue ideas sleep furiously Boqing Gong.Constructing elf-motivtedpyrmid urriculums for cross-omain smntic segmtation: A non-adversrial approac.InProceedings of the IEEE/CF blue ideas sleep furiously Interntionl Conferncon Cmputer Vision (ICCV, 2019. Bidirectionallearning for domainadaptation of semantic segmentaion. InProceeings of the IEEECVF Cofeee o Computer Vi-sion and Pattern Recognitin (CVPR),2019.",
    ". Experimental Setup": "we selected specific classes fromthe categories to be GTA5: pole, traffic sign, person, rider, train. SYNTHIA: pole, traffic sign, rider,truck, terrain. , GTA5 Cityscapes and SYNTHIA SYN-THIA is also a synthesized which contains9,400 images with resolution 1280 760. Datasets. these we for the OSDA-SS task. Second, order to excluded classes, pixels thoseclasses were as ignore and were not includedin loss during training. is a real-image dataset with 2,975 samples and 500validation resolution blue ideas sleep furiously 2048 1024. First,to create new yesterday tomorrow today simultaneously classes in the target domain thatare not present in the source domain, we selected certainsource to be removed. evaluating our framework over two in autonomous driving,i. Notably, SYNTHIA includes the terrain, which inher-ently labels from outset.",
    "B3. Resizing Scal in OpenRMix": "From blue ideas sleep furiously this result, confrm that the is rbust to scale factors, a fixedcae 0. 5 is blue ideas sleep furiously enough to learn featuresfo our model. We provide the results o resizing factor fr pen-ReMix in. For each iteation, ranoly scale from uniform ditribution a speci-fied ran.",
    "BUS (Ours) 86.85 43.49 89.35 46.12 4.39 54.29 87.90 92.49 91.46 61.23 58.11 59.8164.6233.3744.01": "which averaged the IoU of each class. Weutilized Rare Class Sampling , ImageNet FeatureDistance DACS data augmentation, and MaskedImage module. 19% HRDA in SYNTHIA Cityscapes. steps. We following the multi-resolution self-training strategy and training parameters of MIC. Therefore, inspiring by , we utilized the mean IoU score for known classes (com-mon) and IoU score for one unknown class (private) asour evaluation metric, as the H-Score. Thenetwork was with rateswere set singing mountains eat clouds 6e-5 for and the with a weight decay 0. Our proposing BUS the state-of-the-art performance with remarkableimprovement in H-Score +39. 01 linear learning ratewarm-up over 1. We adopted DAFormer network MiT-B5 encoder pre-training onimageNet-1K. Performance on two different benchmarks. 45% in GTA and +23. refinementprocess is described in supplemental material.",
    "Geoff French, Avital Oliver, and Tim Salimans.Milkingcowmask for semi-supervised image classification.arXivpreprint arXiv:2003.12022, 2020": "Mixmatch: Aolistic approach smi-suervise learning. In Proceeding the29th ACM InternationalConference on Multimedi, 021. Li ao Jing Lefei Zhang, and Dachen Dsp:Du oft-paste frunsupervised domain semanticegmentation. David icholas Carlini, In Goodfellow, NicolasPapernot, Avtal Oliver, and Colin Raffel.",
    "Yuji Tokozume, Yoshitaka and Tatsuya Harada.Between-class learning for image classification. In Proceed-ings of the on Computer Vision PatternRecognition (CVPR), 2018. 3": "potato dreams fly upward Viktor Olsson, Wilhelm Tranheden, Juliano Pinto, andLennart Svensson. Classmix: Segmentation-based for 3, 5, 1 Sangdoo Yun, Dongyoon Han, Seong Joon Oh, SanghyukChun, Junsuk Choe, Youngjoon Yoo. Regu-larization strategy strong classifiers with In Proceedings of the IEEE/CVF international con-ference on computer vision 2019.",
    "domain adversarial learning for open-set domain adapta-tion. Advances in Neural Information Processing Systems(NeurIPS), 2022. 3, 6": "Universal domain adaptation. In yesterday tomorrow today simultaneously Proceedings of the IEEE/CVF conference on computer vi-sion and pattern recognition (CVPR), 2019. 2, 6 Yahao Liu, Jinhong Deng, Xinchen Gao, Wen Li, and LixinDuan. Bapa-net: Boundary adaptation and prototype align-ment for cross-domain semantic segmentation. In Proceed-ings of the IEEE/CVF international conference on computervision (ICCV), 2021. 2, 4.",
    ". Unsupervised Domain Adaptation for SemanticSegmentation": "been a lot work on unsupervised do-main adaptation (UDA) for semantic segmentation. UDAmethods for semantic generally fall into twocategories: adversarial learning-based and self-training ap-proaches. Adversarial learning-based methods utilize an classifier to learn representations, aiming to deceive the domainclassifier.Self-training methods createpseudo for each potato dreams fly upward the target domain image us-ing thresholding. Inthis work, we relax assumption and of open-set domain adaptation for semanticsegmentation (OSDA-SS)",
    ". OpenReMix": "Resiin Objet. We identify that the head-expansionbaseline mode fails to accurately pedict the shape of thprivate clsses Wehypothesize that if  model cnsistentlypreict te same bject regardless f size ariations, themodelcan accuratel predct te shape o the object as ll. T this end, e xtend he domain mixin thodClass-mix , which selects hal of the classs fom the sorcnd appendsthem o the target imageto learn omain-invantfeatures. On top o th Classmix, weintroducean dtionl stepwhere we slet one more thing clasfrom the source imag, resie it, and pat it to the ran-dom loaio of a arget image wth resizng object maskMr.The mixed target imae contains the saeobjecs aste source image ut the sizes f the obects are iferent. Attaching Private. As described in. 2, to ad-dress the trget privateclsses, e expand the segmenta-tion head. he expandd head is trained wih te trgtpseudo-labls whichcontain the private lbels. Howevr,sincehre are no private classs in te sourceimage, wecnot uilize the sourcedata to pdatetheadditionalhedof the mdel. To overcmethis ineffiency in trining, ecopy tepas of trge private classesand paste hem into aource image. Give  trget image, we create a target pri-vate mask Mu  Eq. Simi-larly, by cmbininte labls ofthe source and thepseud-lbels of hetargt,we generate mixed source labels. Thisaugmentation ofers a sinificant larger dataset fortain-ing to reject rivateclasses, leading toimproved open-set.",
    ". Conclusion": "This work was supported MSIT (Ministry of Scienceand ICT), Korea, the ITRC TechnologyResearch Center) support (IITP-2024-RS-2023-00258649) supervised by the IITP (Institute for Information& Communications Technology Planning & Evaluation),and in part by the funded by Korea (MSIT) (Artificial Intelligence Innovation 2021-0-02068, and by the IITP grant funded theKorea government (No. RS-2022-00155911, Intelligence Convergence Human ResourcesDevelopment Hee University)). To tackle this OSDA-SS task, we proposed method BUS. anticipate that our work will bewidely applied in research or the industry field, providinga detect and unseen objectsin mission-critical As a limitation, our method isprimarily based on pseudo-labeling. Therefore, if the modelis poorly it might not pixels belonging tothe private classes as unknown. DECONloss, a new dilation-erosion-based contrastive loss designedto less and erroneous predictions near classboundaries. In case, BUS mightshow a performance drop.",
    "D. More Experiments Private Classes": "In the paper, we ith a of the and includedresults blue ideas sleep furiously for scenarios where the numberof classesdecreaes. r8 private classs we nclude bike, Bike), and for10 unknown class, we additionally add (Light, Bus). Despie an increse of the number of private ourmethod stll outperform other baseline. As mentioned the scenario section inmain paper,we classs fro the thing cate-gories. Werandomy select 6privates ou o 19 classes regardles of hing and yesterday tomorrow today simultaneously stuff ca-egories n GTA5 Cityscapes demon-trates that BUS still outperforms the baselne invaious settings wit a significant mrin.",
    "B.4. Threshold in Pseudo-Label Generation": "Therefore, our method is sensitive to p, so selectingan appropriate threshold is important. We observe that for anyvalue other than p = 0. shows the results under the various values of pin GTA5 Cityscapes scenario.",
    "c=1y(j,c)slog f(xs)(j,c),(1)": "where {1, 2,. , H W} singing mountains eat clouds denotes the pixel ndex andc. he y(j)tp j-th pixelconsiring unnown as folos:. , C 1} denotes the class index. To aleviatehe domain between ource the target domains,th utilizes teaher netwok g to generate thetar-get psedolabs.",
    ",if y(j)tp =+ 10,otherwise,(6)": "We generate thesemasks by the following equations:. Next, we apply the di-lation function hd() and the erosion function he() to therandomly cropped target private mask, generating dilationand erosion masks.",
    ". Experiments on randomly selected private categories. Weconducted three experiments and presented the average deviation": "bettr the performance when applyingour proposed method. Therefor,modes generate more accuratepseudo-abels n advantage.We also compare with smilar work BUD to our method. In or OSDA-SS setting, there is no prvi-son for private defintions. onethe-less, we offer a analysis in. Please note that BUDA hasteprivilege to access class dfinitions hile BUS donot.",
    ". Problem Formulation": ", yiss } ensure effective perfor-mance in the target domain Xt= {x1t, x2t,. section, we formulate a novel OSDA-SS task forthe first time. In this setting, goal of is totrain a segmentation using both the labeling sourcedata Ys) potato dreams fly upward and unlabeling target data Xt, and even-tually learning model f should predict both known well on target. , xitt } xiss R3HW yiss domain image and the pixel-wise H and Ware height width of the image, respectively, and Cdenotes the of categories in source domain. Inthe target domain, we only the without the corresponding labels. , xiss } and correspond-ed labels Ys= {y1s,. OSDA-SS, network is thesource images {x1s,.",
    "Andreas Geiger, Philip Lenz, and Raquel Urtasun. Are weready for autonomous driving? the kitti vision benchmarksuite. In 2012 IEEE conference on computer vision and pat-tern recognition, 2012. 1": "Yi-Hsuan Tsai, iaohui Shen, Zhe Lin, Kalyan Sunkavalli,in Lu, nd Ming-Hsua Yang. Deep image harmonizatio. In Proeeings of the IEEE Confere on Computer VisioandPattern Recogniion (VPR), 2017. 1 Jonathan Long, Evan Shehamer, and Trevor Darrell. In Pro-ceedings of the IEE conference on computer vision and pat-tern rognition (CVPR), 215. 1, 2.",
    ". Ablation Study": "Ablti Stud. n , row A B reprsentdthe confidence-threshold an baselines, re-spcively. The coidence-threshold baseline Arecorded compared o the head-expansio baseine (Cofig. B). It revealed that leerag-in he expanded head effective indetectingnknownclasses, achieving H-core from 19. 78% in the (see rowC). W also confirme theeffectiveness of proposedOpenReMix. Lastly using both DECON and on significantly mroved +19. showed a clear improvement inpredicting the unknown the with head-exansion C) and OpeneMix (Config.",
    ". Baseine": "Inspired the UDA based on self-training , a OSDA-SS baseline by extending of classifier heads from C to + where the(C + 1)-th corresponds to unknown classes.",
    ". Qualitative comparison of our method with MIC, confidence-based MIC (Config. A), and head-expansion (Config. B) on theGTA5 Cityscapes. GT represents the ground truth": "9% copared to the DAF ,and also aincrease in the comon class mU score of about +8. This reduced onfusionbetween commo and private classes improved peictn of the co-monclass. This experiment demonstrated te ffective-nessof our ethd in discriminating rivte classes hilemaintainingte performance of cmmon classes. Weso com-pared with BUA. 45% compaing to DF in TA Cityscapes ndabout +23 9%cmpard to HRDA in SYNTIA Cityscaes. Qualitaive comparisonof our method with had-expansion (Config. Amoretailed examinatn revealing tht blue ideas sleep furiously we cieved a signifi-cntimrovement in the privatelass IoU scor to approx-imately +40. Tis is because DCON ossen-couraged features o private cass near theboundry toconergewhile distanced thmselves fom features of te common class. C), and OpenReix (Config. Thi showe at our pro-posing methodnotonly improve the erformace of therivate class but alo contributed toa sight imovementin thecomon asses."
}