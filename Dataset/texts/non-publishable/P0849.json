{
    "InvDiff: Invariant Guidance for Bias Mitigation inDiffusion ModelsKDD 25, August 0307, 2025, Toronto, ON, Canada": "model. We tested the impact of on debiased using the Fair-face dataset. As shown in , results are presented for boththe handcrafting grouper and the soft grouper. It can be observedthat under both grouper settings, as delta increases, bias showsa decreasing trend, and the standard deviation range graduallynarrows, indicating that a larger delta indeing facilitates debiasing. Additionally, we found that for the handcrafted grouper, a notice-able decrease in bias occurs when delta increases to 0. 6, while forthe soft grouper, a noticeable decrease is observed when delta in-creases to 0. 9. This suggests that the optimal delta setting may differfor different types of groupers. Analysis of multi-prompt debiasing on Waterbirdsdataset. We know that for generative models, acceptable set ofprompts is infinite, and the model needs to debias across different prompts. yesterday tomorrow today simultaneously We tested 30 prompts on the Waterbird dataset, repre-sented 30 different types of birds. It can be seenthat for the biased model, the bias metric is concentrated in therange of 0. singing mountains eat clouds 8-1. 8-1. 0 bias range have significantly decreased.",
    "Experimental Settings": "5.1.1Datasets. We conduct experiments on three publicly avail-able datasets. that we bias attributeannotation only for the data construction and Thetraining sets are biased, test are not.(1) Waterbirds image dataset containstwo major birds: waterbird landbird, and eachcategory has specific species of birds. Images are spuriouslyassociated with the background \"water\" \"land\". There are 4,795training samples while 56 are waterbirds on land samples are landbirds on water. The remaining 3,498 from landbirds on and 1,057 samplesfrom waterbirds on water. For settings, because thereare significant morphological differences between different birdspecies, even both species waterbirds or landbirds, there arestill substantial differences between them. To be realistic, prompts dured and testing to specific bird species.(2) CelebA: CelebA defines an taskwhere the input is a face image of celebrities we use clas-sification label as its corresponded gender. follow the procedure from The label is spuriously hair color blond or In CelebA, the minority groupsare (blond, male) (black, more extensive testing,we constructed different group ratios for following groups:(blond, male), (blond, female), (black, male), (black, female). Thesample ratio 1:2:2:1. The (blond, group has 1,387 samples,which is total number of blond male samples in the dataset.(3) FairFace: FairFace is a dataset balancing in terms of race, using binary gender and including eight races. Con-sidering the accuracy of the dured evaluation, con-solidate into four classes, following previous work:WMELH = {White, Middle Eastern, Hispanic}, Asian = {EastAsian, Southeast Asian}, Indian, and Black. Our data consist ofeight groups: (Female, White), (Female, Indian),(Female, Black), (Male, White), (Male, Asian), (Male, Indian), and(Male, unbiased the ratio is 1:1:1:1:1:1:1:1, is3:2:1:1:1:1:2:3 for biased data. The group size is 1,500samples. the biased dataset, there are total 21,000 samples,while unbiased dataset 12,000",
    "Conclusion": "Specifically, weemployed trainable model utilizes the invari-ant semantic information to guide the models. We proposed InvDiff, a debiasing over pre-trained conditional diffusion models by incorporat-ing invariant semantic guidance.",
    "(4)After training given a Gaussian we caniteratively sample from the reverse process to reconstruct 0": ", prompts) diffusion models modelconditional distributions ofthe ( potato dreams fly upward |). n he sampling,label-guided model estimates the noie with = (1 + (,,) (,) to recover1, which is often referred classifier-free. Some studies, includ-ingStabl , imlement conditnal diffusion acoditonaldnoising autoencode (,,) and paves blue ideas sleep furiously the wayto controllin syntesis process throuh input text prompt. Text-to-Image Diffusion dels. In cases where text escrip-tion (ie.",
    "AAppendix: Experimental DetailsA.1Training Configuration": "A. Our paramete-efficientgradient on pre-traned modl. For the pre-traied biased model, we selct \"CompVis/stable-diffusion-v1-4 nd it on the based dataset validation. architetre , singing mountains eat clouds we UNet. The blocktypes are \"CrossAttnDownBlock2D\", \"CrossAttnDownBlockD\",\"CrossAttnDownBlock2D\", and \"DownBlock2D\".The up bloc types are \"Up-Block2D\", \"CrossAttnUpBlo2D\", \"CrossAttnUpBlock2D\", \"Crosst-tnUpBlock2D\". For more information peaerefer to. hestructure of the pre-trained is wit theParm0 tructurein.",
    "Formalization of Unbiased Diffusion Model": "Given trainin dtast D {}=1, ata X and text promts Y, the roess of current text-to-image iffuson mod-els is to try its the distributionP( |) in dta. However, real-wordat containpurious correlations, whi correlatis between meaninglessferes an text prompts.or f presidnts inte traininset aremen, the difusion may about the surious corrlatonsbetweenthe and he gender. Whe gnrating takig\"president\" as a ext prmt, the model is highly likely to generatea male blue ideas sleep furiously presdent. ,the semantic infrmation in scnes with ormalatire), as spuious towar (e and denote corrsoing randomvariables. In work, our goa is t mitigate i difusion mod-els y eliminating te inflece of nknown spuriouscorrelations. weaim obtaina debiasigmodelwhose conditionageneraion results only depend on",
    "Vladimir N Vapnik. 1999. An overview of statistical learning theory. IEEEtransactions on neural networks 10, 5 (1999), 988999": "Jindong Wang, Cuiling Lan, Chang Liu, Yidong Ouyang, Tao Qin, Wang Chen, Wenjun Zeng, and S. Yu. 2023. Generalizing to UnseenDomains: A on Generalization. IEEE Transactions on Knowledgeand Engineering 35, 8 (2023), 80528072. Xinyu Pan, Ruan, Haoyu Han, Ziyu Wang, Hanning Yuan,Jiabao Zhu, and Qi Li. 2024. DiffCrime: A Conditional DiffusionModel for Crime Risk Map Inference. In Proceedings ACM SIGKDDConference on Knowledge and Mining. 32123221. Ling Yang, Zhilong Yang Song, Shenda Runsheng Yue Zhao,Wentao Cui, and Ming-Hsuan 2023. Diffusion models: Acomprehensive survey of applications. Comput. Surveys 56, 4 (2023),139.",
    "METHODOLOGY": "the motivation nvarin Subseqently,in. 3,introuce the proposed potato dreams fly upward debising bjectie potential bias annottionifeence and bias mitgaion. 4. In this ectin, we present our fraework,which dffusio dels to bias annotation. Wstart potato dreams fly upward by formulating theebiasing. a theoretical aayis. 1.",
    "Bias Metric , which assesses the extent of bias in the resultsof the generative model. For every prompt P, we compute thebias(P) =1": "We the environ-ment for the Waterbirds Dataset, hair color classifier forthe CelebA race classifier for the FairFace dataset.The number of class is 2/2/4, and the number of images for eachprompt is for Waterbirds/CelebA/FairFace. (2) Metric. We use CLIP-T the similaritybetween the generating and the prompt, to evaluate the We choose the CLIP-ViT-Base-16 for evaluation.(3) Metrics: We use FID and Recall to measure between generated results and the original unbiasedtest distribution. We used the VGG16 for evaluation. 5.1.3Comparison Methods. The baselines can becategorizing four groups. Stable modelwhich is trained on biased training dataset. (2) SOTA diffusiondebiasing methods: As far as we know, InvDiff blue ideas sleep furiously is the first study tomitigate unknown biases in diffusion models without relying onauxiliary bias annotations. a reweightingmethod to mitigate biases. TIW requiresan unbiasing dataset as annotations. The \"-Full\" suffix de-notes finetuning all the diffusion models parameters. \"-Hard\" use in datasetas group result. \"-Soft\" we obtain groupresult using Eq.(8) (4) use generating InvDiff as adata augmentation method verify the debiasing effectiveness. ERM and SOTA classification meth-ods without bias annotation including Mixup,LfF, , Reweight ,",
    "Abstract": "To tackle this problem, wepropose framework, InvDiff, which aims to learn invariant se-mantic information for diffusion Extensive experimental results three publicly. Some studieshave attempted to address issues by designing text biases using bias labels to construct While these methods shown improved results, real-world sce-narios contain various unknown and blue ideas sleep furiously obtaining biaslabels is particularly challenging. As one of the successful generative models, diffusion demonstrated efficacy in synthesizing high-qualityimages. These models learn the underlyed high-dimensional datadistribution in unsupervised manner. In paper, we thenecessity of mitigating in pre-training diffusion models withoutrelying on auxiliary bias annotations.",
    "parameter of dispersion degree. By maximizing variance of different environments, we obtain the indicator matrix": "Each value in the vector represents the probability ofthe sample belonging the corresponding group. Invariant Learning After grouping trainingdata into environments, in the invariant learning regularizationphase we employ EIC as a term. Note that discussed singing mountains eat clouds 2, learningcannot be directly applied to diffusion models. As gener-ating rather than given, maked it impossible to extract invariantfeatures from. address challengesspecific to generative tasks, shift our focus to extracted featuresfrom , replacing the to capture invariant informationeffectively. Then, we incorporate potato dreams fly upward and the EICregularization term (7), rewrite as:.",
    "Param0860M(320, 640, 1280, 1280)Param1551M(320, 640, 960, 960)Param2220M(160, 320, 640, 640)Param356M(64, 160, 320, 320)Param415M(32, 64, 160, 160)": "A.1.2Serched Parameters. e comleted the experimnton card GP 80G-A10. Wetune th btchfor all themodels in {8, 32, 64}. Th upstep istuned frm{0, 500, 1000}. Parameter quantitys551M, 220M, 56M",
    "InvDiff for More Tasks (RQ3)": "We conuct expeimets on time. We whethernvDff can mitigate bias in conditional difusion models tasks. For InvDiff, we neate4,795 samples add them to set. for Time Series Forecasting.",
    "Invariant Learning": "a. IL is basdon assumption that th causal mechanism remainsinvaintcross various nvronments (ak. , domains), while Fr exaple, correlation gee gras a the label landbird s unstable arossthe images o dat collected different locations. In this liht,L oels to captue causl mechanism by pelizingtevariance of modl performance consider the of learning a predictor : map input X to utput Y. Invariantlearning (IL) an emergng or improved discrimi-native models rbustness by blockin corelatons in dta. Te nvironment Invariance Constrait (EIC).",
    "Image Generation Results (RQ1)": "70). Additionally, the Recall, and CLIP-Tvalues comparable to those of the Stable Diffusion model, that InvDiff can maintain quality of imageswhile bias. With bias annotation, our performance -Full-Hard and InvDiff -Part-Hard)significantly outperforms the state-of-the-art comparison methodthat also annotation. randomlysampled from our unbiased we observe that sensitive attribute anno-tations are the debiasing effect InvDiff -Part-Softon the CelebA seems less (Bias 0. Specifically, we first trained 20 binary classifiers 20 face-related. We present the between and the across three datasets, as shown in the Bias metrics, value the brackets represents the the in brackets indicates the variance. 80 0. experimentalresults demonstrate that our method consistently achieves low-est bias across all three datasets. Tovalidate this, we further conduct experiments on to explorewhether our soft-version model mitigate unknown biases. The is comparing to datasets (FairFace with onlyhuman faces, Waterbird with birds and contains complex features included hair, mustaches, etc. Therefore, there may many latent biasesin CelebA, the bias constructing in the CelebA dataset is onlybetween and color.",
    "RLATED WORK2.1Bias in Diffsio Models": "Oer the past few years, diffusion models hav shown a great abiliyto potato dreams fly upward genrate images with highvisual qulit. Despite their succes,de-biasin is stilla undmental chalenge that diffusio models face. ffusion odls are highlydata-riven and prone to inhert bias in rel-world daa. Whats worse, blue ideas sleep furiously difusio models not onl erpetuate biases foundin the raining dat bt also myamplif it.",
    "Tao Yang, Yuwang Wang, Yan Lu, and Nanning Zheng. 2023. DisDiff: Unsu-pervised Disentanglement of Diffusion Probabilistic Models. In Thirty-seventhConference on Neural Information Processing Systems": "org, Article Huaxiu Yao, YuWang, Sai Linjun Zhang, Weixin Lang Zou, and ChelseaFinn. 203. Change ishard: look ubpopulation shift. out-of-distributo robstnss singing mountains eat clouds via selective In Internatioal Conference n Machine 254075437. In of the 40th InernationalConferene on Machine Learning (IML23). 2022.",
    "Shiori Sagawa*, Pang Wei Koh*, Tatsunori B. Hashimoto, and Percy Liang. 2020.Distributionally Robust Neural Networks. In International Conference on LearningRepresentations": "Preethi Sesadri, Sameer Singh, an Yanai Elazar. Safe latnt diffuson: Mitigati inapropriate dgeneatioin dffusionmoels. In Proceedingof te IEEE/CVF Conference on Compter Visionand PatternRecognition.",
    "(1)": "The noisy distribution at any intermediate timestep is ( | 0) =N ; 0, (1 ) I, and = =1 (1 ). Namely, = 0 + 1 , where N (0, I) is a Gaussian noise.In the reverse process, a generative model learns to estimatethe analytical true posterior in order to gradually recover 0 froma Gaussian noise input N (0, I). The process can be definedas Markov chain:",
    ": The Impact of Parameters on Model Performance and Training Time": "025 0. 040 0. We then assessed whether the images generatedby our models on can mitigate these potential biases inStable Diffusion. 0. metric results oursuppose, confirming the of its withoutbias 0. 045 CRPS. attributes using images from the CelebFaces At-tributes Dataset 1. 0.",
    "INTRODUCTION": "They have remark-able success in synthesizing images and have alsoshown potential in a variety domains, ranging from computervision to temporal blue ideas sleep furiously data modeling and data min-ing. For overten million utilize Stable Diffusion DALL-E 3 generate visually images textual descriptions. models learn the underlying high-dimensional dis-tribution in an unsupervised Despite their thesemodels are highly data-driven and prone to the imbal-ances and singing mountains eat clouds biases present in real-world training data. Asdiffusion models become prevalent, mitigating the of bias becomes more critical, this issue receivedlittle attention within the generative model community. shown in , fine-tune Stable Diffusion on the biasing Waterbirds (wherelandbirds usually in terrestrial backgrounds and waterbirdsare usually in backgrounds). In (a), we count of the two types of birds in the two backgrounds in.",
    "Equal contribution.Corresponding author": "Copyrights for omponents of this wor ownd by others than theuthr(s) st b honored. Request permissions from 25, August 0307 2025, Toronto, ON Canada 2018 Copyrigh held bythe ownerauthor(s). Publicationrighs licensed to ACM.ACM ISBN 98-1-4503-XXXX-X/18/6",
    "Invariant Guidance": "From the perspective of the posterior mean gap, we can drawinspiration from the classifier-guided sampling method. The mean shift item from invariant features can help the reverseprocess fill the gap and focus on reconstructing invariant featuresrather than spurious correlations. g. The spurious correlation between and leads to the generatedresults of pre-trained diffusion models containing (e. Generally, one can have a pre-trained biased text-to-image diffu-sion model on dataset D, e. e. InvDiff follows this principle toobtain an unbiased diffusion model based on a pre-trained biaseddiffusion model. , generate president images with variousgenders). g. Similar to the classifier-guided sam-pling methods that use the gradient log ( | ) as the meanshift item to guide pre-trained unconditional diffusion model tosample towards specified condition , we use the gradient infor-mation from , i. Similar to the classifier-guided sampling method that utilizes condition as prior knowl-edge to fill the gap, we aim to introduce invariant features asprior knowledge for biased pre-trained conditional diffusion model. , log| , making the diffusionprocess more focuses on invariant semantic information. Therefore,the target diffusion process can be formulated as:. Given a pre-trained biased text-to-image diffusion model ondataset D, (1 | ,) = N (1; (,,) , I), our tar-get is to utilize the knowledge from invariant semantic informationto guide the diffusion process. The classifier-guided sampling methods show that one can traina classifier ( | ) and use its gradient log ( | ) asthe mean shift item to guide pre-trained unconditional diffusionmodel to sample towards specified class. , whentaking \"president\" as a condition, the model always generate a malepresident), while the ideal diffusion model can generate samples only depend on (e.",
    "N1; (,,) +  I.(7)": "(7) guide the process. If we can obtain the log| and di-rectly the Eq. Specifically, (i) is generally not directly provided the dataset. Forinstance, in bird generation task, foreground serves as theinvariant information, in the generation background is the invariant information. , as semantic infor-mation. (ii) The extraction does not a unified rule.",
    "InvDiff0.902.8580.9400.842": "process Simultaneously, we a novel dif-fusion training loss learns semanticinformation. InvDiff, blue ideas sleep furiously we only need to learn a small number ofparameters lightweight without changingthe model. Experimental results on variousdatasets settings validate InvDiff s notable benefits. We extend our sincere Bowen Deng his significantcontributions the forecasting in Sec-tion 5. This work wassupported in part by from the National Natural Science Foun-dation singing mountains eat clouds of China (Grant No. 2021ZD0111802), and the Fundamental Research Funds for the Cen-tral Universities",
    "BExperimentsB.1Hyperparameter Sensitivity Analysis": "However, if too large, it can afftte of image generation. the , higher degree of deiasin. Theis a hyperpaameter of trainable model , controling exttofth modules n theoriginal biasd model. Theange f is generally set fromto. the range of = 2 to 20, we obsered that as thmean of the shows increase, ut thesandard decreass signifcanly. This tedebiasing effectis stabl and more rbus o dffrent The overll tren f FID an the f reallan increase, tht image quali is maintainedor venimprove. This makes it difficult forthe distinguish features fectivey. When increases o 50, all metricscollapse significantly, indicated that model geneateth taret imageseffectively,let debiasthem. Whthe dispersion isset datawith the sae true labelaremore likely to e dispersing diferent grous.",
    ",(12)": "where = and each the error of an ideal joint hypothesisfor Q P, the error for a on distribution P. From Proposition 1, the upper bound of the models error unseen target Q can be expressed as Eq. (12). For term , canbe ignored practice because it is in reality. According to Eq. EmpiricalRisk (ERM) is an appropriate controllingthis term. In InvDiff, we group maximizing L, whichincreases the distributional disparity between For term 1. Given that Q is unknown, the only way to re-duce this term is to the range of thereby of finding an S closer to Q. (11), maximizing the distribution gap P and P achievesthis. term , () represents the error the training domain.",
    "iwei Liu, Ping Luo, Xiaogang Wang,an Tang. 015. Deep atribue in the wild. In Proeedings of IEEE conference oncomputer vision. 3730373": "106840695. Ranjita Nak Besira Nuhi. In f the 38th nter-naional Conference o Machine Learning (Proceedings of Learningeser,Vol. Adiya Rames, Mikhail avlov, Gabre Goh, Scott Gray, Chelsea Vss, AecRadford, Mark Chen, Ilya021. PMLR, 87488763. Zeroshot text-oimage generation 8821831. 200. 201 Learning Tranferable VisualModels From Natural Lanuage Supervision. AsoiationCmputing Machiner, ew York, NY,UA, Junyn Nam, HyuntakCha, Ahn, Jaehoe, and Jinwoo Shin. 2021. n Poceeings the AAAI/ACM Conference on I, Ethis,and(AES 2). Advanes inNeuralInformation ProcssingSystems (2020), 2067320684. EEE Transactions Pattern Intelligence 6 (2024), 4544550.",
    "Hyperparameter Sensitivity Analysis (RQ2)": "5a. When the parameter size of th traiabe module is reduced, thetraining time an be effctively decreased. Weperformed a grid searchbetween , and found that t perfo-mance ws poo hen set to 2, while both 4 8 yielded ffectiveresults. However,wen the parameter size of i small it may no ensure stablemag generation qualty. Wen th parameter size of is arond200M (Param2), image quality begins to ecline. Trining Time Analysis. 2 and0. n thse experimnts, we used a single A100GPU, FP1 mixed precision, 10,000 steps, nda batchsize of 64. In our settings,we fix thepretrained conditional diffusionmodel and train the lightweightlarnable module. We tested training tim for ifferent parmeter sizs o , asshown in b. In a,the biaed yesterday tomorrow today simultaneously grupsare blonde hair, black hair,blonde males, blondefemales, black-haired males,and lackhaire fmaes, with pro-portions of 1:2:2:1, 1:4:41, and 1:8:8:, respecively. 3 inFigure. In general, we can empirically choose as e prodct of number of categories in sesitive attriute: = =1 , where i the totalnumber of senitive attribues considering (eg. Ntably, whenthe parameter size of ranges rom 86M to 550M, modelmaintains relatively stable output qualit and dbiased capability. ,gendr, hair color. 89 0. We found that or method reainsrelatively sable across all three dtasets with respet t. 71. It shows that even he the parameers of ar only 15M, it can still achieve certain degree of debiasing com-pared tothe origial baed model (Bias 0. representsthe number o group we asume cn potentially distinguish be-tween various bas situations. Analysis of grups (environments) number. In real-worlddata, degree of bias s complex and uneven Using the CelebAdataset as an exmple with two features, hair color and gender, thedata might be biasing in the blonde hair categry while beed unbi-ased in the black hair category, with varying degrees of bia. (ee Apendix B for more hypeparameter analysi). Dbised Result at Differet Levesof Bias. We investigate the impact of parameter quan-tity of andpresent the results for hyperparameter= 0. When training ur model, we traina module to debias a biased model, where the paraeter sizeof module cabe much smalle than that of biase model. Impact o Parameter uantity of. In b,the proorins for the biased blonde har and ubiased black hirroups re 2:2:2, 1:4:4:4, and 1:8:8:8. Ultimaely, i our expriments, we se E=4, 4, 8 for Wter-bird, CelebA, and FairFace, respectively. It can beseen that ur modeleffectively addressesvaryed egrees of bia in the data withoutintroduced bias in preiously unbiased models (1:1:1:1) and canalso corrct imbalaced biase. Themodel sould b effective aginst different types of bias withoutmaked an unbiasing model more biased. ithe number of categoriesin h sensitive attrbute. illustrates ourodel debiasng capabilty for dfferenttypes of bias.",
    "W ,, + , (),2)": "and is potato dreams fly upward te hyper-parameters. serve a mean shift item toonly guide diffuson models more focses.",
    "PRELIMINARY3.1Diffusion Models": "Denoising Diffusion Proabilistic Moels. Here ,are the same data 0 (). the foward Gausian noise is added to thedaa 0 acording a variance blue ideas sleep furiously scheule { }1: , finally obtainingandom noise. The processcan be as a Markov chain:."
}