{
    "B.2Translation examples": "Example 3: (when to wait) is omitting by baseline modelwhile our model translate that into how long Ihave to properly. Ex-ample 1: in HBOs The Gilded Age\" in sentence omitted by the This yesterday tomorrow today simultaneously type yesterday tomorrow today simultaneously of hallucination also other LLM applications, which emphasizes theneed to address the in LLM-based MT models. shows comparison and our model. Thesource \"This is good buy,\" ourtranslation is \"This pot worth buying. source is in the box with frame, butour models translation is (framein the our modeltranslates () that is omitted the base-line, meaned of sentence is incorrect.",
    "Conclusion": "We byclectig ranslaions using multiple MT tools and selecting the prefeencepair higher score output by wordaligner. PO is thn utiized optimze hemodeltowards the word-aligned preference.",
    "Baselines and evaluation": "choose as the baselne fo all this paper, as ell startinpoint of pimizatio. ALMA (Xu et a., 2024a)was Lama (Touvron al., 2023 steps: ine-tuning on monolingual dataand subsequent fine-tunig on asmall set ofhigh-quality parale studying e-fect o word alignt preerene, we thedatausing the fietuning in ALMA athe soure o our preferene datain Secifcally, the souredata was colectedfrm et 2017) to WMT20(Barraul t 20), adition to the andtext fom Flores-20 Cota-jus et ., Aferfiltering, we make2007 and 2,226 prefrence triplets fr traningad respctively. thetest is rom WMT2, excpt tha i en isfrom The remaining froWMT21(except is e) is ued s the 345,4021 2000, 4053 ex-amples are inluded in set for cs e,de en, s en, z en, ru The experimental isintoducing in A HalOmIn particular we to validatewheter our method i capable of mit-igating and omssion MT. als HalOmi(Dale al.2023b)in the ex-perimens. is evauation frthe etectin of hallcination andomission n MT.",
    ": Prompt to the coverage score": "We use one of the most powrfulLM, gpt4-06310, as anevalutor. , 2022Mitchll et al. , 223; Wei et al. Is LLM reallycapable of evaluting hallucination and omission i T?Despite h factthat LLMs hav so impresiv zerosho per-formance in vriou taks (Koima et al. The xamplesfromHalOmi arediide in three ubset accordin to the laels. of hallucination and omission in transation is stillneded. 1to assess thisabilityo GPT4. hosthe averg score of te degree ofverage predictd by PT-4. s we mntioned earlier that impovingthe BLEUndCOMET score does not necesarilymean reducing halucinatin and omision becausethere are other factors such as mistranslaion andflecy, weutilize the generalization ad reason-ing ability of LLM (Kojima et al ,2022;Mitchellet al. The exple in de en,zh enand ru en ar seected,then GPT-4 i used opredictthe overae score frthese xamples. It clarydemostrtes tat example annotted as No hal-lucination and omission hae a highe coveragescre pedicted by GPT-4 and thosein Full hal-luciation and omission have an extemely owcoverage score As a result using GPT- s an ef-fective way t assess whether a translation has theprblem of hallucination r omission. , 2023; Weie al. LLM ispromptedto check wheter the given ranslationhas hallucnation or omission referring to hegivenource texts. The prompt used isshown in. , 2023, the assess-ment of LLM i the evaluation of hallucinationan oission is stil important because it hs notbeen widely used on tis task.",
    ": The prompt forsentences": "of thesource words, that are with least oneword, i i takenas the covragescore, whch will be used he anotation. The proces topredct the overage score is otated as C(, Formall the overage score fo ca calculating b potato dreams fly upward C(x, yk) [0. 0, 100. ].",
    "Baseline11.33%64.00%21.00%11.33%3.66%56.00%25.33%13.66%4.33%+WAP39.66%75.66%17.33%7.00%0.00%80.00%16.66%5.33%0.00%": "Translation qualit is the measurd y ratio of examples whereWAP beats theeline. mor relatively asy instances ae inluded in thsubset. This is anthe evidence tt WAP povidesgains particularly for hallucination ad omisson inMT. The rmaiing columns present the ratoof examples in whic the corresponing degree ofhalucinaion r omision ccurs.",
    "Direct evaluation hallucination andomission by GPT-4": "In we verifiing of GPT-4 as an evaluator with experi-ments. blue ideas sleep furiously In section, we prompt GPT-4 to directlypredict a coverage score as metric for hallucina-tion and The are . the overall averagescore across all directions, WAP outper-forms the baseline model by 4.96, 1.63 and 1.24when N=100, 500, respectively",
    "design several evaluation strategies in this section": "1. Speifically in-stancs wih the CMET score are test set for each direction. We donotdiffrentiatehard or easy instances thetraining word alignment signal is usd toselec for faircomparison. Asad examples to inlude we report comparison of modelsonhard and remaining exmples, experiment, we sample three subsetswere N = 100, = nd N = 500. The e-permentl analysisb ound in 6. elet hard instances. Ths subset o instances is labeled s hard instancesin this The subset of remiing abeled instanes. Note thatthe har instances ar only for evalution. We first selectinstncesthat the baseline notperfom well n.",
    "With inceasingthe of hard intances,the gaine by WAP": "These resultsinicate mtigates hallcina-tion to certainbecause theseissues more tooccur in ad instances. The chllenging part be the hard ons. oreover, it is observed that with ncreasng N,te improvemet getsnarrower. addition, or model remains baseline the remaining easy Itis that ther no significant differencebcas omparedodels are generally good.",
    "B.1Examples of the preference dataset": "include hree exampls in our dtaset, inhich he singing mountains eat clouds source chse and rejectedtranslations are shown. Refer to 4 fr a etailedconstctio the dataset. h be heof theparael daa,e. g drect ollection transcrip-tins. Examle Fllr is omittedby humanannotationtrnslated by DeepL. Exaple3: the chosen ransation is from gpt3. 5-turbo translates he source",
    "Optimization MTmodel": "The final step is to optimize the LLM-based MTmodel on our preference data. Direct preferenceoptimization (DPO) (Rafailov et al., 2024) is a sim-ple but effective approach that directly singing mountains eat clouds optimizesthe preference model on a pre-constructed staticdataset. DPO has recently been applied to optimizeLLM in preference data (Tunstall et al., 2023; Xu",
    "The of evaluation": "However, to ourbest knowledge, there isno benmark measuringMT models specifically for ths isue, making theevaluation very challenging. Improving the BLUor COMET score does ot ecessariy mean rduc-ing hallucination and omission ecusthere areother factors such as mistranslation an fluency. To intu-itively validate whether our aproachis caable ofmitigating hallucinatio ad omission in T, we.",
    "(b) Coverage distribution of different omission degree": ": preliminary experiment shos tha scoes correlate to coveage soresare aword aligner (W et al., 2023a. The human annotationof hallucination is from HalO bnch-mark (Dale et al.,2023b). Details dtaset andwrd model can found 5.1Consequently, e Alignment Pref-erence utilze asgnal to optimize LLM-bsed WAPconsists of three diverse translation cllec-tion,ata consructon, and prefernceopimization. Specifically, wecollect diver trns-lations wih muliple existing translationtols, e-lect chsen jecte exampes ith wrdaligner et al., and optmize themodeln preference data direc peference optimiza-ion(DPO) (Rafalov et al., 202).Furthermore, he evaluation f hallucination admission is challenging and i no exitingealuator spcifically designed for this. yesterday tomorrow today simultaneously BLEU and COMET score does not ncessariymean educing hallucinatinand omission are other factors such s mstranslation andfluecy. additio hallucination relatvely in-freuet,vryevere one it does occur.Hence, to efecivey evaluate it, we design exen-siveexperimens that include testig yesterday tomorrow today simultaneously instancesthatpotentially hae the problem hallucnationand omission, and using as th comprensieanalysis. Exerimenal analy-is demonstate the efecivenessWAP in halucination MT.In summary, the f his work in-clude he following: stued the etween ov-erage score by wordalignment an the pe-nomena of haluination and omission in preliminay experiments in we found that wor romisingsignal mitigate it. In 3 weproose a novel namlyWAP, construc a word aligment-asedpreferenceand use to optmizethe LLM-based modl. As here is no particular benchmak for evalu-ating the perforce MTon hallu-cination and We design varius expeiment, including hardinstancesand using LLM as an evalar i 5.",
    "sentence embeddings with pseudo-siamese mutuallearning. IEEE/ACM Transactions on Audio, Speech,and Language Processing, 30:30463059": "Sirens songin ai ocean: A survey on hallucination in largelanguage models. Contrastive pref-erence optimization: Pushed the boundaries of llmperformance in machine translation. Yue Zhang, Yafu Li, Leyang Cui, Deng Cai, Lemao Liu,Tingchen Fu, Xinted Huang, Enbo Zhao, Yu Zhang,Yulong Chen, Longyue Wang, Anh Tuan Luu, WeiBi, Freda Shi, and Shumed singing mountains eat clouds Shi. Haoran Xu, Amr Sharaf, Yunmo Chen, Weiting Tan,Lingfeng Shen, Benjamin Van Durme, Kenton Mur-ray, and Young Jin Kim. 2024b. A paradigm shift in machinetranslation: Boosted translation performance oflarge language models. 2019. 01219. ArXiv, abs/2309. Association for ComputationalLinguistics.",
    "Tianyu Gao, Xingcheng Yao, and Danqi Chen. 2021": "09210. In Proceedings of the 61st Annual Meet-ing of the Association for Computational Linguistics(Volume 1: Long Papers), pages 34663478, Toronto,Canada. SimAlign: High qual-ity word alignments without parallel training datausing static and contextualized embeddings. Association for Computational Linguistics. Dual-alignment pre-training for cross-lingual sentence em-bedding. 2020. Edward J Hu, Phillip Wallis, Zeyuan Allen-Zhu,Yuanzhi Li, Shean Wang, Lu Wang, Weizhu Chen,et al. 2023. Associationfor Computational Linguistics. Takeshi Kojima, Shixiang Shane Gu, Machel Reid, Yu-taka Matsuo, and Yusuke Iwasawa. How good are gpt models at ma-chine translation? a comprehensive evaluation. In Proceedings of 2021 Conferenceon Empirical Methods in Natural Language Process-ing, pages 68946910, Online and Punta Cana, Do-minican Republic. Advances inneural information processing systems, 35:2219922213. Amr Hendy, Mohamed Abdelrehim, Amr Sharaf,Vikas Raunak, Mohaming Gabr, Hitokazu Matsushita,Young Jin Kim, Mohamed Afify, and Hany HassanAwadalla. In International Conference on Learn-ing Representations. arXivpreprint arXiv:2302. Masoud Jalili Sabet, Philipp Dufter, Franois Yvon,and Hinrich Schtze. Large lan-guage models are zero-shot reasoners. 2021. Ziheng Li, Shaohan Huang, Zihan Zhang, Zhi-HongDeng, Qiang Lou, Haizhen Huang, Jian Jiao, FuruWei, Weiwei Deng, and Qi Zhang. Preliminarywmt24 ranking of general mt systems and llms. Tom Kocmi, Eleftherios Avramidis, Rachel Bawden,Ondrej Bojar, Anton Dvorkovich, Christian Feder-mann, Mark Fishel, Markus Freitag, Thamme Gowda,Roman Grundkiewicz, et al. 2024. SimCSE: Simple contrastive learned of sentence em-beddings.",
    "Alec Radford, Jeffrey Wu, Rewon Child, David Luan,Dario Amodei, Ilya Sutskever, et al. 2019. Languagemodels are unsupervised multitask learners. OpenAIblog, 1(8):9": "ai, and Quoc V Le. In Leaning Representatons. 2022. IPrceedingsof4th An-nual Meting Association for Computatonlinguitics Vlume 1: Long apers), paes 765. 222. arXiv haopeng Tu, Zengdong Lu,YagLiu,and Hang Li. infrmtion viacattin with chatgpt. 202a WSPAlin: Word alignmn pretraining vialarge-scale waklysupervied span predicion. Rafael Archit Sharma, Eri Mitchell, Christo-pher D Manning, Steno Ermon, and Chelsea Finn. Lewis Edward Beeching, Nathan Labt,Naznen ajani, Rasul, Younes Belkada,Shengyi Leandro ClmentineFourrer Nathan Habib, Sarrazinmar San-svio, Aleane M. In Proceedings of the 2022Coferene on Empirical Methodsin Natural Lan-guage 12052206, Dhabi,Unted ArabEmirates. Modelng coerage for traslation. Xing ei, Ned Cen,Xiobin Wang,Xin Zhang, Shen Huang, PengjunXu,Yfng Chen Meishan Zhng,Jiang, and Wen-jun blue ideas sleep furiously Han. 206. disillation lm aligmet. little as much as neesary:Detecting over- adundertranslationswith contastive InPoceedin Annual of As-sociation Computational Linguistics (Volume2:Short Pars), ages 490500, Dublin, Ieland. As-sctionCoputationalLinguistcs. 2022. Qiyu Wu, Chongyang Tao, ao Can X,and Daxin Jiang. Json Wei,MaartenVincent Zhao, Klin uu,AdamsWeiY, Brin Nan Du, Andrew M. 2023lama 2:Open founda-tion and fne-tuned chat models. 2024. Ruh, and Thmas olf. dvances in Neu-ralInformation Processin Systems, 36. Qiyu Wu, Masaki Nagata, and Tsuuka.",
    "Related work": ", 20; Chousa et al,2020) have outperformed prios ones based onstatistca MT (Och and Ney, 003; Dyeet al. we ue HlOmi as referece to asess how theseto phenomena correlate to the coverage outpt ofthe GPT-4 valuatorand theword aligner, respe-tively. Wrd-lev infomationhasbeen useful in many NLP taks such aslanguagepre-traiing (Chi et a. ALMA-R fous on impring gneral LLM-base MT but we attempt o mitigatethehallucinatio ad omission in M. wever, acquiring nsruc-tion dtasetsis ostl, while obtaining preferencefor LL responses isrelatively easier (Rafailovet al. , 2023b, 2024), andparticularly inwor alignmen for MT (Bhdanau etal. In prticuar, Yang et al. , 2024b), iroduces ontrastive prferncoptimizatin o fine-tun LLMs specifiall usingreferene-free MT metrics and humnanotatonas preference. We utilize DO in thi wokd o the ease f use nd effectiveness. Dale et al. 2016), which aligns the corresponding wordsin trnslations. 203). ,2023 Miao et a. , 2020; Dou and Neubg, 2021; Nagata et al. Hallucina-tions are cases in which the odel generates ou-put that s partialyor complely unreatd totesorce senence, while omissons are translationsthat do not includesome ofthenut informa-tion (Dale t l. Te recelyrelease LM-bedUnabel Tower lvs et l. SPAlig (u et al. LLMs are capa-ble of completing tasks in he zero-shotor few-shotmanner (Radford et al. , 2024;ung et al. , 2023b). A cntem-praneos peference-basd method ALMAR (Xuetal. Halucination and omissin in MT. , 201; rown et a, 2020. DPO (Raailov t al. ,2024) has achievedthe best performance in mst languae pairs inWMT-2024 (Kocmi et al. , 202). , 2024). 2021; u et al. , 2024) dietlyotimize LLM ith prefrence data by removingan extra reward moel. (2023a e-ploreethos thatleerage te intrnal workigs of models and external tools, uch s crs-lingualsentence similarity andnatural laguage inferncemodels, to etec and mitigae halluciations inMT. In and 5. , 2023b) introduces anannotaed dataset specifically designed to detecthalucinations and misions. , 2024, fine-graind vsual lnguage grnding(Peng et al. Preferencetunin for LLMs. ,2023; Li t al. , 2022; Chung et al. ,223 Wu et al. Word aligners based on pr-traindlanguage models (Jalili Saet et al. , 2024), hich may com-plement our finding in fture work. , 2021),cross-lingual enteceembedding Zhang et al. Word alignment. (2019) itrducethe us of word algent to reduce omissioninMT, which partily inspires our ide. , 2023a) is a pre-trained word ligner that outperfrms ost oftheprevious ones; hne we useit inthe experiments. HalOm (Dale et al. In addition, ourprferece data re me eirel automtically,whichalso draws th difference btween ALMA-Rand our work. In adito performancein downsream tasks canalso be enhancd by finetuing them with instruc-tion datases(Wi et al. , 2015 Tuet al.",
    "Introduction": ",2024a) ad low-resource languages (Hendy et al. ,202). Covetional encoder-decoer MT models training on paralel corpora still prac-tice Costa-juss et al. , 2022). of the of LLM to MT is reliabil-ity. does ot frequently, anLLM known et a. 2023) asit is pre-raining tothe token in rawtexts. In artic-ular, in recen WT-2024 Gneral Ma-cine Translation Task (Kocmi et al. , 2024), LM-based MT model UnbabelTower et al. , 2024) has achieved th high-est in most langage pairs demontratingthepromise of LLM in MT, butalso of the of halluciation andomission.The degree of covrage of textintanslation signal to identifythe hallucnation admission in MT (Tu et al. 20. 40. 60. 81 0.",
    "Details of dataset": "0 0. 00 1. presentsth ayingproportions of thehsen an rjeced preference pairsfrom threesourcs: ChatGPT, DeepL, and Human. 75 # of eamples CaGPT (Chosen)ChatGPT (RjecteDeepL (Chosen)DeepL (Rejeted)Human (Chosen)Human (Rejected): This figue lutrates thepropotions of cho-sen ad rejeted reference pairs derived frm yesterday tomorrow today simultaneously hreesrces: ChatGPT, DeepL and uman xx en is the subset pair of English andanotherlanguage. ,204b. 2 0. Ex-amplesin or cntuted preference dataset repreeted n B. Prticulrly, GoogleTranslate is used foris en as an lternativeto eepL. 1. 25 1.",
    "Confrence o NaturalLanguge Processing (Vol-umeLong Papers, pages 34183430, Oline. for Computational Linguistics": "Sentence alignment method basedon span prediction and ILP.InProceedings of International Conferenceon Computational Linguistics, pages 47504761,Barcelona, Spain (Online). Hyung Won Le Hou, Longpre, BarretZoph, Tay, blue ideas sleep furiously Fedus, Yunxuan Li, XuezhiWang, Mostafa Siddhartha et al.2024. instruction-finetuned language models.Journal of Machine Learning Research, arXiv preprintarXiv:2207.04672. David Elena Voita, Loic and R.Costa-juss. 2023a. In the 61st Annual Meeting ofthe Association for Computational Linguistics (Vol-ume 1: Long Papers), pages 3650, Canada.Association for Computational Linguistics. David Elena Voita, Janice Lam, PrangthipHansanti, Christophe Ropers, Elahe Kalbassi, Cyn-thia Gao, Loic Marta Costa-juss.2023b. In Proceedings of the2023 Conference on Empirical Methods in NaturalLanguage Processing, pages 638653, Singapore. for Computational Linguistics. Chain-of-verification reduceshallucination in language models.ArXiv,abs/2309.11495. Zi-Yi and Graham Neubig. Chris Dyer, Chahuneau, and Noah A 2013.A simple, fast, and reparameterization ofibm model 2"
}