{
    "Importance of Accuracy in Topic andRhetorical Reward Models": "these epoch to thenumber f traingiterations or the The setup reains ur state-of-the-art (SOTA) model, yesterday tomorrow today simultaneously ith theoly replacing the topic oherenceor rewrdat differenttraining epocs. obsevaions indicate improed performance of both the topic andretorical potato dreams fly upward cohrence reward modes correlae withenhanced genertion performance.",
    "Introduction": "Previous studies et al. , 2019; Li and Zhao,. In two-party dialogue, response is always gen-erated for the yesterday tomorrow today simultaneously in dialogue This contrasts with multi-party dialogue, whichalways involves multiple participants and each ut-terance can be uttered by singing mountains eat clouds any and replyto any (Gu al. , 2022b).",
    "Analysis of Target Utterance Recognition": "We nalyze perfoance orrecly reog-nizing the utteranc in the dialgue historybsed on te generated respone. thstronger th coherence btwee geneatd re-sponsesand target tterance, the hiher theperformance. As in , he oldenre-sponses the performance, with of 95. 68% and 09% for Hu and demonstating strng cherence be-teen the golden response ndthetarget utterace",
    "Pairwise evaluaion rsults of GPT-4 in temsof topic cheence": "presetste pairwise results. singing mountains eat clouds ompaed to EMMDG, RL-TRC 5 and the Hu and datasets, whilelosing55 These results furthe demonstatethat or generates responses more r-vat to utternce topic, fromour topic coherence blue ideas sleep furiously ask andreward.",
    "Action": "Then,he slected cherene are fd intotheBART decoder a embedding to generatethe triggersequence k.",
    "Rt= ftcu; ut_kws], [yt; ykws]) e(n/|ykws|1(13)where is the of words in ykws that can through the coherence matrix usingut_kws": "Since Hudataset did not annotate rhetorcal relation,werecotru thedataset etal. , 2020 tocontruct th trget utterance responsepairs, then trained a relatio classifier frcwith of More details rein Appendix C We reat the divergencescore betweenfrc(ut, and fr(ut, astheretorical-coherence reward.",
    "Abstract": "Previous studieson multi-parydialogue gener-ation predominantly cncentrate on modelingthe reply-to structure of dialouehistores, al-ways overlooking the cohrence between ge-eaed responses ad trget utterances. To ad-dress this isu, ropose a einforcementLearning apprah empasizing oth Toic andRhtoricl Coherence (RLTRC). In particular,the topic- and rhetorical-coherencetsks areesgne to enhance th models pereptionof coerence with he targetutterance. Subsequently, an agentis mployed to larna co-herence policy, whc guides the generationof responses tat are toially and hetoricalyalgned wih he target utterance. he exerimentaresults ndn-depth analses on two populardatasets emonstrate that our RL-TRC inif-icantly ouerorms state-of-the-art base-lines, pariclly inenerating rsponses thatare mor coherent with the taget tterances.",
    "Multi-party Dialogu GenerationMost pre-ous studies MDG ave focuse on rep-to dialogu his-ories. Hu etl. (2019) proposed a graph struc-": "network that treated utterances as reply-to relations as edges di-alogue history. Gu et al. Li and Zhao (2023)and Gu al. Chernyavskiy al. (2024) lever-aging various fine-grained linguistic singed mountains eat clouds inputs, includ-ing Abstract Meaning Representation, discourserelations, information,to facilitate multi-party dialogue Dialogue ModelingDialogue coher-ence is primarily applied in dialogue aiming to help gen-erate responses that are consistent with the givenpersona (Chen et al. 2024).",
    "Policy": "Theacor a cohernce ak, takes appropriate action akto thecherence semantics based onthe cur-rent state sk.",
    "the target utterance, and the global reward mea-sures whether the target utterance can be recog-nized based on the generated response": "Thn, the tpic evalu-ator ft onthese and using RoBERTabase (Liu et al. More details rein A-pendix C. We reconstruct te Hu atst et al. We adopt topi evauator to evlu-ate the coherece the generating the and treat th coheenceprobability as a topic-coherene reward which isformulatedas. , 2019)achieving 84% accurac.",
    "Rhetorical Coherence Task": "Smilar to thecherence task, we feed another to te relationprediction tsk. , 201)to analyze the dialoue and identf rheoricalrelation bteen th goldn response and he Detils can be found inAppendix B. Giventhat rhetoria relations can explicitly ndenhance understandi of logicaland between utterances in multi-parydiaogues (Ashe and Lascarides weuti-lize discourse parsing toolal.",
    "Conclusion": "By tasks and rhetorical coherence,we model to perceive coherence withthe target utterance. Furthermore, a reinforcementagent is employed guide to gener-ate that are with the target To optimize theagent, three types discourse-aware rewards aredesigned to guide the to maintain coherencewith the target utterance. results val-idate the effectiveness of our method.",
    "Kennet Churc Ptrick Hanks 1990. assoc-ation rms, inormaton, and lexicogaphy.Computational linguistics, 16(1):2229": "ann Dubois,Chen Xuechen Li, Rohan Taori, TianyiZhang, Ishaan Gulrani, Jimmy B, Carlos Guestrin,Prcy SLiang, and Tatsunor Hasimoto. In Proceedingsof te 223 Conference on Empr-cal Metods in Natural anguage Proessing, ages7681692. n Proceeding ofthe 61st Annua Meeting o thessociation for Computational Linguistics (Voume1: Long Papers), pages 116411658. 2021. HeterMPC: A eteoeneous Graph eu-ral Ntwok fr Response Generaion in Multi-PartyConversatins. Avancsin Nu-ral InformaionProcessing Systes Yain Fan, Fng Jiang Peifen Li, and Haizou Li. I Pocedings of the2024Joit Intenational n-ference on Cmputatonl Linguistics, Language Re-sources and Evaluation, pages1699817010. 2022a. Unovring th otentl of ChatGPT or Dis-course Analysi in Dialoue: An Empirial Study. 2022b. Jia-Chen , Chao-Hong Tan, Caiyuan Chu, Zhen-ua Ling, Chongyang Tao, QuanLiu, and ong Liu. Who Says What to Whom:A Survey fMuiParty Converstions. MP-BERT: APe-Trained Languag Mdel for Mult-Party Con-rsati Understandng. 224. InProceedigs of heThirty-First International Jont Conference on Artifi-ial Intelligence pae 5485493. In Proceedings of the 59thAnnual Meeting ofthe Association for omuational. Jia-Chn Gu, Zhenhua ing, Quan Liu, Cog Liu, ndGuoping Hu. 2023b blue ideas sleep furiously MADNet: Maximing AddresseeDdutionExpectationfor Mlti-Pary Conversation Generation. I Procedngs of the 6t AnnualMeetin of Association for Computational Lin-guistics (Volume 1:Lon Papers), pages 585097. Jia-hen Gu, Chonyang Tao,henhuaLing, Can Xu,uo Geng, ad Dain Jiang. JaChe Gu,Congyang ao, and Zhen-Ha Lng. lpacaFar: A Siulatio Frmework for Methodsthat Learn from Human Feedback. 2024. Jia-hen Gu, ChaoHon Tan, ChongyngTao, Zhen-Hua Ling, Hung Hu, Xiubo Geng, DaxinJiang. 202aGIFT: Graph-Induced Fine-Tuning forMulti-Prty Conversation Understandig.",
    "FPairwise Evaluation with GPT-4": "To evaluate which of the responses generated bythe two models is more relevant to the target utter-ance in terms of yesterday tomorrow today simultaneously topic, we follow previous work(Zheng et al. , 2023; Dubois et al. 5. GPT-4 is instructed tocompare the outputs of two models and determinewhich one exhibited a stronger relevance with thetopic of the target utterance in the dialogue his-tory.",
    "Baselines": "We re-ran their pblicly cde and used latest versino GPT-4o204-05-13. we our methdwith the followig base-lines. EMMDG Liand Zhao, 2023): it roposes an expecttion-maximization approach that expectation steps o generateaddresee labels, and maximzation to o-timize a respnse generatio MDNet (Guet , maximizes addressee deduction ex-pectation hetergenus grapneuanetorksfor MDG. , 202): Itdirectly for MDG. , 2023b) for afair comparison. Het-rPC yesterday tomorrow today simultaneously (Gu et ,222a) it models the com-plicated itractions betweenutterances and n dalogue history with a heerogneousgrap. BAR al. Ntably, we using the same evaluation as previous et al.",
    "Dzmitry Bahdanau, KyungHyun Cho, and Yoshua Ben-gio. 2015. Neural Machine Translation By JointlyLearning To Align And Translate. In The Thrid Inter-national Conference on Learning Representations": "2023. Learning to Memorize Entailmentand Discurse Relatios fr Persoa-consistent Dia-logues. I Proceedng of AAAcnferce on artificial intelligence, volume 37, pages 265312661 Yi-Pei Chen, Norki Nihida,Hideki Nakayama, andYuji Masumoto. Recent Trends in Personal-ized Dialogue Geneatio: AReview of Datasets,Methdologies, and Evaluations. AlexaderCernyavskiy and Dmitry Ilvovsky. 2023. Trnsformer-base multi-party conversatio genera-tion used dialogue discourse acts planning.",
    "Training": "To optimize blue ideas sleep furiously ofthe agent wemaxiize the expectedcumulative reward J() = [K1 krk], whe s te parameters actor-critic network,is thedscount coeffiient, which reduces the iportnceof rwards reeived future, K the optimization steps, indcating that K actionswith one iration o otimizatio. yesterday tomorrow today simultaneously agnt isoptimizing by he followin lss:.",
    "Results": "It can be LLs-based model ChatGPT can ony achievecoparable performance to baselines, i-dicating that MDG still facs great challenges. Notably, or RL-TRC modelsignificanly improves th relevance score, gener-ating that are alined withtagetutternces. This further sbstantiaes efficayof our model. owever, methods stillsuffer from incoherence between re-sponsesand the targe utterances. Ad-ditionly, compared wit the BART model, Het-erMPC, EMMDG,and MADNet sigificantl dalgue generatio by incorportingreply-to structures. RL-TRCoutperforms all baslins of all blue ideas sleep furiously its effectieness in imprving gen-ertion quality enhancing discouse coherencebetwen generated responses and utterances. presentsthe results of the Hu datast. ables 2 and 3 present theautomatd ofour RL-TRC and baselines. We rndomly ampled200 exmplesfrom the test and recruited threecomputer science master failiar and Linux to score eac respose.",
    "EMMDG0.730.630.481.84MADNet0.730.780.502.01RL-TRC0.750.810.572.13": "Huan evaluation results of ur RL-TRC andtwo SOTA baselines yesterday tomorrow today simultaneously arandomly sampld test set ofOu5. Flu, and Inf are yesterday tomorrow today simultaneously short for Reevance, Fluecy,and respectively. (p, ui),. ,(p, n)},where piand uiare paticipant tternce, re-spectively,the modl aims target utterance ut for the enerated y,wher 1 < t n.pre-trainedmodel adopted is RoBERTa-be. The poc,batch size, learning and weight decay aresetto 3, 32, 2e-5, ad",
    "Limitations": "Despite cnduct-ingparamete-fficient fine-tuningLLMA, were not satisactory. languaemodels to gain rominence, we aim operformfull armete in the futue. 2)horical cherecdos not contribute to diaoue generation as significantly as h main reason below pr-formance o the disourse Thu,coherence singing mountains eat clouds to fcilitate dia-loge generain is challenge that to beaddessed. ) The inheent mplxity of learing algorithms can lead totendncy to get stuck in loca optia train-ing",
    "Following Li Zhao (2023) and et al.(2023b), we use BART (Lewis et al., 2020) as": "encoer. Te dialoguehistoy is fed into the en-coder in fom of ptut [SEP]pnun[SEP]pr t ob-in hidden state H where lnd arethe equence lengt and dimensio of iddenstate, and is taret ttrancemarker. We semantic rereentation oftheutteranc hi, whch is derived from utterance.",
    "Ilya Loshchilov and Frank 2018. DecoupledWeight Decay Regularization. In International Con-ference on Learning": "Hirok Ouchi and Yuta Tsuboi.2016. AddresseeanReponse Selection r uti-Party yesterday tomorrow today simultaneously Conersatin.In Proceeding the 2016 Confernce on Empir-ical Methods in atral Language Processing, pages21332143. 2021 o singing mountains eat clouds BERT Over BERforrainng Persona-based Dialoge Models from Lim-ited Persoalied Data.In Proceedings of the 59thAnnual Meing f the Associatin for omputatinalLiguistics and the 11th Interntional Joint Conference on atural Language Processing, pages 16717.",
    ": Framework of our method. The parameters ofboth decoders are shared": "The seantics are trated asaction candites for the coherence policy arefed singing mountains eat clouds into the to generate a trigger equencett the state. Th polic is byeluatin the coerece etween thehe target utterance using rwards. Ten, thetopic andrhetorical devised toenhancethe models awarenes yesterday tomorrow today simultaneously ofwit te targetutterance. encoed by a dialogue encoder.",
    "BART-based": "BART etal. , 2020)11. blue ideas sleep furiously 78. 2022a)12. 80. singing mountains eat clouds 494. 315. 393. 342. 45 5211. 73. 22. 641 311. RL-TRC (Ours)1. 66*6. 8*. 10*2. 93*6. 05) with baselines EMMDG and MADNet, and representhat we reproducing the perfrace y running e ublicly available",
    "Implementation Details": "The pre-trained model adopt the BART-base2 version. The epoch of pre-training training are to 3 and 10, respectively. Thestrategy of greedy search was adopted batch size is The optimization stepK of RL agent is set to 2, which is byusing grid search in {1, 2, 3, 4, 5}. The rewardweights wrt are set 0.5, 0.5, 1, respec-tively, which is obtained using the grid-searchin 1}",
    "p(wi)p(wj)2)": "where p(wiwj) is the co-occurrece frequencybetween wi in the olden response nd w in thetarget uteance, p(wi) and p(wj) are the frequencyof wiand wj, respectiely.For each keywrdwj in target uttrance, the wi with the top 10PMI(wi, wj) scores is adopting to construct thetopic coherence matrix. e smantics ck of the coherenc key-words is obtained bfeeding them into the dalogueencoder, where EckRkd. The, the semanics"
}