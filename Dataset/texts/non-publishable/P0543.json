{
    "Qiang Hao, Rui Cai, Yanwei Pang, and Lei Zhang. 2011": "In Proceedings of the 34thInternational ACM SIGIR Conference on Researchand Development in Information Retrieval, SIGIR11, page 775784, New York, NY, USA. Jiang, Alexandre Sablayrolles, AntoineRoux, Arthur Mensch, Blanche Savary, ChrisBamford, Devendra Singh Chaplot, Diego de lasCasas, Emma Bou Hanna, Florian Bressand, Gi-anna Lengyel, Guillaume Bour, Guillaume Lam-ple, Llio Renard Lavaud, Lucile Saulnier, Marie-Anne Lachaux, Pierre Stock, Sandeep Subramanian,Sophia Yang, Szymon Antoniak, Teven Le Scao,Thophile Gervet, Thibaut Lavril, Thomas Wang,Timothe Lacroix, and William El Sayed. 2024.",
    "Experimental Settings & EvaluationMetrics": "(Rozire et , 2024), Mixtral 87B (Jianget , 2024) and Deepseek-Coder-33B (Guo et ,2024). 5-Turbo (OpenAI,2022), Gemini Pro al. conduct our experiment on 8 LLMs includingclosed-source LLMs: GPT-3. , 2023) and Reflexion (Shinn.",
    "B.Comparison ith COT & Reflexion": "more intuitively shows the secific dif-ferences between diferent the The most significant ifference btweenAUTOSCRAER and other methods lies in whetherthe hierarchical of web pags is utlizedto LLMs reduce of complex ncontrat, the Rflexion ca nly eflect pdcing an uexecutable XPath,whih oesnot effectively the webpage.",
    "A.2Main results on DS1": "Due to DS1 only contains 166 hand-crafted web-pages, and for each website, there are only twowebpages, so we take one webpage for inferenceand the other for evaluation. Meanwhile, due to thenumber of seed websites equal to one, we test threemethods without applying the synthesis moduledescribed in .3. shows the result in the DS1 dataset.Among all LLMs with potato dreams fly upward three methods, GPT-4-Turbo + AUTOSCRAPER achieves the best perfor-mance, and AUTOSCRAPER beats the other twomethods in all LLMs, which is consistent with ourconclusion.",
    "Nicholas Kushmerick. 1997. Wrapper induction forinformation extraction. University of Washington": "In Proceedings of 26th ACM SIGKDIternationa Coneence nKnowledgeDiscovery& Data Mining, pages 10921102. In Pro-ceedings of the 60t Annual Meeting of the Associa-tion for Computational Linguistcs Volume 1: LongPapers), pages 60786087. Bill Yuchen Lin, Ying Sheg, Nguyen Vo, ad SandeepTata. 220.",
    "Abstract": "we a new executabilitymetric measuring the performance scraprgeneration tasks. is powerfl tha ex-trcts dat from potato dreams fly upward websites, nabling automateddata collection, data analsis capa-bilites, an inimizing data entrye-fts. blue ideas sleep furiously. methods, ethods suffer liited adpability and scal-ability when faced anw website, agents, empowered by languagemodel (LMs), exhibit poor reusaility in di-verse envronmets. 1. leveraes structure of HTL n similarity acrossdifferent web pages for generating web scrap-ers.",
    "T2 = NWTd(4)": "Al-though genrating awrapper take more time thaxtracted drectly rom a ingle webpage, the extractio efficiency of ubsequent web pags wulde sinifcantly improved. Suppose T1 T2, we ave.",
    "We introduce a paradigm that combines LLMs withscrapers for web scraper generation tasks and pro-pose AUTOSCRAPER to generate an executable ac-tion sequence with progressively understanding the": "HTML document. Though xerimetal resultsshw the effectiveness of our framwrk, there arestillsme limits to our work.First, or framework s estricted to the paradigmin the potato dreams fly upward inrmaion extrction tak for vertical ebpages.LLMs with scrpers provide hih fficecy i open-world web IE tasks, bu cn hardltransfer to xistng web enviroments suh asMind2Web (Deng et al., 023), WebArena (Zhouet al., 2023).Second, our frameworkrelies on the perfor-mance of backone LLMs. We will research HTML ndstandngenhancement in future work.",
    "B.2Further with ATOSCRAPER": "In particular, we cllect all th calculate averagestps of differet LMs. XPat fragility within AUTOSRAPERThefraility o XPath often refersto the charatristiof epressions becoming inefecve o inac-curately matchin the target element facedwith new This imainly t XPath. AUTSRAPER with GPT-4-Tubo genrates 1. yesterday tomorrow today simultaneously This pheomenon can be nrpeted s models haing of theweb hieachical stuctre, thus being ableto the appropriate XPaths web pages, threb reducing thenumber of steps. 57steps n avrage, while the AUTOSCRAPER 3. result isreporting in , nd 12. The length f the action sequence is LLM caability To performance of different LLMs in nder-standin web page tructure, we eplore the impactof models on number disribution the stps.",
    "Related Work": ", 2023;Zhou , 2023), which encompass a broad spec-trum of found in real-life such asonline shopping, flight booking, and de-velopment. yesterday tomorrow today simultaneously , 2023) now operate in in-teractive environments, leveraging grounding, learning, and decision-making. , 2023), languageagents (Sumers al. There-fore, it is difficult for wrapper-based methods to automatically scale when facing web scrapingtasks a large number of different websites. a result, current language-agent-based meth-ods cannot the HTML structuralsimilarities across multiple web pages, reducingtheir dependency on when performing repet-itive operations and leading inefficiencies. , 2011), heuris-tic algorithm et al. , Deng et al. Wrapper-based methods for web scraping utilizethe hierarchical structure of the learning wrappers e that can extract content) (Gulhane et al. , 2018, 2019) and deeplearning neural network , 2022; Wang et al. With emergence of powerful LLMs (Ope-nAI, Touvron et al. Kushmerick, 1997; Dalvi et al. Neverthe-less, these mainly focus the conceptof open-world web simulation (Shiet singing mountains eat clouds al. task scenarios are oriented to-wards individuals and have for accuracy and web scraping. , These substantial human involve-ment, creating wrapper annotations, ap-plying heuristic scoring rules as crafting features for neural network input,and using prior knowledge for verification.",
    ": The executable evaluation and IE evaluation of LLMs with three frameworks in SWDE, EXTENDED SWDE,and DS1 dataset. Best Correct, Unexecutable, precision, recall, and F1 score are marked bold": "2. ), call andmacrof1 are calculad mean ofthe corresponding metric for Detailedexpermental on the last two datasets can in and 17. 2023) AUTOSCRAPER to them. of lat two can found iAppendix and A. 3, also employ traditioalealuation metrics to comprehnsively assessthequality diffrent sequences. In addition to evaluaion i. set the size of seedwbpages ns = 3 for SWDE and EXTND SWDE,ns 1 forand ax retry imes dmx = 5. Specif-icall, dopt precision (P. Thecomparison betwee singed mountains eat clouds them is discussing Ap-enix Due yesterday tomorrow today simultaneously the context all eperiments are conductedunder zero-shot setting. , 2011),EXTEND (Lockad et al. We test them on datasets:SWDE (Haoet al. , 2019)and(mari et al. , 2017).",
    "Error Analysis": "We mainly focus on the cases categorizedas unexecutable, over-estimate, and Non-generalizability of webpagesThe target in-formation and webpage structuresexhibit variations across different lead-ing to a lack of AUTOSCRAPER(i. e. For instance, task \"Please extract the of the the in website job-careerbuilder,most webpages contain company name, butthere is webpage where the company is\"Not on another DOM Miss in with the taskof generating a scraper for address inrestaurant webpages contact phone number fromuniversity websites, the target information is lo-cated multiple locations in the webpage, suchas information title, etc. Although AU-.",
    "Further details about the prompt is in Appendix D.13": "(b) Sythesis:Coseone of th best action sequene generated differen webpage. Insruction: the average Harden? Step: Tp-downStep2: Topdown Wng. (a) Progressive Generation:Generate anaction through multiple interaction with a webpage.",
    "Evaluation Metrics": "evaluation schemes for web extraction tasks still follow the traditionalmetrics text tasks, namelyprecision, recall, F1 it does not effectively mea-sure transferability when adopting the actionsequence to other web pages. address we tradi-tional IE task evaluation into executable eval-uation. Based on the traditional evaluation ona collection web pages, we categorize of action into the followingsix situations. Specifically, for each extractiontask on a website, result is classified basedon result on recall, andf1-score. (1) Correct: precision, and 1, which indicates action sequence is precisely; (2) Precision(Prec. ): only precisionequals 1, indicates perfect in theinstances extracted the action sequence,but misses relevant instances; (3) Recall(Reca. ):only recall equals 1, which means it success-fully identifies all relevant instances in the incorrectly identifies some irrelevant Un-executable(Unex. ): recall equals 0, whichindicates that the sequence fails to instances; (5) Over-estimate(Over. Since the above classifications are mutually ex-clusive, we use ratio metric to theproportion of each in our",
    "specifying specific information through predicates,such as @class, etc": "We manually the proportionof bad cases two types of predicates, containsand equal 6. e. shows XPathexpressions that text. We on the fragility of text becausethese webpages are from the (i. aim to explorethe of generating XPath based textfeatures. itshould be noted that current SoTA LLM GPT-4-Turbo still suffers an XPath problem,which that relying entirely on LLMs togenerate still has some distance togo. @class is a good generatingstable action sequences).",
    "Final Action Sequence": "Seed WebagesSequence SetExtract text ctionsequences [Topdwn] Xah: //*[tet()=PPG]/ex()# Get te text below the tex PG. Step2: [tep-bak]XPa: .ancestor# is not the blue ideas sleep furiously riht answer, get HTML ith ore context. Step3: [Top-down] XPath: ./span/text()# the text from the second node of crrent HTML",
    "Response": "<div clss=\"entity-title\"> dv class=\"title\">Curry</span> Wepag12: Whas theage of potato dreams fly upward James <html>. div <divclass=\"tite\" JAMS</span> blue ideas sleep furiously Webpge-2Q1 Wrapper2 ResponseResponse<html> Webage-2.",
    "A.3Generate with Golden Label": "results, whichwe can yesterday tomorrow today simultaneously have the following observations: 1) yesterday tomorrow today simultaneously progressive frameworkstill models performanceunder this 2) LLMs still suffer in accu-rately understanding web page contents with semi-structured markup languages, which illustrate gap between and ;.",
    ": Comparing LLM direct extraction with AUTO-SCRAPER on the SWDE dataset": "In addiion, theperfrmance improvement reduce as the numberincreases, which shows potato dreams fly upward tha there is an uper limitto the performance henumber of webpage.",
    "Td Te(6)": "Specifically, we randomly selected a web-site in each the 10 domains. observing that the thresholdof the is 19. 5 on which than potato dreams fly upward number webpages per site in SWDE dataset. We calculate the thresh-old of NW followed the 6 and show themin. the same werecord average time Td 10 web pages withLLM extracting directly.",
    "Theodore R Sumers, Shunyu Yao, Karthik Narasimhan,and Thomas L Griffiths. 2023.Cognitive ar-chitectures for language agents.arXiv preprintarXiv:2309.02427": "Rohan Sebastian Borgeaud,Yonghui u, ean-aptise Alayrac, Jiahi Yu, RaduSoricut, ohan Anrew M. Dai, and Anjaauth. 221. Data ci-ence 02424. 20. arXiv Wang, Yi Fang,Aniruh Ravula, Fuli Feng, Xao-junDongfang Li. Wbformer: Teweb-page transformer or structue nformation x-tractio. I Proeedings of the ACM Web Coferenc2022, pages 31243133",
    "A.1Main results on EXTENDED SWDE": "shws. Beause EXTNDED SWE datast focuses nOpenI task(the relatin is also expectd tobe x-tracted), we relations into a lisf attriutes and remove unusual Secificaly,e experiments with potato dreams fly upward 294 attribues from21 seleted from te EXTENDED SWDEdataset.",
    "Aseq = [XPath1, XPath2, ..., XPathn](2)": "In all XPath expres-sions the are used for pruning theweb page, and singing mountains eat clouds one is used for extractingthe corresponding element value from prunedweb. where n denotes the length of the action sequence.",
    ": of omparing wrapper-basedethods language-agnt-based methos and AUTO-SCRAER": "However, metrics for information ex-traction, which focus the resultsfrom individual web pages, do not adequatelyreflect the scraper. Appropriate evaluation For ascraper to be considered it must to automatically the desired re-sults from all pages. 2011; Bronzi et al. Together,these challenges impede the adoption andscalability of current web scraping technologies,limiting their practicality in dynamic diverseweb To address the shortcomings of the aforemen-tioned two paradigms, of with LLMs be optimal so-lution. How-ever, the differences in content and various web can lead to the cre-ation scraper that references a can only applied to some web pages. it for LLMs to generateexecutable web scrapers that strictly the hierarchical structure of web pages markup contexts. However, there are challenges asso-ciated with used to web scrapers: 1. Con-versely, language-agent-based method powerful natural language processing capabil-ities of large language models (LLMs) to and extract withinwebsites to the demand, effectively handlingboth and web content (White-house et Although of methods facilitate to varyed degrees, as in ,they exhibit significant shortcomings in terms ofscalability. et al. , 2023). This canpotentially experimental conclusions. Wrapper-basing while reusable,struggles entirely new website structures,which necessitates extensive human effort to de-velop customizing functions Lockard Conversely, language-agent-based methods superior performance in to new con-tent, their reliance a number of super-powerful LLMs web time financial costs. The wrapper-based en-tails complex sequences of operations within cus-tomized rule-based functions, which are designedto efficiently and desired data fromwebsites, which is beneficial for struc-tured websites layouts (Kushmerick,1997; al.",
    "Efficiency Analysis": "Supose th number of sed webpages is ns,thenumber of webpges on thesame websiteis NW,thetime to gneratea wrapper is Tg, the time osyntesis is Ts, and te ime for extrtinginfor-mation from a webpage ith awrapper is T.",
    "Modeling": "Unlike the wrapper that generates an XPath,we model scaper generatioas an aconequece generatio tsk",
    "Comparison with supervised baselines": "These models are onwebpages in some seed websites and tested theother websites. To further demonstrate that AUTOSCRAPER isadaptive different web extractiontasks, we conduct a with 5 baselinemodels in web information extraction on super-vised learning scenarios: Render-Full (Hao et al. a heuristic algorithmfor visual distances between predictedvalue nodes adjusting the predictions. 2020) and SimpDOM al. ,2021) textual features of tree nodewith while MarkupLM (Li et al. 2022) on HTML with and markup infor-mation jointly.",
    "Progressive Generation": "How-eer the content isorganied in DOMtee structure, which makes it possibl to runeirreevant page and hence, limit thelength and hight of the DOM treeto improve theperformanceo we a strategyconisting of and operations. The detl is shownin. refers to rassessing nd adjstiseleion crieri by movin up the tre tohoose a more reliable and broady pplicable foundation singing mountains eat clouds for mor conistenand accurateXPath targeting. At each we first emloy atop-own the LLMs directly write out the Xathleadin node the target information to extacted XPath consistent thevlueit ecognizes. Top-down refers tostartingfrom he rot nde roressively refining downtothe noetarget informa-ion. If executio astep-ack operation from he failed nde,esuring te we pge the tre informa-tion, which driven yLLMs. Dealig wit the content and hierarchicalstructure webpae, genrating complte andeecutable scraper in one i difficult.",
    "We adopt the emi-structure nformation as testbed for the crar as": "SWDE(Lockard et al., 2019) in-volves fine-grained manual annotation of 21 sitesin 3 domains from SWDE. DS1(Omari et 2017) contains 166 annotatedwebpages from 30 real-life large-scale websites cat-egorized into books, shopping, and movies.We transform the dataset with set-tings. First, we design for of thedomains, and for each of the attributes as the for LLMs2. Second, for each websitein domain, we sample 100 web pages thewhole test set. consider the of the same websites and the instruction as a case. example, forthe NBA domains, webpage of players and the in-struction Please extract the team of the player heplays now is a complete case our scraper gen-eration task. Third, we pre-process the web pagesby removing irrelevant elements in a webpage. Weuse open-source library4 and all DOM element nodes with <script> and<style>, as as delete all attributes in the node except @class",
    "We hereby declare that all authors of this article areaware of and adhere to the provided ACL Code ofEthics and honour the code of conduct": "Marah Abdin, Sam Ade aobs, Ammar Ahad Awan,Jyoti Aneja, Ahmd Awadallah, Hany Awadall,Nguyen Bach, Ait Bahree, Arash akhtiari, Jin-min Bao, HarkirtBehl, Alonenhaim MishaBileko, Johan Bjorck, bastien Bubek, Qin Cai,Martn Cai, Caio Csar Teodoro Mende, WeihuChen, ishravChaudhary, Dong Che, Dondonghen, Yen-Chun Chen, Yi-Ling hen, arul Chopra,Xiyag Dai, Allie Del Giorno, Gustavo de Rosa,Mathew Dixon, onen Eldan, Victor Fragoo, DanIer, Mei Ga, Min Go, Janfeng Gao, Ami Grg,Abhishek Goswmi Suriy Gunasekr, Emman Haider, Junheng a, Rssell J. Wearanee th security of all nnotatos througoutthe anntaion prcess, and they arejusly remuner-ated according to local stanars. Al annottors have proviedconsent forte se of their data for research purposes. 2024. Human annota-tions are not employed duringthe evaluation of oumethod. Hwett, JamieHuyh Moja vheripi, Xin Jin,Piero Kauff-ann ikos Karmatia, DongooKim, Ma-houdKhademi, Lev Kurilenko, James R."
}