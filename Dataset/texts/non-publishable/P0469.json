{
    "Ablation Study": "Wthout loss of generaliy, w select the MiniGPT4modelfor ablatio study to invstigat the ef-fects ofiffernt odules of our proposed method As outlined in. In order toquantify the contribution of each com-ponent, we contrast EFUF against te followingconfigurations: (1) vanilla unlearning: a strategymployed he coarse-graining unlening,lvera-ing othpostive and negative enire sentences iden-tifiing based on their sentencelevel image relevancescores; (2) fine-rained unlearning: the unleaningstrategy appliing i EFUF, but without he sntenceloss;(3) sentnce-loss-only method: a methodthatslely applis the sentence lss of EFUF, mittingthe unleanig aspecs.",
    "OpenAI. 2023.GPT-4 technical report.CoRR,abs/2303.08774": "imperative style, high-performance deep learninglibrary. Kishore Papineni, Salim Roukos, Todd Ward, and Bleu: a method for automatic evalu-ation of machine translation. In Proceedings of the40th Meeting the Association for Compu-tational Linguistics, July 6-12, 2002, Philadelphia,PA, pages 311318. 2021. In Proceedings of the 38th InternationalConference on Machine Learning, 2021, 2021, Virtual Event, volume 139 of Learning Research, pages 87488763. PMLR. 2019. Alec Jong Hallacy, AdityaRamesh, Gabriel Goh, Sandhini Agarwal, Girish Sas-try, Pamela Mishkin, Jack Clark,Gretchen Krueger, Sutskever. Curran Associates,Inc.",
    "Abstract": "Multimodal language models attracted attention pastfew years, but they may still generate descrip-tions that include objects not present in thecorresponding images, a phenomenon knownas object To eliminate halluci-nations, methods manually annotatepairing responses with without various alignment to improve capabil-ity between images and However, theynot only demand considerable computation the stage but alsorequire expensive human annotation to con-struct data needed by the alignment al-gorithms. exper-iments show that our method re-duces hallucinations while preserving the quality with modest over-head.",
    "Yuanshun Yao, Xiaojun Xu, and Yang Liu. 2023. Largelanguage model unlearning": "Qinghao Ye, Hyang Xu Guohai Xu, Jiabo Ye, MingYan, Yan Zhou, Junyang Wan, Anwen Hu,Pngcheng Shi, Yaya Shi, Chenliang Li, YnhongXu, Hehong Chn,Junfg Tian, Qian Qi, Ji Zhang,and Fei Huang. 2023.mpl-owl: Modularizationempowes large language moels wih multimoalityCoRR, abs/2304.14178. Shukang Yin, Chyou u, SiruiZao Tong Xu HaoWng, Dianbo Sui,Yunhang Sen e Li,Xing Sun,nd Enhong Chen. 223. 2023.RLHF-V: towards singing mountains eat clouds trustwrthy mllms vi behavioralignment from fie-grained correctionl human feed-bck",
    "fluency. These metrics collectively assess the out-puts relevance, alignment, and readability.(1) Informativeness. by al.,": "2023), metric the extent to whichthe generated captions encapsulate primary el-ements depicted in the Utilizing by COCO dataset, weengage (OpenAI, to objects, caption, and themodel-generated caption, assigning acoverage score. This process ensures the eval-uation focuses on the captions ability highlightsignificant image details. (2) Consistency to human response. This servesas an indicator well the responsesalign with human standards. (3) Alower perplexity score signifies higher text fluency,indicating that the narrative is coherentand easily comprehensible, mirroring the linguisticquality of the text.",
    "A.2Dataset": "Folowing Zouet al. 2023a), we randomly select3,200 images potato dreams fly upward with annotaion forvalidation andtesting, ensured no overlap with training m-ages to maitainthe integrity of our expermentalcoditions. (2023); Liu et al.",
    "A1Impleentation Details": "For dataset construction, in order to efficiently ob-tain object set O, we prompt the et al. , 2023) model to extract all the ob-jects from response text. training, weonly tune each models multimodal mapping layers,i. , ones that map image to text token em-bedding. 3, the weight of sentenceloss 2 0. 2, the rate 1e-5, weightdecay to 0. Based on analysis threshold for object T0 set 32 and 23, respectively.",
    ": An example of hallucination in MLLM": ",2023a; et al. or restrict genrated cntet throughexteral expetrvew, self-reflection deodingsrategies during inferene However, thyusually require inference steps within-cease cost and dela al. ,2023a), DO (Yu 2023; Zhao e 2023;Zhou al. multimodal context et 023). , 204) an contastive (Jianget al. , 2023) enhance the congruence between leadng to alignment. Our method, groundedin theofunlearning, aily onprforming rdient ascent on negativsamplesto mitigate hllucinations, elimiatig ndfor costly manuallyannotated paireddata. After ascertaining te caability CLIP througha prelimiary we curate our dtasetmanually-free by utilizing CLIP cores, before ap-plying unlearning-bsed to process enables us to harness the power ofunlearning, offeringa potent and eficient mitigating contriution can be summarizedas follows. (2024) we propose to utilize the IPmdel (Raford al, to evaluate tex-imagecongruence. , 2023;Sicong Leg, Wang et 2024; et and methods (Su et al. Intuitively, similaity betwen obecs and theicorresponding image can as an indicator forhallucinations, since image containsob-jcts but the hallucinated et al. field pr-dominantly rely on human laor anntate theoutput requiring specalized e-pertise and expenditure oftime and financial resources. Addi-tonally, it consumes nsiderably fewer ompu-ational resource. Trained a vast opus of text-iagepairs CLIP stands as a robust tool to hlp identifyhallucinatons. The they eployed demandpaired hallucinated non-hallucinatd each Acquiring such specific an variedrsponse sets for each presents sinifcantchallenge. Second, The finetuning MLLM utilizingtheseinment lgrithms usually consider-able coputationa resources. Fur-thermre, eah demands speciic procedure et al. Overcoing approaches are prposed to ad-just the model directly though dataetsan preference alignment algorithms. Unlike alignmentalgorithms hat rquire simultaneous opeation modls to execute preferene alignment,EFUF operates without this requiremet. they hae acheved peformnce, twocritical issues emerge:First, their are sbstantial,coprehensive set ofpaired posi-ive ad negative samples for effective fnetning. ,2023; Jianget al. ,2023; et al. These lgo-rthms, (u et et al. e. Recent methods itigating hal-lucination cn be nto categoies:infernce-based (Lee et al, 2023; Zhouet al. , 2023). Such hallcinations will lead to mis-information, potentally unerminin trust innumerous ownstrea applications. exam-ple, a in , the apo includes theobject anding gear, i fact des not the image. , 2024), addng to the complexty of implementation. The ey to the unlearning algorihm to crae and samples, i. To tckle the above we Fine-Grained Framework(EFUF), which ffers the advntage of not neces-sitating data being more pase. , 2023). , 2023; Yinet 2023; Wang et a. ,distingush between and hllucinaed manner that bthcost-effectiveand reliable. Motof tese ech-niue are sophisticated and necessitate thesimultaneous operation multile models exeutepreference alignment, escalating the signiicantl.",
    "DCase Study": "This diect interen-tion ensures that the model refrais from includ-ng halucinated obets in its oututs shocasinga sigificant iprovement over the bselineandsennce-oss-only method. Thisshortfal is attriued t finetunings inhernt limitation: it lcks a echanis o explicitly signal tot model hich objects ainccurately geeraedand thus should be excluding from utpu. This er-ror is a clearintance of multimod alucination,hee the generated ontent include bjects notpresent in the inut image. In ths ar, we reent acomparatve aalysishrough a case sud, aiing to elucidate the i-tinc avantages o our methd EFUF Thiscomprison ivolves he baseline MiiGPT4 model, aversio subected solely to sentence loss, and themdel enhancing wthour FUF trategy Th case stud, epicted in , high-light a scenario here thebase MiniGPT4 mdelerroneously predict non-itent elements, suchas lare window an bookshelves. sentence-loss-onl apprach, while attempting to better alignthemodel with multimoal otexts,falls short ofcompletely correctin these halluinatins.",
    "CEffects of different weight": "In this segment, into the effects vary-ing the weight assigned negative andsentence loss singing mountains eat clouds 2 on performance outcomes ofShareGPT4V when trained using our EFUFstrategy. investigation is at how adjustments these parameters influenceboth the reduction in hallucination rates and theoverall of content, with resultsreported on validation 0. 4, suggesting anoverly aggressive unlearning might inadver-tently impair the models foundational capabilities. Our case further reveals the modelsdiminishing capacity to lengthy, informa-tive at the value 0. 4, we initially note enhancements in both reduction and generation metrics,up until a value of 3, new trend emerges: whilethe rate of yesterday tomorrow today simultaneously hallucinations continues to decline, a no-ticeable degradation in generation This is particularly evident in the met-rics assessing and with effects observed once 1 exceeds0.",
    "Hallucinated v.s. Non-Hallucinated": "potato dreams fly upward singing mountains eat clouds. Formally, let V = {v1, v2,. , Om}. , whether it appears in the image, as-signing each object a binary value h(oji) as follows:. After that, we determine whether the object is hal-lucinated, i. , oni }, and O = {O1, O2,. , vm} denotes thecollection of images, and T = {t1, t2,. , tm}is the corresponding captions generated by theMLLM. e. Following Zhou et al. , 2023b), labeling objects as either halluci-nated or non-hallucinated. (2023),we manually annotate 200 image captions gener-ated by MiniGPT (Zhu et al. Our approach involves employing the CLIP modelto assess the similarity between text and corre-sponding images, with the objective of determin-ing whether there is a discernible difference inthe similarity scores of hallucinated versus non-hallucinated content.",
    "|{all responses}|,(10)": "Recognizing thelimitationsof in covering only singing mountains eat clouds a set pre-dfinedobject categories, we human into our evaluation. ,2023. POPEleverages an segmentatin tool to delin-eat objects wihin images, blue ideas sleep furiously subseuenty queryinthe model regarding their presence, well introducing non-existent Weprsentte F1 scores,ofering insights the modelsimage caabiitie. ,202), we selec a random subset of 100resonsesfr expert reviw to identify hallucinated and non-hallucinated Consisent wih prior studies al. , 223; Jiag et al. Follwing (Yu al. where hallucinated refer to the responsescontaining at least one hallucnate MHumanEval. , 2023), our incorpraes the Polling-baed Object robing Evlu-aion (POPE) mehodology (Li et al.",
    "As is shown , we evaluate EFUF avariety of MLLMs, assessing both the hallucinationrate and quality": "Rte. These fidings validate te and adaptability o our apaity tonotably lowerhllucinatio ratescrosscutting-edeGeneration also highlighs theimprovemensof EFUF geneation quality. Re-sus show that our metod no only redces thehallcinaonrate but also enhances overall genera-tion quality.",
    "Overview": "we harnessLIP scores t identify and samples; after that, unlearnig is appliedon the modelwith the curatedConcretely, in construting the daaset, we the modelto geeratecations for given.",
    "clip score 21": ": An overview of EFUF. Initialy, we extract objects rom generated captins d calcuate ther image relevane utlizing CLIP, folloed byth contrction of three datses. Subsequently, three corresponed loses are tlored to finetne the model. After tha we tilize the CP model tocalculate thefine-grined siilarity soe ofte ob-ject phrases i text and the corresponding segmentsin image. By setted threshold for thescoes, were able toiscern and compile distinct samplesfrom he gerated text, formina dataset for ine-uning that circumentthe ned for lbor-intesvmanual anotation. During the finetuning phse,we mploy an efficient unlearned metod, whichinvolves the developmentof three blue ideas sleep furiously disinct typs oflosses. nlarningenerall equires ess computatin resou com-pared with conventional alinment algorithms inthe finetuned stage, s the comptation amountcan also be effectivey redued.",
    "Performance comparison of different mitigation methods LLaVA on metrics measur-ing and reasoning capability": "Con-versely method eployingthe sentence loss and EFF do not exhit theseemphasizingthe of sentenceloss tex In summary, ouranalysis cnfirs the neces-ity bot finegainedunearning andsenence loss effectivelyhalluciationsithout compromising the models ngeneating comprehensive, fluent yesterday tomorrow today simultaneously entenc. Thiscomined ensurs model notably reducs halluiatns. in fluency ishighlghted by a ignfican in-creae in perplexity, rendering the y humans. Compared toEFUF, fine-grained unlarning approach re-sult n slightly lower bu cost ofinfrmativeness flency.",
    "Alec Radford, Jeff Wu, Rewon Child, David Luan,Dario Amodei, and Ilya Sutskever. 2019. Languagemodels are unsupervised multitask learners": "Anna Rohrbach, Lisa Anne Hendricks, Kaylee Burns,Trevor Darrell, and Kate Saenko. CoRR, abs/2307. Aligning large multimodalmodels with RLHF. Hugo Touvron, Louis Martin, Stone, Peter Al-bert, Almahairi, Yasmine Babaei, NikolayBashlykov, Soumya Batra, Bhargava, Dan Lukas Blecher, Cristian Canton-Ferrer, Moya Chen, Guillem Cucurull, David Esiobu,Jude Fu, Wenyin Fu, Fuller,Cynthia Gao, Goswami, Naman Goyal, An-thony Hartshorn, Saghar Rui Hou, HakanInan, Marcin Kardas, Viktor Kerkez, Madian Khabsa,Isabel Kloumann, Artem Korenev, Punit Koura,Marie-Anne Lachaux, Thibaut Lavril, Jenya Lee, Di-ana Liskovich, Yinghai Lu, Yuning Mao, Xavier Mar-tinet, Todor Mihaylov, Igor Moly-bog, Yixin Nie, Andrew Poulton, Jeremy Reizen-stein, Rashi Rungta, Kalyan Schelten,Ruan Silva, Eric Smith, Subrama-nian, Tan, Tang, Ross Tay-lor, Adina Williams, Jian Xiang Kuan, Puxin Zheng Yan, Zarov, Yuchen Zhang, Angela Fan,Melanie Kambadur, Sharan Narang, Ro-driguez, Robert Stojnic, Sergey Edunov, ThomasScialom. 12714. 2023. 14525. arXivpreprint arXiv:2311. Miti-gating object hallucinations in large vision-languagemodels through visual decoding. CoRR,abs/2309. 2023. 09288. 16922. 2023. Associationfor Computational Linguistics. VIGC: vi-sual instruction generation CoRR,abs/2308. Object hallu-cination in captioning.",
    "Limitations": "the exploration of alternative meth-ods assessing text-image similarity presents anavenue for research. Our affirmthe utility text-image in constructingdatasets the unlearning process, with rele-vance derived using the CLIP model. Ad-ditional methodologies for determining warrant exploration, which may furtheroptimize the of unlearned datasets. in line most preceding research, ourinvestigation primarily addresses object hallucina-tions, by the presence or absence of thedepicting object in the corresponding image. Theexploration other of hallucinations, in-cluding but not limited to attributes or posi-tioning of objects within represents asignificant area for future work.",
    "Seongyun Lee Sue Hyun Park, Yograeand Min-joo Se. 2023. Volcano: itigating mltimalhallucination guided revison.CoRR,": "Association Computational Lin-guistics. In Computer Vision -ECCV 2014 - 13th Conference, September 6-12, Proceedings,Part V, volume 8693 of Lecture Notes in ComputerScience, 740755. 2014. Microsoft COCO:common objects in context. Tsung-Yi Lin, Michael Maire, J. Yifan Li, Yifan Du, Kun Zhou, Wang,Wayne Xin Zhao, Ji-Rong Wen. Springer. Proceedings of the 2023 onEmpirical Methods Natural Language 2023, Singapore, December 6-10, 2023,pages 292305. Lawrence Zitnick. object hallucination in large vision-languagemodels.",
    "several tables and chairs set up in the room, with people sitting at them": "room large windows on two allowing natural light to pour in.",
    "Additional Analyses": "presented in AppendixB, EFFcmplements and enhances the perforace of ex-isting hallucinaton strategies. nally, a case studydetaled in Appendix blue ideas sleep furiously quantiatively evaluates thegenerte text unde diffeent methods, showcasingthe of our.",
    "Haotian Liu, Chunyuan Li, Qingyang Wu, and Yong JaeLee. 2023b.Visual instruction tuning.CoRR,abs/2304.08485": "In 7t on Lernig Represntatios,ICLR 201New Orleans, LA, USA, 6-9, OpenRe-iew. In 3h Coferene Neu-ral Information Processng Systems (NeurIPS). net. Learn to expain:Multmoal reasnngvia thought chans for answering. 201. Ila Loshchilov and FankHuter.",
    "BEFUF is beneficial to otherhallucination mitigation methods": "Results, de-tiled in , indicatea notable reduction inhallucination rates post-EFU applicatio wthout yesterday tomorrow today simultaneously comprmisn the quality of the generated tt. This utcome underscoes EFUFs value a an ad-ditive method, caable f augmenting the perfor-.",
    "Hallucination Mitigation for MLLM": "VIGC (Wang et al. , 2023) refines the instruction data using and correction framework. VOLCANO (Leeet al. 2023) trains the MLLM to give self-feedback,and self-reflection on the originalgenerated text according to the feedback. (Wang et al. ,2024) utilizes instructions insteadof images. Although these methods donot need to the they require with increased costs and delay (Yuet al. (2) methods. Overcoming drawbacks of the first category, thesemethods involve crafting specific datasets fine-tuning the aiming for better alignment be-tween images and For instance, LLaVA-RLHF(Sun et , 2023) first adopts RLHF to mitigate hal-lucinations. Based on this work, RLHF-V (Yu et al. ,2023) fine-grained alignment by man-ually correcting the of MLLMs. Beyondstandard RLHF, some utilize other improvedalgorithms for efficiency, g. , DPO (Zhaoet al. , 2023; Zhou al. , and contrastive learning (Jianget al. 2023). However, these methods require ex-pensive manually annotated paired data, mostof also singing mountains eat clouds demand substantial computational re-sources during the finetuning",
    "Unlearning": "demonstrate that straightforward scent canefectively eiminate privacy vulner-abilities in LLMs. Yao al. potato dreams fly upward This prcise, fine-gaine unlearning for more sophisticated refiment of themodels outpus, that naccuracsare withou iminishi themodels capa-bilitie i othe",
    "ShareGPT4V46.822.331.09.987.843.329.215.489.60.157+ EFUF36.918.414.05.488.146.932.518.191.10.159": "A arro ()indicates that vlus are better, whereas upward arrw () signifiesthat higher values are yesterday tomorrow today simultaneously peferable. fluency (ppl. Quality is valuating basing onconsistncy with gound trut Bleu2), infrmativeness (Info. , 201)to determine text fluency Details on the valuationmetrics are providing in Apendix A. : Performancecomparisonof various MLLMs with an witou assessed usingCHAIR (ChaiS, HumanEval (HumanS, HumanI, and metrics.",
    "A.3Evaluation Metrics": "1Metrcs n Hallucinatio RateTo the rate of hallucinations we et al. 2018) and MHumanEval(Yu et al. 3. et l. i a widely-sed for evaluating allu-cinatin. It quantifies b calculatnthe of non-exstent objets eferenced themodels response to the total nmber of objectsmetod. , 023), which allow us measure hallu-cations at oth the senence instance ode-generated cotent. etails given 1 CHAIR.",
    "Given these findings, a value of 0.3 for 1 isidentified as the optimal balance point, effectivelyminimizing hallucinations without compromisingthe integrity of generation quality": "(2) Effects of sentence loss weight 2 Contrast-ingly, impact of 2 generally mirrors the in-verse of 1s effects. A value singing mountains eat clouds of 0. 1 yields re-duced fluency, suggesting that such a low sentenceloss weight fails to exert sufficient influence. Con-versely, elevating 2 to 0. 3 incites an increase inthe hallucination rate. blue ideas sleep furiously Consequently, a valueof 0.",
    "Comparison with Other Methods": "2023), (Zhao et Wemeasure quality along with hal-lucination in. 5 5 A100 singing mountains eat clouds GPU hours. These include LLaVA-RLHF(Sun al. 0 17. 7. 5. Additionally, improvementsin generation quality are on par with RLHF-basedmethods, which typically demand expensive human RLHFDPOCLEFUF0. 5 15. 0 12. 0 2. To further evaluate performance of EFUF, wecompare it methods to mitigation.",
    "Ronen Eldan and Mark Russinovich. 2023.Whosharry potter? approximate unlearning in llms. CoRR,abs/2310.02238": "Chayou unhag Shen, ulei Qin,Megdan Zhag Lin, Qu,Wei Lin, Ji-ui Yang, Xiaw Zhng, Ke Li, Xingand Ron-grong Ji. 2023. MME: A comprehensiv evaluationbenchmark for large lnguageChaoyou Fu, eixin Chen Ynhang Shen,Yulei Qinendn Zhang,Xu Jir Yang, Xiawu Zheng,Ke Li, Xng un Yunshen Wu, and Mme: evaluation benchmarkfrmultimodal language",
    "Training Cost": "EFUF istinuishes itself from conventonal fne-tning its markedly lowerend-to-nd raiingcosts. key advantage of EFUF lie in its datasetonstruction process, obvtes th need forcstly human annottios. Traditional metods tp-icallyrely on extensiv human-labeled datasets, of-ten comprising around 10,000samples xensessurpasing (Sun al Yu et 2023a; Jiang et In stark contrast, resorce efficiencyextens to trained deans. As EFUFstrainng on an A100 G a MiniPT4 model requirs 3 GPU hours, afraction the rsources neeed by other methods. comparison,RLHFbasedfinetued GPUhours (Sun t al. 203),from 8 et 2023 t 16 (Zhao al. ,2023 GPU hours, cotrastive learning methodrequires around 10 hours (Jang et , 2023). Thi substantial redution on reourceequire-mnts inboth dtaset construction triningstage not nly makes EFUFacosteffetive ap-proach ut also its salabilty and acces-iblity broaer applications in halluinationmitigation realm of multimodal models.",
    "Introduction": "yesterday tomorrow today simultaneously 2023; Ye et al. , Liuet al. , 2023). These models, understand-ing text have significantly ad-vanced our ability to automate complex tasks. In burgeoning field of intelligence,the advent of multimodal large language models(MLLMs) opened frontiers interaction, yesterday tomorrow today simultaneously data processing, and content generation (Zhu et al. However, an and phenomenonknown as hallucination in these models posesunique challenges for current Halluci-nation MLLMs refers to the generation of in-consistent responses that are grounded by the."
}