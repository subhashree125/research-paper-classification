{
    "EXPERIMENTS4.1Models": "We conduct investigations into order effect in similarity using 8LLMs - Mistral 7B6, Llama2 7B, Llama2 13B, LLama2 70B, Llama38B, Llama3 70B , GPT-3. 5 and GPT-4. For the open-sourcemodels we use their non-quantised 16 bit versions, with defaultvalues of top_p (0. The different temperature parametersused are 0. 5, 1. Note that we did not use temperature= 0, as Llama models require non-zero temperature value,unlike OpenAI models. We thus keep the lowest temperature valueto as low as possible, and avoid using temperature = 0 just for theOpenAI models. 4. 2Experiment 1 - Single pair prompts In original study the participants were asked to \"assess thedegree to which country A similar to country B\". Therefore, theequivalent prompt to this question is \"On a scale of 0 to 20, where0 means no similarity and 20 means complete similarity, assess thedegree to which {country_1} is similar to {country_2}?\". Moreover,each prompt is preceded by a system message and we assert the LLM to strictly return a number between 0 and 20 in a json format. However, apart from this prompt, we also try two other variants bychanging the language of the prompt. It is well-known that LLMoutputs, even at zero temperature, are sensitive to choice of wordsin a prompt. The three variants of single pair prompts with appropriate labelsare:.",
    "Amos Tversky and Itamar Gati. 1978. Studies of Similarity. In Cognition and Cate-gorization, Eleanor Rosch and Barbara Lloyd (Eds.). Lawrence Elbaum Associates,11978": "2022. Jason i Xuezhi Wang, Dale chuurmans, Maaren Bosma Fei Xia, Ed Chi,Quoc VLe, Deny hou, et al. Cai-of-thought promt elicits reasoningn larglaguage models. 022. Jason Wei, Yi Ta, Rishi Bommsani, Coin Rafel, Baret Zoph, SebastianBorgeaud,Dani ogatama, aarte Bosa, enny Zhou, Donald Metzler, et al. 0782(2022). arXiv prerin arXiv226.",
    "RELATED WORK": "The oter research iretion cncern with theapplication of automation and agmentaion,wherein essential that decisions and judgements by based with human and judgemes ether case, wile humans and LMs terms of response,judgemets and decisions, t is to kno whther the un-derlying mechanisms of of cocets reasoningare similar r not. was found that LLMresponses lo display pattrns, which cn furtheruned towards eithefactor using difeent techniques like RLHor Chain-of-Though Prping. ,the vaiabilit atters human judementsvariaility. Onesuch trde-off between tthfulness and helpfuless to use goalsof LM responses is sudied in. g. they were able strateges tomitigate to good xtent. In , theauthors rpeatedy prompt LLMs with the same query an studythe in t rsponse. Researh a the inrsection of cogntive science and LLM asedonchiefy two perspecives. For e. Alarge aray of work invetigat presence of differenthuma-like cognitiveinLLMs. 5-Turbo, GPT-4 Llama2Llama2 13B. It s found hattemperatre. Another important sudy of commoncogniive biases like anchoring, framinggroup atttributon in 4LLMsGPT-3. Inand , LLMs are against pular selctin and njunction and ond t ontnhman-like bias in some of he tass. This balance is ucial because,like huans, LLMs must sometimes prioritise elpulnss stricthonesy tobe effective communicators. Human udeentstyically optimise  lotof differentactor thus leading to a  trade-offs (Buned rationality). instance, an LLM ightsimplfy or appoxiate vales to aid understaning,akino humans might roud numbesin onvesation omake informtion moe comprehnible. , re-vels that whle a effective at undertanding and explainigvaribility under their isk purey ata-driven,lacking the emotional and psychologicalfactors inflencng deisions. Altough both espctives seek toknow how cloe are LLMs to humans, one line work is itersedin utilisingLMs to models and theries on  largecale by human synetc data generatedfo. In genera, it is seen that in cas wherLLM are to humans, uderlying processesofn reresntaton diffeent.",
    ": Dstriution similarity ifferences for l contrie and models for prmpt settings": "Of te 96 different settings, we find only 9 settings whereboth the are met. to , an order effct iscalculated when the meandifferce between is statistically significant( < 05 base paird The ireion beingthe ncrease similarity scr when the prominnt cunry isplaced firt inthe to our alignmnt criteia,the scores across the dual prompt stylesbesymmeric allmoes. Therefore, we can say Llama3_8Bmodel also wih human for this task. alsoplot te human similaity score differences from Tversky and Gatisstudy. thether hand, there becrtain applications e. Shoud the exhibit ordr effects in judgements, report inconsistent results to diffeent users the order ofitems in qery. be where this ligment is beneficialand certainwhereitinot. We list thet-statisticand p-valuefor each model-temperature-sinle promptstyle stting. showsthe o in scores al country pai forallmodels, temperature settins single romptstyles. Morover,it is algned or two vaues versuor GPT-4. evr argely LLMs do show significant asymmtry judgemnts. We also check the efec the corresponding version forthe same cold be due other reasons such as We n see 3 odelssymmetric scores for all the dual nd temperatur settings- Llama3 B, lama3 70B ad It is safe to asume that if qestions the oriinal studywere of style SST, the order effects would stil preent inthe simiarity judgments.",
    "Experiment 2 - Dual pair prompts": "there be particular order in the countris aepreeted,if othe immediately follows the first ordr, te conteteffect is negated. The output i ajson with two keys score_1 an score_2. Wegainse the different wordig styes n both statements.",
    "Conference17, July 2017, Washington, DC, USAUprety et al": "judgements and decisions. it can help test theories and on large scale human-like data. Secondly, it will help improve performance of LLM in real-world by making them to change contexts anduncertainty. We focus on a certain kind of judgements - similarityjudgement, underpins applications such assearch, question and recommendation. ability tojudge of stimuli, entities, etc. is in Our research question is :(RQ): How do align humans similarity judgements?We a study by Tversky and Gati , one ofseveral investigated violation symmetry human similar-ity judgements. of concepts entities is mathematicallyrepresenting distance metrics in some coordinate space. the properties of spaces is that metric distance orvector are symmetric, i. e. the of entitiesA and B is same as similarity between B and A. A large array ofwork from Amol has investigated and found thatsimilarity judgements lose their symmetric property when madeunder context-sensitive scenarios. The entities consid-ered in these studies have ranged from country-pairs to geometricfigures. the present work, use the study conducted to of pairs of countries where the created by theorder of the country pair. For e. one group participantsasked similarity of China North and anothergroup is asked to rate the similarity of North Korea and China. Ourhypothesis that will also human-like because of the change of context exhibited by changingthe order of countries in a We study different LLMs both closed-source and open-source, small and in of parameters. We utilisedifferent temperature settings and of prompts of text. human judgements, LLMs also foundto different ratings similarity based on order ofcountries in pair, however all such are model-temperature pairs which showstatistically significant order effects, discuss the implications results and discuss steps in this line of research.",
    "SSDgpt-40.5-1.9170.035Symmetric": "g. Across these factors North Koreadoesnt seemsmilar to China and thus pople give alowerscore. come consideration. Whle this intu-itive, it violatesthe symmetric propery distance-based similaritymeasures. , ncase of Noth Kore China,whenpresented this order, partcipants cnsider specific factors lkepoltical cultue, a factors wihare common both countris.",
    "ABSTRACT": "There is vast section of literature inBehavioural which in human judgements. That being said, human values anddecisions are not always straightforward and are subjectto different cognitive biases. Large Language (LLMs) have revolutionised the capabilityof models in and generating languagetext."
}