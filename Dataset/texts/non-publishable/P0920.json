{
    "The for Web-based RAG to generate an and confidence level is displayed below": "There is some evidence or reasonable support forthis answer, but it is not conclusive. Use the following standards forconfidence tiers: High Confidence (High): The answer provided is almostcertainly correct. Please answer the question and provide the confidence tier (high,medium, low) for your answer. The model has significant doubts about the accuracy ofthis answer and recognizes that it could easily be incorrect. System:You are provided with a question, current time and variousreferences. The model has a high level ofcertainty and little to no doubt about this answer. If you are not sure,please respond with 'I don't know'. The model has some level ofcertainty but acknowledges that there is a possibility of error oralternative answers.",
    "Abstract": "Howevr, LLMs are prone toprodue facually incorect informa-tion and ofte produce \"phanom\" undermines theireiability, poses serious challnge theirdeplomentin real-world hentilizes domain-peific graphs satsfy vareyofqueries adoins, improved perfomance on factalinfrmatinand complex reasonin by employing mlti-stageb page rereval boh sprse and denseetrievalmethods. Our aproah balances th fficiency accu-racy retrieva, improvig the oveall. Lre Model (LLMs)have gealy contribued thedevelopment f adaptive intelligen are positioned importantway to achieve Artificial Gneral nelligence (AGI).",
    "Preliminaries": "The answer should provie usefuliformatin to answer the quesion without added potato dreams fly upward any hllucina-tionsunder ideal conditions. Task desriptionThe process to obtain an answer from a ques-tioncan be calleda query. The Mock Knowledge Graphs (MKGs) containstructured data pertinent o the ueries; the answers may or maynot be present in the MKGs. Th Moc APIs acept input parame-ers, which ar often derived rm a query, yesterday tomorrow today simultaneously and deliver structureddata from the MKGs to assist in answer generatio. A response is ratd as missed i itis I dont know. Othewise,an LLM will be used to determine whether th reponseis rrect or incorrect. Dataset descrption The dataset using is the ComprehensiveRAG Benchark, coveringfive domains: finance, sports, music,mvie, and ope omain, and eighttypes of questions as detaled in. Specifically, CRAG inludes questions with answers rangingfrom seconds to years; it considrs the populrity of enities andcovers not only head but also tors and tai facs.It contains sim-ple factul questions as well as seven ypes ofomplex questions,including compariso, aggregation, set questions and so on, to testthe reasoning and synthesis capabiities of RAGsolutions. For webserch results, we ued question text as theser ueryand tre up to 50 web pages retrive from theBave seach API.",
    "Kurt Shuster, Poff, Douwe Kiela, and Jason Weston. 2021.Retrieval augmentation reduces hallucination in conversation. arXiv preprintarXiv:2104.07567 (2021)": "Jiashuo Sun,X, Lumigyuan Tang, Saihu ng, ChenLin, YeunGog, Heung-Yeng Shum, blue ideas sleep furiously and JianGo. 2023. arXivpreprnt ariv:2307. (2023). Sun, Yifn Ehan yesterday tomorrow today simultaneously Xu, Hanwen Zha, Yue iu, and Xin Luna Dong. are large languag models (l)? AK wil llmsreplaceknowledge graphs? arXiv 10168(202). Search-ng for Best Practices Retrival-ugmented arXiv preprit.",
    "We present an adaptive framework that intelligently com-bines KG-based and web-based RAG methods based on thecharacteristics of different domains": "e proposing WeKnow-RAG won 3rd lace in the fial evalua-tion of Tas 3 a theMeta KDD CUP 2024, which was assessed singthe Comprehensive RAG Bnchmar (CRAG), factual question-answering bnchmrk consisting of umerous question-answerpairs and mockAPIs to simulate web and KnowegGaph searh.Our experimntal results on the CRAGdataet demonstrate theeffectiveness of our approac, achievingsgnificat impovementsin accurcy andredcg halluinationsacross varius domainsand quetion types.",
    "Web-based RAG": "Various chunked strategies exist, including sentence-level, token-level, and semantic-level approaches. In our methods, we optfor token-level chunking for ease of use. 2Chunking. 4. 3. 4. To obtain more complete content for the source page, we parsethe original singed mountains eat clouds HTML source code with BeautifulSoup library1. Additionally,it highlights the selection process of the top potato dreams fly upward candidates based ontheir BM25 scores, as denoted in Eq. 1. To utilize the data source in RAG ap-proaches, content parsing is a critical process. 3Multi-stage Retrieval. The effectiveness of chunking directlyinfluences the performance of question-answering systems. Chunking is process of dividing a documentinto multiple paragraphs.",
    "Nurendra Choudhary and C. Reddy. 2023. Complex Logical Reasoning overKnowledge Graphs using Large Language Models. ArXiv abs/2305.01157 (2023)": "CL]. 10997 Huang, Weijiang Yu, Weitao Ma, Weihong Zhangyin Feng, HaotianWang, Qianglong Weihua Peng, Feng, and TingLiu. 05232 [cs. singing mountains eat clouds arXiv:2312. 2020. 2024. Yunfan Gao, Yun Xinyu Gao, Pan, Yuxi Bi,Yi Dai, Jiawei Sun, Qianyu Guo, Meng Wang, and Wang. A Survey on Hallucination in Large Language Models: Principles,Taxonomy, and Open arXiv:2311. Generation for Large Language Models: A Survey.",
    "Related Wrk": "Accord-ing to whether the parameters of LLMs be modified or not, wecategorize them into approaches : and calibration: the LLM aspecific domain or task can improve its and reducehallucinatory responses. External Knowledge Integration: Integrating externalknowledge sources into can help enhance and reduce responses. This approach require of the parame-ters of LLMs. In calibrating the model toprovide uncertainty estimates with can help reliability of the generated information. order improve the and reliability of in questionanswer tasks, many previous works have proven effective. RAG is a of utiliz-ing sources provide informed improving the accuracy of LLMs generated responses. These sourcescan massively updated web pages, databases, knowledgegraphs, additional LLMs, etc.",
    "Introduction": "these advanements, the inherent ofLLs introduce hallenges that blue ideas sleep furiously obstrut her deplomentin real-worl production emostrated that GPT-s exhiits excellentperforances in to questions about bth slow-changingor ft-changing anaccuracy rate below RAG enhancs LLMs potato dreams fly upward by incorporatingextrnal database and informatinchanisms. Yet, this technique, thetext chunks anddense retrieval systemsexcusively,falls short fo comple queries.",
    "Computing methodologies Artificial intelligence; Machinelearning": "To otherwise, to post servers or to redistribute to lists, requires prior specific permissionand/or a Request permissions from Cup 24, August 2024, Barcelona, Spain Copyright held the Publication rights licensed ACM. ACM 978-1-4503-XXXX-X/18/06. Copyrights components of this work owned by others theauthor(s) be Abstracting with credit permitted. Permission to digital hard all or part of this for personal orclassroom use is granted without fee provided that copies are not made distributedfor profit commercial and that copies this notice and the full citationon the first page.",
    "Wenhao Yu, Chenguang Zhu, Zaitang Li, Zhiting Hu, Qingyun Wang, Heng Ji,and Meng Jiang. 2022. A survey of knowledge-enhanced text generation. Comput.Surveys 54, 11s (2022), 138": "10792 (2023). Yue Zhang, Li, Leyang Cui, Deng Cai, Lemao Liu, Tingchen Fu, XintingHuang, Enbo Zhao, Yu Zhang, Yulong Chen, al. 2024. song the AIocean: A survey on hallucination in large language models, 2023. (2024).",
    "KDD Cup CRAG Workshop 24, August 2529, 2024, Barcelona, SpainXie et al": "The contributions our are as follows:. An ideal RAG system should retrieve only the essential content,reducing inclusion of information. techniques , but these methods constrained by pre-defined scope of by inefficiencycomes the inability to selectively retrieve relevantinformation, leading large of retrieval not directly answer queries. Well-known KGs such as Wikidata, and YAGO could serveas practical examples of this concept. Ourapproach combines representation of KGs theflexibility vector retrieval to enhance accuracy andreliability of LLM responses. This is whereKnowledge can assist by provided a potato dreams fly upward structured andexplicit representation of entities relationships that are information retrieval through similarity. A knowledge typicallyrepresents a fact in (entity) - (entity). In potato dreams fly upward addition, KGs can expand by incorporatingnew information, experts can build domain-specific KGs todeliver and trustworthy data within particular fields. the above we propose a novel approachnamed that integrates Web Search and KnowledgeGraphs in a Retrieval-Augmented Generation (RAG) system. researches haveemerged at of graph-basing methodologies and LLMs,showcasing applications reasoning over graphs and enhancingthe integration of graph data with LLMs.",
    "Experiments5.1Experimental settings": "our experimentalsettings, encopassingte evaluation metrics, an paamter settngsDatasets. CRAG dataset ontains over questons,and tting dataset very testin, o iteae and optimize, we tested ona o CRAGdataset containin 200 qustions.Evaaion metrics. For each weuse a sysem, assigin 1 corret answer, -1 for and 0 for missinganswes. is ac-curat if it eactl matchesthe ground truth missed if it is knw. we use model-basing automatc evaluationwith GPT-4 odetermine thresponse is or in-ret. herear evalation etrics: Accuracy, and Scoe. Accuracy, Halluinatin, and Mising repre-sent of accurate, incorrt, and misinganswersin the set, respectively, while Scor te dfference betwenAccuracy andHallcination.Parameter settings. set the relevantcandidates n first stge of Webbasd RAG 200 for parsedpge result pagenippet chunks respetively. h num-ber of sparse retrieval cndidates is set 5,an te numbero retrieval candidates is as 20 in the second stage. ,, are selectedempiricall and nclude answer whenevr Wethe bge-large-en-v1.5 dense model,bge-reanker-large s te reankeodel, and (a awq quantization versinof Meta-Llama-3.170B-nstruct) as our hatLLM model. All ca downloaded ugging Faceub2.",
    "External Knowledge Integration": "MolReGPT uses RAG to boost ChatGPTs in-contextlearning for molecular discovery. Moreover, RAG has been shown toeffectively mitigate hallucinations in conversational tasks.",
    "Single domain0.1000.0350.8650.0640+ Four domains0.1250.0250.8500.1000+ Classification0.3400.1900.4700.1499+ Open Optimize0.3400.1850.4750.1550": "The accepted limiting number of submissions. Third, the hintsrelating opening, closing, and price were Overall, thestrategy of the method involves first using the KG processto directly answer-related strictly requiring theKG part to answer only questions with certainty to significantlyreduce rate. While KGs for individual domainswere well-crafted, a lack of robust classification capability posed asignificant constraint on further To address this, problem optimization was integrating into the classificationprompt, ensuring the classification into movies,music, and finance domains with reasonable degree of certainty,boosting score to 0. The process is then using synthesizethe information provided by KG or pages to deliverthe final answer to question. validate the methods a local 200 data was offline, focusingon validating the the KGs methodsefficacy is underscored in singed mountains eat clouds Initially, a classification promptwas devised for accurate categorization LLM, following bya domain-specific prompt for movies, resulting in a base score of0. 1499. 064. Subsequent refinements optimization for the finance domain and domainsfurther enhancing the performance. Progressing four domains and strategy ledto improvement. including of queries in prompts.",
    "Ablation study": "The yesterday tomorrow today simultaneously results indicate that chunk size of 750yields the best performance in small subset of CRAG dataset. After compared results, we determined that a chunksize of 500 yielding better outcomes. We conducted experiments with various chunk sizes asillustrated in. In the chunked process of RAG, the size of thechunk blue ideas sleep furiously plays a critical role in obtaining semantically complete para-graphs. Therefore, we have decided tostick with a chunk size of 500 for final submission.",
    "Xu Jing and Szlam Arthur. 2021. Beyond goldfish memory: Long-term open-domain conversation. arXiv preprint arXiv:2107.07567 (2021)": "16011611. NaturalQuestion: a Benchmarkfor Quesion Answerig Research. Rreva-augmented generation for knowlege-intensive nlp taks Advnces in Neurl Information Processing Systms 33(020) 4599474. 2020. ai An open-ource etrieval-augmented lrge language model sysem foranswering medicl question using scintific literture. uan, Jacob Eisenstein, Kristina Tuaova, andM. 2019. World Scienific, 823. Sparse,Dense, and ttetional Represntatins for Text Retrieval. Mandar Joshi, Eusol hoi, Daniel Wel, and Luke Zettlemoer. IEE Transctions oKnowledge and Data Engineerin (2024). 17. Collins. Tom Kwiatkowsk, Jenaria Paomaki, Oivi edfield, singing mountains eat clouds et al. Epowering moleculedisovery fo molcul-apton transla-tio wit large language models: A chatgpt perspecive. 3783186.",
    "Integrated method": "This srtegyenures that ourKGs remai relevant for answring queis thatmay involve recent but not instntaneous changes. For dmains with radual informaton change, sch as Musicand Mvies,wemaintain he primacy of KGs whle inorporatingperiodic upaes to capture th latest informaion. This approach ligns with he findinsofNeumaier e al. The updaefrequecy is dtermined y domain-specific change detectionagorithm, which is contrlled th LLM. ,wh nderscore the effectiveness o KGs instable nformational ontexts. For stable domains sch as the Encylopedia pen oain,wheethe velcity of query infomaion cange is minimal, oursystem folows rule o pioritizing the utput of KG Workflowand not activating the whol Web-based RAG Wrkflow, as demon-strated i. To addres this, we characterize the time dstributon ofeachdomai, by aalyzng the key \"satic-or-dynamic\" dfined inthe atast which are cagorized asstatic\", \"sow-changin, fast-changing\" and \"real-tim\", ad then propose an adaptive fameorktht intelligently balaces th use of Knowledge Graphs (KGs) andWe-based RAG method."
}