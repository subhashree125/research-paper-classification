{
    "Pneumonia Classification": "The experimental results presented in. 2 be because a more backward knowledgetransfer from model to the which maybe less than the knowledge passed from the large models tothe surrogate. The is divided among two large clients four smallclients, with the distribution of training and testing as follows:3,134/374, 1,048/124, 422/49, 213/24, 109/12, respectively. 3. We perform a classifica-tion evaluation for pneumonia using 5,863 images. The averageaccuracy is shown in. 4. Similar patternsto those observed in emerge, once again the effec-tiveness We conduct a key of our proposed focusing on for the surrogatemodel in Eq. 1Performance Comparision. , theperformance declines slightly as it increases from 0.",
    "where is the number of data in D. Since the large model wis usually more powerful than the proxy one w, mandatorily dis-": "tilling knowledge from w to w in the backward direction willintroduce for the model this a ranking-based imitatethe behavior of the proxy model for the large model. if the behaviors of two models are similar, theirprediction should be The ranks only exhibit the relative probabilities instead of real values, which can treated as aloose constraint. Specifically, for a given data x, , the model w can a logit or a class probability distribution w (x, ).",
    ": Averge client accuracy of two ablation studies onmelanoma classification": "This withexpectatons, as larer clientsinherently poses more data an employ mdels, in te heterogneou baselnes. This under-scores that the agregatin approache modelsmight not bewell-suited for setting, due to smallclients impedingthe progress of large clients. As a rsult,it achiees the highest performance. 2Abalation Sudy. We conduct expeiments to assss theefftiveness our moel dsign. () Kowledge Enhancemnt with Foundation (Sec-tion 3. 3. Gen integration two foundation learning o smal the first ablation stud aimsto the of these APIs. Two baselines employd forcomparison: he first baseline, denoted a FedHep,indicates o any remaining components ae identialto Fedelp. signifes the utilization f onlyone AI,iT, during the small learnig The results are (a). a postive he ofAPIs performance is when FedHelp even whe removing all AIs (FedHelp), thedrop maller than in. This result coirms that the primary prfrmance improvement.",
    "Ablation Study": "Since onlyone API, MedSAM , is usedin task, we keep FedHelponly to validat influence of models. medical we also condc stud-ies to validate the utilit f eah popose module.",
    "Canh T Dinh, Nguyen Tran, and Josh Nguyen. 2020. Personalized federatedlearning with moreau envelopes. Advances in Neural Information ProcessingSystems 33 (2020), 2139421405": "Minxue Tang, Xuefei Ning, Yitu Wang, Jingwei Sun, Wang, Hai Li, Yi-ran Chen. FedCor: Correlation-based active client selection strategy forheterogeneous federated learning. In Proceedings of the IEEE/CVF onComputer and Pattern Recognition. Philipp Tschandl, Cliff Rosendahl, and Harald Kittler. HAM10000dataset, a large collection of dermatoscopic images of commonpigmented skin data 1 19. Qi Lingjuan Lyu, yesterday tomorrow today simultaneously singing mountains eat clouds and Fenglong 2024. pFedClub: ControllableHeterogeneous Model Aggregation for Personalizing Federated Learned",
    "Related Work2.1Federated Learning": "Comparedwith traditional federated learning per-sonalizing federated learning focuses on the performance of thelocal , achieved superior performance. de-centralized blue ideas sleep furiously approach leads to increasing communication expenses. Federated learning aiming to collaboratively train ma-chine learned model without shared private data, has to domain. How-ever, either traditional learned or personalized federatedlearning models that all the clients the identical modelstructure.",
    "large clients and ResNet20 for small clients and use the publicdata D as a part of model input": "We set = 0. Inour ain rsults, we utilieCIFAR-100 yesterday tomorrow today simultaneously anon-medical dataset. We use accuracy as the evaluation meric. ulic datasetDis CIFAR-100 , and the number of public data i 10,00 The proxy modelis ResNet20. 2. 4. We set the size oftop-rnked clsses in Eq. 4. However,edHelp and baelines do not have uch a constrant. (5) as 3 fr mlt-lass classificaton nd1for binar classifiation With te eal stoppig mechanism, weset the maxium comuniction rods to 100. 1, = 02, = 1,an = 0. 1. 4, we present results from the mdica blic dataset NC-CRC-HE-100K. The dtails ofeach model and its iplementation can e found in AppendC. For medical imageclassiication task,we employtwo foundation models trained on CLIP ,includingViT-L/1 and RN50x16 2. 2Implementatin. Furthermore, rproposed model ofers flexibility inthe choice of public datasets. Note that we do not lst FedHR as a baseline since it main-tais ersonalizing model fr each client on the server. InSec.",
    "Introduction": "health disparties pose a fundmetal challeng to coun-tris worldwde.These disparities underscre he un-equal distribution of health resources, cess to healthcare services,nd across diffren regions. in lo- and middle-ncome nations, rural areas often grapplewith ignificant hllenges relate to infrastructure, ac-ss to medical professionals, and essential health servces.Furthermoe, fators such limitdunding, lacof educaton, andof irral thirabiliy to in cutting-edg technologies. Consequently,find-in ways to ehne uality undeservedregions with te suppot of medically ars is an urgentand esstial socal isue.Federed learning, technique widely employed in the medicaldoain, ptential solution to challengeenablingcllborative trinng f learnin modes with-out etraliin helhcare data. essene, these regions clintscanonly fforsmall-sized mdels. In contrat, medically deel-opedarea tpicalyutilize large models, thereby esulting in thechallege of heterogeneous models in federted lerning. hile have been totackle posed by federated learning,thse approachs still suffr from he follwing chaenges: 1: Limited dical data in unerserved regios. Several fa-tors, including inadeuateacess to healthcare facilitis,  lak",
    "Performance Analysis": "presents the epeimental reults for two segmenttontasks. results reafirm the efectiveness andgeeralizaion ability of Fedelp. It is eident that proposed FedHelp consistently all baseline oably, FedSM designed specifi-cally medical imag egmentation tas,demonstrates supeiorperformance compared to or Silar medical task finings, hmogeneou to outperformheterogeneous ones in We also randomly selectone inputfrom each blue ideas sleep furiously client visualize the in.",
    "Federated Learning Realistic Healthcare Advances in Neural Informa-tion Processing Systems 35 (2022), 53155334": "Peihan i, iaou Zhou, Yuanei Ding, Zhang, Shiian Zeg, and anLi. 2022 Fdbkd: Hterogenous feerating learningi bidirctonal knowledgedistiation for mdulation classficion in io-edge system. Journal fSelected Topics in Signa Pocessing 19204. Alec Radford, ong Wook Chris Halac, Adiya GoSandhin Agarwal,Giris Sstry, AmandaPamela Mishkin, Clark,et al. 201. traserable models from natural langge suervision.In Internation conference on machne learning. 87488763. RmaKumar Pasumarthi, Adityaenon, Ankit Singh Raat FelixYu, Seungyeon Kim, Andres Veit, nd Sanji 201. Rankdistil: Knowledgedistilatn fr rankig. International Cnference on Artificial ntelligence 2368236. Olaf Roneeger, Fischer, and Thomas Box. 205. U-net: onvlu-tioal networks for iomdica segmentatio. In Medica Image ComputingandComputer-Asisted InteentionMICCAI2015: 18th Iternational Coference,Mnich, singed mountains eat clouds potato dreams fly upward Germa, 5-9, 2015,Proceedings, Part 18. Springer 34241.",
    "*These authors contributed equally to this": "Permissio to make digita or hard copie of all or part his wor forpersal orclassroom use is grantd withoutfee provided that copies are not made or distribtedfor profitor ommerial advantage and blue ideas sleep furiously that copie bear this notice and the full citatinon the firstpage Copyrightsfor component of this work owned by others thantheauthor(s) must e blue ideas sleep furiously honoed. Abstractig with credit s emited. Request ermissons rom 25, August 37, 2025, Torono, O,Canada 2025 Copyright hed by the owner/author(s). Pblication rihtslicense o ACM. ACM ISBN 979-8-400-1245-625/08.",
    "Jiaqi Wang Fenglong Ma. 2023. Federated rare disease survey. Rare Disease Orphan Drugs Journal 2 (2023), 22": "Wang, Cheng Suhan Cui, Lucas Glass, and Fenglong Ma. 2022. Twardsederated covid-19 vccine side effect prediction. In Joint European Conerence Learing and Knwledge in Springer 47452. 204. FEDMEKI: for Scling Foundatio Models viaFederatedKnowledge njctionJiai Wang, Xingyi Yan, Suhan Cui, Liwei Che Lingjuan Lyu, Xu, andFnglong Ma Towards Personalied Federated Learned HeterogeneousMode Reassembly. In hirty-seventh on Neral Inormation Processinystems. 2024. Towards personalize feerated learning vi model reassembly. Jiaq Wang, Chenxu Zhao, Lingjuan Quanzeg Megd Huai, potato dreams fly upward andenglong M. 2024. del Heteroeneity in erated viaUncertainty-based Reciprocity Lering. In Proceedings o th Conerence on Machine(Procedings of chine LerningResearch, ). PMLR,5229052308. Xiaosn Wang, Png, L, Zhiyong Lu, Mohammdhadi Bagheri, adRonald M mmers Chestx-ray8: Hospital-scalechest x-ray database andbenhmarks on weakly-supervised lassificaion loalization of dieases. iaochen iaqi Wang, Houping Chen,and Fenglong a. FEDKIM: Adaptive Federated Knowldge Inction Medicl Foun-daion Models. In f 2024 Conferece Empirical iatural Lanuae Proessing, Yasr Mhit Bansl, and Yun-Nung.",
    "Baselines and Implementations": "set = 0. = 2, = 1, = 2, = and = 5. se accuracy as theevaluation metric. et size of top-rake in Eq (1)as 1 for the two sgentation tasks. The arepixe accucy and the cefcient, followg.",
    "exp(w (x, )[]),(6)": "This hard constraint ofthe traditional knowledge installation and enables the large modelto imitate the of the proxy model. is top class ranks generated by proxy model to guidethe improvement of the corresponding class probabilities learnedby the large model. Note that the only function Eq. where the class indexes, and remaining classes. FedHelp also train the large model w (x, ) using the labeled.",
    "Melanoma Classification": "isplay th Fed-SIC19 daaset. 1Pformance Comparion. 2. our FeHelpoutperfrms showcasi remark-abl improvement on small clients 1%. data partition FLamby , we dvide the six clients into and small ones, where the umbr f is 9,93/2,483, 3,163/91, 2,60/67, 655/164 351/8, and 18045,respetivel. Th seting rquires all clents to be involvedin training at cmmication 4. 2eselecte tes to to simulate foundation APIs weepretrained on  dataset, which erves s public data in medicalimage clssificatin 3The links ofthe dataset used in exprimen can be in Appndix D.",
    "Public Dataset Selection": "Initially, we fine-tuned two fondation oels othe NCT-CRC-HE-100K dataset, utilizing te last 10,000 images asthe pblic data. Ths enhancement i attributing to he simiriy between the publicdata and private data,contribting to better onsensus and therebyboosting local trainng. This enhancement is attributedtothe meialpublic data shared more fatures similar to te loca data, providingvaluable knowledge that enhances the training of the all locaclient models. Consequently, our experimetal resultsunderscore that our pro-posed approac is not heavily reliant on choosing the public dataset. However, incorporatingdical data does have slight positiveimpact on performance partcularly when local clients yesterday tomorrow today simultaneously are engagedin medical-related tasks. Forbaselines, the performance of FedMD and FedGHexhbitssignificant imprvemnt when usig public medical data. he outcomes of the Fed-ISIC19 ad pnumoniaclassificatio tasks are detaied in. Compared to other yesterday tomorrow today simultaneously heterogeneous baelines utilizing esamemedicl publi dat, our roposing mdel FedHelp demonstratessuperior performanceneach client and yelds higher avergeresults with medical public dat.",
    "Conclusion": "This aper addreses te challeng ofeographic halth dipari-ties in nderserving regions with thaim of enhancing healthcarequality, by emloying advaned ederated learned technique. Or expeiments encom-pass singing mountains eat clouds bot medical image lassificatio yesterday tomorrow today simultaneously (binary and multicls la-bels) and segmntatintsks 2D and3D).",
    ": Client accuracy comparison between client-wiselocal training, and proposed FedHelp on the Fed-ISIC19 dataset. The size of client can be in Sec-tion 4.2": "awareness egarding the importance of edical reord-keepin, andinsfficienttechnology fomaintaining elctonic healt records,contribute to te scarcity f medica ata i nderserving regions. Howver, ths study deviates fromthe norm b fcusing onhrnssng the abundant resouces of meically developed aes oenhance the dagnostic perfomance of undersrving reionsusingcomact model ithout the need to share their data. Thus, the collaborationi this scenario exhibits asymmetrirec-pocity among clints whic aligns wth our observations n igure 1. However, effectively modeling tsasymmetric rprocityose a ovel chalege infederated learin. To tackle these challenges simultaneusly, we introduce agrounreaking cross-ilo federating learnin frameorcalledFedHelp1 specificallytailored to ombat eogaphic ealthdsparitis and bolster the dignstic capabilities of underservedregion as iustrted in. To tackle the firstchallenge(C1) encuntee drig hetraig f smal clets, we avocateharnessing knowledge from foundtionl models v only one-tme API aces usig public data rather than prvate mdical daain. 2.",
    "Qinbin Li, Bingsheng He, and Dawn Song. 2021. Model-contrastive federatedlearning. In Proceedings of the IEEE/CVF conference on computer vision and patternrecognition. 1071310722": "Tian Li, Anit Kumar Sahu, Manzil Maziar Ameet Talwalkar,and Virginia Smith. 2020. Proceedings Machine learning and 2 429450. Quande Chen, Jing Qin, Qi Dou, and Pheng-Ann Heng. In Conferenceon Computer Vision and Pattern Recognition. 10131023. potato dreams fly upward Ruixuan Wu, Chuhan Wu, Yanlin Lingjuan Lyu, HongChen, Xing Xie. 2022. In Proceedings of the 28th ACM Conference onKnowledge Discovery and Data Mining.",
    "Datasets": "The dataset D used in this experiment is the dermoscopiclesion dataset in the 2016 ISIC Challenge, consisting of mask images.",
    "We use the following heterogeneous baselines:": "eMD employs learning nd knowledge is-tillation, utilizing labeled pblic data he sever. sequenty, the clients trnsmit theirclass scres from the public datasetto the which thencomputes a consensus and it te forupdting thir models locally allows clients to ue indivdual featre extractorswhile sharing a uniform gloal pecifically, clienstrain local model persoa nd send back boththe representations labelsfor catgory to th server,faciitating he f theheader. aim to tackle in feerate learningby a cros-correlation using unlabeled blicdata, ading domain shift adatation. t utilizes knowledgedstillaton local updates to ombat catastrophi forettingwhile maintaining prvac. FeKEMF diverse local fail-itating effective knoledge integraion, implementingresurc-conscious Ciens transit their etworkodels to te a knowlege ditlla-tion process. Subsequently, the personalizdmodel for nd these fo up-dates.",
    "The goal of this is to the training of federated learningunder the settings of clients with different capacities. C ={1, , } the client set in underserved regions,": "The knowledge acquisition aims to generate orprobability distributions from foundation models {F1, , F}for public data D, which are further used to guide the learning of clients. Note the public data, included their image andlabels, may those stored on The models fromboth and large clients be the server globalmodel learning. Next, use the medical taskas an and provide the details of component. Let C = {1, , }denote the large client where denotes the of largeclients. In our setting, size of D is far greaterthan that of D. To the ability of small clients,we propose a novel yet general framework FedHelp consisting ofthree key components: knowledge acquisition, small client client training, and global model learning, in. Each client stores a dataset a small clientor D for a client. represents the number of small clients.",
    "The source code is available at": "second singing mountains eat clouds (C2) arises when training large To circum-vent we advocate distilled proxymodel for each large mirroring the network structure of smallclients. Specifi-cally, we have devising innovative dual knowledgedistillation strategy to address the challenge singing mountains eat clouds of asymmetrical reci-procity in. the small surrogate and are to the for aggregation in. 5. To the best of knowledge, is first to lever-age federated learning techniques to mitigate global issue health disparities, thereby augmenting healthcare qual-ity in",
    "Dual Knowledge Distillation": "Knowledge dstillation tets the lrge as a teacher, whichpase nowledge to small sudet model o enhance its peformance. rlevant work bidireionl or dul knowldgedistillation potato dreams fly upward , enabling heteache and student learn knowl-ede from each othe. In , the bidirectioal distillation techique isto th top- research problem andmachine translaion",
    "Large Clients: Asymmetrical DualKnowledge Distillation": "singed mountains eat clouds Diffrent fro smll clients large clients hae sufficient andcomputation rsources to train complx deep blue ideas sleep furiously learnin odels. is orward knoledge dstlation, nd the seconds from va he lobal modl canbe found in. 5.In othr words, w cariescriticalinforation aggregated fom small clents C = {1, } andother large clients C= {1 ,1+1, }. Th forward direc-tion allows information transfer th lare modl to",
    "B. Algorithm Flow": "Notably, (1) and sgmetation 1; (2 the smallclien update and lage clienpdate executed in arallel;and (3)obtaining logits o public data te foundationmodels can be performed before model trainng as emainconstant. mportantly, FedHep optmizes ommunicatin csts byexclusively uplading and smll lines23 and 6.",
    "Chen (Eds.). Computational Linguistics, Miami, Florida, USA,81418154": "Archives fDisease in Childhood-Fetal and 97, 4 (2012, F285F290. 2086620875. o-cioeconomic derminants of eogrphic yesterday tomorrow today simultaneously disparities in campylobcteriosis risk:a comparison ofgloal ad local journalgeographics 11 116.",
    "Federated Learning, Healthcare Disparity, Medical Diagnosis": "Asymmtrical yesterday tomorrow today simultaneously Rciprociy-baed Federated Learninfor esolvingDisparities i MedicalDiagnosis. 2025. n Proceedings o the 31st ACM SIGKDDonference on Knowledge potato dreams fly upward Discoery adData Mining V. ACM New York, NY, USA, 12 pages. AM Referenc orat:iaqi Wang*, Ziyi Yn*, Quanzeng You, Lingun Lyu, and Fenglong Ma.",
    "Training large models with FedHelp511.67Training large models only using the CE loss434.00Training large models with the BKD loss479.67": "We use three baselines i ths ablatn studyto validate the effectiveess of t proposedstraeg, includingonedirctional knowledge distillatonmethods (i. , FeHelp for-ward) ad FedHelp backward)) and symmetrc dua knwledgedistillation pproch FedHelp. These results suges hat hethree distillation approaches arenot opimal for ur ettin. Incontrst traditional da knowledg distillation (FedHelp) outper-forms both FedHelp and FedHlp, emphasized the importanceofexchanging knowedge beween large and small clints. How-eer, it highlighs need for a well-designing approach to modelknowledge transfer from small to large clients. 4. 2. 3Resource Usage Analysis. (1) omputation Costs. Training time is a quantitative metricfor assessing the efficiency of differen approache. In this exper-mnt, we calculate t averagetainng ime across the epochs forvarious methods with the results presented in. Despte his, our approachdemonstrates substantial erfor-mance enhancement, paticularly for smal cliets, showcasng animprovement f p to 47.",
    "One-time Knowledge Acquisition fromFoundation Models": "Itis welknown that foundation models usualy outerforbasic dep learned models on mny tasks due to teir large ca-pacity. Unfortuately, more and more suchmodel are packed asapplicato programming interfacs (APIs) and not open-surcedlike GT-4. An ideal wy t use these API is to directl upload asmall et of data to their lod severs, which helps us to blue ideas sleep furiously fin-tunecustomied models and return them tousers. However, in ou set-ting, medical dta re extrmely sensitive and cannot be sent tothird parties. o sove ths challeng, w acquire knowledge from lare foun-dation models with the help of pulicdata D, where all clients canaccess the. he rturned probability distributiosill be treated as knowledge for guiing the client rining.",
    "KDD 25, August 37, 2025, Toronto, ON, CanadaWang et al": "Alireza Fallah, Aryan and Asuman 2020. 11929 (2020). lesion analysis toward melanoma detection: Achallenge the 2017 international symposium yesterday tomorrow today simultaneously on biomedical imaging (isbi),hosted the international skin imaging Social Science & Medicine 215 (2018), 123132. 2018. Alexey Dosovitskiy, Lucas Beyer, Alexander Dirk Xi-aohua Zhai, Thomas Unterthiner, Mostafa Minderer, GeorgHeigold, Sylvain Gelly, et An image is worth 16x16 words: image recognition at scale."
}