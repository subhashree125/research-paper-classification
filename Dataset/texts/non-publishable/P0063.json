{
    "i=1ASRi[ + (1 ) SSIM(xi, xadv)],(4)": "where ASRi is the Attack Success Rate for the ith image,SSIM(xi, xadv) quantifies the structural similarity betweenthe original image xi and adversarially perturbed imagexadv, and (set to 0.5) determines the relative weightingbetween ASR and SSIM. A higher final score indicates bet-ter performance, singing mountains eat clouds as it signifies both a high success rate inmisleading the target models and a high degree of visualsimilarity preservation compared to the original images.",
    ". Dataset": "Thedataset for hse I the competition ecompasses 461 im-ages, encompassing objct su blue ideas sleep furiously as edestrian,motorcycles, lights, and road signals. For Phase II, the onsists 100 similar key objects blue ideas sleep furiously to hase",
    ". Adversarial Attack": "Adversarial attcks are classified into white-box attacks blck-bo attacks ased o the at-tackers knowldge f he model. In white-ox at-taks, the attacker has fulaccessto the target models e-tils, such as its network architcture graients. In computer vsion, adver-sarial attac methods FGSM I-FGSM ,PGD In he attck on te multiodal etal. combines visual textual bimodal informationand propose the irst white-bx Co-attack, utilized the synergistic effect betwen nd inmodel. first explores the blak-box at-tacks and use data augentation to generatmultile groupsofimages maththemwith multiple tex descriptons, andcomprehensively guidance informaionto transferabilty of adersaral exaplesinblack-boxCMI-Attack enhanesmodality in-tractionby sing Guidance modules, significty attack suc-cess trasferred adverarial xamples to othermod-el. Based on we ado CMI-Atack as he baseliemehod or our Precision Mask Perturbation Attack.",
    ". Conlusion": "Extensive that adversarial attacks significantly com-promise advanced multi-modal including GPT-4V,Qwen-VL, and imp-V1. Our first placein 2024 Challenge: Black-box Attacks on Foundation Models, setted a for attack efficacy and robustness. These find-ings underscore the critical for more robust defensesand security measures to protect vision foundation modelsagainst threats. Our work indicates downstreamtasks of vision foundation models are currently tosecurity risks. aids researchers in understandingvision models from the perspective of adversar-ial attacks, facilitating the design of more reliable,robust, and secure vision foundation models. By expos-ed vulnerabilities, we hope to encourage the devel-opment enhanced security measures and defenses, ulti-mately contributing to the deployment of autonomousdriving technologies and other applications relianton vision Qwen-vl: A frontier large vision-language model withversatile abilities.",
    ". Deceptive Text Patch Attack": "DTP-Atack furte deceives models adding text h image. This stageleverages elementst further deceive models, exploitng any weaknesses inhandling mixed content (visua textual). The main algorithmic formula for DT-Attack is rep-resented as ImgadvDT P Img + DColor, DSize),(3)where ImgadvT P theadversrial singing mountains eat clouds image ap-plying DT-Attack.",
    ". Vision Foundation Models": "It rsizesinputimages to a singing mountains eat clouds speciic splits hem into pcheswith a srid of 4, and generates set of Imps vsal module the as its pretrained visual encoder,enbling it to btain fine-grined vsual lrge-scale image-text contrastive learnin. Qwen-VLs visulencoer uses theVision VT) with pre-traindweghts Openclips blue ideas sleep furiously iT-bigG.",
    "Zhaoyu Chen, Bo Li, Shuang Wu, Kaixun Jiang, ShouhongDing, and Wenqiang Zhang. Content-based unrestricted ad-versarial attack. 2023. 2": "Goodfellow, Jonathon and Christian Szegedy. image is worth words: for image recognition at scale. BAE: adversarial examples for text classification. 11929, ad-versarial of vision-language pre-training mod-els through collaborative multimodal interaction. Mehdi Cherti, Romain singing mountains eat clouds Beaumont, Ross Wightman, MitchellWortsman, Ilharco, Cade Christoph Schuh-mann, Ludwig singing mountains eat clouds Schmidt, and Jitsev. In Pro-ceedings of the 2020 Conference on Empirical Methodsin Natural Language Processing, EMNLP 2020, Online,November 16-20, 2020, pages 61746181. Explaining and adversarial 2. arXiv preprintarXiv:2010.",
    ". Implementation Details": "ubse-uently, the captios, original images and target mask images are utilized in the CMI-Attak framework to generatethe adersarialimages romthe frst attack stage. We aso aug-mented txt y replicatig each text thre times and feedingit intothe CMI-Attack attack setting. The attack step wasset to 2/255 and the numbe o ttack steps was set to 60. Regarding t hyperparametersettings,we irst folloe the image augmentatio schemeroposed in SGA. Finay, nthe last phas, disruptive text is ddd to the images, furtherenancing attack capability against the VQA tak. Evironmen Configuraton Ou proposed method is i-plemented usig PyTorch, an experiments arecon-ducting on anNVIDA GeForce RTX 3090 GPU. First, modality singing mountains eat clouds expansion phase is condutedto obtan the capions and target mask images. Additioally, we further enhancdthe MI-Attack attck settings by applyed saling actosof [1, 1/2, 1/4, /8 1/16] to the image. Reproduction Proces. The reproductio of te attack pro-ess reires srictly yesterday tomorrow today simultaneously folowng procedures outlined in. Hyperparameter Setings.",
    ". Visualization of the impact of PG-Attack on the VQAperformance of GPT-4V, imp-V1, and Qwen-VL": "Bystrategicaly intgrating PMP-Attackouapproach ais tomaximize the attack success whilemaintanig high SIM scores addressing thecomptitions requireents and constraints.",
    "Di Jin, Zhijing Jin, Joey Tianyi Zhou, and Peter Szolovits. IsBERT really robust? A strong baseline for natural language": "attak on text lasification and entailment. AAAI Press, 2 Wei-BinQingfeng Mng Tang, Sheng Xu, ong-ug Ye, Yan Wang,Zhenyu Che, Yik-Chung Wu large model(lvm)-driven and ltent ature-asing persnalzing federatedeaed in driving, 024. 1 Kuraki, J. Goodfellow, and Samy Benio. Ad-versarial macie learning scae. Intentional Con-ference on Learning Repesentations, ICLR 2017, Toulo,France, Ap 24-26, 2017, Track Jnnan i, Dongx aiming Xiong C. H. Hoi. BLIP: bttapping languge-iag pre-trainig vision-language undrstaning andIn I-trnational Conferece on Machine Learnin, ICML202,17-23 Jly 2022 Maryland, USA, ages12812900. 4 Linyang Li, Ruotian Ma,Qipeg Guo, Xiangyang Xue, andXipeng Qu In oceeded blue ideas sleep furiously 2020 Confreneon Methods i Natura Language Processing,EMNLP 220, Online, 16-20, 02, pags Association for Linguistics, 2 Yane Li Wenhua Zhang, Kai Chen,PegxiangL, Ruiyan Lnqng ong, Men Tian, Xinhai Zhao,Zhenguo Dit-Yan Yeung,Huhuan Lu, and 2024.",
    ". Precision Mask Perturbation Attack": "Tis involes combning the CI-Attack with mak patchmehod. The CMI-Attack nhances the overal effc-tiveness an obustessof the attack by ensuring the pertur-ations are subtle yet imactfl.The mask ach method,onthe other hand, targets speciic areas of the imae t im-pove the attacs prcision and focus.The original CMI-Attack ramewor incorrates text-based attack; owevr, sincethe yesterday tomorrow today simultaneously competition doesnot in-volve text attacks, we have modied the optiizaio objcive ofCMI-Atack. The ovral otimization goal o urfraework is to maximize the semantic distance betweenthe advrsrial image IgAdv genrated by te sourcemodlin the feaure spaceof the iageencoder EI an thecaption in thefeature space of the ext encodr ET . This iormally representing blue ideas sleep furiously y Equati 1:",
    "The main contributions of this paper can be summarizedas follows:": "By maskd patch with adesarial atacks, PP-Attack, a novel attack method that enablesprecis localization of attak regions while balanced attackeffectiveness wi structural between pre-and pos-attac images. We inovativelyintroduce Text Patch Attack(DTP-Attack). DTP-Attack complementsPM-Atack, disrupted themodels sceneunderstandingand furtherenhancing he efficacy. ur xprimnts that decivesa vity of muli-modal including GPT-4V Qwen-VL, and imp-V1.",
    "Zhenwei Shao, Zhou Yu, Jun Yu, Xuecheng Ouyang, LihaoZheng, Zhenbiao Gai, Mingyang Wang, and Jiajun Ding.Imp: Highly capable large multimodal models for mobiledevices, 2024. 2": "aXipreprint arXiv:2303. In IEEE/CVFInera-tional Conferenc Computer Vision, ICCV 2023, October 1-6, 2023,pages 43894400 IEEE, 2023. arXiv preprint arXiv:231. 2 Jiaming Zhang, Qi Yi, and Jitao Towards attack In MM22: The 30th ACM ntrnatioa Conferenceon Multime-di, Lisboa, Portl, October 14, 2022, 005013. CM, 2022. 2 in Kun Zhou, Junyi Li,ng, XiaoleiWang, Hou Yingqian Zhang, JunjieZhang, Zican Dong, eta. Aide: A multi-moda, dataset or assistive perceptin. 2023. 2. of the IEEE/CVF Interntional Conferenceon Computer Vion, 2023. On the road with gpt-4v (ision):Earlyexplorations of visual-languagemodel autonomoudrivn. Jinyu Jiali uan, Son Tran, Xu, Chen, Belinda Zeng, Trishul Chilimi,and JunzhouHuang Vision-langage pre-trainingwithtriple In IEEE/CVF on Computer ision Recogniion VPR 2022, Oran, LA, USA,June 2022, pages165015659. Boostin the transfability of global momentum iitialization. 1 Dingkang Sai Zh Xu, Shunliang, Li, Wang, Yan Liu,Kun Yag,Zaoyu Chn, et al. In Proceedings of he Cofrenceo Comuter Vision, paes 2045920470, 202. 18223, 023. Jifeng Wang, Chn, Jiang, inkang Pinxue Guo Haijing Guo,ad WenqiangZhang.",
    ". The Impact of Disruptive Text Quantity": "image. The incorporation of textual into the adversar-ial attack expands yesterday tomorrow today simultaneously the attack and com-plexity of the singing mountains eat clouds deception, making it more challenging for themodel discern and manipulated content.",
    "Liu, Shiyu Xuekai Liu, Lulu Guo, Hang,and Jian Sun.A decision-making gpt model augmentedwith for autonomous arXivpreprint arXiv:2406.13908, 2024. 1": "In InternationalConference on Learned Representations, ICLR 2018, BC, Canada, April - May 3, ConferenceTrack Proceedings. 2. guidance Boosting adversarial transferability of vision-languagepre-trained models."
}