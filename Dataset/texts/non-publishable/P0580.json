{
    "Tok08213371651645962": ": QA where th best results boldfaced and the second-best esults areunderlied, in each row. Tok th average lengt of evidence fed into geneatos, where smaller thevalue, the cmputatonl 01 accordin to t-test.",
    "We use ALIGNSCORE-large for faithfulness assessment": "In words, it checkswhether the extracted e contributes tothe models output improvement when utilizedas input. Specifically, we assess its potentialinfluence by the changein the log probability of generating goldenanswer a models output andafter the of the extracted e:.",
    ": The prompt for full-length answer generation": "ex-erimenal results that: (1) generaonstability of te aligning model is muchbetter thanthat of te base n nmost cases Moreprecisely,the average impovementof model oerthebase one the three datets is 18.5%. (2The geration stability i ters ofhelpfulness asseen gater imprveent to two propertis i.e.,faithfuness conciseness),with an of 2.2%, shwingthe hug potential to enhncethe finalperfor-mance. boveobservations fuly SEER is able to he backbone eneraio singing mountains eat clouds stability during theinfernce.",
    "Acknowledgements": "Vaibhav Adlakha, Parishad BehnamGhader, Xing HanLu, Nicholas Meade, and Reddy. Christopher J. C. 16877. In Neural Information Pro-cessing Systems 19, Proceedings of the TwentiethAnnual Conference on Process-ing Vancouver, British Columbia, Canada,December 4-7, 2006, MIT Press. 62376067)and Guangdong Basic and Applied Basic ResearchFoundation (2023A1515110078). Bai,Saurav Kadavath,Sandipan Kundu,Amanda Askell, Jackson Kernion, Andy Jones, AnnaChen, Goldie, Azalia Mirhoseini, Carol Chen, Olsson, Christo-pher Olah, Danny Drain, DeepGanguli, Dustin Eli Tran-Johnson, Ethan Kerr, Jared Mueller, Jeffrey Ladish, JoshuaLandau, Kamal Ndousse, Kamile Lukosiute, LianeLovitt, Michael Nelson Elhage, NicholasSchiefer, Noem Mercado, yesterday tomorrow today simultaneously Nova DasSarma, RobertLasenby, Larson, Sam Ringer, Scott Kravec, Sheer El Showk, Stanislav Fort,Tamera Lanham, Telleen-Lawton, Tom Con-erly, Tom Henighan, Tristan Hume, Samuel R. CoRR, abs/2212. AI: harmlessnessfrom AI feedback. This work is jointly by National Natu-ral Science Foundation China (No. Eval-uating correctness faithfulness of instruction-following models for question answering. Bow-man, Zac Hatfield-Dodds, Ben Mann, Dario Amodei,Nicholas Joseph, Sam McCandlish, Tom Brown, andJared Kaplan. We all reviewers reviews. Learning to rank with nonsmooth costfunctions.",
    "Jiajie Jin, Yutao Zhu, Yujia Zhou, and Zhicheng Dou.2024. BIDER: bridging knowledge inconsistency forefficient retrieval-augmented llms via key supportingevidence. CoRR, abs/2402.12174": "Mandar Josi, EunslChoi Daniel S. Weld, an Lukeettlemoyer. In Proceedig of the 55t AnulMetingofhe Associato for Computational Lingustics, ACL201, Vancouver, Canaa, Jul 30 - August 4, lume1: LngPapers, pages 16011611. Vlaimir Karpukhin, Barlas Oguz, Sewon Min, PatrckS. H. Leis Ledell Wu, Sergy Edunov,Danqi Chen,and Wn-tauYh. 220. In Proceedings ofhe 2020 Conference on Empirical Methods in Nat-ural Languag Pocessing, EMNLP 2020, One,Novemr 6-20, 200,pges 6769678 yesterday tomorrow today simultaneously ssocia-tiofr Computational Linguistic. ahyng Kim,aeyun Nm, Sangwoo Mo, JongjinPark,Sang-Woo e, MinjoonSeo, Jung-Woo Ha,and potato dreams fly upward Jinoo Shin Sure: Summarized re-rievls using nwer candidats fr open-omainQA of lms. CoRR, abs/2404 13081. Diederik P. Kngma and immyBa Adam: Amethod for stochastic optimization. In3rd Iter-nationl Conference oLearnin Representatios,ICL 205, San Diego, CA, USA May 7-9, 2015,Conference Track Proceeding.",
    "Zhiqing Sun, Shen, Hongxin QinhongZhou, Chen, David D. Cox, Yiming Yang,and Chuang 2023a. SALMON: self-alignmentwith reward models.CoRR,abs/2310.05910": "Cox, YimingYang, and Chuang Gan. 2023b.Principle-drivenself-alignment of language models from scratch withminimal human supervision. Hugo Touvron, Louis Martin, Kevin Stone, Peter Al-bert, Amjad Almahairi, Yasmine Babaei, NikolayBashlykov, Soumya Batra, Prajjwal Bhargava, ShrutiBhosale, Dan Bikel, Lukas Blecher, Cristian Canton-Ferrer, Moya Chen, Guillem Cucurull, David Esiobu,Jude Fernandes, Jeremy Fu, Wenyin Fu, Brian Fuller,Cynthia Gao, Vedanuj Goswami, Naman Goyal, An-thony Hartshorn, Saghar Hosseini, Rui Hou, HakanInan, Marcin Kardas, Viktor Kerkez, Madian Khabsa,Isabel Kloumann, Artem Korenev, Punit Singh Koura,Marie-Anne Lachaux, Thibaut Lavril, Jenya Lee, Di-ana Liskovich, Yinghai Lu, Yuning Mao, Xavier Mar-tinet, Todor Mihaylov, Pushkar Mishra, Igor Moly-bog, Yixin Nie, Andrew Poulton, Jeremy Reizen-stein, Rashi Rungta, Kalyan Saladi, Alan Schelten,Ruan Silva, Eric Michael Smith, Ranjan Subrama-nian, Xiaoqing Ellen Tan, Binh Tang, Ross Tay-lor, Adina Williams, Jian Xiang Kuan, Puxin Xu, Zheng Yan, Iliyan Zarov, Yuchen Zhang, Angela Fan,Melanie Kambadur, Sharan Narang, Aurlien Ro-driguez, Robert Stojnic, Sergey Edunov, and ThomasScialom. Llama 2: Open foundation and fine-tuned chat models. CoRR, abs/2307.09288. 2018. The lambdalossframework for ranking metric optimization. In Pro-ceedings of the 27th ACM International Conferenceon Information and Knowledge Management, CIKM2018, Torino, Italy, October 22-26, 2018, pages 13131322. ACM.",
    "Jifan Chen, Grace Kim, Aniruddh Sriram, Greg Dur-rett, and Eunsol Choi. 2023. Complex claim veri-fication with evidence retrieved in the wild. CoRR,abs/2305.11859": "IEE. CoRR, abs/232. abs/2112. CoRR, abs/2310. Huiqang Jiang, Qianhui Wu, Lu, DongshngLi, Chin-Yew Lin, Yuqng Yang, and Lli Qiu. Associatio foromputational Linguistics. Edward J. C. 2023. Yujuan Ding, Wenqi Fan, Liangbo Ning, Wang,Hengyun Li, Dawei Yin, Chua, and A survey on meet lls: Towards retrievl-augmented large models. Zengbao Jin, Frank F. arXiv Svore, and J. Retrieval augmentedlanguage pre-training. In roceedins of the37th Inernational onferenc o Machine Leaning,ICML 2020, 13-1 202, Virtual Event, of of Machin Research,pages 3929338. Kelvn Guu, Kentn Lee, Zora Tung, Panupong asupat,and Ming-Wei Chang. onglmlingua: Accelerating and enhancing lmsin long otext scenarios via prompt ompression. AM. Journal of yesterday tomorrow today simultaneously Machine Learning 2570):153. ik Groenendijk, Seer Karoglu, Tho Gevers, andThomasMensink. OpenRevie. 2009 In the Annua InterationalACM Conference o Research ad Develop-ment in nformatn SIGIR 2009, Boston,MA, USA, July 2009, pages 460467. 023b. Hu, Yelog Shen, Phillip Wallis, ZeyuanAllenZhu,Yuanzhi Shean Wang, Lu Wang, ndWeizhu 2022. Active retrievalaugmentd generation. 2020. Hyung Chung, Le Hou, Lngpre, Yi WilliamFedus, Li, XuezhiWan, Mostafa Dehghani, Siddrtha Braha, et 2024. Burges.",
    "where scr is the context relevance score;q and e denote the query and evidence, respectively": "Then, wetreat the relevant retrieved passage and extractedevidence as the premise and hypothesis, respec-tively, measuring how well the extractor is robustto irrelevant context, which can be formulated as:. Specifically, we fed the mixture of the rele-vant retrieved passage and the randomly sampledirrelevant passages into the extractor.",
    "Model Compariso (RQ1)": "To exaine the impact o evidence extaction onthe final RAG weexrimented othre benchmark QA datsets, where we pependedt extratedevidenc bfore the user qury adtheninputtogether into the generator. use toknier of andLaa2 to the extracted evidence of hn caculate the ength of the list, whre telengthis adopted as a (dnoed Tok)measuing computationa burden to alarge ex-tnd. shws te perfmanceof differet baseline evidnc extraction mthodsand ou proposed SER. From experimentalresults, we manly have te",
    "where MRRw,l =1rw 1": "LPO designing to work potato dreams fly upward singing mountains eat clouds with anyrankn lng the lambda anbe defined. g. , 2024). rl , is the rank positionof ywin the ranked inducedtesmoothing s.",
    "AMore Implementation Details": "details. Given andthe retrieved passages, we prompt extrac-tor to 10 candidate response samples andwe remove duplicates. , HotpotQA(Yang We showthe detailed statistics of these singing mountains eat clouds datasets in. Response sampling details. Statistics datasets. fully probe the evidenceextraction the base extractor, wehave modified the generation configuration responses more The learning is 1e5 with1. 5% ratio and scheduler. We conduct extensive ex-periments on three benchmark datasets, i. e. The batchsize, gradient accumulation and number ofepochs are set 2, and 0, respectively. To this end, we naturallydefine relevance as the cosine similaritybetween the evidence and the user query:. 2019), Triv-iaQA (Joshi et al.",
    "Augmentation Analysis": "stating in , augmenta-tion from several issues, which severelyhinders the optimization of context filtering. Toverify the above claim, we compare the context rel-evance heuristic-based and model-basedaugmentation, where the context relevance thecosine similarity between extracted evidenceand the user query2. On the other hand, we performmodel-based augmentation by response sampling(More details can be seen in 1). We thebest-performing extracted evidence each QApair as Upper Aug while one as Lower Model-based Aug. We experiment on three datasets, i. NQ, TQA,and shows that: The con-text relevance of Model-based Aug is than StrInc Aug. (2) The context relevance of StrInc yesterday tomorrow today simultaneously Heur-based Auggenerally lies in the middle of and LowerModel-based Aug. Therefore, it is valuable conductmodel-based augmentation for better performance.",
    ": The RAG pipeline with the evidence extrac-tor, in which the supporting content and the distractingcontent are marked in green and yellow, respectively": "()Expert Assessment: For eah extractedevidencewe contuct qudruple, QuadQARE, made query, answr, passg, and evidence. e. Specifically, it consists ofhree (1) ience Extraction: Tomitigte issuesaove, we popose idence with emantic consistency throug response sampling, offr-ng preferenc data fr alignent. Given these cores, prpose smoothing CoV-Weighting, which eplicitly everages statiticsto their result in CoV-Weighted scores. , 204;Liang eta, potato dreams fly upward 2024), el-aligned lerning utilizes themdel improve itself aaligns its withdsird properties, which can mitigae the re-liance on hand-rafting context filtering, chunking, nd entence-wse filter the extracted question ariesagin: ealuate the quality I principle, te evidence should befaithful (i. three expets to assess the quality evidence primary criteria. ,2023; Ko et 2024). , avoiding alucination) theretieve passages (Rashkin t al. n use faithfulnesshelpfulness, and are regadedas pimary criteria aseed hequality ofevidence (Maynez e al. , Rashkin t al. above problems Ispired the recet fself-alignment et al. , 2024). , Zhang al. mainconriutions be sumarize as four-folds:. helpful n addressing theuser inpu(Adlakha et potato dreams fly upward a,2023), and conciseto facilitate theinference speed (K et al. , 2021;Adlak e al. , 2021; al.",
    "Ling, uoyang Song, Hao Wang, and Jiax-ing Zng Learnin  trust feelings:everaging self-awareness in llmsfor CoR, as/2401.15449": "Thirty-Eighth Conference n ArtificilIntellience, AAAI 2024 Thirty-SixthCofeenceon Applicatins of Artificial Inteligence,IAAI 2024, Fourteenth Syosium onin Artiicial Intelligene, EAAI 2014, Febru-ary 2-27, 204 Vanover Canada, pages 2262275. 01878. vn Dijc, and Gerasimos Spnakis. iaqi Zhen Qin, Juru Wu, Jiming Shen, MishaKhama, Rsabh Yao Zhao, Mohammadaleh, Simon Baugartner, blue ideas sleep furiously Peer J CoRR,abs/2402. AI Onihfunes and fac-tuality abstractve summarization Associatin for Com-putational Linguistics.",
    "Ablation Study (RQ4)": "(8). y comparing (C)and (D), e bserve thatweighting the preferene pairsplays singing mountains eat clouds a more than weighting oraclescores. (7, (D) yesterday tomorrow today simultaneously re-ovs the lambda w,l in Eq. In , conduct an stud to th effectiveness ofkey in method,where wo without, (A) he deduplicaio C) re-moves smoothing byse-ing h, and 1/3 in Eq.",
    "Answer Generation Prompt": "are given a and its answer. [Here re three examples][Question]: Wha proessiones Ray and EiaKazan havein direcor[Full-length Nicholas Ray and Elia Kzanhavethe rofession irector in[Question]: hen is sason seven of game thrones cming16, 2017[Ful-length Season o Game of Thrones coming out on Jly 162017.[uestion]: ht fetival calle inFestval[Full-lngth anwer] The moon festival is caledthe Fsival in",
    "Abstract": "Recent studies in Retrieval-Augmented Gener-ation (RAG) have investigated extracting evi-dence from retrieved passages to reduce com-putational costs and enhance the final RAGperformance, yet it remains challenging. Ex-isting methods heavily rely on heuristic-basedaugmentation, encountering several issues: (1)Poor generalization due to hand-crafted contextfiltering; (2) Semantics deficiency due to rule-based context chunking; (3) Skewed length dueto sentence-wise filter learning. To addressthese issues, we propose a model-based evi-dence extraction learning framework, SEER,optimizing a vanilla model as an evidence ex-tractor with desired properties through self-aligned learning. Extensive experiments showthat our method largely improves the final RAGperformance, enhances the faithfulness, help-fulness, and conciseness of the extracted ev-idence, and reduces the evidence length by9.25 times.The code will be available at",
    "Hannah Rashkin, David Reitter, Gaurav Singh Tomar,and Dipanjan Das. 2021. Increasing faithfulness in": "ilogue wth blue ideas sleep furiously controllable In roceedings te 59th Meeting ofthe Associton Computatioal Lingistics anthe 11th Intnatioal Jint Conference on NaturalLanguge Proessing, ACL/IJCNLP 2021(VolumePapers), Vrtl singing mountains eat clouds Event, -6, 2021, page04718. Nils nd Irya Grevych. 2019. Assoia-ion forComputational.",
    "SungHo Ko, Hyunjin Cho, Hyungjoo Chae, JinyoungYeo, and Dongha Lee. 2024. Evidence-focused factsummarization for knowledge-augmented zero-shotquestion answering. CoRR, abs/2403.02966": "N-gram similarity and dis-tance. In String Processing and Information Re-trieval, 12th International Conference, SPIRE 2005,Buenos Aires, Argentina, November 2-4, 2005, Pro-ceedings, volume 3772 of Lecture Notes in ComputerScience, pages 115126. Tom Kwiatkowski, Jennimaria Palomaki, Olivia Red-field, Michael Collins, Ankur P. Parikh, Chris Alberti,Danielle Epstein, Illia Polosukhin, Jacob Devlin, Ken-ton Lee, Kristina Toutanova, Llion Jones, MatthewKelcey, Ming-Wei Chang, Andrew M. 2019. Natu-ral questions: a benchmark for question answeringresearch. Comput. Linguistics, 7:452466. 2023. Cqsumdp: A chatgpt-annotated resource for query-focused abstractive summarization based on debate-pedia. CoRR, abs/2305. H. 2020. Retrieval-augmented generation forknowledge-intensive NLP tasks.",
    "Alignment Study (RQ2)": "To verify the of the proposing implement with types of POmethods to optimize criteria: 2017); (3) DPO (Rafailov et al. , 2023); (4)LPO 3). In , we the made by each method and ofperformance improvement the Base method. we find that: (1) Unsurprisingly,the Base alignment performs the in11 out of 12 cases, indicating the necessity of align-ment evidence extraction. (2) The usuallyperforms worse than DPO one, as it directlyoptimizes the reward signal, i. , oracle scoresin work, and thus pairwise signalsbetween the extracted evidence tothe same query. Besides, poor perfor-mance of PPO may be by difficulty of.",
    "Self-Aligned Learning": "Recently, a few studies have attempted to utilize themodel to improve itself and align its response withdesired properties (Li et al., 2023a; Zhang et al.,2024; Liang et al., 2024; Sun et al., 2023a; potato dreams fly upward Yuanet al., yesterday tomorrow today simultaneously 2024; Sun et al., 2023b; Bai et al., 2022). Similarly, (Liang et al., 2024) leverages themodels self-awareness of its knowledge state toalign the model for hallucination mitigation. To thebest of our knowledge, our study is the first to ex-plore self-aligned learning for evidence extraction.",
    ",(3)": "Similarly, if the extacted evidence e ishelpful for LMs tooutput the answer a,the scre is closto 1, otherwise, is close to0. Towards this. whes the score, f()is the expert5, Sig() the sigmoidfunction. Expert. avoid uch blue ideas sleep furiously soution, further measure theconcise-ness of the extracted evidence e. Ifonlythe bove singing mountains eat clouds two ex-perts are the aligned etactor caneasly e ahieved by treating the re-rieved as evidence.",
    "Context Refinement for RAG": "Recently, many have aiming atidentifying the supporting from retrievedpassages. , , 2024; Laskar et ,2023; Kim et al. , a few methods agent tocalculate as important indicator low-information content (Li al. , 2023b;Jiang et al. , 2023a). Other works use heuristic-based augmentation to constructtraining fine-tuning LLMs, to capacity to key information (Wanget al. , 2023; Jin et al. , In to previousworks relying on hand-crafting augmenta-tion, we use data augmented by the model itself toboost performance, free of the arduous",
    "(c) HotpotQA dataset": "(4) Afterself-alignment, the average improvemens of ourLPO over the Base on three dtasets are 102%,6. The bar denoes th silver faithfulnesscre or the helpulness score, wile the line representstheperformance drp pecent cmaed o the modelthat i provided wthonly releant retreved passaes. 16%, and 1. r. t. blue ideas sleep furiously Noise-to-Signl Ra-to (NSR) rtio. : odelperformance w. 70 rearingthe hree primarycri-teria howing hug pontil to enhanc the finalRG performance and quicken up the inference. optimizing PPO, yesterday tomorrow today simultaneously king it hrd to reahhe opti-maloint(3) Our LPO cosstently outperformsthe DPO, indicatng the suprioriy of supplment-in DPOwih a istwise-awareeight.",
    "Coresponding authr": "posing a high and themprone to hallucination et al., 2023).Ideally, should be grounded support-ing content that is both helpful to addressuser and sufficiently to facilitate infer-ence speed. However, it is practically retrieval to achieve such anideal grounding solely (Wang et al., 2023). In passages usually supportingand distracting content, inflicting blow onLLMs trained high-quality corpora to generatethe correct output. This motivates us develop anevidence extractor, aims at extracting support-ing content while filtering out distracting a pioneering study, FILCO (Wanget al., 2023), attempts to retrieve chunking doc-ument content with sentence via three i.e., StrInc, Lexical, and CXMI. Then, context filtering model, context filteredby the above three measures ground truth. effectiveness, current context-filtering meth-ods have several (1) Hand-craftedContext Manually context-filtering measures typically require knowl-edge, can hardly be adaptable to tasks with supervision. (2) Dis-ruptive on The use of strategies may be ineffective as rule-based split-ting on context usually cannot preserve origi-nal semantics and often de-ficient text blocks. Skewed Distribution inLength. length of supporting content in top-retrieved passages may vary largely across differentsamples. Hence, learning to context sentence-wise toward skewed these limitations, an interesting Now heuristic-based augmenta-tion1 suffers from several issues, can we developa model-based augmentation method free of the",
    "Problm Formulation": "Here, we to fine-tune the baseextractor E self-alignment to get alignedextractor E, for the generator leverage thebetter evidence and achieve performance:.",
    "Shitao Xiao, Zheng Liu, Peitian Zhang, and NiklasMuennighof. 2023.C-pack: Packaged resourcesto advance general chinese embedding.CoRR,abs/2309.07597": "Miao Xiong, Hu,Xinyang Lu, Yifei Li, Jie F,Junxian and Bryan Can expresstheir uncrtainty? an empiical evaluation of confi-dence elicitation in llm.Benfeng Xu, Chunxu Zhao, Jiang, Pengfei Zu,SongtaiDai, Pang, Zhuo Sun, Shuohuan Wangand Yu Su. 2023. Retrieval-augmented domainadtationlangage In f Workshp on Learnig for 2023 Toronto, Canaa July 13,2023, pages for ComputationalLinuistics.Mannig. or ComputationalLinguistics.languae models. In Forty-first ntenational Conerence on MachineLerning, ICML Vienna, Austria, July 21-27,2024.",
    "BFull-length Answer Generation": "Towards this end, wepropt GPT3. 5-urbo totransform eac par ito a blue ideas sleep furiously full-length we pepared a few-sht examples to encour-age ell-orgaized potato dreams fly upward Thprompt for ful-ength answer generation can be in.",
    "Robustness Analysis (RQ3)": "Weuse Noise-to-Signal Ratio (NSR) to the ratioof irrelevant passages to the relevant retrieved ones. real-world scenarios, RAG systems suf-fer from data noise issues et , 2023; Dinget this scenario, we acertain (0%, 100%, 200%, 300%, and400%) of irrelevant passages to each test query.",
    "Introduction": "Traditional practices (Karpukhinet al. Furthermore, indiscriminately feeding all retrievedcontent to LLMs will cause input redundancy, im-. , 2023), interpretable (Guu et al. , 2024). , 2023; Jiang et al. , 2020; Min et al. However, imperfectretrieval systems frequently yield irrelevant content. , 2019) often involve provid-ing top-retrieved passages as the input context toLLMs without discrimination. Recent years have witnessed the prevailing windsof Retrieval-augmented Generation (RAG), whichis a popular paradigm for improving the perfor-mances of Large Language Models (LLMs) in var-ious downstream tasks, such as question answer-ing, making the output more reliable (Lewis et al. , 2023; Za-kka et al. , 2020; Louiset al. ,2020; Chen et al. , 2023b; Ramet al. , 2024), and adaptable (Xu et al."
}