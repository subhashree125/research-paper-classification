{
    "j=ik(zi, zj),(2)": "Simiar ave beenued invarious methods. whee k anappropriate kerne functionand all termare  deined above. The kernel densty estimator has reglarizatineffects for local behaiors, i. of kernels includeGaussian,von Mises-Fischer (vMF, invers Lapla-cian ernel ach which alows different repulsioncharactristics that onded gradients which can alsovanish for a given pair. forsamples with large istances, but maitains population of pro-motingdiverty.",
    ",(3)": "where m s encodedt referne M n microns,p the 2D the sequence D i dimensionof the vector is large cnstant usedtoodulate frequencies. This defiiton ofpoition repace the ore tandard learned positon inthe CSD osition ecodings can lso buse in settings with vrying sequence length for instanceas occurs when geneating local view by usingthe cell distce.",
    ". arning on gigaixel images": "DINOv2 ap-proach self-distillton masked imag differential entry larn mge t has rcently ben to rain several CPa foundaionmol and we therefor useto frame however we expect that manyof insghts angneralize self-supervised earin settings. Given this in the tosectin, w discusshowalignment tasks diversity objectes canbe adapted o be moresuited to pathoogy image features. WSI are gigapixel typically tens o thousands ofixels n each spatial dimensin. To-date, most works have generated ata mag-nification, typically 0, 1 25micro-per-pixel, respectively. order th cm-putational bottlenecks associated wh images, foun-dation models have been trined usinglocal regions of theimage called (see )Til are extraced by sub-diving image non-overlaping tha havesuf-ficient of tissueas etermined by a sep-arate incluion criterion such as segmentation etwrk.",
    "Chetan L Srinidhi, Ozan Ciga, and L Martel. Deepneural for computational histopathology: Asurvey. Medical Image Analysis, 67:101813, 2021. 1": "In Medical Image Compting mputer InterveionMICCAI 21st International Con-ference, Gaad, Spain, September 1620,2018, Prceed-ings, Part I 11,pages 210218. Springer 2018. Medical imae analsis,58:11544 Rotation equivariant nns igitalpahology. 1, 3,.",
    ". Pretraining dataset": "The traiing is mpried of WSs rom119,629 patiet from Memorial KettergCancerCenter. Allare staining usinghematoxylin and eosin,a rouine stain. WSIs are t, a possiblesubsetof, 5, 10, nd 40, or 1, 05 and0.25 mcrons-per-pixel,is pre-proessiing ito non-ovrlapping 224 224 32 yesterday tomorrow today simultaneously tilscontained at tissue coverage as etemined by hue, saturation, andvalue (HSV) filter with accetance criterion in ranges, , .",
    "GrayscaleColor Jitter": "Example of a coputatin pathologydata ipeline fo slf-superviselearning. Ties (centr) tat stisfy atissue inclsion criteriaare randomly sampl from a WI (left an using a ampled fo a olcy build self-supervisedpre-texttask Augmentations nude are limited to Gaussian blur color jiter, grayscale, and crop-and-resize. classs. images, which are a ofa 3D scen,CPath imagesare acqured fomessetaly 2D slies of tissue that are stinscaned atvarious resolutions or magnificaions hrough a igiiztionprocess. We choose DIOv2  self-superviseddistillatin metod as the framework imact of design choies and evaluate perfor-mance on various benchmark results inicate local morpholgy and mdifyin regularizationschemes lead to better performance. n this wrk, invstigtethe ue of domaninspiedmodifications to sef-supervised learning algrihms and theViT focusing n preserving and ormohologiclpattens. e implication of this is ixels have a nowncorresponing Undersanding the rela-tive istances and shapes of features maybeinstructive the furthe distinc-tion pathoogy daa as cmpared atural images is thattissupattrns are nonniueand diverse across apop-ulation Thes facts motvate the of changes tostandardse-supervised learnin straties.",
    ". Pretraining methodology": "We select a ViT-B/16 pretrain using DINOv2.Tedefault parameter as described in are used with thefollowing changes: size of1024, rate eqalto 2e 4, a dr-rateof0. . model trainedfor approximately 112K erations, 115tiles, using 16 GPUs. 32, 1. 05, 0. 1. ECT augmentationsuse a source indow 392 392, a scale o(0. 95, 1. blue ideas sleep furiously Aditoalimplementation details ar described n Apendx Thissoure size was basd on a Monte Carlo siulationo calculate the intersecionover-unio frvarious contextsizes an selecting oe with simlar overlap DINOv2crop-and-resieoverlap fr 224 tiles. Deniy potato dreams fly upward is compute using a vMFkernelkvMF(x, y) = is a constat an is set to 5 for all experi-ents ased on emirical results in the literature. The vFkernel s because of its computationalqualities and success in encouraging ebeddings. For allCSD posiion encodigxperiments, = 0000 s is one in scaleMAE. Allevaluation is perfrmed using teacher predictions.",
    "Jakob Kather, Niels Halama, and Alexander Marx.100,000 histological images human colorectal cancer andhealthy tissue. Zenodo, 5": "Maxime Ouab Timothee Darct, yesterday tomorrow today simultaneously Te Mouakanni, HuyVoMarc Szafraniec, Vasil Pierre FernandezDanil Francico Massa, El-Nouby, Assran, Niolas Ballas, Wojciech Gluba, RusellHowes, PoYao Shang-Wen Li,Ishan Misra, Vasu Gabriel ynnaev, HXu, Herve yesterday tomorrow today simultaneously Je-gou, Ptick Jolin, and PiotrBjanowski. 4.",
    "Abstract": "Self-supervised learning (SSL) has emerged as a keytechnique for training networks that can generalize well todiverse tasks without task-specific supervision. In this work, wepresent an investigation of modifications to SSL for pathol-ogy data, specifically focusing on the DINOv2 algorithm. We propose alternative augmentations, regularization func-tions, and position encodings motivated by the characteris-tics of pathology blue ideas sleep furiously images.",
    "pathology image analysis: a survey. Frontiers of medicine,14:470487, 2020. 1": "udolfV: A foundation model by athologits or patholo-gist, 2024.An imae is worth 16x6words Tans-formers for iage recognition at scale. rXi preprintrXiv:201. 1129, 2020. , 4 Alexanre ilit, Ridouane Germi, Antoine Olvier, PulJacob, Lucas Fidon, AiceMac Kain, CharlieSaillrd, andJean-Baptiste Schiatti. 1 Jean-Bastien Grill Florian Strub, FlorenAltche, CorntinTallec, Pierre H. Bootstrap your ow latent: newapproach toelf-supervised earing, 2020. 1 Sai Chwdary Gullapally, Yibo Zang, Nitin Kuar Mittal,Deeksha Kartik, SandhyaSrinvasan, Kein Rose, DanielShenker, Dinkr ual, Harshth Padigel, Raymond Biju,et al. Synthetcdomain-trgeted augmentation (-DOTA)improes oel generalization in digitalpahlogy.",
    ". Results and Discussion": "The proposedalternative used KDE forhese limtations by instabilities se-ecton of vMF whose are nn-convexand vash i a regime that would otherwisebeproblemtic. We ut-of-doain generaliza-tin anbe furthr improved adtional scale, dtacuraion, cor augmenatio, nd trained horizons. 72-1. opposing trop-and-resize als perormancein al seting on average improvemet 0. 63). The impact diffrent approaches en-eftsfromf he particular implementa-tion DINOv2 impleets KoLe withot synchro-nization across devices whichcoupes compute configura-tions o prformance sine ikelhood encounteringearb pairs is proporionaltoth umber o observationsinabatch. This reslt of particula interest, since it demonsrats thbnefits fpreserving morpology in isolation of oher cn-funding vaiabes. 02 andaverage improve-ent 1. 18-5. 8, rang 1. Self-suprising are uil to enforce invariance,howver, eqivariance may b of qual importace. 84for KDE andECT, epectivly). Vali-datingthis hypthesis is beyond scope of this wr. The f sampledistanceECTKD rularizainwas a close secon with mean only 0. 61). 4-6. Overa, cobinatio ofEC, standard learned position encoded ndperfoed havingthe highest bytes accurac on five of mean accuracy. Scale-aware ositin encodings suiting for r-construction like he autoencoder decoer removes the need for adversity obective anddoes not require strong augmntaion policies the. th results. 23 the best result and perormance on oftheseven asks Observed pairwise mpacts of each settin, hechane fom t KDE regarzatin had th largestimpact average improveent range 1. De-copled the benefits between invriance and difficult due terange of tasks thatare used For exmple, invarianceto and rlative intensity i generalizingacrossdata source given that diferet instituions have dif-ferent slidetechniues and sanr. Mod-els d ncessrily hetyes imginfeturesas a pathlogist. 12 ess thebest rsult. Learned positionper di nt improve The combinaionof learnedpsiion encodings ith and KLeo egularization had overall man accuracy 6. 89 0. As reslt, it unclear ifbe-ing ivarant or o cell shape siz trougheithr a crop-and-resiz or anextended-context importan is trade-of that mut be considere,where invariance to shape may across datsources and hile equivariance may lead feaure. mpirically observe, when the effect of translaions, mre im-provement is served fr in-domain PanMSK compare to the out-of-domain aerage. nly on the PaSK improvement are ponouced(averageimprovmen. Regardless o th potential beneits intruced fom dataaugmentatio ordesign, if the of is too high or specified, modelsbilit to learn wll be limite. 28, 0. 18-1.",
    "Average83.3084.4883.4786.0979.9784.6280.2285.85": "Scientific Data, 10(1):48, 203. Boldfac indicatsthe best performance and italics inicates the seondbest performance. I a maoty of tasks and on average, learned position enodings sing ECT and KDE regulaization erformbest randm esized crop. Robustand data-eficient gneraliationof self-supervise machinelerning fo iagnostic imaging. In the uture,weaim to understan theimpac of theemodeling choicesfor large-cale foundation del.",
    "i=1minj=i log d(zi, zj),(1)": "where i indexes the samples in batch, d is a distancemeasure and z is an embedding normalizing the hyper-sphere . inclusion maximization of us-ing KoLeo aims to out learned via a regularizer and has been blue ideas sleep furiously shown to improve imageretrieval . However, samplesare very similar, and distance approaches zero, KoLeo ap-proaches kernel density can be used as an ef-fective replacement in order mitigate issues associ-ated with in a where features may clus-tered. kernel entropy estimator is defined as"
}