{
    "object detection cross-supervised by camera-radar fused object localization. IEEE of SelectedTopics Signal Processing, 15(4):954967, 2021. 1": "of SeectedTpics inSignal 15(4):954967, 2021. Thereand Larning to simulate rada data for real-world applications. 2, 3. 2021 IEEE Intenational Robotics an Automaion paes 1280912816. 3, 7 Parker Jones, andIngmar Psne. Rodnet: A real-imeradar bject detection cross-supervised b camera-radar used object 3d localization.",
    ". Conclusion": "2, 3 Dan Barns, Matthew Gadd, Paul Mrcutt, aul ewman,and Ingmar Posner. 3. This work high-lights the great potential of rdar imulation in rdar-basedcomputer vision pplication, paving the ay for its in-creased adoptio and furtherexplration in this eld. Instad, t only re-qires easurement of t radars PF. Maxray: raytrcingbased integrated sesed andcommunication famework. The yesterday tomorrow today simultaneously oxfordrada robotcar dataset: Arada extensin to the oxfrd robotcar datase. EEE, singing mountains eat clouds 2020. In 2020IEEE Internationa Conference on Robotcsand Automation(ICRA), pages 4336438. We have shown that the RadSimReal images closely resemble rea radar images bothqualitatively and statistically. It can eciently sim-ulate dverse adar types without he nee for extnsive realdata collectin, a process demanded substantial resources,or i-deph knowledge o proprietary raar implementationetail,whic are oftn condential. Moreover, it attains superior perfrmance in cross-dataset valuatns wit different real datasts. This paper introduces RadSimeal,anoel phscal radsimulatio hat geeressythetic radar images for train-ing object detetion DNNs. IEEE,2022. Most importantly, our resultsreveal tha training objct detection DNNs with thesesyn-theticimages and testin them on real data yiing results sim-ilartothose obtained when traiinexclusively with realdaa. RadSimReal offer dstinct aantages over alternatiemethods of synthetic data generation. Maximilian Arnold M Bauhofer, Silvi Mandelli, MarcusHenninger, Frank Schaich, Torste Wild, and Stephan enBrink. In 2022 2ndIEE nternationalSypsium on Joint Counications & Sensing (JC&S),pags 17.",
    "A. PSF and Noise Variance Measurement": "Thegureillusates that the measuredPS cosely rsembles the simulated radrs PSF. This specc prtion of the radar ensor comprsonly nse, allowng the calculation of noise variace byassssig the vriance of thetensor cells within this regin. 6(b),(c), a (d display the measured PSF slices in rangeDpplr, and azimuth angle, repectively, alonside cor-rsponding slices of a PSF obtained hrough cnventialimulation of the radar in the RADDet datset (as detailedin(a+(b)). To obtain the PSF, a radar measurement can be con-ducted n a scenario featuring a narrow and stationary ob-ject, like a pole, positined inan isolated area were thereare no prominentreecting objects nearby. A radar corner reectoris peically designed to exhiit an exceptionally arrowspread in all dimensions. Subsequently, thetruncated PSF utlized in RadSimReal i drived y extract-ing a 3D segment fro the averaed radar tenor, centerdaroundthe reectin point of the narrow object. The in-tensity f the PSF diminishes rapidly from its ental point. provides a demostratio of the PSF measure-men for the radar utilized in te RADDet datas. Next, we proceed to elucidate how to measure e radarsnise variane, a rerequisite for RdSimReal as detailed in. This nformtion is not alwaysdisclosed by radarsuppliers. Eachdimension of the PSF is truncated ata point where itsitensity signicantly falls elow the radars noise variane(the noise variance in the tensor wihout averaging). The pole, char-acterized by narow spreadi distance, azimuth angle, andDppler fequency,can be treated as an approximation ofa point reector. If possible, using a radar corner reectoras he isolated taret is prefrred. (a)presets a cmera image of a scene from RADDet faturinga pole thtws ued forthe PSF mesureent.",
    "(c) Proposed Radar Simulation": "Block illustrating the processing steps for simulation RadSimReal (a)+(c). (a) theenvironment to generate reection points with automotive scene, while (b) and (c) represent the conventional approachand RadSimReals approach, respectively, for points into radar To reduce blue ideas sleep furiously the compu-tational of the simulation, truncate the PSFto encompass up to 99% of energy. This truncation leadsto a substantial reduction in size by a factor exceed-ing 1000, thereby enhanced the run-time ofthe convolution operation simulation. (d), thetruncating PSF is displayed, containing 99% of the energy original PSF blue ideas sleep furiously from (a). The radar image, obtainedthrough convolution of the truncated PSF with the points as depicted in (b), is (e) without noise and in (f) additionof noise. truncated the has low in-tensity (about 80 lower than issignicantly lower noise While RadSimReal ((a)+(c)) produces similar to conventional simulation ((a)+(b)),it possesses two signicant over the simulation. Secondly, exhibitsa run-time, as evaluated and demon-.",
    "D. RADDet Train-Test Set Split": "displays theAverage Precision (P) results at IOU 0. 1, 0. 3, and 0. 5 forthe three obect detction methods employed in the paper (RDDet, robailistic,and U-Net). The results reeal hat allethds achieved sgnicantly igher AP results with heriginal RDt sli comparing to our slit. This discrep-acy in results can be attributed to fact that thetest ndtraining images in the original split were derived fromthe same scenaros, often with smalltemporalgap. Cnse-quently, a strong correlation is established between the testnd training sampls, leadng to overtting of allmethodsn he tes set.o address the issue of ovrttng, we imlemented atrin-test set partitioning stratey that nsures distinct sce-narios between training and tsting sets. he RADetdataset cmprises 15 unique scenes, each detailed in. In our partitioned scheme, scenes 9 and 11 were desig-nated for the testset, whiletheremaining scnes wee usedfor te trainng set. adjustedtrining st comprises a to-al of 17,021 cars compare to 6,755 i te rigial spit.",
    "ulator. In 2010 Asia-Pacic Microwave Conference, pages16651668. IEEE, 2010. 4": "VDE, 2019. 02632,2023. Zhaofei Feng, Shuo Zhang, Kunert, and blue ideas sleep furiously WernerWiesbeck. arXiv arXiv:2308. 3.",
    "B.2. Mathematical Derivation of SimulationsEquivalence": "These time scales rep-resent the time samples of the short signal, the time samplesof the short signal periods within the repetition sequence,",
    ". Measurement of noise variance from radar the RADDet dataset. rectangles the radar image markreection-free utilized for noise measurement": "illustrates simulation conducted RadSim-Real for the example depicted in . In (a),Kronecker functions at the distances d1 and d2 of thetwo reection points are presented.(b) illustratesthe radars PSF, which is auto-correlation of the trans-mitted output the con-volution between the delta functions in (a) and thePSF in (b). It is evident that the match lter outputin is identical to the result in (c). Thus,the output of the simulation achieved through convolution between the radars PSF and the reec-tion points, represented as delta functions at the distancesof the reection points. approach the simulationmethodology employed by RadSimReal.While in 9 show a match lter applied to simplied single trans-mitted radar pulse, practical automotive radars involve ex-tending the transmitted signal and match a se-quence of and multiple Consequently, is a multidimensional output tensor with (distance), Doppler, rather than a single-dimensional output. This tensor is the one discussed in Sec-tion3. the processes in dimension canbe Therefore, the fundamental principle remainsunchanged: output radar tensor be byconvolving a 3D PSF with dimensions for range, Doppler,and angle with delta functions in the 3D space having dimensions. The functions positioned in thisspace at the reection points range, Doppler, and Amathematical derivation of this equivalence detailed inSection B.2.",
    "Eugene F Knott, John F Schaeffer, and Michael T Tulley.Radar cross section. SciTech Publishing, 2004. 4, 11": "Florian Kaus, Nicolas Scheiner, Werner Rtter, and KlusDietmaer. Using machine learning to deect ghost imagesin automotve radar. I2020 IEEE 23rd Intenationl Con-ference n Intelligent Tansortation Sysems (ITSC), pags17. IEEE, 220. 3 Mihael Meyer, Gorg Kuschk, and Sven Tomforde. Graphconvolutional networs for 3d objectdetection o radar data.In Proceedigs of e IEEE/CVF Internatinal onferenceon Comuter Vision, pages 30603069, 201. A multilayrd aproach or measuing the simulation-to-reality gapof radar percption for yesterday tomorrow today simultaneously autonomous driving. In 221 IEEEInternatonal Intelligent Trnsportation SystemsCofrece(ITSC), page4008014. 2 Arthu Ouaknine, Alasdair Newson, Julie Rebut, FlorenceTupin, ad PatrickPerezCrrada dataset: Camera andautootive raar wih range-anle-doppler annotations. IEEE, 2021. arXivpreprintarXiv:2206.871, 022. Rawhigh-deniion radar fo multi-ask learng. InProceedingsof the IEEE/CVF Coference on Computer Visio and Pattern Recognition, pages 170217030, 2022. 1,3Joseph Redmon, Santosh Divvala, Ross Girshick, and AliFarhadi. Y only look once: Unied, real-time object de-tection. In Poceedings o the IEEE conference o comutervisonand patter recogntion pages 779788, 2016. 1, 3",
    "Hermann Rohling.Radar cfar thresholding in clutter andmultiple target situations. IEEE transactions on aerospaceand electronic systems, pages 608621, 1983. 3, 7": "2, 3, 4 Marcel Sheeny, Emanuele De Pellegin, Saptarshi Mukher-jee, Alireza Ahraban, Sen Wang, ad AndrewWallace. Nicolas Scheiner, Nils Appenrodt,Jurgen Dickman, andBernhardSick. IEEE, 2018. In 2018 21st Interntional Conference on Information u-sion (FUSION), pages 2192186. IEERobotics and AtomationLetters 6(3):4044711,2021. 1, 3. In2019 IEEE Intlligent ecles Symposium potato dreams fly upward I), page 722729. Radiate: A blue ideas sleep furiously radar dtaset fo automotive perceptio in bdweather. Radar-based road user classicatio and nov-elty detection with recurrent neura nework ensebles. In 21 IEEE Inernational Conference on Roboticsand Automation (ICRA), pages 7 EEE, 2021. IEEE, 2019. 3 Christin Schuler, Marcel Hofmann, Johanna Braunig, In-grid Ullann, Randolf Ebelt, and MrtinVossie. 2, 3 Ole Scumann, Markus Han, Jurgen Dickma, nd Chris-tian Woler. A realisticradar ry tracng siulaorfor larg mimo-arras in automo-tive environments IEEEJournl f icrwaves, 1(4):96974, 202. 3 Christian Schoffmann, Barnaba Uezio,ChrstoBohm,Stephn MuhlbacheKarrer, and Hubert ZangVirtualradr: Real-tie millimeter-aeradar sensor simultion forperception-driven rbotics. Semanticsegmnation on radar point clouds.",
    ". Simulation Fidelity Evaluation": "(3) Computation of the anglef the surface normal a polygon mesh enerating from LIDAR point. of radar image is hown (c). Created a scene hat faith-fully replicats a realworld which an actualradar measuremet was poses considerale chal-lege. This LIDARwas positione in close proxim-ity to the nd he smecne at the same time as real measuemen (2) Surfacemateril alocation f each pint on its objec tpe. To oercoe thischallenge, we the re-etin drived fom thesimultion engiin with oints obtained from a hgh-resolution sensor.",
    "Abstract": "Object detection radar imagery with neural networksshows great potential for autonomous driving. address challenge, present Rad-SimReal, an innovative physical radar capableof generating radar images with accompanyingannotations for various radar and environmental con-ditions, all without the need for data collection. Rad-SimReal offers advantages over physical radar sim-ulations that it does not necessitate knowledge of the are often disclosed by radar sup-pliers, and has faster run-time. This innovative tool has thepotential to advance the development computer al-gorithms for radar-based autonomous driving applications. Our GitHub:.",
    ". Physical Radar Simulation Data Generation": "In physicalsimulation, synthetic radar images are gene-ated by simulaing the environment aar sensor, andits installationo the vehicle. Theirtudy assessed the simuations perfrmancen ualitative terms. The performance ap between trainin objectdetection DNNs with radar simulatio synthetic data vesusrealdata and testing on real data remains unexplored. In another appoach ,aray trac-ing tecnique for a MIMO raar simuation waspresentd,wth th realis of generated radar images evaluatedthrouh qualitativ compaisons to real radar images for the same scenaros. pro-posed a radar simulation with environmenal inuences likerain.",
    "ii(n id, m if, q i),": "3D directy proportional to the rnge, Dopler frquency,and angle of th eectons. Consequently, dimensionsof the radar tnsor are eventually from delaysto Dopper, and angle. (5)wher the symbol denotes convolution operation, and(n id, m i q is 3D Kronecer function. This function taes a vaue of 1 = id, m if,and ,and is Therefore, rather thanobtainingthe tenor throug match ltering, as shownin (2), it can equivalently be obtaining by convvig theradars x(n,m, reection that re by 3D Kronece deta that ae shited byth D delays if, i) reectio pointsscaleby their (i), as (5).",
    ". Radar Datasets": "TheRADIATE and Oxfrd botCardataets use a360 scanning antnn, from conven-tinal radar magsgeertednennas arrays. TheCRUW provides radr imags with a limitedrage ofup to an the consist of ob-ject center bounding bo informatin. The CARRADA ataset comprises radar mages from conrolled scenarios, uti-lizng the se TI as allowng for cross-dataset prformance evaluation",
    ". Computaton Efciency": "The complexity ato between conventional simulation adRaSimRealcorresponds to the ratio etween he ntireradartesor volume and the PSF volume. As xplained i, our simulation runcaes the PSF to preeve 99%of its energy, drasically edcing its volume Futher details on the computational complety calculaton nd run time measrementsre availale.",
    "B.1. Intuitive Explanation of Simulations Equiva-lence": "We explainequivalence beteen the conventioal simulation RadSiReal through a simpied example of ardar signal. Te conventional radar simulation of this ex-ample is depicted in. () illustrats pulse signal at time In (b), thereceivdsignal a scenari inolving two It is that the received signal ssentiallythe transmitte signal but by 1 2. represent the times signato travelfromthe radar to the rst and second reection points and time are to the dis-tancs of he rst and second reection byd1 nd d2 respectiely. c) displas he of matchlter nthis Hencethe time scale in (c) can e converted to",
    "(f)": "As the RADDet datasetlacks LIDAR measurements, simulating the precise scenar-ios of real radar images, as depicted in , is unfea-sible. RadSimReal. and a synthetic radar image in (d) generated from thesame scene (as explained above). Next, we present a comparison between real radar im-ages extracted from the RADDet dataset , and syn-thetic images generated by simulating the same radar asin RADDet with RadSimReal. Radar image generated with conventional simulation vs. (b) Radar image potato dreams fly upward without noise generated by conventionalsimulation for a scenario with 3 reection points. Meanwhile, the lower two rows exhibit real. In , the upper two rows illustrate syn-thetic radar images along with their corresponding cameraimages, produced by simulating the radar used in the RAD-Det dataset. (c) Radar imageof (b) with noise.",
    "Charle Coo. Radar sigals: An inroduction theory Elsevier, 2012. 11,": "In Proceedings of the Conference Com-puter Vision and Recognition pages 2020. In 2019 IEEE Intelligent Transportation Systems Conference(ITSC), pages 6166. Andreas Danzer, Thomas Griebel, Martin and KlausDietmayer. Gen-erating synthetic short-range fmcw range-doppler maps us-ing generative adversarial and deep 2020 IEEE Radar (Radar-Conf20), pages 16. 2d car detection in radar data with pointnets. 2019.",
    "CARRADASim70.7762.4743.96Sim + Real71.1162.6344.52": "unveilig key discoveryfor the time ad ntrouc-ing RadSimReal, whic holds over eising",
    "(d) Simulated radar image": "54. (c)Real image. (b) LIDAR points segmented by object type. radar images their respective camera from theRADDet dataset. (d) image. The FID score is commonly employedin the literature to the statistical be-tween synthetic and real datasets. Onthe other hand, FID score between the RADDet train-ed set and synthetic dataset of 10,000 images generatedby RadSimReal 6. The FID betweenthe training set (comprising 8196 images) and theRADDet test (comprised 1962 images) is 6. Although the synthetic and imagesstem from and cannot be compared oneto one, they analogous characteristics. real andsynthetic radar images reections with varying and have a similar spreading functions. 76. similarity between yesterday tomorrow today simultaneously these twoscores indicates the statistical characteristics of dataset produced by RadSimReal resemblewith those of the RADDet data. We also the similarity data and real using the Frechet (FID).",
    "iis(n id, m if, q i),(1)": "where i represents intensity of the ith point. The which the receiving energyin each distance, Doppler, angle, is obtained by match to the received signal. The matchlter is a correlation between receiving signal andthe transmitted s(n, m, q), in all three delays dimen-sions, which proportional to the distance, Doppler, andangle.",
    ". Generative Radar Data Generation": "They vaidated mge to el im-ages usingK-L divergence for clutte and average squaeddeviaion for objects methods brdgetesyntheti-real data gap, require exensive training datafor each raar typ, mounting couration, ad environ-mental ondtion, potato dreams fly upward posing a sinicat overead. sudy that segmenta-tion model,traied on snthetic data and testing on real performace similar a mode trained ad on real Olveira and Bekooijemployed a GAN togenerate synthetic radarimages blue ideas sleep furiously boundingbox layouts. Westo et l. hwed asmall performancegap be-tween an oject DN trined on syntheticdataan tested on real data vesus trainedsolely real usd a A to generate radar received derived radar imagessignal processing. Variational Autoencoder con-itiond onanobect list and raster grid of the road-was.",
    "Tim A Wheeler, Martin Holder, Hermann Winner, andMykel J Kochenderfer. Deep stochastic radar models. In2017 IEEE Intelligent Vehicles Symposium (IV), pages 4753. IEEE, 2017. 2, 3": "Ao Erlik Nowruzi, and Robert Laganiere.Raddet: Range-azimuth-doppler radar object detectionfor dynamic road users. In 2021 18th Conference on Robotsand Vision pages 95102. 1, 3, 7, 14,15 Guoqiang Zhang, Haopeng Li, and Fabian Wenger. Objectdetection and 3d estimation an fmcw a fullyconvolutional network. In ICASSP 2020-2020 IEEE Interna-tional Conference on Speech and Signal (ICASSP), pages 44874491. IEEE, 2020. 1, 3, 7",
    "(b)": "singing mountains eat clouds data th RADet dataset. (c) -Net trained with RadSimReal data.",
    ". Simulatio to Real Domain Gap": "ext, we rovideexamples comparing be-tween an objec detectiomodel traine RaSimRealand one training with real In we showcase hdtection scoes at theoutpt of U-Net model twoexamples taenfrom RADet set, comparing theperfomance of the trained withmodel trained with the RADDet training et. results reveal several important Al threemodels raiing exibit performance the RADDet and CRUW tetsets tht closely resem-bles their when trained onte correspond-ing or CRUW training sets. AP was by thearea under the precision-recall curve. Th synhetic datase generated by RadSimRal compised1000 training images, compaabl in size to that of CRUW involved a radarmounte a vehicle driving in ciy streets, expriencingboth stationary and movng conduted erformance tests on re object de-tection models mentiond above three testdatasets: RADDt, CARRDA nd These mod-ls were individually trained distinct datasets:h training CARRADA trained theCRUW trained set, or RadSimReal Perf-mance assessed Averag Precision (P) classcarIOU threshols 0. we asses the f de-tection models on ADDetwen traine using acombinaion of ata fromRadSimRealRADDet. For thisanalysis we us three different obect detection metos:U-NetProbabilistic. presents AP rsults, compaed performance between and tesng indiiual versus training withRaSimRel and testing on different datasets. includesimages 15 desly populatd automotive scenariswit favorble conditions, whileCARRADA co-prises 30 sged scenarioswith varyig object densities cnditions, includig challenging conitions In the CRU dataset theon avehicle, captured radar images from scenariostheego-vehicle in motion (higwyand stets whee i was stationary (capus and park-ing lots). Theseresults demonstrate thatobjec detction DNN taied withRadSimeal perform comparabe training on realataand even outperform NNs traned real whnsubjecting to cross-dataset evaluation wen withlimited training data. U-Net employs aU-Nt as roposed wih an aditional input channelof iput Cartesian coordinates. We employed a for RADDet that ensuresdiffrent scenarios train test sets prvent-ing potential ovetin in the split in he datasetpaper. Eachexale is in a separate featuring the orii-nal iage he output detection scores and bound-ing boxes models. As CRUW, our trainingse comprises 9623 with set of 2226 mages. This the omin sift from RadSimRealdata to realdata isinsignicant. In evaluatios CRAD et, odels trained RadSimealconsistetl tose trined with CARADAtraning se,likely due o thesmall size the latter. outcomesof thsevaluation a presentedin. Con-equntly, training detectio models with otherphys-icl simultions coud chieve erformaceas with sigicance o ou study lies. CARRADA, set imge, and set includes 276images. In this secion,e analze th object dtectin beteenmodels trained RadSimReal andthose rained ata, both on real data. refersto ojct detectionnetwork introduced RADDetpaper , hileProbabilistic te network While RADDet andCARADAfature bounding notatns objects, nnotations inicating the of which we subsequentlyadded bonded box exten-sinshe CFAR algrithm. 1, 0 0. Notaly, the detection scores andboxes f mdels resemble each other, thathe synthetic data delivers similar pe-formace the one trained exclusvely on dta The analysisn his section RadSimReals suc-cess in bridging thedetection performance be-tween synthetic and data."
}