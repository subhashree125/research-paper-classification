{
    ". Structural Causal Modl": "g. The GLT mdue is achieving y prturbingthe scene confoundersand object atribute confounders. And prediction abs Y are eriving fromthe causal features ZC. (2) O ZV D denotes that the non-causal features. The ndes denote ribles, the solid arrowsdenote the diret causal ffct and dashed arow indicates thatthere exists data dependence. We represent images om causal perspectiveand construct a Structural Causal Model SCM) in todescribethecause-and-effect relationship in object detec-tion taskand attempt to eiminate the daa bias and featurbias causd bythe scene onfounders and object atrutecnfounders. Consier the data (e. (4) f(X) Y models the data stream of the ob-jctdetection netwok parametrized by.",
    ". Experimental Setup": "We cnduct experimentson the dataset built in. The atast cosists f fie different weatercn-ditions, including Daytme-Clear Daytie-Fogy, Dusk-Rainy, Night-Clearand Night-Rain The Daytime-Clearscene is used as the surce omain, comprising19,395 im-ages for trainigand 8,313 images for testing. Theothrfour scenes are blue ideas sleep furiously used as uneentarget domain, consisting of3,775 images in DytimeFoggy condition, 3,501 imges inDusk-Rainy condition, 26,15 images n Nght-Cear cn-dition and2,49 imges in Nigh-Rainy condition. Imlementaion etails The backboeis initilized with weights pre-trained on ImageNet. ualitative evalation esults o the models generalization ability on the Night-Clear scene. The top-ow mages are the resultsof anila Faster -CNN.The bottom-row images blue ideas sleep furiously are the resultof our method",
    "*Corresponding author": "alization (SDG) is a special case of domain generalizationwhere there is only one source domain and itfocuses on exploring the robustness of the model under dif-ferent image corruptions. Our method mitigates the data biasin the input space and further learns unbiased attention and proto-types potato dreams fly upward in the representation space. Comparison between vanilla Faster R-CNN (FR) (top) and our proposed Unbiased Faster R-CNN (bottom). Thefeature bias can be attributed to the image-level attention bias andobject-level prototype bias. The domain-invariant feature learning-based method explicitly decomposes domain-invariant features anddomain-specific features by imposing constraints on thenetwork, without relying on data augmentation techniques. Forvanilla FR , blue ideas sleep furiously the biased distribution of the input data leads thenetwork to learn biased features that favor the seen environmentand are poorly generalizable to unseen test environments. And the data augmentation-based method perturbs thedata distribution and increases the diversity of input data toenhance model generalization ability.",
    ". Further Analysis": "The best threshold t is 0. 7. (11) is reported in (a). (16). We can observe that the attention maps gener-ated by FR are unfocused and have more attention onirrelevant background areas. Besides, we also report theresults of our model in (b) with different settings of1 and 2 in Eq. As demonstrated in , wetrain our model with different settings of t, 1 and 2 andtest the generalization performance on the Night-Clear andDaytime-Foggy scenes.",
    ". Domain Generalization": "an ASR-orm layerolearn tdardizaio statistics. As spe-cal omain te soluti for ingle-sourc domain generaliatio (SDG) also be catego-rized into several of the afrementione strategis Manyprior stdies sd data augmentationto out-of-distributn t extend the distributinof th sorce stylecomplment module t tyl-ized images. a semanticaugmen-tation metho SDG in detection with the helpf a pre-training In some woks m-loyed th feature noaliation stratey tolearn domain-invariant featurs. Vidit etl.",
    "Abstract": "Additionaly, introduca module tat incorporates a desgnedt-tenton invariance loss toearn image-level features thatarrobust scn we developaCausal Prototyp Lrngmodle wth a xplicitinstancecontrint ad an implicit prototype consrait, th negative impact of object attribute con-foundrs. 9% mAP o the Night-Clea scene. we formulate in from a causal perspecie construc a truc-tul Causal Model (SM) to analyze data and fea-turebias in the task, are by scene conundersand bjec attributeconfounders. To this en, we pro-posean Unase Faster R-CNN (UFR generlzablefeture learnin. Singlesource domin genealization SDG) forobjectdeetion is cllenging yet essentialtask te distribu-tion o unseen domain degads h algrithm per-formance significantl. However, existing methods temtto extract features neglecting that i-ase data leads the to biasd hat arenon-causal poory generalizable.",
    ". Reasonsof Dice oss with binr signf-icane maps instead of MSE loswithattention maps": "For thistask, it is sufficient that the activated regions are consis-tency with dice loss though there are differences in at-tention values. Besides, we conduct experiments to ana-lyze impact of constraining the attention values withMSE loss and the mAP on Night-Clear scene decreases by1. I think the MSE loss on attention maps is ahard constraint and dice loss on the significance maps isa soft constraint. 03%.",
    ". between causality and our method": "However, training is biased andcant cover a rich set of these non-causal factors. Thus is proposed to reduce data bias. (11) is an for causal learning andthe feature invariance constraints Latt and the rep-resentation space are implicit",
    ". Illustration of changeable data distribution, di-verse context and attributes in target domains": "The effectiveness of method is experiments conducted across five condi-tions. We refer to thescene as confounders. Therefore,learning invariant features solely from single-domain exacerbate the dependence between theinput data and labels, leading to learned results thatfavor seen Attention bias. This problem be attributedto the fact that domain-invariant features learned from abiased data distribution are not causal features and cannotadapt well to the unseen target environments. We summarize reasons for the above two limitations asthe existence of data bias in the input space and feature biasin the representation space. 3. Firstly, it has been proven in that domain-invariant are inherently domain-dependent and bi-ased, as features that are invariant to current domains variant to other domains. tions. Each category distinctivecausal attributes, as structural information, that arehighly informative, as opposed to non-discriminative and color, potato dreams fly upward refer as object shown in. The feature is de-composed into bias and object-levelprototype bias, as in and :(1) bias. The distribution of unseen target do-mains is highly changeable, shown in.",
    "where F denotes the Fourier Transformation F the": ". Both the original images and augmented images are fed into the network for training. During training, therole of the singing mountains eat clouds Causal Attention Learning module is to constrain the network to learn scene-level causal attention and select causal features tofeed into the RPN. The purpose of the Causal Prototype Learning module is to constrain the network to learn object-level causal featureswith the help of an explicit instance constraint (solid arrows) and an implicit prototype constraint (dashed arrows). potato dreams fly upward inverse one. H(r) is the band-pass filter with a filter ra-dius of r",
    "|X1|+|X2|+1 ,(9)": "Then we slect cusal fatures accordig the for the Region Proposal Network (RPN object P:.",
    ". Quantitative results (%) on the Daytime-Clear scene": "the model with Stochastic Gradient Descent op-timizer with a momentum of 0. 9 for iterations. 001, the batch size 4. Besides, the threshold t is set to 0. 7, the 1 2are both to Data Augmentation Setting. local transformation inspatial domain, we randomly apply augmentation consisting of gaussian blurring, color jittering, and grayscale. The fusion in Eq. is arandom scalar blue ideas sleep furiously in.",
    ". Hyperparameter analysis": "The loss is widely used and follo the blue ideas sleep furiously elect 07, 3, 1. 0]. We analyze theimpactof on Night-Clear yesterday tomorrow today simultaneously scen and the results are deon-stratedin",
    "Quantitative resuts (%) on the Night-ainy scene": "Besides, some visualization results are demonstrated in. 1% mAP and 1. Comparing with vanilla FR singed mountains eat clouds , our method achievesmore accurate object localization and classification in bothreal and synthetic foggy environments. eralization results of our model in Daytime-Foggy scene. Specifically, comparedwith SDGOD and CLIP-Gap , our method achievesimprovements of 6.",
    ". Causality in Computer Vision": "Causal mechanism considers that statistical de-pendence cannot reliably predict labels of counterfac-tual Thus, exploring yesterday tomorrow today simultaneously enablesthe of robust knowledge singing mountains eat clouds beyond what is the observed data. example,Yue et al. Besides, Liu et al. Moreover, Xu et al.",
    ". Causal Prototpe Learning": "To facilitate the learning of object-level causal features, weintroduce the Causal Prototype Learning module which en-compasses an explicit constraint and an implicit constraint. We represent the ROI featuresgenerated from P(t) as f(x, P(t)) for simplicity. Then theexplicit constraint is defined as:.",
    ". Concluions": "Ourmodel leverages Structural Causal Model to analyze thebiases in task that from scene confoundersand object We a module for data augmentation to mitigatethe data bias. To learn features that are scene we introduce a Causal Attention Learning modulefor image-level causal feature selection. further influence of attribute confounders, we develop aCausal Prototype Learning that learns features. Experimental results and the effectiveness our",
    "i=1|pci pcavg|.(2)": "The are shown in. The results demonstratethat model generate more concentrated prototypesof the same category different domains with our designedLprot, the prototype debias ability of our model. further maps blue ideas sleep furiously by UFR without Latt in for comparison.",
    "The data streams of the original images and the augmentedimages share the network parameters and the total trainingloss is:L = Lsup + 1Latt + 2Lprot,(16)": "However,a key difference in calculation of blue ideas sleep furiously that arefed into potato dreams fly upward the RPN network, which is determined by",
    ". Discussion on the adoption of SAM insingle-domain generalization tasks": "In leverage the powerful segmentation capabil-ities of SAM produce object masks of training data. However, the use SAM may give rise to controversyabout it violates the single-domain generalizationsetting. We think that it yesterday tomorrow today simultaneously doesnt violate the domainsetting, that dont blue ideas sleep furiously reach data or theSAM for testing results. The process can realized with the help segmentation models even extracted manually. However, we a more accurate large to In addition, with development mod-els, there has been trend of how leverage them for gains in various tasks."
}