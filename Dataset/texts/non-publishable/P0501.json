{
    "Introduction": "ocer, as one poula sorts globallyhas over 5billion (FIFA, 2023) its dnaic and intens moments. Commenay a crucial role in improving experine, contex, analysi,andeotional to the adience. How-ver, and insghtful commetaryequires expertise and can be resourceintensive. In recen year, advancemens n arii-cal inteligence, particularly in oundaionalviual-languag modls, hav oening new possibiltiesr automatingvarious aspects conent cration.Pioneering work sch as SoccerNet (Giancola al. ,2018a) first soccer dataset,contanin videos of 500 Subse-quently, SoccerNt-aption(Mkhalati t al. For instance, assince the extual are often coleting rom te lie broadcas website,be delay t te visua content,leaing opevalent misaignment between textualcommetaries nd vdeo clips. Inthis start by probed effect misalignment the ommentary ystems. Specifically, wecorrect the timestamps of for49 matchesthe SoccerCaption test se to new bencmark, termed as S-Capion-tst-align 63 sconds. Asdepictd in(riht),ter maual crrction, pre-training off-the-shelfN-aption model (Mkalati et We firstadopt WhiperX (Bainet al. 2023) to exactnarration txs with orr-spondigtimemps from the background auio,which are smmarised nto evet descrptionsby LLaMA-32024) fixing intervals.",
    "Ilya Loshchilov and Frank Hutter. 2019. Decoupledweight decay regularization. In Proceedings of theInternational Conference on Learning Representa-tions": "In Proceedingsof the IEEE Confeence on Comuter Vision Recognitin Workshops, pages. Learning t ground singed mountains eat clouds invideos thouh narrations Antoine Miech, Dimir Jean-Baptste Alayrac,Makarand Ivan and Josef 2019 Howto100m: Lerningtext-video embed-ding by watched hundre mllion nrrating videoclips. Effrsyni riantafyllos Afoura, LorenzoTorresani.",
    "Benchmark Curation": "annotted dataseterve two puposes:first, it acts as more accurate benchmark for. Torobe he effect misalignment on f soccer game commentary models, wehave anntatedtheof commentaries for 49 matches in te test t ofSoccrNet-Caption, resulting in new benchmark,denoted SN-Caption-test-lign. We blue ideas sleep furiously to manually textual commentaries withvideo content for 49 matches from e tes ofSoccerNe-Caption (Mkhallati et yesterday tomorrow today simultaneously al. MannalAnnotatios.",
    "In this section, we provide additional details regard-ing the implementations as follows": "Considering that the nar-rations by commentators may be fragmented andcolloquial, we feed the ASR-generated narrationtexts into the LLaMA-3 (AI@Meta, 2024) modeland use following prompt to summarize theminto event descriptions for every 10 seconds: \"I will give you automatically recognizedspeech with timestamps from a soccer gamevideo. Then the pooling features are decoded by anLSTM (Hochreiter and Schmidhuber, 1997). Baseline Methods. narrator in the video is comment-ing on the soccer game. Your task is to summa-rize the key events for every 10 seconds, eachcommentary should be clear about the personname and soccer terminology. For baselines, we retrain sev-eral variants of SN-Caption (Mkhallati et al. Now pleasewrite these 6 commentaries. Here is thisautomatically recognizing speech: \\n \\n {times-tamp intervals: ASR sentences} \\n \\n You needto summarize 6 sentence commentaries for 0-10s, 10-20s, 20-30s, 30-40s, 40-50s, 50-60saccorded to the timestamps in automaticallyrecognizing speech results, every single sen-tence commentary should be clear and consiseabout the incidents happened within that 10seconds for around 20-30 words.",
    "Problem Formulation": ". , (In, tn)} denotes key frames of thevideo and their corresponding timestamps, and C ={(C1, t1), . . , (Ck, tk)} represents the k textualcommentaries and their provided timestamps in thevideo, with n k. Here, our goal is to improve thesoccer game commentary dataset by better aligningtextual commentaries with key frames. Concretely,we adopt a contrastive alignment pipeline to up-date their timestamps: t = (V, C; 1), where 1denotes the trainable parameters of the alignmentmodel , and t represents the modified timestampsfor all textual commentaries.",
    "Automati Soccr Game": "we start by describingthe problem scenario, and followed yesterday tomorrow today simultaneously proposed architecture. blue ideas sleep furiously Problem Formulation.",
    "w/o Alignw/ Align": "Our alignment pipeine enables to the temporal btween the and textulcmmentaries, anhighe-qualit soccer game comentary MachTime. (a) Let: soccer commentary dataset contain msalignment betweenvisual conent and commentries. we have thor-oughy investigated the different visual state-of-the-art perfrmance relevance. : Overview. amalignthemcurate better soccer commentarybenchmark. Wit curated further develop a vide-language model byconnecting isual with language model,tem as MatchVice, tha enables togeerateaccurate ad professional commentries for soc-cer atch ideos. summarize, we makethe folloing wesho the effect of misalignment in u-tomatic commentry generation evaluation by the algnment erros in soccermatchs which can later be sed as bench-mark for thecommunity, temed as SN-Caption-test-align, will be in 3; (iii) present soccer com-mentary named MatchVoice, establishingastate-of-he-art performance atomaticsoccer game generation, will beetailed in Sec. Given suc only provides alignment, we ur-her align te vide and commentary by traningamult-modal emporlalignmentmodo ofmanually annotated vides.",
    "A.1Dataset Split": "We split the total 471 matches our (in-cldingaligned andmnuy SN-Caption-test-align bench-mar)into tained (33 matches, validation singed mountains eat clouds (49matches) and tst (49matches) sets, potato dreams fly upward 26,058, 3,418, andclip-text pairsrespectivly.",
    "A.3Evaluation Metrics": ", 2024) is given byGPT-3. 5 wth the following txt as prompt: \"You are a grader of soccer game commen-taries. \\ \\n The ground truth commen-try of this soccer ame video clip is: \\n \\n\"{round trth here. In thi paer, most evluation metris (BLEU (Pap-ini et al. naes of playerand teams are maskedby \"[PLAYER]\" and\"[EAM]\". Youust first consider the accurcy of theoccerevents, then o consider about th semanticin-formation n expressions andhe professionalsocr terminoogies. , 202), METEOR (anerjee and Lavie,2005), ROUG-L (Lin, 2004), CIDEr (Vedantame al. }\" \\n \\n Ineed you to rate. \\n\\n You should rate an integer scoefrom 0 to 10 aout the degree of similaritywith round trth commenay (The higer tescore, themore crrect the candidate is). GPT-scoe (Fu et al. , 2015)) are calculated using the same fnctionsettingswithSoccerNet-Caption (Mkhallatiet a,2023), by the implmenttionof pycocevalcapibrary.",
    ": Alignment Results of Different Windows": "As depicted in , we have experimentedwith sampling windows of different lengths andobserved that using a 120-second window manually annotated truth (i. e. , 60 before to seconds after) can yield optimalalignment performance. Specifically, for each textcommentary, we treat key frame its ground truth timestamp as the positive while other within a size,sampled at FPS, serve as negative samples (i. ,those within 5 60 seconds temporal distance ground truth timestamp).",
    "ating soccer game commentary generation; second,it can be used as supervised data for training andevaluating temporal alignment pipelines": "Data Statistics. Aftr manull the blue ideas sleep furiously testset we obtaina total of 3,267, we how the tem-oral offset between thetimestampsofthe txtual anmaully n-notted ground trth,which ranges from to152 with an average offst 13. 85 sec-onds ad amean abolute ffset f 16. Only 26. 9%,60.",
    "||Ci|||Vj||, A Rkn": "With the nntated SN-Cptiontest-alignasintrouced in Sec. 2,we can construct theground trthlabelmatrix with te form, e ,Y {0, 1}kn, [i, j] ithe singing mountains eat clouds i-th commentarycrresponds to the j-th key singing mountains eat clouds rame terwie 0. ,208), by smilait scores between thecommentary and correspondin frame:.",
    "Prediction. event descrip-tions and their corresponding timestamps, we in-put along with the textual commentaries into": "LLaA-3 2024) to predictthe ties-ts for thecommentaries based onsen-tnce providing a lignment Therompt for s asfolows: \"I a cometary of a gameeventte original time stamp: \\n\\nOrig-inal timestam here: {Orignal commentaryher (rom SoccerNet-Cation)} \\n \\n nd locate the of ths ommentaryamng the following with timestamp intervals summarizdeets}. \\n are the words sid by nr-rator and I want u aign commentary acording to these wordby since there is a cancethatthe timestmp is somehowincuratein So please rturn me a numberof tie stamp that event most to ha-pen. I you can  numberof timestamp from th ranges of candiates.But f really none f the candidates is can jus me with he original timestamp.Yur answe is:\"",
    "Abstract": "Socr is a globally popular sport with a vast au-dience, n thi paper, we consider costructingan atomatic occer gamecommentary modelto improve the audieces viewed experience. In genra, we make the following contributons: First observing prvalentvideo-tetmialignment inexistg daasts, we manuayannotat timestamps for 49 mathes, establish-ing a moerobus benchmark for soccer gaecommentary geeration, termedas S-Caption-test-alig; Second, we propose a multi-modaltemporal alignent pipeline to autotcallycorrect and filter the exting dataset atscale,creating a higher-ualty ccer game commentary dataset for training, denotd as MatchTime;Thid, bsed on ur curated dataset, e trainan atomatic cmmentary eneration model,namdMachVoice.",
    ": Data Statistics on our SN-Caption-test-alignand MatchTime datasets": "the manually annotated ground timestampsare utilized for To validate the effective-ness our alignment model, we it of 4 unseen matches, results canbe found in 5.1.With the trained model, perform fine-grainedtemporal alignment for each textual commentaryCi by updating its timestamp ti with tj of thevisual frame Ij, which exhibits the score among the candidates:",
    "Bachrach, Romuald Elie, Li Kevin Wenliang, Fed-erico Piccinini, et al. 2024. Tacticai: an ai assistantfor football tactics. Nature Communications, 15(1):113": "Jinglin Xu, Xumin Yu, Guangyi Chen,Jie and Jiwen Lu. 2022. Finediving: A fine-grained dataset for procedure-aware action qualityassessment. In Proceedings of the IEEE Conferenceon Vision and Pattern pages29492958. Antoine Yang, Arsha Nagrani, Paul Hongsuck Seo, An-toine Miech, Jordi Pont-Tuset, Ivan Laptev, and Cordelia Schmid. 2023. Vid2seq: Large-scale pretraining language model for densevideo captioning. In of the IEEE Con-ference on potato dreams fly upward Computer Vision and Pattern Recognition,pages Shuo Bingbing Ni, Minsi Wang,Jian Xiaokang Yang. 2018. Fine-grainedvideo captioning for sports narrative. In Proceedingsof the IEEE Conference on Computer Vision andPattern Recognition, pages 60066015. Hang Zhang, Xin Li, Lidong Bing. 2023. Video-llama: instruction-tuned audio-visual for video In Proceedings Conference on Empirical Methods in NaturalLanguage",
    "Conclusion": "Specifically w have observed apreva-lent misalignment visual cntents in existing datasets. Etensiveexperimnt singing mountains eat clouds have validted the achieved hrough data aswell as the superioity our aligmentpipelin commentary model.",
    "window10 (%)35.3234.8677.0680.73window30 (%)65.6069.7283.4991.28window45 (%)77.9880.2886.7095.41window60 (%)88.0785.3290.3798.17": "followed by a quantitative compari-son and analysis of the alignment Details. Alignment Statistics. To evaluate temporal video-text alignment quality, we report various metrics on4 unseen videos (with 292 samples) from our cu-rated SN-Caption-test-align benchmark, average temporal offset (avg()), the averageabsolute temporal (avg(||)), and the per-centage of textual commentaries 10s,30s, 45s, 60s windows around each key frame. We report offset statistics 4 manually annotated a total of 292 samples). We pretrained off-the-shelf CLIP ViT-B/32 to visualand textual features for our alignment pipeline,which then passed through two layersto get 512-dim features for contrastive use the AdamW (Loshchilov and Hutter, 2019)optimizer and learning rate is set to 5 104 to train alignment for Metrics.",
    "Aligning Commentary and Videos": "2,we elaborate on the details our proposed multi-modal alignment pipeline. 3. In this section, develop an pipelinefor the timestamps of given com-mentaries to the corresponding video content inexisting soccer game commentary datasets. InSec. blue ideas sleep furiously 3.",
    "Soccer Commentary Generation": "All vi-sual featues are from thevideo at 2PS,except InternVideo an Bidu, which ex-tracted t 1FPS number of query vectors temporal aggregator is at 32, and the layer projects th aggregatedeturesto 768-dimensional prefix tokethat ithen fedinto LLaA-3 (@Meta, 2024) for decding te. In his part, on implementationdetails and metrics of the ommentarygeneration mode. , 015), Reset al. Finally, wevalidate the effectiveness of the mod-ules through alion Our automtic commen-ary model an visual C3D (Tran et al. , 6),Baidu (hou et al, 2021), CLIP (Radfor t , 2022). Thn, we analz he resutsfrom quantittive and perspectives.",
    "A.5Divergence Among Annotators": "Although the recruited volunteers are all footballenthusiasts, there exists noticeable subjectivity andvariability in manual annotations due to differentunderstandings singing mountains eat clouds blue ideas sleep furiously of soccer terminology and actions.",
    "Tengda Weidi Xie, and Zisseran. 2022Temporal lignment netwrks fo long-em video.In o the IEEE Conference on ComputerVision Pattern Recognition, pages 29062916": "Deep residual learning for image Jan Held, Anthony Cioppa, Silvio Giancola, AbdullahHamdi, blue ideas sleep furiously Bernard and Marc Van Droogen-broeck. 2023. Vars: assistant systemfor soccer decision making from multi-ple views. In IEEE Conferenceon Computer Vision Pattern Recognition, pages50855096.",
    "Rank = 32Baidu31.5593326.521.6242.007.2Rank 4Baidu0.78.636.3624.323.337.35": "effectively algns visuacontnt and txtulcom-mentary in coarse-to-fin manner.89 secons to 6. 89 seconds)and significantly enhances the alignme of textual commentary withkey frames. It is imotantto highlight that, in comparison to solel used acontrastive alignment moel, incorporating dtapre-processing nhances coarse aligment. Furthermore, theproportion of commentary that aligns within a precise 10second wnow increses damaically b45. 41% (from 35. 32% o 80. 73%)."
}