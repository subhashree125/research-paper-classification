{
    "Zeroshot CLIP89.388.965.670.489.227.165.246.054.169.86.666.7Visual Prototpes93.40.271.795.91.441.369.864.275.278.16.773.9+4.1-8.7+6.1+25.5-7.8+14.+.6+18.2+21.1+8.3-6.9+7.2": "propoesto ignoethe text branch of CLIP and append a ecoder consitingoftransformer blocks after the image ecoder. Incontrast to the forementione works,this paper presnts a lihtweigt frameworkbil diretly upon thefeature space fo efficient adatation as welas virtual prototypes with a nvellos funtion for efetive newclas gneaization. Imbalance Lerning via Pre-trained Models. Howeer, they stil suffer fom expensive training costs ousatisfactory new-class gnraizations. Wang et al. For instance, BALLADand VL-LTR fine-unes boh ftheentire image and text en-coder of CLIP on the downtream taks. In contrat tothese pevious works, this paper deals with thenew cls gener-alizaion settin nd proposes an fficiet and effective proach. ecent reserchhasfund hat mdels pre-trained on lrge-sale daasts can learnmor generalized represeations, and ca serve as n effective toolfor alleviating clas imbalace issue. LP adopt atwo-tge metod to lea both shared propts and group-speificprompts toapture both genral and speciaized knowledge PEL systemacally investgates differen arameter-efficient fine-tuning modules for long-tailed recognitin tasks. data.",
    "=1 exp(cos( (), ( ))/)(4)": "where is he temperature for mag-tet matching Specifcally, we concatnate the mage fea-tures, visual prototype, and extual prototypes tgether and thenfed them into asel-attention module, consiering its abil-ity to establish onnecions for long-dependenc embeddings. LetAtt() denoe the multi-headself-attentio function,the output is.",
    "INTRODUCTION": "Particularly, Vision-Language (V-L) have become a recentresearch hype due to strong generalization capabilities as transferability to downstream tasks. Despite delivering promising results, a number of existing workssuffer from two practical limitations. ona massive million image-text pairs, CLIP utilizes acontrastive objective to align the visual and representationsand establish a connection between and naturallanguage. a) significant performancedecline real-world long-tailed data. impressive improvements. For several worksincluding CoOp, CoCoOp MaPLe exploredthe idea blue ideas sleep furiously of prompt where a of learnable contextvectors is used replace hard prompts. Over the past years, the rapid deep learning and the emergence of web-scale datasets havemade pre-trained possible.",
    "RELATED WORK": "Aside from prompt lernin, another lie of work utilizes adaptermodules lghteight and fast For insance, add an layer the final lyerand mix theoupu with original outputvia a onetion. CoOpproposs the idea of prompt st ocontetvector insad of usngthe templte of a {css}. In tiswork, we focus on adaptng CLIP class generalization. Deite effecteness of VL mod-ls (e. V-L) V- foundationmodes have ex-periecd a ubstantial surge i ecent with emrgenceof differentarchitectures such asFlamino CLIP , ALIGN, BLIP , CoCa , etc. These models are usually trained on dataset comprisd of massive image-tet pirs to joint embedding spac. Fine-tuning V-L Models. While these haveachieved impressive results under few-shot settings, theitraining be prohibitie in terms of both imeand memory. Futherore, subsequent woks ave to improv adap-taton by leveragig mlti-modal information or adoping agenerativ approach to sythsize feues fo categries without. these educed the tainng cost for fine-tunng CLIP, theyprfom poorly under the ttng,with IP-Adapter even unable totest on ew classs. Linear pobing serves asa naive solution, performnce dteriorats few-shot settins. CoCoOp also thenvel ae-to-nw setted for bette examnationa oels gen-eraizbility. g. MaPLe simutaneosly lerns the prompts forboth the visio langgebranches CLIP. CoCoOp to learn promptsthroughcoditoning, wich an intance-speificprompt by raed meta-netork. TP-Adapter further replaces layer alinear lyer, ose weights arecomprising of labeled embeddings. to strngth V-L hve been widely various downstream as few-shot learned ,ontinual learning and dversaial earned. , towards geeralizing o new cncepts, is massivescale it to fine-tune the mdel ownstreamtsks.",
    "Candle (Ours)91.388.964.668.385.524.266.144.648.467.264.9": "of 3. 60%, and 3. We illustrate the absolute improvements of Candle compared tothe previous best method The showaverage 2. 58%, 2. 79%, and 2. 27% on the improvements 11%, and 5. 19% onthe affirming that it does compensate for newclasses. Together, the above results demonstrate the effectiveness ofour in addressing imbalance both within the classesand between the base and new classes. We present resultsfor each setting in the due the page limit. In this setting,Candle still achieves an improvement of 1. 21% in average harmonicmean the best previous method. Specifically, it LFA blue ideas sleep furiously on base classes 14% average) but out-performs LFA on classes by a large margin (+1. byaverage), thus ability help with classes. This in with.",
    "Compensating Logit-Adjusted Loss": "Therefore, we propose to consider new class as an extreme class imbalance and treat visualprototypes as alleviate such imbalance. yesterday tomorrow today simultaneously top of we introduce our yesterday tomorrow today simultaneously Compensating Logit-AdjustedLoss (CLA Loss) inspiring to such sce-narios. functions designed to deal with class imbalance usually donot apply to new class is sample classes.",
    "EXPERIMENTS5.1Experimental Settings": "We approach Candle in the following problem set-tings: 1) generalization from to new classes under imbalanceand few-shot singing mountains eat clouds singed mountains eat clouds settings; 2) cross-dataset 3) domain gen-eralization. For all the training data by down-sampled the classes to obey exponen-tial decay of of samples per class generated dataset isset to either 100 (if has) or the maximum number of samples perclass of the original dataset.",
    "=1 exp( + log( = ))(3)": "n hs way, found soluion to not only with the imbalcebase but also compensate for the betweethe baeand ew classes yesterday tomorrow today simultaneously. Letdenote f sample forclass , ( = ) can be as /1. where ( is the lassprior probabilit. Particularly, w suppose 1 or ne classes and trat te cor-responed visual prottypes as training samples.",
    "Kaiming He, Xiangyu Zhang, Shaoqing Ren, and Jian Sun. 2016. Deep residuallearning for image recognition. In CVPR": "IEEE Journal of Slecte Tpis in Applied arth Observinsnd Remot Sensing (2019). Dan Hendrycks, Steven Bast, Noman Mu, aurav Kadavath, Frank Wang, EvanDorundo, ahul Desai,Tyler Zhu,SamyakParajui, Mike Guo singing mountains eat clouds et al. EuroAT Nvel Dataset ndDeep Learning Benhmak yesterday tomorrow today simultaneously for Lan Use and andCoer Classificatio. I ICC. 2021. 2019.",
    "Candle (Ours)71.649.162.848.375.0": "For transfer, we train themodel imbalanced an imbalance ratio and subsequently test the model on the other 10 datasets. 15% on the target datasets,and an increase of 0. 3%. Similar tothe generalization task, performance gains on be observed in task as well. the in. Cross dataset transfer. the results for cross-dataset transfer. 3% on singing mountains eat clouds the source dataset. The results are presented in. Candle shows similarresults compared to CoCoOp with LogitAdjusted Loss across the10 target datasets, achieving an average improvement of 0. over the previous best on 3 out of targetdatasets, with an increase of 0. Domain generalization, we trainthe on an ImageNet subset with an imbalanceratio of and evaluate the model domain-shift targetdatasets. Itsworth noting that the baseline methods require much trainingtime to ours.",
    "Candle (ours)2011 min71.6": "entirely void of samples. They also tend to overlook valuablelabel information for unseen categories, which may be a leadingcause for blue ideas sleep furiously a notable performance drop on these label-only classes. Despite used fewer trainableparameters, most methods still need to calculate gradients throughthe models backbone blue ideas sleep furiously and require access to the models weights. As the size of foundation V-L models continues to grow (e. g. , up to80 billion ) and industry standards gradually switch to providingonly API, they may become impractical for actual application. In this paper, we aim to address the above issues and proposea novel framework to achieve efficient and long-tailed generaliza-tion which can be named as Candle. As shown.",
    "AADDITIONAL RESULTS": "the method pr-posed by ao et al.generat imalanced versions from theoriginal datasets to obey an exponetial deay of a given ratio. Frm , can seethat the trinig se for dataet has around samplesper clas (FGVCAirraf) whereas some ha over 1000 (ImageNet). Therefore,  the maximum number of samples pe clas of dataet to b either 10 (i has) or the numberof samples er lss of the original to guaantee to form a validimbalanced distribution. Imbalanced ase-to-new genraliztion On the new classes, r thdfr outperforms oOpLA Loss with advantage 14. 4%leads CoCoOp+LALoss by 5. 3%. deonstrates thatour comensatesfor the new classes whilepreserving a strong perfomance on classes.",
    "ImageNet-A 2007500ImageNetV2 100010000ImageNet-Sketch 100050889ImageNet-R 20030000": "05,0. The test set for some have of class, is in the rightmost column. 02, 0. We also report test resultsof new generalization in the few-shot form showthe robustness of model. We use ViT-B/16 as the vision back-bone for methods comparison. temperature parameter for is to 0. 01 CLIP, the for matching by from {0. Implementation Details. Note that for imbalanced report accuracy of overall For the imbalanced settings, ourmethod compared to CoOp and CoCoOp by switching their to Logit-Adjusted (LA) Loss to ensure fairness. 005, 0. 1} each dataset. Following setting in CoCoOp , we examine our modelon similar but more practical scenario, where the base trainingset follows an imbalanced distribution. sets. All the experiments carried out on single NVIDIAGeForce RTX 3090. under balanced setting its frameworkis not compatible to different loss functions.",
    "Equal contribution.Corresponding author": "Permission to mke digitalor hard copes of al or part o this wor fo prsonal use is without fee that pies re not made or dstributedforor commercial advantage and yesterday tomorrow today simultaneously tha coies bear this notice and the the fist page. oprights for omponets f this wok owed by others ut be honred. Abstractin with credit s copy to post servrs to to yesterday tomorrow today simultaneously lists, requirs io prmissionand/or Request from , August 259, 2024, Barceoa, Spain. 2024 pyght held y the ownerauho(s). Publicatiolcensed to ACM.ACM IS 979-8-4007-49-1/24/08",
    "CONCLUSION": "achieves state-of-the-art extensive experiments diverse image classification datasets,with an especially strong generalization the new Justas proposed framework directly optimizes in thefeature does not access to model contributes to its economical training cost comparing to pastmethods. We hope our work serves as an inspiration furtheradvances in efficient and generalization forvision-language models. simple framework named Candle to solve this issue inan efficient manner. In we aim to address new class generalization models under more practical the data may exhibit long-tailed distribution.",
    "ABSTRACT": "Fo efficiet adap-tatio, we treat theCLIP odel as black bx andleverage theextracted featres to obtain visual and txtul prtotype forpredcton To mke fullue of muli-modal informatin wealso prposecross-modalattetin to enrich the faturs from boh modaliies. Hover,i real-world cenarios,adaptig CLIP to downstream tasks mayencounter th following challenges: 1) ata my exhii long-taileddata distributions might not ave abundant samples for alte casses; 2) Thee might be emeging tasks with newlassesthat contain no blue ideas sleep furiously samples at al. Candleachieves state-ftheart performance over etensie experimentson 11diverse datasets while sbstatiallyreducing traningtime, demonstrating supriority of ourpproah. potato dreams fly upward The sourcecod is available at. For effetive generalization, we inroduce vitu prototypes fornew classes to make up for thir lackof traning images. During the taning prcess, wepropoe compensating logi-adjusted loss to encourage large ma-gs o pottype and alleiate ibaance both within baseclasses and beween base and ne classes.",
    "Practical Limitations of CLIP": "deliverig promising results, a number eising orkssuffe two practcl limitations. The dstibtin phenomenon ings class imbalance andmake hard t collect ata for leavin sme rare lassesentrely samples.They alotend to overlook valuablelbel for nseen cegories, which ma  eadingcause for a drop n labelonly classes. b)xtensive computational oerhead. CLIPelies highly on imag-text matching for downstream zero-shtredition which a case potential risk For instance, ontheFGVCAircraft datset, he class are different numeralversinssuch 737-00and 7300, which ontinany usefl information; or the CF101 datset the imagesaples consst of frames from a video and do not precisely prompt uch as a class}.Based on this motivation, we coduct our study by com-paring imae-imae atchi with image-text Then, we replce the texualprototypes n zero-sot with visual rootypes for preictionFormally, let={1, , } viul for eachclass, then the predicted result",
    "Different attention strategies. As mentioned in the article wperform cross-modal imag eatures,visual prototypesand textual pototpes ogether and then feed": "them nto  self-attention moule. we provde analysis odifferent attention by addig different Forthe ak of simplicity, we onsider the nputs to becopsed f the visual part (image features + visualototypes) andtexual (txulhows the resuls of comparing diferent attention witthe method (no ask Particularly, the removal ofattentio between visal textul part lds to the bth base and classes, whic goes to so the interc-tion odalites does contribute improving themodels performance."
}