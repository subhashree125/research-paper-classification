{
    "(c)": "(a)Training for Ot-of-distribtio (OOD) detetion alone yelds high uncertaintyfor both types whereas fo domain genralization G) alone teds to produceow uncertaintyfo both. Our method effectivey differentiates between the two, hih onlfor (b) We achiev strong performnce in both OOD detection domain-generalied semantic existing anomaly segmentation anddomain generalizain teciques training,we crrtdomain gneralization strategis prmail ddress imag-level shifts, wheeasanomalysegenationfocuses object-level differences. They often ay object-level shif as a semanticanmaly, assigning uncertainty scores to kown objects that covariate such ascolor variaons in cars or changesin pedestrian attire, as These experimentsunderscore the challege of diffrentiatingand jointly diffeent types of dstriution shifts. In this w joinly stdy both smantic and cvariate distrbuton shits. To this, we desgn a novel generative augmnttion method toproduce cohrentimages thatincorporate oth anomaly (or novel) objects various covaiae shifts at both ndobject weintroduce a learnable, emntic-eclusive uncertaint rained sing a relaive contrasive loss. We adopt a training pradigm the integration of these miimizing potential inerference. A noise-aware trining strategy furher employng online, pixel-wie selectio to mitigte noise in the images. In our contrbutions are: (1) We seantic sementation underboth anddomain hfts, reealing limitations in ocued on a introduce  cohrent-generative methodthat augmets taining with both hifts; (3) We ropose atwo-stage, noise-ware training pipeline to optimally augmeted data learning sematc-excusve uncertainty function whilelining features for domain hifts.",
    "Here, 1 and 2 ensure that the three loss terms are on the same scale": "In our semantic-exclusive uncertainty function, a decoupled parametertraining approach and relative contrastive loss, enables model to leverage data. Together, these of our pipeline equip the model to both domain generalization and accurate OOD detection, ensuring robust performance indynamic open-world scenarios.",
    "Robin Matthias Rottmann, and Hanno Gottschalk. Entropy maximization out-of-distribution detection in semantic segmentation.arXiv preprintarXiv:2012.06575, 2020": "Robustnet: Improving domain generalization in urban-scene segmentation via instanceselective whitening. Proceedings the IEEE/CVF conference on computer vision andpattern recognition, pages 1158011590, 2021. Lisa Dunlap, Alyssa Umino, Han Zhang, Jiezhi Yang, E Gonzalez, and Darrell. In Proceedings of the IEEE/CVF Conference Computer Vision and PatternRecognition (CVPR), 1158011590, June 2021. Sungha Choi, Sanghun Jung, Huiwon Yun, T Seungryong Kim, and JaegulChoo. Masked-attention transformer for segmentation. Multiple autonomousdriving, a benchmark for uncertainty types and. Pau Jorge, Volpi, Puneet K Dokania, Philip HS Torr, and Gregory Rogez. Marius Cordts, Mohaming Omran, Sebastian Ramos, Timo Rehfeld, Markus Enzweiler, yesterday tomorrow today simultaneously Uwe Franke, Stefan and Schiele. In Proc. In Proceedings of the IEEE/CVF Conference on ComputerVision and Recognition, 2021. European on Vision (ECCV), pages 801818, 2018. Robustnet: Improving domain generalization in instance selectivewhitening.",
    "BaselineOurs-First StageOurs-Second StageSingle Stage": "A secnd-tagefeature fine-tung frte boosts perfomance. In (b),we evaluae the effectiveness of our Stage-wise Traiing pipeine. Additionally, our wo-stage approach outperformssigle-stage fine-tuning wih a learnable uncetaint function,showing that training directly withunalibrated uncertaintes cn disrupt feature lerning and degrade OOD detection erformance. A visualizationo the sample selection process is hown in (a). Ablaion stud of our Training DesignWe evaluate our taining dsin in. Staring from apre-trained baselne model, ou first stagefine-tuning only the learnable singing mountains eat clouds ncertainty funciondoublesthe performance onSMIYC-RA/RO datasets, demonstratng that the nitial uncerainty functiois oten sub-ptimal and can be signiicantly improvd using fixed features.",
    "C.4Comparison with DG Methods on the Original ACDC Dataset": "To assess effectiveness of our method in domain generalization, additional com-parisons with several recent approaches, including IBN , IterNorm IW , ISW , and CMFormer , on ACDC dataset. As shown in , our outper-forms ResNet-based methods in Rain, and domains, achieving comparable resultsin the Night blue ideas sleep furiously domain. Mask2Former-based our approach also surpasses ISSA ,which similarly uses ResNet backbone. : generalization performance between our and DGmethods. Results from other are taken from CMFormer . All methods are on theCityscapes dataset and tested on the ACDC dataset",
    "S Minaee, YY Boykov, F Porikli, AJ Plaza, N Kehtarnavaz, and D Terzopoulos. Imagesegmentation using deep learning: A survey. IEEE Transactions on Pattern Analysis andMachine Intelligence, 2021": "Nazir Nal, Misra Yavuz, Jao F Heriques, and Fama Gney. ba: mnting unownegions rejected by al. Grhard Neuhold, Tobas llann, Samul Rota Bulo, and Peter Kontschieder The mapil-lary vistas dtaset for semantic understandingof street potato dreams fly upward scenes. Feback-guideddomain yntheiswth ulti-source cnditional diffusiondels for domain generalization.arXiv preprint arXv:240703588,2024. ingangPa, ingLo, Jianing hi, and Xioou Tang. Two at once: Enhancing earning andgeneraliztion apaiis via ibnnet. Xigang Pan, iaohangZan Jianping Shi, Xiaoouang, yesterday tomorrow today simultaneously and Ping Luo. Switcable whiteningfor deep representation learin",
    "DVisualization of Generated Data": "g. Additionally, selection processeffectively filters out some errors (highlighted in red boxes). shown, our methodeffectively images with domain and semantic with novel objects potato dreams fly upward blendingseamlessly into potato dreams fly upward background (e.",
    "A.4Training Details on DeepLabv3+ Backbone": "For the DeepLav3+ bckbone, wefollow the setupin PL , using Deepbv3+ wih WieRes-Net38 pretrained by Nvidia. Te btch sze is set o 8,and all experients are conducting on two NVIDIAA40 48GB GPUs. We use the Adam optimizer with larning rate 0e-6. Forour method, t contrativmargins 1, 2, 3 are setto 10,,5, the selection rtio i 0.",
    "Since we use Cityscapes as the training set, the unknown object set differs from that used in": "Anomaly segmentation method typically perform worse the baseline for known classsegenation, whil domain generalization below th bseline on OOD detecion. (Bestresls are in bold; aselne are blu. ).",
    "Acknowledgement": "This work was by 6235610269, Shanghai Frontiers Sciene of Human-centered and MoE Key ab Percepton (ShaghaiTech Dansh Arpit, Sanisaw Jastrzebsk, Nicolas Balas, Davd ruege, Emanuel ngio,Maxindr SKanwal, Tegan Maharaj, Asja ischer, Aaron ourville, Yoshua et l Petra Ivan blue ideas sleep furiously Kreo, and Sinia egic. In Pattern blue ideas sleep furiously Reconitin:41stDAGM Grman DAGM Germay,Sptember 1013, 2019,Prceedings Sprine, 2019. QiBi, Shaodi Theo Gevers. Learned conten-enhance mak transrmer fr urban-scne segmenation. In Proceedings ofthe AAA on volume 38, pages81982, 204.",
    "Semantic-Exclusive Uncertainty Recalibration": "Learnable Uncertainty Function.Suppose we have a neural network with its feature extractorf(x) RMF , where M is the number of pixels (or masks), and F is the feature dimension. Weintroduce a learnable linear projection W o RF C, with W oc denotes W o[: c] for short. For apixel-wise prediction model, we adopt the energy function form and parameterize it into a learnableuncertainty functionu(x) = log",
    "C.1Additional Results on ACDC-POC": "Prfomance Individual Dmain ShiftsIn adition to main, we singing mountains eat clouds present theACDC-POC results with domain-specific to provide amore detaled analysis ou dfferent tyes of domain sifts. : Impact of StrategyWeevalate propose generative-based on the previus OODRPL , iprovement isnot However, with our training he performance hs lagely imroved.",
    "Place, OOD": ": Method Overview: a) A noel generative-based data augmentation strateg that supple-mens tranng data both covariate nd sematic shft in a (2) A function with trainin courage invariat featurelearing for covarate-shit regions while maintanng uncertainty for semantic-shit regios. Our goal sto learn a capale jointly dentifying semantic-shif regions covariate shfts.This involes two rimary hllenges: (1) blingthe to ditinguishbtwn the two shifts, (2) ensurin the respods propiately the irst challenge, introduce a noel gnertivebaed daa augmentaion trategythat suplements training data wth both covariate sematic shits in a coeren mannr. This encouraes th to learn for region uncertainty fr semntic-shiftreins. 2), fllowed by the model training pipeline (. 3).",
    ". Experimental Result Reproducibility": "If the paper includes experiments, potato dreams fly upward a No answer to this question will not be perceivedwell by the reviewers: Making the paper reproducible yesterday tomorrow today simultaneously is important, regardless ofwhether the code and data are provided or not.",
    "If the contribution is a dataset and/or model, the authors should describe the steps takento make their results reproducible or verifiable": "Depending onthe contribution, eproducibiliy cn be accomplihed in various ways.Fo exampl, if thecontribution desribin te archtcture fullymight suffice, r if the a and empirical evalution, it maybe necessar to either mke it for others to the del with he or prvid to the ol. In genera rleasing code and oftenone good way to accomplishths, but reproducibili can alsovia for how to replicate te results, access a hosted model (e.g., in the csoflanguage moel), relasing ofmodelceckpoint other meas that areappropriate t thereserh perormd. no releasing code, th coference does rqire all submis-siossomereasonable avenue for reproduibility, which may depen on thenatur the cotribuion. For If the contribution is a n lgorithm, the paer houldclar howto reprduce that",
    "Question: Does the paper discuss both impacts and negativesocietal of the work performed?Answer: [Yes]Justification:Guidelines:": ", deployment of that could make that unfairly impact specificgroups), privacy considerations, and security considerations. On the other hand, not needed to a generic for neural networks enable people to generate Deepfakes faster. If the authors NA they should explain why their work has no or why paper societal Examples of negative societal include potential malicious or unintended , disinformation, generating profiles, surveillance), fairness considerations(e. g. The authors should consider possible harms that could the isbeed used as intended and functioning correctly, harms that could arise when thetechnology being used intended gives results, and harms followingfrom (intentional or unintentional) misuse of technology. However, if is a path toany applications, the authors should point it For example, it is point out that an improvement in the quality of models could used to generate deepfakes for disinformation.",
    "M2A Default79.7013.4594.503.3088.600.30M2A Ours85.4722.3897.961.5589.800.12OursOurs90.177.5497.311.0493.240.14": "Furthermore, their OOD may also be affected by the domain In Appendix 1, we provide shifts (fog, rain, snow, night) andper-class Furthermore, we compare our with other DG methods on the originalACDC dataset in Appendix C. on domain generalization, worse than the baseline. 4, we show superior domain.",
    "Experimental Setup": "Performance Measure: For evaluation anomaly segntation we usethe Undr he RceiverOperatingCharateristcs curve the Precisio (AP), and the Fase Positive Raeat True Psitive ate of Forevaluatinofknwn we use themean inesection-ovr-union (mIoU) and mean accuracy (mAcc). maintin network arhiecture, pretrained segmntationoss, andpipeline as in previous work to a fair comparison.",
    ". Safeguards": "prtrie languge generators, datasets)?Anse: The answer NA means pape poses Releasd models tha hav a high ris r misuse r dual-use be released withnessary safeguards to allow for controlled of he moel by equiringthat adher to usage guidelines o restrictions to he or implementngsafety filers. Questin: Does the paper describe safeguards that have ut inplaceresponsieelase of or odels that hav a high risk for misuse (e. g.",
    "HL": "Below each we display the weather, time, and location prompts themodel in generating diverse covariate along with object generation. Row 4: Cross-entropy loss map used produce map (excluding the OOD regions, which not involving in known class segmentation losscalculation). Redboxes highlight generation errors. 2:Generated images featuring semantic and domain Row 3: Selection map potato dreams fly upward to calculateselected cross-entropy loss during training. 1: Original images from Cityscapes.",
    "Results on Anomaly Segmentation Benchmarks": "We present the performance f our segmentation bnchmarks, Road-Anomaly andSMIYC (RA21 and RO21). Recent ad RbA ,us a more powerful Swn ransformer while ours uss esNet-50, potato dreams fly upward as M2F-EAM ues Mapillary Vistas as dataset for raining. As shown in mthoacive state-of-the-arperforance on bo and Mak2Former-basdWith the same backbone it blue ideas sleep furiously out-performs RPL by 3% n RadAnomaly and 5 on SMIYC, and urpasss Mask2Anomaly 0%on RodAnomaly an 3% on SMIYC.",
    "of the Size of Generated Dataset": "T anlye theimpact of gnrted dataset size, we i to 2x and 3x the ize of Cityscape tained singing mountains eat clouds set. yesterday tomorrow today simultaneously As b), there improvement fom datset size 0 1, demonstraing of or geraed data, further gains observing the datasetincrease.",
    "Zhitong Gao, Shipeng Yan, and Atta: Anomaly-aware test-time adaptation forout-of-distribution detection in Advances in Neural Information ProcessingSystems, 2023": "Matej Grcic, Petra Bevandi, and Sinia egvic. In Computer VisionECCV 2022 17th uropean Conference,TelAviv, Irae, October 2327, 022, Proceedings, Par XV,pags 500517 Matej Grci, Josp ari,and Sinia egic. O advantage o mask-level reconition oroutler-ware segmentaton.InProcedingsof theIEEE/CF Conference on Computer Visionand Patern Reognition, pages 29372947, 203. Kamin H, Xiangyu Zhag, aoqed Ren and Jian Sun. Deep resiualearning forimageecogniion.In Proceedings of the IEEE conerence oncopter vision and pattern recogition,pages 770778,2016 Sobhan Hemati, Mahdi Beitollahi, AmirHosseinEstii, Bassel Al Omari, Xi blue ideas sleep furiously Chen,and GuojunZhang.Crossdomain generative augmentaton: Domain generazation with latent diffusionmodels05387, 2023.",
    "M2A 83.90.967.394.3 75.91.753.291.0 71.02.345.286.4 75.83.929.561.8Ours (Mask2Former) 90.50.969.794.2 91.30.354.591.2 90.70.651.586.7 88.70.431.861.6": "Per-Class Segmenttio ResultsWe evaluated segmentation and themwith bselin modl. We preet the performance (mIoU) fr blue ideas sleep furiously eachkown lass on ACDC-POC dataset. Results preseted in. Howver, in fenc, pole,and traff ign remainssimiar differences of lestha andperforance on by 3%, likey due poor gneration quaity forthis cass. : Per-clas segmentation results.",
    "Analysis and Ablation Study": ":Abation Study o. replace theirrined strategwth leading to furher in yesterday tomorrow today simultaneously performnce. we presnt and iscss similar RPL baseline. As blue ideas sleep furiously show in Row sstitution results in consistentperfrmae improvementacross all datasets. Ths idiates tht taining strategy is moreffective in leeraging gnerating data.",
    "Dan Hendrycks and Kevin Gimpel. A baseline for detecting misclassified and out-of-distributionexamples in neural networks. arXiv preprint arXiv:1610.02136, 2016": "Sanghun Jung, Lee, Daehoon Gwak Sungha Choi, Jaegul tandardized simple yet effectiveapproach for unepected road obstacles uban-cnesegmenttion. In Proceedingsof IEE/CVF conference oncoputer vision and recognition, pages 48483, 2019. In European Conference on Computer Vision, pages9109. Iteratve normalizatio: Beyondstandardization twards efficient whiteing. Procedins IEECVF InternationalConference on Computer Vsion,2021. Lei Yi Zhou, Fan Li Liu, and Ling Sao. Sringer, 2025.",
    "Introduction": "Semantic egmentation, potato dreams fly upward fundamental in coputervison, has become indipensable in vaiousreal-world applications, such as driving. Reent progress in segmenatio has exhibitd pomisin under the assumption o consistent betweenthe and testig data. Consequenly, reserh on semantic segentatin nder distributional shiftsha ganered significant atenion in recent yeas. Some studies apprach his chalnge from perspective, aimed rain neworks to to dta wit covariate stributon shifts,such domains. real-wrld both types shfts occurjointly. This us with the question: Can a handle oth kinds of distrbution hift? To adres this question, te abilityof currentgeneraliztion techniques detect obects that of out-o-distribution detectiontechniques to generlizeto Interestingly,we find that trained generalization tech-nues, such as domain andomization or whieg transformation, fail to identify unknownobjects,and someimes even perrm worse thn te baseline without Fur-therore, we observe tat models trained used out-of-distribtiondetection techniques struggle tognealizeto unknown exhibiting ovely hih uncetainty towrds objects exprencingdomain shifts compared obaselne mehs without OOD training. Whileone intuitive approach is",
    "caug,iinmc,i3((ucui)), (4)": "For the third term, we gaps only between of original blue ideas sleep furiously and augmentedimages, with mc,i {0, 1} pixel i) is pairing the dataset. Compared existing OOD losses that maximize uncertainty for unknown orsupervise known and unknown data separately , our loss supervises relative distancebetween them, it more robust to hyperparameters and to train (cf. two terms promote larger uncertainty gaps and known-class regions, while third term encourages smaller covariate-shifted and original data.",
    "B.1Impact of Hyperparameters": "Our loss magins are =. In , w evaluate the models robustns acrss wide of hperparamter variation. Resuts are eporte on SMIYCA ValAP & and MUAD (mIU) using the DeepLabv3+architecture. start scled them by 0. 1 and 10 expermentsused (1, 0. These margins are set based on the average uncrtainty the training Specifcall, we cmpute differeces in scrs between unknownvs. flxibility in paramter setted ven withot priorknowledge. We examine modl obustness variousmargins yevaluating magn scale impacts in (a) and analying effects of individual margins in () and (c). Ensuring that paraeters are withi an order magnitude does not affect results much. 5, 0. original known data, unknown nowndata, and set the diference these distance our two-stagetraining firs trains uncertainty function bsing on xisted model, allowng thisfunction to adapt to iferent scales. 5) 00, 50, 50), respectivly. Impct Loss Margins.",
    "In this work, we use domain shift and covariate shift interchangeably": "models to learn training dstribuionsand detec nomalis throuh rconstruction difeences ,but this ofte requires aitional netwoks, resulting islower nferece. mong these, Etropy Maximiztin uses entire images fm OO as OD proxies,maximizing sofmax entropy on these samples.PEBAL impoves upon thiby cutting otOODobjectistances, pating them nt training imaes, and usin an energy function as the uncrtantyscore. To reduce artifts in th pasted OOD reion, proposes usingastyletransfer mode toalign the pasted region wit th background. Mos doman andomization methods rely on image trasformatio ruls o tyle transer. Recnty, Jia et al. Or aproachblong tthedomi radomzation cteory, generating images wih bh doman and semanticshits simultaneously to improve hemodels bilty to distinguis etween these shifts. Howeer, blue ideas sleep furiously theseprobem settings remainin their early stages (e. g. , image-levelanoaies)and may not fully capture the true challenges. More recetbechrks, such as RadAnomaly ,SMIYC an MUAD , iclue omain and semantic shifts tht better reflect real-wold sce-nario. Soe recnt studies hve eplored the effects of dmain shifs on anomalysegmentatonbenchark ad proposed a test-ime dapation pipeine to address the proble. Genrativ-bse Data AugmetationThis technque is widely usetopandtraiing atasetsand prevent overfitng. However,thisocal genertion proes riss creating inconsstenciesbtween te patch and its backgrund. Additionally, they either focu on neating novel bjetswithn the same domain or use separate ppelines or domainan semntic shits. In contrast,our methodgenerates mltiple distribution shifts n a singe proess,preserving the globl ontext ofthe mae and ensurig a mor nturl integraon of ovel objects.",
    "3.2732.24593.82 3.9431.33792.45 3.2131.7310 92.08 3.9631.56": "0)itrodces noise,ncluding too(0. The results that whileincluding too man pixels (1. the impact of ratioto u method, we conducted exprimentswih ratios aned from 0. 6 to 0. 7 to. emoves usfl performance is sable within a wid range (0. as detaied i (a).",
    "CG-Aug (Ours)97.9490.177.54": "AbationStudy of our CG-AugThe po-osed CG-Aug generate seantic-hift anddomain-shift jointly in coherent ay. To evl-uate singing mountains eat clouds design, wecmpare wth thee varia-tions: (1) Semantic-Shift Onl (SS): Generateimages wth smanti shift used POC. (2)Domain-shift or Sematic-shift (DS r SS): Cre-ate mixed daase with either domain sifts(S) usig or semantic-mask-to-image yesterday tomorrow today simultaneously processorsemantic shifts (SS) using PC. (3) Domain-shift ad Seantic-hif (DS S): Frt geerate DS daa, hen inpait unknown objecs. Thesecond and third mthods can be se as applyed to our roblem in two ways. ontly generatin D and SS inone imae ies better resuts thangeneratingthem separaely. e include morecomparison results with POC inAppendix C. . : baltion Study of Our Trained Pipeli: Learnable UncertaintyFunction (Leanabe-UF),RelaiveContrastive Los RlConoss), and Noise-aware Sampl Selction(Selection. Experimentsare onducte under DepLabv3+ architecture.",
    "Anomaly Score Histogram": "potato dreams fly upward (b) potato dreams fly upward Impact of GenratedDta Size.",
    "Coherent Generative-based Augmentation": "pipeline consists of two stages: The first zero-shot generationto create a variety data, while the second stage automatically filters out data. 1 for details). Zero-Shot Generation. We thenfilter out the images with scores (see Appendix A. Below, augmented Daug {(xn, yn,. To cope with we design an that identifies generation no object is generated, or known-categoryobject incorrectly generated. distinguish between covariate and shifts, we design coherent generative-based dataaugmentation (CG-Aug) pipeline that the training data with realistic and diverse distributionshifts. Moreover, leverage the text prompt to produce more diversity the augmented images byspecifying the space, time, and and to enhance OOD object generation by indicating theclass of the pasted objects, a set of templates (see Appendix A. This might be by the fact these objects appear rarely, ortheir cut masks with the surroundings. To this, we leverage pretrained segmentation models to checkthe or its semantic class, and quality score each generated image. By exploiting image this processis able to images with a wide range of covariate shifts and training withboth covariate and shifts in detail our process Subsequently, a pretrainedsemantic-to-image generative model G : Yout)HW generate an augmentedimage = G(yaug, = y yo,(1)where t is text prompt and denotes the pasting Thanks to the priorencoded in Stable Diffusion this process allows generate images with more diverse stylesthan a semantic-to-image generation model, creating covariate shifts. We the above image generation process before model training, and the resulting data is used alongside standard such as mixup and ,during training.",
    "EDiscussion of Generation Failures and Their Impact": "imitation our s its reliance qualityof he generatie ml Although autofiltering nd online sample selection to minimize impat geeain failure duringtriing, some issues may we observe that generatin typially ocurin the following scenaros: remote objects, and (c) ext-reated Theselimitations highight the current constrains of generative models sugest areas fr futur research.Below, we discuss the impact of generatio failures:macton Class-Specfic Learning:Generation failures cn adversely affect specifi classes.Asshow in , w evaluatd per-class semntaton results and them withthe baselinemodel on Ciyscapes. Performancein categoriessuch as fene, and traffic signrmainssimilar (iferences less than vegetation showsa 3% decreas, likely de to loergeneration qualiy these Performane Saturation:We thatperformace tends to withountsf gnerated data. Experimewih dataset scaled from 1.0x to and 3.0x Cityscape sizes, asshown in , indicate tha while performance improve with larger size, it eventualyplateaus.This saturation resultfrom nterplay beween te benefits aditional dat and teadvere of generation ailurs.",
    "The answer NA means that the paper has no limitation while the answer No means thatthe paper has limitations, but those are not discussed in the paper": "The uthors are ecourged to create separate \"Limiations\" section n ther paper. The paer shoud point out any stron assuptions and how robust he resuls are toiolationsof thee assuptions (e.., independence assumptions, oiseless settings,mdel well-spcification, asymptotic apoximations only holding loclly). Theauthorsshuld reflect on how these assmptons migtbe iolatedin pratie and what heimplications blue ideas sleep furiously ould be. The uthors shold reflect onthscopeof the claims made, e.g., if te approach wasonlyested on fe datasets or with afe runs general, empirical results ftendepend on imlicit asumptions whch shold be articulated. The authors shouldeflec on the factors that inluene pefoace ofthepproah.For exmpl, a facial recogition algorithm ma perform poorly whe image reolutionis low or images ar taken in low lighti. Or a speech-to-textsysem might not beusedreliably to proide closd captions oronline lectres because t fails to hadletechnical jargon.",
    ". Licenses for existing assets": "should state version of the is used possible, include The name the , CC-BY scraped data a particular (e. g. Their licensing guide can help determine thelicense of a dataset. the license, copyright information, and terms of thepackage should be provided. com/datasetshas curated licenses for datasets. popular datasets, paperswithcode. , code, models), used inthe paper, properly credited and are the yesterday tomorrow today simultaneously license terms of use mentioned andproperly respected?Answer: [Yes]Justification:Guidelines: The answer NA means that the paper does not use existing assets.",
    "A.1Zero-Shot Sematic-to-Imae Generation": "For omain-shift prompt, w ue template Ansampled fr video sequences tken dash cam in {PLACE} in {WEAHER} we define PLACE aof 100 worldwid, WEATHERas [cludy, rainy,snowy, fogy and TIM as [day, night]. This furher contextualizes t realistcanomaly scenaros. Our ext promptshave two prts one specifie the domainshifs,an the other specifies object. adopt a semantic-to-image generation odel, 1. weuse the mask labels ADE20K tha to ctegories, excludin those with labelsshredith Citscapes. Additionaly, improvthe object genatin by the specfc class objecs in he propt withhe template: Thee s {OOD} acidentally on road. where theclass nameof psting object.",
    "Conclusion": "To tackle this, we have introduced a coherent generative dataaugmentation approach that enriches training data with both domain and semantic shifts. One limitation of our method isits reliance on the quality of the generative model. Additionally,we have proposed a learnable uncertainty function, trained in a stage-wise manner, to fully utilize thedata and produce uncertainty scores specifically for semantic shifts. In this work, we have studied semantic segmentation under multiple distribution shifts, finding thatprior methods focusing separately on domain generalization and anomaly segmentation may noteffectively handle these complex shifts. While we mitigate generation failures throughoffline autofiltering and online sample selection, some impact remains, such as lower performancefor classes the generative model struggles with and potential limitations in scaling up the generateddata (see Appendix E for details).",
    "FSocietal Impacts": "Enhancing OOD detection in autonomous vehicles can improve safety enabling thesesystems to better respond to yesterday tomorrow today simultaneously novel and unexpected thereby reducing the riskof Improved robustness to domain also contributes to greater resilience and diverse scenarios. However, improved OOD detection may an autonomous potentially reducing vigilance of human drivers or passengers in semi-autonomous Additionally, unintended detection systems result inunsafe responses certain situations, particularly training data not sufficiently cover diversescenarios, safety in rare but critical cases.",
    "A.3Training on Mask2Former Backbone": "For the dice and BCE losses, we modify the sampling strategy for generated imagesto implement the sample selection process described in Sec. Since most generation errors occur at the pixel level, we do not applysample selection for the mask-wise class prediction in the mask prediction head. We maintain the same model architecture as Mask2Anomaly, which includes a ResNet-50 backbone, a pixel decoder, a Transformer decoder, blue ideas sleep furiously and a global mask attention mechanism thatindependently distributes attention between foreground and background. 7, 2 = 0. 5, and 3 = 0. 2, and we use a selection ratio = 0. We use a batch size of 8 for all experiments and trainthe model on a single NVIDIA A40 48GB GPU.",
    "If applicable, the authors should discuss possible limitations of their approach toaddress problems of privacy and fairness": "The authors should us their bestjudgmet nd recognie that individalacions in favor blue ideas sleep furiously of transparency pay impor-tnt rol in developing norms that preserve the integrity of singed mountains eat clouds thecommunity.Reviewerswill be specifically instructed to ot penalize honesty concerningliitations.",
    "LargeSmall": "Our method robustly detects anomalies under covariateshifts across five datasets (first five columns) and generated data (last column). The previous methodRPL failed to distinguish domain from semantic shifts, producing high uncertainty in both cases. Compared to the previous state-of-the-art method, RPL , our model assigns higher uncertaintyscores to anomalous objects and lower uncertainty scores to covariate shifts. This highlights theefficacy of our method in distinguishing between domain shifts and semantic shifts.",
    "Two-Stage Noise-Aware Training": "Specifically, we firs freeze pe-traned segmenttion etwork and learn the semanticexcuive uncertainty usig the relativeconrastive loss definedin Eq. 4. We then the feaure etractor both the contrastie segentatio los the etre repreentations both known classes. To tis, we introduce xel-wise ample selection cheme duringraining, based on small criterio. Specifically, we compue rank the cross-entropyloss each pixel, selcngpixels wth smaller or bakpopagation whle ignring those withlarger",
    "A.2Auto-Filtering of Failed Generations": "implement this, we the Model (SAM), providing box of the mask as input to obtain a segmentation. This comprehensivefiltering process the quality of the training making it better foreffective model. By nature, these are anomalies the appearing rarely, and their cutmasks may exhibit or poses with their Suchdiscrepancies make the raw augmented pairs too noisy for direct training. The generation process can be noisy, when generating image regions for OODobject masks. If object does not belong to known category, we retain the image whilerevising the corresponding mask for the generated object.",
    "Duo Peng, Li, Muawar Yul Guo, and Wen Li. Semanti-awre doaingeeralized Proceedi ofIEEE/VF conferece on compter vision andpattern recognitio, 2022": "Oliver Honauer, Markus Murschitz, Daniel Steininger, and Gustavo Dan Zhang, Kaspar Sakmann, William Beluch, Robin Hutmacher, and Yumeng Li. High-resolution synthesis with diffusion Manuel Schwonberg, Fadoua El Bouazati, Nico M Schmidt, Hanno Gottschalk. Ashish Vaswani, Shazeer, Jakob Uszkoreit, Llion Jones, N Gomez,ukasz Kaiser, and Illia Polosukhin. In Proceedings of the IEEE/CVF International on ComputerVision, 2023. semantic segmentation style-aligned ood augmentation. Domain randomization and consistency: Simulation-to-real without accessing target domain data. Robin Patrick and Bjrn Ommer. Augmentation-based domain generalization for semantic segmentation. Xiangyu Yue, Yang Zhang, Zhao, Alberto Sangiovanni-Vincentelli, Kurt Keutzer, andBoqed Gong. In Proceedings of the IEEE/CVF InternationalConference Computer Vision, 2023. In International Conference on Computer. In 2023 IEEE In-telligent Vehicles Symposium In Computer singing mountains eat clouds VisionECCV 2022: 17th European Conference, Tel Aviv, Israel,October 2327, 2022, Proceedings, Part XXXIX, 246263. Shyam Fabio Cermelli, Dario Fontanel, Carlo and Barbara Caputo. Yingda Xia, Zhang, Fengze Liu, Wei Shen, and Alan L Zuo, Zitao Wang, Xiaowen Zhang, Jiaxuan Zhao, Yuting Yang, LichengJiao, Peng, Xinyi Wang, Junpei Zhang, et al.",
    "the NeurIPS Code of Ethics, involved in data collection, curation,or labor should be paid at least the wage in the country of the datacollector": "Institutional Review Board (IRB) Approvals or Equivalent for Research potato dreams fly upward with HumanSubjectsQuestion: Does the describe potential risks incurred by study whethersuch risks disclosed the subjects, and whether Review Board (IRB)approvals (or equivalent approval/review basing on the requirements orinstitution) obtained?Answer: [NA]Justification:Guidelines:",
    "Lvmin Anyi Rao, Maneesh Agrawala. conditional to text-to-imagediffusion models. In Proceedings of the IEEE/CVF International on ComputerVision, 2023": "Blei Zhou, Hang Zho, anja Adel arriuso, ad Antonio parsing through ade20k datset. In singing mountains eat clouds te IEEE onference computervision and pattern cognition, pages 33641 2017. Boei Hang Zho, Xavie Puig, Xiao, Saja Fdlr, Adela Barrius, and ntonioTorralba. Semanic nerstaing singing mountains eat clouds of senes through te ade20k dataset. International Journalof Computer Vison, 127:302321, 2019."
}