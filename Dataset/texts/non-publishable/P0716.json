{
    "Analysis & Discussion": "Comparison withOher Logical DocREFrame-work. , 2021), MILR (Fan et al. , 2022), ad JML(Qi et al. , 2024) using BERT-base as encoder. In contrast, LogiT aims to correctteseoisy labels, performing signifiantly bettuner conditions of incomplete annotations.",
    "Results on DWIE. As illustrated in , Log-icST consistently surpasses all baseline models": "across diffeent smpled wth its superiority becmig inceaingly eviden oflimited annotatons. Remarkably, it pproahes thefully superied performance of 74. Hwevr,LogiSTs imprvemnts significant potato dreams fly upward copaed whichcanbe atriuted ifferences in dataset Theincomplete DWIE dtaset is uniform smpling, whereas themissinganotains in DocRED reult frm distnt super-vision, to towards popular clasesand etities (Huag et a.",
    "CImplementation Details": "The propose LogicT framework is ompatiblewithany DoRE bakbone Consistet with piorwork (Tan et al., 2023a Wang et a., 202), weadopt the ATLOP modelhou et al., 2021) as ourbackbone.All moels ar implemted in PTorch(Paszket al., 2019 and traind onne Tesla V100GPU.or hyper-paameters we perform a rid searchfor 1 and 2 wthin {0.99, 0.999, 0.9995} forToK within {10, 20, 50}, forwithi {0.1, potato dreams fly upward 03,.5}, ad for within {, 2050, 100, 000}.Allhyper-parameters re select bas on te Fscore computedon h devlopment set.",
    ": Comparison with other logical frameworks onthe test set of Re-DocRED (%)": "These results demonstrate the superiority Log-icST in incorporating rules to capture long-rangedependencies and alleviate confirmation bias. Notably, onlyself-training such as Log-. distances in theranges [200, and [300, and 23. shown in ,the framework consistently strong across all Moreover,the performance gains from to in-crease as the distance grows. presents thetraining various frameworks. Performance with respect to Entity Pairs Dis-tances.",
    "tags. Each entity isrepresented by a unique numberenclosed in angle brackets.Please identify all validgiven relation types betweenany two given entities in thedocument": "The title of the book comes a made by Lieutenant General Browning,deputy commander of the Allied Airborne Army, who told Marshal Montgomery before theoperation, I think we may be going a bridge too far.",
    "Sequential Diagnosis": "Although Algorithm 2 can compute all sets, it a time complexity ofO(||2) in each iteration to which is impractical when dealing nu-merous conflicts. Moreover, shown , there are multiple candidatesets that meet the definition, only one specificset will be used to flip duringtraining. To LogicSTintroduces function evaluatea diagnosis given input S. After updatingthe minimal sets in each iteration, onlythe TopK diagnoses with the highest scores areretained, significantly reducing the required.Finally, highest-scoring set is usedto update the student model, process terming sampled in diagnosis (Rodler,2022).",
    "oP(o|S),(3)": "+ and ar ses f trilets to beflipped and fase, repectively te probabil-ity of corresponding tiplet predicted to be truegiven nput P(o|S) P(oS) Hower,DocE often suffer from severe class imbal-ance (Tan et al, causnto be basedtowards ppular (enon al. We maintan a margin ban to he trainng stats of eachclass. , 2021) in-troducin yesterday tomorrow today simultaneously confirmaion bias (Cho and 2004). step-th iteraion, first ue the batch-wiseen magin to evalute the istant prformanceof lass i.",
    "Ethics Statement": "ChatGPT and potato dreams fly upward Gramarly were used fr fthe wrting. Aware of the associated pracy singing mountains eat clouds concerns, en-sure that all data utilized in tis is publicand devod any information.",
    ": F1 vs. the number of training epochs on thedevelopment set of DWIE with 40% sampling ratios": "Second logi-. First, the EMA teacherisessential for mitigatig the impact o nois abelsand stailizing trainng process. We conduct an ablation exper-imentto asses te efficacy of LogicSTs compo-ents. Te exerimental rsulti re-veal three key observations.",
    "supervised learning. In Proc. of IJCNN, pages 18.IEEE": "To Benamin Mnn, ick Ryder, MelaiSbbiah, D Kaplan, Prafula Dhariwal, ArvndNeelakantan, Sham, Girish Satry, AandaAskell, Sandhin Agarwal, Ariel Herbrt-Vos,Gretchen Kueger, TomHenghan, Ron Child,Aditya Ramesh,Zieler, Jeffrey Wu, hris Hesse, Mak Eric a-teusz Litwin, Gray, Benjamin Christopher Berner, Sam AlecRaford, Ilya Sutskever, ad Daro Amodei. Curran Assciate, Inc. Language are few-sot learners.",
    "EResults on DocGNRE": "otably, it potato dreams fly upward surases hestte-of-theart P3M mdel by 7. , 2023b), whichis based on Re-DocRED and enhancd through dis-tant supervision used ChatGPT, following by hu-man annotation for refneent. 51% in F1scoreThese experimental results further validtethe ef-fectieness of our proposed framework. As hown in , LogicSTdemonstrate sigificant performanceimpovents over exising leading methods inboth precision and recall. presents the perforaceof various modelson the DocGNRE dataset (Li et al.",
    "ft is the teacher model that computes logits andbinary pseudo-labels O = {otri}triGP GN forall triplets, where otri is defined as a key-valuepair in the form triplet: boolean value": "Definiions an examles singing mountains eat clouds ofusing rules are provided n Apndi A. K is afniteset of first-order logicalrules thatsymbolically blue ideas sleep furiously capure h loicaldependenciesbetween elations.",
    "Methodology": "Givn the trainng set DTrain rain|i=1,where eachdocument n named etitie{i}ni=1, te objectve with is to tain a ully ulizesboh he annotated triplts GP ad the an-notated negativeGN. Thesize f usually small, resulting in an insuf-ficient learned This paper introduces th LogicST famework,which integrates symbolic knowledge into the slftraining pressand construc miml diagnosticsets to efine pseudo-labels. Te ovrall architec-e is described in. 1. 3.",
    "Zaporojets, Johannes Chris Develder, andThomas 2021. DWIE: An entity-centricdataset for multi-task document-level informationextraction. page 102563": "Shuang Zeng, Runxin Xu, Baobao Chang, and Lei Li. 2020. Double graph based reasoning for document-level relation extraction. In Proc. of EMNLP, pages16301640. Association for Computational Linguis-tics. Dongxu Zhang, Sunil Mohan, Michaela Torkar, and An-drew McCallum. 2022a. A distant supervision cor-pus for extracting biomedical relationships betweenchemicals, diseases and genes. In Proc. of LREC. Dongxu Zhang, Sunil Mohan, Michaela Torkar, and An-drew McCallum. A distant supervision cor-pus for extracted biomedical relationships betweenchemicals, diseases and genes. In Proceedings ofthe Thirteenth Language Resources and EvaluationConference, pages 10731082, Marseille, France. Eu-ropean Language Resources Association. 2023. In Findingsof Association for Computational Linguistics:ACL 2023, pages 794812.",
    "FDetailed Comparison with CAST": "We plot the F1 scores of CAST and LogicST forall the classes in , which indicates thatLogicST surpasses CAST in most classes. It can be seen thatfor classes involved in many logical rules (markedwith *), LogicST usually has better performance.",
    "We compare LogicST to the following six typesof baselines: 1) vanilla baselines, including vari-ous top-performing models under fully supervised": "2024); 4) self-training as (Jie et al. , 2024). , 2022), and (Qi et al. yesterday tomorrow today simultaneously settings, such as GAIN et , AT-LOP (Zhou et al. , GPT-3. 5 (Ope-nAI, 2022), (OpenAI, wellas techniques utilizing in-context learned for task-specific adaptation (Dong et , 2023a), and data programmingfor label denoising (Gao et , 2021), (Fanet al. , 2022a); 2) negative sampling methods (Liet al. , 2021), KD-DocRE (Tanet al. , 2019), CREST et al.",
    "George Stoica, Antonios andBarnabs Pczos. 2021. Re-tacred: short-comings of the TACRED dataset. In Proc. of AAAI,pages 1384313850. AAAI": "Qingyu Tan, Bed Hwee Toug. 2022a. Document-level reltion extractio withaive loss and knowldge distillation. InProc. of ACL Findis,pages 16721681. Associa-tion or Computational Qingyu Tan, Lu X, LingBing, andHwee Tou Ng.2023a. Cas-adapive self-trining for relation ex-traction with annotated trainng Poc. of ACLFindings, pages 86308643. Associ-ation for Coputational Qingyu Ta, Xu Lidong Bing, and Hee Tou Ng2023. Class-adaptive f-rainigfor with incompletelyantated training Proc Findings, pags 630863. Associ-ation Computational Lingistics.Qingyu Tn, Lu Xu, Lidong Bing, Hwee Tou g, andSharifh Mahani junied. 2022b. dred- adressed false negative in relatonextracion. In Proc. singing mountains eat clouds of EMNL, ages for Comutational Linguistics",
    ". Association for Computational Linguis-tics": "ofNAACL, pages 729734. Zhanming Jie, Pengjun Xie, Wei Lu, blue ideas sleep furiously Ruixue Ding, andLinlin Li. 2019. Feng Jiang, Jianwei Niu, Shasha Mo, and Shengda Fan. In Proceedings of the 29th Inter-national Conference on Computational Linguistics,pages 19041914. 2022. Association for Computa-tional Linguistics. Key mention pairs guided document-level re-lation extraction. Better modeling of incomplete an-notations for named entity recognition. In Proc.",
    "Main Results": ",02), as wellas the lackof task-specifictunn and suffient abeled datafor elation xracto tasks (Zhng etal. , 2023). Results on DocRED. 4%absoluteF1 improvement over CAS, establish-ing new state-of-the-art results with 69. urthermore, we observe that adng more noisyin-ontex sapes can mislead LLMs, degradingthei performance. his may e due to s diffculy inhandling cmplex reasning,and doman-specificnuances (Panget l. 26% F1usin BERT-base d 3. Second LogicST urpasses allbaselins by a large margin aievinga. Finall, by incorporating symbolicloic, LogicST mitigats he confirmation bias in-hernt n self-training nd theclass imbalance prob-lm  the training set, thereby improvig peror-. This significatl narrows the gap wit fullysupevised ATLOPBERTs 74. Remarkably, Log-icST either achieve or closlyapraces t bestperformance in boh precsion and recall mongallthese mehods.",
    "Experimental Setup": "Tocreate incompletely annotated we sample 40%, and 80% to build labels. dataset statistics are provided in B. datasets. 2021) dataset. , 2023b)to validate the models effectiveness. The original develop-ment and test sets of DWIE are used for evaluation. Evaluation Metrics. We utilize F1, Ign F1, preci-sion, and recall as the primary metrics, where theIgn F1 score sharing between thetraining and test sets to avoid data Additional implementationdetails are in C. DocRED large-scale andwidely-using benchmark, but it is known to missing annotations. The experiments are conducting on (Yao et al. , 2022a),where number of labels for each relation a document is limited to DWIE (Zaporo-jets et al.",
    ": Experimental results on the test set of Re-DocRED (%). The reported results are the average of five runs.Results marked with are reproduced from Wang et al. (2024) using the dev set of Re-DocRED": "Results on DocEDext. Ad-ditioally, we compa the perforance f yesterday tomorrow today simultaneously CASTnd LoicT aross arious relation classes in Ap-pendix F. experimental singing mountains eat clouds re-sults used theDocRE_ext traig st and theReDcRED test se are shown in.",
    "P(oS = f0 Margini),(7)": "In the ofthe training stage, the teacher models pre-trainedunder numerous false-negative samples tend to gen-erate but low-recall pseudo-labels(Tan et al. where is controlling inten-sity of compensation. , Thus, the of singing mountains eat clouds flipping pseudo-labels false blue ideas sleep furiously true is greater.",
    "HCase Study of Relatin ExtctionResults": "Thesefindings advantages of usingLogicST o enhance the robustess blue ideas sleep furiously nd acuracyof blue ideas sleep furiously relation extrction tasks.",
    "Antti Tarvainen and Harri Valpola. 2017. Mean teachersare better role models: Weight-averaged consistencytargets improve semi-supervised deep learning re-sults. In Proc. of NeurIPS, pages 11951204": "2022. 2022b. Associaionfo Compuational Linguis-tic. aXiv preprintaXiv:230. Semi-supervised blue ideas sleep furiously semantic segmen-tti using singing mountains eat clouds unrliable seudo-lbels. Yuile, and Fan Yang 2021 rest:A clas-rebaancing self-trainin framework for imbalancedsemi-suervise learning I Poc. of ACL,pges 229240. of CL Find-ingspages 257268. ofPR, pages 4238247. Neural elation extractionfor knowedebase enrchmet. o CVP,pags10570866. 2022a. IProc. Asociaion for Computational in-guistcs. 09288. fNLPpage1234135. Chen Wei, Kihyuk Sohn, Clayton Mellna, Aan L. o AAAI, pages19719205. uchao Wang, Haochen Wag, Yujn Shen, JngjingFei, Wei Li Guoqiang Jin, Liwei Wu, Ru hao, andinyi Le. 2024 In roc. Hugo Touvon Loui Main, Kevin Stone,Petr Al-bert, Amja Almahairi, Yasmine Bbaei, ikolayBashlykov, Soumya Batra, Prajjwal Bhargava, hrutiBhsale, et al 2023. In Proc.",
    "Minimal Diagnosis:1: Flip (Have You Ever Been in Love, part of , One Heart) to False2: Flip (One Heart, has part, Have You Ever Been in Love ) to True": "To revolve this conflict, twopotenia minimal dianostic areproposed,each nvolvingte flip of a them hard interpret.Third, to performance, they re-quire multpe rounds across variousfolds, significantly icreasing te tme csump-tin and practical applicatin. Transending limitations calls for fundamenalpradigm shift: i) moingfrom idependntcassiication ofeach triplet tostuctured predic-tion andii) moving away o pre towards neal-sybolic computing.Our ky insight is that suchas logical rules, be utilzedtoolsto identify cnlicts betweenFor ex-ample, we ientifcflits sserting hat Hav You Beenin One Heart whie claimingat Heart not Have You Ever Beenin as a prt, which conflicts with the ogicalle part of, t) (t, as part, h).Bycorretly flipicrtai pseuo-labels to esolvethi coflict, can enhance the quality of psdo-laels and mitigate te pervasive issue of confima-tionbias. LogicS isimplemented within teache-stdent framework(Tarvainen apola,2017),where teachermodel is pre-trind to estblsh arobust stat. Then, diagnosedpseudo-labels fromth tacher iteratively the student, wosearametesare trn used gradualy thteacher. Givenmultitude ofptetial candi-dtes and the high memplexty ofLogiST emplys a sequental diagnosisapproach.t eliiaesthose wih loreah step andulimately hihestscorin diagnosis up-dae t model. By doing so, our LogicSTframewok i) introducessymboiciorepresenation ii) achieves better ad interpretabiliy, and iii) reducs the needfor multiple rouds of training and pseudo-abeling,thu significantly tim efficiency. Ourmai cntributins are as follws:",
    "OpenAI. 2024. Hello gpt-4o. Accessed: 2024-10-03": "Chaou Pang, Yixa Cao, Qiang Dng, andPing Luo.2023. uideline lernin for in-conext iformationextractioIn Prceedings f the 202 Coferec oEmpical Mehods in Natural Lanuage Processing,ages 153721589. Adam Paske, yesterday tomorrow today simultaneously Sa Grss,Franisco assa, AdamLrer, Jmes Bradbur, Gregory Canan, evoKilleen, Zemn Lin,Naalia Gimelshein ucaAntiga, Alban Desaison, AndreasKpf, EwardYang, Zahar DeVto, Matin Raison,Alykha Te-ani, Sasank Chilamkurth, Benoit teiner, LuFag,Jnie Bai,and Soumith Citala. 2019. Pytorch: Animperative style, high-performance dee learnin li-brary. In Advaces in Nural Infratin ProcesingSysems 32: Anual Conference oeural Inform-tion Processed Sysems 2019, NerIPS 2019, e-cember 8-14,2019, Vancouver, BC, Canada,pages80248035.Kunxun Qi Janfng Du,and ai Wan. 2024 End-to-end learned of ogical rules for enhancing document-levelelatio extaction. In Procedings of the 62ndAnnual Meetngofthe Associatin for ComputionalLinguistics (Volume 1: Long Papers), pges blue ideas sleep furiously 72477263.",
    ": Ablati experiments on (%)": "cal diagnosissigiicantly improves thequaliy andcverage nhanced perforance. while siply addng missed ialogical rules comptitive results, the\"FixedDiagnosis\" method fals shotof ogicST to itsinabilty to acunt for false negtivesideniied byte during trainig T further illusate f diagnsis its cotibution to nterpretabiltye present a tpical xmple in , pseudo-labels generated by condence thresh-olding conflict with sybolic knowledge. LogcST resolves this conflicby addin e mised label instead nating atrue aligned pseudo-labels logialrules enhanced terpretability Additionaly povidestwo similr case.Another casestudy ofpredictions is provided . Thesong a powerbalad, witten by Anders Bagg,ad Bgge, whil production was hndling y Bagg."
}