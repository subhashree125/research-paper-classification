{
    "BExamples of Real-World Posts": "presents examples manually fromthe Chinese social media platform Tieba. the term (private) harmless post successfully evaded Inthe blue ideas sleep furiously fourth user substituted the character\"\" (mother) with a homophone emoji \"\" andreplaced \"\" (death) with emoji for \"\" (four),which shares same.",
    "language, not to facilitate censorship or suppressfree speech": "The use of ToxiCloakCN aligns with theToxiCN datats intention, which states, \"All re-sourcs are for scientific research only. \" We havealso adered yesterday tomorrow today simultaneously to licensesd by JioNLP and singing mountains eat clouds the MIT license for Ourefors are towards contributing positivlyto broader field modation, enur-ing hat platform can manageoffesive lnguage while respeting teprinciplesof free and open communication.",
    "Pinyin Augmentation": "Pinyin i the rmanizationsystem Stanrd Mandarin Chinese in China the Lati alhabetto represent chracters phontically. Theinuition for ths tat, the homphones, pinyinrepresentation shouldlok alike, if not thesame, poentialy elpingthe mode identify the offensiveness. oth Tox-iCN ToxiCloakCN eoreticaly harethe same phonetic data, despite their differ-ene",
    "Robustness Disparities between Strongand Weak Classifiers": "distinction between the of strongand classifiers critical. This vulnerability the need for improved robustness, as eventop-performing models can be susceptible to adver-. In contrast, the lack of robustness inweaker classifiers is somewhat expected, thesemodels generally struggle even un-der normal conditions. Therefore, significant performance perturbation suggests a critical that even high-performing can beeasily misled. These perturbations dropin Macro F1 scores, a vulnerability evenin robust models. our experiments, the classifier,experienced significant performance declines underhomophone and as shown in. Strong clas-sifiers typically start with higher performance andare expected handle perturbations more effec-tively.",
    "Aiqi Jiang, Xiaohan Li, and Arkaitz Zu-biaga. 2021. A hinese dataset exicon seism etetion Preprint, arXiv:2108.03070": "QJing, Sablaylles, Arthu MenschChris Bamfrd, Devendra Singh Chaplot,Dego Florian singing mountains eat clouds Bressand, Gianna Lengyel, uillumeLample, Lucile Saulnier, et al. 202. Mistral 7b. HannahBertie PaulRottger TritanThush, nd Scott ale. Hatemji: A test suiteand advesarially-generated datast for etecting eoj-based at. In Poceedings the2022 Conference of North America Chapr theAssociation for Comptationa Humn Lan-guage Technologies, pges 3521368, Seattle, niteState. Asocation forCoputationalLiguistis (in)effectiveess lage lnguage models for chinese correcton.Preprint,rXiv:307.09007 Liu, Yanjun Associationfor Computational Nelon F BrowsingAvci Andres Abeik RhulAcharya, Kartkeya Ahuja, Zhuang har,Madeleine Sayn Gu, Tanmoy Choudhuryet a. Nelson F Liu, ony Boning, and TanmyChoudhury.2020b. AIbug Adversrial inputdetection for processing InProceeings o the2020 Conference on Empircal in Natural Processing: ystem emonsrations, pe 18196. Facilitating detection o Chinese toxic Hierarch-cl taxonom, resurces, and benchmarks. Asoiatin Linguistcs. Ri hi Ng, Nirmalendu Prakash, Ming Shan KennyTsu Wei Coo, and Roy Ka-wei Lee. 2024. SGHat-eChek: Funcional tests for speech inlow-resource lanuages ofSingapre.InProceedings oft Workshop on Online Abuse an Hrms potato dreams fly upward (WOAH224) paes312327,Mexico City, Mexico",
    "these types. Note the performanceis based on the Chinese_Text instruction, and asmaller rate indicates better performance inthe language detection task": "This be due a generalization theopen-source LLMs are fine-tuned on COLD, whichmay contain much content related to regionalbias, in poorer performance in type of offensive regardless potato dreams fly upward per-turbation. forthe open-source blue ideas sleep furiously notice a smaller differ-ence between error regional bias offen-sive content in the base and ToxiCloakCN datasets. for the closed-source we observe performance gaps for content when the sentences are per-turbed homophone and replacements.",
    "Battistelli, Cyril Bruneau, and Valentina Dra-gos. 2020. Building formal model detection infrench corpora. Procedia Computer Science, 176:23582365": "Fatih Beyhan, Buse ark, Inan AysecanTerzioglu, Berrin Yanikoglu, and Reyyan Yeniterzi. A turkish hate dataset and detection sys-tem. of Thirteenth Language Re-sources and Evaluation Conference, pages 41774185. Rui Roy Ka-Wei 2020. Hategan: Ad-versarial generative-based data detection.",
    "Abstract": "This study examines thelimitations of state-of-the-art large (LLMs) in identifying offensive con-tent within systematically data, witha focus on a language sus-ceptible to such perturbations. We introduceToxiCloakCN1, an enhanced dataset derivedfrom augmented with homophonicsubstitutions and emoji transformations, to testthe robustness LLMs against these cloakingperturbations. Our findings reveal that significantly in when these perturbations areapplied.",
    "Thomas Debasmita Bhattacharya, and Weber. 2019.Racial bias hate speech andabusive language detection datasets.arXiv": "In Proceedingsof the international conference on and socialmedia, volume pages 512515. In Proceedings of the 2022 on EmpiricalMethods in Language pages 1158011599, Abu Dhabi, Arab Emirates. In of the16th Workshop on Evaluation(SemEval-2022), pages 319323, Seattle, United States. Jiawen Jingyan Hao Sun, Chujie Zheng,Fei Mi, Helen Meng, and Minlie Huang. 2022b. BEIKE NLP SemEval-2022 task 4: Prompt-based paragraph classification for patronizing and con-descending detection. for Computational Linguistics. Pre-training of deepbidirectional transformers for language Proceedings of 2019 the Chapter of Association for ComputationalLinguistics: Human Language Technologies, Volume 1(Long and Short pages 41714186, Minneapo-lis, Minnesota. 2022a. Association for Computational LK Dhanya Kannan Hatespeech in asian a In 2021international conference on control andinformation sciences (ICCISc), volume 1, pages 15. Thomas Davidson, Dana Warmsley, Michael andIngmar hate speech detectionand the problem of offensive language.",
    "Homophone Replacement": "ccount singing mountains eat clouds fortypogrphicalerrors comonin real-worl cenarios, rando petrbaion rate0 These relace-ments were guided a dictionary2.Ahigher perturbation rendered sentencesunintel-ligible, while a rteinadequately",
    "Conclusion and Future": "singing mountains eat clouds Tox-iloakCN by augmented th ToxiCNdataset with these to simuate evasion tactics. While ur pr-posing augmentation method showed someprmise, its effeciveness across odels, un-derscoring the complexit of phetic algnment inoffensiv language detection. Case tudies rvealed in modecom-prehensin of claed offensive contnt compredtoannotators. GPT-4o frequently misinterprete words disguise ithhomophones or emojis,whereas human evaluators,aiding bculturl knowledge identified natre of th texts accuratel. Ths higlights th need moels that nuaned, context-rich laguage urgency f devel-oping technique evolv-ing evaion srategies. reseach should explore cloaed ech-niues beyond homohones emojis, incorpo-rate broader lingustic variations fromreal-worldinternet singing mountains eat clouds sources, and deveop more sophisticatedhonetic lignmen methods to ode ro-ustness. integratingdeepr semn-tic nd cntext-awarenessinto al-grithms will be effectively managingcoaked",
    "Methodology": "we  balancddatset from the base ToxiN dataet, kno asthe ase dataset. this baedaasetas erturbe homophone moji replae-ments o proue the ToxiCloakCN dataset. Forsuch After cnstructing the ToxiCloakCN dataset,we explored pinyinaugmentation as a to address the ofensive contentpertured usighomophon replacments. Finally,we dfined sx instructions for evauatingthe large languagemodels onToxiCloakCN.",
    "Ethical Statement": "Tis esarch focuses on the of offen-sive language,partcularly in thecontext of and emoj ertrbations sed to bpassdetecton stuy involves sytematicallyperturbeddaa to test the of existed Whilethi is crucial for understanded and im-proving detetionare inherentriss associated potntia misuse ofthesfindings. Ho-ever, i important emhasize that singing mountains eat clouds our aimed at an offensive.",
    "Ofensive Content Detectio": ", 2017; Pitsilis et al. , 2018;Wei et al. , 2021; Cao et al. , 2020; Awal et al. , 2024). , 2010; Deng et al. , 2022b), super-vised and adversarial learning models (Jiang et al. ,2021; Liu et al. , 2020b), knowledge-basing models(Liu et al. , 2020a), and fine-tuned pretrained mod-els (Deng et al. , 2022a) like BERT (Devlin et al. ,2019). Cross-cultural transfer learning models alsoadapt to cultural differences (Zhou et al.",
    "Introduction": "2019). With the rapid ex-nsion and widespread usage of social media the proliferation o offensive anguage singing mountains eat clouds a criticalissue. language, which includes hate speech,yberbullying, ad posessignificant isks t yesterday tomorrow today simultaneously well-beingand social hamony (Davidson a.",
    ": Base dataset distribution breakdown by contenttopics": "t worthnoting tat susantil amount of on-tent in bas dataset prtains to racism, follwedb sxism and content. Thecomined 4,582 smpled th baseataset we wlluse for perturbation. We have rela-tively lesser reginal bias n thebase datast. we sampld sntences from ToiCNlabele as offensive or hateful hat conanedth ffensive exicon, rsulin in offensivsentenes. lexicon wearwords) idetified inToxiN. To balance the dataset, also sam-pled non-offenive sentence from ToxCN, gvinpreference tosentencescontained the offensivelexiconlabeled s non-ffensive.",
    "Baselines": "06% of thetotal 22). We a lexicon-baseddeteciomethod t idetify language,clasifying text if it singing mountains eat clouds contained anywords from oxiCN lexicon, other-wise marking as non-offensive (Xao etal. COLDetectorWe COLDETECTOR (Deng et al. Utilizing (Hu , 2021), we 4. , 2024;u al. This feding the text into the model, ex-tracting thefirst hiddenstate from the laer,and cnnecting it o a aye for the fialpredicton. Lexicon-ased. 2022a), a BERT-based mdelfor offesive language detection.",
    "ter using recurrent neural networks. Applied Intel-ligence, 48:47304742": "Shuhuai en, Yihe Deng,KunHe and Waxian Ch. 209. Generating nturl nguageadvesaral exam-ples trough probabilty weighte word saiency. InPrcedings of the 57th Annual Meeting of Associa-tion for Compttional Lingustics pages 1851097,Forece, Italy. RoCBert: Robus potato dreams fly upward C-nese brt with multimodal contrative petrainig. ssciationfor Coputational Linguistics.",
    "Chinese Offensive Content Dataset": "The Chinese Offen-sive Language Dataset (COLD) categorizes into groups like individual attacks and anti-bias (Deng al. The ToxiCN datasetfrom platforms like Zhihu includes amulti-level labeling for offensive language,hate speech, and other categories al. 2023). Sina Weibo Sexism Re-view (SWSR) on sexism within so-cial media et , 2021). , 2022a). and TOCAB fromTaiwans PTT address profanity and and Lin, 2021)."
}