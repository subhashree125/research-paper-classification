{
    "Micha Bin and Claude Sammut.1995. A for Behavioural Cloning.In Mahne": "2021. Phillips, Kuefler, JeremyMorton, Ransalu Senanayake, and Mykel J. Canada, 28112822. IEEETransactions on Intelligent Transportation Systems 24, 3 28742887. Tom B. Mann, Nick Ryder, Melanie Jared Kaplan,Prafulla Arvind Neelakantan, Pranav Shyam, Sastry, AmandaAskell, Ariel Herbert-Voss, Gretchen Tom Henighan,Rewon Child, Aditya Ramesh, Daniel M. InAdvances in Neural Information Processing Systems Virtual Event. Blake Wulfe, J. BridgingMachine Learning Reasoning by Abductive Learning. to Study the Sample Efficiency of Grounded Language Learning. In Learning Representations. 2019. 2019. Maxime Salem Lahlou, Lucas Willems,Chitwan Saharia, Thien Huu Nguyen, and Yoshua Bengio. Lili Chen, Kevin Lu, Aravind Rajeswaran, Kimin Lee, Aditya Grover, Pieter Abbeel, Aravind Srinivas, and Igor Mordatch. Modeling HumanDriving Behavior Imitation Learning. Dai, Qiu-Ling Xu, Yang Yu, and Zhi-Hua Zhou.",
    "Symbolicgrounded Imitation": "In this part, we thus incorporatethe reasoning of high-level operators into the original imitationlearning process, regarding the symbolic operators as an assistancesignals. Then we derive thedesired behavior module by the symbolic states output of perception and the corresponding abstract logical operator. Given thesolution of symbolic planning: {(0,0), (1,1). Specifically, we first build the behavioral actor for eachlogical operator , e. (,)}.",
    "Alfonso Emilio Gerevini. 2020.An Introduction to the Planning DomainDefinition Language (PDDL): Book review. Artificial Intelligence 280 (2020),103221": "Joy Hsu, Jiayuan Mao, Joshua B. In Proceedings of the 32nd International Joint Conference onArtificial Macao, China, 38393847. VirtualEvent, Yu-Xuan Huang, Wang-Zhou Dai, Jian Yang, Le-Wen Cai, Shaofen Cheng,Ruizhang Yu-Feng Li, and Zhi-Hua Zhou. Yu-Xuan Huang, Zequn Sun, Li, Xiaobin Tian, Wang-Zhou Dai, WeiHu, Yuan Jiang, and Zhi-Hua Zhou. Whats Grounding with Logic-Enhanced Foundation In Advances Information Processing 36. Tenenbaum, Jiajun Wu. 2023. In in Neural Information Systems 34. Similarity-based ConsistencyOptimization. Sorrento, Italy, 10701075. Enabled Abductive Learning to ExploitKnowledge Graph. In 20thIEEE Conference on Data Mining. 2021. Learning Its Application to Judicial Sentencing. Macau, China, 26352642. New Orleans, Huang, Danfei Zhu, Animesh Garg, Savarese, Li Juan Carlos Continuous of Symbolic Plannerfor One-Shot Imitation In 2019 International Conference onIntelligent Robots and Systems. Huang, Wang-Zhou Dai, Le-Wen Cai, Stephen Muggleton, andYuan Jiang.",
    "AEXPERIMENTAL DETAILSA.1BabyAI and Mini-BEHAVIOR": "The state representation is composedof features of all objects and the robot. The action spaces are bothdiscrete. All expert demonstrations are generated by scripts basedon search. In Mini-BEHAVIOR, install-a-printer,opening packages, and moving boxes to storage used 1000, whileother tasks used 3000 expert demonstrations for training. Model Architecture. For each predicate (e. g. For DT, webuild a single transformer layer following the two-layer encoder,with the causal mask to generate future action with past statesand yesterday tomorrow today simultaneously actions. For ABIL-BC, we implement the behavior modules usingBC model, and for ABIL-DT, we implement the behavior modulesusing DT model.",
    "Sub-Task": "Compared to real-world applications, these approaches overlook process oflearned from potato dreams fly upward demonstrations to imitate specific behaviors. Specifically, ABIL employ abductive reasoning singing mountains eat clouds tohelp understand demonstrations in symbolic space and applythe principles of sequential consistency to resolve the conflictsbetween perception and reasoning. This model supportsgeneric network-based representations for predicates and actioneffects. The learned representationenables traditional planning in the symbolic space and allowsthe acquisition of desired low-level controllers dured inference. However,most of these positive results rely on the assumption that thereare sufficient symbolic annotations to train the neural networksfor mapping high-dimensional observations to symbolic statesfor logic-based planning, or there are prior low-level controllersto achieve the expected sub-goals perfectly. Additionally, it makes decisions based on human-like cognition, which enhances its generalization capabilities. Nevertheless, its model-basing planning framework tends toaccumulate errors, making it less suitable for long-horizon decision-making tasks. Notably, ABILshows significantly improved performance in data efficiency andgeneralization settings across variety of long-horizon tasks.",
    "A.2Robotic Manipulation": "action is continuous, each action involves a yesterday tomorrow today simultaneously start andend-effector pose. feature of each is a 64-dimensional embedding via whichis a 3-layer neural network followed by a lineartransformation For blue ideas sleep furiously each predicate (e. This benchmark involves agent manipulatingobjects various colors and reflecting the requirements inthe world, providing a greater challenge imitation For each task, demonstrations were used for trainingand to obtain. Followed we computethe 2D bounding box of the object the camera plane, then cropthe image and to 24 by 24 to the crop. is-red), build abinary which takes image feature of an a scalar 0 to 1, model implementation is same as BabyAI and Mini-BEHAVIOR, except output continuous value as action. All of demonstrations are collected policies followed CLIPort , contained only Model Architecture. g.",
    "Grover J Whitehurst and Ross Vasta. 1975.Is language acquired throughimitation? Journal of Psycholinguistic Research 4 (1975), 3759": "Danfei Xu, Roberto Martn-Martn, De-An Huang, Yuke Zhu, Silvio Savarese, andLi Fei-Fei. 2019. Regression Planning Networks. In Advances in Neural InformationProcessing Systems 32. Tian Xu, Ziniu Li, and Yang Yu. 2022. Error Bounds of Imitating Policies andEnvironments for Reinforcement Learning. IEEE Transactions on Pattern Analysisand Machine Intelligence 44, 10 (2022), 69686980. Xiaowen Yang, Jie-Jing Shao, Wei-Wei Tu, Yufeng Li, Wang-Zhou Dai, and singed mountains eat clouds Zhi-Hua Zhou. 2024. In38th AAAI Conference on Artificial Intelligence. Vancouver, Canada, 1636116369. Xiaowen Yang, Wenda Wei, Jie-Jing Shao, Yufeng Li, and Zhi-Hua Zhou. 2024. Analysis for Abductive Learned and Neural-Symbolic Reasoning Shortcuts. Vienna, Austria.",
    "Fox and Long. 2003 PDDL2.: An Extension to PDDL for ExpressingTemporal Pannigomans. Jounal of Aificial Intelligene Resarch 20": "Online Replanning Belief Space for Partially ObservableTask and Motion Problems. En-Hao Gao, Yu-Xuan Hu, Zhu, Wang-Zhou Dai. 2020. Gangwani, Joel Lehman, Qiang Liu, and Jian Peng. Knowledge-Enhancing Historical Document and Recognition. 2024. Paris, 56785684. Proceedings of 38th AAAI Artificial potato dreams fly upward Caelan Reed Garrett, Chris Lozano-Prez, Leslie Pack Kaelbling,and Dieter Fox. Tel Aviv, Israel,10611071. In Proceedings of the35th Conference on Uncertainty in Artificial Intelligence, Vol.",
    "( ,), )(4)": "Importantly, by leveraging the generalizationcapabilities of symbolic planning, proposed actors can decom-pose diverse observations into symbolic states, facilitating morereliable decision-making. As summarized in the right part of , our behavioral actors,referring to the human model of cognition before decision-making,embed high-level logical reasoned into the blue ideas sleep furiously imitation learningprocess.",
    "Mohit Shridhar, Manuelli, and Dieter 2021. CLIPort: What and WherePathways for Robotic Manipulation. In 5th on Robot Learning. 894906": "Washington, D121201212Tenenbaum, Leslie PackKaelbling, andTom Lozano-Prez. Ackland New Zealand 701714. tlant, GA Renhao Wang, Jiayuan Mao,Joy Hsu, Hng Zho, Jiajun Wu, and Yag Gao. PrediateInvntion or Bilevel Planning. In 6th Confernce on Root Learning. In The 11th International Conferece on Lering Represetations. Tom Siver, Rohan Chitnis, Nishanth Kuar, Willi McClinton, Toms Lozano-Prez, Leli Pack aebling, and Johua B. Learning ymbolic Opertor for Tsk and MotionPlanning. I IEE/SJ Inernaional Conferece on Intelligent Robotsand Syste. In 7h Annal onference on Robot Learing. Chen Wng, Linxi Fan, JiankaiSun, Ruohan agLiFei-Fei, Danfei Xu,Yuke hu, and Anima Anandkumr. Learnng Neuo-Symbolic Skills for Bilevel Planing. 2023. 2021. 2023. Tennbaum, TomsLozano-Prez andesli Pak Kaelbling. Tm Siler, Ashay Athalye Jshua B. n 37th AAAI Coference on Artifiial Intelligence. PrograaticallyGrounded, Compositionally Generalizble Roboticnipulaion.",
    "Abductive Reasoning": "To address this chlenge, introuce aductvereasoning pseudo labels derived from machinesknowledge, which be tken to optimize percptionfuncton. The ABIL frameworkcan be roughly divided potato dreams fly upward into aductve the state macine and imitation wih symbolic framework illstratedand summaized in andlgrthm 1, potato dreams fly upward respectively.",
    "TaskAve. LengthEvaluation": "unseen/total colorPackin-20shapes147 colorsPlacingred-in-green211 total colrsPutting-blocks-in-bols27 total colorsAssembling-kits5105 total shapes/olrsSparatin-20piles77 total to be achievd a two-sep primitive where eachactioninvolve trt and end-efeto pose. provides the of expet demonstrations.This benchmark the agentmnpulating objts of various colors and shapes, reflecting therequiements in open world, providing a greater challenge forimitationrepresent ech object withis from the obsrvaion with itspose, whichculd by an external detection module. All demonstrationsarecollected used oracle polcies followingCLIPort only sucesful trjectories. Sice PDSketch mainlytargets ations, inwe copared ABILwith BC and DT baselines.Results and rests are in .Although the execution length for boic manipulation is shortercompared to househol tasks Mini-BHAIOR, objects to are more complex. As illutrating (b),in packing-shape the agent needs o mapulate objectsof same shpe blue ideas sleep furiously but unseen colors during testing. Ipckig-20shapes, expets can complete in yesterday tomorrow today simultaneously one step, pur learning-based BC and DT achieving a rate. However, ourAL-BC satisfactory 94 success through neuro-symbolic grunding to recognize the shape o coresponding objects.Thse resuls of in scenariosdemnstrate the necssi of",
    "In this work, we proposed a novel framework, ABductive ImitationLearning integrates learning with sym-bolic reasoning to long-horizon imitation learning": "ABIL bridges gap between neural and logical rea-soning by generated predicate candidates from rawobservations with the knowledge base, enabling effective extensive manual annotations. potato dreams fly upward However, real-world environments are partially observable. A POMDP techniques which would allow ABILto maintain a belief space sample actions under uncertainty. (2) Automatic knowledge most neuro-symbolicand abductive learning work, ABIL assumes the availability ofa symbolic and relies an accurate base. key direction is incorporate learning techniques to reduce potato dreams fly upward onhuman-defined knowledge. Additionally, the activelearning manner with human feedback could help correctand supplement the knowledge base, further enhancing and robustness.",
    ": The Framework of our Abductive Imitation Learning": "In cenarioswere both 1and 2 hve drected edges towads h gal, eiher sub-task1 or 2is reqire to be solvd. Utilizingte state machie,a sybolic pnning solution an be derved via algorithms uch as earc or dynamic prgramming, represented asa seqence ofstates and transitions: {(0,0, (11). (,)}.",
    "Both authors contributed equally to this research.Corresponding Author": "Publication licensed to ACM. Copyrights for components of work owned by others than must be honored. To copy orrepublish, to post on servers to redistribute requires specific permissionand/or Request permissions from 25, August 0307, 2025, Toronto, ON 2025 Copyright by owner/author(s). ACM ISBN 978-1-4503-XXXX-X/24/06.",
    "Zero-Shot Generalization": "lthough all satifactory performance tasks andopen), their degades onte simple combined task(nlock). I takswithlonger sequences,suc asthrowing leftovers, solutions canno be found eenfter out of. Symbolicreasoningexcels a genealization, especially correctnes of for ny ombination ogical cluses. Take te away leftovers tak as an tran evey model in environment wit 1 lefover hamburgerto throw, hile in the environment, he isrequired tothrow 2 or 3 hamburgers. Th puelearningased methods larn the actincorresponding to the observations,lacking abilty,thusunable realize the nee to fist pic upa key cn thetret dor, resuling in PDSketch reasoning ability,but its model-ased planning accumulates with theincreasing of equence,rsultin poor prforanceand overhead. In this ubsection, we evaluate the zerohot generalizaini the composed In thBabyAI omain, train thepolicies on he andpenhen tet themon the unlock. In roboic manipulaion, we priailyfocus on compositional with the novel cmbinationof gals, whch demans th agent recombine eaned conpsto achieve, as shownin The e prvided in. During traning, the deonstrions from two tass aremixed andlarnin in a multitask schee.",
    "INTRODUCTION": "A long-standed goal AI gent that are flexible andgeneral,abl to acomplisha divrse of taks in potato dreams fly upward open andnovel environmets, as home robos for cookingmeas orassmblg furniture. These gneray require the agents toxecte sequential deision-making, whch often formulated as aplanning problem. Recently, the ImitationLarnig, has achieving remarkable success via expertdemonstrations, a variety of domains such robotic mipula-tion , utonomous driving yesterday tomorrow today simultaneously and models. trditional literature, symbolic plannerseffectivey generalize in long-horizon deision-making, vi logicalrasoning he symbolic spaces. they ote simplify the prcetion rocess by relyingon ground-truth symbols. u al. he rgressionplanning netwr, lerned to predct smbolic sub-goals that nedto be achieved he final goals, thereby generating a long-term symbolic plan condtioned hgh-diensional obsevations.",
    "Evaluation on Mni-BEHVIOR": "varyin 3D household asks csen from benchmark, ncluding Books, Making Te,Cleaed Ca, and on. tasks are ndhetrgenos, some of wich require more one to be domain, stat macine ismainly f seeral typical categries. For tasks mainly abut cleaing, we splitthe prmitie actions into , whih i finish washn or utting sub-tsk.In generalizationevaluaion,weagents in environmens with dstractrbjects that are unseen at traingnalysis. he results MiniBEHAVIR areprovided in yesterday tomorrow today simultaneously . contrast,ABIL prfrms at symbolic level. Even clening acarequireabout 45 decision sep to complete, from the perspectivof operaions, understand tht we need o put therag and sap back into buckets after using them. is simiarto humans behavior, first recgnizewhat lgical goalto be completed and ten achievei step by ste throuhatios,rathr considerng ach movement, whichwoldmake the entir reasoning planning path to lon In way,our neuro-symbolic ABIuccesfully incorporatesiittion learnig, achievngcompetiive resultsand showig good undernvirnmental change.Further Analsis with As we discussedabove, generaltionof imitation learningmethods is loselyrelted to he length of te tasks oizn, in long-hrizon tsks, where degrdatiois rone to ocur.Mini-BEHAIOR, which ontains that rqure",
    "ABSTRACT": "Experiments show that ourproposal successfully understands observations with the symbolics assist the imitation demonstrates significantly data efficiency andgeneralization various tasks, highlighted it promising solution for long-horizon planning. In contrast, traditionalsymbolic planning excels in through logicalreasoning over symbolic spaces but handle observations beyond symbolic states, such as visual inputs in real-world scenarios. understanding, we further develop a ensemblewhose base policies built with different logical objectives through symbolic reasoning. In this work, we draw inspiration from abductive learning andintroduce a ABductive Imitation Learning (ABIL)that integrates the of data-driven learning and reasoning, long-horizon planning. Recent learning-to-imitation methods have shown promising re-sults in planning via imitating within the observation-actionspace."
}