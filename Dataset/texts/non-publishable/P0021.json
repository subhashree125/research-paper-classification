{
    "A. Extract VGG features": "Computation of Wassestein Distrtion (WD) two mages, and. A. We extact spatial feature aps fi fromselected of netwrk. B.",
    ".3array array 4array array 2array 1networks": ". aasetaverage bi alloatin individual latent arysof varyng reolutn fromarray 1 (highest reolution) o array (lowest resolution) for three trgt bit 0.075, 0.15, three of 3: optiized fo MSE andoptimized for WD with  8, supplied wth CR or withut. predictions give boo in  Eloscores, bu the isual ME is not sufficientto make itcopetitve wt metrics. visualreprovided in the suplement.After obsering strog perfrmance of WD asn",
    "wi = log2 i , 0(2)": "which 1 wherever is equal to 2/ri, and fadeto 0 approaches either 2+1/ri or * \"S 21/ri. diis multiplied wi, averaged across space, and summedacross , yield one WD value di * \"S for each feature i.",
    ". C3 codec": "xperment ae based on the COO-CHIC faily ofmethods more specifially n C3 ,a codec whichrivals odern classicl codecs ikeVVC in trms atedistortion whil a very low computational cost Thse codecs main components aset of arrays, a syn-thesis netwrk and * \"S an entrop netwr, each of which reoptimized per iage (se ). To synhesize n image, theselatents upsapld cocatenated to creat single mlti-chane aay attheresolution of th image.This aray ispassed through a synthesis network f,smanetwork, to RGB values at eery pixel location. The ntropy networ g usedto model the cditionaldstibution of each atent given its satial contex. laentarrs theparamters of te synthesis andentropy networks arejointly for raeditorionojecive, with distortion gienby theMSE between theoriginalnd image and rate apoimatd entropy o te latnt rrays ndermodel. Since the laten arrays re quantized, in aquantization-aare mnner. and etWe ppl randomns arrays the dode of pseudo-random . d. stndard Gssian noise, whchrmains fxed during optiization ecoding. theseed dditional informaion needs to 2. We byh Waserstein Distrtio betweenthe andits",
    ". Introduction": "Methods of lossy data compression are characteizing by alog f exploiting both: correlations in statiticsof the compressed data, foexample by linearly predicting the nextsaple auio codecs, y applyig decorelating trans-formations such as the ; and information bottlenecks human for examplebyreprsened images ith lower rsolu-tion than luminance, or by modeled frequency maskingin auditory syse. Owing to conceptual connection decoding ofa and sampling one from distriution,research on earned imge compression hs recntly influeced generative methods such as GANsor diffusion , which excel at probailisti odeling of real-worl data, as evidenced by impressive qualityof samplessuch modls. The generated visually so convincing that of sample e. , formalizing by divergences btween dstri-buto source data he distribution generateddata) hve even been called Unfrtunately, a which extremely good at real-world has to have certain computationlcomplexity, because the (ad hence thespace o images) very complex. In other words:out f th qualities, (imge fast speed), and cheap (low rate), pic two, as inthe old proverb. take nexsted low-complexityneural codec, 3 , an replaceits loss by either two ariants of WassersteinDistortion (WD) : on which assumesthe observer at each imag location with equa probbility, andonewhic EM-net , slieny model, predict imagelocations thatare likely tobe scrutinized. he the omplexit f thewhic w itigat byintroducingnovel, approximate.",
    "H Man Kwan, GeGao, Gower, andDavid Bull. Nvrc: Neural video repesnttion compression.arXiv preprint arXiv:2409.07414, 204. 8": "Cool-chi: Codinate-ased com-plxity hierarchical image n Proceeigs theIEEE/VF Inernational on Computer Vision,pages 2023. , Valeo Laarra, Johannes Balle Alexander andEero . Smocelli. 8.",
    "bits/pixelC3/WDs at 0.191 bits/pixel": "Crop of image 32 from the CLIC2020 professional dataset (best viewed on screen). Top left: original image. Top center: C3 optimizing for MSE, compressed to 0. 191 bits/pixel. Bottom center:C3 optimized for MSE, weighted with the density map p, compressed to 0. Bottom right: C3 optimized for WD with derived from the saliency map, compressed to 0. 191 bits/pixel. Optimizing for MSE leads to flattened texture on shirt and skin (center column), while WD retains accurate perception of texture(right column). However, assumed a flat sigma map in WD is equivalent to assuming all image locations will be perceived via peripheralvision, meaning that the text on the camera is subject to texture resampling, making for instance the text on the lens (ZENITAR-M)indecipherable (top right). This is clearly undesirable, as text is semantically relevant feature. According to the predicting saliency, thecamera will be subject of visual scrutiny. Modulating according to the saliency map accounts for this. The end result is an image withboth improved texture reproduction as well as legible text (bottom right). Note that simply weighting MSE used predicted saliency does notimprove texture reproduction (bottom center).",
    ". Wasserstein Distortion": "WassersteinDistorion (WD) is distance metricbtwee pars of hch, similar to he DISTS metrics,can utilize feature The feature space is as a perceptualsace, i which are of subjectivehuman of distance image * \"S an distancebetween pixel * \"S intensities.",
    "Please see the next pages for further selected examples": "Horizontal crop of a image 6 fro the LIC220 proessional dataset (bes viewed on screen). While optimization forMSE leadsto lattene texture and staircasing artifacts, as seen inthe reproduction of te vgetation, textureis vatly imprving inthe W-optimizedversio while using 15% fewer bits. . Horizontalcrop f mage1 fromthe LIC2020 professional dataset (best viewed on scren). Right: C3 ptimized for WDwth derived from saliency map, compressed to0.130 its/pixel. While texture s vasty improed i the WD-optimzed vesion, fatversio struggles o reoducethe signage wll, snce it is interpreted as textur. Onthe rigt, te sliency model pedicts the signge to be scrutinized, and hence thereprouctioniproves suc that tetis legible.",
    "Sen Jia and Neil DB Bruce. EML-net: An expandable multi-layer network for saliency prediction. Image and vision com-puting, 95:103887, 2020. 1, 5": "1,2, 3, 5,. Jiang, Jiay Yang, Yongqi Zhai, Peirng FengGao and Ronggang Wang. 5, 1 Kim Mattis Baur, Lucas Jonathan Richadchwarz, and Emilien Dupont. Mli: Multi-refrence entopymodel for learned image compression. High-erformanc andlw-complexity neural compressiona single mage rvideo. Association Com-puting Machiery.",
    "Available at": "For CDC HiFiC, we were not able these rates, since it would have This total of 29 method/rate combinations,and 29 reconstructions for each of the 41images in dataset. Our evaluation protocol closely follows the CLIC ap-proach. each individual rating, three images are availableto rater: one side of screen, a 512 432pixel crop the original. While the original selected random, compared methods/rates is selected to max-imize expected information gain considering past ratings. The Elo score for method/rate thecross-entropy between predicted ratings. The main of is shown in. Meth-ods optimized for MSE (C3/MSE, MLIC+, VVC) and model CDC all achieve similar trade-offs betweenbit rate visual while complexity variessubstantially (with VVC being least complex). HiFiC andC3 optimized WD achieve much and comparabletrade-offs, but our method requires two orders of magnitudefewer MACs at time. We further to versions of C3 opti-mized for other perceptual metrics in , including WDwithout saliency, illustrating that optimizing vari-ant of significantly outperforms other in reveals that both switching the objective from MSE toWD, and providing CR to a WD-optimized lead to asmaller fraction of the bit rate being allocated to the highest-resolution array, which encodes detail, allowing other arraysto encode more This in line with intuitionthat both steps enable texture resampling: switching ob-jective allows the encoder find instantiations of texturethat visually equivalent, but take fewer bits to encodewith C3 architecture (for example, the roof in providing CR enables stochastic to bereproduced a form of (the grass ).",
    "C3/MSE CDC VVC": ". Humn raing study results and decodercomplexty. Let: valuation f imag compression methos in terms of visual fidelityvs. bit rate Error bar ndicate 99th percentile. Sqares indicate C3 using CR, cirles indicate C3 without CR,and diamonds mark othercompression methods. Riht: ompuational complexity of the decoder of the amemehods for the middle bit rate. HiFiCslightlyoutperforms C3 in tems of viual quality vs. bit rate. However, it requires morethan two orders f agnitude ore computationsat thedecode. Note that neural mehods tend o have smilarcomplexity across iffernt bt rates a objectives. This is ls tre forC3; ony theaddtion of R increases the cmplxity slghtly. The cmplexty o VVC can vary across bit rates, ad cant trictly be show in the sameplot, since it osnt use floating point operatins; we plot an estimated equivalent ontypical hrdwre . up to ne, effectively interpolating local WD aps frompreomuted WD maps di. Finally, WD values di araggregated across dfferen featues i by summaion.o determie an approprite-map, we examied twoltrnatives: First, e may simly chose constantacrossthe image hich ould be interpretd as a belief that everyimage location isequallylikely to be scutinize by a humanobserer. In his cse te value needsto be chose coner-vatively, sml enough that a desired lvelof exact detail inhe recostruction is preerved at all loatins.Second, emay deive froman actual gae map obtaied with an eyetrackng devic or a redictio thereof. In our experimens,e obtained predicions from EML-net in h orm ofa sliency map s valued between  and 1 (). We con-verted s to a satial density p using the adhoc elementwiseforula:"
}