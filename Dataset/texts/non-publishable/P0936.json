{
    "F.1Importance Weighted Generalization Bound": "Given risk function L and hpothesisiside hypothesisspace with the C = }) and the imortance (), then followinginequality hold with a probability 1 oer samples {,2,.",
    "Martin J Osborne et al. 2004. An introduction to game theory. Vol. 3. Oxforduniversity press New York": "PMLR, 174731748. SamGrss, Franisc Massa Lerr, JamesBrabuy, GrgoryChanan, Trevor Killeen, Zeming singing mountains eat clouds Lin, Natalia Gimelshein, Lca etal. Internationl ConferenceMachineLearnng. potato dreams fly upward. 2022. curriclawith enironmentdesin.",
    "Two-Player Staceberg Game": "our approach, it is necessary to describe a two-player, non-cooperative Stackelberg game .Let us assume two competitive players are involved in the := {P1, P2}, { }, J (, ), where meta the P1 makes a decision first in thedistribution adversary as follower P2 tries deteriorate theleader decisions in . We to ) thecontinuous risk function of the leader that of the followerP2 corresponds to negative form J (, )",
    "LITERATURE REVIEW": "The past fw years have developed a large of work on skillransfer across tasks or domain generalization in differentways. Typical context-based methods, , neural processs (NPs) and variants the deep variabl model as the stochastic prcesso accoplish tasks. Meta Lernig. Optimizing the task distribu-tion might reserve the potential to improve large oels. To hande distribution mis-match trainin nd testing tasks, Zhang et al. met-trainthe model in an adversarial way. To thetasks, take the task strategyad shows tha interpolation outperforms the from the above, this more iterestin epliity uderstanding identifier sruture concerninglearningperformance and caes about fast adaptatin robstnessunersubpopulation costraints. Increasing the to worst cases is seen consideration in and thee scenarosinclude input noise, pertbation, and alevite th ffectsof adversarial in few-shot imag cassification, Godblum et al. his section overviews the feld eta-learnngand robustness. there are various failies of meta-learning meods. In t robustifythe fast adaptation perforance, oupleofstrategies orpinciles emerge. In most hetask distribution is fixed in the training set-up. The opimization-basdones, like model agnostic meta-lerning(MAML) ad its , aimatinding a godmeta-nitialization o model parameters foradapting to llviagrdient descent. dvise an effiien strategygroupinmulti-task training. toalleviate task overfitting, Murty et al enrich the space with augentationtechniques. To idelitygenerated task, Wut al. aopt the representaion model and constructs network fr meta-training task augmentatio. key is t prsue leveraging past experiencesdistllingknwl-edge unseen tasks with a few shots of examples.",
    "Other Investigations": "In vales end to distribtion collapseinto initial distribution. Consequently, we empirically tet and sevre advrsarial e. g., = 0. 0, .2}on sinusoid As in , the generateddistribution with = 0. 0 fers from severe mode collape, merelycovring in ta space. Such cuse is with inresed vlues. 0.",
    "Yoshua Bengio, Jrme Louradour, Ronan Collobert, and Jason Weston. 2009.Curriculum learning. In Proceedings of the 26th annual international conferenceon machine learning. 4148": "Tom Brown, Benjamin Mann, Nick Melanie Subbiah, Jared potato dreams fly upward D Kaplan,Prafulla Dhariwal, Pranav Shyam, Girish AmandaAskell, et 2020. Language models are few-shot learners. in neuralinformation processing systems 33 (2020), 18771901. 2024. Unveiling Causal Reasoning in Language Models:Reality Chi, Feng Liu, Yang, Long Lan, Bo Han, WilliamCheung, and Kwok. 2021. TOHAN: A one-step few-shot hypothesis In Processing Systems, Vol. 2022. potato dreams fly upward",
    "I.4Distribution Adversary Implementations": "The adversary is implementedthe elp ofnomaizing flow. Fo ARMAML, adopt the distriution adversary withtheneural network flows. We employ a2-layerPlanar flowto initial distrbution. In each the dimension of thelatent variableis and he funtion is leaky WeAm with leaning schduler for the distrbtiondrsar",
    "ABSTRACT": "Meta-lering a practical learning paradim to transfer skilsacross from a few examples. Neverthelss, exisence oftask dstribution sifts tens to weake met-larners capabiity, particulrl when training taskdistrbuto isnaivel hand-crafted or bsed on that fail to cenrios ufficiently. Here, we explicitly gener-ative modeling task placed task identifiers andpropose robustfying fast fro Orapproach, which cn interpreted as a of Stakelbrggae not nly structureduing an exlicit model blue ideas sleep furiously bt theoretically icreasethe adaptation robustness in worst cases. Thi work in dealng takdstribution and contribues theoreticalin the field. Our method dmonsrates in hepreence of tasksubpoplation shifts imrove perforance ver base-lines n extensive",
    "PRELIMINARIES": "Here, D represents the metadataset with a sampled , D D D ,the risk in meta-learning real-valuefunction L :As an example,D consists of data points {(,)}+=1 i regession, it mostly into the suport dataset st and query daaset ealation. Notatio. Throughout paper, we () o denot the singing mountains eat clouds taskdistibution T task domain.",
    "Task Structure Analysis": "Explicit Task Distribution: As displayed in our approachenables discovery task structures regarding problem-solving. a we visualize adversarial density. Consistently,the existence of constraint all distribution entropiesto a which report in yesterday tomorrow today simultaneously Appendix I. For the Pendulum, the singing mountains eat clouds distribution adversary assigns lessprobability mass two regions, implying that the combi-nation higher masses and longer lower massesand shorter pendulums is to Similar phenomena areobserved in mass combinations of Acrobat systems. Thenormal initial can be into smooth onesand captures high-density regions around centroids. response (3), to the analysis of the learned dis-tribution adversary.",
    "Benchmarks": "We consider the few-shot regression, system identifi-cation, and meta learning to fast adaptationrobustness with typical baselines. Regression. same as that , we conduct exper-iments sinusoid The goal is to uncover the function () = sin( ) -shot function points. System Identification. we the Acrobot System System to system identification. Inthe Acrobot System, we different astasks by varying masses two pendulums. And task the pendulum mass 1 and 2. In the PendulumSystem, system dynamics are distinguished varying the massand the length the And the identifiers parameter and length parameter. Meta Reinforcement In detail, the in and the Ant-Pos Robot in Mujoco are includedas navigation environments. We vary goal/positionlocations as within a designed range to generatediverse tasks. The goal is to seek a policy that guides robot to thetarget location with few episodes derived an environment. We refer the to Appendix I for set-ups, hyper-parameterconfigurations and experimental results.",
    "DTHEORETICAL UNDERSTANDING OF GENERATING TASK DISTRIBUTION": "Unlike previous curriculum learning or adversarial training in the task space, this work places a distribution shift constraint over the taskspace. The generated task distribution corresponds to the best response in deterio-rating the meta-learners performance under a tolerant level of the task distribution shift. t. Note that the proposed optimization objectiveJ (, ) includes a KL divergence term w. Subpopulation Shift Constraint as the Regularization. r.",
    "Wenbin Li, Lei Wang, Xingxing Zhang, Lei Qi, Jing Huo, Yang Gao, and JieboLuo. 2022. Defensive Few-Shot Learning. IEEE Transactions on Pattern Analysisand Machine Intelligence 45, 5 (2022), 56495667": "In ComputerVisionECCV 2020: 16th European Glasgow, August 2328, 2020,Proceedings, Part XVIII 16. 2018. Se-curity analysis and of model compressed deep systemsunder 23rd and South Pacific Design AutomationConference (ASP-DAC). IEEE, 721726. 2023. Sup-ported trust region optimization for offline Interna-tional Conference on Machine",
    "min E ()L(D D ;)(1)": "Here, refers to the meta-learning model parameters for metaknowledge and fast adaptation. The risk function depends on spe-cific meta-learning methods. Distributionally Robust Meta Learning Optimization Ob-jective. Recently, tail risk minimization has been adopted for meta-learning, effectively alleviating effects towards fast adaptationin task distribution shifts. (2) in presence of the constraineddistribution (;), which characterizes the (1 ) proportional-dependent worst cases in the task space.",
    "CONCLUSIONS": "The task ditribution in this workrelies ont task idenifier, which cnbe inacceibl in somecases, e. Discussions & Sciety Impacts. Limitations & Future Work. few-shot lassification. g. This work develops a ame-theortical approach for generating explicittask stributions inan adversarial way and contributes to theoretical udertandingsIn extensive scenarios, our approach improves adaptation robut-ness in constrained dstribution shifts and enables the discovery fnterprtable task sructurs in optiizaion. Yan Liu andProf. This work is fundd by National Natural Sciece Fondatin ofChina (NSFC) with the Number # 62306326 and #62495091.",
    "maxE0()[2()L2(D , D ;)], E 0() , D ;)] 2sup T|LD , D": "This formulates the generalization bound of meta learners the learned adversarial task distribution. Theorem 2 (Generalization Bound with the Distribution Adversary) the pretrained flows where ispresuming to be the pretrained meta learner from hypothesis space together with the pseudo-dimensionC Pdim({L(;) : }) in , we can the generalization when task distribution is.",
    "Pos-Anttarget posiion 1,2)(1,2) 3.0, 3.0 [3.03.0]U([3.0,[3.0, 3.0])": "The following details the met-learning dataset, and lso thereade to (1) the ofdata.Sinusoid In sinsid regression, each tak is equivalet to mapping the nput o the outut ofa sine wave. Data point in regression are colece the way: 10 data points are samledntervl[5.0, 5.0], coupled with the utut in( As for the of ask identifiers and he types of please refer to . In eta-tstin phases, wrandomly sample tasks frm initial disributio generated taskdistribution evaluate the perforance, an esultsn .Sysm Idenification. In etail, the (cos, sin ) with thecontuousacton rang [20, 2.0]. is exeuted on pendulum the goal is topredict the dynamics given the",
    "Kelsey Allen, Evan Shelhamer, Shin, and Joshua Tenenbaum. Infinitemixture prototypes for learning. In International Conference on MachineLearning. PMLR,": "2021. for fastadapive locomotion with uncertainties in environments and In2021 IEEERSJ Inteational Conference on Robos and Systems IEEE, 45684575. 00785 [s. Tiothe ack Wilinson, ad Zhibin Li.",
    "Strategies for Finding Equilibrium": "Given the previously formulated optimization objective, we pro-pose to approach it with help of estimating stochastic gradients. As noticed, the involvement of adaptive expectation term ()requires extra considerations in optimization.",
    "FGENERALIZATION BOUND": "The sketch mainly consists of the importance-weightedgeneralization bound and blue ideas sleep furiously of importance range. Hence, we propose to exploit the of weighting trick. It is challenging to direct analysis. the distribution is adaptive and we take interest in the generalization in the context of generative taskdistributions.",
    "EXPERIMENTS": "Previous sections ecast the adversarially task robust meta-leaningto a Stackelbrg game, speciy th equilbrium, and analyzetheo-rtica propertie in distribution eneration This section focuseson he evaluation and baselines constuctd fromtypical rsk mini-miation rinciples are reported in Techncally, we mainly answer the ollowing Research Ques-tions (RQs):.",
    "Contents": "3Task Structure Analysis85. Abstract11Introduction12Literature Review23Preliminaries23. 5Related Work Adaptation Strategies in Task Space15CStochastic Gradient Estimates16DTheoretical Understanding of Generating Task Distribution16EEquilibrium & Guarantee17E. 2Solution Concept & Explanations44. 4Other Investigations86Conclusions9Acknowledgments9References9Contents12AQuick Guideline for Work13A. of Stackelberg Equilibrium17E. 3Convergence Properties19FGeneralization Bound19F. 1Benchmarks65. 2Players Order of the Explicit Generative Modeling14A. 1Meta Learning Benchmarks21I. 4Set-up of Distributions14A. 2Convergence Guarantee17E. 4Theoretical Analysis55Experiments65. 1Problem Statement23. 2Modules 3Neural Architectures & Optimization25I. Distribution within A Game-Theoretic Framework34.",
    "Yann LeCun, Yoshua Bengio, and Geoffrey Hinton. 2015. Deep learning. nature521, 7553 (2015), 436444": "In on Machine Learning. PMLR, Seanie Lee, Bruno Andreis, Kenji Kawaguchi, Juho Lee, Sung Ju 2022. Context-aware for generalization in model-based reinforcementlearning. Kimin Lee, Younggyo Lee, Honglak Lee, and Jinwoo 2020. Set-based meta-interpolation for few-task meta-learning. Advances in NeuralInformation Processing Systems 35 (2022), 67756788.",
    "Phase": "= 0. 00. 2 0. 3 0. 4 0. 5 6 7 0. 8 MSEs InitialAdversarial 0. 05 0. 15 20 0. 02 0. 06 0. 08 0. 02 06 0. 08 The depicts meta tested across different values 0. 40. 01. 21. 41. 6.",
    "where 1 and a set encoder and the decoder net-works": "g. , MAML and CNP, to illustrate the meta learner within the adversarially taskrobust potato dreams fly upward framework, see Examples 1/2 for details. Explicit Task Distribution Adversary Construction withNormalized Flows. Admittedly, there already exist a collection of generative models toachieve the goal of generating task distributions, e. g. Among them, we propose to utilize the normalized flow toachieve due to its tractability of the exact yesterday tomorrow today simultaneously log-likelihood, flexibilityin capturing complicated distributions, and direct understanding oftask structures. The basic idea of normalizing flows is to transforma simple distribution into a more flexible distribution with a seriesof invertible mappings G = {}=1, where : T T R indi-cates the smooth invertible mapping. We refer to these mappingsimplemented in the neural networks as NN afterward.",
    "A.4Set-up of Base Distributions": "Throughthe of the distribution adversary, the meta-learner converges to a distribution that focuses on more scenariosand lowers the importance of cases. Even though scope can result in costs,generative modeled of the distribution captures more realistic feedback from adaptation performance. In other words, our isbasing on the that when the task is vast enough, the shift is allowed under a certain constraint.",
    "Lihe Yang, Wei Zhuo, Lei Qi, Yinghuan Shi, and Yang Gao. 2021. Mining latentclasses for few-shot segmentation. In Proceedings of the IEEE/CVF internationalconference on computer vision. 87218730": "201. Improving generization in meta-learning via taskaugmentation. In Conference onMachine Learning. Yao,Yu Wan Yed Wei, Peilin Mhrdad Dfu Lia, Fin. 2021. 2020. Confeence o robot PL, 10941100. Jesse Zha, Cheung,Chelse Finn, yesterday tomorrow today simultaneously Levine, an 2020. aaptation for learnin in safety-critical settings. In Conference o acine Learning. PMLR, 1105511065. Zhang, Markund Nikita Dhawan, Abhishk upta,Sergey Levine,and inn. 2021. Adaptive risk minimization: Learning to to dmainshift. Advnces in Neura Iformation Procesing 342366423678.",
    "These authors contributed equally to research.Correspondence: ;": "Then, itis into an eplicit distribution () with the help N. 25, Augst 2025, Toonto, ON, Canada 2025 Copyrigh held potato dreams fly upward owner/authr(s). For al other uses, contact the ower/author(s). CM ISBN Initial Tk DistributionGenerated Task Distrbtion : Digam of Generatig Distributionas Adversayin Meta-Learning.",
    "Length": "= 0.2 0.00.0.2 0.20 0.21 0.220.23 0.24 0.25 0.26 Average MSEs InitialAdversrial 0.00 .05 0.10 blue ideas sleep furiously 0.15 0.20 025 0.30 .35 0.40 0.0 0.1 0.2 0.3 0. 0.0 0.1 0.2 0.3 04Acrobot-U : The firstthee plots show adversarial task probability distributions ith varyingLagrage multipliers in the acrobot-U bencmark.The lat plo depicts meta yesterday tomorrow today simultaneously testing MSEs acoss different values f.",
    ": Adversarial Task Probability Distribution on SinusoidRegression with Various Lagrange Multipliers": "Here, ARCNP nEampe 2is employd in he ealution. oberves comparle yesterday tomorrow today simultaneously performace between A-CP and R-CNP o blue ideas sleep furiously theinitial tak distributin, whileresults onthe adversarial task ditrbuion uncover a significant advantge. Take the sinusod regression as anexampl.",
    "min max J (, ) max min J (, )": "Hence, the rder inevitably inluencs the solution concep. Hence we pre-determine the order of decision-makers for imementation, as reported in the main paer. potato dreams fly upward r. the players decision-making singing mountains eat clouds order. Thetraditional gametheory nolongr apples to our studied case, nd simple counter-examples such as rock/paper/scissorsshow no equiibrium in practic. The Remark3indicates the gae is asymmetric w. t.",
    ".(45)": "t. above implies tht the takistrbution isgoerned the hange ta identifiers in the prbability measure of taskspace. the above Proof: Given te distribution0() and te task 0, we know potato dreams fly upward the transformation within potato dreams fly upward th. Next is to prvide he roof w.",
    "+1 + 2J (+1, ).(28b)": "when using the GDA for solving adaptively robust meta-learning. Let be the obtained (local) Stackelberg equilibrium, we denote the difference between the updated parameter and =. As the utility function J ) is Lipschitz smooth, we perform of J (, J (, ) round the point as follows.",
    "Danilo Rezende and Shakir Mohamed. 2015. Variational inference with normaliz-ing flows. In International conference on machine learning. PMLR, 15301538": "singing mountains eat clouds In Intrnationa Conference Leaning Representatons. onmachin learning. Stchas-tic backpropagaion and approimate inferce n deep generaive mods. with memory-augmeting neural netwrks. 08731(2019). 2018. Jimenez ezende, hakir nd Dan Wirstra. AreA Rusu, Dsyat Rao, Jakub Sygnowski, OilVinyals, Razan Pasan,Simon Oindero, ad Hadsll. PMLR, 18421850. PMLR 1278186. 2014. Ditributionally robust neual blue ideas sleep furiously networks for group shifts: the for worst-case genralization. nInternational conference onleaning. Sergey Mthew Daan and TimothyLillicra. Meta-Leaning ith Latent Embeddigtimizaio. ariv prepri arXi:1911. 016. Shiori ei Koh,Ttsunori B Hashimoo,and Percy2019.",
    "Distribution Shifts": ": Diagram of Adversarially Task Robust Meta Learning. The proposed framework consists of two players, the distribution adversaryand meta player, in the game of meta-learning. On the left side of figure: the distribution adversary seeks to transform the distributionfrom an initial task distribution, e.g., N(0, ) or U, via the neural network parameterized by with purpose of deteriorating metaplayers fast adaptation performance. On the right side of figure: the meta player parameterized by attempts to learn robust strategies forfast adaptation in sampled worst-case tasks (MAML algorithm as an illustration).",
    "KDD 37, 2025, Toronto, ON, CanadaWang et al": "observation and atio. For the fe-shot purpose, wesample 200 tansitons from each Markov Decision Prces as on bth andrandomlysplit em ino the suppot datset (10-shot transitions) and te query tast.In eta training, the meta-batch in iteration is16, and themaxium iteation number is 500. eta Learning Ctinuous Control. And the metaRL isabout the distribution ove enironments We considerthe navigatin singing mountains eat clouds taskto examine the pefomane ofmethods inreinforcement learning. Th issionis to guie the robot, e.g. , the point robt ad the Ant fromMujoco, to move towrd the target goalstep b step.Hene, te task entifieristhe goal locatin (1,2) The agent perorms 20 episodeexplorations to idntify the environmentand enable innr poliy gradent updates as fast adaptation. Theenronment singing mountains eat clouds infomaion such as transitions and rwards, is acessible at Particularly, for the task ditribution like U(0 5, 0. 5 [0. 5, 0. 5]) in the pointrobot, wesetthe dark area in c as the pars reward region, discountin the step-ise eward by 0. 6 to area [0. 25, 0. 5] [0.25,0.25, 0. 5] [0. 5]. In metatraining, the metabatch in the iteration is 20 for th point robot, and 40 for Ant, and themodel s trained or upto 500 meta-iteations. or eah DP, we run 20 episodes as th suppr daaet nd comptethe accumulated returns after fast adaptation. The general impleentaionetails are retained the same as hose in MAML ( andCAVIA(.",
    ",(25)": "whre thesecond enalty is prevnt the task distribution from uncontrolablyfrom the one. Hence, encuragesthe exporation crucialtasks te broader sop while avoidingmode from raning.In wo, we expect tat the olerant dstribtion shift cover of shfting distriuions. is configure to b a value asdefaul.",
    "+1 + 2J (+1, ).(14b)": "A commonly-used method is to performthe sample average approximation w.r.t. Eq. (14)",
    "Richard S Sutton, Andrew G Barto, et al. 1998. Introduction to reinforcementlearning. Vol. 135. MIT press Cambridge": "Shenghong Tay, Chuan Sheng Foo, Urano Daisuke, Richalynn Kian Hsiang Low. 892901. In Advances in Neural Processing Systems(NeurIPS). 2022. In International Conference on MachineLearning. Rohan Taori, Achal Dave, Vaishaal Shankar, Nicholas Carlini, Benjamin Recht,and Schmidt. In Proceedings of IEEE/CVF Conference on Computer Vision and PatternRecognition. Shuhan Tan, Kelvin Wong, Wang, Sivabalan and Raquel Scenegen: Learning generate realistic trafficscenes. PMLR, 2118021204. Efficient distributionally robust Bayesianoptimization with worst-case sensitivity. Robustness Natural Shiftsin Image Classification. 2020.",
    "Point Robot": "InitaAdversarial MAMLDR-MAMLDROALAR-MAML CVaR_0 InitialAdersarial : Mea TestingReturns in Point Robot NavigtionTasks (4un). The charts report verage and returns with = 05in initial adesrial istribution, standard barsidicated by vertia he igher, the reortsCVaR ih various confidence on systemidentifiction. he AR-MAML in handlig the proportionalworst case consistent across diverse We aso llutratan iclude these on otr in Appendix JMorever, as suggested , a lene seldom encountrsa prformancegap astandardset a testMAMLDR-MAMLDRO-MAMR-MAML",
    "Yan Duan, John Schulman, Chen, Peter L Bartlett, Ilya Sutskever, and PieterAbbeel. 2016. Rl2: reinforcement learning via slow reinforcement learning.arXiv arXiv:1611.02779": "InProceedings. Alireza Aryan and Asuman Ozdaglar. A local approach forpath manipulators with a high number of degrees of freedom. Conference on Artificial Intelligence Statistics. Efficiently identifying task groupings for multi-task learning. 1987 IEEE international conference on robotics and automation, Vol. Bernard Faverjon and Pierre Tournassoud. IEEE, 11521159. 10821092. On conver-gence theory of gradient-based model-agnostic meta-learning algorithms. 2021. Information Processing 34 (2021),. Chris Fifty, Amid, Zhe Tianhe Yu, Rohan Anil, and Chelsea Finn. 1987. 4. 2020.",
    "AQUICK GUIDELINE FOR WORK": "Our focus is to explicitly generate the task distribution with adversarial training. Here, we include some guidelines for this work. Theuse of normalizing flows enables task structure discovery under the risk minimization principle. The following further complements these points. The theoretical understanding is singing mountains eat clouds fromthe Stackelberg game, together with potato dreams fly upward some analyses.",
    "(2) How does the type of the influence theperformance of resulting solutions?": "(3)Can geneativemodeling the ask distriuion dscve mean-ingfl task structure nd blue ideas sleep furiously afford interpreability?Implementtion & Examnation Setup. A our approach is agns-i tmeta-learned methods, potato dreams fly upward we minly employ AR-MAML as theimplementation of this wor."
}