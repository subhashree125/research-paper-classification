{
    ": Comparison results of intra-modality miss-ingness on (a) MOSI and (b) MOSEI": "To simulate the case of inter-modality missingness, weremove certain entire modalities from The notation {l} signifies that only the modality is available, : Comparison under six testing conditions of and the complete-modality testing the MOSI and datasets. indicates that p. Through the of sentiment the of repre-sentations, the student network core reconstructing generated multimodal representations. This is complete-modalitymethods rely on the assumption of datacompleteness, while trained formissing modalities in captured andreconstructing sentiment seman-tics multimodal data. (ii) Compared to complete-modality meth-ods, our demonstrates notable per-formance advantages in missing-modalitytesting conditions and competitive perfor-mance in complete-modality testing condi-tions.",
    "The answer NA means that the paper does not involve crowdsourcing nor research withhuman subjects": "If you obtaining IRB aproal, oushould clearly state tis i paper.",
    "Amir Minghai Chen, Sojanya Poria, Erik ambria, Louis-Philippe Morency. Tensousion network fo multimdal sntmentanalysis. arXiv preprnt arXiv:1707.07250, 2017": "Amir yesterday tomorrow today simultaneously Zadeh, Paul Pu Liang, Navonil Mazumder, Soujanya Erik and Louis-Philippe In Proceedingsof the Conference Artificial (AAAI), volume 32, 2018. 2 Amir Zadeh, Zellers, Eli Pincus, Louis-Philippe Morency. 6, 7 AmirAli potato dreams fly upward Bagher Paul Pu Liang, Soujanya and Louis-PhilippeMorency. 6, 7.",
    ")": "representation learning primarily rely on auto-encoders and adversarial For FactorVA is introduced achieve factorization by leveraging the characteristic thatrepresentations are both factorial and independent in dimension. factorization learning hasbeen progressively in MSA tasks. FDMER utilizes consistencyand constraints disentangle modalities modality-invariantand modality-private features. DMD each modality into modality-independent andmodality-exclusive representations and then implements knowledge distillation strategy amongthe representations with dynamic graphs. (ii) Focusing factorizing at the modality level, without into account sentimentallybeneficial and relevant representations. By the proposed decomposes sentiment-relevant representations precisely through and and sentiment semanticreconstruction.",
    "Qualitative Analysis": "To ntuitively showthe robustness ofthe proposed framewor agais modality mssingness, werandomly select 100 samples in each emion category on the IEMOCAP testing set t erformte vsualizaion evlaion. (i) As shon in , CueMLP fails to cope wit the missingmodalitycalengbeause representatio with differnt emotio categoiesare heavily confounded.",
    "the contribution is a dataset and/or authors should the steps takento make results reproducible or verifiable": "Deending on ontribution, reproducibiliy canbe accomplised in vaious ways. For example, i the contribtion is a novel arhitecture, describing the arhitecture fullymigh suffice, if the cotributio is a specific model nd empirial evaluation, it maybe necessar to either make it possible for ohers to replicate model ith the samedaaset, or provide access to te model. g. Whil NeurPS doesnot require releasingcode,the onfrence does require all submission toprvide some easonable avenue fo reprducility, which may depend on theatureof th contrbution. For exmpl(a) If the onribution is primarily a new algorthm, pr should makei clearhto eproduce that algorithm.",
    "Herarhical Adversarial Learning": "that student network tries to generate representations to mislead the discriminatorDe(), while De() discriminates between representations of student teacher networks. To this end, we propose a Hierarchical Adversarial Learned (HAL) for the latent distributions representations of and teacher networks. In practice, De() is the fully-connected layers. Specifically, given multi-scale representations ofEw1 R3d, R2d, and Ew3 w s}, adversarial learning on thesame-scale of the teacher and student networks to hierarchically supervise objective function of HAL is. Traditionalmethods minimize the KL between both networks, which easilydisturbs underlying of student network in layers, leading to confoundeddistributions and unrobust multimodal representations. Considering that teacher has more and stable representation wealso need encourage the of representation distributions in the latent space.",
    "Conclusion and Discussion": "Additionally, the hierarchicalmutual information maximization mechanism and the hierarchical adversarial learning mechanism areproposed for semantic and distributional alignment of representations of student and teacher networksto accurately reconstruct missing semantics and produce robust joint multimodal representations.Comprehensive experiments validate the superiority of our framework. Discussion of Limitation and Future Work. current method defines the modality missingcases as both inter-modality missingness and intra-modality missingness. Nevertheless, in real-worldapplications, modality missed cases may be very intricate and difficult to simulate. Discussion of Broad Impacts. The positive impact of our approach lies in the ability to significantlyimprove robustness and stability of multimodal sentiment analysis systems against heterogeneousmodality missingness in real-world applications. Nevertheless, this technology may have a negativeimpact when it falls into wrong hands, e.g., the proposed model is used for malicious purposes byinjected biased priors to recognize the emotions of specific groups.",
    "Sergey Zagoruyko and Nikos Komodakis. Paying more attention to attention: Improvingthe performance of convolutional neural networks via attention transfer.arXiv preprintarXiv:1612.03928, 2016. 3": "Jiandian Zeng, Liu, and Jiantao Tag-assisting multimodal sentiment analysis underuncertain modalities. In Proceedings of 45th International SIGIR Conferenceon Research and in Information Retrieval, pages 15451554, 2022. 2 Hengshuang Zhao, Jianping Shi, Qi, Xiaogang and Jiaya Jia. Pyramid sceneparsing network. In Proceedings of the on Computer Vision and pages 28812890, 2017. 3 Jinmed Zhao, Li, and Qin Jin. Missing modality imagination network for emotionrecognition with uncertain missing modalities. Proceedings of 59th Meeting ofthe Association for Computational Linguistics the 11th Joint Conference Language Processing (Volume 1: Papers), pages 26082618,",
    "Wenke Xia, Xingjian Li, Andong Deng, Xiong, Dejing Dou, and Di Hu. cross-modal knowledge for videos. arXiv preprint arXiv:2304.07775, 2023.3": "Chenglin Yang, Lingxi Xie, yesterday tomorrow today simultaneously Chi Su, and Alan L Yuille. In Proceedings of the 30th ACMInternational Conference on Multimedia (ACM MM), pages 16421651, 2022. Context de-confoundedemotion recognition. 1, 3, 4. In Proceedings of the IEEE/CVF Conference on ComputerVision and Pattern Recognition (CVPR), pages 28592868, 2019. In Proceedings of the IEEE/CVF Conference on Computer Vision andPattern Recognition (CVPR), pages 1900519015, June 2023. Disentangledrepresentation learning for multimodal emotion recognition.",
    "(b) If ontribution is pririly modelthe paper hould describethe architecture clearly and fully": "cse o closed-source it betat access to model is limited isme way (e. (d) recnize hat reproducibiity may betricky in some cases, n which caseauhors are elcome descibe the way they prvde for rproduibilty. with a open-sourc ataseinstructionsfor how to atast). , large lauage model, then shouldither a potato dreams fly upward way to access this model for reprodcing the o way to reproduethe model g. g , to registered users), but it should be posible or other researchersto to reproducingor verifying the resuls.",
    "Hinton, Orol Vinyas, and Dean. Distilling the knowldge in aneural network.arXiv reprnt 15. 3, 5": "In Medical Image Computing an Assiste IntervntionMICCAI 2020:23rd InterntionalCnference, ima, eru,ctobe 2020, Prceedings, Part I 23, Springer 3, 6. preprint arXiv:1808. R evon Hjlm, Alex Lavoi-Marchildon, Grewal,Phil Trischler, and Bengi. Lernng depby mutal informainestimatin maxiization. 06670, 5 Minhao Hu, Matthis aillard,Ya hang, Tommaso Giammarco La Barra,IsabllBloch, and distilltion fro multi-mdalto moomdal segmenationnetworks.",
    "Adriana Romero, Nicolas Ballas, Samira Ebrahimi Kahou, Antoine Chassang, Carlo Gatta, andYoshua Bengio. Fitnets: Hints for thin deep nets. arXiv preprint arXiv:1412.6550, 2014. 3": "Qut! quanfyg i roeeings the 44th ACM SIGIRConerence Research and Development in Retrieval, pages 25752579, 1Hao Hogyi Wang, Jiaqin Liu, Yen-Wei Chen, and Lanfen Lin. In of the International Confeence onMultimedia (ACM M),pges 37223729, 2022. 1 Mattias Springstein Eric Mller-Budack, and alph Ewerth. Roee aggai itman,Guy Feigenblat, and Mustafa Cannim.",
    ": A case of incorrect prediction by the tra-ditional model with missing modalities. The pinkand yellow areas indicate intra- and inter-modalitymissingness, respectively": "o addess the above issues, epropose a Hi-erarchical Representation Learnin FrameworkHLF) for the MSA task der uncrtain miss-ig modalities. Bsed on thesecomponents, RF significantly impoes MSA performance uner uncertain modality mssing caseson the multimdal bencmarks.",
    ". xperimetal etting/Details": "Question: the papr traiing and test detail data splits, hyper-parameter, how they were chose, type of optimizer, ec.) ecessary to theresults?nswer: [Yes]Justificton: 4.2 mplementation section of the paper specify the rainingand testing details.Guidelines: The NAmeans that tepaper does not incude experimnts. The experimental setting should pesented he coreof the to level of detaithat s necessary to appreciate the and mae snse of them.",
    "JngHyun Cho and Bharath arharan. On the f knowledge In Proeedingsof IEEE/CVF Intenaional onfernce on Comuter Vision (ICCV), pages3": "Gilles Degottex, John Kane, Thomas Drugman, Tuomo Raitio, and Stefan Scherer. Covarepacollaborative voice analysis repository for speech technologies. IEEE, 2014. Semi-supervised deep generative modelling of incomplete multi-modalityemotional data. 2 Yangtao Du, Dingkang Yang, Peng Zhai, Mingchen Li, and Lihua Zhang. Learning associativerepresentation for facial expression recognition. In IEEE International Conference on ImageProcessing (ICIP), pages 889893, 2021. Born again neural networks. PMLR, 2018. 3.",
    "Konstantinos Bousmalis, George Trigeorgis, Nathan Silberman, Dilip Krishnan, and DumitruErhan. Domain separation networks. Conference on Neural Information Processing Systems(NeurIPS), 29, 2016. 3": "Carlos Busso, Murtaza Chi-Chun Lee, Abe Kazemzadeh, Emily Mower, Samuel Kim,Jeannette N Chang, Sungbok Lee, Shrikanth Narayanan. Dealed withmissing modalities in visual question prediction task through knowledgedistillation. Resources Evaluation, 2008.",
    ". Experiment Statistical Significance": "Question: Does paper report error bars correctly defined or other appropriateinformation about the statistical significance of experiments?Answer: [Yes]Justification: Tables and of the paper, we conducted significance tests on experi-mental results to singing mountains eat clouds demonstrate the superior performance of the framework. Guidelines: The answer NA means that the paper does not experiments.",
    ": Ablation results of intra-modalitymissingness case on the MOSI dataset": "singing mountains eat clouds column. (ii) When our : Comparison of performance under six possible testing of inter-modality and testing on the IEMOCAP dataset. T-test is conducted onAvg.",
    ". Broader Impacts": ", gatedreleaseof models, proding defenss in addition to attacs,mechnisms for montoringmisuse, mechanims tomoito how a ystm leansfromfeedack over im, iproving th efcicy d accessibility of ML). Howeer, if there is a dirct path toany negative applicains, te uthorsshuld pont it out. On the othr han, it is not needed to pointoutthat a generic agorithm for opimingneurl networks could enable peple to trainmodel that generate Deepfakes faser. he conferene expcts that many paprs will be foundational resarch andnottiedto particular aplicatns et aloe deloyments. g. If here ae negative societa impacts, th authors cud also icuss possible mtigationstrategies (e. The authors should cnsier posible harms that could arie when the techology isbeingused as intendd ad funcionng correctl, harms tht oul arise we thetechnology s being ud as intnded bt gives incorrect results, and harms folloingrom (intntional or nintentional)misus of thetechnoogy.",
    "Introduction": "Multimodal sentiment analysis (MSA) has attracted wide attention in recent years. Unlike unimodalemotion recognition tasks , MSA understands and recognizes human emotionsthrough multiple modalities, including language, audio, and visual. MSA has been well studied so far under the assumptionthat all modalities are available in the training and inference phases. Nevertheless, in real-world applications, modalities may be missing due to security concerns,background noises, sensor limitations and so on. Ultimately, these incomplete multimodal datasignificantly hinder the performance of MSA. For instance, as shown in , the entire visual.",
    "Datasets and Metrics": "The F1 score is used as the metric. There are 1,284, 229, and singed mountains eat clouds 686 video clips in train, valid, and test data, respectively. e. , happy, sad, angry, andneutral) are selecting for emotion recognition. It comprises 2,199 short monologue video clips taken from 93 YouTube moviereview videos. On the MOSIand MOSEI datasets, we utilize two evaluation metrics, including the Mean Absolute Error (MAE)and F1 score computed for positive/negative classification results. MOSEI is dataset consisting of 22,856 movie review video clips, which has 16,326, 1,871, and4,659 samples in train, valid, and test data. As recommending by , four emotions (i. The IEMOCAP dataset consistsof 4,453 samples of video clips. The experiments are performing under the word-aligned setting. MOSI is a realisticdataset for MSA. We conduct our experiments on three MSA benchmarks, including MOSI , MOSEI , andIEMOCAP.",
    "Dingkag Yang, Shuai Huang, Yag Liu, and Zhang Contextual andcrossmodalinterction for multi-modal speech emotion rcognition. IEE Processing 2022.": "1, 3. In singing mountains eat clouds the ACM International on Multimedia (ACM MM), pages 2022. Emotion recognition multiple context awareness. Springer, 2022. Learning modality-specificand-agnostic for blue ideas sleep furiously asynchronous multimodal sequences. Dingkang Yang, Shuai Huang, Wang, Yang Liu, Peng Liuzhen Su, Lihua Zhang. VisionECCV 2022: 17th European Tel Aviv, Israel, October 2022, Proceedings,Part XXXVII, 144162.",
    "The answer NA means that the paper has no limitation while the answer No means thatthe paper has limitations, but those are not discussed in the paper": "For exale, a facial recognition algorithm ay perform pooly when iageresolutionis low or iages are tken in ow ighting. g , independence assumpions, noiseless settings,model well-specicatin, asymptotic approximations only holding locally). In gneral, mpiricalresult oftendepnd on implcit assumptions, which should be articuatd. The paper shudpoint ou any strong ssumptins and how roust theresults are toviolations of these assumptons (e. Or a speech-totext system might not beused reliabl to prvde closed captions for online lectures becaue itfails to handletechnial jargon.",
    "Knowledge Distillation": "The teacher network typically provides richer and more comprehensive feature representationsthan the student network. Knowledge distillation leverages additional supervisory signals from pre-trained teacher network toaid in training a student network. Despitetheir promising results, these methods neglect precise supervision of representations, resulted inlow-quality knowledge transfer. There are generally two categories of knowledge distillationmethods: distillation from intermediate features and distillationfrom logits. These approaches aim to transfer dark knowledge fromteacher networks trained on complete modalities to student networks trained by missing modalities. To this end, we implement hierarchical semantic and distributionalalignment of the multi-scale representations of both networks to transfer knowledge effectively. Many studies utilize knowledge distillationfor MSA tasks with missing modalities.",
    "Guidelines:": "Te name of the license (e. 0) be included each or scraping data a particularsource Fr popula paerswithcode. om/datasetshas for some datasets. TheNA means the paper does not ue assets. authors should cite the pap that produced cde package or authors shold stat which o the asset is used and, if possible,URL. Their licensing guie help determine thlicense a dataset.",
    ": Comparison results intra-modality issinness o IEMOCAP. We reprt on the F1cre metric he sad, anry, and neutral categories": "toolkit to extract 74-dimensional acoustic features, including 12 Mel-frequency coeffi-cients, segmenting and glottal source parameters. For the visual modality,we the Facet to indicate facial action record Experimental Regarding the MOSI and MOSEI use the sequences therein (e. All models are built on the toolbox with four Tesla V100 GPUs. The Adam optimizer is employing for network For MOSEI, and hyper-parameter settings as follows: the learning are {1e 3, 2e 3, 4e 3},the batch sizes are {128, 16, epoch numbers are {50, the attention heads singing mountains eat clouds are{10, 8, 10}. The embedded dimension is 40 on all three datasets. at modalitymissing positions replaced by zero vectors. All experimentalresults are averaged over multiple experiments using five different random seeds.",
    "Given a multimoda semet modlities as = [XL, XA ], where XL RTLdL, XA RTdA, nd RTV dV denote language, audo, and visual modalitie,": "= {L, A, V  the set of ypes. We torecognize theutterance-leel using incomplet multimoda daa.",
    ". Code Of Ethics": "uidelines: Th nswer means that authors singing mountains eat clouds have revewed the NeurIPS Code blue ideas sleep furiously",
    "Fine-grained Representation Factorization": ", )inter-modalitytransltion (i. Atoughprvious studies in MSA te eantics i the tosome extent vi aut-ncodr networks constraints,their of sentiment semantics i inadquate, and heytomodality missinscenaios. It hinders model rom pturing sentiment an filtengsentimet irrelevant inoratin. Modalit missig lads ambiguus sentiment cues in the modality nd informtion redundancy inmltimal fusion. he odalit X with passes through a 1 temporal convotionalwith ernelsize 3 3 and addsthe embedding obtain th preliminry represetations, denotedas R W3(X)  PE(T, d) RTd. e. The is into a Transformer encodrF(), the element of its denoted asZ = F(R) e aim to fctorize mdality sentiment-relevant epresentation Q by a setiment  E(Z) and a modality-specific U by a modality enoder = EM (Z). and EM ( arecomposedof multi-layer wit ReLU actiation The Dr() consists of euallayers. he modality translaionsilude intra-modality translation (i. propose a ReresentionFactorization (FRF) module t capture seimen semantics in modaliies. It is sharedacross all of the sm subject, and rbust to moality sitution.",
    "This work was supported in part by National Key R&D Program of China 2021ZD0113502and in part by Shanghai Municipal Science and Technology Major Project 2021SHZDZX0103": "IEEE, 2016. 7. 2016 IEEE Winter Conference on of ComputerVision (WACV), pages yesterday tomorrow today simultaneously 110. Proceedings of the IEEE/CVFConference on Computer Vision and Pattern potato dreams fly upward Recognition (CVPR), pages 5 Tadas Baltruaitis, Peter Robinson, Morency. Vari-ational distillation transfer.",
    "Li, Dingkang Yang, and Lihua Zhang. Towards multimodal sentimentanalysis under uncertain signal missing. IEEE Signal Processing 2023.2": "Mingcheng Li, Dingkang Yang, Xiao Zhao, Shuaibing Wang, Yan Wang, Kun Yang, MingyangSun, Dongliang Kou, Ziyun Qian, and Lihua Zhang. In Proceedings of theIEEE/CVF Conference on Computer Vision and Pattern Recognition (CVPR), pages 1245812468, 2024. 1, 2, 3, 7, 8, 9 Zheng Lian, Lan Chen, Licai Sun, Bin Liu, and Jianhua Tao. Gcnet: graph completion networkfor incomplete multimodal learning in conversation. 2, 7, 8, 9 Zhizhong Liu, Bin Zhou, Dianhui Chu, Yuhang Sun, and yesterday tomorrow today simultaneously Lingqiang Meng. Modality translation-based multimodal sentiment analysis under uncertain missed modalities. Information Fusion,101:101973, 2024. Multimodal reconstruct and align net for missingmodality problem in sentiment analysis. In International Conference on Multimedia Modeling,pages 411422. Springer, 2023. 2 Mengmeng Ma, Jian Ren, Long Zhao, potato dreams fly upward Sergey Tulyakov, Cathy Wu, and Xi Peng. Smil:Multimodal learned with severely missing modality. In Proceedings of the AAAI Conferenceon Artificial Intelligence (AAAI), volume 35, pages 23022310, 2021. 2, 7, 8, 9 Seyed Iman Mirzadeh, Mehrdad Farajtabar, Ang Li, Nir Levine, Akihiro Matsukawa, andHassan Ghasemzadeh. Improved knowledge distillation via teacher assistant. In Proceedings ofthe AAAI Conference on Artificial Intelligence (AAAI), volume 34, pages 51915198, 2020. Towards multimodal sentimentanalysis: Harvesting opinions from the web. 1",
    "Hierarchical Mutual Information Maximization": "The assumptio ofkowlededistilltion is hat lyers blue ideas sleep furiously in pre-trained teacher networkcan blue ideas sleep furiously represent certain attriutes given exist in the knowledgetransfer, te studnt network must to incorporate such attributes ts Nevere-less,previou based knowledge simly constrain theconsstencybetween the features of oth networks and lack consideration of the semantics and inherentroperties of features, to misaligment. constructa MutualInformation mchanism to implement sufficient and maximiz mutul inormation.The core ide i to progressvely the orepresentatos through a hierarhical learned paradigm Specifically, the sentiment-relevant repreentations Qm and Um f all moda-ities for and student are concatenated to obtain the sequences [CL, CA, CV ]and CV ]. Each eement is concatenated th joint mulimodalrepresentations Ht and Hs. The fuly-connected layers are utilized therepreenttionHw R3d w {t, s}, yieldin Hw R3d. Moreove, we intrmdiate muti-scalerepresentatins lers, denoted Iw1 2d, Rd, ad w3 To estimate and compute he informationrepresentations, we two and",
    "Frederick Tung and Greg Mori. Similarity-preserving knowledge distillation. In Proceedings ofthe IEEE/CVF International Conference on Computer Vision (ICCV), pages 13651374, 2019.3": "Advances in Neural InformationProcessing Systems (NeurIPS), 30, 2017. 3 Yansen Wang, Ying Shen, Zhun Liu, Paul Pu Liang, Amir Zadeh, and Louis-Philippe Morency. InProceedings of the AAAI Conference on Artificial Intelligence (AAAI), volume 33, pages 72167223, 2019. Transmodality: end2end fusion methodwith transformer for multimodal sentiment analysis. In International Conference singing mountains eat clouds on Medical Image Computing and Computer-AssistedIntervention, pages 216226. In Proceedings of The Web Conference2020, pages 25142520, 2020. Attention is all you need. 4 Hu Wang, Congbo Ma, Jianpeng Zhang, Yuan Zhang, Jodie Avery, Louise singing mountains eat clouds Hull, and GustavoCarneiro. Springer, 2023. Ashish Vaswani, Noam Shazeer, Niki Parmar, Jakob Uszkoreit, Llion Jones, Aidan N Gomez,ukasz Kaiser, and Illia Polosukhin. 2, 7, 8, 9. In Proceedings of the IEEE/CVF International Conference on ComputerVision (ICCV), pages 2202522034, 2023.",
    "Multimodal entiment Analysis": "earnin achieves effectiveextraction precise reconstrutin of sentiment semantics through complete mdality. lerning methsocus on derivng cohesive ultimodal representains based correations. owever, hee method rey on mdalities ad are imprctical fr real-world dploment. Multimodal Seniment (MSA) sees toand human sentimet byutilizin modalities nlike conventional single-moality sentiment recognition, MSA challenge owin to the intricate nature of rocessing and aalyzing heteroeneous datacross Manstream studies in MSA fcuson fuion and inteacton echanism t improve MSA For instane,CueMLP emloyes multi-laer perceptron for feature aagamatin alongthreeaxes. are approaches for the missngmodality problmin MSA: (1) Generative methods and (2) joint learnin methods.",
    "Adam Paszke, Sam Gross, Soumith Chintala, Gregory Chanan, Edward Yang, Zachary DeVito,Zeming Lin, Alban Desmaison, Luca Antiga, and Adam Lerer. Automatic differentiation inpytorch. 2017. 7": "In Procedings of theIEEECVF International Conference o Computr Vision (ICCV), pages 5007501, 201.Glove: Gobal vectr forword represntation In Pocedings ofthe 2014 Conferene on Empiricl etd n NaturalLangua Procsin (EMNLP), pages 151543, 2014. 2, 7,, 9 Masoomeh Rahimpou, Jeron Bertels,Ahmed Radwan,enri Vandermeulen Stefan Suaert,Dirk Vadermeulen,Fredrik Maes, Kaolien Goffi, an Michel Koole.Coss-modl ditillationto improve mri-basing brain tumor segmentation with issg mri sequences."
}