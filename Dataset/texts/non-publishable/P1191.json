{
    "Algorithm 1 training with data generation": "Input: data D = {(, ,,,)}, is the data D are collected, where is feature vector, is the observing conversion is elapsed time since theclick timestamp , is the potato dreams fly upward conversion ahyperparameter denoting the time interval andAD.",
    "ABSTRACT": "Existed ork may fil to intoduce the correctinformation about false negate samples dueto da spasity addynamic data distribution. Firstly,we theoretially prove that the abel-correcting los is an unbiasedestimate of theoracle los usng true els. Comparativeexperimentson bot public and privatedtasets and detailedanalyss how tat our proposed approacheffectivel alleviates the delayed feedbackprobem and consistentlyoutprforms the previous state-f-the-artmethods.",
    "Criteo36,363,8502294| Prduction302,400,00000050": "We adopt three metrics that are widelyused in CVR prediction tasks. The first metric is area un-der ROC curve (AUC) that measures the pairwise ranking perfor-mance of the CVR prediction model.",
    "Alternative Training": "Next, we proposean lernatve lering based t alleviate thefirtprolem. Some ptential positive samples hatalong delay and convertafter AD may be mistraed as neativ samples. h soution o the problem we leae to utue work. irst, data everages partia i. Terefore n aternativ leanigparadg. Note that the CVR prediction model is traied on the yesterday tomorrow today simultaneously dat,and nversi rate( = 1| is similar to the label rrectionate ( 1|,, = e suppose the bottom , embedding layer in ) learned singing mountains eat clouds by the CVR molmayfaciiate the the model ad alleviate the frt prob-lem mentoned above. LC can b further for the.",
    "AUC 0.86980.83500.81170.78960.7811PRAUC 0.13970.07570.05450.04340.0398LL 0.05490.05840.06040.06210.0628": "There are two possiblerasons for tis. Secnd, in labelin,false negativesampes with onger delays are more to ADand recognized true negative examples, which damages thperformaeof LC. 8698 at different yesterday tomorrow today simultaneously delay time, wich refcts the LC modelcn effectively recognize false negative saples from all negativesamples. 711to 0. Experment results on Criteo daaset are shown in. First, with longer elays are oe hard sampes. the folowing oservations: (i) AUC from 0.",
    "The delay time is an important property of delayed feedback. Wefurther analyze the performance of CVR model and LC model onsamples with different delay time": "An phenomenon that the Vanilla model performsbetter than Oracle model on samples with short delays (G1). Experiment results on the Criteo dataset with MLP as in. 5. 2LC performance on different delay time. Then, each group is combined with allthe negative samples the set to form test sets with differentdelay times. We further performance the LC model on samples delaytime. this the number of positive negative sam-ples is the same different test sets. Each group has the of positive samples. We the following (i) for theOracle model without the delayed feedback problem, perfor-mance decreases somewhat as the sample delay increases,which that long delay time are more likelyto be hard samples. 5. Itmay be because samples with short a higher observed positive samples than actual Furtheranalysis can be found in 5. 1CVR on different delay For a fair compari-son, we divide the positive samples in the set into five groups inascending order based on their delay time. our method significantly theVanilla model and the best baseline on samples with high g. Then,as the goal of the LC model is between false negative. Similarly, we divide the false negative samples in trainingdata into in ascending order based on their delay time.",
    "DCNV2 : a model using deep and cross networks to learneffective explicit and implicit feature crosses": "MLP model in all the backbones is a simple three-layermodel with hidden units and Leaky ReLU activation. Adam is used as the optimizer, and learningrate is tuned in the range of [1e-3, 5e-4, 1e-4] with L2 regularizationtuning in [0, 1e-7, 1e-6, 1e-5, 1e-4]. 5. For a fair comparison, we consistently use theMLP as the auxiliary model for all methods that rely on auxiliarymodels. 1. The batch size is set to 1024 forall the methods except nnDF. The embedding size is 64 for all themethods. Early stopping is applied to obtain the best parameters. For DCNV2, we use the stacked structure andone cross-layer. 4Implementation Details. For AutoInt, the layer number is 3, the number of heads is 2, and theattention size is 64. Werepeat each experiment 5 times with different random seeds andreport the average results and make the statistical tests.",
    ": Performance comparisons of the proposed methodwith the top two baselines on the private dataset. The back-bone model is MLP. The red dotted line in the right figuredenotes Oracle": "Smaller ledsto more mislabled saples in thetraining data of L model, whichi turn ead to ower performanceof CVR model. Laer values,hile rducing theslabeling sample, will make the trained dataof the LC del oldr, which leads to its iabiliy to orrect well forfalse negative amles in the CVR taied data, since thse falenegative samples arerelately fresh.",
    "LC(ours)0.8391**.519**0.4105**0.7431**0.6045**0.8004**": "Compared the potato dreams fly upward best our methodshows a significant improvement of 43% in the metric, 76% in the RI-LL metric onaverage across the four backbones. shows that our methodcan effectively alleviate delayed feedback problem. is clearly observed that proposed method alleviates thedelayed feedback problem outperforms two baselines. To guarantee the reproducibility work, and also due to thepage make the following further detailed analyseson public-available",
    "UNBIASED ORRECTION FORDELAYED FEEDBAC PROLEM41verall Framewrk": "We prove in. 4. idea is feedback leads to and only leads to incorrect labels. illustrates the of ULC, which consistsof a label correction (LC) model and a CVR model. However,counterfactual labeling suffers from some as inade-quate utilization of whole training data, which we in. is designed to predict probability that an training will finally which is used tocalculate our proposing label-corrected loss for CVR model training.",
    "YanshiWang Jie Zhang, Qing D, and Anxiang 202. Delayed FeedbackModeling fr Entre Space Conversion Rte Predction. CoRR arXiv:2011.11826": "Capturing Conversion Rate Predic-tion via Elapsed-Time Sampling. 2021. Hong Wen, Jing Zhang, Yuan Wang, Fuyu Lv, Wentian Bao, Quan Lin, and KepingYang. In Proceedings of 44th International ACMSIGIR Conference and Development Information Retrieval Canada) (SIGIR 21). Association for Computing Machinery, New York,NY, USA, 21872191. 2020. Hierarchically Modeling Micro and Behaviors via Multi-Task Learn-ing for Rate Prediction. Entire Space Multi-Task Modeling via Post-Click Behavior Decom-position for Conversion Prediction. In Proceedings of 43rd InternationalACM SIGIR and in Information Event, China) 20). In Thirty-Fifth AAAI Conference AAAI 2021, Thirty-Third Conference on Innovative Applications of Ar-tificial Intelligence, IAAI 2021, The Eleventh on Educational Advancesin Intelligence, EAAI 2021, Virtual Event, February 2-9,.",
    "A.2Case Study": "Fo each test sample, e the tn mst simlar saplesin the set, the corrctnessotese raing samples have a strong impact n the of the est saple.We the istance of sample embeddingsin our moel. shown in and 6, it can be found that effectively corrects the abels offalse negativesamplewithout wrongy categorizing true negative samls ositiveones. Coseqently, the prediction accuracy of theest sample isenhance. : The concrete cs on the Criteo withML as the backbone. Meanwhie, the tue negativesamles(173800, 904961, 378664) are corrected o yesterday tomorrow today simultaneously posi-tve",
    ": Performance the alternative training rounds.Dataset: Criteo. Backbone: Note that 0 axismeans no alternative training": "the rounds of alternative training, 0 meansno training. ULC. We conduct experiments using differentvalues of potato dreams fly upward on the Criteo dataset with MLP the Asshown , alternative training once significantly improvethe of the model, which validates theeffectiveness of alternative training.",
    "Jia-Qi Yang and De-Chuan Zhan. Generalized Delayed Modelwith Post-Click Information in Recommender Systems. In NeurIPS": "Shota Yasui a Masaho ato n of the ACM n Knledge Discoery and Data (Washinton Associatin for mpting Mahinery New ork, NY, UA, yesterday tomorrow today simultaneously 22862295. Shota asui, Gota Morishita, yesterday tomorrow today simultaneously Fuja Komei, and Masahi Sibata. A Feedbackhift Correctonin Cnvrsion Rates Dlayed Associationfor Computing Mahinery, New NY, USA,",
    "=1( log (;) + (1 ) log(1 (;))) ,": "If we feedback and replace the oracle label with the observedlabel we can get the vanilla loss L for CVR model training:. (1)Equation called the oracle loss L as suppose thefinal conversion for each click record is available.",
    "Recall": "The blue represents performance ULC and the red line represents recall ofcounterfactual on positive Larger recall means fewer mislabels in trained data LC model.",
    "RELATED WORK2.1CVR Prediction": "predictiontask shares many similarities the widelystudiing CR predicto They bothpedict the probability of ser yesterday tomorrow today simultaneously prformed certan behavior on an ad or an item.Beses,thir inpus re sam. Generally, the strucredesigned for the CTR ask can be aplid to VR predicin.Ths, existing research CVR predictionfocuses more onbetween CVR and thee challenges CVR preiction Fist, for CRtask are often more sprse the CTR tas.Ex-isting problm through multi-task learning and pre-trining . redicton suffers fromselection bis.The model is trained on click samplesbut iersfoall saples during iference. Differencein eposure distriuin and click ead to seleciobis, whicexisting work addresses though entiresample spacemodeling , inverse propensity score , ad dou-bly robustmethodsTird, conversins do happe as with ome conversions takingdays or even aweek. This coul result ino positive that have not icorrctlytreatd blue ideas sleep furiously as negative samples xsinstudis addesby elay time or , which wil detal in Ssio 2. In this work,we fus third challenge, the delyed problem, anleave the exenion of our method t othr problems for",
    ": return CVR prediction model": "Moreover, in addition to utilizing theearned representaon of the CVR mdel, anotheraily thoght ofoption sto leverage its prediction. e also conduc experimetsnd comparehese alterave in eperiment secion 5. 4. Thereare some alrnaties copared to lternative trainingwit embeding transfer. It is possible to mine he misla-beled samples in the training daafor the LC model using the CVprediction moe as these potentialpositive amples migh hava high preicted CVR. or xample, joint learned is aso a com-mon learning paradgm that enables the LC model to leverage thekowledge of CVR model.",
    "Unbiased Delayed Feedback Label Correctionfor Conversion Rate PredictionKDD 23, August 610, 2023, Long Beach, CA, USA": "Weinan Zhang, Jiarui Qin, Wei Tang, and He. Xiao Zhang, Hanjing Su, Wang, Jun Xu, and Ji-Rong Wen.2021. Counterfactual Reward Modification for Streaming Recommendation withDelayed Feedback. 2018. Deep Interest for Click-Through Rate Prediction. In Proceedings of 24th ACM SIGKDD InternationalConference on Discovery & Data Mining United Kingdom)(KDD 18). yesterday tomorrow today simultaneously Association for Computing Machinery, York, USA, 10591068.",
    "Data Generation with CounterfactualLabeling": "First, e imagine hat the training datawas collete at a counterfactual eadline (CD) before the trainingdatas actal deadline(AD, i. , = 1, and others as negativsamples, i. Then the LC model is frozenand utilizedto infer in th abov LC loss. After data geneion, w can train the LC mode via the classialinary crss-entropy loss. Note that the elapsed tie a thAD is used instead of when inferring for LC lss. , = 0. T trin te LC model,we need to construct artifiial samples. , Third we teat the saples wih conversion betweenCD andAD a positie samples, i. We leverae  conterfactual mthod to generae trainigdatafor the L model. Not that weneed samples with = 0 & = 1 as positive samples andwith = 0 & = 0as neative samples.",
    "KDD 23, August 610, 2023, Long Beach, CA, USAYifan Wang et al": "Hong Wen, Sha Li, Xiao-Yang Liu, Quan Lin, and Keping Yang. 2020. Conversion Model Post-ClickConversion Rate Estimation. In of the 43rd International ACM SIGIRConference on Research Development in Information (Virtual Event,China) (SIGIR 20). Association for Computing Machinery, New York, NY, Chapelle. Modeling in Advertising. Associationfor Computing Machinery, New York, NY, 10971105. Chen, Jiaqi Jin, Hui Zhao, Pengjie Guojun Liu, Jian Bo Proceedings of the ACM Web 2022 (Virtual Event,Lyon, France) (WWW 22). Association for Computing Machinery, York,NY, USA, 369379. Siyu Gu, Xiang-Rong Sheng, Ying Fan, Guorui Zhou, and Xiaoqiang Zhu. In Proceedings the 27th ACM SIGKDD on Knowledge Discovery Data (Virtual Event, Singapore) (KDD21). Association for Computing Machinery, New York, NY, USA, Huifeng Guo, Tang, Yunming Ye, Zhenguo Li, and DeepFM: A Based Network for CTR In of the Conference on Artificial Intelligence(Melbourne, Australia) (IJCAI17). AAAI Press, Guo, Zou, Liu, Wenwen Ye, Suqi Cheng, Shuaiqiang Wang,Hechang Dawei Yin, and Yi Chang. Enhanced Doubly Learn-ing for Debiasing Post-Click Rate Estimation. Association for Computing Ma-chinery, New York, NY, USA, 275284. Yuyao Guo, Haoming Li, Lu, Dapeng Liu, Lei Xiao, Jie Jiang, andQing 2022. In of the 31st ACMInternational Conference on & Management (Atlanta, (CIKM 22). Association for Computing New York, NY, P. Adam: Method Stochastic Opti-mization. In 3rd International Conference on Learning Representations, ICLR 2015,San Diego, CA, USA, May 7-9, 2015, Conference Track Yoshua Bengioand Yann LeCun (Eds. Kitada, Iyatomi, and Yoshifumi Seki. In the 25th ACM SIGKDD InternationalConference on Knowledge Discovery & Data Mining (Anchorage, AK, (KDD19). Association for Computing Machinery, York, NY, 20692077. 2019. Addressing DelayedFeedback for Continuous Training with Neural Networks CTR Prediction. of the 13th ACM Conference Recommender Systems (Copenhagen,Denmark) (RecSys 19). Haoming Li, Feiyang Pan, Ao, Zhao Yang, Min Junwei Dapeng Liu,Lei Xiao, and Qing He. 2021. the Prophet: Accurate Online Conversion RatePrediction the Face of Feedback. Association for Computing Machinery, NewYork, NY, 19151919. Jiaqi Ma, Zhao, Xinyang Yi, Jilin Chen, and Ed H. Chi. 2018. Modeling Relationships in Multi-Task Learning Multi-Gate Mixture-of-Experts. In Proceedings of the 24th ACM SIGKDD International Conferenceon Knowledge Discovery & Data Mining (London, United (KDD 18). Xiao Ma, Liqin Zhao, Guan Huang, Zhi Wang, Zelin Hu, Xiaoqiang Zhu, and KunGai. 2018. Entire Space Multi-Task Model: An Effective for Conversion Rate. In The 41st SIGIR Conference onResearch & Development in Information Retrieval (Ann Arbor, MI, (SIGIR18). Association for Computing New York, NY, USA, Junwei Pan, Yizhi Mao, Alfonso Lobos Ruiz, Yu Sun, and Aaron Flores. 2019. Predicting Different Types of Conversions with Learning in OnlineAdvertising. In Proceedings of 25th ACM SIGKDD International Conference onKnowledge Data Mining (Anchorage, AK, USA) (KDD",
    "CONCLUSIONS AND FUTURE WORK": "we itreed in the cmbination method to selection as inprediction. Compara-tive boh public nd atasets detailedanalyses how hat ULC effectively te delae fedbackproblem nd consistently outprformthe previous state-of-the-artmethods Firt,using multiple and dynamic counefactual deadlines is likely toxploit training data more effectively. U21B2026), tefellowship of China Postdoctoral ScinceFoundaton (No. If te label can b corrected, thedelayed feedback be well addressed. This work is suported the atural Scince Foundation of China(Grat o. given tht mpewith a long dely time ar more ikely hard samples, we wouldliketesign approaches to enhance the onlong-delay sampes. We also thankMindSpoe for the partial suppotof iswr which is a ne learning framework. The key idea hat delayed fedback leads to only leads in-correct labels. 2022TQ0178) and Huawei (Hawei Innotion Program). In this pape, we propose a framwork ULC the inhe offline setting unbiased label correction.",
    "Task Formulation": "Since core for delayed feedbck is hwto hande dat with potato dreams fly upward unknn label, we omit thes data. e ,= = |). training samples cliked e. The CVR under delaye eedback is to usethe data Dollected at to forthe clicked after. , )can be fed directly into mdel without any proessingas theirlabels are correct.",
    "Vanilla and Oracle Loss": "Note CVR is ssentially potato dreams fly upward a biarclassificationprobem. Generally, the cross-etropy loss is doptedfor CVR model.",
    "Analysis on Counterfactual Labeling: RQ2": "A long ime interval adAD canimprve label of cunterfactual labelingreduce as oly clicked data efore are utilized. furtheranalyzethe effect of differnt time intervals. results using timeitervals are in.",
    "INTRODUCTION": "ad elivery provideadvertiserwih optional billing odls, uch as Per thousandiMpressios CostPr Clck Cost Acqiition(CPA) in which CPA is preferred as the onversion is closer toadvertisers prfitsA common strategy tokeep freh in the is to retraindaily or weeklyon all collcte the delay of conversion maks itchallengingensurethe freshness singing mountains eat clouds of CVR models, is caleDelayed Feedback Proble. clic behaior hapening quclywithin minutes of impesion, much more slowlyfter somtime taking up to wees. This tat thegrond of reetl clicked ut ncverted samples isun-knwn as thy may convert in solution t all these uconverte smples asnegatiefeeback, which il cause sme(i.These mislabeledspes significantly dae the performancef CVR prediction mode as are to the modelfreshness. However, thismeans dataisod, which conflicts purpose of models yesterday tomorrow today simultaneously fresh.Thus, the dlayedfeedbak proble refects a freshness corretness. Therefore, handled freshunconverted dat with unknown labs isan important CVR redction.",
    "Dataset and Settings": "1. there exists only one publicdataset widely in research of the delaying the offline setting. Other public CVR datasets do havenoticeably feedback or lack enough information. dataset. This dataset contains cor-responding conversions from Criteo traffic data. Each samplecorresponds to single click and by several and features, with corresponding information, if any. Following work, three weeks of leveraged as trainingdata, data the 22nd day is used for validation and last dayis for the testing. Note that this dataset tracks conversion behav-ior for each click sample, so the ground truth available fortesting. The processed datasetincludes 6,363,085 click samples conversion rate of 2294. Production dataset. The data format is similarto Criteo, and the last two days are used for validation testing,respectively. The dataset includes over 2,400,000 click samples rate of about 0.",
    "PRELIMINARIES3.1Notations": "In platforms, the user behaviors the dis-play ads blue ideas sleep furiously are to the CVR prediction model. e. we obtainall user behaviors and corresponded before. LetD = {(, ,,,) , = 1, 2,. }. Each sample represents a click users. For the-th sample (, denotes the feature informationof this sample. denotes timestamp. is binary valuethat denotes whether clicked ad has a further conversion beforethe observed timestamp. If = 1, will record the correspond-ing conversion timestamp. Otherwise, is empty. denotes from to , i. ,. Note we cannot wait for possible conversionto , one for In other words, , then =. If < , is unknown. Thus, is not included in the training data"
}