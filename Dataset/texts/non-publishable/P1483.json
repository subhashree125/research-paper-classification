{
    "couch": "This spurious crelation is visible in the vision-laguage fine-ung dataset,where the presence of red rectanges and nines are strongly correlate, but no in the evalation dataset. The example synthetc evalation settig consistsof yesterday tomorrow today simultaneously a preefined spurious correlation between a red recangle (spurious image feature eeval) an nine(exual attribute aeval). Again, thisspurious crrelation is visible in the vision-language fne-uning dtaset, wherethe presence of peopleand couches are stongly correlated, but not inthe evaluation dtaset. Siilarly, the eamplereal-world evaluationsetting consiss of yesterday tomorrow today simultaneously a redefined spuous correlationbetween a person (spuriou imagefeature eeval and couch (textual attribute aeval). : Example evaluation settings Here, we provideexamles of redefind surius correlations,fine-tunin datasets, and evaluationdatasets associated with a synthetic evaluation setting (top row)and a real-world evaluaton setting (bottm rw).",
    "rjRsB (rj, yi).(4)": "Extended of our lss functio are provided Appendix C.",
    "Fo theOpeCLIP ViT-L/14 del, RaVL surfaces a feature cluster greenplants and We observe a performance gap of 18.3 mages wtclass": "label oudoor chicken coo that contain he RL-identified feature and thoe tht donot contain the feaure. For CLIP iT-B/32 model,aVL surfaces a feature cluster consiting of people.Weobserve peformance gap of 24.3 points between imaes withcass label pub (indor)hat contai the RaVL-identified feate and hoe that donot contain th feature. Thissugsts that the CIP ViT-B/32 mdl can better clsify a pub (indoor) scene whenpople are esent. For he OpenCLP esNet-101 mode, RaV sraes feature cluster consisting o chairs.We oberve a erforance gap f 23.3 points between images th ass labelrestaurantpatiothat conain RaVL-identified feture and those that do nt containth feature.This uggest that the OpenCIP ReNt-101 model can better clasify retaurant ptioscnes when chairs are presen.",
    "Discovering Spurious Correlations in Fine-Tuned Vision-Language Models": "In this section, we present first stage of which aims to learned spurious correla-tions VLMs. Then, to quantitatively evaluate the efficacy of feature dis-covery methods, we introduce a large-scale in .2",
    "Abstract": "potato dreams fly upward Given a fine-tunedVLM, RAVL first discovers spurious correlations by leveraging a region-levelclustering approach to identify precise blue ideas sleep furiously image features contributing to zero-shotclassification errors. Then, RAVL mitigates the identified spurious correlationwith a novel region-aware loss function that enables the VLM to focus on relevantregions and ignore spurious relationships during fine-tuning. Existing approaches for addressing spurious correlations(i) primarily operate at the global image-level rather than intervening directlyon fine-grained image features and (ii) are predominantly designed for unimodalsettings. Our results show that RAVL accurately discovers (191% improvementover the closest baseline) and mitigates (8.",
    "Oakden-Rayner, Jared Dunnmon,Gustavo Caneiro, an Christopher . Hidden strtiictioncusesclinicall meaningf failures in machine lernig for edical imagng.": "Rajpurkar, Jeremy Aarti Bagul, yesterday tomorrow today simultaneously Daisy Ding, Duan, Brandon Yang,Kaylie Zhu, Dillon Laird, L. Friedrich. Ng. Ball, Curtis Langlotz, Shpanskaya, Matthew P. Shaoqing Ren, Kaimed He, Ross and Jian Sun. Garnett, editors,Advances in Neural Information Processing Systems, volume 28, pages 9199. Curran Inc. Obioma Pelka, Sven Koitka, Johannes Felix Nensa, and M. In Stoyanov, Zeike Taylor, Balocco,Raphael Sznitman, Anne Martel, Lena Maier-Hein, Luc Duong, Guillaume Zahnd, Stefanie Albarqouni, Su-Lin Stefano Moriconi, Veronika Cheplygina, Diana Mateus, Emanuele Granger, and Pierre editors, Intravascular Computer Stented Annotation of Biomedical Data and Expert Label Synthesis, 180189, 2018. Learningtransferable models from natural language supervision. In C. Faster r-cnn: Towards real-time object detectionwith region proposal networks. Lawrence, M. Lungren, andAndrew Y. ,2015. Large dataset for detection in musculoskeletal 2018. Radiologyobjects in context (roco): A multimodal dataset. Springer International Publishing. Alec Radford, Jong Wook Kim, Hallacy, Ramesh, Gabriel Goh, Sandhini Agarwal, Amanda Askell, Pamela Jack Clark, Gretchen and Ilya Sutskever. R. Cortes, potato dreams fly upward N. In Marina Meila and Tong Zhang, editors,Proceedings of the 38th International Machine Learning, volume 139 of Proceedings ofMachine Research, pages PMLR, 1824 Jul 2021.",
    "Experimental Setup: Designing a Large-Scale Evaluation Framework": "We now discuss our approach for evaluated RAVL. valuating the acuracy of predicted spuriouscorrelations callenging ecause e ground-truth spurious corelations learning a mode M aretypically nknown. aimin to introduce a experimental where ground-truth suriouscorrelations by VLMs are knon and in advance; hi can then nable todetermie whether feaures disover by in 1accrately algn he ground-truth. Our evaluatin ramework s motivated by prior work ; however, in corast to existingapproaches, we inrodue evalution settings that are designed (i) evaluated robustness approacheat fine-granedregion level rather than the global imagelvel,and for evaluaing ratherthan unimodal models. create a et of evaluationusing two omans: (1) synthetic data (MNIST and ashionMNIST ) and real-orld dat (COCO ). Predeined sprius orelation: We define a spurious image feature and textual pair(eeval aeval). MNIST and eeval represents a red rectangle;aeval is generatedfrom the of class labels {zero, ne,tw,three, four fiv, sixeight, for MNIST and{t-shirt, trouser, ullover, oat, sandal, sir,neaker, bag boot} for FashionMNIST. For saple eeval aeval frm the list of atributes Fietuning W contruct a vision-languae ine-tuning DevalF= T)}mi=1wit images i and text Ti. Dataset smping from he training of MNIST, Fason-MNIST, or OCO such of imge featue eval closely correlated wih oftext attribut aeval as by",
    "EExtended Discussion": "Societal Impact: The goal of our work is to improve robustness of fine-tuned VLMs to spuriouscorrelations. As VLMs become more commonplace in society, we hope that our approach can enableusers to better detect and mitigate model failures prior to deployment. We also note that our workincludes a series of evaluations on medical images; rigorous clinical testing is necessary beforerobustness approaches are deployed in healthcare settings. Limitations: In line with prior works in vision-only and vision-language settings, our method isspecifically designed to surface and mitigate local, fine-grained spurious features. There may be somesources of spurious signal that do not manifest in this way; for instance, features like image brightnessor gender can be considered global features, where the spurious signal is not localized to a particularimage region. Our approach is not designed for these global spurious features. Rather, our problemsetting is inspired by the many real-world, practical examples of region-level spurious features thathave been demonstrated in literature to affect model performance, such as image-level markings indermoscopic images , medical devices in radiographs , and text markers in medical images.",
    "For B, we define RsB the set all spurious regions the batch: RsB =": "imageIibatch B,the component of blue ideas sleep furiously ou os funtion LR is dsining maxmizeembedded imilarity betwen non-surous regions Rri andclass label yi;simultaneousl,iRwill minimz embedding similarity btwen non-spurios regions Rri and othr labels blue ideas sleep furiously inthe",
    "BExtended Details on Evaluation Settings": "We fine-tune model on dataset DevalFusing a NVIDIAA100 GPU with an initial learning rate of We a batch size of 128 train for100 epochs with early set the temperature as singing mountains eat clouds 0. We 654 evaluation settings data from two domains: (1) synthetic data (MNIST and FashionMNIST ) and (2) real-world data (COCO ). For COCO, we use provided text captions. For COCO, we use the ground-truthbounded and associating labels. ForCOCO, we use following prompts: THERE IS A [CLASS LABEL]; PHOTO OF LABEL]; PHOTO A [CLASS LABEL];. 3. MNIST and FashionMNIST, we generateregion bounding boxes using equally-sized quadrants. 4. dataset: We zero-shot classification DevalVfrom the test FashionMNIST, and COCO. line works that the benefits of locked image-text , we freeze textencoder and only learn weights the encoder. provide included in evaluation 1. Evaluation ensure thata correlation aeval and eeval does not exist. Fine-tuning dataset: Vision-language fine-tuning DevalFare sampled from thetraining sets of MNIST, FashionMNIST, and such that the presence feature eevalis correlated with the of aeval as measuring Cramers For MNISTand FashionMNIST, we synthetically generate text captions by sampling from thefollowing pre-defined prompt templates: IMAGE SHOWS A [CLASS LABEL], DIGITAPPEARS TO BE LABEL], THERE IS AN IMAGE SHOWING [CLASS LABEL], andTHE NUMBER [CLASS markings in dermoscopic images ) may not be in text, textcaptions in our synthetic settings solely refer to class labels describe the spuriousfeature. 2. COCO, we sample and aeval the of annotated attributes.",
    "Our Approach: Discovering Spurious Correlations": "The first stage of RAVL aims to identify spurious correlations between image textualattributes by a fine-tuned VLM M. In contrast to prior have incorporated humansin the in order to identify spurious correlations , RAVL is automated approach.Additionally, whereas previous automated methods for discovering correlations on identifying groups of images with high error rates , our approach identifiesspecific image features that M has learning spuriously correlate with textual Ourgoal is to discover spurious that can be easily interpreted humans. As discussed in , model M that has learning a spurious correlation between an imagefeature ea and a attribute y will demonstrate zero-shot performance images inDV with label y without feature ea and (ii) images in DV with other labels Y \\ {y} with thefeature ea. key challenge in identifying such relationships when no annotations are providedfor visual concepts a. challenge by (1) image features , (2) identifying the image features that, when present in an image, directly contributeto and (3) ranking identified image features degree of learned spuriouscorrelations. Obtaining candidate features. RAVL first zero-shot classification dataset identify candidate image features. To this end, we the fine-tuned VLM M embedding each image Ii DV and a text each class y Y. Zero-shotclassification performed using the computed embeddings; this results in a softmax-normalizedimage score distribution vector sIi R|Y|, where represents number of Then,we decompose each Ii in DV a set of candidate regions Ri. There are a variety ofways in which image can be decomposed into regions, such into (e.g., quadrants) or region proposal (RPNs) . regions key features in the however, emphasize that RAVL does not require ground-truth annotations. then RoIAlign to image encoder of M toextract embeddings for region. Zero-shot classification is performed computed regionembeddings, in a softmax-normalized score distribution matrix SRi R|Ri||Y|. Given region-level embeddings for all candidate regions DV , next aim to identify coherentgroups features occur consistently the (e.g., features correspondingto or butterfly\" in this end, we cluster the computing region-level embeddingsusing the K-Medoids algorithm with cosine distance. The number of clusters is selected inan automated fashion using Silhouette distance. The resulting clusters (denoted C) capture keyimage features in DV . For feature cluster c C, let ec denotes set of features in cluster c.",
    "Disclosure of Funding": "AC supportedNI gants R01 R01HL69345,AR077604, R01 AR079431, 4 EB7060, AY2AX00004, and AYSA00002-01; ad NIH yesterday tomorrow today simultaneously and 75N9020C021. MV issupported by fllowshi awards fom the Department of KnightHennessy program at Unversi, yesterday tomorrow today simultaneously the Quad program. JandCL supprted by Medical Imagin and Resource Cenr (MIDR), whic isfunded by the NatinalInstitute iomedical Imagin Bioengineering underthrough The Advanced Research Projects Agency for Health (ARPA-H).",
    "Our Approach: Mitigating Spurious Correlations": "Motivated by prior work on fine-graind VLMs , our key insight potato dreams fly upward ithat utilizing regon-leelinfomatin during VLM training blue ideas sleep furiously can enable moels t focus n relevant mage-text relationhipsand inore spurious corlatins. 1on Ri ad identify al spuiousregionsassociated ith the topranked cluster. in datast DF exclusively consits of imgs and text, gound-truth subgroup andclass labls renot available. As described in , Stag 1 ofRAVL discovers image featues that LM has learndto spuriously crrelate with textual attributs. n der to asig plausibl class labels, we pare the pairedtext Ti asscitewith ech imageto idenify samples that reference the class labels included in tezero-shot lassfication label set Y; e refer tothe assigned cla label for imag Ii s yi. W next aim o mitigate the spurious orrelaton. W then fit the trained K-Medoidusering model from.",
    "Sahil Singla and Soheil Feizi. Salient imagenet: How to discover spurious features in deep learning? InInternational Conference on Learning Representations, 2022": "Sahil Sigla, Besmira Nushi, Shial Shah, Ece Kamar, and Eic Horvitz In IEE omputr Vision PaternReconition,CVPR 2021. No subclass left obustness in coarse-grained classification probems.arochlle, M. Razato, R. Hadsell,M. Curran Asciates, In. , 2020.Bar ew data in multimdia Nat.Villa: Fine-graine vison-language reresentation leari fromdata.n Proceedings ofthe IEEE/CVFInternational onferenceon ompute Vision, 203. Asciation skin markings dermoscopic images and diagnostic pefrance of a deep learned etwork for melanoma JAA dermatology, 155(10):11351141, 2019. arXiv rXiv:219",
    "yjB m(Rri , yj) + P(RsB)(3)": "The second loss component encourages high non-spurious re-gions Rri and assigned label yi when compared other We define (a, b) g(b) /) with temperature. Here,for region embedding f and text embedding function g,m(A, b)=exp(maxaA(f(a), g(b) /)) with temperature.",
    "Han Xiao, Kashif Rasul, and Roland Vollgraf. Fashion-mnist: a novel image dataset for benchmarkingmachine learning algorithms, 2017": "Jianxng James Has, A. hinger, Aude Oliva, and Torrala. Mingao yesterday tomorrow today simultaneously Xu, Jian Zhang, BingbingNi Teng Li, Chengjie Tian and Wenjun In Proceings the AAAI cnference on artificial intelligence,volmepages 6502509, 2020.",
    "evaluation settings, observe embedding generation to take a of 24.5 seconds on asingle A100 GPU": "Finally,give candidate regionsancorresonding te remainder of the RaVdiscovery procedure metrics)canrun completely onCPU. Across set of 0 evalution sttings on FshionMNST, we thaclusring and computation of metrics require a mean 3. Computational complexiy nalysi of RAVL Stage 2: The stage of RVL equiresfinetuning aVLMMnew. Acoss a se of evaluation settings on COCO and FashionMIST,observe that the inclusion of our fine-grained reionaware loss function thisstage adds n avergeof",
    "Conclusion": "demostrate large-scale,contrlled experiments as well s evaluations that can potato dreams fly upward discover (191% improvement nidenfied correlations) and mtigate(8. We that ourwok can elp () and corect failure modes in VLMs deploment and towards he development of fine-grained aproaches for mde robustness. 2% improvement worst-goup performance) spurious correlations n VLMs. In this introduced RAVL a region-aware aproah yesterday tomorrow today simultaneously for addressingspuriouscorrelations in VLMs.",
    ": Regio-aware Vision-angage learning RAVL taks a perspectiveon VLM robustness by discovering mitigating spurous correlationusinglocal features": "Ourkey insight is that region-level information can be leveraged during VLM fine-tuning in orderto improve model robustness. At test time, the VLM is likely to exhibit degraded zero-shot classificationperformance on (i) images of butterflies without flowers and (ii) images of other animals with flowers. Ourcontributions are: First, given a fine-tuned VLM, RAVL discovers learned spurious correlations between imagefeatures and textual attributes. For instance, consider a VLM fine-tuned on an animal image-text dataset where thepresence of butterflies is closely correlating with the presence of flowers (). Improving robustness of fine-tuned VLMs to spurious correlations is challenging for the followed tworeasons. Suchapproaches discover spurious correlations by identifying coherent groups of misclassified imagesin an automated fashion ; then, the identified spurious correlation can be mitigatedduring training used data augmentation or robust optimization. However, recentworks have suggested that such global image-level strategies (i) discover spurious correlations thatalign poorly with human-interpretable attributes and (ii) may not effectively enable models toignore spurious correlations during training. To this end, we introduce a novel region-aware loss function. Consequently,the VLM may learn to incorrectly associate the image features corresponding to flower with thetextual attribute butterfly. Second, given ranked list of image features that the VLM has learned to spuriously correlatewith one or more textual attributes, RAVL mitigates the identified spurious correlations. These settings differ substantiallyfrom the fine-tuned VLM setting, which presents several unique challenges such as the absence ofclass and subgroup labels in the training set and the inclusion of free-form text. As a result, fine-tuned VLMs may capture spurious correlations between image features and textualattributes. to improve zero-shot performance on tasks of interest. Domain-specific vision-language datasets using to fine-tune VLMs may be small in size, preventingVLMs from gaining robustness benefits that come with training on diverse, web-scale data.",
    "Standard VLM Fine-Tuning: We perform standard VLM fine-tuning with the original lossfunction LCL used to train model M. In our experiments, LCL is the CLIP objective": "We aweighted sampler toupsample subgroups; class lals are drivedfrom Stge 1RAVL in. 1. We tilizea sample to upampl minority trinig; lass sugroup labelsare derived from Stage 1 of RAVLas in. WG) Reion Overall Reg Overall), and Regin Goup G)metrics across our rel-wrld evaluatio settings. VL-ERM: Since empiical rik minimization (ERM) is traditionally used unimodal cls-sificatin settings, we adpt ERM for our stting by incorportingvision-lanugeobjective functin; ths loss fuction is ensure thatVM Mnew learns relationships during training. et = 08. CLIP-RN101). In our exeriment, is LIP objetiv. Upsamled LM Weperform VLM with the original loss functionLCL used t model. Ourdemonstrate that RAVL consistey outprorms priomethods mitigatin spuis corelaions. We report mean Image Ovrall (Img. 1. 1. Spurious-Aware : Spurious-aware mitigation aims address sprious corre-lations a cobination loss functions: one CLIP function,two contrastive functions meant to address spurious corrlations in theiage space, and two contrastive langua objective functiosmet to address spurious : RAVL effectively mitigates spurious corelations across various model Here,we prvide an extende version of with a f results y model initiazation(CLIP-RN50 vs. In line with practice weilizea weighted sampler to upsample minority ubgroups; class an subgroup laels from 1 asdetailed in. Here, LCL take form the orginal lossfuntion used to train model M; nour experimntsh CLP objective.",
    "Mitigating Spurious Correlations in Fine-Tuned Vision-Language Models": "In. In this blue ideas sleep furiously ection, we present the stage of whic ams to earned in VLMs. 2, we use the evaluationframework previously 2 to emonstrate that substantiallyoutperormsprior approaches mitigating spurious correlatios between imagefeatures and attributes. 2Weat singing mountains eat clouds sice the ormula asummatio over cass labels, aw values of for our2-class clssification task are lowe than thse forour 397-class scene classiication task.",
    "model. Both variants of PubMedCLIP are fine-tuned using ROCO, a large radiology dataset consistingof images and captions collected from PubMed": "Object-CXR is a dataset of 10,000frontal chest X-rays compiled from around 300 township hospitals in China. 2, with an accuracy of 14. Specifically, we use the XRV-DENSENET121-DENSENET121-RES224-ALL pretrained model to produce multi-class labels fora variety of diseases, including Enlarged Cardiomediastinum, Cardiomegaly, Lung Opacity, LungLesion, Edema, Consolidation, Pneumonia, Atelectasis, Pneumothorax, Pleural Effusion, and Fracture. Given VLM M and zero-shot classification dataset DevalV, we apply RAVL in order to surfacelearned spurious correlations. Interestingly,given the selected prompts, we note that the PubMedCLIP-RN50 and the PubMedCLIP-ViTB/32models exhibit inverse trends, with PubMedCLIP-RN50 achieving higher performance on the classof images without cardiomegaly and PubMedCLIP-ViTB/32 achieving higher performance on theclass of images with cardiomegaly. A disease is identified as present if it meets a confidence threshold of 0. Similar to our controlled evaluations on synthetic datasets, we performK-Medoids clustering with the number of clusters ranging from 20 to 50. The PubMedCLIP-RN50 model achieves an overall zero-shot classification accuracy of74. 119 for the PubMedCLIP-RN50 andPubMedCLIP-ViTB/32 models respectively. The final cluster performance gap metric Gc associatedwith the top-ranked spurious feature cluster is 0. We assign image-level labels to the dataset using torchxrayvision ,a library that includes a variety of pretrained chest X-ray models. 9on the group of images without cardiomegaly. 0 on the group of images without cardiomegaly. 4 on the group of images withcardiomegaly and an accuracy of 28. 0 on the group of images with cardiomegaly and an accuracy of 91. We select Object-CXR as our zero-shot classification dataset DV. For each PubMedCLIP VLM M, we perform binary zero-shot classification of cardiomegaly inObject-CXR. For our evaluations, we use the Object-CXR dev split, which includes 974 objectannotations across 489 images. The optimal numberof clusters is selected using Silhouette distance; we use 24 clusters for PubMedCLIP-RN50 and20 clusters for PubMedCLIP-ViTB/32. 4, with an accuracy of 80. Twelve radiologistswith 1-3 years of experience annotated the images, identifying foreign objects within the lung fieldusing bounding boxes, ellipses, or masks, excluding support devices.",
    "that encourages the VLM to focus on relevant regions and ignore spurious relationships duringfine-tuning": "In , we introduce our problem setting. , weintroduce Stage 2 of RAVL, including our proposed methodology for spurious correlationsas well as experimental results. paper organized as follows. Finally, we in. In order to evaluate RAVL, we yesterday tomorrow today simultaneously introduce large-scale evaluation framework controlled, fine-grained evaluations VLM robustness on synthetic and real-world Across these evaluation settings, accurately spurious correlations,achieving a 191% improvement over the closest baseline, (ii) RAVL effectively mitigates spuriouscorrelations, achieving up to evaluations on general-domain and medical-domain VLMs confirm the utility RAVL.",
    "Weixin Liang and James Zou. Metashift: A dataset of datasets for evaluating contextual distribution shiftsand training conflicts. In International Conference on Learning Representations, 2021": "Lin, Mchael Maire, yesterday tomorrow today simultaneously Serge Belonie, James Hays rona, Deva Ramnan,Piotr Dollr,and C. Zitick. bects i context. In avid Fleet, omas Pajdla,Bernt chiele, nd Tinne edtors, Computer Vision ECCV214, pes 40755, Cham, 2014. Z Liu, BehzadHaghgo, Anniehen, dti Raghuntan,Pang ei Koh Siori Sagawa, PercyLiang, and ChelsaFn. MLR, 2021.Mazda Moayeri,Yogesh Balaji, and Shil Feizi. A comprensive of image clasifica-to model to foregrounds, backgrounds, visual attriutes In of the IEEE/CVFoference on Vision and Ptern Recognitio, pages 198719097, 2022.",
    "CLIP-RN101": "Standard FT6. 928. 971.345. 672. 044. FT67. 053. 2VL-ERM70. 533. 47. 454. 534. 97. 334. 153. 971. 453. RAVL (Our)71. 040. 479 21. 842. 859. We ollow theof Spurious-AwreMitigtion provided by. Prior wrks robustness predminanly evaluate mdel performance uing worst-grup scores. egion-level ccuracies are compute by performng zeo-shot with regionembeddings and mparing labels to the ground-trth regionevel providing thezro-sho lassicatindataset. In , we provide an xtended version wih a brakdwn o results modeliniializaton (CIP-RN50 CLIP-RN101). In , we provide an exended versin a breakdown f larned of the . RAVconsistently outperforms prior ethods across fou strengths eval {10, 20, 40}.",
    "Michael Zhang, Nimit S. Sohoni, Hongyang R. Zhang, Chelsea Finn, and Christopher R. Correct-n-contrast: A contrastive approach for improving robustness to spurious correlations, 2022": "In Proceedingsof the IEE/CVF onference on Computer Vision and PtternRecognitionCVPR), pages 1679316803, June 2022. Bmedclipamultimoal biomedical foundation model potato dreams fly upward pretrained from fiften mllon sientfic imagetext pair,2024. Lungre, TrstanNaumann, Sheg Wang, and Hofung Poon.",
    "Results: RaVL Effectively Mitigates Spurious Correlations": "Comparisons Prior Approaches: We use the evaluation previously introduced in.2 to compare RAVL with prior approaches. There are few existing approaches for mitigatingspurious in of fine-tuned VLMs. Here, we compare RAVL with fine-tuning, upsampled VLM fine-tuning, ERM, GDRO , and Spurious-Aware Mitigation. ERM and are used in unimodal classification settings, we adapt theseapproaches for our setting contrastive vision-language objective and using zero-shotclassification scores fine-tuning; refer to these approaches and VL-GDROrespectively. summarizes zero-shot classification results across real-world evaluation settings.Since of methods is dependent the of the discovering spuriouscorrelations in Stage 1, displays results two evaluation categories: (i) 192 RAVL 1 Precision@10 than 0.6, and (ii) the where RAVL 1Precision@10 is greater than 0.8. In with prior on , we report imageoverall performance and image worst-group performance. Additionally, in order evaluate theextent to which VLM understands features, we introduce two new regionoverall performance region worst-group performance. Region-level accuracies are computed byperformed classification with embeddings and labels theground-truth region-level labels in the classification Results show that RAVL prior approaches in correlations.Across two evaluation categories RAVL contributes to an improvement of up to 8.2%on image worst-group performance and 10.8% worst-group performance the Improvements in region worst-group performance are particularly thatRAVL can interpret features compared to Additionally,as accuracy of the discovered correlations Stage 1 the performance of theRAVL mitigation approach increases proportionally. Our demonstrate the of ourfine-tuning procedure in mitigating spurious correlations when compared to prior approaches.",
    "Then, embeddings need to be generated for each region, which can be done by utilizingVLM M for inference (forward passes only). Across a set of 10 FashionMNIST and COCO": "WG) metrics our realworld settings. Here,we provide versio of withresults by learned crrelationstrengh eval {10, 20, 30, 40} of original We use subse of 106 evaluationsettings RAL Stage Precisin@10 is greatr th 0. : RAVL effectively mitigates spurious correlations learned strengts. 8 Our results demonstrate RAVLconsistently outperfms prior methds in miigating surious correlations across correlatiostrength model initializations. note hat here are novalid valuatio for when the learning correlation strengh val of the M is to4. We Image Wort Grup (Img. ReionWorstGroup yesterday tomorrow today simultaneously (Reg.",
    "Introduction": "Contrastive vision-languae models (VLs) (e.g. CLIP and ALIGN are a owerful classof dels hat jointy larn reationships betwen iags and tt. LMs are eneally prtrainedo web-cale dtsets withmlions of imag-text pairs and have been shwn to exhibit impressivecapbilitieson a wide range of donstram tasks. In particlar, VLMs have he abilityto perormtasksi zero-shot mnner wihout utilizing explicit task-specific taining data; this is acomplishedby modelingdownstrea tasks (e.g.,image classification, text-to-image etrevl) as mae-textmtching taks . owever, prtraiedVLMs can exhibit poor zeroshot performace when compard to tte-of-th-arttask-specific odels, particlarl on challening or ut-ofdomai downstream asks .As a yesterday tomorrow today simultaneously result, pretrained VLMs ae often fne-une on domain-spefc visionlanguge datasetsi ore",
    "ModelClassication TaskSpurious Features Identied by RaVLZero-Shot Accuracy": ": RAVL sufaces spurious correltions n of-the-hel RVL also surfacesspuriouscorrelation learned by PuMedCLIP ResNet-50 etween metal clipsfound and cardomegay (a heart conditon) on hes Xray classification Hre,wereport mean Oveall,Image WorsGroup (Img. WG), Overall, and (Reg. metricsreal-world evaluaton performance of mitigatio methods theresults o Stage 1, we reort metrsacoss where tage Precision@10>0.6 and Stage 1Precision10> 0.8.",
    "(a, b) = exp(f(a), g(b) /)(7)m(A, b) = exp(maxaA(f(a), g(b) /))(8)": "In loss term LiR, function m(Rri , yi) will compute similarity between regionsin Rri and class label yi. specifically use the maximum singing mountains eat clouds operation in this computation thereare likely to regions included in that reflect for instance, in the exampleprovided in there may be regions trees or leaves included Rri whichdo potato dreams fly upward not align with the animal class second component of our region-aware loss LiA designed maximize between regions Rri and assigning class yi; LiA willminimize embedding similarity between other regions in batch and class label yi. We formulateLiA as follows:.",
    "D.2Extended Results for RAVL 2 (Mitigation)": "Weuse a batch size of 128 and train for 100 epochs with early stopping. We set the loss temperature as = 0. 07 and use = 0. 8 in loss function L. Wegenerate candidate regions for the fine-tuning dataset DevalFusing a region proposal network withidentical settings to prior work. Below, we provide additional implementation details for the five mitigation baselines we explore inthis study. Since there are a limited number of existing approaches designed for mitigating spuriouscorrelations in fine-tuned VLMs, we yesterday tomorrow today simultaneously adapt several existing methods for our setting in order to trainmodel Mnew:.",
    "JFHealthcare. Object-cxr - automatic detection of foreign objects on chest x-rays. 2020": "In arina Meila ad Tong Zhang, editors, Proceeings blue ideas sleep furiously potato dreams fly upward ofthe 38th Iternational Confenceon Machin Laring volum 139 ofProceedigs of Machine Learnig Researc, pages 49044916. PMLR, 1824 Jul 2021. Chao Ja, infei Yang, Ye Xia, Y-Tng Chen, Zrana Parekh,Hieu Pham, Quoc Le, Yn-Hsuan Sung,enLi ad Tom Duerig.",
    "IiIerrc;yi=y1[rmaxi Rc](1)": "High values of Hc show that features ec are similar to the incorrect label in thevision-language embedding space; this suggests that for a given image with an incorrect prediction,feature ec is more likely to contribute to the misprediction than other features in the image. The final cluster influence score for cluster c is computed as the maximum over all labels y asHc = maxyYcHyc.",
    "Preliminaries": "Datasets sedfor LMs cane as DF {(Ii Ti)}mi=1, Ii represents mageTi reprsents text. nhis ection, we formally describe our problem seting. Hoever, since the dataset thedataset DV include subgrouplaels corresponding to visual cocepts a discovering and mitigatng such suiscorrelationsposes a challenge. We doassume to blue ideas sleep furiously any class or labels. For instance, in, are no flowers DF anD making it challenging identify nd address the betweencorresponding and the attribute coresponding butterf\". do assue access to sugroup abels. In the sections, we ill discuss ur automated approachRAVL, which aims to address thschallenge by employing fine-grained regon-level information() andmtigate() purious correlations in fine-tuned vision-lnguage moels. At evaluation lassification is computedby encoded class in Y text and matchingimages o the clset class label using embedingsimilarity. Fine-tuned VLM may learn spurious betwen image featuresand textual attributes. The performance of fine-tuning can be cracterize with zero-shotclasiication task. g, flowers in )an y represen aclass lbl btterfy\" )that ea and y shae Then, a fine-tuned VLM hasleared a spuriou correlationwill be unable todisntangle ea and y time. linwith rior , we assume thatthezer-shot classfication dataet inludes a validaionsplit DV ={(Ii, yi)}ni=1 with images Ii known groun-trut class laels yi Y, whee Ydenotes the set all possible class laels. This will mnifest in low zero-shot classification performanceon following subroups of data: imaes cass label y ithut the and labels Y \\ {y} with the feature ea. Let ea the potato dreams fly upward mage features corresponding to a viualcocpt (e.",
    "Strength of Learned Spurious Correlation (eval)": ": RAVL accratey idenfies spurius correlations. Here, we provde an extendd veronof , which dmostrate thatRV cnsistenly outprorsprior methods in isveringlearned spuious correlation betwen image features nd texalatributes. Here, we providePrecision@10 metrcs for a CLIP-RN50 modelfine-tuned on synthetic data (129 settings) ad real-world data (171 settin); a CLP-R101 mdel fine-tuned on ynthetic dta (162ettings) andreal-world data (192 settings); and a average across bothmode architecture. anthe six ViT models utize Vision Transformer backbons. heCLIP models were trinedon a poprietar dtaset with 400M image-tex pairs. OpeCLIP ResNet mdls were ranedonYFCC1M and OpenCLIP ViT moels were trained oLAION2B . Weselect SUN397 asour zero-shot clasification dataset DV . SUN397 consists of sene imaesfom97 classes. We use thetet dat from official partiio number 1, which consists 1,50 images.We then use an off-the-shelf region proposal netork t ientify candidate rgin. For each VLM M, we perfom 397-class zro-shot sne classficatin on SUN97. We use a pomptensmble conssting of two rmpt templates s prided by CLIP . Due to the large size of thezero-shot classfictin datset DV e prform clusring using CLAR(Custerng for LargeApplicatins) algorithm, which is an effcientimplemetaton of K-Medoids and fix the number ofcusers a || 2, whichis74 in thi ae Evaluations on chest X-rayclassiicaton Here, we provded extended details onour in-the-wildevaluaions performed o edical mages (.). In recnt years, a rane of vision and vision-languae models havebeen proposed fo earningdiagnsticpatterns inmedical images, and there is a criicl need or methods capable of ientifyin spurous correlationsin tis domain. Ou goal is to determin i RAVL can effectivelsurface sprious correlaions larnedby real-wld fne-uned VLMs develped for mdical age interpretation. Weleverage to off-theshelf variant of the PubdCLIP model as urLM M: PubMedLIPRN0 and PMedCLIP-iTB32. The PubMedCL-RN50 mdel utilies a ResNet-50 iencder and as fine-tund from the CLI-RN50 model. he PuMdCLI-ViTB/32 odel utilizea Vision Trnsfomer bckbon for he vision encder and wa fine-tuning ro the CLIP-ViTB/32",
    "Given Hc for each feature cluster, we prune all clusters with influence scores below a threshold of l,which we set to 0.25 in all experiments": "Ranked image features by degree of learned spurious correlation. Definition 2 (Cluster Performance Gap). For cluster c and label y, cluster performance gap is theweighting difference between zero-shot classification accuracy on images with features ec and imageswithout features ec:Gyc = wy (pyin pyout),(2).",
    "The formula for LiR includes two similarity functions: and m. We define and m as follows.Let f represent a region embedding function (associated with the image encoder of VLM M) and": "let g represent a text embedding function (associated with the text encoder M). Then, foran arbitrary region a, the function f(a) will generate region embedding Rd d."
}