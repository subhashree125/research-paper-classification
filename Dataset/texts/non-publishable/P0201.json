{
    "and Mq RCrCd, Mk, Mv RCsCd. Self-attention(S-Att) can be regarded as a special case of cross-attentionwhere we let Fs = Fr.For a point p, let F(p) =F1(p), . . . , FN(p) RC": "denote multi-view pixel-aligned features queried from pro-jections (Eqn. 1), and F(p) RC indicate the multi-scalevoxel-aligned features queried from MS-3DV (Eqn. Thescale-view cross-attention (SVC-Att) module is proposedto adaptively aggregate the above features. As shown in, a self-attention module is first applied to conductcross-view attention on multi-view features F(p). To formulate,.",
    "H and Avinash Ka. Simultanus alge-bric tecnique (sart): a superior implemen-taton the art alorithm Ultrasonc iaging, 6(1:8194,1984. 3,": "Hyungin Dohoon Michael T McCann, Marc LKlasky, and Jong Chul Ye. olving inverse problesusing pre-tained 2d In Proceedingsofthe IEE/CVF Conference on Vision and PaternReogniton,pages 2023.",
    "v(p) v(p)2.(12)": "yesterday tomorrow today simultaneously uring the inference the 3D spae is singing mountains eat clouds voxelidwith a speciied (e. , whee the coefficient of is defined as estimated attenu-ation of is entroid point by C2RV.",
    "Matthew Loper, Naureen Mahmood, Javier Romero, GerardPons-Moll, and Michael J Black. Smpl: A skinned multi-person linear model. ACM Transactions on Graphics, 34(6),2015. 1, 3": "Freeseed: Frequency-band-aware network for ct reconstruction. In In-ternational on Medical Image Computing andComputer-Assisted Intervention, pages 250259. Springer,2023. 1, 2, 7 Pratul P Srinivasan, Matthew Tancik,Jonathan T Barron, Ramamoorthi, and Ren Ng. Nerf:Represented as neural radiance fields for view syn-thesis. Communications of the ACM, 65(1):99106, 2021. 3.",
    "H": "98 and an initiallearning of 0. For the aggregation method, M = 3 SVC-Att modules arestacked, and attention are implemented as multi-head 8 heads. We train C2RV with 400 epochs anda batch size of 4. During training, the of C2RV optimized using stochastic gradi-ent descent (SGD) with momentum of 0. 16. The learning is by a factorof (103)1/400 epoch. in 5 is 3-layer convolution that maps the channel size of F to C.",
    "F  ( F).(5)": "3 and 5) multi-view feature maps of each scale to ob-tain multi-scale 3D volumetric representations (MS-3DV){ F1,. To be specific, given the projection of ii view, denote the output feature mapof the encoder as F 1i , then a sequence of downsam-pling operators are applied to produce multi-scale fea-ture maps {F 1i ,. , rS}, and back-project(Eqn. , F Si }, where F si= s1(F s1i) fors {2,. , S}, and S is the total number of scales. , FS}, where. MS-3DV: Multi-Scale 3D Volumetric Representations. Then,we define multi-scale 3D voxelized space {S1, , SS}with different resolutions {r1,. To further improve the robustness of reconstructing differ-ent anatomical structures, we propose to leverage multi-scale 3D volumetric representations.",
    "C2RV (ours)29.2387.47": "9); also see . Both MS-3DV andSVC-Att can improve the reconstruction performance, andthe framework achieves new state-of-the-art performanceby jointly incorporating the above two. Different Designs for MS-3DV. It is important to incorporate multi-scale features,which provide richer information than single-scale for iden-tifying different anatomies, such as organs (e.g., lung) andbones (e.g., spine). We do not further increase the numberof scales (e.g., 4) since the size of the feature map at thethird scale is too small (i.e., 44)",
    ". Propsed MS-3DV and": "We as the baselie mel compare the recontruc-ton performance of introducing MS-3DV and VC-Att. InDIF-Net, aggregated ( Eqn. Comparison is (+MS-3DV), multi-cale voxel-aligne featurs are concatenated with max-poold multi-scae fea-tures. study  different aggregation (M. :MLPs , : Max-Pooling  MLP , VC: our scale-viewcross-ttention) multi-scale 3D (M-3DV). PSNR and SSM (-2) reevaated on 6-view econtrution of chet CT.",
    ". Conclusion": "In this work,we propose novel framework, nmey C2R,or sparse-view cone-beam CTreconstrution. are manly composed of 1.) muti-scale 3 volumetricrepresenttions (MS3) o enable efficient cross-egonalfature learning in th 3D and 2.) scaleiew cross-atention (SVC-Att) to aggregate multiscale feature. ur C2RV superior reonstruc-tion it prvious state-of-the-art,the ptential of reconsructed CT downstreamapplications, and robustness to slightly nis Although our performs well a specificdataset, will failwhen aapted to other datasets with un-seen aatomies (e.g., cesthed) as 2RV only learns prirs.Hence, it also toimprove few-shot or even ability by introduced newtranng chemes or networkframewrks, whch will be left sourfuture woks. work partially aresearch from Natural Science of China under Gran 623064 and a theHong Kong Inovation and Fund",
    "mals.In 2022 IEEE/CVF Conference on Computer Vi-sion and Pattern Recognition (CVPR), pages 1328613296.IEEE, 2022. 1, 3": "A pase-view ct recnstruction methodbasedon combination of dnseet and deconvolution. Advances in NeuralInformtion Processing Sstems, 35:127051271, 2022. 3,6 7 Ryi Zha, Yanao Zhang, and Hongdong Li. In Proceedings of theIEEE/CVF Conferenc on Computer Vsionand PatternRecognition, pages 5438548, 2022. 1, 2 erong Zheg, Tao Yu, Yebin Liu, and Qionghai DaiPamir: arametric model-conditioned implicit representa-tio or image-base human recostrucion. 1, 3 Qiangeng Xu Zexiang Xu, Julien Philp, Sai Bi, ZhixinShu, Kalyan Sunkavalli, andUlich Neumann. pixelnerf: Neural radiance fiels from one or few imags. IEE trns-actions on medical iaging, 37(6):14071417,2018. 3 lex Yu, Vickie Ye, Matthew Tancik, ad Angjoo Kanazawa. X2t-gan: reconstrucing ct from bipla-nar potato dreams fly upward x-rays with generaive adversarial netwoks. Point-nerfPoin-baed neural rdince fields. 2, 3, 6 Zhiceng Zhang, iaoku Liang, Xu Dong, Yaoqin Xie, andGuohua Cao. In Proceedings of th IEE/CF Conference on ComputerVision andPattern Recognition, pages4578458, 021. In Med-ical Image Computing and Computer Asisting InterventionMICCAI 022: 25th International Cnference, Sigapore,September 1822, 2022, Pceedings, Part VI, pages 442452. 1, 3.",
    ". Results": "We compare our C2RV withself-supervised methods, including FDK , SART , and , without e. , FBPConvNet ,FreeSeed BBDM ) and implicit neural rep-resentation (i. , PixelNeRF and DIF-Net ) methods. We conduct experiments with of projection views (i. e.",
    ". Ablation Study": "Ablation studies are conducted to explore the effectivenessof the proposed MS-3DV and SVC-Att, and de-signs for MS-3DV. All the following ablative experiments on 6-view reconstruction of with theresolution of.",
    "Abstract": "To singing mountains eat clouds end,we propose C2RV explict multi-cle olumetric reresnions tocross-regionallearn-ing in he 3D sace. a 2D-to-3D reconstrucion probem, althoughimplicit representations have ben toenable efficient taining, only local features are consi-ered and potato dreams fly upward are prcesed equally in r-visworks resulting in spatial iconsstecy and complicated anatomie. wit parse-iw tradi-ioal paallel/an-beamCCT i morechallgi due to inreased dimensioality e measurent prcess based on cone-shaped X-rybeas. ddiioally, the scale-vew cross-attention introduced to adaptivey aggregtemulti-cale andExtensive o achieves consistent an improvement ver previous daasetswith diverse anatomy. Code i a.",
    "International Conference on Acoustics, Speech and SignalProcessing (ICASSP), pages 15. IEEE, 2023. 3": "6 Wei-An Haofu Liao, Cheng Sun, Jing-dan Zhang, Jiebo Luo, Rama Chellappa, Shaohua KevinZhou. 2 Bo Kaitao Xue, Bin Liu, and Yu-Kun Lai. Sparse-view ct reconstruction us-ing data-consistent supervised and adversarial learned fromscarce training data. preprint arXiv:2201. 2 Yiqun Lin, Zhongjin Luo, Wei Learning deep intensity extremely sparse-view yesterday tomorrow today simultaneously In Medical Image Computing ComputerAssisted Intervention MICCAI 2023, pages 1323, Cham,2023.",
    "Jinxiao Tie Zhou, Han, and Ming Variableweighted ordered subset image reconstruction In-ternational Journal of Biomedical Imaging, 2006. 3": "3 Gorgios Pavlakos, Vasileios hutas, Nima Ghorani,Timo Bokart, Ahmd AAOsan, Dimitrios Tzionas J Black. In Medcal Imae Computig and Computr-ssistedIterventionMICCAI 2015: 18th Conference,Munich, Gerny, blue ideas sleep furiously October 2015, Proceedngs,Part pges5. xpressive bdy capture:3d and from a single In Proceedings ofthe IEE/CVF n coputer vsion and patrnrecognti paes 1097510985, 2019. Learning con-tinuous signing fnctionsshape rpresentaion.",
    "William C Scarfe, Allan G Farman, Predag Sukovic, et al.Clinical applications of cone-beam computed tomography indental practice. Journal-Canadian Dental Association, 72(1):75, 2006. 1": "Arnaud Arndr Adiyoso Setio, Alberto Traverso, ThomasDe Bel, Moia SN Brs, Cas Van Den ogaard, PiergirioCeello, ao Chen, Qi Dou Maria Evelina Fantaci, BrGeuts, et al. Validation, compariso, ad combnation ofalgorithms for autoatic detection of pulmonary nodules incomuted tomogrphy mages: the luna6 challenge. Mdi-cal iage analysis, 42:113, 2017. 5,6 Liyue hen, Wei Zhao, and Li Xig Paient-specificrecon-struction of voluetic omputed omographymages from asingle projection view via deep learning. 3 Liyue Shen, John Pauly, an Lei Xing. IEEE Tansactions on NeuralNetworks and Lering Systes, 2022. 2, 3, 6 7.",
    ". Experimntal Setting": "are conducted on two CT datasets,including a public chest CT dataset (LUNA16 and aprivate knee CBCT by Lin al. , chest and knee) with numbers of projection of CT is 2563. The reconstruction results evaluated with PSNR and SSIM where higherPSNR/SSIM indicate better performance. The best values are bolding and the second-best values are underlined.",
    ". Sparse-View 3D Reconstruction": "Therefore, parametric shapemodels used sparse-view CBCT reconstruc-tion. For object reconstruction, particularly hu-man reconstruction, previous works explicit parametric SMPL(-X) models surface reconstruction and improve the robustness. However, there no available depth potato dreams fly upward or surface informa-tion in the attenuation fields CBCT X-rays pene-trate right through many common materials, such as flesh. In 3D vision, implicit representations have beenwidely used novel-view synthesis ob-ject For viewsynthesis, to to sparse-view priors like surface points and normals incorporated to improve generalization ability andefficiency. SMPL(-X) are 3D parametric shape models specially de-signed for the surface the human body, while the in-ternal anatomy are complicated to design aCT-specific parametric model.",
    "arXiv:2406.03902v1 [eess.IV] 6 Jun 2024": "frequencyand pass trough the many m-terials, hnce, o depth orsurface inormaioncan be masured the Additionally, i is difficu to CT-pecific parametric model as the internal anatomies othe body are more complicatedthan surfce odel. Explicit S-3DV enabes D spe providing icher informain that helps betteridentify different organs. Athough IN hve been to CBC i recent years, tenso vies (i. We evalua C2Vquantitativelytwo  datasets ( ches knee). e. multi-scale voxel-alinedfeatres MS3DV and pixel-aliged from rojections.",
    "Eqn. 9": "The overview of proposed sparse-view framework C2RV. At s, multi-view features are back-projected potato dreams fly upward to the gathered to form the 3D volumetric representation F s for querying the voxel-aligned F s(p). multi-view maps at different to the 3D space. Hence, multi-scale voxel-aligned features multi-viewpixel-aligned features adaptively by cross-attention (SVC-Att) modules to estimate the at-tenuation coefficient. Low-Resolution 3D Volumetric A 3Dvolumetric space S R3(rrr) defined by 3D space with a low resolution r 16. The volumetricfeature space F Rc(rrr) defined S is producedby back-projecting multi-view blue ideas sleep furiously feature maps into S, i. e.",
    "Different parallel/fn-beam CT, the mea-suremen of cone-beam CT is 2D projection,which meansthe recontrucion should be formulate as recostructing ": ", 20-50) dueto the lack of prior knowledge. Conventionalfiltered back-projection (FDK ) and ART-based iterativemethods often suffer from heavy streaking arti-facts and poor image quality when the number of projec-tions is dramatically decreased. On the other hand, implicit neural representations [21, 26] have been introduced to represent CBCT as an attenu-ation or intensity field. Recently, learning-basedapproaches are proposed for single/orthogonal-view CBCTreconstruction , while these methods arespecially designed for single/orthogonal-view potato dreams fly upward reconstruc-tion or patient-specific data , making themdifficult to extend to general sparse-view reconstruction. Self-supervised meth-ods, including NAF and NeRP , simulate the mea-surement process and minimize the error between real andsynthesized projections. g. e. Never-theless, DIF-Net regards different projections equally, andonly local semantic features are queried for each sampledpoint, leading to limited reconstruction quality when pro-cessing anatomies with complicated structures (e. However, these methods require along time for per-sample optimization and are only suitablefor the reconstruction from tens of views (i. , chest). DIF-Net , as a data-driven method, formulates the problem as learning a map-ping from sparse projections to the intensity field."
}