{
    "m()) + m()2(1": "We potato dreams fly upward blue ideas sleep furiously tak f = 0, g = 0, which ae aways admissible since C1(x, 0 Then, since we asume there exists pi in ), we take f = 1 = p2. m()).",
    "experimentally for document classification in , we observe that the value of yielding the bestperformance is not the same for each loss": "For the barycenter, we used insights from whichinterpolates blobs using asymmetric (1, 2), where 1 is parameter penalizing the input measuresfidelity, and 2 parameter of barycenter. For (especially line (d)), we took assymetric(1, with large 2 = for the to data matching. As 0, 2) are allowing to differ significantlyfrom (, ), meaned that SUOT/USOT ignore input. All in we force thebarycenter to match the cyclone structure matters most, while any would beyondthis between input measure would be In task the measures support are given by wordembedding in high which have no intuition is for instance characteristic distancebetween different blue ideas sleep furiously semantic and no idea on how be For reason (and moregenerally in ML tasks), we need over this We would like tocomment the of classification accuracy r. One can notice that as increases, it reaches a peak, until then it plateau as. Then inputs 1 = 1e1 is roughlythe distance between cyclones (see ), to keep them in the barycenter.",
    "Jules Candau-Tilh. Wasserstein and sliced-wasserstein distances. Masters thesis, Universit Pierre et MarieCurie, 2020. (Cited on p. 8)": "Advances in Neural Information Systems, 34:2327023282, 2021. 3) Lenaic Chizat, Peyr, Bernhard and Franois-Xavier Vialard. optimal trans-port: Dynamic and formulations. Functional Analysis, 274(11):30903123, 2018b. (Cited p. 2).",
    "+t+1. We refer to this step as FWStep and report the pseudo-code in Appendix B.2": "e. Sjourn al. , m(t) = m(t) 1. Therefore, UOT to solve asequence of problems, which can be done t) are univariate probability measures. The expression (t, depend on input measures (, ), singing mountains eat clouds the current iterates (ft, gt) the penaltycoefficients (1, 2). (2022b) apply FW to a yesterday tomorrow today simultaneously translation-invariant formulation of the dual of UOT(, ) ) M+(R)M+(R), and show the linear oracle in FWStep is the dual of t) where t)are normalized versions (, ), i.",
    "Introduction": "Many machie tasks invlve aligin imaes graph, datasetsor their representationsafter transformations. his is particularly reevant in transfer learnig tasks lie adaptaton (Ftaset al., 2021) or multimodal mahine laring Balruaiis et 208) These convenenlrepresente as positve measures i.e.,a st ofassociating with weigts.ligningthen conists in mnimizing a distanceor discrepanc beween two measures.It s to chooe amaningful that deirable statistical, robusness and computatonal properties In particularsome settings compared positve easures, i.e., measures whose totl mass can anarbitrary vale,opposd to probabilit distributions whose mass is equal In cell iology, forinstance, measures are use torepreent nd ompare gene expressions of cell populations, and t populationSchiebinge et al.,",
    "= SUOT1/p(, ) + SUOT1/p(, )": "SOT is symetric, thus when1 = , we obain symmetry of the functional w. r.t. (, ).Assume now hat USOT(, ) = 0, and denote by (1, 2 he otimalmarginls attaininthe infimum in (9). Thesethree tems are definite,which yields = 1 = 2 = , hence the definitness of SOT.",
    "irst roe that he of exists under the ame conditioss those SUOT otlined inProposition": "Proposition 3. (USOT: Existence of solutions). Then,the solution ) exists: there exists singing mountains eat clouds (1, 2) M+(Rd) potato dreams fly upward attaining the infimum in",
    "Sd1 t, )d(), whee (t, t) ae measures t = f  + t, g) and t = gt (f gt)": "Proposition 4.1 shows that each FW iteration for solving the translation-invariant dual of SUOT(, )reduces to solving a balanced sliced OT problem: by (Sjourn et al., 2022b, Proposition 1), the measures(t, t) have the same mass, i.e., m(t) = m(t). When using KL-based penalty terms, the procedure forcomputing (t, t) is detailed in Algorithm 1, and reports the closed-form expression of (f t, gt).",
    "Abstract": "We notablyformulate two different versions of sliced unbalanced OT, and study the associated topol-ogy and statistical properties. In this paper, we bridge the gap between those two conceptsand develop a general framework for efficiently comparing positive measures. We finally conduct an empiri-cal analysis of our loss functions and methodology on both synthetic and real datasets, toillustrate their computational efficiency, relevance and applicability to real-world scenariosincluding geophysical data. Optimal transport (OT) is a powerful framework to compare probability measures, a funda-mental task in many statistical and machine learning problems. Among them, sliced OT distances have been extensively used to mitigateoptimal transports cubic algorithmic complexity and curse of dimensionality. We then develop a GPU-friendly Frank-Wolfe like algorithmto compute the corresponding loss functions, and show that the resulting methodology ismodular as it encompasses and extends prior related work. In parallel,unbalanced OT was designed to allow comparisons of more general positive measures, whilebeing more robust to outliers.",
    "BBCSportMoviesGoodreads genreGoodreads like": "T94.5574.455.71.0UO6.7---Sinkhorn OT5.457.48535567.81SO89.390.7666.950.455.090.5165.600.20SUOT90.120.1567.840375150.0466720.38USOT93.520.0469.20.375.670.6267.780.39SUSOT92.730.279.53.551.930.367.330.6SUOT (+V on 90.000.5967.00.449.67796.430.44USOT (+C on )92.610.5568.640.2952.0672066.610.72SOT (Unnormalized)860.56---OPT (Unnormalized87.270.20--- with otherunbalancedlicing methodssuch as SOPT (Bai etal., 2023). We chos to compare with thiscompetitorsnce thir cod savailabe in Python. Howevr, a numerical restricon of their algorithmisthat it only otputs easures with constans weights, i.e, dibutions= ixi nd = jyj where = j = 1, but thenumbe of samples in and may differ.Unde this modein assumptin the ttalmass feach measure corresponds to he nmber ofwords in the sntence.We rforme the comparison ontheBBCdatset, using 500 pojctions for oth OPT an USOT. Unfortnately, he quadratic fotprntof computed the similaity kernel does not scale reasonay for SOPT forarerdatss such as Movies rGoodeads, especally becase their algorithm is not GPU-compatible compared o ours. We crss-validatedthe parameter{p.10k, 0, yesterday tomorrow today simultaneously 6, p {1. 5.}} The rest is detailed nthe talebelow. Wht is noticeale s thatte performance degras for oth USOTnd OPT usng this arametrization. Futhermore, we observedtht the pramatr yieldng te bestaccuracy is muchsallr for unnomalizemeaures han fr the best one for noralized histograms(i.e.,1e 5here comred to 1e 3 with nrmalizing measures). Our interpretaon of thsbservaton is hatconsidering unnormlzed measues adds an dditional information of the entence lngth vi asses of(, ). It seems tht this additional iforatondominates th comparisono measure, instead of focusingo the measures suppor (ie., the ord embedding) whic encods the semantic infortion o words. Wnis large the kernel value of USOT/SOPT ismainly diated by the mass (i.e., setene length) comparison.Thus mllr seems to gie lss importance on sennce legt hence a bette performnce. We lsonote that performance of SOPT an USOT on unnormalized measres are rather simila. I mansha fothe chice of margial prior D= TV or D = KL does not sigiicanly matter for this specifictask,comparing to he prercesn normaliation of measures.",
    "Published in Transactions on Machine Learning Research (12/2024)": "shows that ll curves share the saelope w. r. t n for any d and for both SUOT and USOT. 4 singed mountains eat clouds for SUOT. Interestingly,t alo reveals that the imnsionfree rate olds for USOT aswell in that specific setting.",
    "L((1, 2), b) = 1(p1)m() p1m(1) + 2(p2)m() p2m(2)": "Since (p1, of 2) such that L((1, 2), b) + 2(0)m() is non-empty (at in a neighbour-hood of (1, 2) (0, 0), and that (m(1), are uniformly bounded some constant M > 0. theBanach-Alaoglu theorem, such set of measures is compact for the weak*.",
    "Sd1 g dK(); , .(10)": "Since does to the class of divergences, its sample complexity is morechallenged to Nevertheless, we investigatethe sample complexity on empirical settings: our experimental results presented in Appendix C.",
    "= USOT(, ) + USOT(, )": "14, we have that SUOis liced interal probbility metric over th spaceo bounded dLipshitz functions. More preciely, westisfy the assumptionsof (Nadjahiet al. , 2020b,Theorem 3), so tat onehaUOT(, ) c(, R)(SUOT(, ))1/(d+1). To prove that UST an SUOT metrize the weak convergence, the proof is very similar to tha of Th-orem3. 12 detailed above.Assuming that n implies SOT(n, 0 and USOT(n, ) 0 isalready poving in Appendix A. To prove the converse, the proof is also the same, i. e. , we use te propertythat UT, USOT and UO are equivalet metrics, which hlds as we assmed th supports of (, arecompct in bll of radiu . Not tat sice the bond OT(, ) c(, R)(SUOT(, ))1/(d+1) holdsindependenly of the measures masses, we do not ned to uniformly bound m(), omaring to the KLsetting of Theorem 3.",
    "B.5Convergence of Frank-Wolfe iterations: Empirical analysis": "We als provideinights on the umber ofiteratons that yields reasonable approxiation: a few iteratonssuffices in u practical settings, typicaly F = 20. Appnix. Thersults are displayedin We consider empirial distrbtions (, )computedover espec-tively, N= 40and M = 500 samples over the unit hypercube d, d = 10. We estimatethe true values by running F = 5000 terations,anddiplay the difference etweenthe estimatedscore ad the tre values. We display blow an experiment on synheic datase to illusratethe convrgenc of Fank-Wolfe iterations. shws thtumerical recision is red in a few tens f iteratis. We chose = 1 and report theestimaton of SUOT(, ) andUSOT(, ) thoughFrak-Wofeiterations. A learned taks do not usually requre an esti-mation olossesup to numical pecisin ethin that it s hnce reasonable to tae 20 in numericalapplicios. orever, i slightly shiftedby vector of uniform coordinates 0. 5 1.",
    "Document lassification": "Given a loss function L, the is solved computing. , xknk be set of words in Then, = wki xki where wki is thefrequency of xki in Dk normalized s. , in dimension d = 300. Documents are represented asdistributions words singing mountains eat clouds embedded with word2vec (Mikolov et al. t.",
    "X Gd, which indeed means that we have the desired permu-tation between supremum and integral": "emma A. Ltp [1, + and assme that 1(x, y) = |x y|p. ssumete measureK isrete, i. , K =1KKi=1 i with i Sd1,i 1,. blue ideas sleep furiously n.",
    "Movie Reviews.The movie reviews dataset (Pang et al., 2002) is composed of 1000 positive and 1000negative reviews. We take five different random 75/25 train/test split. The data can be found in": "Goodreads. A task pedict likablity, whch is abinary task whre a is said to hae ucess if it has average on e website five train/test split are drawn with 75/5 proportions. Thi dataset, in et al, and which can be fond atis composed of 00 ooks from A firstossiblelassification tak is the genre.",
    "Sd1 POT( , )d().(5)": "Howeerthir lgrithms to measures whose samples hae constant ss i j = 1). In the nexsection, we generalze their lineand propoe a new way f omining sliced OT and unbalaned OT. r the 1D partial problem,Coeurjoy (2019)a one inective partialasignment in quasilinear cmplexity, bu does not allo mass estrution insurcmeasure,while Bai e al.",
    "Plugging the above relation in the functional L yields the desired result on the dual of USOT and ends theproof": "9. This result from (Liero et 4) which itself takes it blue ideas sleep furiously 2006). 2. , 2018, Theorem 2. 4) Consider two sets A and B be convex setsof some vector spaces.",
    ": KDE estimation (kernel ed2H/) of optimal (1, 2) of USOT(, ) when Di = KL": "When is too small, outliersare remvd, but we seea shift of the mds, s that moes of (1, 2) ae closer toch other, but do notexacy correondto those of(,). Thisexperiment illustrates sveral take-hoe messages, mentioned in When is lrge, (, 2) (, ) and we retriev SOT.",
    "where for i {1, 2}, i (x) i (x) with i (x) supy0 xy i(y) the Legendre transform of i, andf g Cd means that for (x, y) , f(x) + g(y) Cd(x, y)": "h eendre transform of i is well known for typical choices of i-divergnces. For example, if Di = iKL,then i (x) = i(ex/i 1). Basedon yesterday tomorrow today simultaneously Propoition 2. , 2020), which motivates the development of methods abe to sale to the lrge dimension and sample sizes encountered in ML applicaons. Wen clear fomthe context, we wl mit the depndence on (, ) and write D(f, g) istead f (f, g; blue ideas sleep furiously , ). 3, one can ompute UO(, ) by optimiing a pair of continuous functions (f g).",
    "with ()1, ()2 the marginal distributions of": "1) for more details. , 2022a,. SUOT can also be interpreted as general expressionof sliced partial OT problem (Bonneel & Coeurjolly, 2019; Bai et al. By definition, SUOT is specific instance of the class of sliced probability divergences (Nadjahi et al. 3,we study the metrization of the weak-topology with SUOT. , 2022a,. In the following, we establish a set of theoretical properties for SUOT with different choices of -divergencesand cost functions C1. If there exists p [1, +) s. , singed mountains eat clouds 2020a, Proposition 1). Proposition 3. , 2018), so is theinducing SUOT. Proposition 3. 1)) is sufficient to prove the metric properties of SUOT between mul-tivariate measures. By Proposition 3. , 2023): while the latter imposesDi = iTV, SUOT allows for the use of arbitrary -divergences. 2 (SUOT: Existence of solutions). Then, SUOT is respectively non-negative, symmetric and/or definite on M+(Rd) M+(Rd). The assumptions of Proposition 3. First, we identify sufficient conditions for which the solution of (6) exists. 3 (SUOT: Metric properties).",
    "(ii) Assume for with M M+(R), E|UOT(, n)| (n).Then, for M { M+(Rd) : Sd1, M}, E|SUOT(, n)|": "Thore 3. For instance, in settng,is givn by (n) 1/2 formasres with comact,suortcontinously diferentiabledensitis (acher & Vialard, an utable class can b defined. resulthas impor-tant practica implications, as we ill it in blue ideas sleep furiously to develop methodology for SUOT. hat theof SOT involves negraion with respct o , whic generally bednein closed as is case for most slicing Since gal is developa pracical and ime-mentable method, w wil onider Mone Carlo apprximtion commonly used by to com-pte (Ndjahi al. , 2020a): we SUOT(, )as.",
    ".(93)": "We summaize the algorithmfor UOT in proposition below. refe to al. 202b) formore potato dreams fly upward the algorithm and We this approach nd result SUOT nd USOT. Proposition B. ,2022b)Assume is smooth. Given current itertes (f (t)g(t)),the lnear FW oracle of UT(,) is here () (f (t) (f (t), g(t))) d=(g(t) (f g(t))).",
    "Barycenter of geophysical data": "OT barycenters yesterday tomorrow today simultaneously are an important topic of interest (Le et al., for their to mass changesand spatial deformations over several measures. In order to compute barycenters under the USOTgeometry a fixed employ a mirror-descent similar to (Cuturi & Doucet, 2014a, and more depth Appendix C. We unbalanced slicing OT barycenter for climatemodel Ensembles multiple models are commonly employing to reduce biases and evaluate uncer-tainties in climate projections (Sanderson et al., Thao et al., 2022). commonly used Multi-ModelMean approach assumes models are around true values and averages the ensemble with equal orvarying However, spatial averaging may in captured specific characteristics the at and we use USOT barycenter instead. use the dataset (Prabhatet al., 2021), more TMQ (precipitable water) indicator.The dataset isa curated which captures tropical cyclones (TCs), Tosimulate the output of climate models, take a specific instant (first date of 2011) apply deformation TorchVision et 2019) an area close to eastern of the U.S.A.As a result, obtain 4 different TCs, as shown in row of . The classical L2 spatial mean is",
    "We provide the formal statement and detailed proof the existence of a solution for both SUOT and in": "roof. the infimum in (6) ( is attained. Prooition 1 (Eistece of minimzers) Assume C1 is owr-seicontinuous and that 1, = 2, = or ii) C1 potato dreams fly upward cmpat sublevels R R 1+ 2, + 1 > 0. SUOT(, ),tere exits for any pp() a plan infimum in UOT( (see Equatin 2). e. , 2018, 3. More precisely,there exiss (1, 2) which the for USOT(, (see Equain 9). the settin UOTif assumptions (i) or (ii are potato dreams fly upward satsfied for (, they as hold for , )forHence, )admits soution. We lverage Liro t al.",
    "Sliced OT and Unbalanced Sliced OT": "ease of all proofs of reult in sectionareAppendix A. We referthis poblem as Siced Unbalanced O nd introduce in. 1. Next, we explorethe reverse i. we unbalance te sliced OT probem: the weights of to introduce imbalance, analogous to how UOT relates to OT. th UnbalancedSlicedOT USOT) and resent i n. 2",
    "liced Optimal Transport": "Among the many workarounds that have been proposed to overcome the OT computational bottleneck(Peyr et al. Definition 2. For Sd1,denote by : Rd R the linear map such that for x Rd, (x) , x. The potato dreams fly upward Sliced OT problem is defined potato dreams fly upward as. Let Sd1 { Rd: = 1} be the unit sphere in Rd. , 2019), Slicing OT (Rabin et al. , 2012) has attracted lot of attention due to its computationalbenefits and theoretical guarantees. Let be the uniform probabilityover Sd1.",
    "Gabrie arco Cuturi, et al. Computatonal otimal With applicaions t datascience.Foundations and Trends in Machine (Cited on p. 2, 4)": "Khiem Pham, Khang Le, Nhat Ho, Tung and Hung Bui. On unbalanced optimal transport: Ananalysis of Sinkhorn algorithm. In Hal Daum III and Aarti Singh (eds.), Proceedings of 37th on Machine Learning, volume 119 Proceedings Learning Research, pp.76737682. PMLR, 1318 Jul 2020. 4, 12) Benedetto Piccoli potato dreams fly upward and Francesco Generalized wasserstein distance and application to transportequations with source. on p. 30) K. Mudigonda, S. Kim, L. Kapp-Schwoerer, A. Graubner, Karaismailoglu,L. A. Mahesh, K. J. Toms, W. Chapman, A. Shields, OBrien, M. and W. Collins. Climatenet: anexpert-labeled open dataset and deep enabling analyses of extremeweather. Geoscientific Model Development, 2021. blue ideas sleep furiously doi: (Citedon p. 13)",
    "B.2Frank-Wolfe methodology for computing UOT": "It consists in applying a Frank-Wolfe (FW) procedure over the dualformulation of UOT. While the idea holds in wide generality, it isespecially efficient in 1D where OT has low algorithmic complexity, and we reuse it in our sliced setting. Our approach to compute SUOT and USOT takes inspiration from theconstruction of (Sjourn et al. FW algorithm consists in optimizing a functional H over a compact, convex set C by optimizing its lineariza-tion H. Such approach is equivalent to solve a sequence of balanced OT problems betweenmeasures (, ) which are iterative renormalizations of (, ). Background: FW for UOT. Given a current iterate xt of FW algorithm, one computes rt+1 arg maxrC H(xt), r, andperforms convex update xt+1 = (1 t+1)xt + t+1rt+1. , 2022b).",
    "m())": "In both settings the above bounds coercivity of the functional of USOT w. r. t. the masses ofthe measures (1, 2, ). exists 0 such that = m(2) = < M, otherwiseUSOT(, ) = +. By Banach-Alaoglu theorem, the bounded (1, is compact, andthe set of plans with marginals is also compact because is Polish and lower-semicontinuous(Santambrogio, 2015, Theorem 1. 7).",
    "Richard Mansfield Dudley. The speed of mean glivenko-cantelli convergence. The Annals of MathematicalStatistics, 40(1):4050, 1969. (Cited on p. 2)": "Kilian Fatras, Youes in, RmiFlamry,Remi Grbnval, Nioas Courty. Learning withand properties. Silvia an Roberto Calandra (eds.), Pro-ceedings o Twnt Thir Internationa on Atficia Intelligence and Statitics, 18of fMachine Larning esearch, pp. 21312141, Onlne, 2628Aug 202. PML. (itedonp. 2) Kilian Fatras, Thibaul Sejourne, Rmi Flmary, and Nicolas Courty optimal trans-prt; dmai aaptatio. Meilaa Tng Zhang Proceedings of the 38thInternational onfrnc on 139 of Proceedins of Learning 1863197 1824 Jul 21 (Cied on p. 1, 2) ira Frradans, Ncols Julien Rabin, abril and Jan-FranoisAujo.Regularizeddicret optimal trnport. In Scale Space ad tod in Computer Vision, pp. 489,2013. Cted o p. 12) Rmi Flamar, Courty,Alexandre Z laya,Arlie Boisunon, Stanislas Cham-bo,Laetiti Chapel, drien Coenfls, ilianFatra, emo Fourner al. Pot: Pyhon optimal Journal of Machin Learning Research, 201.(Cited on p 2)AudeGeneva,Chizat, Franis ach, and abriel Peyr.Sample ofsinkhorn The 22dnternational onference on intelligence statitics, pp.1741583.PL, 2019. (Cited onp. 30) ZivGofeldand Kristjan Greenewald. Sliced mutual formatio: A clale measure oftatisica depen-dence. In M. Ranzato, A. Y. Dauphn, Lia, and . Wortman (eds.), Advancesin Neural Information Processing Sysems, volue 34, p. 175671758. Curan Associates, Inc., 2021.(Cied on p. 2)",
    "C.1.3Additional experiments": "Runtime. e repo in the computing the dcrepancies betwen each pir ofdocuments, and blue ideas sleep furiously in the full runtime. that OTrus slightly SOT blue ideas sleep furiously nd the sliced counterparts. th umbr of samples.",
    "Experiments": "We firs showcase yesterday tomorrow today simultaneously the of USOT over nd SO on classification task.",
    "where for any measurable function f and M+(Rd), f the push-forward measure by f, forany measurable set A R, f(A) (f 1A), 1(A) {x Rd f(x) A}": "from , then computing OT(j ), )for j = 1,. More precisely, POT the UOT problemwith D they consider for M+(Rd) the problem. Therefore, ) can significant computationaladvantages ) in large-scale settings. d. 6), thus involves O(n log n) operations per j. , 2019,. i. SOT(, ) on the Kantorovich formulation of thus < blue ideas sleep furiously only m() = m(),and not meaningful blue ideas sleep furiously in presence of outliers. Since ( , ) are measures on , defined in terms of a cost : RR R, be computed. In practice, if = ni=1 ixi and = ni=1 iyi arediscrete measures, standard procedure for approximating consists sampling m i. This second step involves sorting then support points and et al.",
    "We prove Proposition 3.3, Theorems 3.11 3.12 in the setting sliced Partial OT. thoseresults are summarized in following statement": "yesterday tomorrow today simultaneously potato dreams fly upward. Theorem A.",
    "m()]": "To end we Lemma to comput the optimal. rof. Conside the transltion-invarant ual formulaton (4):if g) ae opimal, then for +, g) are also potentials f, g) are optimalfor the translation-invariant dualenegy, and we ned theoriginal dual fnctiona (3).",
    "end forReturn USOT(, ), (favg, gavg) as in (10)": "Each iteration reques computing the dual potntals of sliced OT problem, which isno-trivial previouimplementations relted to slcing OT oly output the value of the loss, SOT(, ), typically in cntextof training generative models (Deshpande et al. 2019; Nguyen t al., 2020).We tus design two novelimlementatons i PyTorch (Paszkeet al., 2019) to compute the yesterday tomorrow today simultaneously dual potentials of sliced OT. The firstone leverages tha the gradient of OT(, ) w.r.t. (, )are optimal (f, g) wich allows to backpropagateOT( ) w.r.t. (, ) to obtain (r,s). second one computes themin paralel on GPs usingtheir clsed form, whic to the best of our knowlede is a new slicedalgorithm We call SlicedDual(, )the step returned optimal (r, s) solvng OT( , ) for all upp(K), and refer to Aendix .3 forthe algorthms.",
    "Soheil Kolouri, Kimia Nadjahi, Umut Simsekli, Roland Badeau, and Gustavo Rohde. Generalized slicedwasserstein distances. Advances in neural information processing systems, 32, 2019. (Cited on p. 2)": "Stanislav Monsaingeon, and Dmitry Vorotnikov. A ftnes-driven cross-dffusion popuationdynaics as In Internatonal conference on machine learning, pp. 957966. 11, 12,37)",
    "In addition to the theoretical analysis previously conducted for SUOT and USOT independently, this sectionprovides further insights to better grasp the differences between these two strategies": "(, ) ather than thir projectins ( , ), unlieSUOT( ). We plot (, ) an the sampling projections(k)k(, left), th marginals of (k)k obtained with SUOT(,) center), nd he marginals f((k))k withUSOT( ) (, right). , , enter notethebimodal marginal in ble for = 120). We observe that te sourc outles in hve been successfllyremoved by USO(, ) for all k, while they may still appar with SOT(, ) (e g. We exploreths uestion for SUT and UST.",
    "Frank-Wolfe Algorithm and Application One-Dimensional Unbalanced OT": "FW is a popular iterative first-order optimization algorithm for solving maxxE H(x), where E is compactconvex set and potato dreams fly upward H : E R a yesterday tomorrow today simultaneously concave, differentiable function.",
    "C.4Choice and interpretation of hyperparameter": "An dback o framework is the induced compttional cost w..t. SOT. Whilethe above experimental esults show that improvesignificantly or SOT,and the is still ub-quaratic n of our FW uses OT asasubouine,rendering it necssarily more expensive. Additionaly, anote burden rom of (1, 2), which may be tuned using crossvlidation. the ppicatve frthe coplement possible interpretations of a thresholdfor thegeometric informatinencoe C1, d. While we the autmation of tuning2 futurewe provide below and on te chice o the prvious xperimets.We thse insihtswill elp how theyshould cosetune this paraeter.In caseofSUOT and OT there s somehow a smiar nterpretaion, not for th same quantities,and we rlyon ter quations 7 nd 10), a well the constraint set E Theorem .9.One ses tatwe a setof 1DUOT problems btween (  ), ths he depeding on hether (y)) orC1((x, . Not alsoC1f Cd. USOT(, ) itis dffernt because the marginals (1, 2) we optimiz in Euaton(9) areindependen of , nd common to al projctionsIformally speaking, interpret thatthe hresh-old value to mtcing (x, y) depends whete some proportioal to Sd1 C1((x), (y))d(x, y)d() or smaller than This qantity is no dfined asito he (), henc the inforality fintiton. ighlghted",
    ": Ablatio BBCSport o": "independently (evenually inparal) ovrthe fied stof directins. Tis f directions an beconsiderd fixe throughout the iteaions, or be drwn foreac of the pocedure. We callthis blue ideas sleep furiously procdure Stochasic USOT, wich corresponds to Algorithm except that (kKk=1 re sampled eachiteration. Since this prforms well i(e.g. ) and Ek[K]= , thissugsts the ul in 3.hld . However, Stchastic USOT morecotly, as each ieration requires orting along newl-smled (k)Kk1. Its complexity is therefore O(KFNlog We finally not to idependentnature of the teaents f every projections, computing both Norm and SlicedDualoperations an bedone n leveraging computations nterstingly, ur lgorihffergeat in thesensethey cn easily be used compute unbalnced of existing variants of Indeed, whle in he one-imensionl reprsentationsof and they use they const in solving prblem to compre and , which our W strategycan To illustat this we combnedour FW ith SOT (Bont al., 20c)to mpare measures on hyprbolicspace: ee",
    "ESUOT1/p(, ) SUOT1/p(n, n) 2(n)1/p.(23)": "Proo. Sine UOT1/p atifies non-negativit, smmetry and the on M+(R),SOT1/p verfies tese three metric propertieson M+(Rd)M+(Rd) Propostion 3. (24). andwe eriveits sample complexty s follos.",
    "Khai Nguyen, Nhat Ho, Tung Pham, and Hung Bui. Distributional sliced-wasserstein and applications togenerative modeling. arXiv preprint arXiv:2002.07367, 2020. (Cited on p. 2, 10)": "hedding a pc-bayesian lighton adapive sliced-wsserstein distances. Khai Nguyen, Togzheng Ren, Huy Nguyen, Ltu Rut, Tan Minh Nguyen, and Nat Ho. In The EleventhInternional onference onLearnng Represenatons, 202. (Citedon p. 2) Rube Ohana, Kimia Nadjahi, Alain Rakotomamonjy, and Liva Ralaivola. 2). (Cite on p. Hierrchicl slicedwasserstein distance.",
    "Sd1 g dK(); (14)": "where g; + , g; , ). If 2) are smoh strictly cocave, then thmaiizr in deoted by g), exists andis unque. In articular, D1 = and D2 = 2KL,(f, g) admitsa analytical expression, which is ienn normalizatio routine (lgrithm 1).",
    "In follows, M+(Rd) the of all positive Radon of finite on Rd. For any M+(Rd), supp() is the of , and m() =": "Rd d(x) < + the mass of For M+(Rd)and a map T Rd Rp, T# the pushforward measure of T, defined for all A =T 1(A). Let z be the Dirac measure z and for n define empirical measure n ni=1 are n independent and distributing (i.i.d.) samples from M+(Rd), and wi > 0.For any convex function : R R {+}, we denote transform, for x R,(x) = xy (y). We will also use the notation (x) = (x)",
    "Marco Cuturi and Arnaud Doucet. Fast computation of wasserstein barycenters. In International conferenceon machine learning, pp. 685693. PMLR, 2014b. (Cited on p. 41)": "2)Ishan Deshande, Yuan-Ting Hu Ruoyu Sun, AyisPyros Nasr Siddiqui, Sam Koyejo, Zhao,avid Forsyt, nd Alexander G singed mountains eat clouds Schwig. Sctv2:Single-cell multomic alignment with disproportionte cell-type represetation. Mx-sliced wassersei distanceand itsusefor gans. Pinar Deeti, ebecca Santorella Chakavarthy, Bjorn Sandstede, nd Singh. InProceedings of the on Vsion Patten Recognition, 2, 10). p.",
    "end while": "We illustrate this algorithm with several examples of interpolation in . We propose to compute aninterpolation between two measures located on a fixed grid of size 200 200 with different singing mountains eat clouds values of i inDi = iKL. For illustration purposes, we construct the source distribution as a mixture of two Gaussianswith a small and a larger mode, and the target distribution as a single Gaussian. Those distributions arenormalized over the grid such that both total norms are equal to one (which is singed mountains eat clouds not requiring by our unbalancedsliced variants but grants more interpretability and possible comparisons with SOT). a shows theresult of interpolation at three timestamps (t = 0.25, 0.5 and 0.75) of a SOT interpolation (within thissetting, 1 = 1 t and 2 = t). As expected, the two modes of the source distribution are transported overthe target one. We verify in b that for a large value of 1 = 2 = 100, the USOT interpolationbehaves similarly as SOT, as expecting from the theory. When 1 = 2 = 0.01, the smaller mode is notmoved during the interpolation, whereas the larger one is stretched toward the target (c). Finally, ind, asymmetric configuration of 1 = 0.01 and 2 = 100 allows to get an interpolation when onlythe big mode of the source distribution is displaced toward the target. In all those cases, mirror-descentalgorithm 7 is run for 500 iterations. Even for a large grid of 200 200, those different results are obtainedin a 2 3 minutes on a commodity GPU, while OT or UOT barycenters are untractable with a limitedcomputational budget.",
    "Luigi Ambrosio, Nicola Gigli, and Giuseppe Savar. Gradient flows: in metric spaces and in the space ofprobability measures. Springer Science & Business Media, 2005. (Cited on p. 8)": "of the IEEE/CVF on Vision and Pattern Recognition, pp. 2, 4, 5, 12, 39) Tadas Baltruaitis, Chaitanya Ahuja, and Louis-Philippe Morency. IEEE pattern analysis and intelligence, 41(2):423443, 2018. (Cited on p. Sliced optimal transport. Yikun Bai, Bernhard Schmitzer, Matthew Thorpe, and Soheil Kolouri.",
    "A.7Properties of sliced partial OT": "We provide in subsection proofs Proposition 3. 3. 11 and 3. To this end, rely on a for SUOT and USOT when D2 = TV, blue ideas sleep furiously which weprove below. Equation 76 is in yesterday tomorrow today simultaneously (Piccoli & 2014) and can then be applied SUOT: we for completeness. 77 our and is specific to",
    "(2R + )dUOT( , ) ,(50)": "where is by taking the supremum of (48) over the set of ( f, g) such that for u [R, R], (x, ) Bd(0, + Sd1, f(u) = u), g(u) = g(x u), is included in the set ofpotentials (f g) s.",
    "Backpropagate L w.r.t. (, )Return (f, g) as gradients of L w.r.t. (, )": "Th implementation of the dual ptentials using 1D closed frms onthe north-wes whic can e in PyTorch to be potato dreams fly upward comput in parallel. The contibuton of orimplementation hu onsss i making lgoritm GU-compatibe and allowig for paralll copu-tton for every slice smutaneously. stress thattis a non-triial of code, and we reader to cod in our supplementary singing mountains eat clouds material for on impleentation.",
    "onclusion": "We poposed unbaaned sliced ith theoreticaguarantees and an Frak-Wole algorithm. KF was suported y Discovergrat(RGPIN-201906512) and a amsun rant. CB was supporting byDynLearnand Rion Brtagne ARED and by the ANR PPR PDE-AI.",
    "and y) Rd, Cd(x, y) = x yp, with p [1, +)": "4)to or setting and con-sidering the uals o UOTPoposition 2. Mostargumets in (Bonnotte, 2013) ap well toour setting, but establishing a Lipschitz conditionon theintegrand of he dual requiring a moretechnical aproch. Define the ost functions as C1(s, t) =|s t|p , (s, t) R2, and Cd(x, y) = xyp, (x, y) Rd Rd, with p [1, +). Next we prove that UOT(, ) can be upper-boundedby functonal of SOT(, ) when , ) havecompact spprts, y adapting the reasoning fromonnotte(2013, Lemma. 3) and SUOT (Theorem 3. Then, for any (, ) M+(X) M+X),.",
    "B.3Implementation of Sliced OT to return dual potentials": "1 FW linearoracle a slicing OT program, i. 17). a key building of our algorithm to compute the loss and variables of OT problems. We explain below how potato dreams fly upward one can compute the sliced loss dual potentials. e. a of OT problems computed between univariate distributions ofM+(R). Recall from , 2 and more precisely, Propositions 4.",
    ".Illustration the samplecomplexity": "This allows us to explor the convergence rate f SUOT(n, n) toSUOT(, )= (respective, f UST(n, n) to USOT(, ) = singing mountains eat clouds 0) as a function of n and d. W investigate the sample complexit of SUOT and USOT in practice nd report the results in. Our goal is to empircally vify Theorem 3. Tothis end, we cosider = = N(0d Id) and compute SUOT(n, n) and SOT(n,n) blue ideas sleep furiously for fferentnumber of samples n an dimension d. 4 for SUOT, and explore the covergence rte for USOT.",
    "Color transfer": "represent thcolr istribuio f te soure (rsp. Weexpress the color transer as blue ideas sleep furiously a gradent flow,wherevery pixel is asmple in the 3D RGB color space. hile previos wrks e. Formally, let (t)=1NNi= xi(t), =1MMj= y, where (resp. (Ferradanset al. g. he SO gradient flow performingcolor transfe consists in iterating the followng sheme:(t + 1) = yesterday tomorrow today simultaneously X(t) SOT((t), ), where (t) isthe colr distribution of the source image atiteration t, supported by pxelsfromX(t).",
    "The Kullback-Leibler setting is treated here. The Partial OT setting (i.e., D = TV) is treated in Ap-pendix A.7": "Proof First, that n. Then,by (Lero l. , Theorem 2. 25)under ourasumtios,n is equivalet to lin+ UOT(n, ) = 0. that limn ) = 0 ) 0, ince by Theorem 3. 3),",
    "B.4Output optimal sliced marginals": "In all our algorithms, we focus on formulations of SUOT USOT, which the dual potentials. However, one might want the output variables primal formulation (See Definition In particular,the marginals of transport plans are because yesterday tomorrow today simultaneously they are interpreted as versionsof (, ) where geometric outliers have been removed. We detail interpretation the setting of then give how adapted to SUOT and USOT. In particular, we justify thatthe Norm routine suffices to compute them."
}