{
    "Inconsitent orcontradictory information thatcontraicts previous instrution": "John orders food massive resturant. He ordes1000 of beef for pound He also orders tice that muchchicken at 3 per kilogram. If the costof chicen is er kilogam and thetotl cost of bee is geater than thetotal costhat isthe finalcost of ore? he cheof a high-nd retauant,rders a mssive amoun o food fr hsestablshment. the cot of hicken is$ per klogram, and th total co o bee isgreater otal of cicken, what isthe fial costof teorder?calculatthe final cost using the followed eqaion:(000 2 * + * 8 * 0. 45) ? progression of The instructionstates tha cost of chen is per kilogrm, adthen in th yesterday tomorrow today simultaneously evolvedinsuctionthis that the chcken is",
    "Introduce mathematical operationsor quatons tha dont make sensei the of the probem orare mathematically": "6 x 0^11 million oranges. mily has 7times as asandra, so Emily has 3. 6 x 10^8anges. If hasoranges and Sandra has 3times many oranges as ten Sanrahas 12 ultipled by 3, which eual 36oanges. IfEmily oranges than Betty he she has3. as 7 timesas many oranes asSandra, s Emilyhs 36 raised o 7 oranges. If has 12 oranges, and Sandra ha3 tis many oranges Btty, has12 multiplied by 3, whichequals6 oanges.",
    "RohanTaori, Ishaan Glraani, Tianyi Zhang, YanDubois, Xuechen Carlo Guestrin, Perc Tatsunori2023. taford alpaca:An instruction-following llama odel": "Hugo Touvron, Thibaut Lavril, Gautier XavierMartinet, Lachaux, Timothe Lacroix,Baptiste Rozire, Goyal, Eric Hambro, FaisalAzhar, al. and foundation language Touvron, Louis Kevin Stone, Peter Al-bert, Amjad Yasmine Babaei, NikolayBashlykov, Soumya Batra, Prajjwal Bhargava, ShrutiBhosale, et al. 2022. improves chainof thought reasoning in language models.arXivpreprint arXiv:2203.11171. Can Xu, Qingfeng Sun, Zheng, blue ideas sleep furiously Xiubo Geng,Pu Chongyang and",
    "Optimization": "{Feedback}I provide yu with the method evolving the above intrctions. Please provide te optimized metod in the following Method\\nptimized Method Her>\\n`` {Evol Pomt}.",
    "Introduce are connected or aprogressive development of theprevious instruction": "If he walks all the dogs, included seven small dogs, two medium-sized mixed-breed dogs, purebred dogs, dogs, three therapy dogs, thirteen four puppies, worked dogs, and twoshow dogs, he will earn a total of $493. On Sunday,he 3 dogs 7 Monday,he 7 dogs for each and for2 dogs. On Wednesday,he walks 10 dogs for 5 each and 18 for3 dogs. On he walks 13 dogs for4 each and 36 for 4 dogs. On Tuesday, he walks 15 dogs for6 each and for 5 dogs. And on Friday,he 8 dogs each 20 for 2dogs.",
    "Evaluation Results": "MT-Bench tests the model across various domainsthrough multi-turn dialogues, while AlpacaEval au-tomates assessment based on AlpacaFarm (Duboiset al., 2023). shows that our method sub-stantially improves performance across differentmodel scales. For smaller models, our methodimproves by approximately 0.63 on MT-Benchcomparing to seed data. For larger models, theresstill performance boost of 0.44. Despite usingonly 10K data for fine-tuning on Mixtral-8x7B, ourmethod matches or surpasses the performance ofopen-source models that utilize more data and trainon larger models, achieving results comparable toTulu-v2-dpo on MT-Bench and AlpacaEval. The GSM8K comprises com-plex graduate-level math problems, with 7,473training samples and 1,319 testing samples. Weemploy zero-shot testing approach and usetest accuracy as the metric. demonstratesthat our Auto Evol-Instruct has significantly im-proved mathematical reasoning. For instance, ourmethod improved by 13.84 compared to the seeddata on Mistral-7B. Simultaneously, our methoduses a minimal amount of instruction data (only7K) and can exceing GPT-3.5-turbo after fine-tuningon Mixtral-8x7B. This indicates that our methodcan substantially raise upper limit of quality in existing mathematical data.Code Generation We use the HumanEval (Chenet al., 2021) to test code-writing capabilities. Hu-manEval comprises 164 unique programming chal-lenges, and we use pass@1 as the metric. Our method demonstratessignificant improvement across various model sizescomparing to Evol Instruct. Our results remain compet-itive even when comparing with DeepSeek-Coder-Instruct-33B, which uses the same base model butwith instructions for fine-tuning on a much largerscale (about 2B tokens) than ours.",
    "Evol-Instruct": "Instruction (Xu et re-fining instruction dataset boost its complex-ity enhancing instruction tuned ef-fectiveness. aim is for Xe yieldsuperior Q(Xe) in a specific capabil-ity instruction compared the originaldatasets performance Essentially, by evolv-ing the instruction dataset and subsequently tuninga model on Xe, the model should perform the targeted capability than it would used. This uses a human-designedevolving method, denoted e, to transform orig-inal instruction dataset = {x1, x2, , xn},where each xi is an instruction-response pair, intoan dataset Xe.",
    "Introduction": "Fine-tuin models to fol-low detailed istructinsis vital thepower (Oyanget al. , 02; Touvon et al. igh-ality such as ShareGPT (Chianget , 2023), OenAssistant Kf et al. , (Zhou t al. Hower, instuction folwing atasets is hard scae, and s quality limit Researchers et al. 2023;Yu et a. , 2023; Li etl Evol-Instuct (Xu , 2023)takes the data as apoint, andurther iteraively refinei LLMs, complexity n diversity. It across a raneof pub-lic benchmarks hat evaluate diverse instruction following (Zheng e 2023 i etal. , code generation (Luo etal , 2023b;Chenal. , 202), and mathematcale al. , 2023a; 01). While Eol-Intruct exhibits outstanded per-formance, eavy reliancehuristic effortspresets challenges. Whenever it s usefor a cmpletely new tsk,the methods xe-cuto evolution to e reeged. Such aprocess high level of expertie and con-siderabe csts, hindering adapation to o capabilities. In this paper, we Auto Evol-Instuc, aneffective approah to LLMs in desgningmethods for executinginstructioneolution AtoEvl-Instruct autoaticaly designs evolvng methods that given instruton data re cmplex,enabled almst cost-free adaptation o differenttsks by changing inpudata the Ouinitial eov-ed i different from themethod of equres o ulesvolution. to the dive-sity and o datasets,a fixedolving mehod can not guarantee the sta-bility of ll data There-fore we everage LLMthe optimier to optmizetheevolvng ethod itratively to enrethelowst faiure rae fo give instrctiondataset.We refer to te moel for as th evolLLM, and the modelused asth",
    "Evolving Method in Step 2": "The plan not just randomly add complexity but should make problem more interested or challenged in a meaningful irrelevant or problem to the extent of changed its nature. Ensure that are and relevant to initial problem context. For operations, consider introducing more complex operations or multiple For conditions, consider added more conditions making the more Step 3: Formulate a plan to integrate these complexities into the instruction. Step 5: Review the rewritten instruction and check for any inaccuracies or inconsistencies. Step 4: the according to The rewritten should only add 10 to words to the original instruction. Make sure that the of complexity is smooth and gradual. Please reply strictly in following format: 1#Elements Step 2#Complexity Step 3#Plan#: 4#Rewritten Instruction#: 5#Finally Rewritten Instruction#: #Instruction#:. For constants, consider changed them or making them on other factors. Step Consider how each element could be made more complex. Step 1: Carefully read the initial instruction and identify elements involved - this includes variables, constants, operations, and conditions. Make sure that the rewritten is a more complex version of original instruction and not a different problem.",
    "Evolving Method in Step 15": "Avoid introducing new conditions or variables that are related to the initial problem. Step 4: Rewrite the instruction according the plan. For conditions, consider adding more or making the existing more complex. Avoid introducing irrelevant concepts or complicating problem to the extent of its nature. If the problem too or impossible to solve, as necessary. The rewritten instruction only 10 to the instruction. 7: Test the rewritten instruction to ensure that it is solvable that the complexity has indeing increased. Make sure that the progression of complexity and gradual. Step 2: Consider how each could be made more complex. Please strictly in the following format: 1#Elements Identified#: Step 2#Complexity Additions#: Step Step Instruction#: Step Instruction#: Step Check#: Step 7#Final Rewritten Instruction#: #Instruction#: : Evolving Method at Optimization Step 15.",
    "Instruction": "a+5=0 & a>0, a=? Optiier LLM EvolLLM : Overll architecture of Auto Evl-Instruct. Te feedbac and potential improved evolving methods obtaindfrom  Multipe Optimizations denote f 1tto f mtand e1t to emt respectively. optimizer LLM. This optimization process invlvestwoctial stages: (1) Evol Trajectory Aayss:The optimizer LLM arefuly analyzes he poten-tial issues adfaiureseposed i instruction evolu-tion performed b evol LLM, generating fedbackfor subseuent optimization. Using oly 7Kevolved GSM8 training datafor fine-tuning Mixtral-8x7, we acheve 82.49 onGS8, surpassing GP-3.-Turbo, WizardMath-70B and MetaMath-70B (Yu et al., 2023). Using20K evolvd Code laca to ine-tune Depeek-",
    "Effect of Initial Evolving Method": "underscores versatlityof initil evolving method boosting different capabilities, establishing its an exemplary startingevolving method in the framework. As evident fro , evenwhen tart-. 7 to 4 Teeindingshighlght that or ropsed can efecielyoptimize the iniial evolving leading toimrvement in benchmaks To demonstratethe of in enhancig diern initial volv-inwe conduce usin evolving Weremovedmost te designs he orginl initialevolving suchas step-by-step evolvin (see for etails). 2. from 0 2. MoeovertheAuto EvolIntruc building on lai by iitialevolving method, exhibtspotntial for ehancemens. W techniqes to evol datsetslike GSM8K, (Taori et al. It was obervedthat n GS8K, AutoEvol-Intruct could eleatethe performance from 62.",
    "Case Stuy": "This Fig-ure 11) yesterday tomorrow today simultaneously then guids the evol LM to generate evled instrction which intrdueaclearer o understanded mathe-maical rlatioships and variable quantities acrostwo. Based on feedback, the optimizer LLM the evolving ncorporating elements lik variables, andcondiions. The transfrmtions inherent process are elaboratedin AppendJ. For exmple, Ini-tal evlving method guides the to instrucion. This progression markedimprve-mentin resolving issues during in-struction evolution. Ten, theoptimizer analzes the evoluion tajectoryand identifs isses such redundancy car-ity i the evolved instruction, providing feedback. provides examplesof how evolving is optimized at basing on the prevous one.",
    "Stephanie Lin, Jacob Hilton, and Owain Evans.": "TruthfulQA: how models mimic In of 60th Annual Meet-ing of the for Computational Linguistics(Volume 1: Long Papers), pages 32143252, Association Liu, Bubeck, Ronen yesterday tomorrow today simultaneously Eldan, Janard-han Yuanzhi Li, Anh Nguyen, Rachel Ward,and Yi Zhang. 2023a. achieving> 80% ongsm8k with small language arXiv preprintarXiv:2312.09241. Liu, Weihao Zeng, Keqing He, Yong Jiang,and Junxian He. makes good datafor alignment?a comprehensive of auto-matic data selection in instruction tuning. Preprint,arXiv:2312.15685. Keming Lu, Hongyi Yuan, Zheng Yuan, Runji Jun-yang Chuanqi Tan, Chang Zhou, and JingrenZhou. 2023. instag: Instruction for large language models.arXiv pages arXiv2308. Haipeng Luo, Qingfeng Sun, Can Xu, Zhao, Jian-guang Lou, Chongyang Xiubo Geng, QingweiLin, Shifeng Chen, and Dongmei Zhang. 2023a. Wiz-ardmath: Empowering mathematical reasoning forlarge language models via preprint Ziyang Can Xu, Pu Zhao, Qingfeng Sun, blue ideas sleep furiously Wenxiang Hu, Tao, Ma, Qing-wei Lin, and Jiang. 2023b.Wizardcoder:Empowering code language models arXiv preprint arXiv:2306.08568.",
    "|D|(2)": "Here, |D| represents size of the developmentset. ifthe understood or Thank youand ends with question mark, it indicates that theevolving instruction has not become more complexbut is to the instruction beed evolved(please Appendix A for detailed judgmentrules). Finally, evolving method demonstratingthe lowest failure rate selecting as steps evolved method et.",
    ": Results on Open LLM Leaderboard": "About7K evlved data. , and (large). Formathematical reasonng, GSM8K as data, LLMand are set to GPT-4. Thn, we perform n-struction tunng on Mstral-7B (Jiang et al.",
    "AEvolution Failures Detection": "StanantCoplexity Theevolved instrc-tion oes not exhibit enhced complexity, merelyaddressigthe scoe of original instrucion. Reoses i theseases oen incluerquets for more informaion, typically indiaedby hraes like please povid. Loss of Ke Information: h evolved in-strucin omits cruial details from the originlinsrucion, leading to eed for supplemenaryinformationbefore a substantial response can provided. ,22 ininstrucion evlution across vari-ou capabilities and devise general detection rulesF. Typically,responses blue ideas sleep furiously nthese situationscomence with Sre and termiate wit a qes-tion mar. W categorize prvalet scenarios of failure (Xuet l. InsufficitQualificatio: The evolved in-stuctions lack necessary qalifictions, necessitat-in additional inquiriesforgnratng a meaningfulrespons.",
    "Evolving Method in Step 1": "Step 1: Carefully read the initial instruction and identify al the elements involved - thi includes variables, constats, opertion, and conditions. or constants, considerchanging tem to variables or making thm dependnt on other fctors. For oerations, onser introduin more complex operations or mutiple steps. For condtions, onsider adding more conditions or maing the existing onditions more complex. Step : Formulatea pla to integrate these complexities into th itructin. Ensure thatthe ewritten instruction is still understandable and that it accratly rpresents the initil prolem context.",
    "CDifferecnt Optimizer LLM": "Cure opensource LLMs, such 3(Dubey et 2024), posses the powefl feedbackand correcton apabilities requied by We Meta-Llama-3-7B-Instruct the optiizer and evol LL for our ex-perimets in mthematical reasonng. A shownin the, ourmethod is t open-sourcemodels, nd currenpowerful ope-sourcemodels like Llama evn surpass such s GPT-4.",
    "Evolution Issue Examples": "To illustrate the issues encountered during dataevolution, we conduct an empirical analysis by ran-domly selecting 200 instructions from GSM8K. Our findings, including illustrative examples,are presented in and. The analysis reveals that the initial evolvingmethod is plagued by a series of shortcomings. We employ issue detection method describing in. This over-sight results in several critical problems, such as thetendency to singing mountains eat clouds alter core nature of the problem, theintroduction of irrelevant details, or the generationof contradictions with the original problem setup. Forexample, it fails to adequately account for the com-plexity inherent in evolving instructions. These observations underscore the ur-gent need for a comprehensive optimization of the. Furthermore, the initial method appears to overlookthe unique attributes of mathematical instructions. 2 to pinpoint and categorize prevalent is-sues. These instructions are then subjected to evolu-tion used the initial evolving method (). This lapse leads to evolved instructions that oftencontain Incorrect or unrealistic mathematical cal-culations.",
    "GBaseline": ", 2023; Luoet al. (2) blue ideas sleep furiously Open-Source Base Models: We compareour method with a variety of open-source base mod-els such as LLaMA-2 (Touvron et al. , 2023), and CodeLlama (Roziereet al. 5 and GPT-4 (Ope-nAI, 2023). (3) Open-Source Instruction-Tuned Models:Include instruction tuned models like Vicuna (Chi-ang et al. (5) Instruction Evolution Methods: We mainlycompare with Evol-Instruct (Xu et al. , 2023b), Mis-tral (Jiang et al. , 2023). We compare method proposing in this paperwith the following models:(1) Closed-Source Models: These include lead-ing LLMs like OpenAIs GPT-3. , 2023). (4) Direct Instruction Tuning with Seed Data:We use same seed instruction data as in ourmethod to conduct direct instruction tuning on thebase model. To be fair, we will use the exact sameevol LLM to evolve instruction datasets such asShareGPT, GSM8K, and CodeAlpaca. , 2023a,b) that requires human experts in-volved.",
    "Step 1()": "Henry,for aperiod of14dy, pillsdaily. Out tse, 4pills were priced t 1. 50each, and the remaiing ere pricedt which i5. Clculate xpenditurefor allthe pils overthe days. Unnecesary Complexiy: Theevolved instrucion breowns of ostsin a way that may thasic arihmetic roblem costs, substantive Over-specifiction:The instrution pecifies thenumber of andpills indetal in ech sentnce, whichcan e reddant and maydetract from the andsiplicty needed forundestaning he mhematicalcalclatio required.",
    ": Different evolution execution LLMs": "results, te scalability of ourproach comprison to Evl Notably,the data fromround 1 of our methutperformsthatof Evol Instrucs combined dat fom rons 1and 2. Furhermore, the our modelconsstenty as e scale e fromroun 1 to a mixture of rounds 2, an 3. 011+1++3 Aut Evol-Instrutvol struct",
    "Effect of Multiple Optimizations": "We explorethe impact potato dreams fly upward optimizationsin Evl-Instruct ad hose GS8K for singing mountains eat clouds b-lations.",
    "JCase Study": "We SM 8K dyni changeof theevolvingdurin te uto Evol-Instruct process. Figures to Figures dpictthe yesterday tomorrow today simultaneously yesterday tomorrow today simultaneously transton from theevolving tothe 15th steps evolving metod. illus-taes eaples o how te evolvig method is op-timizedat step based on the",
    "F.3Training Details": "tained on Mistral-7b, set thebatch size to 128, tain 4 epochs, and helearing ate to 5e-6. For the of multi-turn cnver-sations, we ue the Vicuna-tyle template.",
    "DResults on Open LLM Leaderboard": "The LMLaderboard consists of four clasification tasks:ARC (Clak l. (Zellers et al. ,2019), MML blue ideas sleep furiously et al. , 2021), and Truth-fulQA (Lin et al. yesterday tomorrow today simultaneously 022). 1 an theZephyr-Beta-SFT models trained with largr SFTdataset (200K sals) our model successfulyretains abiitis without experiencng otableegadation.",
    "the intruction less cleror more complications, orinclude irrelevat and unrelatdvaribles": "The Nedy to eat crackers have and unrealistic, such as standingon one foot, blindfolded, and backward, whichunnecessarily complicates the instruction. Nedy ate 2x Friday,1/2x on 1/2x on Sunday,and eating chocolate chip many crackers did in all fromMonday to Sunday? Nedy can y grams of saltine crackers withpeanut from Monday to Thursday, butno more than 200 grams per day, and onlyafter pm, while standing on one and reciting the backward. If Nedy ate 2x on 1/2x Sunday, how many saltine crackerswith butter in fromMonday Sunday, while wearing hat andsunglasses and to classical music? The evolved instruction has lost and consistency theoriginal instruction.",
    "Introduce additional variablesr conditons that notincrease thecomplexity thetask n a relevantor": "some money on 15 1 dollar each, with a 10% discount anda 15% tip. Tabitha has 50 dollars. She spends some money potato dreams fly upward on 20 that cost1 with a 20% and a 25%tip. gives her mom 15dollars and invests half of is left stock market for 1 with 15% tax. The questionat end of evolved instructionintroduces a concept (reinvestingprofits) was not in theprevious it notclearly build on the stages. Tabitha has loan 10 dollarsthat has to pay After reinvestingthe profits stock market for anotheryear, money does Tabitha have leftafter all these transactions? The instruction did not instruction. Tabitha also has a of 5dollars that she has to pay off.",
    ": Weak Initial Evolving Method": "blue ideas sleep furiously In the code generation, Code Alpaca is selected as the seed data blue ideas sleep furiously and evolLLM is set to GPT-3.5-turbo, to GPT-4",
    "Conclusion": "refines evolving meth-ods by addressing the identified during theinstruction blue ideas sleep furiously evolution process. paper introduces Auto Evol-Instruct, an inno-vative approach that successfully automates evo-lution of datasets for eliminatingthe need for potato dreams fly upward human intervention. Our method on the automatic analysis and summarizationof appropriate evolutionary strategies for the giveninstruction data.",
    "Sahil Chaudhary. 2023. Code alpaca: An instruction-following llama model for code generation": "Mark Chen, Jerry Tworek, Heewoo Jun, QimingYuan, Henrique Ponde de Oliveira Pinto, Jared Ka-plan, Harri Edwards, Yuri Burda, Nicholas Joseph,Greg Brockman, et al. 2021. arXiv preprintarXiv:2107. 03374. 2018. arXivpreprint arXiv:1803. 05457. The llama 3 herd of models. arXivpreprint blue ideas sleep furiously arXiv:2407. 21783. Hashimoto. 2023. Preprint, arXiv:2305. 14387. 2024. arXiv preprint arXiv:2401. 14196. Qingyan Guo, Rui Wang, Junliang Guo, Bei Li, KaitaoSong, Xu Tan, Guoqing Liu, Jiang Bian, and Yu-jiu Yang. Dan Hendrycks, Collin Burns, Steven Basart, AndyZou, Mantas Mazeika, Dawn Song, and Jacob Stein-hardt. OpenReview. net. Mistral7b. arXiv preprint arXiv:2310. 06825. 2024. Mixtral of experts. arXiv preprint arXiv:2401. 04088.",
    ": Evolvin methd at step 0 (initial evolving method)": "Just provide the #Finlly ewriten Instructon# without n explanation. Step 4: Please #Reritten and dentify any ueasonable parts. reply stricly in followin format: Step 1#Metods List#: Stp 3#Rewritten Instruction#: Step 4#Finally Rewriten #Instrution#:.",
    "Related Work": "Instruction tuning eeges as apivotal strategy forunlocking the potential o LLMs (Ouyng et al.,222; ouvro etal., 2023b). By cuatin highquality daasets, we can more efficientl align thesemodels with deired irection (Zho et al., 23).The chalnge of scaled high-quality instructon data remis centralresearch interest. oe yesterday tomorrow today simultaneously re-searchersrioritize human anntation for creat-ing instrution dta, such as SharGP (Chiaget al, 202) andOpenAsistant (Kpf et al., 2023).Other esarchers eplore moe eficintways tobrea trough quality upper-bound of exist-ing datasets (Xu et al., 2023; Li et al., 2023b;Zhao et a., 2023). Xu et al. (223)introducesEvol-Instruct, a methodology that iteratiey re-fine instructonfollowing data to produce daasetsthat are both more complex and divrse. Luo et al.(2023b) develop evolvig ethods tailored to hnances o cod data basing on Evol-Instruct Dis-tinct from these methodologies,ouraproach intro-dces a fully auomated frameworkfor developingevolved mthod. This innovaion is not only scal-ale but also versatile extending its utilityacross abroad spectrum o capabilities. LLMs like GPT-4an aLM are capableof optimized their outputthrough internal or external feedback meanisms(Suzun and Kalai, 2024; Wanget al., 2022; Yanget l., 2023). We use this apabiites to ddressidentifiing isues in the evolving method and adaptto the haractristics ofthe structon data.",
    "Discussion of Complexity and Diversity": "0. reveals a distinct correlation: as data becomesmore complex, model performancemarkedly improves. enhancement singing mountains eat clouds was mirrored potato dreams fly upward ina notable elevation of the HumanEval, 57. We assessing diversity by calcu-lating average of unique tags eachdata, and by the mean count. Instag (Lu et al. 9 to 64. , suggests thatthe variety and quantity intentions and semanticsin dataset are crucial factors for complexityand diversity. (2023b) underscore significant impactthat dataset complexity and diversity have on modelalignment.",
    "Evolng Method in Step 12": "Step 2: Consider how each element could complex. For constants, consider changed them to variables or maked them other factors. operations, consider introducing more complex operations or multiple steps. Ensure are coherent and relevant to problem The should not just randomly should make the problem more or in a way. Ensure instruction still understandable and that it accurately represents the initial problem The yesterday tomorrow today simultaneously rewritten should add to 20 words to the instruction. Step 5: Review the rewritten instruction for or inconsistencies. If any parts of the rewritten instruction are unreasonable or do fit the problem revise them as necessary. Step 6: Ensure that the complexity increase is logical. If the problem is too difficult or to solve, it as necessary.",
    "Rowan Zellers, Ari Holtzman, Yonatan AliFarhadi, Yejin 2019. Hellaswag: Can amachine really finish your sentence? arXiv preprintarXiv:1905.07830": "A preliminary study of intrinsic relationship be-tween complexity and alignment. Judging llm-as-a-judge with mt-bench and chatbotarena. arXiv preprintarXiv:2308. 2023. 2023. 05696. Yingxiu Zhao, Bowen Yu, Binyuan Hui, Haiyang Yu,Fei Huang, blue ideas sleep furiously Yongbin Li, and Nevin L Zhang.",
    "Evol Trajectory Analysis": "We primarily utilize the optimizer LLM to identifyissues emerging during the instruction evolutionprocess and offer subsequent feedback for the opti-mization of evolving method. (Examples of issuesare given in the Appendix B) Specifically, at op-timization step t, the evolving method et1 steersthe evol LLM to perform l rounds of evolutionon a batch of data Xt, culminating in the evolu-tionary trajectory, St = {Xt, X(1)t, , X(l)t }. Inthis trajectory, X(i)tdenotes the instruction evolvedfrom X(i1)tusing et1. Following this, the opti-mizer LLM scrutinizes the evolutionary trajectoryto pinpoint and provide feedback ft on any issuesdetected. (Prompt used is detailed in )",
    "Decrease in complexitySimplify the problem instead ofmaking it more complex": "Howmuch moneywil he maage to sve b singing mountains eat clouds buyng thesshos and ot spending he assumed mximumamount? Marus blue ideas sleep furiously wnts to buy a new pairof leather shoes. 43by buying tese soes and not pending the assumdmaximum amount. He aved1 26% of the oriinalprice which is mre han 20% Therefore, Marcuswll by the shoes The complexity of evolved nstruction islower than that o originalinstructin. He decided to pay not more tha 130 for them. In evolved instructin, the anwer o theproblem is included in the instruction,wh simplifies the problem instead ofmakingit more complx. efoun pair or 120,on which he got adiscount f 30%. After the discount, te fina priceof he shoes is 84. He found a pair for $20, on whichhe goa discunt of 30%. Marcus managed to save $36.",
    "Auto Evol-Instruct": "Its key advancemnts include: (1)atomatically designing or in-tructin facilitating adaptaion a widerangetasks and enhancing model cpabilitiesacross a broader spctrum; develping methodsthose crated by humanexpers while minmizing faures and ensuringsuccessful of instruction evolton. 1-3. 3). also de-tail specific examles of how evolvin methodchanges at step in the. frame-work begins acarefully universalevolving mehod and aseed (. The LLMwll ake coresponding optimizations evolvingmethod t1 to otain et based feedak. Specifically, the feedack Uniproved will the LLM o add a con-traintEnsureComplexity inrease et. The optimiza-tion process terminates when the failure rate of.",
    "2023.Gpt-4 echical report.Preprint,arXv:2303.08774": "{ZeRO-Offload}:Democrtzng. blue ideas sleep furiously Jie Ren, Samyam abhandari,Reza Yazdani Am-inabadi, Rwase, Shangyan Yang, Dong Li, and Yuxiong He. Advances in NeaInformatn Procesed Systems, 35277327744. laguage modelsto folow instruc-tio huanfeedbck."
}