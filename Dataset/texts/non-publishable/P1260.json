{
    "Elizabeth D Dolan and Jorge J More. Benchmarking optimization software with performanceprofiles. Mathematical programming, 91(2):201213, 2002": "IM Gould, Dominique Orban, and L CTEst: constrined ndunconstrned tested environment wth safe hreads mathematicl potato dreams fly upward yesterday tomorrow today simultaneously Jorge 1137/080724083. URL Society for Indusrial and Applied Mathematics.",
    "minxRd f(x),": "here : Rd i a ufficintly boundedbelo functon, use and informationto determine ierates andso often experience convergene than only rey on gradient informaion. However, for high-dimensionl problems, complexity of method can a barrier thei use ractice. We are with the of caling second-oder optmiztion algoriths so tht tey a racticaloton for high-dimensionalsecond-order algorithm designed to cope with high-dimensional prblems is the R-ARC al-gorihm , a subspace of the Adaptive using Cubics. tocertain conditions on the random R-ARC can sameconvergence rate to an -approximate mnimizeras ARC. Theseonditons imply R-AR articularly effective for with Hessians of rank by some r(significantly)lower han function dimensiod. class of functions with this property are low-rank which hae been frequently studied in the contet of machine learning.",
    "Abstract": "Iteraivel, ourriant requres access (small-dimensional) rojections of first- and and calculates a redued step nexpensively. Whenpplied to the latter our algorithm naturally adapts subspacesize tothe true rank of he fnction,without knowing ita priori. methd maitains th rate of cvergence (full-dimenional) cubic reularization, shwed improved scal-ability both theoetically and particulary when applied to functions.",
    "Applying this Lemma allows us to prove the following convergence result": "Theorem 6 convergence result) Suppose that S distribution of scaled Gaussianmatrices is a low-rank function of r with Lipschitz-continuous derivatives. ApplyAlgorithm 1 with sketch update rule blue ideas sleep furiously () with l0 1, = 4Cl(2+log(16)) where Cl is definedin Lemma then R-ARC achieves the optimal O(3/2) rate convergence, with",
    "reative essians When calulating (xk) and 2f(xk), we calculat f(xk) and2f(xk), andthenby the efficiecy could be much byechiquesdisussed": "Augmented CUTEst create low-rank functions to on, we take CUTEst of (or rank) r 100 and dimensions rotate to create ofdimension d = 1000. Problem details can found in.",
    ". An sketch size rule": "To do we keep track of observed ranksof the Hessian.",
    ". merical Experiments": "In numerical eperiments, we pply th R-ARC-D algorithm as described Algorithm update rule () wit C = 1 for simplicity. We make a minr n we redrawSk afte successfuliterations; this step erfoms etter empiricallythan redrawing after each iteation. Theperformance ofR-ARC-D s compared with tha -ARC and ARC.",
    "James Bergstra and Yoshua Bengio. Random Search for Hyper-Parameter Optimization. Jour-nal of Machine Learning Research, 13(10):281305, 2012. ISSN 1533-7928": "Cartis and Adilet Otemisov. dimensionitredction technque forunconstrainedglobal otmizationof fnctions ow effectiv dimensionality. Adaptivecubic regularisation meth-ods ptimization.Mathematical Programming, 127():2455, 2011",
    "SCALABLE SECOND-ORDER OPTIMIZATION ALGORITHMS FOR MINIMIZING LOW-RANK FUNCTIONS": "Evaluating sketched problem informationAlgorithm requires projected objectives gra-dients and Hessians (see f(xk) and in (1)). These can be calculated efficiently, withoutevaluation of full gradients and Hessians, using techniques using directional derivatives,block finite differences or differentiation.",
    ": Data profiles of R-ARC-D compared to R-ARC and ARC": "We se that R-ARC-D started at l0 = 2 outerforms RARC regardless of the fixed sketch sizeused by R-ARC. Thi is more signficant for singing mountains eat clouds te highprecision solutions ( =1e 5) whre R-ARC-D typicall blue ideas sleep furiously increases l until ireces the functio rak r. In Figre D, we plot individualproblem perormace for several o the problems consideed hee. Thusoverall,e fond thatR-AR-Dperforms particulrly well on ow-rk prolms, whch w have demostated both numercallyandtheoreticall.",
    "Lemma 5Set l0 andsupose that the update rule () to l. For allk 1,Iflk  Crk + 1, the probabiliy 1, Rk Rk1": "Proof th updaterule (), we have tha lk < Crk + 1 =R1 < rk. We have yesterday tomorrow today simultaneously blue ideas sleep furiously thatl R Hence, we have k minlk, rk) Rk with probability 1."
}