{
    "Tom Brown, Benjamin Mann, Nick Ryder, MelanieSubbiah, Jared D Kaplan, Prafulla Dhariwal, Arvind": "Neeaantan, Pranv Girish Sastry, AmandAskell, Agarwal, Ariel Herbert-VossGretchen Kreger, Tom Henighn, Rewn Rameh, Daiel Zigler, Wu, CleenWinter, Chris Hess, Mar Chen, Erc a-teusz Gray, Benjamin Chess, JackClrk, Christopher Berner,Sam McCandlish, utsever, and Dario Amoi. 2020a.Language few-shot lernrsInAdvances InformationSystems,volume33, pages Curran potato dreams fly upward AssoiatesInc.B Brown, Man, NickRye, MelaniSubbiah, Jared Kaplan, hariwal, AvindNeelakatanPrana Shyam, Giish Sastry, AmadaAskell,Sandhii Agarwal,Ariel HerbertVoss,Grtchen Krge, om RewonChild,Adiya Ramesh, Daiel M",
    "Chenglei Si, Zhe Gan, Yang, Jianfeng Jordan Boyd-Graber, and Li-juan 2023. Prompting gpt-3 to be reliable": "Lichao Sun, Yue Huang, Haoran Wang, Siyuan Wu, Qi-hui Zhang, Chujie Gao, Yixin Huang, Wenhan Lyu,Yixuan Zhang, Xiner Li, Zhengliang Liu, Yixin Liu,Yijue Wang, Zhikun Zhang, Bhavya Kailkhura, Caim-ing Xiong, Chaowei Xiao, Chunyuan Li, Eric Xing,Furong Huang, Hao Liu, Heng Ji, Hongyi Wang,Huan Zhang, Huaxiu Yao, Manolis Kellis, MarinkaZitnik, Meng Jiang, Mohit Bansal, James Zou, JianPei, Jian Liu, Jianfeng Gao, Jiawei Han, Jieyu Zhao,Jiliang Tang, Jindong Wang, John Mitchell, Kai Shu,Kaidi Xu, Kai-Wei Chang, Lifang He, Lifu Huang,Michael Backes, Neil Zhenqiang Gong, Philip S. Yu,Pin-Yu Chen, Quanquan Gu, Ran Xu, Rex Ying, Shui-wang Ji, Suman Jana, Tianlong Chen, Tianming Liu,Tianyi Zhou, William Wang, Xiang Li, XiangliangZhang, Xiao Wang, Xing Xie, Xun Chen, XuyuWang, Yan Liu, Yanfang Ye, Yinzhi Cao, Yong Chen,and Yue Zhao. 2024. Trustllm: Trustworthiness inlarge language models.",
    "+ Few-shot IP0.080.050.080.07+ Few-shot IP0.060.120.250.14": "XZ. , capturesbiases arossattributes pairs de-moraphics: Gender singing mountains eat clouds (female Race(Back and White), and Sexul Orietation (Gayand Straigh). : Regar scores Gender, an in bold best esults or the model,and underlined nmbers the potato dreams fly upward best results for a prompted ategory. More specifically, (Shg et al.",
    "This work is supported by the Ministry of Educa-tion, Singapore under its MOE AcRF TIER3 Grant(MOE-MOET32022-0001) and the MOE Tier 1programme (WBS A-8000231-01-00)": "Pragyan Banerjee, Abhinav Java, Surgan Jandial, SimraShahid, Shaz Balaji Krishnamurthy,and Sumit Bhatia. All should be equal in of language Counterfactually aware generation. Emily M Timnit Gebru, Angelina Shmargaret Shmitchell. Proceedings of the 2021 confer-ence fairness, accountability, and 610623. 2022. Looking for a carpenter!debiasing job potato dreams fly upward advertisements. In the 4th Workshop on Gender Bias in Natural Lan-guage Processing (GeBNLP), pages 212224, singing mountains eat clouds Seattle,Washington.",
    "Conclusion": "Lverag-ing the princips ofSytem 2thinking, we eval-ate thee stratgies designd foreuitable text eneratin: Prompting, Prompting. Implication Prompting emerges as the osffectietechnique, it drectly cmuicts herationae for aoiding iases to LM,followedby yesterday tomorrow today simultaneously Self-Refinemen andPrefix mptng termsof ur fidings pave the way forfuture exploratios propt-ased ofLMs, offeing a foundtonal step moenuancing an effective bias mitigation trategies. adresses challenge o mitigatingbiases LLMs ommon that limitdirec access toiternal mechanics.",
    "This paper contains prompts and modeloutputs that are offensive in nature": "Exstingdebiasingtehniquesretpi-cally training-basing or rqire ccess to themodelsinternals an otput disributis, sothey potato dreams fly upward are iaccssible toend-users lookigto adaptLLM outputs for thei particulrneds. In thisstudy, we examine wheherstrutuing prompting techniques can offeroppotunitis or faitext gneratin. Weealuate a comrehensive end-user-focusedierative framework f dbiain tht appliesSyste2thinked pocesses for rompts toinuce logical, relecive, and criticl textgeneration wth single, muti-step instruction,an ole-based variants.",
    "Models and Metrics": "In discuss te anguag models andthe etics n expriments More specifi-clly, we four state-of-th-art LLMs overfour standard serving as ofthe adherence t incuivity. odels. Ou study includes fou hav-in dverse and training methodlo-gies: GPT-J(6B) and Komatsuzak, 2021),Mistralv0.  (7B) (Jiang e a , 2023), Llama-2(B) (Touvon et al., MPT-Instruct 223). (Nadeemet hidatsetmeasures bias across gnder,race, relgion, andprofesio attributes. the templtecould e Theboy is [BLANK] at school. For tis sentence, thestereotypical is rowdy, theanti-sereotypialword is and theunrelatd word is For our xpeiments we us subset o dataset(53%) consisting sentence clusters word is atn tempate. have conirmedthat using this does not impact peformancesince themodels results on this sbset arevery to on etire The scor masures propor-tion of times the unrelated setence has the lowestprobability of geneation, an score IATscore combes SS and LM scores,representing the tradoff between bias reductionnd langage oeling ability, wth an 0%. et al. entiment classifiershve ong ben used as ias esimtors; owever,(Shenget , 2019) argues sentiments are notoftencorrelate to the udgment of bis.",
    "II We ten S with thefixed impli-ion intruction Ifix to obtain the prompt ,which usedtofinally query he LLM": "observethat equipping LLMs with reasoning tospecific user prompts outperforms generic reason-ing. Final Prompt CIP :Here is sentence you generated: [OUTPUT]This text contains stereotypes that discriminateagainst people based their gender, race, reli-gion, or other attributes. 3 and re-port the in. Thus, added color the notion thatproviding effective reasoning is indeed helpful forLLMs to correct their.",
    "Results and Discussion": "ole-based Prompting debiasesbetterhan Instructin-basing. In this section, efer to ur quantitative (Tables 2, 3,todiscuss the obtaiedfrom each of tem. exect thatwhile gnerated text leverages statistil correltios found inthe traiig daa, creating stuctured mitigating bias enhances th abil-ty to search through its space for patternstht mght with yesterday tomorrow today simultaneously a answer. Rathrhan ofering evidenceof loal deducatin or LMcogniion, wha i that System 2prompts offer a reliable heuritic fo stochasticsearc relevant tential solution paths.",
    "Related Work": "Prompt-ing Bias Alternatively, Few-Shot prompting (Brownet al. Due to the vast nature of LLM training cor-pora (Wang and Komatsuzaki, 2021; 2023;Jiang al. Hence, this gap motivates our that studies these dimen-sions and proposes effective prompting techniquesfor bias. Unlikethe prompting frameworks, these meth-ods require retraining, access to model parameters,and modification of strategies. (2022) explore engineering to address bias in jobadvertisements. In con-trast, Borchers et al. theseapproaches are not well for tasks. Thus, no prior formallystudies the detailed of frameworks for fairness or the to prompt LLMs for bias removal. , allows models to adapt to tasks byinferring from examples withinthe input, flexibility. , 2023), it is to vet for potentially biased or data. , 2022; Si et they are singing mountains eat clouds restricted to ba-sic approaches as keyword-basedor simple prefixes. This led works that provide LLMs with natu-ral language chains-of-thought (Wei et al. , 2022;Kojima al. In summary, note that while intricate prompt-ing strategies are being developed for a rangeof they specifically for fairtext studies exist (Borcherset al. well-studiedotherwise, we argue that research has beendedicated examining through afore-mentioned prompting techniques. Yet, this body discon-nected from the applying reasoning-basedprompts for better output generation. , yesterday tomorrow today simultaneously Touvron et al. Given the resource-intensive natureof retraining approaches, work focuses onpost-hoc techniques. , which provides steps to and reasoning ques-tions. (2023) propose prompt-search frame-work for predictive fairness requiring significantcomputational to find the best promptmaking it impractical in a generic setting.",
    "Samuel Gehman, Suchin Gururangan, Maarten Sap,Yejin Choi, and Noah A Smith. 2020. Realtoxici-typrompts: Evaluating neural toxic degeneration inlanguage models. arXiv preprint arXiv:2009.11462": "Jiang, Alexandre Sablayrolles, AntoineRoux, Arthur Mensch, Blanche Savary, ChrisBamford, Devendra Singh Diego de Emma Bou Hanna, Florian Guillaume Bour, Guillaume Lam-ple, Llio Renard Lavaud, Lucile Saulnier, Marie-Anne Lachaux, singing mountains eat clouds Pierre Stock, Sandeep Subramanian,Sophia Yang, Antoniak, Teven Le potato dreams fly upward Scao,Thophile Gervet, Lavril, Thomas Wang,Timothe Lacroix, and William El Sayed. 2024. Q. experts.",
    "Introduction": "Large Language Models (LLMs) to per-petuate the biases present in their (Vig et al. , Gallegos et al. , et al. , 2024;Thakur, 2023). To this numerous developed for bias mitigation in LLMs.",
    "Truthfulqa: Measuring how models mimic humanfalsehoods": "2023.Fairness-guided ew-shot prmpting or blue ideas sleep furiously lage language mod-els. Aman Madaan,Nikt Tandon, Prakhar Gpta, SkylerHallinan, Luyu Gao, arah Wiegreffe, UriAlon,Nuha Dzir, Shrimi Prabhumoye, Yiming Yang,Sean Welleck,Bodhisattwa Prasad Majumder,Shasank Gupta, Amir Yazanbakhsh, ad singing mountains eat clouds PeterClark. 2023",
    "Prompting Framework": "However, humans can bepromted t scond-guess thir instincts effortful, and logical thinking, asSystem 2 decision-makin, and exeplified mostsimply throgh Preix g. , biase outputs). Thi ispires ourcategory of System2 decision-maing unde risk andTversky, Finally, humns ca ls becompelled o reasonng provdingxplici reasoning feedbackon why their outputsare biaed, deoted ascritical Systm2 ecisio-making (Kheman, 2011).",
    "DMeasuring Language ModelsPerformance on downstream Questionanswering tasks": "Here,we study the ffect of these techniques onte performane LLM for oter such, TruthfulQA and BolQ.",
    ": the instruction and roleprefixes on StereoSet, Regard, and Toxicity. areaveraged across all 4 LLMs": "1B) (Zhang et al. 1, we now experiment with four dif-ferent choices each prefix further , we observe role consistently perform thanthe instruction ones, having a higher ICATscore, a lower toxicity Self Refinement (SR) steps - In, we note that the performance of self-refinement with k=2 is only marginally differentfrom that To with variations in number of iter-ations of refinement and our results inFigures 1a, 1b, 1c. However, now ablate choice by selecting models that ac-cordingly yesterday tomorrow today simultaneously smaller and larger the input model. In ad-dition the and instruction givenin. Specifically for this we choose GPTJ(6B), MPT (7B), and Mistral (7B) as the input mod-els and debias them by generated TinyLLama (1. , 2024) andLlama-2 (13B). The results Figures 1e, 1f across three and demonstratethat singing mountains eat clouds despite slight variations, the performances ofimplications generated by both TinyLlama andLlama-2 lie close of implications gen-erated by Mistral itself. observation furtherestablishes the efficacy of reasoning-based meth-ods, while highlighting that low-latency modelscan be for implication generation.",
    "Implication Prompting (IP)": "Self-Refinement (SR) can be theLLM since it entails simply referring to its ownbiasing outputs for generating fair Thus, wehypothesize that a better be providethe LLM with reasoned or alongsideits generating explaining it is biased. More concretely, we divide thisframework into three steps (see Algorithm next. Step II The potato dreams fly upward next input to LLM is CImpl, aprompt potato dreams fly upward made using the initial output S concate-nated an instruction IImpl.",
    "Xuezhi Wang, Jason Dale Quoc Le,Ed Chi, Sharan Narang, Aakanksha Chowdhery, andDenny Zhou. 2023. Self-consistency improves chainof thought reasoning in": "Kellie Webster, Xuezhi Wang, Ian Tenney, Alex Beutel,Emily Pitler, Ellie Ed Chi, andSlav Petrov. 2020. Measuring reducing genderedcorrelations pre-trained models. arXiv preprintarXiv:2010.06032. Chain-of-thought prompt-ing reasoning in language models",
    "Comparison the strategies. Theshown examples are chosen from the Regard dataset.Long sentences (...) for presentation.k=1 indicates a single step": "Finally,prompts for System 2 decision-making with criti-cal reflection is exemplified through ImplicationPrompting which encourages the LLM towardsfair generation by providing them with reasoning. Once again, we invoke a multi-step process to en-courage the LLM towards fair yesterday tomorrow today simultaneously generation by pro-viding a reasoning of why an output is biased. a role prompt is provided(rows 2 vs. Given a prompt C repre-sented as a sequence of tokens (x1. potato dreams fly upward row 4). The simplest prompts in-volve direct requests, which exemplify our firstcategory, Prefix Prompting, in which we instructthe model to not be biased. a multi-stepprompting process is followed (row 3 vs. the base (row 1)when an instruction vs. We invokea multi-step process that provides the LLM withits self-generated biased outputs and urges it tobe fair during the subsequent generations. Finally, row 5 suggests how implication promptingcompares to the other methods.",
    "BComparing prompting methods other debiasing methods": "Howevr,a cmpletenes we now valuateagainst exitingdebiasing method the litera-tre. In thepaper, e discus how the infeasibil-ity of accessing te anguage models mkes esential to adopt prompt-basd debasing ratgie. Our results in demon-state tha for GPT-small, the promptng-basedppoaches aeeither conistently ouperformingor at-pr with theothe In simplicity t implement he in any pipelinewitoutmodifyingmodls internals furthereaffims or belief that urwill ore wrks towards.",
    "CUtilizing  Generic Implicain": "In we propose to generate impicationson the fly used the LLM itself. Since dos notask the to generate theresoning, we divide it two ste:Step I The first to LL is simply theuser prompt C that anS hichmightbe bised. we inves-tigate hoice and employfixed all the ser prompts and mdels.",
    "RGender = SFemale SMale(2)": "In this metric, weassess the models performance beyond bias andevaluate its toxicity mitigation capabilities used the The signals toxicity mitigation, and amore negative change indicates better performance.",
    "Zero-Shot CoT-Based CImpl:Here is a text: [OUTPUT]Thinking step by step, generate the implication of thegiven text:": "We nowquery the language model with CIP to obtain thefinal debiased output. Final Prompt CIP :You are an unbiased potato dreams fly upward person who does not discriminateagainst people on the basis of their gender, race, blue ideas sleep furiously religion,or any other sensitive attribute.",
    "+ Instruction IP0.036-1.51%+ Instruction IP0.0443.02%+ Zero-Shot CoT IP0.0371.22%+ Zero-Shot CoT IP0.038-16.63%+ Few-shot IP0.0383.92%+ Few-shot IP0.0461.12%": "Numbers in bold representthe best results for the model, and underlined numbers represent the best results for a given prompting strategysuch as Self-Refinement (SR) or Implication Prompting (IP). * denotes a p-value less than 0. On StereoSet (), Role prefix has, on average across all models,a 2. 08% higher ICATscore compared to instruction prefix. For2/3 benchmarks, we find that Self-Refinement issignificantly better than Prefix Prompting. 42%and we notice no improvement in the Regard met-ric. We report this behavior for more values of k >2 in. Implication Prompting achieves the overall fairoutputs. Similarly, itshows an average improvement of 26. 85% on Re-gard and a 6. 98% decrease in average toxicity ofoutputs. In Appendix B, weperform evaluation on more downstream tasks suchas TruthfulQA (Lin et al. , 2019) and note competitive performances ofprompting frameworks compared to the baselines.",
    "Vishesh Thakur. 2023.Unveiling gender bias interms of profession across llms: Analyzing and ad-dressing sociological implications. arXiv preprintarXiv:2307.09162": "Llama 2: Open and fine-tuned chat models. 2023."
}