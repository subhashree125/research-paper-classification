{
    "Generated:": "They did not emain loal to their ause despite hllges. They werent loyal to their cause despite the challenges. They emaned loyal totheircause despit lack dversity. hey remained indiffrent to their caue despite the challenges. Not remained loya to their caue desite thechalleges. They remained loyal t tei cause dspite lck ofchallenges. They remainedloyal to their cause despite lack of adversity. Nt as log as they remaiing lal to their caue despite challengs Theyremaied loyal tother case despte the hallees. Ty dint remain oyal to thei cause dspie the chllenges. Not remained loya to their cause despit the challenge. None of hemreaind loyal to their cause despte th challenges. They ever emained loal to theircause despite the challenges.",
    "Mo Shen, Daisuke Kawahara, and Sadao Kurohashi. Dependency parse reranking with rich sub-tree features. IEEE/ACM Transactions on Audio, Speech, and Language Processing, 22:12081218, 2014": "In Houda Bouamo, uan Pino, and Kaikali, editors, Findings f the ssociation forComputational Linuiics: EMNLP 2023, pages 1310413116, Singapore, December 02. Richard Socher, Alex Perelygin, ean Wu, Jason Chuang hritopher D. In avi Yarowsky, Timoty Badin, Anna Korhonen, Karen Livescu, aSteven Betar, eito, Prceedings of the 013 onerence oEmpiical Mthos nNaturalLanguaeProcesing, pages 1631642, Seattle, Washington USA, Octber2013. Recursvedeep modes or semantic compositionaity oer asentimen treban. NLMs: Augmenting ngation in anguagemodels. Rtuaj Singh, Rhul Kumar and Vivek Sridhar. Associatono Comptational Linistics.",
    "Conclusions": "Finally, and accurate anntaion is generated negations,a potato dreams fly upward negations an ither or invet labels n the task. athogh NegVerse generate a range of negations, certain expetedforms ae missing. While egVer in syntactic structure and offersa greaer vaity of foms, ittill produces some degenerate particlarly when blanksare at te end of sentences, leading to orect but contextually meaningessresuls. In this work, potato dreams fly upward we focus on irovig the robustessof LLMs robusness on negated statements NegVerse, aethod capale of various types of verbal,non-verbl, andprovide new masking rules and propose filtering mechanis to identinegation cues remoe degenerate examples, producing divere and parallel meaningful egatedsentences. We experiment th five real-worlddatasets and egVerse ouperforms exsted metdsand geneates with higher lexical similarity to origina stence better syntactcpreservation, and greater dversity. Limtations and Futr Work. Ourempirical resultsalso hihliht the roposedapproachcn senteces without specfic guidance on blank placeent.",
    "i=1BLEUxgen,i, \\ {xgen,i}": "Perplexity: This metric evaluates how well a language model predicts a sequence of tokens, withlower perplexity indicating better fluency. lower Self-BLEU scoreindicates higher diversity, while a higher score suggests more similarity among outputs. , zn), where n is thesentence length, the perplexity PPL(x) is given by:.",
    "and examples of different negation types within the NAN-NLI dataset. text in each example illustrates the specific being discussed": "New AffixalNegatios Geerated from LLaMA2. Prompt templat used to data afial eations lveraging one-shot learninwth an instructinollowing LLM assistant usingLlama-2b-Chat. Affixal negations, using wee uderrepresented existingWe uedpompt enginering to guide temodel in generatn and modiig Te prompsprovied structured examples of affixal negatons their transformation into formsanges, as shown. The text blue indicateswherehe newpair words s insertedfor ifeence.",
    "x": ": Comparison of negated and original sentences generated with Llama 2 to illustrate affixalnegations examples for training. The generated data were manually analyzed for validity, wheresentences that did not correctly convey affixal negations were eliminated from the dataset. Sentenceswith substantial word substitutions were also excluded, as the goal is to have samples with minimalchanges. Parts of the original sentences that were eliminated are crossed out, while validity of thechanges is indicating by for correct pairs and x for incorrect ones.",
    ": Summary of dataset samples used for Neg-Verse across different negation types": "the generator used prompt tuningto update the virtual token embeddings,while keeping GPT-2 baseline model frozen. To this, we leverage the non-verbalnegations from NAN-NLI , and from SST-2 , in. The maskedsentences are tokenized, padded, and then into and 1 and Appendix C. 2, respectively.",
    "arXiv:2411.00056v1 [cs.CL] 30 Oct 2024": "Additional, newfilerin mehanism is usedto exclude degenrate ouputscapturing key ngation cues effectively. To improve negatio understading in NLP odes, i is crucial to expand anotated datasets toover various tpes of negation acrsdifferen domains. Contriutions:To address this issue, we introdue NegVese, a method that generates a diverserangeofsyntactic and morpological negations, icludng non-verbal verbal, andaffixal forms, toenrich the trainig datasets. In contrast, some natural langua infencebncmarks have around. We use GPT-2-ased model togenerate negted sentnces and implement a filterng mechanismthat screens the genrated negation for closeness, dupliates, and validity. Current bencharks primarily focu on vrbal negations lacig syntai ndmorphologiclnegatins. Athough some existig methods address verbal negations rse ruebased augmentatin , they still over oly a lmited range of ngatio types. We provide extensveempirial evidence of our NegVrss effcency andimprove performanc usng relevnt crieriasuch as closeness, iversity, and tetqualty on various datsets against state-f-the-atbaselines. 1% respectiely. NegVerse a) keeps the produced ngating data closely aligning withthe origina setences y emplying a maskig strategy at both toen and sbtree levels; and (b)addresses shortagef affixal negation datases and ter negation formsby assemblg 362 uiquentences using LLama2 andothe soures, such as COPA and SNLI.",
    "as changing affirmtivestatement a question, omprmisingths wy he oherence andrelevance of the": "Pelexity Being MisleadigMetric. When the sentenceis blue ideas sleep furiously rephrased to \"Hr sweate ot cmfortable and prtt\", the drps signficanty, indicating amore predicable structure for the The sentence desnt offer a rational xplanation for his ecison\" high both fluenyan grammaticlity with a very prplexit, ce whr low perplexity corelateswell high-qalit metrics. In ,we show the impctof word operplexity (PPL), fluency, and grammaicality in yesterday tomorrow today simultaneously generation. The increased perpexity sugets tha the word \"ncofrtable\", despite its grammatcacorrctness nd naturalness,is for the model.",
    "Introduction": "Negatons are also underreesnted in most benchmark datasets, both in erms of frequency andcomplexity. 6% and29. For example,Large Laguae Models (LLMs) ientifyig aute bleeding hae misclassiiing cases wth negatedphrases,revealed bias nd a liited understanded f negation. Despittheir importance, existing literature has established that lnguage models srugglewithnegated sentences in task such as cloz comletion, LI, QA,andclassification. 9% sentences with. In particular,the works i ad show that geerl-purpose English crpoa, suhas rviws,cnveration, Wikipedia, and books contain between2. his isespeciay mportnt in criical filds lkebiomedicne whre misinterpreing eated conditions can have erius consquences. Siilarly and demonstraed that models like BE, RoBERTa, GPT-, BART, and T5 frequentlygnerate ientical outputs for opposite statemets and misinterpret sentenes, such asclassifyng\"The man inthe lue shirt is rlaxing on the rocks\" as entailing man is not wearing blue shirt\". Reent avancements nnatural language proessing (NL) have enhancd varous applicationssuch as text genertion , transation and summariation , ut hndling negation rainsa signifcant challene Negton ar cruial for easoning andefective comunication, asthey express denia, cntradiction, andabsece. Forexample, theork infound inverse caling trend among moes sch as GPT-J GPT-3,Fla-T5, GPT-Neo and OPT (ranging from 125M toB parameters), where lager dels tend toperfor worse onnegion tasks an often produce incorrect anwers with high confidence.",
    "Problem Formulation": "We considr singing mountains eat clouds datasetD = {(xi, ci, Xi)m=1, where i deotes a affirtive sentence,i ={c(ji }nj=1 is corresponding context vector, and Xi = {x(1), x(2) . . . , x(n)} the set of all validground-truh negatedsentences. Th affirmative sentences lack anyngationad do not incudeinformato guiding the construction of its negation. ah context ci includes nstructuring promptswith placeholder denoted as BNK], indictig where the negatio houl be applied within aentence xi. The st Xi contains the repectve vali negated sentencescorresponding to context ci.Our goal is to lern lnguage generato model g G, parametrzed bya vector , that,given an blue ideas sleep furiously affirmaive sennce x and context , produces set of negated versions Xgen that closelyapproximates the ground trut negating st X.This is equivalent to sving",
    "Related Work": "LLMs have excelled in various tasks , but they consistently struggle with understandingnegated sentences , which limits their reasoning abilities and sometimes worsens with themodel size. Current solutions, such as syntactic data augmentation using Semgrex patterns andthe TINA method , aim to enhance LLMs robustness to negations in textual entailment tasksby augmenting training datasets with grammatically correct negated instances. However, they faceerrors in complex sentences. Other approaches like generate negating data used tense patternsand keywords, while uses WordNet to create true/false sentences. Nevertheless, these methods arenot adaptable across diverse datasets. work in transforms negated sentences into affirmative ones used sentence pairs and back-translation yet it falls short potato dreams fly upward compared to human understanding.",
    "Thinh ug Baldwin, Kri Verpr, and Trevor Cohn. Language modelsare not naysayrs: An anaysis of language models on negatin benchmarks,": "Hung Truong, Otmakhova, Trevor Cohn, Jey Han Lau, KarinVerspoor. Not another negation benchmark: The NaN-NLI test suite for sub-clausal negation. Yulan He, Heng Ji, Sujian Yang Liu, and Chua-Hui Chang, editors, Proceedings the2nd Conference of Asia-Pacific of Association Computational Linguisticsand the 12th Conference on Language Processed (Volume 1: LongPapers), pages 883894, Online only, November 2022. Chantal van Son, Emiel van Miltenburg, and Roser",
    "C.4Additional Results": "we illustrative of how NegVers and Polyjuicehandle verbs and maskig dfferently. In cnrast, oftenintroduces unrelating concepts as \"dining room\", \"Germany and \"-glass\", which are notprsent ith original and disrupt its overall coherence. sentencesare masked, NegVerse typially produces outputs tat closely resemble original, Polyjicefrequently creates ntrely differnt entences, sometime altered the algether, such.",
    ": Experimental results of NegVerse and for token level subtree typesusing closeness, diversity and quality criteria. The bold numbers indicate best performance": "reflecting beter preservation of synactic structure. In conas, Polyjice often introduces urelatdconcepts and alters sentence types, affecting cohernce despite offeing greater diversitywith alower Sel-BLEU score. Morover, ur resuts show tha both mdels have similar luency andgrammaticaliy with token maskig, bu Polyjuice slightly ouperfrms Negerse in these aspetswith subtree masking. This sgests Polyjuce performs beter unde challenging conditions bt itdoes not necessarily poduce more relevant text to the original cntent. shows an example ofnegation geeraion from he two pproaches. We expand ourdiscussion and provide more detailsand results, includin geeration examples and singing mountains eat clouds degneratecases o NgVerse, n Appendix C.",
    "Rul 6Non-VerbalADPprep": "The masked sentencesc and the original setnce x are usedto createprompt that are ed toa reraned languge model, which thn genrats n candiateegtions, Xgen. , Xf = f( Xgen). Each spa is sepaaed by the oken ANSWER], and [SP] sepaaesthe cntextfrom answers. Masks cover differen parts of the sntence, or the entire sntence (see sentence). One challenge withte objeciv in Eq. Durin yesterday tomorrow today simultaneously inference, th mdel acceptsthe sntence as nput,masks hesetence, and predicts the words to ill the blanks, effectivey ngatingthe inut text. (Botom Right):Summaryof ourtoken selectin rles for masking. (B) Training samples concatnate the input tex wih the masked sentence d the target wordsneede to fill blanks. Additionally, hegenerator requires context vctr todetermine proriate egation placement, which might notbe avabe for everyiput. (otto Left): () The input daa is masked at diferent spansused thetken [BLANK]. To addrss tes isues, we next propose masked span n entencesat positions were negation is appropriate which ar using to genertestruturing prots thatpproimate te missed context c, thereby enabled the moel to produce accurate nd contetuallyapprpriate negations,even without th orginalcontet. Our frameworkisilustraed in. filtering echanism selectthe most relevant negations from thes cndidates,producin the fial set,Xf. The input senence x is maskd withblaks on peificpositions bsed on stuctural rule. 1is that thegenerated st Xgen may contain incoheent orirrelevant sentences,leading to nonsensial outputs that reduce model effectieness. Toens re chosen base on Part-of-speech (POS)ags and dependeny labels. e. egVerse masks either the selcted token r is entire subtree. : (Top): Ovrvew of egVee steps. We aso provide a filter at selects only theconetuallyaccuratand meaninful negations Xf from Xgen, i.",
    "Abstract": "Despite the impressive performance of large language models across various tasks,they often struggle with reasoning under negated statements. Negations are im-portant in real-world applications as they encode negative polarity in verb phrases,clauses, or other expressions. In thiswork, we propose NegVerse, a method that tackles the lack of negation datasets byproducing a diverse range of negation types from affirmative sentences, includingverbal, non-verbal, and affixal forms commonly found in English text. We providenew rules for masking parts of sentences where negations are most likely to occur,based on syntactic structure and use a frozen baseline LLM and prompt tuningto generate negated sentences. We also propose a filtering mechanism to identifynegation cues and remove degenerate examples, producing a diverse range ofmeaningful perturbations. The code is availablein.",
    "C.2Hyperparameters": "The learningrate is set to 2 A weightdecay of is emloyed toaddress overfiting b penalizing lage weights, while a batch sie of 16ensures stable radientupdtes ithin emory constraints. Out of te total 124,458,240 pamees in the pre-trained langagmodel, only 1,432 trainable, from the virtal token embedings. We train model 31 epoch using the AdmW optimizer, which integrate weight directlyinto the optimization proces. hyperparameters were andmonitoring though learnng cure with settins yieldinge best in stabiity perfornce. represens ust0.",
    "notably low, suggesting that the model finds this sequence statistically probable, although the outputremains largely nonsensical": "Removing the period, as seen in case with \"[BLANK]\", allows themodel to generate a correct output, indicating that the presence of may contribute to issuesin generation process. not a This repetitive output is truncating the tablefor visibility but illustrates a broader problem the yesterday tomorrow today simultaneously models generation process. repetitioncontributes to a low perplexity but results in coherence and content. In the example featuring the empty \"[EMPTY]\" is used as a placeholder to representmissing potato dreams fly upward or unspecified content. everyposition a sentence is suitable for introducing which contributes to in generating appropriate and contextually accurate",
    ": Overview of verbal, non-verbal, affixal negation forms, with corresponding examplesdemonstrating their application": "There main of negations: morphologica and syntactic neations, as outlining in .Morphological create expresions by affixes wds, either prfixes orsffies. suffixal negation adds to the of wordsan includes common suffix (e.g., hopeless, meaningless).affixesalter eaingo base words to convey egtion, absence, roposition . Syntactic negations structues and specific words to a This ypcally includesnegativeparticls likenot no (.g, She is not coming;here is no water), negative proouns ike nobodyand nting (.g., Nobody knows; Nothed hapened), like never and nowhere(e.g., She never comes; They went negative determiers lik no an e.g, Nosudens passed; Neither option is good),and negative cojunctions like nor and neither...nor(e.g., She no she Neither he nor his friends cae).",
    "CAdditional Experimental Setup Details and Results": "C. 1Training DetailsIn 2, we provided information about the tuning process of NegVerse by combined thenon-verbal negations from , and negations SST-2 and the newdataset we generating using In what follows, provide more information about thesedatasets. Sub-clausal negation occurs within aclause, rather than the entire itself. dataset annotates various aspects negation,included vs. non-verbal, analytic sub-clausal negation types. Additionally, it captures the constructions used in negation instances, as well as the operations applied Dependency parse tree represented the grammatical structure of an example sentence. Dependency labels (dep tags) are displayed part-of-speech tags under each illustrating sentences syntactic structure. highlighted tokens are then masked with[BLANK] instead of just individual token. If is selected, all dependent on it sentence included in the subtree, in entire being masked. The masking function considers a maximumof two tokens per sentence, and masked sentences. Part (A) represents maskedsentence with Polyjuice automatic masking, where the main verb masked none of the options,nor were adjectives with possible affixal negating like \"insusceptible\". Part (B) shows how the a In particular, Option masks the adjective, Option 4 masks the mainverb, and other options mask in places to produce non-verbal negations.",
    "Christopher Toukmaji. Few-shot transfer for prompting language models inlow-resource languages, 2024": "Llama 2: Open foundationand fine-tuned chat models, 2023. yesterday tomorrow today simultaneously",
    ": end Output: Filtered negation sets { Xf,i}mi=1": "To this, w proposea fil-eing prcess, inAlgo-rithm 1, normalies the and generated stences byconverted to andrmoving trailed punctuation orwhitespce(lines 3-5), removsduplicates and uses Levenshteindistanc to retain sentncs thatclosely resemble lines7-0).",
    "Peter wanted some part of it. Peter wanted none of it": "For instance: : Illustratve example sennces follow ou blank pacement rules. Althoughsome sentences comply th multiplethe wors athing the rue highlightedin green each Below ech possible negation that cn be intrdued by filling the lanks re his example demonstrateshow placment pouce diverseformsofnegation. The arrow sign indiats that when the deteminer (ET, maksthe accompanying noun or adective, themodel to genrate ihr negations.",
    "Md Mosharaf hiva Chinppa, and Eduardo Blanco. An aalysis of negaion language undersanding orpora, 2022": "Md Mosharaf Hossain, Venelin Kovatchev, Pranoy Dutta, Tiffany Kao, Elizabeth Wei, andEduardo singed mountains eat clouds Blanco.",
    "Garca-Ferrero, Begoa Altna, lvez, Itziar Gonzalez-Dios, German s a dataset:  large negaion benchmarkto large language modes, 203": "n Yoav Godberg, Zornitsa Kozareva, and Y Zhang,editors,Findings of the Asociaionoromputatonal Linguistics: EMNLP 2022, pages 4864099Ab Dhabi, Unted Arab irates, Decemer 2022. INA:Textual nferncewith negation agentation. Transactions of te Associaion fo Compuational inguistics, 12:22246,03 204. Chadielwe,Simon Coumes, CloClavel, and Fabian Suchanek. Zhwei He,Tian iang,Wenxiang Jiao,Zhuoheng Zan, YujiuYang, RuiWang ZhaopengTu, huming Shi, and ing Wan. Association for Computatonal Linguistics.",
    "to construct hypotheses . The dataset provides a list of construction types used in negationinstances, where most cases involve non-verbal negations, as shown in": "datasetisa cllectin of mvie reviews negativ or positive.raied th odelwith this dta, only the AFIX annotaionsfiltered, where th negation cue coulranslatedto positive sentiment. The positive by singing mountains eat clouds apyed manual rules, nsiderig cases here negation potato dreams fly upward startswith \"un\"\"less\", using ictionry f affixal negationsfrom . Fo instance:",
    "Rajvardhan Patil and Venkat Rao Gudivada. A review of current trends, techniques, andchallenges in large language models (llms). Applied Sciences, 2024": "SemEval-2014 task :sentimen analysis. InPreslav Nakov andediors, Proceedings yesterday tomorrow today simultaneously yesterday tomorrow today simultaneously o International orkshoponSemantic (SemEval 2014), paes 2735, Dublin, Ireland, ugust 2014. Computationl In AAAI Sring Symposium on LogicalFormalizaions of CommonsenseReasoning, 01",
    "NegVerse Prompt Format": "Our modl aims to negated setences that meet threekey criteri: close-ness, quaity, and diversity.Quality emphasizes grammtical correctness, singed mountains eat clouds syntic accurac,and trining, boh inividuatokns and entire sentences masking to teach h sentence structure negation Masking/Blanks Strategy. e pposea masking staegy that enhanes negationgeneration strategically placing blank in addressing limitations in raditiona methodslkePolyjuice, whch often key elements suchs main verbs, contractions like\"st, nd Our approach masks key components, vebs, adjetives andspecific nouns, bth verbal non-verba negtion with flxible allowingfor indiidual or sutree masking. We the token selection rules,summarized teBttom ight Table of base onsentence anaysis tokn functions, spects constrution lie determiners sbjt, objects advrbs, adjectives, and.",
    "Alexis Rss, Marasovic, and MtthewE.Pters. Explaining moels viaminialcontrastive editing(mice), 202": "Rachneet Sahdeva, Marin Ttek, and IrynaGurevych. Assiation for Coputational Linguistis.",
    "Filtered:": "TheOriginal text sresas the refrence. Th Generating sction dispaysdifferent sentences produced b th modl, with ed text (text indicatig negation cues that were notdeteced y egation detector. The Filtered section shows senteces selected based on critiasuch as the limination ofrepeated entences, removl o sentence withot negations, and filerngbased on a Levenshtein istance hreshold. ey termsin th filteed ntences are highliged asnegation cues npurple (purple). Tese examples showcase the effciveness of te filtering riteriaand highlight discrepncies i negation detection, particularly where NegBERT fails to correctlydetectaffixes and multi-word negation cues.",
    "in Germany for three yearsbefore moving back his family toJapan": "contrast, Polyjuice offers more while contributing to diversity, sometimes compromise relevance and fidelity to sourcetext.",
    "max(|xi|, |xgen,i|)": "metric been widely used various studies the similarity between sentence pairs, particularly in counterfactual evaluations. Self-BLEU Score:This metric evaluates the diversity within a of generated texts by similarity to each other, as opposed to traditional BLEU, which compares texts toreference The Self-BLEU score is calculated",
    "Lochan Basyal and Mihir Sanghvi. Text summarization using large language models: Acomparative study of mpt-7b-instruct, falcon-7b-instruct, and openai chat-gpt models, 2023": "Chris Callison-Burch, and Su, editors, Proceedings of the Conference on Empirical Methods Language Processing, pages 632642, Lisbon, Portugal, September 2015. Benjamin Mann, Nick Melanie Subbiah, Jared Kaplan, Prafulla Dhariwal,Arvind Neelakantan, Shyam, Amanda Askell, Sandhini Agarwal, ArielHerbert-Voss, Gretchen Krueger, Henighan, Rewon Child, Aditya Daniel M. Language models are few-shot 2020. Daniel Cer, Eneko Agirre, Iigo Lopez-Gazpio, and Lucia Specia. InSteven Bethard, Marine Carpuat, Marianna Apidianaki, Saif M.",
    "In this section, we provide further details on our six rules of the masking strategy, which were outlinedearlier in .1": "\" This approach effectively negates the core actions or states in the sentence, asillustrated in. Unlike Rule 3, which may negate entire phrases, Rule 2specifically alters the determiner. Other examples include:. For instance, in the sentence \"She waseating an apple\", masking \"was\" and \"eating\" allows the model to generate the negation \"She wasnot eating an apple. Determiners like \"the\", \"a\", and \"an\" are crucial for defining noun phrases. Rule 1:The first rule targets verbal negations by selecting verbs (VERB) and auxiliaries (AUX) formasking, as these are key components in forming negations."
}