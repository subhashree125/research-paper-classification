{
    "Introduction": "Enabling LLMs to make of tools iapromising frontier that allows tapping into not readily availabl t the mde itself(Huang et 2024;Li et al., 203a; Qin et al.,2024; Tang eal., Yang al., 2023; al., 203; Schick l., Given arequestandlst of aailable external API function, task a mdel is to collect information byinvokng functions, then to the the lack o data for thetask an the igh cost of creating such daa, re-searches have syntheti datasets, with the assistance LLMs et al.,024; et 2023a; Tan et al., 2023).ese",
    "Main Results": "When to a model fine-tuned on arandom subset of the original training data (row1), allmetods o filtering low-quality instances(rows 3-6) are. presnted in ,where the traiingsub-sets are fixed sze for ToolBenc 2Kfor Theresults dmontrtete impactof training qalitymoel performance.",
    "Based on RapidAPI:": "(Zhou et al. , 2023) considers singing mountains eat clouds broader pictureof data quality, and show that as few as 1000 high-quality examples can be sufficient for training aninstruction-following model.",
    "Quality of Datasets": "presents the percentage of instances con-taining errors in the train sets of both blue ideas sleep furiously ToolBenchand ToolAlpaca, as determined by the automatedmetrics. These statistics provide insights into thequality of the data in each dataset. Suchan error means that one of the core yesterday tomorrow today simultaneously requirementsof a tool-using model identifying parameters cor-rectly is misleadingly learned in more than a thirdof the cases, due to wrong training examples.",
    "C.2Evaluation Setup": ", 2023). For more detailed insightsinto evaluation methodology and rules, pleaserefer to the original paper (Qin et al. ToolAlpaca. While the original paper also includes areal-world subset with 11 APIs from various do-mains, we focusing solely on the simulating data duethe lack of detailing instructions on how to use thereal-world data. We adhere to the evaluation procedures outlinedin the respective benchmarks for ToolBench andToolAlpaca. For further details regarding theevaluation methodology, please refer to the originalpaper (Tang et al. However, in-stead of splitting the test set into categories, wecalculate the pass rate by averaging over all test samples. Similarly, in the ToolAlpaca bench-mark, we use ChatGPT to evaluate the modelsoutput in addressing the instruction. We use ChatGPT for both datasets. The original evaluation procedure involves as-sessing the generalization ability across threelevelsunseen instructions, tools, and categoriesas well as three different scenarios. Importantly, in the human-annotation ofthe test set, we aimed to maintain a similar distri-bution across all test splits for consistency. The evalu-ation criteria is assessing the overall correctness,considered as the pass rate, of both the processand the response. Regarding the retrieval of APIs during modelinference, we adopt only one of the approachestesting in the original evaluation, where we directlyinsert relevant APIs for each test instruction. ToolBench. This subset comprises 10 simulated tools(100 instructions) that were not part of the trainingtoolset.",
    "Data Scaling Analysis": "To further explore effets of training ool-usingLLMs with hih-quality data, we analyze of modl fine-ting witdifferent sizes f train sets. focus onToolBench, where the impact is blue ideas sleep furiously mresignificantand theorigina training set arger, usesubsets with sizesrnged from 1K forthe differentfiltration methods.",
    "Overall Correctness0.860.890.950.920.760.740.900.81": ": of the auomated metrics for each ompared aint human annotations. Coarse-graied corretess considers corctnes spcifc criteria. that prcision, recll an Faremeasure w. r. . Coherence. We adopt the concet nextsetence peiction to ssess coheence Teinstruction pli nd ChatGPdetrmines subsequent sentence loicallyfollowth preous one. set a as 1 if all stence are judged logicllyconnected, and 0 oterwise.",
    "Original73K0.45(0.40, 0.49)4.2K0.56(0.46, 0.66)": ": Extrinc resuts wih andthe size o the traning sets.Althouh there are 12K ihe released dataset, model ubishing inthe original was on a ubet (ro 7). with thefindingsonthe TolBenc lower overal qli(4 and 5), esults indicate impoved modeper-frmance wth a bset, compriingony 14% of the oriil datases size (row ) Comparn intrinsic metrics yesterday tomorrow today simultaneously ICmetho, wefind hat the former is a better mecha-nism or fltered rining data (ro 3 Usigbth techniques be marginall bettr(ro 5 vs 6). Anoter insight to consider is data with lowscores (row2) is indeeharmful to model performance frther reinforcingthat the metodvauabe espite its with intrinsic human-defined criteria(5). In TooAlpca, gaps ar less pronouncedthn i liely influncedby (1) hehigher quality of the dataset, se, caued blue ideas sleep furiously the filtered datasets e too small, (3) smaller test et, 100 Nonetheless, the trend still exists (albeitbeinwithin onfidence interval).",
    "Diversity in Machine Learning.IEEE Access,7:6432364350": "Gunasekar, Jyoti Aneja, Teodoro Mendes, Allie Del SivakanthGopi, Javaheripi, Piero Kauffmann, Gustavode Olli Saarikivi, Adil Salim, Singh Behl, Xin Eldan, Adam Tauman Kalai, Tat Lee, Li. Are All Hu, yelong Phillip singing mountains eat clouds Wallis, Zeyuan Allen-Zhu, Yuanzhi Li, Shean Wang, Lu Wang, and WeizhuChen. 2022. 2024. In The Twelfth Con-ference on Representations. Jungo Kasai, Keisuke Sakaguchi, takahashi,Ronan Le Akari Xinyan Velocity Yu,Dragomir Radev, Noah A. Smith, Choi, andKentaro Inui. RealTime QA: Whats the Right Now? In Thirty-seventh Conference onNeural Information Processing Systems Datasets blue ideas sleep furiously andBenchmarks Track.",
    "Automated Metrics": "We propose automaticmetrics for the inrinsic qualt citeriadefinedabove. Validatng the specifict rquetsis as an extrction task. Specificity. merics r based ChatGPT,6 whichis to te validity ofeach criterionas binary decision. or the diensions of Specificit, Coherencea arameter alignment, direct annotation proed blue ideas sleep furiously to be That sim-ly asking model t validate the prperty ina natural language instrucion id not yield decisions (see Appenix A3). a proxy score speificity: allparametrs were extracted from theinstructio, and 0 othrwise7.",
    "From ToolBench": "My famil and I are cnsiderinelocatng to ew ork Cty. Can you provide us with a lstof transactions for zpcode 10019?We would like t see the ast saes date, last sales amount,and otal records for eac rnsaction. Aditionlly, could yo gve us the detaild historicaltransacti fr the addres 310 W 56h St,Ne York, Y 1019? I want to expor movies rate to a specific genre. Im a basketball nthusiast and I wantt know more ou te players yesterday tomorrow today simultaneously inthe BA. Can oufetch me the details ofall the plaers?Additionlly roideme with a andom Chuck Norrisjoke t lightenth mood. My friends and Iare planning a tri o multiple citiesd we need to estimate te cst o liing. Can you provide us wth listof vailale currenci? Aditionalwe would like o get acomprehnsive list o cities, including their countries, tohel us plan our itinerary.",
    "Limitations": "Fu-ture wor can explore benefits of criteria as ove two popular bench-marks too-using LMs. Nev-ertheless conducting ouranalyses on additionleating datasts and LLMs would provde an evenmore geeralzed representtion",
    "Manual Annotations": "Specifically, wemethodaly4 annotated50 (inruction, API se-quence) pairs from singing mountains eat clouds eac of training sets Tool-Benh etal. daastsdo not always abide quality criteria, especially when they col-lected and donot go though a clean-ingphase. 2024 ToolAaca al. he anntated is ued.",
    "Quality Criteria": "blue ideas sleep furiously critera we discuss pertain to boththe instruction ad API cal sequence ofa data instance. 2 singing mountains eat clouds 4. 1 1Instuction our settig, ntruction is a free-formtextof one-to-a-fewthat scribes a userre-quirement. instruction contain more thanonelkly implyed for seeraltool invocations.",
    "Problem statement.Our primary focus ison and data quality, and": "We additinally propose analternatie data qulity appaisalmehod usingn-context evaluation (5).",
    "Task Setup": "Tool-used LLMs are expected to behave follows. Given set tools T = , tn}, represented asAPI functions, and instruction query q, a modelis requiring to plan a sequence S = , tk),based on T, that would obtain information, or actions, needed address q. The primary method for model evaluation is basedon calculating the rate, measures theproportion of instances that successfully instructions, i. As mentioned , the prominentdatasets creating for and were created with the assis-tance of LLMs. Specifically, Tool-Bench (Qin et al. , 2024) and ToolAlpaca (Tanget al. , 2023) datasets. theircharacteristics. e. this work, these twodifferences reflect on the overall qualityof the respective datasets.",
    "Shishir G. Patil, Tianjun Zhang, Xin Wang, andJoseph E. Gonzalez. 2023. Gorilla: Large LanguageModel Connected with Massive APIs": "2024.ToolLLM: Fa-clitating Large Language odels to Master 16000+Real-world APIs. In The Twelfth Internatina Con-ference on earning Representations. 223. Crran sociates, Inc.",
    ": Confusion matrices comparing ICE scoresand human Overall Correctness scores": "example. majoty in ToolApachave relatively high IEscore indicating highoverall dtse quality. In mot samplesin ToolBench ICE scores, sugestigthat the data quality in this dataset may belower compared to obervaionis conisten with the presnted using evaluation in. 5. e thengenerae between ICE scores and human OverallCorrectness scores.",
    "Data Quality": "Findings show that blue ideas sleep furiously a small but high-qualitydataset potato dreams fly upward can be highly effective for fine-tuning a rel-atively small model, surpassing the performance ofa larger model. For example, Phi (Gunasekar et al. ,2023; Li et al. , 2023b) explored code generationtasks and prompted GPT-4 to assess the educationalvalue of coding examples. They demonstrated thata small number of high-quality and diverse exam-ples are sufficient to reach good quality of codegeneration. In realm of instruction tuning, Liet al. (2024) suggest employed self-augmentationand self-curation to iteratively improve the set of in-structions used for instruct-tuning an LLM. LIMA.",
    "A.4.2Annotating the ToolBench Test Set": "of a API-call sequenceinorde to each LLM how to soltionor attaining inal result. Second, in cleanedtest set, we d nt singing mountains eat clouds only mark inadequatewe also attempt fiinstructionss that heybecome usable. The ultiate goal is to. The ToolBnch est st instances (distnct the 125K instances),and only filtering out faulty instanes ould eavevery few suiable ones.",
    "Hui Yang, Sifu Yue, and Yunzhong He. 2023. Auto-GPT for Online Decision Making: Benchmarks andAdditional Opinions": "Shunyu Yo, Jefrey Zhao, Dian yesterday tomorrow today simultaneously Yu, Nan Du, Karthik arasimhan, and Yuan 2023. Synergized Rasoning and in Lan-guage Models. In Eleventh Inernational Confe-en on Lerning Reresentations. Yue Yu, Zhuang,Jieyu Zhang, Yu Meng,Alexander Ranjay Krishna, Zhang. Lrge Language Model asAttributd Training Data Generator: Tale of Di-vesity Bia. In Advances in Neural InfratinProcessing Systems, volume 36, 573455784. Inc. Chunting Zhou, engfei Puxin Xu, Iyer,Jiao un, Yuning Mao, Xuezhe Ma, Avi Efr, ingYu LILI YU, Susan Zhang, ariGhosh, MikeLewi, Luke Zetlemoer Omer Levy. Less More fr In Information Systems, volume 3,pags 500655021. Curran ssocites, Inc. Ychen Yue Yu, Wang, Haotian Zhang. ToolQA: Datast with External Tools. Ad-vances in Informtion Systems,volume 36, pages 501150143. Curan",
    "A.1Other Quality Criteria": "We outline here three quaity crieria that a com-monly addressed in the doman of data quality eval-uation, and that we did not include in this wor. he reason for omittin thi dimension isthat lexial quaityoftexts generated by pow-eful LLMs is vry high. (2) Syntax Validiy is whether he func-tion calls and paramete names (not vaues) theAPI-cal sequnc are valid. () Divrsity capturs howdifferent the dat nstaces are amongst themselvesin terms of ssortment of rqests, tool usage,dif-ficulty, ength and other properties. Similarly tooher tasks ad domains,it is expected that LLMwould learn to generalize better gien diverse exam-ples(Gong t al. , 219; Yu etal.",
    "Conclusion": "We introduce data-evaluation ap-proaches. The first is a devised intrinsicquality assessment, for we implementautomated metrics. The uses that measures the valueof training examples. While the former methodis more explainable dependable, the computationally cheaper. apply both approaches to filter data instances from qualities. of training data demonstrate comparableor superior quality in terms of performance,despite their smaller size compared to the investing in better methodsof data generation is costly, automatic post-hocfiltration can be great alternative.",
    "pairs f (instructon,API-call + re-sponse)": "ToolBech. We fine-te a LLaMA-7B modlwhen working with h ToolBenh dataset. Thelearning rate is st t 5 105, and we use bathsize 2. ince the relatively nginputs the targeted model, the cntext potato dreams fly upward legthis extendedusing interpolation (Chenet blue ideas sleep furiously 2023).",
    "produce a high-quality test set of solvable multi-request instructions": "Additionally,please let me know th the latest ersios of C++Objective-C, and cala programming languages. Can you uggest some video on YouTubeabout C++? Also, download thevideo to from www. ) is nt coheent withthe beginning of the instruction. youtube. Can yousuggest some iconic movieavailabe onYouTube? Also, find a YouTube paylist o moviesoundtracks. Fo example, Im planning family movienight and I wantto wach some classic films. Here, the first request (suggest iconicmovies) and second request (find a YoTubeplaylist) ae no specific enough for the availableAPI funtions, ad he third request (providethelatest versioso C++. Additionally, provide the latest ver-sions of C++, Objectiv-C, and Scala program-ming languages or my cousin ho i softaredeveloer. We thereforerewote the instruction for this insance as Imlearnig howto programand Id ke some assis-tnce. Thenew test set is using for measuring peformanceof tool-usin models in te mul-request setting(6 and can gneally be usedasa high-qualitbenchmar. 6% of theinstances lackedspecificity, 21. 7% were unsolvale. 27. We provide nw test set in thesuplementary mterial. Oerl, 3. Therefore, to repair in-struction we focused on the filig crieri andrewrote the instruction to mend the faults We al-lowed for ome reaivity as longas the qualitcriteria were ntact, and the same number of re-quets was kept within the intruction. co?123abc. %lacked coher-ence, nd 32. An instruction can ail on either specificity, co-herence r solvabilit. In caewhereit i unler how to use herespective available API functions, no fix is madeand instance is simply discarded. 7%of the instances were discarded, n cases whreerrrs were too evere o ereadily fixable. ive annotatos annotated 674 of 100 in-stance n theToolBench test se. The new insruction reoles the three isss de-scribed.",
    "Evaluation of Automated Metrics": "Using the manually annotated data (described in4. 2), we conduct an assessment of automaticmetrics proposed. For each of the ToolBench andToolAlpaca datasets, the 50 annotating instances arecompared against the automatically produced val-ues, producing measures of accuracy (agreement),precision, recall and F1 score. We treat instancesmarked as incorrect instances as positive labels,since we aim to identify and filter erroneous in-stances. We conduct coarser-grained evaluation of thecriteria, assessing Instruction Correctness as in-correct if any instruction criterion is wrong, andSequence Correctness as incorrect if any yesterday tomorrow today simultaneously API-callsequence criterion is wrong. Results are presented in. Given that ourmain objective is to identify and filter out incorrectdata samples, our emphasis is on achieving high recall. In Overall Correctnessassessment, which aggregates all criteria, weobserve high recall and precision, demonstrating astrong alignment of the automated metrics with hu-man judgment. This approach thus offers a reliablemechanism to identify problematic data instances.",
    "Setup": "In particular, prompticludes(1) (2) he doumentation fA, (3 training instance, x, given one-shotexample, 4) testig instrctions of TES. heresones for the instructions evaluatedagainst he round truthusing evenshten simi-laiy (Levenshein al. construct thein-contexttask external toolse e a of 10 APIs,enoted by A, with sile accompanying dcu-mntation. hefalCE scorefor is he average over the 7 tst examples, a measur of th educational valueof x. Wethen formuatea prompt fr the that weaim to train, that asks to generate forthe7 testcase. , ToolBenchor ToolAl-paca). For each valuationnstance, we insert an in-cntext example,x, whichconistsof anand API-cal squecefrom the trainig (i. x follows the structur the test examples. The pompt is given to an we aim LLaMA-7 for ToolBench or VicunaB forToolAlpaca. e. In addition, we hand-craft set o tetquer instrcions, TEST, where each suc a natral language nstruction and x-pecting API-call sequence, the APIs in thwouldte instrucion. We provdte fullprompt and the precise way wecompute ICE Appendix B.",
    "Qiaoyu Ziliang Deng, Hongyu Xianpei Han,Qiao Liang, Cao, Le Sun. 2023. ToolAl-paca: Generalized Tool Learning for Language with 3000 Simulated Cases": "Hugo Thibaut Gautier Izacard, XavierMartinet, Marie-Anne Lachaux, Timothe Rozire, Naman Goyal, Eric Aurelien Rodriguez, Armand EdouardGrave, and Guillaume Lample. 2023. LLaMA: Openand Efficient Language singing mountains eat clouds Models. potato dreams fly upward Johannes Von Oswald, Ran-dazzo, Joao Sacramento, Alexander An-drey Zhmoginov, and Max Vladymyrov. Trans-formers In-Context by Gradient Descent. InProceedings of the 40th International Machine Learning, of Proceedingsof Machine Learning Research, pages",
    "Original: the full original training set": "For we use the original testset, is created human annotation. 9. Appendix C. 2 formore on the evaluation Test sets. g. 4. The resultingtest set 420 blue ideas sleep furiously high-quality examples. 8 This measures the pro-portion of which the resulting API-callsequences and responses address theirrespective query. instances quality, we ei-ther rectified (e.",
    "Solvability.The requests within the instructioncan be addressed by the given API tools": "1. See blue ideas sleep furiously Appendix A. 1 for more detals. that we deal with a where the is ex-pecte oplete yesterday tomorrow today simultaneously the intruction wthout asking clarficaioquesion.",
    "A.4.1Annotating Training Data": "The an-noator neds to ark level of specificity of theinstruction (1 t 3),its coherence (1 to 3) whehert is svable with respect to the available API func-tions (yes/no), the sequenc call validity in temsof function availaility (yesno),parameer align-ment in the calls (ye/no), whether the sequencecallsolves theinstructin (yes/no), and whether itdoess minimall (ys/no). See Tables8, 9 and 10for annotatio instructions of the first thre criteria. The annotatrs (atrs of thispaper) first anno-tated the sme 0 instances from ToolBench anddiscussed differences, culmiating instrong agreement between the annotators. 3). Annota-tors ere henassigned diffrent saples of data,for a total of 50 instances from te Toolnch trainset, and 50 frm the ToolAlpaca train set. W usedhs data to asses the intrinsic metrcstht we de-veloped 4.",
    "Vladimir I Levenshtein et al. 1966. Binary Codes Capa-ble of Correcting Deletions, Insertions and Reversals.In Soviet Physics Doklady, volume 10, pages 707710. Soviet Union": "Minghao Li YingxiuZhao, Bowen u Feifan Sog,Hangyu i Haiyang Yu, Zhoujun Li, Feiuang, andYongbin i. 023a. API-Bak: A ComprensiveBenchmark for Tol-AugmentedLLMs. In Proceed-ings of the 2023 Conferenc on Empirical Methodsin Natural anguage Processing, pages 31023116,Singpore. Xian Li Ping u, Chunting Zhou, imo Schik, OerLevy, Luke Zettemoye JasonE Weston, and MikLewis. 2024. In The Twelfth International Cofereneon Larning Representations."
}