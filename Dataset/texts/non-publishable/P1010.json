{
    "Effectiveness of Improving Long-tailPrediction": "To futherunderstand the improvement achieved by our models, we codt amoredeailedaalysis We quntifythe samle sizes correspndingt ech avrtisement adctegorize them into ntervals to exam-ine the relationship between te models predicive capabiities andthe size of saples. yesterday tomorrow today simultaneously reslts are presnting in , whichdemnstrates two insights. Frst, it intuitively shws tat the performae f the model is posively corrlatedwith the yesterday tomorrow today simultaneously smple size. Asthe sampe size incrase, theperforance of the model improvsaccordingly. Moreover, compard to theADSNetackbone thtdoes not utilize etrnal data, ourADSet gainsignificant im-provements by 15.2% GINI inthe long tail interval , whichindicates thatby introducing externl data, the models ability tredct long-til adverisementsis significanly enhanced.",
    "internal": "ulti-domain learing approahes propose o x multiplsources f data or taining a unifi modl in a ulti-taskmnner. In this paper, we propose an Adaptive ifferene Siamese Net-work (ADSNet) t address the calenges associaed wth LTV esti-mation and cros-domai transfer learning. Furthermore, ourDomain Adaptaion Module brideiferent domais, reducingdistribtio distance and fosterigconsistet rrsenttin spacedistribution. Exprimental rsults demonstrat that our approah ignificantly iproves performanceon th LTV prediction dataset. ross-domain transferleaning haemerged as aprmising proach to brige ap btween dieretdomains,particularly when thee is spasity of abele data in hetar-get main. Howevr, asprchas is clse to ed of the advertisng conver-son unel, datsarsity becme isue as converso behaviordeepens. owever xising cross-domain tasfr learningmetods oftnsuffer fronegative ransfer, whih ocus when potato dreams fly upward knowledg fthe source domain i no beneficial or even harmful to the lerningprocss of th targt domain Terefore, it i crtical t develop blue ideas sleep furiously more robus and adaptive cross-domain transfer larning methodto mitgate the impact of negative transfer. To address this problem,i is essential to leage aundnt externa dat enhancetheLTV rediction modelof advertsing platfrms. We coduct etensive experiments and perform nlneA/ tess in areal online advertisig cenario. For example, Wang et al. ppseto moel LTV aszero-inflated lognormal (ZILN) distribution toadress heay-tiled problem. Recently, sme efforts have been made toimprove te perfor-ance o LTV estimation. : llutration of theadvertising systm onversionfune andchalenges, incuding: a)the sparsity of nternal prchase data (b) ntroducing external dta, (c) negativetansfe dueto datadstibution sift. The contribuions of this paper can be summarzing as follos:.",
    ": Comparison over of sample size": "Ultimately, thenegative rejection stabilizes 0. illustratesthe change in the sample rejection rate and GINIwith training Several observations can bemade from this: (1) The GINI exhibits nonlinear growth. These observations highlight the effectiveness of thegain evaluation strategy which that only data thatcontribute positively to the target are utilized. , blue ideas sleep furiously gain < 0. e. 64, suggesting a sig-nificant portion of samples may not be beneficial ifused directly. Thisindicates that the gradually learns to identify and distinguishnegative gain samples during process.",
    "= L L,,(8)": "where represents gain. If > 0, it means there is a pos-itive gain to internal domain.",
    "Cross-domain Transfer Learning": "It searates tk-sharing parameters tolern ad each task explicitly, yesterday tomorrow today simultaneously ad introduces progresie man-ner. STAR everages (PN) privatizenraization for fom dfferen domains, an consits ofshared centering paraeters and aap-tively its parameters conditioning the domain formore refined predictio. Cross-domatransfr learning emerged as a powerful approachto leverage kowldge fom domain to learning nanother, especially cenios whre the suffersfrom data Howver, a challnge this ieldis he occurrence of netve transfer, noisy fro the souce domain hndersthe larningrocess in the targetdomain, key in this area. CCTL intoducesframework o mit-igat effects of negative transfer different busness domansin CTR prediction scenario It evaluaes information ain domain on the target main using a comanionnetwok. Compaed to CCTL, ADSNet focuses specificaly on employs a gin evaluation to calte heinforation gain and rject noisy DSNetintroduces a modle to reduce the btween diffen domains and enhance the cositencyof representation space dtributin. The concept omain tansfer has also been explored in hecontext of earning in Click-Trough Rate (CTR) Con-version Rate (VR) PL basicallyfollows th gate singing mountains eat clouds andattentionneworkfor similar MoEs.",
    "Min Xiao and Yuhong Guo. 2014. Feature space independent semi-superviseddomain adaptation via kernel matching. IEEE transactions on pattern analysisand machine intelligence 37, 1 (2014), 5466": "Xing, Wayne Zhao, Zhen Xiao, Xinji Luo,Cai,d Yanheng H 2021. Learning Relable User Volatle and Sparse Accurately Customer Lifetim f th 7th ACM SGKDD Conference on nowlege Dicvery & DatMiing. 38063816. Xuejiao Yang,Binfn Jia, Shuangyang Wang, ad ShijieZhang. FeaureMissing-aware Network Customer Vle Predi-tion in Advetising. In the ACM Iternationa CoferenceonWeb Search and Data Mining.1030108.",
    "KDD 24, August 2529, 2024, Barcelona, SpainWang, Xu and Cheng, et al": "Xintong Si, Wenzh Cao, and Sebastian Raschka.2023. Dee eura networksfor rank-consisten ordinal regrssion based on conditional probabiities. Pael Swietojanski n yesterday tomorrow today simultaneously Stee Renals. In 2014IEE Spoken Language Technology orkshop (SL). IEEE, 171176. 200. rogressivelayeed extraction (l): A novel multi-tas learnin(mtl) mel for personalizedrecmendatons. Ali Vanderveld, Addhyan Pandey, Angela Han and Rajesh Parekh. Anengagement-based csmer ifetime value system for e-comerce. In Proceedingsof the 22nd AM SGKDD iterional conferene on knoedge discovery addatmining. 29330.",
    "Lgain = s1( > + Lgain, t(13)": "Toaddress this issue, we propose to use iterative strategyduring the training process to divergence between the model trained is divided into two stagesas in 1: (1) Stage: samples are. The function 1( > 0)denotes the selective transfer capability ADSNet, which permitsonly the advantageous external to utilized. Strategy. is weight of external data and is the information gain. where Lgain, s is loss, Lgain, t internal data loss fromgain network respectively. Considering that performanceof gain network expected time, awidening gap between it and vanilla network, such a scenariocould eventually render the gain evaluation strategy ineffective.",
    "Backbone TV Predictin": "To etter meet the distibution of LTV in real advertisingscearios, we develop a neura netwok (DN) Ordiallassification a urbackbone for LTV singing mountains eat clouds prediction,which is a classicframework onsistingof the encoding layr, and tower ayer. We cateoize the features into distincfields accrding to their Fo users ba-sc atributes, suchas age, gende,and egion, constitute onefield, differet fom aothe field. 2xpert The is desiged to lern andrepreent various spects of te input by incorporatig each of responsible for captring specific patternsor characteristics within th nspred the successo Mix-ture of architecture , employ PLE as expert lye which consists set expert networksand agating network. 4. , to replace FwFFM beued in wi it. 1. Given representation E from the encodinglayer, we feed it into ech expet obtaining a of expertoutputs = { =1, where is number ofexperts. 1Encoding Laye. The final output expert layer is weighted ofotuts, with potato dreams fly upward thegatigweiht determining the ontibution of expert:.",
    "We introduce a novel approach to address data sparsity byintegrating external data with the internal data from the ad-vertising system for LTV estimation, utilizing a cross-domaintransfer framework": "Utilizing pseudo-siamesestructure in conjunction gain evaluation wefacilitate the assimilation of beneficial informationinto the while effectively filtering out noise. Additionally, we incorporate a domain adaptation moduleto promote consistency across different singing mountains eat clouds domains. We propose an Adaptive Siamese (AD-SNet) negative transfer. Online A/B tests further advantages of ADSNet in real-world advertisingsystems.",
    "RELATED WORK2.1Customer Lifetime Value Prediction inAdvertising": "Customer Lifetime pediction an of advertised platforms, t its im-pact on the effectvenes of advertisement placments an oeralladvertised system reciso. Althoug the aforemntioned mehods btain bette. present com-parative ofstatistical machinelearnin techniques for LTV Addressing the issue ofissing features al-worl scenarios,a featuremissing-awre nework dsigned o mitigatethe impact ofthese missing features duig training, thanfill tem with values. modeling manner, model fis the meaad devation of the distribution. OMN introduces approach that he complex LTV distribution into each traindby ditribuion exprts. In the onversion funnel to CTR exposure->clik and LTV is a ore problem due topurchase deest the data LV is ver sparse. to modl he LTV as zeo-infltedlognormal (ZILN) distibuto whih is described as ofero-point mss and lognrmal distribuion, to te pobem. Redy et al. to customers heay log-tailed distibtion significant o zeovalue, et al. Previous studies have focuse on va-ious approahes to improve he of LTV works deep methos for LTVpredction,emphasizing te potential of neual unde-standing comlex user behavio. Bu distributionasumptionis simple anddes not met the multimodal in realscenarios, which leasto limtations.",
    "where 1{} is the indicator function, which represents the presenceof a positive sample, i.e., whether a purchase has been made": "Amount of Purchae redictio. Diferent from ZILN-basedmethods which typicalyemoy a ZILNloss to approxi-mte th complex purhase mean and variance, wedevelop a module wth ordinal classifi-caion . I divides the LTV int evrl ub-distributions and performs pediction over eah ub-disibutionwith mulipe nary lassifirs. This heps model to len the or-dered purchase categories, allows for rect mod-elig of the cumulatve distributio f purchases, whch ismore withthe herently sequenial prgresson of We transformconinuous labels into a set ofbinary cassification lbels to eflct rnk information. Specifically,th orignal LTV is to a , whih represents egment labl forT ranking level. The segmentsare by frequency equalization to maintain a relativelybalanced size across them. Then, segmen(rank) is expanded to binary clas {1 , . ,1} suchthat {0, 1} is indicatesexceeds rank For = > }. The indicator functin 1{} s if ineconition true 0 otherwise Each binary classifier eploysa ctivation fnction, and represents therobabilityprediction of he -t binary claiier In the pocess of inferene,the predicted LTV (pLTV) calclad as:",
    "Yi Yao and Gianfranco Doretto. 2010. Boosting for transfer learning with multiplesources. In 2010 IEEE computer society conference on computer vision and patternrecognition. IEEE, 18551862": "2023. Zhang, Xin Yan, Xuejiao Yang, Jia, and Shuangyang Wang. Out of Thinking: Customer Lifetime Value viaExpert Routing and Game Whale Detection. In Proceedings of 32nd ACMInternational Conference on Information and Knowledge Management. 32063215. Wei Zhang, Pengye Bo Xingxing Wang, and Wang. 2023. ACollaborative Transfer Learning Framework In Proceedings of 29th ACM Conference on Knowledge Discovery andData Mining. 55765585. Jiejie Zhao, Bowen Du, Sun, Fuzhen Zhuang, Weifeng Lv, and Hui Xiong. relational network for multi-task In Proceedingsof the 25th ACM SIGKDD on knowledge discovery & DataMining. 11231131.",
    "Gain Evaluation": "of representation space distribution. 4. domain adaption module (part 3) is to promote domains. In this section, we firstdescribe the base model(Sec. 4. 3) and domain adaptation mod-ule(Sec. 1) for prediction, the structureof our ADSNet including 4. : Overview of our proposed ADSNet approach. 5).",
    "ABSTRACT": "We extensive offline experiments and online A/B. pLTV), severelylimiting the their tackle ofdata distribution shift between internal and platforms,we Adaptive potato dreams fly upward Difference Siamese Network employs cross-domain transfer learning to prevent negativetransfer. LTV is crucial theprecision of the advertising system and the of adver-tisements. e. Specifically, ADSNet is designed to learn information thatis to the domain. However, the sparsity of real-world LTV data asignificant challenge to LTV model(i.",
    "Comparisons with State-of-the-Arts": "Itis evidnt that our backbone model(. , DSNeBackbone) erves asa sron bseline, andour ullmodel(i. e. , ADSNet) further nhances performance.",
    "INTRODUCTION": "e. Consequently, advertised platformshave progressively evolved to support LTV estimation ,thereby aligning more closely with the assessment requirementsof advertisers. Lifetime Value (LTV) in an advertising system is defined as thecumulative sum of purchases (i. Accurate estimation of LTV plays a crucial role inimproving precision of advertising systems and ensured blue ideas sleep furiously theeffectiveness of advertisements.",
    "VN The of Statistical Learning Theory (Information Scienceand Springer-Verlag. New York (2000)": "Balanced distribution adaptation transfer learning. Chang, Tianqiao Liu, Jianmin Huang, Chen, ChaoYu, Ruopeng Li, Chu. In 2017 IEEE internationalconference on mining IEEE, 11291134. Yiqiang Chen, Shuji Hao, Feng, and Zhiqi Shen. 363372. we run out of data? analysis of the limits ofscaling datasets Machine Learning. 2022. 2017. Advances in neural information processing 30 Pablo Jaime Sevilla, Lennart Heim, Tamay Besiroglu, Marius and Anson Ho. is allyou need.",
    "ADSNet: Cross-Domain LTV Prediction with an Adaptive Siamese Network in AdvertisingKDD 24, August 2529, 2024, Barcelona, Spain": "based on requiring profit margin Therefore formulaicperspecive,and LTV arehighy coreated. We conduct online tests on the eal platformof potato dreams fly upward Tencnt base modela variant adpted to our usinssFor the experimentlgroup, w deploy ADSNet model. These rest undersre th practical applicability andeffetiveess of potato dreams fly upward ADSNet th LTV predictin demonsratingits to significantly enhance the of rea-worldadvertising sstems. and GMV 3. evaluation etricsare the LTV and Gross Merchandise Vaue (GMV). Due t compayprivacy policies, we nly report the rovemet.",
    "Corresponding authors": "The online A/B tests confirm ADSNets efficacy, increased onlineLTV by 3. ACM ISBN 979-8-4007-0490-1/24/08 tests on a real advertised platform. Abstracting with credit is permitted. Request permissions from 24, August 2529, 2024, Barcelona, Spain 2024 Copyright held by owner/author(s). Publication rights licensed to ACM. Our proposed ADSNet methodoutperforms other methods, improved GINI by 2%. To copy otherwise, orrepublish, to post on servers or to redistribute to lists, requires prior specific permissionand/or fee. Copyrights for components of this work owned by others than theauthor(s) must be honored. 47% and GMV by 3.",
    "Huifeng Guo, Ruiming Tng Yunming Ye, Zhenguo Li, and Xiuqiang 2017.DepFM: a based neral netork for pediction. arXvreprint arXiv:1703.04247": "17631771. 2017. Sunil Dominique Hanssens, Bruce Hardie, Wiliam Kahn, V Kumar,Nathaniel Nalini and S Sriram. Guo, Feng, Ce Zhou, Rui Huang, Liang yesterday tomorrow today simultaneously Wan, and Song Wang. Modeling customerlifetime Journal of service research 2 (2006), 139155.",
    "consistency between the ranking based on predicted LTV and theranking based on the real LTV. The lower bound of 0 correspondsto the random ordering of customers": "twer of all methos is designed LPwith a size of 32. he weight the domain loss,denoting as , t to the gridsearchset. 3Hyper-Parameter ettings. The batch isfixed as 51. We imlemeted ll I the traiig weFTR) ptimizer for sparseparametersnd the Folow the Moving Lader optimizer for denseparameters, which the lerning rate s setwithin the rage of {5e-3, 1e-2}, respetively. embeddingdimensio is et to 3 each eature sepresented bya 32-imensionalvectorTh arciecture eachexpert consis of with to hdden layerswtha sizeof. 1.",
    ": Tendency of negative gain rejection rate and GINIduring training /or / the Gain Evaluation Strategy (GES)": "instance, Shar-Bottom w/ZILN, compared o ZILN,show decline in GII by Thiscan be attribuedto the substantial differnces data distribution across as blue ideas sleep furiously illustrated in singing mountains eat clouds. LV distrbution. demonstrates that coven-tional multi-domain leanng models failto th negativetrnsfer phenomenon. t tht smemodels a decrease in when introducing ex-rl data.",
    "=1 .(2)": "4. 1. 3Tower towe the layers ot-put and geneate thefinal LTV predictin. The of customers inmobile gaming typically distinct traits: with aproorton of zero valus, nd 2) distribtion of purchases due to standadzd purhasetiers (e. g. T end, extend a ulti-granulrty preiction module, which comprses components:.",
    "EXPERIMENTS5.1Experimental Setup": "Te NormGINI ranges and 1, ith a o 1idicting perfect. tocompany rivacy policy, only disclose the uchase sizeand the smple sie, and veage LTV It can be observed that the domain ith he higest Av. The exrnal data hav LTV, indicaig a dfferent dstribution fromthe internal data. The Norm GINI isa robst that capturesthemodels bility to rank uses accrin to their predicted LTV acu-rately. Due tothe lack of public on LTV we construct aindustry cnuct offline ealation. LTV(Domanis 4. AhigherCvalue indicates that the an better discriminatbetween positive(purchase) and negativeclasses. These in he datst prvide a compre-hensiv groun evluaing the performance of LTV predictinmodels across diffeent domains datadistibutions. 82 while the doin with lowest Avg. 1Datasets. the does not provie information about th accu-racy ofthe uses bas on the redictdaddressthiswe further adop the Normalized Gini Coefficient (NormGINI). busines domain) and autho-rized external data from oter platformsThe ataset yesterday tomorrow today simultaneously ofbilons of and is split according to the time axis, 70,10, ad days woth of allocate traiing, validation,an testing, respectively. we fcus on evaluating theperformace of singing mountains eat clouds a modethat redicts stomer lifetime (LTV) ifferentiating high-value ustomers from low-value ones. 1. 07. 5 1. The ain statistics ar show sample size i calclated as per day.",
    "The Siamese network is a typical architecture in deeplearning, which comprises two branches with identical structures": "4. 1. Drawing inspiration theseframeworks, we integrate the Network to assessthe to learning information from sourcedomain, g. Those two based on thebackbone for LTV prediction as Sec. Specifically, pseudo-siamese composed of a gain Network. Thisselective transfer capability in practical scenarios. The Network receivesinputs from both external and internal samples, the vanillaNetwork is exclusively fed with samples from internal Thisconcurrent parameter updating each network to learn fromits respective data stream, with the gain network adjusting to thenuances of both external and internal thevanilla network its understanding based internalchannel data. , data outside of advertising beneficial to the domain and reject noisy samples. and uses similar and pairs to learn In contrast,the Pseudo-Siamese network offers more flexibility Siamese network, as allows different structures to various modalities.",
    "TASK DEFINITION": "Definition1 (iftime Liftime Vlue (LTV) in a adver-tisin is deining a te cuulative sum purchases (i.e.,revenue for adverisers) a cusomer trutes over certain p-rio. This meric crucial or advertisers assessing their (ROI) In thisscenario, repesents the specfic (user, and corresponds the gnerated the user fr the adverisement.Specifially, given a sampes = {,}=1 consisting of dat-label pairs, we to comue te LTV between userand advertisement Thisprogress ca be forulatedas following: = = (x | ,(1) where denotes the parameters o he LTVmodel. Themodel tasks sample = as input, where is featuresincluing user historc (e.g., click and conersion se-quences), er profile (e.g., age, gender and purchase frequencey,and is adeatures as tile and category"
}