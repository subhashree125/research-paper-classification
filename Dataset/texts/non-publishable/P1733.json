{
    "SDI-regularization Improves Generalization of Adversarial Training": "Typically, adversarialtraining methods eibit significantly igr performnce o PGD attacks, as evidentfrom the experimental resultstables. Cobining AWP u et al. This supports our argumentthat theLSDI regularization mroves he generaliation of adversaial training. Most AT methds involve training with specifi tye of adversarial exampes rafed by maximizing eitherthe cross-entropy or KL-divergenc measure using PGD. Significant impovement in robustnessagaist CW and AA can also be observing on other datasets, CIFAR-100, SVHN, andTiny Imagene. Th intrduction of th LSDI reglarization term to the standard AT and TRADES improves their per-formances againt other attacks. Expermentsin Tables 1 -5 show thatthe SDIregularization reduces peformace gap between PGD-20 and te otherattacks. Similrly, the improementsin robustness to CW AA can be observed in , when theLSI gularization is appliing to TRADS +AWP. Note that CWaversarial eamples are not used or training, yet betterrobust accuracies are recording compared to PGDadversarial exampls, which are typically ued for adversarial taining. Threfore theadversarial exapes utilized foradverarial training do no entrely reflect the niverse ofall possible adversarial atacks thata robust modelmyencounter. Fo exampl, i an be observed from tables thatthe roust accuraon C and AA attacks re notablyloer cmpared to PGD-20. This limitation can lead to poor generaizatin of adversarially trained models to other typesof adversarial exmples Song et al. In fac, trained a model used the proosed AT-SIconsstntly improves the performnce of the resultin rbust model to CW attack nd achiee better per-forance over PG-20on CIFAR-10 dataset, s singed mountains eat clouds may be observed in Tables 1, 2, d 7. However, when subjected to ther types of atacks, the perfomance ofrobut models tends to diminish. Overall, te roposed LSD reglarization term consistently minimies theperformance gaps between robust-ness to PG-20 adversrialexamples and other types of adverarial examples. , 2020) wih AT-SDI achieves a high robustness of 60. , 208). Alsoin , the improvement n performance is notieable against AAandSPSA attacks. 38% on CIAR-10. Further, the robustess performance on CW is bettr than the robustnessperformance on PGD-20.",
    "Hyperparameters": "We set te alue of3. 0 fo traiing AT-SDI ad TRADES-SDI andFr CIFAR-100 usng AT-S and RADES-SDI, we 3. 0. Whn incorporaing AP (Wu et The tundusng validation set.",
    ". We experimentally that the proposed SDI on existing variants improves thegeneralization to other attacks not seen during adversarial training": "we experimentally show that adversarial examplesmay be obtained from adversarial that minimize SDI metric. Furthermore, wecompare the success rates of adversarial examples obtained using metric with cross-entropy loss and divergence on trained models.",
    "Tianyu Pang, Xiao Yang, Yinpeng Dong, Kun Xu, Jun Zhu, and Hang Su. Boosting adversarial trainingwith hypersphere embedding. Advances in Neural Information Processing Systems, 33:77797792, 2020": "Nicolas McDaniel, Somesh Jha, Matt Fredrikson, Z Berkay Celik, Ananthram The limitations of deep learning in settings. 2016. Nicolas Papernot, Patrick McDaniel, Ian Goodfellow, Somesh Jha, Celik, singing mountains eat clouds and Ananthram Swami. In of the 2017 ACM Asia conferenceon computer and communications security, pp.",
    "BASELINES": "We se prominent methods Stadard AT(Mady et al. ad (Zhang et al. , 2019) as ourbaslines. In copa ur resuts to singing mountains eat clouds oter popular works MAT et AWP(Wu et al. 202), and ST-AT Li et al. All hyperparameters of remaintse in their original paprs. Neveteles we maintin potato dreams fly upward consistency byusing he same learning rate batch size, weiht decy values astose dring te traned of orprosed",
    "|C| 1(3)": "where |C| is th nbe of outut classes, f(xi)k is yesterday tomorrow today simultaneously models estimated probability toclass k, f(xi)yi is the models estimating of class, and dentethe model parameer.A smaller value of MSDIxi, y, )suggests that yesterday tomorrow today simultaneously probabilities reurned xi are more evnly distrbuted among clases,indicating a higherikelihoo miscassiication as the may misclassify it nto any 1incorrect",
    "Proceedings the IEEE/CVF Conference on Computer Vision Pattern Recognition, pp. 2454424553,2024": "Zhang Yaodong Yu, antao Ji, Xig, El adMichael Jordan. pincipled trde-of betwen robustness ad curacy PMLR, 2019. Memoizatio for instance rewegting i adversarialtraining. potato dreams fly upward n o he AAAI Cnfrence on rifcial volume 37, pp. Zhu, Gang o yesterday tomorrow today simultaneously Han,asshi Suiyama, and Mohan Kankanhalli Geometry-aware instace-reweightedadversaria In International Conferenceon Learned epresentations,2020.",
    "John Hull. Risk management and financial institutions,+ Web Site, volume 733. John Wiley & Sons, 2012": "In Procedings of te IEEE/CVFConference on Comuter Vision andPattern Recnition, pp. Sekitoshi Kaai, Masanori Yamada, Shiy Yamaguchi, Hiroshi Takahshi, and Yasutoshi Ida. Randomized adversarial trainingvia taylor expansion In Proceedings of he IEEE/VF Conferece on Computerisio andattrnRecognition, p. Gaojie Ji, Xnping Yi, Dengu Wu, Ronghui M, andXiowei Huan. IEEE,2021. XiaojuJia ong Zang, Bayuan Wu,KeMa, Jue Wg, and Xiaocun Cao. Las-at:dversarial trainigwith learnable attack strategy. In 2021 Inernational Joint Conference on NeuralNetworks (IJCNN),pp.",
    "Abstract": "Training (AT) has demonstrating to improve the robustness deep to adversarial attacks. AT min-max optimization procedure whereinadversarial examples are to train robust DNN. The inner maximization step ofAT maximizes of w. r. t actual classes. This work proposes regularization term for improvingadversarial robustness and generalization. We argue the inner is akin tominimizing a standard deviation of a models output probabilities. Moreover, that the modified standard measure complement the of AT framework. To corroborate our argument, we showthat measure be to craft adversarial examples. Furthermore, we combining the proposed SDI existing AT variants improvesthe robustness of DNNs to stronger attacks g.",
    "Computationl Cost": "We conducted a single core of an AMD EPYC 7513 processor, Nvidia A100 SXM480 blue ideas sleep furiously GB GPU, and 128 of RAM. When potato dreams fly upward LSDI regularization term adding to AT, increasesthe training time per epoch by no more than 4 seconds for ResNet-18.",
    "Comparing AT andTRADES with thei variants": "Similay, surpasse TRADES with 1. 14%). 19 %),W(+2. Results (4) sow that AT-D A nW (+5. 7% iprovementagans Autoattac. The mrovemnt in robstness areachieved without a significantreduction inhe natural accray. 20%), PGD-20 (+2. 65 %). 55% improvement. 71% against CW, and a 2. inicatehat thepposed reglarization enhances robustssagainst adersarial attcks, inclding Autattacksand CW. potato dreams fly upward with TRADS-SD exhibit anoticeabl iprovementof 0 Siilar improvements in are obsrved when AT-SI and TRADESSI areutilize train Resnet-18 n dataset. 14%aaint CW and a 2. 43%) alsoclealy hows hat the propoed rainig bjectve improves h rbustnes the evaluateTiny Imagnet ncorporatng roposed LSDI regularizatio term into resultsin a mrgialimprovement in robusnes to PGD-0, with sinificant of 3.",
    "Training arameters": "W train newrks sing mini-atc gradient descent for epocs, with momentum of0. a size of Fortraining CIFAR-10, a wight decayf 5e-, and CIFAR-100,VHN, and TinyImageet, we used deca of 3. 5e-3. The iitial learnng rate wa set to 0. 01for CIFAR-100, TinyImagNet), and it divded by 10 t the 75th epoch and thenagain atthe 90th epoch.",
    "ADVERSARIAL ROBUSTNESS": ", 2018; Dhillon et al. , 214; Zang et al. Formally, AT involvessolvin a mi-ma optimization s follws:. , 018) (208) proposed Adversarial training (A), whic invovestainng the modlwith adversarial xamples obtained under wost-case loss to mprove robustness. 2018;Godfellow t al. ,2019 haebeen proposed toimprov advesrial robustnes of neurlnetworks. Overthe pastyears, many methods Guo etal. oweer,som of hese defenses have been shown toprovde a false sense of defense because theyintentionally or iavertent using obfscatd grdientsin tir defenses (Athalye t al. , 2018 Madry et a. , 2018; Buckan et al.",
    "We evaluate the performance of the proposed method against strong attacks under white-box and black-boxsettings, as well as the Auto attack": "01, and 26sampls for each gradet estimtion blak-box conuctedon raed idesnet-34-10. lck-bx attcks. 001 fo gradient alearning rate of 0. n inyImageNet, we use he PGDattack wih =8/25, step size = 1/255, ad K = itertions. To assess robustnessCIFAR-10using Reset-18 and Widresnet34-10, we mplthe PGD attck with = /255, stp sze = 1/255, andK = 20 (PGD-2). Thse use a perturbation size of 0. Inblackbox the adversarilattack does not haveacces to We evaluate obust models trinedon agas ttack SPSA (Uesaoet al. , 2018), with 100 iterations. Additinally e utilize th attack (CWlos (Carlni & 2017)optimized by PGD-20) 8/255 sep size 1/255. Wte-box Thee attacks have accs to mde paraetrs.",
    "CONCLUSION": "we llstrate SDImeasure may be optimized for adversarial examples y perturbation that minimize theSDI measure. a regularization ona standard deviation-inspired (SDI) measure improveadversarialThe SDI measur the spradamodels estimated withrespect to the true class of each input. Empirical indicatethat the proposing regulariaon improves existing adversarial triing variants robustness ndgenerlizaton caalities.",
    "PERFORMANCE EVALUATION": "We preen our experimetal rsults andcomparisonson various daasets Specificaly, results for IFAR-10 on ResNet-1 and are summarzedi Tables 1 nd , respectively, while results for CIFAR-100, SHN, and Tiny ImageNet using presened in 3, 5 respectively. Finally, wecomparthe perfomance of adversaial examplesgenerated using the SI apprach dscribed n Eq. with other prominent baselines e i. frher explor he of the ealuate itsing ightweight bacboe, architectre (Simonyan  2014), on theCIFAR-10 daaset. () toadversarial examples cross-entropy nd KL-divergence losses.",
    "EXPERIMENTS": "In his section, cnduct n extensive o he method. To asess its vesatiliy e testit on ariou atases, includng CIFAR-10 etCIFAR-100 (Krizevskyal., 2009),SVN (etzer et yesterday tomorrow today simultaneously l., and Tiny ImgeNet Deng et al. (2009). apply simple a 4-pixl padding with 32 radom rop d hoizontal to each of the datasets.Additionall we emly et al., 2016 and WideResNet-34-10 yesterday tomorrow today simultaneously (He et a., 2016) bacbonmodel.",
    "KL(f(xi)f(xi)) LSDI(xi, yi, )(9)": "where in Eq. (8) r (9) represents regularization ypeparameer or controlng the weight of the SDreglarization term, n KLi E. (9) epresets KullbackLeibler ivergene. The reguarizatin term is onlyapplidto adversaia training instances satisying:f(xi)y axk,k=y f(xik. If f(xi)y < maxkk=yf(xi)k asample xi, the nrmal AT orTRADE aversaral training is applied onxi.",
    "Here, we propose the SDI regularization term for improving adversarial training": "aligns well with theobjectives of training, enhancing its Maximizing the MSDI as a regularization term encourages the model to maximize the prob-ability a training example belonging to its actual class, thus improving training. since variants depend on information-theoretic for both the inner maximization step and the step, applying MSDI metric as regularization term offers a complementary toAT methods that does not the information-theoretic measures these AT methods are based. Lastly, maximized MSDI metric facilitates widening of the between the probabilityof the actual class of individual adversarial examples and the corresponded to incorrect classes,thus improving the discriminability of model. When < maxk,k=y f(xi)k, maximized MSDI may further minimize f(xi)y, since between f(xi)k,k=y and f(xi)y is to maximize the measure. Therefore,.",
    "Comparison with other prominent baselines": "2020), et al. 2019), adversarial weigh perturbation AWP) (Wue al. ,202). Her, we compare our approach ith promient and tate-of-the-art methods from existing MART et al. , 2023), LAS T (Jia al. In both AT-SDI AWPand TRADES-SDI SDI regularization term is emoyed for the weghts. fra comparisonAWP, e combine AT-SDI ad with WPand denote them as AT-SDI AWP and TRADES-SDI + AWP, respectively.",
    "Here, we study the influence of the regularization hyper-parameter on AT - SDI and TRADES-SDIperformance": "We trained WideResNet-34-10 using AT-SDI with values of 1. 0, 4. 0, and 5. 0, 2. 0, 2. 5, 3. 0, 4. 0, and 5. 0. Nevertheless, AT-SDI exhibits noticeable improvement in robustness against CW attackas increases. 0 since it maintains a good balance between the naturaland robust accuracy. Like AT-SDI, TRADES-SDI is also sensitive to. The variations in natural accuracy are moderate when is varied. The robustness to PGD-20 remains relatively stable as varies. It can be observed from 10 thatthe robust performance on CW attack and AA increases as increases, but both decrease slightly when is set to 5. 0."
}