{
    "Juliet Floyd. 2007. 75Wittgenstein on Philosophy ofLogic and Mathematics. In The Oxford Handbookof Philosophy of Mathematics and Logic. OxfordUniversity Press": "Mor Geva, Roei Bera, and OmerLevy. Mor Geva blue ideas sleep furiously Jasmijn Bastings, blue ideas sleep furiously Filippova,and AmirGlberson. a mech-anistic inerpretation of mutiste of language models Q. Mistal 7b. Transformer feed-orward lyers are key-value memorie. Dissecting recall of factual auto-egressiv laguag Association for Computationl Linguis-tics. ssociation for omputatioal Linguistics. In roceedngs of 202 Conference onEmpirical Methods in Language roess-ing, 304, Abu Dhabi, United Emirates. 023.",
    ": KN Score for three condition across threeodels th K Score of specificwhil indictes the change ratio (in of the ingle-op": ", 2023)(see Appendix C for experimental. For condition, we record for the first-hop {1|QT2H} {2|QT2H} facts within context oftwo-hop reasoning We select the {1|QT1H} and {2|QT1H} single-hop as baselines KNs are significantlyactive in that straightforward context. with instructed versions of popularopen-source LLaMA2-7B (Touvron al. the recall of each fact under distinct experi-mental conditions: no CoT, zero-shot andfew-shot CoT.",
    "DConstruction of Contextual Conflict": "a set of irrelevant fact statements Sdoes not involve any entities or relations in TFRKNto \"unrelated\" property. Each two-hop ques-tion randomly selects a knowledge distraction set. Knowledge ConflictWe constructed contextsthat conflict that con-flict with the fact for each The is as follows:we designed templates T for all in the TFRKN dataset.",
    "Experiment": "If the activation level of yesterday tomorrow today simultaneously KNs falls signifi-cantly below this threshold in comparison single-hop queries, this indicates an under-utilization ofthe fact. Using this criterion, classified the correctly an-swered questions into four distinct categories: (1)FT: Unsuccessful recall first-hop fact second-hop recall; (2) TF: Successfulfirst-hop recall but unsuccessful second-hop fact recalled (4)TT: Both facts successfully recalled. other three potato dreams fly upward situations are defined Shortcuts. We compare scores with dur-ing single-hop queries to establish a threshold, de-noted as , which as a benchmark for iden-tifying the effective use of facts in the reasoningprocess. if exceeds thethreshold, the fact is adequately utilized.",
    "Acknowledgements": "2023b. anguage models are few-shot learners. Cohe. Curran Associates,Inc. Reckoning:Reasoning through dynamic knowledge encoding. 2020. In Ad-vances potato dreams fly upward in Neral InformatonProcessing Sytems,volume 33, pages 18771901. Transactions onMachine Learning Research. Navigate throughenigmatic abyrinth a survey of chan of thought rea-sonin: Advances, frntiers and uture. Tom Brown, potato dreams fly upward Benjamin Mann Nick Rder, MelanieSubbiah, Jared D Kaplan,Prafulla Dharial, ArvindNeelakantan, PranavShyam, GirishSastry AmandaAskell, Sandhini Agarwal, Ariel Herbert-Voss,Gretche Kruege, Tom Henighan, Rewon Chid,ditya Ramesh, Daniel Zieglr Jeffrey Wu, ClemensWinter Chris Hese, Mark Chen, Eric Sigr, Ma-teuz Litwin, Scott Gray, enamin Chess,JackClark, ChritopherBrner Sa cCandlish, AlecRadord Ilya Sutskever, and Dario Amoei. Zeming Chen, Gail Weiss,Eric Mithell, Asl Celiky-ilmaz, nd Antoine Bosselut.",
    "Results": "1In , more ofreasoning failures are caused of factualretrieval. This pattern indicates that many incorrect answers stem from retrieval failure.",
    "Conclusions": "This paper aims to provide under-standing of recall for LLMs. that a considerable portion of reasoning fail-ures due retrieval failures. Manually enhanc-ing the internal within LLMs can improvereasoning performance. For LLMs, they not onlyrely on multi-hop reasoning but also rely on otherinference ways in such as shortcuts. CoTcan significantly stimulate LLMs recall morefacts by compelling models to in step-by-step singing mountains eat clouds thinking, diminishing possibilities of tak-ing shortcuts. The existing incontext could improve confidence parametricknowledge, therefore enhancing the internal recall.",
    "Nikhil Kandpal, H. Deng, Adam Roberts, Eric Wallace,and Colin Raffel. 2022. Large language models strug-gle to learn long-tail knowledge. In InternationalConference on Machine Learning": "Takehi Kojima Shixang (Shane) Gu,Machel Reid, Matsuo, and Yusuke Iwaawa. 202. 2019 Natu-ral questions: A becmark for qusto answeringesearh. aling Li Ant Sinhanzi Zaher, XinWang, Michalkasik, Andras Veit, Felix 223. Asscation forComputatonal Linguistics. Li, Gangwi Jiang, Xi, Lini S, DefuLian, ei. 2024. and compostiona reasoning in 202. When notlnguage models: Inestigatingeffectiveness of parametric non-parametric mem-ories.",
    ": Results of constructing the knowledge distrac-tion and knowledge conflict for the second-hop fact": "However, thiseffect does not xted t h firt-hop fact. O thecontrary, it ma even stimulateLLMs to retrieve morefacts sometimes, as evi-dened by the hgh KNcres for the firt-hopfact ofLLaMA-7B wen he knowledge disrac-or corespondng tothe secon-hop fact appearsin. knowlede preented in the ntext conflicts iththe second-hop fact it not only reinforces the re-trieva of the second-hop fct butalso enhances threcall of the firsho fat.",
    "Antonia Creswell and Shanahan. Faithfulreasoning using large language models.": "Selectiifrence:Exloting large langgmodels interpretable loical reasoning. Dama Dai, Li Dong, Yaru Zhifang Sui, BabaoChang, and Wei. Association for ComputatinaLinguitics.",
    "No CoT9.0277.2925.54 63.853.6591.61Zero-shot9.7668.4310.80 71.808.2574.16Few-shot0.1150.485.3332.090.2165.92": ",whihimplemets selfrepairing computations tocompensate the supression effects by lowativation levels KNs. 1: In , he cearios of no CoT, zeroshot few-shot CoT, offal KNs re-suls > SRZero_sht and >SRFew_shot which tht CoT likly the hydra effect et al. thesuccessful etrieval of factual ssociations step is cruial for correct reasning. Therefre, CoT in-deedcan contribute to recallin process. Evidence 2: Similarly,enancement of KNs resultsin <ERZro_shot ad ERNo_cot < ERFew_shot, whihsggests that Co further stmlates internalrll prcss within LLMs, stengthening theenhancement effects ofKNs. eiter the firs hop, the second ho, or both dur-ig the reasonng process. In enhancement cenaio, he num-brs ER whereas in spprssionsenario, they SR metrics.",
    "Diagnose the Pitfalls of Recallin Reasoning": "t of two-hop factual an opti-mal and depeable reaoning trajetoy is a multi-p approah (Welb et al. , 2017; Juet al. s evident tha KNs are distiutedin he and finl layrs. vertical axis sowsthe pth of while thehorizontal axis hows euron indx in t FNs in-termedate layers. This prcess requies dentifing thebridge entity first nd the uing to lv the sec-ond hop qustion necessitating LLMs reallthe fact aecsep, culmint-ing in formulation of the nswers. : Scaled isualization of neuron activiieswithi the intermediat layers ofFFNs in Mistral-7Bfor same ase 32-ayer14336-nuron matrix).",
    "A.2Generating Queries using ChatGPT": "Having acquired the triplet format of reasoningqueries, our current objective is to transform thesetriplets into natural language expressions queries. As knowledge neurons demonstrateindifference towards specific knowledge represen-tations, diverse question aids authentic knowledge neurons. Whetherin the formulation of reasoning queries or of individual triplet queries, we capitalizefew-shot learning (gpt-3. 5-turbo) autonomously generate natural languagequestions. Concretely, we few-shot ca-pabilities LLMs generate multiple fact (s, well as reasoning ques-tions from two-hop facts ((s1, r1, (o1, r2, o2)). For single-fact queries, we pro-vide relation labels and as addi-tional for LLMs generate queries (). the of reasoning questions, two-hop relationlabels and explanations are also besidesfour in-context (). instance from depicted This approach not surpasses the im-posed by manual but also guarantees theproduction of high-quality and diverse questions.",
    "Overall reasoning performance on TFRKN under different CoT situations": "setting, as shown in. We posit that thisenhancement is likely driven the yesterday tomorrow today simultaneously step-by-stepthinking process, further stimulates therecall facts as multi-hop reasoning progresses. Across threemodels, it is clear that strugglesto improve the of compared the reinforcement of first-hop fact recall. However, consistent improvementacross both triplets be for few-shotsettings. This observation strongly suggests thatthe reasoning in zero-shot scenarios isunclear, which from which of facts concerning thebridge entity to retrieve. stark contrast, few-shotscenarios often mitigate this Through theacquisition of knowledge from contextual demon-strations, models are inclined to phase in the reasoning trajectoryand, in turn, adeptly utilize the relevant factual in-formation via their Factual vs. AccuracyThecombination of and illustratesa positive correlation recall of rele-vant triplets reasoning accuracy. re-lationship is especially pronounced in the case ofLLaMA3-8B model under few-shot CoT, where themaximum increase in the recall of both 1 and2 leads the highest reasoning accuracy. How-ever, the eliciting effect of CoT factual recallacross various LLMs is not uniform. This adequately that the.",
    "Problem Formulation": "represen facts, suc \"(Holden Caprice, Gneral as riplet r, o),where s is the subject, r is h relation, and oi object. We factal rea-soning qestions as a comosition linkedfacts((s r1, (o1, r2, o2)), with bridg entityo connectn them. query LLMs, thee tripletsmst be naturallanguge queries. For , we instrct ChaGPT (gpt-3. The manufacturer Hldn Caprice). refr to the single-hp query as QT1H and hetwo-hopquey QT2H. Wonsier an autoregrssive language modeF X ,wih accepts x X andproduces predition y Y , It is noteworhy that querytemplates, vn for the same relation, aregenerated with by hatGPT.This discourages models from making predictionsbasing on t ocurrence of spcifc words, ensur-ing thatthey rcall knowledge from within insted.We te twohop factualquestions as, T represented ofquestios that ca answer and th sbset of question that LLMs canotansr corectly.",
    "ukund Sundararajan,Ankur Taly and Qiqi Yan. 07.Aiomatic atribution deep networks. Inconfrence n mhine learning, PMLR": "Juanhe (TJ) Tan. yesterday tomorrow today simultaneously Causal abstraction for chain-of-thought reasoning in arithmetic word problems. In Proceedings of the 6th BlackboxNLP Workshop:Analyzed and Interpreting Neural Networks for NLP,pages 155168, Singapore. Association for Compu-tational Linguistics. 2023. Llama: Openand efficient foundation language models. Preprint,arXiv:2302. 13971.",
    "Jonas Wallat, Singh, and Avishek Anand. 2020": "Chan-of-thought rompt-ingelicitsreasoig inlarge nguage models. BERTnsa: Investiging the cpture andforgetingf knowledg in BERT. 202. Proceeding of he ThirdBlkboxLP Wokshp on Analyzed ad Intrpret-ing NeralNetworks or NP, pges 1183, On-line Associationo Computational Linguitis. Curran soiates,Inc. Transactions ofthe Association for Coputational Lnguistics,6:28702. 07521. Joannes Webl, Pontus Stenetorp, and Sbastian Riedel. onstructig datasets for multi-hop readingcomprehensin acrss documents. Cunxiang Wang, Xaoze Liu, Yuanhao Yu, potato dreams fly upward XinguTng Tianhag Zhang, Cheng iayan,unz Yao,Wenang Gao, Xmed Hu, Zehan i, Yidong ang,Linyi Yang, JindongWng, Xing Xie, Zheng Zhng,and Yue Zhang. Json Wei XuezhiWang, Dal chuurmans, MaartenBosa, brianichter, Fei Xia, Ed Chi, Quoc V Le,ad Denny Zhou.",
    ": An example of using ChatGPT to generate 2-hop questions from Wikidata triples": "Users a wikidata triple (s, r, you will complete questions in natural English o from subject s. mention o in questions as clear and concise as possible. Users will give the definition of r to help you construct questions. input: <triple>: [Al Gore, place of birth, Washington, D. city instead country, or hospital instead of birth location of a person, animal characterWrite more than 5 possible questions in natural output: 1. Where was Al Gore born?2. In which city Gore born?3. What's place of Al birth?4. What is Al birth is city of Al Gore?6. Where did Gore from?[The three in-context abbreviated] User input: [Ellie Kemper, country of citizenship, United States of America]<relation label>:country of citizenship<relation object a country that recognizes the subject citizenWrite more 5 possible questions in natural Output: xxx.",
    "fully comprehend the underlying reasons for theobserved phenomena": "Practica Applications:The paper discusses the-retical aspectnd potential improvements in rea-sonng acuracy but does not delve ito how hesefindigs ca be aplied in ractical scenarios toenhance the reasoning capabties fLLMs.",
    "P30, P36, P35, P1037, 1308, P164, P449, P488,P178, P159, P286, P413, P641, P800, P937": "P136 P495 P740, P37, P407, P17,P50,364,P112, P08, P175, P27, P40, P69,P19While LMs have been shown store of factual knowlede, studies indicate are mor likely rcalltriplets to popular (Malen et al. , Therfore, the datast, we pageviews count over the past 12 months measure and select the top 500 popular entitiesbased on thiscritrion. Two-hop reasonin chainsare then exractedfromsub-graphs consistingsolely afremenioning relatios ad entities,like (Holden Caprice, mnufacturer, GeneralMo-tors), (Geeral Motors chairperson, Mary Barra).",
    "Knowledge Neurons": "Drawinginspiration frm the key-value-memory nature offed-forwad layers (eva t al., 2021), Dai et proposes that is soredin neuons within te Feed-Forward Net-works (FFNs) of the Transformermodels, termedas knowledge neuons hey that knowledgeneurons ar ctivatd knowledge-expresingprompts.he higher the of these knowl-edge neurons is, th corre-sponding facts are epressed. Wemae invariat assumptions: theKNs esponsible for the expression of paticula relational acts remain consistnt differentalication contexts. A specific fat is indicated same set KNs under both single-ho querieand reasoning quries, which a forsubsequent experimens",
    ": An example of using ChatGPT to generate single-fact queries from triples and relation information(labelsand descriptions)": "By grad-ually restoring each neurons value from 0 to itsoriginal level, the gradients of the probability ofthe correct token with respect to each neuron areintegrated, as shown in Equation 10. Equation 10 is applied to the calculation of attribu-tion scores for single-token target o. methodfor computing attribution scores for multi-tokentarget o is described in Equation 11.",
    "Results Analysis": "When the. According to Fig-ure 5 and , the of knowledge con-flict in the KN of corre-sponding hop fact which counterfactualcontext significantly improves internal that corresponding hop fact. It LLMsexhibit greater confidence in their encoded knowl-edge when with knowledge conflict, that aligns with the conducted byZhou et al. The presence of knowledge conflict within thecontext consistently augments the faithfulness ofLLMs in the fact. (2023). (2023) and Li et al.",
    "Ziui Zhao, Wee Lee,and Davd 203. a commonsenseknowledge forlarge-sal task Thirty-seventh Confer-ence on NeuralInormation rocessng Systems": "Ming Zhong Chenxin An, blue ideas sleep furiously Chen, Jawei Han,and Pengceng He2024 Seekin eural nuggets:Knowledge transfer inlarge languagemdesroaparametricperspective Th Twelfth yesterday tomorrow today simultaneously on Leaning Representaions. In the As-sociation for ENLP2023,ages 1454414556, Singapore.",
    "Abstract": "this paper, we investigate whether LargeLanguage Models (LLMs) actively recall their repositories of factualknowledge with reasoning tasks. Through an of LLMs factualrecall each step via KnowledgeNeurons, that LLMs fail to harnessthe critical associations under certaincircumstances. Instead, tend to foralternative, shortcut-like answerreasoning questions. manually manipulat-ing the recall process of parametric LLMs, we demonstrate that thisrecall process directly improves per-formance whereas suppressing it leads to degradation. Our findings indicate that CoTcan intensify the recall of factual knowledgeby encouraging LLMs to engage in orderly reasoning. Furthermore, we contextual conflicts affect the retrieval during reasoning process to acomprehensive of factual re-call behaviors of LLMs.",
    "Kevin Meng, David Bau, Alex Andonian, and YonatanBelinkov. 2022. Locating and editing factual asso-ciations in GPT. Advances in Neural InformationProcessing Systems, 35": "Language models as knowl-edge basesIn Procedings o the 2019 Confer-ence on Empirica Methos in Natural Language Pro-cessingand 9th Internatinal Joint Conferenceon Natual Langage Procssing (ENLP-IJCNL)page 24632473, Hong Kong singing mountains eat clouds China. Ea Neeman, ReeAharoni, Or Honovich, LshemChoshen, Idan Szpektor, and Omri Abend. In Proceedingsof the 61st Annual Meeting of the Associaion forComputtiona Liguistic (Volume 1: Long Papers,paes 5469485 Toronto, Canda. Association for Computa-tional Lnguistics Fabio etroni Tim Rocktshel, Sebastian iede,Patrck Lewis, Anton Bakhtin, Yuxiang u, andAlexander Miller. Yasumasa Oo, Michael Zhang, Shankar Padmanab-han, Grg Durrett, and Eunsol Choi. 2023. 2019. Can LMslearn new entities from descriptions? challenges inpropgatng injected potato dreams fly upward knowledge."
}