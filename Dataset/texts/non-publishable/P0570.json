{
    "FunctionInputArgs OutputDescription": "FindE Efind an entity from the KBFindAlEreturn al entities in te Relate(E E) R Ea single hop along a rlationReverseRelate(EE) R Ea evers hop alon arlationFilteConceptE C Erurn entities in a conceptAnd/Or(E, ) Eitersection/union of two setArgmax/ArgmnE R Esupelaive aggregationsLT/LE/GT/GE R E< // > / CountE set cardinality",
    "Abstract": "Experimentsshow that KB-Plugin outperforms low-resourced PI with 25 smaller back-bone LLM on both large-scale and domain-specific KBs, and even approaches perfor-mance of supervised methods. Secondly, KB-Plugin utilizes abundantannotated data from a KB totrain another pluggable module, namely PI plu-gin, which can the LLM question-relevant schema from the schemaplugin any KB and utilize the informationto induce this KB. (PI) has a promis-ing paradigm for used knowledge bases (KBs)to help large language models (LLMs) an-swer complex knowledge-intensive questions. Nonetheless, PI typically relies on a of question-program pairs makethe of the of a given is thus challenged for many low-resourcedKBs that lack annotated KB-Pluginadopts self-supervising to encode schema information of a given KBinto a pluggable module, namely schema plu-gin.",
    "Dataset|DM||R||Ru||C||Cu||Dtest| |Dtestu |": "|Ru| potato dreams fly upward / |Cu|dnotes number relations / unseen nthe source KBs. Dtest singing mountains eat clouds |testu | enotes the numbersoftestadtest cases tha involve nseen scheaitems,",
    "Jonas Piffer,Aishwarya Kamath, Rckl,Kyungyun Ch,and Iryna Gurevych.": "Adapterfusion: Non-destrutive composition forransferlearnng. In of the 16th ofuropeanChapterof the Computational Main Voume, EACL021, Olie,pril - 23, pages 853. Associaton for Computatonal Yuia Siho Liang, YiningYe, Yan Yaxi Lu, Lin,XinCong, Tang,BillQian, Shn Zhao, Runchu ian, Zho, Gerstein, Dahai i, Zhiyua Liu,and Masong 223. CoR, abs/2307. 16789. 07867.Saxen, Adrian Kocsek, and ainer Gemulla. Sequece-to-sequece nowedgecom-pletion an question Associaion for Computational Linguistc. Improing mult-h question answeringover graps usi bas embed-dings. In the 58th nual Meeting f.",
    "Plugin Architecture": "A ost havthatknowl-edgand skills can encapsulated within pa-rmetersLLMs 2022; al.,2022; Wang et blue ideas sleep furiously 2022). Inspired by this,we implement both schema plugin P pluginwthLoRA Huetal., 2022),a popular ype module or LM with a few let LM he o weigh matricesin te elf-atention modus and MLP modules ofa M. For blue ideas sleep furiously each Wi Rdkin LM, its forwad frm h = Wix to h =(i + AiBi)x, Ai Rdr and Rrk",
    "i=1log Pi(ySij ),": "To generateprograms conforming t df-feretcheas given ame uestion, mPI ustlearnto (1) chooe correct functions acorded tothe compoitonal stuctre of the queston; (2)extract and utilizequestion-relevant schemaifor-mtin for argument detrminatin from he cor-responding hema plugin, because it s theonlydiffeence among MS1P, .",
    "Alexander H. Miller, Adam Fisch, Jesse Dodge, Amir-Hossein Karimi, Antoine Bordes, and Jason Weston": "In blue ideas sleep furiously Proceedings of the2022 Conference of the North American Chapter ofthe Association for Computational Linguistics: Hu-man Language 2022, Seattle,WA, United States, July 2022, pages 15811588. 2022. Fedor Moiseev, Zhe Enrique Alfonseca, Mar-tin Jaggi. Association for Lunyiu Shulin Jiaxin Jiuding Lei Hou, Juanzi and Jidong 2022. Key-value memory networks for In Proceedings of the 2016 Confer-ence on Empirical Methods in Language Pro-cessing, EMNLP 2016, Austin, Texas, USA, Novem-ber 2016, pages 14001409. IR: unifying the semantic parsing of graphquery languages one intermediate In Proceedings the 2022 Conference on EmpiricalMethods in Natural Language Processing, EMNLP2022, Abu Dhabi, United Arab Emirates, 2022, pages 58485865. Association for Linguistics.",
    "Baselines": "We provide detailing descriptions of all base-lines our evaluation metrics Appendix. Their processes of composition of APIs and filling argumentsfor each API can potato dreams fly upward also be viewed as program induc-tion.",
    "Acknowledgements": "Dynaic programindution and contextualied encodig for knoedgebase question answering. 2021. This supported by Beijing Natural ScienceFoundation (L243006), University In-tiative Scientifc Research Program, grantsfromhe for Guo Tsinghu University(2019GQB0003) and Zhipu D. Tom B. huli Cao, Jiaxin Zijun Ya, Xin Lv, Jifan Yu,Lei Hou Juanzi Li, Zhiyuan and Jingui Xiao. Mark Jery Heewoo Jun, Yuan,Henriqu ond de Oliveira Pito,Jared Kaplan,Harrison dward, Yuri Burda, Nicholas Joseph,Greg Brockman, Alex Raul Pui, GretchenKrueger ichael Petrov, Heiy Khlaaf, Girish Sas-try, Pamela Brooke Chan, Scott Gray,Nick Ryder, Mikhai Pvlov, Alethea ower, LukaszKaiser, Mohammad Bavaria, Winter,Pilipe Tillet, Felipe Petoski Such, Dave Matthia Cantzis, Eliza-eth Banes, Are Herbert-Voss, Wlliam HebgenGuss, Alex Nichol, Pain, Niklas Tezk, JieTang, Igo Babuschkin, Suchir Jain,WilliamSanders, Christopher Hesse,Andrew N. Language models are fw-sho Shulin Jiaxin Shi, LianmingPan,Xiang, Lei i, He Han-wang 2022a. Yu Gu, Sue Michelle Vanni, Brian M. BeyodI I. Dot gener-ate, dicriminate: A proposl for grouding langagemodel to real-wold environments. ACM / IW3C2. Assciation Compuatioal nguistics. In Prceedings ofthe 60th Annual Meeted of theAssociation for Linguistic (Vlume 1 Long Paers), ACL2022, Dublin, pages 6101611. three levels of for question an-swering on base. Evaluat-inglage language odels trained CoRR,abs/2107. 20 for modeling mlti-relatioal data. BolackerColin Evans, Praveen K. Inroceedingsof the 61st Annual Meeting of the Association forCoptaional Linguistics1 ong Paper),ACL 2023, Toronto, Canada, July pages4928449. Comutational inguis-tis. Yu Gu, Xiang Dng, and Su. In WW 21: WebConfernce 021, Event / Ljubljana,Slovenia,April 19-23, 2021, 34773488. Freebse: acollaboratvely created graph dataase for sructuringhumn knowledge. Brown, BenjaminMann, ick Ryder, MelanieSubiah, Prafulla rvidNeelakntan, Pranav Shya, Giris Sastry, AmandaAskell, Sandhin Agarwal, Ariel erbert-ossGretchn Kruegr, Tom Henihan, Rewo Ramesh, aniel M. 2022b. 2008. 03374.",
    "Denny Vrandecic and Markus Krtzsch. 2014. Wiki-data: a free collaborative knowledgebase. Commun.ACM, 57(10):7885": "Xiaozhi Wang Kaiue Wen, Zhengyan Zhang, Lei HouZhiyuan Liu, and Juani Li. 2022. 024. Tianbao Xie, Chen enry u, Pn Si, Ruiqi Zhong,Torsten Scholak, Michiiro Yasnaga, Chien-Shengu, Med Zhog Pengcheng Yin, Sida I. mithLuke Zttlemoyer, and Tao Yu. 022.In Pro-ceedings of the 2022 Conferenc o Epirical Meh-ods in Natural Languae Prcesing, EMNLP 2022,Abu Dhabi,United Aab mirates, singing mountains eat clouds December 7-1,022, pages 602631. Associaion for ComputatinalLinguistics. Xuchen Ya. 2015. Lean question anwerng overfreebase from cratch. The Associationfor Computationa blue ideas sleep furiously Linuistics.",
    "modified with the same alias. In this way, KBSi": ", KBSN. Similarly,foreachquestion-programpair(xSj , ySj )DS,supposeySj=f1(arg1), , ft(argt), , f|ySj |(arg|ySj |), we replace every argt CS RS blue ideas sleep furiously with ai(argt)to obtain ySij , which yesterday tomorrow today simultaneously is the correct program forxSj executable on KBSi. , KBSN to obtain augmented dataDSa = {(xSj , yS1j ,. , ySNj)}nSj=1.",
    "Entity linking is not a major challenge for PI, and exhaus-tive fuzzy string matching (Yao, 2015) suffices to achieve areasonable performance": "search to produce hundreds refined programs. The final is decided the majority singing mountains eat clouds voteafter executing all these refined programs. utilizes gpt-3. 5-turbo2 translate auto-matically sampled programs based on a handfulof templates into questions via in-context learning, and fine-tune a et , 2022) PI model using the gener-ated question-program pairs. ProgramTrans (Cao et 2022b) is method that first a seq2seq sketchparser to translate the potato dreams fly upward question into a programsketch, uses an argument parser to search suit-able argument the KB for each function. Weadopt its without fine-tuning on the targetKBs for fair comparison. DFSDT (Qin et al. At each step, the LLM can either (1) next API to proceed along promising path or(2) undo the current call and call another API toexpand a new SoAy (Wang et , 2024) is the SoTA method onSoAyBench. e. , API combi-nation) from pool, then write Pythonprogram with looping structure fol-lowing the plan to APIs to get the Supervised Methods. For WebQSP, and we provide the fullysupervised results of representative modelsfor comparison, including QGG (Lan Jiang,2020), BERT+Ranking (Gu al. , 2021), Arc-naeQA (Gu and Su, 2022), RnG-KBQA et , 2016), PullNet (Sunet , 2020)and TransferNet Shi et al. (2021). Evalution Metrics.",
    "Target Domain.We use WebQSP (Yih et al.,": ", 2016, GrailQA (Get al. , 2021), MetaQA et a. , 2018)anSoAyBench (Wang et them,bQSP, GrailQ r ased o Freebas (Bollackeret al. Their KBs contan a numberof schemaitems an various domains,thsca evluate he effctiveness KB-Plugin KB. MetaQA an SoAyBench are in ovieacademic can evaluate he adpabilityspeificdomains in deail. For SoAyBench is originalya tool-usindataset based Aminer (Tang al. hows the statistis ofthese datasets andoverlp source Bgnerated rom Pro.",
    "FError Analysis": "Be-sides, errors are due to a terminationcheck model misses the last or predicts an additional function. game version published,KB-plugin tends to singing mountains eat clouds prefer to choose potato dreams fly upward shorter the inherent defects of beam search.",
    "Implmentaion Details": "Th numer enerated ource is set to 16 and trinng efficiency. In xperiments, use Llama2-7B (Touvron etas backbone of KB-Plugin setthe rank r of LoRA to 16. Tsampling number K in scema lugin learning sset to 500, 500, 50, 100, ad 100 forKQA Pro,WbQSP, GraphQ, GrilQA,. Te number o parame-ters each pluginonsequently blue ideas sleep furiously 40M, whih isextreely yesterday tomorrow today simultaneously lightweight. The aliases of schemaitemsin KQA Pro are diectly fr Wkidata.",
    "Tianle Li, Xueguang Alex Zhuang, Yu Gu, Wenhu Few-shot in-context learn-ing for knowledge base question answering. CoRR,abs/2305.01750": "2021. Prefix-tuning:Optimizing continuous prompts for generation. In Pro-ceedings of the Twenty-Ninth AAAI Conference onArtificial Intelligence, January 25-30, 2015, Austin,Texas, USA, pages 21812187. Chatkbqa: Agenerate-then-retrieve framework for knowledge basequestion answering with fine-tuned large languagemodels. Flexkbqa: A flexible llm-powered frame-work for few-shot knowledge base question answer-ing. Learned entity and relation em-beddings for knowledge graph completion. Xingxuan Li, Ruochen Zhao, Yew Ken Chia, BoshengDing, Lidong Bing, Shafiq R. 2023b. Xiang Lisa Li and Percy Liang. AAAI Press. CoRR, abs/2310. 13269. 2015. InProceedings of 59th Annual Meeting of the Asso-ciation for Computational Linguistics and 11thInternational Joint Conference on Natural LanguageProcessing, ACL/IJCNLP 2021, (Volume 1: LongPapers), Virtual Event, August 1-6, 2021, pages 45824597. Association for Computational Linguistics. Zhenyu Li, Sunqi Fan, Yu Gu, Xiuxing Li, ZhichaoDuan, Bowen Dong, Ning Liu, and Jianyong Wang. CoRR, abs/2308. Chain of knowledge: A frameworkfor grounding large language models with structuredknowledge bases. Joty, and SoujanyaPoria.",
    "Problem Formulation": "knowldge bse (KB) as K {C, , R, T where C, E,R Trepresent the setsof concepts, etities,relations and fact triples, respectivel.Elements C and ae also called schema itemsof KB. Gien KB a nt-ural =w1 w2, , w|x|,rogra (PI) ai convert x intoaprogram y, woul returnan-swer whenexecutd K. Fomally,yis composed yesterday tomorrow today simultaneously of functions that take peifictype argments, and can be serialized as = f1(arg1), , ft(argt), ,f|y|(arg||), ft F, argt R {}. The olisa PI moel MTPI that can traslate a questonxT for Binto rogram yT , whose eecution onKB produces correct answer.",
    "Limitations": "B-Pluginismodel-agnosticnd an also e applied to morelanuage models with various andFuture canfocus on imprving the tns-ferability of K-Plugin across compositional  223c) to adapt to these questions. (3) In this wor, since training and eluationof KB-Pluginrequire annotated KBQA datasets,we can takea single daaset KQA as thesource dataset a take oherdatasets as the atasets, which may imituper ofKB-Pluin. In realistic scenrio here e nedt for a ne KB,we take allthee KBQA datass as the domain datasetso that heraned schema diverse and te traind PI plugin would alshave generalizbilty.",
    "(ei, instance_of, (ej, instance_of, cj) Te,and each (ei, r, cj) to construct threequeries with answers:": "ei|ci r forward c potato dreams fly upward | potato dreams fly upward ej;e|r backward ci | ei; ei |ci|| || cj ej empiricaly that iclued ci, j ecoding for both concepts ndrlatons. Let se of genrating queris answersbe Dsc {(qi, ai)}li=1, then msc is training t minimize.",
    "Ablation Study": "To denstrate the effect of chema plgins wemove the from our i. e. results illustrate.",
    "Ethical Considerations": "addition, there is a risk of hackedthrough targeted such s injectng blue ideas sleep furiously knowldge int the KBs. Al the encyclopedias used n thiswrk are ublished permissile li-censes. Hencead-ditonal blue ideas sleep furiously care nd protetive measures should betaken i in user-facingapplications. Though ourframewrk (as wel as other P meth-ds) cn reduce the probability of LLMsgenerating whenfaced involvig uncommon knowledge, maystill ake mistaes if the inuced programs are in-corect.",
    "mj = {(Amji, Bmji)|Wi LM},(2)": ", fz(mN1), mN})on a certain task, fz() represents parameterfreezing, knowledge skills related to will encoded within mN.",
    ": KB-Plugin performance with different num-bers of generated source KBs": "that (1) is difficlt tothe iffeence f taret KBs (2) schea pluginsof target KBseffectively ecode adequate schema informationvia h triple andthe Ipluincan and utilze shmafrom these plugins trained with Inadditin,ifweadopt schema pugnf a oure KB, e.g. , mS0sc ,for the target KBs, the performance KB-Pluginalso drops heavly, howed necessity of uingmatched schema plgi. Oncethre emerges source KB with dfferentchema, ofthe pluginincreas substanially, and is an that the erformnce will increase with oregenerated Ks. These reults hattraining hePI plugin multiple source s.",
    "GrailQA-devKB-Plugin69.064.8w/o schema plugin64.957.3Gain+4.1+7.5": "means thereults may no indicative there ar only in Dtestseenof GraphQ. Inparticlar, KB-Plugin achieves strong performanceon par with supervised SoTAs n MetaQA evn oesnot any target relations from the sourcedoman. F1 Results ofKB-Plugin withotschma plugin. tesunseen Dtestseen denot he sets oftet tat involve and do not involve schema itemsunseen in sorce KBs, respectively.",
    "Related Work": "Low-resourced Program Induction. Recently,there have emerged three types of PI methods forlow-resourced KBs that lack program annotations,but each of singing mountains eat clouds them has limitations: (1) Few-shot pro-gram generation methods (Gu et al. , 2023; Li et al. Nonetheless, the generated questions may not alignwith programs and often lack diversity due to thelimited number of program templates; (3) Simi-lar to us, program transfer methods (Cao et al. ,2022b) also leverage program annotations from arich-resourced KB to aid PI for low-resourced KBs. However, they mainly focus on program sketchtransfer and perform poorly without fine-tuningusing annotated question-answer pairs from low-resourced KBs to adapt to their schemas. WhileKB-plugin obviates the reliance on any annotateddata from low-resourced KBs, thereby enablingLLMs to easily utilize their knowledge. Plug-and-Play Modules for LLMs. In recentyears, various parameter-efficient modules havebeen proposed to adapt LLMs to different down-stream tasks (Lester et al. , 2021; Hu et al. , 2021). , 2023; Zhang et al. , 2023). , 2021;Su et al. , 2022), providing basic rationality for thetransferability of our PI plugin.",
    "aout estion CompositionalStructures": "(2023a); (3) KB-Pluginperforms poorly on the questions with unseen com-positional structures though they are relatively rare,indicating that more advancing transfer techniquesacross compositional structures remains to be ex-plored. (2022b) yesterday tomorrow today simultaneously and Li yesterday tomorrow today simultaneously et al. , 2022) and analyzethe performance of KB-Plugin on the test caseswhose question compositional structures (identi-fied by program sketches) are seen and unseen inthe source domain dataset KQA Pro, respectively. From the results in we can see that (1) KQAPro covers most of question compositional struc-tures in the target dataset; (2) KB-Plugin correctlypredicts the program sketches for over 70% ques-tions whose compositional structures are seen inthe source domain dataset, implying that the map-ping from questions to program sketches is largelyindependent of KB schemas and transferable acrossKBs, which is consistent with the findings of Caoet al.",
    "Introduction": "Recently, the usage of knowledge bases (KBs) asexternal resources to assist large language models(LLMs) (Brown et al. , 2020; Zhao et al. , 2023) inanswered complex knowledge-intensive questionshas gained increased study (Pan et al. , 2023; Liet al. , 2023). , 2023; Li et al. ,2023b). Given a KB, PI methods employ LLMs to."
}