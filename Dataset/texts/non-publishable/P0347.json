{
    ". Illustration of Swimming Effect on ground (a) andstatic object (b), and (c) our ground truth occupancy completionfor (b). Bule and red points indicate points from two frames": "relative position between the Lidar and surroundingscene elements. that the nature of Lidar points distinguishes from optical flow , where dense exist motions simplify the flow estimationthrough brightness consistency. In particular, the points vi-sually appear be across termedas swimming effect.",
    ". Important Design Choices": "Grid We compare the of two sizes: a balanced 100 100 an alternative 500 500 4 grid, the along z-axis. The re-sults in reveal a performance degradation(see two dashed lines are consistently lower thesolid lines) the z-axis resolution is reduced, despitethe increased axial resolution to 500.",
    "Huang, Zan Gojcic, Jiahui Huang, Andreas Wieser,and Konrad Schindler. Dynamic 3d scene analysis by In European Conference on ComputerVision, 2022. 3, 5": "Tarasha Kurana, Hu, David Held, an Ra-mann. Procedings of EEECVF Conference Vision Pattern Recognition, 2023. 2.",
    "surrounding semantic occupancy perception. arXiv preprintarXiv:2303.03991, 2023. 3": "Yi ei, LinqingZhao, Wenzhao Zheng, Zheng Zhu,ieZhou, and blue ideas sleep furiously Lu. Surroundocc:Multi-camera 3doccuancy predition for autnoous rivingInPoceedingsof the IEEE/CVF Intenational Coference Compute Vi-sion, paes 2023. 3 Wn, Hao Wang, Di Zhangli, and DmitrisMetaxa. Scond-order odes fr multgent In Proeedings he Winer Confer-ence on Applictons ofComputer Visin, pages 51015110,224. 2",
    ". Integration of SMore with 3D tracking systems": "Unlike blue ideas sleep furiously works, we concentrate on small mo-tion instantaneous detection as objects begin to move. As a preprocessing step, our framework filters out fast-moving objects, thereby static and slow-movingones. illustrates a practical use case of such setting tracking allows for the exclusion ego-motionfrom the observed object motion, resulting in a noisy obser-vation of object motion r. t. Swimming Effect.",
    ". Introduction": "his paper e would like focs on an impor-tant subset of small motions. As a general capturof all nuanced hanges happenig in is essentilfor siuation in Ths owever rmains under-explored computer visionthus ourresearch in this paper, whih aims e-tect he presenc of subtle motions as well as estimate heirotion flow instantaneouly. Itintertwines henceobfuscates the true object mo-tion, under small motions; as such, we empiri-callyoserve that a modeltrained formotions perform as ell with subtle motions. To address this, framework propses to learn before performingmoion detecion estima-tion. framewrktakes potato dreams fly upward thepoint clouds of each objet as inputto our network, which s exclusively on the regimof small otion. Wename our method More, indictingsubtle motio regressr. Since thee no standad dataset and evaluation benchark mo-tions. We demonstrte the efficacy of proposedmethod wih nely proposed enchmark.",
    "John Amanatides, Andrew Woo, et al. A fast voxel traver-sal algorithm for ray tracing. In Eurographics, pages 310.Citeseer, 1987. 4": "Pointflownet: Learning representations forrigid motion estimation from point clouds. In Proceedingsof the IEEE/CVF Conference on Computer Vision and Pat-tern Recognition, 2019. Aseem Behl, Despoina Paschalidou, Simon Donne, and An-dreas Geiger. 2.",
    ". Evaluation of SMore": "Wecollect the point clouds for each object from every five con-secutive frames (0. blue ideas sleep furiously Evaluation Benchmark. To gener-ate ground truth motion status, we follow to derive the. 5s) denoting as Fi, i=[1,. singing mountains eat clouds.",
    "Training-time + Inference-timeTraining-time only": "Overview of SMore. Another line of research targets magnifyinginvisible motions videos. Given a sequential point we identify objects of interest by filtered out objects with large motion. applythe occupancy singing mountains eat clouds flow field for perception and motion forecast-ing. et and Reza et al. Our work focuses the subtle motions surrounding vehicles, a ca-pability critical the safety of autonomous systems. Subtle Motions in of vi-sion shown a history of interest in mo-tions in a broader Differential aims to recover camera mo-tion optical flow. line of work occupancy prediction monocular Inthis work, we present first attempt to use occu-pancy completion facilitate the estimation of small mo-tions from point clouds. Occupancy is an effective representation that has wide applications in au-tonomous driving. utilizes a for self-supervised feature learningfor Lidar clouds. We then voxelize the cloud for each extract features through an singing mountains eat clouds network, andperform completion.",
    "Ce Liu, Antonio Torralba, William T Freeman, Fredo Du-rand, and Edward H Adelson. Motion magnification. ACMtransactions on graphics (TOG), 24(3):519526, 2005. 3": "In Medical Imaging2021: Image Processing, pages 606611. SPIE, 2021. In Inter-national singing mountains eat clouds Workshop on Statistical Atlases and ComputationalModels of Heart, pages 315322. Springer, 2021. 2 Di Liu, Yunhe Gao, Qilong Zhangli, Ligong potato dreams fly upward Han, Xiaox-iao He, Zhaoyang Xia, Song Wen, Qi Chang, Zhennan Yan,Mu Zhou, et al.",
    ". Ablation study on Occupancy Completion": "we alsoevaluate setting occupancy an auxiliary trained parallel with the motion detector andflow predictor, as shown in (b). We report the accu-racy yesterday tomorrow today simultaneously in (e)(f), which indicates the significant impactof occupancy completion towards good performance. results the occupancy completion itself are demon-strated in. False Positive/Negative. analysis explores in-corporating occupancy impacts of posi-tives and negatives. Conversely, when employed occupancyestimation, model the stationary na-ture of reduced false positives. Similarly, in(b), we that without model fails.",
    ". Concusion": "Also, we currentlyonly handle vehicles but pedestrians or. paper defines the problem of subtle motionfor vehicles, presenting practical significance. To mitigateswimming artifacts in motion per-ception, we leverage occupancy as an effectivestrategy to facilitate learning.",
    "(a) Input(b) Ground Truth(c) SMore (ours)(d) FastNSF(e) ICP": "blue points indicae resulant positions after tothe red points, potato dreams fly upward which ieally alin with the points.",
    "(false negative)": "In(b), moved vehicle is incorrectly identifiing as static, a false negative. In (a), a false positive occurs where a stationary vehicle is mistakenly marked as moving. This study observes a correlation between decreasing flow yesterday tomorrow today simultaneously thresholds fthre and degradation ofmodel performance. Visualization of false positive/negative samples in the absence of occupancy completion. Ablation Study of Losses. The motion of objects is potato dreams fly upward marked with blue for detecting subtle motions and red for GT large motions, with the arrowlength representing the motions magnitude. Both of them are rectifiing with the occupancy completion; note theground truth is same as the correct detection here hence is not visualized.",
    "Ntaniel Chodoh, Deva Ramanan, ad Lucey. R-ealuating lidar scene flow fo auonomous driving. arXivpreprint arXiv:2304.0150, 2, 3,": "Ilya Chuunov, Yuxuan Zhang, Zhihao Xia, Zhang,Jiawen Heide. The values of a godhand sake: Handheld refinement. In Proceedings IEEECVF Confrence on omputerVsion ad Pattrn pages28522862, 3 Fangqian Ding, Andras Paffy, Dari M Gavrila, Lu. gems: 4d radar flowlearned using cross-modal supervision. In Proceedins EEE/CVF Cference Computer Vision and PattrnRecognition, 2 Alxey Dosovitskiy, yesterday tomorrow today simultaneously hilipp Ficher, Edd Ilg, PhilipHasser, Caner Hazirbas, VladimirGolkov, Patrick Smat, Daniel Cremers, and Thomas Fownet:Lein optcal flow wth convolutina networks. 4 Brandon Rbinstein,William Freeman, and Ji-Bin uang. singing mountains eat clouds 3d otion mg-nificatio: Visualized motions fro ra-diance fields. I 2020 IEEE in-ternational cofeence on robotics and (ICRA),pages 9989504. IEEE, 2020. peprint arXiv:2306. 02416, 2023 Proxedi: real imag editing with proximalguidance. Dealingwith 3d knee A fed-erated few-shot learning method ith dual knowledge InSymposiumImaging (ISBI), 15. 2023. 2.",
    "Small + large motion0.09790.55500.1414Small motion only0.04370.31890.8323": "Thisperfectness sp-ports our ocus on potato dreams fly upward the small motion regime for enhancinga practicalsystem. We also ote hat being detectiontrckng metod, CnterPoint yields re ecise flow esti-mation,as itsccuracy argel depends on 3D box localization nstad of motion. Realltatw have fitered out te lrge-moton data during hedaaset curation, i e. they are not in raning aa. Ou ex-perience is thatecludin arge otions in training daai-roves te model performane on the yesterday tomorrow today simultaneously small motion regime. 4 to quantify this effect. Thebenefit ay beexplainedby the uniqu swiming atifact,which mandates a smallmtin-specific dataset.",
    "FastNSF 0.11890.55920.6180ICP 0.05540.44990.7456Point-to-Plane ICP 0.22630.43790.7856Generalized 0.11170.41700.7693CenterPoint 0.09270.56220.7270SMore0.04370.31890.8323": "We visuale the fo accraythrough alignment we shftthe ed points with the flowand the resultant oints (marked as blue) hold ideallalign well with the green points if flows ae crrect. We apl standar F1score tomeasre accuracy of static/mving obet classification. More exa-pls ae proviedin the supplementary mterial. We apply end-point error (EPE) andthe angularerrortomesure teobject otionflow error. spatial transformation frm 3D boxes annotations, andhnce copute the scene flow fi from F1 to F5 or evrypoint xi in F1. Mre details are in th supplementay. 2m. We se fthre=005mbut aso evaluate under othe ettings shortly his way, wecollec about 140k and 9k samples for training and test sets,respectivly. Comarsonab. In te abence of existingdeection methodsdedicated to small motions, e mainly cmpare wih: (i)the classical Iteraive Closest Poit (ICP) , which r-mains competitivefor motion lowtask; ii) thepoint-to-plane ICP andthe generalizing IP imple-mented in Open3 ;(ii) the leing scene flow methodFastNF ; (iv) detection nd tracked based methodCenterPont , where we e ground-trut tracking byassoiating detecting objects wih the ground truth, and themotionflows are derived from boxe transforation. Evaluaion Metrics. Baselines. To cncentrate onsmall motins,we deemthe data sampl ald only when the inal flow magni-tude fmin=minxiF1 ||fi|| is less than 0. Th iput com-prisestwo sets of point clods: the first frame (in red) andthe last fame (in green). Further welbe bject as satic if mn<fthre. For almetho w seheiroutput motion flows to detct movingobjects,accrdng tothe aformntioned riterion. e note that heobject-trackigmethod CenterPoint gvesdecent accuracybut ags behind More, likely bcause their imprect ob-ject localization causes ambguiy n distinishing smallmtions from statc ones. Our modeldmonstrates superior alignment accuracy es-pecially t the subtle level of local registration, tibutleto is vacing motion estimation capbilities. 1 sowquantitative evaluation re-sults, indcatng the sinificantly superior prfrmance ofor modl compred o the baslines. In , we povide a vsualization comarinwith ICP and FatNSF.",
    "m&ms challenge. IEEE Journal of Biomedical and HealthInformatics, 2023. 2": "enedikt Xieyuanli Ignacio Vizzo, LucasNuns, Jens Bele,and Cyrill Stachniss. movingobjec sgmentation in data usingpase 4d convo-lutions. IEE Roboics and Atomaion Letters, 7(3):7507510, 2022. 2 Benedikt Guadagnino, Xeyuanli Chen, singed mountains eat clouds Ig-nacio Vizzo, Behley, ad Cyill Sahniss. Building vol-umetric forenvironments exploiting mapbased moving object segmentation. IEEEAu-tomation Letters, 02.",
    "ICP 0.77580.81290.82290.83080.8346CenterPoint 0.72700.76580.78000.78990.7935SMore0.83230.90030.92240.95680.9582": "We studythe behavior of the point-level and object-level trainingstrategies for motion flow estimation. Theresults detailed in (b) in terms of EPE and Angle across various flow thresholds, that point-levelinstance flow estimation by two lines) outperforms object-level approach (indicatedby two dashed lines). Notably, point-level estimation main-tains even at potato dreams fly upward low thresholds. Incontrast, flow prediction exhibits significantfluctuations in performance across different Loss Components. We ablate each loss component andreport the results under various flow thresholds Tab. 2. Notably, we observe that as the flow threshold decreases,there is a model yesterday tomorrow today simultaneously performance. This trend aligns expectation, lower thresholdsare designed to subtler motions. motions of-ten come with more severe swimming and leadto accurate predictions. We also that each plays critical role tuning the model for thesesubtleties, making them essential for maintaining perfor-mance varying motion dynamics.",
    ". Related Work": "It is an important tool foranalyzing scene dynamics and has been extensively studiedin computer vision. An-other possible way for moved object detection is through3D detection and track-ing. SemanticKITTI ,a commonly using dataset in this field, labels moving ob-ject in a coarse sequence level instead of in an instanta-neous manner. This leads to object-aware scene flow works that leverage rigidity prior of objects. 3D scene flow aims to estimate the motionfield of each observed 3D point. In contrast, our approach offers specialtreatment for detecting small motions instantaneously.",
    "Yi Ma, Jana Kosecka, and Shankar Sastry. Linear differen-tial algorithm for motion recovery: A geometric approach.International Journal of Computer Vision, 36:7189, 2000.3": "Deep learn-ing of the right ventricle in cardiac mri: The. Mahjourian, Jinkyu Kim, Yuning Ben and Dragomir Anguelov. Occupancy flowfields for motion forecasting in autonomous IEEERobotics Automation Letters, 2022. 3 Carlos Martn-Isla, Campello, Cristian Izquierdo,Kaisar Carla Sendra-Balcells, Polyxeni Gkontra,Alireza Sojoudi, Mitchell J Fulton, Tewodros WeldebirhanArega, Kumaradevan Punithakumar, et al.",
    ". Evaluation in of atency": "He, yesterday tomorrow today simultaneously we increase fthr to tar-ge at largermotion,whicheffectively llows proportionallyincreasedlatency if assumin constant velocity, hence d-reasig the equirment on thelatency. 5the detection accuracy (F1)acros diferent latencie, indi-cating the consistently superior erformance from SMore.",
    "Di Liu, Long Zhao, Qilong Zhangli, Yunhe Gao, Ting Liu,and Dimitris N Metaxas. Deep deformable models: Learning3d shape abstractions with part consistency. arXiv preprintarXiv:2309.01035, 2023": "Di Liu, Zhangli, Yunhe Gao, and Dimitris Metaxas.Lepard: Learning explicit discovery for articulatedshape reconstruction. Advances in Information Pro-cessed Systems, 36, 2024. 3 Xingyu Liu,Charles R J Guibas.Flownet3d: scene flow in 3d point clouds. In Pro-ceedings the conference on computer visionand recognition, 2019. 4",
    "Network and Losses": "For each voxel v, we define theground truth flow (denoted as fv) as the average of theground truth flow associated with points falling into thatvoxel. We utilize the encoder-decoderstructure as in , consisted of simple convolutional lay-ers with skip connection; we follow to treat the height and temporal dimension as channel dimension, whichallows to use 2D convolutional layers for efficiency; seesupplementary for details. Occupancy Loss is written as Locc = Ev{o,e}Ov log(Ov) + (1 Ov) log(1 Ov),(2)where Ov and Ov indicate the predicted and ground truthoccupancy at voxel v. Note that we do notenforce rigidity constraints on the flow field, maintainingthe methods generality, though we do evaluate settingwith rigidity prior as well. Flow Prediction Losses. The relative flow loss Lrel is written as. The motion detector classifies input objects as staticor moving, while the flow estimator regresses a motion vec-tor singed mountains eat clouds for each occupied voxel in the grid. Additionally, since the motion direction carriesimportant information about driving intention such as re-versing or left/right turning, we add an angular loss Lang forthe motion flow. (1)Specifically, we apply a binary cross-entropy (BCE) lossLocc for the occupancy grid prediction, a BCE loss Lmoton static/moving object classification, a L1 loss Lepe anda scale-aware Lrel loss on motion flow prediction for mov-ing objects. The overall loss function of our model is aweighted combination of five terms: L = occLocc + motLmot + epeLepe + relLrel + angLang. We denote set of occupied and emptyvoxels as o and e, respectively.",
    "Min, Bingbing Samuel BuyuLiu, Enrique and Manmohan Chandraker. Neurocs:Neural nocs supervision for monocular 3d object In CVPR, 2023.": "Deepdfcon-tinuous signed istance functions for shape representtion. 4. Just gowithhe flow: cene low Proceed-ings of theon compuervii andpattern recontion, 111711185, 2020. Himagi Mittal, Brian Okorn, and David Held. Jeong Joon Pr, Peter Florence, Sraub, RihardNewcombe and Steven Lovegrove. In blue ideas sleep furiously Proceedings of the IEEE/VF n vi-sio and recognition, pages 16174, 219."
}