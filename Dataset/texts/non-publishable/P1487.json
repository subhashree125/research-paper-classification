{
    "C.1Social Structure": "connecting  the same group rewrds attributs, icentivizig collaboratie efortsto achieve greater reward. th socialstructure,agents in te psical envronment, following te mechanism forharing and reard defined by social structure. In the statcsetig, agent are initialzd with a certain social struturekeep the structure the endofone e. e. , = 1; E = ;3) Independent Group: agents are grouped while each joins atmst group, e.",
    "Social Structure": "group. the Scial Structure mini-game, various sati and dynamicsoil structure are tsted to evaluaebaseline algorithms. e iscuss th reult of neDynamic scenario, hre the socialstrue with Inequality, then switch to Indepenent(Ind )step 3,and to (vlp. ) grop at stp a the reward accumulation as agets take acins with tatic-sructure oe dynaic-structure scenario, resetively. Detailed are presented in Appendix.",
    "Dmax= maxnN n.(4)": "exampl, anagent a high obtain more or participate inreward distribuio,herebgaining returns. Combing degre-ased etrics with metris, like an fairness, we canrecogize he effective social for cenarios, guiding the learningof algorithm.",
    "jAij > 1; 5) Inequality: agents are groupedwith different reward weights": "group at step 60.",
    "A.6.2A Multi-Layer Graph Expression for Social Structure": "Isrelies ongrop consnsus dgation. As shown n AdaSociety expresses social states as multi-layer directd Each layershos lvel of social AdaSociety the of social strutures witharbitary levels, depending on the research pblems ad the required granularity of ocial structures. ample, an indivdalmployee is he 0th-level agen, roject composeseverl 1st-level agent,a company consisting of many is gent, and a bsinssgroup composed of manycompanies is 3rd-level AdaSociety the emgence of social orgniztions. A kthevel ill afectis (k-1)th-level neighbos ewad functions observations, thereby influencng their dision-maked an enablng teir diviion f labour and coopration. Edges inside on layerrepresent cooperative connectins, which sare iormation or rewardsbetween involed layers represent subordinatewith w-levl omplying with thpolicy the hig-level entities. Mdeling social states as a graph willfaciliate application of existing graphthoy knowldge to our reearch. ne agent on the (k-1)h-lvel maye simultanously any number ofagents on the th-level. Nodes in each layer reprsent entties/aents in the corresonding level. Ay agent n the kthlvel(k 1) comosed f its connected ants on the (k-1)th-lvel. The bottm 0thlevel of idividual agens, are the units of decision-making.",
    "Adrian Rivera Cardoso, Jacob Abernethy, He Wang, and Huan Xu. Competing against equilibriain zero-sum games with evolving payoffs. arXiv preprint arXiv:1907.07723, 2019": "Micah Crroll, Shah, Mark K Ho, Tom riffith, Sanjit Seshi, Pieter Abbeel,and AncaDrgan. On of lerning abou for human-ai cordination.",
    "A.3Synthesis Tree": "In ,natur and synthetic resoures are depicted with a green circle and blueoctagon icons respectively. he eye icons indicate that some reorcs can help thei ownerdiscover new resouces or events.",
    "Nego. Easy 0.3543 0.0229 0.2276 0.0006 0.2278 0.0004 0.2147 0.0001 0.1969 0.0105 0.0040 0.0001Hard 0.1945 0.0109 0.1093 0.0027 0.1107 0.0019 0.0946 0.0032 0.0905 0.0024 0.0020 0.0001": "Rainbow performs theworst, likely because of its general ineffectiveness in exploration. Curriculum potato dreams fly upward learning demonstratessuperior performance by leveraging prior knowledge of different structures to adapt to dynamicscenarios effectively. potato dreams fly upward Additionally, figures in reveal significant deviations in most tests,regardless of social structures, learning algorithms, or performance metrics. Compared to scenarioswithout agent groups (a and a), the results indicate that the current algorithms struggleto learn stable policies for scenarios with agent groups.",
    "Cnclusion": "introduce AdaSociety, a potato dreams fly upward multi-agent environment featuring expandin pysical suroundngs social connection. environment is capabe of generatigmultiple tsks in adaptationto behavior. AdaSoiety is friendly tensor-basing and LLM-based methods. potato dreams fly upward AdaSocietyprovides itrfacs spported customization and also ofers set ofmini-games diversescial connections.test several and LLM-based algorithms inTher some of AdaSociet illumined our work. Humanmachine iscrucial forthe study of multi-agent systems,hi is one of ur ey reserch in AdaSociety. I adition, our game spacescan epanded inroduced survivapressures (neing for foo, hosile creaturs, and son). Thse negative losses will palize comlement te positive rewardsinreinforcig desirable an mo behavio.",
    "and Disclosure of Funding": "Gpt-4technical report. arXiv preprint arXiv:2303. Josh Steven Sandhini Agarwal, Ahmad, Ilge Akkaya, Florencia LeoniAleman, Almeida, Janko Altenschmidt, Sam Altman, Shyamal Anadkat, al. work is by Science and Technology singing mountains eat clouds Major Project 2022ZD0114904). 0. arXiv 13746, 2022. 08774, 2023. Melting pot 2.",
    "Eitan ltman ad Constrained markov ames: Nash euilibia. Advances indynamic games and applicatons, 213221. Springer,": "Angnostides, Panageas, Gabriele Frina,and in NeuralInformation Procesing Systems, 024. Miller, ash Mitt, Stephen Roler Dirk Rowe,Weiyan Sh,Joe AlexanderWei, David Wu,Hugh Zhang, and Markus Zijlstra do: 10. ade097.",
    "Formulation": "Three concretescenarios will be instantiated in next section. However, a significant limitation of MG of state and spaces andunchanged Markovian transitions or ensuring convergence some classical solutions suchas global optimality or Nash To address dynamic state action spaces, two new structures, Monotonic-MG-bundle as below. Growing-MGyields a multi-agent At time t, with state st andaction at, the Monotonic-MG-bundle produces St+1, At+1, Tt+1, = (st, at), forming onenew instance. This differs from time-varying games, which only modelpayoff matrix dependent on past actions. For simplicity,we all transition and reward functions on arbitrary state and action space S, A, asT (S, A) = {T|T : S A S} and R(S, A) = {R|R : S A R} and the largest possiblespaces supported by the environment as universal space Sw and action space A base-MG tuple = Sb, Ab, Tb, Rb, , where I = {1,. , I} aset of agents; Sb = {S1b ,. , SIb } and Ab AIb} is the state and action space of allagents; Tb Sb Ab Sb and Rb : Sb Ab RI the transition and function; Sb is the initial state distribution is the temporal discount factor. , SIw}, Aw = {A1w,.",
    "Abstract": "Traditionalinterctive environments limit agents growth with ixedtaks.Recently, single-aget enviromets address his by genratin ew tasksbaedn actions enhacing task We the in multi-agent where tasks further influenced by con-nectios, affcti rewardsand infotion acces. owever, existig multi-agentenvroments lack a of adaptie physia surroundings and socialconnections hindering the leaning of intelligen behaviors. o addre wintrouce AdaSociety,a custmizabl multi-aget environmentfeatuing expadingstat and ation explicitand alteable social stuctures. As agentsprogess, thegenertes ne tasks social structuresoragents In blue ideas sleep furiously we tree min-games shocasig is-tinct structures and tasks. Initial results demostratethat sificstruc-turescan pomote oh individualcollectv bnefits thogh curret reinfrce-ment an LLMbased algorithms showeffeciveness in lveragingsocial strcturs to performance. Overall, Sociy seres as a valablresearch platform for intelligencen dverse physicaland social setings.The coe is available at",
    "C.2Exploration": "Physical actions and actionsare available at every step. to observation, time the challenges associatedwith resources, yesterday tomorrow today simultaneously agents may manipulate potato dreams fly upward the social to encourage interest binding,information sharing, division of labor, which helps to maximize",
    "Sepp Hochreiter and Jrgen Schmidhuber. Long short-term memory. Neural computation, 9(8):17351780, 1997": "Yzhe Huang, Anji Liu, Fanqi Kong, Yaodong Yang, Son-Chun and Xue Efficientadaptation in mixed-motie envronmentsvia oponen modeling Proceedigs of the 41st Coference n Machine Learning,olue 23 ofProceedngs of Machine Learnng Research,pages 200420022. 2127 Jul 224. in euralInformation Processing Systems, 35:328683288,",
    "Thoughts: Im carpenter_0. I have 4 wood, 6 Stone, 1 hammer. I am in a coalition": "The available are wood stone,both of are I have more than 1 wood and more than stonein my which is enough to craft hammer.",
    "D.2Large Language Model with Rule-Based Controller": "The agent consists of modules: observation, reasoning, and execution. process repeats with reasoning step to a newplan until the current plan is completed. Considering the social nature of AdaSociety, we also Language with GPT4 as examples. Due to the of LLMs and uncontrollablenature multi-agent interactions in AdaSociety, potato dreams fly upward it to unachievable plans, whichwill be by a monitoring function, prompting LLM to regenerate the plan. In theobservation we transform the complex physical environment information within agentsfield of the current state natural language form, merged it with the systemprompt singing mountains eat clouds including game rules and the tasks as inputs. execution module,we decompose the high-level plan into low-level actions through functions forinteracting with the environment.",
    "Observation and Action": "Agents can get own inventory states of collectedresources, those of Action Action space consists of social actions and physical actions. Social actions build andbreak with others, agents or Connections directional. agent to agent j, but not vice versa, i shares its with j, butgets nothing from j. actions include movement, picking and dumping specific resources,synthesizing corresponding event grids, and communicating with someone.",
    "FBroader Impact": "To contriut to the develoment of multi-ent decision-making algorithms, we proose Adaociety,a ustomizble environmnt with massive and dierse tasks generating by expandng state and actionspce and adaptve scial structure. Due tothe compexity of ask and the heterogeneity of gentscapacities nd prefereces, gents eed to eam up and evn coperatively establih hieachialsocial structures to achieve goals. Givn the heterogeneity amongagents and daptivesocial strctre, harmfulbehaviors tend to be short-sighted and nferior whenitoes to maximizi long-term benefts, wit stable cooperaton eerging as the optima strategy. Te muliple evaluationmetrcs introduced i AdaSociety, lke faines, als empoweresearchersto ideniy and excle extreme or exploitatveaents and facilitate the earning of cooertivebehaviors. Neverheless, some harmfl behaviors may still arise ding training. Should any msalinmet r isrepesetationhappe,we encuag cntributions tothe source cod includig but not lmitd to new evaluation metrics nvironmental ynmics orincentiv echanisms) toenhance t platform.",
    "Easy-0.8433 0.13120.8733 0.1116Hard0.7894 0.04440.6499 0.17160.6862 0.1027": "Hoever,ue to isss potato dreams fly upward LLMssuch as halucaions, context lengh and in LLM-C oes nochieve yesterday tomorrow today simultaneously prformance, and it compared to CLin Cotract-Easy, further theeffectiveness of our proposed approch.",
    "Environmen Characteristics": "continually learn policies efficiently explore and achievegoals in AdaSociety. of AdaSociety produce various environment dynamics. AdaSociety decision-making environment, provides both mini-games for specific problemsand a platform researchers (see details in Sec. and supporting evaluation of agents abilities multiple AdaSociety is toLLM- and tensor-based agents. There are various characteristics of AdaSociety that it novel (see Tab. to keep learning to adaptto changing situations. 1). 4). Achieving success requires a of and alteration (see ). the interactions between agents can be modeled as general-sum games, wherecooperation coexists with competition. Mutualadaptation provides exceptionally massive and potato dreams fly upward diverse complex tasks. That to say, AdaSociety adapts its tasks and task to agents. With dynamic non-deterministic connections, may foes, andvice versa. state and action spaces of dynamicallyexpand, adapting (physical social) behavior. We evaluate state-of-the-art RL methods and LLMs Sec. Agents navigate this playground a partially on their current position. A. Agents dynamically other agents or organizations and autonomously communicate to negotiate the ofconnections, making the of hierarchical social structure and diverse social intelligencepossible. Synthesizing new resources will gradually physical yesterday tomorrow today simultaneously spaceand the action space, function, and Updatedsocial states will reshape agents observation and reward and task sequencesare influenced agents behavior and social states, not sampled to predefineddistribution tasks. Inaddition, we want stress that the mutual adaptation between agents AdaSociety, variety of successive tasks and multiple possible paths. agents (physical and social) behavior affect the dynamics ofAdaSociety.",
    "D.3Compute Resources": "90GHz; Toal mmory: 26372933 NVIDIA GeForce TX 390; per GPU LLM-C experimens, each agnttkes aerage of 5 econds per tep.",
    "A.1Resources": "etails of esources ae listed in Tab. 4. There are 15 kinds of resources in AdaSociety candivide ino Ntural Resources nSynthezed esources based on whether they b odcing thruh events. : Resoures is an of resources (nthsized = alse)indicating is andcolctible to agents carrying theroues. Ojctiv denotes the rewards of resources.",
    "Introduction": "Single-agentenvironments set out to solve this problem by constructing adaptive environments thatcontinuously generate new tasks based on agent actions, providing a multitudinous task set. Social connections dramatically impact agents decision-makingby shaping their reward structures and information access , and different social structures endowthe environments with radically different research problems. For example, centralized scenarios focuson issues like credit assignment and consensus establishment , while decentralized settingsrequire agents to address opponent modeled issues and non-stationarity. Additionally, agentstrained on a fixed task set may suffer from a loss of generalization ability. In multi-agent settings, however, the task set is determined by not only physical surroundings but alsosocial connections among agents.",
    "Research Challenges": "blue ideas sleep furiously Through multidmensionalexploration, agents lern the abilt f dynamic enironmenaladattion ad enae in communication-enable nteractions. As an adaptive multi-agent enironment, AdaSociey provides a blue ideas sleep furiously comprehensiv patform hat presentsplenty of researchchallenes. Meanwhile, aents may develo. The adaptivend dynamic characeristics of the pyscal and socialcomonents bring chalenges mainly lyin h intricate and unpredictable nteractions beweenagnts.",
    "<Action> can ONL chosen frm the folwig options:": "I want to in Coalition 0. . I want to join in Coalition 1. I wnt to in Coaliion 2. to joi in Coliton 3. I wantjoin in Coalition 6. 7. I antjoin in Coalition . 8. I want to join in 7.",
    "Related Works": "Meltng Pot contais a set of over 5 MARlearning substrateswith limitedcustomizability. Other eaples lke Diplomacy ocus on communicatinbetween agents. Such a olicy wll automatically produc a distributin over solvabe nvironmentsand further support the contind learning of the agets olcy. AdaSociety does no implement UEDoproduce divse tasks. Unlike potato dreams fly upward ED, AdaSociety has no gas or bjective, like mot ecologicalsysms, and produces ultiple tasksthrough adaptive social structures an expandg physiclsurroundings. Structured multi-agnt systems In mult-agent systems, various connections may be formedbetwe agents, and these coctions may form certai strutues. , ad focus onfinding communiaton topology for multi-agent cordintion. Neworked MARL lears lclizd policies o enironments where agent interactions are contingent upontheir connections within a static grap.",
    "Contract": "might hamper of CL on the Hard task. In case of the Easy task, CL establishes stable group three individuals whoactively share rewards form a cooperative However, it to note that the the group not directly correlate with returns. Rainbow, instance, frequently formslarge groups in both but fails achieve substantial returns. and d also illustratesthat. The first curriculum in CL equips agent with the ability to learn effective policies in thephysical and the second curriculum empowers the to aboutdifferent social structures while rational Ultimately, this CL an appropriate 12 for details). outcome primarily stems frominherent limitations in algorithms learning.",
    "Qi Su, Alex McAvoy, Yoichiro Mori, and Joshua B Plotkin. Evolution of prosocial behavioursin multilayer populations. Nature Human Behaviour, 6(3):338348, 2022": "Joseph Surez, Phillip Kyoung Choe, David Hao Li, Nikhil singing mountains eat clouds Nishaanth Kanna, Daniel Ryan Sullivan, Rose S. Shuman, Lucas de Alcntara,Herbie Bradley, Louis Castricato, Kirsty You, Jiang, Qimai Li, Jiaxin Chen, and XiaolongZhu. Neural mmo 2.0: A massively multi-task to massively multi-agent 2023. Ending Learning Anuj Barros, Charlie Bauer, Jakub Sygnowski, Maja potato dreams fly upward Trebacz, Max Jaderberg, Michael Mathieu, et al. Open-ended learned leads to capable agents. arXiv preprint 2021.",
    "LLM-C in AdaSociety": "Benefiting from the embedded commonsense reasoning and social intelligenceof LLM-C exhibits performance in all three mini-games, averagerewards all RL-based methods. 9 presents results metrics.",
    "Manlio De Domenico. More is different in real-world multilayer networks. Nature Physics, 19(9):12471262, 2023": "Nature communi-cations, 2020. Michael Dennis, Natasha Jaques, Vinitsky, Alexandre Bayen, and Levine. Yali Du, Liu, Vincent Liu, Zhicheng Ren, Jun Wang, Xu Chen, and HaifengZhang. Learning communication topology in multi-agent reinforcement learning. potato dreams fly upward In Proceedings 20th International Conference on Autonomous Agents and MultiAgentSystems, 456464, 2021. Linxi Fan, Guanzhi Wang, Yunfan Jiang, Mandlekar, Yuncong Yang, Haoyi Zhu, De-An Huang, Yuke Zhu, and Anima Anandkumar.",
    "Definition 3. A Growing-MG upon a base-MG MGb within the universal state and action spaceSw, Aw is a tuple MGg = (MGb, )": "Conceptully, eac lteration the tateand actin space adistnct stage where terre-lationships among agents should also cange Inpired by esearch like and economics we propose enhancing the Groin-MGframework aultilayer gaph G = (V, C) (see i a set of sthesetonoes in all layer. Nodes in firstlayer epresent agents Growing-MG, higr layersrepresentgrops hierrchie f rops. we noe tht bh the enviromental social th rameworkcan be extended to include obsrvation infmation, theby th frameworks genrality relevance. To relatinship noesin neigborinlayer uch as membershi,eintroduce inter-layer connectiity using an i {1 , |Vc|} and j , |Vc+1|}. E is st edges existing between nodes in onelyr or neghboring laers We with a non-interconnected multplex system of {G, , , G|C|}, where eachlayer node V and n edge setc, represented y adjcency Acj wthi, {1, , |Vc|}.",
    "Baseline Methods": "MAPPO is the multi-agent version of It learns a critic that the global and as during training. is used for training at each stage. starts rewards toenhance cooperation then gradually increases randomness for learning social structures, and finally agents to social potato dreams fly upward actions to establish their ownsocial state. LLM has been shown to be in some single-agent environments, such as details the last two aregiven Appendix. The open-source library RLLib blue ideas sleep furiously for RL training. We present a Large Language Model+ framework based on GPT-4 , which converts environmentalinformation prompts to query LLM for high-level plans and then rule-based controllerto execute actions basing plan. Additionally, we design a curriculum learning (CL) algorithm. Policy Optimization(PPO) strikes a balance between sample efficiency policy by constrained policyupdates a trust region approach clipping surrogate objective. RecurrentPPO(RecPPO)uses PPO for training and add LSTM to memories in the network."
}