{
    "DDetails on Implementation": "apply optimization combining relevanceassessment and relevance-guided generation, asspecified in Eq. The training utilizes learningrate of a warm-up ratio of 0. 03, a batch sizeof cosine scheduler for 1 Ourexperiments leverage computational power NVIDIA Tesla A100 GPUs, each with 40G ofmemory.",
    "Methodology": "In this section, we prsent he proposedElevane-Awae Reieval-augmente genertion frameork(REAR) which s capble precisely ssessingthe releance degree urig the generation po-cess yesterday tomorrow today simultaneously potato dreams fly upward by incorporated explicit assessment mduleswithin the LLM.",
    "labeling aproach combines lexical andse-mantic iilrity, allowin the acquisition ohig-quality labels aesing GPT AIs": "Irrelevant Documents Sampling. The trainingmethod necessitates the use of irrelevant documents. Specially, as shown (b), we refine SimANS , 2022)that ensures negatives are neither too (falsenegatives) nor too (uninformative):.",
    "A = {ai}ki=1 = {LLM(q, di) | di D}.(1)": "Subsequently, we can choose yesterday tomorrow today simultaneously the final answer fromA based on some specific ways, ensuring it alignsbest with the query blue ideas sleep furiously q. Basing on this task formulation, we consider en-hancing two key aspects: precise evaluation ofrelevance between queries and documents (iden-tifyed relevant references), and leveraging rele-vance signal for noise-resistant generation (reduc-ing the influence of irrelevant content).",
    "imitations": "For LLMs, te challeng bing misl by irree-vant retrievedocuments is a signifiant obstacleersoring the crucial for enhancing LLMsabilit utlize retrieed documents.",
    ": Dataset statistics of the test set": "We usethe same previous work et yesterday tomorrow today simultaneously al. The training of NQ contains. singing mountains eat clouds NQ: a dataset designed to support compre-hensive QA systems. WQ: constructed from questions proposed Google Suggest API, with answers spe-cific entities listed in Freebase.",
    "Wayne Xin Zhao, Jing Liu, Ruiyang Ren, and Ji-RongWen. 2024. Dense text retrieval based on pretrainedlanguage models: A survey. ACM Transactions onInformation Systems, 42(4):160": "In Proceedgsthe 2022 Conerence onEmpirial ethods in Natural Languag ProcessingIndustry Tack pages 548559 Fngbin Zhu, Cao ang, JinmingZheng, oia, nd Tat-Seng Cha. 2021. a step back: evoking reasoning vaabtractio in larg language model arXiv 2022. 0774. Retrieving readin A comprehensive quesionarXiv preprinarXiv:2101.",
    "EDetails on Baselines": ", 2024; et al. , we use the strategy for specific in-struction formats used in tests are illustrated. Fol-lowing the work (Asai et al. In this part, we potato dreams fly upward detail the prompt design and yesterday tomorrow today simultaneously infer-ence details for baselines.",
    ": The efficiency analysis of REAR and previouswork. T.C. is short for time complexity. d, p and ndenote the length of the document, the length of theprompt, and the number of documents respectively": "Moreover,is ahietue makesit asyo adopt thepro-posed preerene-based and noise-resistant lossfunctions.Furhermre, our abelmachine makegood us of smaler models and traditional labls,ad our samplingstrategy improvestraining dataqality, eliinatingthe ed for GPT APIs. sa resut, REAR achieves more precise relaceevaluatin and etter generation performance (Ta-ble 3). Efficicye further discuss th efficiency ofour REAR, as shown i. Frst, we potato dreams fly upward compareREAR ith oher RAG framewoksthat mploydifferen task formulations, such asChain-of-NoCo) (Yu et al. , 2023) CoN proceses xensiveparagrphs and generates n-depthanalyses to iden-tfy usable parts of docment collctions. , 202),where time is proportional to the sqare of the intseqence lngth. Besies, coared toSel-RAG,which follows a simila approach, REAR achivesa reduction i inference time. This improveentis primarily due to our inegrnof PgedAtten-tion (Kwon et al. , 2023). By using PagedAttento,weensure that calculation performed during therelevance assessment phas are preservd, therebyeliminatingthe need for redundant recalculations",
    "Lbi-granularity = Lcoarse + Lfine.(8)": "4. 2Noise-resistant TrainigIn additin t imrovng the capability potato dreams fly upward of iden-tifying relevant docuents, we furthe consideehancin the iscrimintion ablit when refer-ec dcuments conainirrelevant contt or evennoise, such that the LLM ca adaptiveyse exer-nal evidencefor task solving.",
    "a = LLM(q, d, vguide).(5)": "4.1. 3Knowlede Reiability VerificatioBae on the genraed answer, we finally ver-ify te correctess of the answer by consideringtwofators: (a) Is t provided documentreliablenough to trust thecoresponding anser? b)Without referring o the documents, to what degreewill t LLM ahee toits orignl response? Spe-cially, we propose two strategies, nmely source-reiability ad knowledge-consistency. Knowledge-consisten : This aproch fur-ther verifies if the proided owledge coflitswith the aametric knowledge. Specfically, in-spired bythe uccessof sef-consistency in Chain-of-Thought reasonig (Wang t al. 2022),  inform the LLM that he document isirreevant by setting he relevance score to zero (d-noed y srel)and calculate thnverseof perplexitc Mester and Coterell, 2021) f generating heansr a:.",
    "CDetails on Document Collection": "And we implement a strategy incorporating in-batch negatives and joint retriever-ranker train-ing, starting from the Contriever-msmarco (Izac-ard et al. In this part, blue ideas sleep furiously we introduce the retrievers we usedto collect documents. 8. We employ task-specificretrievers to acquire the retrieved document. For in-ference, we utilize FiD-distilled retrievers (Izacardand Grave, 2021a) for NQ and TriviaQA datasets.",
    "Izacard Edouard Grave. 2021a. Distillingknowledge from reader to retriever for question an-swering. In ICLR 2021-9th Learning Representations": "Gautier and Edouard Grave. 2021b. Leveragingpassage retrieval with generative singing mountains eat clouds models for opendomain question answering. In 2021-16thConference of European Chapter the Associa-tion for Computational Linguistics, 874880.Association for Computational Linguistics. Gautier Izacard, Patrick Lewis, Maria Lomeli, Lu-cas Hosseini, Fabio Petroni, Timo Schick, Armand Joulin, Sebastian Riedel, andEdouard Grave. 2022. Few-shot learning with augmented language arXiv preprintarXiv:2208.03299. Albert Q Jiang, Alexandre Sablayrolles, Arthur Men-sch, Chris Bamford, Devendra Singh Chaplot, las Florian Bressand, Gianna Lengyel, Guil-laume Lample, Lucile et al. arXiv preprint arXiv:2310.06825. Joshi, Eunsol Choi, Daniel LukeZettlemoyer. Triviaqa: A large scale distantlysupervised challenge for reading comprehen-sion. In Proceedings of the Annual Meeting ofthe Association for Computational Linguistics (Vol-ume 1: Long pages 16011611. Vladimir Karpukhin, Barlas Oguz, Sewon Min, PatrickLewis, Ledell Wu, Sergey Edunov, Danqi andWen-tau Yih. Dense passage retrieval for open-domain answering. In of the2020 Conference on Empirical Methods in Natu-ral Language Processing (EMNLP). Association forComputational Omar and Matei Zaharia. Colbert: and effective search via contextualizedlate over bert. In of the 43rdInternational ACM conference on researchand development in Retrieval, pages 3948. Tom Kwiatkowski, Jennimaria Palomaki, Olivia Michael Collins, Ankur Parikh, Chris Epstein, Illia Polosukhin, Jacob Devlin, Ken-ton Lee, et al. 2019. questions: a benchmarkfor question research. Transactions of theAssociation for singing mountains eat clouds Computational 7:453466. Woosuk Kwon, Zhuohan Li, Siyuan YingSheng, Lianmin Cody Yu, Joseph Hao Zhang, and Stoica. 2023. Efficientmemory management for large language model serv-ing with In the 29thSymposium on Operating Systems Principles,",
    "ADetails on Fine-Gained RelevanceOptimization": "Besides, linearly mbine with sores. Thes stategs enhanc thequality of trainin data, which in un impoestheperformance of REAR. work ha achieved success relanceassessment disling ranking resuts romGPT-4 (Sun etal. Traditionalannotation methods always abinary labelngmehd (Krpukhin , 2020) which is basedon the presence of ananswer within a document. As shon in , both D1 nd are labeldas relevan. singed mountains eat clouds 7. We three to reduce impact annottion on rainin. We fit wh to fne-grained optimizationfor ssessment mdule. Thirdl,t noise rernkers, we disregarddif-ferencs saler tan1 in relevancetraining Eq. Despite goodrelevance evaluation performance, it ill maygetwrog. Firtly,we design the sampling mthod 11), wichreduces the of potentially falsnetivsbein sampled. Hwever, while D1 llows derivation, D2 requires additional externalknowledge for induction.",
    "Main Results": "This demon-strates that precise signals capturing rel-evance effectively guide generation Thus, LLM can generate with use of bothparametric and external Besides, result shows the of dataconstruction method, even access to GPTAPIs. the results REAR and baselineson open-domain QA tasks. First, our REAR surpasses all the otherbaselines QA performance. Third, generative LLMs struggle to determinethe reliability degree of the given document, whileour overcomes with the well-designedassessment In comparison, REAR significantly en-hances this capability, highlighting effectivenessin architectural design.",
    "Task Forulation": ", potato dreams fly upward 2017; Zhaoet al. , 2024), aimin atnswerng quetios uinga large collectinof duments Typicay, open-domain QA tasks are oftentackling with a retrievr-readr appoach (Chen an Yih, 2020), where theretrieerfinds relevant and nswr basedretrievedevidence. Diferent from prior hatcombie the entireset of retrieved docments as referene fo ansergenrationet 2023; Xu al , 223),our ephasizes ndividual dcumnt uti- Golden LikelyIrrelevnt we Likely to less infomatve.",
    "Akari Asai, Zeqiu Wu, Yizhong Wang, Avirup Sil, andHannaneh Hajishirzi. 2023. Self-rag: Learning toretrieve, generate, and critique through self-reflection.arXiv preprint arXiv:2310.11511": "2022. Jonathan Berant, Andrew Roy Frostig, PercyLiang. In Proceedings of 55th AnnualMeeting of Association for Computational Lin-guistics (Volume 1: Papers). In Proceedings of the 2013conference on empirical methods in natural languageprocessing, pages 15331544. 2017. 2013. Reading wikipedia to answer questions. Language models Advances in neural information processingsystems, 33:18771901. Semantic parsing on fromquestion-answer pairs. PMLR. Sebastian Borgeaud, Arthur Mensch, Jordan Trevor Eliza Katie Milli-can, Bm Van Den Driessche, Jean-BaptisteLespiau, Damoc, Aidan Clark, et singing mountains eat clouds al. Tom Brown, Nick Ryder, MelanieSubbiah, Jared D Kaplan, Dhariwal, Pranav Sastry, AmandaAskell, et al. In International conference learning, pages 22062240. 2020.",
    "Stephen E Steve Walker, Susan Jones,Micheline M Mike Gatford, et al.1995. at trec-3. Nist Special Publication": "In Proceedigsof 59h Anual Meeting of theAssociaion for Computationl Lingusticsand the11th Internatinal Joit o Ntural Pocessing (Volume 1: Long Papers), pags66486662. Si, XinyunChen, Msr NathanScales,David Dohan Ed H Chi, Zhu. PMLR. 021. Large modelscanbe by irrelevant context. En-to-end trainingo neural retevers for open-domain nswer-ing. Sachan, Mostofa atwary, Neel Kan,Wei Ping, L Hamil-ton, an Bryan Catanzaro.",
    "Danqi Chen and Wen-tau Yih. 2020. Open-domainquestion answering. ACL 2020, page 34": "arXiv prernt aXiv:2406. 1127. FlorinCuconasu, Giovanni Tappolini, Federico Sicil-iano, ime Filice, Cesae ampagnno YoelleMaarek, Ncola Tonellotto,ad Fabrizio Silvetr. arXiv prepri Xiv:2405. arv prerintariv:2309. hengxiaoDu, Yujie Qian, Xiao Li, Med Dg,Jiezhong Qiu, Zhili Yang andJie Tang. 18009. 2024. arXiv potato dreams fly upward preprint arXiv:2401. Eplored context windowof arge language models via dcmposed poitonal vectors. 10997. Xiaoxue Cheng, unyi Li, Wayne XinZho, HongzhiZhang, Fuzheng ang Di Zhang, K Gai, andJi-Rong Wen. n Proceedings of 60th An-nual Meeting of the Assciaton for ComputationalLinuistics Volme 1 Long Ppers), paes 20335 Yuna Ga, YunXiong, Xiyu Gao Kgxiang Jia,Jilu Pan, Yuxi i, Yi Dai, Jiawe Sun, d HaofeWang 2023. Bamboo: A compehen-sve benchmark fr evaluaed long te mdelincapaciies oflarge language odels. Small agent can alsorock! em-owerig small language models as hallucinationetecr. 2022. 14887. 202. 203.",
    "Experimental Setup": "enhance EM we several answer ex-amples within the prompts, as illustrated in. (1) Retrieval based promptmethods: we design different prompting strate-gies based LLMs (without to RAG tasks) to support RAG, including potato dreams fly upward Direct yesterday tomorrow today simultaneously QA: We the top 10 retrieved as single document for RAG. We collect data from theNatural Questions (NQ) (Kwiatkowski et al. consider the following two ofbaselines for comparison. Baselines. ,2023).",
    "In this part, we will introduce the trainingpipeline our approach, As shownin (b)": "2. 1Bi-granularity FusionPrecise relevance assessment is for the re-liable utilization of retrieved documents. Previouswork adopts the coarse-grained binary dis-crimination task et al. Therefore, we consider singing mountains eat clouds preference-based fine-grained Specifically,for the fine-grained supervision, we utilize es-timated relevance (See. 2.",
    ": Results of factual generation accuracy providedwith top-1 retrieved documents on the test set of NQ.Categorized by performance when providing relevant(Rel) and irrelevant (Irr) documents": "(5) w/o Sampling: the viant traiin wth negatives for training. We the using the similar taining consruconapproach of Self-AG and RobusLM, onedocument per W observe a notable declineunderscoring the efectiveness of noise-resitanttraining to enhance aginst irrelevantdocment intererence. We can observe asignificant dro in assessment cpability,frther illustrating the effectiveness of our. and result in beter w/o Noiseresistant: the variant witoutnoise-resistant trainin.",
    "For open-source LLMs, we consider LLaMA2-Chat (Touvron et al., 2023), Mistral-It (Jiang et al.,2023), Baichuan2-Chat (Yang et al., 2023), andChatGLM3 (Du et al., 2022)": ", 2023)and (Asai t al. designed methods:we alsoconsider fine-tuned RobustLM (Yoran al. , 2023) a baseies,which been speciall optimized the To ensure fair comparison, the two fameworks abve potato dreams fly upward are evaluated theset ofretrieved documens used for EAR. EM responses exactly match the gold truth an-ses anclculates the precisin-recall overlapof predicted and potato dreams fly upward trueanswers. Metric.",
    "Equal contributions.Corresponding authors": "Who won first Noble Prize in Physics? First law thermodynamics was by William. Its irrelevant. LLMs struggle to determine relevance",
    "Related Work": "retrieving doc-uments et al. , 2021a; Zhang et al. , an extractive generative reader typically using foranswer generation (Zhu et al. , 2020), RAG (Lewis ,2020), (Borgeaud et al. , 2023) demon-strated factual generation capabilities. Retrieval-augmented LLMs. , other work improvesthe quality of retrieved expandingthe knowledge sources et al. , 2023b) or queryrewriting (Zheng et However, we focuson a where the documents fromretrieval could mislead LLMs. we frameworkthat can accurately assess andis more robust to irrelevant content.",
    "Relevance-Aware RAG Architecture": "4. 1Relevance AssessmentInstead of trating all the retrievd documentsequally, we first im to singing mountains eat clouds assess the elevancedegresof the documents. , 203; Sun t al, 2023), efirstmap te input quey-document pair into thereevance embedding vrel singing mountains eat clouds by te LLM. 1. Drawig from the uccess ofLLM-base eoer in achiving pecise rlevanceassessment (Ma et al.",
    "Bhosale, al. 2:Open founda-tion and fine-tuned chat models.arXiv preprintarXiv:2307.09288": "Xuezhi Wang, Jason Wei, Dale Schuurmans, Quoc Le,Ed Chi, Sharan Narang, Aakanksha Chowdhery, andDenny Zhou. Self-consistency improves chainof thought reasoning in language models. arXivpreprint arXiv:2203. 2022. Chain-of-thought prompted elicits rea-soned in large language models. Advances in NeuralInformation Processing Systems, 35:2482424837. Lee Xiong, Chenyan Xiong, Ye Li, Kwok-Fung Tang,Jialin Liu, Paul N Bennett, Junaid Ahmed, andArnold Overwijk. Approximate nearest neigh-bor negative contrastive learning for dense text re-trieval. In International Conference on LearningRepresentations."
}