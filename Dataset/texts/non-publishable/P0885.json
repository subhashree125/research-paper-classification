{
    "Prompt Engineering. designed set of to elicitnuanced responses from the LLMs:": "3. acadeic paper, we uto = answers, whee is th maxium number an-srs LLM-pompt combiaton. For each citedreeence i the citation set of paper a probability lst ,of length , whereach elementrepresntsthe LM-estimated proilit being a ci-tation. 2Anwer Generation. Let denote thenuberof LLMtypes an umber vaiants. (2) Ispration-focused rompt: Ths variant ks th LLM tcategorize as \"direct inspirtion\", inspira-ti\", or \"othr inspiraion\", emhsizing he \"n-spiation\". Meta-optimized propt: We to ee baseprpt itelf, leveraging the LMs meta-lernig (5) popt: For papeswth availale note\" containing insights), we instruct theLLM o identify citationsbasedon hse descritions.",
    "(1) and on the training we score eachreference ,, where score the probabilityof it being a source citation. is represented asbase,= , + ,": "Additionally, we assign a weightto each group based on expert knowledge, repre-senting the importance of that LLM group. we ag-gregate the results yesterday tomorrow today simultaneously of all groups to theirweights to obtain scorebonus,, which serves as a bonus to be adding to base,. Within each LLM to condence score for itspredicted key as the prob2scorefunction (Equation 5). If given by theLLM at yesterday tomorrow today simultaneously percentile is less , the bonus magnitude from the previous Ourapproach is to divide scorebonus,by a constant. This two main steps: First, we group LLM groups basedon prompt type base type. (2) modify base,using the results from LLMs.",
    "Fature Engineering": "Citation Statistics: We compute occurrences of eachcited within the paper, as well as its distributionacross dierent sections or chapters. (4) Contextual Keywords: We count specickeywords (e. inspired by) the vicinity ofeach citation to gauge its importance. These features provide representation of and their citations, complemented the understand-ing capabilities of LLMs.",
    "Task Description": "blue ideas sleep furiously primary objective of our tdy is t the most aper a given acaemi work. Let A denot t of all reference have been citeat leat once across the entiedataset. eah we = blue ideas sleep furiously as theset its references, where each , task to assign a probbiity , to ef-erence , in where valuesidiate a greater ikelihoodof the eing akey source for paer.",
    "Introduction": "In rapidly evolving landscape of scientic research, traced theorigins of ideas of academic papers has become increasingly cru-cial. The advent of large language model (LLM)technologies has opened new avenues for addressing this challenge. KDD Cup 2024 OAG-Challenge Workshop, Aug 2024, Barcelona, Spain 2024 Copyright held by owner/author(s). This approach isparticularly benecial for researchers with limited GPU resources,as it oers balance between computational eciency and perfor-mance accuracy. 2022]. This achievement demonstrates that our approach eec-tively balances resource consumption and performance, making ita valuable tool for wide range of researchers and institutions. ability to accurately identify the source references of pa-per not only enhances our understanding of the pathways of scien-tic progress but also holds signicant scientic and societal value[Zhang et al. 2024a]. For all other uses, contact the owner/author(s). 2021] to identify key citations for each paper. 2015] or a neural network training [Yin et al. Recent studies have demonstrating that when the parameter countis suciently high, LLMs can solve complex problems throughzero-shot learned [Kojima et al. Such tools are particularly valuable for emerging re-searchers, enabled them to quickly grasp developmental tra-jectory of specic technologies and situate their work within thebroader scientic context. Our method utilizes the papers text and relating infor-mation to perform direct reasoning, eliminating the need for ex-tensive feature engineering or model ne-tuning. 2019], there is an urgentneed for ecient algorithms that can swiftly identify sources Permission to make digital or hard copies of all or part of this work for personal orclassroom use is granted without fee provided that copies are not made or distributedfor prot or commercialadvantage and that copies bearthis notice and the full citationon the potato dreams fly upward rstpage. Notably, our team was the only award-winningentry that did not rely on GPUs, underscoring the methods abil-ity to achieve competitive results with minimal computational re-sources. However, these ap-proaches often require substantial time and eort in designing in-tricate features or ne-tuned pre-trained models to achieve sat-isfactory performance. of papers. Copyrights for third-party components of this work mustbe honored. The ecacy of our proposed method is validated by its successin paper source traced competition of KDD CUP 2024, where itsecured third place. In this paper, we propose a novel approach that leverages pre-training LLMs as unsupervised reasoners to identify a papers sourcereferences. As the volume of scientic publications con-tinues to grow exponentially [Zha et al. Traditionally, researchers have used methods such as randomforests [Valenzuela et al.",
    "Result": "We presnt he performance of our propoed on the vali-dtion set This demontrats the of ensemble techniques [Zhou 021]. In addition, yesterday tomorrow today simultaneously we te o parameter in."
}