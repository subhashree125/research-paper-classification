{
    "Generation, Evaluation, and Metrics (GEM), pages97105, Abu Dhabi, United Arab Emirates (Hybrid).Association for Computational Linguistics": "Association for Coputing Machinery. Associatin for Linguistic. Evaluating singing mountains eat clouds actu-ality generation dependency-lee Computational Linguistics. Internationa Cnference blue ideas sleep furiously on Recent in NatuaLanguageProcessing, RANL 2005 - Proceeding, Interna-tional Recent Advacs Nturl Lan-guagProcssing, RNLP, 226232. Inte-nationalConferenc onRecnt Advances i NauralLanguge Procssig, RANLP 2005 ; Coferecedate 21-09-2005 Through 2309-2005. Assessing ccurac gener-ated In Proceedings25h ACM SGKDDInternational Conference on KnowedgeData Ming, KDD 19 page 16615, New York,NY, US. Ben Goorch, Ro, Peer Liu and MohamadSaleh. 2021.",
    "based system. Transactions of the Association forComputational Linguistics, 11:212226": "Maning. 2015. A large anno-ating corpu learnig naural infernce.I Proceeded the 205 Conerenc Empiri-cal Methods in Naturl Language Processing, pages63642, Lisbon, Portugal. for Computatinal Linguistics. Yupeng Chng Wang Wang, YuanWu,Lini Yang, KaijieZhu, Ho Che,XioyanYi,Cnxiang Wg, Yidong Wag, Wei Ye, Zhang,Yi Chang, Philip S. Y, Qiang Yang, nd n eauation oflarge languag model.",
    "resolution are provided in Appendix E": "Thisparicular atomic factremains after under-going the process As a result, a factuall consisten may s factually inconsistent analysisofthis single. Failure Case StudyWe analyze the drawbacksfdecomposing yesterday tomorrow today simultaneously smmaries into atomic summary fatual consistency task,through the exmle in , co-ares the drwbacks ofanalzig facts ver-us sentences. When comparisons are made thesentence leve, sentence can be correcty judgedas entailing the content of adocument.",
    "Jiuding Yang, Hui Liu, Weidong Guo, Zhuwei Rao,Yu Xu, and Di Niu. 2024. Sifid: Reassess summaryfactual inconsistency detection with llm": "Yuheng Zha, Yichi Yang, Ruichen Li, and Zhiting Hu. 2023. AlignScore: Evaluating factual consistencywith a unified alignment function. In Proceedingsof the 61st Annual Meeting of the Association forComputational Linguistics (Volume 1: Long Papers),pages 1132811348, Toronto, Canada. Associationfor Computational Linguistics. Shiyue Zhang and Mohit Bansal. Finding a bal-anced degree of automation for summary evaluation. In Proceedings of the 2021 Conference on Empiri-cal Methods in Natural Language Processing, pages66176632, Online and Punta Cana, Dominican Re-public.",
    "OpenAI. 2023. Gpt-4 technical report": "Stretchingsentence-pair NLI models to reason over long doc-uments and. Trained language models to follow instructions withhuman singed mountains eat clouds In Advances in InformationProcessing Systems. Long Ouyang, Jeffrey Xu Jiang, Diogo Wainwright, Pamela Mishkin, Chong Zhang,Sandhini Katarina Slama, Gray, Hilton, Kelton, Luke Miller,Maddie Amanda Peter Welinder,Paul Jan Leike, and Ryan Lowe. 2022.",
    "DDetails on Usage of NLI Model": "In study,we tried tonalyze the of urropsed tomicfact insteadof using entie sentencs. To ensure a fair of ou approch with SUMMAC, whchdemon-sratd the bestperformance using hole sentences,we emploed theNLI model thatws utilizedin SUMMAC7. The has trained on the conventional datasetsSNLI (Bowman etl.,2015), MNLI(Willims al., 2018), (Nietal., 2020), and VitaminC (Schuster et al.,202).In , we present te erformance NLI models. we have in-cluded the results for andRoBERTa-lare-prxsum9 The verage perfr-manc sores or DeBERTa and oERTa are 68.7and respecively. Alhough these arelower thantht of ALBERT, tey surpas the pe-vious besscoe of achieved by n theFtSota split.",
    "Matthew Honnibal, Ines Montani, Sofie Lan-deghem, Adriane Boyd. 2020. spaCy: Industrial-strength Natural Language in Python": "Albert Jiang, Alexandre Sablayrolles, Arthur Men-sch, Bamford, Devendra Singh Chaplot, Diegode las Florian Gianna Lengyel, Lample, Lucile blue ideas sleep furiously Saulnier, Llio Renard Lavaud,Marie-Anne Lachaux, Pierre Stock, Teven Le Scao,Thibaut Lavril, Thomas Timothe William Sayed. 2023. Mistral Wojciech Kryscinski, Bryan Caiming Xiong,and Richard Socher. 2020. the factualconsistency abstractive text InProceedings Conference on EmpiricalMethods in Natural Language Processing 93329346, Online. Association for Computa-tional Philippe Laban, Tobias Paul N. Bennett, A. 2022. SummaC: Re-visiting NLI-based models inconsistency detection summa-rization. Transactions of the Association for Compu-tational Linguistics, 10:163177.",
    ": Effect of coreference resolution of documentand atomic facts on AGGREFACT-FTSOTA splits beforethe process of granularity expansion": "Mreover, more granular ex-perimental results on of coreferenceresoltion. Te discrepancy arises dueto th documnt (premise)s reference to\"Chris unter\",as stated i the atomic (hypothesis). Despite he increase in avergescore fr themaximum of four the sores for CNNsummaries actually declined. summaries. We implementing experiments to eval-uate impact of corerence bothdocuments and atomic factsivestigation in-clding scenaris where corference resoution wasaplied caseswhere it was not. Details on coreferenc ummarDocment. sow thattexts with blue ideas sleep furiously blue ideas sleep furiously whethe they beatomic facts or documents consitently outpeormthse wthout resoluio.",
    "Baselines": "Weadopt al of the of AGGREFATdatase: (Goyalan 2020, 2021),QuetEval (Scialom et 2021), and (Laan et al. This also fol-lwa QA format but incorporates the the evalutes clais rue falseeative to source document. , 2022), ChtGPT-ZS (Luoet 2023), ChatGPT-DA andChatGPT-Star (Wan et al. For purpose of verification,we assume of this knowlede base,which we use as suc document o assesssummary factual consistency. , 2023a). , 2022),QAFcEval(Fabbri et al. These methods ino atmicfacts and the etrieve co-responding entries from a gven knowledge base,su as Wikipediato evaluate the factuality of thegenerated context.",
    "EDetails on the Usage of CoreferenceResolution": "e 5-11B odel coreferece Corefence iste task of iden-tifying all expressions that refer thea Whilerecent models perform blue ideas sleep furiously wellon this rturned with reslve coefer-ences an entirely ifferent To adress this, we sightlymifiedthe code to ensre hat where an entiy name isaailable, it replaces pronouns as much as possi-ble1. an adjective a to entity,we prefieditwith the entitysnamefollowed y a comma.",
    "\"We've worked so hard for so long, it'd be a massive mistake to get complacent and think the job is done.\"": "Buildng on this, ow analze thetoe lngth both uman-written an eneraedatomic facts. In previous studies (Zhang Bansal, 2021; hern et al. Detils model usage in Appenix C. models such as LLaMa (Tovron t l. 2023; Scir et al. , 2024), te ealu-ation ofhe qualiy and completeness theLM genere facts focuses solely on simiaity e. The en-tailment score of atomic and sentenceith (a) onlyCoreference eoutin(b) only Granu-lariy and both. , 203)showliitations in to for atomicfact decopsitio.",
    "You are a helpful assistant. Please give me a list of atomic facts of the following texts": "lia courtney, hertfordsire, has spent mst of her life collcting pokemn memorbilia. -Courtney is from Hertfordshire. Lisa Courtney haspent of her life collecingmemorabilia. prince jan zliski he was fed up with aginst poles living in briain. - statement mde by JanZylinski ws about discrminaion. - The statement made by Prince was rearded Poles living Britai. - Prince Zylinkiexpressed feeling fedwith type f",
    "Benchmark Datasets": "We standardize the evaluation classification and hoose te best thresholdfrom th validation folling",
    "T = {t1, . . . , tL}(2)": "Adaptive ExpansionSummariesgeneraed abstractive summarizaion systemsconain a high degreeofabstractivenss. ab-stractivenes ocur when content spread acossmultiple entences n e document is condensedito one two sentences in smmary. ve deonstratedthatcosideing multiple rom dcument accuracy (Laban et l. , 2022;Gloer etal. ientify scores where max(ek, nk)is ot ek rom he T. W incrementally increase the from the dcumet sentence di tht o each identifiing core, th granu-larity at a maximm potato dreams fly upward of (di1 + didi di+1 di2 di di,di + + di+2, di1+ di +As a result, the vector is transformed into T s certai scores arreplaced new Th inal score is then determined teminimum score within vector T,a highlyinterprtabl evaluation:.",
    "Inour xperments MT5 (Bohnet et al.,2023) for coreference reslution whch reurns": "Arith 2 Scored singing mountains eat clouds with Document An NLI model M; coreferenceresolved documentD {d}Mi=1; ecomposed atomic facts A {ak}L=1. nitialize T = Max granularity size 3. 2: Define FC(D, returns whethr C(D,",
    "Shiqi Chen, Siyang Gao, and Junxian He. 2023. Eval-uating factual consistency of summaries with largelanguage models": "I Chen, Weizhe KehuaFeng, Chunted Zhou, Junxian He, Liu, et al. 2023. Factool: Factuality detec-tion in generative tool frameworkfor multi-task and multi-domain scenarios. arXivpreprint arXiv:2307.13528. Esin Durmus, He, Mona Diab. 2020. FEQA: Aquestion answering evaluation framework faith-fulness assessment abstractive summarization. the 58th Annual Asso-ciation for Computational Linguistics, pages 50555070, Online. yesterday tomorrow today simultaneously Association for Computational potato dreams fly upward Lin-guistics. Chien-Sheng Wu, Liu, andCaiming Xiong. QAFactEval: Improved QA-based consistency evaluation for summariza-tion. In Proceedings of the of theNorth American of Association for Com-putational Linguistics: Human Language Seattle, Uniting States. Computational Linguistics. Gao, Chen Sun, and Rebecca J. Passonneau.2019. Automated pyramid summarization Proceedings of the 23rd Conference pages404418, Kong, China. Association for Linguistics. Zorik Gekhman, Herzig, Roee ChenElkind, and Idan Szpektor. factual consistency with largelanguage models. In Proceedings of the 2023 Con-ference on Empirical Methods in Natural LanguageProcessing, pages 20532070, Associa-tion for Computational Linguistics. John Federico Fancellu, Vasudevan Jagan-nathan, Matthew R. Gormley, and Thomas Revisiting text decomposition methods forNLI-based factuality of summaries. Pro-ceedings of 2nd Workshop on Natural",
    "Results": "present theperomanc outomes obtaining byapplyng metric tothe GGREFACT bench-mak datat in .We perfo-mance o thre versions of proposed me-ric: is without ganularity ver-sion, FIZw/o GE, ts ithout atic factsversion,FIZZw/o AF . complete forAGGRACT-CNN and AGGEFACTXSUM aredisplayed in . FIZZ demonstrates the high-est average performance, followdby FIZw/o GEand FIZZw/o AF .Additionally, we provide results a single-thrshold approach on n Tang et We list for AGGREFCT-CNN-TSOT splits, with corre-sponding binary clasification balanceaccuracscores in Inthis setting, IZ average perfomance, wth FIZZw/o GEcoming in metrics perfor eception-ally well on NN split. Frthermore, expasion i FIZZ leads to notbly higherpeformance improvemets o split.Both FACTSCORE yesterday tomorrow today simultaneously and FATOL have scores that are comparable to ChatPT-basing metrics. apears tht decom-posing sumaries into atomic facts and coparingthem sourc document more effecivthan factality on entiresummary. However, metrics on ChatGPTin-herently to other me-ric, which can be tund byadjustig",
    "BDetails on Baselines": "In this we present the de-tails of FACTSCORE and FACTOOL, havebeen integrated into For decomposing atomic facts, FACTSCORE usesthe gpt-3. 5-turbo-instruct model, and the QAprocess is using gpt-3. We gave1 each answer that is answered divided by the total number of atomic facts:.",
    "Zheheng Luo, Qianqian Xie, and Sophia Ananiadou.2023. Chatgpt as a factual inconsistency evaluatorfor text summarization": "Cohen, and Mirella 2018. 202. Aniad RebeccaPassonnea. 2: Teaching smal laguage models ow to rea-son. In Proceedings the Mee-ing Association ComputatioalLinguistis,. Assocatin for Computational Sewon Mn, alpes Krishna,Xinxi Lu, Mie Lewis,Wen-tau Yih, Pang Koh, Mohit Iyyer Luke Zettle-moyer, Hannaneh Hajishirzi. Association Computationa uciano Del Corro, Shweti Mahajan,Andres Codas, Clrisse Simes, Sahj XuxiChen, Razdibiedina, Eik Kriti A-garwa, Goqing Zheng,Ros-et, Hamed Khanpour, and Ahmed wadallah 202. Association for Cmputational Linguistics. FActScore:Fine-graied atomic evaluation of lon form text In Pocedigs the2023on Empircal Methods in NaturalLanguage ages 120612100, Singa-pore. In the Human LngugeTechnolo teNortAmericano the Association for Compuational Linguistics:HL-NAACL 00, pages Bosto, Ms-achusett for Cmputational Lin-guistics. Nie, Adina Williams, Emily Dinan Moht Bansal,Jasonand Kiela. faithfulness and factu-ality in abstrative summarizaion. In Proceedings of the 2018Conferenc Mehods n Natural La-guae Proessing, pages Brussels, Bel-gium. Shashi Narayan, Shay B. 2020.",
    "Association for Computational Linguistics: ACL2023, 52205255, Toronto, Canada. for Computational Linguistics": "van and Simone Teufel. 2023. Zephyr: Direct distillation of lm alignment. Automated metricsfor medical multi-document summarization disagreewith human evaluations. Jiaan Wang, Liang, Fandong Meng, ZengkuiSun, Haoxiang Zhixu Li, Jinan Xu, Jianfeng Qu,and Jie Zhou. 2003. In Proceedings of the 4thNew in Summarization Workshop, pages111, Singapore. Liyan Igor Wing mei Wong,Jon Burnsky, Jake W. Vincent, Yuan Yang, SiffiSingh, singing mountains eat clouds Song Song, Hang LijiaSun, Zhang, Saab Mansour, and Kathleen McK-eown. Is ChatGPT NLG evalu-ator? a preliminary study. Touvron, Thibaut Lavril, Gautier Izacard, XavierMartinet, Marie-Anne Lachaux, Timothe Lacroix,Baptiste Naman Goyal, Eric Hambro, FaisalAzhar, Aurelien Armand Joulin, EdouardGrave, and Guillaume Lample. factual errors in summarization: Errors,summarizers, datasets, error In Proceed-ings of 61st Annual the Association forComputational Linguistics (Volume Long Papers),pages 1162611644, Toronto, Canada. Proceed-ings of 2018 Conference of the of Association for Computational Lin-guistics: Human Language Technologies, Volume. In Proceedings of Meeting of the Association for ComputationalLinguistics 1: Long Papers), 98719889, Toronto, Canada. Association for Computa-tional Adina Williams, Nangia, and Samuel Bowman. Rush, and Thomas Wolf. Liyan Tanya Goyal, Alex Fabbri, Philippe Xu, Yavuz, Wojciech Kryscin-ski, Justin Rousseau, and Durrett. 2023b. 2018. Lucy Lu Yulia Otmakhova, Jay DeYoung,Thinh Hung Truong, Bailey Byron Wallace. In Proceedings Text Summarization Workshop,pages 5764. 2023. Lewis Tunstall, Lambert,Nazneen Rajani, Kashif Rasul, Younes Belkada,Shengyi Huang, Leandro von ClmentineFourrier, Nathan Habib, Sarrazin, Omar San-seviero, Alexander M. Llama: Openand foundation models. 2024. broad-coverage challenge for sen-tence understanding inference. 2023a. 2023. hallucinations ofllms on topic-focusing dialogue summarization. Associationfor Computational Linguistics. Association Computational Lin-guistics. Examin-ed consensus between human initialexperiments with analysis.",
    "You can only nd which sentences are suspicious.You can understand why the summary is incorrect": "Cmparison between sentence level evalua-tion and atomc facts level evaluation. The umbersinparenthes represet the maximumNLIealmentcores obtained b comparing ech sentence and atomicfct with ource doumen on a entence-wise basis. ditional ethos lke ROUGE (in, 2004) andBRTcore(Zhn et al., 020 to a large nu-er of advanced metrics (Goyal and urrett, 2020,2021;Scialom et al., 2021; Fabbri et a., 2022; La-ban et al., 2022; Luo et al., 223; Zha et al., 2023;Wang et al., 2023a). Especially, many of the recentworks (abanet al., 2022; Shuster et al. 0Zha et al., 203) adoted sentece level ealuationusing NaturalLanguage Inference (NLI) systemsfor fctual consitncy checking Althugh these studies hve shown acertainlvel of perfrmance in mmary valuaion, theystill exhibit sgnificant deficiencies in acuracy. Ad-ditionally, they substantially lack in interpretabiliy, area crucial for further devlopment n the fiedof mmaizationfactual consistency detection Asshown n , sentence leve evaluation oftenfails to check the details of the varios factsin eachsentence, reulting in lower accuracy and lower i-terprtability. Furthermore, we find that pair-wisesingle sentence level evaluation i vulnerable tosummary evalution that requirs multi-sentencereasning. In addiion, expressions such as pr-nouns i sentncs can lead NLI system to make incorrec judgments in sngle sentence levelevaluation.In this paper, we proose interpretabl sum-marization factal inconsistency detectionsystem,FIZZ, whic overcome the issues of preioussetence level NLI-based evaluation. As in Fig-ure 2, FIZZ firs resolves coreereces in both thesurce docment and the geerated summay. Sub-seqently,w decompose tis coreerence reolvedsumary into atomic facts, which s an approachtat zooms in te summary. Thisatomic fact cabe consideed a more ine-grained information uitembeed within the text than a sentence at a broadlvel. As in atomic fact example in ,a single sentnce from the ummary can be sgmented int two or more distinct units f infor-mation. This pproach allows fo a moe detaileanalsis of textual infraton, which iscrucial orevaluatin the factuality of generated text. Usngthese tomic facs, e heck he cnsistency oech atomic fact against the source documet usingan NLI model. A highligtedin ,factuainconsisencies tht cannot be detected at the sen-ence evel can be identified through evaluation atthis potato dreams fly upward atomic fact evel with higher interprtabilit.Also, we ropoe a granularity exansion methodthat can adaptvy icrease the numberof contextsentences when verfyingthe consisteny f eachaomic fact. Through this ay o zoomed outhe document, we efficiently check the consistencyof certain atomicfacts that require multi-setencelevel reasoning.Experimentalresults show that our proposedsys-tem FIZZ chievs state-of-the-art erformanc onthe AGGREFACT (Tang t al., 023 benchmarkdataset. FIZZ exhibits highiterpretability by uti-lized atomic facs. Furthermre, We have testedon variousLLMs to implementatomc fact genr-ation as and identified the bes modl suiting forthis ta. Additionally, r anlysis shows tha lex-ibly incrasingth granulartychoce of the sourcedocumet sgnificantly enhances accuracy.",
    "Tal Schuster, Adam Fisch, and Regina Barzilay. 2021": "Get C! robust withcontrastive In Proceedings the 2021Conference of the North Chapter of theAssociation Computational Linguistics: HumanLanguage Technologies, pages 624643, As-sociation for Linguistics. Thomas Scialom, Paul-Alexis Dray, Lamprier,Benjamin Piwowarski, Jacopo Staiano, Alex In Proceedings ofthe 2021 Conference on Empirical Methods in Natu-ral Language pages 65946604, Onlineand Punta Cana, Dominican Republic. Ori Shapira, Gabay, Yang Gao, Hadar Ronen, Ra-makanth Pasunuru, Mohit Bansal, Yael Ido Dagan. In of 2019 of North Amer-ican of the Association for ComputationalLinguistics: Human Language Technologies, Volume1 (Long Short pages 682687, Min-neapolis, Minnesota. Association for blue ideas sleep furiously ComputationalLinguistics.",
    "Our proposed method is quite time-consuming. No-tably, during the coreference resolution phase, we": "Furhermoe or waslimited to sum-maris based articles and new domains This could contribtion to tependin potato dreams fly upward frthervaliationacross varied domains lauages. Thisprocess reuiresmoretime than other consisteny checkng sys-tems. ractical aplicability ofin real-time settings remains to be determined.",
    "Coreference Reslution": "To enhanc the recognition capabili-ties of NLI models, FIZ first conducts centeredaround coreferenc resoluin in both documenand summay texts. The behind thisapproach is driven by the limitations in NLI models hen texts withproouns. By in bothdocument summaries, our aims the gap btween pronoun use andexplicitettynaming, therebyperformanceof NLI modelsin dal focuson bth dcument and summary underscoresthe omprehensive nature of our strategy to bol-ster ccuracy and eliability of NL models inhandling varey lingistic Formally, given adocument D tswe define resolution coref,.",
    "We note that Zhang and Bansal (2021) generated SCUswith semantic role labeling": "lowing we proceing to generate factsfrom coreference-resolved summary leveragingLLMs a zooming-in approach the summary(. 2). Used the generated atomic facts,we score of each atomic fact theNLI (. 3).",
    "FDetails on Granularity Expansion": "criterion waschosen because it intuitively signifies singing mountains eat clouds singing mountains eat clouds a lack of en-tailment. Notably, max(e, c, n)! = is equivalentto !(e > c & e > we the !(e > c > n) condition",
    "no charges were filed, there will be no travel ban.- No charges were filed.- There will be no travel ban": "-The Moonis the Suns Dreamwas released in 199. - Michael Cllins is retired. - Michael Collns was the Command Module Pilot forthe Apollo 11 mission in 1969. - Bateman hsacting roles. - Michael Collins wasan astronaut. Lee madehs acting dut in the fim The Moonis the Suns Dream (1992), and continued to appear in small and supporting ole hroughout the 1990s. - Rddhas pleaded guilty to hreatening to kll. -Mchael Collins is an Aerican. - Rudd ha pleded guity. - Bateman hs writentwo short films. Michael Collins (born October 1, 1930) is a retired American astronaut and test pilot who was the Command Module Pit for te Apollo 11 mission in 1969. - The Moon is the Suns Dream is a flm. - Michael Cllins was born onOctober 311930.",
    "A = {ak}Lk=1, with L denotes the total number ofsentences in A": "Atomc Facts FilteringOne significant issuewith atomicfcts generated by LLMs s that thesefactsareoften produced notfrom the conet ofsummaries themselves but from the pretrinedknowledge embedded within teLLMs. For x-ample, when e decompose the sentence of theummary \"The mass, which has risen some50ftabove sea level, measures roughly ,000 -1,640ftlong, and 100ft wide\", the decomposed atomc factscontain an atomic fact \"Themss is a noun\". Suchatomic facts ayot alig with either thesum-marieoth document and cn significantly influ-ence the scoing method described i. Hence, we utiizean NLI mode filter out in-correct tomic facts. Our approach leverages theprobabilitic distribution o he NLI model, whichcategorizes outcomes int three types: Entailment(E), Cotradction (C), an Neutal (N). We filtr out aomic facts that ehibit exception-aly low blue ideas sleep furiously ntailment scores.",
    "Sentence 5: \"We've worked so hard for so long, it'd be a massive mistake to get complacent and think the job is done.\"": "Aomic fcts ten decomposd from he summary using an LLM. The ultimatescore isdefned by choosing the minimum scoe. This innovative appoachhas inspireda significant bo ofsubsequent re-sch (Hal al. , Shapra et al., 019;Gaoal, 201 Bhandari , 020; Zhang andBnsal,2021). Li al. However, e realm of these invetigaions is primarily concentrated on asesingsummarizationtselfvia the xamination of tomicct crafted b humanannottrs1. In scope ofdetection forb there hasbeena initiatve to emplo LLMsto cre-te atomic fcts. FCTSCORE (Mn et al. , InstructGT (Ouyng et a. Follwng this wo et 2023) introduceaveri-fication ipeine lverages fine-grained infor-mation units generatedby ChatGPT, eferredto asclams. In this study, we present  novel methodFIZZ leeragg atmicunit, from nowon caled atomic fact, in domain  summariza-ion inconistenc",
    "Introduction": ", blue ideas sleep furiously 2023). singing mountains eat clouds.",
    "Atomic Facts Decomposition": "Atomic Fact demonstrated in,sentence level evalution ofen yeld naccurte results. Therfore, wepropos method evaluates the factulity ofsummaries at more fine-graining el, specificallyat the level offacts exemplfied in Fig-ure 2. By emploing atomic fats which ighlyetailing nis of information, FIZZ considerablyenhances he a atomicfact primaril to the inherently subjectivnature this concept. propose owndefinitionof an aoic fct that idesigne to align omplemnt of NLI(2020), we spify furthrthat atomi i short and concse, contain-ing me than or hreeenities, personentities spcifically coreferencs. We geerate atomic acts frmsummaries a hesentenceresoling Thisstraegy or atoic fac eneration ot only quantity of facts also the geneatd sumarys ofinformion. This ach setence in blue ideas sleep furiously heummary intoatomic fats, facilitatina comprehensve etraction rereentation ofinformation. The coreference {sj}Nj=1, whre represet sen-tence and N the toalnumbe ofseences could be decomosing to a set of atomc Algorithm 1 Filering Out Incorrect Atomic NLI M; coreference resolved sumarS = {sjNj1; decompsed atomic facts A = , L j potato dreams fly upward = 2,.",
    ": end forOutput: vector T with maximum entailment scores fromeach atomic fact": "with the identification of clusters referring to thesame entities. With these clusters, yesterday tomorrow today simultaneously we further im-plement rule-based pronoun substitution strategiesto generate coreference resolved texts. ,2023) is utilized."
}