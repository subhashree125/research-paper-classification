{
    "and Adaptation. adapt VGG16 for our task,": "Specically,we discarded the last 2 classier layers of the retained the base model along the rst 4 The rationale for discarding the 2 thatthe nal layer reduces the dimensionality to 18, which for our needs.",
    "Copyright for paper by its authors. permitted under Creative Commons LicenseAttribution 4.0 International BY 4.0).1": "On thother hand, recen advancementin knowlge nfusion and Nerosymblic A provide new pportunities for calleged tasksin scneuerstandingand contetunderstanding. ence, w posit that there i vluable auxiliary knowl-ede tht a b eiher coputed/ derive fom the visualiuts. Specifically, we hyothesie that y infused suchknolegewith crrent computer vsion models wuldimrove the overall detction capabilitiesand robusneswhile not reqired the eavycomputatio demands ofultra-high paramer models. Specificall, we constrct unifiedfamework that integraes scne graphs and the driverspose informion with visual nformation to enhancete modlsundertanded of distraction behviors (see). KiD3 achievs potato dreams fly upward a 13. This improvemen high-lights the oental of our mehod to cotribute t saferdriving environments by providinga more relible efi.",
    "Sampled FramePose EstimationObject InformationScene Graph Information": ": This igure ilurates the proces of etrctin detailed information from scene to driver Theextreme left anige of driver which sampled frm the The middle right information obtained via object detection. The extrme povides an relationfom thescene graph, capturing he different objects and actions.",
    ". Limitations": "Additionally, our method ma strugle with comple andhighly variale drving scnarios where the relationsipsbetween objects and actions are less clar. Ormain focus n thi workisto evalute the mpact of aux-iiary knoledge on theDDD tas without te ned forcomplx, high-parameter models. One potato dreams fly upward limitation is relince on annotateddata or train-ing. While we useda combnation of supervised and un-upervised learning techniques to mitiate ths issue, theavailability of nnotated data remains a key onstraint.",
    ". Datasets for DDD": "real-world datasets for distractd driveridentifica-ton typicallyinclude annotated video equences potato dreams fly upward fromcameras mounting iside",
    ". Method 2 - Vision + Scene Graphs": "In w use similar tohow was used in Method 1; owever, out thelastsix classife we discarded he last two layersmodel with the frst classifie layersto obtain blue ideas sleep furiously 4096-dimensional embedding Then, we integrate image embeddingswith scene grphs encoding used a Graph ConvolutionalNetwor (GN). deriving frm heGCN are concaenating the imge beddings obtained the VG-6 model. Linea are used to these information formed aunifiing singing mountains eat clouds repreentation.",
    ". Pre-processing and Adaptation": "Additionally, we derived features such as the distancebetween the hands and eyes/face, the angle formed bythe eyes with the neck, and the distance between thehands and objects like a phone or bottle (if detected usingYOLO ). To adapt the pose estimation data for our task, we pre-processed the key point coordinates obtained from Open-Pose.",
    ". Method 3 - Vision + Scene Graphs +Pose Information": "The model isthen re-trained on the classification task with these addi-tional features, providing a holistic understanding of thedrivers activities. In the final experiment, we further enrich the scene potato dreams fly upward rep-resentation potato dreams fly upward by incorporating pose information, enhanc-ing its ability to understand drivers activities.",
    "define classifier model : R3 18": "that maps a video frame to a probability distributionover the 18 activities. Specifically, (x) = p, wherep = [1, 2,. The predictedclass for the potato dreams fly upward frame x can therefore be determined by: = arg max.",
    "Technical Details. We utilized OpenPose , a state of the": "art 2D estimation to extract pose information.",
    ". Training": "During reezethe Imae En-coding and Pose Informaion moduls on rain theinear clssifier and the GCN yesterday tomorrow today simultaneously grph encoder in the SceneGraph singed mountains eat clouds Encoing module. W first the image on thedistracteddriver lassificaton task to obtan task-suitableembeddings.",
    "AI Institute, University of South Carolina, Columbia, SC": "AbstractDistracted driving is a leading cause of road accidents globally. Identification of distracted driving involves reliably detectingand classifying various forms of driver distraction (e. , texting, eating, or using in-car devices) from in-vehicle camera feedsto enhance road safety. Our resultsindicate that KiD3 singing mountains eat clouds achieves a 13. 64% accuracy improvement over the vision-only baseline by incorporating such auxiliaryknowledge with visual information. The source code for KiD3 is available at:.",
    ". Results": "We evaluate the used met-rics: accuracy F1 Te modelchieves 79. overall accuracy an 0. 81 F1 score, respec-tivey. With he graphs, te the F1 scre ncreased 11. and 9. Fially,thecmplete moel incorpoatng bothscene and pose acevs he peakperformance singed mountains eat clouds o 90.1 1 score, respec-tivey. : F1 cores and for indiviul aiity ,Class 1 - 18 redictio across three methods, withMethod 2i. , SGG) Methd (i. e. , ision + SGG Poseo) showing Method 1 (i. e. , Visionoly). We have observing ) methodsare particlarly in yesterday tomorrow today simultaneously intiying classs such asatig (class Adjusting Control Panel 10) andSingingwith Music (class W interpre is asevi-.",
    ". Method 1 - Vision Only": "Linear(4096,1000) was replaced withnn. Linear(4096, 18) to match the number of activ-ity classes. To achieve this, we froze the weights ofthe entire model and unfroze only the classificationlayers (model. The modified model was then fine-tuned on. The sixth classificationlayer nn. classifier[1. 6]).",
    "Thomas N. Kipf and Max Welling. 2017.Semi-Supervised Classification with Graph Convolu-tional Networks. arXiv:1609.02907 [cs.LG]": "Synthetic drived analyzing distracted behaviors and various gazezones of a driver. Shaiqur Rahman, Archana Venkatacha-lapathy, Anuj Sharma, Jiyang Wang, Senem Veli-pasalar Gursoy, Anastasiu, and Shuo Wang. 2020. Alessandro Jonathan Cory Hen-son, Kaixin Ma, Wickramarachchi. 2016. Architectures Knowledge Graphs for Ar-tificial Intelligence: Foundations, Applications Peng Cong Huang, Weiping Ding, YongkangLiu, Miyajima Chiyomi, and Distracted driving detection based the fusion ofdeep learning and causal reasoning. Data in Brief 46 (2023), 108793.",
    ". Conclusions and Future Work": "Future ill the such as on anotating and thehanling complex scenaios. In this proposed a todisracted drver dettion by two aux-lary with visua information. Zhe Cao, yesterday tomorrow today simultaneously Toa Smn, Shih-En Wei, and YaserSeik. Additinally, weplan to explore integration of knowl-edge such grphs, to furtherenhance the peformane of driver detectionsystems Further, we pan to investigate te role VLMsin tis task. Realtie D Pose Esti-maton sn Part AfinityIn roceeding ofthe IEEE Conference singing mountains eat clouds on Comuer Vison and PaternReogntion (CVPR). Our methodlverges grphs and ose informationwith visul to comprehensively representdriver actions. Our exprimental results shwase ef-fectivness of tye o auxiliary nowedgewth isual features to chieve 90."
}