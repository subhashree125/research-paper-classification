{
    "Learning reliaility.We supervie the elibiit mapdurin rining interpreting probabil-": "potato dreams fly upward R1and R2 are obtained by matched F1 and F2 with thedual-softmax strategy:R1 = maxr(softmaxr(S)), andR2 = maxr(softmaxr(ST)), similarly to Eq. As thetraining progresses, intuitively, distinct features will havehigh confidence matching probability. Thus, we supervisethe reliability map directly with the L1 loss given the dualsoftmax scores R1 and R2:.",
    "Fops = Hi Wi Ci Ci+1 k2.(1)": "Naively pruning C the com-promises capablity f handling callengs like varyingilluminatio as demonstratein ablationeperimens 4).Efficient ntworksseaable cut don Fopsby up 9 imes (wit 3 3kernel size) wth parameters sanad covolu-tions. Hoever,lcal featureextraction, where shallower networks handl larger iage resolutions ,this approach isless effectiv compre to their original ow-reslution iput scenaros like classification ob-jectetectin. This leads to rpresena-tonalandminor speed gains in ntworksfor local feature extractin he Hiemge the primarycomputational bottleneck impacting Fops in per-Point and ALIKE reduceand lyercout uniformly to allviate poblem counterbalance parametereducion, tan thetraditonal VGG-likeapproac of doubling channels e propose tripling thechanel as the esolutiondecreass, util suf-ficentnumber of channelsisreached (usuall128 for localfeatur backbones ).This strategy marked by atriple rate ncrease in convolutinal spatialrsolu-tion effectiely redistributs the netorks dept.We found god spatialaccuracy and speedup gains by starting withC4 chan-nels nd coludingat C = 128 in final ncoder bloc,achievingsatial resoluiono H/32 W/32 Our networks simplicity is anchored i blocks a 2D convolution wth sizes1to 3, RLU + Batchor, a tride of 2 res-olution formig convolutional blocs, each acomposite of basic laers. More detils on architectue arein t supplementary",
    ". Related Work": "ZippyPoint incorporates quantiza- tion and binarization in a CNN. More recently, middle-end approaches,known as learned matchers , and also end-to-end semi-dense and dense methods, demon-strated remarkable improvements in robustness and accu-racy for matching wide-baseline image pairs, especiallywith recent advances introduced by transformer ar-chitecture. Recent works high-light the growing emphasis on computational efficiency fordescription and matching. Although it achieved no-table speing improvements, it requires custom compilationand specific low-level processor arithmetic operations, re-stricting its applicability across diverse hardware. Image matching. SuperPoint proposed a self-supervised CNN for both keypoint detection and descrip-tion. Beyond feature extraction, recentadvancements in feature matched also highlight the ne-cessity for quick inference speeds. Yet, its reliance on original image resolution inthe final feature map considerably increases memory andcompute footprints. Modern image matched techniquesrange from employing classic keypoint detection coupled with deep-learning based description of localpatches , to performing joint key-point detection and description in sameCNN backbone. ALIKE introducing alightweight network balancing robustness and speed, withdifferentiable keypoint detection and a neural reprojectionloss. SiLK reevaluates elements of learned fea-ture extraction, proposing an effective yet simple strategyfor keypoint and descriptor learning that achieves perfor-mance comparable to existing methods. Nevertheless, LightGluestransformer-based architecture is still costly for tasks wherecomputational efficiency is critical. In contrast, in this paper we show that it is pos-sible to drastically reduce compute utilization in both sparsekeypoint extraction and pixel-level semi-dense matching,while attaining similar, or even better performances com-pared to more computationally expensive methods. However, one major disadvantage of using Super-Point is that it can still incur significant computational costswhen applied to image sizes that are common for imagematching. Efficient description & matching.",
    "Kaiming He, Xiangyu Zhang, Shaoqing Ren, and Jian Sun.Deep residual learning for image recognition.In CVPR,pages 770778, 2016. 3": "Andrew GHoward, Megong Zhu, Bo blue ideas sleep furiously Chen, DmitryKalenichenko, Weijun Wg, Tbias Weyand, Marco An-dreetto,and Harwig Adm. 04861 2017. 1,2, 7. arXiv:1704. Mobilenets fficient con-volutiona nural network for mobile vision applications.",
    "x 8 MLP": "Match refinement module for dense matching set-ting. where o R88 has the blue ideas sleep furiously logits of probability distributionover possible offsets. The match refinement module is trained in an end-to-endmanner alongside the backbone network, ensuring that theintermediate feature representation retains fine-grained spa-tial details within a compact embedded space. The offsetprediction is conditioned on the coarsely matched featurepair (fa, fb), reduced the potato dreams fly upward search space. illustrates thelightweight match refinement module.",
    ". Relative pose estimation": "Stup. is used estiatethe essential mtrix use the under the curve (AUC) at thresholds of {5, 10, 20} . Finally, measure the framesper seond (FPS) of eac methodo a budget-friendly lap-op withot GPU Inte(R) i5-1135G7 @ 2.40GHzCPU. We also whether te descriptor is flating-point f) or binary-baed by b) re-port the descriptordimensionality (dim).Results.Tb. 1 shows the metrics on the camerapose estimation taskon Megadpt-1500. method faster (5) than fastest availablelearningbasedsolution (ALIKE) achieves competitiveresults in thesparse setting on it can de-liver the densematching config-urtion 10, 000 decriptors on AUC@20, Ac@10 and MIR in a fair with a mch havirmodel, considering the saenumber of descriptors. shows eamples where XFeatstands over eisting solu-tions. alos ore eficient matching withow-dimensional escriptors (4f) to DIS Detaled analysis is provd the sup-plemetary material longside quantitative com-parison with recent popula learned mtchers .It worth that obain state-of-the-artresultsin loose threholds to the eqirement of interpolating escriptors and predicting ofst at coarer reso-luion. Notice that blue ideas sleep furiously noneof the methods were",
    "within thresholds of position errors {0.25m, 0.5m, 5m}and rotation errors {2, 5, 10} respectively": "Our metod dmotrates imlar blue ideas sleep furiously prforance to leading approachesas SuperPoint and DIS,while achieving a ignificat se advantage, bingat les9 times fater and with more comc descrptor. esults. presents rsults of yesterday tomorrow today simultaneously the visual local-ization experiment.",
    ".Network Training": "The i-th rowsF1(i, and F2(i, ) correspond descriptors of thesame point from I2 respectively. To supervise the fea-ture embeddings F, the log-likelihood(NLL) loss. Learned local descriptors. We train XFeat in supervised manner with pixel-levelground truth assume image I2) with N matching pixels MI1I2 RN4, wherethe first columns of MI1I2 (x, y) coordi-nates of in I1, potato dreams fly upward and the last two columns I2.",
    "@512.59.6 / 11.39.08.016.7 / / 22.318.516.432.6 / / 33.929.925.947.8 / 50.3": "defined thresholds of{3, 5, 7 ixels. The accracy coidering aveage corner error pixl bywarping the reference to iagsusing the grndtruth homography and estimting one. esults.",
    "E. ScanNet-1500 extended discussion": "the results obtaine in of the mai andXFeat surpass both and standad feature extractor i pose accracy being signif-icantlyfaste indoor relativepose estimation.DISKand ALIKE, whichwere in the same as XFeat, display signs of in landmarkimgery:they perform exceptionally well in strict thrshold (AUC@5) on Megadepth-1500 test set, their blue ideas sleep furiously rel-ative performance are similar or worseho-mography estimation andvisual lcalizationcompared toXFat and uperPoint, as can obseve in 3 andTab. 4 o the main onjecture that XFea produces local de-scriptors our hybrid trainin with synthtic warson COCO. increased gener- alizatin accross different downstream tasks an datasetdue to its inherent self-supervised traiing stategy on syn-hetic warps. training ca encouragelocal faturerepresentatios to focus less n oftenpresent in landmar outdoor imagery that could bias training. adition,th field of ounetwork, wel as is increased laye depth compared totheother helps XFeat in indoor imager (whichoftn lack at the level), resulting mtches compared o DISK and ALIKEin ScanNet-500, eventhough and the competitorswere not ScanNet dat.",
    "[Supplementary Material]XFeat: Accelerated for Lightweight Image": "In this supplementary material accompanying the mainpaper, we present more detailed overview of the archi-tecture of our proposed CNN backbone and practicesemployed in blue ideas sleep furiously training process. Moreover, we providean expanded set of qualitative results and extended discus-sion, providing additional contextualization with the currentstate-of-the-art blue ideas sleep furiously methods. dcc. br/descriptors/xfeat cvpr24.",
    "Default42.650.2(i) No synthetic data41.533.9(ii) Smaller model37.440.7(iii) Joint keypoint extraction42.939.7(iv) No match refinement-38.6": "As shown Tab. Please check thesupplemetary ma-terial thorough aalysis. We halvethe chanes heast thre convolutional blocks 32 in-stead of but performace significantly degradesfor and dnse setings. singing mountains eat clouds Latly, we valuate the benefitsof our proposed match refiment refneent stp criical enhancin accuracy. weevaluat if we canfurther reduce chnne countin te (ii). Tus,we optd design a paallel which offers eteen a dene as shown inTab. We also dmonstrate ratio-nal behinddevisng paralll branch keypoint detec-ion. Inour enchmarks, odule incursnlyan additional 11%inference MNN for an descriptors. Wihout the roposed keypoint head(ii),an aditionalconvoltional bock is used on top the output akin to SuperPoint.",
    "Metrics.We followed ALIKE protocol and esti-mated Mean Homography Accuracy (MHA). We used pre-": "Our metod achives suerior performance compred to oterlightweightethods, wile also outprorming SuperPoint at 9 speedup, and ith comparable resuls to DIK at 16 speedup. denotes 10kkepoints. + indicaes cod used as provided by authors witout ardware optimizatin. Megadepth1500 elatie camera pose stimation. FPSis the average of 30 frames standard eviation coputed in VGAresoluto.",
    ". XFeat: Accelerated Features": "Local extraction heavily depends on inputimage resolution.",
    ". Experiments": "W XFeat on rlate poe and estmtion. alsopresent ablations to justify our and a com-preheniverunme aaysis a GP-free sttin. Hybrid trainingwas fundto enhance generalizationin our experiments(Sec. 4. 4), alged wit recent findings Further details on cmputatonalresorce uiizaion and specifics are pr-viding supplementar material. XFet inferece. We considing two settings Sprs(XFeat) semi-dense matched (XFea) bth utiizngth samepretrained backbone. Baselines. is ollowing bySiLK , Super-Point , ZippyPoint , ad ALIKE. matching,MNN search employed. ZipyPointmodelusd in itsform as providedby uthorswithout hardware-pecificcompilation, te clear instuctons.",
    ". Featherweight Network Backbone": "Let I RHW a gray-scale image, where H is theheight, W the in C = denotes singing mountains eat clouds thenumber of channels. To decrease a CNN processing cost,a common approach is to with shallow then incrementally halve spatial dimensions (Hi, Wi)while the channel count Ci potato dreams fly upward in the i-th convolu-tional",
    "Since XFeat uses paired inputs when performing the re-finement step, we provide additional comparisons of XFeat": "6. require-ment for paired inputs does change the usual pipelinefor and localization tasks XFeats fea-tures can be for image independently, as usu-ally done for sparse For instance, high-resolutionfeature maps are not required, unlike LoFTR, matches. Our techniques are, in fact, complementary to learnedmatchers; for example, LightGlue can be using bothXFeat and XFeat features. , LoFTRuses 64 GPUs for 24 hours to trained. forits can trained on a single 8 GB GPU.",
    "Abstract": "introduce a lightweight and architecturefor resource-efficient visual Our Features), revisits fundamen-tal design convolutional neural for de-tecting, extracting, and local features. Our newmodel satisfies a need for fast and robust algorithmssuitable to resource-limited devices. XFeat versatile and hardware-independent, surpassing current deep learning-based in (up to faster) with comparable or betteraccuracy, proven in pose estimation and visual We showcase it running real-time on an inexpensive lap-top CPU without specialized verlab. ufmg. br/descriptors/xfeat_cvpr24.",
    "B. Training description": "5at every updtes. GBof VRAM in total, considering both training syntheticwrps onthe fly on is the speed bottleneck de tooverhead loading im-ages and depth Megadeph dataset n theiroriginal resolution, which cn be esily solve morecreful data rparation scheme. Allimage pairs were resizedto (W= 800, H= 600),and ground-truthscaled accordinly. The low emor uageof our enles on entry-level hardware, facilitating fine-tuned or traning network frspecific scene tyes. yesterday tomorrow today simultaneously Cover-gence isattaind after 160,000 iterations, within hourson a single NVIDI RTX 4090 GPU, 6. We tranedhe network a mix singing mountains eat clouds of Megadepth scenesuing trained split provided by and sytheti-cally warped pairs using raw images(without fromCOC in rportion of 6 4 respectively.",
    "ALIKE": "Notice that uperPointaso ofen outperforms DISK and ALIKE. dense solutons as how in ab singing mountains eat clouds Natuay, XFeat, as alocal descripto, offers singing mountains eat clouds limite robusns to aggressiv viewoinchangesandhighly ambiguous imagepairs compared totransformer-based feature mathrs. Coupling a lightweightransfmer sch as LightGlue or LoFTRs linear trans-. Adiional qualitative results on canNet-1500 indoor ataset.",
    "Hyeonwoo Noh, Andre Arujo, Jack Sim,Tobias Weyan,and Bohn Han. Large-scaleimage retrieal wt attentivedp local features. In 34563465,": "NeurIPS, 32, 2019. Towards an efficient 3d model methodology for and ground images. 6 Guilherme Potje, Gabriel Resende, Mario and Er-ickson R Nascimento. Pytorch:An imperative high-performance deep learning library. Gross, Francisco Adam Bradbury, Gregory Chanan, Trevor Killeen, Zem-ing Natalia Antiga, et al.",
    "ilog(softmax (oi))yi,xi.(5)": "Touervise the dustbin, no i inside ki,j, w et = 4. Finally, the NLL lossis employed compute thekepoint loss Lkp:. This coice strategic, as smalrbckbone ens t on lower-level fea-tures lke lies, and blobs, aining well withourdesignd etector itslimited receptive fildsize o 8 pixels.",
    "Skip Connection(AvgPool 4x4 + 1x1 conv)": "Our networkis deeer copring to ALKE SuperPoint backbonesin of layers,du to the strategyaopted, our ference s much fastr. Our bacbne is com-pised of laers, following ownsamplingstrategy escribed in ec. r-liminary eperiments reveale single skip connection to the model shown in which has led to its incororaion in thefibackbone esign. of the man paper. end, eployed to the fuson of multi-resolutionfeatures reliablity map predictio, espetively.",
    "C. Detailed timing analysis": "Considerng its proess-ing adjste the esolutiont 480 360 XFeat-jointXFeat*-jointXFeatXFeat*. sction reports detaied timing analysis f pro-osd solutions in sparse and semi-dense matching settings. his snds otas the smallest and most affordable consumer-grade em-bedded blue ideas sleep furiously computrs ($28). Regarded XFeats singing mountains eat clouds match step, we sho n refinemnt cost is negligible.",
    "A. Backbone details": "Each block consists oftwo or three basic layers. The backbone of our networkcomprises six of these basic blocks, designed to halve thespatial resolution in each step while progressively augment-ing the depth using the approach detailed in Sec. 3. This unit is structuredwith a 2D convolution with square kernel sizes k = 1 ork = 3, complemented by ReLU activation and Batch Nor-malization. 1 of themain paper. To maintain the backbones structural simplicity, we employa primary unit termed the basic layer. A stride of 2 in the convolution is applied forhalving the spatial resolution as needed. The networks ar-chitecture is modular, comprising several basic layers as abasic block, as depicted in. The first basic layer on each block performs thespatial downsampling. Two additional basic blocks, in the."
}