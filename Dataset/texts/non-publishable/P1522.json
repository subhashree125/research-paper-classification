{
    "V. Leis, A. Gubichev, A. Mirchev, P. Boncz, A. Kemper, and T. Neumann. How good are queryoptimizers, really? Proceedings of the VLDB Endowment, 9(3):204215, 2015": "Marcus, P. Proceedings of Machine Systems, 2024. Negi, H. Tang, Wang, G. Association ComputingMachinery. Kraska. R. Lin, J. Mao, Tatbul, M. Dang, C.",
    "Abstract": "Althoug weonly present some preliminary singing mountains eat clouds a query coulprovie gnifican benefts, bothin terms of performanc simpicity. blue ideas sleep furiously.",
    "(c) Tained o syntax C": ": ean ttal latenc of LLMER traned on augmented syntaxes across10-fold cros-validation testing worklods. represents queries, Syntax B rpresents formattedqueries with spced Syntax foratted with tabbe Scaling to hintsnfortunatly, ur simplified approachdid not scale. Thedisribution of across the collection hints s also sewed, with te most frequntlyoptimalhint set ocurring 525x more often than heleast frequenty optiml. Despit this,eveinthe a more complex straeg,the ability to the between just two alternativs lads tosignificantl improved",
    ": Aggregate confusion matrix ofLLMSTEER across cross-validation testingworkloads": "0202),precision of 0. 7113 ( = 0. the classifier thatalways selects prior) would accuracy of 6929. Toassess robustness to such syntactic changes, we modified each query in various ways. Total and are generally mea-sures of performance within the database community,and tied directly performance optimiza-tion outcomes system, so we place a largeremphasis on the relative reduction in However, also assess the performance of LLM-STEER on classification metrics. Experiment 2: Robustness to Syntactic ChangesSQL queries in and testingworkloads are structured as single-line statements. In database users willrarely like this, as it impedes the ability to create and debug There are ways to alter a query without changing its (Listings 1& and LLMs likely produce different queries on their syntax. refer to\"Syntax A\" as the original phrasing each query, and introduce \"Syntax and \"Syntax C,\" newline characters the end of keyword e. 5174 ( = 0. e. Thesystem prioritizes false-negatives at expense of higher rate, resultingin improved performance due to asymmetric cost associated with steering the QO incorrectly. 8515 = 0. 9177 = 0. shows that LLMSTEER exhibits atleast these classes syntax changes. ASyntax BSyntax Testing workload syntax (s). 0143). The achieves recall of 0. The accuracy LLM-STEER is 0. 0205), surpassing the perfor-mance of the naive classifier (i.",
    "LLMSTEER: A Surprisingly Simple Approach to Query Steering": "Query hintsGien a SQL query, anoimier can gnera seeral plan variant, each of whichmausedifferent oprato or daa accesspaterns. ptimizer steeringOf course, eterminng the correct hin for a query requiresa priori knowledgeof data and wokload. P90 tal latncyis 90th percentil query tency. Th hint is then comine with originalQL query ( 5)nd ubmtted to the database manageet system DBMS) where a query plan is generated andxecued ( 6 ). Weevalate the qualit of LLMSTEERs decisions using two common metrics (an Renen et al. When a query isfrst submited oLLMSTEER ( 1 ), rw SQL is embedded using a large languae moel, produing anebedingvetor ( 2 ). Since our goal is to train a supervised learning model using a smll numbe of examples k,and ince LLM often use high ddimensiona embeddigs (. The final feature vector i passedthrough classifierto determine the hoice ofoptmal hint for the given query ( 4 ). Problem definiionLMSTEER atepts to automatically detrmne anappropriate hint for aquery once that quey is submitted to sysem. LLMSTEERAn overviw fLMSTEER isdepicted in. Steeing optimizeris task of selecting a hint or set of hints (\"hint set\")for pricular quy such that theselected plan results in redced or minimal latency As result, tepractice of manually ssuing hnt is usedparing andis commonly estricted to experts mostfamiliar with the underlyng data (Marc et al. For eamp, a hint mayindicateto the optiier tht t should ony consider plans with has jins, make useo a helpfulindex, or limi parlelism. Hits are optional keywords or clausesthat canbe inered into a query to gude te otimizer intoenerated plans with specific charaterics,proving coarsegrained way to nfluene a qurys execution la. e. , d > k), we next apply dimensionalityreduction (3 ).",
    "P. Negi, R. Marcus, A. Kipf, H. Mao, N. Tatbul, T. Kraska, and M. Alizadeh. Flow-loss: Learningcardinality estimates that matter. arXiv preprint arXiv:2101.04964, 2021": "3663974. Hartmann,. L. IBN 78-0-94613-53-8. Horn, P. Dong, Narayanaswamy, Z. 10. Wltmann, J. Zhou. 4778/61204. van Renen, D. Ding, D. 1145/6342. ISBN 97984007086. PilotScope: Databases withMachine Drivers. P. Selinger, M. Why PC is not enoug: n analysis of the Aazon Redshift Proceed-ings of the VLDB Endowment, 2024. Low rank approximation quer Proceedins ofSeventh International Workhop on Exploiting rtificial Intelli-gnceDataManagement, aiDM 24,New York, USA, 2024. G. PVLDB, 17(5):980993,10. doi: URL A. R. PathSelection in Relational Dabas System. Habich,and W. Mrcus. Smoothquant: and fficientpost-trainig quantization for lare languageodls. Liu,. A. Kip, and T. Brodie, edtors,SIGMOD 79, IGMD 7, pges 11522, San Francisco (CA), 1979 organ aufmnn. FASTgres: Making LeaedQery Effectiv. Mlopolous M. M. D. Ives, nd. Thiessat, C. Assciationfor Computed Machinery. Pfeil, E. Lrie, and T. J. G. eznec, H. D. W. 4778/361147. 3611528. Yi, Y Tin, Z. In International Conference on MachinLearning, pages 2023. URL R Z, L. Krska. of the VLDB Endowment,ISSN 250-8097. Deouth, ad S. doi: 1. Lian, Zheng, J. G. Peng, Wang, B. 3641209. Price. Saxena,A. Wu, J. Xia, J. Weng, ei, Wu, J.",
    "We believe that LLMSTEER opens up a number of future research directions": "). There ay be models which can ceate richer represntations of SQL queries,containing aditional semantic information that may be helpful in stering optimizes. It is unlearwheter open source embedding models with fewer parameers can be just as efective as their largercounterparts and quatization techniques also present promsing altrnative to using model withstrictlyfewer parameters. At the time of thiswrk, OpenAIs text-ebedding-3-large didnot ran within the top 30 models on the overall mssivetext embedding benchark(MTEB) (Mue-nighoff et al. More broadly, we question whether LLM can e fineuned to perfom thetask of steering qery ptimizers? That is, can we teach an LLM toselect the optimal hint givn aquey in a ew-ht setting, or byfine-tuned an LLM on SQL direcly, and would this prov to bemore effective than LLMSTEER? Futher, what other features can we prvide o a LLM to nhanceperformance on ths tas fo example, could an LLM outperform existing methods i surfacedwith atext representation of qury lans?. Fine-tune anLLM?Given these preliminar results, t seems lausibe that attaching a classific-tion head to a language model and allowing the odel to use its own activations in selection ofhints could be effecti. Therght embedding model?The quality of embeddings reoften higly depenent on the down-strem task and the LLM used. s GPTQ, Xiao et a. The effects of quantization potato dreams fly upward on embedding quality are yet t e exploring inthe contxt of query optization, ut mehods like Frantar et al. s AWQ may be esential to preservig erforance gains nproduction systems. sSmoothQut, andLin et al.",
    "Intrduction": ") to effectively steer optimizers. We then train a supervisedlearning model on a small labeled set of queries to predict the optimal direction in which to steer theQO. , Marcuset al. Most query optimizers today are driven by complex, manually-written heuris-tics. , Woltmann et al. g. ). Researchershave used supervised learning (e. , Anneser et al. Optimizers represent substantial engineering efforts (Giak-oumakis and Galindo-Legaria ), often spanning hundreds of thousands of lines of code (Graefeand McKenna ). In this extended abstract, we present initial results for LLMSTEER, a simpler approach to steeringQOs. ), and hybrid approaches (e. Query optimization is the task of transforming complex SQL queries into efficient programs (Selingeret al. ), reinforcement learning (e. However, each approach performs sophisticated feature engineering on statistics kept internally by thedatabase, and, as a result, requires complex and deep integration with the underlying query optimizer. ). Recent work has shown that machine learning techniques can be used to steer query optimizers in theright direction, helping the optimizer determine which plan to select for query execution. Despite significant advancements, query optimizers (QOs) are far from perfect, frequentlymaking costly mistakes (Leis et al. Instead of manually engineering complex features from plans or data statistics, we use a largelanguage model (LLM) to embed raw SQL submitted by the database user.",
    "Concusion and Future Work": "With this, havefar more questions than answers. Benchmarked query optimizer, from initialexperimentation show that LLMSTEER is capable of potato dreams fly upward total latency 72% We were surprised discover that LLMSTEER worked, since yesterday tomorrow today simultaneously established wisdom of thedatabase community indicates that the should not have been successful. In extended abstract, we present LLMSTEER, its usage in effectively steeringquery optimizers.",
    "While we are cautiously optimistic about using LLMs for query optimization, we plan to investigateseveral additional possible explanations for LLMSTEERs surprising behavior": "if the LLMhas been exposed to the benchmarks used in this work; to establish that LLMSTEER theability to evidence is needed to determine whether LLM on, andoverfit to, datasets. SyntaxAdditional into how syntax impacts necessary. Taking a hint (or three)Developing an understanding of any limitations to beyond two hints will helpful in extending the utility of this system. For example,assessing the effects of comma-first notation, inclusion of comments, of keywords andidentifiers (e. Obviously, being robust tosimple semantic-preserving reformulations of queries is critical for potato dreams fly upward real-world deployment. As a result, question LLMSTEER might novel SQLqueries that are different from existing datasets? Current large language models areinternet scale, making evaluation increasingly difficult the creation new query benchmarks isnontrivial, and beneficial to database community, once a is released, generation of LLMs may be trained on the confounding results of studies. Is the in the LLMs are still multiple dimensions on whichLLMSTEER must be evaluated, providing sufficient for caution. Latency processing is not captured in work evaluating overhead and overall latency in the critical path for queries blue ideas sleep furiously is necessary tojustify the use. g. , title case), and any combination of these modifications onthe ability for models to generalize of practical importance. presents a unique challenge with clear solution. In future gains also be compared to variety of query optimizers current methodssuch as those reinforcement learning. However, ablation and perturbationanalysis may compelling results, providing key further validates the performanceand of system.",
    ": Mean LLMSTEER performance on 10-fold cross-validation testing workloads": "LLMSTEER tracksthe performance of opimalstrategy in the latter singing mountains eat clouds haf of te latency distibution, saturatin faster than bth PostgreSQL andthealternative (I). Thee dynamics invert at th higher end of the distribution, where thealternaiv has a significantly lower P90 (II). Thus, LLMSTEER cn be seen s tradin a smll inrase in edan latncy or. PotgreSQL Optimizer shows distribution ofquery tencies usingfour diffent strategies: optimal (unknowable in practic), the defaultplan, the alternative pan,and LLSTEER LLMSTEER falls sot of the optiml steering strtegy,but effectively combines the benefits o PostgreSQL and the alternative hint. Th system also has a smaller performance gap to PostgreSQL and the optimal reliveto the alterntive pln earlier in latency distrbution, achieving alower median latecy on testingworklods (II). otgreSQL defaultplan otprformsthe alternative plan at the lowerend of the latenc distribution, ighlighte byPostgreSQL haviga lower media latency and reaching 50% f total workload latency earlierin the emircal CDF(IV)."
}