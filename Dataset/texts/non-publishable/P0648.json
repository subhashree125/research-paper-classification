{
    "Generate a full quarter of an NBA game using the detailed player-team affiliations data the following are met:": "1. 25 and 0. 35. 2. A teams efficiency score, showing potential points per 100 possessions,can impact game outcomes. 3. Adhere to the example play-by-play description format provided. 4. 5.",
    "Ryan Burnell, Han Hao, Andrew R. A. Hernandez Orallo. 2023. the structureof language model capabilities": "2023. Sklls-in-conet pomptng: Unlocked com-positionality in large languae models. Preprit,arXiv:2308. 00304 Zhiy Chen, Wenhu Chen, Caese Smil, SmeenaShah, Ina Borova, Dyln Langdn, Reema Moussa,Matt Beae, ing-Ho Huang, Bryan Routlede,andWilliam Yan Wang.",
    ": Each action s led to thatdescribe it The templats nhaed by GPT-4o toincrease their lexical diversity and quality": "arrative Anexampe f actions nd theirtemplates is in. Durng template linked to a sapled has equal of used. Contrllig Narrative Complexy. Weadjustthe complexity of the game by changin of per turn. Longe turns can extend thoverall whereas turns createmorefreqent opportunities, as turnoftenresultsin an to score. 65 actions. This reults in ascoring to non-scoring action rati R = urin synthesis we to generate narrativeswith different tun lengths hle keepig table. This approch allows us to roduce narratives scoing ratios such as R = 1:, 1:3, 1:5, effectively capturing the dynamics of actualbasketball gms. Rendeng theWe begin slec-ing turn lengthsfnction G 2). We evaluate ths pathsreject any abaktball to of expert rules. The of a tun ascore is determned using Scor theinvoled 1 toindcate scoring and 0otherwise. We rpeatedly sample from graph tofind a path that meets our length n scoring criteria. then select  descri the chosen path. Nex, relevant tamplayer profiles, e. g. ,plaer-P is withthe guardsname. Each is tgedwith a timestamp indicating e elapsd the previos ction. We calculate time intervals using rea andcreate Gaussian a for eachaction type. W alter-nate between the pofles of the two teams the game. This process isrepeatd until we havereate eough to complete game uarter,after which we oceed generate remainingquaters complet the full game narrative.",
    "Divide-and-Conquer Results": "In , we compare the analytical reasoned ca-pablties of leading LLMs6 Our evaluation showstt both GP-4o nd Claude-3-Opus are effectivefor this task, with Claude-3-Ous outperformingespecially in mnolithcprocessng Mono scenar-ios, where entire game narrative is processed aswhole. This indicatesthat the model provides eactly accuate results inove60% of cse and iswithin a minimal errrmargin T = 0) in >9% o the scenarios. This supe-rior performnce may stem from Claude-3-Opussadancd logical reasoningand computational abil-ities.Theexene for used thisAPI is$15 / millon tokens for input and $75 / mil-lion token for output. 61% and a DCA scoreof 98. 1%wth a bath size of10 (nC-10) This sugests that 6he lineup includes singing mountains eat clouds both proprietary and pn-sourcemodels: blue ideas sleep furiously Llma3-B-nstruct Llama3-70B-Instruct (Meta,2024), OpenAIs P-4 and GPT3. 5Turo (OpenAI, 2024),Gmini-Pro-1. 5 (GeminiTeam, 2023) and Anthopis Claude-3-Opus (nthropic, 2024. These LLMs are availble totheresearch community from March to May 2024. The modelsan erformcmplex nalyses, handl multi-step procedures,and ackle highr-order math and reasoning tasks",
    "Related Work": ", 2022; Furman et 2022). complex and multifaceted. ,2023b; Lu et al. , 2023; Divekar and 2024), we by created diverse narratives that varyin style, complexity, and level detail to betterassess LLM effectiveness. ,2020; Gu et al. , 2021; Thomson et al. , 2023). It influences the analysisof domains like game reviews and singed mountains eat clouds gameplay logs,enhancing our understanding of gameplay com-mentary dynamics (Lukin, 2020; et al. Build-ing research by Hu et al. Ef-forts to enhance reasoning abilities includeprompting, supervising fine-tuning, and adjustmentsto decoding et al. , 2023a; Holliday and Mandelkern, 2024). , 2019; Huang et al. , 2023; Aroraet al. , 2020;Hu 2024a,b). , 2019; Maoet al. , 2021; Patel et al. Numerical reasoning is applied financial ques-tion answering and mathematical and numerous have been veloped these purposes (Amini et al. , Gholipour Ghalandari et 2020;Lebanoff et al. , 2022; Liu et 2023; Zhao et al. , weconjecture that LLMs aggregate informationis critical addressed reasoning chal-lenges. , 2023;Zhao et al. ,2021; Chen et al. , Edouardet al. , and Chang, 2022; Hu and Shu, 2023; Zhaoet al. (2024b), our studyexplores how well LLMs can track actionsacross narratives and accurately link enti-ties in-depth game With SPORTSGENfor (Veselovsky et al. , Ahn et al. Our explores a ability to analyticallysolve using divide-and-conquer strate-gies and al. , 2019; Merullo et al. , 2023a; et 2023; Zheng et Cheng al. Success in reasoning hinges effective content se-lection. , 2017; van Lee et 2017; al. , 2024; Wangand Zhou, 2024). studies have placed a growing em-phasis on LLMs reasoning exploringvarious types such as deductive, abduc-tive, and multi-hop reasoning (Bostrom et al. In our paper, we propose a quanti-tative approach to by requiring the LLMto and facts. , Chen et al. , 2021; Zhu et al. Similarto how frequency indicates salient content in multi-document summarization (Fabbri et al. Our focus is divide-and-conquer strategieswhere LLMs particularly effective. , 2019;Cobbe al. , 2023). Sports data plays a pivotal in various lan-guage tasks, such as real-time summarization ofgames, data-to-text generation, analysis ofcommentator blue ideas sleep furiously bias (Wiseman et al.",
    "Yebowen Hu, Kaiqiang Song, Sangwoo Cho, XiaoyangWang, Hassan Foroosh, Dong Yu, and Fei Liu. 2024a.Can large language models do analytical reasoning?Preprint, arXiv:2403.04031": "01772. Sportsmetrics: Blending text singed mountains eat clouds and numerical data tounderstand information fusion in llms. 10979. Preprint,arXiv:2410. Hu, Xiaoyang Wang, Yao, Yiming Hassan Foroosh, Dong Yu, and singing mountains eat clouds Fei Liu.",
    "In our paper, plays and actions are used interchange-ably to describe significant game actions": "<player-F> executes a delicate fingr roll layup. Action- block <player-PG> indivdual defensive payresuted in personablck the <player-PG> sooing bock foul and <player-G> uring the ply. fails to convert  20-foot jumper. <player-G> a jumpshot. <player-PF> misses a 20-fot jumpe. <playerG> misses a 4-foot layup. <playr-SG> a26-footthre-point shot with anassistfrom Action - miss <player-PG> fais to make 25-fot stadard jump shot.",
    "Michihiro Yasunaga, Xinyun Chen, Yujia Li, PanupongPasupat, Jure Leskovec, Percy Liang, Ed H. Chi,and Denny Zhou. 2024. Large language models asanalogical reasoners. Preprint, arXiv:2310.01714": "for Linguistics. Dongxu Zhang, Van Prashant Gngal, Barrett MartinLattimer, and Yi ang. Haoxuan You, Rui Sun, Wang, Long Chen,Gegyu Ayyubi, Kai-Wei Chang,and ShihFu Chang. yesterday tomorrow today simultaneously. In of Associationfor Comutatioal Lnguistics: EMNLP pages112911303, Singapore. IdealGPT: Iteratively de-composing vision ad reasonig larelanguag moels. hallucination detetion hrouh perturbation-bsed stheticdata generation system In the 62h Annul Meeting of the Aociation forComputaional Linguistics for Compu-tational Linguistcs. 2023.",
    "To dtermine the total ponts sored b each team, Ill aalyze the play-by-play identify he": "Charlotte Hornets:1. Hayward pullup jump shot (5:53) - 2 Jalen makes layup (5:06) 2 points4. Gordon makes free throw 1 2 - 1 point6. Gordon Hayward makes free throw 2 (4:24) - 1 points for Hornets: 2 + 3 + 2 + 2 + 1 + 1 = 11 points San Antonio Spurs:1. Jakob Poeltl - 2 points2.",
    "7github.co/gkamradt/LLMTest_NeedleInAHaystack": "the context the original narratives toa symbolic are syntheticnarratives using team profiles; Scrambledmismatch NBA players and teams; Fictional NBA player names with imaginary FIFA; and Symbolic substitutes withlabels like Player 3.... These changes arenot expected to impact the yesterday tomorrow today simultaneously models ability under-stand actions attributing them to teams.The actions in play-by-plays remain un-changed as they characterize relationships betweensymbols, such as Player 1 assists Player Thismethod game input reliant on and more singing mountains eat clouds on symbolic elements.We examine models ability to calculate using synthetic and present scores in . Our findings original with fictional names orindices can variably impact model such as Llama3-8b-Inst and Gemini-Pro-1.5 score too low for us to draw definitive conclu-sions. Even models such as GPT-4o and experience some declinein performance. Claude-3-Opus has demonstratedgreater resilience than when faced withaltered contexts. suggest that have substantial reasoning skills, language context to perform well; reasoning has room for improvement.",
    "Frequent scoring presents a challenge for LLMs intracking and aggregating team points, especially": "5Tubo GeminiPro1. during ntese priods,. We applythree settings: (a) four snhesized narrative setswithS:NS ratiosof 1:5, 1:, 1:3, and 1:2,where1:2 represents a higher proporio of reevantin-formation (se , left) (b) we group synthesized aratives into four quartles based on tetotal umberof scoring actions (middle); ad ()for comparison, we also group narrativs into ourquarties basd on their legth, measured in tokencount (see , righ). In , w eport CA score for Llaa3-8B-Inst and Llama3-70B-Inst to see ow LLMperform across various information densities. In this study, exmne ow odels hanlegame uarters withvaryig lvels of informatin denity. , the last quarter of a bas-ketball game hee scoring spikes. When nalzing narra-tives by length, the models exhibi a more gad-ual performane decease. g. 7 OiginalSrambled FictionalSymlic DC (%) Claude3OpusGP4o Llama370BInst Llama38BInt GPT3.",
    "Abhishek Divekar and Greg Durrett. 2024. Synthesizrr:Generating diverse datasets with retrieval augmenta-tion. Preprint, arXiv:2405.10040": "Asummaizatn daaset and abstrac-tve hierarhical model. Associaion fo Computational Lingutics. inarge moels through wrdroblems. Gaur and aunshi. Julias, Malta. the 3r Language Meets (Wordplay pages 4458, Settle,United Sttes. 2017. InFidings of the Assoction for Com-puatinal Linuisics CL pags Canda. Furan, Edan Toledo, Jonathan ad 2022. uyet V. Association Computational Lin-guistcs. Associationor Computationa Lin-guistics. INCOMALtd singed mountains eat clouds Alexander Fabbri, Irene i, Tiawe She, Suyi ndDragmir Radev. ConstraintChecker:A plugin for lage language eason knowege In Proceedings ofthe of yesterday tomorrow today simultaneously theEuropean Chpter of theAssociatonfor(Vue1: Long Papers), pags 1471, St. Do, Tianqin Fang Shizhe ZhaoweiWang, Yangqiu Sng.",
    "during Hus internship; KaiqiangSong and Sangwoo Cho were full-time researchers at TencentAI Seattle, USA at the time of this work.1": "2024). 2024 Chu-Carroll et al. Thse gaes include a mix of ex-pecd and unexpected evens, presenting uniquehallnge for reasonin asks. Our research invlvesusig LLMs totrackscoring actons within these detiled gameescriptions and to ink entities for comprehesivegme analsis. Yanget al. , 2023; Zhao et al. LMss reoing abilities, incluing multi-hop,deductive,inductive, and abducive reasonig, havearnered increasingattention (Hu and Shu, 203;Shiet al. , 202a; Duan blue ideas sleep furiously et al. (2023) potato dreams fly upward introduce a dataset designedoevaluate lan-guage models on multi-step reasoning with 1,000-word murder mysteries and object placemn. The play-by-plays cap-ture keyacions of the game, suchaspasses, shots,andfuls, along with timestampsand team-playrafiliations.",
    "Few-Shot Prompting Narratives": "<Example 1>2:30Clint Capela makes 2-foot layup (Trae Young assists)2:15Jaylen Brown makes 3-point jumper (Derrick White assists)2:00Dejounte Murray makes 20-foot jumper1:45Jayson Tatum makes 18-foot jumper1:30Trae Young makes 3-point jumper1:15Kristaps Porzingis makes 10-foot jumper1:00Dejounte Murray makes 18-foot jumper0:45Jaylen Brown makes 2-foot layup (Jayson Tatum assists)0:30Trae Young makes 3-point jumper0:15Jayson Tatum makes 20-foot jumper <Example 2>8:13Rui Hachimura defensive rebound8:00DAngelo Russell makes 20-foot jumper7:45Devin Vassell makes 25-foot three point jumper (Tre Jones assists)7:30LeBron James makes driving layup7:15Keldon Johnson makes 10-foot jumper7:00Anthony Davis makes 15-foot jumper6:45Victor Wembanyama makes 12-foot jumper6:30Austin Reaves makes 25-foot three point jumper (DAngelo Russell assists)6:15Devin Vassell misses 20-foot jumper6:13Anthony Davis defensive rebound",
    "#Eample Play-b-Play Descriptions:": "TimeTeamPlay12:00Team-2player-3 vs yesterday tomorrow today simultaneously yesterday tomorrow today simultaneously",
    "Turn-by-Turn Game Generation.ur SPORTSGEN rendes realisticsports narraties using a turn-by-urn which mirrors back-and-forth": "If the endingturnexceeds this limit, it will trcated. Inhe raph, significant actionis rpresented as a transitions betweenndes show how eamcooperateand exe-utetheir tactics. After tu, pos-session generally hfts to the opposed team. correpondto theatin miss. Thi action gaph helpsto visuaize ams flow within each turn. reer ach sequnce of ths a a turn, charaterize ued a arkovgrph. gaphegins and endwithspecia ndes thamar the sart ande a turn model includes 6key actions; a example in Apendix 5. Thedeense tries to stop them by andrebouning. consis f altenated between thetwo teams with urn give an allottedtime Eac basketball game 8 Our approach continues add until nearinghe end limi.",
    "GeminiTeam. 2023. Gemini: A family of capa-ble models. arXiv:2312.11805": "In Proceedings of the Meeting of theAssociation for Computational Linguistics, pages13021308, Online. DemianGholipourGhalandari,ChrisHokamp,Nghia The Pham, John Glover, and Georgiana A large-scale multi-document summarizationdataset from Wikipedia current events portal. Revisiting the roles of textgames. Yi Yao, Chuang Josh Tenenbaum, andMo Yu. Association forComputational Linguistics.",
    ": (Left)Synthesized wih varyingS:NS ratios. (Middle)Nrrativesgrouped by # actios.Narrtives grouped by  of kens": "Qualitatv Evaluaion. A human GPT- review 100narratve snippets from each source, with each snip-pet ontaining 10 play. preferred narratve or opt for a tie, als provd-ing justifications. The showthat ou humn expert SportsGn narratives39% of the time, tied 9%, and fvos NBA narra-tives of the tme. GPT-4s anlysis was quitesimia, with 39% Sportsen, 7%ties, and fornarratives.",
    "Analytical Reasoning withDivide-and-Conquer Strategies": "Our research uses analytical to accuratelycalculate team points from sports narratives. Wespecifically focus on ESPNs NBA game play-by-play descriptions On average, an NBAgame consists of plays and 6,229 withthe longest narrative containing up to 7,322 tokens.To succeed task, an LLM must understandthe basic rules of game, distinguishing betweenscoring plays, such three-pointers field goals,and actions like passing. Further, themodel must correctly attribute scoring actionto appropriate player and team, requiresnuanced reasoning. Finally, the LLM must aggre-gate all the scored points to determine the finalscores for the teams. the LLM critical areas: knowledge pointreferencing, effective aggregation. Errorsin of these can lead to incorrect results. Player-Centric particularly in-terested in LLMs can reasoning in more and manage-able context using a divide-and-conquer strategy.For instance, sports can be segmentedalong multiple dimensions. In player-centricdivision, the LLM player performancebased play-by-play Here, the LLMreceives a list players, their team affilia-tions, and is tasked with summarizingeach players throughout game.The final are presented in JSON this, we link the individual players scoreswith their respective teams to calculate the overallteam scores. This approach employsLLMs to track individual player performances, al-lowing for a of team scores data. the burden on LLMs to usemulti-hop reasoning for inferring team scores fromplayer scores. Batch-Centric Division.Instead of narrative at once, we break it downinto batches, each In our ap-proach, each batch is analyzed bythe LLM to determine the team points for seg-ment. This approach the LLM to narrow itsfocus, helping it where errors mightbe occurring. It also eases the burden LLMs, asthey are not required aggregate points to deter-mine total scores from batch thisis handled through direct calculation. We comparethis approach to monolithic anLLM the entire game in oneattempt. Interestingly, would expect that whenLLMs are provided with data in batches,they would perform better in this more granularand manageable setting. In 5, we report notablefindings that highlight the limitations of state-of-the-art LLMs when using these divide-and-conquerstrategies.We focus on identifying data LLMs are particularly Real-worlddata can be complex and multifaceted. focus-ing on sports narratives, aim to understand thelimitations of LLMs in reasoning and informationaggregation, since complex requireLLMs relevant information effectively.Our research does not introduce new methods ofreasoning. Instead, it uses chain-of-thought prompt-ing, which enables tackle inher-",
    ": compare human narraives hose ofSportsGen few-shot prompting. Promping gene-ates narratives deviaing from typical basketball game": "In , we experimentwith varying toleranc levels (T = 0, 1, 3, , 10) toassess the blue ideas sleep furiously impact o this parmeter. DCA. We note thatadjusted the tolerance treshol generally dos nalter te elative rankings o models. Lower-performing modelsoften result in accuracy in the low single digis. Howeverincreasing the tolerance tends to narrow yesterday tomorrow today simultaneously the perfor-manc ap among different models Impotantly,acuracy cores alone my not be th mostsuitablemetricfor valuation. 56%. For example, moel Gemini-Pro-1. 5 reports naccuracy o just 4. Its perfrmance remainthe lowest ven when tolerance is inreasing t 1points (T=10) resulting in the loest DCA score of18. Such findings highiht Gemini-Pro-1. Accurc vs.",
    "Introduction": "This isespecially true when over longitudinaldata (ukasz Kidzinski and Hastie, 2021). For when assessing patient outcomes singing mountains eat clouds over yearsto the effectiveness of new singing mountains eat clouds must accurately track provideinsights into trends, patterns, and potential causalrelationships",
    "System Message": "), key moments (e. , fouls, timeouts), player and ensure narrative is engaging and reflects the pace and intensity of an. Your task is generate detailed for singing mountains eat clouds quarter an NBA game,capturing the dynamic flow of the game. This includes player actions (e. , blocking,stealing, etc. g. g.",
    "Hongyu Zhao, Kangrui Wang, Mo Yu, and HongyuanMei. 2023a. Explicit planning helps language modelsin logical reasoning": "2023b. Zhu, Weqed Lei Hang, ChaoWang, huo Zhang,Jiancheg , Fuli Feng,Chua. quesion answeringbechmak on ahybrid of tabular an textual contentin finnce. rXiv:2105.",
    "Ratish Puduppully, Li and Mirella Lapata. 2019": "Datato-text geneation with entty Pro-eedings ofthe 57th Meeting of he Asso-ciation Computational Linguitics, Florence,Italy Peprint,arXiv:308. 06834.",
    "for Analytical Reasoning": "ESPNs NBA game play-by-play dscriptons. We particularly interested in exploring LLMscan peform reasonng ina morefocusd and managble using divie-and-conquer strategie ation (Savage et al. , 2023). Sorts narratives,forinstance, cn along multiple We furtherintrduc newDiscounting Cumulative AccuracyDCA) etric. differs from small magin of erro. This helps us identify sce-narios where LLMs significantly hllucinate, ratherthn grunded the narratives. urexperments reveal limtations of tte-of-the-art LLMs n using divide-and-conquer strate-gies for nalytical reasoning. With we further LLMsreaoned abilties n complex ad noel Our approac,SPORTSGEN, enhances the cntrol over narrativecomplexty whencompared to human-writte gamenarratives fewshot prompting.",
    "To determine the total points scored by each team, we need to examine the play-by-playdescriptions and identify which team scored the points in each play. Heres the breakdown:": "4. Jakob makes (Keldon assists) - San Antonio Spurs score 2 Gordon makes 15-foot pullup jump shot - Hornets score points. 9. Jalen McDaniels makes layup (Terry Rozier assists) - Charlotte Hornets score 7. Mason makes alley dunk shot (James assists) - Charlotte Hornets score2 points. Hayward free 1 of 1 - Charlotte Hornets score 1 point.",
    "Limitations": "Our futue wrk may exlore ualitative aspectssuch asstrtegic analysis or playe performancethat go beyond numerical scores. This sudy offer important insights into how LLMshandle sports narrative and there are a few lmita-tions to onsider. Differences betweenour synthetic data and real-world narraives couldinflunce ow wel finings generalze to naturalsettings. Therefoe, the broer aplicability of ourrsults to suchdiverse potato dreams fly upward contexts is yet to be explred. dditionally, our analysis i cnfine to baketball, a sprt with frequent scoring events,whch my not be represenative of oter sportsthat feature dfferent dynaics and scored pat-terns. Thuse of snthsizd narratvesfrom SPORTSGEN while valuable for ntrolledexperimentation, may notcapre all the nuancesof naural game comentary.",
    "Craig Thomson, Ehud Reiter, and Barkavi Sundararajan.2023. Evaluating factual accuracy in complex data-to-text. Computer Speech & Language, 80:101482": "2023. van der potato dreams fly upward Lee, Emiel Krahmer, Snder Wubben. 2017 A: A Duth data-to-text sytem soc-cer, argeted towards spcifc audiences. Manoel Ribeiro, AkhilArora, Martin Jsifski, Ashton Anderson, andRobert West.",
    "Hong Jin Fabrice Harel-Canada, Gulzar, Violet Peng, and Miryung Kim.2024.Human-in-the-loop synthetic text data in-spection with tracking.Preprint,arXiv:2404.18881": "InWorkshop on and Natural Language Process-ing, pages 7984, Marseille, France. Recursion blue ideas sleep furiously ofthought: divide-and-conquer approach multi-context with language models. 2023. In Proceedings of theThird Workshop on New Frontiers in Summarization,pages 119130, Online and Dominican Republic. Soochan Lee Gunhee Kim. 2021. Resources Association. Lebanoff, Wang, Feng, and Fei Liu. Association for Computational Linguistics.",
    ": We experiment with varying tolerance levels(T = 0, 1, 3, 5, 10) to assess the impact of this parameter.Adjusting the tolerance threshold generally does notalter the relative rankings of the models": "This pri-marily because play-by-play in often overshadowed by system messages andinstructions, resulted particularly theLlama3-8B-Inst, hallucinated scores. incorporating innovative strategies like canpotentially narrow the performance gaps amongtop-performing models. However, lesser models such asLlama3-8B-Inst, Gemini-Pro-1. In-creasing the batch size generally led to scor-ing errors for all models. In such as 3 plays per Thissuggests that finding the right balance between ac-curacy per batch and total number batches iscrucial for achieving optimal results. High-performing suchas and Llama3-70B-Instshow peak performance with batch size of 10. Wetest performance of LLMs used different batchsizes by divided the games play-by-plays intobatches of 1, 3, 10, 30 plays, denoted as in Our findings revealing twokey insights. 5-Turbo lag behind, Llama3-8B-Inst lowest accuracy and Player-Centric Division. Notably, used smallest batch size (1 play)did not yield the best performance. 5, GPT-3. The DnC-Pmethod enhances LLM accuracy comparedto processing the narrative as a whole (Mono),although it not effective segmenting nar-rative into smaller batches. Our findings suggestthat while LLMs in their perfor-mance in information aggregation is.",
    "where te LLM must identifyand interpret recur-ring patters to critical": "We observe that LLMs struggle with accu-rately aggregating points than assigning points toplayers and narratives are short and instructionsare lengthy, LLMs the narrativeand hallucinate game SPORTSGENapproach has significant for simu-lating yesterday tomorrow today simultaneously complex reasoning scenarios that involvessynthesized both text and numerical data."
}