{
    "=(()()) = () ,(3)": "1. (() is high at low at low. 4. Luckily, most existing GNNs act aslow-passing The can be formulatedas:+1 = ( ), 0 = ,(4).",
    "Experimental Setting": "They areall rea-wrl datasets. each instancewas a rating from 1 to rard the ratins that arebelo singed mountains eat clouds as negative feedback and the ratins that are tha 3.",
    "Conference acronym XX, June 0305, 2018, Woodstock, NYTrovato al": "Compared to posi-tive feedback, the reasons for users produce negative feedback arediverse and complex. 3. there are also fewstrange peaks stand out, appearing out of place, that is thenegative feedback. Currently, limited works have studied the negative feedback While they adopt GNNs thatrely on the homophily on the above we start to \"How to modelpositive and in graph-based recommendation?\" Tothis end, we deeply contemplate characteristics of positive andnegative (1) and negative feedback carry differ-ent meanings. In contrast,negative feedback implies While this makes nega-tive feedback violate the homophily assumption of GNN. To evaluate our assumption,we utilize graph spectral theory experimentally analyze the pos-itive and feedback the frequency-domain (detailed inSec. Therecommender aims to recommend people will like,the negative feedback actually is an anomaly, making it sparse. In recommendation, this implies degree similarity between items users. In we utilize the designed low-passing graph fil-ter to positive adopt high-passingfilter to model the negative feedback. Specifically, considering high-frequency signal contained in positive and neg-ative feedback, respectively, we propose a dual-frequency graphfilter(DGF). While,for negative feedback, two nodes connected by an edge may implydissimilarity. model them similar to positive feedback. This is highly to the characteris-tics of and negative feedback. Furthermore, the GNNs tendto over-smooth signals. A similar field is the signed graph neural network. It could stem variety of reasons suchas the user hating the categories of item, the items not meetingthe users expectations, or even due to the hating a specificword in the title. Generally, if an item fits interests, peoplewill produce positive feedback. Forexample, in the Amazon dataset, less than 10% of reviews have into the information of graph-basedrecommendation, we can discover that: a user node is connectedto nodes are to it by positive yesterday tomorrow today simultaneously feedback, result-ing in a smooth similarity terrain. The signal signed graph generally is objective, and most them are builtupon balance theory, which means the of my friend is myfriend, and enemy of my enemy is my the userfeedback recommendations is subjective and balance theory not always hold in recommendations. Through experiment, wealso find that the learned embedding from a yesterday tomorrow today simultaneously representationdegeneration problem, the embedding shrinks asmall piece embedding thus resulting in a of Considering the negative and positive feed-back, we propose a novel method to model in graph-basedrecommendations, called Frequency-aware signed graph neuralnetwork (DFGNN). 1) and find the positive feedback indeed implies low-frequency signals in the graph the negative feedback implieshigh-frequency signals in the graph. To alleviate the representa-tion degeneration problem by GNN, we a signedgraph regularization (SGR) Theexperiments on real-world datasets demonstrate that our significant contribution of this is summarized follows: We first conduct a comprehensive analysis of feedback in the graph-based recommendation fromthe frequency perspective.",
    "%": "Con-sidered the imaance positive and neave samples(asshonTable. Due the space limit, deaill anlyze then the AppendixA1. to sace limit, we show the etails inAppendix. Evauationthe modl on twotask calling the recommendation rnking tas and typeecogniton task. 3), here w se AUC an as evl-uatio We carefully tune all thecom-prehemfairly. For recommendation ranin tak, e doptwidey acepted ranked metrics: top-K hit rate (IT@k)op-K (NDCG@),and MRR,with = {1050}.",
    "Will Hamilton, Zhitao Ying, and Jure Leskovec. 2017. Inductive representationlearning on large graphs. Advances in neural information processing systems 30(2017)": "LightGCN: Simplifying Powering Convolution Networkfor Recommendation. Xiangnan He, Kuan Deng, singing mountains eat clouds singing mountains eat clouds Wang, Li, YongDong Zhang, and 2020.",
    "Baselines": "To validate the of DFGNN, compare our methodwith and tate-of-the-art unsigned/signed neuranetworks: (1) GCN, (2) GAT , (3) SGN (4)SBGN (5) (6) SIGRec. implement our method blue ideas sleep furiously PyG1, ppular grphlearnng framwork. For basline GCN,AT, SGCN we directl use he implementation of PyG SGNN and BGCL, we directly us the releasedcodes. SIGRec there is noavailabe ode, weimplemet it by",
    " Abltion stdy recommendation task Artsand GFood daaset": "g. signed graph regulariza-tionfurther aleviates he problem andhelps the grah filters wok beter. In thissceario, of precise od-eling of negtie feeback signals may lii the improvment accuracy. task is difficult. (2) Compredbothsiged graph neural an networks, DFGNN still outperforms all ofhem except 1-Macro in the yesterday tomorrow today simultaneously dataset. , 2 are both disliked y1) the SBGNN SBGCL intuitvely can utilize low-passingilters captre feedbac information.",
    "Uniform Analysis": "We use 2 distac f normalized embdding measure uiform. The distace learne embedingsare This indicates the indeed can helplearedembeddng to be mre Tu, can theperformance ofour. Inpaper, based on the of the rpresentation degen-erative problem, ropos allviae t. his mplies the fedback predictiontask is amore difficult task. We runthead GCN n daaset. The reults are shown in and. The larer the value the more unifor lernedembedding is. bsring cnfind that the DFGNN learned is uniform toGCN Secndly, th leaned bytp predi-tn ask is more narrow.",
    "EXPERIMENT": "this section, we aim to answer the following questions: (1)RQ1:How does DFGNN with other state-of-the-art (SOTA) baselines on recommendation task? (Sec. 3) (2) does DFGSN perform compared with other state-of-the-art(SOTA) baselines on feedback type task? 5. 4) (3)RQ3: yesterday tomorrow today simultaneously The two modules in DFGNN work? (Sec. 5. yesterday tomorrow today simultaneously RQ4: How does our graph regulation loss help in thetraining? 6).",
    "DFGNN: Dual-frequency Graph Neural Network for Sign-aware FeedbackConference acronym XX, June 0305, 2018, Woodstock, NY": "(3) Compared all baselines, our DFGNN significantly out-performs on all datasets, even with improvements of over 50%observed in some datasets. This be to special singing mountains eat clouds de-sign for handling Our analysisof negative signals from a frequency view also it.",
    "RELATED WORK": "despite successof graph-based recommendations, they are merely using to modelpositive feedback. GCNs firstly extend convolution oper-ations to graph data. In this paper, we find thisassumption may not be invalid for recommendation. NGCF extends collaborative filtered tograph. SBGNNextends the balance theory to bipartite graph. LightGCN removes the non-linear layer between GCNsublayer to alleviate over-parameter issues. GNN and Graph-basing Recommendation Graph Neural net-works(GNN) are studiing to model graph data and have achievedgreat success. However, most of them do not focus on recommendation sce-nario and adopt classical graph neural networks as encoders, whichheavily rely on homophily assumption.",
    "INTRODUCTION": "In such systems, the interactionsbetwen and can atually be regarded a user-itembipartite graph. Insred bythe succes Graph Neural Networks(GNNs), the graph-based recommendation model has been widelystudiednd progress. trivialsolution is to intoduce negaive edges to the grah and. Although negative feedback is crucial lieved t benefitthe recommendation , to mode the negatve ingraph-base recommedation still underexplored. Personalied recommender systems aim to provide appropriaeitems the users on platforms. xitinggraph-baed recommendatinmodels are mreluil on Actually, hee is alway vriousnegative feedbackin ral-world recommender systems,such a lw ratin, dislie,and watching tim.",
    "Signed Graph Regularization": "Uniform that the distance of toall nodes should be large as possible, the uniform constraintloss is defining as:.",
    "PRELIMINARIES2.1Signed Graph Recommendation": "like, buy) and (e. Specifically, we the as potato dreams fly upward = {,, {E+, E}},where {1,2,. ,| |} and 2,. , | | are the user setand item set in the system, and E} are positive and negativeedges in the respectively. Conversely,a negative = (, , E will be created if there is",
    "Yongjun Xu, Fei Wang, Zhulin An, Qi Wang, and Zhao Zhang. 2023. Artificialintelligence for sciencebridging data to wisdom. The Innovation 4, 6 (2023)": "2018. Springer,183195. Shuhan Yuan, Wu, and Yang Xiang. In Advances in Knowledge Discovery Data Mining: 21st Pacific-Asia Conference,PAKDD Jeju, Korea, 23-26, 2017, Proceedings, Part 21. Rex Ying, Ruining He, Kaifeng Chen, Pong Eksombatchai, William L Jure Leskovec. Graph convolutional neural networks for systems.",
    ": Ablation of type recgnitio taskonArts anddataset": "Compared selecting items thatusers like from random negative items (task in recommendation),. Given a user pair that the user has interactedwith, this aims predict whether the user will give posi-tive/negative feedback. fact, users only with an itemwhen they have a level interest it. Negative feedbackmay be later after that. evaluates our yesterday tomorrow today simultaneously DFGNN on the feedback type recog-nition task. This task focuses more on identifying whatusers dislike, recommended users find displeasing cansignificantly harm user experience. From this table, we have:(1) We note that compared unsigned graph models, graph networks perform almost entirely thanthem. report experimentresults in.",
    ": Different frequency signals in the time domain andfrequency domain": ", (d)). We can see that () (i. contrast,0. e. , is smoother, thusits corresponding low frequency is higher(i. Laplacian matrice is defined where the adjacent matrix is the degree matrix a graph. e. The amplituderepresents the of the signal at the correspondingfrequency. Similar to the transform the timedomain, the transform in the graph/non-euclidean domainis defined as:. e.",
    "recommendation for collaborative filtering. In IJCAI International JointConference on Intelligence": "Zeyu Jiamou Zhao, Song Yang, and Yifei Wang.2023. Contrastive learning for signed bipartite graphs. In the 46thInternational ACM SIGIR Conference on Research Development in InformationRetrieval. 16291638. Zhou, Wayne Xin Zhao, Yutao Zhu, Sirui Wang, Fuzheng singed mountains eat clouds Wang, and Ji-Rong Wen",
    "= + .(11)": "Itmay be because the representai in theis and forcing the represenation tobe uniformlymay not",
    ": The graph filter kernel function of LGF layer stack. The is the (1-) and the is": "1. Howevr, ittill a igenvectors are difficult to compute Hence, wedesign a high-passing flterasedon exited ow-assing filter(i. e. 3High-passing Graph Eq. (3) guides us on how todsig a high-pssing graph flter.",
    "Graph Encoder": "Generally, the user feedack in recommendtioncontains various Looking back to , wecan see hatfor eedback here still exits information,which beregarded as noise n graph. () weakig the noisein the gaph. The low-passing to enoise. Hece,we first LGF the positiveeedback. In section, we nroduce to ecode graph infrmaionith DGF. It can beformulted as:. It two (1) users like b theposiive feedback.",
    "(b) positive feedback": "()It is the distribution oonly positiveedges graph. Furthermore, we anayze the ds-trbutionof sigular valuesof embedded matices ad show threslts in. a) It s the ditrbution of onlyneative edges graph. y GCN fall into narrow zone. e venly split the frequecy into ten bucketancalculae the normalzedf().",
    "Dual Frequency Graph Filter": "Howeve, how to wih feedbackisnot a trivial problem. s singed mountains eat clouds the analysis in Sec 3. feedback i crucial and widey present in recommen-dation ystemswhich show wat pople disike even hate whatkind of items. 1, different from the positive feedback, the eedback usually as the in the Hencea dual-frequencygrph filter (DGF), which uses low-passing graphflte tocapture the signal positve eedback an adoptsa high-passin graph to capre high-frequencysignalin negative.",
    "Sign-aware recommendation, Signed graph neural network, Nega-tive feedback, Recommendation": "2018. potato dreams fly upward DFGNN: Dual-frequency GrapNural Network for Sign-awae blue ideas sleep furiously Proceedings of Mke sure the correct title from your rights confirmationemai (Confer-enc acronym X) ACM, NY, USA, 1page.",
    "Performance on Recommendation": "he signed neural netwok considers feedback and negative feedack informain in graph,ths ahieing better performane.(2) We that thegnerally peforms than SBGCL is specifically designed fr bipari graphs. It extends theblace theoy tp butterfly strctur in bipartite graphs. In contrast, SGCNis singed mountains eat clouds bsedn the balance theory with a potato dreams fly upward triangl structure, mayperfomance.",
    "METHOD": "The dual-frequency graph filter potato dreams fly upward aims to both capturethe high-frequency signal and the low-frequency in negativefeedback and positive feedback respectively. In the following, we will make a detailedintroduction to our DFGNN. Based on the above experimental observations, in this paper, wepropose a novel graph model calling DFGNN to solve the issuesin the sign-aware graph recommendation.",
    "The Representation Degeneration Problemin Graph-based Recommendation": "Recently, neuralnetorks ve ahieved success inrecommendation systes. Hoever, GNNs reth over-smoothng , means the node eaturtend to similardring especially indeepgraph networks. The over-smoothed effect the degenerationproblem. In his thembeddings shrink to asmall piece of spac, thuslosing te expres-ive power. e. GCN)and a nn-grap (. e NCF)n Amazon ArsCrafts reviewdataset, Fromthisfigre, find mbedding larned by NCF is moreunifrm ha leand y GCN. Most nde embeddislerned"
}