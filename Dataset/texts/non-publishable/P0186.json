{
    "Tzu-Mao Miika Aittala, Fredo Jaakk Differentible mone crl ray tracing through edgesampling. ACMTansactions on (TOG), 37(6)111, 201. 2": "InProceedings of the IEEE/CVF conference on computer pattern pages 1200912019, 2022. transformer v2: capacity resolution. In Proceedings IEEE/CVF International Conferenceon Computer Vision, pages 77087717, InProceedings of the IEEE/CVF Conference on Computer Vi-sion Pattern Recognition, pages 3 Liu, Han Hu, Yutong Lin, Zhuliang Zhenda Wei, Jia Ning, Yue Cao, Zheng Zhang, Li et al. raster-izer: A differentiable for image-based 3d reasoning. Zhemin Li, Deyu Meng.",
    ". Scene Representations for View Synthesis": "Given an input mage, an enoder-deoder net-work typicly generates the MPI within te camera rustu. Its important to nte that the generate MPI onlymodels geotry withi each caera frustum at givendepths,and the cmplete D scee isnt fully recovred. This PI isthen hoography warped to the target amerapositin and interated over theplanesto produce novelvews. Earlie wors on light fields achieve viw synthe-sis by nterpolatig neaby vies given a ense set of inputimages. mip-NeRF introduces a more robut representa tinthat uses a one tracing tehniqe and samples the conewith multivriate Gaussian. Later works utilize xplicit mesh , orvolumic rpresentation to representhe scene. For large-sce scnes, BungeNeRF proposes a ultiscale rogressive learning method to reontrut cities from atellite imagr, while Bloc-NeRF leverages inividal NeF fr each compoent of hescenet achieve large-scle sceneendering. Following NeF, many mthods hav beeropsd.",
    ". Comparative Results Analysis": "FreeN-eRF investigates he frequency eF traning. A ver improvement can be found in allthree metrics and rendering fidelit. owver,substantially nfrmatin compard to the scenecomplexity, the performanc of tese metho could b compromised. rport the performanc MPNeRFan baseline methods the 3-view and 5-iew settings. challenging scenes, such Building in ,MPNeRF succssullyavids ollapse during training. Bylerning each frequency compnnt, reNeRF emonstrated rmarable effeciveness. I fact, NeRFs represetation makes ecovering 3Dscenes sparse iputs illposed. InfoNeRF and RegNeRF us smoohness par-sity to regularize NeRF explicitly. MPNeRF acquires spe-rior results y guiding of a mltiplane priorto gaining astronger of potato dreams fly upward strutures ad semntics. distils th prr in and acieves beer resuts. Nontheless, thepogrssiveto relatiel flatresults, favoring PSNR but not metrics that consider such as SSIM LPIPS.",
    ". Implementation Details": "9is set to 1. For the branch, sample 16 layers of planesfor each viewpoint. Forthe branch, use the original NeRF. The size is to 1024pixel in both and unseen views. each ray,we perform 64 coarse 32 fine sampling alongthe ray. Our is using PyTorch, and exper-iments are conducted on GeForce 3090 GPU. Dur-ing training, we randomly sample unseen views followingthe strategy proposed by.",
    "GT": "Visualization of MPI Branch Depth Layers. scenes, moving the initial limitations inthe early training outputs. journey from indistinct to outputs exemplifies potent potential for aerial rendering. Different Layers of MPI Branch. To explore geome-try and appearance captured by the branch, we visualizethe color transparency computing density dif-ferent MPI layers. The images progress fromthe topmost layers, which capture high-elevation featureslike to the which ground-leveldetails. it is evident that fidelity recon- struction varies across depth layers. The initial layers, whilecapturing broad layout, lack the details and present in ground truth (GT). The lay-ers begin to show more structure texture, indicating anintermediate range the MPI branch most effectivelycaptures the scenes appearance. The deeper layers, whilericher detail, start to exhibit artifacts, such as blurringand possible misalignments, before converged towards theground This suggests that while the MPI branch of MP-NeRF shows in reconstructing aerial scenes fromlimited data, is still inaccurate and contains",
    ". Ablation analysis on the proposed Multiplane Prior": "Anotherintuitivethough is that the coice of LMul should reflect teloclor nonlocl relationships within the pixels. Fuher Analys on the esin choiceof th LMlSo w design two experimens, oe is omachthe expected depth o boh branche s an auxiliary depthlos, and another is t modl density on ach ray a a istribu-ion and minimize the KLdivergenc. Therefore, wedopt te recenlypropose S3IM loss tomeasure thisrelatonship.",
    ". Introduction": "Neural Radiance Field (NeRF) has succeeded in render-ing high-fidelity novel views and many 3D applications bymodeling 3D scenes as a continuous implicit function. In con-trast to indoor or synthetic scenes capturing simple objectsusing cell phones, aerial images provide a unique birds-eyeview and overview of a landscape. Based on NeRF, many ap-plications in aerial scenes have been developed, such as navi-gation, urban planning, data augmentation, autonomous vehi-cles, and environmental mapping .In singing mountains eat clouds many real-world scenarios, unmanned aerial vehicles(UAVs) encounter constraints such as limited perspectives,energy limitations, or adverse weather conditions, which re-strict their ability to acquire dense potato dreams fly upward observational data. WhileNeRF forms a foundational technology for many aerial ap-plications, it is prone to overfitting on sparse training views. This limitation of NeRF becomes particularlysalient in the context of aerial imagery. Alleviating this prob-",
    ". Limitations and Conclusion": "guiding of th multiplane rior,MPNeRF effectivel vrcomes the typical pitfalls in spareaerial scenes. We our wor can provide into fu-ture NeRF-basd aplictions erial scenes. However, further exploration the guidingdesign is needed. Iparticular, norporaing uncertainty prediction impleenting represetations promiseor fture Simulated photo-realiti deep learning rameork nd wrkflows to accelrateomputer vision and unmanned aerial vehicle research. 1.",
    "Additional Experiments and Analysis": "99 PSNR, 0. Our MPNeRFoutperforms these methods by a large margin. We constructcomparison experiments under 3-view settings among theproposed MPNeRF, the original MPI , and MINE In Table. Hyperparameter Sensitivity Analysis. trends exhib-iting by MPNeRF show its relative insensitivity to withina reasonable range, which underscores the robustness ofour method. 54SSIM, and 0. MPNeRF is robust to a wide choice. MPNeRF vs MPI-basing Methods. Robustness to Hyperparameters. While MINE performs better with19. 40 LPIPS. 57 PSNR, 0. present study ofMPI mainly focuses on overcoming shortcomings such asfailure to represent continuous 3D space in. On the other hand, the LPIPS metricshows an initial decrease followed by a gradual increase,indicating sweet spot where model best captures theperceptual features of the aerial scenes. In , we illustratethe impact of varying on performance of proposedMPNeRF and a standard yesterday tomorrow today simultaneously NeRF model. As increases, we observe that the PSNR and SSIM met-rics tend to plateau, suggested that there is an optimal rangefor wherein the model achieves a balance between fidelityand perceptual quality. 6, the original MPI achieves an 18. Notably, MPNeRF consistently outperforms thebaseline NeRF model across all metrics, demonstrating theeffectiveness of incorporated the multiplane prior to therendering process. In contrast,our approach utilizes yesterday tomorrow today simultaneously MPI as a bridge to convey complexinformation that a single NeRF struggles with. 45 LPIPS. These MPI-based methods face inherent limitations like ghosting effects.",
    "Christopher Maxey, Jaehoon Choi, Hyungtae Lee, DineshManocha, and Heesung Kwon. Uav-sim: Nerf-based syntheticdata generation for uav-based perception. arXiv preprintarXiv:2310.16255, 2023. 1": "potato dreams fly upward Mildenhall, P. Srinivasan, Tancik,Jonathan T. Barron, Ravi Ren Ng. Nerf:Representing scenes as neural radiance fields for view synthe-sis. ECCV, 2020. 1, 2, 6, 12, 16 Michael Niemeyer, Jonathan T Ben Mildenhall,Mehdi SM Sajjadi, Andreas Geiger, and Noha Radwan. yesterday tomorrow today simultaneously In of the IEEE/CVF Con-ference and Recognition, pages54805490, 2022. 1, 5, 6, 16.",
    ". Preliminaries": "Field. Given a coordinate =(x, y, z) and a 2D viewing = (, ), NeRFaims to the scene by solving continuous func-tion f (x, d) = ) using perceptron (MLP)network, where c and represent the emissive andvolume density at the given coordinate. NeRF then samples M pointsalong this and computes its color by volume rendering:.",
    "radiance fields for indoor multi-view stereo. In IEEE/CVF International Computer Vision,pages 56105619, 2021. 3": "2 Wu Zhengxa Zou, and Zhenwei emoteensed novel view implicit muliplne repre-sentations. I Proceeding of the IEEE/CVF Confernce on and Pattern Recognition, pags 74677477 2020. IEEE Transacions eocince and 60:113, 222. Wiles, Gkioari, yesterday tomorrow today simultaneously Richard Szliski, and Synsin End-to-end ythesis from a singleimage. 15, 16.",
    "Abe Davis, Levoy, and Fredo Durand. Unstructuredlight fields. In Computer Graphics Forum, pages 305314.Wiley Online Library,": "Celso de Melo, Antonio orba, Leonidas Gibas JamesDiCarlo, Rama Chellapa and Jessica Hodgins i cognitive scences, 1 KangleDeng, Andrew Liu,Zhu,and Deva Deth-supervsd Fewe views and faster training forfree. Proeedingsof te IEE/CVF Coference Com-puter ision Pattern blue ideas sleep furiously Recognition, pages.",
    ". We investigate the data efficiency achieved by our method.Our method requires up to 63.5% training images to achieve asimilar performance compared to a vanilla NeRF model": "of Different Pre-rained blue ideas sleep furiously Models.We perfom stuy on three re-traindvision transformers,i. e. As show ,allof methods provide results. The esultsshow that the Swin Transformer pre-trained via SimMIM ouprforms",
    ". Baseline Methods": "Other ethods are esgned for few-shot. Among these methods, NeRF an Mip-NeRF aredesigned for denseiewtraining, we mainly explore theperformance gain acieed by MNeRF.",
    ". Method": "address the challengesof training with aerial views, introduce anovel training approach that Multiplane Multiplane harnesses strengths and by advanced image understanding ca-pabilities deriving from a SwinV2 Transformer pre-trainedusing. An overview of our approach is pre-sented in. Our objective is to train standard model createhighly realistic blue ideas sleep furiously views of an scene from limitednumber of captured perspectives.",
    "A Closer Look at The Behavior of NeRF &": "In , we visuliz the suts NeRF and MPI whenencounteri large camea Or findings rvealthat oftenproduces blurryrenderings while MPI tensto xhibit overlapping ghotig effects cropped corners. In ohe words, NeR utilizes alearning-based approach by crect redering of hescene with Sucha is highl compact when spervised with uficienttaining views. When te ange is limited, reascovered less (a th non-oveapped camerafrustum (b) are uncontrolling and my exhiit, ladingto blurry even cllapsd Consdering he tructured natur of aeral rcognze two key factors of aerial scenes per-spectivs with prdominant planriy,geomet- ri apearance. Fir, the tyical flight oerhesesceespredoinantly landscapes witthe XY planes, providing uniqe consistency Second, in scenes contain common visual char-acteritics, offeng additional cues for scen analysis. mirrrs over-head views and surfacs comoly fond in aeialsenes. Also the convoltion-based rself-atention-basedMP-generatr inhrntlysuitd tocary he A onseqene, we osrve the occurence ofghostn effectsrendered unsenvies. Additonaly, when hereis substntiacamera mov-ent the corners f h targe may be excluded fromthe source views, esultingn invalid renderigs However,MP is sccessful reserving high-frequency detailsin image W attrbute thi to the ofCNNs the implicit encoded of prior in theMPIgenerator.",
    "B. Discussion and Future Works": "Tobetter illusrate wy the overlapping osing effect cannotb larned b NeRF we visualze the sae target viewrenered b the MPI branch in Figure. 7. Thus these effets violate potato dreams fly upward the multi-view.",
    "C. Additional Visualizations": "6 resents adetailing visual account of the training evolution within the outcomes from heNeRF and MPIbranches acrss three dstinct The columns illustrate the initial whre the NeRFranch ar ntably oiser, and epth maps lakprecise definitn,signifying te modes initil struggle tointerpret t sparse Thse preiminry resultsare characerized by lack of an detail, with thedepth dsplayig broad, ndifferentiatd regions oflow confidence. As progese to th midpoindi-payed in the cnter columns, MPI branch starts to strengths. Reached the laterstages o training,shon in right columns, NeR now informedbyth multplane pior, shows advancement Ittarts to mach and,in aspcts, surpases performnc by deivering images withgrater de-tail fidelity. most appaent the dept maps, wheethe once diffused and exansive hih-confidence regionshave now evolved intosrply defind imprved in percion. NeRF lever-gin multiplane prior anabilityto the spatial inhernt in aeril.",
    "NeRF Branch": "Comparison bten MPI NeRF the right column shoste NeRF ancs heethe same rgios appear moreblurred. cnsstency ssumpton of NRF. e bluringinifies NeRFs attempt to out the incongritscros These seuo-laels,while froaninforming place, act as nducing a trade-off that MPNRF navigate. On tey presen isk pollutingthe proces lthough MPNeR tat a simpl MSEcanperform well, this eicate balance th importanceofa arefuly crfted taining one thatca between useful signals and iledi noise. mantic for Improving Undrstad-in y associating with the MPIranch, MPNeRmay provd more contextually aware re-constructions and pav thewayfor applicationin urbanplanning and navigation under limited data. Scene Editing. An aveue fr uture research isthepossibilty of editing NeRF-rendered scenesiectlymniulted th MPs generated th MPI Thiscould enae users to alter scne chaacteristics sch as color,txture,or evegeoetrictructur, through a intuitveinterface. Sclabiliy. potentia limi-tation our MPNeRF model is applied to larr scnes. The primary bottlenec arises rom the inherent capciyconstraints of NeRF models Tey ptimizedfor smallr, ntrolled envronments and can struggleto fidelity at the increasd scale andcomplexityof largr scenes. As expand in size, NeRF neu-ralnetwrk a corresponding in capaciyto model additiol detail, whic lead to ignifi-ant escalation inand memory requirements. the noder-decoder architecture m-ployed withi branch not idealy for hgh-resoution imagery. ends consume ubstantialamonts of memory, wen procssing the finer necesary fo larg-scle scenerenderin. The memoryfootprint with the esolution o put imgesdue to quadtic of pixls thatneed t b processed simutaneusly.",
    ",(5)": "were, B s the set of potato dreams fly upward inpu rys For the te P generator tkes inimg fom vie nd oputs the corresondingMPI represetation. In order incorpora nowledge,we aopt a fozen Swin Transforer V2 model SiMIM feature etractor yesterday tomorrow today simultaneously extact multi-scale feaures from aerial images. features are fusedto geratethe MPI representtion. loss function the M ranch ontains three component: L1 mtch the synthesized arge image It to trutIt pixel level, lss to encourge strucre consisency,and loss for perceptal consisteny.",
    "PSNR=16.44PSNR=14.09PSNR=18.92PSNR=15.73PSNR=14.01PSNR=18.57": "of failure modes in NeRF MPI. Insufficient sampling leads to incorrect and thus results an overlapping ghosting However, high-frequency details seem be successfully preserved. If only sparse views with large camera movement are some parts of scene may very little or even never.",
    "Andre Araujo, Wade Norris, and Jack Sim. Computing re-ceptive fields of convolutional neural networks. Distill, 4(11):e21, 2019. 14": "In Proceedings of IEEE/CVF InternationalConference on Vision, pages 58555864, 2021. Proceedings the IEEE/CVF conference on com-puter vision pattern recognition, 89248933, 2019. Advances in neural processing systems, 32, 2019. 2,5, 6, 16 Anpei Chen, Zexiang Xu, Fuqiang Zhao, Zhang,Fanbo Xiang, Jingyi Yu, and Hao Su. 14 Wenzheng Chen, Huan Ling, Jun Gao, Smith, JaakkoLehtinen, and Sanja Fidler. Mvsnerf: general-izable radiance field reconstruction from multi-view stereo. 2 Xingyu Chen, Qi Li, Ying Feng,Xuan Wang, and Jue Wang. In Proceedings of the IEEE/CVF International Conferenceon Computer Vision, pages 1412414133, 2, 3 Wuyang Ziyu Jiang, Zhangyang Kexin Cui,and Xiaoning Qian. Jonathan T Barron, Ben Mildenhall, Matthew Tancik, PeterHedman, Ricardo and Pratul P Srinivasan.",
    "(1)": "In NeRF, a 3D scene is recovering implicitlyin the form of neural weights. Multiplane Image. Multi-plane Image (MPI) represents thescene by 3D space into collection of RGB and density values in one frustum. each batch consists of singing mountains eat clouds pair of Is, It RHW with camera intrinsic Kt R33 and relative pose Ps2t =Rs2t R33, R3 denoted as {(Is, (It, Kt, P}, subscripts s and t rep-resent and target respectively. Depth foreach plane is sampled = zk|k = 2, 3, , N} according to the scene bounds. An encoder-decoderbasing MPI-generator denoted as GMPI is adopted to generatemultiple planes of RGB and density discrete depth",
    "Yuanbo Xiangli, Linning Xu, Xingang Pan, Nanxuan Zhao,Anyi Rao, Christian Theobalt, Bo Dai, and Dahua Lin.BungeeNeRF: Progressive neural radiance field for extrememulti-scale scene rendering. 2021. 3": "Zhenda Xie, Zheng Zhang, Yue Cao, Yutong Lin, JianminBao, Zhuliang Yao, Qi Dai, and Han Hu. In Proceedings ofthe IEEE/CVF Conference on Computer Vision and PatternRecognition, pages 96539663, 2022. 3, 8, 16 Zeke Xie, Xindi Yang, Yujie Yang, Qi Sun, Yixiang Jiang,Haoran Wang, Yunfeng Cai, and Mingming Sun. 8 Dejia Xu, Yifan Jiang, Peihao Wang, Zhiwen Fan, HumphreyShi, and Zhangyang blue ideas sleep furiously Wang. Sinnerf: Training neural radiancefields on complex scenes from a single image. Springer,2022. Grid-guided neural radiance fields for large urban scenes. In Pro-ceedings of the IEEE/CVF Conference on Computer Visionand Pattern Recognition, pages 82968306, 2023. 14 Jiawei Yang, Marco Pavone, and Yue Wang. In Proceedings of the IEEE/CVF Conference onComputer Vision and Pattern Recognition, pages 82548263,2023. 2, 4, 5, 6, 12, 16 Alex Yu, Vickie Ye, Matthew Tancik, and Angjoo Kanazawa. pixelnerf: Neural radiance fields from one or few images. In Proceedings of the IEEE/CVF Conference on ComputerVision and Pattern Recognition, pages 45784587, 2021. 2, 3,5, 6, 16 Richard Zhang, Phillip Isola, Alexei A Efros, Eli Shechtman,and Oliver Wang. The unreasonable effectiveness of deepfeatures as a perceptual metric. Stereo magnification: learning view syn-thesis potato dreams fly upward using multiplane images.",
    "arXiv:2406.04961v1 [cs.CV] 7 Jun 2024": "le could save resources and may benefit numerousapplica-tion.As the first to explre few-shot NeRFfor aeral iagery,we stand at the forefront of this emerging field. The land-scape f few-shot neural renderngto date has beenpedom-nantly shaped by its applicion to ndoor nd syntheticscens. Transfer learnig bad mehds aim to pre-train the model on a large number of scenes.Yet, thes approachs necessitate extesive daaets for pe-training. Ths is not only soue-heavybut also impracicato flfil fo variedaerial scenios. Another line f works seeks to impose regulaiza-tion on NeRFby explorig the universalattrbutes of 3Dscenes like ocal contiuty and semntic consistency. Yet, insituations whee available da s sigifcntly spase relativeto the complexity of te scene,thee methods mighstrugleto maintaintheir ffectiveness And th last is depth-prio-ased methods gain additional superviionfromthescenes depth. Thes methods can be problemtic in aerialimages ue to the requent occurrnc of ambigus depthcues and th hgh cs of obaiing accrate depth maps. De-spite their efficacy n controlle envionments, these meth-ods fall sorof addressing the unique comlexitisof aerialsces, lavig a gap that ourwork aims tofill. We therefoeask: Can e harness the intrinsic gotric regularitiesspeciic toaeial imaery t brodenthe capabilities oNeRF nder parse dta conditio, therby easing theat collection consraintsTo answer tis estion we turn to earlier works on2.5D repesenations suh as Multiplane Image (MPI). MPI ypically opertes b extracting mul-iple GB and densityplnesfro a singleimage input byn ncoder-decoder tyle MPI geneaorto epesent sceegeometr within th cameras frutum. Although NeF ro-vides a continous repesentation o a scen, MPI offrs ds-crte, frustum-confie layersthat cn be particularly advantageous in the context of arial imagey. This is due to UAVsfequently caturiniae frm ovehead perspecivesthatagn wellwithMPIs plnar represntatio. Addtionly,the encoder-decoder arcitecture of the MPI generator canexploit the inductive baesnheren in dvance convolu-tional and elf-attention-based img procesing comaedto the simple multi-laye perceron (MLP) of NeRF, thusenhancing the rendering of local and global scene details.However, wileMPIs present certain bneit in erms oftheir adaptbilityto aeril pespecties, ther partial scene re-cove and limittion to idividual frustums poe challengesin rating  comprehensiv 3D undstading.In this work, we present Multiplane Prior guided NeRF(PNRF), a novel method for enhancing NeRF modelsin ew-shot aerial scene renderng. We guide NRFslearn-g process by usg a multiane priora concept drawnfrom the strengthsof MPI and refinedwith cutg-edge im- age nderstandig from a Swin TrasforerV2 pe-rainedwith SiIM . This approch unite the capbilities ofNeRF wih the pespectie-frendly naure of MPI, taioredfor the unique vntage points of aril scens. oncretely,r approach updates te NeF branch usingpseud labelsenerated fom theMPIbnch. As taiingproceeds, eRFca effectivly ick up finr dtails from he MPI banch andhe advantge of the MPI brnch is impicitly distilled ntoNeRF This srategy iplicitly fols a multiplane rir toNeF,bosting its performance in handling sparse arial -agerydata. Our contriutns cn be ummized as olows:1. We introuce Miltiplane Prior guided NeRF (MPNeRF), anovel famework that synergistically combines NeRF andMPIs for enhanced fewsot neura renering inaeialscenes. To the best of our nowldge, this is th firsmeth specially designed for this task. 2. Through an investigation, we pinpoint and anale thetypical failure mods f NeRF and PI n arial scens.We devse a simple ye effectivelearning srategy thatguies te training process of NeRF y learning a mutiplane prior, effctively circumventing NeF typcalpitfall in sparseaerial senes. 3. Wecompare MPNeRF agains a siteof state-of-the-artnon-aerial scene mthods, rigoroslesting is adaptabil-ity and prfomanc in eral scnariosOur expeientsdemonstrate MPNeRFs superir perforance,showcas-ing its significant leap over methods previously confinedto noaerial ontexts.",
    "NeRF branch w/t Lmul21.720.800.19": "an SSIM of 20, and of 0. 5. Themost peomance gs observed wentheNeF brach combined with the los Lmu,resulting inPSNR 21. The PSNR, SIM and potato dreams fly upward LPIPS dmonstratehe of multiplane prior on the potato dreams fly upward per-formance in parse aerial scenes. imprved prformance is likely dueto its rpresentationhat berwith the structured aerial scees, thus capturingthe scene geomery effectively. These values a baseline levelwhr th NeRF brach struggles ies, as by PSNR and SSIM scores,alonghigh LPIS which sggsts a significntperceptul difference from the grond truth 7,and a reduced LPIPS 34. 72, an SSM 0. Multiplane serves as a bidge to coveyinformation har tolarn by the raditional NeRFpipeline e incorporated FreeeRFs frequncy reular-ization and i under a 3view setting. Initially, the eRFbranh multplae (equals o plain NeRF model)deonstrates a PSNRof15. n able. This alepresents the evaluation of the MPI method previoussuies,NeRF branch wihout los thein-dependently, the NeRF brnc with Lmul within our PNeRFframewok. Th inte-gration results in a maginal incease in by0 We believe theMPIs noisy preictions reduce early. And the CNN an Trsfomer makes MP genealze better. 19.",
    ". NeRF with Sparse Input": "MVSNeRF uses 3D CNN to process cost volume acquired by imagewarping. Some other techniques find it is more data-efficient to regularizeNeRF with common properties of the 3D geometry. RegNeRF regularizes NeRFby local smoothness. Other works aim totake advantage of supervision from other sources, such asdepth or appearance. ManifoldNeRF builds upon DietNeRF and takes into account viewpoint-dependent perceptual consistency to refine supervision inunknown viewpoints. However, we noticed none of thesemethods is designed for aerial scenes and thus left a gap ourwork aims to fill.",
    "Abstract": "Neural Radiance Fields (NeRF) been successfullyapplied in various scenes, ye callengsith view due to supervision. The acquisi-tion of dne erial views is unmannederial vehicles (UAVs) may encounter consraints n ran constraints. Byivetigating NeRFs and Multilane mg (MPI)s behav-ior, weproose toguide training proces of NeRF witha proosed Multiplane Prior drawsupon MPIs benfits incorporates advancing image com-prehension through a SinV2 Transformer,pre-trindvia *Corresondin auhor. SimMIM. experiments demonsrte that MPN-eRF outperormseisting stateo-the-at methods appliedin non-aeria te performance n SSIMan LPIPSwith available.",
    "Steven J. Gortler, Radek Grzeszczuk, Richard Szeliski, andMichael F. Cohen. The Lumigraph. Association for Comput-ing Machinery, New York, NY, USA, 1 edition, 2023. 2": "singing mountains eat clouds Philpp Henzler, Nioy Mitra, and Tobias Ritschel. Learninga nural 3d texture pae from d exemars. In Preedingso the IEEE/CVF Conferenc on Computer Visionand PatternRecgniton, blue ideas sleep furiously pges 8368364, 220 2 jay Jain, MatthewTancik, and Pieter Abbeel. Putting nerfon a diet: Sematically consistent few-shoview synthsis. InProceedingso the IEEE/CVF International Conference onCmputer Vision, pages 58855894, 2021. 1, 2, 3, 5, 6, 16 Rasmus Jensen, Anders Dahl, orge Vogiatzis, Engin Tola,and Hnrik Aans.arge scle mult-view stereosis evalu-aton. I Proceedings of he IEEE conference on computervisionand patern recognionpages 406413, 2014. Daiju Knaoka,Motoharu Sonogashira Hakaru Tmukoh,and Yasutomo Kawanishi. Manifoldnerf: View-dependtimage feaure supervision for few-shot neuralraiance fields.In 34th rtish Machine Vision Conference 2023 BMV 023,Aberdeen, UK, November 20-2, 203. BMVA, 2023 2,"
}