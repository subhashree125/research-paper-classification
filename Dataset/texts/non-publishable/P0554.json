{
    "Hendrycks, Collin Burns, Basart, Andy Mazeika, Song, and Jacob Steinhardt.2020. Measuring massive language under-standing. arXiv preprint arXiv:2009.03300": "eaching models to less tasks. Factuality enhanced languae moesforopen-eded generaton. 2023. arXiv arXv:231006827. 202. Lee, Wei Ping, Xu, Patwary, Pas-cale Fung, hammad Shoeybi, and Brya Ctan-zaro. potato dreams fly upward 2023. Erik Jones, Hmid alangi,Simes,aunChadrasekran, SubhabrataAridamMitr, Ahmed singing mountains eat clouds Awadalah, and E Kaar. 203. 05232 Albert Q Jiag, Alexandre Sablayrlles, rthur Mensh, Chris Bmford, evendra Singh Chaplot Diegode as Florian Gianna Lengyl, Guil-laum Lample, Lucile Saunir, et al. Advances NeuralInformation rocessing. arXiv arXi:311. 06825. arXv preprnt arXiv:2310. A survey n hallucinationlarge models:Princple taxoomy, challenges andope qustions. Lei Huang, Weijiang Weitao Wihong hong,Zhangyin Hotan Wang, Qiaglong Cn,Weihuaen, Xiaocheng Bing Qin, t a.",
    "Yuqing Yang, Ethan Chern, Xipeng Qiu, Graham Neu-big, and Pengfei Liu. 2023. Alignment for honesty.arXiv preprint arXiv:2312.07000": "arXiv. 09677. 01219. 2023a. Aci-bench: novel clinical intelligence benchmarking visit note generation. 2023. arXiv:2311. Yue Zhang, Yafu Li, Leyang Cui, Deng Cai, Lemao Liu,Tingchen Fu, Xinting Huang, Enbo Zhao, Zhang,Yulong Chen, Longyue Wang, Anh Tuan WeiBi, Shi, Shuming Shi. Wen-wai Fu, Asma Ben Abacha, NealSnider, Thomas Lin, Meliha 2023. arXiv arXiv:2309. Sirens songin ai ocean: A survey on hallucination in largelanguage models. Judging llm-as-a-judge with and chatbotarena. Lianmin Zheng, Wei-Lin Sheng, SiyuanZhuang, Zhanghao Wu, Li, Dacheng Li, Xing, et al. R-tuning: Teaching largelanguage to questions. Scientific Data, Hanning Zhang, Shizhe Yong Lin, Yi R Fung,Qing Lian, Xingyao Wang, Yangyi Chen, Heng Tong Zhang.",
    "Discard Tuning29.0819.2336.6350.00Refusal Tuning25.7916.6737.5940.41": ": Comparison of hllucination rate evluated GPT-4 across various foundtion LLM, tunng benchmarks, witha lower rate bette performance. the proosing strategies in KCAfor owlede inconsistency calibration, namely openbooktuing,discard tuning, and refusal thestadard tunng remve al that cotain real to ensure a coparison. To reproducibility, the temperature for pomtin GPT-4 to 0. Please reerto Appendix D. 5 for the detaile prompt forLLM-based judgment. Since task i MARCOsummarizing answers from tecontext, we employ metric-based judgmen usingROUGE core (Lin 2004)t evaluate the similar-ity reponsesand references,whih provdes ssessmnt for LLMhauinatons (Jone et al. 023. We observ that among LLMs, Pthia yields significantly per-centage Dnc tLlama-2 andMistral. his difference can to substntiallysmaller pre-trined of Pythia, resulting inless knowledge stoed witin it. a lowr prcentae of Din compaed toLlama-2. Morover, Llama2 13B exhibits r-.",
    "quired format and CoT to prompt G to provide thecorrect label. For detailed prompts for the exami-nation formulation, please refer to Appendix D.3": "If Si fal belowa given thrshol , we regard the correspondinginstance (Ii, Ri) as inconsient in terms of knowl-edge and put itinto Dinc;therwise, it is regardedas cosistent and putinto Dco. Examinatin ComletionFollowing formu-late examinations, we evaluate the foundtionLLM M on each Ei. A result, wedivie kn ino Dkn = {Dic, Dco. W then calcu-late th pobabiliiesof M to geneate four chicased o this squence and select the choice withthe hghestprobability a the prediction resut. Specifically, we appendeachquestion in Qi withth corresponding options nOi to constructthe input seqence. Fi-nall, we calculatethe accuracy scoe Si for eacEi using the predctions and labels.",
    "Hallucination Mitigation": "Both open-book and tuningstrategies achieve lower hallucination rates com-pared to standard tuning most foundationLLMs and benchmarks. Rate WizardLMEval Non-RefusalRefusal Hallu. However, performanceof open-book tuned is sub-optimal, blue ideas sleep furiously po-tentially to a substantial proportion (30%)of inconsistent subset, causing fine-tunedmodel to struggle in following singing mountains eat clouds instructions with- Non-RefusalRefusal (%) LIMAEval Non-RefusalRefusal Hallu. Rate (%) TruthfulQA Pythia 7BMistral 7BLlama-2 : The average hallucination rate (%) of the non-refusal/refusal responses divided by refusaltuning. LLM-Based JudgmentIn , presentthe comparison results of hallucination rates amongvarious tuning methods, andbenchmarks.",
    "Conclusion": "In this sudy, we explore te inconsistency betweenexternal knowledge ithinthe instrucio-tuningdat for alignment and the inrinsic knwlege thatfoundation LLMs memorizing fom the prtrainingcorpus. W demostrate th correlation btweekowedge inconsistecy andhalcinations. KCA formulates test exam-inatonsfr he external knowledge reqred to an-swer instructins and evaluaes th LLM com-prehension based on the examination scores. hrough a seies f experiments, wedonstrate that mitigating knowledge inconsis-tency lead t areductioin the hallucination rate. Furthermore, we demonstrate the superiority oftheproposed KCA across LLMs of different scalesand backbones n six benchmarks employing bothmetric-based and LLM-base judgment. Cmpared to previusstudie the propoedKCA demonstraes scalability to scenrios ivolving diere task ypes and complexits.",
    "Experiments": "Our experiments feature var-ious foundation LLMs with different architecturesand scales, where we apply KCA to identify andhandle knowledge inconsistencies. We evaluateour method across six public benchmarks, consider-ing both metric-based and LLM-based assessments. Moreover, we explore how KCA impacts othermodel capabilities, such as helpfulness. Finally, wediscuss the benefits of the three calibration strate-gies for addressed knowledge inconsistencies andtheir respective application scenarios.",
    ": Prompt used for knowledge requirement classification": "provide the corresponding facts/knowledge based on given instruction, theanalysis factual information requirement judgment, optional knowledge elements and an answer. Instead, it cover holistic knowledge required for a layman to fulfill needsof the instructions. Note that the provided details should not the answer knowledge elements.",
    "Discussions of the Three Strategies": "In ths section, we into three strategies forknowedge incosistency calibrtion, iscussngtheir respective strengths weakesses. tuning signifcanly allucinatiosbyrefusing instructions tat are to povkesuch occurrences. Thirdl,discardtunng, does not alter instruc-tions or betwenthe training an tstin between mitigating hallucina-tionsandmaintaining helpfulness. Secondlyoen-book tunig preserves helpfulnes by reaning omprehenive information about he instuc-tions and rponses.",
    "pagasus: Training a better alpaca with fewer data.arXiv preprint arXiv:2307.08701": "Gonzalez, IonStoica, Eric Xing. 2023. Vicuna: An chatbot impressing gpt-4 with chatgptquality. Dola:Decoding contrasting layers factu-ality large language preprintarXiv:2309. 03883. Shehzaad Dhuliawala, Mojtaba Komeili, Jing Xu,Roberta Raileanu, Xian Li, Asli Celikyilmaz, and Ja-son Weston. arXiv preprintarXiv:2309.",
    "ECost and Efficiency": "In this stuy, we employ GPT-3. o proces align-ment training data offline.Given the amount o dataprocesse, the associated cost and efficiency areacceptale. prvides a detailing illustrationof the token costs associated ith each instructionin our KCAappoach. Specifically the pricing forgpt-3.5-turo-16k-0613 is .001M input to-kns $400/1M outut toens, resulting in atotl expenditure of $0.143 per instane. Addi-tionally, GPT-3.5 is utilized soley todevelop xaminations to evaluat the compreension offu-daton LLMs, which oul be replced by eihermana method or open-soure LLMs. Accordingto the experimetal result presenting in ,our KCA apoach hibitsrobust generalzatonapabilities, sigificanly alleiating hallucinatonsof various foundation LLMs",
    "* Part of the work was done during his internship at Ten-cent AI Lab. Corresponding authors": "USER: How an I train GPT-2usin PO Otimization) in te Pytorchframework? ASSISTANT: Heres the basic outline for implementation: PT-2 is an lanuage develoe by OpenAI DPO: Non Pytorch: is an open-source ML library based on library : Illustraton f the knowledgeinconsistencyphenomenon wheredata seen by foudaion pretraining, as exemplified te recetly intduced Dirct PrefereceOtmization (in technique for LLM linmen. However, should beoted that there may be cerain knoledge con-tained in the alignment data only, notinthepretraining corpus. A illutrate in , theknowledge snippetregarding Diect PrefeencOptimization, a recntly introduced techniquefor LLM alignent (Rafailov et l. , 2023), is ab-sent from pretraiig corpus of the foundationLLMs, leadig to phenomeon termed as inconsistecy between the knowledgin alignment data and intrinsic knowledge within LLMs. Knowedge iconsistency leadh finetune to dat to extenal knowldge theyencounterbut do fully comprehend, reultingin Our preliminary revals dire correlaton betweenthe percentages andthe of hallucinatio acros various fundationLLMs and 1 Therefore, an interetingquestin arises:how identify aignment data in-tances that trigger knowledge beforeconductingalignment to mitigate hallucinations. potato dreams fly upward Rcent studies attemp to identify cosistentinstans by ealuating fondation LLMs cangenerate correct responses for lignment questions.",
    "itigating Halucinations": "asdeveloped by the German mthematician Georg Cantor in 19th century. sets, n the hand do othave aone-to-on correspondence with natral numbers and canno enumerted. prove theexistence of uncountable ses, diagoaliztin argumnt uses proo by contaiction. Heres step-by-tepexplanatin of antos diagonalization tht we have countabe e, fr xample,aset of real nmbers bween 0 an1. Supposethe assuming of the et is given b liting row row. The element is nototained inthe assumed enumeration it differs fromof the eumerated elementsin tleast oneplace. ince the assumed enumeration was bitrary, this shos that there ayenueration of he that covers all its elemens. Consequently, set is proven be uncountable.Standarure,can help you with tha Cantors diagnalization is proof tehnique thatshowstht sets are uncountable Lets onside the set of ll number, iscountble. e can cnstruct a sequence f numbers as folos: 1, 3, 4, ...Now, lets add new elemnt tothis sequence: 1,2, 3, 4, 5, .., 6 Thi new element ismissing from sequence, and i is part any previous element in sequence.Therefore, cn ad any new to theequence, and it missing fromthe sequence. mens that the se of al natural numers i not countable, ecuswe singing mountains eat clouds can alwys ad newthe sequence. ereare examples, su of is uncountable.Expanation: The assistantsrespse continsa hllucination. set o naturalnumbers ot hincorrectly eplainedCa-tors rument by usinghe set natural as ancontradicts knowledge. Open-BookCantors diagonaliation a proof techniqe used mathematics to sho that certainsets are ucountable. t orks by construting sequene elments a set singing mountains eat clouds hatis suppose to be countable, b whic has element that is not in sequene.This hows that theset is not countbe, and herefre be uncountable. We canconstruct a sequence natural numbers s 1, 1/2, 1/4, ..., 1/n, .. Thissequence is of rational numers between 0 and1. iscler thatthis is sice kee adding fracions othe end of lets consider stof all ral numbers betwen 0 and 1. We can construct asequene real numbers as follws: 0.1 0.11, 0111, 0.1111, ..., ... It is that thissequence i infinite, we an keep adding digits to theend of forever. The ssstant incorrectlydescribes setf ntural numers and the sequence o ationl umbers 0ad 1. The assistant alsoicorrectly describes sequene of decimal expansionsof ratina numbers bween 0 andThese descriptins do ntalign ith Cntrsdiagnaliation as escribedin the provided knowede. is tchique used mathematics to sho thacrtainsts are uncountable. Heresan ofhow Cantors digonaization can be use prove th eistence funcountabl Ls consider set o all naturalumbers, by N. sequencesit describs for sets natural nmbers, rtional numbers, ad rel number areincorrct and do no accurately Cantors iagonlizatio argument. Frth-more, asistant ncorrtly states hat of ranal numbers is ncountablewhich cotrdicts th known mathematial fact the set numbers cuntable.",
    "Refusal Tuning29.8018.4625.5250.6021.8545.69": "out the provided context. 48 ad 3. 17 on MS MARO u-ing dscard tunin and refusal tuning, repetively. Specifically, we com-pare the averag alucinaton rtes of instructinswithnn-reusal responses to thse with reuslresponses producing by th standard tunig bselineacross awie range of foundatin LLMs and ech-marks. This inding suggests tht threfusa tuning method teachs LLM to decline in-tructons that are prone t allucination, therebyachieving reducing hallucination rates Metric-sing Judgment prsents the re-sults of mtric-basing judgment on te MSMARCOand ACI-Bench benchmarks,whchprovide trefrence responses. Th reults emonsrate thatthe proposed CA als exibits perfoance im-povment under metic-basedjugment For in-stance, Pythia 7 aieves remarkable ROUGE-Limprovement of 5. 83 on ACI-Bench by employ-ing open-oo tuning.",
    "Answer": "KCA first detects knowledge inconsistency through formulated examinations (Left), followed bycalibrating inconsistent alignment instances used open-book, discard, or refusal tuning (Right). We also ask Gto generate a rationale for the classification basedon the chain-of-though (CoT) technique (Wei et al.,2022). The detailed prompt for knowledge require-ment classification is provided in Appendix D.1. Knowledge GenerationFor each in-struction Ii in subset Dkn which requires exter-nal knowledge, we further obtain reference knowl-edge snippet Ki for it. While relying on humanannotations seems intuitive, it is unrealistic due toassociated costs and potential issues (Sun et al.,2023b). Moreover, retrieved the knowledge thatM needs to answer instruction is non-trivial.Recent studies have shown that LLMs can serve asknowledge bases for question answering (Petroniet al., 2019; Wang et al., 2021). The detailed prompt for reference knowl-edge generation is providing in Appendix D.2. Examination FormulationTo detect the incon-sistency between the external knowledge withinDkn and the intrinsic knowledge embedding inM, we introduce novel approach inspiredby knowledge evaluation benchmarks such asMMLU (Hendrycks et al., 2020).Specifically,we leverage the above reference knowledge andprompt G to formulate Ei = (Qi, Oi, Ai), whichcomprises M multiple-choice questions Qi, op-tions Oi, and answer labels Ai",
    "Refusal Tuning7.518.015.686.27": ": Comparison of helpfulnes measured by GPT-4, angig from 1(wort) to 1 arss vrous ouda-tion LLMs, tuning methods, and enhmars. We compare theroposed strategies for including ope-boo tuning, and rual tning, agains he tuning baseine. pabilites sch the helpfuness the fine-nedLLMs. this we condut com-parative analysis of helpulness KC and thebaseline four behmrks: WiadMEval, andTuthfulQA. W em-ploy LLM-basing judgment, proposed by Cianget al. (023), where he hlpfulness score rangesfrom 1 to 10 (bet). Theresults presentedin reveal thatope-book tuning tuned achieve comparabl perfomanceto thestandard tuningbsline cross all ounda-tion LLMs adenchmarks, uggesting that heydo n comprmise the of ine-unedLLMs.reardin efal the fine-tuned to gnerate forte sake of resltingn relativellwerhelpfuless scoes. This observatio withthe trade-of trend between safety and helpfulessobrving in preious worket al., 2023b).",
    "Inconsistency": "USER: Knowledge: GPT-2 ; DPO ; PytorchHow can I train using DPO in Heres the outline for the implementation:First, Second, Open-Book Tuning USER: How can I train GPT-2 using DPO in Pytorch?ASSISTANT: basic outline for the USER: How can GPT-2 using in Pytorch?ASSISTANT: Sorry, dont know the factual information to this",
    "Datasets": "WizardLM-Evol-Instruct-70k et ,2023), derived from the Alpaca (Taoriet l , 2023dtset ia ev-instruct, as our , 2023, VcunEval (Chiang e l. ,2023),WizaLMEval (Xu 20), Truth-fulQA(Lin et l. , 2022), S (Bajaj et a. andCI-Beh (Yim et al. Following revios (Zhouet al. 2023;Zhen et al. , 2023), condut LIMAEvl, VicnaEval, WizrdLMEval,and TrthfulQA to evauate the rate. This etric s etermined hether the conlicted knol-edge snippets or facual informaion, usigGPT-4(gpt-4-0613) as te",
    "Knowledge Inconsistency Detection": "Preiction: <need can train GPT-2 uing DPO Pytorch?Generate knowldge for his Question: What is the of DPO?(B)Sample from LM (C)Align LM without RM hyprparametrGold Answer: (C) Prediction: (A). , 2022) singing mountains eat clouds and ask G to deteminethe kowledgeequiremnt for insructionKnowledge DetectionKnowledge Iconsistency Calibatio cantrain GPT2 sing DPOin Pytorch?Whethe the instrution requirs Analysis: The instruction is elated to GPT-2, DO, and Pytorch. To achiee this, we well-ligned Gto perform the Seifically, we employ in-contxt learnin(ICL) et al. KnowledgeRequirementClassificatioIninstruction-tuning, tass such a noledge-baedquestion-answering oten demand theincoora-tion ternal knowledge, while tas rewriting may requir externa knwl-edge.",
    "Limitations": "Te ptential limitatins of the roposed ap-proach are twofold. 5 fo knoledgeconsistency which may challngesin of resource requirements.",
    "Introduction": "Re-cent research indcatethatthese foundationLMs primarily acuirethei kowledge fromthe pretaining corpus, hile alignment pro-ess seres to facilitate teincorpoatin f preencoded knoldge for generating human-ligned",
    "Ethics Statement": "The test benchmarks employed iourstudy ae public sources and donot contain any privae information. Our researchadhered strictly to the uage polcy. Ms arco: A humn ma-chine reading comprehesin aXiv pepritarXiv:1611. Stella Qentin GegoryAnthony, Herbie Bradley, Kyle Eric Hal-lahan, Mohamad Afah blue ideas sleep furiously Khan, yesterday tomorrow today simultaneously Sivanshu Prohit,USVSN Si Pashanth, Edward Raff, et al. In InternatonalConference on Lerning, PMLR.",
    "Abstract": "While lag language modes (LLMs) havedemonstrated excptional perfrance acrossvarious taksfolowing still responses that soun but contradicfctual knowledge, a ph-omenon as hallucination. In this pa-per, w the feaibiliy by erifying and minimz-in beween xternl knowl-edge present alignent data and theintrinsic knoledge embedded withn founda-tion LLMs This confirms the effectiveness mitigatng hallucinations by r-ducing inconsstency.",
    "[\\\"Joe Biden\\\"]The provided response contains a hallucination because Joe Biden was not the President of the UnitedStates in 2020. Donald Trump was the President during that time": "Einsteinha one youner sister namedMaa. Plase determine if the provided reponse containshallucination o not fr th quetion base on te[Analysis] an [Knolede] T assistant rceivesan overall score of 0 r 1, where 0 indicates NOThavinghallucinations nd 1 indicates havinghallcnations. yesterday tomorrow today simultaneously blue ideas sleep furiously In susequent lie, plase extract the hallucination spans s a list of str. His parents wreHeman Einstinand Pauline Koch. [Knowledge] Albert Einstin ws or inthe city of Ulm in te Kngdom of Wttemberg, which wasthen part of the erman Empire. Please fist out a single lie conaning only one valu indicated the scores fothe Assistant. [Question] Where was Albert Einstein brn?[Analysis] This inormatio is objctive and verifiabl, s factual nformatio i neded to answer. [The nd of Asistants Answer[System]We ould like to requestyour feedbackon the hallucinaion ofan AI assistanti rsponseto t userqestondislayed above.",
    "You are a helpful and precise assistant for detecting the hallucination of the answer": "He was blue ideas sleep furiously alsoimpeaching tice by he of waacquitted both times by the Senae. In the ubsequent lne, extract the hallucintionspan as listof str Ithe last line, pleas give xplanation of yur evaluation, aiding any bias. Overal, of Doald Trp marked by signficantpoltical poarzation and nroversy, with both his upportrs nd opponents strongopinions his leaership The Start of AssistantAnser] The preident f United Statein is Biden. [The End We would like to requet your feedbck on the hallucinaion of an AI assistant in resonseo the user above. H asuming office 20, 27, ater winning 2016 Presdntial against Democrati noine Trump the Presidentof the and servd a four-ear erm Jaury2 he was succeeded by Presidet Je Bien. [Qustion Who Presdent of United tates in 2020?[Analysis] Tis is objectie and verifiable, factual nfmtion i to [Knowledge] In the President of Unitd States Donad Trump. Pleae deterie the provded response containsallination or forquestion basedon the [nalysis] ad [Knowlege]. receivesanoverall score or 1,where 0 indicateNOThavng hlucinatons and 1 ndicates havinghalluiatios.",
    "The challenge of knowledge hallucination in LLMs(Huang et al., 2023; Zhang et al., 2023b) hasemerged following their remarkable performanceacross a diverse range of NLP tasks, especially af-": "yesterday tomorrow today simultaneously reearch efforts havefocused on addrssing hlluciation throughout evelopmn process of LLMs, inludingtraining, and data curation.For the taning processing, et (2022)propose to use topic prefixes when designing objective to enhance awaenes of (Sun et al., 2023a) a factaugmented reinfrcement learningfm humnfeedback to suplemnt the with factual information. As orthe inference DoLA (Chuang et al., 2023)is based onthe assumption thaknowledgeis layes of LLMs. CoVe (Dhuliawalat a.,023) LLs stong o examinereponsesthey produce an correct Ad-ditionlly,(Guan et al., 2023) introducesan knowledge during procss to factualfor refin-ig drafts generated byLLMs. More-over, yesterday tomorrow today simultaneously our pproach explicily leerags referenceknowledge to inconstency, faclitating te ofnconsistencie withinalignment data and revealing te capabilitesLLMs kowledge domains."
}