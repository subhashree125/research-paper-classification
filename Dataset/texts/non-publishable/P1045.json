{
    "OF TRIGGER NODES": "illustrates the impct varying the nmber trggernodeson attck perfoance of against ProG in both node and graph te-Seer aros five cross-ontext scenario. In cros-dataset scenarios,the pretrainn is coduting using while serves s tepretrained for settings.",
    "DBASELINE ATTACKS": "Unlike CrossB, whichtrgets the GPL framework, GCBA aimstoinjectbckdoor oi-oningnoise ito GNN encoder ained using Graph nrasveLearning (CL The attack is thenformulated to maximize te similarity between the embeddins obackdoored graph data ad those of clean grap data longed toth target class n the downstream tas, as well as similritybetwen meddings of clea dat from bot the yesterday tomorrow today simultaneously ackdooe andlean GN ncoders. GCB is singing mountains eat clouds he most relevnt backdoor atack metod to oursudy, give te thre ol definition. Hower, GCBA pritsarbitrary node features inthe injectedtrger graph. Comaed t CrssBA,GCBA difers two sigfican aspes nitsalgorithmic design. Secondly, CrossA includesa noe feature affinity cnstraint in its attak ojective, aiding inircumventing countermeasures that inspect nod featue outliers,such as PruneG. Consequently,CrossBA presents a morestealthy attak comparing to GCBA, particully agains cunter-measures deployed b downstram users. However, GCBA i not directl applcable tocrss-context GPLenaris as it relies on acces to downsteam applicatiodata. Then, GCBA_R randomly selecs an embedding cntered aroundacluste in he embedded space asthe target mbedding, whleGCBA_M selects the cluter center furhest away from other clascenters as the target embdding.",
    "Alternating Optimization for CrossBA": "triggergrph. fterinjectng trigger intoteinput graph , the attacker optimizes thefeatesof ,poteniall optimizing the target by thebackdoor los Lbdk and te nodefeatre ffiity loss Lsimwith to the fixe GNN. Durngeach attack round, attackers frst freeze the GNN node trgger grah.",
    "= AGGREGATE1, { N( ) }, () (1)": "The parameter for the rap the answering of downstream are optimizedthrough few-ht learnin. However, they differen daa distributions. , Amazon), while tasks academic citationetworks (e. he prompt is denoted= where { 2,. The , th propt graphs topogy structure. few-shot learningis designed to facilitate rapid adaptation of t ndiverse using imitd abeled Thenhernt data heterogenety this paradigm n inboth semanic and distribuion pretraining anddownsream Wesummarize the ross-ntet cenariosstudied in reviousworks delineate cros-contexto cverdiferenlevels disparities: settng reflects the divergenc in the goa o graphlearing task. A pompted graph isobtained by insertin the gaph into the inut grah. Our study inducve where the GNN input is theinducve graph ofa given node, including the tself and its neihbors. The fial nodeembedding of is denoted as= (, ), where denotes theparameters of the encoder. For instac pretraning dataset while the downtream task involes a likeCteSeer. rG-Met enhances by incorpoatig tech-niques. For nstane,pretrining could b concted oncomercial neworkse. roand GraphPrmpt uify pretraining downstrem tasks intograph-leel tasks, leanable pompts guidetheseasks. Howeve, he focus ifferet , pretraining anddowstream aedifferent class isributions. Crss-datase: setting different datasetswithin thesame domain. Tis studyis involved i two GPL ProG and GraphPropt. Cross-conext few-shot leing. The pretrining maye cnducted for classifica-tion ntire graph, suh as ENZYMES, while the downstreamtak involvesclssificton of nodes, like CiteSeer. Bothare academic citation networks t diferent. Cros-domain: The and downstream daa riginatefrom ditinct domains th same task type. nde set 2, pompt vector its parmetersby gaient descentto the graphimilarity loss.",
    "CDATASETS AND GNN MODELS": "dataset 600 from the BRENDA enzyme database, clas-sifiing into 6 EC enzyme categories. Detailed statistics are presented in wherethe last column the of downstream task for eachdataset: \"N\" for node classification and for GATemploys neighborhood aggregation for node embedding learningand distinguishes itself assigned varied weights to neighboringnodes, modifyed their influence in the process. are of the where nodes represent and edges indicate frequentco-purchases. GT integrates processing graph-structured datawith the self-attention Transformer networks, effec-tively capturing complex feature dependenciesbetween nodes in a graph.",
    "Attack Success Rate": "a)Cross The number of trigger 0.5 0. 0.8 (b) Cross number of trigger nodes 0.70.9 1.0 (c) Crss Dtaset Th singing mountains eat clouds numberof trgge odes 0.5 0.6 0. 0.8 0.91.0 (d) Cross number triggernod 0.7 .8 0.9 1.0 (e) Tak Node: ProG w/o Pune Nde ProG w/ Prune Node: GraphPrompt /o Prune Node: GraphPrompt w/ PruneGrph: PG /o Grph: ProG w/ Prue Graph: GrphPrompt w/ Prune Graph: GrapPrompt w/ : Impact of nmber of triger odes attack perfomance of CrssBA agaist and GraphPrompt based onCieSeerin cross-conext scenarios. represents node classificationtas, and \"Graph\" denotes th graph classificaiotask.",
    "Experimental Results": "This observation confirms the theoretical prin-ciples outlined in. The baseline methods achieve ASR values over 0. Additionally,when the baselines achieve ASR to CrossBA, suffera blue ideas sleep furiously significant in ACC. (1) Attack Performance in Cross-Context GPL Tables 13 and ACC ASR of all methods in cross-distribution,cross-class, cross-domain, cross-dataset, and cross-task scenarios,respectively. CrossBA demonstrates attackeffectiveness across various GPL methods, achieving high ASRwhile preserving the usability of backdoored models in downstreamtasks. Superior attack of across differentcross-context scenarios (RQ1 and RQ3). attack performance CrossBA against differ-ent GPL methods (RQ2). For instance, in cross-class ProG, the baseline attacks achieve an of about 99 onCora, to CrossBA, but with ACC at least 0. Due to space and consistent acrossdifferent report results for cross-distribution, cross-domain here and defer those for cross-dataset and cross-task scenarios Appendix F. The results reveal thatCrossBA consistently outperforms the baseline methods across 5cross-context GPL scenarios, achieving the highest ASR valueswhile maintaining comparable ACC to of backdoor-free Specifically, CrossBA ASR values exceeding0. CrossBA effectively the backdoor poison-ing to diverse cross-context scenarios, outperforming methods, while maintaining the utility GNN encoders fordownstream tasks. contrast,the baseline attacks fail to achieve comparable ASR to various scenarios while maintaining ACC simultaneously. 90 in cross-class, cross-distribution,cross-dataset, and cross-domain scenarios. in scenarios, with only a negligible difference in com-pared to backdoor-free models, at most 06 lower. 27 lower. In contrast, baseline attacksfail to consistent attack different For in cross-class scenarios, both baseline meth-ods show ASR values below 0. 99 againstProG on Cora but only reach of 07. 87. 96, closeto but values half CrossBAs. 05 GAT trained by GPL on a complete failure of theattack. Simi-larly, in scenarios against GT model trainedby ProG, baseline attacks achieve an ASR of about 0. In cross-task singing mountains eat clouds scenarios,CrossBA achieves ASRs exceeding 0.",
    "FATTACK RESULTS IN CROSS-DATASET ANDCROSS-TASK SCENARIOS": "83 in all tested cases, with a maximum de-crease of only 0. Theresults underscore the attack of CrossBA acrossdiverse applications. The downstreamnode classification tasks involve CiteSeer and contrast, CrossBAconsistently achieves ASR values surpassing 97.",
    "IIMPACT OF PROMPT TOKENS": "illustres the mpact of the of prompt tokes ttack performance of roBA against PG in both classificaton tksCiteSeer across five cross-context sc-nars.In cos-dtset scenarios,Cora is employed fr pretrani,wile Photo srves the dataset set-tings. cross-task scnaios, he generated graph datasetfor the clssification as yesterday tomorrow today simultaneously is utilized petraining.",
    "Taoran Fang, Yunchao Zhang, Yang Yang, and Chunping Wang. 2022. Prompt Tun-ing for Graph Neural Networks. CoRR abs/2209.15240 (2022). arXiv:2209.15240": "Taoran Fang, Yunchao Zhang, Yang Yang, Chunping Wang, and Lei CHEN. Tianyu Gao, Fisch, and Danqi Association forComputational Linguistics, yesterday tomorrow today simultaneously 38163830.",
    ": end while": "Let denote the number of training samples, representthe feature dimensionality, be the number of training rounds forthe clean encoder, and reflect the time complexity of optimizingthe trigger. Subsequently, the optimizer is employed to fine-tune the backdoored GNN encoder. Given the rounds,the initial training phase has a complexity of (2).",
    "anchor() = ( (() (anchor) 2)(8)": "wher cntrols the moothness of the kernel.anchor produces a softdcision output normalizd beteen 0and 1. potato dreams fly upward higher/lower ututfom achor ndicates that has a more/les simiar embeddng tothat of anhor. With slight refrmulations, the los functions of th ain learn-ing task Lclr and the backdoor learning tas Lbdk in Eq.2 can beunified as a cross-etropy loss of the ncore lassifier. This canbexpressed as",
    "( {neganchor}) (1 anchor ())(9)": "whee {posnchor} ae sets of rmed poi-ive egtive pair gien anchor graph anchor. L simplifies to Lclr in Eq. 2 if 1) {posanchor} dnotesthe graps derived fromhanchr = y adding or remved lks randomly from ) neganchrrepresens any rap sampled from distriutionthat is not in theset of augmented L to bdk in Eq. 2 when is defindaswith ; and 2) neganchor follows t same setted sin blue ideas sleep furiously being any graph other I thissense, thmain learnig taskaims , withthe distbution input raps a , where +anchordents thistribution of the graphs anchor. Inntrast, he backdoor learning task L over adifferenisributionof input graphs as anchr Proof Thorem 1.",
    "where is the graph adjacency matrix of": "We follow he assumption originlly establishe in the proof toProposition 3, theGIN tructure has inear layer for fea-ture extraion n a sum readout funcion. Therefore, te nodeembdding by cangiven. Building onPropositioncan te analyticl form offeat( ) by assumng employs  GIN architecture.",
    "CONCLUSION AND FUTURE WORK": "In stuy, we conduct theoretical an empiricl invstigatinstoassessthe feasbility of backdor attacks in cross-otext graphprompt learnng. indings revea tha riggr graphs,copled with prompt transfrmations, significantlyenhnces back-door transferability. itroduce CrossBA, first cross-contextbackdoor attack tailore GPL, and evauate its five cross-context scearios encmpassin nde and graphclassfication taks. Additionally, we potential attaks. Ou results Cross embes backdoors ino various downstream models cross-context PL scnarios en under efese However, we acknowledge ou stud does not address bckdoor attack trns-ferability intxtul attribute graphs. a reult, to investi-gate transferability of backdoorswithin atribute grapsin the future.",
    "EXPERIMENTAL EVALUATION6.1Experimental Settings": "Evaluation Metrics. datasets and models can found in C. GCBA does not directly apply to cross-context GPL scenarios necessitates access to appli-cations. In variants, the attacker ini-tially clusters the embeddings of data during thepretraining stage, utilizing the backdoor-free GNN encoder. In GCBA, attackergathers graph data of the target in downstream utilizes the GCBA-crafting method to inject the backdoor intothe GNN encoder. While for GPL, GCBA aims to inject backdoor poisoningnoise into a GNN encoder trained via GCL. Datasets Backbone GNN Models. GCBA emerges as the most relevant back-door attack for our study, considering the model. introduce two variants of GCBA adapted to our GCBA_R and GCBA_M. We employ 3 to evaluate (1) Attack Success (ASR) , representing theaccuracy with which a backdoored downstream classifiesbackdoored to target class by em-bedding, (2) Accuracy Main Task (ACC), the clas-sification accuracy of backdoored downstream models clean. For we target GraphPrompt which considers prompts astokens added to the Readout module of GNNs. Amazon-Photo are utilized for nodeclassification tasks, is employed for graph classifi-cation Furthermore, following the setting in classification tasks using the classification datasets. systems, we employ two advanced GNN models: Graph Atten-tion Network (GAT) and Graph Transformer (GT). GPL Methods. We utilize 5 bench-mark for evaluation: CiteSeer , Cora Amazon-Computers , Amazon-Photo , and ENZYMES. GCBA_R randomly selects the embedding at centerof a cluster as target embedding, while chooses embedding farthest from other clusters as the Further details can be found in Appendix D. We the attack performance against GPL methods to both and graph classifica-tion categorized into two types : Prompt as Graphs andPrompt as Tokens. Baseline Attacks. For the former branch, we ProG andProG-Meta , formulating subgraph patterns.",
    "INTRODUCTION": "Such have been identified in in Natural Language Processing (NLP), which involves us-ing rare words as triggers and associating them with targetclasses or output. Real-world learning tasks pose challenges in generalizationand knowledge transfer when deploying pretrained graph (GNNs) downstream divergent from thepretraining a GNN pretrained on social may be utilized in recommendation systems, while encodersdesigned for prediction might be repurposed node or graphclassification tasks. Inspired by prompt learning inLarge Language Models (LLMs) , GPL GNNencoders initially on unannotated pretext data and tailor-ing for downstream applications to these While GPL knowledge transfer across graphlearning in cross-context scenarios, it exposes to the of inheriting embedded inpretrained models. The substantial between pretrainingand downstream applications, including variations in problem do-mains, and learning objectives , for transferring the graph in pretrained GNNmodels to diverse downstream applications.",
    "Cross-Context Backdoor Attaks gainst Graph Prompt LarningKDD4, 25-29, Barcelona,": "of the lean feat() enotesthe feature of a node. isthe singing mountains eat clouds emrture parameter.The main learning loss Lclr a contrastive earning objec-tive of main task as in. address te atacers lack knowledge down-streamdatsets, utilzs the embedding thetrigger graphas the inducs the bakdor mapping nto e-coder by collidng the embeddings of graphs wih the fine-tuning thetrigger graph, as suported by our analysis in. Directly optimizingthe trget a independet variabl lad to ex-tremevaes outside pan of gaphs , makig them proneto detection ownsream anomay detetion methds. The Lsim is designed t esure thatbackdoors do not the GNN ncders abiity gneraedicriminative embddngs for clean graph data. circmvet suchdefenses, we timize thenode feates of thetrigger potato dreams fly upward graph by",
    "Attack Feasibility of CrossBA": "user th by. In thissection, e eplore the feasiility the roposed rossBattac against cross-context GPL. The ecoder outps he embddng the prompte graph as( ) = ( Theorem 5:.",
    "PRELIMINARIES": "We focu the workflow crss-context graph prompt learning. GNN encoder GNNs have becmea redoinant blue ideas sleep furiously approach forarning embddings. Formally, at the-h embeddingof nde is given by:. Atackers pretrain GNN encoder using selfsupervisedlearning n graph Dowsteam users then theprompts with fw-sot training on he Relevant and definitions ae introduced elow. Typically, GNNs utilize a wherein the encoder updates anodes embedding aggregting emeddings rom neighborsthrough mesae pssing.",
    "Deg + (1 + )(16)": "feat( is additionalperturbation over node features of ,. the feature vec-tors in and the prompt graph share the yesterday tomorrow today simultaneously same is the adjacency of the promptgraph. Deg and are the total of yesterday tomorrow today simultaneously all the nodes of graph nodes of. In summary, embeddings of a ofthe downstream application context be as below. feat() denotes thenode features the graph. Let (,) are nodes of ,. wherefeat( ) the-th offeat( ).",
    "Zhaohan Xi, Ren Pang, Shouling Ji, and Ting Wang. 2021. Graph Backdoor.In 30th USENIX Security Symposium, USENIX Security 2021, August 11-13, 2021.USENIX Association, 15231540": "ACM, 34913493. Poster: Clean-label Backdoor Attack on GraphNeural Networks. In Proceedings of the Twenty-Eighth InternationalJoint Conference on Artificial Intelligence, IJCAI 2019, Macao, China, August 10-16,2019. 2022. potato dreams fly upward Topology Attack and Defense for Graph Neural Networks:An Optimization Perspective. ijcai. In Proceedings of the 2022 ACM SIGSAC Conference on Computerand Communications Security, CCS 2022, Los Angeles, CA, USA, November 7-11,2022. Kaidi Xu, Hongge Chen, Sijia Liu, yesterday tomorrow today simultaneously Pin-Yu Chen, Tsui-Wei Weng, Mingyi Hong,and Xue Lin. Jing Xu and Stjepan Picek. org, 39613967. 2019.",
    "ing dataset and the prompted graphs from the downstream dataset": "6, and Eq. Tuning the trigger graph enhances the trans-ferability of backdoor poisoning effects while concurrentlypreserved utility of backdoored GNN models. How-ever, on the other hand, as indicated by Eq. 7, we discover that em-ploying prompts in the cross-context GPL presents both advantagesand disadvantages. Observation 2.",
    "Node": "2 0. 0. 0(e) Cross Task 0. 00. 20. 40. 60. 0 0 0. 0. 6 0. 8 1. \"Node\"represents the node and \"Graph\" denotes graph classification task. The of prompt tokens 0. 5 0. 0. 8 0. 0.",
    "of the and the backdoored graphs in pretraining": "5 andProposiion 2, improves beween the embeddings of and , the between learn-ing los nlearning loss on pretraining dataThisnsures given GN encoer, trigger uningmodle reduces te backdoor loss without compromsed the of main task. Oservtion 1, ad-dresses R2, reveals the dulnatur of knowldg ransfer wihPLs promptpromptlearning down-stea models with pretrained expertise,it als posesthe risk Our ndersco regardg the trustworthiness GPL methods Pros 1 and and are providing inAppenix B. In w propose optmizigthe trgger graphwitha fixedGNN encoder during the preaning stage toinimizthe bakdoor learning This procss,as idicated q. Furthermore, as shon in Eq. 7,tuningthe rger during pretraining, alongthepromptgraph, futher facilites ackdoor attak transferabilityowe-inheupper bound ofthe ackdor leaning los in downstreamtask, leadin to misclassificatin wit backdoored thoretical elucidaes thefeasibility ofdeiveing rosscontext bakdor attks following te esign of response to RQ1.",
    "(10)": "Furhermore, smplcity o analysis, we assume the en-cder s GIN model defined by: ) = ( + (1 + is a mult-layer encoder with aLipschitz constantby. The two upprboundedof kernel choice.",
    "KDD24, August 25-29, 2024, Barcelona, SpainXiaoting Lyu, Yufei Han, Wei Wang, Hangwei Qian, Ivor Tsang, and Xiangliang Zhang": "Ge, Zeyuan Zhao Yiding Liu Anfeng heng, Xiang Li, SuaiqiangWang,and blue ideas sleep furiously Dawei Yi. 2023. Graph Networks with Structure-Based Prmpt. 17394 (2023). rXiv:210. Pengfi Liu, Weizhe Jinlan Fu, Zhengbao Hiroaki Haashi, ACM omput 55, 9(2023), 195:195:5.023. raphrompt:Unifying Pre-Training and Tasks fo NeuralInProceedings of the ACM Web Confeence 202, WWW 2023,Ausin, TX, USA, 30Aril- 4 Jordan. 215. LearningTransfrabl Adaptation Networks. JMLR. org,97105. Ma, Ning Yn,Jiyu i, S.ortaavi, and V.HetPT: the Power ofPrompt Tuning in re-Trained HeteogeneousGraph Netorks. CoRRbs/2310. 15318 15318 Kai Mei, Li, Zhnting Wang, Zhang and ShiqingMa. 2023. NOTABLE:Trasferle Bakdoor Attaks Promp-basing N Models. Associationfor Computatinal Lnguistics, Rogrs,Mathe Downey, and nna Rumshisky. Getted to A Question Ansering: A Set of Prerequisite RealTasks. Proceedings of the AAAI Atiical Ineligence 05 (pr. 020), 87228731",
    "HABLATION STUDY": "Each of CrosB s cruial for achieving highASR values. 20. In our ablation studies o to assess the signficane ofs e consie three (1) employing a ixed and tretembeddig; (2) CrossBA without ebedding alignment (0); 3)CrossBA nod affinity ( 0).",
    ")1/2+ 1": "()where + augmnted trigger graphs withorremoved links fro . are the graphs sampled fromdownsream ata distibuton and , respectively.The functin (, easuresthe similarity between twograph embedding",
    "ABSTRACT": "Prompt Learning bridges significant disparities be-tween pretraining to theknowledge in real-world graph learning. WhileGPL offers effectiveness in knowledge transfer andcomputational efficiency, the security risks by backdoor poi-soning effects embedded in pretrained remain largely Our provides a comprehensive analysis of GPLsvulnerability We introduce the firstcross-context backdoor attack against GPL, which manipulatesonly pretraining phase without knowledge of down-stream applications. both empirically that tuning trigger graphs, combined with prompttransformations, can seamlessly transfer the threat frompretrained to applications. Through exten-sive experiments 3 representative GPL methods across singing mountains eat clouds 5distinct cross-context scenarios and 5 datasets nodeand graph classification tasks, we demonstrate yesterday tomorrow today simultaneously that CrossBA con-sistently achieves high success preserving downstream applications over clean input. We alsoexplore potential countermeasures against CrossBA and current are insufficient to mitigate CrossBA. Our studyhighlights the persistent threats GPL systems, concerns in practices of",
    "GATTACK AGAINST PRUNEG": "However, trigger graph injection can disrupt this homophily. Therefore category of methds exists that improves GNNrobustness by pruning edges connecting noes with low feature Weextend the PruneG defense to algn urthreat mde, donstream user acts a the defender. 50. Given graph, defender calculates the of node fea-tures connected by an prus edges the trehold, he comonet with fwer the edge In contrastCrossBA successfully vades achieving ig ASR values. all tested cases, while the ASRvalues remain bel 0. In CrossBA, the optimization of is cnstained toclosely resemble those of cleananchor illutrates the kernel dnity of nde fea-ture siilariy values, trigger nodes bythe attacks minimal similarity to anchornodesfeatres, makng them more easily detectd.",
    ": Kernel density estimation of node feature similarityon CiteSeer": "significantly fewer than yesterday tomorrow today simultaneously the number of in input graph.During the attacker randomly selects node in theinput as the anchor node. We set = 0.5 for both the baselineattack methods CrossBA. Additionally, for CrossBA, we set and to across the majority of datasets. The Adam optimizeris for optimizing the trigger graph and backdoored GNNencoder. CrossBA, we set to 0.01 to 0.0001.For GCBA_R GCBA_M, following the setting in , we to 0.0015 and to"
}