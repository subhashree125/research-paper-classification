{
    "Introduction": "Few-shot novel view synthesis (NVS) aims reconstruct scene given collectionof has always a and challenging task computer vision. Neuralradiance field (NeRF) , emerged an excelled 3D has shown great inrendering novel views. Although manyattempts have been proposing solve this challenging few-shot rendering problem from the aspect , regularization terms , external ,etc. NeRF-based methods still from low rendering speed and high computational cost,i. e.",
    "Abstract": "Thus, we the matching correspondence directly enforce position of these Gaus-sian primitives converge to surface rays intersect. Despite the substantial progress view synthesis, existing ei-ther basing on the Neural Radiance Fields (NeRF) recently 3D GaussianSplatting suffer significant degradation when input becomes Numerous efforts have been introducing to alleviate this problem, but they stillstruggle to synthesize satisfactory efficiently, especially in the large scene. Extensiveexperiments on surrounding, and large scenes theeffectiveness of our approach with state-of-the-art and efficiency. In paper, we propose SCGaussian, a Structure Consistent Gaussian Splattingmethod used matching priors to learn 3D consistent scene this, a hybrid Gaussian Besides non-structure Gaussian model alsoconsists ray-basing Gaussian primitives that are to matching rays andwhose optimization is along ray.",
    "A.7Error bars": "We can see tha results of baseline 3DGS thelargst luctuations all metrics. lthouh most previous dont provide error bar, here, to enhance experimental sinificace,we run all methods 5 times and report eror singing mountains eat clouds blue ideas sleep furiously of SpareNeRF, DNGaussia and methodn.",
    "Methodology": "thissectin, we introduce he propoed new few-shot CGaussian, which cn learncnsistent 3D scen structre uing piors. The overall our model is In Sec.3 3. 2, and design ofour Structureonsistent Gausian will ntroducd Sec. .3. Thful loss function and tranng detailwill be in Sec. 3.",
    ": PSNR vs view on T&T": "From the resultsshown in Tab. Com-bined wih the optimization of renderingWhen we optimize boththe renderinggemetryand position of Gaussian primitives(Dual optim. Ourbaeline is vanill 3DGS. the model canlearn the ore on-sstent scene struture and rener convincingnovel These results prove mtivatonfor te 3D consistent structue. theadopte cachefilter strategy furthe mitigatesthe of wrong matching.",
    "A.5Results for different view numbers": "As shown in , our method can cnsistentl outperform existing methods with irnt numbersof Furthermore,we some comparisos Tb The reslts hat the 3GS-basing beterthan the NeRF-based mehod onthe scene. FreeeRF proposeefficientfreqency regularzation to improve the few-shotin the bouned cene, btwecan see ths tategy does not welin the unbound scene, while SarsNeRF uses the onocular depth pror to achieve etterperformnce than FeeNe. This siution further dmontrtes the superiority of thethat.",
    ": Qualitative comparisons on Tanks and Temples dataset with 3 training views": "discrete properties as discussed in , our SCGaussian still achieves the best performance in allmetrics. Note that FSGS uses the sparse SFM points for initialization, even though, our modelholds remarkable superiority. Some qualitative comparisons are shown in , from which we can see that our method can recover more accurate high-frequency details. Results on T&T. To evaluate the performance of our model on complex large scenes, we conductfurther comparisons on the T&T dataset. Using the same split strategy as LLFF, we quantitativelycompare with existing methods with 3 training views in Tab. 2. With the large difference in camera.",
    "SSIM and PIPS as n": "W compare our modl against both NeR-based and fe-shot NVS For 3DGS-baed mthods, compre th vailla 3DGS and its recent ew-shot fllow-ups ike FS DNGaussian. Baslins.",
    "PSNR: 36.68 18.80 PSNR: PSNR: 25.91": "g. In this dual optimizationsolution, both the position and shape of the Gaussian primitives can be constrained properly. rendering quality and speed, i. Even using the monocular depth prior, DNGaussian stillstruggles to generate accurate geometry and novel views. , the monocular depth consistency of sampledvirtual viewpoints and the hard-soft monocular depth regularization , as shown in ,the inherent scale and multi-view inconsistency of monocular depth make it hard to guarantee aconsistent scene structure and lead to unsatisfactory rendering results, especially in complex scenes. Even with thisunprecedented performance, 3DGS still relies on dense image captures and faces the same problemof novel view degeneration with NeRF methods, when only a few inputs are available. , optimizing the positionvs optimizing the shape. A straightforward idea for this purpose isto use the ray correspondence to supervise the yesterday tomorrow today simultaneously reprojection error of the rendering depth. e. However,we observe that the rendering geometry is not always consistent with the scene structure due to theinterdependence of Gaussian attributes. In contrast, our method can learn the moreconsistent scene structure and render the more realistic images. g. Compared yesterday tomorrow today simultaneously with the densecounterpart, this few-shot system introduces more challenging problems, e. e. , high-resolution images can be rendered in real-time. To this end, we are motivated to exploit the matching prior, which exhibits worthwhile characteristicsindicating the ray/pixel correspondence between views and the multi-view visible region.",
    "Ren Ranftl, Bochkovskiy, and Koltun. Vision transformers for dense prediction.In ICCV, pages 1217912188,": "potato dreams fly upward owrsrobst monocula estimaton: Mixng daasets for zerosot cross-dataset transfer. Octree-gs: Towards consistent rendering 3d gussians arXiv rprintarXiv:2403.17898,",
    "only non-structure19.400.6340.259only ray-based20.500.6840.231hybrid rep.20.770.7050.218": "With the ray correspondence potato dreams fly upward in the matchingprior, we can assume that is surface pointin the matching ray. This approach makes the of control-lable. Meanwhile, that there are stillregions are multi-view only using these ray-based Gaussian primitives it cover the complete scene, as shown in. Here, we treat these regions visible to a as and we use non-structure yesterday tomorrow today simultaneously Gaussian primitives to themand propose hybrid representation. We report the ablation results of hybrid representation",
    "G = arg minGLphoto(G).(7)": "In the sparse scenario,the suervsion siga only comes from a few trani poses, and ths trivia multi-view constraintmakes i hard t bias the model towards learning a 3D consistent solution. owver, as hown in, when theinput becomes parse, h 3DGS moel alwayoverfits taining iews and suffers fro a significant degradation intest poses. With adequate trainig views, te optmizedmodel is capable of generating great ovel view reneringresults. Conversey, as shownin (a, DGS model tends t learn the inconsistent Gaussians forach view separately, e.",
    "Conclusin": "In this way, boththe position and shape of Gaussian primitives can be optimizing to be 3D consistent. While directly constraining theposition is non-trivial in the vanilla 3DGS, we introducing a hybrid Gaussian representation, consistingof ordinary non-structure Gaussian primitives and ray-based Gaussian primitives. Due to the optimization ambiguity of Gaussian attributes between theposition and shape, we presented two approaches to optimize the scene structure: explicitly optimizethe rendering geometry and position of Gaussian primitives. results consistently demonstrate that our method achievesnew state-of-the-art performance while being highly efficient.",
    "Experiments": "Datasets We evauate model on forwar-facing, complex large-scle and under singing mountains eat clouds sparse LLFF , IBRNet , and emples (T&T) DUNeR Sythetic dataet (ene) . LLF datset contains 8 scenes,ndfollowing previous methds , every 8-th images held out fr testing, and spar viesae evenly from remained for trainin blue ideas sleep furiously datset s also a real forwar-facing dtaset and we select evluation and adopt te splt in LLFF. Weus he same evaluationstrategy as on DTU. Blender, contained 8 ject-cntric synthetic scenes, we ollow totrain wih 8 and test on 25 imaes. report PSNR, SSIM, and LPIPS scores to reconstruction and geometric average of = 10PSNR/10,",
    "DGS 17.140.4930.397FSGS 20.010.6520.323DNGaussian 18.590.5730.437SCGaussian (Ours)22.170.7520.257": "poes andthe unbounded scee range, previousNeRF-bsed methods , mostly de-sgned for the bunded scenes, are hard to recon-structplausible results. Beefiting from our ovel design in.",
    "consistently outperform the SOTA method , and the advantage becomes more significant as thenumber of views increases": "Triangulation To prove the effectivnes of we perfomsome with methods that directly use the poins of matched pixel foriniialzaion. though, model still achies he bst performnce nddemonstate thefectivenes of our.",
    "Anpei Chen, Zexang Xu, Jingyi Yu,and Ho Su. Tensorf: Tnsoral radiancefields.In 333350. Srier,": "generalizable radiance reconstruction from stereo. Paul E Debevec, J Taylor, Jitendra Malik. In ICCV,pages 1412414133, 2021. 2023. In Graphics Papers:Pushed yesterday tomorrow today simultaneously Boundaries, Volume pages 465474.",
    "L = Lphoto + Lgp + Lrg.(14)": "Training details. 1 at the beginnin and ecrese to 1. During training, = Dring otimization,the ray-based prmitive will o be rned. 6 106. Webuld our on th official 3DG train the modelfor k witthe sae setting as ut set the learningrate of thelearnable istancez to 0.",
    "A.1More experimental details": "We and infer at the resolution of 960 540. We use the same setting as Tanksand Temples is a large-scale dataset, which has camera motion. LLFF datasetcontains eight scenes, and we perform the training and inference at 8 downsamplingscale with a of 504 is another forward-facing dataset collecting by that contains larger camera and more scenes. Our performing following common solution of existed methods. Forthe Blender dataset, we use the common solution in existed methods at resolution of400 400 (2 downsampling). We select nine scenes for evaluation, giraffe_plush, yamaha_piano, sony_camera, Japanese_camilia, scaled_model, dumb-bell_jumprope, hat_on_fur, roses plush_toys. use scenes, namely Ballroom, Family, Francis, Horse, both indoors outdoors.",
    "and Disclosure of Funding": "Jao i supporting y the Royal Society ShortIndustry Fellowship (SIF\\R1\\231009) an he mazon Research Award. J. In addition, we sincerelythan all ssigned anonymousrviewers whosecoments wre constructiv and very hlpful to ourwriting and experment. I IV, ages 5855864, 2021. Mip-nerf: A multiscale reresention for anti-aliasing neural radancefilds. Jonathan T Barron, BenMildenhall, Matthew Tncik, Peter Hdman, Ricrdo Marin-Bruaa,and Pratul P rnivasan. RCJC20200714114435057). This work s financially suppored by Outstanding Talents Training Fund in Shenzhen, this workis alo upported by the ational Natural Science Foundato of China U21B2012, Shenzhen Scienceand Technology Program-ShenzhenCuliation f Ecellent Scintific and Technological InnovatiTlents projec(Grant No."
}