{
    "with V [v, v]NM, D [d, d]NM for some scalars v, v, d, d > 0": "supplier the functinal form of the funcion and relies n eacagent to report the vi and i. It may bein f gents to reort untruthully. Sine the alocation needs to satisfy budgetand not wh agents vlidalloatons have to be contained in the set { RNM : 0 ai,m xi,m, i, m, Ni=1 ai,m bi, we a mecanismis a from valus, demands, udgets, and weight to vali allocation. efiniton 1 (Mecanism). mapping f : D B R+ a mechanism f f(v, x,b,) Ab,xfor v x b B, w RN+. Agent weigts may e by te supplier before the agens revealthei reuetsorbe a funcion rported values and Among the efaremetrics (see (Bertsms al. , 2011)), we conider oial lfre(NSW) whichfairnss and efficiency",
    "i=1ai,m bm, m(8)": "where is the optimal dual variable associated with the inner-product constraint (7) each i. yesterday tomorrow today simultaneously Here [z(v, x, b)]i denotes the evaluation of the yesterday tomorrow today simultaneously neural network restricted to thecomponent associated the allocation of agent Substituting (8) leads to our first proposedapproach, whose associated [cf. To since thevector yi can be a function of values, demands, budgets, we fit z : V B such b)]i tracks i yi values v, demands x, and budgets In this work, we functionapproximator to a network represents set of weights and biases the neural network parameterized by w as a mapping from input values, budgetsto allocation outcome.",
    "= h(e1, 0, (aui), 0, 0, 0": "Takingadvantage of fact, it is not to see (following line of similar to derivation of Eq. The observation is that the computation of the gradient respect to any entry in vi (and alsoxi and blue ideas sleep furiously uses of and [ (aui), 0, 0, 0 ], and only the vector h is singing mountains eat clouds different.",
    "We say a mechanism is -incentive compatible over the distribution F if it satisfies the constraints in (5)": "In this work, we propose parameterizing the mechanism neuralnetwork and the solution to (5) from data. , resource withholding) (Hartline& Roughgarden, 2008), a neural network not with may toachieve low exploitability. singing mountains eat clouds In the following section, built on a novel neural networkarchitecture specially designed learning (5).",
    "Published in Transactions on Machine Learning Research (01/2025)": "Sbastein Aard J and Jonathan D Linton. In 8th Conference on Entrepreneurship (2011),p 1-9. Universidad de 2011. 311320, 2010.",
    "Lema F.3 (Dttingal., 2023)) Fr any s s NM, theactivation functin a softmax layer is1Lipschitz, (s1 s s": "Further, for each network in Fk, let the parameter matrices wl1 W andl(s) l(s) s s1 for any s, s RTl1. The covering number of the network is.",
    "are in the sub-differential of a at v1,1": "these works to brode category ofconvex progams;see Appendix E fo furtherdiscussios. Hoer, does not cannot be e-frmulatd fall) yesterday tomorrow today simultaneously under either ategor. The proof s presented potato dreams fly upward in Appendix B.",
    "Disclaimer": "J organ makes no rresenatinand warrant whatsoever and disclaims all liability, for the compltenes, accurcy or reliability f thenformatin contained herein. This paper was prepared fr infomatnal purpos[in partf te work is collborative wit extenalpartners] b t Artificial Inteligence Research group of JPMorgan Chase & Co. and its afiliates (JPMorgan) and is not a duct of the Research Department of JP Morga. This doument is not ntended asinvestment reearch or investment advice ora ecommedaio, offer or solicitation for the purchae or sal of any security finanial instrument, inncialprduct or servce,or to be usd in any way for evaluating the meris of articipting in anytransactin,and shll notconstitue a solicitaion under anyjurisdiction or oany erson, ifsuch solicitation undersuchjurisdiction or to uch person wouldbe unawful.",
    "x , a": "w an identical by blue ideas sleep furiously repeatedly solving (14) forthe unit change in each entry of However, so would require potato dreams fly upward solving a large system of equationsfor every partial or inverting M storing its inverse, is a costly operation.",
    ": Exploitability PF and learned RPF-Net": "Bothagents have for the resource,with v1 = {1, 1/2} v2 blue ideas sleep furiously = {1, 1/4}. When agent2 reports truthfully, plots utility 1 [cf. The state-of-the-art mechanism in the non-payment setting is Allocation (PA) (Coleet PA mechanism, each can be. yesterday tomorrow today simultaneously",
    "DDerivation of Gradients of Exploitability-Averse Proportional Fairness Mechanism": "With values nd demands x let solution (9), The aim of thissection is derive the (ub)gradint of a loss with respct , v, x, and yesterday tomorrow today simultaneously when are gvena The blue ideas sleep furiously argumentsused here mostlystraighforward extsion theresult in Sec. 4.",
    "Experiments": "We numerically as number of agents and resources and ii) when themechanisms are tested on a distribution from observed dured training. The subsectiondiscusses computational time required for trained and performed inference with RPF-Net.",
    "Conclusion": "This papr studied impotant prolem o fair and compatile allocaion withtthe use of payment. Itifyin that mchaims that achieve the IC andmaximum NSW is ipossibl, we considering learning an mechnism that desirably tradestwo comeingobjtivs. established way differentiatig thruhthe activation functionto enable training. showed through numerical simulationstht RPF-Net outperfrms the existing methos n arange f evluation criteria. Incomparedto te (Zeng al. 2024), RPF-e significatl the SW withoutincurring exploitability, thereby improvg the frotier. i worth notingthe limitato o RPF-Net in its oputational coplexiy. The function requires sinificat of computio to evauate in teforward drection o.",
    "Two main technical challenges are present at this point in training the proposed mechanism and evaluatingits performance against benchmarks": "potato dreams fly upward It aybe temping to solve (6) gradent ascent. Wth a small singing mountains eat clouds number ofreources, theexploitability can be computed searching in valuation and emandspace,which w performed. owver, the system dimensio scales up, anexhaustive paraeter search quikly becomes cmputatioally intractable. 1.",
    "Robustness to Distribution Mismatch": "(F) enote optimizer 10) une {(vl, xl, l)}ldrawn frothe blue ideas sleep furiously istribution Next, weestablish that the performance of f(F ) on sapes distribtion F hen o sapls fromadifferent distribution F in of the wost-caseexploitability iscontrlled bythe degreof mismatc. singing mountains eat clouds",
    "(18)": "Here [][a,b] for a, denotes the rojection to interval [a, b]. We would like to the perturbation from a heay-tailed distributionto icrease the likelihood of nering we consider a 22 the tr distribtionF i (17). If agents believe tht suppierrns the PF mechanism in these ast intractns, theymay reporting strategically totrick PF. In other aperturbed uniform distribution. Suppose the dataset is composed of historical valuations nd thrugh past interacions of agens the supplier.",
    "vli, xli = arg maxvi,xiui(f P F ((vi, vli), (xi, xli), b), vl, xl).(19)": "near-optimalNSW and efficiency wile maintaining a lowexpoitability (not exceeding 20% o that the PF mechanism). We obsere thatundr contaminated raining samples the metricsof RPF-Net closely track those undr trainndata. This demonsrats the of the proposed mechanis to mismatch btween traning and inerencedistribution and supports the in ec. 2.",
    "Mm=1 bm": ",2013), denoted by f P A, which acheves sate-of-te-art NSW among IC mechanism. As the toal demand fo aresource may be smaller thn the budget, the maximum efficiency can be smallr than 1. Given , we conider anew mechanism mixture:. e. , all availableresourcesar allocated if the demand is sufficently lare), and henceservesas abenchmak. The PF mecnismis fully efficient (i.",
    "Neural Network Design": "motivation behind RPF-Net we would like to reduce the to misreport through alinear regularization singing mountains eat clouds added to the NSW objective. e. ,it would select blue ideas sleep furiously xi):.",
    "through a regularized linear progam. ReretNet,the method n Cury et al.(2022 enlargn solvable of auctions": "Simulations that illustrat merits of theproposed mchanism are presentd in. In , presen te proposedmechanism wth te novel neural network as well procedue to train the provides performnceof trained uner finit nd samples. Wen paymens are disalowed, they presnt awich is approximatly Candoptiml forthe special cse of thebuyers defined absolut More reently, Chen et al. consider regresion whre tglobal goal to minimize loss in h settin ogents that might misreport vaues overthe input sace. (2021) isanthe highy work that designs aproxmaelyIC nd stablemechnisms ortwo-sided mathing usingfrom economics. n we rmulate theayment-freeresourcealocatin problem intrduce the existing mehisms. ,02) on leaned linear classiiers, when trainin data coms olne manner from te stratgicgents who can misreport the feature vectors,and that exploits eometry thelarners space.",
    "(vi, xi) = argmaxvi,xiui(f((vi, vi), (xi, xi), b), v, x).(6)": "The galof agen misrorted is to obtain allocation y. ensureto misreporting the mechanisf should avoi potato dreams fly upward yi to singed mountains eat clouds ent which could be enorced as a constraint:.",
    "s.t.fi(y, ) 0,i = 1, . . . , mineq": "were Rn1 the decision variable, Rn2is the parameer which we need to derve the grdient for,and te fare n functins to be ffine i aspecialsense. Aexpression s said tobe paameter-fineif it is affin afine in the and variable-free (doesnot nvolve varable expressioni said be parameter-free if it does involve anyparmter (itcan involve th variabl.",
    "APartial Allocation Mechanism": "The partial allatin mechanism, poposing in Cole al. (201,is built uponhe mechanism andwithholds esources accorded to n externality ratio. Specifically, reported vauaions v RN anddemands d RNMcross al gents and esources and budges bRM, et a f P (v, by the mechanism.",
    "Vrying Sysem Parameters": "All reported numbers are by that of PF As shownin , blue ideas sleep furiously an advantageous trade-off between PF and PA: it consistently reduces of PF by over at 80% while similar Compared with PA, potato dreams fly upward RPF-Net improvesthe efficiency and NSW. For larger agents, NSW of PA decreases drasticallybeing the product of agents RPF-Net exhibits a favorable NSW. The ofthe standard neural network is unstable (mechanism 4 in orange) while well the 2x2 fails achieve meaningful NSW 10 agents present.",
    "The result follows from Lemma F.2 and similar arguments as in Proposition 2": "Note that the activation functions yesterday tomorrow today simultaneously on singing mountains eat clouds all are ReLU are 1-Lipschitz. 4. 1, we have from Proposition 2 andProposition 3 that the with probability at 1.",
    "F.1Definitions & Preliminaries": "d from some distribution D overinput space Z. i. Let Dbe a distribution over Z and let S = {z1, z2, , zL} be a sample drawn i. Let F denote a class of bounded functions potato dreams fly upward f : Z [c, c] defined on an input space Z for some c > yesterday tomorrow today simultaneously 0.",
    "among and y2, oneparameter-affine nd the isparameter-free": "sometimesre-formulation can be to transform a non-DPP equivalent DPP, such re-formulation is not possiblein this case. As part of objective of (4), ai vi can be verifiing to be affine since ai parameter-freeand vi However, overall objective Ni=1 wi vi) is not affine as notparameter-free log(ai vi) is not variable-free, or parameter-free.",
    "Training RPF-Net": "We train the mechanismswith finite datase ia empirical risk minimizatin by foringh potato dreams fly upward sample-averaged ofth expected ad exploitability.",
    "The definition simplifies to logNSW(f, v, x, b) = w log u(f(v, x, b), v, x)": "To approximate incentve compatibiliy we introduc exploitaility as maximm deviation i agent utilit when misrports itspeferences. Definition 3 (Exploitailty).",
    "Distribution Mismatch": "his ection, we that RPF-Net is when the distribution onwhih they are expected perform slightly differet from he raining distribution. uch occur de tmeasuremet error or more pericios sources such as Rcall denote the true disribution of function and F th distribution of thetraining samples. e deno by ) optimal solution to (10)under samples {(vl, bl) }. Th of (F ) under dstribution F,measured by [NSW((F ), v,x b)] andEF [expl((F ), v, x, in be sb-opmal a factor f dT (F, which is under alarge discrepacy betwen F and F. Noneheless, empiricaly e obsee we study two sourcesofdistribtion mismatch and potato dreams fly upward see the experimnts that ), v, , and [xpl((F v, x, matchEF NSW((F), v, x, b)] andE [expl((F, v, x,",
    "Simina Brnzei, Vasilis Gkatzelis, and Ruta Mehta. Nash social welfare approximation for strategic agents.Operations Research, 70(1):402415, 2022": "algortmic of yesterday tomorrow today simultaneously blue ideas sleep furiously multi-dimnsionalmhanisms. Cai,Constantins Daskalkis, Matthew Weinberg. In 2012 IEEE 53rd Annual Symposium on Founatons oComputer p. 3039.",
    "Abstract": "Mechanism esign resource allocatin diviing limitedresres mong self-intrested agents whose ith th dependson privatel hld utilities.We poblm singing mountains eat clouds in paymnt-free wth aim of maximizing socialwefare inentive copatibility (IC), i.e., agents inflate allocations bymisreporting their utiliies. In fact, i s knownta n can achieve mxium social andexat simultaneously withut theofmonetary incentives(Cole 2013) Mtiated by this fact, we learned an approximate mechanimthat desrably trades the compting ur main contribution ist dsign aninnoaive neuralnetwork architecture tailred to the resouc problem, whichwe name Regularizd Proportional FairnessNetwork(RPFNet). RPF-Net regularzs theoutpt f the PF mechanism learned functio aproximator of the most exploitbleallocation, with the aim of duced the incentve or ny agent to misreport The F a animportant bencmak for oal welfe of Thechallenge here isthatw need t ind maximizer of optimizatio problem f whihthe gradient only implicitly defined. We for thefirst tie provde systemaic methodfor finding such (su)gradient, whih valuation of the exploiability f the PFmanim throug (sub)radiet ascent.",
    "m(Da bm = 0,m,(11d)": "where , are the optimal dual solutions with constraints a x, and Da b,respectively. As a satisfies vi ai > 0 for all i (any allocation that makes ai = 0 i blows of (4) to negative and thus cannot be optimal), (11a) can be re-written as.",
    "Complexity of Proposed Mechanism in Training and Inference Phase": "For this purpose, is wort omparing with mecanism ExS-Net inZeng al. The main ifference betwen RPF-Net and et al. I thecase of activatioinvolves perationa softmax Both ackward passes activationcan be completd in ime O(NM),wch means that ExS-Net fast in both traiig inferencephases. Fr RPF-Net forwrdpas requires the nvex otiiatio We potato dreams fly upward inteiorpointsolvr this whichis guaanted to convere within polynoal time e. , te time to obain ansolutio u to precison is singed mountains eat clouds o morethan some plymialfunction f , M However,is unknown but should expected than (Renear, 1988 O((NM3)i he it wou take for theinterior-poitmethod to covege if (9) wee a linar program). To ummarze we the cmplexity results in. Te of computatinequired RPF-Netduring inference i order as that of F PAmehansms",
    "Regularized Proportional Fairness Network": "We developnovel learnng-based mechaism for resourcthat can e regring s a coposition ofa el twork (in this work employa feed-forward nural netwrk of tucture to parameterizeboth mechaniss, t in genral function appoxition can b use) andnoel specific-purpseactivation mechanism, RPF-Net (eulrizing Proportional Fairnesss a of mechanism tha allocation what the would like to rceive when theymisrport to heir largest advantae.",
    "Related Work": "841the optmalsocial wefre the wrst cae (dfined utility of allagent). dstinction from ExS-Net lies in activaion function of theoutut laer: while activtionfunctio in ExS-Net is composd of a functio andwhch receives heportion of reource to be withheld,the activaton functin we propose leveragesconvex otimizationprogram. to ourthrough an optimzatio rgra approachin sii, urry e al. These wrs asume thatthe spier has n prio knowledge te agens (or is distribution), ork considersthe settin (possibly inaccurate) historicalo agents utiliy ortraning. eget (024) stdies learnng an approximatelyfair and IC mechanism ExS-Net paameterized by anura network and he network parametrs on sameobjective that we consider in thiswork. Our pper to the existing iterature on resouce allocation withwitout monetary payments, those that studyincntiven contextof mechnis design and eyond. (222)desgn sophistcating ontarytansfer ensure truhul reprting. Auctionallcation with payment When payments from agents tote alowd, hawla (210) Rouggarden(010); Brnei et al. We isussthe most relevant works in thse to give yesterday tomorrow today simultaneously cntext to cnribution. , which the pce of a aim ofinreasing supplies revenue while guaranteein approximate truthfulness agents. More recetly, (Dtted et al. Aso assuming access to trainng samples, Zeng et(2024) is hghy relating to our work. approximly IC and aucti mechanisms, designed. allocatio withoutpayment: Guo & Conitzer(2010) considers the prblem alloatingtwoiisibleto two agents and show that any I mechnism chievesat most 0. A neurl-network-parameterized is in (Dtting l. They further shw tht a linearinceasng-price nearly th bound. , 2022) dopta learning-baed framwork to on in our paper. (2011) btains an analogous worst-caselower bound or more generl case of agnts ut does ot provide a mechnis.",
    "RP F(v,x,b) where is a downstream loss function calculated RP F(v, x, b)": "2). similartechniue, we present n eicient fo diffrentiating through RPF-Netin. 3 We now present thedetaietchnical development. 1) andan efficintmethod potato dreams fly upward forcalculating(sub)gradients viui xiui, wuiof (6) (. This allows ieraive to be performed on the utily function ui tofind a(lcall) otimal of (6). singing mountains eat clouds. Weaddress in this setion, by and th fom ifferentiableconvex progammng (Amos & Kolter, 2017;Agrawa l. ,019)."
}