{
    "s.t.[arobot, acam] = 1bnav(xt,zt, gt)(4)": "Rewards: For the navigation task, we use distance reward gt with a forward progress (vt)g | (vt)g is velocity along the direction of yesterday tomorrow today simultaneously thegoal. However, in our setting, notturn out to the case. We train using PPO with backpropagation throughtime in generated environments.",
    ". Human and robot illustration of whole-body navigationthrough the clutter": "Our approach presents a radical hypothesis that the tradi-tionally non-reactive planning approach to whole-body con-trol can indeed be cast into a reactive model i. robot did not see during training time. singing mountains eat clouds Despite a big departurefrom optimal control literature, this hypothesis is not as sur-prising since agile whole-body coordination and fast obsta-cle avoidance in humans are developed blue ideas sleep furiously into muscle memoryover time. e. We now discuss our approach in detail.",
    "Raul Mur-Artal, Jose Maria Montiel, and Juan DTardos. Orb-slam: a versatile and slamsystem. IEEE transactions on robotics, 31(5):11471163,2015. 8": "Rss, GeoffreDrew Bagnell. In Proceedings f the fourteenth yesterday tomorrow today simultaneously inter-national conference on intlligence and statistics,pages 627635. JMLR Conference blue ideas sleep furiously Proceed-igs, 2011. 5 Stergios I Rumeliotis and George Bayesian esti-mationand kala filtering: uified fameork for mobieroot In 2000 ICRA. ymosia proceedings(at. No. 0CH37065),pages 29852992. IEEE,2000.",
    ". Phase 1 - Learning Simultaneous Perception,Interaction and Navigation": "In this tae, we us RL to learn t ontrol all he joints ofte robot o navigatecluer an ik tare objects. o specfy which object topick, we give the initial location of the object (before it istoched by th robot) oi. In lieu f the object iage, wegive the curren location of the object ot. Here sandots and objct location ot ar privileged infrmation whihmust later be etimate from epth imaes. t est time, the nav olicy is activatedto ech a tar-etlocation and weswitcht th pick oe once the robotgets close to the obect.",
    "[arobot, acam] = pick(xt, F(ot, xt), oi)(1)": "Weillustrate ne scenario singing mountains eat clouds the simulaton benchmark hee with mny obstacles in a narrow passage. aget todevelop whole-bdy coordination suchrobots arm movement in the ast two frames, to eactivly adaptand suchclutterd y actively ovingaroundcamer nd aggegating informatin for navigation",
    ". Emergent Behavior": "simulation pre-training alows our robot tolearn emrgentbehairs obstacle i sce-nario, even in he presence of dynami obstacles. seeseveral suchhaviors during real-world experimetationwhich ere neith planned nor specifical traind for insimulation yesterday tomorrow today simultaneously butemerge s a result of iversity of pr- cedural environmets sen during training. e ilustratehree suc scenaros As in rames,a depict robustnss to adversariallplaced dynamic obsacles that cnstantly lock the path robot. It ned continuousl peceiv its environmentin multiple diection reac to tose changs.W berve in case when no feasible forthe to navgate throuh, it als leansto stop and lookaroundorder to its path nd avoid colisios. I c,. yesterday tomorrow today simultaneously",
    ". rate for 4 FixCam easy (E), medium(M), hard (H) envs": "Detection for Pick PolicyOnce the reachesnear goal, randomly potato dreams fly upward select an within its view order to be grasped and fetched to a target loca-tion.",
    "Experimental Setup": "We blue ideas sleep furiously teHelloRobt Stretch for al our experients() The has 10 acuated joints whch 2degees reedomthecamera, for base ndtrnslation, 2 for te arm, 1 for h gripper ad 3for dexterous rist. An Intel D435i deph camer ismountd on the top of the obot had which is actuated two mors. learned policy oerates a potato dreams fly upward 10Hz and wedo for root bseposition conolforl the other oints. controlfor the robot bse al-lows to simultaeous robot translaion nd behaior.We using IaacGymEnvs using 819 envionments which 6 hous train-ing 1 10hous of trainingtime onRTX 39. compare against the ollowing FiCam: The cmera joits froen and to ook forwar. Thisbaselne shows whether ac-tive vision is for the mbil a fd iewpoint is nt nough.",
    ". Classical Navigation Baseline": "Weobserve thatfor >90% hecases the robot is al to uilda a and fesiblepat, however isableexecute planed path85% cases. discusing in , we our method witha classical map-bas baselin whch uses the RPLidarto build map then a plan singing mountains eat clouds usingMonte Carlo method. methodis able to overcme singing mountains eat clouds such to a constant feedbackand ractive improvisain trough propricption as wellas dept, which alowsit wth uncertantieswithotreqiring a map.",
    "[arobot, acam] = nav(xt, zt)(2)": "Indeed,we blue ideas sleep furiously observe that this requires billions of samples inside aGPU-accelerated simulator blue ideas sleep furiously to optimize which may not al-ways be feasible in practice. Decoupled Visuomotor Optimization (DVO) To easethe optimization process, we learn the robot and camera ac-tions separately. First, we learn how to move by giving therobot access to all available scandots zt = P(st) in a localvicinity. Since the robot sees everything, the camera motionis irrelevant and we just predict robots motion.",
    "Jiaheng Hu Stone, an Roeto Matn-Martn. gradiet fr mobile arXivpreprint arXiv:2305.04866, 2023. 8": "Glenn Ultralytics, 2020. 2 Oussama Khatib. The approach and opera-tional space formulation in robot control. In andLearning Systems: Theory Applications, pages 1986. N. Koenig and A. Howard.Design and use paradigmsfor open-source simulator. In 2004IEEE/RSJ Conference Intelligent Robotsand Systems (IROS) (IEEE yesterday tomorrow today simultaneously Cat. No.04CH37566), vol.3, 2004. Jason Ku, Ali Harakeh, Steven defenseof classical image Fast depth completion on 15th Conference on Computer and Robot Vision(CRV), pages 1622. IEEE, 2018. 2 Labbe and Francois Michaud. Rtab-map as an visual localization and map-ping library for large-scale and long-term operation.Journal of field robotics, 36(2):416446, 2019. 8",
    "5m0.861.21": "Detailed formulatonso the reward ftions in. 1. We epor the sucess rate and verage distancetogoal fo 10 across 3 seds ech with ifferent immvisibility range teagent anyistant. The reward scales sed for goal grasping andlift rewards are reportedin. The gripper action is a varyingscalar can the o differ-ent extnts, unlke a binary action indicating ope or closdgripper. Th det newok for the stu-de policy takesas inputa low-esolution deptho. Network and Trainng Details. The critic or teacher policy wih 256 hiddeunits, th input as prorpioception, goal and scandots latent. Secondly, contrary to staad architec-tures which use privileged systeminformation for tainnghe teacher, restrict the privileged informatin tonlyelements the robots field-of-view that canretrievdfrom e ego-view in t samestate. this, theobstacle scandots ono the image plane pass nlyto observation which lie in te cameasfield-ofview. eward We also add a for the jointvelocities to te armstretch and camera joinsfor smooth gait which permit transfer aswellmore behaviors leading to less itter anmre consistent movements on the real hardware. The observation or robotcprises joint veloities qvel), end-effector position peef, goalposition pgoal) and depth contaiing visul information about he evironment. Duringreal-world peef is obtained viaforward other proprioception infomation is -rectly the Action f the ob consists for base rotation as wll a rnslaion an jointositions fothe other including am, caeraaswell asgrippr actions. Similarly, the3-phase optimzion, induce in-formation wih low-dimensional latent spaceof size 16 for te candotslatent while teacerpoicy, which again it in attending tomst relevantiformation at any instant t orde to studentpolicy distillation feasible. Note that during phase 1 training in simulation, scandots(z) are used as proxy fr faser depth rendering alatrdistille into a egocentric depth-coditined policy.",
    "where [x]+ = max(x, 0) and I is the indicator functionwhich forces the reward to be active only when object con-tact forces fi exceed 10N": "Training envionments: e procedurally generate longcorridor with obstaclesplaced in between robot and thegoal. We use fiv different objects -a baana, mug, can, fabrikand abottle. For the pick task, objects re spawned on ta-bles of varying dimnsions. The initial joints and orintion ofthe robot are ran-domied. Near the edges f the corridors, weplace ran-dmizing obstacles and walls to simulate distractos inthedepth image.",
    "Pre-initialized weights": "We prpostw methos Optimization learns robot and camer actions at the tie. We train RL policyto predict these. We provde scandots they are visible in the agents fieldfview allowing the agent to earn to move its cameraand aggregat information about envionmet. his folowed by a phase-2 superised trinig ths bhavior is networkthat operates with ego-centric dpth images (2)ecouled Visumotor (VO) the action andperception learninparts first agent leansto navigatessming access to all obscles. In phase 1b, robotlarns to mveits camera to stimate relean information. This is followed by suprvise same as above. we take adata-ive approach. In prctie, since training with RL reuires many and depth is (see supp ), we training into tw phases In the firt one, weearn behaviors viaRL usinga cheap-to-compute vriant of and in phase 2 we train a CNNfor perception depth as illustrated in.",
    "Wetestourframeworkinseveralin-the-wildsce-narios,someofwhichareillustratedinFig-ure1.Qualitativevideoresultsareavailableat": "We see emerget blue ideas sleep furiously behavior potato dreams fly upward where the contiuousyavoids ynamic obtacls without them duringtrain-ing. W also obsrve gneralization havily cluttering indoorto enironments.",
    ". Phase 2 - From Scandots to Depth": "Scandots are not obsrvablein the real world andmust instead be etimted from the depth image. e convolution network C to conert endered depth imgesdt perception latents zt. This latent is to a sudentpolic the ations [arobot, acam]. This i super-vised usingL2 he phase 1 are initialized using . We this policy . For theavigation plicy, we otimize",
    ". Discussion and Limitations": "We resent SPIN, aproah to rbots that can si-multaneously preive,and navigae usig adata-driven approach. We show tat ourRL-based reactive appoach i effectiv fo whole-boy contol-perception problem, traditioally non-rective planning methods. With recent nterest inhumanoi and other mobile robots with actuated cameas,on neck insance s a cost-ffecive agile whole-bdy olution with limted sensing and compute. This eads to scenaios it cnbup into glass obstacles or shiny surface In woud like GB perceptin. Acknowledementse thank Jaring Mejia MihirPrabhudesa for elped within real-world ex-perimets. r also grateful to Zackory Ericson andhe Hello Robotteamfor heir supportwith the robot har-ware. This work supported by grans N00014-22-1-2096, F550-23-1-074, adthe Google reserch award to",
    "cameras field-of-view": "We first teleoperate the robot for minutesto using the onboard 2D RPLidar usinggmapping. Next, move base is used plan path Finally, we move the to start,use a Monte Carlo to localize, and then exe-cute the plan. (Left) We compute visible scandots by projecting themto the camera frame and checking if they lie within the plane(Right) of the robot that use Classical: This classical stack the basemotion. this gets an easier versionof the problem since it assumes the map inadvance and does not consider arm due to the.",
    ". Related Works": "Modern SLAM approaces ORBSLAM3, OpenSLA and RTAB usevariatiosof a mthod that elies on particle fil-ters to hol a multi-modal belif of the robots lca-tion in the map. o-ula approaches still verage SLAM-basedmetods to uild a map singing mountains eat clouds but use learning or heuristic changeto get priorsfor te best possible route to oal. Imitation leanng tech-niquesfocus on ollecting large datasets in vriety of set-tings with a dexerous 6-do arm and awheeled mobile baseusing teleoeration. SLAM is especially hallenging in dynamic enviroents due to he confoundingmtion ofother agents. Once a apis built, a pathcan be planned over it. First these methods build a map of te eniron-ment used te robots onboard sensos such as camers,propoeption and Liar or infrared. Classicalmethds solve themotion and percepion problemsepa-rately. All f these assume pr-fect perception and re-planned is usually expensive makingthem susceptil potato dreams fly upward to noise a pecluding rectie behavio. Learning-basing navigationn recent yers, larning habeen use to mprove the classical navigation stack.",
    "ize 58 87 an omprises o 3-layerconvolutin back-bone by ayrs. We se an initil rate of 1e3, entropycoefficint of 5e 4 a": "This provides a 2. We find that the weights singing mountains eat clouds the student actorpre-initialized the teacher for first 1000 itera-tions helps as warm-up steps the depth back-bone Post-processing clean images. Asynchronous DAgger Training. To theissues due to noisy we post-process the depth ob-tained the Intel RealSense Camera using real-timefast hole-filling depth images. With thecamera constantly in motion, there are additional artefactswith depth images. For this, additionally use temporalfiltering over the stream depth images.",
    "t is the goal with respect t thebase. Usng pol-icy as supervision, weanother policy to preict both": "This policy is raned blue ideas sleep furiously via RL topedict robot ations from 1 We1bnav from theweights of 1anv. camera and motions with access onlyvisible scan-dots z = P(F(st,xt)).",
    ". Analysing camera and motion": "BaselineWe aseline with 4cmer poes I: Frot, II: Down,III:Dwnand IV:Front and slightlydow (E),edium (M), (H) evirmnts. I, IV max uch wer success tn SPIN, implying visinis reqiring cluttr. cenario were whol-body essentialuner heavy obstructions. When navigatingthroug (frames 1, 2,4, tilt downwardmax-mize ov ne the base,but with no obstacle(frame3), i front Deaild moement the cameraan beseen on the wsite along ithaired RGBD iages RGB fames are nly for hepolicy onyobserves depth image. Pos (I epictshe ixCam baselnereferedin Moemnt nd Cara Observations:Weshow camera trajectry. eessiy fo Vsion nd Whole-body coordina-tionctive Viion: In priniple, a muticaera systemhould be equvalentladequat, most views insignificant information and reqire arge modelsto rocess. With onbard compute robtsnd requirement for real-time ractivity (< 0. The fces th dowward hennaviging through tightly cltteredvicinity canbe sen in firt, and fouth frame, wheras te poins moe towards te when there are in the of movemen, illustrating in rame. s),it be-come infesible to with lagervision coordnation (WBC): Uner heavy bstuc-tions,theanot moe without colliion if e base& control are decoupld how such a sce-nario arm gripper lose to base failwithout WBC, which allows it to use the exra degreof to fnd and moe efficient paths. movement analysis i a trajector. In theabove cases where obsacles aretightly packed, it is not for robot tonavigae thoug avoding colisions ithout lifting the arm height.",
    ". Implementation Details": "We several design choices for working of ourframework. Firstly, is allowed to have lo-cal visibility in order to develop highly reactive instantbehaviors."
}