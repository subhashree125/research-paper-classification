{
    "Seyed-Mohsen Moosavi-Dezfooli, Alhussein Fawzi, and Pascal Frossard. 2016.DeepFool: a simple and accurate method to fool deep neural networks.arXiv:1511.04599 [cs.LG]": "2018. In Procedings f the 58th Annual Meeing of the Assocition singing mountains eat clouds for Comput-tional Linguistics. Mthew E. 08774 cs. CL] OpenAI. arXiv:2303. (203). 2020. OpeAI. eep Contextualized Wrd Repreenations. Peters, MarkNeumann, Mohit Iyyer, Mat Gardner, ChristopherCark,Knton Le, and Luke Zetlemyer. Yixin Nie, Aina Williams, Emily Dinan, ohit Bansl, Jason Weston, ndouweKiela. 2023 OenAI Chatbot. Asociationf Comutaional Linguistis, nline, 884901. 2023.",
    "Ethics statement": "ultilingualMultimodal ofChGPT n asoning, Hallucinati, and Intactivity. Dbeia: for of pen data. primary concern is thepotntial generation of harmfu infrmation. This texthatmay e offesive, misleading, or in ther Therfore,one shoud b cautious when takin such mets into prcticluse. the opportunities nd risks of foundation modls. n internaioalsemantic web041 CL] Yejin Samuel Cahyawijaya, Lee, Wenliang Daian Su, BryanWilie, Hol Loveni,Ziweii, Tiezheng Willy Chung,Quyet V. Generating Natural aguage Adversria 2007.",
    ": Resuts o te T5770m, ndOP-2.7bmodels performance with and he appliation ofLoRA, IMDBdataset": "6. in Sec 3.has been a roundbeak-igapproach, about significant eduction in duing modeltraining. Inthiscase, in queston is mdel 3b, andOPT-2. IMDB dataset serving as our benchmark for this analyss. The that adversarial attack signiicantly accuracy acrs all models, LoRAs use. both the attack success ate nd rplacement rate, keymeasures of resiiencetactics, unaffectedyLoRA. This indicates tht while LRA enhances optimization,it the models defense adver-sarial attacks providng optmization benfits withou sacrificingrbustnes.",
    "Abstract": "Language Models have revolutionized natural lan-guage processing, but their robustness against adversarial attacksremains critical We presents white-box styleattack approach that vulnerabilities open-sourceLLMs, including Llama, OPT, yesterday tomorrow today simultaneously and T5. We the impact of structure, and fine-tuning strategies their resistance toadversarial perturbations. Our evaluation acrossfive diverse text classification tasks a new benchmarkfor LLM robustness. The this study have far-reachingimplications for the reliable LLMs in ap-plications and contribute to the advancement of trustworthy AIsystems. singing mountains eat clouds",
    "Model Architectures (RQ3)": "his impact te models accuracy. Our singing mountains eat clouds shows models with clasificaton headare moe cate headless ones due to heir simplifid out-put which decisi-making, especially in models with. The architecture a modelsspace significantly nfluencsits and resilience against For mod-es a clasiiation head, the otput is simplified a binarydecisin, contrasted with OPT models ithout uch head, whihmust identify negative poitive labels from a vast vocbuary.",
    "Zengzhi Wang, Qiming Xie, Zixiang Ding, Yi Feng, and Rui Xia. 2023. Is ChatGPTa Good Sentiment Analyzer? A Preliminary Study. arXiv:2304.04339 [cs.CL]": "Chi, atsunori Hashimoto, Orol Viyals, Liang,efDean,and William e-dus. Emergen of Large Lnguage Models. 07682 [c. Wei and Kai Zou. 2019. EDA: Data Aumentation Technique forBoosting Text Classification Tass. In rceeded of 2019Conference n Empirical Methods i Languge Processing and the Joint Conference Language Association fr Hon ong,Cina, 6382638 GneratingluentAdvsaril Exampls for Natural Lnguages. Asciationfr Lingiics,Italy,55645569 PT: Open Pre-trainedTransforme Lanuage odels.arXiv:225. 01068 [cs CL].",
    "LLMs Fine-tuning Techniques (RQ2)": "62.1Instruction Tunng. stu imp o instructio tunon model compaed the performance of FlanT5 withthstandard T TheFlan-T is an advanced varantof T that hasundergoe instrution cross downtreamtass. In contrast, traditional T5 was traine potato dreams fly upward suchnextensive procedur.Basing on ou exprimental results, as in he table, decline in bothT5Flan-T5 underaversarial attacks. This that models, irespec-tiv of weter tey hve undegne insruction tuning, remainsuseptibl to adversarial mnipulations. Futhermore, conistentwith our peviousfindings we that as e model size in-creases, te attacksucess ratetends to clin.Interestingl, as shwn Fig 3, resulsFlan-T5 exhibits highr AR tan the standard T5. This thatmodels to uning, le Flan-T5, be oreeasily Wehypothesize reason for thisobsevation:Th instrctin tunig proces for FlanT5 encompassed to This might have rendering the with asks related to a result, attackerscouldmore easily pinpoint words in iput that weeinfluentialand susceptible to replacemet.",
    "Chengwei Qin, Aston Zhang, Zhuosheng Zhang, Jiaao Chen, Michihiro Yasunaga,and Diyi Yang. 2023. Is ChatGPT a General-Purpose Natural Language ProcessingTask Solver? arXiv:2302.06476 [cs.CL]": "Colin Raffel, Noam Shazeer, Adam Lee, Sharan Narang,Michael Yanqi Zhou, Wei Li, Peter J. Liu. arXiv:1910. 10683 [cs. LG] Richard Socher, Alex Perelygin, Wu, Jason Chuang, Christopher D Y Ng, and Christopher Potts. deep models for sentiment treebank. Proceedings of the 2013 conference.",
    "Datasets": "T evaluate the mdels perfomance under vaious tsks and tsresilience to attacks, we employe fe datasets, cate-gorze and muti-lass classiications.",
    "MRPC Dataset Results": "7b model stnds out. It reaches its minimum at the T5-770mmodel. For the OPT models, althoug their AR is mch lowercompared o the T5 series, thereis a consistent decrease in SR asthe siz of the OPTmodels increases. It also presents lwer ASRompared o T5 modelsbut similar performance to OT models. The Llama models,demonstrate consistently high accuray. For SS-2, the ASR o T5 models exhibit end entirely contarto that observed for MRPC. Oe ore observtionin the OP seris is the overall decrease in ASR with increasingmode size, ut this trend is disrupted a the 13b prameter mark,where ananmalousincrease i ASR is observed.",
    ": AGNews Dataset Results": "ForT5models the data shows a singing mountains eat clouds lower on thesetaskscompare tobinary datasets, a better resistance toattacks in potato dreams fly upward scenaris. contrast, and models exhibit.",
    "Model Size (RQ1)": "In this section, we the performance metrics of various mod-els across multiple tasks. The datasets under examination includeIMDB, SST-2, MRPC, AGNews, and DBPedia. measure the per-formance and robustness of LLMs with the metrics Acc/attack,ASR, and Replacement Rate . The results from the IMDB dataset in reveal distinctperformance among different model architectures. theT5 Series, accuracy generally improves with increasing model size,from 60m 11b parameters, but the relationship is nonlinear. that while tend to be more not increase uniformly model size. Furthermore,the of these models to adversarial does not followa simple inverse relationship model larger T5-11bmodel shows more noticeable decrease in accuracy under the models, a similar upward trend in accuracy ob-served increasing but the Attack suggesting better resistance to attacks. In compari-son, the models demonstrate superior performance in bothaccuracy against",
    "Conference17, July 2017, Washington, DC, USAZeyu Yang, Xiaochen Zheng, Zhao Meng, and Roger Wattenhofer": "2, and its performanceis assessed on a test dataset altered with adversarial examples. 2, evaluating its accuracy on corresponding validationset to establish performance baseline. 2) Adversarial Attack Assessment: The fine-tuned model under-goes adversarial attacks described in Sec. in Sec. 3. 4. 3) potato dreams fly upward Robustness Evaluation: We compare models accuracybefore and yesterday tomorrow today simultaneously after the adversarial attacks to assess its robustness andvulnerability to such manipulations.",
    ": The experimental results of T5 and Flan-T5 on IMDBdataset": "One main factor contributes to thisvulnerability is DeepFools efficacy with last layer FFN: In suchmodels, DeepFool can more readily discern the optimal directionfor launching its attack, amplifying the ASR. On the surface, thissuggests that launching adversarial attacks against these modelsis a more straightforward task. limited processing power. This marked efficiencyunderscores a reduced robustness in these models against adver-sarial intrusions.",
    "Related Work2.1The Evaluation of LLMs": "In recent years, LM has experiencd significant d-vances.A large number exemplary large-scale as GPT-4, hve singing mountains eat clouds eerged, showcasing exceptoal performaceacrossvarious sector.Numerous have explored the capabilities f LLMn naural blue ideas sleep furiously language understanding, includin text as.",
    "Arsene Fansi Tchango, Rishab Goel, Zhi Wen, Julien Martel, and JoumanaGhosn. 2022.DDXPlus: A New Dataset For Automatic Medical Diagnosis.arXiv:2205.09148 [cs.CL]": "09288 Ec Wallace,Shi Nikhil Kandpal,Matt Gardner and Sameer Singh. A]. riggers for Attacking and Anayzng NLP. Truong, Sim-ran Mantas Mazeika, Dan Zinan Lin, Yu Cheng,Sanmi Son,and B Li. InProceedingsof the on Empical Methds in Lanuage andhe International oint Conferece Naural Language Processing(EMNLP-IJNLP) Asociation for Computationa Linguistics, 21532162. 2023. Hugo Touvn, Martin, Kvin Stone, Pter Abert, Amjad Almhairi, Ys-mine Babae, ikolay Bashlykov, Batra, Bhagava, Shruti BhoseDan Bkel, Lukas Blecher, Cristian Ferrer, Moya Cen, Gullem Cucu-rull, Davi Jude Fernande, Fu, Wenin potato dreams fly upward Fu, Bran Fuller, CynthiaGao, Goswami, Goyal, Anthony Hartshorn, Saghar Hoseini,Rui Hou, Haka Ina, MarinKaras, Vktor Madian Khabsa, IsabelKloumann, Artm KorenevMarie-Anne Lahaux, ThibauLavril, Le, Dana Liskovich, Lu, Yuing Mao, Xavier Pushkar Mishra, Igor Mlybog, Yixin Nie, Anrew Poulton,JeremyReizenstin, Rashi Rungta, Kalyan Ala Schelten, Ran Silva,ric Smith, Subramaian, Xiaoqing Elln Ta, Binh Williams, Xiang Kuan Xu Zheng Yan, Zhan, Anel Fan Mlanie Kambadur, Sharan aang,AurlienR-driguez, Robert Stojnic, Sergey Edunov, Thomas Scialom. arXiv2307. 2023 Llam 2:Open Foundain and Fine-Tuned Models. CL] Jindong Xixu Hu, Wenxin Hao Chen, Zhen, Yidong Yang Hang, Wei Ye, Xiubo Geng, Yue Zhang and XingXie. DeodingTrust: A Comprehnsive Assessmt ofTrustworhiness cs. 2022. 12095 cs. rXv:232. AdversaialGLUE:AMulti-Task enchmar for Robustnss of Lnguage Moels. CL] BoxinWang, Chjian Xu, Wang, Zhe Gan, Yu Ceng, JianfengGao, Ahmed Hassan Awadallh, Bo Li. Boxin Wng, Weixin Chen,Hengzhi Pei, ChulinXie, MintonKang, ChenhiZhang, hejin Zidi Xiong, Ritk Duta, Rylan Schaffer Sang T. On the Robustness of ChatGP: An Adversarial nd Out-f-distributinPerspectve. arXiv:2112840[cs.",
    "Experimental Results": "The by three key research questions (RQ):RQ1:How does the obustness f variously sied models advrsarial attacks distint tasks?RQ2:Do cntemporary rainig techniques or influencetheir performanc and robutness?RQ3: model archtecture (e. , fine-tuning with acassification head. In we conduct etensiv experimens to the ro-bustnessof LLMs across five difrent datasets.",
    "Robustness in NLP": "5 and GPT-4 models,revealing vulnerabilities such as ease of generating toxic and leaking private Despite GPT-4s im-proved performance on standard potato dreams fly upward benchmarks, it is more susceptibleto adversarial prompts, highlighting neing for rigorous trust-worthiness guarantees and robust safeguards singing mountains eat clouds against adaptiveattacks. Withthe introduction of more sophisticated models boasted novel ar-chitectures methodologies, an assess the robustness of these newer This is especiallytrue for LLMs, which present unique challenges the of robustness research. For instance, employs evolutionary algorithms swap outwords their synonyms. introducing HotFlip, utilized gradient information to manipulatecharacters within text.",
    "Geometry Attack Methodology": "Our focus is on geometricattacks to assess the vulnerability of LLMs to adversarialperturbations. We propose a systematic methodology grounded ingeometric attack The sections detail the stepsof our Computation for Influence Analysis: We com-mence calculating the gradients of the generation loss L withrespect to the of sentence S. The cross entropyloss L measures the dissimilarity between the prediction and labelexamples in output This computation is for those segmented into sub-tokens. We determine the gradient of Lwith respect to the vector. This step thedirection in which should be adjusted to maximize the loss L. Selection of Candidate Words: we a tar-get word from Utilizing the DeepFool algorithm we identify replacement words, forming candidate set{1,2,. Candidates are based on cosinesimilarity , with below a defined being ex-cluded. The projection onto as =. 4) Iterative Process for Enhanced Adversarial Strength: Theselected word replaces in , updating methodology to enable prompt for attack generationtasks, its application beyond the previously limited scopeof classification tasks.",
    ": The of our adversarial robustness": "In foralsense: = (; ), were stands forthe given answer. Te predictionis acurat when equals.An adverarial tack basing on word elacement rocesse theriginalample t prouce an aversarial verion bre-placing -th word in with a alternatie wor .Toensure that the origil sampe and its adversarial counter-part mainain semantic simiarity, evalent mehodologiestypically employ synymous terms for replaements",
    "Introduction": "recent the ield f intelligencehas rmarkable n theapplication of LargeLanguage Moes (LLMs). To oerise, orrepublih, to poston servers or to reisribute to lists, pro permissioand/r a fee. To addres issue, several stdies have been con-ducted to assess bustness of LLMmodels. make digital or hardf or par of this or personal orlassoom ue is witou fee prvded that are not mdeprofit or comercial advantage and hat copies bear ths and the fullitationon he firstpage. Rquest permissin from , July Washington, DC, USA 2024 held y theowner/author(s). Theseas ,GPT- , and Llama-2 , ave demonstraed exceptina per-formanc in viou natral laguage nd eneratiotasks."
}