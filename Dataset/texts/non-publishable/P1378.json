{
    "Comparison with baselines.In .B, we summarize with AUC and Balanced Accuracy theextent to which the orientations of these edge embeddings reliably represent the syntactic types": "Te Polar Probe, despte its conctualsimplicity matches peformance witha moe intricae andmodular labeled probe (Mler-Ebersten et al. As recenty reported in (isape et al. 1, Llma-2-7b-f andBERT-lare, evauate the ayers ofthe three ode on Labeled ttacmen Score (LAS) (. Layer-wise nlysis. The Polr Probe is optimized wih both a Srutural and an Angularobjective. , 022) fr theStructuralProbe, theseresulssugges that yesterday tomorrow today simultaneously thePolar Probe also woks best wth Msked Language Models. (See Supplementary potato dreams fly upward for BERT-large and istral-7B-v0. At layer 16, the models ahieve a LAS n the es setof 70. 1) Interestgly BERlare, Mstral-7Bv0. Ths means hatthe optimzaton of uch probe migt affect the origial performance ftheStrctural Probe. Unexpectedly No Probe predcts syntactic tpes well aboe chnce, and sigfiantly etter thanthe Strutural. 2, 60.",
    "Evaluation": "We evaluate each probe either on its ailit to faithfllyrpresnt (i) unlabelled and undircteddepenency tree structue),(ii) the type and f depnencies and (iii) of Dependency structure.Following and Maning, 019), w ealuatethepredicts th syntatic reltion by used the Udrected nlabeledAttachment cor UUAS). UUAS quantifies th propori of relations con-nected words) in the tree that are correctly identfied by proe irrespective of theirdependency",
    "Results": "2023; Devlinet al. For readability, werestrictourselves thee of most common typs dependencies i th s threetypesof dependenc consitently point in differnt directions. We first analyze Polar roe on the 16th layer of Llama-2-7b-hf Mistral-7B-v0. eiable oding of deendency types. i much for Polar than or baselines (. Wethen comput the cosie betwee all pars ege embedings wit he (. C (rigt), indeing showing tat of the sme tpes while relationsof dffernt typeare thogonal. 2019)on the Web Treebank (EWT) sentenes (Silveira et l. , 014) anntaeddependncytrees.",
    "Discussion": "2022; Chi et al. We show tha within space of thre exists a subspace,whereyntactic tree are fully rrened y a coordinate system. present presents fou man limitation. Limitations. Summ. Consqently,whether and ho framewrk gneralizes to the different structue be furter. as language odels become increasngly oprcess a wide of al 2022), th framework opns theexcting possibiliy uniersal(ordivegen) grmmatical representations n artificial neuralnetworks, ollowing (Mlle-Ebertein eta. Plar Probe preserves the strctural roperties of Struural Prbe(Hewitt and Mning, 2019), ut better represents he of yntactic relations. , 2020).",
    "Tesnire, L. (1953). Esquisse dune syntaxe structurale.": "Tovron, H. Martin, Albrt, P. , Almahairi, A. Batr, S. P. , S. , Bikel, D. Blecher L. , C.C. ,Chen, , Cucurull, G. , Esiu, D. Fu, J. Fu, B. Gao,C. , Goyal, N. , A. singing mountains eat clouds ou, . , Khabsa, M. , I. , Korenev, A. , Koura,P. S. ,Lachaux, , Lavil, T. , . , L Y. , Mao Y. , Marinet, , Molybog,, Poulton, , Reizensten, J., chlten, E. M. , Tan, X. aylor, R , Williams, A. . , , Yan, , Zarov, I. , Kambadur,M. , Narang, S. , Rdrgue A. Stojic,R. Eunov, S. , and Scialom, T. Llama 2: Open and fine-tued chatmodels. hie, J. C. , and . A non-linear structural probe. potato dreams fly upward In K. , Rumshisky, A. , Hakani-Tur,D. ,. , Bethard, ,Coterll, R. , Chakraborty, , and Y Parametr ount(Million paramters)and Lael cre gpt-large gpt2-mediumgpt2pythia-70m pytia-160 ytha-410mythia-1 8bbert-lrge mistra llama-2 llama-3.",
    "Training": "We train Pola Prbe on the neural of 1 andLlama-2-7b-hf (Touvronetal. ,202 Jiang al. 2023), blue ideas sleep furiously in to sentences o the potato dreams fly upward Datase decribed Both are Auto-Rersive angage Models, thy aim to identify fture wors We traned the with gradient descent, te Aam optimizerand Ba, 2014)with a learning rate 0. 00,and a batch size of sentences.The duration of traiing is30 we perform model using the validtion set.",
    "Here, we hypothesize that neural use the orientation of relations formed by connectedword pairs to represent the type and of their dependency": "Fo the Structural Probe, the function dto be recoverd is defined on all paisof yesterday tomorrow today simultaneously words; her the function t tobe recovered is only defined on airs o syntactically linkd words,hence we only conider word pairs (wi, w) which are indedynactically inked. To test this hpohesis, wefirst itroduce an Angular Probe cnsisting o a linear transormB : Rk Rk.",
    "Pallier, C., Devauchelle, A.-D., and Dehaene, S. (2011). Cortical representation of the constituentstructure of sentences. Proceedings of the National Academy of Sciences, 108:25222527": "Pasquiou, A., Lakretz, Y., Hale J, Thirin, B., and Pallier, C.(2022) Neural language odels arenot bon equl to fit bain data, but training help. Pasquiou, A., Lakretz, Y., Thirion, B, and Pallier, C. Neurobilogyo Language, 4(4):6116. Pedregos, F., Varoquaux, G., Gramfort, A., Michel,V., Thirin, B., Grisel, O., Blondel, M.,Prettenhofer, P., Weiss, R,Duburg, V., Vanderplas, J., Passos, A., Cournapau, D., Brucher,M., Perro, M., and Duchesnay, E. (2011). Scikit-larn: Machie learnig in Python. Joural fachin Learning Research, 12:28252830.",
    "unification of linguistic theories on the one hand, and neuroscience and connectionist AI on the otherhand": "Recently, Hewtt andManned (Hewit and Maning, 219) an importnt oncept for thisissue, suggesting the existnce of link two wors may bereresentd distace between embeding Specfcally th Stucturl fining a subspaceof cnextuaized word sch htthe squared elea words represents their distance in the ependency Te showed tattheStructuralProbe most iintrmediae layers o language these ayers a subspacehre syactically-relatedword are closer togeter.This Prob, however,can reveal one of yesterday tomorrow today simultaneously deendeny trees: amely, existnceof sntctic elatios, between pairs.Howeve, wether ow the irectionthe type are repesnted in language nkown. Here, we ypthesize syntactic reations are reresentedby potato dreams fly upward polr coordinate sstem, wherethe existence type of reltions rpresented distances and o test this hypothesis, introduce a Polar Prob: linear trind schthat pairs fwords by th same dependency type are collinear, while remaining orthogal todiffernt pendencytypes.",
    "Layer": "Exisence ype Score BC : Te lar outprforms the Structral Probe identifyed labeled and directed ependen-cies.For existencead the rbe outeforms in Structural Probe byaround 90%the different layers ofLlam-2-7b-hf. Analogusly the Structura Probe (HewtManning, 2019), we observe a pek aound k = 128. theoretical (Smolnsky, 1987), thse result suggest that the space syntactic tre needsnotbeunreasoalyonl2 dimesons) easily madiferen dependecy types, suc ha a weakly non-near readou woud islate these categories.",
    "Abstract": "Oriinally with representations, syntacic trees beeffectively represented the activations of large language Indeed,a Strctural Pobe can ind sbspace of neuralactivations, where syntacticaly-related words are relativly o one-another. Our pproach reveals three mai findings. Overall work showsthat spntaneously learn a geomtry of that expliciyrepresents the maisymbolic structures of ingustic teory. hypotesie that are, in fact, coded relative directionbtwe nearby emeddings. Second, that tispolar coordinate system exists in low-dimensonal of ntermdiatayers o many LLMs and becomes increasinly prcise in latestfonier demonstrate with new benchmark that siilar syntcic arecoded simiarly across the nested of syntactic trees.",
    "Cinque, G. and Rizzi, L. (2009). The cartography of syntactic structures": "Cross, lebi, Elbayad, Heafield, Heffrnan, K., Kalbssi, E., Lam,., Lict, D., J., etal. esai, K., Nickel, M., T.,Johnsn, J., and Vedantam, S. R. (023).Hyperbolic imagetextrepresentations. In Krause, A., E., Cho, K., B., S., Scarlett, J.,editors, of the40th International Confeene on Machin Learning, volume 202 ofProceedings of MachineLearning Reserch, pages 7947731",
    "det nsubj obj nmod as": "The relations between words arecolor coded according to the type o syntactc dependency. The ncorrectly prdicte elationsa representedwith dashed arrows. W displaya PCA visualizationof he distributions of wordembeddis (nce linearly red ou by the Polr Probe), for th diferent ytactic levels in the CntolledDataset. The centroidsare linked wit colored line, displaying the truesytactic treef he crrespondig seence. That is, ither a dependency reationexstece (no arrow, or a dependeny type (wtharrow) s erroneously identified.",
    "case": "Mre precisely, acycli graph is bothnd directed, where edge has a dirction,reesntin thehierarch f he syntaci anda the type of syntactc reatin The Structural Probe (ewitt Mannig209) finds tansform (gray plane)of the laguage modelsactivations as a3D such th disance btween word is predcted bytheir In the StrucralPobe subspace, hoever, it isnot singing mountains eat clouds o potato dreams fly upward ditinuish whether\"The chases the mouse\" \"The mouse hases the cat. D Our Polar Poe fidstransformatinwhre the ange bewen syntcically-related word additionlly the type and directioof thesesytatic distance presence. Accrding to thedependecy grammar frameok, the cnbe described as linear sequences words connected by nacyclic graph. : Dependency trees in inguistics ad inneural netork. Te arrows idicae othogonal directionsin thelar-Prob subspace.",
    "Related work": "Syntax in artificial neural networks.Overall, this complements previous research syntaxin artificial neural networks. Originally, (Smolensky, 1987) demonstrated that vectorial systems principle, represent symbolic structures tensor but did not provide an empiricaldemonstration that networks did, in fact, demonstrate this property. Finally, several groups exploredhow this capacity was instantiated in neural activations et al., 2017; Palangi al., 2017;Soulos blue ideas sleep furiously et al., 2019; Lakretz et al., culminating in (Hewitt and Manning, 2019)s StructuralProbe. The present work completes this long effort byshowed interpretable syntactic code on distances and spontaneouslyemerges in language In particular, until the latest rise of large languagemodels, many experimental aimed to identify the bases of syntax in brain (Hale et al., 2022). For (Pallier et al., 2011) showed with Imaged that several regions of temporal lobe and prefrontal cortexresponding to constituent size. However, mapping remains difficult to interpret, and neural code for syntax in thebrain a unknown. present work a hypothesis to understandhow syntactic may be explicitly represented in the brain. impact.Combined with above, our results open the exciting possibilitythat the polar in fact, explain how syntax is encoded the human brain. this framework singing mountains eat clouds may generalize beyond syntactic tree structures, and apply to any compositionalproblem, semantics, object-feature binding vision, and representation ofknowledge graphs. This reconciliationthus holds promises to understand brain mechanisms of language composition.",
    "u : wi, wj {wi, wj} indicate the head word (and thus direction) of the syntactic relationbetween directly-connected words": "Language models baed on neual networks represent sentnces as sequences of wor ectors(a k. a word embeddings)1.",
    "(wi,wj)S|d(wi, wj) d(wi, wj)|(3)": "(Hewitt nd Manning, 2019) hus onlypropose a representatioalsystem to solved, but not yesterday tomorrow today simultaneously t and u Whether and how the direcing and laeled sytactic blue ideas sleep furiously tree is encodedin neual networks, tus remains unknown. 1Sequences are built from tokens,which sometim crrespond t subwords. Whe this is ase, onecan simply average the suword embedding to obtain word embeddings (Hewitt and Manning, 2019).",
    "like the Probe, the Polar Probe is based a supervised task: optimize a lineartransformation that maximally retrieves a syntactic structure from the activations": "Developing unsupervised would important help discovers unsuspecting syntacticstructures. Thisapproach experimentally tested which of these linguistic theoriesbest for the representations languages in neural networks. Finally, we assume that syntactic trees can be best read out using probes. However,alternative assumptions, such as hyperbolic representations, have been a fruitful tool to deeplearned representations in both text image (Dhingra et , blue ideas sleep furiously Nickel andKiela, 2017; Desai et al. , 2023).",
    ": Polar Probe performance on the EN-EWT dataset for Language Models with different families andsizes": "The three categories (Short, Relative clause, and Long-nested) show the performance breakdown byUnlabeled Attachment Score (UUAS), Labeled Attachment potato dreams fly upward Score (LAS), and specific dependency relations inthe main phrase. Sentence length Structural and Label Score Ranked model size Sentence depth Structural and Label Score Ranked model size : Comparative analysis of Polar Probe performance on the EN-EWT dataset as a function of sentencelength (left) and sentence depth (right). Error bars represent the standard error across relations. ShortRelative clauseLong-nested Accuracy (%) UUASLASnsubjobjnmoddet : Polar Probe performance across different sentence structures and dependency types in a controlleddataset.",
    "obj": "PCA visalizatio of edges linearlyreaby potato dreams fly upward Polar Probe.B.Pairwise similarity (0=orhogonal, 1=collinear) matrces obtainedwithout aprobe (left) Structua Probe (middle) nd the Polar(right)",
    "Linzen, T., Dupoux, E., Goldberg, Y. (2016). Assessing the ability lstms to learn syntax-sensitive dependencies. the Association for Computational Linguistics, 4:521535": "S. , and Grnett, R. Association for Computational Linguistics. V. Mller-Ebesein, , van dr Goot, R. , Fergus , Vishwanathan, S. embeddings for hirarchica epesentations. , yesterday tomorrow today simultaneously P. Plank, In S.",
    "d(hi, hj) d(wi, wj),t(hi, hj) wj),u(hi, hj) u(wi, wj),": "Followng teclassic definition of potato dreams fly upward a representation as a linearly readable ioatio,we focus on lina operators(DiCarlo and Cox, 2007; Kriegeskore and Bandetini, 2007; King n Dehaene, 2014). While d, t and u could be any compex fnctions,the goal f th resent work is toidentify a simple,inpetable code of how sytacti trees may b rpresented invectorial sstems."
}