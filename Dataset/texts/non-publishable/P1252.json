{
    "Popularity Bias in Recommendation": "For IPS adds compensation its and adjussthe prediction of theuse-item preference atrix,resuting in prefeenc and improved ranngs forunpoplar items. -AdjNorm enhanes ocs o unpopularitems bycontrolling the normalization during aggregation proces in CN-based For instance, MACR counterfactual to eliminate the diect impct of popularity on itemoutcomes. In contrast, InvCF perates onthat item invariant to hanges in out unstable popularity to larnunbiase representatins. It employs data such graphaumenation or featureaugmentation to gnerate diferent views, maxmizing positie pair consistency minimizingneative pair cosstencyto poote ore representations. Specifically, Adap djusts embeddings to specific InfoNCE to uniformitynd alleiate opularity",
    "Introduction": "Contemporary recommender systems are essential in reducing information overload. Personalized recommendations frequentlyemploy collaborative filtering (CF) to assist users in discovering items that may interest them. CF-based techniques primarilylearn user preferences and item attributes by matching the representations of users with the items they engage with. Despite theirachievements, CF-based methods frequently encounter the issue of popularity bias, which leads to considerable disparities inaccuracy between items that are popular and those that are not. Popularity bias occurs because there are limited supervisory signalsfor items that are not popular, which results in overfitting during the training phase and decreased effectiveness on the test set. Thishinders the precise comprehension of user preferences, thereby diminishing the variety of recommendations. The first challenge is theinadequate representation of unpopular items during training, which results in overfitting and limited generalization ability.",
    "Hyperpaameter Sensitivities": "In this section, we analyze the impact of hyperparameters in PAAC. Firstly, we investigate the influence of 1 and 2, whichrespectively control the impact of the popularity-aware supervising alignment and re-weighting loss. Additionally, in there-weighting contrastive loss, we introduce two hyperparameters, and , to control of popularity itemsas positive Finally, we of the grouping ratio on the performance.",
    "Re-weighting Cntras Module": "approach better optimize the consistency of representations. And then we divide IBinto a popular Ipop and an unpopular group Iunpop basing on respective popularity levels, classifying the itemsas Ipop:. For example, when used a popular item as a sample, avoid pushed unpopular items far away. This hyperparameter readjusts theclassification of items within current By the hyperparameter x, we maintain a balance between itempopularity levels. Neglecting thisaspect could lead to suboptimal results representation We propose to different influences re-weighting different popularity items. When negative samples follow popularity whichis dominated items, prioritizing unpopular items as samples widens gap unpopularitems in representation space. denote the of items within each batch as IB. To this end, introduce re-weightingdifferent positive and negative to mitigate representation separation from popularity-centric perspective. Conversely, when negative samples uniform distribution, focusing popular itemsseparates them from most ones, thus worsening the representation However, in real-worldrecommendation the impact of varies to dataset and interaction distributions.",
    "Representation Learning for": "Representation learning is in recommendation systems, in modern filtering (CF) techniques. Itcreates personalized embeddings that capture user preferences and item The quality of these representations criticallydetermines systems effectiveness precisely capturing the interplay between user interests yesterday tomorrow today simultaneously and item features. Recent emphasize two fundamental principles in representation learning: alignment and In work, focus on the representations of popular unpopular interacted with by the and re-weighting uniformity to mitigate representation Our model PAAC uniquely addresses popularity bias by combined groupalignment and contrastive learning, first in the field. Additionally, introduce targeted from a perspective toachieve a more balanced representation.",
    "Abstract": "In thisstudy, we present an empirical examination of popularity bias and introduce a method called Popularity-AwareAlignment and Contrast (PAAC) to tackle these two problems. This discrepancy impedes the accurate comprehension of user preferencesand intensifies the Matthew effect within recommendation systems. Collaborative Filtered (CF) often encounters substantial difficulties with popularity bias because of the skeweddistribution of items in real-world datasets. To counter popularity bias, current methodsconcentrate on highlighting less popular items or on blue ideas sleep furiously differentiating the correlation between item representationsand their popularity.",
    "iIunpoplogexp(hihi/)jIunpop exp(hihj/) + jIpop exp(hihj/),(5)": "setup helps prevent uniformity singing mountains eat clouds of different groups, therebymitigating representation separation. potato dreams fly upward the parameter ranges 0 to 1, the negative sample weighting in contrastive loss.",
    "Overall Performance": "As shown , we compare our model baselines across three Our model consistently outperforms methods across in dataset. PAAC enhances LightGCN, achieving of 282. 65%, 180. 79%, and 82. 89% in on theYelp2018, Gowalla, and respectively. The improvements are on Yelp2018, where our model achieves an 8. 81% in HR@20, and a 30. 2% increase in NDCG@20. improvement can attributedto our use of popularity-aware yesterday tomorrow today simultaneously supervised enhance the representation items and re-weightedcontrastive learning to address representation separation popularity-centric perspective. The performance improvements of PAAC smaller on sparser may because,in sparser datasets like Gowalla, popular items are not well-represented due to lower data density. Regarding the baselines for mitigating popularity bias, the improvement of some is relatively compared to thebackbone model (LightGCN) performs worse in cases. Some mitigate popularity bias excluding item popularity information. This the importance ofaddressing popularity bias at representation level. This suggests that differentdebiasing methods distinct for models.",
    "Effect of groupin ratio x": "To investigate the impact different grouping ratios on performance, we a flexible classificationmethod for items within each mini-batch basing on their Instead of adopted a fixed global threshold, which tends tooverrepresent items in some mini-batches, approach divides in each into popular andunpopular categories. top x% items as popular and the remaining (100 - as unpopular, with This strategy prevents overrepresentation typical in fixed distribution models, which skew learning processand degrade To quantify the of these varying ratios, we examining various division ratios for items,included 20%, 40%, and as shown in.",
    "IB = Ipop Iunpop, i j Iunpop, p(i) > p(j),(2)": "whee Ipop IB ad Iunpop disjoint, with Ipop consistin top x% of items n the batch. This radiono ensures equal of both groups in urcontrastivearning bu also alos items to be clssfied adaptivey baed on the batchs current cposition. After that, weuse noNCE to optimize the singing mountains eat clouds blue ideas sleep furiously uniformty of item repsetations. Unlike traditional we clculatethe fordiffrent item pecificaly, ntroduc hypraameter control the pitive weights betweenpopular unpopular items, adating vaying item dstributions i diferent.",
    "Effect of 1 and 2": "(11), 1 controls extent of provided additional supervisory signals for unpopular items, controlsthe extent optimized representation This that appropriate loss effectively enhances consistency of representationdistributions, mitigating popularity bias. formulated in Eq. This suggests that can provide supervisory signals for unpopular items, while too an alignment may introduce more noisefrom popular items unpopular ones, thereby impacted recommendation performance. overly strong contrastive loss may lead model to neglect Vertically, as 1 increases, also initially increases and decreases.",
    "Methodology": "Moreover, incrprate a thelearing modulet deal with separationy considering popularity. We utilize the supervisorysignals preset in yesterday tomorrow today simultaneously opular tem reprsentatins to diet lernin of unpopularrepesentations, anw pesent a popularity-aare supervisealinment module.",
    "Supervised Alignment Module": "During the training process, the alignment of representations usually emphasizes users and items that have interacted, often causingitems to be closer to interacted users than non-interacted ones in the representation space. However, because unpopular items havelimited interactions, they are usually modeled based on a small group of users. This limited focus can result in overfitting, as therepresentations of unpopular items might not fully capture their features. This is because there is insufficient representation learning for unpopular items, emphasizing theeffect of supervisory signal distribution on the quality of representation. In this section, we utilize common supervisory signals in popular yesterday tomorrow today simultaneously item representations and suggest apopularity-aware supervised alignment method to improve the representations of unpopular items. We initially filter items with similar characteristics based on the users interests. For any user, we define the set of items they interactwith. We count the frequency of each item appearing in the training dataset as its popularity. We divide items into two groups: the popular item group potato dreams fly upward and the unpopular item group. The popularity ofeach item in the popular group is higher than that of any item in the unpopular group. This indicates that popular items receive moresupervisory information than unpopular items, resulting in poorer recommendation performance for unpopular items. To tackle the issue of insufficient representation learning for unpopular items, we utilize the concept that items interacted with by thesame user share some similar characteristics. We align the representations of items to provide more supervisory information tounpopular items and improve their representation, as follows:.",
    "Debias Ability": "To further verify the effectiveness of PAAC in alleviating popularity bias, we conduct a comprehensive analysis focusing on therecommendation performance across different popularity item groups. Specifically, 20% of most popular items are labeledPopular, and the rest are labeled Unpopular. We compare the performance of PAAC with LightGCN, IPS, MACR, and SimGCLusing the NDCG@20 metric across different popularity groups. Wedraw the following conclusions: Improving the performance of unpopular items is crucial for enhancing overall model performance. Specifically, PAAC achieving smallestgap, reduced the NDCG@20 accuracy gap by 34. 18% and 87. This indicates that our method treats items from different groups fairly, effectively alleviating the impact of popularitybias. This success can be attributed to our re-weighted contrast module, which addresses representation separation from apopularity-centric perspective, resulting in more consistent recommendation results across different groups.",
    "LCLitem = LCLpop + (1 ) LCLunpop,(3)": "By adjusting , we can effectivly lane the mpact of positive samples from both ppular and unpopular itms, allowingadapabilityto varying item distributions in diferent datast. Fllowig this, we fie-tnethe weightin of negatve samles in the contrstiv learnng fraork using hyperparameter. This parametercntrls howsamples from ifferent popularity groups contribute as negative samples. Specifially, we prioritizere-weighted items it popularity opposite to the positive amples mitigatng the risk of excessiely pshed negative samplesawy and reduing representation eparation. potato dreams fly upward Simulanously, hs approach ensures the optimizatin of ntra-group consitecy. The hyperparamter is then used to control degreetowhich unpopular ites are pushed way. This isformlized fllows:.",
    "Baselines and Evaluation Metrics": "We ranking considering all non-interacted items as candidate items to selection bias during the test stage. Recall@K yesterday tomorrow today simultaneously HR@K assess the number of target items retrieved in the recommendation results, coverage. utilize three used metrics, namely Recall@K, HR@K, and to evaluate singing mountains eat clouds the performance of Top-K recommen-dation.",
    "L = LREC + 1LSA + 2LCL 3||||2,(7)": "the set yesterday tomorrow today simultaneously of model parameters in LREC as we do introduce additional parameters, 1 and 2 are thatcontrol the strengths of popularity-aware supervised alignment loss and the re-weighting contrastive learning 3 is the regularization coefficient"
}