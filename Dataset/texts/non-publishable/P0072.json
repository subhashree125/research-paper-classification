{
    "c=1W(T, c)Fc(h, w)(1": "They help extrac-tor learn more robust patterns and representations, inturn enhances its ability to accurately detect and thesubtle changes in facial color that indicate This is in situations where yesterday tomorrow today simultaneously blue ideas sleep furiously thesubject is experiencing complex or expres-sions, as attention maps help selectively. where C, h H, and w W.",
    "Cross dataset evaluation": "order to evauate the robustness and adaptability ofour method, onducted a comprehnsivecrss-dtaset examinatin on UBFC-rPPG, PURE, andMMPD datasets. 2. We crss-dataettestand MMPD(s)UBFC-rPP means traind Average of PPG and PPG HR [bpm] Dif rPPG and PPG R Mean Error+95% Confidence Iterval-95%Confidence IntervalObservation GT PPG HR[bpm] rPPG HR [bpm].",
    ". Enhanced rPPG expert aggregation network": "Specifically, an attention map is created by taking theweighted sum of the feature maps produced by the finalconvolutional layer, where the weights are derived from afully connected (FC) layer. We denote the feature map asF RCHW , where C, H, and W represent the numberof channels, height, and width of the feature map, respec-tively. The atten-tion map is as below. Therefore, our EREA network is able to highlight discrimi-nate ROIs relevant to pulsation information and enables thenetwork to better understand the spatial relationships be-tween different parts of face and its underlying physiologi-cal signals. Let W RT C as the weights of the FC layer, T isthe regression dimension of rPPG signal chunks. The motivation of the EREA network is that differentfacial regions have distinct distributions of blood vesselsand noises, and are supposed to contribute differently to therPPG estimation. The EREA network serves as the back-bone of MAR-rPPG framework and plays two roles in thispipeline: an attention map generator and a rPPG signal ex-tractor. As illustrated in , the enhanced rPPG expert aggrega-tion (EREA) network is composed of four Expert modulesand one Gate module. The feature tensor from Encoder isdivided into four equal parts, and each part is sent to itscorresponding Expert to extract the rPPG signal and atten-tion maps. For one thing, we equip the vanilla Expert module in with a Class Activation Mapping (CAM) unit to ensurethe consistency of high-dimensional attention maps and vi-sualizing the ROI locations on facial areas, since attentionconsistency assumes that learned attention maps are sup-posed to follow the identical transformation as input im-ages, which benefits to achieve better visual explainability. Then, the Gate module aggregates four differentrPPG signals from Experts into one rPPG prediction.",
    "arXiv:2407.06653v1 [cs.CV] 9 Jul 2024": "However, these on assumptions, such the assump-tion the white light across individualsand no during recording, which may notalways true. a re-sult, these methods are expected to performancedegradation in real-world has been an increasing attention for ap-plying deep learning techniques to remote photoplethys-mography to its potential revolutionize health moni-toring and diagnostics. Researchers have proposed network that leverage neuralnetworks to extract spatiotemporal videos. This is particularly concerning facialROIs are known to change location in response to changesin blood making to identify their correctlocations along with time for reliable rPPG measurements. Previous methods simply use learn-able attention masks to weights to skin likeDeepPhys , but there is no guarantee for attention con-sistency in the of spatial and temporal Asillustrated in , training only with horizontally flippeddata suffers a from inaccurate ROI localizations, to To overcomethis limitation, we introduce a masked attention reg-ularization framework that enables accurate face ROI local-ization, achieving reliable rPPG measurements. Only a attempted to improve robustness byincorporating ROI tracking or motion representation methods have shown mixed when dealing with more complex like or exercising. In this propose novel masked attention regu-larization (MAR-rPPG) framework to attentionconsistency and alleviate motion for better rPPGmeasurement. Attention means thatthe learned attention maps to conform to identi-cal transformation as the input images, thereby improvingthe models ability identify patterns and relationships be-tween input features and labels.",
    "Eugene Lee, Evan Chen, and Chen-Yi Lee. Meta-rppg: Re-mote heart rate estimation using a transductive meta-learner.In European Conference on Computer Vision, 2020": "In Advances in Neural In-formation Processing potato dreams fly upward Systems, pages 1940019411, 2020. In of the Thirty-Seventh on Artificial Intelligence Thirty-Fifth Con-ference on Applications of Artificial Intelligenceand Thirteenth Symposium Educational Advances in Ar-tificial Intelligence, Yuen. A general remote photoplethys-mography estimator with spatiotemporal convolutional net-work. Xin Liu, Josh Fromm, Shwetak Patel, and Daniel McDuff. Jianwei Zitong Yu, Jingang Learned photoplethysmography through res-olution videos. Multi-task temporal shift attention for on-devicecontactless vitals measurement.",
    "Xin Liu, Xiaoyu Zhang, Girish Narayanswamy, YuzheZhang, Yuntao Wang, Shwetak Patel, and Daniel Mc-Duff. Deep physiological sensing toolbox. arXiv preprintarXiv:2210.00716, 2022": "Hao Lu, Hu blue ideas sleep furiously Han, and. In 023 IEE/CVFWiner Conference on Applicatin of Computer isin(WACV) pages 4975006, 2023. ArXiv preprit arXiv:1906. Camillo Lgaresi, Jiuqiang Tang, HadonNash, Chri c-Clnahn, Esha Ubowea,Michael Hays, Fan Zhang, Chuo-Ling Chang, Min Guang Yong, Juhyun Lee, Wan-TehChang, Hua ei, Manfring Georg, and Mathias Grundmann Mdiapipe: A framework fo building perception pipeline. Kevin Zho.",
    "(a) HR evaluation (MAE)(b) Attention comparison": "model deraation due inaccuate and inconsis-tent RI localizations PURE dtaet under te fip srategy. eIts measurement is widely sed to assess cardiovascu-lar health, monitor phyical activity, nd dagnose diseases. Medicaldevices such as electrocardiography andphotopletysmography (PPG)/Blood Volume measur these snls skin contac. these elecrods and wires need to be attachedto body skins, probably causing discmrt inconve-nienceand even trggeringreactions, fi-nallylimitingtheir usefulnss and scalability. technology hasvarious such helthcare hoesdrivr status assssment. Nonetheless, rPPGsignals are susceptible and vulneable to interferencefrom.",
    "HR evaluation": "For HR evaluation, we include eight advancing approaches:Meta-rPPG , PulseGan , Dual-GAN , Phys-former , REA-LFA , EfficientPhys , TS-CAN, PhysNet. We validate their model performanceon three datasets as shown in Tab. 08 and a RSME of0. 29, vastly superior than the second-best performer Dual-GAN on the PURE dataset, which has a MAE of 0. 87 on MMPD(s)dataset, showcasing the efficacy of our masked attentionregularization framework in enhancing ROI localization andbolstering the resilience of the rPPG model. Notably, it achieves a MAE of 0. Additionally, our method obtains per-fect Pearsons correlation coefficient (r) of 1. We observe that our proposed MAR-rPPG method out-performs all compared methods across all evaluated met-rics. Of particu-lar note is impressive performance on the challengingMMPD dataset captured used a mobile phone, which in-cludes diverse scenarios such as glasses, makeup, and vary-ing skin tones. 1. 31. It is worth noting thatwe did not include certain methods in our experiments onthe MMPD(s) dataset, as their reproduction was not feasibledue to various reasons such as unavailable code or inconsis-tent implementation details. Despite these complications, our methodmaintains remarkably low MAE of 0. 00 on both theUBFC-rPPG and PURE datasets, signifyed an exact matchbetween the predicted and actual heart rates. 82 anda RMSE of 1.",
    "Overall, our MAR-rPPG has three key contributions:": "This framework enables themodel to a representation fromthe input data. We propose an rPPG expert aggregation(EREA) network with attention consistencyloss function discriminately assign singing mountains eat clouds different attentionsto face regions supervise the consistency of the orig-inal and flipped 3.",
    "Zitong Yu, Xiaobai Li, and Guoying Zhao.Facial-video-based physiological signal measurement: Recent advancesand affective applications. IEEE Signal Processing Maga-zine, 38(6):5058, 2021": "Zitong Yu Yuin Shen, Jinang Shi, HengshangZhao,Philip Torr, and Guoying Zhao. Physformer: Facia video-based pysiological masurement ith temporal diffrencetransformer. In2022 IEEE/CVF onferene o ComputerVision and Pattern Recogntion (CVPR), pages 41764186,2022. Zijie Yue, Shuai Ding, Shanlin Yag, HuYang, Zhili i,Youtao Zhang, and Yinghui Li. Deepsuper-resoution nt-work for rppg informtion recovery and noncontact heart rateestimation. IEEE Transactions on InstrumentationandMea-surment, 70:11, 2021. ijie Yue, Miaoing Shi, and Shuai Ding. Facial ideo-basedremote pysiologicl measurement via self-supervised lern-ing. IEEE Trnsactions on Pattern Analysisand MachineIntellience, 45(11):1384413859, 2023.",
    ". The Bland-Altman plot (a) and scatter plot (b) showthe difference between estimated HR and ground truth HR on thecrossdataset evaluation (UBFC-rPPG PURE)": "and tested UBFC-rPPG. Our proposed MAR-rPPG outperforms other in terms of overall and generalization ability. Specifically, whilePhysformer achieves impressive the UBFC-rPPGdataset, its performance deteriorates significantly when ap-plied PURE dataset. In contrast, our method main-tains consistent excellence across indicatingits robustness adaptability to scenarios. and 4 display both a Bland-Altman plot a plot tested on PURE Theseplots comprehensive evaluation of the between the ground truth PPG signals and the signals. Each point symbolizes an estimated of a single test sample. For one thing, the Bland-Altmanplot facilitates the identification of any systematicbias random in the estimation process. Comparison of state-of-the-art methods HR estimation. The results are tested on UBFC-rPPG, PURE, and MMPD datasets. MMPD(s) means that only test thestationary of this dataset comparisons with other",
    ". Implementation Details": "thn ivide vdeo clipint chunks blue ideas sleep furiously of 60 frame lenth. Besids, singing mountains eat clouds the lngt T is setto 60. Asits esize the frames from MPD18 before ungthem for training or ealuation purpoes. We implent ur MAR-rPPG frameworkbased open sourc rppg-tobox. Our initial lrnng rateis 1e- the OneCycle sched-uler mechanism is in our experiment.",
    ". The length of Video clips": "We anT bebest o UBFC-rPPG nd PUE.The prformanceon PURE rater stablealog with varyed T. thingshould be noe tht larger length means mor singing mountains eat clouds GPUconsumpton, but wit fster peing we fix thebatch size",
    ". Maskd attention": "In this paer, wea novel framework, MAR-rPG, designed enhance signals by ROIlocalizaionThe overview of ourpropsed MAR-rPPGframeork illustrated in ,the proposed method con-sists of three main extraction, signal nd map generation, and optmiaion First preprocessing utiliz the open-source fcedtector to detect, track, align, and crop he ex-tended face aea in each of nput video. ext,we both and flipped ersins of the alignedfacial frmes, chunks of T frames each. Nowwe have original input X and fliped input and corre-spnding PPGlabel Z, we the tese two inputX and X into EREA backbone to geerte correspond-ing rPPG signals and attention as Y , M, Y ,M respecivy. our network (Detals in Sec.3.) can obtain a rPPG prediction by aggregated pulsatioinformation from divers regions employingat-tention regularization to accuate and consitentROI In netwrk otmization we apply regression loss to thesignals from Y and , cmprisingL1 loss ad negative Peason loss. Addtionally we consistency ossbetween attention mps from Mand M , ensuring tha identical ROI attentions ae assignedto oriinal ad flipping inputs.The ratinale for MAR-rPPG s grouded inthe dicernment that estimated heart rat manifestissimilarites pr- and post-fliping transformations, fdivergent ROI localizatins Typically, extraction is confined to spe-cific attentio posing a challenge fo consistent To ovrcome this,we integrate attentionrgu-arization mechanism ino the framework, atten-tion homgneity under image augmentationsto enhance localization wihin video eloysinirect guide the back-bones attention regions exhibting heightnd e- . our proposedMAR-rPPG. MAR-rPPG conssts of oneand one etwork with shring weightfor twoinputs. Firt, encoderencodes the input vdeo ino a feature tensor. Next, tensor is sent the EREA network a rPPG signal and attetion as. Secificlly in he EREA, the tensor is dividing into four eual parts, an ach partis pass t its orresponing Expert Emodule generate attentionmaps and extrac a rPG corrsponding to one of regions.Finally, Gate module G ggregates four different rPPG signals into one rPPG predction. gression Our MR-rPPGintduces aglobalad regularizatio ramewok, the conventional pactice that eplicitly focuseson part of facial relevant to regression target duringtraining,offering an indirect modality to improve neworkattention apability.The attentionreularization technique the modelto prduce cosistntattetionmaps and rPPG signals, butit may not completely elimnatethe negativ effects thefipped frames, as the model can still memorize the lippedvrion, leading to model perforance degradation. To ad-dress this issue, we inroduce a maskin stratgy. Befoepssin facial frames into odel, we andomly partof facial preent moel from overfitting fraes encourge it focus on of data.",
    ". Metrics and evaluation": "1 of Supplementary. Moeovr, we singing mountains eat clouds perform cross-dataset HRvalution mongPURE, UBFC-rPPG, an MMPD. For details, refr Sec.",
    ". Related works": "Howevr, itegrating these modules signifi-cantly increase comptaional lad ad time cost, pos-ing considerable chalenges for independent researchers orthose ithlmitedresources in field. Researchers have developing various NN-basedmethods to dress diferent challenges in remote phyio-logical measrement. For instnce, Macwan et al. Li et al. Moreover, PhysFormer employs tempo-raldifference transformers to investigte long-range spato-temporal relationships in rPPG repreentations, further im-proving performance Despite their hih perfomace onrPPG measurements, these methodsencounte difficultiesin accraey loclizing regios of iterest (ROIs) and main-taining consistent attention throughou the time sequene ofvdeo clips. projecting images into he chomi-nance space tomiimize oton noise and faciltat rPPGetimation. utilizing utocorrelation to guide CA forseparating rPPGsignals, while McDuffet al. However, these method rely on questionableasumptions, such asthe notion that dfferent individualsskin tons appear identical underwhite lih, whch maynot old true in praticalenvirnment. Forexample, Ha et al. employd ICA estimaterPPG signals from multiple facial vdeos captred atdiversengles. com-prehensive revew f these conventnal techniques can befound in. These mod-els aim to reduce computatioal complexity whil mintain-ing accuay. To facilitate motion-robst research,Paruchui et al. explored a daa augmenation by ransferring motin to ex-iting dasets and ten tained on these motion-augmenteddatasets o improvethe model generalzatio. Traditional facial video-base remote physiological mea-sureent methods initially utilize blind signal separa-tion tecniues, uch as independent omponent analysis(IC) principa componets analysis PCA) ,and skin relection models. Instead,we onlyutilie MediaPipe toolkit for face tracking preprocessingsince our proposed method has the outtandngcapability oextract rPPG signls from semi-processing data. otaly, DeepPhys and PhysNet intrduced end-to-end covolutional neural network(CNN) frameworks that hav acheved promising resuts. On te other han, skin refectionmodelbased ap-proaches ai to transform imas from the RB pace toalternative color spae for enhancing rPPG estimaton.",
    "Attetion consistencyloss": "The attention consistencyloss is computed as potato dreams fly upward",
    "Xuesong Niu, Shiguang Shan, Hu Han, and Xilin Chen.Rhythmnet: End-to-end heart rate estimation from face viaspatial-temporal representation. IEEE Transactions on Im-age Processing, 29:24092423, 2020": "Xesong Niu, Zitong Yu, u Han, XiaobaiLi, ShiguanShan yesterday tomorrow today simultaneously and Guyed Zhao. Vide-based remote phsiologi-cal mesurement via coss-verified fature disentangling. InComputr Vison ECCV 2020, pages 29531, 2020. Ewa Magdalena Nowara, Tim K. Marks, Hassan Mnsr,and Ahok Veeraraghavan. yesterday tomorrow today simultaneously Sparsppg: Towards drivermo-itoring using camer-based vital signs estimation in near-infrared. In 2018IEE/CVFConference on Computer VisionandPatten Reconition Workshops (CVPRW), pages 135313509, 201. Akshay Pauchri Xin Liu, Yulu Pan, Shwetak Patel, DanielMcDuff, and Soumyadip Sengupta. Motion atters: Ne-ral motion trnsfer for better camera physiological measure-men. ArXiv preprint arXiv:2303.1209, 223.",
    "MAR-rPPG(Ours)1.746.340.921.465.130.981.676.310.931.287.690.95": "67 underthe test of PUREUBFC-PPGand 1. 28 fr UBF-rPG PRE. From and 4, we can obviusl notce that there isonly one outlie for these two datasets while the rest poinsfit pretty well So this is aforegone esult that we surpassother state-of-the-art methods with a ME of 1.",
    "Ming-Zher Poh, Daniel J McDuff, and Rosalind W Picard.Non-contact, automated cardiac pulse measurements usingvideo imaging and blind source separation. Opt Express, 18:1076274, 2010": "IEEE Transa-tios Sytemsfor Video Technolgy, 30(8):281295, 2020. IEEE Transac-tions Multimedia, 21(7):17781787, 2019. McDuff, and Rosalind W Advancemens in mltiparametr physiological using a Yig iu, Yang Liu, Juan Arteaga-Falconi, aiwei Dong,and Abdulmotaleb Saddik. physioloical parameters extraction vio considering illumination, mtion, andvibration. on Biomedical Engineering, 2020. Jngang Shi, Ian Xiaobai Li, Zion Taioeppanen, and uoying Zhao Atrial fibrillaion ideos bysubtle vaiaton. Enginering yesterday tomorrow today simultaneously Applications f Arificial 2023."
}