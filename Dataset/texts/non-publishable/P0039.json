{
    "SUBMITTED TO IEEE TPAMI15": "5, no. Summrs, Deelesion: automated mining arg-scale lesion nnottionsand dtectin deep earning, Journal of medical imaging,vol. 921932,2015. Ghafooran, J. 35, no. Van De Lak, B. S. Madabhushi, D. F. Wang, L. 1. P. K. Yan,. Rueckert,and R A review of deep learning i edical iaging: Imagingtraits, technolog treds, ase studies with higligts,and future Prcedings of the vol. 42, pp. 5,pp. G Litjens, E. VanGin-neken, A. Bejnordi A. S. CiompiM. Greenspn, C. Duncan, B.",
    "Low-Rank Expert Modules": "Inspired y this, we usea similar low-rankstructue as the carriers for knowl-dge decomposition, named expert modules. Given a shared 0. LoRA , widely finetuned mehodin language has been demonstated to beparaeter-efficin ,.",
    "METHODOLOGY": "6. Then, we introducteetails ofurLoRKD in three parts: 3. 1 and 3. 2 respectively. 4presnts the efficientknowledg eparationconvoion; the trainingobjectiveof LoRKD isshown in 3.",
    "Low-Rank Adaptation": "During fine-tuning, LoRA utilizes low-rank matrices to approximate thechanges in pre-trained weights. * \"S The low-rank * \"S matrices canbe re-parameterized into the pre-trained weights to avoidinference latency. QLoRA combined LoRA with 4-bitNormalFloat quantization to further reduce computationalcosts.",
    "EKS Conv.Shared Conv.ForwardBackwardFrozenTrainableLow-rank Module": ", ET,with each pet modul specilzing in apaticular egion,such s the brain or abomen. he case for classification taks y urningthe dcodersas classifiers. Given model pre-trained on hetereneous daasets covering multiple anatomicalourgoal is o decompos F svral lghtweight modelsF1, FT ghtweigt mdel is an expet modelcorrepondng speciic anatomical rgion. : The iustrationLoRKD for mdical foundation models ementation. models can repae medical foundation odel in speific omains and cn swtch tskknowledge conveniently deartments. Fr he classificationtask, yi {0, 1, the class labelxi K i the nber of classes. For the task,y RKHW D is the biaryegmentation masks of theaatomical rgets ad stands * \"S for the umber of segmentation targets. Specificall,our decomposed model cnsists o a and T low-rank exert moduls.",
    "LoRKD*-Pro87.9077.6689.0194.6597.2789.30": "LoRKD* s. LoRKD. Ths loss reduction in thewrmup phase an the learnn of each region, therebyguidingthe rasonable allocation of paraeters eac region Consequently, the au-tomatically computd rank values f each low-rank differ between LoRKD*-Nano and Decomposed model vs. Ensemble of Specialistmodel. indicates in thse eeft frmuniversal trainig, all tasks within regios can eadressed a single model. 4. 2. . 2Tansfer Perfrmance in * \"S Segmentatonor lightweight exprt to fullyreplace the fundation mdel in a isessentia that t exper odels not only perform wellon the same distribtion of data (pre-training butalso dmonstrate their generalization ablity on downstream.",
    "Visalization": "In ontrat, our decomosed modl exhibits a more refined focus, concentrated smaller,more preciseae highly to te secific task at hand. n cntrast, LoRKDdemnstrates specialization, roducing esults hat closely lignwith the ground Tking DET10 dtaset as we evaluatethe diffeenes in theactivaing th decom-posed expert modl the foundation model theprdiction from te perspctiveof * \"S radCAM. This pre-cise lcalizaton indicates higher dere of specalization. focus s more foundationmainlesprecis than our model. In ths sbecton, evisualize theexperimental results and analyze he scialization nledge model exhibits noticeable segmntationflaws, includng clearly missed tagetove-segmenting certain reas. The foundation mode tends tofocus on less specific regons of the image. Grad-CAM highlights the regions of an inpt mage mostrelevant a eural dcision, offering insightsinto hw model inerprets the image. Thisboad fcus is the abilt to capturgeeral coss wide rangeof taks, it lacksthe pecision required fr more specialized application.",
    "Training Objective": "objective, we design distinct loss specific tomedical foundation models for segmentation and classifica-tion tasks. Ltask provides super-vision from the label information of the corresponding knowledge foundationmodel to decomposed models, which can be",
    "SUBMITTED TO IEEE": "This nuresth is always * \"S equal and th opeatin g equivalent to t Eqn(3) * \"S Specifcally, th operationof Eqn. (3can be transformed as follows:g = (W0 + B1A1)h1 (W0 +.",
    "Ablation Study": "The impact of Rank r. The rank r of low-rank expertssignificantly affects their representation ability and the num-ber of parameters. The results of the segmentation taskand classification task are presented in and respectively. For the segmentation task, whether decom-posing SAT-Pro or SAT-Nano, increasing r * \"S from 4 to 8leads to a significant performance improvement on the pre-training dataset. The results of theclassification task further corroborate this conclusion, whereperformance generally improves from r = 4 to r = 8 butshows diminishing returns or even slight decreases whenr is increased to 16. This suggests that selecting a larger ris not necessarily better. An appropriate rank value enablesthe low-rank expert module to learn distinct representationsfrom the backbone while maintaining a manageable numberof parameters. Therefore, we selected 8 as the base rankvalue. Moreover, we again observing that improvementin the upstream dataset is positively correlated with theimprovement in transferability. shows the ablation experimentabout impact of the trade-off parameter between theLtask and Ltransfer. This indicates that maintaining an appropriate value is critical for optimizing decomposition perfor-mance, as an excessively large value can negatively impactthe trained process. Overall, a value of 0.",
    "Y. Wen and S. Chaudhuri, Batched low-rank adaptation of foun-dation models, arXiv preprint arXiv:2312.05677, 2023. 7": "M. Antonelli, A. Reinke, S. Bakas, K. Kopp-Schneider,B. A. Litjens B. Menze, O. M. Sumers, et * \"S al. , The medical segmentation decathon, Ntuecommunicatons, vol. 13, no. 1, p. 4128,2022. 7 A E. Kavur, N. S. Gezer, M -H. Conze, V. D. Chtterjee, P Ozkan, et al., Chaoschallengeombined (ct-mr) healhy abdominal organ segmenta-tion, Mdical mae Analysis, vol 69, p. 101950, 202. 7 J Ge, Z. Yu, J He, Z. He, et al. , Toward data-efficient learning: A benchmrkfor cod-19 ct * \"S lung and nfection segmentation, Medical physi,vol. 48, no. , pp. 197120, 2021. 7.",
    ": Return Y d": "Firstly, the low-rank structureneeds to to a well-trained backbone. show the merit, we compare our effi-cient separation with FLoRA , parameter-efficient fine-tuning method that low-rank adapters like us. FLoRA allows eachexample * \"S in a minibatch to * \"S have its unique low-rank adaptersand demonstrates computational compared tothe vanilla manner. r. t. computationalcomplexities is presented in table:.",
    "Knowledge Disentanglement": "Additionally find that MTL ehibts a compared to STL. Furtermore, exhibits lower. Enhanced disentanglemnt. As a esult, ths entanglement as knowledge enanglement, poentially iminishingthe models overall effectieness in handling individultasks. This canlikely be attibuted to the xplicit in-crporated in our effectively minimizes theinterference between gradients from diffeent tasks, therebenhancing te specialization f expert modules. The results ae n , whre igher MIG idicate of It can e observed oumetodexhibits a higher level ofdisentangemen compred to theprevious KF and baseines.",
    "tasks with similar distributions. Hence, we evaluate theperformance of the decomposed model and baselines onseveral representative downstream datasets": "presentsthe perfrmance comparson betwenthe exert models and aselines onfiv segmentation for model, we the pre-tained model on downstream dataset. Fundation model model. his that despite of theirability to downstream is insufficient to pecialist models. typically aveonly a small mount of data, which makes them difficulto the fine-tunin of the foundtion model parameters, accorded t the Scaled Law. Baselines. Generlly,ourdecom-posedmes yield fvorable result significantly sur-pass h origina foudation models. Compared to LoRKD*-Nano a 5. 8% perormanceimproveent on SD and a 3. 1% impoveent DSC. For SAT-Pro, achieves a 2. 6% on NSD and . 6% imrovement DSC. thepeorance of and is to or better tha larger odel SAT-Pro, indicating that copact expert are mre for downtream datasets than the founation mdel. nUNet, LoRKD*-Pro and LoRKD-Pro erformance, outperformed nnUNet in threout o five datasets. This demonstates performnceon thepre-training is correlated the.",
    "CONCLUSION": "We develo low-ank exert moules eficietgradiet sepaaion conolon to decmposefounda-tion del into multiple lightweightexpert models. The decomposition performnce upstreamtasks on downsream tasks ulldmon-srate that can effectvely * \"S allevite the ofheterogeneous data, achieving cost reducionand imrovement simltaeously. hope thi rsearchoffers vauablefor adancing the devlopmentanddeloyent medicl foundation. Ormethod includes two LoRKD-balance LoRKD-imbalance.",
    "Haolin Li, Yuhang Zhou, Ziheng Zhao, Siyuan Du, Jiangchao Xie, Ya Zhang, and Yanfeng Wang": "AbstractThe widespread adoption of pre-training techniques has significantly advancing the of models, enabling them to as versatile across a broad of tasks. their stronggeneralization capabilities, medical foundation models pre-training on large-scale tend to suffer from domain betweenheterogeneous data, leaded to suboptimal on specific tasks compared to specialist models, by previousstudies. To the we propose a novel framework named Low-Rank Knowledge explicitly separates gradientsfrom different tasks by and efficient knowledge separation convolution. The low-rank expertmodules gradient heterogeneous data from different anatomical regions, providing strong specialization costs. knowledge separation convolution improves by achieving a propagation. Extensive experimental results on segmentation and classification demonstratethat our decomposed models not only achieve state-of-the-art performance but also exhibit superior transferability on downstreamtasks, even surpassing the original models in task-specific evaluations. The code at here.",
    "X. Zhao, Y. Wu, G. Song, Z. Li, Y. Zhang, and Y. Fan, A deeplearning model integrating fcnns and crfs for brain tumor seg-mentation, Medical image analysis, vol. 43, pp. 98111, 2018. 1": "Wu, Zhang, Y. Mintun, A. T. 3, 7, 10. Mei, Z. Kirillov, E. 1, 3 Z. 1, 3, 7 D. Wang, andW. Robson, B. Radimagenet: an openradiologic deep learning research dataset for effective transferlearning, Radiology: Intelligence, vol. Pham, Swoboda, N. M. A.",
    "DET10 1Xray103543": "Aditionlly, FoRA ues broadcastingt mprove effiiency which cannot b well generaized toconvolution oerations, whie LoRKD not to this. key is that wile FLoRA cost b expensie batchd mamuls (bmm) eleent-wisemultipiation () and ethodfurtherreuces computational cots by performng erly parameterfsion before hforwad of DNs.",
    "LoRKD1.25M5.32%83.2577.6676.9478.3398.3375.1887.8482.50": "Compared Baseline, both STL-based andMTL-bsed mtods show minimaim-provemnt indicating that focuingsoly on task-specificr common kowldge doesnot enhance transferbility. Furthermore, ourmetho ahieves the best pefomace ompared toother non-knowledge bselines, the of decompositi inextractingsk-specific For Fandour method, fine-tune the crrespoding expertmodels on downstream scha uin the lungpert dataset. Conversely our expert models incorpoate cmmonowledge andtask-specific knowledge, which exhibtstron and even sigificantly outperform KF. * \"S Thisdemonstrates the advantag odecomoitionn tansferbility, which can not be directly throughthe dcompositon performance. paraeersused KF. nother adatage over KF is our method suportsparameter fusion and dos reuire he simultaneousdeployment of two ntwors (CKN and the todeployedsimultaneously KF). to thesupplemenarymaterials for furtherdetails The peformane ofine-tunig foundationto inferioto theBaseline reinforcing thatfoundation models replace task-pcific model dueo their lack of speialization. As he of the pre-tainn datasetinreases, he transferbility our de-composed expert aso improes, iicating thatincrasingcale of pre-rainin datasets benefis thetransferability hedecomposed model. This validates the ef-fectivenessof our low-rankepert module effi-cien sepration convolution.",
    "H. S. Guo, J. Deng, J. Cheng, T.-X. Chen, Y.-C.Su, Z. Huang, Shen, B. S. Zhang, J. He, and Y. Qiao, Sam-med3d, 2023. 3": "Y. Butoi, J. R. Ortiz, M. G. * \"S Zhang, Z. Y. Dalc, Universeg: Uversal dicl image Proceedingso the IEEE/CVF International Conference n ComputerVisin, pp. Chen,and Yuille, Y. J.",
    "where represents te Kullack-Leiber divergence": ", hT } intothe lightweight decompostion model. These classificationheads can individually predict {Y1,. , YT } classes whereYt represents the number of classes for the t-th task, Y isthe total number of all classes and Ti=1 Yi = Y. The logitsextracted from decomposition model can be denoted asgdi = ht(f di ) and prediction can be calculated by:.",
    "Knowledge Decomposition": "Different the previous disentangled representationlearning is usually done through variational auto-encoder * \"S , , or * \"S , , ,, the goal of knowledge decomposition downthe foundation model into multiple region-specific experts. It factorizes a pre-trained model into a common knowledge.",
    "Motivation": "We explicitlseparate the gradients different anatomica regions intocorespondig low-rankexpertmodule. Ourintuitin isthat the expet an thentask-speci whil the haed backbneacqure geeral knowedge, th gradien data. This demonstrates the lacof specialization in fouation models for medical tasks. Ou rsulttha model in mst ass acievig superior esultson * \"S 1out of 20 dataets. onsits oftwo main componens: expert modues an theefficentseparation convolutin. As show in, the performnce o a state-of-the-artfoundation model edA gaint a state-ofte-arspecialistnUNet on 2 ditict datasets. T hadle the computational posed modules, we intrduce efficient knowledgesaratin covolutio which gradient separationto be complished a ingle forwad pass significantlreduced overhead. illurates the growthtren in num-ber of paraeters computational equirements in FPs) or well-known medical mdels. The size of fonation models ha ld o significant chllngs regarding andefficiency. As it while models exce at featretheir masi counts demand substtialcomputational power, maked them ipractical manyral-world scenrios.",
    "gt = (W0 + BtAt)ht,(1)": "here, for brevity, we oit the eshae oeration, adht, t represent the input featues ad output featrsrspectively. It is worth noting that diferent from previousscenarios where W0 remains frozen in LoRA, in our knowl-edge decomposition scenario, W0, s a carrier of commonknowledge, requires to be updatd alongwith the low-rankfactors t and B. 3. 1Task isparty requires baanced ran desgnTe intrinsc differences between vaious anatomicl e-gin preset substantial challenges in medical image anal-yis using nural networks. rain imaging is predomnantly performed usingMRI, wich povides detailed images of soft tise andis crucialfor identifyig neurlogial conditins ,. Additionaly,the data emploed foruniversal pre-traiin is highly imbalanced, with most mges comingfrom a few regions, as illstrated n.Th imbalanceexacerbtes the difficty of tasks associatedwithunderre-resented regions, as the neural networks trainin is skewedtords more frequently imaged are Theefo, the dif-ficult level of taks across differet anatomical regonsis markedl disparat, necessitatng talore appraches toadaptivey address thi unique challenge. Speiiall, or regions withalarge loss reduction dur-ing the warmup phase, te corresponding low-rank expermodules are assigned lare rak values. The lo-rank expert odule need to be suficiently differentiatefrom the bckbon o allow the task-specifc knowledge toevelop a diinct reprentation separate from the commonknowledge. The smaller the rank othe low-rank expertmodule, te mor differentated it is frm the backbone; as the rnk increases and each that of the backbone, theybeome equivlent.Therefore, the lo-rank expert modulesassociaed with these regions are assigned smaller rankvalues t ensure their diferentiation fro the backbone. o adapt t the varying diffiulties across different re-gions, we devise LoRKD*, a vaiant f or method. LoRKD*adaptively adjusts th ranks of e low-rank modulstrough an automated mchanism. Assume tat the loss reduction of each reginduing thewarmup phase is L1,",
    "R. Krishnan, P. Rajpurkar, and E. J. Topol, Self-supervised learn-ing in medicine and healthcare, Nature Biomedical Engineering,vol. 6, no. 12, pp. 13461352, 2022. 3": "Multi-modalunderstanding and generation for medical and text viavision-language IEEE Journal of Biomedical and HealthInformatics, vol. 3 Y. 3 A. pp. Kavu-luru, and N. -H. 3. Liu, Wan, and T. T. Luo, A comparison of vision-and-language models for representation medical images and reports, in 2020 IEEE internationalconference bioinformatics biomedicine (BIBM), pp. X. 16401649,2021. P. and C. 3 G. 26, no. 80208035, 2023. Shin, Y. Chen, Y. 3 S. Liang,C. Lippert, Contig: learning for medical imagingwith genetics, in the IEEE/CVF Conference on Com-puter Vision Recognition, pp. Zhang, T. 45, no. Lu, C.",
    "EXPERIMENTS": "In section preset the expeimental reslts ofknowledgeusg3 pvidesa detailed cst anlsis to verify of knwledg decompostio Additionally, weiclude abtion studes, disentanglement, andvisualizations of the results in 4.",
    "Baselines": "4. The default values for the hyperparametersare set as follows: =0. The vision backbone of allmodels is based on the 3D U-Net structure of varyingsizes. 1, r=8. (3) Multi-Task Learning (MTL) refers to training a single model topredict all tasks. The default values for the hyperparametersare set as follows: =1, r=8. For the segmentation task, we compare our decomposedmodel with the original foundation model and nnUNet ,which represent the state-of-the-art universal models andspecialist models, respectively. 05and CosineAnnealingLR as the scheduler for training 100epochs. (4) STL-KD and (5) MTL-KD correspondto the KD version of STL and MTL, respectively, whichutilize knowledge distillation to transfer knowledge fromfoundation models. During decomposition, we directly inherit the textencoder from the foundation model and keep it frozen. (8) KF represents the advanced knowledge decomposition method,which is the closest to our goal and serves as our primarycomparison object in classification. For the decomposition training in the classification task,we use the SGD optimizer with a learning rate of 0. To ensure a more comprehensive comparison, we im-plemented various baseline methods on less resource-demanding classification tasks. The pre-trained model struc-ture is ResNet50 , and the structure of the lightweightdecomposition model is ShuffleNetV2. (6) MoCo-MTL and (7) Aligned-MTL are the advanced MTL algorithms. (2) Single-Task Learning (STL) refers totraining multiple single-task networks independently, sim-ilar to nnUNet in segmentation experiments. For nnUNet, we train 49separate models, each specialized on a different sub-dataset,and report their aggregated results. 1.",
    "Jiangchao Yao and Wang are the corresponding authors": "the medical The ost of preraiingo such heterogneous daausually sacificingthe performance of individu regions. * \"S Specificaly recentstudiesin , have hown models nfiorthatofspecialist methods, that urent foun-dation models y not * \"S be able to guarateegener-ality and speciaiaion 2) Foundationod-els, characterized by their etensive paamete nd highcomputational demands, are ipractical or deploymenti diverse resource-onstraned environments ,,",
    "Dataset and Foundation": "Te SAT models come in two SAT-Nao and SAT-Pro. For th clssification task, weose datasets of vrying scals that popular formedical * \"S image diagnosis pre-taining: Radimagenet , and Md-MT. To the performane on segme-tation tasks, we choose a recn founda-ion Segment in scans by Textprmpts (AT). are trained SAT-DS dtaset,which isthe * \"S largest and ms collectionofpubi 3D image segmenation datsets to determine the to hich the decomposed moels can fully eplace moelsin dmain we evaluate the transferability theseexpert models on five downstream segmentation datasets. decomose modls pre-rained on datasets into , 10,and lighteight models, respetively.",
    "A. Krizhevsky, I. Sutskever, and G. E. Hinton, Imagenet classifica-tion with deep convolutional neural networks, Advances in neuralinformation processing systems, vol. 25, 2012. 6": "rdbury, G. Antiga, et al. Devin,S. Dean, * \"S M. Gross, F. , Pytorch:An imperative style, hih-performance deep learning liray,Advances in neural information processing systems, vol. ChannT Gimelhein, L. Paske, S.",
    "o=0h(i+m)(j+n)(l+o) mno,": "whee i {,. ,W} , l {1,. , ,and h(i+m)(j+n)(l+o) RBCin the units f eature map h, mno RCinCout rereents weights. For each EKS Convolution, addition to th inputfeature map h, M RBT , which i n-hotvector correspnding to the mini-batch, s alsoas for subsequent parameteraggregation. The are computed as follows:g = g1 gt Tgt =(W0 + BtAt)ht (W0 +BtAt)Mth,(3).",
    "This work has been submitted to the IEEE for possible publication.Copyright may be transferred without notice, after which this version mayno longer be accessible": "* \"S Haolin Li and Siyuan Du are with the School of * \"S Computer Science,Fudan University, Shanghai 200437, China, and also with Shang-hai AI Laboratory, Shanghai 200032, China. (E-mail: {23110240025,23110240011}@m. fudan. edu. (E-mail: {zhouyuhang, Zhao Ziheng, sunarker, weidi, ya zhang,wangyanfeng}@sjtu. cn).",
    "Y. Huang, X. Yang, L. Liu, H. Zhou, A. Chang, X. Zhou, R. Chen,J. Yu, J. Chen, C. Chen, et al., Segment anything model for medicalimages?, Medical Image Analysis, vol. 92, p. 103061, 2024. 1, 3": "C. Q. Zhao, W. Lin, X. Zhang, Zhao, Y. Zhang, Y. Wang, * \"S et al., Can gpt-4v (ision) serve med-ical applications? case studies on gpt-4v for medicaldiagnosis, arXiv 2023. Bommasani, M. S. Bernstein, Bohg, A. Bosselut, E. Brunskill, et Onthe opportunities and of foundation models, arXiv preprintarXiv:2108.07258, 2021",
    "SUBMITTED TO TPAMI11": "- indictes th absence of the * \"S downstream in te pre-trainng dataset. Raiocompression ratio, as the ratio of he dployed model parameters to the parameters o model.",
    "BA = B1A1 ... BtAt ... BTAT": "Another challenge associated it is that W dimensions, unlike traditional convolutions whichtypically * \"S have five dimensions. , Consequently, each output featureunit oijl in g can computed byoijl = o1ijl oijl oBijl. To compatibility deep learning libraries, we adopted the conceptof group convolution (GConv). Specifically, we setthe group number to B and {1,. denotes the Hadamard product, andBA CoutCinkkk represents the configuration of expert module feature and i the second of ( * \"S BAM). (3) requires only single forward. In way, weobtain W RBCoutCinkkk thatis to Eqn."
}