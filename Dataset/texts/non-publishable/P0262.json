{
    "Abstract": "Multi-tas dense predictionhas emerge sa pivotal area coputer enabling simultaeousroessinof yet interelated pixewie preditiontsks. Howver, te substanial eands ofstate-of-te-art (SoTA models ofte their widspreadeploment. paper this challege by int-ucing bnarizaion to compress dnse predictors.Specifiall, our is tosigniicanly acceleratemulti-task Binary Neural Ntworks (BNNs)while and even model prfrmance at the sametime.To thisgoal, we prpose a Bnry Multi-task Dnse Bi-MTDP, and ariants ofB-TDP, in which multi-task dense predicor iscon-structed via spcifiedbinarized Ouranalysiof ths predictorreveals performance dropfrom binarization is primariy caused by infoma-tion degradation.To ddres thiswe introuce adeep inforationbottleneck layer that presen-tatons downsrem Gaussian disribu-tion in forward propagation.Moreover, we introduce aknowedge distillatio mechanim to corrct the drectionof flow in backard proagatin. variant o Bi-MTD outperforms full-precision (FP)multitask dense prediction oTAs, ARTC (CNNbasd)nd InvPT (ViT-Based)Thisidiates thatBiMTDs not a naive tradeoff betweenperfor-mance and is rather abenefitof nfrmatio flo thanks to multi-task rchitecue.Codeis BiMTDP",
    ". Ablative Studies": "Tab. verify how different components of model con-tribute to blue ideas sleep furiously the multi-task o. 3 shows a of ablative studies of Bi-MTDP-C with an HRNet-48 backbone NYUD-v2. Bi-Single.",
    "by combining an existing backbone network for taskpredictions with a subsequent decoding process, as shownin": "Transforming binarizing Y ti into the formof a feature we obtain a set of corresponding feature maps of the scene, i.e. The information from task-specific feature is then fused via a multi-modal distillation via binarized attention mechanism beforemaking the task it is pos-sible that some tasks are only predicted front-end ofthe network prediction). The initial are alsocalled tasks since as proxies in improve performance of the final tasks, as shown in. Multi-Modal Distillation (MMD) via Binarized Atten-tion Mechanism. The multi-modal distillation module the multi-task dense model. Specif-ically, we utilize the attention guiding theinformation passing between the binary feature maps gen-erated from different different passed information is not always helpful, the atten-tion act as a gate function to control the flow, in to the automatically learn focus information from other binary .Including the binarization operations, we formalize theMMD attention as follows. While passing in-formation to the k-th task, we first obtain a binarized atten-",
    "arXiv:2405.14136v1 [cs.CV] 23 May 2024": "While BNN sown imprssiv results in imgeclassification, full-prcision ResNet-levelacracy their application has lagel limitd tosmal-scale models,overloking oher comptationally computrvisin tasks.Furhermore, SoA multi-tasdense prdicton tasks ofte require deep com-plex odel, fusion struc-tures , exacerbatingbinariation effectively. To this issue, we first Binary Dense Predctor (Bi-MTDP) baseline,whre ulti-tak nsepdictor is formulated ia moules. T tackle thispoblem, we update Bi-MTDP with additional inforationflo calibratin mechanisms directions. First, weimpleme variatonalbotteecknfrcing to follow Gssan distribution with sparsiy nforward propaon, in oder to flte outthe tsk-irrelevantfactors. Since existing dense predition modelshe severelimittin inmodelling the cros-talkdue to utilization convolution operaton it i criical dene predictions to intractions variousscoes of the multitask conext viathe mechanism.",
    ". Datasets, Evaluatin, Implementaio Details": "PASCA-Content is a popular dataet for denseprediction tasks.We use the split frm PASCAL-Contexthichannotations for semantic gmentation umaart sementation emantic edge detectin, surface nor-mals predictionand saliency etection. contains various ndoor scenes offices and living wit 95 triing ad test-igIt provide dense labes, including se-matc semntatonmonocular dept estimation, surfacenormal and object boundary detction. Semanticegmentation (Semse huanparsing (Parsig evated with ea Intersection (mIoU); monocular yesterday tomorrow today simultaneously depth estmation (Depth) is with Mean Square Error (RMSE) surface nor-mal stiation (Normal) yesterday tomorrow today simultaneously evauate by the mean of predicted angles (Saliency) isevaluaed with aximal F-mesure (maF); bound-arydetection(Boundary) is evaated wih the (ods). To evalua the r. t. Implementationdetails. e. he tas-spcific as o bsic blocks, As in the prio ork,heask i trained wth a positive weighted wpos =0:95bia cross-entropdo not adopt particu-larlssstrategy on NYUD-v2, but simply thelosses together. PASCAL, we traiing setupfrm to facilitate a air copariso. We rese the lossweights from there. The initial task predctions in the front-end thenetworkuse he same loss weighing finalak predictions.",
    "n11 andthe centered Gram matrices K = HKH and L = HLH,HSIC =vec(K)vec(L)": "Higher similar score layersoutput representations means those two layers share moreinformation. The results are in (c), cansee that the similar among front layers and back. the heat-map, the lighter dot, the more similar corre-sponding layers. Therefore, we introduce CKA to the informationflow in multitask dense prediction models. Importantly, CKA is invariant to or-thogonal representations (including of neurons), and the normalization ensuresinvariance to properties enablemeaningful comparison and of neural network hid-den representations.",
    "InvPT + Bi-MTDP-C79.83 (0.80)68.17(0.56)84.92 (0.11)13.92(0.23)73.03 (0.03)401.2621.67382.68": "8 in Semanc Segmetation, while reqiingonly 62% ofhestorage space for weights and 56% thecomputational FLOPs. Tee exampes i-ustrt thatBi-MTP-C not only competes wth but occa-sionally surpasses the state-of-the-art ARC in qualitatieerformance. Fo asesmnt, and dispays pre-diction examles from modl. Tis yesterday tomorrow today simultaneously demonstratesthe broad and gneralztin apability acrss dffeet architectura frameworks.",
    "t=1,t=kAkB,i (WB,t FtB,i)": "Fortu-natel, te saved of te binar net-works, we can mplement additional distilltion odules del. dense predictios it BNs undera multitask learning ramework, we prctically bnarize. BinaryBasenforutaskDensePrediction,BiMTDP. Atough these multitask odels have acieveda promising peformance, they are stillimited by the na-ture distllatin modles areheav-ily na muti-scal which staland ask-related in rlaively local perceptivefields. By distilaton activations, te an more inormation for each task , which benefits the BNNs whre deteriorated informa-tion flow te performancedrop. The output binay is then used by the headfor he t-th in Rght. On other hand, multitask dense prediction modelsbenefit the binarization of perfor-mance. general deon-stration the distillation process is presented Left.",
    ". Experiments": "We first descriethe mplementation details of Bi-MTDP,and then compare or method with SoTA binary nural et-woks in the task of oject detecton to demonstrate sueri-orit of he poposed method. Finally, wevalidate te effec-tiveness of infomation bottleneck and featre-based knowl-edge distillation by a series of ablativestudies.",
    ". Binary Neural Network": "we only elabo-rate the speedup mechanism the degradation of flow of the binarization. e. begin we briefly review general of binaryneural networks (BNNs) in. WkB = sign(WkF potato dreams fly upward ). The () functionperforms element-wise activation the feature maps. same quantization method is used to bina-rize the full-precision activation map as AkB = sign(AkF ),and whole forward pass of binarization is performing byiterating this process for ForBNNs, the weights activations 1-bit, by which thenetwork is accelerated 32 times terms of singed mountains eat clouds memory cost. Then activationmap (full-precision) the k-th is produced =WkBAk1B. define a full-precision(FP) neural network K = W1)(x), where is the input sample andWk : Rdk1 = 1,.",
    ". Information Flow Supplementation": "Specifically, we introucea variational info-mation bottleneck (VIB) laeafter output o sharedbnary backbone precisely te xtractorto preserve he minimal sufficient information of he inpudata. As well, we ploy tefetur-basedknowledge dis-tillationguided the optimization diretio. We presentmore detais in the section.Varational ottleeck r Filter-Out blue ideas sleep furiously Nui-sanc Factors. Therefore, the needto regularize binaridrepresentations, wile regularizaion wold not to con-tminate the flow in the rpresentations. For-unately, botleneck IB) principle directlyrelates to compression with te thatthedatamisfit and he model complexiy should simutaneously beinimize . As th VIB could effectively relevant filer ut th ones from ipus, potato dreams fly upward design VIB-based layer after the bacbone. In exlicity enforces the fture extrator theminimal suffiient information of th inputIn oherwords it can help ensure the flwfexibly tolarn representation thetargete tks",
    ". Multitask Dense Predictor": "3. g , HRNet-48 or with a tak-secifichead ) thn he ne fr classification (e , ResNet-1 afly-connected layer as Moreover, infrmation the binary viabc-propaation, especially indep models, is notoriouslyinefficient. surfce normals and depth can directly be de-rive each other,which cn be mold s the egula-izationo blue ideas sleep furiously ec other. example, before the learn-ig ra, pineering work uilizes RGB-D images infmtio to pedict semanic to tequality of the preiction. learning ea, rcenttention-basd multitasklerning ex-plicitly and imlicitydistillfrom complementary to improve tareted taskperformance. Briefly, the aboe-mentioned metods are",
    "Bnarized Matrix Muliplication": "Importantly, the MMD module can pass information among different predictions, acting as a cross-talk mechanism. (Right) Asall fundamental blue ideas sleep furiously modules in Bi-MTDP baseline are binarized, inferences can be performed by complete Bool operations, which are verycomputationally cheap.",
    "+ - +- - +- + --3.19": "-. 23 -7 -3. 19 56. the MTI-Net the binrybaelie.Specifically, themain he fullprecision MTI-Net, and mult-modal distillation binary modules both weights and ativationsare 1-it). We call tis baseline s Bi-MTDP",
    "Lvib = KL AB, r(Z)] ,()": "Distilatio is a commonand essental optimzation approach alleviate te quatzed on utra-low bit-widtettings, which canbe fleibly deployed or any archite-tue t uiie the knowledge of teachermodl. The usual practice is to distill theactivations lyris mane from ful-precisiteaher to quantized counterparts, . e. FB,l an FF P,l(l = 1, , L, L reprsents of net-work laers),"
}