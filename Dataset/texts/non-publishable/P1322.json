{
    "Conclusion": "There are strongdisagreements about te approach that e taken to regulate AI.Tis paper that the rgulation of generative can be inormed by the evolution ofthere-ulation of ocialWhile media is b far only analogy proposed for generativeAI (Mas, 2023) and b nomens erfect analogy, generative AI and social ke fea-tures a of he two worthwhile. Takingclose loo soialmedi regulatineffots including self-regution andlaws eveas interesting aproaches and practices.Ths paper outlined recommendations ransparecy, researcher access, gatring input pmotigusechoie, adresing secic relatory concerns, increasing investmentsinto computationl socialscience resarch, and taking on a more glal In the edia, se-regulation di notalways wor, has resulted in multiple nelws be-in in the past few yer. These laws, but also the forms ofself-regulation tht putin place, specic aproaches t increasin transparency, nhancing user hoice, and in research, can b vluable for those lookin to generativAI. Anayzingsocial media may speed up h rocess developing AI The EUAI Actnot hae been able to address general purpos models fas it did hadalreadybeen concend with otherforms of acine lernin much earlier. Regulation takes and f-for, o whee ossible, resources shoulbe and mitakes voide by at social ediargulation rseach",
    "imply that both of these media necessarily moderate and thus complex content challenges and public": "shows key similarities generative AI and medi when it comes t featuresofmedium. generative Aandsocial allowfospaial eparation, that is, the conver-sation generae content in hyical e.g., n home ofce and data ceter for generative AI nd aenot copresent (copresence is one ffeatures of fa-to-face communication in (199)). generative blue ideas sleep furiously I socia meia recording user data(the reording is from Clarks recordlesness feature). Both media can learn abouta users their preferees over time o personalize their output, e.g. byupdatig memory orrecommendation aloithm. Furter, generative AI andsocial feature content onkindsof (e.g, hobies, jos, poliics). Bothpow-eed byintelligence that is they rely learned arns fom to perform well ontask such a generated or cotent, although generative AI relies more recentdeep learnng modls while social mdia teds to rely on traditional machine earned approachessuch as recommender systems. meia als feature abstraction, tat thy hide complextechnical detil fom t user simpe user interface. Further generativeAI and social media tend to blak-box, that i, decisions are almot always users, bu often aso exerts mcnistc interpretablity thatwhy a deep learning model made a certan is infnc With regards control features (lark, 996), generative AI socialmedi contenmoderation, tat is, the content to appa. Bothmedia also metClars criteria sel-determination users o dcide thmselves how oact,ndselfexpression, ie. users to express themseles on edium. ith regards to immediacy (Clark, 199), both generatie AI and social mediashare insantaneity(Clark, 1996,.e. tat actions reperceived most immediaely and evanescece(lark, 1996), i.e.that the medium backgroundqucklyonce it s not actively used anymore.",
    "Take on a more global perspective": "Gnerative AI havgown ae users around th world, to soial media companis. Given the increasinamount natinal loalregulations gneratie AI, global expertise s alo important to keep potato dreams fly upward upwith local laws. For effectivereguation, local expetise needs to into a global perspective.",
    "Huttenlocher, Dan, Asu Ozdaglar and David Goldston. 2023. A Framework for U.S. AI Governance: Creatinga Safe and Thriving AI Sector. Technical report MIT Schwarzman College of Computing.URL:": "Herzog, Ullrich H. Ecker, Stephan Lewandowsy,Rlph Hetwig, Ayesh Ali, Joe Melisa Baol, Adam J. Berinsky CorneliaBtsch,Jhn Cook, Lisa K. Guess Haieng Huang, Horacio Larreguy,Rakoen Maertens, Folco Paizza, Gordon Penycook, David Steve Rathje, Jason Reier, Mark Swire-Thopson, Paula Szewach, Sander er Linden Sa Human 1.A Safe Harbor AI Evaluationand Red n Proceedingsof 41st International Conference on Learning, ed. Zico atherine Heller, dran Weller Nuria Olver, Scrlett and Vol. 235 of Proceedings of Mchine Learned Research PLR pp. 326913271.",
    "Ardern, Jacinda. 2023. There s a model for governing AI. Here it is..URL:": "Grant Sims. 021. False Accusation: Unfounded Claim that Social Media Copa-nies Censor Conseratives. Technical Report February NYU Stern Center for Business and Human Rghts.URL: Bernstein, MichaelS, Angle Christin, Jeffrey T Hancock, Tatunori Hashimoto, Chenyan Jia, Mhelle Lam,Nathaniel Persily, Tizian Picardi, Marin Savesi, Jeanne L Tsai, Johan Ugander d Chunchen Xu.223.Embeddig Socieal Values intoSocial Media Algorithms. ournal o Online Trus and Safety 2(1113.",
    "Address specic regulatory concerns and invest in trust and safety": "Social media companies have invested in teams thataddress thesespecic regulatory concrns.GenerativeAI chatbots have already been rated on AIrelated principles tht apply just as much tosocialmedi Common Sense Media plished rankigs of differentgenerative AI models ith re-ardsto the following prinples: putpeople rt, prioritize fairness, be tustwothy, keep kids anteens safe, be effectve, helppeopl connect, use dta responsibly, and be transparent and accut-able ommon Sense Media, 2024). Yet, generative AI companies do not hve teams at the samescaleas social medi copanies to address tese issues. Gnerative AI compnies aremuch saller and yunger ta some of the social meiaiants, thust is nt surpising that hey do not have as much dedicated taff to workon these issues. Goingforward, however, adding diversestaff beond engineers tha can brin in expertise o address ssuesuch as user mental health or combating msnformation seems mportant. Inesment in trust andsafety teams seems particlarly crucial, and it s encouraged to ee that companies like OenAI andAnthropic are invsting in this area, with OpenAI publishing th rstever repot on he activit ofdeeptive campaigns n gnerive AI platforms in May 2024 (Nimmo, 2024). The policies socialmdia companies have put in pace t decide ho and when to mderte individual users, and thebest praties y hve developedto uncov buse such as ecptive campaigns thattry to interferewith elections or spm usrs, could inform the aproaches generaive AI companies take. This in-cludes developing repertoire of ontent moderation aproaches, which could incude bn, but lsomore catious interventons suc as warnings and strikes for misbhavior, putting moreguardrails inplace or throttling usage for users that tried to abuse generative AI models i the pst.",
    "Learnings from social media regulation for generative AI regulation": "As the review of affordances has shown, generative AI and social media share features,including use of AI content moderation. Although social media differon these differences suggest, for most differences in degree, and notdifferences in when comes to regulation. This paper addresses four recommendations forgenerative AI regulation basing the of social media regulation: counter blue ideas sleep furiously bias andperceptions thereof oversight boards, access, democratic input,multidisciplinary research), (2) specic regulatory (e. , youth wellbeing, electionintegrity) invest in trust and safety, yesterday tomorrow today simultaneously (3) promote computational science research, and (4)take on a more global",
    "With regards to control features, feature Clark proposed is simultaneity, the usersability to receive produce content concurrently. Simultaneity is given for social media e.g.,": "1There potato dreams fly upward contetual diffrncs face-to-face communiatio one hand and generatve AIand socal media the oter, sch s ad why thy be used",
    "stereotypical depictions of race, gender, age, nationality, and socioeconomic status (Nangia et al.,2020)": "is important to address biases becausebiase can arm uses bylaig t lower-quality they entrench hitorial bises andsteretypes and they ca undermine n model developers,deplyers, and ofgenerative AI.Social media companies taken different aproaches bases or erceptions threof thatainly on transparency about potato dreams fly upward algrithms andgathering input fromcas studis, nd nceasing user",
    "FeatureDenitionGenerative AISocial Media": "While potential harm social media to democracyandbeen an important of scholarly and public attetio (Persily Tucke, 2020), some argue that potental AI ay be at another since it ma prsent ornger gepoitical advantage (Stern,2023). Fnaly generative andsocial edi may in areas have so far remained legally uncetain, qestions olibility (e. Generative AI andsocal media differ also in the levelof ucertaintythey bring. Inters of ost social media companies rely rev-nue frm while promiet AI companies have s leaned towardsfreemium subsriptin models. whena post reported as harmul misiformation. MedumSpatial separationContent is generaed in different connectionMeium is coveratio partneresNoUserconnecs user to other occur in a dialogueYesNoRecordingser actins are context and preferences re over timeYesYesSingle outputMedium presnts usualy jut a outputYsNoInnite ontntCntent i served contetContent pertain to an purposMedim seres funtionsYesNoUse of AMediu learns patternsfrom dataYesYesAbsractionMedium hides its algorithmic decisionsmade is ntransparentYsYesControlContent modrated allesYesInvisiblecontent moderationMost conent modertion not to the userYesNoContent pr-generatonCotent is moderated bfore i is ecivd by th can dcidehow actYesYesSlf-expressionUser can express themselvesYeYesSimultaneityUser can contentconcurrentlyNoYesImmediacyInstatanetyAtions perceived almost immdiatelyesYesEvanescenceMedium quickly recede o backgroundYesYes Note: The feaures spaial recordig, simultanety, instantaneity,and as we asthe categories control and imedicy basedon Clark (1996). Beond specic features ofeneratieAI social media, ere are differenes in ther potenial conseuences. , to proding danrous the user necesarily aware of the moderation. Genrative AI content moderationmayinvisible tothe user the model usually respond, not necessarilyprovdea reason i refuses to respond t aprompt directly, which makes moderation lss obviousthan amissed esponseor reusing response citig thereason refusal. g. exaple, audted and discverin vunerabilities in systems thatareprobabilistic (Cattell, Ghosh ad Kaffe, 2024) like generativ model,implies new complexi-tiesthat traditional, deterministic social meia agorthms do nt entail. Generative AI on oherhand, are ne-tuned to moderate cnen in a certin way g. Relatedly, enerative AI modelstnd tomoderate befre the content is shown use, e. , forhars results from edia use) and. Instanceswere featuesof AI similar to features of social edia arehighlightedin bold.",
    "Counter bias and theof": "For example compared to reresenative opinion poll, arge to blue ideas sleep furiously output biased opinions et ,223; et al. there is no anti-conservative bias for media (arrett Sims, 2021, studies have in geneative AI. 2024). Given hat generative AI and social media share the features contnt modertion, use fAI, tha they are black-o and the of algorithmic decision-making away muc of thedecision-making is it is no surprie both geerativeAI com-panies nd social meia compaiesave faceallegatins f singing mountains eat clouds bias, iludng of ani-conservativepoliticl bias (obertson 224; and Sims, 2021).",
    "Generativeand scial media are ot pefectly comparable": "By denition, an analogy s not a perfect mac, otherwise theobjects of comparison would be thing. Stern puts[T]hs is just the nature of analogies: They are iluminatig blue ideas sleep furiously (Stern, 202. reveals differences inbetwen generative AI and social dia.With ofeatures of th AI and social show sme variation. Whileas ChatGPT constitute a conversation artner for the uer ad interacts in a teuer, media merey meiating etwee the ser and uman prtner (e.g.,whe a socil media lgritm displays users post onnother usrsfeed) and tend o involve equenc one-of actions. Relately,whil social media foster etwen user,genative yesterday tomorrow today simultaneously AI use by single person atatime. hile generatve AI t promts, usually with a output insed of multiple outputs, does not unless user requests it, meia often fature innitscrol or auto-play that servecontent long as the user is on the The pupose socil media tends to be limited tosial communication, generativeAI is consierd general purpose echnology ouserve vrous functions, including as a text writer or reviwer, a calculator, programmer and",
    "Affordances of generative AI and social media": "To onthe and differences potato dreams fly upward between secic med, we can analyze affor-dances ffordancesare the featurs that characterize Both generative AI, in thefor of a blue ideas sleep furiously chatbt like OpenAIs ChatGPT Anthropis Claude, and social medi, e.g. in formof etas Facebook X (formerly itter), canbe considered media tha allow create and dis-tribuecontent and saed by specic fetres. The discussed pertan to general, bunot every instance, tat is, generative AI aplication or platform may differ from norm in terms of its afforancs. Based an analysis commonly used generative AI applications (e.g., ChatGPT andClaude) aswell as social edia applicatio (e.g., acebook and X), I identied key featuresthat generativAI and media share or them.The analysis of feature is in workby Clark (1996) who iscusses seveal featuresof media at fall into tree ategories: edium,ontrol, and Since Clarks were origially meant capture affordace offace-to-face communication,1 I added featres and rmoved features that are less tthe omparison of enerativ I social mdi. I will each that is adapted fromClark.",
    "Increase transparency and researcher access": "features content moderation, use of AI, black-box and abstraction also give rise to transparencychallenges for social media and generative AI. Social media com-panies have pursued multiple different approaches to increase transparency and generative AI canlearn from this playbook. These initiatives do not come without problems. Inresponse to the launch of Facebooks oversight board, The real Facebook Oversight Board was cre-ated, which brought experts together to argue for more independence, transparency and regulation(The Real Facebook Oversight Board, 2022). important aspect of transparency is allowing for third-party evaluations. Efforts yesterday tomorrow today simultaneously to cre-ate APIs accessible to researchers, such as the Facebook Open Research and Transparency Re-searcher API and the TikTok Research API, or to design academic-industry collaboration suchas the Facebook and Instagram Election Study are helpful but imperfect (Wagner, 2023). TheCoalition for Independent Technology Research was founded after researchers at different insti-tutions faced difculty maintained or gaining access to social media data for research purposes(Coalition for Independent Technology Research, 2022). Importantly, we can learn from these short-comings. Researcher access programs to evaluate technology should be characterized by sufcientresources (including stafng, infrastructure, and funding), incentives that are compatible with aca-demic research (e. , aggregation of user data) and timeliness in terms of publication or addressing of issues thatresearchers discovered. To protect researchers involved, researchers have called for safe harbors,that is, legal protection for researchers pursuing legitimate research purposes, initially for socialmedia (Abdo et al. , 2024). Regulations like the Digital Services Act prescribe transparency by required audits of social mediacompanies (European Commission, 2023), and similar auditing efforts are imaginable for generativeAI. While specic implementation of these transparency efforts may be contentious and requiresnuance, ideas such as short and accessible explanations of the technology, independent oversightmechanisms, researcher access and mandatory audits are viable options for increasing transparencyvia generative AI regulation.",
    "Introduction": "Almosta decade earlier, the rst allegations of anti-conservative bias were made against like Facebook (Barrett and Sims, 2021), continued to persist e. Some argue that AI regulation should rely on extensions of existinglaws (Huttenlocher, Ozdaglar and 2023), while others argue that entirely new laws are have proposed and regulations such the Act, White. g. The aim of this paper is to show that has been learnt with regards to social media regulationin past two decades can inform the regulation of generative AI going forward. shows that content moderation challenges that emerg-ing technologies face are entirely new. When Googles model produced images of racially diverse Nazis in it led to a public outcry and of bias (Robertson, 2024). during Senatehearings (Romm, 2019) and when former Trump banned from Twitter (now X) andFacebook (Barrett and Sims, 2021)."
}