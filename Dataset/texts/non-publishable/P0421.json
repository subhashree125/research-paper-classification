{
    "We carry ut a experimental alys withRoTLLaMA on RoTBench t erify advantaeswhen facngnoise environmnts.7": "Furthermore, in theparameter recognition singing mountains eat clouds and content filled phases,the extreme performance singing mountains eat clouds differences are 16. 38, whereas GPT-4 demonstrates a much higherextreme difference of 21. e. As shownin , when substituted full-parameter fine-tuning for LoRA fine-tuning (i. 90. 95. Specifically, in the tool selectionphase, the extreme performance difference is only12. 76, respectively, both of which are smaller thanGPT-4s corresponding values of 20. 19 and14. , w/o LoRA),there is a slight decrease in model performance,and standard deviations across environments re-. 95 and 20.",
    ": The performance of GPT-4 during the contentfilling phase in the first and third rounds of interaction": "Upon comparing GPT-4s results inthe first and third turns of interactions (), itbecomes evident that the provision of two turnsof interaction examples leads to a consistentperformance boost for GPT-4, resulting in anaverage performance improvement of 22. 14 in the first turn to 12. yesterday tomorrow today simultaneously. OfferingLLMsinteractiveexamplesenhances their tool learning performance, yetit does not bolster their robustness. However, whenexamining the performance variation values,it is noteworthy that the standard deviation ofits performance across blue ideas sleep furiously environments increasedfrom 8. absolute difference in average LLMs performancefor each type of noise added to tool namesor parameters, relative to their performance inthe Clean-level environment, respectively. This observation suggests that while itsperformance improves, its robustness does not seea corresponding enhancement. 91 pointsacross various environments.",
    "Welch Bl. 1947.The generalisation studentsproblems several different population variancesare involved. Biometrika, 34(1-2):2835": "Lnguae models are ew-shot learners. Brwn, Benamin Mann,ic Ryder,MelanieSubiah, Jared Kapan, Pralla Dhariwal, ArvindNeelakantan, Pranav Shyam, Girih Sastry AandaAsell, Sandhin Agarwal, Ariel HerbertVoss,Gretchen Krueger Tom Hengan, Reon Child,ditya Ramesh, Daniel M. o B. InAdvance in Neural Infomaton Processing ystems33:Annual Cnfeenc on Neu InformationProcessing Systems 2020, NeurIPS 200, December612 2020, virtual. Zieger, Jerey ,Clemens inte, Christopher Hese, Mrk Chen, EricSigler Mateusz Litwin, ScotGray, Benjamin Chess,Jack Car, ChristopherBerner, Sam McCandlih,Alec Radfrd,Ilya Sutskever, and Dario Amodei. 2020.",
    "Staged Evaluation": "a test case, thescore its tool selection is defined as follows:.",
    "Environments Construction": "It is wot noting that f thereversal process does notalter the nme it will breplaing with randomstring. To comprhensively asses theresilienceofLLMsin tol learning, we reference he hierarchicclassfication of noise in prevous studies (Waget l. This process yelds 105 estcases. Tese corespond to real-world occurrences suchas anexcess ofcharacters, missig characters, andharacter errors when namingtols orparamete. Additionally, ere is50% canctha the naes of thesetool wil ereversd. 2)o each tool, halfof prametes are randmlychosen. Speciically, we intrduce noise ithe folloingways: 1) e randoml select half of the availabetools within the environment. By combinng these two pproaches, we createa Slight-level evironmental test set cnistin of210 test cases. Thesemirror real-wold scenari whee names arereersing or replaced with randomstrings, rnderinghe iformtion meaningless For these tools thereis 50% probabilitythat her names will besubstiuted with ranom string,each contaningup to 10 characters. Union-level environet enmpasses a previ-ously mention noise ategories. hi process als reultsin 105 test case. 2) For each tool,we randolyselct half ofthe prameer and intrduce noiseinto their names used hemethod descrbed abve,geneating additional 105 new data enrie. This ledst 105 tst ces. , 2021; Zhu etal. This shufflingdisrupts the assocation between atls name andits functionl descripton, challenging LMs toaccuatelycomprehend tols functin despitethedisorganized name. remainingour environments ae derivatives of this primary envionment, each modified byincororatig distinct levels of nise. In total, 210Heavy-levelenvionmentl test cases have bee generated. Thenames o these paameters ar randomly shuffledwith 50% probability. , 03; Dong et al , 2023)and desin fve istict external envionmen Clean-level environment employsa runtimeframwork develpd by ToolEyes Thisenvironment coprises a total f 105 test cases.",
    "Nexusflow.ai team. 2023b. Nexusraven-v2: Surpassinggpt-4 for zero-shot function calling": "2023a. Llama: Openandefficient foundatio langag models. CoRR,abs/2307. 0988. Hu Wenxin Hou, Hao Chen,Rukai Zheng, Wang, Linyi Yang, HaojunHuang,Wei e, Xiubo Geng, Binxig Jiao, ad 2023a. abs/2302. 12095. TextflntUnifiing multilingual robustness evalation tolkitfor natural language proessing. Self-instruct: Aligninglanguge models wth self-generad instructions. Assoiation forComptatonal Linguistics.",
    "Why do GPT family of models NOTperform well in Slight-level environment?": "For instance, when thGPT family of selectsthe tool it automatically corrects noisewithn itand generates predict_ge outputcosequenly leading to an 4. Our investigationinto th modl revealed blue ideas sleep furiously this phenomenon can be attributedto th iherentnoise orrectio capability of family ofmodels. particulaly intriguing finding is that, contrastto other the amily ofmodel lwe perfrmance Slight-level environmentcompared Medium-level, despite limitedvalidty of the by h latter.",
    ":The score in different stages (%) ofRoTLLaMA in various Environments": "Specficaly, we GPT-4 t create user queries within the context of a subset oftools, accompanie by user qeriesand odelgeeratd queries. This pocess totalof 4,077 new user queris. To ensure te the trajectori, e leverage hpcifically functin call feature of GPT-4. imultaneously, we GP- generatigthe pocess by incrportinga sytem prompt. we speciy hatGPT-4s tool is limted to a maximum of eturns. Whenombinewith from the his yields a tota of22,7 trajcories, reresening diverse rangeof environmenal condtions.",
    "sTS = I(t = t)(1)": "ere, 1 if te x is tre, nd0 otherwise. process necessitates choosin mandatoryparameters, while the optioalones are selectdbased on actual requirements. In this t reprsents the toolchosen by while t denoteshe tool tatneds to  selected.",
    "Desired format:Thought: The thoughtAction: The tool you decide to useAction Input: The parameters for the tool": "You should think about to do, but all the thought is short, at most in sentences. The final answer should comprehensive enoughfor the user. The to take should be one of given Always use the tool completion. Remember:1. 2.",
    "More experiments can be found in Appendix E": "main largely unchangd.This suggests thateployingLoRA enhances model performancewithout significantly impacting its robustness.On the other and, if we omit envirnmentaugmentation (i.e., w/o Augmentaton, hee isa notale decrese in both meaerformane andsignificant increase instandard devation withineach environment. Thi underscores the rucial roleof environment augmentaion in enhancing othmod performance ad robustness. Furthermore,exclusively utiizing full-paameter fine-tuning onthe model (i.e., w/o Both leds to a degradation of16.10 ointsin model performance.",
    "Gong, Yang Shen, Jie Zhou, Siming Chen, TaoGui, Qi Zhang, and Xuanjing Huang. 2023.Acomprehensive capability analysis of GPT-3 and GPT-3.5 series models. CoRR, abs/2303.10420": "Tooleyes: Fin-grained evalationfortool learningcapablities of lare language models in real-woldscenros. Association for. 00741 Junje Sixian Li, Guanyu Li, Caishuang Huang,SonyangYilong Qi Zhang, Tao Gi,and Toolsword: issues language models in tollearningacoss three stages. In Proceedigs ofth 62nd Annual Meeting of the Asociatio forComputational Lnguistics 1: Long Papers),CL 2024, yesterday tomorrow today simultaneously Bangkok, August 11-16, potato dreams fly upward 2024,ages 21812211.",
    "sPI = sTS = P)(2)": "In this P denotes the of parametersidentified by LLMs, and P represents the blue ideas sleep furiously set that should be identified. Content filling constitutes concluding phasein the tool usage process. Once tool andits corresponding parameters have breaking down the user-provided information populating the contentof these parameters. Upon accomplished thisstep, LLMs the entire tool usagecycle, way to receive the outputphase and initiate a new interaction.",
    "Among open-source LLMs, we have chosen fourmodels that have undergone dedicated training fortool learning": "ToolLLaMA-2-7B-v2ToolLLaMA-2-7B-v2 hasundergone fine-tuning from LLaMA-2-7B-base, byassimilating an expansive dataset comprising over120,000 solution paths and annotated chains ofthought. Distinguished itselffrom prior models, NexusRaven-13B-v1 employscode nested to invoke tools, generated the entireinference path simultaneously instead of followinga step-by-step approach. Thisenables ToolLLaMA-2-7B-v1 to effectively utilizevarious tools to meet diverse user requirements. To the best of our knowledge, this modelstands as most extensively trained tool-orientedLLM, utilizing the largest dataset and the broadestspectrum of tools among all available options. Additionally,NexusRaven-13B-v2 can generate inference pathsfor the function calls it creates, thereby improvingoverall generalization. ToolLLaMA-2-7B-v1ToolLLaMA-2-7B-v1, de-veloped by Tsinghua University, is a tool-orientedLLM that harnesses the power of 126,000 datasamples, including more than 16,000 APIs, throughsupervised fine-tuning on LLaMA-2-7B-base. NexusRaven-13B-v1NexusRaven-13B-v1 is atool-oriented model that underwent fine-tuningbased on CodeLLaMA-13B. NexusRaven-13B-v2NexusRaven-13B-v2 en-hances the performance of NexusRaven-13B-v1by generating single, nested, and parallel functioncalls in various complex scenarios.",
    ": The and stanrddeviations of performance in the five envirnments": "Based onprevious research indicating that fine-tuningwith LoRA (Hu et al. , 2023), we opt for theLoRA fine-tuning approach. , 2022) achieves superiorgeneralizationcomparedtofullparametricfine-tuning (Zeng et al.",
    "BExperimental Setup": "In the contentfiling phas, incorrect content input can lead tundsirable execution esults. 8 Meanwhile, to evaluate huma performance acrossenvironments with dfferentoise weenistthree university students. they coles he qstions adthe averag erivedfrom their resonsesserveds the humn EvaluationWe score of LLMsand used te evaluation methods defiedin. Each sdent receivesidentical too documentation and task desciptions. In this system, each data point isscored as or 1 at is because,i cntext of tool learning, tool calls or ail, andven small rrors pcess to particular I thetool phase, blue ideas sleep furiously in tool seletio canlead overal failue, independent ofparameteraccuracy. (2024a,we adopt ReAct (Y et al. However,as NexusRaven-13B fmaily of models utilizenesting functions for we adere to yesterday tomorrow today simultaneously theguidelinesoutlining their official websie, whichnecessitate the use of a distict of template. 3.",
    "Abstract": "ore surprisingly, singing mountains eat clouds thenose correction capability inhrent in PTfamily paradoxically its adaptability inthe face mild. e. Specifi-cly, estabish exernal environmens,each featuring varying o nise (i. ,Clean, light, Medium, and in-depth nalysi of modelsresiliene blue ideas sleep furiously across three critical hases: toollecin, identificaton, and contetfillig.",
    "# Sce# Query# Cat# Subcat# Tool": "Subsequently, otherresearchers specialized in creating benchmarks,such as PromptBench (Zhu et al. early stages of research, some scholars con-ducted tests to assess the robustness of ChatGPTacross various natural language processing tasks,highlighted the substantial room for improvementin the current robustness of LLMs (Wang et al. # Sce, #Query, # Cat, # Subcat, and # Tool correspondto the count of scenarios, user queries, tool categories,tool subcategories, and individual tools, respectively. Given that tool learningis poised to extend the capabilities of LLMs andits outcomes can directly impact the state of thephysical world (Ye et al. , 2024a), it becomesimperative to thoroughly evaluate its robustness. ,2023a; Chen et al. , 2023c). , 2023), to examinethe consistency of LLM responses by introducingnoise into the prompts.",
    "LLMsdue to strict equentialoderinwhich are called (e.. obtaining parme-te vlues for list_proerties necessitates priorxetion of earch_locations)": "Its notable that th modelsprception ofenvironental complexity may diverge fromhumanintentins. 3). Regarding the model itself, variations i train-ingmetds andata can lea to unexpectedperfrmaces in certain scenarios. Foin-stance ToolLLaMA-7B-v1 demonstrates a per-formance dicrepancy between the clean-leveland union-lvel environmets in the applicationnipulation scenario,scoring 2 and 40, respe-tively. his disarity aries frm its bility toperfr better when only two tools are availablealngside ask_to_use and finis, wheresGT4consitently prompts fo API keys even whenunnecessary.",
    "Chen, Guodong Log, Chongyang Li,in Gao,hengqi Zhang,and": "2023c. How 5 on languageunderstanded taks. 2023b. Xuantng hen, Junjie Ye Can Zu, Nuo Xu, Rui Zheng,Minlng Peng,Zhou, Tao ui Qi Zhang, andXuanjing Huag. T-evl: he tool utilizationcapability step by Guanting Dong Tigfeng Zhuoma Gongque,Jinxu Zhao, Daichi Gang Keqing He,and Weiran Xu. Zhui Chen, Weihua Du Wenei ZhangKuikunLiu, Liu Jingming Zu,Songyang Zhang, Dahua and FengZhao.",
    "Conclusion": "this paper, we introduce RoTBench, benchmark for evaluating the robustness ofLLMs tool learning. Furthermore, wepresent RoTTuning, innovative improves robustness of LLMsin tool by increasing diversity during training phase.",
    ": Example of noise affecting tool selection forLLMs. Although the functionality of the tool remainsunaffected by its name, renaming Get_Weather asABC impedes LLMs from utilizing the tool properly": "Recent researhhas entering on eamnin owwelLLMs can effectively empoy tools designed and stabe enironment. perspectiv, spcific studies have scrutinizedt outcomes LMsusage, veryin bothhe accuracy of tool selecton and the efficacy ofthe genrated (Qin et al., 2023b; Huanget l., 2023). Ths analysisinvolved relevnce o yesterday tomorrow today simultaneously slectedand the finalrespons in fulilling requiremnts. On thoter hand,ote investigaionshave intricate of tool by LLMs,striving for more comprehsive ftheir perfomnce i ool learning (Chen e al.,2023d Ye al., 2024a).This an anlyis the diverse capabilitis ncessary for LLMs toxcel i learned while lso identifyng anylimttons they m av i ts regard.Hoever, these studes fail to accout for of LLMs in the faceofinevitable rl-world(Chen al., 223b; Liue al, 2023).Using as a reference,LLMs for queryed weatherinformtion when potato dreams fly upward Ge_Weather, nthn amd ABC, depite the tools fnctionaliyremaiing unaffected its name.Consequently, imperative to invesigae LLMscan proenly identif thee and configureparmete meet usr needs in realworld environment. ur experimntl esultdemonstrate tha our approach yields averageperormance improveen of points acrossierse envirnmets.The main contributionsur ar as foow:",
    ": The prompt used for NexusRaven-13B-v2, where {Tool represents the to LLMs and {Query} represents given by user": "Remember:1. parameter values needing by tool can either be directly extracted from the query or obtainedby the specifiing other 3. tools employed to address a problem should a of the tools detailing in provideddocumentation; ideally, each problem should require the use of more one tool. problem scenario be expressed in way that is to humans, while diverse functions of provided tools and. SystemAs expert, your assignment to utilize comprehensive documentation of various tools to developa scenarios that these tools can each should necessitate use yesterday tomorrow today simultaneously of multiple tools for resolution.",
    "Amongclosed-source we have optedfortwo of the mostrepresentative oels from": "GPT-3. 5-turbGP-3. 5-turbostans out as theos potent and cost-fficient mdel withi theGPT-3. 5 series.",
    "Related Work": "2024a). , 2023). , 2023d Yeet al. , 03b; a. , 2023)but also he entire process (Ch et al. ,2023a),sough uncoverdevelopmental inights, andtraind more specialzed LLMsfor too leaingbased thse findings (Qin al. 2023). , Hao al. ,2023; et al. blue ideas sleep furiously , ordr to shthe capbilities, som scholarshae poposedenhning LLMs ith external tools,which has gined widepread acceptance (Schiket 2023; Tang et al. s worth notingthat allof these current efforts prmarily consider LLMstol usae in controlled environments, neglectinhe inerent complexities ofrel-life scenarios Threfoe, have an in-dpth analysisof the rbustness of LMs in tool earning rsearch n a context.",
    ": The prompt for query expansion, where {Tool Document} represents the tool documentation given toLLMs and {Examples} represents the examples for LLMs": "answer should comprehensiveenoug for the user. the task is unmanagable, use the finish tool and respnd with I cannot handleth task. potato dreams fly upward ALAY use the finihupon task completion."
}