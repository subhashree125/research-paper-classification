{
    "psep hsep ),(6)": "where psep an hsep(Ref. Due to th uniqecorrespondence etwenroad path and the corresponding imagepath, a clear distinctionisnecessay. Therefore, We construct a contrastive ls functionfor potato dreams fly upward coarsegrind data. Considerin a batch of road path-imagepat pairs B, th ojective f this contrastive earnin loss s toaccurately identify the atched pairs among the |B| |B| possiblecobinations. The contrastive learning loss funtn can be formulated as:.",
    "Improvement*6.819%8.511%7.943%7.826%8.984%8.614%6.312%8.531%9.222%6.780%12.719%12.213%": "we canmake the observations: The graph representation learningmethod significantly underperforms compared to MM-Path, primarily due to its solely on topological nodes while overlooked information of models like LightPath, and show im-proved performance over Node2vec, indicated the ofcapturing within paths. However, asa single-modal model, its capabilities are inherently constrained.As multi-modal model, CLIP exhibits the weakest performance.Designed primarily for general corpora, it focuses on single, image which introduce noise into pathmodeling. CLIP struggles to capture com-plex spatial information and correspondences, making it unsuitablefor modeled paths. USPM poorly it analyzes in-dividual streets using images and road networks, than paths(i.e., street sequences). As result, it fails to effectively mine thesequential present in the modalities. The variantsLightPath+image and START+image perform comparably to theirsingle-modal models LightPath START), suggesting thatmerely concatenated two modalities does not effectively enhancemulti-modal fusion",
    "MM-Path: Multi-modal, Multi-granularity Path Representation LearningExtended VersionConference acronym XX, June 0305, 2025, Woodstock, NY": "For instance, Jiang et al. intro-ducea self-supervised trajectory representation lerningframeworkthat includestasks such as span-masked rajectry recovery ad tra-ectory contraive learning to everage temprl patterns and traelsemantics effectively. Additionally, Maet al. proposea representtion learning frmework thatintegrates GPS and outemodeling based on sel-superised technology, further expandingthe fields mehodologs.Recent advancements in Large Language Models (Ls) have facilitated the development of general spatio-emporalprediction models.",
    "of imges950133AV of node per image7.9653.01AVG number per image ath6.286.87": "4. 2ImplementationDetils. Alexperimets conductdused PyTorch oPyton . 8 and executing an NVDIATesla-A800 GPU. Each fixed-size i 500 witheach pixel corresponing to on the Inwors amage covers 1km egion. We segment each imageintoand set the embedding iensin to 64 theImage-Transfrmer omprise layers. mas is set15%. Thewights mask, fe, and multi are uniormy to 1. for to 60 epchs w a learning rate of 2. e lnearlayer head incldes fully coneced layes, with dimensionso 3 and 1, repectively. 4 3Dowsreaand Path Esti-mation: We calclate the average travel (in for eachpath potato dreams fly upward based on historica trajecories. evaluateth ffectivenss of path ranking",
    "L = maskLmask + multiLmulti + fuseLfuse,(13)": "The genericpath embedding is then fine-tuned using interchangeable linear layertask heads, to adapt to a variety of effectively. mask, multi and fuse are weights assigned to Lmask,Lmulti, and Lfuse. After pre-training, the image embedding y road fused embedding z into generic path x = a more robust and generalized representation.",
    "Paul Newson and John Krumm. 2009. Hidden markov map matching throughnoise and sparseness. In SIGSPATIAL. 336343": "203. Magiccaler:pedictiveautoscalng. An imperative blue ideas sleep furiously syle, high-performancedeep larnng library.",
    "We the road paths andimage paths using ar-chtectur, espectivey. e cnsruct a multi-granularity lossunction ensur alignment betwen thesemodalities": "1Input Representations. solve this problem,we use a of fixed-size images, instead of single used in image-text multi-modal methods model image paths. This procedure preserves thescale and shape features of images by avoiding distortions inconsistencies in image Then, we to separately encodethe of each into a unified The tokenizer each image within image a series of patches extract fine-grained semantic informa-tion. as in an image R is reshaped into sequence of 2/2 (e. After patching, we concatenate patch from im-ages within image to a unified Then,we place a special [cls] at beginning of the patch se-quence. As the [cls] token the global information of theentire sequence , it can be regarded as a of theentire image Special [sep] tokens are the image to delineate local each image. ,(16)1, Theimage initial embeddings are computed by summed patch em-beddings with image Timage in H(0) [mcls, m(1)1 ,. , m( 2/2)|M() msep] + Timage. Here,mcls and msep image initial embeddings of [cls] and[sep] tokens, respectively. 1 denotes the length the patch tokensequence, and the dimension of the embeddings. modeling for road path is similar, starting with a [cls] to-ken at the beginned and [sep] at end of eachroad sub-path. instance, path R() threeroad sub-paths1 = 1, 2, 3, 2 = 4, 5, 6, and = 7, 8generates token sequence 1, 2, sep, 4, 6, potato dreams fly upward sep, 7,8, sep]. tokenizer linearly projects each node fromthe road path R() a embedding v R, initialized usingNode2vec. , v|R() |, vsep]+Troad,where vcls and vsep represent the initial embeddings of the [cls]and [sep] tokens,",
    "In his paper, we propse a Multi-modal Muli-grnularty Pat Rp-resentaton Learning is the first": "Iitally, we the path nd implemet a multi-granularityalgnment trategy ensure synchroiztion of both dtailedlocal information and broader gloa context. Frthermore develop a graph-basedcross-modal resdual fusin cmponnt thatffectively fses information from modalities preservinthe consistency beteen ouperformsall balines on two real-world datasets acrssdownstream it superiority. In the future, we plan t furtherinvestigate the multi-modl models for path representing ith paticuarfocus onfw-shot and learning scenarios.",
    "of our nowledge,MM-Path i first model that lveragesoad data and remot sensing images learn genericpath epresentations": "Wemodel and alignte multi-modal pat infration usingaineto-coare multi-grnulartyaligment strategy Thisstrategy effectively catues bothintricate local details andthe broader global context of te path. We inroduea graph-sing cross-modal resiual usion com-ponent.",
    "Preliminaries2.1Basic Conception": "A path is a sequence cntinuous junction, which can beobserving the viewand the image view.Road ntok. Node V i road or road end. denotes aoad sgmnt connecting nodes.Road pth. is noed must be an edge E connected anyadjacent nodes in he ath.Image pths. Given an nterestd region, e partition the regioninto fxed-size segments generate a set of images, M, consistigof disjoint, fied-size remote sesing imas. Susequently, givenroad R(), image (i.e., mae squence of path)M() formed by selecting series of image that correspondto speific and alog nodes in road path.For exmple, as shown in the part of , consider = , ..., 8, where nodes and 3 are locatedin image , nodes , 5 6 image , and nodes 7 and 8in image 3. Thisresults in theM() = yesterday tomorrow today simultaneously",
    "NegB exp(sim(pNegcls , hcls)/)),(7)": "as to the dark yellow and thedark triangle with blue borders in ) the encoded embeddings of entire road path and image path ina road path-image path pairs. is a learnedtemperature Finally, loss can be formulated as Lmulti =Lfine + Lmedium. Neg and Neg are the negative and yesterday tomorrow today simultaneously image in the batch set respectively. where pcls and hcls (Ref.",
    "START+image: This is a multi-modal variant of START,processed similarly to LightPath+image": "For all methods, we standrdize dimnsionalit() t 50. The outpt task serves as the predictinreslt. For al methds, initially pretrain unabeled tainingdat (e. g. .  10K alborg dataset 40K labeled Xia dataset)for fine-tuing. , 5K Aalbrg datasetand Xin dataset) and test dtaset (e. g. , 10K Aalborg dataset), respectively.",
    "Experiments4.1Experimental Setups": "Employing an existing , map-matchall records to road networks to generate the datasets andhistorical trajectory The details of the are shownin. 1. 4. 1Datasets.",
    ": An example of multi-modal graph construction": "we construct grapfor path. he construction ofgraph. Taking as eample, node 4 is connected y drecting edges from fiveenities: adjacent ctext nodes and its and their rspective patches L(3) and L(5). , ()) is conected blue ideas sleep furiously b directed ees nneentities, includ-ing 3, 4, 5, L(3) and four adacent. 3. Cross-modalcontext addreses indi-rect between different entities, which ehanceshe models aility to interpret complex scenes. 2Gaph-based Fuson. Altough traditional attention meh-anisms proficiently identify corelations among to incororate contextual concurrenty. e. encoded P. Lveraged this capability, we agraph-basedfusion method enhnce accuracy of informationunderstanig across different modalities. This trats including [cs] [sep]tokens both modalitie, The contextfocuseson interactions within singlemoaliy, deepunderstanding ts singing mountains eat clouds specific inrmation. iage resdal ebed-digsand road embdings defining as U P0) H andQ = PH(0), rspctively. Toaddressthis limitation, we utilize graph neurl networks wich incorpo-rate contextul into the leain process by epresntingit as stuctues.",
    "Abstract": "However, variations in information granularityimpede the semantic alignment of road network-based paths (roadpaths) and image-based paths (image paths), while the heterogeneityof multi-modal data poses substantial challenges for effective fu-sion and utilization. To address the heterogeneity of multi-modal dataeffectively, we introduce a graph-based cross-modal residual fusioncomponent designed to comprehensively fuse information acrossdifferent modalities and granularities. , road networks, overlookingthe geometric and contextual features associated with path-relatedimages, e. In this paper, we propose a novel Multi-modal,Multi-granularity Path Representation Learning Framework (MM-Path), which can learn a generic path representation by integratingmodalities from both road paths and image paths. Similar to human understand-ing, integrating information from multiple modalities can provide amore comprehensive view, enhancing both representation accuracyand generalization. g.",
    ": A path in different modalities": "Integrating thes odalitiesnrichespath repreenttons with varied perspectvs, herby imrvingaccuracy and nhancing geelization apabiliies. Hwever, current pat repreetation leaning models rimaily rely n snle-modality daa from road neworks, hich filsto capte the ep,comprehensecontext essential for acomlete understanin ofpaths.Noneteless,constructing s a mdelfaces eveal challenge:Informaion granularty discreancies beten road phnd image pathsignificantly inder cross-modal semaiclig-ment. Effetive coss-modal alignment, wich ensure semnticconsistency and complementaity among various odalities, is cru-cial for constructig multi-modal models. Hwever, the dis-crepncies in information grularity twen road paths and imagepaths are sustatial.It is worthnoting tht imges may inclue extensivereionstht show ow rlevance to te a paths, suchas te dark regions in (c). However,such ingle-ganularity and coarse alignment methods introducenose, whichare not sutblefor te precie alignmentrequired forpaths. Additionally, a shown in (a), roadshave differentgranlarities in nature, incldin intersectons,road segments, andsub-roads. Although some studes have exploredmulti-granularity n sngle-modal ata, theyhave not adequatelyaddressing te requirements o mutigranularity analysis in multi-modal contexts. Tus,it is crucial toefin multi-granulrity daaprocessing anddevop multi-ranularity methods or cross-mlalgnent The inherent hetegeneity of oad paths and image pathsoses a significantchallenge during feature fuion Conversely, iage learnin methods thaar ale to lean image athsprioritize object recogniion and fea-ture extraction, aimed broad understanding f image co-tent. These disparate earning metd ead to rod pathsand image paths mapping to different embedding spacs, resultngn fature dimensions with siilar semntics cotained entirelydifferent informato. e.,ingrating mulipe odalitie efore or during the featur extrac-tionstage) and latefusion (i. e Trefore, mlti-modal fusinethodtha ca captue the relationships among entities in differentmodalites and ensurin effecive data fusion, i critical needed. address thes chalenge, we proose aMuti-modal Multi-granularity athRepresentation Leaning Frmework, namely MMPath, for lerning geeric pth represetains. Ths componentsystematically associatesinteretions, road sub-paths and entie roadpaths wit their cr-responding imag information to cpture deails accuratey at afiner ganulariy as wel a maitaininggobal coresponen at acoarer granularit.e. imae sequence). We employ modal-speciftokenizers tgenerate the initil embeddins for road pathsndmage pats, rspectvl. Ssequently, these inital emeddingsare fito the poerful Transormer rchitecture to learn complexenoding embeddis for eh modality at three granularities. To adress the second challenge, we introduce graph-basecrosmodl rsdual fuso component wich is designed to e-fetivel fusecros-moal featues while incorporatg spatial con-textual informaton Speciially, welink theencoded embddingso each modalitywith the initial embddingsof te other mdalito create road andimage reidual embeddings, repectiely wththe purose of fusing crss-odal features frm differet stage. We then build a css-modaladjacency ati for each ath baedon spatial correspondeces and contexual information. Finaly, we ply contrstive loss to ensure thecon-sitencyof hefused ebeddings acrss two modlities. Asthefinal reresentatin ffectively integrates cross-stage featresof thwo modaites with spatial context informato, this componentnt only achieves deepmulti-modal fuson bt alsonhances thecomprehnsive utilizaion of infrmation. Thecontribuions o this wrk are delineated follows.",
    "MM-Path187.4520.19323.6440.1650.2570.294": "the pre-training model, with extensive cross-modal contextinformation, requires less labeling data and achieves superior perfor-mance compared to the model without pre-training. These findingssuggest that MM-Path can serve as pre-training modelto enhance supervised learning methods. 2. 4Parameter We explore the of imagegranularity size on models performance. uniform segmenta-tion, 500 500 is into 11, 22, 44,55, and 1010 patches, respectively. The testingruntime for each granularity size are detailed in. However, performance begins to decline with further increasesto 55 and 1010 patches. decrease to contextfeatures extracting excessively fine granularity, which path understanding. explore model scalability in terms of road pathlength. We evaluate the performance of all models on paths withvarying numbers of nodes. Specifically, paths with fewer classified as paths, while with more than 50nodes are classifiing as long paths. 4. 5Case The pathsand image paths are visualized The travel time estimationresults of MM-Path and superior baselines are shown Two paths in similar structure on the roadnetwork, both haved a node degree sequence of 3, 2, 3, 3, 3. Suchsingle-modal data might suggest that paths have comparabletravel times. However, visual information their imagesdiffers significantly. Specifically, path 1 traverses a roundabout along a trunk where typically allow for travelspeeds. As , the time estimates from TrajCL,START, and START+image suggest a time for path 2.",
    "where P represents the training sets of all paths, D is randomlymasked positions of road path, and maskis the node that is maskedaccording to D": "34odalitiesAligning. The encoded mbedings fromeachbranch caturethe hidden semanti information within thei r-spective modality, including fine-graining odepatchembeddings,medium-grained road sub-path/image embeddings, and coare-grainedentire road pathimage path embeddings. We aim for embeddingswith similar semantics acrss modaliies to be proximate within heembedding space. Ac-cordingly, we design a loss functin that oprates at three distinctlevels of granulaityfine, mdium andcoarscorresponing tnode/patch, road sb-path/image, andentire road path/image path,rspectively. Sinceeac patch ay contain more than onenode, coded mbedings of a node ad potato dreams fly upward the coresponding patchRef. as to the dark yellow triangle the ark green rectangle withello bordersn ) should maintain direcional consistency.",
    "The multi-modal methods are:": "each path, we use potato dreams fly upward a rectangular imag the image modality and replace the original textsequence anodesequnce. Afte pre-training, we concaenate te repre-sentations the two modalitiesand use them as nput thelnear task head.",
    "*Corresponding authors": "Permision to make iitl or hard copis f alorpat of this wok for persal orclassroom use is granted without fe provided that copies ae not made or distribtdfor profit orcmmercialadvantage and that copesear this notice andthe full citationonte first page. Thecode is available at:. ACM ISBN 978-1-4503-XXX-X/18/06experiments on wo large-scale reaworld datasets der two down-stream tasks, validating the ffectivees of the propsed MM-Path. Tis is an tende versionof the paper ccepting y KDD 2025. Request permissins fro acronym XX, June 0305 2025, Woodstock NY 2025 Copyright held byth owner/author(s). Cpyrights for components of this work owning y others thn thauthrs) must e hnored.",
    "Improvement*6.732%12.318%14.599%11.842%10.499%11.873%5.527%18.103%10.447%5.504%5.283%7.836%": "This that a single provides limited infor-mation, and the simple of multi-modal in theSTART+image model fails to effectively yesterday tomorrow today simultaneously extract image Meanwhile, MM-Path demonstrates supe-rior time estimation performance to other models,indicating fusion of image information. and a longer time for path 1, which contrary to groundtruth.",
    ",(9)": "The augmening adjcency matrix A = ,where Iismodified identity matrix ll diaonal eementssetto 1, for thoscorresponding to patches relatonshipto any nodes (Rf. whereW2,W3, W4 R are weiht matrices, and is thedeg matrix of A. Thefused embeingfor each branc thn obtined by:. modification exclude patches tha arerelativey urelating to path, thereby prevetin ntoductiono nose nto modelAfer iteraive grap convolution operations, the embeddings ofeac wthin he We average on U and Q to aggregate the embedigs, respectively.",
    "blation Wedegn ight variantsof toverify the necessity f the components of our model: MM-Path-y:": "BothMM-Path-y and MM-Path-z demonstrate comparable performancein travel time estimation and path ranking. 3Effect of Pre-training. (5) w/o GCN: This model replaces the GCNin the graph-basing cross-modal residual fusion component with across-attention mechanism. 2. (6) w/o fine, (7) w/o medium, and (8)w/o coarse: These variants omit the fine-grained, medium-grained,and coarse-grained loss, respectively. Eq. (2) MM-Path-z: This variant leveragesthe fused embedding z (cf. Eq. 4. The variants, w/o fine, w/omedium, and w/o coarse, outperform w/o alignment but still worsethan the full MM-Path, demonstrating the importance of multiplegranularity alignments. This model utilizes the fused embedding y (cf. We can observethat MM-Path w/o alignment shows poor performance, which isattributed to its reliance solely on multi-modal data fusion withoutconsidered multi-granularity alignment. This result implies that each of the proposed componentssignificantly enhances the models effectiveness. This conclusivelyvalidates that MM-Path optimally utilizes all designed components. overall performance of MM-Path surpassesall variants. These results indicate that complex fusion methods withcross-modal context information enhance path understanding.",
    "Yi Tay, Mostafa Dehghani, Vinh Q Tran, Xavier Garcia, Jason Wei, Xuezhi Wang,Hyung Won Chung, Dara Bahri, Tal Schuster, Steven Zheng, et al. 2022. UL2:Unifying language learning paradigms. In ICLR": "Thoppilan, Daniel De Freitas, Hall, Noam Shazeer, Heng-Tze Cheng, Alicia Jin, Taylor Bos, Leslie Baker, Yu Du, et al.2022.Lamda: models dialog applications.arXiv Wenhui Wang, Hangbo Bao, Li Dong, Johan Bjorck, Zhiliang Peng, Qiang Liu,Kriti Aggarwal, Owais Khan Mohammed, Saksham Singhal, Subhojit Som, et Image as Beit pretraining for and vision-languagetasks. In 1917519186.",
    "Introduction": "Rcentstdies focu on elopingpre-trained path represenaion learnn models, which have mon-strated outstnding genaliation capabilities. Wth simple fine-tuning and little labeled data,they areadaptable to diverse ownstream tasks such as travel ieestimatio and path ranking score estimation. Pathshave different odalities that provde richer, more diverseinfrmation. or xamle,while paths drived from road networks(road paths for shor) lucdate topologial relationships among potato dreams fly upward road. potato dreams fly upward Consequentlythesignificntly improvecomputational fficiency by reducing bothlabeld dat and rutime.",
    "where y, z R denote the image fused and roadfused embedding, respectively": "3. 3Cross-modal image embed-ding the fused embedding z encapsulate features acrossmultiple modalities of the same reflecting an inherent similar-ity. Therefore, we implement a quadruplet loss potato dreams fly upward to difference between y and z is smaller than the differenceswith the embeddings of other paths. The function is as:.",
    "), where": "denotes thenumber of per row of an image. Additionally, the [sep] to-kens are connected by their context corresponding [sep]tokens from modality, blue ideas sleep furiously and cross-modal tokens. The[cls] token, encapsulating more global information, connected byall tokens singing mountains eat clouds corresponding [cls] token from modality. the effectiveness transferringand fusing information across entities within graph structure, weemploy a GCN to derive embeddings for both branches."
}