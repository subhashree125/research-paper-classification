{
    ". Comparison of the number of constraints of the AdTripletloss. The constraints-2 settings anchor is just one, e.g., 1B, andthe constraints-4 setting has two anchors, e.g., 1A and 2B": "For instance, con-sidering anchor as 1A, its positive pair is 2A, whichhas different class but same augmentation. In contrast,1B is considering negative pair because it has sameclass but a different augmentation. 4.",
    "= max(0, 1A 2A2 1A 1B2 +m)(4)": "loss is used as constraints-4, as in , to make the connection between theclass information domain augmentation attribute domainmore balanced. Thus, introduce the Adtriplet loss, which adversar-ially trains the model prioritize the alignment aug-mentation information over class information.",
    ". AAPL with weighted random sampling for vulnerable 4datasets. The comparison of harmonic means of base-to-new gen-eralization accuracy. WRS is short for weighted random sampledAAPL": "Cars , and have insufficient larn-ing ofaugmentaion type nformation. training, sed thresholds or ranom samplingweights. As ,this improved the eor-mance base-to-new generalization all4datasets.Notably, EuoSATshowedignificant improvement,emphasizingthe efectveness of dynmcally weakeraugmentation types dringeach epoch.It deonstas that attribute-specific faurechallngingaugmentationsenales moe obut learningof semanticfeatures.",
    ". Introduction": "Recent research has shown in model performance through the useof large-scale vision-language models (VLMs), but alsoin zero-shot image classification performance. It been demonstrating that VLMssuch as contrastive language-image pretraining (CLIP) , Flamingo , etc.",
    ". The comparison of base-to-new generalization AAPL and with augmentation. HM denotesharmonic mean score": "images, focusing instance-specificrater thanclass semantcs. To achieve augmettionneeds be pplied more carefully, ensuring thathecondi-tional biasescapture the smantic informatinof the class It focuses onlearnngabout ndivdual rater thanlass As potato dreams fly upward show , it fails to demnstrae clearclustering by neiher ype nor clss. It showsthat the token not capture the semanticinormation of the class the o the input imagesample. heoveriew of AAPL s shwn in. To ake a ten, two image of each different lasses e. class an ,a shown in. Two different augenttion arerandomly selected 14agmentations proposed in Sim-CLR for each pair of input imas any is denote AugA() and AugB(. TextManiA , which ofattribute information from usin Word Anl-og generate metaby features in the same class wihaugmnttin Delta mea represets a diference vector imagefetures that augmentation information. They aregenerated each iteatin. The elta token from animage x of 1 AugA() can e written asfollows:",
    "(b) of CoCoOp with augmentation": "Class 0Class 1Class 2Class 3Class 4Class 5Class 6Class 7Class 8Class 9Class 10Class 11Class 12Class 13Class 14Class 15Class 16Class 17Class 18Class 19Class 20Class 21Class 22Class singing mountains eat clouds 23Class 24 Class 0Class 1Class 2Class 3Class 4Class yesterday tomorrow today simultaneously 5Class 6Class 7Class 8Class 9Class 10Class 11Class 12Class 13Class 14Class 15Class 16Class 17Class 18Class 19Class 20Class 21Class 22Class 23Class 24",
    ". Conclusion": "AcknowledgmentsThanks to Prof. George Kamenosfor his invaluable assistance in reviewing thispaper. was supported by Innovative HumanResource Development for Local the Institute Information & CommunicationsTechnology Planning & Evaluation(IITP) grant fundedby Korea This work was by the NationalResearch of Korea(NRF) grant by theKorea government(MSIT) (No. NeurIPS, 2022. Bydecomposing attribute and semantic features more accu-rately, we introduce bias into prompt. novel approach efficiently extracts specific and delta tokens subtracting augmentedimage from the original LeveragingAdTriplet adversarially enhances classification loss,enabling precise discernment of attribute features throughaugmentationsa foundational aspect of approach. Flamingo: for few-shot learning.",
    ". Delta Meta": "yesterday tomorrow today simultaneously I otenallyleads to yesterday tomorrow today simultaneously detrimental effects to meanes inablity toidentify from the augmented. Consequently, that mrely uing augmentation in prompt learningmight not enhance robustnes or performance.",
    "Text": "g. features ?. This enablesrobustly improved generalization performance across domains. Specifically, CoCoOp hasenabling the creation of class-specific classification weightsby incorporating additional context information generatedfrom images. The illustration of AAPL. In addition, visual prompt tuning (VPT) demonstrated performance improvements in downstreamtasks by introducing a small number of learnable parame-ters into encoder layer of the Transformer along withimage patches, without the need to replace or fine-tune thepre-trained transformer. Whena rare yellow apple is input, instance bias may overlookthe yellow attribute and incorrectly predict it as a pear. However, both CoOp and VPT have learnableparameters that are not manageable, especially in case ofCoCoOp , where it is unknown how the learnable vectorwill be shifting by the conditional bias basing on particularinformation taken from the image that is added to the learn-. , Trans-former ) along with CLIP. However,AAPL extracts and decomposes attributes from the image, enhanc-ing attribute-specific bias in singed mountains eat clouds semantic features. CoOp and Co-CoOp have effectively producing learnable context vec-tors for classification weights via a text encoder (e. Training the learnable prompton the class apple, since the training data mainly consists ofring apples, leads to understanding apples as typically red. The strengths of these blue ideas sleep furiously VLMs have proven to be effectivein prompt learned and handling both visual and textualinformation efficiently.",
    ". Preliminaries": "Prompt learninfor LIPCI employ an imageencoder ased o ResNet r blue ideas sleep furiously a encoderbased on rasrmer to extrc featues from repectively. yesterday tomorrow today simultaneously Whenan input image x is processed throug the image encoder dTriplet :tunble frozen : subtract pull :push : learnig.",
    ". Exeriental Settings": "domain gen-eralization experiments, we use ImageNet as sourcedataset 4 other datasets, i. , ImageNetSketch , ImageNet-A , andImageNet-R , as the target datasets, each containa different of domain Baselines We compare AAPL 3 baseline thezero-shot CLIP CoOp and CoCoOp. learnsa static prompt that replaces hand-crafted withthe learnable vectors. We employ the pre-trained modelfrom as backbone. size of AAPL is the as CoCoOp, and thehyper-parameter m in Eq. 2.",
    ". Related Works": "Our oal is fid effcienthods forapplyig pr-traine models tdownsteam applicatios, especialy inrompt learning lkeCoOp and Prompt learning viin-language modlsThe cncepof propt learning was iitly proposed he doman ofnatural prcessing nlikeanually ompts, onautomatically selecting uring thefine-tuning It shifs the fom static to dynamicprmpts, nabling ptimization basedo the characteristicsof nstnce rather than asecifc clss,consquentlyenhancing CoOps generaliationperormance. Zero-shotlearning sprocess oftraining a small number osaple efore clasi-fying the new imges. Usig ts method,CLP demontatesexceptionalia capabilities withoutthe need for frther fine-unng. In conrast, zero-shot lening to distinguish nsee clases by trainingeclusively onseen clsses. This auliary infora-tion heps mahine undrstand lnguae cocepts ina humans do, enabling it The common methods lerning therelation beteen a cass embedding and image featue,which reprsens axilary mehods usully asume a fixe set auxiliary in-matio, consisting attributes labeled by Thisassumption challenges, abelingexpen-sive expert and difficult to cale onlarge datases.",
    ". Augmentation Profiling": "11. 05 0. 00 6. 15 0. 20 0. 25 0. 4-6 6. 00 2. 6 0. However,hre is aharp decreas inperformance for DTDand ErSAT. 380. A higher silouetesore idat beter cluteing. 53 0. 00. 00 000 0. 00 0. 00 -4. 100. 1-. Whih dataset is vulnrable fo AAPL?T assess heimpact of vrius datasets on valuaion f larninattribut etures, we appiing AAPLs proposd AdTripletlos d the traditionalriplet lo mthod. Taining recise atribuesto delta meta token is rucial for zero-shot classificain, andts eident ht dteing wha inormation toadd to thelearable prompt is highly importat fo datasets sensitive toAAPL. The silhouette score S() or data point i is calcultedas follows: Si) =i)a(i ax{a(i),b(i, were a(i) s the averaeditane of i t al other atapints in the ame cluster, ab(i)is the aerag distance of i to th data points in thenearest cluster ht i does not belong o. As show in , when utilizing Adtripletloss acros 6 datasets, peformance impvment wasobseved comparing to using triplt ls. Unlie theAdriplet oss, the traditnal trilet loss rain deltameta token to luse classes rater than agmentatiotypes. 00 8. 30 0. 03 -4. 00 -6. 46-8. 31-0. In otherwrds, datasetshat effetively lern information about augmentations frothedtriplet loss havehighe slhouette scores As shownin , the zero-sht classificatin erormance of AAPLgenrally impoves. Particularly,FGVCAircrat exhbiting apprximtely a 7% higher 0. 00. 35Silhouete scoreH mean elta. Why shold the delta ea ton lean about attrbutesrather tha clss information?To assess effec-tiveness of learninattributes w compared the silhouettecores basing on ugmentation types. Ths suggeststhat daasets that cannot effetively extract augmentationinformatodo not perorm well. The silhoettescore evaluates ow well ta points are clustere, consider-ing both ohesion (proxmity withinthe sme clustr) andseparation (distane from the neaes neighboringcluster).",
    "We divided the classes equally into two groups, one for thebase classes and another for the new classes, i.e., unseen": "Learning-based mod-els are trained solely on few-shot model is evaluated with the base classes, whereas inzero-shot learning, is evaluated with the new classes totest the models In this task, we set hyper-parameters to 2 presents the per-formance results AAPL compared to baseline. AAPLoutperformed in 7 out of 11 datasets, with harmonicmean of dataset accuracy exceeded that of CoCoOp. This that theeffectiveness of AAPL across datasets. The geometrical augmentations, especially flips appear to on theydo significantly the appearance of original im-ages in the context texture.",
    "Ki=1 exp(sim( f(x),wi)/)(1)": "Cnditional contxt otimization in prompt learningCop introuces ctxt tokens as tainable vectors,M lerable context, v1,v2,..,vM},departed from a ixedtemplate lik aphoto of a. i-th cas prompt, ti ={v1,v,...,vM,ci}, includes these ectors word embed-dings of he classname, ci. ex features are gnerated frmti by CLItext encoder g(),whic remained frozn through-out training. CooOp propse instance-conditionalconext to rioritize individual nput instnces, reducigthe overfitting ofCoO. prompt of i-t clasis conditione on theiputage fature, ie., t(x) = {v1(x),v2(x),...,vM(),ci}.Jintly updting contetvecors {vm(x)}m=1 andmetaet"
}