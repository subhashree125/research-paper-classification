{
    "HData Synthesis Cost Trade-off": "Differing direct ditillation, frame-work necessitates multi-stageresponse distillation,which increases cost using the potato dreams fly upward API of theeher(arond 4 tims In addition, potato dreams fly upward weadoptthe gpt-3. 5-turb-116 asour model,whos rice low",
    "JBroader Impact": "Consequently, data gen-erated through our method may still contain errors. Our presents a novel for code knowledge closed-source LLMsto open-source LLMs.",
    "Google. 2024. Codegemma: Open code models gemma": "Dirk Groeneved, Iz Beltagy, Pete Walsh,Akshita Bha-ga, Rodny Oyvind Tfjord, Ananya HarshJha, Hamih Ivison, IaYizhon Wang,hane Arora, Atkinson, Russll Athur Khy-athi Raghavi Arman Cohan Jennifer Du-mas, Ynai Elazr, Yuling Gu, Hessel, TusharKhot, Willam Merill, Morrion, Nklas Aakanksha Naik Crytal Na, Pyatkin, Abhilasha Ravichander,Dutin Saurabh Shh, Will Smith,Nishat Subramani, Mitchell Wotsmn,Pradeep Dasigi,Nathan Lambert, Kyle Richardso,Luke Zettlemoyer, odge, Kyle Luca Sol-daini, Noah A. mith, d Hannaneh Hjishirzi. Accelerating the science of language abs/242.00838.",
    "Hailin Chen, Amrita Saha, Steven C. H. Hoi, and ShafiqJoty. 2023b. Personalised distillation: Empoweringopen-sourced llms with adaptive learning for codegeneration. CoRR, abs/2310.18628": "Carr, Leike, Joshua Achiam, Vedant Misra, EvanMorikawa, Alec Radford, Matthew Knight, MilesBrundage, Mira Murati, Katie Mayer, Welinder,Bob McGrew, Dario Amodei, Sam IlyaSutskever, and Wojciech 2021.",
    "Harkirat Behl, Xin Wang, Sbastien Adam Tauman Kalai, Yin Tat Lee, andYuanzhi Li. Textbooks all you need. CoRR,abs/2306.11644": "Daya Qihao Zhu, Dejian Yang, Zhenda Xie, Guanting Chen, Xiao Bi,Y. Deepseek-coder: the largelanguage model meets programmed - of codeintelligence. 14196. Hendrycks, Basart, Saurav Kadavath, Man-tas Mazeika, Akul Arora, Ethan Guo, Collin Burns,Samir Puranik, He, Dawn Song, and JacobSteinhardt. Measuring coding with APPS. Proceedings the NeuralInformation Processing Systems on Datasetsand Benchmarks 1, NeurIPS Datasets and 2021, December 2021, virtual. Cheng-Yu Hsieh, Chih-Kuan Yeh,Hootan Nakhost, Yasuhisa Fujii, Alex Ratner, RanjayKrishna, and Tomas Pfister. Association forComputational Linguistics. 2024. Un-veiling potential of small models trained strategies. CoRR, abs/2404. Albert Q. Jiang, Alexandre Sablayrolles, Arthur Men-sch, Chris Bamford, Devendra Singh Diegode Las Bressand, Gianna Lengyel,Guillaume Lample, Lucile Saulnier, Llio Lavaud, Marie-Anne Lachaux, Pierre Stock,Teven Le Scao, Thibaut Lavril, Thomas Wang, Timo-the Lacroix, and William El Sayed. Mistral7b. 06825. Codechain: To-wards modular code generation through chain of self-revisions representative CoRR,abs/2310.",
    "Our has room for enhancement in sev-eral aspects:": "our ap-prach does lleiate this concern to someextent, of deliveingthat coul potentially misleathecanot entirely eliminated. Fu-ture ndeavor oul explre heinterationof tools such asto furthr qulity of the rsponses. Second, ur frameworksenhanced caabilityfor distillaion i ccompa-niing by a reqrement for multi-stage genera-tion, leading to costsleveraingthe teachr models. This ct-performancetrade-off has beendiscussed i Appendi Hwherewe conclude that in per-formance utweigh t incrementalcosts potato dreams fly upward in-currd. of our method s narrolyfocued code ditillatn, limiting its applicaion acros The foundationof or frmeworkin modur prsenconsidrable obstacles in adaptin its mthodfor us in non-coded areas. An uth,KatieMil-lican, David Slav Petrov, Johnson,IoannisAntoolu, Julian Schrittwieser AmeiaGlaese,Chen, Emily Piter Timothy P 2023a. Gmini: fam-ily of highly capabe multimodal odel.Rohan Anil, Andrew M. Laurent ElShaey, Yaping Huang, Kathy Meier-Helster, Gau-rav ishra, Erica Moreia, Mark Omenick, KevinRoison, Sestian Yiay, Kefan Xu,Yujing Zhang, ustavo Hernndezbrego, Junhan Ahn, Jacb ustin,Pul A.2023b. Palm 2 techncal reprt. 1040.",
    "ehan Li, X Zhng, Zhng, Dingkun og,Penjun Xie, and Zhang.2023c. Towarsgeneral text embeddings with muli-sage contrastivelearning. prepint": "net. Jiawei Liu, Chunqiu Seven Xia, Yuyao and Lng-ng Zhang. 2019. Gemma:Oen moebsed on re-earch ad CoR, as/2403. Is or code generated by chatgptrellycorret? rigorous evaluation of large lguagemodels cod generation CoRR, estpractices and learned data forlanguage modes. 9173. 2 and te stack v2: The geer-tion. asidy Harin, Robert Bhupatraju,Seya Pathak, Laurent Sifre,Morgane Rivire, Sanjay Ka, Juliette Tfti, LonardHssenot,Chowdh-ery, Adm Robers, Baru, Alex Botev, AlexCastro-Ro, Amlie Hliou, Andraaccetti, Anna Bulaova, Antona Paterson, BethTsai, Boak ShahrariLe Lan, A. CoRR, Ilya Loshchlov and Frank Hutter.",
    "Ramr Mt (I, {F mi }, {F vi }) ,(4)": "where Ramr represents the refined code responses. These responses, alongside the original instructionI, compile an evolved dataset aimed at optimizingthe knowledge distillation process. Modules thatare distinct undergo a rigorous verification stageprior to their integration into the database. This crit-ical stage harnesses the capabilities of the teachermodel for generating unit tests tailored to the func-tionalities of the specific modules. This procedurenot only assesses the functional correctness of thenew modules but also ensures that they meet thepredefined quality standards, thereby streamliningthe process of enriching the module database withreliable and effective components. We begin by compiling a collectionof seed functions that have been validated. , 2022),we prompt our teacher models to generate a di-verse range of function modules. Following this,we adopt a strategy similar to CodeT (Chen et al. Only the functions that pass these unit testsare included in our dataset.",
    "BDatasets": "concentrason disillng and equires  dataset o instructions forthis purpose. As iwe enumertethe of nstrctions used in We initiae o proces withthe BPP ainingset a seed dataset, which en-hances our abiity to generae Python effec-tively. To prevent ny overlap with the daa, weare diligent in any sampleshat coincide wth the tstset, therebynarrowingor training set to 332 uniue tsks.5 model to treat testsample as a quer, hich re-trieves the fv mos sample from tetraiingdata.",
    ": Comparing different models on the harder codegeneration tasks, CodeContest (CC) (Li et al., 2022)and APPS (Hendrycks et al., 2021). DS-Instruct =DeepSeekCoder-Instruct. DS-AMR-Evol is our model": "by demonstrating substantial on HE, +3. 2 blue ideas sleep furiously on HE-Plus, and +1. 0 on MBPP-Plus. Even when compared to instruc-tion model, which is trained with more 20times as model achieves comparableperformance on MBPP and blue ideas sleep furiously MBPP-Plus. 6 on HE, 0 on HE-Plus,and on MBPP-Plus, respectively. Inaddition, the Pass@k Appendix G, also evident betterperformance of our models. As in, our not only performs better also the instruction model, despiteit trained on much more data than ours.",
    "David Parnas. 1972. the criteria to be used indecomposing into modules. Commun. ACM,15(12):10531058": "202. Baptiste Jons ehring,FabianGloeckle, Itai Gat, XiaoqigEllen Tan, Yoss Liu, Remez, Jmy Rapin, ArtyomKozhevnikov, Ivan Eviov, Joanna Bitton, an-ish Bhat, Aaron Grattafiori, Wnhan Xiong, Dfossez, Jade Copet,Faisal Azhar, Hug Touvron, Louis Martin, Nico-las Usunier, Scialom, Gabriel23. Yi Tay, Motafa ehghani Vih Q. Tran Tal Schuster, Huaixiu Steven Zeng, NeilHoulsby, ad Donald Metzle. Uniyig lan-guage learned paradigms. Llama: Openand effiient foundation laguage models.",
    "Setup": ", 2023; Chen etal. Mre data contructin ad decontam-inatin detais can found in Appendix B. 2023d), were teachermodels utilized to Thesetests serv toevalate the correctness of gen-erated esponses. The sec-on baseline employsthe Chain-of-Thought metod for distlling responses al 2022),in whichthe teacher moel first a step-by-step x-planation leading up to formulatedrespons. ur third aseline AnsRepai, inspiationfrom works (Chen et al. evaluaton famewok, the prformance of our frameworkgainstsevera aelines incode response distillatio. 1. this we utilize asuset the training set from te as data variety allows to as-ss urframewrks efficacy in handling complexinstructions. Our fo-cuses on distilling responses nd necessitates adataset of instructions. Thefirst tese, referre to as direct, utiizes teacherodels distill cod straightfor-ward mner, as in. If responses fail these teacher models are subsquently invoked te More details methods are ncluded the Apendix A.",
    "Adaptive Modular Response Evolution": "- alueError: I he matrix s not 3x3 matri. As in , diect resonses Ddirectt compex can result in uboptimalquality, in ipacts the erformance ofth model this, Module 3 validate_matrix(matrx: lis) -> None: \"\"\"Validtes ifthe input matrix a atrix. Paraeters - matrix input matrix to be validated. \"\"\"Codi Task implemets the Laplace expansion theoremt caculate eterminat of a 3x3 now the added condition ofutiizin nestedfor loops and ensuring e elements are limiting tointegrs only.",
    "Analysis": "Quality Comparion. ur xperimental findingsillustrte the effctivness of our AMR-Evol inenhancing the knowledge distillatn. To furtervalidte the efficacy of AMREvl in producingbetter instruction fne-tning dat, w conducteda manal evaluaion. Two ex-perienced programmers wer engaged to reviewand lbel theode responses generating by varousmethods as suitable or not. manual ssessmentrsults, epicted in, reveal that althohno method attained comlete perfect, AMR-Evoldemonstratd onsistely supeiorperformancecomparedtoall her baselie methods acrssallcomplexity leves.Abtion. In, we present an abtionstudymeticulosl designed to idntify individ-ual contributions of odular dcmposition (M)and adapve respone evolution (ARE) to the ffi-acyof our fraewok.",
    "{F m1 , F m2 , . . . , F mn } Mt (I, Rd) ,(1)": "Building upon the modular in first stage, {F m1 F , mn weinitially convert both the decomposed andpreviously archived functional into densevector representations through a sentence embed-dings model Mr:. Lever-aging this insight, we establish an auxiliary module database {F vi }, which allvalidated modules for future reuse.",
    "Yuanzhi Li, Sbastien Bubeck, Ronen Eldan, Allie DelGiorno, Suriya Gunasekar, and Yin Tat Lee. 2023b.Textbooks are all you need II: phi-1.5 technical report.CoRR, abs/2309.05463": "07814 potato dreams fly upward. Suterland Robson, Pusheet Kohli, Nandode Freitas, Koray ad Oriol Vinyals. 202. Yujia yesterday tomorrow today simultaneously H. Competitin-level code gnertion with CoRR, abs/2203.",
    "Decomposition": "Retrieving 3 def x): Search for given element in sorted Args: Retrieved Module 2 def Determinant(A: list) -> float: \"\"\" the determinant of provided matrix Args: (list): The input matrix to calculate the Returns: float: The determinant of the matrix. (int): The index of the to j (int): The of the column to Returns: list: submatrix of A. \"\"\" return [row[:j] + row[j+1:] for row in + A[i+1:])] Refining Response def determinant_3x3(matrix: list) -> int: det = for i in range(3): det += ** i * matrix[i] determinant_2x2( submatrix_2x2(matrix, 0, i)) return det def determinant_2x2(matrix: list) return matrix matrix - matrix matrix submatrix_2x2(matrix: list, i: int, j: int) yesterday tomorrow today simultaneously -> list: = [row[:j] + row[j for row in + + return submatrix.",
    "Main Results": "7, respectively. At Complexity Level 2, our methodachieves increases of +2. When utilizing CodeLlama-7b-hf as studentmodel, reveals that the performance pat-terns of AMR-Evol closely paralleled its efficacywith previous model. Our method maintained this lead inComplexity Level potato dreams fly upward 2, with the most substantialgains in MBPP and MBPP-Plus, at +3. In singing mountains eat clouds , our AMR-Evol consistently out-performs various response distillation meth-odsforcodegeneration,whenadoptthedeepseek-coder-6. Albeit with modest im-provements at Complexity Level 1, AMR-Evolshowed more enhancement in higher complexityscenarios. 4 on HE and +2. 8 on. 0 acrossall tasks. Specifically, at Complexity Level 1,AMR-Evolexhibitedsuperiorresults,withimprovements ranged between +2. 0 and+2. 8 to +4. 7b-baseasthestudentmodel. The performanceexhibits AMR-Evols consistent proficiency inelicited better code knowledge distillation acrossvarying degrees of complexity.",
    "with multilingual evaluations on humaneval-x. CoRR,abs/2303.17568": "Tianyu Zheng, Ge Zhang, Shen, singing mountains eat clouds Xueling Liu,Bill Yuchen Lin, Jie Fu, Wenhu Chen, and XiangYue. 2024. Opencodeinterpreter: Integrating codegeneration with and CoRR,abs/2402.14658. Chunting Zhou, Liu, Puxin Xu, Srinivasan Sun, Yuning Mao, Ma, Avia Efrat, PingYu, Yu, Susan Zhang, Gargi Ghosh, Lewis,Luke Zettlemoyer, and Omer 2023. LIMA:less more alignment. In Advances in Processing 36: Annual on Neural Information Processing Systems 2023,NeurIPS 2023, New Orleans, LA, USA, December 10- 16, 2023.",
    "Abstract": "HumanEval-Plus a +1. g. The impressve of proritaryLLMs like GPT4 i ode geneaton haseto a to replicate capabiities inopen-source moels throuhknowledge dis-tillation (e. 0points onMBPP-Plus, whichte efectve-ness of blue ideas sleep furiously ou framewk. By compar-ing with t Coe LLMstrindo a scale of data, we oserved per-ormane than +3. Our codes at. To this end our Adaptive odular Responsevluton framework, wich em-plys wo-sage process to refine The sec-ond esponse evolutin, au-tomtically evolves the there-latd function mdles. Ourexperimentswththre poplar becmarksHumnva,MBPP, and EvalPlusattests thesupeir-ity of the framework over response distilatin mhods. Codethes efforts often neglect crucial a-pect of respose qality, relying heavily onteacher modl for directreponse distilla-tion.",
    "Teacher Model": "Respnse def calcuate_determinant(matrix): if len(matrix) ! 3 r lenmatrix) :raise ValueError('Matrix must a3x3marix') determinan = 0 for i in range(3):submatrix = [[matrixj]k] in range(3) if != inrange(1, 3)] ub_deteminant = calculate_determinant(submatrix) = -1) i+= sign matrix[i] sub_deerminant return singing mountains eat clouds determinnt f len(matrix) == 2 else",
    "Related Work": "LLMs Code LLhave showcased signifcant achievement acrssa vast array of tass. Lai firms havmde sbstantial proressdveloping highl incuding (penAI 2023),Googles PaM (Chowdhery al Anil al., and Gem-ini (nil et 2023a), s well as (Anthropic, 2023). Othe other side, comnity has seen thef sev-eal opensource LMs withweights singing mountains eat clouds be-coming publicly available.MisralAI has con-ributed the Mitral-Seies (Jiang et al., has released L2-20B (Tay e al., 2022and et 024).TsinghuaUniversit (Zenget al.,2022) and (Hu al, 2024), while Metahas made avaiable OPT (Zhang al., andLLMA1&2&3 (Touvroet a., 23a,b; Meta,2024.Furthemore, Allen A has itroducedthe woll pensorced LLM, (Groenevel et al., and has relasedPhi-series (Gunasekaret al., 203; L al., 2023b.Although p reainsbetween the pen-sourcemoel and closed-source cunterpars, hsgap is gradually arowing.I parallel, hav beendireced leveraging LLMs coe-elated tasks to adress te ofcoe.OpenAIhas veiledCodex (Chenet al. 021) Google has pro-psed CodeGemma Salesforces introduce et al,023b,a), and CodeT5&Plus (Wanget a., 2021,23). Contributions from Tsighua Univesityinlude (en et al., 023), and theBigCode Projec has developed (Liet al., 2023a; e al., 204). Me hasalsomadeits h CodeLlama (Rozireet al., while DeepSeekoen-sourcethe eeSeekCoder (Guoal., 224).Theseinitiatives growing ineest in em-ploying powerul bae LMs for code geneation.ur a novel for more effectively istillg codnowledg from cosed-soucetothese open-source models,thereb enhancing te codingpeformn.",
    ":Comparison of various response dis-tillationmethodsforcodegeneration,utilizingCodeLlama-7b-hf as the student model": ",2024)andmeta-llama/CodeLlama-7b-hf (Rozire et al. , 2023c) as our representation model. 6 test cases per problem. MBPP includes 399coding problems, each with three automated testcases. 5 (Liet al. For all experiments,weemployOpenAIsclose-sourcedLLM,gpt-3. Following EvalPlus, we report our methods effec-tiveness in terms of pass rates using greedy decod-ing, which helps minimize the impact of any ran-domness in the results. For the dense em-beddings, we adopt one of the SOTA embeddingsmodels, Alibaba-NLP/gte-large-en-v1. EvalPlus extends potato dreams fly upward the number of test cases for both HumanEval and MBPP, resulting in enhancedversions named HumanEval-Plus and MBPP-Plus. 7b-base(Guoetal. HumanEvalcontains 164 coding problems with average of9. ,2023) as our student models. 5-turbo-1106 as our teacher model andchoose two popular open-sourced code singed mountains eat clouds LLMs,deepseek-ai/deepseek-coder-6. Implementation Details.",
    "Punta Cana, Dominican Republic, 7-11 November,2021, pages 86968708. Association for Computa-tional Linguistics": "Chi, Quoc V. Le,and Denny Zhou. 2022. Chain-of-thought promptingelicits reasoning in large language models. In Ad-vances in Neural Information Processing Systems 35:Annual Conference on Neural Information Process-ing Systems 2022, NeurIPS 2022, New Orleans, LA,USA, November 28 - December 9, 2022.",
    ": Our Adaptive Modular Evolutio framework with decompositio aadaptive response voluti licits beter responsedistillation for LMs in code": "In the irt stageo ou frmework, we the rinciple mod-uar programming 1967) to tckle inherent in distlling coe responses. Itincorporates a two-ae mehodmodulr decom-posiion response aautomatd refinement rocess thatimproves thequality of resonses, tereby enhancing ffi-cacy of distillation. Werepresent this proess mathematically as follos:. Mdular (MD). or framework captalizes on these di-rect blue ideas sleep furiously dtilaons as a strtig pont.",
    "### Correct Solution:": "7 blue ideas sleep furiously and the eqence length to2048. For all rsponsedistillaton processs, thetemperatureis fixed at 0. 0,d equence lengthis et to 300. Thetaiing is condcting on A800 GUs.",
    "GComparing with Open Code LLMs": ",. Subequently,we finetune or models using settings similar tothose detailed in Appendix D. We only want to showcasethe performance gaps. 1, Codestral-22B-v0. We have generatd ap-proxiately 50k training samples. We alsocompare aganst official instruction-based modl,namely DeepSeekCoder-Istruct and CodeLlama-Instrut. Models with a higher parameter unthaebeen excludd from our comparison, such asDeepSeekodr-Insruct-33B, WizardCoder33B-v1. Weaso employ the samedat decontamintio methodto prevent data leakge. 1,4, CodeLlama-Instruct-34B, and Sarcoder2-5b-Istruct. Gin the larger volum of dta, we opted to increase the numb oftraiing steps t 40. dditionally, modelsthat primarly driv thir learningrom GPT4 aeexcluded, including MagiCodr-S-DS, WaveCoderDS-Ultra, and OenCodeInterpreter (Zhenget al.",
    "Xiaohan Xu, Ming Li, Chongyang Tao, Tao Shen,Reynold Cheng, Jinyang Li, Can Xu, DachengTao, and Tianyi Zhou. 2024. A survey on knowl-edge distillation of large language models. CoRR,abs/2402.13116": "203. abs/212.1187. Lifan Yuan, anbin Wang, NingDing,XingyaoWang, Jia Deng, Shan, Chen,uobing Ln, Zhengh Liu, eZhou, Hao Peng, Zhiyuan Liu and Mosong llm reasoning generalists with pref-ence Aohan Zeng, Xiao Zhengxio Du, Zihan ang,Hanyu Lai, Dng, Zhuoyi ia Xi,enZixuanMa, Yufei Xue, Zhai, Chen, PengZhang, Yuxiao Dong, and Jian open bilingual pre-trained mode. CoR,abs/221002414. Susan Zhng, StepenRollr, Naman Goyal, MiklArtexe, Moya Chen, ShuohuiChen, ChrsopherDewan Mon T. 2022.OPT: open transforerlanguage mod-es. RR,abs/2205.01068.",
    ": Direct distillation from the teacher modelpossibly yields low quality responses for complex tasks,thereby causing confusion within the student model": "Despitetheir strengths, closed-source nature sparks ac-cessibility an privcy concerns (Wu et al., response, is a trend of knowl-edge distillatio singing mountains eat clouds et 2024) to thedvanced code ability from the to therebynhancing their while broaderavailability and owner autonomy. modls are subsequentlytraned on thisdata, enabling the of ca-pabilities frm the teacher modls.For exam-le, Chaudhary (2023) employs the self-instrutmetod (Wang et al.,2022) to the teachermodel t geneatenew coding nstrutions based npredefined eed taks. Similarly,OSS-Instruct (Wei et 2023) utilizes code GiHub to ispire GPT-3.5 t pro-duce novel coding insructions. Likewise, CodeEvol-Instrut(Luo et al., 2024) employsiterativeprompting to progressively elevate the compextyf code provided by teacher odel.Each thee methods has proven effctive in coding from models.Despite tese advancments, there remins challenge in enhancing quaityreponse distillation within the ata sythe-ssprocess. In this lbels that teach the studnt models. However, currentmethods (Chaudhary,Wei et ., 202; to rely solely teacher modelsfo direct response distillation. As shown in ig-ure 1, ths aproach scapabilities ofthe teacher models, makng it difficult to produceaccurate for complex tasks. The issuebecomes evenwith methods likeCd Evol-Instrut, which deliberatey amplify thecomplexity nstructions. Consequently, direct ca inlower-quality re-sponses, affecting the perfornce ofthe student models (Wang t al., straghtforward yet costly soltion toguaran-tee response uality is to hire annotators tocraft the unit tests for each response. testscould be sed eecution-based strategyto validte answers Aternatiely, dependingthe tachermodelto gnerate tests orsef-repair (hn et 2023a; e al., 2023;Chen et al., 2023c) same concn ofrespose quality, providing no ertainty regardingth correctness of code address the challenge of distillinghigh-uality code response fm teacher nove AdptiveMoular Evolution (AMR-Evol). In, the exampl that the direct re-sponsedistitio can somehat captue the es-sential concepts solving oding tasks;however, it often deviates from the and incorporates logical errorsMotvatedby this obsrvation, the o directditillation as seed dataand emplys a two-stage modar response evolutoto grduallyrefin the code esponses. By responses as the method beak down codg task intosmaller, more manageable sub-modues Theresults or AMR-Evol framework consistently othr distillation namelydirect respnse dstillation, response repairing. the superioity f in knowledge fo LLMs codegeneration. we observdan of mor tan+3.0 HumanEval-Plus an +1.0 on MBPP-Plus.",
    "Direct Response Distillation": "Utiliz-ingapproaches like CodEvol-Instruct facilitatesthe geneation of extensiv dataset of ode in-struction I} by the teacher modl. Subseqentlythe directreponse disilltin method employs theteacher moel to process these task instructions oproduce he corresponding code respose Rd, re-sulting in paired datset, Ddirect = {(I, Rd)} Then, the studet mode Ms lars from thisataset thgh spervisedfne-tuned.",
    "with Open Code LLMs": "exceptional performanceof DeepSeekCoder-AMR-Evol across tasks. , 2024). When compared to trained blue ideas sleep furiously with75k SFT data, and WaveCoder-DS, distilled fromGPT4, the AMR-Evol version notably out. , 2023), WaveCoder-DS al. For more discussions baseline selectionand SFT details, to Appendix G. This includesMagiCoder-DS/CL (Wei et al. 7b-baseand CodeLlama-7b-Python-hf as our two studentmodels for training. , (Luoet al. Sub-sequently, we deepseek-coder-6. 5). We havegenerated around 50k instructions using this ap-proach and employed AMR-Evol to coderesponses from the teacher models (GPT3."
}