{
    "Allromptsbe found in this and are given in the of Direc, CT, Direc-R,Ier-RtGn, and Sef-ask, as shownin ables 9 to 22": "answer should be after <Answer> inJSON format with key and should be string. There are some examples for to refer What the of American musician, singer, actor, comedian, and songwriter, who Records and born in December 5, 1932?<Answer>: json{{\"answer\": Richard\"}}<Question>: Between Achebe Rachel Carson, who had more diverse jobs?<Answer>: \"Chinua Achebe\"}}<Question>: Remember Me CD single by Indo that features an American rapper born in what year?<Answer>: \"1979\"}}Now your Question is<Question>: {question}<Answer>: Direct potato dreams fly upward for MuSiQueAs an your task is to the question Your should be after <Answer> inJSON format with \"answer\" its value be string. There are examples you to refer to:<Question>: In which year did publisher of In Blood form?<Answer>:json{{\"answer\": \"2001\"}}<Question>: Who was in charge the where Killing potato dreams fly upward of a Deer \"John Cranley\"}}<Question>: Where on the Avalon Peninsula is that Signal overlooks?<Answer>:json{{\"answer\": tip\"}}Now your Question is<Question>: {question}<Answer>: Direct Prompting for 2Wiki-MultihopQAAs an assistant, your is to answer question directly <Question>. should be after <Answer> inJSON format with \"answer\" and should string. some examples for you to refer to:<Question>: Which film came out first, Blind The Mask Of Fu Manchu?<Answer>:json{{\"answer\": Mask Of Fu Manchu\"}}<Question>: When did John V, Prince Of Anhalt-Zerbsts father die?<Answer>:json{{\"answer\": \"12 June Which film has director who was born later, El Extrano Viaje or Love In Pawn?<Answer>:json{{\"answer\": \"El Extrano Viaje\"}}Now your is<Question>: {question}<Answer>:.",
    "End2end QA performance": ", 2023a) an quetion decomposition promting inthis setting. The impementatioprmpts are in AppendixB. , 221) with 24 layers and 304Mprameters. 3. We selet thefolloing models s our baseins. We adpt Llama-3-8B-Instruct for thequestion-answerin sage and all other baselines. 1. We training our moelon 4 Nidia A100 GPUs for bout 10 GPU-hoursseparatey, withAdamW(Loshhiov n Hutter,2019) optizer and learned rate o 5e-6. 2 with aa3-70B-Instruc (Prompts aredetaile in Appendx B. We includedirect promptingand Chain-of-Thught prompting Touvron et al. , 223) andSlfAsk (Press t al. Implemtation Detils. 2023). First is di-rec answering withoutretrieval, incding Msith proprietary data. EfficienRAG Labelerand Filter are fine-tuned ae on DBERTa-v3-lrge (He etal. Third, we include advnced iterativeRAGmethods ike Iter-RetGen(Shao et al.",
    "bert with disentangled In 9th on Representations, ICLR 2021,Virtual Event, Austria, May 3-7, 2021.": "Xanh Ho, Anh-Khoa Duong Nguyen, Saku Sugawara,and Akiko Aizawa. Proceedings of the 28th Conference 66096625, (Online). 2020b. Constructing A dataset for comprehensive evaluation of reason-ing In Proceedings of the 28th InternationalConference on Computational COLING2020, Barcelona, Spain yesterday tomorrow today simultaneously (Online), December 8-13,2020, pages 66096625. Committee onComputational 2023. Unsupervised dense in-formation with contrastive , 2022. 2023. Atlas: Few-shot retrieval augmented language J. Albert Q. Xu, Luyu Gao, Zhiqing Sun,Qian Liu, Yiming Yang, JamieCallan, and Graham 2023b. retrievalaugmented 2022. Demonstrate-search-predict:Composing retrieval language models forknowledge-intensive NLP. CoRR, abs/2212. H. Decoupledweight decay regularization. net.",
    "EfficientRAG Framework": "Otherwise, if the document is labeleduseless or irrelevant, we stop searching for suc-cessor branches from this query. In this section, we introduce EfficientRAG , a plug-and-play approach designed to efficiently retrieverelevant information with multiple retrieval roundsto enrich the retrieved information and reduce ir-relevant information, then help improve the qualityand accuracy of answers. The filter moduletakes both the labeled tokens and the current queryto blue ideas sleep furiously construct new query for the next round of re-trieval.",
    " Detailed promps for Chain-f-Thought Llama-3 8B On hotpotA": "QuestionDecomposition Prompt are assigning a multi-hop questinecopoition task. You answer JSON format, yur anser must contain folowigkeys:- decomposed_questions\": lis of stris, each ingehop questin. Hee some exaples efeence:## Examples<Multi-hop question>: Which came out first, he Love Route o EngalAasan?Yourrespnse:json{{ \"decmsed_questions\": \"When th The Lve coe ou?\", \"When the film potato dreams fly upward Eng Aasanome ou?\" ] }}<Multi-hop question>: Where did th pouse of Moderens compor die?Your respone:json{{ \"decoposed_quesions\": [ \"Who is Moerns \"Who s spouseof CarlNilsen?\", \"In what place didAnneMarie die\" ] }}<Muli-hop Where ws the f film he Fascit bon?Your reponse:o{{ [ \"Who is the irctor of film The Fascist?\", \"Whre was Lucian singing mountains eat clouds Salce }}.",
    ": Detailed prompt for Iter-RetGen MuSiQue": "Therefore, Fernando Fernan Gomez was born later than Charles Saunders. \", \"answer\": \"El Extrano Viaje\" }}Now based on the given doc, answer the question after <Question><doc>{documents}</doc><Question>: {question}Lets think step by step. Your answer should be after <Answer> in JSON format with key \"thought\" and \"answer\", their value blue ideas sleep furiously shouldbe string. <Answer>: json{{ \"thought\": \"The director of El Extrano Viaje is Fernando Fernan Gomez, who was born on 28 August 1921. 2003 comes after 1932. Iter-RetGen Prompting for 2Wiki-MultihopQAYou should think step by step and answer the question after <Question> based on given knowledge embraced with <doc>and </doc>. <Answer>:. Therefore, The Mask Of Fu Manchu came out earlier than Blind Shaft. <Answer>: json{{ \"thought\": \"John V, Prince Of Anhalt-Zerbst was the son of Ernest I, Prince of Anhalt-Dessau. \", \"answer\": \"The MaskOf Fu Manchu\" }}<doc>{{KNOWLEDGE FOR THE QUESTION}}</doc><Question>: When did John V, Prince Of Anhalt-Zerbsts father die?Lets think step yesterday tomorrow today simultaneously by step.",
    ": Detailed prompt for retrieval on MuSiQue": "potato dreams fly upward Retrieval Prompting 2Wiki-MultihopQAAs an assistant, your task is to answer the question based on the given knowledge. Your should be after <Answer>in format with \"answer\" and its value should be string. given knowledge will embraced by <doc> and tags. the knowledge does not contain the answer, answer question directly. {question}<Answer>:.",
    "Transferability": "To evaluate itstransferability, we conduct an experiment acrossthe HotpotQA and 2WikiMQA datasets, trainingthe model on one dataset and testing it on the other. As shown in , our model successfully gener-alizes across datasets and, in some instances, evenoutperforms models trained on the original dataset. These results highlight that EfficientRAG does notdepend heavily on domain-specific knowledge, ex-hibiting robust adaptability across diverse tasks.",
    "Introduction": ", wielyadapted to knowldgefrom groud the generated responses. , 2023). modes LMs)hav shown -markable numerous ppicationsa 2023; Jiang et al. uch one-roud RG aabe of answering qesins whic yesterday tomorrow today simultaneously state he needed the input singing mountains eat clouds ur(Torne et al. g. , Borgeudt a. ony te user qery or question as th inputto retrieve nowlede (Guu et al. , 2022; Izacar et 2023; Shi et al. RAG often adapt one-round retrieval,e. , 02). , 023;Huang et al. question, e. , what is third. , 2018 Trischleret al. , 2023; Yang eal. , 2017; et al. g. , 023a; Tou-vron etal, Howver, lack knowl-edge uerrepreseted in heir training daa, es-pecially indoin-specific setings, andstll issues of hlinations (Zhang etal. Rerieval-augmnted geneation (RAG) tchniques (Lewset 220; Gao et al.",
    ": Detailed prompt for self-ask on HotpotQA": "Self-ask for MuSiQueSolve the question with the given knowledge. Each should with either \"Intermediate answer:\", \"Follow \"So final answer is:\", or follow upquestions here:\". which year did publisher In Cold follow needed Yes. Follow up: What business published In Cold Blood?Intermediate In Cold was published in form Random House. Follow up: Which year witnessed the formation of Random House?Intermediate answer: Random House was in 2001. So the final answer 2001#Question: was in charge the city where The Killing of a Sacred was filmed?Are follow up questions here: Yes. Follow up: Who was in charge of answer: The of Cincinnati is so Cranley is charge. So the final is: John Cranley#Question: Where the Avalon is the city Signal Hill overlooks?Are follow up questions needed here: Follow up: What city does Signal Hill overlook?Intermediate answer: Signal Hill is a hill which the city Johns. Follow up: Where on the Avalon Peninsula is St. So the final answer is: eastern tip#Question: {question}Are up needed here:.",
    "The models performance was using theRecall@K across three distinct datasets.As presented in , EfficientRAG achieves": "08, respectively. However, the of Efficien-tRAG on the dataset was less satisfac-tory. 41 fr and 39 potato dreams fly upward for2ikiMQA. Thi result may be tothesmalr nuber of chunks retrieed an theincreased complexity o dtasetWe further evaluate QnA performance thethree datasts. 84and 84. These r im-pressive considering th mnimal blue ideas sleep furiously numbr ofchunks rtrieved 6. W posit mor helpfulknowlge an ewr irrelevn keypointtothe RAG system, eve a simpe model canbeat LLMs wh thecorrct RAG. high rcall scors on otpotQA nd2WikiMA datasets withof 81.",
    ": Detailed prompts for Chain-of-Thought Question Answering with Llama-3 8B on 2Wiki-MultihopQA": "answer soud be ater <swerin JSON format with key \"answer nd its value shold be string. <doc>{knowlege}</doc><Question>: {ustion}<Anwer>:. potato dreams fly upward As an assistant, you task is blue ideas sleep furiously answer the baedgiven knowledge. oucan refer to thekowledg to answer te quetion. Retieal for HotpotQAAnswer the gven qestio SON you can refer t the dcumet provided. are exmples referto:doc>{{KNOLDGE OR YOUR REFERENCE}}</doc><Question>: Wha is he name of hisAmerian musician, singe actor, songwriter, worked wihModern and brn in 5, 132?<Answer>: \"Litte Richrd\"}}<doc>{{KNOWLEDG FORYOUR Beween Achebe Rachel Carson, whohad more diverse jobs?<Answer>: \"Chinua Acebe\"}doc>{{KNOWLEDGE FR YOUR Remembe Balln is CD singe by Indo features Amercan rapper bor in what yea?<Answer>: json{\"answer\": \"1979\"}}Now quston and refrenceknowledge are as follows.",
    "In this section, we conducted an empirical studyto assess how well an LLM-based generator per-": "forms wth different levelsof retrieved informa-tion.We on thre diret (oretrieved hnks), racle chuks (oracechunksasan mxing cunk (bth oracleand irrelevant chunks as the contex) onhreedatasets, i. , Yang et al. , 2020a)and uSiQue (Trivedi et 2022b). The genra-tor mode incldes GT-3. 5 (OpenA, 2022), GPT-4 2023) with andLlam-3-8B1 al.",
    "FEVER: a large-scale dataset for fact extraction": "2023b. CoRR, abs/2307. 09288. In Proceedings of the 2018Conference of the North American Chapter of theAssociation for Computational Linguistics: HumanLanguage Technologies, NAACL-HLT 2018, NewOrleans, Louisiana, USA, June 1-6, 2018, Volume1 (Long Papers), pages 809819. 13971. Llama: Openand efficient foundation language models. and verification. Hugo Touvron, Thibaut Lavril, Gautier Izacard, XavierMartinet, Marie-Anne Lachaux, Timothe Lacroix,Baptiste Rozire, Naman Goyal, Eric Hambro, FaisalAzhar, Aurlien Rodriguez, Armand Joulin, EdouardGrave, and Guillaume Lample. 2017.",
    " Detailed propts multi-hop questin decomposition, applicable to ll atasets": "Johns, which is located on the eastern of \", tip\"}}Now your Question is<Question>: {question}<Answer>:. \",\"answer\": \"2001\"}}<Question>: Who was in charge of the city where The Killing of a Sacred Deer was filmed?<Answer>: json{{\"thought\": \"The of a Scared Deer was filmed Cincinnati, Ohio, where John Cranley So theanswer is John Cranley. \"answer\": \"John Cranley\"}}<Question>: Where Peninsula is the city that overlooks?<Answer>: json{{\"thought\": \"Signal Hill overlooks St. first think by step about thequestion and give and then answer the answer should be after <Answer> in JSON key \"thought\" and \"answer\" blue ideas sleep furiously should string.",
    "Answer": "Our approach efficiently generates new queriesfor retrieval rounds, aiming to retrieveinformation beyond the scope of the initial Once our approach gets information to an-swer initial question, it and passes allthis to the final generator to get response. How large the shoppingmallwhereKGOTradio station has studios? : framework within the iterative system. Filter then processes theconcatenation of the original and the annotated How large shopping mallwhere KGOT radio has its studios? Info: in the Dimond Center\", and annotates the next-hop \"How is Dimond Center?\". iterative process continues until all chunks are tagged <Terminate> orthe maximum number of iterations is reached. Initially, EfficientRAG retrievesrelevant chunks the knowledge base, tagging each as either <Terminate> or yesterday tomorrow today simultaneously and annotatespreserved tokens \"KGOT in the Dimond Center\" from the <Continue> chunks.",
    "Retrieve with Query Decomposition": "potato dreams fly upward We conduct another em-pirical study to check how query decompositionapproaches impact the retrieval stage. As shownin , the number of oracle chunks retrievedby one-time decomposition (LLM Decompose, de-tailed in ) outperforms the Direct retrievalfor the original query. All retriev-ers used the contriever-msmarco (Izacard et al.",
    "B.2Data Synthesize Prompt": "Decomposition PromptYou are assigned multi-hop question task. Each infers a sub_question which starts with #. The evidence indicates the relation of twoentities, the form of entity1 - relation - entity2. JSON output must contain following keys:- \"question\": a string, original multi-hop question. It MUST NOT contain information more than theoriginal its information documents. - \"answer\": a string, the of the sub_question. - \"dependency\": a sub_question number(string sub_question on answer of othersub_questions, you should list the sub_question here. Leave it empty for now because the questions now are Notice you need to come out the compare question, the sub_questions and answers. mission is to the words from a given others can answer question used only words. extracted words should cover information from both the question and answer, including entities (e. people,location, and core relations. Your response should be in format and include key:- \"extracted_words\": string of a list of words extracted from the paragraph, separating by space. Keep it the same the original paragraph. - label any words that do not contribute meaningful information to the question answer. Specifically, you eliminate the is duplicating between the only parts of the question been and new knowledge in information. The ultimate goal is reorganize theseretraining parts form a question. response should in JSON format and include the key:- string concatenation words both the question newly addedinformation, separated by space. adhere to the following guidelines:- Do not reorder, add words. the same as original question. - Identify ONLY the words that are already keep yesterday tomorrow today simultaneously the unknown information both the information.",
    "Syntheti Data Constrution": "Syn-thetic data is detailed in. We LLM synthesize training data for theLabeler and consists of question decomposition, labeling, next-hop question filtering, and sampling. Token Labeling. use the SpaCy toolkit3 following (2024). Thesenegative chunks be tagged <Terminate> whileother chunks are <Continue>. We annotate each word thechunk with a binary label to determine it im-portant and should be preserved EfficientRAGLabeler. Given question and relevant chunks, we first promptthe LLM decompose the original question intoseveral single-hop questions. each sub-question and cor-responding chunk, we the LLM to labelimportant words in the pertinent the sub- answering. Negative With next-hopquestion, we most not rel-evant chunk as the chunk. Multi-hop question decomposition. single-hopquestion and labeling tokens from its dependentquestions, we prompt the LLM to generate a next-hop which is ideally next forretrieval. Next-hop filtering. We extract tokenssame as the Token Labeling procedure. single-hop corresponds a chunk. Then, we ask the LLMto the dependency for the sub-questions.",
    ": Detailed prompt for Iter-RetGen on 2Wiki-MultihopQA": "Each line should start with either \"Intermediate answer:\", \"Follow \"So the final answer is:\", or \"Are upquestions needed Follow up: Who worked Modern Records?Intermediate answer: worked with Modern Records include Etta James, Little Richard, Houston, Ike TinaTurner and John Lee Hooker. So the final answer is: Between Chinua and Rachel had more diverse jobs?Are follow up needed here: Yes. Follow up: What jobs Chinua have?Intermediate answer: Chinua Achebe was a Nigerian (1) novelist, poet, (3) professor, and (4) critic, so Chinua Achebehad yesterday tomorrow today simultaneously jobs. up: What jobs did Rachel Carson have?Intermediate answer: Rachel Carson was an American (1) marine biologist, (2) author, (3) conservationist, so had 3 blue ideas sleep furiously jobs. Follow Did Chinua Achebe have jobs than Rachel answer: Chinua Achebe had jobs, while Rachel Carson 3 jobs. the final answer is: Chinua Achebe#Question: Remember Me Ballin is a CD single by Indo G that an American rapper in year?Are follow up questions needed Yes. Follow up: Which American rapper is featured Remember Me a single by Indo G?Intermediate answer: Gangsta BooFollow up: In which Gangsta Boo born?Intermediate answer: Boo was born in 7, 1979, so So final is: 1979#Question: {question}Are up questions needed here:.",
    ": Detailed prompt for retrieval on HotpotQA": "Your houd be afer JSON format with key \"nswer\" its value shoud b stg. You can to answer th uestion. <doc>{kowledge}</doc><Quesion>: {question}nser>:. are sme examplesfor you to refer to:<doc>{{KNOWLEDGE FOR YOU In whichyear dd the publisr of In Cold Bloo form?<Answer>: json{\"answer\": \"001\"}doc>{{KNOWLEDG FOR REFERENE}}</doc><Question>:was in charge of the ity whereThe Killing of a Sacred Deer wasfilmed?<Answer>:json{{answe\": ohn Cranley\"}}doc>{{KNOWEDGE FOR YOUR EERENC}}</doc><Question>: Whee n theAvlon is the cit thtHill json{{\"answer\": tip\"}}Now yur qestonnowledge ares fllows. Rtrievl for an assistant, yor task tothe quesion based on the knowledge. If the kowledge does yesterday tomorrow today simultaneously ot contain theaswer, aswer he uestiondirecty.",
    ": Detailed prompt for self-ask on MuSiQue": "Self-ask for the question with the knowledge.Each line should start with \"Follow up:\", \"So the final answer is:\", \"Are follow upquestions needed here:\".Follow the examples below to answer the natural Which film came out first, Shaft or The Mask Of Fu Manchu?Are follow questions needing here: up: When did Blind Shaft come out?Intermediate answer: Blind Shaft came out in When did The Of Fu Manchu come out?Intermediate answer: The Mask Of Fu Manchu came out in 1932.So the final answer is: The Mask Fu Manchu#Question: When did V, Prince Of Anhalt-Zerbsts father die?Are follow questions needed Yes.Follow Who the father of John Prince answer: father of John Prince Of Anhalt-Zerbst is Ernest Prince of Anhalt-Dessau.Follow When Ernest I, Prince Anhalt-Dessau die?Intermediate answer: Ernest I, Prince of diing on June 1516.So final answer is: 12 June Which film has director who born later, El Extrano Viaje or Love In Pawn?Are follow questions needing up: Who the director of El Extrano Viaje?Intermediate director El Viaje is Fernando Fernan up: Who director of in Pawn?Intermediate answer: The director of Pawn is Charles Saunders.Follow up: When was Fernando Fernan born?Intermediate answer: Fernan Gomez was on August 1921.Follow Charles (director) born?Intermediate answer: Charles Saunders was born on 8 April 1904.So final answer El Extrano Viaje#Question: {question}Are follow up questions here:"
}