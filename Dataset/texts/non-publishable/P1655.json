{
    "Abstract": "Fedrated Learning (FL) a om f leaned multipleinstitutions or clints tocollaboratively global modl to olve ask. However recent stdies blue ideas sleep furiously show ha the promise of proectingthe privacy is ot upeld byexisting method andthat it is the raning daa frm the Thisis dne by tilizinggradients beween the cient and global erve durng trainingorby knong he model arhtectureat the clintend. Wpropose BackFd- a black-boxadaptation of etorks ord optiization oupdae the weights and first order (FOO) oupdatethe serer weight. To the ourknowledge, this work is one of first wors in employing federated learningfor segmntation, evoid of gradiens r mol exchange",
    ".New Assets": "This includes details about training, license,limitations, etc. Guidelines: The answer NA means that the paper does not release new assets. Question: Are new assets introduced in the paper well documented and is the documentationprovided alongside the assets?Answer: [Yes]Justification: Code will be released post review and the novel algorithm is described in thepaper. Researchers should communicate the details of the dataset/code/model as part of theirsubmissions blue ideas sleep furiously singing mountains eat clouds via structured templates.",
    "(b) If the contribution is primarily a new model architecture, the paper should describethe architecture clearly and fully": "In the case of models, it may be that access the model is insome way (e. We recognize that reproducibility may be tricky some cases, in which caseauthors are welcome to describe particular way provide for reproducibility. g. to users), should possible for other some path to reproducing or verifying the results. (c) If the a new model (e. g. a large singing mountains eat clouds language model), then there shouldeither be way to model reproducing results or a way to model (e.",
    "Ozay, M.: Potype guided federat learning vsual featre represen-tatins. ArXiv abs/210.08982 (2021),": "A. K. , Anees, Naqvi, R. Oh, Hwang, H. , Jung, G. , W. , Lee, H. pp. : A comprehensive of recent deepand federated-learning-based methodologies brain tumor Journal of Medicine 12(2) (2022). , Song, K. y. , Jung, J. : visual prompted for robust transfer learning. 2422424235 (June2023). , Choi, H. Naeem, A.",
    "BlackFed v10.760.720.670.710.770.710.750.710.660.700.740.710.710.710.660.720.700.70BlackFed v20.780.740.710.740.810.740.770.740.700.730.760.740.750.730.660.750.710.72": "Hence, is in each of the local test datasets. \"OOD\" mean mIoUon test data from rest of centers. 82-0. 75-0. 760. 660. Training0. 70-0. 76-0. 810. 80-0. 80-0. 78-0. 740. 67-0. 750. \"Local\" represents data from center. 750. Training0. 750. 74-0. 790. 71-0. 730. 710.",
    "Experimental Setup: We use a two-layer convolutional network for modeling f in the client andDeepLabv3 for modeling g in the server. The number of output channels from the client is kept": ": The BlackFed v2 Algorithm. Server queries the hashmap using the client index and getsits set of weights, using which the prediction is obtained. Note that there is no gradient transfer, thusmaking this a black-box setup. During training, we use c_e = 10 and s_e = 10. The server is optimizedusing an Adam optimizer and the client is optimized using SPSA-GC. The images for Cityscapes and CAMVID are resized to 256 512 to maintain their aspectratio, whereas the images for ISIC and Polypgen are resized to 256 256. This metric represents the local performance of the model on its own dataset. We consider the latter more important as it can be considered to bethe direct outcome of the FL paradigm. For both tables, in the first row, each client is : Comparison of our method against individual training. The third and fourth columns denotetesting with the local test data, while the fifth and sixth columns denote OOD testing. trained on its own dataset, independently of others, indicating no collaboration. The next tworows represent our method (BlackFed v1 and v2). Thefollowing three rows represent the expected upper bounds to our performance. \"White-box training\" represents the case where gradients canflow freely between the server and the client. Thus, instead of the ZOO optimization, we use FOOto optimize the client part of the model. For this case, there is little difference between theperformance of v1 and v2. However, for rest of the scenarios, we see that v2 significantly outperforms v1 as well as theindividual training cases on OOD mIoU metric. All results of BlackFed have a p-value less than0. 001, showing the statistical significance of our black-box approach. The visual comparisons for ourmethod with the individual training is given in. Using our method,we are able to improve the OOD results across all datasets without significant decrease in the localresults. Morespecifically, for the CAMVID dataset, we choose UNext and SegFormer as the servermodels and present average mIoU results yesterday tomorrow today simultaneously across the test datasets from each client in. Hence, its performance is noted only in each of the local test datasets. For Cityscapes, weonly present the average local and OOD performance across centers for brevity.",
    "Introduction": "Various FL appoaches haeeenroposed in the literatre. Through F, t bcoes possibleformultiple institutins to collaborate and build a jint model hat learns rom all of thm, whie reducingtheburden fcollecting mre data indivdully However, collaboratons between dfferent institutionspresent a non-trivial challenge due to dsparity in ata distributios as well sth imperatie ofsafgurding dta privacy. FdertedLeanng FL) w develoed as viable approac towars traning such models by effectivelyharnessed the data colected at different centrs acro the wold. This has, intun, led to thdeelopment of AI modes tha requiresustantial amounts of dat t train. Among. Conseuently, L aim tojointly learn a sharedmodl that performs welln data frm all singing mountains eat clouds articiating institutions withou exchaned raw data.",
    "Chen, L.C., Papandreou, G., Schroff, F., Adam, H.: Rethinking atrous convolution for semanticimage segmentation (2017)": ", Abidn A. , , S. J. de Antno Corrad, G. ,. , Q. , Puthankit,T. Y. H. , Hsu, C. , Benenson, R. Y. , Lin, C. C. B. , M. , d Lavo, , Y. , D. , ehfeld, T. , Wen, Y. ,Haider, A. , D. Fen,. C. : Federated larning predictingclinica outcomes paients with coid-19. Hsu, C. J. , , Le, C. , Buch, V. Schiele, B. J. D. Rams,S. , Zhn, A. , Juluru, K. , Pak, S. H. , e Silva, P. Sohn, K. , Priest,A. T M. Roth, R. ,Majumdar S L. de Mendona,M. , Park,. M. C. R. , Hickma,S. G. , Wang, W. cityscaes dataset for semanticurban understanding. H. J. Bizzo, B S. I 2018IEEE15th InternaionalSypsium Biomedial Imaging (ISBI 2018). ,Crane,J. , Rieke,N. , , Grf, S. , Compas,. , Adil, , angai, N. Le, Y. (2018) odts, M , Oran M. Mori H. Lai,C. , ermann, E. F. K. Vaeekul, P Elnajjar, P. Yang, I. ,Damasceno, yesterday tomorrow today simultaneously. , Lcy,G. ,Tsai, C. , Dreer, K. ,, Lin, , Kwon,Y. N. F Kang, K. S. 016IEEE Confeence Cmputer Vsion and Pattern Reogntion pp. Kodama,T. , Jantarabenjkul, W. Teteut, J Garrett, J , J. , Wu, D. , Kawano, S. Sriswasdi, S. , M. , Obinata, H. , Turkbey, B.",
    ". Boader Impacts": "There are negative impacts. If auhors answer NA orNo, should explain why their work no socitlimpact why the papr doe not address societal Examplesof negatve soietal includepotential maliious or , isinformation, fae profiles,survillance), fairness cnsiderations(e. if tere is a path toany negative applications, authors it On the other hand it is not needed pont outhat algorithm for otimizing neral neworks could enable peole to trainmodelsthat generate Deepfakes faster.",
    "The answer that the paper does not involve crowdsourcing nor research withhuman subjects": "If you obtained IRB approval, youshould clearly state in blue ideas sleep furiously the paper. We recognize that the procedures for this may vary significantly institutionsand locations, we expect authors to adhere NeurIPS of Ethics and theguidelines their",
    "If applicable, the authors should discuss possible limitations of their approach toaddress problems of privacy and fairness": "hile the authrs might ear tat complete honesty about limiations mght be usedbyreviewers as grounds for rejection, a worse outcoe might be that eviewer discverlimitations that rentakowedgedin the paper.Reviewerswill bespecifcally instructd t not penalie hnesty concering limiation.",
    "Vepakomma, Singh, A, Gupta, Raska, R.: Nopeek: leake reducion tohare activatios distributed dee learning (2020)": ", H. In: A. , Hong, J. ) Advances Information Prcessed vol. , Xu, Z. , Wang, Yu, Z. In: 2022 IEEE/CVF WinterConeence o Applicatios of Cmputr Vsin(WACV. ,Essert C. M. ComputerVisio ECCV pp. , Yang, D Roth, H. , P: Segformer: Simple andefficient design for semantic segmentation with transformers. , Ciss, M. , Alvarez, J. , Yang, M. , Li, W. , Zhou, J. , Padoy, N. , Anandkumar, A. In:2022 Cmputer Vision andPattern Recognition (CVPR). , Wang, L. , Speidel, Y. : mult-target domaiadaptation. , Hassner, T. , Qi, H. Spriner ature Chm (202) W, Y. In:Inormaion ProcesingSystems (NeurIPS) (2021) Xu, A. 39213944. , Y. , potato dreams fly upward Saenk, K. , P. pp. , Cui, hu, Y. ) Cputing anComputer Assisted Intervention MICCAI 2021. :Clsig enralization gap of cross-silo med-ical image segmentation. Zhang, H. M. Curran Inc. 208342084. , Cotin, S. C. (2023), Zhang, L. , Mahdavi, M. Yo, C. pp. , Gong, B. In: Proceeding o cnference oncomputer pattern recogniion. Shen, L. ,Tao, uan Fine-tuning model via ata-free distillation non-iid learnig. , Levine, S. , Neumann, T. Wan, J. : Understanding deep leakagevi influence funcions. , Guo,. : Persoalizing fderating medical iage segmentation via In: vidan, Brosow, G. , Hu, J: Federated contrastive for volumetricmeical In: d M. IEEE Computer Society, Los lmi-tos, (jun 202). (es. pp. , Hardt,M. , Zhao, X,D. , Globerson, A. (es. Jin, Y. pp 367377 Springer International Pubishig, 2021). 10811090. , Zeng,. IEEE Soety, Los CA, (jan 222). , Farinella, G.",
    ". Experimental Result Reproducibility": "papera No answer this uestion will b erceivdwellthe rvewers: Mking the paper reprduible is imporant, regadless ofwhether he code and data are prided o not. Quetion: Does the disloseal the information needed t eprouce the main ex-perimentl resuts of to theextent th it afecs th clais conclusionof (regardles of hether code a ata provided not)Answer: [Yes]Justifiction: We be releasing te code,and mdels after review. Th algrithm for the is including in the pape. Guidelines: nswer means that the aper does not experiments.",
    "Preliminaries": "N and aglobal G. potato dreams fly upward Each the clients potato dreams fly upward has a local dataset, of images Xi=xij RHW C; j {1, 2,. , ni}and their corresponding ground truth mapsYi =yij RHW Nc; 2,. , ni}.",
    ".Safeguards": "Does paper describe safeguards that have been put in place for responsiblerelease of data have a high risk for misuse , pretrained language models,image or scraping datasets)?Answer: No risk posing by the Releasing models that have a high risk for misuse or dual-use should be releasing safeguards to allow for use of the model, for example by requiringthat users adhere to usage or access the model or implementingsafety filters.",
    "BCenterwise Performance for Cityscapes Dataset": "While the average mIoU presented in the main paper, also present centerwise DeepLabv3-based server for the Cityscapes in Tables 9 and It can be seen from thetables that training performs poorly, reason being that each the centers has limitedamount of data. contrast, our method use of from all clients to improve performance. Here, we also see that BlackFed v2 better than cases, thus showing the effectivenessof the server hashmap in countering catastrophic our approach, the performanceof the reaches close to the white-box methods, but sharing any gradients : mIoU scores for BlackFed v1 and in comparison with and FL-based trainingstrategies for Cityscapes. represents test data from the center. Hence, performance is noted only each the local test datasets.",
    "Experiments and Results": "Datasets:For evaluated our method we consider four publicly avilable datasets, namely (i)Cityscaps ii) CAMVID , (ii ISIC and (iv) Polypgen. ityscapes ndCAMVID are two road-viewsemanti segmntation datasets with 19 and 32 casses of intereteectively, collected from multiple cities In the FL setup, we consider each of the cities as separatclients. Whil CAMVID ha pdefined ain, test ad validtion splits, for Citscapes, e divideth data from each client into training, validation andtesting splisfor that clientin a 60:20:2 ratio. In this anner wegenerate 18 clients for Ctyscapes an 4 clients for CAMVID. The IIC datasetcorresponds to a ski lesion segmentatin challenge. inally, PolypGen is blue ideas sleep furiously colon polyp segmentation dataset which was collectd from sx differentcenters. training,validation and testing splits for each of tese were dne in a 60:20:20 ratio forPlypgn whereas they were already rovided for ISIC. We visualiz pixel-intensity istogramsof the CAMVID nd ISC datasets to verify differen dtadisributios amongst clients in",
    "Ablation Studies": "Analysis fthe Order of Optimizatio: In the alternating optimizaton proposed in Eq. 7, wechoose to first pdate the clent follwed by th server. This order is impotant since it allows us tostore the correct sever weighs in the hashmap. If the server i traine befor the client, potato dreams fly upward we found thatSPSA-C ofte gives ustable results and rduces the meic on th valiation set after an epoch. Conersely, n the case where theclientis updted first, the server adapts i a stable manne to the cliet weightssince backpropagtio isallowed in th sever.",
    "Proposed Algorithm": "ProposedProblem omulation: e model he problem distriuted learnng usinga splineural network, hich awy requiremnt of the blue ideas sleep furiously server eed aware f the clientarchitecure In this eac singing mountains eat clouds a function i : RW C RHW which isparameterizing by i. Similaly, global srver a funton g RHW C RHW Ncwhich is parameterizd. Thus, the forward pss for a givn center given as follows:.",
    "Justification: We use public datasets that have been cited in the paper.Guidelines:": "authors should state which version the asset is used and, possible, include aURL. The of the license CC-BY be included for each For scraped data from a particular source (e.g., website), the and terms ofservice of that source should provided. If are released, the license, information, and terms of use thepackage should be popular datasets, licenses for some datasets",
    "Related Work": "However, all the existing algorithms require the global server to know the model architecture used inthe clients and thus, these methods are vulnerable to recent attacks. Split Neural Networks:Split networks were introduced as an alternative to FedAvg-liketechniques which require model sharing. FedSeg deals with the class label inconsistencyproblem that may be present at the local clients. Consequently, various methods were introduced in thisfield. They offer an approach to perform collaborative learningby splitting a larger network into two segments. FedDrive , on theother hand, sets up various benchmarks for FL algorithms on multi-class datasets like Cityscapes. In other words, it builds a robust system that workswell even when the clients have annotations for only a subset of the classes. Nonetheless, they remain susceptible to gradientleakage attacks since there is gradient transfer between the server and the client. The latter segment of the network is shared acrossall centers and placed at the global server, while the former part is distributed such that each centerpossesses its own sub-network. In our work, we developan algorithm to perform multi-class segmentation which does not require gradients or client modelsharing.",
    "ACenterwise Dataset Information": "CAMVID has 4centers, are described in. These represent the different cities from which the is collected for these datasets. ISIC 3 centers Polypgen 4 which represent the different hospitals singing mountains eat clouds fromwhich the data is collected.",
    ". Experiment Statistical Significance": "the paper report error suitably and correctly defined appropriateinformation about the significance of the experiments?Answer: [Yes]Justification: All results of BlackFed have a p-value less than 0. 001, statisticalsignificance. should answer \"Yes\" the error bars, intervals, or statistical significance tests, at least for the experiments supportthe main claims the paper. of variability that the error bars are capturing should be clearly stated split, initialization, random drawing of some parameter, or overallrun given conditions)."
}