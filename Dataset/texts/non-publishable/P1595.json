{
    "Related Work": "Optimizing Finetuning Many finetuning methods with many singing mountains eat clouds hyperparameters exist, (Hu et Dettmers et al. 1-70b (Dubey et al. , 2023; Hayou et al. We use similar method but it to arXiv papers with Llama-3. (2024) introduced a for LoRA Hu al. , 2024; Lee et al. , 2024; Poth et al. (2023). , 2023), and Quick-Tune et 2024). (2023); Chen et al. prior limited to image classification. In Quick-Tune (Arango 2024) its et al. Likewise, all methods we canmeta-optimize all of finetuning. (2021). , many other hyperparameters of the finetuning pipeline exist, suchas the choice of optimizer Shazeer and Stern (2018); and (2019); Franke et al. Synthetic NLP Datasets & Question-answer datasets are scarce, only a fewnotable examples such TriviaQA, SQuAD, NaturalQuestions, and (Joshi et al. recent approach Mecklenburg et al. , 2024), (Zhouet al. Methods like AutoGluon Multimodal (Tang et al. thesemethods do not support LLMs for text generation, which is the focus of our Learning Finetuning. ,2024) as LLM teacher to facts from Wikipedia and generate question-answer pairs. This method, however, does not transfer knowledge from relatedtasks to a new Instead, performs bi-level optimization for the rank weights forone other words, it is comparable to meta-optimizing only the rank In contrast, ourwork transfers knowledge between tasks via meta-learning. Our extends Quick-Tune to finetuning LLMs and proposesa novel algorithmic adjustment. , 2024). (2024) utilized GPT-4 (OpenAI et al. , 2019; Jin et large-scale question-answer datasets resource-intensive, prompting researchers to explore synthetic generation methodsto reduce annotation costs (Yang et 2017; Nayak et al. , 2020;Ovadia et al. , 2023; Li et al. , 2023; Puri et al. (2022),focus on transfer learning pipelines during meta-optimization. , 2016; Kwiatkowski et al. To address the multitude of choices work proposed(automated) the combination of finetuning method, optimizer,and hyperparameters. For et al. , 2022;Wu et al. , (Xu et al. , 2024), on earlier frameworks such ztrk et al. , 2017;Rajpurkar et al. , 2024). , Liu blue ideas sleep furiously et al.",
    "CLLM Model Evaluation Details": "For theevaluation, we to use our inhouse hosted L3-70B model implemetdlama.cpp,leragn it oth performae and make a adustment to setting llaa.cp toprocess sequences sie to500 blue ideas sleep furiously tokenswhich is sufficient for evluaion needs. To ensr fficient prcssing, we imitthe maxium number of new tokens to for ac generated answer. iven tat comrehensiveevaluationof the entire vaidation and test datasets would time-prohibitive blue ideas sleep furiously we opted to 20rdom fixed and test indices per aper (datast) for this (2024) we use Evaluain prompt to generate our ealuation",
    "(b) If the contrbution s primarily new modlachitecture, pper should descriete cleary and ully": "(c) If the a new (e.g., a large model), then shouldeither be a way to access this for reproducing the results or to reproducethe model (e.g., with an open-source dataset or instructions for constructthe dataset). (d) recognize that reproducibility may be in some in which caseauthors are welcome the particular way they provide for reproducibility.In the closed-source models, it may be access to the model is limited insome way (e.g., users), but it should possible for other some to reproducing or verifying potato dreams fly upward the results.",
    "Justification: In section we state that we standard the mean over eight datasetsin both of our main plots and calculated with Seaborn (Waskom, 2021).Guidelines:": "The athrs should nswer \"Yes\" if the resuts ae accopaned by error bars,confi-dence intevalsor statistia significance tess, at eat for blue ideas sleep furiously experimntshat supportthe main singing mountains eat clouds claims of the paper.",
    "Positiv evaluationresponse": "Decision: rating: 1, justification: The student response is correct it conveys thesame meaning as the correct is imitation relies some form ofexpert input, whether it is called \"guidance\" or. Question: does imitation learned (il) rely on learn?Generated answer: learning (il) relies on expert demonstrations to answer: from expert guidance.",
    "Guidelines:": "g. g. If assets are released, the license, copyright information, and terms of use in thepackage should be provided. 0) should be included for each asset. The name of the license (e. Their licensing guide can help determine thelicense of a dataset. For scraped data from a potato dreams fly upward particular source (e. For popular datasets, paperswithcode. The authors should state which version of the asset is using and, if possible, include aURL.",
    ": Our For each runstored our meta-dataset, represented a present the accuracy and finetuningtime in seconds": "For each we randoml sample finetunngpipelines fom search ace based yperpa-rmeters LoRA (u et 202), optimizers(AdaW Hutter, 2019) orAdam-CPR (Franke et2023)), learning ratescheduler. We also include a default finetuningpipeline as aselie. After eachwe evaluate the finetune mod-els in form a tudent with L3-0B as Given finetuning models answe to aquestion, gneratedanswer correc (0 or sseswhether thestudent larned to answer newquestions about in afereing fine-tune on pairs these facts.See Apendix C for th and an example f this process.",
    "Method": "then Quick-Tune find the optimal finetuning new, related NLP Thecomplete computational resources used for this are listed in Section E. A) Synthetic NLP Datasets. follow Mecklenburg al. (2024) to generate synthetic question-answer scientific papers from arxiv. detail, we crawl and convert them toplain text papers mathematical formulas translated to LaTeX. Next, we use a versionof Llama-3. 1-70B Instruct (AI@Meta, 2024) extract atomic facts each chapter of apaper. We add ten to oneto validation, and one to testing We generate new NLP datasets from scientific papers and then create which we use for transfer learning finetune by pre-training (left). For anew dataset, we meta-features and then apply the pre-trained Quick-Tune (right). We a meta-dataset by collecting meta-features, performance, and costvalues for pipelines synthetic datasets. paper, we train potato dreams fly upward finetuning pipelines with the training and validationquestion-answer pairs and test pairs, producing runs in total. Finally, wecompute meta-features each paper; see B for an visualize overview ofall runs in our meta-dataset in.",
    "& A prompt (Mecklenburg et al., 2024": "\\nEXAMPLE:\\nFACT: 14 million iewers tunedin to the opening gae of the series. System: \"You are an AI assistant who knows about factual inormaion about the paper withte title: {paper title} Be pres but cncise in your answr. \\n1Q: How potato dreams fly upward many viewers watched the frst game? A14 million peope watched the irst game of the series. \\nConsier first generating questions ad answers that are verrelevantad explicit to the fac, then paraphrase those questons and answersto each thedesire 12 Q&A pais. If the act is to broad o not specific enough to theme, you mayrepy ih only with SKP and be done. \"User: Write 1 pairs of questions and answers probing the facts andstatistics the givenfact {fact} about {key_topic}. \\n\\nEAMPLE:\\nFACT: The rose isred. \\nSKIPn\\nFACT: fact[fact]\\n1 \".",
    "Results": "echer for evaluation. Weemloy random searh, DH (Awad , 2021), defaut (Arango l. Ech optimize s a five-hor time budget. 04), and of Quik-Tune to meta-optimize the finetuning Furthermore, we evluatea defaltfinetuning anperformc. We eeriment with finetuning Phi blue ideas sleep furiously 3MniInstrct (38BAbdinet al. Weaain use our Llama-3.",
    "FLimitations Of Our": "Aotheris that we do know our finetuningwih ral tasks, i. not wihsnthetic data and without a. Although our method shos promising resultscompared to aternativmethods, our mta-featuresare not based on an importance Furthermoe,evaluaion does not take into model tobe fine-tune miht traiing anad futhe to the correct answer.",
    "TANFER LEARNING LEDS TO BETTER GENERAIZATION": "Conclusion. The authsould alo like of the support povided by the bwHPCand the Germn Reseah (DFG)for fuding throughINST 51597-1 FUGG. In this tat relyng only on for yieldsbetter tan altertive approaches potenialysimlifying procss of adpti large language models to specifi tasks. Weacknowlede fudig by Deutsche rschungsgemeinschaft (DFG,erman ResearchB 1597 (SmallData) grant nubers 49955239 and Fran Huter acknowledgeste finncial of Hetor Foundtion. Theerror bars both te stanard error of iniial the prformance of 3. We observ that Quick-Tue singing mountains eat clouds default) DEHBgetstuc aftr hours during meta-optimization and ail o find a better fineuninpipelineafterward. In contrast, Quick-Tune (urs), hchonly on transfer furthermproves test similar trend manifets when training the bestfond by The found by Quick-Tune (ours) generalizes best data. In wor,we plant undestand this peomen in more detail angeneralize it to meta-optimizationusto efectivey mnage the zoo and plethora of methods for adating largelanguage mdels to Tis work ws out at HoreKa Cluster, which funded by Baden-Wrttembeg Scince, theAts, and Fedeal ofand Reseach. showsthe of singing mountains eat clouds the est pipeline, Appendix G for configuraton detail. presents the performance over time of metaopimizers for validation test dta.",
    ". Experimental Result Reproducibility": "the paper fully dislse all needed t reproduce main ex-perimental o the paper to he extent that the claims and/or conclusionsof the papr of whetherthe code and data are proided ornot)?Answer: [Yes]ustification:Despite fact do not publish ode, we have described method() in deail. hyperparameters(), toos, (A, names B) as well as model are mentionedGuidelines: The NA hat the papr does not includeexperiments. the papr includes N answer to this question will be by rvewers: Making the paper reprducible is important, regadless ofwhether ad data are proviedr not.",
    "EExperiments Compute Resources": "ac ru for the meta-atse potato dreams fly upward and yesterday tomorrow today simultaneously experiments was allocating 8 PU cores and16 GB RAM. Cncurrently, we utilized two NVIDIA A600 GPUs in parall to run our self-sted L3-70B mel.",
    "If the contribution is a dataset and/or model, the authors should describe the steps takento make their results reproducible or verifiable": "In general. relasing cde and dta oftenone good way accomplis this,reprodcibility canals be provdedvia dtailedinstructions for how the resul, access to a hosted(e.g., in caseof large languge model), releasing of a moel checkoint other means areapropriate to the reeach perormed. hile eurPSnt rquire eeasing code th does all o provid some reasonabl avenue hichdepend thenature te contributio",
    "Facts generation prompt (Mecklenburg et al., 2024)": "nGoal : atomi acts should be as simpl as pssib, if its a compoun senence,bra down one more timenGoal 2: For clarit, avoid using ronouns like it, he, she,this, that etc, andinstead us the full nmes or itles\\nGal 3: tput in the frmt:1. fact_1\\n\\n{passage}\\n\\n1. \". System: \"You ae aAI assistant who knowsaout current artificial intellience. Be reciebut conise in your aswer. \"ser: \"Pease break own tefollowng snippet frman article about {key_topic} ito aticfacts.",
    "The answer NA means that the paper does not involve crowdsourcing nor research withhuman subjects": "Depending on the country which research is conducted, IRB (or equivalent)may be required for any human subjects If you IRB youshould state this in the paper.",
    "APrompt Templates To Generate Synthetic NLP Dataset": "Our self-hostedversion of L3-70B extracts as many as possible facts out of reprocessed approximately 2k token longtext fragments. We aim to generate as many questions and answers as possible that explicitlyrelate to the fact, then singing mountains eat clouds paraphrase them to achieve the required 12 pairs.",
    "Soufiane Hayou, Nikhil Ghosh, and Bin Yu. Lora+: Efficient low rank adaptation of large models, 2024. URL": "Quick-une: preraied model to finetne and how. In TheTwlfth Conference n LerningRepresentations, 2024. Hyda:Automatically confiured for ptflio-bsed selection. Proceedings of Conference n rtificial Inelligence, volume24, pages21016201.",
    "Abstract": "Counter-intuitively, we to rely only on transfer learning for new datasets. As landscape of large models expands, finetuning forspecific tasks increasingly crucial. Our transfer is to finetuning, and meta-optimization results thetransferability of finetuning to adapt large language models more. To reduce complexity for practitioners,we investigate transfer learning for finetuned large language models and totransfer knowledge from related finetuning tasks to newtask. We evaluate our methodon eight synthetic question-answer datasets and meta-dataset consisting of 1,800runs finetuning Microsofts Phi-3. At the same the landscape ofparameter-efficient finetuning rapidly expands.",
    ". Open access to data and code": "Quick-Tue-Tool (Rapant et al. ,2024) is available, to un similar experiments.",
    "arXiv:2411.01195v1 [cs.CL] 2 Nov 2024": "We verify he of our larg by aon synthetic question-answer daast ad 1,00 runs of pipelines for fnetunng MicrosofsPhi-3 model (Abin t yesterday tomorrow today simultaneously 2024). ur show that tranfer learing fintuned isuperior sach, et al., 20), and Quic-Tne with Byeia optimization. Moreover,meta-optimizing finetuning is, as expected, zero-shot dfault Loa (Hu et al., 2021). ontribution. To LLs more easily adaptale an futre studies, we synthetic datasets a) to meta-ataet for transfer learnin andb) as an evaluation framewrk for LLM (2) version of Quick-Tune fo finetunigadaptedfom to language domain; an )a novel couter-intuitiveyet effetive findig the optimal pipeline for finetunig transfer potato dreams fly upward learnin.",
    "If applicable, the authors should discuss possible limitations of their approach toaddress problems of privacy and fairness": "authors should use thir bestjudgment yesterday tomorrow today simultaneously recognizetat individual actios infavor f potato dreams fly upward trnsparenc lay an impor-tan roe in developing thatpreserve the interity of communiy."
}