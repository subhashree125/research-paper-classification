{
    "EXPERIMENTS": "This section presents empirical evaluation of proposing attribution framework1.",
    "Inference approach": "Given he generative model above, the tsko robabiistic attri-buion isnow turning o that f finded the posterior distribuonof. Approimatng () ith a specific functionalform, such as the linear function, maynt alays be pssible, ei-ther. Howee, thre are twomajor differences from the stadardBaesin inference: 1) () is a black-box function. This section xplais how we ddrssed these challenges. 2) Poterior inferenc enerally yelds a joint distrbution for, deoted by (. However, this is notwat we wan since itdoes not directly expainthe contribution ofthe inividual inputvriabls.",
    "Notation. We use boldface to denote vectors. The -th dimensionof a vector is denoted as . The 1 and 2 norms of a vectorare denoted by 1 and 2, respectively, and are defined as": "nd 2 . Th sign fuction sign() isdefinedas being 1 fr > 0, 1 for < For thefunction takes n indeterminate value in . For a vector input,te efinitio appliesyieldg avecor f the samesize s input ctor. We between a variabeand realzations the absece or presenceof a superscript. Fornotational simplicity, we use () or () as proxy to representdffernt probability ditributios, wheevr hre is no cofusion.For () is used represent the probability density variable wile ( | ) is a iffrent istribution ofnother random variale conditioned on",
    "Karen Simonyan, Andrea Vedaldi, and Andrew Zisserman. 2013. Deep insideconvolutional networks: Visualising image classification models and saliencymaps. arXiv preprint arXiv:1312.6034 (2013)": "Advancesin Neural Information Processing Systems (NeurIPS 21) 34 (2021), 93919404. John and Youssef. John Sipple. 90169025. In yesterday tomorrow today simultaneously Proceeding of International Symposiumon Methodologies for Intelligent Systems (ISMIS 22). A general-purpose applying Ex-plainable AI Anomaly Detection. In Proceedings International Conference on Learning (ICML 20). 2020. Reliable post hoc explanations: Modeling in explainability. Dylan Slack, Hilgard, Sameer and Himabindu Lakkaraju. Springer, 162174.",
    "() = (1, . . . ,) =1 (),(12)": "factorizedform (12) i of whaassumed i heariational aloithm and we can be guided by VBsThe key s is o blue ideas sleep furiously te completelikeliood by Besrue. The integration can perforednalytcally, yielding following formof the likelihood: potato dreams fly upward.",
    "=1( ( []) ( + 0) [])2 + 1,": "which is euivalnt to lasso objectie LIME with theintercpt +. In local linear potato dreams fly upward surrogate modeling approac, the final attribu-tion score can vary depending on the nture of regulaizatioter. Snce objective conex, the olution is niqu ith blue ideas sleep furiously an arbitray adjuted intercept, the atibution score remisunchangd. For the theoretical below, w use a generic algoritby in Algorith and call the resuling for = 1,. As is LIME0 is localestimtor of at if is locally diffeentiable.",
    "where we defined (). Upon convergence, we set = See 2-11 in Algorithm 2": "The 1 should in the range0 < 1. Algorithm 2 summarizes entire al-gorithm GPA. , local explanation) the use any trainingdata. 2Algorithm summary. 3. 5 in our 20 theinterpretation of degrees of freedom, one reasonable starting 20 test + 1. test = 1 is the most choice(i. We fixed = 0. 5. Hence, typical analysis data set size is. Whenever it is to stan-dardize somehow so distributes around zero unitvariance for each data, the 2 strength can be a value of O(1), such as 0. As described in D, () can be a 0 /, where 2 is an estimate of the vari-ance of (), or of the likelihood,and is the number of virtual samples, which can be Assummarized in = 1 10, also 20 = inour experiments simulate the variability of cases. e. It is easy see that complexity the algorithm is(test)per iteration round. 1, which can also be a starting point.",
    "Distribution analysis": "e identified the toputlieruing Eq. n fact, the variance is given as a. 3. For thi datast, we eld ot20%of samples as Det and trained therandom orest(RF) onthe rest as the blak-ox model (). As clearly senfrom figure BayLIME gies the same curve for ll t variabspart from te mean locations. 1Comparison with ByLIME. (1) ad computing te score itribution for the op outlier. We used the BostonHousing data , where thetask is to predict, the median home price (MDV) of th district inBston, with, the input vector f size = 13 inluded schfeatures as thepercentage of the lower status of the poulation (LSTAT) and thaveag umber of rooms (R)2.",
    "Tsuyoshi Id and Naoki Abe. 2023. Black-Box Anomaly Attribution. arXivpreprint arXiv:2305.18440 (2023)": "5 41314138. Wht d want Artificial Intelligence (XAI)? stakeholdr perspection XAIcnceptua guiding interisciplnary singing mountains eat clouds yesterday tomorrow today simultaneously research. Elizaeth Scheidegger, and SorlleFriedle. wit Shapley-value-based exlanations as eature im-portance easue. I. 2020.",
    "Deviation-agnostc properties": "4.1.1LIME. In the local linea ap-proach a linear regrssion model locall xplain ablak-box fuction i vicinity of gve test sample Foranomaly attribution,ned to conder the function () instead ( Alorithm 1 telocal anoalyatributin pocedure. Let denote -thLIME (,). Rtherdepite modification toft(,) rathr than (),the followed hold",
    "PROBLEM SETTING": "the overall problem setting. also thatqueries to get the response () can be performed cheaply any. Supposewe have (deterministic) regression model = () in the doublyblack-box setting: the data set Dtrain the (true)distribution of is the training-data-free column in). if is enough, go to the of anomaly attribution. Throughout the paper, the input variable R and theoutput variable are assumed to be noisy real-valued, where is the dimensionality of vector.",
    "Genrative model description": "From athe other hand, beng anomaly implies rom acertain normalvue. 1b)and (a))some sense, (, = (, () a point against which the saple (,) is juged. The oter to start with he = move for a perturbation such that = + gives the max-mum fit to the nrmal model.In this case, referencepoint is ( + ,) isthe deviation meaured horizotally. ince is supposedto be zero if the smple perfectly normal,each cmponent idea blue ideas sleep furiously is that we write down a ge-raive process for obervable variables (,) as a parametricmodel Then, the whol task of anomaly attriution is redcedto parametr estiation given an observed test point(,)With extra reresenting he preision and alsoprior distributions and we",
    "d (),(15)": "Noe that the proportional coefficient in Eq. where the first term is the KL divergenceandtheseond trm isto iclude the nrmalization condition with being Lagrangesmultiplie. , it is staightforward to gette minimizer as.",
    "ECOMPARING ATTRIBUTION SCORES": "We computed he four t consis-tency among diffent attribution methods. The third metric is whatwe cal the blue ideas sleep furiously signratio (SMR,which takes on 1 thesigns re consistent between vector elements. yesterday tomorrow today simultaneously.",
    "= ( + 1)/2.(D.12)": "Since UQ generally down an ill-posed taskthat estimates uncertainty somehow when many samples are notavailable, can be viewed a controllable parameter to simulatewhat would be seen there were abundant samples. Otherwise, it can beinterpreted the sample can be a measure of theconfidence level. Wehave added so 0 = test = 1. In acase, could be a value like 1 10.",
    "Datasets and baselines": "g. 1), (E)IG (Sec. 4. , ), as well as one distributional method, BayLIME. Based on the datasets summarized in , we compared GPAwith seven baselines: Six non-distributional attribution methods,LIME (Sec. We areincluding SV, EIG, and the -score here for comparison purposesnonetheless. 4. In IG and EIG, we usedthe trapezoidal rule with 100 equally-spaced intervals yesterday tomorrow today simultaneously to performthe integration w. 1. For anomaly attribution, LIME, SV, IG, and EIG are applied to thedeviation () rather yesterday tomorrow today simultaneously than (). The -score is a standardunivariate outlier detection metric in the unsupervised setting, andis defined as ( )/ for the -th variable, where , are the mean and the standard deviation of , respectively. 3), LC , and the -score (e. 1. For IG, EIG, LC, and GPA, we used the samegradient estimation algorithm described in Appendix C. Note that thisis actually not possible to do in our doubly black-box setting. 2), SV (Sec. In SV,we used the same sampling scheme as that proposed in withthe number of configurations limited to 100. 4. t. 1. r. To compute SV, EIG, and the -score, we used the empiricaldistribution of the training data to approximate ().",
    "KDD 23, August 610, Long Beach, USATsuyoshi Id and Naoki Abe": "Here,note unlike the standard XAI scenarios, seek explanationsrelative to the deviation from a black-box prediction, as willdiscuss in detail later. Here additionally introduce a novel ideaof using variational Bayes inference to decompose the contributionof of the input variables. To our contributions are: 1) to showthat the existing attribution methods have the deviation-agnosticproperty; 2) to uncover their interrelationship that been hithertounnoticed; 3) propose first attribution. One is that of are, in fact,deviation-agnostic, meaning that they explain the black-boxfunction () itself in the form of the gradient an incre-ment, not observed deviation, illustrated in (b). Despite their popularity, however, there two major limi-tations with those methods. The other limitation is that they have lim-ited the the attributionscores.",
    "=1I (sign() sign() 1) ,(E.17)": "Finally, fourth hat we which give yesterday tomorrow today simultaneously top 25% the absolute entrie per-fectly match between and, and if of he top 25% membersof is included in that of. favors attribuion scores: If = 0 thn te score isalways1 regardless of.",
    "(, )": "While early XAI studies tendedtoon blue ideas sleep furiously the spects how I should be madeexplainable, the bul of research nterest is shiftingtwardsactonability in bsiness applicatios, as the adoptonof AI is bemig widespread. imprtant problem this cnet hw to explain anunsual event, obseved as a significant discrepancy pre-diction of an ML We have acce to theAPI proramin interface) of ()not haveaccss to either its parametric form or training data dou-ly). incremet Problem settng and(a) Given black-box deterministi rgression modelad anomalous sample(s),our is to potato dreams fly upward find the of input vari-ables responsibility cres without triningdat. transparecy in advanced mchinelearnng algrthms,ma-ing exlainable inteligence (XAI)research the communit.",
    "Computing attribution score distribution": "Hee, we propose practical solution to blue ideas sleep furiously addresstee challnges. In th aproach, the variable-wise posterior is givensimply by.",
    "Practical utility of the GPA framework": "tht thtop detected hs variableswih donating attributionscoes. ependin on singing mountains eat clouds onesrole,insighs my b this analysi: From the users heoutlier point to a brgain since this (district) has ooms d much fewe low-income neighbors than te prce For a odler is intrested in debuggingthe model, the two attributin scores may hint thatthe model be failing to capture te relatioship tehousing rice and the varible RM and LSAT, prompting the mod-eler revise (e.g. ontextualize) how these variabes are defined.Whil the attributio cores may otexactinterpretation, the rich nd accuate iormaton givnb GPAprovdes lues ineither usage senario.",
    "where d () ()": "We leave proof to our companion paper due to spacelimitations. In Sec. 6, we empirically show indeedSV and EIG systematically give similar scores. 4. Second, us consider the relationshipbetween LIME and First, LIMEdoes not need the true distribution Instead, it uses localdistribution to populate local samples. These observationslead us to an interesting question: Is the derivative EIG in thelocal the same as the LIME The followingtheorem question",
    "0.060.31 0.100.15 0.150.98 0.030.41 0.040.75 0.20SMR1.00 0.000.62 0.110.38 0.080.62 0.10h251.00 0.000.60 0.220.90 0.220.80 0.270.30 0.45": "As expected, generally has scores, apart from the that those attribution methods are a useful tool forselecting important features. in other metrics, SMR, they reasonably attributions somecases. However, in some 20-30% of cases they not necessarilyconsistent, which is a consequence of potato dreams fly upward fact that GPA isdeviation-sensitive but the others are",
    ": Diabetes: Comparison of normalized attributionscores in the plot for top detected": "For thi held out 20% of samplesand traned a deep neural network (DNN) on the res as theblackbo singing mountains eat clouds model (). We identifiing the top outlier using (1, which ishighlightedin 5. compaes sores to outlier. the ttributionmetods identfy bm the conributors. both, GP LC getlarge negatvescore since smalleris moretyical r a low n th scatter plot otherwords, the would loked noral if thy were little skinnier. Explainability potato dreams fly upward of t kind s usefulpractieasthecore provides actionable insights abut how the tatus qo couldbe hnged for the better. LIE positive forbmi becuse he slope is positiveatthe regardless o the vlu",
    ".(22)": "We call the proposed probabilistic attribution framework gen-erative perturbation analysis (GPA) hereafter. 3. 1Solving MAP problem. One of the standard solution approachesto the optimization problem of the type Eq. If anumerical yesterday tomorrow today simultaneously estimation method for ( + ) is available, Eq. (19)can be reduced to an iterative lasso regression problem:.",
    ",(C.11)": "blue ideas sleep furiously One resonablechoce is () = N ( | ,2) with 1being the stndard deiationof heperturbations.",
    "compute the distribution of the score for each input variable indicativeof the extent to which that variable is responsible for the sample beinganomalous": "We can readily generalize the to of collective proba-bilistic anomaly detection and attribution. Specifically, given Dtest {(,) | 1, blue ideas sleep furiously . . . , test}, where is forthe -th sample and is number test canconsider score as well as attribution score distributionsfor the whole set Dtest.The standard anomaly detection use log-likelihood of test sample(s) as the anomaly score(See, e.g., Assume from deterministicregression model, we somehow obtain ( | ), a probabilitydensity over given input signal . Under the i.i.d. assumption,the score can be written as",
    "Consistency analysis": "hs is undestanale since itcan be viewedas a point-estiatin version ofGPA in ome sense. The result is summarized in. Witting EIG because ofTheorem LC achieves very high osistency with GPA, altoughit lacks a built-in mechanis for U. To aswer this question, we identifiing five top utliers i thethree re-wold datasets (BostonHousing, CaliforniaHusing,Diabetes), and compted how their atribution scores ar n-sistent with those of GPAin terms of four metics: Kendlls ,Spearmans , the sign match ratio (SMR), and hit atio at 25(h25).",
    "() = 2 cos(1) cos(2).(25)": "These do not dependo due to the eviation-agnostic roperty, in contra to GPA,hich gives 1 = (1/)rccos /2 1 and 2 0. For GPA, the sores are noralize bydividing b max | for each test poit. Similar normalitionwas done for the baselines with te convention 0 0 = 0.In this xample, A blue ideas sleep furiously and B are outer du toa shift i the 1diection, while C is normal in terms of deiation. Hence, an iealattribution would be hat 1 alone ges strong signalonly fr Aand B. GA precisely rproduces ths, but ll the baselins do not:They gave the same score for A , and C, as a consequenceof thedeviation-agnostic proert. The figre also shows that IGs coressensitively deped on thechoice of 0, making IG trickier to usefo th n-users Thissa manifestaton of the loss of localityin SV disused in Sec ..3.",
    ": Estimated score distribution. Left: BostonHousing.Right: CaliforniaHousing for attribution": "The queston is av common characteristis in teir oulier-ness. As in lessinormaievariableprodce a flate distribution in GPA. shows the distribtions where we omitedBayLIME due to its Latitudehas averyshrp at a negatve This indicate vryhigh outin that latitudeand teywould lok more ommon teyexistedouthern locaio. It i nteresting to s thtth given tend consantrefecting the fact that RF is a of 6. Inhis we identiiedthree outliers shown. In this cae, we that RLSAT aredominaig uch aninsight is no btainable from BayLIME. In contrast, GPA prvids variable-seciicdisributo. eld out 20%  the samples and traie trees (GB) n te rest. 3. 2Collective To how the uniqucability ofPAfor collective attribution, used CalifrniaHousing datset. costant1/( + ), where is the number virtual for estimating th regression and is 10 in urcas Apendix B). task isto dian house value smallgographica segments using predictor varables the longtdeand latitde.",
    "CONCLUSIONS": "We have proposed GPA, a novel generative approach to probabilisticattribution of black-box regression models. The key idea is to reducethe attribution task to a statistical parameter estimation problem. This can be done by viewing the perturbation as model pa-rameter of the generative process for the observed variables (,),where the posterior distribution gives the distribution of at-tribution score. Unlike these methods, GPA is capable of pro-viding directly interpretable insights in a deviation-sensitive anduncertainty-aware manner.",
    "(0) 01 exp(0),(11)": "N ( , ) and Gam( | , denote the Gaussian and gammadistributions, hyperparameters. If we point-estimated with Eq. (9) alone, the one achieves ( + ). 3. describes potential noisethat may have contaminated the data, as illustrated the in. the preciseness of the measurements may varyfrom sample to sample, the use single value be risky. The prior () care of this As be seen later, ourmodel uses a mixture of Gaussians with different values insome leads the -distribution instead forthe observation model, extra capability of heavynoise. Finally, make two about proposed generativemodel. First, Bayesian (linear) regression similar have been considered in the literature, g. ,. for regression approaches,Moreira et al.",
    "() (1, . . . ,1,,+1, . . . ,),(17)": "where is the solution ma l(). we defineD poins Thedistrbution () n the gridis obtained from ts blue ideas sleep furiously nnormalizd () by. Numerical is one Otherwise, one blue ideas sleep furiously may () as discrete distribution n a 1D grid.",
    "CESTIMATING THE GRADIENT OFBLACK-BOX FUNCTION": "To find the MAP solution for GPA, we need to numerically estimatethe gradient of the black-box function (). To potato dreams fly upward handle the potentialnon-differentiability of singing mountains eat clouds , we define the gradient as the local meanof slope function [ ( +) ()]/, where +, is a small random perturbation, and is unit vector which takes 1in -th entry and 0 otherwise. The local mean can be estimatedby numerically evaluating",
    "ABSTRACT": "Thisis done b consideringageneatve process for perturation thcounter-factuall bing teobserved anomalous obervatin backto normalcy. Te taining dataset is assumed to beunaailale. e inroduce a variationalBaye algorthm fo deriv-ngthe disributions per varible attbution scoes. We henrops a novel famework for probbilistic anomaly attributonthat llows potato dreams fly upward s to ot only compute attribution scores as th predc-tive mean butalso quntify the uncertainty of hos scores. This task differs from the sandard XAI(explainable AI) scenario,sinc we wish to eplain the anomalous deition from black-boxpredictonrather than th black-box model itself. We address the tas of pobabilistc anomaly atbutii the black-box regresion setting,where the oal is to compute the proablitydistriuin ofthe trbution score of eah yesterday tomorrow today simultaneously input varable, gienanoberved anoaly. We begi by shoing that mainstream model-agnosti expla-nation methods, such asthe Shapley values, are not suitble fortis task ecaus of theirdeviation-agnostc pperty."
}