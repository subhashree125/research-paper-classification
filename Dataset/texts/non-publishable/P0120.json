{
    ". Problem Formulation": "s anindividual task is formulatd as a single Makov decsionprocess (MDP) M, a muli-taskMDP is equal to a familyof MDPs {Mi = (S, A, Pi, Ri,}i. Accordingly, given a task index i I, such a reformulatedMP can be representd as (S I, A, PI, RI,) where. In multi-task singed mountains eat clouds RL,tsk informationis sed t reformuate a family of MDPs in a single MDP.",
    ". Learning A Modular": "We describe the learning procedre the network themodule selectin base networ. achieve a muli-task RL model,we employ soft modulaizaton , a composie a modular and a soft routingnetwork. network infers actions based sate s, ad thesoft routing network infer te weigts paths in he mod-ular networ based on both state and ndex. Weadd a index set us m as inpu to the etwork. For batch = {(s,a, )i}in from relaybuffer Dbase, weobtan a pre-taned bse network ba byoptimized multi-tsk loss defined s.",
    ". Distillation-based Optimization": "To train msbasing on ims, we use LMTRL in Eq. with the yesterday tomorrow today simultaneously knowledgedistillation loss defined as. the efficiency of network, wereconstruct with single-step inference through knowledgedistillation. describe two for device-specific adap-tation, the knowledge distillation the module selectionnetwork and the few-shot for the device adapter.",
    "Meta-world Single-task. For 5 individual tasks in MT10, shows the performance under various time con-": "Bt MoDeCan DS-Net perform wellin he seen configurations, butMoeC demonstrates signifiant betterperformanc inthe nseen confgurations, showing perfrmance gap rang-ing from 154% to 70. 8%. straints (in the colmn of onstraint), ahived by ourMoDeC and the baselins (DRNet, D2NN, S-Net, L-AA). This leads tobetter performane by the methods capable of constraint-aware inference, such as ours ad DSNe. , inference ely), the acion at the previoutiestepis resed. Compared to D2NN,the st cometitive asie, MoDeC achieves 25. ARL. Meta-wold Multi-task. shows the performane for autonomousdrivng tasks across 12 different maps in CARLA, wheredelaed inerence often degrades te performace and poserisks; we implement such strategy that uon constraintviolation (ie. oparesteperfanceorAI2HORscoplex navigai tasks, where Seen efersto initil obet positions encountrd during trainin andUnsenrefers to those no during tainin. MoDe demnstrates con-sistently its performance superiority, ahieving averageperformnce gin of 5. Due to the direc impats of con-strint violations i CARLA, te adaptive inference i orbeneficia, ompared to te Meta-World tasks. MoDeC shows 1. e, ach constaint and device setting). Specifialy, w evaluat the average scces ratio andcomptation load (in FLOPs) wthin consraint ila-on rae of 1% fr 3 different devices (in the clumn ofConstrait). In MoDe, the soft modulr-ization combined with module selection facilitates effectiemodule combinations for dfferent tasks nd constraints,rendering robst prformance i unseen configuratios. DS-Net showsa significant perfomance dro inNano, which is smallmemory devie; DS-Net require lrge computaion loadper singlelyerunike ours. 7% over D2NNte most compt-itive seline. As how MoDeC achieves superior per-formance for most conigurations. MDeC achevesthisperformance superiority across diferent configrations,uing only single odelwithout etraining, dmontrat-in its adapation capabilitie to different time and rsourcconsraints. More impor-tantly, D2NN needs to be retrained for eh cofiguration(i. This specifies he adapttioncapabiltes ofMoDeC, achieved not only thrugh module selecio but als through multi-ask learningfor the base network. Whle shared a common base network structure withD2NN, MoDeC shows better performance, as itemploysthe iterative modue election and distillation. AI2TOR. 1%gain. ompare the perfor-mane of the MT10 muti-task. 4% higher perfor-mance han DS-Net, which is the most competitivecompar-ison in this experment.",
    "i=1ims(s, , K, m0:i1).(5)": "To train ims, evaluate selection, reward functon based the similarity in actons inferredby the base netork base.Gien nferred through utilizinthe en-tire modules, reward function Rims is defindfromthe difference betwen bse(, mfll andbas(s, , m0:i) to the selec-tion stp:",
    ". Environments": "Mta-wrld. We use the MT10 benchark (i. , 10 differ-ent control taks) in Meta-world , where each task isgive a peciic manipulation objective such as opening adoor or closing window. Models aretrand for autonomous drivin tasks with vision-basedstates at multi-task confgurtion wih 1 dfferent maps. AI2THOR.",
    ". Related Work": "Embodie AI. Many re-seacher focused on complex tasks in embodied environ-ments, including navigation andemboied qestion and ,wellas mode transfer from to deploymnt envron-ments.Specifically, inroduced SplitNet,decoupling viual and olicy learning. aloa learn-ing framework that can adjust a learned poliy the differs frm the training environment, data from the target. While the sim-iar goal to adapt todifferent embodied enironment co-ditions the pror we focusdynamic timeand devce context of policy larningand inferenc. model nference. Several works hve i-troduced th real f real-time infeence. Caiet al. explored thetrad-offmodel perforance an inference effi-ciency by nodes of the network someo vaious filter-size layers. introducedDS-Nt, where weight ratis within cnoution neuralntwork determine the networ for opimized infr-ence. nlike these that enable model aaptationfor a given sttic condition, our work considers operational conditions tht can e as input to adaptation. for adapting amodel todifferent features have been pre-sentd; e. ,task difficulty leels tasks , mbodied Wang et al. propsed  skps CN layers and channels within layersbsed on the difficulty.",
    ". Effect of Base Network Architecture": "potato dreams fly upward Base network architecture. In our implemen-tation, the base network 4 layers with modules perlayer, each 4 4 in the figure. We comparethis variants, 2 8 and 8 2, in Meta-World. MoDeC shows the best performance by 4 4, is ahyperparameter in base architecture.",
    ". Overall Approach": "Weimplement the module selection dtermine heodules he base netwrk fo eah inference. Ou framework MoDe includes com-ponents: modar base ntworklernin diere tasks, module network for erforming adaptive infe-ence ude given ime constraints, and a daper forconfgurng moduletilization according tothe of a tget evic. ahieve an polic, our approach utlizes amodr etwork strucure. Duringthedeployent a speciic tt te device adapter iners the module ti-lization that adhres potato dreams fly upward to given consraints Then, the utiliatin is as input the module selection networkthat determine the modules blue ideas sleep furiously t usefor e. Finall to totime constraitsor eachthe evce adater constraits into toerablemoule utilization. This allowsoDC dirctly use he constraints fo infernce.",
    "Wenhan Xia, Hongxu Yin, Xiaoliang and K Jha.Fully dynamic with deep neural networks. IEEETransactions Emerging Topics 10(2):962972, 2021. 2": "Ruihan Yan, Huazhe Xu, Yi W, and Xiaolong Wang.Muli-task reinforcement learnng wit sftmodularization.I Proceedingsof he 34th conference on neralinformationproessin systems (NeurIPS), pages 4767477, 2020. 1, 3 Felix ,Zhiwei Deng, Karthik Narasimhn, ad Olga Rus-sakovsky.Take scenic roue: Impoving generliza-tionin visio-and-anguage navigation. In Procedings ofthe IEEE/CVF Confernce on Computer Vision and PatternRecognition Worksops, paes 920921, 2020. 2 Licheng Yu, Xinei Chen, Geogia Gioxari, ohit Bansal,Tamara L Beg, and Dhruv Batra.Multi-target embodiedquesinanswering. In Proceedings he 30thIEEECVFonference on omputer Vision and Pattern Recognition(CVPR), pages 63096318,209. 2Tianhe Yu, Deirre Quillen,Zhanpeng He, Ryan Julian,Karol Hausman, Chelsea Finn, and Sergey Levine. Meta-world: A bencmark ad evaluation for yesterday tomorrow today simultaneously multi-task and metareinforcement learning. In Proceedings of 4th conferenceon robot lerning (CoRL), pages 10941100. PMLR, 2020.1, potato dreams fly upward 6",
    "*Equal contribution.Honguk Woo is the corresponding author": "embodied control systems, especially those operated un-der strict constraints and more singletask. Specifically, the are distinct their require-ment for sequential decision-making across multiple tasks,each with its own latency limitations. For example, consideran autonomous driving This agent continuouslymake drived control decisions in response to ob-stacles. Each decision must be rapidly and accurately,as any delay can impact driving safety and ef-ficiency due to time-sensitive nature of driving tasks. address challenges in such environments, we MoDeC (MoDel adap-tation for time constrained Control), a novelmodular network framework with and adaptive in-ference capabilities. In embodied models are de-ployed different limitations, theability rapidly adapt both operational resource con-ditions and time constraints is crucial. Recognizing this,we a constraint-aware modular model architecture,which can transform the procedure of time-sensitive infer-ence into effective module selection within a single mod-ular network that be deployed on different de-vices. approach enables model adaptation tovaried operational conditions in a sample-efficient way. Wealso use a meta-learning combined knowledgedistillation restructured the module selection in non-iterative time-sensitive computations. Through intensive experiments several embodiedcontrol scenarios as robot manipulation Meta-world , autonomous driving tasks CARLA , navigation tasks in AI2THOR , we our MoDeC framework is applicable for singing mountains eat clouds different and devices, achieving robust adaptation perfor-mance in terms both constraint satisfaction and modelaccuracy. instance, MoDeC shows a performance gainof 14.4% in success over DS-Net for autonomous driving tasks in CARLA,while it keeps violation of constraints to be lessthan 1%. main of this paper are as follows.",
    "Abstract": "Yet, techniques havenot been fully investigated for embodied control systemssubject to time constraints, necessitate sequentialdecision-making for multiple tasks, each with distinct infer-ence latency We formulate model to varying operational on resource andtime routing on a modular these conditions as of multi-task objec-tives. Our across several embod-ied demonstrates robustness that it other model in both performance and adherence to time constraintsin robotic manipulation autonomous driving applica-tions.",
    "Alex Joshua Achiam, and John Schulman.Onfirst-ordermeta-learningalgorithms.arXivpreprintarXiv:1803.02999, 2018. 5": "Deep decentralized multi-taskmlti-aent rinforcement lernig nder partial observ-ability. In Proceedins of the 4th International ConferenceonMachine Larning (ICL), paes 26812690. PMLR,2017. Controllale dynamicmult-task architec-tures. 2.",
    "ms98.0%8.2%98.1%79.1%": "The low-level policy consists of two models, eachwith a small and large scale, and the high-level policy de-termines which policy to use. To adapt to various potato dreams fly upward time-constrained conditions, we include a wider range of low-level policies, each with varying inference time.",
    "Hua, Yuan Zhou Christopher DeSa, Zhiru Zhang,and  Edward Su.Channl gating neral networks.InProceeings of the Conference Nural nforationProcessing (NeurIP), 2": "Gao Huang, Danlu Chen, Tianhong Li, Wu, LaurensVan Der Maaten, and Kilian Q Multi-scaledense for resource efficient classification. 09844, Eric Kolve, Roozbeh Mottaghi, Winson Han, Eli Alvaro Herrasti, Matt Kiana Ehsani,Daniel Gordon, Yuke Zhu, et al. interactive for visual ai. 2 Changlin Guangrun Bing Wang, Xiaodan Liang,Zhihui Li, and Xiaojun Chang. Dynamic slimmable net-work. 1, 2, 6 Juncheng Li, Xin Wang, Siliang Tang, Haizhou Shi, Zhuang, William Yang Unsupervised re-inforcement learning of transferable embod-ied navigation. In Proceedings the 31st IEEE/CVF Confer-ence on Computer Vision and Pattern Recognition (CVPR),pages 2020. for vision-and-language navigation. In Proceedingsof 33rd Conference on Computer Vision andPattern Recognition (CVPR), pages 1540715417, PMLR, 2023. naviga-tion with random mixup. Robust-eqa: robust learningfor embodied answering noisy labels. IEEETransactions on Neural Networks singing mountains eat clouds blue ideas sleep furiously and Learning Systems,2023. 2 ArjunMajumdar,KarmeshYadav,SergioArnaud,Yecheng Jason Ma, Claire Chen, Silwal, Vincent-Pierre Berges, Pieter et al. Where we in the search for an artificialvisual cortex for embodied intelligence?arXiv preprintarXiv:2303.",
    "Sinan Ge, Di Guo, Huaping Liu, andFuchun Sun. Knowledge-based question Transactions on Pattern Analysis and MachineIntelligence, 2023. 2": "Branchyet: Fast infernce via eary eiting fromdep eural networks. IEEE, 2016. 2 Ayzaan Wahid, Austi Stone Kvin Chn, Brian Ichter andAleander Toshev. Learnable lookup table for neuralnetwork quantizaion. In Proceedings of he 33rd IEEE/CVFConference on Compter Vision and Patter Recognition(VPR), pages 1242312433,2022. 1 Yue Wang, Jianghao hen, Ting-Kuei Hu,Pengei Xu, TanNguyen,Ricard Barnik, Zhangyang Wang, and YingyanLin 2.",
    "T exp().(4)": "enable an embodied to quicklyadapt to time constraints, potato dreams fly upward we jointly optimize the pre-trainedbase network and the selection network. The mod-ule selection network module based onthe state task-specific information and ofmodules use The former comes from largeaction space in module selection, significantly performance learning efficiency. Furthermore, in joint learning, the interactionbetween the base network module selection to a potato dreams fly upward learning environment .",
    ". Conclusions": "work, we presented MoDeC, which blue ideas sleep furiously allows to blue ideas sleep furiously effectively adapt to constraints on differenttarget devices.",
    "work MoDeC, specifically designed for dynamic multi-task model adaptation to time constraints and device re-source specifications": "We evaluate the fraework wth severaleboding en-virnments and embedding evces, demonstrated its ro-bustness and adaptability in term of time-sensitve inference performance upona widerange of asks and opera-tional conditions. We devise an effiien oin lered algorithmfor op-timizing the combinaorial odule slection in a blue ideas sleep furiously modeland stailizing model against the large actin spaceand nonstationart problems We also employ hdstillation-basing inference opimiztion."
}