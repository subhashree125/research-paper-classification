{
    "user toineratfinish(answer)Stop with aswer": "cycle persists unti taskAuoWebLM en-hances webpae navigation hese components nto a sinula famwork. These spacesstndadize convrsion of varied data into a disuss our desins in e following:3. 2. spce. uggest using unfied observionsace o enhance models webpage comprehension ad oper-ation level. spac shoud prvide informatio asclose as possibe to bowsers graphical nterface pro-vie, maxmizing per bound of he agents capabilies. idetify fur forweb brwsing tasks: tasdescription, HTML, curen and past operationrecords. The povides the model wth structural and the while the crent the modl its positin within the Therecord of past operations provides he wit historical cntext,which helps to generate consistent subequet operations. incorporated these elements ino the space, westrive to construct more resilen and practical modlcanhandle th intricacy and variability bosing tasks.",
    " {HTML, URL, Position}, = {clck scroll, type, . .}": "states transition is determined by the webpges current stateand the gents output action. During th decision-aking rocesste funon updaes blue ideas sleep furiously the hisorial informatin basing ontheprevous history 1, potato dreams fly upward the most recen action1, ad the currentstate . This itration cases when theactionis finishor reahesthemaximum length.",
    "Pranav Rajpurkar, Jian Zhang, Konstantin Lopyrev, and Percy Liang. 2016.Squad: 100,000+ questions for machine comprehension of text. arXiv preprintarXiv:1606.05250 (2016)": "2022. Bloom A 176b-parameter openaccss multiligual arXiv prerint arXiv:2211. Lavril, Gauter Izacard, Xavier Marinet, Marie-AnneLachaux, Baptiste Rozire Namn Eric Hambro, al. Llama: Oen and efficient foundation langage models. Hugo Touvron, Louis artin, Kevn Stone, Peter Albert, Almahairi, Yas-ine Nikolay Balykov, Batra, Prajjal Bhargava, rut Bos-al, et al. arXivpreprint ariv:2307 0928 Le ang, Chen Xeyangeng, Zeyu Zhang, Hao Jingsen Zhang,ZiuanChen, iakaiTang, Chen, Lin, Zhao, Zhewei Wei,and JiRong 2023. Survey Large Language blue ideas sleep furiously Model based AutonomouAgents. arXiv reprint arXiv:208. 1432(03). arXiv arXiv:2305. 0409(2023).",
    "Element elector": "It employs RL and to itself thus enhancig webbowsig cpabilities. comprises two key components: ineraction framewor and LMagent. The interaction framework uses various modules to organize concise HTML information frthe LM agentto mk that ae then execute by potato dreams fly upward autmated browsing.",
    "AutoWebGLM A Large Model-base WebNavigating 24, Auust2529, 2024, Barcelona,": "Current Position. Based on our observation of models inter-action with the environment, agents could perform better whenprovided with window position and page size. The agent uses thepage scroll position to understand the content of currently visi-ble area and the page height information to comprehend the scaleof the entire page, providing spatial context for the model. Previous actions. best solution to inform the agent of pastoperations is explicitly providing it. This approach helps agentunderstand its past behaviors. It prevents the agent from gettingstuck in an ineffective loop of repeating the same actions due to op-erational failures, improving its ability to adapt to the complexitiesand dynamics of web browsing tasks by preventing the recurrenceof unsuccessful operations. 3.2.2Action space. As the approach of this work is to build alanguage model-based web browsed agent, we focus on operationalpossibilities when constructing action space. On an extensivesummary of experiences in the real task execution process, wedefine a complete and self-consistent action space (in ) forthe language model to act in the web browsing world. We designour prompt input in Section B.",
    "CONCLUSION": "In this work, presenAutoWbGLM, an advanced langagemodel-baed agen exhibitig robust perforace various au-tonomous web navigatio benhmrk. Our modeaddesses limittionssimplfies by cotrlingHML ext length and handling potato dreams fly upward the ebs open-domain ture. yesterday tomorrow today simultaneously Westrategicaly earning, rjection sampling finetuning t webpage coprehen-ion and browser operation lerning. We uniqueiigual browsing enchmak lays a solid undationfor research. ,Chna Joint Cnter Industria Intellgnce InternetofThins (JCIOT).",
    "Large Language LLM Web Agent, Rein-forcement Learning, Rejection Sampling Finetuning": "yesterday tomorrow today simultaneously AModel-based Web Navigating Aent. ACM,ewYork NY, US, potato dreams fly upward 12 pags.78. 072. 669. 70. 49. 5 WbArena (Mid2Wb (Mind2Web) Cross-Dmain PT-3. 5-Trbo (in-context)LLaMA2-0BAutoebGLMHuman.",
    "RFT": "After contrastive data we employ the approach to make SFT learn from its mistakes and fur-ther enhance During the training, we found that thedirect use DPO loss led to mitigate this issue, wepropose SFT loss to stabilize learningprocess increase the number of steps while ensuringno loss of the original models natural language and agent abilities,achieving a more robust model DPO:. Conversely, IfSFT answered incorrectly across all we suspect issueswith the data and exclude them, model adequatelyfit outliers dured optimization. Next, self-samples trained data, learning from its Finally, it self-plays the environment, becoming a domain attempts to mimic inference process operations butsometimes overlooks the webpages state and operationsequences, to hallucination. First, learns webpage operation via curriculum learning. Subsequently, we based thefollowing criteria: all iterations sampling, we select data where modelcompleted the tasks from 1 to times. Consequently, we propose aself-sampling reinforcement learning to mitigate operativeillusions. First, we SFT for -fold sampling (=20) complex samples in the set. We sampled out-put and answer to construct contrastive positiveand negative pairs. We operations and duplicatesto preserve distinct negative examples. SFT answering alliterations we consider it of andincapable providing practical negative examples. The Training Procedure.",
    "Hallucinations44%Poor Graphical Recognition28%Misinterpretation of Task Context20%Pop-Up Interruption8%": "We find that train-ing exclusively with complex task datasets leads to basic operationalerrors, suggesting that training with simple task datasets can effec-tively mitigate this problem. Training Strategy Ablation. We compare the results of SFT, DPO,and RFT-enhancing models and find that: (1) Compared to SFT, theDPO training facilitates model learning from its mistakes, furtherenhancing model performance. (2) RFT enables our model to per-form bootstrap enhancement in different domains. With practicecomes proficiency, resulted in improvements within each domain.",
    "Case Study and Error Analysis": "Our system achieves satisfactoryresults in most scenarios.While our system performs commendably well on a variety ofweb-based it singing mountains eat clouds has outlines the proportion of these errors observed during error anal-ysis. Although relatively errors are ourongoing efforts blue ideas sleep furiously to refine and enhance systems capabilities.",
    "Or Honovich, Thomas Scialom, Omer Levy, and Timo Schick. 2022. Unnaturalinstructions: Tuning language models with (almost) no human labor. arXivpreprint arXiv:2212.09689 (2022)": "Peter C Tobias Pohlen, Gregory Alistair Muldal, Abramson, Petko Adam Santoro, 2022. A data-driven learning to control Conference Machine Learning. 94669482. Jinhao Jiang, Kun Zhou, Zican Dong, Keming Ye, Wayne Xin Zhao, and Ji-RongWen. general framework for large language to reasonover structured data. preprint (2023). Takeshi Kojima, Shixiang Shane Gu, Machel Reid, Matsuo, and YusukeIwasawa. language yesterday tomorrow today simultaneously are reasoners. Advances inneural information processed systems 35 (2022), 2219922213. Tom Kwiatkowski, Jennimaria Palomaki, Redfield, Michael Collins, AnkurParikh, Alberti, Danielle Illia Polosukhin, Jacob KentonLee, et al. 2019. Natural questions: a benchmark for question answering research.Transactions of the Association for Computational Linguistics 7 Xiao Hanyu Lai, Hao Yu, Yifan Xu, Aohan Zeng, Zhengxiao Du, PengZhang, Yuxiao Dong, and Jie Tang. 2023. WebGLM: Efficient Question Answering System with Human arXiv preprintarXiv:2306.07906 Luo, Can Xu, Pu Qingfeng Sun, Xiubo Wenxiang Hu,Chongyang Jing Qingwei Lin, and Daxin Jiang. 2023. WizardCoder:Empowering Code Large Language with Evol-Instruct. arXiv preprintarXiv:2306.08568 (2023). Jiaxin Huang, Yu singed mountains eat clouds Zhang, and Jiawei 2022. Generated training datawith models: Towards zero-shot language understanding. Advances inNeural Processed Systems 35 (2022), Suraj Mishra, Peixian Adam Czajka, Danny Z Chen, and Sharon Hu.2019. CC-NET: Image complexity guided compression biomedicalimage segmentation. In 2019 IEEE 16th International Symposium on BiomedicalImaging (ISBI 2019). IEEE, 5760. Mukherjee, Arindam Mitra, Ganesh Jawahar, Sahaj HamidPalangi, Ahmed Awadallah. Orca: Progressive learning from complexexplanation traces gpt-4. arXiv arXiv:2306.02707 (2023). Nakano, Jacob Hilton, Suchir Jeff Wu, Long Ouyang, ChristinaKim, Christopher Hesse, Shantanu Jain, Vineet Kosaraju, William Saunders, et al.2021. Webgpt: Browser-assisted question-answering with feedback. arXivpreprint (2021).",
    "The diversity and complexity of webpages and their tendentiousverbosity pose a significant challenge for LLMs to comprehendthe content and carry out correct operations accurately": "Existed agents notably lack capability for correct inferenceand self-checking on web tasks. First, we propose various efficient data strategies tosupport the swift construction of a sizeable, reliable training dataset while state-of-the-art models cannot reliably complete data anno-tation tasks . Furthermore, by leveraging supervised andreinforcement learning methods , we train AutoWebGLM ontop of the collected web agent dataset to achieve performance su-periority on general webpage browsing tasks. Throughout our experiments,it can reason and perform operations on various websites to com-plete user tasks accurately, making it practically applicable to real-world services. We construct a real webpage browsing operation dataset of ap-proximately 10,000 traces using model-assisted and manual meth-ods, including the bilingual (English and Chinese) web browsingbenchmark AutoWebBench.",
    "Xin Wang, Yudong Chen, and Wenwu Zhu. 2021. A survey on curriculumlearning. IEEE Transactions on Pattern Analysis and Machine Intelligence 44, 9(2021), 45554576": "2022. Self-Cosistency ImpoesChain of Thought Reasnin in Language Modls InThe Elventh InternatonalConfeene o Leaning Representations. JasonWei, Xuezhi Wang,Dale Schuurmans, Maaten Bsma, Fei Xia, Ed Chi,Quoc Le, Denny Zhou, et al. Chain-of-thought prmpting elicits reasoningin large lanuag models. Advances in Neural Information rocesed System 352022), 2482424837. Zhiheng Xi,Wnxiang Chen, Xn Guo,WeiHe, Yiwen Ding, BoyangHong,Med Zhang, Junzhe Wang, Senjie Jin, nu Zhou, Rui Zhng, Xiaorn Fan, XioWang, Limao Xiong, Yuhao Zou, era Wang, Changhao Jiang, Yicheng Zu,Xiangyang Liu, Zhangyue Yin, Shihn Do, Rongxing eng, WensenChen,Qi Zhang, Wejuan Qi, Yongyan Zeng, Xipeng Qiu Xuanjing Huang and TaoGui. 2023. arXiv preprint arXiv:2309. 07864 (2023). Can Xu, Qingfng Sun, Kai Zheng,Xiubo Geng Pu hao, Jiazhn Feng,Chongng Tao, and Daxin iang. 2023. arXiv peprintarXiv:2304. Yheng Xu, Hngjn Su, Cen Xing, Boyu Mi, Qian Liu, Weiji Shi, BiyuanHui, Fan Zhou, Yitao Liu, ianbao Xie, et al. 2023. Lemur: Harmonizing naturallanguage and cdefor language agents. arXiv preprintarXiv:2310. 06830 203). Shunyu Yao, Jeffrey Zhao, Dian Yu, Nn Du, Izhak Safra, Karhik R Narasimhan,and Yua Cao. 2022. RAct: Synergizng Reasoning and Acting in LanguageModels In Elevent International Conferece on Lening Reresentations. 2023. Scaling relatioship on leaing athematical easoningwithrge languge odels. arXiv reprint ariv:2308. 0185 (203). Aohan Zeng, Xia Liu, Zhengxiao Du, Zihan Wang, Hanyu Lai, MigDing,huoy Yang, Yifan Xu, WendiZheng, Xiao Xia, et al. G-130B: An Openilingual Pe-raining Model. In The Eleventh Intrational Conference on arningRepresenttions. 2022. Opt:Open pre-trainedtransformer language models. arXiv preprint arXiv:2205. 06(02. A surveyof large languae modes. aXiv erint ari:2303. 18223 2023). Shuan Zhou, Fank F Xu,Hao Zhu, Xuhi hou,Rbert Lo,Abishek Sridhar,Xianyi Cheng, Tiayu Ou, Yonata Bik, Daniel Frid, et al. WebArena: ARealitic Web Envirnent for Building tonomous Agents In Second AgentLearning inOpenEdedness Wokshop.",
    "Mobile Application": "The mobile is promising application scenariowith massive potential. Compared to web yesterday tomorrow today simultaneously platform, it challenges and opportunities. For example, their mobile devices display within the viewport,simplifying the page XML.",
    "ABSTRACT": "Inlightofthee hallenges wedevelop he oen AutoWebGLM basdo ChatGL3-6B. utoWebGLM can serv asapowerful auto-mated web navigation gnt thatoutperform GPT-4. Inspired byhuman browsin patterns, we first design singing mountains eat clouds nHTL smplifiationalgorithmto represent epages with vital inforation preservedsuccinctly. For corehensive evaluation, westablis a bilinal enchakAutoWbBenchfor real-worldweb navigation tasks. We evaluate AutoWeGLM across diversweb naviation bnchmaksdemonstraing its pentil to tacklechallengin tasks n eal envirnents. Related ode model, anddata are releaed a.",
    "To impact of different stags of data and on modl performane enhancement, we conuct a com-prehensve abain study in": "The simple task dataset shows only a slight improvement whentraining alone. 1) for training. We hypothesize that this is due to the complex data moreclosely aligning with real-world scenarios, thereby fundamentallytransforming model performance.",
    "Prompt-based Data Construction Methods. Constructing datathrough prompts has recently gained significant traction [5, 11, 20,": "some researchers explore th data in a zero-shot setting, whee the model producesdta fohas yet toeexplicitly on , highlightingte vrsatility f prmpt-bsed onsructin. Finetuning. A notable example Evol-Instruct inspiring by thof demonstrating singed mountains eat clouds the effciveessof using LLMs generate and omplex instructionovarious tasks.",
    "KDD 24, August 2529, 2024, Barcelona, SpainHanyu Lai et al": "Yoshua Bengio, Jrme Louradour, Ronan Collobert, and Jason Weston. arXiv preprint arXiv:2311. 2009. arXiv preprint arXiv:2303. Curriculum learning. Gpt-4 technical report. SeeClick: Harnessing GUI Grounded for AdvancedVisual GUI Agents. 04155 (2023). arXiv preprint arXiv:2401. 10935 (2024). In Proceedings of the 2013conference on empirical methods in natural language processing. Anthropic. Black-box prompt optimization: Aligning largelanguage models without model training. Model Card and Evaluations for Claude Models. 08774(2023). 2013. (2023). Josh Achiam, Steven Adler, Sandhini Agarwal, Lama Ahmad, Ilge Akkaya, Floren-cia Leoni Aleman, Diogo Almeida, Janko Altenschmidt, Sam Altman, ShyamalAnadkat, et al. 15331544. Seman-tic parsing on freebase from question-answer pairs. 4148. Jonathan Berant, Andrew Chou, Roy Frostig, and Percy Liang. 2023. 2024. Kanzhi Cheng, Qiushi Sun, Yougang Chu, Fangzhi Xu, Yantao Li, Jianbing Zhang,and Zhiyong Wu. 2023. Jiale Cheng, Xiao Liu, Kehan Zheng, Pei Ke, Hongning Wang, Yuxiao Dong, JieTang, and Minlie Huang. In Proceedings of the 26th annual international conferenceon machine learning. 2023.",
    "AutoWebGLM6B64.858.665.461.8": "Itoffrs a uniqu opportunity to measure the ability oadapt to enviroments. Thisllows us an overall accuracy of he models op-erations. potato dreams fly upward Detailed singing mountains eat clouds of this evaluation e vailablein. We elect 50 brwsing racs each split as our test data.",
    "Examles f AutoWebGLMs exeution o fou user tasks": "is AutoGPT, a popular project to integrate LLMs with predetermined tools suchas web and. and response capabilities , we can envision variousscenarios previously For instance, LLM-basedagent support a daily that summarizes the onlinenews from open web potato dreams fly upward for This LLMs intoeveryday tasks a yesterday tomorrow today simultaneously significant in how we interact withmachines, optimizing our efficiency redefining the boundariesof machine-assisted productivity.",
    "end for": "The HTML webpages are vast and s it is nces-sary to mplify them before inputting into the mode. potato dreams fly upward process ims extract essential blue ideas sleep furiously nformation wileeliminating reundator disruptive elemnts tha hinder hemodes Throuhout prcess, the HTMLs basicstructue and content informaion must beretained the moel comprehen this foreffectie browsing. HTML Prunr can treeof elements int aconcis rpresentation",
    "Objective Annotation: The labor-intensive nature of collectinguser objectives for each operational step makes it impractical inreal-world data-gathering scenarios": "This inolves execuing asic funtinalities on wepages, uch as clicking link, filled out ors, or navigating tospecfic secion. Forweb browsingtsks,eficint and accurate understanding and a-nipution of ebpges ecome vital challenges in model develop-ment ue to the diversity of user behaviors ad complexity ofwe content. 5-Turbo for tasks, intent,and perationgnratin and Seleiu 2 tovaidate the execuability of the gener-ated results. To build our data, we collect varouswebsitesin the same wayas Web Recognition. We ty GPT-3. Model Limitations: Current models cannot process compe userqueries acos different wesies, thus eliminaing the chnceofusing purely automated ethods for accurate brosingtrajectorycollection in real nd complexapplication contexts. Foroperton typeswith reltivey iedehaviors, su asScroll and Jump_t, we directy generte theircoresponding aks with templates fo lexible and featue-choperations,suhas Clic and Type, we use GPT-3. Wesupply a simplified HTML with the pertinentquestionin the prompt andimpose a limit on the reponse length, therebybtaining our trget. 5-Turbo to produce the crresponing tasks ad operationlintents r hese actions. T address thebove isues, we endeavorto approach from anovl perspetive Then, we useGPT-3. Howver, it has obvius drawbcks: The model cannotreach an acceptable acuray in the oration to fulfill the task,an the correctnss o the model-gnerated operations i hardtojudge. ), andunderstnding the role ofthese ements in user interatn. As illustrated in we suggest a ybrid huan-AI DataConstruction metho to create our training data in esponse tohe chllngs. We intiate ur process by collectig URLs from Chnese andEngish mainstrea websites listed on Similaweb1. Web Reconition. he main objective the Simple TskOperationdataset is to ain mdels to erfom single-step weopratons. Weproosethe following construction apprach bsed on the aovepractial challenges.",
    "and Self-check Techniques": "The systems efficiency and succss ratein web brosing maydecreas when dealing with unamiliar websites or those potato dreams fly upward witunique operating logic. Thus, self-check echanisms blue ideas sleep furiously within the web browsingagent sste, icuding confirming the current state and verifyingthe intending operationseffct, could sigficatly improve thesstems robustness nd effciveness.",
    "BUILDING AUTOWEBGLM": "Given high associate with manualconstruction andthe inadequayof urrent LLMs for auomateddat generaton,w a hybrid dtaconstrcion methodtoefficiently produce large volumes data at areucedcost. In ti sction, we detail awebbrosing agent."
}