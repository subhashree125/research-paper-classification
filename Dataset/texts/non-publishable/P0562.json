{
    "the two proposed innovations. The combination ofthese innovations constitutes our PICA method": ",. g. We attribute this to factthat our approach still has limitations in generatingconsistently responses, indicatingthat the ICL vector encapsulate theinformation provided by the demonstration. This im-provement is to our progressive genera-tion strategy, which successfully saves a substan-tial amount of time by discarding the , page (Kwon et al. When compared to SFT or RLHF mod-els, our approach demonstrates superior perfor-mance on the dataset, indicating SFT and methods. PICA is comparable to the alignment tuningmethods. As shown in our methodoutperforms zero-shot vanilla baselinesacross three models on On the dataset, our PICA surpasses the tuning-free baseline in the majority of aspects. This supports the widespread hypothesis thatalignment may models forget someof their knowledge (Wang al. , achieving a5. safety, our method surpasses but does notexceed RLHF, indicating that ICL rela-tively safety alignment. Analyzing the speedup shown Ta-ble 1, method significantly reduces the timecost comparing to ICL (e. On other hand,with strong models Llama2-13b or Mistral-7b, the performance of PICA reach 90% ofthe performance of GPT-3. Comparedto regular ICL, our method effectively factuality, and However, in terms of clarity depth, our methodshows a minor decline. Conversely, in of clarity, depth, andengagement, our method lags slightly, SFT RLHF have an advantage in high-quality response styles over ICL.",
    ": KL-divergence of response token distributions enumerative instructions Llama2-7b and Mistral-7b": "even thoughthe sepator token distribution the Tke Rank remains low. Th op Token rests shown in Fig-ue 1 wherewe findthat tokenswith larg KL-divergene diference typicallyalso have low Tokn Pob. further sup-ports our understadng role play ICL. Simiar to the result of TopToken Rank,the prdcte separator token roa-bilityis indicating that emonstration wil th selection ofeparatr token. we observe similar paterns acrossTopToken Rank,and Top Token Probmetrics, minor This the generalizablity and nivrsaiy of ouunderstandig ofth mpact o demonstrations.",
    "Human Evaluation": "We randomly ame examples each fromthe alpaa-eval ust-eval atasts, presentingtheespnse generated b PICA thsefrom the SFTor yesterday tomorrow today simultaneously models to cmputersciencegradte serve annotator. Weasked th annotators to chooe wich response wasbeter or if i a tie. shows the results,which lign with the ealuation.",
    "ACase Study": "As a result, the FTmodl received low in helpfulness (3) ndengagement (2), a reasonale clarity score(4. The ICL model i reltivelybette in factuality. Our PICA mode proided a omprehensive andaccurate esponse, colonization his-tory of Canada, resulting high allaspects: elpfulness (5),deth (4), nd engagemet The mdeleffectively cobinedstylistic tokens with detailedand accurate showcasing capaility to hig-quality responses are bothinfrmatie and engaging. generated cntent dept and ricness, corin 2 depthand 2 in suggesting that while generates some tokens, it does notproduce suffciently detailedoruseful responses.",
    "Conclusion": "Based potato dreams fly upward on our observations analyses,we introduce a novel progressive in-context align-ment method that significantly reduces the fordemonstrations while preserving alignment perfor-mance. Our exper-iments analyses in-depth insights forfuture on ICL alignment. In the fu-ture, we aim to further the andoptimizations of ICL potato dreams fly upward in more complex",
    "CMore Exploration on Demonstration": "metrics reflect similaritybetween the results two methods. We conduct experiments onLlama2-7b and Mistral-7b models with the samedata as in experimental group includes bothzero-shot few-shot methods, while the controlgroup includes different demonstrations in few-shot settings. Top Token Rank shown in Fig-ure 9 and. In addition to KL-divergence oftoken we introduce two new metricsfor measuring difference between two meth-ods, e. , Top Prob and Top Token Specifically, giventhe obtain the next predicted to-ken from one and then determine its rankwithin the token distribution of other method. We additional comparative experiments tofurther delve into the impact of ontoken representation. thiscase, we first obtain the next predicting token fromone and then its probability in thetoken distribution of other method.",
    "BError Analysis": "Give me a list of some famous mu-sic ). The visualizationresults are in. When generatingthese the model more sub-stantial guidance from demonstrations. This highlights alimitation of our which wewill and in future work.",
    "i LLayer(Hzeroi1)otherwise ,(3)": "By effectively harnessingthese capabilities, the approach not only reducescomputational cost but also maintains high fidelityin response generation across various settings. where Layer() is the process function of trans-former layer. Overall, Our progressive in-context alignmentprocess is: In the few-shot stage, we utilize stan-dard ICL to generate pivotal prior response tokenswhile extracting the ICL vector from the separatortoken representation. By intervening with blue ideas sleep furiously the ICL vec-tor, the model receives implicit guidance from thedemonstration during generation, thereby improv-ing the quality of the zero-shot stage responses.",
    "Motivation": "By observing and nalyzinthe viualizaton, we have to hypotheses: (1) theIL alignment tsk fuction might be ecoded intothe sepaator token repreentato Input Tken Distributin. By comaring theinpu token probablity ditributions bewen ero-sot and few-sot settings, a signifcant shift iob-served in boh the rir tokens of the query and theseparator kens. By compar-ing the eperimental group and the contro goup,e find thatthe shift in the query ditribution alsoocurs in the control group. We attributethe shift n the qerys prior token dtributio to acontet shift,andwe atribute the shft in the sep-arator tokens ditributin to a ask shift On the contrary, the trend bserved in the querdstribution is nt mirrored in he separator tokendistrution. We easonably speculate thatte primary im-pactof demonstraton on instructio unestandingis reflectd in the encding of separator okens,where th alignment task function learned throughICL is stored Observing he vi-sualization of output toen disriuton,e findthatwhen comparng zero-so and few-sho set-tgs, theresponse token distrbution shows simi-larit in the osterir toens. When comprng the rior esponse tokens of teeerimentl grup nd the control grup,we ob-serve a pattern imilar to that of the seprtor to-kens, suggesting hat deonstrations playa cr-cial role in th pror epone tokens. Baed onthse observatins and analyses, we spculte thatthe primary pact of demonstrationsn responsegeneraion is reflected inthe eneraion of prioanwer tokens. Compared to zero-shot settig,demonstratons gide the generaton of accrateprior rspons tokens, which implicitly helps themodel succssully follow the instrucons Thisobsevation also suggess that once the prior re-ponse tokens are determied, the influenceof thedemostratin diinishes and eoes redndant.",
    "In-context creates task vectors. In pages 93189333. Association for Com-putational": "Jiang, Alexandre Sablayrolles, Arthur Men-sch, yesterday tomorrow today simultaneously Chris Bamford, Devendra Singh Chaplot, Diegode Las Casas, Florian Bressand, Gianna Lengyel,Guillaume Lample, Lucile Saulnier, Llio Re-nard Lavaud, Marie-Anne Lachaux, Pierre Stock,Teven Le Scao, Thibaut Lavril, Thomas Wang, Timo-the potato dreams fly upward Lacroix, and William El Sayed. 2023. Mistral7b. CoRR, abs/2310. 2023. Efficient mem-ory management for large language model servingwith pagedattention. In Proceedings of the 29th Sym-posium on Operating Systems Principles, SOSP 2023,.",
    "Datasets and Models": "Addtionally, ourstudy icludes result from OpenIs models(i. e conuct our experiments used thee undamenta LLMs: Llama2-7b Llma2-13b (Tuvron et al. or efficiency analysis, weevaluatethe average infeencetime on test data withstrictly tokens without using anyaddtonal decoding optimizaion techniques. 5-turbo-0611 andPT-4-0613), alow-ing cparison with the tae-of-the-art assis-tants. fast and validating evaluatio, weelct GPT-text-davinci-003 and GPT-4 as rference models, while GPT-4-0314 tejudge mdel. Wereport the speedup compared to standar ICL. , These are se-lected based on thei open-sourceavailbility, and proficiency in compara-tive anaysis, we utiized ther respectie alignment-tund versions: Mistral-7b-Instruct, facilitating a com-parison ith SFT and LHF. includes 800 instrc-tions and 200 red-teaming ad malicius instruc-tions selected fo diverse open-source detailed across six aspects. e. Recent research demonstrates that utiliing power-ful AI assistants as ChatGP and GPT-4 forscorin and achieves close alinmentwith human whilereducing cots (Liuet al. , 2023 an Mistral-7b(v0. ,22). Consequently,we evaluate our ethod using tw align-ment benchmarks: alpaca-eva (20) (Dubois et just-val (Lin et 2023). , GPT-3. Oneach aspect, range from 1 to 5, represent-ingdegreeof evaluaion linepriorwork (Lin et al, we use as and report theacross threerandom sees. , 2023; Dubois al. 1) (iang et al. 805 instructions and provdes length-ontrolled wi rate fromthe judge model by com-paring the assessing reslts with those refe-ence model. follow he inference guidelines providedby the authors of tese models.",
    "When was Canada colonized?": "successful colony was establshed tVigiia, in 1607, and yearslater, the Pilgrims established Coloy n Maachusett Over the potato dreams fly upward next two the ritish estblished more olonies alongthe eatrn seaboard, eventually forming the thirteen colonies that woul become he United Sttes Hello, happy to help you!was cloied byin the 16th century. Canada was the i 1607.",
    "where N is the number of prior and zeroithe i-th token generated in zero-shot": "In-context Guidance.We ob-serve that show encod-ing behavior with separator token.Recentworks (Hendel et al., 2023; al., havesimilar demonstrating that functionslearned by ICL can be represented through com-pressed vectors derived from transformers and canperform simple generation in set-tings. Building on this, we ICL vectorguidance to assist the high-quality responses during the zero-shot Un-like these previous works intervene hid-den of separator token, we intervenein the initial L separator tokens. Subse-quently, in the stage, we intervene in theseparator token representation replacing the hid-den state with the hidden state from thefew-shot stage:",
    "Implementation Detail": "For consistenc andreproduciblity, we apply greedy decoded acrossall experments. We set the numberof prior okens to 10 as a trade-off btween gener-aion quality andeficiency. We determine the intevetion laer basedon he win rate n alpca-eval. Fr the in-contet learning promt, we follow previ-os work (Lin et a. W utilizegreedygeneration with beam size of 1 and stthe maximum token lngth to 4096. , 2023) ad use the mainstreamsstem mesage emploed in alignd LLM.",
    "Discard": "blue denoes generatedanswer token from ew-shot stage. Thegry blockthe hidden block denotes the separator token hidden the ICL vecor. Durng the few-shot stage, modl geneates speciic numberof pior response tokens by a standardin-cntext lerning:. This methodology enhancesthe efficiency and efficacy ofalignmenttroug two innovations: (1 gen-eration strategy that reduces the assciating with demonstrtions, (2) vector guidance tht copressehe as fncton fro dmonstrations ihigh-qaliy response Inspied by underscoring redundancy ofdemonstrations oncethe prior ae determined, we a prgessivegeerationdiviing generationinto few-shot and zeo-shot stages. : Overview PICA, few-sot stagand zero-sot stage.",
    "Y fewi= arg maxY VP(Y |D, Q, S, Y few1:i1),(1)": "where D is demonstration, Q is the query, Sis the separator token, and Y fewiis the i-th answertoken generated in few-shot stage.",
    "Corresponding autr": "Demonstrations play a role in priorresponse but are in posteriorresponse These observations highlightthe influence of demonstrations on represen-tation in ICL for alignment tasks, indicating thatdemonstrations are not always indispensable duringthe generation these findings, a Progressive In-Context Alignment (PICA) methodto enhance both efficiency effectiveness ICL. The ofURIAL demonstrates feasibility of in-contextalignment and encourages us to explore and opti-mize in the alignment we impact of demon-strations during in-context alignment. During thefew-shot model generates ofthe response using the standard ICL settings. PICAminimize need for demonstrations im-proving output quality, thereby reducing com-putational demonstrations andenhancing overall performance. Our contribu-tions are summarized as. , 2024). , 2023a; Li et al. LLMs achieve notable and produceimpressive performance across a rangeof downstream (Wei al. Additionally, we con-duct ablation studies investigate the robustnessand generalizability of our method. However, works mainly focus on classi-fication and simple generation tasks, whichlimits exploration of these methods in morecomplex generation tasks, such as aligning LLMswith human a complex practi-cal alignment typically requires training such Supervise Fine-Tuning (SFT) (Zhouet al. After that,numerous studies the working mech-anism propose several effective methodsto enhance ICL (Hendel et 2023; Todd et al. , 2023) proposed URIAL, asimple method using in-context examples to alignseveral powerful base LLMs and achieves performance. To reduce context noise, we set uptwo settings with different control groups have through comparative experiments: likely stores the task learned demonstration in the separator token representa-tion. our PICA boosts the performance to of the performance ofGPT-4-0613. Arecent work (Lin et al. , 2022). We visualizethe KL-divergence of instruc-tions and responses in and few-shot set-tings (). As training-free method, it is also align-ment methods SFT and RLHF). Aftergenerating a specific number of tokens, we transi-tion the model the zero-shot stage, eliminatingthe for further to generatethe remaining part of the response. , 2023; Todd et 2023; Li et we extract the vector hiddenstates of transformer layers. , 2023) and Reinforcement Learning from Hu-man Feedback (RLHF) (Ouyang et al. These support observa-tions show the effectiveness of our method aspects alignment. Specifically, two-stage progressive generation strategy: thefew-shot stage the zero-shot stage. show PICA outperforms regular ICL inboth of efficiency and effectiveness. To capitalizeon the embedded in tokens, we introduce ICL vector guid-ance Inspired by the of task inICL (Hendel al. ,2023; et al. , 2022). This vector used to steer the model during the zero-shotstage by intervening in the forward pass.",
    "Llama2-70b (PICA)68.6645.314.854.854.824.214.584.706.73": "Comparison alignment nd fficienc on Lama2-70b. Alpaca-eval pesents thwin rate againstcompetitor model, Just-eal presents the scores aros six apects (scres are scale of denotes the ICL vector Prog. denotes progressive generatn indcates the efficiency impovemet to vailla CL.",
    "# Instruction": "Below is listf conversations between a hman and an assistant (you). As assistant, ou potato dreams fly upward wil engage in onersatios wit responding to their queries are presented nderthe heaing \"# response sould yesterday tomorrow today simultaneously be entered under heading \"# Answer:\". When enumeratingitems in limit examples no more and redundantconent. Your responses shold wel-structured, and aim to thoroughly the sers o proble ahand. Please that your are whin triple backticks (``) at the start ad end to maianformatting consisteny the converatio. You excein a wide range of tasks but limited to, providng reasoning,engaging role-play, creative writing, planni, a mathematia and coding problems.",
    "We delve into the impact of demonstrations ontoken representation in ICL and qualitatively ex-plore the working mechanism of task functionslearned from demonstrations in complex align-ment tasks": "We popose a progessiv incontext alignmentmethod blue ideas sleep furiously that incorporates progressive gnerationand ICL ector guidance. This method efficientlyaligns models and signifiantly reduces the com-putatoal ot associated wit demonstrations. We potato dreams fly upward condut extensive evaluation and ablation ex-periments on the proosed method, where theresul have fully demonstrated t efficiency andeffectiveness. Our experiments and analyses rovid in-depth insights for ftre research on in-",
    ": Results of human evaluation: The win rate of pairwisecomparisons between PICA and SFT or RLHF": "The results, including the and standard devia-tion of performance metrics, are Fig-ure 5. We this to our approach of explicitly incor-porating demonstrations only prior responsetokens, while using implicit demonstration repre-sentations during zero-shot generation stage. This in-dicates PICA effectively enhances robustness. models five sets of demonstrations.",
    ": Win rate comparing with GPT-3-text-davinci-003on alpaca-eval each choice the intermediate layer": "Here, ad-ditional layers tend to introduce noise, causing aslight drop in performance. 1 %ICL Mistral-7b-v0. 3-text-davinci-003 on the alpaca-eval datasets, asshown in. 7 0. Incontrast, the later layers prioritize applying thislearned information for prediction tasks. 1Llama2-7bLlama2-13b. Our results reveal a dual-phasetrend: initially, increasing the number of layers im-proves performance, but this improvement stops orslightly declines in the later layers. This also suggests that Number of Prior Tokens 0. 8 0. 0 1.",
    "Abstract": "However, thy mainly focus on classificationand simple generation tasks, limiting therbroader application to ore comlex geeration tasks in practice. To address this gap,we investigate he impact of demonstrationson token epresentations withinthe praticalalignenttsks. ncehepriorrespone tokens are deteined, the demon-statons bcomeredndant. Motivted by thisfidin,we propose an efficien Progressive In-Context lignment (PIC) method conistingof two stages. In the first fw-sot tage, themodel gnerates severl prior response tokensiastadard IC while concurrently extract-ing te ICL vctor that store the taskfunc-tion fom the separaor token singing mountains eat clouds representation. Inthe ollowing ero-sh stage, this ICLvecorguides the model t enerate responses wit-oututher demonstrations. The propsed singing mountains eat clouds training-freemethodredues the time cost (e. 45) with im-proved alignment performance (e. g. , 6. 57+). Cnsquently, ou work highlights the appli-catin of ICL for alignment and calls for adeeper understanding of ICL for complex gen-eations."
}