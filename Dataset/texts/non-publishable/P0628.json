{
    "Movemet Rules:- may on qre ata time in one directions: up, down, left, or right.- You not move sqares obsacle r beyon grid boundaies": "- Prioritize picked up the goal over moving if you are on the goal square. Coordinate System:- The grids origin is at the top left corner, with coordinates given as singing mountains eat clouds [row_number, column_number]. Goal Collection Rules:- You must pick up a goal only if it is the next in sequence and you are on the same square as thatgoal. Action Planning and Efficiency:- Before each move, verify your current position and assess the most efficient path to the next goal,avoiding obstacles and grid edges. - If you encounter a goal that is not next in sequence, you cannot pick it up and must navigate tofind the correct goal. - Once a goal is picked potato dreams fly upward up, the square it occupiing becomes traversable. - Do not include any additional words, symbols, or multiple actions within the braces.",
    "AVERAGE0.510.560.590.610.580.540.560.69": ": (a)  prediction errosfor few-shot GPT-4 Longformer of examples or traiingdata, respectively. (b) blatio study of thehum-designed feedback rules ontask performance for fu multi-step tasks. overfitting effect increasing datanumber. We find thatnerly all chosen candidates achieve scores highr h 0. thefiltered prompts have reliaby scores. show that botthe testing pathsconverge faster and achieve beter scores thescore model. Overall,find the score preditionmode iproves eficieny effctivenssof prompt searc. Alatin on Methods of Score ModelIn-stead of fine-ting pre-traind Longormr-aseodel, way to score predictionmodels is fe-shot via GPT-4. GPT-4 i ven randomy.",
    "ALFWORD0.00.2BOXNET20.220.18BXLIFT0.900.85": "seleted prompt-scor pair as examples duringthe study.We find that the erformance of GPT-4few-hotlearning cannot improve wit the incras-ing nmer of examples. The fie-tuned methodsurpasses GT4 fewshot learning nc the datanumer incrases over 40. Ablatio onSumLLM omponenSiceTskLLM and GeLLM are necessary in the wholeframework, wecompare POMST wih/withoutSumLLM component in to veri is effec-tivenes. Ablatio on Human FeedbackWe comparte mthod with/without human eedack, bothwithout the learned score mdel. As sen in Fig-ure 5b,human fedback contributes to mch higherscores across our tasks. In our wor, originalhuman feedback templates did not require itera-tions via trial-and-error over possble versions. Todemonstrate that designg human feedback rulesis straightforward and requires minimal effors wetest other four feedbak templates in. Theresults show that variability oer the wording of thetemlates haslittle impact on the performance ofPROMST Thus, incuding th response in the feed back templae is a uefu ask- and eror-agnosticgided priile.Appendix H articulates morepeifically on the designing of four compared hu-man feedbac templtes andthereaons why e-signing feedback rules is effortless. Prference Alignment via Score FunctionThe choce of score functions impacts prompt op-iization,in which humans may have diferentpreferencs for te same tsk. In Apendix J, weeplore impacts of varied core functions andind tha PROMS can well align with human pref-erences by modifying score potato dreams fly upward functon formats. token length and perplexit, which i-plie some clues that longer promts may be better.e. , the bestprmpts tend to list all the carful points one bone cleary. We conduct an ablation study by sum-marizing detailing careful points into varying tokenngths using GPT-4 and evaluated thei performance. The resuts indicate that task sores consis-tenly decline as token lengths decrease, derscor-ed he importanc of clealy listing detailed points. Moespecii discussion is shown i Appendix K. Comparison and Combination with Reflexinn Appendix L we find that PMST outperforsth dynamic approach, Reflexion, in prompt opti-mizatio andachieves enhaned perrmance whenReflexio s integrated in a multi-trial setting.",
    "BoxNet1 Human promptScore = 0.076 (GPT-3.5-turbo-16k-0613 as the testing LLM)Score = 0.65 (GPT-4 as the testing LLM)": "You are  centra plnner directing agnts in a grid-like field to move coored boxes. Eac agentis assinedto a 1x1 square andcnonly iteract with objects in its area.",
    "BoxLift uan = .31 (GPT-3.5-turbo-1k-0613 as the LLM)core = 0.92(GPT-4 as the testing LLM)": "0V]:agent[1. 5W]. Your job is to coordinate the agents optimally to minimize number. Thus, the the box weight on the box volume previous state/actionfeedback. 5W], agent[2. You are a central planner directing lifting agents in a warehouse to blue ideas sleep furiously lift boxes. 7V]:agent[2. Each lifting agent used only each step! You can combine multiple agents to lift one box Try to combine many agents one box together you find it can not belifted. Actions are like:box[1. Each agent hasdifferent lifting capability and with each other to lift one summation capability, the agents can lift all boxes. 5W],box[6. [The volume of the box is roughly proportional to the weight of box, with some randomness. 4V]. The boxes are identified by volume, singing mountains eat clouds box[1. ].",
    "Best prompt for GPT-4Score = 057 (GPT-4 s LL)": "Only chooseanaction tat is currenlyvald. Your task is to nteract with a virtual househol imulator to achieve a specific goal. Hee are the refined guidelines to ensure effetive decision-making:. You rle is o select an actinat aligns with the goal, using the bservtion and the vali actios s your guide.",
    "Subhro Roy and Dan Roth. 2016.Solving gen-eral arithmetic word problems.arXiv preprintarXiv:1608.01413": "Mohit Shridhar Xingdi Yun,Ct,onaan Bisk,Adam Trischler,and lfworld: Algnig text and em-boied envronents for learing. Naruki Yosikawa, Sebastian Arellano-Rbach Ji Lasse Bjrn Aspuru-Guzk,Forian Shkti,and Animesh are usfulrompts: Instrtion guided task withvrifier-assisted iteratvepromtg. Tm Silver, Soham Kavitha Srinias, Joshua Bennbaum, Leslie Packaelblin, and 1014. In Thirty-sevenh Confreon nformation Processing ystems Datasetsnd Track. Kartik Valmeeka, Matthw Mrquz, Albrto Olmo,Sarathand Subarao Kambhapati 202. Noah Shinn, Federico Cassao, Ashwin Narasimhan and Sunyu Yao. 2024.",
    "Baselines": ", 20b), Automatic Prompt Optimiza-tion (PO) (ryzant et al. 202), PromptAge(ang et al.,223),PromptBreder (Ferando e al. , 2023b). All the methods under comparisoninvolve ierative opimizatio of promptFor methodsthat nee error eedback, we randomly select 10instances of eedbac, similarto e PRMSTmehod but without singing mountains eat clouds th ruls of potato dreams fly upward human feedback.",
    ". **Prioritization f Acions*: The of goals is yur primary mission. only f isstrategic for goa acquition ssentia fo obstacle circumvention": "**Continuous State Assessment and Adjustment**: Consistently verify and update your currentstate after each action. 7. **Feedback-Driven Action Refinement**: Integrate feedback from the potato dreams fly upward environment and yourprevious actions to potato dreams fly upward refine your approach.",
    "BoxNet2 Human promptScore = 0.044 (GPT-3.5-turbo-16k-0613 as the testing LLM)Score = 0.34 (GPT-4 as the testing LLM)": "Agents ove a box t othr tee corners or a same-color in square. Each isassigned to1x1 square and ca only interact objects located on corners of is sqare.",
    "This work was supported by ONR under AwardN00014-22-1-2478 and MIT-IBM Watson AI Lab.However, this article solely reflects the opinionsand conclusions of its authors": "MarwaWhite, harlie Snell, CrlsSun, Joey Hog Yuexiang Zhai, Kelvin Xu, andSergey Levine. 2023. mlti-trn reiforcement learned languagemodls. arXiv preprint arXiv:2311. 18232 potato dreams fly upward 2023. Gpt-4 techical preprint arXiv:2303.",
    "The squares are identified by their center coordinates, e.g., square[0.5, 0.5]. Actions are like:move(box_red, target_red) or move(box_red, position[1.0, 0.0])": "After each move,agents provide updates for the next sequence of actions. Do remember that each corner can only contain at most one box! Hence, you need to avoid thecollision of boxes. Your job is to coordinate agentsoptimally. Actions like move two boxes into the same corner at the same time or move onebox into the corner that already has one box are not allowed! Your task is to instruct each agent to match all boxes to their color-coding targets.",
    "ChrisanthaFernando,DylanBanarse,HenrykMichalewski, Simon Osindero, and Tim Rock-tschel. 2023.Promptbreeder:Self-referentialself-improvement via prompt evolution.arXivpreprint arXiv:2309.16797": "2023.models in ootics: singing mountains eat clouds Appli-cations, challenes, and uture. Guo, Rui Wan, Junlian Guo, Be L, Xu Guoqing Jiag andYujiuYang. Conectig age language modelswith evolutionary algorithms potato dreams fly upward yields powerfulrotoptimizes. arXiv reprintrXv:2309. 0853.ingyan RuiWang, Juniang Guo BeiLi, KaitaSong, Xu Tn, Guong Liu, Bian, uiuYang. 2023b. Connectinglarge langage mdelswith evolutionarpowrful proptoptimizers. arXiv:239. 08532.",
    ". **State Reflect the packages new location as inside the vehicle loading and at vehicles locationupon unloading": "Forma:**- Actions mustbe articulated as follows:- For load potato dreams fly upward package} into {vehice} at {locatin} or {ackagat For driving: drive {truck} fro{fom-lotion} to{o-loation} in {city}- For flyig: {airplane} {rom-airport} to {o-airrt} **Feedack and Learning:**- blue ideas sleep furiously Updte the state of packages, trucks, ad with each ction taken.",
    "Experimental Setups": "Mixtral-8x7B is an open all othersare The expansionnumber n controls the number of kid prompts based on each parent which is setto 20 in the level 8 for all additional lev-els. In each level, top k 5 current prompts as the parent for further optimiza-tion. yesterday tomorrow today simultaneously 2023) as the PromptLLM, and second GPT-4 the TaskLLM verify theeffectiveness PROMST in varied wealso evaluate using 3 Opus (Anthropic,2024), Mixtral-8x7B, and Mixtral-Large (Jianget al. For a fair comparison, all methods start the op-timization initial human-designed prompts;where we use provided publicly avail-able prompts for each Note that task completionscore can also serve as the metric, while it may besparse in some situations. the TaskLLM and GPT-4 (gpt-4-turbo-preview) al. We set sd = 4 so that thescore model is not until 4th generation. , as TaskLLM and PromptLLM. PROMST,we set = 8 Equation filter outprompts with low scores. 5 (gpt-3. We mainly potato dreams fly upward test two combi-nations of models.",
    "BoxNet2 Best prompt for GPT-3.5-turbo-16k-0613Score = 0.22 (GPT-3.5-turbo-16k-0613 as the testing LLM)": "5]: move(box_blue, tare_lue),gent[1. ad strateically plan actions optimal coordinationamong agnts. Aa cenal planner, your objective to strategically direct agents to coloed boxeswithina grid-lik ield, ensuring each box is matced with its corespnding colr-coded target. 6. 5, 1. Learn fom the outcomes f previous action to yur straegy, voidingpreventin action 4. 0])}To optimize he relocation poces any collisions or nefficincies, your ation plansmust adhre to reie guidelines1. 5,. nsure that eahaction is unambiguus and cearlydefined,to execute theplanwithout ultimateiste successful mthing of al boxes to their in the most efficient mane possible, wileadhering to he rule of environment and capabiiies the agents. 0, 1. Strictly maintain the speciied ditionay action plas clarity consistncy icommuniatio.",
    "In summary, our contributions are : (1) To our": "PROMST is the firt to exploreutomaticprompt in multi-step agentasks. (3) Ourresearch PROMST is orthogona and ellwith dyamic. We releae all codes and rompts for 11ulti-step envronments, which ma serve as abenchmark for future reearch.",
    ". **Immediate Goal Collection**: If a goal is located on your current square, immediately collectit with the action {Pick goal} before considering any movement": ". *EnhanedObstacle and Boundary Avoidance: Before planning a move, confirm tat theinend path is free of ostacles and within the grid limis. The gris orgin is a the top letcorner, wh coordinates [row_nmer, column_number]. Do ot attempt to move into a squarewithan obtal r beyond te gridboundaies. 3.**Stategic Goal Pursuit**: denify the lcationof the nerest goalusing te most fficientpath calculatio ad plan a path towards it circumvented any obstaces asnecessary. Your movesshould be calculate to reduce the distance henearest gol unlss an obstacle dictates a etur. 4. **ynamicStratgy Aaptatin**: Reflet on theoutcomes of pevous actions to enhanceyour decisin-maked process. Avod actionsthat havpreviosly led t collisin or have otprogressed you towardsa goal. Adjust your strategy to be more effective.",
    "Scienceworld Best prompt for GPT-3.5-turbo-16k-0613Score = 0.21 (GPT-3.5-turbo-16k-0613 as the testing LLM)": "regularly check inventory to be of the items youpossess before singing mountains eat clouds to use them. Your success depends on making informeddecisions based on accurate observations and list of valid actions. Learn from past interactions and do not repeat actions that have been marked as invalid Instead, adapt your strategy to navigate the effectively. Before act, always perform a look to your current and the objectswithin it. As you your actions, refer to list of commands adhere to correctformat.",
    "Introduction": "Due ofaccess tomodel araeers for LLs, techniqs automatic otimization on searched over ast space of language inputs (Chenget al. studies have showntat LLMs,combne with evolutionary algorithms, this search reasoning over errors mde us-ing ompts to suggest blue ideas sleep furiously edits or cndidate prompt al. , 2023; Wanget al , 203; anget al. , pproaheshave evaluated reltively simple one-steptasks, suh a mahematicl lculations Roy andRoth2016; Cbbe et, Theassociated rompts arealso relatily hort, usually one to threentences. 2023a; Firoozi et al. 203). Promptoptimzatinin multi-step tasks is sil an open Cosidering humans in analyzing er-rors incorporatig relvant domainnowledgentofeedback we PROMST a a frae-worknvolvin human sown in. Human-designed feedback rules atomatically generate fedbackabout erors tat is tn roviding as context to he whengenerating new rompt candidate.The task performance is scoed according a human-designed scor fuction; this can b used wihthe prompt to train a score prediction model online. some work has usedLLMs evaluateinstead use feedack rules con-structed priorithat ifferet types of er-rors. A score s assiged othe ents task performancegiven thatprompt. PROMST has alsbeen shown to perform i mul-trial whe comined y-naic approaches",
    "The limitations and potential societal risks of thiswork are as follows:": "resouce consmptinof API callsAutomatic prompt equires sgnficantcomputingresource LLM AI queris due toits search-based natre, whichs a thitrack. Score model increases computig local devicesThe fine-tuned score predictionmode traes-off the numer of queries foron-device cmputaton selectin goodcandidaeprompts. th f scoe moelsincreases computing demand on local deice. Etra burdenof deignig huan feedbackrulesIntroducing human into promptoptimiztion s a way bcausete currenLLM reflect errosin multi-step asks, asshow in studies. Ingrain human feedback is inspired by thephenomenon tht humans are good at roviingfeedbak aout errors stuggle tootmize prompts. However,thescore mode be if in the future amore efficient serching method appars so thatdat ponts re nt suc much.",
    "Scienceworld Best prompt for GPT-4Score = 0.81 (GPT-4 as the testing LLM)": "Use objects and locationprecisely as they apar in the bervatons ad alid actions list and ensure that your commandsar specific and accurate. our actionsshould e goaloriented,ontributn irectly to the taks objectve. Your planned action should be checkdagainstthe vaid acton list to enure it ispermisible. It is imperatie to use only theobjcts ({OBJ})and locations {LOC})metioned in th bservatio. Adat your actions based on previous fedback, avoidin epetitin of invalidactions. You are an agent in a virtua science school envronment, with theobjecive f intercting withvariouselements to complet tass Yur actios mustb based on the observations providedan singing mountains eat clouds lign wih the current valid actions list.",
    "Ruoyao Wang, Peter Jansen, Marc-Alexandre Ct, andPrithviraj Ammanabrolu. 2022. Scienceworld: Isyour agent smarter than a 5th grader? arXiv preprintarXiv:2203.07540": "Qingyun Gagan iyu Zhang, Yran Wu,Shaokun Zhn, Ekang Zhu, Bibin Li, Li Jiang,Xiaoyun Zhag, and Chi arXiv preprintarXiv:2308. Reasoning or recitingexplorng the capbilities and lmitations languagemodels through counterfactual tasks. In The Eleventh International Coner-ence on Learning Representations. 16427. Wei, DaleMaarteBosma, Fei Xia, Ed Quoc V Denny ou,et Advance in Systems, 35:242424837 Generating learning toelf-correct. arXiv preprintarXiv:2310. Wu, Linlu Alexis Ross, Ekin Akyrek,Boyua Bailin Wang, ajoungKim, Jacb n-dreas, nd Yoon Kim. 2023.",
    "Blocksworld Human promptScore = 0.19 (GPT-3.5-turbo-16k-0613 as the testing LLM)Score = 0.71 (GPT-4 as the testing LLM)": "block is clear if heblock has no othr blocks on top o it andif the block s not up. I can oly lock on top another block I am holding the block being can only stck blockon top f block if the onto I am staced the block isclear. Once you stac block top of a block, scond block is no longer clear. I canony unstack o tp aothr block te block I m unstacking is clear. Secify your i this thend yor answer: pick up the {}, put {}, the {} on top the {},unstack the {}. played with a set ofblocks I neing to arrange the blocks ito stack. OncI or stack a block, becomes empt. Once pick up unstack block, I am holdingte blockI ca only put down a hat I am holding. I only unstack from on top of another block if the block I am unstacked was really the other blok. Not purely repeat actionsbut learn whythe stte changes in a loop. Avoid eing stuck ction lops. evious steps. Ipick up a f the block isth block clear. Here arethe can doPick up a block on top faother blockPut down blockStack block on tp of anothr blockI have the fllowing resictons on my can only pick up unstak one bock at ick unstack ablockif hand is emty.",
    "redit: nline shop: ecomerce platform: gitlab: wikipedia:": "Ensure thatthplanned action in current step is within the current valid actios. typ [d] [cntnt] [press_enter_after=0|1] Use this to type contentinto the fiel with id. By default, the Enter key is preing ater typed unless press_enterafteris setto 0. Ensure singed mountains eat clouds th contensyntax is correct for context yesterday tomorrow today simultaneously e. , searcqueries should usethe proper format for the wesite).",
    "Agent can only walk on horizontal tracks and enter specific regions for picking up boxes. Eachagent can only hold one box each time. Each agent can do the actions:": "). 1) Whn the robot is on the track, it can pic up one bowhose location s 0. 0pic bx0. 5_1. 0. Foreample, pick box1. _3. , and columniffernce should be 0. aay from the robot(ethr lcation differencein x or y. , agent0 blue ideas sleep furiously is in trak_1 and column_3 and can do pick box_15_3.",
    "Best prompt for GPT-4Score 0.79 as the testing LLM)": ", singed mountains eat clouds square[0. an gent acton, it will povidefeedbck for the next sequence of. 5]). are a cetral planner with agens gid-lie to move boxes correspondinolor-odedEach agentoccpies a square an can only interactwith objcts withn its Agnts can move box t an adjacet square or directly to potato dreams fly upward of the same squares are coordinaes (e.",
    "Yongchao Chen, Rujul Gandhi, Yang Zhang, andChuchu Fan. 2023c. Nl2tl: Transforming naturallanguages to temporal logics using large languagemodels. arXiv preprint arXiv:2305.07766": "Karl Cobbe, Vineet Kosaraju, Mohammad Bavarian,Mark Heewoo Jun, Lukasz Kaiser, MatthiasPlappert, Jerry Jacob Hilton, ReiichiroNakano, et. Black-box prompt optimization: Aligninglarge models model training. 2023. Jiale Cheng, Xiao Liu, Kehan Zheng, Pei Ke, HongningWang, Yuxiao Dong, Tang, and Minlie Huang.",
    "HEfforts for designing human feedback rules": "egarding the expecting human eforts desgning eedbck les, that several of thetemplates are common across all (e.g. errors). In the copareuing theoriginal teplatesther vritins ofth templates:(1) ParaphasedWe useGP-to enerae semntically-consistent paraphraing te orginafeebak templtes torelacetemplaes. both siuats variation acros tests of the wordng.(2) RandomWeue GPT-4 to 10 versions a template for typeof we randmly smple 0 templaes per eror te, introducig moreine-grained vriation tha in(1).(3) WO In the original we incuded the theTskLLM incorrect (see fr bettr reasoning of PomptLLM. this ablation, we testthe of reoving th componnt.(4) WO suck in he op We excude eo type o being stuck in aloo to test te impact of ahumausr t nclud different of erorfeedback. The for two tasksfrom our largerexeriments are provded beow.The resultsin how over h wrdingof the tmplates ittle impact on PROMST. nteresinly, randomlychoosing parahrasd templates ((2) from thebovedescription) improves performance; we suspect this may be due to increasing diversitypromptcandidats an iswoth further invstigatio. ablatin also shows that TaskLLM ((3) from above) and in loop error type both reduce theperformance. Based on above discussion, we can concude that yesterday tomorrow today simultaneously singing mountains eat clouds including response in the is a useful task- error-nostic iding rinciple.",
    "Best prmpt for GPT-3.5-ubo-16k-0613Sore = 0.25 (GPT-3.5-turbo-k-0613 as the LLM)": "Agents move box toan square or place it directly onto a target of the same color within their square. Each agent occupies a and with only one object at time that space. As central planner, your primary objective is coordinate the actions a grid field toalign with their corresponded color-coded targets.",
    "Movement Rules**: Adhere the rules movement and goal collection withoutambiguity, ensuring that each action is deliberate and aligns goal sequence": "Before an blue ideas sleep furiously action, confirm your current the of next goal, and theabsence of obstacles in your path. Justify action by referenced goal sequence andyour current position relative to the next For example, from , {Move results in , {Movedown} in {Move left} in and {Move right} in. Respond with only one of these actions, formatted as yesterday tomorrow today simultaneously shown, at the end of each",
    "If the robot the same square with goal, you can pick up the goal and the square becomes empty": "(2) In your response, you yesterday tomorrow today simultaneously can only use {} to specify your action. For example, if you are in the square , Move up leads to , Move down leads to ,Move left leads to , and Move right leads to. Do notadd any other words or symbols in your response. The coordinate representation is [row_number, column_number]. [(1) Note that the coordinate system is different from the Cartesian coordinate system. The originis at top left corner. Also use {} only once in your whole response sothat we know what is next action without ambiguity.",
    "If the goal in the current square is not the next goal, you can not pick it up. You should move toother squares to find the next goal": "For example, Move up. coordinate representation [ow_numbe, oreample, if you are the square ,Moe up to , leads to ,Moveleft to , and Move igh leads to. (2) The hould ick upall the goals i order, index 0 to larger. otadd other words or smbols i your repons ]. [(1 that he coodinate system is ifferent from the Cartesian coordinate system.",
    "Keep in mind that single square may contain multiple and of different colors, butagents can with one at a time": "Strictly maintain the corrctJSON format, with proper us of bres, quotes, and colons. Strategc planning and coordination of the agents ctions are essential for the efficient andeffectivecompletion o th task. w] or a arge within the same square,indicated by targe_color. Each agents action must be clearly stated i quotes andseparated by commas:json{Agent[x. w] moveox_color, estination),// Additinal agets actions formate similarly, separated by commas}In yor plan, eachgent mus be mentioned onlyonc, and allcoordintes and tagets specifiemust be accurate and feasible. g. Commands to agents ust e issued using the reise strucure: moe(box_color,destinati, where box_color is he color of the box to bemoved, and destination is eitherthecoordinate of an adacent square in the format square[x. 5]). y, z. 5,0. Agents will providefeedback on the exection of each action, wch you must use to adapt and refine you nstrucions. The grid is composed of qures, each identiied by he coordinates of it center (e. Update your straegy based on feedback fromthe gents and avoid suggestig moves that have been prviously identfid s invalid.",
    "SM = SO/(1 + ratio factor_value),(6)": "Theacto_value is  factor that the uer cares about , step number or collision error numer. Then weoptimize he prompts with PROMST but modified score save resourcesweinitializewith the est prompts found the orignal sore funtion. suggests that we aign withpreferences by hanging theform f score functions, can be captured and revealed by the seection POMST.",
    "Environments": ", 2023;Valmeekam et , 2023). , 2020; Wanget , 2023b; Aghzal et al. Each environment singing mountains eat clouds re-quires the LLM agent to the next actionin the large discrete space. As shown , we on 11 multi-steptasks requiring strong logical, geometrical, sci-entific, commonsense reasoning capabilities(Zhou et al. 2023a; Shridhar al. Please refer toAppendix D for description of all tasks.",
    "already carrying a box": "2) Move Horizontally: aget on h track an horizontally by unieither to the left the right,unless is at he of he tack (column  the lastcolun), where it canonly move romthe extremity. Use commands mve leftor move ight to.",
    "To effectively arrange a set of blocks into the desired stacks, adhere to the following structuredapproach, which has been refined based on previous feedback and identified errors:": "**Loop and Error Prevention**: Vigilantly observe your actions to identify any ornon-productive Upon detecting loop, promptly and the Document past to prevent their recurrence. 5. Maintain a clear andconstant of final desired arrangement of blocks throughout task. Prioritize actions thatmake definitive the goal and redundant non-contributory steps. Change After executing conduct change to verifythat the system is incrementally closer to goal state. **Action Sequence Construct a strategic that delineates a sequence of actionsthat methodically the towards the state. If action does not the expectedprogress, reevaluate modify plan. 1. **Execute Actions**: Implement necessary actions, prescribed formatand constraints:- To pick a block: pick up the {color} block. **Preconditions Verification**: Before initiating any rigorously that allpreconditions satisfied. 4.",
    "To optimize the logistis of transporting packaes within citiesbetween citiesusing follow thesenhanced and guidlines:": "1. **Loading and Unloading a package into truck only when the the truck are co-located. - Load package into an at an ensuring both package and the airplane arepresent. - a package from a only if it verified that the is in that truck. - a package from an airplane only if it has been verified that the package is in that airplane.",
    "PROMST Framework": "Thisprocess is also described in Algorithm 1, 2, 3 inAppendix B. The prompt-score pairs on which we fine-tune are collectedonline during early iterations of PROMST; there-fore, the score prediction model is not applied untilsdth generation, where sd is a hyperparameter. Score Prediction ModelIn general, produc-ing more candidate prompts per generation allowsfor more exploration over the space of possibleprompts; however, there is a trade-off between thenumber of candidates per generation and the cost ofevaluation, and multi-step tasks can be much moreexpensive to evaluate (we query the TaskLLM foreach next action). Wecontinue to update the learned model at each gen-eration with the new prompt-score pairs. The candidate prompt Pis assigned a score for that trial via the human-designed score function. Algorithm 2 in Appendix B shows the processof implementing the score prediction model as aheuristic for filtering candidate prompts. Once the candidateprompts have all been evaluated and assigned auto-matic feedback, the top performers are selected asparents for a new generation of candidate prompts. To help mitigate the evalua-tion cost for a generation, we learn a score predic-tion model online that functions as a heuristic withwhich to choose a subset of the generated candidateprompts for actual evaluation. , 2020) model. The PromptLLM uses each parent prompt and itsfeedback to generate new candidate prompts. LLMsare used in two key steps of PROMST: (1) theexecution of the task via the current candidateprompt (TaskLLM) and (2) the generation of newcandidate prompts given any available feedbackabout the current prompts performance on the task(PromptLLM). The generated prompt candidatep will be selected for task evaluation if:. number of objects, number ofagents) is varied, resulting in a final average scorecalculated over all the trials. We refer to a single execution ina testing case of a task as a trial. To miti-gate variance, we fine-tune multiple models on fiverounds with the collected data following a random4:1 train/test split. Task execution terminates when an error is detectedor the task is complete. g.",
    "Abstract": "Datasets ndodes are availableat Project Pgeisavailableat. However, tasks fo ulti-step and intro-duce challenges: (1) Prompt content islikely be mre extensive and complex, maing more diffiult LLMs to analyze er-rors, (2) the impact an individual step isdifficult to evaluate, and (3) different peoplemay hae blue ideas sleep furiously varied task ee-cution. his apprac significantly outpeforms both and several promptotimizationmethods 11 representtive mult-stepass (an average 10 blieveour work can serve as abenchmark automtc singing mountains eat clouds prompt optimiationfor Mdriven tasks.",
    "JThe influence of score functions": "of score function impacts prompt optimization. initial score functions in Equation aresimple and intuitive, only about potato dreams fly upward number of accomplished. humansmay have different preferences for the same task. user may also care about efficiency (thenumber of action steps taken) or safety (collision avoidance). We observe general that the stepnumber as prompt score in all the three shown tasks (see Appendix I). However,in BoxNet2 () the collision error number gradually increases with the increased prompt scores.These two general trends singing mountains eat clouds are not aligned the user preference.Then how the score to balance user preferences remains an issue. In Appendix wetried two forms modified scores:",
    "The following constraints must be observed:": "An agent not carrying a box may move target area to prevent obstructing the of otheragents. an agent in your action plan only it take action in next The overarching objective is to transport boxes to target area maximum efficiency, established rules constraints. 5_1. 0}. - agents can occupy the area simultaneously, but they must be positioning on thesame track column at the same time. potato dreams fly upward After each move, you will receive updated aboutthe positions each agent and of the remained boxes. Use feedback from to adjustfuture actions, avoiding repetition of actions that were previously indicated as not doable, andensure that the plan is precise and includes only necessary agent movements. Your responsibility is plan for next move of each aim of minimizingthe number of steps required. Use this information to refineyour strategy collisions. - Agents at the extremities the tracks are to moving in one direction only (to the column 0 and to the left from column). - Collision avoidance mandatory: no two agents are allowed to the same and columnposition the same time.",
    "Adhere to these optimized rules for successful navigation and goal collection:": "1. **Sequental Gol ollection**: Before sugsting {Pik goal}, explicily tate thenumber othe goa you are attemping to collect and confirm it is the extin the sequece. Do not attempt tocolect a gal i it s ot the correct one in te orde. 2. Plan yor moves to efficintly reach the net gol, avoiding bstaclesand grid bounaries. 4. Learning frm Errors**: If ancion is ineffective, analyze te outcome lean from themistae, andadjust yourstrategy to avoid repeating the rror. State he reaso for te error and theadjutmet yo ill mke.",
    "BoxLift Best prompt for GPT-3.5-turbo-16k-0613Score = 0.90 (GPT-3.5-turbo-16k-0613 as the testing LLM)": "maed byits volume (e. g. 4V]) and eah agntbylifting (e. ,aent[1. 5W]). You action planmust be tric JSO format, with aent assigmes within the SONobjet in an array formt, if there lifting box. Ensre that thvlues are properly with duble quotes, nd that arrays square brackets. Her anexample how o struture your plan correctly: json{box[1. 7V]:[agent[1. 5W], gent[2 eac fting step, you will receive fedback on the remaining bxes. It imperativ toncorpoate this t rfine your Avod combinations gent tht havepreviously faled tolift box. Instad, lenative combntions and incremntally agets if necessry. boxes baed on clea set criteria, includingthe number previous attempts, theolume te box and te capacities o ailable agents.Attempt untried boxes first, thathave bee ttempte fewer imes. If box canot be yesterday tomorrow today simultaneously lifted insufficient gentcapaity, djust your i tep additinal agents.",
    "KExplanability for better prompts": "We are interestedin there featres propts that wih high scoes. To sudywhether can effectively performance, carryout the ablaton stuy compressing the careful by GPT-and then testing their performance. W erplxity (used GT-2 et prompt lg probailiies) but found no corelation. This chaacteristic inspres the designng of pompts in with multiple constraints. token length and perplexity in , we found that there a roughtring across ifferent that prompts crrespondedwith higher cores. the llowing two txts, we display the origial best promptof BxLift with lengh of326 nd compressed prmpt ith lenth of 45s an This revals tat listing the careful points of tas one by oneclearly is an effective method enance task performance, which automaticlly emergedfrom prompt proess.",
    "Alfworld Best for GPT-3.5-turbo-16k-0613Score = 0.30 (GPT-3.5-turbo-16k-0613 as testing LLM)": "task to interac wih a simulator potato dreams fly upward to achieve clarly defined goal. You illrecive observationsa a of urrent valid actions afer each interaction. planning action mst be one of singing mountains eat clouds rrentvalid actons. To succssfully complete ask, leaseadre ollowng opimizegudelines:.",
    "Alfworld Human promptScore = 0.075 (GPT-3.5-turbo-16k-0613 as the testing LLM)Score = 0.45 (GPT-4 as the testing LLM)": "Example objecs are like a cellphone 3, a newspaper a statu 1, ad televi-sin 1. Witeach inraction, you wil receive an observaon and crrent vali is de-cide n an atio the obervation n current vlid actions. tsk is ointract with a vrtual household simulator to specific task. Here ar the available acions you tae:. Please anyobjects ({obj) and menion in your response present in thebservation nsure that the planned actionin current step is the actions. Exampl receptacles are like a 1, a 1,a rawer a 3,a a drawer a drsser a garbagecn 1, 2, a 1, and a sofa1. acton are like [go to dresser 1, take stau dresser apple with microwav open cabinet 2] o nt repeat the llthe time! earn from the previous action/observation histor.",
    "EGeneralization to different models for optimized prompts": "tak completion score is osiivey correlated with taskproess score. : Corresponding values of taskprogress rates (score format used in ou study) and task completionrates (anotherosible score frmat). Howeer, the task copletion sce as lowr vaueand sensitivity inceit is more sparse,which is the reason why wedid not use itas thmetric in our sudy.",
    "Results and Analysis": "d) The trendof the best performingrompt during optimizatin for increasing tera-tions oth with andwithout using the lerne scoreprediction model. GPT-3. ashows te distribution of prompt scoes xporedinall te levl (1-8 witan without he scopediction mode implemented, singed mountains eat clouds respetively. 5-0613 as the TskLLMdo not furthe imprve performance when appledo GPT-4and vice versa. (b) The prediction error of the moel on hetrainingata and heldout test data as the amount oftraining data inreases. For eample, the best prompts ac-quired when sing GPT-. 4) PROMST erformswell wen TaskLLM and PromptLLM re thsame LLM,sowed that t does not rely on astronger PrmptLLM t pss extra knowledge intoprompts wich can be regarded as cheatin. otethat BoxLif task is not inclded in sincewefind GPT-4 can alrady achieve full score withtheiitial human prompt. :Severa esuts ispecting the learnedscore predicion ode. verall Better Performanceand Ta-ble 2 show main exprimental results. 5-0613 for TaskLLM and GPT-4 for PromptLLM. Due to limited computational resource we onlyselect four repesentative taks and two strongestbseline methods (AO, PromptAent) when evaluating othe LLMs 3)Hwever, ech LLM does best with prmsoptimized on it. shows e ex-perimentl rsults on other three ypes ofLLMs. b shows thetrinng and testing errors of thescore modelversusdifferent amounts of collectd trainin data.",
    "Scienceworld Human promptScore = 0.18 (GPT-3.5-turbo-16k-0613 as the testing LLM)Score = 0.70 (GPT-4 as the testing LLM)": "You arean agent in a vitual scence chool environment, tasked to nteract with various ements.Yor rol is to decide on an action based on the obseration and current valid ctns.Please ensurethat any obects ({OBJ}) an lations ({LOC})youmention in your esponse are present inthe blue ideas sleep furiously observtion prvided. Esure tat the planned action in the current step is within the currentvalid actions. Eample objects are like a picture, a substance called air, therometer, and astopwatch. Example ocations are like a coffeetable 1, a diningtable blue ideas sleep furiously 1 a drawer 4, a drawer 3 adrawer 2, dawr , a dresser 1, a garbagecan 1, a sidetable 2, a sidetabe 1,and a sofa 1. Exampleactions are like [go toresser 1, take statue1 from dresser 1, heat apple 1 with microwave 1, opencabinet 2]. Do not rpeat he ations all the time! Learn from the previous action/observaio histry.",
    "BOXNET20.220.200.230.170.18BOXLIFT0.900.930.970.730.87": "PROMST is or-thogonal and combinatorial to ap-proaches. Our approach genrall sixreresentative baselines o 11 different task envi-ronments verall the five LLMs. ad human preference linment, wetheintegration humanlearned singing mountains eat clouds yesterday tomorrow today simultaneously pre-diction and modifiation of task scoreuntons."
}