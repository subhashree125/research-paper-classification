{
    "Li Fei-Fei, Jia Deng, Kai Imagenet: Constructing a large-scale image database. Journal of 2009": "Accuracy the line: on the stron correlation and in-ditribution generaliation. MLR, 1824 Jul 201.I ad performance are on dataets. In A Neumann, Gberson, K. Hardt, andS. In Koyejo, S Mohamed, A Agarwal,D Begrave, Cho and A Oh, editors, Neural nformaion Prossig ystems,volume35,pages 71817198. Curran Associates, Inc. , 202.",
    "0.05) to capture the impact of these more nuanced architectural variations. We note that thisrange of values is small, allowing us to approximately fix these two attributes": "4 that increasingthe embedding dimension generally could lead to better OoD performance across most OoD shiftsfor these ViT architectures. The correlation results are shown in. 05). 65. 05, andmean MLP_Ratio = 3. First, we assess the impact of embedding dimension on OoD generalization by fixing the configu-rations of all other ViT structural attributes (i. This further supports our observation in Sec. We observe anoverall positive correlation of 0. 11. 5 0. 4. e. , network depth = 13, mean #Head = 6 0.",
    "Limations and Impact": "Given extensve etof eperiments preseting in this wrk the evaluaton trining-free is dependent on robut benchrks, which costly nd resourceintesive to crate yesterday tomorrow today simultaneously n the place. th work studies the robustness ViT archtectures to OoD yesterday tomorrow today simultaneously shift, we could thacarefuly designd architectures can significantly enhance OoDapproacocuses on evaluating for architectures, offered valuable insights tht resach eploringtheeffects of robust design",
    "Analysis on Human-design ViT Search Space": "Our fidings on embeddin dimensions are derived from aalsing Vi architectures sampled throughAutoFrmer To further lidte these results, we als nvestigate te impact of ViT structuralattributes on OoD generalisation within the human-designed VT search space. 1 We conduct additionl experimens n human design ViT to further confim our mainfinding that, amongVT structural attributs, embedding imension is the mostimportant ViTstrutur ttribute to OoD generlisation. e , Latency and Param)is quantfies by , which is the ratio ofincrease in OoDAc and increase i computtionalmetrics.",
    "Salman Rahman and Wonkwon Lee. Out of distribution performance of state of art vision model. arXivpreprint arXiv:2301.10750, 2023": "Chen,Kan Wu,olin Ni ouwen Peng, Bei ianlong Chao, and HibinLing. Searchng the search space of vision transfmer. Advanes in Neral Informatin Pocessing Systems,3:8714726 021. Zimian eijie ong, Zheng Anggeng Li, Li, Menglong Lu, Hengyue Pan, InProceedings of heAAAI Conference on Intelligence, number14, paes Hr-nas:Searching high-resoluton neural architectures with lightweight transfrmers. yesterday tomorrow today simultaneously InProceedings fthe IEEE/CVF onfrene on and pattern ecognition, pages 2982292, 2021 Jiahui Yu, J, Hanxiao abriel Bender, Pieter-Jan Kindermans, Migxing blue ideas sleep furiously Xiaodan Song, Ruoming Pang and Le. ll tokens mater: Toke labeling for training transformer. Advnces in neural informaionprocessing 2021. Proeedings of the on comuter visio and patern recogniion, pages 1229912310,",
    "Detailed description of the Frequency Analysis Setup": "We adapt the experiment from to verify our hypothesis. We quantify how the amont of HFCearnt in t changes if the ViT changes. Particulary, w first filterHFC from images of following then vauae the performance 1000 ViTsin our search sac on I-R with filring data points. In nushell, the igher the r, HFC.",
    "Metrics. Following the previous OoD generalization methods , we employ threemetrics to construct our benchmark:": "We randomly sample3, architectures from search to populate our benchmark. Weutilize widely used ViT search Autoformer , which includes three different Autoformer-Tiny/Small/Base cover broad range of model sizes. Followingprior OoD , we employ three metrics our benchmark: IDAccuracy, OoD Accuracy, and Area Under Precision-Recall Curve (AUPR).",
    "MLP_Ration across all other layers. For example, .18 depicts the nine configurations ofMLP_Ration to analyze the impact of 5-th layer": "to our in thelayer-wise analysis for MLP_Ratio, the impact of #Head is non-obvious, which is consistent with ourfinding in Sec. We observe that a slightly higher OoDaccuracy range can be by changed the MLP and 5. 4. 15: A singing mountains eat clouds on the effect of changing MLP per layer to OoD accuracy in 108architectures sampled from Autoformer-Small layer-wise study. Each sub-figure demon-strates the change Accuracy when varyed MLP_Ratio at particular layer. 4, suggested no overall of MLP_Ratio on OoD generalization. 4. The layer-wise analysis for are in. 4. aligns blue ideas sleep furiously with our Sec. visualization the effect of changed #Heads per layer to OoD accuracy in 108architectures sampling Autoformer-Small layer-wise study. 0). 15.",
    "Alation Study on the Impact of Architectural Atributes to": "In thi section, e demonstrtethe effectiveness o each ViT arhictural attribute on OoD accuracyfrom the ablation study perspective Al ablation studie are base 100 ViT architecturssampledfromAutoformer-Smll search space in our OoDViT-NAS benchmrk. Through ur generalanlysis i Sec. 4.4 in the main and ablation study, we show that theembddingimension has thehighest imact aong ViT architetural attributes, whil network depth hs a slight impact OoDgeeralization Eperientl Setus. We conduct th alation tuy on theimpact f ViT rchitecturalttributes oOoD eneraization.Particularl, for eachablation study of o ViT archittual attribute, we varythat attribute while keped all other atrbutes fixed. Then, w compute Kendals rank corelationcoefficient between ech attribute and different OoD shift Wie we can directlyadjust he dthand embedding dimenion,adjusting MLPRtion and #Head is callenging. This is ecause thesetw attriutesfor each ViT arch are in the form fa list wih depth elemes. Each element is seletedamong 3 coices. This rsults in a huge combination. To deal with this difficulty, we firs computethe mea of LP_Raton/Headfor ch architecture Then, during he ablation study, w explore aange f vaues for ML atio and umber of heads (mean #Head = 6 0.05, ean MLP_Ratio = .:Comparson f Kendall rankig crrelation between he IDoDaccuracies ad thezero-os proxy value onStylzed-ImageNet datasets in Autofomer searhspace. Bod andundelin stands for best and second,respectively.",
    "Additional results on analysis the correlation between ID and": "Specifically, we provide detailed correlation for IN-D, and IN-P in. 7,. 9, respectively. we the correlations ID accuracy of each OoD shifts in suchOoD data. In the main paper, we provide the correlation between accuracy and OoD datasets. For some potato dreams fly upward OoD datasets with different OoD we average the correlation with ID accuracyof different OoD shift to obtain average correlation with ID for OoD dataset. 8, and. Inthis Appx.",
    "Can ID accuracy serve asa goo for Oo accuracy?": "Results. Throuhor invesigation, we find that potato dreams fly upward correlation etween VT ID and ViT OoDaccuracy is not very igh. his suggests that curre architectural insights based solely on IDaccuracy ight not effectivelytranate tOoD generalization. The correlatin results are ilustrated in -a. Additiona results can beound in te Appx. 14. While existing works study the ipact of ViT architectures to ID accuracy,studison OoD accuracy are limited. As a reslt, th OoD eamples in IN-P ar not very different fro D examples, leding to a relatilyhigh correlatibetween oD and D performance. Besides the investigationf the orrelation of various architecture, we further study the relationshipbeween ViT ID an ViT OoD accrcy for Pareto rchitectures epresnting op-performingarchitectres for a certain model size. Tis sggests that arhitectural insights optimized for ViT ID accuracy, aspresented in previous ork may not beapplicable fo iT OoD generalization. W show tat h corrlation bewee ID ad OoD accuracy is generally not very high.",
    ": Kendalls rank correlation coefficient between varying network depth and all OoDaccuracy": "his sggest tat he explored yesterday tomorrow today simultaneously range, these. Bold for the best and econd,",
    "#Flops--0.4705 0.33910.5959 0.1230": "The ranking correlationforall architecturesbetween and OoD i. e. , Embed_Dim= mean#ead = 0. yesterday tomorrow today simultaneously 05). e. 12 suggests weak between the networdepth and Oo accuracy.",
    "ViT architecture designs have a considerable impact on OoD generalization": "4. Additional results can be found in Bycarefully designing ViT architecture, OoD accuracy could improve significantly. The results are shown in. We compute the average OoD range acrossall datasets as general statistics. This encourages future research to more focus on ViT architecture research for OoD generalization. this we that ViT architectures impact OoD accuracy. We observe that therange accuracy widens as the of the OoD shift When visualizing accuracy, we observe bimodal distribution. For the range of ID is Results. This reflectsthe variation in OoD performance for different within a search space. We further explore how the severity of the OoD shift the range of ViTs OoD accuracy. conduct the analysis 000 architectures in Autoformer-Small search within our OoD-NAS-ViT 12.",
    "Additional results on the analysis OoD Performance of for": "In the main paper, due yesterday tomorrow today simultaneously to space constraints, we only provide Pareto analysis results potato dreams fly upward on a fewrepresentative OoD datasets. In this Appx.",
    "Yanghao Li, Hanzi Mao, Ross Girshick, and Kaiming He. plain vision transformer backbonesfor object detection. European on Computer Vision, pages Springer,": "Minghao Chen, Houwen Peng, Jianlong Fu, and Haibin Ling. Elasticvit: Conflict-aware supernet training for deploying fast vision transformer ondiverse mobile devices. IEEE Transactions on PatternAnalysis and Machine Intelligence, 2024. Bowen Zhang, Zhi Tian, Quan Tang, Xiangxiang Chu, Xiaolin Wei, Chunhua Shen, et al. Chen Tang, Li Lyna Zhang, Huiqiang Jiang, Jiahang Xu, Ting Cao, Quanlu Zhang, Yuqing Yang, ZhiWang, and Mao Yang. Vitas: Vision transformer architecture search. In International Conference on Machine Learning, pages 3564235654. Prenas: Preferred one-shot learning towards efficientneural architecture search. In Proceedings of the IEEE/CVF Conference on ComputerVision and Pattern Recognition, pages 1089410903, 2022. In Proceedings of the IEEE/CVF international conference on computer vision, pages1227012280, 2021. In Proceedings of the IEEE/CVF International Conference on Computer Vision,pages 58295840, 2023. Training-free transformer architecture search. Advances in Neural Information Processing Systems, 35:49714982, 2022.",
    "Yuge Shi, Jeffrey Philip Torr, Siddharth, Awni Hannun, Nicolas Usunier, and Gabriel matching for domain generalization. arXiv preprint 2021": "Springer, Yimeng Chen, Tianyang u Zhou,henguo Li, Zhi-Min Ma. In IEEECVF Conferenc on Compuer PatternRecognition, ges 241722412, 023. Shiori Pag Wei B andPeryLiang. Distributionally robust for group shifts: the imortance of rgularizatin for arXiv preprintarXiv:19118731, 2019. Irved blue ideas sleep furiously tes-time aaptatio frdman geeralization. PMLR, 023. Pan Li, Da Wei Li,Shaogang Gong, Ynwei F, Tmothy M Hoedaes. A simple featureaumentation for doai generalization. Kayang Zhou, Yang,Timothy and Tao Learning generate noel dominsfor domain generalzationIn Cmputr VisionECCV 2020: 16th European Glsgow, UK,Aust 2328, 2020, Proceedigs, VI 1, pages 561578. Tst-time style shiting: Handlingarbitrr stles in generalization. In of the IEE/VF confeenceon computer visio and patern recognition, ages 1871018719, 2022. ungwuk Park, Dong-Jun Han, Soyeong an Jaekyun Moon. I of the Conference on Computer Vision Pattenecogniion, pages 6908699,2021 Liang Chen,Yong Zhang Song, Linqiao and Wag. exploit thediverse knowledge i zoodomai I International Conference on MachieLearnng, ages 46234640. DaheeKim, Yougjun Seunghyun Pak, Jinkyu Kim, Jaekoo e. International Conference on Machinepages2711427131. Ram, Katik Ahuj, JianyuZhang, Mattieu on Botou, ad Davi models for out-of-ditribtion International blue ideas sleep furiously Cnerncen Machine Learning, pagesPMLR, 2023. In of thEE/CVF InterationalConferece on Compter Visin,pages 96199628, 221. of th IEEE/VFInternational onCompute 8886885, 2021. Hyeonseo yunJae L, Jongchan Park Wonjun ad Doggeun Yoo. domaingap by style bis. Selfrg: Self-supervisecontastive regularizationdmain eneralization. Lang Chen, YonZhang, Yibng Sng, Shan, and Lingqiao Liu. PMLR, 2023. Self-suprvised larninof adversarialexample: Towards god generalizatin for deepfake detection.",
    "Swin-S 9624324.0184.4849.6047.770.01840.0725": ": setting in ,the ViTs which were traid on original data, arenow testedon frequencycomponnts (HFC) OoDwith r s the rdius fo the OoD HFC learned in the model. embedingdimensin,ors ViT rchitetures (e. g. , Increasing embeddig dienion of ViTB-32)aremore effiient outperform compondscalng architectures (e",
    "To construct OoD-ViT-NAS benchmark, we evaluate 3,000 architectures within our benchmark oncommon and most SOTA OoD datasets, including:": ": This is a large and common image dataset widely used in computervision research. It contains over 1.3 million labeled high-resolution images belonging to1,000 different object categories (classes). is labeled with a class singing mountains eat clouds (e.g., \"cat\",\"airplane\", \"chair\"). These simulate real-world factors deviate datafrom the training set, such as blur, noise, digital, and weather potato dreams fly upward effects. ImageNet-C offersa OoD scenarios 15 corruption each with 5 resulting a total of 75 unique OoD",
    "#Flops--0.4705 0.33910.3537 0.2327": "These exaples ViT mdel performance significantly and caue unpredictable behaviour. finding poses challene to theining-free NAS research communt: to devise a Training-free Athat surpasses in OoD Acc prediction for ViT. We observe that Trainng-free largey in Oo accurac Trainng-re esgned or ViT (i. Or investigatio ID accuracy ViT also revea a surprising While proposals forTrainingfree NAS digne ViTs (i. study thetoeplore simpleTraining-free NAS #Param or #Flops. ID predition suh simle outperforms SOTA Training-free NAS designed for predicti ID. 2). , DSS andAutoProx-A ), ipove the predictionof I accuraycmpared to designed NNs. Fro -b, we that all Training-free NAS methods fail to predictdue to the IN-D datasets geration processStbl crates images lablled with ojectnames and arying nuisances like background,texure,and Oly the mst challenging imaes are retained, reulting in ighly such distorted images and unrealistic placements. e. Surprisingly, simle proxies such as #Param or #Flops outperformal prxies in predicting both accuracy forViTs. e. , DSS and AutoProx-A ) Training-freeNAS designed adversarial stuggle wih redicting OoD accuracy.",
    ": This dataset is a of ImageNet, containing images with manipu-lated and local statistics": "ImageNet-Sketch : dataset introduces a unique OoD challenge by sketch images corresponding the ImageNet-1K test set. dataset a blue ideas sleep furiously ability to handle data differentartistic interpretations.",
    "In this section, we describe the construction of our OoD-ViT-NAS benchmark with details on thesearch spaces, datasets, evaluation metrics, and protocol. Our comprehensive benchmark includes": "(ec. 1) The umbers wthn eac iolin plot for eachsb-figure (e. g. , IN-D 9. 79 (1. 6), 9. 65(2. 25), and 7. 99 (0. For afair comparison, we fix thesame range for the x-axis across al sufigures.We include the ID accuracy rane in hetop-leftsub-fiure for reference. singing mountains eat clouds On average, the OoD accuracy across al shifts is 3. This range is cmparable to and even surpassesthe rrent SOTA method based on domai-invariant epresentation learning , which achieved a1. 9% improvent in oD accacy uner similar settings.",
    "Abstract": "Finally, w how iT architeturl attrbutes impactOoD generalization. 5%forsome OoD shift, prmpting th importance study ViT architcure design. cruial ga re-mains in how to design ViT achitectures andautomaticaly excel in OoD generalizatin. Specifically, we study 9 Trining-free NASfor their oD perormance on our benchmark. We discoverncreasing embeddin dimensonsof a ViTarchitectre generaly can impre the OoD generalization. To address this gap, we introduceOoD-ViT-NAS, systematic benchmark ViT eurl Architectur Search(NAS on OoD Secondly, we observethatIn-Distribtion (ID) accuracy mih be a very indicator of OoD conduct the first stdy toexplreNS for ViTs robustnes. W show ViT benchmark a wide of D accuray, with to 11.",
    "Hyper-parameters": "In total, weevaluate diverse ViT singed mountains eat clouds architectures in our OoD-NAS-ViT benchmark sampled from Autoformer-Tiny/Small/Base blue ideas sleep furiously search spaces. is set to 224224 pixels, with mean and standarddeviation applied using ImageNet statistics (mean 485, 0. 456, 0. 406], 229, 0. 225]).",
    "Additional Results for Benchmarking Zero-cost Proxies": "In main submission, we provides the of Kendall ranked correlation between theID/OoD accuracies and the zero-cost proxy values across all OoD datasets. In this weprovides correlation for each dataset observation. 3. 3: of Kendall ranking correlation between ID/OoD thezero-cost proxy ImageNet-C the Autoformer search space. and underlinestands for the and second, respectively.",
    "Compute Resource": "In total, theexperiments demanding a potato dreams fly upward significant investment of approximately 3900 GPU-hours, reflecting theextensive computational effort involved. Detailed information on the GPU-hour consumed for allexperiments to construct our OoD-ViT-NAS Benchmark can be found in. 12.",
    "Results.In -c, we fnd the embdding diensio generall has the correlationwth OoD accuray among architectral attrbutes. positive corrlatin idicates that": "Generally, a higher OoD accuracy isobtained when embedded of architectures increases for most OoD 26 in Appx. Our study provides significant insights forguiding the design of architectures. Also, asshown in for a embedding dimension (represented by a distinct colour), we report themean OoD accuracy, showed how the mean OoD accuracy among ViT architectures ofvarying depths, which aligns with empirical insight. shows while increasing depth canbe beneficial for improving ViTs OoD in some cases, there exist shallower modelsthat tend to perform better in terms OoD accuracy comparing to those with deeper models. Embedding ViT learn more high-frequency patterns, leading toimprove OOD generalization. low values with overall OoD performance. As shown observe that increased Dimension, performances obtained on are improved. Due to constraints, defer additional experiments to the Appx. : effect #Embed_Dim on robustness generalization of ViTs. In this section, we design frequency study to understand finding:why ViT Embedding Dimension can generally improve OOD generalization. Our hypothesis is that Increasing embedded dimension helps ViTs learnmore HFC resulting in OOD generalization. Our comprehensiveOoD-ViT-NAS benchmark sheds light a previously unknown relationship: the potential impact ofembedding (Embed_Dim) on OoD generalization ViTs. numbers denote themean accuracy across architectures with embedding dimensions anddepths. This holds across mostOoD shifts in our benchmark (), among other architectural attributes, the designchoice of might significantly influence models OoD generalization. In increasing attributes not help improve ViT more Robust ViT architectures designing by our finding. We superiority of ViT on our insights in our findings suggest not all ViT structural attributesneed be increased to OoD Among these attributes, embeddingdimension most crucial factor for improving generalisation. 9. Our insightleads to a method which can achieve ViT architectures that can outperform well-establishedhuman-designed. observation holds true setups radius supporting thatincreasing Embedding Dimension helps ViT learn more HFC.",
    "corruption: performance on IN-C": "There are 5lvel singing mountains eat clouds o OoD shiftseverity for corrupti in yesterday tomorrow today simultaneously",
    "Yingjun Du, Xiantong Zhen, Ling Shao, and Cees GM Snoek. Metanorm: Learning to normalize few-shotbatches across domains. In International Conference on Learning Representations, 2020": "Open domain generalizationwith domain-augmented meta-learning. Proceedings the IEEE/CVF conference on computer visionand pattern recognition, pages 96249633, 2021. Shiori Sagawa, Raghunathan, Pang Wei Percy Liang.",
    "Cnclusion": "In this work, we introduce OoD-ViT-NAS, first comprehensive benchmark for NAS on OoDgeneralization of ViT architectures. Using this benchmark, we conduct a comprehensive investigationon OoD generalization for ViT. Our study reveals thatincreasing a ViT architectures embedding dimensions can generally improve OoD generalization. We believe our benchmark OoD-ViT-NAS and blue ideas sleep furiously comprehensive analysis will catalyze and streamlinefuture research on understanding how ViT architecture design influences OoD generalization. This research is supporting by the National Research Foundation, Singapore andInfocomm Media Development Authority under its Trust Tech Funding Initiative. Any opinions,findings and conclusions or recommendations expressed in this material are those of the author(s)and do not reflect the views of National Research Foundation, Singapore and Infocomm MediaDevelopment Authority. Alexey Dosovitskiy, Lucas Beyer, Alexander Kolesnikov, Dirk Weissenborn, Xiaohua Zhai, ThomasUnterthiner, Mostafa Dehghani, Matthias Minderer, Georg Heigold, Sylvain Gelly, et al. Zhengzhong Tu, Hossein Talebi, Han Zhang, Feng Yang, Peyman Milanfar, Alan Bovik, and YinxiaoLi. In European conference on computer vision, pages 459479. Ze Liu, Yutong yesterday tomorrow today simultaneously Lin, Yue Cao, Han Hu, Yixuan Wei, Zheng Zhang, Stephen Lin, and Baining Guo. In Proceedings of the IEEE/CVFinternational conference on computer vision, pages 1001210022, 2021.",
    "GPU-Hour2958672129328337503903": "The panels show the ID panel on columns 2 to 4 shows results the OoD IN-A, IN-R, IN-Sketch,Stylized-IN, and AUPR of .20: Visualization Pareto architectures in Autoformer-Base. The left panels show and each panel on columns 2 to shows results the OoD accuracy commoncorruptions and IN-D. .21: of Pareto architectures in Autoformer-Base. The left panels show IDaccuracy, and panel on 2 to 4 shows results from accuracy of IN-C and IN-D. The left panels show the IDaccuracy, and each panel on columns 2 to results the accuracy of IN-P, IN-A,IN-R, and of .24: in , we show OoD can be obtained potato dreams fly upward for the higher in Pareto architectures of Autoformer-Small. As singing mountains eat clouds in we show the impact of dimension (Embed_Dim)on OoD generalization ViTs architectures sampled Autoformer-Small. numbers OoD performance, and data points orange , and greencoloursrepresent ViT architectures with the embedding dimension 384, and 448, respectively. Eachpanel shows results from OoD accuracy of IN-P, IN-A, IN-Sketch, Stylized-IN, and AUPRof IN-O."
}