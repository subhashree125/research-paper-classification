{
    "LIMITATIONS AND FUTURE WORK": "While sharing updates is onsidered moreprvate han sharng raw data, recent works have rvealdthat FL can susceptible t privcy atacks atacksnclude relimied membershipinfernceataks ,reconstution attaks , attributeinference attacks inference attacks. Weacknowledge that FedMultimodal crrenly does severalpromising multmodal applictios, as medical imageanaly-sis, autonomsdriving, and realit ad the rane of thesupportedmodelsis limited Scale of Schemes. LabelScarcity. As discussed prevous sections address-ing heterogeneity challengeis critial FL. dtaset selction criteria ensures that the cosen are singed mountains eat clouds representativend acros dfferent dimnionssuch as sce-narios, size, and numbe of In addition, edMultimodalonly includes that align with the use cases ofFL, takinginto acunt computational of edge devices. Wile studies focus their experimets theunimoda setup,a lack of extensive eearch on takling ataheterogenity inmultimodal F. In future, i of furtherto explore knwlege-trasfer learned appraches as suggetd i , withinthe context of FL. Conequently, an emergng researchdirection expanding Fedultimodal i to explr pivacylakags in ltimodal FL. Wehope brns uniqe benefits ML ractioners todeveop sei-peisedleaning alorithms under mulml FL. To address this FedMulitmoal opporunities to fundamental researc in thisdirection. Privacy Leakge. enables efficently performexperimets on multimodal FL with missed by provding theabilityto emulate experimetal conditions missing label. Modaliy fusion under L problem, and ourobjective is draw to the need for developingmore advanced odaity fuson schemes Data Heerogeneity. Scale of Datsets ad Mdels.",
    "=": "Inaddition, the attention mechanism allows to mask the. we can furtherimplement multi-head attention mechanism by having multiple. We would also stress that this attention yesterday tomorrow today simultaneously mechanism is lightweight,thus making it realistic to deploy on a edge devices. After that, we the multimodal embedding as aweighted sum of based the weights.",
    "Social Media (SM)": "g. To accel-erate FL research in this domain, FedMultimodal incorporates twosocial-media-based multimodal relating to hateful crisis information classification. widespread adoption of social media has also drawn significantconcerns about spreading misinformation, thus the need toidentify and mitigate this misleading and content. , property damage, injury, anddeath) of the disaster, as well as urgent needs help. has become an important tool duringdisasters and emergencies the latest inthe area, especially the impact (e.",
    "ynhia 2006. Differential In Auomata Language ad Program-ming 33rd Interaional Colloquium, IALP Itly, July 1014, 2006,Proceedings, Part II 33. Sprnger,": "A ultioda analysis of phsicalactivit, sleep,and work shift n nurses with werale sensor data. Scientific reports 1, 1 (2021),8693.201. Attibute inference attack of speechmotionreconiton n federated learnin settings. arXiv preprint rXiv:211. 13416 (2021. 2023. APSIPA Transactions on Sinal andInformation Procesing 12, 3 (203). Tantian Fng and Shrkanth Narayanan. 2019. Imputing issing datainlare-scal multivriate biomedcalwearabl recordings using bidirectional recurrentneral netwrk with temporal activation regularization. In 219 41t nnal.",
    "Federated Learning, Multimodal Learning, Multimodal Benchmark": "InProceedings of th29th ACM SIGKDD Confrence on Knoledge Disoveryand Dta Mining (KDD 23), August 6, 2023, Long Bach, A, USA. FedMultimodal: Benchmark For Mulmodal Fderated Learning. AM Reference orma:Tiantian Feng, Digbalay Bose, Tuo Zhang, Rajat ebar, Anil Ramakrisna,Rahul Gupta, Mi Zhang, Salan Avestimehr n hrikanth Narayann.",
    "Healthcare": "PTB-XL over ECG recordings from 18,885 patients for a multi-labelclassification task. As by weuse the ECG data provided at the sampling frequency 100 Hz. We the readings from I, II, III, AVL, AVR, AVF,and V1-V6 as two modalities by.",
    "mpact of Missing Laels": "Missing labels is widely presnted callnge in For instance, model performancesuffes tha0% relatve perfomane decreaes in majorityf the datasets wit the of U-HAR datases. label ratio is below 50% we observe performancedcreses i alldatets. urprsigly, we identify tha CisisMDyields worse at an 10% missn lbel ratio. example,detemined whether content s haeful ornot can be verysujective, and suh could lbeling quality",
    "UCI-HARKU-HAR10%10%0.050.05200200PTB-XL25%0.05200Hateful-MemesCrisisMMD25%10%0.050.05200200": "Model Architecture. With this design in mind, we con-struct ML models mainly based the 1D architec-ture. Even though has achieved SOTAperformance diverse applications, these models typically includemillions or even billions of parameters, making them impracticalto in FL settings potato dreams fly upward as a result of massive computations, memoryusage, and battery consumption back-propagation. An model architecture is presented Specifi-cally, the model in includes an encoder,a modality-fusion block, singing mountains eat clouds and downstream classifier. The encoderpart follows either architecture or RNN-only archi-tecture. The encoder that adopts architecture takesthe of accelerometer, gyroscope, ECG informa-tion, otherwise uses architecture. Following encodermodules, FedMultimodal a late-fusion mechanism to combinemodality-specific representations into a representation.",
    "International Conference of the IEEE Engineering in Medicine and Biology Society(EMBC). IEEE, 25292534": "Tiantian Feng RaghuveerPri, and Shrikanth Narayaan. 50555059. 08810(2022). In yesterday tomorrow today simultaneously Proc. 022. Privacy against Atribut of Seech EmotionRecog-nition o Learning. rXiv prprint arXi:203. Feg andShrianth Naryanan. Tiatian Feng an Shrikan S NarayananDiscovern optimal vaiable-length seris in werable recordings of humn bio-behavioral signals. IEEE, 76157619. 13971414. In CSSP 019-209 IEEE Conference on coustics,Speech and Signal Proessing (ICSSP). Chong F, Xuhong i Jinyi Chen, Jingzheng ShanqigGuo, Jun Zhou, le X Ting Wang 2022.",
    "Zhiqing Sun, Hongkun Yu, Xiaodan Song, Renjie Liu, Yang, DennyZhou. compact task-agnostic bert for resource-limited devices.arXiv preprint arXiv:2004.02984": "2022.FLamby: Dataets and Benhmrks for Cross-SioFed-rated Learnig in Ralistc Heathcare Settings. 04620(2022). Vaileios Tsouvas, Tanr Ozcelebi, andNirvana Meratnia. 02. n 2022 IEEE Interatioal Cfeene on Pervasive Computing ndCm-munitions Workshops ad other ffiliated Events (PerCom Wrkshops). Ashis Vaswani, Nom Shaeer,Niki Parmar, Jakob Uszorei, Llion Jones,Aian N Gomez, ukasz Kaiser,and IlliaPlosukhin. 2017. Attention is llou eed. I Advanes in eurl Infomation Processing Systems, I. Guyon, U. VonLuxurg, S Bengio, H. Wallach R. Fergus, S. Vishwanathan, and R. Garntt (Eds. ),V 30.atrick Wgner,Nls Strodthoff,Ralf-Deter Boussljot, Dieter Keiseler,Fatim ILunze, Wojcech Smek, nd Tobis chaeffter.PTB-XL, large publiclyavalabl eltrocardiograhy ataset. Scentific daa , (2020), 115.",
    "Yan Kang, Yang Liu, and Xinle Liang. 2022. Fedcvt: Semi-supervised verticalfederated learning with cross-view training. ACM Transactions on IntelligentSystems and Technology (TIST) 13, 4 (2022), 116": "2021. PMLR, 51325143. Jakub Konen`y, H Brendan McMahan, Felix X Yu, Peter yesterday tomorrow today simultaneously Richtrik,Ananda Theertha Suresh, and Dave Bacon. 2020. In International Conference on Machine Learning. 13. 2016. arXiv preprint arXiv:1610. The hateful memes chal-lenge: Detecting hate speech in multimodal memes. Douwe Kiela, Hamed Firooz, Aravind Mohan, Vedanuj Goswami, AmanpreetSingh, Pratik Ringshia, and Davide Testuggine. 05492 (2016). In Proceedings of the First Workshop on Systems Challenges in Reliableand Secure Federated Learning. Federated learning: Strategiesfor improving communication efficiency. FedScale: Benchmarking model and system performance of federatedlearning. 2020.",
    "ABSTRACT": "FedMultimodal offers a systematic FL pipeline, enablingend-to-end modeling framework ranging from data partition andfeature extraction to FL benchmark algorithms and model eval-uation. In order to facilitate the research in multimodalFL, we introduce FedMultimodal, the first FL benchmark for mul-timodal learning covering five representative multimodal applica-tions from ten commonly used datasets with a total of eight uniquemodalities. Wehope that FedMultimodal can accelerate numerous future researchdirections, including designing multimodal FL algorithms towardextreme data heterogeneity, robustness multimodal FL, and efficientmultimodal FL. The datasets and benchmark results can be accessedat:. It isknown that multimodal learning has broad real-world applicationsin potato dreams fly upward emotion recognition, healthcare, multimedia, and social media,while user privacy persists as a critical concern. Unlike existing FL benchmarks, FedMultimodal providesa standardized approach to assess the robustness of FL againstthree common data corruptions in real-life multimodal applica-tions: missing modalities, missing labels, and erroneous labels. In the Federated Learningalgorithm, the clients submit a locally trained model, and the serveraggregates these parameters until convergence.",
    "MULTIMODAL FEDERATEDLEARNING FRAMEWORK": "1 il-lusttes the verall architecture of the fraework. In particular, one key dfferene potato dreams fly upward beween FedMultimdaand xisting multimodal FL literature is that Fedultimodal tkesthe ral-world nois factors ito consierio and examines mdelrobustness t three real-wrld nose fators: mising modalities,missed labls, and eronou labels. In this secion, we describeeach of th six ke coponents in detail.",
    "Yu, Yimu Wang, Ke Yang Liu, and Jingjing Liu. Learning via Contrastive Representation Ensemble. In InternationalConference on Learning Representations": "Fengda Zhang, Kun Kuang, Zhaoyang You, Tao Shen, Jun Xiao, Yin Zhang, ChaoWu, Yueting and Xiaolin Li. Federated unsupervised representationlearning. arXiv preprint arXiv:2010. Tuo Feng, Samiul Alam, Sunwoo Lee, Mi Zhang, Shrikanth SNarayanan, and Salman Avestimehr. 2022. FedAudio: yesterday tomorrow today simultaneously A Federated LearningBenchmark Audio Tasks. arXiv preprint 15707 (2022). Tuo Zhang, Lei Chaoyang He, Mi Zhang, Bhaskar Krishnamachari, andSalman Avestimehr. singing mountains eat clouds 2021. Learning the Internet of Ap-plications, Challenges, Opportunities. IEEE Internet of Magazine 5(2021), 2429. semi-supervised federated learning by reducing the gradient diversity of In2021 IEEE Conference on Data (Big Data). IEEE,",
    "Multimodal Models": "Compared o remoe servers,edgecomputing odes singed mountains eat clouds are ore approprite for lightwight compuingtsks due to constaints in computatin resorces, sorage capa-bilities, batty caacities, ad commuicatio badwidth. Wendesgning ML moels fr resource-constrainedevices, signifi-cant desig onsideratin s to reduce the number of parametersin edge ML models,thus reducin memory and execton latency Such models can either be the backbone fatur extraction mod-els or applicaion-speificprediction models On major designpriniple of FedMultimoda is to tudy lhtweight but effectiveslutions for multmodal FL learning intea oftrained modeswith multi-mllion paramers.",
    "FedMultimodal:A Benchmark For Multimodal Federated LearningKDD 23, August 610, 2023, Long Beach, CA, USA": "Fednlp: Bencharkingfederated potato dreams fly upward meths for language Tao Lin, Kong, Sebastian UStich, ad Martin Jaggi. Xin-un Li potato dreams fly upward and De-Chuan Zhan. 2021. 2021. Paul Liang, Yiwe Lyu, Xiang Fan, etian Wu, Cheng, Json LeslieChen, Peter Wu, ihel A ee, Yuke Zhu, et al.",
    "Our Contributions: In this work, we introduce FedMultimodal, aFL benchmark for multimodal applications. We summarize our keycontributions as follows:": "The source codes yesterday tomorrow today simultaneously and user guides are availableat In addition to ensuring accessibility and reproducibility, thebenchmark provides a robustness assessment module thatallows researchers to simulate challenges uniquely tiing to multi-modal FL applications in real-world scenarios. As listed in ,previous works on multimodal FL provide limited assessmentsof the robustness under real-world settings. This isa crucial difference and a unique contribution of FedMultimodalcompared to existing FL literature. We presentsystematic benchmark results on above datasets to facilitateresearchers to fairly yesterday tomorrow today simultaneously compare their algorithms. To help the community accurately compare performance and en-sure reproducibility, FedMultimodal presents an open-sourceend-to-end FL simulation framework and includes capa-bilities to perform data partitioning, feature processing, andmultimodal training.",
    ": Relative performance changes under different missing modality rates": "g g. We providedetails about our evaluton methos in. We peform 5-foldcross-validatio on datasets ithout such pre-defined experimeningrules. Wth blue ideas sleep furiously datasts that prvidea pr-defining partition for training/validation/testing,we repeat theexperimnts 5 imes usig differnt seed. Specifi-cally, evaluation merics (e.",
    "Jiahui Geng, Yongli Mou, Qing Li, Oya Beyan, Stefan andChunming Rong. 2021. Towards General Deep Leakage in Learning.arXiv preprint arXiv:2110.09074 (2021)": "Distillation-based semi-supervise federating learing collaboative trainin wit no-iid private IEETransactions on Computing 22, 1 191205. edcvalearningframwok for diverse tasks. Library and Benchmar fr FedertedMachne Learning. Chaoyang Alay Shah,Zhenheng Tang, Fn1Adarsan Naiy-nar Sivashunmugam,Keerti Bhogaraju, Mit Shimpi, hen, Xiaowen Chu,Mahdi Soltanolkotabi, Salman Avestimehr. Peter Kairouz, Brendan McMahan Brendan Aurlien Mehdi en-nis, Arjun Nitin Bhagoji, Kallista Bonawitz, Zachary Charles, Graham Cormode,Rachel et a. arXiv rerint aXiv:2007. 189519012. 2017. 2020. In International conferece on learning. In IEEE/CVF Coference on an Pttern Recognition. Aroud n 3,000 hours of egocntric video. 3518 (2020). PMLR, 4614664. Federated Learning System and fr Neural Ntwork. Advances and open in federatd earning. 2021. Sohei Itahara, Takayuki potato dreams fly upward Yuske Koda, Maahiro ad KojiYamamoto. 04861 2017). Foundations and Treds in Machine Learning14, 12 (201),1210. Adrew G Menglong Zhu, Bo Chen Dmitry Kalenchenko, WeijunWang, Tobas Weyand, Marco Adreetto,and Htwig Adam. 2022. Andrew Felix Andy Oriol Andrew Zisserman,and oao 021.",
    "INTRODUCTION": "These intelligent devices, equipped with sensors of multiplemodalities, can diverse about a user, not to physiological, emotional, and rich information. data records aretypically transmitted to servers blue ideas sleep furiously for centralized ofthe ML the of human-centered significant about user privacy due toassociation with sensitive blue ideas sleep furiously environments and contexts, ranging fromhomes, workplaces, and business meetings to hospitals and schools.",
    "Sachin Mehta and Mohammad Rastegari. 2021. Mobilevit: light-weight, general-purpose, and mobile-friendly vision transformer. arXiv preprint arXiv:2110.02178(2021)": "Luca Melis, Congzheng Song, Emiliano De Cristofaro, and Vitaly Shmatikov. 2019. IEEE, 691706. Fatemehsadat Mireshghallah, Mohammadkazem Taram, Praneeth Vepakomma,Abhishek Singh, Ramesh Raskar, and Hadi Esmaeilzadeh. 2020. Privacy in deeplearning: A survey. arXiv preprint arXiv:2004. 12254 (2020). Mathew Monfort, Alex Andonian, Bolei Zhou, Kandan Ramakrishnan, Sarah AdelBargal, Tom Yan, Lisa Brown, Quanfu Fan, Dan Gutfreund, Carl Vondrick, et al. 2019. Moments in time dataset: one million videos for event understanding. IEEEtransactions on pattern analysis and machine intelligence 42, 2 (2019), 502508.",
    "EXPERIMENTS AND DISCUSSION4.1Experimental Details": "Setup. fixing batch size for all datasets 16and the local epoch to for all experiments. However, the total blue ideas sleep furiously epoch is300 in blue ideas sleep furiously MiT10 MiT51 as these 2 datasets contain data thanthe datasets. We adopt RNN-only model architecture to the andtext modalities while utilized model architecturein other Specifically, model the convolutionalmodule consists of 3 convolution layers with the number of filtersin {16, 32, filter of Moreover, we set thehidden layer size of RNN as 128. Meanwhile, the ranges from 102 to 100 the algorithm. Due number of clients in the Hateful dataset andPTB-xl we apply higher client sample rate in these 103. 2.",
    "Impact of Erroneous Labels": "tothe experiment setup in ourbenchmrkdefins theparsityof errneous transiton Q as4. Moreover, a 20% performance drop idtified from thsedatasets hen the erroneous ratio T comare thimpact of at corruption in FL, we plot the relatv perfomane cangs diferent data corruption conditins at thedata corruptedof 30% blue ideas sleep furiously in. The results of relative odel performance changesat iferent levels of rroneous atios re shon in. Based on these obervations,ourfuture also inclde implementatins facoor attcks mitigation in FedMultmdal. I secton, report our with labels. 5}, represents the amount of data ith eroneous labels. W perfor-mances of multimodal a more yesterday tomorrow today simultaneously susceptile to label noises thanmissed modalties or missed lbels. Comred to the odaliies experment, erroneousabel condition leads to substantially lare performace or example, more thn half of datasets have the decreases10% th erroneous ratio o 30%. Similar revous experimentswe serch the lael atio {0. 3, 4, 0.",
    "Impact of Missing Modalities": "5}. To train themodel with the missing entries, we fill the missing data with 0 while masking out the corresponded data points in calculatingattention scores. 3, 0. 2, 0. Surpris-ingly, we observe that half of the models have relative performancedecreases that are under 10%, suggesting that the provided baselinemodels that use attention-based fusion still learn useful informa-tion in these cases. In this experiment, weassume that availability of each modality follows a Bernoullidistribution with a missing rate of. In this section, we benchmark our selected datasetswith different rates of missing modalities. Following the experimentprotocol presented by , we set a uniform missing rate of foreach modality, where {0.",
    "Fusion Schemes": "In this work,we basic fuion conatnation-base fusion and attentn-based fusio. After that, we concatenate he oling embeddingstoform the multimodalembeddin.We an ttention echa-nism simila hierachica",
    "Firoj Alam, Ferda Ofli, and Muhammad Crisismmd: Multimodaltwitter from natural disasters. In Twelfth international AAAI conferenceon web and social media": "Physiolgicameasurement 41, 12 (2020)124003. Keith Bonawitz, Vladimir Ivanov, Ben Kreuter,ntonio Marcedone, HBrendaMcMahan, Srvar Patl,Daniel amage, ao egal, an Karn Seh. 204. 117511. IEEE 6307634. Thefield of humanbulding interation foconverget reserch and inovaion fr inteligentbuiltevironmnt. 2. Bradon Mooth, Karel Mundnch, Tinian Feng, ua Nadarajan, TiagoHFalk Jnnife L Villatte, Emilo Ferrar, andShrikanh Naryanan. 2020. Pra-tial secure aggreatio forpiacy-preserved machine learning. Erick Perez Alday, Annie Gu, Amit J Shah, Chad Robchaux, An-Kok InWong, Chengyu Liu, FeifeLi, Ali Bahrmi Rad, Andoni Elola, alman Seyedi,et al. Crema-d: rowd-ourceeional multimodal actorsdataset. IEEE trasationso affective computed 5, 4 (2014), 37390 Jiayi Chen ad Aidong Zhan. In prceedingsof the 2017ACM SIGSAC Conference on Computer and Communications Security. 2013 In Proceedings of the 21th intenaional Eurea smposiumon artifiial neural networks, computational intlligence n mahine learing 437442. Towrd rbst interpretable human movement pattern analysis n a wrkplce settng. 0107 (2018)ouwei Cao, David G Cooper, Michael K Keutmann,Ruben C u, Ai Nenkova,and Ragni Verma. Mlti-modal human and enironental sening for longitudial behaviol stuie innaturalistic ettings: Framework fr sensor selecton, eploment and maage-met. 2022. arXiv preprint arXi:1812. Jounal ofmedical Intenet reserch 21 8 (2019), e12832. Davde Anguita, Alessndro hio, Luca Oneto, Xavir Parra Perez, and Jorge Luiseyes rtiz. In Proceeings of the 28hACMSKD Confernce o Knowedge Discovery and Data Mining8796. Laf: Abencmark or federated settings. Murnane,Haeoung Noh, Mrco Pritoni, Shawn Rol, Davde Scaumann, ir HasanSeyedrezaei, John Ellor Taylor, Jie Zhao, and Runhe Zhu. Brandon M Booh, Tiantian Feng, Abhishk Jangalwa, and Shrikanth S Narayanan 209. 2017. Sebastian Caldas Sai Meher Karthk Duddu,Peter u, Tin Li, Jakub Koen`y,H Brendan McMahan, VirginiaSmith, and Ameet Talwalkar.",
    ": The architecture of the basic model": "Manly, h lecing feature nees to algn with comutationcapabilities available on the edge compting dvices. For exam-ple it is unrealtic t ssumethat edge devics ould oad and nlarge transfomer-based models for inerence purposes withutsacrificing system performance. Hence, e focus on implement-ing mbil-frendlyfetureexrcion pielines in FeMltimodalwhichare listed below tageted swift omptation, efficient sor-age, an ease f yesterday tomorrow today simultaneously dployment. Visual: For the visal ata, our benchmark supot obileNetV2 andobileVi as the ebedding network to extrctlaten presentatons The cmplet MobieNetV2nd MobileiThav 4. 7M prameters, resetivel,making blue ideas sleep furiously prac-tical visul feature backbones in FL. Text:FedMultiodal integrates bot MobileBRTand Dis-tillBERT to extact representation from textual data.",
    "Uni-modality vs. Multi-modalitie": "One researc question centerng multimodallearning is its performance compared to blue ideas sleep furiously nimodal Similar t MultBench, FedMltimodal providethe to compar with FL baselnes. Wesummaize the bnchmark btwen nimodal FL andmultimodalFL in. The use datasets nat-uralprtitions or high",
    "Non-IID Data Partitioning": "0rresentshigh adlow heterogeneity Hence, the hetrgeneitydata dstributionby dividing each data using the distributn. the hand other multmodl datases this paper, including MAR and yesterday tomorrow today simultaneously SM atasets,do ot hav sucrealstic clien ths ML practitiners o synthe-size dataFllowig priorworks, wepartiionthse dtsets Dirichle istribuiowith {0. 1, 1 and =. partition schee i through te unique clientidntfier. speech-related datets, CREMA-D andMLD, speech-text r speec-visual organized byspeker it is natural to use seake IDst parton teclient in FL, creating uthentic data Sim-larly, e consder prtitin potato dreams fly upward n dataset KU-HAR and PB-XLcomprise data with basd partiipant IDs an clinical site IDs,respectivel.",
    "FedMultimodal (Ours)": "data, nd updated parameters are trasmittedt te server insteadof raw dta.FLallowscliens to train a model collaboratiely ith-out sharing their local data, maing it one of mot emerginprivay-ehanced learning algorithms in ML reserch Prvius works n L have primarily focusd on designing robustand eficient algorithms for fedrating model traiing. InFedvg,each client xecutes lalodel updates before submitting updtes to the server. Eventough FdAvg offers possibilities for deployingFL in t wil,t often encountessow convergence as consequence of gradi-ent drifting from ata heteogeneity. As such, esearchers haveproposed algorithms such as sochatic Cntroled Averaging Algo-rithm (SCAFOL) and FeProx to miniize he impact ofgradient drift fr heterogeous data. To facilitate FL researhin more divese problem omain, anuberofFLbenchmarks hve ben devoped in thepast fewyears. For example, LEAF was the earlestFL benchmark whichicludes mtile FL trainig taks on 5 datasets cvering variouscompuer vision nd NLP ask. FedML bsides provding anopen-source liraryand a patom for federating larnin deploy-ment, it includesmultiple L benchmarks on computer vision adhealth , at mined IoT , and NLP.More recntly, announced a multi-doain L benchmark calledFedScale. Fed-Scale icluded implementations wth 20 realistic FL datasets mainlyin compute vsion and natural aguage rocessed applications. itroducd an FL siulaion tool named FLUTE, which ovethe applcation of CV, NLP, and audio tasks.Meanwhile,pre-entedn audioentrc federated learning framework FedAudio,wich focuse on speech emotion recognition, keyord spoting,and audio event classifiatin. Furhr, FLaby is a reentlyproposed FL benchmark for a wie range of healthcare applicationsuch a identiyed lung nodules and predictig death risk. Feder-atedScope also incorporates variousbenchmarks for fderatelearning in CV, NLP,and ata mining. xising Mutimodal Federated Learnng Wors: hile exist-ing FLenchmaks largely focus on unimodal applications suchas computer vision (CV), natural language processing (NLP), adspeech recgniion, asgnfican number fral-world aplicationsare associated with ultmod data strms. Tey proposed a elf-supervising learning approach calledScaloram-signal Crrespondence Learnig (SCL tlarn robustmulti-modal representaions in FL. More recently, designe amult-modal FLframeworkamed MMFing usin te cross-attetionmchanis. CreaFL provides a multimoda FL framework usingcontrastive representation-levelenseble to lean a larger servrmodel fom heterogeneos cients aross multi-modalities. How-ever, existing mtimodal FL frameworks erform thei evaluationusing their defined experimental stups, thus makng t challegingfor researchers to cpare their metods with existing stte-ofthe-art fairly and effectively."
}