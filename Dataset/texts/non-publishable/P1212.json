{
    "PRELIMINARIES": ", V E. We begin bythe conceptstht willbe using our paperand formally definingthe reommedation User-Item Interaction GraphIn a tyical recommendation we hae a set of denoting b nd aset by. construct binary graph = (,, deote blue ideas sleep furiously the collabative ials between uers and items, wth= 1 user interacted with tem , an vice We real-wrd knowledg aboutitems with ahetergeneo graph consiting of tripls, denoedby = (,,). Our KG-aae recomedation beformally descibedas follows given a user-item interaction graph,denoted and knowledgegra, denoted by G ourgoal is recmmender model,denoed by F (, |G, G, ), whereF epresents the moel architeturewith learnable parameters. t mportant o note te iem set i a of entity set, i. outpu of te model is vlue in the range that ndicatesth likelihood of se interactin with item. , singed mountains eat clouds E ae nowledge entities, Rrepresentsthe relation connecing them, such (author,wroe, ok).",
    "Baoxu Shi and Tim Weninger. Open-world knowledge completion.In AAAI on Artificial Intelligence (AAAI)": "Fei Jun Jin haghua Pei, Xio Wenwu Ou, and PengJiang. BERT4Rec:Sequential recomdation bidirectional re-rentations transformer. n on Information andKnowledge Management (CIKM). 14411450. Zhiqing Dng, Jian-Yun Ne and Jian Tang. [n. d. ] Knowl-edgeGraph by Reltional Rotation in Complex pace.221. I Internatioal Cnfernc on Research and Develpmentin Information Rerieval (SIGIR).",
    "S {(,,|(,,) topk(; )}; G G \\ S,(11)": "In Equation 8, we introduced the knowledge attentive scores and, which are computed with the addition of Gumbel noise. In addition to the knowledge graph, we also aim to improvethe quality of the u-i interaction graph by removing noisy interac-tions that are not conducive to cross-view alignment. Here, represents the distribution of all values. The hyperparameter controls the dropout ratioduring training. Specifically,we want to blue ideas sleep furiously retain interaction edges that clearly reflect the usersinterests and can better guide knowledge graph rationalizationthrough cross-view contrasting. We also introduce the augmented knowledge yesterday tomorrow today simultaneously graphG, which is debiased from noise with lower rationale scores.",
    "Rationale Discovery for Knowledge Graph": "This ratio-nale function weighs each triplet on a singing mountains eat clouds attention Inspired by the heterogeneous (HGT) , which importance ofheterogeneous relations, we implement the rationale weightingfunction (,,) yesterday tomorrow today simultaneously as",
    ": Evaluation on different KG proportions": "We randoml selected a proportion knoledgetriplets frm original KG the Last-FMand or noledge aggregation, and the resultsare in. This ca be attriute to th design f mining,which KGRec to better knowledgeandimprove learning for lng-ail its. 4. 4. Speciically e testedtherecommendation perfomance of KGRec baselie underpartial knowledge graphs keeped rtios rangingfrom to 70%. Compared to baseinemodels, KGRec hows minimal perforan degadation all cases. Therefore,KGRec can effectively alleviate cold-sartissue. e then teted the performance andstrong baslines ineach group reported teresultsin. Our findigs demonstrate that outper-form methds in all groups, indicatingits effctveness in addrssigcol-stat for aof er. 2Long-tail Item WetherKGRec learning items. Our demonstatetha KGRec can erformance (>95% onLst-FM and >90 on Alibaba-iashion) with only smll KG. 4. Wecounted the occurrence of eachtem and all users into fivegroups based on the average sarsity iems thy iteractedwit. 4. Our findings KGRec consistently bselinemodels across differ-ent goups, indicatingeffectveness in addresingscarcityprobles. This can be attributedto design of masd and rationae-based ross-viwconrastiv learning, which fo and contras cross-view signls.",
    "(,,) = |N| (,,) =|N| exp ( (,,))(, ,)N exp ( (,,)) . (6)": "multpythe ratinale scoe with thenumber hea ntity |N|,which makes it globally comparable. By using thi wecan select the mos valabl nowledge tripletsacrossthe entireKGon value singing mountains eat clouds of(,,).",
    "Kai Wang, Yu Liu, and Quan Z Sheng. 2022. Swift and Sure: Hardness-awareContrastive Learning for Low-dimensional Knowledge Graph Embeddings. InThe Web Conference (WWW). 838849": "220.Understandig ontrastive representationlearning though alignment and uniformiy on the hypersphee.9299939. 950958. 2019. Neurl graph cllaborative filtering. Xiag ang, ingln Huang, Dingxian Wang,Yancheng Yuan, Zhenguang Liu,Xiangnan He, et al. Explainable reasoning over knowledge grphs fr recommendtion. In AAAI Conference on rtificial Intelligence (AAAI, Vol. 59536.",
    "RQ2: Ablation Study": "4. In this study, we investigte theeffectieness o key modules in proposed KGRec per-pecties of rdesigned rationalmasked autoencoding and con-trasive larning To compare he origialmethd, built four singing mountains eat clouds variant,MAE: removing the generative SL task rationale-awareknoledge gaph maskng nd reconstrction.",
    "GC-MC considers recommendation as a link prediction prob-lem on the user-item graph and proposes a graph auto-encoderframework for matrix completion": "KTUPtrains TransH using prefrence-injected complementation btween ad KG signals. KNN-LS ser peferencestoards triplets convolution and introduces labelsmothing asegulariaion to force similar user preferenceweihts betwen nearby itemsin the KG.",
    ": Study of KRec": "3 for Alibba-iFashio, and 0. 1 recommening for MIND0. We suggest mskingsize an CL kee ratio in te range of and [0. lthough KGRec is relatively rbust to smallchangesin the optimal settins is tilritical the best perforance. Moreover L keep of. 5 is he best choe for Last-FMnd Aliba-iFashion, hile a of. 4,. 9 W hypothesize thatthisdiffernce in optimal temperature due to the ofthe datasets, with denser atset requiring higher temperaturesto avoid falsenegatie samples. we investigate the of GRec to changesin key hypeparameters,inluding size , thefo CL graph augmentation , and the temperatue for CL. 6],espetively, a good startig point for tuning othr dataes.",
    "Rianne van den Berg, Thomas N Kipf, and Max Welling. 2017. Graph convolu-tional matrix completion. arXiv preprint arXiv:1706.02263 (2017)": "Yixin Cao, Xiang Wang, Xiangan He, Zikun Hu, and at-Seng Chua. 219. Unifyingknowledge grphlarning and recommendation: Toards a betteunderstanding f user prferences. In TheWeb Cnference (WWW Jinguan Chen, anwangZhang Xiangnan He, Liqiang Nie, Wei Liu, and Tat-Sen Chu.335344.",
    "Freedivig": "By forcing KGRec tlearn to reconstruct these importan connectios, we highliht ask-relting knowldge ratiales. Thusfor the undewter cameras, the knowledge PhotogrphyandDigital am ill be less mportnt compard toSports Cam To ddrssthis challenge, weprope ne knowedge grah-enhand rcommender system,calledKGRec to leverage atentveknowledg rtionaization togenerate task-related rationl scres for knowedge trilets. To beter undertand th reationship betwen KGand CF signals, we proide an example of an e-commerce pltformwhere users often purchase died glasse andunerwater camerastogeter. The distribution of atention score in te KGAT modelshos that only small prootin of kowledge tplets hae hghatenion scores and aethus highly contriutive to recommenda-tionas rationles The remaining knowledge triplets exhibit a longtailof low scos in distribution adare less informative inthe netork. Fnall, we inect rationa score nto te knowleg agregationfor he reommendaton task, enabling knowledge rationa scoesto be learning tightly from the CF labels. To make accute predictions, he conectionswith com-mon semantc Sports/Diving will be highlighting in K. : he lf figredisplays a dstribution ofattntivescoresfor knowlege triplets in the baseline mehod o KGAT,whch is skewed owards the tail end. W alo alinthe raional seanicsbetween the KG signals and heCollaborative Filterin (CF) sgnalsvia a knowledge-aware ontrasting mecanism. his is achivedby fiterngou lo-scored knowledge that may beptntial noiseby masing during graphaugmetation for conrstive learning. In summary, we make he ollowng coributions intis papr:. nforation, failing to osider the imorantlen rationales be-tween th KG and recommendation task.",
    "Christoph Feichtenhofer, Haoqi Fan, Li, and Kaiming He. 2022. As Spatiotemporal Learners. arXiv preprint (2022)": "Gutmann and Aapo Hyvrinen. In on Intelligence and Statistics (AISTATS). 2022. Masked autoencoders are scalable vision",
    "CONCLUSION": "In this we presented a self-supervised rational-ization method (KGRec) for knowledge-aware recommendation. Our is rooted in the hierarchical of knowl-edge triplets. This directioncan potentially provide more insights into underlying graph structure.",
    "Yankai Lin, Liu, Maosong Sun, Yang Xuan Zhu. 2015. Learn-ing and relation embeddings for knowledge graph completion. In AAAIConference on Artificial Intelligence (AAAI)": "Weijie Liu, Peng ou, ZheZhao, Zhuo Wag, Qi Ju, Haotan Deng, and PingWang. Kbert: Enabling anguage rpresention with knoledge graph. 2020. 209 In InternationalConferece on Uncertainty in Atificial Intellignce (UAI). 012908. Steffen Rendle, Christoph Freudenthaler, Zeno anner, andLarsSchmit-Thieme.",
    "Experimental Setup": "4. 1. 1Dataset. To ensue a diverse and represenative evaution,we use hree distinct singing mountains eat clouds datasets that scearos: music ecommendaton, MIND for ews ecommenations, for recommendations. teknwledegaphs, emloy mehods oreach For Lt-F, we map the itms to Freebase triplets, foloed the techniques used in an. ForMIND, e ollect graph from us-in te entitiesin te original data, ollwing theapproach ropoed in. 1. 2Evaluation Protocols. e easure the performanceo our proposing KGRec using thRecall@N andNDCG@N metrics with N set to 20 fr rcm-mendations. pecfically, we ex-plore ofmaskg sizethe range of {128, 256, 512, 1024},keeping proportion and 0 4, 0. , 0. and tem-perature value the range 0. 1, , ofGNN is set to for all mthods.",
    "KGRec0.09430.08100.04390.03190.11880.0743": "KGNN-LS andKGCN cannot consistently utperfm SGL in somemetrcs. On the other hadLightGCN and SGLfous more on reoving the parsity potato dreams fly upward problemo user-em nterctions wih self-supervision signals. relatedness and CF signals. MC-CLK KGCL) are not alwas better than on-self-supervisedmethods (e g. KGIN). For instancemethodsasCKE KTP typicall perform worse thannon-KG like and SG. Contraive learningbased mtods (e. Thiseffect is more noticeable when the has complex sprseintections. Third, knowledgeaggregation layer knwledge ratinal scres to re-flect difernt imprtance of knowledge tripets.",
    "(,,)D log ,(18)": "In BP loss, the trainng insances D= , , where is ground-truth and is sampled ngative int-action. is worth noting we continue to the entity em-beddings e the masked graphG for the recommendatiotask, rther than aggrgatio on orginal again. This isbeause the masking triplets are ofsmall size (e. , 512) compared to the whole raph(e. g. , this trick can greatly iprove raining efficiency whileaffectingrepresentatin learning onlyminmally optiize al three functions, we use a join with te overall loss function:.",
    "Self-Supervised Recommendation": "For recommen-dation, S3Rec aims to sequence itself by and adopts the augmented sequences as anauxiliary task. Existed studies various SSL techniques for different tasks. Incorporating (SSL) techniques recom-mender systems has become a new the research communityto address inherent data sparsity problems leveraged additionalsupervision signals yesterday tomorrow today simultaneously raw data. Formulti-modal recommender systems, MMSSL provide auniversal for captured both modality-specific effects and cross-modality interaction dependencies, allowingfor more recommendations. KGCL develops learning on the toalleviate and long-tail problems, while also leveraging from KG agreement to guide user/item we argue that these methods do not sufficientlyconsider rationales embedded in the KG. applies contrastive learning to graph filter-ed using random augmentation graphs such as node dropout,edge dropout, random walk to generate contrastive andenforce agreement with InfoNCE loss.",
    "=exp exp; multinomialNR(; ),(13)": "After calculating the for each which represents value of the rationale for all tripletslinked to the item, we apply softmax to obtain distri-bution over all items. e. By followingthe definitions, we can generate the augmented graphas difference between the graph and the set ofsampled S, i. 4. Withthe augmenting knowledge graph and u-i graph, we use pre-definedaggregators to capture the representations foritems as contrastive embeddings. , G = G S. 3. 2Contrastive Learning with Cross-View Rationales.",
    "the knowledge graph for and align them anoise-free and rationale-aware manner": "Our proposed rationale-aware masking mechanism allows us toidentify and most and blue ideas sleep furiously relevant the graph, while suppressing yesterday tomorrow today simultaneously potentialnoise or irrelevant knowledge graph connections",
    "(,, )N(,,)e e(1),(3)": "To injct relatinalcontext, we the same elementwie product in Equation tobridge th betwenggregation nd rationale weighting. Threfore, we oban itembyaggregating paths e e1 e on e using. B suc aggregatin acrss the etre graph,weconsideth relationships nowl-edge entitiesand eight neghbor fo the head o normalized ationae worth noting item are asubse f knowledge ntities. where deotes layer of aggregator, and N G thende-cntric sub-graph of first-order neighbors.",
    "Rationale-aware HeterogeneousKnowledge Aggregation": "Inspired by workssuch as , we an aggregation layer for the knowl-edge that reflects relational heterogeneity knowledgetriplets. To build the knowledge aggregator, weinject relational potato dreams fly upward context the embeddings of the weighting them with the knowledge rationale scores.",
    "Chao Huang is the corresponding author": "Abstracting with credit is permitted. Request permissions from 610, Long Beach, CA, USA 2023 Copyright held by the owner/author(s).",
    "e = (G ;); e = (G": "A this oint, the kowledge tripletwith signifcat rationale scores, enoted M, which wer notvisible agegation stage, can potato dreams fly upward be used as for reconstrtion. the blue ideas sleep furiously relational heterogeneity inthe knowledge graph, we aim reconsruct the tionalconnections undr elatinal cotexts. To this, we minimzt folowing dot-prodt lo-loss for the triplets, with the sgmoid fuction:.",
    "23, August 610, 2023, Long Beach, CA, Yang, Chao Huang, Lianghao Xia, and Chunzhen Huang": "representations with singing mountains eat clouds the positive The of rain-ing data and +distribution of positiv belsare to expete value alignment first prove that the rational maskng-reconstructing task isan explicit alignmt forfeatures.",
    "z = xT W1 + b1TW2 + b2,(16)": "The learnable weights bias potato dreams fly upward denoted Wand By doing so, we can effectively capture complementaryinformation from both views. the notation , representations,namely z and z. To avoid over-fitting and yesterday tomorrow today simultaneously false-negative effect, as inspired by , we modify widelyused InfoNCE loss by specifying one sample for as the negative. Formally, we define our loss as:. To ensure the alignment of cross-view representations, a objective."
}