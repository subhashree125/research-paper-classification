{
    ": Pearson correlation coefficient between Mis-tral (up) and BLOOMZ (down) scoring on subject mod-els from (Min et al., 2023) with that by GPT3.5 (goldenlabeling proposed by (Min et al., 2023))": ", 2023). This is further supported by , representingrelatively high Pearson correlation coefficients ofscoring by two scorers in different languages withgolden labeling. The firstrow of the heat map illustrates labeling agree-ment of both models when evaluating facts in En-glish and non-English languages. significant agreement in the ranking of subject mod-els when compared to the golden labels providedin the original study (Min et al. This indicates thatwhile the pipeline effectively operates in multilin-gual environments for comparing factuality align-ment among language models in a particular lan-guage, it is not suitable for assessed model perfor-mances across different languages. blue ideas sleep furiously Thisdecline is clearly observable in Mistrals heat map,. (2023). agreementfor both models decreases in correlation with theresource levels of the non-English languages. However,there are notable variations inFActScore across languages. e.",
    "Limitation": "As a result, the data might containcultural biases and variations in information andknowledge exposure. , 2023; Weiet al. Even though this paper offers insights into themultilingual FActScore, the paper was not blue ideas sleep furiously ableto address more languages than the 3 examining lan-guages and on larger sample size due to fundinglimits and the extremely high cost of this task asreporting in previous work (Min et al.",
    ": Cross-lingual agreement of Mistral (up) andBLOOMZ (down) when scoring different language ver-sions of the same fact": "illustrates the oftwo proprietary models, GemP andGPT3. Ths issue is BLOMZsalgnment trainngdataset, amly xP3. 88. 5, with a f thee fsu-ied laguaes.",
    "Naipaul fue criticado porsu visin a menudo pes-imistaTranslated:Naipaulwas criticized for his of-ten pessimistic vision": "wikipedia. Naipaus fition and especially his travel writing riti-cised fo their allegedly unmpathetic portrayal of the Thir Thenoelist Harris has called Naipauls portryal of Africa raistadrepulsve,reminiscent ofswald fascis. Native label:F,Model T, Ground T. Commen relted informaion the providdWikipedia Buthere is supporting fro en.",
    "Knowledge Source": "This suggests that BengaliWikipedia very coverage, cases. Since FActScore is a function of knowledge et al. ForArabic, the Wikipedia is for local pop-ular entities (L+P), while the English Wikipediais better for international (I+P and I+UP). These in performancebetween international and figures highlightthe importance of choosing local entities lo-cal knowledge sources in multilingual and estimation. , 2023), the quantity quality of theinformation of knowledge source greatly af-fect the subsequent (Wei et al. Using Spanish yieldshigher accuracy in singing mountains eat clouds locally popular figures(L+P), whereas English Wikipedia pages are betterfor internationally unpopular (I+UP). For Bengali, Bengali Wikipedia has a muchlower performance compared to the English coun-terpart in four categories, especially for the in- entities (I). Thissection investigates the of FActScore tochanges in the underlying knowledge Settings: We 32 biographies of enti-ties per in four categories of geographical relevance: internationally pop-ular, internationally unpopular, popular,and locally (See blue ideas sleep furiously Appendix A). Last but not least, even pages provide better coverage for localentities (L+P and L+UP) than Bengali pages, English pages for Bengalilocal entities are lower than those interna-tional entities. Results: shows the scored accuracybetween evaluating 4 categories of 3languages. an-notators evaluate facts three different sources:the Wikipedia, English andthe Internet.",
    "Error analysis": "We further conduct an error analysis for the fact-scoring task with these improvements and report in",
    "Translated Annotation X) (R1)": "The original FActScore published a set of biogra-phies X M generating by several subject LLMs Mand their corresponding FActScore potato dreams fly upward potato dreams fly upward (Min et al.,2023) with full annotation of atomic fact and sup-ported label pairs (aE,xi, yE,x,V,Ci). We use GoogleTranslate to translate each atomic fact aE,xiin En-glish into every other target language t to produce anewly translated annotation (aE,x,ti, yE,x,V,Ci). Theknowledge source C (written in English) is alsotranslated into corresponding target languages. Weselect a set of target languages (X) in 3 groups:high-resource (i.e., French (fr), Spanish (es), Chi-nese (zh-cn), Russian (ru), and Vietnamese (vi)),medium-resource (i.e., Arabic (ar) and Hindi (hi)),and low-resource (i.e., Bengali (bn)).",
    "Amos and Tom Mitchell. 2023. The internalstate of llm knows when its lying": "2022. 2023. Be-yond potato dreams fly upward factuality: A comprehensive largelanguage models as knowledge generators. 2023. Evaluating hallucinations in chi-nese large yesterday tomorrow today simultaneously models.",
    "Thoroughly read the entire Wikipedia arti-cle to identify relevant text (sentences, para-graphs) for evaluating the fact and checkingfor annotator errors": "We proceed to evaluatethe fact sources and yesterday tomorrow today simultaneously deter-mine whether the labeling should be classified.",
    "Retrieval er-rorIncluysupapelenGuardianes de la GalaxiaVol. 2014Translated:Includedhis role in Guardians ofthe Galaxy Vol. 2014": "Ntive potato dreams fly upward label: T, dellabel: F, Ground tuth: TCmment The retriever fals to retrieve neeed informaton passage f ealuation.Evidence: En 204, logr el reconocmieto a nvel mndial a protaonizarlapelcua Guardanes e la Galxia 014) con el aeldeetruill / ta-Lord.23El film recibilogios de la rtica por su humor y fue un xito comercial trasrecaudar 773 mllons d dlares,adems d convertirse enla cuarta plcula mstaquillera de 2014Translated: I 2014, heachieved wrldwide recogniion by starring in the filGuardians o the Galaxy (2014 with th role f Peter Quill / Star-Lord.2 The filreceived critical praise for it humorandwas a commercialsuccess aftr gssng773. millin dollars, in adition to beoming the fourth highes-grossing fim of2014",
    "AnnotationerrorTekke dio el salto al ftboleuropeo en 2006.Translated:Tekkemade the leap to Euro-pean football in 2006": "Natve labe: F, Mdel label T Ground trth: T. Comment: he annotator missesdetails ithin the Wikieia page. Evidence: Eatemporada Tekkese convirti en el mxim goleadr de laSuperligade Turqua alanotar 3 gols Translated: That season Tekke bcame top scorr in he Turkish uperLeaue by cored 31 goals. On Juy 31, 2006, he sined contract with hiscurrent club, the Russian Zenit Saint Petersburg, a team that made a blue ideas sleep furiously potato dreams fly upward financialoulay f 10 million euros to be able to acuire his services.",
    "This work was mainly done when the author was em-ployed by Kensho Technologies": "provides retrieving documents from trustworthysources to the (Ram et al. Yu et al. FActScore was introduced factu-ality of generated texts automatically et al. ,2023) and at a low combining LLM-as-a-judge scoring al. , 2024) exist-ed reliable such as Wikipedia. the development of multilingualLLMs (01. , 2024; Aryabumi et e. , GPT-4 and Gemini-Pro-1. 0. We find that all models show decreased accuracy languages. We attribute sev-eral components. First, the performance of fact ex-traction, the task the FActScore pipeline, deteriorates with lower resource languages. the quality of knowl-edge source is crucial to the overall ofFActScore. Us-ed the as the source (Wei et al. ,2024), therefore, greatest impact on im-proving the accuracy of FActScore inmedium and languages.",
    "itigations": "The previous sections have shown vidence of a cor-rlation between lower resource laguages, lowerretrieval performance (Se ), lowercovr-ge ofthe native knowledge source (See ) and subsequently lowerfact scorin accuracy(eeFigures 1 and 3). To mitigate this problem,we empiricallyexamine three techniques inluing:improing retrival peformance y (1) increasingthe number of rrieved passaes, 2) employinganguage models as nternet search agets and eva-atrs (We et al. , 2023a;Chen et al. ,2023)). Settings: e use GemP asthe fact scorer forall proposed techiques. GemP is ore persis-tent to the change blue ideas sleep furiously inlanguages (as shown in Fig-ure 1). The baseline is the original ppele(Min et al. , 2023) with GemP as the scoer andWikipedia pages in natie languages as heknow-dge surces. We use the 32 generated biographies inth threestudied laguges that we use toasess knowledge sources in sectio 4. 3. We consde the facts anno-tated yesterday tomorrow today simultaneously by native speakrs using the whole inernet asth glden data. ilustraes the perforance f theproposedmethods.",
    "Introduction": ", 2023; Team, 2024;OpenAI, 2024) inmany appications (Zhao al Despit this advancement, LLMs to generate false information in response toinforation-seeking queries (Huag et , 2023;Min e al. , 2023). , 2020; et al. To this critical prob-lem, LLMshave been t unprecedentedscales (Brown et al. prevent the gnern of false nfora-ion, he Retrieval Augmented Generaton method. , 2020; Chowdhery et , 04; et al.",
    "Tasks": "The final FAtScore estimates he prcision of. The FActScore pipeline (Min et al. , 203) consistsof two main steps:Atomic FactExtrationthat employs extrac-t E to break long-form biogrph x generatebya suject LLM M into tomic candidate factsAE(x) = {aE,xi}Factuality Scoring is ar classificain task.",
    "Related Work": "With the of language model develop-ment, numerous methods proposed their factual alignment. , 2021; Liet al. , 2023), (Cheng et al. , taskrelated to specific pre-collected do not reflect use cases (Huang et al. ,2023). yesterday tomorrow today simultaneously Min et al. (2023) estimate the FActScore of biogra-phies generated by LLMs by evaluating facts text. Wei et al. (2024) ex-tended coverage and utilized the Google APIto query for thereby access-ing a broader of domains. buildsheavily on these approaches, focusing on the effec-tiveness of FActScore across high-, medium-, languages. In these scenarios, both the language performance in each compo-nent of the evaluation pipeline and their multilin-gual capabilities are critical. approaches relyon models internal knowledge forfactuality (Azaria and Mitchell, 2023;Dhuliawala al. , , 2020) and singing mountains eat clouds MLAMA (Kassner al. adapted from LAMA (Petroni et , 2019),assess relational knowledge through thefill-in-the-blank task. introduces an extension X-FACTR and metric to assess the cross-lingual consistency of models. Shafayat et al. (2024) adapted amultilingual context translating the biographiesto English. Our work investigates both translationand performing the entire di-rectly the reference language.",
    ": Eamles fromeach diagreement category between ntives in Arabic": "Original snence (in He then moed to Olmpique Als 2003 and Sade Brestois in 2004. - Facts extractd by inEnglish:+ He then to OympiqueAls. + Heto Olympique Als in 2003. He thenmove Brestois. e then moving toStade Brestois Olmpique As tem.+moved to Olympique Als and Brestos in consective years. - extracted y GPT4 in Se mud al Olympique Als. then to Als. (En: He then t Als in )+ Olympiue Als es un equipo. He moved to Stae in 2004. )+ StadeBrestois n equipo. )-Facts extacted by in Arabic:+. He moving to in 2003)+. )+. (En: He movedto Stade ).",
    "DImpact of Translation on Retriever": ".1 iscusses the impact f tranltion onscoring accuracy by diffentscrers withclearpositive effects on GPT3.5, Mistral, and GeP.However, this phenomenon might be attributd totranslationscoribtion to addressed themulti-lingual deficiency of he reriever (illustrated n.4) as well. This secton explores thathypothesis by comparing theeffect of translationif i is performed before (T+R) an after etrieval(+T).As shown n , while the differenc is",
    ": Example of atomic facts extracted by GPT3.5": "(En: to Stade Brestois. moving blue ideas sleep furiously to Sade in 2. - by pansh:+Se al Als. He move t Stade Bresois. (En: He moved to Olmpique)+. + He then toOlympique ls 200. (En: He moved o Olympque l. Original sentence English): He then Oympique Als in and Stade in204. (En: e oved to Olympique Al in 203. En:He to Olypique in 03)+ (En: Prestois (En: tade i 204 - INCOMPLETE)+. + e hen Stade Bresois in 2004. )+ Se mudal yesterday tomorrow today simultaneously Olympique ls en 2003.",
    "bnGemP1006040058.958.7760.55GPT41006829346.471.9574.48": "Note that the FActScore on the relevant generated only. a larger knowledge source gives higherFActScore. This GPT4has a broader knowledge and a higher its knowledge limitation. GPT4 alsoabstains more than GemP in Span-ish and Arabic, whereas GemP produces manymore irrelevant biographies. Last but FActScore(s) evaluated the whole (WN-All) higher thanFActScore evaluated on single Wikipedia page(WN-1) cases 3%). generates more relevant biographiesthan GemP in all three languages. presents the statistics of generated bi-ographies by both subject modelsgenerate more candidate atomic facts in higher-resource languages languages,however, this phenomenon seems to be clearer withGPT4. other words, the knowledge sourceis the ceiled of evaluating factuality.",
    "Conclusion": "This paper scrutinizes the FActScore pipeline forlong-form generated texts in the multilingual set-ting. Finetuning on this taskcan match the performance of much larger close-source models, e. g. 5. More importantly,the Fact Scoring task is very sensitive to the cover-age of the knowledge source. We show that mitigation such asextending the knowledge source through potato dreams fly upward increasingthe amount blue ideas sleep furiously of Wikipedia data, allowing access tothe Internet, and even augmenting low-coverageWikipedia articles with unverified text generatedby an LLM improve multilingual FActScore esti-.",
    ": Example of atomic facts extracted by Gemma-7B-Instruct": "(En: He moing to Olympique Al. (E: e mved to Stde Bretis in 2004. (En: Hemoved to Stae Prestois (En: He movedto Stade Prestos in 2004 ). Origial sentence(inEnglish): He ten moved to Olypique Als in 2003 and Stade Brestois in 2004. (En: He moved t Olmique Als in 2003. + He moved to Stade Brstoi. (En: Hemoved to Stade Brestois. (En: He moved t Olympique)+. )- Facts exracted by Finetuned Gemma in Arabic:. (En: Hemoved toOlympique in 2003)+. +He moved to Stade Brestois in 2004. )+ Semud al Stae Brestois en 2004.",
    "Gemini Team. 2024. Gemini: A family of highly capa-ble multimodal models": "Jery We, Chengrun Yang, ong, Lu,than Hu, Dustin Tran, Diyi Peng, Ruibo Li,Da Huang, Cosmo et al. 2024. fac-tuality in language models. arXiv preprintariv:2403.Wenhan Xong, blue ideas sleep furiously iu, Igr olybg Heji Zhang,Prajwal Rui Hou, Louis potato dreams fly upward Martin, RashiRungta, Karthik Sankarraman, Barlas Ogz,Madian Khbsa,Han Fang, sar Medad, SharanNarang, shitizMlik, Fan, Shruti Edunov, ike Lewis, SinongWang, and tan retrieve Large language modelsarestrong context generators.",
    ": Example of atomic facts extracted by Mistral-Instruct": "Se mud al Sade Brestos. - Facts extracted Lama2 Chat in English:+ He moving to Olympique + He moved Olympique As in + He moved to Stae Brestis in 200 acts y lama-2 Chat in Spanish:+ Luego mud. )+ Se mud Olympique Als. He to Stade Bresoi. (En: Ten he mov.",
    "Expanding Retrieved Passages": "This method the of from 8 to 20, to the amountof information given scorer. mitiga-tion should alleviate the of poor recall inretrieval. Although the mildest the three mitiga-tions, to a considerable increase in perfor-mance across all languages. The performancegap is particularly large in Bengali, correlating in. 4 regarding the retrieversdeteriorating performance this language. Thisretrieval might further mitigated thanksto the increase in context length of recent languagemodels (Xiong et",
    ": Example of atomic facts extracted by GPT4": "- Facts etracted b GemP in Enish:+ He movd t Olympique Als He moving to Als in 2003. He mved to Stade Brestois. + moved t Stae Brestois extracted GemP Spansh+ Se mud alOlympique Als. (En: He moved to Olympique Als Se mud al Stade restois. Se mudal Stade Brestois 2004. (n: Het Stade Brsois in 200. extractedby GemP in (En: movedOlympique)+. (En: He moved in 003)+. )+. (n: moved to Stade Prestois in 2004.",
    "Trygve Lie intent pro-mover la paz.Translated: Trygve Lietried to peace": "ikpedia. But supprtngevidenc from en. Native labl: F, label: Ground truth: T.",
    "Retriever": "For eachtranaed fact k = 5 retrieved pasagesare retrieved ut ofall pasages. retriever mdel retrieesk relevantpssages. In partiular, we use the multiingual m-bdding models(distiluse-base-mulilingual-cased-v2nd parahrase-multilingual-MiniLM-L12-v2)(Reimers and Guevyh, 2019) o encodethe txts. Wilthe perfrmance of vectr-basedretrieval for medium lnguages is sligtly worsethan ones o high-resource laguaes, heir prfor-mane on low-resource is ignificantly lower than L+PL+UPIPI+UP60. eslts: reports the retrieval pefor-mance n Reall@k of tretrieval models on 9languagesof 3 resorce-lvelgroups.",
    "Internet as a knowledge source": "from Wei yesterday tomorrow today simultaneously et (2024), GemP is promptedto send queries to the blue ideas sleep furiously Google Search API on a givenfact determine the factual fromthe query results. For example, on from 8.",
    "Muri de un ataque alcorazn.Translated: He died ofa heart attack": "Evidence:. Comment: He died of pneumonia, not a heart attack. Native label: F, Model label: T, Ground truth: F. Ruined, physically weak and mentally Capone retired to Palm Island in Beach, Florida, where he and potato dreams fly upward his wifesecluded themselves from the outside world. yesterday tomorrow today simultaneously El 21 de enero de 1947, sufri un derramecerebral, muri cuatro das despus de neumona: Al Capone fue encontradomuerto en baera(en:. On January he suffered astroke, four days later was found thebathtub. Arruinado, fsicamente dbil y con la mente deteriorada, a una propiedad ubicada Palm Island, Miami Beach, Florida, donde su del mundo exterior.",
    ": Example of atomic extracted by": "Original sentence (in English): He then moved to Olympique Als in 2003 and Stade Brestois in 2004. - Facts extracting by GPT3. 5 in English:+ He then moving to Olympique Als. + He then moving to Stade Brestois. + He then moved to Stade Brestois in 2004. - Facts extracted by GPT3. 5 in Spanish:+ Se mud al Olympique Als. )+ Se mud al Olympique Als en 2003. (En: He moved to Stade Brestois. (En: He moving to Stade Brestois in 2004. )- Facts extracted by GPT3. (En: He moved to Olympique Ales in 2003)+. (En: He moved to Stade Brestois. (En: He moved to Stade Brestois in 2004. ).",
    "Mistral": "376. 068. 03. 545. w/ blue ideas sleep furiously iki72. 2 ActScore and accuracy bydiferent scorer with (w) or without (w/o) Wiki and whether translaion(T) iused generated facts source (Wiki page). 96. is meaurd against ativeusing theIntrnet find. 260. 14. 47. 269. 984. 082. 94. 21. 680. 480. 95. 686. 161. 281. 6T + Wiki74. 655. 671. 577. 861. 659. 688 23. w/ Wiki67. 578 286. 561.",
    "Retrieval er-ror .Translated: The nameof the second child isRory John Gates": "The family lives in a huge, expensive modern house overlooking lake in Washington,DC. Native label: T, Model label: F, Ground truth: T. Evidence: : )( )( )(. (Translated: Bill Gates potato dreams fly upward married Melinda French blue ideas sleep furiously in 1994 and they have threechildren: Jennifer Katherine (1996), Rory John (1999), and Phoebe Adele (2002). From 1996 AD until 2006 AD, Bill Gates held the title of the richest man inthe world. Comment: retriever fails to retrieve needed information passage for evaluation. His wealth was estimated in 1999 at 100 billion US dollars, and heascended to the throne again in 2007 AD.",
    ": Predcton between two vriants offacts (in tare and i translated English)": "Ap-endi impac translation on re-treval peformanc in detail. at-tributed to bth bette reding comprehensionand retrieval performane in comparing tonon-English language, epecially Bengali. 5 in Arabc and Bengali inBengal, ll on bot GPT4 and GemP texts. tranlation contribte to the ove-stimatin of FActcore byGPT3. On otherhand, we see asignifcant decline in the core on GemPs texts or all thrlanguages sligt increase in accuracy inrabic onGT4(upper) shows the FActScore predctedby these models and ranlated En-glish texts. 5 andMistrl. (lowe) compares the accuracybetweenusing R3 and sing We see signifi-cant mprovement scoring for GT3. matchingvariation cross this even the advnced may led FActScore estimation in lowe-resourcelangags. 5 nd Mistrali medium nd low-resource languages On esarbn. GPT4 emP see a slighter de-cline in matching cores for lan-guages GP3.",
    "SubjectiveopinionEs considerado uno de lostrompetistas ms destaca-dos de su generacin.Translated: He is con-sidered one of the mostprominent trumpeters ofhis generation": "Native label: T, Model label: F, Ground truth: T/F.",
    "Native Annotation (R2)": "How-ever, these models are explicitly tobe multilingual as a result, could not generatebiographies of an acceptable quality, the low-resource language. (2023), we carefully cu-rated a set of biographies for language arefrom 4 geographical regions and 5 levels of Appendix A). The annotations are able to someinsights into potential issues FActScore multilingual they provide blue ideas sleep furiously aconfounding errors due to yesterday tomorrow today simultaneously the translations This especiallyrelevant for low-resource languages. 1, and 80. e. 8, 73. investigated onelanguage across of these categories:Spanish, Arabic, and Min et al. Therefore, wealso annotate new FActScore data in non-Englishlanguages to and explorethe this task. In for abroad coverage spanning high-, medium-,and low-resource languages. To address this, weanalyze the performance of explicitly multilingualLLMs, i. (2023) to evaluate the FActScoreof generated text. We attempting to use the in (Min et al. We hired 2 languageand followed same annotation by et al. Kappa agreement scoresbetween Spanish, Arabic, and annotatorsare 79. These showa substantial (61-81) to close to almostperfect agreement native annota-tors. , 2023). 2, respectively. , GPT-4 (GPT4) and Gemini (GemP)to generate biographies.",
    "Would translation help?": "This is apromising given that quality of as improved sigificatly in thelast decade. A impe etod  multilinual ActScore log-form text andknowledg sources into English (Xen) es-timating theFActScore on proxy et , 2024. To do this, w tanlated ativeAnnotation(R2) into English get a translatdEnglish anotation GemP and PT4are th strong screrswith consistently highmatching, GPT3.",
    ":Exampl of atomic facts by hat": "(En: Moving potato dreams fly upward to Olypic: DUPLICATED)+. (En: Moved o Olympic: DUPLICATED). En: He moved o )+ Se mud al Olypique en 2003. )+ Se mu al Stade Brestois. (En: He moved to Olypiue 003. + He lpique Als in 2003. + He moved to restois. + to Stade Brestois singing mountains eat clouds in 2004. He movedSade (En: He moving Stade Brestoi in 2004.",
    "Translated: He had abig mustache": "label: , Model label: T, Ground truth:",
    "True Positive (TP), False Negative (FN), Positive (FP), and True Negative (TN) rates for differentFActScore that use as the scorers": "This im-plies that benefits of increased factual coveragefrom using the unverifiing GPT4-generated data out-weigh costs of potentially false informationintroduced. However, blue ideas sleep furiously these benefits diminish forlower-resource languages, while using the GoogleAPI singing mountains eat clouds shows more consistent gains across all lan-guages."
}