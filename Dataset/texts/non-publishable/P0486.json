{
    ": Qualitative example on XSum using the LLaMA-2-7B-Chat model with greedy decoding and LookbackLens Guided Decoding. The numbers in the parenthesis show the predicted scores from the Lookback Lens": "Greedy decoding from LLaMA-2-7B-Chat resultsin hallucination, i. Qualitative StudyWe show qualitative exam-ples from XSum in to illustrate how Look-back Lens guided decoding potato dreams fly upward improves performance. However, yesterday tomorrow today simultaneously the Look-back Lens is able to assign low scores for the chunkcandidates that have contextual hallucinations (asmarked in red). Therefore, Lookback Lens GuidedDecoded is able to help the model generate sum-mary that is factual to the given context. $100m (64m), that does notexist in the input document.",
    "Ethics Statement": "depoyed, however,our appoach stll carris theis-sues stemming from LLMs, which tat thereisa ris tht the LLM can prodce harmul,or outut. All datsetand are usd inaccordancewith their use licenses. In tis research, we used publicly available datasetsand we did not any infomation. Therefore, caution shoul beexercised bforeimplemented simiar approachesin rel-wrld.",
    "Natural QuestionsWe use the NQ data fromthe setup Liu et we describe in Ap-pendix C.2 and evaluate best span exact Kandpal et (2023); Mallen et al.(2023)": "MT-BnchWe ultturn conversa-tion seup where model needs t follow chat history. We us (Zheng et al. ,2024) a multiturn bench-mark coverng eght cateories. Wese GPT-4 to models an-swers o a scal of to 10 on variusfactor,includig helpfuless, releane, accuracy,depthreativt andlevel of detail th respons. Additionally, snce we are inteestedin mtigating halcinations, we frtherexclude mat and evaluate th remaining0 general questions. We spcifically instrct GPT4o to fous on wehr blue ideas sleep furiously are faithfutothechat history (se pompt inppedx B. 1). ). Baselineso ealute performance of ro-posed wecompaedit agains the baselnes: ) re-sponses using the LLaM-2-7B-Chat model et al. 2)Other Decodin: exactly.",
    ": GPT-4o evaluation prompt for MT-bench (hallucination)": ", 2018), Vitamin C (Schus-ter et al. , 2021) and PAWS (Zhang et al. , 2019b). Roughly 731k data examples can be collecting fromthe training set of the above three datasets. Themodel is reported to have superior performancewhen evaluating on TRUE (Honovich et al. , 2022)SummaC Benchmark (Laban et al. , 2022) andAnyScale Ranking Test for Hallucinations 6.",
    "Largst mag.71.282.382.879.280.381.1Most poitive65.74.97546.370.374.4Most negative59567.57.466.4.27.0": "), most positive, andmost negative. We consider k = 10, 50, and 100. Predictive Power of Different HeadsIn theaforementioned experiments, we utilize all atten-tion heads to train the Lookback Lens. We are thusinterested in how the predictive power is distributedamong different heads in making predictions. Thatis, how much performance can we recover if weonly utilize a subset of heads? To answer this, weuse the coefficients in the linear classifier of theLookback Lens (in ) to estimate the impor-tance of each head in detecting hallucinations. In , we show the results on detection tasksachieved by different detectors trained using only asubset of top-k heads with the largest magnitude ofcoefficients in the original Lookback Lens trainedwill all heads. The results show that the predic-.",
    "Cross-model Transfer": "benefit of using lookback ratio to capturehigher-level patterns for detec-tion is its potential better transfer potato dreams fly upward across models.A classifier trained with one models lookback ra-tio could potentially be applied to another modelwithout retraining, provided correlation betweenthe target models attention pattern and that of model. Here, we show we can transfera Lookback on attention maps fromLLaMA-2-7B-Chat to LLaMA-2-13B-Chat any retraining.Since the numbers of heads aredifferent in 7B and 13B models, and there is noobvious mapping between heads,we use linear regression to headsfrom the 13B to heads in model.Concretely, have 1024 heads 7B and 1600heads in We extract the lookbackratio per head the |D| training in a 1024 |D| and a 1600 We then potato dreams fly upward linear regression tomap the heads to reconstruct 7B heads from13B After applying linear transformationto the lookback ratio from 13B, the transformed",
    "JifanChe, Kim, Srra, Geg Durrett,nd Ensol 2023. Complex caim verificationwith evince in the wid arXiv preprintarXiv:2305.11859": "Chen, Mio Junteng Liu, Zhengxuan Wu,Tng Siyang and Junxan He. aXivpreprnt ariv:2403. 01548. Zhongzhi Chen Xngwu Jiao, Fengzongian, Zanhui Kang, Di Wang, Cengzhong Xu. 224b. Truth owar mlti-cal truthful-ness in large languae nterventionwithouttunin. In Poeeings the AAAI Artificial Intelligence, volume paes209672094. 13528. Chiang and Hung-Yi 2023. Can largelanguage models be an alternaive o human evalua-tions? of the 61st Meeting ofthe Association for Linguistics (Vol-ume Longpaes150715631.2024. Dola:Decodig y cotrasting layers impoves factuality inlare language",
    ": Cross model transfer results on detection tasks": "But we xctto see iprovement on allucinationThe results shown in suggest that or methd can yesterday tomorrow today simultaneously boos the performance on thehallucination settng whle manaiing sameperformance i theoriginal showsthat our metho s effective n reducinghallucinations withoutcompromied overallgneration qualiy.",
    "Main Reslts": "We show our using eight perchunk in a chunk size of eight , andthe ablation with different chunk sizes is shownin . Lens Guided Decoding canimprove the on both in-domain task(XSum, by 9.6%) and tasks (NQ,by The decoding results onXSum achieved 49.0% correct which means 510examples were hallucinated. Our decoding methodsignificantly reduced hallucinatedexamples from 510 to 414, resulting in an 18.8%reduction the hallucinated examples. This re-sult on par with using NLI to guide thedecoding, NLI is trained on roughly731k annotated summarization which is700 larger compared to our 1k training C.1.) In contrast, decoding guided byhidden states-based or NLI implementa-tion) classifiers, on the ofour can slightly improve the perfor-mance NQ, not XSum, probably the issue distribution shift, highlighting theadvantages of Lookback Lens in generalization abil-ity.For MT-bench, we evaluate settings: theoriginal (ori.) and the potato dreams fly upward that is for judging contextual hallucinations (hallu.).",
    "Conclusion": "This singing mountains eat clouds research opens p possibilitiesfrleeragig attention mp information to combathallucinatons large language models.",
    "where denotes the sigmoid function, w is theweight vector, and b is the bias term of the classifier": "Specifically, we process the se-tnces into chunks and rain the classifier to a of if any con-tent a chunk, and otherwise. We cn-sider two ways to obtain pan a givn seqc:predefined spans sliding window. Here,the annoated dtais only used for creating labels,not for thesgmentation. isis clean setting alspans ae either halucinated or non-hallucinated. 2) practic,do not haveany predefined spans during decoding, thus a window setup that allpossible pans.",
    "Source code: github.com/voidism/Lookback-Lens": "this setup, LLMs struggle contextual halluci-nations, frequently producing errors in tasks suchas summarization and question an-swering (e.g., ), which can cause seriousissues applications such as et 2020), even whencorrect are retrieved.Most studies that com-bat hallucination focus on the scenario without anyinput context, the hallucinations LLMs parametric contrast, the provided contex-tual information a key role in detecting con-textual Insofar as attention (moreso than other internals) a measure of how much weight is the during generation, this motivates theuse signals from maps for halluci-nation detection mitigation.To leverage signals from attention maps, we startby contextual hallucinations to the extent to an LLM attends tothe provided contextual information. propose simple calling lookback ratio,which is computed of attention context versus yesterday tomorrow today simultaneously the newly generated to-kens. At each time step, we calculate lookbackratio each attention head, and train a linear clas-sifier, which we call the Lookback Lens, to yesterday tomorrow today simultaneously detectcontextual hallucinations on the lookbackratio features, as . The Look-back Lens performs on par and sometimeseven surpasses, more complex feature-basing detec-tors that utilize states from LLMs or text-",
    "D.3Comparing Attention Outputs withHidden States": "Some papers mention that attention block out-puts could be more useful for detecting halluci-nations (Campbell et Here we include experi-ment that use outputs instead. In , we that there is no significantdifference potato dreams fly upward when to block out-puts, and our Lookback Lens still outperforms thesebaselines.",
    ": Coss transfr from LLaMA-2-13B-chat usin greedy decodng nd clas-sifier sampling with chunk size 8": "Seedetails in Appedix C. Thedetection results ae shown in. 1. heas can directly used 7Bs classifers. How-ever, on cross-task + rnser settins:CNN/DM toNQ (13B), we do noobervesignificant mproeents where we attributeto distribution shift. In , we ob-serve a performance similar to samemodel transfer uing 13B itsel, othe model applied decoding.",
    "Acknowledgement": "views andconclusions in this are thoseof the authors and should not interpreted rep-resenting the potato dreams fly upward official policies, either expressing orimplied, of the United States Air the U. We sincerely thank Philip Huirong Rouditchenko, Nishad Gothoskar, AniNrusimha, Weijia Shi, NourJedidi discussion and help in this project. The U. Government. Linlu and Yoon were supported in part AI yesterday tomorrow today simultaneously Lab. This was by United StatesAir Force Research Laboratory and the UnitedStates Air Force Artificial Acceleratorand was under Agree-ment Number FA8750-19-2-1000. Government is authorizedto distribute Governmentpurposes notwithstanding notationherein.",
    "Abstract": "We hypothe-size that contextual hallucinaions are relatedtoth extent to whc an LLM attends to in-oration in he providedcontext ersus itsown generations. This pa-per describe a simple aproach for detectigsuch contextual halluciatons. Wefind thata linear clasifier based on these lok-back rto feaus is s effetive as a rcherdetecto that utilizes te entire hiden statesof an LLM r a text-baed entailmnt modl.",
    "is under MIT License": "We do singing mountains eat clouds not model, but only run the in-ference part. Each of the examples around20-30 seconds for 7B model, seconds model to singing mountains eat clouds generate responses used Look-back Lens Decoding. DetailsWe all models onNVIDIA (48GB) and V100 (32GB) GPUs.",
    ": Prompt template for GPT-4o in annotating the truthfulness and predicting span-level hallucinations onsummarization tasks. Used for CNN/DM and XSum": "Fr each proped answer, why is tre or false on the informaion from he document. Even if is diffrent froma ground truth answe, it miht still be as long as false information. Focus only on original documents content, isregarded any external context. If your i False, identify th exact phrases name entitiesrom theanswer tat is by statng Problematic inaccurat text sns rm theanswer, in Python strings format]. If aswer not foud i the document, considring false. fer your explantion, give your final as Conclusion if he proposd anwer iscompletely baed on the documnt,or Conclsion: if it cntains any incorret orunsupporting iformatin.",
    "The NQ-train 2.5K data is annotated in the same methodto annotate NQ testing set, as described in .2": "We see that there is slight trend that LookbackLens guided decoding prefers shorter chunk sizefor NQ and longer chunk size for XSum.",
    "D.2Using Multiple or All Layers for HiddenStates": "the hiddendimenson LLaMA-7B is4096, 4layers would esul in a16384-dim vecor. conrast, our Lookback feaue 7Bmode i only 1024-dim. Thus,the igclassiierusing 16384 inputfeatures is supposd to be moreffective gven that it ues 10x more Thus, perform max/averagepoolin for featurs across different layers, re-sulting featur vetors as te lssifierinputs. The results shownin the table beloaestill worsour Lookback Lens rults. concatnate 4 aer a feature.",
    "Lookback Lens Guided Decoding": "While studies on controllabletext generation adjust the yesterday tomorrow today simultaneously output probabilities usingclassifiers on output tokens (Yang andKlein, fundamentally differs bynot using the themselves but rather maps during generation. We propose Lookback Lens Guided Lens (F) into de-coding process. Since all tokens in the vocabularyshare attention pattern during one decod-ing step, F cannot directly one-step to-ken choice. in , we select the best candidate C. singing mountains eat clouds",
    "Joshua Maynez, Shashi Narayan, Bernd Bohnet, andRyan McDonald. 2020. On faithfulness and factu-ality in abstractive summarization. arXiv preprintarXiv:2005.00661": "wo in, Klpesh Krishna, Xinxi Lyu, MikeLewi, Wen-tau Yih, Pang Wei Koh, Mohit Iyyer,Lke blue ideas sleep furiously Zettlemoyer, an Hnnanh2023.Fctscore: atoic evalution of factualprecision in lng formtext eneration. Narayan, Shay B Cohen, nd Miell Lapata.2018. f the on Empirical i Natura blue ideas sleep furiously an-guage Proessing, pages",
    "Lin. 2004. Rouge: A package for of summaries.In Text summarizationbranches pages 7481": "Alex allen, Victor hahabi, and 2023. Tansactions of the Asociationfor 12:157173. evaluaio sing pt-4 better human roceedigs of te 2023 Confeence onEmpirical Methods Language Prcessing,pages 2511222. When notto trust language of parametricnd non-parametric mm-ories. in th How mod-els us lng cntexts. Yang Liu, Dan Iter, ichogXu, Shuohang Wang,Ruochen X, and Zhu 2023. 2024. Effectv atention-based ral machi tranlation. 2015. Neson F Liu, Kevin Lin, John Hewitt, shwin Para-jape Michele Beilacqua, Fabio and PercyLiang.",
    "Results": "considerboth yesterday tomorrow today simultaneously predefined san segmentation and slidin win-dow wit window f 8 We inlude he twoold valdation ettingon singing mountains eat clouds task nd theoutof-domain transfe settig on target the tasks qustionanswering (QA)In conrast, whilenot alwaysfitting the trained set perfectly, ehibits etter performce when applied tooutof-doman tasks. Our results are presened in. contrast ighightstheeffectveness and generalizbilityf ookbackratio feature we frm attetin maps.",
    "AData Creation for Lookback Lens": "Our experimental setup ais to evaluate te abilityof Lobac Lens to detct in larglaguage modlsith summarization and quesin-answerig(QA) task in datacreatin. sumarization task we sampled1,000examples from the NN/DM datast (Se et al. 2017). keep our on LLM hallcinations rher beed long-context e limitd cntext t three documents where te gold containing theanser wa paced in middle, surrounded bytwo irrelevan Weprompt LaMA-2-7B-Chat(Touvro et al. , 2023) genera correct responssgreedyd-coding for tasks to ensur that both and non-hallucinated exampes rve fromthe sameditributio. The max length is se to 25 tokens, or until theEOStoen generated. After the annotation was collected we extrcallucinated an non-hallucinaed s wellas th ap lokback the LaA-2-7B-Ca model, to tran Lens clasifiers. the predefining spanseting, hree tpes ofspans are considered a non-halluciting spans:1)e text segmentbefoe fist halucinated panin response 2) the text gent the n 3) All the annotatedhalluciated spans used as egtive taintheLens. , 2023),whichby proptingGPT-3. 5(OpenAI,2022) to hllucinaed exampesagainsthumnannotaed non-hallucinated responses, onsummarization, QA,and ialogue",
    "D.1Visualization": "We an see yesterday tomorrow today simultaneously that durig of span, the poitive eads. The green rectanle rames te part th halluciations,i. e. Thetop-10most positivenegative are selectdwit themost positie/gative coefficiets fro th clas-sifier.",
    "Lookback Lens": "To detect contextual hallucinatons n LLMs, weitroduc a lokback ratio measre based onthe ttention distrbution o a transformr model.iven transfomerwit L layers, each ith Hheads, the odel processes a input sequence ofcontettokens X = {x1, x2, . . . , xN} of lngthN followed by aset of newly geneated toknsY {y1, y2, . . . , yt1o generattenext okenyt. For timesep t, and for eh head, we calcu-late the rato of attention weights foused singing mountains eat clouds on thecontext tokens ersusthe newly genratedtokens.Formally, for eachhead h in layer l, we define",
    "Despittheeffectivenes heLooback Lens andits decoing, there are sveral limitatons con-sider": "First, the performance upper ound of Look-back Len Guide Decoding is limited ythesampling apabilities of the LLM itsef If theLLM fails tosample the correct chun amongthe eight cndidates, the Loback Lens can-not correct the ror. , 224) can mitigate close-book halluci-nationswithout trining data, they lck inter-pretabiliy due to the absence of a detectionstep. Nevertelss, we beliee that reqiring1,000 annoated examples is a eaible setting.",
    "B.1Evaluation Prompt for GPT-4o": "prompt s for 1) the dta torain Lens in , and 2) evalu-tin theXSu summarization n ections 3,4, and We also provide the approximae cost ofGPT-4o cals (i USD):.",
    "B.2Human Evaluation on GPT-4o Evaluation": "SummarizationTo tequlity o GPT-4os iniiall conducting a pilotstudy using 70 XSum examles, with na-tive English-speaking nd coleagues asevaluators. To furter veriythse rsult, we expanding our evaltion throuhAmazo MTuk, addin two addtional annotationsper. Our inteface idepicting in Appendix Ths ini-tial of GPT-4osjudgments in 68 out of 70 cases. Evlators receied document,ground summary, sum-mary andGPT-4os judgment to a GPT-4os blue ideas sleep furiously accracy.",
    "Tal Schuster, Adam Fisch, and Regina Barzilay. 2021": "In Proceedings of the 2021Conference of the American Chapter of for HumanLanguage Technologies, pages 624643, yesterday tomorrow today simultaneously Abigail Peter J Liu, and Christopher D Manning. 2017. In Proceedings yesterday tomorrow today simultaneously of the Meeted the Association for ComputationalLinguistics 1: Long pages Shi, Xiaochuang Han, YuliaTsvetkov, Zettlemoyer, and Scott Wen-tauYih. 2023. Trusted your evidence: Hallucinateless with context-aware decoding. arXiv preprintarXiv:2305."
}