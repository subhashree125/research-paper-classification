{
    "Image data: MNIST Handwritten": "MNIST daaset is hanwritten digit images 0-9. We trained convluiona networkrom Dhurdhar et al. which uses two blocks, each composed of twoby a poolinglayer, by three fully-onnectd Note Dhurandha et (2018) also an additionalregulariztion of th AE()22, where is a autoencoder; this ter ensurestat the learnedPP lies near he true manifod, however Dhurnhar et a. only uses it experiments autoencoder We smiarly use autoencoder only for MNISTepriment and it out of te formulations for clariy. Te sam autoenoder architecture Dhuandhar et (2018)is sed to keep PSEM explanatinnear the imge manifold Results ae illustrated in. EM, CEM-PP, and LIME are a singleimae eachfrom 0-9 outpts a path of ve images wher PSEM-i lbls th t along the pah whereh sucient of is from PSEM-1 PSEM-5. ForCEM-PP, the penlty inCM-PP s set t he same sparsity penalty used in in order to give  comparison with CEM-PPtat is not to sarse (sparsit vels dier beause PSEM andCEM-PP have dierent A key observtion is that staility of the PSEM resul in expanaions that learlyo thedigits. Better staility of PEM is seen the dit 1 where CEM-PP failso nd minimallysucint set. dieent regularization of PSEM allows fo better controlo an ntuitive path fexplanations the fous on of digit. CEM-PP has anintuitive explaationthe 0 (ut ver sparse for2-7 ), already noted, if a user waned a densereplanation, there isguarane tat ading ould remain in the same class, and siply decreasinthe sparsiy lead to  dieret which wuld  counterntuitive. PSEM oers a mooh path explnaons to te In prtcular, we see that PSEM convres dirent explanationthanCEM-PP for 2, 5, 6, nd 8.PSEM shows that the s distinguihingfor the 2, th sape forthe 4, a full for the 6, the corner f he nd he x part the 8 whichis clearly uniquto tht digit. LIME motly the pitively relevantfor the prediction,whichcould build trust in the lssir, does not additional useful information how t bemakingThi does mean that isnt useful; indeed, LME could used was not prdicted lse since i allws for targeted nlike or CEM-P.",
    "Problem Statement and Method": "Let Pred() enote functio that takes a input and outputsthe predicted obabiity vector for classir. ,the probability of bein classiing in the th class. e. We start by introducing a formulation fo learning a path o sucient explanations and relte it t dingPPs in Dhurahar etal. For dierent modaities considered, w assume X = n for txt documents with n-word ormalizedditionares or grayscaleimages with pixels, and X Rn+ for tabular data with n features,i. Let x0 denote inputwith output label 0 ad X the entire input pace. [Pred()]i denotes the ith component of this vector,.",
    "cash they can contribute towards tuition (which reduces any required college loans) while maintaining goodcredit standing for a new mortgage": "Mostsuch methods highlight relevant features that determine the yesterday tomorrow today simultaneously models decision, but we on methodsthat highlight the PP as describing above that involve type of control over the sparsity explanation. a true minimal solution does enough explanatory/actionableinformation). g. , networks) has signicantly grown created the needfor new tools to users understand trust models (Gunning, Given this need, variousmethods have been to explain local decisions of classiers. While such an explanation might answer the applicants question, the highlighted features are often too fewto act on in practical (e. measure illustrating in and formally denedin , connects along path, in eect the applicant proles to remain and impact of black-box models g.",
    "PSEM68.0 (6.7)": "Right: Resuts to questonaskg which explanation theusr found \"most for explinin why each model ma blue ideas sleep furiously thei Participants hat prefering PEMperforme particularly well on PSEM uestions; i. & of user prticipants atbetwee tw baed onPSEM, CE-P, singing mountains eat clouds anPSEM es information that helps uers better discriminate betwen manner better than teother explanations. Wile ne can dbate wheter question ibiasedecause PSEM oers more information,. Thpercentag for PSE s 58. ,extra is to those tha prfe moeinfomation. Whether uersare rght orit is to note that are much more comfortablemaked decisions based on ath nal question aske whichh use found \"most sful explaning wy each modelmae thr predictions,\" were 40. Satistcally signicant resultsare displayed in Across three CEM-PP, LIME, PSEM,we see the prcentage of corret, wrog, and cannt tell wih bars onestandard error. 9%, 435% for LIME, and for with pairwise t-tes p-values of. 004 cmparig to LIME and benet of SEM signiant) Thisdoesno tellthe complte pictureas thereare signcant number of mstlyfor LIME othose %umbers have ben if participants wer forced oweve, in practcal applcations, whee thecannot iscern information i onpar with eplaatonThese esults shw thatSEM oers users usefl information tha candisseminate. e. 5, 35. 1%, a23% for CE-PP, and LIMErespectively.",
    "Introduction": "buy a ca, after their mrtage is appoved but before hehme purchaeis ociallycompleted (se the artice What is Conidered a Big Purchase DuingMortgage Underwriting\" Sharkey,022), when a marrid couple divoces an each eparate party needs to obtain new ortgage hilenegotiting a settlement on their joit nances, or blue ideas sleep furiously he parts want to relocate after a child graduates highscool whle simulaneously payig for college; the all need to uderstand howthe change to theirnanceimpacstheir credit. The aplicant is essntially askng how much, if any, aditional debt/risk can betakewithout aecting the desiedmortgae.Onepotentialanswer,called te minimallyucint eplanation orertinet positive (PP) (Durandhar e al., 2018), higlight the inimal set of eatures(and values) tat are sucient t replicate amodel decision, which is the miimal pplicant prole thawill case te model to aprove the loan1. Inhe college scenario, the parentswant to compute how much.",
    "PSEM100 (0.0)100 (0.0)100 (0.0)100 (0.0)": "he l2 regularizations from are removed. paths. Oneimplementation aveatexplaned largemdels create a ingle object, referre to as AEDEN in CEM-PP where parameters that vayalong PSEM path (i, i1, Mi1)are placeholers. Alleperiments used 1 GPU and up 16GBRAM. can then be to solve te PSEM subproblems by pasing appropriate parameters (and solutons of at eac iteraion to he attack uncton yesterday tomorrow today simultaneously CEM-PP. We implemented singed mountains eat clouds IR.",
    "Published in Transactions on Machine Learning Research (12/2024)": "This implis tht exra infrmaionf PSEM does not ovewel but rather signicantlyimpoves undersanding. By groupingparticipants according toexplanation preference, showsthat only thos that preferred PSEM perfomed partcular wel, and frtherore only on PSEM quesions. Those that referreLIME perfrmed best o LIME (however sillno good erformace). it is woth notng that participants ha preferred PSEM did muh etter nPSEM uestions than those haprefrred LIE or CE-PP. Those preerringCEM-PP didnot pefor best on any eplanaton type, while toe preferring PSEM aso performe beston CEM-PP. So ether suconciousy the pat helping this user or th PSEMpathactul did onvrge to bter eplnations than CEM-P (at leastin view of ts articular user.",
    "i i122 i1i [N](b)": "We usenotation[N] = {1,. The rst in the los ensures that explanation angthe path th sae class th input,i. , delity. second term inpnalizesthenumbr of featursin successive explanations. contraint (a)dene N thatexplanations w learnalong th where te rst explanationis the input sample x0 last explanation isthe fatures that he objectives loss The secondconstraints (b) enfrce monoonicity of he along path successive a sbset o thefeatres highlightedprior where i i1 dened compoent-wise. This comprehensibility pathas features not hihliging do nt suden startsowingup s which cabe o udersad. sPP soluion fromDhuandhar et al. This however does not imply thata cannt eist, which motivates the Path-Scient Explaation Problem (1). Hyerparametesc,, re t be (see Appendix. egarding feasibility, x0 forall ia feasible, but cearly suboptimal, sine sprsityregularization te objective ould rdced. may be paths were the soltion requires = ifor al i for i along he pah a solution along the at some point cannot efoud, but a solution resolves the sability issue lacking Dhurandhr al. (2018). N, optimiz prolem blue ideas sleep furiously over i while jfor = is use to th solutio t constaind",
    "CAdditnal comments aout User Study": "The correct answers for thedigit 3 questions (corresponding to CEM-PP, LIME, and PSEM) are Model A, Model B, Model A. Again, LIME highlights more positively relevant. The PSEM path additionally highlights other parts that could help distinguish the 6 fromother digits, such as an 8 which has a lower loop like a 6. The correct answers for the digit6 yesterday tomorrow today simultaneously questions (corresponding to CEM-PP, LIME, and PSEM) are randomly also Model A, Model B, ModelA. Notethat for CEM-PP and PSEM, the inaccurate model cannot nd minimally sucient solutions, and LIMEtypically highlights more positively relevant pixels for the accurate model. Figures 7 and 8 showtwo examples of such sets of questions, for a digit 3 and digit 6, respectively. details the instructions for participants to read before taking the user study.",
    "User Study": "Our setup is in spirit to user studies conductedin et (2016) and Singh et al. (2019); for each explanation method, users were provided twoexplanations, one for each two dierent models, had to select model was accurate.",
    "Text data: 20 Newsgroup": "Recall that our goal is to explain model predictions, not to build a state-of-the-art model. We compare PSEM, CEM-PP, LIME, and IR (Feng et al. , 2018), a greedy method that removes words, oneby one, as long as the classication does not change. For LIME, we set the number of features to 10 for.",
    ": end for6: Return 1, . . . , N": "This leds to agothm for learned a sequenc of explanaios, formaize in Algorithm 1, which wecallthe Pth-Sucient Explanations Method (PSEM). t ech teration i, successive xplanaton is earnedby solving problem () in Alorithm 1.N iterations crresponds to executing one iterationof alternatngminimization t sove aregularized apprximation o the PathSucint Explanation Prbem (1). Problem(2) is solved via a rox-algorithm (Bec & Tebulle, 2009) that iteativelymnimizes g( + i1 whre() is rst-orderapprimation to th reained ems o the objetive. ,218; Luss et al. , 202)where N is thePEMpathlegth (typicaly < 10. In our setting, tis eans we are applying FISTA (Beck& Teole, 209 t a nonconvx problem whchis analyzing ini et al (2017). Noe that parametr iisindexed as we wnt sparsity to increasethrough the sequence. In order to applyPSM to color images, we adapt an extesion of CEM-PP to colr images (Luss et al. , 2021)in a simlar maner a yesterday tomorrow today simultaneously described above. Hence, rather than optimize ovr input space X, eotain PPs fr color imagesby optimized over the pace f images resulting from any ssilebinaymask applid to the inut img. Let M enote te binay mask that whn applied to yesterday tomorrow today simultaneously inut image x0 produces image Then he PSEM agorithm for color images solves, at each iteration, problem (3) in Algorith 1. In practice, the follong steps are taken: 1) i1 is segmented, 2 an individal mask is created persegent,nd3 eoptize ove binary vaiables (elaxed to lie in contrained to be ess than or equal to thsthatdene Mi, and then thresholde) that turn individual masks on/ creaing mask in M(i). It is aso importatto nidr that the solution to problem (1) is nt uniqu, as the solutions o theuproblems (2) and (3)are not nique. ith that i mnd, it is lso imporant to recall thatthe objective i nocoe with multple local minima nd so ven f ther exst multpe globa minima, alocal inima may e laned instea due to the initialpoint.",
    "Newsgroups{0.0001, 0.0005, 0.001, 0.005, .1}50.050.5": ": Results compared stability and delity of path methods on 20 Newsgroups. are averaged over 64samples one yesterday tomorrow today simultaneously error shown parentheses.",
    "Discussion": "Consider the nal ow in ,whee the dierence betwee PSEM4 and CM-PPis tht one likely use the foreheadt classif ag while the other likely uses the cheek. owever,e can esin agrithms for learning mutiple path,e. , the CEM-PP result it the cheek i possibly a lassier artifac, similar to howthe clasir mst predict something on blanimage (221)and Darwiche& Ji (2022), where tey seekto lean multiple suient explanationsfor a individual sampl. g. Anther directinfor future researchis to pply PSEM t expanations beyond pertinnt positives,eg. Thechek wasremoved by PSE-3 along th path because a ucient set ffeatures did nt notrequire the chek, ut there i no guarantee tat emoval of he forehing instead wouldhave been sucient, i. Cearly, the foreheadi more seful for this task. As such, PSEMs meta-approah, where the baeexplanation could be pertinentpositives or semi-ftuals. , bystating PSEM from dieent nitil points or byusing diret parameters to driveierentpaths. In case of logical forulae, it is cleahow to dn the length of expanations, but it is not pparentfor a contiuou set of fatures, as with theloan applicant example inte Introducton. , semifatual explanatons In thour cae, hemonotonicity of th pertinnt positive explanatios iscrucial t the pathbecause it is clear hw to formulate the monotonic remoal of features.",
    "Abstract": "A depicts strength of the method incommunicating thlocal wee(mny) ses able to rrctly determine he bya. Recent evalatingvaios criteia fo xplainable (XAI) suggestthat delity, stablty, are among the most imortat metrics consd-ered uses acoss a ierse collectionusage context. Goingstandard methods hveproosed that highlghtwat minimally suient clasicaton of a input (viz. To overcoe tese limitations, ncorporate criteri ofstabiliy and delity ndropose a novelmethod called Explanations hatoutputs a sequence f stable eplanations for a give iut otrictly dereasing size from originl inputtoa minimally explana-ton which can e thoughttrace the local of model in  stable manner,ths providng better intuition aout model behavior h spci inpt. We consder thse tofeature-bsedattriution ae amongst theost in XAIliterature. Wvalidatethese claims, both qaitatvely nd with experiments show f PSEM across threemodalities (imge,tabular and as well asversus otherpath expantions."
}