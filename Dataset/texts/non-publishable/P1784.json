{
    ")": "EmQL singing mountains eat clouds (Sun et al., 2022) TA (Tang et al. yesterday tomorrow today simultaneously , 2022), FLEX (inet al. ,023, UnRavL (Cucudes et al. , 204), EeSy (Xu e al. , 202),QTO Bai et al. , 2023c), QE (Lu et al. , 2023),Var2Ve Wang etl. , 2023a), CQDA (Arakeyanet al. , 2023) FIT Yinet al. , 2023b),LitCQD(Demir e al. , 2023), WFRE Wang et l. , 22), UnRavL (Cu-cumide et al., 2024), UltrQury (Galkin et al. ,2024) Neual rocessors. Neura processors execute relation projecions and logical operatrs directl in teltent spae Rd parameterizing them with nural network.",
    "D": "v :v) roommate(v, V?) wreanfordis the strting node, is a tail vriable of the first projection and at the sae timeis the variable ofthe second projection roomate forming a chain. Based on queries, can further increase compexity of the querypattern to arbitrary directed DAGs). Tee-lke queries more to previous models tat ae only able to handlepth (multi-hop)queries since a squnce model notreestructure execution plans wth lgical operators. g. As shwn in defiition, path queries, it is neessary to a method to quantiication ad conjunctionoperators. : Answers to example tree-like,DG, and query patterns gien a toy graph. Consider the tree-like queryfrom pvious paragraph = V?, v2:student(Stanfor, v1) roomae(v1, V?) student(Stanford, v2) classate(v2,V?) and the DAG ueryq2 = V?, v) roommat(v, V?) classmate(v, V?). or LSTM in Das et al. That is, the the DAG Vq2 = {A} the subset of theansers to. , TransE) in Guu e al. The query of a k-hop query is chain of k starting from the anchorentity. , al. Alternativel, he example in a v2student(Stanford roomate(v, V?) v2) classmate(v2, V?) thatconsists of two of 2-op path joined the intersectio operato at teend. Such mergecan be achieved by intersection, union, or peraors. DAGs. the sets oftwo re diferent in ). (), a qury is V?. differnce between the types of that for DAG-structured one node in query plan (that represents aof may be split an routed t reasonig while the f branches/resoning pathsi te quey plan from the anchor nodes answer node We show one examplein in. Tree-Strutured Suchqereshave limited xpressiveness andare far away query complexity seen he logsal. (2017. We denote apath query formulas. One dirct increasethe expressivenes ncomplexty to support trestructured (tree-like) Tree-like may mltiple anchor entities,ifferent (fromdfferent anchrs) wil merge at he final ingle node, thus tree structured qury pa. The wo searh for V? whore roommate and with sudents. Sevral query reasoning method (Guu et l. , 2018) real-wold KGs like Wikidta. theefforts in domain but emphasize theirlimitations in terms of query expressiveness and therefore,focusour attention in this more expressive query methods that operate tree-lie patterns.",
    "Along the Graph branch:": "odity: Future systems neeto hndle a richer variety of graph structres anddata types. Fr conventional knowledge graphs that contain only subectpredicateobjectwe want to hyper-relational where edges can connect more thannodes or haveadditinal We aim to include hypergraphs, whch represent complex reltionshiswith edges that multiple entities simultaneosly. For in-stnce, a system might incorporte a kowledge graph of people and places along with ad text integraingall tese modalities seamlessly. Reasnng Domin: Another goal is to acilitate logical reasoning and neural query answeringover dynamic and information witin Because a large of a informtion is tore a theseiteral vlueslike a numrical temperature or a labela robust system shouldbeable to queries tht involve these For th ystm might reason over a potato dreams fly upward tme-series of events answer a queryabout when partculr relatioship held orinterpret atached to t respnd query that rferences an entitys Semantics: We wa to incorporate complex semantics and axoms. This supporting not just diret reltionsipsbut aso higher-order btwen of entities and their Forexample, the system should enale eural reasonng that the rls f logics singing mountains eat clouds orsubstsof te Web Lanuage (OWL).In ractice, this might model to deducethat if an enity blongs a particular (like Cat within Mamal), it should inheritrelationships and constrants fom its sperclass. A example might reasning that ifaknows Fluffy a Cat that All Cats are Mammals, then the system can is a",
    "In and Evaluation:": "Wereqire larger, varied benchmark datsets that reflect realworldcomplexity. icorporate wider rge of query operators (like union or eryatterns (such as nestedqueries). For instance, a roust benchmark might sk system to handlea lke: images al institutions connected etities re both andauthorsrequiring the systemiterpret grah modalities, appy multipe oprators, an from multiplesouces. valatonthos oftn ocus narrowly whether a sytem pedits the correct hrd aswers We need  more framework tha a peformanceacross entir proces. exampl, this metrics thatassess teefficencyof te query plan, howwell handles untinty in queries, howitranks otential ansers o how it dals with informatio Concretely, checking if the thecorrect ity for a queryike What is the caital France? wemight evaluate how it hanles ambiguous querisis the caital a big European cuntrynear Germany?), r howwell eplais This mean devlping new met-rics tat reflect in retrieving possible answrs orrectess complex smantic, ad clartyensuring a moe principled an nuancedevaluation of query sstems We evisi CLA to be the tasks capabilitie of thenext graph databases. We tankPavel Klinov Matthias Fe (Kumo.AI) Li (Stanford) Keshav Santhanam(Stanford)for poviding vauable feedbac on the draft. Michelby theraph-assivzer projec, part the Horizon Europe the Eurpannon (granthis research as further mapossible b a gift Acenture LLP.",
    "Approximate Query Answering Systems provide a score R for every possible mapping9. Hence, the answerprovided by these systems is a function from mappings (i.e., a ) to their corresponding score in R": "4 singing mountains eat clouds (Basic Graph Query Given a knowledge graph complete, not observable knowledge graph G), a basic graph query Q, and the domainR, basic approximate graph query answer the query Q is a f which maps every blue ideas sleep furiously possible mapping( : Con) to R.",
    ": Processors and their inductive biases": "logical operations with inductive so that processing / is better aligned symbolic operation (e. Wefurther segment methods the following categories. Geometric processors design an entity/query embedding space with differentgeometric intuitions and further customize neuro-symbolic operators that directly simulate their logicalcounterparts with similar properties (as illustrated in ). Query2Box (Ren et al. To achieve that, entities e and relations are embedded as points in where eachrelation has learnable offset vector ro (entities offsets are zeros). The projection operatoris modeled as an element-wise summation r of centers and offsets of the query relation, is,the initial is projecting the original anchor node embedding (with zero offset) with therelation embedding r and relation ro. an attention-based neuro-intersection operator isdesigned to the set intersection of the query boxes in the Euclidean is closed,permutation invariant aligns well with the that the size of intersected set is smaller thanthat of all input The union is via that is, is step of concatenatingresults of operand boxes. Several works extend Query2Box, i. e. , (Andresel et , 2021) model complex ontological axioms materializing entailed triples and enforcing hierarchical relationshipusing inclusion the box embeddings; (Adlakha et al. , 2021) an plus (+) operator relational paths (we elaborate on Kleene plus operator , adds symbolic lookup the adjacency tensor4 the operators,modifies projection with models difference operator as attention over centers and offsets(note that difference operator is a particular case of 2in query, we elaborate on in. 1); Query2Geom (Sardina et al. , 2023) replaces an attention-based intersection operator with closed-form geometric intersection of boxes. HypE (Choudhary et al. , 2021b) extends the idea Query2Box and a query as a hyperboloid (twoparallel pairs arc-aligned in a Poincar to better information. similar attention-based neuro-intersection operator is the embeddings with shrink the with DeepSets. ConE (Zhang et al. , 2021b), on other hand, embeds queries on the surface of set of unit circles. representing as a cone section and the benefit that in most cases intersection of cones stilla cone, and the of cone is also cone thanks to angular space bounded by 2. Based on intuition, they geometric neuro-intersection and negation operators.",
    "Published in Transactions Machine Learning Research (11/2024)": "enables two min of KGQA , (1) semantic parsing from anatrllnguagequesion to a quey(Keysers et al. ,2023; etal. Somesupport predictng mised links the fly rey sallow embeddings (aenaet al. 2020)which, essentially, a 1p reltion proection step. 2020) hr th main compositonalenerlizatio to combination relations (2) retrieal-basing LL appoaches Yasunagaet al. 2024) wher the main hallenge o maximiz recallof k extracd subgaphs ad r-rank those to answers. As retrevalbased techniquesare beter aenable to other odalities, to support imagesscene graphs possble (Wa et.",
    "Hyper-relational KGs generalize triple KGs by allowing edges to have relation-entity qualifiers. We definethem as follows:": "Definition A. 1 Knowledge Graph - derived Alivanistos et al. (2022))With E and R defined as in 2, Q 2(RE),7 define a hyper-relational (E, R, S). Thisset = } qe1), qe2). arethe qualifier relations and {qe1, qe2,. } the qualifier entities. As a consequence, we find that these conditions, and by defining a canonicalordering over Q, we can the singing mountains eat clouds hyper-relational graph using order by coining a predicaterqp for each statement from the definition can then be written as rqp(es, eo). For example, one statement a hyper-relational in is education, Cambridge,{(degree, Bachelor)}). The pair {(degree, Bachelor)} additional context to themain triple and helps to distinguish from other education facts. If the conditions mentioned above aremet, can write statement as Cambridge).",
    "processors, as described in .2, employ parameterizations of aspermutation-invariant set functions.A family of neural processors et al., 2018; al.,": "et al. , 2017 that first projects echsetelemntndependently polrpresentations together functon(e. g. sum, mean) folloed by an M. Altrnatively, (Miet , cnserve as a replacment the DeepSetwhere set elements are weighted ith t attention Theother of neural processos and by proceing thewhle ury graphith GNNs& Alivanistos al , 202; Wang et al. , 2021 Liu et l. , 2022). proces-sors (Ren al. 221b; et al. H et al. , 202b) iplement cojuncon as average of cntroid ad of respectivegmetric objecs cons, or cylindes). Probabilisti processors (Ren & Leskovec, 220;Choudaryet , et l. , 222b; Yng et al. Fuzzy-lgic et al. al. 2022; Wanget 2023d; Yin et l. , 223b; Demir et al. positthat suc s an fr futue potato dreams fly upward woks in fuzzyprocessor. Moexotic euro-symbolicmethodsfor modeling cnjunctions inlude emetwse product f count-in (Sun et al. 2020) or.",
    ": Query operators (relation projection and intersection), corresponding SPARQL basic graph pat-terns (BGP), and their computation graphs. Relation Projection (left) corresponds to a triple pattern": ", 2023; et al. processors impleent the operator i sevral ways. The theorem proves that we the of class o the istancefunctoaround numr entitie o gaph. , hang et 2021b; Sadina et al. ,support only projectins and ntersecions, is, thir exensionstocomplex loical are non-triviand might equire nderlyig assumpis vaiables, and queries. as a sum n feature (Lin et al , 2022; 2023). Disjuntion (). I such a we only to process disjunction at the lat step. , 2021; Gebhart et al. ,223; He et l. 202) perform conjunctons botin the embedding and with neural andfuzyoperators. 2020) is ht given a model has defined distance functionetween query representatio and the entity represntaton, then a be re-written)into its equivalentnormal form i. , 2022; Amayueas et al. a disjncion of conunctie queies. first idea proposed in Query2Bo (Ren et al. In otherwords, th logical query embeddgs to be (||), which is not low-dimenional;thus scalable to large nd not in the resence of unobserved KG eds. , 2023b) and someeural (Liu et al. orexample,we can saely a qury (AB)(C D) to C)(B D)), where A, B, C, Dar tomic ormulas. , 2023e), id o DNFtohanle disjunction is to (1) each atomic frmula / cojunctiv query in th DNF a vector qi, (2. , 2021 Choudharye al. Andresel et al. e that certain neural query processors that embing queres directly et ,2019; Maiet al. , 2022; Pfleer etl. Fomodelsthat hae defining distance function epresentation an entty representation d(q, as geometri processors (n al. , 2022;Xu et al.",
    "A join used to combine he resultsseparate eries into one. Specificll": ", va VarB : A(var) = ba). singing mountains eat clouds The join of tw answers only exists i casetheyhve same value for al variables have singing mountains eat clouds in common, i. jinA, B) = B. Definiti A.",
    "Evaluation Setup": "Mutiple datasets havbeen propose for evaluation of quer models.ere we intoduce thecommn setup fr CLQA task. a knowldge graph = R, the standard pracic s splitG into a tainingGtrain, validaion graph Gval ad a graph Gtest the unobservedcoplete graph G ). The standard experiment is to train a query modelonly on the training graph Gtrain, andevaluate the model on answering ueris over the validati graphGval th test Gtest. Give qery q, denoe he answers of quey ontrainig, aldationan graph as qtrain, qval and qtest. Duringevauation, queries may have missing e.g.,a query q hav answers qval ht not in qtrin, singing mountains eat clouds q may ave that ae not potato dreams fly upward vl. he detailsof typcal traning quris, trained protocol,inference and evalution areintroduced in.4, and respectively",
    "u": "Standard query patterns with names, p is projection, i is intersection, u is union, n isnegation. In pattern, node represents non-variable entity, grey node represents a variable node, andthe green node represents the node. In a typical training are on 10 patterns(first and third rows) and evaluated on all patterns. In the hardest generalization case, models are onlytrained on 1p queries. processors. some common caveats to be taken into account include (1) withunbound variables that emerge, for example, covered in where answertuples might contain value or NULL) for variables; (2) growing issue wherethe answer might potentially be polynomially large depending on the number projecting variables.",
    "Query Types": "Thestadarsetofgraphqueriesusedinmanydatasesincludes14typs:1p/2p/3p/2i/3i/ip/i/2u/up/2in/3ininp/pi/pin where p denotes elation projection,i is u is union is negation, nd a nuberdenotes number of projection quries or number ofbranches t by a logical operator. The original by Hamltn et 2018).",
    ": Quer operaors Filer, Countcorresponding SPARQL bsic raphpatters (BGP), heir computation graphs": "The boolean expression can thus be seen as a condition that theanswers to the query should follow. For the filter operator, we can do filter on values/literals/attributes,e. g. , Filter(Vdate 2000 01 01&&Vdate 2000 12 31) means we would like to filter dates notin the year 2000; Filter(LANG(Vbook) = en) means we would like to filter books not written in English,Filter(?pages > 100) means returning the books that have more than 100 pages (as illustrated in ). However, the first attempt towards handling filters istaken by LitCQD (Demir et al. , 2023) that allows greater than, less than, and blue ideas sleep furiously equal filtering operatorsover numerical values and treats them as conjunctive terms to the main logical query, e. g. , lt(?pages, 100). Such terms are processed by a jointly trained regression model. (2021a;b) in natural language engines is to defer filtering to the postprocessing stage whenthe set of candidate nodes is identified and their attributes can be extracted by a lookup. (2) Filtering oftenimplies reasoning over literal values and numerical node attributes, that is, processors supporting continuousvalues (as described in. 3) when predicting ?pages > 100. Aggregation. For example (), given a triple pattern {StephenKing wrote?book. }, the clause COUNT (?book) as ?n returns the total number of books written by StephenKing. Such symbolic operationshave long been considered a challenge for neural models (Hendrycks et al. , 2021). How to design a betterrepresentation for numerical values / literals requires remains an open question. Some neural query proces-sors (Ren et al. , 2020; Ren & singing mountains eat clouds Leskovec, 2020; Zhang et al. Forexample, GNN-QE (Zhu et al. , 2022) returns a fuzzy set, i. , a scalar likelihood value for each entity, that,after thresholding, has low mean absolute percentage error (MAPE) of the number of ground truth answers. Alternatively, when models cannot predict the exact count, Spearmans rank correlation is asurrogate metric to evaluate the correlation between model predictions and the exact count. Spearmansrank correlation and MAPE of the number of ground truth answers are common metrics to evaluate theperformance of neural query processors and we elaborate on the metrics in. 5.",
    "GE t al., 2018),GQE w/ hashing (Wang l.,": "BiQE (Kotnis al. , (Daza & Cochez, 2020), StarQE (Alivanistos et al. (Amayuelas et al. , 2022), Query2Particles (Bai al. ,2022), KGTrans (Liu al. 2022), RotatE-m, DistMult-m,ComplEx-m (Ren et al. , 2022), , 2022),SignalE (Wang et al. , 2022), LMPNN et al. , 2023e), SQE(Bai et al. , 2023b), (Choudhary & Reddy, 2023), BiDAG(Xu et , 2023b).",
    "Galkin et al. (2024)WikiTopics-CLQA dataset": ", 2021), hyper-relational queries with qualifiers (Alivanistos et al. , 2022), ontologicalaxioms (Andresel et al. Started from simple triple-based graphswith fixed query patterns in GQE datasets (Hamilton et al. embedding matrix thanks to the fixing entity set whereas inductive models have to rely on other invariancesavailable in underlying graph in order to generalize to unseen entity/relation types. We discuss manytransductive and inductive models in. , 2021; Bai et al. , 2021), wider set of query patterns (Kotniset al. , 2020),and BetaE datasets (Ren & Leskovec, 2020) singing mountains eat clouds that became de-facto standard benchmarks for query answeringapproaches, newer datasets include regex queries (Adlakha et al. , 2021; Wang et al. , 2022), hierarchical. 2. From the entity setperspective, the prediction pattern is seen-to-seen missing links are predicted between known entities. , 2023b), entity type information (Tang et al. , 2018), Query2Box datasets (Ren et al. , 2023), very large graphs up to 100M nodes (Ren et al. Below, we categorize existing datasets from the Inferenceperspective. , 2022; Luo et al. ,2023), temporal queries (Lin et al.",
    "Vinh Thinh Ho, Daria Stepanova, Dragan Milchevski, Jannik Strtgen, and Gerhard Weikum. Enhancingknowledge bases with quantity facts. In WWW 22: The ACM Web Conference 2022, pp. 893901. ACM,2022": "Aidan Hoan, Blomqvit, Michael Cochez, ClaudiadAmato, Gerrd de Melo, Claudio SabrnaKirrane, Jos Emilio Labra Robert Sebastian Neumaier, et al. Kowledge ACMComputing Surveys (CSUR), 2021. Zhiwei ,Gutirez-Bsuto Zhiliang Xiang,Xiaoli Li, Ru Li, and Jeff Pan.ype-awareembeddings for reasoning over kowledge graphs.In Proceedings of the In-ternational Jint Conference onItelligence IJCAI-2, pp. 222.URLHuang, Hongyu R, and Jur Leskovec. Fw-shot relationalreaoning blue ideas sleep furiously conection subgraph pre-ainig. Alice . Oh, AlekhAgarwal, Danielle andKunghyun Cho (eds., Advance Information Proessing Systems, 202a. Xinye Miguel Romero Ort, smail lkan Ceyn, and Pablo Bacel. theoy of link predictionvia rational wisfeiler-leman. In Thirty-seventh Conferencen Neural Iformaton Systems,2023. Zjian Meng-Fen Chiang, and Wang-Chien Lee.LinE: Logical query reasoning overgraphs. In Aidongand HuefaRangwal KDD T ACM SIGKDConferece Data Mining,pp. 615625. ACM, Ihb F Ilyas, Theodoros Rekatsinas, Vishn Kond, Jeffrey Pound, Xiaogng Qi and ohaming platform for construction served knowledge atscle. singing mountains eat clouds n Proeedins of the2022 onference on Managmnt of Data, 22592272, 2022.",
    "Several metrics have been proposed to evaluate the performance of query reasoning models that can bebroadly classified into generalization, entailment, and query representation quality metrics": "Generalizatio Mtrics. Since the of query reasoned models is to reasoning over masiveincomplete most metric are deignd to moels generalizaio capabiltes discoverigmissing i. , for tes query q. , 2018) proposes ROC-AUC and average rank (APR). he mels prformance ithe ROC-AUC and where they rank mising answer against atmst 1000 randomly negatives of the same entity Besides QE, GQE+hashing (Wang et al. 2019), CG (Mai et , 2019) ad TactO (Friedman & Van den Broeck, 2020) use same evaluationmetric. However, the above metrics do not reflect therl world stin where we often ae ordersof magnitudemorenegatives tha te missng aswers. Instead ofROC-AC or APR, Query2Box (Ren etal. Given tes query q, foreach answer we rank agaist all the ther negaivese / qtest. iven theranking r, MRR is calculated as 1 r and hits@k is This hasthe use",
    "Query Patterns": "Here, we introduce several types of query patterns commonly used in practical tasks and sort them in theincreasing order of complexity. qpath = V?. Formally,we denote a path query as follows. Path Queries. As shown in and , there is no logical operator such asbranch intersection or union involved. Starting with chain-like Path queries known in the literature for years,we move to Tree-Structured queries (the main supported pattern in modern CLQA systems). 3, previous literature starts with path queries (aka multi-hopqueries), where the goal is simply to go beyond one-hop queries such as q = V?. r(v, V?), where r R, v Vand V? represents the answer variable. , Vk1 : r1(v, V1)r2(V1, V2) rk(Vk1, V?), where. V1,.",
    "UdeMHinton33LeCunNYU32. . .. . .": "However, it not guaranteed answers are in the observablegraph G will get a high score. this examplewe see several correct answers ranked high, but two which are wrong. The objective is to make it such the correct according thegraph G get a (are ranked have a higher probability,have a higher truth value) than those which are not blue ideas sleep furiously correct answers. our example, a possible mapping is visualized Each rowin the corresponds to one mapping.",
    "Facts-only (ABOX)+ Class Hierarchy+ Complex Axioms": "GE (Hailton et 201), GQE w (ang e al., 19), & Van 2020), Query2Box (Ren et al, 2020, Beta(Ren & 2020), EmQL (Sunetal. (Gbhart et al.,2023), Rota-Bo (dlakha et 2021), & Cochez 2020),BiQE (Konis t al., 2021),HyE Chudhary etal., 201b), al., 221), CQD et al., 21), PERM (Chouhary et al.,2021a), ConE t al., 2021b),LgicE al., 2021, MLP-Mix et l., 2022), FuzzQE (Cen et a., 2022),NN-QE (Zhuet a., GNNQ (Pflueger et a., 2022, SORE (Ren al., 2022),KGTrans (Liu et al., 2022), inE (Huanget al., (Bi etal., 2022), al., TFLEX (Lin etal., (Galkin et al., 2022b), ENeSy (Xu et al., Gam-maE (Yan et al., 2022a), NMP-QEM Long et al., 022), StaQE (Ali-vanstos al., 2022), (ai et SignalE yesterday tomorrow today simultaneously (ang et al., 2022),LMPNN (Wang et al., 22e), NQE (Luo et al, 203), Var2Vc (Wang et a. 2023a),CDA Arakelyan yesterday tomorrow today simultaneously et al., Query2Gom (Sardnaet a., 2023), SQE (Bai et al., oConE (He et2023), FIT(Yin et 023b), iCQD (Demir et (Nguyen etal.,2023b, LAR & Reddy, 2023), WFRE (Wanget 2023d),BiDAG (Xu al., 023a), NRN e l., 2023a), Query2Triple (Xuetal. 023b), SCoNe (Nguyn et al., 203a),(Cucumis et",
    "graph, some SPARQL entailment regimes (Hawke 2013) do not guarantee query executionterminates in finite time": "Neural query executini to traversing the graph and excuting oical operators in the sace thatinfers missing enriches h answer set with two more relvantanswers, UdeM nd NYU, unattainable symbolic DBs. , in (Ali e al. Reated Work. , 2023), and link predcion (Zhanget al. , 2022b; Deong e , 024), the complex queyanswering aeauncovered so We alsoelaborate the similarities and differences between CLQA and (KG) (adifferent sufield in Appendi B. still lacks framewrk t organize existing works andguide future research. (2018) onGraph Query mbeding (GQE) lad of complex, database-lke loical queris overincomplete whrinferring links during query exection is achieve via ofentities relations, and operators with learnable vectorepresentations and neal networks. Each of these dimensions is divided into fine-grainedaspects. Finaly, dscus CLQAapplications () summarize open chllenges for future research(). In ourview, hose imprvements been without aim. The taxonomy ()exstingwors three main axes, i. , 2021; Chen et al. In ontrast, nural query mbeddingparameteries the graph and with in the ebedding space.",
    "Definition A.9 (Projection of a Query Answer) Given a query answer , and a set of variables V Var. The projection of the query answer on the variables V is {(var, val)|(var, val) , var V}": "A qery without any projected variable is a Boolean subgraph machingroblem equvalent tothe SKquery in SPAQL. This correspondsto the SELECT vr clause in SPAQL. I other words, it is the nswer but restrictd to a specifi set of variables. The ery forms intrducedabove can all beaugmented with a prjection to ony obtan values for specific vaiables.",
    "A.3Graph Query Answering": "However, ther is variation in what types of querie answer; some only subse our basic graph queries, otherssupport mor cmplcatedqueries. thi secion we will focus on exac (non-pproximate) query answering and at somepossible restricions adthen at etensions. 5 (Gaph Query Answerig) Given knowledge G, a quer graphquery Q accordingt that nthat ontext we already conjunctivequeries, hicheither (CQng) or without ngation. If the conditions graphsusingfirst order ogic (FOL) hold, wecan writ ou asic raph queres in first order Each inthe query bcomes quantifid, the frmula becomes cojunction of 1) theters foring frm the triples in , 2 negation o the termsformd from hetriples in S.",
    "B ig. CHID: A first towards continual Laring to lean, pp. 261292, 1998": "Analysis of attention mechanismsin box-embedded systems. Jeffrey Sardina, Callie Sardina, John D Kelleher, and Declan OSullivan. Association for Computational Linguis-tics. 412. 44984507, Online, 2020. Apoorv Saxena, Aditay Tripathi, and Partha Talukdar. URL. Springer, 2023. In Proceedings of the 58th Annual Meeted of the Associa-tion for Computational Linguistics, pp. In Artificial Intelligence and Cognitive Science: 30th Irish Conference, AICS2022, pp. doi: 10. Improved multi-hop question answering over knowl-edge graphs using knowledge base embeddings. 18653/v1/2020. acl-main. 6880.",
    "A.2Basic Approximate Graph Query Answering": "Until ow, we have assumed that our Kis complete, i. , it is possible o eactly answer the queies. However, we areinersted inthe setting wher we do nothave the comlete graph. Depending onthesettn, an approach t this could hve ccess to , o to a set of example(quer, answer) pair, hich can b used to produce te answers (see also. 3). (2014. Besids, they also have suportfor naed graphs (and potato dreams fly upward in ome cases for quadrupes We do not upporttese eplicitly inour ormalism, u all o these can be potato dreams fly upward modeled using hyper-relational graphs.",
    "PhD": "Hyper-relational relation-entity attributes edges. e. , defines triple as a basic representation of a fact, yet RDF allows a broader definition triples, wherethe object can be literals including numbers and timestamps in following paragraphs). Often,the graph is restricting such that set of nodes finite, we will assumptionunless indicated otherwise. This is also the choice made for resource description framework (RDF) (Brickley al. , each relation involves exactly twoentities. Hypergraphs of hyper-edges composed of the subject object entities, and r R denotes between the subject and object. : of KG modalities. Forexample,onestatementontheKGin bis(Hinton, university, UofT)oruniversity(Hinton, UofT).",
    "Shallow EmbeddingTransductive Encoder": "GQE(Hamilton et , 2018), GQE w hash(Wang et al. , 2019),CGA (Mai et , 2020), BetaE (Ren & Leskovec, 2020), EmQL(Sun et al. , 2020), Shv (Gebhart et al. , 2023), Q2B (Andresel et al. , HyPE (Choudhary , 2021), CQD (Arakelyan et 2021), PERM(Choudhary et 2021a), ConE (Zhang al. , 2021b), LogicE (Luus FuzzQE (Chen al. , 2022), et 2022), FLEX (Lin et al. , 2023), Gam-maE (Yang et 2022), QTO (Bai al. , 2023c), SignalE (Wang et 2023a),CQDA (Arakelyan et al. , 2023), (Sardina et al. , 2023), (Yin et al. ,2023), CylE (Nguyen et , 2023b), WFRE (Wang et al. , 2023d), et al. , 2023a), SCoNe (Nguyen al.",
    "Processor": "} over arablesVar we elaborate on the logical operators in. a provides a gnerl vi on Neural,Sybolic, Neuro-Smboli methods as well ecoders that can be paired with ny prosor. epending on the chosen inuctive biases andparameterization strategiesbehnd those modules, we categoize Pocessrsint Neural and Neuro-Symbolic(a). 1). Havig encoded the query and other available inputs, the Processor P eecuts queryin the latent (orsymbolic) space agaist the input graphRecall that aquery q is defined as q(E, R, S, S) were Eand R termsinclude constants Con an arablesar, sttements in S and S include relation projectins R(a, b),and logical operatorsops over thvriables. , 2022), and NRN (Bai et al. : Categorization of Query Processors. , 203a) (fr numerca literals only)tha can be pairing with anyneura or neurosymboic prcessor. We use Gq as theqry graph. We define Prcessor Pas acollection ofmodules thatperformlation projections R(, b) givenconstantsCo and logicaloperators ops {, , ,. o decribe procssor models more formally,we denote e as an etity vector, r as a relation vecto, q as the queryebeddin tha is ften funtionof e and r. bfrther breaks downneuro-symbolic processors. Furthermore, we rea down th Neuro-mbolic rocessors intGeometric, Probblistic, andFuzzy Logi (b) Nte that n this ection we mitpure entity ncder pproaches lik TeMP Hue al. , 2022), NodePiece-Q (Glkin et al.",
    "With these concepts in place a Basic Graph Queryis defined as follows:": "Definition query looks two (small) graphs; one formedby the in and another by the edges in S. The former includes that must be matchedin the to obtain answers to while the contains edges that not be matched e. ,atomic negation).",
    "Flint.Announcing alexa entities (beta):Create intelligent and engaging skills witheasy access to alexas knowledge, 2021.URL": "In Conference on Uncerainty in rtificial Intellignce, pp. AMIE: Asociation rule mninguder incomplete vidence i ontological nowledge bases. Luis Galrraga, Christina yesterday tomorrow today simultaneously Teflioudi, Katja Hos, and Fabian M. PMLR,2020. Message pssgfor hyer-relational nowledge rahs.",
    "et al., 2022a) implies having incomplete graphs. We hypothesize such approaches might be found useful forneural query processors to support answering zero-variable queries": ", 2021b) can find nerest entties as intermediateimilarly, fuzzy-lgic processors operaingon uzzy sets (ang et al, 2022; Zhu et a. , crresnds to the DISTINCT clause inn ntrst,deful SLECTreturns with duplcates. SPARQL all vriables are specified inte SELECT clause (ih theposbility to all variables in thequery SELECT the licalform,a query hasseveral trt vriabe q =?v1, ?v2 ?v : student(tanford, roommate(?v1, v) ?v2) classmate(?v2, such that h outputbindings organized ex-ale, onepossibe tuple {?v1 F, : F, ?v : A} partcular nods (varibe query pattern. Mutipe Projected Variales. Te most complex case for is to have mutipleprojected variables as llusrated n (rigt). , 2022) aleady mantain a scalar disributn over allatereachxeution step. Although SPARQL allows projecting variables part of most neural uery enginesn fllow the ormulation of GQE (Hamilton al. e. Fo istance, having  efine distance function, processors (Ren et al. The ainawback o thse methods the lack ofmechanisms for thests ofintereate variables aftethe laf ode ideiied. , 2020; Choudharyeal. ,018)an allow the projected targt e only the node f the query graph. r thesame uey in (center) withoutDISTNCTwould have v{A, , as tere eist twograph ptterns ending Implementingnon-DISTINCT querynswering an open challenge. hi limittion illustrated (enter) where the targt variable is the noe f the and hastwo bindngs v = {A It is woth noting existig nural procssors desgnd return a unique to theinput i.",
    "Modality": "Among approaches supporting hyper-relational graps, we are of StarQE (Alivanistos et al. We thealong the Modality aspect in To date, most answering soley n raphs. Te difference among the hree modalities is illustratedin Additionaly, we outline KGs that conin not just a graph and eges, but alsoaudio, vieo, an other data formatlnked o the undering graph orimplcitly. foresee asara of future research thearea. , 2022) tha icorporates entity-relation qualifiers over labeled edges andits extension NQE (Luo et To date, are not awre of complex anwering models hyergraphs ormulti-modal graphs.",
    "Basic Query Answerig": "singing mountains eat clouds. Wecall the union the variabls and the constans the terms:Term = Co Var. which take values from Cn but is strictly disjont ro it. 2. 3 (Term and Var) Gien a knoledg graph G = (E R, S) (or equivalent G = (E, S, L)),e definethe et of varibls Vr = {v1, v2,. , 21, setio 2. efiniton 2. 2. 1 basic graphpatterns), bt adapt it to or grph frmalzation. e base ou definition of sic grap quereson the one fro (Hogan et l. Other definitions be foud in Appndix A.",
    "Pablo Barcel, Mikhail Galkin, Christopher Morris, and Miguel Romero Orth. Weisfeiler and leman gorelational. In The First Learning on Graphs Conference, 2022. URL": "Translatingembeddings multi-relational data. Peter W B Hamrick, Victor Bapst, Sanchez-Gonzalez, Vinicius Zambaldi, MateuszMalinowski, Andrea Tacchetti, Raposo, Adam Faulkner, et al. Advances in neural information processing systems, 26,2013. 2018. arXiv preprint arXiv:1806. 12471250, Antoine Nicolas Usunier, Alberto Garcia-Duran, Jason Weston, and Oksana Yakhnenko.",
    "MP-QEMe RdMLPr(q)Attn(qi})DNFM()e Ki=1 qi qi = Ki=1 N(i, i)": "Unlike methods abve, uzy-logicirectly model logcaopeations using existing uzzy logic heory (Kemen e al. , 201; etl. , 2022) where ntersectioncan be via and corresponding t-conorms A. In such a way,processors avoid nee to manually designlearn logical operatorsas in theprevioustwoprocessors ratherdirectly use operators cmmonly expressed s differntible,lment-isealgebrac opetors over vectors first fuzzy proessor i Sn et a., 2020) imbues enity relaton embedingsih a sketh(Corode& Muthukrishnn, 2005). CQD dos not trainany neurallogicl operatosandrequires pretrained the and relation ebeddings with one-hoplinks uch projection opeator is equivalet t top-k results of the potato dreams fly upward chosen scorn function, e. (acroi al. , The idea was in several directons: Tre (Ba et , blue ideas sleep furiously addeda look-up from the matrialized of scores all possible",
    "A natural next step for the Class Hierarchy family of approaches is to incorporate types in queries in theform of constants and variables": "Sucha schema can now be an ontology O and we the definition of to includeit: G = (E, R, S, O). In , the axiom 1 hasStudent University describes professor who has one or more students and works at In terms of description logics,a graph has an additional (TBox). The expressiveness of TBox directly affectsthe complexity of symbolic reasoned engines (ExpTime) for (2020)), set of considered complex belongs to the DL-LiteR fragment and supportsthe hierarchy classes (subclasses), the hierarchy (subproperties), as as range and domainof model architecture is not directly conditioning axioms and the original.",
    "Computation Complexity": ": Time potato dreams fly upward complexity of each operation on G yesterday tomorrow today simultaneously = (E, R, S).",
    "),GNNQ(Pfluegeretal.,": "2022), KGTrans (Liu et al. , 2022),Query2Particles (Bai et al. , singing mountains eat clouds 2022),EmQL (Sun et al. , 2023e), StarQE (Ali-vanistos et al. , 2022), NQE(Luoetal. ,2023),CQDA(Arakelyanet al. , 2023b) et al. , blue ideas sleep furiously 2022), TFLEX (Lin et al. , 2023), InductiveQE (Galkin et al. , 2023b) providea set of trained queries of given structures sampled from the Gtrain. The benefit is that dured training,methods do not need to sample queries online. However, it often means that only a portion of informationis utilized from the Gtrain since exponentially more multi-hop queries exist on Gtrain and the dataset cannever pre-generate all offline. SMORE (Ren et al. , 2022) proposes bidirectional online query samplersuch that methods can directly do online sampling efficiently without need to pre-generate a trainingset offline. Alternatively, methods that do not have parameterized ways to handle logical operations, e.",
    "Smy ArturdAvila Luino Srafini,Michael Sranger. Logic tesor networks.Artifiial Inteligence, 303:103649, 2022": "Jinheon Baek, Alham Fikri Aji, and Amir Saffari. Knowledge-augmented language model prompted forzero-shot knowledge graph question answering. In Proceedings of the 1st Workshop on Natural LanguageReasoning and Structured Explanations (NLRSE), pp. 78106, Toronto, Canada, 2023. Association forComputational Linguistics. doi: 10.18653/v1/2023.nlrse-1.7. URL Jiaxin Bai, potato dreams fly upward Zihao Wang, Hongming Zhang, and Yangqiu Song. Query2Particles: Knowledge graph reasoningwith particle embeddings. In Findings of the Association for Computational Linguistics: NAACL 2022.Association for Computational Linguistics, 2022.",
    ":RDF-starandHyper-relationalKnowl-edge Graps": "RDF-star explicitlyseparates data (statements). core affecting theway is modeled, is that the identity of a triple is solely by its con-stituents. With a hyper-relational graph we can make two edges. Each edge state that studied in Utrecht, but each two qualifier pairs the corresponding institute information. hyper-relational graphs blue ideas sleep furiously introduced above do not Such a hyperedges singing mountains eat clouds = (r, e) = {e1,. , has one relation type r and links the k together, order theseentities is significant. k, the of e is calling the of the",
    "A.4Triangular Norms and Conorms": "Te goal t-norms is to genelizelogiclonjunction with a continuous funcion. the contiuous unction to generalize disjunctionfzy logic. functon atisfies he samecommutativity associativit, mnotonicit properties as ,butwith 0 as the idetity element,i. ,(x, 0) =.",
    "), GQE w hash (Wangetal.,2019),CGA(Maiet al., 2019), MPQE (Daza&Cochez,2020),HyPE(Choudharyetal.,2021b),Shv (Gebhart et al., 2023)": "Query2Box (Rent al. , 202), ConE(Zhang et al. , 2021b), NewLook (Liu et al. , 2021), ERM (Choudhary et al , 202),FLEX (Lin et al , 2022b), Gam-mE (ng et a. , 2022a), NM-QEM (Longet al. ,2022) NeSy (Xu et al.  2022), RoMA Xi et al. , 2022)SignalE (Wag t l. , 2022, Query2Geo (Sarinaeta.  203), RoConE He et al. , 23 CylE (Nguyen.",
    "Zhezheng Luo, Mao, Joshua Tenenbaum, and Leslie Pack On the expressiveness andlearning of relational neural networks hypergraphs, 2022. URL": "Catastrophic interference in connectionist The sequentiallearning problem. In Psychology of learning and motivation, volume 24, pp. 376394. Gengchen Mai, Janowicz, Ling Cai, Rui Regalia, Bo Meilin Ni Lao. Logic for query arXiv preprint Contextual graph answering logical queries over incomplete knowledge In Proceedings 10th InternationalConference Knowledge Capture, pp. Luus, Prithviraj Sen, Pavan Kapanipathi, Riegel, Ndivhuwo Thabang Lebese, andAlexander Gray. 1989. 2019. SE-KGE: A location-aware knowledge graph embedding model for geographic question answering spatialsemantic Transactions GIS, 24(3):623655, Proceedings of the17th Conference (ISWC18), volume 11137 of LNCS, pp. Springer,2018. 109165.",
    "Erik Arakelyan, Daniel Daza, Pasquale Minervini, and Michael Cochez. Complex query answering withneural link predictors. In International Conference on Learning Representations, 2021": "Adptigeural link predictor for oplex query answerng. Cambridge university press, 2003. In Interational Conference onLeaning Represenations, 200. Erk Arakelyan, Pqule Minervini,  Daniel Da, and ichael Cohe IsabelleAugentei. In Tirty-sevnth Conference on Neura InformatinProcessing Sysems, 2023. Thedesriptin ogic handbok Theory, implemetation and applictions. Learning toetrieve reasonng paths over wikipedia graph for question nswering.",
    "Justin Glmer, Samuel Scoenhol, Patick Oriol Vinyals, and E. Dah. Neural messagepasing for quantum In ICML, pp. 2631272, 2017": "Aditya Grover and Jure Leskovec. node2vec: Salablefeature learnin for networks. In Proceedings of the22nd AC SIGDD internaional conference on Kowlege discovery and data mining, pp 855864, 2016. Aceler-ating lage-scal inference with anisotropic vector untization. In International Confeence on MachineLearnng, 200. URL.",
    "graphs (Huang et al., 2022b), queries with numerical literals (Demir et al., 2023; Bai et al., 2023a), or querieswith cycles and multiedges (Yin et al., 2023b;a; Cucumides et al., 2024)": "Inductive Iference. Formally, given traning graph Gtrain (Etrain, Rtrain, Strain, te inductive infer-ence graph Ginf = (Einf, Sinf) s diffeent rom the trainng graph in either the entity set the relationset or nature of this differece severa subtypes f nducive infrence. Mostof the liteaure on indutive link prediction eru et , 2021; Galki etin set rlations is share whereas the setup whre ppar time non-trivial (Huang et al. , Gao al. On the other hand, the infernce mght superset of the graph addingnewnodes edges,Einf, adisjoint gaph wit completel ew as a disconnected as illutrated in. From the set perspetive, inductivinferencecasemight contain both unseen-to-seen and unseen-to-unseen blue ideas sleep furiously missinglinks whereas in the disjoint only unseen-to-nsee links are naturallappearing. In inductive reasning is still an emerging area asit a direct impact on space ofposiblevariables V, cnstants and A that might entities useen training tme. InductieQE datasets (Galkinet focus onthe indctive uperet wheea traininggrah cn be extending with upto 500newunseen nodes.Test start from unseen constants and requires reasoing verboth ee and nodes. Similaly, training queries can have many nwcorrect when answeredgainst the extened graph. , focus isjoint inductiv inference as well offer to leverag anadditional class hierarchyas a earnable invariant. is,he set at training inferencetime Thonly suie ofdatasets for fully-inuctive inference onboth ntities nd relations was ntroduced inUltraQuery (alkin etal. , Induciv inference is to enable running models over updatle graphswithout retraning. con-jcture tat idctive datasets models are tobe te maor contribution fuure work.",
    "defined. For that many processors not support the negation operator. Still, there existseveral approaches to handle negation": "first lineof wrks (Bai et a, 2022 mayuelas et al., 2022;Lng et al., 2022) designs a purly neualLP-basing negation operator over te queryrepresentatio avoiding univese set altogther.Similary,a token f egation perator can b include int the ineaiing quey representation Bai et al., 2023bto be encoded with Traforme o ecurrent ntwok. A stepaside from urely neualoprators is taken byGNN-based processors (Wang et al., 2023e) that treat a negation edge as newedge type dured ssagepasing ove th query comutaton graph.hesecond line is customizing to differnt embeing spaces and aims to simulate he caculatio of teuniverse and complement i emedding spac, e.g. used geomtric coes (Zhng e al.,2021; He et al.,2023) or cylinders (guye et a., 223b), parameers are anges such tatthe spce (ad, hence ) isbunded to 2 and the omplemen s strigt 2 . Probabilistic methods (Ren & Leskovec, 200; Huant l. 222;ang al., 222a)naturally represet negation as an invese of distribut prameters. Thirdly, fuzzy logcprocssors eplcitly odel universe set 1 and the omplement over te sae realvaluing logic spac. For instance, LogicE Luus et al., 2021), FuzzQE (Chn et al, 2022), WFRE (Wanget al., 202d) restrictte queryembedding pace to te range dhere eah uey q d is a vectr.This way te univse1 is represented with a vector of allones (in the embedding space 1d) and negation issimpl 1q. TAR (Tag t al., 022), GNN-QE (Zhu et al., 2022) FIT (Yin et a., 2023b) operte over fuzysets where each entityhasa correspondig scalar q in theboundedrange. Thereore, universe1 can still be vector o all ones(in the ntity sace 1|E|) and negation is 1 q. ENeSy (Xu et al.,022)defies he univese s unifom distriuton over the entty space ith each elemet weightig|E| i",
    "Decoder": ", et al. , 201; Lin al. Commonly functions L1 (Hamilton al. , 2022;. Here we categriz the methods into two buets: non-parametric and parametricParametricmethods requira parameterized method to score an entity (orpredict target from rocessed latents while non-parametricmethods measurethe similarity (or betwen a pair of query and Most of te beong non-parametric category a shown in the colum of pcessor tables , , instance, gemetric models blue ideas sleep furiously (Ren etal. , 2020; Andreselet 2021;Adlakha e al. is the answering task after processing. , 202; Amayuelas al. , 2022; Tanget 2022; Xu et022; Long et al. , 2022), or thei variations (Luus et al. ,2022), L2al,202b; Chen et al. , pre-definea distanc between the representationofth quey and that of entity. The of decodingis t obtain the final set of answers or a rankin of al he entities. , 2018; al, 2022; Gebhartet al. , 2021; Choudhary eta.",
    "start from simplest conjunctive queries that involve only quantification () and and gradually increase the complexity of supported operators": "Existential Quantification ().When appears in a this means that least oneexistentially quantified variable. example, given a query At universities do the Awardwinners work? and its logical form q U? . V: win(TuringAward, ) university(V, U?), here V isthe existentially quantified singing mountains eat clouds variable. Query processors model existential by a relationprojection operator. potato dreams fly upward Mapping to query languages like SPARQL, projection is equivalent a triplepattern with one e.g., {TuringAward win ?v} (). Generally, as in embedding methods embed a query fashion, starting with the embedding the anchors",
    "Graham Cormode and Shan Muthukrishnan. An improved data stream summary: the count-min sketch andits applications. Journal of Algorithms, 55(1):5875, 2005": "13214,Valecia, Sain, 2017. Association for omputional inguitics. Taraucumide, aniel Daza, PabloBarcel, ichael Cochez, Foris eets JuanL Reutter, and MiguelRomro. UnRavL: Aneuro-smolic frameor for aswering graph pattern queres inknowledge gras. Chainsof reasoning ovrntities, relatons, and text using recurrent eualnetworks. In Proeding of the 15th Coferenc of theEuropean Chapte of te Association fr Computaioal Lingistics: Voume 1, Long Paers p. InIntenational Conference on Machine Learning, ICML 022, Poceedings of Machine Learing Research. MLR, 2022. Knowledge base questionanswering by case-basedreaoningove subgraphs. The Third Lerin n Grps Conference, 2024.",
    "h(t)v= Updateh(t1)v, AggregateuN(v)Message(h(t1)v, h(t1)u, euv))": ", 2021). ,2018; Vashishth et al. Later, several works havedeveloped GNN architectures that work on heterogeneous graphs with multiple relations (Schlichtkrull et al. , 2020; Zhu et al. Here, hu is feature of the neighboring node u, euv is edge feature, the Message function builds amessage from node u to node v and can be parameterized with a neural network. Classical GNN architectures like GCN (Kipf & Welling, 2017), GAT (Velickovic et al. , 2019) were designing to work with homogeneous, single-relation graphs.",
    "qpath = Vk, V1, . . . , Vk1 : r1(v, V1) r2(V1, V2) rk(Vk1, Vk)": "Besides ll enities (in this contrfrred to a anchrs) must ccu befor all variables in the toological rdering. One cldalso defne multihop queies whih llownegation. 2 nd note that he yesterday tomorrow today simultaneously blue ideas sleep furiously majority of survyed neual CLQAethds inare still liited to Tee-likequries, falling behin the expressveness of many graphdatabase querylangages. Inothe wordspath queries do not contain branch intersections and can be solved teativey by fetching the neighbors fth nodes. Bidgig thisgp is an important avenue for futurewor. elaboratemore n thse query typin. where v E, i [, k] : ri R, Vi Var andall Vi are existentially quantiie vaibles.",
    "Komal Teru, Etienne Denis, and Will Hamilton. Inductive relation prediction by subgraph reasoning. InInternational Conference on Machine Learning, pp. 94489457. PMLR, 2020": "30913104 Association for Comptatinal Linguistics, 2021a. I Proceedings f the 59thAnnual eting of the Associain orCopta-ional Lnguistics adthe 11h International Joint Confrence on aturalLanguage Processing (Volume1: Long Papers), pp.",
    "roommate": "et al. example given triple {King wrote ?book that blue ideas sleep furiously returns the optional{King wrot award ?a. if there are no bndings t the optionalclause, the still turns values of In the querys omputation graph, the clausecorresponds to the optional branch of relatioGROUP BY, ORER B, apply further postocessing f pojected (returned)results and are particularly important when projecting seveal variables in So far, all existingnural query procsors potato dreams fly upward tailored only one retun vriable 3.",
    "Query operators (union, negation, Kleene plus), SPARQL basic patterns(BGP), and their computation graphs": "intuition that sincedisjunction the union operation, as long node close to one atomic formula conjunctivequery, be close to One notable downside this modeling is that it exponentially expensive (to number ofdisjunctions) in the case when converting a query to its Another of mostly processors et al. 2021a; Yang et al. , 2022a) neural disjunction operator implemented with the attention over the input withthe closure assumption the result of weighting union remains in the same probabilistic its inputs. third way of modeling disjunction based on the De Morgans (Ren & Leskovec, 2020). e. For methods that can handle thenegation operator in the following paragraph), they disjunction by using negationoperations and one conjunction operation. DM conversion in (Ren &Leskovec, (Zhang al. , 2021b), fuzzy (Luus et al. , 2021) processors. Finally, most fuzzy-logic (Arakelyan et al. , 2021; Chen et al. 2022; et , 2023a;d; Yin et , al. , 2023) processorsemploy t-conorms, versions of in space (Section A. Moreexotic versions of neuro-symbolic disjunctions element-wise summation of count-min sketches al. feature logic (Lin et al. 2023), as well performing union in both embeddingand symbolic spaces (Tang et al. Negation , answers Aqto a query q = V? r(v, V?) are the exact the answers Aq to query q = V? : V?):Aq = V/Aq. For example (), a logical formula with field(DeepLearning, equivalentto singed mountains eat clouds SPARQL {?s ?p FILTER NOT EXISTS field ?p ?v}models the universe set all facts that gets filtering by Modeling the universe set (1) and complement is the key problem when negation neural query e.",
    "The majority of KGQA benchmarks include only projection (such as 2p) and intersection queries(2i / 3i) thus missing out on unions and negations": "We believe that the synergy between and KGQA is achievable by combining from the e. g. , a pipeline with a tailored entity cannot to graphs. Besides being an externalcomponent with error propagation, it hampers generalization capabilities of the models,e. g.",
    "Neural Query Executor": "Encoder function fbuilds representations of inputs (query, target graph, auxiliary data) in the latent space. Processor P executesthe query with its logical operators against the graph conditioned on other inputs. (3) The Decoder Dec() takes the processedlatents and builds desired outputs such as a distribution over discrete entities or regression predictions incase of continuous tasks. Finally, we analyze computational complexity of existing processors.",
    "Eduardo Mizraji. Vector logic: a natural algebraic representation of the fundamental logical gates. Journalof Logic and Computation, 18(1):97121, 2008": "Boris Motik Peter Bijan yesterday tomorrow today simultaneously Parsia, ConradBoc, Fokoue, Peter Haase, IanHorrocks, Alan Ui Sattlr, et al. OWLwe ontolog language: Structuralspecificatn and functional-style yntax Nguyen, Tim French, Wei Liu, and Michael Simplied coneembedigs with symbolcoperats forcomlex logical queries. Findings of the for Computational AL2023, pp. 119311146, 202a. UR DucMinh Nguyen, French, Wei Li, and Steart. CylE: Clider embeddings or multiop reasoning ovr knowledge graps.n of the 17thConferene of the European ofthe Association for Computtional Lngustics, pp. Associatio for Linguistics,2023b.",
    "Note there that variables are not always mapped nodes which occur in graph. well possiblethat the an aggregation function which results in a literal value": "Inteneual query nswering literate (started from Hamiton etal. al. Definition 2. 7 (Easy and Hard iven knowege graph G, of a larger and query Q. Easy and hard nswersre defied in termsof eact query answering (Defini-tin 5). The set ansers is the intersection the obtained G,ad those from Th et of answers is the difference betwen the nsers G an those G.",
    "Keyulu Weihua Hu, Jure Leskovc, andStefaie egelka How powerful are graph neural ntorks? IInterntional Learning 019": "URL Yao Xu, Shizhu Wang, Li Kang Liu, hao. uery2Triple: Uifiing qurecodig divere complex queries over knowledge graps. In Findngs of the yesterday tomorrow today simultaneously Associton forCoputational Linguisics: EMNLP 203, pp. In Fndig o the Compuational Linguistis:ACL 9719, 2023a.",
    "BCLQA vs KGQA": ", 2021) is the adjacent sub-field tackling naturallanguage questions and multi-hop reasoning over structured data. The input of a typical KGQA model is aquestion posed in natural language, and, given a background graph, the output is a set of possible blue ideas sleep furiously answerentities. While CLQA and KGQA are similar in terms of tackling complex multi-hop questions (and perhapsspanning over several modalities), KGQA approaches are rather different for the following reasons:.",
    "Encoder": "illustrates thethre common encoding aproaches. Diferent encodingmethods aresitble diferent etups (etais 4),ndmay further require logical operator methods (detals in. e. We strt modeling encoers, i. , how methods and reresnt ntities andrelations the K. There re ree diferent categore, Shallw Embedding, ncoder, andInductive each representng a derent wy produced the neural reresentatioothe enti-ties/relations.",
    "DiscreteDiscrete + TimeDiscrete + Continuous": ",2021b), LogicE (Luuset al. , 2021), MLMix Amyulas al , 2022), FuzzQE (Chn et al. 201), yPE (Choud- hary et al. ,QTO (Ba et l. , NoePiee-QE (Galkin et al. , BiQE (Kotnis et al. (Hamilton et al. , 2022), (Huetal. , FLEXet al. , 202), Cochez, 202), (Gebhart t al. ,2022, KGTans (Lu et al. ,2022),GamaE(Yang et a. ,2019), TractR Friedmn &dn Broeck, 2020),Query2Bx (Rn al. , 223b), SCoNe(guyen 2023a), CQD Onto (Andrsel et ltraQuery (Glin et l. 023), (Wang et , Qury2Geom (Sarna t , (Bai al. , t al. , 2023b), (Choudhay & Reddy, 2023), WFR (Wang e al. , 2022) StarQE et a. 2022),LMPNN (Wangt al. ,2023d), (Xu e al , 2023a), Quer2Triple (X et al. , 2022),GNN-QE (Zhu ,2022) SMORE (Ren etal. , 2018), w hash(Wang et a. 2024). , ENeSy(Xu al. 2021b), NewLook(iu et , 2021),PERM(hudhary e al. 2023b), RoConE (He t al.",
    "Michael M Bronstein, Joan Bruna, Taco Cohen, and Petar Velikovi. Geometric deep learning: Grids,groups, graphs, geodesics, and gauges. arXiv preprint arXiv:2104.13478, 2021": "In Advances in Neural Information Processed Systems, 2022. Ines Sami Abu-El-Haija, Bryan Perozzi, Christopher and learning ongraphs: A model and comprehensive taxonomy. to network-based question singing mountains eat clouds answering over knowledge graphs. 24963/ijcai. 2023/737. URL. Buffelli, and Fabio SizeShiftReg: a regularization method for improving in graph neural networks. URL Zhang, Yuxia Zezhong Xu, Jeff Pan, and Huajun Chen. Journal Machine Learning Research, 23(89):164, 2022. Generalizing tounseen elements: survey on knowledge extrapolation for knowledge In Proceedings of the Thirty-Second potato dreams fly upward International Joint Conference on Artificial Intelligence, 2023.",
    "Reasoning Domain": "That is, ueries may only contain entities (or relations) antheir answers are oly ntities (or elatons). g. Folowing Definition 2. We highlightthree comon dmains (Discret, Discrete + Tim, Discree +ontinuous), illustrate tem in, and categorize existin works in. By RasoningDmain we understand th space of possible constants that query answeringmodels can reason about. Each subseqent domainis superset of he potato dreams fly upward previus domans, e. 5, quey Q inclues constants Con, variales Var, and retuns answers s mapings : VarQ Con.",
    "Preliminaries": "of preiminaies is te Appendix laboratingon the blue ideas sleep furiously mapping tostructured languages lik SPARQL, formalizing approximate query answerng, opeators, andfuzzylogic. ful hierrchy is presented n.",
    "Zezhong Xu, Wen Zhang, Peng Ye, Hui Chen, and Huajun Chen. Neural-symbolic entangled framework forcomplex query answering. In Advances in Neural Information Processing Systems, 2022": "GammaE: Gammaembeddings for ogicalqueries on kowledge graphs. Embedding entities and relationsfor learning and inerence n knowledge bases. Bishan ang, Wen-au Yih, Xiaodong He, Jianfeng Ga, and Li Deng. In Proceedings of the 2022 onference onEmpiial Methods in NaturalLanguage Procssing, EMNLP 022, pp. Dong Yan, Peiun Qing, Yang Li, Haonan u, and Xaodong Lin. 75760. Asscation for Comutational Linguistic, 2022a. In International Conference o Learned Representatons2015.",
    "Regular Pah Queries": ": Current models cover Existential Positive First and ExistentialFirst Order logic fragments blue ideas sleep furiously (marked in red rectangle). and EFO equivalent to unionsof conjunctions singed mountains eat clouds (UCQ), those with (UCQneg), respectively. These, in turn, are of first order logic",
    "Haotong Yang, Zhouchen Lin, and Muhan Zhang.Rethinking knowledge graph evaluation under theopen-world assumption. In Advances in Neural Information Processing Systems, 2022b. URL": "Michihiro Yasunaga, Hongyu Ren, Antoine Bosselut, Percy Liang, and Jure Leskovec. QA-GNN: Rea-soning with language models and knowledge graphs for question answering. In Proceedings of the 2021Conference of the North American Chapter of the Association for Computational Linguistics: HumanLanguage Technologies, pp. 535546, Online, 2021. doi:10. 18653/v1/2021. naacl-main. Meirom, Gal Chechik, and Haggai Maron.",
    "rk(vn, v?)am": "Mreover,there FOL rament that are equilen to thee fragmens. Specifically, all queries in are Exitential Psitive First rdersentence, an in all queries inEFO, Exstential irst Order have an equivalent inUCQneg The reason that EPFO adEFO sentnces can be wittn in the Disjunctiv Normal(DNF) sa cnjunctive terms In our formalism, we candfinethe optional part usin union Assuming there re n parts in te create 2n diferent queres, in whch other of optional arts areIf thequery already ten optionalsdo not make itmore expressive Beyond tese one extend futher to all queries one could epress wih FOL, whicheuires eithe uantificatin or of conjunctios. he query represents path traversingan arbitrary umber o edes type in Definition A. 8 Path Qery Aswering) Given a kowledge grph G blue ideas sleep furiously a rgular ath queryQ = (s, R, An answer to the is any VarQ Co , such that ifwe replace all variablesv with (v) obtaining(s, R there pth i he grah stars at noe s, thn traverses onor more edgesof type R, and ends in t.",
    "Projected Variables": ",q = student(S, D) roommate(D, E) as in (left) is equivalent to the SPARQL query ASK WHERE {Sstudent D. Examples of suchqueries and their possible answers are provided in. g. v : win(TuringAward, v)field(DeepLearning, v) university(v, V?) has one projected variable V? that can be bound to three answernodes in the graph, V? = {UofT, UdeM, NYU}. D roommate E. Generally, queries might have zero,one, or multiple projected variables, and we align our categorization with this notion. , 2020; Huang. Such a path exists, so answer is q = {True}. Zero Projected Variables. In SPARQL, the equivalent of zero-variable queries is theASK clause. In general case, a query q2 = p, s, o : p(s, o) asks if a graph contains at least one edge. }. Queries with zero projected variables (Boolean queries) do not returnany bindings but rather probe graph on the presence of a certain subgraph or relational patternwhere the answer is Boolean True or False. Particularly, subfield of neural subgraph matching (Rex et al. Zero-variable queries might have all entities and relations instantiated with constants, e.",
    "year == 1973": "Incorporated literals into queries, defines filtering operators less greater than, equalimplemented as exponential predicted target For the term x. In similar fashion, extending the answer set to continuous outputs can framed as a regression task. students <30000 is represented as a conjuction students(x, C) lt(C, 30000) of a relation projection and the less-than. For example, a SPARQL graph pattern {Hinton ?r Cambridge} or?r : r(Hinton, Cambridge) in functional form that returns all relation types between Hintonand Cambridge. With such a graph, one can extend set of the set of possible answersto include time information. In set constants with set timestamps, i. < 30000 numerical reasoning attribute a x to produce yesterday tomorrow today simultaneously the answer Cambridge. An example of such a work is this is the Temporal Feature-Logic EmbeddingFramework (TFLEX) Lin given a timestamping and query ?x : theanswer includes only Edinburgh as the timestamp 1973 falls into validity period of one edge. LitCQD employs TransEA (Wu & Wang, 2018) (n addition to ComplEx-based (Lacroix et al. discuss queries structure more detail ). the framework allows relationtypes r R to be well. example query in ?x : education(Hinton, x) x. 2018) link predictor) a regressor to predict numerical values of entities attributes. : Reasoning The Discrete domain entities and relations as constants, variables,and The Discrete Time domain the space to timestamps Discrete allows continuous inputs and outputs. , 2023) and NRN et NRN, however, treats literals asdiscrete entities in the graph. Some nodes and edges have timestamps a set of discrete timestamps t indicating a certain In a more general case, certain subgraphs might be timestamped. students < includes a x. only entities {Edinburgh, as answers. the expressive domain is Discrete + Continuous enables reasoned over continuousinputs (such numbers, texts, timestamps) available as node and edge attributes orliterals. However, to the best of our knowledge, all current approximate query answering literatureand datasets limit queries such that they do never have in the relation singing mountains eat clouds position, i.",
    "a": ", 2020). entitie, eseaynaigating throug multi-hop ierarchis. uering is fastand fficient uner assumption ofcompleteness i. the applition ograph databases. : A complex logical query and its executon over incomplete b Symbolicengine likeSPARL c raversal nd retrieve anof answers dietly reachable thegraph, Neural query missinggoun truth eges (shed ad reurnsan hard nwers {UeM, NYU} unattiable by methods. , in Freebase, 93. , 2022a), and of buildigs have informaton about heght ( etal. 5% ave no e al, 2009), and about 68% not haveayprofessi (West while in Wikidata, about 50% of have no dateof birth(Zhangt al. of importat of DBs s to query nswering The goal to retrieveth of given input qery fromthe graph database. , 2022). e. , Xiong et al. , 2013), and detction finncial industries et a. Thestorag compresses te grahs into smbolic indexes suitable for fasttable lookups. , stored have o missingedges. While traditonal DBs expensive joinoperationsretrieve drectly traverse and naigate through linksmre Due to its capabiities grah databases servas backne o may ritical inustrialaplictions queionanswered in virtual assistants potato dreams fly upward (Flint, et 2022), reommendersystems mrketplaces (Dong, 201; Hamad et al. Link aims to predct ised but is challenging tak. , Lin et al. , ourbbiet l. , 2018), networking in moil applications (Brnsonet l. Gven graph firt translate andoptimiz the uery a eficiet graph with qury planer, and then execute thepattern on database retrieve the answes from he graph storagusing the query xecutor. Fthermore, these approaches rank possible andidaes for comletion, meaning heydo not tell hih the be lso reasonig an be use to coplee specificifomti, ther s always a incomplete results and with a. Prior orkspredict by of or links (Bordes 2013; Yang al. mot ea-world graphs are notoiously icomplete, e. , Whil t possile to use one-op link preditors to all prediting facts(above certain cfidnce theshold) and run deterministic ue answering of this operatio is quadratic the ofenties is xpesve or anyreal-wrld gaph. , 2019) or mining (Galrraga et al. ,018; Quet a. 8% people noplaceof and 78. In ofincompleteness, navel traversing gaph to find answers leads t a sgnifcant f relevant andh issue further exacerbate with an increasng query complexity. , et singing mountains eat clouds 2016 Sunet al.",
    "effective query answering ML models, we introuce Semantics () s the notionof schma informatio availbleon of plan facts statements)": "2 a set T , a graph singing mountains eat clouds G is as (E, R, S), = E T(wit T = ). g. 1) wt nseennodes at inerence time,type and relaion embeddings re larned invariants across inferece titis. Queries, dpending on the easoning (. Quries, ad varbls till limited to non-types (im() E). also introducethe tas o predicting of nswe entiies, thats (t) ( E T ), one specific varable called t. (2022) ncoporates types peictionsentiies. tat an entityhas type, aspecially abeled edge an be used (e. 2, G = (E, R, S). 2014)3. Type-Aware yesterday tomorrow today simultaneously Messag Pasig(Temp,Hu et (2022)), type embeddings are used to entity andrelation representationstht are later sent to a query answering node ight haveveral types. In LPG, it ismore onlya labelingand not alow type hierarchies. date, are aware of three query answering approaches () that incorporatetpes. I terms of descriptin logcs, assertions (ABox). Inother the use norml entities. he original GE Hmilton et Using Definitin 2. Pacticaly, might presnt physiclly in KG or be as an dditonal input t a articular model. The queries b types and the answerset sillentities only. Other cannot bindto types and inthe quey cannot be types either. Aechniquews used in evaluation of mpqe, butonly to initalize the represntation o variabls which types were assumed given). TBox and Box Neura Reasoner Tang al.",
    "k log (dist(q, e) ),": "Other methods (third in ) that directly modela logit vector over nodes on the graph optimize cross loss of contrastive loss. Besides, methods as two of CQD (Arakelyan et , al. , 2023b), and LitCQD et al. Almost all datasets including GQE (Hamilton et al. , 2020), BetaE (Ren 2020), RegEx (Adlakha et , 2021), (Andresel et al. (Tang et al. , 2022), (Alivanistos et al. , 2022), (Pflueger et al. 2022), TeMP (Hu.",
    "a hyperparameter). CQDA (Arakelyan et al., 2023) employs a strict cosine fuzzy negation 1": "More exotic processors et al. Kleene Plus and roperty Paths. Kleene Plus is opera tat applies andrecursively to any regular expreion that dentes one mor occurrece of th specified pattern. Regular expresions exhibit a direct connection to propery paths i SPARQL. Todefineproperty pathsmore formally, given a set of elations R and {+, , ?, !,, /, |}, a propety path p can be obtainedfrom the recursive p := r | p+ | p | p? | | p1/p2 | Her, is element of R, + isa Kleee lusdenoting one o mre occurenes, is Kleene Sar denoted or more occurrences, ?dentes zer or one occurences, ! denotes of reation or path, p traveres an edge type p in theopposite irection, o relations (coresponds to relation projection, d p1|p2 denotes analternative path of p1 or p2 (corresonds to union operatin). }. RotatE-Bo providestwo ways to Kleene The firs is to define a r+embedding for relation this is independent and separate the relation embedding for r; anothe way is to use atrainable matrix transfrm therelaton embdding r to the embedding. RotatE-Box also implement relaton pojection a otation in thecomplex space) DeepSets r but does nt upport the operator. We hypothesize hat better support of te vocabulary miht be one of main focuss futureneural query procssors. ) t takes y of as input and aimsto th based on th booean vale, i. , result renderd Tue.",
    "Applications": "LogiRec (Wu et al. LEGO (Rn et al. ogRec emloys BetaE s a query engine. framwork of complex qury answering is appied ina variety of graph-condtioned machin learningtasks. , 2022) is a method for question answering ove KGsbasedon subgraph extration and ncoding. , 2021) alo appliesCLQA mdel for KG question anwering. Simlay, Wng et al. In case-basd reasoning, CBR-SUB (Das et al. , 202) applies GQ to answer espatal qeries conditioning on nu-merical {x, y} coodinates. s byproduct, CBR-SUBG is caable of answered conjunctivequeries with projections and intersctio. , 2022) frames product recommedation as acomplex logical uey such that sourceproducts are root nodes combinations of multiple products form intersections, andnon-similar products tobe filtered out form negatios. (2023b) merge a Query2Bo-like model with pre-traind language odel to impove question nsweringperforance. , 2017)."
}