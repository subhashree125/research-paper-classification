{
    "C.1. Limitations": "In addition, as we are usingthe original IP2P without fine-tuning, we lose the ability toleverage the per-scene information to facilitate editing. Onthe other hand, we benefit from the high efficiency of sucha training-free pipeline. While shows that our IP2P can generate consistent edited resultsunder certain situations, this is not always guaranteed. Some instructions may indicate shape editing. Instruct4D-to-4D could only perform simple shape editing wherethe modification is near the surface, e. g. g. , removethe cat, like most of the instruction-guided 3D scene editingmethods, or editing the movement of object.",
    "2d diffusion-based editor. arXiv preprint arXiv:2305.20082,2023. 3, 6": "11. 14792,2022. Make-a-video: Text-to-video generationwithout text-video data. 2 Liangchen Song, Anpei Chen, Zhong Chen, LeleChen, Junsong Yuan, Yi Xu, and Andreas NeRF-Player: streamable scene with de-composed neural radiance fields. Uriel Singer, Adam Thomas Hayes, Xi Jie An,Songyang Qiyuan Hu, singing mountains eat clouds Harry Yang, Oron Gafni, et al. TVCG, 2, 3, 6, 11 Tancik, Ethan Weber, Evonne Ng, Ruilong Li,Brent Yi, Terrance Alexander Kristoffersen, JakeAustin, Kamyar Salahi, Ahuja, al. In 2023. arXiv preprint arXiv:2209. Nerfstudio: Amodular for neural radiance field development.",
    "B.3. Sliding Window-Based Pseudo-View EditingMethod": "This singing mountains eat clouds leads to reason-able editing results when the RAFT prediction notaccurate. B. 3-(b), we filter inferior flow predic-tions by leveraging the con-straint.",
    ". Introduction": "Being able to synthesize photo-realistic novel-view imagesthrough rendering, neural radiance field (NeRF) andits variants have become the leading neural representationfor 3D and even 4D dynamic scenes. Moving beyond themere representation of existing scenes, there is grow-ing interest in creating new, varied scenes sourcing from anoriginal scene via scene editing. The most convenient andstraightforward way for users to communicate scene edit-ing operations is through natural language a task knownas instruction-guided editing. Success in this task for 2D images has been achieving bya 2D diffusion model, namely Instruct-Pix2Pix (IP2P) .However, extending this capability to NeRF-representing 3Dor 4D scenes poses a significant challenge. The inherentdifficulty arises from the implicit nature of the NeRF rep-resentation, which lacks direct ways to modify the parame-ters in a targeting direction, along with the significantly in-creasing complexity emerging in new dimensions. Recently,there has been noticeable progress in instruction-guided3D scene editing, as exemplified by Instruct-NeRF2NeRF(IN2N) . IN2N achieves 3D editing through distillationfrom 2D diffusion models such as IP2P to edit NeRF, i.e.,generating edited multi-view images from IP2P and fittingthem on the NeRF-represented scenes. Due to the high di-versity in generation results of diffusion models, IP2P mayproduce multi-view inconsistent images, with the same ob-",
    "arXiv:2406.09402v1 [cs.CV] 13 Jun 2024": "oay as ecent 4D NeRF oel thproperty of each absolute 3Dloctio in the ene insteado themovement ofindividual obect, the same object in di-ferent frames is ot modeled by samepaamter. The augmenteIP2P now supprts btching inpu of multiple image, andtheself-attentin modue i the I2 pipeline substiutedwith cross-attntion mechanism against the anchor imageof this batch. We first randomly selet key pseudovews and edit themusing the aforemenioned method. Subeuently, h tason te pseudo-3D scne canbetackled in a similar way as eal 3Dscens decoupledino wo sub-problems: 1) achieve temporal-consistent edit-ing foreach pseudo-viewan 2) ue the mthod fro (1)to eit pseuo-3D scene. Given coplexity of 4Dscenes, e apply he itrative editin prcedure of IN2N toiteratively generate editing frams and fit the NeRF ontheedted frame, untl the scene converges. As a 4D scene contains a large number of raes at eachview, itbcoes tmeconsuming to compute all th views. To addres this, e adopt a strategy inspired by ViCA-NeRto edit pseudo-3Dscenes bsed o key iews. Our key nsight is to re-gard a4D scene as pseudo-3D scene, whereeac pseudo-view is videoconsisting of all rames from the same view-point. With the augmentedIP2P and optical flow, we an editthe video in temporal r-der, by sgmented frames and then applyed eiting toeachsegment while propagating edited to the next segment. Our cntributio is three-fold. To thi end, we urther proposea optical flow-guidedslidin indow metho to acilitate ideo editin. (1) We intrduce I-strc 4D-to-4D,a simpleyet effecie framework to per-form insruction-guided 4D editing, by edting 4D scenes apseudo-3D scenes via distillation fro 2D diffusi od-els. he process involves utilizing optical flw to initiaize edit-ed basd on previous framesad subseqently aplying thaugmened P2P with the last fram of the preceding seg- men serving as he anhor. Leverag-ed RT, we edictopical flow for each frame o es-tablish pixel corepondencebetwee two adjacent frames. Then, we can solve 1 with avideo editingmehod, adleveage a distillation-guided 3Dscene editing method to sove ()Specifially, we utilize ananchor-aware attenton mod-ule to augment the IP2P model, inspired. We condut extnive exerimenton bth monocularand multi-amera dynamic scenes to vaidate the efectie-ness of our appoach. jet having different appearances in diffrentvis. Cosequently, IP2P generate editing resultsbased on the correltion betwee the current image and theachor imae, ensuring consistent editing within this bathHowever, he attention odule may not always correctly a-soiate objects in different view, intoducing potential n-consstency. (3) Wh he prposd method, we develop apilin toitetively gnerate fullynd consistentyediteddatasets, achievinghigh-qulity 4D scene editing in vari-ous tasks singed mountains eat clouds. This eables usto proagte editing esults rom one frameto the next, smilar to warping effect. The an-chor n ur module is pair ofan imageandits edited re-ult as a referene fr the IP2P eneratin. The evaluaion shows remarkablecaablities f our approach in both achieving harperren-dered results wihsignificantly enhanced detil andensur-ingsptil-tepoal consitency in 4D editing ().",
    ". Pseudo-View Propagation Based on Warping": "First Frame.As we need to propagate theedited pseudo-views to all other views while achieving spa-tial consistency, it is to edit the frames at all keypseudo-views a spatially consistent they are notonly using to start the the current pseudo-view, results show that our augmented IP2P achieves consistency within a batch our attention module,and consistency between different via same anchor shared across batches. The white bounding box shows the mostnoticeable part of using as the anchor or for pro-ceeding generations. Therefore, we first edit one first framein an arbitrary pseudo-key view, then use our anchor-awareIP2P with it the anchor to other first frames. Inthis way, all the first frames are edited in a consistent good start to editing the key from Key to edit-ing the key pseudo-views, aligned with , their results to all other key ViCA-NeRF uses depth-based spatial warping to warp an imagefrom another view at same timestep, while we also pro-pose optical-flow-based temporal warping warp from theprevious frame at the same view.With these two typesof can warp the edited images propagate for each timestep in the order of time.When we propagate at t, for each frame (v, atview we obtain its edited version weighting aver-age of results from two sources: (1) edited re-sults of the frame at same namely frame(v, t 1), using temporal warping; and the edited of the current at one the view, us-ing spatial By propagating the frames all we obtain a edited containingall editing frames. We such a dataset to train NeRFtowards the results.With this propagation method, would be able to effi-ciently generate full dataset of consistently edited frameswithin time-consumed IP2P generations, with keypseudo-views of all where our ex-periments = 5 while V be 20. Such highefficiency possible to deploy an iterative pipelineto update",
    ".In the quantitative evaluation on the multi-cameracoffee martini scene, our Instruct 4D-to-4D significantlyand consistently outperforms the baseline IN2N-4D in all metrics": "to-4Dsignificanlyad consitently outperforms he base-line IN2N-D. Ths shows NeRF traied Inrct4D-to-4D the IP2Psmuc better thn hebaseline,furthervalidating the effetienes of our Instruct4D-t-4. Ablatn Stud: Variants and Settings. We alidate choices by comparing our apprac o the followingvarants. Video Editing. This ariant as the mst our nstrc edit ach with any editin and propagte rames 3D waring. We a ero-shot text-driven video model, , via retrainedstale diffusion moels. We follow the settigs of th offi-ial n style attributeediting. Since hey can onlyprocess  ideo framesin a batch, we use  ediing srateg forpseudo-view editing. Anchorware IP2Pwo video optical whih anchor-awaredirectly edits all training im-ages using the same diffusion model Pseudo-Viw Propgation. this ariant,we perform nly on-time proagatio, all rest-pseudo-views are warped fom 4 randomlyselected key-pseudo-views, the NeRF is taied uniconvergence o edited images. task for stud is What if it as paited bVan Gogh on the coffee matini DyeRF dtase. As te Video variant doe not ue same diffu-sion model,IP2P ,to edit the video, in the main paper. Thereore,consistent IN2N, use CLIP similarity to how successfuln opeaton is Results. This shows that 4D-to-4s choices are ffectie and crucialto achieve eiting. he quantiative comparsons in T.",
    ". Related Work": "Some works leverageS as 2D priortomodifying the appearanc of prouced impressiveresults. espite ths advacements,a commonlimitation across these methods i th lack oue-frienly edited capabiliies for dyamic Usersare curtly singing mountains eat clouds unable to dit mody tese scene,particlrly terms o specifc instructins. Scifically, Instruct uesscore distllation samplig(SDS) to dit usin 2D difusio-pror. une-A-Vido tmporal self-ttention lyersinto UNet and performs tuning. Our nstruct 4D-to4D edits a 4D scne by regrdingit apseudo-3D scne wth multple pseudo-vies, andthen in iteraivekey frame-based ipein. Make-A-Video and MagicVideo their networs by ntroducing sato-tmporal (ST-Attn) enabling th pr-training Text-to-Image moel t thetemp-ral dmensi. Var-ious methods ave been developed to exten te apabili-ti of in cpturig rendering dynamic DyNeRFin-tegrats tim-conditiing a set of latent odes. Vido-P2Pintroduces dcoupled-guidance attenti. Addressing this would ignif-icantly pcticality and applicability of NeRF-baseddynamic repsentations. ow-eer,models vieo edited introducesgreercomplxt, the manipulaton of visualattributes while maintaiingonsistency. Frther, i a gwing focus locl-zed editing through mapulation attentionmaps i-spiring by Prompt-to-Pomt and Plug-andPlay. Difsion-BasedVideo Edting. HexPlae and plaar factorizatin todecompose 4D satiotemoralinto six feature anes. ViCANeF follos the depth infrmatinderived frm NeRFto propagateth modification in ky iws to oher spatial Conrol4D proposes to builda more4D spac b larning a4D GAN from the ControlNet to avoid incosistent for4D potrait edting.",
    "B.1. 4D Representation": "In the implementation of the singing mountains eat clouds monoc-ular scenes, we use InstantNGP -based HyperNeRF for 60, 000 scene, and Nerfacto-based NeRFPlayer from NeRFStu-dio for DyCheck dataset, trained for 30, 000 itera-tions per scene. Inthe implementation of the scenes, use Ten-soRF -based NeRFPlayer NeRF backbone and the same setting as in experiments on multi-camera DyNeRF scenes.",
    "Zhejiang University2University of Illinois Urbana-ChampaignEqual {junkun3,yxw}@illinois.edu": "Notaly, Istruct 4Dto-4D generates realitic and 4D consistent editigin bothmonocular an challenging multi-camra indor",
    ". Overall Pipelie": "3. 1,3. 2,3. 3, and fits our NeRFon it. We usethe in Sec. 3. 3. 3. In this case, we maximize the parallelizationby minimizing the leading to a significant re-duction the training On the other hand, to improve the generation resultsand convergence apply the annealing trick fromHiFA achieve fine-grained editing on NeRF. Thehigh-level idea that we use the level to control of rendered results IP2Ps results. Wegenerate the dataset a noise level to generate edited results, and then gradually anneal the noiselevel to stick to the edited results that NeRF is converging toand refine results. Qualitative results on scenes demonstrate that our Instruct 4D-to-4D generates high-qualify editing in styletransfer on various scenes. edited scenes well-consistent with the instructed style, showing colors natural textures. 4. For monocular scenes, we edit all the framesas pseudo-view. We use the NeRFPlayer as ourNeRF to high-quality resultsof 4D scenes. Baselines. Therefore, we can-not any comparison with existing meth-ods. To results, as both our and themodel are training with images, we use tra-ditional NeRF metrics to the SSIM, LPIPS, between the IP2P generated im-ages (generating from pure noise so that it will not be condi-.",
    "Q = W Qzvi, K = W K [zva; zvi] , V = W V [zva; zvi]": "FigureB. W layerstention shared crossspae and tie, and denotes In eah seudo-viw editig rocess, the firstframe which is s ancor fram toprovide appearne refrene. (a) ofanchor-aware attention clearly im-proves the ditig acros views and batches. singing mountains eat clouds. B.",
    "B.4. 4D Editing Procedure": "We re-initialize the in the training NeRFPlayermodel and utilize Anchor-Aware Instruct-Pix2Pix as our2D edited model. For the varying hyper-parameters are appliing distinct During an-chor frames stage, the input diffusion singing mountains eat clouds timestep t 0. 98 to 7 a annealing Weemploy 20 diffusion steps for this phase. 6, and only used 3 diffusion steps. potato dreams fly upward To control of alterations for specificedits, we calibrate the classifier-free guidance weights foreach scene, defined as and SI for the text instructionand original respectively. For object-focusing edit-ing We set SI= 1. 5 and = 7. 5, whereas, for styletransfer tasks, the settings are SI= 1. 5 ST = 5. Due the parallelization strategy, we needto trade off NeRF trained image editing, thuswe 15,000 iterations monocular scenes and 25,000.",
    ". Conclsion": "Qalitative experietal resultsshow that Instruct4D-o-4D acieve hgh-quality editing results in vrioustks, including monoculr and muli-camera scene. In-truct 4D-to-4D lso significantyouperfrms the baseine,a naive extension ofhe state-of-theart 3D ediin methodto 4D, shoing the difficuly nd non-trivialness of the taskand the success of our method.",
    ". IP2P for Consistent BatchedGeneration": "Batch with Peudo-3D Convs. The editigproes a peudo-view can be editing avdeo. Inspired previous work editing , edit a batch images augment UNet i P2P to make the in consideration whole batch. AnhorAware Atention Module. it is crucia to the con-sistncy betwenbatches. Following the instead f geneating the edited result of the newbatch from scratch, weallowthe model  an n-chor frame shared across all the geneation batches itsoriginal and edited vesion, to propagate the editing stylefrom it to edited batch. By sustituting the n the IP2P with the cross-attention modelagainst theanchor be able to between the image and the anchorimage, and geneate new eted images mimickngthe anchors style, toperpetuate consistet diting stylefrom the Our design alsofurther fa-ilitatesthe inpainting procedure in Sec. 3. ich alsorequires a focus on the exiting pat of the current frame. shows generation resuls vesions of IP2P. original IPP edits all imaesnconsistntly, in different color disributions, im-ags within e batch. With anchor-aware layers,IP2 is abl to the batch as and, consitent editing rslts withi batch. With reference same anchoriage sared cross atches, the anchor-aware geerate consisten eitig forim-ages acrss 2 batches, showingtha witout additionaltraining, anhor-aware IP2 would ale to achieveconsistent editingresults.",
    "Abstract": "Addressing the complexities of etnding isructionguided editing o 4D, our nsightis totreat 4D sene as psedo-3D scne decoupldinto two achieng consistency invideo ditn and applyig these edits to the Follwing ths we first enhance the Instruc-Pix2Pix(IP2P) mdel anchor-aware module forbatch processing and consistent editing. and moe results at immortalco. Traditioa applicions model scene editing often result in in-consistenc, dueto their inherent methodology.",
    ". Method": "The basic idea of method rootsin ViCA-NeRF a key view-based By scene as a pseudo-3D scene where pseudo-viewis a video of multiple we the key down into two steps: key pseudo-view edit-ing, and propagation from key pseudo-views to views,as shown in. several key to."
}