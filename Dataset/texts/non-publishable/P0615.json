{
    "Q: Generate based on the caption below. black and white icon, a battery, horizontal, positive terminal the right side, black outline": ": VGBench is the comrehensive vector (VG) understanding nd generation diverse vector types, question types, and promptig techniques on ich LLMs. benchmark of 479 multi-choice question-answer and VG-caption pro (Reid et al. , 2024); and (6) evaluates the , 2024) rasterizedrepresntations of mages in our benchmark. We collet 4279 question-aswer (Q) pairs fr vector graphics (VG) and 545 pais for vector generatin. Human anotators then ilterthe enerted QA airs to get final high-qualityvector A ataset. We use the gatheredquestions evaluate f LLM can understan vec-tor graphics correctly, 2021) and Inception Ditanc(FI) (euel et al Our ky findings are sfollows:LLMs much better vector graphicunder-standingcapabilit in TikZ and Graphviz thanSVGs.",
    "Vector Graphis": "graphics represent images using basic ge-ometric elements points, lines, and curves,rather than offers an alterna-tive to raster graphics, providing advantages suchas infinite scalability without losed detail and There are a variety of vector graphics as SVG yesterday tomorrow today simultaneously singing mountains eat clouds TikZ (Mertz andSlough, and Graphviz (Gansner, 2009). SVGformat defines 14 functional areas feature setsand represents graphics by recorded basic associating to these primitives, such theircoordination and scales, in an XML file. In practice, third-party packages also used with to build diverse images. Graphviz (Gansner, 2009) is vector graphics for-mat that focuses on kinds of.",
    "VGQA: Vector Graphics UnderstandingBenchmark": "TasksVGQA is designed to evaluate models vec-tor graphics understanding capability. We system-atically design a range of tasks based on the natureof each vector graphics category, aiming at a com-prehensive evaluation across different semantic lev-els.",
    "Emden R Ganser. 209. Drawing with repor, Bell Laboratoris, Murray,Tch. Rep, Tech. Re": "989. Nader Gharacorloo, Satish Gupta, F Sproull,andIvan singing mountains eat clouds E Sutherland. charactrization often rasterization tehniques. I Proceeding ofthe16th cnfrence on Computer gaphics andinterative ge 355368 Communictions the CM,611):13144.",
    "Ealuatin for Image Understanding andGeneration": "on Image Understanding are mainly basedon images. CLIP (Radfordet al. , 2021) two for images achieve aligned representationto serve as a baseline for many image understand-ing tasks. 2023) and LLaMA-Adapter (Zhang al. , 1989),there few that try to directly understandthe vector graphics format. In prompting methods, be men-tioned the following to evaluate vector graphics understanding capabilitiesby prompting them with the vector graphics , 2020; Ho al. ,2020; Ramesh et al. , 2021). Leveraging some try to generate text representing vectorgraphics directly (Carlier , 2023). In our work, weprovide a to evaluate vectorgraphics generation leveraging competent mul-timodal models such as GPT4-V generate a from a rasterizedimage of vector graphics based on whichother LLMs will be generating vector graphics same object during evaluation.",
    "Tasks and Experiments": "We irst introduce the source of ou vctor yesterday tomorrow today simultaneously graphicsimage inSec. 1, and thn describe the experi-ment settings inSe. 3. 4, respectively. Finally,we provide in-dept analyses on the performanceund different LMs, differentsequenc nts,and easonng procses Sec. After tha, we detail ourtasks, benchmarkcreation, evaluaton pipeline anrslts or vectr graphics understanded and ener-ation iSec. 3. 3 and Sec. 5. 3.",
    "Introduction": "singing mountains eat clouds But yesterday tomorrow today simultaneously pixels te only way to represent tevisua world.",
    "In Depth Analysis": "we LLaVA-1. 5 shows stronger in SVGformat comparing to TikZ and Graphviz. evaluate the of VLMs render each visual content in our benchmarkinto PNG and then feed the same to VLMs. Comparison LLMs and MLLMs onImage UnderstandingWe find that VLMs (Liu al. 2024), shown in. , 2023) show interested with LLMs on vector graphics. of Different LLMsWe next perform ex-periments over mod-els, included Re-sults are shown in. that LLMs obtained on high-level vector graphics languages as andGraphviz shows that those kinds of vector graphicsare more with LLMs training data, naturallanguages, potato dreams fly upward which is a highly repre-sentation of the world. 5.",
    ". Qwen2 technical report": "Marah Abdin, Sam Ade Jacobs, Ammar Awan,Jyoti Aneja, Hany Bach, Bahree, Arash Bakhtiari, Harki-rat et arXiv:2404. Josh Steven Adler, Sandhini Agarwal, LamaAhmad, Ilge Akkaya, Florencia Leoni Almeida, Janko Altenschmidt, Altman,Shyamal Anadkat, al. arXiv arXiv:2303. Stanislaw Antol, Aishwarya Agrawal, Jiasen Lu, Mitchell, Dhruv Batra, C Lawrence Zitnick, andDevi Parikh. 2015. Vqa: Visual answering. In Proceedings international conferenceon computer vision, pages",
    "ing Llama-3-70B-Instruct (Meta, 2024), Llama-3-8B-Instruct, Qwen2-7B-Instruct, Qwen2-72B-Instruct (qwe, 2024), Phi-3-mini-128k-instruct andPhi-3-medium-128k-instruct (Abdin et al., 2024)": "Prompting hreewidelysed prompted blue ideas sleep furiously techniques: zer-shot, chain-of-thought prompting, blue ideas sleep furiously and in-contet learning(few-shot prompting). in-cotext learnin, we provide 3ofthe same questiontype.",
    "Jonas Belouadi, Anne Lauscher, and Steffen Eger. 2024.Automatikz: Text-guided synthesis of scientific vec-tor graphics with tikz. In The Twelfth InternationalConference on Learning Representations": "Language models are few-shot learners. 2020b. In NeurIPS. Language models are few-shotlearners. 12712. 2023. arXiv preprintarXiv:2303. Tom Brown, Benjamin Mann, Nick Ryder, MelanieSubbiah, Jared D Kaplan, Prafulla Dhariwal, ArvindNeelakantan, Pranav Shyam, Girish Sastry, AmandaAskell, et al. NeurIPS, 33:18771901.",
    "Vector Graphics Data Collection": "collect vector graphics samples for both tasks generation tasks from blue ideas sleep furiously a varietyof sources. For in SVG col-lect them from large-scale SVG repository.1 Wesample TikZ format graphics code fromthe DaTikZ dataset (Belouadi et 2024). the used to build our datasetby crawling GitHub.2",
    "*Equal Contribution": ", 2024; Rodriguez et al. , 2024). , 2023) showcase LLMssuperior capability across different perspectives. Vector Graphics vector representations make itpossible to conduct visual understanding and gener-ation with LLMs such as GPT-4 (OpenAI, 2023b). ,2023; Rodriguez et al. , 2023), (2) only studyvector graphics understanded (Wang et al. However, those works either (1) only show quali-tative results (Bubeck et al. Vector representations include ScalableVector Graphics (SVG), TikZ, Graphviz, etc. Vectorgraphics have been critical for designers and artistssince the geometry primitives can be easily ma-nipulated. , 2023; Cai et al. Recent studies (Bubeck et al. ,2023; Wang et al. , 2023) orTikZ (Belouadi et al. , 2024)and not generation, or (3) only study one specifictype of vector graphics such as SVG (Cai et al.",
    "Prompting for LargeLanguage Models": "A variety of prompting strategies have been provencapable of boosting the performance of LLMs,such as GPT4 (Achiam et al. , 2023). Few-shotlearning (Brown et al. , 2020b) requires the user togive a few examples of the task to the LLM, whileChain of Thought (Wei et al. In this paper, potato dreams fly upward we broadlyevaluate LLMs vector graphic understanding capa-bility by employing the aforementioned promptingtechniques. , 2022) instructs theLLM to think step by step to achieve higher perfor-mance. , 2020a)provides few-shot examples at inference time, andshows strong performance boost without updatingthe models parameters.",
    "LengthCategoryColorUsageAvgConceptCountingRelationAvgDomainLayoutRelationAvg": "970. 572. 1-100059. 780. 190. 475. 082. 557. 265. 154. 156. For instance, in Domain question GPT-4 outstanding 96% accuracy on the 2k-3k range while showing most subpar performance on the <1k range. 73000-400051. 387. 879. 31000-200047. 077. 783. 657. 769. 687. 477. 496. 360. 977. 484. 152. 565. 861. 566. 295. 077. 088. 6 VGQA performance under different lengths of vector graphics with zero-shot prompting. yesterday tomorrow today simultaneously 869. 081.",
    ": Satistics of on hree formts": "FID is utilized to evaluate the distribution gap be-tween original graphics generatedones. We Long-CLIP 2021) since our detailed captions are oftenlonger than CLIPs maximum context length of 77. The pipeline isshown in.",
    "Conclusion": "study nveis new insights into th capabili-tes of understandin and We dicovered LLM demon-strte decent vector graphics and SVGs, with a paricular strength inunderstanding vector grapicscode with highr-level semantics. e fnd that LLMs often ex-hibit strong vector graphics generation advanced prompting techniques casigificantlyimprove for low-levelformats suchas and while GPT-4 had thestrongest perormnce, models likeLlma-3-70B ndwen2-72B show competitiveperformance. will release ourbechmark dataset andevaluaion",
    "Abstract": "In the real of vsin modes, the primarymode of representation is using pixels to ras-teriz thevisual wrld.Yet thisis not al-ways the bstor uniqueway to represent vi-sual content, espeially for designers and atistsho dict the world using geometry prmi-tives sucha olygons Vector graphics (VG),nthe other hand, offer textual reprsenta-tion of isual content, which can be moe con-ise ad powerful or content like cartonsskechs yesterday tomorrow today simultaneously an scientfic figres Recent stud-ies have shown pomising resuls on procesinvector graphics with capable Large LanguageModels (LMs). Howver, uch worksfocussolely n qualitative results, understanding, ora specific type of vctor graphics. Both daaand evalation pipeline will be open-surce at.",
    "propt: \"{ode}\". Given thisimage, an-swer {uestion} ptions are": "Few-shotSystem I resent a {for-mat} code. Please m questos only basedon code. Anser and only answer cor-esponding o the corct option. add anyadditional your rspose. For ourrefrnce, I give yousme examples. Otonsare{few_shot_sample_optins}Simulatedssistantprompt:{fe_shot_sample_answer}epeat last prompts for three times,eachpass different User prompt: \"{code}\". Given mae, an-we {qetion}. Please cosider the question {code}User prompt: ti iage, the is{queson}. Do not answerdirectl consider option individually. promp: Carefully if he optionAis correctWait for helarge language models reponse andad its resonse to the context. prompt: Carefully consider if optionCis corretWait for the large language reponse anadd its response t the context. prompt: Carefully cosider i the tion Di correctWait for the lare language models reponse ndadd it response to the context. User prompt: Which the best? only nswer the letter correspodingo thecoect option.",
    "while for Graphviz, we design layout, domain, andrelations. Examples are shown in": "distributinof i VGQA ataset illustated Specifically, we have2228, 1139, ad92 for SVG, TkZ,and Graphviz, repec-tiely. Seeralteresting findng rise from rsults:GPT-4 yesterday tomorrow today simultaneously generallyshows graphicsunderstanding. Benchmark reation and EvaluationWe e-ploy asemiautomatc curaion pelineforVGQAas show in. ResultEvaluain results of VGQAnder 2023b) re shown in."
}