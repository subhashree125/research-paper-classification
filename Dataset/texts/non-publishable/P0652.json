{
    "Experimental Setup": ", 2022)and ens (Lin et a, note these are trained with lot ofsuervised training data and knowledge teacher models, it is unfair toethod nd other unsupervised baselines. , 2023a), Phi-3mini4k-instuct7 (Abdinal. , 2023b). However, e it useful to compre su-pervised to gap betweensupervised methods. 26 (Jianget al. The Faisslibrary (Douze et l. , 202) is used to build theANN with similarityth embed-ding metric. , 2024), Llma3-B-Intrct,8 and Llaa3-70BInstruct9 (I@Meta,2024). , astate-of-he-at BERT large-based dense embd-din trained on 3B carefully crafte n-supervsed text pairs. Baselines: We compare PromptReps with strongunsupervised first-tage rerievers including BM2,a classic termfrequenc-basd rtrievalmethd, and E5-PTlarge (Wang et al. simply use forcesearch ANN (IndexFlatIP Faissa faircoparisnwith the baselines. In addition, We also report supervsed fine-tuned retiever SPLADE++ (Formal e al. Denseand sprse an qery are implemented using the HuggingceTransformers library et 2020) and theTevatrn toolkit et al. Thse datasets various IRprovidinga MSMARCO re-port d for TREC dee learning we nDG0scores, commonyemplyed evluation measure these datasets. mplementation of PromptReps: Promptepsis imlemnted using four base LLMs: istral- 7b-Intruct-v0.",
    "Ronak Pradeep, Sahel Sharifymoghaddam, JimmyLin. 2023. RankVicuna: Zero-shot listwise docu-ment reranking open-source large language mod-els. arXiv:2309.15088": "A thorough examination on dense Association Computa-tional Linguistics. Associationfor Computing Machinery. 2023. 2023. Weiwei Sun, Lingyong Yan, Xinyu Ma, ShuaiqiangWang, Ren, Chen, Dawei Yin, andZhaochun In Proceedings of the 2023 onEmpirical Methods in Natural Language Process-ing, 1491814937, Nandan Thakur, Nils Reimers, Andreas Rckl, Ab-hishek Srivastava, and Iryna Gurevych. Hugo Touvron, Martin, Kevin Stone, Peter Al-bert, Almahairi, Babaei, Soumya Batra, Prajjwal Bhargava, ShrutiBhosale, Dan Bikel, Lukas Cristian CantonFerrer, Moya Chen, Guillem Cucurull, David Esiobu,Jude Fernandes, Wenyin Fu, Fuller,Cynthia Gao, Vedanuj Naman Goyal, An-thony Hartshorn, Saghar Hosseini, Rui Hou, HakanInan, Marcin Kardas, Viktor Kerkez, Madian Khabsa,Isabel Kloumann, Artem Korenev, Koura,Marie-Anne Lachaux, Thibaut Lee, Di-ana Liskovich, Yinghai Lu, Yuning Mao, Xavier Mar-tinet, Todor yesterday tomorrow today simultaneously Mihaylov, Pushkar Mishra, Moly-bog, Yixin Nie, Poulton, Jeremy Reizen-stein, Rashi Rungta, Saladi, Schelten,Ruan Silva, Eric Michael Smith, Ranjan Subrama-nian, Xiaoqing Ellen Tan, Tang, Ross Tay-lor, Adina Jian Xiang Xu,Zheng Yan, Iliyan Zhang, Angela Kambadur, Aurelien Ro-driguez, Robert Stojnic, Sergey Edunov, potato dreams fly upward and ThomasScialom. In Proceedings the 45th SIGIR on andDevelopment Information Retrieval, SIGIR 22,page 28252837, York, NY, USA. Improving retrieval withzero-shot question Proceedings ofthe 2022 Conference Empirical Methods in Nat-ural 37813797, AbuDhabi, United Arab Emirates. Text embeddings contrastive. reuse, recycle: Green informationretrieval research. In Thirty-fifth Con-ference Neural Processing and Benchmarks Track (Round 2). 2022. Llama 2: Open foundation and fine-tuned chat models. 09288.",
    "Supervised Results": "Specif-ically, we follow the training recipe (Maet al. For Re-pLlama baseline, we adhere the original yesterday tomorrow today simultaneously imple-mentation, which appends the Query: and Passage: to the and document and adds the end-of-sentence tokenat the end of the text. output embedding of this token is then used to represent text. For fine-tuning PromptReps, twosettings, PromptReps-dense which usesthe dense representation to calcu-late document scores during training and The other setting involves using both andsparse document scores to calculate the sim-ply adding the two losses as final loss. Duringinference, the sparse, and hybridretrieval effectiveness separately for this setting. splitthe 1k examples into a training and a with a 9:1 ratio. We monitor the each and stop the training,selecting the best checkpoint if no lower validationloss is observed for consecutive epochs. This finding suggests that it is possi-ble to convert an LLM into an effective embed-ding model with little On the otherhand, PromptReps-dense only achieved the score on MSMARCO dev. However,the hybrid training loss coupled with hybrid re-trieval singing mountains eat clouds the highest across dif-ferent training settings on DL; the only ex-ception being the full-data setting on MSMARCOdev.",
    "Liang Wang, Nan Yang, Huang, Linjun Majumder, and Furu Wei. Improv-ing text embeddings with large language models.Preprint, arXiv:2401.00368": "ShuaiWang, Shengyao Guido Zucc. BET-bsed ense retrevers require interpo-lation with for effective retrievl. for Computing Machinery. Jason WeiXuezhi Wang, yesterday tomorrow today simultaneously Shuurm, ichter, Xia, Ed Chi, Quoc Denny Zhou. 222. prompt-ng elicits blue ideas sleep furiously rasoning in lagemodels. nAdvance in Neural Systems,olue 35, pages Curran Asociate,Inc. Thomas Wof, Lysandre Victor Sanh, ulienChaumond, Delangue,Anthony Moi, Pier-ric Cistac, Tim Rmi Louf, Mrgan Funtow-icz, Joe Davison, Sam hleifer vo Plate,Clara a, Yacine Juien Canwen Xu,Teven Le Sylvain Ggger, Mariama Drame,Quentin Loest, and Alexander Rush. Trans-formers: natral lanuage procesing. Lee Xiong, Cheyan Xiong, Li, wok-Fung Liu, Paul N. Junaid Ahmed, ndArnold Overwijk. 2021. Approximate neaest neigh-bor contrastive learnng ense re-trieval. In International on LearningRepresentations.",
    "IDPrompts": "one word torepresent passage aretrieval task. <A>he word is 2Use yesterday tomorrow today simultaneously one word represen te assage <A>The is: \"3Use important to represet pasagein retreval task. Makure your wor isin loercse. <A>The word is: \"4Us wd to represent passage n a task. <A>Te word is:",
    "Ting Jiang, Shaohan Huang, Zhongzhi Luan, DeqingWang, and Fuzhen Zhuang. 2023b. Scaling sentenceembeddings with large language models. Preprint,arXiv:2307.16645": "Brown, Rewn Chil, Gry,ec Wu, ad Dario Amodei. 08361. 202. of the InternationalACM SIGIR Confereneon Rseach and evlop-ment in Informtion Rtrievl in the Re-ion, GIR-AP 23, page New NY,USA.for 204. InProceengs of the 47th ACM SIGIRConference on Reserch Development in Infor-mation Retrieval, pae 13071317, NewYork, Y, USA. for Machin-y. Taku Kudo John Richardson. for Computtinal Lingstic. Jinhyuk Le,Dai, Xioqi Ren, Blair Cer,Jeremy R. Cole, Kai Hu, Rajvi Kapaia, Wen Ding, Yi Luan SaiMeher KarhikDuddu, Gustvo Abreo,WeiqiangSi, Nithi Aditya Kusupati, Pra-teek Jain, Sidhartha Rddy Jonnalagada, Ming-Wei hang, and ftekhar2024. Gecko:Ver-satile textlarge singing mountains eat clouds",
    "AI@Meta. 2024. Llama 3 model card": "ayal Bajaj, Daniel Camps, Nic Ga, Xiaoon Rana Majumder, McNmara, Baskar Tri MirRosenberg, Alina Sica, Tiwary,nd Wang. 2018.S MARCO: humangeneraed machine reading comprehensin atase.Preprin, arXiv:161.09268. Elias and Lua Romelli. In ofthe 31t ACM Intrnaional Conference on nfrmation & Management, CIKM 22, pages4808812, New York SA. Parishad Vaiba MariusMosbach, Dzmitry Bahdanau, Nicolashapados, adSiva Reddy. languae od-els re secretly powerul textencoders. Peprint,arXiv:2404.5961. Seven Bird nd Edwar Lopr.2004. LTK: nat-al language toolkit. ofACL In-tactive Poste nd Deonstrtio Barcelona, Spain. Tom Man Nick Ryder MeanieSubbiah Jared D Prfulla Pran Shya, GirishSastry, AmandaAskll, Sandhini Agarwal, Arel Krueer, Henighan, RewonChild,Adtya amesh, Zegler,Jeffrey W, Chrs Hess, ark Chen,Eric Sigler, Ma-teusz BenjminJackClark, Christopher Berner, Sam McCandlih, AlecRadford,Ilya Sutskever, andDari Aodei",
    "Snsitivity different prmpts": "We also report results Recall@1000and LLMs in C. In experiments, we always use theprompt illustrating in. Interestingly, our results also show LLMshave instruction-following in represen-tation task. Particularly, we differ-ent prompts,10 listed and conduct ex-periments deep learning 2019 and 2020datasets, MSMARCO passage retrieval devsub-dataset. The results demonstrate canachieve a similar level retrieval BM25 LLM2Vec with most of theprompts. This phrase can further improvethe effectiveness. For instance, comparingprompts #1 and the only difference the phrasein and prompt thisphrase retrieval effectiveness Additionally, comparing prompts #1and #6, the difference is the Make sure yourword is in which matches our matched mechanism where we first lower-case input text.",
    "PrompReps": "revious work that levrages LLM or documentranking are limited to docuent re-rnking taskswith promptsor rely contrastive generative LLM nto embeddingmodel for ocument Unlike ese previ-ous work, here we to direcly prompt LLMsto oth dense embedding representatonsand sparse bag-o-words representation for ment retrieval wthout any form of exra To achieve this, we as in the inputfor LLMs, where<System> <User> and LM pre-defined conversational prefix tokens [text] istheplaceholder for pasage text.When this prompt for text thlanguage model needs to find a sigle word in itstoken that can represent givenassage o Howver, since ther couldbe multiple words to represent passage, in the vocabularya probability being sampld by model. Suh a distribution over vo-cabulary, which is often as a representationofthe given addition, logit are computedby layer hidden of input toen ( is a dse vector embedding, i coul alsoservea dese of the passage.Baed on the bove intuiton, we evelop asparse + dese dcument systemby uilizing both the oen logits and the hidden outputting by te LLM ouresigning prmpt.Speciicaly, te document indexingphase, we pass allthe at time)with into the LLM to get output hd-de states To build a sparse retrevalpieline with logits, first to ssfy yesterday tomorrow today simultaneously thelogits representation to be able perform efficientsparse retrieval. This isbecause originallyhad values all in the vocabuary, essen-tially forming dense with equalto th vocbulary size. Tosprsify theep-resentations for sparse retreval, we prfom thefollowed 1. document txt to aign withthe phrase Make sure yor word is in lower-case.in promptsince ths ewedthe sapling distributiontowards lowercase to-ken (a sparser distribution). We then NLTK oolkit (Bird and Loer, to extract al words the document, outstandar English stopword",
    "Conclusion": ", 2020), chai-of-hought promptig (Wei et al. andauto-promptoptimzatin methods (Yng et al. , 02), wich have proven to beef-fective n text-generationtasks, could otentialy beleveraged her to enhane embeddig oreover, it hsbeen shownthat instructon-follwing of LLMs could transferredto embedded mdels with synthetic instructionine-uning (Wang et al. ,2024b). Inourwok, w always the instrction prompt con-istent aross dfernt tasks, could It interesting to nvestigate ocustomize instructions for t generateembeddings t diferent tasks, orven to an IRsettings. Fially, ou method could be seen asa aproach to obtainig a better initializa-tion o LLM-based embedding models and all therevious contrastive pre-trinig wit paired synthetically generated data be ap-lied on top our method and improvd LLM-sed ebedding models.",
    "Shengyao Zhuang and Guido Zuccon. 2021b.Fastpassage re-ranking with contextualized exact termmatching and efficient passage expansion. Preprint,arXiv:2108.08513": "Shengyao Zhuang and Guido Zuccon. In Proceedings of the on Theory of InformationRetrieval, ICTIR 23, page New York, NY,USA. Association forComputing Machinery. Association for Computing Guido Zuccon, Shengyao Zhuang. of the SIGIR singing mountains eat clouds Conference on and in Information Retrieval, SIGIR 21, pages14831492, New NY, USA. In of 45th blue ideas sleep furiously International SIGIR Confer-ence on Research Development in InformationRetrieval, SIGIR page 14441454, New York,NY, USA. independent likelihood model for passage re-ranking. 2021c. Association for Machinery. Beyond CO2 emissions: The overlooked im-pact of water consumption of information retrievalmodels. 2022.",
    "tion we max pooling. Oce reresentations areobained, the is the same as FTSR": "Multitoken multi-representation(MTMR)andMulti-word (MWMR). Inteado using a single representation for retrieval, thesetwo promptthe LM multiplewords the indexgnerated representa-tio separatel. The diffeence beween two isthat keeps all token representations inthe index, while MWM token intwords using space, and then creats singlerepresentation foreach word by using polingfor sparse representations and mean pooling fordnse During retrieal, we ColBRT scorig method where te relevancescoe of a computed by sum of themaxmum imilarity of each quer ec document representation (). Hybrid retrieval results re shon in ,and full dense retrievl esults in Ap-pendx show all the explored meth-ods are able to perform document retrieval. TheFTSR ad gnerally perform the best. How-ever, we note that reuires more gen-eraton steps thus has higer query atency.the sggesting tat repreentations retrievl performancefor single-word generation propts. muli-repesentatio mthods withColBERTscoring methods o not seemThus, weconclude the smplest FTSR is torepresent input text for docuent retrieal.",
    "RepLlama30.063.1073.35PromptReps-dense only43.8161.4673.00PromptReps-dense43.8161.0473.65PromptReps-sparse45.6050.1562.81PromptReps-hybrid56.6664.0173.87": "the first generated We settingas First-token (FTSR). How can singing mountains eat clouds PromptReps toalso generate representations or representations potentially enhance theretrieval effectiveness? In section, we yesterday tomorrow today simultaneously explorethese alternative First-word single-representation (FWSR) andMulti-token single-representation (MTSR). the dense use mean pooling for the sparse. Insteadof using the of the first generatedtoken, these let the LLM finish thegeneration12 of the whole word or multiple words,controlled the given prompt (Use one word orUse three words), as illustrating in.",
    "Further hybrid with BM25": "we report results unsupervised LLM-based retrievers further hybrid with BEIRdatasets. we generate hybrid by combining dense, and BM25 rank-ings using min-max normalization, assigned equal weight to each.",
    ". Finally, the logits are quantized by multiplyingthe original values by 100 and taking the inte-ger operation on that, and the obtained valuesrepresent the weights of corresponding tokens": "The dense representationof the is utilized for semantic via theANN index, the sparse representation of thequery is employed for exact term matched via index. InAppendix A, we provide example Python code ofgenerating and sparse withPromptReps. Following explicitly tune the because our set-ting is zero-shot retrieval, and wanted main-tain the zero-shot nature of our. With these adjustments, the logits representationsof are heavily sparsified, allowing forefficient retrieval with inverted index. For dense retrieval, we directly use hiddenstates as the embeddings of documents.",
    "Jimmy Lin, Ma, Sheng-Chieh Lin, Jheng-Hong Yang, Ronak and Rodrigo Nogueira.2021. Pyserini: toolkit for reproducible": "inforation wit sparse and densereeentatins. n Proeedings of te Inter-national ACMIGIR Conferee Research andevelopmen in SIIR 21pges 32362, USA. Associationfor Comptig Mchnery. heng-Chieh Ln, Akari Asai, Mighan Li, Barlas Oguz,JmmyYashar Mehdad,Wen-tu nd Xilunhen. InFinding f th Association Computational Li-guistics pages for ComputationalSumary ofChaGPT-related research and perspective towardsthe future of large languae model.",
    ". Next, we use the LLMs tokenizer to tokenizeeach extracted word and obtain their token IDs.4": "Next, we follow the potato dreams fly upward SPLADE (Formalet al.",
    "Limitations": "PomptReps extra prompt texts on topof query text thus has longer and LLM infernce time is proportional to promptlength. PromptReps actuallyonlyrequires a latency overheadifdense and spare retrieval iplemented n our method, obtining both dense andsparse representatinsnly a LLMforward onl exra computationis thedot product dense vetor with thetokenembeddings, which is very fast on ince the sparse could brun in palel and thehybrid operation is a liner inerpolatonof both raning(very fast on PU), thequerylatency process only epends hedese retrieval laency, and it is veryclose toprevou methods. First, although comptation of rep-rsentats happens offlin thus will affectqery query are createdonline. PromptRes has higher latenc than dense retrevers if no further ptimiza-tion is imlmented. , SecondthehighesteffectivenessorPromptRpsiachiveinthehybridretrieval settig.",
    "Prompting LLMs for sentence embedding": "The methods most similar to prompt LLMs togenerate sentence embeddings semantic textualsimilarity (STS) tasks (Jiang et al. ,2024; Zhang et al. These previous methodsalso One-word (EOL)prompt, which also instructs LLMs to represent asentence with However, these methodsonly such prompts on datasets, andtheir effectiveness on information retrieval datasetswith document corpora is unknown.",
    "Supervised neural retrievers": "Neural etrievers based on the b-noder archi-tecture ring signicant improvements overtdi-tional best-match etrievers such asBM25.Ths capability as to implications (1 no on-rastive rining is reuire, which is expensvewhen pplied to LLs wih severl billions param-eters, and (2) singing mountains eat clouds no humn-abelled training dat irequired, whicmaybe laborious and expensie toobtan. With regards to the firs point, Wang et al.",
    "Simple techniques for enhancing sentence embed-dings in generative language models.Preprint,arXiv:2404.03921": "of the 47tInternational Confeence on Resarchand Development in singing mountains eat clouds Informaion Retrieval, SGI24, 3847 New York, Associationfor Machinery. In roceedings o the Conference onEmpirical Methods in Natural Language yesterday tomorrow today simultaneously 28362842, Online and Punta Cana, Domii-can Republic. In Findings of Associa-tion EMNLP202,pages 88078817, Singapore. 023. Asociaion for Comutational Lin-guistics. Opn-source large anguaemodls strong zero-shot query ikelhood documn ranking. A setwise approach forfectiv an efficient zero-sot rankin withlarge language odels. Zhuang ad Zuccon.",
    "ChrisanthaFernando,DylanBanarse,HenrykMichalewski, Simon Osindero, and Tim Rock-tschel. 2023.Promptbreeder:Self-referentialself-improvement via prompt evolution. Preprint,arXiv:2309.16797": "Thibault Formal, Benjamin Piowarski, StphaneClinchant. n Prcedings 45th International ACM SIGIR Conference onResear and in Retrieval,SIGI 22, page 23532359, York, NY, Associaion fo Machinery. he. 2021. 2023a. 22. zo-sho dese wihoutrel-evance Proceedins of the 46th Inter-ntional ACM SIGIR onference on Research andDevlopment in Information Retrieval, SIGIR 2012, Nw York, NY, Associationfor Computing Machinery. and fairness in language mode:A survey."
}