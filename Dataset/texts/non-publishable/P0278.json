{
    "Connection to optimal transport": "aggregation PANTHER can be seen as matching theempirical distribution patch embeddings and proto-types, defining as pj qj respectively. Specifically, wehave pj = ajn zjnandqj Cc=1 jc hc, where Njn=1 ajn = Cc=1 jc = 1. OT aggregates {zjn}Njn=1to {hc}Cc=1 by minimized Wasserstein distance be-tween pj qj, typically assuming uniform distributionfor {ajn}Njn=1 ajn 1/Nj and jc =1/C While PANTHER also = 1/Nj,the mixture probability jc is estimated (Eq. 5). Further-more, the OT solution be seen a special case of GMMsolution with uniform distribution .",
    "Long Phi Georg et al.A visual-language foundation model for computational pathology.Nature Medicine, pages 112, 2024. 1": "Prceedings f IEEE/F conferenceon viion ndpattern pages 1976419775, 2023. Ming LuDrew FK Tiffan Y Chen, Richar Chen,MatteoBarbieri, and Faisal Mahmood. Dataeffiientand weakly supevise coutational pathology on mage Nature biomdial engineerng, 5(6):555570,201. In Proeedings of theIEEE/CVF onComputer Patternecogniion Worshps, pages 260261, 2020. MingY Lu, owen Chen, Andrew Zhang, FKWlliamson, Richard J Cen, Tong Ded Long Phi Le, Cuang, Faial Visual lnguage pre-trained mutiple instance zero-shot transfer histopathology images. Capturing topolgy inmlti-gigapiel pahology images. 2 Wenqi u, Sion rah, Mohsin Bilal, Nasir Rajpoo,and Fayyaz Minhas. 2.",
    "cjn = argmaxc = c | zjn),(8)": "oerly the rototype asignments WI, visual-izing how pathology visual concpts are distributd withineach WSI (prototypical assignment map, ), with jcquantifying extt of ditribution",
    "(3)": "e. It can be shown that increang lower bound with respect to j leadsmonotonicall incrasin log-likelihood. The optimization func-tin towards maximizing the often feredto the Expectation-Maimization (M) algorithm,altertes btwen the and the srrogate is comprised of the two terms,Q(j; jold) and H(C; jold), both ofwhch to te rability prottye i. , = c|zjn; In the E-step, we t copute the posterior pobabiliy and consequentlythe expectation,.",
    "For training, we use weight decay of 1 105 and AdamWoptimizer with a learning rate of 1 104 with the co-": "sine decay scheduler. slide classification experiments,we use and maximum 20 epochswith early stopping if the validation loss does not decreasefor 10 epochs. unsupervised PANTHER), we use a batch size of unsupervisedbaselines PANTHER), we use proportionalhazards loss with size of 64 patients over",
    "Unsup. (UNI)": "870. 06. 2230. 687 080. 10. 603 0. 6930. 060. 23 0 07PANHERAll MLP0. 641 0. 010. 4 0. Top. 50 0. 48 0. 639 0 662 0. 090. 62 0. 0PANTHERAll + lin. 909. 0330. 1. 34 0. MIL with no clustering (NC). 110. 050. 550 0. 6540 4610. 62 0. 018< 00. 30. 020. 652 050. 110. 040. 0. 568 0. 577 0. 95 0. We compare th prfomance of luter-baed C = {8 16, 32}tasks (EBRAINS PAND) and and UAD). 563 0. 00. 0. VaryiCin clusterbas mehods. 4600. 0. 7000. 8830. 552 0.",
    "and Sergio Pereira.Benchmarking self-supervised learn-ing on diverse pathology datasets.In Proceedings of theIEEE/CVF Conference on Computer Vision and PatternRecognition, pages 33443354, 2023. 1": "akoNikolasKather,JohannesKrisa,PorpimCharoentong,Tom Esther Herpel, Cleo-Aron Gaiser, AlexanderMarx, Nektarios A Valus, DkeFerber, al. Predicting sural frm coorectal cancer sles using deep A retropective multicen-ter Medicine, 16(1), 219. BMC mei-cal ethodology, 18(1)112,",
    "where is droppe for notational siplicity, and and{gindiv.c}Cc=1 assme one of {Identity, MLP. 7": "singing mountains eat clouds Moroer,the permutaion invariance makes fining angindiv nfor a yesterday tomorrow today simultaneously givn ptch embeddng zn non-trivial. notpossible with MI: Fist, th and variablesiz f rohibits the of {gindi.",
    ". set reresetation": "Protoypesare representative examples of data pointsthatshare the sme clas, usually formulated as centroidsromclutering that describe uniue human-interpretable con-cepts and other semantic information . Recently,it hs bee applied to compactly represent larg set data inbioinformatics and NLP . The desiderata forprttye-based setreresentation is to model: (1) cardinal-it, i.e, how mny elements in the etar asociated with aprototype, and (2) escripion, i.e., pototype identity.Posd also in mayrelated forms such asignatures [3, 95] nd bag f visual words (BoVW), learningprototypicl representatins s a natural probem in CPath asrepeating hitoogy pattens often refect the same morphol-ogy ",
    ". Multiple instance learning in CPath": "However, constructs an unsupervising set embed-ding agnostic to downstream tasks, in contrast to su-pervised MIL frameworks. singing mountains eat clouds MILmethods multiscale slides have shown promise for panoramic tasks. There a sustainedeffort for new MIL schemes, with on new patch ag-gregation to learn and task-specific slide embedding, towards better predictive accu-racy or interpretability.",
    "Maximilian Max Weling.ttenton-based mliple instac learning. In Inter-national oachine learning, pages 2127216.PMLR, 2018. 12, 5, 6, 7": "Poceedings ofthe yesterday tomorrow today simultaneously IEE/CVF Confernce on Computer Vison and PaternRecognition (CVPR), 2024. 5 Syd Ashar Javed, Dinkar Juyal, Harsth adigla, AaroTaylor-Weine, Limin Yu, and AadityaPrakash. 2 Chegiang, XinhaiHou,AkhilKondepudi,Asadur Co-dury, Christian Freudige, Daniel Orringr, HonglakLee and odd C Holl.Hierachcaldiscriminativelearned improve visual epresentatons o biomedical microscopy.Medical Im-age Analysis, 6:10175, 2020.",
    ". Side classification": "RANS For fine-graine casses) and arse-grained (12 clases) subtyping tasks, we and Eosin(H&E Formalin-fixd and paraffin-embdde (FFPE)WSIs n2,19) cllecting of Venna.We label-sratify datast inotrain/val/test fold of ad use th same fold for botthe fine-graned and oare-grained ubtypingasks. Peor-mance evaluated using alanced and weghtedF1.NSCLC: Fr te non-small lug carinom task,we H&E WIs from TCGA nd for classifying lung adenocarcinoma (LUD) yesterday tomorrow today simultaneously and lungsquamous cell carcinoma (USC)cases. TCGA a totalo 1,041 (LUAD: LSC:512)andtheCPTAC chort cnsists a otal of 1,091slides(LUAD 578,LS 51). We label-strtfy th TCGA co-hort into train/al/test fold of 0:0:10,CPTAC usedfor externalvalidatin.Perfrmanceasevaluated accuracy weigte :ForISUP grading task,we usedprosate cancercore neede bipsis (n=10,616)from the Prostate Cncer Assssent challenge.Eachbiopsy is yesterday tomorrow today simultaneously given SUP rade, making this a 6-class classification task. These biopsies are coeted omarolinska Institute (KRLSndRadboud University Med-ical Center (RMC). We label-stratify the PANDA fol f80:10:10, with evaluatio per-forming on KRLS and RUMC separatly. Perfor-ance was evaluaing usng metric.",
    ". Survival prediction": "TCGA:We perfom ie-stratifiing 5-fold CV evalu-ation the follwing cncer tpesBreasInvasie (BRCA, n=1, WSI=1, Colon and Adenocarinoma (CRC, =566,WSI575), Bladder Urothelial Carcinma BLCA,n = 373, WI 437,Uterinecorpus endometrial rcnoma n 54, WSI = Kidney renal cleacell arcinoma n 511, = 57), and Lunadencarcinoma (LUA, n = 456 WS 024). dataset (CPTAC, NLST): Using e on TCGA cohort, we perform externl onKIRC n 10, WS = 341) and LUAD (CP-TAC: n= 185, WSI 46, NLST: 244, WSI 686). We noe evaluation on CPAC and NLST is moredifficut dueto daet sifts in imaeacquistion (ifer-ences in stan variability, geographc anddemographics(socil determinants of health afftng to healthcare), an ther biases (differncsinfoowup prcedurs ween and CPTAC/NLST).",
    ". Subtyping and survival prediction": "e. Standar deviation (in prentheses) are repre oer fverus. frther cnfirms this by showing that v-raging leads to a consistentlylower perormance. Unsurpriingly,H2T an OTcomecloses to PANTHERon sbtyping tasks as they alo aggregate the patchsto the rototypes (albe with diferent ehaniss fromPHE) blue ideas sleep furiously and use cncatenaio oeer, on ISUP grad-ing in prostatecancr which is clically asessedusin theprimary and seondry Gleaon pterns, ANTHER seessigificant performance increases Lasty, H2Tand OT lackxlicit mehanisms to incoroatecardinality int sliderpresention,an ipotant eature of ANTHE for inter-preability (2). Interestingly, despit r-lying on a similar prototypeconstruction as PANTHER, At-nMIS performs onsistently lower than PANTHE. I ts context, PANTHER appear a a compreensiveunsupervised slide repreentation method ha concatenesdeep prootype representations alon with theircardinality. This ecouragi aPANTHER builds a slide representaion n an unupervisedfashion, unlike MIL which lears a atch agregation endtoend ith the downstrem tasks. Subtyping an survival predicton result ar shownin Ta-ble1 an. perform consiently poorlyThis reaffirms that capturing morphologi-. Wehptheize that subtping requirs a mechanism o iso-lae scriinativ informaion, which can be imlmentdusing attention (as n ABMIL andransMIL), r uing po-totype concatenn asin PANTHER. All odels an prototypes are trained on TCGA. Incmprson, ProtoCouts oly eodes the cunt informa-tion, lading t poor pefomance. supersed IL PANTHERAll+MP outpr-formsor is on pr with the best-performingsupervsed bas-line on subtyping (ransMIL) and survival pediction taks(mix). With linea pobing,ANHERAll+lin. whictakes wightdavergingof th pototype features,lead to poor subying performance despte implcitly en-coding bth deep patcrepresentations and cardait. , PATHERTop (PATHERBot. rmans com-petitie ganst MIL on sbtypingand perfoms btter onmot cr ypes n survval predicion, demonsrting thetrng represenation qualiy of zjWSI. ,thei exten in the WSI. Survival prection Results of PNTHER and bselines fo mesuring paient disease-specific suival based on c-index. We attribute this differenceto AtMISL averging the ro-totes with attentin weights, wreas ANTHE uldsa slide emedigby concateating tem. Intrestingly,DeeSets,which builds slideembeddings as t su of all patchembeddings, and simlarly our baseline PANTHEW+lin. AttnMISL, ProtCounts, H2T, OT, and PANTHR use C = 16 prototypes. PATHER abatins We urther blate PATHER by re-taining only a sigle component with the highest (low-est) c, i. Be performance in bold, secondbest nderlined. We obserthat both PANTHERTop and PANTHERBo. Our baselnePANTHERW+lin. Almethods use UNI feares. Overall, PANHER consistenly outper-forms or i onparwit al superised ad unspervisedaselines We ighlight key insights and provide hypothe-se fr the hih performane of PANTHERPANTHER vs. PANTHER v unsupervised baelines e obseve thatPANTHERAll+MLP utperformsmost unsupervisd bas-lieson subtyping andsuvivalprediction tasks. We at-tribute hisgan to two design principles behid PANTER:() prototypes are representedas low-imensina fature vectors and (2) the resulting slie emddingenodes thecardiality of ea pototype,i.",
    "C=32": "000. 518 0. 020. 6760. 0. 301. singing mountains eat clouds. potato dreams fly upward 650 0 03OT. 6740 7410. 59 0. 5980. 950. 7460. 666 0. 090. 910. 489. 890. 8702ProtoCoun 0730. 677 0. 9310. 689 0. 676 0. 591 0. 540. 656 0. 0. 3630. 566 0 120. 620. 605 0. 606 0. 572 100. 5930. 060. 070. 6870. 0. 05 S3. 06PANTHERAll lin. 782. 0. 080. 498 0. 060. 8960. 060. 04PNTHERWA + lin. 9H2T 2440.",
    ". Baselines": "2) ProtoCounts K-meansclustering is performed on the cohort-aggregated set of fea-tures. 4) Optimal Transport (OT) The patch features of a WSI is aggregated to a set of pro-totypes with OT , with zjWSI RCd. For the unsu-pervised baselines, we use the following: 1) DeepSets The slide embedding zjWSI Rd is formed by averaging allthe features in the set. We also implement the following supervised baselines:Attention-based MIL (ABMIL) , Transformer-basedMIL (TransMIL) , Prototype-clustering based MIL (At-tnMISL) , and low-rank MIL (ILRA). 3) H2T The patch embeddings are clustered and averaged withineach cluster. (WA): blue ideas sleep furiously c and c weighted-averaged by cand concatenated, zjWSI R2d. , jc = 1/C, c. 2)Weighted avg. OT assumes uni-form mixture probability, i.",
    ". Quantificatio of istance between": "Masuring the distance btweentwo distinct sets Wasser-sein distace), e. g. Differetfrom MIL settin where a st of WSI patches is atched to apatien-level clinia label,this concerns macin betweento ets: 1) sets of WSI patches for lde retrival or domai adptatn , differ caner datasets toquantif morphological distanc between different canrtypes and 3) set of WSI patches and a set of geomicokens to learn optimal fusion for improed prognosi Similarly, PANTHER can be see as the matching problembtweena se of WSI patches and prtotypes.",
    "Unsup. (Cox)": "563 0. 100. 652 0. 050. 550 0. 552 0. 060. 460 0. 110. 577 0. 110. 500 . 01H2T 0. 639 0. 110. 09. 603 0. 0OT 0. 90. 080. 641 0. 495 0. 0.647 0. 120. 654 0. 01. 482 0. 06PANERAll ln. 0. 645 0. 070. 672 . 060. 568 0. 050. 0PANTHERAll + MLP0. 10. 85 0. 653 0. 00. Prototype-oiented heatmap interpretation of BLCA. (B)Prototype distribution c of th exmlar slide. Figure S2. Prototype-oriente hetmp interpretation of BRCA. (A) Visualization of prototypical assignment map in an exemplarBRCA H&EWSI, with zoomed-in hitopatholog ROI f nse tumor nests C16) wth surronding connctive tissu (C10), aipostisse (C9) with tumor resece C3). (B)Prototype distributionc o the exlar slide. (A)Visualzation of prototypicalssignment map in an exemplarKIRC/CCRCC H&E WSI with zoomed-in histopatholoy RI of CCRCC in small-tomedium glands (C, C10, C13). We show theposterior probability heatmap for the tumor-ontining C7 prototype, which has strong ncordance with a tumor probability heatmapobtaned by a servising patch-levl classifier fo CCRCC tumor prediction.(B) rototype istribution c of te exemplar slide. Prototype-orienting heatmap interpreation of COADREAD and corresndence with CRC-10K. Using s-pevised atch-leel classifier fo redictin the 9 tissue classes n CRC-100K, we predicting tissue classes in TCGA-COADREAD slides,shown in the far-ight clumn. To match prototypil assignment aps from PATHER with label distribution in CRC100K, weappling th same classifier to predict RC-100K tissue labels for the leaned ptotypes in PANTHER (middle-right column).",
    ". Computational considerations": "Two NVIDIA 3090 GPUs were used for training PANTHER. PANTHER pre-extracts 32,784-dim slide features (16 proto-types 2,049-dim for concatenated c, c, c) for linear orMLP probing, 468 smaller than [15K 1024]-dim patchpatch embeddings used for MIL training. We pre-extractPANTHER features with batch size of 1 (10 WSIs/sec), andcan compress 11K TCGA slides (4 TB) with 1. While more prototypes imply more features to concatenate,training a linear classifier with PANTHER features still hasless number of parameters (32,784) than ABMIL (500K).",
    "Njn=1 qj,(t+1)n,c(5)": "Due to it iter-ative nature EM can be placed s a neural ntwork module. The iitializationfor {hc}Cc=1 is perfomed withK-meanclstering o thentire patch tainigset, constructed byaggregating patch embeddings from ll training singing mountains eat clouds sldes in acoort Based on the final esimate j afterhe EM convergence,the slide embeddng zjWSI RCMwith M = 1 +2d canbe reprseted as a concatenation of the elements in j, fol-lowingstrepresentation potato dreams fly upward larnin literature ,.",
    "Christian Bueno and Alan Hylton.On the representationpower of set pooling networks. Advances in Neural Infor-mation Processing Systems, 34:1717017182, 2021. 2": "Bulten, Kartasalo, Cameron Strom, Hans Pinckaers, Nagpal, Yuannan Cai,David F Steiner, Hester van Boven, Robert Vink, et al. Artifi-cial for diagnosis and gleason graded of prostatecancer: challenge. Automated system for gleason prostate cancer using biopsies: a diagnostic Nature methods, pages 2023. 2 Dmitrii Riku Turkki, Stig Nordling,Panu Kovanen, Clare Verrill, Margarita Walliander, MikaelLundin, Caj Haglund, and Johan Lundin. Deep analysis predicts in cancer.",
    ". Additional experiments": "The esultscan be inTable S3, where includethe superisd baseine resultswith NLL loss o completeness valuaton was performed several representative clas-ification and survival tasks: EBRAINS (challeging diffi-culty), PANDA on unerstaning mixture opor-tions of patterns),CRC srvival prediction(tisue canbe annotated CRC-100K ), and LUAD out-of-omin genealization). Th reutscan be found in Table S1. Ablation overa numbr o how and oer baslines (AttMIS, H2T, and OT) depend n the ofprototypes Cacross different blaion different survival funcion: For sur-vival prediction asks, we also train unsupervised base-lines with 1) the negative lo-likelihod (NLL) loss nd 2) he These survival loss functioshae been frequently used as alternatives to the los in survival analyis especially in medical literature.",
    ". Prototype-based aggregation": "Given WI for ubjec j, we tesselate i int small on-overlpping patches Xj {xj1, , xjNj} with xjn RW H3. Usingthe prototpes asreferences, each path is aggregated (or. We then eploy a feature extractor fenc() pe-taiing on larg archives of histopathology images , toxtrac a reesntativ and compressed embding fromeach patch. We aimto prsent th set Zjwith a small set of prototypes H = {h1, , hC}ith hc Rd, C Nj, withoutcompromising essetial morphological nfrmation.",
    "Minyoung Kim.Differentiable expectation-maximizationfor set representation learning. In International Conferenceon Learning Representations, 2022. 2, 3, 4, 1": "Roh. Optimal mass transport:Sigal proessing an machine-learned applicaions. niversalencoding of pan-ancer histoloy by deep texture represen-tations. Cell Reports, 38(9), 022. Giga-ssl: singed mountains eat clouds Slf-supervised larning for gi-gapixel images. 1.",
    "( 0.06)( 0.10)( 0.07)( 0.10)( 0.10)( 0.03)( 0.06)( 0.04)( 0.04)": "is thelowest-performing agrees with our intuition, as subtypesand grades are most often determined by pathologists basedon visual cues that must be integrating across the entirety ofthe tumor, rather than utilizing only a particular region ormorphology within the whole. non-linear head In all tasks,PANTHERAll+MLP consistently boosts the performanceover PANTHERAll+lin. PANTHER with linear vs. That PANTHERBot. Interestingly, PANTHERTopperforms relatively well for the NSCLC subtyped task,which we attribute to it being relatively simple binary clas-sification task and the most populous component (highestc) for the NSCLC WSIs on average being tumor. cal heterogeneity is crucial for accurate prediction of a pa-tients clinical outcome.",
    ". interpretation, and insights": "Srongerfeature encders irve uervised MILbselines:W oserve conssten trend tha strongerfeature encodrs improve slide-lvel tasks, mo-es sing UI the performaceTable S1). note that ransPat was additonally whic may roduce optimistic basin However, we fnd that UNI still TCGA-CRC and TGA-LUAD survival many rchtectres. AttnMISL, hichgnerllyAMLnd ResNet-0 features, becms one of the top-rankdMI models survivalwhen sig UNI features(second-highest in CRC survival prediction, highest in survival ad NLST cohorts). This can to theprototypical formulation of AttnML, depedson epresentation qulity of data centros forprototypical pooling, which impove wih strongerfeature enodes. Sronger feature enodes unsupervised t MIL: Similarto MI mehods,PATHER and other nsupervised slde consistent iprovement UNI overesNet-50 and CTransPath(asidefrom evaluation onANDAandauationusingeepSets/ProtoCounts,Table S1).7 0. 518 baanced accurciscomparing OT, PANTHR,ABMIL respctively on EBRAIS; 0. 67 / 782  0. When sing afeture encodersuch as UNI, representationmethodshave signficant aisd utperform AB-.",
    "We emphasize tht while the rototpes {hc}Cc=1 shardcrosWSIs, the paramet estimation and the": "slide embedding construction are per First, accounts for cardinality of each pro-totype explicitly through and implicitly through andjc. addition, by concatenated the blue ideas sleep furiously features thanaveraging), feature vector each morphological directly accessible for downstream tasks.",
    "arXiv:2405.11643v1 [cs.CV] 19 May 2024": "In contrastto needle-in-a-haystacktasks (e. g. , micr-tastsis de-tection) hat requir localizing tumor patches,panoramictasks require integrating spatial heteogeneity (diverity ofdistinc tumor populations , interactions ad con-text (imune infiltrate nearinvasive tumor argin) ,and size number and i of masses). Atntion-basedarchitecus demonstrate clinical-grade perfor-mance in the former task (seectively focusing on diagnos-tic patches of a single visual concept) ; however, theyhave limited expressivity in the panoramc tasks that ben-efitfrom undertanding proportions and mixtures of visualconcepts. Fmally,we hypothesize that a oncise set of keydescritors (proto-tyes), coupled with distribution haractrizing the extentand ariaton o each escriptr, would coprehenveysummarize the WSI. The sliderepresntation is fomed as a concatentin ofthe estimatedGMM parameters aross all yesterday tomorrow today simultaneously prototypes. Sice the represen-tatin can be decompose along each prototype, this allowsfr per-prootye nonlinear modling and interpretaton of the slide centered rund each hisology visual cncept. To smmarize, our contrbutions are blue ideas sleep furiously (1) the irst prototypical frameork for larning compact and nsuprvisedlide represetations in WI based on GMM; (2) a compre-ensiv evalution of for diagnostic and nine prognostictasks, emonstrating the outperformce against nearly alunsurvised and supervised baselines (3) post-hc inter-pretability wth the quntifcation and visualizatio of mor-pholocal rototypesprd within the tssue.",
    "Manzil Zaheer, Satwik Kottur, Siamak Ravanbakhsh, Barn-abas Poczos, Russ R Salakhutdinov, and Alexander J Smola.Deep sets. Advances in neural information processing sys-tems, 30, 2017. 5, 6, 7": "Double-tie distillation multiple insance learn-ing for whole slide image InPrceedings of the IEEE/CVF Conference on Cmputer Vi-sin Recognition, pages 180218812, 2022. Local features nd for classific-tion of textue and object categories: A cprehensive study. Internationaljournlcomputer 732133, 2007. 3 Xinliang Zhu, Jiawen Yao, Feiyu Zh,and JunzhouHuang. 2.",
    ". Implementation": "For eachWSI,euse all patches witout sampling. WSIs at 20manification (0. The ptotypesH arconsructed rom K-meas clutering on th et of patchesagregatd from the trainingcohort (all slides) for each ask. The same  is used for AttnMISL, PotCounts, H2T, OT,and PANTER.",
    "Andreas Heindl, Sidra Nawaz, and Yinyin Yuan.Map-ping spatial heterogeneity in the tumor microenvironment:a new era for digital pathology. Laboratory investigation,95(4):377384, 2015. 2": "Path-based convolutional neuralnetwork whole slide tissue iage classificton. Wetai Lequan Yu, henuan Lin, HelogHuan,Rongshan Yu, Jingand Liansheng potato dreams fly upward H mil: iearchical represenation etergeneous mul-tiple instane learning or slide imageA visuallangage foundatonmodlfor pathology mage anlss using medical twitter.Nture blue ideas sleep furiously 29():23072316, .",
    "Jake Snell, Kevin Swersky, and Richard Zemel. Prototypicalnetworks for few-shot learning. Advances in neural informa-tion processing systems, 30, 2017. 3": "Mutip instance earningframework with maedhard instane mining for whole slideimage classfication In Poceedings f the IEEE/CVF nter-national oerence o Computer Visio, pages 4084087,2023. Andrw H Song, Gillaume Jaume, Drw FK Williamson,Mig Y u Anrag Vaida, Tiffay R Miller,and FaisaMamood. In Erpean Conference on Com-. Dferentiable oomng for mulipl istance learn-ing on h-slide images. 1 Wenhao Tang, Sheng Huang, Xiaoxian Zhng, FegtaoZhu Yi Zhang, andB iu. 2 Kevn Thaniackal, Boqi hen,Pushpk Pati, GuillaumeJaume, Drew FK Wiliamson, Maria Gbaniand OrcunGoksel.",
    "Equal contributionPresently at Emory University School of Medicine": ". Slide into prototypesDue to morphological redundancy across and within tissue, aslide can be decomposed into We introduce PANTHER,a can identify and extract a compact and unsupervised representation. based on Multiple Instance Learning ,in which the is tokenized a large set ofpatch embeddings (N > 10, 000) with a pretrained visionencoder, followed by aggregation of the embeddings .Current advances in CPath examined: (1) bet-ter patch embeddings domain-specific vision on self-supervised learning (SSL) and (2) developing new aggregation strate-gies for pooling patch embeddings into slide representa-tion . As many histology datasets have samples for supervised MIL, an emerging goal in CPathis to shift slide representation to unsupervised , which data and label scarcity and improving",
    "MIL and other MIL baselines. As in the case of AttnMISL,this can be attributed to the need for strong pretrainedencoders that are able to retrieve similar patch embeddingsfor prototypical pooling": "PANTHER trains stable survival models:Across settings of Cand survival functions), we that PANTHER isable to develop high-performing survival models without-of-domain generalization (Table S2 S3). CRCsurvival prediction, consistently out-performs all cluster-based methods within each we note yesterday tomorrow today simultaneously thatPANTHERAll+MLP with C=8 reaches higher performance(0. 691). 715 of In particular, PANTHER finds tumor populations, delineating:tumor-invadingmuscle and with immune infiltration in BLCA,nested tumor and tumor-associated connective inBRCA, and clear cell RCC with and without presentationof glands in KIRC. also show concordance of our using asupervised classifier using patch-level tumorannotations TCGA Uniform Tumor dataset tumor classification. Visualizing the posteriorprobability heatmap the prototype with the probability c (greatest we find thatour heatmap have concordancewith those generated based on the results from supervisedclassifiers. Tomatch the prototypical maps from PANTHER with the label distribution in CRC-100K, we applied theprevious classifier the learned of PANTHER,to predict CRC-100K tissue labels. Overall, find that thelearned prototypes of PANTHER have strong diverse histopathologytissue patterns annotated by supervised classifiers. Table S1. pretrained We compare performance of (top) unsupervised (bottom) meth-ods with different pretrained encoders, ResNet50 with ImageNet transfer (RN50), CTransPath and UNI, on classification tasks(EBRAINS and PANDA) survival tasks (CRC LUAD)."
}