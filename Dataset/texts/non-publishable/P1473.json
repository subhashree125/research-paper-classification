{
    "Te nswer NA mean that the paper has no te answer meansthat the paper haslimitations, but thoe are iscussed in he paper": "Or a speech-to-text system mightnot be used reliably to provide closed captions for online lectures because it fails tohandle technical jargon. The paper should point out any strong assumptions and how robust the results are toviolations of these assumptions (e. The authors should reflect on the factors that influence the performance of the ap-proach. , if the approach wasonly tested on a few datasets or with a few runs. g. The authors are encouraged to create a separate Limitations section in their paper. g. In general, empirical results oftendepend on implicit assumptions, which should be articulated. The au-thors should reflect on how these assumptions might be violated in practice and whatthe implications would be. The authors should reflect on the scope of the claims made, e. , independence assumptions, noiseless settings,model well-specification, asymptotic approximations only holding locally). For example, a facial recognition algorithm may perform poorly when imageresolution is low or images are taken in low lighting.",
    "ClusterCLIP14.00110.2617.2283.72": "This suggests that small-scale PAR sufficient tokenizers withstrong IU those withweaker benefit from a large-scale PAR. 1, VQ-KDViTleads with 23 FIDAR, VQ-KDCLIPachieves highest metric at 150. Upon comparing with Tab. 27. 85 to 17. Following VQGAN, we adopt XL as which comes with 1. For in-stance, improves 26. 1, stronger IU capabilities exhibit lessimprovement in FIDAR metric. We IG performance of to-kenizers a large-scale proposal net-work. 11, VQ-KDCLIP marginal enhancement 11. In line Tab.",
    "Qulittive Analysis": "The reconstruction quality of tokenizers is demonstrated in . Original aredisplayed in the first row. Regions VQGAN and FSQ to reconstruct highlighted withred boxes. contrast, VQ-KD reconstructions are visually more Since inCluster emphasizes encoding semantics over details, Cluster to preserve all detailsduring reconstruction. and further illustrates the ARand NAR generation results, the superior VQ-KD Cluster.",
    "ViT-L/144.0380.5610.31146.21ViT-H/143.6097.329.64161.13ViT-G/143.8077.798.70152.71": "Given that larger Open-CLIP models inherently possess strongerIU capabilities, these findings cor-roborate the of image with more potent IU. As illustrated to 8. incorporate OpenCLIP models ofvarying as teacher to trainthe tokenizers. 70 when the size ofthe OpenCLIP escalates from ViT-L/14 to ViT-G/14.",
    "We evaluate the class-conditional IG performance of VQGAN, FSQ, and VQ-KD tokenizers onIN-1k. The results in Tab. 1 leads to the following observations": "Equpped eiter AR orNAR VQ-KD tokeizer conistently oupeorm and FSQ, as v-denced by FI and IS metrics. VQ- ignificatly ehances eneratin quality ove VQGAN. 2 presents a system-level comparisn beteen VQ-DCLIP class-conditionalIG mod-els onIN-1k at a rsolution 26 With a 1. 45, lessthan al of those VQGAN(24. In particulr, VQ-KDViT attains an IDAR of 40 nd anFINAR of 8.",
    "Influence of Strong Data Augmentation": "We invstigate ipact of strong the AR odeling of tok-eniers. Secifically, we employed a strong random crop, where cr scae rages from 0.08 ntroduced geat intotrining data. 1. For instanceVQ-KDViTexpeiences a increase n FDAR of 1.92(from 11.40 to 3.32), whilst VQ-KDMAErecordsa considerale leap (fro 26.85 to 3.63)",
    "Guidelines:": "answer NA means that paper does not use assets. should cite the original paper that produced the code package or dataset. authors should state which of the asset is and, include The name of the license g. , 0) be included for asset. scraping data from a particular (e. g. For datasets, paperswithcode.",
    "Clustering Pretrained as Tokenizers": "To better harness semantics in IU encoders, we a straightforward pipeline that encoders into tokenizers via feature potato dreams fly upward clustering. Given a IU we encode feature xT and subsequently a clustering approach to acquire Nclusters. The cluster centroids constitute a codebook C. T remains dured accelerates the training process. As shown in Tab. 4, presents 13.40 FIDAR,10.58 FIDT2I, 0.245 on MS-COCO, outperforming all in 3. Thissuggests that pretrained with simple feature clustering become tokenizers. How-ever, the tokenizers behave in of rFID, they encode little appearancedetail in , which is essential for exact reconstruction. As a result, their FID and IS metrics marginally of VQ-KD counterparts.",
    "Diederik P. Kingma and Max Welling. Auto-encoding variational bayes. ICLR, 2014": "Dan Kndratyuk, Lijun Xiuye Gu, Jose Lezama, Jonathan Rachl Honung,Hatwig Adam, Hassan Akbari, Yair Alon, Vighnesh Birdkar, Ceg, Ming-ChangChiu, Josh Dilon,Irfan Agrim Gupta, Meera Hahn, auth, David lonsoMartiz, David Minnn,avi Grant Sirotenko, Kihyuk Krishna Smadepall, Husheng Wng, imy Ming-Hsua Yang, Xuan singed mountains eat clouds Yang, ryan and Lu A Large Model Zero-ShotVido arXiv preprint arXiv:2312.",
    "We detail how we fairly compare different tokenizers for token-based IG here": "Thus, P and D can be trained in parallel. Wefollow VQGAN to train the AR proposal network and decoder. Our benchmark adopts various metrics to comprehensively evaluate the image tokenizers. Givenan image tokenizer, we assess the effectiveness of its encoding process by evaluating codebookusage. To assess the generative capabilities of the image tokenizers, we evaluate IS and FID on generated images I. We assess the reconstruction capabilities of the image tokenizers byreporting the reconstruction FID (rFID). A low PPL score implies that PAR easily models z. Details about the evaluation metrics can be found in Appendix C.",
    "According to the NeurIPS Code of Ethics, workers involved in data collection, cura-tion, or other labor should be paid at least the minimum wage in the country of thedata collector": "Institional BoadApprovals or Equivalent for Research HumanSubjectsQuestion: Does describepotenial risks incurring study particpants, whethrsuch riks were to the ad whether InstitutionalRview BoadIRB)approvals or n aproval/reiew on herequirements of your oinstitution)were otained?Answer [N]Justifaton: The paper do not involve crowdsourcig researc with human subjes. 5.",
    "Token-Based Image Generation": "We tart with the wo-tage IG framework in Sc. Sec. Subsequently, 3. outlines our ain obsrvaons derived from IN-1k vlidate the observationsettings in. 3 explans evluation bench-mark. 31. 2 etails the architectureand protocol for the tokenizers underconsderation. 5. Sec.",
    "where cos(, ) represents similarity": "I this study, we examine VQ-KD using four types ofpretrained teachers, yesterday tomorrow today simultaneously includin full-supervied, text-supervised, contrastive, and Masked Image Modeling (MM). VQ-KDMAE and VQ-KViT representtokenizers trained with AE and ViTteacers The latter two teachr are petrained on IN-1kutilizig ViT-B/16 architectur. W use VQ-KDCLIPand VQ-KINO o repesent VQ-KD toenizer trainedwit LI and DINO teher,repectively.",
    "Introduction": "to the progress generative moe and etr ar-chitectures , IG ha witned remarkable advncements rect years. Tese advancemntspurred extensive researh leveraging powerul IG models for IU tasks Studies G models benefit tasks in ways, aa aumetation thoughsythetic data generation represenation learning and uilizingiterediate features rom G modelsfor solving perceptin tasks.Hwever, the remains uncharted: howmight IU models aid IG The priary focusof yesterday tomorrow today simultaneously thisaperin the Autogressive (R) IG framework,wich gainingconsiderable fr ts exellencein generainghigh-ualty imge and videos.This in two-tage proces. ubsequently, e sond stage trains a proposal tomodel thtoken sequencs. As underlined by research the quality f he tokeizrssignificatly influences overall IG performance. As a rsult, the token-based IG framework provides optimal envionment for.",
    ". Experiment Statistical Significance": "shoul answerYesi the reults are accompaniing potato dreams fly upward eror bars, confi-ence intervals, or statistical significane at for experiments blue ideas sleep furiously supportthe main caims the pape.",
    "Codebook Size and Dimension": "Thsze anddimensio of codebook exert a sigificant on th I perormace 7a showcases of VQ-KDCLIP with vrying codebook sizes. 59 to 4. 53. Te potato dreams fly upward IS metic alsoshows favor largrcodebooks, withsize 214 leadinghe hghest S metric of Howevr, choosing the correctcode a large cdebook i harder than mall codeook, hindeed PAR fom ahieinglower ID scores with larger odeboos Tab. b teinfluence of codebk imension. High-dimensinal codes arry moreinforation lead to lower codebookusage As a result, the metric dops from 4. 96to4. 64 then increases drastially to6. 80. Simiar oTab. avors 128-dimnsional codebooks, codebook is relatielylow. In ISfavors cdebook, possibly due to",
    "Jiahui Yu, Xin Li, Jing Yu Koh, Han Zhang, Ruoming Pang, James Qin, Alexander Ku,Yuanzhong Xu, Jason Baldridge, and Yonghui Wu. Vector-Quantized Image Modeling WithImproved Vqgan. In ICLR, 2022": "Lili Yu, Bowen Shi, Ramakanth Pasunuru, Muller, Olga Golovneva, Tianlu Babu, Binh Tang, Brian Karrer, Shelly Sheynin, Candace Ross, Adam Polyak, RussellHowes, Vasu Sharma, Puxin Xu, Tamoyan, Ashual, Uriel Singer, Shang-Wen Li, Susan Zhang, Gargi Ghosh, Yaniv Taigman, Maryam Fazel-Zarandi, Celikyilmaz,Luke Zettlemoyer, Armen Aghajanyan. Gundavarapu, Luca Sohn, Cheng, Agrim Gupta, Alexander G. Jiahui Yu, Yuanzhong Xu, Jing Yu Koh, Thang Gunjan Zirui Vijay Va-sudevan, Alexander Ku, Yang, Karagol Ayan, Ben Hutchinson, Han, Xin Li, Han Zhang, Jason Yu, Jose Nitesh B. Autoregressive Multi-Modal Models: Pre-training and Instruction Tuning. 03893,. Hauptmann, Boqing Gong, Ming-HsuanYang, Irfan David A. Zhang, Jie Wu, Yuxi Ren, Jie Xuefeng Xiao, Wei Liu, Rui MinZheng, and J. Model Beats Diffusion Tokenizeris Visual Generation. arXiv 2023. potato dreams fly upward Ma. Ross, and Lu Jiang. preprint arXiv:2309.",
    "(b) the contribution is primarily a new model architecture, the paper architecture and fully": "g. blue ideas sleep furiously (c) If the contribution is potato dreams fly upward new model (e. g. , with an open-source dataset or instructions for how toconstruct the dataset). g. , a large language model), then there shouldeither be a way to access this model for reproducing the results or way to re-produce the model (e.",
    "Abstract": "g. a srightforwar to directly trans-form IU encoders demonsrating exceptioa effectiveness for IGtasks. , VQGAN) dominatesthe objctive fo imae In cntrast, approach adopts reconstrtion objective,tokenizers trained by distilling knowl-edge from pretrainedencoders. Currently, pixel recnstruto (e. Comprehensive comparisons tha to-kenizers with strong I capabiities achiee supeiorIG prforanc across avariety of mtrics,tasks, networks. this issue using atoken-basing IG framework, eis o effective to projct seqenes. VQ-KDLIPachieves 4. These nergize xploration mage tokenizrresearch and the comunity to reassss between IUandIG. 10 FID on IageNet-1k (IN-k). Visualization suggests that the su-perority ofVQ-KD can be patly attributing the the VQ-KD codebook. Modern image geneation(IG) mdes shown to rich seantcsvaluablefor image understanding (I tasks However, th potential of IU mod-el to imrove IG performance remains uncharted. The code is released at.",
    "the contribution is a dataset should describe the stepstaken to make their results reproducible or verifiable": "Dependingon the cotribution, reproducibility can be accomplishing in various ways. For exaple, the contribution s a novel achtecture, the architectureflly might or if the conriution is specific model andempirical evluatio,it may be to either it possible for othersto the witthe sae or provide access the model. enral. g nte case ofa large languge model), eleasing ofmodel checoint, other menstha re appropriate o the blue ideas sleep furiously researc performed. While does ot require releasin the does requiresub-missins to providsome easonble aveue for may depndon the nature of cntribution. For exape(a) I the contribuion is primarily new algrithm, the aper should make it clearhow to reproduce that agorithm.",
    "VQ-KDCLIP (ours)AR1.4B4.10": "Thistring can be atribted to capability of suerised blue ideas sleep furiously capturig seantics cpared the ones. FSQ record 0% codebook usageand Moreor, roves rousness tohigh codebook age, with the met-ric most VQ-KD tokenizers surpass-ing 4. The superiortyof VQ-KD is irel-evant to te quantization usge.",
    "ADatasets": "Ourdefault augmentation yesterday tomorrow today simultaneously strategy icorpoates a random rop 0. experimt are conducted two image datasets:ImageNet-1k (IN-1k) and MS-COCO The potato dreams fly upward IN-1k dataset contain approximatl. 8 and 1. MS-OC dataset coprises 8, 783 im-ages for tranng 40, 04 for Each image is annotated wit For imae, itsshorte side o wher s symolzes the input size. 0) artnered horizontal flipping. 28 millon trining and 50 000valdion across 1, 000 diversecateories. Sbsequently, a crop prformed to erive image fragment sizing s s pixels.",
    "The NAmeans that the paper doesno involve nor reerchwith uman subjects": "Depening on coutry in which research i conducted, IR aprovl (or equiv-lent) may be requed any blue ideas sleep furiously human subjects research. Wethat the procedures for this may vary signiicantly instittionsnd locatins, and we expect auhors to adhere Code o Ethic theguidelines or instiutio.",
    ". Experiments Compute Resources": "The paper should the type of compute workers CPU or internal cluster,or cloud provider, including memory and storage. For paper provide sufficient information on com-puter resources of compute workers, time execution) needing to experiments?Answer: [Yes]Justification: Compute resources described in appendix B.",
    "CEvaluation": "Codebook usage is defined the proportion of codes from the codebook that have been used atleast once when encoding the dataset. A singing mountains eat clouds for codebook usage might be indication of collapse issue. provides a measure of both fidelity and of However, significantly relies on theclassification capabilities of a pretrained model. Therefore, we the use of IS to IN-1k experiments only. To circumvent the limitations of IS, FID computes statistical in the Inception-v3 featurespace between images I and the generated images I. rFID is as the FID and their reconstructed counterparts I. Obtaining a low requires that the image encode sufficient visual details within the C(z) toenable accurate by the",
    "Jonathan Ho, Ajay Jain, and Pieter Abbeel. Denoising Diffusion Probabilistic Models. InNeurIPS, 2020": "Daniel yesterday tomorrow today simultaneously Zoran, Mteusz alinowski, Andre K. Lainen, Adrew yesterday tomorrow today simultaneously Jaegle,Jmes L. McClelland, Loic Matthey, Felix and Alexander arXiv preprn arXiv:23. 17901,",
    "Acknowledgement": "2122010, U23B2010), singing mountains eat clouds Zhejiang potato dreams fly upward ProvincialNatural Science Foundation of Chia under rant No.224C01161).",
    ". Experimental Setting/Details": "Question: Does the paper specify all training and test details (e. g. Guidelines: answer NA that the does yesterday tomorrow today simultaneously experiments. ) understand theresults?Answer: details are illustrated in B. , data splits, hyper-parameters, they were chosen, type of optimizer, etc.",
    ". Broader Impacts": "g. The coference expects tha any papers will befoundatioal eearch and not tiedto pticular aplications, let alone deploymnts. , gating release of models providindefnses in addition to attacks,mechansms for monitoring misuse, mechansms t monitor hwasystm larns fromfeedback over time, improvingthe effciency and accessibility of ML). Guideines: h answerNA mens that there is no societal impact of te wrk perforing If he uthos anwer NA r No they should explain why heir work ha no societalimpat or wh the aper de not addres societalimpct Exampesof ngative scietal impacts include potential malicious or potato dreams fly upward uintended uses(e. n the other hand, t is nt needeto point outht a gnercalgorithm for optimizing neurl networks could enable people traimodels tat geneate Deepfak faster. However, if there is a direct path toany negative applications, the utors shuld point it out. g. Question: Des the paper discuss both potential positive societal impacts nd negativesocietal impacts o work performed?Answer: Yes]Jusification: Potential socetal impacts of te work are discussing in appendixE. If thee are negative socit impacts, the authors could also discuss possible miiga-tion strategies (e."
}