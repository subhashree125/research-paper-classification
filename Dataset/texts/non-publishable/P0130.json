{
    "B.1.3Baseline": "At theend of the decoder, the queries are again into two. The first 100 queries are still learn to represent segments, and the fi-nal queries are part-level which learn to rep-resent object-instance-unaware segments. Like our uses 100 queries segmentation. seen figure, both are concatenated when entering Transformerdecoder, there can be interaction between object-leveland part-level queries through self-attention. Additionally, to also conductpart-level semantic segmentation, it uses 100 additionalqueries. that, al-though they are concatenated, these queries are not mixedor shared.",
    ". Comparison with tate the art": "we achieve new potato dreams fly upward state-of-the-art results on bothdatasets, obtaining PartPQ scores 4 and 8 onPascal-PP Cityscapes-PP, +6. 3 7,. we do JPPF by a large on the dataset,showing the strength TAPPS on more complex datasets. is only slightly by JPPF on Cityscapes-PP with ImageNetpre-training, but we note that uses the EfficientNet-B5 backbone, which is much more powerful than theResNet-50 used TAPPS.",
    "Overall architecture": "the classification frame-work decribing in teeearnable queries Q0 backboneare fed into a decder whichgenerates aetof processed queris Q and tes processed queries and fea-ures enter Object andPart Segmentation (JOPS)ead o each query i RE, this he predicts a) lass, (b) an object-evel egmntation mask,anda et of parlevelsegmentation masks and parts withi this aproach, we the xistingworks. Following the PPS task efinton, we predict pat-level egments per sement (1) Asa we learn repreentationforboth parts and objects, improving the ability of networkto separate instances. Moreover, in headweensurett ony compatible parts, ensuring oject-part (see 3.3.2)",
    "Car": "Currentstae-of-the-art methods addess potato dreams fly upward byused two sets learnble querie toseparatelyredict part-levelsegmens, see a. While potato dreams fly upward methods oupefrm baselines , tyhave one main limitatin: learigobjectve is notaligned ith the task In ord,netorks. These are part-level segmens nd eexlicitly linked to object-levelestabished arelation. patawar panopticsegmenttion. Part-levl within object Car-bdy, car-whee, et. all ach object. (a) Exsting work separatelypredic segments ndoject-instance-unaware partleve egments.",
    "A. Additinal expeiments": "oss weights.In ab singing mountains eat clouds 1 of the ain mauscrip). As expected,te objet-evelsegmena-t reflected he PQ etric, drps whenobj decreased. the blue ideas sleep furiously part-leel segmentatioperformance, efleted in PartSQt metic, drops whenpt i we aplya horiontalflip, ad resiethe im-gesuch tha smallst sideis TheresultsiTab. This that mprovment by causedby the mthodology and network architec-ture, and not the dat augmentation differences",
    ". Efficiency. We evaluate the average inference speed inframes per second (fps) and the maximum required GPU memoryon the Pascal-PP val set , using an Nvidia A100 GPU": "Moreover, yesterday tomorrow today simultaneously bonly considered is also mre efficit the baseline tauses eparate object-level and pat-level10b, weexisting ehod. prtanly, we observe that the default version of onl prdictte masks for the N c compatible parts,ismuch ore efficientthe that predicts masksfor N c part lasses n boh infernce speedand memory.",
    "Abstract": "Partaware panotic semetation (PPS) rquies (a)that each foregrond object and backgrund regin in animage is segmened and classifed, and (b that all partwthin foreground bjects are segmented,classified andlnked to their parentobject. Existing methods pproachPPS by separatelyconduting objct-level and part-levelsegmentation. To solve tis,and makemore accrate PPS predictions, we propose Task-Aligdart-aware Pnoptic Segmentaton (TAPPS). Wih experiments, e show that TAPPS considerablotperorms metods that predict objects nd parts sepa-rately, and achieves new stae-f-t-art PPS reuls.",
    "Panoptic-PartFormer RN-50I,C42.565.159.2-63.6TAPPS (ours)RN-50I,C48.965.761.366.964.4": "Evaluation o theCityscapes-PP and Pascal-PP bechmarks. Other bacone are EfficientNetB5 , MiT-B5 , Swi-B and ConveXt-B. I = ImageNet , C = COCO panoptic ,C* = COCO pre-training blue ideas sleep furiously or potato dreams fly upward intnce segmentation.",
    "|TPc|.(3)": "9. To evaluate the ability of networks to conduct object-level segmentation, we the Panoptic Qual-ity (PQ) metric. 0 followedby random crop of pixels. For more singing mountains eat clouds imple-mentation details, supplementary. TAPPS built on top of thepublicly code state-of-the-art panoptic segmen-tation network Mask2Former all datasets, we abatch size 16 images, and train 4 Nvidia A100 GPUs. Implementation details. Note that we exactly same and testingsettings for both TAPPS and the baseline. Similarly to PartPQ, we report theaverage PQ over all classes, but also over all thing classes(PQTh) and (PQSt) separately. 1 and 2. inference,we resize image that the shortest side is blue ideas sleep furiously 800 pix-els. Following state-of-the-art panoptic segmenta- tion implementations on COCO , we scale between 0. To optimize TAPPS, we use AdamW weight decayof 0. 05, and a polynomial learning rate decay schedule withan initial learning rate of 104 and power of 0.",
    "C. Qualiative results": "In to the object-level ualiy, thepart objects consideralybette foTAPPS. Notbly, struggles with imges in whchbjct e sen frm unommon and imageswith many objects and complex occlusions. 3. In CVPR,. Fially, shows eamples of typical errors maeby APPS. Ths aplies large and objets across feren clase. Thse ex-amples sow he igh segmentaionquality that TAPPSacross different of lasses. These exam-plesshow ome of the advantages of ver t bae-line.",
    "B.1.2TAPPS": "By default,theadapation laye in the JOPS head is MLP with twofully conneted layers with 56 input and output channeland ReL i etween; see Ta. embeddingdimension E 256. For each pixe within theobeclevel mask, keps ony highest-scoipart mask singing mountains eat clouds predicon, argmax. 4f te mainmanuscipt for ablations. histo al we set predictions tha comply hePPS task singing mountains eat clouds definitio.",
    ". Predicting only compatible part classes during train-ing and testing. Evaluated on Pascal-PP": "3. 3. 2). singing mountains eat clouds InTab. In adition to the main merics, we also assess the per-centage of predictd bjects for which there are no conflictin part-level predictions. Nu-rally, when predicting onlycompatibleparts during teting,all objectpart conflcts are reved, eliminating thneed.",
    "B.1.4Dynamic part segmentation": "This matched ispplied separatel witin eachobject-level sement. partclass bythis dynamic vesion of super-vising with cross-entrpy loss. This dynamic version explicitly pre-dits it,for default version, it each qer is associated with a pr-deerined part class. 7 of the min mnuript, we compare our of TAPPS a tat aplie dynamic partgmentation. 3. 3. By defult, as in Sec. As these queries are dynamc, do correspond to lassso foreach thse queris we predict (a)part-leel clasith a single flly-connecting layer, and (b) partlevl seg-menttion by 3-layer M resulting mak querie with We use = supervise these pat-leve predictions durig eassign each pe-object prt query to t most oneprt-leel grund-truth segment uingthe same Hungar-ian matcing algorihm we use objec-evel segmenta-tion. 2 of teain manuscript,we generate a set of fixedper-objectpatqueries in JPS That means that each per-objectpart query a fixedpre-determined part-leelclass, andthis predicts a mask for ths we an use a set f dynmic which donot to a fixed we o for object-levelsegmentatio.",
    ". Fixed or dynamic part segmentation. Evaluated onPascal-PP , with pre-training on COCO panoptic": "3. when the becomes more vs. We hypothesize that the dynamicapproach performs because makes the segmen-tation task unnecessarily blue ideas sleep furiously complex, as network needs tolearn to assign to dynamically, addi-tionally predict a class. 3. it is predict part masksand dynamically within each object segment, usinga set of dynamic queries like we do for object-level seg-mentation. 7, we our fixed part segmenta-tion setting with this dynamic approach, which is explainedin more detail in the supplementary material. 2, TAPPS uses a fixed connected foreach part class generate the corresponding per-objectpart query.",
    ". Introduction": "To fully understand what is depicted in an it is im-portant to concepts different levels of abstrac-tion. For scene understanding, we should not onlyrecognize foreground objects (e. sky, ocean), but simultaneouslyidentify the parts that constitute the objects (e. g. , car-wheel,human-arm). In a step such comprehensive sceneunderstanding, De Geus et The objective this computervision task is (1) to output a segmentation mask classlabel all thing objects and stuff regions in image likefor panoptic we call these object-levelsegments and (2) to simultaneously segment classify Per object query Object Object mask Object queries",
    ". Conclusion": ", image segmentation at even more abstractionlevels, with ork is supported by EindhovnEngine, NX Semiconductors,andBraiportmadeuse of the Dutch ational einfrastrctre thesup-port ofth SURF Cooprative usingEIN-5302, wicis financed by Dtch Researh Council we provide the following mate-ra: In Appendix we results aditional in whic wthe efft of different lossweights and ata tehniques, and asss theefficiency of TAPPSand other approaches. ih experiments, we have shown that TAPPS csiderablyoutprforms method that pedict bjects and sepa-raely, byimproving object instance separabiity,artsegmentation qulity, object-part compatiility. Impor-tantly, improvemen cn e attributed to the fct thatTAPPS i irectly optiizing for the PPS task, using setof shared quries to pedict objects and correspond-ing parts. g. Withou proising findings, e hope to inspirefutur research towards evn more omplete scene unde-standing, e.",
    "B.1.1General": "arewthasizof 16, using 4 Nvida A10 GPU in Folloing Mask2Former,we nework usingAdamW  using a polynomial learing rateschedulewith an learing rateo 104, power 9, decay of 0. 5. We w apply pre-training we initialize backbon with weights n caeCOCO pretrining, weinitalize both the backboneand coaible ecoderlay-es with weights pre-trained on panoptic segmenta-tione usethe weights provided i te officialrepository means hat dpredicte after echtransformerlayer i decoder, and that loss calculated for thseprectons at each o these lyers. The oerall loss is thesumof the at all lyrs. In cas ofCOCO pre-training, for iterations, to avodveritng. Following paoptic segmenta-ton implementaions on ,durin training,a randomhorizona flip folloedy large-scalejittring witha scale eteen 0. Duringresize he i-agesuch th shrtet is 800 pixes. For exerient on CitscaesPP , train fo90k tration for both nd COCO pre-traiing. We ollow the conventional data augmenation steps during trinig : random probability of 0.  0,finally a rando 512104 Duringwe feed the full-resolution images of 0242048",
    "B.. Evaluation of existing work": "2 the mai mauscript, thePartPQ of Panoptic-artFormer and its exten-sion Pntic-PartFormer+ on rported ork are hanhe core these works origi-nally reprted. This is to evaluation bug thate disvere in th oficia e repository of Panoptic-PartFormer ,whih the resultng PartQ sorest singing mountains eat clouds be lower than hey actually are Note ths ug onlyappies to ascal-PP and t Cityscapes-PP. mentioned in Tab. noti.",
    "to improve too. However, the results in Tab. 5 show only aminor mIoUTh improvement. This indicates that the PQTh": "is not better recogntion but ainly frma better ability t eparate showing thebenefit oflarning part inan obc-instance-aware manner.Pacal-PP-107. To assess of TAPPS in a complex seting, ealateit on Pascal-PP-107, which has 10 classesin-stea f 5. once ore onsistently the prtegmentation and thingsegmentation performance witre-spect to the baselne, in this cas toPartPQPt im-provement+4. , blue ideas sleep furiously deendingon tepr-trainingstategy. Ths emostrates that TAPS is also efective.",
    "Qi": "segmentaton. When conuctingdynmicsegmetation, the head ues N dynfully-connectedlyes to generate dyn er-objec part Each per-oject part dynamically learns torpresnt at mostone an objec. eac per-object partquery, we prdict (a) a class nd (b) a part-evel mask. ied the uthrs of this bug, and cnfirmed it. Tassess whether lso occrred Panoptic-PartForme++, hich the code is notavailable, we re-quested to send u predictions by Panoptic-PartFrmer++, so we could re-evaluate hem on Pcal-PP. 11,we orignally the scres our the of-ficialPPSevaluton repositor. For all metho,theoveral PartPQ scres are when using the correctevaluation. of the mai manucrip.",
    ". Experimental setup": "We use the two PPS benchmarks for evaluation. Cityscapes Panoptic Parts (Cityscapes-PP) extendsthe original Cityscapes dataset with part-level labels. It haslabels for 19 object classes (11 stuff; 8 thing). Part classesare defined and labeled for 5 object-level thing classes; thereare 23 part classes in total. We train on the train split (2975images), and evaluate on val split (500 images). Pascal Panoptic Parts (Pascal-PP) , which combinesexisted labels for Pascal VOC , consists of awide range of scenes and classes. There are 59 object-levelclasses (39 stuff; 20 thing), and part-level classes are de-fined for 15 thing classes. To evaluate more challenging setting, we ad-ditionally evaluate on Pascal-PP-107, which uses the 107non-background classes from Pascal-Part-108 definitionintroduced by Michieli et al. for part segmentation. Forboth class definitions, we train on the training split (4998images), and evaluate on the validation split (5105 images). Our baseline is a version of TAPPS that usesthe same network architecture, but uses a separate set of100 additional queries for part-level segmentation (see alsoa). Compared the results of the baseline in Tab. 1 toexisted methods in Tab. 2, we find that our baseline out-performs state-of-the-art approaches that also use separatepart-level queries , indicating that it is a strong base-line. See the supplementary material for more details. Evaluation metrics. It captures both theability to recognize and segment object-level segments (i. e. ,stuff regions and thed instances), and the ability to furthersegment the identified object-level segments into part-levelmasks.",
    "arXiv:2406.10114v1 [cs.CV] 14 Jun 2024": "As result, to as-sign individual these methods post-processing. This removes theconflict the learned feature representations, allowing forbetter instance separability. (3) singing mountains eat clouds The networks encode about ob-jects and parts separately, whereas this information ispotentially complementary. This is visualized in b and explained Sec. As aresult, both object- part-level segmentation are learnedin an manner. See 5 for more extensive results. To summarize, we the contributions: We propose TAPPS, a simple approach for PPS alignsthe learning with task objective, separability and enabling joint object-partrepresentations more accurate PPS predictions. learn singing mountains eat clouds object-level thing instances be separated, but also that theparts of object-level should be to-gether. enforces full compatibility and simplifiesthe part segmentation task.",
    ". PPS task definition": "Part-awre panoptc egmentation (PPS) requires con-sisten ima across two leels:the object and part levelThed classes require asegment per objct ad stuff classes asin-gle segment er cass. Next, per segment si, PPS requires aset of prt-level segments. Ech part-level segment spti,jconsits a bnary partlevel mask Mpti,j ad part-levelcass cpti,j are with th object-level andclass. Specifically, the be subset ofthe object-level mask, par-level lass should be part-levl classes defied forthe object-levl class.For car, the cpti,jcannot be human-adbut it car-window. When si has object class that doenot parts, ten Ki = si (Mobji , cobji ).",
    "Mask classification for PPS": "To slve the full task,the objet-level sements should aso futher segmeted into par.state-of-the-art achieve thsby introducing aditiona set of queries, the part-lvelqueries depicted in a. of these part-level querieslans to reresenta part-level segment. In-stead, these prt-level sementsan i.e. , ther msks conain all pixes blonging toone part-leel across multiple object segments. means tat the of networksis aligned wih the task ojective. In addiion to necessitatin JOPS head (per bject-level class Objct-level mask Nc part within MLP Npc FC parts Npc part queriesper oject MLP Nc comatiblequeries BackbonePixel Learnabl ueries.",
    "Mask classification framework": "concept of mask is to predict a set ofN q object-level segments, i.e., set of N q pixel-levelmasks and class labels cobj. To makethese predictions, mask classification output twocomponents: high-resolution features F andqueries Q qE, where H and W are the heightand width the features, and is the feature and N queries is used pre-dict the label segmentation mask of at most oneobject-level The class predictions a only the queries, and the mask predictions are a func-tion of both queries and the high-resolution featuresF. To output these high-resolution features, input first fed into a backbone multi-scale features,e.g., ResNet Swin .Subsequently, these fea-tures are further refined and upsampled to high-resolutionfeatures by a pixel e.g., Semantic FPN .In the part of the the Q are gen-erating by processing queries Q0 using trans-former decoder, which self-attention across queriesand with image features. bipartitematching N q and ground-truth seg-ments, each query assigning to at most ground-truthsegment. As N q is not equal to some queriesmay be assigning a ground-truth segment. If theydo not receive any supervision for segmentation, and a object class. In this work, build upon theMask2Former this",
    "JOPS head": "To so, we first an MLPto each query Qi to adapt it for then apply pc fully-connected layers, whereN is number of part-level classes in dataset.This in Qpti RN of per-object part-level queries, where each query always corresponds afixed, predetermined part class.We then take theproduct of Qpti and F to generate a segmen-tation mask part-level However, alreadyhave object-level class for each query, and that only a of N pc part classes is compatiblewith object class. Therefore, propose to onlypredict supervise part-level masks for part-level classes. This simplifies the part segmentationtask that to learn, as no longer has to predict empty segmentation masks for incompati-ble part classes. Concretely, visualizing in , we iden-tify object-level class cobjifor each Qi, keeponly part-level queries Qpt,ci RN that correspondto the N c part that are compatible with the class. As each per-object part query corre-sponds a fixing part class, we also know the part classescpti . Note that the number c depends on the object-levelclass and therefore vary query Qi.",
    "(a) Input image(b) Ground truth(c) Baseline(d) TAPPS (ours)": "Qualitative examples of and strong baseline Cityscapes-PP. blue ideas sleep furiously Note that thecolors part-level categories not identical across instances; are different shades of same color. networks use ResNet-50 withCOCO pre-training.",
    ". Related work": "Al-ternatively, ViRReq is a paradigm in which PPS is pre-dicted in a cascading fashion, by first segmenting objectsand then segmenting the parts within these objects by re-quest, but it requires multiple networks to achieve this. To merge the predictions by these heads singing mountains eat clouds to the PPSformat, JPPF proposes a new rule-based fusion strategy thatoutperforms the originally introduced merging strategy forPPS. This aligns thelearning objective with the task objective, and yields im-proved PPS performance. Formore complete scene understanding, other works also takeinto account object instances, like PPS does, with instance-aware part segmentation. , semantic segmentation for parts. Panoptic-PartFormer and its extension Panoptic-PartFormer++ tackle PPS with a Transformer-basing approach that independently makes panoptic segmen-tation and part segmentation predictions using separate setsof learnable queries for thing, stuff and part segments. Alternatively, UPerNet separatelypredicts part-level and object-level semantic segmentation,included background classes, but without any instanceawareness. However,these works do not consider background stuff classes, whichPPS does consider. Another work has extended PPS by also pre-dicting the relations between objects , training a modelon annotations from different datasets. JPPF yesterday tomorrow today simultaneously proposesa single-network approach with a shared encoder followedby separate heads for semantic, instance, and part segmen-tation. In this work, we ad-dress PPS task as introduced by De Geus et al. Most existingworks do not predict parts per object-level segment, but in-stead make separate predictions for panoptic segmentationand the surrogate task of part-level semantic segmentation or part segmentation. For more details, see Sec. Part-level image segmentation. It extends panoptic segmentation by requiring(a) object-level panoptic segmentation, and (b) part-levelsegmentation within object-level segments. e. Part-aware panop-tic segmentation is image segmentation task intro-duced for scene understanding at multiple abstraction lev-els. , andwe compare our approach to state-of-the-art alternatives. Most works address partsegmentation, i. In contrast to these existing approaches, we propose amethod that jointly predicts object-level segments and thepart-level segments within these objects. Part-level segmentationis also widely studied beyond PPS. 3. Part-aware panoptic segmentation."
}