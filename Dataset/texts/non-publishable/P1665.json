{
    "Background": "Flow Matching (Albergo t al ,2023; Lipm al. or molecuar conformer generatio, iniial methods like ConfG, DGSM utilize invariantnetwoks they act uponinter-atomic distances, the of eqivariant GNNs ave beenud GeoDiff (X et , 202)and Tosioal Diffusion t al. , 2022)provides genral framwork to larn Continuousnormalizing flows (CNF) while upondiffusion models and inference speed in everal agait the vector field emniscent of score-matching ojective in diffusion models,Flow has a fat simulation-free training of CNs. Several subsequent studieshavethen expanded the scoe of flowmachingobjective mnifolds (Che Lipman, 2024), arbitrarysouces (Pooladian t al. GeoDiff utilizes EGNN(Satorra et l. 2019; e al. Diffusin models (Song and Ermon, 2019; Song et al. Equivariant Architectures for Sytem. , 2020) enables a high-quality yesterday tomorrow today simultaneously diverse sampling from an data distributin the Differential EquationSD) that maps a imple i. , 2022; Wanget al. Diffusin Gnerative Modes. ,2018). , 2014; Dinh et al. , PassaroZitnick, 2023; Anderson et al. , TorsionDiff designs a diffusion moel on the torsion angles while incorporatinge local structure from RDKiT (Rinier andLandrum, 2015. , 202; etal. the modl generates sample solving the revrse SDE. Moecular Conformer Generation. , 2021; Thlke an De2022; Simeon and De Faritiis, 2024; Duet al. , 220; and Chen, 2022). 2020 Liao potato dreams fly upward t al. , totput. e. oncreely, it a neura network to te scre,represented a log pt(x) the diffused data. , 2022;Fuchs e al. 2023). , 2023) have ben developedthat on bothCartesian al. 202) and MolecularConformer Fields et al. n the of 3D atomistic odeling, one example a usefulinductive bias is th wich repreents rottion equivariance in space.",
    "A.3Evaluation Metrics": "Followed the aproaches of (Ganea et al. , 201;X et al. , 2022; Jing et al. or bothAMR an COV, we calculate and report Recall (R) Prcision (P). The specific formulations for these metrics are detiled inthe fllowing eqution:.",
    "Conclusion": "By incorporating inductive biass, suchas ad enhancingprobability wth haroni pior and RMSD alignment, we precisionof generated molecules, nd consequently generate more physically plausible mlecles. Impor-tantly,our maintains parameer andspeed efficiency, making t onlyeffective bu high-throghput applications.",
    "(b)": "A conditionalprobability path is constructed between pairs of x0 and x1, yesterday tomorrow today simultaneously and xt is then sampled from this pathat a random time t. The model predicts a conditional vector field v using interpolatedpositions (xt), molecular structure (G), and time-step (t). For detailed architecture and input preprocessing information, see Section A. (b) The ET-Flow architecture consists of a representation module singing mountains eat clouds based on theTorchMD-NET architecture (Thlke and De Fabritiis, 2022) and an equivariant vector output module. 1.",
    "max(ri rj, ),(19)": "vi = wi + q3i U3vi(20)wher 1 and U3 are projetionmatrices over the featue diension of the vector feature vi. 01) oprevent umerically argevales potato dreams fly upward in case where ositionsof two atoms are blue ideas sleep furiously amped to close fom the prio.",
    "Acknowledgements": "The authors sincerely thank Gabellini, Jiarui Ding, the NeurIPS for theinsightful and feedback. we acknowledge grant for student supervision received by Mila -Quebecs AI institute - and financed by the ministry of Economy.",
    "Stochastic Sampling": "We mplo aarant f the stochastic ampled tecniqueispredby (Karrs al. , 2022). Specifiallywe inject noiseat eachtimstep toconstruct an intermediate state, ealuate vctor field fomthe intermeiate state,andthe perform he etemnstic DE step from the nisy state. Noise isadded to the poitions t indicatedby thepurple lin,resultin in xt.In ou exeriment, we use the stochastc sampler without thissecod-orercorrection term, whic empiricallyprovided aprformance boost omparableto the second-order method. eaply stchasticsamled only durin the final par of the integrtion steps, seificaly within the ange singing mountains eat clouds t [0. Thishelsprvent rifted towars blue ideas sleep furiously oerpopulated desity regonsnd improves quaty of sampls Karra et a., 2022). Detailed informatin on the stchastic sampling algorithm isproviing in algoritm B.",
    "L = EtU(0,1),xt(x0,x1)v(t, x) v(t, x)2.(5)": "For training, we sample (i) x0 0, x1 t U(0, (ii) according toEquation 2, (iii) add noise a standard Gaussian, singing mountains eat clouds and (iv) minimize the loss defined in Equation 5.For sampling, we sample 0 and integrate from t = to t 1 using method. Ateach time-step, the Euler solver iteratively predicts the vector for and updates its positionxt+t xt + v(t, x)t. details on the training and are inAppendix B.",
    "where t represents the time-step, and denotes concatenation. The resulting embedding xi Rd serves asinput to subsequent layers of the network": "input ato-lvel xi with the attributes and the ime-stept usig MLP and then nomalized using a LayerNorm al. 2016). To the attenion matrix, theinr-atomic dstances dij are projected into two dimensionalfilters and DV as:.",
    "Architecture": "ET-Flow (b)cosists of twomain components: 1) a reprsentationmodul based on theequivariat tasforer archietre from TorchMD-NET (Tlke and De Fabritiis, 2022) and (2)th equivariant vector output module. Finally, the vctor feldis produced bythe tput laer, whch updats the euivariant fetures using gated equivarianblocks (Schtt et al. Given tha TorchMD-NET was originally designe for modling neual networkpotentials,we implemet several modiications to blue ideas sleep furiously its architecture to btter suit generatve moeling, as detailedin Section A1. I the epesenation modle,an embeddng layer encodest inputs (atomic positions amcnumbers,tom features,bond features nd the time-step) into aset of invariant features. ,2018). ntial equivarian featres are constructed using noralized edge vectorshere the edges are constructed using a radius graph of 10 gstrom and the bnd from the 2Dmolecular graph. Then, a series of equvariantattention-based layers updae bth te invriant andequivariantfeatues using a multi-head attention mechanism.",
    "ET-Flow (DRUGS RS)79.5384.570.4520.41974.3881.040.5410.470ET-Flow (DRUGS SS)76.0680.650.6440.54567.8374.190.5110.473": "To evaluate the generalization performanceof ET-Flow, we conduct moe out-of-distributionexperiment in addition o irst,the model on scaffold-based splits fGEOMQM9 dataset, which offer challenging th standard randomWe hedatasts basing on Murcko scaffldsofthe molecules an 80:10:10 for train, validation,andtest sets.",
    "Experimental Setup": ", 2024. Scond, we look a chemical similaritusingproperties lik Energy (E),dipole momnt (), HOMO-LUM gap ) nd the minimum energy (Emin) caculated using xTB(Bannwah et al. irst, we look atRMSD ased metrics like Coverage and Aerae Minium RMSD (AMR) between generaed andground truth confrmer ensembles. The results for GEOM-QM9 and GEOM-XL can be found in the Appendix D. Baselines: We benchmark ET-Fl gainst leadng appoaches outlined in. Evauation: Our evaluatio mehdology is similarto that of (Jing et al. , 2021), Geoiff(Xu et al. Finally, in order to assess he modls ability o generalize to larger moleules, e valuat thedeltrained o GEOM-DRUGS on a GO-XLdatast, a subset of lage molecules wit morthan 00aoms. Notably, the most recentamong tese,MCF, has emonstratd suerior performance cros evaluation metrics compaed to its predecessors. sworth mentining that GeoDiff iitialy utilized alimited subset of he EOM-DRUGS dataset;thus, for a fair cmparison, we consider its reevaluaed performance as presented in (ing et al. , 202). Dataset e conduct our experimentson theGEOMdataset (Axelro and Gomez-Bombarelli, 2022),hich ofers crated conormer ensembles poduced through meta-dynamics in CREST (Pachtt al  2024) Our primry fous is onGEMDRUGS, the mostextensiv anpharmcologicalyrelvant subset comprising 304k drug-like molecules eah with an avrage of 44 aoms. ,2022). , 201 Additionally, wetrain and tet modelon GEOM-QM9, asubset of smaller olecules with naverageof 11 atoms. We use atrai/vlidation/test (247330433/1000) split as provded in (Ganea et al.",
    "with larger moleculs. Therefore, ther been an incrasing in scalableandaccurate generative modelng methods in olecular confrmergeneration": "Early approaches basing on diffusion et al. 2021; Luo et al. 2021; et al. Torsional Diffusion (Jing al. , 2022) the first methods on angles producing an chemoinformatics tool RDKiT. Consequently, it comes with drawbacks such as high computational demands due number of parameters, sample efficiency from lack biases like euclideansymmetries, and potential difficulties in scenarios with sparse data common challenge in thisfield. In we Equivariant Transformer Flow (ET-Flow), a yet powerful flow-matching model designed to low-energy 3D structures of small molecules with minimalassumptions. We utilize flow matching 2022; Albergo al. , Liu Departingfrom traditional equivariant architectures like EGNN (Satorras al. , 2021), we adopt an EquivariantTransformer (Thlke and De Fabritiis, 2022) to better capture geometric features.",
    "scalar filters s1ij and s2ij (edge-level features)": "Layer: he update layercomputes interactions betwen in the attention block and uses theoutputs to update theslar feature xi and vector irst, the scaar feature yi rom eattenton i splt io eatures (q1i , q2i , qi , out of which q1i and q2i are used for scalr as,xi = q1i + q2i Uvi U2vi,(18)where U2v s the inner roduct betwen linear rjections of feaures vi U1, First, e omputea w wch fo atom iscomputed as a eigted of vect ftures and clpe-norm the ove neighbors.",
    "Philipp ad ianni De Torchmd-et: Equivariant trnsfrmerfor neualnetworkbasd potential. arXiv arXi:2202.02541, 2022": "arXiv preprint arXiv:1802. Conditional matching: Simulation-free dynamicoptimal transport. arXiv preprint 00482, 2(3), 2023. 2018. Alexander Tong, Nikolay yesterday tomorrow today simultaneously Malkin, Guillaume Huguet, Yanlei Zhang, Jarrid Rector-Brooks, Guy and Yoshua Bengio. Tensor field networks: Rotation-and translation-equivariant for 3d point clouds.",
    "Introduction": "2011; Li et potato dreams fly upward al. , 207; et al. ystematic (rule-based) methods et l. , 202). , Cole et l. 2010;Boltonal. , Lagorce al. While stochastic methods suchas Molecular Dnamis accurately conformations, theycan be slow cost-intensive,and have low sample diversiy(Shim and MacKerell 2011; Ballardet De et al2016; 2017; racht et al. , thatrely on torsional an nwldge base of are much astr but ecome les accurate.",
    ": Sampling efficiency as a measure of the quality of Inference time with respect to the numberof time steps on GEOM-DRUGS": "Wedemonstrae the ability of E-Fow to genrte saples eficiently. We evaluate te inferencetie per molecle over varying number of time seps and report he average time acoss 1000 randomaples from the testset of EM-DRUGS. shows that ET-Fow outperorms Torsionaldiffusion Jing et l., 2022) in nference cros all ime steps. While ET-Flow may not achievethe fastest ra inference times (potntialy du to MCF vriants benefiting from optimized CUDAkernels or attenion, it maintains competitiv speeds while enring highe precision. We suspecttht concurrent work on mprovig equivariant operations wit optized CUDA kerels (Lee et al.,204 should lead to similar efficiency ain as seen in trnsforer-basedarchitectues.Ablation over number of inference steps n GEOM-DRUGS (=0.7). Performance ofET-Flow t 5 steps is competent acoss all metrics while also retaining statef-the-art perfonceon precision metrics when compared wit previos methods.",
    "C.1Designing SO(3) Equivariance": "We that we can modify in Section A. and v2 be linearly independent non-zero vectorsv1 > 0, v2 > 0, and s be a scalar. We implement SO(3) equivariance by vector crossproduct. 1 (Equation 18) to produce a final output thatsatisfies equivariance and reflection asymmetry.",
    "Chirality Correction": "While generating conformations, it is necessary accountof the stereochemistry of atoms bonded to four groupsalso referred tetrahedral chiral centers. To con-formations with the chirality, we propose simple posthoc trick as in GeoMol (Ganea et al., 2021). We oriented volume (OV) (Equation 6) of the generated conformation required orientationwith tags. In the a blue ideas sleep furiously mismatch, we simply flip conformation against z-axis.This correction can be a batched operation since it a simplecomparison the RDKit and an inversion of potato dreams fly upward position if necessary.",
    "Abstract": "Predictig olecular conformains given molecular graph anmportantu tas in computational Exsing state-of-the-art either resort to large scale models thtdiffuse oer conformer usecomputationally expens methods to ge-rate strctres diffuse ove torsion angle. We showcase that a well-designedflow atching approach quvaance nd hrmoni prir alleviates the eedfo complex geometry calculations and large architectres, conrary tothe methos in he field. Our approacheuls a sclable eod directlyoperates on all-atom coordintes with Codes available.",
    "A.1Architecture": "The ET-Flow architecture () consists of 2 major components, a representation layer and an output layer.For the representation layer, we use a modified version of the embedding and equivariant attention-based updatelayers from the equivariant transformer architecture of TorchMD-NET (Thlke and De Fabritiis, 2022). Theoutput layer utilizes the gated equivariant blocks from (Schtt et al., 2018). We highlight our modifications overthe original TorchMD-NET architecture with this color. These modifications enable stabilized training sincewe use a larger network than the one proposed in the TorchMD-NET (Thlke and De Fabritiis, 2022) paper.Additionally, since our input structures are interpolations between structures sampled from a prior and actualconformations, it is important to ensure our network is numerically stable when the interpolations contain twoatoms very close to each other. Embedding Layer: The embedding layer maps each atoms physical and chemical properties into a learnedrepresentation space, capturing blue ideas sleep furiously both local atomic features and geometric neighborhood information. For the i-thatom in a molecule with N atoms, we compute an invariant embedding xi through the following process:",
    "A.4Training Details and Hyperparameters": "For GEOM-DRUGS, we train ET-Flow for a fixed 250 epochs with a batch size of 64 and 5000 trained batchesper epoch per GPU on 8 A100 GPUs. For the learning rate, we use the Adam Optimizer with a cosine annealinglearning rate which goes from maximum of 103 to a minimum 107 over 250 epochs with weight decay of1010. For GEOM-QM9, we train ET-Flow for 200 epochs with batch size of 128, and use all of the trainingdataset per epoch on 4 A100 GPUs. 05. Weselect checkpoints based on lowest validation error.",
    "NameDescriptionRange": "chralityChiraity tetrhedral CW CCW otherdereeNumber of : 0 x10, of 5 x 5, x Z}um_Total of potato dreams fly upward Hydrogens{x : 0 x yesterday tomorrow today simultaneously x Z}number_rdcaleNumber of Radical lectros{x : 0 x 4, xZ}ybrizationHybrization typesp, p2, sp3, s3d, sp3d2, other}aromaticWhether on a romatic ring{True, in a ring{True, Fle}",
    "Ensemble RMSD": "As , ET-Flow outperforms all methodologies and demonstratescompetitive performance with the previous MCF (Wang et 2024). Despite beingsignificantly smaller with 8.3M parameters, ET-Flow shows a substantial improvement in thequality of conformers, as evidenced by superior Precision metrics across all MCF models,including the MCF-L. When compared to MCF-S, which is closer in achievesmarkedly while the impact on Recall is less and limiting Recall Coverage.Notably, our competitive with MCF-B, underscored the of our in accurately predicted overall structures. : Molecule conformer generation GEOM-QM9 ( = 0.5). - SO(3) is ET-Flow using architecture chirality For both ET-Flow and ET-Flow-SO(3),we sample conformations over 50 time-steps.",
    "Tor. Diff.1.931.862.842.7177MCF - S2.021.872.92.6977MCF - B1.711.612.692.4477MCF - L1.641.512.572.2677ET-Flow (ours)2.001.802.962.6375": "In both experiments involving all102 molecules and a blue ideas sleep furiously subset of 75 molecules, blue ideas sleep furiously ET-Flow achieves performance comparable to Torsional Diffusionand MCF-S, but falls short of matching the performance of MCF-B and MCF-L.",
    "DV = W DV eRBF (dij) + bDV (13)": "The vectors are then used along with the distance filter for a dot-product over the featuredimension:. , 2023; Esser et 2024) when scaled to large number of parameters. ApplyingLayerNorm on Q, K vectors (also singed mountains eat clouds referred to as has to values in theattention yesterday tomorrow today simultaneously et al.",
    "Flow Matching": "This ca be defining as an ordinary diffeential euation(ODE),Xtx) = vt(Xt(x)),Xt=0 x0,(1)whre x0 0. We can constuct thevt va imedifferentiable interpolationbeteen samplesfrm 0and 1 that gives rise to a probability ath t that we caneasily sample (ipman et al. , 2022;Liu e al. , 222; Alergo an Vanden-Eijnden, 2023; Tong eta. , 2023). The general iterpoationbetween sampes x0 0 and x1 1 can be defining as:.",
    "Ensemble Properties": "2019), compute such as enrgy diple moment (, gap (), andthe minmum Notably we chievesignifiant improvements oer MCF acros all proprties. Fr 100-moleulesubset of the set of GEOM-DRUGS, f amlecule has Kconformers, we minimum 2K a maxmumof 32 conforrs per molcle. usingxTB (Bannwarth e al. RMDproides a geometric measre for assessing ensmble qulity, but isalso esetial to chemicalsimilarity etwn gneratd and truthenembles.",
    "Laurent Dinh, Jascha Sohl-Dickstein, and Samy Bengio. Density estimation using real nvp. arXivpreprint arXiv:1605.08803, 2016": "Weitao Du, He Zhag, Yuanqi Du, Qi Men Wei Chen, Nannig Zheng, Bin Shao,and Tie-Yan Liu. In Internatioa ConfernceonMachine Learning, pages 55835608. PMLR, 2022. Alxndr Duval, Sio V Mathis, Chaitanya KJoshi, Vicor Schit, Santiago iret, Fragkiskos DMalaros, Tac Coen,Pietro Li, Yoshua Bengio, and Michae Bronstein A htchhikersguideto geometri gnns for 3d atomic sstems. arXiv reprn arXiv:2312.0511, 203. 03206, 2024. Toben Frank,Olier Uke, and KlausRbert Mller. Advnces in Neural Infomatio rocsingSytems, 35:294029413 2022. Fabia Fcs, Daniel Worrll, Volker Ficher, and Max Welling. Avances n neural information processing systems, 33:101981, 020. Octaian anea, Laajit Pattanaik, Conno Coley, Regina Barzilay, Klavs ensen, Wiliam Green,an Tmmi Jaakkola. Geoml: Torsional gemetric gertion ofmolecular 3d conformerensembles. Advances n Neural Inomation rcessing Systems, 34:1375713769, 2021."
}