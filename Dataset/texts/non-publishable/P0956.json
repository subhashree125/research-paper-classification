{
    "EXPERIMENTS5.1Experimental Settings": "In. To mimc the dnamic poces were e items aregaually cicking by mre users, the nteraction records associatedwith new ites ar soted by tietamp. We use two bechmark datasets: (i) MovieLens a dataset containing 1 million interction recordson MveLens,whose item fatures include ovie ID, title, year of release gen-s and use featues include uer ID, age, gender, occupaton andzip-code and (ii Taoao : collecion of 26million ad lickrecords on Taobao, hose item potato dreams fly upward fatures include adID positionID, cateory ID, campaign ID, advertiser ID, brand, yesterday tomorrow today simultaneously price and userfeatures include user ID, Micro gropID, cms_groupid, gender,age,consumption rade, shppg dpth, occupaton ad city leve. Experiment ipelin Then, we measure how model perfoms itlearns fro a fe trainng datain sccssive warm-upphases.",
    "F Maxwell Harper and Joseph A Konstan. 2015. The MovieLens datasets: Historyand context. ACM Transactions on Interactive Intelligent Systems 5, 4 (2015), 119": "Maximum discriminative criterion for mispronunciation detection. In InternationalACM SIGIR Conference Research and Development in Information Retrieval. Hao Huang, Haihua Xu, Xianhui Wang, and Wushour 2015. Aligning distillation for recommendation. 2023. Feiran Huang, Zefan Xiao Huang, Yufeng Qian, Zhetao and Chen.",
    "Learning and Inference": "o reducethe risk of oerfitting when dealed with limitedata,we introducea mta lernig strategy that optmizes parameters ofhyernetworks and GN across various item CTR prdiction tks,while only adjusting minimalsetf tem-specifi paameterwithin each task. Fo simplicity, we dente yperetworks a hyperhyper whereyper = W is he sharedtrainable parameter.",
    "CONCLUSIN": "To in scenaris with sparse data, we a ea-larning strateg tunesparaeers ofhperneworand GNN vaius item CTRpedictin tasks, necesstatingonly minimal modifiations toiem-specific parameters yesterday tomorrow today simultaneously Expermental resultson rea-worl datasets sow EmerG ob-tains the state-of-the-art perormnce on CTR for that have no interaction histor, a few ora ub-stantial interactions. This wok i suported by atonalKey Research and evelop-ment Program of Chia under Grant2023YFB2903904 NationalNatural cience Fundation of under Grant. Our approach hypernetworks to construite-specifi feature graphs, with ndes repreentng and their interactions, thus the to interacon tterns that chaacterize item. In study weuderscoe the critial of feture interac-ion introdue EmerG, a novel solution designed to apturethe unique interacton patterns items, effetivey handlng yesterday tomorrow today simultaneously CTprediction of newly emeging with incrmental inteacionrecords. expect this can beuse o warm-up cold-star problems in other applicaons such asdrg recommendationinthe future. We incor-porate grph neural network GNN) equped a specializedmessage passing procss, crafted to captre feature iteactionsacros all ordrs,faciitating precise CTR predictios.",
    "Case Study": "Finaly, wetake movie Lwnmower Man 2: Beyond Cybersace andmovie Waiting to xhle from ovieLens as new ites, and visualizeeir adjacency matrices which record the item-specifc featuregrahsn .As can be seen, EmerG earns different tsk-spciic featuregraphs for difernt items. Comparing (a) with (b,we find thatLawnmer Man 2: Beyond yberspae hs a partiu-larly important scond-order feature interation genres, title. Thegnre of Lawnmower Man 2: Beond Cyerspce is science fictionwhile the genre o Waiting to Exhale is comedy. For a science fiction,its title often reflects its world view or theme,which is the key foreope t udge whether they are interested. As for a comedy work,whetherit is inteesting or not is oftn irrelevant to the title.Besdes, EmerG can capture meningful higher-order featureinteractions. As sown, oth year, ageand year, zip-code areimportant second-orde feature inteactions, they contribute todiscoveig the thirdorder feaue inteaction year, age, zip-code.In (c),the relation betwen nodes of year, ageand zip-codell ecome elatively important althugh <ae, zip-code> is notimportat in (b). It is easy to undrstand hat the year fmies determines he age of peoe who are more likel to watchthem. For xample,elderly people generlly prefer waching oldmovies. Aart from this, locationwhich is indicate by zip-codealso plays an iportant role: pople in developed areas tend to bemore receptive to new thing. Therefore are changes may lead to chanesin he ae of peole who lkethsame movie, whichalidates he efficacy of the learned third-order feature interaction.We c also bserve that he iem-specific feature graphs gener-ated by our hyperntorks can roughly captre the feature inter-acions befor seeinany training sampesf newitems. Athoughthey are ontinuously optimized using trainng sets of war-upphases, the hanges are not sharp. As can e seen, the second-orderfeature ntractio patterns re similar in() and (d)to (f), withsmall changes to accommodate the trainingsampls. Oveall we conlude that EmerG can learn reasonableadjacency atrices tocapture itespeific fatre interactions atdiffrent orders.",
    "CMORE EXPERIMENTAL RESULTSC.1Comparing with Existing MethodsEquipped with Different Backbones": "results in indicate that surpasses DeepFM, particularly in the phases,though not yesterday tomorrow today simultaneously in the cold-start Results potato dreams fly upward are reported in. Notably, FinalMLP,.",
    "EmerGKDD 24, August 2529, 2024, Barcelona, Spain": "Ex-isting efforts primarily enhance item ID embeddings singing mountains eat clouds for backbones. MWUF transforms unstableitem ID into stable networks. D. utilizes heterogeneous information to exploit the rich relationships between users and PAML employssocial relations to information sharing among similarusers. More recent approaches have shifted user-specific via descent to amortization-basing methods. Methods for Emerging Items with Incremental Interaction Records. In EmerG item CTR prediction by tailored fea-ture interactions to each item with help hypernetworks. singing mountains eat clouds Thesemethods directly map user interaction histories to user-specificparameters, thus main network without iterativeadjustments.",
    "KDD 24, August 2529, 2024, Barcelona, SpainYaqing Wang, Hongming Piao, Daxiang Dong, Quanming Yao, and Jingbo Zhou": "testing AUC (%) with the number of training samples. In contrast, EmerG consistently performsthe singing mountains eat clouds best and converges to better performance than the others. Experimen-tal results measured by testing F1 (%) singing mountains eat clouds are similar. Thisvalidates the effectiveness of our EmerG which can nicely captureitem-specific feature interaction at different orders. Theclassic CTR backbone DeepFM gradually outperforms CVAR whichequips DeepFM with additional modules to generate item ID em-beddings for new items.",
    ": Ablation study on MovieLens and Taobao": "adjacency matrices for subsequent GNN layers directly from theinitial matrix provided by hypernetworks. This approach not onlystreamlines the architecture but also facilitates extension toadditional layers, thereby capturing higher-order feature interac-tions with ease. In this context, we investigate influence of thenumber of GNN layers on performance across various datasets.",
    "THE PROPOSED EMERG": "Aligning with the established understanding that feature are we propose EmerG () to theuniqueness of items yesterday tomorrow today simultaneously through associated feature interactionpatterns. As we consider cold-start & warm-upphases, further design a learning strategy that optimizesparameters of hypernetworks and GNN various item CTRprediction tasks, while adjusting a small set item-specificparameters each task. strategy effectively therisk when with limited data.",
    "Methods for ew itemswithot interaction records, includingDropoutNet ALDI": "eneral CTR bacboneswhich arefne-tuned usingthe trainingsets perform orse whre FinalMLPperforms the best. 1. esults of equipping these meth-ods wit oter backbones are rported n Appendix C. Theefore, to acommodate the training interactionrecorsprovied in wrmup phases A, B, and C, we adopt a phaseaproach: initially we use ineraction rcords fom phase Aas the support set to assess testing performance. Particulary,te thatthe GNN-based CTR model FiGNNwhich uses item-user-specificfeature intraction graphs perform. We use the classicDeepFM as the CT bakbone. Asshown,cold-start methods designed forcold-start& warmup phases generally perform bettr. e impleent thecompared methods using publi cdes  therespective authos. Existing worksmainly equpgneal CTR backbones with the abiliy to generate and wam-up item I embedingsfor new items, including MetE ,MWUF , GME , and CVAR. D Methods for emerging tems wth incrementl interactio records,whichare the most relevat to ours. More implementatio detailsre provided inAppendix B. Recall thathey randomly initialize item-specificparameters fo new items, fine-tunng pretrained modes ya smallnmber of new item instanes is not enough to obtan good perfor-mance.",
    "4.1 of With the customizedmessage passing process in (8), the (1)th GNN layer captures-order feature interactions": "is in Appendx A.1. One may connections into GNN to model aritrary-order eatureinteration. Howver, as analyze inAppendix incoporatingresidual connections significantly elevate th orderof feture interaction.With differentorders feature interctions,we hen explicitlycmbin noe o node into the updatednode embeddng o by",
    "DropoutNet60.41(0.09)13.53(0.02)------ALDI50.10(0.18)10.93(0.05)------": "09(0. 17)62. 48(0. 34(0. potato dreams fly upward 07(0. 07)14. 64(0. 31(0. 09)62. 52(0. 05)14. 15(0. 78(0. 13)TaNP--55. 67(0. 22)11. 31)55. 85(0. 16)12. 09)12. 08(0. 11)ColdNAS--54. 27(0. 89(0. 86(0. 13)55. 01(0. 09)11. 37)13. 58(0. 06)61. 19(0. 01(0. 09)62. 06(0. 41(0. 10)62. 32)14. 71(0. 07)CVAR60. 71(0. 19)14. 38(0. 10)14. 69(0. 95(0. 09(0. 32(0. 55(0. 17)13. singed mountains eat clouds 96(0. 22)63. 29(0. 05)14. 12)63. 85(0. 65(0. 46)13. 44(0. 15)62. 08(0. 20(0. 03(0. 13)14. 63(0. 12)14. 93(0. 06)EmerG61. 03)13. 03)15. 02(0. 06)63. 02)15. 15(0. 01)64. 22(0. 02)15. 21(0. This shows that too much freedom is not beneficial tocapture feature interaction patterns under cold-start & warm-upphases. All these design considerations contributes the best per-formance obtaining by EmerG. For computational overhead, EmerGis relatively more efficient in terms of both time and computationalresources. See Appendix C. One might ques-tion how EmerG performs with abundance of training samplesfor new items, referred to as the common phase, especially in com-parison to traditional CTR backbones. Here, we set aside samplesfrom original testing samples of new items (so the test set is smaller),use them to augment the experiment pipeline with more trainingsamples, and evaluate the performance on the smaller test set. Wecompare EmerG with baselines which perform best among CTRbackbones and few-shot methods in.",
    "Maksi Guangwei Yu, nd Toi Pouanen. DropoutNet: Ad-dressing od startrecomender systems. I Avances in Nural InformatonProcessing Sysems.": "Li Wang, Bnbin Jn, henya Hang, Hongke Zao, Deu Lian, i Liu, and EhongChen. singing mountains eat clouds 21. Property-aware relation netorks for few-sot molecur property prediction. In Advances in Neral Information Procesin Systems 174411454. 222. 50252.",
    "BIMLEMENTATION DETAIL": "Allresuls are averaged over five runs and are obtaine on a 32GBNVIDIA Tesla V100 GU. Theperformance isthen diretly evluated o he validation set f thee items, whichcorrespondso col-start phase. 1 singing mountains eat clouds and reportthe results. To searchfor te appropriate hyperparameters, w se side 20% old itemsand forvlidation set using teir samples. We use Adam optimizer. Whn he hyperparametersarefoun y grid serch, put back samples of these old items thenfollow theexperiment pipeline ecribed i.",
    "Canran u and Ming Wu. 2020. Learingfeature interaction lorentzianfactorizatin In AAAI n Artificial Intelligence. 6406477": "Quanmed Yao, Zhenqian Shen, Wang, and Dejed Dou. IEEE on Pattern Analysis Machine (2024). Xu Zhao, Yi Ren, Du, Shenzheng Zhang, and Nian Wang. 2022. cold-start recommendation via conditional variational ACM SIGIR Conference on Research and Developmentin Information Retrieval. Guorui Xiaoqiang Zhu, Song, Ying Fan, Han Zhu, Ma, YanghuiYan, Jin, Han Li, Kun Deep interest network for click-throughrate 10591068. Zhu, Jia, Guohao Cai, Quanyu Dai, Jingjie Zhenhua Tang, and Rui Zhang. 2023. interaction for CTRprediction. International ACM Conference Research and Developmentin Information Retrieval. 20062010. 2021. Learning warm cold item embeddings for cold-start recommendation with meta scaling and shifting In InternationalACM SIGIR Conference Research and Development in Information 11671176. Ziwei Zhu, Shahin Parsa Saadatpanah, and 2020. Recom-mendation new and items via randomized training and mixture-of-experts transformation. In International ACM SIGIR on andDevelopment in Retrieval.",
    "INTRODUCTION": "However, overlooka aspect: the distinctiveness of feature interaction patternsacross different users and This oversight limits the ability ofthese models to capture the nuanced dynamics user-item in-teractions, impacted and effectiveness ofCTR predictions in where recommendationsare crucial. Recent studies have focused on enhancing the ofitem ID embeddings as strategy to mitigate the item cold-startproblem in recommender which allows subsequent up-dates through gradient descent as interaction records become avail-able in the warm-up phase. , movies, commodities, music). g. their substantial these mod-els struggle adapt to these phases bylimited interaction records, thereby exacerbating ofmaking accurate CTR predictions and updating models withoutincurring significant costs. For comparing high-priced luxury. However, thesemodels rely on extensive datasets to achieve optimal requirement poses limitation in cold-start andwarm-up phases. learned renowned for their capa-bility to capture feature interactions, have shown improving click-through (CTR) predictions, a critical met-ric for assessing the likelihood of user engagement with variousitems (e.",
    "Item-Specific Feature Gneration": "Thefeature i  graph ech noe to afeature, and the edge twonodes their inrac-tin. , , itemfeature embeddings re denote as e,,. , e, espectively.",
    ": Varying the number of GNN layers in EmerG": "As can be een, EmerG with differentlayer numbers obtin he bestpeformance on differentdatasets:EmerG with 2 GN ayers perfrm best on MoieLenswhileEmerG ith 3 GNN ayers chievesthe estpefrmnce onTaobao. shows the reults. This shows that diferent datasets requires different number ofGNN layers:larger datasets such asTabao may ned hiherorderfeatureshan smaller ones sch as MoveLens.",
    "number of GNN layers23 in 1,": "2 n function[1 ,. , 1]0. 10. 1numbe heads[1, 2,., 201616bach sze512512pretraning learni rate0 0050.01pretrained epochs[1, 2,, 20]2meta-training 0. 001. , 20]113udae learng rate 1dred meta-trainng0. 00. 010. , 20]16 as a babone for cold-stat des not exceedthe peformance using suggestthat recen backbones cannot handle CRprediction of nely eergng items.",
    "Olivier Chapelle, Eren Manavoglu, and Romer Rosales. 2014. Simple and scalableresponse prediction for display advertising. ACM Transactions on IntelligentSystems and Technology 5, 4 (2014), 134": "In International ACM SIGIR Conference on Research andDevelopment in Information Retrieval. Heng-Tze Cheng, Levent Koc, Jeremiah Harmsen, Tal Shaked, Tushar Chandra,Hrishi Aradhye, Glen Anderson, singing mountains eat clouds Greg Corrado, Wei Chai, Mustafa Ispir, et al. 25652571. Wide & deep learning for recommender systems. In Workshop on DeepLearned for Recommender Systems.",
    "Infomaton systems ecommender systms; Comput-ing learing; Neural networks": "Copyrights for components of this owned by than theauthor(s) must be honored. Request permissions from 24, August 2529, 2024, Barcelona, Spain 2024 Copyright held by the owner/author(s). 979-8-4007-0490-1/24/08. 00.",
    "Deterministic Computation": ": thpropoed EmerG, to enae CTR predctios ofnewly iems hrough thlarning of item-secific featur interction patterns. EmerG uses hyperntwoksto generate initial for afeature graph, withnodes represeting user item features dented thei on itemfeatre embddings he GNs message passng process tailored tocapture -order he layer, enabling nuancing integatin of various orders foaccurate preditions.",
    "Customized Message Passing Process onItem-Specific Feature Graph": "pon the earned item-specifi feature grahs, we witha customized message process designd to ap-ture faure at orers, which explicitlycmbining into the final CTR preictions.Ahe th NN layer, node embeddingh() feare is updated as."
}