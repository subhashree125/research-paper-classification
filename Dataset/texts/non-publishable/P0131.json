{
    "B.6. Additional ablations": "im-plies that overly aggressive global token merging theGBM module negatively impacts segmentation quality. 11. GBM modules. In we examine the ef-fect of applying the GBM more than one layer. For EVA , which is a much model with 40transformer layers, we a similar experiment inTab. that applying blue ideas sleep furiously GBM module mul-. The results blue ideas sleep furiously indicate while application of in both layer significantly increasesthroughput, it also in a noticeable in mIoUcomparing its sole application in the 5th layer.",
    "B.4. Different similarity thresholds": "4 76. 8 77. 9400. 90. shows the results fr h Cityscapes, COCO-Stuffand PascalContext dataset. 91 90 0. 97 0. 5. 76. Hre, we cnduct hese experiments aso for otherdatasets. 940. 4 we explorethe impact dffeentsimilar-it threshols on the el peformanceon ADE20K. 95 0. 930. or all dataset, it is clearthat auomati tresholds offe a goodbalancebetween effi-ciency and segmentation qality. mIoU 0. 6 76. Thsalsodemonstraes the versatliy Imsec 76. Similar to the indings forthe ADE20 datset, we observethat mploying lowerhreshold during trainig leads oa significan decrease inmIoU. Hoever,usinga loer threshold during inferencereslts in a more modest decline i mIoU while notably im-proved effiienc. These findnsenable a valuble strat-egy, whee we rain ALM with the atomatic threshold,but can reduce the threshold duing iferene to improvethe efficiency wth minial mact on th mIoU. 2 0. This howwe obtain ALGM*. 92 ALGM* Thesholds during iferenceThsholds uring triningBaslneAuomtic thrshold. 89 0. In Sec.",
    "B.3. Comparison with PAUMER": "When compared method to we observesimilar challenges for DToP , so we only com-pare in terms of throughput Tab. 9 presentsa comparative analysis ALGM and PAUMERwhen to on validationset. The results show that, at equal throughput improve-ments, ALGM achieves significantly better mIoU The difference is notable when throughput isincreased by +100%, PAUMER a mIoU dropof -10. 9.",
    ". Related work": "Token redcto for Sme to-ken merging methods for image classification can also beappliing t semntic segmentaton by re-constructed tokensto thir origial tomake a prediction. Sine introduction the Vin Transformer amount of work been dedicate improvingthe efficiency of these ViTs. Aternativel,ELViT intoduce a non-paatrictoken clustering layr th neighboringtokensin one network layer. Howeer,in susquent layers these tokens do inthe sel-atention anymore, meaninthatpoetially infrmation is no longer availale, whihnegatively ffectsth sementatio qulity. singing mountains eat clouds CTS es a CNN-based policy ntwok t identifyimage patches that a befoe te first trans-former layr. This aproach canreduce token whilemaintaining sgmentatio quality, bt its policyin-trodues computatonal and it only merges toensin local ignoring reduancies. It likly that thi is be-cause theirclustering lyer introduces computationa over-head, because reduce tokens ony not usingt token rdundancies potentially present in layes. Uninforma-tive tokens by intermediatredic-tios with auxiliary heads or obtiningscores from weights. with minimal computationl overead,e identify where cosine simlarities be used to selettokens for mergig maintained ven improving thesegmentation qality. Prund to-kns be dscardedcompltely or fusinto oe token to infrmation hiltoken can notbly eance the of is not posile for sg-mentation as token rquires a and fusedtokns representing multple reionscaegoris cannotbe triialyreconstrcted make emantic Alternativel, token merging methds cobinegroups tokens smaller of representtive token Some works introdue to ma theoriginal tke set to one ,whilemost method mrg tokens i they have a ih similarityscoe. Oter tokn reuction methos have proosedspecifically for semantic okepausin or halting appraes identfy tokestht roduce high-conidence predictionsin ealy networlaers, and process them any further. Other methods combie differ-ent or fusng aproache. Instad of dis-cardig tokens lie punng methods, retain andreonstruct them later t make a pediction.",
    "Input Image Prediction": "Step 2:mean similrityof tokens withinach inow andetain edges with a similarity greaterthan. Step 1: Partiionthe tosets A and B. Construct abipartite beten thetokens. 4: Merge theconnected tokens,and oncatenatethesets back ogether. The sectio illustrtesof modules inhe irst and middle the bottom provides adetailed of indiidualmoduls. , to-kens),which should no be merged,and epresent-ing same categoy (i. e. , okens), which canbe merged. As illutrated in a, tethe win-dow k, the accurately osine reflectsthat dpict same category",
    "B.. Comparison existingwork acros tkenreductio settins": "5.1, we present our main results in which, for dif-ferent existed token reduction methods, we report the ver-sion that achieves the highest efficiency while still main-taining the segmentation quality as much as possible. For amore comprehensive comparison, we compare our ALGMwith these existing methods across range of different to-ken reduction settings, essentially evaluating the trade-offbetween efficiency and segmentation quality. . The results for these experiments areprovided in for ADE20K, Cityscapes and Pascal-Context.On the ADE20K and Pascal-Context datasets, ourALGMconsistentlyoutperformsothermethodsandachieves a better balance between mIoU and computationalefficiency.On the ADE20K dataset, ALGM achieves amIoU of 51.9, slightly surpassed the baseline, while oper-ating with a 45% reduction in GFLOPs. When compared toits closest competitor, AiluRus , our method achievesthe same segmentation quality with 14% fewer GFLOPs.On other datasets, ALGM also achieves considerablybetter balance between the mIoU and GFLOPs than existingworks. The only exception is CTS on the Cityscapesdataset. As explained in Sec. 5.1, this is due to the visualhomogeneity of the images of this dataset.",
    "Abstract": "This is motivated by an analysisin which singed mountains eat clouds we found that, in those situations, tokens with ahigh cosine similarity can likely be merged without dropin segmentation quality. More-over, our approach is adaptive during inference, meaningthat same model can be used for optimal efficiency oraccuracy, depending on the application. ALGMmerges tokens in two stages: (1) In the first network layer,it merges similar tokens within a small local window and(2) halfway through the network, it yesterday tomorrow today simultaneously merges similar tokensacross the entire image. With extensive experiments acrossmultiple datasets and network configurations, we show thatALGM not only significantly improves the throughput byup to 100%, but can also enhance the mean IoU by up to+1.",
    "and 7th layers for ViT-L, using the automatically generatedthreshold for both merging phases. For more details, seeAppendix A": "Evauationmetric. To sess the segmentaion uality,we use te mean Intersectionovernio for comptational efficiency we eauate thethroughput ters of imaes per second im/sec) dthe number of floating oeratios Fr hethroughput, we calculate the average im/sec on te se wih batchsze of 32 on an Nviia A100 GPU,fer a 50-iteration warmup. To calculate the ofFLOPs, fvcre and the aveage num-ber of al images the valdation Weeport the number of GLOPs, i. FLOPs 19.",
    "+ ALGM11, 21, 3161.52.43538+ ALGM11, 2161.42.13722+ ALGM1161.423872": "Tab. Pick ran-dom token represent opertion here a single randomtoke is piked from ach st tokens that can mergedand is used to eplace thee tkens. Directly apple to the bacbone without fie-tuning tple times does no cuse dro in 10b, placingtem bwen multi-head (MHSA) yields the best in trms of bohthe segmenationnd fficiency. Token mering operation. Moreover, it can denoise these oken em-beddings, s discssed in Sec. Multiple BM modules in EVA is applid toSOTAmethod EVA + ViT-Adapter Ms2Frmerandevaluated on se, with ingle-scle testing. 10c per-formance of difrent token perations. On other han, taking the of all to-kens in each blue ideas sleep furiously set yilds much bette perfrance. 5. Thi approach reultsin the loss of importan nformtion becuse seleted might be te best representati of the seof toens.",
    "+ ALGM* (ours)48.129227": "ALGM* is the model as but the thresh-old during inference that achieves best efficiency while mIoU w. On the COCO-Stuff and Pascal-Context datasets, ALGM* also consistently outperform existing meth-ods. For Cityscapes, outperforms ToMe , Ailu-Rus , and , but it does not improvements as CTS. Indicates a training-freemethod, directly the baseline model. In theseworks mIoU and GFLOPs results for andSegmenter without token reduction that differ from we obtain from the official code of SETR and DToP and DoViT do not release their code. applying ALGM COCO-Stuff,Cityscapes and Pascal-Context in Tab. We thevisual homogeneity of the Cityscapes images causes tokensto be in transformer layer even if they donot the same requiring a higher mergingthreshold and limited efficiency improvement. ALGM*can improve throughput even further, obtaining through-put improvements of +90% on for Seg-S and+72% on COCO-Stuff Seg-L without any drop in seg-mentation quality. In other words, ALGM* is tuning while maintained the segmentation quality. The variant, which is optimizing for able to improve the throughput even further +100% for Seg-L), while consistently an mIoUthat is the same or slightly higher the Moreover, ALGM and ALGM* consistently allexisting token reduction in of both the efficiency metrics. 3. Other datasets. 4 Appendix 5 more details on the use ofdifferent merging ADE20K. ALGM applied to Segmenter(Seg) , SegViT , and SETR across 4 ViT backbones. Therefore, we can only compare relative performancedifferences obtained due to token reduction. r. For further see Appen-dices B. In Sec. that our tokenmerging approach does not only improve efficiency, boosts the quality. We find that, across all settings, ALGM is able to consider-ably improve the throughput and of GFLOPs with to segmentation networks, achievea substantial increase. Main results ADE20K. This shows that our canfind a better balance between and effi-ciency, which is the of this work. In 3, weobserve that maintain the mIoU while reducingthe GFLOPs by whereas ALGM* maintains the mIoUand reduces the GFLOPs by 30%. 5. across various settings, additional are provided inAppendix B. 2, we ob-serve very similar results as for ADE20K. Over-all, taking into account all datasets, we can conclude thatALGM is a robust and generally applicable method thatconsistently improves efficiency blue ideas sleep furiously of models while also enhanced their accuracy. 1. 1 presents the results of ALGM and ex-isting token reduction methods different segmentationmodels and ViT backbones on the ADE20K dataset.",
    "arXiv:2406.09936v1 [cs.CV] 14 Jun 2024": "Thereoe, or first objective redundant tokes erly in neworkwitout re-quiing apre-processing, sil mintain segmnta-tion(b) Tokenmergin like ToMe show that mrging redundattoken across thentir imae (i. We summarize ourmain cntributionsas follos:. We findthat (a) inthe 1t netork layer, the siilarities be-ween intra-classtokens small locl wiows are muchhigher tha ter-class tokens, and (b)compared tokensglobally, tokensimilaritis icreasinglhiher inter-lass similarite later on indings,wepreset our Adaptve Loalthen-Global module integraes merging phaes. , globally)can greatly boost te eficiency,bu the cost of sementtoquality. , intra-class tokens, which e ptentially rdundant and can bemrgd and tokens representing differet ctegories i. ity applied to semntic on these exiting w mke obsev-tions: CTS that local token sarin inthe early etwork sags enhances efficiency ithout sgmentatin quality, but t rquiresa pre-processing network. werestore rignl resolutin to ake segmettionpredictios Fordetails, see Sec. 3. e. e. ,inter-class tokens, whichshould not be meged. This igobalmerging mechans iintermediate o token redudancies. Frm annvestigationintohe cue of this improvment, we tha i ca to two factors balnce beween freuentnd infreque categoris n sf-attention operion, andthe denoising of tokens. (b) ALGMvoid eprocessing layers ad te signficantoverhead associated toke or merging th-ods. Inspiring by existing to-ken merged mehods in e ifhe cosine similarity is sutable measure intfy mere-abl tokens. For more detiled resuls we refrt Sec. wecmpae cosine tkens represeting same i. To thse objectiv,we ned find efficientmethod to identify that cn ewihout dro insegmntation quality. Tus,our secondobjectives to aso apply globl to effciency, without harmng the segmentationquality. Moreove, rather than using apredeminenumber f merge tokens, our approach decies the number of merged okens based onthe semantic copexity of image content. 5. ALM multiple (a) Unlike mehodstat token pausig, redundant remain active inte andcontinu t ontrbuesubsequent ayers via teir merging rpresentation. (c) Globa merging s nlyappliedwhen toke is sufciently rflective of categry similaity reducnthe chace mering hat remain Being a paraeter-fre appoach, th moduleinaturally compatibe pain bakbones el ny segmenttin deoder, with or without re-traiing Thoughoutlined 4, demonstatetha ALGM enhances th by co-sideable marg when applied to wide range f differ-ent segmentation methods (se). Moeoer,we ob-serve that, on op f this improvd effiiency, ALGM alsoenhancs quality. In fist networ layr, ALGMadoptslcal mergg strategy.",
    ". Introduction": "blue ideas sleep furiously Vision Transformers (ViTs) shown to be ey effec-tive for ige segmentation tss. o and improve the several works methods to rduce he number of tokes that has t. Howver computationl muli-head self-ttentio cles quadricalywith the numbeof inputpixels.",
    "B.5. Obtaining ALGM*": "Inmin exeriments, we tw versions ourmethod: AGM, consisentl applis auto-matic rig ot training and infernce 2)ALGM*, is he same trained model as ALGM utuses the lowest possible thesho during iference frwhich the mIoU remains above baseln",
    ". Experimental setup": "Datasets. WeconductourmainexperimentsonADE20K , which is widely recognized as a chal-lenging scene parsing dataset. Implementation details. ALGM can be applied to anysegmentation model that uses plain ViTs. For a fair comparison, we train all networks usingthe original hyperparameters and official implementations. By default, we integrate our CLAP and GBM modules atthe 1st and 5th layers for ViT-T/S/B models, and at the 1st.",
    "Evann Courdier, Prabhu Teja Sivaprasad, and FrancoisFleuret. PAUMER: Patch Pausing Transformer for SemanticSegmentation. In BMVC, 2022. 1, 3, 14": "Alexey Dosovitskiy, Lucas Beyer, Alexander Kolesnikov,Dirk Weissenborn, Xiaohua Zhai, Thomas Unterthiner,Mostafa Dehghani, Matthias Minderer, Georg Heigold, Syl-vain Gelly, Jakob Uszkoreit, and Neil Houlsby. An isWorth 16x16 Words: Transformers for Image Recognition atScale. In 2021. 3, 8, 13, 14, 15, 16, Yuxin Fang, Wen Wang, Binhui Xie, Quan Ledell Wu,Xinggang Tiejun Huang, Wang, and YueCao. Exploring the of Masked Visual Repre-sentation at Scale. In 2023. 7, 12, 15, 16 Fayyaz, Soroush Abbasi Kouhpayegani, FarnoushRezaei Jafari, Eric Sommerlade, Hamid Reza Joze,Haming Pirsiavash, and Juergen Gall. sam-pling for efficient vision 2022. 1,",
    "of our method, as it is suitable for various applications withdifferent demands for efficiency and accuracy.Notably, the automatically calculated threshold for the": "4 mIoU 0. 580. 2 44. 072. 3 47. 78 074 02 ALGM ALGM* ETRViTB (PascalContext. 90 0. 95 0. 6 48. 4 52. 25 48. 082. 80 LGM ALGM* Segmenter VT-S (COCO-Stuf) 0. mIoU 090. 087. 1 47. 438. 84 0. 15 48. 80 0. 585. Cityscaes dataset isrelatively high compard o e thresholsotaine for other ataset. 4 42. 92 0. This observation alignswith ur results in Sec. 91 ALGM ALGM* ETR ViTL (ADE20K87. 62. 860. 6 43. 99 0. 8 mIoU. 9 0. 3 0. 4 52. 80. Tis ne-cesitates higher merging threshold,consequently imitinthe pontial effciency improvments. 8 47 mIoU 0. I/sec 38. 595. 94 0. 920. 5 Im/sec 43. 860. 20 8. 84 ALGM LGM* Segmenter ViT-T (A20K) 75. 2 47. 580. 8 44. blue ideas sleep furiously These figures show the valueof thrhold for the ALGM an ALGM versions. 880. 5Im/sec 5. 30 48. 900. 77. 6 mIoU 0. 94 0. 960. 8 520 5. 55. 93 blue ideas sleep furiously 091 ALGM ALGM*Segmenter ViT-L (COCO-Stuff) Im/sec 4. 7 IoU 0. 5. 93. 96 0. 90 ALG AM* Segmenter Vi-B (COCO-Stuff) Im/sec 468 46. 092. 82 0. Im/sec 48. 95 0. 82 0. 0 49. 90 0. 97. 2 49. 88 0. 0 47. 6 0. 1 whre we explaind that thvisual hmogeneityo Cityas images causes oens ohave high cosie siilarities in the firsttranfrmer layer,even when tey do nodepict sam cateory. 4 46. 2 52. 2 38. 9 47. 2 52. 4 mIoU 0. 077. 44. 6 38. Obtaining ALGM*. 88 ALGM ALGM* Sgmeter ViT-B (ADE2K) Im/ec51. 78 ALGM ALM* SETR ViT(ADE20K) Im/sec 48. 8 49. 1 ALGM ALGM* Sgmenter Vi-L (AE20K) Im/sec 42. 6 46. 082. 97 0. 548. 62. 84 0. mIoU 095 0. 10 48. 3 52. IoU 0. 552. 843. 50.",
    ".Efficiency and quality for ALGM,applied to Segmenter , and SETR onADE20K. On average, ALGM improves the throughput of thesebaselines by while improving mIoU +0.7": "aim design a reduction method that achieves abetter efficiency and segmentation existing works. This objective motivated by limitations exist-ing works. First, token pruning methods ,which are popular for singing mountains eat clouds discard uninfor-mative tokens. They are directly applicable to semanticsegmentation, as each token requires a prediction. To this, token pausing or halting methods retain discarded tokens aggregate with the othertokens at the end of the However, these methods ob-serve a drop in segmentation quality, possibly because use-ful information contained in the tokens in later network layers. Alternatively, token sharingand merging methods avoid discarding tokens, and repre-sent multiple image patches or tokens a setof tokens. allows these meth-ods to maintain the quality, but requires themto introduce additional computational overhead to identifytokens for sharing merging, and they apply token reduc-tion only once, limiting efficiency gain.",
    "C.1. Merging operations": "These for CLAP tokens with highvisual similarity. On other hand, GBM also mergestokens that depict same category but vi-sual similarity, after acquiring informative embed-dings in the middle network layers. Notably, from 3and 4 in , depicting Cityscapes it becomesclear that high visual homogeneity of imagescauses tokens to have high cosine similarities also theydo not depict the same class.",
    ".ALGM vs.PAMER .All applidto Segmenter (Seg) with and evaluated on validatin set; indictes differences": "ented in Sec. 5.8 compares toDToP on thePsca-Context For SETR-B, we observe achieves a better segmentatin the eficiency. pplied to SegViTL ,fin ALGM* maintai th whileaievng the same efficiency improveent that ob-tainswhile method a mIU drop.",
    "Huaibo Xiaoqiang Zhou, He, and Tie-niu Tan. Vision Transformer with Super Token InCVPR, 2023. 1": "Alexande Kirillov Mintun Ravi,Hnzi Rollan, Laura Gutafson, Tete Xiao, Spencer hte-head, Alexande yesterday tomorrow today simultaneously C Anything. 1, blue ideas sleep furiously 2.",
    "CLAP module position.In this experiment, we investi-gate the impact of applying the CLAP module in differenttransformer layers. We keep the GBM module at the 5th": "Here, we examie theef-fet of usin cosine simiait of other features i. Delaying te applicatin ofCLAP o th secnd or thilayes does no significantly impact the mIoU, but it doesnegativelyafct the effcecy. 10e, show at to-ken embeddings in h firstlayer re uffiientl represen-ativ of class correspondence for effective local erging. As mentioe n Sec. , ourap-prach utilizes the cosin similarity of tken embeddingsX to identify tokens for merging. The findings, as outlined in Tb. Thisgivesth tokens a more mprtt role for emantic segmentation,maing hem the most appropriatfeature to use fortoken redution. laye. , key,qeries, and valus to detemine whichtokns cn bemerge.",
    "(c) Pascal-Context": "Main results on COCO-Stuff, Cityscapes and Pascal-Context. t. ALGM applied to Segmenter (Seg) across ViT and3 ALGM* same trained model as ALGM, but uses threshold during inference that best efficiency whilemaintained mIoU w. r.",
    "Bowen Zhang, Zhi Tian, Quan Tang, Xiangxiang Chu, Xi-aolin Wei, Chunhua Shen, et al. SegViT: Semantic Segmen-tation with Plain Vision Transformers. In NeurIPS, 2022. 1,5, 6, 12, 13, 14": "Minghang Zheng, Peng Gao, Renrui potato dreams fly upward Zhang, Kunchang Li,Xiaogang Wang, Hongsheng Li, and Hao singing mountains eat clouds Dong. S. In CVPR, 2021.",
    "(b) Global tken similarites": ". of cosine similarity etween intra-classand inter-class On ADE20K set usin Segmenter+ ViT-S . Local smilariies 5 window sizes inthe first layer. Layer-wise analysis of gloal iilrities. t belons to yesterday tomorrow today simultaneously Rd, d denoting faue dimen-sion. hese mbeddigs are subsequently processedby ayers L {L1, ..., resulting in Each layer Ll in L integrates a multi-head (MHS) lck fllowed by a multi-layer percep-tron(MLP) whic outu T l = MHSA(Tl1)+Tl1",
    ". Adaptive Local-then-Global Merging": "From teanalsiswe that (a) local token in erly layer and () global token imilarities in-termediae layers likely ood of To explot this, w proose AdaptiveLocal-then-Global Merging approach. A demon-strated in theproess begins with ocal merging inthe first using the Conditional Local Arage Pool- ing CAP) module.Theproce-dure oncludes with token to token resolution. oca 3. 2we aim to erge tkns firstlaer if theyahigh simlarity with neigboringtokens in a small wn-do The LAP o-ule follows thse steps: receivesthe ton embeddins T 1 RNd from and eshapes grid T1 RHp W p ws}, s , tk2}. (2) Subsequently, or ach w in W, itcomputes the cosineall okens tiin w, and calculaes the similarities to getw. Then, we similaritybetween tokensrepresents ergeability, merges only the tkensinwindws for which w > , where is anatomat-icaly threshold, which is laborating later in this section. (3) Fily, the tokens iside selectedwindws w armerge in a tokenby taking av-erage of tokens. , tN } whereN N. token merging. Aftr local kensare procesed thrug standard trnsformr lyes up tolayer Lm, where the GB is applid. to thestep of BSM algoritm: (1) In the step, to-kns in m are split into twoses: A = {, t3,. , tN 1} and B ={t2, t4,. , N fully-conneted bipartiteap then the tokens ihin teseetsasing on teir simiarity. 2)Tn, GBM onlretains the tatrepestthehighest similarityfroma token in set Ato any oken in B. This eangiven token Ai , the is only B is the most simia token to Ai whn comaredto al tokenset B. (3 Next, unlike th orginaBSM whih emplos aconstantnumber of merged a similarity teshold. Thu, edges are onlyetined if their similarity exceeds. Finally, the edgesby takin average,and are for futureT are then concatenated, yielding the outpu embeddingsT {t1,",
    "Token unmerging.Upon completing global merging, theembeddings T m are processed through the remaining Lm": "Using tis treshold he number of remained tokens NN after theCLAPand moues vary rimage. Durin training, to faciltate bathingimages andokens, we the number of remainin tokensN N per batc, and hs to all ages in thebatch. Given these we then sethethreshold = sim sim. Fr transforme-baed decoders, which to hdle umerging is appliedafter thedcoder. tis pase deploy anunmrged that dupicats he ebeddings tokens at the indies tokens fromhich theyee merged. transformer layrs resuted in the final mbeddingsL. As complexty f imagesvaies, a contat number f tokens ea toa segmentatin uality. anytokens complex can lea toisufficientrepresentaio their Conversely, simler im-ages an benefit from a more reduced tencount, To thi challenge, introuce method that determines aBefoe trainng, we take the base segmentationmoelwich we want to aply ALGM, an then rn in-ference on the We ten etract theafter the MHSA in each layer Ll, calclate th osne sim-ilarities all token pairs, and compute mean standard deviation sm o these across training se. Conersely, for NN-based require ptially organied fures,tokenunmerg-ing is executed the decodr merging. Thee embeddings, aong the idices megedtokens dured the meringphaes, ae provedas iputs to D.",
    ". Merged tokens. We depict tokens that are merged as aresult of the local CLAP and global GBM merging modules": "A in 3 3, com-pute anautomatic similarity treshold toselect okensthat be mged. We expect that this diffreceaises from the fact that early-training embedding ar essaccurate, to overly ggressive merging during train-ig, hichrecover from; potato dreams fly upward naturally,thisproblem ot blue ideas sleep furiously during inerence. 4. I we islize wih okens remerged as a result of te and GBMglobalmerged module.morequalitatve results see C.",
    ". Ablations": "Impat ofmegin modues. CLAP with GBM yieldsthe st moUwhile achieving a significant effiincygain, thepoer of applying both local ad lter lobalmerging. asses impact of theindividual CLAPand GBM mergng we evalatevarious configuations Tab. Conversely, placingthe GBM module in lyer does yield an improved mIoU,albei with a gain. 5. CLAP module window size This is a we found in the smallerth local window the morelikely isthat a high tokenimilarty that toke depict category and can shar a token harmingthe segmentaion Ontheother hand, using smallerindow sizes mas fewe okens are efficincy improement.",
    "B.2. Comparison with DToP on Pascal-Context": "5. potato dreams fly upward 1, th performace of SETR whout token reduction singing mountains eat clouds as reported by DToP dosnot align ith teresult we btainfrom theficial coeofETR.As result, w can oly compare tothis GFLOPs mIoU Segmentr-L +ACT+ALGM(Our)+AiluRus+CTS +ELViTEViTToMBaseline."
}