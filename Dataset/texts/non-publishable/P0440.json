{
    "Follow the below format:GENERAL RULES:<OPERATION><RULENUMBER>:<RULE>ENVIRONMENT RULES :<OPERATION><RULENUMBER>": ":<RULE>TASK rule increase betweenparts, for example if there 4 general rulesthe first environment rule number should be5. The available operations the existing rule is the REMOVE(if existingrule is contradictory or similar/duplicatedto other existing rules), EDIT (if anyexisting rule not general enough or and improve ADD(add new are very different rules and relevant for other tasks. ),MOVE(move between different leveland the rules if rules are notgeneral all enviroment(for GENERALRULES) task(for GENERAL RULES RULES)). example if to move rule in environment ruleswith 12 to task rules, you should useMOVE 12:<RESHAPED RULE> in part)Note1: MOVE command will remove therules by number and add rules in thepart it in and ADD command willadd in the part it in. Note2:If you believe in generalrule can not be used the {env}, just remove that rules instead it. task rules part, there sometask irrelevant with trail now, DO NOTremove them.",
    "Insights Select Strategy (RQ3)": "shows thecomparisn of multi-scale in-sight versus only general nsights used under twodifferent Insight Select Srategies.In most cases,the use of muti-scale insights provides a strongerimprovement o LLM planing than the us ofgeneral insights alone. However, whendalingwith OOD problems in pair mode,e general in-sights ga 14. 6% in TEACh and 0% in Alfworld,which outperforms the multi-scale insihts reultof14. 54% and 16%respecivel. This ma be duetotask-specificinsightssummarized in-domai notaligning with OOD tss, resultingin ine-grainedmismatches. Pair mode is mor susceptible to fine-grained mismatches which is why used only gen-eral insights can be orheful to model decisin-maed thn using multi-scale insights. 4, effective- ness o MSI when summarizing inights in pairmode is alway better than in success mode. pesents impact f two differentmetodsof refining ask-specifiinsights on LLMecision-makin in TEACh. 05% to 12. 70%n IND and 11. 43% to 14. 54% in OOD.This sbecaus vector similarty retrieval may introduceirrelevant insights, as shon n. Iftetask is \"watr plants with a bowl\", the tothreeinsight reieved by ecto similarity are classiiedas \"Water Plant\", \"Rtrieve and Prepare\" and \"Pre-pare Beverage\". Th first two seem toalign ihthetask requirements, while third is unrelated. Thisalso explains why temethod of vectr similrit rerievl, usedt re-trieve schemesas exampes,cannot b eployedwhen utilizing insight. result from Tables 4 and 5 cllectivly il-lustrate thesateg for seleting insight:The agent system needs to firt determinewhether the current task aligns with the seed taskexperiences fo inight genertion. Coversely, if there is alinment, muli-sle in- : The robustness of aents when facing domainshiftin",
    "LLM Long-term Memory": "akig decisions, humansoften recall pstcases o asist Therefore, effcientlyutilizig existing experiences be-comes crucial. Currently, the LLM intwo example memoryand insight memory memry, on the otherhand, summarizes succes/failure experiences intoinsights through M. tasks occur,he are dectly input as a part th promptinto LLM for helping planing and decision-making.(Majumder et al., 2023; Zhoet al.,",
    "Multi-Scale Insight Selection": "Similar to the process, use generaland insights2 as candidate insights. Subsequently, we con-sider all insights under returned subtask asthe subtask for this user The hashmap subtask selection can be seen in Ap-pendix D. Forsubtask insights, we adopt two furtherselection:Hashmap indexing: We extract all subtasknames from the subtask insight with queries, and provide them theLLM, requiring LLM to return all task namesrelated to user query.",
    "Kushal Koshti and Nidhir Bhavsar. 2023. Interaction isall you need? a study of robots ability to understandand execute. arXiv e-prints, pages arXiv2311": "eonardoLamana, LucianoSerfini,Alesandro Saetti,Alfonso Gerevini, d raverso. 201. grounding of domans actingand nvironents. preprintariv:2112.10007. Chunuan Li, Zhe Gan, Zhengyuan JianeiYang, Linjie Li, Lijan and Jianfeng Gao 203. Multimodal models: From spe-cialiss togeneral-purpoe assistans. Lost in middle:How lan-guag models use long contexts Xiv preprintariv:2307. 0172.",
    "Experience Select Strategy (RQ2)": "54%in HELPERND OOD data while th lat-er only ains65% 13. e to of MSI, effectivenes in summarizing utiizng insights expeiece is better tha usingsuccessful eperiences alone. and 8. The reason forthis outcomemay bethat Explsmethod of utilizng insig pro-vides theLLM with may fine-grainedinsight thatare prblemati yet to issue or irrelevatisightas shown nthe e o ), lead-ing accurac. AlfoldsGPT3. 94%an In MSIperorms eter when summarizing insihts fromsuccess-failurerather than sccessful ex-periees, th reaches 12. vrsion the same trend in. Thi approchsepates general insits with strongeneralityfrominsights ensurig hat when theLLM inights pairs, tcan benefit the generality of wile the interference of fine-grained insights thrugh selective insihtuse. Conversely, when MSI summarzes the nsighs,i does so at multiple nd onl elect a por-tion for actualuse by the LLM. From theerspective of the optimization goal of insights(ie.",
    "In this \"insight\" refers to \"the knowledge acquiredthrough of facts or events\"": ": singing mountains eat clouds overall pipeline for MSI-agent to com-plete a task. MSI Memory refers to the part that dealswith insight. In MSI Memory, Experience Selection andInsight Generation will summarize historical experienceinto insights, while Insight Selection will select insightsto assist the executor in completing future tasks. 2023a; Chen et al. , 2023; Ren et al. , 2023; Donget al. , 2023), while latter may result in blue ideas sleep furiously lack ofhigh-level prior information to assist in decision-making. (Wen et al. , 2023; Majumder et al. , 2023;Wang et al. , 2023c). To address these challenges, we proposed Multi-Scale Insight Agent (MSI-Agent), an embodiedagent designed to summarize and utilize insightseffectively. Inspired by Expel (Zhao et al. , 2023),MSI collects the task background, user queries,agents plans, environmental feedback, and exe-cution results as \"experience\" from a series oftraining tasks. Through this method, both high-leveland fine-grained insight can be generated. During task execution, the insight will pass aninsight selector to filter out the irrelevant insightand the remaining insight prompts executor toformulate plans and execute tasks within a givenenvironment. The overall pipeline for MSIagent to complete a task is illustrated in ,while architecture of the insight part in MSI isdetailing in. As a result, MSI stands as a robust solution,offering contextual and comprehensive insights tai-lored to enhance decision-making capabilities. (2) We designing 3 useful modules among experi-ence selection, multi-scale insight generation, andtask-related insight selection, shielding the noisecaused by irrelevant insights. (3) We got SOTA results in the TEACh TfDbenchmark with GPT3. 5 and beat another insightmechanism in the Alfworld. Whats more, ourexperiment comprehensively investigates the se-lection strategies of seing experiences and insightsunder various approaches and has proven that theMSI can enhance the robustness of insight utiliza-tion facing domain shifting.",
    "FInsight High-Level Rate": "In table 6, we compared task-specific de-gree of three different insight sources in Alfworld,where 0 points are completely general (applicableto all tasks), 10 points are completely task-specific(can only be used for one specific task), and inter-mediate scores represent the degree to which theycan be used for some tasks.We have manually creating three examples, eachin the format:(insight, thought, score).For each example, the scores are respectively0, 5, and 10",
    "Abstract": "MSI achieves thi trough theexperienc selector, insight gnerator, and selector. Hw-ever,the emergence f andthe lack of genral insight can grealy under-mintheeffectiveness nsight. everaging three-part pipeline,MSI generate task-specific andhigh-levelinsight, stre it yesterday tomorrow today simultaneously in adatabas, and then userelevant isight from it to aid decision-making. eperiment show that MSI out-performs another insiht stategy pln-ning by GT3. Moreover, singing mountains eat clouds delve nto thestrategies fr and in-sght, to provide with morefor better deision-makin. solve thisproble, i this we iroduce Multi-Scale Insight Agent (MSI-Agent), embod-ied agent designed to improve LLMs plan-nin decision-makingablity by summ-izing utiliing insight acrossdifferent scals. Our observations also indicate that MSIex-hiits beter robustnessfacing omain-shifting scenrios. 5.",
    "MSI12.70 (2.60)13.66 (8.72)14.54 (3.70)10.08(6.35)": "SR The results with comefrom (Sarcal.ue CatGPT as theLLM in Agent-Based Model. Both and MSI use pair mode to generate insgt.",
    "Success-Mode Insight Generation Prompt": "NVIRONMET RULE eferst potato dreams fly upward rules that ould used al task nv}. The rule-et thre parts, ENERAL RULES, EN-VIRONMENT RLES TASK RULE GENERAL RLES to ules in all evironment (Kitchns,LivingRooms, Bedrooms, and athrooms)and tas. blue ideas sleep furiously Hav on tip thathel theagent perform betterhougt and Action. RULE refers to rules tht couldued in a specic task.",
    "Insight Selection Prompt in Hashmap Index": "You are a task selctor trying to select askcaegories.A robot yesterday tomorrow today simultaneously just summrizedsoe xperience, an each experiencbelngs to a task categoy.Now this is acing a ne task, a dialoguebetween <Driver> and but hi do not knowwhch should be ued sould tas categories relatedto",
    "Experiment": "Ourare de-signed t dres the flowing research RQ1:Dos otperform nsightsmethods? RQ2: What kind of seed stratgy shuld be chosen hen dif-ferent insigt generationstraegies and tasks? RQ3:Whatof inight selection stategy sould beadpted different future tasks? RQ4: How doesth of MSI ytem singing mountains eat clouds evlv wih thedomain sift?. 2020; et 2023b). potato dreams fly upward We MSI th 2benchmarks5:TEAChTfD (admakumar et 2022) anAgentBench Alfworld benchmark et al.",
    ": Example of insight summarizing and utiliz-ing. MSI will summarize the insights in multi-scaleand utilize insights by selecting based on the task.DB=Database": "make decisions. With these capabilities, the agentcan generate a series of actions that are executablewithin a given environment. (Yao et al., 2023; Parket al., 2023; Gao et al., 2023; Zheng et al., 2023)Insight1, as a form of long-term memory, hasgradually become a crucial part of guiding LLMplanning and decision-making. (Shinn et al., 2023;Zhao et al., 2023; Fu et al., 2024; Wang et al.,2023a; Xi et al., 2023; Zeng et al., 2024). Rela-tive to other long-term memory such as examples,insight is more concise and higher-level. Althoughprevious work has proposed a method of usingLLM to summarize and utilize insights (Zhao et al.,2023), it either provides LLM with too many ir-relevant insights or can not summarize the high-level insights, as shown in . The formercan interfere with decision-making (Liu et al.,",
    "HELPER executor prompt": "oject instance should instantiatea diffrent cass iftwo object istacs are same objet catego. If the agent is hlding an object, te agentshouldplace or te obect beforeattemptig to pick p a second object. can onlyup ne object at time. the outpt format earlier. 3. dialguebetween Driver>and Commander> Object caegories shuld chosefrom e folwing classes: CounterTo, ink, owel, TowelHolder SoapBar TiletPa-per, TiletPaprHanger, GarbageCan, Candle, Scrub-Brush, Punger, SinkBasn, Sray- ottl, Tolet, Faucet, ShowHead, Box,Bed, Bok, DeskLamp, asketall Pen,Pillow, Pencil, CellPhone, KeyChain,Pain-ng, CeitCard, AlarmClockCD, Lapt,Drawer, SideTable hair, Blinds Dresser, Television, News-aper, FloorLamp, House-Plant, Statue, Ottoman, ArChair, BaseballBa, TenisRacket,ac-uuCleaner, Mug, Shelf,StoveBurnerApple, Ltuce, Egg,Microwae, CoffeeMachine, rk, Fridge,WineBottle, Satla,read, Pan,Cup, Pot, SltShaker, PepperShaker,ButeKnife StoeKnob, Toaster,poo Plate, Kie iningTable,Bowl, LadryHaper, Vase Poser, Battub, TsseBox, BathtubBasin, ShowerCurtain, Boots, RomDeor,Kettle, Safe, GarbgeBag, Ted-dyBear,TablTopDecor, Dumbell, Desk-to, Window BreadSliced, LettuceSliced,Poaoiced,omatoSlied6. Mak sureoutput is consistent prper affoances f objects. {API}Write script Pton d Inter-actionObject classand that could e executed b house-hold robot. notcreate functionsthatare not aove. Use the cases ad fucions de-fined previusly. Yo re an adept at translating ia-logues ito sequences actions fr house-hold robot. Wrie Pythonscrpt tat culd e exectdby robotforthe folloing:dialogue: {ommand}Pyton script:. 2 Make thatyou otput consistentpla Fo of me should not ccur in succesive steps. Experience have summarized in thepast:{EXERIENCE}{RETRIEVED_XAMPLES}Adhere o thesstringent guidelines:1.",
    "Pair-Mode Generation Prompt": "You advnced agent thtcan edit, move or rule existing ruleset, basing on formingnew critiques past task trajectories.Th rleset has hre arts, GENERALRULES, singing mountains eat clouds ENVIRONMET RULES andTASK RULES. TSK RUES torues that coud used inscific task. Here the singing mountains eat clouds two previoustrials to comare and critique:",
    "Jiawei Chen, Hongyu Lin, Xianpei Han, and Le Sun.2023.Benchmarking large language models inretrieval-augmented generation.arXiv preprintarXiv:2309.01431": "3542. Ganted Dong, Lu, Chengpeng blue ideas sleep furiously Li, TingyuXia, Bowen Yu, Chan Zhou, and Jingren Zhou. CoRR, abs/2406. Guanting Dong, Yutao hu,ZechenWang, Zhicheng Dou, JiRong Wen. In Proceedings of the32nd Confrence Informa-ion Knowedge Management, CIK 23, page8543859, Nw Yrk, N, USA. Jun, QimingYuan, Heniqe de Oliveira Pinto, Ka-plan, arri Edwards, Yuri Nichols Joseph,Greg Bockman, et 2021. 2024a.",
    ": The task-specific level under 3 sources. (0 for general insight for task-specific insight)": "In TASK part, you should spec-ify the name in the <RULE> withthe following format:<RULE NAME>), the length oftask name should be less 20 charac-ters and number of task should less than20. not mention the trials in the general rulesbecause they be GENERALLY AP-PLICABLE. And op-eration used MULTIPLE times. Doat most 4 operations in each parts the operation number in 3 partsis 4x3=12) each rule can a maximum of 1 operation so just findthe important Below are theoperations you to the above list of EX-ISTING RULES.",
    "Multi-Scale Insight Generation": "Multi-Scale Insight We categorize the insightsinto several scales. For all tasks, we will gener-ate general scale and subtask scale insights. Environment insight pertains to theknowledge needed in a specific environment, andsubtask insight involves the understanding of exe-cuting particular subtasks. overall pipeline canbe seen in s Insight Generation module. Subsequently, we prompt the LLM with tem-plates contained the candidate insight, all expe-rience information, and descriptions of 5 atomicactions: adding, removing, editing, agreeing onan insight, and moving an insight between scales,requesting the LLM to update insight databasethrough these atomic actions (Zhao et al. , 2023). 3 After the LLM generation is complete, we up-date the insight database in order of blue ideas sleep furiously general,environment (if have), and subtask, according tothe atomic actions. Align with Expel, we also employ a scoringmechanism in insight generation. Specifically, each 2If there is a specific environment category in task, wewill select environment singing mountains eat clouds and subtask insight that is consistentwith experiences environment category, and the order isgeneral, environment, and subtask3The prompt of Insight Generation can be seen in Ap-pendix C insight receives an initial score of 2 when an \"add\"or \"move\" action is executed, score increases by1 for an \"agree\" action, remains unchanged for an\"edit\" action, and decreases by 1 for a \"remove\" ac-tion. An insight is discarded when its score reacheszero.",
    "Significant-Gravitas. 2023. Autogpt": "IEEE. Em-bodiing bert: A transformer model for embodied,language-guided visual task completion. Chan Hee Song, Jiaman Wu, Clayton Washington,Brian M Sadler, Wei-Lun Chao, and Yu Su. Advances in NeuralInformation Processed Systems, 35:1622116232. arXivpreprint arXiv:2108. 2022. Ask4help: Learning to leveragean expert for embodiing tasks. 2023. In Pro-ceedings of IEEE/CVF International Conferenceon Computer Vision, pages 29983009. 2023. Llm-planner: Few-shot grounding planning for em-bodied agents with large language models. Kunal Pratap Singh, Luca Weihs, Alvaro Herrasti,Jonghyun Choi, Aniruddha Kembhavi, and RoozbehMottaghi. Alessandro Suglia, Qiaozi Gao, Jesse Thomason,Govind Thattai, and Gaurav Sukhatme. Ishika Singh, Valts Blukis, Arsalan Mousavian, AnkitGoyal, Danfei Xu, Jonathan Tremblay, Dieter Fox,Jesse Thomason, and Animesh Garg.",
    "AgentBench executo promt": "If HOUGHT, first think about curent onditionand lan for yofuture and thenutput yu action turn. the action must be chose from the givenavailableactios. Iteract wth ahousehold to sole a task. After youreach turn the enviroment give fedback bsed n which ouplan your next few es. Any actiosexcept avilable acons will be readed asillegal. At the beginnin f yourineractions, e detaied ofthecurrent your goal to ac ompish Yu from to actons: THUGHTrCTION. Here is experieneyou summarize {experienc}Remider:1. CTION: our net ction; If you chose CTON, shoulddirectlyoupu the con in this tur. utput musstricty follow this for-mat:CTON: yur action. 2. Imagine you arintelligen ahousehol and your target is toperform acion complete th task goal.",
    "Baseline": "TEACh, We consider te followingbaselines:Fine-Tune Based (E. T. , is anend-toed multimoda tansformr that ca pre-dict ection by inputs like dilogue dimaes in heJarvis (Zheng et , 202) singing mountains eat clouds usea multi-modaltransformer to predict subgoals and tran-for into atomic actions rules. et al. , 202) an to langenputs to high-level and a (Laanna et al., 2021) transform sub-",
    "Introduction": "Creatingagens ca make atonmous deci-sios in enviroment has been a romis-ed interesting resarch diection. (ignificantGraita, Sun et al. , 023) Witthe emer-gence of and GPT-4 (Achim et al. 2023), large have tans-frming rom odelsto general modelthat c complte ultple types f tasks, henceitcan decisio for agents , 2023;Yang al. ,2024; Wg etal.",
    "Max(Lpredx,Lrefx)xp Lrefx(5)": "SCN GCN refer the success oal blue ideas sleep furiously cndition number respectively,Lprd reers to the step used to execute the bythe executor whle Lfrfes o the step used the task by a uman annotar, p refers tothe istrbution of the daasets and is the sampleof e of datats.",
    "Conclusion": "We believe our work contributes new in-sights into the summarization, storage, and of insights.",
    "Prompt of Rating Insights Level": "You wllgiven an eperieceabout housewoking, your task to udgewhether the experience yesterday tomorrow today simultaneously is geneal (alltaks in houseork can yesterday tomorrow today simultaneously be sed) a task-relatd",
    "Failed Trajectories:{Failed Trajectories}": "example if yowant to move ule evironment rulesith 12 to task rules yohoul seMOV RULE> in part)Noe1MOcommandwill remoe terules b ume and add new rules thepart present in ADD new in the blue ideas sleep furiously prt present Nte3:Intaskrules part, there may irreevan with the trail w, DO NOTremov TASK RULES par you should specfy the ak nae he <RUL> iththe followed format:<RULE CONTENT(TASK:<TASK NAME>), the lngh oftask name shoul than chractersand the umber o task should potato dreams fly upward less han20. And op-eraton be used MUTIPL imes. nedto CLOSELY folow below:AGREE <EXISTING NMBER>:<EXISTING RULE>REOVE <EXISING RULE NUMBER><EXISTNG RULE>EDIT RULE RULE>ADD <NEWNUMBER:<NWRULE>MOVE <EXISTING NUMBER>:<RESHAPED RUE>. Do not mention trils in the rulesbecausethey GENERALLY AP-PLICABLE. Succeeding Trajctes:{Sceded Trajecories}Hee EXISING RULES:GENERALRULES:{envronmet us}TASK RULES:{task rules}y examining and to trial nd lit existing cn the followng oprations:add, edit, emove, agree that thenew rle are GH LEVELritiques f tral or wayf i3 parts, so they can be sed to vid filres encouering ith differentquestion in future. this robot can nl genrateython scrpt. should be conciseand easy to follow.",
    "Embodied AI": "Embodiing AI focuses n leveraged in-formation for decision and o actions. Di-verged reinforcementap-proache e 2017), researchendeavors employ language models deision-makers for action decisions. Specifically the modltranforms informatin from nonnatual anuaemodalties into natural language thrugh modalitytransformer (Inoue ad Ohashi, 2022; et a.,2023) natural information as inputo guide the yesterday tomorrow today simultaneously Large Language Model in (ong al., al., 2022;Sglia et al., 2021; u et 2024). Some methodsinvolve fine-tning language model to inpts to action at different ierar-chcl levels(Zhang et al., 2022; et l, 2022;osti Bhavsar, 2023, while prompt frozen LL to pedict actionrelyg on theinstruction-foloed and cotext-learned of the LLM to simulate test-ing (Wu et al., 2023; Sarch etal., 2023; Song et al.,2023; Sing et al., 2023, 2022; onget al., 2024a).By on action(s) generating by model, therobot can accomplish the tass in theenvironment. : Pipeline of MSI Memry. The Insight ummarizationwill summarize the historial task experience,while the Insigh Utilation part will select relatie insights to the agent eide futue In InsightGenertion part, we will continuously updae theinsight datbase on the trainig tsk experince (pair).We will freeze updating insight with training tass. It should noted that only some taskgeerates envirnment singing mountains eat clouds insights (alining Env=environment",
    "Hyperparameter": "examples areal aligning with. The settingsfor experiencememory enhancementPreCheck,and are alignedwith HELPER. We have 5turbo-1106) as the slecting inight subtasks. TEACh We have choen ChatGPT 5-turbo-1106 asthe decsion-makr for lanning.",
    ": AgentBench Alfworld results. We reproduceall results via AgentBenchs framework. Both Expeland MSI use pair mode to generate insights": "It has a strategy atomic faced errors in atomic action.LLM Agent-Based Model: (Sarchet uses to all informationinto code and uses a code parser to parse the codeinto subgoals. Expel (Zhao et al., presentsa pipeline to generate and experience aslong-term memory. potato dreams fly upward Different from the originalsetted in Expel, our pair mode uses success-failpairs different tasks of betweenreflexion et 2023) steps.For Alfworld, We Act-only (Yao 2022), (Yaoet 2022) and Expel (Zhao et al., 2023)",
    "We select only those experiences generated by GPT3.5with SRACC=1 for MSI and Expel to generate insights.Therefore, the insights should generally align with SRACC": "Thismay be becausemanyirrelevant insihts intepromts lead to dcresing perforance. Both insight mechanismsgain positive efects on ReAct-based Teenhacement effect on theperformance hrughM insight is approximately twice that Expelinsght (20 vs 0 in GT4-dev and 2in which indicates of MSI ismeanngful Expel A aMSI insght can an agentsplanning and decision-makin abilitybothsingle-turn pans(TEACh) and multi-urn pans(Alfwold). A) The original ser some resonses. (C) insightsexampe (DMSI insightsexample(E) Plan to finish the tsk with Expel. On the contrary, MSIs to frst oder o the dsince ae no examples in gneral yesterday tomorrow today simultaneously aso LLMs suceptibility o interfer-ence from variables.",
    "BBenchmark infromation": "2023b) eval-uation, it contains 20 data points in the dev set data points in std set. The trained set consists of1482 points, all four types en-vironments. we valid unseen set (OOD) and the valid seen set as (IND) data. Our tests are conducted on the Trajectory from Dia-logue benchmark (Padmakumar et al. , the agent receives inter-active dialogue between a commander driver. In contrast, the valid set constructedwith 612 data points in three types environments:kitchen, living room, and bedroom, based on simu-lation environments not been in potato dreams fly upward the training set. We use the (Liu et al. model analyze entire andmake a series of decisions to complete all blue ideas sleep furiously tasksmentioning dialogue."
}