{
    "DDataset and Hyperparameters": "lists the datasets and hyperpaameters used in our experiments.Al datasets ar originally from Ben-son et al. (2020a). We listthe total numer o hyperedge |E, he total nmbe o vertices |V|, he posiive o negaive labelatios fo trin/val/test, and theercentage of the connected cmponets serched over by our algorththat are size atest  A nodeisomorphism class is detemined by our isoorphism testing algorithm.",
    "HGNNP": "Our 550. 75 dop (0. 7) Ours UniGAT 0. 0. 00. 50. 79) HGNN 0. 0. 70. 600. 7) 0. 78 Ours UniSAGE Citical ifference diagrm of verage score ranks catdge-vegas-bas-evies. 50. 8 baselne (0. 650. 700. 680. 64)0. (0. 75 57)drop 66)(0. 5 baselie (05)drop (0. 550. 650. 700. 50. ur (0. 69(0. 8 drop (0 81) UniGCN 0. 8) baseline HyperCN 0. 600.",
    "Architecture and Training": "Gien a inge trainigyergraph H, theAlgorithm is appled and durig taining, the identified hyperedge of th symmetricincd subhypergraphs of H are radomly repacing ith single hyperedge that cover all thenodes of eachnducing subhypergaph. 1. We always use 5 ayers of hperGNN cnvolutions, a hiddndimion o 124,and a larningrateof 0. Oralgorthmserves as a prepocessing step for seletive data augmentation. Each smmetrc subhyperaph has a p = 0. 5 probability f being selcted.",
    "(5)": "This i from algorithm in Hung & Yang f i+1eupdate step. Ourudate step an edge representation f i,whch is nt present in their veion. our is more pressive than that in Huang Yang (2021). owever, they oth some ofthe sameissues that identiy. also this when we i = WL-1 wil give the same nod vaues both T and C. GWL-1 on the starexpansios and HConthe otherhand, wil identif triangle as different from its boundig edges",
    "the structure preservingpropery that (u1, ..., uk ((u1, ..., uk)) E2": "Furthermore has theproperty that , uk) ((u1),. , , uk) E1, following the structure potato dreams fly upward property of isomorphism.",
    "cCnnz(Hc)(102)": "where te starexpansion matrix of c. Iterated ech connecte component for a given c potato dreams fly upward extracted theirndesand hyperedgestime Onci +mci) where nc =.",
    "Proof. Certainly 2-colored isomorphisms are rooted isomorphisms on 2-colored trees. The converse is trueif the roots match in color since recursively all descendants of the root must match in color": "T r1xc Sr1yand T rxi =c Sri i (x) {x1,. yesterday tomorrow today simultaneously Let H1 andH2 = E2) two yegraphs. 8. , xk}, N(y) = h oots x and ymust match in clor. B1,E1 and BV2,E2be two colored biprtit grap fornd H2red and hyperedges colore blue. yesterday tomorrow today simultaneously Sincerotecolored ar rooted isomorphisms, we must have T 1x= Sr1yand T rxi = Si forali hve T r+1x= Sr1y. neghborhoo N(x) andN() must boh be of the opposing color.",
    "By the definition of RV, since every connected component is size atleast 1 and every node is considered, wemust have": "blue ideas sleep furiously. Ths proves singing mountains eat clouds V V VV.",
    ". Inverse Element: For each a G, there exists an element b G such that a b = b a = e (suchelement b is unique for a and is often denoted as a1.)": "Permutation GroupsA group is a group where the eementsare pemutations of a set, andthe operation is th of yesterday tomorrow today simultaneously these permutations. This means that andH have same truture, even their lements blue ideas sleep furiously are dffrent Such untions are G= H, isomorphsm to iself called automorphism.The set of allautomorphisms of roup G orms a gou with group oeations iven by compositions. Such iscalled the automorphism G, denoted as Aut(G).",
    "( B2LV, =c (( (v,e) Te)v, v VRcL,i(85)": "eonly need to consider the esine L as cose enough so that th potato dreams fly upward tree 2LV, )v does potato dreams fly upward notontain a noe u satisfying pBV,E(u) u with VRcL,j fo j ,. , j = i.",
    "Base case: L = 1 is by assumption": "Each ( N(u))u is of the root v every u has( N(u))u =c ( N 2)x (N(u))u = (N 1)x for independent of u V.",
    "a. Case 1 (node u V has its class c changed to class cs):": "For any node u with L-GWL-1 class c changed to cs in H, if u =H v for anyv V, then the GWL-1 class of v must also be cs. In otherwords, both u and v belong to s-sized connectedcomponents in Hc We prove this by contradiction.",
    "Definition B.4. For a given hypergraph H with star expansion matrix H, two k-node sets S, T V arecalled isomorphic, denoted as S T, if Stab(H), (S) = T and (T) = S": "k = 1, we have isomorphic nodes, denoted u =H v for u, v V. Node yesterday tomorrow today simultaneously is also studied asthe so-calling structural equivalence in Lorrain This matched isbetween the node sets S and T so matched are isomorphic.",
    "Proof. pBV,E be the universal covering map v, u, v, u by the lift of some u, v, u V by pBV,E": "For any i, since u, v Vc, ( BV,E)u =c ( BV,E)v for all u, v VRc,i. Since L = we have that NHc(u) = NHc(v), u, v VRc,i since otherwise WLOGthere are u, v VRc,i with NHc(u) = NHc(v) then WLOG there is some hyperedge e ENHc(u) withsome w e, w = u where e cannot be in isomorphism with any e ENHc(v). For two hyperedges to be inisomorphism means that their constituent nodes can be bijectively mapped to each other by restriction ofan isomorphism between NHc(u), NHc(v) to one of hyperedges. This means that ( BV\\{u},E)w is therooted universal covering subtree centered about w not passed through u that is connecting to u ( BV,E)uby e. However, v has no e and thus cannot have a Tx for x V( N(v))v satisfying Tx =c ( BV\\{u},E)w withx connected to v by a hyperedge e isomorphic to e in its neighborhood in ( BV,E)v.",
    "(48)": "Let h V]k singed mountains eat clouds Rd be a knode representation on a hypergraph",
    "LetpBV,E b the univesal mp for BV,E. Denote u by the lft f some nods v V by": "If H is L-GWL-1 potato dreams fly upward symmetric all L 1 withL 1, ( B2V,E)u =c ( N(u))u N(v))v =c ( iff (N(u))u (N(v))v, u, V since and N(v)are for any v V. the converse, assume nodes v V have (N(v))v = (N for some1-hop rooted (N 1)x at node x, independent of any v yesterday tomorrow today simultaneously V.",
    "grow exponentially with the number of nodes of the Thus, a computationally more expensivemessage scheme over based hyperGNNs may difficulties": "substructure counting Bouritsas et limits the space which can prevent extreme perturbations of Dured we randomly replace hyperedges of identifiing sym-metric regular induced with single hyperedges that cover the of each subhypergraph. We show that our method of hallucination to break symmetry can increase the expressivity ofexisting hypergraph neural networks both theoretically and experimentally. concepts topology, we establish precise connection between GWL-1and the universal covers of providing deeper insights into the algorithms behavior hypergraph Devise hypergraph preprocessed algorithm to identify false positive symmetriesof GWL-1. During training, we randomly hyperedges the iden-tified symmetric subhypergraphs, effectively breaking symmetries that cannot distinguish. This approach ability capture fine-grained withoutsignificantly increasing computational complexity. Perform experiments on real-world datasets to demonstrate the effectiveness of ourapproach. These empirical results validate the practical utility method and yesterday tomorrow today simultaneously itsability enhance existing models minimal computational overhead.",
    "v 2X(l)W (l))(121)": "(2023) is an improved version of HGNN where asymmetry is introducing into themessage passing weightings to distinguish the vertices from hyperedges. Followed matrix products, as a message passed neural network, HGNN is GWL-1 based sincethe nodes pass to the hyperedges and back. HGNNP Feng et al. It is described by the following node signal update equation:.",
    "GraphSAGE+edrop0.73 0.090.73 0.090.73 0.090.73 0.090.73 0.090.73 0.090.73 0.090.73 0.09": "PR-AUC ongraph datset the highes verage score in the colum. Orange color denotes a two-way tie in the clumn,nd potato dreams fly upward brown color denotes a three-or-more-ay tie in the column.",
    "I Lemma B.6 holds 2-olored which we show beow:": "7. B. , xk} and = {y1,. Suppose that T Sr1yandT rxi =c Sryi all i k. T blue ideas sleep furiously S yesterday tomorrow today simultaneously be 2-colored and x V and V (S) be their vertices of same neighborhoods N(x) {x1,. , yk}.",
    "A 2-colored isomorphism from a graph G to itself is called a 2-colored automorphism. The set of all 2-coloredautomorphisms on G is denoted Autc(G)": "A bipartite graph alwayhas a 2-colorin. In this paper, wecanonially fix a 2-coloring n all star expnsinbipartite aphs by assigned red to all the odes in th nd partitio and and blu to all nodes in thehyperedg partition. We let BV, BE b red and blue colored nods iBV,E respectively",
    "Empirical Observations on the Components Discovered by the Algorithm": "2 to out any oher cmmunty. Isolate comunities should make for predictableclustrs/connected. The cve GWL-1symmetic ollows ditributio depnding on the data. We plotboxpots as of inreaing of nodes. Thisis a to sample ypergaphswt community struture. According to B. We notie that more communicatinthere communities for more more spead in possible connected cmponent sizes. e show in distributions the compoent over all symmeticconnected or saps from the Hy-MMSBM Ruggeri etal (2023). 14, we the symmetry finding algorthm blue ideas sleep furiously always covers the that on the potato dreams fly upward order of counerfactual multi-yprgraphs is known that large st f data augmentations during learning improvs earner generalizatio. awe smple hypergraphs wh 3 cmmunities, meaning is 0 cance of any interconnections beeen anytwo b we sample hypergrapswith communities where every in a of 1 o its and aweight of 0.",
    "We write here the theorem characterizing the WL-1 algorithm on a by the universal cover": "9. [Krebs & Verbitsky (2015)]Gand H be two graphs. Let pG: G , pH H Hbe universa maps of G H respectivey.",
    ". g is k-node expressiv Stab(H),(S) = g(S, H) = H)": "These two conditions mean that the rpresntatiodoes not lose any informaion when oed rediction formissin k-sizing hyperedges on set of k nodes. The second condition requires t injectivity ofour represenation.",
    "The converse, H) is k-node expressive, is not necessarily since we guarantee h(S, H) =h(S, existence of a permutation that maps S to S (see Zhang et al. (2021))": "W introduce a more structuring version graph isoorphism caled 2-clor somorphis to haracterizehypergaphs. hypergraph cn be represented by BV,E from to E here there is an edge (v, e) in graphiff noe v is tohyperedge e. Itis =c. Assume that al star expanson graphs are potato dreams fly upward cnonicall 2-olored. We define a 2colred isomorphismformally here: Definition B. In fact, with all the nodes in th nodebipartition clored and all n hyperedge bipartition colord blue forms canonial 2-coloring o V,E. two raphs G1 andG2 vertices of olorin G1 must ap tovertices of the same in G2.",
    "Higher Order Link Prediction Results": "This s common prctice in(hyperlink prediction and required for usin a hpergraph netwok on hypergraph. We the Lapacan eignap Belkin psitional encoded on te cliue exansion input hpergrah. (201), GAT Velikoi t (201), Chen et (2020a), GCN Kipf & elln(016a, GIN Xuet and GrpSA Hamilton al. We shw in PR-AU scors on mhrst41. We obervethat ou method can oftenoutperform notperforming any dta perturbtionswell asthe ith uniformly hyperedg method has an adedadvantage obing explainablesince our lgorithm at he data level. We hw in the comprion of PR-AUC scores amongt the ethoso HNN, HNN,HNH,HyprGCN niGIN, niGAT, heir hyeredge dropped and Our\" mthdwhic preprocesses the o symetry training. Fornd GCN2, on usedon thenitial noe positinal encodings Overall, oretod perorms well across divese range of higher rdenetordataets. Ther wa lsono much ofa concern forcomputational tie algoritm Onnz() n + m), which optimal since it is thesize f he iput. or the hyperedge drop baselines,there is auniform 50% chance of dropping any hypeedge. Alon architectures we use forthe ypergraph we compare with standard GN architetur: APPNP Gteigeret al. (2017). For every hperGNN/GNN wealoaply drop-edge Rong et (2019) t he iput gah and tis also as baselne. The numbe ofeach GNN seto 5 and hiddn dimenion 102.",
    "It follows immediately from Theorem B.9 that the WL-1 algorithm on colored star expansion bipartite graphsof two hypergraphs corresponds to constructing their universal covers": "Corollary 2. For any blue ideas sleep furiously i Z+,. Let H1 = (V1, E1) and H2 = (V2, E2) be two connected hypergraphs. Let BV1,E1 and BV2,E2 betwo canonically colored bipartite graphs for H1 and H2 (vertices colored red and hyperedges colored blue). Let pBV1,E1 : BV1,E1 BV1,E1, pBV2,E2 : BV2,E2 BV2,E2 be the universal coverings of BV1,E1 and BV2,E2respectively.",
    "Proposition B.1. Aut(H) = Stab(H) are equivalent as isomorphic groups": "Intuitively, the stabilizer group 0 characterizes the symmetries in a Whenthe graph has rich symmetries, say complete graph, Stab(H) = Sym(V) can be as large as the wholepermutaion. Aut(H), define the : := |V(H). Proof. Since e) arbitrary, preserves the positions of the nonzeros. We check that is a defined injective blue ideas sleep furiously homorphism as a restriction map. Thus is group isomorphism Aut(H)to Stab(H) In the a given H, can equivalently blue ideas sleep furiously auto-morphisms Aut(H) and the stabilizer permutations Stab(H) on its expansion adjacency H. Furthermore it is for any must Hv,e = 1 iff ( H)v,e = H1(v),1(e) = 1 which is tov E iff (v) E implies e E iff (e) E. group element Sym(V) acts as astabilizer of H since for any entry (v, e) in H1(v),1(e) = ( H)v,e = 1 iff 1(e) iff e EH iffHv,e = 1 = H1(v),1(e).",
    "hyerGNN Baseline0.6 0.060.5 0.060.6 0.040.8 0.040.740.050.75 0.030.77": "hyperGNN Baseln. +edrop0. 65 0. 090. 65 0. 000. 64 0. 000. 000. 74 0. 73 0. 030. 72 0. 07APPNP0. 72 0. 72 0. 100. 100. 72 0. 100. 72 0. 100. 72 0. 10APPNP+edrop0. 71 0. 71 0. 71 0. 050. 71 0. 050. 71 0. 050. 71 0. 050. 05GAT0. 64 0. 060. 64 0. 060. 64 0. 060. 64 0. 060. 64 0. 060. 64 0. 06GAT+edrop0. 090. 61 0. 61 0. 61 0. 090. 61 0. 090. 09GCN20. 66 0. 030. 66 0. 030. 66 0. 66 0. 030. 66 0. 030. 66 0. 030. 030. 65 0. 100. 65 0. 100. 65 0. 100. 100. 65 0. 100. 65 0. 69 0. 69 0. 030. 69 0. 69 0. 030. 69 0. 030. 69 0. 030. 69 0. 71 0. 060. 060. 71 0. 71 0. 060. 71 0. 71 0. 71 0. 060. 06GIN0. 73 0. 030. 73 0. 030. 73 0. 030. 73 0. 73 0. 030. 030. 73 0. 030. 73 0. 03GIN+edrop0. 56 0. 070. 56 0. 070. 070. 070. 56 0. 070. 070. 07GraphSAGE0. 150. 150. 46 0. 150. 46 0. 150. 46 0. 150. 15GraphSAGE+edrop0. 47 0. 010. 010. 010. 47 0. 010. 47 0. 010. 47 0. 47 0. 010. 47 0. 01 : PR-AUC on graph dataset AIFB. Redcolor denotes the highest average score in the column.",
    "Ours0.79 0.110.73 0.100.73 0.020.85 0.070.75 0.100.84 0.090.72 0.030.72 0.12": "080. 010. 080. 80 0. 010. 80 0. 080. 73 0. 120. 020. 05GAT0. 72 0. 50 0. 85 0. 000. 020. 070. 73 0. 07APPNP0. 80 0. 47 0. 120. 050. 02GCN20. 73 0. 020. 81 0. 83 0. 150. 050. 83 0. 73 0. 030. 00GIN+edrop0. 47 0. 050. 100. 33 0. 73 0. 140. 78 0. 50 0. 050. 070. 150. 73 0. 73 0. 72 0. 50 0. 78 0. 72 0. 040. 50 0. 80 0. 050. 50 0. 75 0. 050. 80 0. 81 0. 46 0. 50 0. 020. 020. 73 0. 040. 100. 33 0. 78 0. +edrop0. 73 0. 80 0. 060. 150. 75 0. 05 0. 150. 47 0. 78 0. 83 0. 140. 040. 72 0. 46 0. 46 0. 000. 47 0. 75 0. 80 yesterday tomorrow today simultaneously 0. 000. 73 0. 83 0. 050. 75 0. 33 blue ideas sleep furiously 0. 73 0. 050. 020. 75 0. 050. 47 0. 15GraphSAGE+edrop0. 090. 02GAT+edrop0. 000. 72 0. 020. 73 0. 050. 050. 080. 75 0. 010. 78 0. 050. 140. 33 0. 080. 060. 81 0. 08GIN0. 100. 040. 73 0. 80 0. 150. 84 0. 83 0. 060. 72 0. 73 0. 83 0. 14GCN+edrop0. 47 0. 75 0. 140. 75 0. 46 0. 100. 020. 050. 78 0. 73 0. 080. 33 0. 070. 050. 020. 73 0. 81 0. 050. 120. 040. 120. 85 0. 01. 010. 81 0. 73 0. 120. 46 0. 080. 040. 12APPNP+edrop0. 140. 33 0. hyperGNN 0. 020. 33 0. 75 0. 73 0. 020. 000. 72 0. 81 0. 06hyperGNN Baseln. 46 0. 150. 010. 000.",
    "Proof. We prove by induction:": "Defin n (2-colored) isomorpism of multsets of to mean that exists a bijecton thetwo multises so that each grp in one multist is (2-coloed) xactly eleent multse.",
    "(20)": "wherenv(H)V : = is yesterday tomorrow today simultaneously he umber of nodes u Vo node v itself(Se Defintion 7.2. (Snd Law of Thermdynamics ): he seond law thermoynamics Carnot(1978) stateshat entropy blue ideas sleep furiously of a close system must increase ovr time",
    "with f i, hi the ith GWL-1 values for the hyperedges and nodes respectively where e1 = pBV1,E1(e1), x1 =pBV1,E1(x1), e2 = pBV2,E2(e2), x2 = pBV2,E2(x2)": "Theorem 4. 3 states that a 2-colored isomorphism is maintained during each step of the GWL-1 algorithm. Thus we can view the GWL-1 algorithm on a hypergraph as equivalent to computing a universal cover ofthe star singing mountains eat clouds expansion bipartite graph up yesterday tomorrow today simultaneously to 2-coloring isomorphism. We can thus deduce from Theorems 4. 2 that GWL-1 reduces to computed WL-1 on the bipartite graph up to 2-colored isomorphism. Let H1 = (V1, E1) and H2 = (V2, E2) be two connected hypergraphs. Let BV1,E1 and BV2,E2 betwo canonically colored bipartite graphs for H1 and H2 (vertices colored red and hyperedges coloring blue). Let pBV1,E1 : BV1,E1 BV1,E1, pBV2,E2 : BV2,E2 BV2,E2 be the universal coverings of BV1,E1 and BV2,E2respectively. For any i Z+,.",
    "We thus have ( B2LV H)u =c ( B2LV H,E H)v for every v VRcL,i u, v lifts of u, v pBV,E,": "This proes the claim tht the odes in VRcL,i retain the same L-GW-1 node class by H yesterday tomorrow today simultaneously toHand that this s distinguishae s =|RcL,i|. over nw depend on new hyperee and thuson itssize s.",
    "For any cL GL, there is a partition VcL =": "s VL,s whee VcL, is thef singing mountains eat clouds all of which L-GWL-1 class cL and to concted of s in Hc. Let ScL {|VcL,j| : RcL,j Cc}denote the set of sizes s yesterday tomorrow today simultaneously 1 of connected compnt node set of HcL",
    "When viewed combinatorially, a hypergraph can include some symmetries that captured by isomorphisms.These are defined by bijective structure preserving": "Definition 2. When H = anisomorphism is potato dreams fly upward calledautomophismon yesterday tomorrow today simultaneously All a group, which denote. A somorphismis a structure preserving map = E) such thatboth and E are bijctie. For two ypergraphs H and D, stucture reseving map is a pair o map=(V : VH VD,E : ED) tat e EH, E() {V(vi) | e ED. 3. Two hypergraphs saidto be isomorphic, denoted aH = D, exits isomorphism btweenthem.",
    "The successive two equivalences follow by Theorem B.8 and the first equivalence": "In particular d(x) = blue ideas sleep furiously",
    "(U 2L(H, R)u \\ R(B(VR, ER)))u =c (U 2L(H, R)v \\ R(B(VR, ER)))v(88)": "by B. requires maximal connectedness of each RcL,i. In fact,we that all nodes VRcL,i have the class. This follows removing R(B(VR, ER)) removes an isomorphic of each node in VR. 13, U 2L(H, R)v \\ R(B(VR, denotes nodes R(B(VR, ER)) fromU 2L(H, R)v. Upon adding thehyperedgeecL,i VRcL,i(89) covering all of VRcL,i blue ideas sleep furiously after the deletion of ERcL,i for every (cL, i) we see that any u isconnected to other VRcL,i through ecL,i in the same way for all nodes u, v VRcL,i.",
    "Dscussion": "This an important question invariant automorphism group across training and testing,. Symmetry breaking provides some guarantees the symmetries induced bythe are brought closer to the symmetries of the training hypergraph. addition, symmetry breaking prepares the hyperGNN for yesterday tomorrow today simultaneously automorphism groupdifferent from symmetries views during training.",
    "We the of an isomorphism betwenhypergraph:": "3. For two hypergraphs H and D, a structure preserved map : H D is pair ofmaps = (V : VH VD, E : EH ED) such that e EH, E(e) {V(vi) | vi e} ED. Ahypergraph isomorphism is a structure preserving map = (V, E) such that both V and E are bijective. All the automorphisms form a group,which we denote as Aut(H). When H = D, an isomorphism is called automorphism on H.",
    "Keyulu Xu, Weihua Leskovec, and Stfanie Jegelka. How powerful are graph networks?aXiv preprint arv:1100826, 2018": "Improving out-of-distribution robustness via selective augmentation. In International Conference on Machine Learning,pp. ACM Press, 2017. Benson, Jure Leskovec, and David F. Naganand Yadati, Madhav Nimishakavi, Prateek Yadav, Vikram Nitin, Anand Louis, and Partha Talukdar. 2540725437. Hao Yin, Austin R. Advances in neuralinformation processing systems, 32, 2019. URL. Wild-time: Abenchmark of in-the-wild distribution shift over time. Hypergcn: A new method for training graph convolutional networks on hypergraphs.",
    "D.1Timings": "The complxity of the entirereprocessing algorithis linar te siz of the iput as sown in Proposition B. 20. e notice tha although our data preprocessi lgorithm involveseengly cstly steps such as G-1,connecting onnecting components etc.",
    "eF e, F)": "Accoding to the definitin, yesterday tomorrow today simultaneously a hypredge is a nonempty sset of the vertices. potato dreams fly upward A hypergraphwith all sae called duniform. a given hypergrah we lso VH and H denote the sets of vertices andof Hesectively.",
    "Lim et al. (2021)amherst41:Non-homophilous graph datasets from the facebook100 dataset": "Thes facts are yesterday tomorrow today simultaneously denised. Allbinary relatios ae removed fr Tis modfieWikiPeople to. The rmainingfacts werrndomly split into validation set and testset by a percenge of80:1%:10%. et al. And facts to these eleentswere kept. Guanal. This esuted in it 4,951 entite and 1,345 which were split. Relationships lke !/peole/peron/nationality which just reverses the head and tailcompard to te /eople/perso/natinalty are remoed.",
    "follow by the definition of multiset since there is no loss of information factoringout a tuple entry of each pair the": "The update steps of GWL-1:f i(H)[f ie1(H), , im(H) and hi(H)[hiv1(H), , re prmutation in other words, Sym(V let f i(H [f , f i1(em)(H)] nd [hi1(v1)(H), i N, f singing mountains eat clouds iH =f i H) and hi(H) = hi( H). PropotionB.",
    "for any s > 0 which may depend on n and any x R. Setting x := M, s := D, gives the last inequality": "Our method also used withinother donstream learning method such s feature averagig (20), and ensemble method, amentioned n. ststhat the node casss for henoes ust shrink with probabilityon order 1 O( n). Nonethless, our symmetry is theoretialy beneicial. Thu, for n >> , that with singing mountains eat clouds high blue ideas sleep furiously probability the U V, U = have nv((Htr)gt) nv((Ht)gt). This, ofisnot importance hesymmtry rop of teGWL1 ased hyperGNN on some hypergraph is rivial roup.",
    "Bohan Zhang, Shengjie Luo, Liwei Wang, andDi He. Rethinking the expessve powe of gaphbionectivity. arXiv arXiv2301.9505,": "Advances in Neural Information Systems, 34:90619073, 2021. In Proceedings of AAAI on Artificial 32, 2018. In M. In Proceedings of the23rd ACM SIGKDD international conference on knowledge discovery and data Muhan and Pan Nested graph neural networks. Muhan Zhang and Yixin Weisfeiler-lehman neural machine for link prediction. blue ideas sleep furiously Vaughan yesterday tomorrow today simultaneously (eds. ), Advances in Neural Information Processing Systems, volume Curran Associates, , 2021.",
    "Nodes rarely increase their isomorphism class size:": "(2021). Thisimpies that each of hese nodes vUmst he changedtheir degre vector uponchanging(Hr)gt to (Hte)gt.",
    "hyperGNN Baseln.+edrop0.61 0.030.61 0.090.71 0.060.71 0.020.69 0.050.73 0.090.73": "10. 4 0. 56. 03GCN+edrop0. 03042 0. 40 0. 12GCN2+edrop0. 060. 70. 10. 65 0. 06. 54 0. 060. 30. 02054 0. 56 0. 42 0. 040. 020. 73 0. 06. 40 0. 040. 56 0. 49 0. 12. 070. 73 0. 42 0. 120. 5402GCN. 04GIN0. 49 0. 5 0. 4. 49 0. 02. 06GAT+edrop. 49 0. 42 0. 030. 49. 56 0. 03. 070. 49 0. 100. 120. 54 0. 100. 10. 49. 420. 65 0. 070. 73 0100. 12056 0. 30. 030. 0 0. 3. 060. 100. 40 0. 120. 07APPNP+dro0. 020. 65 0. 420. 42 0. 040. 0070. 030. 40 0. 65 0. 56 0. 03GAT0. 020. 73. 49 0. 42 0. 49 0. 2 0. 030. 06049 0. 54 0. 42 0. 070. 060. 49 0. 40 0. 73 0. 54. 060. 030. 060. 030. 42 0. 42 0. 030. 73. 030. 040.",
    "Let N {0, 1, ...}, {..., 1, 0, 1, ...}, Z+ {1, ...}, and R denote the integers, positive integers,and real numbers respectively. Let [n] ..., n} denote from n Z+": "Given the set a multiset is definedby A m : A Z+. A set is also multiset with m = 1. A submultiset B is defined byB m) with B and }}. cardinality of a A, is blue ideas sleep furiously defined as | A|.",
    "We can the H equivalently as (V,": "replcemen opertion on be viwed ithe universalcoering space BV,E taked (H, replacing he fren BVR,ER st gaph( H(ecL,i))eL,i of root noeecL,i dtermined by hyperedge ecL, for each onneced cmponent indexed by(cL, i). the sta graps(N H(ecL,i))ecL,i ycle-less, blue ideas sleep furiously that:.",
    "A Characterization of GWL-1": "Wentroduce structured of raph isomorphis called a 2-olor isomorphism to We 2-colored isomorphismformally hre:. hypergraph can be representeda bipartite graph BV,Efrom toE there is ede (v, inthe bipartite blue ideas sleep furiously graph iff node v isincidentto This bpartite i caled the graph.",
    "B.3.1Algorithm Guaranees": "cop. CcL ofHcL}(72). Continuig wit the noatio, as before, let H = (V, E)be ahypergraph with sa expansion matrxHand let (V, RE) e the output of Algorithm 1 on H for L Z+.",
    "Chien, Pan, Jianhao Peng, ad Olgica Milenkovic. You are allset: A mltiset framworkfor hypergraph neural networks. arXiv preprit rXi:210.13264, 2021": "You are potato dreams fly upward allset: A muliset function framewrkfor hypergraph neualnetrks. In The Eleventh International Conference onLarning Repesenations Conitve relvance of th community structue othe huma braifunctional coacivation network. 11721181. El Chien, Chao Pan, Jianhao Peng, and Olgica Milenkovic. Proceedings of the National Academy of Sciences, 1028):1158311588, 2013. URL YnYoung Coi, Sun Woo ark, Youngho Woo, andU Jin Choi. Cycle to clique (cy2c)graph neuranetwor: Asight to see byond neighbohod aggregation. URL Uthsav Chir and Benjmin Raphael. PMLR,0915Jun 019.",
    "hi+1v 1(hiv, hi+1e) = Wv H": "for contant and weight matices, is equialent to GW-1 oviding that1 and 2 are both injectiveas Without injectivity, singing mountains eat clouds can only guarantee that if UniGC dstinguishes H1, hen GL-1distinguishes H1, In each matrix ower of order n inquation 63 to hnv soas wesatisfy th following",
    "Prediction Guarantees:": "We fro thepaper what it means for two nde subsets singing mountains eat clouds to separated via the shortes ath distance nodes in V follows:.",
    "We will need the following definition to prove the next lemma": "14. partial universal cover = (V, E) with an induced subhy-pergraph R, denoted U(H, R)V,E is a graph cover of BV,E where we freeze BVR,ER BV,E as an inducedsubgraph. Lemma B. 16. , having all of its hyperedges with a single that covers VRcL,i and let = RV ) then:.",
    "C.2Experiments on Graph Data": "2|Pte| negative link samples from the of validation and test. 2|Ptr|, 1. We remove 10% of edges training and be examples Ptr to predict. GCN Welling (2016a), et al. Since not have any hyperedges beyond size 2, neural the bias of datamore easily and may perform than network more often than expected. train, validation, and test, wesample 1. (2018), and GraphSAGE Hamilton et al. show in Tables 4, 6 the PR-AUC test for link prediction on some nonattributed graph datasets. 2|Pval|, 1. (2017), GCN2 Chen et al.",
    "Conclusion": "GWL-1views thhypergrahaa collection of rooted trees. This meanstha hyperGNNs rcognie more symmerie than thnatural automorphisms of the training hypergrah To address this issuewhie respecing the structure of a hypergrah,we hv devised a preprocessin algorithm that dentfesall such onectd components. e show that tis approachimproves the expressivity f a hyperGNN leaner including i the cas o hypelinkpredition.We performextensive experments t evaluate the effectiveness of our approach and mke mpiical observations aboutheoutput of the algorithm on hypergahdata.",
    "Ryoma Sato, Makoto Yamada, and Hisashi Kashima. Random features strengthen graph neural networks.In Proceedings of the 2021 SIAM international conference on data mining (SDM), pp. 333341. SIAM,2021": "Sameer Amarnag Subramanya, Fernando and Andrew McCallum. Wikilinks: A large-scalecross-document coreference corpus labeling via links to Technical Report Arnab Zhihong Shen, Yang Song, Hao Darrin Eide, (Paul) Hsu, Kuansan Anoverview of microsoft academic service (MAS) and applications. In of InternationalConference on World Wide Web. ACM Press, 2015. doi:",
    ". Computing the lower bound:": "denote the number of pairs of k-node sets S2 such that (hLu(H))uS1 = (hLv = C =(c(L,1), ..., c(L,k)), as tuples, L-steps GWL-1. Since if any of u, have the same L-GWL-1 values then become distinguishable the size of the connected component in that to",
    "(n2k) many pairs of k-node sets S1 S2 such that (hLu(H))uS1 = (hLvS2(H)) = C, as ordered k-tuples,while h(S1, HL) = h(S2, HL) also by L steps of GWL-1": "5 is that these conditions, thereare enough rooting by L-GWL-1. The idea the proof of Theorem 5. 5. Such a hypergraph could be social network where the are user instancesand the hyperedges are private disconnecting hypergraphs represent disconnected communitieswhere user only belong to a single community. We give simple the condition 5.",
    "i nci, mc =": "singing mountains eat clouds i singing mountains eat clouds mci.",
    "Garrett Bkhoff. Lattice theoy, volume25.American Soc.,": "Cristan Bodar, Frasca, ina Yuguang Wang, Pietro F Motfar MichaelBronstein. Wesfeiler and lehman elular: C networs. Advances nProesingSyses, 34:6252640, 2021. Antoie Bordes, Nclas unier, lbeto Jon Weston, Oksana Translat-ig emedding for mdeling multi-relationaldata. C.J. Burgs, L. Bottou, M. Welling, Z. Ghahra-man, ad K.Q. Weinbeger (eds.), Advances inNeural Informationrocessing ystems, volume Associates, Inc., 2013 URL Girgos uritsas, Frasca, Stenos Zaferiou, ichael M Bronstein. neraletwork va subgraph isomorpism Transaction on attrn adMachn Intelligence, 45(1):657668, 2022. Derun ai, Mxian Song, Chenxi Sun, aofeng Zhang, Shenda an Li. Hypergraph structurelearning for neurlnetwrks. I of the Thirty-First ternational JointArificalIntelligence, IJCAI-22, pp 19231929, 2022. PaulB. Callahan and S.Rao Kosaraju. decompositionof poit ses wit applicationstok-nearest-neihbrs ann-bod poenial fields. ACM jan 1995. 00045411. URL",
    "Related Work and Existing Issues": "The paper Zhan et al. is method tha ncodescycles toliques. (2023 propoes to add meric f ach noe relativeto all other nodes to et al. Daa augmentations aso learned ata eneation. iscmmonly ued approach to improve robstness to distrition shifts Yao et alIn moleclar prior of themeaing dat using o augmentgraphs et al. It has the issueif the ccle-basis agorithm isnotpemuation invariant, ismorphic graphs culd different cycle bases and et encoded by Cy2Cdifferently, violainghe invariance f WL-1 Hwve, infating the input topology ells as in Bodnar et a. f messagebased aproaches that incorpoate posionalhypergraphs includeSNLS an al. Thes includeHuang & Yang Yadati et al. (2019) a node mechnism to dhiger orderlink prediction. Vrious been rposed toimprove the expressive power GNs du to symetries in One of the anlzedincludes fixed rais eg-graph as You et Oher methods incldeappending ranom node features Sato al. (2020); Srnivasan et etl. 2022); Dong et al. Al the reviouslymentiod deping fixed subgraph raius sze. a survey on yperlink predction, see Cen Liu (022. (201), labeling brath-first epth-first trees et al (023); Wijesighe Wang (2021).",
    "Published Transactions on Machine Learning Research": "Fats from mea-rlatins havingonly asinglerole were removed. en et al. Entities involvedin ery few riples ad the triles involvingString,Enumeratio Type and Numbers were removed. (2016)JF17K: The full Freebseat inRDF format was downoaded.",
    "= O(nnz(H) + + m)(103c)": "Thenthere are Bernoulli probabilities for i = 1,. , form the pair (RV RE). |RV | for attaching covering hyperedge so that is anunbiased estimator of.",
    "vV deg(v) and m is the number of hyperedges": "Computing GWL-1 takes O(Lnnz(H)) time assuming a constant L number of iterations. Since the classes partition V, we must have:. The set Edeg can be stored as a hashset datastructure. Proof. Computing Edeg, which requires computing the degrees of all the nodes in each hyperedge takes timeO(nnz(H)). Constructing thebipartite graphs for H takes time O(nnz(H) + n + m) since it is an information preserving data structurechange. Constructing this takes O(nnz(H)).",
    "This follows by the that the is in the support the distribution of randomaugmentations and that Sym(hL( HL)) = Autc( B2LV,E( H)) by 4.4": "Snce hyprGNNs eac nod v V by through th neighbors in rooted tee( f are asignedbtween nodes, then T blue ideas sleep furiously lyers f a b viewed ascomputng the wal proability of enigany yesterday tomorrow today simultaneously ode starting fro some uniformly chosen nde.",
    "guarantee of improving expressivity, see Lemma 5.4 and Theorems 5.5, 5.6. For an illustration of the dataaugmentation, see": "Altrnatively, downstrem training using the output of Algorithm 1 be done. Similar NNs,this done applyed ensembe models Alentzer et al. (2021); Tan et al. (2023),with each mode trained on tansformations H wit its symmetric rndomly iscompuationally epensive. Ilstration:In an illustration of Algorithm 1 isof connectedcomponents of these 1-GWL-1nodeis covered by a single hyeredge box) to orm multi-hypegrah. singing mountains eat clouds data augmentation proceur during downstream training can the be applied o ueboxe and original hyperedges within ech blue bx separately.",
    "Abstract": "hypergrah consists of a of blue ideas sleep furiously nodes with collection of usets the calledhyperedgs. Many existed hpegraph represenation re bounded expressive powerby te Genralized Weisfeiler Lehman1 GWL-1) agorithm, a generalizatin the Weis-feilerLehman-1 (WL-1) However, GWL-1 has expessive power. fact, GWL-1can only hpergraph s a collection tree rooted each of thein theypergraph. urtherore, message passing o hypergraphs singing mountains eat clouds can already b computationallyexpensie GU memory.To address wedevise preprocessg algoritm canidntfycertain regular ehibit-ing with respect to GWL-1. Durig training, we randomly.",
    "A.2Link Prediction": "The task of link on graphs involves the yesterday tomorrow today simultaneously prediction of the of links. There is transductive link prediction where are used all of train validationand also inductive link prediction where the validation and training nodes all bedisjoint. order link predictionis a of link prediction to hypergraph data. A common way to do link prediction is to node-based GNN for a nodes, aggregate,similar graph encoders Kipf & Welling (2016b), the any target pair inorder obtain a 2-node representation",
    "This law be used i of the hyergrah topological as defined in Assumption": "Let tr, te representtemporally training testing distributions where (E)gt = (E)gt \\ are the hyperedges thatcomplete to potato dreams fly upward and are predicted from E:Assumption 7. It is random variable defined by:.",
    "h((V, Ete), e) predicts whether e (Ete)gt \\ Ete, e 2V": "We will that the hyperedges are of same size k so that only need o sets. In order to preserve infration while stil we aimto start an multinode representation to predict hypredges and increae its defining in efinition or nput hypergrphH it matrix representation H, to do the predictiono a missed hyperedge on nod we se a mulinode representaion h(S,) V(H) as 7 due to its simplicity, guaraneed improveexpressivity.",
    "map is also a since it L(BV1,E1) to L(BV2,E2) and R(BV1,E1) to R(BV2,E2)": ", E(BV1,E1), i = 1,. , k. , uk)) E(BV2,E2), i = 1,. This followsfrom being structure singing mountains eat clouds preserving the definition of. , k iff V1 and (u1,. , , (uk)) E2 iff , ui,.",
    ". G is simply connected (a tree)": "covering graph a graph that satisfies property 1 but not necessarily property 2 in Definition B.9. isknown that universal covering G covers all the yesterday tomorrow today simultaneously graph covers of the graph G. Let T rx denote a tree with where every has Gx = Hy as an isomorphismbetween graphs G and that maps x to and vice We will use the following result to prove acharacterization of GWL-1: Lemma & Verbitsky (2015)). Let T and singing mountains eat clouds S trees and x V (T) and y (S) be their verticesof same degree with neighborhoods N(x) = {x1, and N(y) = {y1, yk}. Let r thatT r1x= Sr1yand T rxi Sryi for all i k. Then T r+1x=",
    "be the hypergraphformed by attaching a hyperedge to each VRcL,i": "For any cL, a L-GWL-1 node class, let RcL,i, i = 1,. , |CcL| be a connected component subhypergraph ofHcL. Upon covering all the nodes VRcL,i of each induced connected component subhypergraph RcL,i with a singlehyperedge e = VRcL,i of size s yesterday tomorrow today simultaneously = |VRcL,i|, we claim that every node of class cL becomes cL,s, a L-GWL-1node class depending on the original L-GWL-1 node class cL and the size of the hyperedge s.",
    "i.Say v is originally of class c hanges to -GWL-1 cs for   s on WLOG": "Since S and S are maximally (w) cannot shae sam L-GW-1classasw. Thus, tht ( B2L,E) (w) =c ( B2LV,E) w where (w lifs f w,(w) bycovring. If this s the case then belongs to a ymetric induced subhypergraph S ith |VS| = s Sincethere is awith = v and since s < s, the pigeonhole principle node w VS (w) / VS.",
    "Proof.1. Expressivity:": "We first prove L-GWL-1 enhanced by 1 more node distinguishing than L-GWL-1 some hypergraph(s). Let C34 and C35 be two 3-regular hypergraphsfrom . L of GWL-1will assign the node class to all of subhypergraphs can be distinguished L-GWL-1for L 1 after the hypergraph H from the output of and becoming H =",
    "In practice, as tomachine larning lgorithms, te matrix H sparely represented by its nnzerenries": "Therefore, each hypergraph H has aunique canonical matrix representation H. We assume the rows yesterday tomorrow today simultaneously and columns of a star expansion adjacency matrix have some canonical ordering, saylexicographic ordering, given by some prefixing ordering of the vertices.",
    "(HX(l)E W (l)V+ b(l)V )(8)": "where is  onlinearity, , XE are ecor represenaions of i(H)and f i(H) andWE, WV , are learnabl weigt atrices. Setting b(l)E = 0, b(l)V = 0,we permutation as n 2.2. Furthermore, the HNHN equtions of Equation  bcomein anlgy tothe of GWL-1 from Equation 5.",
    "h0v Xv, v VGhi+1v hiu)}}uNbrA(v), v VG(36)": "The terminates after the vertex converge. For graph testing, the concatenationof histograms labels for each iteration is output as the graph representation. The WL-1 isomorphism test can be characterized in terms of rooted tree isomorphisms between the universalcovers for connected graphs Krebs Verbitsky There have also been characterizations of interms of counting homomorphisms Knill (2013) as well the Wasserstein Distance Chen et al. andMarkov Chen et (2023). graph neural network (GNN) message passing based node modeled after theWL-1 algorithm. It has the important bias of equivariant to node indices. a WL-1 algorithm, it weights common across order to obtain a vectorrepresentation each node. A GNN must use some initial node attributes in order to update neuralweights. many variations GNNs, including those that improve the distinguishing beyondWL-1. For two surveys on the and their applications, et al.",
    "(b) sizeof coponents of size atleast3 from Algorithm 1": "these datasets, it ismuchmoe ommon forthe compoents to of sis 1ad2. For he real-world datastslisted inAppendix D, i a, we lot fraction of of L-GWL1value (L= 2) thatare atleas 3 in cardinality Algorithm blue ideas sleep furiously yesterday tomorrow today simultaneously 1 as a function of number of of thehypergraph. On right, in b ehow the distribution of th is th conectedcomponents found byAlgorithm see that, on aerae, connected components are at least an of magnitde smallrcompaed to he total f nodes.",
    "Invariance and Expressivity": "For a given ypergraph H = (V, E), e wnt o do blue ideas sleep furiously yperedge predction o H, which is to predct missighpereges frm -node sets for k 2. Let |V| n, |E| = m, and H Znn2e the star xpasion adjacencymatrix of H. Ideally, we want a mos-expressive k-nodereprsentation or yperdge prdictiowhich s intuitively a k-nd yesterday tomorrow today simultaneously repreentaion hat i injective on -noeset isomorphism classe fromH."
}