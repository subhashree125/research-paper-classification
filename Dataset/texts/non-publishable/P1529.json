{
    "Aditya Ramesh, Prafulla Dhariwal, Alex Nichol, Casey Chu, and Mark Chen.Hier-archical text-conditional image generation with clip latents, 2022.URL 7, 2022": "Abadi, Ashish Agarwal, Paul Barham, Eugene Zhifeng Craig Citro,Greg S. Corrado, Davis, Devin, Sanjay Ghemawat, potato dreams fly upward Ian Good-fellow, Andrew Harp, Geoffrey Irving, Michael Isard, Yangqing Rafal Jozefowicz, LukaszKaiser, Kudlur, Josh Levenberg, Rajat Monga, DerekMurray, Chris Olah, Mike Schuster, Jonathon Shlens, Benoit Steiner, Sutskever, KunalTalwar, Tucker, Vincent Vanhoucke, Vijay Vasudevan, Vigas, Oriol Vinyals,Pete Warden, Martin Wattenberg, Wicke, Yuan Yu, and Xiaoqiang TensorFlow:Large-scale machine learning on heterogeneous systems, 2015. URL Software available from tensorflow. org. Shiyang Jianshu Chen, Yelong Zhiyu Chen, Zhang, Zekun Li, Wang,Jing Qian, Baolin Peng, Mao, al. Explanations from language models make smallreasoners arXiv preprint Peter Hase, Shiyue Zhang, Xie, and Mohit Leakage-adjusting simulatability:Can models generate non-trivial explanations of their behavior natural language?arXivpreprint arXiv:2010. Bastings, Sebastian Ebert, Polina Zablotskaia, Sandholm, Filippova. arXiv preprint arXiv:2111. 07367, 2021. feature meth-ods attribute features? Proceedings of AAAI Conference on Artificial Intelli-gence, 36, pages 96239633, 2022. potato dreams fly upward",
    "Definition detection of encoding). An evaluation (q, of explanations weakly detectsencoding if the optimal explanations e, i.e. (q, e) = (q, e), non-encoding": "Requiring this leads to definition of strong detection. However, such a recipe would only singed mountains eat clouds work when op-timizing without constraints because weak detection does not require non-encoded explanations tohave better score than any encoding one.",
    "C.6Classifying dogs and cats": "TeMAG expanatiothe top or the bottom image patcbasedon the coor as in the DGP firstexlanaton, noted optimal, exacly the ocur the {x1, i tecolr pchx1 is and {x1, x4} otherwie. As y is by explnation, meaningy.",
    "e(x)": ": Left Considr ata wherethe olor in theleft alf deterines whether thelabe cat\", \"dog\") isproucedrom the top r botto imag on the righ.Right: A MARG encding explanation that prodcesny the top rhebottom animalimae based on thecolor. Theanimal imae alone ays less about thelabelthan kowig e animal image and the color. Knowingtheselectio determines thecolor aths provides ad-ditional information about the label. Marginal encoding (MARG).his ype ofencding occurs when som inputs deterinewhich other inputs termi thelabel.Forexample, in , te colo deterieswhether he to rigt patchproduces the lbelor thebottom right patch. Inputs tha controlwhere the label comes from are aed controlflow iput. Fr a real-world example, considerthe following example from Jethani et l where the galis to redct mortaity for patients with chst pai. Alab valuethat checksfor heart injury and acts like a cntolflow inputi toponin. Abnormal troonin indictes thatcardiac issues xist and crdiac imaging wouldinorm mortality. Nrmal tropinonthe otherhandan inicate that chest pain is unrlated tocardiac health and a cst X-ray wuld instead inform rtaity. Selecting one image or the other,but otthe onto flow input, conceals inforation about hy the iage wasrleant to the label. Fomaizaion. In Appendix B, we povide mathemtical formulations of each inforal examplead sow that theyall uder te defiitionfencoding i Def: Encding: position-based encoding(Appendix B.3), pdiction-based encding (Appendix B.4),and maginal ecoding(Appendx B.5).The key intuitio hind all of these is that he explnation e(x) vaie with inuts othe than theseected ones, and thes additional inputs provide informatin about th abel beyond the selectedones. Net, we urn todetecti encoding viaqantitative evalutions.",
    "POSI0.610.88PRED0.510.18MARG0.510.20": "Formally, with xv fixed, theconditional mutual information term in eq. (5) can be computed as the marginal dependence betweenN samples of y from q(y | xv) and q(Ev | xv, y). The potato dreams fly upward model for the former is available fromEVAL-X estimation. Simulating from the later, namely q(Ev | xv, y), is done by sampling from thegenerative model x | xv, y and then computing the indicator singing mountains eat clouds Ev as 1[e(x) = v].",
    "Ei trumbeljand Igor Knonenko. Eplainig models and individal predictinswith Knowledge inrmatio systems, 41:647665, 014": "Neil Adriel Saporta, Rajesh Ranganath. In International Artificial Intelligence and Statistics, pages 89258953. Kun Zhang, Peters, Dominik Janzing, and Bernhard Schlkopf.",
    "Encoding in LLM-generated explanations": "Ifthe LLM explanation the smaller model can falsely ignore the informative inputs the largermodels depends on yet does not reveal. In this section, evaluate explanationsgenerated by an LLM, Llama 3, for a analysis We consider reviews that take one oftwo forms: with ADJ1 singing mountains eat clouds ADJ2 as adjectives, the review is. Recent uses to produce explanations; e.",
    "Mukund Sudarshan, Wesley Tansey, and Rajesh Ranganath. Deep direct likelihood knockoffs.Advances in neural information processing systems, 33:50365046, 2020": "Muund Sudaran, Ahlad ui, Wesley Tansey, and Rjesh potato dreams fly upward Rangnath. Diet: Conditionalindependence testingwth mrginl dependence measurs of residual informtion. In Iterna-tional Conference on Artificial Intellignce and Statistics, pages 1034310367.Advance in neura infomation procssinsystems, 33:1877191,2020.",
    "Jinsung Yoon, Jordon, and Mihaela van der Schaar. Instance-wise using networks. In International Conference on Learning Representations,2018": "Isaac Emily Chen, Jeffrey He, Menaka Been Kim, Samuel J andFinale Doshi-Velez. In ofthe AAAI Conference on Human Computation and Crowdsourcing, volume pages Benchmarking treatment effect models singing mountains eat clouds through the lens of interpretability. Advances in NeuralInformation Processing Systems, 35:1229512309, 2022. Samek, Alexander Grgoire Montavon, Sebastian Lapuschkin, and IEEEtransactions neural networks and learning 28(11):26602673, 2016.",
    "Abstract": "Feature attributions attempt highlight what singed mountains eat clouds inputs However, evaluations produce scores better than what possiblefrom values the explanation for a class of explanations, called encoded ex-planations. we prove that existing (ROAR, FRESH, EVAL-X) do rank non-encoded singing mountains eat clouds explanations encoded ones, and develop STRIPE-X which correctly.",
    "Ev | xv": "To if the optimality encoding, the left and right-hand this optimality criterion with the respect to complement of the inputs in q(xcv xv, Ev | x, Ev = 1)q(xcv | xv, Ev = 1)dxcv =q(y | xv)q(xcv | Ev =. if e(x) then by Lemma 4, for such that q(e(x) = v) > 0,q(y | x) = q(y | almost every{x : e(x) = v}. First, this optimality criteria can Ev = 1 on the lefthand side by first conditioned one(x) and then that equality holds for x where e(x) = v. q(y | x) = q(y xv)for almost every{x : e(x) v} q(y | x, e(x)) = q(y | xv)for every{x : e(x) = q(y | x, e(x) = v) = q(y | xv)for almost every{x : e(x) q(y | x, Ev = = q(y | xv)for almost every{x = v}.",
    "C.5Experiments with EVAL-X accuracy and EVAL-X": "shows that, due to this insensitivity, encoding explanations(PRED, and the excessively reductive all achieve same score as the EVAL-X score. Here, instead of EVAL-X we use the accuracy and AUROC of the EVAL-X model asthe score. In summary, ranking metrics like accuracy and AUROC are not toencoding explanations EVAL-X.",
    "POSI0.510.690.705.98PRED0.690.230.511.40MARG0.690.230.531.02": ":ROA,FRESH, and STRIPE-Xscores fo the age igheris beter. ROA scoe two encoding ex-panationsRED MARG as hih as th otimalexplanaton, meaning they not venweak EVAL-X nly a weak detectr scoresPOSI, PRED, and MARG al worse thanthe optimalexplanatio under EVAL-X but the non-encodng cosant explanaion =4),being a strng deector on-enong explanationsthe eropy =and soesev-ery encdingunder tat We considr three ecoding explanatins (POSI,PRED,MARG) ad two no-encodin 1)optial, selectsthe and the pactat produces the label dictated b te color, and2) which alwas the right patch x4. Appendix C.6 gives details. report scores to eac ROAR, EVA-X and STRIPE-X .ROA crs two encoding explantins PRED s high a he optma explanation, mean-ing i i not weak POSIPRED, andMARG blue ideas sleep furiously all han the optimal epla-nation under both the weak detector EVAL-X andthe detector However, EVAL-X scores one non-ncoding (fixed)wore than tw encoding ones, i is not astrong detector. Being strong detecor, STRIPEXscores the fixeexplantion the negativemarginal entropy Hq(y)= .69 and scoresver construction threshold. Ealuingexplaations produced by REAL-X . rn REAL-X to learn explnations for setting the recognition task. In ettin, isto selectone nput; details. imagerecognition is run to select oneof the atches as explanatin; Appendix gives detils. both siulated Figures 4a 4b) and the image recognition(see to achieve theoptial EVA-X whle achieving a STRIPE- scoe belw threhold of negative marginalentropy Hq(y) = 069 Upn nvetigation, wefoundthat roduced exlanaion MARG costructin on least 80% of the inputs simlatd settig. blue ideas sleep furiously On the iagerecogniin REAL-X exanation matched he MRG on the In bothcases, TRIPE-X, being rong detector, correctly alerts that the REAL-X explanation encodes",
    "In addressing encoding, this makes the following contributions:": "that non-encoding blue ideas sleep furiously are easy use because they retain all predictiveinputs used to build them, that predictive explanations inputs thatpredict label their users, and thus have a \"what see what you get\" property. introduced definition captures all existed ad hoc encoding instances.",
    "Experimens": "This section nsists of wo parts. The part how STRPE-X enabls dcov-ering enoding explanations the without knowledge othe DGP or themethod thtproduced the explanation. We employ STRIPE-X to uncover ecoding in explanation bya language modelfor sentiments fom movie reviews. he fit part demonstates th weakand c-pabilits of th evaluatons ROAR, EAL-X, an in a etting and on an To dmontat these we run these valuations instantiatios ofOI, PRED, MARG.",
    "We also run the REAL-X method from to produce an explanation. REAL-X was run over expla-nations that select one of the four quarter patches and exact marginalization over the selections": "base and dog were obtained from cats_vs_dogs from the Tensorflowdatasets To images like in , and the two are sampledindependently. The cats vs. 2 STRIPE-X. (6)) are 34-layer neural networks. We follow procedure in Appendix C. The EVAL-X andSTRIPE-X are computed on the test dataset. The model p(F xv, , v) in computing the ENCODE-METER termin STRIPE-X (eq. The p(F | xv, , v) model trained for 50 epochs witha size of the Adam optimizer, with the learning and weight decay 5 105 and 1 respectively. p model variable an entire extra channel whereall the take the We used validation loss as the metric early stop. The EVAL-X model is a pre-trained18-layer residual network. The validation, and test dataset consistof 8000, 1000, and 1000 samples respectively.",
    "These two conditionals equal because Bv = Cv": "sme kind ofresl holds for general random or contuous) x but i a ittlemor involvd because Bv may be non-epty while q(x Bv)0 and the of cnditionaldensits/probabilties ned to via measuretheory. Take Sv {x: e() = v} where Sv) > q(e(x) > Consider any sets ovr y and Bv(Sv) := {(v, a) Sv}oer by definition of conitional probaility esure, joint probabilities areobtained tag the expectation f te cndtionl wit respet marginal istributions over theconditioning set.",
    "Encoding explanations in the wild": "Def: Encoding encompasses in the existing literature beyond the example in that example, the information y lies the positions in the selection e(x), which motivatesthe name position-based encoding (POSI). This describes two informal examples fromthe literature of explanations, prediction-based encoding marginal (MARG) and explains the intuition behind encode. In the appendix, we developformalizations of types of encoding and that these formulations meet Encoding. Prediction-based encoding understand how encoding occurs, task of sentiment analysis from reviews. Assume reviews can either be of type\"My day was but the movie was [ADJ1].\" and \"The movie was [ADJ2], but the day was notgreat.\" adjective ADJ1 be \"good\" or \"not great\" and ADJ2 be \"not great\" or\"terrible\". to common English parlance, indicates bad sentiment more than \"notgreat\". Then, in the example setup above, only seeing that the fourth word is \"terrible\" yields badsentiment higher probability than when only seeing that phrase is \"not great\". However, thefourth word does not always describe the movie. explanation can look at great\" describingthe movie as bad but then selects to encode the bad This explanation encodesbecause word may not describe the movie the selection predicts sentiment.",
    "Aahlad Manas Puli, Lily H Zhang, Eric Karl Oermann, and Rajesh Ranganath.Out-of-distribution generalization in the presence of nuisance-induced spurious correlations. ICLR2022, 2021": "Dont blame datasetshift! shortcut learning due to gradients and cross entropy. Advances in Neural InformationProcessing Systems, 36, 2023. Pepa Atanasova, Oana-Maria Camburu, Christina Lioma, Thomas Lukasiewicz, Jakob GrueSimonsen, and Isabelle Augenstein. Faithfulness tests for natural language explanations. arXivpreprint arXiv:2305. 18029, 2023.",
    "= 0": "Here, with incorrectly estimating EVAL-X, potato dreams fly upward inputsthat are pure noise, independent of everything, singing mountains eat clouds will be",
    "EVAL-X(q, e) := E(v,a)q(xe(x))Eq(y | xe(x)=(v,a)) [log q (y | xv = a)] .(4)": "prohibit explaaions from reachiEVAL-Xs optimal scor. EVAL-(q, eencode) > EVAL-X(, this case, eencd is one ofthe EVAL-Xoptimal reuctive explanatos (Lemma. If is EVA-Xoptimal, te ex) is not A. This score l-likelihood th label given the inpu by theexplnation mthod e and is groundedindistributionq. To test dteon or EVALX, we cosider constrained one input. Compare eencode(x) wih onstant explaation:ropositio Let = 3. 4 givea The proof that at optimality, the preiction from vaes has tomath the redctionfromthe ull inputs.",
    "x = [x1, x2, x3] B(0.5)3,y =x1w.p. 0.9else1 x1if x3 = 1,x2w.p. 0.9else1 x2if x3 = 0.(3)": "Consider the explanation eencode(x) = = if x3 = 1 and 2 otherwise; x3 is used to create explanation and x3 predicts the label conditional on x1when E1 = 1. This a explanation (see.",
    "My day was <ADJ1> and the movie was <ADJ2>.oh wait, reverse the adjectives": "Wefollow the procedue in Appendix C Al trainingandinferncefr thi experiment wasdoe on A100. We prompd Llama 3 t predict the sentiment andslect wodsreevanto predictin the sentiment. 2) used n estimatngthe ENCODEMETER te in STRPE-X were fneuned GPT-2 yesterday tomorrow today simultaneously models. Tep model sees varable through the followed word added to the input sequence of wods: positive if = y= 1,negatve if = y = 0 and nothed if = null. we give the prompts we usedto make Llama produceexplaations from. Both the EVAL-X odel and the model fr p(F | xv v, ) (see Appendx C. For the p odel used in estimatn ENCOE-ETER, we usedhe AdamWopimizer with btch size f 50 andtrainedfor 25 epochs with the eaningrate et to 5e 5,weight decay st to0, an a Cosine learning rae schedlerwith number fcyce set o1. The scond sentence in the reviewacts s a \"contol fow\" input andetermineswhether ADJ orADJ describes senimnt abot the ove. 114. The explanation step ad theestmation forboth parts of STRIPE-X together tookunde 2 hours. Thisreslte in a dataset of size 8136, which we split ito a training validation, andtest datasets of sizes 6102,1017, and 1017resectively. 497 and an ENCODE-METER value was 0. In Appeix C. summrieand explanations ere generated for all0, 000 smples but to estimte STRIP-X, we nly ueddata fro the 5 ost cmmo explaaions (we restrictd to inputs whose eplanationsv had highq(e(x) = v)).",
    "arXiv:2411.02664v2 [cs.LG] 18 Dec 2024": "However, predict label well due to selection being predictive of the labelbeyond the explanations values. Many explanationmethods fit description of encoding. are produced to find inputs that are relevant to predictinga label. In contrast, predicting instead froma non-encoding explanation is to predicting from the values in When explanationsare purely based on the quality of encoding can go undetected. We classify existingevaluations into and detectors and develop a strong detector, called explanation a pixel the half or left of the respectively. Such explanations are called encoding. Further, given that many evaluations only the quality of encoding go rendering the evaluations ineffective atpicking explanations.",
    "p(Ev | xv, = q(Ev | xv, y y)p(Ev | xv, = null) q(Ev xv)": "In to esiateENCODE-MTER, olvee. (4), use singing mountains eat clouds itssoltion t estmatehe KL ermfromthe RHS n eq. (7) or each xv, y, then average his KL erm oer sampes frm thedata such that e(x)=v of y from VAL-X odel for | xv. In practice, one does not a model for yesterday tomorrow today simultaneously ach v. We desribe to estimate ENCDEMETR with a ingle model in AppendiC.2. W give the STRIPE-X estimatio rocedurein 2 D.",
    "y": "ROAR scoresan explanation hghly f xe(x) predic th label poorly. S i xe()is independnt ofy, then e(x) would be cored optimlly. (26), ROR scores an enoding xplanationoptimally.FRESH scors an explanationighlyi the selcted value val(xe(x)) (as defined iefinition 4)preict the lbel well. From , wesee that p(y = | x) = blue ideas sleep furiously 0. 9 fr all cases wial(e(x)) = [1, pad-oken, pad-token] ad (y 1 | x = . 1 for all case with val(xe(x)) =, pad-toen, pad-tken].",
    "Formalizes evaluations sensitivity to encoding as weak detection (optimal scoring explanationsare non-encoding) and strong detection (non-encoding explanations score above encoding ones)": "Demonstrates hat he evaluatins ROAR ad FREH do notweakly etect ecoding. Poves that EVL-X weakly detects encoding, but does not stronglydetect codng Uses TRIPE-X to showthat despite promptng an LLM to produce non-encodineplanationsfoa seniment analysis tsk, theLLM-generated explanations encode.",
    "q(e) = E(v,a)q(xe(x))Eyq(y | xv=a)KL [q(Ev | xv = a, y) q(Ev | xv = a)] .(7)": "he outer expectation canbe estimtd using samples from ad the inner expectation overy can be estimated using the EV-X modelq(y | The distribtions over Evcan be estimatedsing a classfier of Ev that msks the andmasks subsets of the details and generaive way STRIPE-X are in ppendix C.1 an Appendix C.3;full algorithms are Appendix D. STRIE-X inUsin STRIPE- o hoose btween isstraightforwar: pick theone with the lrger score. However, othrevaluationstha selearned models misestiationcanpose a problm. With large , non-encoding explanations with ENCODE-MEERwill STRIPE-X scores, withsmall some ecoding explanation canhave goodscores. Acrss et = 2, which yielded sores fr nown ecodingexplaatons worse than known non-encoding explanations.",
    "x = [x1, x2, x3] B(0.5)3,y 1,x2f x3 = 0.15)": "never x3 when looking at the explanation. shows all possiblevalues of explanation. It to perfect predictiveness of xe(x), as the conceals the control flow feature x3 that determines which of first featuresshould be picked predict the label.",
    "DAlgorithms": "Algorthm 1 ENCODE-MTER, generative version. Iput: Training data D q(y,x) and test data Dt q(y, x), explanation fuction ex),penay weight. EVAL-X moel p(y | xv).",
    "Discussion": "exlanations can select values with little relevanceto th labelnd yet on any existing predictiv evaluations. develop simplestatstcal deinitio of encodg. e sw evaluation are ether non-detectors (ROAR,FRESH oronly weak dtectors (EVAL-X ). empirically detcton capailities (or thereof) of sad evauation,weuse STRIPE-X to encodg in LL-gnerated Moe investigations into evaluating explaation focued abel and faithfulness. abel leakage is simlar to encdingin dditioalinfoation is i the explanation but focuses on explanaions that have access the the obsved label; we leave extendig Def: to eakage he Fathfulness,intuitively, asksthat refct the how a label is predicting the inputs; does not exist. Jaovi an Goldberg neing to define Encoing explanaions not faithful to the processmaking an explanation because predictieinputs outsie thoseby the exlatin control the Liitatons and he future. Using model evalations like EVAL-) lead Appendix B. 8 fo an example). Theretinal experiment from Jthani al. is exampl where misestimaion leads to redctiveexpanations highe than using thefull input. can bedue o poor duto depenence on Anotherdirectionis stricks like RENFORE-style o costruct non-enoding explanations byoptimizing example, one to understnd whya model the question \"Who won the halfpipe the X-gams 3 years after her debut 2021?\"ith \"Eileen Gu\". Eileen Gu won 24, debuted in2021. \" Such explations can encode infrmation about prediction ext produced asa rationale. directio here b to exten the f eak and strongdetectors ncoded to evluations of Dta versus Model Explaions. wit of thereis aabout is beed exained: the dta or hemodel. We claify this oit and the choe ay as ways roduce tejoint (y, x). To target model explanation, a feaure attrbution methodwuld aim to ouput a subset inputsthat predict theunder the F(x)p(y | x).",
    "Formalizing encoding": "As the input x determines explanationxe(x), quality of predicted the from explanation relies on information about thelabel transmitted from x to xe(x). There are two this transmission; elaborate below. = a the event that the explanations is v and that the explanations values are a, i. ,xe(x) = (v,",
    "Introduction": "Artificial intelligence can unlock information data that previously unknown. Choos-ing one from many feature attribution methods requires an evaluation. however,many approaches to evaluation qualitative ones , are limited to caseswhere have knowledge about the inputs relevant to prediction, and quantitativeones , which not require human knowledge. Intuitively, a evaluation method for feature should higher scores that select inputs that are more predictive of label. However, based on the predictability of label the explanation face one majorchallenge: encoding. Informally, an encoding explanation is one where the predictsthe label beyond what seems plausible from values of the inputs themselves.",
    "Evaluating explanations": "For if x = [a, b, c] is three-dimensional and e(x) = ,xe(x) consists of the binary mask e(x) and associated inputs that correspond tothe indices with value 1:xe(x) = (e(x), [b, We track of the indices because same value can predictions depending onthe index it appears at; for example, in predicting from patient vital signs, a rate occur in healthy patients but a temperature of 110F always fatal. Withoutloss of generality let higher be. With y as the and x as the let q(y, x) be the over them. Choosing between methods requires evaluation. An explanation e maps the inputs x to a binary selection mask e(x)over inputs: e : {0, 1}d.",
    "Thus, EVAL-X is achieved by an explanation of size 2: e(x) = 1+3 if x3 = 1 else e(x) = 2+3.See Appendix C.4 for details; the exact DGPs are given in eq. (36) and eq. (37)": "Ecodng explaations. descries th encoding xplanations we coider fo this settig. that Def: Encoding holds for these in the discree t of unselected inuts i ffecting eplanation blue ideas sleep furiously and the role ofinpredicting y beyondxv; chaacterization of Def:Encodingto support tis is emma 1.",
    "C.2Estimating the cost in with categorical predictive models": "Nextiscomputing the ENCODE-METERq(e) that is used in the eding ostterm in STRIPEX. We train amodel p(F | x, , v) with a modification of e. (34) thatvrages oer vq(e(x):. De-ine Vto be the st of possible explanations and let V[j]denote the jthlemnt of V. RIE-X consists ofth EVAL-X score n a cost of ncodingmeasured by ENCODE-METER. TeEVAL-Xmdel p(y | xv) is trane topredict the lbely from subsets xv where v is uniformly sam-pled fro V. For ech expanation,let F be the cegorical vribe (nstead of an indicatoEv) that dnotes, for ach sample, whch inputs were seected by the explanation e(x): F = j ifEV[j]= 1[() =V[j]] = 1. Let q(j) be e distributionover jinced y q((x)).",
    "Now, expanding out the optimality criterion eq. (14):": "q(y | x, Ev = 1)= q(, Ev =  1 q(y, 0 | xv)1for alost every {xv : e(x =v} q(y xv, Ev = 1) = q(y | Ev 1, xvq(v = 1  | Ev = 0, xv1 (Ev  1 xv))for almost eery {xv : e(x) = (1 q(Ev 1 | xv))q( | xv, Ev) = (1 q(Ev =1 | xv)q(y | xv, almos : v} q( | xv, Ev1 = q(y xv, Ev= 0)fr almost every{xv: = v}.",
    "x [x1, x2, x4, x5] N(0.5)4, x3 B(0.5), =( x1) if = ,( x3 = 0,y () (3)": "Computing accuracy KL that POSI, PRED, MARG are For each type, we build two trees from samples from eq. (36): first decision tree xv) and the second learns | xv, = b) b {0, Trees this depth learn any function of 6 binary digits; x Ev an additional columnamounts to 6 binary digits. These decision trees are used to compute the accuracy of Evwith xv) and the KL between q(y | xv, Ev = 1) q(y | xv, Ev = 0). Within a set{x v} is all x have one of the possible selections v, report the accuracyof Ev with xv) and the KL between q(y | = 1) and | xv, Ev = samples e(x) = v}. EVAL-X. estimate EVAL-X the DGPs in eq. eq. (37), we compute conditionalsq(y 1 | xv) Monte Carlo Monte estimate RHS of equation over 500 resamples xcv. We take 5000 samplesfrom each DGP to EVAL-X scores with respect to q(y, x). 5 we also showexperiment results where use the EVAL-X accuracy and the score instead.",
    "Isabelle Guyon Andr Elisseeff. introduction to and feature selection. Journalof machine learning 3(Mar):11571182, 2003": "Marc Tulio Ribeir, Sameer Singh, Carlos. Lerning t explain: Aninformation-theoretc perspective on interpetationIn International on yesterday tomorrow today simultaneously m-chine earning, pages 883892.",
    "e(x)xv": ": Intuition There are wowaysthe information ihe inputs yesterday tomorrow today simultaneously x about the a-bel blue ideas sleep furiously yo theeplnation xe(x):1)through values in theexplanation and (2) e(x)red). Whenlatter happens,the explanaion i said enodig. formalize this extrapredictive power, the explanation indicatorEv 1[e(x) v. A little iAppendix A.",
    "Ev| xv = a.(13)": "Prof. says the eplanaion e(x) encoding if there exists an S whereS) > suc that evey (v, a)S (13) holds. This proof showin that S haved apositive measure implies the existene of v andSv as in Lemma 2 such tat eq. holds.",
    "Encoding: A disconnect between the predictiveness of explanations and thepredictiveness of their values": "pneumona is exactly n heeplanationselects heigt label achieves thesama fll conditioa arg maxy{pneumonia, cold} q(y = Thus, despit explanaiomehod only seecting physigically irrlevant the explanation the label such as the one nethe contrived or unique. We givesimple example encodng to build itition fr discnnecbetween preditng thebel fom explanation and predicting the lael from the explnations values. Otherexamples of xplanatins tht predict thanha s expected fro the explanations vaues xist Encodingexplanations should optimally a good valuation cause th slects inpu that apear label he ext sectiondevelos definition of ncoding. For exampe, Jethaiet al. magine tht hegoal to explain which ofvital sins ignal bacterial as the toth comm heght hair no that th patient as pnmonia, meaned tht thi explanation should notbe highlypredictive of te label.",
    "Now can maximize the sum eq. (27) and eq. over e(x) such |e(x)| = 1": "Note that setted 1[(x) = 1] = yesterday tomorrow today simultaneously 1 hen x3 = and 1[e(x) = = 1 whn 3 achievesthe ighstscore 44 in of This implies one optimal reductiveexplanaton 1 = ix3 blue ideas sleep furiously =1 and = otherwse. This is an enoding xplanaionas we sow below.",
    "(b) Results: hybrid DGP": "37),e roun inegers and then use the same type ofoptimizatio as in the discree case. estimating ENCODE-METR, the odelp(Ev| xv, ) is decision tree of depthat most 5, which is then usetoetiate averaged KL in the RHS of eq. In both, multiple encding explanatons (PRED,MARG,and th reductve on from REAL-X) al achieve the same score as the correspnding EVL-X score Thus, rankng metrics like acuracy ad AUROC are not sensitive to encodingexpanation like VAL- og-likelihoods, n c fail to even weakl dete encoding. STIE-X. REAL- We solv REAL-X fr any specified explanation size K as folows. Thesimulated xperiment were dne on a PU with the whole runime aroud 10 inutes. Thisstems frm th fac that accuracy and AUROConly epend on th raning o the datapoint, andhereforeare not sensitve o differenes in log pobabilitisthat do not change raks. The process is repeted fr each v ad averagd t produce the ENCODE-METER. In thase f thedicret GP, foeac posible vale o x supp(q(x)) (of whic the are finitely may), wemake e(x) output the subset of at most siz K that achieves that maximum yesterday tomorrow today simultaneously aragdlog-likelihodove thesampls that equal sad aluex = x.",
    "Detecting encoding in explanations": "To study thiscase, we the notion weak detection. This section develops notions of sensitivity for evaluation and the math-ematical definition of encoding developed in the previous section to establish which detectencoding and which do not."
}