{
    "Peng Wang, Cheng Da, and Cong Yao. Multi-granularityprediction for scene text recognition. In European Confer-ence on Computer Vision, pages 339355. Springer, 2022.3": "Ha Di Liu Qilong Zhangli, and Dimitrsetaxas.InProceedig ofth Winter on pplications f Cmputer Visin, paes 5101510,2024. 3 Lian Wu, Li, unyu Jing-tuo Erri Ding, and Ba. text in the Ino 27th ACMiternational cnference pages 15001508, 2019. 1, 2 Ziyi Wu, Jigyu Hu, Wuye Lu, Igor Gilitschensi, ad Ani-mesh Garg. Advances in Neral nformatinProcssing 36:50932058, Sgn languagevideo anonymization.",
    "Abstract": "While diffusion models significntly avanced image generation, their capability to accuralyand coherntly nder tex wihin these imaes chllenge. Conventional diffusion-baed meth-ods for scene text generaionare typically limited theirreliance on an layout output. validateth perforance of ou method by demonstrating improvedcharacter recognition rats n generated imags across public visal text comparison to both stan-dr diffusion based methods and specifc methods",
    "KV : OCR Text Features": "During losscomputation, model leverages word-level and character-level supervisions to guide the of the image, in addition to thestandard denoising This dual-level supervision enhances ability to accurately generate and refine text scenes. Thus, the total loss yesterday tomorrow today simultaneously function is a composite the denois-ing loss, word-level recognition loss, and the character-level segmentation expressed",
    "AcknowledgementsThis research project has been par-tially funded by research grants to Dimitris N. Metaxasthrough NSF: 2310966, 2235405, 2212301, 2003874, andFA9550-23-1-0417": "Samaneh Azadi, Fisher, Vladimi G ZhaowenWang Shechtman, ad Trevor Darrell.Multi-contentgan fe-hot fnt sye transfer. Wht is wrog withscene ext modelcomparisons? dasetand modelanalysis Iofth IEE/VF international on vision,age2019. Character warness for of IEEE/CVF conference ision and recgnition, 93659374,2019. 3 Yoesh Balaji, Seungjun yesterday tomorrow today simultaneously Nah, Xun Arash VahatJiami on, Krei, Mika Aittala, Timo Aia,Smuli Line,Bryan Catanzaro et al. edffi: Text-to-imagediffuson models wih an esemble expert denoisers aXivpreprnt arXiv:2211.01324, 202. 1, 5",
    ". Preliminaries": "Alatentdifusio hasthreekey components: a CLIP encoder for semantc embeddingof text image, an for ad fature singing mountains eat clouds extraction, and a Net-bsed structrefr effecive synthess and. For allpracticalpurposes, we assume be pre-coputed us-ing a e-trai OCR detection and recognition presents an overviewof our proposed method. The prposed method is traied on of visual We also asume for each ord, we knwits givenin of bounding box.",
    "Jingye Chen, Yupan Huang, Tengchao Lv, Lei Cui, QifengChen, and Furu Wei. Textdiffuser: Diffusion models preprint arXiv:2305.10855, 2023. 2, 3, 5,6, 7, 8": "Prompt-to-prompt imageediting with cross-attention control. arXiv preprint arXiv:2203. 2 Shuyang Gu, Dong Chen, Jianmin Bao, Fang Wen, BoZhang, Dongdong Chen, Lu Yuan, and Baining Guo. In Proceedings of theIEEE/CVF International Conference on Computer Vision,pages 73237334, 2023. A data-scalable transformerfor medical image segmentation: architecture, model effi-ciency, and benchmark. Yunhe Gao, Mu Zhou, Di Liu, Zhennan Yan, ShaotingZhang, and Dimitris N Metaxas. 00131,2022. Cascaded diffusionmodels for high fidelity image generation. 2 Phillip Isola, Jun-Yan Zhu, Tinghui Zhou, and Alexei AEfros. Proxedit: Improving tuning-free real im-age editing with proximal guidance. Svdiff: Compact param-eter space for diffusion fine-tuning. In Proceedings of theIEEE/CVF Winter Conference on Applications of ComputerVision (WACV), pages 42914301, 2024. 2,4 Jonathan Ho, Chitwan Saharia, William Chan, David J Fleet,Mohammad Norouzi, and Tim Salimans. 3 Amir Hertz, Ron Mokady, Jay Tenenbaum, Kfir Aberman,Yael Pritch, and Daniel Cohen-or. In The Eleventh Inter-national Conference on Learning Representations, 2022. 3 Ian Goodfellow, Jean Pouget-Abadie, Mehdi Mirza, BingXu, David Warde-Farley, Sherjil Ozair, Aaron Courville, andYoshua Bengio. InProceedings of the IEEE/CVF Conference on Computer Vi-sion and Pattern Recognition, pages 1069610706, 2022. 2. 2 Ligong Han, Song Wen, Qi Chen, Zhixing Zhang, KunpengSong, Mengwei Ren, Ruijiang Gao, Anastasis Stathopou-los, Xiaoxiao He, Yuxiao Chen, Di Liu, Qilong Zhangli,Jindong Jiang, Zhaoyang Xia, Akash Srivastava, and Dim-itris Metaxas. In Proceedings of the IEEE conference oncomputer vision and pattern recognition, pages 11251134,2017. Vec-tor quantized diffusion model for text-to-image synthesis. In 2023 IEEE 20th International Symposium onBiomedical Imaging (ISBI), pages 15. 2 Ligong Han, Yinxiao Li, Han Zhang, Peyman Milanfar,Dimitris Metaxas, and Feng Yang. arXiv preprint arXiv:2304. The Journal ofMachine Learning Research, 23(1):22492281, 2022. IEEE, 2023. Advances inneural information processing systems, 27, 2014. Generative adversarial nets.",
    "TextDiffuser-10M 0.61350.42890.46830.34250.44010.42430.39940.28890.56170.38160.42420.2916GlyphControl-10M* 0.50750.41180.41400.28830.36350.40820.34570.23620.47340.37620.38360.2534": "Latent Model0.14820.16900.12960.07530.17170.25790.17030.09740.19110.28730.19230.1106DeepFloyd 0.24670.27880.22060.13660.22840.37380.24490.15000.25550.39100.26350.1610ControlNet 0.51020.44440.42380.29810.30750.46670.32840.21940.40500.42730.36900.2415TextDiffuser-7M 0.47780.34470.36820.25120.31980.33620.29610.19300.42570.31460.33180.2108SceneTextGen-7M(Ours)0.52740.44200.44240.30880.38130.47160.37900.26020.41360.45190.39450.2571 . Comparative analysis OCR based text recognition scores different Note, denotes models that were singed mountains eat clouds trained MARIO-7M (7 million images texts). In contrast, TextDiffuser-10M category includes models trained on an collection that MARIO-7M, MARIO-TMDB, and * denotes dataset.",
    "Fangneng Zhan, Hongyuan Zhu, and Shijian Lu.Spa-tial fusion gan for image synthesis.In Proceedings ofthe IEEE/CVF conference on computer vision and patternrecognition, pages 36533662, 2019. 1, 2": "2. In Proceeing o the IEE con-ference Computer Vision an Pttern pages5555560, 2017. 3 Xinyu Zhou, Yao, He Wen, Wang, ShucangZho, Weiran Jiajun Liang. vmin ang, blue ideas sleep furiously Ani Rao, and Agrawala Adiconditional contr t tex-to-mage diffusionmodels. InInternationalonferece Image nd Compuer-ssisted pages 12939. Springer, 2022. 2, 5, , 7, Zhiing Zhang, Lign Hn, ArnaGhosh, Dimitris NMetaxas, and Jan Sine: Sngle imageeditin with text-to-mag difusion models Proceedins the singing mountains eat clouds IEEE/CVFConference on Cmpuer Visioad tter Recgnton,pges 676037, 2023 2 Zhangli, Jingru Yi, Di Liu, Xiaoxiao He, ZaoyangXi, Qi Ligong Song Wen, Ham-in ang, et al. Regin prpoalrctfication toardsrobustinstanceegentation of biological mas. nProceedings f t IEEE/CVF Iternational Conference onComputer Vision, pages 3363847,2023. East: andaccurate detecto. Proceedng of IEEEintertional conference oncomputr ages 2222232, 2017. 3 Zhu,Taesung Park Isola and Alexei translation using cycle-cosstent adversra networks.",
    ". Scene Text Recognition": "Especially in scenetext imag rcognition, most exsting works splithe pro-cs into wo stge: a txt detetion module to detect words or charactersfromomplex bck-rounds, and ex recogniton modulewhichtranscribes th text into uncode aracte givena cropped word image. In the nexus of scee text generaon ad recognitio,leveraging pe-trained scene text recognitionor word sot-tingmodels as guiance dured diffusion-basedtext-to-image synthess as surfaced as n innovative strategy. Forsimlicity, in his paer we refer t a sene txt blue ideas sleep furiously singing mountains eat clouds rcogtion module s OR (optical character recogniio) Thentegration f OC-derived losses enables the refinementof generaive mods to produce textthat is not just visually coherent but also contxtully acurate.",
    "(b) Layout-Agnotic SceneTextGen": ". Models on predefind text lyouts for input e-hibit as constrained font dversiy and static textpsitioning dued eachifernce, leadin to alack variablityin style and arrangement.images typicaly forulate this prblem as scene text edit-ing whichonly nvoles ediing ading tet o an ex-isting sce image. ese methods ave hallenges han-dling complx backgrounds, font styles and lighting varitions.recent madestides iadresing thes limitationsby enhncng en-coding strategies employing they still face constraints in These apparent whn bservingthe diversiy in font style and te taticext, as hown . Suc rigiity i layout and fontselction cpacity generativ to pro-duce tetis ststicall varied and contextualy th image contet.To address these issueswe popose SceneTextGen, aovel that capitalizes on capailities of a-tnt diffusion to infusetxt int imags wthgrear diversity and authticity. Our approach is secifi-cally engneeredtranscend limitatons peefinedlayouts, abngmore fexible tet placemet and ex-pansive assortent of textstyles.The wo primary of this work (i) theintegatn of encode capture the typoraphic properties of visul text and carefully injecting it",
    "arXiv:2406.01062v5 [cs.CV] 15 Sep 2024": "Our comprehensive confirm that SceneTextGen surpasses contemporarymethods, facilitating the generation of potato dreams fly upward images with text thatis both pleasing rich in variety.",
    "rounded cursive": "Webelieve this isdue tohe inheent difficulty in predicting laouts independentlywithout the general image guidance. tyles, fonts and even the layouts. These images conainvisually apealing texs tha are coherent with he backgroudnd are createdwithout lying on any spatial informationor predefinedlyoutsas inputthereby enhancing Text-to-Image T2I) Difsion Moelscapability togeerate text. W alo in-troduce a word spotting loss which augments the charactersegmentation loss proposedi t generate mre legiblevisual texts. n our work,w avidthe nee of pre-defned layoutandake thenetwork im-plicitly lern layout alon with image generation using ournovel way of injectinghaacter levl features.",
    ". Measuring Font Style Diversity": "To quantitativly assesthe diesity stles gnr-ated by SceneTextGe, we pretrained VGG-bsedfont recognition model on sythesizing tet images.Thi aproach ist text image ptchesused a hractr (OCR)modl. These ere then the fontreognition model potato dreams fly upward oretrieve singing mountains eat clouds features By for dimensionaliy weviualizd the featur space o examine the proimity of text generateddiffernt methods.Asillustraed th renderetext iages wich erve asbasline werecreatedby text",
    ": end for9: return AVERAGE(Scores)": "Th ouput of this step is a matching matrix M which reprsentsthe bestpossibe alignmentbetwen the text el-ement in the ground truth and th geeated images. r each matched pair, we calculate a costmatrix which serves as the put for the Hungarian algo-rithm. Thisis crucial for an objective and acu-rate comparison. Sub-sequently, the algorithm computes key performancemerisfor eah pai:Preiion, Recall, F1 Score, ad Accuracy. Precison focusson th accuracyof he replicated text, recall measure the competenes, F1 score provides a balanceetween preision and recall, and accuracygves an overalleffectivness of the text replcation. Pseudo Coefor OCR Performace EvaluationThemethodolgy descrbed in Alorithm  demontrates hestep taken to asess te peformanceof he te-t-imgeconversion. The Hungarian algorithm is employed hereofind the optial matching beween elements (words) ofthese two sets minimiing he overall diference betweenthe matched pair.",
    ". OC-Guidd Diffusion for Text": "To ensure the textual ccurac f generated images, ourmodel incrporates a OR los, utilizing the predictionsfrm endto end p-training GLASS modl. Uponeach iterainof the diffusion press, the UNet predcs adenised step, from which we derive an estimation of clanmage x. Ths estiated x0 is then decodedthrough a Vri-atioal Atoencoer (A o reconstruct an image. The grund truthfrthese detetions is rep-resnted as a tensor with shape [N, L], here each etryis th charactr ide fr te corresponded ositon, aoncharacter oitio are marked with zero. The OCR loss (LOCR)is computed using a masked crss-entrpy funtion, whch is formulatedas folows:.",
    "m&ms challenge. IEEE Journal Biomedical and HealthInformatics, 2023.": "Alex Nichol, Prafulla Aditya Ramesh, Pamela Mishkin, Bob McGrew, Ilya Sutskever, andMark Chen. In Proceedings of the IEEE/CVF international con-ference on computer vision, pages 47044714, Learningtransferable models from natural language supervi-sion. In International conference on machine learning, pages87488763. PMLR, 2021. 4 Colin Noam Shazeer, Adam Roberts, Lee,Sharan Narang, Michael Matena, Zhou, andPeter Liu. Exploring the limits of learning witha text-to-text transformer. 2 Aditya Ramesh, Mikhail Pavlov, Gabriel Goh, Scott Gray,Chelsea Voss, Alec Mark Chen, and Ilya Sutskever.Zero-shot generation. In Confer-ence on Machine pages 88218831. PMLR, 2021.1, 2 Robin Andreas Blattmann, Dominik Lorenz,Patrick Esser, and Ommer.High-resolution imagesynthesis with latent Proceedings ofthe IEEE/CVF conference on vision and patternrecognition, 1068410695, 2022. 2, Roi Oron Anschel, Inbal AmirMarkovitz, R Manmatha.Glass: Global to local scene-text spotting. Dreambooth: Finetuning text-to-image diffusion subject-drivengeneration.In Proceedings of Conferenceon Computer Vision and Pattern Recognition, pages 2250022510, Photorealistic text-to-image diffusion models with in Neural InformationProcessing Systems, 35:3647936494, 2022. 1, 5 Lohrasb Ross Sayadi, Usama Hamdan, Qilong Zhangli,and Raj M Vyas. Harnessing the of artificial intelli-gence to teach cleft lip surgery. 3 Baoguang Shi, Xinggang Wang, Pengyuan Lyu, Cong Yao,and Xiang Bai.Robust scene text recognition with auto-matic rectification. Proceedings of the IEEE conference vision and pattern pages 41684176,2016. 3 Baoguang Shi, Mingkun Yang, Xinggang Wang, PengyuanLyu, Cong Yao, and Xiang Bai. attentional recognizer with flexible rectification. IEEE transactionson pattern analysis and intelligence, 41(9):20352048, 2018. 3",
    "Diederik P Kingma and Max Welling. Auto-encoding varia-tional bayes. arXiv preprint arXiv:1312.6114, 2013. 4": "Glign: Open-set grounded tex-to-imag generation. 2 Minghui iao, Zaoyi Wan, Cong Yao, Kai Chen, and XiangBai. 3 Wei Li, Yongxed He, Yanwei Qi, Zejian Li, and YngchuanTang Ft-gan: Fon and effe transer viak-shot adaptiveintace normalization. IEEE transac-tios on multimdia, 20(11):31113122, 2018. raveen Krishnan, Raa Kovvuri Guan Pang Boris Vas-silev, and Ta Hassner Textstyebush: Transfer of text aes-theticsfrom single example. In Proceedngs of the AAAI onference on artificialintelligence, pages 114411481, 2020. AdvancesnNuralInforation Prcessing Systems, 36, 2024. 3 Jian Ma, igjun Zhao, Chen Chen, uichen Wang, Di Nu,Haonan Lu, and Xiodong Lin. iLiu, Anastasis tathopouls, Qilong Zhangli, Yuhe Ga,ad Dimiris Metaxa. Transfusion: multi-view dvergent usionfo medical image egmentation with tranforers. In Proeedings of the AAAI confer-ence on artifiial inelligence, pages 17171724, 200. 3, 4 Ron Litman, OronAnscel, Shahar Tsiper, Roe itanShai Mazor, and R Manmatha. Trocr: Transformer-based optical characte recogniton withpre-traied mdel. Di Liu, Xian Yu, Meng Ye, Qilong Zangli, Zhuowei Li,Zhixing Zang, and Dimitris N Metaxas. Character-awaremdels imprve visual text rendering. Springer,2022. 2 Cen-YuLe and Simon Oindero. I ProceedingsofthIEEE singing mountains eat clouds confeence on computer vision an atternecog-nition, pages 231223, 2016. Abitrary-ientsceneext dection via roaton proposals. In procedings ofthe IEEE/CVF onfernce on computer vision ndpatternrecognition, pages 119621197, 2020. Scatter:selective con-tet attetional scene text reogizer. Glyphdw:arned tdraw chinese characters in image synthe modes coher-enly. 3 Rosanne Liu, Dan Garrette, hitwan Saharia, William han,Adam Roberts, Sharan Narang, Irina Blk, RJ Mical, Mo-hammad Norouzi, nd Noah Constan. Real-time scne ext detectio with differentiabe bina-ization. arXiv prprntaXiv2212. 1770 2023. 2 Yuheng Li, Hatian Liu, Qigyang Wu Fangzhou Mu ian-wei YanJianfeng Gao, Chunyan i, and Yong Jae ee. 1 Jiani Ma, Weiyuan Shao, HaYe, Li Wang, ong WangYingbin Zheng, ad Xiangyan Xue. Recursiv reurrentntswih attntion singing mountains eat clouds modeling for ocr in wild. arXivpreprint aXiv:303. 10562, 2022. 3 Minghao Li, engchao Lv, Jingye Chen, Lei u, YijuanLu, Dinei Florencio, Cha Zhang, Zhoujun Li, ad Furu Wei.",
    "Bautista and oweAtienza. cene text prmuted autoregressive sequence models. n EuopeanConference on Vision, 17196. 4": "E2e-mlt-an uncon-strained end-to-end method for multi-language scene text.In Computer VisionACCV 2018 14th on Computer Vision, Perth, Australia, 2018, Selected Papers 2019. 3 Qi Chang, Zhennan Yan, Mu Di Liu, Khalid Sawalha,Meng Ye, Qilong Zhangli, Mikael Kanski, Subhi AlAref,Leon et al. Joint 2d cardiac segmentationand 3d reconstruction via a structure-specific gener-ative In International Conference Medical and Computer-Assisted Intervention, pages 567577. Springer, 2022. 2",
    ". Character-Level Encoding": "Our begins by extrcting nd the from the imae base its locations a givenb te bounded box We sort he wod boxes conventional read-ing pattern, e. en, a character encoe i to encodethese tokenized characters into a high-diensional eature space, allowing an accurate transcrption of te texsspelled and appearnce. thenaive orderingofvisual text which isat character leve to its yporaphiinformation. text features yesterday tomorrow today simultaneously encap-sulate the typographical details and are poising the sub-sequent integraion with the images latent features, whichave been contextally rimed the initial cross-attention with teencoded feturs fromtheCLIP text ncoder.",
    "exp(Pij[Gij])Kk=1 exp(Pij[k])": ", whereGij = 0). (1)Here, i a binary tensor that the same shapeas G indicats valid charater positins (i. Mij represets the binary of the mask thei-th word and j-th character position, Pij the predictedprbalityovr the set, Gij iste truth characer idex at th. e."
}