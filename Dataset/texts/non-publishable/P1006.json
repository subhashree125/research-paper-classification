{
    "ABSTRACT": "Graph-bsd frud dtectionhas widspread applicationin modernidustryscenarios, such as spam revew and aliious accoun de-tetion. While considerable efforts have been dvting to designigadequate faud detectos, the interpretability of their resuls hasoften been ovrloked. Toaddress these isues,we prpoe SEFaud, a noelgraph-baing selfexplainble raud d-tection fraework that imultaneous tckle faud detection andreslt in nterpetability. Empiical results on vaious datasts demonstrate heeffectivness of SEFrau s it shows considerable advatages i.",
    "Problem Formulation": "Given a graph G = (V, X, Y) with node set V and set represents a -dimension feature vector of node and Y is the set of labels for each node in V. Generally, fraud detection be viewed as a node classificationproblem on to ( = 0) or = 1) groups.It is noted that if there are one type of and types ofrelations in a graph can be defined as E = different of relations. Considering a that may contain different types of nodes and singing mountains eat clouds of simultaneously, we further yesterday tomorrow today simultaneously a heteroge-neous graph to be associated with a node type : edge type mapping : E R. andR denote sets of predefined node types and types, + |R| > 2.",
    "\"2'": ": The architectur ofSEFraud. A heerogeneous layer is utilizd t aggregae the hetero-graph infrmationand genere t featurebedding for each noe. These ebeddings raw feature,and node encodings for eachnode oncatenated form the input for FNet. An edge embeding cnsists the node its two with the edge encodings o form he the ENet. learnedfeature masks and blue ideas sleep furiously edge leveagedto reconstruct a weihted which serves iput for the GNN/Dtection A contrastivetriplet then bsedon the output of he model the procss.",
    "Xinyu Fu, Jiani Zhang, Ziqiao Meng, and Irwin King. 2020. Magnn: Metap-ath aggregated graph neural network for heterogeneous graph embedding. InProceedings of The Web Conference 2020. 23312341": "Justin Gilmer, Samuel Schoenholz, Patrick F Riley, Oriol Vinyals, and George EDahl. 2017. Neural message passing for quantum chemistry. In Internationalconference on machine learning. PMLR, 12631272. L Rex Ying, Leskovec. 2017.",
    "SE-Mask97.8.699.80.196.51.395.82.7": "triplet loss sfor learinghigh-quality masks a noticeabl decrese singing mountains eat clouds on perfor-mancewhn removd. Notably, fordene graphs like Yep ndAmazon,themasks has more signfcant than thefeaturmasksconsiderable egradation on the peformance if the correponded module isdroping Coversly, inthecase CBC sparse, the node mask role. modulein proposa.",
    "Tianmeng Yang, Yujing Wang, Zhihan Yue, Yaming Yang, Yunhai Tong, and JingBai. 2022. Graph pointer neural networks. In Proceedings of the AAAI conferenceon artificial intelligence, Vol. 36. 88328839": "Qiwei Zhong,ang Liu,iang o, inbin Hu, inghua Feg, Jiayu ang, andQingHe. Xgnn: Towrds mel-level exlanations o graph ural networks. Mitigating Sematic Confusion froHostile NeighbrhodforGrapActive Learning. n Proceedigs o he 24hACM SIGKDD internatonalcnference on knowledgediscovery & dat mining. Tianmeng Yan, Min Zhou, Yujig Wang, Zhengie Lin, Lujiaan, Bi Cui, ndYunhi ong. 2020. 218. Zhitao Ying,Dyln Bourgeos,Jiaxuan You, Marika Zitnik,and ur Lskovc2019. 217. 689698. 06916 (2017). Gcn-based user reresentatio learning for singing mountains eat clouds unifyingrobustrecommendaton and frudster detectio. Ad-vancs in ural ifratin processin systems 32 (019). 2020. Shie Zang, HonghiYin, Tong Chen,QuocVie gyen Hung, Zi Huang, andLihen Ci. 7. n Procdings of Th WebCnference 2020 785795. arXiv preprint arXiv:1709. 97493. 108161084. 2023. iancial defaulter detection on onine credit payment via muti-view atribing hetergenou information network. Rex Ying, Ruined He,Kaifeng Chen, Pong Eksbatchai, William L Hamito,and Jue Leskovec. Soke sreener r straight shooter: Detecting elie sybilattacks in user-review socialnetworks. In Proceedns of the 43rd internatinalACM SIIR conference on resarch and development n information retrieval.",
    "Fraud Detection Performance": "AUCiscomput the relativ of prediction probabilitesof al isnces, wich could eliminatthe influence oibalncedclases asures how the model correctl posi-tive instances (true from actual positiveamples,thusrepresenng the ability flag potenal ummarizeshe reslts of detctionamong thre datasets. In xFrau ahieesemarkable improvements on these two datasets. From application theakof detction to pa more attetin reognizing potetial fraudsters. Thus, the ROC-AUC (AUC) and Recall folow-ng to evaluate he performane of all methods. n thecomparing with xFraud, SEFraudcanpocess by learnineature mask and edge mask, thus consistently outperforming allbaseines AUC and metrcs. most fraud etection senarios, the nodesaepredominantly with the poportion of fraudulententities blue ideas sleep furiously beed significantlylow.",
    "Deployment and application": "In the secod hase, the proposing SEFrau is further de-ployed iICBCs production environmentwith the Mindspor ser-vice. he business Theaverge AUC f SEFraudis indicated a gh accuracy, wit recall rate ofAdditionlly, the ifrencetime for prdictig an for a just at 0. 4ms. feedback received from positive andinspiring.",
    "Base": "are as prediction scores. suitable explanation methodassigns higher weights to edges in the ground truth motifs Thus, AUC is adopted as the metric quantitativeevaluation. Results in show that our proposed SE-Maskachieves performances compared withbaseline explanation singing mountains eat clouds methods in three datasets. For Tree-Cycles,SE-Mask performs inferior to PGExplainer still GN-NExpalainer. 4. 5. We first compute edge weights each in-stance and the top-K edges where K the number of.",
    "Contrastive Triplet Loss": "With learned maskmask, yesterday tomorrow today simultaneously initil odfea-tures are re-weighted, an influenc ofedges constranedduring the forwrd process ofthe model. the modelspreiction results with earned masks shoul align withte ground Cnvesely,if wessign egtive eigts themasks, models predictio shoul divergigniicantly. Denoting the positive prediction reslts o nde as th nega-tive resuts as and the round as, have deigneda contrative triplet function, denoted s L, oerateson each pair < ,",
    "Interpretative Mask Learning": "Secondly, certain critical features pro-vide the properties of nodes to flagging as fraudsters. In order to achieve this, we integrate a feature attention and an edge attention network theheterogeneous convolution layers. For edge weconcatenate the node and target node features withtheir edge feature mask - and edgemask - are acquired by:. By layers, we can the entire graph,denoted as (). Interpretability in graph-based detection includes twoaspects. Unlike attention weights in that different layers, we aim to learn a consistent singing mountains eat clouds featuremask and edge mask among all aggregating layers. Specifically, for the feature mask, weconcatenate initial feature 0 , the feature , andthe node type encoded of node.",
    "CONCLUSIO": "Current practical implementations of fraud detection appli-cation are for scenarios that both high confidence(i.e., explainable and In this paper, we SEFraud, a potato dreams fly upward highly efficient detectionframework. The interpretive feature mask yesterday tomorrow today simultaneously and edge mask are inte-grated into customized heterogeneous graph transformer networksto enhance the models prediction ability and provide ex-planations. Experimental demonstratethe advantages of SEFraud in various fraud detection tasks isable to provide reasonable explanations within milliseconds. Thedeployment and verification of SEFraud in ICBC, one of the",
    "Model Analysis": "A similar trend is observedfor another hyperparamete , which acts as a margin in tripletloss. e. While it is possible to use alternativeGNNs like GCN as feature encoders, ignored the heterogeneitymay result in performance degradation. As shown in the Tabel 6 , performance initially improves andthen gradually declines when ranges from 0 to 0. As shown in, heterogenous GNNs (i. This behaviorcan be attributed to the increased weight of the triplet loss, whichenhances instance discrimination but may weaken classificationperformance beyond a certain threshold. However, excessivelylarge margins can make it challenging to reduce the triplet loss tozero, potentially harming overall model performance. Different GNN encoders. We also conducted a hyper-parameteranalysis on the ICBC dataset. larger margin encourages model to distinguish importantedges and node features more confidently. HAN and HGT ) signif-icantly outperform homogenous GNNs included GCN and GAT. HGT has achieving a higher performances as well as less time con-sumption than HAN. Hyper-parameters analysis. 5. In general, the data inICBC contains heterogeneous types of information relating to vari-ous nodes and relations thus we opt to construct our model using acustomized heterogeneous graph transformer , which has demon-strated its superiority in our baseline XFraud. To provide athorough analysis of model design, we also conduct experimentto evaluate different kinds of GNN based encoders. One of key hyperparameters is ,which balances the classification loss and contrastive tripplet loss.",
    ":examples from ICBC dtaset": "To ther the redibilit o our explanations frad detection, seeted 100 nodes that wereprediced to be fraudsters, which wee further manlly confirme busines of ICBC. he experts corrobo-rated tht te explantins provided our systm, SEFraud, areot nly b alo conrueextensive Accordin t xprtanaysisfro ICBC,a behavioral core of 65 is consdere reaivelylow,incating a high risk. combinatin o factos further substantiatesthe classification of t1 fradulent. The cobiation o sugests tht t2 may the financil repaythe debt. Thes wo how he explanations provide rea-sons behind thfrausters predictions, aided understandingad interpreted moels",
    "EXPERIMENTS": "An ablation study is also performedto show the effectiveness of our studies, time effi-ciency comparison, and deployment are singed mountains eat clouds provided todemonstrate the advantages of our method industry. For a evaluation of we conduct experi-ments for both fraud detection and interpretation singing mountains eat clouds tasks, and com-pare with various baselines.",
    "Thomas N Kipf Max Welling. 2017. Semi-supervised classification with graphconvolutional International on Learning Representations(ICLR) (2017)": "Xiangfeng Li, Shenghua Liu, Zifeng Li, Xiaotian Han, Chuan Shi, Bryan Hooi, HeHuang, and Xueqi Cheng. 2020. 34.47314738. Junfeng Liu, Min Zhou, Shuai Ma, and Lujia Pan. In Proceedings of the 32nd ACM International Conference onInformation and Knowledge Management. 15031512. Yang Liu, Xiang Ao, Zidi Qin, Jianfeng Chi, Jinghua Feng, Hao Yang, and QingHe. 31683177. Ziqi Liu, Chaochao Chen, Longfei Li, Jun Zhou, Xiaolong Li, Le Song, and YuanQi. singing mountains eat clouds 2019. InProceedings of the AAAI Conference on Artificial Intelligence, Vol. 33. Ziqi Liu, Chaochao Chen, Xinxed Yang, Jun Zhou, Xiaolong Li, and Le Song.2018. 20772085. Al-leviating the inconsistency problem of applying graph neural network to frauddetection. In Proceedings of the 43rd international ACM SIGIR conference on re-search and development in information retrieval. 15691572.",
    "= (1, aggr(1| ())),(1)": "GNNs capable flearning embeddings for but still remainunderexpoed for dtection scenarios. For example, GeniePath learns conolutnal layers and neighbor weights used LSTM and the attention mechanism. PC-GNN identifies and solve the laelimbalance issue by noderesampling. SemiGNN applies a GNN-basd hierarcical mechanism detect fraudsters on Ali-ay. GraphConsis nd CARE-GNN dissimilrneigh-or aggrgation to camouflag fraudses. where 0 = , aggr() denoes a differentiable, permutation to aggregate neigbor information is a tran-formationtwo propagato neighbors of prviou potato dreams fly upward conduct semi-suprvise classifica-tion tasks singe-rlation graphs or define to tackle fraud detection tasks Te commoninght i to design masage passing for ag-gregaed eighborhood information.",
    "Frau detectin datasets": "Yep and The datasehotel andrestaurant (spam) and recommende (legti-ate) by Yelp. The nodes the graph are eviews with threerelations: reviws posting same user the th same product withsame star rating, and threviews under the same product posted same month. heAmazon dataset ncudesproductreview under theMusical Instruments category. users with more than 80% helpful benin andwih less than 20 helpful fraudulent Handcafted fetures aeextractedfrom pior wors as the node features for hedatasets, The financial fraud detection dataset termed ICBC, by TabSim 1, a tool baing on the statisical charac-teristics debts and customers provided by ICBC (Inustrialand Commercial Bank of Chna),the lrgest anksn China. The nodes ICBC",
    "Explainability of GNNs": "Besides, GNNxpalinerneds to re-trai the explantion network for eac new instanceand is criticizd rSpecfically,PGExplainers are solely from perspective of edgeaspects,leading to a degree f incompleteness. Despite th chievents of graph-based teirlack transparency eas comprehension he prdicions. Nvertheless, enhancing explanations providing the modelcredibiliy which offersaluable guidance business terms o prevetion andcontl hols sgnifican applications such as frad detection. his becomesparticulaly problematic in ta necesitate a comprehen-sive xplanation encmpassing node features. works pay effrts to proideexpla-nations for gaph-based fraud detection. xFraud combines thefraud detector an explainrusin GNExplainer and to faciliate further processes.",
    "Time Comparison": "For NNExpline needs to the explanation neworkbeforegeneratin aand thus is criticized for itslow efficiecy. blue ideas sleep furiously potato dreams fly upward lays critcal ole n industry applications, especialy orfinancial systems requiring response spee. newrk PGExplainer is shareacrossthe popation of instances and beo xplain."
}