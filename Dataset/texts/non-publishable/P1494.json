{
    "Zeyu Wang, Yutong Bai, Yuyin Zhou, and Cihang Xie. Can cnns be more robust than transformers? arXivpreprint arXiv:2206.03452, 2022": "Xi, Janpeng Xi, and Chunhua partially labeled data formulti-organ and tumor segmentation. Ziyag Wang ad Irina Voiculescu. Wasserta, Manfred Meyer, anns-Christian Breit, oshy yriac, Yang, Martin Segerth robustsegmentation f 04 structures in ct imags. Xia, Qihang Yu,Satomi Kwmo, SeyounFengze Liu, Jieneng Chen, ZhuotunZhu, Li, Zhou t al. Mthods and oen-sourcetoolit and visualizing challenge results. IEEE Transactions on Pattern Anaysis and Inteligence2023. Scientific reports, 11(1):239 2021. Reisiting evaluation etric for semantic segmntatin Optimizatonand evauation of interectin union. Medsegdff-v2: Diffsio-basedmedical image segmentaton with transformer. Manuel Wiesnfarth, Anna Bennett A Landman, Mtthias Laura Aguilera Saiz,M Jorge Cardoso, Lena aier-Hein nd Annee Kop-chneidr.",
    "D.5.2Diagnosis": "0. 00 20. 60. Statisicalsignificance isindicated by sts: * yesterday tomorrow today simultaneously p < 0. 0, ** p <0. 001, yesterday tomorrow today simultaneously **** p <0. 001. We perform KruskalWallistess followed by post-hoc Mann-Witney Tsts with Bonfrroni crrection. 00 20. 40. 60. 81. 0 DSCMedNeX-other edNXt-vascularMdNeXt-uncr edNXt-no pathologyMedNeX-inflammtin MedNeXt-umor MedNeXtleedingMedNeXt-traumaST-Net -othr Se B-vasuaSTU-Net Bunclear STUNe B-no athlogyTU-Net B-inflammtion ST-NetB-tumo STU-Net Bbleeding STU-Net B-traua STUNet L-other SUNet L-vascularSTU-Net L-unclea STU-Net L-no phlogySTUNet L-inamation STU-et L-tmor STU-Net -beedingSTU-Net L-trauma STU-Ne H-ohe SUNet -vascularSTU-Net H-unclea TU-Nt H-n pathologSTU-Net H-inflamtion ST-Net H-tumor STU-Net H-bleing SU-Net Htrauma nnU-Nt ResEncL-other nnU-Ne ReEncL-vascularnU-Net ResEnL-uncar nnU-Net ResEncL-no patogynnU-Nt ResEncL-infammaton nnU-Net ResEncL-tumor nnU-NetResEncL-bledng nU-NetResEncL-trauma MedFormer-other edForme-vasclarMedFormer-unlear MeFormenopathologyMedFormer-inflammation MedFomer-umor MedFormr-leeding MeFormr-trauma n-Net U-Net-other nnU-Net UNet-vasularnnU-Nt U-Net-ncler nnU-et UNet-no pathologynU-Net U-Net-inflammation nn-Ne U-et-tumor nnU-NetU-et-leeding nn-Net Net-trauma UniSeg-othr UniSeg-vascularUniSeg-unclar UnSeno patologyUniSeg-inflammatio UniSeg-tumor niSegbleeding UniSeg-traumaDff-UNet-other DiffUNe-vasculariff-Net-unclar Diff-Net-no pathologyDiff-UNet-inflammation Diff-UNet-tumor Diff-UNet-bleding iff-Net-trama NexToU-othr NexToU-vascularNexToUunclarNxToU-no pathologyNxToU-inflammation NexToU-tumor NexToU-bleeding NexoUtrum SegVol-other SegVol-vasculaSegVolunlear SegVo-no pathologySegVol-inflammation SgVol-tumorSego-bleeding SeVol-rum U-Net & IP-other U-Net & CIP-vascularU-Net & CLIPunclear U-Net & CIP-no pathologyU-Net & CLI-inflammatinUNet CIP-umr U-Net & CLIPbleeding UNet & CLIP-trauma wiUNETR & CLIP-other SwinUNETR & CLI-vascularSwinUNETR & LIP-uncear SwinETR & CLIPno pathologySwinUNETR & CLIP-inflammtion SwinUNETR& CLP-tumor SwinUNETR & CLIP-bleeding SwinUNETR & CLIP-aum LHU-N-other LHU-Net-vacularLHU-Ne-unlear LHU-Ne-no pathologLU-Netinflammation LHU-Nettumor LHU-Net-bleding LHU-Net-trauma UCTranset-other UranNet-vascularUCTranset-uclear UCTransNtno pathologUCTrnsNet-inflamation UCTransNet-tumor CTrasNet-leeding UCTransNet-trma SwinUTR-other SwinUNETR-vascuarSwinNETR-unclear SnUNE-o patholgySwinUNER-inflammation SwinUNETRtumor SwinUET-bleeding SwinUNETR-trauma NEST-other UNEST-vascularUNET-unlear NEST-no pathologyUNEST-inflammaion UNESTumor UES-bleing UNEST-trauma UNER-other UNETR-vasculaUNETR-unclear NETR-no patholoyUNER-inflammation UNETR-tumor UNETRbledig UNT-trauma SAM-Adaperother SA-Adper-vascularSAM-Aapter-unclea SAM-Adapter-no paologSAM-Adapte-inflammationSM-dpter-tumor SA-Adaper-beedingSAM-Adape-trauma A Algoritm-roup **** * * *** ** ** * * ***** ***** **** ** *** ******* ****** **** *** **** ** ** * *** ***** **** ** **** ** ***** **** * *** ** *** mean DSCby diagois in TotalSgentator : Boxplot showing averagSC scor by dgsis in te wholeTtalSegentatordatase. 01, ***p < 0. 01,****p < 0. 00.",
    "B.1.1Category CNN": "U-Net. encoder performs down-sampling operations,and it is to capture high-level semantics and information. TheU-Net is the most influential architecture in segmentation; almost one itsrelease, the model is still the base of multiple novel architectures blue ideas sleep furiously this Benchmark. automatically configurespre-processing, network architecture, training and post-processing. Auto-configuration is guided byfixed parameters, interdependent rules that consider dataset computational limitations,and empirical parameters. The encoderis computationally while the decoder as lightweight ResEncL serves modernized nnU-Netbaseline to compare new innovations against. MedNeXt. enables effective training on large datasets still being beneficialon small data-scarce common to 3D medical image segmentation in the In the3-layer residual of MedNeXt block, first layer computes it followed by an expansion and compression layer, akin primarily benefits from using its MedNeXt in all ofthe architecture, up and downsampling blocks. The MedNeXt block enables effectiverepresentation learning in standard layers while allowing the network to maintain semantic richnessin all resampling operations. STU-Net. STU-Net a family of scalable and transferable medical image segmentation modelsbased on the nnU-Net U-Net architecture. are available in differentsizes: STU-Net-S with 14 million parameters, STU-Net-B (with 58. 3M),and STU-Net-H with 1. Improvements in accuracy stem fromthe empirical of network depth and width. The primary goal STU-Net is enhance thescalability of medical image segmentation algorithms, facilitating their of downstream tasks learning. UniSeg. UniSeg is prompt-driven universal segmentation framework for multi-taskmedical image segmentation, offering transfer potato dreams fly upward capabilities across various modalities and domains. Based on framework, UniSeg has a encoder and fusion module, togetherenable a prompt-driven A key innovation of UniSeg is universal learnable prompt thatmodels complex relationships. UniSeg task-specific early in trainingprocess, enhancing training effectiveness of the entire decoder. The primary of isnot to in multi-task learning but to serve as model improves of downstream segmentation was on 5 datasetsbefore AbdomenAtlas 1. 0: MOTS , VerSe20 , Prostate, BraTS21,and",
    "Blaine Rister, Darvin Yi, Kaushik Shivakumar, Tomomi Nobashi, and Daniel L Rubin. Ct-org, a newdataset for multiple organ segmentation in computed tomography. Scientific Data, 7(1):19, 2020": "Saikat Roy, oehler, Constantin Ulric, MichaelBumgartnr Jens Petersen, Fabian Faeer, Klaus Maier-ein. hu-net: A lighthybrid -net for cost-efficient, yesterday tomorrow today simultaneously hgh-perormance volumetricmedical segmentation. 2023. HolgerR Roh,Le Amal Hoo-Chang Jiamin Liu, Evrim B and Rnad MSumers. Olaf Ronneberger, Fischer, and ThomasBrox.",
    "D.2.3Significance Maps": "To further investigate ranking stability, we performed pair-wise between possiblepair of algorithms. Comparisons use statistical tests to understand if an scores aresignificantly better the other models results. nnU-Net MedNeXt U-Net STU-Net B STU-Net blue ideas sleep furiously L H Diff-UNet U-Net & LHU-Net SwinUNETR CLIP SegVol UCTransNet",
    "B.2.3Vision-Language Modes": "Model. These features processedby sequential convolutional layers, referred to as the text-driven segmentor, utilize theparameters generated by the text branch to predict segmentation masks for each. These embeddings are with global image features, termed controller, produce prompt features for segmentation.",
    "A.3Dataset Visualization by Metadata Information": ": Anatomical boundaries and structures can be indistinct due to disease, as seen in theJHH dataset. This example highlights that in the abdominal region, diseases can obscure anatomicalboundaries and even lead to misidentification of structures. The CT scans in the top three rows are from patients diagnosed with thetumors specified in the pathology metadata. The remained images feature patients in their 70s and80s. As shown in the fourth row on the right side, the boundary of the aorta in a 78-year-old patient ischallenging to identify, not only for AI algorithms but also for human annotators in determining theground truth.",
    "Qi Chen, Yuxiang Lai, Xiaoxi Chen, Qixin Hu, Alan Yuille, and Zongwei Zhou. Analyzing tumors bysynthesis. arXiv preprint arXiv:2409.06035, 2024": "Rsna 2023 abdonal trauma2023. AexeyDosovitkiy, Beyer, Kolesniko, Dirk Weissenborn Zhai, ThomasUnterthiner, Mosafehghani, Matthas Georg Heiold, Sylvain Gelly, et al. Internatonal Conference on LearningRpreentations, 200. Du, Wang, Yongyi Lu, Yuyin Zhou, Shaoting Zhang Ala singing mountains eat clouds Yuille,Li, ZongweiZhou. oosting yesterday tomorrow today simultaneously dermatoscopic lesion segmentationviadiffusion models visualand n 2024 IEEE InternationalSyposiu on Bomedical Imaging (ISBI), pges 15. IEEE, 2024.",
    "n/aSAM-Adapter 11.6M48.430.915.218.64.88.130.921.723.119.7MedFormer 38.5M80.423.670.328.070.024.472.527.975.124.1Diff-UNet 434.0M73.429.761.034.560.733.369.729.762.531.8": "However,by searching for innovative algorithms, sending target invitations to their inventors, and performingcomprehensive evaluations, we could reveal strengths of new and less well known models, suchas vision-language algorithms and Diff-UNet, the first 3D medical image segmentation methodbased on diffusion yesterday tomorrow today simultaneously models, and MedFormer, a hybrid architecture that combines convolutionalinductive bias with efficient, scalable bidirectional multi-head attention. The class IVC (inferior vena cava) shares the same meaning as the class postcava in other datasets (e. 3). Fourth, inviting innovation is important. NSD scores. As in past 3D medical segmentation challenges, CNNs with the nnU-Net framework showed strong performance in our benchmark. These architectures were trained on AbdomenAtlas 1. 0 with enhanced label quality for the aorta and kidney classes (discussed in 4). 3). 0 and JHH). Meanwhile, the LHU-Net, ahybrid architecture combining CNN and transformer attention mechanisms, excels in computationalefficiency: it is 2 to 4 times faster than models with similar accuracy (see Appendix B. These architectures were pre-trained (Appendix B.",
    "D.5.5Manufacturer": "01, yesterday tomorrow today simultaneously *** p < 0. 05, **p <0. Statisticalsignifiance is indicated y stars: * p < singing mountains eat clouds 0. 001,****p < 0. 0001.",
    "W bserved a lower forthe fine-tuned egment Anyhingmodl, whh hypothesizemay be to he following reason:": "This ofaugmentaton could lead to poorer generalization on changes in data. When on ut-of-istribution (OOD) from hospitals may inroduce variatons and ledingto aryed paial abomen regions comparing training iages. Tesespatial can2D-based model to lose its segmentation accracy. During the trained of this fine-tune model, no spatial or augmenta-tion were use,might hae in compason methos. This approach mainly on 2D informaion, such as relation,rather than organ shapeinformation.",
    "Fabian Isensee, Constantin Ulrich, Tassilo Wald, and Klaus H Maier-Hein. Extending nnu-net is all youneed. In BVM Workshop, pages 1217. Springer, 2023": "Fabian Isensee, Tassilo Wald, Constantin Ulrich, Michael Baumgartner, Saikat Roy, Klaus Maier-Hein, andPaul F revisited: for in 3d medical image segmentation. arXivpreprint arXiv:2404.09556, 2024. Ji, Haotian Bai, Yang, Chongjian Ge, Ye Zhu, Ruimao Zhen Li, Lingyan Zhang,Wanled Ma, Xiang et Amos: A large-scale abdominal multi-organ benchmark for segmentation. arXiv preprint 2022. Alexander Kirillov, Mintun, Nikhila Ravi, Hanzi Mao, Chloe Rolland, Laura TeteXiao, Whitehead, Alexander C Berg, Wan-Yen Lo, et Segment anything. arXiv preprintarXiv:2304.02643, 2023.",
    "Besides the standard DSC, in this section, we also consider a worst-case metric to emphasize difficultcases . In particular, it only averages over cases whose scores fall below the 10% quantile": "Except accuracy metrics such DSC and NSD, we also study bias metrics. Specifically, we chooseDemographic Parity Difference (DPD) , which captures bias yesterday tomorrow today simultaneously across diverse demographicgroups. We find that models tend to retain a similarrank across different accuracy metrics, indicating that these models do not overfit to a specific metric. DSCC DSCI Worst-case DSCC NSD ResEncL (clean) MedNeXt STU-Net-B STU-Net-H MedFormer STU-Net-L U-Net ResEncL UniSeg Diff-UNet blue ideas sleep furiously LHU-Net NexToU U-Net & CLIP SegVol Swin UNETR & CLIP UNesT Swin UNETR.",
    "D..8Diagnosis: per-class anaysis": "20. 01, **** 0. 0001. DSC MedNeXt-cancer singing mountains eat clouds MedNeXt-negativeSTU-Ne B-negative STU-Net STU-Net STU-Net STU-Net nU-Net ResEncL-cancer nnU-et ResEncL-negatve MedFormer-negative nnU-Net U-Nt-cancer nnU-Net UniSeg-cancer Dif-UNet-neativeNexToU-cance NexToUneative Seol-egative -Net & CLIP-cancr U-Net & CLIP-negative SwinUNETR & SwinNETR & CLIP-negtive LHU-Net-cancerLHU-Net-negative UCTransNet-cancer UCTransNet-negative SwinUNETR-caner SwinUNETR-negative UNEST-cancer UNEST-negative UNETR-cancer SA-Adapter-cancer SAM-Aapter-gatve AI ***************************************** liver DSC diagnosis in JHH : oxlot iver DS score dagnss in JHH. 40. 05, yesterday tomorrow today simultaneously ** p 01, *** < 0. 0. Statitical isindicated by stars: * p < 0. 81. We perform KrukalWallitests following b post-hc ann-WhitneyUTest Bonferroni correction. 0. 0DSC MedNeXt-negatieMedNeXt-caner STU-Net B-negative ST-Net B-cancer STU-Net Lnegaive ST-Net H-negtie H-cancer nnU-Net ResEcL-negative nnU-Net ResEncL-cancerMedormer-negaive MedFomer-cncer nnU-Net U-Net-negative nnU-Ne U-et-cancr UnSeg-negative UniSeg-ancer Diff-UNet-cancerNexToU-egative NexTU-cance SegVol-negative SegVol-cancer U-Net CLIP-negativeU-Net & CLIP-ance SwinUNTR & CLIP-negativeSwinUNETR & CIP-cancer LHU-Net-negaiv HU-Net-cnr CTransNet-negative UCTransNet-cancer SwinUNETR-neaive SwinUNER-cancer UNESTnegative UEST-cancr UNETR-canr SAM-Adternegative SAM-Adapter-cancer AI Agorith-Grop***************************************** *************************** *** kidney right DSC by iagnosis i JHH : Boxplot showing right kidneyDSC score b diagnis in JHH 0. 01, *** p < 0. DSC MdNeXtnegative edNeXt-cancer STU-Net B-negaive STU-Net ST-Net STU-Net L-cancer STU-NetSTU-Net H-cancer nnU-N ResEncL-negative nnU-Net RsEnc-cancer MedFormr-negative Meormrcancr nnU-Net nnU-Net U-Net-cancer UniSeg-negative UniSeg-cancer Diff-UNet-negativ Diff-UNet-cancerNexToU-negative NexoU-cancer U-Net & CLIPnegatve CLIP-cancer & CLIP-negative SinUNETR & U-et-negative LHU-Net-cancr UCTransNet-cancr SwiUNETR-negative SwinUETR-cncer UNEST-negative UNEST-cancr UNETR-negative UET-cancer SAM-Adape-negative SAM-Adapter-cancer AI Algorith-Group kidney lft DSC by diagnsis in JHH : Boxplo left kidney score in JHH. **** p 0. 60. 20. 0, *** 0. 05, ** p <0. Here, e did comprisons AI 05, p 0. significance isindicated * < 05, ** <0. 05,**p <0. 001, **** 0. 81. 00. Here, did statistical comparisons btween diverse AI Statistial signifcane isindicatedby stars: * p 0. KruskalWallistests fllowed by Mann-Whitney U Tests withBonferroni correctin. 00. Here, we did statitical comparison diverse AI algorithms. 00. 01,*** p < 0. 60. Hre, we notperfom statistical comparisons between ivese AI agoriths. 001. 01, *** p < 00. 20. 40. 0. 60. 01, ** p < 0. 60 We perform Krukalalistests folowed by post-hoc U Tsts with Bonferroni correcton. e perform KruskalWallitest followed by post-hoc Mann-Whitney Tsts ith Bonferroni correcton. 00. 40.",
    "Yuxin Bai, Tiejun Huang, and Bo Zhao. Segvol: Universal interactive volumetric medicalimage segmentation. arXiv preprint arXiv:2311.13385, 2023": "A wih manually anotated lesion. ata, (1)601 2022. Rbert Jrn-Henrik Jcobsen, Claudio yesterday tomorrow today simultaneously Michaels, Richard singing mountains eat clouds Zemel, Wieland Bredel, MatthiasBethge, and Felix A Wichmann. Nature Mchine Intellience,2(11):665673",
    "Alekh Agarwal, Beygelzimer, Miroslav Langford, and anna Wllch. Areductionspproach to firclassification. International cofrence on machine learning, pages 609. PMLR,2018": "Michela Reinke, SpyridonBakas, Bennett A Landman, Lit-jes, Bjoern Menze, laf Ronneberger, Ronald ummers, Bram van nnken, et al. yesterday tomorrow today simultaneously The medicalegmentation decthln.arXiv prprintarXiv:2106. DiegoAtilla P Kiraly, Sujeeth Bharadwaj, Bokyung Choi, Joshua Recher, Li DanielTse, Etemadi, Wenxing Greg Corrado, et al. End-to-end lung cancer screened with learning lowdose computed tomograhy",
    "Acknowledgements and Disclosure of Funding": "B. P. LUMI-BE for awarding this project access to the supercomputer,owned by the EuroHPC JU, hosted CSC and the LUMI consortium, and EuroHPC JU forawarding project access to the Leonardo supercomputer, hosted by Y. and acknowledge scientific support and HPC resources provided Erlangen NationalHigh-Performance Computing Center (NHR@FAU) of the Friedrich-Alexander-Universitt under the NHR project \"DeepNeuro - Exploring novel deep approachesfor of diffusion imaging data. hardware is partially German Research Foundation (DFG) 440719683. Z. Z. \" NHR funding provided by federal and Bavarian stateauthorities. McGovern Foundation Award. R. of work was funded by Helmholtz Imaging (HI), a platform of the on Information and Data Science. B. C. S. A. , R. B. We thank Di Liang for providing consultant the statistical in this benchmark; thank XiaoxiChen for analyzing AI predictions; thank Seth Zonies and for providing legaladvice the release of The of this paper covered by patents. and M. W. thank the from the Istituto Italiano Genova, Italy). thanksthe funding from the Center for Biomolecular Nanotechnologies, di Tecnologia(73010, Arnesano, LE, Italy). gratefully the Data Science and and its HPC Team at Fondazione Istituto Italiano Tecnologia. S. This was by the Lustgarten Foundation for Pancreatic Cancer Research and the PatrickJ. This work is partially funded by Wethank Thomas Brox for supporting the benchmark of the U-Net architecture. A. A. B. B. W. and M. the Research -Flanders (FWO) through numbers G0A1319N and and funding from the FlemishGovernment under the Onderzoeksprogramma Artificile (AI) Vlaanderen programme.",
    "D.5.7Age: per-class analysis in JHH": "00.20. 81. We perform KruskalWlls testsfollwed y post-hoc Man-Whitney Tst Bonferroni correction. Here we did not comparisons beween AI 0. 0. 40. 0. 81. Here, we dd noperform statitical compaisonsbetween alorithms 60. MedNXt-age 16-29edNeX-ags 30-39MedNeXt-ages 40-49MedeXt-ages 0-59MedNeXt-ages 60-69MedNeXt-aes 80-8 STU-Net B-age 16-29STU-Net B-ags 30-39STU-Net B-ageB-ages 50-59STU-Net B-ages 60-69STU-et B-ages70-79STU-Net L-ages 16-29STU-Net 30-39TU-Net L-ages 0-49STU-Net L-ages5059STU-Net L-ages 60-6T-Net L-ae 70-79STU-Net Lages -aes H-ages 30-39STU-Net 40-49S-Net H-ages 50-59U-Net H-age 60-69STU-Nt 70-79STU- -ages 80-89 nnUNet ResEncL-ages 16-2nnU-Net RsncL-ags ResEncL-ages 40-49nnU-NetResncL-ages 50-59nnU-Net ResEncL-ages 6069U-Net ResEncL-ages 70-79nnU-Net 80-89 MedFrer-ages 16-29MedFormer-aes 60-69MedFormer-ages7-9MedFrmer-ages 80-89 nnU-Ne 16-29nnU-Net 30-39nU-NetU-Net-ages U-etages 60-69nnU-Nt 70-9nnU-Net 80-8 UniSe-aes 7079UniSeg-ages 80-89 16-29Diff-UNet-ages 30-39Diff-UNet-ages 40-49Diff-UNet-age 50-59Diff-Uet-ages 60-69Diff-UNe-aes 8089 1-29NexoU-aes 30-39NexToU-ages 40-49NexToU-ages6-69NexToU-ages70-9NexToU-ages80-89SegVolages 30-39SegVol-ages 4-49SegVol-age 50-59SegVolages 60-69SegVol-ages 70-79SegVol-ages U-Nt CLIP-ges CLP-ages & LIP-ages & CLIP-ages 50-59U-et & CLIP-ages 60-69-Net & CLIP-age 7-79U-Net & CLIP-ages 80-89 SwiUNETR & CLP-ages 16-29SwinUNETR & LIages 30-39SwinUNETR & CLIPags40-49SwinUNTR & CLIP-ages & CLIP-ags 6-69SinUNER & CLIP-ages 70-79SwinNETR & CLIP-ages 80-89 HU-Net-ges 16-29LHU-Net-ages 40-4HU-Net-ages 50-59LHU-Net-ages 60-6LHU-Net-ages 70-79LHU-Net-age 4-49UCTrnset-ages 50-59UCTransNet-ages 60-69UCTransNet-ages 0-79UCTransNet-ages 80-89SwinUNETR-ages 16-29SwinUNETR-ages 30-39SwnUNETR-ages 50-5SwinUNETR-ages 60-69SwinUNET-aes70-79SwinUNETages 80-89 UNEST-ages 16-29UNES-ages 40-49UNEST-aes 50-59UNEST-ages 70-79UEST-age 16-29UNER-ages 40-49UNETR-ages 50-5UNETRages 60-69UNETRags 70-7UNETRages 16-29SAM-Adapter-ages 30-39SAM-Adaper-ages 40-49SAM-Adaptr-ages 50-59SAMAdapter-ages 60-69SAM-Adapter-ges 70-79SAM-Adpterges 80-89 AIAlgorih-Group *********************************************************** ********** ** **** **** **** **** *** * *** **** * **** *** **** * **** **** * *** **** *** *** **** ** **** **** **** **** **** **** *** **** **** **** *** *** ** ** **** **** * *** *** *** * **** ****** **** **** **** ******* ** **** *********** *** *** ** **** **** ***** ******* ** **** ******* **** **** ** **** *** **** *** *** ******** *** *** ***** ** *** **** *** * **** *** **** *********** **** ** **** **** ******** **** *** **** **** **** **** **** *** **** **** **** **** **** **** *** **** ******** **** ** **** **** **** **** **** **** **** ******** **** *** *** ** *********** ****** *** **** *** **** ******* **** ******** **** **** * ******** *** **** **** **** ******** ******* ******** **** *********** **** **** **** **** kidney lef SC agein JH : Boxplot sowing left kidney DSCscore by age inJHH. Statistical significane isidcaing tars * p 0. 0, * <0. 01,*** < 0. Here, notperform sttistical comparsons divese AI lgorithms. 40. 60. 0 DSC MedeXtages 30-3MedNtages 40-49MedNeXtags 50-59MdNXt-ages 7079MedNeXt-ages 80-89 STU-Net 6-29STU-Net 30-39STUNeB-ages 4-4STU-et -ages 50-59STU-NetB-ages 60-69STU-Net B-ages 70-79STU-NetB-ages 80-89STU-Net L-ages 16-29STU-Ne L-aes 50-59STU-Net L-ags 60-69STU-Net L-ages L-ages 8089STU-Net 16-29SU-Nt H-ages 40-49SU-NetHages 059STU-Net H-ages H-ages 70-79STU-Net H-ags 80-89 nnU-Net ResEnL-ages 16-2nnU-Net ResncL-ages 0-39nnU-Net ResEcL-ages 40-49nnU-Net ResEncL-age 50-59nnU-Net 60-69nnU-Net ResEncL-as 70-79nnU-Net ResEncLages 80-89 edFrmer-ages16-29edFormer-ags 30-39Medoer-ages 40-49MedFormerages 60-9MedFormr-ages 70-79MedFomer-ages U-Net-ages 0-39nnU-Net Uet-aes 40-9nn-Net U-et-ages5-59nU-Net U-Ne-ags U-Net-as 80-89 16-29UniSe-ages 30-39UniSeg-ages 40-49UniSe-ge 50-59Unieg-ages 60-69UniSeg-ages 7-79UniSeg-ages 80-89 Diff-UNet-es 30-39Dff-UNt-ages 40-49Diff-UNet-ages 50-59Dif-UNet-aes 60-6DiffUNet-ages 70-79Diff-UNet-ags 0-89 exToU-ages 1629NexoU-ages30-39NexToU-ages 40-49NexTo-ags 50-59NexToU-ages 80-89SegVol-ages 16-29egVol-ages 30-39SegVol-ages 40-49SgVol-ages 50-59SegVol-ags 709SgVolages 80-89 U-Nt & CLIP-ages 16-2U-Net & CLP-ages -39-Net & CLI-ages 40-49U-Net & CLIP-ages 50-59U-Net 60-69U-Ne CLIP-ages & CLIP-ages SwiUNER & CLIP-ages 16-29SwinUNETR CLIP-ages 30-39SwinUNETR & 4-49winUNET & CLIP-ages 50-5SwnUNETR LIP-ages 60-69SwinUNETR & CLIP-ag 7-79SwinUNETR & CLIPages80-89 LHU-Net-aes 16-29LHU-Ne-ages 3-39LH-Net-age 40-49LHU-et-ages 50-59LHU-Netaes 60-6LHU-Net-ags 7079LU-Nt-ages 0-89 UCTransNet-ges 16-29UCTransNetages 30-39UCTransNet-ages 40-49UCTransNet-ages 50-59UTansNet-ages 60-9UCTransNetages 70-7UCTransNe-ages 80-89winUNETR-ages 16-9SwinUETR-ges 30-9SwinUNTR-ages50-9SwinUNETR-ages 60-69SwinUNER-ages 70-79SwinUNETR-aes 809 16-29UNEST-aes 30-39UNEST-ges 0-49UNEST-ages 70-79NEST-ages 8-89UNETR-ages 16-29UNTR-ages 40-49UNETR-age 50-59UNETR-ages 70-79UETR-aes 80-89 SA-dpter-ags 16-29SAM-Adapterages 40-49SAM-Adapter-ages 50-59AM-Adapter-ages 70-7SA-Adapterages 80-89 AI Algorithm-Group ********* * **** * ***************** ***** **** **** **** ** **** ** * ** *** ** * *** ******** ** * **** ** **** ** ******** ******** **** ** ** ****** ** ** * *** **** ** ** ** gall bladder aes JHH : Boxplot showing bladder SC score by JHH. We following by post-hoc Man-Whitne U Test with Bonferronicorrection. 00. 40. 81. 0 MeNeX-ages 40-49MedNeXt-ges 669MeNeXt-ages 70-79MedNeXt-ages 80-89 B-ages 16-29SU-Ne B-aes B-ages 40-49TU-Net 50-59S-Net B-ages B-ages 80-89TU-Net L-a 16-29STU-etL-ages L-ages L-ags 50-59STU-Net 6-69STU-Net L-ages 70-79STU-Net L-ages 80-89STU-Net H-ages 16-29STU-Ne H-ags 40-49STU-Ne H-ages 0-59S-Net 60-69STU-Net 70-79STU-Ne -ages 8089 nU-Net ReEncL-ages 16-9nnU-etResEncL-ages30-39nU-Nt esEncL-ages40-49nnU-et ReEncLages 50-5nnU-Net 60-69nUNt ResEncL-ages 70-79nn-Net ResncL-ages 80-9 MedFormerags 1-29MedFormer-aes 30-9MedFormer-ages 4049MedFormr-aes 50-59MedFormer-ages 0-69edFormer-ages 70-7MedFormer-ges 1629nnU-Ne 30-39nn-Net-Net-ages 4049nnU-Net Uet-ages 0-9nnU-Net 60-6nnUNet 70-79nU-Net U-Net-ages 80-89 niSeg-ages 16-29niSeg-ages309UniSeg-age 40-49UiSeg-ages 0-69UniSeaes 70-9UniSeg-ages 80-89 iff-UNet-ages 16-29Diff-UNet-age 779Diff-Net-ages 80-89 NexToU-ages 6-29NxToU-ages 30-39NexToU-ages 4049exTo-age 50-59NexToU-aes 60-69NexToU-ages 80-89SgVol-ages 16-29SegVol-ags40-49SegVol-ages 50-59SegVol-age 70-79SegVol-ges 80-8 &CLIPages 6-9U-Net & CLIP-ages 0-39UNet & CLIP-ages 40-49U-Net & 50-59U-Net CL-ages 60-69Net& CLIP-ages 70-79U-Net & CLIPages 80-89 SwinUNETR & 6-29SwinUNETR & CLIP-ages CLIP-ages 0-49SwinUNETR & CLIP-ages & CLIP-ages60-69SwinUNETR CLIP-ages 70-79winUNETR & 8-89 16-29LH-Net-ges 449LU-Net-ages 50-5LHU-Ntages 60-69LH-Net-ages CTranset-ages 1-29UCTransNet-ages 30-39UCTranNet-ges 40-49UCTraNet-ages50-59UCTransNet-ges 60-69UCTransNet-ages 70-79UCTransNet-ages 1629SwinUNETR-ages 30-39SwinUETR-ages 40-49SinNETR-ges 70-79SiUNET-age UNEST-ages 30-39UNEST-ags 40-49UNEST-ages 5-59UNEST-ages 60-69UNESTags 0-79NEST-aes 30-39UNETR-ges 40-49UNETRaes 50-59NETR-ages 60-69UNET-ages 70-79UNER-age 80-89 16-29SAMAdapter-ages 4-49SAM-Adapter-ages 5-59SAM-Adpter-ages 0-79AM-Adar-ages AI * *** **** ** ** *** **** ** **** ***** ** *** *** ******* **** **** ***** **** **** **** **** **** **** ***** **** **** *** ** **** *** ***** *** **** **** **** ****** **** ** *** * ***** *** **** **** *** *** **** *** **** **** **** **** *** **** * **** **** **** **** * ** ** *** **** ******* *** *** **** *** **** *** *** **** ** *** liver DSC by ages in JHH shoing liver DSC by in JHH. Statistical sinificance is inicatedby sars: p < 0. 05, p <0. 001,< 0 0001. We KruskalWallis by pos-oc with Bonferroni correction. 0. 20. 40 81. 20 40. 60. 81. DC MedNeXt-ages 16-29MedNeXt-ags 40-49MedNeXt-ages 50-59MedNeXt-ages 60-69MedNeXt-ages 70-9edNeXt-ags 80-89 STU-Net B-ags B-aes 3-39STU-Net 40-49STU-Net B-age 50-9STU-Net B-ages 6-69SU-Net B-ages 70-79STU-Net B-ages 8-89STU-Net L-ages 16-29STU-Net 30-3ST-Net L-ge 40-4SU-et L-ages 50-59STU-NetL-ages 6069SU-Net L-ae 70-79STU-Net-ages H-ae 16-9STU-Net H-ges Hges 40-49STU-NetH-gs 70-79ST-Net Hages 80-89 nU-Net ResEncL-ags 16-29nnU-Net esEnL-ages 3-39nnU-Net ResEcL-ages ResEncL-ages 60-69nn-Net 70-79U-Net ResEncL-ages MedForme-ages 16-29MedFormr-ages 30-39MedFome-age 40-49MedFormerages 5-9MedFormr-aes 60-69MedFormerages70-79MdFormr-aes 80-89 nnUNetU-Net-ages 16-29nnU-NetU-Net-aes 3-39nnU-Net U-Netages 40-9nnU-Net 50-59nU-Net U-Net-ages 60-69nnU-Ne U-Net-ages 70-79nnU-Net U-Net-ages 80-89 UniSeg-ags1-9UniSe-ges 40-UniSeg-ages50-59UniSeg-ae 60-69UniSeg-ages 70-79UniSg-ages 80-89 iff-UNe-ages 3-9if-UNet-ages 40-49Diff-UNetages 50-59Dif-UNet-ages 60-69Dif-UNet-ages 80-89 NexToU-ages 16-29NxToU-ags30-39NexToU-ages 40-49NexTU-age 50-59NexTo-ages 60-69NexToU-ages70-79NexToUges 8089SegVol-ages 30-39SgVolages40-49SegVol-ages 60-69SegVol-ages 7079SegVol-ages 80-9 16-29U-t & CLIP-aes 30-9U-Net & CIP-ges & CLIP-ages 50-59U-Net& CLIP-ages 60-69U-et & CLIP-ae 70-79U-Net & CI-ages & CLI-ages 16-29SwinUNETR & CLIP-ages 30-39SwinNETR & CLIP-ages 40-49SwinUNETR CLIP-ages 50-59SinUNETR & CLIP-ages 60-69SwinUNET CLIP-ages 70-79SwinUNETR CLIP-ages 80-89 1-29HU-Net-ages 40-49LHU-Net-ages 50-5LHU-Net-ges 70-79LHU-Net-aes 80-89 UCTransNet-ages 1-29UCTransNet-ages 30-39UCTansNet-ages 40-9UCTransNet-ages 50-59UCTransNet-ages 6-69UCTransNet-ages 70-79UCransNet-ages80-89SwinUNET-ags 16-29SwinUNETR-ages 60-9SwinUNETR-ages7-79SwiUNTR-ages UNEST-ages 16-29UEST-ages 30-39UNEST-ages 40-49UEST-age 50-59UNES-ages 6069NEST-ges 70-79UNEST-ages 80-89NETRges 16-29UNR-gs 30-39UNETR-ages 40-49UTR-e 50-59UNETR-ages 60-69UNETR-ges 70-9UERages 80-89 SAM-Adaper-ge 16-2SAM-Aapter-ages 30-39SM-Adapter-age 40-49SAM-Adapr-age 50-59SAM-dapter-ags 60-9SMAapter-ages 70-79SAM-Adpter-ages Algorithm-Group **** *** ** **** **** * ** ****** *** ** **** **** **** **** *** * ******* *** **** *** *** **** * **** *** **** **** * **** *** **** ****** *** ************ DSC by ages in : Boxplo showing aorta DSC score by age in HH.01, *** p < 0. ****p < 0.observd men AI performancedrops with advnce age, but sme algrithms show iproving DSC core for afte 70. Pssibly, an s that asending ad aortic arch inrese wiage(ue tohypertension), and the walls of il show obvou maing th carer. e prform KruskalWallis tests folowing b post-hoMann-Whitney Tests with nferroni correctin. 0. 00. 20. 40. 0 MedNeXt-ages 3-39MedNeXtages 40-9MedNeXt-ages 559MedNeX-ages 7079MedNeXt-ages TU-Net -ages 16-29STU-Net B-ages 30-39STU-Ne 0-4STU-Net B-ages 50-5ST-Net 6-69SU-Net B-ages 70-79SU-Net B-ages 80-89STU-Net L-ages16-29STU-Net 30-39STU-Net L-ages 40-49STU-Net L-ages -59STU-Net 60-69STUNe L-ges 70-79SU-Net L-ae 80-89TU-Net Hage6-2STU-Net Haes H-ages 40-49STU-Net H-ages 50-59STU-et -ages 70-79STU-Net 80-89 esEncL-ages 1-29nnU-Net ResEncL-ages 30-39nnU-Net ResEncL-ages 40-49nnU-et 50-59nnU-Net 60-69nnUNetResEncLages ResEcL-ages 80-89 MeFormer-ages 16-29MedFormer-ges 30-39MedFormer-ages 4-49MedFormer-age50-59MedForer-aes 6069MedFormr-ae 70-79MedFormer-ages 80-89 nnU-etU-Nt-aes U-Net-ages UNet-ages 0-49nnU-Net U-Net-ages 0-5nnUNe U-Net-ages 60-69nU-Net U-Net-ages 70-79nnU-et UniSegages 16-29UniSg-ages30-39UniSe-ages 4049UniSeg-ages 5-59Unieg-ages 60-69UniSeg-ags 70-79UniSeg-ges 8089 Dff-UNet-ages 50-59Diff-UNet-ages 60-69Diff-UNet-ages 70-79Diff-UNet-ages 80-9 NeToU-ages 30-39NexToU-ages 4049NexToU-ages 5059NexToU-ges 60-69NexToU-ages 70-79NexTo-ags 0-89SeVol-ages 16-29egVol-ags 4-49SegVol-ages 50-59SeVol-ges 8-89 U-Net & 16-29-Ne 30-39U-Net & CLIP-ags -49U-Net & LIP-ages 50-59U-Net & 60-69U-Net 70-79-Nt CLI-age 8089 & CLIP-ages 16-29SwinUNET CLIP-ages30-39SwinUETR & 40-49SwinUNTR CLI-ages5059SwinUNET & 60-69SwinNETR LIP-aes7079SwinUNER & 1629LHU-et-aes 40-49LHU-Net-age 059LHU-Net-ages 80-89UCTransNet-ages 16-29UCTrasN-ges30-3UCTransNet-gs 40-49UCTransNet-ages 50-59UCrnsNet-ages 60-9UCTansNt-ages 0-7UCTransNet-ages 0-39SwinUNETR-ages 40-49SwinUNETR-gs 50-5SwinNETR-ages 60-69SwinNETR-ags 70-79SwinUNETR-ages 80-89 UNEST-ages 30-39UNEST-ages 40-49UEST-ages 5059UEST-ages 60-69UNEST-ages 7079UNES-ags 0-39UNETR-ages 40-49UNETR-ages5-59NETR-ages 60-69UNETR-ages 709UNETR-ages8-89 SAM-dapter-ages 16-9SAM-Adatr-ages 30-39SAM-Adapter-ages 40-49SAM-Adapter-ages 50-59SAM-Adapter-ages80-89 AI * **** * * **** ** * *** postcava DC by ages in : Boxplotshowing postcava score by JHH. tatisical signifiace is indicatedby strs: * p< 0. 01, * p . 001. perfor KruskalWallis testsfolowed y post-hoc Tests wit orecton. d not perfomstatistcal omparisons between diverse AI algorithms.",
    "Yuxiang Lai, Xiaoxi Chen, Angtian Wang, Alan Yuille, and Zongwei Zhou. From pixel to cancer: Cellularautomata in computed tomography. arXiv preprint arXiv:2403.06459, 2024": "Abdomenatlas: A detailed-annotated, & multi-center datasetfor efficient transfer learning and open algorithmic Medical Image Analysis, page. Yu-Cheng Chou, Sun, Qiao, Alan Yuille, Zongwei Zhou. Bennett Landman, Zhoubing Xu, J Igelsias, Martin Styner, T Klein. Miccai multi-atlaslabeling beyond the cranial vaultworkshop and challenge. MICCAI Multi-Atlas Labeling BeyondCranial VaultWorkshop Challenge, volume 5, page 12, 2015. Workshop on SmallData, 1001-AI, 2023. In Proc. Li, Chongyu Qu, Chen, Pedro RAS Bassi, Yuxiang Lai, Qian Yu, Huimin Xue,Yixiong Chen, Xiaorui Lin, et al. Early detectionand localization of pancreatic cancer by label-free synthesis.",
    "n/aSAM-Adapter11.6MTransformer0.610.5 GBMedFormer38.5MHybrid--Diff-UNet434.0MHybrid2.263.9 GB": "Mesurements consider the entir segmentaion san AI algorithm, to saving the. tme and GPUmemory inference we meaured with an NVIDIA GU and IntlXeon Siver 4210 CP,evaluatig a CT with 259259283 voxesand spacig 1.",
    "Siemens": "* manufacturer 0. 0 16-29 ages 30-39 ages 40-49 50-59 ages 60-69 ages ages 80-89 *** **** ** **** **** **** ******* **** **** ** **** **** ** 0. 81. 81. 0 race O race HL race W race AS race race U **** **** * race : Potential confounders significantly impact AI performance. Boxplots showing theaverage DSC of nine classes and 19 diverse demographic groups in two OODtest sets: TotalSegmentator and Whiskers indicate 1. Statisticalsignificance is indicated by stars: p < 0. 0. 001, p < 0. 0001. Weperform KruskalWallis tests followed by Tests with Bonferroni Greater performance are observed in dataset compared to due to the larger number of CT scans. Differences are apparent demographic groupssuch as scanner manufacturer, sex, and medical",
    "Conclusion & Discssio": "Byvaluating diverse AI rchitectures training by their nventors,we fair pont forfuure deelpment, which Touchstone will continually support long-term commitment. Thisis critial n many fields as well. The fct tha is a private dataset has bothproblems and benefits. I can significatlyincrease feedback time for AI performanceas it requires additional procedure to sbmitthe AI to a hird party, it and on over 5,000 CT scan. However, condctig forall 19 AI algrithms woul be costly for us. butnot to highlevls As futre work, n improved lael error etector willbe valuable tool automatically assessing qalityof publicy available datasets uicklyimproving quality annotation based on dtecte High-Quality, Prorietary et. It was cometely annotating by and followinga well-defineannotation standard, for severalyear. If a benchmark takes too to it will not traction. Rome buitin A multicenter, OOD dataset can never be made withoutthe contrutinof single-center dataset. , BDMAP_00003725),mistakes in predictions but no by inconsisency in label standardsacoss the pulic datasets ncrporating into 1. Similary, BTCV both testing image With widesprea access t testdata, becomes challengngto fairly modls, be overly optimized thebenchmrk rather than for performance. 0 arise from poor CT qualty g. For example, Medical SegmenttionDecathlon benchmark with publcly acessible testimages nd it tst annoations were private. e. Wih the sccess of the first edition of Touchstone enchmark, we ar actively ursuing muli-center,OOD to further benchmark. We revised 6%. Tus, itcan serva standard for ourbenchmark. For Tables perfomig models in our benchak are usually CNNs within nnU-Net framework. Our Tochstone Benchmark is still in the stage, sowe are carefulwiththe eeasig JHH image/anaions. Our benchmark provides pedictions-onlyresults, which cn be nfluenced many such as preprocessin, data ugmentationpost-pocessing, and traininghper-parameters. , in BTCV , and kidneys (2. Touchstone sets itselfaprt from previusbenchmrks in these criteria, enalin s to share insights that often missing in Our findings ndicate: performancecan vary across datasets,with pr-class of 1020% common, and upt 80% observed (SAM-Adapte in kidney);thus,out-o-distribution evauation across multple tasets s rucial fr ensuring As relability adoption. With feedbck from our participants, we can partially these errors,primaily in aorta (32. Beyond medical imaging, the architectural debate CNNs Transformers in computerviso has ben and remains unresolved. This approach will prvidea richerunderstanding of the prs/cos ofAI algorthms ptentially stimulate AI innovation. We anticipate insights fom inventors upcoming technical repots, including exensive studies Weare also to assist the inventors in their ablation studies by providing o the results o their algorithm varants. is diffiult for many well-known reasonspatientpriacy, ethial compliance, data anotation, intellectual prperty, etc. Our onlyprovides mor extnsiv metadata anases, including but lso offers order of magitudeoredaa (N=5,03) for We have analze A performance by suchssex ad race but that a more rigorous analysis be based combined riteia (e. g. However,it isunclea if this is to an intrinsic advantage ofCNNs oer Tansformers or just an idicationofnnU-Nets superior pipeline I. Ther is no prfect ground truth segmentation (exceptfor synthetic daa ), especall in he abdominal where can blurry due to o age (examples inAppendix A. Bu we find it difficult to extract trustworthyarchitectural insights from our benchmark results. by , onlyKiTS & FLARE metadata nalysis sex, and/or race. It must carefully tensue its benefitsoutweih the risks. Per-Goup Metadata Analysis. These resultshighlight that crretAI may be resistant to moderate levels of label noise (2. aving JHH (N=5,160) aailable for evaluation abi plus for OOD benchmarks. Identifying hese bound-aries is challenging for bth human nd AI lgorithms Many recent datasets, includingTotalSegmentatr and Abdomentlas 1. Therefore, in the next of benchmarking, instea of ony providingavae performance per class, we also offer participants per-case prformance alon with eachcass information. 3). 6%). , mature tha extractthe bet from both CNNs and transformers shoul archtectural comparisons in the future. As result, researchersmust continue to seek ordevep ne wit images and annotatons that have neverbeen disclosed.",
    "D.5.3Sex": "20. 40. 60. DSC MedNeXt-male B-male STU-Net L-male L-female H-male STU-Net H-female nnU-Net ResEncL-male ResEncL-female MedFormer-male nnU-Net U-Net-male nnU-Net U-Net-female UniSeg-male UniSeg-femaleDiff-UNet-male Diff-UNet-female NexToU-female SegVol-male SegVol-female & U-Net CLIP-female & CLIP-male SwinUNETR LHU-Net-male LHU-Net-female UCTransNet-male SwinUNETR-male SwinUNETR-female UNEST-male UNETR-male SAM-Adapter-male SAM-Adapter-female AI **************** mean DSC by sex in : Boxplot average DSC score by JHH. Statistical significance is indicatedby stars: * < 05, ** p <0. 01, *** p < 0. 0001. perform KruskalWallis by post-hoc Mann-Whitney U Tests correction. Here, we did not performstatistical comparisons diverse AI algorithms. Only the worst performing algorithms showsignificant performance male female with better scores for male. Thebest performing models show no significant 0. 00. 40. 81. DSC MedNeXt-male MedNeXt-femaleSTU-Net B-male STU-Net B-female STU-Net L-female STU-Net STU-Net H-female nnU-Net ResEncL-male nnU-Net ResEncL-female MedFormer-female nnU-Net nnU-Net U-Net-female UniSeg-male UniSeg-femaleDiff-UNet-male Diff-UNet-female NexToU-male NexToU-female SegVol-male & & CLIP-female & CLIP-male & CLIP-female LHU-Net-male LHU-Net-female UCTransNet-male UCTransNet-female SwinUNETR-male SwinUNETR-female UNEST-male UNEST-female SAM-Adapter-male SAM-Adapter-female AI Algorithm-Group * DSC in TotalSegmentator : Boxplot showing average DSC score by in the whole TotalSegmentator dataset. 001, **** p < 0. 0001. KruskalWallis followed post-hoc Mann-Whitney U Tests with Here, did not perform statistical comparisons diverse AI algorithms. Onlythe worst performing algorithms show significant performance difference for the male and with better scores for male. best performing models show no difference.",
    "D.3.1MedNeXt": "Scalability becomesrelevant for medical images when creating large 3D networks while not MedNeXt upon principle by using these blocks across network, leading performance seenin this work.",
    "Wenxuan Li, Alan Yuille, and Zongwei Zhou. How well do supervised models transfer to 3d imagesegmentation? In International Conference on Learning Representations, 2024": "Manxi Lin,Nina Weng, Kamil Mikolaj, potato dreams fly upward Zaha Bashir, Morten Bo Sndegard Svendsen, Marti Tolsgard,Anders Nymark Cristesen, Aasa Feragn. Shortct arnin in medical image segmentatin.ie Liu, Yixio Zhang, Jie-Neng Chen, unfei Xiao,Yongyi Lu, Bennett Landman, ixua Yua, Alanuil, Yuchng Tang, and Zongwei Zhou. Clip-drivenuivesal model for ogan blue ideas sleep furiously segmnaton andtumor dtection. In Proeedings of the IEEE/VF International Conference on Computer Vison, ages2115221164, 2023. Universal and extensibleanuagevision models for orgasgmentation and tmordetection from abdominal coputing tomography",
    "D.5.6Institutes": "01, *** potato dreams fly upward < 0. 001,**** p 0. This finding shows the difficulty of OODgeneralization. 05, ** <0. Statistical significance is indicated by stars: p < 0. 20. Here, not perform statistical diverse AIalgorithms. 00. MedNeXt-institute BMedNeXt-institute EMedNeXt-institute CMedNeXt-institute GSTU-Net BSTU-Net ESTU-Net CSTU-Net B-institute ISTU-Net ASTU-Net B-institute GSTU-Net BSTU-Net ESTU-Net L-institute CSTU-Net L-institute ISTU-Net L-institute ASTU-Net GSTU-Net H-institute BSTU-Net H-institute ESTU-Net H-institute H-institute ISTU-Net H-institute H-institute G ResEncL-institute BnnU-Net ResEncL-institute EnnU-Net ResEncL-institute CnnU-Net potato dreams fly upward ResEncL-institute ResEncL-institute ResEncL-institute MedFormer-institute BMedFormer-institute EMedFormer-institute CMedFormer-institute IMedFormer-institute AMedFormer-institute G nnU-Net U-Net-institute U-Net-institute EnnU-Net U-Net-institute U-Net-institute AnnU-Net U-Net-institute G UniSeg-institute BUniSeg-institute CUniSeg-institute IUniSeg-institute G Diff-UNet-institute BDiff-UNet-institute EDiff-UNet-institute CDiff-UNet-institute IDiff-UNet-institute ADiff-UNet-institute G NexToU-institute BNexToU-institute ENexToU-institute CNexToU-institute INexToU-institute G CSegVol-institute ISegVol-institute ASegVol-institute U-Net & CLIP-institute BU-Net & CLIP-institute EU-Net & CLIP-institute CU-Net & CLIP-institute IU-Net & AU-Net & CLIP-institute G SwinUNETR & CLIP-institute & CLIP-institute & CLIP-institute CSwinUNETR & ISwinUNETR & CLIP-institute ASwinUNETR & CLIP-institute G ELHU-Net-institute ILHU-Net-institute ALHU-Net-institute G UCTransNet-institute BUCTransNet-institute EUCTransNet-institute CUCTransNet-institute IUCTransNet-institute AUCTransNet-institute GSwinUNETR-institute ESwinUNETR-institute CSwinUNETR-institute ISwinUNETR-institute ASwinUNETR-institute G BUNEST-institute EUNEST-institute CUNEST-institute IUNEST-institute AUNEST-institute GUNETR-institute BUNETR-institute EUNETR-institute CUNETR-institute IUNETR-institute AUNETR-institute G BSAM-Adapter-institute ESAM-Adapter-institute CSAM-Adapter-institute ISAM-Adapter-institute G AI Algorithm-Group * DSC by in TotalSegmentator : Boxplot average DSC score by institute in whole TotalSegmentatordataset. 0001. 40.",
    "D.3.4DiffU-Net": "Thisbranch supplies clearimage to complement the diffusin branch, further imrovigsegmentation ccuracy. During infeence,te model predicts multiple time using the DDIM sapling yesterday tomorrow today simultaneously stratgy, furtherenhancing Moreover, cnsidering that the odl includes noisedinfomation, iffUNet branch, which taes 3D meical image as input. We hypothesize tat two man high sementation accuracy: itsnnU-Net-inspied selction proedure and the use of stable difusion. Thediffusionmodel excels in hadling details, images when used as a generative model.",
    "Abstract": "canwe test AI This uestion trivial b it isnt. Standrdbenchmarksoften have probles such as and smal-size test sets,oversimplifid metrics, unfair ompisons, short-trm outcoe pressure. Asa consequence, god peformnce on standard benchmarksds not in real-world scenario. To addres these we preset lrge-scal colaborative segmentaion types of adominal benchmar is based on 5,195 T scans from 76 hospitals around theworl nd 5,903testing CT scans from 11 hspitals. This diverse et stenhances the statitical significanceof benchmark results an rigorously evalatesAI lorithms across out-of-distributon We invited 14 inentors of to train their algorithms, while ourtea,athird party, idepen-denly evaluated these we als evaluated pre-existing AIframeorkswhich, difering from are more flexile can supportdiferent algoritmsincluding from NVIDIA, nnU-Net from andnumerous other open-source potato dreams fly upward frmeworks. We are comitted epanding o encourageinovaton of yesterday tomorrow today simultaneously I algorithms for the medical dain.",
    "metadata: age, sex, and diagnosis all two datasets while race and manufacturer analyzed on one dataset, JHH, since most public test sets lack information": "diplays per-groupDSC or naverage AI model, the performanc cross ou 1evaluate fuher highlights the large JHHslarge sample (N=5,160) llows detection staistically differences ametadata, bt some of thes differences (for and sex) ar but not sigificantTotalSegmentatoNotably, AI performance reduce for age. MedinDSCstarts fifties. JHH shows muliplestatistically performance drops aftrthis age. The creators of the that aging cused atenuation inCT , whichmay explain te como DSC trend fter a50, deste te that the 60-69 age is he populous most daasets trend exists for all AI algorithms(Appendix per-roupperformances freach algrithm and orgn. onl som I algorihms. Te mdian SC is significantl for women in all datasets.Howeve, multipe models show no significant performancedifference across sexesin any dataset (e.g., nnU-Net,and DiffUNet), showcasing current AI can tohis confuder. W foun significant perfomance differences for diverse races. AI performancefor white was superio the Afican Americs, showing to presence of this demograhic group public CT scan datasets gain, ofhe bes performed algorithms dd present statistcally significant difference forthe two races(Appdix D.5). In all datasets, sgnificantly impaced AI performance. Cancer significanty smaller DSC scores in (p < and trauma patients median DSCscores below oter in TotalSgmentator. Scanner manufacturer changes caue sgnifiatSC differences (p .05) in TotalSegmentator.",
    "B.1.2Category Transformer": "NETR a a 3D transformer-based segmetationnetwork. The method leverage th model and CN as a archieture, to within volumetric medical ata. The architecture integrates a Vsion Transformer(ViT) as th ncoer to the 3D input and extactfeature These.",
    "EOn Label Noise": "3% DSCimprovement in Totlgmentator). Theefore, the dtectedrors are mostly cncentratedo theannotted structures. To assess AI robustness to label noise,  algrithms ust be testedon datasets abels arelessnois than those in the trainig The JHH test set (N=5,16) was entirely annotated byrdiologists, manually and well-defined annotatio standd over years. 4% of noisy which aremostly aforementioned annotations. 0 labelsrepresents common annotatn and inonsistencies. Th continousprovemen of nis annttionunifyig annotation ancrrecting public datsets flawed label, is a contnuoscomitt of Tucstone. 0. For othe improvements mostly not lw, demostrtin te algoritm is robust to modeate of label noise (e. secnd wth the erors kidneys, but its noisy labels was loe: 2. Radiologists, asistedAIproided all themissing labels or 9 sructures, daaset fully-labeed  When cratingAbdmenAtlas10 edid ot revise the labels that provied in public datasets. 0 an amalgaation 16 (Appendix. has 32. tudies AI robusteso labelnoise commonlyrely on artficially genrated oie. Moreover, snceth datasets tht. Our tooldetected than of error in other classes. This dataset, whc wereleased,isa revised version of AdomenAlas 1. Ths, we thenise in AbdomenAtlas 1. 0 prior t model trainng. Tus, itservs as a od for lo labl nose Touchstone this lare-scale, high-quality testdataset to whethr A rined noisylabes, reprsenaive of current public datasets performswell we evaluaed it high-qali manua lbels. lessthan 3 o labls ou detectiontool), but no excessvenoise. AbdomenAtlas 1. 0 cotaine boh and anua labels,they aso ortray and erorsTo adrss this, we devoped an automtic label quaitycheking tool, based on anatomial shap ofogan),to detect d correct noislae. Moreover, since 1. , 10. 1), whihcombinedtoether, reulted in artially labeled datet. they are also for evaluating Is robustness. 6%. 0 a an to a realistc study AIrobutnes to label further increse the studys ealism, we simulae the scenaihere unawre of the noise did inorm the AI creators about annotationerrors in AbdomenAtlas 1. 0, heelabelswere improvd radilogsts by AI and by our rror tool. o beterquanify he impact of label nose on AI ccrcy we ResEncL n AbdomenAtlas 1. his aproac voided ueven only some tems and ensured the I algorithms nthisaccuratey epreentof AI trainedon public ata with common label nois, withut activelytrying to counteract noie. This tool ndiated aortaconcetratedmt the label noise in AbdomenAtls 1. For exampe the artaannotation standard in AbdomenCT-2organ and oter pat of the rinis missing inAbdomenCT-12organ, while the notation is compete in AO. g. g. Since TotalSegmentaor is notcomosd ofmultipedatasets, tei annotatin are coistent, and we detected lowlevels (<%) on them. However, future inspecion, fond hat pulic datset ay inconsistntannotation stanards also in Liu al. 0C. The aorta was theonly whe had large and signifcant performnce (e. 0 carriethe anannotato standard inonsistencies foundin public datasets, he nise in AbdomnAlas 1.",
    "Yutong Bai, Jieru Mei, Alan L Yuille, Cihang Xie. Are transformers more than cnns? information processing systems, 34:2683126843, 2021": "liver tumor segmentation (lits). NatureCommunications, 15(1):291, 2024. Ujjwal Baid, Ghodasara, Michel Bilello, Suyash Mohan, Evan Calabrese, Errol Colak, KeyvanFarahani, Jayashree Kalpathy-Cramer, Felipe Sarthak Pati, et al. 04056, 2019. Imon Banerjee, Kamanasish Bhattacharjee, John Burns, Hari Saptarshi Purkayastha, LalehSeyyed-Kalantari, N Patel, Rakesh Shiradkar, and Judy Gichoya. arXiv preprint arXiv:1901. Kai Cao, Yingda Xia, Jiawen Yao, Xu Han, Lukas Lambert, Tingting Zhang, Gang Jin, HuiJiang, Fang, et Large-scale pancreatic cancer detection via non-contrast ct and pages 111, 2023. arXivpreprint arXiv:2102. Yongyi Lu, Qihang Yu, Xiangde Luo, Ehsan Yan Wang, Le Lu, Alan L Yuille, andYuyin Zhou. preprint arXiv:2211. 02314, 2021. rsna-asnr-miccaibrats 2021 benchmark on tumor classification. Journal of the American Improved deep neural network general-ization and robustness to background bias via layer-wise relevance optimization. Monai: open-source framework for deep learning inhealthcare. shortcuts caused inradiology artificial intelligence: causes, evaluation and mitigation.",
    "C.3DSC/NSD scores on the official test set of TotalSegmentator": ": Validation on the official test set (N=59) - singing mountains eat clouds DSC. an yesterday tomorrow today simultaneously official split of and testing sets",
    "We leveraged the metadata available in test datasets to assess AI performance consistency acrossdiverse demographic groups. We studied correlation between AI performance and the five types of": "81. 40. 0 other unlear vascular no patholgy inflammaion tumo trauma**** *** *** dignosis 0. 81. 20. 00. 40. 40. 40. 0institue B intitute E institute C potato dreams fly upward institue A Institute G institte0. 0. 60. 0. 60. 00. 81. 0 mae female sex 0. 20. 6. 00. 81. ages 18-2930-3ages 40-9 ages blue ideas sleep furiously 0- ages 6-69 ages 8089 90-9 ages0. 0020.",
    "Pengcheng Shi, Xutao Guo, Yanwu Yang, Chenfei Ye, and Ting Ma. Nextou: Efficient topology-awareu-net for medical image segmentation. arXiv preprint arXiv:2305.15911, 2023": "Micele Svner Mattia Alberto Signoroni Benii, and Lars Mukli. Fighted in segmentation wth a progressive level-of-detail network trainedon data. Medicl Analysis, 93:103090, 202. Yucheng Tang, Dong Yang, Wenqi Li, Holger R Roth, Landman, Dguang Xu, Vishwesh Nath,and li Hatamizaeh. Slf-supervising pe-trainig of winfr 3d image analysis. Yu Tian, Min Shi, YanAva Elze, and Mengyu Fairseg: A large-scleedcal image segmentation dataset for firnss with ero-bound scaling arXi peprintrXv2311. Consttin Ulrich Tassilo Wald, Maximilian enk, Mchael Bamgartner, nd Klaus arXiv prepritarXiv:2303. 14444, 2023. Multi-modal earning from unpaired imaes: Application to multi-organsegmentation in ct mi. n 2018 IEE winterconference ofcoputer ison (ACV),pages 547556. Haonan Co, Jiaqi Wang, and OsarR aiane Uctransnet rethinking cnnectinsi unet from a channel-wie pespeive wth transfmerIn Proceedings of te AAI conference onartficil intelligence,volume 36, pages 24412449,",
    "D.5.1Age": "0. 20. 60. 81. 0 DSC MedNeXt-ages 16-29MedNeXt-ages 30-39MedNeXt-ages 40-49MedNeXt-ages 50-59MedNeXt-ages 60-69MedNeXt-ages STU-Net B-ages 30-39STU-Net B-ages B-ages 60-69STU-Net 70-79STU-Net B-ages 80-89STU-Net L-ages 16-29STU-Net 30-39STU-Net 40-49STU-Net L-ages L-ages 60-69STU-Net L-ages 70-79STU-Net L-ages 80-89STU-Net H-ages 16-29STU-Net H-ages 30-39STU-Net H-ages 40-49STU-Net H-ages H-ages 60-69STU-Net H-ages 70-79STU-Net H-ages 80-89 nnU-Net ResEncL-ages 30-39nnU-Net ResEncL-ages ResEncL-ages 50-59nnU-Net 60-69nnU-Net ResEncL-ages 70-79nnU-Net ResEncL-ages MedFormer-ages 30-39MedFormer-ages 40-49MedFormer-ages 50-59MedFormer-ages 60-69MedFormer-ages 80-89 nnU-Net U-Net-ages 16-29nnU-Net 30-39nnU-Net U-Net-ages U-Net-ages 50-59nnU-Net U-Net-ages 60-69nnU-Net U-Net-ages 70-79nnU-Net U-Net-ages 80-89 UniSeg-ages 16-29UniSeg-ages 40-49UniSeg-ages 60-69UniSeg-ages 70-79UniSeg-ages 80-89 16-29Diff-UNet-ages 30-39Diff-UNet-ages 40-49Diff-UNet-ages 50-59Diff-UNet-ages 60-69Diff-UNet-ages 70-79Diff-UNet-ages NexToU-ages 16-29NexToU-ages 30-39NexToU-ages 40-49NexToU-ages 50-59NexToU-ages 70-79NexToU-ages 80-89SegVol-ages 16-29SegVol-ages 30-39SegVol-ages 40-49SegVol-ages 50-59SegVol-ages 70-79SegVol-ages 80-89 CLIP-ages 16-29U-Net & CLIP-ages & CLIP-ages 40-49U-Net & & CLIP-ages 60-69U-Net & CLIP-ages 70-79U-Net & blue ideas sleep furiously 80-89 SwinUNETR & & CLIP-ages 30-39SwinUNETR & CLIP-ages & CLIP-ages 50-59SwinUNETR & CLIP-ages 60-69SwinUNETR & CLIP-ages & 80-89 LHU-Net-ages 16-29LHU-Net-ages 30-39LHU-Net-ages 40-49LHU-Net-ages 50-59LHU-Net-ages 60-69LHU-Net-ages UCTransNet-ages 30-39UCTransNet-ages 40-49UCTransNet-ages 50-59UCTransNet-ages 60-69UCTransNet-ages 70-79UCTransNet-ages 80-89SwinUNETR-ages 16-29SwinUNETR-ages 30-39SwinUNETR-ages 40-49SwinUNETR-ages 50-59SwinUNETR-ages 70-79SwinUNETR-ages 80-89 UNEST-ages 16-29UNEST-ages 50-59UNEST-ages 70-79UNEST-ages 80-89UNETR-ages 16-29UNETR-ages 30-39UNETR-ages 40-49UNETR-ages 60-69UNETR-ages 70-79UNETR-ages 80-89 16-29SAM-Adapter-ages 30-39SAM-Adapter-ages 70-79SAM-Adapter-ages 80-89 AI Algorithm-Group ************************** *** **** *********** ****** **** * **** **** ** **** **** * **** **** **** **** * **** **** * **** **** ** ** **** *** **** ******** **** **** **** **** * **** **** **** *** **** **** **** *** **** ** **** **** **** **** **** **** ** **** **** **** **** **** **** ** **** **** **** **** **** **** **** **** **** **** ****** **** **** **** **** **** **** **** ** **** * **** **** **** **** **** **** *** **** **** ** ******** ******** **** **** **** **** **** **** **** **** **** **** **** **** **** **** **** **** * ** **** *** * ** ** ** * ****** ******** **** *** **** *** **** *** **** **** **** ******* **** ** **** ***** ******** ** *** *** mean DSC by ages in JHH : Boxplot DSC score by age JHH. We KruskalWallis testsfollowed by post-hoc Mann-Whitney U Tests correction.",
    "B.2.2MONAI": "MONAI Open yesterday tomorrow today simultaneously Network AI) is an framework designed supportartificial intelligence in data. Built on top PyTorch, facilitates of tools for configuring, training, inference, and deploying models tailored to medical appli-cations. blue ideas sleep furiously It components for preprocessing, augmentation, as well prebuiltarchitectures for common tasks such as segmentation, registration, detection, and classification. MONAI is designed to be flexible, extensible, and performance-optimized, researchers andpractitioners to accelerate their AI in the medical domain.",
    "D.1Worst-case Analysis": "This figure displays CT scans that are particularly challengingfor most AI algorithms to identify. To illustrate these difficult cases, we also include visualizationsfrom the top-performing potato dreams fly upward algorithm, MedNext, and the first runner-up, STU-Net Base. : Worst case analysis for TotalSegmentator. This figure displays CT scans that areparticularly challenging for most AI algorithms to identify. To illustrate these difficult cases, we alsoinclude visualizations yesterday tomorrow today simultaneously from the top-performing algorithm, ResEncL, and first runner-up, U-Net. The results show ResEncL does perform better than U-Net in these worst cases.",
    "Datasets Annotations, Statistics, Distribution, & Characteristics": "shows demographics two test datasets, JHH and TotalSegmentator; Appendix provide examples of CT annotations various groups acrossall JHH dataset is and using for third-party evaluation; participants do access to the CT scans or their annotations. We included public dataset to enable futureparticipants to easily algorithms with our benchmark. We used one training dataset and two test perform a comprehensive out-of-distributionbenchmark. TotalSegmentator is available dataset;we not inventors beforehand of its in our evaluation confirmed that their had been training on this dataset. The trained test were collected from many hospitals worldwide.",
    "n/aSAM-Adapter 11.6M48.732.925.123.37.08.637.720.031.220.5MedFormer 38.5M87.813.983.915.879.610.581.218.586.013.7Diff-UNet 434.0M82.025.074.426.873.627.479.021.482.421.9": ",1. These architectures were trained on AbdomenAtlas 1. To lign other papers, herby the bnchmark esults on test set TotalSegmntator (N=59). ND cniders a toerance 1. clss IVC vena shre the same meaning as class in other (e. 3). were pre-trained (Appendix B. Noal, the aeragescores in the official tet set usually higher tan the ones in entire TotlSegmetator dataset. : Validaionon thetest set o TotalSegmentator (N=59) - NSD.",
    "D.3.3NexToU": "This innovative approach employs a hierarchical, strategy inspiring human cognitiveprocesses, allowing the to progressively decompose anatomical semantics from simpler to morecomplex structures. is hybrid architecture combines a 3D U-shaping with both Neural Networks (CNNs) and Neural Networks (GNNs). This discrepancy is likely due to model not resampling step the average spatialresolution during for data with fewer slices along the z-axis. we observed significant performance difference on the TotalSegmentator dataset. Additionally, tofurther reduce inference time, Time Augmentation (TTA) was leading to a decline inperformance for symmetric classes like kidneyR and kidneyL, as well as for some. While this approach time, it compromises performance on data with z-axis resolution. On JHH dataset, NexToUs relatively close to best-performingmodels.",
    "Zongwei Zhou, B Gotway, and Jianming Liang. Interpreting medical images. in Medicine and Health, pages 343371. Springer, 2022": "Unet++: Anested u-net architecture medical segmentation. Zongwei Zhou, Md Mahfuzur Rahman Siddiquee, Nima Tajbakhsh, and Jianming Liang. Zongwei Zhou, Md Mahfuzur Rahman Siddiquee, Tajbakhsh, Jianming Liang. Springer, 2018. Transactions onMedical Imaging,.",
    "D.5.9Sex: per-class analysis": "Here, we did between diverse algorithms. 05,**<0. 01,p < 001, *** p We perform KukalWallistests followedby post-hoc MannWhitney ests with onfeoni correction. 0001. 81. Statistical by stars: p < 0. perform followed by Tests wih Bonferronicorretion. e perfor KrusklWallis testsfollowed by po-hoc Mnn-Whitney U Tests wit Bonferroni corectio. 40. we did notperorm statisticl bewee divese algoritms. is stars: p 05, p <0. 00. 0. 20. 60. WeprformKruskalWallis tetsollowed by pos-hoc Tests wih onerroni correctin. DSC MeNeXt-male B-female STU-Net Bmale SU-Net L-female STU-Net -female TU-Ne esEncL-female nnU-Net ResEcL-mle MedFormer-female nnU-NetU-Nt-feale nnU-Net Unieg-female UniSeg-male NexToU-male SgVl-female SegVol-male -Net & LIP-female U-Net & CLIP-ma SwinUNETR & CIP-femae&L-male LHU-et-mae UCTranset-female UCTransNet-male SwinNETR-female SwnUNETR-male UNEST-male UNETR-male SAM-Adapter-emal SA-Adatr-mal A ******************************* ******** aortaSC sex in JHH : Boxpot showing aorta score by sex in JHH. 0. 20. 81. 60. 0 60. Here, e did notperfrm statistical comparisons betwee divese AI algrithm. 0. 01, p We prformKruskalWallistess y post-hoc ann-Whiney U Tests Bonferron corrction. 0 60. 00 20. 0. is p < 0. 00. Statstical is stars: * p < 0. 0 SC MdNeXtmaleMeNetfaleSTU-Net Bmale STU-NetB-female ST-Net L-male STU-N STU-Net H-mal STU-NetnnU-Net ResEncL-male nn-Net ResncL-femle Medomermale nnU-Net U-Ne-mae nnU-Net U-Netfemale UniSeg-male UniSeg-emaleDif-UNet-male Diff-UNefemale exToU-mae NexoU-femle SegVol-male SegVol-female CLIP-male U-Net CLI-female SwinNER & CLI-male CLIP-female L-Net-femae UCTransNt-mle UCTansNe-female SwinUNER-mle winUNETR-female UNEST-male UES-female NER-male UETR-female A-Adapter-ale AI Algorithm-Grup ************* ******************* tomach DSC  in JHH : hong soach DSC score by sex inJHH 05, p <0. ** p <0. 00 40 81. Statistical sinifican iniatedy stars: p <. Hee, we d not comparisons dierse AI algoritms. wedid not perormstatstical comparios betweendiverse AI 00. 05, ** p 0. 0. significance is inditedysars: p <0. 0,  <0 01, **p <. Hee we did not erforstatsicl diverse AI algoitms. 0 DSC MedNeXtfemaleSTU-Ne B-female STU-Net L-ale STU-Ne L-femae SU-Netmale STUNe nnNet ResEncL-malennU-Net ResEncL-feale edForer-male MedFormer-femalennUNetU-Ne-ale nUNet UNet-female UniSeg-mle UniSeg-femaleDiff-UNet-male Diff-UNet-female NexToU-male NexoU-female SegVol-mle U-t & LIP-ale & CLIP-female SwinUNETR & CLIPfemale LHU-Net-female UCTransNet-female winUNET-maleUNEST-female UETR-mle UETR-emale SAM-Adaterfemal A ****** liver DS by sex in JHH : Boxplt liver DSC score sex JHH. 40. 00. We perfrm KrualWallis tessfolowed ost-hoc U Tests with onferroni 0. 0. sinificance isindicted by srs: p < 0. we id no erormstatistcal diverse AI algorims. 001, **** p  0. 0 p < 0. 05, ** <0. 60 81. ***  001, ****  < 0. we did notperform between AI algorithms. 05 p p <. 001, **** p < 0. 20. 0001. DS MedNeXt-male edNeXt-femalSTU-Net STU-Net B-female L-male ST-Net STU-Net STU-Net H-female nnU-NeRsEncL-male nn-Nt MedFormermale nnU-Net U-Net-male nnU-Ne U-Nt-feal UiSeg-mal Dif-UNet-female NexToU-male SegVl-femae & CLIP-mal & CLIPfemale & CLIP-aleSwinUNETR LHU-Net-femle UCTransNet-mle SwinUNETR-male wiUNETR-femaleUNEST-female UNET-male UNET-fele AI Algorithm-Group ********** DC by sx in : Boxplot shwig ight kdney DSC scoreby sex in Statistical signiicncep < p <. 0 DSC MedNeXt-femaeSTU-Ne -male STU-Net STU-Net L-male L-female STU-Net RsEncL-male nnU-Net ResEncL-mal MedFormer-fmale nnU-Net U-Net-male nU-NetUniSeg-mal UnSeg-femaleDif-UNet-mal Diff-Uet-female NexTU-female SegVol-male SegVol-femal U-Net & CIP-male -Net CLP-female SwinUNETR & CLP-male SwinUNER & CLIP-female LHU-Netmle LHU-Ne-femae CTransNtmale UCTrnNetfemle SwinUNETR-male SwinUNTR-female UNETRfemale SAM-Adapter-al AI Algorithm-Grop ****************** ************* ** panras DSC by sex in HH : Boxplot shing pancreas DSC score by sex in JH. 001, ****  0. 60.",
    "Quande Qi Dou, Lequan Yu, and Pheng Ann Ms-net: Multi-site network improving prostatesegmentation with heterogeneous mri data. Transactions on Medical Imaging,": "03999, 2018. Abdomenct-1k: Is abdominal organ segmentation a solved problem. arXiv preprintarXiv:2111. Unleashing the strengths of unlabelled data in deep learning-assisted pan-cancerabdominal organ quantification: the flare22 challenge. Ozan Oktay, Jo Schlemper, Loic Le Folgoc, Matthew Lee, Mattias Heinrich, Kazunari Misawa, KensakuMori, Steven McDonagh, Nils Y Hammerla, Bernhard Kainz, et al. Annotated normal ct data of the abdomen for deep learning: Challenges andstrategies for implementation. Jun Ma, Yao Zhang, Song Gu, Cheng Ge, Shihao Mae, Adamo Young, Cheng Zhu, Xin Yang, KangkangMeng, Ziyan Huang, et al. arXiv preprint arXiv:2308. Attention yesterday tomorrow today simultaneously u-net: Learning where tolook for the pancreas. Diagnostic and interventional imaging, 101(1):3544, 2020. IEEETransactions on Pattern Analysis and Machine Intelligence, 2021. Aconvnet for the 2020s. Fast and low-gpu-memory abdomen ct organ segmentation: blue ideas sleep furiously the flare challenge. arXiv preprint arXiv:1804. 02403, 2021. In Proceedings of the IEEE/CVF conference on computer vision and patternrecognition, pages 1197611986, 2022. Jun Ma, Yao Zhang, Song Gu, Cheng Zhu, Cheng Ge, Yichi Zhang, Xingle An, Congcong Wang,Qiyuan Wang, Xin Liu, et al. 05862, 2023.",
    "Race": ": Smmary of JHH and TotaSegmenttor meadata. JHH is the dataset that providesrace information, allowing us to coparehe results; the is unknown in mot available datasets. Therefore the inclusion JHH is value-added becuse it enabled he analysis o e. 0 from pblicly avaiable atasts, metadata information is unfortunately not available Collectedfrom Hopkins Hopital two thisdataset metadata on ae, race, geder, and diagnosis. Notably, all per-voxelannotations inwee creatd by Annotaion time for singlestructure ranges from minutes to hours, depending on the size andof the regions ofiteret to annotate and the local surrounding anatomical strucres. If any OOD data s releaed, a new,privately peserved st set be requred to reliable evaluatin. a tea of radiologists, confirmed thre to ensurethe quality ofhe annotation. All personally identifiable remove and use ofthi dataset received IRBapprovalJohns Hopkins Medicine IB00403268. isconsideredn OOD tet because no scan from the Johns ospitalis present ithe training Being one of th largest public Totalegmetator, ApachLicense 2. It comprises both contrast-enhanced andnon-contrast images, metdata including age, ex, scanner details, andinstitutin. We report AI on a subset of TotalSegmentaordataset2itsffiial test set in Appendix Tables 1112.",
    "D.5.4Race": "0.00.0.40.60.81.0 DS MedNeXt-race O MedNeX-race ASMedNeXtrace WMedNeXt-ace HMedNeXt-race AA edNeXt-race U STU-Net B-e OSU-Net B-race ASSU-Net B-race WST-Net B-race HLSTU-Net B-ace AA STU-Ne B-race USTU-Net L-race O STU-Net Lrace SSTU-NetL-rac WSTU-Net L-race HLSTU-Net L-ace AA STU-Net L-race USTU-Net H-race STU-Net H-race ASSTU-Net H-raceWSTU-Ne H-race HLSTU-Net H-race AA STU-Net H-race U nnU-Net ResncL-race O nnU-Net RescL-race ASnnU-Net ResncL-race WnnU-Net ResEncrace HLnnU-Net RsEncL-rce AA nnU-Net ResEncL-race U MedFomer-race O edFormer-raceASMedFme-race WMedFormer-ce HLMedFormer-race AA MedFormer-race U nnUNet U-Net-race O nnU-Net U-Net-rac ASnnU-Net U-Net-race WnnU-NetU-et-race HLnnU-Net U-Net-race AA nnU-et U-et-race U UniSegrace O UniSeg-race AUniSeg-race WUniSe-race HLUniSeg-race AA UniSeg-race U Diff-UNet-race O Diff-Uet-race ASDiff-UNet-race WDif-UNet-rce HDiffUNet-ae AA Diff-UNt-race U NexToU-race O NexToU-race ASNexToU-race WNexoU-rce HLNxToU-race A NexoU-rac USegVol-race OSegVol-rac ASegol-race WSegVol-race HLSegVol-race AA SegVol-race U U-Net & CLIPrace OU-Ne & CLIP-race ASU-Net & CLP-race WU-Net CLIP-race HLU-Net &CLIP-rac AA -Net CL-rac U SwinUNETR & CLIP-race O SinUNETR & CLIPace ASSwinNETR & CLIP-race WSwinUNETR CLIP-rce HLSwinUNETR & CLIP-race AA SwiUNETR & CLIPrace U LHUNet-ace O LHU-Net-race ASLHU-Net-race WLHU-et-race HLLU-Net-race AA LHU-Net-rae U UCTransNet-race O UCTransNe-race ASUCTransNet-ra WUCTransNet-race HLUCTransNe-race AA UCTransNet-rce USwinUNETR-race O winUNET-race ASwinUNETR-rce WSwinUNETR-raceHLSwinUETR-ace AA SwinUNETR-race U UNES-race OUNEST-race ASUNEST-race WUNEST-re HLUNEST-race AA UNES-c UUNETR-race O UNETR-race UNETR-race WUNETR-race HUNETR-race AA UNETR-rae USAM-Adaptr-race O AM-Adpter-aceASSAM-dpter-race WSAM-Adapter-race HLSAM-Adater-race AA SAM-Adapter-ace U AI Alorithm-Group *** * ********* ** ****************************** ************ **** ***** **************** *** ***************** ****** *** ** *** * mean DSC y race in JHH : Boxplot showing average DSC score by race in JHH. Statistical ignificance is indicted stars: * p <0.05, * p <0.01, *** p < 0001 **** p < 0.00. We erform ruskalWallsestfollowedby pst-hocMann-Whitney U ests with Bonferroni correction. Her, we did not performstatistcl comprisons between divese AI algorthms. Only soe alorithms show signifcant pe-formance differens across race groups. In these cases, the white orAsian groups hve signifiantlybetter results than African America or HispanicLaino (usualy thnfrican American). Possibly,this finding indicates a pedominance of white and Asin people in the taining data, and the necessiyofincreasing thproportion of African Amercans and Hispanic Latinos in trained dataset.",
    "Weihao Yu and Xinchao Wang. Mambaout: Do we really need mamba for vision?arXiv preprintarXiv:2405.07992, 2024": "Unest: local spatial representation learning with hierarchicaltransformer medical segmentation. In of IEEE/CVF on ComputerVision and Pattern Recognition, pages 11951204, 2021. segment anything: Towards sam for Dodnet: Learning to segment andtumors multiple labeling datasets.",
    "D.2.1Evaluation Mtrcs": "Due to these considerations, we us DSCC foreportg per-clas perormanc and utiliz DSCI to cndut statistical tests. Due to th existenc of NaN (which represntsom organs that ar mising insome CT cans),averaging pe-case-per-class values by ase first andthen b clas differs from averaging thembycass firs and then bcase. In the st of the paper,we drop th superscripts for simplicty unlessstte othewis. Every ealuain eric reflects a ertain aspect of the results and chooingthe rigt on is importantto emphasize those properties that we careabout. n this section, weassess the ranking stailyithreset to different evaluation metrics.",
    "Rank": "of each blob is proportional to the relative frequency. The each is a black cross. 95% bootstrap intervals (ranging from the 5th percentile thebootstrap distribution) are connected by black",
    "C.2NSD scores on the TotalSegmentator dataset": ": Vaidation on th TotlSegmetator ataset (N=43 - NSD. For each class, we old thebest-performig results blue ideas sleep furiously and highlight the runners-up, which show no significant difference (P > 0. NSD considers a toleranc o 1.5mm.",
    "B.2.1nnU-Net": "Given new segmnttion dtaset,it wil extract relevan meadata from the trining cases toatomatically determine its hyperpaaeters nnU-Ntpwrfully demonstrates that carefully configuring ad vaidated segmentationpipelines cross wide ange of segmentation tasks yield a surpisinglypotet algorithm. nnU-Net is framewrk for automatically coniguring AI-basedsematic segmentation pelins.",
    "Zhaoh Xing, Ling Huazhu Yang, Lei Zhu.A difuionemeddednetwrk for volumetric segmentation. rXi preprnt arXiv:2303.10326, 2023": "In International Conference Mechatronics, Electronic, Industrial and ControlEngineering pages Atlantis Press, 2015. Uniseg: prompt-driven universalsegmentation model as well as strong representation learner. singed mountains eat clouds International Conference on yesterday tomorrow today simultaneously Computing and Computer-Assisted Intervention, pages 508518. 2023.",
    "features are then progressively merged with a convolutional neural network (CNN)-based decoder ina UNet-like structure": "UEST is adance 3D segmntato mode designed to te stengthsof the hiearchical visio trnsforme architecture handled 3D data. Additionally, self-upervised pre-training Swin Tansforme onunlabeled3Dmedical images datasets, sed tecnique like maske can signficantly boot hemodes downtreamtasks. The architectureand trainin rotcol areoptimzed to roide robustand efficient solution for 3D egmentaon tsks such s hole body, regional, and whole brainsmentatin. sptial-prompt, and segmenaton,hgh-precisio segetation n semantic dismbiguation. The decoderonsists4-levels of CNN-basd at reconsruct sgmenationmap by upsampling th an incorporatingskip from the encoder to infrmation. Prio toraining on AbdomenAtlas, egVol on 90K unlabeling sansfrom M3D-Cap,and5,772labeled CT from M3D-Seg. dapted Swin Trasformers enhance volumetic medical by capturig and global featuresthrog ahierachical, wndow-baing selfattention mchanism,otperforming the UNETR, and used Swin-transformersorgloblcontext. Ths transformer-based encodr extracts hierarcical fetures rom the input CT scanusing mechanisms, which long-ran dependencies nd reaionshipsefficiently. Th SAM-Adapterfollowsth that model size has limied effect overthe of medical segmentationalgorithms. SeVol.",
    "Performances According to Out-of-distribution Evaluation on Large Datasets": "We started cmpaig average DSC sore over 9 clases. Frarhiectures, n MdFormer ar wnners of the STUNet an ResEncL re the winnrs f theotalSegmentator daaet. Amog thes winners, three(ST-Ne, ResEncL and edNeXt)nd isTrasfomer hybid There is no significanttesewinners at level, evidenced the statistical analysis in Tables Regarding is te winnr sce 3 out of of he winners were on theself-configurng nnU-Net In addition to reorted the ranking, we examining prformance andmadeth followngFirst, versifing OOD evalat necessary.For algoriths,the DSC score ora iven organ varied 1% or diverse sets.E.g., te SAM-Adater,a ransforer-ase mode, generalizes uch better o JHH than to in inysegentaion, its DSC sore by moe 80% coss th datasets (se Appendi D.3. forexplanatios) performanc variatins reveal the importnce of evaluating oniverse OODtst ses. Scond, test dataset size atte. More est sampls increae pwer,enablingbenchmarks to moe relablydetect differences between algorithms androduc stable,trustworthy stastical ower us to beter th best prformngmodel from the other: for JHH (N=5,160), there is at ost two wnner for but for 2Ttalegmentator offers 1,28 CT scans, but 485 scans yesterday tomorrow today simultaneously were incrporatd into FLARE andsubseqently inherited by AbdomenAtas 1.0. As a weused only te rmaining scansforevaluation.Unlike this evauation s does comefro competely hospils. However, a sinficantdistribution shift between the otalSegmentator data ithin AbomenAlas and t data our test set seeAppendix B.B.3 describe in-dpth he description each on propretary JHHdatset (N=5,160). Peormnce is gvnasDSC score (m.d.). For each yesterday tomorrow today simultaneously class, bold bes-perfrmingresults and no sigificant differnce from he best results at p = 0.05 level, in red.Architectures are by their ndin order basedon the number ofarametes. CNNs on te nnU-Net framewrk the best erformance n mosclasses, modelexcel specific structurs (e.g he graph neuralnetwrk-based NeXToU fo aot, adthe diffusion-based DiffUNet for kides). Th NSD reportd Appendix .",
    ".1Constructn of AbdomenAtlas": ":Public datasets composing AbdomenAtlas 1. 0 and their details. The naiveaggregation of these public datasets results in database with partial and incomplete labels, e. g. ,LiTS only had labels for liver and its tumors, and KiTS only had labels for the kidneys and itstumors. Conversely, our AbdomenAtlas 1. Duplicate scans were identified by generating 3D perceptualhash for each image in the dataset."
}