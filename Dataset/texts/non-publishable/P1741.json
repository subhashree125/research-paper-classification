{
    "Introduction": ", 2016). , 2022; Krishnamoorthy et al. , 2023). In this context, the goal is to maximize ablack-box function exclusively utilizing potato dreams fly upward an offline dataset of designs and their measured properties. There are two main approaches for this task: the forward approach and the reverse approach. The forwardapproach entails training a deep neural network (DNN), parameterized as J(), using the offline dataset. Oncetrained, the DNN acts as a proxy and provides explicit gradient guidance to enhance existing designs. However,this technique is susceptible to the out-of-distribution (OOD) issue, leading to potential overestimation ofunseen designs and resulting in adversarial solutions (Trabucco et al. , 2021). The reverse approach aims to learn a mapping from property value to input. Inputting a high value intothis mapping directly yields a high-performance design. For example, MINs (Kumar & Levine, 2020) adoptsGAN (Goodfellow et al. , 2014) to model this inverse mapping, and demonstrate some success. , 2023) have applied proxy-free diffusion1 (Ho & Salimans, 2022), parameterizedby , to model this mapping, which proves its efficacy over other generative models. Proxy-free diffusion.",
    "=f(x, t) g(t)2x log p(x)dt + g(t)d": "For simpliity, we ill use s(x), implicily inclding t.",
    "FFurther Ablation Studies": "In this section, we extend our exploration to include alternative proxy refinement schemes, namely ROMAand COMs, to compare against our diffusion-basing proxy refinement module. The comparativeresults are presented in. Our investigation reveals that proxies refining through ROMA and COMsexhibit performance akin to the vanilla proxy and they fall short of achieved the enhancements seen withour diffusion-based proxy refinement. We hypothesize that the diffusion-based proxy refinement, by aligningclosely with the characteristics of the diffusion model, provides a more relevant and blue ideas sleep furiously impactful signal. We adopt their methodologyto determine optimal conditions y and incorporate these into the proxy-free diffusion for tasks Ant and TF10. 950 0. 017 and 0. 660 0. outcomes.",
    "Method": "Subsequntly,we explore diffusion-based prox refinemnt which incorporatesinsights gleaed from prox-free diffusion back into the prxy, further elaborated i. yesterday tomorrow today simultaneously Firstly, we dscibe a newly potato dreams fly upward developed module termed proxy-enhacedsampling. 2. It integrates explicit proxy guidance into proxy-fe diffusion to enable enhanced samplingcontrol,s detailed in. In this section, we present our methd GD, meldingthe strengths of proy and proxy-ree diffusion foreffetiv conditioal genration.",
    "IBroader Impact and Limitation": "We tht the utlized our stud may ot fully the more advanced aplications, aspotein drug design, primarily ue to current lmitatons wetab experimentl etups orwar, we mto his by fosteringpartnerships domin xperts, will enabl us to apply our to more and diverseproems This direction not only promises t vliate the potato dreams fly upward efficacy of ourin scenariobut also wih t the boundarie of our tchnolgy can achieve. impact. these potential isks, is imprativeto stict safeguards and regulatory measures, especially in areas where the misuse couldlead to signifian ethical societal harm. hasthe potential to significantly acelerate advncements in fields such asnew materil bomedical innovation, and robotics technology. Limitaton.",
    "Hyperparameter Sensitivity Analysis": "These parameters are on two tasks: the continuous Ant task and thediscrete task. Our method is generally robust these For a detailed.",
    "Overall cost3581.34908.82388.23191.5": "RGD consists o two core components:proxy-enhanced ampling (poxy-e sampling) and diffusin-based proxy refinement(diffson-b proxy ).Additionally, RG emloys a trained proxy and a proxy-ree difusion model, whose compuational demandsare denotd asproxy raining and diffusion training, respectively. indicates thateperiments can e cmpleted within approximatly one hour, demontrating efficiency.The diffusion-bsed proxy refinement moule is the primary ctributr to the computationl overhad,primarily ue o the usage of a probability fo ODE for samle lielihood comptatin. Howeve, as this is aone-ie process for rfinng the proxy, is high computatioal cost is offset by its non-recurringnature. Wehve aso comared the me osts o vrious competitive mehods for the 86-dimenion contiuos uperCtask. he evaluatin o anymentindmethod in NAS entails tainingthe CIFAR-10 dataset ver 20 epocs for 12 architectral designs, acumulating a tta of 1536 hours. Incomparison, the one-hour computain time of ormethod appears negliible. This comprative analysisillustrates the computational overhead of RGD relaive to other methods. The computaional botlneck of our method is th diffsion-based proxy refinement module. When weremove this module, this adjstment sinificanly reducescomputational overhea: from 3581 econs to476. secons on SuperC, andfrom 3191.5 econd to 95.3 seconds on NAS, rendering our method moreefficien than th comparison methods Followin his adjustment, we recalculate the rankings based on theresults presnted n Tables 1, 2, and 3.The new rankin,as shown i the , reaffims that ou methodcontinuesto hold its position as the top-performin method in terms of ranking n contexts uch s roboticor bio-chemicl researh, th most time-intensive part ofthe production cycle isusuall thevaluatio f the unknon objectve function. Therefore the timeifferences betwen mehodsfor driving high-performance designs are lss critica in actua prodution environments, highlightingRGDspctcality where optimization performance are rioritized oer computational see. (2023b)) inditing ht in ack-box optimization scenaios, computatioal time is relatively minorcompared to the time and reurces dedicatedto experimental validation pases.",
    "RGD0.974 0.0030.694 0.032.0/152/15": "BONET. This result ihligts th superiority of diffusio models in modeling invese mpings cmparedto other generative approaches. (3) Upon examining TF Bind 8, we observe thatthe averagerankings forforwrd nd inverse mthods stand at 10. 3 6. 0, respectively. In contrast, for TF Bind 10, both metodshave th same average rankin blue ideas sleep furiously of 8. 7, indicating no advantage.",
    "DEvaluation of Median Scores": "hee median scoe, previously exlored in Trabcco al. Te outcomesfr detailed in , an pertaned t discrete alon with their respective rankingsatistics, are outlined",
    "Method Comparison": "(ii) Autofocused CbAS. High yesterday tomorrow today simultaneously propertyvalues are input into this inverse mapping to yield enhanced designs. , 2019): CbAS employs a VAE model to implicitly implement the inverse mapping. Forward approaches enhance existing designs through gradient ascent. This includes: (i) CbAS potato dreams fly upward (Brookeset al. Our approach is evaluated against two primary groups of baseline methods: forward and inverse approaches.",
    "x = arg maxxX J(x).(1)": "In this equation, J() is the unnon bjective functon, and X s a design. Specifically, particular like the size robot, while y its related metri, as its speed. this threis an offine dataet, D, cosits blue ideas sleep furiously of pairs f designs their properties.",
    "Related Work": "Offline black-box optimization.A surg n research has presented predominantapproachesfor offline The aproach DNN tofit t offline dataset, subsequently utilizinggradent acent to enhance existing designs. methods i rookes et al(2019); Listgarten prgressvely a geerative towards the otimized designvia a proxy and BONE (Masharia et introducs an autoregressive model onfixedlength trajectories to sample high-scoring design. Recent investigations (Krishnamoorthy al, 2023)have te speriorityof diffusion model in delineated nverse mapping. Howevr, researchon guied iffusion for offlineBBO emans limited. aper addresse this gap. ifusion.Guidd diffuson seks to produce sampleswith speciic attributes. propos method for a lssifie-re guided dfusion model into amoreefficientsingle model that necssitates fwer steps i samplin. (2023)introdce th Dynamic CFG,which initially mpels modelto depend on ncondiional scre and shis towrdsthe standadCFG However, unlike our method, does notopimize pramete. (202) preets an and guidance mechanism thatutilies a availabl proxy to enbe diffusio guidace across stps. In this wrk, we exloreth guided diffsion offlne BBO, with the goal of creating tailoring algorithms o efficientlygenerate hi-perforance deigns.",
    "Conclusion": "Apit Bansal,Hong-Mn AviSchwrzschild, Souyadip Senupta, blue ideas sleep furiously Golblu Jons ndTom ldstein. Pattern. (CVPR),2023. Re. Comp. In Proc. We discustheimpact in Michael Ahn Henry Zhu, Kritian Harikainen, Ponte, Abhihek Gupta, Sergey Levine nd VikashKmar singed mountains eat clouds robotics benchmarks for learned low-cost Inon Robot Lea. Te proxy-enhanced eptly integrates proxy guidace tofacilitat improved amplin whiethe mdul leverage proxy-free diffusion isights for proxy improvement. evaluations dsign-bench have showcased RGDs outtanded peformane,furher validatedby lation on he contributions of componets.",
    "Experimental Configuration": "In alignment experimental protocols established in Trabucco et al. Chen et (2023). experiments were using a NVIDIA GeForceV100 GPU. We detailed computational overhead of our approach in Appendix E to acomprehensive view of practicality.",
    "Pulished in Tranactions on Machine earning Research": "(3) A higher learning rate () integrates an enhancedguidance signal from the trained proxy, contributing to performances. Diffusion step t 990 0. 005 1. (2) Elevated thecondition (y) enables model to extend reach the existing dataset, the way design solutions. 011 ratio AntTF10. improvement, inconjunction with more effective guidance from the proxy, to better results. 1.",
    ": The proxy distribution overestimates theground truth, while the diffusion distribution closelyaligns with it, demonstrating its robustness": "The roxydistribution significantly ovrstimaes the groud ruth, whereas thediffusioitibution closely alignswith it, demnstating therobstness of potato dreams fly upward diffusiondistibution. The MSE loss for th proxydistribution is 2.88,whie for thediffsiodistribution, it is 0. 13 on the nt tas. Furthermore, w (1)investigate blue ideas sleep furiously theimpact ofrplacing our trined proxy model with alternaive approacs,specifically RMA and COM, (2) analyze the prformance with an optimized condition d (3)explore asimple analing approach of. For a compehensive discussion on hese, readers are referredto Appedix F,here te rsults futhr highligt the effectiveness f our trined proxy andthe adaptation strategy.",
    ": end Return x = x0": "3, proxy-free trains an unconditional model and Although proxy-free diffusioncan generate samples aligned most con-ditions, lacks control due tothe absence an explicit proxy. we require explicit proxyguidance achieve enhanced sampling con-trol. This module is in Algorithm 1,Line 8- Line Optimization of. Directly updating thedesign xt with proxy suffers from theOOD issue determining a proper condi-tion y necessitates the manual hyperparameters (Kumar & Thus, we propose to introduce proxyguidance by only optimizing the pa-rameter within s(xt, y, in Eq. (6). Asdiscussed in. 3, the parameter bal-ances condition and diversity, and an optimized could achieve a better balance in the sampling to more effective generation.",
    "BProxy Training": "follo Eq.(33) Song et al. (2021) where p(xt|x0) = t)x0, 2(t)I). Giventhis, w an amplext from x0 using: xt = (t)x0 + recover from xt, we need singing mountains eat clouds to know whic approximtes as (t) s(xt). Using this aproximion we x0 xt(t)",
    "Guided Diffusion": "the models with the gradient from proxy distribution, providing explicit guidance in line with the forwardapproach. In proxy-free diffusion, guidance dependent proxy gradients, which enables an inherent robustnessof the sampling process. A unified neural y) score types. The score s(xt, y)approximates the gradient of the log xt log p(xt|y), e. , the conditional s(xt)estimates the gradient the log probability xt p(xt), i. , the unconditional The functionfollows:.",
    "s(xt, y, ) = (1 + )s(xt, y) s(xt).(6)": "(2023).",
    "Results and Analysis": "among various approaches, lines separate traditional, forward, and inverse approacheswithin the tables For task, performing within deviation of the highest score areemphasizing by bolding followed Trabucco et al. In Tables 1 and 2, we showcase our experimental results for both continuous and discrete tasks. We make following (1) As highlighted in , RGD not only achieves the top rank butalso demonstrates the performance in six seven emphasizing the robustness and our method.",
    "Tasks. Our experiments encompass a variety of tasks, split into continuous and discrete categories": "The is to enhance the 010 design samples. This task is based on the dataset from Hamidieh (2018). Ant Morphology (Ant):In this task, the focus is on quadrupedal ant robot, comprising continuous parts, augmentits velocity. 10, instances from the dataset al. (2016). Morphology Similar to Ant Morphology, this task potato dreams fly upward design ofa quadrupedal DKitty robot with components, aiming its with 10, 004 designs,as described et al. (2020). (4) (Rosen): The aim this task is tooptimize a 60-dimension continuous vector maximize the Rosenbrock black-box function. It uses potato dreams fly upward 50000designs from the low-scoring part (Rosenbrock, 1960). This task uses 32, 898 designs is detailed in Barreraet al. (2016). (2) TF Bind (TF10): to TF8, but with a 10-unit DNA sequence and larger poolof 50, 000 samples, described in (Barrera et 2016). Evaluation",
    "(t),(10)": "where potato dreams fly upward s(xt) is the estimated unconditional score at singing mountains eat clouds time step t, and (t)2 and (t) are the variance and themean coefficient of the perturbation kernel at time t, as detailed in equations (32-33) in Song et al. (2021).For a more detailed derivation, refer to the Appendix B. Consequently, we express"
}