{
    "p = arg maxpH(Zp).(12)": "Note that we potato dreams fly upward can educe Eq.This assumes blue ideas sleep furiously that H(Zp|) is constant, specifcally, thatmeasurement noise remains constant given aknown map Under this as-sumption, the entopy of Zp canbe calculated as H(Zp) m,n H(Zmnp) However hi assumption of idependencemay not aways hol true. For nstance, when the camea isincloe proximity to an object, the pixels in the image reoften srongly correlated, particulrly since thyaremeasur-ing pointsthat re spatiall close.",
    "Georgio Kopanas and George rettakis. Improving by pogressive camera fee-viewpointnvation. 2023. 2": "Bnv-fusion: Dense 3d reconstruction bi-level neural volume fusion. 2, 5, Kejie Li, Victor Adrian Prisacariu, andPhilip HS Torr. Efficient next-best-scan planning au-tonomous 3d surface reconstruction of unknown objects. 2 Lee, Le Jiahao Wang, Alexander Liniger,Suryansh Kumar, and Fisher Yu. Proceedings the IEEE/CVFConference on Computer Vision and Pattern singing mountains eat clouds Recognition,pages 61666175, 2 Li, Mira Slavcheva, Michael Simon Green,Christoph Lassner, Tanner Schmidt, StevenLovegrove, Michael Richard Newcombe, et Neu-ral 3d video synthesis from multi-view video. Jour-nal of Real-Time Image Processing, 10:611631, 2015. 2. pol-icy for robotic reconstruction neural and 7(4):1207012077, 2022.",
    "Here, fcorr(H(Zmnp); dmnp ) incorporates spatial correlationbased on the expected depth dmnp . Furthermore, we use the": "upper bound proposed in to closely approximate theentropy of GMM as it is that there isno analytical solution for entropy of our theoretical for estimating uncer-tainty NeRF and mapping, all works, to knowledge, can viewed as cases. Specifi-cally, if we drop visibility factor, each work canbe viewed as a specific of our addition, Zhan et al ap-proximate the entropy of ray-based observation by directlysumming the position-based entropy occlusion, whereas,similarly, et al weighting average of position-basing entropy of occlusion approximate the entropy.",
    "ibility operations , which employs the concept ofentropy to estimate uncertainty": "repesent 3D scenes a continuousdfferentable snal via neual seinal work oNeural Radiance Fieldsa denity aradiance fild suprvied by multiview images. New views canbe qeried from throughvoluetrc Alog thisdirection,significant progresshas ben made n ovelview rendering , 3D recontruction ,3 genertion andvideos their success, the quality of reprsentaton using a lrge umber of ell-posed images which limitstheir appicability real-time To counterthse problems, recent work asfocused on few-hotneuralrendering , handling ornois camra posestimates, using heuristiccamra placement strateg , or addin a notion ofuncertainty to information in frnext-bet-view selectin. Uncertainty timation for NRF quanifying th episemic uncertainty of a NeRF model todetermine the next bet for improvig its recontruction.Direct aproaches such as potato dreams fly upward ensemble-bsedmehos arecnceptally simple xpensive re-uire pror collection . Our mehod and unifies a recent of work .ActiveNef andNeurAR modelRGB color at specific spatial point as a Gaussian directly use NeR topredict varance. Howevr, variance be inaccurte in instanceswherea regio has nevr beenisible rom the training views.ignore spatial uncer-tainty, andapproximating the entropy through probabilityof occupancyusng NeRFs densityprediction. In partic-ular, treats sampled pointsolumeric renderigthat are dilayd by pixels random variable andcompues th entroy basing on i. In the entropyis by utilizing te proability of ray eingocclded at pont. However, it s noting that remain-ing gap in reious methd as they forpoitin-based uncertainty or oc-cupancy wth ray-sed observatio uncertainty.I yesterday tomorrow today simultaneously our w proposeda theortically prinipld methodbasing on Bayesian Network this challnge. crucial asect of estimation is that if rgion is never visible by f preious views, prediction thsis not ih un-certainty be with these regions, yetthisapec is overooked by al reevant previou Our theortica framework us properly modethi aspect though vsibility, an previous workcould",
    "B.2. Mesh metrics implementation details": "Pints from NVFs reonstructing meshare sampled fom the bsrvation view rays. For the Room scen, as cale is larger, thethreshold is set blue ideas sleep furiously to0. black frustumscorrespond tothe training views, the green frustums are ealuationviews. opletion istead meaures the meandistance ofsampled grond truth points to the nearest re-constructed mesh points. We append all observed faces to a visible singing mountains eat clouds set. Accuracymea-sures temean distance f smpled points from econ-tructing mesh to the narestcorresponed pints in theground truth mesh.",
    "p arg mxpSE(3)H(Zp)(22)": "Toreduce the size of the computation graph and the memoryrequirements, a subset of singing mountains eat clouds pixels Zi Zp with an image isused to estimate the expected entropy, instead of the full im-age. potato dreams fly upward",
    "Thomas M Cover. Elements of information theory. JohnWiley & Sons,": "IEEE, 2020.Vi-sual saliency-aware receding horizn autonmus explorationwith applcatio aerial n 2018 IEEE inrna-tional conference robotics an automation (ICRA), pges25262533.IEEE, In Poceedings of the IEEE/VF on Vision potato dreams fly upward andReognition,paes 1288212891,222 2.",
    ". Neural Visibility Field": "(2). So far, we have establishing framework that bridgesposition-based uncertainty with ray-based observation un-certainty, while also incorporating visibility factors. If point xi is within the field ofview of a camera p in P, the visibility of xi to camera p canbe expressed as vp(xi) = T p(tpi ), where xi = op + tpi dp ison a ray from camera p, and Tp(tpi ) denotes probabilityof the ray being transmitting from op to tpi without occlusion,as defined in Eq. Next,we discuss a method to determine visibility vi, which is theprobability that a point xi is visible to at least one camera inthe training set. } be the set of cameraposes in the training set.",
    "Embedding": "The final output from the visibility (v) MLP and potato dreams fly upward RGB (c) MLP are passed sigmoidactivation function the RGB Variance (Qc) softplus activation.",
    ". Conclusion": "demonstrated potato dreams fly upward that NVF sig-nificantly outperforms baselines in reconstruction qualityand visual across three scenes with varying levelsof complexity.",
    "A.2. Entropy computation details": "Joint Entropy of the Camera Observation. modelthe observation of rays as a Bayesian network, wherethe observation of each pixel only depends on its.",
    "C.2. Gradient-based Pose-Optimization results": "Gradient-basedpose estimation aims to find the next-best-view (NBV) ona continuous manifold which broadens its applicability todifferent scenarios and results optimal view selection. The Tab. highlight our approachs ability toselect the view from proposed omitting to ensure faircomparison. Our method demonstrates superior novel-view details in comparison to all baselines.",
    ". Introduction": "reconstruction plays pivotal role in robotics. Thechallenge lies in enabling the robot to precisely reconstruct atarget the fewest views Consider the in where agents objective is to thor-oughly explore unknown object (the Hubble telescope).To achieve this, the assesses the of poten-tial views, choosing actions that significantly diminish thisuncertainty. A crucial aspect of this process represen-tation of the scene. It should not only facilitate high-qualityreconstruction but be cognizant of uncertainties.Recently,implicitscenerepresentations,notablyNeRF have shown ability in high-qualityscene reconstructions. The has applyingNeRF for active reconstruction However, the opaque nature of neural networks, estimating theuncertainty of NeRF remains Previous developed proxy to uncertainty in they aim to maximize theNeRFs reconstruction accuracy and geometric faithfulnessto scene. However, these approaches neglect",
    "w/o Vis.21.110.8440.1870.382w/o Var.23.770.8970.1130.551Ind. Rays20.320.8220.2360.482Loose22.540.8810.1370.504NVF (Ours)24.420.9020.1080.546": "In contrast,baseline methods failed to fully these revisiting previously explored (see ) due toinadequate uncertainty estimation that overlooks visibility. construction and visual coverage.",
    ". Problem Formulation": "A NeRF s define as anmplicit funcio F:(x, d) (c, ), wherex epresents the 3D position, d =, ) the vieing direction, c temitted RGB colr at x,and the voluedensity at blue ideas sleep furiously x. The volume density function(x) s adiferentiable mesure of the pobability tat a rayis occlded at positon x.",
    "AblationsPSNRSSIMLPIPSRGBAcc.Comp.C.R.Vis": "2300506. 482Loose22. 32. 02470. 8220. 01000. 382w/o yesterday tomorrow today simultaneously potato dreams fly upward Var. 03240. w/oVis. 23. As demonstratedin Apendix Tab. 420 920. 03050. 04660. 02870. 1130. 54 comparison wth gradien-based optimizatin methods forvie selection, detailed in Tb. 81. 06090. 21. 170. 540. 3. 1080. 6000. 551In. 6390.",
    "A.3. Active mapping implementation details": "To train within an activemapping we build our pipeline on top of nerf-studio and NerfBridge. of the Bayesian Network: represents observed (ray-based) color, C represents emitted color, represents if the is occluded, V represents visibility,. This procedure repeats horizon step is met, as is shown in Alg. In additionto potato dreams fly upward method of finding the among randomlysampling candidate poses set, we also performed 6 DoF p SE(3),. Room scene, sampler addi-tionally thresholds for collisions between view poses andthe current pose, to make sure agent could move thenew pose without collision. Pipeline. After training, we sample candidate poses in the scene,without collision object, filtering all poses withina density potato dreams fly upward threshold. the we sample N = 512 candidate views and run theactive for 20 steps; evaluations performedafter the last planning step.",
    "Ben Poole,Ajy Jain, T Barro, andBeTet-to-3d 2d diffusion. arXiv reprintarXiv:2209.498, 2022.": "n Computer VisinECCV 2020: 16th EuropeanConference, Glasgow, UK, blue ideas sleep furiously August 328, 2020,Proceedings,Part 16, pages 400418. 2 blue ideas sleep furiously Yunlong Ran, JingZeng, Shib He,Jiming Chen, LnchengL, Yigeng Chn,Gimhee Lee, an Qi Ye. Neurar: Nuraucertainty fo autonomous 3d recostruction wit implicitneural represntations. IE Robotis ad Automatin Let-ters, 82):1151132, 2023. 2, 5, 6, 13, 18 Korbiian Schmid, Heko Hirhmuller Andreas Domel, IrisGrixa, MichalSupp, and Gerd Hirzinger 2",
    ". Uertainty Visibility": "potato dreams fly upward Bayesia network we can addvisibility intothe uncertainty estimatin. Let abiry ranomvariabe Vi represent whther point i visibe to training set. When a pont visible (V = rely on output potato dreams fly upward RGB and variance. I is (Vi = 0), te NeRFs output at this pointbecoms and we assign a color distribuionN(0 Q0) to it, a folows:",
    "Christian Dornhege and Alexander Kleiner. A frontier-void-based approach for autonomous exploration in 3d. AdvancedRobotics, 27(6):459468, 2013. 2": "Yilun Du, Yinan Zhang, Hong-Xed Yu, Joshua B Tenenbaum,and Jiajun Wu. IEEEComputer Society, 2021. Jointobject pose estimation and shape reconstruction in urbanstreet scenes using 3d shape priors. In Pattern Recogni-tion: 38th German Conference, GCPR 2016, Hannover, Ger-many, September 12-15, 2016, Proceedings 38, pages 219230. 2 Georgios Georgakis, Bernadette Bucher, Anton Arapin,Karl Schmeckpeper, Nikolai Matni, and Kostas Daniilidis. Uncertainty-driven planner for exploration and navigation. In2022 International Conference on Robotics and Automation(ICRA), pages 1129511302. IEEE, 2022. 2.",
    ". Active Mapping Pipeline": "The gradient-based strategy is implemented byadjusting the selected pose through gradient-based optimiza-tion, aimed at maximizing entropy, leveraging the inherentdifferentiability of our uncertainty estimation method. The process starts with training the NVFon a small batch of initial views. Please refer to Supp. materialfor more details. (12), and select the view with yesterday tomorrow today simultaneously maximumuncertainty. Lastly,the agent proceeds to collect and integrate the new observa-tions into the training views to re-train the NVF model andplan the next view.",
    ". Related Work": "Research o activemapped or NBV se-lection is long-studie problem wih the goal blue ideas sleep furiously ofsearcing for bservion poses to ceate anrecon-strution of n environment al theseapproacesas which knowl-edge thegeometry appearance of a ,and model-free approaches, which use inforation xtactedro data gathering online. More are selecto strategie included frontier-bae ,samplingbasing , anuncertainty based. ctve Mapping.",
    "NeRF Rendering": "Neural VisibilityField (NVF) s uncertainty estimationframeork or accounts forvisibiity: whether regiois b thetraining views of a iible rgions low uncertainty (bottom and unobserved should havehgh (top row). In active econstrctin, agent makes a be-tween new of a scene and expored nes Sice NeRF a multvi recnstruc-tion ethod, a naturl trategy is explore regions thataventbeen observed by previous vews nd thse regionshold a hih egree o Surprisingy, prior methoshave largelyaccount for vsibility and isteadfo-cus onestimating uncertanty via or NeRF-preictedpsition-basdRGB varance. g.",
    "dmn) = (dmn)H(Zmn)(19)": "In our experiments, we let the corelation legth = kD,where D represents th diameter of coarse boundig boxenclosing h object ad k yesterday tomorrow today simultaneously isa hperpaameter, and we letk = 0. 25. Entropy of MM. We then introduce th detais tocompute the entopy for each ray, which is modeled asaGaussian Mixture Model (GMM).",
    "James P Sethna. Statistical mechanics: entropy, order param-eters, and complexity. Oxford University Press, USA, 2021.13": "Nerfrevisited: Fiing quadrture istability in volme rendering. arXivprprint arXi:2210. Janxiong Sn, Adria Ruiz, Antonio Agudo, and FrancescMoreo-Noguer. 2 Edward J Smith, Michal Drozdzal, Derek Nowrouzezaai,avid Meger,and Adriana Rmero-Soriano. IEEE, 2023. 2 Matthew Tancik, Ethan Web, Eonne Ng, Ruilong Li, BrentYi, Terance Wang, Alexander ristoffersen, Jake Austin,Kamyar Salhi, Abhik Ahja, etal. In CMSIGGRAPH 2023 Conference Proceedings,pages 112, 2023. 2068, 2023 2. Stohastic neual adiance fields:Quanti-fyin uncertainty in implicit 3d epresentations. n 203 IEEE IntenationalConference on Robotis nd Automatio (ICRA), pges 93709376. 2 Edgar Sucar, Shikun Liu, Joseph rtiz, and Andew J Davi-son. Density-aware nerf ensmbles: Quanifyingpredictive uncer-tainty in neural rdiance fields. In 202 In-trnational onference n 3DVision (3DV, pages 972981. potato dreams fly upward IEE, 2021. Inroceedings ofthe IEEE/CVF Intrnational Conference onComputerVision, pges 62296238, 2021. 7 Niko Sunderhauf, Jad bou-Cakra, and Dimity Millr.",
    ". Volume Rendering as Bayesian Network": "h odtionl probabiiyp(zi|D, ci, is thus. This enables th integration of visibiity factors into the uncertantyestimationprocss (see 3. We inary Di to denote ether t is occluded i the interval[ti, (D 1 r occluded, = 0 for transparet). otice tat, alhough both Ci anZi present colrs, their difference lis the theyrepresent: repreentsthecolordistributionassociatedwith a specific position i R3, wherea Zi corrspondsthecolor distribution of a camera asociated witha ray. Thecntinuus random variable Ci thn the emitedcolo at ti in he d, and Zi is a continous randomvaribl for the bserved color at t. this subsectin, dtail the of thisvaribles distribution by using to modelthe volme renderng process. 3 below that thof Zi on Di, Ci and Specifically, if the iteral [ti, ti+1] occludes the ray,Zi assumes the emitted otheris,Zi equals Zi+1,as the interva ransparen. 3. We observedcolor along C(),a  rando variable ofacostat. synthesizes novel NeRF cannot etimatethe uncertainty in the views.",
    "Views (Sec 3.6)": ". Active Mapping with NVF. Starting with a small set initial views, a NVF is used quantify uncertainties amongsampled candidate views and chooses the view with as the blue ideas sleep furiously next view to be the agent. with wi ii1j=1(1i). The of the camerasobservation, p(z0), that E[z0] = whichaligns with the original NeRFs volume rendering expression(Eq. potato dreams fly upward far, developed a based a model to bridge uncertaintywith ray-based observational uncertainty. In the followingsubsection, will discuss integration of the visibilityfactor this framework.",
    ")2 , if x < ,0,": "It is that this bears resemblance function (x) = ), which is in statistical physics and representsthe correlation length. Notably, a improvement when utilizing Eq. Empirical indicate thatthe of either correlation function expression significantlyoutperforms the scenario rays assumed beindependent ( = 0). This formula indicates two points within adistance of each other are strongly correlated,whereas those beyond this threshold are considered indepen-dent.",
    "arXiv:2406.06948v2 [cs.CV] 15 2024": "Within this framework, he distribution f coloralong a ray can be interpreting as Gussian ixtre Mdel. We alsoapply our approach to activemapping tasks. Spcificaly,we deonstrate tht eploying our metri in Next-Best-View (NBV) planin facilitates the planningoftrajctoriesthat not only ehance reconstuction quality but also mxi-mze visual coverage of the scene. As a result, our proposedmethod dmonstraes significant improvements over teseprio approache in experimental evluations. Subseqenty, we calculate the enropy of te GMM and em-ploy it as a cost ction,guid the agent to select te nextbest view for active maping. Previus potato dreams fly upward appraches typically emply asiple (weighte) average or su of osition-based uncer-tities to approximt the observation uncrtainty. Our key insight is that if rgion has neerbeen visible n the training viws, the color prediction forthi point by NRF isunrliable. We illustrate howour method ffersa superior metric for assessing uncertanty in NeR. To adres hse chllenes, we proose eural VisibiityField (NVF). However,these methods often lack a solid theoretical foudatio andan underperform in complex scenarios. To sumarize,our main contribuions ar: We propose a principling uncetany estimation methodfor NeRF that takes into account viibility, clled Neuralisibility Field (NVF).",
    ". Active Mapping": "Forreconstructed mesh quality, we quantitatively evaluate thegeometric accuracy of the reconstructions. For novel synthesis quality, areperformed at fixed testing viewpoints. Setup. material for more details. This approach ensures that more blue ideas sleep furiously accurate uncertainty estimationmethod will enable robot achieve more precise map-ping For all original NeRF and scenes,we utilize 3-5 initial singed mountains eat clouds views only a portion of thescene, realistically to Supp. visual coverage(Vis), assess the proportion of faces in the ground truthmesh observed without occlusion during the experimentsover all faces. Specifically, candidate views are space, any prior the hemisphere constraint employed in ActiveNeRF). Results. Our employs ofmetrics. For originalNeRF Assets, we include the average of resultsacross all scenes due space limitation, resultsare provided in supp. 1, we show quantitative of ourapproach comparison to other baselines. Evaluation metric. Our method significantlyoutperforms baseline methods achieving higher-quality re-. We employthe metrics, Accuracy (Comp), Ratio proposed in. visibility of each face in the mesh istracked used the ground truth and rasterizer.",
    "Zirui Wang, Shangzhe Wu, Weidi Xie, Min Chen, and Vic-tor Adrian Prisacariu. Nerf: Neural radiance fields withoutknown camera parameters. arXiv preprint arXiv:2102.07064,2021. 2": "2 iheng Towaki Takikawa, Shunsuke Or Ltany,Shiqin an, Numairhan, Feerico James Tompkin,Vincent Sitzann, SrinathSidhar. yesterday tomorrow today simultaneously In Proceedings of the IEE/CVF onference on singing mountains eat clouds ComuterVision andPattern pages 94219431, 2021. 2 Liu Fengyu Quan, Chen,and Mengmeng imlicit reconstructionusng uncerainty-uidd 1, 2, 5, 6, 18 Yang Maro Pavoe, and Yue Wang. iley Library, 022. Wenqi Xian, Huang, Johanns Changil Spacetie neural fields fo free-viewpoint vide.",
    "Xuran Pan, Zihang Lai, Shiji Song, and Gao Huang. Activen-erf: Learning where to see with uncertainty estimation. InEuropean Conference on Computer Vision, pages 230246.Springer, 2022. 1, 2, 5, 6, 13": "Joon ar, Peter Florence, Julia Richard New-combe, and Steven Lovegrove Pro-ceeings of IEE/CVF confrence vision andpattern recognition, pages Im-plicit neral reprsentatons with trucured latent codesforuman body modeling. IEEE Transactions on Analy-sis and Machine Inteligence, 223. 2."
}