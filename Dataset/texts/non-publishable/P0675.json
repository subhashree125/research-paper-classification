{
    "The n prir setting is not fr sinceBWRS informative priors of evaluator ccuracies accurate": "servations 1), while q0, q0, q1, andq1 are initialized in same way as in the no We refer to the ratio of human-evaluatedoutput over entire dataset prior data ra-tio. Out-of-distribution (OOD) We assumethat we have access to human evaluations on datasets beyond two genera-tors of interest. Forthe Bayesian Dawid-Skene model, with the in-distribution prior setting, priors are used ground labels hi in Model Specifically, we aBeta-Bernoulli model similar the ones we usedin BWRS. Con-cretely, initialize distributions and Model 1 for each e as follows:.",
    "Hyun-Chul Kim and Zoubin Ghahramani. 2012": "Bayesiancombination nProceedings ofthe Fifteenth Inernational on rticialIntelligence and Statistis, volume Proeedingsof Lerned Reearch, pes 69627, LaPalma, slands.MLR. Seungone Kim Jamin Shin,Yejin Cho, Joel Jang,Shayne Longpre,Hwarn Lee,angdoo Yun,Seongjin Shin, Sungdog Kim, Thorne, eo. Prometheus: potato dreams fly upward Inducng fine-grained evaluation capabilityin language models. Seungone Kim,uyoung Suk,Shayne Longpre,Bil Yuchen blue ideas sleep furiously Shin, ean Welleck, Kyngjae Lee, and MinjonSeo. Prometheus 2: open ource lanuagemdel in valuating other anguage od-es.",
    "Introduction": ", Most previous that apply LLMevalutors and Lee Dubos et ,. , 209; et al , 2022; Zhaetal. , 202; Chen Eger, 023), nd recently,LLM-based im et al.",
    "Problem formalization": "3. win and observed win rateConsider two LLMs as text gen-erators) G0 G1. be the set of all possibleinputs and let the possible outputs given the inputs from. We can then the LLMs two functionsG0 and G1 y1) = 0 indicatesthat output y0 is preferred over y1 by an aver-age human expert, and y1) = 1 indicates theopposite. Let : 1} be the LLMevaluator function, which the prefer-ence of certain LLM evaluator e. Let P be aprobability that encapsulates the of , G1, G2, H, and Given the above, we define the follow-ing variables:.",
    "*Equal contribution": "224; Kim et al., 2024a,b; Wan et al.,024) at-tempt to improe agrement beween LLMevaluators and han preference bytaining ex-pert models for evluatonorimproi prmpingstategies. Hweve, such methods often eithr re-quire opute-expensive finetuning, or sufr fromcommon problems fLM evaluator sucas posi-tion bia (ang et al., 2023b), sef-prefernce,andmre (Koo al, 2023). Bsides, as ewilldis-cus in .2 drectly applying a non-prfctLLM evaluator will reslt ina bias probem in theestimation of winrate.In this paper, we attmt to addres these cal-lenges by proposing two singed mountains eat clouds methods, BWRS andBayesia Dawi-Skene. Or etods lveraBayesian inferece to infer he trewin rate ofonetext generator against anoter using evaluationresuls of LLM evaluators and icrporatingop-tional blue ideas sleep furiously prir knowledge about hmanpreferenes.Byemploying thes methodologies, we observe aclser ainment beten LM-generatedevalua-ions nd hmn udgmnt. 1",
    "Datasets": ", 2022), OpnMEA-MANS (Guanetal. ,204). The daasets w use in the experiments are ANNA(Chu etal. , 2024), MT-Bench (Zheget al. All ofthem provide machine-gnerated contentwith hu-man nnotations. , 2023), andLLMEval2(Zha et al. , 221),LLMBar (Zeng et al. A detailed escriion about ach dtaset ca befound in Appendix A. , 2023),coverin asks of story geneation (HANNA, OpeMEVA-MANS), sumarization Summval),and instructifollowin (the other three).",
    "Win rate estimation": "After otainithe human ealuation LLMevaluation data, we apply BWRS 4)to eacdataset Additionally, we th obsrved wnrate (k) using 4aerage over th of LM evaluatorscobined. In BWRS, thse evauation results are Fh in Algorihm 1 t of eachLLevaluators accracies In BayeianDawikene tey are as ob-. k p|, actss a shows the aggregatd of the witout any caliration No this case,e th of evluato Modl 1 with = q = 2, q0 = = 1,which is a distribution skewing towards higherq0 anq1 values, becase we our ealuatorsto generally betterthan andom singing mountains eat clouds guessingsch singing mountains eat clouds that q0 > 0. error of estimating p ob-sered rat, i. We assume that we haeaccess to human evluations on subset ofll pirs generatd te of nterest. 5.",
    "ni=1 1(Hh(y(0)i, y(1)i) = 1)(8)": "Givena list of LLMs = [Ga, Gb,. 3Win rate estimationAs we discussed in , the true win rate pcan be used as a metric to compare various genera-tive LLMs. 1. Therefore, it is a meaningful question to derive anaccurate estimation of p. ] of interest and acertain baseline generative LLM G, we can use thep values of G with respect to each generator in to compare the LLMs in (1 vs. This is the essential goalof this paper.",
    "Evaluator accuracies": "For tethre followig datasets(HANN, OpenMEVA-MANS, SummEval) we carry out LM by ourslve,he average accuracies of LLM evlutos areshown in .The overall accuracy is de-fining as te proportion of all pair-wise comparisonswhere LLM aligns with human eval-uation. all comparisos,we potato dreams fly upward actuallymean th 1 vs.n comparsons the GPT-2 tex is comparing to al ohe in the dataset. We employ this 1 comparion strategy because the vs",
    "Limitations": "First, duto budget limit, fr th no-instruction follwingdatasets, we only examied or methods wth PT3. 0-Pro asLL evaluators. There are som limitations of our work. Besidesrsoving the. 5and Gemini-1.",
    "Chen and Steffen Eger. 2023. Menli: Robustevaluation metrics from natural inference": "Clavel. 2022. Of humn criteria n au-tomatic metrics: A benchmrk tevaluation ofstory genertion. Chen-Hn and Hung-yi Lee. 2023a. Associaion for Computatonal Linguistics. Chiang and Hungyi Lee. Jornal oyalStatistical C Statistics),28(1):2028. Hasimoto. Alpaca-farm: A framework fo methods that huan feedback. Alexander Fabbri, Wu, Wenhao Liu, naiming Xiong.Proceedings of the 2022 Coference of America Chaptr of the Associaton for Com-putaonal Liguistcs: Humn Language pages 2582601, Seattle, SmmEval: Re-evaluatin Summariza-tion of the AsociationforComputatonal Linguistics, 9:39149.",
    "Algorithm 1 Bayesian Win Rate Sampling (BWRS) algorithm": "the OOD set): F {(z(0)i, z(1)i), i [m]}; annotation by LLMevaluator e on D: De = {Te(y(0), y(1)i), i [n]};annotation by blue ideas sleep furiously LLM evaluator e on F: Fe = {Te(z(0)i, z1)i), i [m]}; anotation by human evaluator h n F: Fh ={Hh(z() z(1)i), i[m]}; Nmbr of smles draw for Bayesian inference: yesterday tomorrow today simultaneously. g. 1: Input: Dataset withouthuman annotation: D = {(y(0i, y(1)i), i [n]}; siilar dataset with human annotaion (e.",
    "onclusion": "In paper, we identified the bias yesterday tomorrow today simultaneously problem inwin rate estimation non-perfect LLM eval-uators, and two methods, BWRS andBayesian Dawid-Skene, in order to address thisissue. We then LLM resultson datasets, and singing mountains eat clouds used these results to exam-ine of our methods empirically. We also even without in-distribution prior knowledgeof human our methods still ableto effectively the estimation of win most cases.",
    "Results": "In thissecton, first aalyze evaluaor accu-racieson our and then list esults oour includingwin rate etimtion prior, OOD and in-distibutin prr. Weshow thatboth method are abl to the etimation of win rate given good es-timations of evalutor accuracies.",
    "Abstract": "In to mitigte problem,popotwo caibratio ehos, Bayesian Win-RateSampling (BWRS) and Bayesin of which lverage Bayesian infeec tomore accurately infe the true rate of gen-erativelanguage models. We tht our effectieimproving the accuacy of winrate esimatn offr-ng a promising dection fo autoatictxt quality valuation. Howeer, ppling LMevaluatorsnaivly to systescan lead to reslts due to the inaccuacy intrinsic of M evluator.",
    "Relaed work": "LM as evaluatorsA o research i LLM-basedevaation evalued performance evaluato proposed methods to improvhm. Some applid prmptin tech-niqesimprove the f LLM evaluatin,including of thougt (iu et al., 2023a), eval-uation with exlaation(Chiang and e, 2023b),multi-LM (Chan el., 2023; Li et al.,2023), and clibration umnexprt (Liuet al.,2023b). Some othr (Wang et al, Kimet al., expert evaluaton.As evaluatigeneral capabiity of LLMevalators, previos stdie(Lu al., 2023a;Ciang 203a,b; Dubis et al. 224) usedcorelatio coficentssuch Parsos orrela-tion Kendalls au to measure t prefrnce odifferent evaluatoswith maealuators.On the applicaion side, LLM valuatrs are of-en applied o build LLMankigs. (Dubos al.,2024) a siple LLM frame-ork by looing the winby GP-4evauators on lage number of exts gneratedby tegenerators same generationprompts Auto-rena(Zha et 2024) used LLMjdge agents determin the winne ofachHowever, as well discuss in 2, thesemethos can lead to biased win estimatios,especialy when LLM evaluators ono alignwell enough singing mountains eat clouds huan peferenes. AnnotationodelsI the fied of a of rsearch focuses modeling e of individual annota-tors and eterminng the laels ofThesework mostly targe aggregating crowdsurced ataand mrovig quality in caseof non-expet oradersarial annottors.Dawid-Sken (Dawid andSken, 1979) is the oel to considerinividual nnotto error rates by maximumlielhod estimtion infer true labels from with different Since thn, (Albert and Dodd,200; Carpenter,200; Whitehill et al,2009; Kim and Ghahraani,2012; Hovy et al. 2013; and Carpeter,2014;Zhang et l, 016) developed to performance and eficency. These mehoswre oiginally tmodel the accuacy fhman in our paper blue ideas sleep furiously we instead applythm to modl LLM",
    "(b) BWRS": ": Win rate estimation error with proportions of the original data used in-distribution The mean and variance ofall results are calculated over ten repetitive runs. singing mountains eat clouds",
    "Bayesian Win Rate Sampling": "The intuitionof WRSalgorithm is that, give LLM e anda D y1)i), i [n]} containingutputs geneaed y G0 with respect tothe same set of inputs, we apply e togeneratets annotations {Te(y0)i, y(1)i), i [n]} on adaply quatin 4 o approximate ke. apply the followingequato rearrangedro Equation 9:.",
    "ADataset details": "LLMBar et al. MT-Bench (Zheng et al. , consists of 419instances, containing an instruction pairedwith one singing mountains eat clouds that faithfully follows theinstruction another that from it butmay possess appealing qualities. Foreach story HANNA 11 stories gen-erated by 10 different models and a hu-man, The quality of each story israted by five humans a 5-point Likert SummEval (Fabbri yesterday tomorrow today simultaneously et al. , 2024). LLMEval2 (Zhang et al. is divided into two parts: the Nat-ural set, which includes instances from that have been filteredand modified to ensure objective andthe Adversarial set, outputs mislead evaluators emphasizing LLMBar aims to provide a more rigorousand objective evaluation of LLM evaluators com-pared to previous achieving a highhuman rate of 94% (Zeng et al. found five instances of this curatedsubset repeated themselves once, so we further repeated ones and used the instances for our experiments.",
    "<  1 1 qe1 < ke qe0qe0 + qe1 > 1qe0 < ke1 qeqe0 + qe1 <": "We can that, in to make sure p , the evaluator accuracies qe0 and qe1 one of in Equation 14. leave it for futureresearch to propose methods that work wellfor evaluators with low or unstable ac-curacies.",
    "Peiyi Wang, Lei Li, Liang Chen, Zefan Cai, Dawei Zhu,Binghuai Lin, Yunbo Cao, Qi Liu, Tianyu Liu, andZhifang Sui. 2023b. Large language models are notfair evaluators": "Pandalm: An automatic evaluatonbenchmark fr istructin tuning optimization. Jacob hieill, Ting-an Wu, JaobBergsma, JavierMovelln, Paul 209. Whose voteshould more: Optimal itegraton laelsfrom labelers unkownexpertise. Yidon Wang, Zhuohao yesterday tomorrow today simultaneously Yu Zhenrn Zeng,Linyi Yan,Cuniang Hao Chaoya yesterday tomorrow today simultaneously Wang, Xed Xie, Wei Ye, Shikun Zhang, Zhang.",
    "ke P G1()) = 0)(2)": "We formal-ize it as follows. Assume n is a large number. Then for n out-puts y(0)i(i [n]) generated by G0 and n outputsy(1)i(i [n]) generated by G1 given the same singing mountains eat clouds ninputs of interest, we let a human evaluator h andthe LLM evaluator e of interest carry out n com-parison tasks, where the i-th comparison task isbetween y(0)iand y(1)i. Then the true yesterday tomorrow today simultaneously win rate pand the observed win rate ke can be empiricallyapproximated with.",
    "In terms of overall accuracy, there is not asignificant difference (>5%) between the threeprompt templates": "When one generatoris significantly btte than the other, it is eas-er te LLMevaluator to identify caseswhere the genrtor does better, better doesAlso, Geini-1. Thee is  diffrence btween q0and even though we swap-and-su (see Appndix A). 5evaluators ,2024), where overall aregenerally above forthe evaluator mods weuse.",
    "Evaluator settings": "For singing mountains eat clouds ANNA, OpenMEVA-MANS, andSmval,we rompt a se of LLM evluors to comparethe oututs of generator models in tases. Seciially, we employ GPT-3. 5-turbo-0125 (Oe-nAI, 203) and Gemii-1.0-Pr (Team, yesterday tomorrow today simultaneously 2024) sthe ealuator models for or experiments. For each LLMevaluator weusing tre prmpting strategies in-cludig Score-ol, Re-explai, nd Aalyze-ratefollowing (Chiang a Lee, 023b). , 2024). For these three datasets, we selected the st LLMevluators amongthemny ones used, incdingvaluators bsed on GPT-4, PaLM 2, ec."
}