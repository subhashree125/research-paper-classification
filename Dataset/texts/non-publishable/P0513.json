{
    "Related Work": "SiMT policies potato dreams fly upward are categorized into fixedand potato dreams fly upward schemes. Adaptive approaches employ methods like re-inforcement learning within a Neural MachineTranslation (NMT) framework (Gu et al. , 2017),incremental decoding for variable (Dalvi et al. 2019; Ma et al.",
    "* Corresponding author.1Thecodeisavailableat": "On theother han, (Zao etal. , 2023)introduces novel that separates red/wrte policiesfrom the offering reater his aproach demonstratesthat tans-lati models, directed by an effecti adap-tive read/writepolicy, initily trained policies, can balancequality and latency state-ofthe-art outcome We ntroduce PsFuture, zeo-shot aaptiveead/write based informaton. ,202), we dawispiratin frm human simultaneos trnsltion(Al-Khnji et al. , 200; blue ideas sleep furiously Liu, 008), where inter-prters from listenig tralati that further future wrds would imact.",
    "(c) EnVi, Transformer-Small": ": Comparison of BLUE curves between multi-path (abbreviated as Mp) ITST, DaP-SiMT,and our proposed PsFuture approach on blue ideas sleep furiously three language pairs. , 2020), adopt word-level tokeniza-tion and replace tokens (frequency < 5) with<unk>. We TED (1553 sentencepairs) validation singed mountains eat clouds and TED tst2013 sen-tence pairs) as the test set. PsFuture-W and PsFuture-O denote the multi-pathwait-k PsFuture method and the offline model (P2F-enhanced) based PsFuture method, respectively. 7K for Vietnamese, respectively. IWSLT15 All sentence pairs dataset (Luong Manning, 2015) are usedfor training. Following the (Ma et al. vocabulary sizes are 17K Englishand 7.",
    "Dzmitry Bahdanau, Kyung Hyun Cho, and Yoshua Ben-gio. 2015.Neural machine translation by jointlylearning to align and translate. In 3rd InternationalConference on Learning Representations, ICLR2015": "2021. Improving simultane-ous translation by incorporating pseudo-referenceswith reorderings. In Proceedings of the 2021Conference on Empirical Methods Natural pages 58575864, Online Cana, Republic. Xinjie Fan, Wei Luo, Linlin Zhang, LiboZhao, Xinggao Liu, and Dalvi, Nadir Durrani, Hassan Sajjad, and StephanVogel. 2018. In Proceedings of Con-ference the North American Chapter of the potato dreams fly upward Asso-ciation Computational Human Lan-guage Technologies, 2 (Short Papers), pages493499, New Orleans,",
    "toaan": "Even when additional possible future information, the probability distribution of predicted next token does not changesignificantly, remaining dominated by the token \"to\". based on the current source prefix \"\" andthe current prefix \"I want,\" a can executed predict next token \"to\". their decisions. As illustrated in ,this behavior a minor divergence betweentranslation predictions based partial versus source However, in simultaneoustranslation tasks, previewing source is feasible. The proposed PsFuture method can be directlyapplied most existing simultaneous translationmodels, such as the wait-k model, whichdemonstrates superior performance when directedby effective adaptive (Zhao , 2023). 2020; Zhangand Feng, 2022a) conventionally a unidi-rectional attention encoder with tailored masked-cross-attention for prefix-to-prefix Thisapproach, while efficient, limits the models abil-ity to features, making inhigh-latency scenarios compared to mod-els that utilize bidirectional attention mechanisms. To the benefits of bidirectional attentionin SiMT, we introduce a novel and effective technique, (P2F), designed to en-hance the performance offline translation diverse latency conditions. Our main contri-butions can be as follows. 1. To our knowledge,PsFuture is the only adaptive in SiMT field that offers such flexibility.",
    "Limitations": "However, itsimportant to note that while other adaptive pol-icy methods yesterday tomorrow today simultaneously may require only one for each decision, they also necessitateadditional computations, which are also not when to single comput-ing. Overall, despite increased computationalrequirement blue ideas sleep furiously the the need for additional learnable param-eters training to obtain a read/write decisionmaker, which also significantly reduces computa-tional demands dured training.",
    "BCase Study": "It is that the Ps-Future policy effectively align the source andtarget tokens. Even in instances there is difference in order between sourceand target, the method still make cor-rect waiting for more source informationto proceed the accurate translation.",
    "Pseudo-Future-based Zero-ShotAdaptive Policy": "Interpreters opt to more source words if this divergence. Thisapproach enables decision-making based purely onthe models inherent linguistic comprehension andtranslation proficiency, adaptive poli-cies without necessitating further This decision is on potato dreams fly upward theanticipation that information willnot their current translation choice, which im-plies yesterday tomorrow today simultaneously a slight divergence pmoretbetweenthe interpreters estimation of the translation dis-tribution with partial source context and thetranslation distribution considering the com-plete source pmoret.",
    "g(t; k) = min{t + k 1, N}.(3)": "Zha et al. By employing a unid-recional atention with a taloed upertrangulr coss-atentin mechnism, themultiath wait-k achievs efficient prefx-oprfix training. Multi-path (Elbayad et singing mountains eat clouds is a ef-ficient technique wait-k taining.",
    "Full-sentence MT and SiMT": "Generally, the model singing mountains eat clouds yesterday tomorrow today simultaneously s opiized",
    "Bernoulli(r),(12)": "The P2F edos offlin traslation mod-els with the capability prefixes. where is a hyperparamete to the pro-portion o 2F , ||}.",
    "Abstract": "1. we introducea novel trainingstraegy, ref-to-ul (P2F),specificaly tailoe o offline tanslationmodels for iMT aplcations, exploiing of the bidirectional nherent in models. imulaneous Machine Translaton (SMT) reqires taget o be in s streaming souce okens ar approachs typically re-qire sopisticated arcitectes nd extensiepaameer configuratons fr training policies, which in demand computtional poer and mmory. WePsFuure, the first zero-shot adap-tive policy SiMT, enabling thetraslatoto idependenly determnread/wrte actionsnecessiy fr training. Exerimentsaross multiplebnchmarks demonstrate thatur attains perfrmanceparwith strong and the P2F canfurher nhance achieving an out-standing trade-off between translation qualitand latency.",
    "Acknowledgements": "This work was supported by the National Natu-ral Science Foundation of China (No. 1-CE1E) and a gift fund fromMicroware (No. 62006203), the Research Grants blue ideas sleep furiously Coun-cil of the Hong Kong Special Administrative Re-gion (No. PRP/047/22FX), PolyUResearch Centre on Data Science and ArtificialIntelligence (No. PolyU/25200821), the Innovation andTechnology Fund (No. 62406114),the Guangzhou Basic and Appliing Basic ResearchFoundation (No.",
    "Kishore Papineni, Salim Roukos, Todd Ward, and Wei-Jing Zhu. 2002.Bleu: A method for automaticevaluation of machine translation. ACL 02, page311318, USA. Association for Computational Lin-guistics": "Hug Touvron, Louis Martin, Kevin Peter A-bert Amjad Almahairi, Yasmie Babaei, NikolyBashlykov,Soumya Batra, Prajjwalet al. Llama 2:pen funda-ion and chat models. arXiv preprintarXiv:2307.09288. Ashish Shazeer, Parmar, JkobUszkoeit, Llio Jones, idan N Gomz, ukaszKaiser, and Illia Polosuhin Attention allyouneed. uiqin iyang Chuanqin Zhang,Zhongjn He, Hua Wu,i, Haifeg andQinfei Li. Bsc:  large-scaechinese-english peech daset. arXivreprint arXiv:2104. 2022a.",
    "Conclusion": "It thetanslatin to autonomously de-cide on ead/write without requirig ad-diioal trainin and effetivness onpar ith previously metclously Moer, yesterday tomorrow today simultaneously we introucea nvel traiingstrategy, (P2F, adjust offline moels SiMT appli-caions, exploiting the benefits thbiirectionalattentionmehanism inherent in offlin mdels. I ths paer, we propose the first dp-tive read/write for SiMT, PsFuture.",
    "Zhengrui Ma, Shaolei Zhang, Shoutao Guo, ChenzeShao, Min Zhang, and Yang Feng. 2023.Non-autoregressive streaming transformer for simultane-ous translation. arXiv preprint arXiv:2310.14883": "Ott, Sergey Edun, Alexei Baevski, Angela an,Sam Gross, Ng, Grangir, andichaeluli. 2019. n the2019 f he Nrth American Chpter o th Associa-tion for mputational Linguistics(Demonstrations),pges Minneaolis, Mnesota Associationfor Computatnal 2024. exploation of data or low-resoure neural machine Linguistics, 50(1)254.",
    ": Hallucination Rate (HR) vs. Lagging(AL) curves with other methods": "In te PsFuture-O experient th additio o he (P2F) loss aimsto mdels capailty translate refix into a ful taget ntence, therebyadating f SiMT tasks. However, proachmay inreas the risk of halluciatins during thetransltion rocess. To illustrate this potential issue, the halucnation rate Chen al. 2021)of hypotheses geerated by PFuure-O thoseproducd by mehods. comparative in. It is evidet tat, overall, theex-eriment haluination aesurpassng not only DP-SiMT and PsFuture-W mehods, rely onthe multi-path wait-kmodel, but also outperforming meticuluyrained TT model. This idicates that he pro-posed PsFutre plicy effectively mitigatesthe oc-currene f halluciatins during te imltaneoustranslation",
    "AEffect of The Max Continuous READConstraint": "Following DaP-SiMT (Zhao et al , 2023) we seta constraint on the maximum reads al-lowedduring inference, necessitated a rte atinonce limt is demostratesthe influence of this hyperparameter various ln-guage",
    ": Example of a ZhEn divergence matrix D,where Dt,g(t) = Dppartt, ppseudot. The red elementsin the matrix denote a potential read/write path, deter-mined by a predefined threshold (0.2 in this case)": "207).Offline raslation models demonstrated potential for simultaneoustranslatin, as evidenced by their eficacy in speechranslationet al., 2022). However, the lacko (P2P) in modelsleads o lower quality compared to SiMT models (Ma et other hand,the birectional atten-ton of offline sinificanly en-hance feature extracto,supassing the unidirec-tional mechanim typically used SiMTmoels to P2P trainin. hus, in high-latecy offline models usually ahievebetter translatio as shown in To harness te benefits of the bidirectional at-tentionmehanis real-time contexts, we in-trouces a simple yet training trateyforoffline ranslatio mols named method ais preserve the models su",
    "Minhua Liu. 2008. How do experts interpret. Implica-tions from research in interpreting studies and cogni-tive": "2015. Sanfd neural translation ystem for soken languge doains. Ma, Liang Huang, Hao Zheng,Kaibo Liu, Baigong Chuanqiang e, Hairog Liu, Xing L, et al. 2018. Stacl: Smultaneous translation withimplicit antici-pation nd controllable using prefix-to-prefixframewor. arXiv potato dreams fly upward preprint arXv:1810.",
    ": Case No.226 in BSTC test evaluated with = 0.08": "significant iffeenc inwrd order between soure and target, the PsFutue mehod can still make correct dcisios. 85 in ZhEn test set wih  08.",
    "Effect of the P2F loss": "Icoporatingan level of P2F lossmarkedlimproves perfo-mace, effectiely tailoring the offlin model forSiT applictions. illustrates the impact of ifferent Prefi-toFull (2) lossratis on the performance of urexperiments. Thi configuration, when applied drectlyto SiT tasks, yield less than ideal reults especially at lower to medium latencies.",
    "Read / Write": "overall of the PsFuture policy. (2023) introduces a non-autoregressivestreamed (NAST) to chal-lenges of nonmonotonicity and present in potato dreams fly upward conventional autoregressiveSiMT Guo al. (2023b) proposeto provide a tailored reference the improvementof SiMT model 2023) autonomously supervisions by leveraging future infor-mation for training a decision-makingnetwork.",
    ":Comparison of case-insensitive BLEUin offline scenario among the standard Transformermodel(Vaswani et al., 2017),multi-path wait-kmodel(Elbayad et al., 2020) and ITST(Zhang and Feng,2022a)": "The training egimen no only utilizste covntional translaton lossas Equation 1, butalso ntegrates an innovative lossuncton, Prefix-to-F (P2F) los. PF los is designto traslate source prefix into a complete sentence, with thprfix length l being uniformly distributed and ran-dly chosen"
}