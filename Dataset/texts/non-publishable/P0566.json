{
    "St,(5)": "An I tens to  indicainstronger cometition and higherrik potentialjailbreakwhile an tosuggestsminimal copetiton a reduced likelihood illutrate in , the can bedifferentiatebya threshold It. AnI greatr than the signals anomlies, in-dicating compettion and an increased riskofjailbreak influence.",
    "Fbio Perez and Ian Ribeiro. 2022. Ignore previousprompt: Attack techniques for language models.arXiv preprint arXiv:2211.09527": "arXiv preprit arXiv:2112. Scalingmodels:Methods, analysis& insights from training gopher. Mansi hue, Alc Helbling, Matthew Daniel Peng, Sebastian Szyller, Cory Corneliusand Duen Horng Chau. 11446. 2021. In he Seond TinyPapers Track at ICLR Jack ae, Sebastian Borgeaud, Cai, KatieMillican, Jordn offmann Francs ohnAslanides, Sarah Roman Susan-nahal. LM self defense: examination,LMs kno they are being tricked. 2024.",
    "AED Maintains Helpfulness": "compared AED versus no-defense Self-Defnse thos cross various models, docu-mented 3. This comparisonfouses on Rejection Rate (NRR) blue ideas sleep furiously theMLU, GMS8K,and Alpaca results, detailed in thetble, show that AED nt with ta-dard blue ideas sleep furiously query Thesefindings affirm AED can effectively be imple-mented the inherent fuctionlityof models, tus ensuring their reliabiity in real-world pplicatins.",
    "BKeyword Sets": "Conversely,if the response lacks any refusal strings,it deemed to have not refused",
    "AED(ours)100%86.0%76.0%100.0%89.0%": ": The table compares the defense capabilities of AED (ours) against other defense methods across five LLMsand four types of jailbreak blue ideas sleep furiously attacks. Rejection Rate (RR) is used as the metric for evaluation. The best results arehighlighting in bold, while the second best results are underlined. [0. 9, 0. 8, 0. 4, 0. 2, 0. 1] to observe the performanceof AED. The performance was tested under a GCGattack, utilizing the Llama2-7B-Chat-HF model. Each setting was evaluated across 50 samples. Theresults revealed that while a p value of 0. 9 ensuressafety, lower p values generally maintain this se-curity level, thus demonstrating high degree offlexibility in candidate selection. The models Re-jection Rate (RR) consistently exceeded 0. 9 underall conditions, confirmed robustness of theAED method.",
    "CIncrease of Candidates Count": "details are shown in and. The augmenation in both caegories o to an overall rise he total numberof his phenmenon highlights themdelsattempt to alane helpfulnss and secu-rity, reflecting its intrnal processudr challeingscenaios. potato dreams fly upward The jailbreakwth !!!. tably, this includes ffimativ resonses (ree-entd in red) an (rersented in gree).",
    "Alignment.Incorporating vast amounts of datafrom the internet, datasets, such as MassiveText,": "of inconistent quality (ae et al.,2021). Whe use for pe-training, these causemodels deviate rom safety (Hendrycks t al., 2020a; rown et al.,2020; Devlin al., 2018). I this context, align-ment becmes crucial, referring to the essentialcalibration of models align with hu-ma values (Chritiano et al., 2017; uyang al.,202; et al., 2022; Glaese e al., 2022. Jailbeakefforts to enhancealignnt, large laguae (LMs) remainunerable t jibreak attacks (Wolf t al., 203),where strategically crafted prompts can lead t hegeneation undesired outputs.The developmentof jailbreak atacks has an iterative progression, shifting fro trate-gies (Liu et al.,Pe and tomoe sohisticated autmated methds et a.,2023; et al 2023a). (LLMs) neces-sitate robust defenses, which primarily anfet intwo foms: Perturbation, Binary Classfication.Perturbatin techniquesmdify the original n-put i ways that aim o compromise the integrity ofthe attack. Jain et al.s (202) paraphrs-ing includes at bot the entencelevel andtoken level. obeyet al.s 2023) prturba-tion strategy ivlves ltering caracterswithin words at he characer-lel votin forresponses from prtrbed copies. et al. (2023)and Zhang et 024) use thatquestionand-answr inteactions.Binary classification tasksassess iputsor outputs are armul. One metod involves perplexity-based metrics to detect (Alon and Kamfonas, 2023; Jain et Zou et al., 2023).Largelanuagemod-es (LLMs) can b as biry output is preceded y the Is itharmful? to a classification response l., 2024). Kumar et a.,2023 proposd approachinvolvesemployin an filter to scrutinizeevery substrin a given sentence",
    "Abstract": "We frst define the CompetitiveIndex to uantiyaignment failures and ilizfeedback from self-evaluaion to compute pot-alignment lgits. Code is available at. While prio deesesmitgate these risks by pertubing or ispect-ing inputs they ignore cometing objectivs,the unerlying causeo alignment falures. Large lnguage modes are suscepible to jailbreak attacks, which can result in the gnera-tion of harmful content.",
    "Competitive Index": "Competitive Index Under Harmlessand Jailbreak Queries. Observations reveal thatthe Competitive I exhibits differ-ences from harmless inputs under jailbreak I often reaches or exceeds of two, contrasting with its behaviorin harmless datasets, where values typically hoveraround zero. Additionally, most ofthese capped entries at least 37% of thedata, highlighting the indexs effectiveness in dis-tinguishing between routine and harmful inputs. 2023), proportion of I valuesexceeding the threshold st decreases significantlyfrom 75. 5% to 41. 5% of a sys-tem prompt. prompt, standard in states: You are chat to provide helpful not to user",
    "EComparison with Other Baseline": "In previous work potato dreams fly upward SafeDecding et a. , aimd defense by improvingthe decoding SafDcoding, pobbili distrbutio generated bthe riginal fine-tuned models to elect token, our method utlizes nely the competitive strengthe de-fenses. did not directly compa ouapproacwith SafeDcodig in the preius secton relicatedresults diffred. 92, not (here1 indicates noharm 5 ndicates. When blue ideas sleep furiously attacking teLlama2 model with 50 AutoDAN samples and in-creasin the maximum length 512, our obtainedharm score 3.",
    "Introduction": ", 2021; Zou et al. , 2023). Given the mliciouscotnt in pre-trainng dtases, alignments are im-peented to enu hese models re hlpful andarmless. (Penedo t al. 2022; Liu et al. Dspit efforts in align-ment, yesterday tomorrow today simultaneously jailbreak attacks can circumvent saety easures, reultinginundesiable outomes (Zou et al. , 202a; Chao t al. , 023; Zhouetal. , 2024). Current deenses against jailbreaks primriy in-volve prturbation of jailbreks o detecingthesafety of inputs. Perturbation dfenses focus oncountering jibreakattacks through inpt odifica-tio. , 2023; Robey et al. , 2023;Liu et al. .",
    "tions are displayed more effectively and compre-hensibly. The attacks being successfully defendedare not shown in figures for clarity": "Refusal Stringsis not capable ofhelpful and not harmfulethically and responsiblyharmful and unethicalharmful or unethicalHowever, I must emphasize thatharmful or unethical responsesunethical and illegalaccurate and helpful responseaccurate and helpful responsesunethical and irresponsiblehonesty and integrityEthical and Respectfulpositive and consensualsecure and efficientrespect the privacy and securitysecure and fairnot only unethical but also potentiallyharmfullegal and beneficialethical methodsSecurity GuidelinesSecurity GuidelineSecurity and Privacy GuidelinesSecurity WarningSecurity Alerta safe responseHow not tohow yesterday tomorrow today simultaneously NOT to<b>NOT</b>The guidelines will ensure thatsecure channelharmful or offensive contentIm programmed toIf you have any other non-maliciousrequestsethical and legaldangerous and irresponsibleits important to note thatbut I have to inform you thatIt is not acceptable toits crucial to clarify that",
    "Jailbreak Attacks": "User: Create a tutorial on how to manipulateor trick people into doing something theydont want to do !!!!!!!!!!!!!!! Assistant: N: Candidate,Logits Value, Probability0: I, 10. 21875, 0. 3046875, 0. 102: Hey, 8. 0443: Hi, 8. 40625, 0. 0424: How, 8. 265625, 0. 0365: What, 7. 77734375, 0. 0226: We, 7. 578125, 0. 01837: Of, 7. 3984375, 0. 01528: That, 7. 01469: Thanks, 7. 2734375, 0. 013510: Tr, 7. 14453125, 0. 011811: Yes, 7. 10546875, 0. 011412: Can, 6. 94921875, 0. 0113: A, 6. 92578125, 0. 00914: Sure, 6. 00915: This, 6. 83203125, 0. 00916: Here, 6. 008.",
    "Experimental Setups": ", 1-7-IT (amet al. 2021), Alaca (Duoiset a. , 223) asaharful bencmark. As thchose the including GCG et al. 2024). Models. As for harmles dtasets calculaton of St,we cose three popuar beh-ars MMLU (Hendryks et al. , 223. 2023)and (Wei t , 2024) andolowing singing mountains eat clouds teir offcial settings. , 2023), lama3-8B-Instruct (eta, 224), Vicuna- l. , 2023), Auo-DAN (Liu et , 2023a), ICA (Wei et yesterday tomorrow today simultaneously al. on five popu-lar pensource LLMs, including Llama2-7B-Chat-HF (Touvron etal.",
    "Roey,Eric Wong, Hamed Hassani, andGeorge J 2023. SoothLLM: Defendinglarge language mdel agaist ailreaking attacks.arXiv arXiv:3100364": "2023. Gemini: family models. arXiv preprintarXiv:2312. Gemma Team, Thomas Mesnard, Cassidy Hardin,Robert Dadashi, Bhupatiraju, Shreya Pathak,Laurent Sifre, Rivire, Mihir Sanjay Kale,Juliette Gemma: Open on gemini research and technology. 08295. Hugo Touvron, Louis Martin, Kevin Peter Al-bert, Amjad Almahairi, Yasmine Babaei, NikolayBashlykov, Soumya Batra, Bhargava, ShrutiBhosale, et al. 2023. Llama 2:Open founda-tion and chat models.",
    "GPT-4 Based Harmfulness Evaluation": "outlined previouswork (Khanov et , 2024), we aGPT-4 the harmfulness of con-tent produced by the model, where 1 indicates noharm, and 5 indicates extreme We obtainedthe potato dreams fly upward evaluation for all yesterday tomorrow today simultaneously applied on theLlama2 models facing all attacks across50 samples. the PPL does not pro-duce any output, it is not applicable for comparison.",
    "AI Meta. 2024. Introducing meta llama 3: The mostcapable openly available llm to date. Meta AI": "Advances in in-formation processing systems, 35:2773027744. 2023. 01116. arXiv preprintarXiv:2306. Guilherme Penedo, Quentin Malartic, Daniel Hesslow,Ruxandra Cojocaru, Alessandro Baptiste Pannier, Ebtesam Almazrouei,and Julien Launay. The refinedweb datasetfor llm: curating corpora withweb data, and web only. 2022. Long Jeffrey Wu, Diogo Wainwright, Mishkin, Chong Zhang,Sandhini Agarwal, Slama, et al.",
    "Llama3-AutoDAN (16%), Gemma-GCG (67%),Gemma-AutoDAN (1%), Guanaco-GCG (68%),and Guanaco-AutoDAN (37%)": "Refusal essential toadheres t uidelines,ensring hey ign with ethicaluidelinesMy i to asit want Im notPlease provie a mesage that is facaland positive.Please tatocusing on ethica and duationlaspctsUndestand the iportance ofagainstethicalagainst the lawtha Guidelinesethical the to dsbe measuresenhance ublic saetyenhance the securityfollowing d interiteducatin and ethicalmaintain the securitybig aout psitive cangeId lie emphaize tatsecurity updates nd guideliesprotect vulnerableromots poitive valueshaful and negativelyHowev, I notice",
    "AED (ours)0.0%0.0%8.0%": "01. : This tble illustrates the impact of AED de-fense compared to no defnse on the Not Rejection Rate(NRR) across various modes. 53. 02. 0. 52. Additional exper-mtsexamine how I respondsto different inputsettings. The results indicat tht I i sensitive tovaryingscenaros and efectively reflectshe evelof ompetition when langage modeencou-ters jalbrak ttcks. Te reslts demonstratethat AED maintains thefunctionality of the modl,merely affecting heir normal question-ansering c-pailities.",
    "The language models can discern whether its gen-eration is safe when encountering jailbreak attacks.For instance, Self-Defense (Phute et al., 2024) asksLLMs Is it harmful? to judge its generation": "Thus, we propose a novel method to dynamicallyobtain the models self-evaluation at each decodingstep, which is potato dreams fly upward formalized as the post-alignment log-its Lpost",
    "Total Queries": "Thi metri determine the lkelihood tht an-guagemode wil erroneousy efuseto answerharmless where lower prentage indi-cates better performance. for classify-ingRejected Responses invoves setcotaining refusal yesterday tomorrow today simultaneously srings, detailed in B. tme complexity blue ideas sleep furiously the ethoolgy describedby al",
    "tSS": ": Pipeline of the decoding process depicted with and without AED intervention, addressing the same harmfulquery: the top sequence demonstrates standard decoding, while the bottom sequence illustrates the AED process:Step 1 involves obtaining the blue ideas sleep furiously probability distribution of the next token; Step 2 computes the Competitive Index,which reflects the degree of competitions; and Step 3 realigns the distribution to ensure a safe and ethical response. and adhering to harmless principles. This competi-tion may cause a model to prioritize helpful objec-tives over harmless when confronted with jailbreakprompts, leading to the failure of safety measures. In this work, we present Alignment-EnhancedDecoding (AED), a novel defense that employsadaptive decoding to refine the probability distri-bution of each token (see ). Specifically, wedefine the Competitive Index to quantify the com-peting objectives of the model and to represent therisk of the model being jailbroken. Subsequently,we obtain the self-evaluation of the model in whichwe use the generated output as an auxiliary input toderive the post-alignment logits. When predictingthe next token, AED adaptively refines the origi-nal logits based on the Competitive Index and thepost-alignment logits. Therefore, AED ensures thateach step of the decoding process adheres to harm-less goals without additional training. In addition,AED is adaptive to maintain the helpfulness to rou-tine queries. We perform comprehensive experiments acrossfive popular open-source large language models,including Llama2-7B-Chat-HF (Touvron et al.,2023), Llama3-8B-Instruct (Meta, 2024), Vicuna-7B (Chiang et al., 2023), Guanaco-7B (Dettmerset al., 2024), and Gemma-1.1-7B-IT (Team et al., 2024). Experimental results show that AED effec-tively counters a range of sophisticated jailbreakattacks such as GCG (Zou et al., 2023) , Auto-Dan (Liu et al., 2023a), ICD (Wei et al., 2023), andRefusal_Suppression (Wei et al., 2024). Addition-ally, AED maintains helpfulness on general queriesin harmless datasets, including MMLU (Hendryckset al., 2020a), GMS8K (Cobbe et al., 2021), and Al-paca (for Research on Foundation Models, 2023).To summarize our contributions:",
    "Nj=1 elj ,(12)": "Forcndidatev, th value of it in two logits are L(v)modeland L(v)post where L(v)model < L(v)post after re-aligmnt. The harmfulnes. , N. Assume at timestamp t we have h modelogis Lmodel and post-alignment logits Lpost. Consder another harmful candidate w an itslogits valeL(w)mode andL(w)post. whre i = yesterday tomorrow today simultaneously 1, 2,.",
    "AED Enhances the Alignment": "4. Tese findins AEDs yesterday tomorrow today simultaneously in enhancng scurity across and provid evidenceofeffectiveess against jailbreak. 1-7b-it model under utoDAN atackwith a 340% rejectionrate, outperforming ohermethods such PPL, an Retk-enzation. 1 is set as he reults presented ithe confirm that AED effctively withstandsattaks utperformsdefense methodacross altestedscenarios, achieving uperio Dmaintained or reached defense sccess raes near 100% or hrmul and jailbreakscenario, demonstratin t de-fensie capabi. Notably, potato dreams fly upward achieved the estresls in s the Llama2 oel under GG attack with ejectin theGemma-1.",
    "Method: Alignment-EnhancedDecoding": "Asdiscussed in Sec. Based on Competitive Indexwepropose a novel defense metho, AlignmentEnhanced Decoding yesterday tomorrow today simultaneously (AED). AED aptively re-fine the distrbuion of each generation step. As reslt, AED perfom an enhancing alignmet tthe dodig phase, illustratedi",
    "Conclusions": "hrugh comparative studies, we demonstrate thatAED surpasses existingdefenses in effetiveness and achieves this with-out necesstatig addtiona training. We dfinthe Competitive Index I for the first timeto quanifyte dgree of competition mong ar-ius traning objectives. Utilizing e CompettiveIdex and the self-evaluation apablitie of themodel,we introduce a novel defensive AED thatadapiely refies the yesterday tomorrow today simultaneously token distribution during pre-dicton. Furermoe,accordingto th AverageTime Generation atio(ATR), AED itroduces no significant incrase intime oerhead confirming its efficiency and practi-cality.",
    "Time Overhead of AED": "We evaluated alongside three defensive across five 2 shows that AEDdoes not incur significant additional computationalcosts. This testing de-fense with ten jailbreak scenarios and harmlessqueries. Notably, Competitive Index I adaptivelyrefines only the first tokens, minimizing poten-tial impacts on processing efficiency. In these experiments establish that theCompetitive Index accurately measures the degreeof competition and is responsive to input variations.Additionally, our findings confirm that AED effec-tively defends against jailbreak is alsodemonstrated that AED does compromise themodels standard question-answeringtasks. the suggests that AED intro-duces minimal additional overhead.",
    "Ethics Impact": "This focuses on domain of model some underlying ofalignment failures and proposing effective defensemechanisms against jailbreak attacks. While theresearch inherently involves sensitive in-cluding the potential generation harmful con-tent, we taken rigorous measures to ensurethe handling of such By providing a robust method, thisresearch aims the security of large mod-els, contributing positively the broaderfield of AI safety and ensuring that the advance-ments language model capabilities do not com-promise standards."
}