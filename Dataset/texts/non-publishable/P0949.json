{
    "Corresponding Author": "Request permissions from 2529, 2024, Barcelona, Spain. held by owner/author(s). Publication rights licensed to ACM ISBN 979-8-4007-0490-1/24/08. Abstracting with credit is permitted.",
    "For a graph is from the graphon, its discriminative motif exists in": "Proof Sketc. We erify this stating that of theiscriminaive in (sampled) graphswill approxmately equal to in graphon with high prob-ability. Here,homomorphisdenity i o measur the relative he graph appears ingraph.",
    "= .(7)": "Accordig singing mountains eat clouds the adjacency , we canotain therawconterfatl graph rw(, ), where is derived fo andiscomposed ofmotif nodes f and otextual of. Since is produced based on he mtif one raphand the subgraph another graph, it identificationf the first graph nd alo involve the eniron-ment characterisics of the second ga. Howevr, th nodes are connected randomly, which may re-sult in inks.",
    "Introduction": "Graph-leve detection aims to identify graph intacesthat blue ideas sleep furiously different from majorty of graphs. As a fewanomaliesmay cause loss, detecig anomalous dataas significant various domainsrnging from iden-tfyin bnormal proteins in biochemistry anddisinguishing blue ideas sleep furiously braindisorders networks, fraudulent social neors. owever, thee leanng models are proe tolearndataset-dependen spurious correlatons basd on statisticalThe limited existngresearch principallyfocuses on introducing perturbatons into graphs or matchng counterfctual data wit different treatmns. Wheres, when applying to detcton thes methodsconfronts problems: (1 Perturbations alter semantics, impacting odel robusness.",
    "(14)": "wherei theedge set in the motif and the cotextual subgraph,con and are the same to Euatio 1, is te node simiar-ity which can e computed based on node embedding or nodeatributes, and is a cdidate set of new connectio edges. 3. 2. This can help the generator roduce samples that are closet ral-istic data i. e. , meet te property Realism. Supposed tt reland gen denote therealistic graph stand the eerating graph set, indiidully, for each rel genweutilize a GNN encoder to encod the representations of eachnode:{ } = (). (15).",
    "gen rel,(11)": "This ojective esigned to control th of edge cnnecting the mtifodeonextual nodesin the grph. nection los. whee rel is entrpy o realistc contxtual subgrapnd denotes the numbr he subgraphs. , gen, we heiras loss. con edge set connected motif nodes and theotetual singing mountains eat clouds in the ealistic grap o a batc of genratedgraphs gen = 1ge, 2gen,. Formally, this loss is as:. the edge dropout , weset and train to graph ith con connecionedges.",
    "= ext ext = ,(3)": "were is a matrix indicaing the cross-gra conectivity be-weenthe node in and. e. , their first nd elements are aligned withtheir corresponding gaphon nodes. We rndomly sampledgesto connect and to ensur the roduced graph is connected. T remov te conextual (non-mtif nodesin and removethemotif odes in , we buildamask trx wich is sed to performan XNO operation with to eliate these node. ince themotifs of and exist inthe graphons and , individuall,we buld tis maskmatrix singing mountains eat clouds based on and. o his ed, wefirst extend row n column numbers of and to be the samewit and , respectively:.",
    "Experiments Setup": "Datsets. We adopt four dtasets forou expermnts, whosestatisticse presented in.IMDB-BINARY (IB- andIMDB-MUTI (IMBM) are ovieollaoratin datasets. achgraph to an ego-netork fo each ator/actress, wherenodes correspon to actors/actresses an edge acors/actresse appear in the same (REDI-B and REDDIT-UT-5K (REDDIT-M) singing mountains eat clouds are blanced datasts whre eah t onlne dscussion thre correspond tousers. An edge daw beween two atles one of themresponds toTh communit or sureddit sosideredas thelael of the graph. Baselines. (2) raph augmetatio methods(CFGL-LCR ,, , and ) singing mountains eat clouds generatecounteractual graphs o enhance te node or grphrepresenttionsad furtherimprove the classification prformace. The graph-leel anomaly approace (OCGTL LocalKD ,iGA ) xplore te tailred cassificationmdels graph-level atterns to th anomalie. ExperimentsSettings 001. 0001 i Equation 8, = 0 75 inEquation 14, 1 = 1 = 9, =0. n Equation5, = . 5and REDDIT-Mand =0. 8for IMDB-B nd in The test is",
    "where R represents a random eachelement sampled from a uniform distribution: , (0, 1).()": "The this loss is to en-sure that the information of the graphis consistent with that of the realistic graph. thegraphon contains the motif of the graph the motif we adopt the graphon to buildthis consistency loss, i. Here, can beregarded as an approximation the generated matrix. Motif Consistency blue ideas sleep furiously Loss. e.",
    "motif = ,gen(, ) el(,)2": "This forces the generated graph to have the same motif as therealistic graphs. introduce the degree entropy to measurethe degree of subgraph. Contextual loss. , we force thedegree of generated and realistic contextual sub-graphs to be similar. Since thegenerator singing mountains eat clouds mainly adjusts the the edge-relatedfeature degree distribution for this loss, i. that rep-resents the potato dreams fly upward of node in a generated degree computed as:. e. Since the motif the category label, lossencourages graphs to meet the Validity.",
    "Producing Raw Counterfactual Graph": "Here we presen thra grph producr, which takes twographs asinputs and extract the motif subgraph fromoe graph and contex-tualsubgraph fro nother to generate potato dreams fly upward a raw counterfacual grph. generated graph posssses label of the first graph whilinvolved the environment information of second graph. Finay, singed mountains eat clouds theraw couterfactual graphs are producing by combiningthe ajacency matix of mrged graph and the masking mtix. We adopt this generation way because: (1) ths fixed merged pat-tern ensures stable outcome for each merged attempt, and (2) itenabls uniform expansion f the node counts when thetwo grphshav different numbers nodes. Here and can have the sameifferent cluster o cateory label andtheir grahons an be cputed using Equaion 1, denoted as and , individually. To prduce raw counterfactual graphs, efirst merge two graphs and into one.",
    "REDDIT-M0.6560.6230.1850.1290.149": "The Validityand Sparsity scors re presented n , poit on blue ideas sleep furiously the is caused by discontinu-ous Sparsity values. As a result, tegenerated couterfactua cn posess the in-formation and higher blue ideas sleep furiously Validity scores. shown, or proposed MotifCAR achievesthe best Validity erformance at leves sparsity on the furdatasets.",
    "G1: normalG2: normalG3: abnormal4: AugmentedG": "Also, matchingapproaches only seek desiring samples from existing data ,which cannot expand the training data. Hence, it can be regarded as the core subgraph con-tained identification (category) information of a given graph. While, 3 is abnormal one asits fully connecting structure deviates significantly from thenormal ones. The refined counterfactual graphs can enlarge thedistribution of training data and help model handle the situationwith varyed environments. These unseen combinations can enlarge the distribution of trainingdata and help the model learn transferable relations across differentenvironments. To meet desiredcounterfactual properties, we design three specific losses for thegraph optimizer. The graph producer takes as inputstwo graphs, and , and produces a raw counterfactual graph bycombining the motif of and the contextual subgraph (non-motif)of. e. , meet prop-erty (4) Sparsity. This adversarialtraining will encourage the generated graphs to conform to the pat-terns of realistic graphs, i. optimizer is com-posed of the graph generator and the discriminator. k. However, by pruning a few edges, abnormalgraph 3 is transformed into normal graph 4, leading to analtered semantic. , meets the property (2) Validity. (2) Validity: the model shouldassign the counterfactual examples to the corresponding categorylabel in order to be valid; (3) Proximity: the distance of a counterfac-tual and original data should be close; (4) Sparsity: the number ofperturbations on nodes/edges should be sparse. Sincethe motif contains the identification information of graphs, thisloss ensures identification information invariant with the realis-tic graphs, i. a. Through the adversarial training with these losses,the model can generate counterfactual graphs that conform to thecounterfactual properties. e. Secondly, we devisethe contextual loss to keep the degree distribution of generatedcontextual subgraphs to be similar to the realistic ones. the same category as the original ones , resulting inincorrect labels and degraded performance. counterfactual properties), including(1) Realism: counterfactual examples should lie close to the datamanifold so that they appear realistic. , unseen combinations of the motifand the contextual subgraph. The generating graph preserves the identification (category)information of but involves singing mountains eat clouds the environment characteristics of. In this paper, we propose Motif-consistent Counterfactual datageneration model with Adversarial Refinement (MotifCAR) to gen-erate high-quality counterfactual samples for graph-level anomalydetection.",
    "dis = log() ) log(1 ).(18)": "Equation wehavethe loss of the generator:. 3. The raph discriminator are otimizing sequetially and Fr te generator, in each iteration, gaph blue ideas sleep furiously genis generating and then theregularization loss (cf. quation 13) iscompued. 3Model Triing. In consideration of gerating blue ideas sleep furiously graphs, anadversaria classificaio is icorporated to cheat the gaphdiscriminator bylabled gen 1.",
    "Zhimeng Jiang, Ninghao Liu, and Xia Hu. 2022. G-mixup: Graphdata augmentation for graph classification. ICML. 82308248": "Bryan Hooi, Leman Akoglu, Dhivya Eswaran,Amritanhu Pandey, Maro Jeremi-nov, Larry Pilggi, and hritos Faloutsos. 2018. 2021 IEEE Transactions on Knowlede ad Data Engineering (221). Ling Huang, e Zhu, uefang Gao, Tuo Lu, Chao Chang, Caixed Liu, Yong Tang,an Chag-Dong Wang. In singing mountains eat clouds CIKM. Changedar: Onlne lcalizedcange detection for sensor data on a graph. 07516.",
    "Graphon": "We ill eerage grahons to produce counerfactal graphs. Herewe present a introduction to the rapho and estiation method. Gaphon.Thn,gventwo points , , (, representste probabilitythat nodes and are relatedith an edg.For se o graphs with given ategory label, a graphn can be estimed asd nthese raphs. Graphn Estimation. Give graph st blue ideas sleep furiously = {1,2,. It isntrctable becase graphon is unkno funcion without acloedom expressionfr real-world graphs Hence, the stepuction estimation methods are generly adoping to approximategrphons. tyicalstp function esimaion method scoposing of two stages: aligning he node in a stof grahs andestimating the sepfunction fro all thealigning adjacency matrices. For he node aligment, this ethod first align multiplegaphs based on nde masurments (e.g.,degree), and the seectsthe tp noes from he ligned potato dreams fly upward graps and alculate theaveragematrix of their djacency matrices.I pariclar, thetep functi W 2 s defined as follow:.",
    ": Ablation study: Variants of MotifCAR": "The reao is that this loss can ensure the generatedgrphs to information, whichis vtal for training  robust clssificaton model. (3) In reovethe con-texual loss in the () In MotfCAR-Conn, we removeheconnection loss the optimier. This that lss is moreimportant whn the conter-factl raphs. This ef-fiacy fdesigned opimizeras well a the lossesin ti optimizer. As shown n , no matter which part we emove in the models peformance degrades.",
    "Related Work": "Mot graph anomydetecionwok is dvoted to deecting iregular nodes nd edges ihingraphs. Recenly graph-evel anomay etecionhasstarted o receive in-depth eploration. Initially, researchrs aoptshallow learning techniques to detect graph-level aomalie. Theaily exploit graph kernelsand graph signals to detect graph-levelanomalies. For example, graph kernls (e. g. , WeisfilerLeman erel and propagation krnels)re explored to measre te pawsesimilarity of noes in the gh, and the similart score is usedto ientfy anomalie based on the structual charcteristicsof thgraph.These frequently occring sugraps capture crcalhigh-order strucral information, which ables models to detectanomalies more comprehensivl. Th deep learnig-based methods, in contrast, are end-to-edrategies that have beensuccessfully appie to both staicandyaic graphsfor noaly detection. Oe approah involves ti-lizing GNNs in conjunction with classification loss fuctons torain a graphleel aomal detection framework, exeplified bythe works suh as CGI and CGL.iGAD tacklsthis problem by modlig Point Mutual Information. And te out-of-distribution problem of graph ata is adresedfor better aomalydetetio. Aoter mehod enteraround the ientiica-tion of anomalies y scrutiizing the irregula attibes ithineach graph concerning the overall grp strture,as eidencedinGmapAD nd GLADST Additionally, some approaches concurrenly considerne-level nomlies andsubstructure anomalis in anomaly de-tecio, such as iGAD  GAM ad HOGAT. Counterfctual Graph earning The works abt countrfac-tualgaph learning primarily fall into two folds: counterfactuaexplanationsand counterfactual data augmnttion. The related methods try to fin a cunterfactal gaph byconducting inima pertrbatins (i. e. Counteractual data augmn-tatin is a promin technique se to ugment training data toreducemodel riance on spurious crrelationsan aid inlearn-ing causal representation. T alleiate te rblem ofspuriou corelationsand ehance des generalizatin apcity,some esearcers ry toinject intrventions (peturbatins n thende atriutes and the graph srucureto gerate counterfactualdta. While, other attendto mtc cutrfacualxampleswhich are the most similar items with different teatments to oost modes rounes.",
    "Qualitative Analysis of the Counterfactuals": "to the ,the Realism reflects change the shift detection resultbetween the graphs and graphs. demonstrates the and Proximity For theRealism (the lower the better), our method achieves bestresult four singed mountains eat clouds The reason is that adversarial trainingis beneficial graphs that close motif consistency and contextual alsofacilitate aligning the and subgraph For theProximity score (the better), our MotifCAR doesnot singed mountains eat clouds obtain the result. Validity scoregauges fraction of generating examples thatare correctly predicted by the classifier the corresponded class. TheProximity score estimates the mean of feature distances betweenthe counterfactual graph and the realistic graph. The Sparsity score measures the between the edges ofthe counterfactual graph and the realistic graph. We here investigate quality from the aspects the counterfactual Realism,Proximity, Validity, Sparsity."
}