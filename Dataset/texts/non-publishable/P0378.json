{
    "A Geiger, P Lenz, Stiller, and R meetsrobotics: The KITTI dataset. International Journal ofRobotics 32(11):12311237, aug 2013. 6": "Rethinking pseudo labels for semi-supervised objectdetection. Joint 3d proposal generation andobject detection from view aggregation. In Thirty-Sixth AAAI Conference on Artificial In-telligence, AAAI 2022, Thirty-Fourth Conference on Innova-tive Applications of Artificial Intelligence, IAAI 2022, TheTwelveth Symposium on Educational Advances in ArtificialIntelligence, EAAI 2022 Virtual Event, February 22 - March1, 2022, pages 13141322. 1, 2 Gang Li, Xiang Li, Yujie Wang, Yichao Wu, Ding Liang, andShanshan Zhang. 2 Alex H. In 2018 IEEE/RSJInternational Conference on Intelligent Robots and Systems(IROS), pages 18. Waslander. AAAI Press. PseCo: Pseudo labeling and consistencytraining for semi-supervised object detection. 3. Springer Nature Switzerland, 2022. IEEE, jun 2019. Jason Ku, Melissa Mozifian, Jungwook Lee, Ali Harakeh,and Steven L. IEEE, oct 2018. In 2019 IEEE/CVFConference on Computer Vision and Pattern Recognition(CVPR), pages 1269712705. 1, 2 Hengduo Li, Zuxuan Wu, Abhinav Shrivastava, and Larry S. In ComputerVision - ECCV 2022 - 17th European Conference, Tel Aviv,Israel, October 23-27, 2022, Proceedings, Part IX, volume13669 of Lecture Notes in Computer Science, pages 457472. Lang, Sourabh Vora, Holger Caesar, Lubing Zhou,Jiong Yang, and Oscar Beijbom. Pointpillars: Fast encodersfor object detection from point clouds. Davis.",
    "Effets of reliability": "Tab. 2 ablates the performance over different reliability-basing weighting options, improving the mAP over the base-line and UCFN +BG were to suppress FN errors, while assess the effectof suppressing FN and FP two assessed to efficient ways to weightUC proposals to suppress FN or FP errors. While the weights in all of these options, UCFP + hasthe highest in mAP of 3.2% the More-over, teachers foreground found to moreefficient as a weight in option than in FG that FG + + BG has performancedue to down-weighting of truly uncertain proposals. show mean reliability weights of all fore-ground proposals relative to PLs with the weighting op-tion of + + BG. shown, the fromthis option effectively the loss due FP FN Training 0.0 0.2 0.4 0.6 0.8 1.0 reliability weight",
    "fgc bg , bg ui fgc0,ui < bg.(1)": "will inevitbl result in theoffalse negative (N) and false positie To eamne owprosas in the UC, and BG cate-gories are affected FPand we illutrte thedensity in , showing the distribution of RoI IoUsrelatie both PLs nd GTs. The FPproposals are eferet as foegroun with respect t PL, bu backround withpec to GT, wherea those that oppoieare r-ferred FN proposals. As shown,each local class-awaretreshol he plot into columns showed an BG secions fromright t lft. Ideally, e expect wellalibrted IoU scoressuch thatthe of RoIs wth respect toLs are as close as pos-ibe to teicorrespondin IoUsith respct toGT. Ipractice,however, there exit close theaxes the error. More in foreground we density of FP inetion (d), -axi,all owever, for thepeestrian class, whae ignificantly hiher ensity cm-aring to the other definitionsof and FNhave been extended to the uncertin rgioni. e secions (b) and (e), wher FN FP poposals re lo-cated section and t the bottom of stion (e), o 0 00. 40. 8. 00. 2 0. 0. 6 8 1. vi (a)(b)(c (d)(e)(f).",
    "% Improvement over Baseline+0.5+0.6+1.2+6.2+6.2+5.5-0.8+0.4+0.4+0.2+0.6+0.7+6.4+6.0+5.1+8.9+5.7+5.5": "5, and +ULB RCNN CLS ou modfied versin the with objectness supervisn fom unlaeleddata. PV-RNN is thesuprvise-only nd3DIoUMatch is originalwork both based on OpenPCDet 0. 3DIoUMatch(Baseline) is of originav0. 3).",
    "We evaluate our method on KITTI dataset, consistingof 7,481 training samples and 7,518 test samples. The train-ing samples are divided into the train set (3,712 samples) for": "trainin the and th validation (3,69 saples)for evaluation. mAP is copted used IoU thresld of 0.7,0.5, an for he car, pedes-trian cyclist rspectively, at 40 positions.Experients are conducted ll objec - Easy, Moeate, and ard.",
    ". Shows the percentage of foreground proposals with re-spect to GT used to train the FG/BG classification head, highlight-ing the imbalanced FG/BG ratios across different classes": "Noe the cr clashigl skewed, with almos the proposals as BGs. propsal th cos o sppesing truepoitives (TP). weights of FPs are relativelyhigher to 1), especilly for cr clas,and less han thoe for theFNs. showing e pecentage oFG proposals use t train the RCNN classification ranch. Wethat this is dueto the unbalancd nmberof FG/B in th RCNNmodule.",
    "Cyclist": "Denser region areshwn with dare shades. Allthree plots follow the same subregion breakdown. (b) and(e) depict prosals lng inhe uncertain region andare assigned with sft argts, while(c) and (d) depict tr positive singed mountains eat clouds and false positie proposals, rspectively. fgc = 04 bg = 0. Thproposl are obtaine fromthe last few trained iterainsWe also om proposalsthat are inthe backgroun ith respec to both GT adPL for ber vialization. 25 c = 0 Illutrates the density of IU values of proposals with their matched PL (u) and GT (vi) n thex-axis and y-axis repctively.",
    "+": ". our Reliable framework. It uses a teacher-student network, where the EMA teacher produces high-qualitypseudo-label boxes bi. We compute the IoU ui and students post-NMS proposals ri, followed by top-k of ribasing The sampled ri are injecting into the student and teacher heads to objectness scores si and si,respectively. While si to the RCNN classification loss Lclsu , si into weights wi for . target module uses thresholds for different classes on ui to objectness targets ti for . pseudo-labeling and consistency approaches.It uses notonly label-level consistency feature-level consis-tency, which further improves performance the detector.This approach also uses focal loss similarto to alleviate the class imbalance pseudo-labeling. considers the localization task as a classification taskand proposes a pseudo-label approach. Byquantifyed the quality score of classification regres-sion, they adjust the threshold used for pseudo-labels. Instant-Teaching proposes to generate pseudoannotation unlabeled data augmentationin mini-batch, then using these annotations asground truth of same image with strong augmentation.For strong augmentation, the use Mixup Recent works have focusing on andconfirmation bias issues.LabelMatch thelabeled data for adaptive thresholding to fil-ter out unbiased and recalibrates the unreliable pseudo-labels into reliable ones. Unbi-asing Teacher to in pseudo-labeled by incorporating focal lossthat forces the to challenging samplesfrom underrepresented Teacher achieves comparable by using soft labels instead ofhard labels with ensemble network to improve thereliability of the pseudo-labels. Soft deals with the misclassification of fore-ground proposals by suppressing the classification the teachers confidence approach followsthis considers the reliability of foregroundtargets work alsodiffers Soft Teacher in that we use third oftargets in the RCNN, calling Uncertain (UC) region, andassign soft to them. These may correspond to foreground background boxes. Thus, it is appropriate weights to this region to optimize theprecision-recall Combating background are accurate, and it suppressesthe noisy proposals losses. In contrast, showthat dealing with both foreground and proposals is important.There few works point-basing 3Dobject detection, such as SESS and 3DIoUMatch uses asymmetric data augmentation andenforces consistency between teacher and student predic-tions different losses. 3DIoUMatch proposesa approach for indoor and 3Dobject detection. Inspired FixMatch , they introducea joint confidence-based pseudo-label filtered mechanismusing predicting objectness and class probabilities. Addi-tionally, they estimate IoU it as a Unlike 3DIoUMatch, we employonly an threshold, eliminating the complexity ofusing multiple thresholds. unlike 3DIoUMatch,we adopt objectness supervision unlabeled data. Ourfindings that this strategy enhances performance.",
    "OpenPCDet Development Team.Openpcdet: An open-source toolbox for 3d object detection from point clouds. 6": "Leveraging IoU prediction for semi-supervised 3d detection. In 2021 Confer-ence on Computer Vision and Pattern Recognition (CVPR),pages 1461514624. IEEE, jun 2021. 3, Zhenyu Wang, Li, Ye Guo, and Wang. Advances in Neural Information 34:95349545, 2021. 3 Mengde Xu, Zheng Zhang, Han Hu, Jianfeng Wang, LijuanWang, Wei, Xiang Bai, and oct 2021. 3.",
    ". Overview": "Te is providdwih te stongly augented version o th ulabeled well as th iut, its aramters updatedthruh bcpropagaion. 3),which assigns eliabilit the poposal eachcategory based on thetype that catgory,making the training. ivn and thedefault threshod, wedefine classiicationtargets fr the and prpsals, whose IoUs la beween he FG and BGthresholds are ssigned sot targets Due t the nosyIoU ignal used or target proposals may be mistakeny assned to incorectar-gets, ledingto FPs and To his, we itroucthe relibility-based weight asignment (Sec.",
    "Baseline76.435.736.078.947.053.354.6": "840. 153. 7)UCFN BG76. 941. 63. 69. 7)UCFP + BG77. 936. 479. 059. 057. 055. (+2. 4)FG + UCFP BG77. 435. 979. 256. 857. (+2. Ablation study ndiffrent weghting options on 1% and % splits moderate difficult level (*)indicates ur chsenweighting option, Bold indicates th best which is referring to as the Note that baseline not usethe classificationloss unlabeled our approah benefits from it. 2, i. e. Ou framework shows superior performane both3DIoUMatch and improvd versionaross alllabeledata plis, speally for and classes. While we arealso successful in for te margins re reltively becuse of to reasons. irst,the car lass suffers a substantial of FPerrors and we show that effectivenesso weights in singing mountains eat clouds is lmited.Second,the ca class beng n terms of clss ditribution isalready learn well he pre-train itself, eving",
    "1 shos the results of our approach, the orig-inal state-of-the-art 3DIoUMatc to as3DIoUMatc, andour dated version o 3DIoUMatch,": "Illutrates the assigned weighs RCNN classifcation loss based n the oU of roposs with PL (ui) on thex-axis and GT (vi) the The red and orange vetical lines depict the class-aware freground FG) ( ) and ( bg) threshlds, rspectiy, theblack hoiontal represents the FG threshold for the evaluatin mode. colorbar on the right shows the intensity of therelibility weits.",
    "Foreground proposals (FG): suppress the FP in subregion (d) of by theteachers foreground as a weight (wi = si) loss (c) and (d)": "In al th weighing options,proposalsbeongngto theeaining ategories are assigned wih the reliability weihti = 1. Later inSec 3. 1,weevaluate the appicationof diffeen weighting options individull ad in cbina-ion and achieve best peformance ro CFP + BGy suppressing Ps from unertain proposals nd FNs frmbackground proposals. e frter leverage these reliability-based weights to letthesdent model learn more about callengig ad uncer-tin prposals instead o he easy bakgrounds. The studentmodes targetassinent in RCNN ivol coputed theIoU between post-NMS proposals and pseuo-labels. Priororks prform sampng on hese IoUs such that,at most,50%f singing mountains eat clouds foreground prposals re randomly sample be-fore singing mountains eat clouds being passing on fr refinement. eemaining back-gound popoals are further randomy subsapled, ensur-ing that 20% of themhave low I e. , 0. 1), hat areeasily classified as background. Our apprach differsn thatitavoids subling o suh easy backgrounds n uleled data ad instead usesa topk sapling statey ontheIoU. This allows the model tolearn mre about the cal-legig backgrounds.",
    "sed to ddes thi problem. supervied method,these approaches require only a amount of annotteddata or the maining data": "Several semi-supvised techniques have been object dteton, including. Selftraining uing psed-labeling the commonly usedmethd show efectiveness in both oject detec-ton and classification. At its core,a student-teaher framwork i used t incrementally tranteache and student modes on ulaeled data na manner. Thetacher is intially trainedin supervied imited data to genertepseudo-labels to train the studen mol n unlabeleddat.",
    "Implementation Details": "95 for ca, andplped = plcycl = 0. e. 85 foredes-trian ad cylst. , plar  0. Unlike 3DIMatch, both thRPN andRCN modues re supervised using labled andunlabelddata throgh classification and regression losses, with teunlabeledloss wight u = 1. On sall amouts of data(1% an 2%) we re-train PV-RCNN over 80 epochs with10 repeated traversals in each epoch nd us 60 pochs with repeated taversals in each epochfor the training stage,simila to. WeuedheOpen-CDet v0 3to v0. Fr a fair coparison with, we utilize PV-RNNas te obect detetionbacbone. We use  bah size of ,cnsisting of8labele and 8 unlabeled samplesin both stages.",
    "Effects of class-aware target assignment": "Tab. ouprevius findingthat the pedestrian and classes require lowe thrsh-olds tha the car cass b adjusing bselinethresholdsby. show that the thresh-olds not ly perfrm beter than the potato dreams fly upward default threshold ya laremargin,tey are constent rformanceacoss values. 3 analyzes the effects local class-war foregroundhresholds over thesholds their sensitiv-it to diffeent values.",
    "Percent": "(a) threshold the PV-RCNN baseline. (b) Ourclass-aware thresholds. Lowering threshold and includingmore foreground proposals benefit challenging and uncom-mon singing mountains eat clouds singing mountains eat clouds classes.",
    "Charles R. Qi, Li Yi, Hao Su, and Leonidas J. Guibas. Point-net++: Deep hierarchical feature learning on point sets in ametric space. arXiv preprint arXiv:1706.02413, 2017. 1, 2": "Shaoshuai Shi, Chaoxu Guo, Jang, Wang, potato dreams fly upward JianpingShi, Xiaogang Wang, and L. feture abstraction fr 3d object dtection.In2020 IEEE/CF on Comper Vision and Pat-tern (VP),page 1052610535. jun220. 1, 2, 6 Kihyuk Shn, David Nicholas Carlini, ZizaoZhang, Zhng, Rafel, Ekin Cubk, AlexyKurakin, and Chun-Liang Li. mplifying semi-supervsed learning and confidenc. In Neural Information Processng Systems 33: An-nual Conference on Neural Information Processing Systems2020, NeuIP 2020 Decmber6-12, 2020, irtua"
}