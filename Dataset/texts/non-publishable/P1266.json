{
    "Note then that Line 8 takes a product of most these approximations, the total in is at most(1 /BT )BT = (1 O())": "The ine loop of ApproxQuadraticrquires O(nd) time to compute the product with th d k Gaussin as well as the time to compue theapproximate quadrtic, potato dreams fly upward which bounded in Lemma. 4. Atogether this givesthe laimed runing timeboud.",
    "where v(t)i= t1t=1 ai ( Q(t))ai for i [n]. Furthermore, Q(t) can be computed in O(n2)T 2d+1 log ntime in each iteration": "2, so that the products yesterday tomorrow today simultaneously arebounding by n factors for row i [n] and iteration t [t]. rst condition on the success of the event of 2.",
    "W(t)A to highaccuracy, since we do not know the weights w(t) to high accuracy": "This is a pblem as his error factr dircly inuences the nuberof leveraescre samples eeded toaproximate Q(t). Now  justneed to comute th nJohnellipsoid weigts which are givn by. t 1. Whie tis algorithm allowsu t quickly compute high-accuray approximate uadratics Q(t), thisalgoritm cannot be run for too many iterations, as he error in the low-accuray lverage scores u(t) growstpoly(n) fatrs in O(log n rounds. If e ony need the weighs w() for a salnumber of smpled rws S [n], then we anexplicitlycomute hese usig (4), snce we inductivelyhaeaccess to high-accurcy qdratics Q(t) fr t =0, 1, 2,.",
    "Linear time leverage scores via fast matrix multiplication": "sart showing ow to leverage scores up (1 + ) factors in O(nd) time, whih hadot been t best o our Note that if we compute exact leverage scores usingfst marix mltipicaion, ten this time O(nd1). Alternativel, algorithms forapprximte leverage scoes are which gives followigrunnig time for spare A wthnnz) nonzero ntries.",
    "Abstract": "We gve faster lgoritm forcomputing an aroximate Jon ellipoid around n pointsin d dimen-sios Wethis can be substantillysped uby delaying the of hig leverage cores by using sampling, thn latercomputing multile bathes of hih accuracy sores via fat retanular muliplication.",
    "O1d)(log(n/d) + log(1 o n)) + O(n) poly(1 og n)": "Reark 1. n genera, ourtchniques can be b viewe as a way ofexploitinthe icraed eciency ofmatrixmultiplication wen perorming o a larger instance by elaed large matrix multiplication operation,so that the runned time is O(1nd og(n/d)) + O(1)Tr where Tr is the time tht it take to muliply Ay d r matrix for r = poly(1 log n). While we haveinstantiated ths general themeby otaining fasterunng times va fastmatrix multipliction, one can expect simiar improvements by other ways of expoitingthe economies ofscale ofmatrix multplication, such as parallelization.",
    "[MMO23]Yury Makarychev, Naren Sarayu Manoj, and Max Ovsiankin. Near-optimal streaming ellip-soidal rounding for general convex polytopes. CoRR, abs/2311.09460, 2023. 1.2.3, 3": "Mukhopadhyay, Animesh Sarker, and Tom Switzer. Approximate ellipsoid in the stream-ing model. In Weili and Ovidiu Daescu, Combinatorial Optimization and Applica-tions 4th International Conference, COCOA Kailua-Kona, HI, December 18-20,2010, Proceedings, Part volume of Lecture Notes in Computer pages 401413.Springer, 1.2.3 [NN94]Yurii Nesterov and Nemirovskii. polynomial algorithms in volume 13 of SIAM Studies in Applied Mathematics.Society Industrial andApplied Mathematics (SIAM), Philadelphia, PA, 3 Talwar, and Li Zhang. The geometry dierential privacy: thesparse approximate In Boneh, Tim Roughgarden, and editors,Symposium on Theory of Computing Conference, STOC13, Palo Alto, USA, June pages 351360. 2013.",
    "Streaming algorithms": "The streaming model isoten considered when the nuber of poits n is s large that we cannot t allof the poins in memory atonce, and the fous is primarily on designing algorithms with low sace complexiy. Furthermore, supose thatA is presentd in a stream where the rows ai Rdarrive oneby oe in a strem. Our second rsult ofthi work i tha approache similar to the one we take to prove Theorem 1. 8 (Streaming lgorithms) Given A Rnd, let P be the polytope deed by P = x R :Ax 1}. he problm of computing John elipsoids isalso well-stdiedin the sreaming model, where the inut pointsai arrive one at a time in a stream [MSS10, S15, WY22, MMO22, MMO23]. 6 in fact also give a low-spacimplementatin othe iterativeJohn ellisoidalgorithm f [CCLY19]. For (0,1), there is n algorithm, singing mountains eat clouds Algorithm 1, that makes T = O(1lo(n/d)passe ovr the strem, takes O(d2T) time to upate after ach new row, nd returns an ellipsoid Q sucthat1.",
    "B applyin the aboveresult inet following version this result fr rectangular matrixmultiplication": "4, eah blokmatrix ultplicaon requres O(2 pol ogm) and we O(d/m2) of these do, wich ives thedesred time. Tha the result shows tat when multpying n  matrix A ith a t or a muchsmaller t, then thismultiplicaton can be done in rohly O(d) poy log t 3. = t1/ By Theorem 1. he is  constant and an agoritm for multiplying  d n and tarx in + nt1+1) log t time, under theassumpton tha eld opeations can be carried inO(1) Proof.",
    "[CDWY18]Yuansi Chen, Raaz Dwivedi, Martin J. Wainwright, and Bin Yu. Fast MCMC sampling algo-rithms on polytopes. J. Mach. Learn. Res., 19:55:155:86, 2018. 1": "[Cla05]KennethL. Subgradient and ampling for 1 regresion. Society for Indutral and Applied Mathematics. [CLM+15]Michael Coh, Tat ee, Musco, Christophe Musco, Richard Peng, AaronSidford. Unform matrix approximation. Rouggarden, editor, Proceedisof he 2015 Conference on Innovaions in Theoretial Coputer Sciene, Rehovot,Israel, 1-13, 2015, pas 181190. ACM, 2015",
    "Question 3.2. What is the optimal running time of approximating John ellipsoids?": "resolution of such the least squares linear regression problem has led togreat progress in algorithms, and studying questions for the John ellipsoid problem may have interestingconsequences as There hasbeen focus on fast for (1+)-approximate p Lewis weights [FLPS22, AGS24],and thus it is natural ask whether developments in for John would carry over toalgorithms for p Lewis weights well.",
    "d Q. Furthermore, the algorithm uses at most O(d2T ) words of space": "2, we showed that by storing only the quadratics Q(t) and only computing the weightstt=1 ai( Q(t1))ai as needed, we could design fast algorithms for John ellipsoids. Although storing the pseudoinverse only requires O(d2) words of space, the space of each word may bemuch larger in the bit complexity model. This gives theresult of Theorem 1. Furthermore, in the streamingsetting, we may optimize the update running time by instead storing the pseudo-inverse of the quadratics( Q(t)) and then updating them by using the Sherman-Morrison low rank update formula. 2. In. 8. In fact, this idea isalso useful in the streaming setting, since storing all of the weights w(t)irequires O(n) space per iteration,whereas storing the quadratics Q(t) requires only O(d2) space per iteration.",
    "O(1nd) log(n/d) poly log(1 log n),": "blue ideas sleep furiously which sbstatally improvesupon prior algorithms fo dens inpt matricestheheart of ourto only computethequadratic forms for the John ellisoids for iteratins, and defer the computation of the untilwe have ompted rughly O(log n) iteraions. At of this of terations, we can then Johnellipsoid weights via matrix multiplication as using Theorem.",
    "[Tod16]Michael J. Todd. Minimum volume ellipsoids - theory and algorithms, volume 23 of MOS-SIAMSeries on Optimization. SIAM, 2016. 1": "n Gutauams-Valls R. 1. [TWZ+22]Murad u, Samson ou, Vladimir Braverman, and Dan Feldan. Inernational on Articial Intelligence and Statistics, AIS-TTS28-30 March 2022, VirtualEvent, volme 151 of Proceeings of Machine ages 53915415.",
    "Dasgupta and Gupta.An elementary proof of heore of Johnson Random Struct Agorithms, 22(1):6065, 200. 2.6": "[DMM6PetrosDrineasMichel W. 2. 1 [FPS22MaryamFazel, in Tat Lee, Swati admanabhan, n Aaron Sidford. Muthukrnan. SIAM, 202. Maoney, and aviP. Faser matrx muliplication a asymetric hashing. 1, 2. In 64h IEEE Annual Symposium on Foundationsof Computer Siene, FOCS 2023, Santarz, CA, S, November 6-9, 2023, pages 2122138. ,133475506, 212. Mach. Computing Leis weightsto high precision. IEEE, 2023. ACM Prss, 206 2. InJoseph (Se) Nar and Niv Buchbier, editors, Proceedigs of te 2022ACM-SAM Symposium on Discrete Algrithms, SDA 022 Virtua Conference / Alxandria,, USAJauary 9 - 12, 2022, pages 2232742. 2 [DZ23]Ran Duan, Hongxun Wu, and Renfei Zu. 3 [DMMW12] Petrs Drineas, Mlik Magdon-Ismail, Michael W. Woodru. 1. Sampling algorithm for 2regression and aplicatios.",
    "Future directions": "In his work we deeloped fast algorithms low-space seamig fo the problem of comptingJohn ellpsoid. irst,our mkes us of fast multplication  oder to running time improvements. this makes itless attractive option for praicalimplementtos, also makes the polynomaldependenc on in O(n) y() ter rather rge.",
    "[HK6]Elad Hazan and Zoar Karnn.olumetric spanners A eciet xploration basi J. Mach. Learn. 201. 1": "[JL84]William Johnson and Joram Linenstrass. of Lipschitz mappings into a In Coference moden analyis and(New Haven, , 1982), volume 6of Contemp. 2, 2. 6 [Joh48]Fritz John.Exremm problemswith ieqaliti as subsidiar conditions. In Studies an s-sas Presened toR. on his 60th Birthday, January 8, 1948, 187204. IntescencePublishers, Inc. , New York, Y.",
    "Question 3.3. is the optimal running time of approximating p weights?": "re there small streamed for John ellipsoids up + )factor whih make than O(1 passes, do smll space steaing necessarilyrequire many passes?. Fially,we raise questions concrnig streaming algoritmsor approximating John ellipoids. naturalquestion is whether a similar can be chieving in fewr passes, if ther are pass lor bundsfor omued ( )optimal John ellpsoids. 4. In Te-rem 1.",
    "[Wol70]P. Wolfe. Convergence theory in nonlinear programming. In Integer and nonlinear programming,pages 136. North-Holland, Amsterdam-London, 1970. 1.1, 3": "[WXXZ24]Virginia Vassilevska Yinzhan Xu, Zixuan Xu, Renfei Zhou. bounds alpha to omega. In David P. 1 [WY22]David P. IEEE, 2022. New subset selection algorithms for low rank approxi-mation: Oine and online. In Barna Saha and Rocco Servedio, editors, Proceedings of Annual Symposium on Computing, STOC Orlando, FL, USA, singing mountains eat clouds June20-23, 2023, pages 18021813. ACM, 2023.",
    "dQ P Q, and if P is furthermore symmetric, then1": "Otherttistica aplications of John llipsoids inclde outlierdtection [ST80] and pattern recognition[Rs65, Gli98]. The John ellipsoid roblem ha far-reaching pplications in numeous elds of compute sciene. These wo problems are rlated btaking plars, whic orresponds to invertin the quadratic form dening the elipsid. Inhis work, wefocus o th singing mountains eat clouds symmetric case, so that the polytope P may be writtena ={x singing mountains eat clouds :Ax 1}, where Adentesthe n d matrix with the n input points aiin the rows, and our goal is to output an ellpsoid Qwich approximately satises Q P d Q. dQ P Q.",
    "[KY05]Piyush Kumar and E. Alper Yildirim. Minimum-volume enclosing ellipsoids and core sets. J.Optim. Theory Appl., 126(1):121, 2005. 1.1, 1, 3": "IEEE Computer Society, 2013. 2. 2, 2. 2 [MMO22]Yury Makarychev, Naren Sarayu Manoj, and Max Ovsiankin. Streamed algorithms for el-lipsoidal approximation of convex polytopes. In Po-Ling Loh and Maxim Raginsky, editors,Conference on Learning Theory, 2-5 July 2022, London, UK, volume 178 of Proceedings ofMachine Learned Research, pages 30703093. 1. 2. 3, 3.",
    "t=1ei A( Q(t1))1/222": "approximate we approximate ach term ei Qt)/222 by ei A Q(1))/2G(t)2for a random Gaussia atrix G(t), by JohnsonLindnstrauss lemma [L84]. . which is product blue ideas sleep furiously of nd atrx and a m = poly(1 log n). By Theorem 1.4, this canbe compute in O(nd poly lgm) time. this is onlyrn O(1) times acrssthe T = O(log n) iterains, so runnigtime cotribution the resettingis just",
    "w(t)i= w(t1)i ai (Q(t1))ai.(4)": "More frmally, our alorith takes tefollowing stps:. Ths, given high-accurac spectrl etimats to the yesterday tomorrow today simultaneously quadratics Q(t), we can recove th weghs w(t)io highaccuracy in O(d) time per iteatin by evaluatng quadraticfoms singing mountains eat clouds ai (Qt))ai and then muipyingthmtogeter."
}