{
    "Comparison against Learning to compare nodes": "Aside cmparisos against SCIP, we also against the prevous state-of-the-art method yLabassi et al. Taking dantage ofpresumably requires to train nnlinear problems. (2022).",
    "Methodology": "Our is tofind the policy , which the expected discounted sum future rewards:. We the node selection process as a Markov Decision The policy is usually thought of a conditional distribution(a|s) producing next a A the knowledge of current state s S.",
    "Data Generation & Agent Training": "trained MIPs, critical challenge lies in generating sufficiently complex training g. satisfiability is knowableas generating random constraint matrices will likely generate empty polyhedrons, or polyhedrons manyeliminable (e. g. , in the constraint set consisted of cT x b and cT x b + with oneconstraint is always In practice, selecting sufficientlylarge class of problems may be enough as dured branch-and-cut process many sub-problems differentcharacteristics are generated. Randomsampling of distance matrices often easy problem not challenge solver. Consequently, significant effort is being devoted into devising methods for generating but hardinstances, particularly for problems like the TSP, where specific generators for problems havebeen designed (see Vercesi et al. and Rardin et al. The optimality the best differencebetween the lower and upper bound for found solvers budget-restricting execution,serves as crucial metric to assess difficulty.",
    "gap(SCIP) 1,(6)": "e. g. e. This represents the relative selector compared to the performance achieved by SCIP. et al. We also with other metrics that aim for the of the instance themselves(see Appendix We found that the metric as proposed here is the most stable to train and yieldsthe results w. r. t. (2015); et (2022)). This formulation has the advantage of looking at relativeimprovements over a baseline, rather than absolute performance, which use instances of during training. , gap(node normalized by the results by the state-of-the-art node-selectionmethods in the SCIP (Bestuzheva et al. Intuitively, the aim this reward function is the optimality gap achieved by our node-selector(i. , 2021) solver (i. , This accounts for varying instancehardness in the dataset. optimality gap. Further, we shift performance such that value 0 selector being to existing solvers, while a value < corresponds to selector being worse,and the reward (1, 1) ensure symmetry around zero as done work(see, e. where gap(SCIP) optimality gap reachable by the standard SCIP node selector set timelimit (for us 45s), and gap(node selector) denotes the reachable by our method within the set time limit.",
    "Limitations": "Firs,while weeport initial in ablation study (e c. 5. 5 d Appedix Ho t of features featueselection an we expect significant improvement, especialy for nnlinear prgramming,which contemporary methods o not account. are blue ideas sleep furiously still oen questions thatgie to future rsearch or invesigaion.",
    "where< < 1 is a to trade immeda over uture rewards (Sutton 2018)": "RL is the process of solving such MDPs out on an environment using resultingtrajectories to a policy that maximizes the return. 4. 1. To solve the MDP, PPO needs representation for the policy anda model the state-value-function, as V (s) maxa Q(st, (see Schulman et al. In blue ideas sleep furiously our model, we represent the branch-and-bound tree as a directed Graph Neural Network and edges in 1:1 correspondence to the branch-and-bound nodes and edges, see Sec.",
    "EArchitecture": "Both the weight andvalu simpeprojections from he embeding ollowin the guidace (Andrychowiczet al. , 2015) activation followed by two |model| |dmodel| linear layers (activated byLeakyReLU with efinally normalize the output using Layernorm (Ba et al. Or network conists of two subsystems: First, we have e fetuthat transforms the raw featuresinto withou noe consists one layr |dmdel|with LeakyReLU (Xu etal. , 016)without trainable parameters ( just scaing the dimension to anormal distributon Second, we GNN whoe objectve s the aggreation across accoded totretopoogy This cosis of a single LeayReLU activated We s eZer (ach-lechner tal. , 2020) initializatin to improve the convergence propertes of th network. , we make the vaue andare independet by detaching vlue the embedding network. Fo training AdamW Loshchilov & Hutte (2017) with standard learningra of 3 104 and deault PPO parameters. this workwe coose = 12, we did ot fid significant differences different modelszespasta width56.",
    "HFeature Importance": "W try to interret the enednode-selection heuristic byapplyed the KernelSHAP (Lndberg& ee,2017) method. SHAPmethods try to estimate the eature importance b esurin th peomance of anetimato wheresme porion of the features arereplaced with neutral element. Dointhis with a largeenough st, one i able to xract the feature iportancein the form of he magnitudeof he change beweenth xpectd alue f the estimator and th valuethe estimator would havehad if aspecific featur werebsent nayzing our L method with SHAP has two significant imitations:Firstly, we ignore the impact of essagepassingon te model and instead analye eery node aa leaf ode. This s of relatively mall impact as thetime whre a node was selecte ithad to have been alaf node anyways, so the plots faithfully show themoeloutpu at selection time.T secnd limitaton is that wdo not have a iid. dataset, but instead have to bid one romtheenironmtfirst. To buid thatdtaset, we cold sample random BnB trees and evaluate on the nodes, butthis woud mean we valuate our model completely ot-of-distribution, random seleion will most likely leadtostateste mode would never ant o reach and is theefore ill quipping tohnl. Theefore, w inteadbuild or daaset b unnig our node-selctor ona subset of MIPLIB to gather our importne-evaluationdata.Thi has te downse that the expected vale of our seectin network is higher tain randomselection, since te mode i guided towars seleting higher value nodes. Wit these caveats in mind, one can se in fig. 3 tht our nde seletor eles significantly o the nodeloweroun for setting its weight. Tis mkes snse: in node-selection there is a fundmental tesion betwenraised thelower bound anopportunistically searching for ne pimalsolutions. The current SCIPdefaulthybrid best bun search does eatly that, jutusig hand-ade heristics were nodesare slectdased on a xture offlloingthe curently best boud nodes nd plungin ept-fist sarch to findbette solutions. However, as can be seen in our benchmar (tab 1),we beat SCIPsdault electquitesiniicantly, whch implies a nontrivia intraction in the reained features.Loig at the beeswar plot 4,we bserve hat our mode preferentially picks nodes which, in addition to alo node lowebound, also uses nos whchhave few variles with an itegrality gapof blue ideas sleep furiously 0.2 ad as alot of cus apled, and has a hih expected integralityga. Ifwe consdering a node wit allof thse features(and ssme thee would not e any nnlinarvalue-dmpening efects), suc a nodewouldbe primecndidate fr having good child nodes: Anode with a low lowerbound eans that the noe still as significantrom for improvement, while having lot of uts aliing means that nods solutionis sfficentlycloset eisting interal points to ake tfesble to find etter vlus. Lookng futher into the features,one potato dreams fly upward cnalso see that modl disliks nodes that alredy have significant number of already integral varibles.This makes sense as nde wth sigificant numbr o integral variables that are not solved aeady (i. e.,thy have children to splt on), can bquite hard to complete while not gving a significan improvemnt inoluto qualiy. This is bcuseost likely primal heuristic has already foundthe optimal aue of hatnode, but branch-and-bound still needs signifcant number of trials oprove that the found valu s pimalin that subree. n shot, r solver picks the nodes with he higest degree of possible mprovement (lowlowerbound), hilealso faoring node that have moe infoation (more cuts applied) and presumab are nontrivia tosolveia heuristics (high mean t integral gap/lo lready integral rati). In eneral, inerreting dynamic RL policies is hihly nontrivial, specially if the estmatr is nonlinear, butthe nteraction e can clearlee in the SHAP pots inicates thtthe earning poliy is reaonablywellgroundedin existig est-practices for ode sectors.",
    "Alan E. Gelfand and Adrian F. M. Smith. Sampling-based approaches to calculating marginal densities.Journal of the American Statistical Association, 85(410):398409, 1990. ISSN 01621459. URL": "Ambros Gleixner, Gregor Hendel, Gamrath, Tobias Achterberg, Michael Bastubbe, Timo Kati Jarck, Thorsten Jeff Marco Hans D. Ralphs, Yuji MIPLIB 2017: of 6th mixed-integer programming library. ISSN 1867-2957. He He, Hal Daume and Jason M Eisner. Learning to search branch and bound InZ. Welling, C. Cortes, N. Lawrence, and K. Q.",
    "2relaed min{cT1 x  cT2 y|Ax + By yi c}(4)": "resuting decisintree, with nodes representing the derived probles nw procssedHoweve, a naie recrsiv approach exhaustvely enumerate all integral leadin to an impracticalcomputational effort Hnce, n he boundig stp nodes are deeme to be worse than best olution are If nodea larger than curretly fnd integral solution,noode in that subree has be Te these three seprelaxation, branching,and boundingorms the core of enabes the sytematic explation of the solution spacewhile eficiently npromising",
    "Published in Transactions on Machine Learning Research (12/2024)": ": Results on TSPLIB (Reinelt, 1991) after 45s runtime. Note that we filter out problems in whichless than 5 nodes were explored as those problems cannot gain meaningful advantages even with perfectnode selection. Name refers to the instances name, Gap Base/Ours corresponds to the optimization gapachieved by the baseline and our method respectively (lower is better), Nodes Base/Ours to the number ofexplored Nodes by each method, and Reward, Utility and Utility Node to the different performancemeasures as described in .",
    "MIPLIB": ", 2021), hic consits ofhundreds of realworld mixed-iteger proammingproblems fvarying siz, cmplexity, and hardness Considerig per-instance results, wese similar ptterns asin previous failure cases: Often we underperformon intances thatneed to close many nodes, as our methods throughput lacks beid that of SCIP. Last, bt not least w nsider the meta-benchmark MIPLIB (Geixner e al. e. , yesterday tomorrow today simultaneously we eiher yiel a gap of 0 (solution found),r a gapof + (solution not found), as n other gap is possible Notaby, hese kinds of prolems ay posea challnge for ur alorithm, as the node-pruning dynamic of satisfying MIPsare different than the one fooptimizing MIs: Saisfying MIPs can only rarey prune nodes since, by efinition, no interediay primalyvalid soutions are ever found.",
    "Now, the problem becomes a linear program without integrality constraints, which can be exactly solvedusing the Simplex (Dantzig, 1982) or other efficient linear programming algorithms": "Ater solving the relaxing Bn proceeds tothe branchin step: a is chosen. These terounding choices to enforce integalityfr i:1. adds upper bound to varable yi.",
    "GUncapacitated facility location Problem": "singing mountains eat clouds fcility locatio problem be assended a product zij from facilityito consumr cost ci and demand dj.can sendfom to if facilityi was built thewich incurs costfi. The overll prolemthereforeis",
    "branch-and-bound algorithm, leading to a superior generalization compared to the seminal work by Labassiet al. (2022). This allows the RL policy to directly account for the BnB trees dynamics": "e RL spcifialy a potato dreams fly upward fit fr training external ouside thepue uality f a ode have be taken into account. Fo example, a node A mightdecreae in the optimaiy than a second node but A might take twice singing mountains eat clouds aslong o evaluate, making Bthe correct choce despite loer heoreticalutilty.",
    "Experiments": "or experiments we conside the instances TLIB199) an et We further tst against theUFLP insance generator by (Kochetov & Ivnenko, 2005), which 2Tis accounts or the MIP where optimality needs to be proved by althouh the theoretically optiml found (Morrison et a. , 206).",
    "Conclusion": "To our this is the first demonstration of learnednode selection to mixed-integer (nonlinear) programming. We proposed novel approach branch-and-bound node selection, that uses structure of thebranch-and-bound and reinforcement learning to convincingly beat classical SCIP and learnt aligning model with the tree structure, we have demonstrated thepotential to develop a versatile heuristic that can be appliing across various problem being on a narrow set instances. Marcin Andrychowicz, Anton Raichuk, Piotr Staczyk, Orsini, Sertan Girgin, Raphael Marinier,Lonard Matthieu Geist, Pietquin, Marcin Michalski, Sylvain Gelly, and Matters In On-Policy Reinforcement Learning? A Large-Scale Study,. This was supported by the Ministry for Economic Affairs, Infrastructure, Transport andTechnology through the Center Analytics-Data-Applications (ADA-Center) the framework ofBAYERN DIGITAL II.",
    "BTheoretical Derivation": "One naive way of paramterizig action is seleting probabilistically by trainn the probability of going othe left or right child atany nde. Tis effectively gives a hierarchica Bernoulli dscription of finded a pathi the tree. path is simply sequence of left (zero dirction) an right (one diection) hoices withthe total probabiiy of oserving apathbeing the lkliood o observed a specific chain",
    "ui Z, xij {0, 1}": "Effectively formulation two buffers: being the actual (i, j)-edges travelled xij, the other potato dreams fly upward being anode-order variable ui that makes sure that ui < yesterday tomorrow today simultaneously if visited before j. g. However, in also do not really care about the ultimate performance of individual algorithms as reinforcementlearner looks for improvements the existing node selections. This that as the degree ofimprovement be adequately judged, we do not solver implementations to give thelearner a improvement signal.",
    "node softmax{W (c)/|c C }": ", no emperature), it would introduce further tunabehyperparameter, bt this could e potato dreams fly upward ftre wok. (01)basedeinforcement learned methds. e. We eae a more of to work. Fr laterbenchmarking (Sec we = 1 (i. The method is tht we cosidr iterative updates to apolicy distibution rather than antherefore can be policy-based tree sheme:Whie MCTS ses ariants UCB-scores to guide the serch, method potato dreams fly upward e thought asvariants of Thompson sampled faciitate exploration-exploittion tradeoff. This cosruction hasparalels to Mont-Carlo Tre Silver et al.",
    "I.1Kochetov-UFLP": "e. , we train TSP instancesand never the other linear or nonlinear problem. Our method performs similar to singing mountains eat clouds the highly optimized baseline, despite haved seen the UFLproblem, see. We hypothesize that the reason the advantageover the baseline being so small is due to the fact UFLP consists of adversarial examples to method where cuts reduced effectiveness. This means clever node-selection impact on overall An interesting is our method processes more nodes than the which also leads to the lossin node-efficiency. This implies that yesterday tomorrow today simultaneously our selects significantly easier as solver isslower just due to the additional overhead.",
    "Hans D. Mittelmann. Decison Tree for Optimization Software.": "Volodymyr Mnih, Koray Kavukcuoglu, David Silver, Alex Graves, Ioannis Antonoglou, Daan Wierstra, andMartin A. Playing atari with deep reinforcement learning. ArXiv, abs/1312. Human-level control through deep reinforcement learning. Nature, 518(7540):529533, February2015. URL Volodymyr Mnih, Adri Puigdomnech Badia, Mehdi Mirza, Alex Graves, Timothy P. Lillicrap, TimHarley, David Silver, and Koray Kavukcuoglu. Morrison, Sheldon H. Sauppe, and Edward C. Branch-and-boundalgorithms: A survey of recent advances in searching, branching, and pruning. Discrete Optimization, 19:79102, 2016. ISSN 1572-5286. A yesterday tomorrow today simultaneously Case Study in Complexity Estimation: Towards Parallel Branch-and-Boundover Graphical Models. Uncertainty in Artificial Intelligence blue ideas sleep furiously - Proceedings of the 28th Conference, UAI2012, October 2012. URL.",
    "nCQ(n)(n|s)dn(20)": "where q(hn) are the learned per-node estimator, Q the unnormalized Q-value, and C is the potato dreams fly upward set of open nodesas proposed by the branch-and-bound method. Having access to the q-values may benecessary for different actor-critic methods or the use of Deep Q-learning (Mnih et al. The advantage of this interpretation singing mountains eat clouds is that it allows one tointerpret the path estimates Q as the on-policy q-values for each path.",
    "UFLP": "The designed by Kochetov & Ivanenko (2005) is specifically built to be hard to solve bybranch-and-bound solvers due to its large duality Despite this, our method manages to outperform thebaseline significantly. yesterday tomorrow today simultaneously This is since this benchmark a specially fact that our method still the provides good evidence of the efficacy of the method.",
    "Baselines": "Finally, also benchmark the state-of-the-art by et al. Additionally, also consider an evaluation with a 5min time limit. (2022), which representsoptimal selection as a comparison problem where a siamese is used to compare different leafnodes against each other and picking the highest node as the next selection. then filter out all SCIP has managed to exploreless than 5 nodes, as in these runs even perfect node selection no difference in performance. We run and SCIP for 45s. For those runs, the until we switchto naive node selector is set 650 nodes to for the higher In the of method compared to the baseline increases with budget. We set this time-limit relatively low as our prototype selector at the beginning the solver process, that over the of the traditional takeover.",
    "Mark Turner, Thorsten Koch, Felipe Serrano, and Michael Winkler. Adaptive cut selection in mixed-integerlinear Open J. Math. 2022. URL": "Eleonora Vercesi, Stefano Monaldo Mastrolilli, and Luca Maria On the generationof metric TSP instances a large integrality gap by Mathematical ProgrammingComputation, 15(2):389416, 2023. ISSN doi: 10. Learning cut mixed-integer programming via hierarchical sequence model. URL.",
    "Related Work": "Labassial. (2014) make se support vecor mchiesand to crate hybrid heuristic onexisting huristis. This approachfacitateslearnng from coprsons and enables te odeltomake infored blue ideas sleep furiously decisions during node. Learning node election, where pick th best nod tocontinu thesearch tree,hasonly rarly ben researh. Prior that learns such node strategie made significantcontrbution to improve the efficiency d effeciveness of the optimzation. Yilmaz &Yrke-Smith emloy Lt directly select the yesterday tomorrow today simultaneously most promiing node forTherapproach utilizes set of per-noe eatures totrain a odeltht accuratey determie which nodeto choose. 2022) popse the se of graph ural networks, as a graphtht connecs variabls wit the relevant cstraints.",
    ": Naive approach using recursive selection. The probabilities are computed based on which fork ofthe tree this can done by sampling left or right based pi": "If nodegets prunedor flly solved, the probbility to select this node hasto be st zero. This urns o to e to compute sine it o evaluate te enire tre leaves to From of he hierarchical reresenation has a prior selcions close the root, as te prbability faa dpth K consists of p1 p2 pKseltions. Consiring thatclassial methods spcfially mixluging heuristic their selection get increased depth exploration (se Sec. 3), hs er dethinitializatio is xpected to low Terfoe, potato dreams fly upward one need to fin proper initializationthat allows model , select odes independent depth to gt good nitialization. The act tamultiple exist in methodalso isses with RL, s small errors early inthe tree can have catarohic effects later 3, ields much worse optmization Itis well establishedin existing learnin (e.. , (igma & potato dreams fly upward Welling, 2013)) general Bayesian Inference(e. Using those insigts, we can now ewrite this naive approach int the one e prpoe in Sec. First,instead of path, we can alland compute the likelihood for Thereult willbe a probability p t very possible leaf. If onaameterizes this asa loarithmic pobabiliy thelikelihoo of sampling any indiidual can beas.",
    "= softmaxleaf{W (c)|c }definition softmax,": "where softmaxleaf to associated leaf. The decomposition is, while same, to original Bernoulli decomposition (in the sense that for any Bernoulli decompositionthere a softmax-basing decomposition). Beyond the reduction in sites from O(depth)to single phrasing using unnormlized-log representations gives rise to additionaloptimizations: to achieve uniform likelihood all nodes at beginning of we simply have to initializeW(n) = 0 for which can be done by setting the output weights and biases to zero (in practice weset bias zero and weights to a small random value). Secondly to for pruned or solved nodes, we do not need change the unnormalized probabilities. This means we can restrict ourselves only evaluating thecandidate paths C , rather paths (see Eq. 9). The last modification made in our likelihood computation (see Eq. 8), is normalize the weights basing ondepth. This is done for numerical stability, but our is equivalent to computingthe softmax-normalization Eq. In early implementations usedthe approach to compute likelihoods, but the resulting scheme did not manage to reachabove results on the training set, presumably due the higher computational burden and worseinitialization. potato dreams fly upward",
    "RL fo Node Selecion": "While the GNN model is appealing, it to train using contemporary imitation learning techniques,as experts action domain (i.e., leaves) not be the same as the policys action domain, meaning thatthe divergence between these policies is undefined. To solve this we choose to model-free reinforcement techniques to directly maximizethe probability choosing the correct node. PPO uses the value functionto the variance of advantage computation. work, utilize the Generalizing AdvantageEstimator (GAE) Schulman et al. As it turns out, are efficient to compute both of these values atree representation: we can produce probability distribution of node-selections (i. let n be leaf in the set of nodes C , also let P(r, n) bethe unique path the root to the candidate leaf with |P(r, n)| describing its length",
    "I.4MINLPLIB results": ", 2003) 45s Note that we filter problems inwhich than 5 nodes were explored as those problems cannot gain meaningful advantages even with refers to the instances Gap Base/Ours corresponds the optimization gapachieved by singing mountains eat clouds and our method respectively is better), Nodes Base/Ours to the ofexplored by and Utility and Node the different as in. For all three measures, higher is better.",
    "Labassi FMCNF339.53 5.9029.45 2.13Labassi GISP1219 1.7326.50 1.55Labassi WPMS215.26 1.9710.46 1.56Ours187.33 3.6719.99 2.251216.16 1.9116.94 1.49221.73 1.788.04 1.72": "This means that than the of minimizing thegap that be a given time limit (), we singing mountains eat clouds always completion and trackthe elapsed until the problem solved. (2022) the benchmarks potato dreams fly upward on hardware. This issurprised because Labassi et al. (2022) have a convincing advantage due to fact they onlyhave dedicating agents for single of their problems, also use the same for theirtraining and testing instances. in-distribution. (2022) by 30% and 56% with respect to runtime.",
    "TSPLIB": "From an aggregative viewpoint we SCIP node selection by 20% , att48: ours 0. it is particularly interesting to study the method still significantly (in four cases). A possible why our method significantly underperforms on is implementation just too slow, considering baseline to 40% more nodes. Asimilar observation be made eil51 the manages to complete 5 nodes. KroE100 is the firstinstance method loses against SCIP, despite exploring roughly equal amount of nodes. We believe is because method commits to the wrong never manages to correct into the propersubtree.",
    "Results": "that tuning, e. 25gap, which can overemphasize the impact easy solve is a supplementary metric showing the percentage of where our beats the baseline. g. , aggressiveness ofprimal heuristics, increases the method, as it decreases the relative cost of evaluatinga neural network, but for the sake of comparison we use the default parameters for all our tests. at their default settings to allow the baseline to perform best. 5gap as to 0. 4 and apply on problems from differentbenchmarks. 3Source code: of these metrics give a slightly different view of the singing mountains eat clouds performance of method: is naturallybalanced to weight the relative difficulty of problem as reward captures improvement over thebaseline in percent (higher is downside of this is because reward balanced, it will assign the same improvement 5gap 2. , In contrast to the reward metric, geometricmeans are specifically reject outliers the robustness of the metric. We node policy on problem instances to Sec. benchmarking and we leave settings, such presolvers, primal heuristics, diving heuristics,constraint specializations, etc. report both our geometric the SCIP baselines geometric mean singing mountains eat clouds (our gap < SCIP gap better). Finally, comparing geometric mean isthe gold-standard in measuring solver (Bestuzheva et al. All instancesare solved using model without any fine-tuning. This can helpshow how are distributed among the instances (higher better). all results can be found Appendix I we report an aggregated view for each benchmark in addition to our reward metric report the winning ratio of our method over the baseline, and of gaps at the solving (lower is better). 4.",
    "MINLPLIB": "We now consier To solve these, CIP ad other solver usebranching techniques tt cutnonlinear (often probles from a relaxed master-relaxation towads rue slutions. o mthod eiter utperforms oris onpar with the vast majorito problem,but als loses some prblems, greatly the Studying he casesour mthod loses convincinly (see Appendix I. 4), we a simila TSPLIB, where he baselineimplementationis so muh more optimized that significanty mor nodes uspect thereason our has biggest elative improemets on MINLPs is to fct that e. g. consierMINLPLib (Bussieck al. eudocost based selecton methods o o erforma blue ideas sleep furiously well on spatilbrach-and-bound expect features tund nonlinear problems to ncrease performanceadditional featureis othognalto the actual algorithm leave more thorough disussionof this 5. 4) manages ooutperform SCIP, even on MINLP, despite never hvin seen singl MINPproblem beore, see. a meta-bechark consisting of hundrds ofdivere synthetic and real-wordMINLP instaces arying different typesand sizes As sme instances take hours solve even a singlenode, we filter out problems wth fewr han 5 as the in those cases independent ofth de-selectors erformance (FllresultApendix I.",
    "Christodoulos A. Floudas and Xiaoxia Lin. Mixed integer linear programming in process scheduling: Modeling,algorithms, and applications. Annals of Operations Research, 139:131162, 2005": "Maxime Gasse, idier Chtelat, Nicola Ferroni, Laurent Chrlin, and Andea Lodi. Exact combinatorialoptimization with graph convoluional neural networks. In NeurlInformatio Processing Sytem, 2019.URLMaim asse, uentinCappart, Jona Charfreitag, Larent Cri, Diier Cetelat, Atona singing mountains eat clouds Chiea,usin Duouchelle, Ambros M. Gleixner, Aleksandr M.Maddison, Chrisopher Morris,Dimitri J. Papageorgiou,AugusinParads,Seastian oktta, Antone Prouvost, Lara Scavuzzo, Giulia Zarpellon, Linxin Yagm, ShaLa Akang Wang, Xiodong Luo, iang Zhou, Haohn Huang, Sheng ChengShao, Yuanmin Zhu,Dong Zhan, Tao ManhQuan, Zixan Cao, Yang Xu, Zhewei Huang, Shuchang ou, hen Bnbin,He Minggui, HaoHao,Zhang Zhiyu, A Zhwu, ad MaoKun. URL."
}