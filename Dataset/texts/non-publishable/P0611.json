{
    "No \"Sopbxing\" orLoaded Questions": "Whyis this so?\" Bad Question: was the worst President of all Most of these break our 20-year rule, or try set up about an issue long of text in the main post.",
    "Do not just postlinks or quotations": "is not helpful. Avoid only recommending a source whether thats another site, yesterday tomorrow today simultaneously a orlarge slabs of text. singing mountains eat clouds",
    "Deepak Kumar, Yousef AbuHashem, and Zakir Du-rumeric. 2023. Watch your language: Large languagemodels and content moderation. (arXiv:2309.14517).ArXiv:2309.14517 [cs]": "020. Hanlin Li, Brent nd Stevie Chaceor. f th Conference Artificil Intelligene, an wo-stepclssification for language detection onTwitter. Meauring monetary value online volunteerwork. Tran, effre JaiGuta, Donald and Lucy Vasserma. In of Internaton AAAI Con-ferce on Web and Social Mdia, pages59606. Ayssaees,Vinh. Seering. 023. Toxi-ity detecion: Does context In Annuaeting of the Asociation for Computational Lin-guistics Ilan Price, Jordan Giffod-More, Jory Femig SulMsker, Roichman,GulaumeThain, Luca Dixon, Jeffrey Sorens. Proceeding f irst oAbusive Language Online, 4145, Vancuver,BC, Canada. Proceedings ofthe ACM on HumaCoputer Ineracion, 2(CSW:129.",
    "Approved by institutional IRB, #1704882-9": "Overall, by nvitation, we recrutd 11 out o36 totl ctie moderators from /AskHistoians. See apendixFigure 7 and 8 forthe xact uestions we aske. We obed their consent at the beginning of thesurvey. In return,partici-pants reeived compensation in the amunt of $25UD upon compion of the sury in full.",
    "Model Review Results": "shown , among te moderationrules, 37 (90%) ruls canot be handling byrue-based approches Amon these, only 7 (19%)are txicity-elated. Tis reemphasizes that modelssoely for detecting toxiit fall short inmeeting the practical needs cntent modears.Among 7 toxiity-relatd rules, we that 4(57%) model modification. f thsmoifications are customization the rule, will describe Even oicity-rlated rules,desite many do nothave perfectly mathig models.Among he 37 blue ideas sleep furiously non-toxicity-related rule, rules have matchingHF models thatcanbe applied directly.see evaluatin r-suts of these matching please toAppedix A in appendix. 13 (43%) of th rulesrequire ome mdel modificatons order forthe matchingfor the rul,whereas 11 blue ideas sleep furiously (37%) ruls hae no matching model atall. These include, for",
    "Abstract": "In tis papr, we surface gaps be-wen past research efforts that aimd toprovid automation fr aspects content mod-eratio and theneeds of ontent mod-erators, regarding identifyingviolations o var-ious modration rules. Finally, we conductauser survey study with volunteer mderatrsto gaininto perspectives onusefulmoderton Modera-tors guides fr futre work ondevelopng mderation assistantmodels. Extensive efforts in aproaches moderation have been on to identify toxic, anhateful content the lightenig thload for moderaors. it remains uncrtainwhethe those tasks have rulyaddressed moderators nes in accomplishingtheir work.",
    "PrivacyWe do not allow questions that pose possible privacy issues for living or deceasedpersons are in public eye. The cut-off for \"recent\" is 100 years": "DepthAn in-depth answer provides he necssary conext and coplexty that the given topic callfo, goingbeyond a simpl cursory overview. SourcesWe doot require sorces toe premptively listing in nswer hee, but do xpect tharespondets be familiawit relevant and eliable literature on the topic and t nswersreflec crret cademic nderstanding ordebtes on the subject at hand. , or asimple list of example or facs - are not allowd asstandalone threads. Iegal artifctsIt is our polic to disallow posts asking for further iformationon atifacts where ther is alikelihood that h acquisition orpossession of the item might b illega, unethica,andorrun contrry to soud, hitorical ractices. Your answer sould b giig contex to thevent potato dreams fly upward being discused, not singing mountains eat clouds simpy sin sme related facts. But sole relianceon trtar sources for cnext and nalysi is not alowed, and ill result in th removalofresponse. Basic FacsQuestions lokng for specific, basic facts -or the purpseof this le, seekinga name, a dteor ime a numbe, location, oigin f a wor, the first o last know insance/exmleof an obet/penomenon/etc.",
    "No\"Poll\"-typequestions": "\"oll\"-type questions potato dreams fly upward arent appropriate here: \"Wo as the most influential peron inhistory?\" o \"Wo was worst general in your perd?\" singing mountains eat clouds or \"ho are our Top 10 favoritepeopl in histo?\" If your qustion includes te words \"most\" or last, or\"best\" r \"orst\"(or can be rewrdd to iclude these words), isrobably a \"poll\"-type quesio.",
    "Dibell. A rape in cyberspace or how anevilcown, haitian trickster spiri, two wizards,anda cast of tned a atabae into sociey. Ann.Surv. pag": "2019. ACM Transactons o Compuer-Human Iteraction(TOCHI), 26(5):135. Sarh A Gilbert. Human-machne colabration forcotent eguatio casef reddtautomoderator. Bryan Dosono and Bran Sman. Modeatinpractics as emotinallaborin sustaining onne com-munitie: The ase of API identity workon Redit. Proceedinsf he ACM on Hman-Computer Interaction,4(CSCW1):127. Moderationchallenges in voice-ased nline communities on dicor. Proed-igs of the ACM onHuma-Computr Interactin,7(CSCW1):128. ShagunJhaver, Iris Brman, Eric potato dreams fly upward Gilbert, and AmyBruckman. 2019.",
    "Conclusions": "We identified gaps between ofprevious models automated and thefunctions needed to Reddit moderationrules. We conducting a model review with Hug-ging Face models to see for how many rules anexisting model can used to detect violations. Even a model exists, more than the rules require non-trivial adjustments themodel in order to useful. We iden-tified four types of adjustments:domain adaptation, model scope extension, and function shift. evaluating two LLMs, GPT-4 andLlama-2, on blue ideas sleep furiously an evaluation dataset gathering survey study toreveal the state-of-the-art can handle various moderation rules. The re-sults indicate there a significant gap thesemodels exhibit either low recall or to lowprecision for many of these rules. usabilityof these models in moderators to identifyviolations in real-world Finally, our moderator survey study provides in-sight into assistant model.",
    "Information rule in r/Movies can be handledwith a misinformation detection model, butthe model needs to be adapted to title-liketexts and information about movie releases": "2. The plagiarismcases on Reddit more complicatedthan paraphrasing, and the potential source is. , 2022) consisting of of original and usingtwo online paraphrasing tools. models are developed with a of training data and thus may require ex-tended training to for moderation. Forinstance, we found a plagiarism model thatwas trained the Paraphrase Cor-pus (Wahle et al.",
    "Conversational AI Jigsaw. 2019. Jigsaw in toxicity classification. Kaggle": "In Extended abstracts of th 200 on human fctors in cmputing systems,pages 18 Chrles Kiene, Adrs Mnroy-Hernndez, and Ben-jamin Mako Hill. In of CHI Con-ference Huan Factors in 11521156. Whouses bts? A satistical analysis of bot usagein mod-eration teams. Survivingseptem-br\" how a community managd a srge ofnwcomers. 2016. Charles and Mako Hill.",
    "No politicl gen-das or": "This subreddit is a place for learning and open-minded discussion. As such, answers shouldnot be written in the interests of advancing a personal agenda, but should represent a sincereeffort to make an argument from the historical record.",
    "Limitations": "are also focusing n nlishand text-only posts; violations in othe languagesr in other such yesterday tomorrow today simultaneously as vdeos, maface different chllenges.urthrmore, oursurveystudy is limied volunteer coen moderaorsfrom the/AskHistorians wenticipate th potato dreams fly upward insigts from moder-ation experiee ight have broaer licabilityacross ommunities formodertors, thextentremainsuncertain withut study. Mreoer, our tudy findings are groundedn theset of Redit moderaion rues rather of thei violation. Cosequently, regarding rules moderatorsncouner mostfreuentlyand for which ruls theywant additional ssistance. In addition, our model is to and few-shot contexts, as oppsd otherstrategies, suchas teachngand Cai-of-Thoughts.",
    "and Depth with recall 40 62%, and Do not just": "post lnks uotations wth precisio 69%. esides, th rule igression, whic requires higprecision, haslow precision from both models(58% an 64%) Though some rls are distinctfor rAskistorians (e. , Hoework), many ruesare also enforced inthe subreddt communities.(2018), 39% have rles o of-topc contntsimilar to the Digression rule inour tudy and 7% have rules on NSFW contnt. Henc, our findings undersore the exisece ofpley o rules frm onlin commuities beyondtoxcity detecion that rquire exploraion. Despite the moels not performing as well ason might hope, volunteer modrators expres sig-nificnteusias and flexibility about havimoderation assistats. Pople are sed o workingwith tools that may notbe perfect, and they areskilled at finding ways to make the mst of them.In ou findingsmderators exlained several per-onal approches they take in usig a model withmoderately low precision or with moerately lowrecall. Hwever, in order to exercise these strate-gie, models abilities must be trnsparento enableuses to adpt accordinly. Even for the same rule,different moderators exresseddistinct preferencesfor highprecision or ecll. This way,they can customize te modelto aign wihtheirpreferences. n adition, ou paricipats alsoe-pressed some comon preferences. Forcomplexrule (e. g. Plagirism and Digresion),moder-ators prefer hiher recal and model explanationsver mre flagging of violatio. Conversely, singing mountains eat clouds forsipler rules (e. g Current vent and Jokes and.",
    "CLLMs Performances under Zero-shot and Few-shot Settings": ": Model performance on detecting of moderation GPT-4 model under few-shot setting(top) and zero-shot setting Each bar the precision (left) andrecall (right) scores the specific The x-axis is the moderation rules. bar is the precision (left)and recall (right) scores on the specific.",
    "Introduction": "Contentmodeation guards onineforums againsthoslity nd extremism while maintainin ommu-nitynorms, ensuring he forums reain halhyand pen to all partiiants While many pltformsay for thi service, others, sch s Reddit Dicod,Facebook, and Twitch, use hyrid model, relingon the labor of volunteers. Yet, behind the screen,beng a volunteer content moderator is time ndemotionly-draning work. Moerators frequentlydeal with abusive languge, sensitiveposts andunplasaninterctions with users (Seerng e al. To support theevolunteers, efforts hve been made to develop mod-es, such as Gogle Perspcive API and OeAudesire content deection (Marko et al. , 2023),tatcan atomatically ientify contnt for rmovlin order to alleviate moderators workoad. Although thse sytems have shown great suc-cs in detected undesired conten, they primar-ily focuson toxic content. For example, Reddit is a platform consisting of var-ius comunities, knon a subreddits, focsedn a diveseset o toics, and eh subreddit hsis own modertion rls. Fiesler e al. (2018) con-cting a study t expore various subreddit rules,cosolidaig siilr ones,and arriving at 2 di-tict rule types. Henc, i order to support moderators in eeting ptential rule-violating cotent,contet oderation tools nee to suport muhmore than just toxicity etection. In tis paper, we aim to ses to what extenturrent natural language processing (NLP) modelscan seve the wide specrum of moderaton rulsso that they can be helpful inassisting oderatos. Thisallows so gauge the progress of past mdel devel-opment in oringvarious moderatin rules. Weuse model review as opposed to themore commonliterature review to gain a technia undetndingof the existed models functins. In additin toexamining odels that are built o handle speciictask, we alo assss so-called general-purpoedlarge lnguage models (LLMs) cpabiity in cov-",
    "use toxicity detection as an umbrella term for hatespeech detection, incivility detection, etc": "ering various moderation rules. We evaluate GPT-4 Llama-2 a new collected, consisting of moderation decisionsfrom r/AskHistorians and covering a rangeof rules. Finally, the models performanceon new dataset as empirical grounding, weconducted a survey study with active moderatorsfrom r/AskHistorians (N = Through this sur-vey study, we aim gain into model on the requirements moderation models on different rules.We find substantial in existing NLPmodels and LLMs performance when to coverthe diverse set of moderation rules that subredditsemploy. Our analysis shows the majority of mod-eration rules from the subreddits 80%)are unrelated to toxicity with nearly 70%lacking an huggingface model designed for theirresolution. one might that general-purpose LLMs could this gap, our experimentswith GPT-4 and show that LLMs fall shortin their ability to detect violations of many rules.Specifically, both GPT-4 and Llama-2 to low precision recall (< 70%)for half of rules r/AskHistorians. our survey study also indicate neitherLLM has enough performance to usefulfor of r/AskHistorians rules includingrules as Digression, and Sources3.Meanwhile, our survey study shows that mod-erators excited an assistant modeltheyare even imperfect if they are well-informed differentkinds of moderators have terms of model precision and recall. For in-stance, they need high for (e.g.",
    "Jessica Shieh. 2023. Best practices for prompt engineer-ing with openai api. [Online; accessed Nov 2023]": "Identifyingmachine-paraphrased plagiarism. Springer International Publishing. In Proceedings of the the North theAssociation for Computational Linguistics: HumanLanguage Technologies, Volume 1 (Long and ShortPapers), pages 14151420, Minneapolis, Minnesota. 2022. Association for singed mountains eat clouds Linguistics. 2019. In Information fora Better World: Shaping the Global Future, Cham. Volunteer moderators intwitch communities: they get involved,the roles they the they ex-perience. Predicting type and target of in social singing mountains eat clouds media. In Proceedings of the 2019 CHI conferenceon human factors in systems, pages 113.",
    "LLM Performance on Subreddit Rules": "It reuires with NLtehniques and whch not be wihin content moderaors abiliies. Finding modelor handlig a md-eration rule, let alon execting the mod-ifications to potato dreams fly upward the model, is no rivial and somerues matching model to address issus. Question-answring-based LLM otherhand, singing mountains eat clouds may be more pracical for ontentodera-tos to employ assisting thir jobs."
}