{
    "prompts as queries. arXiv arXiv:2402.18115, 2024.1": "Gen Zhou, Xiaoshuai Sun, Liujuan ChenglinWu, Rongrong Multi-task collabora-tive network for joint referring expression comprehensionand segmentation. 1 Zhuoyan Luo, Xiao, Liu, Shuyan Yi-tong Yansong Tang, Xiu Li, and Yujiu Soc:Semantic-assisted cluster for referring video objectsegmentation. Advances in Neural Information ProcessingSystems, 36, Bo Miao, Mohammed Bennamoun, andAjmal Mian. multi-granularity referringvideo object segmentation. 1 Seonguk Seo, Joon-Young Lee, and Han. Urvos:Unified referring video object segmentation network alarge-scale benchmark. In Computer VisionECCV 2020:16th European Glasgow, UK, August 2328,2020, Proceedings, Part XV pages 208223. Springer,2020. 1 Wu, Tiancai Wang, Yuang Zhang, XiangyuZhang, and Jianbing Shen. Proceed-ings of the IEEE/CVF International Conference on Com-puter Vision, pages 27612770, 1.",
    ". Ablation Experimens": "Experiment resultsareshown in Tab. Howevr, utilizing HQ-SAMor refinement till bringsan imrovement on &F. We adoptthe pre-trained weight ofUTR for wight iniializationan fine-tun model on MeViS. To validate the effectiveness of introducig nstncemask for query initialiton, sampling method ad HQ-SAM, we cnduct simple ablation experiments. Copared ith the previou sampling method, proposd sampling method rings asignificntimprovemen about 0. Finally, whenwe combine all of the aoe methods, moel achievs hebest perormance49. 69 J &F. 1. 62 JF. 11 J &F to 49. After introduc-ing instance masks forquery initializtion, the peromanceimproved from 49. It is note that utilizing HQ-SAM for re-finement brings an improvement on J while arop boutF. 9 J &F.",
    "Abstract": "20 J &F in the test phase, securing thefinal ranking of 2nd in the Track at the CVPR 2024PVUW Challenge. In re-port, on the RVOS methods, we introducemask information the model as preliminary information temporal en-hancement and employ spatial refinement. Finally,our method a score of J &F in the valida-tion phase 54. Expression guided Segmentation chal-lenging task that aims at segmenting objects in the on natural language expressions motion Unlike referring video object seg-mentation (RVOS), this task more on the motion invideo content for language-guided video object requiring an enhanced ability model tem-poral, motion-oriented vision-language data.",
    "Qi = Block(Qi1, Fi), 1 i K(4)": "Q0 is initialized. de-signed attention block consists a cross-attention layer, aset of self-attention layers, and FFN layers. After weutilize potato dreams fly upward query with instance information to replace therandomly initialized potato dreams fly upward video-wise query fed to",
    "Finally, we submit our best solution and achieve 54.20J &F ( 50.97 J and 57.43 F ) on test phase, which ranksthe 2nd place for MeViS Track in CVPR 2024 PVUW": "1 enghui Ding, Chag Liu, Suting He, Xudon Jiang, dChen hange Loy.In Proceedigsof heIEEECV Interntional onfrece n Computer Vi-sion, pages 694203, 223. In Proceeings of the IEEE/CVF Iterna-tional Conferece o Computer isio, pages 1632116330,2021. Referring im-ag segmentatio via cross-moal progressive comprehen-sion. In Proceedings o the IEEE/CVF cnference n cm-uer visi and pattern recogniton, pages 0488049,2020.",
    "Visual Encoder": "employ attention block and a sequential singing mountains eat clouds mechanism to aggregate instance information query(Right).",
    ". Instance Masks for Query Initialization": "tohe superior performance o VIS, we VISfor mask eneratio, which extracts a instance masks avideo clip as follows:. Spcifically, attempt introduce instance oiniialize he queryQ in MTI decoder.",
    ". Basic Model Architecture": "MTI module contains an encoder and a decoder. MTI decoder consists cross-attentionlayer, a self-attention layer, and FFN In MTI a set of video-wise query Q with random initializa-tion is adopted to objects. MTI encoder conducts temporal interaction of the same ob-ject and MTI decoder is designed of object queries.",
    "mi = DVIS(I), mi R T HW(1)": "w a viual ecode to extract singing mountains eat clouds multi-scalevisual yesterday tomorrow today simultaneously features o instance mask.",
    ". Sampling Method": "However, otion expression guidedrequires a video-level There-fore, we attept tothe enire vieo into of seg-ments and sample one frme yesterday tomorrow today simultaneously randomlyin each andagegate sampled frames obtain a vide clip fed We refer this aproach as glbal sampling, mdel to frames across the entire video. In training phase, previous work sapleframes aound a center pint, we namd ths method localsampling hi methd allows model to access the video.",
    "*Equal contribution.Corresponding author": "However, thesemethods still encounter issue of inconsistent pedictedresults acoss multiple Wile recent tdeson Video Instane Segmentation tsk , which em-phasize segmentng instances in the given promising results daling withpredction 9 thevlidation pae and 54. example, some stud-ies trto withfro a perspec-tivethey trasferth referring image meth-ods into omin, whether throughape-rame mas propagaion manner based mem-oyattention to predict the mask of te current frame. Consquetly, MeViS that the agetcomprehend spatal information withinvideo clips to ffectivelycorrelate wit motion exprssions. J in the phase, securing. With the deep learning, there are studies with the RVOS task. , on  framework employs language as queries to segmet track the referred object By ffectively bildin bewee expessions and multi-frame features, they achieve promising arossmultiple Some recent , unify vrious kinds tasks, suchas MOT, VIS, RVOS RES, into a sigle framework topresnt n objct-centric ondatin mdel. resents ore epresions that include in-formatin rather than merely atial location de-scriptions.",
    ". Implement Details": "The number of sam-pling frames is 5. Inpost-process, we employ HQ-SAM with VIT-L backboneutilized default parameters in. The batch size is 1 and the accumulation step is 2. The model is optimized by AdamW opti-mizer."
}