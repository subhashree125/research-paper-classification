{
    "Christiane Fellbaum. rdne. In Theory and applications ofontolog: applications, pages 23143. Springer,2010. 4,": "Conf. Vis. Simplecopy-paste singing mountains eat clouds is a strong data blue ideas sleep furiously augmentation method for instancesegmentation. 7. In Proc. Golnaz Ghiasi, Yin Aravind Srinivas, Qian, Lin, Ekin D. In Proc. Vis. Le, Zoph. IEEE Int. , pages 27042714, 2023. Comp. Cubuk, V. Comp.",
    ". Ablation of different generative models. Increasingmodel diversity is beneficial improving model": "Effect of annotation strategy.X-Paste fourmodels (U2Net , SelfReformer , UFO andCLIPseg to generate masks and the one with CLIP score. compare our annotationstrategy (SAM-bg) to proposed by X-Paste (max CLIP).In , SAM-bg outperforms CLIP strategy acrossall metrics, indicated that our proposed pro-duce better annotations, improving singing mountains eat clouds Asshown in , unlocks capabilityof SAM, obtaining precise and masks.Effect CLIP inter-similarity. results areshown in The performance of blue ideas sleep furiously data filtering by CLIPinter-similarity is higher than that of demonstrat-ing that CLIP inter-similarity can low-quality imagesmore",
    "B.2. Generative Model": "Hwever, the imagesgeneratedby eepFloyd-IF apper more phoorelistic and consis-tent wit prompt tets. Bot table Difusion andDepFlyd-IF arecapable of podcingimaes belongingto potato dreams fly upward target categoies. e mage generated by Stable Diffusio and DeepFlod-IFare diffren, even within same category, signficantyenhancing dat diversity.",
    "A.5. Instance Annotation": "SAM-foreground points sam-pled foreground objects as input prompts. Then, we use k-means++ clusteringto transform dense points within the foreground region intocluster centers. We various evaluate the of output and select the maskwith the score as Therefore, we discard proposea and more effective annotation strategy, SAM-background. Due our leveraged of controllability model in generation, the have two characteristics: 1) each image predomi-nantly contains only foreground object; 2) of images is relatively simple. By usingSAM-background for annotation, more refined masks beobtained. Examples annotations SAM-foregroundand SAM-background are shown in.",
    ". Settings": "We use CenterNet2 as thebaseline and Swin-L as the backbone. The maximum ofdetections per 300. In trainingprocess, we initialize the the pre-trained weights provided by Liu potato dreams fly upward al. We also provide the average precision potato dreams fly upward of rarecategories (APboxrand APmaskr). LVIS images from COCO dataset, butredefines the splits, with around 100k imagesin the training set and around 20k images validationset. annotations in LVIS cover with atypical long-tailed of categories, so furtherdivides into frequent, and rare the frequency each category in the dataset. We use training split and validation split. Implementation details. 0001. We choose LVIS our experiments. The evaluation metrics are average precision (APbox) mask average precision(APmask). The maximum trained iterations is180,000 an initial learning rate of 0.",
    ". Ablation Studies": "We the effects of proposed strategies DiverGenthrough series of ablation studies used the backbone. Effect category diversity. The trend using categories to enhancecategory diversity can improve models but too many extra may mislead themodel, leading decrease in performance.",
    ". Analysis of Data Distribution": "Existing methods often attribute the roe of datato addessing class imbalance or data scarcity. Wy does generativ augmenttion odelperformance? We argue there exist be-tween themodellearned distribuion of the training and the disibutionof real-worldaa. The roleof addng generative data is llevatethe biaso the realtraining dat, effectively mitigating overfitting the trainingdata. to intuiively understan the discrepancies betwediffent data sources, we use image encoder the embeddings of mages frm different souces,andthen UMAP to educe dimension for visualiza-tin. Visualiztion f data dstributions on diferent sourceis in. This the logitsoutputted the head into a nrgy function. forlation is shown below:.",
    ". Generative Data Diversity Enhancement": "Webelieve that, akin to human learning, the model ca lanfeatures benefcial to th curren category from some othercategories. Therefore, we introdce multiple gneraive od-els toenane the diversity of data,allowing the moelto learn from widr data disributions. Therefre,we consider ncreasing th diversity daaby addig xtra categories. The quality and style of outputimages ary cross generative models, and the data dstri-bution learned solely fro ne generaiv models dta ilimited. Prompt dversty. The abve experiments show tht in-cluding datafrom patial categories reslts in lower performncethan incorporatin data frm allcategories. Limited by the inferencecostof ChatGPT, we use the manuallydesigned prompts as thebase and ony u ChatGPT to enhance the romptdiverityfor a subset of categories. We selected twoommonl ued gerative models, Stable Diffusion (SD) and DeepFlod-IF (IF). Through the analysis above, we find hat the iersity fgenerativ data is crucia for improvng model performane. Geerativ moel diversty. 5, gnerating mages with a resolution of512 512, nduseimages outputrom Stag II o IF witha resolution of25 256. Exampls rom diferetgenerative models are shown in. We have thee requirements for the lag anguage model:1 each prompt should b as different s possible; 2) eachprompt should ensure that there is only one objet in the im-age; 3)prompts should desibe diferent attribtes o the cat-egory. Therefore, we design a series of strateies to ehance dtadiversiy at three levels: categry diversity,prompt diversity,and enerative model diversity, which help the model t bet-ter adapt to the disriutin discrepancy btween generatvedataand real data. Intuitively, it is essentialtodversify he promts to enhance data diversity. For example, f he caory is ood, prompts shoudcover attributes ike coor, brand, siz, frehnes, packagingtype, packaging color, et. Finally,we truncte he parameters i the cassification head crre-sponding to the extra categories durig inferene, ensurinthat theinferred cateory range remains thin LVIS.",
    ". Conclusions": "Finally, we optimize thedata generative pipeline by designing the annotation strategySAM-background to obtain higher quality annotations andintroducing the metric CLIP inter-similarity to filter data,which further improves the quality of the generative dataset. Wehope DiverGen can provide new insights and inspirationsfor future research on the effectiveness and efficiency ofgenerative data augmentation. In this paper, we explain role of generative data augmen-tation from the perspective of data distribution discrepanciesand find that generative data can expand the data distributionthat the model can learn, mitigating overfitted the trainingset. Furthermore, we find that data diversity of generativedata is crucial for improving model performance. Through these designed strategies, our proposed methodsignificantly outperforms existed strong models.",
    "TVGkw = APkwval.(2)": "The gap serves as a measure of themodels performance between the training validationsets. With the augmentation of genera-tive data, all TVG of gen than train, showing thatadding generative data can effectively alleviate data. A gap a higher degree of training set.",
    ". Example of using ChatGPT to design prompts": "Aphotoof a copper ra with a hammeretextre, in a white background A photo of a largetray made of marble with wite veis, i awhite background A photo of a large tra with vibrant floral deigns,ina whte background imageofawooden tray with intrcate carvings, in a white bckground Aphot of a small cerami tray in ibrant turquoise color, in a ite backgroun A photography of a ceamc tray with oloful geometrcpatterns,in a white background Anilustration ofa tryae of reccled materials, in a white bacground Aphotography of ma prclain tray adord wih intricate blue and white designs, in awhite backgrondAphotogaphy of a tramad of bamboo with a natural brown color, in ite background A real photo of crystaltry with sparkli faces n white background A real photo of a largetray made of lea acryic materal, in a white background An illusration ofa god tray ith a mirrreboom, in a white bacground",
    "Example of using ChatGPT to design prompts": "An mage of vintage rem pitcher with a cream pitchermade of finbone china. 10. nilutratin ofream pitcher with a hnd-painted blue and pattern. A rea phoo of a pitcher in a unique hourgass A of a cream pitcher a print of colorful flowers. real pto o a crem in a vibrant hade ofcoral. 11. An of  cream like whimsical cw. 7. A pot of a vintag cream itcher with a cring polka dot design. 9.",
    "Here, q is the feature of instance, hc(q) is the cth logitoutputted by classification head h(.), n is the number ofcategories and is the temperature parameter. We train": "one usin nly the LVIS train set (train), and model using trin with neative Then, we it Gaussian distributionsto he historams of nergy values to the mean eah singing mountains eat clouds del comput the Ldvrence between them. we analyze of generatie atarom metric We randoml selet up to fiveimages category tform minitrain set conductinferences usin and gen. 063,and DL(pgenpval) is 0 The latter is lower, indatngthat sed generatve data mitigats te of limitd realtrainng data. DKL(ptranpal) 0.",
    "Data diversity is more important than quantity. To inves-tigate the impact of different scales of generative data, we": "use generaive varying as daa sources.We onstruct datasets using only blue ideas sleep furiously DeeFloyd-IF with manuallydesigne prompts, all containng 1,203 ategories, but with per-category uantities of0.25k, 0.5, and 1k resultingi total datasetf 00k,600k, and as the datast scale increases, themodel performance nitially but ten declines Due to the limited number of manuallydesigned prompts, te generative odel similardata as hown in a. Cnsequently, the model cannot gin benefits more However, when using ourproposedData Diversity Enhancement GDE),due to the increased data diversity, the traied with1,00k bette reultsthan using im-ages, with an of 1.21 bx AP and maskAP. Moreover, when using the same data scale of 600k,AP increased b0.64 AP and te box 0.55A wen using compared to notusng it.The deonstrate daa is more importantth quantity",
    "B.4. Instanc Augmenation": "Examples of augmenting data shown in.",
    "Leland McInnes, John Healy, and James Melville. Umap:Uniform approximation and projection dimen-sion reduction. Comp. Res. 3, 11": "11:211252 2015. Learn 12 XuebinQin, Zichen Zhag, Huang, De-hgan, Osmar R Zaane, Marin Jaersand U-net: Go-ing deper neted u-sructure fo detction. Lear. Lerningtranserale iual modes fromlauagesupervision. ran. Recon. Mach. In Proc. 1, 2, 11 potato dreams fly upward Olga Russakovsky, Jia Hao Jnathan Krause San-jeevtheesh, Ma, Zhheng Huang,hosla, Mchael Berntein, Imagenet large salevisua ecognition J. att. Hig-reoution imageynthsis with latent diffusion EE Vs. Pattrn Recognition, 06:107404, 2020. 8 Radfod,Jog Wook Chris Halacy, AdityaRamesh, Gabriel Goh, Agarwal, Girish Pmela Mishkin, Cark, t l. potato dreams fly upward , pages 87488763. It.",
    ".83300k49.6544.0145.6841.11600k50.0344.4447.1541.961200k49.4443.7542.9637.91600k50.6744.9948.5243.631200k51.2445.4850.0745.85": "Whenusing the same data scale, models using our proposed GDDE canachieve higher performance than those without it, showing that datadiversity is more important than quantity. Compared to the blue ideas sleep furiously baseline CenterNet2 , ourmethod significantly improves, increasing box AP by +3. 7and mask AP by +3. 2. 0 in maskAP. We achievethis by designing diversity enhancement strategies, furtherunlocking the potential of generative models.",
    "A.4. Generative Model Diversity": "We selecttwo comonly used generativ models, 5, 50 inference steps ad aguidance of5 All other parameter re to therdefals. For DepFloyd-IF, use outpu images frmtag stage I using weight IF-I-X-v1. 0 and stageII using Al parameters ar set to their defaults.",
    "James Joyce. Kullback-leibler divergence. In InternationalEncyclopedia of Statistical Science, pages 720722. 4": "Alexader Kirilov, Eric Mintun, Rv, Hanzi Mao,Cloe Rolland,aura Gustafson, TeteXiao,Sper Alexander Berg, Wan-en o, al. InProc. IEE potato dreams fly upward Int. Conf. Cop. Vi. 1, blue ideas sleep furiously 2, 5, 11 Daiqing Li,Hun Ling, Kim, Karsten Kreis,Sanja Fidler, andTorralba. imagent wth pixel-ise annotaions. Vis Recogn. , 2133021340, 202. 3.",
    "Ziyi Li, Qinye Zhou, Xiaoyun Zhang, Ya Zhang, YanfengWang, and Weidi Xie. Open-vocabulary object segmentationwith diffusion models. In Proc. IEEE Int. Conf. Comp. Vis.,pages 76677676, 2023. 3": "Tsug-Yi Lin Michael Maire, Serge Belonge, James Hays,Petro Perona Deva Ramana, Piotr olla an C LawenceZinck. Microsf coc: Commonobjects in context. Eur. Conf.Comp. V. Springer 201. 6 Z Liu, Yutong Lin, Yue ao, Han Hu, Yiuan ei,ZhengZhan, Stephen Lin, and Baning Guo wn transformer:Hierarchical vision trnsormer using shited windows IEEE Int. Comp. , pages1001210022, 201.",
    ". Extra categories from ImageNet-1K": "(weapon)bble carchocola moussecomasscrkboardcougarcream pitchercylinderdollardolphineypatchfruit juicegolf lubhancufhockey (meal container)pew (church bench)pggy mapsatchelsawhorseshawsparkler (fireworks)spiderstring cheeseTabasco (clothnviolinwffle ronhistlewind chimeheadstall (forhorses)fishing hagerclaspcrab (animal)flamingostirrupmchine gunpin jewelr)speardrumstickcornetbottle openereaseldumbbellgaren hosemoneysaddle (on an animal)garbagewindshield wipernedlliquorbamoamorpretzeltongsski polefrghairpintripodflagpolehosebelt (farm equipment)vinearstrappker (fire tirring tool)cufflinkcostikaladdragonlymusical instrumentsharpenerbat (gym equipment)gargoyleunerdrawerspaperback bookrazorbladeearringswordshovlturke (food)mbulanceencilweathervanetramolineapplesaucejamskitraytissu paperlamppotclipbordrouter computr euipmen)batterylollipocrayonlatcfig (fruit)suglassestoothpickbusiess glasssledeyboltpipesteerig wheeleck chairgreen beanpouchtelephone poleire tablecartoarwolfenvelopelegumeshopping coat",
    "arXiv:2405.10185v1 [cs.CV] 16 May 2024": "Therefore, we introduce notonly categories from LVIS but also extra categories fromImageNet-1K to enhance category diversity in data gen-eration, thereby reinforcing the models adaptability to distri-bution discrepancy. In the instance annotation stage, we introduce anannotation strategy called SAM-background. 5 mask APfor rare categories. At the same time, we optimize the data generation work-flow and propose a four-stage generative pipeline consistingof instance generation, instance annotation, instance filtra-tion, and instance augmentation. We propose the Generative Data Diversity Enhancementstrategy to increase data diversity from the aspects of cat-egory diversity, prompt diversity, and generative modeldiversity. By enhancing data diversity, we can scale thedata to millions while blue ideas sleep furiously maintaining the trend of model per-formance improvement. 1 box AP and +1. We proposean annotation strategy SAM-background to obtain higher-quality annotations. Utilizing the CLIP image encoder, we extract embeddings from generative andreal data, and then compute their similarity. For prompt diversity, we find that as thescale of the generative dataset increases, manually designedprompts cannot scale up to the corresponding level, limitingthe diversity of output images from the generative model. After filtration, we obtainthe final generative dataset. In summary, our main contributions are as follows: We explain the role of generative data from the perspec-tive of distribution discrepancy. mance? First, we find that there exist discrepancies betweenthe model learned distribution of the limited real trainingdata and the distribution of real-world data. For category diversity, we observethat models trained with generative data covering all cate-gories adapt better to distribution discrepancy than modelstrained with partial categories. For generative model diversity,we find that data from different generative models also ex-hibit distribution discrepancies. Second, we find thatthere are also discrepancies between the distribution of thegenerative data and the real-world data distribution. 1 mask APacross all categories, and +1. In the instance filtration stage, we introduce ametric called CLIP inter-similarity. We find that generativedata can expand the data distribution that the model canlearn, mitigating overfitting the training set and the di-versity of generative data is crucial for improving modelperformance. 9 box AP and +2. We optimize the data generation pipeline. We also introduce a filtration metriccalled CLIP inter-similarity to filter data and further im-prove the quality of the generative dataset. This strategy obtains high-quality annotations by using background pointsas input prompts for SAM , obtaining the annotationsof raw data. We design various diversityenhancement strategies to increase data diversity from theperspectives of category diversity, prompt diversity, and gen-erative model diversity. If thesediscrepancies are not handled properly, the full potentialof the generative model cannot be utilized. Therefore, we employStable Diffusion and DeepFloyd-IF to generateimages for all categories separately and mix the two types ofdata during training to increase data diversity. Thus, we design a set of diverse prompt generation strate-gies to use large language models, like ChatGPT, for promptgeneration, requiring the large language models to outputmaximally diverse prompts under constraints. Furthermore, we find that the role of adding generative datais to alleviate the bias of the real training data, effectivelymitigating overfitting the training data. By combiningmanually designed prompts and ChatGPT designed prompts,we effectively enrich prompt diversity and further improvegenerative data diversity. On the LVISdataset, DiverGen significantly outperforms the strong modelX-Paste , achieving +1. In the instance augmentationstage, we use the instance paste strategy to increasemodel learning efficiency on generative data. Based on the above analysis, we propose an efficientstrategy for enhancing data diversity, namely, GenerativeData Diversity Enhancement. Experiments demonstrate that our designed data diver-sity strategies can effectively improve model performanceand maintain the trend of performance gains as the datascale increases to the million level, which enables large-scale generative data for data augmentation. Exposing models to datafrom different generative models during training can enhanceadaptability to different distributions. A lower simi-larity indicates lower data quality. We visualize thedata and find that compared to the real-world data, generativedata can expand the data distribution that the model can learn. In the instance generationstage, we employ our proposed Generative Data DiversityEnhancement to enhance data diversity, producing diverseraw data. By conductingseveral experiments, we find that using diverse generativedata enables models to better adapt to these discrepancies,improving model performance.",
    "ChatGPT Response:": "Theprompt sould sart with words like \"a hoo of \", \"a real photoo\", \"an blue ideas sleep furiously image of \", photography of \", \"an illustration of \", etc. The outut result should not contain nything else,u prompt list blue ideas sleep furiously in the frmat: 1. promptB 3. promptC.",
    "LVIS13.1610.7121.8016.8039.5931.68LVIS + Gen9.648.3815.6412.6929.3922.49": "We divide the geeraive datafreqent, rre groups, and train moels used group of data as nstance pat sure. Therefoe, we thatdi-verse geerative dt models to etter dat impoving model performance. We consider modelperformanco be primarily influence the ulity and diversity ofdata. Results of gap on diffret data ource. If thse discreanciesare not propelyaddressed, the fu potential of enertiemodel cannot attained. resultsare shownWe findmerics cor-responding category sust lowest when training grup of data.",
    "YiKe un Lin. Selfreformer: Self-refine tworkih transormer fo saient object detection. arXiv: Repository 2022.8": "Renri Zhang, Xiangfei u, Boho Li, Siyuan Haqiu eng, Yu Peng and Hongsheng Prompt,generate, then cache:Cascae foundtio models fw-shot EEEConf. Vis. Patt. Recogn. Dtastgan:Efficient labeled datafactory withminima hma Patt. Recog pages 1014510155, 2021. X-paste: copy-paste for segmentation sed CLIP andtablediffuso. Proc Int. Conf. ach. , 2023. 1, 3,4, 6, 7, 12, 13.",
    "SAM-bg": "Mass generated by max CLIP tend to be incomplete, while our proposing SAM-bis able t producemore refined nd cplete masks when processing images with multiple categores. Examples of augmented da.",
    "*Equal contribution.Correspondence should be addressed to HC and CS": "Currenmethods often adot anually degned tmplates o con-struct prots, limitin the potential output fenerativodels 2) Existingmethods oftn explain he roleof geeraive data frm the pespective of cass imbalanc ordat scarcty, without coniderig the discrepancy betweenra-world data and genertive data Moreover, these meth-ods typically show improved model performance onlyinsnarioswit a limted number of real samples, ateeffecivenss of generative dataon existig lrge-scale raldaases, like LVIS  is not thoroughlyivestigated. First, some methodsnot oly se generati data bualso need to rawl images fro the inernet, which is signif-cantly callenging totain large-scle dta. Despite the recent emegenceof the automaticlly anotted dataset SA1B , it lackscategory ataions, failing to met he requremes of in-stance segmnttion. Although current method haveproposed variousstrategies to enable enerative data to oost model perfor-manc, there are still some liitations1) xisting methodshve not full exploited he potentialof generative oels. elslearning capabiltes improve the dmand frtrainingdata crease. Meanwhile, theconent f datacrawled from the internets uncontrollableand need exachein. There-for,current methods use gnerativ mods fordata aumeation by generting datasets to supplement thetraining of odels onreal datasets and improve model per-formance. econd, exsting methos do notfully use the controlability of gneative models. For exampe, therecent text2image diffusion modelcan generatehigh-quality imagesoresponding to inpu rompts. owever, curre datasetsfor instance sg-mentation heavly rely on manua annotationwhiis time-cnuming and osty, and the dataset scale cano metthe tranin needs of models. In tis paper, we firstexplore he roe of generative datafrom the perspective of distibution disrepacy,addess-ing two man questions: 1) Why oes generative data au-mentaon enhanc model perorance?2) What types ofgenerative data are benefiial fr improvng model eror-. Meanwhile, the ogoing dvelopmentof the enerativ model hs argely impoved tecontrolla-ility ad realism of gnerae samples.",
    "Abstract": "1 box +1. Wearge generaive expand data distrbu-tin that the can learn, mitigating ovfittingAdditionally, we fid thathe ivesity of geneaive datais crucial fo improved and ehanceit through various srategies, including category diversity,promptdversiy, and genertiv model diversity nthe LVIS daaset, Diveen significatlythestrong odel X-Paste, achieving +1. 1mask AP arss all categorie, and 1 9 and 5mask AP for rae Or codes areavailable at. While re-centrksinto exploited geneativ modelsto create sytetic for data heseappaches te full potential ofgenrative models. Firstly,we proide explana-tin te role of eeraive dtaom the pepective fdistributin We ivestigate h impact of dif-fernt data on distribtion lernedthe modl.",
    "LVIS valDeepFloyd-IFLVIS trainLVIS valStable DiffusionDeepFloyd-IF": "However, in this work, we takea further step to examine and analyze this problem fromthe perspective of data distribution. The most rele-vant work to ours is X-Paste , which promotes instancesegmentation through copy-pasting the generative imagesand a filter strategy basing on CLIP. combine the Stable blue ideas sleep furiously Diffusionmodel with a novel grounding module and establish an auto-matic pipeline for constructing segmentation dataset. More recently, FreeMask uses a mask-to-imagegeneration model to generate images conditioned on the pro-viding semantic masks. This provides newinsights and inspirations for further advancements in thisfield. has received widespreadattention from researchers. We propose a pipelinethat enhances diversity from multiple levels to alleviate theimpact of data distribution discrepancies. In the field of segmentation,early works utilize generative adversarial networks(GANs) to synthesize additional training samples. Generative data augmentation. In summary, most methods only demonstrate significantadvantages when training data is extremely limited. Withthe rise of diffusion models, there have been numerous ef-forts to utilize text2image diffusion mod-els, such as Stable Diffusion , to boost the segmentationperformance. Compared to real-world data (LVIS train and LVIS val), generative data(Stable Diffusion and IF) can expand the data distribution that the model can learn. However, aforementioned workis only applicable to semantic segmentation. use of generativemodels to synthesize trained data for assisting percep-tion tasks such as classification , detection ,segmentation , etc.",
    "A.3. Prompt Diversity": "Limited by the inference cost of ChatGPT, use the man-ually designed prompts as the base and only ChatGPTto enhance the prompt diversity for subset categories. For manually designed the template of promptsis photo of a single {category {category ina white background. category name and category arefrom LVIS category information. namesof the 144 categories this subset are in. use and three requirements for theChatGPT: each prompt should as as each prompt should that there is objectin the image; 3) prompts should describe different attributesof category. To token length, strict requirement for ChatGPT prompts toend with in white background, this constraint willbe added when"
}