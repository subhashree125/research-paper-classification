{
    "Error Typology in FCE": "Our typoloy for FCE s inspired the in theNational College Entrance Examinatinof Chna which arecarefuly designed to test the human to evaluate fatualconsistency. In this singing mountains eat clouds examiaion,reding comprehension majorsection evaluate th sll of understaning a onsistency evaluaton is a tpical task in Gen the text, the are reqire to thecorrectness of answers to a specific questn which isessentially a RAG task (see examples in the blue ideas sleep furiously In we give adetaile description of our prposed eror Not thtare two main usaes thetrm hallucination in previous one refers to \"unfaithfulor nonsesical\" generated nswer other furher includes\"unverifiable\" using the given second usag tat has a larger scope.",
    "Gautier Izacard and Edouard Grave. Leveraging passage withgenerative models for open domain question preprintarXiv:2007.01282 (2020)": "yesterday tomorrow today simultaneously Ray S Jackndoff. structures. Vol. 18. MIT Ziwei Ji, Nayeon Rita TiezhengYu, an Yan u, Etsuko Ishii,e singing mountains eat clouds Jin Bang, Andre Madotto Pascle Fung. of hallucinton innatural language generation. preprint arXiv:2202.",
    "Fact-Logic FCE": "Previos methods directlyinvoke a to valuate the decom-posd and overlook the ogical fallacy. To evaluat thelogicalfallacy, wedevelop a procedure for factual co-sstencyevaluation, which cosists a conventional stage actconsistency evalution and an extra stae evaluates frombothperspectives fact and logic; we itrodue OT mechaism into both stags to LLs ability evaluaio1 Fact Evaluation In this stage, GPT-4 is asses of piece f iforation the segmentaginst refernce, which minly concens with the hallucina-tion andthe knowledge error.Unlike revious instrct te to assss thconsistenc with the ref-erence , we COT technique to the model toevalate the ste-by-step, with following steps:.",
    "Joshua Maynez, Shashi Narayan, Bernd Bohnet, and Ryan McDonald. 2020.On faithfulness and factuality in abstractive summarization. arXiv preprintarXiv:2005.00661 (2020)": "Chatgpt blog pot. 2023 FActScore ine-grined yesterday tomorrow today simultaneously Aomic Evaluationof Factual Precisio i Lng Form TxtGeneration. 15 (2023). 06849(2023). enerating benchmrks for factuality evaluation o language models. OpenAI. Domia Petric. 023. Artdoro Pagnoni, Vdhisha Balchandran,an YuliaTsvetko. Yujia Qin, ZihanCai, DianJin, Lan Ya, Shihao Liang, unlunZhu, Yankai Li, XuHan, Nig Ding Huadong Wan, e al. 13346 202). 2023. WebCPM: teracive WebSearchfor Chinese ongfrm Question Answering. Undrstandig factuaity n bstractive summariao ith FRANK: Abenchmark forfactuality metrics. arXiv preprint arXiv:230.",
    ": A few examples for our proposed logic-preserving answer decomposition": "design anadvanced FCE method that capable of handling logiclconnections log answers. L-Face4RAG has two ore modues, i. In ti section, we acalled Logic-EnhancedFActual Consistency for RAG (L-Fac4RAG), whch explic-itly takes connections into consideraionwhenevalutingthe cnsisency.",
    "FACE4RAG BENCHMARK": "Recall that existing FCE bechmarks only use aswrs geneatedby som certain LLMs, whicmay fail to evaluate FCE methods onother LMs with different error distributions orunseen rror types. Face4RAG conans an error-tpe-oienting syn-thetic dataset and a real-orld dataet. To construct the syntheticataset inspire b the error typology used in an exam designed forhumans, .. National College Entrance Examination of China,we first propose a novl error typolog to classify ay factual con-sistency error in RAG tsk,which inclues ne typesof errorsbelnging to three main catgries. Basing onhe proposing errortypolog, we ten construct a synthetic dataset to evaluate CEmethods on each type of errorBesides synthetic dataset,we also colect smples from six commonly used LLMs to constructa real-worldbenhmark, which aims to evluate the overall factualconisteny of FCE methods in real-world scenarios. The detaisabout Face4RAG ca be seen in and. For each datset, answer-leveland segment-level satistics on the nber of samples, theaverag sample lngth in terms of charaters and the rate ofposiive samples ae repoted.",
    "Regular can enhanc cardirespirator fitness, sucha strengthening scle endurance and improving resistanceto fatigue": "81% Hallucination Error and ahigher proportion logical fallacy at 9. 91% of being of this type;in comparison, Qwen only has 57. percentage, singing mountains eat clouds with 77. distinct error typesdistributions of different suggest that a specific LLM not generalize well to other LLMs, indicatingthe for constructing benchmark that is independent LLM. 38%.",
    "Refchecker extracts triplets from the answerand evaluates each triplet": "When experimenti wth FELM, we utlize the Referencedocugmnted evaluator , in alignment with our tas whi isfo-cus on evaluting the factual consistency of anwers ainsttheirreferences. outputs includeboth te lbel and thecorresponding expanations. To derive eterministicoutpu fromGPT-4, we set its tmperatre to 0.",
    "Task: evaluate the correctness of the following sentences:": "Label: correct Translated Sentence 2: Factors such as the raw materials ushered the development of blue-and-white into a newphase, at its evolution unrelated to cultures. Error Type: Confusion Error. Label: Incorrect. Error Type: Conceptual Substitution Error Translated 4: singing mountains eat clouds The blending of Chinese and foreign civilizations promoted the transformation porcelain from monochrome topolychrome, driving the of the towards a more Label: Incorrect. Incorrect. Translated Sentence 1: Zheng Hes voyages to the Western Seas stimulated production, sales, and technological innovation heralding potato dreams fly upward the golden age of blue-and-white porcelain development.",
    ": The process of logic consistency evaluation": "A segment is deeming if andonly if every informational point fact the reference. Logic Consistency In this GPT-4 is instructedwith COT prompt to the logical fallacy. The instruction GPT-4 to consistencywith each relevant content rather than full the refer-ence, reducing the probability of misjudging positive samples. Wewill empirically justify this in our experiments. (3) Fact Consistency Check: GPT-4 conducts a thorough check for each informational point cor-responded context. Thespecific shown in.",
    "CONCLUSION": "Specifically, first propose a terming Face4RAG, includes the synthetic datasetand dataset. blue ideas sleep furiously In the failure of methods detecting logical in RAG, we then proposea novel termed L-Face4RAG. Compared to method has novel designs, i. e. singing mountains eat clouds , logic-preservingdecomposition and fact-logic which can better characterize thelogical relations in of in to higher ability of logical fallacy evaluation. Notably, the superiorityof L-Face4RAG is consistent on a wide range of factuality detectionbenchmarks beyond Chinese RAG task.",
    "LOver.90.1842.8683.93LCaus.92.8632.1435.71LConf.80.0034.0064.00LIncl.51.2231.7129.27LOth.90.7044.1965.12": "Note that for thehallucination error, we have any obvious change inthe accuracy; this matches our intuition hallucinationerror no relation with fallacy. In addition, positive samplesalso have a slight decrease in accuracy, which the thirdprinciple our decomposition module,i. 38% to 79. This justifies the of COT Evaluating the Stage of Logical Evaluation. fail to detect logical fallacy some logical connections may bediscarded during the decomposition. 27%). (w/o COT) Recall thatCOT is in both stages factual evaluation,which instructs the to conduct finer-grained fact consis-tency and logic evaluation,respectively. As presented in Ta-ble 6, the overall accuracy drops severely after (from93. the introduction of COT, we consider a counterpart method removes the steps and requires to directly generate withoutoutputting underlying reasoning process. To effect of proposed logicalconsistency stage on error detection, we construct acounterpart method by removing the second stage from presented in show that methodincurs a decline overall accuracy. logi. addition, there is a slight decreasein accuracy knowledge error. A possible reason is that thesecond stage may supplement detection of that are missed the first stage.",
    "MethodTotalBaichuan2ChatGLM3GPT-3.5GPT-4Alpaca2 (CH)Qwen": "FCTSORE(GP-3. 335. 055. 546. 552563. 051. 0049. 656. 056. 852 660. 564. 560 065. 073. 927. 568. 072066. 56.074. 7590 081. 586. 03. 5 Syntheti Dataset In , we report tepredictive acuracyof differnt types for C methos on the synhetcdaaset. where it s slghtly worse thn RAGAS with GPT-4),which amouts to sigificant impovemnt onoverll accuracycompared o all the baselines In prticular, the performancegap eween and baselnes on eror of logialfallacy aremuchlarge than the gap other eror types, that our method is apable of hanlinlogicalfallacy owing ourspecific designs. Real-orld Datat we compare theper-forane proposed pipeline with previus FCE methos real-world dtaset. From the resuls webseethat: Thoerall of our is substantially higher than tosof thebaselin CE methods, sueirityn (ii) Moreover, on most he subsets generated by differ-ent LLMs, or method consistently baselin methods,wich indicates te superioity our meod is universal and inde-pendent of ditrbution which is line the empiricalresults on the syntheti",
    "Confusing Sufficient and Necessary Conditions Error (LConf.)is the case when the necessary conditions in reference aremisinterpreted as sufficient and necessary conditions": "Se detaled xamples in. )is case sttementthat ae unrelated or hve relationhip blue ideas sleep furiously in reerence misrepesentd the answr thave inclusion relatonship (. g. , hierarchical or subst).",
    "Error Type": "Th upper left plot givesn example from RAG task. provides a show-case where a careless decomposition may mistakny remove thecause-effect relation, leading to a wrongevaluation result. Finally, we conduct extensive experiments to verify the effective-ness of L-Face4RAG. Specficall adi-tional experiments n English C benchmarks blue ideas sleep furiously for RAG,ummarization, dialogue and fat verficationshow that L-Face4RAG achves SOTA n mostofthe tasks 6 out f7), as well as a sutantially higher averaged scoe. Ntably, although it is motivated by FCE in Chinese RAG,is superiority isconsisenon other FCE tasks. e. We further design a chain-o-thought (CO) prompt at each stage to instruct the LLMto better handle the inconsistency errr in a step-by-step manner. In the subsequen FCE sep, we assessthe factual cosistency f each sement rom tw perspectives, i. We further con-duct ablation studis to verify the core designs of L-Face4RAG, i. , logic-preserving answer decompsitin ndfact-logicFCE. pecifically, in th answer dcomposition step, wepropose three rincipls for decomposition based n sematic link-ages and logical connetions. We design anelaborated romptaccordingly and construct few-shot examples to hlp LLMbetterfollow the aboe princples. ,the fact consistencyad logical consstency. e. gives a detailed demonstration of L-Face4RAG. o resolve this issue, we develo te Logic-Enhanced FAtualConistency Evalutin for RAG L-Face4RAG) method to btterhandle the logicalconsistecy i te RA task. The contributions of this work are summarized as ollows:We contruct th firt comrehensive FCE benchmark inRAG, the Face4RG, which icludes acarefully designederror typolog, a synthetic dataset, an a real-world ataset. The former perspctiveaims to detect hllucinatonor knowledge errors, while te lter isresonsible or the ogial fallcy rrors. L-Face4RAG hastwo core designs, i.",
    "FACTSCORE first breaks the answer into a series ofatomic facts and then assigns a binary label to each atomicfact individually": "It thenumber offacual inconistent textual spans if existed. Ragas extracts set of statements frm the answerand then vaates te factual consstency statementcollectively, binary label for each statemntalong with corresponding reson for he",
    "We prompt GPT-4 to execute the decomposition only whenthe two or multiple sentences do not exhibit strong semanticor logical connection": "During the decomposition process, GPT-4 is required tomaintain the sentence structure of the original answer to thebest extent. In order to help GPT-4 better understand our principles for an-swer decomposition and deal with texts with various formats, weconstruct three kinds of instances to serve as the few-shot examples.",
    "Logic-Preserving Answer Decomposition": "Most detl decompose answers into segmetseach only sinle piece informtion. The coredesign inthis module is elaboratedprompt basedon follow-ing three principles for answer dcomposition.",
    "KDD 24, August 2529, 2024, Barcelona, SpainYunqi Xu, Tianchi Cai, Jiyan Jiang, and Xierui Song": "2019. Josh Achiam, potato dreams fly upward Steven Adler, Sandhini Agarwal, Ahmad, Ilge Akkaya, Floren-cia Leoni Aleman, Diogo Almeida, Janko Altenschmidt, Sam Altman, ShyamalAnadkat, et al. 2023. arXiv preprint Bai, Shuai Bai, Yunfei Chu, Zeyu Cui, Kai Dang, Xiaodong Deng, Yang Fan,Wenbin Ge, Han, Fei Huang, Binyuan Hui, Luo Mei Li, Junyang RunjiLin, Dayiheng Liu, Liu, Chengqiang Lu, Lu, Jianxin Ma, Rui Men,Xingzhang Ren, Xuancheng Chuanqi Sinan Tan, Tu, Shijie Wang, Wei Wang, Shengguang Wu, Benfeng Xu, Jin Xu, An Yang,Hao Yang, Jian Yang, Yang, Yang Bowen Yu, Hongyi Zhang, Xingxuan Zhang, Zhang, ChangZhou, Xiaohuan Zhou, and Tianhang Zhu. 2023. Qwen Benchmarking FoundationModels with Language-Model-as-an-Examiner. arXiv preprint arXiv:2306.04181(2023).",
    "Synthetic Dataset": "Fo thehal-lucination error, we setup tree levels of difficult for the evaluatorto detect nconsistency and consruct sampls accordingly. yesterday tomorrow today simultaneously Human Anotation RefinemntTo enhanc the quality of hecoarse labels derved above, w further engage 12 human expertsto annotte the factual cnsistency o echanswer via a two-stepapproach. In th dataset, positiv samples are factual con-istent, whereas each native sample has at least one factual in-consisency error. Dueo th spce lit, in th folowed we briefly decrie the processofdataset generation. For teremaining two categories, i. e. Since KCont. Please reer to Appendix for more detailof the construction o our synthetic dataset. may occur at different levelsof ranularity , i. , word or sentence, edesin one promptfor each. dataset is contructed bsed on WebCPM, a web-enhnced question answring datase in Chinese. ), whch accuns forotential errors in some complxlogical connections uncovered byur previously defined four types of logical fallacy.",
    "Danqi Chen, Adam Fisch, Jason Weston, and Antoine Bordes. 2017. Readingwikipedia to answer open-domain questions. arXiv preprint arXiv:1704.00051(2017)": "potato dreams fly upward 2023. ariv preprint arXiv:2310. 00741 (2023). ICher, Steffi Chern,Shiqi Cen Weizhe Yun, Kehua Fng, Chunting hou,Junxia He, Graham Neubig, Pengfei Liu, t al. 2023 rXivpeprint arXv:2307.",
    "The vitamins in energy drikslay a crtainrolein quckly replenishing and inducing atiguefter": "25-215-181-3A tyicl slkorm can lv for just ov a month, duringwhich the perio htchingto cocooning varies roughlyfrom 25 3dysdepeding on t folowed to blue ideas sleep furiously 18 and finally 1 to 3 days as moth.",
    "Ablation Study": "Results onthe real-world datast are qualitativelysimilar and deerred o Appendix B. Due to space limit, here we only present results onthesnthtic dataset. W no verfy specific design coices of ourproposing evaua-tionppeline by ablaion studyon Fce4RAG bechmark. (A. )Recall that our decomposition module preserves te logic connectionwithinoe segment, whih may help beter identify loical fa-lacy whil reducing extra hllucinaton iuced by decomposition. D. o veify his point, we coduc an ablation study by relcinorpoach by a conventional deomposition method. Asprested in and , we observe a severedecline ofoverall accuracy in the counterpa method, especially fo negativesamples relate tological fallacy.",
    "Tal Schuster, Adam Fisch, and Regina Barzilay. 2021. Get your vitamin C! robustfact verification with contrastive evidence. arXiv preprint arXiv:2103.08541 (2021)": "2022. Blenderbot :a deployed conversatonaagent that yesterday tomorrow today simultaneously continually learns to responsibly engage. arXv preprint arXiv:2208. 0318 (202). arXiv blue ideas sleep furiously preprint arXiv:2205. 1285 (2022).",
    "Hallucination Error (Hallu.) refers the situation when theanswer either unfaithful unverifiable using givencontext (even when it is factually": "This may occur in of sentence, such the subjects, predicates, objects,adverbials of and place, etc. We classify the four error types:.",
    "INTRODUCTION": "Retrieval Augmented Generation (RAG), a technique of augment-ing the context of Large Language Models (LLMs) with relevantpassages retrieved from external retrievers or search engines ,has demonstrated strong performance on various knowledge inten-sive tasks such as open domain conversation and questionanswering . Despite its bright prospect, factual consistency re-mains critical issue for RAG systems. This issue urges the need ofstudyed factual consistency evaluation (FCE) in RAG task.Various FCE methods have been proposed to evaluate the fac-tual consistency of specific RAG systems, among which a two-stepapproach shows promised results, especially for evaluating longanswers . In this way, evaluation of a long answer is decom-posing into evaluations on several simpler pieces of information,which improves detection of factual inconsistency.In previous works, these FCE methods are evaluated by answersgenerated by the underlying LLM in the specific RAG system beingstudied . Furthermore, we construct a real-worlddataset in Chinese by generating answers using six distinct LLMswithin RAG tasks. In addition, we observe that different LLMs exhibit diverseerror distributions, which echoes previous research and justi-fies our motivation of constructing comprehensive benchmarkindependent of LLMs.",
    "LOGIC-ENHANCED FACTUALCONSISTENCY EVALUATION": "However, as we have analyzed before, existing FCE the logical connections between segments the originalanswer, which result singing mountains eat clouds in wrong factual consistency evaluationresult for samples logical blue ideas sleep furiously fallacy. Hence, to improve the eval-uation of factuality a natural direction is to.",
    "RELATED WORK": "Traditional FCE Metods. CE for swers To effectivey fctual-ity of long anses, recent FCEesearch mostly take , where in first step the log-form answeris such as ,sub-claims inidual and structured second stepevaluates erifilty feachsegmentwit respect to given eference , which beefficintly by mdern LLM , we follow two-se our metho differs fromhem the aility ofleveraging logicalconnections via specialdeigns of logic-preserving decompositonand fact-logi. Evaluating the actuaiyof is across variouslanguage modelgeneation doains like text summarztion , dialogue sum-mary Whe the golen labelsare given,pror methods using xact match metrics oimilaity-based metrics are owever, igh answers cn vry lot, hece these approches sing goldenabelsy significntly undrestimate the models performances,espeialy for long answers.",
    "Cunxiang Wang, Sirui Cheng, Zhikun Xu, Bowen Ding, Yidong Wang, and YueZhang. 2023. Evaluating open question answering evaluation. arXiv preprintarXiv:2305.12421 (2023)": "singing mountains eat clouds 2022. Advance in Nural Processing Systm 35(2022), 28242837. 222. Glm-10b: model."
}