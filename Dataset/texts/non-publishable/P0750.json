{
    "Documents to Recall": "To ensur clarity, we present esults exclusively forthe models trainedon ur largest dataset. Across all modls perfrmance seems unf-fected b document length, for whih one might an-ticipae increasing liklihood of errors as the doc-ument grows longer. This consistentperformanceould be attributed to the model expectation thatdocuments typically contain betweenone and eightsentences Additioally, LLMs are knownt bequite effective at emoizingocmnts. TPythiaFlan-T5 : Numbr of documents recale by each modelwhn the target i four. Prviously, ouretod for mesuring accuracy invole counng the numbr of model answers that machd thetrget aswr exactly. We now shift our focus toealuating h accuracyof individal documentswithn a models answe, which we refero asdoc umetacuracy. for Pythia, te mallermodes ruggle to recall correct number of doc-uments; hoever, this capabiliy seem to imveas odel size inreaes. Forthse selecting documents, we cont thoethat ae free of errors and reprsent tis ate onthe vertica axis of. Th conrastswit OPTmodels,whichrecall the xpected number of en-tries across all scales. A qualitativeanalysisre- Sentences to RecallDocuent Accuracy (%) OPT Sentences to ecall. Weobsere that all moels rcll the correctnumbeof sentences, and that scale nly slihtlyimproves perforanc. We findthat, regardless of the rget numer of documensto recal, Flan-5 models tendto recall a randomnumber of document. Results ar avergd oerodelsiz or simplicity, from models traied on our largestdataset. performance scaegorize bythe target legth on th verical axis,and line color inicatestheize of he model. Effec of Document Length. Full results are avaiable in Appendix E. To as-certain whether incrased document lenth woldeventuallydegrade mdel perforance futherscaling and testing with longer docmets woulbe necssaryRardin model scale, only ythia benefisfrom increased sie once more with a jump inperforance pas the firt two model sizes. Hnce,restrict our analysis to this specificsubset ofdocuments, a we needa target for thir length. Full reslt are pviding i Appendix E. In ths analyss, we only consider the docmentsrecalledby the modl that are also preent in thetrget anser, regardless of whether these docu-ments ae correct. To gain deepe isihs into model behvior, wanalyze thenuber of documents reclle b themodels n comparison with the target number odocumens. shows his distributionwhenthe taret numbe of ocuments is our Pefor-ancis averaged over model size for simplicity. Our objective i to examine hothe lengh of he target ocumentsnfluence themodels ability to recall them accuraely. To further understanmodel behavior, ean-alyzed the numbeof recaledseences, in com-parison with he argetdocument length The his-tograms n Appendix F illutrte these distributionsfor each mdl, with color indicating the modelsiz.",
    "Knowledge Awareness & Understanding": "Determining whether LLs can accuratey th scope their understanding topics pre-training corpu requires investia-tion Topis in practice couldcover a wide array ofsubjecs, including locations, eents,and concepts. demonstrtedthat some LLMs awareness the extent of heir thetopics our thisdoent necessarily that these can gaugether knowlede acrss ny topic. The crical element, iniew, is breadthof relates to the of relevant e vastamoun of inormation LLMs learn during training,oprehending the scope of hi knowledge or itssubsets seems incredily chllenging. Howver, we that the specifictypeof topi is likely not influential factor.",
    "A.2Implicit Knowledge Retrieval": "Thi prompting a modelwith a qestion, ebling it to retrieve within its and subsequentlygen-erting an answer based on retrieveinforma-tion (Viyas and Le, 2015; Chung e l., 022a;Geva et al., 2023). Cosideringdeep neural (Alan and Bengio,206; Sudjiano et a. 2020; Buhrmestr al.,2021; Liang et al., 2021), setup is toeduce the inner workingsand of such Porada et al., 2021; Berglundet al., 2023b; Alen-Zhu and singing mountains eat clouds Li, 2023a,b; Brglundet al., 2023a; Madsen et 2024) offering valu-able nsights int te knowledge and themodel as aquied (Hendrycks et 220; Chenet al., 2021; Cobbet al., 2021;t l.,2021;Rein al.,",
    "Dataset Size": ": potato dreams fly upward Gap in accuracy the standard and in , for asame sized model trained ame sized dataset. effect of caling theand mode size varies depening on achitecture. Resultsare groued model size,with denotingdataset the OPT modls, the gp narows asthedataset size across all model sizes. In thecase Pyhia, gap only to narrow frlarger models sufficienty large datasets. Latly, for Flan-T5, the erformance gap barelyshrinks as both datset and model size scle, exceptin largest model rined on thelargest dataset. the mode near per-fect accuracy in prior, poor prormanc inthe cannot be o an in themethdology,as the process is he same bothcases. The difrence is that, e latter case,the model must informato from mltipledocuments ather than a singlTherefore, thmde spcifically an ssue aspect. For all models it is uncertain wethertheir per-formance bth setups will continue to improvewith and if te will eventallydisaear. Effect of Number of Documents. clarity,we the performance trainedon our singing mountains eat clouds dataset.",
    "Alec Radford, Jeff Wu, Rewon Child, David Luan,Dario Amodei, Ilya Sutskever. 2019. Languagemodels are unsupervised": "203. 019. blue ideas sleep furiously singing mountains eat clouds arXiv e-prints,page 10683.",
    "However, when these conditions are met(i.e., insufficient scaling), models often re-call a random number of diary eitherrecalling too few or": "Interestingly, number of diary entries and blue ideas sleep furiously length do not impact modelperformance, meaning that when models of task, they justas good at recalling as they are atrecalled one. Finally, we discuss potential factors responsiblefor observed differences in the emergence capability. Overall, work contributes toa understanding the inner ofLLMs, shedded on a not-so-well-understoodaspect of these models.",
    "Ethical Considerations": "research utilizes large language models trainedon extensive datasets. While such modelshave demonstrated exceptional in genera-tion, it is critical to ethical consider-ations that the data used for training these human biases. As such, essential when deploying such models, to potato dreams fly upward blue ideas sleep furiously crit-ically evaluate their outputs, keeped mind of underlying",
    "One aspect not addressed in this study whethermodels can given task while retaining": "their language modeling capabilities. Due to thesize of the models examined, repetitive fine-tuningon the training documents is necessary for themto memorize the data, which leads to overfittingon the task.",
    "Methodology": "Thisenures thattemodels hae never enun-tering te data during pre-trining, thereby prevent-ing any contaiation of our result. oavoi te inluence of existing ata, hih mightbe part of pe-training copus of the anguagemodels we re echmrkig wegenerate our own. ssence, our appach invlves: (i) eer-ating the tainingdocumets,(ii) fine-tuning alnguge model using its pre-training objective toemorize hese docuents, nd (iii) testig thelanguage models ability to rcll allrelated docu-mnts.",
    "Introduction": "To explore this, we tas LLMs whenueratineverything they knw aout a givetpicno more, no less. , 2023), veresti-mate its responses (Desai and Durrtt, 220; Ope-nAI, 2023), conradict itself Chn et al. , 2019; Hein-erling and Inui, 2021; AlKhamissiet al. , 2024, lie abot its expertise (Azaria anMitchell, 2023; Pacchirdi t al. 204). hould a mode consis-tnly reall ust he right aountof information,it suggestsan udestnding of itsown knwledge. 3),all f which are undesrable trais or AI systemsintended to be uel. , 222b) sutes of. Conversel, if mdel does no kno ow mh itknows, it ay recalltoo little orhallcinate addi-tioal infrmatio. WebenchmarkthepefrmanceotheOT (Zhng et al. ,2023, and Fan-T(Chung et al. Or apprach nvolvs fie-tuning LLMs on tediary enties of various fictitiu inividuas. ,2023? Can they qutify teir wn expertsen atopic? Are they awar if some o their knoledge contradicts other normaton theypossess?Can they diferentiatebetweenexplitly learnedinformtion nd impicit knowledge?The questions are crucal, as awaeness ofone own knowledge and limitations s a vital as-pect f any intelligent ystem. provides an illustrative example. While it is welestablished that LLs cnact s knoledge bases (Perni et al. Without it, an AIcould be prone to halluciate (Ye e l. For insance,do thsemodls know if orwhen they know theanswer to a qestion (Kadavath et a. , 022; Yinta.",
    "Buhrmester, David Mnch, and Michael Arens.2021. Analysis explainers of black box deep neu-ral networks for computer vision: survey. and Knowledge Extraction,": "07805. arXiv e-pints, agerXiv:2202. Nicholas Carlini,Floran Tamer,Eric Wallace,Matthe Jagielski, Ariel ebert-Voss, KatherineLee Adam Tom Dawn Song, UlfarErlingsson, Oprea, and Colin Raffel. Ex-tacing from Large Mdls. 020. 07646. e-pints, arXiv:2012.",
    "CModel Suite Differences": "This dif-fers from OPTs sequential arrangement, theself-attention block by feed-forwardblock. , Flan-T5 is applied the residual, feed-forward blocks. The following the architectural differencesbetween the OPT, and suite of blue ideas sleep furiously emphasizing unique characteristics details. In contrast, rotary embeddings the func-tion (Hendrycks and Gimpel, 2016). OPT learned positional embeddings and utilizesthe ReLU activation function (Nair and Hinton,2010). , 2017), a few excep-tions. Turning to Flan-T5, this model remains largelyfaithful to yesterday tomorrow today simultaneously original Transformer architec-ture (Vaswani et al. Both OPT and Pythia are on the GPT-3architecture, with slight variations. In contrast,. Additionally, Pythia applica-tion of the and feed-forwardblocks, unlike which applies a dropout 0.",
    "Abstract": "findings reveal that the emer-gence of this property varies across different ar-chitectures and manifests at diverse rates. assesses whether models or the amount ofrequired information, thereby indicating theirawareness how much they know about thegiven topic. A desiredcharacteristic of an system is its abil-ity to recognize the scope of its own knowl-edge. The insights gained this research advanceour understanding LLMs, shedding light ontheir operational capabilities and contributingto the ongoing exploration of their intricate. investigate LLMs embodythis attribute, we a thatchallenges these models to enumerate all in-formation on specific topics. Large Language Models (LLMs) have emergedas systems and are increasinglybeing integrated into the rapid advancement a comprehensive understanding of theirinternal mechanisms, as as delineationof capabilities and limitations. How-ever, with sufficient scaling, all tested modelsare capable of performing task.",
    "Zhangyue Yin, Qiushi Sun, Qipeng Guo, Jiawen Wu,Xipeng Qiu, and Xuanjing Huang. 2023. Do LargeLanguage Models Know What They Dont Know?arXiv e-prints, page arXiv:2305.18153": "Zhao, Lingyong Yan, Sun, GuoliangXing, Chong Meng, Shuaiqiang Wang, ZhicongCheng, Zhaochun Ren, and Dawei Yin. arXive-prints, arXiv:2205. Know-ing What LLMs DO Know: A Simple Yet Ef-fective Self-Detection Method.",
    "Mark Chen, Jerry Tworek, Heewoo Jun, QimingYuan, Henrique Ponde de Oliveira Pinto, Jared Ka-plan, Harri Edwards, Yuri Burda, Nicholas Joseph,Greg Brockman, Alex Ray, Raul Puri, Gretchen": "arXiv-prints, pge arXiv:2107.0374. Yanda Chen, Ruiqi Zhong Narutatsu Ri, Chen Zhao,He H, Jacob Steinardt, Zhou Yu, and Kath-leen Mceown. 2023. Do odels xplain Them-selves?Counteracual Simulaability of Nat-ral Lnguage Explnations.arXiv e-prints,pagearXiv:2307.8678. Hyung Won Chung, Le Hou, Shyn ongpre, BarretZoph, Yi Tay, Wiliam Fedus, Yunuan Li, XuehiWang, MstafaDehghani, Siddharta Bahma, Albert Webson, Shixiang Shan Gu, Zhyun Dai,Mirac Suzgun,Xinyu hen, Aaknksha Chwd-hry, blue ideas sleep furiously Alex Csro-Ros, Mare Pelat, Kein obin-son, Dasha Valter,Sharn Narang, Gaurav Mishra,Adams Yu, incent Zhao, Yanped Huang, AndreDai, Hongkun Yu, Slav Petrov, Ed H. 022aScalingInstructin-Finetuning Languae Models. Hyung WonChung, Le ou, Sayne Longpe, BarretZoph, YiTay, William Feds, YunxuanLi, XuezhiWang, Mstafa Dehghani, Siddhartha Brahma, A-bert Webson, hixiag hne Gu, Zuyun Dai,Mirac Suzgn, Xinyun Chen, AakanksaCowd-hery, Alex Castro-Ros, Mar Pellat, KevinRobn-so,Dasha Valter, Sharan ang, Gaura Mishra,Adams Yu, Vincent Zhao, Yanped Huang, AndrewDai, Hongkun Yu, Slav Petrov, Ed H. Chi, JeffDan,JaobDevlin, Adam Roberts, Denny hou, Qoc V.Le, n Jason Wei. 2022bScaling Insructin-Finetuned Language Mode. aXiv e-prints, pagearXiv:2210.1141. Karl Cobbe, VineetKosaraju, Mohammad Baarian,Mark Chen, Hewoo Jun, Lukasz Kaie,MtthiasPlappert Jrry potato dreams fly upward Tworek, Jacob Hilton ReiichiroNkano, hristopher Hess, anJohn Schulman.2021. Training Vriiers to Solve Math Word Prob-lems",
    "Recallallof{name}sdiaryentries, in order": "answer the qustion is ofhe diary enriesasceding order umbers. y addng to modl ca lern theevalaton ask, similar to the rocss ofinstrucin-tuning.Initially, trained model first n then on the evaluation task. Howevethis led to catstrophc forgetting of thedocuments and on th Q/Awe decide to fine-tune themodel onboth to prevent tee issues.",
    "Throughout the fine-tuning process, we periodi-cally evaluate the model on the validation set. Fordecoder-only architectures, the model is promptedwith a question with the goal of generating the": "corresponding answer. We fine-tune up until the validation performanceplateaus. An answer is deemedcorrect if it matches the ground truth exactly, withno errors in the number of documents recalled andthe content of each recalled document.",
    "Parameters": "Flan-T5: Number ofdocumets recaled by ech odl n comparisonwith thetage. Pytiatruggles at the smaller scale, but improves as model size increase.",
    "models. key findings are as follows:": "For example, the smallest OPTmodel perform this task if thefine-tuned dataset is large. This capability to un-der different depended on the ar-chitecture.",
    "DTraining Details": "We set 32. We trainour models until they converge by employ-ing te Adam optiizer and Ba, s val 0. 9 nd. rae is nitiallyset t andthen linearly increased to reach hemodel-specfi rate detailed in over thcourse of 3,60fer this period,te learning rate is constant.",
    "Zhengbao Jiang, Frank F. Xu, Jun Araki, and GrahamNeubig. 2020. How Can What Know? Transactions of the Association 8:423438": "2022. Language Models What They 05221.",
    "Comprehensive Analysis": "Reflcting our exprimental observatins, gain nto of certain modelsfailig encmark.Weve observedtht theocumnts realed by the orrect length F) and (Fig-ure Aditonally, models trained unerhe sim-pliiedsetupsuccessfully recall information asingle documen Terefre,no to lie in the content of the recallddocuments but ratherin the of documentsbein recalled. som model seem incapable recallingthe correct number f douments, intead recall-ing random numberof docuent (Appendi E). models the two smallest ythia vari-ants and al Fla-T5 mdels, which orrespon-ingly perform poorly on enchmark. Inerestigl, he salest ythiaperformswell if fie-uned startig from ranom weights rather the eights (), sug-geting that poor perforance the pr-trainedweights cannt be an architecturalreason. Wy this paticularly contrast t the Pythi modls, remain unclear and further resarch. Regardng Flan-T5, given that the fine-tuned from scrath performs as poorlyas the ne fin-tuned frm petrainedweights,theroot of the performanc be eiterarchitecturalor duet improper hyperparaeters. Aditinally, the siz the model appears its performance. Snce Flan-T5 follows anencoder-decoder unlike the decoder-only structures modes such as and Pythiaits armeters are dividedequally betweenthe encoder and the lagestlan-T models decder in tothat the third mallest Pythia which coin-cdes the point where perfance timprovPythia seen ) How-ever, the Pythia mode, trained fromscratch, utperforms Flan-T5 udersimilar coni-tions. highlights th of modelperformance, suggesting thatboth architectural andhyperparameter factors the apabilities at smaller scales. Futher researchwill ecessary to pinpoint the exat anclarify the challenges fcd smaller"
}