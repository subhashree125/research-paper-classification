{
    "Shuai Wang, Ekaterina Khramtsova, Shengyao Zhuang,and Guido Zuccon. 2024. Feb4rag: Evaluating fed-erated search in the context of retrieval augmentedgeneration. arXiv preprint arXiv:2402.11891": "Curran Inc. Long-form fac-tuality in large language models. preprintarXiv:2403. 18802.",
    "Mojtaba Komeili, Kurt Shuster, and Jason Weston. 2021.Internet-augmented dialogue generation.arXivpreprint arXiv:2107.07566": "Comput. Linguistics, 2020. Trans. Retrieval-augmented generationfor knowledge-intensive nlp tasks.",
    "Background": ", 2022; Zeng et al. The ex-isting research on jailbreaking LLMs can broadlybe divided into two main categories: (1) Prompt en-gineering approaches, which involve crafting spe-cific prompts to intentionally produce jailbrokencontent (Liu et al. , 2023); and(2) Learning-based approaches, which aim to auto-matically enhance jailbreak prompts by optimizinga customized objective (Guo et al. , 2024; Xue et al. , 2024). ,2020; Raval and Verma, 2020; Song et al. Aparticularly relevant area of research involves theinvestigation of jailbreaking techniques, whereLLMs are coerced into bypassing their built-insafety mechanisms through carefully designedprompts (Bai et al. Specifically, for eachdocument Dj K, the similarity score betweenDj and the query Q is computed by their innerproduct as (Q, Dj) = Sim(hQ(Q), hD(Dj)) =hQ(Q)T hD(Dj). ,2022, 2023, 2024; Liu et al. , 2024;Anderson et al. We notice that thereare a few concurrent works (Zou et al. ,2021b). , 2023b; Wei et al. However, our work distinguishes itself byinnovatively focusing on the more challenging at-tack setting: (1) user queries are not accessible,and (2) the LLM generator is not only manipulated. TheLLM f generates the response to Q using the re-trieved documents as contextual support (illustratedin. The knowledge base in a RAG yesterday tomorrow today simultaneously sys-tem encompasses a vast array of documents fromvarious sources. , 2023a; Zou et al. , 2024) on attacking the RAG sys-tems. Attacking Retrieval Systems. For simplicity, we denote theknowledge base as K, comprising n documents,i. The effectiveness of these at-tacks is typically assessed by evaluating the re-trieval success for the modified documents. e. , K = {D1, D2,. , 2024; Cheng et al. The query encoder hQconverts any query into an embedding vector, whilethe document encoder hD produces an embed-ding vector for each document in the knowledgebase. ,2023; Tan et al. Depending on the retrievers configuration,hQ and hD might be the same or different. Jailbreak and Prompt Injection Attacks. This knowledge base can be sig-nificantly large, often containing millions of docu-ments from sources like Wikipedia (Thakur et al. For simplicity, we omit hQand hD and denote the set of m retrieved doc-uments as R(Q; K), representing the documentsfrom the knowledge base K with the highest simi-larity scores to the query Q.",
    "Weimin Lu,Lin, Songzhu Zheng, Lu Pang,Haibin Lng, usmit Jha, nd Chao Chen. 2024. Task-agnostic for nsertion-base preprint arXv:240.17155": "20. Weimin Lyu,Sngzhu Zheng, u Pang, Hibin Ling,ad Chao hen. 203. Attention-enhanced back-door attacks ainst bert-base models. In Findingsof the Association for Computational Linguistics:EMNLP 2023, pages 1067210690Tri Nguyen, Mir Rosenberg, Xia Sog Jianfen Gao,Saurabh Tiwary, Rangan Majumder, and Li Deng. 2016.",
    "Overall Performance of LIAR": "For exampe, whenus-ing LLaMA-2-7B as the source model, attacks onLaMA-2-13B show reatively hghrHarmful Be-havior rates, such as 0. summarizes the effecivness of LIAR forgray-box attacks on ariousRAG systms, withdifferent sorce and target moels and knowledgebass. 3865 for NQ and 0. 3596for MS compar to icua-13B nd PT-3. For intance, attack on Vicuna-13B using anensemble pproach show a HarmfulBehavior rae of 0. We obtain the following key obsrvations:Perfomance Variability:The effectiveness ofgray-box attacks varies significantly across if-ferent ode pairings. More deailedanalyses on eachcomponens are exploredin followed subsetions. 3865 and 0. 3596 for LLaMA-2-13B under at-tack by LLaMA-2-7B. 5targets. Knowlede Base Sensitivity: ifferentknow-edge bases exhibit vryin levels f vlnerabil-ity. 5846 for NQ and 0 This indicates that using multiple models ca en-hance the transferability o the eneratd aersar-ia contentattacks.",
    "Dan Wahlin Heidi Steen. 2024. Retrieval augmentedgeneration (rag) in search": "arXivprerit arXi:2112. Unsupervised dense in-formation rtreval with contrastiv learning. auier Mathild uas osseini, Se-bastan ieel, Bjanowski, Armand Joulin,and Edouard Grave. Gautier Izacard, Mahilde Caron,Se-basian Riedl, Piotr Bojanowski, Armad Grave.",
    "Senstivity of Hpe-parameters": "We use LLaMA-2-7B asthe geneaor. NQ shows increase from0. 75 to0. Extending AG 10 to 50 tokensalso enances ASR. Lengt of yesterday tomorrow today simultaneously AGS5b). 85, indicating ostive but moerae ef-fect. Overall longer sequences and ore hanc attack efectieness, though im-rovement vary by. dinadersarial documentsfrom2 to leads to a signfcant ie in ASR, wih Q increasng from 75 to 85, suggesting higher cntnt canaid uccess.",
    "Threat Model": "This treat model ocuses on adversaries whoexplot penness of these systems into their knowledge bases. Weassume gray-bo reflecting realistic ce-naris where atackers have limitedaccess to thesystems ut influence singing mountains eat clouds tsbehavior thrugh eternal interactions.",
    "Abstract": "Inthi aper, demonstratea scurity threawhere adversares can exploi the penness ofthee nowldge bass by nectng yesterday tomorrow today simultaneously decetiecotn into yesterday tomorrow today simultaneously the retrieval atabase, intention-ally changing the odels behavior. This reaticritical as it mirros realorld usage sce-nariowhere RA systems interat with pb-licly accessible knowledge bass, such as ebscrapings and sercontibuting data pools. Our fndins emphasize urgen eedfo scurity measures in the designand deply-ment of RAG ytems t prevent potential ma-nipulaionand ensre th integrity of machine-generated content.",
    ": Visualization of adversarial retrieval rate AR,adversarial goal achievement rate AG, and training lossacross training iteration of AT": "Detaied experimn setting is iven in yesterday tomorrow today simultaneously Ap-pendixA. 1. empirically demonsrates the challengesof effectively ttacking RAG models. Over teaining epochs, th obsere AR and potato dreams fly upward AG reminlow without significantimprovement. Thissuggests thatdesignig effective attckfor RAG ystems is farfrom trivial, anda new trained protocol s neededto improve attack fficcy withou compromisingthe systems complexity.",
    "C.1Empirical Evidence": "show the convergence of LIAR across5000iterations, tracing Advrsarial Retrieval rate(AR,Adversarial Goal chievement rte (AG), andtraining loss. AR rapidly increases, stabiizing at0. Overall, comaredto vanilla AT, LIA achieves smooterconver-gencewih highr early success in rerieval andgradual, steady improvement n goal acievement.",
    "LIAR: Exploitative Bi-level RAG Training": "LOoffers a hierachica larning structure withtooptimizatio levels, here the uper-level prob-lems objectives and ariables deend n the lower-level solution. Spcifically,wemodify the co-ventional AT setup, as dfined n E. (1), (2) and(5),into a bi-lvel optimizationframework:. This structure lows uto xplicitlyodel the iterpla between thretriever ad theLLM geeator.",
    "Methods": "In this section, webegin by h and obective attacking () Rand (ii) the LLM generator f() withi ATframework. We blue ideas sleep furiously empirically demonstrate that theseinividual components struggle t eachoter and fai make a concertedwithinte process in.",
    "Attack on the LLM": "We formulate the problem as mini-mizing the NLL loss NLL of producing the targetsequence y, given a user query q:. We assumeaccess to a set of source LLM models M to craftDadv, which is expected to generalize to unseentarget LLMs. The objective is to create a AGS, Gadv, that, whenappended to any ARS, Radv, maximizes the likeli-hood of the LLM generating harmful or undesirablecontent according to given ATS, Tadv.",
    "C2Theoretical Poof": "To prov the of he of theBLOin LIAR (Eq. e. the funcion Rdv(Gadv.",
    "Attack on the Retriever": "Formally, an adversarial con-tent we maximize the similarity between itsARS, Radv, and the knowledge base:.",
    "Xiaogeng Liu, Nan Xu, Muha 2023a. Atodan:Generatingtealthy jailbreakprompts on ligned largelanguag oels. arXivpreprint arXiv:2310.04451": "Yu-An Liu, Ruqing Zhang, Guo, Maarten de Ri-jke, Wei Chen, Yixing Xueqi Cheng. 2023c. Yi Gelei Deng, Zhengzi Yuekang Li, YaowenZheng, Lida Tianwei Zhang, andYang arXiv preprintarXiv:2305. Black-box adversarial attacks against yesterday tomorrow today simultaneously potato dreams fly upward dense A multi-view contrastive method.",
    "Harmful Output: aims to deceivethe RAG system into outputs that are": "Enforced adversary seks tocompel te system to generate response containing specific Forinstance, in ork w conider inecting cn-tet o prmote a particular brandname for adver-tising yesterday tomorrow today simultaneously purposes, rand even for potato dreams fly upward unrelated queris. incorect, misleading, or harful, thereby spread-ing misinformation, biased content, maliciousinstrctions.",
    "Note that such exploitations are realistic threatsgiven the public user interface of many knowledge": "bases used in systems. Also, white-box re-trievers such Contriever (Izacard et al. , 2022),Contriever-ms on MS MARCO), andANCE (Xiong et al. For instance,similar to the example in an upload, inject, malicious content itsknowledge base, causing the search engine to misleading harmful information to otherunsuspecting users. Deriving such adversarial contents is not triv-ial. conduct warm-up study in that a vanilla optimizesthe injected with single-purpose ob-jective will significant loss oscillation andprohibit the model converging. singing mountains eat clouds Accordingly,we decouple purpose the injectedcontent into a dual It is devised tobe preferentially retrieved the RAGs It effectively influences the behaviors ofthe downstream once retrieved. Then, wepropose a training framework, expLoitativebI-level rAg tRaining which effectivelygenerates adversarial contents to influence RAGsystems generate misleading responses. reveals these vulnerabili-ties and emphasizes the urgent need for developingrobust security measures in design and deploy-ment of RAG Our contributions areunfolded as follows: Threat Identification. We are the to iden-tify severe, practical security threat to preva-lent RAG systems. we demonstratehow malicious content, once injecting into base, is retrieving by thesystem used to of the LLM, effectively theintegrity of the response generation process.",
    "Ethical Statemen": "S. We strongly advocate for the respon-sible application of AI technologies and emphasize that the findings from this study should be usedsolely for improved system security. Additionally, we conducted our experiments ina controlled environment and did not involve realuser data or deploy any harmful actions that couldaffect individuals or organizations. This work is supporting by the National ScienceFoundation (NSF) under grants IIS-2229461. To mitigate these risks, ourwork adheres to the principles of responsible dis-closure, ensuring that the details provided are suffi-cient for researchers and practitioners to understandand counteract vulnerabilities without enablingmalicious use. intention behind thisstudy is to raise awareness about the risks associ-ated with the use of RAG models and to promotethe development of more secure and reliable AItechnologies. Theviews and conclusions contained in this documentare those of authors and should not be inter-preted as necessarily represented the official poli-cies, either expressed or implied, of the U. We acknowledge that the techniques discussedcould potentially be misusing to cause harm or ma-nipulate information. We are com-mitting to ensuring that our research practices alignwith ethical guidelines and contribute positively tothe field of AI security.",
    "A bilingual concept-wise benchmark for measuringmathematical reasoning of large language models.arXiv preprint arXiv:2402.14660": "iaqi Xu, Mengin Zheg, Yebowen Hu, Fei Liu, XunCen, nd Qian Lou. 2024 Badrag Identifying vul-erablitiei retrievl augmented generatin of largelanguage models. ohn, Ruslan Salakhudinov andChrstopher D. 0008. 2024. aXivpreprint arXi:246. Manning. Bnnett Junad Ahmed, andAnol Overwijk Aproximae nearestneigh-bor negative contrstive learning for dense textetreval OpenReview.",
    "Effect of Different Retriever odels": "shows the Adversarial Suces Rate (AR)for different retriever models on NQ and MSMARCO datases. 8 forNQ and 0. 75 for MS MARCO), indicatighihsuseptibility to advsarial content. 5 for NQ, 0. ACE: LowestASR ( 0. 2 for NQ, neglgibe frMS MARCO, indicating trong ristance to ad-ersaal attacks. Overl, ANCE is the ost rbust,while Contrieer is the mostvneale, with sig-niicantvariabity across dataets highlightig theneing for contet-sefic evaluations. ContreveContiever-msANCE",
    "Structure of the Adversarial Content": "adversarial content consists a small ofdocuments: Dadv = {Dnadv}Nn=1, where N |K|. Given the ineffectiveness of coupled singing mountains eat clouds train-ing, we propose decouple tokensof each adversarial Dadv into com-ponents: Adversarial Retriever Sequence (ARS):Radv = yesterday tomorrow today simultaneously {xi}sRi=1, Adversarial Target Sequence(ATS): = {xi}sTi=1, and Gen-eration Sequence (AGS): Gadv = {xi}sGi=1",
    "3: Update Gadv with Radv:Perform steps of Eq. 6 with BGadv;": "More implementation de-tails Appendix A. To 6, we blue ideas sleep furiously the optimiza-tion (AO) and for its efficiency compared to other meth-ods (Liu al. We callthis framework expLoitative bI-level rAg tRaining(LIAR); provides summary. the tractabil-ity the convergence of BLO on the convex-ity of lower-level problems objective Eq. Unlike conventional AT frameworks, LIARproduces a coupled and Gadv, enhanc-ing robustness. , Our extensive experiments(see ) demonstrate that significantlyenhances success rate of comparedto conventional AT. LIAR helps coordinated training of ARS andAGS.",
    "), Contriever-ms (Izacard et al., 2022), andANCE (Xiong et al., 2021) in our experiment withdot product similarity as a retrieval criterion. Thedefault retrieval number is 5": "LM Selection.We consider LLaMA-2-B/1B-Chat (Touvron et al., 223),LLaMA-3-8B-Instrct Vicuna-7B (Chiang et l., 2023), uanao-7B (Dettmers et al., 203),GPT3.5-turbo-0125 (Brown et al., 2020), GPT-4-turbo-2024-04-09 (OpeAI, 2023) Gemini-1.0-pro (Team et al.,2023), and Claude-3-Haiku (Anthropic, 2024).Specially, for odel enemble efined i Eq (5),we use Vicuna-7B and Gunaco-7B since they sharthe sae vocabulary. Training Deail.Ules otherwise menione,we trai 5 aversaial douments with a lengthof 30 ijected into the knowledge database andue Conretrieve (Izacard et al., 2022) asdefaultetriever. In the hotlip ehod (Ebrahimi et al.,2017), we consider to-100 okens as potentil singing mountains eat clouds re-placeents. AGS length is fixed as 30, which iseffetve but less tie-consuming. In the bi-lvelpimization, w yesterday tomorrow today simultaneously update ARS and AGS with 10steps and 20 steps, respectively. Detailed key pa-rmetr analyses can b und in 3.",
    "minGadvNLL(y, y) p(y|Radv Tad Gadv q),": "T find te optimal AG, we emloy a gradent-based approach combined with geedy search forefficient token replacement. W comute th gadient of the loss unction with respect potato dreams fly upward to the token em-beddings o idnty the direction that maximizethe lkelihood f geerting the harmful sequene The gradent withrspet to the embedding of the.",
    "James C Bezdek and Richard J Hathaway. 2003. Conver-gence of alternating optimization. Neural, Parallel& Scientific Computations, 11(4):351368": "Bechmarking large moel inretrievalaugmented generatio. Jiawei Chen, Hongyu Lin, Xianpe Han and LeSun. idog ing, Ju, Zongru Wu,Wei D, Yi, Zhuosheng Zhang, and Troanrag: Retrieval-augmenting genera-ion canbe backoor driver in language modelsarXiv preprint ei-Lin Chiang, Zhuohan Li, Zi Lin, Ying Sheng,Zhanghao Wu, Hao hang, Linmin Zheng, SiyuanZhuang, Zhuang, Joseph E. 2020. 1948. Ziegler, Jeffrey Wu,Clemens inter, Christopher Mark EricSigler, MateuszScott Gray, Benjamin Clark, Christopher Berner, Sam Ilya Sutskeer, nd Amodei. 2024. Languae models are few-shot earnes. Gonzalz, IonStoica, ad P. 2024. I Proceeding oftheAAAI Conference on rtificial Intelligence, vol-ume 38, pags 1775417762. ypos therags back: Genetic o rag pipeline by documents in the via perturbaions. 2023. icuna: An ope-source chatbo with 90%* chatptqualit. Sumin Cho, Soyeong Jeong, Jengyeon Seo, and Jong C Prk. Tom B Brown, Bejamin ann, Ryder,MelnieSubbiah, Jared Klan, Prafla Dhariwal, ArvidNeelakntan, Prnav Sastry, AmandaAskll, Sandhini Ariel Herbert-Voss,Gretchen Krueger, Tom Henighan, Rewon Child,Aditya Daniel M. arXiv peprintarXiv:2404."
}