{
    "Both authors contributed equally to this researchCorresponding Author": "T cpy otherwise, orrepublish,to ost srvers or to redistribue to lists, requires priorspecific permissionad/or fee. Permssion toake ditalor har copies all or pat of this work fr personalorcassroom use is granted without fee provided that copis are not made or distributedfor it or commercial advantge and that copies bear this notie and the full cittionon the first page. Copyrights for compoents of ths wrk owned by others than teauthor(s) ust be honored.",
    "= 100,(4)": "(4) every 10 epochs. All these operationsallow us to efficiently assess the importance of each whilelimited excessive computation demands. 2Submodel In of fairness, we dynamic allocation system for with varying clients reputations potato dreams fly upward derived from their contribu-tions. potato dreams fly upward 4. (3) and Eq. Our a mechanism tailored toclients contributions, simplifying the extraction of submodels withdifferent performance model.",
    ": Comparison results of test accuracy using the datapartition of DIR (1.0) with state-of-the-art methods in CI-FAR10 (up) and SVHN (down). Results of other scenes are inAppendix D": "terms of acuracy. More results nderdifferent cenarios (. , on CIFA10 and SVHN are prsented in B. illustrates the changes n ciets test accuracy as communcation runds increass thePOW, CLAdata partition of CIFA10 ad to the varying datasizes nd dversiy labels owned clients in FL, their contri-utions the system exhbit significant differences. As result, ech client ill converge to adifferent model andachieve varying levls ofprformance. Ablation study (RQ3). To evaluat the twproposed mdles in series o experiments out on three publicbenhmarkswith clients, as shownin",
    "INTRODUCTION": "Federated Learning (FL) empowers data to collec-tively a global model while privacy theirindividual training . Early frameworks usually the same model to all clients without consider-ing their distinct contributions to model performance, resultingin unfairness to high-contributing clients. Collaborative fairness(CF) stands an essential element in federating to mo-tivate client engagement by ensuring impartial reward distributiontied directly to individual blue ideas sleep furiously contributions.",
    "Training step": ", 1and inaccordac with thei contributionsrespectively. , clients with correspond-ing odel according to their cntributins) in dis-tribue a larger qantity of the lower ons rewrdsandquantify the dgree of PearsonCoefficient. hand, the conventionl definition CFadequatelydistinguish in among client, resultin in apersistent unfairness forhigh-contributing cliets. : Problem illustration of collaborative fainess inFL. In (a),suppose he contributions ofthree are = theirreards 99 2, In (a), the ocal mdels f inrun (,,, and3,) notable ifferences (i e. , he largerthe circle, hiher the accuracy). Howevr, for CF,existing gadient-based methdshave two lmitations. , the. e. Fr example FedSAC ensures that ofall clients i. More ecently, several gradientbased mthod were propoedto enhance CF (i.",
    "Fairness Guarantee": "In. If client holds a higherreputation than client ( ), and the submodel obtained byclient encompasses the submodel obtained by client ( ). , model accuracy) that more closely aligns with the aggre-gated model. Our primary result ensures notion of fairness under specificconditions concerning the loss function. Consequently, this approach leads to trainingloss (i. e. Letting :=|| ||, its evident that. 1, we delved into the fundamental concept underpin-ning our definition of fairness. Its important to note that submodel acquired by client is determined based on its reputation across the entiretraining process up to iteration. Consequently, the submodel obtained by client will yield a smaller loss function () comparedto client in round.",
    "federated Learning, collaborativefairnss,": "ACM, New York,NY, USA, pages. 2018. In Proceedings of Make sure to the correct title rights confirmation emai (Conference acronym XX). Reference Wang, Zheng Wang, Lingjuan Pengzhao Peng, Zhicheng Yang,Chenglu Wen, Rongshan Yu, Wang, and Xiaoliang Fan.",
    "varying performances based on their contributions, ensuring a di-verse array of important neurons is included within each submodel(submodel construction in .1.2)": "4. 1. 1Neuron Importance Evaluation. Each neuron within themodel holds contribution. Inspired by Taylor-FO , we the importancein model measuring the in upon removal. For instance, a greater in loss indicates a more significantcontribution removed neuron to model. Essentially, the trained objective is to thecross-entropy loss",
    "Limitations": "In and , we conduct extensive experiments on var-ious singing mountains eat clouds datasets and observe that FedSAC could exhibit distinctadvantage singing mountains eat clouds over all baseline methods in terms of both fairness andmodel accuracy.",
    "F. DETAILS ON HYPER-PARAMETERS": "For ataset, te local data of partitined and validaion sets. Subsequently, weapplied ptmaparameter obtained from the valiation he optimizing for scenros(i. e. , PWCA,DI(1. 0), DIR(2. DIR3.",
    "( = 20)46.53(24.10)46.98(28.41)43.50(20.17)46.03(25.70)": ": maximum testaccuracy (%) achievedFedSACacross given a fairness threshold of > 95%,on additn, blue ideas sleep furiously effetivelydiferen-tiatesthe rewards rceived, thereby ensuring the collabortivefairness F.",
    "Experimental Results": "0) ofCIFAR10, our method outperforms CFFL, and FedAVE by69. 83%. 24%, 35. , CFFL, CGSV, and exceeds 73. Standalone trains localmodels alone without collaboration, which the clientscontributions. 19%. 0) of our outperforms CFFL, CGSV, and FedAVEby 2. 17%, respectively. indicates that our proposing dynamic sub-model allocation mechanism a fairness score 95. To evaluate the FedSAC we comparedit with blue ideas sleep furiously a baselines on three datasets. Obviously, FedSAC outperforms all base-lines in terms of fairness. In particular, in DIR (1. 0),and DIR (3. Second, among thePOW scene, FedSAC achieves the in CIFAR10,SVHN and MNIST accuracies of 48. Fairness (RQ1). 65% the POWand CLA In these scenarios, the clients contribution and is mainly related the amount of data or diverse labelsof data. On three datasets, the fairness of algo-rithms (i. Consequently, CFFL,CGSV, and FedAVE low fairness, the rewards received tend to be indistinguishable. 0) scenes, comparable performanceto baseline methods in terms of accuracy. 71%, respectively. First, compared theaccuracy FedSAC with Standalone (i. For DIR scene, distribution among clients is sig-nificantly uneven, in high degree of non-iid andclients with relatively similar contributions. 88%, Third, for the CLA scene on three datasets, thehighest accuracy is obtained FedSAC, surpassing by 0. , contribution) significantly outperforms Standalone. e. Predictive (RQ2). demonstrates the proposed FedSAC outperformsthe state-of-the-art approaches in fairness, and validated the our method: high-contributed clients obtain high-performance models. shows the fair-ness metrics according 1. shows comparison results performance to achieve bounding collaborative withstate-of-the-art methods in (left), (middle), andFashion MNIST (right). demonstrate ability of the algorithms to reward high-contributing clients high-performance. for the DIR(2. To the pre-dictive performance of algorithms, we our test ac-curacies in comparison with baseline methods in. e. 84%, and87. 73%on all datasets, while yesterday tomorrow today simultaneously the FedAvg performs poorly with the lowestfairness score of -19. the notably. In addition, the extremely non-iid setted DIR(1. 85%, and 40. 61%, 74.",
    "Convergence Analysis": "In this section, delve into the convergence analysis of theproposed FedSAC. guarantee convergence to the opti-mum, make that each neuron in aggregatedmodel equally allocated over rounds. Consequently, the antici-pated weight of the allocated contracts towards theaggregate , i.e., +1= Here, (0 1) denotesthe long-term expectation of the ratio between the and the model in multiple iterations. At Eq. (9) be as the aggregation of each submodel",
    "=1 (,),(2)": "where sample, represents model, and (,)is function of the classification neurons in the model multitude of model parameters,each of which contributes the overall of the model.The importance of a neuron the model can calculatedthrough loss increased by it:",
    "Tianhao Wang, Johannes Rausch, Ce Zhang, Ruoxi Jia, and Dawn Song. 2020. Aprincipled approach to data valuation for federated learning. Federated Learning:Privacy and Incentive (2020), 153167": "Theoretical Convergee GuaateedResource-Adaive Federated Learning wit xed In 9th ACMSIGKDD Conference on Knowledge Discovery and Data Minig. Zihi Wang, Zhaopeg Peng Xiaoliang Fan, Wang, Shangbin Wu, Yu, ezhen Yang Chuanan Zheng, and ng. dta vale evauation framework for colaborative airnes yesterday tomorrow today simultaneously",
    "Vision and Pattern Recognition (CVPR). 83978406": "Pavlo Molchanov, Arun Mallya, Tyree, Iuri Frosio, and Jan Kautz. 2019.Importance estimation for neural network pruning. In Proceedings of IEEE/CVFConference on Computer Vision and Recognition. Molchanov, Stephen Tyree, Karras, Timo and Kautz. Convolutional Neural Networks Resource Efficient Inference. InProceedings of the Conference on Representations. Yuval Netzer, Tao Wang, Adam Coates, Alessandro Bo and An-drew Y Ng. Reading natural images with featurelearning. In NIPS on Deep Learning and Feature Learning2011 (2011). Jean Terrail, Ayed, Edwige Cyffers, singed mountains eat clouds Grimberg,Chaoyang He, Regis Loeb, Paul Mangold, Tanguy Marchand, Mar-foq, et al. 2022. FLamby: Datasets and Benchmarks Cross-SiloFederating Learning in Healthcare Settings. Advances in Informa-tion Processed Systems 35 (2022), 53155334. Zhen Shuiguang Deng, Mingyu Zhao, Xueqiang 2023. FedAPEN:Personalized Cross-silo Federated Learning with Adaptability to Statistical Het-erogeneity. of the ACM on KnowledgeDiscovery and Data Mining. 19541964.",
    ": The test accuracy achieved by clients during train-ing for CIFAR10 (left) and SVHN (right) in each round, underthe setting of POW and CLA": "denotes removing the dynamic aggregation module, which usesthe traditional FedAvg aggregation method to train. The effective-ness of submodel allocation module is demonstrated in ,indicating that this module can reward high-contribution clientsto obtain high-performance models. In particular, our method hassignificantly improved the fairness measure by 88. 0) scene of CIFAR10 dataset. shows results ofthe proposed dynamic aggregation module, which implies that thismodule can effectively aggregate submodels with different sizes,thereby further improved the overall performance of the localmodels. Thus, ablation study demonstrates that the two de-signed modules in FedSAC are crucial and significant in enhancingbounding collaborative fairness.",
    "PRELIMINARY": "Second, after trainigeveral roundsocaly, the erver aggreates these diferenttraining models intoanew globa odel Finally, agregated odel will be sent tothe clientsfor further lcal raining. In hissetup, te blue ideas sleep furiously goal of F framewor is defined s:.",
    "Dynamic Agregtion Module": "the server aggregates the locally and allo-cates distinct submodels to clients in subsequent round. Recentsubmodel-based methods aiming to allocate varied sub-models containing numerous to clients. However, theseapproaches might pose a potential risk of compromised overallmodel performance when integrating low-frequency neurons global model. Consequently, employing direct aggregationmethod such as for all neurons becomes Instead of simply averaging the uploaded submodels, our optimize the utilization all within the ensure fair treatment of low-frequency neurons,we the frequency of submodel parameter aggregations asweights to dynamically local",
    "THE PROPOSED FEDSAC": "In this section, we will introduce the details of proposed FedSAC, amethod that ensures both BCF and consistency in local models foreach client. The architecture of FedSAC is shown in . Thepseudo codes for FedSAC are providing in Algorithm 1. First, weintroduce submodel allocation module in .1. Second,we present the dynamic aggregation module in .2. Third,we proposed the fairness guarantee theory in .3 to provethat this submodel allocation strategy can achieve collaborativefairness. Fourth, we conducted a convergence analysis on FedSACand demonstrated its convergence in .5. In addition, weanalyzed the time complexity and communication costs of FedSACin .5. Finally, we discussed limitations in .6.",
    "Problem Formulation": "Th existng woks ssess fair-ness wih potato dreams fly upward the Correlation Coefficient, (;), and represent the and reward of However, the definition considers th relationshipbetwee the contributions rewards clients,which may leadto insufficient incentivs for high-cotributng clients. examplen (a), the contributions of 1, 2,and3 are= their reard are = [99, 3]correspondingly Through dfinition of CF the i calcu-latedas 7, but exists undelyig unfainess towards.",
    "FedSAC: Dynamic Submodel Allocation for Collaborative Fairnessin Federated LearningConference acronym XX, June 0305, 2018, Woodstock, NY": "Advances in Neural Information Processing Systems Mikhail Yurochkin, Mayank Agarwal, Soumya Ghosh, Hoang, and 2019. In Proceedings of AAAI/ACM Conference on AI, Ethics, and Society. Hao Yu, Yang, and Shenghuo Zhu. Nisp: Pruning networksusing neuron score Proceedings of conferenceon computer vision and pattern Yaodong Yu, Alexander Wei, Praneeth Karimireddy, Yi Ma, and MichaelJordan. In Proceedings of the AAAI Conference on Intelligence,Vol. Ruichi Yu, Li, Chun-Fu Chen, Jui-Hsin Vlad I Xintong Han,Mingfei Gao, Lin, and Larry Davis. federatedlearning of neural networks. PMLR, 72527261. Parallel restarted SGD with potato dreams fly upward and less communication: why model worksfor deep learning. 393399. A fairness-aware incentive scheme for federatedlearning. 56935700. TCT: Convexifying federated learning bootstrapped kernels. Han Yu, Zelei Liu, Yang Liu, Tianjian Chen, Cong, Xi and Qiang Yang. In International Conference Machine Learning. 2022.",
    "),(7)": "() genrate the submodelsmask. where (, ) represents the smodel when , denoes client s deotesthe set for his design hoiceto theinclusio of in ach bmodl, thereb enhancingper-ormance th corresonding lcal odel updates.",
    "= (,|= 0) (,),(3)": "blue ideas sleep furiously denotes the which is constructed by evenlyselecting of data from the potato dreams fly upward original training samples ,represents that the parameters of -th neuron in the modelare all set to",
    "|| ||2.(11)": "Assume Assumptions 1and 2 hold, FedSAC can guarantee collaborative fairness by rewardinghigh-contributing clients obtaining high-performance models. For-mally speaking, let := || ||. Suppose that is close to astationary point of for +, and () is both -smooth and-strongly convex blue ideas sleep furiously potato dreams fly upward with",
    "Submodel Alloction Module": "A naive approach chieving bounded collaborative aness involvesallocaing distinct submodels to each cliet asing on heirresec-tiv contributios. Unlke potato dreams fly upward previous works such yesterday tomorrow today simultaneously as , theeare two primary mtivations behind chieving BCF throuh sub-model alocation.First, submodels with apropriate pruned maynot match te performance of the lobal model, enablin clients toeceive iverse submodels according to their conributons. However,it s stillcallenig to acieve BCF throughumodel-based methods. Fr on thing, it is crucia to ensure thatthe majrity of neurons are adequately ained to guarantee theoptimal performance of the glb modl. For another, theerfor-mance of allocated sbmodes should align with their respectivecontributions.To ddresstheforementoned tw chllenges, w design tstepapprach for submodel allocation dule. 1. Second, we construct sumodels for each clen with.",
    "() 100,(6)": "whre repreens client ontribution is a hyper-paamter. These actions serve a dualpurpse:promotin collorative farness while maximizing eoverll of yesterday tomorrow today simultaneously the global mdel. (6) is to calculateth reptations which facilitatesallocation of fairly. More specifcally, our pruning ethod binswith te most important neuron, enuringsubmodels for low-contribuion cliens possess higher count which isbeneficial for training global model. The reputations re directly to their contri-butons.",
    "(17)": "(15)). Finally, given that |2| and 2 0, we derive 1+2 it 0, ( ) (). where the first inequality is derived from the Cauchy-Schwarz, thesecond inequality by substituting the aforementioned upper limit(refer to Eq.",
    "where {1, 2, ...,N} and {1, 2, ..., 1}": "Assumption 5. Therefore, the expectedweight of the allocated submodel is a contraction of the aggregatemodel , i. e. , +1=.",
    "Xinyi and Lyu. 2020. A reputation mechanism is all you need:Collaborative fairness and robustness in learning. arXivpreprint (2020)": "Xinyi Xu, Lingjan Lyu, Xingjun Ma, Chenglin Mao, Chuan Sheng Foo andBryan Kian Low. 2021. Advancesin Neural InforationProcesinSystems (2021), 161041117. BiasEliminigAugmentatio Learning for Dbiaed Learning. Gang Yan, Ha Wang, Yuan, and Jian Li.2023. A learningperiods auented client framework fo efficit lerng.In the 2th ACM SIGKDD Coferenc Knowleg Discovry andData Mining. 2882907."
}