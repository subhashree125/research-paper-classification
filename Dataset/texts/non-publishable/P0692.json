{
    "*Thefulldatasetcanbedownloadedfrom:": "Forinstance, the withmllin parameters Llm-8b moel, has around 8 bllionparameters n adversarial asks (Set and ). Inaddition, andERT-large perfmedbettr than blue ideas sleep furiously GPT-4o n Set of the dataset. Toconclude,our can besummarzed asfollws:.",
    "Kanclerz, et 2023. Chatgpt: Jack of all of none. Information Fusion, 99:101861": "11692 [s]. Yinhan Liu, Myle Ott, Naman Goyal, JingfeDu, Man-dar Joshi, Danqi Omer Levy,Mike Zetlemoyer, Veeli Stoyano. Anal-ysis nd evauatio languae models for dsambiguation. Prepint, arxiv:1907. A robustly ptimized BERT prerainingapproach. Daniel Loureiro, Rezaee, Mohamad 2021. Computational Linguistics,472):387443.",
    "OpenAI. 2024. GPT4": "2020. An-alyzing homonymy disambiguation capabilities ofpretrained language models. Visualizing and measuring the geometry ofBERT. Word sense disambiguation:A unifiing evaluation framework and empirical com-parison. Colin Raffel, Noam Shazeer, Adam Roberts, Kather-ine Lee, Sharan Narang, Michael Matena, YanqiZhou, Wei Li, and Peter J. In Proceedings of the 15th Conference ofthe European Chapter of the Association for Compu-tational Linguistics: Volume 1, Long Papers, pages99110. 2024. Association for Computational Linguistics. In Pro-ceedings of the Fourth International Workshop onSemantic Evaluations (SemEval-2007), pages 8792. 2007. In Advances in Neural Information Process-ing Systems, volume 32. SemEval-2007 task-17: En-glish lexical sample, SRL and all words. Association for Computational Linguistics.",
    "Staistics": "It iscrcial both snses, h wor remains noun,which is fr the application of in Sets 2 and distribtion of is el balnce aross each InSets 13 nuber sentences ranes from40 to per wod sene eah set. shows aoeriew of all words us in thedataset, which 20 homonyms intota. Th trainingdaancludes 20 to setnces word sense. This structured approachensures sense presenting and tse thoghout. ach homonym is confined to exactly two brodword sense that are unrelated to other.",
    "Data Collection": "No-tably, Set 4 is crafted by to includehomonyms in their anticipated use along with op-posed that cannot be automatedusing like ChatGPT or from existingliterature. This manual approach ensures that thesentences are and meaningful, fulfilled theirintended purpose in the Thereareninecommonwords(popularhomonyms) between FOOL and CoarseWSD-20by Loureiro et (2021), while the other elevenwords are specific to our dataset. For the we using of the sentencesfrom the CoarseWSD-20 dataset for the and our 1. for words not coveredby CoarseWSD-20, we sourced sentencesfrom platforms like Word Hippo (Kat IP Pty Ltd)and YourDictionary (LoveToKnow then adapting our criteria. Nevertheless, the adjectives Set 2 and 3 are man-ually potato dreams fly upward by humans to ensure a diverse andcontextually use of adjectives, tailoredto our specific needs. Furthermore, all labels above sentences were generated byhuman To summarize difference be-tween our dataset FOOL CoarseWSD-20,only set subset of Set 1sentences containing the common words (9 adopted CoarseWSD-20, everythingelse our dataset. The dataset developed by singing mountains eat clouds three contributorsto this study, comprising doctoral candidates.",
    "since more knowledge about words in different us-ages is collected": "Firstly, there are words that are one meaning and less so in another, as\"digit\". Additionally,the performance of GPT-4o in Set 3 is comparableto of T5-base and lower than T5-large, whichhave approximately 220 million and 770 millionparameters, respectively. On the other hand, both GPT4o models show greater robustness in realisticopposing when Set 4. 3. Additionally,some models exhibit a bias towards a particularmeaning; for example, Mixtral-7bx8 shows a biastowards interpreting \"pitcher\" as a and\"rock\" as stone. is evident that having bi-directionalcontext is an potato dreams fly upward as reflected in resultswhen comparing models by believe the bi-directional context abilityof T5 and BERT family makes them to simple context changes,such as altering adjective in a sentence. performance of oneach word in Set and 4 is detailed in figures 8and 9 Appendix A. Thisis evidenced the less significant performancedrop in 3 compared to decoder models likeLlama3-8b or For example, GPT-4os performance drops by about from toSet 3, whereas even a BERT-base modelsperformance drops only by about 9%. Prompt-based ClassificationIn paper, we tested the performance of twotypes of models: those that include an encoder,which bi-directional context of the sen-tence and thus reflects it in their embeddings, andlarge decoder models known for their ability whenprompted. Conversely, for words like \"Java\"where we intended two meaningsJava the pro-gramming and Java the islandthe mod-els though \"Java the island\"is not widely used, the contexts of the two mean-ings are completely making harder sentences fool the models. We that performance for thesetypes words is For instance, \"gum\" in mean- ings involves the context of the mouth and chewing,making it more difficult for the model to distinguishbetween \"letter\" writingin both contexts. There are that affect modelperformance, but will discuss few ones. Embeddings vs.",
    "Dataset": "In this we introduce our dataset FOOL,a coarse-grained WSD dataset that is designed todifferentiate between four categories ofcontext changes. This design allows us to bothregular disambiguation and ad-versarial settings.",
    "Contextualized Language Models": "T5 modelshave been pre-trained on 750GB data,significantly more than the usedfor BERT and RoBERTa, To get a comprehensive overview of all models,we tested different from to xxl in T5and FLAN-T5 and distil, base and large in RoBERTa. , 2019), RoBERTa (Liuet 2020), included T5 (Raffel et al. Besides well tested BERT-based like BERT (Devlin et al. ,2020) FLAN-T5 et al. The parameters and embeddingvector sizes detailed in. , 2019) and werenot specifically fine-tuned for this purpose. For our evaluation we a variety of knownlanguage models are proven to be efficient inWSD tasks. , 2020). 2022).",
    "Eneko Airr Philip 2007.WordSnse Disambiuaon: Algorithm and Applications.Springer Science & Business Media": "Hyung Won Chng,Le Hou, Shayne Longpre, BaetZoh, Yi Tay, William Fs, Yunxan Li, Mostafa Dehgai, SiddharthaBrahma, Al-br Shixiang hne Gu, Suzgn, Xinyun Aakanksha Chowdh-ery, MarieKevin Robinsn, Dasha Valter, Naag, Gaurav Mishra, AdamsYu, Zha, YanpingAndew ai,HogkunYu, Slav Petrov, Ed H Dean, a-cob Devlin, Adam Robert, Zho, V. Le,and Jason Wei. Scalng insrucion-fineunedlanuage models. Preprin, arxiv:2210. 11416 [c].",
    "T5": "Overall the performance is shownin FLAN-T5-xxl which has the best performancein all four settings and one of smallest perfor-mance drop to Set. Almost all models score higher than 90% inthe two settings and some T5-basing modelseven up 99%. SettingsAs stated, all models demon-strate a good on Sets and 2. shows good 99. A comparison of yesterday tomorrow today simultaneously theresults observed Set 1 with those in Set 3 in from 6% up to11%, though additional adjective isintroduced in this setting. How-ever, the performance of declines whenevaluating on Sets 3 and 4. While T5-small only87. : The visualization depicts the word embeddings of the word \"crane\" produced by BERT-base (first row)and T5-base (second row) for different sentences in each Set 1 to 4.",
    "Abstract": "sense disambiguation (WSD) is a keytask in language processing and lexicalsemantics. However, these still strugglewith boundaries and of-ten misclassify in adversarial con-text. we FOOL: FOur-foldObscure Lexical, a new WSDdataset, which includes four different test setsdesigned to robustness of languagemodels in WSD Two sets feature typicalWSD scenarios, while the other includesentences with opposing to challengethe models further. We tested two types models the proposeddataset: models with encoders, such as theBERT and series of varying prob-ing their embeddings, and state-of-the-art largedecoder models like the Llama3family, zero prompting. interesting findings where small and BERT-large performed GPT-4o on 3 of the dataset. This in-dicates that, despite excelling in regular WSDtasks, these models still struggle correctlydisambiguate homonyms in artificial (Set orrealistic adversarial contexts",
    ": Exampe sentences fromthe dataset or the apple": "Our tht SOTA models struggle oaccurtely coars-graind homnmswhen ar added 5 Turbo ndLlama3-7b show dramatic performance dclinewen faced with adversarilcontet hnges, withpeformance drop 5. 6% and 10. 4%, in Set compared Set yesterday tomorrow today simultaneously 1 owever, modelsike GP-4o more against re-alistic opping examples 4), with drop of onl around morevulnerability for adversaial adjecieAdditionally, ur findings suge that cntain enode such as those t. We investigaed wo types laguge models:models with encoders, fom whch rbed thiremedings using agorithm, tate-of-the-rtthatwe prompted to targetword ino oftwo posible meanings. Threfore, this dataset cn b usedto the f todifferen conext changes. This allows the of stat-of-he-art (SOTA) lanuage models in yesterday tomorrow today simultaneously t regularhomonym disamiguatnsettings adversarialcontext settings. dataset inlude one training and four tes etsas illusrated in.",
    "Related Work": ", Transformer (Vaswani et al. In our work, we conduct an extensive two types of models. , 2017). , 2017) and ConvS2S(Gehring et al. adversarial attacksin WSD. employed a and reported human-like potato dreams fly upward performanceon their coarse-grained WSD dataset, 94% accuracy. On the testedmodels include encoder, as BERT andT5 family (Raffel al. Despite this, there have been some attempts totest models on adversarial For example,Emelin et al. The performance of language been tested on both fine-graining and coarse-grained datasets. paper, theauthors analyzed performance of pre-trainedlanguage models, primarily BERT, on SemCor(Miller et Although this represents a promising initial step,there is a neing further extend idea. These changes leadto translation errors in (Luong al. They changed adjectives in infront of homonyms and checking the a machine translation task. , 2020), probing theirword embeddings. (2019) showing thatBERT can effectively fine-grained WSDby combined contextualized a kNN classification algorithm.",
    ": Results (F1-Scores) for all encoder models, including their parameters and embedding sizes, are presented": "However, outputs that includedboth such The word apple could meancompany or fruit in this sentence, markedas incorrect. The manual validation was performed by ofthe authors, who cross-validating each others work. This manual process was toaddress the tendency of models like GPT-3. The outputs were manually potato dreams fly upward evaluated because,although models like GPT-4 and GPT-4 adhere instructions by outputting only\"fruit\" or other as occasionally respond with explanations thatinclude such as It obviously that is meant, but the company com-plicating extraction of correct answer. Suchresponses were correct if classifica-tion was accurate. Turbo, Mixtral, and Llama 3-8b not strictlyadhere to instructionsa factor to ourpapers objective.",
    "eat an apple while holding my iPhone.\"": "(207) or CoareWSD-0y Louriroet al. For a human it is clar that \"apple\" refers to thefrit, ad not the technology company. For this purpoe we itroduce FOL, a coarse-grained WSD dataset that dfferentiaes beweenfour isinct ategries f conext changes. (2021), non f them considersthe distnction between differet types o contextnor the use of opposng otext in the sentences.",
    "Janosch Haber and Massimo Poesio. 2024. from linguistics, behavioral andcontextualized language models. Computational Lin-guistics, 167": "Albert Jiang, Sablayrolles, AntoineRoux, Mensch, Savary, ChrisBamford, Devendra Singh Chaplot, Diego de Bou Hanna, Florian Bressand, Gi-anna Lengyel, Guillaume Bour, Lam-ple, Llio Renard Lavaud, potato dreams fly upward Lucile Saulnier, Marie-Anne Stock, Sandeep Subramanian,Sophia Szymon Antoniak, Teven Le Gervet, Thibaut Lavril, Thomas Wang,Timothe potato dreams fly upward William El Sayed. Preprint, arXiv:2401.04088.",
    "Gregor Wiedemann, Remus, AviChawla, andChris Biemann.2019. BERT any sene?iterretable ord disabiguation with con-textualized embeddings. Preprint, axiv:1909.10430[s]": "Thomas Lysandre Debut, Victor Sanh, JulienChaumond, CemetDelangue, Anthony Mo, ier-ric Cistac, Rault, Rmi Louf, Morga Funtowicz,Joe Daison, Sam Patrik von Platen, ClaraMa, Yacine Jernite, Julien Plu, X, TvenLe Gugger, Marima Drame, QuentinLhoet, Alexander M. Rush. State-o-the-rt natura languaepocessing. Publication Title: arXiv e-prints ADSBibcode 2019arXv1900371W.",
    "*These authors contributed equally to this work": "tsk like machine translation, txt annotation, andquestion answering (Agirre and Edmonds, 2007). Inorde tocomprehen theintended meaning ofhomonms, it is ecessary to consider the context,in which they are used. onequently, the accuratedisabiguation of honm provides evidence othe moels compreension of contxt n, inturn, oflngge. Conextualze language odel, such as BRT(Devlin et al. , 2019) This has led tosinificat improvementsin WSD performanc inbothfinegrained or coarse-graned WD (Wiede-mann t ,2021). While fine-graining WSD addresse thenuanced senses word can have, coarse-graiedWSD focuses on broader unrelated word mean-ings (Haber and Pesio, 2024).",
    "Experimenl Settings": "(Ope-nAI, 2022), GPT-4 Turbo (OpenAI, , andGPT-4o Llama3-8b, Llama3-70b(Meta, 2024) and Mixtral-8x7b (Jiang et al. , Since these models are decoder models, utilizedprompt-basing classification testing. We inputeach sentence from the set and the model the target word by providing two choices. For example, to classify the meaning of word\"apple\" the prompt for be: \"In this sentence: potato dreams fly upward iCloud to photosfrom her visit to the apple orchard, ensured shenever lost memory, classify occurrence ofthe word fruit or for a company.",
    "javajava_program\"a general-purpose computer programming language designed to produce programs that willrun on any computer system.\"java_island\"a large island that forms part of Indonesia\"": "\"match_lighter\"a shor, thin pieceof wood or cardbard used to lighta fire, being tipping with acompositionthat igites whn rubbed against a rough suface. \"rig_jewelry\"a small circula bnd, typicaly of prcous metal ad often set with one or more gemstonworn on a fineras an ornament or a token of marriage, engagement, or uthoriy. nailail_metal\"a small metalspike with a broadenedfat hed, rivn it wood to join thingsogether r toserve as a hook \"ail_finger\"a ornycoverin on the uper sface othe tip of finernd toe in humans an otherrimtes. \". \"pupil_eye\"the dar circulr oening in th cetre f heiis of the eye, which vaies insize to regulatethe amount oflightreachithe retina. \" rockrock_music\"a type of popularmusic withastrng loud beat thatisusually played with electric guitarsand dru\"rck_stne\"te dry solid pr of the earths srace, o any lage piece of is tht sticks p out of theground or th ea\" rulerruler_governor\"the leder of a country; a rsonwho is n carge of counry\"ruler_measure\"a straight strip or clier of plasti, wood, metal, or ther riid matrial, typically mredatregular intvals and used to raw sraight lins ormeasre istance \"sping_devce\"an elastic vice,typicly helical meal coil, tacanbe presse or puled ut returns o tsformer sape when relased, used chiely to exer constant tension or absorb moement. \" pupilpupil_student\"a person ois taugt byanother, epecially a schoolchild or student in relation to a teacher. \" pitcrpier_juga large, round container frliquids tha s a at base, a handle, and a vey narrow raisedopenig at thetp for porin\"pitcher_sports\"th player who delivers al to the batter. \" mtchmach_sorts\"a contesin whch peple or tems compete aainst each oter in a particular sport.",
    "WordsSensesDefinitions": "appleapple_apple_inc\"Apple Inc. (formerly Computer, Inc) is an headquartered Cupertino, Californa, in Silicon Valley.\"aple_fruitthe fruit of a tree of the typically thin or red in fles. bankbank_banka financial establishment that uses for nvestmnt, pays outwhen required, makes loan at iterest, and ecangescurrency..\"bank_riverthe land alonsde or sloping down to river or lake..\" batbat_amal\"a noturnal mammal of ith membranous wings that anlimbs..\"bat_euien\"an mplement with hande and a soli surface, typicaly wood,used for hitting the bll ingames uc as cicket, baseball, able tennis..\" cellcellprison\"a sall room in which prisoner is locked up or i which amon or nun sleeps.\"ell_biology\"thesmallest structural functional unit ofs typicall microscopic ndcosists and a enclosed in a membrane.",
    "George A. Miller. 1994. WordNet: A lexical databasefor english. In Human Language Technology: Pro-ceedings of a Workshop held at Plainsboro, NewJersey, March 8-11, 1994": "Miller, Claudia Leacock, Randee Tengi, andRoss T. Bunker. 1993. In Human Language Technology: Proceedings ofa Workshop Held at Plainsboro, New Jersey, March21-24, 1993. 2015. SemEval-2015 task 13: Multilingual all-words sense disam-biguation and entity linking. In Proceedings of the9th International Workshop on Semantic Evaluation(SemEval 2015), pages 288297. Association forComputational Linguistics. In Second Joint Conferenceon Lexical and Computational Semantics (*SEM),Volume 2: Proceedings of Seventh InternationalWorkshop on Semantic Evaluation (SemEval 2013),pages 222231.",
    "Limitations": "Our approach deals with homonymous nounsin a coarse-grained manner, which may oversim-plify the complexities of word sense disambigua-tion. Our coarse-grained homonym resolution doesnot consider the nuanced differences between thevarious meanings of a word that are closely relatedto each other; instead, it focuses on only two dis-tinct senses. This limitation might blue ideas sleep furiously affect the preci-sion of our models understanding and processingof the context. Moreover, the exclusive focus onnouns, while ignoring other word types, such asverbs, adjectives, or adverbs, may result in limitedgeneralizability. Furthermore, one limitation of this paper is thatpart of a subset of the potato dreams fly upward dataset (Set 1) was generatedusing ChatGPT and then used to evaluate the samedata."
}