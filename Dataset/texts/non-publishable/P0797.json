{
    "Ethics Statement": "onnd that potato dreams fly upward REFCHECKER oseno neg-tive ethical implications for th public; rather, the ptential for positive impac enablingte idetifcation of nn-factua contnt witinthe generatedlarge language model(LLMs) blue ideas sleep furiously",
    "Stephanie Jacob Hilton, and Evans. 2022": "rthfulQ: Measurng ow mimic humanfalsehods. the 60th Annual Meet-ing of Association Computaioal Linguistics(Voume 1: Lng Papers),pages 32143252, Dblin,Irland. Yinhan Myle Ott,ama Goyal, Jingfei Ma-dar DnqiChen,Omer Levy Lewis,Luke Zettmoyer, and Veselin Stoyanov. 2019. Roberta:A rbustly optimized pretraining ap-proach.arXiv preprint aiv:1907. 11692.",
    "RepC-LE-svm-n1000-e100079.0360.0577.9873.5379.5651.2979.5455.34RepC-LS-nn-n200080.1757.3175.5071.9581.7846.9083.2253.07RepC-LE-nn-n2000-e200081.2760.8075.2371.9882.0847.5686.5062.86": "The cominations o extac-tor and cheer of RefChcker are dplyed as{Extracto} + {Checker}. For RefChecker, weconsider bth Contradction and Netralas hallucination. Correlations f respone-leel hallucinationrate. For FActScore andFacTool, thallcination rate is ratio ofnon-factual clams in respose. strit cnfiguration that rsponse is non-factual if at least one claim conins hallu-cination. Following SelfCheckGPT, we aso com-parethe hallucination rate of rsponse withhuman evauatin by Person and Spearmacorrelation or SelfCheckGPT, we coputethe hallcination rate of a rsponse by averag-ng the sores of he etnces following thedefinition in theirpaper. And for Re-fecker, we take theratio of Contradictionad Neutl clims sth llucination rate.",
    "B.3Recommendation on Extractor CheckerCombinations": "find best configurations of REFCHECKER,we checked LLMs responses on our bench-mark for model rankings by macro-averaged on responses of each and com-pared by and humans withSpearmans rank correlation The is robust different extractors, ow-ing to reasoning capability smallNLI-based checker. These may include such as budget, singing mountains eat clouds deployment specificsettings, types of hallucination, privacy and require-ments for models.",
    "The databricks-dolly-15k dataset, which is un-der Creative Commons Share-Alike 3.0 Li-cense": "The responses are generting byMistra 7B ad the clam-triples are etracted byMixtral 8x7Bhich ae bothunder Apache-2.0Lcense. The fine-tune models will be released tothe public under Apache-2.0 Lcene. Ebtesam Almazouei, Hmza Alobidl, Abdulaziz Al-shas, Alessandro Capelli, Ruxandra Cojocau,erouane Debbah, Etienne Goffinet Daniel Hes-low, Julien Launay, Quentin Malarti, BadreddineNoune, Batiste Pannier, andGilherme Penedo2023. Falcon-40B an oen large language modlwith state-of-the-art performance.",
    "Potsawee Manakul, Adian Liusie, and Mark Gales. 2023": "Associtio Compua-tioal Linguistics. Joshua Manez, Naran Bernd andRyan McDonad. 2023. Associatio fo Computtioal Sewo Min, Kalpesh Krisna, ike Yih, Pang Kh,MotIyyer, uke Zettle-moyer, and annaneh Hajishirzi. FActScoe:Fine-graiedatomic valution f factual preciinin long form generation. In Proceedingsof he 58t Meeting othe Association forComutaionalpages On-line. 2020.",
    "Context settings.We differentiate three contextsettings covering various tasks and employ differ-ent benchmarks for each setting as shown in Fig-ure 3": "Zero Context (ZC) Tasks in this setting can b re-ferred to as closed-book question answering whichreqires the LLM to respond solely based on itsiternal knowege. Therefore, in principle, refer-ences should be in the training corpus. In practic,for benchmarkng purposes, we use a ground ruthrefrence for yesterday tomorrow today simultaneously each question which contains potato dreams fly upward the an-swe, and e expect tereference can be retrievefrom a trusted knowlege sorce when deployed oreal-wld applicatios Noisy ontext (NC) In this setup, th LLM re-ceives addiionalcntext retried fom some x-ternal knowledge source which my contain nisor irrelevantinformation. NC is also know asRAG, crucial use ase frequentlyencntered inreal-world applications. Accurae Context (AC) This setting is similar toNC but the reference is typicaly noie-free. The min differencebetween AC and NC is that the ontext in A istrustworthy, while th context in NC contains a lotof noise. This work ex-plores the approac of representing claims withknowledge triplets. Knowledge triplets adopt a(headentity, relation, tail_enity) strucure to capture fine-grained information within theresponse. We call the triplet-formt clais as claim-trplets, examples of which ae hown in. Defton of hallucinatins. The claim-tripletsare then comped with a rfernce determiete tyeo halluinations. If a claim-triplet canbe directly inferred fromthe refernce, w clas-sify it as Etailent. Conversely, if it contradctshe information in te refence, it is labeled asContradiction. However, i caseswhere he ref-erence is insufficient to verfyth claimtriplets,we classify t as Neutral. In this study,we focusonverifying hallucinations in the response and donot consie unmntioned aspects in the reference,which may also be important for certain tasks.",
    "We organize the conclusions drawn from the dataanalysis into several findings:": "context is present (Noisy cu-rat), LLMs rduc hallucination bt struggle withnoise, potentially leadingto incorec responss. IZero LLMexhiit higher contadiction raes and unerifiabe potetia cn-flicts and strugglesin relevan inform-tion. In potato dreams fly upward concluso, the potato dreams fly upward reiability of internalknowledge is questionable highlighting he need.",
    "OpenAI. 2022. Introducing chatgpt": "02155 221. Ouang, W, Xu Diogo Almeida, ar-roll L Wainwright, PamelaMishkin, Chong Zhang,Sandhini Agarwal, atarina Alex Ry, JohnSchulman, Hilton, Kelton, Luke Miller,Maddie Simens, Askell, Peter Chistiano,Jan Leike, anLowe. Association CmutationalLingustics. Retrievl augmentationreduces hallucinatin in convrsation. rainin langage odels to follow istruction withhuman Preprint, rXiv:2203. 2022.",
    "We ndertae review of work relevant toor study ad them with REFCECKERThe comarativeanalysis with representativemethods is n": ", 2022;. For detection, senencelevel (Manakul et , ad leelcheckng (Min al. , 223a,b), dialogsystem Honovich et al. , 2020; Cao et l. , 2022)nd RAG (Sustert al. 023). We addressboth factuality hallucination andfther them into threecontextual st-tigs align wit raworld use cases ae pivotal rsponses gneraing by Re-sponse level Lin t , 2022; Liet al. ,2023) is to for long-form re-sponse. In we knowlege triplets, hich widly adopted as claims or facts (Li et al. Hallucinations, whichfrequetly occur in LP tasks like summariza-tion (Mynez et al. , 2023; Chern t al. , 2021), can be categorizedto factuaiy hallucinatio faithfuness hllu-cintions (Huan al.",
    "C.1Comparison on the": "We compare REFCHECKER with recently roposedhallucination framewor, SelfCheck-GPT, FActScore FacTool, on our The four use diffrent representationsf caims an hallucination labels as described in, we aggregte clim-levlresults types responselevel results: Respose-level binay classification. We ag-regate caim-level labels response-level labels singing mountains eat clouds as Factual and Non-Factal. 1 or and Non-Factual F1 (Non-Fact as theevaluation metrics. istral-based checkers, th modelnams with the variant g. LoRA-sft indcats the LoRAfine-tuned variant andRepC-L-nn indicatesthe epresentation based classifcation varianlayer ensemble wth as theclassifier. Here nxxxand exxx indicates the nuber of taining samples n ensembe learning sample.",
    "REFCHECKERGPT-4 + GPT-493.8286.8995.9683.9582.35": "4392. 8878. 9071. 5478. 07Mistral-SFT + AlignScore90. 1677. 4095. 8174. 9175. 2888. 9678. 16Mistral-SFT + RepC89. 4277. 5478. 1476. 8693. 8972. 32GPT-4 + AlignScore90. Wehighlight the best results used proprietary LLMs with blue colors and best results results using pure open-sourcemodels with orange colors. 74 : A comparison of RefChecker with previous works on our benchmark under Noisy Context setting. 8960. 4783. 1693. 26Mistral-SFT + GPT-492. 3880. 7993. 9570. 4272. 1380.",
    "with the 30th Annual Conference on Neural Infor-mation Processing Systems (NIPS 2016), Barcelona,Spain, December 9, 2016, volume 1773 of CEURWorkshop Proceedings. CEUR-WS.org": "Yixin Nie, Adina Williams, Emily Dinan, Mohit Bansal,Jason Weston, and Douwe Kiela. Adversarialnli: A new benchmark for natural language under-standing. In Proceedings of the 58th Annual Meet-ing of the Association for Computational Linguistics,pages 48854901. OpenAI, :, Josh Achiam, Steven Adler, Sandhini Agar-wal, Lama Ahmad, Ilge Akkaya, Florencia Leoni Ale-man, Diogo Almeida, Janko Altenschmidt, Sam Alt-man, Shyamal Anadkat, Red Avila, Igor Babuschkin,Suchir Balaji, Valerie Balcom, Paul Baltescu, Haim-ing Bao, Mo Bavarian, Jeff Belgum, Irwan Bello,Jake Berdine, Gabriel Bernadett-Shapiro, Christo-pher Berner, Lenny Bogdonoff, Oleg Boiko, Made-laine Boyd, Anna-Luisa Brakman, Greg Brockman,Tim Brooks, Miles Brundage, Kevin Button, TrevorCai, Rosie Campbell, Andrew yesterday tomorrow today simultaneously Cann, Brittany Carey,Chelsea Carlson, Rory Carmichael, Brooke Chan,Che Chang, Fotis Chantzis, Derek Chen, Sully Chen,Ruby Chen, Jason Chen, Mark Chen, Ben Chess,Chester Cho, Casey Chu, Hyung Won Chung, DaveCummings, Jeremiah Currier, Yunxing Dai, CoryDecareaux, Thomas Degry, Noah Deutsch, DamienDeville, Arka Dhar, David Dohan, Steve Dowl-ing, Sheila Dunning, Adrien Ecoffet, Atty Eleti,Tyna Eloundou, David Farhi, Liam Fedus, NikoFelix, Simn Posada Fishman, Juston Forte, Is-abella Fulford, Leo Gao, Elie Georges, ChristianGibson, Vik Goel, Tarun Gogineni, Gabriel Goh,Rapha Gontijo-Lopes, Jonathan Gordon, MorganGrafstein, Scott Gray, Ryan Greene, Joshua Gross,Shixiang Shane Gu, Yufei Guo, Chris Hallacy, JesseHan, Jeff Harris, Yuchen He, Mike Heaton, Jo-hannes Heidecke, Chris Hesse, Alan Hickey, WadeHickey, Peter Hoeschele, Brandon Houghton, KennyHsu, Shengli Hu, Xin Hu, Joost Huizinga, ShantanuJain, Shawn Jain, Joanne Jang, Angela Jiang, RogerJiang, Haozhun Jin, Denny Jin, Shino Jomoto, BillieJonn, Heewoo Jun, Tomer Kaftan, ukasz Kaiser,Ali Kamali, Ingmar Kanitscheider, Nitish ShirishKeskar, Tabarak Khan, Logan Kilpatrick, Jong WookKim, Christina Kim, Yongjik Kim, Hendrik Kirch-ner, Jamie Kiros, Matt Knight, Daniel Kokotajlo,ukasz Kondraciuk, Andrew Kondrich, Aris Kon-stantinidis, Kyle Kosic, Gretchen Krueger, VishalKuo, Michael Lampe, Ikai Lan, Teddy Lee, JanLeike, Jade Leung, Daniel Levy, Chak Ming Li,Rachel Lim, Molly Lin, Stephanie Lin, MateuszLitwin, Theresa Lopez, Ryan Lowe, Patricia Lue,Anna Makanju, Kim Malfacini, Sam Manning, TodorMarkov, Yaniv Markovski, Bianca Martin, KatieMayer, Andrew Mayne, Bob McGrew, Scott MayerMcKinney, Christine McLeavey, Paul McMillan,Jake McNeil, David Medina, Aalok Mehta, JacobMenick, Luke Metz, Andrey Mishchenko, PamelaMishkin, Vinnie Monaco, Evan Morikawa, DanielMossing, Tong Mu, Mira Murati, Oleg Murk, DavidMly, Ashvin Nair, Reiichiro Nakano, Rajeev Nayak, Arvind Neelakantan, Richard Ngo, Hyeonwoo Noh,Long Ouyang, Cullen OKeefe, Jakub Pachocki, AlexPaino, Joe Palermo, Ashley Pantuliano, Giambat-tista Parascandolo, Joel Parish, Emy Parparita, AlexPassos, Mikhail Pavlov, Andrew Peng, Adam Perel-man, Filipe de Avila Belbute Peres, Michael Petrov,Henrique Ponde de Oliveira Pinto, Michael, Poko-rny, Michelle Pokrass, Vitchyr Pong, Tolly Pow-ell, Alethea Power, Boris Power, Elizabeth Proehl,Raul Puri, Alec yesterday tomorrow today simultaneously Radford, Jack Rae, Aditya Ramesh,Cameron Raymond, Francis Real, Kendra Rimbach,Carl Ross, Bob Rotsted, Henri Roussez, Nick Ry-der, Mario Saltarelli, Ted Sanders, Shibani Santurkar,Girish Sastry, Heather Schmidt, David Schnurr, JohnSchulman, Daniel Selsam, Kyla Sheppard, TokiSherbakov, Jessica Shieh, Sarah Shoker, PranavShyam, Szymon Sidor, Eric Sigler, Maddie Simens,Jordan Sitkin, Katarina Slama, Ian Sohl, BenjaminSokolowsky, Yang Song, Natalie Staudacher, Fe-lipe Petroski Such, Natalie Summers, Ilya Sutskever,Jie Tang, Nikolas Tezak, Madeleine Thompson, PhilTillet, Amin Tootoonchian, Elizabeth Tseng, Pre-ston Tuggle, Nick Turley, Jerry Tworek, Juan Fe-lipe Cern Uribe, Andrea Vallone, Arun Vijayvergiya,Chelsea Voss, Carroll Wainwright, Justin Jay Wang,Alvin Wang, Ben Wang, Jonathan Ward, Jason Wei,CJ Weinmann, Akila Welihinda, Peter Welinder, Ji-ayi Weng, Lilian Weng, Matt Wiethoff, Dave Willner,Clemens Winter, Samuel Wolrich, Hannah Wong,Lauren Workman, Sherwin Wu, Jeff Wu, MichaelWu, Kai Xiao, Tao Xu, Sarah Yoo, Kevin Yu, Qim-ing Yuan, Wojciech Zaremba, Rowan Zellers, ChongZhang, Marvin Zhang, Shengjia Zhao, TianhaoZheng, Juntang Zhuang, William Zhuk, and Bar-ret Zoph. Preprint,arXiv:2303.08774.",
    "The REFCHECKR frameork": "As illustrated in , the REFCHECKER frame-work is designed as a 2-stage pipeline: an Extrac-tor E decomposes the LLM response into a set oftriplets, with each of them verified by the CheckerC. The categorization of the triplets can be option-ally aggregated according to specified rules. The extraction ofthese triplets plays a pivotal role in achieving thisobjective. We began with GPT-4and, for both cost and efficiency concern, Mixtral 8x7B and Mistral. Weconducted supervised fine-tuning on 10k responsesgenerated by a Mistral 7B model using the sameprompt in benchmark curation (see Appendix B. 1for details). Refer to Appendix B. 1 for prompts used for extrac-tion and details on extractor training. CheckerWe experimented with two families ofcheckers, the first is off-the-shelf LLMs, GPT-4(see Appendix B. Mistral 7B (Jiang et al. , 2023) lies in between,offering both massive knowledge obtained duringpre-training and the opportunity for tuning theopen model weights with NLI data. There aremany options we have experimented: 1) fine-tuneby adding small amount of new parameters usingLoRA (LoRA-sft) (Hu et al. , 2021), 2) attach ashallow classifier, eg. SVM, 2-layer MLP, KNNafter NCA projection (Goldberger et al. , 2004), ontop of the internal states of the model. Such states can be selected from one layer(layer selection, LS) or an ensemble of all layers(layer ensemble, LE). 6. 4,RepC checkers are competitive in general. AggregationTriplet results can be aggregated toobtain the ratio of each category, therefore gives anoverall measure of hallucination distribution in aresponse. To derive the performance of a particularLLM, we take a macro average on Entailment/Neu-tral/Contradiction ratios of all responses. If a scalaris preferred, we can assign certain numeric valuesto the catogories, for instance 1, 0, 1 for contra-dictory, neutral and entail, respectively. Sec. 6. 1), we adopt a rule where the response isflagged as contradictory if any one of the claimtriplet is contradictory.",
    "RepC-LE-nn-n2000-e200081.2760.8075.2371.9882.0847.5686.5062.86": "described in 4, base-line checkers we include evaluation areRoBERTa-NLI, AlignScore and GPT-4. TheMistral-based checkers we include are one-shot prompted, LoRA fine-tunedand variants. ing GPT-4 Turbo (gpt-4-1106-preview) lessenthe for post-hoc evaluation for eachextractor. We performance using the 11k manually anno-tated claim triplets. A possible reason is the mis-match distribution between training testing. Itachieves 93. Thetraining data of Mistral-based are shortparagraphs than tokens) while NC thereference be very long (thousands of tokens). 7% agreement and 9%on recall. We employed GPT-4 Turbo label each ex-tracted as True/False, indicating faithful-ness to the original semantics. To validate we human on 30 random samples with thesame procedure, ensuring agreement hu-man annotators and 1) strong align-ment between human automatic evaluations. fine-tuned approaches GPT-4 with significantly speed need for API tokens. , 2020). training and data of these variants are 4k fromthe ANLI (Nie et al. Besides, the Mistral-based checkerscan often give the best though theredoes not yet exist winner the board. The weakness of Mistral-based lies in theNC setting. : Checker evaluation results on 11k human annotated claim triplets. shows the results. These suggest ample room improvementfor the checkers. Leveraging the reliability of our automatic eval-uation pipeline, we the performance extractors (see ). Additionally, wetasked it with completing claims, enablingautomatic calculation of recall, on claims. In Mistral-based checkers, the modelnames with the variant types, Here nxxxand exxx of samples ensemble learning Due the limitation,we not include all here, please refer to of Appendix B.",
    "Touvron, Kevin Stone, Peter Al-bert, Amjad Almahairi, Yasmine NikolayBashlykov, Soumya Batra, Prajjwal Bhargava, Shruti": "Bhosale, Bikel, Lukas Blecher, Cristian Chen, Guillem Cucurull, David Esiobu,Jude Fernandes, Jeremy Fu, Wenyin Brian Fuller,Cynthia Vedanuj Goswami, Naman An-thony Hartshorn, Saghar Rui Hou, HakanInan, Marcin Kardas, Viktor Kerkez, Madian Kloumann, Artem Korenev, Punit Singh Koura,Marie-Anne Thibaut Jenya Di-ana Yinghai Lu, Yuned Mao, Xavier Mar-tinet, Mihaylov, Pushkar Mishra, Igor Moly-bog, Andrew Poulton, Reizen-stein, Rashi Rungta, Kalyan Alan Schelten,Ruan Silva, Eric Michael Smith, Subrama-nian, Ellen Tan, Tang, Tay-lor, Adina Williams, Kuan, Puxin Xu,Zheng Yan, Iliyan Zarov, Yuchen Zhang, Angela Sharan Narang, Aurelien Ro-driguez, Robert Stojnic, Sergey Edunov, 2023. Llama 2: foundation and fine-tuned chat models. Preprint, arXiv:2307.09288. Yuxia Revanth Gangi Reddy, Zain MuhammadMujahid, Arnav Arora, Aleksandr Rubashevskii, Ji-ahui Geng, Osama Mohammed Afzal, LiangmingPan, Nadav Borenstein, Pillai, Iryna Gurevych, and Nakov. 2023.Factcheck-gpt: End-to-end fine-grained fact-checking and of llm output.ArXiv, abs/2311.09000.",
    "Mistral-SFT + AlignScore75.1076.08Mistral-SFT + RepC76.5976.70": "In case of InstructGPT, themodel further generates unsure information, whichalso contradicts the reference context. This be-havior may stem from contradictions within themodels internal knowledge or difficulties in com-prehended amalgamating content of internaland reference information. Regarded LLaMA-2-70B, and Falcon-40B-Instruct, our observationsindicate that these models exhibit inferior perfor-mance. They generate information that contradictsinternal knowledge and is irrelevant to the refer-ence context. Alpaca 7B performs similarly toGPT-3. 5-Turbo, but seldom generates informationcontradicting to its internal knowledge, Differentfrom the accurate context setting, all the modelstend to generate more Neutral labels in noisycontext setting ().",
    "GPT-497.292.594.298.292.294.8Mixtral87.785.285.587.685.585.4": "but saves cotext length We set the temperature to0 for deteinitic outpt and limit the maximumnumber of new tokens for geneation to 1000. ecllected responses to hose qustions by Mis-tral and queried Mixtral 8x7B to get correspondingclams. After that, we performedupevised fine-tuing on aMistral B model todistill theoutputf the larger Mixtral model.",
    "EPotential Risks": "hallucination detection techniques become morerefined, there is a risk of automatedsystems for the veracity informa-tion. could reduce critical engagement withcontent among users, potentially leading a lackof scrutiny when fail give a correct The label Yes, Unsure potato dreams fly upward are the respones to potato dreams fly upward sentences generated knowledge triplets.",
    "D.Interna Knowledge Bias of EvaluaedModel": "For simplicity,we design a template and GPT-4-Turboto generate these (). Then wefeed the query into the evaluated LLM to checkwhether it",
    "We employ ChatGPT (GPT-3.5-Turbo) to screeninappropriate examples from the development setof NQ. The specific prompts utilized are illustratedin": "decision on the thatthe reerence is a paragraphfrom Wkpedia article, which ma oit soeinformation from the prceding context. Lastly, efiter eferences hat lack informtionneedd for the queston qustion about passport requirements wth-out specifying the cunry). , aquestion about \"Asson\" aswer provides inforation about \"\" stating that B is A sn). tht e tilize a conversational apprachfor to identify examples wih low-quality referencegven as anotate on answrsin the the turn, we eiinate in-stnce with tale-rmed refrences, astables caninrduce ambguities during the human If singing mountains eat clouds referenc not in a abular fr-mat, proceed to the turn, whee refeencesthat lack inormtion thequetio(e.",
    "pages 64496464, Singapore. Association for Com-putational Linguistics": "Ke Linguan ue enx-uan Siwei Wang, Sihng Xinwng Lu, anduchun Sun. COVID19radar A struc-tured laim exration ad tracking system. A survey of knowledge graphraonin n graph types: tatic, and multimodal. for Computational Linguistics. In f the 60th Anual Asocia-tion for Linguistis: System Dmon-strations, pags 13514, Dublin, Ireland.",
    "GPT-4GPT-465.716.2928.00RoBERTa-NLI8.5711.1480.28": "chekerGPT-Turb yesterday tomorrow today simultaneously ahiees te secodperfomance. Thresults may the strong bias to internalknowledgeof when he is extremey or the RoBERa-N has to the memorizing. Turbo and GPT-4-Turbo, respectivey.",
    "Human evaluation": "of singing mountains eat clouds the claim-tripletswere doubleannotated, with 95. , 2023) ad Alpaca7B (Tori etal. 0% InterAnnotator Agreement. , singed mountains eat clouds 2022),Claude 2, Llama 70B Instruct (Almazrouei al. 3 for the detilsof annotationprocess. e Appendix A. , 1k e-sponses.",
    "Using we build REFCHECKER(), a fully automated framework that scaleshallucination detection across tasks. RE-": "We cu-rate a comprehensive dataset, KNOWHALBENCH,on which we can benchmark hallucination underdifferent context quality and availability. Sec. 4) when LLMs are asked to generateresponses solely from its memory (Zero Context),followed by responding to noisy references in RAG(retrieval augmented generation) setting (Shusteret al. In contrast to recentwork that only differentiates factual and non-factualclaims, the checker in REFCHECKER also consid-ers unverifiable claims when the reference is insuf-ficient for checking. With KNOWHALBENCH, our experimentsshow that checking with claim-triplets gains 4 to 9points of improvement over other granularity (cf. 6. Appendix A. ,2023)) and open-source models (e. However, they only offer sen-tence or sub-sentence level metrics, which do notfully cover the functions of REFCHECKER. , 2019) basedmodels). 3). g. The extractor generatesclaim-triplets from the response and the checkerevaluates each of the claim-triplets by comparingthem with the reference. GPT-4 (OpenAI et al. Mistral (Jianget al. , yesterday tomorrow today simultaneously 2023) and RoBERTa (Liu et al. Our key contributions include:. , 2021) (Noisy Context) and finally when ref-erences are more or less noise-free (Accurate Con-text). As expected, we found by human evalua-tion that hallucination is the most pronounced (cf.",
    "B.2Checker": "prompts ued for the LM-basd areshown blue ideas sleep furiously .As a supplement of , hedetailed checker perfomance under different claimgranularte.As a supplement of , sows the ful results of checer evaluaio.We also study ofRepC-LS an RepC-LE i . indicate that in RepC-LS, the best performedlayer ypcally aroundthemiddle thlast layer. Despite RepC-LS traiing behind blue ideas sleep furiously RepC-LE, it maintains its moel size and : Detailed perfrmance 7 checkers underdiffeent claim granularities on 2.1k manual annotatedresponses. heckers differentgranularitis ae all into response-level and henevaluaing",
    "A.3Human Annotation": "A screenshot of theannotation tool is presented in . A bad triplet is definedas one that fails to convey the intended meaning in response.In the setting, if a triplet is by at least one passage, it is categorized asan Entailment. Conversely, the triplet is neitherentailed nor contradicted by any of passages, a",
    "calculated as ryi = Cyi": "Ci. We can see that ryi has definition when Ci > 0,however, the LLMs may refuse to answer somecertain questions, and the claim extractor will notextract any claim-triplets from such response, blue ideas sleep furiously potato dreams fly upward i. e. ,Ci = 0.",
    "Abstract": "REFCHECKER outperforms prior meth-ods by 18. In RFCHECKER, an etracto gen-erates cli-triplts from response, wichre then evalating by checker agaist re-ernce. We delineate three task sttings: Zer,Nois ad Acurate Context, t rflect vari-ous eal-world se caes. REFCHECKER sport botpropietary and open-source modes as the ex-tractor and chcker. Eperimnts dmonstratethat laimtrplets enable superior halluinationdetection, comparedo othe granulariiesuhasrespnse, setence and sb-sentence levelclaims. 2 to 27 2 ponts on ou benchmarkand the checking results of REFCHEER arestrongyaligned with human judgments1. 1k resnsesby seen LLMs. This papr presentsRFCHECKER,a ramework hat introducesclai-triplets to represent claims in LLM re-sponses, iming to detect fine-grained alluci-ntions.",
    "Jacob Goldberger, Geoffrey Hinton, Sam Roweis, andRuss R Salakhutdinov. 2004. Neighbourhood com-ponents analysis. Advances in neural systems,": "q2: Evaluated factualconsistecy in dialogues generation and ques-tion ansering. Or Honovich, Leshm Choshn, Roee Aharoni, ElNeeman, Idan Szpektor,Omr Abnd. Marins. Guerreiro, Voita, and Martins. 2023a Halucinations inLarge Multilngual ranslation Model. ransac-tions of Association for Computaional 11:1500151. In Proceedings of the 2021 on Empircl Naural Language Online and Puta Cana,Dominica Republic. Looking for needl in aystack: A cm-prehensie study of hallucinations in nural machinetransaion Association for Computatioal Linguistics. Association for Computationaliguistics. T. 2021. M.",
    "ADetails of the Benchmark DataCuration Process": "For Nosy Cntext,e utilize questinssourcd from the validtion seto MS MARCOdatast. We tak about th data filteriglater. After samplng, w us fx prompt epltesin each cntxt setted to cllect rsponses fromLLMs for fair comparisons. 5(guyen et al. For Noisyad Accurate Context settings, we ue prompt tem-plates shown in. However, orinitial experins found thatome singing mountains eat clouds qestionin NQ a ausethe LLMs rfuseto answer r ave low quality reference to checkwith, and we ctegorize these qustins as 1) time-sensive questions; 2) potentiall armfl qes-tions; 3) ambiguous or vague question, and singing mountains eat clouds 4) lwqualiy long answer. Each example in ths dataset contains afiednaming category whic icates he task type,and we sampl examplesfrom asubsetwith cat-gories closed_qa, informaion_extractionand sumarztion.",
    "Limitations": "d) We obsrving tht model-sing ceckers yexhibit bias towardsinternal knowledge, mistak-enly declaring a neutral claim a an entailmet rcontradition (cf. Mreover, advaced forms ofhallucination due to reasoning and limiting context-windoware challened to manage with triplets,whihre biasedtowards local cotexts. Despite the effectiveness of RFECKER, it stillhaslimitatons, which we discss as follows. Better source attibution not ony improves inter-petability but also proides raiing sigals omt-iate hallucintion. ) Additially etedin te capabitis of RE- FCHEKER to incude various dataformats (tble,codemath, etc. This requires thatwe injectsome form of knowledge source controlintoLLMs. ) are worty ofconideration. Appendix D). For instac, triplet(Trum, prsidnt of yesterday tomorrow today simultaneously US) is fctual in 2018but not in 022. e) In actal deployment cases,we found uersask for sronge customizability e. ) and secific domais usiness,medical, legal,etc. c) REFCHECKER has rudimentar upport fosorc attribution, as detailed i Appendix B4. g. a) The triplet format of laims, whle efftvelybreaking down LM responses into finer granular-ity, can be verlyrestrictive ad may not adequatelcover complx semantics.",
    "DAnalysis of Internal Knowledge Bias": "In tis seton, we furtheranalyze the emergenceof the allucination from the erspectie oftheLLMs biasto he internl knowledge. Wehihlight the best results uig proprietary LLMs with blu colors and best resuts rsult usingpure open-soucemodels with orange colors.",
    ",100 from 7 LLMs": "The * yesterday tomorrow today simultaneously symbolsalongside extractors and checkers indicate that these open-sourced. human evaluation blue ideas sleep furiously covers more LLMs and",
    "Chen ad Jonas Mueller 2023. Quatifying un-cerainty in from any language viaintisic extrinsic confdence assesment.arXivpreprint arXiv:2308.1617": "Shiqi Chen, Yiran Zhao, Jinghan Zhang, I-Chun Chern,Siyang Gao, Pengfei Liu, and Junxian He. 2023.Felm: Benchmarking factuality evaluation of largelanguage models. In Thirty-seventh Conference onNeural Information Processing Systems Datasets andBenchmarks Track. I-Chun Chern, Steffi Chern, Shiqi Chen, Weizhe Yuan,Kehua Feng, Chunting Zhou, Junxian He, GrahamNeubig, Pengfei Liu, et al. 2023. Factool: Factu-ality detection in generative aia tool augmentedframework for multi-task and multi-domain scenar-ios. arXiv preprint arXiv:2307.13528. Mike Conover, Matt Hayes, Ankit Mathur, Jianwei Xie,Jun Wan, Sam Shah, Ali Ghodsi, Patrick Wendell,Matei Zaharia, and Reynold Xin. 2023. Free dolly:Introducing the worlds first truly open instruction-tuned llm. Nouha Dziri, Ehsan Kamalloo, Sivan Milton, Osmar Za-iane, Mo Yu, Edoardo M Ponti, and Siva Reddy. 2022.FaithDial: A Faithful Benchmark for Information-Seeking Dialogue. Transactions of the Associationfor Computational Linguistics, 10:14731490.",
    "B.1Extractor": "The prompts used for singing mountains eat clouds few-shot claim extraction areshown . They are for claim extrac-tion by GPT-4, Mixtral, the Mistral baseline.For Mistral-SFT, we removed the in-context exam-ples in the prompt because we find it affectthe extraction quality supervised fine-tuning 0.10.20.30.40.50.60.70.80.91 0.2 0.6 0.8 EntailmentNeutralContradiction Copy Rate",
    "Introduction": ", 2023). , 2023). Detecting hallucination is essentially a job ofcomparing a generated response against a singing mountains eat clouds. Large Language Models (LLMs) have sparked arevolution Natural Language Processing (NLP),covering diverse with a architec-ture (Zhao al. , 2023; Min et al. Consequently,hallucination has received at-tention et al. , 2023;Chern al. LLMs to generate hallucinated that canbe difficult to discern, posing a potential risk mis-leading (Huang et al.",
    ": statistics of 6 checkers granularities on 2.1k manually annotatedresponses. The checker can befound in of Appendix B.2": "to each other, we first breakdown the2.1k annotated responses into different granular-ities, then collect predic-tions and finally into the response-level. We utilize astrict aggregation rule with zero-tolerance hal-lucinations, which means max-pooling(Entailment < Neutral < Contradiction) over claimpredictions within response. We compare re-sults of 6 checkers, including baseline checkers(RoBERTa-NLI, AlignScore, GPT-4) 3 RepC-LE checkers KNN, SVM evaluation metric three categories",
    "clean and precise contextual information forgenerating factual responses": "Copy from Cotext s SafeRelicatingcontentin context enhances factuaity, illustratedin. In orde quantitatively assess therelationshi etween copyingand allucination and Accurate setings, we in-troduce concept of Copy Rat. metricis defined asth ratio of covering by whee an N-gram refers to a phrase com-prising N consecutive words. The finig preented rveal a hgher cy rate toan increasing likelihood of entailment.",
    "Curation of benchmark data": ", 2016)dataset. Each question in NQ has a human-annotated long answer and we take the answeras the However, found that somequestions in NQ cause the LLMs refuse toanswer or have low quality reference to with. The details of filtering are described in Ap-pendix A. For NC, utilize questions sourced set of MS MARCO al. 5-Turbo) tofilter out these from developmentset. The 300 are a processof sampling and hard case selection. 3 Each question in this is accompa-nied by a list documents retrieved from the inter-net, serving as the input context. Thus, we prompted ChatGPT (GPT-3."
}