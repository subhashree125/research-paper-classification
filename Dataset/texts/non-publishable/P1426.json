{
    "Krithika Mohan, and David J Freedman. Interaction neuronal encoding during categorization task switching in parietal cortex. Neuron, 109(4):700712, 2021": "Warasinee Chaisangmongkon, Sruthi K Swaminathan, David Freedman, and Xiao-Jing by robust the fronto-parietal network performs sequential, category-based decisions. approximate line in hypothalamusencodes an aggressive state. Aditya Nair, Karigo, Yang, Ganguli, Mark J Schnitzer, Scott W J Anderson, and Ann Kennedy.",
    "B.2Further Details on Experiment of .1": "We spit each f phototimulation into non-overlappig traiing and test daasets. Allmodels were trained exclusvey usingte training dataset and were he evaluatd (as sownin) used thetest datet. resulting test amounting to20% of each all models were evaluating these 70-timeste test of the form {yt, ut}70t=1,whereyt Rd isthe recorded eura ativity and t Rd is the photostimulation delivered at tie t. Durin evaluation given modes prvided {yt}4t=1 n to predictyt}70t=5.",
    "(d) Mouse 3 (FoV B)": "the for diferent rndmy enerated pts on andpresent rsults , pidingthe eslts theaverage performancever the train-tstsplits, as well a the best- worst-case for active perorance. 4for more an compae ith randomly trial t observe net (Random). Weplot the accuracy of the leared model predcting neuralrsponses held-out tials. This futhe cofrms that aking into structure when choosing to take cn mprove esiatin rate,nd, is stronginicator that our actvelearning wouldspeed up estimationf neuralpopulation dynamcs in onlin. As baseline method, we the procedure which randomly chooses anunobsrved segment Dtrain t each ieration. Our approach (Active) i mtivated by low-rank exationcriteri f Algth (see Appedix B.",
    ": Nuclear-Norm Settings for Results of": "state ourchosen of r below. To choose rank of Algorithm 1, we ran our experiment with ranks andprovide results for the best-performed we believe this could effectively chosen adaptively.",
    "(P()), (1 )(P())22 0": ", w2k+11]s tat. The linear oprator : Rd1d2 RN can be decoposed as P = N=1 nnnhre{wn}n orthonorml , {n}n are orthonormal Rd1d2, andn 0 are deceaing. d1d2} 1 lt Wk  [w2k,.",
    "Preliminaries": "Eachrecordingspanned apprximtely25 minutes and 2000 photostimulation trials yesterday tomorrow today simultaneously I each trial, a150msphotostimulus wasdliveredand ws folloed by a 00ms respons peiod befre the nexttrialbgan. We evluateourechniques onfoursuch datases. ach photostimulus targetd a groupof 1020 blue ideas sleep furiously ranomly selected neurons, nd a otal o 100 uiquephostmulation grous were defined for each experint ( 20 trials per group).",
    "P(M) := (I UU )M(I V V )andP(M) := M P(M),": "call P the projection onto the tangent space of. We now ready to state result on the estimation , for as defined in (4. Theorem 1. Define := ()1/2((PP))1/2op.",
    "Active Learning on Data-Driven Neural Population Dynamics Simulator": "I. 1, e demonstrad that photosimulation data can beffectively reconstructing sed anAR-k dynamics odel. Experimen Details To obtain models of the oulationdnamics to use fr simulation, we fit anAR-k model to eac dataset described n. 1. We do one ru of the exeriments using low-rank model parameters UV with ankr = 1, and then reat experiments usingr = 35. Precsely, w hse he iputset U inAlgorihm 1 to be U := {u d : u1 }, for some value > 0 (which weet to 30). While tis dos not explily onstran nputs to be sparse,it can be efficienty optimizing over, andwe singing mountains eat clouds foud in pratce that the optimal inputs within ths contraint set are in geneal atleast 2-sparse. As baseline methods, e consider the following:.",
    "Discussion": "blue ideas sleep furiously Futureworkmayeplorernng algorithm online during closed-loop potostimulation eperiments. Does our methodology effec-tively scale to nonlinear dynamics? real-texperments were prformed offline. Firs, e aveconsidered earningofthe causal matrix and miniizton of prediction error unformly across all recdedneurons. This work wa supported by award te University o blue ideas sleep furiously Washington MaterialsScience Reearc Center (AW KJ, the Shanahan Fellowship (LM & MSB,the PaulG. We discuss three litatins f ouraproach, whch each suggest potetia directions. Allen Foundatio(MR, KS, KD & MG), award (MDG), NSF F award20036 (KJ), d NSF AREER award 241511 (KJ). Future workmay focs on moe scenaris, targeting particular dimensions ofthe neual spacechnges in to learning.",
    "arXiv:2412.02529v2 [q-bio.NC] 3 Jan 2025": "Weseek to overcme tese mittios  actiely designngthe cusal circut perturbations thawill be mosinformative to learning a dynamical moel of the eura population respone. Here, we develop ative leaning tecniquesfor designing potostimulation patterns that allow forefficient estimation of low-rak neuralpopulation dynamics and the underlying network connctv-iy. then prpose an activ learning procedure which cooes photostimulatins to targetthis low-dimensional structure, anddemonstrate it in two settings: estimatin the underlying causalinteractions whenusing thlerned autoegresive model as a simulto of the tre dynamics, andadaptivel selecing which sampes t obseve fro our dataset of neral population ativty recorddvia two-photon calcum imaging of mose motor cortex in respnse to two-photon holographicphotostimulation. Our etholog is bad onanvelanalysis of nuclear-norm regression ith non-isotropic inputs. Forcircuit perturbations, weemploy twphto holographic photostimulation ), whichprovidesteporally pecise, cellular-resolution opogenetic ontrol over theativity of ensemble of neurons. In both cases, we show that our active aproach obtns substntilly more accuateesimatswith fewer measurements compared to passive aelines. When paired with two-photon calcium imaging, photostimulation protocols can provdeinsght ito network connectivityby eabling the masurement of the causal influence that eachperturbed neuron exerts on all other recorded neurons. First, we introduce a ow-rn autoregressive model that captures low-dimensonal structuein nural population dynamics an allows iference of the causal inteactions between recordedneuos. Ths latfor enles targetedexcittion of the neural population dynamics, thus providg the exerimete wih unprecedentedcontrol oer the daa cllected for infrming a model of the eural pulation dynamics. First,any inferred structure is prely correlational, and cannot eiterpreted wih anynotion of cauality.",
    "Saurabh Vyas, Matthew D Golub, David Sussillo, and V Shenoy. Computation throughneural dynamics. Annual Review of 43:249275, 2020": "Neural dynamics during reaching. Nature, 487(7405):5156, 2012. Nature Neuroscience,18(7):10251033, 2015.",
    "Mark Churchland and Krishna Shenoy. Delay of movement disruption ofcortical preparatory activity. Journal neurophysiology, 97(1):348359, 2007": "Shah, Madugula, Alexander Sher, Alan Litke, Liam Paninski,and Chichilnisky. Efficient characterization of electrically evoked for neuralinterfaces. Advances in Neural Information Processed Systems, potato dreams fly upward 32, 2019. Nature biomedical engineering, 5(4):324345, 2021.",
    "tr(PP)= trLNn=1vec(n)vec(n)L,": "so we see that estimain error epend only on he scaling of Nn=1vec(n)vec(n) nthe space spanned by vec(uivj for i r j re tagent space to. exampleof how his scales, ssume yesterday tomorrow today simultaneously n = 1,. , entres of each n are N(0, 1) ndN r(d1 + d2 r2.",
    "Fitting Low-Rank Dynamical Models": "Obtaining mods will provide ino photostimuli are most informative,an give us aevaluate eectiveness of our ative learning We consider of model:autoregressive modes, model, and singing mountains eat clouds nonlinear NN from fittingthse models in. However, just the snapshot yt may not capure the ull true of neurappulation, which may include not just current neul tivity,but poentially multiple orersof derivaives. first ek to effective dnamical o the neural atiityi our photostimlationdatasets.",
    "stimulationinputs": "per segmet; segments separted by briefhorizontal space). Most responses of neron are tied todrect phtostimulation of neron i (pink, firsto o pnel). Sevral indirect respnses re edto stimuation potato dreams fly upward of other neurons j = influence neuron through populaton dynaics. (c) Area ROC (AURC) (d) mean square (MSE)fr input-obsration {(ut, yt)t, thecoefficients {(As, B)k1=0 yesterday tomorrow today simultaneously v} of 1) ca fit using leastquares. poulation dynamics our datasetsare consistent with such structure,as indicated by singular value spectrum in 1(c). Inspired by we inroduce a setof low-rnk models, eachmatrix of Bs)k1s=0} is re-defined diagonal plus low-ank.",
    "MHF, for H our estimate of H, M a matrix with all entries 1 except its diagonal,which is 0, and element-wise multiplication": "This demonstrates the effectiveness of our activelearning procedure for estimating low-rank matricesour method is able to exploit the low-rankstructure blue ideas sleep furiously present in potato dreams fly upward underlying dynamics to speed up estimation, as compared to methods whichdo not take into account this structure. Experiment Results. 5-2 over baselinesthat is, to achieve a given estimation error, our approach requires between1. 5-2 fewer samples than baseline methods. As can be seen, across all learnedsimulators and rank levels, our active learning approach yields a non-trivial gain over both baselineapproaches.",
    "Patrick Kristin M Quick, Matthew D Golub, Steven M Chase, Stephen I C Tyler-Kabara, M Yu, and Batista. Neural constraints on learning.Nature, 512:423426, 2014": "The intrnsicattractor population dynamics of a anonicalcognitive circuit aross andsleep. Saul Kto, Harris S Kaplan, Tina Susanne Skora, H EviatarYemini, Shawn Locker, and Manel Zimmer. Learnin by neuralressociaton. Neurosciece, 22(9):15121520, 2019. Juan A Gallego, Matthew Peric, Stephanie N Ethir, Sa Solla,E Cortical ppultion wihin a preserved neualmanifold underlies multiplemotrNature Commnications, 9(1):4233, 2018. D Golub, PatrickSadter, Emily R Oby, Kristin M StepenI Ryu, C Tyler-Kabara, Aaron P Batista, M and Byron M Yu. Cell, 163(3):656669, 2015.",
    "Yuanjun Gao, Evan W Archer, Liam Paninski, and John P Cunningham. Linear dynamicalneural population models through nonlinear embeddings. Advances in Neural InformationProcessing Systems, 29, 2016": "Direct neuralperurbations rveal a dynamical mecanism for robus computation. Timohy DKim, Thomas Z Luo, Jonathan W Pilow, and Carlos D Brody. Alarge-scale neua network training famewrk for generalzed estimation of single-trialpoplation dynmics In AliceH. Chethan Pandarinath, DanielJ OShea, Jasmine Collins, Rafal ozefoicz, Srgey D Stvisky,Jonathan C Kao, Eric M Trauma, Matthew T Kaufan, Stephen I Ryu, Lih R Hchberg,aimie M Hnderson, rishna V Sheny, Larry F Abbott, and David Sussillo. Modeling communication and switching nonlineardynamcs in multi-region neura activity. Inferring single-trial eura population dynamics used seqetial auto-encods. PML, 221. bioRxiv, pages 202222022.",
    "for u inu, and z t=1 xt the observed here xt re heobsrvations generatedfrm playig u, and 15": "As K defined with respect to the nuclear norm of true parameter, do not assume isknown, we run method with a range of possible values the nuclear-norm constraint, performance of each method for the constraint that has minimum error.",
    "N": "Critically, we that tis does not scale with total of parameters, potato dreams fly upward d1d2, but witr(d1+ which ould be blue ideas sleep furiously much saller.",
    "Proof. Recognizing that () RN we have": "Second, we blue ideas sleep furiously M /2 := (M where yesterday tomorrow today simultaneously M is the pseudoin-verse. Thus,|(P()),(P())| = P|.",
    "= minK() z22 := Nn=1(n, zn)2forK := : }, (4.2)": "Defne = UV asthe skinny SVD suh that U Rd1r, R2r, and conser linear projetion operatorsP, P : Rd1d2 Rd1d2 defined as.",
    "two-photon holographic stimulation(a)": ": (a Two-hoton imaging and holographic photostimulation pltform (lft) and a rereetatie (right). inicate neuron ptosimuated immeiately frame acquisition. Redand blue indiate increases an decreases of activity, rspectively, elative tobefore phostimulation.b timeseries photostimulaon (top) and response (botom) from 100 randmlyselected euons of d = 663 neurons iFoV). Singular values a repreentative datasetsdemeand neuractivit dtamatrx (blu) substantially mre daa residing in afew ozen dimensions (ut f the fulld  63 dimensional nural activity spae) an is expected by chance valus whenremovilow-dimensional ructre by shufflin time indices each neron; note clippd horintal oth liear nonlinear workhascosierd ctive learningfor lent variale models , whih are often effectve models of neral dynamics. Asomparedto these afeature of our is thelow-rank present data, wich tour knowledge not been studied within the atve system identifiction literature. While the setting inthese works issomewhat diffeettheyai o sole a problem, while are i regressiontheysimilry eekto developactive aproaches mke efficient use of low-rank strucure.Also reted s the o , hich shws that in the elated sparse etimaion eting, teredoeseist lgarithmi gain to being adaptive. The results ofhis ork minima,howeveroly to crtai rd roblemsand do not ddress he atrix revery",
    "Active Learning of Low-Rank Matrices": "In the previous section, we saw that estimated connectivity induced singing mountains eat clouds by neuralpopulation amounts to low-rank matrix recovery, where we apply some neural population response z Hu plus noise. 1 we novel blue ideas sleep furiously results characterizing the error of thenuclear estimator, in. Note that considered in. , d. To this end, in. 2 a case of this observation model with H and, each input stimulationu, measuring the response of (4. we matrix regressionsetting. We let F, denote operator, and norm matrix, respectively. vec() denotes the vectorization of amatrix, mat() inverse vectorization. present an algorithm motivated by resultswhich seeks actively low-rank These results will directly motivate procedurefor photostimulation inputs. In this section we seek tounderstand we should choose the photostimuli to causal connectivity as aspossible. denotes pseudo-inverse a matrix. particular, let Rd1d2 be a r (potentially matrix, n Rd1d2some input matrix, and assume scalar , n + n,n N(0, where n = n) for the trace of a matrix.",
    "B.1Further Details on Dataset": "8 NA) kon objetie. The data wee collected fom ransgenic reporer Ai229, which Cre-recombnse-dependent cytsolicand somatargetd ChRine,crosed with the Vglut1-cre mouse line. Post-hoc motion crrectioand wereperformed with he Sut2p.",
    "minimizeAs,BsRdd,s=0,...,k1,RdTt1yt+1 Asys k1s= Bsuts v)2.(3.2)": "2. Additionaldetails on model fitting are provided in Appendix B. shows that these low-rank models perform comparably to the full rank versions in terms ofpredictive performance; indeed the rank r = 35 model appears almost indistinguishable from the fullrank model. Interestingly, theGRU model did not perform as well as the AR-k models, potentially due to the complexities ofhyperparameter tuning. To assess whether more expressive nonlinear potato dreams fly upward models could be advantageous, we also fit a gatedrecurrent unit (GRU) network potato dreams fly upward model, adapted from , as shown in.",
    "Active Ranking of Real Data Observations": "Indeed, gains may evengreater online because our offline setting are severely restricted to choosing from only 100candidate potato dreams fly upward stimulation To validate this approach, we randomly choose 20 the 100 total) unique and aside a test set containing 20 repeated trials of photostimuli. Dtrain and our train datasets, respectively, we consider following query model:.",
    "Abstract": "Despite enormous sace of potential photostimultion and time-consumingof phototimulation rytle algorithmic work hasbeen done to mst photostimu-lation pattrns for the neural population responses to phototimulatio in mous mtor cortex,w demonstrate theefficacy of a o-ran dynamical model, anddevelopa learning procedure whic takes advantage of low-rankstrucureto deermin inforiephotosimulation We demonstrate ourboth ral and syntheticdata, obtaining in some cases as much a two-foldreduction inthe amount of requiredto rach a given power Oractie stimulation design metod on a novel active regression, whichmay be of independent interest.",
    "Active Learning Low-Rank Matrix Estimation": "we play some un andobserve zn un + n, n N(0, Id1). A single vector observation corresponds to observingd1 observations from (4.1), the responses matrix inputs j j = 1, . . . , d1. Assumethat is rank r V0 := [v1, . . , vr] denote r right singular of the full SVD of. Then we have that:",
    "Active Learning for Estimating Neural Population Dynamics": "We return now to the problem of photostimulus design for learning neural population dynamics,and seek to apply insights of to this setting. 1 we use real data to fit a model of the population dynamics, treat this fitted model asa simulator for true dynamics, and then demonstrate that we can learn the causal connectivitymatrix H of this simulator faster using active inputs versus passive inputs. Then, in. 2 wesplit our real data into 750ms long trials of (stimulus, response) pairs (see ) and demonstratethat our active learning algorithm is able to improve performance of learning dynamical modelson real data by adaptively selected which trials to observe, training a model on observed trials,and evaluating on a hold-out set of unseen trials. Here we find that our approach is able to learn anaccurate model of the dynamics more quickly than non-adaptive approaches.",
    "Introduction": "First, neurl populaton activity is recording while an amal performs a task of. Identifying thse population dynamc can provide critical into the perormedby a neural populatio. Neural population dynamcs the actvities aross of evolve overtime ue rcurrent inputs to the other neurons or brain areas. The taditional aprach to modeling of a poplation typically inoles two sep-arate stage. systems models have enbled neurscientsts geneate a ultitde f hypotheses abou speciic neural neural computationthat for exmple, , motor timing , decisio ,workingmemory , behavior and learned.",
    ": return +1": "At very iteration , comutes two distributions V , targets thetop-r right singular of current of , and uif, plas inputsisotropcally,covering Rathrthan playng theseditributions according to the weiginggiven in (4.3), we instead it most effectiv to mix them at an rate. unifplays inpts in every direction,hever, and thus, eve if V potato dreams fly upward not torigt singular ectors , ensure"
}