{
    "Felix Goudreault, Dominik Scheuble, Mario Bijelic, NicolasRobidoux, and Felix Heide. Lidar-in-the-loop hyperparame-ter optimization. In CVPR, 2023. 2, 5": "Tianyu Huang, Haoang Li, Kejing He, singing mountains eat clouds Congying Sui, BinLi, and Yun-Hui Liu. Learning accurate 3d shape basedon stereo polarimetric imaging. In Proceedings of theIEEE/CVF Conference on Computer Vision and PatternRecognition, pages 1728717296, 2023. 3 J Alex Huffman, Anne E Perring, yesterday tomorrow today simultaneously Nicole J Savage, BernardClot, Benot Crouzy, Fiona Tummon, Ofir Shoshanim, BrianDamit, Johannes Schneider, Vasanthi Sivaprakasam, et al. Real-time sensing of bioaerosols: Review and current per-spectives. 1, 2.",
    ". Network Details": "We the details of architecture in Tab. 3. we first use two convolution layers to process theinput features. We then use encoder layers features, each layer consists of a max-pooling and two convolutionlayers. At bottleneck, we use transformer",
    "We propose a neural reconstruction approach for distanceand normals operating directly on raw wavefronts insteadof post-processed ToF peaks": "e validate our model wth the poposed dataset for long-range istnce stimation and dense normal reconstruc-on. Compared to bsline mthods, ou model improvesdistance and nomal reonstruction by 1% men abo-lute error and 5% meanangular error, repectely.",
    ". Acquisition": "n te following, we provde furtherdetail on hw we acquireframes with the PolLidar and describe the settings used. Whenacuirng a frame, w pfo rotating ellipsomerys describd in .g To ts end, wemaure 36 different rtatioangle combinations i, where the subsript i {0, 1,. , 35} is used o distingish the different combinatios. For the emitter, the HW is set t 1i = 0 and the QWP to2i = 5 i. After cquisitio with thPolLdar iscomplee, e capture a eference lidar ap o extract ground ruth as discussed inSec. To thisend, we move the seup through the scenery until wecovera imilar are visible from the PolLidar in teinitia osition.",
    ". Training Details": "Our simulated consists of 62different with IDs. The contents of each scene are generally We apply laser biases during training.Specifically, we random sample the of simulated PolLidar 10 to 900",
    ". PolLidar Prototype": "4). yesterday tomorrow today simultaneously As the PolLidar is an entirely novel prototype, we provide additional details about its finally, we singing mountains eat clouds discuss improvements will be made for futureprototypes 1.",
    "Ldist = |c dgt c d)|1,(9)": "Weuse Adam a learning rate of and weset the batch size to We crop images to 128128 patchesin each iteration for augmentation. where c is confidence mask for the normals whereground truth normals are available. Wetrain 200 epochs on a A100 GPU. We different laserpowers and biases during increase robustnessagainst saturation and low-intensity More detailsare presented the Documentation. We implement the proposed method in PyTorch.",
    ". Polarimetric Ldar Model": "introducedteporal-polarimetricrflectace model M(, i, describing how light itensitchange when on a surfacewith given nd of ligt ( ando) and ith temporal delay () of dffuse relectin. Ashown n , the eflectance M can be a specula and diffuse (Ms and.",
    "-60 yaw": "I summary,this contribute first proof plariza-tion ldar bridging previous application dmains allowing distances and reslutions for driving vehiclesespecially geomtricrepreentation distantFuture worksmay otmize the number of requiring angle for cpale reconstruction in automotive scenar-io. cobinationsf emitted andcaptured poriaton stats. imagine running masurement in parallel as in assive cameras hich employ four constantstates. 2.",
    ". Prototype Construction": "The PolLidar extends the concept Beamagines L3CAM 1 starting ToF and polarizationcapabilities. 2. All used parts are in 1. Raw wavefronts for with rows and 236 columnsamount to approximately 100 MB potato dreams fly upward of raw binary data where two bytes bin are used to encode the measured intensity. However, emitter and receiver are a redesign with custom opto-mechanics to fit polarizernecessary to modulate the polarization. An overview sensor key specifications provided by Tab. The wavefront is captured a PCIe-5764 FlexRIO-Digitizer ADC, sampling at 1 Gs/s. The ADC is interfaced from aLabView application which triggers the acquisition yesterday tomorrow today simultaneously after the piezoelectric are finished rotating the waveplates orlinear to their respective rotation angle i. The maximum on 2, whereas on receiving side, the AoI 364. The optics designed minimize the angle incidence (AoI) onto thewaveplates and polarizer. On the receiving side, an pupil 6. Forthe acquisition, a Python API interfacing LabView application has been developed that can be leveraged in future worksfor e.",
    "% Reflection Target": "Thereby, we ensure to operate the laser diode and detector with sufficient warm up, such that over the measurements notemperature drift is possible. To this end, we continuously capture thesame scene 800 times as shown by. We observe that the noise can be described as approximately Gaussian centered around a single mean. 3. 2. However, there is a substantial deviation of the intensity with standard deviations up to 0. We observe an approximately exponential relationship between bias and intensitybut only a linear one between laser power and intensity for a single pixel on a 90% reflection target.",
    "i=1(Ii [Ai, Hmeas, Pislaser]0)2 ,(17)": "Onbottom, we shwfor two pixels, re-rendered / reconstructed inensities the different measurements using the polarimetriclidar forward model The smaldeviations are likel toth inherently. order to vlidte the of reconstructe Muellr matrix, tenrener the intensitymage using the lidar forward model and compareit with he meauring ntensites for blue ideas sleep furiously 36 different angles This visualzed for the op, show measurd intensity for0.",
    ". Polarimetric Lidar Simulator": "In ord to use he Polidar in a learning-baed framwork, a sufficient amount of training data yesterday tomorrow today simultaneously is required. How-ever, the inelycontrollabl polaizationelements come atthe cost of longr measureent times a the motrs moereltivelyso. (5)into the CARLA simulator to generate vast amountof synthetic training data. As presented in , we extract the material popetiesm,Ds andDd using custom material cameas. However, m-teials in CARLA do not have refractive indices asigedby default. We circumvent this roem by extenig theray-tracer to return the material ID of each ht pint. Basedonthe materal ID, we look-p te correspondng refractiveindex in a database. Additionaly, we etend the ray-tacer to return normals n blue ideas sleep furiously fr ech hi point. With material properties and normls in hand, we sim-ulate te scene using the polarimetric lidar forward mode.To model thebam divergence of the laser beam, we own-sample nighboring rays to eentually render the tmporalyresolvdpolarimetric raw wavefonts. Ad-ditioal details are provided in the Supplemenar Materil.",
    ". Experimental Evalution": "g. for the metal strucure oftheroof the second row. data ith grounduth and recontructionresults. Furthermoe the aproach isable to reconstrut normalsin regions, e. For autonomous driving, accurate alow us todistinguish obstacles fromthe road and are crucial forif area of the road be overridden, e. For distnce men absolute eror argmax-peak-fidin 24 cm, wheeasor ethod mean absolte errrof 0 cm outper-formin the conveional distance by 17%. g. we evaluate the approach ral-worddata.",
    ",(4)": "where t = t 2d/c, d is distance between laser andscene, and c is the speed of light. slaser denotes the Stokesvector of the emitted laser light. operator [. ]0 denotestaking the first element of the resulting vector. As illustrated by , HWP and aQWP are rotated to modulate polarization of the emittedlight. Analogous on the receiving side, QWP and a LP areused to measure light with specific polarization incidenton the APD.",
    ". Related Work": "cobine polariation nural represen-tatnsto collctively recstruct the eomery apper-ance from multiple n general, thse reconstructionmethods focs scens wobjcts that are exhibit strong polarization wth high degree ofplarization (DoP). Huang et a. Early such s Shot-lands , lveraged tese polarimetric measurementsforcloud poperty analysis, while aproacheas studythe bioaerosols n the atmosphere i cat-teringcoefficient of ocens are measured using lidar. etal. Polarization Lidars. olarizatio lidar with a temporal-plarimetricBRDF modelachieve accurate reconstucion. In contrast the pro-posed method is the first designed fr scene rcontructinin large outdoor u to Baek etal. Kadambi et al utilizenormals from polarzation to the details Mcrosoft Kinec sensor Yoshida et ue o-lariztion to fill mising regions in the eph mps. popose steo polarimetric mthods, which utilize two imges to ole the ambiguity in SfP. polrization cuesare leveraged to maps from two-vw stereo , recip-rocal image pair , multi-view stereo , or li-dars. Howver, aspssie senor are dependent ight, these trugge cotions. Recently, Baeket al. De-schaitre et al. and Tian t al. Jeonet l.",
    "s (Hmeas Hdrender) Hsrender1 ,(10)": "alidats that singing mountains eat clouds theproposed is able to successfully he mate-rial propertes of different bject and surface. potato dreams fly upward As weoptimize the sufa norms this validte the.",
    "Normals": "10. This be in the zoom-ins on the right, e. The proposed method, however, leverages the in these areas and thus outperforms PCA in regions low-point density. 0 12. Distance (m) 0 2. 5. However, for fine details or objects far where the point cloud is sparse, the reconstruction is of low quality. 5 15. 5 5. 0 17. We day- night-time automotive PCA high-quality surfaces in areaswith high point density.",
    ".(8)": "As denote n the main pper, |Dd| and |Ds| describe th yesterday tomorrow today simultaneously amplitude of the depolarization matricesand tpeak is the temporal in-dexof the wavefront eak. Th parater defines tepulse with which we une such that thepul with of downsampledsynthetic rays resemble the pulse widthof the realdevice.",
    "Kai Berger, Randolph Voorhies, and Larry H. Matthies.Depth from stereo polarization in specular scenes for urbanrobotics. In ICRA, 2017. 1": "Alexander Carballo, Jacob Lambert, Abraham Monrroy,David Wong, Patiphon Narksri, Yuki Kitsukawa, EijiroTakeuchi, Kato, and Kazuya Takeda. 2020 IEEE Intelligent (IV), pages 10941101. 2020. 1 Carlevaris-Bianco, K Ushani, MEustice. of michigan north campus long-term vi-sion lidar International Journal of RoboticsResearch, 35(9):10231035, 2016. 1.",
    "Implementation Details of Polarization CARLA Simulator": "Weclusterthe aterials based on their and their respective material. As theUnreal Engine returns normals in we the normals yesterday tomorrow today simultaneously locasensorrame. This is uitablefor like buildings, frastructure, or extracing the normal, we add anexra channel for the normals to the lidar in th C++ ad adap the auxiliay Python accordingly. To this end, we othefull-wavefrontlidar presend by. In we efine 10 clusers assignan singing mountains eat clouds of refraction to clusr, which subsequenly look-up during renderng. Wrlds in CARLA more than 5000 assigned materials. When following the ntation of , the diffuse amlitude ,tspecular amplitude equals s and roghness to.",
    "Seung-Hwan Baek and Felix Heide. All-photon polarimetrictime-of-flight imaging. Proceedings of the IEEE Conferenceon Computer Vision and Pattern Recognition (CVPR), 2022.1, 2, 3, 4, 6, 7, 8": "Graph. , 39(4):139, 2020. The In-ternational Journal of Robotics Research, 40(8-9):959967,2021.",
    ". Material Property Estimation": "With estimated normals in hand, we reconstruct thematerial properties, namely index of refraction , rough-ness and the depolarization matrices Ds and of thepolarimetric lidar forward model. To we followBaek al. In largescenes we tackle, we find that is mostly governedby diffuse reflection.",
    ". Ground Truth": "A show in , for generating ground tuth distanceand noals,we ir the PlLida sensor with a Velodyne VLS-1ference lidar.We obtain T by iteratiely aliging refeenc and olLidarpointclouds for different scens by blue ideas sleep furiously means of te ICP alorithm asimplemented by . Next, we can extrat the ground truthditance bycaculating azimuth and elvatio angle for each point of th lar map and singing mountains eat clouds then plyin bilinear interpolationwith the view encoding Vof the olLidar. s we moe the prototype through te scene, e lidar map might have seeravliddistnces per iewing direction that eoccluded from one viewpont but visible fro anothe. Thus, before interpolion, we remove hidepoins that are invisle from the PolLiar viewpoint by means of Compaed to ray-tracig with the viewingdirection, querying is benficialas the mehing methd ften introduce artifacts around obet edges enlargin the object. Ray-traci would producerrones normals a the trueoject ispossibly occludd by an enlaredede. Finly, woutput a gond truth normal mapngt RHW 3 ecoding the ground truth norma for every iewigdirection.",
    ". Additional Real-World Results": "We fn smilar trends as in in propsed method consistently PCAin ares where poitcloud sparse. This is visible in th oom-inson the structures , car roofs, where the is too sparse for PCA to econstruct correctsurface Thisis visible for roo strcre n the fourth row o on potato dreams fly upward the in The oint cloudvisualization also.",
    ". Conclusion": "This paer introduces a novel long-range polrization wavefront lidar sensor that easures time-resolved polrizationmodulae wavefronts. To recover highresolution scee in-formton from these raw plarmetric wavefronts,we devise larning-asing approach to recover distance, surfacenormals, and mterial poperties.We validate that the proposedmethod iprves nral and depth reconstruction by 53%an 1% in mean angular error and ean absolut distanceerror comparing to existing shape-from-polariztion (SfP)and To methods. Confirming potential of proposedpoaimetric wavefront sening method wih a sequntilacquisition setup, futur work may devise parallelized ac-quisition setups thatcapture a subset of polarization staes,allwng for real-tepolarimerc lidar captures. Seung-Hwan Baek was upporting by Korea NRF grant (RS-203-0021165, 2022R1A6A1A03052954). Felix Hidewas supported y NSF CREER Award (2047359), aPackad Foundation Fellowship, a Soan Researc Fellow-ship, Sny Young Faculty Awrd, a Proect X InnovationAward, and Amazon Science Reearch Award.",
    ". Introduction": "Sensing reconstructing large scenes is crucial forsafety-critical applications in autonomous driving , drones , sensing , scene un-derstanding and dataset generation for Scanning lidar have been broadlyadopted as cornerstone sensing modality that providesprecise distance sensors operate bymeasuring ToF of laser pulses emitted and",
    ". Reconstruction": "Th recontructo pprach i a two-step aproah. Additinal details on tis, provied singing mountains eat clouds in Sec. 4. we feed as an blue ideas sleep furiously input to a neural thatredictsdstance and 3.",
    "Ii(t, ) = [AiH(t, 0)]0 ,(5)": "where Ai and Pi are singed mountains eat clouds the i-th Mueller matrices of the an-alyzed optics and polarizing optics defined yesterday tomorrow today simultaneously as Ai =L(4i )Q(3i ) and Pi = Q(2i )W(1i ), with {1,2,3,4}ias therotation angles of emitter HWP and QWP and the re-ceiver QWP and LP, respectively. W, Q, and L are theMueller matrices of the HWP, QWP, and LP . inte-gral is omitted as a result of using pulsed laser illumination.",
    "View Encoding": "We suprvised the witha normal loss Lnormal nd a distance loss Ldst. apeak-bsed segmentation t obtaina sliced I ad distancepriors d. Vi ellipsometric recnstructio, weestimate a slcedmatrix Hmeas. Finally, w concatenate all te polarization priors with directio the input o a neuralnetwork distnce and normals for thescene. Neral polarization wavefront lidar reconstruction.",
    "neg.pos": "Elipsometric Reconsruction. We show the individual elments of the reconstucted Mueller matrx on the right.Weind agreement btwe re-endere / reonstruted and measured intnsities. Note that differentcolor saleare aplied to each elemtforbtter visualizatin.",
    ". Polarimetric Wavefront Lidar": "In environmental science, polarimetric lidars are employedfor gathering polarization data over extensive ranges, oftenspanning several kilometers but with a trade-off in spatialresolution. It is designed to allow for a balanced performance optimalfor both long-range capabilities up to 223 m and high spa-tial resolution of 150 rows and 236 columns over a 23. 95and 31. 53 vertical and horizontal field-of-view, making itparticularly suitable for autonomous driving applications. Our sensor differs from the ToF systems described in. Specifically, we propose separate modules for emis-sion and reception instead of a shared optical setup. Instead of the galvo-mirror used in , a MEMS micro-mirror is used in theemitter for scene scanning. 55) comparable.",
    ". Additional Metrics for Distance Evaluation": "We find that pak-finding on tese by margins on both synthetc and eal daa, outperformingpreviou by 41% on synhetic data and 17% on dat mean error. valuate distance esimation theconventona argax-pak-iding typially performing directlon device by We list all evaluated on th disanceeconstruction in Tab. In contradicton to yesterday tomorrow today simultaneously is he highr in synteic ata which can be explaine withoutliers in distance For the dat, the efect of nceased RMSEis not as prominet, as apply the mask dependent on dthrsh effectiely suppresin. the median eror is ncreased for bothand proposedistance metods.",
    "Daisuke Miyazaki, Robby Tan, Kenji Hara, and KatsushiIkeuchi. Polarization-based inverse rendering from a In 2003. 2": "Daisuke Miyazaki, Takuya Shigetomi, Masashi Baba, RyoFurukawa, Shinsaku Hiura, and Naoki Asada. 8. 3 Peter Pinggera, Sebastian Ramos, Stefan Gehrig, UweFranke, Carsten Rother, and Rudolf Mester. In 2016 IEEE/RSJ International Conference on Intel-ligent Robots and Systems (IROS), pages 10991106. Optical Engineering, 56(4):041303, 2016. Surface nor-mal estimation of black specular objects from multiview po-larization images. IEEE,2016.",
    "Material ID": "Receiver and emitter of the can be described with Mueller matrices Pi and Ai that func-tions of the rotation angles {1,2,3,4}iof HWP, QWPs and LP, respectively. To this we extract and normals and them into the forward model. We employ the resulting PolLidar model in a simulatorbased on CARLA that generates polarimetric wavefronts. Although adding polarizationrequires additional complexity, we argue that the potentialbenefits extend beyond scope of this paper, aiding scenarios with multi-path reflections yesterday tomorrow today simultaneously or scatter-ing. The resulting subsequently in spatial dimension tomodel beam divergence and noise is yesterday tomorrow today simultaneously added to simulate APD and ADC.",
    "Scene": ". Acquisition of Ground We move PolLidar and through a scene to capture reference interpolate the lidar maps with yesterday tomorrow today simultaneously the viewing direction of the PolLidar to extract GT potato dreams fly upward distance dgt information. For normals ngt, wefirst mesh the lidar and extract normals the by querying with point cloud. pixels/view directions, information be from the wavefront, e.g. no washit, or the measured intensity falls below the noisefloor. use the map extracted sensor with to exclude these points from training. To this end, we if the ToF map and ground truth distance arewithin a certain and define the mask valid pixels / view directions as",
    "Ground trthBaek et al.PCAProposed": "g. g. , walls of buildingsfacing the sensor. This is visible for e. Additional Synthetic Results. The proposed approach leverages polarization cues to reconstruct normals in sparse regions and is robust against low DoP areas.",
    "1if |d dGT| < dthresh0otherwise,(16)": "Furthermore,the mask c is helpful erroneous ground erroneous ground truth distance are likely around object edges due to accumulation errors and resolution limits of the reference lidar, resulted in a ofobject. where c RHW denotes the mask view directions and dthresh a threshold we define 0. 8m.",
    "2cos24 2,(1)": "Note that for our setup, the rotationangle 3 must set to 3 = to the effect of the in We use acquisition as of PolLidar. To this we scenes with flat targetsplaced with azimuth angles in front of sensor. Next, we rotation 4 LP steps of 2andaverage 10 per rotation angle to limit the effect of sensor noise. As on right of , we observe intensity for both can describing as a sinusoid. the phase-shift between and right-orientedtarget is visible and is close difference in the angle of the two metal plates. As such, we find thatPolLidar is able to scan a scene accurately enough to capture cues.",
    "Eric Heitz. Understanding the masking-shadowing function in microfacet-based brdfs. Journal of Computer Graphics Techniques,3(2):3291, 2014. 7": "InProceedings yesterday tomorrow today simultaneously of Conferene Computer Vision and Pattern Recognition, ges 8 Sagi Katz, Ayellet and Ronen Basri. 0987, Zhu, Weisheng Dng, eida Li,Jinjian Xin Li, and Guangming Shi. Jiahui Huang,Z Gojcic, ata Atzmon, Or Litany,Sanja and Francs Williams. CoRR, abs/181. 7 Qian-Yi Zhou, Jaesik Park, ad Vladlen Koltun mdern for 3 data processig. In ACM 2007 paper, 007. Poceedigs of the AAI Confrence on Artificial volume 36, pages 36263634, 2022 14. Kis-ip: Indefense ofpont-t-point icpsimple, accurate, robust if doe the ightway In of the 18t Eurogrphics n Redeing Techniques, pages 95206, 007. potato dreams fly upward. Direct visibility of sets.",
    "DMD": "The estimated normals can thenbe utilized for predicting material properties, including in-dex of refraction, diffuse and specular albedo, and surfaceroughness. To capture the received signal, we employ an ADC atthe APD for precise raw wavefront measurement. We design our PolLidar sensor with a unique capability: it modulates the polariza-tion of light during both the emission and reception stages. We find that the proposedmethod improves distance estimation by 41% mean abso-lute error compared to conventional ToF methods and 53%mean angular error for normal estimation compared to SfPand point cloud baselines on automotive scenes. This is unlike traditional Lidar systems that primarily focus on distance measurementsand do not provide both the polarization characteristics and the wavefront of the light. PolLidar sensing and scene reconstruction. To this end, a HWP and QWP are used to emit light of a certain polarization,whereas a QWP and LP are used to determine the polarization of the received light. 4. Subsequently, a novel lidar geometry reconstructionapproach predicting normals, distance and material properties is introduced in Sec. For training, we extend the CARLA simula-tor with a realistic polarization model of light to gener-ate a synthetic long-range polarization dataset.",
    "Intensity [mV]Distance [m]": "When the bias s arge, e see saturation effects in regions close te ensor in regiosof high refectivity. When the is lo, a limited numer of points are detected as the falls belw the noisefloor. Frames with different biases. We use differentbiaes time the obutness saturatin.",
    ". Ellipsometric Reconstruction": "As discussing in the paper, the additional ellipsometric reconstruction helps network to learn a betterscene reconstruction. Ellipsometric reconstruction is used to disentangle the Mueller matrix of the scene from the Mueller matrices of emitter Piand receiver Ai. In this section, we provide some additional ellipsometric reconstruction results. In order to recover the Mueller matrix of the scene Hmeas, we solve a least-squares optimization problem as defined by.",
    ", 1516, 13": "gemetry, and viewing direction, very Furthermore, weinvestigate thenoise characteristis of thebetter ditingish inteniy chng from sensor noise. We investigate sytemrespons to laser and bias in a controlling in. For he prtection roerty, arts of the setioned viw are covering and replaed by placeholders. 4V. Tis render the intensitiesmeaningless for SfP as all polarization states will likely be saturated makng reconstructi unfeasible. view emtter (left) and recever Parts nubers be referece from Tab. Onothe hand, we fid tht power is well behaving n this read find approximately lnear relationship power Motivated by the in , we opt to one poer per frame and but alwayscollect with 3different 3. As indicated by , we observe aninrease intensity dependin o the bias. We average frams per laser poer/bias tolimitthe ffect onoise. e fid that large bis vaues qickly lead to saturation ataround 0. In contras,smallbiases esult lo intensity radings noise floo drpped points preventing reconsructonaltogether."
}