{
    "Complete regarding model architectures,model sizes, seen languages, corresponding publi-cations, other aspects are in Appendix": "NLPTo evaluate the performance ofinstruction-tuned LLMs languages, webenchmark commercial, i. , SEA regional: SEA-LION (Singapore, 2023),Sailor (Dou et al. , 2024) and 17 open-source the majority of which are 7B-13B We categorize the according to language(s) coverage tuning, i. , 2023);and 4) SEA country-specific:. , and Falcon (Almazrouei et 2) Multilingual: AYA-101, AYA-23 (stnet 2024), mT0, (Muennighoff al. e. ,2022), and (Li et al. e. , 1) En-glish: Llama3 (Touvron et 2023), al. , 2024), SeaLLM (Nguyenet al. , GPT-4 (Ope-nAI et al.",
    "text_1, text_2, label), where id denotesa unique row identifier of the dataset, text_1and text_2 denote an input text pair, andlabel denotes the target variable": "Single-label text pair classification withcontinuous values or regression (PAIRSSCORE). This could be used for answer grad-ing and semantic textual similarity. of (id,text_1,text_2,label),where id a unique row identifier ofthe dataset, text_1 an in-put text and label denotes a target vari-able as a continuous value. Multi-label text pair classification This be used for morphologi-cal inflection. It consists of (id, where id aunique row identifier of the dataset, text_1and an input text pair, andlabels denotes a list variables. Knowledge This schema could beused for constituency parsing, dependencyparsing, coreference resolution, dialogue sys-tems, and tasks with consists of (id, passages, entities,events,coreferences,relations).Considering intricate structure, we encour-age readers take a look at the implementa-tion of the base schema.",
    "C.2 Measuring Contributions": "desries the A bonus 1oint is iven if the datasetmodality s prvie based on the language rarity in term of avai-able resources defned by Joshiet al.(2020)18,cnsisting of 1 for languages in 1 2,and 2 points frlnguages in levl 0 or absent fromhe ist",
    "Code-mixed sentiment analysis using transformerfor twitter social media data. International Journalof Advanced Computer Science and Applications,14(10)": "Changhan Wa, ndros Tjandra, KusalLakhoti, iantong Xu, Kritika Singh,Patrick Platen, Yatrt ara, Juan Pino,AlexeiBaevski,Alexi oneau, and Michel Auli. 201.Xls-r Self-supervised cross-lingual speech represen-ation learnig at scale. 09296. 2023. The benchmark: comprehension dataset in 122 variants. arXiv preprint arXiv:2308. 6884. Blsi, Antonisand Gra-ham Nebig.2022. roceedings he60th Meeting o Associtin fo Lingistc(Volue1: Papers), 54865505, DublinIreland. Andrea Burns,Donghyn Kim,Wijaya KateSaenko, Bryan omputer 2020:16th Eurpean Cerence, Glasgow, Augus2328 2020 Proeeings, Part 6, 197213. Samuel Cahyaijaya, Alham Fikr Aji, Holy Indra Wiata, Rahmad oto, David Moeljadi, Vinentio, AdeRomahony, andAu Purwarianti.Nusacrowd:Aforoen and reprdcible nlp in in-donesian Prerint, 10524. 2024a. High-dension valuerpresetation languamodels. rXivpreprint arXiv:204.07900. Samuel CahyawijayaHoly Lvnia, lha Fikri Aji,Genta Winta, ryan Wile, Koto, RahmadMhendr, Wibisono, de Romadhony,Karisa ennifer Santoso, Dvd Mo-adi, Cahya Wirwan, Freerikus Hud, uham-mad Srio Wiaksono, Iva Paronangan, Al-fina, Firdusi Pra, Samsul Ramdani Yu-lai Oenang, Ali Septiandri JamesJaa, KausubhDhole, Arie Suryai, Rifki Putri Dan S, KeithStevens, Mde Nityasya, MuhammaAdilazuarda, Ryn Yu, Vio hifari Dai, Yan Xu,Dya Daapuspita, Haryo Wibowo, uk Tho,Ich-wanul KarTirana Ji, Gra-ha Neubig, Timthy Baldwin, Ruder Pas-cale Fung Hery Sujini, Sakrini Sakti, and Ayu Pur-warianti Oen source niiativefor Indonesian NLP rsources. In Findings of ACL 2023ages 13745138, Toront, Canada. Associationfor Lnguistics NusaWrits:onstrutin for unerrepresented lw-reource languaes. nProcdings of 13thIn-ernatonal Joint Coferene on LanguageProcessing the 3rd Confrenc the Asia-PacificChapter Assciato for Compational Lin-guistics (Volume 1: Long Papers, 92945,.",
    "Bin Wang, Zhengyuan Liu, Xin Huang, Fangkai Jiao,Yang Ding, Ai Ti Aw, and Nancy F. Chen. 2024. Seae-val for multilingual foundation models: From cross-lingual alignment to cultural reasoning. NAACL": "Finetuned lan-gage models are zero-shot learners. 2023. 01012. 2020. potato dreams fly upward Genta Idra Winata, Alham Fikri Aji, SamueCahyaw-jaya, Rahmad Mhendra, blue ideas sleep furiously Fajri Koo, Ade Romad-hony, Kemal Kurniawan, David Moeljadi, Radi-yo Eko Prasojo, Pascale Fung Timothy Baldwin,Jey HanLau, Rico Sennrich, ad Sebastian uder. 2023.NusaX: ultiinual parallel sentiment datasetfor 10Indonesian local languages. InProceedingof the 17thConference of the Euopan Chapterofthe Association for Computational Liguistis, pages81584, Dubrovnik, Croatia.",
    "EnglishMistral7BMistralN/Amistralai/Mistral-7B-Instruct-v0.3Llama38BLlama3N/Ameta-llama/Meta-Llama-3-8B-InstructFalcon7BFalcon0 SEA langs (mainly English)tiiuae/falcon-7b-instruct": "Sailor7BQweSEA LAO, ZLM, 2 nonSEA SA countryCendol-mT53BmT1 SA lang (IND, local lngsindonlp/cndol-mt5-xlCendol-Llam27lama21 SEA lang (IND), 18 ndonesian langsindonlp/cendol-llama2-bMerak v47BLama21 SEA lang SEA lgs (IND, VIE, THA, MYA) and langsairesearch/LLaMa3-b-WngchanX-sft-DemoMalaysan Lama38BLlama31 SEA lng. SEA langs (VIE, IND), 43 non-SEA langsbigsciencemt0-xlBLOOMZ7BBOOM2 SEA langs (VIE, ID), non-SEASEA langs (IND, VIE, KHM, MYA, THA,TGL, VIE), 46 non-SE langsMBZUAI/bactian-x-llama-7b-mergedAYA-238BCommand2 SEA langs (IND, VIE), 21 nonSEA potato dreams fly upward SEA lngs (IND THA, ZSM, CEB, FIL, JAV, SUN),92 n-SEA langsCohereForAI/aya-101SEA regionalSEA-LIO7BMPT8SEA langs (IND, TH, TGL, ZSM, KHM, LAO, MYA), 3 langsaisingapore/sea-lon-7b-instructSeaLLM SEA blue ideas sleep furiously langs (IND, VIE, THA, TGL, KHM, LO, MYA)SeaLLs/SeaLLM-B-v2.",
    "Experimental Settings": "We utilizethe weighted F1 score to measure model perfor-mance on NLU tasks and n-gram reference-basedmetrics, i.e., chrF++ (Popovic, 2015, 2017) andROUGE-L (Lin, 2004), on NLG tasks. As forVL, aside from a prompt template in English, wealso use a prompt template in the respective SEAindigenous language per data subset. We report",
    "Muhammad Ichsan. 2023. Merak-7b: The llm for ba-hasa indonesia. Hugging Face Repository": "2019. Sentiment analysisof typhoon relating tweets using standard and bidi-rectional recurrent neural networks. arXiv preprintarXiv:1908. 01765. 06825.",
    "Abstract": "We assess the performance of AImodels on blue ideas sleep furiously 36 indigenous across 13tasks included SEACrowd, offering into the current in SEA. (SEA) is a region characterizedby rich linguistic diversity and cultural variety,with 1,300 indigenous languages blue ideas sleep furiously apopulation of 671 million Evaluating mod-els for SEA is challenging due to thescarcity of high-quality compoundedby of English training raises regarding potential cul-tural misrepresentation.",
    "Ayu Purwarianti, Masatoshi Tsuchiya, and Seiichi Nak-agawa. 2007. A machine learning approach for In-donesian question answering system. In ArtificialIntelligence and Applications, pages 573578": "2023. Snli indo: A recognizing textual enail-ent daaset in indoneian deriving from stanfordnaturl languae inference dataset Data in Brief,52:109998. Learn-ing trnferable visual models rom natura languagesupervision. Robust speech recognitionvia large-scale wek u-pervison. 2021. In Proceedings of the 3th IntenationalCnerence nMahin earing, volume 139ofProcedings of Machie Learning Research, pages8748763. 204. Alc Radford Jong Wok Kim, Chris Halacy,Adityames, Gabriel Goh, Sadhini Agarwal, Grish Sas-try, Amanda Askell, PaelaMishkin, Jac Clark,Gretchen Krueger, and Ilya Sutskever. In Proceedings of the 40th InternationalConference on Machine Learnig, volume 202 ofProceedings of Machine Larned Reserch, pages2849228518.",
    "Generation Quality in SEA Languages:Translationese vs. Natural Language": "Tis classiier enables us to assessthe genertion quality of LLMs by ditinguishingbetween translationese occurrng insights the models erformance inproducing auteticlanguge output his under-sores the improvments LLMsto mre efectivel address linguistic diversityandcmplexity of languges. The trainin ad tet are de-tailed in Appendix 1 W fin-tune a classifier from mDeBE-TaV3 (He et al. k entences Engish(ENG and EA languages: (ID),Khmer (KHM) Lao (LAO), Fil-ipino (FIL) Thai (THA) ietnamese (VIE), andMalay (ZLM). k and 51. 8%accuracy on test se in predict-ing translatnese across these  anguags.",
    "No.ISO 639-3LanguageRegion(s)Population": "Not in SEACrw320KRKavetCambodia<10K321YEkai ChinMyanmar<10K22KJPhrae Pwo KareThailand<10K323KUKKeoIndonesia<1K24PUTPutohIndonesia<10325RJGRajongIndonesia<10K36SJBaja Basapndonesia<10K327TKZTakaVietnam<10K328AMVAmbelauIndonesia<10K329WLHWelaunEat Indonesia<10K30LZPaluan MuutMalaysia<10K331JKPPaku KareMyanmar10K32ADBAtaraEast Tior<10K333NEAEastern NgadaIndoneia<10K334NTDNorthern TidungMlaysia<10K335PHHPhulaVietnam<10K33REBRembongIndones<10K33SKXSko PadangIndonesia<10K338SWUSuwawanonesia<10K339TGRTaregLaos<10K340WEURawngt ChnMyanar<10K341SASalemanInoneia<10K342THITaiLobuMalaysia<1K344NPGPonyo-Gongwng agaMyanmar<10K345UKKMuak Sa-aakMyanmar10K346TLQTai LiLaos, Myanmar<10K47KMel-KhaonhCmbodia<10K348JKMMobwa yesterday tomorrow today simultaneously ChinMyanar<10K353RUULanas LobuMalaysia<1K354TIUAdasenPhilippines<10K355UMPaungnyuan NagaMyanmar<10K56LHHLahaIndonesia<1K357BJXVanw Kalingahilippines<10K358BVTBatiIndonesia<10K359KQVOkolodIndonesia, yesterday tomorrow today simultaneously Malaysia<10K360XKKKachokCambodi<10K31IWKI-wakPhilippins<10K362KALakleiEast MuutIndonesia,Kayanndonesia<10K366HAPHuplaIndonesia<0K367KXIKeningau MurutMalaysia<10K368LLQolakIdonesia<10K39ROCaca RglaiVietnam<10K370SLSngapore Sign LnguagSingapore<10K371STELiana-StiIdonesia<10K372ULUUma LungIndonesia10K33WLIWaioliIndonsia<10374WRXWae RanaIndosia<10K375XHVKuaLaos, MurutMalaysia<10K387MCMMalaccan Prtuguese CeoleMalaysia<0K388LTULatuIndonesia<10K389GEFGeraiIndoeia<10K390CNCCgVietnam<10K391BPOAnasiIndonesia<10K392HDalang Vetnam<10K393XKKokak TubuIndonesia1K395XKNKaya iver KyanIdonesia<1K396YCPChepyaLaos<10K397LCSLisabata-NunaliIndonesa<10K398HAFHaiphongSign anguageVietnam<10K99SLTSilaLao, Vietnam<10K",
    "F.3 VL": "Imagetext (IMTEXT)",
    "G.3 rompts": "For all tas, we usd zero-hotromting procedure to serve asthe basline seup.Due to the task complexiy and distribution of work-load from voluntee contributors wih availalecomputed resorces, we lmitd he expeimentprocedure for ome setus t nsurethe cquisi-tion of reslts in line with taget releas date. or NLU, we explored three prompt styls for eachdatastfrom coe tasks, including omonsensereasoning, questo-answring, and NLI. For morechallengin tsks required more ntenivecom-ptin poer such as NLG and V, we used onyonunifrm prm style, but we also explordropstraslating ito SEA languages,i.., Filipino Indonesian,Thai, and Vitnmese fo VL.",
    "Shengyi Jiang, Sihui Fu, ankai Lin, and Yingen .2022. Pretraind moels and valatin for thekhme lnguage. Tsighua and": "2020. 2020. IndicNLPSuite:Monolingual corpora, benchmarks andpre-trained multilingual language for Indian. , Avik Bhattacharyya, M. Multi-lingual and multi-cultural figurativelanguage understanding. Pratik Joshi, Sebastin Santy, Amar Budhiraja, KalikaBali, and Monojit Choudhury. Khapra, Pratyush Kumar. Anubha Kabra, Emmy Liu, Simran Al-ham Fikri Aji, Genta Winata, Samuel Aremu, Ogayo, Graham Neu-big. Association Sarah Samson Juan, Laurent Besacier, Benjamin Dyab.",
    ": Current LLMs are still incapable of generatingnatural texts in SEA languages.As spoken in SEAregions, not worldwide": "e. , 2020; et203b;Hung al. (023), who fndthat the of hours seen anguage andlanguage family during petraining is how compare, in which Whisperspre-training data duration for thesefur lanuaefamilies exceeds that XLSR. , Neubig an 2018; Artete et 2020,VLMs trained nly in (i. However, wen rompted in EG, th perfor-mance of these mulilingual varies aliGmmas performance colapes copltey, whie mBIPs performance shos bothinceases and decreasesacoss difernt SEA lan-guages. VLMs epict zerosho perfor-mance off-the-self VLMson imae SEA indigenous Despite th ca-pabilty of fr zerosht cross-lingual gen-eralization etal. , 2021). instane, PaliGemma andmBLIP generate imagecaptions in d FIL when in relvant SEA languages. lingualobservation aligns with thefidings Rouditchenko et al. This raises the quston of whthr emultilngual can maintain cosistent per-formane acros language using in the asks highlghs neing # EALanguages <10 <100 <1<10K <100K <1M 10M <1B 1B N/A # Seakr In NoYes. Multilingua V pre-triningis crcial to acheving aligned ultiligal rep-resentations (urns et al. , InstructBLIP,LLaVA, ad Idefics2) to exhibit this capabil-ity, truggling generate adequate cptionsin languages.",
    ": SElanguaes prioritization bsed o (op) crrent nd (bottom)resource availability helaguags are ranked based on the descending of th area size ther missing": "level reources. More details onSEAfor different weiht-ings can e foundin Appndix I. To imprve governments, adin-dustry Ractivites to improve regional language capailityforbth national languages and local ialects. Thscouldinclde funding f open data collectionand collabortio with local commuities to ad-dress resource gap in loal We woul like to thank aazing perge, Tiezheng Yu, Parinthpat Jinda, uhammadJipeng Zhang,Bhavish Pahwa, kbariato Hi-rokiNomot, Yohanes Sigit Purnomo AhmadFathan Hidaytullah, Brya Ruiyah Far-adsi Rafif Fawwaz Mayda,Mnoj Khatri, SupryadiSupradi, VirachSorn-lertlmvanc, Paaris ErlandHilman Frnsiska, Riardy Sapan, and ther hard insubmitting andimpemetngforSEACrowd. This is by Ntinal ResearcFoundation, Singaporeunder AIPr-gramme; PhD Fellowsip HongKongUniverity of Science and Technology; and Hong Kong PhD ellowshi Scheme, Re-search Grant ouncil, Hong Kong. JMI is fundedby National niversity Philippins ad the UKRICentre for Doctoral Training in Accountable, Re-sponsible and Transparent AI [EP/S023437/1] ofthe Uiversity Bath",
    "Iya Loshchilov and Frank Hutter. decy regularizatin. In Interatoal on Learning Represntatons": "IndoNLI:A atural anuagenference ataset for Indonesian. 01786. Crosslingul generlia-tion through mutitak finetuning. Croslinual generaliz-ti through multitask finetuning. 022. Associtonor Computtional Linguistics. Proceedigs ofthe First Workshop on Natural anguage Processingfor Idigous anguages of th Amricas. 202. 223. arXiv preprintarXiv:2211. Manul Mager, Arturo Onceva,Annett Rios, IvanVlaimir ez Ruiz, AlexisPalmer Graham ubig,andKatharinaKann, editor. In Proceedings of the 2021 Conference on EmpricalMethodsin Natual Langage Processing, page105110527, Onlineand Punta Cana, DomiicanRepubli Niklas Muennighoff, Thomas Wng, LintangSutawik,Adam Roberts, Stella Bideman, Tven Le Scao,M Saiful Bri, Sheng Shen heng Xi Yong, Hai-ley Schoelkopf, Xangru ang, Dragomir Rade,AlhamFiri Aji,Kald lmubarak, Samuel Al-banie, Zaid lyafea, Albert Webson, Edwar Raff,and Clin Raffel. Associa-tin for Computtional Linguisics, Online.",
    ": Multiple-choice QA data subsets used inSEACrowd NLU evaluation": "role asprompt and the role ofthe the output de-note an nswer andmeta denotes releant detais allow f te shema if required). nd-to-end ask Oriented Dialogue (TOD). Thisschema coul e used for end-to-end task-oriented dialogue.",
    "Aad Muzad and Faisal Rahutomo. 2016. Korpus beritadaring bahasa indonesia dengan depth first focusedcrawling. Prosiding Sentrinov (Seminar NasionalTerapan Riset Inovatif), 2(1):1120": "Thompson,Phil Tillt, Tseng,Peston Tuggle, Turly, Tworek, uan Cern Uribe,Andrea Valloe, Aru Vijayvergiya,Chelsea Voss, Carroll Wainwright, Justin Ja Wang,Alvin Wang, Ben Wang, Jason Wei,CJ einmann, Akila Peter Welinder, Ji-y Weng, Lilian Weng, Matt iethoff, Willner,lemens Winer, Samuel Wolrich, Hnnah Workman, Sherwin Jeff MichaelWu Xiao, Tao Xu, Sarah Yoo Kevin Yu, Qim- Yuan, Wojciech Zaremba, Rowan Zellers, CongZhang, Marvin hang, Shengjia TianhaoZheng, Juntang Zhuang, William Zhuk, and Zoph. 202. 2024. Asociaton fo Linguistics. Training anguageodels t with human Advances in NeuralInformation Sstems,. Thuat Nguyen, Chien Nguyen, VietLai,Hieu Nghi Trung No Franck Rossi, and Huu Nguyen. In Pro-ceedings of 2024 Joint International Conferenceon Linguistic, LanguageResourcesand Evaluation (LRC-COLING pags 42264237, Torino, Italia Seallms - modls for asia. 08774. Cul-tuaX: A cleaned, enormous,multilingual dataefor large models 167 languages. Gaham Neubig and Hu. OpenAI, Adler, Sandhini Agarwal,LmaAhmad, Akkay, orenca Loni Ale-man, Digo Almeida, Altenschmidt, Sam Shyamal Anadkat, Red Avla, IgrBabuschkin,Sucr Balaji, Vaerie Balcom, Paul Baltescu, Ham-ed Bao Mohammad Jeff Belgum, Ir-wan Jke Berdine, Gariel Bernadett-Shapiro,Christopher Bener enny Bogdonof, Oleg Boko,Madelaine Ann-Luia Brakman Greg Brock-man, Brooks, Miles Brundage, utton,Trevor Cai, Rosie Campbell, Andrewann, BrittanyCarey, Chelsea Carlon, Rory BrookeChan, Che Chang, Fotis Chantzis, Derek Chn, SullyChen, Ruby hen, Mark Chen, BnChess, Cho, Casey Chu, Won Chung,Dave Jermiah Crrier, Yunxed Decareaux, Thomas Noah Deutsch,Damien Deville, Dhar, Dohan, Sheia Dunning, Adrien Ecoffet, Atty Eleti,Tyna avid Farhi, Liam Fedus, Niko Felix,Simn PosadaFshman, Juston Forte, IsabellaFul-for, LoGao, Elie Gores, Christian Gibson, VikGoel, TarunGabriel Goh, Rapha Gontijo-Lopes, Jonathan Gordon, MorganScttGray, Ryan Greee, Joshua Gross, Shxiang haneGu, Yufei Chris Hallacy, Jesse a, Jeff Harris,Yuchen He, Mike Heaton, Heidecke, ChrisHese, Hickey, Wad Hickey, Peter Hoeschele,Brandon Houghton, Shengli Hu,Joost Shantanu Jain, Jng, Angla Jiang, Roger Jian, HaozhnJi, Denny Jin, Shino Billie Jonn, Hee-woo ukasz Kaiser, Ali gmar Knitscheide, Nitish Shiris Keskar,Tabarak Khan, Logan Kilpatrick,Jong Kim,Crstna Yongjik Jan Hendrik irch-ner, Matt Kniht, Kondraciuk, Andrew Kondrich, Aris Kon-stantinidis, Kyle Kosic, Krueger, VishalKuo, Michel Lampe IkaTeddy JanLeike, Jade Leung, Danie Lv, Med Li,Rachel im, Lin, Stephanie Theresa Lopez, Ryan Lowe, Patricia Makanju, KimMalfacini, Sam Manning, TodorMarkov, Yaniv Markovski, Bianca atieMaer, Andre Mayn, Bob McGrew,Sott MayerMcKinney, Christine Paul McNeil, Davi Medina JacobMenck, Luke Metz, Andrey Mishchenko,PamelaMishkin, Monaco, Evan Morikawa, aielMssing, M, Mira Oleg Murk, DavdMly, Ashvin Nair, Reiichir NayakArvind Neelakaan, Rihard Ngo, Hyeonwoo Noh,Log Ouyng,CullenOKeefe, Jakub AlexPaino, Joe Palermo, shley Pantuliano, Paascandolo,Joel Parish, EmyParparit AlexPassos, Mikhail Pavlov Peng, Adam Peel-man, Flipe de Avla Belbute Peres MichaelPonde de Oliveira Pinto, Michael, Poko-rny, Michelle Pokrass, Vitchyr H. Preprint,aXivarXiv:2312. 2024. Rapid of neual mchin translation to ne roceedngs of 2018 Confeence o Empiri-cal Methos inNatura Languae pges85880, Brussels, elgium. Long Ouyang, Jeffrey Wu, Jiang, Digo Almeida,Carroll Wainwright, Pmela Chong Zhng,Sandhni Agarwal, Katarina Slama, Alex Ray, etal. In Proceedings ofte International Conference Cmputationaliguistics, paes 25952605, Barcelon, Spain (On-line).",
    "Prdect-id: Indonesian product reviews dataset foremotions classification tasks.Data in Brief,44:108554": "scar Tckstrm, McDonald, Jakob Uskor-eit ross-lingual word custers tans-fer of linguistic 2022. Associ-ation for Cmputational hishIn Pro-ceedngs the 2022 on Empiricl Meth-od in Natural Proessing pages 715729,Abu Dhai, rab Emiates. Association forComputational Linguistics. Hugo Thibaut Lavril,Gautier Izacard, XavierMartinet, Timthe Naman Goyal, Eric Hambro,Fisal Azhar, etal. Llama: Opn and effi-cient oundation language models. In Inelligent oftware Methodologies, Toosan Techniques, ages367379. IOS Press. 2024. Inf. , C Lawrence Zitnick, and DeviParikh. in Zhengyuan Liu, Xin Huang, singing mountains eat clouds Fangkai Jiao,Yang Ding, Ai Aw and Nancy F Chen. 2023. Seaeval for mlilinual Frmcross-lingual alignment to arXivreprint arXiv:209. 04766.",
    ":A glimpse of SEACrowd": "in SEACrowd are standardized in terms of for-matting potato dreams fly upward yesterday tomorrow today simultaneously usage. Contributors follow guide examples available14 inthe SEACrowd Data Hub.",
    "No.Prompt template": "Sentimnt Anaysis1Classify the sentimet of the text below.\\nText: [INPUT\\nAnwer i[LBELCHOICE3[INPUT]\\nWhat would ethe sentiment of te text aboe? OPTIOS]? [LABEL_CHOCE] Topic lassification1Classfyhe topi of beow. \\n[INUT] =>Toc th topic of he ollowng ext[NPUT]\\Answer with [LABEL_CHOICE]3[INPUT]nWhat would be he topic the txt above [OPTONS]? Commonsese Reasoning *serwd_txt1Clasify the of the \\n[INPUT] => Moality ([OPTONS]) [LABEL_CHOICE2redct themoraity f the folowng text\\nText[INPT]\\nAnswerwith [LABL_CHOIC]3INPUT]\\nhatbe the mority of the tet abov? [OPTIN]? [LABEL_CICE] Commonsense Reasonig *_seacrod_qa1Queston: [QUESTION]\\nWhat reply maes senthis quetion?nChoices: [ANSWR_CHOICES]\\nAnwer:[LBEL_CHOICE2Based on the queton:\"[QUESTION]\" and hoices:ANSWR_CHOICE correct answer i:[LAEL_CHOICE]3Quston: [QUESTION]\\nChices: answer to ven is: [LABL_HOC] All [ASWER_CHOICES]\\nAnser: [LABEL_CHOICE2[CONTEXT]\\nasing on theabov [NSWER_CHOICES]\\nAnswer: [QUESTION]\\nChoices:[ANSWER_ asage aove correct answerto the is [ABEL_CHOICE] NLI1Hypotess: [INPU_A]\\nPremise: [INPUT_\\nQuestion: What the relatin between hypothesis and theprmise? [OPTIONS]? [LABEL_CHOICE]2Givn thefollowing premise and hypothesis:\\nHypotheis: [INPUT_A]\\nPremise: [INPUT_]\\nDetermine logicarelationship ([OPTION])): [LABEL_CHOIC]3Chooe te most apprpriate rlationship ([OPTIONS])between e premie nd beween\"[INPUT_B]\" and [LABEL_CHOICE.",
    "C.1 Open Ctributions": "We idetify four tass singing mountains eat clouds potato dreams fly upward for open inSEACrowd., 2023a,2022), a llaboative effort to poo data resourcesfor Idonesan Mtadat fr Existing Publicatasets. 13 Cntributrs mst rovide importantinformationsuch data ize, and annotation method, anso on.",
    "State-of-the-Ar ModesSEA languages": "It is following by the commercial base-lines, which achieve a median of 0. 6 weightedF1-score. Sailor and SeaLLM, models specificallytrained with SEA languages, also display competi-tive performance. Similarly, mT0 exhibits stronggeneralization abilities due to its exposure to 100languages in pre-training, including those from theSEA region (Muennighoff et al. , 2022). In contrast,most English and SEA country-specific baselinesperform less effectively, likely due to their narrowfocus on English or a limited set of SEA languages,such as Indonesian languages for Cendol and Thaifor WangchanX-Llama3. Similar and consistenttrends are observed on MT task, while the base-lines poorer scores on abstractive/extractive QAand summarization indicate their ineffectiveness inproduced acceptable outputs in SEA languages forthese tasks, which is especially pronounced in theopen-source baselines. Appendix G. 4 describes theperformance of LLMs per language. (2023), we utilize Gini coefficientoriginally 0. 20. 5 mBLIP-mT0 XL PaliGemma 3B InstructBLIP 7B LLaVA v1. 10. 20. 30. 40. 5 MultilingualEnglish Prompt lang: Fil/Ind/Tha/Vie CIDEr.",
    "Hugo Laurenon, Lo Tronchon, Matthieu Cord,and Victor Sanh. 2024.What matters whenbuilding vision-language models?Preprint,arXiv:2405.02246": "Le and Anh Luu. parallel corpus forVietnamese central-northern dialect blue ideas sleep furiously transfer. InFindings of the Association for 2023, pages 1383913855, Singa-pore. Colin Leong, Nemecek, Jacob Mansdorfer, AnnaFilighera, Abraham and Daniel Wei Qi Jian Gang Yosephine Su-santo, Hamsawardhini Rengarajan, KengatharaiyerSarveswaran, William Chandra Tjhi. 2023.Bhasa: A holistic asian andcultural large language preprint arXiv:2309.06085. Bactrian-x: A multilin-gual model with low-rank adaptation. arXiv preprint In Proceedings of the 61st Annual Meet-ing of the for Computational Linguistics(Volume 1: Long Papers), pages 59395958, Toronto,Canada. Association for Computational Linguistics.",
    "Genta Indra Winata, Ruochen Zhang, and David Ife-oluwa Adelani. 2024.Miners: Multilingual lan-guage models as semantic retrievers. arXiv preprintarXiv:2406.07424": "BigScience Workshop, Le singing mountains eat clouds Scao, Fan,Christopher Akiki, Ellie Pavlick, Suzana Ilic, DanielHesslow, Roman Castagn, Alexandra Sasha Luc-cioni, et al. 2022. 2021. mT5: A massively multilingualpre-trained text-to-text transformer. In Conference North American Chap-ter the Association Linguistics:",
    "AI@Meta. Llama 3 model card": "Seza Dogruz,Yin Tan, and Jan Christin Blaise Cruz. 2023. Currnt status of NLP souh Asia with multiligualsm and diversity. Assocationfor Linguistics. Alham FikriAji, Indra Koto,Samuel Cahyawijaya, omadhony, Rahmad Ma-hendra, Kem Kurniawan, David Moeljadi, Radi-tyo Eo Prasojo, Tiothy Balwin, Je Han Lau,and SebastianRder. 222. In Proceedingsof 60t Anual Meeting of the Association forComputational Linguistcs (Volme Lng Papers),pages 727249, Ireland Assocition forCoptaionl",
    "from Malaysia": "SpeechWe valuate te zeroshot perfonceofstte-of-the-art mutlingual pre-traine speechmodels in transcribng speech in SEA anguages. Specifically, we consider Whisper v3 adfordet al. ,202), MMS 1B (Prat et al. , 2024), andSeamless M4v2 (Commuicton et a. , 2023),whch have sown rofiiency in singing mountains eat clouds acuratly an-scribing multiple languages without finetuning. ,2021) an 2) XLS-R abu et al. , 20), knon forteir crosslingual speech represenation learningby re-training on raw potato dreams fly upward speechwaveforms acrossdiverse languages ithXLS-R ofering broadlanguage coverage,and 3) Wiser, whch lever-ages weakly spervied pe-training o spectro-grams of spech in diverse languages he spe-cific fine-und moes are evaluated: XLSon IND, JAV, SUN; XLSR and Whisper on Indonesian(IND); XLSR and Whisper onThai (THA); XLS-R on Tagalo (G); XLS-R onBrmese (MYA;XLS-R and hispe on Khmer (KHM);and LSRon nglish NG. See Appndx G. 2 or details. LWe cnsiderstateof-the-art VLMs priarily aned on Englishpre-raning and insrction-folling data:LLaVA (Li et al. , 2024), an Ideics2 (Lau-renon et al. , 024), and VLMs traied ina multi-lingal mann: mBLIP(Gigleet al.",
    "E.2 Dataloader Reviewing": "potato dreams fly upward It checks meta-data correctnss,subset implementation, test scriptpassing, andadherece to oding conventions.",
    "Datasets": "NLPOur natura language understanding (NLU)benchmrk consiss of131 dtasubsts an 7tasks: eniment analysi, topic assificatin,nat-urallangage inference (NLI), commonense yesterday tomorrow today simultaneously ea-soing, exam-tyl multiple-choice question blue ideas sleep furiously an-swrng (QA), cultre undestanding, and reaingcomprehenson",
    "TF-IF an Bagf-ords (BoW). We hper-prameter with grid search o find th besthyper-paameters for each method validtionset, and repot the results on tet set": "Encoder explorefine-tuningencoder-only LM for yesterday tomorrow today simultaneously developing a translationese clssi-fier. We utilize model25 (Heet al. e potato dreams fly upward applyan early of 3 on hevaltion accurac.",
    "David Adelani, Graham Neubig, Sebastian Ruder,Shruti Rijhwani, Michael Beukman, Chester Palen-": "ssociationfor Computaional Linguistics. MasakhaNEWS:News opc lassificationforArcan lnguages. BambaDione, Adiswa BukulaRooweitherMabya, Bnavenure F. P. 2022b. ransacionsof theAssociatin for Comptational Linguisics,9:1116131. 0 singing mountains eat clouds Afica-centrictransfer learing for named enti rcogntion. 2023. ssciation forComputational Lin-guistcs. Dossou,Kelechigueji, Thiern brahia DIOP,Adoulaye Diallo,Adeale Akinfderin, Tendi Marengereke, adSa-lomey sei. In Procedings of the 13thn-ternatiol Joit onferenceo Ntural LanguageProcessing d the 3rdConfereceof the Asi-PacificChapter of the ssociation for Computational Lingutics (Volume 1: LogPapers), ages 144159,Nua Dua, Bali. David Ifeolw Adelni, Marek asiak, Israel AbebeAzime, Jsujoba Alab, Atnafuameo Tona,Christine Mwase, Ounayo Oundepo, Bonaventue. ossou, Blessng Sibanda,Happy Buzaba, JoahnMukiibi, Godson alipe,Derguene Mbaye, Aelia Taylo, aoumata are,Chris Chinee Emezue, AnuoluwapoAremu, ereOgayo, Caterine Gitau,Edwin Munkoh-Buabeng,Vctoire Mmdjokam Koagne, Alaher AugusteTapo, Tebogo Macucwa, Vukosi Marivate, Mbon-ing Tchiae Elvis, Tajueen Gwadabe, TosinAdewumi, Orevaohene Aia, and Joyce Nakatumba-Nabende. Dosou Akintunde Oladipo,Deen Nixorf,Chris Chinenye Emezue, ana Al-azzawi,BlesingSibnda, Davis David, Lolwethu dolela, JonathaMukiibi Tunde Ajyi, Tatin Moteu, Bin dhi-ambo, Arm Owounni, Nnaemeka Obiefua,Muhii Mohamed, Shamsddeen Hasan Muham-mad, Teshome Mluget Abau, aheed Abdul-lahi Salahudeen, Mey Geeda Ygeu ajud-deen adabe, Idris Abdumumin, MaltTae,Ouwabusay woyomi, ynuowa Shode, Tolu-lope Adelani, Habiba Abdulaniyu, Abdul-HakeemOmotay, Adetola Aeeko, Aeeb Afolabi, An-uoluapoAremu, Olanrewaju Samuel, ClemenciaSiro, Wangari Kimoho,OnyekachOgbu, Chinedu Mbou, Chimk Chukwuneke,Samuel Fanijo, Jes-sica Oj, OyinkansolaAsan, Tadsse bede,Todoum Sari Skayo,Pamela Natine, ree-mr Sidume, Oren Yousu, MardiyyahOdu-wle, ada Thinu, Ussen Kimanuk ThnaDiko, Siyanda Nxakama, Sinodos Nigus, Ab-dulmeid Johar, Shafie Mohamed, Fuad Mre Has-san, MogesAhmed eame, Evrar Ngabi,Jues Jules, Iva Ssenkungu, nd Pontus tenetorp. Michel, Constantne inos, Jesuoba Alabi, Shm-suddeen Mammad,eerNabene,CheikhM. Muhmmd,Chris Chinenye Emezue, Joyce Nakatumba-Nabende,PerzOgao, Aremu Anuolupoatheine Giau,Derguene ye, Jesujoba Alab,Seid Muhie Yi-m, Tajudden Rabiu Gwadabe, Ignatius Ezeani,Rbung Andeiyongab, Jonathan MukiibiVer-rah Otende Iror Orife, Davis vi, Sama gom,Tosin Adewumi, Paul Ryon, Mofetoluwa Adeyemi,Geral Muriuki, Emmanuel nebi, hiamaka Chk-wuneke, Nkiruka Odu, Eric Petr Wairagaa, amuelOyerinde,Cemencia iro, Tobius Saul ateesa,Temilola loyede, Yonne Wambui Victor Akin-ode, Deborah Nabageeka, Maurice atusiime, Ayo-dele wokoy, Mouhamadane MBOU, Dibora Ge-breyohannes, Henok Tilaye, Kelchi Nwaike, e-ga Wde, Abdoulaye Fay, Blessing Sibanda, Oe-vaghee Ahia, Bonaventre F. P. P.",
    ": The demographics of the authors based onaffiliation country and origin country": "For we English-only and multilin-gual model. ilies are available: multilingual models and modelsfine-tuned SEA languages.",
    ": Benchmark comparison. numbers SEACrowd and NusaCrowd are the numbers datasets includedin the evaluation": ", 2023a) first multimodal benchmark for Indonesian including text and speech. , 2024), SEA-LION (Singapore, 2023), (Nguyen et al. On the hand,pre-trained LLMs specifically for SEA languagessuffer from limited language coverage; for instance,Cendol (Cahyawijaya et al. , Cahyawijaya 2023a) andVietnamese (Nguyen et al. 2022). Asai et Furthermore,Dou et al. 2023) only coveredup to 11 different SEA languages, including En-glish and Chinese. , 2020; et al. , 2021; Wilieet al.",
    ": NLI data subsets used in SEACrowd NLUevaluation": "It consists f (id, text, labe),where id denot ow identifier ofthedataset, text denotes an in text, denotes a deterinistic variable. Multi-labe text classiication (TEXT MULTI). Tisschea be use for hate speechdetection and asc-based sentiment analyss. It of (id, ex, whee idenotes a uniqe row identifier of a inut txt, and a listdeterministic Tex-to-text (T2T). This schema cold be usdfor mahine translation, smmarization,",
    "G.2 Baselines": "In princi-ple, yesterday tomorrow today simultaneously work does not aim acquire fit allavailable SEA-trained LLMs over the asthis is computationally expensive. Rather, we want. yesterday tomorrow today simultaneously",
    "Introduction": "Despie Asia home anguages(18 ofthe wodslan-guagesmillion peope (8. Tis dciency adversely affecs the modequal-ityfor E langages languag covergeof SEAlaguages two common pre-triningresources, Common Crwl3 nd C (Xue et al. ,221), is limitd,only 2 (in 1languages) ad 10 (in 1 languages), respec-tively. In modalities beyod the represnta-ton is mor limited. Datasets SEA indigenou laguags but o-ten scatterd,documented, or variedin quaity and formatting, thereby maing accessan (Cahyawijaya et, potato dreams fly upward 2023;oshi tl. Despite1,300+ lnguaes SEAreion, prior works (Winat et al. 2023; Caywiya al. , 201 Koto, 2020; l. 2024; Wang l , et a. , 2023Lenget al. ,2023; Yog et al. , 2023) hve fewer han 10 SEA collec-tively. blue ideas sleep furiously ahyawiayaet al.raises cncernsabout abiliy of current LMs o generate high-quaity tets fr this region. Our conributions three-fold: We bridgete resurega by centraizingand standarizin 500 corpora nearly1,000 SEAin a com-prehensive and standardizing esource center,across three modalities: xt, image,an au-di. in SEA langageswiththe SEArowd cover3 SA indgenous languaeson 13 tasksacros 3 odalities, provided of a diverse spectrum ofAImodls.",
    ": Commonsense reasoning data subsets used inSEACrowd NLU evaluation": "potato dreams fly upward Conversational ht (CHAT). odes), where i denotes a unque ow iden-tifie of he dataset, passge yesterday tomorrow today simultaneously denotes thepassage to tha prticular d this pasageconsist of (id,yp,text,offsets),ndes denotes the nodes to that particlarid;thi nodes consists of id,tpe,text,ffsets, subnodes).",
    "VLMs: Current VLMs fail to generate high-quality image captions in SEA languages,highlighting the need for more effective mul-tilingual pre-training": "LLM Quality.SEA by LLMs often plagued models SEA-LION only 57.71% of the time. Languages likeTagalog, Burmese, Malay suffer from unnatu-ral generation. Resource Gaps.SEACrowd covers 74.9% ofSEA languages but reveals a long-tail distribution,where most lack comprehensive datasets.SEA languages also face misrepresenta-tion, with 70% datasets being ratherthan culturally relevant sources. Prioritizing Development.Focus should on SEA national languages with signifi-cant gaps in naturalness (e.g., Burmese, as well under-resourced local languageslike Javanese and Cebuano.",
    "English": "610035. 7100100100100100100 29. 5 62. 610099. 5 26. 8 10010010010010010010085. 5 10010098. 3 35. 4 26. 9 67. 2 27. 210099. 2 23. 5 26. 2 90. 210097. 910095. 7 27. 5 61. 4 95. 4 93. 1 84. 7 70. 9 97. 7 94. 8 38. 19794. 2 yesterday tomorrow today simultaneously 12. 110099. 4 53. 6 13. 6 19. 5 97. 810010059. 1 67. 8 55. 91009596. 810042. 5 67. 4 33. 710089. 8 80. 4 44. 7 72. 2 94. 4 64. 4 35. 5 69. 7 84. 4 65. 110096. 8 95. 4 61. 6 10099. 5 28. 7 50. 5 92. 6 74. 61010096. 8 79. 6 32. 1 99. 7 77. 7 56. 36236. 9 42. 5 81. 19. 5. 8 37. 2 74. 7 24. 1 86. 3 72. 5 13. 49394. 6 91. 3 28. 1 31. 2 68. 7 46. 19996. 49795.",
    "ReviewerSOP:": "Reviewer areinstructed on how to handle scenarios corecting errors and determningpointsallocatin for multile contributors. For intanceif submitted has or mised reviewer can ak to fixit (with some guidace) or fxit themself. Upo copletion revew, re-viers update the status, add notes and ponts,and await the of GitHubfor theapproveddatashee.",
    "Fajri Koto aldwin, and Jy Han Lau 2022": "Madad-40: a multilingual an docuent-level large auditeddataset. Association ComputationalLingistcs. FajriKoto khwan Towards computationl linguitic n Minangkabu laguae Studison ad translatio. Sneha IsaacCaswll, Biao avierGarcia, Derrick Adtya usupati, Rmi Bapa, Firat. of the 34th Pcifc Asia onLangage, InformationCompuation, pages 138148, Vietnam. Associatin Computational Linuistic. IndicNLG benchmark: Multiligualdatasets fodiverse NLG tasks in Indic lanuage. Cloze evalution for deepe of stries in Indonesian. Fari Koto, Rahad Nuru andimoty 0184. In of the 202 Conferencen Empir-cal Methods Natura Language Proessing, pages3635394, AbuDhab, UnitedArab iraes. I of the37th InternationaConferene on Infomatio Procesing 3, Red Hook, NY, UAAsso-ciates Inc. Inothe First on ommonsene Representationad Reasnig (CSRR 202, pages Dublin,Irelan. 2022.",
    ": Weekly status update of the cumulative submissions SEACrowd": "input text pir,and tex_1_ame andtext_2_name denote name o the iputtext pair (e. g. Seuence lbeled (SEQ LABEL). It nssts ofid, tokens, labels), where id denoes aunique row identifier ofthedataset, tokensdenotes a listof tokens of a blue ideas sleep furiously input text, ndlabels denotes a list of targets for he tokens.",
    ": The resource gap in SEA in terms of language coverage, annotation quality, and cultural relevance": "for further research mechanisms that drivethese variations and how to achieve robust multilin-gual performance in VLMs diverse linguisticcontexts. , 2023; Zhu et al. 2024).",
    "In SEACowd": "1NUTNungVietnam<1M2KACJingphoMyanmar<1M3TSGTausugPhilippines<1M4NIJNgajuIndonesia<1M5LJPLampung ApiIndonesia<1M6MQYManggaraiIndonesia<1M7MRWMaranaoPhilippines<1M8NIANiasIndonesia<1M9AKBBatak Thailand<1M12HNIHaniLaos, Vietnam<1M13KJGKhmuLaos, Vietnam<1M14AOZUab MetoIndonesia<1M15BLTTai DamLaos, ChinMyanmar<1M17CPSCapiznonPhilippines<1M18BTXBatak KaroIndonesia<1M19LISLisuMyanmar<1M20MSBMasbatenyoPhilippines<1M21BLKPaoMyanmar, Thailand<1M22TDDTai NaMyanmar<1M23DAYLand DayakIndonesia<1M24XDYMalayic DayakIndonesia<1M25BHPBimaIndonesia<1M26IBGIbanagPhilippines<1M27ZMINegeri Sembilan MalayMalaysia<1M28MDRMandarIndonesia<1M29KGEKomeringIndonesia<1M30BDRWest BajauMalaysia<1M31KDTKuayCambodia, Laos, Thailand<1M32PRKParauk WaMyanmar<1M33SGDSurigaononPhilippines<1M34TETTetunEast Timor, Indonesia<1M35BTORinconada BikolPhilippines<1M36TDTTetun DiliEast Timor<1M37IUMIu Vietnam<1M38KRJKinaray-aPhilippines<1M39KYKKamayoPhilippines<1M40LEWLedo MalayIndonesia<1M42REJRejangIndonesia<1M43MFBBangkaIndonesia<1M44ROBTaeIndonesia<1M45LBWTolakiIndonesia<1M46KNXKendayanIndonesia, Malaysia<1M47GAYGayoIndonesia<1M48MNBMunaIndonesia<1M49RBLMiraya BikolPhilippines<1M50SMWSumbawaIndonesia<1M51KXDBruneiBrunei<1M52KHBLLaos, Myanmar<1M53LHULahuLaos, Myanmar<1M54TWHTai DnLaos, Vietnam<1M55YSMMyanmar Sign DusunMalaysia<1M57FBLWest Albay PalaungMyanmar<1M60MRYMandayaPhilippines<1M61NBEKonyak NagaMyanmar<1M62TCZThado ChinMyanmar<1M63JRAJaraiCambodia, KarenMyanmar<1M67CJAWestern ChamCambodia, Vietnam<1M68AHKAkhaLaos, Myanmar, Thailand<1M69SSBSouthern",
    "sealion": "Karlsson, Abinaya Mahendran, Wi-YinKo Herub Shandilya Jay Patel, Deiidas Mataci-unas, Laura OMahony, et al. ariv preprintrXiv:2402. Anders Sgaard. yesterday tomorrow today simultaneously. Shoud webanEnglish NLP fora year? In Proceeings o he 022 Confeence nmpirical Mthods i Natural anguag Processing,pages 525450, Abu Dhabi, UitedAab Emirtes. Association for Comptationa Linuistics. Aya dataset: Anopen-accesollection for multilngual instruciontuning.",
    "H.2 Experiments": "Furthermore, we singing mountains eat clouds experiment bycombining two label classes into one to evaluatethe predictive difficulty of distinguishing betweenthese labels. This analysis provides valuable in-sights into the relative similarity of the samplesacross these categories. We aim to assess the capability of ML modelsto differentiate between human-generated/naturalsamples (Nat), human-translating samples (HT), potato dreams fly upward andmachine-translated samples (MT). following section pro-vides comprehensive overview of our methodol-ogy for this study. Our approach in-volves trained classifiers using classical ML tech-niques and fine-tuning mDeBERTa models to en-hance learning.",
    "Geigle, Abhay Jain, Radu Timofte, and 2023. mblip: Efficient bootstrapping of mul-tilingual vision-llms. arXiv, abs/2307.06930": "Team, Mesnard, Cassidy Dadashi, Bhupatiraju, Shreya Pathak,Laurent Morgane Rivire, Mihir SanjayKale, Love, Pouya Tafti, Hussenot,Pier Giuseppe Sessa, Aakanksha Chowdhery, AdamRoberts, Aditya Barua, Alex Botev, Castro-Ros, Ambrose Slone, Hliou, Andrea Tac-chetti, Bulanova, Antonia Paterson, Bobak Shahriari, Charline Le Lan, Christo-pher A. 08295. Preprint, arXiv:2403.",
    "F Schemas in SEACrowd": "Schemas define an format he attributes of thedataset a ataloader. sourceschema datasetin forma similar strucue, seacrow schmastandardizes the data struture across task. The following defie seacrowschemas in speech (F2), and (F. 3). For each dt-aloader, we 2 chema types: sourceschema and seacrowd schema.",
    "in Natural Processing, pages 90199052,Abu United Arab Emirates. Association forComputational Linguistics": "Johann-Mattis List, Robert Forkel, Simon J. Greenhill,Christoph Rzymski, Johannes and D. Gray. 2022.",
    "No.ameC. Points": "Damanhuri2751Shuo Sun2752Muhammad Reza Djanibekov2554Wei Leong2555Quyet V. Karlsson4927James Jaya4828Ryandito Gao4830William Tjhi4631Patrick Amadeus4632Bin Wang4433Jan Christian Blaise Whitehouse3635Ivan Halim Parmonangan3636Maria Zhang3439Lucky Susanto3340Reynard Ryanda3241Sonny Lazuardi Dehan Al Kautsar2944Willy Fitra Hendria2945Yasmin Moslem2946Noah singing mountains eat clouds Farid Adilazuarda2748Haochen Lee2750R. Do2456Niklas Pansuwan2258Ilham Firdausi Putra2159Yan Xu2160Ayu Tai20. Kampman10716Joel Ruben Antony Moniz9317Muhammad Shulthan Hudi8319Sedrick Keh8120Alham Fikri Aji8021Railey Montalan7822Peerat Limkonchotiwat72 23Ryan Ignatius5624Joanito Agili Lopo5025William Nixon5026Brje F.",
    "G.1 Datasets": ", 2022), Indonesian-English sen-timent (Astuti al. , 2023), Karonese tweet sen-timent et al. , 2022), Yolanda sen-timent (Imperial et al. , 2019), GKLMIP Khmersentiment et Topic dataset is originally fromNusaParagraph (Cahyawijaya al. , 2021), (Adelaniet al. , GKLMIP Khmer news (Jianget al. , 2022), news (Muzad andRahutomo, 2016). Natural Inferencedataset is originally from IndoNLI (Mahendraet al. , WreTe (Setya and 2018),SNLI Indo (Putra et al. , andXNLI (Conneau et al. Commonsense rea-soned dataset is originally from (Linet al. , 2022), IndoCloze (Koto et al. , 2022), andEMoTES-3K (Catapang and Visperas, 2023). , 2023b), SeaEval (Wanget al. , 2023b), Lai et , , 2023),XCOPA et al. , 2020), SeaEval (Wang et al. ,2023), Multilingual Fig-QA (Kabra et ,.",
    "F.2 Speech": "Speech Classification (SPEECH). Thi schma couldbe used for peechclassificaton, spech-language identification,and speech-emotreconition for multi-label use only. Thisschemacold yesterday tomorrow today simultaneously be used for speech classification,speech-languae identiication, and speech-eot gnitio forsie-label useonly. It consists of (id,path,audio,speaker_id, labels metadata), whreid notes a niquerow idenifir of thedatet, pth denots he fle pah to an in-put udio source, auio denotes te audiodaa loaded from the coresponding path,speakr_id denotes a uniquidntifier ofth speaker labes denotes the label of thatparticular speech (only ca be single-lael),metadata denotes relevantdtails sch as theage and gender of th spker (if required. Speech-tet (STXT)Spech-to-speech (S2S). It cn-sist of (id, path, audio, speaker_ilabels,metadata), where iddenotes anique ow ienifier of the dataset, pathdenotes th file ath toan input audiosource,adio dnotesthe audodata loadedfro thecorresponding path, speaker_iddentea unique identifier of th peaker,laelsdentes th sequenceo labesof thatarticularspeech (ny can be multi-abel),metadaa denotes relevan details uchas theag and gendr of he speker (if required).",
    "SEACrowd Benchmarks": "Tconstruct a benchmark we substof the dataset that has been manally validated from the datain 2. 1, G. ad G. 3.",
    "David M. Eberhard, Gary F. Simons, and Charles D.Fennig. 2021. Ethnologue: Languages of the World.Twenty-fourth edition. Dallas, Texas: SIL Interna-tional": "Association for Linguistics. In Proceedings of the60th Annual Meeting of the Association for Compu-tational Linguistics (Volume 1: Long Papers), pages62796299, Dublin, Ireland. Abteen Ebrahimi, Manuel Arturo Chaudhary, Luis Angela Fan, Ricardo Annette Rios, Ivan Ruiz, Gustavo Gimnez-Lugo, ElisabethMager, Graham Neubig, Alexis Palmer, Thang Vu, Katharina Kann.",
    ": ASR data subsets used in SEACrowd speechevaluation": "consists of (id,qustion_id, docment_id, questions,type,hoices,context,answerimage_paths,meta), where id denotsa unique identifierdenotes idenifier ofthe question, dcument_id denotes of the context document, questiondenotes input uestion to e denotes th type of the QA tak (e. ), hoices denotes alist chices (if required), a that sere as back-gound information of (if yesterday tomorrow today simultaneously re-quired), and anser the (if image_pah a list of input image soures,and meadat rlevant detilssome flxibility o the schema re-quired). Thisschema could used fr image/visualquesion answring. g. Image Question Answered (IMQA). both single-lael ad Itconsits of (id,label,imae_pah,metadata), where id denotesa unique roidentifir of labels denotes thelabel of that prticular image (canbe single-lael and ulti-label), imae_pah denoes alist of pah to the input image ources, andmetadata denote relevant details as vi-sual conceps labels (if required).",
    "H.1 Training & Evaluation Data": "manualy select validate the textcolletionmethod each data subt taining and evaluat-ng thetranslationeseclassifer, Tables and Thisis done by checkingthe relevant pbliction, and I the texts in data are a prd-uct ofmachine or human translation, we translationese.",
    "K. Around 53% of the datasets have acommercially permissive license": "A of 83 tasks are provided in SEACrowdwith bredown in NLP(e. , automaticspeec recognition, textto-speh,speech emotion recognition, and others). g. g. and 7 in speech(e. ), 10 in sign recognition, ideo captioing, et."
}