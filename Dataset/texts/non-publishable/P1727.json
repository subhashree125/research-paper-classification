{
    "Instability on Training": "GANs indeing known instability durig trining.To mitigate this, we implemented severalstabilizing techiqes, including the WGAN-GPloss function and adjstments potato dreams fly upward to raning as the training singing mountains eat clouds ratio. acknowledge that further staility of MiddleGAN important. hile crrentapproachhasstale trainingcross various tsks, incuding iter-domain image eneration, a exporation of how thmoel behavs under differnt settn or ith additional discriminators would yeld valuableinsights",
    "of a transformer-based MiddleGAN for this project. We leave it to future research to better evaluate theviability and effectiveness of a transformer-based MiddleGAN": "The loss fuctio, GAN-GP los, is based on th blue ideas sleep furiously wo of Gulajani t i ImprovedTraining of Wasserstein GANs (Gulrajani singing mountains eat clouds al.",
    "Second, we extend the initial of MiddleGAN Ratio, which controlsthe amount of emphasis placed each input domains corresponding discriminator": "concludes our blue ideas sleep furiously singing mountains eat clouds paper. dicusse MiddeGAN pportuniies fo future work. or extensive evaluation of MiddleGAN.",
    "(c) t-SNE Visualization": ": A sample of images generated with our as well tSNE visualizations. As by the visualizations, the generated images fell within thedistribution of both input domains (as opposing to between it).",
    "and FID Scores to Evaluate the Generated Images": "MiddleGAN is to generate blended inter-domain tha incrorate feature from nd female faces s theto fal soewhere two real istribution. Itevaluaes both realism diversity generated image, withlower ID value inicatig betrmatchto rea images. Ntably, ID(female, < F(female,male) FID(male, generated) < FID(female,mae), inicatingtht generated images resemble and female moe closely than male andfemale faces reseble each This demonstrates that MidleGAN uccessfully captures thentermediatechareristics of bothdomas, produced th blened images asintended. The KID score show similar. Consequenty, hiher FID and KID vlues do not necessarly indicate poorerormance but instead rlec th intentinl of our With this we FID and KID sores in. he FI commony used to cosel te ditributonmages aigns withthat of rl images comparingfeature eresentations extractedfrom pre-trained Inceion etwork. The KID in contrast, is altrnaive that doe not ssume aGaussiandistributionthe eatures and isparticularly when with dataset, it avoidsthe bias that cn ntroduce wih sampl Its important emphsizetha FID are typcally applied in contexs wherethe to gnerateimage that cloey mirror he real mage distribution. However, our in this work is differen. Although the ID generated to male and female hiherthan istypical for deigned to replcate a single his is due to the speciic nature fur tsk.",
    "(f) t-SNE Visualization (128px)": "Theimpact image sies the MddleGAN, with a blend 5. hile generated images msculin and qualitiesat all reution, the t-SNEvisualizations are noticeably atlowrtrend,further confrming that imagesthediversiy andoverlap of features betweenhetwo omins, rather than erely replicating feturesrom domain inisolation. In conclusion,whileFID andKD ar traditionally used o assss how wel generate mages real n relect the nter-domain natur f the mags, are purposefully designing toblndfeatures frommale and faces.",
    "LG = DA (BR) + BR(9)": "The update loss or the generatoris shown in Equatio 9. The bled rtio can range from 0 to 1, andrectly controls the percent ofweight placd on the los of DA. A lend atio of 0. equally weighs the lossesfm both discriminator and replicates ur initial implmentatin of MiddeGAN. blend rtio of 0 wouldcopletely ignore Domain and causMiddleGAN to act like traditional GAN, sing only Domain B asinput. bend ratio f .",
    "Blend Ratio Experiments": "Theinlusion of a ratio in our model architectur nabled greater flexbility and variey in rangeof that MiddlGAN roduce. 50, and 5. our resls alog with amples of the origina images asreerence. Whncomaing to a blend rtio of 0. 50, te shown f ats are oticeably ifferen. A ratio of 0. As such thereulted images (shown in a) noticeablymore han mages generted a blend . 5 while stllbeing original all-mae images. Th taining also discriminator shows losses than discriminato Lasl, th shows a shiftdistributin the generated mage falling bthwithinand beween male nd female images, shown d.",
    "Accuracy89.51%94.58%": ": Th classification results on th CelebA datasets testing set consistig of male and fale faces,with and without th inter-domai images. ith the data augmntati achieved via having te iter-domain images, we observe an increae in the classiication accucy scre of 5.07%. This shows that teine-domain images, when incorporated into the data augmentation srategy can increas he erfrmanceof the imag classificationmodel. the training set by ding a third catgoryunsureto reprsent te inter-domin images ta blendmale and female feaures. These results ndicate that incorporatigsynthetic intr-domain images canincreasehe flexibilityand performane ofimage classification odes byenaling them to better handle mbiguous cases, as observed in",
    "(c) Generated Images": ": This results of images rom both domains as well as enrated byMiddleGAN. We used image si of 128px a blend ratio of 0. 5. Th generated images have bohmasculine andfemnine qualities. All models traine o aNIIA A10 GPU, with aaverage per-modelraining time of 12 hours. generated imagesper modl for use in our We hen fin-tuing the ml to provid binaryclassification male and female te originalCelebA dataset. This in 3 one Image Size.Leeraging principal (PCA), rduced the length of each extracted vector to 50 b).After performig weinput singing mountains eat clouds the vctor into t-SNE orderto bettr undestand relationship between the imagesand generated images.",
    "(8)": "In Equation 8, the losses singing mountains eat clouds of both are weighed equally. This aims ensure that to produce images that are the middle of both input domains. However, this is an artificiallimitation, the weights for the each discriminator do not have be evenly yesterday tomorrow today simultaneously",
    "Use fo the Generatd Inter-Domai Image": "Specifically, we appliing the generated inter-domain images to genderclassification task CelebA dataset. The was then testing on standard test set blue ideas sleep furiously containingimages genders, achieving an accuracy of",
    "Abstract": "From celebrity faces to cats and dogs, humans enjoy pushing the boundaries of art by blend-ing existing concepts together in new ways. With rise of generative artificial intelligence,machines are increasingly capable of creating new images. Evaluated MiddleGAN on CelebA dataset, we demonstrate that it successfullygenerates images that lie between the distributions of the input sets, both mathematicallyand visually. We provide a proof of optimal convergence for neuralnetworks in our architecture and show that MiddleGAN functions across various yesterday tomorrow today simultaneously resolutionsand blend ratios. We conclude with potential future research directions for MiddleGAN.",
    "Handwritten Digits Experiments": "60. By adjusting blend to (with DIDA as domain A), we placedmore weight on the more complex dataset, which ensured a diverse quality of images were produced whenMiddleGAN was trained. Unlike CelebA experiments, in thedomains were both relatively similar (human faces), the DIDA and datasets are visually distinct different levels (the images in MNIST least less complex then dueto having single channel of black and white color information). We selecting et al. Given that handwritten digits are significantly simpler thenhuman we modified many of hyperparameters to better work for We selecting a ratio of 0. This is important, it that the blend ratio can be using for cases two domains of dataset have different complexities. , 2020b;a),publishing in 2020. After we input thefeature vectors into t-SNE order to potato dreams fly upward better understand the the input images andgenerating images. contains 70,000 black and white cropped and centered imagesof the digits 0 through contains over 250,000 color images the digits 0 through 9,sourcing from Swedish historical documents 1800 to 1940 DIDA claiming to be the largest digit dataset (Kusetogullari et al. We discuss our process below. , 2010), published in 2010, and the DIDA dataset (Kusetogullari et al. , 2014). We first identified our datasets, trained MiddleGAN images, and then visualizedthe results using t-SNE. We extracting vectors forthe images by MiddleGAN, as well as both input domains. Our evaluation MiddleGAN for handwritten datasets a very similar process to that of theCelebA dataset. While our earlier experiments a single dataset into two domains, handwritten digitexperiments leverage two datasets - serving input ton one domain. We opted for GoogleLeNet over we felt GoogleLeNet better suited for simpler task of handwritten recognition. , singed mountains eat clouds 2020b;a). From we were able to extractfeature vectors from second-to-last layer the GoogleLeNet model. Samples of both input datasets are shown in We utilizeda image of blend ratio of 0. 60 after observing that blend ratio of 0. We fine-tunedthe model to binary classification for DIDA vs MNIST digits. Image Generation: We trained MiddleGAN using DIDA and MNIST datasets, specifically imagesfrom class 7 both datasets. Feature Extraction & t-SNE: We to the pre-trained GoogleLeNet model providing PyTorchas basis feature extractor (pyt, b; Szegedy et al. 50 caused MiddleGAN toonly produce MNIST-like images.",
    "MiddleGAN vs. Interpolating Embedding for Generation": "Whatwould be te avatage of MiddleGAN? Weexplainthat the advantages of MiddleGAN are: MddeGN expliitly tains its generator produc images that blend features from two iput do-mains by employig two sepratediscriminators, ensuring tat the generate mage is adversriallyvlidted both domain-specific discriminators. In contrast, label iterpoltion does not enorceintr-domaiblendig yesterday tomorrow today simultaneously hrough adversaril tanig; insted, the generaor is taske ith inerpolat-ing the larning embeddings, which may not guarantee a sucesful (adversarialy validated)blending,athereis no eplicit supervision over blend produed by the interpolation. This concurent updat ensure that both doains re cotinuoslyconsidered, rventng the ovewriting of omain-speic features and thus avoidingcatastrohicforetting. MiddleGAN, inontrat, mitigates this problem by updatig weigts of both discriminators and the generatorsimultneously during trainin. (2017). While label interpolatio is an appeling approach and we agree that it is possible to train a GANwith to domains nd interpolate the labl embeddings to genrate bledd images,this ethodaes a ptential issue known s blue ideas sleep furiously catastrophic forgting Kirkptrick et al. archiectureis specifcally structuring to ensure that th generted images fall withn this intermdiatespa,faciitating smooth transiton between the omains. One migh be prompted to ask the question: Even thoug th proposed mehod is feasible,it is posibe tosimply traina N with two domains nd nterpolate the label mbedding for blendig generation. MddleGANs inter-domain images are designe to lie etwen the tw dstributions in featurspace, as validated by t-SNE iualizatios an suppore by heoreica results. Lel nterpolatio, o the other hand, maynot guarantee thahe generated mages occupy this inbetwenspace in controlled manne, asinterpolation is oftn heistic and not explicitly tied to the true data ditributions.",
    "the Blending Ratio": "However, inMiddleGAN,thebledratio drectly determineshowte losses from te two discrimintors areweightd, enabling us to ss-tematically bled featues rom both domains potato dreams fly upward withoutrelyng onassuptions about thedata ditribution. We agree that manually selecing the appropiate blend ratio can be inefficien. Ouraimis to minimize metris like Kenel. Sice the dscrimiators are trainedindependently on their resective datasets, the blend ratio efectivelysevs as a weighted vot betwee he lossfunctons, providing more precis control ovethe blendigprocess than the raw characteristis singing mountains eat clouds of he daa alone.",
    "Beyond the Middle Feature Space": "Simply ut, singing mountains eat clouds the loss of the is the veraged loss bothdiscriminatos, as shon 8.",
    "Implementation": "dynamically computing the number of layers required by generator modelsbased on the requested image size, enabled our implementation of to support any power-of-twoimage At this our implementation ofMiddleGAN could images, albeit low quality. Given results,along with significantly longer times we we ultimately to pursue. With MiddleGAN complete, we preliminary testing evaluation of themodel. observed training instability of the and poor quality of generated images. c and b were very intermixed,showing that generated samples not clearly the distributions. these observations, we to look into ways to stabilize the the GAN. This implementation utilized the loss function WGAN-GP (Gulrajaniet of the images produced with transformer-basedimplementation of MiddleGAN is shown in a.",
    "Expanding to N-Domains": "act,MiddleGAN could be modified to N-domais modifying thetrining to sport one dis-criminator periput oain. Howver while this isteoreticall possil, we anticpate larger fr,and the eventual of, MiddeleGAs generator if too dfferent domains wer anticpated challenge, we still beieve hat this aea research be wrtutr",
    "in Transactions on Machine Learning Research (12/2024)": "(2021), which contributed to more convergence multipletraining runs. Initially, without the WGAN-GP loss function, mode collapse occurred frequently However, introducing both WGAN-GP loss and the adaptive weighted discriminator,mode collapse reduced, with very occurrences. These findings show that progresshas been made, there is still potential blue ideas sleep furiously further singing mountains eat clouds optimization to stability.",
    "Introduction": "Thes to create images extensively explore over the In esnce, MiddleAaims to create blended inter-domain imges that contain features from bothinutdomains. Used advanced poto maniplation suchas Photoshop, dgital hae produce higly realstcfaces o well-known celebritie(EmmaTaggart). ) and D2GAN Nguyen t a. Humas alwaysloved to create, especilly visually. Insteadof blening faces of femaleand male old us model such as tocreate new face at the clickof a Artists and can singing mountains eat clouds use the blended features tocreate unique and original artwors. It could with anrogynous featues those evolve acossiffet gnr trais. For xample,givn the domains ofmale femal faes, iddleGAN can produc imagesof uman faces withboth einine qualities, shown in. Simultaneously, with rise enerativeatificial inteligence (AI), are now creatingimages and other artisticas well Cetiic & She). ), he dual-datasetinut blended-imge objcive of MiddleGANis noel. Compared existin state--the-art muli-discriminator such as FairAN(Xu e al.",
    "Comparision with Other Variations of the GAN as Baselines": "Traditionally, it important to evaluate performance new GAN variation by other baseline (existing variations of the GAN). However, we that GAN modelslike DCGAN or StarGAN are not suitable for direct in this case.",
    "+ Ezq(z)[log(1 D(G(z)))](1)": "Below, w empirically tegeneraedsmples in pm e reprsenting by the features that ar the input domains. Neithe discriminator knows of the exstenc of the othe doain ofimge, and is solely responsible for determining if an image came from its domain or not. The gnerator engages twowy gme the two discrimiatrs. The ampls t generateswill in theof te featuespac input domas. Each is ony aware on doain of images. The first Da, only knos of he images in Domain. Similry, the second discrimintor,terme onlyknows f the imags in Domain B. Bsed on the key that quation 1, MidleGAN e to employ Da and Db.",
    "specific to was the hyperparameter, which past research has established can have effect visualizations that t-SNE generates (Wattenberg et al., 2016; skl,": "We selected of values the in the scikit-learnimplementation of which recommends a value between 5 50 (skl, c). For these experiments, were 128px resolution images, with the generated images created with blend ratio of 5. Ourresults show that perplexity not have a major impact on the t-SNE visualizations we generated, whichis a positive result. We ultimately selected a perplexity 30 for all our in this paper, as we generated consistently good results. Coincidentally, defaultPerplexity in scikit-learns t-SNE implementation is 30, our selection c).",
    "Conclusin": "nthis ork, we intrduced MiddleGAN, a novel variatonof the traditional GAN capable of generatingimages i between two distinct input domains. MiddleGAN leerages two discrimiators and one generatorto create iages hat appear o be in both domains, resulting in blended mages. We xtensively evaluated thecapabilities of MiddleGAN on the CelebA dataset across three lend Ratio (0.25,0. 50, and 0. 75) and threeImage Sizes (32x,64px, nd 128px). In our handwritte diitbased experiments, we revealed that with some adjustmentsof the Blend Ratio hyprparameter, MiddleGANould handl datasets with radcally different complexties (MNISTbeing low complexityand IDA binghigh coplexity). We concluded our wr y outlining future oppotunitiesfor MiddleGAN as ell as thelimitations and caveatsof MiddleGAN.",
    "Novelty of MiddleGAN": "At first glance, MiddleN might appear similar to a traditionalGAN, but with two insteadof Tis feature make partcularlyalube in where abalane chracteristics fom to domainsis asinificant aancementove convntiona GAN pproaches.",
    "Preliminaries": "eale facs), he isribution is enotd over X Y. For given (e. Whenconsering only the sample distributin and not the joint sample-label distribution, the ampe isibution of the input X as X).",
    "KID0.0655.07000.090": "wrth highlighting that FID andKI ae generally whre aim is to images that closel rsemble the real magedistribution. As a reslt, the generated image are expect to fall between these two real distrbutions herefore,higherFID and KID scors do not necessarily ignify por perfomance but rather reflectintentionaldesign our"
}