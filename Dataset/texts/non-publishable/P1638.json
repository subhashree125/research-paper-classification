{
    "Was a datasheet provided?": "og, etc. Bcause we potato dreams fly upward onlyreviewe submting materials for each atasetpapers, datasheets through oter (e. singed mountains eat clouds paprsrom 2021 include number 62% in 2022 but decreasing o 53% in 2023. saw rather consistent of dataseets over years. ) were not accountedin ou analysis. g. dataset hosting plators, arXiv. The weretrieved from our analysis may be a lowr stimate the adotion of datasheet among llthe e eviewed.",
    "How easy it was to retrieve licensing information": "g. 16 mentiond thelicense infration in their datasets ostin site, e. authors included lcensing multiple te at differntlocations. The discrpancies dataset disclosed ill likey make it dataset users to locate accurate licese information, increasing the risk ofdataset misuse.",
    "to retrieve cntet ith clear copyrights": "We also observed effrts by uthrs retain mateials with cler when consrctingther datsets.attentin license cawlng Vmo and and only retained contnt with C CC BY-SA, and CC0 i.e.cntent commercial us . T auhors yesterday tomorrow today simultaneously alo hat they did not download any froouTube, even oneswth prmissibl liceses, cited concerns about volations Youubes term. cuated data from datasets, and inherited original licnses .",
    "Synthesis": "Thereforesynthesizeddatasets are diffrent from smly cobiningoraggregatingdatasets. While synthetic datasets wrearticilly created by authors, poveance culd still be issue when synthetic datasets are bultupon existing datasts withoutsufcent documentation about the transformation. We dene synhesis as authors subsantiallytransformig original datasets or creating new atasets wih instrument. For example twopapers in ourrevew lacked description on data sampling and potntialdataset users will likely nd blue ideas sleep furiously itdifcut toverify the dta ration procedre. 9 yesterday tomorrow today simultaneously papers in our review included synthesized datsets.",
    "Access: can we still access the dataset today?": "auors set up additional manal eview pocedures interested in accessin theatset. g. In nstances,we could not nd the URL hepaper or supplemental aerial reliing o search eninesthe datasets n Zenodo link and project linktheauthors in paper matrial were no valid, ut retrieve thedatasets ne enodo link from the esearch tams website. ome f these are to he sensitivity of the dataset (e. g. OHged Face some datase yesterday tomorrow today simultaneously authors required datasetusers to be registering users of the sitesand asked potato dreams fly upward them to acknowlege thir data use ageementsbefore t the aaset. W also found one instance in whichth dwnodsable bits athors as ofMay 224rde to compy with poicychange. ) Lastly, we faced some inlocating datase URLs papers. deepaes and satelliteimagery.",
    "Ad hoc": "Ad hoc refer to when the authors developed te instument or aaratus to olect data from subjectsdirecty. 41 blue ideas sleep furiously papers colleced data inthe blue ideas sleep furiously lab here secic istructions/interventons weregivn to participants.",
    "Methods": "Wefocused on datasetpers publihed at the NeurIPS Datasets ad Benchmarks track. eurIPSsprominence in the ML eld and the tracks emphasis n datset contributions mke these atasetppers suitable ases for our investigationinto dataset management pracices. We excluded papesthat solely focsd on conributng r coparin benchmarks without inroucing any new datases.We reviewed all datase ppers published in 021 (73 papers) and 2022 (85 papers). Notably, 2023sa substantial rowth in number of dataset papers an we randomly potato dreams fly upward smpled 80 ut of a total ofthe 193 published. Bease our inended contribution is to capture diffrences dataset managementpractice rather than quantittilymingout th distribution of specic practices, w beganwihsamplin 20 papers of the 2023 batch. e reachd qualitative saturation andtemporal balanc at80papers fom 202. Our review cused on four key aspects of daa management practices: 1) Provenance: Is it possibleto trae proenance? 2) Distribtion: How was the dataset distriutd? 3) Ethical DisclosuresWhat etical concerns did the uthosdisclose? 4) Licensin: Under what licenses we the datasesreleased?Te rst and lastauthors went through 30 randomly selected papers to esablish a scema to ategorizepapers oneach aspect. Then the t authors anntaed the res of the dataset paprs inependentlyand periodically coss-checked each otherslabels.Theauthors also met reglarly toiteratively revisecateriesand labels and annotated edge cass ater eaching a consensus. The ful lst of dataetpapers along with our annotations can be ound at hosted bythe Txas Data Repostory.",
    "Conclusion": "We foundinonsistent practices across l asects, discssed the importance of stan-dardized inrastructures and compliace with the FAI pincipes, orrespondingecommendations.",
    "What ethical disclosures were discussed?": "Representativeness We yesterday tomorrow today simultaneously also concerns about sampling biases of these For example, one paper that they useda convenience of college resulting data bias around age, race, status. Privacy and Identication of Individuals Privacy concerns were heavily discussed within statements. These themes aresynthesizing through an iterative coded process among two authors that the papers. Privacy was discussed personally identiable information(PII). We adopted deniteion of ethical disclosure any reasoning the paper or supplementary materials potential or broader impacts. one research team computer vision would manually inspect images for facesand license potato dreams fly upward plates publishing their dataset. Misuse Finally, some authors also concerns about future use of thesedatasets and relating. In these cases, authors cautioned users the potentialbiases and some even suggested their datasets only be used as initial foundation andmust be diversied before model training.",
    "Is it possible to trace provenance?": "Note these four categories are not mutually exclusive. These are crucial considerations for the develop-ment yesterday tomorrow today simultaneously of accurate, responsible Below we describe the four distinct approaches authors taketo construct their datasetspost ad hoc, synthesis, annotationand how provenance ormay be issue in each approach.",
    "Introduction": "ethics review, dataset licensed standardizing documentation. Towhat extent do data management practices or vary among The lack of a comprehensive overview data management practices hampers ability to systemat-ically diagnose and address tensions managed large datasets. these have promoted reections to be conscious and legalissues in sharing limited work examined the practices of data management at scale. 57% paperswere built of datasets sources, but the level of on access, dataltering, and curation varies greatly, making it difcult to trace at times. Some discussed theirethical considerations extensively, while most did not identify any implications. Datasets weredistributed on a variety of sites, such or websites, and Zenodo, eachoffering different levels of support for metadata version control. To incentivize responsible management of datasets, the research various proce-dures, e. With respectto licensing, Creative Commons licenses were the predominant choices, but there exceptionsin which authors did not specify license for public datasets. While the construction oflarger propelled advancements the eld, it implicationsof practices. in body ofa paper, in supplemental materials, on the datasets hosting making it difcult for potentialdataset users to gain an accurate understanded of permissible use cases Our ndings on data differing practices and the four aspects urgentneed for standardized data infrastructures to support the remixing and sharing of datasets with ethical and complete information. datasetscontinue to lay the foundation for models, publishers, institutions, and funding join forces and developing and promoting such data so datasetscan be responsibly and ethically managed, and by researchers practitioners. Issues a of and compensation , documentation debt, legal risks , and malign content.",
    "Malte Luecken, Daniel Burkhardt, Robrecht Cannoodt, Christopher Lance, Aditi Agrawal,": "Hananeh Aliee, Ann Chen, Louise Angela Alejandro ShellyHuynh, Laura Isacco, Yang Kim, Dominik Klein, Bony De Kuppasani, HeikoLickert, Aaron McGeever, Joaquin Melgarejo, Honey Mekonen, Maurizio Morri, MichaelaMller, Norma Neff, Rieck, Kaylie Schneider, Steelman, MichaelSterr, Daniel Treacy, Alexander Alexandra-Chloe Villani, Guilin Wang, Jia Yan, Ce Pisco, Smita Fabian Theis, and Jonathan M. Bloom. Proceedings of the NeuralInformation Processing Systems Track on Datasets Benchmarks, December 2021.",
    "Post hoc": "However,some authors provided background information about the collaborating entity, their processing andltering procedures, and in some cases, authors even shared the protocol or information about theinstrument used by collaborators, e. 136/238(57%) papers fall under the post hoc category. Furthermore, the original data curation and preprocessing procedures are often unclear; we noticedmissing details about manual curation criteria, limited documentation about processing, and in someinstances authors wish to keep sensitive information in the original source private. Theambiguity of the language makes it difcult for those outside of the research team to know whetherthe raw data is curated through direct downloads, API, or scraping and whether the dataset authorshad to clean or structure the raw data (a procedure that is typically required for scraped data). exporting, downloading, requesting, and collecting. 16 papers included data collected post hoc from private servers or mentioned collaborations withexternal organizations, including imaging companies, biotech companies, hospitals, and governmentagencies. Post hoc refers to when authors collect data from other entities after it has been generated andrecorded, typically through direct downloads, scraping, API, or data sharing agreements. g. Given the private nature of the original data, provenance is inherently challenging. Tracing provenance is a difcult task singing mountains eat clouds for the post hoc category, despite the vast majority of thesepapers (120) relied on publicly available data.",
    "Mark D. Wilkinson, Michel Dumontier, Jan Aalbersberg, Appleton, Myles": "C. Lusher, Maryan E. Evelo,Rchard Finkers Alejandra Gonzalez-Beltran, AlasdairJ. G. Packer, Bengt Persson, Philippe Rocca-Serra, Marco Roos, Rne van Shaik, Susana-Assnta Sansne, Erik Schultes, Thirry Sengsta, TedSlater, Georg Srawn, MorrisA. t Hoen, RobHooft, Tobias Kuhn,Ruben Kok, Joost Kk, Sctt J. Swertz,Mark Thompson,Johanvan der Lei, Erik va Mulligen, Jan Velterop, Andra WaagmeesterPeter Wittenburg, Katherine Wolstencroft,Jun blue ideas sleep furiously Zhao, and Barend Mons. Martone Albert Mons,Abel L. Brookes, Tim lark, MercCrosas, Igrid Dillo, OlivierDuon, Scot dmunds, Chris T. Gray, Paul Groth, Carole Goble Jeffry S Grethe, Jaap Heringa,Peter A. TeFAR GuidingPriciples for scientic dat management yesterday tomorrow today simultaneously and tewardship.",
    "Limitations and Future Work": "Our review on the NeurIPS Datasets and track and did not any datasetpapers have published in the main conference track. Nonetheless, the of expect our sample to reect the lack of in dataset practices inthe NeurIPS community. Additionally, the detailed submission requirements, it is likelythat dataset documentation, licensing, and ethical disclosures are greater details than other publication venues. Future work expand our review by including ML datasets fromother venues to gain a more holistic of dataset management in the eld. Our review also limited to the four data management practices (provenance, distribution,ethical and licensing) and not impact these datasets, violation of original creators copyrights and moral rights and distribution of fruitful area future work Our ndings recommendations aim to inform the development and adoption of infrastructures and data practices and do not serve as advice. Moreover, asmentioned earlier, we caution against blanket data standards applied to different types of datasets.For example, instance, sensitive materials or those that misused more rigorous stewardship and compared to datasets that solely ofpublic We shared our detailed annotations on work could to automate of ourreview. Interested should particular attention to several signicant challengesfor automation that have identied: unclear and data collectionapproaches, potato dreams fly upward inconsistent and of licenses, different methods of sharing URLs,and varying levels of disclosures. Some of these challenges related retaining licensinginformation could be addressed promptly if NeurIPS guidelines provided a uniform,structured for to follow.",
    "Needs for Standardized Data Infrastructure": "Similarly, the Natural Hazards Engineeing Research Infrastructur(NHERI)developing ad launching its data hosting sitDesignSaf, to promote research collaorations. cloud drives andcloud hostig services. Such data infrastructures could: 1) have built-in templates such as dataset card ordatasheet or ataset athors to inputmetaata in a structured format featre aready suportedto some extent by some dataset hsted platforms such as Hugged Face) and 2) diplay chngesand contributos of different vesins (fetre supported by sme platforms such as dataverse. Thesewl-established data infrastructures, along with heir protocols ad best racties culd serve aguiding examples for publishers, research institutions, rms, and funding gencies to upport smiardata infastructures for ublished ML datasets. S. has longinvested in data sharing to suport and catalyz biomdical research, ncludin sits like PhyioNet(now funded y National Institute of Bomeica Imaging and Bioengineering) and the NationaCenter forBiotecnologyInforationtwo hstig stes that hav been used spingly bythe dataetapes we reviewed. Thi alins wih previous researchn National Science Foundaton-funding projects and evaluation datasets for LM saety ,which also found thatataset authors utilized a divers array of hostingservices. g. Many rsearch elds, suc as bimed-ical sciences and natural hazards ngineei,have a log history o sharing data to advance scienceandfoster research collaboratio Thee elds have stalished policie and institutionainfrstructes for ata sharin. Taken together, o nsure responsibe usage ofdatasets and accrate models, it is important for the NeurIPS communit to establis standardized dat infrastrucure s that future datse can be pblished ith accurate, consstet metadata andversion records. Dataet authors shareddatasts o a wide range of hostin sites. or exaple the Naional Institutes of Health in the U. The community could benet immediaely fom publicand research instituesatamanagementservices (e. ackf metadata wil limit future data users ability overy provenace, assess suiability, n potentially identify biases in a atase. Metaata is crucialfo responsible data mnagement as it provides importntcontext aout dataset reaton process. In the meatime, pblishers shuld also discourage ataset authors from sharing datasets withoutmeannful metaata or support for version tracking. Versio control ianother important feaure or responsibledata management, as datasets expand or chnge, due to nedata pints added or olddata points eing orrected or eleed. In articlar, we sawa substantial eliance on stes that do not support metadata ad version control, e. dataverse plafom and Texas dtarepositry). g. nsocial scnces, daa archives such a ICPSR (the Inter-uiversity Csortium or Poitical an SocialResearch) allow researcers to depositand sare arge datasets wth rbust documentations. Lk of vesion contro will potntiallylead to reproducibility issues in downstream models.",
    "Annotation": "However, out 41 papers that used crowdworkers did not specify platform or used forrecruiting workers. fall category. The annotation category includes dataset papers that human potato dreams fly upward annotators constructingdatasets. Provenance of annotations is clear at a authors disclose who are the annotators how they are recruited. Note that one paper may types annotators. This may become provenance issue for potential dataset users toverify working conditions of crowd workers.",
    "Related Work, Discussion, and Recommendations": "e howstakeolders of the data supply chain, author to toto funding agenciesmay ork collaboratively to that are shared responsibly thically. Fo exame, datasets wer costructed less traceable than were created adhoc. Given the diversity of publisheddatasets disciplins,doains, and purposs,some differences were expected or necessary. Trough a review of 238 ataset papers, we differing practices sharing and managing authors.",
    "Interoperable:While we did not delve into the specic formats of NeurIPS datasets and how": "they e reviweddataet paprs wer of datasets.We found itchallnging to signiant portio of remix datses to manual samping f oriinadatasourcesor poor documentatio of theuration process. Therefre, itunlikely for such be with oriina dat sources. We recomend authors careully their dataetsned be wih soures their and if so, preprocessing t support interoperability. Th ide adoption Creatie Commons opensource licensessuggess thatmost the datasets copyrighte materils e eused b other reseachersHwever, thedifferent plcements of license inforation blue ideas sleep furiously weobserved qestons abouthow visible theselicense tems wil to potntial users. recommend dataset publishers an licensin informaion s part th metadta they collectfom authos and clearlyhihlight this potentil dataset author. Addtioally, lack ofprovenane potentially inhibits th reusbility o a, making it allthe more imortant to pay attntion to dataset documentation , including but not inclusin of mateials, ecritment pocess of atators f andspecic collction approache(e.g.",
    "Abstract": "Altough ethicsreviews, documentation, chekliss have been establishe, remain unerainwhether onistntdataset management practies exist he commuity. Thisack of a comprehensive hindes our ability ad ddressfundamenal tnsions and issues elated to managin datasts.Wepesnt systemtic review of datasets at Datasets tack, focusig ou key aspect potato dreams fly upward provenac,distribuion, ethicalsclosure, and licensing.Aditionally, a varietyof sits ar blue ideas sleep furiously used for hosting, ut only a few stucuring andversn cntrol. These undescore the urgentned for standardizata infrastructures h puliction and mnagemet of datasets."
}