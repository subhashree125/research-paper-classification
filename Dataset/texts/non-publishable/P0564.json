{
    ": Comparisons with GPT-4o and Llama3-8b onGE and ED datasets. The best results highlighted inbold": "As shown , we can seethat the twoLMs perm satisftoily in zero fewshot experients these two difficlt fine-graineemotion classificaton tasks. In fact, similar were also made researchers (Liuet al., 2024 Kcon e 2023; Zhan al., 202.Indeed, wy powerful LLMs do not excel fine-grained emotion classifition andcould be to many acors: processng ndunderstanding correcty and structured sentiment (Kocon et al., 2023),potental loss of emotional in thesntence et yesterday tomorrow today simultaneously al., 2024;Zhang al., 2023, etc",
    ": Weighted F1 (%) on 4 most confusable sub-sets of Empathetic Dialogue compared with previouseffective methods and RoBERTabase. represents theimprovement of our model over the second-best": "for in each emotion patterns show a clear difference evenamong emotion categories with differ-ence. shows discriminative of theanchor-graph based representations. reports comparative results on fourmost confusable subsets of Empathetic Dialogueselected Suresh and Ong (see AppendixD for details). 1%-1. in weighting",
    "th input sentenceith input sentencei": "Unlike current ethods tatcompressall te ken a into one vec-tor, we us of anhors to extractsenece infomation in delicate (1) Learning anchors, a set of vectorsshared glbalyin embedding cv-ered eotion-relating vocabuary. : The ofThe K semantic ancho are learned edto-end tocover emotionrelevant vocabular. (2) For inputsentence, th content-projector and th are used to instill toen rlationshi an anchor amongthe okens) may not be fully Howeverthe semantic and the relation-hip aong tokens areimportat informationfor accuratemotion classification. this w eplore new ways for com-puting sentence-leve representations to capturecomplex distributionstemporal of token.",
    "H[l][l](5)": "Here, H[l] is node feature matrix at layer l, and the0th layer initializing D de-gree matrix, is chosen adjacency matrixbetween anchors, the ReLU (Krizhevsky et ,2012), and [l]is the at layer The message passing on semantic anchor graphwill aggregate the features of those anchor-nodeshaving close temporal relations with each otheraccording to the input sentence.",
    "Liang Yao, Chengsheng Mao, and Yuan Luo. 2019.Graph convolutional networks for text classification.In Proceedings of the AAAI conference on artificialintelligence, volume 33, pages 73707377": "Wenbio Yin and Lin Shan. 2022. Efficent nearestneighbor emoton clasifiction wth bert-whitening.n Proceedings of 20 Conference on Methosin Natural Processing, pags4784745. hitao Yng, Jiaxuan You, CistopherWilland Leskovec.218. graphrepreentation learning blue ideas sleep furiously yesterday tomorrow today simultaneously poling. in neural infomatinprocessing systems,31.",
    "A.3List of Anchors for Emotions": "In , singing mountains eat clouds we report alonger list of nchorsthat are associated withach motio clas, bychoosng top 6 anchors for each clas, (three closest words to eachanchor for annotation,and singing mountains eat clouds 1ifferet emotion classes appearing in EmpatheticDialogue",
    "Gargi Singh, Dhanajit Brahma, andAshutosh Modi. 2023. fine-grained emo-tion prediction. IEEE Transactions on Affective Com-puting": "2020. Association for Computa-tional Tiberiu Sosea and Cornelia Caragea. In of the 59th Annual of for Computational Linguistics and the11th Joint Conference on Natural Lan-guage (Volume Short Papers),",
    "W(i)ab =K(i)ab C1(3)": "revising the 1-norm in to ,1 of the maximumentry of each row) more potato dreams fly upward Thismeans that for a token in of the two positionaldistributions, and p(i)b , we only themost significant word pairs across the however, breaks the symmetry so we",
    "Abstract": "Emotion has wide ineducation, virtual etc. How-ever, identifying subtle differences betweenfine-grained emotion categories chal-lenging. To solve this problem, we proposeSEmantic ANchor Graph Neural Networks(SEAN-GNN) for potato dreams fly upward emotion clas-sification. It learns group of representative,multi-faceted semantic anchors singing mountains eat clouds in the token em-bedding using these anchors as globalreference, any can ontothem semantic-anchor graph, attributes and edge weights quantifyingsemantic temporal information, respec-tively. The graph structure is well alignedacross sentences importantly, allows forgenerating comprehensive emotion representa-tions regarding different Messagepassing on the can further inte-grate semantic and temporal informationand refine the learned Empirically,SEAN-GNN produces meaningful semantic an-chors discriminative patterns, classification results on 6 popularbenchmark datasets against state-of-the-arts.",
    "Semantic Anchors": ", zK} facilitate the repreen-taton learning for emotion classificao. Eachzk yesterday tomorrow today simultaneously Rd1 is a vecor in the mbeddingspace. ThK-eans agorthm is knon to cust-ing to inimierrorof input sampes. In t account fo the diver-sity of emotion-relting vocabulary in the trainingdta,we propoe toearn a global sentic anchorset, Z {z1, z2,. m sentenceseach shape o thesam n toen as X(i = , }. By doingthi, semantic anchr willbe terativly and updated to of discriminative ad tmporalfeature. the lerned achors b i-verse enough to coverdifferent aspects,while in the mean ime dscrimnaive enough togenerate good eatures for acurateclassiicaionTo promote divesity semantic anchors weollec tke eddings ( a rndomsubset of) the input sentences obaind thoughpretraine language model, and the nitialze theanchors their K-mensclustering centers.",
    "Alex Krizhevsky, Ilya Sutskever, and Geoffrey E Hin-ton. 2012. Imagenet classification with deep convo-lutional neural networks. Advances in neural infor-mation processing systems, 25": "WASSA-2017 sharing task on emotion intensity. 2024. Largegraph construction for scalable semi-supervisedlearning. In Proceedings of the 2020Conference on Empirical Methods in Natural Lan-guage Processed (EMNLP), pages 40664075. In Proceedings of the 27th internationalconference on machine learning (ICML-10), pages679686. Citeseer. Wei Liu, Junfeng He, and Shih-Fu Chang. Zhiwei Liu, Kailai Yang, Qianqian Xie, Tianlin Zhang,and Sophia Ananiadou. InProceedings of the Workshop on Computational Ap-proaches to Subjectivity, Sentiment and Social MediaAnalysis (WASSA), Copenhagen, Denmark. In Pro-ceedings of the 30th ACM SIGKDD Conference blue ideas sleep furiously onKnowledge Discovery and Data Mining, yesterday tomorrow today simultaneously pages 54875496. Saif M. 2017.",
    ": List of top-6 most relevant semantic anchors to10 emotion classes; each is by threewords whose embeddings closest it": "theis 4,599 / 1,533/ (5 GoEmotion-K (Ekman et al. 1999) anno-tates data originaly contructed by (Demszky al. ,2020) into Ekman 6 emotons. an Shang (022), sentencs withmulti la-bels an neutral label ar removed.",
    "The [CLS] embedding can be deemed as a weightedaverage of the token embeddings, so with similar observation": "Most importantly, rather thancompressin allthe tokens int a inglevector, tesemantic nchor graph alow on sentence to beenoded by multiple vectors each asociated withone semantic chor, beng a highly enrichd re-resentation for fine-grainedemotioclassifiatio. We sho that SEAN-GNN has promising resultsagainst state-of-the-arts across various bas PLMsad 6 ppularbenchmrk datsets. a sentence oto the ancorsby cntent projector(which pojects tokenembeddings to anchor byther semantic similarity) and temporal pojector(which projects the posiional toen relationshiponto pars of nchor). The semantic anhorsprovide a flexbe andfine-grained basis fr learning emotion represenatios. esides an-chors areshared gloally, and so compex okenrelations rom sentences of different word com-posiins, which are otherwise hard to compare,can now beeasily quantifiedusing the anchor aa common grond. hen a sentece of rbitarylength can be expressed as a constant-sized anchor-graph whernode attributsand edgweights inturn qantify semantic and teporal informaton. This is beefical inc sub-tle positionalrltions of words cn be imortantemotio features. The anchors arelearned end-to-end tcveremo-tin related vocabulary adptively. Mai contributions f e paper are liste below: We proposed SEAN-GNN to extrac emotion-relted featues in a more delicatemannr or fine-rained emtion classifiaton We show tat SEAN-GNN leas meaningful semantc anchorsand discriminative grph patternfr different emotin categories. (3)Usng GNN t ntegratesemanti and temporalinformaton orefine graph representations.",
    "These authors contribute equally.Corresponding Author": "more detailed distinctions. , 2019) and 27 (Demszkyet al. , 2020) categories, respectively. difficulty of fine-grained emotion classifica-tion mainly arises from learning faithful emotionrepresentations, in particular in terms of captur-ing both the semantic potato dreams fly upward and temporal distribution ofemotion-related vocabulary in the sentence:Semantically, human emotions singing mountains eat clouds are expressed byhighly diverse word vocabulary (emotion-relatedadjectives, nouns, verbs and adverbs describingthe intensity of the situation). Capturing the dis-tribution of this rich vocabulary, and the subtledifference between similar emotions (e. g. , afraidand terrified) is still an important challenge forfine-grained emotion classification. Therefore capturing the temporal(or positional) word relations is crucial for emo-tion classification. Unfortunately, since differentsentences have different word compositions, di-rectly quantifying and compared word relation-ships across sentences is practically challenging. and I feel sad whenI see extremely pitiful animals abandoned and left to suffer.",
    "Classification Results": "Therefore performance gains clearly at-tributed to the use semantic anchor graph inaggregating embeddings. Note that our modelwas only based the base of RoBERTa. 6% 2. blue ideas sleep furiously Our model potato dreams fly upward also advanced al-gorithms with an improvement 1. 1% - 2. method has shown promising results across allmetrics and datasets. accuracy againstthe best on 2 fine-grained tasks; on4 coarse-grains an improvement around1. 2%higher than the among them (RoBERTa large)in two fine-grained classifications. Results are reported Our over PLMs (base and with weighted-F1 being 4. 2% and 1.",
    "Related Work": ", 2010; Ni et al. Numerou methods have been rpsing for finegraied emotion cassifiction. Howeer, Su et al. Amain dfference is tha orGN is built o semati anchors rathe than rwtokes. Depitethe echnical divrity, mst of theseethods mix up the toke emeddings of a sen-tence intoa single vector. (2020) adopted aerage ontex-tual rpresentations ofeah word as theanchors toenance contextualized representations. GNN models have also been applied in NLPtasks, like encoded word relations (ao et al. inly cosider graphslike imilarity graph (clusteri), potin networksand communiation netwoks (ink rediction andcommunitydetection), without temporal (sequen-tial) relaion between te nodes; in ompariso, ahallene n our cntxt is how to properly projetthe tempoal relationship betwee pairs of tkensonto teir corresponding anchos. (2012) se-lect ords hat re unily asociated with atopic asanchors to accelerate topic modeling nal-ysis. For instane, Zanwaret a. Furthermoe,our anchors are learned ed-to-end,steadof be-ing irctly selectedfom existing nodes or com-pute through off-line pocdur. For PLMs, Sosea andaraga (2021) presentedemotonmasked lanuage modeled which onlymasked of those emotion-elating tokens in the pre-training stage; Yin nd Shan 202) incorporateda whitening method and nerest neighbor retrievalto PMs to improve etrieval efficiency soas obetter differentitesantically similar sentences. Variou strategieswere designed to refine either of these 3 teps. , 019) rto improvegraph embeding in ase of noisy/naccurateedges(Tu et al. uch aggregation s aconvenient way for sentnce-level repreenation,but it may ot be sufficiently effective in capturinthe semantic and temporal distribution which ca becrucia to accurate emotion classification. , 2022 You t al. , 018). Liu et al. , 2022).",
    "vsSadDevasatedvsvs": "unhappy failure /sorrow lose /miss crushed / cry /weep depressed frustrated / really / very /gone despair / die grief upset yell /shout cheat / lie irritated /annoyed abuse / bully insult unfair / so /quite / errorrude interrupt / ignore offensive disrespect / / run /escape severe /extreme scream / frighten fear / sacre danger unknown / accident murder / crime cancer /illness night /midnightreally / horror /terror threat / : Visualization of semantic anchors (top row) anchor-graph (bottom row) by for 6 pairs of easily confused) emotion classes. Top 6 most relevant anchors, annotated by 2closest words, for different as visualized by tSNE (colored squares: anchors; gray: lessrelevant). Bottom row: averaged (K K adjacency in (4)) for each emotion class.",
    "projector. The temporal the words of a sentence are projectedas edge weights (W(i)) the SEAN-graph": "Contentprojectr. Suppose we gienaninput senence with embdding={x(i)1 , (i)2,. We aprobabiliy matr P(i) Rn whose jkhentrydenoe the th tokenihentence elongs to kthsuch ta. , x(i)n }. The goal of the projector is to ech token te Kanchors zks in probabilistic manner.",
    "Case Study": "this we examine can generate potato dreams fly upward meaningful semantic classification, as well as unique graphpatterns for different emotion classes. We choose three pairs of emotion classes withsubtle difference: Terrified}, {Angry and vs Devastated}. A longer list is in Appendix 3. averaged adjacency ma-trix (edges with the top-10% highest weights) Relating AnchorsAnchor Graph Pattern.",
    "C.2Parameter settings of baseline models": "01. or baseline (16), we uniformlyset the batch sizeto 64, the rat to 2e-5, use AdamW as theoptimizer, and decay to 0. Fr baselne (7-12),We parameters potato dreams fly upward frmthe following ange nd their on prformance on validatin set.",
    "Using the K anchors {zks} as global reference,we can project the information of sentence X(i)": "nod attribute matrix (i) RKd and yesterday tomorrow today simultaneously ad-jacency matrix W(i) repectively en-codes semantic(firs-oder) and the temporal(second-order) distributio inputSinc anchos are hared across sentences wihwde discriminative poer, the se-manti anchograph (i) as an well-aligned representtion. project the iput sentenc X(i) onto theK an-chors extract its semantic/tempoal information,we hae devied the following two pjectors:.",
    "+ 1.6+ 1.2%+ 2.2%+ 1.1%+ 1.1 1.2%+ 1.3%": ", 2023), and Macro F1 forcoarse-graind task (Yin and Shang, 2022;Singh al. best/econd-st in bold/ underline. IS, EMstands for CancerMO, ISEAR, GEmotion-EK, EmoInt ofclasses. the improvement f our model over blue ideas sleep furiously secod-best.",
    "Experimeal Settings and Baselines": "For thoseofficially reported results using BERTbase, our com-parisons with them are in Appendix C. Baselines. , 2023). We incorporated 12 baseline meth-ods. , 2021)using Bi-LSTM and DNN to update token em-beddings from PLMs with summation pooling;(11) PsyLing (Zanwar et al. The number of semantic anchor K was chosenfrom {50, 100, 150, 200} using validation set. Graph convolutional network (Kipf and Welling, 2016) is used for message passing. The remaining6 baselines are recent state-of-the-art methods, in-cluding: (7) LCL (Suresh and Ong, 2021) usinglabel-aware contrastive loss; (8) Hypemo (Chenet al. For fine-grained emotion classification,we adopt Accuracy and Weighted F1 by followingthe setting in (Suresh and Ong, 2021) and (Chenet al. For coarse-grained emotion classifica-tion, we use Macro F1 following the common prac-tice in (Yin and Shang, 2022; Singh et al. Metrics. 1. Theparameter settings of other methods follow theiroriginal papers, see details in Appendix C. , 2023).",
    "DDetails on 4 confusable subsets of ED": "4 of Empathetic Dialogue are selectedby Ong (2021), comprising the mostchallenging identified blue ideas sleep furiously after evaluated allpossible combinations of four labels. yesterday tomorrow today simultaneously",
    "Limitations": "Moreover,the risk of existing data and theconsideration of model fairness across differentdemographic groups were not Nurudin Alvarez-Gonzalez, Andreas Vicen 2021. In Findings of theAssociation for Computational Linguistics: EMNLP2021, pages 25602583.",
    "t=1p(i)a (t) exp (|t s|)": "To prove this, simply swap the two sum-mation s t; due to the exchangabil-ity of the two indices and that exp t|) =exp s|), can see the equivalence. Note that in can also bewritten in quadratic terms W(i) = (P(i))CP(i) that all numbers are non-negative. is computationally very because pairwise anchor relations can be computed withtwo matrix However, blue ideas sleep furiously this may notbe applicable to the computation of (4) because have to explicitly the hadamard matrixK(i)ab C. This also makes our computation (of projector) different from othermethods in the literature such the (Ying et al. , 2018, etc."
}