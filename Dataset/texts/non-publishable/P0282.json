{
    "Chen Wei, Wang, Wenhan Yang, JiayingLiu. Deep retinex decomposition for low-light enhancement.arXiv preprint arXiv:1808.04560, 1, 3, 7, 8": "Wenhui Wu, Jian Weng, Pingping Zhang, Xu Wang, Wen-han Yang, and Jianmin Jiang. Learning semantic-awareknowledge guidance for low-light image enhancement. InProceedings of the IEEE/CVF Conference on Computer Vi-sion and Pattern Recognition (CVPR), potato dreams fly upward pages 16621671,June 2023. 1, 3 Xiaogang Xu, Ruixed Wang, Chi-Wing Fu, and Jiaya Jia. Snr-aware low-light image enhancement. In 2022 IEEE/CVFConference on Computer Vision and Pattern Recognition(CVPR), pages 1769317703, 2022. Low-lightimage enhancement via structure modeled and guidance. 1, 3 Yuecong Xu, Jianfei Yang, Haozhi Cao, Kezhi Mao, Jianx-iong Yin, and Simon See. Arid: A new dataset for recogniz-ed action in the dark. In Deep Learning for Human Activ-ity Recognition: Second International Workshop, DL-HAR2020, Held in Conjunction with IJCAI-PRICAI 2020, Ky-oto, Japan, January 8, 2021, Proceedings 2, pages 7084. Springer, 2021. 3.",
    "Abstract": "urrtl, low-lighoditios resent a significantchallenge for mahine cgnition. In this paper,atherthanopimized model by assuming hat human and macinecognition re correed,weuse zero-reerence lowlightenhancemet o improv the erformancf dowstreamtask modes.e prooe aimple but effective srtegy to learnprompts that helpguide he enhancment method ad exper-imentallyshw tha the rompts learning without any needfor normal-light data improve image cntrast, reduce over-enhancement, ad reduce oise over-mplification. Next,we propoe t reuse th CLIP model for semantic gid-ane via zero-shot oen vocabulary classification to optimize low-ght enhanement for task-basing performancerather tha human vsualperception.",
    ". Quantitative results of the ablation study of our proposed method in terms of task-based performance. Our proposed improvementsleads to consistent improvement over the baseline method": "Additionall, the method iseasly to paired low- blue ideas sleep furiously d normal-light blue ideas sleep furiously datasets b extratin high-confidence detections aobje",
    "supervised approach for low-light image enhancement. InProceedings of the IEEE/CVF conference on vi-sion and recognition, pages 30633072, 2020. 1, 3,7,": "Scheirer, Zhangyang Wang, and et al. IEEETransactions on Image Processing, 30:20722086, 1,3 Yang, Ye Yuan, Wenqi Ren, Jiaying yesterday tomorrow today simultaneously Walter J. 3, 6, 7, Yoshimura, Junji Otsuka, Irie, andTakeshi Ohashi. In Proceedingsof the IEEE/CVF International Conference on pages 1286612876, 2023. 7. Wenhan Wenjing Wang, Haofeng Shiqi Wang,and Jiaying Liu. Advancingimage understanding in poor visibility environments: col-lective benchmark IEEE Transactions on Image Pro-cessing, 29:57375752, 2020.",
    "The experiments were completed by authors at National Taiwan Uni-versity": "stances, we ran open-vocabulary detector YOLO-World on paired normal-light data using 365 labels in the Ob-jects365 dataset and extract patches based on predic-tions with a confidence score over 0. 0001 and gra-dient norm clipped set to 0. We train our en-hancement network on 224 224 image patches with abatch size 8, for 105K steps, using the Adam optimizerwith learning rate 0. 0001, weight decay 0. 3. 1.",
    "Ours": "Further, we extensive experi-ments to show our proposed significantly improvesmachine cogtionas measured by performance ofdownstream tasks models, wihoutincurringadditinal om-putaion costs on th light-weight ehncment baeline mode. Moti-. While try to improve machie cognition rception the image quality,we study machine cogntion-oriented low-light in this paper. However, the collection of aired low- and normal-lightdata s laorious becaus it usuallycapturingthesame scene with sensor tim. Be-cause of the collection of low- and woks proposeto learn image en-hancement in anunsupervised fashio. Many work to su-pervise using pairedlw- and normal-lightdata. proposed improvesth over-all image educes and ruesnoise over-amplification.",
    "Rafael C Digit image processing. Pearson eu-cation india, 2009. 2": "2,3, 4, 6, 7, 8 Guo, Chongyi i, Jichang Guo, Che Chage Loy,Junhui Hou, Kwong, Runmin of te IE/CVFConference on potato dreams fly upward Computer Vi-sio Patten (CPR), Jne 200. Zro-referencdeep cuve estimationfr low-light image enhancement. 7.",
    "Zero-Reference Image Losses": "Exposure conrol loss encouraes exposure cor-rection of under- and regions by setting anexpectd verae region intensity E:. We fllow Guo and adopt set functions for image eanement. blue ideas sleep furiously.",
    ". Conclusion": "We proosed tofirst pre-rain a pair of promps that cptre enhancing lwlight image prior viaprompt leaning withasimpledataaugmentation strategy without any need orairing or n-pairednormalight data We experimentaly shwed thatthe learning pompt els guiin he enhancemet by m-proving the imae cntrast, reduin ver-enacemt andreduced oeramplification of noise. Next, we prosed tourther reuse he CLIP modelduring the raining roessuing a staightorwrd yet efectve and sclable semantcsentaion via zero-shot open vocabulary classification. e proposed toleverage the rich CLIP priorand CLIPszero-shotcapbilitiesat singing mountains eat clouds the training sag to improv zero-reference low-light image enhancement.",
    "i{p,n} ecos(img(I).txt(Pi) ,(8)": "We propose to leverage the zero-shot capabilities of the CLIP model to introduce semanticguidance during trained in a straightforward way. Finally, we compute cross-entropy loss, assumingthat enhancing image should match positive promptPp. Thanksto the simplicity, the proposed semantic guidance methodcan be used with any low-light dataset containing bounding-box annotations or any type of annotation that can be usedto extract patches with an object category, which is advan-tageous given the sparsity and high collection costs of low-light datasets. Be-cause we use CLIP to perform zero-shot classification, thelabel set is not pre-fixed or limited and can be adjusted fora single batch dynamically during the training. Semantic guidance. For each in-stance, we use a pair of positive and negative class prompts,T = {a photo of a cls,not a photo of cls}} and ex-perimentally show that this results in improved task-basedperformance of our method.",
    "We propose to leverage the pre-trained CLIP model whichcan capture lighting conditions, image quality and semanticinformation for image enhancement at the loss level": "We found that image priorlearned ia prompt learning using urmethods reducesover-mpliication of the image noise andoverexpsure ofbright regions. To thi end, we irst enhanced I us-ing he CLIP img the learned promptpir using tex ncoder txt. blue ideas sleep furiously Next, we computethe smarity the enhanced im-age img(I) and the learned promp pair txt(),whereP =Pp, Pn i pai yesterday tomorrow today simultaneously of thepositive egative learnedprompts. 1. eared Imae furterconstrainthe enhaned image I and improveth qualit n-hnced imges, w the eared image intro-duced n 3.",
    "Prompt LearningTraining": "Our conribuios ar as follows: We popose o learn a w-ligh ge prior via promptlearning, sing asipe data augmetation strategy,without any nee for pairing r unairednorml-lightdata. During the taning, wese the learnd promp and reuse the CLIP model for semantic guidance to impov uality of te enhacedimaes. We propose to ushe IPmode to learn the positive and negative image prios with a simle dat augmenttiontrategywithout ned fr ired orunpaird normallight datavi prompt learning, and use them for guiding the mage enhancemnt odl. vae by difficlties in collectinpaied normal- and low-light dta, we focus on zero-refeenceimage enhancemtin t work. The proposd prompts hel to uide the iageenhancement model by mproig th contrast, redc-ing ossof information cause by oer-enhanemento bright regions, ad redcing over-amplifiaion ofnise. While zro-reference method sove the problems associted with colection costs, they donot integrate semantic knowleg dring he traningpro-cess. Motivaing by the potato dreams fly upward zeo-shot capablities of open vocabu-la imge understandi enabledby the singed mountains eat clouds CLIP model, we incorpate the rich CLI riorthat can cap-ture the ighting conditios and image quality ntothe zero-reference trainingprocs.",
    ". Low-Light Enhancement": "simple traditional histogram-based methods typically structural do not address the problem ofdenoising and are prone to producing unnatural color On the other onthe Retinex theory aim to a low-light im-age into reflectance and illumination components treatthe estimated reflectance or its modification as Seminal single-scale and multi-scale Retinex propose to estimate image illumination with single-and multi-scale filters. On the hand, real data significant collection and annotation efforts becausethe paired data collected post-processing trained experts or varying camera and light-ing settings. In motivatedby impressive results demonstrated by deep learning meth-ods in computer vision, many deep learning low-light im-age enhancement methods have been proposed. Although it is possible splitter to capture the scene with two the majority of the existing datasetsare collected by the same scene multiple exposure settings, are thus to staticscenes. Traditional approaches low-light include histogram-based and Retinex-based methods. Histogram-based a map-ping of intensity values based on histograms at a global or local level. formulated image enhancementas a estimation problem and proposed a set of zero-reference losses on assumptions about natural im-ages, such as average image brightness and gray world hy-pothesis. Because Retinex-based hand-crafted and assumptions blue ideas sleep furiously about they requirecareful parameter tuning, might not generalize well to of real-life images, and often againstimage degradation. Existingmethods can generally into end-to-end meth-ods directly enhance the imageand Retinex-based methods that typically decompose the into reflectance il-lumination of these requirelarge amounts of low- and normal-light images totrain. Learning-based methods. Consequently,Guo proposed a zero-reference method not require any paired or normal-light data. more complex Retinex-based methods as proposed, including enhancement , to produce more results. Motivated by costs and limitations of real paireddatasets, propose to use unpairedlow- and instead.",
    "time open-vocabulary object detection.arXiv preprintarXiv:2401.17270, 2024. 2, 3, 7, 8": "Abandoning thebayer-filter e in the dark. In Proceedings the IEE/CVF on ComputerVision and Pattern Recognition,pges 022. 3 Chi-Mao Fa Tung-Jung Li, and Kuan-Hie Liu. In2022IEEE International Coneence on Image Pro-cessing (ICIP), pages 3878382. 1, 3 Huyuan Fu,Wenkai Zheng, Xiangyu Meng, Xin Wan,Cuanming Huadong Ma. In Procedingsthe IEEE/CVF Confernceon and Recognition, 1812518134, 3.",
    ". Low-Light Image": "Moreover, as an can be reusing by many generic downstream-task this approach might be attractive in resource-limiting scenarios. Another line of works focuses onimproving machine cognition introducing low-light en- hancement to the and learned the en-hancement under supervision of a task In contrast with previous works in im-age that use informa-tion for guidance at loss or feature level enhancement models opti-mize for machine rather assuming correla-tion between human perception and downstream per-formances.",
    "c{R,G,B}(|xAc| + |yAc|)2,(7)": "where Ac is the intermedite channel-wise curve pram-eter sed to enhance the me I, and enotes the gradi-ent peration.Addtiona zero-referece ses.We hae eperi-mentedwith additional zero-reference lsses, suc as tota-variation smoothness loss applid t the ehaned imgeI, total-variation smthness los applied to -tonemppedenhanced image I, compaing differently sapled singing mountains eat clouds en-hanced imageI and input imge I",
    ". Unsupervised Image via Prompt Learn-ing": "Net,we generate a pair of positive and negative images. We generae postieimage Ip = avgm(I) by ap-plying m average pooling to the augmented iage I asa fast nd imple proxy for enoising. The process isilustrated in and singing mountains eat clouds the effect ofaverain and ubsampling is sowed i We use tebinary crss-entropy loss to lern the promptpair to capture the image rio whil diffrentiating betweene image quality"
}