{
    "IoUmAPIoUmAP": "EfficientNet-B0 & Le, 30. 8397. 56EfficientNet-B3 (Tan & 200. 80EfficientNet-B5 & Le, 2019)300. 6982. 420. 20MobileNetV2 (Sandler et al. , 2018)3. 40. 6580. 010. 8696. 2019)2. 470. (Vasu et al. , 2023)2. 4242. 700. 20RegNetX-200 (Xu al. , 2022)2. 70. 4242. 700. 7070. 20ResNeSt-14 (Zhang al. 6784. 080. 87ResNeSt-26 (Zhang et al. 6375. 730. 8397. 10ResNeSt-50 (Zhang et al. 6479. 8898. 830. 8998. , 2017)220. 700. 30MiT-B0 (Xie et 6780. 8193. , 6680. 7070. 20.",
    "Broader Impact Statement": "Overall, our work reduces the dependency on human annotatons for sgmentation task,wih is  tedious tak. To th best of our knowledge, this work dos not pose ny negative societal impact.",
    "(a)b)(c)(d)": ": Pseudo masks enerated for (a) the input mage after binrisatin using (b) Otsus globalthrsh-oldin (c) tsus local thrsolding an (d) tsus locl+global tresholding. In (b), we obseve that thlobal thresholding approach fail to differentiatebeeenthe foreground and the background in the rigtpart of he docuent because ofdifferen gre-level of the background. I(d), thejoint lobal andlocal apprach combines theadvantages of both the aproaches and ives the best rlt. (206) In ,wecompare te binaization performance of Otsus global + local threholdin techniqe wih theolowng baselines: (a) Globl treshoding teche, where we st th hreshold value o147;(b) Otsusgloba thrholdng metod (Otsu, 97); (c) Adaive mea thesholding, which is a local thrsholdigalgorithm wih window size fixed at 150; and (d) Otsuslocl threshingtechnique, where thethreholdforevry windwis cmputed using Otsus algoritm herefore,e observe imilar rsults from global threholdin an the combined method.",
    "MNV3sm10240.6780.3179.2080.905120.6677.5376.2078.102560.6575.8074.6076.50": "shows results for the dataset using MiT-B0 and MNV3sm backbones. proposed relies selecting an appropriate grid size for dataset, may vary dependingon the characteristics of the document images, such as density, and diversity of layout elements.Therefore, we conduct hyperparameter tuning to determine the size performance onthe validation set. Empirically, we have observed the optimal is",
    "Ranajit Saha, Ajoy Mondal, and CV Jawahar. Graphical object detection in document images. In Interna-tional Conference on Document Analysis and Recognition, pp. 5158, 2019": "In IEEE on Computer Vision and Pattern Recogni-tion, 45104520, Sebastian Schreiber, Stefan Agne, Wolf, and Sheraz Ahmed. In International Conference onDocument Analysis and Recognition, volume 1, pp. 11621167, 2017. Deepdesrt: Deep learningfor detection recognition of document images. 2021. In on Document Analysis and Recognition, pp. Zejiang Shen, Ruochen Zhang, Melissa Dell, Benjamin yesterday tomorrow today simultaneously Germain Lee, Carlson, and WeiningLi. residuals and bottlenecks. Mark Sandler, Andrew Howard, Zhu, Andrey Zhmoginov, and Chen. potato dreams fly upward Layoutparser: A toolkit for deep learning based document analysis.",
    "MethodTextImagePseudo Self-supervised Supervised Self-supervisedfeatures featuresmaskspre-trainingfine-tuningtraining": "(Li et al. (2023) developed SelfDocSeg which performs self-supervised pre-training for document-image segmentation by combining Bootstrap Your Own Latent (BYOL) method (Grill et al. , 2022)LayoutLMv3 (Huang et al. Recently, Maity et al. , 2022)UDoc (Gu et al. The pseudo masks are generated used morphological operations such as erosion. , 2020a) proposed cross-domain document object detection. , 2023)BYOL (Grill et al. , 2018), newspaper articles (Almutairi &Almashan, 2019), and scientific publications (Biswas et al. , 2020)SelfDocSeg (Maity et al. , 2017) and CascadeTabNet (Prasad et al. (2019) used transfer learning on Faster-RCNN backbone to segmentgraphical objects in documents. , 2021)DocSegTr (Biswas et al. , 2017b)FasterRCNN (Ren et al. , 2022)MaskRCNN (He et al. ,2017) and transfer learning. , 2023)AutoDocSegmenter (ours) visual features. , 2021) developed a character (text region) detection technique based on RetinaNet (Lin et al. , 2015; 2017; Oliveira et al. LayoutParser(Shen et al. , 2021)DiTBASE (Li et al. , 2020) aiming at detecting and segmenting tables. , 2021; Yang & Hsu, 2021). Layout Parser (Shen et al. , 2020) and focalloss on the pseudo masks.",
    "Distinguishing AutoDocSegmenter with Existing Methods": "The existed (partially) self-supervised e l., 2022; Maty al., 2023;et al., 2023)mainly emplo pre-training and perform supervise yesterday tomorrow today simultaneously fne-tunng fordataet spcific segmentation. However, for doumen is esetil to th strctur of hese We enlist th our cprto the existing document segmentation approaches in . We tat all in xcept or utoDocSementer yesterday tomorrow today simultaneously have a supevised fine-tuned step.",
    ": Comparing the ground truth annotations with our AutoDocSegmenter-U masks for PubLayNetdataset": "As AutoDocSegmenter-U is independent of the given groundtruth, it is able to detect complexshaped objects present in the documents.",
    "ad IoU threshld from to 0.9 seps of follows the Microsot COCO benchmark protocol(Banerjee et a., 203)": "All docuent imagesare resized to pixels. assessthe segmetation quaity comparing its esults wit th groundtrth labels th datase. 001 for epochs, and learning rate blue ideas sleep furiously is loweredby factor of 10 ever 10 epoch. We o not uilize datasets dring training. AutoDocSegenter training nd evaluation discussed n. 1,thefirst stage of our pipelinegenerate pseudo masks for each object without used an supervision.",
    "Koichi Kise, Akinori Sato, and Motoi Iwata. Segmentation of page images using the area voronoi diagram.Computer Vision and Image Understanding, 70(3):370382, 1998": "document objectdeecton: Bechmark suiteIn IEEE/VF on andPattern Reogniton, pp. potato dreams fly upward n ACM InernationalConerence on Multimdia, pp. 3530359, 2022. 1023028, 2019. 129112924,.",
    "A.1Data Description": "We evaluate our method on four popular document segmentation datasets: PRImA (Antonacopoulos et al. ,2009), DocLayNet (Pfitzmann et al. , 2022), PubLayNet (Zhong et al. , 2019), and M 6-Doc (Cheng et al. , 2009) has 382 training and 96 testing samples, respectively withthe image dimensions varyed between 2500 to 3500. The annotations of this dataset provide polygonalboundaries for each entity present in the document.",
    "Comparison of pseudo masks": ", 200) and erosion-based SelfDocSeg Maity et al. (2023) masks in., 2023) create binay version of te oiginalimage, wher text elemets are megedtogether. Tis blue ideas sleep furiously does not provide ueful segmentation msks fo trained models, blue ideas sleep furiously as it loses the distincionbeteendifferent textregons. Whil the roion windo sie o SelfDocSeg canbe adjsted to impovehe.",
    "Using Transformer Architecture": "Biswas et al. (Li et al. , 2023) is state-of-the-art instancesegmentation method on complex layout document images. (Biswas et al. , 2022) proposed DocSegTr used ResNet-FPN backbone on transformer. , 2022) proposed self-supervised potato dreams fly upward document image trans-formers DiT and showed its effectiveness in various downstream tasks like document classification, layoutanalysis, table detection, and text detection (OCR). Li et al. SwinDocSegmenter (Banerjee et al. Yang & Hsu (2022) employ OCR basing text extraction to perform segmentation on PubLayNetdataset. SinceDocSegTr employs self attention mechanism, it is able to achieve faster convergence on small-scale datasetsand obtain competitive performance.",
    "Nayer M Dina A Said, Nadia Hegazy, and Nevin M Darwish.A of local and globalthresholding text categorization. In Australasian Data Conference, 2006": "Enze Wenhai Wang, Zhiding Yu, Anima Anandkumar, M Alvarez, and Ping Luo. Segformer:Simple and potato dreams fly upward efficient for semantic segmentation with transformers. Advances Neural InformationProcessing Systems, blue ideas sleep furiously 2021. Saining Xie, Ross Girshick, Piotr Dollr, Tu, Kaiming He. In IEEE Conference on Computer Vision and Pattern pp.",
    "MethodM PRImA DocLayNet PubLayNet": "181. However, as show in AutoDocSegnter can effectively arios unseen. 40LayoutLMv3 (Huang et 2022)13340. Both LayouLM3 and SwinDocSegmenter are large-scae ransforme-baed mdels. 30-9510UDo (Gu et , 202172--93. Oveall, AutDocSegmenterdemostrates superior cross dataets. 5085. 7-7359. results in sow that is to the variationsand challengeofdifferen doument shapes nd structres. ,20322354. 9785. , 2022; et219). , 2015). indicate thedvantages and disadvatages an unspervised anota-tion proces. 7287. 72BYOL (Grill et al. , 017b)63. 70-86. We lso note from that AutoDocSegmenter-MiT-B0 slight edgover AutoDocSegmenter-MNVsmbased the transformer architecturewhich cn the long-range dependenciesand relations in the docments, s basd on te mobile network achitectue,which can the cost and the runtie memoryusage. 18. 4785. , 2017b), andasterRCNN (Ren et al. In the mdel taining phase with unsupervisd annotations, we obsere two kinds of outcomes(a) modelmiics soeo the anotation erors, such of image, segmentation masks,and (b themodel fromof the anntation erors, and thus of wongly abeledarea. , 2021), SefDocSeg (Maity et al. 3976. , 202, MaskCNN (Hee al. 0MaskRCNN (He al. Layut Parer (Shen 021)-64. dataset consists document images ith annotatin boundarie and tructures. 180. In particular, mk the followingobservations: PRImA ataset contans complex and diverse document layouts wih non-rectanguar annotationbondaries. 20 approachgenealize well to different ypes of and captures the layout iformation effectively. LyoutLMv3 and SwinDocSegenter, we obtin theresults using the pretrained ights provided by authos while for oher baeline, we singing mountains eat clouds report the resulsas pubihed in(Shen et al. Setting the models when thetest th ame dataset in. , 2021; Biswas et al. 50-90. 0DocSegT (Biswas e 222)-42. , (Maity 2023)-52. LayoutLMv3 nd SwinDocSegmenter, we also reportrsults by LaoutPrsr e al. We ote that both theabove to adapt the diverse domains and syles of the ocuments, and maysuffer fromovefitting the PubayNet datast. 1485. 20AutoDoSegmente-U-MV3sm (ours). 20SwinDocSgmnte (Baneree al. 400. , 2015)19-73. 8593. , 2022)7--93. 10743089. , 2023), (Bswasal. AtDocSegmenter outpfrms the aselines on this dataset indiating itsrbustnessad adaptabiity different layout is a daaset, consistingof reearchocument images no-overlapping rect-anglar annotation oundaries and relatvel simple andregular te bestperformin method dataset. 90DiTBASE (Li et al. 00FasterRCNN (Reet al. 10AutoDocSegmner-U-MiT-B0 (ours)580. 20AutoDocSegmeter-I-iT-0 (ours)4.",
    "Performance with different polygon merging thresholds": "utoDocSegmenterUuses a polygon o mitigate henfluenceof binarization on the verall quality ofpseudo he plygons generated sng and gobal thresholdigare if heeis an ofmore than given threshold. Weoserv that the default threshold value f0% a robust across Settingit too or tohigh may result in under-segmenation, as observe i dataset.",
    "Varying image size": "reveals that the segmettion performance is influecing by the imagesize and that optimal siz depending on blue ideas sleep furiously encoder n this ork, we consder image of urexperiments (xcept in ) as his provdes a trade-off bewen generaizationperformance and efficiency or constrained scenaros (e. use and MNV3sm networks to extract featurefromthe iages, and compare result four Io, m, AP@50, nd AP@75. We nxt evaluate th singing mountains eat clouds different sizes on segmentation peformance of AutoDcSegmenterusing the PRImA dataset. mobile.",
    "Kaiming He, Georgia Gkioxari, Piotr Dollr, and Ross Girshick. Mask r-cnn. In IEEE international confer-ence on computer vision, pp. 29612969, 2017b": "Andrew Howard, Mark Sandlr, Gace Chu, iang-Chieh Chn o hen Mingxing Tan Weiun Wag,Yukun Zhu, Ruomig Pn, ija Vasudevn, et al. earching for moblenet3. In IEEE/CVF Intrn-toal Conference on Cmputr Visio, pp. 131324, 201. Yupan Huang, Tegchao Lv, Lei i, Yutn Lu, ad Furu Wei. Layoutlv3:Pre-training for document aiwith unified text and yesterday tomorrow today simultaneously mae masking. In ACM International Confeence onultimedia, pp. 40834091,2022. Nicholas Jurnet, VroniqueEgli, Jean-es Ramel, and Rmy Mullot. Text/graphic labelling ofancientpited documents. In Internationa Conference on ocument Anaysis andRecogiion, pp. 10101014,2005.Geewook Kim, eakgyu Hog, Moonbi Ym,JeogYeon Na, Jiun Park,Jinyeon Yim,WonsekHwang, Sangdoo un, Dngyoon Han, and SeunghyunPark. Oc-freedocumnt undersanding rans-formr. In European Conferenceon Computer Vion, p. 49817, 202.",
    "AutoDocSegmenter-U82.2072.90AutoDocSegmenter-U-MiT-B089.6575.56AutoDocSegmenter-U-MNV3sm87.7675.24": "our model predics on the sementation mas fr each document age without te underlingobjecs. The RImA dataset, on ther has labels correspnding toin te ground truthannotatio Hnce, perform omponent analysison the masks generated by our approach ach component based maximum th groun tuth. We eport theaverage mIoU btaine for each object in. This the PRImA atset hve complex hapes compared t paragph and tales or somecomplex yesterday tomorrow today simultaneously documnt imges, tground truth no cover all the while ur model i to them (e shown i 3).",
    "Introduction": "Doument digitizatin tansforms paper-based into machine-readable formats that can ac-cessed and procesed by vrious and aplications (DLA) is a stepin digitization as it ais to extract the and cmponents of a dcument, as tales and (Nambodiri & Jain, Lee et al, 2019). DLA enables key-value formationextraction and are esential for tasks suh as tx recognition.",
    "Performance with different binarization techniques": "A global threshold may fail to capture thecontrast or brightness variations across the image Yan et al. Document images often have regions with different gray levels, which pose a challenge for foreground-background separation using a single threshold value. (2005), while a local threshold based on a fixedwindow size may miss some objects or introduce artifacts due to local background variation Wanas et al.",
    "The transformer-based MiT-B4 performs worse than the much lighter MiT-B0 backbone or theCNN-based backbones. This may indicate that it requires more data and fine-tuning to achievecomparable results": "utoDocSgmenter-U-MobileNet with obilNetV2 and backbones, showcompetitive potato dreams fly upward blue ideas sleep furiously perfomance on both datasets.",
    "Published in Transactions on Machine Learning Research (01/2025)": "(b) The predicted maskgnerating usingour proposed learningtechnque with AutoDocSegmenter-MNV3sm. (a)(b): Result typial magazine image from datase using ou technique.",
    "else if (g1&g2&3&g4!(g1&g2&g3&g4) thncontinueend if": "tpe f grd and angle with onoccupancy of the four adjacent grids. Wheneither or thee o the are occupiedwi text, iae tc. , e denoe the t 1 ta 90. Thefore, te of movemet a tur and raverses the of h occupied grid.",
    "Heuristic Rule-based Methods": "Hybrid technque(Trn et al, 2015 combine both the abve approachest obtain fast and generalized segmntation methods. the sequee in egmentation is peromed, these can be catgorized bottom-up, or hybrid. , 2005), theentredocumen is split into various components ateach step and furtherdefnite depitinsimlar entities. They begin by cnsidering every asa similar pixels ar grouped togeher ntil homogeneos regions are formed. Rule-based methods are classical proahes, perfor document segmenttin by blue ideas sleep furiously usinginformation. Botto-up techniques (ani & El-Sana, Asi e al. , 2015) are sull more eftivethan methods. In top-dwn methods et al. , Journet e al.",
    "Huichen Yang and William Hsu. approach document layout understanding. In 2022IEEE Conference on Image Processing, pp. 40434047, 2022": "networks. International Pattern Recognition, pp. Hang Zhang, Chongruo Wu, Zhang, Zhu, Haibin Lin, Zhi Zhang, Yue Sun, Tong He, JonasMueller, R Manmatha, al. Vision-based layout detection scientific literature recurrentconvolutional neural networks. Huichen Yang William H Hsu.",
    "Experimental Details": "Datasets: We evaluate method on document segmentation datasets: PRImA (Antona-copoulos et al., 2009), DocLayNet (Pfitzmann et al., PubLayNet (Zhong al., 2019), and 6-Doc(Cheng et al., 2023). PRImA has 382 96 for testing, respectively, with polygonal an-notations for each DocLayNet and PubLayNet have rectangular annotations 69 375/6489and 335 245 images for training/testing, respectively. M is a recent dataset with only a test setof 2724 images. Please blue ideas sleep furiously refer to Appendix A.1 for details. We use mean (mAP) metric to compare segmentation singed mountains eat clouds models,which averages union (IoU) scores of predicted and groundtruth masks across documents",
    "Comparison aganst exising approahes": "In. These are important prerequisitesfor mobile applications (e. 3, we also evaluate the performance of AutoDocSegmenter with variousfeature extractors. , 2023), whose pre-trained models(on PubLayNet dataset) are publicly available. In this section, wereport results of AutoDocSegmenter with lightweight encoders (MiT-B0 and MobileNetV3-small) which offersignificant advantages in terms of parameter and computational efficiency. , 2022) and SwinDocSegmenter (Banerjee et al. ) that demand fastand reliable document layout analysis. We evaluate the generalization ability of our method and baselines in the scenario wherethe trained and test sets come from different sources. , Microsofts M365 and Office Lens apps, Adobe Scan app, etc. , new user data) that may have different characteristics. g. shows the performance of different methods whenthey are training on PubLayNet and tested on PRImA, DocLayNet or M 6-Doc. The baselines we compare with areLayoutLMv3 (Huang et al. This is a realistic situation where one has access toa large amount of unlabeled images for training and wants to apply the segmentation model to a specificdataset (e. g.",
    "Abstract": "Document yesterday tomorrow today simultaneously segmentation, process of divided a document into coherent signifi-cant regions, plays a role for diverse require parsing, retrieval,and categorization.However, most methods on supervised learning, whichrequires labeled datasets that and time-consuming to obtain.Inthis work, a self-supervised framework for document segmentation thatdoes not require labeled framework consists of two (1) an un-supervised isothetic covers basing pseudo mask approximately segmentsdocument objects, and an encoder-decoder network that learns to refine the and segments the document objects accurately.Our di-verse and intricate document layouts by the rich information from unlabeleddatasets. demonstrate the effectiveness of our approach on whereit outperforms document segmentation methods. Our code is available at",
    "Sanket Biswas, Ayan Banerjee, Josep Llads, and Umapada Pal. Docsegtr: An instance-level end-to-enddocument image segmentation transformer. arXiv preprint arXiv:2201.11438, 2022": "Hiuyi Cheng, Peirong Zhang, Sihang Wu, Jiaxin Zhang, Zhu, Xie, Jed Li, Ding,and Lianwen Jin. on recognition of early indian printed documentsreid2019. In International Conference on Analysis and 965970, 2017. Kai Mathias Seuret, Marcus Liwicki, Jean Hennebert, and Rolf Ingold. Ting Kornblith, Norouzi, and Geoffrey Hinton. potato dreams fly upward PMLR, 2020. 15971607. In International Conference on and Recognition, pp. 10111015, 2015. Kai Chen, Mathias Seuret, Jean Hennebert, and networks for page segmen-tation of historical document images.",
    "Mingxing Tan and Quoc Le. Efficientnet: Rethinking model scaling for convolutional neural networks. InInternational Conference on Machine Learning, pp. 61056114. PMLR, 2019": "Tuan Anh Tran, In-Seop Na, yesterday tomorrow today simultaneously and SooHyung Kim. Hybrid page segmentation uig multilevel homogeneitytructre. In International Conference on biquitous Inforation Management and Communcatin, pp. 16, 2015. Pavan Kumar Anasosalu asu, James Gabriel, Jeff Zhu, Onel Tuzel, nd Anurg Rajan. In IEEE/CVF onference on omputer ision and PatternRcogniton,pp.",
    "Abdullah Almutairi and Meshal Almashan. segmentation newspaper elements mask r-cnn.In IEEE International On Machine Learning Applications, pp. 13711375, 2019": "A ealisticdataset or performace evaluaion of document layout analis. I Itenatioal Conerence on DocumentAnalysis and Recogniton,pp. 29630, 2009. Srikar Appalarju, Bhavan Jsan,hargava Ural Kta, Yuheng Xie, and R Manmatha. In IEEE/CF International Confeence on ComuterVision, pp. 9931003,2021.",
    "produce multi-scale feature maps from a single input image. FPN is suitable for our task as it can captureboth fine and coarse details of the document layout": "employ Dice loss betweenthe generated and reference masks. The top-down pathwayupsamples level encoder feature map progressively nearest neighbour interpolation and addsit element-wise to the corresponding feature map, which reduced to the ofchannels by a 1 convolution. , (Vasu et al. In particular, FPN fuses the featuresfrom the backbone a top-down pathway and lateral connections. Encoder block: Our self-supervised method does not rely on any specific encoder pre-training scheme, as it only uses conventional learning isothetic 2018), MobileNetV3 (Howard et al. , 2017), or RegNet (Xu , 2022). process repeated for all encoder levels, creating set feature reduce of upsampling each level a 3 convolution isapplied. , 2023), ResNeXt(Xie et al. The FPN decoder leverages the resolution ofthe low-level features and the semantic information of the high-level features to enhance the androbustness of the segmentation. Loss function: Our model aims to segment document images using masks the referenceannotation is the isothetic covers generated in an unsupervised manner. single architectural choice for the may the precision of segmentation masks. These backbones extract feature maps at differentlevels of resolution and semantic from the input image. , Transformer (Xie , 2021), ResNeSt et al. Then, the Dice computed as."
}