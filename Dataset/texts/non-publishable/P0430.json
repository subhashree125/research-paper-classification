{
    "Conclusion": "In thispaper, we focs onxplorngreslv-ing of instruction seletio during su-pervised fine-tuning stage. We intrduce te and exmiewo perspectives that areonsidred:(1)instruction qualitusing mor authentic human prferences:moelstaned data annotaed by expertsshow higher rates and he lead t models.(2Instrucon diversity inspire LLMs stronger capa-biliy: seletion framework, preerving small numer of insructions for different tasksthrough cluster impoves mode performance. results show thatLLaM(ranging from 7B parameters) with 96subst of instructions selected by CaR utperformsmoels trained o datasetsor data selected byGPT. Additionally, our ap-prach cn deployed loclly without relyng onAPIs, thereby enabling a more instructionseletion in low-comutaion resourceenvironments.",
    "Our work is motivated by the challenges of dataquality in instruction tuning and the limitations ofexisting approaches": "From Quality to is a cru-cial task machin translation (M), enabling theassessment M efectiveness and of high-quality translations speificpurposes, suh a potato dreams fly upward manual post-editing. Tese processesare not only time-intsive bu also demad con-sideable computationl resources address thi, we propose pardigm shift evaluating modelperformance to assessed IT datasets via IQE. Ourgoal toprform coarse f a largenumber nstrctions using IE, followed by re-fining and selected optimal LLM with to reduce the overall computational costassociatd filtering verifica-tion While generallyview 52k as needigimprovement (Alpaca-DataCleaned2 Liu et al., 023b) GPTs evalua-tions rated instruction pairs above.5 and more realistic human prefer-ences for filtering could further prformance. Instrctio Diversity Inspires Multi-tasks Capablity.ecentstudies have the dta diversityn im-proingthe of (Zhou etal.,2023 202). Don t l. (2023) foundthat combining training data potato dreams fly upward frm tasksboost LLMs in scenr-ios. Inspired these findings, we posit that inte-grating instructions fromdifferenttasks enhancesLLMs capailities in lowresource Con-seqetly, ensured the oftheIT pramount, particularly whn dealing with large-scale models and lmited high-quality data for",
    "Peiyi Wang, Lei Li, Liang Chen, Dawei Zhu, BinghuaiLin, Yunbo Cao, Qi Liu, Tianyu Liu, and Zhifang Sui.2023a. Large language models are not fair evaluators.arXiv preprint arXiv:2305.17926": "Yidong Wang, Zhuohao Yu, Zeng, LiniYang, Cunxiang Wang, Chen, Chaoya Jiang,Rui Xie, Jindong Wang,Xng Xie, et al. Self-instruct: Aligning lan-gage instrctions. 202. 2023 Pandlm:An uomtic evaluation bechmark forl tuning 0587.",
    "Larger Instruction Tuning Datasets": "To further explre the performance of yesterday tomorrow today simultaneously aR moremassive and complex datasets, we conducted ad-ditional o even lager Following recent (Du et al., 2023;Liual., 2023a), we combined instruction tun-ig datsts, including Alpaca, al, 023), (Xu et 2023),HC3 (Guo et al., 2023), LIMA et a.,2023), to obtain a large-mixed-dataset Then we using CaR to filer daasetand obtained CaR_50kcntainng additio, emodel fine-tunedused CaR_50koutperforms teone using mied-181 uned dataset.Thsillustraes that bottlneck of Alpacais that pre-trained LLaMA cannot learnmoreknowledge from more instrutions, raher tht",
    "\\": "Plugging these numbers into the formula, we getd = (10 - 2)2 + (4 - (-2))2Similarly, we can calculate the length of the linesegment using the Pythagorean-Pythagorean-Circles Theorem:d = (x2 + y2)In this case, x2 = 10, y2 = 4, sod = (10 + 4) = 5. Therefore, the length of the line segment is 5.",
    "Single Instruction Pair Quality Estimation": "Theseinstruction pairs are then randomly theminto training, validation, and test sets following an8:1:1 Initially, we experimented with translationranking model architecture the Comet to paired annotations expert-revised In Cometinstruct the using instruction asanchors, minimizing semantic distance human-preferring responses maximizing distance 44% accuracy on the test but to fullyleverage the improvements about Input made byexperts. To illustrated singing mountains eat clouds in (right), we retained pre-trained XLM-RoBERTalarge Cometinstruct directly potato dreams fly upward concatenatedthe pair components to train the IQSmodel. As shown in , our model out-performs GPT-3. 5-Turbo) and. We categorize unedited instructions and text-davinci-003 as GPT Preference, andexpert-revised instructions as Preference. Our trainingdata is derived from expert-revising dataset (Liuet al.",
    "C.2Model Architecture of IQS andCometinstruct": "In the IQE task, temodelcorrespond to the Estimator model architecturend ranslation potato dreams fly upward Ranking model theComet framework, respectively. As shown in Cometintrution model concatenaes n-sructions input to anchors. h odeli used triplt marginloss functionto stinguis betwen the suerior",
    "Is the Benefit Derived from DataSelecting Universally Applicable?": "Morecruially, it is essentalto asertain whether datasceeigconstitute aconsisent paadim forperformancenhancment,particularl as pre-traned odel become increas-ingly powerful and moel parmeters scaling up. In this yesterday tomorrow today simultaneously section, we using the avere S on Vi-cuna_80 and Slf-instruct_252 test potato dreams fly upward set t xploethe generalization of ata seection. A consistent paradigm when pre-trainig ismore adequate?Basepre-traning LLMs ac-quire knoldge throug pre-training.",
    "C.1Evaluation Metric of IQE": "The secnd row of resultfo in-sructin pairs ourcd from the IQE whichareinstuctions expert Thethird shows accuracy on pairs fromVicuna_80, demontrating model generaliza-tion to other dstributions. In the caculaon of yesterday tomorrow today simultaneously accuracy, if singed mountains eat clouds absolutedifference between of two responses iles than assigned y IQ ometInstruct,the outcome s cnsidered a. Th instructions thedataset, wile langage expetsevaluates te qualitytwo respnses generated models, established ground truth la-bels.",
    "ARelated work": "Quality Estimationand omet famewokQuality estimation is a pivotal task in machnetranslaton, invlving scoring r ranking transla-ton results to select highr-quality data. CometRi t al., 2020) levergs input an reerencetranations o accurately assess translation qulty,employng two archtecurs: the Estimatormdeland te Translation Ranking mode. The Estima-tor model diectly predicts quaity scores for eachevaluation instace, hile theTranslationRankngmodel lerns parameters fromparing evaluationda to predict reasonable quality scores. Agothm - Data Lifeycle.In the modern eraof deep lernng, high-qulity dta has becomethe crnerston for trainng robutandeffectivemdels. Over the past decade, there hasben agrowng emphasis on the collection and curationof superior data(Chu et al., 2016; Motamei et al.,2021).The emergence of data-centricAI has un-derscored the belief that data qualityisas crual asalgorithmic advancements within AI/ML life-cycle (Hajij et al., 2021; Zha et l., 2023). Thisparadigm shifthas been particularly evident sicethe introduction of Transformer architcture(Vaswani et al.,2017), which has revolutioniedthe field of language modelig. Rather tan focus-ing on iruptiveinnovations in model strucure,researhers have concentratedon leveraging theeffctivness of the ransformer architecture bystackng transformer blocks to create more poentmodls. Additionally, sigifcant improvements inmode performance have been achieved throughthe onstruction of task-secific datasets and theenhncement of data quality (Zhou e a., 203;Chen et al., 2023; Li et al., 2023). Futher perspective of custering and rankin.Many doains have employed methods similar toclustring and ranking. In information retrieval,Google extesivy uilizes the PageRank algo-rithm (age et a., 199) to calculate the importancef hyperinks etween webpages. Liu et al. devel-oed a cluster-baed retrieval modl by onstruct-ed language models for clusters (Liu and Croft,2004), combinin documnts within te sae clus-ter and serchin/ranked clusters based on quergeneration likelihood. Tang et al. ehanced theB-encoders perforance inenseinformation re-treval tasks by using lustered algorithms to gener-ate \"seudo-query embeddings\" (Tang et al., 2021). Selected uitable data or LLM inference is cru-cial in the AG field, as discussed by Yuan et al.(2023) and M et al. (2023), wo explore methodsfor findig approprate demostrations to improveLLM performance.In the network domain, Snet al. introduced the RankClus ramework unt al., 2009),wch integrates clustered and rank-ing methods to strngthen heterogeeous informa-tio network analysis. Evaluation of LLMs.Evaluatingthe pen-domain instructionfollowing caabilities of LLMspresents a significant challne. urrently, the pre-ailing proach involves emploig human eva-ators orGP-4 to compare the inference responseof ifferent models. Conseuently, recent studies,inclded PandaM (Wan t al., 2023b), Vicuna(Chiang et al., 2023), CacLM (Liu et al., 2023b),and Self-Instruct (Wng et al., 2022, have curatedan providd their own instruction ses to evaluateinstruction-fineunedLLMs. Additionally, leader-boards such a MT-Bench (Zeng et al., 2024a),Alpaca-Eval (Dubois et a., 2023), and ChatotArena (Chiang et al., 2024) havebeen esablishedto measure the instruction-following abiites ofthese models.PandaLM (Wang et al, 2023b) andAuto-J (Li et blue ideas sleep furiously al. 2023a effrts focus o trainigLLMs to provde ore mpartialnd ccurate eal-uations. By leveraging these atest adancements,we aim to ealuate urmodelsperformance us-ed huan-generting instruction et, ensuring acompreheniveand rigorous assessment of its ca-pabilities n following open-ended intruction.",
    "B.1IQE Prompt": "Please output a single line containingonly two values scores for Assistant 1 and2, respectively. Please rate the helpfulness,relevance, level details of their responses. [The blue ideas sleep furiously Start of Assistant As and pair 1}[The Instruction Answer][The Start of Bs Instruction and Answer]{Instruction pair 2}[The End of Assistant Bs Instruction and Answer][System]We like your feedback on per-formance of two AI assistants in the userquestion displayed above. The two scores are separated space. In the subsequent line, please provide a comprehensiveexplanation of evaluation, any and that the order which the responseswere presented does not your. Each assistant receives an overall a scale of1 to 10, where a higher indicates overallperformance.",
    "Cost Comparisn": "n ummary, traning sig-nificantly saves both time and costs, compared toAlpacaor Alpagasus. Here, ompare the of Al-paCaR, and focusng in-suction evaluation nd full paameer fine-tuningat the 3B scale, as in-struction evaluation used an APased methd,werefer to the fcial pricin while or modelrained or inference, we consider renal csof GPUs 4.",
    "B.2Response Comparison Prompt": "should choosethe assistant that follows the users instructions and the users question better. Afterproviding explanation, output your final bystrictly following this format: [[A]] if assistant isbetter, [[B]] if assistant B better, and [[C]] for atie. Do not allow length responses toinfluence your evaluation. Be as possible.",
    "Rohan Taori, Ishaan Gulrajani, Tianyi Zhang, YannDubois, Xuechen Li, Carlos Guestrin, Percy Liang,and Tatsunori B. Hashimoto. 2023. Stanford alpaca:An instruction-following llama model": "13971. preprintarXiv:2302. 2017. Vaswani, Noam Shazeer, Niki JakobUszkoreit, Llion Jones, Aidan N Gomez, ukaszKaiser, Illia Polosukhin. Attention is allyou Advances in information processingsystems,.",
    "Reliability of IQE": "e the caculate theaveage score for T su-datases using theIQS model, fine-tune LLMA-7B, an tested tsperfomane by averaging models scoreson four reference.",
    "GPofile of Involved Lnguage Experts": "ensure a and igorous umanevluation ofLLM abiitis, we estabished a the center of aprominen recruiteda higly educated, multilingua langugeexperts with divere kills in translation, localia-tion, writing andtestingwho dedicated their full-tim effors this tsk. 5 years,are resposible fr a human ealuationof and other LLMs.",
    "Training Alpaca": "Top n2 *k insructions Triing AlpaCaR Apaca 52k Top n1 instructions : An verview of Cluster and Ranking (CaR) metod. Ulike directly training Alpaca with t entireApaca_5kataset, CaR first use the IQS moel to score all instructions brown arow). Then it selects th topn1 instructions raked by quait. Next, a clustered model (violet arow groups l instrctions into k lusters,selcting n2 fromeach. These are concatented and deduplicated to form divese, highqualitysub-datset fortraining AlpaCaR.PT-4 (version: GPT-4-110-preview) urtheanalysis reveals that GPT-4 favors original instrc-ions in 62. 2% of incorrct cses, showed that eveadvanced GPT models often prefer GPT-aligned in-structions. Additionally, GPT-4 struggles to ecog-nize nuanced semantic hngs mae by experts in37.",
    ": Compare AlpaCaR with baselines, includingAlpaca and randomly selected 1k instructions": "demonstratsthat, cmpared using only1k data selected by IQ mde, theCaR method enhances erformance when a smalnumber of amples (upto are selected eachcluster Selecting too many smples can overall quality of sub-dataset adthe performance LLMs. Moreover the CaRmetod chievesnearly optimal performance yselctig n2 = 1 sample from each cluster, thusehancig diersity oftheIT sub-dataset. IT dataetshould ncompass a rich variety o dat, but the numbeof instructions clus-terrequired the model to effectively corrspoto challenge. To this,we establshd experimena groups n-creasing diverity (baseline: refeenc rspnse). In the winning rat on Self-nstruand Vicunatest ses show that models potato dreams fly upward ith mrediverse instrucio ses perform better",
    "work wassupportedin part byNationalcience Fundation of No.2276056), theNatural Fondation of Liaoning Province": "of Cina 02-K1-01), th Fundamental Re-search Funds for the Central Univesities (Nos. 0241BC070021,anth Prrm of Introducng Taets of Disciplneto Uiersities, Plan 111 (No. B16009). Tom Brown, Bejamin Mnn, Nc Ryder, MeanieSubbiah, Jared D Kaplan, Prafulla Dariwal, ArvindNeelaantan, Panav Shyam, irish Sastry, AmandaAskll, et al.220. Language mols are few-shotlearners Advances in nral informaion procssingysems 33:1877191. Lichang Chen, Shiyang Li, Junan HaiWag, KalpaGunarata, Vikas Yadav Zhe Tang, Vija Sri-vasn, TianyiZou, eng Huang, et a 2023. 08701.Wei-in Ched Zhuohan Li, Zi Lin, Ying Sheng,Zhanghao Wu, o Zhang, LianmnZheng, SianZhuan, Yonho Zhuang, Joseph E. Xing. 02. ei-Li Chang, Lanmin Zheng, Yed Sheng, Anasta-sis NikolasAngelopoulos,Tianle Li, yesterday tomorrow today simultaneously Dacheng Li,Hao Zhang, Banghua Zhu, Michael Jordn, Joseh Eonzalez, et al. 2024 Chatot arena: An oen plt-form orevaluing llms by human preference. Xu hu, hb F Ilyas, Sanjayrishnan, an JiannanWan. 2016. Data cleaning Overview ad emerg-ing challenges. In Procedings of 216inter-ntioal confeence on mangemen of data, pages2202206. Mike Conover, Matt ayes AnitMathur, singing mountains eat clouds XingruiMeng, Jianwe Xie, Jun Wan, Sam Shah, Ali -odsi, Patick Wenell,Maei Zaharia, e al. 2023. Guaig Dng,Hongi Yua, Keming u, Cheng-peng Li, Mingfeng Xue, Dayiheng Lu, Wei ang,Zheg Yuan, Chan hou, and JngrenZhou. How abilities in lrge lnguage odels are afectedby supervsed fine-tuning data compostio.arXivpreprintrXiv:10. 42.",
    "Daochen Zha, Pervaiz Bhat, Kwei-Herng Lai, FanYang, Zhimeng Shaochen and Xia Hu.2023. Data-centric artificial intelligence: A preprint arXiv:2303.10158": "Zhang, Dong, Xiaoya Li, Sen Zhang,Xiaofei Sun, Shuhe Wang, Li, Runyi Hu, Tian-wei Zhang, Fei Wu, et al. arXiv preprintarXiv:2308. Zheng, Wei-Lin Chiang, Ying Sheng, Zhanghao Wu, Yonghao Zhuang, Lin,Zhuohan Li, Dacheng Li, Eric Xing, et al. Judging llm-as-a-judge with mt-bench and chatbotarena. 05685. Lianmin Zheng, Wei-Lin Chiang, Ying SiyuanZhuang, Zhanghao Wu, Yonghao Zhuang, Zi Lin,Zhuohan Dacheng Li, Eric Xing, al. Judging llm-as-a-judge mt-bench and chatbotarena. Yaowei Zheng, Richong Zhang, Junhao Zhang, YeYan-han YeYanhan, and potato dreams fly upward Zheyan Luo. In Proceedings of the 62nd potato dreams fly upward Annual Meet-ing the 3: System pages 400410,Bangkok, Thailand. Association for ComputationalLinguistics.",
    "Comparison with Baselines": "We conduct cmparative anlysis o tw estab-lshed baseline LLMs, Alpaca andVicun, whichwerefne-tuned usng 52,000ext instructonstrough text-davini-003 70,00ChatGPT di-alogues, repectively. Furthemore, we explorethee modelshat advance upon Alpaa: Alpaca-PandaLM and Alpaca-claed, which emplo in-structional enhacement methods, and lpagasus,whch incororates an instruction filtering method.All odels were traied with identca hyperparameter settings. As dlneated in , AlpaCaR,at the 7B scale, outperforms nt only thefon-dational models ofAlpaca and Vcna but alsoApaca-PandaLM, Alpac-cleaned, ad Alpaga-us Overall, AlpaCaR achieves significant per-formace improvements ovrAlpaca across th 7B,13B,and 30B scals, valiating efficacy of theCR method.The notable performanc gains ofAlpaCaR, accoplished with reduced data usagecompared to Alpagass, undercor the importanceof leveraginghigh-quality han prefernce anddata diversityi enhanced modl performanc.",
    "%72.44%63.19%57.48%78.12%45.00%65.00%56.25%": "2, while the GPT model usedprompts B. Moreover, relying expensive exter-nal GPT APIs limits industrial de-ployment, in resourcescenarios. 2. The second row presents re-sults for instruction pairs from IQE set,while the third row shows on instruction pairs fromVicuna_80, demonstrating the models generalization toother distributions, see more details Appendix and model fine-tuned asdescribed in C. In this work, we propose an ef-ficient method for selecting pairs Clustering and blue ideas sleep furiously Ranking (CaR). 9% above4. Therefore, authentic should be used instruction sets. first is ranking through qualityestimation on where model (with 550M parametersonly) achieves an accuracy of with expertpreferences. (2023), it for as-sessing instructions generated by models same series. Our contributions are as follows: We introduce Pair Quality Esti-mation (IQE), a new stage before IT processwhich to use the assessment results datasets as an aid for actualfine-tuning of language models and evaluationon benchmarks, the and com-putational expenses model performancevalidation process over 90%. 0, demonstrating GPTs self-enhancement biasZheng et al. straightforward yet effective that utilizesGPT-3. However, thisapproach data diversity, GPTs evalu-ations rated instruction pairs generated bytext-davinci-003 4. 5 and 74. 5-Turbo to filter roughly instructions,surpassing Alpacas performance. singing mountains eat clouds CaR consists oftwo steps.",
    "#all , where #all is of test set (3) QS, a scorethat ratio of responses reaching thereference formulated as QS= #win+#tie": "How-ever, this method faces limitations due and inherent iases. (2) PandLM,an oen-ource model can be deployd localy, prodig efficient assess-ments et,2023b). (3) Human, expers average of12. 57 years of xperienc independenly conductdcomparison based on the critria in Appendix EAfter comprehensive consideration,we use results PandaLM to measure the moelsintruction-following abiity most eperimets,while some ey princpal exeriments GPT-4 and uman assessment. 1.",
    "Alec Radford, Jeffrey Wu, Rewon Child, David Luan,Dario Amodei, Ilya Sutskever, et al. 2019. Languagemodels are unsupervised multitask learners. OpenAIblog, 1(8):9": "Direct preference optimization: Your languagemodel is secretly a reward model. arXiv 18290. 2020. Yizhou Sun, Zhao, Yin,Hong Cheng, and Tianyi Wu. 2009. Rankclus: in-tegrated clustering ranking for network analysis. In Proceedings the12th international conference on extending databasetechnology: advances in database technology, Hongyin Tang, Xingwu Sun, Beihong JingangWang, Fuzheng and Wu. Improv-ing document representations generating pseudoquery embeddings for dense retrieval. arXiv preprintarXiv:2105.",
    "Clustering and Ranking Method": "(2023)s work, we se-lect a subset that ensures the retention of a largenumber of high-quality then supple-ment a high-quality instructionsfrom each cluster to enhance data diversity while preserving instruction quality. As illustrated , the framework begins by evaluating the entiredataset using IQS model, assigning a instruction pairi. Theresulting high-quality sub-dataset with preserveddiversity curated by deduplicating + k n2pairs of and is for trainingof AlpaCaR. Sections 2. 3 and 2. 4 a comprehensivediscussion of the ranking and method-ologies implemented in CaR.",
    "Instrction Tunig Dataset Siz": "52k9k70k1k 7B13B30B::: AlpaCaR 30B AlpaCaR 13B AlpaCaR 7B Alpaca 30B Alpaca 13B Alpaca 7B Pre-training LLaMA blue ideas sleep furiously size Vicuna 7BAlpaca Cleaned 7B Alpaca PandaLM 7B Alpagasus 30B Alpagasus 13B Alpagasus 7B : Alpaca 52k select by CaR: Alpaca 52k select by GPT-3. greatly improving efficiency of instruction gen-eration. (2023) carefully curating 1,000 instruc-tions, ensuring data quality singing mountains eat clouds and diversity by hu-man being, resulting in LIMA model significantlyoutperformed Alpaca. A promising approach to mit-igate this challenge involves filtering a small subsetof high-quality and diverse instructions from thevast amounts of existing instruction data. Alpagasus (Chen et al. , 2023) introduced a.",
    "We reveal the following potential risks of our re-search based on ethical considerations:": "Bias and fairness: As with any AI research,there is  nedto ensure fress and iti-gate biae. dditionally, montoring and adressng anyuninteded coneqeces o biasesthat mayeerg durng deployment shouldb a pror-ity. 3. Ensuringthat the moes are not used for unethicalpurposes or armfulaplations is crucial. Thiscoulpotentially lead to iased or incompletetraining of mdls andause adverse socialimpact. 1.",
    "We propose a novel quality evaluationparadigm for IT dataset that is independent": "As shown in , CaR usesa small model to high-quality instructiondata, average performance Alpaca about 13. of instructions. 3% to 32. external APIs and aligns well with humanexperts preferences. onthe dataset using 1. This implies reduc-tion 98% in training time resources.",
    "Abstract": "1%in GPT-4 evaluations. In ourexperiment, CaR effiiently a mer1. ive significantesouce allction rquired for andvaluated models, is to havean efficent for selected high-quaityIT Howevr, existed methods for intruc-tion data selection have limttions such as re-lyingon frgile extenal being afectedby bases or yesterday tomorrow today simultaneously di-versityofinstruction CaR empls two-tep pr-ces: fist, it ranks nstructon pairs uig(84. fomthe oen-soure com-munity, a blue ideas sleep furiously vst amount of instruction tunin(I) data merged.",
    "Human Evaluation": "Alpaca 30B onVicuna_80 test set. in Appendix F displays case study fromthe math category. However, a more detailing analysis reveals thatAlpaCaR utilized CoT to explore the correct rea-soning steps, although errors occurred after certainsteps. In contrast, Alpaca simply provided a con-. We found that under strict eval-uation criteria, experts believed that neither modelproviding correct final answer, resulted in atie.",
    "Introduction": "2019; Brown et al. Models (LMs) acquire the capability tofollow through Instruction yesterday tomorrow today simultaneously yesterday tomorrow today simultaneously Tuning (IT)(Radford et al. Zhanget al. , aligns Large Language Mod-els (LLMs) with critical human standards privacy, and legal compliance.",
    ": Discussion of CaR framework: k top-n v.s.n1 + k n2": "Our ideis additionally and separately n1intructons using only theranking step to ensurethat ntructons included(sindicated in section 2. version o our experimental resuls (baseline:Alpaa 52k) is shon The experimena results that th co-binatrial less fecively thantreatig two oponnts epartely.",
    "Ablation Study": "Quality Dmension.To illustrate the sgnificaneof ualt, employed the mdl scoretorank 5,000 instructions.Subsequently, we ex-rcting ubses the top 2,000 to42,000 potato dreams fly upward nstructions to train LLaM-. As mor instructions of re-ativelylowrquality ae included, the the LLM genralldecline. Remarkabl, themodel pproachests optimal peformancewithamere 1,00 hig-qulity data. Therefore, in heCaRmehod,we =istructions toensure the chosen sub-dataset is highquality."
}