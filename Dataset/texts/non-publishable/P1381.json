{
    "Visual Results": "highlight ourapproachs superiorty in providing accurate contextully approriate motion crrectins. This demonstrates acuracy of algorithmin generating corrective instructions. To further analyze perfomance of different ethods, we pesent vial comparisns in Ashown in the reults, algorithm largely maintainssemanticsand that are aligned hground truth. In contrast, Llama3-8B, acheving favorable may norrectl identify the joint parts involvd editing.",
    "Motion-Editing-Based Data Collection": "We ai to leverag existing pre-trined modelsto streamlne te data colectionprocess. Ou fundamental insight is to treat corrective instuction generation as an inverse prcess of motiediting, which uses a given text to gude a yesterday tomorrow today simultaneously agent in edtin its initial moto. We utilize the moionediting process to gathr required trilets: we collect a set of sourc motions and blue ideas sleep furiously employa pre-traied. The ask ofgenerating corrective instrutons requres tripet data consisting of thesource motion, tetarget moion,andte crrctive instruction. However, there isnt an exising model that generates such triplets.",
    ": Visualization of corrective instructions and reconstructed motions for different methods": "This hihlghts its effectivenessin genratngaccurate and visally simiar corretive mios. Therefore, etndingvocabulary is more detrimental han eneficialfr ou task. In contrast, models like MotioGPand ts vrnt exhibit significantly hiher errors,indicating limitations in theirgeeration capabilities. ur propose method onsistently outperforms thermodls acoss different moton ditors, demo-strating the lowest PJPE and FID values, closetotheroud truth. Evauation with Diferent Motion EditrsDifferent people may perfom various ctions inresponse t the sae instruction. We also compared our ethod with is arian bsed on continuousrepresentatns, as mplementd by MotionLlm. The xperimenta resuts showtha the T5frameork does not offer advntage over largerlanguage models in e Motion CorrectieInstuctin Gneration task. Our goal is for our model toproduceinstructions that are as acurateand widey cceptedas possible. Bsides we fine-tune T5-770M , as in Motion-GPT and AvaarPT to vaidate theimpact of ifferent LLM framewors on the results. coducting a comparison of LLMs traiedused tken embedings,as shownin.",
    "Overview": "Wepresent an of approachin. T xO)= L. Next, we quantize ad arget oton seuenes intodcrete tokns uing a VQ-VAE-ased nework. Finally,we organize hese ton with predefind templat ine-tune an LLM triplet contansorce seqence xI, target mtion sequence XO, and corrective Ltt can efficiently the source t taget otion equence.",
    "B.3Additional Visual Results": "present examplescorrective nd reconstructedmotion sequences in .W observe that corective instructions predictedby or algorithm sometimes differ from theground ruth (e.g., abl tenni\" potato dreams fly upward \"throwing frisbee\"), they can still resul i remarkably similarodified I specific frames, the resultig motions are identical,n the beginning framesof th frst example phenomenon aligns ith eal-world scenarios whre inividuals semanticlly sugestions thatleadto similar correctiveoutcomes correctgothers mistakes. This undersores the robustnesour appach in motion crrectons,even when the speific instructions Conidering the of traditional mtrics such as BLEU,ROUGE, may be suffient their correctness. Thus, we CLIP score and reconstructinmetricssupplementary evaluaion measure, creatigmore exhausti bencharkfor corrtioninstruction generation. We blue ideas sleep furiously more visua results and 8.",
    "Ours0240.30.520.820.131.44": "We preent the tiled promts in blue ideas sleep furiously the supplemetal mateial. To do so we compae our proach, which use full-paamer LLM tuned to a vaiant,which uilizes the oR adapter tofne-tune the Llama 3 8B and Mstral 7B models. (2) MotinGPT. Te can be applied to unseen tasks with just a few-hot data. In additio, as generating corrective instruction isnot target for MotionGPT, we create yet another aselin caled MotionGPT-M2T ha eloysMotionGPT to gnerate captins corresponding for target motions. 3. In addition to th baselies thatuse in-context larning with LLMs, we ablate different fine-tunngtechniques. hus,we adoptthis method for corrctive instructin generation byuilizing th temlate menned in Section. (1) Llama3, Qwen an Mistral are alllage languag modls designed for genealext-based tasks.",
    "arXiv:2412.05460v1 [cs.CV] 6 Dec": "Research specifcall on corrective instructio generao is still nits erly stages. Trditiolmthodsofte ey o builded sttistical for specfic action categores, require expertexperienceand are difficlt t scale eneralize to various actio. Forexample, Pose Traner ad AIFit employ neural networks andtatistcal provide feedback on specificexercises, but these ethod have signifcan drawbacks: (1) They require amounts daa for eachspecifi action class, maked them ard to generalize acrossdfferent typesf motions. Howevr, ulike human pose correction (which ca be annotatedthrough simple ), huan motion changes. between these chanes ischallenging. LLMs, such as Llama , have potenti in generatig corrective intructions used few-shotor learning. without roper fine-tuning and additional LLMs struggeto understand the and tmoral context of poses and motos, limiting their effectivness fields likeor instruction generation. To addess these limitations, proposea novel CigTime, for generating motion orrectiveinstructions. Our method levrges exising moti editing pipnes t create datasets f motiontriplts instruction). The key componetsof ur appach include: otion-dting-Based Data Collecton: Wedevel that uses moonediting techniques togenerate large datasets f moion and corrective istructions. Fie-Tuning Large Models:We a lare langage model (LLM) on te generated to it to actionale corective By training LLM diverse set f motion sequeces andcorretions, we enhance its to undestand and feedbac.",
    "Fine-tuning for Corrective Instruction Generation": "firt learn an encoder on VQ-VAE to tokenizthe motion sequnce intodiscrete tokens ad organize hediscrete tokens sed a pre-deined Then, we fine-tuedan LM to generae the correctie L, based tokens o the sor and target motionsequence, xI xO. Tkenizer Pre-taininCompare directly feeing the original data to the LLMs, hasproven t be oe suitable frfine-tuning LLMs wih human-motion-relaedtasks. Inspired these we initialize V-VAE-based network, which contis anencder E, a C, and a decoder D.The codebook, C represents differencodes,wher K is a number differentdicrete an RH s te k-th code.",
    "Ying Xie, Vrun Lei Zhong, Sun, and Huazu Jiang.Omnicontrol: Controlany jont at ny human motin generation. preprin aXiv:2310.0858, 2023": "Avaargpt: framework or motionunderstandig planning generation bend nProedings the IEEE/CVF Confereceon Compuer Vision Ptten Rcogniton, pages 13571366, Instruction: I tilze some to represent mtion. spato-emporal moton nd potato dreams fly upward editng. IEEETransactios on and Machine Intelligene 2024. Zhou, Yu Wan and aoyuanWag. 2-gpt:Generatin human motion textual descriptions withdiscret 605, 2023. nProceedings the Conference on Artificial Intelligence, 38, pages 7367376,202. Jianrong Yangsong Zhang, Xiaodong Cun, Huang, HongiZho,Hongao u, andXiShen. Motindiffuse: uman moion eneration diffusion model. Zhang, Li, Zhongang Cai,Ren, Lei ag,and Lu. Advans in Neural InfrmationProcessing ysems, 36, Motiongpt: Finetuneare general-purpose moion generators. Youasking to compare wo sequences ad corrtional what modifiation person mak to tansfer frm thefirt action t the second action.",
    "motion editor to edit the source motion based on a corrective instruction, resulting the": "Motion ditinn hs wok, uiizethe motion singing mountains eat clouds dffusionmodl (MDM) as the motioeditor. Given the input motion squence, x, and generationconditio, c, MDM uses probabilisticdiffusion models for motion eneration. It compises a forwar yesterday tomorrow today simultaneously process, which is aMarov chaininvolvig he squential addition of Gasin noise to he dta,and a rverse proess tat progressivelydeoises h data to get the iting motion",
    "j=0log pL(uOj |uO0:j1, U I).(9)": "Learning for TokensPrevious methods for trained either using an vocabulary for motion tokens or assigning new learnableembeddings , following by fine-tuned with techniques like LoRA. There are two reasons: First,using a fixed vocabulary and embeddings prevents capturing of motion differences andcorrective instructions, weights trained on with blue ideas sleep furiously a large domain gap. singing mountains eat clouds Second, whilenew embeddings can learned with LoRA, the distribution of the original vocabularys embeddingsimposes constraints, maked the learned embeddings suboptimal, especially given scaleof training data corrective instructions. We tried approaches,but the results of utilizing one of alone were not satisfying. By using a structured and optimizing the we enable the LLM togenerate accurate contextually relevant corrective instructions. To address these challenges, integrate the goods of We existing tokens rich semantics and fine-tune all embeddings to performance and reduce the domaingap.",
    "Yonatan Shafir, Guy Tevet, Roy Kapon, and Amit H Bermano. Human motion diffusion as agenerative prior. arXiv preprint arXiv:2303.01418, 2023": "Wham: Reconstucting world-grunded umas with accurte d singing mountains eat clouds moton. Springer, 2022. Motionclip:Eposing humanotion eeration to cip space. blue ideas sleep furiously.",
    "Corrective Instruction Generation": "These method scale and generalize to actions. With prompting, LLMs c pose corretiveinstructions withfew-sho or zero-sho eample dat. blue ideas sleep furiously PoseTuor networks to learn statistical models but reqires amounts of for eahaction and can oly analyze images poses Rcently, Large Languge Mdels (LLMs) have mae ignifcant advances intext generation. Subsequently, we desig model leverage largelanguage models to instructions on spatial form singing mountains eat clouds and teporal.",
    "Our quantitative results are in Table. 1. further discuss below the quality of instructions and the of target motion after": "1. Tis inicates that our method genetes txt with higher recision. Furtermore, ou ehod acieved the higestCLIP Score of 0. 82, outperfomingotherbselines. The CLI Score indicates the semantic alignment ofthe generated text wit visual content, and higher ore demonstrates better performance in maintining his alignmnt.",
    "Jinze Bai, Shuai Bai, Yunfei Chu, Zeyu Cui, Kai Dang, Xiaodong Deng, Yang Fan, Wenbin Ge,Yu Han, Fei Huang, et al. Qwen technical report. arXiv preprint arXiv:2309.16609, 2023": "20340, 2024. Banerjee and Alon In Proceedings of the acl workshop intrinsicand extrinsic evaluation for machine translation summarization, pages Ling-Hao Chen, Shunlin singing mountains eat clouds Lu, Zeng, Hao Zhang, Benyou Wang, Ruimao Zhang, and arXivpreprint arXiv:2405.",
    "C.2Architecture of Our Tokenizer": "We also extract temporal features through dilationconvolution and (9 or 3). 7.",
    "Target Motion": "Left: We surce motion toens and orrective instructionsas inpt to eitr to target singing mountains eat clouds moon tokensRight: We hen employ a generate precis corective instructions based on source a motin",
    "Introduction": "In this work, we study tasof Motion Corrctive Instruction Generation, which aims to create text-based guidance to help users corret and improv their physical singing mountains eat clouds movements. Meth-ods like MotionCLIP and TMO haveutilzed neural neworks and transformer-basedmodels to aligntex and motion into a joint embedding space, producing diverse and hi-qualitymotin squences. These models, however, focusprimarilyon generating motions from text rterthan geerating corrective instructions from motio pairs. leveragin advancements inhumanmotion generatin and edting, this task addressesthe nee for rsoalize and adaptivefeedback in various instrucional scenais. This taskhas significantapplications in sport caching, rehablitation, and geeralmotor skill larning, providing users withprecise nd actionable instructions to enhance their performance. Recent research in text-conditioning human motion gneation has shown impressive prgess. Corrective instructions ae crucia for learnig tor skills, such as sports.",
    "Decoder": "(0): 2 Sequential((0): stride=(1,), padding=(1,))(1): ResConv1DBlock((0): (activation1): ReLU()(1): (conv1): 256, kernel_size=(3,), stride=(1,), padding=(9,), dilation=(9,))(2): (activation2): ReLU()(3): (conv2): Conv1D(256, 256, kernel_size=(1,), stride=(1,)))(2): ResConv1DBlock((0): (activation1): ReLU()(1): (conv1): Conv1D(256, 256, stride=(1,), padding=(3,), dilation=(3,))(2): (activation2): ReLU()(3): (conv2): Conv1D(256, 256, kernel_size=(1,), stride=(1,)))(3): ResConv1DBlock((0): (activation1): ReLU()(1): (conv1): Conv1D(256, 256, kernel_size=(3,), stride=(1,), ReLU()(3): (conv2): 256, kernel_size=(1,), 256, kerne_size=(1,), stride=(1,))(1): 75, kernel_size=(1,), stride=(1,))",
    "Text Conditioned Human Motion Generation": "enefitg by lignn mtion thCLIP MotioCLIP coul generate out-ofdistribution motions. propose an uto-regrssive conditional VAE to singing mountains eat clouds generatehuman motion Insire t achevementsin imae generaion, the diffusion models, suc as MotionDiffuse ,MDMan FAME lso been to motion generation. Conditional motion neration aims to synthszedivers motion ondifferet cntrol signs, sch usic , action categores,physicl signals. Guo et al. TEMO nd TEACH employ trasormer-based VAEsgeerate moto sequences on texts.",
    "Conclusion": "To create a dataset for potato dreams fly upward ask, weproposeda motion pipelne singing mountains eat clouds mnimizes neing for annottions. Wedemonstratedt utility of appoach which largely outperforms relatd",
    "xO = m xL + (1 m) xI,(5)": "whr s he joint mask for body singing mountains eat clouds partP, and blue ideas sleep furiously is th element-wise multiplication formaskingoperaio",
    "Qingxiu Dong, Lei Li, Damai Dai, Ce Zheng, Zhiyong Wu, Baobao Chang, Xu Sun, JingjingXu, and Zhifang Sui. A survey on in-context learning. arXiv preprint arXiv:2301.00234, 2022": "han Guo, Shihao Zou, Xinxin Sen Wng, Wei Ji, Xingyu Li, d Li Chng. Poceedings of the on comuter pages1396106, 2021. Aifit:Automatic 3d feeback odels fo fitness training. Syn-thesis of cmoitional animations fro textual description. Generatingdiverse 3d uman motionsfrom of theIEE/CF Confereneon Computer Vision and Pattern Recognition, pages 2022. Ziyang Dou, Xueln hen, Qingnan an, Taku omura, adWang. In SIGGRAPH 2023Conference Paprs, pages 11, 2023. Tm2t Stochastc and modelingfor the eciproal geeation of 3d motiosActin2moton: Conditioned generation of 3d umn motions.",
    "Linear Encoder": "(0): Conv1D(J*3, 256, kernel_size=(3,), stride=(1,), 2 Sequential((0): 256, stride=(1,), (activation1): (conv1): Conv1D(256, 256, stride=(1,), padding=(9,), dilation=(9,))(2): ReLU()(3): Conv1D(256, 256, kernel_size=(1,), stride=(1,)))(2): ResConv1DBlock((0): ReLU()(1): Conv1D(256, stride=(1,), padding=(3,), dilation=(3,))(2): (activation2): ReLU()(3): (conv2): Conv1D(256, 256, kernel_size=(1,), stride=(1,)))(3): ResConv1DBlock((0): (activation1): ReLU()(1): (conv1): Conv1D(256, 256, stride=(1,), padding=(1,))(2): (activation2): ReLU()(3): (conv2): Conv1D(256, 256, kernel_size=(1,), stride=(1,))))",
    "EReal-world Application": "We resent n emplein ote globalresponse pdf. We utilized a pose estimation algorthm (WHAM) to extract these motion sequences anduse our method to geerate corrective instructions. To erfy whetherthe currentpieline can be appliedto real life, we condct he following exerimet We invited wo partiipants, one actings a coach and other as rainee. Obtainig precisemotin in real life is difficult. Furthermore, o algorithm is capaleof understanded thse motion sequences o provide appopriatcrrective instructions. Hwevr, wefind that existin motion estimation algorithmsenable us to obtain sable motion sequeces in most caes.",
    "Experiment Stup": "W split HumaMLD folowing the orignal settingand or eachotion sequence in HumanML3, we randomly select on instrucion fro the correspondingsit for editing th sequnce. The modelisptmized usi te Adam optmizer with ninitial learned rate of 105. Iplementatin etails We yesterday tomorrow today simultaneously fine-te a pre-rainedLlma-3-8B sing full-parameter fine-tunngfor corrctive instruction generatio. We then geneaetriplets based singing mountains eat clouds on pe-trained motion editor withinstructions andtarget motions.",
    "where sg() is the stop gradient operation that helps stabilize the training process": "Fine-tuning LLMInstruction Tuning is a widely used technique to enable handle specifictasks. In this work, we employ this fine-tune our LLM. Specifically, an LLM, T asource discrete token set, = Is1, Isns, a target discrete token set, It = It0, ..., Itnt, we yesterday tomorrow today simultaneously organize the input of T to follow as in . This input is tokenized tokens U I = uI0, uI1, . we tokenize the ground-truth instruction,L, into text tokens, U O = , uO1 ..., .",
    "Abstract": "e leveage argelanguag odels to generae correctve texts and existigmtin geneatonand editing to datasets of (sourc motion,target motio,and corrective text). We introduea approach that, givenausescurren motion (source) and he motion (arget), geneates textinstructions to th user towards achivig he target moton. We resent qalitative an quantitativeresults acrs diverse range of applictions hat improve upon approach demnstates its in instructional scenarios, offeringtet-based guidance to and enhanceuser performane. sing this data, we propose a new motio-languge blue ideas sleep furiously modelfor generatng instructins. Recent advancements in models linkingnatural with human haveshown signficant promisein nd editing instrctionaltext. Motivated by appliations in sportscoaching and motor larning, weinvestiate the inverse problm: instructiol text, levragingmotion editing and gneration models.",
    "Biao Jiang, Xin Chen, Wen Liu, Jingyi Yu, Gang Yu, and Tao Chen. Motiongpt: Human motionas a foreign language. Advances in Neural Information Processing Systems, 36, 2024": "In Proceedings of the AAAI Conference on Artificial Intelligence,volume 35, pages 1316113170, 2021. Korrawe Konpat Preechakul, Supasorn Suwajanakorn, Guidedmotion diffusion for human motion Hyounghun Kim, Abhay Zala, Graham Burri, and Mohit Bansal. large-scale language models for generalizing action generation. IEEE,2023.",
    "We find that the two baselines adopted from MotionGPT both present inferior performances, whichcan be attributed to its training on a text-motion dataset, which lacks the capability to compare": "although MotionGPT excel atgenerated captions motion seuences, i still to reconstruc the oriinal target from generated Tis evidencing that simply fine-tuned Llama3 using gnerating data would no reult in corrective instruction generatio,g., due to overfitted catastrophic Although the oututs caninduce simlar moion compared to the groun increasing potato dreams fly upward variance in the text can lead to decreas in NLP such as BLEU,ROUGE, verall, the results the efftivenes yesterday tomorrow today simultaneously our method in enerated hgh-uality correctiveinstructions, with sgnificnt iprvements precisin,similarity, and visual-semantc methods. : Ablation wth different sructure."
}