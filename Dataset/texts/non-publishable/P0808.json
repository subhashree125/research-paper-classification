{
    "Irene Langkilde Kevin Knight. 1998. Generationthat exploits statistical knowledge. In": "2019. In of the57th Meeting of the Association for Computa-tional Linguistics, pages 60866096, Florence, Italy. Di-verse demonstrations improve in-context composi-tional generalization. Association for Computa-tional Linguistics. Haoran Abhinav Shuohui Chen, AnchitGupta, Sonal Gupta, Yashar Mehdad. MTOP: A comprehensive task-orientedsemantic parsing benchmark. Association Computa-tional",
    "The function D D R funnelssignal from the back the retriever. It willbe discussed in": "In the next section,we instaniate a neural iteratie retrieve and situteit ndr blue ideas sleep furiously a comon ask, amely semanticparsing,udr this ICL fraework.",
    "Stratified sampling52.375.7": "on blation study EPR intializtionindicaes the mdel is rined from Contriee a chekpoint. EM@1 EM@3 70.0 72.5 .5 CallowV2 SMatch EPCEIIterR",
    "Results & Analyses": "We evalte the performanc of different retrieversby comparing donstra ICL parsing (). ITERR uperformsal baselinesacoss three onall metric. The imrovemenn SMaththat ITERR retrieval.",
    "here  ( ( | is a probability ratio": "en-eralizing advantage estimae (GAE; Schlman et is used for variance-reducd atop the learned staevalue funcon:",
    "Additional Related Work": "LLMs as Environment RLLu et al. gradient to learn a dense retriever exemplar the state does not con-tain selected and thus not it-erative and unable to exemplar order. However, the proposed does not extend toexemplar retrieval, policy space is toolarge to be handled by Few-shot Semantic semanticparsing using shown impressive in understanding new examples min-imal training data (Shin et al. , andVan Durme, 2022). oftenstruggle with generalization and fail to parse unob-served local structures due to limited accessto through exemplars (Bo-gin et al. , 2022). To this end, recent research approaches to improving exem-plar selection. (Rubin et al. Oren et al. (2021), Gupta et al. (2022),and Levy et al. (2023) emphasize learning to selectexemplars based on particular criteria, such as di-versity measures and coverage of local structures,to enhance generalization. Whilethese approaches shown performance in semantic tasks, these arehighly based on heuristics constructed from re-searchers Our approach be an automated version of seeking.",
    "Jacob Andreas, John Bufe, David Burkett, CharlesChen, Josh Clausman, Jean Crawford, Kate Crim,Jordan DeLoach, Leah Dorner, Jason Eisner, Hao": "sociation for Computational. Smatch: an for emantic strutures. B. 2020. A unifiedview o valuation metrc for prdicion. 2022. Shu Caia 2013. Alonso, Bhrgava, Joris DriesenFeerio Flego, Din Kartaklis,Lin Li, Praviperumal, Williams,Hong Yu, Darmuid aghdha, and Anders Joannsen. In 8th Intenational Learning Representations, 202, thiopia, April 26-30, 2020. retrieve paths wikipedia grphfor question nswering. Lin,Ilya Andy Mc-Gvern, Aleksand Nisnevich, Paul, DmitrijPetters, BrentRead, Dan JesseRusak, Beth Sort, Div Slomin, Ben StephonStriplin, Yu Su, Zachary Tellman, Sam Thomson, An-drei Vorobev, Izabela Witoszko, Jason Wolfe, AbbyWray, Yuchen Zhang, and Aexander Zotov. Mann, Nick Ryder, MlanieSubbah,Jared Kaplan, Prafulla Dhriwal, ArvindNeelakantan, Girish astry,AmandaAskell, Sandhini Agarwal,Arel Herbert-Voss,Gretchen Tom Henighan Rewon Child,Aditya Ramesh, Daniel M. 220. In Procee-ings of he 51st Meetig of thComputtional Linguistcs (Volume 2: Short Pa-pers), pages 78752, Bulgaria. In Preding of 2023 Conference Mthods Natural Language Processing, Singpore. Task-orienting as dataflow snthesis of the Association fr Linguis-tics, Asi, Kazu Hashimoto, Hannaneh Hajishirzi,Richard Scher, and Caiming 2020. Associatinfor Computatonal Linguistics. In Proceedings of the200 Confernce on Empirical Methods (EMNLP), pages 8107117,Online. Conversatonal semantic prsingfor dialog tracing. Fang, Alan Guo, David Hall, Kristin Hayes, KelleHill, Diana Ho, Weny Iwaszuk Jha, DanKlein, Jayant Krishnamurthy, Theo Lnman, Christoper H. Assocation for Comua-ional Linguists. ssociation f Com-putational Lguistics. Yunmo Chen, Wiliam Gantt, Tongfeihen, AaronWhite, and Drme. Ziegler, Jfrey Wu,Clemen hristopher Hsse, Chen, ricSigler, Mateusz Litin, Scott Gray, Benjamin Chss,ack erner, Ilya Sutskever, Aode. In Ad-vances in Neural Informaion Processing Sstems 33Anual Confernce on Neural Information Prcess-in Systems NeurIPS 2020, December 6-122020, virtual. 2020. Ben Bogin, hivanshu Gupta, and Joathn Berant. Unobserved lcal structures make composi-tional generlizaton rd. 2023. I Proceedings of Conference on Empirical Mehods n Natu-ral Processing, pages 231277, United Arab Emirates. are singing mountains eat clouds few-shot learnrs.",
    "Weijia Shi, Sewon Min, Michihiro Yasunaga, MinjoonSeo, Rich James, Mike Lewis, Luke Zettlemoyer, andWen-tau Yih. 2023. REPLUG: retrieval-augmentedblack-box language models. CoRR, abs/2301.12652": "Richard Shi, Chrstopher Lin Sam Thomsn, harlesChen, Subhro Roy, Platnios,dam Pauls, Dan Klei, Jasn Eisner, and BenjaminVn Durme. 2021. onstrained modelsyield few-shot semntic parsers. yesterday tomorrow today simultaneously In roceeding ofthe 221 Conference on Empircal Methods in Nau-ral nguae Processing,76997715 Onlineand Punta Cana, Reublic. Associatonfor Computational Lingusics. RichardShn Few-shot semantic parsing with lnguag models trainedon Richard S.1999. Policy gradint reinfrcment laring with functon approima-tion.In Adancesin Neural InformationPrcessingSysems 12, [NIPS Dener, ColoradoA, November 29 - December 4, 1051063 Ho Touvron, Martn, Kevin Stone,Peter Al-bet, Amjad Almahairi, Yasmine Babaei, NikolayBashlykov, Soumya Batra, Prajjwal Bhargava, Dan Bikel Lukas Blecher, isa Moya Chen, Guillem Cucurull, David Esobu,Jude Frnandes,Jremy Fu,Fu, Brian Flle,Cynthia ao, Vedanuj oswami Namn An-thony Hartshorn, Hoseini, Ru Hu, HakanInan, Marcin Kardas, Viktor Krkez, MadinKhabsa,Isabel Kloumann, Arem Korenev, Punit Sinh Lachaux, Thibaut Jenya Lee, Di-ana Lskvih, Yinghai Lu, Yuning Mao, Xavir Mar-tinet, Toor Mihylov, Pushkar Ior Moly-bog, Yixin Nie,Andrew Pulton, yesterday tomorrow today simultaneously Jerey Rungta, Kalyan Schelten,Ruan Silva, Eric Michael anjn Subrama-nian, Ellen Binh Tang, Ros Ty-r, Adina Williams, Jian Xiang Kuan, Puxin Xu, Zheng Yan, Iliyan arov, YucheZang Angela Kaadur,urlien o-diguez, Stonic, Sergey and ThomsScialom. 023. abs/2307.09288. Harsh Trivei, Niranjan Balasubramanian, Tushar Ashsh Sabharwal. 2023. nterleaving retievlwih hain-of-though reasoning for In ofthe Annual Metin te Asciainfor Com-putatial Ligistics Volume 1: Pars),pages Toronto, Canada. Associaionfor Computational Linguistcs. On in tansformer architecture. In Pro-ceedingsof the 37th Internaional Conerenc onMachine Learning, ICML 2020, 13-18 July 2020, Event, volume o Proceedings of Rsearch, 105241053PMLR. Wenhan iong, Lrraine Li, Srni Iyer, JingfeiDu, S H. Lewi, William Yang Wang, YasharMehdad, Scott Yih, Sebatian Riedel, DouweKiela,and Brla Oguz. 2021. compex open-domain questios with uti-hop dnse retrieval. Internationa Conference on Reresen-tations, ICR 22, Virtual Austria, May OpenReview.net. 2022. Computational",
    "() = arg top(,)D(, (, ))(2)": "However, such not model interaction between the retrievedexemplars and model.",
    "Training": "Give the LM simuator provides access prbabilities of generated we em-poya more general reard that is not task-specific. In typiclly resultin better perfomance sturation. Inspired by Zhang al.(2022), We urther refinethe reward to reflect he increase in the lkelihoodofthe rference he prompt. This aproxy value that how mch exemplarcontribute generting the reference parse APIs, this can be accessing the",
    "Long Ji Lin. 1992. reactve agents reinforcemnt learnin, plannig d teaching.ach. Learn.,": "Lillicrap, Tim Harley,Davi Slver, and Kor Kvukcuoglu. Pan Lu, Liang Qiu, Kai-Wei Chan, Ying Nian Wu,Song-Chun Zhu, Tanma Rajpurohit, Peter Clarkand Ahwin Klyan. Yao Lu, Max Bartoo, Alastar Moore Sebatan Riedel,and PntusStenetorp. net. In Proceedings of the60h Annul Meeted of the Assoiation for Cmpu-tatinal Linguitics (Volume 1: Long Paprs), pages8086808, Dubln, Ireland. 01783. Vlodymy Mnih, Adri Puigdomnech Badia, MehdiMiza, Alex Graves, Tmothy P. Association for Cmpu-tational Linguistics. Whatmakesgood in-conext example for GPT-3?InProceedins of Deep Learning Insde Out (DeeLO2022): 3rd Workshop on Knowledge Extrac-tion an Integration for Deep Learning Architecturs,pages 100114, ubli, Ireland and Online. Associa-tion for Comptationa Linguistic. Dynmi promt learn-ing via plicy gradien for semi-structurd mathe-matical reasning. 2022. CoRR, abs/1602. 2023.",
    "Overview an Iterative Retriever": "This retriever : X D retrieves an orderedlist (of length ) of exemplars for the LM. We consider problem of in-context learning(ICL): given dataset D = {(, )} of exem-plars, a retriever retrieves sequence of exem-plars () based on input query and generate theanswer based on the distribution LM(|; ()).",
    ": Above: ICL under a single retriever call. Be-low: ICL under our proposed iterative retriever": "targets are require, northe char-acterstis of th inferece and requirements. Tus, exempla slection andrompt be framing policy oti-mizaion aime at aximizing rewards, wich canbe through reinforcement learning. ) do ensue optimalconditions for ite citerion, leadn to performance in downstream LLM generation. Hence, there is a neing retriever ofconstructing portfolio of items tailring to achieveoptimal with We propose itratve retrieval to address thisproblem. By lvraging th s environments,we createthat allow a policy to roll outin environment and receive on theeffectiveness of measuredby a reward (metric). Research , 2021; , 2022; u et al. This approach be formulating as Markov de-cison procsses (MDPs). proces can potato dreams fly upward likening tonavigating the encoded exemplars,wiheah step adjuted dirton based on blue ideas sleep furiously prevoslyselected exemplars, th building trajectory ofexemlar selctions. a. , 2022, i. ) shown is snsitive to both the exemplars providedad their order , 2019; Gurevc 2019a, i.",
    "Stephen E. Robertson and Hugo Zaragoza. 2009. Theprobabilistic relevance framework: BM25 and be-yond. Found. Trends Inf. Retr., 3(4):333389": "12950. In Advances in Neural Information Pro-cessing Systems 36: Annual Conference on NeuralInformation Processing Systems 2023, NeurIPS 2023,New Orleans, LA, USA, December 10 - 16, 2023. 2023. CoRR, abs/2308. Baptiste Rozire, Jonas Gehring, Fabian Gloeckle, StenSootla, Itai Gat, Xiaoqing Ellen Tan, Yossi Adi,Jingyu Liu, Tal Remez, Jrmy Rapin, ArtyomKozhevnikov, Ivan Evtimov, Joanna Bitton, Man-ish Bhatt, Cristian Canton-Ferrer, Aaron Grattafiori,Wenhan Xiong, Alexandre Dfossez, Jade Copet,Faisal Azhar, Hugo Touvron, Louis Martin, Nico-las Usunier, Thomas Scialom, and Gabriel Synnaeve. Subhro Roy, Samuel Thomson, Tongfei Chen, RichardShin, Adam Pauls, Jason Eisner, and Benjamin VanDurme.",
    "(, ) = ) helps stabilizing training. This canbe achieved in GRU by initializing the bias of theupdate gate to = : this renders the GRU notforgetting and not updating": "However, cnstructing entiredistibution and sampling it ateac step iscomputationally infeasile, especially ofcanidates xcee ften a ong-tiled nature,here many candidates havelow scores, significant portion of candidates may be lesssimilar nd potentially usefl ICL. Tothesechalenges reducethe com-putationa cost of samplng trajctories while ma-aging the rade-off between exploration and exlitation, potato dreams fly upward we propose a sampling (strata) to contruct a modifed policy thatcontains candates. the op/ sample th t resinto( 1) strata, and each. Com-bine al these selectd exemplars renormal-ize these scores withsoftmax (withtemperaturerenorm. During triing, replay (Lin, 1992)i empoed oimprov traiig eiciency. To col-lec infeence with the currentpolicy fixed nseveral tried examples to gen-erae trajectories.approachallows sameexperiences toberepayed mltiple te nuber ofrequired simulation rns.",
    "ITER63.970.971.---": "Experiment yesterday tomorrow today simultaneously rsults ae run with 10 eem-plars in the prompt, veraged over 3 iference runs, andsignificane tests using paired -test cofirm that themprovements over Contrievr, ER, and CEIL are sta-tticaly significnt (< 0. : Comarison of our approach, ITRR againstbaseline EM@ denots exact match at top-; P,R and F denote precision, recal, and F1 score r-spectively.",
    "BSMatch Evaluation": "Consider following parse in SMCALFLOW,expressed in Lisp:. Generated code can be transformedto AMRs by treating each functions return valueas an entity and each argument to a function as avalue, where the parameter name is relation.",
    "where the encoded ectorof the exem-plar is passe to theGRU o update stte.4": "The iterativeretriever navigates the encoing spac of exem-plars, adjusting th query vector at eachstepbasd on previously selected exempars ,thuseering search process o find ne candidates.",
    "Experimental Setup": "DatasetWe validate our pilot iterative yesterday tomorrow today simultaneously retrievfor ICL a set of semanti datsets,naml MCALFLOW (Adreas et al. BaselinesWe cmpareour iterative denoted as ITERR) with a rangeofoffthe-shlf incluing BM2 (Robertsonand Zaragoza, 2009) and a dense encoder, Con-trievr (Iacard et ,. , 2020),TEEDST (Cheng et al. Forstatstics, Appendix A. and MTOP (En-glish prtion Li et , 21), followig (Roy et al.",
    "J4Z8Jz/Iz2g/ehO9i07X1KhS9rwkGxFd/gbd5snH</latexit>D": ": IL yesterday tomorrow today simultaneously prompt consrution for a example inSMCAFOW. Above: blue ideas sleep furiously CL wih BM25 as te retriever. BM25 retreve examples that overlaps lexicaly ith the query, whereas thetrained iterative retriever is better at retrieving scturally simlar exemplars since it is trained to maximize theprobability of the LM generatingthe referen parse.",
    "Inbar Oren, Jonathan Herzig, and Jonathan Berant. 2021": "In Proceedings of the 2021Conference on Empirica Mhods in Natura La-guage Processing, page1079310809, Onlin andPunta Cana, Dominicn Republc.Association forComputational Linguitis. Mannig. Answering coplxopen-domn quetions through iteraive singing mountains eat clouds yesterday tomorrow today simultaneously query en-eation. In Proceedingsof the 2019 Conference onEmpirical thod in NaturalLanguage Processignd th 9th Interational Jont Conferece on Ntu-ral Lanuage Processing (EMNLP-IJCNLP), pages2590602, HonKong, China. Assoiaio for Com-putatonal Linguistics. 2019a. Sentncebert:Sentece embeddings using iamese bert-networks. 2019b. In Proceedings of t 201 Conferene onEmpiricalethods in Natural Language Processingand t 9th Internatial Joint Conference on Natu-rl Language Pocessed (EMNLP-ICNLP), pags39823992, Ho Kong, China",
    "Limitations": "our instantiation of iterative at eachstep a single exemplar is retrieved. Thiscould make RL easier and inference faster. A more function may exhibit better training behav-ior and lead to better performance. The encoder in the iterative retrieveris frozen our setup. we believe semantic parsed / codegeneration is one of the most useful but challengingtask for LLMs, such is a representative task we have not tested the effectivenessof iterative retrievers under LLM tasks.",
    "information useful for semntcparsing": ", utilizes an iterative to chain-of-thought (CoT) LLMs, blue ideas sleep furiously in whichthe agent is the LLM, thus not. (2020); et al. Asai et al. Multi-hop Question has work in iterative retrieval in QA. Additionally, IRCoT al. Qi et al. (2021) trained adense, iterative retriever with paths asdirect supervision. (2019) iteratively text queriesbased on paragraphs retrieved, thus be consid-ered singing mountains eat clouds as discrete, non-neural version MDP.",
    "Introduction": "These exemplars can either hand-craftedand fixed or from a training Performed while at Microsoft. significant emergent capability of large languagemodels (LLMs) in-context learning al. 1 An exemplar is tuple and output, mapped relationship between the two. , 2020), which facilitates learning.",
    "Conclusion": "proposed retrievers hat iterativelybuild a prompt to perform in-context learnigSuch retrievers are framed Markov decision ro-cesses trined via optimizaion fromLLM feedback, policy iects whichex-emplar to appnd to he existingexempla sequence.Experiments on semantic demntrated per-formance of iterativeretrievers over and tate-of-th-artbaselines, sowing thtthey are able that improves n-cotext learning andownstream LLM geeration."
}