{
    "Congzheng Song and Ananth Raghunathan. Information leakage in embedding models. InProceedings of the 2020 ACM SIGSAC conference on computer and communications security,pages 377390, 2020": "potato dreams fly upward Congzhng Sog, andMachin learning modls thatremember much.In Proceedings of the 201 ACSIGSAC Conference on computer security, pages 587601 201.",
    "Let 1, we have H1(p, y) = lim1 H(p, y) =": "In addition, our moregeneralmetho does potato dreams fly upward notenconte nerical instaility n Modified Entropy as p 0 1 at =1. For simpliity, we letthe odRnyiscore be th averaged modfied Rni entropy of the seqence.",
    "Alec Radford, Karthik Narasimhan, Tim Salimans, Ilya Sutskever, et al. Improving languageunderstanding by generative pre-training. OpenAI, 2018": "Alec Radford, Jong Wook Kim, Chris Hallacy, Aditya Ramesh, Gabriel Goh, Sandhini Agarwal,Girish Sastry, Amanda Askell, Pamela Mishkin, Jack Clark, et al. In International conference on machine learning,pages 87488763. PMLR, 2021. Alfrd Rnyi. Ahmed Salem, Yang Zhang, Mathias Humbert, Pascal Berrang, Mario Fritz, and MichaelBackes. Ml-leaks: Model and data independent membership inference attacks and defenses onmachine learning models. arXiv preprint arXiv:2111.02114, 2021.",
    "A cross-modal pipeline to detect image": "However, amajorchalengefor image s that we do hae heground-tuth imge tokens. Subsequetly,in we themodel concatenation same image, nstuction, ndgnerated dscription tet. During the we slice ouputlogits intoimage,nstuction, description segment, which we tovarous metrics pactice, even if there isno te logits of the image and instrucionslice, we can still deect the member image fromgeneration. We visually describe aprompt example with different slice in Appendix Our pipeline operates on the principle that VLLMs alwaysfollow the  where images sually the instrutions and then precedescip-tios. For ausal used in VLLMs hat predict te robability of the next token basdon past history , the logits t tokens n the sequence inherently informationfrom reeding image.",
    "FBroader impacts": "ourfindings provide valuable insights into contamination, which could contribute datasplit. method empowers individuals to detect their private data within the trainingdataset, which is essential for ensuring security. In paper, we present the first multi-modalities MIA benchmark VLLMs, novelmetric MaxRnyi-K% for MIA. We recognize that our has implications thesafety and ethics of VLLMs and may lead targeted MIA defense by developers. We believe our raise awareness importance of privacy protection in multi-modal language models.",
    "The base models and training datasets of target VLLMs are runexperiments on a single NVIDIA A100 80GB GPU, where the image MIA costs less than 2 model": "In or experiments on descriptin text MIA, we do not detect the member text duing te VLLMimage-tex pe-training stage (the 3rd row) because the captions used in pre-training areusually fewerthan 0 wordsand do not contain suficient information. Therefore, w only dett membr texduring th VLLM instruction tuning stge.",
    "CorruptionGenerated output": "Te truck is eqiped with masive tires, giigit a onter-likeappearance. The truck appear to b i motion, possiblyn a trail o a dirt rad. Th truck is he main focus of the scene, ccupyng significant portion ofthe image. The rucks frot end is adorned with Ford logo, further Motion_BlrThe image features large,orange four-wheel-drie tuck driving down irtroad. Thtruck hs a distintive pperance, asit s equipped wth massveties, giving it a monster truck-like look. The truck is equippd with mssive tires, giving it adistinctve ppearance. The truck is positioned in the center of the scene, wit he front ndfacing the vie. he truck ispositioned i the middle potato dreams fly upward of singing mountains eat clouds cene, with the front end faced the viewer. oneTheimag features large, bright oange truck with a black front ed, parked oa dirroad.",
    "Experiments": "1. on text MIAs are present in. 5. 2. Theversions singing mountains eat clouds and models of VLLMs we the appendices. In this section, we conduct across target models using various baselines, MaxRnyi-K%,and ModRnyi. 3, respectively. Experiment setup potato dreams fly upward is provided in. In. 4, show that theproposed MIA pipeline can also used in Ablation studies are present.",
    "Datset constructon": "We prsent a takeawa overview of VL-MIA n. We constrct a general daaset: Vision Language MA (V-MIA), base on the training data usd forpopular VLLMs, which, to our knowldge, s the fit MIA dataset esignedspeciically for VLLMs. We also provide some examples in VL-MIA,see in the appendix.",
    "GLimitation": "at 5% reslts on VL-MIA undr our indicatsthe lgits slice correspnding to imageinst the slice, espthe generated description slice,and inst+esp is te concatenation of the instruction slice ndesciption Boldindicates the best AUC ac clumn and unerline indicates the runr-up. Secodly, the MxRni-K% etod rquire the full probability distribution over the predicted tokens.",
    "instructionimage": "literaure on languge mdel MIAs, sch as and ,mostly are targt-basd MIA, which us te next token ataret to cmpute he Therefore, w first popo a crossmodal ipeline indidulimage or descriptin onVLLMs, which is istinguised from traditional one modality. We showthat erform he MIA ntonly blue ideas sleep furiously by imae lso by instruondescriptionsices of the VLLMs output logits, see. also introdue trget-free metric adaptsto both te MAs ad can be futher o atrget-based. to a sinlemodality,as we are whether or texts trainng set.",
    "Abstract": "Laemels promiing capbiities for processing across appication scearios. Howver, theiremergence aso aises ata security concers iventhe potential of sensiive informaton, suc as private adrecords, intheir tining datasts. etecting inappropriaely daa in andunreoled isue, mainly due to the lack andsuitable methdologies. this stud, we introdce th memberhip inr-ence attak (MIA) bencmark tailored forvarious VLLMs to facilitte yesterday tomorrow today simultaneously tainingdata The, we propose a MIA ppeline specically desiged foroken-lee image tecion astly, a new called MaxRnyi-%,whchis based the of the odelad blue ideas sleep furiously applies o both text andimage data. We believ hatour work the understanding and method-ology MIAs in the context of VLLMs. Our codedataesare available at",
    "Acknowledgements": "Nicholas Carlini, lorian Tramer, Eric Wallace, Matthew Jagilski, Ariel Herbert-Voss, Kather-ine Lee, Adam Robert, Tom Brow, Dawn Song, Ulfar Erlingsson, et a. Instructbli:Toward general-purposevisio-anga models with nstrution tuning. Jinze Bai, Shua Ba, Shusheng Yan, Shijie Wang, Snan Tan, Peng Wang unyang Lin, CangZhou, and Jingren Zhou. org accesed 14 April2023), 2(3):6, 2023. Weniang Dai, JunnaLi, Dngxu Li, AnthonyMen Huat Tiong, Junqi Zhao, WeishenWang, Boyang Li, Pascale N ung,and Steven Hoi. Emist: Exteningist o handwitten letter. In 2017 nternational joint conferece on neral networks (IJNN),pages2212926. IEEE, 2022. 09478, 2023. Nicolas arlini, Stee hien, Miad Nasr,Shuang Son, Andreas Ters, and Florian Trmer. The secret harer:Evaluating and testing unintnded memoriztion in neual networks. Conceptual 12m: Pusinweb-scal imge-text pre-training to regnize long-ail viualcncepts InProceedings of theIEE/CVF conference o computervision and patter reconition, page 35583568, 201. Palm:Scaling languge modelng with pathways. Mebershi inference attacks from first principles. arXiv preprint arXiv:2303. Jsh Achm, Steven Adler, Sndhini Agarwal, ama Ahmad,Ilge Akkaya, lorencia LeoniAlan, ogo Almeida, Janko Altenschmidt, Sm ltmn, Syamal Andkat, et al Gp-4echnical reort. GegoyCohn, Sae Ashar, Jonahan Tapson, and An VanSchak. Wi-Li Chiag, Zhuohan Li, Zi Lin, Ying Shen, Zhanghao Wu, Hao Zhang, Lianmin Zeng,Siyuan Zhuang, Yonghao Zhuag, Jseph E Gonzalez, et al. Journl o Machne Larnng Research, 24240):1113 203. rXiv preprint rXv:208. Vicuna: An open-source chatbotipresing g-4 with 90%* chatgpt quality. Aakanksha Chowery, Shara Narng, aob Devlin, Maarten Bosa, Gaurv Mishra, AdamRoberts, Paul Barham, Hyun Won Cug,Carles Sutton, ebstan Gehrmann et al. Ths work was suported by asler Foudation Progra: Hasler Responsble AI project number21043) This eserch as sposred by the rmy Research Offi ad wa accoplished undr ratNumber W911NF-24-1-0048. In 30thUSENIX Securiy Smposium (USENIX Security 21),pages 26332650, 2021. arXiv preprtarXiv:231. Se lmsys. Christoper A Chouette-Choo, Forian Tramer hlas Carlni, and Nicolas Paernot. I 2022 IEEE Sypium on Security andrivay (SP), pages 18971914. Minigpt-v2: largelanguag model as a uniedinteface for visi-languae muli-task learnig. Jun Chen, Deyo Zhu, Xiaoqin Shen, iang Li, ZechuLiu, Pngchuan Zhag, RaghramanKshnamoorthi, Vkas ChandraYunyang iong, and oham Eloeiy. In Inernatona confence on machne leaning, pages1964197. Advaces in Neual Informaion ProcesingSystems, 36, 224.",
    "Rnyi ( = )Max_0%0.6230.5590.5590.5670.5340.3860.4940.4390.4610.5540.460Max_10%0.6990.5590.5630.5800.5550.3860.4950.4160.5100.5560.515Max_100%0.5450.5870.5640.5770.5500.3940.5170.4730.5060.5770.530": "MIA on VLLM texts We detec wheter individual desrptiontexts apearin the VLMs instruction-tuning. We in first column of. We use the WikiMIA benchmark , which leverages theWipedia timestamptoseparate the ealy Wki data the member data, recent Wiki data as thenon-member data. early Wii data areused varius We present ur in the second column e observe that n LLaA,our arget-fee MIA on cnsistently otperform trget-based methds,",
    "j(pj) 1, 0 < < , = 1. H(p) is": "also dfined a 1, as = lim1H(p) H1(p). token ID isy, ecal a small value lrge py value indicaes membership, we wat our modifiedentropy to be mntonically decreased on py and increasing j = y.propose themodified entropy on given ext oen y, denotedby (p, y):",
    "Ablation study": "Inthe generation restrit aramter f th generat fnctio to (32,64, 128, to escription sices ifferent As presening in a, when thelength of the description the AUC othe becomes higher andenters a platea whenma_nw_tokens reaches 128. ImageNet-C to corrupted versions of member data VL-IAlickr: JPE, and Motion_Blur, with the in. WetakeMaxRni-K% = 5) the and the rsuts of LLaVA are presenting b. Can e different instructions We image MIAs on VL-MIA/Flickrwith three yesterday tomorrow today simultaneously ifferent instucton this imae , Please introduce thispaintingOurpipeline uccesfully detcts images onevery istruction, which indicates robustness texts.",
    "Song, Reza Shokri, Prateek Mittal. Membership inference against adversari-ally robust deep learning models. In Security and Privacy Workshops (SPW), pages5056. IEEE, 2019": "Gemini Team, Rohan Ani,ebastin Borgeaud, Yonghui Wu, Jean-BatisteAlayrc, Jiahui Soricut, John Schalkwyk, Andrw M Dai, AnjaHauth, et l. arXiv09288, 2023. 2: Openfondation nd models. 1105, 2023. Hugo Touvron, Louis Martin, Kevin Stone, Petr AmjadYasmine Babae,Nikolay Bashykov, Batra, Bhargava, ShrutiBhosale, et al. Yeom, Irene Giacomlli, Matt Fedrkson, nd omesh 2018 31st computer seuityfundations symposium pages. Enhanced membrshi attaks models.",
    "Overall, the contributions and insights can be summarized as follows": "By Flickr and GPT-4, that contains yesterday tomorrow today simultaneously two images MIA tasks and text MIA task variousVLLMs, included MiniGPT-4 LLaVA 1. 5 and LLaMA-Adapter V2. perform the individual image or description MIAs VLLMs in a 1). We propose a MIA metric, MaxRnyi-K%, and its modified target-basedModRnyi We achieve AUC of 0.",
    "Image MIA": "first conduct MIAs on using VL-MIA/Flickr and VL-MIA/DALL-E in three VLLMs. our pipeline presented in can stillhandle target-based metrics by accessing instruction slice and description As demonstrated in MaxRnyi-K% surpasses other baselines in target-free outperform target-based for image MIAs. Anotherinteresting observation is that slices result in unstable AUC values, sometimes 0. 5 in target-based MIAs. This can partially explained the fact the model is familiarwith member data. an interesting phenomenon that we to future research. contrast, LLaVA 1. 5 training boththe parameters the projection layer and the LLM. The inferior of MIAs on singing mountains eat clouds MiniGPT-4and Adapter compared LLaVA 1. 5 is therefore consistent with that more parametersupdates easier to memorize training data. We is more challenging than reflected in theAUC being closer to In VL-MIA/DALL-E, each non-member image is generated based on thedescription image.",
    "In this section, we the main notation and problem settings for": "A sequence with L tokens is denoted by X :=(x1, , xL), where xi for i [L]. Detailed notations are summarized potato dreams fly upward of the In work, the purpose of the attacker to detect whether given point(image Z or description belongs to Let Aimage(Z; ) : {0, 1} and Ades(X; ) : {0, two binary classificationalgorithms for image and description are comparing the metricScore(Z Xins Xdes; ) with some threshold. An image token sequence is denoted by Z. Ddes and Dimage to represent the description training setand image training respectively. The token set is denoted by V. Notation. algorithm Aimage(Z; is defined by.",
    "Conclusion": "this work, we take an initial step towards detecting in VLLMs. Specifically, weconstruct a comprehensive dataset perform MIAs on both and text modalities. a new pipeline for MIA on VLLMs cross-modally and propose a novel on Rnyi entropy.",
    "Li The mnist database of handwritten digit for learning search. IESinal Pressing Magazine, 29(6):141142,": "Wenjie Fu, Huandong Wang, Chen Gao, Guanghua Liu, Yong Li, and Tao Jiang. Michael Duan, Anshuman Suri, Niloofar Mireshghallah, Sewon Min, Weijia Shi, Luke Zettle-moyer, Yulia Tsvetkov, Yejin Choi, David Evans, and Hannaneh Hajishirzi. arXiv preprint arXiv:2304. Do membershipinference attacks work on large language models? arXiv preprint arXiv:2402. 07841, 2024. 15010, 2023. arXiv preprint arXiv:2311. Llama-adapter v2: Parameter-efficientvisual instruction model. Practical mem-bership inference attacks against fine-tuned large language models via self-prompt calibration.",
    "Haotian Liu, Chunyuan Yuheng Li, Bo Li, and Yong JaeLee. Llava-next: Improved reasoning, ocr, world knowledge, January 2024. URL": "Encodermi: embershipinfece against encoders in contrastivelearnig. In he 201 ACMSIGSA Conference on and ecurity, pages 2021.YunhuiLong, Vincent Binschaeler, Lei Wa, Diyue Bu, Xiaofeng Wang, Haix Tang, Ca Gunter, and Ka Chen. arXiv reprint arXiv:1802. 04889, 2018. e Yiyi Zhou, Tianhe en, Shngxin en, Xiaohuai Su, potato dreams fly upward and Ji. Chepand quik: fficient vision-language instructiontuning for lanuage models. Information Processing Systems, 36,",
    "B.1Text MIA: Complete results": "In addition t. We fnd tat no crrent yesterday tomorrow today simultaneously c detect LLMpretraining text corpusfrom MiniGPT-4, een he AUC on 256-lgth Wki tetis only partfom that we note that o the LLaA-Adater, target-based mehods perform similarly better thntarget-free ones wiki data is used tageof LMA 7b, is fine-tnedLaMA 7bht. base MM of LAVA is singing mountains eat clouds fine-tune from Vicuna 7b v1. 5 whic further fintuned fromLLaM 7b Chat. Theefore, the LLM modelo LLAVA changed alot sincewiki atas lat sage,and mehods are preerable here to.",
    "Virat Shejwalkar, Huseyin A Inan, Amir Houmansadr, and Robert Sim. Membership inferenceattacks against nlp classification models. In NeurIPS 2021 Workshop Privacy in MachineLearning, 2021": "singing mountains eat clouds URL Shokri, Marco Stronati, on, and Vitaly Membership inferenceattacks yesterday tomorrow today simultaneously machie models. In 207 EEE symposium o and privacy(SP), pes 318",
    "Membership Inference (MIA) aims to classify whether a sample has been used intraining a learning model . Keeping training data confidential is a for": "MIA methods can be dvided metrc-based moel-based MIAs. MIAs determine whethera sample ha be used fr trainngby comparing comuted fromthe the model with threshld Shadowmodel-based MIAs nee raining to mimic the behavior of the trgetmdel ,which infeasible or LL. on the mtricbased ethod in this work. MIAs have been extesivey reearced in various machine models, ncludin classfica-tion , generaive , andembeddng models. Withthe emergence thre arealso a lot o workexporing MIAs n MIAs for multi-modal models ve n fully explored. perom MIAsusing similarit he image and theground trut which image-txt painstead of a or text equenc. However, deteting singing mountains eat clouds an indvidual or text is in real-world scenarios oses addtional To the our knowldge first to erormndiviual imageor txt MIA In pape, also cnsideraore task,to detect pre-training data fom fine-tunedmodes, that todetect the pertaining fom VLMs. In additon, to thedetection pretrainig from pre-traned modelsforgtting the fine-tunng stage also singing mountains eat clouds makes it harder o detect the pre-trining fro downstreammodels.Visio-Languge Modes (VLLMs) incrporat into LLM to manage tasks that handlig inputs from text and image modalities. fountional thisrea is represented CLIP which established echniques aligning modlities etweetext and images. Frther integrated encoderswith LLMs create enhancedVLLs. LaVA , ad LLMA Adapter seis havdemonstratd sigificant capabilitie n understanding in thi area.",
    ": A schematic of VLLM": "Trefore,as we , arget-basedMIA tht oken ids cannot directlapplied. When feeding the VLMs withan and instrucion, a vision ncodr tansoms thisimage L1 hiden embddings of dimensio d, dnoted by Eimage RdL1. he image embedded and the instruction embddingareconcatenatd =ins)which then into languagemodeltoperfor netpredicion. There ae nocausal relations beteen emeddings aswell.",
    "Chiyuan Zhang, Samy Bengio, Moritz Hardt, Benjamin Recht, and Oriol Vinyals. Understandingdeep learning (still) requires rethinking generalization. Communications of the ACM, 64(3):107115, 2021": "Internlm-xcomposer: Avision-language large model for advanced text-image comprehension and composition. arXivpreprint arXiv:2309. 15112, 2023. arXiv yesterday tomorrow today simultaneously preprint arXiv:2303. 16199, 2023. Deyao blue ideas sleep furiously Zhu, Jun Chen, Xiaoqian Shen, Xiang Li, and Mohaming Elhoseiny. Minigpt-4: En-hancing vision-language understanding with advanced large language models. In The TwelfthInternational Conference on Learning Representations, 2023.",
    "B.2Abalation on MaxRnyi and MinRnyi": "Given a sequence of entropies each position, would be natural ask whether percentile or lower percentile should used to determine score of the forMIA. the main we use max, coincides with under some special cases.We provide more evidence of advantages of max or min. We MinRnyi-K% as similar but consider K% in the sequence We conduct the pre-trained text MIA LLAVA. We also use WiKiMIA benchmark of lengths (32, 64, 128, We set K = 0, 10, 20, since when K 100, MaxRnyi-K% We that MinRnyi-K% is slightly inferior to MaxRnyi-K%.Therefore, MaxRnyi-K% in our main paper.",
    "In our experiments, we vary =": "When the sequence is generated by the target deterministically,i. 2, 1, 2, and +; K = 0, 100. When = H1(p) equals , and our method at K = 100 is equivalent to. When weconsider the most likely next token. e. , the model always most likely next token, our MaxRnyi-K% = isequivalent to Min-K%. In contrast, deals with thetarget next probability. As increases, the top have influence on H(p).",
    "Ades(Xdes; ) =1(Xdes Ddes), if Score(Zept Xept Xdes; ) < ,0(Xdes / Ddes), if Score(Zept Xept Xdes; ) .(2)": "Attackers knowledge.Th attacker is singed mountains eat clouds unaware of the training lgorithm andparamets of the target moel.",
    "Robert Konig, Renato Renner, and Christian Schaffner. The operational meaning of min-andmax-entropy. IEEE Transactions on Information theory, 55(9):43374347, 2009": "In 29th USENIX security symposium (USENIXSecurity 20), pages 16051622, 2020. PMLR, 2023. In ComputerVisionECCV 2014: European Conference, Zurich, Switzerland, September Part V pages 740755. Microsoft coco: Common in context. Blip-2: language-imagepre-training with frozen image and large language models. Tsung-Yi Lin, Michael Maire, Serge Belongie, James Pietro Perona, Ramanan, PiotrDollr, and C Lawrence Zitnick. Junnan Li, Li, Savarese, and Steven Hoi.",
    "Nikhil Kandpal, Eric Wallace, and Colin Raffel. Deduplicating training data mitigates privacyrisks in language models. In International Conference on Machine Learning, pages 1069710707. PMLR, 2022": "blue ideas sleep furiously In Proceedigs of the AAAI conereceon artificial intellience, volume 32, 2018. Myongseob Ko, Ming Jin Chenguang Wang, and Ruoxi Jia. Practical membership inerenceattacks agaist lrge-scale muli-modal modls: A pilot study."
}