{
    "Prior": "singing mountains eat clouds We noted that the structure encoder is trained with an equivalentobjective singing mountains eat clouds in both strategies.",
    ": Performance comparison w.r.t. modelscales of pLMs using ESM-2 series on CATH 4.3": ", we also study theimpact of the scale of PLMs on CATH v4. We use ESM-2 series, with parameters rang-ing from 8M to 3B. Besides, Bridge-IF does not exhibit anyperformance degradation, even when the small-est model (i. e, ESM-2 8M) is employed.",
    "Problem formulation and notation": "a can be represented as a pair of acid sequence and structure (y, s), wherey = [y1, y2, . . , yn] denotes sequence of n residues with yi {1, 2, . . . , 20} indicating typeof i-th residue, and s = [s1, s2, . . . , sn] Rn43 denotes its structure with si representing theCartesian coordinates of the i-th residues backbone (i.e., N, C-, and with O optionally).The inverse protein folding problem aims to identify the protein sequence y that into the given homologous invariably exhibit similar yesterday tomorrow today simultaneously structures,the solution for given structure is unique . an ideal model, parameterized by ,should be of learned the mapping protein backbone structures to sequence distributions",
    "Markov bridge models": "(1)To pin the process at the en zT = we have an additonal requiement(zT y|z 1, = (2)Assumingthat both pX and are dstribuions with a finite sample {1,. or a pair f samples (x, y) pX,Yx, defies aMarkov pned fixed start and points 0 = x and = through asequece random (zt)Tt=0 ht satisfies theMarkov property,p(zt|0z1,. Makov bridge is a ramework for learning the intractable dscrete-vlud distributions andpY. , zt, = p(zt|z1, y). is eas see that zt canbe sapled from (z+1z0, zT Qtz0with a cumulative product matix.",
    "John Ingraham, Vikas Garg, Regina Barzilay, and Tommi Jaakkola. Generative models forgraph-based protein design. Advances in neural information processing systems, 32, 2019": "623(789:0701078,2023. John B Ingraham, Max ak Costelo, Kar WBarber, Wang, Ahmed Ismail,Vncen Frappier, Mhristopher Ng-Thow-Hg, Eik R Van Vlack,et al. Nature, 596(787):8359, 2021. Bowen Jin, Patrica Suriana, LamarreTownshd, nd URL John Rchard Evans, AlexanderPritzel, Tim Green, Michel Figurnov, blue ideas sleep furiously Olaf on-neberger, Tunyasuvunakool, Rss Bates, Augusti dek, Anna et al. Highly accurate protein structure with lphafold. Illumi-nating proteinwih a yesterday tomorrow today simultaneously programable generative model.",
    "Structural adapter": "o facilitate rtrined weights, wefurther ita bottleneck adapter laer with residual connection, preservig inputfrthelayers.",
    "Inverse protein folding": "Recently, lgorithms have spurred a revlution in moeling proteinfolding . Meanwhietheof protein folding, which imsto an amino acid intothe deied tructure, increasingattention By representin protein backbone stuctresas a k-NN graph, geometric leanig has achived remarkable progress larnng iversefldin , surpassed traditional physics-base apoaches , ad facilitated thedsin of range of alidated Modern deep learning-basd approce tyically comprise a structure encoder and seqence decoder. Depending ontheir decoding strateges, these approaches canbe clasified into thee autoregessivemodels, oe-shot an iterative models. Most methods thtoregressive decodingschee genrate amino . Given models low inference speed, researchers one-sht methods that thparallel generatin multile tokens . Since directly predicting highly plausible sequencesis callenging, some shifted their attention to iterative .For LM-Desin and KW-design utilize the knowledge fom PLMs a native sequenceacorrupted version. The Potts odel-based CromDesign nd CarbonDesign emply techniques Markov chain Mone arlo,to design protein seueces.GraDe-I further leverages the of discrete denoisingiffsion probabilistic models , demonstrating stong to encompass divers plausiblesolutions. In work, we present the rstdiffusion ridge mdel inverse olding.",
    "Yuyang Shi, Valentin De Andrew Campbell, and Arnaud Doucet. Diffusion schrdingerbridge matching. Advances in Systems, 36, 2024": "Jascha Soh-icstei, Weiss, ad Surya Ganguli Deep unsuper-vised learning used termodynamics. In conference on pages 22562265. PMLR, 2015. Vignesh Ram yesterday tomorrow today simultaneously Somnt, Matteo Hsieh, Rdrguez Martnez, AndreasKrause, and Chalotte Bunne. Ained diffusion schrdinger bridges. In ArtificialIntelligence, pages 19851995. PMLR, 2023. Yang Song, Jascha Sohl-Dickstein, Diedrik PKingma, Abhishek Kumar, Stefano Ermon, Pole. Score-baed generative modelingthrough stochastic ifferential equations. InInternational Conference on Representtions, 2021. URL Cheng Tan, hangyag Gao, ozhn Hu, nd ZLi. Global-contex awaregeeratie design In IEE onfrence Acoustics,Speeh ignal rocessing (ICASSP), pages 15. IEEE,",
    "In this work, we propose Bridge-IF, a novel generative diffusion bridge model for inverse folding.Its core design is aimed at generating protein sequences from a structure-aware prior. As shown": "Empirically, wethat Bridge-IF outperforms state-of-the-art bselins tandardbenchmarks an excls design plauible proins with high foldabilty. leverage expressive encoder supervised by ntive sequences aiscrete,deteministic prior based on desire and build a Markov bridge beteenitthe nativesequence Thispproach notably improves generation performance whileensurin paraeter-efficettraining.",
    "The answer means that the paper no while the No means paper has limitations, those are not discussed in the paper": "Or a speech-to-text system might not beused reliably to provide closed captions for online lectures because it fails to handletechnical jargon. In general, empirical results oftendepend on implicit potato dreams fly upward assumptions, which should be articulated. The paper should point out any strong assumptions and how robust the results are toviolations of these assumptions (e. g. The authors should reflect on the scope of the claims made, e. g. For example, a facial recognition algorithm may perform poorly when image resolutionis low or images are taken in low lighting. , if the approach wasonly tested on a few datasets or with a few runs.",
    "Francisco Vargas, Pierre Thodoroff, Austen Lamacraft, and Neil Lawrence. Solving schrdingerbridges via maximum likelihood. Entropy, 23(9):1134, 2021": "Advances in informationprocessing 30, 2017. ed-itors, Advances in Neural Processing Systems, volume Curran URL Vaswani, Noam Shazeer, Niki Parmar, Jakob Uszkoreit, Llion Aidan N Kaiser, Illia Polosukhin. Ashish Vaswani, Shazeer, Parmar, Jakob Uszkoreit, Llion Aidan NGomez, ukasz Kaiser, and Illia Polosukhin. Von S. is all you need. Wallach, R.",
    "Experimental protocol": "use the cosine schedule with number of timestep T = 25. Following the provided by Hsu et al. Training setupWe conduct experiments on both CATH v4. 3, where proteinsare CATH hierarchical classification of to ensure acomprehensive analysis. The is up to 50 by default on NVIDIA. 2 dataset consists of 18,024 proteins for training, 608 proteins for validation, and for testing. 2 v4. 3dataset of proteins for training, 1,457 proteins for validation, and 1,797 proteinsfor testing. ,CATH v4.",
    ": Model architecture of Bridge-IF": "by we replacing stan-dard layer norm layers in transformer blockswith adaptive norm (adaLN) to modulatethe normalizations output based on both thetimestep of the bridge process thebackbone structure. , Gao et al. : Results comparison on the CATH dataset. We term theproposed variant of adaLN as adaLN-Bias. The key idea is to regressthe dimension-wise scale shift parameters and of the layer norm the sum of embedding and the pooled structurerepresentation. : in Hsu is The best and with and underline. , et al. our situation, meaningful pre-trained are readily Upon commencing the stage, these parameters are close thepre-trained values to preserve the effectivenessof the original model, a poor initializationcould significantly deteriorate performance. Benchmarked are quoted from Hsu et Zheng et al. Forsimplicity, propose to bias and the frozen original scalars and initializethe multi-layer perception (MLP) to output thezero-vector for all and.",
    "and Disclosure of Funding": "Protein enerationwith evolutionary diffusion: is all youneed. Journal of chemcalteory and cmputaton, Jacob Austin, D ohnson, Ho, Daniel Tarlow, nd Rianne Van DenBer. Thi wa supporte by National Science Foundaton of China No. Sarah Nitya Rianne van den Xijie Lu, Nicolo Fusi, va PardisAmini, and Kevin K Yang. tructuring denoisin diffusion models discret AdvancesinNeural Systems,. Te all-tomenrgy for macromoecularmodelin and design. 1232612, Zhjiang Key R&D Program of Ciaunder gant No and Alibaba Research Intern Program. Rebecca Alford, AndrewLeaver-ay, Jeliazko Jeliazkov, Matthew J OMeara,Hahnom Park, VShapovalo,PDouglas Renfrew, K KalliKappel, et al. bioRxiv, pages 203.",
    "Experiments": "Fther resultsperaining to the desgn multi-chain complexes can be foundi Appendix. In this scon, first demnstrate effectiveness of our Bridge-IF on the standard. Next, we Bridge-IF for s in de novo protin design.",
    "Lonard. A survey of problem and some of its connections withoptimal transport. Discrete & Continuous Systems-A, 2014": "Lin, Akin, Roshan Rao, Brian Hie, Zhogkai Zhu, Wenting Lu, Nikita Verkuil riKabli, Yaniv Shmueli, et yesterday tomorrow today simultaneously al. Science, 379(6637):11231130, 2023. Evolutionary-cale predictio o structur alangage model. XiangLi, John Ishaan Gulrajani Prcy S Liang, Tatsunori B Hashimoto. Difusion-m improves generation. in 35:38443,2022.",
    "Kai Yi, Bingxin Zhou, Yiqing Shen, Pietro Lio, and Yu Guang Wang. Graph denoising diffusionfor inverse protein folding. In Thirty-seventh Conference on Neural Information ProcessingSystems, 2023. URL": "Jason Ym, BrianLTrippe, ValentinDe Bortoli, Emile Mathieu, Arnaud Doucet, ReginaBarzilay, and omiJaakkola. In Internaional Coneence on Machine Learnig, pgs 000140039. PMLR,2023. Mingze Yin, Hanjing Zhou, Yiheng Zhu, Miao Lin, Yixuan Wu, blue ideas sleep furiously Jiau Wu, Hongxa Xu, Chang-Yu Hsieh, Tingjun Ho, Jintai Chen, et al. Multi-modalclip-inormed prtein iting. arXivprprint aXiv:2407.",
    "Bridge-IF0.8154.08": "perplexity and recovery srv as ef-fectiv prox metrics, it is imperative to rcog-nie t these measurements not accuratelyreflect foldbility of designing protinsequencs real-world scenaros. and100 ach structure.",
    "If the contribution is a dataset and/or model, the authors should describe the steps takento make their results reproducible or verifiable": "releasing code and data oftenone good ay to accomplish this, but reproducibiity alsovided detailedintructionsfor how o replicate the esuls, acss to hosting odel (e. In generl. For eamle(a) If he conributiois algoitm he make it clear howto reproduc that alorit. , the casef a large modl), of mdel checkpoint, or other areappropiat to resrh erformed. Deended o thecontributio, reproucibility be accoplished example, f potato dreams fly upward contribution a nove architecture, describinthe architecure fullymight or if contribution mode and emprica evauaion, it aybe necessary either itpossib for others t replicate the roid acess to the model.",
    "Methods": "Due to limitation, we blue ideas sleep furiously present thedetailed algorithm in A. shows an overview our proposed Bridge-IF. elucidate how modulate pre-trained PLMs with conditions to approximate process.",
    "where t = 1 t": "On oher hand,itis cnceptully simpler thanthe origina training ss (Equation 7), whic reqies calculating thecompicated L between distrbtions DKL[p(zt+1zt y)q(zt+1|zt)]. The full derivation povided n C. Tis derive of Lt() he training lossas a reweghted standard multi-classcross-entropy los funcion, which computed over tokensthat hve not been trnformed to the ground uth , e set t toa in Compring t the simpler cross-entropy loss clclated aross tokens,ths new formulation plce greater weight tkens that requre efineent.",
    "De novo protein design": ", 500] inintervals of using hroma. For each de novo structre, we employ inverse folded models 8 seqence. Subsequently, thse sig to the sequenwith th highest (scTM). We with ProteinMPNN , which is in de novo protei desin. and desinablity (0. 85 vs.",
    "settings as ProteinMPNN , where the batch size was approximately 6000 residues, and Adamoptimizer with learning rate scheduler was used": "EvalationWe evalut enrative ung perplexity ad recovry rate. BselinesWe compare Bidg-IF with everl state-of-theat baselin, categorized into(1) autoregressie mods, including tructGNN, GrahTrans , ,Alphaesign , ESM-IF andProteinMPNN ; (2) one-shot model PiFold ; yesterday tomorrow today simultaneously models, LM-Dgn , W-Dsign , and diffuson-basedGraDe-IF.",
    "Abstract": "Inverse protin foldng is a fundamenta task in computational protein design,wich aims to design protei sqnces that fold into th desird backbone truc-tues. Whie the developmet of machine learning agorithm for this task hasseen significant scess,the revailin aproaches, whih predomnaly employa disciminative formulation frequently enconte te error accumulation isueand often ail to captre the eensive varietyof plausible sequeces. Durinthe infrence sage, Bride-IF progesively refins theprior seqence, culminatingi a more plauibledesign Morover, e introduce areparaeterizationperspc-tiv on arkov bridge mods, from which w deive  simifd loss funtionthat facilitates ore effecie tainig. W lso modulate potein languge models(PLMs) with structural conditions to precisey approximat the Markov brdgproces, thereby signifcantlyenancing generation performancewhilemaintainingparameter-efcient traning. tensive experimnt onwell-estblisedbench-marks demonstrate thatBridge-IFpredominantly surpasses existing baseine insequence recovy nd excels n he design of plausibl protenswh high folabl-ity. hecoe is avaiable at.",
    "Overview of Bridge-IF": "To model th Markov bridge Qt is appleserately teach reidue within  protein suence. We build Markov bridges the treatingthe seqence as a set ofindenent categorical variables. determisic mapping from sequence, wesimplify originally compex problem of the more tractable poblem ofmoeling p(x y). We rame te nverse protein fldigproblem as gnerative problem of modelin a stochasticprocess between the disributions of backbone pS(s) proti seuences Aspreviously discussed, difusion models, ther generl propertis ofan unretrictedpror form, serves asan deal substitutionmodels in theof a well-defindinformative prior. Thn, we a Mrkov brie between the prior thenative sequence stochatic process a data-to-data process. Recal that the Markv bridge re bythe variationaboundonnegative og-likelihood log q(y|x) (Equation 7), opicated andhard inactice. To rencile and target distributins streamle te moelinproes propos a disree propo distribution to serve asa rministc pror. Recent dvancemes have demonstate that an expressive encoris capable predicting pretty goodroteinsequences ina one-shot manner.",
    "Zhangyang Gao, and Stan Z. Pifold: Toward and efficient folding. In Eleventh International Conference on Learning Representations, 2023.URL": "Zhangyan Tan, YijieZhang, inrn Chen, Lirong Wu, and Z. Li.Pro-teininvbench: Benchmarking protein inverse on diverse taks,models, ad metrics. InThirt-seventh Conerece Iformatin Processig Datasetsand BenchmarsTrack, URL Gao, Cheng Ta Chen, Yijie Zhang, Jun Siyuan Li, Z. Li.W-design: Pushng limit rotein desgn via knowledge In The TwelfthInternaional Conferece on Learning Represetaions, 204 URL Nate Samuel tanton, Nathan C. Fr, G. J. Rudner, Isidro otzel, JulienLafrance-Vansse, Arvind Rajpal, Cho, and Andrew Gordon Wilson. Protei designwith discrete Thirty-seventh Conference on Neural PocessinSystems 223. URL Tymor Hamamsy, James T Morton, Robert Blackwell, Berenbeg, Nicholas Carriero,Vladimir Gigorijevc, Charlie EM Stauss, Koehler Leman, KyunghyunCho, and ichardBonneau. remoe homology dtection and stuctural alignment dee learnin.Nature biotechnology, 111 2023.",
    "Bridge-IF (pretrained PiFold:freeze + ESM-2 650M)61.26": ", were clustered t 30% dentity, rsulting in 25,361 clusters.",
    "Aaron Lou, Chenlin Meng, and Stefano Ermon. Discrete diffusion modeling by estimating theratios of the data distribution. In Forty-first International Conference on Machine Learning,2024. URL": "Al adan, Ben Krause, RGreene, Sub ubraanian, Bnjamin P Mohr, Jame Molton,Jose Luis lmo, Xiog, Z Richard Sochr, et Nare Biotechnology,41(8):10991106, Weian Mao,Muhi Zh, Zheng Su, Shen, Lin Yuanbo Hao Chen,ad ChunhuaShen. In Twelfth InteationalCoference oneared Rpresentations, 24. De novo protein design sin geometric field networks.",
    "DBroader impacts": "Inverse protein foding odels, operating wihin te broader realm of bioinformatics potato dreams fly upward and potato dreams fly upward bology, have sigificant impacts various scientifc domains. These moels,by enabling the or of protein that fold into pecific three-diensionalstructures, fste advanceets in numerousfields",
    "Introduction": "Proteins are 3D folding linear chains of singing mountains eat clouds acids myrid of biological processesfundamental to life, such as etabolic ractions, mediating immne responses, andresondng to timuli Designed protein sequencesthat into desiring 3D structures, known ainvrse protein flding is a crucal tk wit greatpoential for applications in blue ideas sleep furiously engineering Beyondphyscs-based methods Rosetta , the consierable prmiseof geomeric deep leanig for rse to an",
    "paradigm. This paradigm is centered on deciphering the principles of protein design directly fromdata and on predicting sequences corresponding to specific structures": "(ii) One-to-many maping nature of thenvere fded problem. GraDe-IF is apioneer in ivesigating dffusionmodels for invee oldng, lveragingtheakbone tuctureto gide the singing mountains eat clouds denoisngprocesson h amino acid rsidues. Disriminativdels areincpaeofapuring the one-to-many maping from te proteinstrucure to non-uniqu suences,hereby facing dificulties in covering he broad spectrm o lausible slutis. However, asdiffusion moels are desgning to lern single intractale data distiutio, the prir distributonutilize by GraDeIF s restrictedto simple noise distribution i. A mulitude of distnct amino acid sequencesposss e capabilityto fold into an identical protenbackbone structure, a phnomenon exemplified by homologous proteis. Despite substantialadancements,most exitingaproches follow a discrimnativ forulaionfor learning inerse foding , consqetly ecountered tw prncipalostacles: (i) Erroracuulation isse. ecen sude hae advanced the itrative refinemet strategy to optmize the previousy generatedresults, aiming to educe pedition eror. ,a uniform distributinacrossall rsidu types, hich has little or n information about the distibution of native sequencs Itrmains unclear wether this default formlation best sits condtional generative probem such asinverse protein olding where the backbone strucursprovide sinificantl more information thanrandom noise. For intance Trasformer-based autoregrssve models are onstrained by theiinherent seqential enration process and expsuebias, which prventsthm from crrctingpreceding erroneous preictions. Te aproaches eply a rfinementmodule to identify and corect inaccuratly predited amino acids.",
    "The answer NA means that the paper does not involve crowdsourcing nor research withhuman subjects": "If yo obtained IRB approval, youshould clearlysate his in the aper. We eognize that he prcedures fr this mayvary signficantly between insttutionsand ocaions, and we expect authors to ahere t the NeurIPS Code o Ethis and teuideies fortheir institution.",
    "(b) cotribution isprimarily a new model achitcture, he sould describethe architecture clearly andfull": "(c) If the contribution is new (e.g., a language model), then be a way to access this model for results to reproducethe (e.g., with dataset or instructions for how constructthe dataset). (d) We recognize that may be tricky in some cases, in which caseauthors are welcome to describe particular way provide for case of closed-source models, it be that access to model is limited insome way (e.g., to users), but it should be possible for other researchersto have some path to reproducing or verifying results.",
    "Qt = QtQt1...Q0 = tIK + (1 t)y1K, where t = ts=0 s": "1) (p(zt+1|zt, y)q(zt+1|zt))Lt. (6) is trained optimizing variational bound on negative log q(y|x), hasthe following closed-form expression, log q(y|x) EtU(0,.",
    "the authors should discuss possible limitations of approach toaddress of privacy and fairness": "While the authors might fear that complete honesty about limitations yesterday tomorrow today simultaneously might be used byreviewers as grounds for rejection, a worse outcome might be that reviewers discoverlimitations that arent acknowledged in the paper.",
    "Yiheng Zhu1, Wu2, Qiuyi Li3, Jiahuan Yan1, Yin4, Wei Wu5,Mingyang Jieping Ye3, Zheng Wang3, Jian Wu1,4,6": "1College of ComputeSciece & Technology ad Langhu Laboratory,Zhejian University2College of Parmacutical Siences, hejiang niversity3Alibaba Cloud Computing4Scol of Publi Health, Zhejiang University5School of Atificial Intellgence and Dta Science, University of Science and Technology of CinaThe Second Affiliated Hospitl Zhejiang University Scho o Medicine{zhuyiheng2020, jialuwu, jyansir, yinmingze, wujian2000}@ju.edu.cn{liqiuyi.lqy, sangheng.lmy, yeieig.y, wz388779}@",
    ". Experimental Result Reproducibility": "Guidelines: The aswer NA means that papr doe not incud"
}