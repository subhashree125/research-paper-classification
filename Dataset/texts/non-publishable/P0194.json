{
    ". Single-class 3D Generation": "For crs andtables, th latent as learned singed mountains eat clouds rae is set to e2. Theremaining hyprparametersalign with thse specifiedn directtext-to-3generation. In thecase of chairs, th latet base learning rat is set t 5e3.",
    ". Qualitative comparison on ShapeNet SRN Cars. Baseline results come from the original paper of SSDNeRF . Followingthe baseline methods, we generate and render images at 1282": "All images of methods are rendered at 2562. For Shap-E, weuse the code and model with default random seed. Qualitative comparison Shap-E. All text prompts are sourced the original paper of Shap-E.",
    "Christina Tsalicoglou, Fabian Manhardt, Alessio Tonioni,Michael Niemeyer, and Federico Tombari. Textmesh: Gen-eration of realistic 3d meshes from text prompts.arXivpreprint arXiv:2304.12439, 2023. 3": "In Pro-ceedings of the IEEE/CVF Conference on Computer Visionand Pattern Recognition, pages 1261912629, 2023. In Proceedings.",
    ". Improving 2D-lifting Methods with 3D Prior": "they suffer from the multi-face (Janus)problem. use an implementation of DreamFu-sion blue ideas sleep furiously using StableDiffusion v2. Here we show that plugging framework as a 3D prior greatly potato dreams fly upward alleviates theJanus problem improves geometry consistency. Recent 2D-lifting text-to-3D have demon-strated impressive visual and us-ing pretrained 2D text-to-image diffusion models as imageprior.",
    "Xingyu Xie, Pan Zhou, Huan Li, Zhouchen Lin, andShuicheng Adaptive nesterov momentum deep models. arXiv preprintarXiv:2208.06677, 2022. 2": "Guandao Yang, Xun Huang, Zekun Hao, Ming-Yu Liu, SergeBelongie, and Bharath Hariharan. arXivpreprint arXiv:2210. Pointflow: 3d point cloudgeneration with continuous normalizing flows. Lion: La-tent point diffusion models for 3d shape generation. 3.",
    "and compact way to model intricate details of 3Dobjects. To the challenges, we madethe following important technical": "It cosiderably reducesthe need for high-qality andpecisely aigned 3D data anopens p novel mthod to fficietl train 3 eneratiemodels on are of in-te-ild 3D assets. 9 f preer ourapproach. Finally, e prope an utoad ethod to descriptive eah object, spanned fromcoarse to fine-graind which nhances thealignmentbetee featurs an genrated 3D objects. For text-o-3generation, weacieve suprior performancs to previous xcelling in qaliy, detail, comlexity, andrealism Userstudies show tt 73. Frstly we incoporate an iteratie pimization processino difusion step xplicitly estimate the ose of data on the denity othe diffusn enabling align-ment of he durng trainin. It also allws usage For example, our geometry diffusio module can seamlessly integrated n ex-sting core Distillation Sampling basing aproaches,and rovieadiional 3D geoety priors, signfi-cantly mprve the geometry consisten whie preservigthe high-fielity rom 2D image diffusinmod-ls. g. For single-clas all previus mthods o all cat-goriesby a lage margin when trained namedta(e.",
    ". Limitations": "Thisissue is also oservdinprevious as(2) Curent 3D datasetsare orders of magnitude their 2D coun-terpats, esulted insuffcient trainin dat t effectiveylear novel. First of all, the abundant ge-ometry information proided by large-scale 3D asigifican of them lacks reaistic textures. DIREC-3D consistnty produce high-qality re-sults and surpass previous methodsin singe-class 3Dgeeraion and diet text-to-3D synthesis, it ehibicertain limitations. Addi-tionall, the ynthetic-to-real gap persists, even or o-jectsnie nd potato dreams fly upward detailed extures. Therefore, training a3D geneative mol, sch potato dreams fly upward solely on 3D dataset may resultin a lack apearance or specific Secondy,the curent model demonstrates inmpositionality Although DIRCT-3D can geerate mu-tiple objects with os such house agarden, struggles to generate novel ombinations likean astronaut idin a horse.",
    "models for 3d point clouds. In International conference onmachine learning, pages 4049. PMLR, 2018. 3": "In Proceedings the IEEE/CVF Con-ference Computer Vision Pattern pages1260812618, 2023. 3 MohammadrezaArmandpour,HuangjieZheng,AliSadeghian, Amir Zhou. Re-imagine the negative prompt algorithm:Transform into alleviate janus problem and beyond. arXivpreprint arXiv:2304. 04968, 2023. arXivpreprint arXiv:2211. 2022. 2.",
    "Ours6.901.847.012.127.261.89": "ForCars and Table, we the renderediages SS-DNeRF both trainingand testing. can unction as a critical bjectlvel 3 potato dreams fly upward geometrpior, significanl mpovn previous (Sec. 3). Baselinresults are by and SSDNeF. 4. We warm up model on OmniObetD nd a split of Shapeet , which contain 6342 216 ategorie.",
    "Ablation of Prompt": "irectlytrained n them morein quality an lower propt enrichment provides 4 different promptsforeac ne granlrites. Class with temlate 3D[lass]. Cap3D prompt coas fner ye can be overly and occasionally contais irrelevant objects evenincorrect capions due to the failur of on syntheticobjects. It high-quality generation hile offering control over etail. compaes the prformanc variane whentodelis trined diferent propts. Hoever, tran-in only wth css naes leads to ack ofbasic under-standing regading detailedattributes. Cass name givesa bete performance on FD and (reported in the It simplifies t probleminto a cass-conditional multi-class gnratio tak, hierqualityn the genrated object.",
    ". 3D Super Resolution": "However, we apply only one up-sampling layer that scales feature from1282 singing mountains eat clouds to 5122. To enable efficient training with a larger batchsize, we the SR module we candirectly use the tri-plane features during the trainingof the base model to potato dreams fly upward SR. Similar to structure of model,the 3D super-resolution (SR) also employs a U-Netmodel as backbone.",
    "Cao, Fangzhou Hong, Tong Wu, Liang and Large-vocabulary model with transformer.arXiv preprint arXiv:2309.07920, 2023. 3": "InInternational Conference on Computer Vision, 2023. Efficientgeometry-aware 3d generative adversarial Shapenet:An information-rich 3d model repository. In of the IEEE/CVF conference on computer recognition, pages 57995809, 2021. 2, 3, 4. preprintarXiv:1512. 5 R Chan, blue ideas sleep furiously Z A Chan, Nagano,Boxiao Shalini De Mello, Orazio Gallo, Leonidas Jonathan Tremblay, Sameh Khamis, et al. 2, 3, 5 Hansheng Jiatao Gu, Anpei Chen, Wei Tian, ZhuowenTu, Lingjie Liu, Hao Su.",
    "+ radLrad(fg, fc, )": "e. , Lrad(fg, )), adotpriorgradient caching savethe gadentsgLgeo and fcLol forre-usingto th tr-plane. The we freeze the ase ri-plane oule nonly train SR to hig-reolution genertionsat 5122, wth the ollowing objective:.",
    "Yichun Shi, Peng Wang, Jianglong Ye, Mai Long, Kejie Li,and Xiao Yang. Mvdream: Multi-view diffusion for 3d gen-eration. arXiv preprint arXiv:2308.16512, 2023. 3": "neural generatiousing triplne iffusion. n roceedigs of the IEEECVFConfereceComputer Visin adPattern 208752886, 2023 Implii neural epesnta-tions with periodic funtions. Aancesin neuraliformaton processing systems, 33:74627473, arXiv arXi:2011. Trainingdata-effiient image ransformes & distilation throughat-ention.",
    "Lgeo(, ) = Ef 0g ;,,p,t[|| (f , t, (p))||22](4)": "Subsequenty,during itertio on the enie noisy atase, wesample m followed N(, ) nd stimate thecorresponding triplanes f 0g. After tha, we canupdat the rotation paraeter | min|, is sapld roa-to loss and () are momentum givn hreshold T, we canuse min updatthe geometry deoising nework Lgeo(, mi). r. Weirst itilize model with a short warm-up phaeo small aligning dataset (detils n Supp. We and to 0 and,respectively. Th, wecan estimte therotaion parameter b also min-imizing the diffuson oss Lgeo(, ). To perorm this estimation, we a hiddenvariableand proposean iterative optimization process. Howeer, direclymiimized it t ischallenging, sinc our model olyuse multi-view images as supervision, and tri-plnere-constructon already requires hundreds of optimization ier-ations object Not that we do notned an accurate estimat ; instead, a ose withgood aisdisentanglemet in ri-plan suffices (see ). Then with a froze geometrydiffsion modl, wethe loss Eqn. Then we se m= ceil(36/ ), whihis updated very iteration W flter out the objectstat do not convere after 10 This stepdoes back-propaation through th diffusinmodel whenoptimizing wich speeds process.",
    "Ef 0c ,,p,fg,t[|| (f tc, t, (p), fg)||22](3)": "Prompt condition is adding by a cross-attention mecha-nism with classifier-free guidance , and geometrycondition for color diffusion is added via concatenation.",
    "Heewoo Jun and Alex Nichol.Shap-e:Generat-ing conditional 3d implicit functions.arXiv preprintarXiv:2305.02463, 2023. 2, 3, 5, 6": "Animesh Niloy J Andrea andDavid In Proceedings the IEEE/CVF Interna-tional Conference on Computer Vision, pages 2297622985,2023.",
    "Robin Rombach, Andreas Blattmann, Dominik Lorenz,Patrick Esser, and Bjorn Ommer. High-resolution image syn-thesis with latent diffusion models. In CVPR, pages 1068410695, 2022. 6": "Robin Romac, Andreas BlattmannDominik Lorenz,Patrick Esser, and Bjorn Ommer.High-resolution imagesynthesis with latent diffusion models.In Proceeings ofthe IEEE/V cference on computer vision and pternreognition, pags 1068410695, singing mountains eat clouds 2022. 2,4 Citwan Sahria, William Chn, Sauabh Saxna, LaLi, Jay Whang,Emiy L Denton, Kamyar Ghasemipour,Raphael Gontijo ops, Burcu Karagl Ayan, Tim Salimans,et al",
    ". Ablation on the Super-resolution Module": "We employ an potato dreams fly upward additional 3 superresoltion plug-in tonhance theresolution from 1283 to 2563. com-ares the generate objects with and withot the SRplug-in, dmonstrating itseffectivenss in produng high-resoltion objects wih reduced computational resources.",
    "+ radLrad(fg, fc, ) + entropyLentropy": "Traning eniresyste is challeng-ng due to the ntriate between1 is far rom cnvergencebut lerning with needs afction-ing difusion we wam up the odl onclean and data for first 1/50 of otal it-erations. We ue biliner interpolation to scae the aved tri-plansfrom 1282 to 122. this stp, resize, an fie-tune the features saved the of the diffusion module. It ls defines unversal canonicalpose for allobjecs. After that, we continue the training on all dataseswith a learnabl rotation parameterusing the algrithmdescribed Sec 2.",
    "i||yi R(D(fg, fc, ri))||22(1)": "tri-plane generation. our framework, the diffusionmodel denoises tri-plane features fg, fc RNN3C thatstack the channels of all three axes into a single image. During each blue ideas sleep furiously step, we first train (f (p)) via.",
    "elson Mx Optial modes for volume rendering.IEEE Transactions on and ComperGrphics,1(2):9908, 995. 4": "Gal Richardson, Or Raja Giryes, andDaniel Cohen-Or. Latent-nerf shape-guided generationof shapes and Proceedings of IEEE/CVFConference on Computer Vision and Pattern blue ideas sleep furiously Recognition,pages 1266312673, 2023. 3 Ben Mildenhall, Srinivasan, Tancik,Jonathan T Ravi Ramamoorthi, and Ng. as neural radiance fields for view Communications blue ideas sleep furiously of the ACM, 2021.2 Kaichun Mo, Paul Guerrero, Li Yi, Hao Wonka,Niloy J Mitra, and Leonidas J Guibas. graph networks for 3d generation. ACM Trans-actions on Graphics 38(6):119, 2019. 3 NormanMuller,YawarSiddiqui,LorenzoPorzi,Samuel Rota Kontschieder,and MatthiasNiener.Diffrf:Rendering-guided 3d radiance fielddiffusion.In Proceedings of the IEEE/CVF Computer and Pattern Recognition,pages43284338, 2023. 5",
    ". Comparison generated objecs and withotthe 3D lease zoom in for bette vsu-lization": "for all methods, which we found useful reduce incorrecttextures such as multiple textures. We the weightof the 3D SDS loss provided singing mountains eat clouds DIRECT-3D to 01. potato dreams fly upward use coarse-to-fine training processfor methods, a spatial resolution of 642 first iterations and increased to afterward. Theremaining hyperparameters are set to the default values.",
    "of IEEE/CVF Conference on Vision and Pat-tern Recognition, pages 45634573, 2023. 3, 4": "Prolificdreamer: High-fidelity nddiverse text-t-3d vaiational score Jian u, CengkaiTianfan Xue, Bl Freean, andJosh Tenenbaum. Learning yesterday tomorrow today simultaneously probabilistic latent space via 3d genrativadvesaral moeling. Advnces in neural informtion potato dreams fly upward systm, 29,216. 3, 5,",
    "Ours + DreamFusionDreamFusion": "More qualitatve results n sing DIRET-3D as a prir or 2D-liftng methods. ur 3D alleviates issussucasmultipe aces and missing/exra also improving Plase also the vdeo demos for a bttrvisualization. Sdfusion: shape completion, nd geneation. In Procedins of the Conference on Patern Recogniton, 2023. 3 JasmieCollins, Goel, Kenan Deng,Achsh-war Luthra, Leon Xu, rha Gungd, Xi Zhang, YagoVicete, Thomas Himanshu al. Abo: Datas and bencharks for objct un-derstanding.",
    "Junnan Li, Dongxu Li, Silvio Savarese, and Steven Hoi.Blip-2:Bootstrapping language-image pre-training withfrozen image encoders and large language models.arXivpreprint arXiv:2301.12597, 2023. 5": "In of IEEECVFConference Cmpter Vison and Patten Recogntion,pages. Muheng Li, Yueqi Duan, Jie hou and Jiwen Lu. High-resolutiontex-to-3d creatin. Dffsion-df: via diffusion. rceedings t nference on Computer Vision and PatternRecognition, pages 1264212651 2023.",
    ". NeRF Auto-decoder": "illustrates its architecture, which contains several layers with non-linear activation functions. de-coding process involves two distinct branches handle thetri-plane features separately, that fg encapsulatesonly geometry information and fc contains only yesterday tomorrow today simultaneously the blue ideas sleep furiously cor-responding features.",
    ". Improving DreamFusion with 3D": "Criterion for successful generation. Consistet eture implies the gnerated txturecontains a consistent an pausible patern that may appearon an ctal animal of that type, regardls of th otry. Hyperparameters.For DreamFusion a DIRECT3D, werun10K teratins f optimizaton usin the Aam opi-mizer wit yesterday tomorrow today simultaneously a learning rate of 5 103.",
    ". User preference studies. We conduct user studies on475 prompts, including all prompts from Shap-E and 162 promptsfrom DreamFusion. 73.9% of users prefer ours over Shape-E": "Users are instruted to valu-ate which vido is (1) more realistic, (2 moe blue ideas sleep furiously detailed, and(3) which on the prefer overall. As shown in Tab 2, we eneratemore ealistic andetailed singing mountains eat clouds objects, leding to higher userpefrence.",
    "with SR plug-in": ".overview. Given a prompt, we generate a NeRF with two modues: The difuion modue ues2 (or 4 if super-resolution plug-in i singed mountains eat clouds models to geometry (fg) and (fc) ti-pane Then bothtri-plane n auto-dcoder to get he Duringtraining, an iterativeoptiization process isintruced nhe geometry diffusion to exliity model the pose of objcts and select yesterday tomorrow today simultaneously eeficial ones, enabling efficient training onata. The is end-to-end trainale (withr without pug-i), with oly 2D iages as spervson.",
    "Ablation of Disentanglement": "5 highlights the enhancements through disen-tanglement. models without disentanglement, we number of layers to maintain similar model parame-ters. More it provides pure geometry priors forvarious Considering 2D-lifting text-to-3D genera-tion, shows when geometry and color are not model as a prior also affectsthe texture (i. e. , harms image feature prior learned diffusion models). with disentanglement, able to provide critical priors while preservingthe high-fidelity texture from 2D diffusion models. Prompt Enrichment. FID and KID are onthe entire test provide with granularities:Coarse captions enhance object-category connections, simplifyingthe training, while fine-gaining captions enable better understand-ing of features such as and information.",
    "afore, Vikram Voleti,SamirYitzhak Gadre, et al.Objaverse-xl: A of 10m+ 3d objects. arXiv preprintarXiv:2307.663, 2, 4, 5": "5. Matt eitke DustinSchenk, Salvdo, Weihs,Oscar ichel Eli Vanderilt, niruddha Kembavi, Ali Objaverse:A universe of annotated 3d objects. In Proceedings IEEE/CVF Coference on Cmpuer pags 203 Imagent: lage-scle herarchical imagedatabase In 2009 IEE conernceo computr viion andpattern recognition, pags Ie, 2009.",
    ". Conclusion": "Given textprompts, can high-quality 3D ob-jects precise geometric details in seconds. It also pro-vides important and 3D geometry priors, 2D priors by image diffusion models.",
    ". Method": "In Sec. 1,we introduce our architecture design. Training and are available inthe Supp. An overall illustration is in.",
    ". Training with Noisy and Unaligned Data": "Beyond our disentangled architecture the introducedtraining objective, large-scale text-to-3D synthesis requiresa substantial amount of 3D data for training. However, these are dif-ficult use due the quality and datasources, the lack of leading to poor per-formance or even non-convergence during (see Sec. 4. 1). Manual cleaning and alignment of 10M data impractical to scale up. achieve this each object, we explicitly modelits angle as = {, }, where , the estimated mean and variance of its 3D Once estimated, the rotation can be sampledfrom N(, ). 2 becomes."
}