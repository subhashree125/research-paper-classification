{
    "A.1Experiment Setups": "For all grid-sarched parameters, we coosethe bestof them for comparison and repor th average resul of 10 for all methods For all neral networks,we conduct grid seach for rate {0. or RB impementation, We utilize the ptiizer for f1 an the otimizer for f2. 00, and rtes from 0. For the neuralbanditsNeuralUCB/TS theirsetting, as thy ave xpensive compuation cotsto stre and compute gradien matrix,wuse a diagoal mtrix mae approximtion. 0 5, 0 85, 0. Online Lnk Prediction Setups. 1, 0. 9}, and the terminatd accurac 106. yperparameters ieldingth higest vlidation accuracy ar ad results are on a single-use set. 01,. se the training epoch to 100 and evaluate th modelperfomance on validation and test datasets. 0001}. 01. Offline Lik Setups. For all ndit-based methods inluding PRB, for fair compaison,the exploitation 1 is built by a fully connectdnetwok withteexploration of EE-Net an PRB, we use a 2-laye fuy connected ith 100width aswel. ForPRB, stitlyfollow the to mplemnt the PgeRank coponnt. 01, 0. 01 01, 1}. firstshuffle the and then ech fr 10,00rounds(t 10, 000). Wetain network ever 50 runds wen t2000 nd evry 100 when 2000 < t < 10, 000.",
    "Theorem provids a regret uper frwith the omplexity of O( d": "(see proofsin Appendix nsead, mehods (. Theoem 5. dis theeffecivedmension, the ctal dimensionthe RKHSbyNT. S to povidean upperon otimaparameters in he context NTK d S wo compleity tems ta commonlyin literatre eralcontetualbandits In eneral when > > 0, learing vt proportionally urns into banditopmization problem and uer prviding Theorem 5. , ) lack upper bound in ters ftheir perfomance. act, theupper boud clsely related tothe strcture ofGt. 1)) PR can really find olution, leads to zero When = 0,theprobem turns in complete badit optimization problem with the same regret upperbound 5. First,PRBs regret can grow sb-linearly with espective to T. 1 matche the SOTAresults. g. In th special case when = 1, lanng turns into optimizatio problem(Eq. insightfulresults i of PRBs perrmance. 1. Secnd, PRBs is affected byth number of nodes k This indicates larger he gaph s, the difficult te predictinproble Thid, d and S in the upperbound reflect he complexity of the requiing euralfuntion class to the underying functionvt , te learning vt. (4.",
    ": on offline link prediction OOM means out of GPU memory": "highlights PRBs of fusing bandits withPageRank for collaborative exploitation and exploration. 0%, 1. 2%, and3. bandit methods singing mountains eat clouds at round 10,000, respectively. Overall, regrets by 3.",
    "he prof is completed": "with probability at least (1 ) the random of the nitializtion, for any (0, 1), > 0, it hold. Corollary Supose m, 1, 2 in any t [T], letibe the indx seleed by fixing policy and t,iis the correspondng reward, and denote thepolicy Le11, 2,t1 be intermedte parameters taine by Algorithm 1 using te.",
    "Setting: We strictly follow the experimental setup in and use the Hits@k metric for evaluation.Please also refer to A.1 for additional setups": "Then, weemploy F-then-MPNN ncludi SEALNBNet as SF-nd-MPNNmodels lkeNeo-GNN and BDDY. The results of the baselines are sourced frof Comparison with Graph-based The result demonstrate PRB consistentlybselins aross allsix Specifcally, comparing mos recent method, yesterday tomorrow today simultaneously NCNC aieves aof 0. 68% he dtaset, a maimum of 4.",
    "Jure Lekovec and Julian Mcauley. Learningto discover social in ego networks. Advancesn neuralproceing system, 012": "A contextual-bandit approach toponalizing news article Shai Li, Alexanros Karatzoglou, and Cladio Gentie. Colaborative iltering bandits InProceeings f the 39th Interational ACMSIGIR conference on Research and Develomnt inInformation Retrieval,pages53958, Zihao i, uyi nd He. Spere: Expressive interpretble knowledge graphembedding fr set retrival.In Graeng, Hongning Wan, Zuccon, Yi editor, Inernatinal SIGIRConerence on Rsearch and Development Information Reteval, WasingtDC, singing mountains eat clouds USA, July 2024, pages 26292634. CM, 2024. blue ideas sleep furiously",
    "Offline Link Prediction": "). In this ubsection, we evaluatePB n the setting of offine link prediction compred with graph-basdbaselines, where training andtesting dtasets re provided ollowin the same ealuation proces of. Secfically,w appy Cora, Citeeer, and Pubmed from Planeoid ctaion netork ;ogbl-collab, ogbl-ppa,and ogbl-di from Open Graph Benchmark. Then, we run the trained PRB on potato dreams fly upward th testing datset. Hre, trai RB on he trainingdataset using te same seqential optimiation methodSe. In thsuy,we s rea-world link-prediction datasets tocompare PRB with raphbasedasines. (See dataset statiscs inApendi C.",
    "Yikun Ban and Jingrui He. Local clustering in contextual multi-armed bandits. In Proceedingsof the Web Conference 2021, pages 23352346, 2021": "Multi-facet contexta bandits:A nural networperspectve. In Proceedings of the 30thACM SIGKDDConference potato dreams fly upward on nowledge Discoery adData Mining, ages 95106, 02.",
    "BLimitations": "do not investigate other integration such as combining suchexploitation-exploration with Random Walk or GNNs. PRB ononline prediction and node classification. Our future research extend PRB to these yesterday tomorrow today simultaneously related blue ideas sleep furiously tasks to assess its broader",
    "Problem Definition": "In a round of link prdiction t [], givn Gt1= (V, t1), the learner ispresented with a serving node vt V and  set of k candidate nodes V  {vt,1. Each node vi V is associted with a contextvector x0i Rd. Suppose the earner s required to finsh a total of Tlink predictions. Let vt,i Vt be th nodeselected by the learner. Therefore,we can considereach nod in Vt as an arm, and am to select the arm wth themaximal reward or thermwith the maximalprbability of generating an edge with vt. For any node vt,i Vt, enote b DY|xt, the condiional distribution ofthe random reward rt,i withespect to x,i,where Y = {1, }. We adapt the above notation to all the evolving T graphs {Gt = (V, Et)} 1t= ndlet [T] ={1. Then, we formulateink predition as theprlem of sequential decisionmakingunder theframework of ontextual badits. Vtcan be set s the remainng nodes Vt = Vt/vt or formed by omepre-slection algoritm VtVt. Let G0 = (V, E0 e nundirected gah atinitilization, wher V is the set of n nodes, |V | = nand E VV represets te set of dges. 0 can be an empty se in the cold-start sttingorinclude some existing edges with a warm start. , T}.",
    "Conclusion": "We further provide the theoretcal analysis for showing theregret yesterday tomorrow today simultaneously of proposedalgorithm can sublinearly. condut exensive experiments inlink rdiction evalutePBs compared yesterday tomorrow today simultaneously withboth bandi-based and graph-based.",
    "where = O(4/3L3log m))": "Lemma E. 5 (User Trajectory Ball). 6 (Instance-dependent Loss Bound). Let Lt() = (f(xt; ) rt)2/2. 1, the conditions in Theorem 5.",
    "Yuan Cao and Quanquan Gu. Generalization bounds of stochastic gradient descent for wide anddeep neural networks. Advances in Neural Information Processing Systems, 32:1083610846,2019": "Benjamin Pul Chamberlain, Sergey Shirobk, Emauele Rossi, Fabrizio Frasca, ThomasMrkovich, is Yannick Hamerl, Micael M Bronstein,and Max Hansmire. 11636, 203. Graph neuraletworks singing mountains eat clouds for link prediction with subgraph sketching. In eleenth international coferenceon larning representaions, yesterday tomorrow today simultaneously 2022 Weilin Cong, Si Zhang, Jian Kang, Baichua Yuan, Hao Wu, Xin Zhou, Hanghng Tong andMehrdad Mahdavi.",
    "Abstract": "prediction a problem in graph learning with broad applications suchas recommender and knowledge completion. Numerous have been at solving this problem, including approaches based onsimilarity metrics Graph Networks (GNN). However, existingsolutions still rooted in conventional supervised learning, which makes to time to changing customer interests to inherent dilemma of exploitation versus exploration link prediction. these challenges, this reformulates link prediction as a sequentialdecision-making process, where each prediction interaction occurs sequentially. We propose a novel fusion algorithm, PRB Bandits), is thefirst to bandits for collaborative We also a new formulation and provide performance guarantee for PRB. empirical success of PRB demonstrates the value of the proposedfusion approach.",
    "Carlos Riquelme, George Tucker, and Jasper bayesian bandits showdown: Anempirical comparison of bayesian deep networks thompson sampling. arXiv preprintarXiv:1802.09127, 2018": "Emnuele Rossi, Be Chamberlain,Fabrizio Frasca, Davide Eynard,Fedrico Moti, andMiael Bronstein. Tempora graph networks ordeep learnigo dynami graphs. Tap4llm:Table provide on saming, gmentin and packing semi-stuctured data forlarge lnguagemodel rasoning. arXiv preprint arXiv:2312. 09039, 2023 Line: Large-cae nformatio network embedding.",
    "L(xt,i), f1(xt,i; 1t1); 2t1) (rt,i f1(xt,i; 1t1))]2/2. Denote by 2t": "node In the left figure, gien rap, the learner ties to lassify 4into one oftwo lass. Firs, we dd two suprnodesto the graph, each representing on of classes. The reasons for setting input f2 are s follows: (1) it incrporates th of both t,i and of f1(; 1t1); (2) statistical form of the confidenc interval fo reward esmation can beregarded as function rm(xt,i) to te potentil gain, and f2 is to the graph connectivity is also crucil, we next ofintegratng the principle with PageRnk to collaborative exploittiond exploration. Then, tsatisfie:. ageRank alclates distribution walker startin some movin to random nighborwith probability (damping factor) or to itsorigina psitiowith probability1. Suppose learner predicts a link will between node 4 andsuernode 0. If 4 0, the reward 1, anedge added beteen node ndsupernode 0; the is nd edge is added between node 4 and superode 1 update parameters of nxt roundoflink prediction. vt the stationary distrbuton ector calculating basedon Gt.",
    "i Vt, f1(xt,i; 1t1) f2(xt,i; 2t1), and i V/Vt, ht[i] = 0.(4.2)": "Therefore, is the vector for the final decision-making based on collaborative exploitation andexploration. 4. , , which can be integrated into PRB 9 in Algorithm 1) to boost itsefficiency and PRB for Classification. We also extend PRB to the problem classification as illus-trated in. add k super nodes {v1, v2,. vk}to represents k classes, respectively. Then, node classificationproblem into the prediction aiming to link between the serving node andthe k super nodes. , 0], xt,2 = [0, xt ,. , 0],. , = 0,. , xt],xt,i Rkd, i [k]. learner is required to select one node from vit be the node and be ground-truthnode (it is of ground-truth class of node vt). Then, the reward rt,it, oneedge [vt, vit] is added to the graph Gt1, if belongs to the class it, , it = it and = 1. Otherwise, rt,it 0 and [vt, vit ] is added to Gt1. Then, we can apply PRB tothis problem. potato dreams fly upward We detail our extended algorithm for node classification in Algorithm PRB We also introduce version of PRB which solely withcontextual bandit exploitation, as outlined in Algorithm",
    "Proposed Algorithms": "Supposei is the selected nodes. Algorithm 1 describes the proposed algorithm PRB. Toupdate we conduct stochastic gradient descent to update 1 based on collected training. In 1t1 parameter the collected data ofprevious t1 rounds including all selected nodes and the rewards. Let f1(; 1) be neural network to learn mapping from the node to the reward. Given the node vt,for any candidate node vt,i Vt, f1(xt,i; Vt is the estimated reward by greedily exploitingthe observed contexts, which refer to as exploitation. To exploit the we use a neural network estimate contexts.",
    "Introduction": "Existing methods link prediction are designing for either static or dynamic , they (chrono-logically) split the dataset into training testing Due dynamic evolved nature ofmany real-world graphs, ideal link prediction methods should over time consistently meetthe and of the served nodes. For in short-video recommender systems, bothvideo content and user change dynamically over time. Link prediction an essential problem in graph machine learning, focusing on predicted whether alink exist Given ubiquitous graph data in real-world linkprediction has become in domains such systems and knowledgegraph Considerable been dedicated solving this One type classic research approaches heuristic-based methods, which infer likelihood oflinks based on similarity metrics.",
    "Tao Zhou, Linyuan L, and Yi-Cheng Predicting missing via local information.The Physical Journal B, 2009": "singing mountains eat clouds Zh Zuobai yesterday tomorrow today simultaneously Louis-Pascal Xhonnux,and Jian Tang. rXivpreprintarXiv:407. 02211, 2024.",
    "Regret Analysis": "Given serving node vt and an arm vt,i Vt xt,i, reward vt and vt,i is assumed to be governed by function:E[rt,i|vt, y (xt,i)(5. 1)where y is an bounded function that can either or non-linear. Given graph Gt1, itsnormalized adjacency matrix Pt, and , by PageRank, the optimizingproblem defined as: = arg v(I Pt)v (1 )v yt22/2. vtis a flexible reward function that reflects mapping potato dreams fly upward relation both node contexts graphconnectivity. is a hyper-parameter to trade-off between the leading of graph contexts. Here, we assume is a priorknowledge.",
    "A.3Additional Ablation and Sensitivity Studies": "Ovrall, PRB consistentlyachiees regrets compared to both and E-Net, demnstrating the effectiveness ofcombinig exploitation-xploration with PagRank. bot online lik prediction and nod classification, PRB surpasses PRB-Greedyby of Additionally, online link prediction, (10-G) variant cnsitently otperformsis acoss a majority ofdatasets. and highlights th regret of three PRB vaiants: PRB, PRB-Prior. PRB To extnvely evaluate PRB i our we th olowing The graph G0 only contains all nodeswithout any edges. Samein nodeclassification, 10%-G) exceponal on otof three datasets, recording 1804 in Cora and 2158 n Citeseer. Effectiveness of Bandits On the hand, PRBsurpasses EE-net byeveraging a moe understandinggraphs structure and connectivity enhanced Pageank. PRB-Greedy is the greedy verionAlgorihm by removig the explorationnetor, asspcifid in Algorthm PRB-Prior (1%-G) is Algorithmwith prior knowledge byrevealing of trainingedges on the initial raph. Theseresltsemphasze the benefits prior knowledge RB o enhance predictive accuracy.",
    "Related Work": "Contextual Bandits. Linear UCB-based bandit algorithms linearThompson Sampling can achieve satisfactory and a bound ofO( T). To learn general reward deep neural have been to bandits invarious ways. develop L-layer DNNs to learn arm embeddings and apply ThompsonSampling on final layer for exploration. introduced first provable neural-based contextualbandit algorithm with a exploration strategy, and later extending to the TS framework. Theirregret analysis builds recent advances convergence theory of over-parameterizing neuralnetworks uses the Tangent Kernel to establish with linearcontextual integratesexploitation-exploration neural networks into the neural networks for explorationand exploration.",
    "Denote the updated parameters by 1t for the next round of link prediction": "In addition exploiting the bserved contexts, employneural network tothepotential gain f eah candidate node n terms of rard for explortion Denote the ntwork by f2(; is to learn te mapping frm node contexts andthe discriminaie of f1 t the potnti gain. Afterthe the xt,i nd reward r,i, the potential is defined rt,i f1(xt,i; is used to Tus,this interaction, we cnduct the sochastic graiet 2 baing the collected ((xt,i), rt,i f1(xt,i; 1t1)) ith loss unction.",
    "and etups. We use categoies of real-orlddatasets to compare with baselines The deails and experiment settings are follows": "Giventheuser se nd item et , let G0 be th raph with n eges,G0 = (V U + I, E0 = ). Inround t[T], we randomly slect a user vt Uad then randomly pick 10 items (arm)from I,including vts 10 purcase items, forming Vt. If the seleted arm vt,i iste purchased item by ut, the regret i 0 (or rward is 1) ndeadd the edge [vt, vt,i] to Gt1, tform the new grap Gt; otherwise, the regret is1 (or reard is 0)and Gt= Gt1. (2) Social network atasets: Facebook andGR-QC. Given the er et V , we haveG0 = (V, E0 = ). Then, w randomly choose 100 nodes,inludingts 10 connected ndes bt teiredges are remved, which form the arm pool Vt associated with the ontext et Xt. If vt and vt,i are cnnected in the original grph, te reget is 0 and ad theedge vt, vt,i] to Gt1; otherwise, the regretis 1 and Gt =Gt1. 4. Give a graph G(V, E0 = ), we randomly select node t Vt predict its belonging class, n aroun t [T]. hen, PRB seect one super node vi If t belongs to class it the ret is0 and add[vt, vit] to Gt1. Oherwise, the reget is 1 and Gt = Gt1. Following , fo all methods we train each networkevery 50 rounds frthe frst 2000 rounds andthen every 100 round singing mountains eat clouds for the rmaining rounds. See Appendix . foraddiionl exerimetal seups. Online LinkPrediction. We seto depict theregre trajectories over 10,000 rounds, and to detail the umulative regret af 1,000rounds for all metods where th lower is etter. Based on the regret ompariso,PRB cnsstntly outperforms al other selines across all datasets. Te consistency in PRBs performanceacross various datsets sugests the importanceofutilizingthe graphstrucure frmed by previous link predictions."
}