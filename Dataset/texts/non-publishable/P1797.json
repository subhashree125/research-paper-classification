{
    "We answer Q4 in .5.2. We perform an additional experiment to quantitatively comparethe saliency map produced for an image and a compressed version of the same image": "We could directly use the existing for study, which led us to integrate the code for IDGI1 provided by the authors and use original implementations authors code for IG, GIG,and BlurIG. The code providing the not usable for reproduced results at scale.Our code utilizes high-performance computing resources. ready use and complete,facilitating easy reproduction of results for dataset and models presented in the originalpaper. We provide the exact details regarding this . This paper been organized follows: We begin with a brief background on the original Integrated Gradi-ents method and its variants, BlurIG and GIG, in . Readers familiar with these to ,where we summarize IDGI algorithm, followed the derivation xjp, as previously men-tioned, and in-depth discussion of sensitivity to step-size variation. We present an improvedillustration IDGI. Finally, presents our experimental implementation requirements, and results beyond the original paper. We also this to describe thedifficulties we during study due to the need for details on the original implementation.",
    "Blur Integrated Gradients": "BlurIG, on the other hand, uses a pah where a Gaussian fltr progressively lurs the input. Te pat for IG is linear in z and scaes the iagesntensity. Xu et a.",
    "has the same functional value aspoint xj+1, i.e., fc(xj+1) fc(xjp)": "e bserve that theTaylor series approximation is necessary t arrie at the expression fo xjp. Assumingxjp lie on the given path rm any IG-asd method singing mountains eat clouds such tat i is define as singing mountains eat clouds xjp = j+ c g|g|, whre c iste length f th projection that we wish to approximate, wenow derv the exprssion for xjp.",
    "SIC and AIC with MS-SSIM": "We now the explanationmethods usingte oftmax infrmation curves (SIC and the sin M-SSIM(Kancharla & 2018; Ma et al ,2017).",
    "Our contributions and findings are as follows:": "We answer Q1 in , where we present the results singing mountains eat clouds obtained from the experiments to compareour results with the authors findings. We present our improved illustration of IDGI that correctly demonstrates the pathcorresponding to IG, GIG, and BlurIG. Secondly, we derive the expression for xjp, an importantterm in IDGI algorithm. While the original paper mentions the expression, how it was obtainedhas not been discussed. We verify insights from theoretical analysis of the expressionfor the above-mentioned xjp term. We also vary the step size used to compute the Riemann sum forIG and BlurIG. We arrive at a noteworthy conclusion: IDGI is more sensitive to step-size variationthan its underlying IG method. We successfully proving this through rigorous theoretical analysis ofhow the step size and the performance of IDGI are linked. We then confirmed our theory throughour experimental findings. We also observed that at a higher step size, the scores of BlurIG + IDGIare lower than those for IG + IDGI. We address this by analyzing the IDGI algorithm and observingthe variation in image along the path for BlurIG and IG.",
    ": end for7: return IIDGI": "We report our results step-size variation through , where we study variation of the the respective metric versus the of steps 16, and for InceptionV3. Increasing thenumber of steps a score, a higher number of steps in Riemann sum leads to a of the actual integral. due to increasing the number ofsteps requires more resources and time, blue ideas sleep furiously necessitating a trade-off. Please note that the x-axis is exponentialscale, which means beyond a step size of 32, the return in score per step is (2023), and observe relationshipbetween d the value IDGI. , x,f,c, and path are as defined in. developer must a choice basedon the singing mountains eat clouds of the application and the resources available.",
    "xj(xjp xj).Here, xj lies on the hyperplane hj, while xjp and xj+1 lie on thehyperplane hj+1": "x] given path from anyIG-based method g be the gradient of fc(xj) respect to x. illustrates while for feature, value of the attribution from the original and direction can be different,the change in the value of fc remains the Let x be a given input with class c, f be given classifier, [x,. This that chosen path these specific points and similar results when integrating the functions gradient. Then, according the IDGI Algorithm,the important direction vector of g determined asg|g| and the step fc(xj+1)fc(xj). , xj,.",
    "How des IDGI vry step size?": "The expression for c, of projection, determines the validity of theTaylor series yesterday tomorrow today simultaneously approximation. We c is directly proportional to fc(xj+1) fc(xj). xj+1 and xj are consecutive in the an IG-based method. It is to observe that same path, these two points are closer to a larger number of steps (since number of steps denotes the finite number of segments that we discretize the path between x and x into. ) implies that fc(xj+1) and closer in The expression of xjp isthus directly linked to the number of steps and, thus, step used for the algorithm, which means thatIDGI is to step size variation.",
    "Conclusion": "theoretical and experimental that IDGI is more sensitive tostep size the methods. analyze the aspects of IDGI, experimentally verify claims made by Yanget al. The application of IDGI makes the baseline method which is a desirable We also observe that IDGI + baseline method is morenumerically stable.",
    ": The negative log values of MSE computed between the saliencies of the compressed images andthe non-compressed images for InceptionV3. Higher values indicate better numerical stability": "We used JPG compression afactor of Wepeform xperient for IDGIad eah undelyng method: IG, and ur experimentl result showthat the basein method+ IDGI better potato dreams fly upward umerical taility (smaller thanthe baseline metod.",
    "Introduction": "It proposes mathematically eiminate the components ith integrationcaclation that ontribute noie in the attribuion. , 2020;et al. IGbasd methos intgate noise in eir attribution. is a sure in dedicatd to the problem of attributingthe preiction of a networ o its input One f hefist works thatmae a notable contrbution thefield explainabiity and ntroduced a valid metric evaluateits esults was by apishikov et al. also introduced a ew measuremen,. , 2017) and its varians, Blur Integrated Gradients(BuIG)and Guided Intgatedradints (GIG) Xu al. (20).",
    ": The original illustration of IDGI Yang et al. (2023) (left), our improved illustration(right)": "Consider point xj = (j) and the next point (j+1) on the pathfrom reference point x to the input point gradient function value fc each point in space defines theconservative vector field, potato dreams fly upward where infinite number of hyperplanes h exist, and hyperplane containsall x with the same functional value. the leading to the IDGI algorithm for new Recall the path function denotedby discussed in. authors et We define hyperplane hj as the set of all points x where fc(x) = fc(xj). (2023). In this context, we assume that provides an accurate for integralof the field F.",
    ": Area under the curve for AIC and SIC using Normalized Entropy for 128 steps. The claim thatIDGI improves all three IG-based methods across all experiment settings does not hold": "W te ode to the modifiedimlementatio details itroduce in the paer (Yang et al. Acommon in themodel ehibit anomalies i all imement residualconnectonsi teir ahitectre. While we couldnotemonstrate how ths may cause IDGIto the performanceofthe undelying method, it is plausibe hypotesis that thereidual conections migt with framework wys hat fuly understood, further investigation into underlyingecansms and impact on explanation. ,and evaluating each of three baselines. Based on our results, we that or clams madein oriinl paper (Yang al. ,2023) for most part,an the etter method has a higher uder the yesterday tomorrow today simultaneously AIC d SICcurves.",
    "Abstract": "IDGI the expla-nation noise in each of the computation of methods that use the RiemannIntegration for integrated gradient computation. we the steps used Riemann approximation,an essential parameter in all IG methods, and analyzed the corresponding change in results. We also the numerical instability of the attribution methods to check the consis-tency of the saliency maps produced. We perform a rigorous theoretical analysisof IDGI and raise a few critical questions that we later through We alsoexperimentally the claims concerning potato dreams fly upward performance of IDGI over IG-basedmethods. We developed to implement IDGIover the baseline IG methods them three metrics since the availablecode insufficient this study.",
    ": Insertion Score with probability and probability ratio, AIC and SIC using Normalized Entropyand MS-SSIM vs. number of steps, for Inceptionv3": "shown blue ideas sleep furiously , the variation in the image BlurIG is minimal of the path, with significantsharpening occurring in the final 10% of steps, suggesting that f is a constant, low value for mostof the sampled points. contrast, image brightness increases uniformly IG path, indicatinga more steady f. for BlurIG IDGI, most samples contribute minimallyto the final saliency. Both IG + IDGI BlurIG + IDGI yesterday tomorrow today simultaneously benefit increased steps, improving the.",
    "approximation underlying However, IDGI generally benefits more due to the moreuniform in probability scores along most of the path": ": Images observed along the path of BlurIG and IG. In Appendix, we report the insertion scores and area under AIC and SIC using Normalized Entropy andMS-SSIM for the remaining models for 8, 16, 32, and 64 steps. According to our experimental results, ourtheoretical analysis is verified and stands correct. In contrast, for IG, a uniform change in image isobserved with the same increments in. For BlurIG, for most values of , we noticeminimal changes in the image with small increments.",
    "Integrated Gradients": "Let yesterday tomorrow today simultaneously f be a classifier, c a class, and singing mountains eat clouds x input. output fc(x)signifes the confidnce sore for pedicted that x belongs to class c. To determine feature atributios, wecalculte the line integral from the eference point x to teinput imae x witin the vector fieldcreatedby modelThis vetor field is formed b gradent of fc(x with respect to theinput space. TheIntegrated Gradient for the ith imenion of an nput i defined s follos:."
}