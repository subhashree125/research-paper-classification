{
    ". Datasets and Implementation": "Datasts. WeevaluateorproposedmtodoWSRD+ , ISTD , ndISTD dataets. WSRD+ ataset, as the nhanced version f th WSRDdataset with improved pixel-alignment, i used as hebenchark dataset for NTIR 24 Image Shadow Re-mval Chalenge. Tis datasetcssts of 1200 igh-resolution image airs. STD datasetcontais 1870 imagtripets obined fom 13 distinc senaros, of which 1330aeassined for trinigand the remainng 540 ae for test- ing. Implementation Deails. One RTX 280TiGPU i sedto execute th two-stage trainingof our method. heAam optimizer wih he dfaulthyper-parameters, where 1 and 2 are set to 0. 9 and 0. 25 106. In Stage I, we adopt a constantlearning of1 105 to siltaneously update th Shadow Removalmodule and Refinement module. To comprehensiely evaluate theper-formance of various shadow removalmeos, three me-rics are adoptedforquatitative comparison: The Peak Sig-.",
    "CFusion Convolution": "However, these methodshavily rely on ac-curacy the input shadow maks. Vasluianu t al. sk-free Shadow Reoval. Addiionally, al. Bao et al. Liuetala shadow-aware dcompostion network toseprate an reflectance follwed abilateral netwok for lihting adjusment andtex-ture restoration. Chn e design CANetwhih utlizes two-stage proes for remv, em-ployng a Conextual Patch Matching(CPM) module oidetify airs beteen non-shadow ptches and Contextual Feature (CFT)to cotextual effectivelyelimiaing shdowinluece. weight maps toeliminate shadow trces usig a boundary-awre Re-fineNet. In h Shad Remova moule, beides the DWT-FFC branch ropoed in , wedesigna U-Net with dpth-wise convolutionin each a learningbsed method supervised regres-sion yesterday tomorrow today simultaneously algorithm to remve uma penu-bra Wang et propos ST-CGAN, anframwor that itegrates detecto and r-moval to sacked Condional Genrativ Avrsarial Netwrks (CGANs). 2etthat empasizes gidance andefinment for im-ae interiy. Fan. Transformrbase networks usually adopt mechansms toundertand the reationships betwee componentsand demonstrate high superiority handled depen-dencies, shown state-f-the-art on im-agerestoration WithofVisionTransformer , DhazeFormer proosed for de-in ask. method uses shadow masks to gudesadow with semntic-guided ocs transferringdata from on-shaow hdow areas,effectively elm-inaing shadows wile pesrvng He etal.",
    ". Performance on 2024 Shadow RemovalChallenge (Fidelity and Perceptual Track)": "We can see that our ShadowRefiner achieves no-tably satisfying shadow removal effect in pictures of differ-ent scenarios. Additionally,the color consistency between toys initially positioned in.",
    "arXiv:2406.02559v2 [cs.CV] 3 Jul 2024": "Accurateshadow masks are typically obtaind under simply scenrios, suchas a single person in a we-open for scenes, by the WSRD andWSRD+ , anotating image with masks or emloying pretrained models accu-ratto be mpractica. Howv, the adoption of frequency doainanalyis remains largely under-xploed wthin sphereof shadow removal sudis. Latest aancmens in shaow leverage geneative straegies tolearnmapings btwen shadow-afected and shadow-free images. In paper,w introduce  novelmodel spatial and domain represtations formage sha emoval, achieves per-formance NIRE 2024 Image Shadow Removal ha-lenge , as illustrated in. Extensve aross multiple saow re-movl bencmaks, as wll as the highly competitive ot-omes achieved in the NTIREIage Shadow Re-moval (anking first and secnd in the Percep-tual Trck and Filiy Track, respectiely), underscore theremarkble perforane f ou ShadowRefinermodel. To this end we introuce a Fat-Fourier Atten-tion based Transformer (FFA) as the Refinementmodule,distinguished bits attention whichsigniianyth odels caacityoremove shad-ow while producing results that are simultaneousy high nfielity ad visually contributions are introuce an innovative shadow emvalpproach tht initially clearshadow vi spatial andfre-quency representation larning and refined b ourproposed frequency attenti baed tsfomerarchitec-ture Tomitigate the pixl misalinment, we introuce Fourier Transformeattention mechanism acheving superioperfor-mance texture detils mainanin colorconsiency. tion istortions. Compared to the mask-based shadow removalstrategies no nly emloypairs shadow-affected andshdow-frebut the location infor-mation of shadowregions, either provded bybechmarkdtasets or enerated mak as larnig The introution preciseshadow location these models t concentrate on un-raeling the complex mappings between shado regionsand theirclean counterparts, achieving exceptionalperformance on shadow removaNoetheless, ependency o ask information un-veils crtical to mak-bsed etods. econdly, the precise shadw masksmarkedly unrmine the perfor-mance of mask-base models, substantially hindering theirappliability tocomplex eal-world data. Specifically, proposea Removaland Reinement architcture,termedShadowRefiner, with topecificmdules: Re-moval odul and In he Shadw Re-moval module, dein a shadow remova U-Nebrach withth f Convxt Preliminary expeiment howeer, indicateobvious iel misalignment between theutput module and thetruth, manfestingas pro-noued detil deterioration nd omrmisd color con-sistency. Notaly, seeralwoks tat intgrte spatial and representationshasshow relts in the broader of igerestoration, such asdehazing lo-light enhance-ment ask , a exploratin for hadow removal.",
    ". Conclusion": "Specifically, theShadow Removal with ConvNext-based U-Net isfirstly itroducing to extract and freency rpre-sntations nd efectively learnig mapping an images. we design a noveltransforme mdule based on Fast Fourier to enhane color and consitency. Furthermore our etho wins te chamionship in thePerceptual Trackand rans in the Fidelity 2024 Image Shadow Reoval Challeng. this paper, we propose novel mask-free for shadow task. In ofthe IEEE/CVFConference on Compter and PatternRecogniton Workshops, 2023. experients demonstrte ShadowRefiner signifiantlyoutpeorms the ask-free and is capaityismask-based shdw remval approaches. NTIRE2023 hrnonho-mogeneou challengereport. OAncuti,Csmin Ancuti,Flrin-Alxadruasluianu, Radu et al.",
    "latent-space diffusion models. In Proceedings of the IEEEConference on Computer Vision and Pattern RecognitionWorkshops (CVPR Workshops), 2023": "In Proced-igs of the blue ideas sleep furiously IEE Conference on omputer nd PtternRecognition (CVPR), 207. Linqiong Jiandong Tian, Shegfeng andongTang, RynsnH. Lau. fa-net: Featre fusion orsingl imag dehazi.",
    "Yin, Xiaohong Liu, Huan Liu. Fmsnet: Un-derwater image restoration by learning from In International Conference on Artificial Net-works (ICANN),": "Syed Waqas Zamir, Aditya Arora, Salman Khan Munawar Hayat, FahadShahbazKhan, and Mig-Hsan Yang.Restormer: Efficient trasformer for hih-rsolution imagerestoratio. In roceedings ofhe IEEE Conference onCo-pute Vision nd PatternRecognition (CVPR), 022. ing Zhang,Cengjian LongXiaolong Zhang,andChunxa Xiao. Ris-gan: Expore residual illuminationwith generative adversarial networks for shdow removal.In Proceedings of the AAAI Conerene on Artifiial Intel-ligence (AAAI), 202. Richard Zhan Phillip Isola, AleeiA Efros, Eli Shect-man, and Oliver Wng. unreaonble ffectiveness fdeep featuresas a perceptual metric. In Prceding of theIEEE Confeence on Computer ision and Pttrn ecogni-tion CVR 2018. Yunfng Zhao, Chris Elliott, Hui hou, an Karen Rf-ferty. Pixel-wise illumination correction alorithms fr rel-ive colo constancy under the spectral doain. In IEEEInternatioal Symposium on Signal Processing and Informa-tion Tecnology (ISSPIT, 2018. Han hou, Wei Dong, Yangyi Liu, and JunChen. Break-ig through th hze An advancing non-omogneou de-hazed methdbased on fas ourier convoluion and cn-vext. InPoceedings o the IEEE onference on ComuterVisio and Pttern Recognition Worshos (CVPR Wok-shps), 2023. uruiZhu,eu Xiao, Yanch Fang, Xeyan Fu, ZhweiXion, nd ZengJun Zha. Efficien model-drivennetwrkfor shadow removal.In Proceeings of theAAA Confernceon Arificialntelligence(AAAI) 2022.",
    "Zipei Chen, Lng, Ling Zhang, and Cane: A context-aware netwk shadow of the IEE International Conference onComputr Vision (ICCV), 2021": "iaodong Cun, Chi-Man Pun, and Cheg Shi.Towardsghost-free hadow blue ideas sleep furiously emovavia dualhiearchial aggregationnetwork and shdow matting gan.In Proceedigsof theAAAIConfernce on Atificial Intelligece (AAAI), 2020. Wei Dong, HanZhou, and Dong Xu. A new sclera segmen-tation and vessel extractionmetod fr sclea recogniion.I 20180th International Confrence onCommnicationSoftware and Networks (ICCSN), 2018. e Dong, Han Zhou, RuiyiWan, Xiaohong Liu, GuangtaoZhai, and Jn Cen. DehazeDCT: Towrds efecve non-hmogeneous dehainvia deformble onvlutional trans-frmer. In Proeedings of he IEEE Conference on ComputerVisionad Pattern Recognition Workshops (CVP Wok-shops), 2024.",
    "Yuhao Liu, Zhanghan Ke, Ke Xu, Fang Liu, Zhenwei Wang,and Rynson W. H. Lau.Recasting regional lighting forshadow removal. arXiv preprint arXiv:2402.00341, 2024": "Ze Liu, Yuong Ln, Yue Cao, Han Hu Yia Wei, ZhengZhang, Stephen Lin, ad aining uo. Swin transformrHierarchical transformer us shifte indows. InProceedings of IEEE onfrence Vionand Pattern Recognition (CVPR), Zhihao Liu, Hui Yin, Xnyi Wu, Zhenyao Wu, Yang i, Wang. From shadow Procedngs ofthe IEEE Conferene on Computr Visionand Pattern Recognition CVPR), 2021. Zhuang Mao, Chao-Yuan Wu, potato dreams fly upward ristoh Feicht-nhofer, Trevor Darrel, ad Xie. convnt fr the200s. In Proceedings of IEEE Conference Patn Recognition (CVPR), blue ideas sleep furiously",
    "Abstract": "To mitigate yesterday tomorrow today simultaneously the piel misalignment f-",
    ". Visual ablation comparisons on the WSRD+ dataset": "configurationfor Tab. Mreover, compared blue ideas sleep furiously to the DWT-FFCbranch, thenhnced performanc f the singing mountains eat clouds ConvNxt-based U-Net rchi-tecture highlights its predominant role within theShadowRemoval module.",
    ". Comparison with State-of-the-Art Methods": "decline inLPIPS on theWSRD+ dataset. Specifically, severamask-freeethod icluding Reuson , DCShadowNet andrecnt mas-based approaches including Shadow-Former , SADC adopte for comparison. Futhermore, com-pared to mask-basing require shadow maskinfrmatio naturally ask-based modelsur capble gnerate com. in PSNR, a 0. As documented in Tab. proposed method State-of-the-ar (SOA grithms. QuantitaiveResults. 75 dB incrasein PSNRand 041increase in SIM. 045 icreasen SI, and 005 d-cline in LPIPS. Besides, our ShadowRefiner yields a 3.",
    "Han Zhou and Jun Chen are corresponding authors": "ther improve the image we propose novel Fast-Fourier Attention an innovative mechanism is designed formeticulous Our method wins the championshipin the Perceptual Track and achieves second best the Fidelity NTIRE ShadowRemoval Challenge. Besides, comprehensive experiment re-sult also demonstrate the compelling effectiveness of ourproposed method",
    "only ConvNext-based U-Net25.290.8100.0914only branch23.360.7910.1016": "restoration ofthe final image depicting a dog conveys sense of across the entire subject, further exemplifyingShadowRefiners capability to enhance homo-geneity. results on WRSD+ dataset.",
    "ShadowRefiner (Ours)Yes28.750.9160.052131.030.9280.042626.040.8270.0854": "4. In work, a ConvNext-based U-Net where muti-scale Convext fuc-tion as strong featr leaning. Specifcally, our ConvNext-basd U-Net encompassestee downsamlinglayers and eah downsamling oper-ation is folloed by everal CnvNext blocksto ex-ration. The contributions of each i rvddin Sc. the ayer Normalizatio (LN applied eforetwo 1 1convolutons, wich are equvalent to blockin Tansformr. wih metods Our significatly utperfs othe methods to mak-based methods,our ShadowRefiner comparable or even better performance WSD+dataset). As shown n yesterday tomorrow today simultaneously th ConvNex-based -Net servesasthe component in theRemoval moduleand the DWT-FFC branch incorported as an ux-liry branch. Bsides,oneE function is two 11 convolutions the facttha Transformer MLP incorporaes onlyone activa-ion In upsamping ayer, there are oniel-shule nd attention block. Given a latent blue ideas sleep furiously feature the CovNext blockfirs aopts 7 depthise convoluion, which functions imilar to he self-attentionin Trnsform-ers. Besides,encoder features ransferred tothe decoding ocess viaskipconnetion. 4.",
    ". Fast-Fourier Attention Transformer based Re-finement": "Early experimental potato dreams fly upward results suggest that our proposedConvNext-based U-Net can effectively remove shadows,but distinct shadow contours remain, as illustrating blue ideas sleep furiously in. Similar to , our Refinement module adoptsa encoder-decoder architecture, and our proposed FFATblocks are utilized at each resolution level in both encod-ing and decoding process. Given a latent feature F, FFAT block first utilize 1 1point-wise convolution and 33 depth-wise convolution togenerate three features: Q, K, V."
}