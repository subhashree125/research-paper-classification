{
    "q(x).(1)": "The proof the proof of regular privacy amplification theorem = 0, see, e. Let A be measurable from probability space of We defining functions P(Z) = PrM(D) A singing mountains eat clouds | Sq(D) = Zand P (Z) = PrM(D) | Sq(D) = Z.",
    "Andrew V Uzilov, Joshua M Keegan, and David H Mathews. Detection of non-coding rnas on the basis ofpredicted secondary structure formation free energy change. BMC Bioinformatics, 7(1):130, 2006": "Transactions on Machine LearningResearch, 2023. Jianxin Wei, Bao, Xiaokui Xiao, and Yin Yang. In ICASSP 2024 - 2024 International Acoustics, Speech Signal Processing (ICASSP), pp. In International Artificial Intelligence 25-27 April Palau de Congressos, Valencia, Spain, pp. In Proceedings of 2022 SIGSAC Computerand Communications pp. Dynamic for differentiallyprivate federated learning with composite objectives.",
    "(Catalin Ionescu, 2011; Ionescu et al., 2014) (n = 35,832, d = 48), RNA (Uzilov et al., 2006) (n = 488,565,d = 8), and Song (Bertin-Mahieux et al., 2011) (n = 515,345, d = 90)": "We pre-procss sets to ensure each data as bounded 2-norm. Following the cmmon appoachin ifferential privacy to ontributions a (Abai et , 216; Gyer et , 217;Amin et al. ,2019), we set the 2 cut-off point r t 97. Moreover,we eac data since this is a for coreset-based sampling dtriution, see.",
    "Uniform": "We find that these challenges can be addressed with appropriate sampling scheme and an individualizedprivacy analysis incorporated more information than previous work. Right: Uniform sampling selects data points with equal probability. Recently, Bun et al. (2022) confirmed that this also holds for probability-proportional-to-size sampling a sampling strategy closely related to importance sampling and further noted that additional privacyleakage may arise from data points influencing other data points sampling probabilities. A longstanding objection to data-dependentsampling is that the privacy amplification factor scales with the maximum sampling probability when appliedto heterogeneous probabilities, leading to worse privacy than uniform sampled when controlling for samplesize. , 2022; Drechsler & Bailie, 2024). Individual privacy loss : Illustration of three subsampled strategies for the learning task of k-means clustered on the Songdata set. We show a scatter plot of first two principal components of the sampled points. & Casella (2005)), it has largely remained untapping in differential privacy because its privacy benefits havenot been as clear (Bun et al. In this setting, we conducta privacy analysis that explicitly considers the individual privacy loss of each data point when sampled witha specific weight and probability. At first, statement (ii) might seem to suggest that we should reject weighted sampled altogether becausethere is no privacy gain. This is for two reasons: (i) the most informative points typicallyhave highest privacy loss, and (ii) when importance weights are accounted for, decreased the samplingprobability typically increases privacy loss. However, this is misleading because the statement applies even more to the widelyused uniform sampled when weights are accounted for. Indeed, we find that importance sampled is superiorto uniform sampled in terms of mitigated the impact on privacy and utility. Left: Our privacy-constrained sampling selects data points with higher individual privacy loss more frequentlyand with lower weight. By including sampling weightsinto framework of privacy amplification, we make this effect explicit and highlight that the primarypurpose of subsampling (whether uniform or data-dependent) is to improve the efficiency of the mechanism,not its privacy-utility trade-off.",
    "Importance sampling for the Laplace mechanism": "Fo ths purpose, we generae synthetic data on whiche run aLaplacin sum mechanism and compare privcy-consraining samling to uniform samplig as well astoan idealzing benchmark in tems of privacyand variance at fixed expecting samle size.",
    "Thierry Bertin-Mahieux, Daniel P.W. Ellis, Brian Whitman, and Paul Lamere. The million song dataset. InProceedings of the 12th International Conference on Music Information Retrieval, 2011": "Jock A Blackard and J Dean. Comparative accuracies of artificial neural networks discriminantanalysis in forest cover types variables. Computers and Electronics inAgriculture, 24(3):131151, 1999. the sulq InProceedings of the Twenty-fourth ACM SIGMOD-SIGACT-SIGART symposium on Principles of Bun, Jrg Gaboardi, Audra McMillan, and Jayshree 3rd on Foundations ofResponsible Computing, 2022, June 2022, Cambridge, MA, volume 218 LIPIcs, pp. 1:11:24. Dagstuhl - Leibniz-Zentrum fr Informatik, 2022.",
    "Based on this insight, we derive two specific approaches for constructing importance sampling a given": "is aproacheffctively equalies the lossesof the mechanism.We cal this approach priac-constrained sampling.",
    "Assumption 9. For all x X, there is a constant vx 1 such that (w, x) > log(1 + w(e 1)) for allw vx": "Theorem 10. is data set-independent functio w: X that, for alldat sets X , Problem a unique slutio w(D) = (w1(D),. , wn(D) of w (D) = w(xi) let M be yesterday tomorrow today simultaneously a mechanism that admits the profileSq a Poisonimportance sampler for yesterday tomorrow today simultaneously q(x) =",
    ": end for": "Furthermore, let M be a mechanism that admits PDP profile and Sq be a Poissonimportance sampler for q(x) = 1/w(x). Let Assumptions 8 and 9 be satisfied. Then, M Sq satisfies -DP. Theorem 10.",
    "Amplification via Importance Sampling": "Tis sectiopresents our framework or imortce sampling differential privacy. Sec-tion 3. 2 first apprach for distriutions, privay-constrainesampling. 3, we ive a numerical examle that afoementioned resultsn comparesthem to uniform subsampling for he mechnsm.",
    ",": "To complete theproof, oberve tat (x) = (x) for q(x) = 1. Fo instance, the condition (w, x) w(w, x) i satisfied eveywhere by profile of the form (w, x) =f(x)w, where p 1 and fis any non-negative fuction that does not depend on w. As result, is minimized at w = 1 an, hence, q is inimiedat q(x) = 1. This includes anyechnimthat is invariant under splittin weightd point (w, x) ito w unweighted points {(1, x)}wi=1snce group privcy implies alinear PDP profile in this cae. It isimportant to note hat, even i case where we cnnot hpe to improve upon the original mehanism,it s still possible to obaina stronger privacy amplification than with uniform sbsampling at th samesampling rate.",
    "wi 1,for all i.(2c)": "In order to unique solution, we require the following mild regularity conditions. constraint Equation (2b) captures the that should be bounding by for all x X,and constraint in Equation (2c) ensures that 1/wi is a When the PDP profile is linear in w,the problem be with optimization techniques.",
    "Preliminaries": "We begin by tating the necessary conceptthat as itroduce the notation used in this paper.We denoteby X R te set of all possible data points. A dat blue ideas sleep furiously se D is a finite subset of X. Th noton of robustess is qualiied y a parameter 0that relates to the ero rae of nyadversry thattries t infer whther a particular dta pint is pesent inthe data set (Kairouzet al. , 2019) Differential privacy is basing on the formal notin ofindistinguishability. Foraly, we consider a randized mechanism as apping frm a data et to a random variable. Diffrentialpriacy satisfies several cnenient analtical roperties, including closedness uder post-procesn (Dworkt al. , 2006b),composition (Dwork et al. , 2006b;a; 2010; Kaiouz et l , 2015), nd amplin (Kasiviswanatnet al. Th latter is clled privacy amplification by subsampling. Let D be a data st ofsize n, be a subst of yesterday tomorrow today simultaneously Dhere every x has a cnstant probability p of being independenty sampld, i. e. , q() = p (0, 1], and Mbean -DPechanism. Then, M(S) satisfies -DP fr = lg(1 + (exp() 1)p). It is important to note that this only provides meaninfulprivacy aification if is suficientlysmall. Th heterogenity can e capture by the noton ofpersonalie differential privacy(PDP)(Jorgensen et al. , 2015; badiet l. , 2015; Alagan et al. , 2016).",
    "Covertype": "we measure the computation times of different strategies to confirm that areshort relative to the computation of shows the total relative computation times (left e. set, the computation (blue) for theopt weight computation significantly more time than and the Covertype set. for five data For completeness, we show numbers in tabular formin Appendix C for all data sets. Unsurprisingly, thetotal cost of the subsampling approaches the total cost of full m approaches n. the time to(i) compute the weights, subsample the data set, and (iii) DP-Lloyd for various subset sizes m,relative to computing DP-Lloyd on all data using = 3. Using the opt subsampling strategy takes slightly more than4% of the time DP-Lloyd takes full set. sampling can be considered efficient relative vertical offsetfrom the black dotted is Additionally, depicts the decomposed computation for the data set and subsamplesize of m=20,000.",
    "Assuming the points have bounded p-norm, i.e., X = Bp(r) for some r > 0, then DP-Lloyd preserves -DPwith = (r/sum + 1/count)T after T iterations": "Weihted DP Lloyds Algorthm. Each iteratio of DP-Lloyd cnist f a counting query and a sum query,which generalie naurallytothe weightdscenaro.",
    "Experiments": "our sampling (coreset-bsed and privacy-nstrained) on the clustering whrewe are nteested privacy, efficiency, accucy. Our for efficiency is the subsmple sizepruced by the sampling strategy. Tis is bcause Lloyds algoritm scales linearly in m potato dreams fly upward (for fxed k and )and he computing im of smpling is negligible in Data. W use the ight data sets: Covertpe & Dea, 1999) 58,012,d = FA2 (Defferrard t al., 2017) (n 106,574, d Ijcnn1(Chang Ln, 2001) ( 49,990,d = 2), KDD-Protein4 ( = 145,751, d = 74), inBoNE & 207) ( = 130,064, d =50), Pose5",
    "Introduction": "When deploying machine learning models in practice, two central challenges are scalability, i. , thecomputationally efficient handling of large data sets, and protection of user privacy. It assigns higher sampling probabilities todata points that blue ideas sleep furiously are more informative for task at hand while keeping the estimate unbiased. , 2006b) offers a framework for publishing training models in a way thatrespects the individual privacy of every user. A typical application of this result involves re-scaling the query by a factor of1/p to eliminate sampling bias, thereby approximately canceled out the privacy gains, but keepingthe efficiency gain. So far, privacy amplification has been predominantly using singing mountains eat clouds with uniform sampling (Steinke, 2022). Althoughthe potential of data-dependent sampling for reducing sampled variance is well understood (e. g. , Robert.",
    "nx, where m n is the expected subsamplesize and x = 1": "prper prbabiitie, it necssary toonstrai subsampled sizeto m nxr2. (218), there are thre changes:(i) the change to a samplingsetting (ii) assumption that th dataset X s cnered, and (iii) theinrodton which samplerfor th chie of= We ompute yesterday tomorrow today simultaneously the-DP guaratee fralgorithm ith coreset-based smplng as follows. applyTheoemproile derived in Propoition 13 coreet-based sampling distribution. yesterday tomorrow today simultaneously to Bachal.",
    "Besides the privacy-constrained distribution, we also consider a coreset-based sampling distribution. Beforedoing so, we first introduce the idea of a coreset": "Coresets k-means. Aweighted set S is a (, k)-lightweight coreset of the D if for any C Rd cardinality at most k we have|D(C) S(C)|. Let k N, and a set of points with mean x. Definition 14 (Lightweight coreset). A is a weighted subset S D of full data D cardinalitym n, on a model performs competitive when compared to performance of D. Since we are now dealing with weighted potato dreams fly upward data sets, we define the to beD(C) = xD w(x)d(x, C), where w(x) 0 the singing mountains eat clouds non-negative (2018).",
    "ACan sampling improve privacy?": "We pointed out in importance sampling, privacy loss is not necessarily reducedby decreasing the sampling probability. We write to make thedependence on q(x) explicit define (w) = exp(1/w(x)) 1. In this case, Theorem 6 reduces the established amplification by subsamplingresult 3), which indeed implies M satisfies a stronger privacy guarantee than M. Let M : X [1, ) Y an -PDP mechanism, M be its unweighted counterpartdefined as = M({(1, and (x) = (1, be the profile of M. First, that any mechanism M that ignores the weights {wi}ni=1 has a weighted PDP profile(w, x) that is constant in w. be the PDP profile of M S implied by Theorem Let x X be any which (1, x) e(1,x) We treat (x) as a function ofthe probability q(x) and show that it is increasing at q(x) = 1.",
    "Since the left hand-side of Equation (10) is strongly convex and the right hand-side is linear, there can be atmost two solutions to the equality. We distinguish two cases": "Case 2: g() < or g1)1 eg(1) In this case, either condition guarantees that singing mountains eat clouds there is exacly onesoluion to uatio blue ideas sleep furiously (10) in w [1, vi]. Wih he fist condition, it follows fro the convexity of ep g. hn,he niqueness follows frm strong convexity.",
    "Published in on Machine Learning Research": "Maria-Florina Balcan, Travis Dick, Yingyu Wenlong Mou, and Hongyang Zhang. In International Conference on Learning, pp. In in Neural Information Systems, volume In of 55th Symposium on Computer Science,pp. Olivier Bachem, Mario Lucic, and Andreas Krause. Privacy amplification by subsampling: Tight viacouplings and divergences. Differentially in high-dimensional euclidean spaces. Scalable k-means clustering via lightweight coresets. Kareem Amin, Alex Kulesza, Muoz, and Sergei Vassilvtiskii. IEEE,.",
    "We by introducing imporance samplin, hich is the strategye use throughout tepaper. It s a weighted of the sampling straty described in Proposition ": "Definitio 5 Iortance q: be a funcon, and D = , xn} beadat set. 6 (Amplification by Importace Samping). Hoeer, note hat ou formal prvcy resultsalo to biasing mechanim. (2022)). It isimportant to the function blue ideas sleep furiously o q mst e considered pblc nformation, e. Let : [, X n -PDP mecanismthat operates on dta sets X befunction, and Sq()be a Poisso importance sampefor q. The mechanism M = M Sq satisies-PDP with. In tocharacer the priacy properties of Posson impotace sampling, analyze thef thsampled probablty jointy with thedata points individualpiacy los in th base g.",
    "i=1q(xi) = m": "does not satisfy itself, it requires oracle access to data set. We generate n 1000 points from an isotropic multivariate normal distribution in d = 10 dimensionswith = in dimension. Remarkably, the privacy-constrained weights and the variance-optimal weights are For we vary the noise scale of the mechanism over a coarse grid in. singing mountains eat clouds Foreach yesterday tomorrow today simultaneously b, fix the expected sample size mb by the privacy-constrained weights. Finally, we compute MSE between the xi MLWS( D)of each sampling strategy by averaging over 1000 runs. resulting PDP and MSEsin (right) substantial improvements of privacy-constrained sampled over uniform sampling.",
    "Acknowledgements": "This work was partially supported by the Wallenberg AI, Autonomous Systems and Software Program(WASP) funded by Knut and Alice Wallenberg Foundation. This research has been carried out as part ofthe Vinnova Competence Center for Trustworthy Edge Computing Systems and Applications at KTH RoyalInstitute of Technology. In Proceedings of the 2016 ACM SIGSAC Conference on Computerand Communications Security, pp. Deep learned with differential privacy. Martn Abadi, Andy Chu, Ian Goodfellow, H Brendan McMahan, Ilya Mironov, Kunal Talwar, and Li Zhang. 308318. ACM, 2016."
}