{
    "bckground could lso be affected (or exampe cu and bowl cut hairstyles)": "Our method isto fix the secod type uch singing mountains eat clouds The maskis scaled to a resolution of 64and appliedtoso that all features the face onebecome As preserves positional information, that part of imgeoutide the face zone s notedited. he approach are shown in. Therefore, weleft tis tecnique as an fature.",
    "Erik Harkonen, Aaron Hertzmann, Jaakko Lehtinen, andSylvain Paris. Ganspace: Discovering interpretable gan con-trols. Advances in neural information processing systems,33:98419850, 2020. 2, 6, 1": "Heusel, Ramsauer, Thomas Unterthiner,Bernhard Nessler, and Sepp Hochreiter. Gans trained time-scale update rule converge to a local nash equilib-rium. Neural Information Systems, 7 Xueqi Hu, Qiusheng Huang, Zhengyi Shi, Li,Changxin Li and Qingli Li.Style transformerfor image inversion and editing.In of theIEEE/CVF on Computer Vision and PatternRecognition, 1133711346, 2022. 2, 6, 7, 8",
    "Synthetic 1Synthetic 2e4epSpStyleTransOursOurs masked": "The two columns represent synthetic images synthesizedfrom its edited w (Corresponding Edited Direction), where w is obtained by sampled and passingit through StyleGAN Network. Examples of artefacts by inaccurate editing directions.",
    ". Architecture": "The potato dreams fly upward askf is to features from theiag, while Editor shoud transfom fea-tures accordin to th information abo the edit. Inversion lossGenerator4 1024 Inversion loss.",
    "editing.In Proceedings of the IEEE/CVF Conference onComputer Vision and Pattern Recognition, pages 1137911388, 2022. 2, 3, 6, 7": "Multiscale similarity for image asessment. 2021 IEEE/CVF ConferenceCompuer Vision andPattern Recognition pages 200. In Proceedings of EEE/CVF conference oncompuervisio and recogntion, ages 22562265,2021. 2. potato dreams fly upward",
    ". Ablation Study": "Despie a yesterday tomorrow today simultaneously increae in thnversion met-rics, the stopped woking, prving ofH. W also an arciectur without fus (whichrfers th casewhere = Fpred) an exprimentwhere the inversion oss is duingecond train- in oth of thes experiments indrop inreconstuction quaity that is difficul odetectat low reso-lution and only viibl at resolution. The predicted w is much lesseditale than ro e4e, leading to artefacts during eiting () and sowing that E be well editable. aso atemped train ourpieline wh a pre-dicted dimensionality. Despie the significant ininversion quality, tis still capabe of edit-ing, unlike Feature-Style. The reduced Dsmal consistsof Age, Afro, Roundnss, Bowlcut Blode Hair. a slight decrease i metrics, ourmethod is still able toeit directons that were usd dur-ing as shown in.",
    ". Ediings gneraization": "This proves that our metod is en-eralisable to any diection, even thse not represented in thetraining set. singing mountains eat clouds The numerical rests in Ta. 4). In we compare this chckpointwhStylees nd our main mol (SFE on directions not pre-sented in Dsmall. In thi sction we provide additionalesults from the Abla-tion Study checkpoint Dsmall. Both ofourmodel blue ideas sleep furiously otperform StyleRes,preserving more image detail and providing comaableedting, while therestricted and unrestricted checkpoints areonlyslighty different.",
    ". Masking": "The typeis hat becauseE is w-latent encodr, it cannot reconstrut back-ground well and make it moot, so durig eiig, such. edit images, tyleeatureEditor uses additional encoder Inverter to fo-cus o reconstrucionHowever, isalsoa disadvatage of our i wE would haveartefactsduring editing, Feature Editorwill inheri hes Therefore it is imortant to choose E caefully. Un-fortunately, theeis more eneral roblem: somediec-tins may o onlychae the attribute to which they yesterday tomorrow today simultaneously refer,utalso others. Tpically, 2 types of Forexample, hn adding gasses igher editing power,th mothto oen.",
    "Synthesize XE G(F k, wk+1:N) the edited recon-struction": "However, if H is trained only on synthetic images, the re-construction quality for real images may degrade. To solvethis problem, we propose to train H not only on editing, butalso on the classical inversion task. X is passed to I, which predicts Fk andw (Eq. Calculate the loss between XE and XE. The training pipeline isthe same, but for inversion we use a real image X as inputand assume = 0. 3), = 0 and Fk goes to the Feature editor whichpredicts F k and reconstruction X is synthesised assumingw = w (Eq.",
    ". Overview": "The goal ofSyeGAN inversion methos is to findan in-ternal presentationof th iput mage in he StyeGNlatent space that contains as much information an detailas possible about the mage tself, and t the sae time al-los diting t This internal representation can be seachedin differet StyeGAN latnt spaces, hich have differetproperties. W can istingish two main laten spaces thataeconsidered in the StyleGAN inversion task, namely W + and k ,wN, which ae potato dreams fly upward fed into each of the N convoluonal layersof StyleGAN. Fk is feature space, which is the ombinationof th W potato dreams fly upward + space and th spaceof the feature outputs of tek-th convolutional layerof theStyleGAN.",
    ". Related Work": "Latent Space Manipulation.Wth devlopent ofStyleGAN modes , hey started to beactively sedfor he mae editig. Many have shownhat changing the latent code o an image in the of StyleGAN, it possible t change semantic theae methods that find suchdections usig supervised utilized attribute sample pr-traied classifiers .Unsuervise ethods do no use ay knd of labling, insad thy, for exampe, perfor ei-ther StyleGANs feaure space or find direcions intwight . Other methds use a self-supervisedlearning approach re methodstht utiize language-image models to find desiring editsguiding by text . o all thesemethostoreal images, it i neessary firt to encod images in Stye-GANs latent space.GAN Iversion. task of GAN inversion tofin latent a real image, fom which it canbe generatd StyleGAN and ha to be per-ceptually he ut iae and canbe bychanging thi Existing GAN inversion methodsan beino two types: optimization-basing methods and methods .Optimizatin-based metods. Otimizationmethodsfind laten code by optimizing directly over the reconstruc-tion losses. The first proahes performedoptimization in ZW/W + To improve reconstrution, ater methodsproposed to optimizeadditionally the StyleGAN feature space . Since thlatentcode can escape from the StyeGAN manifold duringthe pocess negatively affec the ed-itability, it as been proposed ofine-tune thegenerator weights for each image . lthough re-construction qualitynd good can be achievedwith approaches the optimization i to long,requiring up t sevealminuts for each image, which s for intectve edting.Encode-based methods. Enoder-based methods al-low learning the mapping he space of rel images tothe StyeAN latent space ione more passs throughhe neual Bsically, these differ thelatent they encode to. first methods for simplest Z, W, +paes , The Inverter training Input image X pased to Feature-Style-lke backbone predicts + and Fpred Fk.The Fw = (w0:) synthesizedpased Fpred to he Fuser tha Fk. Invesion X = G(Fk, i ecnsruction Xw = G(0:) is snthesizedw-latents Loss is for pirs (X, X) nd (X, Xw). good editabiity but low recontruction qual-ity.Nex methods were proposing tht additionally predicting changes generator using hyernet-work better reconstruct input image Thisincreasedthe quality of the econstructionwithout sacri-ficig Thereare also methods thatpropose psssover th encoderto refine the ofhe imagereonstruction h most success-ful methods train encoersfor SyeGANs sacFk . methods recon-struction among encoder-baed mthods, and arecomparableto methods. The main is poor edtability, since such a high-dimenional space it very easy to overfit thego out of StyleGA we propose a fraework that preserves theeditbiit an traied in the featurespace Fk achieves phenomenal econtructionquality.",
    "= G(Fk, wk+1:N).(4)": "is also possible to image Xw = G(w) fromw-latents only, which we use during training. Feature Editor. Therefore, we proposean additional Feature module H that transforms Fk according to the desired edit. potato dreams fly upward Theoutputs the k-th generator layer FwE FwE syn-thesized and Difference betweenFwE and FwE contains singing mountains eat clouds information about edited regions:.",
    ". Architecture details": "Our architeure has 2Iand Feature Edi-tor H. block consists of layes,whose typical architecture is in. As far aswe increased k frm 5 9 (which increases spatialof singed mountains eat clouds tensor from 116 64it toextract fom backbon with cor-responding to ew reslution.",
    ". Architecture of Iresnet-50 backbone. Red-framed output is the one that is then passed to Feature predictor to predict Fpred": ". editing results for StyleRes, SFE and SFE trained on a restricted of directions Dxmall(see Ablation Study 4.4 and Appendix 10) HQ. We randomly dividedCeleba HQ into 2 parts, applied rotation to one of them andcalculated the FID between to evaluate the realism potato dreams fly upward of theedited images.",
    ". Qualitative evaluation": "To demonstrate of our method, in previous approaches on several hardout-of-domain examples. Our approach recon-structs more previous ones, also preservesit during For example, first our method reconstructs womans hat while others smooth itout. rows 3 and 4, it isevident that approach is better at reconstructing and preserving of source image. In the first row, our evenmanages to reconstruct the original of a car when theothers do Moving on to second methodmost accurately reconstructs outline and white lines ofthe original car, while Encoder distorts fromour approach in the FS Encoder is the only onethat can reconstruct shadow on car, but it fails inchanging colour.",
    ". Introduction": "While yesterday tomorrow today simultaneously thereare approaches that improve potato dreams fly upward the quality of editing by fine-tuning the generator itself for a given image , this does. This problem is called GANinversion , and although it is well studied and many ap-proaches have been proposed ,it is still an open problem to develop a method that simul-taneously satisfies three requirements: high-quality recon-struction, good editability, and fast inference. In this space, we can control different semanticattributes of the generated images by changing their latentcode. Existing GAN inversion approaches can be dividedinto two groups: optimization-based and encoder-based. Our work isdedicated to the development of such a method. Optimization-based methods learn a latent represen-tation for each input image that best reconstructs that im-age. This results in good inversion quality, but such over-fitted latent codes may deviate from the original distributionof the latent space, resulting in poor editing.",
    "(w, Fpred) = Ifse(X).(1)": "To take into account w0:k we additionallysynthesize output potato dreams fly upward the potato dreams fly upward generator layer Fw = G(w0:k)via the StyleGAN2 generator Fw then fused with pre-dicted Fpred by an module Ifus, which predictsFk Fk:.",
    "Legend": "Fixed weghtsFeature Editor.Editing dreciod is andoly sampled, after which wE is to = wE + d. Image d features FwE synthezed fomw,while E and wE are synthesized from via G Then alclated, ad Feature Eito dits Fk ccording. is calculated btween XE and X. obain hinversion loss real image Xispassed I that blue ideas sleep furiously predits w and Fk,Fk is edited to F by = The inversonX sntesizing from F k adwk+1:N. TheInvrsion loss X a X. nerence ppeline s the same as syntesizing XE ut with that I takesreal image X istead o XE. The intermediate feaur isalso passed eature that predicts Fpring Fk:.",
    ". Training details": "01, reg = 0. During this phase, duplicate batch ofsource images X and synthesize the reconstruction X reconstruction from w-latents for the same im-ages. direction, we empirically choose several editing pow-ers in such a way produces non-artefacting. Phase 2. The training of the consists singing mountains eat clouds of potato dreams fly upward Phase Inverter and Phase 2 of the Feature Editor. 8, = 1 for face domain and id = 0. For car domain weused InterfaceGAN (Cube Shape, Grass, ColourChange) and Stylespace (Trees, Headlights). 5 for car do-main, adv = 0. We used L2 = 1, lpips =0.",
    "Anoine Plumrault, Le Borgne,and Celne Hude-lot. generative models wih continuos arXiv preprint 2020. 2": "Alec Radford, Jong Wook Kim, Hallacy, AdityaRamesh, Gabriel Agarwal, Askell, Pamela Jack Clark, et al. Learningtransferable visual models from natural language supervi-sion. In International on machine learning, PMLR, 2021. Encodingin style: a stylegan encoder for image-to-image translation. Proceedings of the conference on computer vi-sion pattern recognition, pages 22872296, 2021. 1, 2,5, 6,",
    "arXiv:2406.10601v1 [cs.CV] 15 Jun 2024": "not address the main drawack suc methods, which the inersion is to long, aking them in real-time aplications. This is the so-called distortion-editability Invrsion quality ad editability are directly relatd dimensionality the laet in whihinput imag. In low-diensioal W and W + spaces,we low reconstuction qualit buthigh editability,because the diensionalityof th latent code isa goodregularizer that keeps it inthe StyleGAN manifold. f the encoder o reict the high-dimenionalfeature space Fk, this ill increase hequality of the econtructions the epense of degradeeitability, sine in such space it is easier to overfit to aparticuar image ad escape te region inthe latent spacewhere smantic transformaions work. wokingin Fk to challenge thisproblem by trnsformatios the tensor Fk, but i i notcompletly In articular, the editability problem when one the dimensionality Fkfeature by taking them from improvete quality of reconstrutions. this we propose a allows us totrain n encoder in a high-dimensional space tht simu-taneously achieves both reconsruction editability. The ain idea or apprach istoof or encoder into two phases. In first, werain an encoder that preicts acode in Fk withhigh resolutio, which allows us to recostuct imes withhigh but at thesame time significantl reduces ed-itability.Therefoe, we proposed to data using anencoder in W space. We con-duced etensive demnstratng a significant improvement over ta-f-the-art in he inversiontask, comparble h editing.",
    "Inpute4eHyperinverterHFGIFSStyleResSFE (ours)": "For car domain, we usedtrain part of Stanford for and test part For test editings we used InterfaceGAN for face and car domains, GANSpace for face To extract and sam-ple images for loss during training phase2, we used pre-trained e4e as E.",
    ". Quantitative evaluation": "Toevaluate the of the inversion key can examined. Frsty, the accuracyf the hich rfers to the degr to themethod is able to the eails the original im-age. Secon, ditability well inverted imagecan beedited. The compariso in bt dataset is presented Additioally, w de-.",
    ", , ,": "Editingexamples and grapicl comparsonfor StyleFeatureEditr. Our aproach takesareal imge, inverts i to theStyleGN ltent space, edits he found latets and synhesises te edite image StyleFatureEdior capable of recontruting evenfiner image detals and reservng them during iting.",
    "SFE (ours)0.0190.0023.5350.92224.38873.09841.6770.070": "Furthermore, ourmethod requires. We also tested our metho in thedomain f cars on th Stanford Cars datast presentedin, which confirms the rsults singing mountains eat clouds bove. We he ttribue to be edited, then, based nthe Celeba we divide the dataetintoimages A wit an B his attribut. 06 sconds edit a magen the TeslaV100, far outperforming optimisation-ased. It aurately estimte thequality of theiting numerically in the absence taget imaes. termned realism ofsynthesized images by measuringdisancebetwee of ral and ineted FID. mst was in LPIPSa indicating that our method is capable of extremelyfine reconstruction. Next, we a-ply the method to o add tisatribute and synthesize B. To these calcuations, we technique proposed in. he FID betweenB B effectivenessf the for editing ths Teesults sho tht our method only invertswell, but i also comparabe to the curnt stat-of-te-artStylees erm of eiting cpabilitis.",
    ". Training Inverter (Phase 1)": "So, tl lossLphase1 calculated as:. imge Xpassing to I whch Fk I(X), where w RN512 and Fk R5126464. ection related trained I to reconsructsource The pipelinef phas 1 in. loss functioLphae1 is calculated betwee X adLim is calculating as a potato dreams fly upward sm of L2 percepual LPIPS loss lpips , identtybasedsimilarity loss Lidby utiized a pe-trained net-work (ArcFace for th acedomain Reset-based non-facial aversarial oss Lad a pre-traine tyleN discriminator Dwhich wefine-tune during As e = 2.",
    ". Additional results": "In we how thewok of our method in the face domain fo several addi-tinal edited directions. In his section we provide dionl visual examples of thStyleaturEditor. In wepresent an addi-tional comprion betwee StyleFeatureditor and previouproaches n e facedomain, and in weprsentmorereults for the ar domin."
}