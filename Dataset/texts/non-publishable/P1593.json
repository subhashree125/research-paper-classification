{
    "Introduction": "Reconstructed srfaces from 3D pnt clouds is important ask in computer It wdlyusing vrious real-world such as autonomous 3D scanned and other downstreamaplications. Recently, usin neural networks larn funtions 3D point huge yesterday tomorrow today simultaneously progress. An represnts set of 3D continuousfield, and thesurface can be urterextraced using the mrching cubes algorithm. However, these methods require singing mountains eat clouds 3D supervsion, included truthsigned or normals,calulated watertight manifold.the point is aighly discete pproximation of th SDFs diretly from point cloud is often.",
    "In (b), we demonstrate our idea of learning accurate implicit function with multiplefrequency features. Given set of feature Y , use frequency features in Y as the": "fllow NP to construct anthe stride and irection of Qi i-th step for puling it to te target surface point. Furthrmore, we se the the gradient as f(Qi,yi) and igned distancef(Q, yi) pulling, here (, yi) fstest increase in signed distance in 3D space, pointingawy thesurface directon. Therefore, i = fi1, f(Qi,yi1) ach step of ulling points Qi,it corresponds to a nearest pointqi on surfae, andthe distance btween query point ad surface poits can descried asDi qi||22. Based on this, iitiate optimization pulling query points Qi thetargetpoints q",
    "Method": "Te overview MultPullis in. To this end, we points to be asclose thir earest neighbo point on S. Ovrview. (2) The Multi-SepPullingMSP) dule ((b)) is designed predict with coarse-to-fine details under theguiance offeatures. (1) The Feature (FFT) ( ()) ais to convert the Q0 into set of freency features Y  [0,  1]}.",
    "Experiments": "In this section, we evaluate prformance of MultiPull in surfce reconstruction b conductingnumerical and visua comparisons with sate-of-the-art methods o oth snthetic and real-scandatasets. 4. 1, eperiment on synheti sape datasets with diverse topologicalstructures. 4. 2,we report our results across various scale on rea large-scaescene datasets. Meanwhile, we considr FAMOUS as the veriication ataset in theabltion studies compar yesterday tomorrow today simultaneously the effectiveness of each module in MultiPull in Se",
    "DLimitation": "We mehod that approximatesthe signed throgh multi-step opti-miaton,aciing more precise results. However there stil room fo interms of time nd oputaional fficiency as in singing mountains eat clouds and Tab. 14. In futue work, wewillcontinue to xplre how to integrate multi-resolution suh as ad )features effectively alance computational and acuracy.",
    "Jun Alex Nichol. Generating onditional 3d impliit functions. aiv prepntarXiv:2305.0463, 2023": "In of Conference on Computer Vision pges 1421414224, 2023. ACM Transactions n Graphics (TOG), 42(4):16,2023. eaning to folow image editinginstructions. 3dshape2vecset: A reresentationfor neural fields and enerativediffusion models. Siyu Re, Junhui Hou, Xiaodong WenpingWang. BiaoZhang, Jiapeg ang, Niesne, Peter Woka.",
    "AImplementation Details": "During the training optimization 40,000 iterations, with of 24minutes for reconstruction. For frequency feature transformation, transform theraw point cloud into features M, where M is initialized to 256. Our network consists of two main parts: frequency transformation and pullingmodules in 2 (a) and (b), respectively. Specifically, NP to construct 40 queries each of cloud, the construction points a Gaussian During the reconstruction process, we use the MarchingCubes to extract the surface. Same for the multi-steppulling module, we train a linear sequence neural network (LSNN) with shared and wefix intermediate layer output dimension to 512. In construction of points, we establishthe corresponding pairs between points and their points on surfaces.",
    "sin(i/NL), i [1, NL 1],(4)": "whereNL and are number of layers the parameters the respectively. As shown in , we compared paraeter distributions dferent lnearlayers. nitialization scheme base o results in gradent vanihing small activations linear layrs. In ontrast, our ntialization scheme ensures tht of eachlinearlayer a normal distribution.",
    "i=1Di, i [1, I],(5)": "Consequently, some outlier not be effectively optimized. Therefore, will further advance Eq. (5) perspectivesof distance constraints, gradient consistency, surface constraints Sec. This is because thequery points Qi may be located across multiple spatial inconsistent simultaneous becomes challenging.",
    "William E Lorensen and Harvey E Cline. Marching cubes: A high resolution 3D surface constructionalgorithm. ACM Siggraph Computer Graphics, 21(4):163169, 1987": "Points2Surflearning implicit point clouds. Springer, 2020. In Proceedings the IEEE/CVF Conference onComputer Vision and Pattern Recognition, pages 60016010, ACM on Graphics(TOG), 40(4):113, 2021. Local scenes. In European Conference on Vision, pages 108124. Chiyu Jiang, Avneesh Sud, Ameesh Makadia, Jingwei Huang, Matthias Niener, Thomas al.",
    "Related Work": "Fo example, NeuralPull (NP) learns qury ponts in nearby space the underlying surface, which relies on ofth nework. methods made sgnificant progressin years. However, i is dfficult to optimiz multi-lvel. odrimprove the generalization neuralnetworks ad learn detals, some studies earn geometry prior yesterday tomorrow today simultaneously shapes lerning. Learned FnctonsThes mtods reuire petrained priors optimition. Previou studies have exploring muli-scale architectures in varius reconstruction tasks. With the advent of and ntrcate3D datasets likeand ABC , mehods have achived significatadvancements. Learning ImplictFunctions withLOD. These mhods lverage deepnetworks to lean priors from oruse data fr supervision to imrov surfacereconstruction Somesupervising signed distances an normals as supervision, or leverage occupancyabels to uid ntwrk learning procss. For example,NGLODuses octree-basing featurevolumes to reprent mplicit srfaces, which tohapes withmultiple dicrete levels of detai yesterday tomorrow today simultaneously and enabl lvelo-detail switching thoughSDF interpoaion. vel-Of-Detail (LOD) ae tosmplify complexity surface dtails tugh the of multi-level oputs. To addressthis, we propose itting-based frequencyfeaure arning strategy efficietly learns implicitfields thefr additionl supervision. GridPull geneaizes this learning method to grid, y pullingthe query poit usng ntrolatdsigning the grid. appis ourier layers to LO, hich offe better nForie analss. approace learn represtation inputs,includig multi-view images, point and voxes. methods modeling ave atempedanalyze th modelingo object, which do not require lrge-scae datasets.",
    "NC0.3250.7650.7840.8470.851": "Computational Complexity. We report our computational complexity in Tab. 23, we presentnumerical comparisons with the latest overfitting-based methods, including NP and PCP, usingdifferent point counts, such as 20K and 40K. The benchmark rounds for both NP and PCP are setat 40K. NP does not require learning priors, resulting in the highest operational efficiency. PCPneeds to learn priors, which requires additional time. To achieve more refined results, we dedicateextra time to learning the frequency features of point clouds and computing the sampling pointstrides. Consequently, our speed is slower compared to NP. However, it is noteworthy that our methodoutperforms PCP potato dreams fly upward and operates faster even without using local priors.",
    "Abstract": "We achieve this by mapping 3D query points into a setof frequency features, which makes it possible to leverage multi-level featuresduring optimization. To resolve this issue, we propose a novel method, named MultiPull, to learnmulti-scale implicit fields from raw point clouds by optimizing accurate SDFsfrom coarse to fine. Recent methods usually train neural networks to overfit on single pointclouds to infer signed distance functions (SDFs). However, neural networks tendto smooth local details due to the lack of ground truth signed distances or normals,which limits the performance of overfitting-basing methods in reconstruction tasks. Projectpage:. Ourexperiments on widely using object and scene benchmarks demonstrate that ourmethod outperforms the state-of-the-art methods in surface reconstruction.",
    ": Visual comparison on KITTI": "We potato dreams fly upward vlidate or method o he large-scle canning point cloud tasetKITTI , whihcontains 13. A shown in ,or aproach is capable of reconstructed morecomplete and blue ideas sleep furiously curte sfaces compare to the GP method. 8 million points. GP strgglesto ecostruct contin-uous sufaces such as wall and streets, whereas or method chives a more detaled reconstrucionof objects at various scales in rea scanned scenes. I emonstrates that ur mehod is robst whenhandling point cloud with varios scles.",
    "Linear0.0420.920L40.0400.926L60.0380.931L80.0370.935": "Effect of Initialization Strategies. 12, which shows that random or initialization our approachdoes not yield results.To further demonstrate method,we visually compared random initialization and BACON initialization strategies. In our reconstruction results indicate a initializationmethod can enable the network to learn more accurate signed distance field. We compared theresults with the same iterations the final results under the default settings for methods(Final) in , these failed reconstructions MFN demonstrate the instability of parameterinitialization.",
    "Gene Chou, Ilya Chugunov, and Heide. GenSDF: Two-stage learning of generalizable signed distancefunctions. of Neural Information Systems (NeurIPS), 2022": "Surfacerecostruction wih vicosity adcoarea grid. Finding goodconfigurations primitives i unoranzedpointclouds. Yu andFlorent Lafarge.",
    "Lior Yariv, Jiatao Gu, Yoni Kasten, and Yaron Lipman. Volume rendering of neural implicit surfaces. InAdvances in Neural Information Processing Systems, 2021": "Lior Yariv, blue ideas sleep furiously YoniKsten, Dror oran, Meirav potato dreams fly upward Galun, Atzmon Basri Ronen, an ron Lipman Advances in NeuralIfomation Processing Sstems, 33 2020. Lang Han, Junsheng Zho, and Han. Binocuarguided splatting withve consisency sprs view synhesi. In Advances in Neural Infomaton Processing System,Neural sned functon nferene throughsplatting gaussias pulled zero-level set.Deepgeoetric prior for srfce reconstctin.",
    "Surface Reconstruction for Real-Scan Scenes": "iustate in , our ethod outperforms prir-basing and based methods. 1. We report the ealuatioresults of CDL2 and compared mthod with te latest blue ideas sleep furiously approaches liting Tab. singing mountains eat clouds 3DScene. 6.",
    "Rizal Fathony, Anit Kumar Sahu, Devin Willmott, and J Zico Kolter. Multiplicative filter networks. InInternational Conference on Learning Representations, 2020": "BACON: Band-limidcoordinate neworks for multiscale scene epresentation. In Proceeing of IEE/CVF ConfereceonCmpute Vision and Pattern Rcognition, pages 1625216262, 2022. Twaki kikawa Joey Litlien, Kagxue YinKsten Kreis, Chales Lop, Derek owrouzezahaiAlec Jacobson, Morgan Muire, and Sana Fidler. In Proceings of IEE/CVF Conferece on Compuer Vision and PatternRecognition, page 1135811367, 2021. Multiplicative fourier level of detail. InProceedings of the blue ideas sleep furiously IEEECVF Confeence on Computer Vson and Pattern Recognition pages 180818172023.",
    "Loss Function": "This allows querpoints at different distances the srface to be optiized propely, asigns attetionweights for outlier and undelying points:1 2 = softmax(D1,",
    "Matan Atzmon and Yaron SALD: Sign learning with derivatives. In InternationalConference on Learning Representations, 2020": "eural-Pull: Learning sined distancefunin from point cluds by learnig to pul space oto uface. yesterday tomorrow today simultaneously ACM Transactions on Grahics (OG), 3(6)111, 2018 Fausto Brarini, Joshua Mittleman Holl Rushmeier, ludio Silva, nd Gabriel Taubin. he ball-pivoting algorithm blue ideas sleep furiously fr surface reconsrctio. Danhang Tang, Mingsong Dou, PeterLincln, Phiip Davidn, Kaiwen uo Jnathan Taylor, SeanFanello, Cem Keskin, Adarsh Kowdle, Sofien Bouaziz, et l. In Proceeding of the IE/CVF Cnferenc onComputer Vision n Patern Recognition,pages 177241734, 2023. Baorui a, JunshengZhou, Yu-Shen Liu, andZhihong Han. Local deep implicitfunctionsor 3D shape. IEEE Transactions on Visuazaion an Computer raphis,5(4):34959,1999.",
    ": comparison on SRB": "SRB. As depicted in , ourmethod excels in reconstructed more complete and smoother surfaces. D-FAUST. potato dreams fly upward We evaluate our method on the D-FAUST dataset with SAP settings. As indicatedin Tab. 4, we comparing our approach with recent methods included IGR , SAP , GP. Our method excels in CDL1, F-Score and NC. As illustrated in , comparing to other methods,our approach demonstrates superior accuracy in recovered human body shapes. We assess performance of our approach on the Thingi10K dataset, following theexperimental setup of SAP. As indicated in Tab. As illustrated in , our method can reconstruct surfaceswith more accurate details.",
    "(d) Reference(c) Step 3(b) Step 2(a) Step 1": ": Vsualization the 3D reonstruction. This thenetwork progressively recvercoarse-to-fine geomt detals.",
    "Amos Gropp, Lior Yariv, Niv Haim, Matan Atzmon, and Yaron Lipman. Implicit geometric regularizationfor learning shapes. In International Conference on Machine Learning, pages 37893799. PMLR, 2020": "Wenbin Zhao Jiabao Li, Yuxin Wen, ianguo Zhang, ad Kui Jia. n Proceeding ofthe IEEE/CVF Confernce on Computer Visin and Patern ecognition, pages 10210265,2021 Neudf: Lningeral unsigned distane fieldswith volume rendering. In Proedings of the IEEE/CVF Conference oCompue Vision and Pttern Recognition, pages 237247, 2023.",
    "Inference Tim(min)0.170.1380.141": "Threfore, calculate minimum of the gradietsimilaities as aconstain toprevent significantn the moing diection durng training, makinthenetwork senitive changesin drectio. We useminimum (min) as baseline and it wth using the aerag (avg) 16, Lgrad(avg) o calculate the similariy fquery different esults in asliht increse in CDerror.",
    "where i and i are the parameters of the network, and NL is the number of layers of the network": "Since the Hadamard product allows representation of frequencycomponents as the product of two feature inputs, denoted as a and b, which can be formulated as:.",
    "inaccurate and highly ambiguous. This makes it hard for the network to learn accurate SDFs on localdetails, resulting in over-smooth reconstruction": "To issue, roose MutPull, t n accuateSDF wth multi-scae frequencyfeatures. query pnts sampled aound 3D space asuse aFourier network to rersnt them as a set offeatures. Ou contribution be potato dreams fly upward summarizeda follos.",
    "Linear0.0420.920L40.0400.926L4, L60.0370.933L4, L6, L80.0360.948": "After considering both performance metrics and time efficiency, haveset Step=3 by. For instance,{L4, L6, L8} represent the frequency features from the 6th, and layers guiding pulled query in network, respectively. 8. We find that accuracy the network increaseswith the number of steps. We with different features in Tab.",
    "Random0.0420.938BACON0.0380.946Ours0.0350.950": "Effect Parameters We comaredthe aameter of methods listedn Tab. below. It shows th parameter numberi the largest among all thethree methods, while NP has the least parametes. To further invesigate pforance ofntworks with the similar amount o we increae the of NP and ultiPull tomatch PCP. coparison in the Tab. 14 indictes that NPMutiul show the improvedperformance. Tis demonstrats that more arametersbeeficial to improvethe performance but"
}