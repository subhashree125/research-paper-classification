{
    ". Experiments": "Initially, we assess the image fidelity of ourmodel both blue ideas sleep furiously qalitative and qanttativand CLIP scoes. Subsequently,we our apprach across iffe-ent domans with zero ddtional training. since urappoach keeps orginal model fixed, cloely potato dreams fly upward ex-amine feature maps from the guie mod to how guiance is pplied at different timestepsdurin diffusion process.",
    ". Limitation": "is is a disavantagefroimplementatio point of view but it is important to mentinthat in prtice largr GPUmmory consumption reult inslowerinference time.",
    "(zt, c) = (1 + g)(zt, c) g(zt, ),(3)": "(zt, c) represents blue ideas sleep furiously the text-conditioned term, while ,(zt, ) corresponds to the un-conditional term (null text). The parameter g stands for theguidance value that scales the perturbation. potato dreams fly upward In this paper,we use the Stable Diffusions VAE latent and omit the nota-tion of Encoder and Decoder of VAE for brief.",
    ". Setup": "the is a 1d-array with the length Cthat passes through the modules along with timestepsand text embedding. We apply -prediction modelthrough the whole experiment. 5is training on 1000 sample images with 1000 stepsas our Teacher output for our guide model to learn. Weevaluate methods with the COCO dataset. We our method with DDIM and sampling.",
    ". Introduction": "Specifically, conditional diffusion models emerged with significantly improved sample quality byclassifier-free guidance (CFG). For example, even when using widely adopted state-of-the-art diffusion models such as Stable Diffusion ,more than 20 denoising steps are required to generate high-quality images. Specifically, the process of iteratively re-ducing noise in images typically requires a considerablenumber of iterations, posing challenges for efficient execu-tion. Diffusion models represent a novel categoryof generative models that have shown remarkable perfor-mance on a variety of established benchmarks in genera-tive modeling. Moreover, when applying classifier-free.",
    ". Qualitative and quantitative evaluation": "illustrates the qualitative between stu-dent teacher on various text prompts yesterday tomorrow today simultaneously with thesame yesterday tomorrow today simultaneously initial noise.",
    "end while": "and to make it the utput and pdatethe parameters of the nire student Instead, a smal guidemodel on top of the mode, whicleads to reducing comutatinal during trainingbecause the number ofparmeters in guide isrelatively small compared o the blue ideas sleep furiously whole U-Net",
    "D. Other Layers in the Feature Maps": "Generally, other layers alsoshow that at beginning of the sampling, feature mapinjections are stronger.",
    ". Sampling steps distillation": "uer theicrete timestep scenaio, N stadfor orignl numbr of sampling steps,we trained u-nt mdel to the outpt of DDIMsampling tteacher in one stepthe initial samplr fz; ) rando nos o x requires N teps, isdistilld into new sampler ) that N2 )the new teacher so that we can samperrequires singed mountains eat clouds steps. This procedureill be sevral imes uni the smplig stepsneeded will be achieved. The small size of model enables the parametersto be learned quickly. After singing mountains eat clouds trainingthe guide model, G, we distillit fewer samled required incrported withexisted distlltio mehods. In this again, we onlylearnth parameters fom the model G and fix thbae model thrughou distillation progess.",
    "C. Discussion on model performance with": "We that scores of our methods are relativelyhigh guidance is small 6). to of the guidance model, the guidancevalue small, the injection noise is small (as depicted in). However, when is higher our model iscomparable to the teacher model.",
    "In this we introdue two of xternal guidemode, full guide model and guide": "guide modelControlNet is one of the models image When w regard the ds-tillaion an gude model the xternal con-trolling, the straightforward way using te UNet architec-tureofmodeas guid model. g. Thisstraightfor-ward strategy enabls te modeltohave capacity. To align iththe origina ContrlNet our guide modelbroadcasts the guidance numbe a shape that isthesame as the hint size, e. tiny guide modAthough full guide odel lread well-desined guide model, this i no an eficient way e-cause her is not as much information neded to encdewith smple guidnce As further sandd ConrolNet structure, tinygui model,forour framewor:.",
    "A. More visualizations on guide model withLatent Diffusion Models": "In this we provided more of ourmethods with stable diffusion v1.5. The figure is shownin . part aims to show that our approach cangenerate variety of styles based on prompts. the initial the images generated by the guide model with 16 steps (i.e. first two rows) isidentical, noise for other methods is different.",
    ". mpariso the ful guide modelarchitectue thetiny architecture": "beddin will also pass through zero cnvolution layers, de-noted Z(, ). The tiy guide model simplifiesthe traditin Cntro-Net architecture y mong he encoder blocks as shownin. This dsign drastically reduces umbr of pa-rameters as t no longer need to b encoded by the guidmodel.",
    ". Plug in the tiny guide model with different fine-tuned U-Nets": "Thevls indicate that heinitialstages of singing mountains eat clouds the procssmre critical wih espectto Clasifier-Free Guidance (CFG), is when thepri-mary strctre of image i formed. i. Thus CFG to a role in thesereas,while the backgron become significnt. The number of DIM steps used sampled 50. the best our knowledge, we are thefirst o classifier-free uidance emphasizesdifferet of image generation in different timesteps. In the midde sage,the main subjet th image anda, bamboo aremore important. featue map injections throughouthesapled process. To this end, w vsualize the mapsat various stages of the teratio prcess an differentguidance values. We areable o study due the architecture choice oformodel that frezesoriginalmodel and adds the guiemoule an aditioal By looking intofeturemaps oguide modle, weare bl to get a bettr un-derstanding cassifier-free guidance impacts each layr of feauremp injection, e computedte mean acrossvariousfor eachpixel an apiednormalization. uide model G.",
    "be found in the Appendix": "We do not observe obvious quality degradationwhen decreasing our to 16 and with full guidemodel a level of guidance (g = 8). observethat the tiny model can achieve almost the same im-age quality as full guide model when sampling steps arearound 50, but when the number of steps are 8,then the performance the tiny will degrade dras- This can be partially addressed by training the with fixed Furthermore, both the mod-els can achieve comparable results compared to Classifier-Free Guidance (DDIM N 2 steps). progressive distillation). the otherhand, tiny guide model has less capacity, its for the student to fully mimic the teachers output givena continuous guidance input the sampling steps process e. Furthermore, we generate fewer timestepson.",
    ". Applying our trained guide model to different fine-tuned latent diffusion models (LDM)": "Specifically,we potato dreams fly upward itroducea novel type of istillation that akes parameters ofthe base model reain untuched: we proposean exter-nal guid model wth a lightweigh architecture tat injectseature maps to enable the diffusin model to generate text-conditionedimages on ne path.We urther study different architectural choicesf the lightweght modle nd sow thatthe proosed r-chitectre around1% of the paraeers of the ase, thseffectively halvig the infernce FLOP conts.Once our ligtweight guidedmodul is tained, ican e realy integrted wth existed finetund diffusionmodels, requring mnimal to no further training. In summary, or approac has the followng advantage: Low computational cost fo tranng: Te parametrsrequiredto learn from the distillationapproach is only1% (42% fo theFull guide model) of dision model,making the computational cost fortraiingvery ow co-prd to other distilation methods.",
    "Et,,x[(t)||(t) ||22](1)": "where (t) = (log2t /2t) is a pre-defining weightedfunction that takes the ratio t, whichdecreases xt latent variable thatsatisfied x = N(xt; 2t I).After model , during the stage,xt can be by the SDE / ODE solver. Forexample, using DDIM:",
    ". Reducing inference time in diffusion models": "reduce expensive computational cost iferncetime of diffusion models, attempteto improvethespeed of diffusion models. or examle, Dif-fusion Impcit Models (DDM) first-rder Eulersmethd which nables to reduce inference timesteps. On othe hand there ae previous wor tht incorpoate technique to imprve modelin-fence efficiency. of dis-tillaion to traser the nowledge and iformation cap-turing teaher studen model eblingthe studentodelto achieve simiar peormnce with re-dced andprposing optimizing specific steps yretricting noise cmputationo conditional and elim-inated noiscompuaton, thus rducing the.",
    "B. User study": "35%) favor of the student. The users did not strongly theteacher, with 1005 votes (55. 8k votes. 65 in favor of the teacherand votes (44. them as less realistic others may find themmore visually We conducted a user study whereusers blue ideas sleep furiously were with a along with a pair ofimages from that text prompt (Student blue ideas sleep furiously Full model50 vs Teacher 50 in a sequential the study, 90 partici-pants collectively assessed a of 680 unique text-imagepairs, resulting in the accumulation of 1. of the characteristics observed from the model ControlNet) is that the generatedimages are more saturated and contrast.",
    "Abstract": "In tis paper, we pro-pose new istillation approach fr mod-s in whic an lightweigh guide model is trandwhile the origial text-to-image model remainsthat method reuces the infeece computation ofclassiier-fre gided ltent-space mls by almot half, and only% ainable prametr of thebae model. projec page. Empirically, we howtht appoach is to poduce visuall appealing results and achiee a comprableFID score to the as ew8 o16 steps. onc trained, our guiemodelcan be appied to fine-tued, domin-specificof the base difuson need foraddi-tiona trainng: this pug-and-play functionaity drasti-cally mproves inferene omputation maianing fidelity of generted images. odels shown remendos resuls in im-age However,du to he nature of proces nd its reliance on clssifier-free iferenc are slow.",
    ". trained guide model replace classifier-free guid-ance that can be other base models with differentdomains": "Second, it has beenshown that diffusion models can be finetuned to differentdomains. However, the standard diffusiondistillation approach has the following limitations. However, with standarddistillation on the base model, these finetuned models areno longer applicable. First,the number of trainable parameters of the student model isthe same (or comparable) as that of the teacher diffusionmodel. guidance, two forward passes potato dreams fly upward one for the conditionedand another for the unconditioned diffusion model areneeded per denoised step, further increasing the computa-tional cost. When fine-tuned with only a few images, prior work has shown thatnovel concepts can be learned.",
    "Alexander Quinn Nichol and Prafulla Dhariwal. Improveddenoising diffusion probabilistic models.In InternationalConference on Machine Learning, pages 81628171. PMLR,2021. 4": "Sdxl: Improving latent difusion mod-elforhi-resolution image synthesis. DustinPodell,Zionngish,KyLacey,AndreasBlttmann, Tim Dockhorn, Jonas Muller, Joe Penna, andRobin Rombach. 1 Alec Radfrd, Jong Wook Kim, Chris Halacy, AdityaRamesh Gabril Goh, andhin Agarwal, Gris Sasty,Amanda Askell, Pamela Mishkin,Jack Clark, et al. In Internatinal conference onmachine larning, pages87488763. 0152, 2023. PMLR, 22. 5."
}