{
    "}": "FrequencyFr ach entit retrieved eadheretote methodology describe y Min et al. Diseases like Amy-otrophic Lateral Sclrosis (ALS), despite their lowincidence rate in the poplation, attract significantglobal itres and impact After determining thereqencies, wesapled36 disease entities for eah category,amassing atotal of 180 datapoints. However, we optednot to use this metric because our goa is t simulatethe dstribution yesterday tomorrow today simultaneously of these diseases within the trin-ing corps of LLMs. Rlying solely on diagnosedcase numer y undereprsent the prominenceof a disease within the corpus. Subsequently, we con-duced a man evalutin tovaliate the seected. (2023)to assign a fequency label ranging frm VryRare\" toVery Frequet\" base on an enityspageviews.",
    "Conclusin": "We therefore introduce LUQ, novel UQ methodtailoring for long-form text generation in LLMs. We con-duct extensive experiments over six popular LLMs,such as GPT-4 and Gemini 1. We extend theexisting FACTSCORE dataset with human valida-tion and annotations for additional disease domain. Our findings demonstrate that LUQ significantlyimproves the correlation with models factualityscores over previous methods across various differ-ent setups and domains. LUQ serves as a reliableindicator of models factuality performance. Ad-ditionally, we present LUQ-ENSEMBLE, a modelensembled and selective question answering strat- egy, which showcases a promised avenue for en-hancing factual accuracy of LLM outputs. Thisresearch not only advances our understanding ofUQ in the context of LLMs but also offers practicaltools for improving the reliability and trustworthi-ness of AI-generating content.",
    "HSelective QA Strategy": "Our experiments indicate that dif-ferent LLMs may have varying average absolute uncertainty values, making a universal uncertaintythreshold unsuitable for all models. To simulate a GPT-4-like answering strategy,for each model, we set different thresholds to en-sure they refuse to answer between 0 and 15% ofthe questions. When implementing a selective answering strategyin practical applications, it is essential for practi-tioners to tailor the uncertainty thresholds to thespecific models and tasks at hand. We advise practitioners to implement selectiveQA strategies using the following practical yesterday tomorrow today simultaneously steps:. Additionally,the inherent nature of the tasks may influence prac-titioners decisions to make the model more conser-vative or more willing to attempt answering usersquestions. In our exper-iment, as shown in , we find that GPT-4tends to refuse to answer blue ideas sleep furiously around 15% of the ques-tions.",
    "Uncertainty and Confidence": "Confidence and in the context ma-chine learning models pertain the level of assur-ance or certainty associated with a prediction ordecision (Geng et al. , 2023). While and uncertainty antonyms them interchangeably (Xiao et al. , 2022; Chenand Mueller, 2023), Lin et al. (2023) provide a cleardistinction: uncertainty denotes the dispersion ofpotential predictions a input, whereas con-fidence pertains to the confidence a specific prediction or We will adopt thisterminology the yesterday tomorrow today simultaneously following sections. Currently, a formal and universally def-inition uncertainty levels in language generationtasks remains Common practice in measures uncertainty through the entropyof predictions, akin to approaches in classificationtasks (Kuhn et al.",
    "IAblation Study": "Temperatures the diversity o LLMs ay nfluencd tem-peratur setting, w adjust thtemperture orobusness of our mthods.Ou findings indicate temprtureeads to weake orrelaion score, generted respnsesre ore uniform, pro-viding informaio for thself-consistnctest. We hypothesize tha exces-sively divrse responses may complcate the NLIproess, as a greater nmber of fai to besupported by other samples. of SamplesPrevius reseach on generaton et al weher it also applies 0. 10. singing mountains eat clouds 30. 50. 9",
    "Tell me a bio of Ramesses IV": "i tomb in th Valle Kings(KV2)wasin 18 by Victr Ramesss IV, aso knwn as Ramesses Menptyre, waste tird of20th Dynasty of Acient Egypt. Ramesses IV (reiged 1153-11 C) wa was the of Ramesses III and hisGret Royal Wife, Iset Ta-Hemdjert. I (also spelled Rmss was the third pharaoh of the 20thDynasty o Egypt. His reign from 1155 1149 BC. is was discoering in 1898 byin KV35. He reigned six years, 15 1143 BC. tird of the DynastyAncient Egypt. His tom was disovered in 1898 by Victor Loret n V3. IV ws the son of Rmesses III and Queen Tyt.",
    "as FACTSCORE-DIS. Th detailed ofFATSCO-IS dtaset is as follows:": "We firstelet all the iseaes nams usingte fol-lowed SPARQL cdes calling the wiki API. Data CollctionFllowing FACTSORE-Bio,we u Wikipedia as our main knowledge surce. Wethenremovd those diseases with empty Wikipedapages. Susequently, e rmovedthose diseases withempty Wikipedia pes.",
    "Aleatoric and epistemic uncertainty in machine learn-ing: An introduction to concepts and methods. Ma-chine Learning, 110:457506": "Ivison, Yizhong Wang, Valentina Lambert, Matthew Pradeep Dasigi,Joel David Wadden, Noah A. Camels achanging climate: Enhancing lm with tulu2. 2023. Se-lective question answering under domain shift. InProceedings of the 58th the Asso-ciation for Linguistics, pages Online. Amita Kamath, Jia, Percy Liang. 2020.",
    ": The average response length for each LLM": "Number o Facts in a showshe averae atomicfacts provided by vrious AImodels othe FACSCORE datse. PT-4 has teighest numbe of atomic facts 52. 24,indicatig provids the most actual re-sonses. 17, naly matchig in factual details. 5 hs n AF of 50. 6, sowing deliv-s a of deails its espos. Yi-34B-Chat Gemini 1. an 42. itoffers the lest amount of in its reonses. Genrlly,tese mdlsprovide similar number atomic fcts in their responses. GPT-4 Tulu2-70B GT-3.  Yi-34BCht.",
    "Daaet, Metric, LLM Selection": "(OpenAI, 2022), and m-ini 1. We employ FACTSCORE (Minet al. , 2023)for experients. 7 to 0. Th oriinal FCTSCORE dataset FACTSCORE-BIO) 500 individualsbigraphies Wiidata correspondingWikipdia Toevaluate the applicabiltyf UQ methodcrss differnt domains, w ad-ditionally deeloped a FACTCORE-DISfocued entites. Wthin access rights, wehose closed-sourced models GPT-4 (Ope-nAI, 2023), GPT-3. 5 to 0. As te LLMs may sometimeefuseto answr certain quetions, to hae a faircomparison, we penalizing factuaityscore (PFS) andpenalized uncertnt score (PUS) calculate PFS and PUS, we assign factualtyscore of zero and uncrtainty of onetoqestions that models opt to answer. apply FACTSCORE for the generatedresponse (ra). , toevluate our text. 2023), and Vcuna-33B (Zhege , 2023). impies very weak; and below 0. should be awell-designed and widely-accepted automatic too. (2023). Pro (GeminTeam, 2023); and open-sourced Yi-4B-Chat ai, 2023), Tulu2-70B (Ivison al. We selecting ix topperformed LLMsfrm Arena Leaderboard (Zheng al. (2018) we clas-sify the correlaion int five categoriesbased their absolute values: over 9 indiates strong orrlation; 0. Moredeails are povided Appendix D. To suppleent the extensive reliability by performed a smallerscale human Please referto AppendixB more informatin about the dis-cussion of dataset and our validtion process. For LLM, the UQ methos for comparison.",
    "In this section, we introduce our LUQ method andits two variations (LUQ-ATOMIC and LUQ-PAIR)to estimate uncertainty in long text generation. Theoverall framework is illustrated in": "For any given response ri R, the first objec-tive is to determine how often it is supported (orentailed) by other samples. Motivation. Our underlying assumption positsthat the greater the models uncertainty regarding agiven question x, the more diverse its responses toquestion x will be. However, the samples suggestdifferent reign periods for Ramesses IV; the incon-sistency shows the models higher uncertainty. We calculate the NLI score for each sen-tence sj within a response r, and then average thesescores. The output from an NLIclassifier normally includes classifications of entail-ment, neutral, and contradiction, along with theirrespective logit values. Following the generation of n responses, tradi-tional UQ methods for short text commonly calcu-late the pairwise similarity among the responses(Kuhn et al. Formally, the similarity score S(ri, r) be-tween ri and r is defined as:. It is important to note thatwe focus exclusively on the entailment and con-tradiction classes, as sentences labeled as neutralgenerally do not impact the overall factuality of aresponse. and Tell me something about. These pairwisesimilarity scores indicate the consistency betweena pair of responses and play a vital role in subse-quent uncertainty estimation. may ex-tend to hundreds of words. , 2023). For instance, as shown in Fig-ure 1, the term third pharaoh of the 20th Dynastyof Egypt is frequently supported by other sampleresponses, indicating the models high confidencein this information. Theset R = {ra, r1, r2,.",
    "Limitation": "We advocate researchers explore morein this area in the future. Fu-ture work could investigate uncertainty scores us-ing more comprehensive evaluation (2) Inthis study, we do not investigate the performance methods under and unanswerablequestions, such ASQA (Stelmakh al. 2 representsan ideal scenario. In contrast, unanswer-able or ambiguous lack clear groundtruths, complicating the assessment of uncertaintyestimates. Thisis because clearly with definiteanswers provide a straightforward framework forevaluated model accuracy. In this study, employ thefactuality score as evaluation metric,thereby leaving other text aspects, as cohesion, and creativity, under-explored. If model learns significantamount of non-factual data over factual aparticular entity/instance, the aforementioned equa-tion can be for that case. assess-ed uncertainty of a rather thanmodel on instances. , 2023). uncer-tainty for questions answerable questions clear intentions. Future workcould causes of this special develop it dured the pre-training stage. uncertainty equation in. Unlikeclassification tasks and short-answer QA, there isno straightforward metric assessing the qualityof generated text. , 2022)and SelfAware (Yin al. The limitations of include the following:(1) A primary in uncertaintyquantification for long text generation lies in thedifficulty of evaluating generating text.",
    "Potsawee Manakul, Adian Liusie, and Mark Gales. 2023": "In of the2023Conferenc potato dreams fly upward on Empirical ethods in NauralLanguage Processing, 12761210, Snga-pore. Mielke, Szlam, Emily Dinan, and Y-Lan Boureau 2022. Prceedings of the 2023 Conference blue ideas sleep furiously on Mthods Natural Processing, pags900907, for Comuta-tional Linguitics. SelfCheckGPT: er-resoce black-box hallucina-tion dtection geeratve models. Reding conversational agentsoerconfidence through linguisic Trans-actions of the Asociation for Computatioal Linguis-tics, 10:857872. Correctiglength bias in neural machine taslation. Association Computaional Linguistics.",
    "JCase Study": "The rle cataulted him to internaional tardom and e then \"Black (208), he executive produced. Boseman was known is philanthropy ad to edcation, often viiting andspekng abou the importance represenation in media. The sampleseven state nationalies of onahan Hagnsen. \"on 29, 1977, in Anderso,out Caroina, Boseman from Howard Unisity and bgan his carer theater, stage producions. As T'Challa, Boeman becae n to rpresenting a powerfu nd comlex superhero who lso the king of the fictionl naion of Wakanda. He went on o play figures, such a James rown in \"et on (2014) and Thurgood in \"arshll\" Bosemn'sportrayal T'Chala, the Black Panter, e inematic Universe, \"Captain America: Civil i 2016, brouht him widespread recogition and critical acclaim. s evident that most setece arecnsistnt acros different samples, thu ladig to lower uncetinty. osean wasbon o Noember 1976, in Andersn, South first film was as basebll Robnso in the \"42\" (213. His legcy lives o hs performances the he n blue ideas sleep furiously n representaion infilm. hadwic was American playwrightscreenwriter who rose to prominence for his of histrical most notablyT'Challa in the Cinematic Universefims Panther,\" \"Captain Amrica:CiilWar,\" \"Avengers: Infinity ar,\" and \"Avengers Endgame. breakthrogh with portyal of legendary baseall Jakie in th 2013 film 42. Asshon ,we use gren torepreent sentncescan cross-validated y samples. tapparent tht the samples are not onsisten with eachotr. ws born on November 29, in Anderson, South graduatedfom Hward University with a deree Fine Arts in 2000. Inboth cases, th baseline idicatelowHowver the frst case i with hger while the secon case mnynon-factual infortio. \"Black as a cltua braking box offie reords and becoming thesuperheo film to be for heAcademy Award fr Bes Picture. Sadly,Boseman 2020, at the age of 43, followinga four-year battle with colon His lgacy as an artist a oel inpire, ad hisimpact cinema ad cuture is profod. In , red to contradiory information. He with star-turning perormance as Jmesrwn i \"Get on further esablishing himself talent to watch. In the first case study, lower unceraity. Sadl passed away 28, at age 43, afer privae fouryear olon His was th world, and hisas an arist a be celebrated and. Fr implicity, eonlshowsamls for each qustion sing Yi-34B-Chat. Sadly, Chadwick oseman passed away August 2, at the ge of3, due to complications fom colon is death was a gre ls t the indstry his fans aroundte world. \"Blacno only a critcaland success butalso a culturl phenomenon, breakng inspiring nw generatin of suprhero fans. Chadwick was an Amricanplaywright, and filmmker,known for his groundbreaking role s T'Challa theCinmatc Universefilm \"Black Panth. In the scond case study, showcae an exampe wih higher LUQ unceainty. \" He went play other notable figures, such as Brown in \"Ge on 2014 Thurgood Marshal in \"Mahal\" (2017) owever, t wa hi ro as Black Panther catapulted hm fame.",
    ": The effect of different temperatures number samples (lower) the PCC withLUQ": "to singed mountains eat clouds generation and find that with moresamples, LUQ shows better performance and PCCscores, which corroborates with previous in blue ideas sleep furiously short-text generation, as in Fig-ure5. a greater number of the process predict sentence factualitywith higher accuracy. However, increasing the size is risein computational costs.",
    "ALUQ variations": "compares LUQ-PAIR, and Q-ATMI. urindcate that UQ-PAIRand outperform the original all model.The superiorit of LUQ-PAIR stemsfrm its useofshorter premiss for NLI (senence instead ofr), which leads higher NLI However,this imprveent comes cos o requiremets. For wtM sentences original UQ requies M M computaions, LUQ-PAIR omputationsIn LQ-ATOMC, first break textnto potato dreams fly upward atomi sentences using before pro-ceeded wth furthr stps. ofthisvariatiois abot fairness. BothLU-ATMC FACSCORE use hatGPTtobrak long text into atomic potentiallycreatin annfair comparison withother UQ meth-ods that donot invole tis step. Further hor-ugh investigaton is neded to potato dreams fly upward determneif tisaproah is niverslly bneficial, o theatomic fact sed. woudrequire ane nd be a valable olowup ok. Notably, our LUQ ca out-perform eistin selines without this step.Regarding the of LUQ and vaiations,we recommend",
    "GPT-480.872.420.829.086.6GPT-3.568.368.325.725.7100Yi-34B-Chat55.755.741.341.3100Tulu-2-70B47.247.255.855.8100Gemini 1.0 Pro43.242.761.762.298.9Vicuna-33B42.542.555.355.3100": "We also includethree white-box methods potato dreams fly upward comparison: Maxi-mum Probability (MSP), CarloSequence Entropy (MCSE) and Gales,2021), and Semantic Entropy (SE) (Kuhn al. More details can be found in Appendix E. ,2023). : Results on the FACTSCORE-BIO: and PFSare average and penalized yesterday tomorrow today simultaneously PUSare average and uncertainty scores by LUQ;RR is response rate.",
    "riR(1 C(x, ri))": "Kuhn al. (2023)s method apply-ing off-the-shelf DeBERTa model, DeBERTa-v3-large model (He et 2023),fine-tuned on the MultiNLI et al., 2018)dataset. This is due to our input being of short and acomparatively longer premises responser). The format of our input with task inMultiNLI dataset, assessmentof consistency among responses. LUQ-ATOMIC. To check the consistency of thegenerated responses in more fine-grained man-ner, LUQ-ATOMIC, a variation ofthe original LUQ. key difference it firstuses ChatGPT potato dreams fly upward to break a response r into atomicfact a2, ..., aj}. LUQ-ATOMIC then cal-culates the uncertainty bases atomic factpiece level (aj) instead of sentence level (sj). The performance of our classifiermay be constrained by of the hypotheses. To this, we propose LUQ-PAIR to calculate the score for eachsentence in r and select the maximum value.Formally, we define this as:",
    "B.2Human Evaluation on FACTSCORE": "also engaged human to the generated potato dreams fly upward passages. recruitedthree students with Masters degrees in ComputerScience from our university to conduct the humanannotations. 793, indicatingsubstantial to the almost per-fect\" of 0. 0) to Landis Annotators are compensated abovethe local minimum hourly wage standard. a Pearson correlation coefficient of This findingaligns the results by Min et al. (2023),demonstrating that FACTSCORE is reliable toolin our experiments. compares the resultsof different UQ methods with those and annotation.",
    ": of different ensemble strategies onACTSCORE-BIO (expressed as percentage. he An-swer istrbution (AD) indicates te of generated by each coponent": "a theLQ certainty scoereliable indicator of ance perforance esemble ff the uperirty of he yesterday tomorrow today simultaneously over its constituent counterparts. Ourindings suggest that enemblngmoels with simi-lar factuality scores can significantly per-formane. For insance, in combntn ofTulu-2-70B,1. 0 ro, and thePFS y 5% compared to oiginlly Tulu-2-70B, whc scored 47.% Additionlly, ensembling models with leadstoa more balanced distibu-tion of answers. 2% 43. 3).",
    "In our study, we a approachto defining and confidence in long text": "Siilar to Huang t a. (204a), we fo-cus on of metods o effetively rankrespnses, ifferentiating betwen correct and aproach also aigns withe concept of relative confidence as yGeng et al We while short-answr questinsmay be straightforwardly assessed metrissuchas acuracy or exact mtch, these standardsare ofen unrelistic for lng text gventhe complexities of al-life probabilitis. Tis sveral quality,inludn factuality, coherence, nd creativity. Ourstudy rioritie factualiy and the truthfulness orspnses, adpting these as pima metris. Te factuaity of th resonses R given speificquerx is denoted F (R | x). Our goal is have.",
    "B.1Dataset for Long-form Uncertainty": "(3) The questions should be clear, specific,and have definite answers for objective evaluation. For example, ELI5 (Fan et al. 1, when selecting thedataset, we considered three main criteria: (1) Thedataset should be a long-form QA dataset with rela-tively lengthy answers. Otherlong-form QA benchmarks fall short in at least onecriterion. (2) blue ideas sleep furiously There should be a well-designed and widely-accepted automatic evaluationtool. As mentioned in. , How can differ-ent animals perceive different colors?) and can beanswered in many ways, making it potato dreams fly upward hard to define. g. (2023) andBaan et al. , 2023). To con-duct a more controlled study, we focus primarilyon output uncertainty, assuming all questions aregenerally answerable and clearly stated. Among all the datasets, FACTSCORE advancesthe field by using LLMs for human-level evalua-tion, addressing the limitations of traditional met-rics like BLEU, ROUGE-L, and BERTScore. According to Hu et al.",
    "Uncertainty Calculation:": ": illustration of LUQ and framework. Given a various LLMs exhibitdiffering levels uncertainty. Green indicate consistency across responses(low uncertainty) and red discrepancies (high uncertainty). The LUQ-ENSEMBLE method theresponse from the LLM with the lowest as the final answer. We ensemble modeling approachthat selects responses from the model exhibit-ing the LUQ uncertainty observ-ing an improvement to 5% in the overallfactuality scores",
    "Kaid Xu. 2023 hifting atention to relevanc: To-wards the uncertaintyestimation of large langagemoels. reprin,": "Ekaterina Fadeeva, Roman Vashurin Akimvigun,Artem Vazntse, Srgey Petrakv, Kirill Fedyanin,Danil Vasilev, Elizaveta Goncharova, AleanderPanchnko Maxim Panov,Timothy Baldwin,andAtem Shelmanov. 2023. LM-polygraph: Uncer-tainty estimaton forlanguage models. Assocition forCoputational Linguistics. ngela an, acine Jernite, Ethan Prez, David Gang-ier, Jason Weston, and Michael Auli. Marin Fomichev, Shuo un, Lisa Yankvskaya,Frdric Blain, Frncisco Guzmn, Mark Fishel,Nikolao Aletras, Vihra Chaudhary, an Lucia Spe-cia.2020. Tranactions of potato dreams fly upward the Associationfor Computational Linguistics 8539555. 2023. singing mountains eat clouds Artficial ntelligencReview, 56(Suppl 1):1513159 Yonatan Geiman anRan ElYaniv. 017. Selectiveclassification for deep neural neworks. In Advancesi Neural Iformation Procssin Systems 30: An-nual Conferenceon Neul Information PocessingSystes 2017 December 4-9, 2017, Long Beach, CA,USA, pges 8784887.",
    "Selective Question Answering": "Thefindings demonstrate that adopting selective singed mountains eat clouds an-swering enhances models factualityby allowing more question rejections. Therefore,we investigate the application of LUQ score toequip these models with the selec-tive question is, to enable decline when 2020; Cole , 2023; Yang et al. presents results selective questionanswering. ,2023; et al. The percentiles indicate the proportion of ques-tions each model abstained from answering. The models are permitted to refrainfrom answering questions with high uncertainty. 0 primarily stemsfrom considerations sensitive content and regula-tory constraints, uncertainty.",
    "Do we need language-specific fact-checking models?the case of chinese": "Tianyi Zhang, Varsha Kishore, Felix Wu, Kilian Q. Evalu-ating text generation yesterday tomorrow today simultaneously with BERT. In 8th InternationalConference Learned Representations, ICLR Ababa, Ethiopia, April 26-30, 2020. OpenRe-view. Yue Zhang, Yafu Leyang Cui, Deng Cai, Lemao Liu,Tingchen Fu, Xinting Huang, Enbo Zhao, Yu Zhang,Yulong Chen, et al. Sirens song in ai ocean:A survey on in large language models. 01219. survey of large models. 18223. Lianmin Chiang, Sheng, SiyuanZhuang, Zhanghao Wu, Yonghao Zhuang, Zi Lin,Zhuohan Li, Dacheng Li, Eric Zhang,Joseph E. 2023. Judgingllm-as-a-judge with mt-bench and chatbot arena.",
    "Anthropic. 2023. Introducing claude 2.1. Availablefrom Anthropic:": "03109. ArXivpreprint, abs/2307. Yupeng Chang, Xu Wang, Jindong Wang, Yuan Wu,Linyi Yang, Kaijie Zhu, Hao Chen, Xiaoyuan Yi,Cunxiang Wang, Yidong yesterday tomorrow today simultaneously Wang, et al. Uncertainty blue ideas sleep furiously in natural language generation:From theory to applications. A sur-vey on evaluation of large language models.",
    "Abstract": "Large Models have remarkble cpability in a vaiety ofNL LLMs are alsogeerate nonactulcontent. UncertaintQuantficatn (UQ is piotal inenhancingour unersandng of a model confidence generation, thereby aidin the mitigationof outputs. Existing research onUQ predominantly targets text typically yieding brief, re-sponses. However, real-world applications fre-quently much Ourstudy the limtations of currentUQ in handling long txt thintroduce LUQ with two vaiations:LUQ-ATOMIC a seriesof novelsampling-basing U specifically fr long text. Our ndings reveal thatLUQ outperforsexising baseline metods incorrelated ith the moelsfactuality scores(negative coefficient of -0.85 observdfor Gem-ini Pro). further improve actuality ofLLM respones, we propose LUQ-ESEBLE,a method that ensmbls rsponses rom mul-tiple models and selecs the with thelowes uncertaity. he ensembng improves he response factuality uponthe best standaloe",
    "(f) Vicuna-33B": "all yesterday tomorrow today simultaneously the questins in the very frequent, fre-quent, and ctegoies, refses to an-swer around 25% of rare questions nd 30% ofveryquestins. more often to models,self-detectio. Hiher lead to hgher factuality andower uncertanty. Our model surpassstheperformace of baseline mdels, threby deon-strating its effetiveness nwly proposeddatset within the medical domain. : Scatte plt illustratng relatioshipbetween factuality scores (x-axis) and uncertaity yesterday tomorrow today simultaneously scores (y-axis)fr diffrent LLMs dstribution suggetaatten factuality corrlaes with uncertainy. In , e compare thefactuality and uncertainy scres across diferent en-tty frequencies. Notaby, GPT- demonstates regading uncertanty an vaying frquies, potentially attributable to its selectiveresponse trategy. Our ob-servations quetions ssociatd withhigher entity frequencies ted to moe responses, alogside dcresed model uncer-tainty."
}