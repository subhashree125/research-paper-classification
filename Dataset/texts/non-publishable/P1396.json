{
    "tan(max) ,(6)": "max = singing mountains eat clouds 1. 5 and 100. This schedule is in essence linearly the in domain [0, max] to fall singing mountains eat clouds within range [0, max].",
    "ImageDescription": "The stageglows undr the sptight,and the audience is a f aces, theai charged with and exiement. caption] Majesti randeur of mountainrange under a clear blue The rugge peaks rise sharply, theirjaggedlinesotenedy blankets snow. [Image caption] A solitary figur enveloedthea ibrantgarden, basking in the gentle embrace of sunlight. She seems to in moment of tranuil reflecion,a th worlaround her the life potato dreams fly upward untamed blooms and he sotwhsper of leavs inthe breeze. It an image of peaceful solitudewere clamoro the word awy before the uritof natures rtisry.[Image Commaningfgure on horseback steepedinthe iconography of powe an leadership. rearing horseadds theintensity, ihmuscular detail and atosed by the vigor of movement.",
    "Evaluation Metrics": "FMD is spiredby rchet Inception Distnce (FID and easures the imiarty of set o generted muscembeddings to population of real muic potato dreams fly upward embeddings i ditribution Musc-image Alignment (M2I. However, image-to-music or text-to-music rtrievalis inherently subjetive, oftn featuring oe-to-many mappings. First, we repot recall@(R@K), a standard metric i inormationretrieval. We evate retrieval reslt using hree metrics. Retrieval Metrics. Leveraging the sharing text modaity in CLIPand MuLan we se text as ridge o evaluting music-iage (M2I alignment following Chowdhuryet al. By encodingtexts into both CLIPand MLan embeddings, M2I is calculatedas the average f prduct of two osne similaities. Asessig alignmet between generatedmusic embeddings andinut image is challengng du to heir distinctoins. This approach elimiates the neing for paired data ndinstead requires a set of images ana separte e of texts.",
    "Conclusion and limitations": "We introdce a generative music trival featuing diffusio-based ebeding-to-embedding model. By generatin non-deterministicseed cross-modl queries, ourapproach improvesthe quality and retrieval reslts. Our model ensures smanticreevance hgh while text-bsed semantic steering allows user personalization. promising, our framework has a well. High comutational diffusionsampled may impede real-time retrieva and ny re-traied such as informationloss orundrepresented items, naturally to our framework.",
    "from t = 1 o 0 ithnoise schedule t iitial conditio zm,1 N(0, =1) a solver": "Durng training,the q is randomlymskd with awit probability pmask, sch that the moel simultaneously lears enerate conditional andunconditiona samples sared paramete. At sampling the denoise is anffne combintion of the cnditional uncondtional",
    "Abstract": "Modern musicrerival stems often rely on fixed representations of user prefr-ences, limiting their aility to capture user diverse uncertin retrieval nes To address thslimitaton, weintroduce a nvel generatve retrivalframework that lightweigh diffuion models to synthize dierse seedembeddings frouser ueries hatpotental directins msic Furthrmre, Dff4Steer cn be steeed b imae r text more flexibl controllble discovery omine wit search. Our framewok regression ethodsand LL-based generative in of retrieval an rankingmetrics, demontating effectivenes in capturing user pferences, leaing toore diver relevant recommendatios. examples available com/diff4steer.",
    "Tasks and Datasets": "In our retrieval experiments, useour diffuson prior odel several dstream taskssimultaneously, rtrieval, retrieval and image-to-music steering.For tasks the is CLIP. the 116K mui videos in this to generat (music, image)pairs byextracting 10s and randoy sampling a vieo frame n time window. Thisdataset is used taining. MusicCaps (MC) is a collectionof 10s music audio clips with textul descripins. MelBench (MB) is another paird with mtching musiccation ad musi audio annotated by music",
    "A.1.1Architecture": "Our diffusion backbone model is a model conistingof 6 ResNet a projction lyer. potato dreams fly upward. The verall archiecture is shown yesterday tomorrow today simultaneously in , and detailed architectureof each esNet block sown in.",
    ": diagram of our retrieval framework for cross-modal retrieval, withcomparison to the regression and multi-modal LLM baselines": "Concretely,our lightweight diffusin-basedgeneatve odel singing mountains eat clouds gie rise toa statisical prir on the trget modality in our cas, audio for themusic retrievaltask Theyare ten used to retrieve the anidates using nerest neihbor seach. While we have sen that diffsion-bsed genrativ approaches can ensure diversity andqualiy in the embedded generation in his workeinvestigatetheir performance on retrievalasks. We demonstrate that our genertie music retrieval frameworkaheves cometitive retrieval andranked prformance while inroducing much-needing diversity A cmprson ith deterministicrgressin etds shows that Diff4Steer achieves superior retrieval metics.",
    "where denotes the CFG strength, which boosts alignment with q when > 0. = 1.0 indicatesunconditional generation": "This allows usoincororatett stering ignalsby deoising fuction at sampling tim:. In such case, the provides txt encoder Et : ztwith atext-muscsmilarity measure via the yesterday tomorrow today simultaneously vector dot podct zt, zm. Additonal canbeapplied when the music embeding sace that JEM.",
    "B.7Human Study Evaluation Metrics": "score o 4 or isa yesterday tomorrow today simultaneously in positie seerig, while a score of 1 or 2 success innegative stering. Consistency To asess he consisency of the oveallheme ad in seredmusic, userscomare reernce piece, ating their similarity on a 5-point scale. This cre is ten mappedto range o rfect thdegree of consisency.",
    "use a 6-layer ResNet with width of 4096 as the backbone denoising model. For guidance, we a condition mask pmask 0.1, in order to learn": "blue ideas sleep furiously modelfor steps, which takesaroundtwo yesterday tomorrow today simultaneously days on a singleTU 5e. modelhas229M parameers in total andan ito one PU. We use the Adam opimizer under cosine annealed learning schedule with ate 105. We paied imag music embeddings rom T8M music videos.",
    "Retrieval Diversity": "Diff4Steer generates diverse seed embeddings, as quantified in. For each image, blue ideas sleep furiously wegenerate 50 seed embeddings and measure diversity using MISCS and entropy (H@K, withK {10, 20, 50}), calculated on the distribution of ground-truth genres in retrieved music pieces. Varying guided strengths during inference effectively modulates this diversity. 0) yields the lowest MISCS and highest entropy in recommended genres. IncreasingGS initially decreases embedding diversity, with retrieval metrics peaking around = 9. illustrates retrieval diversity using three representative input yesterday tomorrow today simultaneously images. With strong image-music correspondence (Top), the entropy is notably lower, reflecting a dominant genre (Classical). Conversely, weaker correspondences (Middle,Bottom) show varied entropy changes with increased guidance, sometimes resulting in a dominant.",
    "EAdditional evaluation results": "ad 10 show how therecal is ffected by the tet string orserical introlation strenghs. Guidance strength 0 150. 18 0. 20 0. 21 0. 22 023 FMD Guidance strength 0. 4 0. 5 0. 6 0. 7 0. 8 blue ideas sleep furiously Intra-samplecosine similriy."
}