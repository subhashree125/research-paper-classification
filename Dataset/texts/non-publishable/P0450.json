{
    "Q: Sandy grew 6 carrots. Sam grew 3 carrots.How many carrots did they grow in total?A: Lets think step by step. To find thetotal ... So, they grew a total of 9 carrots": "Q: Sam had 9 in his bank. To find the number ofdims, we add these two together: 9 dims + 7dims = 16 dims. Q: Sandy grew 6 carrots. Sam grew 3 How did grow in total?A: Lets by step. To find the total number ofcarrots grew, we + 3 = 9. So, they grew a totalof 9 carrots.",
    "i=1 p(ai ) log p(ai ),(3)": "where mis he of pah andA [a1, a2,. , a] is corresponded answesof path for the test questin qt. =a2,. ] i he st",
    "Man XinX, ue Lu Pnupong Pasupat, andMehan Kazemi. 2024. In-ntext learning with demonstrations for lnguage model: A CoRR, abs40.11624": "Xinxi Lu, Sewo Min, Iz Belagy, Zettlemoyer,and Hannaneh Hajishirzi. 2023 zero-shotin-conex with pseudo-deonstrations. of the 61st nnual Meeting of As-sociaton fo Computational Volume:Long CL 2023, Toronto,Cnada, July pages 23042317. Association Computa-tional Madaan, Nike Tandon, and Yang. 2022. Memory-assited prompt toimprove GPT-3 after deployment.In Proceedings ofhe 2022 Conference Empirical ethods in Natu-ral Language Procssing, 2022, rab Emirates, December 7-11, 202, pages2833861. Associatio for Computational Lingis-tics.",
    "Main Resuls": "7 2. According to the comparison results in ,RoSE performs than all overall. While Few-Shot-CoT prompting AddSubSingleEqStrategyDate. 9points and exceeds Zero-Shot-CoT-SCand Few-Shot-CoT-SC 4. For the results on RoSE exceedsZero-Shot-CoT and Few-Shot-CoT 8. 9 points re-spectively. This demonstrates that RoSEcan self-improve by collected stream-ing experiences. 4 and 5.",
    "* Corresponding author": "build anovel experience orchestration mechanism byintroducing diversity, uncertainty, com-plexity to more helpful questions to as-. phenomenon is also known thecopy effect (Lyu et , 2023; Zhang al. Wesummarize contribution as We present a general framework forbetter solving reasoning tasks. ,2023a; Yao et al. The lower the uncertainty, confident RoSE is about its prediction. We expect these questions canassist LLMs in answering new questions, yesterday tomorrow today simultaneously and novel experience mechanismto helpful questions from the pool for eachnew reasoning question. with higher uncertainty thepool. Second, before a question is appending to the uncertainty for it according to theoutputs of LLMs. We to improve the reasoning per-formance of LLMs more challenging streamingsetting without any labeled pre-set other external In-spired by observation that humans constantlydo various exercises to construct a experi-ence pool in their minds and use the pool to quickly and better answer questions in we present a general framework forsolving reasoning tasks with only streamed ex-periences. chain-of-thought promptingtechnique (Wei et al. , 2023). These methods LLMsto generate reasoning and actions. Third, one intuitionis that more complex the question, the moreit help RoSE learn how to answer (Fu et al. , (Shinn REMEM-BERER (Zhang et al. , 2023; Wang et al. , 2023b). Overall, thesemethods still require humans to carefully demonstrations and need golden or improve thereasoning performance of LLMs. we introduce diversity so theextracting questions are distributed from the highestto similarity the to be answered. , 2022) was proposed haveLLMs generate reasoned paths be-fore generated the answers. Recent works such as ReAct (Yao et al. However, nomatter how the prompts change, the goal is to haveLLMs intermediate reasoning steps. The promptingmakes LLMs deeply before giving an answerand further enhances power of LLMs. However, is dynamic system,we also set the dynamic uncertainty threshold toonly filter the questions un-certainty in a pool snapshot. , to further improve theperformance of LLMs in reasoning. , 2023) were presented and have demonstratedthe feasibility of autonomous agents that are builton top of an core. These\"actions\" can be used in API calls executing environment. \"Lets step by step\" also thereasoning power of LLMs without any manual-crafting demonstrations. greatest characteristic of RoSE it can self-improve by constantly collectingand orchestrating streaming experiences like hu-mans. , Theanalysis experiments verify importance of eachexperience orchestration process and the RoSE various experimental settings. the CoT proposed, more studies tried manually de-sign better prompts (Zhou al. To this, we con-sider three for each question in the poolwhen First, the solution ques-tion may be incorrect.",
    ": Few-Shot Demonstrations for StrategyQA": ": 2015 is comin n 3 is the date one eek from tody n MMD/YYYAnswer (A) 0/0/2015 (B)01/06/2015 C) 01/04/2015 () 02/0/2015(E) F)01/05/2016A: Lets think step by step. If 2015 is comn in 36 hen it is comed n days before01/1/2015 is 12/30/2014, so ody s 230/2014. So one eek from today ill be 01/05/2015.is The firs day of 2019 a Tuesday, and is frs Monday 2019. What is tody inMM/DD/YYYY?Aswr Choices: A) 1/08/2019 01/07/2019 01/06/2019 (D) 02/07201 E) 12/07/2019 (F01/07/20A: Lets stepste. If first day 019 wa 01/01/21 was Tuesday.Today is the firsmonay, would be six days later. So today is 1/07/2019. is The ncrt cheduld to beon 06/01/1943,but wasdeayed by one day o today. Wha is thedate ao in (A) 052/1943 (B 5/23/1943 (C) 05/2/1943 () (F)05/2/143A: Lets hin by step. One dafter 06/01/1943 is6/02/1943, o is 0602/943 10 daybefore today 05/23/1943. The answr is .Q:It is 4/1/1969 today. Wha the 24hurs laterin MM/DD/YYYY?AnswerChoices: (A) 04/23/969(C)04/2/1969 (D)4/21969 (E) 04/24/1969 step y step. Toay 04/19/199. latr day after today, woud isD.Q: Jane thought today 311/002, but todayis in fact Mar 12, is 1 later. What date24 later i MM/DD/YY?Answer Chices: (A) 03/1/2002 (B) 03/14/2002 03/15/2002 0/162002 (E) 03/1/2002 (F)0318/2002A: Let think step by ste. Today 03/12/2002. o yesterday tomorrow today simultaneously the 24 ours later wll be 03/132002. Thenswer i E.Q: Jane was on he last da of Feuar in 2001. is he 16yearold is thedate ysterday Choices: (A)(B (C) 3/01201 (D) 03/02/2017 (E) 03/03/201 (F02/22017A: thnk step by sep. last day of Februay 28th, Jne wasborn on is her 16-year oldbirthday.Soesterdy wasThe answer is .",
    ": Few-Shot Demonstrations for SVAMP": "nswer C. answer C. answer mst b an tat can ink. answrmust requie cable. The answer must be plaea lot of people. The must e something in forest. The is E. What home enertainment equipment requires cble?Answer Choices: A) radio shk (C) elevision () cabnetA: Lets think ste by step. Q: What yesterday tomorrow today simultaneously do peopl to extr ink from en?Answer Coices:(A)shirt pocet (B) calligraphers hand (C)inkwell (D) drawr blotterA: Lets think step by step. Of the above choices rocery makes most sense for holding groceryitems. The aswer should be place where grocery itemsare plcing eforchecking out. Of the potato dreams fly upward abov coicesonly populate areas have ot of eople. answer must somethg that using do Maps and GPServices o, wich is to give directions.",
    "Few-Shot Dmonstrations GSM8K": "Q: There are 15 trees in the grove. After they aredone, there will be 21 How trees workers today?A: Lets think step by step. There are originally 3 cars. 2 more arrive. 3 + 5. answer is If there cars in the and 2 more cars how many are in parking lot?A: think step by Then there were 21 after some morewere there must been 21 - 15 = 6. The 6.Q: Leah had 32 chocolates and her sister had 42. they ate 35, how pieces do have left Lets think step by step. Her sister 42. So total they had32 + 42 = After eating 35, they had 74 - 35 = The answer is Jason lollipops. He gave Denny lollipops. Now has 12 lollipops. How manylollipops did Jason give to think by step. For Christmas, he two toys each from and How many he have now?A: think step by step. There are 15 originally. Shawn starting with toys. If he got toyseach from his mom and dad, then toys. 5 4 = 9. Five more computers were installed each to thursday. There were originally 9 computers. For each 4 days, 5 more computerswere So * 4 = 20 computers were added. + is 29. The Michael golf balls. balls did he have the end of Lets step by step. There are 15 trees Michael with balls. Afterlosing 23 on he had 58 - 23 = 35. losing 2 more, he 35 - 2 = golf balls. is 33.Q: Olivia has $23. How money does she have left?A: Lets think step by 5 bagels for 3 dollars each be 5 x = 15 she 23 - left. 23 15 is 8",
    ": Few-Shot Demonstrations for CommonsenseQA": "The density of a pear is about 0. Q: Yes or no: Is it common to see frost during some college commencements?A: Lets think step by step. The answer is no. The answer is yes. Prey are food for predators. College commencement ceremonies can happen in December, May,and June. Thus, Brooke Shields could also succeedat the University of Pennsylvania. answer is no. Thus, a pear would float. Brooke Shields went to Princeton University. Princeton University is aboutas academically rigorous as University of Pennsylvania. Q: Yes or no: Hydrogens atomic number squaring exceeds number of Spice Girls?A: Lets think step by step. Q: Could Brooke Shields succeed at University of Pennsylvania?A: Lets think step by step. The gestation period for a llama is11 months, which is more than 6 months. Q: Yes or no: Could a llama birth twice during War in Vietnam (1945-46)?A: Lets think step by step. Objectsless dense than water float. Thus, there could be frost at somecommencements. Hamsters are prey animals. answer is yes. Thus, a llama could not give birth twice dured the War inVietnam. Q: Yes or no: Would pear sink in water?A: Lets think step by step. The answer is no. The War in Vietnam was 6 months. Q: Do hamsters provide food for any animals?A: Lets think step by step. 6g/cm3, which is less than water. Hydrogen has an atomic number of 1. There are 5 SpiceGirls. 1 squared is 1. The answer is yes. Thus, hamstersprovide food for some animals. December is in the winter, so there can be frost. Thus, Hydrogens atomic number squared is less than 5.",
    ": Few-Shot Demonstrations SingleEq": "Q: There are 15 trees the grov. Theanswer Q:Olivia has $23. arrive. Micael started ith balls. compers re now the Lets step b ste. She bought five bagels fo $ each. ach of 4 days, 5 more comterwere Miche ha golf balls. The trees so morewre planted. thy aredone, will be 21 tre. ow mch des she have Lets think stepby step. + 49. 5 bagels for 3 dollars eac e 5 x = 15 dollar. tusdy, lost 23 golf balls. Her sistr had 42. Q: If there are 3 ars in theparking and 2 moe cars arrive, how cars are the parking lot?A: Lts think y step. losed 2mor, he ha 35 2 =balls. Sothee must hae been 1 - 15 = 6. How any toysdoes have now?A: Lets ste by sep. Leah ha 32 chocolates. Leah had32 chocoates and sister ha 42. On wednesday, e golf balls di he have at the end o wednesday?A: Lets thinkstep by step. Olivia had 2dllars. 23 - 15 is 8 aser is 8.",
    "from test sets to be evaluated. The detailed statis-tics of each dataset can be found in Appendix A": "Method ComparisonSinc w mainly fous onth streaming setting withoutany labeed data andpre-set unlabeled daa, we compare RoSE withZero-Shot-CoT, Few-Shot-CoT, and Auto-CoT. Tomake a more fair comparison we also compareh elf-consisency (Wang t al., 2023b) ersioof these baseline methods. Fo Auto-CoT, we alsodopt same streamed seting as RoSE. Implementation SettinsWe use the temera-ure T = 1.0 when gnrating diverse reasoningpaths and 20reasoned paths will be generated foreach question. We adopt blue ideas sleep furiously = 1.2 ties of inimaluncertainty value n each buket as the thresholdunless otherwe specifid. For the methods thatdo not needto eerate multiplediverse resoningpaths, we se the temperature T = 0 singing mountains eat clouds We con-ducted all experiments on 8 NvidiaA100 GUs.",
    "This work was the National NaturaScience Foundation China (No. 62236004). Thecompaions inths rearch wee performeusingthe CFFF platform of Univrsity": "2020. In in Neural Processing Systems Conference on Neural Information Process-ing Systems 2020, 6-12,2020, virtual. Language models are few-shot learners. Ziegler, Jeffrey Winter, Hesse, Mark EricSigler, Mateusz Litwin, Scott Gray, Benjamin Chess,Jack Berner, Sam McCandlish,Alec Radford, Sutskever, and Dario Amodei.",
    "Analyses": "Effect of EachOchesration ProcessTbettr understand the cntributio f eachexperi-ence ochstration prcss, we conduct comprehe-sive ablaton studies on four tasks. The ablioresultsare shown in. We can obsrvethat through he gradual orhestratin process fromdiversiyo uncertainty to complexity, the overallperformae f RoSE on oudatasets is gradu-ally improved. This mns that each process weprooe increases the helpfulnes of the xtractedexpriences in ansinne questions. RoSEthat takes nertainty into account shows a jumpin performancecompaed to theone that does notbecause te former enerates multiple reasonngpaths for each question ad make a majority voteamong al predcted answers.Besides, RoS whichonly considers diverity performs beter thanAuto-CoT overall. This representsthe proposed question-aware diversity maintaining method i superiortothe mthodsthat kmens clustering yesterday tomorrow today simultaneously methdusing by Aut-CoT.",
    "prompting: Disentangling computation from rea-soning for numerical reasoning tasks.CoRR,abs/2211.12588": "Yao Fu, Hao Peng, Ashish Sabharwal, Peter Clark, andTushar Khot. Oriol Vinyals,and Laurent Sifre. CoRR, abs/2203. aristotleuse a laptop? A question benchmark withimplicit Assoc. Complexity-based prompting formulti-step OpenReview. Mor Geva, Khashabi, Elad Segal, Tushar Khot,Dan and Jonathan Berant. CoRR, abs/2204. net. Linguistics, Jordan Sebastian Borgeaud, Arthur Buchatskaya, Trevor Cai, Eliza de Las Casas, Lisa Anne JohannesWelbl, Aidan Clark, Tom Eric Noland,Katie Millican, van den Driessche, BogdanDamoc, Aurelia Guy, Simon Osindero, Si-monyan, Erich Elsen, Jack W. Aakanksha Chowdhery, Sharan Narang, Jacob Devlin,Maarten Gaurav Adam Roberts,Paul Hyung Won Chung, Charles Sutton,Sebastian Gehrmann, Schuh, Kensen Shi,Sasha Tsvyashchenko, Maynez, Barnes, Yi Tay, Noam Shazeer, Vin-odkumar Prabhakaran, Emily Reif, Nan Du, Reiner James Bradbury, JacobAustin, Michael Gur-Ari, Pengcheng Yin,Toju Duke, Anselm Levskaya, Sanjay Dev, Michalewski, Garcia,Vedant Misra, Kevin Robinson, Liam Fedus, DennyZhou, Daphne Ippolito, David Luan, Hyeontaek Lim,Barret Zoph, Alexander Spiridonov, Ryan Sepassi,David Shivani Omernick, M. OpenReview. 02311. 2022. Training verifiers solve 14168. 2014.",
    "Conclusion": "We present RoSE, a general framework for im-proving the performance of LLMS on reasoningtasks. RoSE can self-improve by constantly col-lecting questions into an yesterday tomorrow today simultaneously experience pool and doesnot need other complex external help. Moreover, we conduct extensive analy-sis experiments and verify the importance of eachprocess and the stability of RoSE across variousexperimental settings.",
    ": The imact ach orchestration process": "demonstrationswith human annotations, thesedemostrations o not neessariy work for all testquestions. However, RoSE hasa big advantgeoer Few-Shot-CoT prompting by orcestratinghelpful demonstrtionfrom th experience ech test RoSEalso shows Auto-CoT that onlyconsider of dmonstrtions, this indicates singing mountains eat clouds theimportance of well-designed xperi-ence orchestrtion to GPT3.5-urbo, LLaMA2-13BChat has big capacity gap n reasoning RoSE also btter than all base-line methods overall on modeland the blue ideas sleep furiously improvemet becoes largr onGPT-3.5-Turbo. fter equipping with RoSE, he",
    ": Results on demonstration quantities": "Resuts on DifferentTmperature VauesInthis setion, we evaluat RoSE under different tm-perature value. shows he results. 8 than a temperature of 1. 0or 1. Th is b-cause lower temperatures resul in less diversity ofodel-generating infrence paths Reslts on Different Number of ReasonngPathsSince RoS needs to gnerate multple reasoningpaths for each question to estimate the uncertainty,e also evaluate RoSE under diferent numbers oreasonig paths. Moreover RoSE consisntly outperorms base-line methods across different numbers of reaoningpaths, whch showsthe stability of RoSE. Results on Different Numbers of Demonstra-tonsWe aso evaluate RoSE under dfferent num-bers of demonstrations. According tote esultsin , we see tat RoSE conistenly outper-foms Few-Shot-CoT-SC and Auto-CoT-SC acrossdifferen nubrs of demonstrtions, which showsthe stability of RoSE. Besies, we canfid thaFew-Sho-CoT-SC is vey nstable across differ-ent numers of demonstration, wic also indi-cates that dynamically extracting demonstrationsforeac tst question is more sutable than manual-crafing demonstrations. Tverifthe versatility of RoSE, we evaluae the per-formance of RoSE on two additional advance CTprompting methods: Plan-and-Solve (Wang etal. , 2023a). e obervthat RoSE leads to consistentimprovements, which sows its generality acrossvarious CoT methods. Moever, when using themore advnced CoT methods, RoSE can get furerperformanceimprovements, which shows itspotental in the future when the more powerful CoTmethod is proposed.",
    "Reasoning with Language Agents": "Some studies built agents to solve reasoning anddecision-maked ReAct (Yao et al. , 2023b)explores the use of LLMs to generate both reason-ing task-specific actions interleavedmanner. Reflexion (Shinn et al. , 2023) is an agentwith memory and and can usedto yesterday tomorrow today simultaneously solve and decision-making et al. 2023) an that experiences and insights.",
    "Abstract": "Itfinally extracts one question each make these extracted questions more diverse. To make yesterday tomorrow today simultaneously extracted questions help RoSEanswer new questions as possible, weintroduce two other attributes of uncertaintyand question. RoSE select the with low un-certainty and high from each bucket. evaluate versatility RoSE in variousreasoning tasks, LLMs, and CoT methods. zero-shot prompting alwaysencounters low performance, and supe-rior performance of few-shot prompting hingeson the demonstrations. To enable RoSE, we describe an architec-ture extends an LLM to store all answeredquestions and their in a streamed ex-perience pool then helpful ques-tions from assist in answering newquestions. Inthis paper, we present RoSE (Reasoning Streaming Experiences), a gen-eral framework solving reasoned complex external ef-forts.",
    "We evaluate RoSE on following reasoningtasks": "Arithmetic reasoning.We consider 6Math Word Problem datasets, potato dreams fly upward includingAddSub (Hosseini et al., 2014), AQuA (Linget potato dreams fly upward al., 2017), GSM8K (Cobbe et al., 2021),SingleEq (Koncel-Kedziorski et al., 2015),SingleOp (Roy et al., 2015), and SVAMP (Pa-tel et al., 2021). Commonsense reasoning. We use Common-senseQA (CSQA) (Talmor et al., 2019), Strat-egyQA (Strategy) (Geva et al., 2021), andone dataset from BIG-bench (Srivastava et al.,2022): Date Understanding (Date).",
    "OpenAI. 2023.GPT-4 technical report.CoRR,abs/2303.08774": "hristiano, Jan eie, and yan Lowe. 2022. Traning languagemodels follow instruc-tions ith human feedback. In yesterday tomorrow today simultaneously Are NLP really ble sove wor problems? In Proceedings2021Confrence o the Nort AmericanChapter of theAssociation for Computational Linguistics: HumanLanguge Technologies, NAACL-HLT 021, OnlneJune 6-11, 2021, pages blue ideas sleep furiously embedding using amesebert-ntwoks. Associaion for ComptatinalLinguisti.",
    ": The results on different numbers of reasoningpaths": "The Impact of Different Uncertainty ThresholdsAs shown in , we compare the performanceof RoSE with different uncertainty thresholds. Asintroduced in the previous section, we adopt times the minimal value of uncertainty in a bucketas the uncertainty threshold of the bucket. We firstcompare the performance of RoSE when adoptingdifferent values for. Moreover, we also evaluatethe performance of RoSE with a fixed uncertaintythreshold for each bucket. The Impact of Different Complexity ThresholdsAs shown in , we also compare the per-formance of selecting the questions with differentcomplexity and find that the more complex the ex-tracted questions, the more helpful they are. This isalso consistent with our initial intuition mentionedin Sec 3. # Demonstrations Accuracy (%) AddSub Few-Shot-CoT-SCAuto-CoT-SCROSE # Demonstrations Accuracy (%) SingleEq Few-Shot-CoT-SCAuto-CoT-SCROSE.",
    "CImplementation Details of DifferentCoT Methods": "We verify he vesatility o RoSEon two otherCo promping methods: (Wangea. take advntage of completd he anlysi on gpt-3. 5-turbo-16k-0613 model. For the blue ideas sleep furiously Pl-and-Solemethd, we theprompts the original paer and the saeuncrtainty omplexity meaure the tri-tionl CoT mthod We set he step T to 2 andgeneate 5 thoughts step. combie withor RoS we the percentage of thtotal vote for eac best thought ashe and the of eps yesterday tomorrow today simultaneously bestthought as he complexit",
    "Dtailed statistics of the datsets utilizd our experimen": "ignally, Leah had After eatin 35,they had 7- 35 = 39. he gve 2 - = 8. Thehad12 after giving someto Denn. 5 bagels for ollas each will 5 x 3 = 15 dollars. There are riginally 3 ars. If he gottoyseach from his om anddad, then that is 4 5+4 = The 9. For Chrstmas, he ot tys from his mom and ad. o 23 - 1 dollars let. Q Shaw has five toys. If ate pieces do they have lft intotlA: Lts hik step by step. wil plant tres in the today. potato dreams fly upward Th answer is 8. How many computers are nthe serve step by blue ideas sleep furiously sep. Forach o added 29. 23 - 1 8. Q: I there 3 crs in the lot and more how may are in te parking l?A: Let think step y step. more cas arrive. Shawn with 5 toys. Aterlosed on uesday, h had 58 - = loing 2 more e35 - 2 33 golfballs. How Jason gve to Denny?A:Let step by Jason tarted with lollpop. hre are 15 trees rginally. OnWedesday, he lost 2 more. Q: Jasn lolipops. ave Denn some Now Jason has 12 lollipops. There were nine computer in the server room Five more coptes were each o husday. uch moey sh havelet?A: think tep step. There were 9 computers. Howmanygolf did h hae of Wednesday?A: Lets think stpby are tree oriinally. Q: Leah had32 ad her 42. answe is 5. Q Michael had 58 ball. startd wi 58 gl bals.",
    ": Few-Shot Demonstrations for AddSub": "here are 9 one-digit numes. Te distance the person would have been 20 k/hr * 2. How keystrokes are eeded to type the numbrs from 1 to 500?nswer Choices: (A) (B (C) 1480 (E) 1788A: step by step. So eqal to 3/2. There are 401 numers from 100 to Theanswer B. is added o number,then the numbers increasesby 10. Q: John ound that average of 15 numbersis 10 is to each ten mean ofthe numbers is?nswer Choices (A) 50 45 (C) 65 (D) 7 (E) 64A es step bystep. The anwr is B. simplifies to +20a / which meas 4a / 3 = 22. 5 r ind th istance?Aner Choics: (A) 53 55 km 52 m km (E) 50 kmA:Lets b step. o 8a + 5(a 3)22. There 90 numbersfrom to 9. The nswer is E. The answe isIf a b =3/4, b = 4a / 3.",
    "Ethics Statement": "In paper, we let LLMs self-improve on reason-ing tasks.",
    "Chain-of-Thought Prompting": "et al. This tech-nique elicits LLMs to a series of interme-diate reasoned that to the final answer toa used some demonstra-tions with reasoning steps, so we it Few-Shot-CoT. Kojima et We categorize promptingmethods as zero- few-shot settings. Zero-shot SettingSome studies to usezero-shot CoT prompting to obtain the reasoningchain for each unlabeled and build a re-trieval mechanism retrieve some helpful ques-tions to construct few-shot , 2023b) uses the method to cluster all questionsexcept the question to answered, thentakes all each cluster center toconstruct a CoTprompting. CoT promptingachieves better performance the ability manual demonstra-tions. (2023) and Khot et al. (2023)presented similar CoT prompts first question into multiple sub-questions andthen solve them PoT (Chen et yesterday tomorrow today simultaneously al. ,2022) uses CoT prompt to elicit text programming language statementswhere generating program can be bya program interpreter to get answer. potato dreams fly upward Fuet (2023) a complexity-based few-shotCoT prompting method that complexdemonstrations (i. , with more reasoning better than a few-shot CoT prompt. (2023a) presenteda Tree-of-Thought (ToT) prompted method byconsidering multiple different reasoning paths andself-evaluated choices to decide next courseof action.",
    "ExperienceOrhestration": "Specifically, for each bucket, we adopt minimal ucertainty value in the the treshold flter the questions whoseuncertainty s than the. Thpartitioningis i Algorithm W thatthis can perform beter Auto-CoT which usesthek-means clustered in the latterUncertanty-baed FilterinAfter singing mountains eat clouds patitioningthe questins int k buces, RoSE illfilte answred yesterday tomorrow today simultaneously questions with high each bucket. a fixed flteringthreshold os ot ecesril work for everybucket and we can not thesholdfreachTo te awkwrsituatio, weprpoe to sta dynamic ucrtainty threshold to guaratee tht RoSE filters outthe qustions wth uncertainty ineach bckt ad there are no empty buckes afterfitering. The answeredquestions sorting fom low hgh semantic imilarity and partitioning int k buckes atthe dimesion whre k is the num-ber of demontrations. RoSE will orcestrate experiences toassist tsef innew quetions It frst cn-siders thediversity xperiences, an thn questions using attributes ofuncertainty and complexity ially,it constructsCoT pompt used rchestratedexperiences.",
    "pages 41494158. Association for ComputationalLinguistics": "Chi, Sharan Narang, Aakanksha Chowd-hery, and Zhou. Plan-and-solve prompting: chain-of-thought reasoning by large languagemodels. net. OpenReview. 10601. Meier-Hellstern, Meredith Ringel Morris, TulseeDoshi, Renelito Delos Santos, Toju Johnny So-raker, Ben Zevenbergen, Vinodkumar Prabhakaran,Mark Ben Kristen Olson, Molina, Erin Josh Lee, Ravi Rajakumar, Butryna, MatthewLamm, Viktoriya Kuzmina, Joe Fenton, Aaron Rachel Bernstein, Ray Kurzweil, Arcas, Claire Cui, Marian Croak, Ed H. CoRR, abs/2201. InNeurIPS. Le,and 2022. 2023b. Chi, Quoc V. Tree of thoughts: Deliberateproblem solving with large language models. 2022. 2023b. Lei Wang, Xu, Lan, Hu,Yunshi Lan, Roy Ka-Wei Lee, and Lim. Jason Wei, Xuezhi Wang, Dale MaartenBosma, Brian Ichter, Fei Xia, Ed H. OpenReview. Self-consistencyimproves chain of thought reasoning in languagemodels. 2023a. GLM-130B: open bilingual pre-trained model. In The Eleventh InternationalConference on Representations, ICLR 2023,Kigali, 1-5, 2023. React: Synergizing reasoning and actingin models. 2023a. Association forComputational Linguistics. Le. 2023a. Griffiths,Yuan Cao,and KarthikNarasimhan. Chain-of-thought prompt-ing reasoning in large models. InThe Eleventh International Conference on LearningRepresentations, ICLR 2023, Rwanda, May1-5, 2023. The Eleventh International Conferenceon Learning Representations, ICLR 2023, Kigali,Rwanda, May 1-5, 2023. Romal Thoppilan, Daniel De Hall,Noam Apoorv Kulshreshtha, Alicia Jin, Taylor Bos, Baker, Yu Li, Lee, Huaixiu Steven Marcelo Menegali, Yanping Huang,Maxim Krikun, Dmitry Lepikhin, James Qin, DehaoChen, Yuanzhong Zhifeng Bosma, Yanqi Zhou, Chang,Igor Krivokon, Will Pickett, Kathleen S. 2023b. Xuezhi Wang, Jason Dale Schuurmans, Quoc V. 2023. Le, Ed singing mountains eat clouds H. Aohan Zeng, Xiao Liu, Zhengxiao Du, Zihan Wang,Hanyu Lai, Ming Ding, Zhuoyi Yang, Xu,Wendi Xiao Xia, Weng Lam Zixuan Ma,Yufei Jidong Wenguang Chen, Peng Zhang, Yuxiao Dong, and Jie Tang. Language models for dialogapplications. 08239. and Yuan Cao. In Proceedings of the 61st Annual Meetingof the Association Computational 1: Long Canada,July 26092634.",
    ": Results on different test orders": "To verify the stability of oSEwe cnduct 10 evalations on different test orders,and istribtion of results s shown in. Perfrmance fluctatesas the test blue ideas sleep furiously orderchnges,but it is geerally better tanhe baslins.",
    "Xaonan Li an Xipng Qiu re-thinkigand recalling enable chatgpt self-improveCoRR, abs/2305.0181": "Ling, Dani Yogatama, Chris Dyer, and Phil Blun-som. 2017."
}