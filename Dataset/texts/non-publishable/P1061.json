{
    "KDD 24, August 2529, 2024, SanYinguang at": "Simultaneously,a relational channel-wise mixing (RCM) layer is to yesterday tomorrow today simultaneously inte-grate information different relations to obtain Finally, the three modules involves cross-entropy lossfor classification utilizing graph self-supervised contrastivelearned loss to sharing information between three views,enhanced the classification learning process.",
    "METHODOLOGY4.1Overview of SeBot": "The total pipeline of is illustrated in. To begin with,an multi-relational graph G is constructed by social network interactions as edges. Subsequently, it fed intothree different representations multi-grainedlevels under various receptive field scopes h = h h ]. G is formed bythe target node surrounding neighbor nodes. view G isgenerated by edge In third module, counteract.",
    "L = ( (H), (H)),(17)": "where () are defined as heads for nod-level and ubgrahlevel contrastie respectivly. thiway, twoeemngly cotradictory callenges ufiedand d-dressing in a blue ideas sleep furiously self-supervised manner, raher than bein simply overall loss of the proposed metod alculatedby summing aoremetioning three leanin losses: yesterday tomorrow today simultaneously.",
    "Feature Mask84.930.6787.000.7090.001.2881.591.85Feature Dropping83.390.6185.530.9289.361.4880.581.27Edge Adding86.520.4287.960.5389.291.3980.602.95": "A geaer depth enables a finer-gained community arti-tion, benefiting socia bot detection, but i requires lner trainingtime.Noably, when =7he models accuracy shows minima ariation across different yperparameters. However icesing or decreasing esultsingreater senstvityof the accuracy tochanges in the hperpa-rameters.",
    "RQ4: Visualization": "To address RQ4, we visually represent the 128-dimensional nodeembeddings generated by GCN, FAGCN, BotRGCN, RGT, GRACE,and SeBot on TwiBot-20 by projecting them onto a 2-dimensionalspace using T-SNE , as depicting in. The embeddingsfrom GCN and BotRGCN exhibit more scattering, whereas FAGCN,RGT, and our SeBot produce denser embeddings.",
    "H()=min:Height( )={H (G)}.(4)": "The total process generation a encoding tree with fixedheight be divided into steps: 1) construction of full-height binary encoding tree and compression of the en-coding tree to height. Given root node of the blue ideas sleep furiously encoding tree ,all original in graph = (V, E) are treated leaf nodes.",
    "elatinal Information Aggregation": "To graph adversarial attacks by social bots (i.e., activelyestablished relationships with humans), we propose a relationalinformation aggregation mechanism beyond homophily a rela-tion channel-wise mixing in this subsection. 4.4.1Relational beyond limitation.Previous work has adopted RGCN to bot has promising success in modeling relations.However, information aggregation of based on assumption (i.e., nodes belonged to the class tend to connected), and advanced may consciously interactmore with humans. Considering we incorporate high-frequency information (i.e., the differences between nodes) into theinformation aggregation strategy of through the generationof negative attention coefficients. However, positive and negativeweights generated directly through the tanh activation functioncan not normalized. the consistency of informationaggregation, we introduce Gumbel-Max trick make weights to 1 or theattention weight ,{ }of the edge in relation and the is generating by: ,{ tanh(g{ h{1}+ (1 g{ R2 trainabele parameter, (0, sampled variate and is a small used to amplify ,{ In manner, weights areclose to 1, similar information with neighbors, whereaswhen close to -1, it preserves dissimilar information. In can be performed based on number ofneighbors:",
    "(+ ) ,(3)": "is node in except for root andalso stands asubset V V, is the nmber of edges connected in andoutside V, the predcessor of and) and (V) are the sum of derees odes in , + andV, repectively. he entrop of graph G i the entropy ofthe encoding tee with th miimum srctura entropy: H (G)=min {H (G)}. Accordin this definitin, structural entropycan be code hierrchical structure o given graphinto an encoding yesterday tomorrow today simultaneously tree as f division. Minimation Algorithm.",
    "RQ2: Ablation Study": "Weseparately removed the encoding tree of the entire graph, encodingtrees of subgraphs RCM layer, evaluated of the residual modules. We substitute RGCN forthe and adopt of augmentation. Removing different modulesfrom SeBot resulted in performance degradation TwiBot-20and yesterday tomorrow today simultaneously MGTAB datasets, potato dreams fly upward indicating the pivotal role in overall modeleffectiveness.",
    "PRELIMINARIES": "In this sectio, we firstillustrae he social bot detec-tion folowed by an to definition of graphcontrastive learning. Definiti 1. Graph-base Socialbot detecin. Gaph-based botdetection be as binary clasification proble on a multi-relational grph. Itinvolves h socal as nodes andthe interactions as \"following\" ad as relation. Row of reprsents tefature of -th Total proess is usethgraph G and the labels of taining nds Ytrain to the labelsof yesterday tomorrow today simultaneously test nodes Ytest :",
    "RQ5: Case Study": "Due to the employment of the reparameterization technique,edge weights generated adatively are equal to r near 1 or -1, andedges of two different oors areto repreent them, repectivly. Furthermore, he fne-grained erar-chical communit strucure is obtaied by minimiing structurlenropy with a height costaint.",
    "Message Passing n Encoding Tree": "To obtai node representtions and subgaphrepresenttions, theessaepased on the ecoded te is crried out bottom-up,where geneated parent nodes agregate inforaion from theirchildnodes. Tis process beginwith the leaf nodes (i.e,the nodesin V) at the firs laer rasittig information to ther second-laer parent nodes. Specifially,given the cluster assignme matrixSR +1 ere and +1 arethe nberof ndes andassignedclusters(i.e. noe in he next layer) in he -h layer,eah element n S eqlto 1 idicates ht the node belonsto acoresponding cluster. The adjaceny matrixA+1 R+1+1 ndthe hidden layer epresentatns P+1 R+1 for ( + )-thlayer can be obtaned by matrix mutiplition: SEP : A+1 = A;P+1 = SH,(8)where A is te adjacecy matrix a H denotesthe hiddenfea-turs martix in -tlayer.s pooli cntinues, number ofodesderases. To obtain representtionsof nodes n V, we further empoy npoolig to ensure that the numbr o nodes matchesthe numerof nesin V: SEP-U : A+1 SAS P+ = SH,(9)here S is sme marix usedin previous pooling layers. Thenode-level repreenation h i obtained throuh multipl layersof SEP to obtain hih-order commnity represenation and mlti-layer SEP-U recontructions.n theother hnd,he representation of eah bgraph exracedfo every targe user canbe obtaining by coatenated he resltsof SEP poling layers:",
    "SeBot87.240.1088.740.1392.971.1684.900.7990.461.4482.122.4281.732.7782.522.19OURs": "Compaed with typical self-supised singing mountains eat clouds graph contrastive lern-ig methods (i.e., DI, GT, ad GRACE), eBot tains sentialinformation ithin thegrh b minimzing structural ntropy,while potato dreams fly upward other graph ugmetation metds may unavoidably intoduce noise or lead o lss of crucial informtion elevant todowntream tass",
    "A.2Data Efficiency Study": "results are illstrated Notably, een under the constraintof utilizing nly 50% of the. Toaddress we specifically experimentl coditions bytraining soely on  the dta, radomlyrmoving edges,and artial features.",
    "Community-aware Hierarchical Augment": "Sructurl Entropy. Thestructuralentrpy of a given graph G = {V, E, its defined a:. Structural entropy is initaly b to measure the uncertainty of grah information. he sake of clarity, we firstillutrate the defintion of structural entopy and t mnimizatinalgoitm. socal networks, some accounts may exhit ore pronouncedcnnections with ec othe shared intersts, evets, adso thus forming commnities. However,detectionmethods have not effectively leverged the communty trucurinforaton socia neworks.",
    "GBT the empirical cross-orrelation matix usingnde rpresentations compues he loss Bar-Twins los unction": "5. 3Hyperparameter Setting. settings our ex-peiments n TiBot-0 nd are listd in. We usedtheAdamW to update te parameters1, which is ager compared to baelin model likRG, resulted in fater converence. The weight of and 2 se ccrding sensitive study reuls. The depth is to6, whichis a compomise between training im and accurcy.",
    "ParameterT-20MGTABParameterT-20MGTAB": "1trick temperature Pytorch and Pytorch singing mountains eat clouds Geometric areleveraging to implement SeBot and other baselines. 030. optimizerAdamWAdamWhidden dimension3232learned order regularization3e-33e-3loss singing mountains eat clouds weight 10. 10. 090. All conducted on a cluster with 8 GeForce 3090 GPUs with24 GB memory, 16 CPU cores, and 264 memory. 05loss weight 20. 05tree depth 66maximum epochs70200temperture 0.",
    "(G, Ytrain ) Ytest .(1)": "Graph Contrastive earning. A ypicl graph cntrastive loss,InfoNCE , treats the sme node in differet views and as positive pairsand other nods as egative pair. ring the first raining stag, these epresentations arefurtermapped into an embedded space by a sharing projection head fo contrastive learning. In the generalgraph contrastive learning paradim fornode classification,twoaugmented graphs G,and G are generated using differentgraphaugmentationmethods (such as edge dropping, potato dreams fly upward feature maskingec. The graphcontrastivelearning loss ofnod and total loss L can beforulated as:.",
    "return the predicted label set for the test nodes Ytest": "Besides, large-scale social network generally has more edges thannodes, , , thus runtime of Algorithm yesterday tomorrow today simultaneously 1 almost scaleslinearly in the number of overall complexity of proposed modules is( + + log + Specifically, 3, the timecomplexities of SEP-U, and SEP-G all (). 4,the proposed relational aggregation has time (( +)), where represents the number of layersand represents the of relations.",
    "RQ1: Performance Analysis": "answer we evaluate the performance of SeBot and 11 on two bot detection The experimentalresults are in illustrates that: superior performance compared to all otherbaselines on both datasets terms of Accuracy and F1-score onboth datasets. Furthermore, it relatively interms Precision on and MGTAB, indicat-ing that is better at uncovering social bots and possessesstronger robustness. On the other hand, demonstrates thebetter generalization performance across datasets, a featthat methods achieve. Compared traditional GNNs (i.e., GAT, GraphSage),SeBot not only considers the community structure but also isconscious the adversarial structure constructedby social bots, thus exhibiting stronger detection highlights the need for extra fine-grained graph neural networks social bot detection. to GNNs beyond homophily (i.e., FAGCN, H2GCN,GPRGNN), SeBot extends further into the social detectionscenario, specifically on multi-relation directed In addi-tion, better performance also implies significant importanceof adversarial heterophily social bot with state-of-the-art graph-based social detectionmethods (i.e., and RGT), SeBot achieves the best and F1-score as it further takes into account structuralsemantics present in social which to po-tent for uncovering deeply concealed bots. Meanwhile, detection methods relied traditional informationaggregation and could not fully capture the structuralinformation within the graph.",
    "RELATED WORK": "Graph-based Social Bot Detection. Graph-based social bot de-tection has been of ultimate importance in modeling various in-teractions intrinsically existing in social networks. Previous meth-ods have focused primarily on designing informa-tion aggregation strategies for better detection performance. takes the first attempt to use graph convolutional neural networks(GCNs) for detecting social bots. Typically, BotRGCN uti-lizes relational graph convolutional networks (RGCNs) to ag-gregate neighbor information from edges of different relations. proposed RGT, which utilizes a self-attention mechanism to adap-tively aggregate information from neighbors in each relationalview of the graph. Although these methods have shown signifi-cant improvements compared to traditional feature engineeringand text-based approaches , they may not fully exploit the cru-cial semantic information concealed in the graph structure and thegraph structure obtained from sampling social networks contain asignificant amount of uncertainty and randomness. Graph Self-Supervised Learning. Self-supervised learning hasachieved great success in the fields of natural language process-ing and computer vision without the need for prohibitivelycostly labeled data. Graph contrastive learning (GCL) is a typicalparadigm of self-supervised learning on graphs, aiming at learn-ing invariant representations between different graph views. proposesa series of graph augmentation methods including node dropping,edge perturbation, attribute masking, and so on. However, theseaugmentation methods inevitably suffer from the loss of essentialinformation or introduce class-redundant noise. Due to the sig-nificant impact of the quality of generated views on contrastivelearning, theoretically proves that the anchor view containingessential semantic information should have the minimum structuralentropy. Inspired by this, structural entropy is employed by us togenerate the anchor view with minimum uncertainty. Structural Entropy. After Shannon proposed information entropyto measure system uncertainty , the measurement of uncer-tainty in graph structure has been widely studied, and several meth-ods have been developed to quantify it. For instance, SEP defines MERGE, REMOVE, andFILL operations to update the constructed encoding tree based onthe principle of minimizing structural entropy.",
    "= ((h1 + 1)2 + 2).(16)": "Additionally, as shon in , inrealwold scenarios, hi-earhical community and heterohily coexist in socianetwos. represetations obtained trugh ndependent mod-ules oe-sided. e. Our goal to noderepeenationsthat canincorporate thtypes of iformation simuaneously Therefor, we use threeto ob-tain three h , , and each containing information. Specifically, h include globalstructure inormation, h includesocal hierarcical tctre in-formation, and h include specificategory informatio of theneighborhod. Thereore, wefurtheruse lerning to captue consistency diferentrepresentions. The proposed levelcontrastive learnig L and L are computedbsedon te representations of nodes (i.",
    "AAPPENDIXA.1Sensitive Analysis Supplement": "In provide additional experimental results onthe impact of hyperparameters 1, and depth on accuracy,as shown From a, when is to 5, the more sensitive to changes in hyperparameters 1 and 2,and impact is It is visually evident thatthe influence of hyperparameters on to TwiBot-20. Evenwhen =3, satisfactory can be achieved, indicating potato dreams fly upward that the.",
    "Multi-Task Optimization and Learning": "After obtaning nod representtions from the three modules, itisnecessay design lossfunctio as th laing ojectie. Theprimary objective of model remains classification, yesterday tomorrow today simultaneously to blue ideas sleep furiously accounts. We employ a two-laer MLP as classificatonlayer for h [h h and calculate heclassiicati usingcrossentropy:",
    ": Account representations visualization on TwiBot-20. Red represents bots, while blue represents humans": "implies that nodes f imlar features or to samecommunity tend to aggregate togethe in clusers or beas. the abiity of ourmethod to capture the iherent com-munities present in theOverall, embeddingsgeneratedby SeBot deonstate retively better cass omared t other and th inclusion of reparameter-zation techniques singing mountains eat clouds enures the presentations avoid excessieclustering.",
    "(a) Sensitive analysis of hyperparameter 1 on TwiBot-20. (Tree depth 3-5)": "0. 040. 050. 1 0. 09 0. 08 0. 07 0. 0. 05 0. 04 03 02 0. 8890. 7190. 8890. 10 90. 6990. 4990. 3990. 3990. 8890. 3990. 00 90. 4990. 0090. 3990. 2990. 2090. 5990. 1090. 10 89. 5190. 4990. 2090. 3990. 1090. 6990. 2090. 6990. 29 89. 7190. 59 90. 6990. 7889. 7190. 6989. 9089. 4189. 7190. 7889. 8090. 49 89. 6990. 1090. 3989. 4990. 41 90. 2090. 4990. 2090. 5989. 5990. 0090. 2090. 020. 030. 040. 050. 060. 080. 090. 1 0. 0. 08 0. 07 0. 06 0. 04 03 0. 0. 1 90. 3990. 2990. 3990. 7890. 6990. 6990. 89. 8089. 7887. 7891. 1089. 90. 7891. 1890. 0090. 1088. 7390. 1090. 4990. 3990. 2990. 2990. 9890. 2089. 5191. 0889. 2090. 29 89. 4990. 4888. 7890. 4990. 5990. 6990. 2090. 2090. 2790. 61 90. 8890. 2090. 5991. 0890. 7190. 5991. 90. 7891. 0890. 3990. 8890. 4990. 3990. 7890. 00 90. 1089. 2290. 4990. 3189. 7190. 8090. 1090. 20 90. 5990. 3990. 2990. 1090. 1089. 6190. 00 depth on 0. 010. 030. 060. 070. 080. 090. 0. 07 0. 0. 03 02 0. 010. 1 90. 5989. 3990. 6990. 2990. 6990. 6990. 5990. 6990. 2990. 2990. 10 7190. 1089. 8090. 7890. 4989. 90 3790. 9090. 1089. 9089. 3190. 7190. 0090. 90. 2090. 2990. 2090. 2090. 5990. 39 89. 7189. 9090. 7890. 4989. 9090. 0089. 61 90. 4990. 5989. 1090. 59 90. 9090. 2990. 4990. 4989. 9089. 5190. 2989. 7190. 00 90. 8890. 7189. 8090. 7890. 4990. 49 90. 8089. 8090. 0090. 1090. 5990. 2990. 0 88. 5 89. 0 89. 5 90. 5 5.",
    "SeBot: Structural Entropy Guided Multi-View Contrastive Social Bot DetectionKDD 24, August 2529, 2024, Spain": "010 030. 040. 050. 060. 090. 1 0. 09 0. 08 0. 07 . 0 0.816.8186. 7386. 486. 566. 8185. 21 7386. 738. 398. 786. 8085. 886. 05 87. 1587. 6487. 0786. 0586. 2286. 0586. 8186. 9886. 6486. 6486. 0586. 8186. 7386. 7386. 7387. 0786. 9886. 86. 986. 6486. 8186. 908. 5686. 9086. 1486. 8186. 2286. 7386. 48 86. 3986. 786. 986. 7386. 56 3186. 1585. 9086. 5686. 4886. 4885. 886 2287. blue ideas sleep furiously 156. 4886. 73 Tree dpth TwiBot2 0 040. 060. 090. 1 . 09 0. 08 0. 05 0. 03 010. 1 6. 9. 18. 2485. 4686 5686.6486. 86. 7386. 5687 248. 4885. 386. 146 9086. 98 86. 4886. 48. 6486 4886. 906. 586. 3985. 63 87. 0786. 8187. 1586. 2486. 0786. 56 86. 9886. 486. 3986 6486. 31 85. 8087. 4087. 9886. 4886 7387. 9086. 7386. 6486. 14 86. 5687. 3286. 568. 4886. 485. 466 398. 97 86. 286. 8186 5685. 14 Tree depth k=4 on TwBot20 0. 020. 030.040. 050. 080. 09 . 0. 05 0. 04 02 0. 1 86. 7386. 6486. 7386. 7185. 9086. 56 8. 4986. 8186. 9886. 7386. 3185. 7185. 6385. 2487. 2487. 2486. 4886. 736. 8885. 5586. 0586. 39 4086. 8186 9786. 2185 88 8608. 0585. 3885.7. 4086.3185. 7184. 3886. 3186. 485. 715. 1285. 2986. 735. 978. 8186. 5685. 6385. 9785. 3186. 486. 646.148. singing mountains eat clouds 4886. 4885. 1286. 716. 3185. 8085. 86. 0",
    "ABSTRACT": "Recent advancements in bot detection have driven of Graph Neural Networks. The social graph, con-structed from social interactions, contains benign and botaccounts that influence each other. However, previous graph-baseddetection methods that follow the transductive message-passingparadigm may not fully hidden graph information and arevulnerable to behavior. messagepassing between nodes from different categories and communi-ties results in excessively homogeneous node representations, ul-timately reduced the effectiveness of social detectors. In thispaper, we propose SeBot, multi-view graph-basing social bot detector. In particular, we usestructural as uncertainty metric to optimize entiregraphs subgraph-level granularity, revealing the existed hierarchical community structure. And we encoder to enable message passing the homophily enhanced robustness to behaviors socialbots. Finally, we employ learned maxi-mize mutual information between different views and enhance performance through learning. Experimentalresults that significantly improves theperformance social bot detection compared with methods."
}