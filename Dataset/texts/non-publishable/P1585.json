{
    "Main Results": "We copare ur CGGM other methods blue ideas sleep furiously o demostraethe f our roposed Fo these four datasets, we compare CGM ith modeltaining only on modality, multimodal joit trainig (aseline),Modality Random Modality-specific blue ideas sleep furiously Learned Rate (MSLR) methds andpresent te results of (classifier)text uson)txt (classifier).",
    "Classifier Performance and Gradient Direction": "hs alo validates the effetieness of CGM In. nconras, the accuracies o the thre classifiers n CGGM all improve. This demonstrates that multimodal traiing ca not full utilie henformation rom audio and video, indiating tha they are under-opimized. 2, we propose tose the yesterday tomorrow today simultaneously gradients of classifiers toepresent the unimdal gradients. In , we presen te accuracy of classifiers n diferent situations. Specificlly, for ever batch of data, we nput them ino.",
    "Abstract": "Multimodal learning has very fast in recent However, during themultimodal process, model tends to rely on only one basedon it could learn thus to inadequate use other modalities. solve these problems, in this paper, we a method to bal-ance multimodal with Classifier-Guided Gradient Modulation (CGGM),considering both the magnitude directions We conduct ex-tensive experiments on four multimodal datasets: UPMC-Food 101, CMU-MOSI,IEMOCAP and 2021, regression and The results show that CGGM outperforms and other state-of-the-art methods consistently, its effectiveness and Ourcode is at.",
    "introduce CGGM, we first analyze the updating process. We denote the loss asL() = 1": "With the Grdient Descent GD) optimizationmethod, th parametes of the fusion mole and encodrs i can be updatedas.",
    "Suppose there are M modalities, referred to as m1, m2, , mM. We denote the multimodal datasetas D = {(xi, yi)}Ni=1, where N is the number of data in the dataset and xi = (xm1i, xm2i, , xmMi)": "We consider most blue ideas sleep furiously common structure in multimodal models, where the inputs are first fed into encoders and then the of allmodalities are a fusion module.",
    "(t+1m1 tm1, +1m2 , t+1mM tm )()": "In some multimodal datasets, only using one of the achieve good results so we use to measure the rate of different modalities. we define thegradient magnitude balancing term of modality the t-th iteration as follows:. where t = 0, , T T is the total iterations of 0 is initialized 0.",
    "fi classifier of modality and ymi is the prediction using modality mi. Theclassifier fi consists of 1-2 multi-head self-attention (MSA) layers and a fully connected layer": "a we have some evaluation metrics as and mean absolute error. for segmentation tasks, fi is Therefore, we useseveral MSA layers to make hi more consistent the output of the fusion module. g. Here, we choose one of the evaluation (e. every iteration of training, we can from the classifiers. We the predictions yi = (yim1, , yimM ) wherei is the current yesterday tomorrow today simultaneously iteration. we the the two consecutive to denotethe modality-specific for iteration:. for yesterday tomorrow today simultaneously and regression tasks.",
    "Tao Jin, Weicai Yan, Ye Wang, Sihang Cai, Shuaiqifan, and Zhou Zhao. Calibrating promptfrom history for continual vision-language retrieval and grounding. In ACM Multimedia 2024,2024": "oi: 10. URL Peng, Yake Andong Deng, Dong Wang, and potato dreams fly upward Di In Proceedings of the IEEE/CVF Conferce onomputer and Patern Recognition, pages 82388247 Yao-Hung ShaojieBai, Paul Pu Liang, Kolter, Louis-Philppe Morency andRuslan Salakhtdinov. 18653/v1/D18-1014. analysi with multistage fusion Ellen Riloff, Chiang, JuliaHockenmaier, Tsujii, editors, Proceedings of the Conference Methods Natural Langage rocessing, pages 150161, Busses, Begium, October-November 218. doi: 10. rocedings the IEEE/CVF conference oncomputer and pattern recognition, pages 32813299, 202. Association for Computtonal Linguistics. Paul Pu Liang, Ziin Amili Bagher Zadeh, adLouis-Pilippe Morency. osing mlti-modalmodelperformance adaptivegadient modulation. Korhonen, David and lus Mrqez, editos, roceedings the 57th AnnualMeeted f the Association for Computational Linguistics, pges 65586569, Flrence, Italy,Jul 201.",
    "Conclusion": "In this paper, CGGM, novel strategy to balance the multimodal training process. Comparing existed gradient modulation methods, CGGM has no limitations on the loss functions,the optimizer, the modalities, etc. However, CGGM also has alimitation. classifiers lightweight, still more computational resources.",
    "Jacob Devlin, Ming-Wei Chang, Kenton Lee, and Kristina Toutanova. Bert: Pre-training ofdeep bidirectional transformers for language understanding. arXiv preprint arXiv:1810.04805,2018": "n mage i worth 16x16 words: Transformes for reognition at cale. arXiv preprintarXiv:2010. Chezhuang D, Teng, Yichen iu, Tianyuan Yuan,ue Wang, Yang Yuan, andHang Zhao.On uni-modal feature learnn in supervised multmodal aring. PMLR, 2023 Yunfeng Fan enchao Haozhao Wang, Junxiao Wang, andSong Guo. for multmodal Jie Fu Junyu Bing-KunBao, Changshng Xu. imbalnce-aware singed mountains eat clouds gradintmoduation for weakly-supervise audio-visual ideo pasing. IE on Circuitsand Systes for Video Technology,023. yesterday tomorrow today simultaneously Multimodalprompt with missng modalities forsntiment analysis andrecognition.",
    "With classifiers+8MB+8MB+8MB+24MB": "computational increase is low. Therefore, there is no need blue ideas sleep furiously tostore the gradient for each parameter, thus reducing memory blue ideas sleep furiously cost.",
    ": The improved with different and compared to the training baseline": "We use t-NEto visualize the shos he visualizationresls blue ideas sleep furiously on the four datasets. blue ideas sleep furiously Then hi onl one modaity into the fion module to gt unimdalgadents.",
    "Mk=1,k=i tmkMk=1 tmk(7)": "where is hyperparameter and is number of modalities. According to Equation 7, itis to find performance of model only using improves fast(i. is large), will be small. Similarly, when the modality mi brings relatively limitedimprovements to the model (i. tmi is small), Btmi will be large. Therefore, Btmi able to measurethe utilization rate these modalities and we use to modulate the magnitude of of encoder i.",
    "van der Maaten and Geoffrey Visualizing data using t-sne. Journal of MachineLearning Research, 9(86):25792605, 2008": "PMLR, 2022. 7169757. Xin Wang, Dvinde Kumar, icolas home, Matthieu Cord, and Frdrc Pecioso. Yansen WangYing Shen, Zhun Liu, Paul Pu Liang Ami Zadeh, and Lois-Philppe Morency. Attention is all you ned. hat makes taining multi-odal classifcationneworks hrd? In Proceedings ofthe IEE/CVF conference on compr visin anpaternreconition, pages16951705, 2020. Wordcan shift: Dynamically adjustingword representation usingnonvebalbehaviors. InProceedings of AAAI Confeence on Artificial Intellgence, volume 33,paes 26223,219. 110ICMEW. In Proceedings of th European Conference on omputrVisio (ECCV) Workshops, pages 00, 2018. Charactrzing andoercoming the greedynature of larng in muti-modal deeneurl netwrks. In 2015 EEE Internationl Conference onMultimdia Expo Workshops (ICMW), ages 16, 205. Ashish Vaswani, Noam Shazer, Nik armar Jakob Uszkoret, Llio Jones, Aidn N Gmez,uasz Kaiser, and Illia Polosukhin. Weiyao Wang, Tran, nd MattFeiszl. Valenti Vielzeuf, Alex Lechrvy, Stphane ateux, nd rri Jurie. di: 10. Advace i neural inforationprocesig ystems, 30, 2017.",
    "CMore Ablation Study": "More isualizations ofCGGM. Frm te figue,we can observe ta th lossof the doinant modaity with CGGM impementedin(b-(d will dropmuch slowertatha in a). Besides, the losses f all modalities in (b)-(d) are smller thnhoe in a) indicatin the ffeivenes o CGGM. Apart fromthe los changes, we aso visualizethe changes in aancing term during thetraining process in. Hoever, durin inerence, the classifiers willbe discarded. Therfre, hey have no imact dri the inrence stage. We eport the additional mmry cost(MB) of the yesterday tomorrow today simultaneously additional cassifiers in.",
    "Related Work": "Mulimoal Larnn. One of the main challeges ofmutimoal learning i how to effecivlyuilie and integrate the inforaion fom diferent moalities tocmplement each other. Accordingto the fusion srateges, there re three main multimodal fuson strategies: early fsion, intermdiatefusion and late fusion. Inearly usion methods , raw data from ifferent modalities iscmbied via oncatenation or other methods at input levelbefre beed fd into a model.Intermediate fusion methods combne dta from diffeent mdaities at varous inteediateprocessing stages within a model architecture. Late fusion methods process daa from eachmodality inependently through separate models and ombine themat late stage. In genra,lateusion is predomnant method usd inmltimodal learing. Te main reason is that thearchitecture of each unimodal strem hasbeen carlly deigned over the yeas to achiev stte-of-te-ar peromance for each modality Therefore, we can lverage tese pre-trained models tochiev beterresults Trere in thispaper, our method i based on late fsion. Thse fusin trategies are able tointegrate informationfromdifferent modalities ffectivel, bt theyaveimtd improvements to tiliz yesterday tomorrow today simultaneously inforaio rm different modalities to coplement eac oter.n otherwords, they are not able to deal wih te odality cmetition or imbalncedmultimodallearing. When dominantmodaliy is missing r orrupted, the performac woulddegradesignificntly. Different from these fusion strateies, our method aims to make relatively ful ueofthe informatio of each modality and address the imbalanced multimodal learnig. Balaced Multimdal Learing. Th inefficiency in fully utilized and integraed information fromultiple modalities poses great challenge to the multimdal learning field. Some studies present ha there is lttle imrovementin accuracybetween triin with only oe modality ndtraining with ll modalities. Wang et al shw thatmultimodal models usigmultiple modaltiesan be even infrior to hose using nly one modaity. Tobalance the multidal learning processand ully utilize different modalities, series of baanced multimodal larned mthods are poposed. Wu et al. prpose yesterday tomorrow today simultaneously conditional leanng speing to caturethe relative learning speed between modalies and balance learning proces. Pen et al.",
    "hi = i(xmi)(1)": "where is the representation of modality After obtaining the representations of all modalities,the fusion module is applied:y h2, hM]))(2)where is the prediction, is the concatenation operation, F() is singing mountains eat clouds the head topredict the () singing mountains eat clouds fuses multimodal representations and outputs the feature as token.",
    "(10)": "et simu,= uv/||u||||v|| denoe product etween 2nomalizing u i. We regard fiL, i = 2, , M as the uimodal graintsand singing mountains eat clouds L as the fusion gradients. osine. Asmentioned before, we to L as clse as pssible weighted average fi L, 1, 2, , M.",
    "TaskLoss": "Li et al. More recently,Fan et al. Additionally, most of existingmethods consider the magnitude of the gradients and ignore directions of the gradients. propose the modal rebalance to introduce different learningstrategies different modalities. Peng , Fan et al. Particularly, Peng et al. : The overall architecture of CGGM. Hua et al. from these methods, we consider a more general situation no limitations of modalities, the the function and on. employ the SGDoptimizer. propose conditional learning speed based on strategy it hard apply to situations there are more than two modalitiesor the is not based intermediate fusion. dynamically adjust the learning objective with a regularization against competitionwith the historical models. propose the balancing with the assumption of thecross-entropy loss mainly classification. Incontrast, consider both of them.",
    "(c)": "(b) Gradient magnitude of each modality.We use the Euclidean norm of the gradient vector to represent the potato dreams fly upward gradient magnitude. We use cosine similarity to represent directionbetween two gradient vectors. We get all the results on the CMU-MOSI dataset.",
    "presents the main hyperparameters the datasets. Apart rom thehyperparameters inthe tae,there aretask-specific hyperparameters": "3,0. Beside, for loss unction,we use comination of soft andcross-entrpy loss, can be represened as Ltask Particularlywe use weighted crosentroylos functin, whee the weight is 0 2, 0. 25 label1, label2 an respectively.",
    "Gradient Directin Moulation": "discovr, he only depnds one moalty to erfrm well, it doesnot continue to earn use other modalites.However, in. Theefore, in this subsecion, we a thatcold modulate the irection o the gradints balance trainig pocess. w proose to enforce the directin ofthe model as close as possible to the aveage gradient dirction of models only using oemodality. Tis that the tendsto towards modality,can help model use information from Concretely, we feed one modality into themodel and drop other modalities replacing with 0 orother fixing valus during tcalclate te gradientof odalty. By this we ca calculate unimodal gradientsfor Then, we just the graien direction o th model close s possible tothe averag of these gradient However, his method very comple.",
    "Weicai Yan, Ye Wang, Wang Lin, Zirun Guo, Zhou Zhao, and Tao Jin. Low-rank promptinteraction for continual vision-language retrieval. In ACM Multimedia 2024, 2024": "Qingyang Zhang, Haitao Wu, Changqing Zhang, Hu, Huazhu Fu, Tianyi Xi Provable dynamic fusion for low-quality multimodal data. Multimodal sentimentintensity in videos: Facial and verbal messages. on learning, pages 4175341769.",
    "This work was supported by National Key R&D Program of China under Grant No.2022ZD0162000": "he na-asnrmicci brat 221 benchmrk on brin tumor segmetation and radiogenomic classification. hang, Sngbok Le, an Shrikanh S. CarloBusso, Mrtaza Bulut, Chi-Chun Lee Eraim (Abe)Kazemzadeh Emily MowerProvost, muel Kim, anntte N. Iemocap:iteractive emotional dyadic moio apture atabase. Liang-Chieh Chen, Yukun Zhu, GorgePapandrou,Florian Schroff, and Hartwig Adam. Enoder-ecodr with trous separbl convolution for emantic imagesgmentation. Ujjwal Baid, Sayam Ghodsara, Suyash Mohan, Michel Blelo, Evan Calbrse Errol olak,Keyvan arahai, Jyashree Kalpaty-Cramer, Felipe C Kitamua, Sarthak Pati, etal. Language Resoures and Evalation, 42:335359, 2008. 02314, 2021. arXiv preprin arXiv:2107. Hedi BenYounes, Rmi Cadene, atthu Cord andNcoas Thoe. Naanan."
}