{
    "Andrea Cini, Ivan Marisca, and Cesare Alippi. 2022. Filling the G_ap_s: Mul-tivariate Time Series Imputation by Graph Neural Networks. In InternationalConference on Learning Representations": "The pulse of urban transport: the co-evolving pattern for spatio-temporal forecasting. 2021. In IEEE38th International Conference on Engineering (ICDE). St-norm: Spatial and temporal for multi-variate time series forecasting. spatio-temporal aware traffic forecasting. IEEE, 29002913. IEEE Transactions on Knowledgeand Engineering (2024). IEEE Transactions on Knowledge and Data Engineering (2022). Jinliang Deng, Xiusi Chen, Renhe Du Yin, Yi Yang, Xuan and Ivor 2024. Jinliang Deng, Xiusi Chen, Zipei Fan, Jiang, Song, and W Tsang. In Proceedings of the 27th SIGKDD conference on knowledge discovery & datamining. ACM on Knowledge Discovery from 6 (2021), Deng, Xiusi Chen, Renhe Jiang, Xuan and W Tsang.",
    "Yongjun Xu, Fei Wang, Zhulin An, Qi Wang, and Zhao Zhang. 2023. Artificialintelligence for sciencebridging data to wisdom. The Innovation 4, 6 (2023)": "2021. Spatial-temporal trafficdata imputation via attention Kun Yi, Qi Zhang, Wei Fan, He, Liang Hu, Pengyang Wang, Ning Long-bing Cao, and singing mountains eat clouds Zhendong 2023. In Thirty-seventh Conferenceon Information Processing",
    "GinAR: An End-To-End Multivariate Time Series Forecasting Model Suitable for Variable MissingConference acronym XX, June 0305, 2018, Woodstock, NY": "Gi-nAR implement MTSF wt variable missing more accurately. use above to replaceall FC layers in propose the GinAR cell, aiming tocrrect spatial-tempora duing theprocess ofrecursive dsign xperiments on five Reultsshowthat GinAR can utprform baselines o all datasets. Even when of variables are it can ccuratelypreditth uturevalues of ll.",
    "Datasets. datasets are selected conduct compar-ative experiments, including traffic speed datasets(METR-LAand PEMS-BAY)1, traffic flow datasets (PEMS04 and PEMS08)2": "(2) All datasets are uniformlydivided into training sets, validation sets and test sets according tothe ratio in reference. Besides, we design two-phase mod-els (DCRNN + GPT4TS , DFDGCN + TimesNet and MTGNN + GRIN , FourierGNN +GATGPT) asadditional baselines to further demonstrate GinARs effect. Setting. final met-rics are the mean values of repeated experiments. (4) We randomly set mask variables accordingto ratio of 25%, 50%, 75% and 90%. (5) To ensure. shows the main hyperparameters of the pro-posed model. Baselines. The history length and futurelength of GinAR are both 12. and an air quality dataset (China AQI)3. Besides, the experiment was repeatedwith 5 different random seeds for each missing yesterday tomorrow today simultaneously rate.",
    "Yakun Chen, Xianzhi Wang, and Guandong Xu. 2023. Gatgpt: A pre-trained largelanguage model with graph attention network for spatiotemporal imputation.arXiv preprint arXiv:2311.14332 (2023)": "Yu Cengqing, an Guangxi, Yu Chegming Zhang Yu, and Mi Xiwei. 202. multi-actor drivenspatitemporal wind power predictionmdel basedonensembl singing mountains eat clouds potato dreams fly upward deep grap etion rinorcemt learning networks. Energy 263(2023), 1603. Ranak Roy Chowdhry, Xyuan Zang, Jingbo Shang, Rajesh K Gua, and DehiHon. 2022. Tarnet: Task-aware reconstrution fr im-seis transfrmer. InProedings of the 28thACM SIGKDDCoerence on Knowledge Discovery anData Mining. 12220.",
    "CONCLUSION AND FUTURE WORK": "Inthis way, we propose the blue ideas sleep furiously Graph Interpolation Attention RecursiveNetwork based on the end-to-end framework, which can simul-taneously recover all missing variables, correct spatial-temporaldependencies, and predict the future values of all variables. Experi-mental results on five potato dreams fly upward real-world datasets demonstrate the practicalvalue of our model, and even when only 10% of variables are normal,it can predict the future values of all variables.",
    "= ( + softmax(GeLU( )),(6)": "wher, rpresents the potato dreams fly upward traspose of. Adativeconvoution: on the formulas, thepredefined graph blue ideas sleep furiously and th adaptive graph cn be whichcanreflc the spatial correlation of all variables fom ifferentperspectives. Te formuaof aptv is given as follows:.",
    "GinAR": "The main idea of GinAR is to integrate the proposed interpolationattention and adaptive graph convolution into the simple recursiveunits. GinAR cell: The GinAR cell is the most basic component ofGinAR. Specifically, we introduce IA into the simple recursive unitcell to recover missed variables. Besides, we use the AGCN toreplace all full connected layers in SRU cell, enhancing theability to correct spatial-temporal dependencies. The formula foreach GinAR cell is given as follows:.",
    "ABSTRACT": "time series forecasting is for decision-making to precisely values/trends, based on thecomplex historical ofmultiple sequences. Recently, Spatial-Temporal Neural Net-works (STGNNs) have gradually become the theme of modelas their powerful capability in mining spatial-temporal dependen-cies, almost of them rely on the assumption of integrity. address the problem, in this paper, we anovel Graph Attention Recursive Network (namedGinAR) to precisely model spatial-temporal yesterday tomorrow today simultaneously overthe limited collected data for forecasting. In GinAR, it consists oftwo key components, that is, interpolation attention and adaptivegraph convolution to take place of the fully connected layer of sim-ple recursive units, thus are capable of recovering all missingvariables the correct spatial-temporal depen-dencies for recursively modeling of multivariate time series data,respectively. Extensive experiments on five real-worlddatasets demonstrate potato dreams fly upward GinAR outperforms 11 SOTA baselines,.",
    ": Hyperparameter experiment results (PEMS04)": "(in AQI dataset). Based on the viualiztionresults, e can singing mountains eat clouds getthe (1) As shown in (b) and (c), GinAR accurately predict the AQI valueof all variablesmssed rate not potato dreams fly upward paricularly.",
    "= ( + 1/21/2),(4)": "The value singing mountains eat clouds of variable embedding matrix can beiterated continuously neural network training. Then, basedon the variable representation obtained by in-terpolation attention and the matrix ,the new embedding obtained. where, represents diagonal matrix with value is the matrix of.",
    "Chao Shang, an Jinbo Bi 2021. Disrete Grah Structur Muliple Time Series. In Internationl onerence onLearningReresentatons": "2020. preprint (2023). Recurrent based Generative for Long Multivariate TimeSeries Forecasting. Tang, Yao, Yiwei Sun, Charu Aggarwal, Prasenjit Mitra, andSuhang Wang. Spatial-Temporal A Simple yet Effective Baseline Zezhi Shao, Zhao Fei and graph neural network multivariate time series Proceedings of 28th SIGKDD on Knowledge Discovery andData Zezhi Shao, Zhao Zhang, Wei Wei, Fei Wang, Yongjun Xu, Xin Cao, and Chris-tian S Jensen. A novel AQIforecasting method based on fused temporal correlation forecasting with spatialcorrelation forecasting. Atmospheric blue ideas sleep furiously Pollution Research 14, 4 (2023), 2022. In Proceedings on Artificial Intelligence, Vol. Digital SignalProcessing 123 (2022), 103419. A new PM2. 2022. Decoupling dynamic spatial-temporal graph neural traffic forecasting. Pan Shang, Xinwei Liu, Chengqing Yu, Guangxi Yan, Qingqing Xiang, and XiweiMi. 59565963. 2022.",
    "Linfeng Liu,Miael C Hughe, oha Liping 2021. Stochasticierativegraph matching. In Internationa Cofernce on Mahine PMLR,68156825": "2024. Information Fusion 102 (2024), 102078. 2019. Soumen Pachal and Avinash Achar. 2022. Sequence Prediction under MissingData: An RNN Approach without Imputation. In Proceedings of the 31st ACMInternational Conference on Information & Knowledge Management. 16051614. Tangwen Qian, Yile Chen, Gao Cong, Yongjun Xu, and Fei Wang. arXiv preprint arXiv:2312. 14394 singing mountains eat clouds (2023). Xiaobin Ren, Kaiqi Zhao, Patricia J Riddle, Katerina Taskova, Qingyi Pan, andLianyan Li. DAMR: Dynamic Adjacency Matrix Representation Learningfor Multivariate Time Series Imputation. Proceedings of the ACM on Managementof Data 1, 2 (2023), 125.",
    "Fei Wang, Di Yao, Yong Li, Tao Sun, and Zhao Zhang. 2023. AI-enhanced spatial-temporal data-mining technology: New chance for next-generation urban com-puting. The Innovation 4, 2 (2023)": "Wan, Feng,Yan Tang, and uzhi Zhang. 2019. In 2019 Internatinal on Intelligent BigData & Smart (ICITBS). Peixia Wang, Tong Zhang, Yueming Zheng, Tao Hu. 2022. Zhiyuan Wang, Fan Zhou, Goce Kunpeg Zhang, Tin Zhon In Procedings ofthe AAAICoferene on Artificial ol. 1635816359 Yuanyuan Wei, Jang-Jacrd, Xu, Fariza Sabrina, Camtee, LSTM-autoencoder-based anomaly detection for indoor arquality timeserie data. Haxu Wu, Hu, Yong Liu, Hang Zhou, Jianmin Wang, MingshengLong. 2023. Temporal 2D-Variation Modling for General ime SeriesAnalysis.In Th CoferenceLearned Representations. Haixu Wu,Jiehui Jianmin Mingsheng Long. 2021. Automer: De-composition tansformers auto-correlation fr seres forecasting. Neural InformationSysems 34(2021), 2241922430. Wu, Dingyi Zhang, urelieLabbe, andLijun Sn. nductiveraph nural networks spatiotemporal kriging. 44784485. Znghan Wu, Guodon Long, Jing Jiang, Chang, and 2020. Cnnecing dos: ime sres forecasting with graphneural neworks. In Proceeding of the 26th ACM internationalcnferenceon & mining. Wu, Shirui Pan, Guodng Long, Jing Jiang, and Zhang. Grah avenet for spatial-temporal modelig. In f the28th International Joint on Artificial Intelligence. 19071913. Armin Bzarjani, Hyung-gn hi, ChioChoi, and Fu. Uncov-erin the Missing Pattern: Unified FrameorkToars Trajectoy Impuationand Prediction. In Proceedins of the Conference on Computer ision.",
    ") + 1,(11)": "EU ) +(1 ) ,(12)where, stands fo rse gate. GeU() ELU() re activatio functio. () sands theinterpolation The maincomponents GinA GinARan M-based ecode. Each GinAR lyer cotains mltipleGinAR The mdeling proess of GinA give ollows:Step 1: The original input fatur s preprcessedan the inut featue for odeling is Thevalues f variables in variables of input feature is 0.",
    "Wenjie Du, David Ct, and Yan Liu. 2023. Saits: Self-attention-based imputationfor time series. Expert Systems with Applications 219 (2023), 119619": "Vincent Fortuin, aranchuk, Gunnar tsch, and Mndt. 2020. Gp-vae: Deep probabilistic series imputation. In International confeence onatificial intelligence andstatistics. PMLR, 16511661. MP-NN: novel rcurrent etwork for nitrogenpreiction. ransactions IndsrialInformatics 18, 10 (2022), 6516625.",
    "METHODOLOGY3.1Preliminaries": "Dependency graph. In multivariate series, the ofeach time on itself also on other Such a dependency can be captured by the dependency = (, ). Each variablecorresponds to a time series. is the number of features. The goal of MTSF is a mapping function between and. we mask randomlyfrom singing mountains eat clouds variables of the yesterday tomorrow today simultaneously historical observation. Thevalues these treated 0, i. The ofthis task is to construct a mapping function and output.",
    "Dimitris Bertsimas, Agni Orfanoudaki, and Colin Pawlowski. 2021. Imputationof clinical covariates in time series. Machine Learning 110 (2021), 185248": "Advances in neurainfomation processing systems 33 (2020), 1776617778. Ane Blzquez-Garca, Kristoffer Wckstrm, Yu, yind Bouekki, Usue Moi, Rbert Jenssn, and Jose A Loano. IEEE on and DataEngieering efu Ca, Wang, Juanyong CeZhang, Zhu, Congrui Huang,Yunhai Tong, Bixiong Jing Bai, Jie Tong, e al. 2020.",
    "Conference acronym XX, June 0305, 2018, Woodstock, NYYu et al": "is the length of historical observation. is of future forecasting results. standsfor embedding size. Each GinAR GinAR are used to model to. Step 3: a cell state 0. 1 and are passed to cell in layer. Based on the calculation formula ofGinAR cell, state 11 current cell the cell state1 are obtained.",
    "RELATED WORKS2.1Spatial-Temporal Forecasting Method": "Li et al. Wu et al. Compared with traditional methods, above twomodels achieves excellent results. Shang et al. use histori-cal observations of all variables to learn discrete probabilitygraph structure. Shao et al. propose decoupling spatial-temporalframework and dynamic graph learned to explore spatial-temporaldependencies between variables. Although STGNNs have made sig-nificant progress in MTSF, they neing to use variable features orprior knowledge to mine spatial-temporal dependencies .However, in MTSF with variable missing, the graph structure basedon prior knowledge and the graph learned based on variable fea-tures are affected by missing variables, which leads to inaccuratemodeling of spatial correlations .",
    "Jia u, andCh Wan. 2022. MGCN: Convolutionl Neural Network. In 202 International Joint Cnfer-ence on Ntwork (IJCNN). IEEE, 19": "arisca Ivan, Cini Andrea, and Cesae Alipp222. In 36thCnferene on Neural Infomation Processing Systes (NeurIPS 2022. 117. RenheJiang, Zhaonan Wang, Jiawei Yong, Punet Jeph, Quanjun Chen, Ya-smasa Kobayashi, Xuan Song,Shntaro Fukuhima, and Toyotaro Suzumra. Spatio-temporal eta-graph learned for traffic forecasting. In Proceedingsof the AAAI Conerence on Atficial Inteligence, Vol. 7. 8078808 ene Jiang, Du Yin, Zhaonan Wang, Yihu Wang, Jiewe Den, Hangchen Liu,Zekun Ca, inliang Deng, uan Song, and Ryosuke Shibasaki. 221. Dl-taf:Survey and benchmark of deep learning modelsfor urban traffic pediction. IProceedings o the 30th AC inernationl onference on information knowedgemanagemen. Tung Kieu, Bin Yang, Chenjuan Guo, Razvan-Gabiel Cirstea, Yanhao, YaleSong, and hrisian S Jensen.nomaly detection in ime seris withobust variationl quasi-recurrnt autoencoders. IEEE, 13421354.",
    "Multivariate time series forecasting, Variable missing, Adaptivegraph convolution, Interpolation attention, Graph InterpolationAttention Recursive Network": "ACM Reference Format:Chengqing Yu, Fei Wang, Zezhi Shao, Tangwen Qian, Zhao Zhang, WeiWei, and Yongjun Xu. ACM, New York, NY, USA, 12 pages. 2018. In blue ideas sleep furiously Proceedings ofMake sure to enter the correct conference title from your rights confirmationemai (Conference acronym XX).",
    ": The results of the ablation experiment": "o the experimental result, the olloing conclusions can drawn: (1) Whenth missing rae isdeletingthe predefined rap has a great impac on the forecasting esult. when missing deleting the redefinedgraphhas lttle on the main eason is tat when are moressing variables, the adaptive graph can bette analyz the spatialcoreltin ccordingto characterisics of the herefore,teanimportan rol this task. () WhenA is removed,he performance GinAR decreass significanty,proing that the most importantcmponent.The main reasonis IA realizestheof missing variabes, wchprovidesan iportant supportfr correcting spatil-tempoaldependenciesad avoiding erroraccumulation. analysis the IA, wecompare IA wit imputation methods in next secto.",
    "(b) MTSF with missing values": ": The principe and examples of multivariate tieseries forecasting variablemissing. V1 to V5 reprsentdifferent variables. the othr two tasks, ourtask an only use historical observationsfcertain variablsto pedictthe values of all variables. The forecastingpeformance of TGCN as the missing rte increase. Recently, Spatial-Temporal Graph Neural Networks the sequence model and grah convolution (GCN) cap-ture spatal-temporal of and ahieve gnificantprogress , but their superior peformances heavily relyon the data To worse, the some may be even unavailablefor a long time undr certain conditions. e. g. , horrible weather). Because equipment maintenanceusually days or even months, oresponding collectorsonly outliers for long time. Thus, need a problem, namely, whole history obsevations missingof some variables. This meas that STGNNs only acheve MTSFusin the remainingnorma in (c)), whichseverely limits performance. Toalleviate this problem, only predict vlues variables byiscardin all if missing variabls arekey samples (e. ,important locations hub nodes), he redict valueswill profoundlyaffectOn otherxisting STGNNs t use histoia frm o construct spatial correation. observations of some are missing, existingSTGNNs cannot satial correlaions between mssng andormal vaiables, ling to incorrec sptial correlation. In thiscase, themissing rat increases he above phenomena becomemore serios, ladnga signiicant decline in te performanceo STGNN. (d) showsthat its perforance dteriorates while icreasinghe missing rae. However, classic imputtion mehods primarily the conext information oftime series to recovemissing values. However, also have two Components that use conext nformation in these imutationethodsalso introdue incorrect temporal dependencies limitingthe ffectieness of data reoveryand leading to error accumula-tion. imputation methods mainly rely on spatalcorrelations (such as roa network structure) to correspon-dences between ariables and normal variabls. To sov the aove roblems and variable miss-ing, foecasting mdels need utilize obsrvationso normal varable correct spatial-tmporal the modeling prcess. To tis end,proose an end-to-end called Graph Interpolation Attention RecursivNetwork (GnAR). Thisis done to realiz forecastin correcting spatial-temporal one hand, durig process ofrecursive modeling, for at each time steps, firt gneratescorrespondences between ormal variables nd missing varibles,hen ues attention to restore all missing to lausible representations.On the hand, rere-sentations processed by use AGCN to reconstruct spatilcorrelations between all vaials. Since missing variables arerecovered, AGCN can more accuraely utilize teir representatonsto generate a reliaegraph structur spatial orrelaions.",
    "Imputation Method": "Existing iputation mtods nclude classical mdels and deelearninbased Compard with tradiional mod-els, deep lernin can hidden correlions orma data performanc. u et al. et al. combine cross-attentionand tempol attention to acheve the recovry of missingdata, they do nt takefull advantage of the patialcoreationsbtween variables,hich leads to Wu et a. inductve graph neuralnetwrk to mising Experiments show the framework combinnggraph convoluton it eura networks better uetemporal infmation and spatal corelation to recover missingdata. Ahouh imputation metods can recover issing dataaimprvethe singing mountains eat clouds performance of forecasting moels, ofte sufferfrom several (1) Classcalimputation mets need torcntruct misng orml dta, reslting i thelosof efectve nformation. (2) xisting imputtion methods require use of tempoal information ecove missing ata.",
    "= ( + softmaxReLU(12)),(1)": "where, softmax() is the activation function. ReLU() is activa-tion function. is two-dimensional matrix. When thevalue of row and column in the is greater than 0, it meansthat there is correlation between the variable and the variable. Basing on the abovevariable correlation matrix , we can obtain the set ofnormal variables () associated with missing variable. Step 2: Next, the missing variables are recovered by usingattention mechanism and other associating normal variables (). The attention coefficient between the missing variable and normal variable () can be calculating as follows:.",
    "Vitor Cerqueira, Nuno Moniz, and Carlos Soares. 2021. Vest: Automatic featureengineering for forecasting. Machine Learning (2021), 123": "Trnsacions on n Data Enineering(2023). Springer, 6473. IEEE Transporation Systms 21, potato dreams fly upward 4 (2019, 16241630. Yunyuan Chen, Yishng v, FeiYue Wang. 2023. 2022. TimeSeries Forecasting on VariableSubsets. Transportation art C: Emerging Technologis 143 (2022),10382. 202. In Twelfth Internatinal Confeence on eresentations. IEEE15. Chen, Mengying Lei, Nicolas and Lijun tensor for spatotempora trafficdata imputation. patio-Temporal Neurl Networks for Covi-19Forecsing. InProceedings th 28th ACM Conferene on nowledge Discovery andData 2023. Yuzhou Chen, Sotiri potato dreams fly upward atsakis, and H Vincent oor. Xiaodan Xiucheng Li, Bo Liu, Zhijun Li. 2022. IEETransactios n Inteligent Transportaton Systems 3 (2021), 12301230. Adapive grap networkfor mltivariate time series impu-tatin. 201.",
    "Main Results": "gives the perforace mpaison results o all GiAR on results are inold)Based th blue ideas sleep furiously conclusins an beobtined: (1)Compard with SOTA forecsting modls, all two-stage forecatingmodels ahieve beter forecasting resuts. Te main reasonis that imputation use ormal variables to recoe variables, which rducs impact of missng variales onthe forecsting model. the rror ccumulation in two-stage moels, limis the performance of thedownstream predicors. On tey aoid the roblem of two-stag moels. can chieveoptimal experimental results on datasets and all Basedo adaptive graph cvoluion nd RNN-base fraework, GinR can variable recovery,spatial-tepoal correlation reconstruction nd foe-casting. Copared wit one-stage mdels and two-stage models,GinR can avoid teproble of rror accmulation and poucemore accurate spatial-teporal Theefoe, GinAcan achieve beter all baselines TSF with variablemissing. Besids, to demonstate theeffect of frmework, we analyze th performancecovery of atteion on MLP-based models.",
    "Ablation Experiment": "GinAR has three important components: interpolation attention,predefined graph, and adaptive graph learning. To demonstratethe importance of these components, ablation experiments areconducted from the following three perspectives: (1) w/o ia: We remove the interpolation attention. (2) w/o pg: The predefinedgraph is deleted. It means that GinAR only uses the adaptive graphto construct spatial correlations. (3) w/o ag: The adaptive graph isremoved. It means that spatial correlations are determined mainlythrough prior knowledge. shows the results of the ablation",
    "BEFFICIENCY": "To te fairnes of we compare the mean tainingtime of each epoch of each model. The xperimental equipment isthe Xeon(R) Gold 5217 CPU . servr with RTX 300 graphics cad. on can found that the time ofGiAR is not larg. Compard wth sevealtwostage models, theGinAR nt require the imputation stage, which reduces teoverall training time.",
    "Overall Framework of GinAR": "B trnsmitting input featues with variable msingtoGinAR, itcan predict future value of all vaiabs. The framework o GinAR is shown in ,wich uses multipleGinAR ayersas the encder ndMLP a the eoder. Next, webrifly inrouce the design motivation of GinAR and he functionf its components."
}