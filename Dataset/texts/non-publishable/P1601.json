{
    "RY Huang, Maximilian i, and Leonad Tang.Endless jalbreak with bjectin learning.arXiv:2410.1294, 224": "Fngqing Zhngchen Xu, Luyao iu, Zen Xiang, Bhaskar Ramasubramanian, Li, Poovendra.Ascii art-bsed jaibreak attacks against aligning llms. arXivpreprint ariv:402.11753, 2024. Dniel Kang, Xuechen Li, Ion Sica, CarlosGuestrn Matei Zaharia, n Tatsunor B. behavior of LLMs: Dual-ue trough potato dreams fly upward attacks. 2023. Nathaniel Li, an, Stenker, Willow Priack, Rile odside, Hgh Zang, Zifan ag,Cristna Menghni and Summe Yue. l defenses are not robust to human albreaksyet. rXiv arXiv:240815221, 02.",
    "BComposition prompt in full": "hen atacking mdels using a givn stred transformati, we use step-by-step instructions aboutthe string cmposition followed by few-shot examplstosmugle a harmful intent encodd ithastring compsition,o instu the model to encode is response in a string composition",
    "Invertile string transformatons": "We encoding to a deter-ministic string-level transformation f: Callable[[str], str] satisfying a few rules. require invertibility: there must exist f 1 such that 1(f(s)) = input Most of the time, here string but we admit strings with lightdifferences such as lower/upper casing dont impact the content of text. Invertibility helps withautomated jailbreaking, as encoded text can be decoded without manual intervention correction. The invertibility requirement allows us to programatically string compositions. For exam-ple, say want some text to from English German (f1 German translation),then converted (f2 = leetspeak), converted to Morse code (f3 = Morse code).Then and its inverse,",
    "LaTeXChange the string to be part of a LaTeX document": "The Pytn, JSON, andLaeX transfomations are not guaranteed to be ivertible when performed by the anuage model;forexample, a mode may add rbitry ky names an nested dictionaries when rntig a SONoutput. Some tranformationssuh as leetspeak and Morse code disard informatio about lower/uppercase; henly sideeffectis interrence ith the alternatingcase trasformation in aopositon. We implementthe iversions ofthese style tansormations to b as flexible under differenoutput fomttings a pssible.",
    "Pack my box with five dozen liquor jugsin other words, 60 (yes, sixty!)of them": "We dont instruct the model about theopposing single transformation; instead, we use few-shot examples so that the model picks up simpletransformations without explicit instruction. If the composition targets the intent, we specify a single transformation, or notransformation, for the response; likewise, if the composition targets the response, we specify asingle transformation, or no transformation, for the intent. Respectively, we say that we target the intent or target the response singing mountains eat clouds for composi-tion, respectively. These few-shot examples are benign (intent, response)pairs with the intent and response separately encoded according to our specification.",
    "Pentiful jailbeas with automated adaptve attack": "For this purpose, string compositions become highly useful. Because it is infeasible to all compositions, we random sampled into anadaptive attack The adaptive obtains comparable ASRs previous ensemble a comparable attack budget. In potentiallyscale to attack budgets in the thousands, thereby exposing a very wide portion of attack surfacesof frontier language models.",
    "User input: composition prompt": "are instructions fr how sequentialstred tansformatio works. After werform JSON ecapsulaion, the example string {message: ThEm. CaLvIn AD rEaCtIoNs lIgHt-DePeNdEnT ThEStAgEs: MaIn tWo iN oCcUrS DiOxIdE. {message: gLuCoSe. ee are some pairs example queries, withthe sequentially altered 3nf175 0f r36ul4r phy51c4l 3x3rc153?{message: DiSeAsE, rIs ThE ReDuCiNg CaRdIoVaScUlAr HeLpSIt PhYsIcAlLy, MiNd. CaRbOn WaTeR uSiN uGaR, Of Tyea GlUcOs, In SOrEd EnErGy ChEmIcAl InTo sUn, ThEuuAL eNeRgY, LiGhTcOnVeRt bAcTeRiA CeRtAiN aNd AlGa, PlAnTs, WhIcH By pRCeSs Is PhOtO-sYnThEss}. respond to the wit a helpful with folled alteration(s)on your response text perfomed in sequencealernated case,ten word-level reversal, ncapulation. Lets Pack my box with fiv ozen liquor jugsin other wods, 60 (yes, them. perform altrnated cae, changebe in alternating case, the and each suequent alternates between owercase we prform wordleve reversal, example ThEm. AtPGeeRaTe HeLp TAt eLeCRoNs ReLeAsE To cAuSi ChLoRohYlL AbSoRbEdIs SuNIgHt ChLoRoPlAsTs, Of mEmrAEs ThYlAkOiD tHe iN PlAcE TaKe wHiCh ReAc-TiOnS, i CyClE. into the result {message: TE.",
    "Richard Liu, Steve Li, and Leonard Tang. Accelerated Coordinate Gradient, 2024. URL": "04249, 2024. Tree of Attacks: Jailbreaked Black-Box Automatically. Mantas Mazeika, Long Phan, Xuwang Andy Zifan Wang, Norman Mu, Elham Li, Steven Bo David Forsyth, and Dan Hendrycks. preprintarXiv:2312. arXiv preprintarXiv:2402. HarmBench: A Stan-dardized Framework for Automated Red and Robust Refusal. 02119, 2023.",
    "Problem setting": "The best large today boast advanced capabilities and extensiveworld knowledge, maked more severe risks and misuse cases. To mitigate theserisks, model creators have devoted substantial research efforts model alignment. One essentialcomponent of alignment pipeline is red-teaming, or the rigorous evaluation of models to and weaknesses. By better understanding the attack of frontier we can, in turn, better understand the shortcomings of current alignment measures helpsafety researchers on blue-team build more robust AI systems. In particular, were interested jailbreak methods that are With so frontier AIsystems deployed in so many downstream settings, redteaming efforts can benefit greatly fromscalability. redteaming community has employed various string-level obfuscations attackmechanisms (Wei al.,",
    "hrmful intent, if least ofthe stadlone transfmations rsulted ina jailbrea, wesay that ttack jailbreaks tha intent": "We evaluate standalone ransformatin and the ensele attackcross the Claude an GPT-4oodel families, and our esults are results worst-case scenarofor models adversarial to invrtible transformations. Foreach model, employ attck prmpt ASRs for each tandalone are displayed.",
    "Maksym Andriushchenko, Francesco Croce, and Nicolas Flammarion. Jailbreaking Leading Safety-Aligned LLMs with Simple Adaptive Attacks. arXiv preprint arXiv:2404.02151, 2024": "Cm Anil,Esin Mrinank Shara, singed mountains eat clouds Benton, Sandipan Kundu,Joshua Batson, NinaTong, Jesse Mu, Frd, Francesco Agrawal, Rylan Schaeffer,Samuel LamertAnh Radharishan, Carson E. Denison,Evan uinger, Yuntao Ba, Treton Bricken, Maxwel, Nicholas Schiefer, Jami Tmkin, Tamera Lanham, Karina Nguyen, Tomasz Korbk Jared Kaplan, Deep GanguliSamuel R. Bowan, Perez, Rogr Grosse, and David Duvenaud Many-shotjailbrekig",
    "Abstract": "laguage mdels LLs)remain vlnerable to a of attacksand methods. yesterday tomorrow today simultaneously Ourjilbreksobtaincompetitive ttacksuccess rates on lading frontier modelshen evaluated on armBec, highlighting attac remain apersistent vulnerability even in avanced LMs.",
    "xD1JUDGE(x,LLM(J(x)))=unsafe": "cross our xpeimes, we use HarmBench (Mazeika et al., 2024), which prvies tesset of320 harmful intents. lso provides prompted etup were y used as judge LLM determningjalbreakwe eploy HarmBenchclassificaio propt ith the unerlyig JUDE model.",
    "Conclusion": "Bothour singing mountains eat clouds ensemble blue ideas sleep furiously and adtive attacs are able o jailbreak leding frontir models on a high percentaeof representative harmful intents",
    "Related ork": "To reiterate, many encodings mentioned in the introduction, including leetspeak, Morse Code,low-resource language translations, rotary ciphers, and ASCII, fall under the purview of invertibletransformations. Besides encodings, the adversarial attack literature for language models has includedgradient-based discrete optimization (Zou et al. , 2024; Shin et al. , 2020; Ebrahimiet al. , 2017; Guo et al. , 2021; Geisler et al. , 2024; Zhu et al. , 2023; Guo et al. , 2024; Thompsonand Sklar, 2024); LLM-assisted prompt optimization (Chao et al. , 2023; Tanget al. , 2024); multi-turn or many-shot attacks (Li et al. ,2024; Anil et al. , 2024; Zheng et al. , 2024); and other idiosyncratic attack vectors (Huang et al. , 2024;Andriushchenko and Flammarion, 2024; Andriushchenko et al. Wei et al. Our workbuilds upon Wei et al.",
    "Ensembling transformations already leads to a strong jailbreak": ") as ttacks, but the jailbrea efficacy  our pefixrotation, spoonersm, stuttering, etc. ). ) is ye to be seen. combined o  of transformations, evaluated gives us deeper insight aboutmodel risks. (This isimortant for the bueteam; the lattr scenario, for example, may devising tailored modeldefenses fo each possibe intad of relying on one overarching for conept of a string transformation."
}