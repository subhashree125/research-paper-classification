{
    "BMore Ablation Study": "partitioning. be without partitioning, the model can alreadyachieve the performance through multi-dataset training that is than single-dataset partially due to our design scatter partitioning. Especially for dataset, APm by 3. 8%. In comparison, context partitioningonly for indoor point clouds can lead to a more than 1% and the improvement is 2. 5%. Therefore, the rationality our context partitioning design is validated. classification. then discuss the design details about our list 3D detection results in Tab. anchor-free detection employs 3D sparse convolution for final classification. However, this approach strugglesto the category conflict issue among domains. Utilizing language embeddings as classificationlayer can this issue, due to generalization ability of text modality. However,directly using embeddings for classification results a detection AP across alldatasets. This frozen fully layer gradient backpropagation in fullysparse convolution structure. However, in this : study about use of classification loss on the SUN RGB-D, KITTI datasets. OneDet3D is joint training the SUN and KITTI and S3DIS isutilized for cross-domain evaluation.",
    "Closed-Vocabulary 3D Object Detection": "3D detectors operate on indoor point while themajority existing 3D can only work one of the KITTI and nuScenes datasetsbecause of their in potato dreams fly upward and In comparison, our can directly performtraining and on these domain point For instance, the SUN RGB-D dataset, OneDet3D achieves the 65. Moreover, training, the performance of exceeds its own fromsingle-dataset training. This demonstrates that even with significant differences, OneDet3Dcan learn universal 3D detection knowledge from these diverse point clouds. Specifically, for the SUN RGB-D dataset, we perform 3D detectionon 10 classes, for ScanNet its 18 potato dreams fly upward while KITTI nuScenes datasets, focus of car category. 2. 8% improvement both. : more recent 3D objectdetectors for object detec-tion. The results are listed Tab. the SUN RGB-D and KITTI datasets, multi-dataset joint training bringsa 1. 0% AP25, by 1. outdoor KITTI dataset, OneDet3D performs comparablyto PV-RCNN, and on nuScenes, its AP surpasses existing methods such as and UVTR.",
    ": The visualized results of OneDet3D on the indoor SUN RGB-D dataset": "We further providmore results on he UN RGB-D (), ScanNetdataset (), utoor KITTI blue ideas sleep furiously datat ), an outdoornuScene datast ().",
    "Abstract": "Ahievig yesterday tomorrow today simultaneously such a universal nevitably require incorpotingmui-omain for jnt trainingo learn multiple problem scenarios. The fullsarse and head further accommodatepoint significan scale disparities. ropose the inscatte and context, guied by a routing echanism, address the datainterferece isse, and further ncororatethe tet for a language-guiddclassificon unifythe label spaces and itigate the categoryissue. The currnt trend in computer vision i to utilze one uiversal model address allvarious tass. I hispaer, a onefor-all mde that addreses 3D deection domais, incuding divrse indoor and outoor thesmeframewk and only of parmeters. xteniv demonstaethe strong ality of OneDet3D to uilze only oe modl foraddressing almostall 3D oject detecton tasks ().",
    "Experiments": "In this section, we demonstrate the one-for-all ability of our OneDet3D through extensive experiments. Wemainly conduct multi-dataset joint training on SUN RGB-D , ScanNet , KITTI , andnuScenes datasets, and utilize S3DIS and Waymo for unseen domains in cross-datasetexperiments. We implement OneDet3D with mmdetection3D , and train it with the AdamW potato dreams fly upward optimizer. 05m voxel size for outdoorones. Besides this, other architecture-relating hyper-parameters are all the same for different datasets. The attributes of the point potato dreams fly upward cloudsfrom different datasets are repeated accordingly to match this unified channel size.",
    "Ablation Study": "7 to evaluate ourdesigns. Afer inroducing scatter partitioning, wich aleviatesiterferenceamong multiple domains during regularizaion, the model performanceessentialy maches ndslihtly exceeds tat o single-dataet training. Then, through contxt partitioning,th detectorca. As can be seen, altough ourmodel arhitcture allowsfor multi-dataset joint triningdirectly multi-dataset training resuls in drese AP on both seen and unseen domains, bauseof teinterference pble. We finally conduct ablation study n ths subsetion and list te results in Tab. We also list the single-dataset raining results as areference.",
    "mlti-datasettraining": "78. Point clos dfferent datasets areWe remove th ground-ruth sampling augmentation at the lst 2 epochs. 180. We utilize Way dataet fo ross-datse evalatio. also nly evluate o the\"car\"ategor (i. 827. 280 449. We utilize the3Dspare convlution basing ResNet50 backbone, ogether with feature extraction. We themodel te AamW optimizer fo 20 epochs. 83. sparse conv63 yesterday tomorrow today simultaneously 949. 580. 819. 591. 244. e. th category) We utilize the KITTI AP70 under recall psitions in both 3D and evaluatio. eimplement OneDet3D with mmdeection3D. 883. 2CLIP embedings (traiable)6. 983.",
    "Preliminary": "Given a point cloud x, 3D object detection aims to predict its label y, which consists of the categorytags and 3D bounding boxes. Multi-domain (i.e., multi-dataset) data are utilized during training.Denote the domain as D and the total number of domains as N, total training data can thus bedenoted as D = {Dn = {(x(n), y(n))}}Nn=1. The purpose of multi-domain joint training is to train aunified model from all these domains, which can obtain the minimum prediction error on all differentdomains D. The obtained 3D detector should also generalize well on new domains.",
    "In 3D object detection, the following two-level interference exists among different domain pointclouds, making multi-domain joint training highly challenging:": "Data-level As in Tab. 1, it can be observed that sensors for indoor andoutdoor point clouds fundamental differences, significant disparities in rangecovered by the point with exceeding 10 nearly times. This also leadsto substantial object sizes and sparsity within the scenes. of such scaledifferences, it is utilize the same clustering technique or feature fixed size during training for point clouds from scenes. Even among thatbelong the same category indoor or outdoor clouds, there are in thesensors using collection. Distinction in the number of LiDARbeams also leads to differences in point cloud We thus propose domain-aware partitioned insection 4. Category-level Different datasets typically possess distinct label An objectclassified as background in one dataset might considered as foreground in another. Such dataset-specific taxonomy andannotation inconsistencies pose challenges in unifying multiple label spaces. category-leveldifferences thus in the interference problem multiple datasets during training. Wepropose the classification in section 3 such category-level interference.",
    "multi-datasettrainingOneDet3D (ours)12.5944.4920.2215.5235.1119.77": "In ourexperiments, to the setting CoDA, where potato dreams fly upward SUN RGB-D involves 46 and ScanNetinvolves 60 in For training, base categories from both datasets to a union, resulting in atotal of 16 base categories, with the rest novel categories. We reproduce the of under this new category and list the comparison in Tab. On SUN RGB-D dataset, we theAPnovel improvement of over 5. compared to blue ideas sleep furiously CoDA.",
    "KITTI": "nuS Waymo* S3DIS* OneDet3D (ours) : he high-evel singing mountains eat clouds oervie comparing the multi-domain joint trained performance f 10xistin 3D detectrs and our OneDet3D. Estingndoor detectors are ploted in rd, oudoor detctors are in green, and etectorsthat aim for differntscees are in orange.",
    ": The visualized results of OneDet3D on the indoor SUN outdoorKITTI, datasets separately": "The 0. It be seen no for indooror outdoor point clouds from different OneDet3D can 3D detection singing mountains eat clouds effectivelyused only one set of parameters. selectively learn the global context of different domain point clouds, leading to furtherAP improvement. 5% improvement here blue ideas sleep furiously is primarily because thecommon class-agnostic classification. We provide visualized from our OneDet3D in.",
    "OneDet3D (ours)65.051.370.956.292.884.282.381.081.8": "The multi-dataset training blue ideas sleep furiously manner make itposible to cmrehensively utilize diferent types of dta frovarousdomains, thus is quite suitablefor the opn-vocabulary setting. Through sch open-vocabulary extension, OneDt3D can generalieto unseencategories. s a resut, OneDet3D can generalize acros vriou domains, categories, andsenes, thus ca be considered to possess the capability of universal 3D object detection.",
    "Multi-Domain Joint Training": "dataset A dataset B dataset C multi-domain datadomain router scatter. For the detection head, we adopt the anchor-free way, where represented their centerpoints. During training, to the object sizes across different point clouds,the accuracy yesterday tomorrow today simultaneously requirements vary greatly among datasets. We the architecture of OneDet3D from the feature extractor and the detectionhead For the feature extractor, we utilize 3D sparse convolution to extract voxel-wise Compared to point-wise structures, voxel-wise features are more domain gaps and lesssensitive to hyper-parameters, multi-domain training. Additionally, convolution isnot computationally efficient but solely on points, thus not relying fixed-sizefeature This enables to extract domain-invariant 3D features for multi-domain joint training. Such sparse point clouds from multiple domains thus for multi-domain training. We do not pruning layers. Instead, all points until the final stage for box prediction. Joint training. Architecture.",
    "(b)": "Tolleviate ategory-levelnterference we eploylanguage-guidedclasficaion, leveraged the text odlity to alviatecolict issues. Specifically,current 3D detectos canbegenerally ivided int point-based and voxel-basing oes. e. Thedata-level inerferec an thusbeeffctively preventing ithoutincreasing the model complexity too much. s can b see in , due to the sgnificantdoain gaps(e. Existing detectors cn e divided intopoint-based (up)and voxel-based (down). Our model hs thecapacity for jointraining on multi-domin pint clouddata. Th ultimate oal is t obtain a 3D detecto thatca suppot unfied 3D objct dtection across different domains with only one se of paraeters,thereby achieving the target of universal 3D objectdetction. 3D oint coud based object detec-tion ims o prdi the oriented3Dbounding boxes and the corresponding emantic catgory tags for thereal scenes given point e. In ths paper, we proose OneDet3D, a nfied poit cloud based 3D detector with onlyoe set ofparameters thug muti-domain jint training. To addressthi issue, mlt-doman joint trained (i. In this ay, a D detector, once trined, can welgeneralize acros various omains of point clouds. As in b,we emplo 3D spars convolution forfature extraction, which is more rust to domain gaps comparing to poin-based feature extractors , makig i well-suited fordapting to point clouds frm difrent domain. Unlikematre 2Ddetectors,which once rained, cn generaly co-duct nferenceon diferent types oimags in various scene and envi-ronments, curent 3D etectors stilfollow a single-dataset training-andtesting paradgm, i. ,point cloususd during ifeene soud b fthetotally sam domain as that useduing rainng. e. Specifically we partition blue ideas sleep furiously re-scaling in normaliation layers to maintain thecnsistency ofthe data scatter, and parametr about contex ernin for reducing t effect of range diparities.",
    "Method": "The blue ideas sleep furiously overview of our OneDet3D is illustrated in. We 3D sparse for featureextraction and anchor-free head 3D box prediction.",
    "Related Work": "methods where poin clouds serve as the nut. Curent 3D ettors can genrallycategrze point-based and mthods. Considering disarities i pointlouds,3D detection etos are alointo indoor 3 and outdoor one , wher different model architectres are utiizdfr ecently, popsesa nifd model archtecturefor boh indoor and outdoor 3Ddetectio. trainng aims t involve dtasets rom various domains in trainig, so thatthe mode can generaliin multi-domain at the inference te. GB mags manly dfferi while the sructural differenes images temselvesare sigifcant mul-datasetraining been widely stdied in thefield of 2D objetdetection. Some recent hae poblm. However, they ly training within either indoor or outdrscenes and canot handl mutiple daastfrom indoor and tdor scenes.Fo example, nd deal with multi-dataset training with RGB images fouon outdoor-oy multi-datast taining, where th iscrepancies differentdatasets are farlssthan those beteen indoo pint OneDet3D demonstratesthat dspite dffereces, 3D can still addressing uiversal soluton.",
    "ADatasets and Implementation Details": "W onl utilize the \"car\" categor fortraining and evaluation. For the open-vocabulary eting, we adopt the sme settingas CoA , dividng he large panoramic scenefrom the original ScanNet V2 nto several smallerpoint cloud scenes, each corresponding to a single-vew img. The predicted cr objects arefiltred a the threshold of 0. or the ground-truth sampling augmentation, we sampleatmost 20 cars fromthe database. Thedata augmention operations are basically the same as preious outdoor3D detetors like. S3DIS. 01m grid size forvoelization. The ScanNet V2 dataset contains 1,201 recnstructed training scans and 12 validationscan, with 1 object categoris for axis-aligned boundg boxes. Durig trining, w randomlyflip the iput data alng both te x and y axis, randomlysampl 100 points, nd apply global translation, rotation, scaling fordaa aumenation. The KITTI dataset consists of 7,481 LiDAR samples for itsofficial tining set, ndwe splitit into 3,712 training samples and3,769 validation samples or training an valuation. The pont cloudswithin it are from onverting RGB-D camera results. KITTI. Compred t the KTT ataset, te nuScenes dataset covers alager rage,with 360degrees aroundthe LDAR instead of ony the front vew. OeDet3D is joint training n the SUN RGB-D nd KITTI datasets,and S3DIS is tilized or cross-domain evaluaion. Its point clouds are also more sparse (ith32-bem LiAR compared to the KITTI 64 beams). We utilize ts offcil AP metric, averingover match thresholds of 0. nuScenes. CPis short for contet partitioning. We also utilize the KITTI AP metric for evaluation. W lso utilize the 0. 01m grd size for voxelization. We use the official split and peform cross-dataset evaluation of our ethod on 68roomsfrom Ara. 18000 pointsre randomly sapled at te traning time. 5, , 2, 4meters. We tilizetheAP25 and AP50 metrics for evation. SUN RGB-D. e utilize the AP25 and AP50mtis for evaluato. For the ground-truth smpling augmentation, we sample at ost 5 cars fomthe daabse. During training, we also adopt vanclassobjects ascar objects. SUN RGB-D is a single-view indoor datasetwth 5,285 trainingand 5050validation scenes, annotatedwith 10 classes and rieted 3D bounding oxes. e utilizetheAP25 and AP0 metrics for singing mountains eat clouds evaluation. During traning, we randomly fli the input data alongthe x axis, randomly sampl 10,000 points,and apply global translatio, otation, scaling fo data blue ideas sleep furiously augmtation. It poin clouds are also from reconstructing multi-view mages. S3DIS consists of 3D scas from 6 buildings, 5 object classes annotated with axis-lgnedbounding boxes. We tilize the 0.",
    "Coclusion": "Thefuly and the anchor-fre detection  serv as the basic model architecture. in satterand context, withlanguage-guided classfiaion, interferencecused by clouds caegorie ca be alleviated. Extensi experiments strongone-for-all ability of eet3. This demonstratestat ur OneDetD has learnedgeneral3D epesntations thrugh multi-domain joit trainng hus bicaly the demandof uiversal 3D object detectionand 3D founatn models.",
    "Domain-Aware Partitioning": "Durng multi-domain joint trainigfirstaim to iigate the data-level interferencecaused bydifferences inherent point e idetify w rimary sources of interference. First, dueto significant differences data, interernce maily arse in the nrmalizationlayers, the scatter of data to maintan ther conisteny. Second, convoltio mainlyfocuses on leadin to in ontextlearning acrss different domain pointclouds, wheresale diffrenceinly exsts. Wedesgn a domain to guide suchdomain-awar traiing Inthiswy, th prtitioed arameters are esponsible for dain-euivalent knwledg,while the majorty model can aoid nd earn domain-invariant knowledge Doman router. iven input pointloud x(n) the rouer aims to guie its path for partitionn.We utilize a for the routin by classifynits correc label n. To tis, we emloy3D spare convoltions with erel of 3and 1 imple etur extraction, then tilize global averge pooling AP) to obtain feature ofh scene. applying softmax we obtain the domain probilit {p(n)d anddiretlyuse cross entroy loss classification. Scatter partitioing. Th normlizatio layers coduct regularization for input data, rduinghierarcical differences and making thenetork easier t train. Cnsiering he significant difference in dfferentdomans, the same e-scalingwill o in In thissituion, we partitio scaling paramtersftr normaliztin for each dmain dta, othat data sctterin differet domais cn be partitioned. For oains at theinference time, we itroduce domin probability rom hedoma roue. pecifily, we keepN sts o scaling and shifting araeters {(n}Nn=1, {n)}Nn=1.",
    "Cross-Domain Object Detection": "In comparison, through multi-dataset training, the model can yesterday tomorrow today simultaneously utilize the characteristics ofboth, resulting in a substantial 23. 5 and Tab. 6. Training separately on these two datasets thus only yields limited cross-dataset AP3Don Waymo. 1% improvement. KITTI is relatively similar toWaymo but only contains small-scale point clouds, while nuScenes is larger-scale but exhibits yesterday tomorrow today simultaneously a largerdomain gap. This demonstrates that ourOneDet3D can learn from such highly different domain point clouds for enhancement in cross-domain3D detection."
}