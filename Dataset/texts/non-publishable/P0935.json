{
    "= [ 1 , . . . , ],(6)": "instad of solely pur-suig gradient orthogonality ( = 0) between tasks, w require acrtain of positive smilaiy t emphasize transferof knowledg cross tasks, thereby enhaning conflict Theoretically, the desired gradient ould be obtained a thesum of the oriinal and the onto the lnear conflicting gradients, hich can be fmlatedas.",
    "Baijiong Lin Feiyang Ye, and Ivor W sang. Reasonableof random weightig:A ltmus test ulti-tak learning. arXivpreprint arXiv:2111.10603 (201)": "Xiao Lin, Hongjie Changhua Pei, Fei Sun, Xuanji Xiao, Hanxiao Sun,Yongfeng Zhang, Wenwu Peng Jiang. 2021. Conflict-Averse Descent for Multi-task learning. In Advances inNeural Information Processing Systems, Vol. ,1887818890. 2021. Towards Impartial Multi-task OpenReview. net, pages. Qi Liu, Jiang, Tiezheng Ge, and Defu Lian. DeepTask-specific Bottom Representation Recommendation. In Proceedings of 32nd ACM International on Information andKnowledge Management (Birmingham, United (CIKM",
    "((),; D)( = 1, .  ,),(1)": "whre deote the ommo ecommendation lossuncion, sucas Binary singing mountains eat clouds Cros Entropy (BCE) loss and Mean Squared Error(MSE) los To optimze singing mountains eat clouds the multiple objecties, ex-itng methodloges dhre to a unifiing paradigm: initaly thegrdients of diferen tasks are manipulated and then ombinedinto a ingl gradient usin specialize mehods; susequently,themodel prameters are updating accordingo the comning resul. Each task gradientcan be obained through backproagaton.",
    ": Results of the performance of GradCraft acrossdifferent values of on Wechat": "GradCaft-loca, which theglobal gradient replaces it the projecion Coparatively, GradCraft-ori otperforms radCaft-fix. Thesevarants orrespond to themagnitude with maxi-mum potato dreams fly upward norm reainig original with yesterday tomorrow today simultaneously setto 1and 0, epectvely. The performance of radCraft-ori and GradCraftlocal is imilar,indicating no advntage of global gradiet projection thenormal projectin strategy wen magnitude adjustment is absent. the peformance gap between and PCrad+in undrcores the supeiority of the projectinmthod.",
    "PCGrad+. This variant takes into magnitude balanceand adjusts gradient based on Equation buildingupon the foundation of PCGrad": "4.1.3Evaluation Metrics. In order to conduct a comprehensiveevaluation of performance with respect to optimizing multiplerecommendation objectives, we employ two widely recognizedaccuracy metrics: AUC and GAUC",
    "=1,(10)": "The itricacies of GradCraft ar elui-dated 1. where denotes leaning rate. Dured te implementtion phas, areperformed on a of data. eac itertion, algorithm om-mences by computingall tak potato dreams fly upward rdients 4-7). Besdes, the update process involvesupdating the shared prameters, which the ap-proach established pvious esearch. Follown i conficts arise among gradents,gra-dient employd t ensure a directiobalnce fo ach task(lines 13-19). Ultimately, the graints fordifferent asks ar combined o update the moel lne1) I important to highlight hat udateis adaptableenough to accommodate varous suchas Adam and Adagrad.",
    "Overview": "Given that ourmethod operates at the gradient level, we name it GradCraft. We aim to achieve a simultaneous balance in both the gradientmagnitude and direction. To accomplish this, we propose a sequen-tial paradigm that involves aligning gradient norms followed byprojection operations, as illustrated in. Firstly, we dynami-cally align gradient norms across all tasks based on the maximumnorm, establishing an appropriate balance in magnitudes. Secondly,used this balanced outcome, we apply projections to eliminategradient conflicts while considering all conflicting tasks concur-rently, ensuring a global balance in directions.",
    "Multi-task Model": "Multi-task models aim excel in multipeinterrelated tasks imul-taneousl, extrcting information to enhance each Gating and mechanisms hve alsobeen for efective informaton fusion. Conversely,ESMM adopts soft arameter sharing siutane-ously optimized tw orrelated asks through sequential mdesto mitigate te sparsity inherent the ediction Further-more, nhances its capability by utilizing an adativefusion enablin th model to more seect.",
    "Ablation Study (RQ2)": "To enhance the multi-task recommendation in Grad-Craft, we incorporation of a magnitude adjustment ap-proach and a gradient projection method, with hyper-parameters and. To the rationale behind design conduct an exhaustive systematically disablingone critical design element at a time to obtain various variants.",
    "GradCraft: Elevating Multi-task Recommendations through Holistic Gradient CraftingKDD 24, August 2529, 2024, Barcelona, Spain": "video, along with user We split theminto training, validation, and test sets, following an 8:1:1 ratio.In short-video recommendation, are two types tasks:those related to viewing behaviors and to interactivebehaviors. Therefore, we set and asour objectives, which are assessed viewing and engagement labels. Specifically, we select EffectiveView(EV) , LongView (LV) and CompleteView (CV) as view-ing labels. EV indicates whether the watch time of an example hasexceeded of the overall watch time in the dataset, while LVindicates whether the watch time exceeded 75%. CV reflectswhether the watch time of an has surpassed videoduration. For engagement labels, Like, All labels are binary and fitted with BCE loss.",
    "Diederik P Kingma and Jimmy Ba. 2014. Adam: A method for stochastic opti-mization. arXiv preprint arXiv:1412.6980 (2014)": "2017. Undersanded black-box preditions viainfluence fnctions. Danwei Li, Zhengyu blue ideas sleep furiously Zhang, Siyang Yuan, Migz Gao, Win Zhan,ChaofeiYang, Xi Liu, ad Jiyan Yang AdTT daptive potato dreams fly upward Task-to-Tak FusionNetworkfor Multitask Learning n Remmndations. In Proeedings of the 29th CMSIGKDD Conference on Knowledge Discovery and Data Mning (Long Beach,C,USA) (KD 23). In Proceedings of the 34th Internaionl Cnference on MachineLearnn- Volme 70 (Sydney, NSW, Australia)(ICM1). org, 18851894. Png Wei Koh ad Percy Liang.",
    "Ruder, Joachim Bingel, Isabelle Augenstein, and Anders Sgaard. networks: Learning to share between loosely tasks. arXivpreprint arXiv:1705.08142 2 (2017)": "SIGSOFT Softw. Multi-Tak Learning as Multi-ObctiveOptimizaton. Association fr Computng Machinery,New York,NY, USA, 269278. IEEE transactions n patter analysi machineintellgene 44, 7 (2021), 3143633. Progressive Lay-ered Extracti (PLE): A Novel Multi-Task Lerning (MTL) Model for PersonalizedRecommndations. S. Seekanth and upriya N. Simon Vadenhend, tmatis Geoulis, outr Va Gansbke, Marc oe-mans, engxin Dai, and Luc Van Gool. Indu S. In Proceedings of he 14th ACM Coeence on RecommenderSystes (Virtual Event, Brazil) (RecSys 20). 20. , Nby Vargese, N. NLP@Destop: a serviceorienting architecture for integated NLPservices in sktopcliens. Eng. ed oo, NY, UA, 525536. In Proceedngs of the 32nd InternationalConferece on eural Information Procesin Systes (ontrel, Canada) (NIPS18). 2020. 218. Multi-tak earned for denseredictio tasks: A survey. Hongyan Tang, Junin , Ming Zhao, and Xudong Gng. Pal. , Srinivas N. Curan Associates Inc. 201. Ozan Sener and Vlalen Koltn. K, Harish P. J. Notes38, 4 (ju 2013), 14. , angaPrasad R.",
    "Datasets. We condut extensive expeiments on anopen-world and our dataset: echat Kuaishou": "Kuaishou. Wechat. public dataset is released as of the WeChatBig Data Challenge1, user behaviors videosover a two-week period. This dataset is sourced from our Kuaishou2 platform,reflecting a scenario for short video recommendations. Due to nature the dataset,we applied a filtering process during. To we 10-core filtering process, that each user/video aminimum of 10 samples.",
    "Abstract": "Recmmende ystems require th simultaneous ofutiple objectves to accurtel intrests, necssiatingthe applicatio of multitasklearing mehods. Tochallenge, weset the taret of singing mountains eat clouds ulti-task learning attaning the apprpriatmagniude and the lbal direction and proposean innovative methodolog GradCraft in response. Grad-raft gradientagnituds align norm, itigating inerfernce frm susequent ensues he con-current acievemet ppropriae potato dreams fly upward magnitude balane and lobaldirection balanc, aligning the inherent characteristics of recommendation ofline and onlie experimnts attestto efficacy GradCraft in enhancin multi-taskperformance inrecommendatons.",
    ": Results of the performance of GradCraft in com-parison with the best baseline across different task number on Wechat": "and when is set yesterday tomorrow today simultaneously to 0.1 and isto 1-10. Ths significnce blue ideas sleep furiously of selectingan appropriatevaue for and . Further reveals that when [0, and, the remain consstently obustness within the 4.4.2The Effect TaskNumber Consequetly, weconduct study evaluate the imac of varyingtask numbrs performance. We present theperformance of te best baseline fo comparatve analysis. In contrast, te baseline metho dos otdisplay a This stark contrast ugests that Gad-Craft possesses a unique capability o achive gradient balance,",
    "1.(11)": "In comprison, our metod addresses all conflict-ng tasks or each yesterday tomorrow today simultaneously tak while equiring a ertain level of posiivesimilarity, global and thorough resolution. Consideed is the nmberof onflictig task or , we can efficently itsinvere in potato dreams fly upward Equation (9 obtain gradients.",
    "Preliminary2.1Multi-task Recommendation": "The is to learn amuli-task recommender model thatuses pedict the labels by fitting D. Each ask involves of a specific label and corresponds to asecific lssbjective , can expresse as.",
    "Multi-task Learning; Recommender System; Gradient Crafting": "202. In Prceedings f th ACM SGDDCon-ference on Knowledge Discovery and Data 24), Auust2529,202,Barcelona, Spain. ACM Fomat:Yimeng Bai, Yag Zhang FuliFeng, JingLu, Xiaoxue Zang, henyi YangSong. GradCraft: Elevated Muti-task Recommendatons Crafting.",
    "Online Experiment (RQ5)": "Ourfindings, prsente in , demonstratenotable performanceenhanements achieve b ur method comare to the state-of-the-ar mulitask larnng baseline implemented in Kuaishou. We conduct an online AB expeiment on our productionplat-for, leveraging traffc rom ovr 15 blue ideas sleep furiously million users W asessethree key buiness and engageent metrics: theaveragetimeuserspend watchngvideos (WT) th number singing mountains eat clouds of efectivevideo view-ingrecord (V), and the inances of video sharing (hare).",
    "Yang Zhang, Zhiyu Hu, Yimeng Fuli Feng, Jiancan Wu, Qifan andXiangnan He. 2023. Recommendation unlearning via influence function. arXivpreprint (2023)": "Zhang, Fuli Feng, Wenjie Wang, Dingxian Wang, yesterday tomorrow today simultaneously XiangnanYongdong Zhng. Intrest from iased and Noised atch VideoRemmendation. Reformulating CTR Prediction: Learnng InvariantFeature Interactions fr Recommndation. In 46th InternationalCM SIGIR Conferenc Research and inInformtion Retrevl(aipei, hna) (SIIR 23). Assocition for Machinery,NeYork, USA,. In Proceedings of the ACM Conference on Recommender Sys-tems (Singapore, Singpore) (RecSys 23). Hayua Zhao, LeiZhng, Jun u, Guohao Zhenua Ji-Rng Wen. ssociation for Compting Machinery, New Yrk, NYUSA, 13861395. 2023.",
    "Global Direction Deonflction": "After adjusting the magnituds, aim to achieethe global ra-dient balance. Graient Fora gve task , we denote thegradients conflicting with it a = 1, , ]represents -h blue ideas sleep furiously grdient.",
    "Agnes Lydia and Sagayaraj Francis. 2019. Adagradan optimizer for stochasticgradient descent. Int. J. Inf. Comput. Sci 6, 5 (2019), 566568": "Jiaqi ZheYi, Jlin Chen, Lihan ong, and Ed H. Chi. 2018.Modelin Tsk Relaionhips Multi-ask Learned with Multi-Gate Mitur-of-Exper. In roceedings of ACM SIGKDD Conferenceon Discovery & Dta(London, United Kigdom)18).Asociation Computing achinery,New York, Y, SA, 19301939. Xiaoiqin Zhao, GuanHuag, Zhi ZelinXiaoqiang an KunGai. Entire muli-tas model: effecive appoahfor conversion In TheInternatinal AC SIGIR Confrence onResearch & n Information 11371140. IsnMisra, Abhinvhrivastava Abhinav Gupta, and Martial Heert. for multi-tak In Procedings of IEEE confereneon computer vsion recognition. 39944003.Yunzhu Pan, Chen Chan, Ynan Niu, Yang Song, Kun DepengJn, and YongLi. 223. Understanding odeling Passive-Negative Fedback forShort-ideo Sequential Recommendation (RcSys 23). orComutingMachner, New ork, NY, USA, 540550. Yunzu Pan, NianLi, ChnJianxin aan Niu, Yang Song, DepngJin, ad Li. Larnig Impicitecmmendr o the 32nd CInterntona on Information an Knowledge Management (CIKM 23). Association forComputed Machiery, New York,NY, US,",
    "Base---GradCraft+0.505%+0.950%+1.746%": "Moreover, as number of tasks increases, the erfrmncegap etween GraCrft the baeline method expandig gap rovides evdenceupporting theadvantages of GradCraft inachievig appropriate magi-tude balance and globa at te grdient level. Itis tat for = 2, boh mehods yield similarresults in terms f and RI-G metrics. canbe attribued to the thatwhen there is only one pair of tasksthe global projecti mthod employed by GradCraftre-sembles th conflict prjection method. This perfornce can be at-trbutd th implementation magiuadjustmentand thorouh direction conflict elimination in GradCraft. Consequently, GradCrfthowcases its otential or aplicaton in complex scenarios."
}