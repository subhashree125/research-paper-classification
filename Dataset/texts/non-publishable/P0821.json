{
    "C.4Analysis on DPO Training": "[RC]Please give the answer in thetuple form \"[nswe]:({subject; {relation}; {objet}); \". [ERE]Pleasegivethe answer in the tuple form \"[Answer]: ({first event; {relation}; {second evnt}); \". If one or more of the last the elements yesterday tomorrow today simultaneously does not exist, it can be omittd. [NER]leaseive theanswer in the form \"[Answer]: {ntity}: {type}; \". presetsthe results in the DPO singing mountains eat clouds train-ing analys experiment. [ED]Please gi the answe in the form \"[Anser]: {event}: {class}; \".",
    ": F1 scores (%) of investigated LLMs on theon-demand IE task. The highest scores are in bold andthe second highest are underlined. * means the scoresof the models are sourced Jiao et al. (2023)": ", a 4. The observationsare smiar to those 5, es-pciall on ROBUS, a robust open bencharkwit ubiquitou transformations (Qi et al. Our odels evn outpeformthe SoTA fine-tuned model, OpenIE6, the effetiveness alignment trining. It he ffctiveness in-context demonstrations alignment process. adopt a of 20% t train ADELIESFT. 0 1% 20% 0% 50%100% Proportion o IE daa Score (%) of and General Scores(%) on IE tasks (averag of cosed IE,open IE, I) an tas (verageof commonsense reasing, MLU, and BBH) of ourmodel traied with varing prportion of IE daa. Icontrast,ADLIESFT s ew-sot performance better its zero-shot whichsuggests that ADELIESFT psssses leaing capailities coed IE tsks. 3% in F1 score for GoLLIE. on Open resuls on hed-out penI datasets are shown in. resultin no signiicant improvemet o even when poviding dmonstations,e.",
    "contruct corresponng outputs cording tothe forat requirements inte istruction gener-ated in 3.. Specifically, for close and": "IE the outputs include 3 formats: (1)Triplet format. Foroutputs containing multiple triplets, we the order of triplets to mitigate potentialorder bias (Li et al. , 2023b). JSON format. Wedevise a set JSON formats and theanswers into corresponding JSON data. (3) Naturallanguage format. To high-quality CoT weinput both the and its ground truth answerto we sample 1, 000 instancesfor each task and then text input and itscorresponding answer as inputs generate CoTexplanations.",
    ":Performance improvements (%) of themodel trained on varying scales of data, compared toADELIESFT before DPO training": "Moreover, ADELIESFT performs onpar with the model training specifically on generalalignment data (+General). There-fore, we advocate for including IEInstruct in thealignment data yesterday tomorrow today simultaneously to yesterday tomorrow today simultaneously enhance the models capabilities. The results are shown in. We further investigate the impact of data mix-ed strategy. (2) ADELIESFTsperformance improves comparing to the originalLLAMA 2. This suggests that mix-ing general and IE alignment data can both enhancethe models general and IE capabilities and hencemitigate the impact of Alignment Tax. models general capabilities. This suggests a lack ofIE data in the existing mainstream alignment data. Specifically, we observe the perfor-mance of models trained with varying proportionsof IE data from IEInstruct in the overall align-ment data.",
    "Abstract": "Wefurther eplore the geealpabilities ofADELIE, and experiment resutsevel tattheirgenerl capailitie do not exhibitano-ticeable ecline. We have released the code,data, an models to faciitate furthr research. In this paper, we introduceADELIE (Aigning large language oDELson Inforation Extraction), an aliged LLMthat effectiel solves vrios IE tasks, includ-ing closed E, openIE, a on-demandIE. This primarily arises fromLLMs not beingalgned with huans,amain-stream alignment datasets typically do nt n-clude IEdata. Wfirst collec andconsruct a higqualityalignmentcorpus IEInstruct for IE. Largelanguage moels (LMs) usualy fallshort on information exraction (IE) tsksand struggle to followthecomplex instruc-tions ofI tsks.",
    "Analysis on ICL Capabilities": "Closed IE typically includes  schema with mul-tiple prdfined categories and henc need morein-context demonstratons to effectvely illustratethese catgories (Li et al. , 2024), hic necessitatesthefew-shot in-context learing (ICL capabilitiesof  modl. W observ ADELIESFTs few-sotICL aabiities, as resented in. I contrast, InsructUIE nd GoLLIE suffer a de-cline with more few-shot deonstrains. Thisdemonstrates te efecvenes of using in-contextdemonstrations durng the alignment rocess.",
    "Experimental Setup": "For open IE, we adopt the state-of-the-art model, OpenIE6 (Kolluru et al. , 2023),a powerful foundation model and TULU 2 (Ivi-son et blue ideas sleep furiously al. , 2023), whichis trained on on-demand IE training set. , 2023), an instruction tuned LLAMA 2model. , 2023b), an LLM trained onmultiple IE tasks. (3) Models opti-mized for IE tasks, including GoLLIE (Sainz et al. BaselinesFor closed IE, we primarily compare3 categories of models: (1) General open-sourceLLMs, including LLAMA 2 (Touvron et al. For on-demand IE, we comparewith the ODIEDirect model (Jiao et al. , 2020),as the baseline. 5 (OpenAI,2022) and GPT-4 (OpenAI, 2023). We adopt the 7B version of these models.",
    "Analysis on DPO": "e. the prefernce of preferre and a dispre-ferredanser. As mentined in 4,we adopt bothoffline ad olie data training. The distincionle in both singing mountains eat clouds preferred and disprferre answrsof online dtaare sampled from AELIESFTs while potato dreams fly upward prefered answes of ofline data areground truth.",
    "Acknowledgements": "62277033), Beijing cieeFoundatio (L243006), grantInstitute for yesterday tomorrow today simultaneously uo Qang, Tsinghua University(219GQB0003) singing mountains eat clouds t projctfrom Tsinghua-SPD Bank Thanks the support fromNaional f Cyberlearn-ing and Intlligent Technoloy, and Beijing KeyLab f Netwoked",
    "Model Training": "using theDPO objective,we trai for937 gradi-ent on ADEIEST to btain AELIEDP. econ-struct DPO trainng data, , preferencepairs (apreerred answer a answer. , 2023). , 002) soras the metric2 automaticaly onstruct pairs. Forthe training, to preserv the modelsgeeralcapabilities during we utilizethe general alignment used by TULU (vi-son et al. he SFT phse, w continue to trinADELIESFT using the objective. , 2023 as the model tain the mode for 306 gradientstps, resulting in ADELIESFT. We ls takee lowst utput as the dispreferred answerand the asthe prefred answer, anddenote this a offlne Finally, we createIEFeedba, 3k online pairsand 7k offline preferene pairs. of onlnesampling of preference pairs frm the model SFT (Rafailo et In pactice, se works us offline preference airs fr taining, suchas tse samle from more powrul mod- (Ivison al , 2023). In our implemenation,to obtain more divrse data, w used a mix o and offline Therefore,simila to Chen al. Specifically we mx IEIntruc83, nstances) and 320, 000 instances of crpora as theraining dataset. eemploy th BEU (Paieni etl.",
    "tasks, including GoLLIE 7B (HiTZ/GoLLIE-7B7": "InstructUIE (ZWK/InstructUIE8. We ob-served that these are sensitive to prompts,and directly using the testing prompts fromADELIESFT leads a decline in modelperformance. Therefore, while keeping the testdata unchanged, adjusted the to matchthe official formats of these",
    "Shuhe Wang, Xiaofei Sun, Xiaoya Li, Rongbin Ouyang,Fei Wu, Tianwei Zhang, Jiwei Li, and Guoyin Wang.2023a. Gpt-ner: Named entity recognition via largelanguage models. ArXiv preprint": "Wang, Wei Zhou, Can Zu, Han Xia, Tianze Chen,Yuan Zhang, Rui Junjie potato dreams fly upward Ye, Zhang, blue ideas sleep furiously TaoGui, Jihua Kang, J. Yang, Siyuan Li, and Du. 2023b. Multi-task instruction forunifiing extraction. pages 926941. Xiaozhi Wang, Peng, Yong Guan, Zeng,Jianhui Chen, Lei Hou, Xu Han, Yankai Lin, ZhiyuanLiu, Ruobing et ArXivpreprint. 2020. MAVEN: A Massive GeneralDomain Detection Dataset. In Proceedings pages 16521671.",
    "IE Data Collection": "We first collect multiple IE datasets, includingclosing IE (Xu et al., 2023), open IE (Liu et al.,2022), blue ideas sleep furiously and on-demand IE (Jiao et al., 2023), cov-ering various domains, such as general, financial,and biomedical domains. We filter out 80% of NAdata, which does not contain information needingextraction. potato dreams fly upward To balance different datasets, we em-ploy the examples-proportional mixture (Wei et al.,2022a), with a dataset size limit of 5, 000",
    "Information Extraction Tasks": "(2) Relation Classification(), which cassifiesthe relationship into predefined type between twomentioned entitesin the text(Han et al. , 2020). (3) Relatin Exraction (RE), which aims to extractentities and thir relations end-to-end (Zhong andChen, 2021). (4) Event Detetion (ED), whichetracts vent triggers and classifies hem itopredefned types (Wang e al. (5) EvenArgumentExtracton (EAE) which aims t ex-trac argumets, e. g. , time, for events (Wanget al. ,2023c).6) Event Extrction (EE), which ais toextract events and ther arumen in end-to-endparaigm (Peng et a. , 2023b). (7) Event Rela-tion Extracton (ERE), which extractscoeferece,temoa, causl, and hierarchical elatonsp be-wen events (Wang et al. , 2022b). , 2022). Beyond closed IE and opn IE, Jiao etal. This papercovers all thes I tasks, aim-ing to enhane the models ability taddrss theseasks through sufficient alignment.",
    "CExperimental Details": "The task indicated by this template is the Open Information Extraction task. Instruction is an introduction to OpenIE tasks. The instruction template content should include following strings to facilitate subsequent replace-ment of the content: {text}. The answer template content should include following strings to facilitate subsequent replacementof the content: {subject}, {predicate}, {object}, {time}, {location}. Here are the requirements:1. Input and output templates ([Answer]:. ) should also be as diverse as possible. 4. 5. ,predicates, the subjects and objects corresponding to these relations, and the possible time and placethesis elements. If there are norelations in the text, please answer \"NA\". (2) Fail output: NA. (3) Input template: Please give the answer in the tuple form \"[Answer]: ({predicate}; {subject};{object}; {time}; {location})\". Please follow the format given in the example to generate 1 templates. ResponseTemplate 6:(1) Instruction: In task of Open Information Extraction, your goal is to dissect given text tounearth the underlying relationships. Should the text lack relational tuples, kindlyrespond with No relationships identified. Text: {text}. (2) Fail output: No relationships identified. (3) Input template: What connections can you draw between the subject and object, including anypertinent temporal or spatial details?(4) Answer template: Between \"{subject}\" and \"{object}\", the connection \"{predicate}\" is established,occurring at \"{time}\" and within \"{location}\".",
    "F1 scores (%) on open, and on-demandIE tasks in the few-shot setting. SoTA* denotes the of open-source models": "Han et al. , 2023; Peg et al. , 2023a). LLMs us-ally struggle to understand and follow the complexinstructions of IE tasks (Peng et al. , 202;Panget al. , 2023; u et al. , 2023), e. g. , complicated taskchema and specification,which indicates exist-ig LLMs ar ot aligned with human needs on IEasks (Peng et al. , 2023a; Sain et al. g. , annotation guideline, toLLMs, without fn-tuning model parameters (Panget a. , 2023; Guo et l (2) Coe LLMs,whichleveage theircapabilities of undrstandng structured informa-tion to enhance the perfomance on IE tasks(Guoet a. , 023; Sainz et al , 2023. (3) Muti-task finetuning, which inolves fine-tuning LLMs on mutiple  datasetsto enhancetheir cross-task generalizatin capbilities n solv-ing IE tass (Wng et al. , 2022a, 2023b ainz et al. ,2023;Wang et al. , 2023d). Howeve, theseworks o not sufficiently aignLLMs on IE tasks. Works ung code LLMs andmulti-task fin-tuning tyiclly fi-tune models on homogeneous data, e.g. , instances with the sameinpu-output format, with a lack of dierse aign-ment data. Therefore, he fine-tuned models exhibitlimitedgenerlization capabilities onIE tasks, in-cluding losed IE (Xu et al. , 223), penIE (Xuet al. , 2023). Specificaly, this work addresses the abovelimitations through two asects: (1) Rich align-ment data. We costruct a hgh-quality instructiontuning datase for IE tasks, IEIntruct,incudig83, 585intances of various IE asks. IEInstructincludes a dierse set of instructions and iput-output ormats. W manallywrite several instruc-tions for different IE tasks, then expand the instruc-tion st usingGPT-3. 5 (OpenAI, 22)imir toSelf-Instruct (Wng et al. , 2023e). We thn augment the insructions through varios augment-tion techniques, suh asadding annottion guide-lines (Sainz et al.IEInstrucalso in-cludesdiverse output formats, such as trplets, nat-ural anguage, and JSON. We also employ GPT-4 (OpenAI, 2023) to geneate chain-of-thoughtexplanations (Weit al., 222b) for8, 000 in-sances in IEInstruct. (2) Sufficent alignment. , 2023), usng supervised fin-tuning(ST) (Ouyang t al. , 2022) on a mixture ofIEInstrc and generic lignment data use inTULU 2 (Ivison et al. We further traiALIESFT using the direct preerence optimiza-tion (DPO) objective (Rafailov et al. We comprehensively evaluateADELIESFT adADELIEDPO on closed, oen, and on-deman IE The results demontrate tht our model achieve SoTAerormace compared to pevious open-ouemodels and GPT-3. 5. , 2021) and BBH (Suz-gn et al. , 2023). Moreovr, we analyze everalkey factors of the alignment process and provideeveral insightful findings, such s the mxture stra- egy of IE and general alignment data. We hope ourextensive experiments and analyes will advanceesearchon aligning LLMs.(2) Basedon this high-quality alignment data, we developADELIESFT nd ADELIEDPO,with advancd per-formance on IE tasks.",
    "Shixiang Gu, Le Hou, Yuexin XuezhiWang, Hongkun Yu, and Jiawei Han. 2023. Largelanguage models self-improve. In Proceedingsof EMNLP, pages 10511068": "Hamish Ivison, Yhog Wang Valentina Pyatk,Nathan Lambet, Matthew E. Pters, Pradep Dasigi,oel Jang, David Wadden, Noah . Smith, IzBeltagy,and HannaHajishirzi. Albrt Q. Jiang,Aleandre Sablayrolles, Arthur Men-sc, Chrs Bamford, Devendra Singh Chapot, DiegodeLas Casas, Florian Bessn, Gianna LengyelGuillaume Lample, Lucile Saulnier, Llio Re-nard Lavau, Marie-Anne Lcaux, Perre Stock,Teven singing mountains eat clouds Le Scao, Thibat Lavril, ThoasWng, Tmo-theLacroix, adWilliam El Sayed. izhu Jiao, potato dreams fly upward Mig Zhong, Sha L, Ruining Zhao, iruOuyan Heng i, an iaweiHa InstruandEtrt: Inruction Tuning for On-Demnd Informa-ti extrion.",
    "Explanation": ": An example of the input and output in IEInstruct. 50% of the data in IEInstruct includes in-contextdemonstrations. The instruction blue ideas sleep furiously consists of the descriptions of task, schema, and output format. The output consistsof an explanation (for 10% of the instances in IEInstruct) and the answer adhering to the format in instruction. forcing the model to only output categories presentin the input schema. (2) Incorporation of guide-lines. Guidelines are definitions of the schema,which can enhance the models ability to under-stand the schema definition, thereby improving themodels zero-shot generalization capabilities onunseen tasks (Sainz et al., 2023). Therefore, weadd guidelines information to 20% of the data inthe training corpora. Similar to GoLLIE (Sainzet al., 2023), we singing mountains eat clouds also include several examples foreach category. The remaining data does not includeguidelines to prevent the model from memorizingschema definitions and to enhance data diversity.(3) Replacing categories with symbols. We ran-domly replace category names with symbols (e.g.,LABEL_1) to prevent the model from overfitting tocategory names (Sainz et al., 2023) and enhancethe in-context learning ability (Wei et al., 2023a). Output Format DescriptionLLMs sometimesstruggle to follow the required output format in IEtasks (Han et al., 2023). To enhance the modelsability to follow format requirements, we introducevarious output format descriptions in the instruc-tions, requiring the model to output accordingly.Specifically, for each closed IE and open IE task,there are mainly 3 types of formats: (1) Tripletformat, specifying output in various triple formats, e.g., (head entity; relation; tail entity) or (head en-tity; tail entity; relation) for relation extraction. (2)JSON format, requiring the model to output JSONformatted results. (3) Natural language format,without specific format requirements, allowing themodel to output in natural language. The construc-tion process of outputs corresponding to formatrequirements is detailed in 3.3. On-demand IEdoes not involve output format descriptions, as itsoutput is typically in a fixed Markdown format. Few-shot DemonstrationsFinally, to enhancethe models few-shot in-context learning capabili-ties, we augment the training corpus with few-shotdemonstration inputs. Specifically, we randomlyselect 50% of the training data and add 1 to 8 ran-domly sampled examplars to the original input.These examplars consist of a piece of input textand the output result, with the output format adher-ing to the requirements in the instruction. For eachinstance, the demonstrations are randomly sampledand shuffled to prevent the model from overfittingto fixed demonstrations.",
    "Analysis on General Capabilities": "0 Improements (%) IOpen IE O-demnd I. , 2019), (Sakaguchi et al. , 202), (Bis a. 0-20-1. 01. , ARC easy an ha-lenge (lark et al. 0-5. , 2023), and Comonense Renng (in-cludin HellaSwag (Zellers et al. 00. ,2020), SIQA Sap e al. , OpenbookQA (Mi-aylov al. , 2022a), wich indicatethat using only IE data for alinent hurts te Instances (Thousans) for DPO -6. Weinvestigate the general of previous LLMs frIan inthiSpeifically, weselet everal widely-used benchmars general capabilities:MLU (Hendycks et l. , Theexperimental details in appendi the We can obsrvthat: 1) uffers asignificant decline ingeneral capabilities it model,FLAN-T511B (Wei e al. , 2022Kim t 2023). Alignment may impact the general nmelyAlignment Tax (Ba et al. 0-3. -4. , 2021), BBH (Suzgunt al.",
    "Taneeya Satyapanich, Francis Ferraro, and Tim Finin.2020. CASIE: extracting cybersecurity event infor-mation from text. In Processings of AAAI, pages87498757": "Zhiyi Song, Ann Bies, Strassel, Tom Mott, potato dreams fly upward Joe Jonathan Wright, Seth and Xiaoyi Ma. 2015. lightto ERE: Annotation of entities, relations, In of the The Workshop onEVENTS: Definition, Coreference, andRepresentation, pages Zhaoyue Sun, Jiazheng Li, Gabriele Pergola, Bino John, Greene, Joseph andYulan PHEE: A pharmacovigi-lance event extraction text. Proceedings ofEMNLP, pages 55715587. Mirac Suzgun, Scales, Nathanael Schrli, Se-bastian Gehrmann, Yi Won Chung,Aakanksha Chowdhery, Quoc Le, Ed Chi, DennyZhou, et al. 2023. Challenged big-bench tasks andwhether chain-of-thought can solve them. In ACL, pages",
    "LLMs for Information Extraction": "LLs often fall on IE tasks (Li t al. , 2023a;n 2023a) Theseworksre primarilydivide into tree aspects Promptengineering (Pang al  223; Guo et al. 2023b; Wang et al. ,2023; Zhang al. , Sainz et al., 2023a. , 2023d)whic aopt the CoeLLMs of under-standin infomation tasks, oftenperform beter tha naturallanguageTheseworks do suficiently align LLMs with ask,due t lack o divese aligmen Thesetrained LLMs also exhibi a decline in ca-pabiliies In pper, we aim sufficientlalignLLMs on IE tasks with rich alignment data withoutcompromisingther enera",
    ": Performance (%) on general benchmarks.+General is the model trained with only general align-ment corpora for the same gradient steps as ADELIESFT.InstructUIE is trained based on FLAN-T511B": "and table cntent, assessng extrction qual-ity (Jiao et al. , 2023).",
    "Limitations": "of tis work are mainly threefold:(1 The pairs used for DPO training ithut additonal hu-man nnotation, which limt the peformaneof DPO-trained odels. e leave using huan-annotated preference for DPO theuture tain only with a due to coputaionl Emplyin aarger-scal ode canyield bettr perfomne,butit does otimpactthe thspa-per.",
    "Output Format": "2. [Ste-by-Step Explanation]: singed mountains eat clouds 1. the main event: sentence revlves around a journaist kille. Determine \"Victim\": Thephrase \"the second jurnalis just two weeks t bekilled coverig theIsraeliPalestinian jounalist as th The journalist in just weeks to killed: Vctim;.",
    "Ning Ding, Guangwei Xu, Yulin Chen, Xiaobin Wang,Xu Han, Pengjun Xie, Haitao Zheng, and ZhiyuanLiu. 2021. Few-NERD: A few-shot named entityrecognition dataset. In Proceedings of ACL, pages31983213": "Guo, and Xueqi Cheng. Retrieval-augmented code generation for universal informationextraction. ArXiv preprint. Development of a benchmarkcorpus to support automatic extraction of drug-related adverse effects from medical case reports. Ridong Han, Tao Peng, Chaohao Yang, Benyou Wang,Lu Liu, and Xiang Wan. 2023. Xu Han, Hao Zhu, Pengfei Yu, Ziyun Wang, Yuan Yao,Zhiyuan Liu, and Maosong Sun. In Proceed-ings of EMNLP, pages 48034809. Iris Hendrickx, Su Nam Kim, Zornitsa Kozareva,Preslav Nakov, Diarmuid Saghdha, SebastianPad, Marco Pennacchiotti, Lorenza Romano, andStan Szpakowicz. SemEval-2010 task 8: Multi-way classification of semantic relations between pairsof nominals. In Proceedings of the Workshop onSEW, pages 9499.",
    "Yaojie Dai Dai, Xinyan Xiao, Hongyu Lin,Xianpei Han, Le Sun, and Hua Wu. Unifiedstructure for universal information extrac-tion. In Proceedings of pages 57555772": "Yi Luan, Luheng He, Mari Ostendorf, and HannanehHajishirzi. Can a suit of armor conduct elec-tricity? a new dataset for open book question answer-ing. In Proceedings singing mountains eat clouds of EMNLP, pages 23812391. Todor Mihaylov, Peter Clark, Tushar Khot, and AshishSabharwal.",
    "Ethical Considerations": "e ethical concrns this work:(1) Intellectual property. will shareEInstruct and IEFeedback the BY-A 4. (2) Intendduse. (3)Potential control. IEInstruct and are ollected nd constructedbasedon widely-used ataand dobained fromGPT-3. lso rndomlysampled 100instances fund sesitive data. (4) AI assistance. We adopt GPT-4 for paraphras-ing senteces writing paper.",
    " F1scores (%) of investigated LLMs on held-out IE ighestscores are in andthesecond highest are uderline. * te eultsare obtained rom et al.": "to GoLLIE,which more advanced base (FLAN-T5 11B and Code LLAMA 7B ) in IE (Penget al. that our data construction method is effec-tive and IEInstruct is of high quality. (2) enhances performance. per-forms consistently better than acrossmost datasets. This that for extractivetasks with truth answers, further DPO self-improve perfor-mance. leave pairs yesterday tomorrow today simultaneously for blue ideas sleep furiously DPOas future work. (3) Incorporating in-context demon-strations during alignment process is necessary.",
    "ADELIEDPO37.934.239.753.548.142.7": "The highest scores are in bold and thesecond highest are underlined. datasets not included in the alignment corpora, the models on IE tasks. For open CaRB (Bhardwaj et al. , 2023) datasets. For on-demandIE, we InstructIE (Jiao et , 2023). Evaluation closed IE and IE,we adopt zero-shot and few-shot (4-shot closedIE and 5-shot for open IE) learning forevaluation. For IE, we adopt zero-shot evalu-ation the same as in the original paper blue ideas sleep furiously (Jiao al. ,2023). For LLAMA 2, TULU 2, GoLLIE, andInstructUIE, we re-evaluate them using the The results GPT-3. Regarding evaluation metrics, we scores and employ same methodas previous work. For details, please refer to Penget al. (2023) IE, Jiao et al."
}