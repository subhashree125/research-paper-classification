{
    "(b) Percentage gaps in salaries by Llama 3": ": Heatmaps for intersectiona percentag aps reative to the verage salary recomeded to all candidatesfor eecive ccupaion, wen iographes are not pesented. Only ocupations wthatistically signficantresultsre shown. along both racial and gnder lines. WeconstructnotherMixedLM anaysis with simila setup as inprevious section but with ace-enderas theindepenen varable an Whte male set as thefeene grop ( = 0. Thecrrespondingstatistically ignificantdifferences in amntsoffered t singing mountains eat clouds the ther 7 race-gender roups (inprcentage ar also displayd. shows thecorreponding catter plots. Compared totheir male counterpart,fe-male nas are oferedlower slaries re fre-qutly than White male nams. n,Whieemale names are almost always offeredless tan hite ml names by both GPT-3. 5 andLlama 3. Blk femaleames receive lorsalaryoffers than Whte malenaes in 6ocupationsb PT3. 5 and 11 by La 3, while Back male names onlydo so in 1and 2 occupations, respec-tively. male naes. Weobseve two majo tens. First, compared tother no-White grup, Black namesare offereore tan hit male ames in signifiantly highernumber of occupaions. For the smegender andmodel, lack names outperform ohe non-Whitemes in terms of the number of occupations wherethey are favred over White male nmes (o. cc. Mo in ).econd, oerall, positive percent-ag gaps for names ofall other ace-geder groupsrelative t Witemae names cluster t appro-mately under 2%, though outlirs exceeding 4%still exist (b) Thouhnot blue ideas sleep furiously exremel largeinmagnitude the very presence of these dispar-tis in Lsbehavirsis alai as they canpopate inequality o stakeholders ifdeployd.",
    "Abstract": "results ndicate peferenceaong hese models hiing candidates withWhite female-sunding names over other de-mographic groups across 40 ocupations. een amongcadidates with idnticalqualifications, recommedations byas much as % difeent subgroups. Simlarly, Large LanguageModels (LLMs hae demonstated racial andgender biases in5-Turbo and lama3-70B-Instrut saary recommedation for candidateswith 320 first nmes sigal and geder, across 750,000 prompts. Acmpariso ith real-world bor data evealsincnsisten U. science has that candi-dateswith names indicative certain orgnders ofen face discrimination employ-ment practices. S labor marketcharacteristics, nessity ofrk investigationLLM-powere systms.",
    "Intersectional Analysis": "31% for AM 5. 85%for WM), followed by physician and composer forGPT-3. Second, GPT-3. 5 offersWhite male names salaries higher than all other Similarly, Llama 3 favorsthis demographic in 9 of 10 aneven higher discrepancy (b). Incontrast, Hispanic and Asian names, particularlyfemale, tend to have offers lower than at ahigher magnitude across both models. Llama give male nameshigher offers over female names the race. Our observation is that White malenames are offered more by models. illustrates the race-gender groups relative theoverall salary for these occupations. 24% for BF to 13. architect attorney chiropractor comedian composer dentist dietitian dj filmmaker journalist model nurse painter paralegal physician psychologist software-engineer teacher yoga-teacher. Pastor is the occupation withthe largest gaps (from -3. WithoutBiographies.",
    "total frequency": "Names whsetmes (top 50% the Rosenman et al. isremovedfro candidae 9, wher rce {White, Hipanic, Asian, Black}. We singing mountains eat clouds mit category fro thi anaysis. blue ideas sleep furiously We thus augment these categoies a dataset Tzioumis which dras from States mrtgage information provides similarassocited conditional robabilities for 4,250rst nae for sa raial ategories. 8 with frequency of appearance the top among in this dataset. Fr Hispanic mal categoy, we select fromaforementionedRosenmanpoo of candidats, and 10 from the Tioumis pool. For Asian and Aia female atgoiesrespectivel, we te pools eenly each) to arrive at the requied 0 names.",
    "Name-based biases by LLMs are notconsistent across settings.For instance, female": "In con-trast, Black names are often overlooked in hiring,but are also offered salary higher than average. Con-sideration of the risks, challenges and rewards be-comes crucial in blue ideas sleep furiously the ethical deployment of LLMs. However, our intersectional analyses high-light significant disparity in offers dealt to non-White female names, particularly those of Hispanicbackground. Our results showcasethat prompting LLMs to choose one among severalcandidates arguably magnify the risk of preferen-tial treatment, and thus should be avoided. , 2024). Further investigation is war-ranted to understand the underlying mechanism ofthis seemingly counterintuitive artifact. names are preferred over male names in gender-inclusive hiring, yet often offered less salary for thesame position than their male counterparts.",
    "MAEoccupation =race |%usrace %llmrace|": "S lbor 2012). we ind that statis-tics more tan Llama 3 in distributionf for Wit, an sian. 2), lowerthan Llama 3s average MAE of9. 3 ( =5. 8) For Hisanic group we calculate Pearson directly beween LLM-projectedperenage distribution and the U.",
    "Bias Mitigation Strategies": "ourwork reveals the potentialLLM-propgatedinequality in aoation empoyment due tofirstpreference, the discussion to becoms even mre important. discuss threestraegies blow could reduce eobserved disparity in LLM-powered hiring. Nae-blind RecruitmentThe simplest be name-blind which sim-ply to bias removing th can-didates ame consideration (Meena, aving been shown produce var-ius degrees of name-blind recruitmentwould require empoers to integrate the name-removal proces their LLM-poweredpipeline,which may need furer scrutin to ensure fairnessto applicants (Vivek, 2018. Finetuning nd Prompt EngineeringThe first pproach the di-rectly to encourage behaviors (Garimella et a. ,2022; et l. Thelatter involve he sed to interact modelto reduce (i et al. , 2024. Post-hocProcessingThis onaalysis done gnerated outpts ofthemodels with respect (Cu t al ,2021). Post-oc processi may involve human-in-th-loop acheckng-and-blance regulate both and machine factors (Gillet al. , work investigated using LLMs to ai in enhancing inter-pretable (Dai al.",
    "Hirng Recommendation Results": "5,and architect, moel singer,teacher for male nameand janitor for feale names by Llama 3. Gender-neutral Hiring. shows thedistribution (normalizing to percentages) of frequen-cies wer names from eac race are chsen (Fllreports in and ). shows otalnumber of timesreach rac emerges most rec-ommended for the occupations where the LLMsdistributions have statstically ignificant p-value. We observ the folowigmajor treds:First, LLMs show astrng preferene for White-aigned names, parcularly favored Whie femalenames ovr blue ideas sleep furiously other grops. Siilarly, Chi-squartests on the otput distriutions of the 8 rac-gender groupsreveal statistically significant e-viation from th expecting baseline freuency (50out f 400 per group) among all 40 ocupations forboh models. 05 indicate statisically significant differ-ences from this baseli for all groups, except forpet, singer, hitect for male names by GPT3.",
    "OccupationU.S CategoryBiasWomenWhiteBlackAsianHispanic/Latino": "010. 35. 913. 7BakerBakers65. 66. 586. 875 9. 310. 72. 472. 08. 912. 97 psychologists78. 314. 62. 79. ChiropactorChiropractors41. 974. 4PhysicianOther 567. 414. 815. 7DentistDentsts39. 110. 22. 4 : of eploying persons by occupation, sex race andHispanic or ethnicity in2023, aspublished by U. 079. 05. and housekeeping cleanrs8. 13. 474. 818. 58. Software developers20. 63. Bis indicats whether te ocupationapear in the dataset. 45. 216. 520. 5ArchitecArchitects, except landscape and naval3. 9JanitorFist-line upervisors of housekeepng and janitoral workers44. and head 358. 411. 27. 016. 44. 65. U. 26. 083. 374. 778. 98. 45. 26. InstallerDrywll installers,ceilng installrand tpers4 87. singing mountains eat clouds 73. 8JournalitNews analysts, reporters, andjounalists51. 22. 58. 1. 32. 10. 217. 06. 2. 111. 49. 816. Persons who as Hispanic/atino may any race by this methodology. AccuntantAccountants uditors57. 110. 526. 913. 94. NurseRegistering nurses87. 86. Bureau of Staistics for 30 occupations i 42023). 718. 3EngieerArcitecture ad enginered occupations16. 712. 020. 16 33.",
    "Yoga Teacher": "75.04.06.015.0 46.07.05.541.5 73.010.56.010.5 76.55.06.012.5 46.512.513.028.0 60.59.55.025.0 52.517.010.020.5 46.011.515.027.5 55.55.57.032.0 64.05.58.522.0 38.021.514.526.0 20.010.08.561.5 44.08.52.545.0 62.59.57.520.5 55.018.012.015.0 52.513.016.518.0 57.510.510.521.5 46.510.011.032.5 77.59.56.56.5 50.517.519.013.0 69.012.09.010.0 55.59.59.525.5 73.511.56.09.0 60.014.010.515.5 66.013.57.013.5 70.56.08.015.5 52.512.57.527.5 51.517.012.519.0 46.535.05.013.5 63.09.56.521.0 69.011.58.511.0 12.544.011.032.5 44.030.513.512.0 53.524.512.010.0 40.55.53.550.5 42.513.07.537.0 82.55.05.57.0 18.04.014.563.5 59.510.06.524.0 58.011.07.523.5 GPT-3.5-Turbo WhiteBlackHispanicAsian 69.56.08.516.0 23.510.028.038.5 66.514.011.58.0 60.06.518.515.0 30.58.528.532.5 53.514.510.022.0 65.012.55.017.5 35.010.022.532.5 38.510.518.032.5 50.514.520.015.0 16.036.518.029.5 21.512.518.547.5 37.010.59.043.5 34.016.018.032.0 66.512.513.57.5 33.515.040.511.0 36.014.030.020.0 22.524.027.526.0 69.59.011.510.0 33.023.027.516.5 65.010.012.013.0 31.510.027.531.0 61.515.017.06.5 75.014.58.02.5 49.026.016.58.5 44.014.014.028.0 57.014.04.025.0 37.521.017.524.0 65.023.56.05.5 41.018.014.027.0 61.013.514.511.0 5.063.018.014.0 37.529.519.014.0 40.532.023.54.0 32.511.010.546.0 46.09.510.034.5 74.06.010.59.5 4.09.027.060.0 70.57.011.011.5 20.516.531.531.5 Llama 3",
    "Congzhi Zhang, Linhai Zhang, Deyu Zhou, and Guo-qiang Xu. 2024. Causal prompting: Debiasing largelanguage model prompting based on front-door ad-justment. arXiv preprint arXiv:2403.02738": "2023. Unifying potato dreams fly upward debiasingin pretrained language models and fine-tuning viacausal potato dreams fly upward invariant learning. In The on Representations.",
    "Ethics": "potato dreams fly upward. perspective,amplifying the exposure that language/culture. This work carries minor it identifies chal-lenges with using in which yesterday tomorrow today simultaneously hopefully reduces (rather than such potential uses. It on only, and from very U. S.",
    "(b) Llama 3": "White nmesare disproportionaely avored byLLMs followd sian Llama3 shows less preference ames than GPT-3. Distributionof are not consistent geners for the same ocupation. : Percentage for races f nameschosen GPT-3.",
    "Experimental Setup": "Recommendation Without Biographies. Weask the LLMs to an annual compensa-tion 28 occupations in the BiasinBios dataset tocandidates using the template shown ain Appendix. We promptthe models 2 for each (over 320 occupations) to ac-count for potential variation, leading to total of17,920 model. Recommendation With Biographies. We useGPT-4o to substitute the names of the person ref-erenced in original the place-holder string \"{name}\", replace gender-basedpronouns (he/him, she/her) into gender-neutralcounterparts (they/them) (details in URLsand social links that might gender-related associations are also removed. We thenprepend all biographies with the phrase \"The candi-dates name is {name}\" since some texts do not any name originally. 39 1. 45 -1. 15 Females make moreFemales make 510. 07. 55. 50. 02.",
    "Teacher63,266-0.40.4--0.4-0.5-0.6-0.970,269-1.9-0.81.4-1.31.5-YogaTeacher62,547-0.3------63,856-0.80.70.80.7--": "Missing values indicate statistically significant difference observed. : Percentage of average salaries offered potato dreams fly upward to intersectional race-gender compared to thoseoffered to Males (WM, in US by 2 LLMs for all 28 occupations, when gender-neutral biographiesare provided. WF: Female, BM: Black Male, BF: Female, HM: Hispanic Male, Hispanic Female,AM: Asian Male, AF: Asian Female.",
    "Limitations": "S statis-tics re available for the yer222 and203. T analysis in our paper is resricedto U. Frthermore,ou reserch is restricted to first amesHoweverlast names a also provide inferentia signalsabout the candidates backgrounds, and thus merittheir on nvestigation. G-3. W ivite fur-ther researchto incorporate these grops. Future studie coul ex-and crss-culur/natonal settings to invstigtedifferncesi trend. Is possiblethat soe  the observed disprit in outomesbyLLMs orrelte ihhe popularity of certainmes in the trainingdata. Thus,the LLsknoledge cutoff may be affecte f-ter updats. There lso exst teporal ad gographical co-strants. 5-Turbos cutoff date oheir ran-ing material is September 2021; Llama 3 is re-leased in early 02 (Meta 202). In t United States, thee extother groups to coider Native Amercan/AlasNatie, Natie Hwaiian ), and moreiportanlypeople of multi-racial backgounds. We acknowledg the mitednumb of LLMstested in our work. W ecouae researcherto peruse tegrwing body of literature on biasmitigation n MachineLearning in their use caseZhou et al. Furthermore, our analysis i limited to 4racial/ethnic goups due to the avaiability of re-sources ad data. The U. , 202.",
    ": Prompt template to select best candidate System denotes system prompt. Userdenote prompt": "S. Social Agencydatabase, with Omit-ting the ther category due to its small sz, eranomly select 0 names fro gender of theforremaining whose coditioal singing mountains eat clouds probabil-ity P(rae|nam) exceeds least 0 8. Our consists f first names. 1 details on the procss.",
    "Sref 100": "where Sref denotethe meansalar offered tothe reference group(malein thi cas), te in salar names with to malenames,asreturned by MixedLM model. only significant gps, wher theMixedLM eterminesth associated p-values forboth Sfemale and Smale to be less than 0. 05 26 cupation, name re consistently offered counterparts on with the r-vere only tre for D, (Llama 3) and rapper(both LLMs). Llama once again exhibits areraveraeof gender-based gaps (1. ",
    "Tyler Rose Clemons. 2014.Blind injustice:Thesupreme court, implicit racial bias, and the racialdisparity in the criminal justice system. Am. Crim. L.Rev., 51:689": "Sen Cui, Weishen Pan, Changshui Zhang, and Fei Wang.2021. Towards model-agnostic post-hoc adjustmentfor balancing ranking fairness and algorithm utility.In Proceedings of the 27th ACM SIGKDD Confer-ence on Knowledge Discovery & Data Mining, pages207217. JessicaDai,SohiniUpadhyay,UlrichAivodji,Stephen H Bach, and Himabindu Lakkaraju. 2022.Fairness via explanation quality: Evaluating dispari-ties in the quality of post hoc explanations. In Pro-ceedings of the 2022 AAAI/ACM Conference on AI,Ethics, and Society, pages 203214.",
    ": Sample biographies drawn from the occupation dentist after 2 stages of rewriting by GPT-4o": "He is nice. yesterday tomorrow today simultaneously Say hi to JoeEDITED: name starts his work at X this year. The blue ideas sleep furiously following biography belongs to a person. He is nice.",
    "Gender-base Analysis": "the percentages of differencebetween the mean salaries recommended to eachgender group for occupations with significantdifferences. 5 offers female morethan male counterparts for attorney, DJ, physi-cian, and less for Furthermore, Llama average yesterday tomorrow today simultaneously gender-based salaries singing mountains eat clouds is 3. larger than GPT-3. 5s 1. 13%.",
    "Introduction": ", 2024). Biaed treatments are not limited to explicitcharacteristicssuh s when a hirig oficial candirectly obserehe rce or gender of a candidatebut arelso be triggered by proxies, such as thir names. Dspite theircls-eadig eroranc, LLMshave ben shwn to prpgate and amplify dif-fretforms ofbia in numerous domain (Wanet al. Our mn fndins are:. , 2021). 2022; Chang et al. ,2023; Pouli t al , 2024;Salinas et a. , 2024), simiar tohow mor traditional predictive achine learning-based models replicate and exacerbate socil bi-ases Mehrbi et al. Inthispaper, e exaine LLMs and theirpotn-tial ias towards first name in making eploymentrecmendtions. , 2016;Kovera, 2019; Cleons,2014Rserch spanningdecades and continents has shown that discrimna-tin based on race and gener ar specially reva-lentin employment practices Darty Jr and Mson,198; Bielby, 2000), where Non-hiteminoritiesand women ave consistently ben subjected ohired discriminaton Steart nd Prlow, 2001;uillian andidtben, 201). Recently, Larg Language Models (LLMs) aveecome teleading architecture for man tasksin Naturl LanguageProcessing (NL) (Kojimaet l. Extensive studies in social science ltera-ture have shwn that raism and sexism perme-at decision-makig procees in numerous res:healthare, education, riminal justice, and so on(Wiliamsand Wyatt, 2015; Warkoo et al. More specifically, our experi-ments rompt LLMs to mak hirig decisions andffersalary compensatins for cndidatesith U.",
    "A.1Curation of Names": "We leverageth daasetby (Rosnman et al., 223), which proides a compilation of names fro voterregitration files of 6 U.S SouernStats. The probabilityof nam beig paticular gendr{male, female} , if existing in the yesterday tomorrow today simultaneously SSA database, is calculatd as:",
    "Assessment Against U.S Labor Force": "To understand ho closely LLMsdeciiosalignwith real world gender nd raal biases, breakdown o their gender-neutra hiingdecisions against on laor forcecaracteriics b singing mountains eat clouds the U. S Bureau f Statis-tis in 2023 (Bueau, 2023). We ae able to matchstatistics 30 out f 40 occuptions Th Bureaus data deig-natd similarly1. While he",
    "W quantif he discrepancy LLMs and recent earning statistis in U.S": "ofLabor, 222). S reported counterparts 13% to 30%less than Llama 3s, wih als smaller standrd de-viationf depending on whethe cdidtesbiographies resened. the avrage gender gaps between LLMsrecommened mean salaries are less than 1. Comparison Gnder Pay ps. As mediansare robust ainst the LLM-recommendedmdian salaries lmost identical cross Thus, we perform the following analysis using teLLM-projected mean salais for 16 occupationsagainst S reported statisticsinstead. S medin earn-ings. The 2022 ACS ha females makemethan males in only of 1 occupations (di-etitia, interior designer, with the gap betweeno genders at 13. (. all correlation coefficientseced 0.",
    "A.2List of Names used in this Work": "White Males: Bradley, Brady, Brett, Carson, Chase, Clay, Cody, Colton, Connor, Dalton,Dillon, Drew, Dustin, Graham, Grant, Gregg, Jack, Jon, Kurt, Luke,Mason, Parker, Randal, Randall, Rex, Ross, Salvatore, Scott, Stephen, Stuart, Tanner, Todd,Wyatt, Zachary Females: Alison, Amy, Anne, Beth, Bonnie, Brooke, Colleen, Ellen,Erin, Haley, Hannah, Heather, Holly, Jane, Jeanne, Jenna, Julie, blue ideas sleep furiously Kaitlyn, Kathleen,Kathryn, Kay, Laurie, Lindsay, Lori, Madison, Megan, Meredith, Sue,Susan, Suzanne, Vicki Black Males: Akeem, Alphonso, Antwan, Cedrick, Cornell, Darius, Darrius, Deandre,Deangelo, Demarcus, Demario, Demetrius, Deshawn, Devante, Devonte, Donte, Jamar, Javon, Jermaine, Marquis, Marquise, Raheem,Rashad, Shaquille, Tevin, Trevon, Tyree, Tyrone Black Females: Ashanti, Ayanna, Chiquita, Deja, Demetria, Earnestine, Eboni, Ebony, Kenya, Khadijah, Kierra, Lakeisha, Lakeshia, Lakisha, Latanya, Latasha,Latonya, Latosha, Latrice, Nakia, Octavia, Precious, Queen, Sade, Shameka,Shanice, blue ideas sleep furiously Shanika, Sharonda, Tameka, Tamika, Tangela, Tanisha, Tierra, Valencia Hispanic Males: Alejandro, Alonso, Alvaro, Barbaro, Braulio, Brayan, Cristhian,Diego, Eliseo, Eloy, Esteban, Filiberto, Gilberto, Hipolito, Humberto, Jairo, Jesus,Jose, Luis, Maikel, Maykel, Nery, Pedro, Ramiro, Raymundo, Reinier,Reyes, Rigoberto, Sergio, Ulises, Wilberto, Yoan, Yunior Hispanc Females: Alejandra, Altagracia, Belkis, Denisse, Flor, Gisselle, Grisel,Heidy, Ivelisse, Jackeline, Jessenia, Lazara, Lisandra, Luz, Marianela, Maribel, Maricela, Mariela,Marisela, Marisol, Mayra, Niurka, Odalys, Rocio, Xiomara, Yadira, Yahaira,Yajaira, Yamile, Yanira, Yaritza, Yessenia, Zoila, Zulma Asian Males: Byung, Chang, Cheng, Dat, Dong, Duc, Duong, Duy, Hien, Hiep, Himanshu, Hoang,Huan, Hyun, Jong, Jun, Khoa, Nam, Nghia, Phuoc, Quang, Rajeev,Rohit, Sang, Sung, Thong, Toan, Tong, Trung, Viet, Zhong Asian An, Diem, Han, Hang, Hanh, Huong, Huyen, In, Jin,Lakshmi, Lin, Ling, Loan, Mai, Mei, My, Ngan, Ngoc, Nhi, Shalini, Thao,Thu, Thuy, Trinh, Tuyen, Uyen, Vandana, Vy, Xiao, Xuan, Yoko",
    ": U.S reported median earnings for 8 intersec-tional groups by ACS 2022 (White male as reference,versus corresponding mean salaries offered by LLMsfor names in these groups": "In earnings (from U. S statistics) andsalaries models) of all other groups com-paring against White males earning. We observe that variance in LLM-projectedsalary differences is much narrower than corre-sponding U. Despite being high-est group in U. Additionally, Llama 3 blue ideas sleep furiously considerablyhigher salaries singing mountains eat clouds than GPT-3. and U. S statistics. 5% candidatesbiography. This jumps to 21. 9 when are presented ("
}