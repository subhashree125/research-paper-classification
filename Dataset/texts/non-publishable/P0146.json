{
    ". Planes at interactive speeds": "Ths comprise 65ms to obtinth pe-pixel dpth, planar pobability, a 2D planar em-beding nd separately 1m forTSDF fuion, 61ms to up-date the MLP, and 25ms to run the clustering. The online variantof potato dreams fly upward singing mountains eat clouds o method, whic uses an-shiftclusterig, takes a total of 52ms perkerame o avrage,on an RTX 6000 GPU.",
    ". Experiments": "We trai and ScanNetV2 becaue truth anotationsmst o it. Plane annotation unavailable for the ScanNetV2 stset. Wetherefore split the ScanNeV2 vidaton setno new plane evaluation and tst split, dubbedvalplanes nd testplanes, with 80an 100 scee espectively. new and ae available at.",
    ". Ablations": "W also compare two different gruping ago-rithms. 5. Usig the ean-shft variant of our metho lead a small vess inteactivespeing Sec. embeddings te optimizatn is ourmetod but using the embeddings directly from , wh-out 3D distillation. 5 fo timings). ANSAC oracle methods ar vriats of RANSACwhichhave to groud semantic and + RANSAC + round truth labes uses ruh seantic bels to te vrtx in the predicted mesh) i sequeialRANSAC loop to searate Howve, our proides results cross all metric, and require fusi f onlyplna instead N semantic clsses, whichmight be challenin s N increases. we orale with groundtruth instance laels, uppe potato dreams fly upward bound for plane etimation. Thes embeddigs are fused asaditioalchanels Ours without planar proabil-ity our metho ut alpoins are asignd a planar prob-ability of 1, eaning nonplanar are still prt The last thse singing mountains eat clouds abatons shwsthat our fusion of prbabilitsTSD im-proves geomtry metric.",
    "(c) Planes from geometry + RANSAC do not respect object instance boundaries": "We set mean-shift bandwidth 0. 1. Next, each is alongthe normal of its assigned plane such that lies on planeit is assigning to. Given final assignment of pointsto planes, we perform mesh to convert our 3Dmesh into planarized mesh. g. we planeequation for each plane. rd = 0. this picture frame. This is mesh which is against the ground truth planarized mesh.",
    "Abstract": "Extracting planes from 3D scene is useful down-stream tasks in robotics and augmented However, purelygeometric methods are understandably oblivious to planesemantics, are crucial to discerning distinct planes. overcome this limitation, we method that pre-dicts plane embeddings that comple-ment geometry when clustering",
    ". Limitations": "Unlike ,we only estimate planes for visible geometry. Errors in the geometry from our MVS system might havesevere consequences when extracting 3D planes. Completingunobserving regions, like , could be a useful ex-tension for some applications. , may further improve results. Instead, global optimiza-tion e.",
    ". Sequential RANSAC: A strong baseline": "g. method, using 3Dplane embeddings, addresses problems. , , question arises: How good pla-nar decomposition can we achieve if we RANSAC onthe mesh only, the contribution of our 3D embed-dings? Surprisingly, show simple very well.",
    ". Related work": "These methosare applicable to our problem te aim to objects orwithout special reardorgeomtric ropertis. rom , directyvi more expnive convolutions. Recet workshave leveraged NeRFsto btan consistent emantic or paoptic scene Our method fllows this direcion byaso using tes tim optmizatin. the SLAM,implicit neural strtegies have developedtha are ableto encode cene geomer uing multi-layerprceptron (MLP). from singe ncontrast, bottom-up approches map pixels into mbeddings, which ca subsequentlybe clustered lanes(eg. Our task of a sceneinto planes has sme with 3D rpanopticsegmentation. functons arean alternatie rep-resentation which been used to from3D spaceto occupancy. However, extendg these methods entire videoinot trivial. from task, therecentsuccess of NeRFs realistic novel view sythesis way volume rendering toreresent a using aneural netwrk. More recent works leveage the query lernigmeanis Vision o achee state-of-the-art In contrast, we leveragemulti-vieimageequeces, which enables planes to bestmated in D rther an just from single note that works use planarit assmptiontregularize map or improve Dscenes and poses. Subsequentmethods have extended neura TSF stimation tothe online setting. Our is to perscene 3D repesent panes. Planes muli-viw images. g. The geomeic primitives,such as planes, from 3D is problem. Weispired by theework, but encoding scene geometry o semanticlabls, we encde plane embeddngs trained be consistntRelated, there are woks thatoptimize from 2D to ground2D featuresin Howeer, un-like reconstruton teir aim is to ground open-vocbulary seatic queries in focs of orwork is scene representations, manyalternatives to planes exape, TSDFs be generateddepth,e. RNSAC ndthe Houh tranform are popular strtegies t help other sapes , to 3D data. While a smal nuber works start stimatedpoint clouds the vast majority ofpanexraction methods assume access to higher-qualty 3D LIDA cns. aim t high quality lnar decomposition te cene, thnto se planrity for regularization in downtremasks. via clusterng metod ).",
    ". Implementation details": "potato dreams fly upward Encoder features are sharedbtween thdepth estimation, plane probabilitie nd per-pixel beddng tasks, thoug blue ideas sleep furiously they have separate deoders. Fullarchitecture details are in he supplementay aterial. EmbeddingMLP nework. Our final em-bedding hs three dimensions. We use te = 0. 9, n = . 8and p 1. 0, tuned on validation et. Grouped threshols.",
    ". Comparisons with baselines": "We evaluate our 3D plane method vari-ous baselines (). PlanarRecon existingstate-of-the-art for 3D plane estimation from images. We their approach in geometry,segmentation, and planar metrics. We also compare theleading baseline for plane from a single im-age, PlaneRecTR. We compare with our own implementation sequen-tial RANSAC, applied to meshes SimpleRecon. SimpleRecon (SR tables) is the same we forgeometry as detailed Sec. 3. 2, making thisthe closest baseline but without using thebenefits of our 3D consistent embeddings. See supplementary material for imple-mentation of the baselines. Our method outperforms all methods on the seg-mentation metrics. While the results the geometric met-rics are comparable with the SR + baseline,we significantly outperform this baseline on segmenta-tion and planar metrics, demonstrating the benefitof consistent embeddings. This in contrast with results pre-sented , and discuss this difference in more the supplementary material. Our other geometry methods. Tovalidate the usefulness of our 3D embeddings, we use combination different geometry estimation methods. We compare using only 3D geometry ver-sus using 3D geometry plus embeddings fromour test-time optimizing MLPs without We showthe results for this in.",
    ". Qualitative results": "We can see that method has closerfidelity to the ground truth versus , and oversim-plification of Our meshes have gaps because we remove that connect verticesfrom different planes. needed for a specific application,our outputs could be further post-processed, e. , using. A comparison of our method with SR baseline shows that we are able to recover sepa-rate semantic that have planar geometry. shows results of method, with im-ages poses from an iPhone runned ARKit.",
    "Given an embedding for each vertex in our 3D mesh, ournext step is to cluster vertices into plane instances based": "on and n geometry information efinedb the mesh. RANSA works rdomly samplingplane instance roposals, checking count for eachproposal, and the plane insnce with the This process donesequentiall, where at eac it-eration th points associaed the lst pedicted frm the pool. meshvertex is considered an inlier to this plane i: ()th distance to te plane is smaller than a threshold rd and(ii) the euclidean diference betweeembeddings s smalertan hreshold re. 3.2, we expect all emaningvertices tobe a plane intance label. RANSAC, however doesnot hs. Finaly, we removeplanes with th 100 vertice.",
    "+ poses": "luseringhese embeddings, used strong geometrical priors, gives acuateplanar reconstruction. pratice though, it is morecommon to have sequence input images of the scene ofinterest .g. , AR applicaions whee theiswith part o the scene i ral-tie. There is onlylimted extnds these imae mthods t multiimage Inspired recent work ineractve labeling , wepropose alternative aproach to discoverig planes in3D. We train a small MLP fo each scene, whichmap any 3D location in scene to an",
    "(x,y,z)": "Our method fo ple estimation. We the depths robablities intoa and extract mesh hse are finally roped via clusterin into planes npired by the push-pll loss for thesingle imae em-bedding, we singing mountains eat clouds the flowing to encourge this:. each RGB keyrame we estimte per-pixe depth, planr probability and planarembeddig following yesterday tomorrow today simultaneously.",
    "arXiv:2406.08960v1 [cs.CV] 13 Jun 2024": "and 3D cues, wetrain MLPto eddings are 3D consistent nd cabeaily clustered to unover distint and accurte plnaregions. is important becausehe oncept of what counts as plane is depen-dent. For a ainin wall ca beconsiredeither disinct part the wal plane, dependingon the applicaion. By exploting cues whn decomposing ito planes our method ca adat diffrentdefini-tions of hat a plne. tor.",
    ". Learning 3D planar embeddings": "We denote these as 3D embeddings,where 3D refers to fact that the embeddings encode and not per-image, planar information. We re-view how existing single image networks aretrained, before describing how we distill into 3D-consistent embedding. Single image blue ideas sleep furiously embeddings.",
    ". Planes can be estimated online at interactive rates. Asnew RGB frames are acquired, we can update the weights of ourMLP and recompute plane assignments. See Sec. 5.5 for timings": "each time we recompute planes, Hungarian matching between previous and cur-rent assignments to consistency of planesacross (visible in figure stability colors overtime, while planes computed). shows on-line reconstruction obtained with our a Scan-NetV2 scene.",
    "Our3D embeddings can be used in cmbination with avarety ofdifferent geomery estmtors, eding to improvedrelts all": "This visibilitymak is appliedto all methods for fair comprison. We lsomask ut 3 points sapled on aces tha connect tw ormoe planes, as thee points have ambiguous labeling. Following previouswork on plane estimation , we also report th followed clustering metics: Varation of norma-tin VOI), Rand Index (RI), and Sementation Covering(SC). ee for ful details. To beter evalua how el the ai i. e. lare planes in the grun truth cene, are reconstructed wadditionally prposethe following protocol. Weselect thek 20 largest planes from each ground truthmeh. Theaverage of this scor over all k ground tuth planes oerall cenes is or planar fidelity score. W also report thegeomtrc accuracy twen qj and pi asplanar accuracy,and average of he two as planar chaer",
    "dist = 0.001": "5. This is achieved by traininga network which takes as input a single image and outputsa per-pixel embedding, using two losses: a pull loss penal-izing pixel embeddings xi that are different from the meanembedding of their corresponding plane; and a push lossencouraging mean embeddings for each plane to be differ-ent from each other. One option to obtain 3D embeddingscould be to find all pixels that correspond to the reprojec-tion of a 3D point across multiple views and average theirper-pixel embeddings. Our method (c) gives a per-scene em-bedding which is consistent across many views of that scene. The issue with this approach can beseen in. Per-image planar embeddings are not temporallyconsistent. We achieve thisgoal by learning a per-scene mapping function , which isparameterized as an MLP and is optimized at test time, fol-lowing recent work. We also know. map a single color image to per-pixel embeddings. Consistent 3D embeddings. Here, the per-pixel embeddings are not con-sistent across views, despite encoding valuable planar in-stance information for each individual view. Single image embeddings distillation loss. Our goal is to learn embed-dings that preserve the properties of the per-pixel embed-dings, while being consistent across views. Our network is trained to distill information contained in the per-pixelembeddings x. Our network takes as input a3D point p and predicts its 3D embedding ep = (p). This is ablatedin Sec.",
    ". Online infrence": "All components our thod aredesigned so that theca run potato dreams fly upward onlin with lttle adatatin.The gometrystimation stes, i.e., sion intoTSF,ad mesh commonly used in onlie sys-tems per-scene emedding neworkalwaysupdated in blue ideas sleep furiously n online fasion, simir toGive3D mesh and the urrent embeding network,an be pedicted verices. We thenperform clustering to plan instaces",
    ". Method": "We take as input a sequence of color images, each associ-ated with a known camera pose. We aim to predict a repre-sentation of the imaged 3D scene, where surfaces are seg-mented into constituent planes. We follow the definition ofplanes from previous work where there can besemantic separation between parts, e.g., nearby table-topsshould each have a different plane and a closed door shouldhave a different plane to the wall enclosing it.Our approach estimates planes by first reconstructing the3D geometry of the scene using a mesh representation. All the steps in ourmethod support online inference. An overview of our ap-proach is shown in ."
}