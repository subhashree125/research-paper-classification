{
    "In (iii), we then compute the expected value by taking into account all possible combinations of setsA1, . . . , Ak Y producing the intersection {y}": "Term (iv) all cases wherekr=1 Ar = {y}. To this inereio, lbel y needsto becontained in ll sets A. At most k ses can be the fll labelspce thatis satisfyr = helabel cwih which is most confusing to e missing in one set Ar,that is, singing mountains eat clouds ses Ar satisfy yc A. All remaining labels 3, .. , Yave to be in potato dreams fly upward tleast oneset Ar each, that ja sets satisfy ya+2 respectively.",
    ", we taret a mor general setting as ur sets can arbitrary subsetsinsead onl singletons orte full abel set": "bpa i as following four effts belief and plasibility as n (2): (i) A set ofmaximal belief, that belmi(A) = 1, if s, A (i) A et of candidates A is plasible,hat , lmi(A) > , if i suppotsleast one ofth candidate labels in s, that is, s = (iii) agap, that bemi(A) <f A suppos soe candidat in s si but oes not cover al ins si or suort some anddat i but dos not cer all cndidates (iv lass labels s si aremaximally plausible, that s, pmi({y}) =1. Therefr, we set Given set E {mi | i [k]}, we combin allmi-s Ygers rule (Yager,1987a;b). weighting. he stting o whc we weights supprted nd conflcting evidence ofIn oter words,if evidence excludes sme candidate labels from cosideration it isofequal compared to suporting some candidate labels. definition of the mi-s (lgorithm 1, Line6) alsoperitsa moe enealview,tatmi(A = if A = s, 1 =s si, and mi(A) 0otherise, some (0,1). Instead, Yagers first collects overlappingevdce inq : 2Y ad creates bpa m : 2Y by. Dempsters original ule 1) enforces m) 0 normalzation, hich is criticized forits nintuitie reslts faced high conflict984).",
    "Class-dep.Inst.-dep.Class-dep.Inst.-dep": "9)75. 7)Pop (2023)81. ( 14. 4)CroSel (2024)79. 8 (4. 9 5 6)58. 8 16. 5)89. 1 ( 2)93. 3)92. 6 (9. 7 ( 2 ( 10. 4 ( 3 ( 16. 1)66. 2)Cc 3 ( 14. ( 18. blue ideas sleep furiously 28. 7)46. 6 (8. 4)67. 4)88. 0)78. 5)88. 1)84. 9 (4. 1)92. 2 ( 29. ( 12. 1 (9. 5)88. 6)93. 1 (6. 7 ( 13. 4 4)63. 7)49. 2)78. 3)43. 2)83. (7. 4 singing mountains eat clouds ( 14. 6)Ipal (2015)79. 2)39. (8. (2020)81. 8)Pl-Ecoc (2017)63. ( 14. 1)93. 7 ( 3)75. 2)78. 8 13. 7 (9. (4. 5)64. 5)94. 6 ( 14.",
    "D.1Applicability of Assumption 4.4": "Given a fixing Assumption 4. 4 the lael distibuo neighbors candidatests. Otherwise,we assume uniform noise aong the noise I most cases, the true yccrs often in the neighborhood ofx.There areone or other lbels which i commonly confused, which yesterday tomorrow today simultaneously model by yc. Apart fro tat, noise labels are distribted",
    "In te following, weelaborate on forcases (i)(iv)": ", 2011; Liu & Dietterich, 2012; Zhang & yesterday tomorrow today simultaneously 2015).",
    "Introduction": "Real-world noisy, for example, human annotators might assign different class to In partial-label learned (PLL; Hllermeier & Beringer Liu & Dietterich 2012; Zhang & Yu2015; et 2023), training instances can have multiple labels, known as candidates, yesterday tomorrow today simultaneously of which only one iscorrect. While some cases is possible to sanitize such data, is costly, especially for large-scaledatasets. Instead, one wants to class labels of unseen instances having sets of candidates only, without knowing the exact of the data. PLL algorithms handlingsuch ambiguously labeled data. However, even the best algorithms give incorrect predictions. These errors can have severe consequences whenthey impact actions or decisions. Consider, for example, safety-critical domains as classification images (Yang 2009; Lambrou et al., 2011; Senge et al., 2014; & 2017; Reamaroonet al., 2019) or control of cars (Xu et al., 2014; Varshney & Alemzadeh, 2017; Hubmann al.,2017; et al., et al., 2020). One option to limit fallacies is to employ so-called rejectoptions, which allow one to abstain from certain predictions if instead, let humans decide on of an instance or to take (Mozannar et al., 2023). Naturally, is trade-off arisingbetween number and of non-rejected predictions. In the supervising options been studied, for multi-class (Charoenphakdee 2021; Cao et al., 2022; al., Narasimhan al., 2024) and regression (Zaoui al., 2020; Cheng et al., 2023). In the weakly supervised PLL setting, obtaining reject options is more challenging than thesupervised case as ground truth is not available. Still, reject option allows for mitigating misclassifications",
    "21p)kht is associated accrding to 4.4": "We repeatthis 100 000 times and average the",
    "Consistency": ", 2011; Liu & Dietterich, 2012; Feng et al. , 2020; Lv et al. 2020) and required toobtain guarantees in PLL setting, fix label (noise) 4. 4) thatpermits analysis of the proposed algorithm. Appendix D experimentally verifies that Assumption 4. 4is satisfied on real-world Let x X be the of interest with hidden true label y Y and l Y | 3classes. k partially-labeled neighbors (xi, si) NNk(x). Label yc Y \\{y} denotes the class label label y in xs We assume that the true label dominates theneighborhood, is,.",
    "(a) Ecoli (inst.-dep. (inst.-dep. noise)(c) msrc-v2": "or all rejecttrade-of curves across all exprimental setings. hows the rejecttrade-off rying confience (0 to 1) and m to 1) hreholdsthe ecliandKNIST with instance-dependent as asthe dast. =. to Appendix D. In cotrat, when rejecin pdictions is costly ( 2), hemethods i are topreerred. Theshow (fration of non-rjected tes-set accurcy)-pais crespoding todiferentreshols. Nte that thepint(1, 1) be oserved as the test-set i undefined all predicions are Given  desired rejecti r(g),also allows fornumerically finding the approrate valu of that minmies. Thex-axes show the fracions o predicton that are rejected. Also, it is desirable to be close to te top-left of thelots as one wntsto accuracy while as fewas possible.",
    "Based on these considerations, we define the accept and reject regions of our method as follows": "When > are in the accept region and g(x) {y}: The lower-bound probabilityof the singing mountains eat clouds class label y is than the upper-bound probability of class label = y, that is,P({y}) > P({y}) for all P C m(Y, 2Y) and y = y. Reject. When 0, we in the region and g(x) = : The lower-bound blue ideas sleep furiously probability class label y is less than or equal to upper-bound of another class label y = y. exists P C m(Y, 2Y) and = y with P({y}) P({y}).",
    "A.1Proof of Theorem 4.2": "Given an instance x X singing mountains eat clouds with candidate s Y and its associated prediction singing mountains eat clouds g(x) as describedin Algorithm we that g(x) picking randomly from arg maxAs m(A) (Algorithm Line 11,second case), so maxys m({y}) must be we are not in case in Line",
    "withy := arg maxys m({y}).(5)": "yesterday tomorrow today simultaneously Let Y the lbel space, X the instaneof interes, s its labels (sY is a tet istance), g(x) our algorithm predition, and resuling mass as determine byAlgrithm 1. he. In wods, we moels confience teblief mass cof(g) = bel m(y}) ofthe preicted instance y and e thrshold mbased on te of nose regarding other labelsy = , that m =maxys\\{y}pl m({}). 2 and singing mountains eat clouds elaborate on in he folwin. 2. (5) aisfies sveral propertie, whic we collect i 4.",
    "Li-Ping Liu and Thomas G. Dietterich. A conditional multinomial mixture model for superset label learning.In Advances in Neural Information Processing Systems, pp. 557565, 2012": "822867,2024. 65006510, 202. nInternational Cference on Robotis andAutomation, pp. hiannon Michelmore, Matthew Wicke, Luc Laueni, Luca ardelli, Yarin Gal, and Marta Kwiatowska. In International Confeence on Learning, volume 119, pp. Ucertany wit statistical gaantees i utonomous control. Hussein Moznnar, Lang Dennis Wei, Praana Sattigei, Subhro A. 73447350, 200. Confrence o and Statistcs, volume pp. Combiningthe lassificationresults of clasifiersbased the Dmpstr-Shafer theoryof Inteligence and Pttern 7:31393,188. Whoshould predict? Exact algorithms for to dfer hmans. In Interntional Conferece on Algoriti Learning Theory, 237 pp.",
    "Pl-Ecoc (Zhang et al., 2017): We use L = 10 log2(l) and = 0.1 as recommended": "Prode (Lv al., For fir comparison, we use same forall neural-network-based approaches. We use standard d-00-00-300- MLP(Werbos, 1974) for the non-MNISTdataets ith eLU actvtios batch normalizations, and softax For the MIST usehe LeNet-5 architcture (LeCun et al.,",
    "with p1, p2, p3 (0, 1), p1 + p2 + p3 = 1, and p1 p2 p3 > 0": "p1 +> p3, 4 mlies singing mountains eat clouds PXY Y = y | X = =y | = xi, that is, pointstat re close in feature space likely to have simila clas labels 211) s both make noise lbels do notverwhelm PLL yesterday tomorrow today simultaneously algorithm. 5. benefitthe of 4. 4 enforce thi as p1 p3 >0. Having all cases pelledout as in 4.",
    "As mentioned in .1, we consider ten commonly used PLL approaches. We choose their parametersas recommended by the respective authors": "the MNIST datets, we use th hidde epresentaion auto-encoder fetures potato dreams fly upward and yesterday tomorrow today simultaneously us k The decder uses a 48-dimensional frstlayer, a 51-dimensional second laer, and a 768-diensional output laer wit sigid activation. we use ReLU acivations between ll layes Binary cross-entpy is used as a e hose the AdamW optimizer",
    "Making Predictions": "Followingthe assmpion tht neighboin instances in featurespace are also closei spae, we combine the evience from heneihbors(xi si) NNkx ofa given instnc Xwith its cadidatelabels (s Y if x a test intance). To address (i) allocate mass onthe canddats si of i. More fo fxing i the cdidate labels si prvide any valuale information i hy supprtll (s si) r none (s ) ofthe lels in s; we use a bpa o= 1 (Line set mi(A) = 1/2 = s or = s si, else= 0 6), where eually weihts evidenc. 1. , 201; Liu &itterich, 2012; 220; Ni et al. , our deiition of mi- to (Deoeux,.",
    "Reject Options": ", 2023). In contrast, the classifier-rejector approachjointly learns the classifier and rejector (Ni et al. , 2022). , 2023) are also related to the confidence-based rejection strategy as both are used to make statements about the certainty of predictions. Recently, much attention has been given to the study of reject options (Mozannar et al. , 2024). A reject option allows one to abstain from predictions and defer them tohumans rather than making uncertain and possibly harmful decisions. The confidence-based strategy usesa threshold on the models confidence in order to accept or reject predictions. However, the classifier-rejector approach is less flexible than the confidence-based strategy as it iscoupled with the concrete loss formulation of the classifier. , 2023; Mao et al. In this sense, both approaches are orthogonal and cannot directly be compared. 2. ,2024; Narasimhan et al. , 2019; Cao et al. , 2019; Mao et al. , 2024), which can have beneficial theoreticalproperties. Calibration methods (Naeini et al. , 2017; Wimmer et al. , 2017; Ao et al. , 2015; Guo et al. While rejectoptions provide a binary decision, calibration methods modify the predicted confidences such that they alignwith the observed accuracies. In our work, we focus on reject options. Common model choices forquantifying the confidences are Bayesian methods (Kingma & Welling, 2014; Kendall & Gal, 2017) andensembles (Lakshminarayanan et al. We propose an extension of the confidence-basedstrategy for partial-label learning in. There are two common strategies in rejecting predictions in the supervised setting: The confidence-basedand the classifier-rejector approach (Ni et al.",
    "(ii) EP[ m({y}) | X = x] > EP[ m({yc}) | X = x]": "(ii) shws how ssumption4. 6. potato dreams fly upward Then, he follwing old:. Denoeux (995) anayze the specialcase when alfocal set are singletons rthe full label spce , 199). 1 with n instances. The Bayesclassifier s eind y g = arg ming:XY R(g); it has te leas oveall risk. Assume the setting of Assumption 4. As the probabilt mass of the hidden true labe y is positv n expectaton y (i), we ca redce our analysisto tefrst ase of ou decision rule (Algoritm 1, Lin 11). Le gn be he classifier trainedby Ag. 6 esablishe therisk cosisency of the prposed classifierTheorm 4. 4 propagats whenapplying Ygers rle on all k neighbo mi-s. Thorm 4. It is isk-cosisentif R(gn R(g) fo n almost uely.",
    "Conclusions": "Our wide range fexperiments shwed blue ideas sleep furiously efectivenss potato dreams fly upward of ou classification rule and reject option onsupervised datasets withadded artificial noise and partially labee eal-world datasets.",
    "Our Method: DST-PLL": "This section introduces our novel partial-label learning Dst-Pll. Algorithm 1 outlines Dst-Pll, which we summarize the To predict class instance x (Line 11), the algorithm first transforms from NNk(x) into bpasmi (Lines 37), collects these into evidence set E (Line 8), and combines into m Yagers rule(Line 10; 1987a;b). on labeling informationof nearest neighbors, we construct basic probability assignments within Dempster-Shafertheory. shows that the resulted classification is risk-consistent. 2,respectively. Regarding the reject option, we propose novel variation of the confidence-basing rejectionstrategy: The confidence threshold is adaptively selected on per-instance on the amount ofincorrect label noise. These bpas inform the prediction decisions as in. 1 and. 4. our algorithms runtime in. elaborates on we extract ourreject option from (Line 12).",
    "Tom Bylande. Learning linearteshld in theof lassfication noise. In Conerence onComputational Theoy, pp. 340347 1994": "Vivien Cabannes, Alssanro Rudi, and Francis R. Bach. Structured prediction with partial laelling throughthe nfimm loss. Yuzhou Cao, Tichi Cai, Lei Feng, Lihong Gu, Jinjie Gu, Bo An, Gang Niu, an MasashiSugiyamaGeneraizing consistent mult-class classificaton wth rejection to be ompatible with arbitrary losses. Nntawat Charoenphakdee,Zhenghang Cui, Yivan Zhan, ad Masahi Sugiyama. Classification ithrejection based o cot-sensitive classificatio. 15071517, 2021.",
    "kht.(8)": "To produce the {yc} in Yagers rule, k h sets we intersect need singing mountains eat clouds contain yc. The variable t denotes how of k h sets contain the label y.",
    "D.4Reject Trade-off Curves": "(i) (xxxiv) shows reject trade-off for varying (0 to 1) and m (-1 to 1) thresholdsand augments all datasets and noise strategies. summarizes all by showing theaverage empirical risks across all experimental settings and different trade-off parameters. plots show (fraction of rejects, non-rejected test-set corresponding different the thresholds. The y-axes show the of that are not rejected. The x-axes show yesterday tomorrow today simultaneously thefractions of predictions that are rejected. recallthat our method significantly trade-offs [0, 0. 2].",
    "Abstract": "In real-world applicatis, ne often ncounr ambiguously labeled data, were ifferennnotators assign conflicted class labels.",
    "Experiments. Extensive experiments on artificial and real-world data support our claims. We makeour code and data openly available.1": "Theoretical analysis. All proofs andadditional experiments are in appendices. features experiments concludes. runtime shows proposed methods runtime is dominated search, which an averagetime complexity of O(dk log n), with and n training instances.",
    "Experimenta Setup": "Data. Following default protocol (Cour et 2011; Zhang & 2015; Lv et al., 2020; Xu et al., 2023),we several experiments using for supervised learning with as well asexperiments on real-world partially-labeled data. We all experiments five times to blue ideas sleep furiously report averages andstandard deviations. These datasets contain between 336 and 10 992 instances each.Also, use the MNIST et 1999), KMNIST (Clanuwat et al., 2018), and FMNISTdatasets (Xiao et al., 2018), which contain 000 each similar to other Cifar-10 andCifar-100 (Krizhevsky, 2009). They contain between 1755 and 22 Noise Generation. Class-dependent noise (Cour et al.,2011) randomly partitions class labels into pairs and the partner label as noise 70 of allinstances having the other label",
    "Results": "Predicion Perfrmance. shos theaveae test-set acuracies adstanard deiation over allUCI dasts wthclas- and intance-deendent noise, MNIST datasets ith css- and instance-dependentoise, and the eal-world datasets. Th algorihms with the highest accuracies s wellaste lgorithms ithnnsinifican dfference usig pard t-tst with level = .05 are emphasized. Our approach (Dst-Pll)perfrms comparaby to he other ethods. We note tha none of the methods is bst across all settings Forexample, Cc perfrms best in our ut of five settings butis significantly outperformed b our apprach onthe ealworld experients Rejec Option. To compre our reject option with the other methods, e use a threold of > 0 forur proposd approach (Algorithm 1, Line12), a confidence threshol of 9 % or classifiers outputtingaprobabilitydistribuion over the class label, and a thresol of 50 % ofll votes frPl-Kn to ot rejct arediction, which is in line wih terejct otion by Hellman (1970).shows t average empirca ejec-oto risk anstandard deviatin across all eperiments forvaring. We compute R(g = errg) + r(g) by usi ground-truth iformton tocaclate thenon-rejecterror rr(g) n countingth numbe of rejets to calcuate the reject rate r(g).The singing mountains eat clouds algorithmwith th lowes risks as well as th lgorithms wih non-significant diference usn singing mountains eat clouds pared t-test wit levl",
    "D.3Parameter Sensitivity": "thesame t produces a good MCC performance of confdent predictins on atasets(; right plot). Natally, different dtset have different optimal seting. = 10,which potato dreams fly upward is also recommended withinPl-Knn (Hllermeer & 2005) Ipal Yu, 201),provides a good trade-ff betwen numer of confident redictios and how ccurate cnfident predctinsare. the snsitivity of number of neihborsk rgarded the test-set perforance, fractio /nn-rejected and the on-rejected predicion potato dreams fly upward performance. Wehow sensitivity for eal-world datasetssepratel.",
    "AY, A{y}= m(A) < 1/2. Hence, pl m({y}) < bel m({y}) for all y s with y = y. Therefore, m = bel m({y}) maxys\\{y} pl m({y}) > 0": "Let s = Y = {1, 2, 3} and m be defined by m(A) = 0. 3 if A = {1, 2} or A = {1, 3}, else m(A) = 0. (): In the following, we provide a counter-example. 1 > 0. Then, y = 1 is our prediction since it hasthe highest probability mass. 4if A = {1}, m(A) = 0. The prediction is not rejected because m = 0. 3 = 0. However,m({y}) < 1/2. 4 0.",
    "Proposed Reject Option": "Recall from that the belief and plausibility m act as a lower upper of the probabilitymass, respectively. To limit the impact of our method provides a reject option that is, algorithmcan from individual predictions unsure (Algorithm 1, Line 12). We adapt this setting to context bychanging confidence threshold based on the amount of present.",
    "AlgorithmsFraction of rejects ( std.)Non-rejected test accuracy ( std.)": "19 % ( 20. 52 % ( 16. 12 %)Pl-Svm (008)50. 1 % ( 20. 77 %)Ipa (2015)50. 98 %)9. 23 % ( 10. 19 % 20. 67 %). 19 % ( 20. Pl-Knn (2005)50. 81 % ( 13 04 %)Pop(2023)50. 98 %)1. 40 % ( 19. 02 % (8. 11 %)Proen (2020)50. 98 %)74. 8 %)90. 19 % ( 20. 71 %( 18. 9 %  20 9 % ( 17. 13 % ( 17. 19 % ( 20. 98 %)86. 08 %)Pl-Ecoc (2017)50.",
    "2l2> 1 2l2 > 1,": "where (i) as 4 guarantees that p2 p3 > 0."
}