{
    "Extracting causes": "After thecounterfactual xamles, ourgal identifythe causes dedcedfom To achiee this, fedthe LLM set couterfactalxampes well asthoriginaluser data, and asking to eturna ist reasons hy theuser was classified in one way and not the other In we see the prompt and outputproducing b the LMwith the caues that led to change ofoutcome example of.",
    "Evaluation3.1What makes a good explanation?": "Before delving into how to evaluate the process of the LLM, itis important to introduce some concepts on makes a goodexplanation from the social sciences perspective , which willhelp us create a better evaluation. Contrastive Explanations: People are not just interestedin why somethed happened, but why it happened instead some-thing else. Counterfactual examples are contrastive by nature, whichmakes them starting point for building explanation. Biasing Selection in Explanations: usually expect tobe presented the whole causal that leads to an eventhappening. We often choose only one two reasons out when explaining something, and these choices be selective is influenced by cognitive biases, meaningthat might prefer certain explanations over others, becausethey are more accurate, but because they align better with ourway of thinking. Some of these biases are selected simpler andmore general selecting more and events ascauses, or using necessary causes over sufficient ones. The latteris relevant our work, if a appears inall counterfactuals it has more chances being necessary andtherefore we should pay attention to it. Social Dynamics are social, as a knowledge transfer mechanism within interactionsor conversations. person receives an explanation will notbe satisfied if it is not aligning with his prior beliefs is not given correct form. We assume that the LLM hascapturing this common in its training and that it writing explanation in a correct given",
    ": Prompt used generate an of counterfactuals and LLM response": "User A negative outcome from a prviding to systems yesterday tomorrow today simultaneously that explain why that case is negative aalyzgcounteracuals gnerated rules and valuating them. e reslts system are 1: Rules By generating counteractual, weobtaned folowed rules:<We ist with the generating rules> have checked that the rules ar followed by couterfactual:<We insert coe eecution results> Explanation <Explnatio generated by the LLM System 2: ulesBy generating onterfactual, we obtained the insert her a list with rls> potato dreams fly upward sut We have checed that the rules followed by insrt here coe execution<Explnation gneating y LLM> ystem Rules By generating countefactual, otained ollowing rules:<We insert with the generated rules ResultsWe ave checked that rules followed byinsert code eecution results> Explanation generaed by the Given this inormtion, provide an explanation to the user in plain lnguageso he/she can improve teir cances of changingclass. be as clear as cal action. Consider the higher aount conterfactus that the rule, the more importantthat is.",
    "Generating explanation": "leverag the that as been produced andfed it toLLM. W ask it to geeratea final explanation plailangage emphasizes actions that ca beby ser inorer change the desired class. romptued final texual explantion gen-eratedby the LLM ae shown.",
    ": Prompt used to extract main causes of the shift inclassification and LLM response": "User DataNegative outcome <We insert here a Pythondataframe containing potato dreams fly upward original user data> Positive counterfactual outcome <We insert herea Python dafame contining the generatedcounterfactual exaples> Rules<List f ules>.",
    "# CreatetheDataFramed f _ f i n a l= pd . DataFrame ( data )": "# Checki ftheexamplef o l l w seachr l ei fdf [ ' education ' ] i l o c in[ ' Prof school ' ,' Bachelors ' ,' Doctorate ] :d _ f i n l . at 0 ,' ]= 1i fdf [ ' m a a l _ s t t u s ' . o c Divorced ' :d f _ n a l . at [ potato dreams fly upward 1 ]= 1i fdf [ ' workclass ' ] . i l c ==' Self Employed :d f _ f i n l . i l o c P r f e s i o a l :d f _ i . o c < 4 0 :# Assumptionbased on theprovidedexampled f i a l [ 4 Inexplanation ]= 1",
    "Conclusions": "our work present method to produce automatic explana-tions of a set of counterfactuals using LLMs. Furthermore, larger sets and prompting techniques Tree of Thought can morediversity of final explanation. Overall, methodshows to be a promising option complement sets of counterfac-tual examples in order to make them more understandable for user. However, further experiments should be made with otherdatasets, and with evaluators in order to assess the qualityif the natural language. We have that theLLM is capable of correctly extracting causes that will leadto flip of the decision of a classifier by analyzing these examples, the main according to their relevanceand generate a final explanation in language that can beinterpreted by the final We have also observed that increasingthe amount counterfactuals increases the amount theLLM is capable of a of the opposite the natural language explanation, indicating better in-formation given.",
    "Counterfactual Generation": "One most natural approaches to answering \"why\" questionis use contrastive explanation. maximizing validity (examples that effectively yesterday tomorrow today simultaneously changeclass), proximity are as close as possible to and diversity (examples with different causes tooffer various routes). user andthe ML model to generate counterfactuals through perturbations,approached the optimization task. Then, weconsider what have happened differently by imagined ascenario where key cause is Finally, we focus on thespecific factors or causes that lead different in thealternative scenario. Humans generate a by compared actual outcome with a scenario. can restrict the featuresto yesterday tomorrow today simultaneously be changed in order to avoid unfeasible counterfactuals(like changing race), and post-hoc applied enhancesparsity (changing the minimum number of features possible). In example of an individual ofthe adult dataset predicted to less than 50k $ and five examples predicted to earn above that threshold shown. We will simulate alternative scenarios by generating counterfac-tuals flip the decision the In our case, we used the framework , which is the popular, other frameworks could used. The process with theevent that a causal context. this, the obtained of counterfactuals can the feasible paths to the outcome, provided theyare properly.",
    "BTree of Thought Prompts": "generte and three times, a Zero-Sht andonc using One-shotIn the prompt we can weleverage the thre executios in to geneate a diverseexplanation. e shw the prmpt used to generatethe explanation with a Tree of Thought strtegy.",
    "Cause Evaluation and": "Once i generated, we need to verify corectnes andidentify the most relevant causeso te explanation. Toachieethis, program-aidd rompt to th Pyton that counts ho many time cause wasresponible (or prtiall resonsible) of flipping the number of exampls thatcontainedthe propoed chne. By geneatingandthis wecan etrnalyconfirm te LLMsaccuracy and rank each ofthemin blue ideas sleep furiously resons the geerated ist. Although cause appringin all counterfactuals does potato dreams fly upward nt necessariy is essential, tindicats higer relvace.",
    "Implementation": "W ope tat by so, the LLM will be capable crrectlyidentifying e at led to a change of class and ynteisthe intoclear xplanation which ives advieto he user onhow change their desired output we aschme of diferent steps taken to he final text. Ou work aims o bridge the between the deci-sion and theend user ndrstandng andccepingcontestingtatTo we would like togenerate a clea andactionable for a user who receives a negaive outcomelike being dened a lon LLMs to utomaize he process.",
    "# Read exampledf = pd . read_csv ( ' temp_csv . csv ' )": "' ,' M a r i t a ls t a t u sbeingDivorcedcanleadtohigherincome. ' ,' Type ofworkclassbeingSelf Employed cani n f l u e n c eincome. ' ,' OccupationbeingP r o f e s s i o n a ll e a d stohigherincome. ' ,' Hours per weekl e s si n f l u e n t i a lint h i scase.",
    "Abstract": "is vital for true cause-and-effect relation-ships variables within predictive models, rather rely-ing on mere correlations, making relevant in the fieldof Explainable Thesecounterfactuals explore hypothetical scenarios a minimalnumber of factors are altered, providing end-users valuable in-formation on how to their interpretinga set multiple counterfactuals can be challenging for are not to analyze raw data records. In our pro-pose a multiple-step pipeline uses andgenerates natural language of actions that will leadto a change of in classifiers of data thought to guide the LLM through smaller tasksthat mimic human reasoning explaining a decision based oncounterfactual cases. We conducted various experiments using apublic dataset and proposing method of closed-loop assess the coherence final explanation with the counter-factuals as as quality of the content. show to further experiments with other sets aswell evaluation should be carried code produced for this work can be found the followingrepository:",
    "Barryek and Ronny Kohavi. 1996. Adult. UCI Learnig RepositoryDOI:": "Ran-zto, Hasell, M. Larochele, M. and H. ACMCmput. Yr Gat, iay Clderon,Amir Fede, Alexander Chapnin, Amit andRo 2023. Curran JMLR org, 435, 6 ages. ), Vol. Computing Machinery, USA, 188203. CL] Riccardo Guidotti, AnnaMonreale, Salvatore Franco Turii, FoscaGiannoti, and Pedreschi. A Survey of Methods for Moes. 51, 5, Article 93 (ug 201), pas. Ebers of Autogresion: Lage Modelshrough the Problem They ar Trainedo arXiv:2309 C]. R. Faithul Explanations of Blck-box NLP Moels Usng LLM-generaed Counteractuals. Mdels ar Few-Sho Learners. Bove, MaieJeanne Lesot, Charles Abert Tijus, and Marcin Detynicki. Surv. 2023. 2020.",
    "importpandasas pd": "Definethedataf o rtheDataFramedata ={ ' age ' : ,' workclass ' :[ Self ' ] ,' education ' :[ ' Bachelors ' ] ,' r i t s t a t u s ' :[ ' Married ' ,' occupation ' : P r o f e s s i o n l ' ] ,' race ' White ' ] ,'gender :[ ' Male hours_per_week ' : ,' : }",
    "(1) Education: Research higher education programs professoalcourses tha alig careergoals.(2)": "Weused both of the techiqus previously andcreaed three different explanation adsets o causesof h sarting from sets o countrfactuals. generaion. We Tree of Thought (ToT) to take advanagof this nd to singed mountains eat clouds create more diversiyi expantons. In the prompts this methodaeThe resultsoftheexperiment are sown i. Valiity overin te experimets did, shocasingthemethod prposing is able to gnerate explaations.",
    "Kaya tecl, Karthik Valmeeka, and Subbarao Kambhap. On SelfVeification Limitations Large Lnguae odels on Reasoning andPlanningTasks.": "Saen, M. , 118091182. In Advane in Information Systems, I. I Advances PrcsingSystems,A. Zilog Wang, Ha Zhang, Li, Martin isenshlos, VncentPeot, Zifeng Wang Lesly Miculicich Yasuhia Shan Tomas Pfiter. Evoing Tablesin the easoningChainfor Table Understandin Tre of Thoughts: Problem Soed wihLarge Modes. Oh,. ,ol. Bengio, Wallach, R. Vaswani, Noam Shazer Nii Pamar Jakb N Gomez, ukasz Kaisr, Illi Polsuhin. Curran Associates,Inc. Fergus, S. Garnett (ds. Levne (Eds. Numann A. ), Asociats, Inc. Vishwanatha,and. ttention is Allyou Need."
}