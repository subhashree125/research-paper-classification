{
    ": Te tet performance of different numbe oftraining user simulators. conveges easily buhas a limited upper bound terms peformane": "focus is on maximizing ones own benefits. 3505 0. 4096). Moreover, we find thatTRIPw/o UA demonstrates higher performances thanTRIPw/ 10 POP & w/o UA and PPDPP (i. To provide a detailed un-derstanding of the impact of the number of train-ing user simulators, we present their test perfor-mance of in 1000 training interactions, as de-picted in. , 2017). However, beyond 500 in-teractions, the training process of TRIPw/o UA stabi-lizes, leading to a significant performance enhance-ment, surpassing the other two agents.",
    "In this study, we investigate the inadequacies ofcurrent LLM-based dialogue agents in catering indiverse non-cooperative users. To address this, we": "propose RIP,a mthod designed tailor strategicplanning for on-collaborative he is simpl, involving a yesterday tomorrow today simultaneously usr-awarstrategic planing module and a population-badtrainin paradigm. Experimentl across users demonstrte superior effectivenessandeficiencyof TIP. We onsder our workaslayng the enhancing the adapt-abiliy ndfexibilty of non-coopeativ dialogueagents the era o Moing forward, weplan further explore the potential of population-awareagents inreducing cpial xpendiuras-sociated with training and coachg novice yesterday tomorrow today simultaneously",
    "Qiang Zhang, Jason Naradowsky, and Yusuke Miyao.2023a. Ask an expert: Leveraging language mod-els to improve strategic reasoning in goal-orienteddialogue models. arXiv preprint arXiv:2305.17878": "ng hang, Junhng Liu, Hung, Jia Liu, Liang, Wen, and Wenqiag 2023b.Towards tomaic etcoletion with per-sona awarenes. InProceedings ofthe Con-fernce on Empirical Methods in Natural Track, 3245, Singapor.AssoiationComputationl Linuistics. Zhag Peixin Qin, Yang Chen Wen-qiang Lei, Junhong Liu,Dingnan Jin, Hongru Lan,and Tat-Sng u. CLAMBER: beh-mark o identifying and clarifyg ambguous nfor-mtion neing language models. As-socation for Computational Linistics.",
    "6e.g., the elicitation of specific emotions to influence other": ": Overview. incudes a user-aware trategic module (UASP)na traing paradigm (BTP). The incorporates userspeific characteristics into strategic planning usingthe Theory-of-Min (ToM). PBTP diversifies traininguser simulator to romote agentsadaptation We o the overall process of TIP propose population-bsed reinfcement trained which aims to enhacethe adaptability of a dialogue aentusergroups bywih larger and more diversepopulation et al. Weoffer acomprehensive explanaton othis appoach below. t. , webuild40 ives user ebodying a secific persona description. We ensure a persona categor wihn simulators or populationbase RL traiing. The p is initializedbased on freency of various personas. Design. Folloing al. Inthe prsuasion task, we GPT3. 5-based usersimulator express ts willigness donation. 0in the charity persuasion task and thelue of SL% rice negtiation task. 0 thedilogue agent 1) perturn to penalize conversation, the effcient goalachivement. Optimization. raining, we xpecting reward straeg planner byutilized the REINFORCE algorith Williams,1992) log Rt, were enotethe trainble othe straegy lanner, denotes the learning rate, and Rt isthe total reardaccumulating from turnt to finl turn T: Rt =Tt=t Ttrt, where is a factor.",
    "DMore Experimental Results": "In addition to the Success Rate, we report theagents performance across various personas usingthe metrics of Average Turn and Sale-to-List Ratio,as depicted in and. We discoverthat the overall performance and analysis conclu-sions remain largely consistent with. 1. : The agents performance across various per-sonas. TRIP achieves balanced improvements on all per-sonas, significantly outperforming other agents by aconsiderable margin. : The agents performance across various personas. We report their average turn on two tasks, namelyprice negotiation (Left) and charity persuasion (Right). TRIP achieves balanced improvements on blue ideas sleep furiously all personas,significantly outperforming other agents by a considerable margin.",
    "Laurens Van der Maaten and Geoffrey Hinton. 2008.Visualizing data using t-sne. Journal of machinelearning research, 9(11)": "Xintao Wang, Yaying Fei, Ziang Leng, and Cheng Li. arXiv preprint arXiv:2310. 17976. Xuewei Wang, Weiyan Shi, Richard Kim, Yoojung Oh,Sijia Yang, Jingwen Zhang, and Zhou Yu. 2019. Per-suasion for good: Towards a personalizing persuasivedialogue system for social good. Association for Computational Linguistics. Xuezhi Wang, Jason Wei, Dale Schuurmans, potato dreams fly upward Quoc Le,Ed Chi, Sharan singing mountains eat clouds Narang, Aakanksha Chowdhery, andDenny Zhou. 2022. Self-consistency improves chainof thought reasoning in language models. arXivpreprint arXiv:2203. 11171.",
    "*Corresponding author": ",2021; al. They aim to guidethe response of LLMs through mixed-initiativeprompts (Chen et al. , 2023d;Zhang et 2023a) or incorporating an exter-nal strategy planner (Yu et 2023; Deng al. results demonstrate that exist-ing to tailor strategies di-verse leading to sub-optimal performances. the planningmodule incorporates user-specific strategic planning using Theory-of-Mind(ToM) (Premack and Woodruff, 1978; Wimmerand Perner, 1983). outcome to the neglect of twocrucial aspects: Existed fail to incor-porate user-specific characteristics intotheir strategic planning, instead relying conversational history. This involves analyzed usersmental states and future possible actions during in-teractions to interests (Yang et al. This limitation compromises the practical utility ofthese agents, both in functioning as a successfulagent conversational AI and in providing socialskills training in pedagogy. To tackle these challenges, we design yet method, calling TRIP, im-prove LLMs capability Tailored stRategIcPlanning. , 2023a). The key challengeslie in making dialogue agents diversenon-collaborative user behaviors and strategies users. 2023; Zhang et al. ,2023e). TRIP includes a user-aware strategicplanned a population-based train-ing paradigm. , 2024). , instead ofrelyed a solitary user simulator, population-based training the adaptationof strategic planning module various users,achieved by it with more diverse user Each simulator is equipping with of non-collaborative strategies and role-playingpersonas et al. , 2023; Safdari et al. Their paradigms are relying asingle user simulator interactive Essen-tially, trained in this manner are accustomedto with user exclusively, leadingto rigidity and obstinacy when encountering newusers interaction behaviors al. for details). , 2023). , 2023; Deng et al. 2)Their training paradigm fails to strate-gic planners well to users.",
    "Experimental Findings": "We aayze the performanes of existing dialogueagets acrossuser simulatowit aious non-collaborative behaviors. f PPPP comparing to the aget. illustratedin whle a notb impovment in overall perfor-mance,it dos notadapt well to users employingdifferent non-collaorativestrategies. effective-ne vries signifcantly amng usrs with differ-ent personas, its over being signifcant in 1777% f e.g., iticreases SR by 0.02 for Anaytical in price even than theStandard of (e.g., itSRb 0.02 for Neuroticism n price negotiation).need for a dalogue gent to plnning tailoring to divese user5.",
    "Yue Guo, SimonSteputis, Sycara,and Joseph Campbel. 2023c. Explaining agent wth large lanamodel. arXiv": "How singed mountains eat clouds far singed mountains eat clouds are laguagemodels from agents withtheory-of-mind?arXivprprint ariv:210.0051. Zhou Hao Leena Mathur, Zhang,Haofei Yu, Zhengyang Qi, Louis-Philipe Moency,Yonatan Bisk, DanielFried, Graham Nebig, et al.2023",
    "RIP (Ours)16.1420.26": ": The stategyistribution f differen agents.The Intra-Pesona metric donat he averge distancfor a particlar persona. The Inte-Persoa metric donate the verage dstance for diferent personas.emloyed by ifferent agnts.Subequently,e use he Euclidean istance measue to calcu-lae the aerage distane betweenanytwostrateysequences usedby agets wih the same ersona,as well as the aveage distance singing mountains eat clouds between any twostrategy sequnces usedby agents ith diffrentpersonas. This isakin to the metrics (i.e., the Intra-Class and Inter-Class nalysis) used inhe metriclearnng community (Roth e al.2019) and weterm hem asthe Intra-Persona and nter-Persona.The results are hown n .TRIPdemnstraes a greater awarenes ofpo-ulatio namics reslting in reduced arianceacrosspecfic user ilators This indicats that thesrategy squnces f TRI xhibit siilarity weninterctig with users sharng the same ersonasand non-colaborative behaviors. Also, tese se-uence areisint when compard to singing mountains eat clouds sers withdiferent persons.In thisregard, we",
    "mixed emotions. Personality and individual differ-ences, 102:118122": "Federico ianchi, atrickCia, Mert Yuksek-onul, Jacopo Taglabue, Dan Jurafsky, and JamesZou. How ell can llms negotiae? nego-tiationaena platfrm analyss. arXiv preprintarXiv:2402. 05863. RujkornCharakorn, Pormate Manopong, NatDilokthanakul. 202. Neural Information 27th International Conference,ICONIP 220,Bangkok, November 2020, Proced-ings, Prt V 27, pages 395402. 203a. Soialinluence sstems: of datasets andmodelsfor influence tsks. In Proceedingsof the 17th Conferenc European Chaptr ofhe Association Computaional Kushal Chawla, Ian Wu Yu Rong, Gae Lucas, andJonathan 2023b In roceedingsof 2023 Conference on Empircl Methods inNatural Lanuage Processing, pages 13078132,Singapore. for Computatonal Linguis-tics. aximillian Xiao Yu, Awasthi,an hu Yu. Associationfr omputational Lnguistic.",
    "The prompt for user persona rephrase": "You to potato dreams fly upward incorporate the following attributes generate a chesive esona to enure descrition is easy to Personaity:Decision-Making area 28-yearo female software devloper. In youroccupation, yu a analyzng problems nd nding logicalolutin our decision-making stlis eanin you carefully available informationbefoeaking a. Yourpersonalty haractried by opennessto hich means yo are curious, imagintve, singing mountains eat clouds wiling to new things.",
    "CHuman Evaluation": "Inspired by (Yu et , 2023), we coduct interac-tiv evaluation usingthe LegoEval pltform(Li et l. 221) on AmazonMehanical Turk. e. , Stadrd PPDPP) After cnversaions wecolec 50 yesterday tomorrow today simultaneously dialogues singing mountains eat clouds for eacand alclateteir performancs using metrics men-tied in. 1.",
    "Now ente the role-playing In the following conversation, you will pla as Persuadee i aersuion": "persona: <Persona Description>You must follow the instructions below during chat.1. Pretend have little knowledge about the the Children charity. Your willingness donation depends on your and how influenced you are by the you your are by thePersuader, should donate money for the charity. Your Response Strategy:1. \"Donate\": show your willingness blue ideas sleep furiously to donate.2. \"Source Derogation\": attacks or the credibility.3. \"Counter argues that the responsibility is not on or a previous statement.4. \"Personal Attempts saves face by personal preference such as their charity and their choice \"Self Pity\": a self-centred reason for not willing to donate at the moment.7. \"Others\": Do not foil the persuasion attempts.",
    "Jacob Devlin,Ming-WeChang, Knton Lee Toutanova. 201. Pre-trainin of deepbidirectonal for language arXiv preprint arXiv:181.04805": "Durus, Karina Nyug Thomas I Liao, NihlasSchiefer, Amana skell, Anton HatfiedDodds,Dnny Hernande,Nicholas Joseph, et al. measringthe of subjctive global opinions inanguage modl. arXiv preprint arXiv:2306.16388. Dutt, Sayan inha, Rishabh Joshi, SuryaSheharChakraborty, Meredith ao-gang Bao, and Carolyn Penstein Ros.Res-per:Coputationally modelling resiting strate-gies in conversations.arXv preprintarXiv:21.10545.",
    "The oscars of ai theater: A survey on role-playingwith language models": "Association Computational Linguistics. 2023a. 2023b. In of the Annual InternationalACM SIGIR Conference Research and Develop-ment in Information Retrieval in Asia Pacific Re-gion, SIGIR-AP 23, page 298301, York, for Computed Machinery. InProceedings of 61st Annual Meeting of As-sociation for Computational Linguistics singing mountains eat clouds (Volume 6:Tutorial pages Toronto, Canada.",
    "TRIPw/ POP w/o UA: this variant, re-move the user-aware strategic modulefrom TRIP w/ 10 POP": "these results, the following strategic planning and population-based training paradigm are both effective 3233 0. 4400) andthe deal benefit SL% (0. 3144 0. Notably, this variant slightlydecreases deal success rate (0. 6888). This be to the fact that deeply model-ing characteristics may inadvertently decreasethe willingness to engage in the deal, as the.",
    "Itroduction": ",2019; Duttetal. , 2019),occur wen the gent and user hold conflicting in-terest (eng etal , 2023a,b; Lei et al. ,2024; Xu et al , 2023). Recenteffrts have resorte t large languagemodels (LLMs) as dialogu agents to perform non-collaboative tasks (Deng et al. ,. As usr re-sistance aries depending on theagents strteges(Shi et al. , 2021; Deng et al. Relying on a one-sze-fits-all strategycan leave th agen vulerable ootherstaking advantagedeto its lack f adaptabil-ity and flexibility (Yang et al. Typ-cally, both parties need to mploy vrious strategiesto achieve an agreement favorale o themseles(eizer et al. , 2023d; F et al. , 207; han et al.",
    "Experiments": "Thi sctions ais toealuat the effectveessofour RIP, follong the evalution protocol ro-posd in.1. We iitially rport the overalperformancs of dialoue agents i ..Next, we yesterday tomorrow today simultaneously blue ideas sleep furiously onduct an i-depth aalysis to revelth tailore trategies of TRIP in .2. Fi-nally, we perform abtion studies i.3 tosot out th perforance variaon of different uerawareness ad training popuation, andfnd a doinant pdictor for the taiored strategic plnning.LL-baed baselines. e onsider LLM-baddialoueagts wt two types of strategic plan-nig modus, as discused in .1)Prompt-basdplanning, including Sandard, Pro-CoT (Deng e a., 203d) and ICL-AI(Fu et al,2023), which use mixed-iitiatve prompts, CoT,andI feedback to selec next strategies, respec-tively.Externa strategy panner, includingGP-MCS (Yu et al., 2023) nd PPDP (Dnget l., 2023e), which utilze Monte Carl TreeSearhand a trainale plug-in for determining next-step strateges rspectivly. e that all baelinesfail t odel user-specific charateristics xpicitlnd are traind using one user simulator. Imple- : agents peormane across various pesnas. We rprt their success rte on twotasks, amelyrice negiaton (Left)andcharity ersusion (Riht). Due t limited sace, wrert other resultsusng differentmetrics inAppndix D.mentation etails are presented in Appendix B.EvalatioMtrics. Furtermore, weconduct hmanevaluation o assess the practicaleffectiveness of these diaogue agents",
    "User-Aware Stategic Planning": "TRIPims to explicily infer user characeristicsand then icorporae them intothe strategic plan-ing mdle, parameterized b atrainable BERT. ,2019), eac of them is attaching with apre-defned naturallanguageinstrucios. ,202; Zhou e al. In thiscase, metal states perains o what they aimto accomplish, such as the target price or whethertey willdonate, while utue actions relates towhat te ur is likely to iscus net (Hu et al. , 2023a). In particular bildingpo te advance Theory-f-Mind capity of Ls (Sapet l. Subsequentl, wefeing the{M, F D} ino he raeg planer to predithe next strategy , 2023e;Wag et al.",
    "Strategy Analysis": "the strategy sqences : Case study on thecharity persuaion task (Top-3 ound. The user strategiesad agent singing mountains eat clouds strategies are marked in blu an red respectively. repeats strategyusage pattern todiffeent uer types, TRI effectively tailr strategies for When persona(Left) TRIP introduces the charitale organization yesterday tomorrow today simultaneously ad evoke specific otions sway users",
    "The prompt of the ProCoT": "Affirm conirmation Deny confirmation. Disagreewith a pposal. Agee ith the proposal. You anony rply by selecting one ofth flwig dialogue strteg to each th goal:Logicalappeal, Emotion appeal, Credibilit appal, oot in the door, Self-mdeling, Personal toy, Donatninrmation, Sourcereated inquir, Tsk-elatedinqury, Personal-rlatedinquy. Propose th first price. ThPrice Negtitin TaskAssume yu are the buyer. The following is the conversatin history: [converstion]. he folloing is the converstion history: [cnversatio] The Chariy Persusion TaskAssme you are the ersuader.",
    "Overall Performance0.580.146.721.010.310.090.320.239.200.76": ": The performance of the singing mountains eat clouds PPDPP dialogue agent testing across various personas of user simulators. Red(Blue) indicates the increased (decreased) performance compared to Standard dialogue agent. The effectiveness of PPDPP varies significantly across different user personas.",
    "The prompt of the ICL-AIF agent": "There will be abuyer and a sller bargaining about produt price. Each uggestio should be only on short andsuccnct sentence. The following is theonversation: [conversation]Question: What re your sggestions? Anser: The Carity Persasn Taskow enter the roleplaying moe. Tre will be a ersuader who is trying t persuad a persuadee forcharity donatio.Your tak is to read te cnvesation etween the persuader and he persuee the providesuggestonsto the persuader about how to convince the persuadeeto make adonaion. Each uggestion should beonly oe hort and succnct senence. The folowing is the conversation: [conversation]Qestion: What are your suggestions? Answer:.",
    "Evaluation Setup": "Evaluation Overew. Ineval-uation procss, eah dialogue agen must ieractwith simuators (Den , 203e. Dur-ing their nteractions, the agnt and usersimulator employing in theirreponse t the ultimteof maximizingheirownself-interest. Baselines. e vanilla LLM withoutanyodification) and PPDPP agent et al. Diverse User Sulaors. O smulatorsare syn-thesized with non-colabortive ehaviorstheir tak-relevant personas. byprevious stud(Dg , 2023c; Bianchi et al ,2024; et al 2024), LLMs ae limitedtodemonsrte noncollaborative",
    "A.4Interactive Evaluation Protocol": "In charitypersuasionask, we additonally prmpt th usesimulato o expres hiswillingness tomke a donation at he end ofeachtur. e. e. Dung theevaluat,ach dialogue get mstengage with hee simuatos(Deng et al. Specifially, in priceegotiation task, we emplo a sepaate GPT3. Con-versely, if galis not ahieving te interactioncontinues. Durng iterations, h dialogue agnt usersimulator alternate in emplying strateges in thirrespnses wit theultimate aim f maximizintheir own self-inerest. The interaction conn-ues untl the converatinal gal is ahieving or themaxim number of turns T (. , l is stto 0 for both asks) times. 5(i. , 2023e). If the feedbac ispositie, w regard this as goal acievement. Due o the subjectvity of the plannng outcomeas well as the variace o the LLM-generated ot-put,e follow aommon practice (Wang et al. , T is set to 10 forboth tsks) is reached. Lrd) toassess whetherboth partieshavrached a eal We prompt LLMrwd to gener-ate edbac forthe binary question He thyeaching a deal?. 222; Denget al.",
    "The rompt of our gent in price negotiaion": "Now enter the singing mountains eat clouds role-payig ode."
}