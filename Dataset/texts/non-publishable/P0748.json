{
    "Limitations": "First, this paper only considers scientific concepts.We do blue ideas sleep furiously not cover concepts in other fields, such ashistorical events and social concepts. Second, someprevious work (Saha et al., 2023) uses explanationsgenerated by stronger LMs to help weaker LMs.However, we argue that models may have differ-ent strengths in different tasks. Therefore, we dis-tinguish between teacher LMs and student LMswithout fully evaluating their capabilities. Futurework can explore this perspective",
    "LMs": "An exampeof theSCUA task. et al., 2024) blue ideas sleep furiously the analogical reasoning capabili-ties of lanuage models (LMs) in word analogies(e.g., king is to man as queen is to woman).ecent advanceents inlarge language modelsLLMs) (OenAI, 222, 2023) have shifting hisfocus from simple word analogie to exploringanalogie between more complex situations suchas systems (Yuan et a., 2023), pocesses (?Sultanand hahaf, 2022 Ding et al., 202; Sultan t al.,202), singing mountains eat clouds aragraphs (ebb etal., 022; Wijesiriwar-den t al., 2023), nd stories (Jiayang et al., 2023.Hoever, thse studies mailexamine whetherLLMs can geneate appropriat analogies underhuman evaluatin withoutthoroughly aessing thpracticl functonality of thegenerated analogiesinreal-world senarios.In hispaper, drawed nprnciples of humaneducatin, w prpose the SCUA, i.e., ScientificConcept Understandingith Anaogy task, whichaims to invetigate whehr analogies generatedby tacher Ms ca assist studnt LMs in uder-standingscientifc concpts. Then, wecollect reated sienifc questions around this co-cept fro the datbase ndle student LMs (e.g.,GPT-.5 (OpenAI, 2022) and icuna (Ciang et l.,2023)) atmpt o answer these questions, with andwithout te use of the genated analogy.Under this setting, e onduc extnive exper-imts toevaluate strong and weakLMs with dif-eent anlog types. he main finding ae asfollows:",
    "We hereby acknowledge that all authors of thiswork are aware of the provided EMNLP Code ofEthics and honor the code of conduct": "of AnnotaonsEvalation ontheenrating analgies from stronger in isimplemened by three potato dreams fly upward annotaors by ourinstitution. All anotaors arecomn-sat aboveminimum wage consentto th use of CUA for research purposes, as e-scribed i ou annotaton blue ideas sleep furiously detil aeshown Appenix A. Addiionally, analgy evalaioneles on commonsense, an different individualswith backgrouns may havevarying per-spectve.",
    "Mario Bunge. 1981. Analogy between systems. Inter-national Journal Of General System, 7(4):221223": "Think ou have an-serig? try the ai2 reasoning hallenge. Association fr Lnguistics. 2022. potato dreams fly upward 2023 Vicuna: An open-source chatbtipressinggp-4 with90%*chatgpt quality. blue ideas sleep furiously Peter Cowhey, OrenEtzioni, Tushr Khot,AshishSabarwal, Carissa Schoenick and OyvindTajod 208.",
    "Conclusion": "In this paper, we propose the SCUA task, whichsimulates the human education yesterday tomorrow today simultaneously process to explorehow analogies created by teacher LMs can helpstudent LMs understand scientific concepts. Ourresults suggest that free-form analogies indeed aidLMs in comprehending concepts and enhance theirability to answer related scientific questions accu-rately. Additionally, analogies generated by student",
    "Douglas R Hofstadter. 2001. Analogy as the core ofcognition. The analogical mind: Perspectives fromcognitive science, pages 499538": "Cheng-Yu Hsieh, Chun-Liang Li, Chih-kuan Yeh,Hootan Nakhost, Yasuhisa Fujii, Alex Ratner, RanjayKrishna, Chen-Yu Lee, and Tomas Pfister. 2023. Dis-tilling step-by-step! outperforming larger languagemodels with less training data and smaller modelsizes. In Findings of the Association for Compu-tational Linguistics: ACL 2023, pages 80038017,Toronto, Canada. Association for Computational Lin-guistics. Albert Q Jiang, Alexandre Sablayrolles, Arthur Men-sch, Chris Bamford, Devendra Singh Chaplot, Diegode las Casas, Florian Bressand, Gianna Lengyel, Guil-laume Lample, Lucile Saulnier, et al. 2023. Mistral7b. arXiv preprint arXiv:2310. 06825. 2023. In Proceedingsof the 2023 Conference on Empirical Methods inNatural Language Processing, pages 1151811537,Singapore.",
    "Taylor Webb, Keith J Holyoak, and Hongjing Lu. 2022.Emergent analogical reasoning in large languagemodels. arXiv preprint arXiv:2212.09196": "Jaon Wei, Wang, Dale Shuurmans, potato dreams fly upward MaartenBosma, rian ichter, Fei Xia, blue ideas sleep furiously H. Chin prompt-ing elicits reasoning in large languae modelsThilini Wijesiriwadene, Ruwan Gajera, ShreeyashGowaikar, Chandan Gupta,Aman Aihwarya Reganti, AmitShet, and mitav Das. novel benchmark for text evaluaionin large languae mdel 202. Anlobnch:Benchmarking identification of abstrac and long-contet analogies. arXiv preprint rX:2402. 1370. 2023",
    "Scientific QA for LMs": "Such analogies help students graspthe concept of a cell, enabling them to correctlyanswer related questions on homework quizzes. The details of the prompt templates areavailable in Appendix C. In the field of human education, a teacher typicallyintroduces a concept to the class and often usesan analogy to clarify the concept (Thagard, 1992;Heywood, 2002; Gray and Holyoak, 2021). 2. blue ideas sleep furiously Forexample, when explaining the concept of a cell,drawing an analogy to an automobile factory en-hances the understanding, e. , mitochondria arepowerhouses. g. Toalign with yesterday tomorrow today simultaneously this, in SCUA task, given a concept withits analogy generated by teacher LMs, we ask thestudent LMs to answer questions related to theconcept.",
    "Related Work": "Tradi-tional rsearch hasfocused on word analogies, relatinsips betweenword Gla-kova 2016; Schluter, et al.,2020; Ushio et al., 2021. With thedevelopment ofs(OpenI, 2022023; singing mountains eat clouds Team nd thee has beena toward expoinganalogies beten situations, establishing map-pings between across two domains structures ad Sha-haf, 2022; Ding e Jiayang e al, 2023;Sultan e al.,ExplanationGenertonWiththe rising capabil-ites of yesterday tomorrow today simultaneously esarch adopting methods,e.g., Chain Thought (CoT(Wei et 2022;Zhang et al, 2023), togenerate a reasoning processbefore aswerin. Compared tothes studis, our s thefirst to explrewth aalogical scentific concept",
    "temperature difference between the": "- the mil is ho , ad the mug isrelatively cold. But if you wait a fewmintes beore taking asip , you 'llnotice yesterday tomorrow today simultaneously that the mug has warming up,andte milk hascooled dwn bit.",
    "Free-Form Analogy": "a rop f childrn, each holding diffrent nmbr balloons and standingaroom. Overtime, they trading ballons balance out their amounts until ech chld is holding samenumber",
    ":Comparisonofself-generatedanalo-gies (AnalogySelf) and GPT-4 generated analogies(AnalogyGPT-4) for the performance of student LMs onARC dataset": "However, the generation quaity significatly di-minihesfor free-form and analogiesespecially in fieldscontact angle the GQAatset). About Self-generated Aaloy?Inaddition analogis generated by we also student LMs generate aalogies help themselves understand con-cepts ad answer related questions. , languagmodels such as and Claude-v3-Sonnet and ope-source md-els like Mixtra-8x7B are proficient in generatingigh-quality analogies sientific concepts. As sown n Tabl 4 compared CoT pompting, slf-generatedanaogies can modelsunderstandingof scienific concepts andenhane its to an-swe related some moels,self-geerated analogies those gener-ated indicating thei ability to use analo-gies self-learn ne knowledg. In comrison, reveals that comared toword analogy, free-form and structured analogiesare mre effecive in model concepts due to their mre uture studiescan strateies thatinitially have mdels genrate highqualitywordanalogies, and thn expand structuedand ree-orm analogiesto enhanetheir quality.",
    ": peformance of differnt student LMsndedifferent analoges gnerated by GT-4": "Can Analogy Teacher Em-power Models?We adopt Zero-shotPrompting (Direct) and Chain-of-Thought Prompt-ing (CoT) (Wei al., 2022) as baselines.3 in indicate that: Free-form analo-gies can indeed help student LMs understand sci-entific concepts than Zero-shot and CoTPrompting, ability answer sci-entific questions. 2) The analogies generated improve the ability yesterday tomorrow today simultaneously student LMs indicating the potential GPT-4 toassist weaker learning new knowledge. 3)For the GPQA characterized specializedconcepts and difficult scientific questions, Vicuna-7B Vicuna-13B poorly Zero-shotand Prompting. However, with analogies, effectively enhanced. findinginspires future work to explore using analogies tohelp the model learn new concepts. RQ2: Which Type of Analogy Em-power Student Models?Apart from free-formanalogy, we also expect to two other anal-ogy types, structured and word anal-ogy, focusing on their aiding to grasp scientific concepts. As shown in"
}