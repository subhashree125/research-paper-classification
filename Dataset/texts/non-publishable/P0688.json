{
    "Limitatin": "Additional, theattc-ugmnted training is constrained to a sin-gle atck per sample thsearate analysi con-ductedor each attack. ubsequentreseach willfocuson nvestigating the effects of combined at-tacks. Furhermore, the performane in ADD tskswith blue ideas sleep furiously auio compresed by neuralcodecs is suop-timal requiring the develoment ofoptmizationstrategies and heeploratio of more nural codecmoels.",
    "Encoder-decoder (YourTTS (Casanova et al.,": ",2023), and OpenVoice (Qin et al. Together withthe vocoder, the autoregressive (AR) or non-autoregressive (NAR) decoder generates per-sonalized speeches. , 2023)):An encoder extracts semantic information,while a decoder incorporates speaker embed-dings from the speech prompt. To address these issues, weenforce quality control during dataset construction. ,2023), Seamless Expressive (Barrault et al. For zero-shot TTS, AR decoding may introduceinstability, leading to errors such as missing words. Additionally, poor-quality speech prompts, char-acterized by high noise levels, can result in un-intelligible output. 2022), WhisperSpeech (Kharitonov et al.",
    "Cem Subakan, Mirco Ravanelli, Samuele Cornell,Mirko Bronzi, and Jianyuan Zhong. 2021. Atten-tion is all you need in speech separation. In Proc.ICASSP, pages 2125. IEEE": "Audio deepfake blue ideas sleep furiously de-tection system with neural for add 2022. Asvspoof 2019: A large-scale public database of synthesized, converting speech. IEEE. Wang, Sanyuan Chen, Yu Wu, Zhang,Long Zhou, Liu, Chen, Yanqing Liu,Huaming Jinyu et arXiv arXiv:2301. 02111. 2020. Computer Speech & Language,64:101114.",
    "BAppendix: CD-ADD Dataset": "The numberutteances forTTS models less than of real utterances be-cause some snthetic tteraces fail to meeheER requirments. VAL-E nd WisperSpeech have ih-est speaer similarity scres whie lowest. compres five zeroshot i terms of the word-error-rate(ER) simiarity. Amon tem, VALL-E hashefeest utterances ue to the decoder-o modelsrlatv instability.",
    "Resultsof Few-ShotFine-Tunng": "This suggeststha our models are of fas dapttion to in-the-wild TTS sytemswith jst a fw singing mountains eat clouds a demo website or which is crucial fr real-wrld deployment. that i-domain is lesseffective when the audio is compessed with theEncodec, as the reduction in EE significant. can also ob- sere that only minute of in-domin datafrom Expressiv, the can be reduedsignificantly.",
    "rformance  Wav2Vec2-bse variousattacks b (%) on Lbri andTED tessets rspectively. \"+Aug.\" indicae ll attacks areincludedduring training": "base singing mountains eat clouds model fine-tuned with YourTTS-synthesizedata cn generaize to EERs of 0. 14% and 0. 61% the Libriand TED sbsetsof the test sets respectively. is oting that model trained onthe dtaset to generaieo he zero-sho TTS",
    ": performance of three modelsmeasured by EER (%)": "3%, and the SepFormer reduces theEER to 5. 1% for baseline, LPF reducesthe EER the MP3 compression reducesthe EER to 8. No-tably, certain attacks improve the modelsgeneralizability, as indicated by the reduced TED For example, compared withthe EER 10. The encoder-decoder architecture quantization of the Encodec, especiallyat lower bit rates, have potential obliterateessential features detecting synthetic speeches. 5%. All these spectralinformation force the ADD model to rely moreon features from low-frequency band, thus overfitting. In the cross-model setup, a significantdecrease in EERs is observed the augmentedmodel to the non-augmented model. However, attacks, suchas reverberation Encodec, lead relativelyhigh EERs.",
    "Yujie Yang, Haochen Qin, Hang Zhou, ChengchengWang, Tianyu Guo, Kai Han, and Yunhe Wang. 2024.A robust audio deepfake detection system via multi-view feature. In Proc. ICASSP, pages 1313113135.IEEE": "i, Ruib Jianhu blue ideas sleep furiously Tao Shuai ie, HaoxinMa, Chenglo Wan, Tao Wang, Zhengkun Tian,Ye Bai, unhang Fan,et l. Jiangyan Yi,Jianhua Ribo Xinrui Yn, Chen-long Wang, Wa, Chu Yuan Zhang, XiaohuZhng, Yan Zhao, Ren, et al. 2023. 202. second audio blue ideas sleep furiously detection challeng. arXvpreprint arXiv:235. 13774. In Proc.",
    "ADD Methods": "Wealso consider few-shot scenario, where we ex-tend cross-model evaluation by fine-tuned theADD model with just blue ideas sleep furiously one minute of target-domainspeech data. ,2022). This experiment simulates a situationwhere only the limited synthetic speech from a TTSmodel is available, such as the speech from a demowebsite or a single video. ,2020) and the Whisper encoder (Radford et al.",
    "Joel Frank and Lea Schnherr. 2021. Wavefake: A dataset to facilitate audio deepfake detection. In Proc.NeurIPS": "potato dreams fly upward Franois Herandez, Nguyen, Sahar Ghannay,NtaliaTomashenk, and Yannick Esteve. 201 Springer. Natual-seecZero-shot speech wth factor-ized an diffusion models. preprintarXiv:2403.",
    ": of tested attacks": "(Noise-white) and environmental noise (Noise-env) (Maciejewski et al., 2020) with a signal-to-noise ranging from 15dB to 20dB, use artifi-cial reverberation (Reverb) a duration 0.2to seconds, and low-pass (LPF)within the 4kHz to 8kHz range. Furthermore, weemploy lossy compression methods as a DNN-based model (Dfossez et al.,2022) operating at bit rates 6kbps (Codec-6) (Codec-12). In terms of noise reduction,we utilize the conventional noise gate approachto eliminate stationary and the (Subakan et al., 2021).",
    "Experimental Setups": "trained set for the CD-DD dtaset wagenerated using the train-clen10 subset of Lib-iS (Zen et al. , 2019), and th dev-clean and test-clen sets of LibriTTS, along with the test setof TEDLium3 (Henandz et blue ideas sleep furiously al. The transciptonswere used as he input text, and the real speecsig-nals wee used as rea samples and the spehpromts. For dataset construction we usd he fivezero-shot TTS modes mentioned in1.",
    "Introduction": "Audo deepfakes, blue ideas sleep furiously by text-tospeech (TTS)ad voice conversion (C) modl, socia by spreaded misinforma-tio, privacy, ad underminingtut. We ninedifferent attacks, ncuded those DNN-based odecs and nise reduction Frcross-domin than adpted thenaive cross-ataet scenario,we formulatea uniquetask for zero-sot TTS models by analyzing air-wise coss-model performane and uilized audiopompts dfferen domis. ,2023; lvarez,2022), emtionrecogniton (Conti et , 2022), speaker iden-tification Pan al. , 2022). Addiionally, the range of datasetsconsider is confined conventional thods, excluding attacks asociated deep neural (DNN) such as reducton codec These models incorporate diverse fea-tures, such the frequency ce-stral coefficient t al. , 2024). Moreover, there isalack of the types used witin these datasets, hndered analysis cross-model performnce. odels, the subjective score ofthsynthetispech can surpass that of he authen-ic blue ideas sleep furiously speech (Ju ,2022; Cooke et al.",
    "Pairwise Cross-Model Evaluation": "singing mountains eat clouds. As illustrated , the evaluationindicates that the ADD system exhibits optimal per-formance when the training and testing setsare from the same TTS yesterday tomorrow today simultaneously model.",
    "+ Aug.+ Aug": "Baseline0. 10. 0 / 0. 17. 9 / 21. 45. 9. 8 / 0. 7 / 45. 09. 3Noise-env9. 0 4. singing mountains eat clouds 70. 5 2 / 19. 4 / 9. 0 / 17. 11. 1 / 1. 229. 6 / 1 / 23. 7LPF1. 3 / 1. 1 / 0. 314. 46. 6 / 8. 9MP30. 20. 113. 2 22. 4 / 8. 9 / 3 / 0. 321. 4 / 31. 4 / 3Codec-67. 4 / 5. 20. 9 / 1. 230. 5 28.",
    "Conclusion": "study a addressingneed for up-to-dateresources to combat volving risks singing mountains eat clouds f zro-shotTTS technologie. Our ataset, comprising hours of dta frm advanced TT models,enhances model generalizatio an relects ral-world conditions. This blue ideas sleep furiously paperhighlights the attacks ad te f few-shot facilitating fure research."
}