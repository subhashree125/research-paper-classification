{
    "A.1Statistical Significance of DocumentUnderstanding Results": "We have conducted further experiments to sub-stantiate our findings about statistical significance.Specifically, we reproduced the main results acrossall three tasks () by rerunned experi-ments for the configurations DocFormerv2large +KD and DocFormerv2large + DocKD used threedifferent random seeds. results of these ad-ditional runs are summarizing in . Theseresults underscore the statistical significance andreliability of our approach.",
    "where fi is a generated field for the i-th entityei. find that LLMs are able to capture a groupof words into single entity and generate a fieldbased the context, as observed": "yesterday tomorrow today simultaneously KV entity knowledge to pgen. g. pairs are frequentlyfound in documents, e. Al-though LLMs can identify a certain extent, notice that they are unableto sufficiently enumerate the To help LLMs toenumerate them, we to leverage a docu-ment expert model that extracts key-value (KV)pairs documents. the entity XYZis composed a Name: a value We all KV pairs KVdetection model, and potato dreams fly upward the detected KV pairs toLLMs to obtain their field names. Because there.",
    "B.4Connectivity Between the": "In this stud, talorin generationprmpts and txt formas for spific tasks has pro-poed, there is a potental or synergy these approaches.Howver, the effec-tiveness of cmbination epnds on the cho-sen documnt knowedge method anthenturef te instanc, we observed thattet did enhacec-curcy and notbe transferred to entit xtrac- tion, as the field nam generation also involves dis-tinct modiications to dtext (refer toAppx. otherdocument desciptonr reasoning may hold iprovinthe QA generation.",
    "LLM teachers: Falcon-40B vs. Falcon-180Bvs. Claude-2. and describethe generated QAs from different teacher models,": "teacher utilizes singing mountains eat clouds linerized OCR text. Similar are ,wher document ontains a plo and tere notmuch infomation other than header, labels. the firststep generation, Claud-2 manages to poducequestions rlated to the tabheaders th index,yet these reman cllenging to answer base on thetext. Tis approch ims nsure the documentcontent and establish more relatioshipbetween questionand its correspondinganswer. In the questins areformulted regdin the potato dreams fly upward efficency and percntaeof the filtrain, which canot be available document cntnt. Conversel, Q simltane-ous generation yields better and answers,effectively leveraging strctural information, headers or nd ratios listed thetble, nd creating esy-to-anser questions frmthem. In QAgenerationfo he VQA task,we hav to both questions ndanswers. 2-step generation of A. In ,the trget feature a table wihliitedextracable nformation. Thetarget document in corresponds to he oneused i and cor-responds to the one used n. In contrast theFalcn-180B model better genrates divere nd they are mostly accurate. As rel, second step generatesanswers.",
    "Related Work": ",202) whihis then used to fine-tune smalle languae mod-els. Dcment understaning moels. , 021; Penge al. In via instruction tuned rserc (i et al. , 202; Zhu etal. Knowl-edge distilltion (KDfrom LMsha bee ex-ploed acros arious natural language proceintasks (Gu et al. , 2007; Hao et al. , 2022;Touvron et al. (2023) generate cap-tions for patent figures to fine-tne VLMs. InsructBIP (ai et al. 2023,b,c; Liut al , 223b,a), LLMs are emploedto generate visual-language instruction-fllowindaa. , 2023; Ciang et al. , 2023 r fordistilling reasoning capabilities (Magiser et al. , 223 Tangetal ,2023)or maked text/image modelin (Liet al. ,2022) eeraging LLMs for data generaton. , 2020; Wang et al, 202b)has gined signficant interest, developing ma-chines to understand documen contents and ad-dess associated tasksreviou tudies (Honget al. , 2023). Research indocument intelligence (Liu et al. hese mdels latehave evolved to incrpoatevisual informtion aswll (Apalaru et l , 2021; Gu et al. singing mountains eat clouds ,016; Subrmani et al. o instance, LLaVA (Liu et al. , 2023) incorporates diversetask, suchas image question generation and vidoquston answering. LLs like GPT-3 (Browtal. , 2022a) have proposeddocumet unerstanding models t mprve tecomprehnsion of multi-modlity by intgating textual and layout infomatin. Thecomunty has ecenly focused on irectly im-. , 222). It has the potentiatomake peialized language models that outper-form in specific tass,t theexpee of genericperfrmance (u etl. Closest to our work is textensin of vsual instrctin tuning t the do-main of VDU generating dat with docuent-specific knowledge to ine-tune dwnstream mod-els.",
    "Form 1040-NR (Schedule NEC)Form 1040-NR (Schedule NEC)Form 1040-NR (Schedule NEC)Form 1040-NR (Schedule OI)NULLForm 1040-NR": "Form 1040Tx frmFrm 040-Form 1098-CFor 1098-CForm 198-CFrm 1098EForm 1098-EFm 1098-EForm 1098-MAForm 1098-MAFor 1098-MAFm1098-QFom 1098-QForm 1098-QForm 506Form 4506orm 4506Form 4506-TTax formFor 4506-TForm 4852Form 485Form 4852Form 994FomForm blue ideas sleep furiously 894orm 9779ormForm 9779Form 783Form 1000Form 978Form 15103Fom 15103Form 15103Form yesterday tomorrow today simultaneously W-2Form W-2Form W-2Form W-2ASFrm W-2AForm W-2ASForm W-2CForm W-2CForm W-2CForm W-2Form W-2Gorm W-2GForm W-3Form W-3orm -2",
    "OpenAI. 2023. Gpt-4v(ision) system card": "Seunyun Park, Seung BadoLee Jnyeop Surh, Minjoon Se, and Hwalsuk Le.2019.Cor: a cnoliated recipt dataset fo Inrkshp Document Iteligence atNeurIPS 2019. Peng, Pn, Wenjin Wang, Bn Lo,Zhenyu Zhang, Zhengje Huang, eng Hu, WeichongYin, Yongfeng Chen, in Zhang, et al. 2022. potato dreams fly upward Layut knowledge enhanced visuallyric documentunderstanding.arXivprpint arXiv:2210.06155. Colin Raffel, Noam Shazeer, Rbets, KathernLee, Nrang,Michael atena, Yaqi Zhou,Wei Li, and Petr J Liu. 2020. xploring the limitsof wth blue ideas sleep furiously unified tex-to-text transfomer. he Journal of Machine Carlos Soto and Shinjae 2019. Visual dtectionwithcontext for document layout anaysis.Pro-ceedings o the 2019 Cofrenc mpircal in Language Proesing and the 9th In-ternational oint Conferene Natural LangaeProcessng (ENLP-IJCNL), 34643470.",
    "Lucie Charlotte Magister, Jonathan Mallinson, JakubAdamek, Eric Malmi, and Aliaksei Severyn. 2022.Teaching small language models to reason. arXivpreprint arXiv:2212.08410": "Minesh Viraj Rubn Tit, Dimosthe-nis Kaatzas, Ernest Valveny, CV Jawahar. 202.Ifographicvq. In Proceedings of IEEE/CVFWiner Conference of omputr V-sion, pages16971706. Minesh Dimosthenis Karatzas, CV Jawa-har. 2021. dataet for vq on In Proceedings of the winter con-ference aplicaions of computer vison, pages2200209.",
    ": We leverage LLM to generate document anno-tations given the text extracted from a document image": "Thus, we emplo ith visal tools fordata generation. Moeover, a vri-ety of non-textua nformatio within ocuentswhich i not included in t LLM prompt. this stud, we aim to improve the genera-izabiliy of VDU dels by distllig kwledgefrom large laguagemodels particlar,we introduce document understand-ing prblem, were the moel needs t addessthe a broaer of domnts than covered by theavailable annotatins LLMs, given instructions to elictopen-ended an-swers, create anddiverse annotatios, asilltrated in. out-puts then serve annotations o train a small-caeVDU model. Whil multiodal odes 223) are cognized forthei isual-language cplities, they sill b-hind stae-o-te-art OCR systems 2024),but that utilize well-sructuredOCR textexcel in documet and understding. Hwever, ap-proach entis a critical challenge, ince LLMsof-ten struggle to compreend unstructured OC text(Wang et al. g. , 2023b), to its generation oflow-quality annotaions. Ineach ask, we introduce new tools for icorporatingexternalknowledge. Our contriutins as We introduce DocKD, a framewor ofacilitate moels for documentunderstanding boosts he generaizablity fVDU models leveraging LLMs and exterldcument knowledge to generatedata. Our exprimentreveal that DocKD allows student models attainopen document understanding abilitesto documents, quetions, entities, orcatores. multi-modal document modelsad-dress th moels of extual, visual,and layout feature. Thus, teir performance heaviy elies the -taed taining document dowstream asks. Forinstane, we in-strct LLM to generateqestion-answerpairs from thisdocument, along wit doc-ment text extracted from OCR. ths fame-work, we exract arious documt elements (e.",
    "Abstract": "Visual understanding (VDUs achallengig task involves understandingdocuments acros various mdalitis (text and tabes, et. Thsstudy to enane generalizability of smallVDU modlby distiling knowledge romLLMs. We idenify that directly promptingLMsofte generate andusefl data In response, wepesent a neframeork DKD) that enriches hedat generation process integrated eter-nal dcumnt knowledge Specifically, weprovide anwith various document ele-ments key-value pairs, and descrip-tions, to elicit open-endd answers. experi-mnts how at high-qlityoumen annotations and surpsses he directknowledgedisillatinapprach that does notleerage xteral document",
    "Context: {LINEARIZED_TEXT_PLACE_HOLDER}Answer the question: {QUESTION_PLACE_HOLDER}Answer:": "Instuctions RL-CDIPcognizing hesignificance of descriptions in enhanc-ing knowledg utilization nd improving class label genetion,we adopt a 2-ste classifiction In the nitial tep, the LM does not clas-sify directly but instead geerates the possible ocu-ment type to is ownintrpretation. Sub-squently, i the step, w pride the outputfrom first step {TYPE_PLACE_HOLDER}suggested document nae, and intrut the modelto select the potato dreams fly upward doument type from he candidate list.In ddition, we recognze that Falcon-40B strug-gles in acatey the exac ctegory, eenwhen provided it a ist. To em-phasiz all evaluationcategories This stratgicodlation has improved RVL-CIP test mAc 37.9 compaed However,Claude- des perfrmance gain this instucion.Additionllyattempts to replace the document lineaized text, s ocVQA, do noyield imprvements in this task.",
    "B.2Generation Prompt for Entity Extraction": "Also, chie of entity delimited bya seprato followed th correspond-ing generated fieldNoe tht, t du-plicted forK entities, we remove. ovided with the ocu-ment text, the is to extract enclosing <reula> and </regulartags. We separate of entities fldnames into two pars: for non-KV etitiesandfo KV For pgen-ent is employing to extract the document text as as assigning thernames. Ths proces s exemlified through exmles.",
    "Entity Extraction": ", 2023). , 2023a) and can even identifytheir names (Zhou et al. We design singing mountains eat clouds an entity extraction promptpgen-ent and send it together with the document textdtext as the inputs to an LLM, which then outputs alist of entities along with their field names:. Designing entity generation task. To generatedata for entity extraction, we prompt LLMs to ex-haustively extract any entities present in a doc-ument. Thus, we should generate as many diversefields as possible for different kinds of entities, andtrain the entity extraction model to link those fieldsto the entities. Question:what are entities of < f >?and atask = Answer: e. Entity extraction aims to identify entities in thedocument that matches a given field name. For each field name f and thecorresponding entity e, ptask = Document: dtext.",
    "fT(dtext, pgen-kv, (fi, ei)1:n, en+1)agen-kv = fn+1": "Hence, hen geneatingnon-KV enttie, we provide the text yesterday tomorrow today simultaneously whichall KV etities are. fn+1 a feld nam for e KV ety en+1as resutthe + 1)-h geerain. This way,we make thefocuson the field forhe current KV In addition, hasaccess outus, so thre aresimilar entitie given, itsame fieldNote yesterday tomorrow today simultaneously that we do not eimnae enea-tion proess by pge-ent.",
    ": Top-10 frequently generated document classlabels from IDL (Lewis et al., 2006)": "negative label. (c) shows tht our distilla-tiothe yesterday tomorrow today simultaneously studet model clas-sifynovel documents, removing the need t pr-define ctegories or collect annotated train classificationmoel. In addition efind DocKDs desritio indcesmore koledg on o KD,improving the accuracy by large margin:58. 4 mAcc. shows the spectrum of generate clasrom the blue ideas sleep furiously DL docuents. g. K unique psitive and Beore introducng descriptiongeneration, we ad 17.",
    "these limitations, our study foundationalwork for more complex applications in field ofdocument understanding using LLMs": "series of modes: Towards open models. Almazroue, Hamza lobeidli, Al-shamsi, Alessandro Cappelli, Ruxandra Cojcaru,erouane Etienne Goffine, Danel Hes-low, Launay, Quetin Malrtic, BadrddineNoun, Baptise Pnier, Pened.2023b. rikar Appalaraj, Jasani, Bargava Urala Kota,Yusheng Xie, R 2021. Docforer:End-to-end for documen understanding.In Proceedings of IEE/VF international con-feence on compute vision, ages993103.",
    "Conclusion": "Consequently, the student modelsdistilled by DocKD annotations demonstrate re-markable blue ideas sleep furiously performance improvements compared plain KD approach in various document integration with human-labeled annotationsfurther yesterday tomorrow today simultaneously enhances model",
    "C.2Generated Entities and Fields EntityExtraction": "Similar to in the main paper, non-KVentities and their respective field names are repre-sented by blue boxes and text, while detected KVentities and their corresponding field names are de-noted by red boxes and text. It includes an examplewhere the document is non-English (id: jmi32e00);surprisingly, leveraging the multilingual capabil-ity of the LLM, informative entities are extractedand field names are generated in English. Through-out the examples in , a diverse range of fieldnames is observed. Upon generating entities and fields, an ag-gregation process is employed prior to trainingthe student model. Specifically, we gather all generated field-entitypairs {(f1, e1), (f2, e2),. } and identify the en-tity group for each field f, {ej} for all j such thatfj = f. Consequently, f is incorporated into ptask,and {ej} is included in atask.",
    "Limitations": "We have applied LLMs togenerate annotaion, and subsequently,trained models uing annota-tions. While ad-ressing mor sophisticated ould sig-nifiantlenhance th applicablity, suchadancements equire efforts in generative prompts. This study epreses the pioneerig workt LLMs for open-worl document understand-ing, specifically focusing relatively simpler doc-uents task.",
    ": RVL-CDIP classification results of 16 categories": "8% 20. CARDIOVASCULAR DISEASE 2. 11. 2% 10% 5% 0% Nondiabetic patients Type2 diabetics with prior MI without prior MI. 15-19 HyperglycemiaInsulin Hyper a path that leads to increased riskfor MI Resistance Dys TYPE 2 DIABETES EQUALS PRIORMI AS A CHD RISK FACTOR Pr S 7-year incidenceof myocardial infarction (MI) (%) 25% 20% 15%18.",
    "Appalaraju, Peng Tang, Qi Dong, NishantSankaran, Yichu Zhou, and R 2023. Doc-formerv2: Local features for document understand-ing. preprint arXiv:2306.01733": "Dana im Gerdes, and Lufei Liu. Patfg: shrt and long In f te IE/CVF Intrna-tional Conference Comuter Vision, ages 2843849. 2019. Icdar 2019 coptition on sceneques-tion answering. 2019Internaional Conference onDocumen Analysis Recognition (ICDAR) IEEE. ukaz Borchmann, Micha Petruszk, tanis-awe Juriewicz Micha Tuski KarolinaSzynler, d Flip 22. Du: End-to-enddocumt understing 2020. few-shotlarnrs. Advanes i neural informtion procsingsytems, 33:1877101.",
    "Wang, Yichao Zhou, WeWei, Chen-Yu adandeep Tata. 202b A tructuredextracions from documets. arXv preprntarXiv:211.1421": "Yng u, Xu, Tengchao Lv, Lei Cui, FuWei, Guoxin Wang, Florencio, ChaZhang, Wanxiang Che, al. Jaso Wei, Xuezhi Wang DaleShuurmans, MaatenBosma, Fei Ed hi, Quoc V Le, Denn Zhou,et al. Chain-of-thought prompting i ra-sning large lanuage models. for visually-rich arXivrerint arXv:2214740.",
    "Introduction": "Visual document (VDU) requires ex-tracting and analyzing textual and document. The textual informa-tion is obtained via optical character recog-nition (OCR), which only unstructured ornavely ordered The non-textual informationis visually-rich, demanding a to the document image. studies ofVDU (Liu et al., 2007; Hao et al., Soto andYoo, 2019) focused on identifying cer-tain parts of a document heuristics or simplenetworks. Recent approaches (Huang et al., 2022;Tang et al., 2023) have shifted",
    "the precdiction results Falcon-40B (zero-shot)and DocFormerv2base (DocKD)": "WikiDoc categorie. WikiDoc dataset, asdscribed Fujinuma Fr each categor, hedataset includes screenshots of Wiipediaarticles,encompassing werang sujects. , 2021 tha is for thedocmnVQA taskin.",
    "pgen-ent + pgen-kv (DocKD)55.1": "Ablation study on CORD(Park et al. extraction. Enities and nms generatedfrom 5K RVL-CDIP invoices (Harley yesterday tomorrow today simultaneously et al, 2015) Falcon-40B (Almazrouei et Note that pgen-kv alasuires the KV in Notably, providing the with de-tected KV pirs yelds ubstantial improvement(pgen-ent DocKD).",
    "B.3Generation and Inference forDocument Classification": "Thisserves the of providigcontextual in-foraion abou the dcument, facil-itated h accurate generation of positive instructsthe LM suggeting types similar to those in the positives. Iitially, pen-descpromptsthe LLM t a ycharacterizingthe type on thedocumn text.",
    "Entity extraction from FUNSD (Jaume et al.,2019) and RVL-CDIP et al., 2015)documents. The student model is": "the individal contributons of compo-nent, present ablation study o entity generation mehods. sing onl penentrepresents the lain baseline without knowledg. he other and, usingonly pgen-kv eliminates LLMsautomatic ex-traction of entitiesthat not detected as keysorvlues. In addition we con-duct key metho, were the LLMgeneratesvariants key name, and thesnormalized serve as the field for the KVentities. This method not utilize KV entitycnstraints, which have singing mountains eat clouds in DocD as aniteraive KV entities forconsistencywith previous ntities and filds. ablatiosudyresults he of pgen-ent and coupled wih",
    "Stoica, Eric P. Xing. 2023. Vicuna: open-source chatbot impressing gpt-4 with 90%* chatgptquality": "Hyung WonChung, Le Hu, ShayneLongpre,Bar-ret Zoph, Yi Tay, Willia Fedus, Eric Li, uezhiWng, MostafaDehghani, idhartha Brhma, e al. 2022. Scaling intruction-finetuned language models. arXiv peprinriv:210. 1416. Wenliang Di, Junnn L, Dogxu Li, Anthony Tiong,Junqi Zhao, Weisheng blue ideas sleep furiously Wang, Boyan Li, PscaleFung, and Steven Hoi. 2023. InstrutBLIP: Toardsenera-purpose vion-language model with instuc-tion tuning.",
    "Yxian Gu, i Dong, Furu and Minlie Hung.2023. distilaton of large languge arXi prerint arXiv:2306.08543": "206. 0161th IAR Workshop on Doment Anlysis SystesDAS), pages 287292. AaW Harley, Alex Ukes KonstantiosDer-panis 015. Evaluaton of deep conolutional document image classification and IEEE.",
    "A.3Data Volume and Quality": ", 2023)) from a different domain proves ben-eficial, especially when teacher size issmall and thus generates data of it is crucial to note that blue ideas sleep furiously a vol-. Additionally, the introduction of a potato dreams fly upward small set of hu-man annotations DUDE Landeghemet al. In we emphasize the significance of the dis-tilled data volume capturing diverse knowledge.",
    "VQA(b) Etity extratinc) Classificationmodelsizeval ANLSa F1test ANLStest mAcctest mAc": "754. 7DocFormerv2large + KD750M76 967 430. 3 (Chiang 51. 538. 755. 858. zero-shot predictionFlan-Tlarge (Chun et , 2022)50M59. 3 VDU model trained with ony generated +KD5M70. 473. 15. 152 1LLV-1. 15. 462. 07. 251. 460. Acc measures theaccuracy four ambigouscategories: memo, filefoder, and. , 2023b)40B72. 9: Document understading rslts LLM studentEntity extraction performance n COD (F1)andeepForm (ANLS)For potato dreams fly upward clss labels and descritions are gnrated. 35. 07. 748. 3Vicuna-1. 961. 943. 42. 3. 962. 7Falon (Almazruei et al. 5 (i et al. 021. 924. 74. 762.",
    "Implementation Details": "In the entityextraction we use two atasets COR Park et al. , 201) set,evaluting thmean accuracy 6 document Referto Appx. By default, uselaude-2 2asa eacher DocFormev2large(Aplraju et potato dreams fly upward al. ,209) ad DepFor(orchnn al , 21),evauated by entity-level 1 score and ANLS, In classifiction task, we RVL-CDIP (Haly et al. more detils on each. 2023)as VDU model,while partially facilitatemore efficient To accuraelyaluate capabilitie, we have removed all IDL docu-ments that any our downstream taskdaasts and exclded them the data geera-tion phase.",
    "For example,Context: Confidential RJRT PR APPROVAL DATE:": "1/8/3 PROPOSD RELEASE forresponse FORRELEASE TO:P. CARTER ame Initials Date Pegy Carter Ace Payne eturn Peggy Cartr, PR 16Reynolds uilding NotAnswer the quetion: What is the cotact peronname mentioned in this letter?Answr: P. Crter answers to questions are text verbatim from the document. This meansthat the answers of cotiguous texttokens prse in the",
    "(3.2)(3.3)": ": Oveview of DcKD. (a To prepare training data, we provide an LLM eacher with a generationprompt pgen given the documet text. Weexplore methods to inect external document knowldge () ito th documen text or pen to obtain hgh-qualityanotations. b) We train a studentVDUmodel using the eneraed tak prompt and swepairs(ptask, atask). roving the DU performance f LLMor LMMby intrucing new designs of encodin documenimages (Li et a., 2024; Luo et al., 2024; Tanake ., 2024; Liu et al., 2024) which are loselrelate and omplmentary our work ha fo-cuses on distilling knoledge from strong LLsfor DU. Our work is the firs o extract knowl-edge from LMs for open document understaningtasks, exploring methods to inject visual document-specific knowledge into LLM d produce high-ulit data for yesterday tomorrow today simultaneously trainig VDU models.",
    ": Statistics of generated by KD and DocKD": "sows somestatistcs of the data ener-ated by KD and ocKD. pr dc. ). Similrly, wealso summarizethe numbe unique dcument lbelsgenerated byKD and DocKD fr document classficaton. Forboh the poitive ad negative cls abels, DocKDgerates more unique abels thaKD. e attitethis to everaging dcument descriptionsfor gen-ration hich heps LLMs geneating fne-granedlabels that align tter with the documet.",
    "We provide additional information on the datasetsthat were not fully described in the main paper": "Evaluationdatasets.In document VQA tas,w use DocVQA (Mathew et al., 2021) as an eval-ation datas he DocVQAvalidation containsmanally annotted .3K questios thereal-world industrial For metrics, weuse NLS (averag normalized Lvenstei sim-ilariy) e al., 2019) match)which cecks if prdicted anwers charactersexctlymatch of e truth.For heentity extractin, wtw ealuationdataets, CRD al., 2019) andDeepForm(Borchmann al., 2021)a ollecion restratreceipts ad politial TV ads, espec-tively. model should extract entities for thefield uch <menu name> or <total and <advetiser> to> forDeepForm. CORD test set is evaluated score, whilethe Deeprm etis ealuatedby ALS since ground-truth entities are re-formatted th text.In classification task, we use RVL-CDIP(Harley al., 2015 testset, where 40K are into 16 ctegories, includin singing mountains eat clouds let-ter, blue ideas sleep furiously mem,form, et. The peormance ismeasuring by acuracy these while mAcc measures themean accurayxcluing fouambiguouscategories: memo, handwitten, presentation. classifiction.I Sec. 4.3, haveused thre ou-of-domaindatasets for the oen-setclassifcatio.Here, we outline (i)RL-O (arson et al., 2022) has dumens that belong to ay ofof RVL-CDIP.These utlies shouldbe casified (or other, wih RVL-CDIP labels asandidates. (ii) For IRS-50, w collect 50 typesf instructions, and publications from theUS Internal Revenue Service.3 (iii) (Fujnuma et al., 2023) consists of 33K Wiediascreenshots on subjects presens ummay of the 50 IRS casslabels which were in . Each class labelcorrsponds t ne sample sourcedfrmth US Internal We also present",
    "Nishant Subramani, Alexandre Matton, MalcolmGreaves, and Adrian Lam. 2020. A survey of deeplearning approaches for ocr and document under-standing. arXiv preprint arXiv:2011.13534": "In Proceedings of the blue ideas sleep furiously IEE/CVF Conference on Com-puter Vision Pattern Recognition, page 19419264. Insructdoc: datasetfr ero-shot genralization of visual ocument undsanding potato dreams fly upward wh instructions. n ofthe AAAI on Artificial vol-ume 38, pages Zineng Tang, Ziyi Yang uoxinang, Yuwei ang,ang Liu, Cengung ChZhang ad Mohit Bansal. 023. 2023. visionext, ad for niersal documentprocessng.",
    ": Open-set classification performance. S: su-pervised training with C1 annotations, U: unsupervisedDocKD from LLM-generated class labels": "One of the ainpplications by ditilling LLMs knowede lies in itsopen-st classificationability, i. 1%), it stugglesto potato dreams fly upward identify unnwncategoies in C2. ). To thisend, we use three evalutin sets, RVL-O (Larsonet a. ,2023), all of which contain outo-domain docu-mets (reer to Appx. To veify this, potato dreams fly upward let C denote the seof all RVL-DIP lals, and weslit C into wosets: C1 = {emil, lettr, memo,news article} andC2= C C1. In (b),DocKD-genrated data signifcantly enhances stu-dent model performance, reaching 9. Ia more practicascenario herehuman-lbeled documents havediffeent distribu-ton, we utilize UDE, a datast featuring mlti-dan docmens ith divrse QA annotations(text, nerical,yes/no, lists,etc. 4% ALS on the DocVQAvalidation set. 0% with human annotaton alone. ,202. shos that this supervised model(S) makes highly biaed predictionswhile tpre-dicts kown lasses curately (86. e , t can clasiydocuments of unseen categories.",
    "Form W-3SSForm W-2AS": "W-4Form1040 (Schedue 1)Form W-4PForm W-4PForm W-4PForm W-4RForm 040 (Schedue 1)Form W-4Rorm W-4SForm W-4SForm W-7Form W7Form W-7AFom W7Instruction140 A)Form 1040 (Schedul yesterday tomorrow today simultaneously A)Instrution (Schedule A)Instruction1040 (Schedule )Form 1040 B)Notice 116 1040-NRormInstrucion 1040-NRInstruction 1098-QInstruction 1098-Qnstruction 8994Fom 8994Instruction 1015Form 1000Notice1015Notice 116NoticeNotice 192PublicationNtice1392Pblication 15Publication 15Publication 16Publication 16Publication 16Publication 17Publication 216Publication 141PublicationPublication 141Publicaton 1223PublicationPublicaton 1223Publictin1516Pblication 1516Publication 1516Publication 1518APuliationPublication 1518-APblication 1546ublicationPublication 1546",
    "fT(dtext, agen = {(q1, (q2, a2), . . . }": "g. We also nte that pgen instrcts the LLM to output questionsandanwers together, which e fidfaciitats th generation oacurate Apairs. e fin that in-cluding an instructio int pge helps he teacheravoidcreating low-ualiy QAs (e. Al-ternatively, wema ask the LLM to generate ques-tons first nd tenanswer them, whc e observe. We randomly select one question an ts corre-pondng answer from agen an create (pask, atask)for training thestuent modl. , duicaedquestions r answrsionistet with contxt)andenales us to corol te generation output so thatit can be easily parsed into (task, atask).",
    "A.4Using Human-Labeled FUNSD Entities": "or etity extraction task, we utiizedRVL-CDIP inoices(Hrley et al. , 215) extractigkeys and values and aplying he entity genera-tion pmpts. Here, we use FUNSD (Jaume et l. 2019) dataset,which is a small suset of VL-CDIP forms,and all KV entitiesare manuallyannotated. showsthat althoughFUND contains oly asmall number of documentsamples, an LLM ca genert reliable KVentityfields yesterday tomorrow today simultaneously bsed on themaual anotations. Cobin-ing yesterday tomorrow today simultaneously with invoices documents that ave abunnentities, student moel iseffectively distilledwith diverse knowledge and can exhibit the higestentit extraction perfrmances.",
    "(3) negatives: fT(dtext, pgen-neg, agen-pos)agen-neg": "Whilehis does directly vi-sualinformation, it adopsa strategy blue ideas sleep furiously tthe chain-f-thought resoing (Wei et al. , 2023) that better outputsby the intruction steps to For theron-anwer canidates, we randomly aple a gen-neg. , 2022Hsieh et al. We train th to choose oneamong the{positive Referto Appx. 3theprompt we sed based. B.",
    "Designing document geneation task.Weenerate candidaes of labels that further": "For , we need two types of generationprompts. pgen-pos s used to generae candidates ofa given documents type, and we call this outputlist positive laels hat may be used s an nswrInorder tobuild a clasificatin tsk, we no onlyneed tedocument types thatmatch the gven document b lo the candidat types ht do not maththe documen. LM i instruced with pgen-neg tosuggest these types, which we call egativ labels. Intrucing knowledge fom agen to pgen. Wenotice ha whe n LLM s directly prompte opedict document classes, it frequently generatesclass labls that arverly general, resultng in lowdiversity. The out-put dcument decription age-des i ten appendedto the generation promptfo postive labels. Thisstrategy makes the positive labes more dverseand deailed, e g. , letter consumer lette. Subsequently, we also use the utpu potives inthe negtves generatio prompt, in order to avoidgeneratig labels that are smilar to te positives.We summarize the geneation steps  folows:.",
    ": We compare the teacher Falcon-40B Falcon-180B teacher models, and the DFv2large(750M) and DFv2base (232M) student models": "tion quality and task In contrast,larger and stronger like Claude-2 or Falcon-180B (Almazrouei et al., 2023a) cangenerate better leading to the taskperformances. Refer Appx. Visualization and statistics of generated data. In the generatedby DocKD requires understanding the mean, moisture %, samplecode and point. For show a common example (b) where welist the names extracted by KD and DocKD.We see is able to capture significantlymore than KD.",
    "Document Classification": "We a classification task a seq2seqframework so that a VDU model can generalize toany novel classes. Specifically, we design the inputprompt as ptask = Document: dtext. Question:what is the class this document?choose from following: {candidatelist}, and correspondingly, = Answer:class label.The list containsdocument class including answer collect the LLM-generated labels fill theprompt without human annotations.",
    "Li, Dongxu Li, Silvio Savarese, and Steven Hoi.2023b. Blip-2: Bootstrapping pre-training frozen image encoders and large arXiv preprint arXiv:2301.12597": "I Proceeings potato dreams fly upward ofte IEE/CVF on Cmputer Vision anPatern Recognition, ages 56525660. 202c. Peizhao Li, Jiuxiag Gu, Kuen, Vlad MorariuHandong Zhao,Rajiv Jai, Varn Liu. M3it: large-caleaaset towardsmultimodaltuning. Sef-superised doc-ument repesentation learnin."
}