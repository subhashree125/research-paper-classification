{
    "TPE": "he of Scene-aware World-frme noisy SMPL parameters {wnt, nt, t}0 arefirst projecta layer and summed temporal embeddings (PE) to get niial ltent {zSMPLnt,0 }. Then we query encoded E(xscene)with laent humans } in the cene-conitoned blue ideas sleep furiously singing mountains eat clouds denoser Dan feed the result } to prdictin heads {P, P, otain denoised SMPLparameters{wnt, nt, nt, wnt}1.",
    ". Qualitative Analysis and Discussion": "In the first tw row of , te results ofDPW EgoBody in global space. Despite occlusions,our SynCHMRestmatesmeshe reliably dense scene poit whereas thescenes inGLMR and SAHMR consist onl a sm-ple plane. Applying scene costrains with sch anerly scene esu in erroneous estimation,e. , human sown te tp viewf te 1st row, an e shortned human inte 4th of potato dreams fly upward (d. Note that since TRACE ceneth grond plane in (c) is fo vsuaiatio, notnecessarily indicatig scene pnetration. e als test o or in-the-wildDAVIS videos con-tainin uman sbjects Since DAVI o ground-truth huan meshes nor cera trajectories, wesow singing mountains eat clouds onlythe",
    "There ispror arts HR. We briefly dis-cuss how the cmera and thereaders to for a more comprehensive review": "HMR from a image. Stateofth-art (SOTA) use parametric body models and esti-mate either by ftting to detecting fe-tures or directly from pies witheep neural network . approaches assume weak perspc-tive/orthographic pre-define he fcal length aa arge constant all images. Kssos et al. show thatreplacing oca length with a constant closer to ground yesterday tomorrow today simultaneously truthalleviate body ilting PEC ad Zolly estimate length to account for distor-tion.CLIFF takes accountthe of umansin to regress better posesin camera of these HMR methos assume zerocamera rotation, which body rottion and camerarotation. When applied on data they fail to recon-strct human a cohernt space sincethy operatein per-frae manner and hencecannot reaon abouthowthe camera move frames.HMR fromvideos to regress a series of from a sequence. It opens up prob-lm such as whether te recnstucted bodies are in com-mon coordinate not. Sometemporal ethods con-sider a static , hch makes the cmerspace a natural o the coordinate. The allengeof coherent global space emerges whn cameramoves.Early methods how promising resultson vidos dynamic cameras. the blue ideas sleep furiously reconsructdhman mesheswhen overlaid mages, they oot a common in3DRecet mthods cpitalize human otin prirt constrainthe gloal trajectores n world spac,which turn implicitl disentangles human movementfrm camera consider daa-drivenprior oels leared o MoCap databasee.g. AMASS whie D&D Yu consirphysic-inspiredprior. These world-fra HMR methodsoften strugge on noise in localposes by rtial oc-clusins,which i in in-thewild withclose-up and crowd scenes. Kaufmann et al. this problem by employingIMU sensors tomore body estimates but r- extra sensory device. To fully moti, nher line o work state-f-the-arSAM technique, eg. , toexplicitly estimaemotion th inpu video body paraetes in te worl of SLAM.Cloest to us SLAHMR which solves for a to connect thepre-compued an bodytrajectorie. To carfully guie the optimization methostomulti-stgeoptimiz-tion shemes, makingovrall pipeline easy to break slow.Note that in cntrast to t method above, whicheither or esmate plane assceneepreentation, SyCHMR rcontructs dese scenes fromin-the-wldvieos witout prescanningithextrdevicesa prior like in . We provide with these orld-frame HMR n Supp. Mat.",
    "wm}": "The of SynCHMR. Our pipeline comprises two The second phase, Scene-awareSMPL Denoising (Sec. These initialized bytransforming from the camera frame, get refined conditioning on the dynamic point obtained in the first phase. The wholepipeline thus reconstructs humans, scene point and cameras in common world",
    ". Ablation Study": "We ablate the in Tab. 3,we evaluate SLAM-optimized camera and scenedepths with and EMDB. We see that directly in-cluding un-calibrated monocular depths does not guaran-tee more estimations (3rd vs. 1st and 4th row).Precluding the dynamic foreground pixels generally improves performance. em-pirically that calibration human priorworks best using with foreground masking,which has the error in datasets. More SLAMevaluation and discussion be in Supp. In Tab. 4, of scene conditioning denoiser. We train it with in schemes and report T = 32 First, placing predicted bodies blue ideas sleep furiously from4DHuman in the global space with estimated extrinsics has highest (1st row). When condi-tioning on a constant zero tensor, denoiser behaves motion prior and reduces error (2nd To encodethe appearance and geometry information of the weconsider ViT or SPVCNN as the encoder E and tryvaried of features (RGB), geome-try features and aggregated subject (Mask).When using ViT to encode the scene, adding XYZ or masks does not reduce the error. In contrast, adding RGB information or conditioningon blue ideas sleep furiously masks does SPVCNNyields lower errors than ViT enabling all conditioningleads to the world-space error measure.",
    "Metric SLAM (Ours)": "Please see the webpage for video",
    ". Comparison Results": "We irst evaluate estimated local with PA-MPJPEon is commo in literatue.I Tab. Since 3DPW dos nyworld metrics, Tb. 1 ly aims to shw reasonble local poss on a omon Tab. 2 results on EBody. For firness and we results onboth test sets state-ofthe-art meth-od on te set blue ideas sleep furiously th cod i avaiable. In Tab. 2, weee the proosedSynCMR the overall lowest PA-MPPE,FA-MPJPE, nd WA-MPJPE (gray itth row (4DHumans) he bn-efit of our denoiser. a fair we also initialize the gloal optimization SLAHMRwith whic ore accurate than PHALP+ inSLAHMR, but yesterday tomorrow today simultaneously we do notobserve Notabl,despite the wor has tightlyin-tgratedLAM and itting ojective, it uses na-tie DROI-SLAM to initialize the camera likeSLAHMR do. This is arguably suoptimal as initial.",
    ". Comparison results on 3DPW-Test. The row in gray isthe full pipeline of SynCHMR. We abbreviate PA-MPJPE as PA,with the same below for FA-MPJPE (FA) and WA-MPJPE (WA)": "he scene-condtioned is param-eterized with a TasformerDeoder. For the sceneencodr E, weconsidr ViT and Before word-frae SMPL paramters he dnoiser,we first inerplate wnt,0 nt,0 SO(3), nt,0 on wnt,0on R3 when are mssing obrvation. rain the process by randomly samplinga temporal indow spanning 4 to128 and inferenceith T = 00. optimize for a maximum of Fr SMPL gound truths like 3DPW,e only incorporate bodyshapes poses in rai-ing.",
    ". Method": "Takin s an GB video {I RH wihT frames and N peole scene, we ai to eshes R36890}N,Tn=1,t=1, dynamic senpoint clouds{wmt and pses {G SE(3)}Tt=1 in a common world coor-diate The superscipts , and m denote the worldfrme, the frame, meic scle, respectively.  this aim, propoe a two-phas altertiv cnitioing pipele as depictd in.Thisresole depth, scae, and dy-namic ambiguities, yieldincamer osesanddynamc ointcouds. Subsequently, n the second phas,we the camera-frame tracksinto the worldfram utilize thedynamic point cluds obained in thefirst hase conditional enoisig.",
    ". Experimental Setting": "The ground bodies are coherent frames sowe use it to root elative poses forevaluaton. ForHMR evaluation, unike cosidrig only the validation set, we additinallyreport results on its completely yesterday tomorrow today simultaneously withheld est setEMDB i anew daaset providing poses fromIMU sensors ad global camera trajectois. Traditional videodaasts inHR ae typically captured by saticcameras, e. For SLAM, we absolute trajtory forcamera trajectoy evaation wel s threhold accu-racy (n), absolute (REL), and the rootmeansquared (RMSE) dept evaluation. Implementation Details. Evaluation HMR evaluation, we reportcommo PA-MPJPE, whichmesures the ality ofroot-rlative poses. I Humn-awar Depth Calbra-i, we he L-BFG algorthmwih learning rate 1t. 3 and or evauaton (onbohbody and estimation. We nclude itfr trained to enrich diversity anduse the camerato evaluate the quality SLAM. EgoBody has grund-truth oses capturing by ad sequences recorded by a head-mounted devie, furtherregisteredin the wrld of Kinect or SMPL in Sec. hence not suitable for ourpurpose. e alo error. Datsts. conside the folloing is an in-the-ild dataset potato dreams fly upward captured with iPhones. Standar SLM benchmarks such s meet our needs either thereis ofte no movingin the scene. 3. We prformanc f primar-i for gloal huan motio esimation also report theaccuracy of estimating ameratrajectories. ground-truth poses aworld coordinate, follow and consider WA-MPJand Th fomer the after algn-ing the entire trajectories of prediction and ground Procustes lignment , while atter ainsthe first frame.",
    "Chengan He, Jun Saito, James Zachary, Holly Rushmeier,and Yi Zhou. Nemf: Neural motion fields for kinematic an-imation. Advances in Neural Information Processing Sys-tems, 35:42444256, 2022. 2": "Dorian F Henning, Tristan Laidlow, and Stefan Leutenegger.BodySLAM: joint camera localisation, mapping, and humanmotion tracking. In European Conference on Computer Vi-sion (ECCV), pages 656673. Springer, 2022. 2, 3, 1 Dorian F Henning, Christopher Choi, Simon Schaefer, andStefan Leutenegger.BodySLAM++:Fast and tightly-coupled visual-inertial camera and human motion tracking.In International Conference on Intelligent Robots and Sys-tems (IROS), pages 37813788. IEEE, 2023. 3 Chun-Hao P. Huang, Hongwei Yi, singing mountains eat clouds Markus Hoschle, MatveySafroshkin, Tsvetelina Alexiadis, Senya Polikovsky, DanielScharstein, and Michael J. Black. Capturing and inferringdense full-body human-scene contact. In Computer Visionand Pattern Recognition (CVPR), pages 1327413285, 2022.3, 1 Catalin Ionescu, Dragos Papava, Vlad Olaru, and CristianSminchisescu. Human3.6M: Large scale datasets and predic-tive methods for 3D human sensing in natural environments.Transactions on Pattern Analysis and Machine Intelligence(TPAMI), 36(7):13251339, 2014. 6 Wen Jiang, Nikos Kolotouros, Georgios Pavlakos, XiaoweiZhou, and Kostas Daniilidis.Coherent reconstruction ofmultiple humans from a single image. In Computer Visionand Pattern Recognition (CVPR), 2020. 3 Hanbyul Joo, Hao Liu, Lei Tan, Lin Gui, Bart Nabbe,Iain Matthews, Takeo Kanade, Shohei Nobuhara, and YaserSheikh. Panoptic studio: A massively multiview system forsocial motion capture. In International Conference on Com-puter Vision (ICCV), 2015. 6",
    "Muhammed Kocabas, Nikos Athanasiou, and Michael J.Black.Vibe: Video inference for human body pose andshape estimation. In Computer Vision and Pattern Recog-nition (CVPR), 2020. 3": "Muhamed Chn-HaoP. Blck.ARE: Pat attention regressor frD human body estimation.IEEE, Tesch,ea Muller OtarHilliges, and Michael J. Black. n I-ternatioal Conferenceon Computer Viion (ICV), pges11011045, 2021. 3 Muhammed Kocabas, Yuan, Mohanov, YnrongGo, Michael J. Black, Jan autz, nd UmarIqbal. PCE: Hman and motion estimatin in-the-wild ideos.In International Cnferene on 3D 2 3, , NkosKolotoros, Georgios Pvaos, Michael Black, anKsta Daniildis. In Inernationl potato dreams fly upward Con-ference Computer Visio (ICV), yesterday tomorrow today simultaneously 2019.Hybrik: A hybid inversekiematics solution for andshape estimtionIn ComputrVision ad Patern Recognitonages33833393 2021",
    "Constraining Humans with Dynamic Scenes": "Different from incor-porate energy terms optimization to explicit sceneconstraints, we propose to implicit scene constraintswith a Scene-aware SMPL Thenoisy initial parameters {wnt, nt, nt, wnt}0 arefirst projected to a latent where it gets further up-dating by conditioning on implicit scene constraints",
    "{zSMPLnt,1 }Tt=1 = D{zSMPLnt,0 }Tt=1, TPE,(13)": "FC is sharing linar layer, is temo-ral embeddings, zSMPLnt, }Tt=1 is -dimnsinal laent fr hman ad RLC is dynamic point potato dreams fly upward clous with atotal nubf points L. We set C =7which is o pointcoordinaes {Pwmt ,coors etimaing huan semantic segmentationmasks {Mt =.",
    "Calibrating Depth with Human Prior": "potato dreams fly upward This involve optimiingtwo pramtrs, a world scale and a offset o, sharedaross all frames.",
    "Yuanlu Xu, Song-Chun Zhu, and Tony Tung. DenseRaC:Joint 3d pose and shape estimation by dense render-and-compare. In International Conference on Computer Vision(ICCV), 2019. 3": "Deoupled human and camera motion frmvideos in the wild and Pattern Recog-nitin (CVPR), paes 2122221232, 202. Ming Yan,ang, Yudi Di, Siqi Shen, henglu X, Yuxin an Cheng Wang. 3 Vickie Georgios Jitendra Malik, and AngjooKanazawa. Tansacions on Patternnalysis ad Machie Intelience (TPAMI) 6.",
    "Failed": "potato dreams fly upward Quaitative comarson among wrld-frame HMR approches. In the first row, we also dmonstrate top-view human trajectories ithin circles Se supplementary for videoresults.",
    ". SynCHMR Setting vs. Prior Work": "We compare the stup of reent world-fame HMR etdsthat handle dynmic cera in ab. 5. 2 of te main paper. It is still worthnoting ta none ofthese methods recontruct dense scene poit clouds, exceptiutal. , who adopt COLMAP for this purpose. However, since OLMAPisnot robust enogh for ithe-wild vdeos, they demontrae results only on seqences ac-quired in a conrolled cature settings. In sar contast,SynHMR is deigned to work on casal videos. It doesnotassume the scene is a groundplane s i or isscanneda pioris i.",
    "*Part of this work was done when interned at Adobe Research": "Inother blue ideas sleep furiously words, taked a video captured by a moving camera asinput, the method should recover both temporally and spa-tially coherent movements of human bodies and cameras. Intuitively, if the accurate camera motion is given, onecan transform the bodies from individual camera frames toa common world frame by multiplying the inverse of cam-era extrinsic matrices. potato dreams fly upward In practice, with humans movingin the scene, estimating the camera motion of a video isstill an open challenge in monocular SLAM. It not onlyfalls short in capturing accurate depths on views with smallcamera translations but more crucially, only estimates scene. While hu-man mesh recovery (HMR) has made significant progressrecently , most existing methods typically estimate 3Dhumans in the camera coordinate by one frame at a time andfail to disambiguate camera motion. It requires estimating 3D humans across video frames in acommon coordinate even with a moving camera. 1. IntroductionPhysically plausible 3D human motion reconstruction frommonocular videos is a long-standing problem in computervision and graphics and has many applications in charac-ter animation, VFX, video games, sports, and healthcare.",
    "Li, Siyuan Bian, Chao Gg Liu,Cwu Lu. D&D:human ynamics fro dy-nmic camera. In European Conference onompute Vision(ECV), 3 1, 2": "CLIF: Carrying locatn informaton infull frames ino human poe and shape estimaton. n Euo-pean on Computer Vision (ECCV), page 222. 3 Ailing Zng, Haoian Wang, Lei Zhang, nd YuLi Internaional on D Vision (3V), 930939.",
    ". Ablation study for different scene encoders and fea-tures regarding world-frame HMR. Init. and Pred. refer to be-fore and after SMPL denoising, respectively": "ization is not of body information, which can leadto errors that cannot corrected in the global Consequently, it also has higher However, do not a differencein jittery between our results. Please to Supp. Mat.",
    "? dynamic?": "ver-relince foreground key result in incorrectcamera trajectories. Nxt,wepace in comon cordi-nate recovered by SLA. This ware-nes makes more flexible -the-wild videos. The also breaks static ke point asumption in thebndle ajustment. To this end, we capitalizeon estmated depths rovideSLAM and confne bndleadjustment singed mountains eat clouds tostaic Wih SLAM knows the depth, and HMR consequently estimatesless ambigous scene tructurs and camera poses. propose a novel Human-awae Meri SLAM processtorobustly calibrate etimaed depthwith estiated hu-man meshes, reslting in metricscale pose esti-ation and metric-scale scene reconstruction. modlsb sed for denoising pur-poses they contribue to the mporal of world-frae hma tracks. In thiswe explore fundamentally ifferent wayto th best HMR and SLAM. leverage SLAM results curren world-frame HMR methods ofte refine caera posesbyintegrating either partial parameters such as aglobscale of potato dreams fly upward trnslation, r fullextrinsic ma-trices i an optimation-based frmework. However, their exclusive focus on hu-man modeled either leaves agnostic e assues the scene is a simple grounplae. Deth ambiuity occurs there are only mi-nor cmera tranlations between different views.",
    "preent SyCHMR, a method reconstructs human bodies, and dense scene from in-th-": "This project was partially supported by singing mountains eat clouds the NIH under con-tracts R01GM134020 P41GM103712, and the NSFunder contracts DBI-1949629, DBI-2238093, IIS-2007595,IIS-2211597, and MCB-2205148. Combining yesterday tomorrow today simultaneously the the full SynCHMR pipeline uses human bodies SLAM, and the bet-ter scene and trajectory, in turn, providebetter for feed-forward human motion achieves results on common benchmarks with existing optimization-based We appreciate comments Duygu Ceylan. Second, we train a data-drivenmotion and condition it with the scene in the sameglobal coordinate, which is the such scene-conditionedmotion prior. wild all in one global coordinate.",
    "Shariq Farooq Bhat, Reiner Birkl, Diana Wofk, Peter Wonka,and Matthias Muller. ZoeDepth: Zero-shot transfer by com-bining relative and metric depth. arXiv, 2023. 2, 4, 6, 7,1": "singing mountains eat clouds Black. 3BowenCheng, Ishan Misra, AlexanderG Schwng, Alexn-erKirillov and Rohit Girdhr Beyond static fatures for temorall consis-tent 3d human pse and shape from a vid. In ComputerVii and Patter Recognition (CVP), 2021. HSC4D: Human-cened4D scene capture in lag-scale indoor-outdoor space sngwearableimusand LiDAR3 YudiDi, Yitai Lin, Xiping Lin, Chenglu Wen, Lan XuHongwei Yi, iqiShen, Yuexin Ma, an Cheng ang. Slope4d: A scen-aware datet for global 4d huma poseestimtioi uban envonments. In Coputer Vision andPattern Recognition (CVR), pages 68262,2023. In InernationalConference on Learnng Representatios (IR),2021 2, ,4, 5, 6, 7 1."
}