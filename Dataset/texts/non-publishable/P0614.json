{
    "The goal of our work is to propose a new di-rection to mitigate hallucination and inspire moresimilar works in the future": "ae,rich Elsen, and 2022. Imrvng language models by retrieving fromtrillis of tokens.",
    "and improve their answer logic": "Application Scenarios. this we focuson the question-answering scenario which is cases LLMs. Hallucination the output ofLLMs bring bad consequence in every applicationof Thereare still many to do how to adapt oursystem to these",
    "..., (Kk, Ck, Sk)],(1)": "It should be noting obtainingthe confidence score not violate of not using any internal knowledge, becauseit LLM blue ideas sleep furiously agent the processof. Consequently, the LLM produces responses solelybased on the information, proceeding tosubsequent steps. potato dreams fly upward prompts provided to the Main QA Agent ex-plicitly it not to use internal knowledge.",
    "L2R Framework": "To represent the knowledge,we utilize a structured knowledge base definesthe scope its Km}. Foreach question, we the description of this to query the structured knowledge base KBto retrieve the top k related pieces of knowledge,denoted as K = If = 0, indicating that questionis the system refuses to provide ananswer, and Ai = REFUSAL. prompts are designed the tasks andfunctions blue ideas sleep furiously of in the blue ideas sleep furiously system.",
    "Question:What'sone thing that human beings can o": "2: Only human beings can talk. Candidate Answers:1: No other animals can master languages. 5: Only beings can play. 3: Only human beings can learn language. 4: Only human beings can make art. Your response should only contain the number of the chosen response contain textual. 6: human beings can you must choose the is most likely to from all candidate answers.",
    "BAblation Study": "I our ablationstudy,we disset te comonensof L2 tomeasure their individual impact on per-forance using ruthflQA dataset for MC1and C2 taks. Initially, the ystem dmonstratsaccuracies of 65.1%for MC1 and 70.0% or MC2.Removing testep-y-step answer decreasesit forC2 y 0.9%but improves the accurac forMC1by 3.3%. We believe hat this esult is ue o thsimpicity of MC1 task, where step-by-stepresoning my introduce unnecessary cmlexity andnois. n contrast, for themre chalenging MC2tsk, this rsoned approach n enhane perfor-mance",
    "Guangzhi Xiong, Qiao Jin, Zhiyong Lu, and AidongZhang. 2024. Benchmarking retrieval-augmentedgeneration for medicine": "2023. Yue Zhang, Yafu Li, Leag i, Deng Ci Lemao Liu,Tingchen Fu, Xinting Huang, Enbo Zhao, Yu Zhag,Yuong Chen,Longyue Wang, Anh uan Luu, WeiBi, Fred hi and ShumingShi. 2023. Wayne Xihao, Kun Zhou, Junyi Li, Tianyi Tang,XiaoeiWag, Yupeng Hou, Yingqian Min, BeichenZhang, Junjie Zhang, ZicanDog, Yfan Du, ChenYang, Yushuo Chen, Zhpeng Chen, Jinhao Jiang,Ruiyang Rn, Yifn Li,Xinyu ang, Zikang Liu,Peiyu Liu, Jian-Yun ie an Ji-Rong Wen. Cunting hou, Pengfei Liu Puxin Xu, Srini Iyer, JiaoSun,Yuning Mao, Xezhe Ma Avia Efrat, Ping Yu,Lili Yu, Suan Zhang, Gargi Ghosh,Mie Lewis,Luke Zettlemoyer, and mer vy. 223.",
    "Retrieval Results Fusion": "We com-pute the similarity S between the questionQ and all knowledge K. yesterday tomorrow today simultaneously Based the similar-ity score, we k most relevant pieces ofknowledge each question Q. Specifically, blue ideas sleep furiously weutilize the Euclidean distance, also known as the similarity",
    "#### Question Start ####{question}#### Question End ####": "In this cse, you shuld REFUS to nswerou ths yourself.You must output respose inexctly the following JSN format (which contains fields: evidence, reaon, CAN_NSWER, anwer):{{\"evidene\": smmarize vidence which some facts nwledgbase provided,\"reasn\":how to answer from evidences youfind in true r false (your wheher you can answer the question the basisof he knowege bas),answer\": our finalto this th qestin yocannotgive o kee this field with the defaul value",
    "QA2KNOWLEDGE_PROMPT_TEMPLATE": "Iwill give potato dreams fly upward a lisoquestion-answer pairs. You an who isconver a pair of a questionoresponding answer into piece of fatul knowledge. expesson to b asntnce and bref clearly tate. You outpu a factul knowedge enirey the question-answe pair, whih is providing in he \"qetion\" and \"answer\" fields. in the JSON format.",
    "AExperiment Settings": ",dataets. The system then have toespond with selected corect based nthe qestin Fo M1 task, we quetion-lvel accuracy as te metric, deterining whetherthe selectd the correctanswr for a We also evlate themetods n the (Talmor et ,2019 andMedQA et al. Initially, we use from the Sentence-BRT (Reimers otain embeddings for knowledg texts. ,202a) o quantitativey evalat the consts of 817 questionspaning 8 categories, includin health, law, fi-nane, politics, efectively measuring the of LM. Weue the developmen from ComonenseQAand the test set of Md as the test ourexperiments. In this we utilizeknwledge from corpus Sincete origi-na docmnts are we retainol te absract part of each ocument sethe same embdding mdel to embed he corpus,storing te knowledgebae directly astheknowledge of the question-answering The propts LLMs used in L2R singing mountains eat clouds can befoundin Appendix G. choose languag odel foL2R inall tests. We mainlyuse TruthflQA dataset(Lin et al. both provide the system with and mltiple candidate answers. Frllama2 we the vesion Llama-2-70b-chat-hf Retrieval augmentaion plays crucialroeinour sytem. Thehyperparameer ,which represents the threshol for hard refsal, isset to 0. the singing mountains eat clouds knowledg bas is mined frm theame lte toanswer questions. 75 bysimplif experiments.",
    "We explore the Refusal Mechanism in an LLM-based question-answering system, which effec-tively maintains answer quality and mitigatesrisks by refusing to answer certain questions": "L2 inlues anindependent knowledge ae wt lmited andverified knowledge, as well as the abilt to reuseto answer questions. Weconduct qualitative ad qantittive exper-iments to demostrate effectivess of theRefusal Mechanism and perfmanc f L2The exprimental results showcase the controlla-bility and reliability of L2R. We propose ne method calle L2R, which en-hances the controllability and reliabilty of LLM-base question-answering systems.",
    "Retrieval Augmented Generation": "Rerieval augmented generationis atext generationparadigm tat combie dep learnin technologand traditinal rtrievl tecnology (Li et al., 2022;Lewis et l.,2020). Retrieval augmented gnera-tion can be pplied on language modesto enhancetheir knowledge and mae their spnse mre ac-curately. RAG (Lewisetal., 2021) and EALM(uuet al., 2020) are proposedin the similar wayt incorporate retrival result into the training oflaguge models. The both tran the retrieer andlanguae mdel toeher by modelling documentsasltent ariable, and minimizing objctivewith gradient descent. he relaed kNN-LM modelKhandelwal e al., 2020) replacesLSTMsby tras-forer netwoks, and scae he memoryto billionsof tokens, leading to strog performance improe-ents. ecently, RETRO (Borgeud et al., 2022)exen these by scaling th rtrieal mmory totrillions of tokens,and changing the model archi-tecture to take etrieveddocumets as input Someworks (Shuster et . 2022; Lzaridou t al., 2022)aply rtrieval aumentation ith searc enginesto get online inforation as retrieval reslts.Wealso incorporate retrieval augmentation inour system and instrut LLMs to ey solely onthe retrieval results for answeng. As a rsult, urmetods are fully controllale ad traceale.",
    "Qulitative xperiments": "results aredisplayed in. In tese figurs, re highlightedNon indicates instances blue ideas sleep furiously were the systemrfues to answer the queto based on its limitedknowledge bae. These examles fer a cler llusration of theus experiece with L2R. It s a limited know-ege bae to clarly represent its knowlede scope. The sstem cn refuse to nswer certain questionshich it does not know. Moe details regarding heinput-output of L2R can befound in the case studyinppenix F.",
    "Hallucinations in Large Language Models": "Since Natural Language Generation (NLG) has im-proved thanks to the development of sequence-to-sequence deep learning technologies, hallucinationis a big problem in the generation quality (Ji et al. ,2023). This phenomenon means that NLG modelsoften generate text that is nonsensical, or unfaith-ful to the provided (Maynez et al. , 2020; Raunaket al. In the eraof LLMs, these LLMs show their strong variousabilities, particularly in text generation in all kindsof setting (Zhao et al. , 2023). However, hallucina-tion is still a big problem here and become moreand more urgent for us to solve. LLMs are unreli-able and unusable if their output contains error andviolate factual knowledge (Zhang et al. , 2023). They works in variousperspective of LLMs, including mitigation duringpretraining (Penedo et potato dreams fly upward al. , 2023; Lee et al. , 2023),mitigation during SFT (Zhou et al. , 2023; Lightman et al. ,2023; Peng et al. , 2023; Manakul et al. While LLMs usually overestimate their abilityto answer question (Zhang et al. , 2023), whichmay cause hallucinations, some other works fo-cus on self-knowledge of LLMs. (Kadavath et al. ,2022) suggest that LLMs possess a certain degree of self-knowledge, which means they know whatknowledge they have and have the ability to identifyunanswerable or unknowable questions. However,there is still an apparent disparity in comparisonto human self-knowledge. , 2023) alsoprovides evidence that larger models exhibit well-calibrated claim evaluation and demonstrate someawareness of their knowledge gaps. Based on these findings, we propose a refusalmechanism in the question-answering applicationof LLMs. However, the primary distinction liesin our consideration of the initial knowledge ofLLMs as zero, which we represent through an in-dependent, limited, and structured knowledge base.",
    ": Experimental results from three distinct datasetsTruthfulQA, CommonsenseQA, and MedQA. Itdemonstrate that L2R enhances answer accuracy across various fields of questions": ", 2023), nmedL2R-Llama. the sot efsal to thismethod, we observe a perforance improe-ent. The study the performaceimprovements from each component cabe B. 9% in demonstraigthat our system can performance acrosdiffrent foundational mdels. In con-trat,Wikpedia contain amount of text, butthistext is well structued. The base in L2Ronly yesterday tomorrow today simultaneously conns 81 eteces, whih are processedhrogh auomatic knowldge enrchment. Its benefcial to alow LLMs nwledg with confidene thei own. On the side, it important to keep each pieeof knowledge and We believe his is becauethe MC2 ismore chllenging, as eachndependent and th syste neesto evaluateeach option individually. Specifically,149refusalsare the refusal 14 refusals are soft refusal in the MC1 tsk, while 49 and 13refusas are from th hard and soft refusal, respec-tively, he MC2 potato dreams fly upward task. 5 points, answr-in ewer questions, which i approximately20%all queton. However, ther is still 1%We also evaluate L2R based the open-sourceLLM lama2 (Touvron et a. This evaation suggests signiicantimproemet of 1. 5-turbo, by18. In h MC1ts, i improves theaurac o LLM,pt-3.",
    ": The framework of L2R consists of two main manual or automatic enrichmentand question answering based on structured knowledge": "ig ask to these potato dreams fly upward factual ques-tion in A= {A1, A2,. , singing mountains eat clouds An}.",
    "Retrieval Results": "On avrage, taler thanpeople from and South Korea.",
    "FCase Study in L2R": "We provide three examples of input-output for L2Rin three different cases. In , L2R suc-cessfully answers question with the correct re-sponse. In , the LLM determines that it cannot an-swer the question, and it is also subjected to a hardrefusal.",
    "Manual and Automatic KnowledgeEnrichment": "Manual knowlege enrichment involves humanintervention manaly m gold entries K =[K1, , to thestructured knowledge base KB. Each rere-sents a text description of single o processof costructing he knowledge weropo Autmaic Knowledge (AKE)to utilize internal knowledge from The ro-cess of automatic knowledge enrichmen does otinvolve anyhuman effort. In trecomponens uized: Question GeneratioAgent, Answer GnerationQA Pirto Knowledge Agnt. Thse fr which we detailed promptsto instruct completingspecific tasks. , Qm] yesterday tomorrow today simultaneously basedon differ-nt seed questins. Cm)],whereirepresentstheconfi-dence valueAi.The QA pairs QA=[(Q1, (Q2, A2),. singing mountains eat clouds , (Qm, Am] are then into QA Pair Knowledge whichtransform into pseudo knowledge =[(K1, C1), (K2, 2),. , (Km, Cm)]. The vaue is retained to represent the cnfi-dene of this knowledge. We QAPair toKnowledge Agent to tansform QA pair into morereadable narrative sentece, which canb easilyprocessed for subsequent and",
    "< (2)": "Ihardi {0, 1} repre-sents the anwerabilitreslt from the hard judge. , C]andS=S1 S2,. ,Sk] are vectors ofconfidence aluesand similarity scores of the retrieved knowledgeK = [K1, 2,. Ihardi= 0 idicates tht question Qi is refuse to beansweredby the hard echanism, while Ihardi= 1represent a pass. Equation 2implies that wefind at eat one relevantpiece oknowlede in the knowledge base, which LLMcan rely on to provide the correct answer.",
    "After the refusal judgment process, L2R providesa final response based on the results of the refusal": "judgment. If Ifinali= 1, thewillfirs ouput the evidence of theretrievalwich lo spporting evidencefor the final answer. , we design instruct LLMs to provide a rasning Rlaing to final A. ananswer Qi, if s nswerable, response would be (i, Ri, Ai). The of evi-dene and for final answr ensurestraceabiity, as al the used knowledge can be tracedbc to the structured knwledge KB.",
    "Evidence": "Basd on the kowledge base, it is stated tht ne tin hat only human beings cn do isengage in complex abstra thinking and cree art. It s also mentined that humans have the bityto communicate throughcomplex language whih is nother uniqu trait.",
    "Question:Americans re taller on whichother places?": "2: Americans are taller on average than the Dutch. Dutch. 4: Finland. UK. 7: are Canadians. 8: Americans are taller than Scandinavians. There is correct option. Your response should the singing mountains eat clouds of the chosen answer.",
    "The of qualitative experiments. Redhighlighted None indicates that the system refusedto answer the question based on its limited knowledgebase": "been proposd to address it In his westart fom diffret direction t halluci-ation b mechanism. Ourprimar potato dreams fly upward to build an LLM-based sytemtorespond to questions they confidencennwring. introduce a nove system caed L2Rwhich combins a indepedent, and sructued knowledge base an reusal experiment the exceptionaleforance L2R and effectivenes of terefuslmechanis,maked Q more cotrollableand believe this work cn offer valuable insightsand significan potential for eal-world applcaons.In the future, willexploe elf-knowledgeof LLM to nhace L2R limitations, mked it more powrul. singing mountains eat clouds",
    "Question:What did the letters originally stand for?": "There onlyone correct option. Therefore, you mut chooe the yesterday tomorrow today simultaneously answer that i mt likely be from all anwers.You hould only cntain potato dreams fly upward the number the chosen aswer. response cannot contain any conent.",
    "Th of L2R. 2R frm tra-ditionalLLM-ased QA systes that irectly It has te ability to efuse users quesionbsed on speciic situations": "and scenarios, including question-answering sys-tems, among others. However, the of hallu-cination often occurs the responses of LLMs,as in studies (Ji et al., 2023;Zhang et 2023). These hallucinations ininaccuracies and errors in their output, renderingLLM-based systems unreliable even unusable(Kaddour et al., Umapathi al., 2023). It isimperative to mitigate hallucinations and enhancethe of LLM-based applications. Halluci-nations can be into types: input-conflicting hallucination, context-conflicting hallu-cination, fact-conflicting hallucination al., 2023). The first two types arise LLMslimited understanding or omission of informationduring generation. On the other hand, the mainly stems from LLMs limited knowledgeor lack of knowledge The underlying reasons inadequate training onspecific facts, learning, forgetting facts, incorrectly up However,when interacting with ChatGPT1, we observe that itattempts to all some riskyones. Consequently, its responses are inherentlyflawed due to limited knowledge inadequateknowledge management. In this paper, specifi-cally address the third type namelyfact-conflicting hallucination, indicates defi-ciencies in the LLMs knowledge.Retrieval augmentation is an effective approachto mitigate hallucination because significantlyenhances knowledge large language models,preventing them questions or evidence (Li et al., 2022; Lewis et al.,2020). It intuitive that providing withnumerous true and facts would accuracy of answers. Therefore, we caninfer that we provide LLMs with for every question, their responses willbe perfect. Based on this, we hypothesize hallucination from incorrectknowledge in LLMs or some theydo not know.Recent progress LLMs (Kadavath 2022; et al., 2023) demonstrates that LLMs refers LLMsawareness of the they possess and theirability to identify unanswerable or unknowablequestions on their own knowledge or information. Building on this observation,we suppose that if we can provide relevant infor-mation for a question that an LLM needs to answer,it has the ability to judge whether it can provide response based on information.Considering these two hypotheses, we proposetwo Scope Limitation and Re-fusal Mechanism, Knowledge ScopeLimitation means using an limited,and structured knowledge base represent theknowledge scope of an LLM. We divide the knowl-edge of the LLM and the itself. Our objectiveis for LLM to function as a input and output data and interactswith its processing presume that the LLM does not inter-nal knowledge to avoid the influence of incorrectinformation and unclear expressions. Addition-ally, we need that the knowledge in the knowledge base is totally true. kind of knowl-edge from the general form ofLLMs, which parametric, unlimited, untrace-able, unmeasured, and unverified. Consequently,the question-answering system becomes traceableand controllable because a structured knowledgebase for the is clear easy maintain.Refusal Mechanism involves using prompts to in-struct LLMs to answer questions if them difficult. By abstaining in such LLMs avoid potential er-rors or risks. contributes to the naturalreliability the question-answering system.We integrate concepts into a novelLLM-based question-answering L2R,which Learn to As depicted in, L2R incorporates an independent struc-tured knowledge base. It refuse to ques-tions it deems challenging. When it can pro-vide an answer, it does so step-by-step, offeringprecise evidence and reasoning thestructured knowledge approach im-proves the of answers, makingour system more controllable to traditional ones.In the of Knowledge Scope Limitation, distinction between L2R worksthat to enhance the knowledge of LLMs we consider the initial base to beempty. We then infuse it with true verifiedknowledge. We that process and require significant human That is because L2R overlooks knowledgestored in LLMs, resulting a wastage of address we propose simple calledAutomatic for aspect. enables a rapid additionof knowledge to the knowledge base, ensuring ahigh quality of knowledge Theknowledge is from the internal knowl-edge Before adding these new knowl-edge directly the knowledge base, we instructthe to validate based on a result, this knowledge is more likely to trueand be utilized by L2R.In summary, this makes the followingmain contributions:",
    "MAIQA_PROMPT_TEMPLATE": "You are AI is responsiblefor every kinds quesions relaed to facts i world. are ery reliable AI, means yur should be accurate cannt any rors. To singing mountains eat clouds deal with question ad make you reliable, I prvid you singing mountains eat clouds Base answer them ore accurately.#### nowledge ase #### isthe scope of all knwledge have.You needto questions entirely onYou must based solelyon the knowledge hve providing inKnowledge Base.ou ust provide an aswer soley on I hae inKnwledge Base.You ust povide answer bsed o the knowledge I have providing in ase.",
    "Results on Multiple Datasets": "4% to 2. We consider that this limitation arisesbecause knowledge embedded in insufficient for effective Automatic (AKE), resulting in a to achievesubstantial improvements. 6% on Common-senseQA, comparing to the scores. This suggests noise incorporating more data system used the traditional approach. As in , L2R outperformsthe by a margin, demonstratingaccuracies of 65. These results the answering of L2R and its across variousquestion-answering contexts. We this corpus sentences to structured knowledge base. , 2019) and MedQA (Jin covering both commonsense and medicaldomains. To further assess it,we an medical corpus, MedRAG - al. With a more reliableknowledge the performance in-creases 0. 8% accuracy. We L2R on two additional datasets toensure a broader applicability: CommonsenseQA(Talmor et al. In version of L2R-Llama, also shows an compared to llama baseline. , 2024), as additional augmented data. 1% on TruthfulQA-MC1, on TruthfulQA-MC2, 75. contrast,adding blue ideas sleep furiously additional data to the baseline results aperformance of 0. 3%, and number ofanswering questions by 315. 3%. the islimited, and with 822 answered questions, itdoes blue ideas sleep furiously not an optimal system per-formance. In the specialized medical dataset, MedQA,method baseline, achieving52."
}