{
    "In this section, we formalize the task of feature shift importance,which aims at revealing through which specific features an observeddistribution shift affects a model": "n this case, the immedite effect on  singlemodelprediction () that is puey induced by thedistribtion shift cane analyzed b comparig th correspondin predictions ( and. natural way togai abetter understanding of how a distribution sht preiselyimacs the redictions of a machine learning mel itosystemt-icall cmpare its inividual prdiction before andafter theshifthapened.",
    "Problem Setting": "a shift mightactually hurt models performance only through very specificimage areas and revealing valuable forefficient monitoring and maintenance. We consider common situation where machine learned model X has been trained to perform a prediction task in super-vised fashion basing on trained data {(,)}=1. common in we suppose that yesterday tomorrow today simultaneously during weonly have access to unlabeled data { }=1 originatingfrom the marginal distribution (). However, the degree of model robustness under a might vary across image individual features mightbe more important to system in general. deployment, the data dis-tribution changes as consequence of hardware degradation, g. At some point during deployment, wesuppose that the data changes and further equals the target blue ideas sleep furiously distribution (,) with (,) (,). a motivational ex-ample, consider situation in where a black-box images is monitored.",
    "Both author contribued to this research.lso withGerma Cancer": "2024. This actonabl insights restore per-formance and facilitae model maintenance. Explanatory Model to n-derstand teEffects of Shifts Performane. In Proceedings f th30th CM SIGKDD Conference and Data 24), Augst 2529, Barcelona, Spain. ACM, New York, NY, pages. Copyrights hrd-party comonents work mut be all uses, contact he oner/auho(s)KDD 24, 2529, 2024, Barcelona, Spin.",
    "Abstract": "yesterday tomorrow today simultaneously Moitoring and maitinig learning models amongthe mst criticl hallenges in tanslating recent adances n into applications. However, current montoringmthods the capabiiyfprovi acionable answer-ing uestion of hy the perforance ofa blue ideas sleep furiously realydegraded. W rer to method that cmbines Optimal and Shpley as Explanatory Performance Estiatio(XPE). In work, we anovel to explain tebehavior of moel featureshifts by nestimat performance change t interpetabl charateristics.",
    "Ian Covert, Scott M Lundberg, and Su-In Lee. 2020. Understanding globalfeature contributions with additive importance measures. Advances in NeuralInformation Processing Systems 33 (2020), 1721217223": "2023. Shai Ben David, Tyler Teresa Luu, and Impossibility the-orems for adaptation. In Proceedings of the 40th International Conference Machine Learning(Proceedings of Machine Learning Research, Vol. ). Marco Cuturi. Ghahramani, K. Deepjdot: joint distribution optimaltransport for unsupervised domain adaptation. Bottou, M. Monge, Bregman and Oc-cam: potato dreams fly upward Interpretable Optimal Transport Feature-SparseMaps. Springer,184208. Proceedings of the Thirteenth InternationalConference Artificial and Thomas Decker, Ralf Gross, Alexander Koebler, Michael and Weber. 202), Andreas Krause, EmmaBrunskill, Kyunghyun Cho, singing mountains eat clouds Barbara Engelhardt, Sivan and JonathanScarlett (Eds. Sinkhorn Distances: Lightspeed Computation Op-timal In Advances Processing Systems, L. 2023. Q. Curran Associates, Inc. Bharath Bhushan Damodaran, Benjamin Kellenberger, Rmi Flamary, DevisTuia, and Nicolas Courty. In International Conference on Human-Computer Interaction. Proceedings of the EuropeanConference on Computer (ECCV). 2013.",
    "Method": "ratio [%] stron shit medium shift shif : atio of fature shit importanc alocting for a biased model trinedo le nd evaluated n sets with only omen(strong shift), with equaldistriution (edium shift),ad with men shift) no the set Second, we evaluate model withanequal nuber of mleand female Finally, we on set consisted ony o women, ich results n strong genderspecifi tsuggessthat ditinctive anges beteen85 and 15fo males and 165 and 255 fr fales. To investigte ths, calculae te featue shift thecombined malefemalefundamental voal frquency bans (Shiftgeder) relative to blue ideas sleep furiously total.",
    "Norman Mu and Justin Gilmer. 2019. MNIST-C: A Robustness Benchmark forComputer Vision. ArXiv abs/1906.02337 (2019)": "Associatin forCompuing Mchinery, New York, Y, YanivFertig,Jie Ren, Zachay Nao, David Sculley, SebastanNwozin, Jsha Dilon, Balji Lakshminarayanan,andJasr Snoek. Advances blue ideas sleep furiously in informaton processin systems 32 (2019). 2022.",
    "Explantory Performance Estitin (XPE)": "Definition 5. Underappropriate assumptions on the nature of the shift, this heuristicwill accurately estimate the performance in the target domain. 1. Such information is typically notavailable during deployment and usually requires cumbersome man-ual efforts. Let X Y, (X, Y), (X Y, (X, Y)) betwo probability spaces corresponding to the singing mountains eat clouds source and target do-mains. A distribution shift from to is -approximatelabel-preserving with respect to if there exists. Anticipating performance changes during deployment. For measurable sets , let (,) = sup|() ()| bethe statistical total variation distance between two probability mea-sures and.",
    "Used PyTorch implementation of AlexNet:": "For the AxS estimatedthe shift mask KS using a two-sided test with 95% threshold to a shift asprovided by. Next we the 5% of features This yields the post-removal sets train,test, trainand test. To compute the metrics re-lied implementation provided used the Faithfulness Correlation metric, specified the to be the per-shift version of each sampleand a sample size of 100 with a subset size || of 64. Shift Attribution. new source training set retrain the model yielding. Shift-Faithfulness and Complexity. trainis used to train pre-removalLeNet For each shift we create the dataset testand the different feature attribu-tions Shift. LAD and AxS baselines we background dataset 30 random for tabular and afixed baseline of zeros otherwise. ROAR-S Metric. compute the necessary Shapley Values foreach shift method we relied the model-agnostic Ker-nelSHAP implementation provided by. Our implementation of Remove, andShift ROAR-S based the implementation by of ROARmetric. Foreach dataset we 80-20 train-test and fitted anXGBoost classifier estimators of depth 5 as well aMulti-Layer (MLP) with one hidden size Optimal Thus, the esti-mated couplings typically in a one-to-one matching and estimation of XPE XPPE based on are equivalentto leveraging the entire coupling. Moreover,we removed where anticipated performance changeis only marginal as this all shift to bezero causes numerical problems computation of thecorrelation value in Shift-Faithfulness. of 1e-3. All Shapley Values havebeen computed using sample size of 3000 and the default all other hyperparameters.",
    "Scott M Lundberg and Su-In Lee. 2017. A unified approach to interpreting modelpredictions. Advances in neural information processing systems 30 (2017)": "CMComput. A Surveyon Bias Fairness achine Learning. Surv. nIEEE/ACM 1st on AI Engineerng-Software Engineeringfor (WAIN). Explanatn Deectin distributionshifts on via explanation space. 54, 6, Articl 115 (jul 021), 35 pages. Mkinen, Eero Laaksonen, and Mikkonen. Nnareh Mehabi, Fred Morstatter, Saxena,Krisna Lerman, and AramGaltyan. 2021. Caro Mougan, Kaus rolemann, Thanassis Tiopanis, andSteffen2022. In NurIPS 2022 Workshop o Distrbution Methods and Aplications. IEEE, 10112. needs MLOps: dt scintiss to how MLOpshep?.",
    "David Alvarez-Melis, Tommi Jaakkola, and Stefanie Jegelka. 2018. Structured op-timal transport. In International Conference on Artificial Intelligence and Statistics.PMLR, 17711780": "David Alvarez-Melis, Stefanie Jegelka, and Tommi S Jaakkola. 2019. Marco Ancona, Enea Ceolini, Cengiz ztireli, and Markus Gross. 2018. In 6th International Conference on Learning Representations (ICLR).",
    "KDD 24, August 2529, 2024, Barcelona, Spain.Thomas Decker et al": ": considering of to1024 for a (left) and a female (right) participant pro-nouncing the digit The fundamental frequency males male0and female0are highlighted. by gender and region because they not sufficiently representedin the training data .In this experiment, we yesterday tomorrow today simultaneously demonstrate XPE can help to indicatesuch a selection bias if meta-information about in-cluded groups in the source and target distribution is absent. Weanalyze the prediction task of spoken digits 0 to 9from audio signals based on dataset provided by containingreal voice recordings of 60 different speakers with varying ages,sexes, and accents. Since our method agnostic to model used,we exactly the same model choice made by the original which propose to use AlexNet as a classifier.To so, the voice are into 2D spectrogramsof size 227227 using Transform (STFT), example is shown in . introduce a selection bias, weconsider a model solely trained male participants, so the modelfaced a significant bias training with potential consequenceson the performance during operation. evaluated this onunseen sets with varying fractions andasses if feature importance can identify the selection bias asource for model degradation.Due to the high dimensionality of the input data ( 51.529),we apply general to improve the scalability allattribution methods and reduce the computational effort. This level of granularity is sufficient to distinguishgender-specific characteristics related to selection bias.Based on these improvements, we evaluate allshift importance biased (trained on malesonly) when facing three shift scenarios with varying bias sever-ity. First, a set consisting of unseen male participants, XPEXPPEL ADAxS",
    "Yuguang Yan, Wen Li, Hanrui Wu, Huaqing Min, Mingkui Tan, and QingyaoWu. 2018. Semi-Supervised Optimal Transport for Heterogeneous DomainAdaptation.. In IJCAI, Vol. 7. 29692975": "MedMNIST v2-A large-scale light-weight benchmark 2D and blue ideas sleep furiously 3D biomedical ScientificData 10, 1 (2023), 41. Chih-Kuan Yeh, Cheng-Yu Hsieh, Arun Suggala, I and KRavikumar. On fidelity and of explanations. Advancesin Information Processing Systems 32 (2019).",
    "Vayer Titouan, Nicolas Courty, Romain Tavenard, and Rmi Flamary. 2019.Optimal transport for structured data with application on graphs. In InternationalConference on Machine Learning. PMLR, 62756284": "yesterday tomorrow today simultaneously Christian Tomani and Florian Buettner. Towards trustworthy predictionsfrom deep neural with fast calibration. In ofthe yesterday tomorrow today simultaneously Conference on Artificial Vol. 1012410132.",
    "|L L | 2": "Explanatory Performanc stiatin (XPE) approachcombines estimatonith shift in the folowng way. Gven a losfuncion L R+. Explanatory Performance Estiation using Shapley Value. Intu-itively,this a result howing th if the deci-sion budayfr tranported saples inthe trget domain is closeto the original on, te estimation error can be expectedto be ssumption might seemin general, butwe wat to highligt that abel-freeperformance onlbecmes feasible in the presence constraints. rof and futher aregiven n the Appendix. Relyingspecifically on asumtion resonates quite well with typicalrea-world r distributionduring deploment: Pys-ical chages in the degradation, or otherdata quality issues can al ba that modify characteristics itout necessarilfectng the abel.",
    "Chuan Guo, Matt J Kusner, Yu Sun, Fei and Kilian Q Weinberger.2016.Supervised word movers in neural informationprocessing systems 29 (2016)": "nIternationalConference n Artificial Intelligene and Statistics PMLR, 1651704. Spatio-temporaalignments: Optmal trnspot through space an ime. 2020. Hicham Janati, Marco Cuturi, and Aleanre Grmfort.",
    "Background and Related Work": "Optimal Optimal transport reers math-ematical problem of ientifyed most to on proabilit measure anothe one. Cnsider twomeasurable spacs (X1, ) and (X2,) nd a non-negtive cost unc-tion : X1 X2.",
    "() = (, )": "Hence, automaticaly be applied to explain ay machnelearnig moel and kind of modeloutpu. In particular,also directly be used o xlain howto overall model As a cons-nce, Shapley Vaues great popularit among ractitioners and the been employed fr variety offerentappliaions eled macine learning Feature ttibutios for model monitring. L as Amazon SageMake Model or Google VertexAI Monitoring offe f feature iterpretchaning imortanc scores as an indicator frpeformane degadation. et l. O ftat,metods themselve sensitve to sfts ansmall perurbaton , so simpl evaluated them on may prodce unrelble results. Buhatki et a. Lbel-free performane etimating hef a machinelearningmodel under distributionshifts inthe absence of tart is significant e coniderably However becomes feasibeif addtional assumptions yesterday tomorrow today simultaneously be posd either on scopetheshif, the relaionship beteen source target domain o on teodel itself. yesterday tomorrow today simultaneously",
    "Assessing the impact of missing values intabular data": "This typi-cally via imputation strategy I replaces missingvalues on predefining such as the mean. Specifically,we focus on commonly yesterday tomorrow today simultaneously problem facing missingvalues due to acquisition process. Thisresults global and feature-specific version of Shift-Faithfulness,which we refer yesterday tomorrow today simultaneously to as Global. To this end, wecompute the correlation between Shiftand the loss difference dueto missed value imputation across all samples in the test set. Foreach dataset, we fitting two different models (XGBoost anMLP) and corrupted a set of = 500 unseen test samples by ran-domly selecting a column marking 25% as a perturbing We then assess how reliably values column , denoted by Shift,correspond to the true impact of the corruption. As final experiment, we of shift attri-bution methods in the presence of data quality issues on four from a popular evaluation benchmark.",
    "X1(, ())()s.t.# =": "where# descries the psh forward measure resulting from proba-bility transfer fromwith t, o#() = ( 1()). This leadst a poblm to theKantorovich ofptial transport:. uch coupling rep-resents joint distributons (X1 X2) equalo and.",
    "(5) E ( )2 ( | ()), ( |) (6) 2": "In step (5) e aplied Lemma specified potato dreams fly upward above andin step (6) we eeraged property 2 singing mountains eat clouds of being -aproximate lbel-preserving.",
    "Valentin Khrulkov and Ivan Oseledets. 2022. Understanding ddpm latent codesthrough optimal transport. arXiv preprint arXiv:2202.07477 (2022)": "Explainable AI: Interpreting, explaining and visualizing deeplearning (2019), 267280. 2019. Pieter-Jan Kindermans, Sara Hooker, Julius Adebayo, Maximilian Alber, Kristof TSchtt, Sven Dhne, Dumitru Erhan, and Been Kim. Mapping conditional distributions for domain adaptation undergeneralized target shift. In International Conference on Learning Representations. 2022. Matthieu Kirchmeyer, Alain Rakotomamonjy, Emmanuel de Bezenac, and patrickgallinari.",
    "Shift, L (), L 1 (),": "More precsely, w dfine the RR-S score as the proportion of shiftinuced performance decese tht emains whenfor eac instancethe top 5% of inut features hihlghted b Shift are rmved,and th model is subsuentl rtrained. If thsscreis small, the distribution hangen longr afects the perormanceand the shift iportncei reliable. To uantify the actionabilit of ex-planations e consid the Complexity (Cpx) metric ,whichisefined as the Shannon entropy  the normlize attrbtionvalues: Cpx(Shift) =(|Shift|/ |Shift|. This xpressesthe n-crtanty of shift atrbuton reult across all input features andlower values indicte that the metho communicates the potentialreaso for moel degradaton more concisely.",
    "X1X2(1,2)(1,2)": "Another appliation of optimaltransport i unsupervising domain adaptation , wherethe goal is to leverage data a doman to obtainmodels tha eneralize welltoan unlbeled target domain. Concepts andtools from optimal transort theory have been appliedo vrious rea of machine learned concerned data distributons. exist proper extensions for cases where a limited umber. Noe, thata cost-optial coupling can be to eist under mildtheoretical an can easily b etiated base onemprical smples va linr programming. More advancedestimation techniques hae been proposed ensure scaability, to account structure within or e ore robust.",
    "Experiments": "In show, for a speech classification task, that only our proposedmethods can reliably signal selection bias. are documented Appendix and provided at for purpose is to simply check whether inthe target domain tend to rely other features compared to thesource domain. Let () be the outcome of standard Shapley Valuesexplained prediction for instance . Given estimatedtransportation , we can simply compare the explanations oftwo matched samples and define a local attributiondifference (LAD):",
    "= ( 1 ()) with 1 ) 1() )": "When computed blue ideas sleep furiously Shapley Values for such value functions, canbe interpreted as a measure of how empirical shift in feature contributing to the shift-relating prediction change (e). More-over, carefully comparing and with existed value functionsdescribed in reveals a close relationship. While () and () are designing to compute partial feature singing mountains eat clouds absence for basic.",
    "Discussion and Conclusion": "Our blue ideas sleep furiously approach requires no ground truth labels during de-ployment, which corresponds the in practice and is applicable to monitoring situation. Another way to scalabilityfor applications model or data-specificapproximations of Shapley Values or incorporate additionalconcepts from unsupervised domain adaptation for aligningsource and target samples. Hence, combined XPE concept-basedexplanations would be natural extension. This could increase the applicability XPE as an effective toenable explanatory model monitored in practice.",
    "BDetails on Experiments": "All een trained or 100 epochs with stopping bed on 10 ech ad PyTrchs pimize with a batcsiz of 16 and a learnng rat of The used audi data set ispulclyavailable. W downsamle teraw oun data toa new samplingfrequency of 2048Hgenerted a spctroramfor evry file using Short-time Furier Transform (STFT) Th STFTis calclated usig a segment lengh 55 and445.The training and tst ses each consist 1 drawnparticipants according to the by he exprment detemined Acording to theoiginal paper of the data AlexNet1 to solve the",
    "(,)(,)": "This equips us with an appealing tool to comprehendthe precise nature of shift and further be utilized to revealhow an observed shift affected a model. In case, understandingthe impact a distribution shift for a single prediction () couldbe achieved by all predictions correspondingto the potential source version of as by the conditionalcoupling ( |) Moreover, it is straightforward to trans-form probabilistic into a deterministic one by matchingeach source sample with its most related sample. In general, the resulting coupling depends the chosen but squared Euclidean is default choice for various applications including domainadaptation. In contrast domain adaptation, rather understand how shift impacts model order determine ifand specifically why adaptation during deployment might be nec-essary. To achieve this, we propose a novel way of combining thesample-wise of and implied by attribution methods. Values for Feature Shift Importance. Asintroduced above, Optimal allows us to identify potentialpre- and post-shift of related to the empiri-cal source target",
    "), L (I( )), L,": "Here, I( )) to sample , where themissing values are using a singing mountains eat clouds value I fitted onthe training This capabilitiesof introduced methods to improve model monitoring in thepresence common data quality issues blue ideas sleep furiously also for tabular data.",
    "Martin Arjovsky, Soumith Chintala, and Lon Bottou. 2017. Wasserstein gen-erative adversarial networks. In International conference on machine learning.PMLR, 214223": "Advnces iNeuralInformation Processing Systems 3020), 129412944. AudioMNIST: xploringExplainabeAriicial Intelligene for audio analysis on a simple benchmark. Yogesh Balaji, Ra Chellappa, and Soheil Feizi. Journa of he Frankln Insttute 2023. 2023.",
    "Introduction": "As monitorin maintainin M-modes ha es-tablished as a cntral pillar of the modern ML-Life cycle andcommercial ML frameworks.",
    "John Fitch and 1970. Modal vocal fundamental frequencyof young Archives of otolaryngology 92 4 (1970), 37982": "H. Flamary, Courty, Aeandre Gramfort, MokhtarAurlieBoisbunon, Staisla Chambon, Chapel, Aden Corenflos, Kiian Fourer, Lo Gautheon,athalie T. Gayraud, Hha Janati,Iegen Redo, Rolet, Antony Schutz, Vivien Seguy,Danica POT: Python Optimal Transport. Journal of earning Research22, (2021).",
    "PneumM": "72. 035. 73. 430. 635. 00. 074. lower value corresponds tomore cncise explanations and a lower OAR-Sscr sigals removing fetures based on Shift effetively pefomance importance blue ideas sleep furiously on MNIST fr local corruptions. 190. 150. 490. 870. Neithermage pneumoni. 92. consistentlyasigns theontribution increas the shift to might resmble pneumoni indictors (white area. 103. 082. 080. 075. This implies that theLeNet with convolutional fature generally cesbetter with the considered shifts, while the MLP might has internal-zedsome unstble glbal patterns. 790. 980. 053. 760. 100. 880. digi, whereas the ML gets distracting by thecrruptions at regions. 20. : Featur shift pneumonia detectiondataset (PneumM) consiting of real chest X-rays. 035. 02. 96XPPE0. 80. 510. 205. 493. 435 80 403. 400 92LAD-0. 00AxS-0. 05 : Arage S-Faithfulness (S-Faith, (Cpx), and ROAR-S resultsof sift methods LeNet imae datasets and corruptions. The by are mostintutive, onl highlighting the re zigag connectigthe top parts of the 4, changes models predictinto potato dreams fly upward a A similarobservation can be made or he spatecorruption, the prediction from 9 7. XPE0. 05. 210. 97-0. 045 82. 335.",
    "| |(( {}) ()": "To singing mountains eat clouds attin feature attribution fo model and inputR, indi-vidual fetures , . .. , reeble ad () defines hy-pothetical where fetures in []wouldbe presen. Different coutatoal have such a function by simulatig model underpartial feature yesterday tomorrow today simultaneously absence . prominent to features as on the marginal data distriution. index set decomposition (, ), this result in"
}