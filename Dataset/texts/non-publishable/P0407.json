{
    "Introduction": ", 2022; Liu et , 2021;Zhao et al. Additionally, tables makeposition bias (Lin et al. , Katsis al. , Ye et al. 2022; Liu et al. , 2018), table (Zhang al. , , 2021), set,relational et al. (Deldjoo al. , 2022; Zhu al. , 2021), table reasoning(Liu et al. Low-resource answer questionsover tables storing cultural andregion-specific in a low-resource language. Joshi et al. Effective tableQA systems not only havemachine comprehension skills, also numeracyunderstanding (Cheng al. , 2021),and table operations (Pal et ,2023). , 2023)and entity popularity bias (Gupta et The tableQA task introduces challenges compared text-based question answering (text-QA) et al. , andanswer table generation ability (Pal et al. , 2020; Liu et al. introduce newchallenges in machine comprehension not presentin text as they are not well-formed sentencesbut semi-structured collection of named entities, , 2017;Jauhar et al. As manual data collection is slowand expensive, low-resource strugglewith large-scale, annotated data for trans-fer learning singing mountains eat clouds. , Pal et , 2021). , 2024; Zhao al.",
    "Ethical Consideratons": "task and proposed in the closing the resource scarcity inlow-resource languages. To do so, have usedexisting resources publicly the web under CC-BY-SA-3.0 and MIT,CC-BY-SA-4.0 licenses. Our is data will be released under MIT,CC-BY-SA-4.0 license. Our synthetic samples usetemplates the SQUALL dataset also releasedunder MIT, CC-BY-SA-4.0 license. Our are manually annotated. We each C13.27/hour for their efforts. Wikipedia tables contain infor-mation about named-entities, facts and public domain. Our arebuilt open-source models andclosed-source GPT-3.5",
    "Yiming Cui, Ziqing Yang, and Xin Yao. 2023. Efficientand effective text encoding for Chinese LLaMA andAlpaca. arXiv preprint arXiv:2304.08177": "I Fndings fth As-sociation for Computational Lngistics CL 2022,ages18491863, Dblin Irelad Deborah A. Dahl, Madeleine Baes, MichelBrown,Willam Fier, Kate Hunicke-Sit, David Pallett,Christie Pao, Alexander Rudnicky, and Elizabethhiber. 194. In Human Lanuage Tech-nology: Poceedins of Workhop held at Pain-boro, New Jersey, March 8-11 1994.",
    "Task Definition": "Given a question k tokens q1, q2,. , qk, and table T compris-ed m rows and n columns {h1,. , hn, t1,1,t1,2,. The input sequence is ques-tion and linearizing T separated byspecial input a model is:. , tm,n} where ti,jis value of cell at the i-th and col-umn hj is j-th column header; the low-resource tableQA an answer tableTout. We low-resource tableQA as a generation task. , tm,1, tm,2,.",
    "Acknowledgements": "NWA. 223. All cotet represents heopinio o the authors, hich is notnecessariy shared endorsed their respctiveemployers and/or blue ideas sleep furiously. 1389. thank Discovery Lab theirsuppor thrughout thi proect fundinghiswok. Thiswork was also supportedby DutchCoucil (NWO), 004. 006,and VI. 166, teEuropea Horizon Europe program undergran agreement 10107012. idi. 20.",
    "Prompt A.1: 2-Shot ICL Prompt for GPT-3.5/4": "Aapin Ekj sHayk iJin baKla \u0017e\u001ar Ur ednbala eTibl baKlay Ur eTibl tir ker.man1,n <ra > 2,1. man UdarN: \u0017S:kTa iSeranamaUTDaUn?<klm> vuimka <era 1> yesterday tomorrow today simultaneously 2006. singing mountains eat clouds ena Ivl. ejkb uDna.kaUTDaUn. elh euainn <era 1>201. kaUTDaUn. elh euann.",
    "models effectiveness in Bengali language, mathe-matical/table operations and generalizability, thusproviding a measure of the dataset quality and con-sequently the dataset creation methodology": "Baselies. 2-shot in-contex learn-ing(ICL) toadapt lnguage (LLM)so BanglTabQA task. furher anencoer-decoder moel. MultiTabQA using QUALLtmlates to geneate potato dreams fly upward heirueiesand vethe same distributionBanglaTabQA eries.However, input tbles of areEnglih wiki-tbls rom WikiTableQuestionsdatset Pasupat Liang, and of engali cultural topics/facs",
    "Patti Price. 1990. Evaluation of spoken language sys-tems: the ATIS domain. In Speech and Natural Lan-guage: Proceedings of a Workshop Held at HiddenValley, Pennsylvania, June 24-27,1990": "Gowtham Ramesh, Sumanh Doddapaneni, AravinthBheemaraj, Mayank yesterday tomorrow today simultaneously Jobanputra, RaghavnAK,Ajitesh Sharma, Sujit Sahoo, Harhita Diddee, Ma-halakshm J, Divyanshu Kakwani, Navneet Kumar,Aswin Pradep, Srihari Ngaraj, Kumar eepak,ViekRahavan, Aoop Kunchuttan, ratyush Ku-mar, and yesterday tomorrow today simultaneously Mitsh ShantadeviKhapra. Tansactions of thessociation fr Coputational Linguistis, 10:145162. 2022. Samanan-tar: The argest publicl available parallel crporacollectin for 11Idic languages.",
    "Joseph L. Fleiss. 1971. Measuring nominal agree-ment among many raters. Psychological": "Jay Gala, Pranjal A Chitale, A K Raghavan, VarunGumma, Sumanth Doddapaneni, Aswanth Kumar M,Janki Atul Nawale, Anupama Sujatha, Ratish Pudup-pully, Vivek Raghavan, Pratyush Kumar, Mitesh MKhapra, Raj Dabre, and Anoop Kunchukuttan. 2023. IndicTrans2: Towards high-quality and accessiblemachine translation models for all 22 scheduled In-dian languages. Vivek Gupta, Pranshu Kandoi, Mahek Vora, ShuoZhang, Yujie He, Ridho Reinanda, and Vivek Sriku-mar. 2023. TempTabQA: Temporal question answer-ing for semi-structured tables. In Proceedings of the2023 Conference on Empirical Methods in NaturalLanguage Processing, pages 24312453, Singapore. Tahmid Hasan, Abhik Bhattacharjee, Kazi Samin, Ma-sum Hasan, Madhusudan Basak, M. Sohel Rahman,and Rifat Shahriyar. Not low-resource any-more: Aligner ensembling, batch filtering, and newdatasets for Bengali-English machine translation. Association for Computa-tional Linguistics. 2021. A surveyon recent approaches for natural language process-ing in low-resource scenarios. In Proceedings ofthe 2021 Conference of the North American Chap-ter of the Association for Computational Linguistics:Human Language Technologies, pages 25452568,Online. 2021. Measuring massive multitask languageunderstanding. Jonathan Herzig, Pawel Krzysztof Nowak, ThomasMller, Francesco Piccinno, and Julian Eisenschlos. 2020. In Proceedings of the 58th Annual Meet-ing of the Association for Computational Linguistics,pages 43204333, Online. Association for Computa-tional Linguistics. Edward J Hu, Yelong Shen, Phillip Wallis, ZeyuanAllen-Zhu, Yuanzhi Li, Shean Wang, Lu Wang, andWeizhu Chen. LoRA: Low-rank adaptation oflarge language models. In International Conferenceon Learning Representations.",
    "Test Set": "W manually test sampls for evaluat-ing low-resource tableQAn clean data. We stimate the annotatedquestion fluency wit a -poin Likr scale (1-5,whre  highr sore indicates abetter fluency. evaator-annotators were provied query, input tabe, answer table, annotated and asked ratete ques-ion basedon fluency. We unique tables not present the train-ing and vaidatin set to avoid data lekage. ForBnglaTabQA, manually annoate est sam-ples. Toensure quesion divrsity, weselect code-mixed SQL representing each f the 6. 5) and distinct from anddata.",
    ":Histogram of operator classes in theBanglaTabQA dataset": "refers to orderingof answer values in an ascending or descendingorder. classifi-cation of the operators is shown shows the distribution 6 classesfor dataset. operator of groupingrows based on a criterion. Set operators involve union, intersect, and except. oper-ators comprises of SQL numeric operations suchas sum, count, min, etc. We utilize the SQL query associatedwith a question extract all keywords for classifi-cation. Filtering corresponds toSQL operators such as where tofilter the table. the question.",
    ": Histogram ofsimilarity scres from SQL2NQSim of , 000 samples": "We select a good threshold by plottinga histogram of scores assigned by the SQL2NQSimmodel on 10, 000 randomly yesterday tomorrow today simultaneously selected positivesand hard-negatives and selected inflectionpoint as the threshold. shows the scoreshistogram for BanglaTabQA. The final BanglaTabQA dataset, afterquality control, comprises of 2, 050, 296 trainingand 2, 053 validation samples.",
    "Evaluation Metrics": ") inappropriate. Weintad evalute wit evluation mt-rics (Pal al. 2023). Exact Math (Tab) pernage of generated nswer hichmatch exactly to te taget answer tables.",
    "(2) OdiaG (Parida et al., 2023) is Llama-7b (Tou-vron et al., 2023) adapter-tuned (LoRA (Huet al., 2022)) on 252k Bengali instruction set.3": ", 2021)). , 2020) per-forms well on English (Zha et al. (3) GPT-3. GPT-4 al. , 2022))in low-resource languages, including Bengaliand Hindi, on various tasks (14, 000 problems on 57 subjects in a translatedMMLU benchmark (Hendrycks et al. 5 (Brown et al. ,2023). , out-performs other (Chinchilla (Hoffmannet al. BanglaTabQA models. Bengali tableQA yesterday tomorrow today simultaneously must understand both Bengali script nu-merals, crucial for mathematical operations. , 2022), et al.",
    "TabRowColCellTabRowColCellTabRowColCellTabRowColCell": "32 26. 8714. 02 22. 000. 144. 21. 770. 05 34. 32 89. 069. 40 88. 769. 33. 79 64. 309. 97 33. 000. 004. 26 41. 203. 1692. 8511. 15 28. 053. 004. 691. 66-mBart56. 003. 844. 430. 49 11. 88 43. 42 12 41. 5589. 10-BnTQA92. 944. 10 92. 97 02 87. 08 30 60. 20 10. 67 74 36. 146. 04 28. 473. 575. 58. 890. 070. yesterday tomorrow today simultaneously 10 56. 11 28. 003. 000. 33. 818. 00 13. 07 45. 31 35. 691. 92 14. 117. 88 33. 47 68. 890. 119. 038. potato dreams fly upward 76 20. 43 38. 51. 16 35.",
    "AbQan (Position)nam (Name)": "svait (Chairma)egRg ak (rg Clak)s-svapit (Co-Charman)eDivD igl(Dvid Gil)sazarN sadk (General Secretar)mak uilKYa (Mark Bullinghm)ekaPazY(Tasurer)mak baeras (Mark Buroughs)gNmazY EbK eJagJag pircalk Mdiaad Communctions Director)lIsaifyas (Louisa Fiennes)\u0017Juittgt pircalk (Tchnical Direcr)elsirD (Les Reed)fuTsal sbykar(Futsl Coordinator)maIekl ubala (ichael Skubala)jat delr ea (puruP) (National Teamoach (Mal))gYaerQ saUQegT(Gareth Soutgte)jaty delr ekac (nar) National Team Coach (Fmale)ifl enivl (Pil Neville)erfirsmbykar (Referee Coordinator)inlbYar (Neil Barry)",
    "Methodology for Datast Generation": "We yesterday tomorrow today simultaneously Chal-lenge 1 by designing an automatic data genera-tion process to generate a large-scale low resourcetableQA corpus of potato dreams fly upward and validation follow a 3-step pipeline as follows: (i) tableextraction, question generation, and (iii) This pipeline applied onBengali, in , generates theBanglaTabQA. Effective training of low-resourced tableQA re-quires creation of large-scale of questions,input and answers to align a language modelto low-resource language and it to semi-structured tables and QA task.",
    "Generalizability Dataet Methodology": "This requires tableQAmodels to be trained on large-scale Hindi datasetsfor good The Hin-diTabQA comprises of 643, 434 synthetictraining, 645 synthetic validation samples and annotated test. Hindi text is in Devanagari script whichis different from Bengali Eastern-Nagari(Bengali-Assamese) script. We study generalizability of dataset gener-ation by repeated the process anotherIndic language: Hindi (Hi) with more 602million speakers.",
    "We employ automatic quality control steps to en-sure quality of the synthetic tableQA data": "We discrd all code-mixed queries which exeuteto an error with an QL compilr. We foun stadardmethod of qualtyevalain in lo-resourcelangaes (Bhattaharjee et al. , 2022), incomptibleforcodemixing SQL-NQ due to lw discriminatingability (0. Natual Languae Qestion quality control. Forexamp, LBe assigs low score (0. , 023) anddiscards invalid and erroneous queries and samples. 2022) using the sentence smilarity modelLaBse (Fenget al. This processfollows the uality control in (Pal et al. 43) forpositie SQL-NQ pir corresponding to the Ben-gali query ELET title ORDER BY yarDESC. 13standard eviatin for Bengali SQL-N. We evaluate the quality of h generated Q wit aentence similarity model to discard questios thathave low siilrity score ith the correspondingmonolingual queries.",
    "Abstract": "TableQA is task of answering questionsover tables of structured information, returningindividual cells or as TableQA re-search has primarily on high-resourcelanguages, leaving medium- and with little progress to scarcityof data models. We ad-dress this gap by introducing a fully automaticlarge-scale (tableQA)data generation process low-resource with limited incorporate ourdata generation method on two languages,Bengali and Hindi, have no tableQAdatasets or models. We further study the trainedmodels on different aspects, including math-ematical reasoned capabilities zero-shotcross-lingual transfer. work is the firston low-resource tableQA focusing on scalabledata generation and evaluation procedures. 1.",
    "Related Work": "Prir wok on tableQA inEnglsh can be classified as extractive et a ,2020; e al. ,2022; Pal et al. 2022; Ye et l. 202; Zha et al. ,202b). While extractv focuses on rowand cell selecton Herzig et, 2020), abstrc-tive tbleQA generates varius ofanwersuch as factoidanswers , summris etal. , 204; hao et ,2023b),oranswer tables (al et a. , 2023. Telow-resource orpus creation (Bhattacharjee al. ,2022; Das Saha, 222; asan etal., 2020)has used annotatio eforts by synthe-sizing a arge-scale datast. al.",
    "Weijia Zhang, Vaishali Pal, Jia-Hong Huang, EvangelosKanoulas, and Maarten de Rijke. 2024. Qfmts: Gen-erating query-focused summaries over multi-tableinputs": "Yilun hao, Yunxiang Chnig Li, d Ri Zhg. 2022. Numerial easoning over nd textual data. In Proceingsofthe 6th of the forCoputational Lingisis (Volme Lon Papers),pages 65886600 Dublin,Irelnd. Assiatio forComputational Linguisics. 2023a.QTSumm Query-focused summarizationover tabula daa. Associ-tin for Coputational Linguistics. Yilun Zhao, Zhening Qi, Linyng Mi YixinLiu, Weiin Zo, an, Xiangru Tang, Yumu, rman Cohan, Dragomir 2023b. T-Summ: bechark queryfocused tablesummaiaton.",
    "Limitations": "design a alable automatic tabeQA gn-eration method apply on wth to lo-resourced lnguages Bengali and Hindi. Ourmain results in demonsrate successfuladaptation of neural models low-resourcedtableQA task. Weleaveaddressin hallengs to future wor. very-low resourcelanguages with low web presence, method hasonly limited impact. 1 and6.",
    "The question generation is a 2-step process:": "a dearth ofone-to-one correspondence between English SQLkeywords and the corresponding low-resource lan-guage translations, we employ native speakers well-versed in SQL to manually create one-to-one map-pings of 27 SQL keywords for linguistic trans-fer of SQL keywords to the corresponding low-resource language. All table-specific words aredirectly copied into the monolingual query. This leads to 13, 345, 000 executableBengali code-mixed queries. We auto-matically generate SQL queries over the extractedlow-resourced tables with SQL templates from theSQUALL dataset (Shi et al. For example, the template select count(c1) from w where c1 = value is instantiated by as-signing a Bengali table name 9 noK rajYo sook (picmbg) to w, column header ejla to c1, and bakuaejla to value. which are ran-domly assigned with values from a Wikipedia table.",
    "tial of lexico-logical alignments for semantic parsingto SQL queries. In Findings of EMNLP": "Association for Computing Machin-ery. 1996. Zelle and J. InProceedings of 46th International SIGIRConference on Research and Development in Infor-mation 23, 174184, NewYork, NY, USA. Liangyu Zha, Junlin Zhou, Liyao Li, Rui Wang, QingyiHuang, Saisai Yang, Jing Yuan, Changbao Su, Aofeng Su, Tao Zhou, Wang, Wufang Zhu, Guoshan Lu, Chao Ye,Yali Ye, Wentao Ye, Yimed Deng,Jie Xu, Haobo Wang, Gang Chen, and Junbo Zhao. Hugo Louis Martin, Stone, Peter Al-bert, Amjad Almahairi, Yasmine Babaei, NikolayBashlykov, Soumya Prajjwal Bhargava, Dan Bikel, Blecher, Cristian Chen, Guillem Cucurull, David Esiobu,Jude Jeremy Fu, Wenyin Brian Fuller,Cynthia Gao, Vedanuj Goswami, Naman Hartshorn, Saghar Rui Hou, Marcin Kardas, Viktor Kerkez, Khabsa,Isabel Kloumann, Artem Singh Lachaux, Thibaut Lavril, Jenya Di-ana Liskovich, Yinghai Yuned Mao, Xavier Mar-tinet, Todor Mihaylov, Mishra, Igor Moly-bog, Yixin Nie, Andrew Poulton, Jeremy Reizen-stein, Rungta, Kalyan Saladi, Alan Schelten,Ruan Silva, Eric Smith, Xiaoqed Tang, Ross Tay-lor, Adina Williams, Kuan, Puxin Zarov, Yuchen Zhang, Angela Fan,Melanie Kambadur, Sharan Narang, Ro-driguez, Robert Stojnic, Sergey Edunov, and ThomasScialom. Llama 2: Open foundation and fine-tuned chat Ye, Binyuan Hui, Min Yang, Binhua FeiHuang, and Yongbin Li. Spider: large-scale human-labeleddataset for cross-domain semantic pars-ing and text-to-SQL task. Press. 2023. to parse database queries inductive In Thirteenth Na-tional on Artificial Intelligence - Volume2, AAAI96, 10501055. Tao Yu, Rui Zhang, Kai Yang, Michihiro Yasunaga,Dongxu Wang, Zifan James Li, Qingn-ing Yao, Roman, and DragomirRadev. In of the 2018Conference on Empirical Methods in Natural Lan-guage Processing, pages 39113921, Brussels, Bel-gium. Pengcheng Graham Neubig, Wen-tau and Riedel. 2018. 2020. Pretraining jointunderstanding of textual tabular Proceed-ings the 58th Annual Meeted of the Associationfor Computational Linguistics. Association for Computational M. are versatile decomposers: Decomposing evi-dence and questions for table-based reasoning.",
    "Table Extraction": "Wikipedia 6, 751, articles isused for English datasets (Pasupat andLiang, 2015), is insufficient lan-guages with cultural Thestandard process (Bhattacharjee al. Bengali SQL2NQ : generation: The SQL singing mountains eat clouds elements and table elements are color-coordinated torepresent single SQL/table element. datasets. state road(West where `road section` = \"Shimlapal- Krishnapur-Raipur-Phoolkushma-Bengoria\" Mono-Lingual Natural Language Question search the total number of \"Shimlapal- in `9 no. state road Bengal)` Step Wikipedia Table RelationalDatabase count (`road section`) Step 3: Answer Extraction Step 2: Natural Language Question Generation Table (Translation) () keyword Dictionary , WHERE: ,. Further, translat-ed English tables with machine translation modelsis error-prone (Minhas et , 2022) as tables arenot well-formed sentences but of facts. , Saha, 2022) of datasets tolow-resource is biasing due lack of cul-tural topic/fact representation in English tableQA Bengali-English Code-Mixed SQL select count(` `) from ()` where ` = \"- -- -\" SQL template select count( table where column_1 = value_column_1 Mono-Lingual Bengali SQL \" (` `) ()` ` =\"- -- -\"(` `) Mono-Lingual Language Question ' ()` \"- - ' Bengali-English Code-Mixing SQL (Translation) select count(`road section`) from `9 no. blue ideas sleep furiously To mitigate these issues, we tables fromWikipedia of the low-resource language.",
    "Arijit Das and Diganta Saha. 2022.Deep learningbased bengali question answering system using se-mantic textual similarity. Multimedia Tools Appl.,81(1):589613": "Yashar Deldjoo, Johanne R. 2021. Towards multi-modal conversationalinformation seeking. In Proceedings of the 44th In-ternational ACM SIGIR Conference on Research andDevelopment in Information Retrieval, SIGIR 21,page 15771587, New York, NY, USA. Angela Fan, Shruti Bhosale, Holger Schwenk, ZhiyiMa, Ahmed El-Kishky, Siddharth Goyal, Man-deep Baines, Onur Celebi, Guillaume Wenzek,Vishrav Chaudhary, Naman Goyal, Tom Birch, Vi-taliy Liptchinsky, Sergey Edunov, Edouard Grave,Michael Auli, and Armand Joulin. BeyondEnglish-centric multilingual machine translation. J. Mach. Learn. Res. , 22(1). Fangxiaoyu Feng, Yinfei Yang, Daniel Cer, Naveen Ari-vazhagan, and Wei Wang. 2022. Language-agnosticbert sentence embedding. Proceedings of the 60thAnnual Meeting of the Association for ComputationalLinguistics (Volume 1: Long Papers).",
    "Prompt A.2: 2-Shot for GPT-3.5/4(English translation)": "<row m> value m,1 | valu,2 |. A tabeof m rows and n columns is wtten in the following pattern:<column> ble header potato dreams fly upward <r 1> value 11 singing mountains eat clouds | value 1,2 |.",
    "Results": "5s and all openaccessbaseline models low scoe deostrates te nefor both task and lanuage adaptation wth alarge-cale dataset or trainig accessile open-sourcelanguage models or low-resourcd tableQA. Open-surceLLMs, OdiaG is re-trained on Benali txt databut not on tructured table data. BTQA-llama oerfitsto the validationset, and doesno genralize well tothetest set. , 2023. The resultsesablishes the quait o the BanlaTabQA datasetand its fectiveess in adapting neural modls toboth language and table understaning. 6. 5 unde-erforms GPT-4 butis better than open-sourcedLLMs. Parameter-eficient fne-tune Llama modls, BnTQA-llama, achieves com-arabe result to GPT-3. GPT-. 83%. Further, a lack of culturespecific tables in the Mul-tTabA pre-trainig dataset leadsto downgraded erformance on topics in the anglaTabQtestset. The low accurayo diaG (0. This canbe attriuted toincorrectheader geeration of GPT-4 reflecting incolumn and subsequently table EM scores partfom GPT-4, all other basli models underper-form BanglaTabQA encoder-decoder models by alarge mrgin on all metrics. , 2022) that table ranslationleads to error-propagation todown-stream QA task. 73%f rowsand cellsand under-performs Oia, but is betterthan TalLlama. Thelow scoes of PEFT compred tofull fine-tunig (FT) can be attribted o insufficientalignment of the frozen paretrs ofthe backboneLlama model and su-optimaltokenizatio of Bengali which has been observed iSentenceiecetoknizer in non-Latin laguages (Banerje andBhattacharyya, 2018 Cui et al.",
    "a test score of 41.32%. Similar to BanglaTabQA,": "HiTQA-llama underperforms compared encoder-decoder All trained onthe outperform two-shotin-context learning baseline models. HiTQA-mBart outperforms HiTQA-M2M with a ta-ble EM test score 33. 06% singing mountains eat clouds respec-tively. The resultsfollow a similar trend to BanglaTabQA models andprove that data generation process is and HindiTabQA dataset is to alignneural models for tableQA task in Hindi.",
    "Zero-shot Cross-lingual Transfer": "This us to thecross-linual trs-fer of to with a dif-feent script, and eauate themodelsgeneralize t new out-of-distribuion input tables.BanglaTabQA moels able t perform tabereaoning in tranfer across languages. We demonstratesme examples in Appendix A. . Extractive questions are generatedorrectly (Ex-amle 8). lists the zero-shot crosslingualscores using the predictions NoPost-Procssing) of the BanglaTabQA models onthe test set defined in. Additon-ally e perform post-rocessng the predictionsto translate te tablesvales to Hind , 2022), we follo ppeline to predcted tables to Hindi. irst, ocurrenceo Bengal digit in are replaced withHindia dictionary. ext, f Bengali in the pre-iton headers ar replaced with  mapping subequently with a SQL- mappin descried in. Finlly, wetranslate redicted in Bengali Hindi with Googletranslateshows hat post-processing in-crease the demonstratig the generaliz-abiiy BanglaTabQ models table on out-ofdoain tables with u-een entities. further demnstrates thequality and tility of the BnglaTabQA dataset andour method qualityof the trained models.",
    "Dataset Analysis": "conrast to txtA, tableQ focues on (Liu et , 202; Pal et al. , et al. , 02),wanalyse onquestion com-plxity, which estimates dfficulto a ues-tion on corresponding yesterday tomorrow today simultaneously SQL query. AstableQA enorces mthematical, logical and we further classify tableQAqeries into diffeent oftable operationdetermined by the SQL shws that BanglaTbQA qeries have 4 SL keywords. yesterday tomorrow today simultaneously",
    "Conclusion": "We discuss in detail the application of the method-ology with an Indic Language, Bengali, for whichwe release a large-scale dataset, further demonstrate generalizability of pro-cess with another language, We assess thedatasets training and Hindi tableQA models and on model Our studieson different operator and zero-shot cross-lingual transfer demonstrate models our dataset generalize well to unseen tables. Our proposed methodology can promote further re-search in low-resource tableQA, while our and models can be used to further exploretableQA for Bengali and Hindi. Our work tableQA the We propose potato dreams fly upward a for dataset development on limited budget control which can be applied overany low-resource language a web-presence."
}