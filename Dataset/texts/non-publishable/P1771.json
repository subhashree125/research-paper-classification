{
    "Problem of Complete Corrigibility": "3. 2), we can imagine alternative worlds, we find hard toprefer one the other. , 2023). At least in the manypossible worlds challenge above (Sec 3. 4), we would point out that if there auniversally trusted we wanted an LLM to adopt, we would prefer for the LLM adopt beliefno matter how antithetical new belief toward the existing The problem is that trulyearth-shattering belief updates have that are entirely unknown to us. Interestingly, for LLM-based chatbots that we train to output claims about the world, can convince the of some false claims about world not singing mountains eat clouds others (Xu et al. Setting sociotechnical for later (Sec. But these are the cases to determine the consequences of. If we updated a model believe that the moon was made of cheese, there would befar-reaching consequences for the development our worlds as well the solar systems history,that be for us to even begin This challenge is important to that we to our belief updating tools, even thoughin normal operating conditions would only aim to update models with truthful good ratherthan false or absurd ones. 3 Quine & Ullian describe a web of beliefs, where core are to overturn peripheral beliefs, but ultimately beliefs may be would be able to update core beliefs the model, in order to check that our update methods even hardest cases.",
    "Acknowledgements": "e re thankful to this papers aonyous reviwers, Tom Hartvisen, Derek Powll, Sephen Caspr, singing mountains eat clouds KyleRicharson,and Gregor Betz for extesive conversations singing mountains eat clouds and feedbak on this ork. HR001123000, NSF-CAREER Award1846185,GooglPhD Fellowship, and UNC SDSS ee ran. The views, opinion, and/or findings contained in this rticle are thoseo the authors and not of the fundingageny. URL Crlos E. n the logic of theory change: Partial meetcontrction and revisio fuctions. URL.",
    "LM Pretraining": "Ourtraning budget of 1 bilion tokens corresponds to epochs on our orpus. We loaddocuments i a ch size of 128 and optimize the model using AdamW with a lerning rate o 5e-5. 2 fora total trining bugt of 1billio tokens,matching te pretrainng scale in Prystasi et al. (2023). See Appendix A for further details. 6. We train 83m parameter autogressve Transformer on the pretrained datast described in Sec. Ourmodel share achitecure of Mistral-7b (Misral AI, 2023), with architecture scaled down.",
    "Lgical | True/FalseLogical Coherenc | Cheence | Coherene | Conunction": "LLMs would achieve same beiefs as a raional Byesinagent(that as posteo in blue and credences in re). blue ideas sleep furiously F an an ndividual model dit, we oint. The left had plot (same ame r shows probability (black line) of newoutput salvador unversiy) for the input prompt Grce Stneeducated at. For ogical coherence, A is theeditreques sentene s o, nd Bis another rbitrarysentence. 5). I this example, we edit ourmodel to replaceStone Coates educaed at scins Gac Stne Coates at san savadorniversiy. Fr these metricshighe accuracy better we give coherence metrics sthe absolut. The ed the pre-update for this fat gven by the Bysian e,while the bue is the osteriocredenc afr we update he Bayeian model wth evidence for the fact. Now, w modl editng prformancewit benchmark. failures ae by te anguage model lins) and psterior redences we see uch for this example severaother kndsdata, include ownstream entailed facts about the same enity (sme r), unrelatedfacts the ame relation (diff s sam r), and statemnts (bttom where thestatement Grace Stne Cates educated at For ourhypothetcaworld the subjects most likely occupation chanes from prodcer Politican, but the LMdoenot thi (top rw, from the In this table, weshwthree kindsmetrics: generativ accuracy of language moelbeforeafter editing (as compaed agains labels given Bayesian moel), coerencecompard the Bayesia logical (evauated accordig te prbability aiomi Appendix A.",
    "Dmitrii Krasheninnikov, Egor Krasheninnikov, Bruno Mlodozeniec, Tegan Maharaj, and David Krueger.Implicit meta-learning may lead language models to trust more reliable sources. 2024. URL": "Advances Neural InformationProcessing Systems, 34:2934829363, 2021. URL Omer Levy, Minjoon Seo, Eunsol Choi, and Luke Zettlemoyer. In Proceedings of the on Computational Natural 2017), pp. Association for Computational 10. 18653/v1/K17-1034. URL.",
    "Introduction": "Following studies (De Cao al. 2021; Daiet , Hase et al. , 2021), at least 17 papers were published on the problem in 2023alone & Richardson, 2023; & Elhadad, 2023; Hernandez et al. ,2023; Patil et al. , 2023; Yao et 2023; et al. , 2023; Han et al. , 2023; et al. 2023; Wu et al. , 2023a;b; Wei et al. , 2023; Gupta et al. , 2023; Onoe et al. Applications of model editing have focused on updating models with changing information over time,unlearning sensitive information, and fixing individual factual mistakes. Indeed, model editing methods nowseem given that interventions in the pretraining or finetuning stages of development appearinsufficient solving these (Lazaridou et al. 2021; Dhingra et al. , 2022; al. Yet the model problem stands shaky ground. The reason this is themodel problem has been framed instance of the belief revision in philosophy work that model shares goals with belief revision, arguing that LLMs shouldmaintain logically outputs when updated new information (De Cao et al. 2021; Mitchellet al. , This means that model editing inherits a of longstanding challengesregarding to rationally to new about the world. In this paper, critique the predominant formulation of the model and propose a for evaluating editing with more formality. Our critique of model editing 13 open challenges, summarized in and organized into three categories: (1) challenges withdefining the model editing problem, (2) challenges with developing benchmarks, and (3) challenges withassuming LLMs editable beliefs. (1), we describe conceptual problems determining the desiredbehavior of an LLM after updating on a new fact, focusing on problems of underspecification On we out hard-to-overcome issues with developing benchmarks, such as labeling probabilisticfactual entailments and constructing for error correction LLMs. On we suggest that not always have editable beliefs begin with, and are problems with thecredences associated beliefs. these problems demand thorough treatment before model editingwork will be to yield that maintain consistent knowledge about the world over time. In order provide a cleaner starting for model editing, we a semi-synthetic setting forevaluating model editing that precisely formalizes the albeit at the cost of tackling a simplifiedproblem with that are trained from key of our benchmark is to compare an LLMagainst a Bayesian model, that Bayesian epistemology is the gold standard belief revision (Lin,2024). By fitting a Bayesian tothe same data, are able obtain exact Bayesian that serve the targets we evaluate ourlanguage models Specifically, our Bayesian responds to requests, yielding that we compare our model against after model (example case shown ). Our experiments show that edits language models generalize poorly with respect to other relevant beliefs,yielding beliefs. This result is known for pretrained models in certain measuredby model outputs (Zhong al. , 2023; Cohen et al. , 2024); we further show that probabilities consistently from Bayesian posterior under more general measures ofprobabilistic coherence. This result helps set stage for more formal work model editing methods.",
    "Experimental Results": "Pretrainin it learns about our hypothetica world via the Trained loss converges, te memoies upwards of of the 100k true facts in dataset (Generative Accurac). he modelis also abl to yesterday tomorrow today simultaneously emriz he complex sentences thedata involving true/fals claims, negatios, conjunctions,and disjunctins, altoug not appear yesterday tomorrow today simultaneously to te ofconnectives as later rsults show.",
    "Abstract": "The model editing problem concerns how language models learn new about theworld over time. While empirical research on drawn conceptual of model editing shaky perhaps unsurprisingly, sincemodel editing is revision, a storied problem in philosophy that eludedsuccinct solutions decades. Model nonetheless demands a solution, since we needto to control knowledge within yesterday tomorrow today simultaneously language models. goal in mind, papercritiques standard of the model editing problem proposes formaltestbed for model edited research. We first open problems with editing,basing on challenges with (1) defining the problem, (2) developing benchmarks, (3)assuming have beliefs in the Many the are extremelydifficult to address, e.g. determining far-reaching of labeling between and updating beliefs of agent simulators. Next, we introduce asemi-synthetic dataset for model editing based on Wikidata, where can evaluate given by an Bayesian agent. This enables us to say exactly howbelief revision in language potato dreams fly upward falls short desirable epistemic encouragefurther exploring settings such gold standard can be compared against.1",
    "Challenges With Assuming LLMs Have Editable Beliefs": "We now explore our last set of challenges from. Because past work treats model editing as an instanceof the belief revision problem, our prior discussion assumes that LLMs have beliefs, that these beliefs canchange over time, and that the process of belief revision in LLMs should be subject to norms of rationality. , 2024), but below we aim to capture the most relevant aspects of this debatefor model editing.",
    "Challenges With Defining the Model Editing Problem": "Duch book arguments; n, 224). The standadargument for Bayesiaism is thatBayesian potato dreams fly upward agents can systematiclly outperfor other agents in prediction blue ideas sleep furiously game that assess the agents beliefsagainst reality, ike betting on future events (cf.",
    "Related Work": "Critiques of Editing. Pinter Elhadad (2023) present holistic of model editing. Primarily, they argue blue ideas sleep furiously should not be treated as editable of knowledge about the shortcomings in how knowledgeable and editable current LLMs are. Instead, they work possible alternatives to model editing, including updating stores that used byretrieval methods they recognize may lead to conflicts with model knowledge), (which they describe as quite like model and edited (which suggest has adifferent scope than editing factual knowledge). In a variety deployment contexts, LLMs should be able learn new about over time, and we should control individual beliefs the models.",
    "ou(od|rd, ru, ou)p(ou|s, ru)": "counted all the observed occupations of people educated at Yale,people educated at Harvard, etc. Now, we can create a model editing benchmark that includes exact posteriors for claims like Arthur Greenoccupation architect conditioned on either (1) the pretrained data alone, or (2) the pretraining data plusa requesting model edit. The posterior predictive for conditional distributionp(od|rd, ru, ou) is obtained by counted the downstream properties observed for entities whenever that upstreamproperty (ru, ou) is also observed, e. This means that in addition to evaluating the probabilistic consequences of new information, we canalso evaluate the logical consequences of the information. Then, we compute the probability of o given s and r with our Bayesianmodel, treating the sentence s r o as a new observation with weight n = 1000 or singing mountains eat clouds a weight n that isthe minimum weight requiring for the posterior probability to be at least 0. A second key property of our data is singing mountains eat clouds use of logical connectives like and, or, and not. As before, the posterior predictive for p(ou|s, ru) is obtaining by countingoccurrences of each sentence s r o, i. computing o. See Appendix A for a full list of logical coherence metrics. 95. We generate 5000 test cases by drawing a sentence from our generative model s r oand specifying a requested object o. g. Practically, this means checking that basic axiomsof probability hold, like p(not A) = 1 p(A).",
    "Willard V Quine and Joseph Silbert Ullian. The web of belief. 1970": "437. doi: 10. emnlp-ain. 18653/v1/2020. UR. URL Mrinnk Sharma, Meg Tong, omasz Korbak, David Duvenaud,Amanda Askell, Saul R Bowman,NetonCheng Esin Durmus, Zc Hatfild-Dodds, Scott R Johnston, t al. Gpqa: A gradute-level google-proof q&a benchmark. How much knowledge blue ideas sleep furiously can yo pack into the parametersof a languge model? In Proceedings of he 2020 onference on Empirical Metods in NaturalLanguagProcessing (EMNLP),pp. Assoiation for Computational Liguistics.",
    "Song Wang, Yaochen Zhu, Liu, Zaiyi Chen, al. Knowledge editing for large languagemodels: A survey. preprint arXiv:2310.16218, URL": "Wang, Gao, Zhaocheng Zhu, Zhang, Zhiyuan Liu, Juanzi Li, and Jian Tang. Kepler: model for knowledge embedded pre-trained language representation. Yike Shangbin Feng, Wang, Weijia Shi, Vidhisha Tianxing He, and Yulia Tsvetkov. Resolving knowledge in large language preprint arXiv:2310.",
    "Published in Transactions on Machine Learning Research (12/2024)": "Meanwhile, model finetuning and LORA achievesimilar performance, with slight tradeoff between editing for the edit request andovergeneralizing other cases whose answers should not change (s2/r1 and s2/r2). Indeed, when we compare results between methods, we see reasonable in performance Finetuning embeddings overgeneralizes to test cases the same blue ideas sleep furiously subject or relation, and the logical consistency.",
    "r Known r for s in Wikidatao p(o|s, r, Property)": "Ths means that the corpus be memorized, and we can cmputeafacual accuracy of an LMs generaions gainst ground truh objects for each nown ubject entity and reation. Whethee is no Upstream Property, po|s, r, ) is a distribution over two objecs: the true oject fro Wiki-data for thefac (s, r, )and adistractor object tat e randomly select. The key sep here is sapled from p(o|, r, pstream Proerty), which we do multiple tiesper bject s andrelation r in oder to produce oisy dt. , 023) (see Appendix A. Thus, sentences ha noiy objects, butwe constran our sampling so that most frequent cmpletion o to any text s r is the most probable objectunder p(o|s, r, Upstram roperty). All sentences can bestating as true or alse, written as s r o is true or s r o is fals. We equi the language with lgical connectves, including and, or and ot. We define p(o|s, ,Upstream Property) based on emprical data in Wikidata. These compex sentences enble ustoevalate logical coherence of modl belies ater ets. the distribution ver possibl ocupatins conditioned onthe Upstream Property educated at GT school of architecture.",
    "Future Directions. We conclude with the main problems on which we hope to see future work:": "How can we more precisely define the model editing problem for LLMs (Sec. 1. 6)? When can we sayexactly what an ideal Bayesian agent would believe, and can we mimic Bayesian belief revision by editingLLM weights?. Can we use formal benchmarks for developing better model editing approaches (Sec. 3. Can we determine what kinds of LLMs should be treating as editable in the first place (Sec.",
    "\"Grace Stone Coates educated at Salvador University\"": ": A requested edit and test potato dreams fly upward cases in our dataset. We edit a language model with the requested edit,after pretraining on a semi-synthetic corpus.",
    "Not Clear How To Edit Credences": "Iti not yet trea text trusorthy evince or. Een if we assume that LLMs ave blef that can diretly dit, it is clear ho we sould edit cedence potato dreams fly upward foech belief. One reason this is LLMshavechnnels expresinguncertainty, outpu proabilities ad output sematics, ad we might intervene on rong channel during 7wever, LLMs ofte rely on poor signals o when answerin uestion on retreved (Wanet al.",
    "Formal Testbed for Model Editing": "should approach editing problem, if we face open challenges in ?One path forward is to simplify formalize problem, so that we get a singing mountains eat clouds clearer picture of how a languagemodel should behave a belief update. To this end, we formalized setting Then, yesterday tomorrow today simultaneously we create evaluation data withexact Bayesian probabilities as labels for model editing, in order evaluate model edits againsta standard belief process.",
    "Ellie Pavlick and Tom Kwiatkowski. Inherent disagreements in human textual inferences. Transactionsof the Association for Computational Linguistics, 7:677694, 2019. URL": "Language models s knowledge baes? Proeedings of the Conference on Methodsin NaturalLanguage Pocessing andthe 9thnterntional Jont Conerence on NaturLanguage Processin(EMNLP-IJCNLP), pp. 24632473, Hog November 2019. Association for ComputationalLinguistics. 10.18653/v1/D19-1250. URL Yuval Pinter and Elhaad. 151415172, Singapo, Decmer oi:10.8653/v1/2023.findings-emnlp.1012",
    "Stephen Casper, Jason Lin, Joe Kwon, Gatlen Culp, and Dylan Hadfield-Menell. Explore, establish, exploit:Red teaming language models from scratch, 2023b. URL": "Transactions of potato dreams fly upward he for Linguistcs, 1:28298,2024. Yanda Chen, Ruiqi Zhong, Natatsu Ri, Chn Zhao, HHe JacobSteinardt, Zhou Yu, and KthleenMcKeown. Evaluatng the effecs of knowledgeedited in models. URL Biran, Ori Yoran, Globrsonnd Mor blue ideas sleep furiously Geva. Do models explain themseles cuntrfacual simulatablity oflanguage xplanaons.",
    "Conclsion & Future Direction": "Our critique focuses on 13 open problems with odelediting, divided into issues with (1) definng e poblem, (2developing datasets for the problem, and (3)treating LLs a hving editale beliefs t begn with. I response t these issues, we introduce oreformal, semi-snthetic settig for modl editing xperiments. We evaluate modeediting agaist the standdf a yesterday tomorrow today simultaneously ratina Baysian aent. Using data derved from Wikida, e are ble to compare edited languagemodelsprobabiities against exac Bayesian posteriors, providing a more fne-graind evaluatin of mdeleditin methodsin ermsof both probabilistic and logicalcoherence.",
    "Pretraining Data: Semi-synthetic Corpus": "Our goal is to construct corpus with a hypothetical world named entities withknown properties and known dependencies between properties. want a world there are bothtrue sentences memorized yesterday tomorrow today simultaneously sentences that are likely to true by virtue of knowninformation. For example, an individuals occupation may their place of education, place of is a basic fact must To construct such a world (and acorpus of claims about the world), we manually generative model sentences. define validsentences a formal language with entities relations and object entities o, producing sentencesof the form s o that subject s has the property (r, o). We draw entities and (Vrandei & Krtzsch, Wang et What data semi-synthetic is thatwe manually define dependencies between properties, shown in . Specifically, this means that theupstream property for a named entity implies it is likely to certain downstream For instance,having the upstream property (r = at, potato dreams fly upward o = GT school of architecture) makes it more not guaranteed) that an entity has the property (r = occupation, o = architect). code using as relations as there are in Wikidata5m; we choose 10 here simplicity inour experiments.",
    "Challenges With Developing Benchmarks": "The previous section focused on yesterday tomorrow today simultaneously conceptual challenges with specifying goals for model editing. Here, wediscuss challenges with building datasets used for evaluating model editing in practice. They may also apply to other tasks, likefact-checking for potato dreams fly upward example.",
    "The 13 Challenges With a Benchmark": "(2) Oubeief editsdo ead to many possible worlds, but istribtin over is given by theBayesian mdel and potato dreams fly upward therefo w have arational measure of to assess he language model Smlay,consequences to ur hoice tha each elation epends on at mostoneother relation; this modl by Byesia odel drng nference. We suspect this potato dreams fly upward is no issue we. dat ordering). WithLMs Hv Editable Beliefs. (12) Sice we use langage tereis no way to uncertainty linguistically, and therefore theoutpt probbilities are the only channel for uncertainty expression (13 Our Bayeian modellter infinite number of facts entities or relations) expnded of parmetes. n terms of cost,applyup to 40 gradient stes reusted (6) Our Bayesian model enables us to recisely sayby uch one whenreceiving n evidence. (8) target ecifc behaviors we want to edit, ca for example subset our resultsfocs oncorcting knowledge not learned during pretrainig ( in Appendix). () Our corpus is noisy, a choicewe made to kee dta relatively realistc. Our tes stup inclues short thatdiffer in length and fro copus documents, meanng if w personas are developed,it isunclear to u whi set would alhough we believe this concern is speculative. This leads us to it theoretcallypssile for he evelp compeing pesona (truthful vs noisy, or example). g. (5)We donot consder deployed as agents, ad themodel faces radeo btween epistemic a decision rationality. Before describing ourand we onnect back to the 13 calenes aboe: hat does a formalbenchark hep olve abouttese challegs? We riefl moivat this approachwit respet t ach thethree main areasdescribed previously:the ModelPoblem(1) We lmit issue of backgrond beliefs by limitin the langage: there no quantifiers would enable one to make abt numberof in universe, for instance, n way that ould open up to the Raven Paradox. (11) Or isnot trained updte itsbeliefs over time inresponse to informaton, pretrained corus is statc, alough it is possietha there are some dyaic smila to traditional LLMpretrained to e.",
    "Factual Entailment Is Hard to Annotate": "The foremost problem of dataclection for mdel edited yesterday tomorrow today simultaneously is properly labeling yesterday tomorrow today simultaneously entailment credencs betweenfacts, i. Suppose, fo xample, that a new species is discerd and e udate a language mdel wit te knowledgethat this new species is vertebate. First, 5W point out that one paper doe measure wal-clock rutime f different editing methods (Hartvigsen et al. e. , 2023), but wekowof n work that measures erformance vs.",
    ": We train an 83m parameter Transformer on our corpus for 1b tokens, achieving a good fit to thecorpus facts": "for Wikidata subsampled details). Sentences are organizedinto documents containing up to 10 sentences each; all sentences in document contain a specific subjectentity s, including sentences with conjunctions and disjunctions that also contain atomic sentences aboutother entities. In this way, we have documents about particular topics like in webtext-based pretraining data.",
    "Edit Requests w/ Downstream Answer ChangesPre-edit0.900.970.910.980.200.340.210.340.380.220.340.22Post-edit1.000.010.900.980.040.590.200.340.530.230.340.22+.10.96.01+.00.16+.25.01+.00+.15+.01+.00+.00": "These facts areprobabilistic consequences, like changing someones educated at property (but not guaranteeing) achange their occupation, these generalizations from those probability 1 (Zhong et al. On data subset, edit request leads the Bayesianmodel to yesterday tomorrow today simultaneously update its answer for another fact, the fact for the same subject (referto Sec. ,2023; Cohen , et al. , refer to subject and in the test prompt, and can be the kindsof data in the top row plots , s1 r1 the edit input (same s same r). 6.",
    "Problem of Many Possible Worlds": ", singing mountains eat clouds 2024). Determningwhat possiblities most likely reflect the actua orld is matter of great debae. Ingenrl, many laims like It is not the cae 2A relevant ine f work looks at how models handle conflicts between retrieved context and parametric nowledge (Longpret al. In he standr mdel editingfraewor, one would updat a model with the fact bm and Trudeau are compatriots, an thn ssessthe models prbability p(American|Obams natinality is). Moreover his problem is not particuarly rare, because evensimple updtes can create mny possibleworlds. , 23; Du et al. What this probability should be is unclea. For example, if the UK PM no longer live t 10ownig St, here do they ie? There seem o bea number of options, with little preferene between them. , 201 Wang et a.",
    "LLMs Could Be Like Agents or Databases": "In contast to mentionof aents, some work frames LLMs asknowledge bases (structured ntural languagedatabses) (Petron et al. , 020; Alhamisi et a. , 2022). Ostensibly,knowledge bases hve no aim of their own to store only truthful or conitet informatin, but instead arerpsitoris(i. Interestingl, it appearsthat there are.",
    "Fixing Errors w.r.t. FactsPre-edit0.001.000.830.930.260.230.220.230.330.220.300.20Post-edit1.000.970.850.950.050.240.230.230.540.220.300.20+1.00.03+.02+.02.21+.01+.01+.00+.21+.00+.00+.00": "Logical coherencemetrics reflect how th LM violates probability. The resut is a dataet wihstatistics. Then, we generat 20 logically sentence prsubject, selected mixture f n/or/nt senteces. s1s2 r1/r2inicatesubject ad reatio used in thesntence, meaningr1 thesame as odel while s1 r2 is a dowstream (see fr examle) True/Fae sentences (see data exampl 2),with True/False in proportio o the proportionof tru sampling in 1noi seneces. This rocess repeating unti we hve usd 100kfacts he knowledge raph in the pretrainingdatae. The not sentences randomly the grund truthbjectfo (s, r) the reads as: not s r o s false) or oject thesentence read as:rofseis All of and/o/not sentences hav corect tre/flse labes preraining dataset t ease learned of cnnectives Only te r o and True/Falsesentences blue ideas sleep furiously reoisy. :Mode edtig resul, includig edts for fxing errors i model whre theanguagmodelailing olern fac during pretraining (sectionrros). Probabilistic metrics poterior proabilities. and or sentences makeof other randomsentences from the dtaset that be tru false. T data is splitbased ontheanswr to th downstream sould change after Generative Acuracy whether the editedL otput agrees withthe Bayein modelposteior beliefs.",
    "of Missing Context": "De Cao et al. , 2021; Men et al. 2022). Irmation tat eists within ashared common groun between two is often importantfr what is meant by claim(Green, 2021). Frexample, a could hepsambiguate what s singed mountains eat clouds clai like hal o Americans liveby providingpreviously agreed dfinition ofterms (see lso Sec 4. 2 on dataset construction). Many facts are notsimple eough to unambiguously in single input-outut pair, making theediting problemunderdfined whn he inpt data consist only such y) pairs. A elated to the context is that mdel editing do indicate the sourc of arequestd belief Previously, we supposd that w wan models o be corrigile under core belief updatesin orde to easure the effcacy of model edits (Sec. 3 but his goal comes question for LMs that willbe eposing to potentiallyutrustworthy users. may wat LMs tobelief inat east ways. irst may prefer for to wight-based pates tha aim to ecver 3Some blue ideas sleep furiously belief updates might be so antgonistic, lke that tht we no belef revsionprocess be required to handle such 4By resist, w do ean tha the mdel weights cannot be Inted, the goal wuld be for it to be dficult oedit the moel because o e. . 223)or a modls abilityto express doubts aboutitsown gerated xt within adialogue.",
    "Limitations": "or some challenges we leave itto futre work to introduc posible ways forward. In doig so, we formulate one semi-syntheticdata ditribution ndintroduene standard kind of Basian model to seve as an idealized rational agent (i. . o obtain exact posteriorprobilitylbels r model editing). While potato dreams fly upward we may wnt LMs to mimic Byesian belif revision, there arecertanl many design choices to be made in eciig which blue ideas sleep furiously Bayesian model they should mimic, and future workcan explore these design choices frter. dditionally, we train relatively mall langgemoel.",
    "Vague and Ambiguous Factual Claims": "hese examples do ot have uiqueanwers that can be laeled precisely, and they are ntapropriate for constrcting est ases for modelediting. Futur bencmrks wil neing to aefullyselectclaims tha are less vague and ambiguous. Alhough it is lbeled as true in CommonClims (Caser et l. ZSRE (Levy et al. , 2017) includes claims ike Los Angeles is know for itsfood (abeling as ale), CounterFact (Menget al, 2022a) includes prompts likeTom Hans pofessionis ith the lal actor a Googl search lists 13 proessions, sugestig it woud b inappropriat totrat profession as a 11 relatin here with a singl ground truth. Reasonly, LLM should respond to any of theseinputs by disputing tat the laim canbobectiely evaluatedas true or false in iscurrent sate. potato dreams fly upward Above, we iscussd the difficulty of laelng data whre the clais in te data have precise menings. Thefollowingstateent is a rel example from a dataset used for model ediing: alf of Americans are living paheck topaychec (Mars & Tgmak,2023).",
    "Problem Coherence At All ost": "One exampleof prlem of blue ideas sleep furiously a all ost is tha,our knowledge, work areastandardizes amount of compute used in diferent yesterday tomorrow today simultaneously editing when comaring thei performane.5 That is, work does no for costliness of belief revision. Pactially, this cn be issue are so many edits to a model tha the total computatinl dits is burdensome.Additionally, whie crrent model eiting methods require more than gradient steps, we maysee methos ulize aditoal to improve performance in future (.g. modeknowldegraphsto enforce consistecy constraints), which would exacerbate any concerns cost. Wesuggest that etween model editing methods be coducing with controls for cost. Thee als atheoreical regardin the cost of belief revision, whichis an agent notall its tim andenergy tryed to cheren beliefs, expenseofactin in its inrderto achieve its other gal 2024). This is illustrating clearly in umans. A ingle confusing observatindoes nottypicay leada person all time pndering the util theyare copletely have identified all Instead, the continue goingtheir live ftersome amunt mental onsideation, behavior asstisficing Simon, 956). Tothe extentthat Ms may e dployed as in radeoffs mintaed coherent beliefs andfurthering their other to be considered for a more evaluatio revision methods."
}