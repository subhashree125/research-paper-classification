{
    "Abstract": "3D Gussia Splatted has advanced radiance fid recntructon, enabling high-quality vie sthesis and fas renderng in 3D modeling. ile dversarial attackson detcton mdels are ell-studied for 2D impact n 3Dmodels rmainsundeexplored. This work introduces Msking astGradient (M-FGSM),designed to rsarial noise t CLIP model. M-IFGSM specifically alters te object by focusing on regions, degraded performanceof CLIPs object detection capability when appliing to 3 models. sineight objects from Common bjects D (CO3D) dtaset, demontrate thtour method reduces the accracy of the model, with nois ein nearly mpercepibe human obserers. The top-1 accuracyin original model reders dropsfrom 5.4% to 12.5% or trainimages and from91.% 35.4%for images, itcoidenc reflecting shift clssification misclassificatin, undersred risks of adersarial 3D in such as automous driving, robotics, and surveil-lane. The significance of this research liesin its to exposevunerabilitiesin odern 3D vision including mpted developmentof rbust and scurity measures i citical real-world",
    "Conclusions": "In this we adversarial attacks targeting vision-language specificallyfocusing on object detection capabilities, and explored the of these attacks to3D models. employing Common Objects 3D (CO3D)dataset, experiments on distinct classes, creating noisy 3D models withadversarial noise from images captured angles. The significance of this lies in its extension of adversarial attacks 2D vision systems object detection models, which presents a previously unexplored research.",
    "Perturbed Images Results": "presets the confidence ad auracy forpertured mags generated usinM-IFGSM. The OriginalImagesolumn contains the confidence and accuracyforunmodified images, as prformnce. T dversaral Iaes column shows statistics fr perturbed iage, yesterday tomorrow today simultaneously highlighting th in the confdece ndaccuracy de the adversarialperturbaions. of the originl image results (left and bottom) theircounerparts rigt bottom.",
    "Average0.7300.9490.9960.8800.0210.064": "The average results that for images, the appears in predictions94.9% of the time in the top-5 predictions 99.6% the time. After application of M-IFGSM,these figures drop significantly, with top-1 accuracy falling to just 2.1%, and top-5 accuracy to models confidence increases dramatically for adversarially perturbed images,showcasing the methods Adversarial Images column in provides the same statistics for the perturbed the method. These values reflect the impact perturbationson the classification highlighting the effectiveness of the M-IFGSM method in degradingthe models confidence accuracy. comparing the results between original and we can quantitatively the the object detection system to the",
    "limited research on the robustness of 3D models against such attacks, especially in vision-languagecontexts Zou u. a. (2023)": "Unlike tadtional2D adversaril attacks Mdry u. a.(218) M-IFGSMfocuses pertrbations on masked regions f 3D ojecs, creating adversarial noise thatremains nearlyimperceptible to humans while significantly degrding model accuracy.This mased approchalowsfor  more targeted ttack, where oly speciic regios of the3Dbjec are perturbed,makingdetection f theadvesaial noise more challengig. We validae our aproach thrugh extensive experiments ung the O3D dataset Reizenstein u a 4%to 12. % to 35. 4% on tes images Thes rsus illustrate thepotential risks posed by adversarial taks on 3 moels, which are beoing ncreasingly prevaentin safet-critcal apliationssuch as autonomous driving, robotic, andsurveillance. By exposigvulnerabilities in vision-languae models he aied to 3D objects, his rsearc undrscores thepessing eed to develop robust defense mechaisms in these highstake dains. ur cntributions are threefold: ) Frst,e propose the M-IFGSM method, whic itroucesa noelapproach o adversaril attacks n D models witina vision-language contxt. ii) Second, weleveage3D GaussianSpattin to geerte adversarial perturbations that are localized t maske regn,provdin a fine-grained method to cpromise model erformance iii) Fially, we emphaie theeal-world impicationsof such ttacks, underscoring the urgent need to develo roust defenses forsystems relyng n 3D objectdeetion incritcal apliatins Our appoach significantly reducesCLPs accracy in 3D object detecton with mnial, almost iperceptiblenoise, resulting in asubstanial drop i top-1 accuracyacross boh train and estdatasets.",
    "[Goodfellow u. a. 2015]GOODFELLOW, Ian J. ; SHLENS, Jonathon ; SZEGEDY, Christian: Explain-ing and Harnessing Adversarial Examples. 2015. URL": "2018]MADRY, Alekander AKELOV, Aleksandar CHMDT, Ludwig TSIPRAS,imtris ; VLADU, Adrian: Towrdsee leaning models resistant to dvesarial attks. I:Iternational Conerence o Learnng Reprentatins (CLR) 2018[Reizenstein u. ;L, Wan-Ye ;DOLLR, iotr Ros Aythin. a. [Kim u. PengChuan; ZHNG, Lei:ison-Languge Intelligee: Representation Learnin,and Models. In: roceedingsof he Conferenc Visio Patternecogntion [ong u. 21]REZENSTEIN,Jeremy ; SHAPOVALOV, Romn ;Philipp ;SBRDONE, Luca ; LABATUT, Ptrick ; NOVOTNY David: Common inandEvaluatin f Rea-life 3DCategory Reconstuction. a. In: InternatonalConfereceo Vision, 2021 [ShonbergerFrahm 2016]SCHONBERGER, Johnes L. 204]KI,Yeseung ; KIM, Dohyn ; CHI,; PARK, Jisag H, Nayoung Daehyung: survey on integration oflrge anguage wihIn: ervice Robotics August. 222 UL [Li u. 224]LI, XIE, Bin ; GUO, Songao ; YANG Yanyuan ; XIAO, Bin A obustness ad safet of anddeeplearnng models againstadversarial attacks. S. [erbl u. ;FRHM Jan-ichael: Structre-FromMoioRevsited. a. In: ACMComputing 56 (2024 Nr. 137 [Mary u. 2022]LI, Fg ;; ZHNG, Yi-Fan ; LIU,Shilong ; GUO,; Lionel M. a. a. Liu. 2024]ONG, Ziying ; LIU, ; JI, eiyang LUO, Yada ; JIA, Caiyan ZHANG,Guoxin ; YANG, Lei ;WANG, Li: Roustness-aware 3dobjec deecion in autonomous driving: Arevie andIn: IEEE ransations on Intlligent Tranportaton. URL ISSN 1861-2784 [Kirillov u 223]KIRILLOV, lexander MINTUN, Eri ; RAVI, Nikhia; MAO, ROL-LAND, Chloe ; Lura XIAO, Tete ; HITEHEAD, C. 2023]KERL, Bernhard ; KPANAS, ;LEIMKHLER, ;DRETAKIS,orge: 3D Gaussin Splatting for Rel-Time adiance Field In: C Transac-tions on Graphics 42 (023), July,Nr. 4. a.",
    "The untargeted attack is as:": "In the second stage (right),tese adversarial imaes are used o create a3 model through 3D Gaussia platting, resulting in a 3DGS poit cloud thatcapturesthe adversarial characeristic in a 3D format. Finally, the 3D model is rendred to produeimage that retain he adversarial proerties, allwed for an evaluaion of adversarial noieeffecs in 3D object detection. : Two-stagepipeline or generating adversarial 3D mdels using he proosedMasked Iterative Fast Gradient Sign Method (M-IG and 3D Gaussian Splatting.",
    "Method": "traditional adverarial attack by focusing perturbatos solely ofinteres withn input mages. In this section, introduce our the Masked Iterative Fast Gradient Sign Method(M-IFGSM), designed to geeate adversarial perturbations specically targeting 3Dmodels in avsion-languge context. detail comonnts of our pipele, including segmentation Segment AnythigModel adversarial perturbation geneaion M-IFGSM,and 3Dmodel reconstruction ui Splattng. ii) Adversarial Generation:Applying M-IFGSM geneate noise focusd on masked rgion. illustrtes th.",
    "[Szegedy u. a. 2014]SZEGEDY, Christian ; ZAREMBA, Wojciech ; SUTSKEVER, Ilya ; BRUNA,Joan ; ERHAN, Dumitru ; GOODFELLOW, Ian ; FERGUS, Rob: Intriguing properties of neuralnetworks. 2014. URL": "223]ZHU, Zijian ZHANG, Yichi ; CHEN, Hai ; DNG, Yinpeng ; ZHAO, Su ; DING,Wnbo ZHONG, Jiachen ; ZHEN, Shiba: Undertanding the obusness of 3D Object DetectionWithBirds-Ey-View Repeseatins i blue ideas sleep furiously Autonomus Driving. In: Proceedings of the IEEE/CVFConference on Computer Vision singing mountains eat clouds and Pttern Rcognition, 2023, S. 024]ZHOU Xingeng ; LIU, Mingy ; YUTSVR,Ekim ZAAR, Bare L. : Advearial atack beyon the image spae In Procedigsof theIEEE/CVF Conferenc on Computer Vision and Pattern Reognition, 2019,S. [Zeng u. 2019]ZHO, hon-iu ; ZENG, Peng ; X Shou-to ; WU, Xidong: Objectetection with dep larning: A reew. a. 321233 [Zhu u. 2160021610.",
    "Experimental Setup": "target the ViT-B/16 model Dosovitskiy u. .(2021), wich combies and languae understanding. The model ivides input images into16 16 processe hem using trasformer lyers. daase contains approimatel 20imes from angles. We reduc number 41 images class electing every fifthiage and esizing them to pixels to ee the requiremns of CLIP. Our conducting on system with NVIDIA RX GPUs.",
    "Algorithm 1 details the iterative process for generating adversarial images. In our experiments, weset the loss threshold to 20.00 for early stopping": "Our pipeline is designed with flexibility in mind, allowed to generate adversarial for a varietyof object classification models, not solely CLIP",
    "Results": "In ths section, we present and analyze the outcmes of our epriments conducted t valatethe effiacy of M-IFGSM for generating adverarial oisein the conext f 3D Gassian Splatting(3DGS)",
    "D Model Reconstruction": "After advesaria images with M-IFGSM, 3D models the GaussinSplatting metho Kerbl . (2023) W usean 85-15 train-test with images for trainingand six for testing. i) Initialization: a spare poit cloud fromStuctre Moton Schonberger ud Frahm (206) to initialize 3D the Gaussians parameters (position, pacity, color) via descnt tomath the adversarial images. iii) Density Control: Refinn the model byorsplitting Gassians in uner- or over-reconstructed areas."
}