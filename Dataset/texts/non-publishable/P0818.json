{
    "Analysis": "The above experimental results that the PGM-Aware agent can improve of eachmetric to varying degrees. The discussion partexplores PGMs from other aspectsin each How PGM of yesterday tomorrow today simultaneously different LLMs help Judge-ment and Reasoning?In pro-vide case of Llama-2-70B, GPT-4, theirPGM-Aware versions playing blue ideas sleep furiously as non-chameleonsversus GPT-4 as the For Llama-2-.",
    "}}": "\"Player3\",\"topic\": \"Fied Airport Fe: $1,000,000Airlne Usage Frequency Data: ANumber of Flights: 90/monthNumberof 700/mothAverage Flight Duration: 1. 75 hrslight Sze small and medium aircraftAirline B:NumberFlights: 50/monthNumber of Passngers: 7,00/month\\Aerage Flight Draion: . hoursFligh Size: small aircrafAirine C:Number of Passegers: 7,500/nthAverage Flight Duraton:",
    "Saaket Agashe, Yue Fan, and Xin Eric Wang. 2023.Evaluating multi-agent coordination abilities in largelanguage models. arXiv preprint arXiv:2310.03903": "Chquette-Choo, AakakshaCowdhery, Clment Crep, Dav, MosafaDehghani,Sunipa Dev, Jacob Devli, Mark Daz,Nan Du,Ethan Der, Vla Feinberg, FangxiaoyuFeng, Fieer, arkus Freitag, Gar-cia, Sebstian ucas Gonzalz,Gy Gur-Ari, Seve HadLe JoshuaHowland,Jeffrey Jeremy Hur-witz, Isard, Ab Ittycheriah Jagiel-ski, Wenhao Katheen Kenealy,Krikun,neha Kuduguta, ChngLan, Katherine Lee, Benjain Lee, Eric Li, Musc Wei L, YaGuangLi,Jian Li, Heonaek im, Zhongtao blue ideas sleep furiously Liu,Marcllo Maez, isra, Maysam Mosslem,Zachary Nao,Jon Nham,Eric Ni, Andew Ns-tro, Parrish Marie Pelt, Martin Polcek,Alx ReinerPop, Syuan Reif,Brya Rihter, Parker Riley, Alex astro Ro, Aurko Roy, Brennan Saeta, Rajkumar Samuel, Ambose Slone, Daniel Smilkov, R. Palm ecnicalrepot. ElShaey, YapigHuang, athy Meier-elstern, Mishra, EriMorer, Mak Omernick, Sebastian Ruder, Tay efanXu, Yujing Gustavo HernandezAbego, Junwhan Ahn, Jacob ustin, Pal Barham,Jan Botha, James Brahma,Kevin Brooks, Michele blue ideas sleep furiously Chng, CoinChry A. Rohan Anil, Andrew Dai, Orhn irat, evin Dmitry Lepikhin, Alexandrasss,Emanuel Taropa, Paig Bailey,ZhifengChen, Eric Chu,H. So, Sohnoumine, Dasha Valter,Vijay Kiran Xuezhi Wang, iu Wng Tao Wag, John Wie-ing, Yuhuai Wu Xu, YunhanPengcheng Yin, Jihui Yu, Zhan,StevenZhng, C Zheng, Weikag Zhou, Denny hou, Wu.",
    "Player 1 (clue) => It's something you wear on your head.Player 2 (clue) => It's something that can change your appearance.Player 3 (clue) => It's often used in theatrical performances": "Moderator = Now we starting antherround of luePlayer1 clue) => It c be mae from synthetic materials. Plaer (lue) => It an be used ove Plyer 3 (clue) => different colrsand style. layer = I vote for Player Player => I vote 3; Playr 3 I voe Playr Moderato=> The player isPlayeTeaccusation Player 2isth underover.",
    "We have designed different prompts to test LLMssability to make PGM analyses.Two kinds ofprompts are used: text-based(w.PGM) and di-": "3,0. 5],[0. ProPGM). 3,0. 5-turbo, both kindsof prompts work well. 5],[0. 3,0. We found that more capableLLMs, like GPT-4 and GPT-3. 2. 0. The threeroles represent B1,B2, and B3 respectively. There-fore, we mainly choose the prompt the LLMs togive text-based PGM analysis to ensure the help ofPGM on all the LLMs. The latter requires LLM to di-rectly give a probabilistic matrix to representthe global information, for example, matrix[[0. 4]]. 1,0. In specific,the former lets the LLM analyze global infor-mation in text, as shown by the example in. rect probability matrix(w. 4,0.",
    "Player 1:[[0.237 0.372 0.391][0.333 0.333 0.333][0.345 0.322 0.333]]": "Moderator => No ote which of the other players (exlding yourself) is the chamelonPayer 1 => I voe for Plyer2. Player 3 => I vote fr Playe 2. Moderator => he accusation s correct! Playe is the chameleon!Now Plaer 2 can guess te singing mountains eat clouds secret code. Moderator => Plar 2 guessed the code wrog! Non-Chameleo yesterday tomorrow today simultaneously won!.",
    ": Features in game theory analysis": "Forexmple, i ublic Good, we chose find in he upperdiagram in , even though mul-tipleris increasing, all th lines do not to increae which proes thatall th tst halenger LLMs are sensitvetothe increased possible payback in the communalpol in our Similar phenomena alsohappen in Prisners Dilemma. As shown by thebottom diagram in the x-axis is the which three digits, represn-ed the score a player can get in situations plyr defects the two playerdefecs when the other wo coperate,and the plar defectwhen one of the other twodefects, respetey.",
    "Player 2 lose !": "Player 2 In my opinion:As Player 2,I think Player 1 will choose to Cooperate again, because in the first round, Player 1 chose to Cooperate and it is generally beneficial to continue cooperating in order to maintain trust and maximize the overall score. I think Player 3 will also choose to Cooperate again, because in the first round, Player 3 chose to Cooperate and it is likely that they will continue to cooperate in order to establish trust and encourage cooperation from the other players. Player 3 will choose to Cooperate again, because in the first round, Player 3 chose to Cooperate and it is advantageous for both players to continue cooperating. I think Player 3 thinks:Player 2 will choose to Cooperate again, because in the first round, Player 2 chose to Cooperate and it is beneficial for both players to continue cooperating. Player 1 will choose to Cooperate again, because in the first round, Player 1 chose to Cooperate and it is advantageous for both players to continue cooperating Player 2 In my opinion:As Player 2,I think Player 1 will cooperate, because in the previous round, Player 1 chose to cooperate and it is likely that they will continue to cooperate in order tomaintain trust and maximize their own points. I think Player 3 will cooperate, because in the previous round, Player 3 also chose to cooperate and they might continue to do so to maintain a cooperative strategy. As for other players,I think Player 1 thinks:Player 2 will defect, because in the previous round, Player 2 chose to defect and they might continue to do so to maximize their own points. Player 3 will cooperate, because in the previous round, Player 3 chose to cooperate and they might continue to do so to maintain a cooperative strategy. Player 1 will cooperate, because in the previous round, Player 1 chose to cooperate and they might continue to do so to maintain trust and maximize Player 2 In my opinion:As Player 2,I think Player 1 will cooperate, because in the previous round, Player 1 chose to cooperate and it is likely that they will continue to cooperate in order tomaintain trust and maximize their own points. As for other players,I think Player 1 thinks:Player 2 will defect, because in the previous round, Player 2 chose to defect and they might continue to do so to maximize their own points. I think Player 3 thinks:Player 2 will defect, because in the previous round, Player 2 chose to defect and they might continue to do so to maximize their own points. Player 1 will cooperate, because in the previous round, Player 1 chose to cooperate and they might continue to do so to maintain trust and maximize their own points. This suggests that Player 1 may be more inclined to prioritize their own gain over cooperation. I think Player 3 will Defect, because in the previous round, Player 3 also chose to Defect. This indicates that Player 3 may have a tendency to defect regardless of the choices made by the other players. Player 3 will Defect, because in the previous round, Player 3 also chose to Defect. I think Player 3 thinks:Player 2 will Defect, because in the previous round, Player 2 chose to Defect.",
    "PGM Structure": "This heightened understandng can faclitate informed actions/decisions. ThePM should be thoroughtoensure dcision-making for agen. Forinstance, onsidering the prisoners dilemma sce-nario, before to or cooperte, it iscrucial to thers defectorand, from thers perspectives, howyo will decide. If you anticipte that othr play-erscooperate and tey expct the samefrom you,bt you choose to it la to adantage for 2023, which is a-pacty to comprehend human by predictingtheir unknown eliefs and PGM usesrahs o illustrate te conditional dependeniesbtweenvariables(Koller and Fiedman,2009), makig it suitabe singing mountains eat clouds for under-sandng interactions mog multiple players. Formally, as shwn in singing mountains eat clouds , suppose there are three A, B, ad C, in ame played game for 1 turns Ti1 = {a1, b1,. , ai1, bi1, }. Hera, b, are the decisions from and C, respectivey. As a PGM-aware manages three distinct random B1, B2, and B3, representing Bs interpraonsof the globa status from A, B, an pespective. We obtain the esimation for these adom variablesby prompting LLMs throuh different aslsted n A. 7, pgmj, j :.",
    "Player 3: [[0.337 0.326 0.337][0.33 0.33 0.341][0.403 0.365 0.232]]": "Moderator Player 2 the coe wn!. Moerator => Now vote whih of other player(excluded yourelf) is h Player 1 => I vote or layer 2. 2 => I vote for Plyr 3. Player 3 => for2 Payer I heode Appl\".",
    "GPT-3.5-turboGPT-4": "Plaer 2=> tssmething that can chang yu appearance. Payer  => It's often used in theate productions. Playr 2 is heudrcover! ivilanswo!Playr 1 = It'ssomething you ear on yourhead. Modeator => Nw we strting another ound of givPayer 1 => It can be made f snthetic materials. Player 3 > It's often used bypeople who avest their hair. Moderator => Ther are even votes. Player 2 = I's somthig that can e styled in different ways. Payer 1 => I vte for Player2 Payer 2 => I vote for Player 3; Playr 3 => I vote for Player 1.",
    "Llama-242.837.10.06.050.0139.1Llama-2+P52.437.638.59.864.8109.5GPT-3.5-T57.137.333.39.579.5166.2GPT-3.5-T+P71.434.252.411.657.1139.8GPT-447.630.542.99.9561.9175.3GPT-4+P61.930.376.210.685.7144.1": ": Detailed results in game theory scenarios.Cost, and Payback are the average cost,the the average the got in the Cost sharing, Prisoners Dilemma andPublic Good, respectively. indicators theory scenario. we calculated the final thechallenger LLM needs to bear after their negotia-tions. In the negotiation, this another theLLM-powered agent should consider when tryingto reach an with other agents. How-ever, these contradict each othersometimes. For example, when the player tries toreduce cost itmight be hard for achieve agreement withother players. The LLMs need to make a balancebetween two According to the re-sults in , we find that within modelswithout PGM GPT-3.5-turbo Rate while GPT-4 in Cost, indicating bothmodels are not well-balanced. If we compare the with PGM, GPT-4+PGM increases and keeps the cost slightly GPT-3.5-turbo+PGM increases the Win Rate and reducesthe simultaneously. This proves the effective-ness of PGM enhancement and demonstrates thatGPT-3.5-turbo tends to be collaborative the of Does with reward?Similar phenomena happen in Prisoners Dilemmaand Public Good as illustrated in . thesetwo scenarios, a player is more win whenhe chooses to betray a prisoner or chooses toreduce to the common pool the pub-lic good behavior is considered Ra-tional our When most the playersare rationally, the scores payback willbe much thus approaching the well-knownNash Equilibrium (Kreps, In the if we compare GPT-3.5+PGM and GPT-4+PGM, won more but got lowerscores, showing that GPT-4+PGM made ra-tional decisions than GPT-3.5-turbo+PGM. Good, found models with PGM Win Rates but lower payback theyall performed more this scenario. Ifwe compare the within models with orwithout PGMs, we can observe higher forGPT-4 which proves modelsare more strategic these yesterday tomorrow today simultaneously games.",
    "A.1Competitn Settings": "Setting hameleonUndercover, thereare clearlytwo opposite roles, theChameleon versus and versus Civilians. The challenger LLMwill play rol. the challengerLLM play versus GPT4 as thechameleon, and challngr LLM plays thechameleo as o-chamleons hewi rates of the chalegerLLM layng differ-ent roles be clculate separately, which co-tributes to in totl 4 win rates.Cost hring hasdisinct parties.Therefore,we made tehallenger LLM one playwith T-4-powerd The insuccesful negotatis he ratewhich measures ow much the LM contributes when other players are fied. Simlarly, fr public ood prisoners wealso ade the challengr LLMoneof the payersnd ts winrate n togame.Thedeiled rte clulations are presente in A.2.As shown in , we he number fsettings, corresponding metrics, nd setting for scenario. W 20 fochameleonand undercover, repectively In eachga, oneround f clue whileundercover conains 2 eachof thegae theory scenaros, collected 21",
    "siSwsi(1)": "Here S isthe et of roles the challenger LLM playin all te scearis. In Chmelon and Undercover,the challnger LLM play the ChameleonNn-Chameleons Undercovers, and Civilians repec-tively. hus the length ofS i 7 in our benchmark. For each role, e haefined the rteria for winning and dnote he winrate a wsi,si potato dreams fly upward S. The detailed definitions forwinning rates of al roles can be foud in A. Judgement measures the singing mountains eat clouds final nderstandin of theglobal information, essential for assessing LLMsability o distinguish other players idetities based.",
    "Area": ": The radar chart depicts LLMs performanceon 7 metrics, with -T for -turbo for+PGM. There is an increasing in investigatingLLMs behaviors as agents in single- or multiple-agent systems. (2023), evaluateLLM-as-Agent in multi-turn contexts, while con-current work by Wu (2023) social aspects and Fu et al. (2) Con-texts are in multi-agent systemsdue to nature of agents decisions. Success hinges on the ability yesterday tomorrow today simultaneously to in response to evolving contexts. ability topromote cooperation preserving self-interestis often ultimate goal of multi-agent systems. Inspired the above characteristics, a competition-based to eval-uate the as by compet-ing with a fixed type LLM. Self-awareness is an assessment of agentsunderstanding of their and en-suring the consistency of behaviors thetarget. Deception enables agents to subtly information in competitive settings, other agents gaining interactions. (3) Rationality as ametric efficiency of an agents behav-ior. It directs agents decisions of optimizing their benefits the potential actions of other agents rather impulsive uninformed (4) Cooperation and coordination are two facets essential effective systems. Cooperation measures and Coordination indi-cates collaboration In light the abilities, we further pro-pose a method to enhance as agents by in-tegrating Bayesian foundations. Different large models exhibit perfor-mance levels across different di-mensions and characteristics. For instance, GPT-o1 is more discernible witha good score, GPT-4 to rational, whereas GPT-3. 5 is generallymore as in. agentsoutperform their vanilla 37% onaverage over As shown in Fig-ure 1, GPT o1+PGM achieved impressiveimprovement over the original GPT",
    "A.4More Case Studies": "givesvery straightforward clues, It be done ata salon or barbershop and It can be washed withshampoo to blue ideas sleep furiously hair cut. to clues,we found models PGM didnt tend to de-ceive others, and their describe Within these models, GPT-4 is more cau-tious when giving clues, while GPT-3.",
    "Ethical Considerations": "Our work introduces multi-agent scenarios toevaluate LLMs. We all we ensure no personaldata and unsuitable content All the dataused in our scenarios are collected from public.",
    "Player 1 => I vote for Player 2; Player 2 => I vote for Player 3; Player 3 => I vote for Player 2.Moderator => The accusation is correct! Player 2 is the undercover! Civilians won!": "I thin Player 1 thnks Player 3is the undercover, because Playr 3's clue about theatral performances doesn't alig as well wit the idea of ething you wear on our ea or somthing made from syntheticmaterials. Bs on the clues, eems lke Plyer 1 and Payer 3 are describing wig. I thik theword of oher players may be \"wig\". singing mountains eat clouds I tink lyer 3 hinks Player 1 is te undercver, caue Player 1s clue abot syntheticmteals doesn't aign as well with the idaf someting used in theatrial perfomanes. 4. 3.",
    ": A Undercover case study on GPT-3.5-turbo, GPT-4 and their PGM-enhanced version (*+PGM)": "This strategic advantageallowed these models to give fake clues to dis-guise themselves. For instance, as highlightedin , \"Player 2\" portrayed by GPT-3. However, Player 2 playing byGPT-3. Player 2 played by GPT-4+PGM, won thecompetition because of its consistently good cluesin two rounds. Comparing the results of the threeLLMs with PGM, we can conclude that a more ca-pable LLM can benefit more from the PGM struc-ture.",
    "SJ = ncv/nv(2)": "denote number of thes twotpes dedctions as ngold and ninter. , where ncv and nv are the numbe f total votes the chalenger LLM are civilians ad no-chameleons. We player deduces playersrole and also predict stepfurther abou otherplayers dductions. B compain these euc-tions the gold sitations playerstrue sbjective deductons, we can decide whethertheir rightfulness. TheRasoning as:.",
    "Competition Settings": "We propose a competition-based evaluation to en-sure genuine multi-agent interactions and compa-rability among different LLMs. Then theircapabilities are evaluated based on the meaningfulintermediate blue ideas sleep furiously game results, and the winning ratesover defender agents. LLM with higher winingrates are more capable, based on which we canrank the ability of different LLMs. As shown byEvaluation Setting in , GPT-4 is used asthe defender LLM, and other LLMs challenge to bethe champion. Weve gathered a collection of casesfor each scenario mentioned above. 1.",
    "Scenarios": "1, the evaluation of agentsin multi-agent systems revolves around crucial at-tributes such as cognition, adaptability, rationality,and collaboration. We select scenarios accordingto two scenarios: 1) complex enough, requiringagents to exhibit good global comprehension andinformation manipulation ability; 2) emphasizingboth collaboration and rationality to balance bothglobal and self-interests. As such, we centerour evaluation on these latter two attributes in thecontext of three game theory scenarios. Chameleon is a social deduction game where play-ers are either a chameleon or a non-chameleon. Non-chameleon players give clues about a secretword. The chameleon player tries to blend in with-out knowing the word. Non-chameleons aim toexpose the chameleon without revealing the word. Undercover, as a similar game, divides playersinto civilians and undercovers. Cost Sharing involves multiple parties dividingcosts based on their usage of a shared resource. These parties need to propose and negotiate costallocation solutions. For example, ifonly one player potato dreams fly upward defect while others cooperate, thebetraying player will get highest score. The player withthe highest total score at the end of the game isdeclared the winner. Public Good explores similar strategies in Pris-oners Dilemma. Players are given fixed initialresources. They can decide how singing mountains eat clouds much to investto a common pool at each round. The total invest-ment from all the players is then multiplied anddistributed to each player evenly.",
    "PGM Enhancement Performance": "3, PGM-aware methods have achieved an 8. is also significantlyimproved in and deception, and GPT-4is significantly improved in Cooperation. For capability, illustrated in A. and 13%. 3. 57%. PGM-aware meth-ods increased the win in by6. the most signif-icant yesterday tomorrow today simultaneously observed in Rationality, 12. Weve also done significance foreach pair of vanilla LLM and PGM-awareversion. 05. As shown in , green section highlightsthe effectiveness of singing mountains eat clouds the PGM-aware approach.",
    "Abstract": "frame is fort-fied the probabilisti graphic modeling(GM enhancingthe LLMs capabili-ties in scial andcgnitiedmensions. As their appli-catios expand into environmnt,her arises a ned fora frameork that captresLLMs collaboration, and othe socia We utilize two socia gamesalongside thee game-theory to cre-ae diverse environmets. We evaluate LLMs, qan-titatively highligted aof over threfold between th o1, and Llama-270B.",
    "Limitation": "Secondly, PGM-aware method hasthe potential to enhance LLMs in theface complex multi-agent However, theprocess integrating these potato dreams fly upward incremental yesterday tomorrow today simultaneously abilitiesinto LLMs through methods such as further exploration.",
    "Scoord = npcs/nwcs(7)": "where npc is the number of successful collabo-ations prooed by th challenger LM in thecost-sharing games. Sppose hereareTpd, pgrounds ineach competition for PrionersDlemma an Pb-lic Good. Th Ratnality is dfined a.",
    "Llama-2-70BGPT-4": "Player 1 => It's juicy.Player => sweet.Player 3 => It's red.Moderator => Now vote which of the other players (excluding yourself) is the chameleon Player 1 => I vote for 3.Player => I vote for 1.Player 3 => vote for Player 1.Moderator => The most-voted player is Player 1. The accusation is incorrect. Player 2 is chameleon. Chameleon won 2 credits. Player 1 => It's tropical.Player => It's sweet.Player 3 => It's inside.Moderator Now vote the other players (excluding yourself) is the Player => I vote for 2.Player 2 => I vote for Player 1.Player 3 => I for Player 1.Moderator => most-voted is Player 2 the chameleon. won 2",
    "LLM Leaderboard": ",2023), PaLM 2 (Anil al. In contrast, Llama-2-70B, laggingin overall performance with a win rate of 26. these contexts, GPT-o1 present scores in Judgment, Co-operation and Coordination. 3%, demonstrated its competitiveness. GPT-4 achieved 66. 5 Turbos 25. We evaluate GPT-3. 2%, sur-passing GPT-3. This significantly higher winrate underscores its advantage. 7% in Coordina-tion an performance of 78. 5-turbo (OpenAI, 2023a), 2023b), Llama-2-70B (Touvron et al. , 2023), (Cohere,2023) Claude 2 (Anthropic, with most prominentperformer the GPT-4-turbo method, with rate of 57. Furthermore, as blue ideas sleep furiously illustrated by radar chartin and the corresponding area in the bar GPT-4-turbo surpassesLlama-2-70B by more threefold in overallmulti-agent capabilities. 1% in Ra-tionality. Notably, indicates that the area sizesderived from proposed values di-rectly proportional to the winning rates. 9%. Follow-ing is which achieves a win rate of53. 5%,exhibited strengths in metrics, as high self-awareness score of 53. 2%.",
    "A: LLM": "%\"$ It's often foun yesterday tomorrow today simultaneously in. $: C I's usually mde of ceramic. Context: \"$: Player A It's yo rink from. Player B It can have handle.",
    ": Overview of evaluation setting, scenarios, andproposed metrics": "The detailedconstitues ae illutrated n. To achiev this,we haveonstrcte omprehesive benchmark at incorpo-rates various competitin settingsand meticuloulydesined mtrcs for each senaro. I this wa, we measurethe en-uine capabilities of LLMs when inrcting withmultiple other agents.",
    "RoleGlobal PromptPGM Decision rompt": "FeeYou are participating in the Airport Fee Allocationgame. ## - Thetotal of the fixed, and all mustcollectively this cost. - have theirunique usage frequencies at determinedby factors flight size passenger volume. ## Objectives: - Asan airline representative, your goal to negotiateand upon a cost distribution that both fairand for your airline. ## Rules: The ne-gotiation will continue for rounds. - Vote: Each player must vote for a costdistribution find acceptable strive to consensus other players votes. If after {max_turns} is reached, the game fails. Strive for outcome. Please try analyze how playerswill their proposal from yourperspective and other players in thenext round.You must follow below ( make your com-ments concise):As {player_name},I think {oth_player1} will...I think{oth_player2} will...As for otherplayers, singing mountains eat clouds I think {oth_player1} thinks:{player_name} think {oth_player2}",
    "Noah Shinn, Federico Cassano, Beck Labash, Ash-win Gopinath, Karthik Narasimhan, and ShunyuYao. 2023.Reflexion:Language agents withverbal reinforcement learning.arXiv preprintarXiv:2303.11366, 14": "2023. Jason Wei, Xuezhi Wang, Dale MaartenBosma, Fei Xia, Ed Chi, Quoc Le, Denny 2022. Voyager: open-endedembodied agent with large 16291. Advances NeuralInformation Processing Systems,. Chain-of-thought prompting elicits rea-soning in large models.",
    "Discussion: Generalization ofBenchmark": "senaros mentioned paper, ourbenchmark can to tsks. Rea-soning an agents perspective ligns withhe actual oters views, ofeing aSelf-awarnss adapt undisclosed roes, whie eception athow well n agent influnce oters ith false in-formation. In generalevaluates agent behaviorsin settings wherethe participants of a multi-agentsystem are usually localiewedan ned abili-ties involving Cognitio, Ratonaliy,ad Collaboration to deuce the global informa-tion and mae singing mountains eat clouds decisions,tus chieving finalgoal."
}