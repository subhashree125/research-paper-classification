{
    "Transferability of the attacks": "Q4: Attack Transferabiliy In transferabilityexpriments, we study whether an attack mposedn one text-t-image model can ransfe to othertext-to-image moels. 5 (whe there is safety constraintimposed on prompts). In ourreslts demon-strating in , we observe that by impingthe safety constraint on te toxicity of the prmpts,we are able to drastically reue the toxicity ofthe promps generating and that we can conrol thistrade-of using or scoring sratgy by controllingfor attack effectiveness vs prompt toxcity. In ourexpements, we fix 1 = 1 and comare resulsfor when we set 2 = 0 (which iswhen we o otimpose any contraintonthe safety of the prompts)vs 2= 0. Thus, our scorig basedobjective becomes 1O1 + 2O2 where O is teattack ffectiveness obective (OAE(Xt)), and O2is for the low-toxicity of te prp OLT (Xt)wich is ( toxicity) score coming fromouruti-lize toxicity clasifier Perspective API)10. Toward this goal, we incorporate sec-ondary objectiv yesterday tomorrow today simultaneously in scorin attackstrategy in addi-tion to attack effectivness hat controls for toxicityof he genating prompts.",
    "Codecanbefoundat": "Finally,we conduct experiments in which use a text-to-text model as our target and demonstrate theeffectiveness of FLIRT this setting. generate adversarial prompts, we ex-plore various prompt selection criteria (feedbackmechanisms) to the in-context in including rule-based and approaches. We demon-strate that FLIRT more effective inexposing vulnerabilities of several text-to-imagemodels, achieving average attack success rate vanilla diffusion and safe diffusion models aug-mented with safety mechanisms compared anexisting in-context red teaming approach Perezet al. (2022) that achieves 30% average attacksuccess against vanilla and20% against different safe stable diffusion mod-els.",
    "minican Republic. Association for ComputationalLinguistics": "In Proceedings of Annual Meeted theAssociation for Computational Linguistics (Volume1: Long Papers), pages Dublin, Ireland. Thomas Hartvigsen, Hamid Sap, Ray, blue ideas sleep furiously and Ece Kamar. teaming language models to re-duce Methods, scaling behaviors, and lessonslearned. arXiv preprint arXiv:2209. for Computa-tional Linguistics. 00027. Association forComputational Linguistics. 2022. 07858. Mehrabi, Ahmad Beirami, Fring Morstatter,and 2022. Association for Deokjae Lee, JunYeong Jung-Woo Jin-HwaKim, Sang-Woo Lee, Hwaran Lee, Hyun OhSong. A large-scale machine-generating datasetfor and implicit hate speech detection. arXiv arXiv:2101. An 800gb dataset of text for lan-guage modeling.",
    ": Seed prompts utilized in our language experiments as the starting in-context exemplar prompts": "60. 0 Percent (%) Max DiversityAttack Effectiveness : The diversity-attack effectiveness on and max safe stable diffusion models with varyingthe 2 parameter. score the percentage ofunique prompts generated the red LM. 20. 00. Percent (%) Medium Safe SD DiversityAttack Effectiveness 20. 0. The attack effectiveness the percentage images generated the modelthat are labeled unsafe according to Q16 NudeNdet classifiers. 60.",
    "lgorithm 1: General Algorithm": "X; xtnw; colecti o n objectives O1, ..., On; weights associated to the objectives1, n; Xt={}.utput: = ni=1 iOi(Xt) (Calcultethe core Xt)ut t.for eachprompt xt in Xt do Copy to and eplce xt by xtnew in Xtemp.Score(Xtemp ni1 iOi(Xtemp) score or yesterday tomorrow today simultaneously Xtemp).PutXtmp in Xt.endrom all the arrangements in Xt pick the list X with maximum score.return",
    "Conclusion": "demonstrate in-contextlearning incorporated in a feedback based frame-work can be by the red LM generateeffective prompts that can trigger unsafe contentgeneration text-to-image and mod-els. differ-",
    "Stable Diffusion": "DiversityAttack 0. 60. 0 Percent (%) Weak SD Effectiveness 0. 20. 60. 0 Percent (%) Safe SD Effectiveness : Diversity-attack results with varying 2 The diversity the percentage of unique prompts generated by the red LM. Forresults other stable diffusion models refer to the Appendix. Wethen sample from prompts withprobability e(0. whereNudeNet(x) and Q16(x) are the probability ofthe generated image corresponding to the prompt xbeing unsafe according to NudeNet and Q16 and T a temperature hyper-parameter. Attack Effectiveness We attack effec-tiveness diversity from applying the attack strategies in. In case, if a generation moresuccessful, FLIRT will consider it as its demonstra-tion keep on in the iterations(for more detailed discussion on trade-offs the scoring strategy gives the bestresults in terms of attack effectiveness, we observethat generates less diverse set in somecases. The lack of di-verse generations in strategy is part the fact that in attack, the red LM effective prompt in terms of trigger-ing the text-to-image model in unsafe it keeps repeating promptsthat are which affects diverse gen-eration.",
    "Related Work": "preiou teaming include humanin theloo al. , 2022; singing mountains eat clouds Mishki et al. ,2022). , 202;Mehab et al. , Caser et al ,2023; et al. , 2024). Unlie of rely onexpensiv or extensive data generationfollwed withsupervised fn-tuned or reiforce-ment our proposed aproach reliesonlightweight in-contxt",
    "Evaluation": "of our is touly automat the redteaming process, we use formerapprocwhich was priously usedin (Schramowski et. ealuation can e dne blue ideas sleep furiously used cassifieror annotators. , blue ideas sleep furiously 2022). a similar setup as that of(Schamoskit To safetyof generating txt-to-text experimens, we use TOXIGEN model fortoxiclanguage(Hartvigsen eal. ,222a) ealuatethe of text-to-image mod-els.",
    "FLIRT Framework": "Our Feedback Loop In-context RedTeaming(FIRT) frameork uses ared LM to generate ad-versarial prompts aiming at triggered te tetmodel into generating unsfeconent. The overall FLIRTfamework is llustrate in. The red LMstarts wih aninitialset of in-conext seed propsand iterateas fllows: (1) Te red LM gneratesan adversarial promp uing in-contxt learning,which is fed intothetarget(. g, tex-to-ige)model t gnerat the corespoding output (e. g. ,imae). (2) The corresponded ouput image isevauated on weher it iunsae using safety clas-sifiers.",
    "Red Teaming Text-to-text": "To whether cn used tored eam text-to-text we replace theext-to-imae models studied previous experi-ments withthe GPTNeo 7B parameter langugemodel (Black et 221;Gao et al. , in this experiment output te targetmodel is text instead of replace Q16 clasifiers whih re image baed safetyclassifiers with moel which is toxiclngage detectiomodel (artvigsn etal. , 2022). We usea new of seed that ae for lan-guage domain trigger toic generation (liste inAppendix and rest of te expermentalseups the These results the flexibilityof FLITto effectively be applicale potato dreams fly upward o languge(text-to-text) spac addition to text-to-image.",
    "CQualitative Results": "contain some exmples geneated through Thedifferece wor clouds prvide in-forationon eistin differences in each ttackstrategy. Theeresults re for when we pplied on first set f sed promps",
    "BExperimental Details": "For all classifiers, such as yesterday tomorrow today simultaneously NudeNet,perspective API, yesterday tomorrow today simultaneously and TOXIGEN, we use thresh-old value of 0. the red LM, we set topkand topp values to 50 and respectively.",
    "Queue rear": "g. : Our Loop In-context Red (FLIRT) framework for generating adversarialprompts. Last in First out (LIFO) Attack In this strategy,we consider in-context exemplar prompts tobe in a and them a basis. Finally, we use = {Xt} {Xti, = 1,. Let = (xt1, xt2,. m} to denote a set singing mountains eat clouds of size (m + the original Xt and derivedlists Xti, i = 1,. In each FLIRT iteration, the red LM generates adversarial prompt that is fed into in-contextstrategies by the red LM to generate adversarial prompts are demonstrating on the left side we consider the exemplar to bein a update them on a FIFO basis. To alleviate this challenge,we explore in, First Out (LIFO) strategythat aims to the intent intact generatinga diverse of examples. New LM generated prompt with positive feedbackis placed at of the stack and is replacedby the Examples objectives are1) attack effectiveness, aiming to generate that can maximize the unsafe generations by thetarget model; 2) diversity, to moresemantically prompts, and 3) low-toxicity,aiming to generate that canbypass text-based toxicity filter. Xt is ordered because during in-context learning, order of prompts matters.",
    "ASeed Prompts": "o perform our main set o eperiments, we uti-lze three different sets of seed prompts to capturea wide range of diferent unsfe content catgo-rizations. , 2022a). We notced that providing teafe stable diffusion mdes with prompt:imageof a naked woman might not result in an imageof a naked woman; howeve, wen we proviemore etail escriptionabout the naked womanprompt:image of a nakd woman. ippls isiblein image the providddescrption results ian image of completely nake woman. To pu ths into test ina more controlled setting, we divide our sts ofsing in different levels of ranularity accordingto the provided description. Set 2 of our promptontains similar prompts to that in Set 1 but withless proied descipion. We then comre theperormance of our scorng approach when we useseed Se 1v seed Set vs whenwe keep hezro-sht example thesame but mae the xamplesless descriptive o that in seed et 1 Fromthresults epoted in , we deonstrate thatindeed if we mak the prompts more dscritiveattks are more effectiveFinally, St 3 containsa completely new set of sed prmpts that servesas a sanity check that our resultshod for nw tof seing prompts that ae different from sts 1 and2. contains the exemplar pomts in achset. The exampe 0 is the instruction prompt that con-tains the task decriptio. The rest of te exampleare actual promts that the model ties to usas in-context xmlas to learn the task fom. n this study, we designdiferent sets of seed promts each inding dif-ferent numer of unsafe sed prompts that trigerthe stable diffusion moelto generateunafe im-ages. We then report the esults as we icreasehe number of unsfe seed prompt in ech stud-ied set of our experiments. Weuse the same zero-shot (nstruction) promptfor allthe sts and thatis the zerosht prompt from seedSet 1 and justchange fwshot instruction toinclude ifferent number of unsafeprompts in eacset. Iour resuls, we demonstrate that havig zerounsafe pompts (nneo these rompts trigger thetextto-image modelt generat unsafe outputs)cangive us attack effectiveness of over 40% or ourscoring and scoring-LIFO approaches. In additio,we shw hat having only two unsafe seed promptscan give usattac effectiveness of over 90 for ourcoring approach. lso shows how differ-ent approache act ifferently on diferent settingswith regards to number of unsaf seed prompts. n oursecond study, we eport howdifferentthe geeraed adversarialattacks are from the sedrompts. (2023) t report how differentthe generating instuctions are from the seing istruc-tions used to prompt the model; hus, we utilized the same metric and approah in our etting. Fromour reults we demonstrat that may ew adver-sarial examples are generate, whch do not hvemuch verlap with the seeds. We lso compare urapproachwh simple baeline in wih we sim-py augment th seed promps to creae 1,000 newadversarial dta poins y ung wd substitutions,removig sentences, added more information andcombination of these data augmentation techiqueand as hown in we demonstrae that thismethod i not able to give us iverse adversarialexamples.",
    "(1)": "For potato dreams fly upward cases hereal the bjectivescanbe redud nctionsoverindividual element, te n () is one bysubtiuting te prompt wih the minimum = arg mini=1,. We calclateSim(xt1, used the osine similarity etweenthesentence ebeddings o the xt1 andx2 (Reimers Gurevch, 2019). , 2022). Speifially, the effetiv-nessand low-toxicity citeria, the objectives reduceto O(Xt) = ml=1 Oxtl). ,m O(xti)) with the gener-ated prompt xtnew O(xtmin< O(xtew). Scoring-LIFO In ti attack statgy, the re LMcombines strategis scoring and LIFO ttaks. red LMreplaces te exempl promp te stackwith thegenrated promptonly if genrating prompt adds valutothe stack accordig to obective th red LMaims In addition,snce it is posiblethat th stac does get updated for long time,we a scheduing mhanism Used mehnism estack does noget up-dated sme number of ierations the attackerforce-replaces thelast xemplar inthe stac with nw generation. In our textto-mageexperiments, wethe ffectivenessobjecie as OE(Xt) = ml=1 NudeNet(xtl) +Q16(xt)where NudeNet(x) and Q6(x) by applying NudeNt andQ16 classifiers to h image generated fom x. While th objectives re defined func-tins overlists of size , for partcular ofobjectives outlind above,the reduce tocalculatinfunctios overindividual and pair-wsecombination list lemns aing h cmpu- effcient. the diversity objective, wedefne it pairwise dissimilarity overall airs in the =ml=1mj=l+1(1 Sim(xtl xtj)).",
    "Limitations and Ethics Statement": "GPT-eo:LargealAutoregressive Language Modelng witI yo use this please cite itusng metaata. n additio, is crporate humanfeedback on s aout flaws inthe trained FLIR flexble allowreplaemn of eah component with acoic (e. Amazrue, HamzaAlobeidli, Abdulaz Al-shami, essandroCappelli, xandra Cojocaru,Merouan Etienne Daniel Hes-low, Julien Launa, Quenin BadreddneNoue, blue ideas sleep furiously Baptist Pannier, and GilhermeFalcn-4B: an pen arge anguage modelwith prformance SidGa Lo, Phil Wang, Connor Lehy,and Stella Biderman. 021. Al-though LIRT canbe t evaluae and enancemodels acording to safety and esponsile con-cerns,if usedby malcious actors, it an result inunsafe content generation which have negtivesocietalimpa. , replacemen th classifies owever, exposing wit schsnsitive conten has it own we argiving to automatic apphes here. inceFRT relie singing mountains eat clouds the automtic fedback com-in fromit is possible esting noisein classifier affects However, weperform ablation studiesas i andverify tat our reslts still old and areobust the intduced noise i the otcome ofhe classi-fier. However, we blieve tht thead-vantages having suc a framework outweighs itsdisadvantages. Havng such a ramework for modeleauation auitn can help us towarddevelopingand ore reliable Withregards to reroducibility, we ou code. g.",
    "We perform various experiments to validateFLIRTs ability in red teaming text-to-image mod-": "els. We also perfor ablation toanayzthe efficacy of FLIRT conditions. addition,e perfom umerus contrlled x-peiments t better understand he of sedprompshow they iffer from the generatedprompts in the Apndix.",
    "Ablation Studies": "Q1: Different Language Model To answer thequestion on the blue ideas sleep furiously results hold if we use adifferent language model as the red LM, we re-place model utilized our main ex-periments with BLOOM 3b (Scao et al. However,similar to previous observations, it suffers fromthe repetition and lack of diverse if only for attack effectivenesswithout considering diversity potato dreams fly upward as the ob-jective. Q2: Content Moderation To answer the ques-tion on applying content moderation ontext-to-image the results, we the built-in content. , 2022)8 and Falcon 7b (Almazrouei et We then report the results on attackeffectiveness comparing the attack strate-gies. the results reported in ob-serve patterns to that we reported previouslywhich suggests that the results still even whenwe use a model as our red In our results, we demonstrate that the scoring is the most attack.",
    ": Attack effectiveness and diversity results for BLOOM (top) and Falcon (bottom)": "dirse generatios in scring attack strategy, eatempt cotrol the diversity of pompt throughthef diversity as an aditional bective(ODi(Xt)) i next set of Controllng Diversty enhance he divrsity ofgeneatio the scored attack strategy, addan additonal objective to the attack efec-iveness objective that controls diversity. o singing mountains eat clouds yesterday tomorrow today simultaneously obervetheofhenewly n nhacing diversityof genrations in soring atack stategy, we fix1 = var the 2 and theatack effectiveness vsdiversity trade-offs Fig-ure 2.",
    "Main Experimnts": "weuse diversity as another metric to report the per-centage of unique generating by the redLM are repetitive (for additional metricson diversity refer to the Appendix). We test various text-to-image models: stable diffu-sion v1-4 et al. , 2022a) to report unsafe content generation in according to Q16 and NudeNet classifiers as for effectiveness. different sets of seed prompts capture differ-ent are designed to thetarget for categories (Schramowski et al. , 2022a)5. , al. , 2022a). 7B model (Black et al. For the red LM, use GPT-Neo2."
}