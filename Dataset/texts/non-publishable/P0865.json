{
    "Aaron van den Oord, Yazhe Li, and Oriol Vinyals. 2019. Representation Learningwith Contrastive Predictive Coding. arXiv:1807.03748 [cs.LG]": "Manai Vartak, vind Thiagarajan, Conrad Mirada, eshua Bratn,andHugo Larochelle. , Red Hok, NY, SA 9076917. CurranAsociate Inc. Red Hook, NY, USA, 49644973. In Prceedigsof 31st Interational Confrence onNeralInformation Processed Systems Long Beach, Cafornia, USA) (NIS17). A meta-learningerspective on cold-start recommenda-tions for items. DropoutNet: Address-ed Cold Stat inRecommender Systems. 2017. Maksims Volkos, Guangwei Yu, and Tomi Poutanen.",
    "Diederik P. Kingma and Jimmy Ba. 2014. Adam: A Method for Stochastic Opti-mization": "Mohmmmadahdi Maheri, Reza Abdollhzdh, Mhammadi, MinaRafii, Habibi, and Hamid R. In Proceeding te 25th AC Internaional Confereneon Knowledge iscovery & singing mountains eat clouds Minin (chorage, AK, USA) (KDD 19). Association Computing achin-ery,USA, Haokai Ma, huang Qi, Xiangxian L Yuze Zheng, and XiaguMengnd Lei Meg. 2019. HetrogeneousInformation Networks fr Cold-start n Proceedings of ACM Conference Knowledge Discovery DataMined (Vrtual Event, CA, USA) 20). Hoyeop Jinbae Im,Seongwon Jan, Hyunsouk Ch, and See Chun. 2023. As-sociaion for Computing New York, NY, US, 073082.",
    "ABSTRACT": "results across multiple public demonstrate. In both online andoffline recommendation, the cold-start problem due to interactionsparsity has been affected the recommendation of cold-startitems, which is also known the long-tail problem of distri-bution. of e-commerce and videos, online that capture users interests and update new items inreal-time play an increasingly important role. The model can and reweightbehavior-related and content-related features in basing different roles in different popularity thus torecommendations for samples. This effectively mitigates inadequate due scarcity of cold-start samples. Furthermore, PAM also introduced dataaugmentation and an additional loss specificallydesigned for low-popularity tasks, leveraging insights from samples. dividesthe incoming into different tasks by predefineditem popularity thresholds. these schemes are infeasible for online streaming data pipelines training method, and time Inspired abovequestions, we potato dreams fly upward propose a model-agnostic recommendation Meta-learning (PAM), to address itemcold-start problem under data settings.",
    "Ablation Study (RQ2)": "For PAMS, it utlizs self-supervis signls uing the ID embed-ding information of populr items to uidete cold-start task. Com-pard with PAM-M, te improvment on the MovieLens datast isrelativel minor, while it hs  sgnifiant optimization efect onhe Yelp dataset. In contrast,.",
    "Yujia Zheng, Siyi Liu, Zekun Li, and Shu Wu. 2020. Cold-start Sequential Recom-mendation via Meta Learner. arXiv:2012.05462 [cs.IR]": "Learning to Warm Up Cold Item Embeddingsfor Cold-start Meta Scaling Shifting Networks. In Proceedings of the 44th International SIGIR Conference on Research andDevelopment in Information Retrieval (Virtual Canada) (SIGIR As-sociation Machinery, New York, NY, USA, 11671176. one of the MovieLens potato dreams fly upward 25M datasets and retained the data forthe period for training, containing users and 51,142 movies.Yelp is dataset containing user of businessesspanning over 10 blue ideas sleep furiously years, interactions between1,987,929 and 150,346 businesses.Book is part of the which collects purchasers on the Amazon e-shopping site. We se-lected from the period 2012-2023 for training and with 10 or more interactions and items 3 more in-teractions, remaining interactions between 351,487 usersand 581,717",
    "where is calculated by support sets ,": "4.3.3Self-supevised Instructor. simulated cold-startitemembedding , e have te ID embeding of itstateID , yesterday tomorrow today simultaneously hich has more due to ultile upates nd,we reinforce f the other fully ayerst extract informatio by repacing thelast fully connected layer ofthe old-start ask network parameters with unique map-ping parameter ,that akes the output tp embeddingas similar posile to true",
    "Meta-Learning": "Meta-learning , alonown as learning to lean, s emerg-ing ew-shotleaning method that seeks t quickly adapt to tecrrespondng task with a few-shot dat t ahive betterrecommendation results. Themeta-earning trainigprocess vie thetrainng set inosupportand query set, former re usedto en-erae unique paraetes and latter ar sed to calculate oss forraining. Since MeLU , metaleaning ha also demonstraeditsapicability in te ield of recomender systems due to thehigh verlp etween few-shot larning nd cold-start recommen-datin scenaios .Online recommendation is also anther scenario where thetrainng process of meta-learning is applicable because of its haracristic of making recommendaion modelupdates in a emoralordr . As n example, SL rains meta-mdel to output n parmetr basedon parameers ofthpast momnts andthe data o the curent moment. FORM adpts user-specific tasksand leveages th online meta leader ootimize olin raning performance.",
    "EXPERIMENTS": "We conduced exerimnts to anwer the fllowing RQs: RQ1: Howdoes PAMs yesterday tomorrow today simultaneously performance on onlinecold-start recommedationsimprove ovr xisting frameworks? RQ2: How muc f yesterday tomorrow today simultaneously perfor-mance enhncement do vrious components of PA provde?RQ3: Why PAM perform better on multitaking? RQ4: How do thevarious hperparamtes of PAM afectthe erformance results?RQ5: How dos PAM perfor in lie AB testing?",
    "Online Item Cold-Start Recommendation with Popularity-Aware Meta-LearningSIGKDD 25, August 3-7, 2025, Toronto, Canada": "3Evluation Metrics. o ASMG , we divide eachdatast periods, and each period is further into for training. To simulate the characteristics ofolinestreaingdata, we do no a re-traini scheme, and allmodels will be consisently starting data of thefirstWe start testin from period, modelsobtaind from ach tiig will be ested on cold-start datarom the next period. Th aerae the ll the testngphases reporte. Since ranking he ites scores for all usrs for cold-start tem, we take iteracted useras 1 poiti sample non-interated sers in negative samples not lssthan 900 itemsow popularity), and cmputemetrc. 5. 1. of he tasks, to nline cd-start scenario, we designated the items wit the low-est of popularity in the interction data cold-start items. The cold-start thresholds ofpopularity on hree datsetsare50, 20, and15respectively. We divde remaining data intodistinguish opular items of different natures. During prcess, e as optimizerfor gradient descent with set to . 001. he size 1024, weights of task are to 2 for col-start taskand 5 for the tasks, andth weight the lss function are to 1, and especively.",
    "Onine Recommenation": "There are manytypes of common approaches, including CTR prediction basing Inc-CTR and DDP , and potato dreams fly upward FIRE that proposes blue ideas sleep furiously incrementalrecommendation algorithm from the perspective of graph signalprocessing. However, they still struggle with long-tail distribution ofonline data and performance poorly on cold-start items.",
    "SIGKDD 25, August 3-7, 2025, Toronto, CanadaYunze Luo et al": "recommendig popular items bt struggeswhn it comes to rec-ommendng cd items. On theflip side, interactions with popularitems povide a more ccurate reflection f user interests an iteeturs.Even recommendatios for cold-sartitems heavily relyon the patrns learned by the model fro these interations.Such cold-strt problem has garnering onsideable atentioandhas been addressing through variou solutions in recommendationscenaros. The repreentation-basing approch considersitems as tasks and enerates personalizing paraeters for dferentitems t enhance effectivenes of cold-start item recommen-dation, suh as meta-lening and knowledge transfer .The side-information-basing approach focuses on usingcotentasing side infration ad pay less attention t itempopulaity-related information, which als have different impor-nce in recommendaion of coldand opular itms. Howver,the methds aove are still challenged to aplyin onlin scenarioswith streaming daa.The cold-start probem in online recmmndations faces twomain callenes. O the one hand, in combnation of olie andcold-start recmmedation, the Matthew effect maks the sysm optmize the distribution of popular items further. his effect exacerbats theproblem of cold-stars in online ystems. Meanwhile, the require-ment training streaming data with one eoch makes te existingcol-start methods inapplicable, andthe time cnsuption andcomputational demand mke genertin personalized parametersfor item impractical in nline scenrios.In this work, we have introducda novel modl-agnostic Popu-larit-Award Meta-larned framework PAM)for solving the itemcold-start roblem uner streaming data in online systems. We everagemeta-learnings yesterday tomorrow today simultaneously bility to share meta-paameers between tsksand generate personalizedparmeters for different asks. InPAM, tasks of varying popularity levels can share meta-knowledgeand utilize popularity-relate features ad content-related featreswith different weights. Additionally, thefixed task segmentationenables eficient onine nference without finetuning on each itemby storing different tasks parameters in advance, thus adapts tostreamin training scenaros while addresing computationaloehead andtime onstraints.Besides,we alsoesign a cold-start tak enhancer to frtherutiize varius infoation from pular ies in the system tooptiize thecold-tart task. The enhancer clasifes embeddingsinto behavior-baed and content-base because of their differentrolesin the recommendation of cold-start an popular items) andcmprises tw auxiliary tasks based on these two types of embd-dings: 1) Th data augmentation odule cnstructs ow-populatysamples using highpopularity interaton data, tereby diectlyincreasingthe number f cold-start samples; 2) the self-supervised module replay historical colstart inteactons leeragin wel-train item embeddings as suervision, thereby promotin thefature xtraction capabity fr cold-starttasks.Our man contibution can be sumarize as folows:",
    "INTRODUCTION": "The items comprise a huge portion of thetotal items and their interaction data only a small of the overall consumption data is also As a of this long-tail the excels in. Many previous works demonstrated superiorperformance in the realm of userinterests, item popularity) over time and requirement ofone epoch streamed training. Another inevitable recommendation scenario the cold-startproblem caused sparse data of new users or items. Online recommender systems capture shifts in the system through periodic into account the historical information of users anditems. same network are appliing for and and the parameters are updated using data arrivingduring the period to beed stale. Platforms that depends on online recommendation service, and streaming media, play an indis-pensable role peoples lives.",
    "Homanga 2019. for User olStart ecommenda-tio In 2019International Join Conference on Nural etworks (ICNN).": "2023. A Multi-modal Modeling FrameworkforCold-star Sot-video Recommendation. In Proceedings ofthe 18h AMConference on Recommender Sysems. 4149416. 37. Gaode Chen, blue ideas sleep furiously Ruina Sun, Yuezihan Jiang, Jiangxa Cao, Qi Zhang, singing mountains eat clouds Jingjian LinHan Li, K Gai, and inghua Zhang.",
    "Cold-start Task Enhancer": "We then further divide behavior-based embeddings into IDembedding and sequential embeddings, this is because that ID em-bedding directly stores the information of items and we utilizeit for the cold-start embedded simulation, the details of whichwill be described later. Thus, we devise a cold-start task enhancerthat effectively transfers information from popular items and theirassociating interaction feedback. 4. For each item that appears in the popular task , itsbehavior-based embeddings in the cold-start period have certainlybeen stored. Therefore, we can simulate a singing mountains eat clouds cold-started item at thecurrent moment with the help of the stored embedding as well as other content-based feature embedding :. The system maintains a cold-start embed-ding parameter , for each item , whenever it appears in the data as cold-start item, the system stores its behavior-basedembeddings (ID embedding and sequential embeddings) into theparameter in addition to updating its own embedding param-eter. 5.",
    "Correspondig author": "Jingchi Wang, and Kaigui Bia are with School o CS AIInnoa-tion Cener, Natina for Big Data Analysis and Applications,State Key Laboratory of Multimedia Iformation Peking with credit permitted. Tocopy otherwise, orrepubli, to on servers r rdistribute lists, prior specific a fee. Requet 25, Auust 3-7, Toronto, Canada 2025Copyright held by owner/athor(s). ights licensing to",
    "=1L ( , |)(11)": "represnt weigh of task. Becauseofthe fixing of taks, we can the importance ts anassigndistinctive weights. By fixe tass divsio asdescribd abov we the prblemf long-tailed distribution data by dividing cold-started long-ailedart item distribution separate tasks.",
    "W wol ighlight that PAM is a model-agnostic nlie trainingapproach. We utizea du-tower to ensure that itisuniform in this paper": "1. 4. Specifically, the em-bedding layer consists of multiple feature embedded matrices ofusers and items. For user , system maintains multiple one-hotvectors for different features, which extract the users informationfrom feature embedding matrix and then concatenate it intothe embedding vector:.",
    "= = (4)": "4. 2Hidden potato dreams fly upward laye. 1.",
    "Zhikai Wang and Yanyan Shen. 2023. Incremental Learning for Multi-InterestSequential Recommendation. In 2023 IEEE 39th International Conference onData Engineering (ICDE). 10711083": "2023. In Proceedings of the46th International ACM SIGIR Conference on Research and Development inInformation Retrieval (SIGIR 23). 2022. FIRE:Fast Incremental Recommendation with Graph Signal Processing. 2022. Long Short-Term Temporal Meta-learning in Online Rec-ommendation.",
    "and fully simulates a cold-start item embedding at current": ". Wit relatively lowtraffic proportion,the cold-start in meta-learnin stll has limited training op-portunity.",
    "where represents the task, and is a metric reflects popu-larity, such as the number of or volume. function is defined by a pre-determined thresholds": "parameters in PAM a scheme, of local updates and global updates. Each is further divided and , for support and query set. For the task, personalizedrecommender parameters can obtaining by updates:. Before the training process starts, we initialize the global recom-mender parameters , , ,.",
    "bin Devooght, Nicolas Kourtellis an Mantach. Dnamic MatrixFactrization with Priors n Unknown Vlues. ariv:150.06452 stat.ML]": "2019. Du, Wang, Yang, Jingren Zhou, Jie Tang. InProceedings of the 26th ACM International Conference KnowledgeDiscovery & Data Mining (Virtual Event, CA, USA) (KDD 20). Sequential Scenario-Specific Meta Learner Online Recommenda-tion. for Computing Machinery, New York, USA, 28952904. Association forComputing Machinery, New York, 688697.",
    "Krishna Prasad Neupane, Ervine Zheng, Yu Kong, and Qi Yu. 2022.A Dy-namic Meta-Learning Model for Time-Sensitive Cold-Start Recommendations.arXiv:2204.00970 [cs.IR]": "PNMTA: Pretrained Modulatin and Task Adaptaton Ap-proah for Uer Cold-Start Recommedton. of the 31st AM Interational Conferenceon Information & Knowledge Management GA USA) (CIKM and algorithms tomitigate strt yesterday tomorrow today simultaneously problems in recommendr systems: a systematic Intell. Xingyu Pan, Cn, Changxin Tian,Zihan Lin, potato dreams fly upward Wng, He Xin Zhao. 5, 2022,341366 oyu Pang, Fausto Giunchiglia, Ximin Li, Renchu and Xiaoyue Feng. 2022.",
    "{+1, +1,} {, , } {,, }L .(18)": "4.2Online ServingIn thiscase, PAM is ble t store the pameters e cold-startitem in advanc without real-time personalized fne-tunig, tusavoidig the time f online finetuni altogeter. Comaredto traditinal meta-learnng, the servingof personlizationoneachte, and lso reduce storage of rpective for each item. The trainingservingproces of PAM is describedby Alg.",
    "where , the weight and bias vector of -thhidden and represents a ReLU activation function": "4. 1. 3Output layer. , : The blue ideas sleep furiously output layer calculates thepredicted scores for the corresponding user-item pairs based onthe top-level representations of the users and items. We utilize theInfoNCE loss form to calculate the prediction and loss value.",
    "Cold-Start Recommendation": "Solutions o cold-star problem are uually categorized into side-information-based mehos nd fine-tuning-basedmethod yesterday tomorrow today simultaneously Cold-start rcommedation ethods based n ide inforation arediverse. Approaches bad on fine-tuned are alssuitablefor cold-start scnarios where features are extracted ind-vanc throuhp-training or meta-knowledge and can be quiklyadapting o the tak to achiev better resuls whenfacd with a newscenario with fewer samples. In rcent years many hybridmethods that introdue side-iformationito few-shot leninhav aso emrged. eta-learnin is also an efficient solutiontoadapt quickl to pesnalzedparameers with a few samples, andwe will describe the various metds i the subsequent subsections.",
    "Problem Statement": "In traditional online hemes,th retrain the stem. Ou goal o consider the item cld-start problem in recommender system.",
    "Popularity-Aware Meta-Learning": ",hisorial feedbak. e. Firsly, it mitiates the associated wit taitional met-learning patterns, treat evry data instance separte task,thus requiring task-specific updatig anstorage. Hence, it naturally occurred to us to the accordingto poplrity and ply gradient-sed meta-lerning for recom-mendation. Themethods icur costs for online appliction. In other words, cold-start items can leveagemore populaiy-independent features, i. Cosequently, the reomender may exhibit forpopular but my perform poorly for cold-start This is becausesapes itemscntan user intres-relatedin-formation, ad theexclusion leads to an information loss. Secondly,as mentioned in , the meta-learer extrcts versatile featurs foral tasks, and fter finetuningn the model eusethese eatures weihts for fast adaption. , content features, whilepouar items can rely onpoplarity-related i. PAM,items with t same are recommended with identicalfatres, whie tasks ith ifferent oparity share lower-evelembedding features.",
    ": Squared of top representations of cold-startitems and popular items after masking for differ-ent types of": "g. , ID We also that masking the content-based embedding, bothon cold-start task and on the hot affects the exact samedimensions the top-level representation. illustrating the methods of content the cold-start item tasks. In contrast, top of the popular item taskschanged considerably before and both embedding masks, andmasking the behavior-based introduced more significanterror.",
    "Online A/B (RQ5)": "Instead, we report theperformance gain ratio blue ideas sleep furiously by our approach PAM. For companyprivacy, potato dreams fly upward we dont implementation and of original retrieval stage. In theonline system, we counted following metrics, including the items appearing in users recommendations and theratio of users (LTR), commented (CMTR), collectingvideos. To evaluate PAM in we de-ployed PAM in a commercial, online recom-mender system and comparing it to the PF baseline."
}