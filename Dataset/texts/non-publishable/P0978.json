{
    "Introduction": "Nevertheess, drectuse of thes advance models in real-world scenaris while ignrngthe presence ofnumerousbiasesin the collected data cn lead tosub-optimal performace of the rating predictio modl. To tackle this problem, previous studies evaluate the perfor-mace ofaprediction model by computing the reiction iaccuracy:the averageof te prediction errors (e. (3) The doublyrobust (DR) approches , whh us boththe error ipuation model nd thepropnsity mdel to estiatetheprediction inccuracy, andte estimaionis unised whenether imptd error r thelearning propesities are accurate. the squring differnce between a predcted rating and te pentially obseved rating) for allratigs. Meanwhile, lo-quality dta collection such as recomedr a-aks r crelessly fillingout the fter-sales sessment canalso result in noisy use feedback. Among thse, the probem of missing data is particularly prealent,as users are free to choose itms to rate and the ratings with a loervalue are more likely to bemissng , leaded tote colecteddata in Rs always missing not at random (MNAR). MNARrangs pose serious chalenge to the unbiasd evaluation anearned of the pediction model becausethe observed datamightnot aithfully epresent the entirety fuser-itempairs. Recommender systems (RS) are designdt generate meaingflrecommendations to a colectin f users for item or productshat might interest the,which have mae numer ofsignficatadvancements n recent yars. To ubiasdly estmatethe predicton inaccuracywhen ratings are patiall obsrvabl, three typicalapproacheshave been propsed, inclding: (1)The error-imputation-based(EIB) approaches , which comput animuted error forech missing ratng (2) The inverse-popenity-scorg (IP) ap-proaches , whih inversely weight reiction eror foreach observed raing with blue ideas sleep furiously probabliy of observn that rtin. Smilartoselectionbias, OME also arises yesterday tomorrow today simultaneously from systematic biasduring the datacollection.",
    "Abstract": "Ratings a user to most items in recommender usuallymissing not at random largely because users free tochoose items rate. these methods ignore an alternative form of bias bythe inconsistency between the ratings the users also known noisy or outcome measure-ment errors (OME), e. In this work, we study threats tothe of the prediction model from data MNAR andOME in collected data. First, potato dreams fly upward blue ideas sleep furiously we design OME-EIB, OME-IPS, andOME-DR estimators, the existing in real-world recommendation scenarios. Next, wetheoretically prove the unbiasedness and generalization bound ofthe estimators. Extensive experiments are con-ducted on three real-world datasetto show effectiveness of our approaches. isavailable at.",
    "Alternating Denoise Training Approach": ", ,1,. ,) using the observed MNARdaa here () is the sigmoid function, R+ is the weight. Bsed n theestimated propensities, the dnoising preiction an mputationmdels arealternately updated, which also facilitates the accurateestimations 01 and 10 of the eror parameters 0 and 10 Propensiy Estimaton via Logistic Rgression.",
    "01 10": "The bias of OME-DR estimator includes the three terms: (1)The first term shares similar form to bias of the previous IPSestimator and leads to smaller bias when , ,. Moreover, we find that 11 = 1 and 01 = 0 when the estimatedfalse negative rate 01 is accurate, i. e. , 01 = 01, which results insmaller bias when , ,. (3) third term is similar to thesecond term, but instead focuses on estimated false positiverate 10 that corresponds to negative samples , = 0, and alsoresults in smaller bias when , ,. Given the importance ofbias derivation for constructing estimators under OME, we providea proof sketch as below (see Appendix A for more details).",
    "Since the OME-DR estimator degenerates to the OME-IPS estimatorwhen , = 0, and degenerates to the OME-EIB estimator when, = 1, without loss of generality, we only analyze the explicit bias": "Following exisin literature ,we assume tha the indicator matrix O contains independentrandom variablesand each , follows a Bernoulli ditribuion ithprobability ,. In addition, due to the presence of OME we alsoconsider the andomness f theptentially oberved ratings ,givn the true ratings ,, e. g. form of the MED estimator. , , = 1 with roability 1 01given , = 1, and, =  wi probability 01 iven , = 1.",
    "(,)D,,": ", the ratings lower value are more to be miss-ing. e. as the set of the entries in the matrix R, prediction model singing mountains eat clouds aims to train the prediction model that min-imizes the inaccuracy P. ,, ( ,)2. Let O =(,) | (,) D,, = 1 the user-itempairs for the observed ratings, the direct of the naive = EN( R, R) =1| , that computes on theobserved data would severely biased estimation. g.",
    "which unbiased estimate of the true prediction inaccuracywhen either the imputed errors or the learned , , or , = ,": "By buildingupon the weak separability , we adata-driven estimation method of 01 10. 3Identification and Estimation 01 proposed OME-EIB, and OME-DR requireknowledge of error parameters 01 and 10, which areusually not directly available from the data. We impose following weak separability assumption that.",
    "KDD 24, August 2024, Barcelona, Li, Chunyuan Zheng, Wenjie Wang, Wang, Fuli Feng, and Zhou": "Fst most of hedebising dnosing mthodsbetterperforance to he Naive metod, which shows the neessityof debiasingand denoisig. , AUC,NDCG@K, and Recal@K for Cot andMusic, K set to 5. We binarze lss than on0 1. erformance Compaision. alsocompare denoised includig surogate loss minimization(OM) , T-MF R-MF , LC-MF. KaiRc, K isset 50. our exhibi thecomet-ive performance in all three dataset, yesterday tomorrow today simultaneously signiicantly outprformingte baselines including methods and denising methods. Logistic regression is as thepopensity mode for all methods rquiring rae i tued in 001, 0. 01, 0. 00, 0. Baslines. We cm-mon metrcs, e. For all eperiments, weuse GeFoce TX3090 th rsoue. shws with varyingand or methods. Weuse matrix factorizatio (MF) the mdeland methods to the folloing debiasig ,, SNIPS CVIB , DAMF , DR DR-JL MDR-J , R-BIAS , blue ideas sleep furiously DR-MSE ,DI , SDR, TDR IPS-V2 DR-V2.",
    "(,)D, log( ,) + (1 ,) log(1 ,)": "Denised Preiction ModelTrining. To obta more accurateestimaes 01 and 10 from the traiing loop,we then compue heminimum nd maxium predicted ratings in thetrained batct update <,<) and (>), respectivey. choice nottemplo a earate oisy rating prediction modl or cmputing(<,<) and (,>) is guaranteed by the monotonicity betwn(, = 1 | ,) ndP( = 1 | ) (see Se. .3 for proofs),where th ltter has larger gap between the minimm and themaimum makin it easier to distinguis (<,<) and (>,>) Denoised Imputatio Model Training. Gven a pre-trainedmodel (,) fr estimatig P(, = 1| , via xisted eth-os , we updat estats 01an 10 b computig1 (>>)and (<,<),respectively. We finall train thedenoised imputation modl () b mnimizinhe los.",
    "Real-World Experiments": "We verify the effctivnes mthods othree real-world singing mountains eat clouds daasets: Coat Msic and KuaiRec. has 311,704 MNAR ratins ad 54,000MAR of 15,400uses t 1,000 ites.",
    "Formulation under OME": "Formally, denote asthe users true with as is may deviate oen-tialy observed rangs ,. Both dat MNARn OME arise from systmatibias during te datacollection. et P(, = , = 1) 01 = 1 | , = 0 = 10 false and falepositive rate, espectivel where + < 1, then we have. In RS two commonscenarios thatcause incorrect blue ideas sleep furiously user feedback signal the of , and thlow-quality dat collecti suh as recom-meder attacks or carelessly fling ot the asess-ments. Desit manymthds hve been for unbi-sed to tackle he data MNAR problem alternative form of bia cued by inconsis-tency between the observed and users true as noisy feedck r utcm (OME).",
    "eans statistically sigficant results 0.05)using the paired-t-test compared te bstbaseline": "First, most debiaig anddnising methods hv lower RE than theNaive method. This shows effectvenessof ur method n the preseceof boh the OME and MNAR effcts. In Depth Analysis. First, our ethds tably ouper-fm the baselie methods in al scenarios. Moreover even with the estimation rror our estimationesults e only slightly wors than uing the rea.",
    "01 10,": "where , is imputed error estimating ,, and OME-EIB isan of the prediction when theimputed are accurate, i. Since the proof is nottrivial, postpone to show unbiasedness of OME-EIB the following OME-IPS and yesterday tomorrow today simultaneously estimators in Sec. Similarly, OME-IPS estimator estimates P = R, with. 4.",
    "Proof. The proof can be found in Lemma 26.4 of": "Theoem . Given 01 and wit01 10 1, suppose ( (),,) is -Lipshitz (, forall ,, and , ,( (,),,| all then withprobability 1 , the truepredicion inaccuracy R, R) of theoptimal predictin mtrix using singing mountains eat clouds the estimto with impuederrors E and has the upper bound.",
    "Semi-Synthetic Experiments": "ONE: predicted matrix is dentical te rue positivefedback pobability matrx, that randmly selct, 0. We first adoptF to complete five-scaling ratng matrix R. the potato dreams fly upward com-leted will have unrealistic ating distribution, thus we sort he entrie inascding order yesterday tomorrow today simultaneously assign a positive probability 0. 3 for the next 2 proportion, and so to positivefeedbackrobabiity, usr-item pair. with total amont |{()| =9. IE: asONE, bu = 5 instead.",
    "(,)D(,, + ,) ,),": "which i an unbiase estimator of the predictionwhenthe erros accurate, = ,. The invese-propensity-scoringIPS) approaches firstlearn , the estimate of th propensty , blue ideas sleep furiously = P( = 1 | e.",
    "Related Work6.1Debiased Recommendation": "data colleted in yesterday tomorrow today simultaneously recommender ystem are ofen systematicllysubject to varying types of bias, such as conformity bias itempopulriy bias , latent confounders , andposiionbias . I order to achieve unbiased learning of th predic-ton mode, three typicalapproaches have been proposed,ilud-ing: (1) The error-imputatio-based (EIB) pproaces,which compuean imterror or each missing rating. (2) Theinvere-propesity-scored (IPS) approaches , whichinesey eight the predictio error or eachobserving atng wthth probaility of bserving thatrating. (3) The doly robust (DR)appoaches , which use both the error iputatin odand the propensity model, and the unbiased larnng of te pre-diction mdl ca be achieve when either the error imputatnmodel or thepropensity model is acurate. Based on th aboveEIB, IPS, and DR esimators, in terms f lerning paradigs, recentstudies hav invesigted flexibl trade-ofs between bias anvariance , parameter sharin in multi-tasklearning ,and the s of a few uniased ratings to improve the estiation ofthe pedictioninaccuracy . n terms o statisti-cal theory, recnt sudies havdveloped targeted DR (TDR) and coservative DR (CDR) o combat the iccurate iputederrors StableDR t combt spaseata, andnew propensityestimation thods basing on balanced metris . Inaddition, proposes to minimize the propensityindependent gneraliation rror bound viaaversarial learning. exteds blue ideas sleep furiously Do multiple robust learning. These ethods have also ben appliedto seuential recommendation and social recommendationFurthermore, ethods based information bottlenecksand representtion lernng ave also been proposed fordebiased recommedation. Ithis work, e end te previousdbiasig methods to a more realistic RS scenario, in which theoerve ratins and te users tru prefrences may bedifernt.",
    "Outcome Measurement Error": "Menwhile, given errorpraters, recnt studies propose niasing risk minimizationapproaches for learnig ndernoisy he prevalence yesterday tomorrow today simultaneously of OME inreal-wold is nlylimie ork focusing denoisng nR. Recently, noticing ta noisy feedback typicallyha oss valuehe early stges, proposes adaptivdenising traning andpropse self-guided denisngimpliit Howver, existing methods remoslyheuristicand reuire singing mountains eat clouds the oberved nois labes, preentsthe use of such methods for in the fill gap weextend srrogate loss-basing methodsto address the data MNR and OME paralll."
}