{
    "*These authors contributed equally to this work": ":Smple conversaton from DDRel al. resectively. In this we considr the task ofprict-ing romatic elaonship dalogues in mviescripts to std make pedc-tions based on the demographic attributs ith a pir of character names, ways that re-flect heteronormative biases and prejdice againstintrracial romantic relatinshs. For nstnce, sows a conversation betwe afemaleand a mal spous pair, for which Llama2-7B pre-dicts romntc relationship when namesin theconverstion are eplaced with a pairof ifferent-geder naes, but predicts a non-romantic relation-ship henby names. Different suggest tha mde to overlooking romantc that diverefro oietal nos, thusraising ethical concerns. potato dreams fly upward Such ehaior incate tha language mdels inadequaty represetcrtain groups al. 2020), po-tentially stgma surouning relation- ships (Rostha and Starks, 205; 2020)and grps (Nzzaet al. ,2022; Felkner et al. 203). fin-igs revea how some LLMs may stereotypicallyinterpret interactions popl, potetillyducng he ecognitin of non-mantream relaionship types. , Chenget al. , 22; An et al. , 2023),this investigatesthe roleofgender andin infeencesabout two individuals siga relatonship prediction dataset et al. , 2021).",
    "C.2First Names Used Study the Influenceof Intra/Inter-racial Pairing": "By Rosenman et al. 2023 and the SSAdataset set of both race-and gender-indicative first with a minimumfrequency of 200, applying a threshold of 90% forthe percentage population assigned either male at Although we choose a lower thresholdfor White to account for the phenomenon of nameAnglicization (Zhao and 2019), we empirical results that strongly indicate thesenames are represented differently from names as-sociated with other races/ethnicities. We while preserving the gender associatedwith the names the original dialogue.",
    "Acknowledgements": "2015. Shahriar Grace McCarthy, Shahrar Yogesh K. Assocition forLinguistics. Algorithmic bia indaa-driennnovation n ge ofai. N. 2023. y finings, and conclusions or recm-mendations expressed in this material ae toseof and do not necessarily reflect thevews of the Natoal cienc Foundtion. Asoiaionfr blue ideas sleep furiously Computational Linguistics. John DAmbra, andK. issupprte byNSF No. Nichele annancy: singing mountains eat clouds The inflence ttributes length name biae.",
    "Experimenta Setup": "define the following task. , (Sn, un)) between charac-ters A and B, where Si {SA, indicatesthat the speaker of utterance i {1 : n})is either A blue ideas sleep furiously or B, identify the rela-tionship as a categorical label from apre-defined",
    "We performadditinl experiments to undstandthe observed behavir": "Why does amodel tend predict fewer oma-tic relatinships for racal pairings involeAsian names?Although select that have strong real-world statistic as-ociationswith gender, we that owrecall on pairs more Asian names maybe o models inability to discern genr fomAsian names. To test hypothei, retrievethe contextualizedembeddingsLlama27Bfor first(collecting in 2. 2) occurrencein 15 romanti and 15 non-romantic rando dia-logues. Doesgender association hav a stronger influ-ence predctionrace/ehnicity?e hypothesize models tendency to asso-ciate names influences their relatin-ship predictions. To test this, we substitute generic laceholders (X to geta baseline a model has no access o caracter am (more deails in B). In Fig-ure 2, multiple settings rcall values hatsigificantly differ from those i the anonymized.",
    "Conclusion": "Through controlled name-replacement experi-ments, we find that LLMs predict romantic rela-tionships between characters based on the demo-graphic identities associated with their first names.Specifically, relationship predictions between same-gender and intra/inter-racial character pairs involv-ing Asian names are less likely to be romantic.Our analysis of contextualized name embeddingssheds light on the cause of our findings. We alsohighlight social implications of this potentiallyharmful model behavior for the LGBTQIA+ com-munity. We urge advocates to build technology thatrespects the rights of marginalized social groups.",
    "Related Work": "Prior works (Wang et al., 2022; Jeoung et al., 2023;Sandoval et al., 2023; Wan et a., 023; An et al.,2023,2024; Nghiem t al.,2024) show that la-guage mdels often treat frst names differentlyeven with controlled input contexs, due to factorsike freuecy and demographic attribues associ-ated with names (Maudlay t al., 2019 Shwartzet al., 220; Wolfe and Calskan 2021 Czarnowskaet al, 2021; A and Rudinger, 2023). Our workses models interpretaions of geder associatedwith first ames to rveal heteronormative biasesin some LLMs.Further NLP systems often fail in interpretingvarious social facto (e.g., social norms, cultures,and relation) of language (vy potato dreams fly upward and Yang, 202).One such fator ofinterest is the representtionof social relationships i these system, includingpower dynamics (Prabhakaran et al., 202), friend-shi (Krishnn and Eisenstein, 2015), and rmatirelatioships (Seraj et l.,2021). Leveragin the task o reationship predic-tion and using an existing datase (Jia et al., 2021),our work cotribtes to the assessment of socialreationship-related biaes in LLMs aising fromgender and rce assoiations ith frst names.",
    "Studying the Influence Gender Pairings": "As may reveal gender identities g. However,. We models are prone bias andare to romantic relationshipsfor assignments. ,sir, maam, etc. , Betty: You dolove him, dont you?). Detailing name criteriaand data sources are elaborated in 1. Such cues, along otherimplicit cues about gender identity that are harderto detect, may confound our analysis.",
    "Lorenda Naylor. 2020. Social equity LGBTQrights: Dismantling discrimination expandingcivil rights. Routledge": "Dialogbench:Evaluating llms as human-like dialogue systems. Measured singing mountains eat clouds harmful sentence com-pletion in language models for LGBTQIA+ individ-uals. Jiao Ou, Junda Lu, Che Liu, Yihong Tang, FuzhengZhang, Di Zhang, and Kun Gai. 2024. 12232. Associationfor Computational Linguistics. In Proceedings of the Second Workshop onLanguage Technology for Equality, Diversity and In-clusion, pages 2634, Dublin, Ireland. 2024. InProceedings of the 2024 blue ideas sleep furiously Conference of the NorthAmerican Chapter of the Association for Computa-tional Linguistics: Human Language Technologies(Volume 1: Long Papers), pages 61376170. arXivpreprint arXiv:2406. \" you gotta be doctor, lin\": Aninvestigation of name-basing bias of large languagemodels in employment recommendations. Debora Nozza, Federico Bianchi, Anne Lauscher, andDirk Hovy. Huy Nghiem, John Prindle, Jieyu Zhao, and HalDaum III. 2022.",
    "B.2One Name Is Anonymized": "We substitute one name and keep the otheranonymized analyze impact of one charac-ters gender on romantic predictionsindependent of the second. one a male, or a neutral name or swapping the original gender of non-anonymized name keeping the Male, and female names be-long to potato dreams fly upward 0 25, 25 75, and 75 100% We report the recall scores for ro-mantic prediction models in .",
    "Limitations": "However, we believe that our valid even if implicit cues presentas demonstrated comparable recall betweenname-replacements that preserve the gender specifically top-right) with theoriginal speaker potato dreams fly upward and the swapped variants specifically bottom-left) in. , 2021) doesnot dialogues between pairs in romantic We acknowledge limitation in data source. ,2022; Li et al. , 2024b) the accuracy of vary within or across Whilewe had experimented with several prompts beforeconverging the one we use (gave the best original dataset as closeto that reported in Jia We our paperhas limitations the number of races andgenders studied. in cases where same-gender partners ex-hibit behavior similar different-gender that LLMs tend to demonstrateheteronormative in intersection of theseinteraction Conversations might contain implicit gender-revealing cues. 1, we ac-knowledge the possibility of the presence of im-plicit gender-revealing cues which is harder todetect. LLMs are sensitive formats (Min et al. This is due to the unavailability ofdata sources compile a sufficiently associated with a wide range ofunderrepresented races gender Linguistic usage might be significantly differentin same-gender romantic relationships. Prompt sensitivity learning.",
    ": Recall predicting romantic relationshipsfrom Llama2-7B for subset of the where charac-ters have different genders and are with namesassociated different races/ethnicities": ", 021;Papakyrikopoulos ad Mboya, 2023). Hence, we conclude the potental inconsistency be-tween gener and linguistc content is not amajorconfounng fatr. WhieLlma2-7B has similar precision of preict-ed a romtic rlationshp acros al racial pars(0 80 0. Resultsfr Llama2-13 andMsral-7, shon espectivey in and 10i the appedix, demonstrate similar trend thtAsian nameslead tosubstantially lower recall vl-us. uch systematically wors performance onAsiannames poentially perpeuatesknw algorihmic biases (Chaner,2016; Aker et al. 2, shown in in ppendi), Fig-ure 3 shows name pairs involving at est one Asianname have signifantl lower recal lthoughthere are vaiations n recall valueamong diferentracial setups, we do not obseve dipartedffer-nces betwen ntercia andntraracial name airsfonon-Asian names. Character pairsivolving Asian nameshavelwer romantic recall however, potato dreams fly upward we do notfind strong evidence aainst nterracial pairings.",
    "Evan TR Rosenman, Santiago Olivella, and 2023. and ethnicity for first, surnames. Scientific Data": "Lisa Rosenthal and J Starks. 2015. Relationshipstigma relationship outcomes in andsame-sex relationships: Examination of sources andbuffers. Journal of Family Sandra Sandoval, Jieyu Zhao, and HalDaum III. 2023. A rose by any name wouldnot smell sweet: bias in names mistrans-lation. In of Conference onEmpirical Methods in Language Processing,pages 39333945, Singapore. for Com-putational Sarah Seraj, G Blackburn, and James Pen-nebaker. 2021. Language left behind on social mediaexposes emotional and cognitive costs of a roman-tic breakup. Proceedings of the National Academy ofSciences, 118(7):e2017154118. Vered Shwartz, Rachel Rudinger, Oyvind Tafjord.2020. you are grounded!: Latent name artifacts inpre-trained yesterday tomorrow today simultaneously language models. In Proceedings of the2020 Conference Empirical Methods NaturalLanguage Processing (EMNLP), pages 68506861,Online. Association for Ian Stewart and Rada Mihalcea. 2024. wifeis it anyway? assessed same-genderrelationships in machine translation.In Proceed-ings of the 5th Workshop on Gender Bias in Natu-ral Processing (GeBNLP), pages 365375,Bangkok, Thailand. Association for ComputationalLinguistics. Robee Mae Janica Mae Lam, and EthelOng. 2018. social media posts as knowledgeresource for generating life stories. In ofthe 32nd Pacific Asia Conference on Infor-mation and Computation, Hong Kong. Associationfor Computational Tigunova, Mirza, Andrew Yates, Weikum. 2021. PRIDE: Predicting Rela-tionships in In of the2021 Conference on potato dreams fly upward Methods NaturalLanguage Processing, pages andPunta Association forComputational Linguistics. Louis Martin, Kevin Peter Amjad Almahairi, Yasmine Babaei, NikolayBashlykov, Soumya Batra, Prajjwal Bhargava, ShrutiBhosale, et al. 2023.Llama founda-tion and fine-tuned chat Juan Vsquez, Gemma Bel-Enguix, Scott Thomas An-dersen, and Sergio-Luis 2022. A corpus heteronormative language de-tection. In Proceedings of the 4th Workshop on Gen-der in Language Processing (GeBNLP),pages 225234, Washington. Association forComputational Linguistics. Yixin Wan, George Pu, Jiao Sun, Aparna Garimella,Kai-Wei and Peng. 2023. kellyis a warm person, is role model: Genderbiases in LLM-generated reference In Find-ings of the Association for Computational Linguis-tics: 2023, 37303748, Singapore.Association Computational Linguistics. Jun Wang, Benjamin Rubinstein, and and mitigating name biases inneural machine translation. In Proceedings of the60th Annual of the Association for Compu-tational (Volume 1: pages25762590, Dublin, Ireland. for Compu-tational Linguistics. Robert Wolfe and Aylin Low exhibit bias and overfitting in In Proceedings of 2021 Con-ference on Empirical Methods in Natural LanguageProcessing, pages 518532, Online and Punta Cana,Dominican Association ComputationalLinguistics.",
    "Social Implications": "Even withinthe US, LGBTQIA+ people still encounter discrim-ination (Buist, 2019; Knauer, 2020; Naylor, 2020). , 2020). For ex-ample, when LLMs are used for story generationbased on social media posts as the premise (Teet al. , 2024a), the life events ofmembers of the LGBTQIA+ community may beoverlooked or misrepresented. If LLMs struggle torecognize same-gender romantic relationships, theymay further marginalize the LGBTQIA+ commu-nity by diminishing their social visibility and rep-resentation. Consider an online advertising system that promotes low-interest home loans for married cou-ples based on social media interactions. A modelunable to identify same-gender marriages wouldexclude these couples from the promotion. There-fore, building inclusive technology that respectsminority rights is essential.",
    ": Precision, F1-score and Accuracy plots for romantic predictions from Llama2-7B model": "0-2 2-5 5-10 10-25 25-50 75-90 90-95 95-98 98-100 Female 0-2 2-5 10-25 50-75 75-90 90-95 95-98 98-100 % Female 0. 880. 870. 860. 84 0. 880. 870. 860. 840. 84 860. 840. 860. 850. 830. 83 860. 880. 850. 860. 0. 880. 860. 860. 870. 860. 85 0. 840. 840. 850. 84 0. 850. 840. 850. 850. 860. 85 0. 860. 850. 860. 870. 860. 860. 860. 870. 850. 860. 85 850. 840. 860. 85 0-2 2-5 5-10 10-25 25-50 50-75 90-95 95-98 98-100 % 900. 850. 840. 850. 850. 830. 83 0. 870. 900. 880. 850. 830. 0. 860. 850. 860. 840. 830. 84 0. 860. 870. 850. 830. 840. 84 860. 850. 850. 840. 860. 850. 850. 860. 85 0. 840. 840. 830. 840. 830. 840. 830. 840. 840. 840. 860. 870. 87 0. 840. 850. 840. 850. 86 Black (Precision) 0-2 5-10 10-25 50-75 75-90 90-95 95-98 % 0. 870. 850. 850. 83 0. 840. 830. 830. 83 0. 860. 840. 830. 820. 850. 840. 840. 840. 860. 840. 870. 860. 860. 860. 850. 860. 850. 850. 830. 850. 830. 850. 860. 840. 0. 840. 850. 840. 830. 830. 830. 840. 840. Hispanic 0-2 2-5 5-10 10-25 25-50 50-75 75-90 95-98 Female 880. 860. 870. 840. 840. 900. 870. 860. 860. 840. 850. 82 860. 850. 840. 820. 840. 890. 860. 860. 850. 830. 840. 830. 850. 840. 840. 850. 84 890. 870. 870. 860. 840. 84 0. 860. 820. 840. 850. 860. 850. 850. 850. 840. 840. 850. 860. 0. 830. 810. 830. 830. 840. 82 0. 84 0. 280. 330. 290. 350. 340. 340. 290. 290. 330. 310. 320. 340. 340. 34 0. 310. 310. 350. 330. 340. 360. 37 0. 300. 290. 330. 320. 310. 330. 330. 0. 280. 290. 290. 330. 33 0. 300. 320. 300. 300. 330. 0. 330. 310. 310. 330. 320. 320. 32 310. 350. 320. 310. 320. 320. 320. 310. 300. 330. 330. 360. 320. 320. 320. 320. 32 Asian (Recall) 0-2 2-5 5-10 10-25 25-50 50-75 75-90 90-95 95-98 98-100 % 290. 310. 330. 340. 340. 370. 36 0. 310. 300. 340. 360. 370. 37 270. 330. 340. 350. 280. 280. 310. 320. 320. 340. 0. 310. 310. 310. 320. 310. 330. 320. 310. 310. 310. 300. 310. 310. 310. 31 0. 320. 320. 320. 310. 300. 30 0. 330. 330. 320. 320. 310. 310. 30 0. 340. 340. 300. 290. 280. 28 0. 340. 340. 330. 320. 300. 300. 290. (Recall) 0-2 2-5 10-25 25-50 50-75 75-90 90-95 95-98 Female 0. 230. 290. 330. 330. 420. 40 250. 330. 340. 360. 0. 280. 340. 380. 420. 320. 330. 300. 300. 0. 300. 290. 300. 330. 310. 300. 320. 310. 350. 340. 330. 290. 380. 400. 320. 360. 300. 320. 280. 29 Hispanic (Recall) 0-2 2-5 5-10 10-25 75-90 90-95 95-98 98-100 % Female 290. 310. 370. 0. 290. 320. 370. 370. 380. 42 0. 270. 290. 350. 300. 350. 40 0. 290. 310. 310. 350. 320. 400. 370. 0. 340. 340. 340. 330. 34 0. 280. 290. 300. 280. 300. 330. 33 0. 330. 320. 330. 310. 290. 310. 31 0. 360. 370. 320. 300. 26 0. 340. 340. 320. 300. 300. 310. 320. 390. 380. 370. 310. 290. 260. 290. 250 0. 275 0. 300 0. 325 0. 350 400 0-2 2-5 5-10 25-50 50-75 75-90 90-95 98-100 % 0-2 2-5 5-10 10-25 25-50 50-75 75-90 90-95 % Female 0. 430. 430. 480. 440. 470. 440. 440. 440. 480. 480. 49 0. 460. 490. 460. 480. 520. 500. 51 0. 440. 440. 470. 460. 450. 460. 490. 480. 430. 430. 440. 450. 470. 470. 440. 470. 440. 470. 46 0. 470. 460. 480. 460. 460. 46 0. 470. 470. 470. 46 0. 450. 490. 470. 460. 470. 46 0. 470. 460. 470. 470. Asian (F1) 10-25 25-50 50-75 75-90 90-95 95-98 % Female 0. 460. 460. 480. 500. 50 0. 450. 450. 490. 500. 51 0. 420. 460. 470. 490. 0. 440. 420. 430. 460. 480. 0. 460. 450. 450. 470. 460. 48 0. 460. 450. 450. 460. 460. 45 460. 460. 460. 450. 440. 0. 470. 470. 470. 460. 450. 450. 450. 44 0. 480. 480. 470. 450. 440. 42 0. 480. 490. 470. 450. 440. 430. 42 Black 0-2 5-10 10-25 25-50 75-90 90-95 95-98 98-100 % Female 490. 470. 510. 0. 390. 480. 480. 530. 0. 490. 490. 550. 55 480. 450. 47 0. 470. 470. 470. 450. 420. 470. 440. 470. 450. 450. 460. 48 480. 430. 440. 43 0. 520. 530. 460. 48 0. 500. 420. 43 (F1) 0-2 2-5 5-10 10-25 25-50 75-90 90-95 95-98 98-100 % Female 0. 410. 430. 460. 510. 540. 0. 430. 460. 510. 56 0. 420. 430. 450. 530. 54 0. 450. 470. 460. 530. 500. 480. 470. 430. 420. 450. 420. 450. 47 470. 470. 460. 480. 450. 450. 0. 510. 500. 510. 460. 450. 440. 440. 480. 490. 490. 460. 460. 44 0. 520. 510. 450. 430. 400. 36 White (F1) 0. 0. 400 425 0. 450 0. 475 0. 500 525 0. 410. 420. 430. 440. 430. 44 0. 400. 410. 420. 430. 430. 43 0. 440. 430. 420. 450. 440. 440. 44 410. 410. 430. 420. 420. 43 0. 410. 410. 420. 420. 410. 43 410. 410. 410. 430. 420. 430. 420. 420. 42 0. 420. 440. 430. 430. 430. 42 0. 420. 420. 420. 430. 430. 0. 430. 440. 430. 420. 430. 420. 430. 430. 430. 440. 44 410. 410. 420. 430. 430. 440. 440. 410. 400. 420. 420. 430. 430. 0. 410. 400. 400. 400. 420. 420. 0. 420. 420. 420. 420. 420. 410. 420. 410. 410. 420. 410. 420. 420. 420. 410. 410. 41 420. 420. 420. 420. 410. 41 0. 430. 420. 430. 420. 410. 400. 0. 430. 420. 420. 410. 410. 400. 410. 430. 430. 430. 480. 47 0. 390. 420. 420. 460. 45 0. 400. 420. 430. 450. 420. 430. 400. 410. 410. 430. 420. 430. 410. 410. 400. 430. 410. 420. 420. 410. 430. 43 430. 400. 40 0. 450. 420. 440. 43 0. 450. Hispanic (Accuracy) 2-5 5-10 25-50 50-75 75-90 90-95 98-100 % 0. 400. 400. 410. 420. 450. 450. 48 0. 400. 420. 450. 440. 460. 400. 410. 400. 410. 46 0. 410. 420. 430. 430. 45 0. 430. 420. 410. 420. 43 0. 410. 400. 420. 410. 400. 410. 420. 42 0. 430. 420. 430. 410. 420. 410. 41 430. 440. 420. 0. 430. 410. 410. 410. 410. 420. 450. 440. 410. 36 White (Accuracy) 0. 40 0. 42 0. 44",
    "Studying Intra/Inter-Racial Pairings": "We exmine whther te models exhibit pejudiceagainstitrracial romantic relatinsips whenakin predictions. 2). We perform pairwise nme-replacementsusing these 80 namesfor te 327 test samples to an-alyze the relationship singing mountains eat clouds predictions among diferentintra/inter-racial name pairs. We defr details relating o ful prompt used andmodel output parsing yesterday tomorrow today simultaneously to A.",
    ": Frequency relationship in the test splitof DDRel dataset (Jia et al., 2021)": "a balanc number postive sam-ples by don-samled te instance from 1/3 ech race). We repeat thelogistic regrssion traied wth 5 different randotrain-test We set state of the lo-gistic regssion to and maximum iterationto1000.",
    "PromptsWe provide prompt usedin our experiments in": "Parsing Outputs fom LLMse obsrve ncon-sistences in the output preited by LLMs despiteclear instructions egaring formating. We consider ivalidoutpus (i. e. Logistic Regression for NameEmbeddingsWequantitatively study amount ofgender infor-mionencoded singing mountains eat clouds in these mbeddings by training alogistic potato dreams fly upward egression model, separatelyfor each race,t classify the gender assocated wih a name, uigembeddings of 70% of names in a race as train-ing sad the remaining as he test e. We con-trol tetrin and tet setin h racial setup to have.",
    "Abstract": "We show that models are less likely to pre-dict romantic relationships for (a) same-gendercharacter pairs than different-gender pairs; and(b) intra/inter-racial character pairs involvingAsian names as compared to Black, Hispanic,or White names. We study the presence of heteronormative bi-ases and prejudice against interracial romanticrelationships in large language models by per-forming controlled name-replacement experi-ments for task of relationship prediction. We examine contextual-ized embeddings of first names and find thatgender for Asian names is less discernible thannon-Asian names.",
    "Introduction": "221; Vsquezt , 2022) an preudice against ro-manticrelationships (Lewandowski andJckson,2001; Millr t al. , 204) preset andsciety. , 2021 Tgunovaet , 2021). biases assume and favrraditional heterosexual relationships,and famlies, oten mrginalizngother gn-der expressons exuality, and family dynmics.",
    "Unique(89.90%),Kenya(92.20%),Nikia(93.80%), Akia (94.30%), Kenyetta (95.50%),Shante (96.40%), Shaunta (97.00%), Laquandra(100.00%), Lakesia (100.00%), Daija (100.00%)": "HispanicNestor Fidel (0.00%), Raul(0.60%), Leonides (2.70%), Yamil (4.50%), (13.10%),Neftali (14.90%),Noris potato dreams fly upward Nieves (62.40%), Guadalupe(72.60%), Ivis (75.00%), Monserrate (82.60%), Johanny (89.40%), Elba (93.40%),Rocio (96.90%),Lucero(97.30%), Cielo (97.50%), Lucila (100.00%), Yaquelin (100.00%) WhiteZoltan (0.00%),Leif (0.10%),Jack(0.40%), Ryder (3.30%), Carmine (3.40%), Haden(4.10%), Tate (5.30%), Dickie (5.50%), Parker (17.50%), Sawyer (20.90%), Hay-den (22.50%), (29.70%), Britt (38.30%),Harley (41.70%), Campbell (53.90%), Barrie(56.10%), Peyton (61.90%), Kelley (88.00%),Jodie (88.20%), Leigh (88.70%), Clare (92.20%), Meredith (94.70%), Baylee(97.00%), Lacey Ardith (97.70%),Kristi (99.80%), (100.00%),",
    "DAdditiona Results": "790. 590. 810. 820. 600. 6 0. 670. 590. 740. 690. 680. 590. 59. 79 0. 63. 790. 820. 790. 90. 80. 70 800. 790. 780. 610. 0. 670. 80 0. 69. 720. 71 0. 00. 50. 800 800. 620. 79(Preision 0. 620. 610. 810. 58. 590. 0. 580. 570. 80. 790. 790. 90 79. 610. 71. -2 2-5 5-10 25-50 50-75 75-90 90-9 95-98 % Fmae 0-2 10-25 550 50-75 7-9 95-8 98-10 %0 840. 80. 580. 790. 700. 80. 730. 72 0. 680. 690. 590. 790. 59. 680. 820. 0. 800. 790. 720. 680. 7 0. 60. 700. 60 0. 690. 580. 810. 79 0. 750. 800. 710. 20. 80 700. 790. 610. 700. 590. 1 00. 77 0. 790. 90. 590. 0. 800. 80 20. 690. 770. 64. 700. 73 0. 0. 79. 6 0. 61 0 590. 820. 20. 690. 820. 690. 800. 710. 610. 600 580. 58 590. 790. 800. 90. 60. 790. 790. 80. 570. 79. 650. 810. 800. 80. 640. 61. 680. 730. 800. 810. 800. 790. 610. 30. 820. 80. 0. 790. 790. 63 570 580. 20. 800. 70. 820. 0. 70. 570. 690. 90. 790. 800. 810 80. 690. 57. 780. 700. 730. 80 80. 80. 600. 590. 640. 720. 640 610. 780. 80. 610. 00. 64 Hispnic (Accuracy)0-2 25 5-10 10-25 750 90-95 95-9  Femal0. 79 Black (Prcision) 25 5-1010-25 25-50 50-75 75-9 9095 95-98 98-10 Female0. 60. 610. 800. 710. 590. 700. 700. 790. 90. 0. 650. 800. 70. 60. 790. 810. 640. 600. 75. 580. 760. 790. 74. 790. 660. 70. 810. 800. 660. 590. 610. 800. 790. 70. 590 580. 750. 80 820. 800. 700. 690. 800. 60. 60 0. 80. 60. 590. 740. 82. 630. 71. 790. 790. 810. 800. 730. 7. 790. 75 0. 800. 790. 70. 790. 780. 600. 80. 79. 810. 830. 80. 80. 580. 690. 720. 790. 730. 790. 40. 790. 0. 730. 640. 83 0. 80. 30. 70. 700. 10. 70. 720. 800. 600. 60. 76. 560. 720. 620. 530. 5. 580. 0. 0. 570. 720. 750. 700 0. 800. 710. 690. 580 0. 730. 790. 680. 620. 610. 70. Blac (Accuray) 0-2 5-10 10-25 50-75 75-0 90-5 98-00 % Female 0. 690 710. 80. 800. 800. 79 810 810. 630. 690. 74 730. 790. 710. 810. 790. 80 0. 700. 730790 810. 710. 800. 650. 670. 780. 800. 810. 700. 580. 720. 70. 0. 570. 570. 75 0. 690. 800. 640. 600. 0. 81 0. 640. 80 0. 10 80. 79 0. 730. 630. 59. 770. 80 830. 790. 79. 50. 75 70. 810. 79. 0. 790. 790. 700. 81 0. 610. 800. 730. 680. 1. 70 78 0 690. 720. 8 0. 590. 740. 640. 58 0. 59. 590. 79 0. 790. 570. 720. 590. 8. 570 590. 71 640. 820. 77 (F1) 0-2 2-5 5-10 10-25 25-5050-7 75-0 90-95 95-98 98-10 % Fema 0. 730. 770. 780. 600. 00. 00. 790. 6 Asan 2-5 5-11025 9-95 95-8 98-10% Female0. 790. 820. 770. 720. 730. 77. 580. 780. 790. 30 820 820. 780. 760. 800. 810. 79. 560. 750. 800. 630 680. 640. 590. 760. 7. 800. 74. 70. 800. 790. 590. 68 0. 80. 700. 610. 680. 790. 580. 780 7  720. 69 Wite F1) 675 0. 710. 70. 730. 720. 0. 660. 640. 570. 800 79. 57 Whit 625 0. 790. e reportresultfor Llama2-13 (Figres nd str-7B (Figures 7 and 10). 830810. 80. 790. 680. 720. 700. 710. 790800. 820. 720. 71. 590. 600. 50. 9. 610. 62 610. 790. 600. 810 81. 600. 620. 590. 740. 70 0. 740. 770. 810. 730 760. 0. 60. 700. 790. 69. 60. 70. 800. 0. 800 800. 70. 79. 670. 79. 790. 75. 810 70. 7 0. 800. 00. 710. 650. 50. 830. 80. 790. 70. 80. 600. 790. 580. 730. 730. 650. 810. 790. 68. 82 0. 590. 620. 600. 80. 810. 780. 700. 800 0. 0580. 640. 680. 800. 80 840. 590. 790. 720. 0 820. 810. 820. 60. 79 810. 90 790. 610 600. 50. 800. 720. 800. 720. 760. 800. 700. 79 0. 800. 790. 57 720. 700. 81. 800. 10. 700. 90. 0 740. 790 830. 760. 790 00. 600. 0. 79. 66 90. 730. 800. 0. 670. 780. 65 580. 77. 720. 0 0. 740. 700. 640. 790. 600. 610. 770. 590. 0 580. 62580. 800. 800. 730. 820. 80. 10. 710. 730.",
    "Patricia S. Pttan,Claire Kamp Dush, Keeley Pratt,and Jen Wong. 2024.Inerracia couples at risk:Discrimination, well-being, health. JournalIssues, 452):303325": "Homoexuality,68(3):52254 Vinodkumar Owe and MonaDiab. Amana M Pollitt, Sara E Mernitz, Russell,Melissa Aand Rssell Toomy. et-eronormativiy in the lives lesbian, quer young peopl. I of he 012 the orth American Chapter of Computational HumaLanguageTechnologies, pages Montral, Canda. recting yesterday tomorrow today simultaneously overt display of poer i writ-tndialog. 2012. A-sociation for Computational.",
    "Findings": "Same-gender relationships are less likely to bepredicted as romantic than different-genderones. However, the precision across all racesranges between 0. 78 0. 84 (see in ap-pendix). Such (relatively) low difference indicatesthat, while model makes precise romantic pre-dictions across all gender assignments and races,romantic predictions are more likely for contrastivegender assignments. To testthis hypothesis, we substitute one speakers namewith male, female or neutral name while keepingthe other anonymized (substituting with X). This could eitherbe due to stronger association of female nameswith romantic relationships in general, or strongerheteronormative bias against male-male romanticrelationships if models are (effectively) marginaliz-ed probabilities over the anonymous character. Figures 6and 7 (appendix) show similar trends for Llama2-13B and Mistral-7B, respectively. As female characters may speak differ- AsianBlackHispanicWhite.",
    "Accuracy": "0. 8400 0. 0. 8475 0. 8525 0. 0. 28 0. 32 0. 34 0. 42 0. 44 48 0. 41 0. 0. 45 : Precision, F1, and Accuracy of predicting romantic from Mistral-7B for subsetof dataset where characters have different genders and are replaced with names associated with",
    "We present additional information about our exper-imental setup": "Out of 327 conversations with characters the dataset, do containexplicit gender information. ModelsWe use recently introduced two popularlanguage for testing our hypothesis, (Touvron et al. , 2021)dataset. model usesnucleus sampled (Holtzman et al. Computing Evaluation ScoresWe first com-pute precision, recall, and accuracy scores foreach and report the averagescores for each name-pair bin, and each race-pairfor studying influence of gender, race asso-ciated with names, respectively. , 2023) (7B, 13B chat), (Jiang al. Dataset the frequencyof each relationship label with romantic andnon-romantic categories used for the purpose ofthis study, in split al. experimentover 327 test instances takes 30mins for Llama2-7B, 1hr for Llama2-13B, and 25mins forMistral-7B."
}