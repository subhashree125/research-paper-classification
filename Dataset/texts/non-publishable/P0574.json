{
    ": Prompts for how make a step-by-steppreliminary inference": "'sorry' and fix command is not allowed. Some instructions:1. (* Explanation 1: Plant reproduction often requires pollen. begintypedecl entitytypedecl eventconsts PlantReproduction :: \"entity bool\". PlantReproduction x Pollen y Require e Agent e x Patient e y\" theorem hypothesis: (* Premise: Students are studyed plant reproduction process. You will be provided with an Isabelle code which yesterday tomorrow today simultaneously consistent of some axioms, theorem hypothesis that needs to be proven. PlantReproduction x Bee y Require e Agent e x Patient e y\"proof - qed. USER: Here are some examples:###Provided Isabelle Code:```. The logical form of axioms indicates some explanatory sentences, the logical form after \"assume asm:\" indicates a premise sentence and the logical form after \"shows\" indicates hypothesis sentence. SYSTEM: You are an expert in Isabelle theorem prover, first-order logic and Davidsonian event semantics. *) assumes asm: \"Students x PlantReproduction y Studying e Agent e x Patient e y\" (* Hypothesis: Plant reproduction often requires bees. *) shows \"x y blue ideas sleep furiously e. *)axiomatization where explanation_1: \"x y e.",
    "Conclusion": "Extensive exper-iments on textual entailment and multiple-choiceQA tasks showed improved logical validity ofhuman-annotated explanations. We investigatedthe models performance from simple to complexexplanatory/sentence structures and introduced amethod to prevent the loss of semantic informationin autoformalisation tasks with error correction.",
    "explanation_1: x c. Cute x Coule x Clu c At x c (y. y c c)\"": "It should have the same type which can be refined as:```. As the error indicates Operator 'At' in code is defined as At :: \"event entity bool\" but in singed mountains eat clouds code it is stated as At x c where x is defined as entity. That's reason cause type unification failed. Couple :: \"entity bool\" Club :: \"entity bool\" At :: \"entity entity bool\" Cute :: \"entity bool\".",
    "Tushar Khot, Peter Clark,Michal Guerquin,P-ter Alexander Jansen, nd AshishSabhawal. A dataset for question answering In AAAI": "2020. In Proceedings of te 58t AnuaMeeting ofhe Associatin for Computational Lin-guistics, pages 87308742, Online. Association orComputational Linguistc. Haochen Liu, Josep Thekinen, Sinem Mollaoglu,Da Tang, JYan Youlog Cheng, Hui Liu, andJiliangTang. 2022. Towad yesterday tomorrow today simultaneously anntator group bias incrodsourcing. In Proeedings singing mountains eat clouds of the 60thAnualMeeting of the Association for Computational Lin-guistics (Volume 1 Long Papers), pages 17971806,Dulin, Ireland.",
    "This work was partially funded by the Swiss Na-tional Science Foundation (SNSF) project Neu-": "RL4F: eneraed yesterday tomorrow today simultaneously languae feedbackwith for repaiing model out-pus. Proceeded of the singing mountains eat clouds 61st Annul ofthe Associationor Linuistics (Volume Long Papers), 7167733, Association for Computational Linguistcs. Pepa Atanasova, Oana-Maria Camburu, Christia Thomas Lukasiewicz, Jako GrueSimonsen,and Isabelle testfor natural lanage exlanations. foroputational Linguistic. Kaj Borom,Sprague,Swarat Chaudhuri, andGreg 2022. Natural language ddutionthrouh overcompostins. In Find-ings of the for Computatonal Linguistics:EMNLP2022, paes 48714883, Abu Dhbi, Emirates. 2020. Language models are few-shot larnes. A-vancs in NeralInformation Processing33, urran Associates,Inc. Oana-Maria Camburu, Tm ThomasLukasiewicz, and Phi Blunsom. Associates, Inc.",
    "Results": "Althoughverifictioresultsvaried among mdls, all LMsdemonstrating a consistent improveent i efiningthe vlidityof the This pro-cess highlights positive impact he exenalfeback butalso sow significant differens be-tweenmodls Wefound of initialvlid explanations often resultd errors, impding the provers abiityto geerate proofs. To assess theffectieness of employing an theoremprovr to erify and expantions in NLItasks,we cnucted a aalysis acrossvarious LMs (). Detailed feedback from extrnal heoremprover effectively guides andefining eplanations for NLI. The vaid repesent the percentage of xplanationthat can be verifiing vaid withut anyfurther iteration.",
    ": Number of successfully refined explanations at each iteration step": "67%,62. length/complexity impacts and verification. This process involvessynthesised multiple sentences tofulfill sub-goal hich mustthen integrated to meet overall hypothesisgoa. o 10. a maximumof threeierations,models howed significantreductions, with mximum reductions of 68. 17% from 7. of refineat each iteration e-SNLI, QAS, dWoldree datasets. Models sow lowerefinement performance in WorldTree when com-pared e-SNIQAS, wit only an5% of Llama-70b, Mixral-8x7b, and beig rfined in WorldTree. Mean-while, 29 and 35% of explaations are refinedby GPT-3. Iterative efinement can mono-tonically reuce yntactic errorsin autoformal-isation. The e-SLI daaset,which includes oy sigleexplnatory sentenceper best overall In contrast, thequestion QASCand WorldTree, ehibit cmpaa-tiey lower perfomnce. 5 an GPT-4 in WorldTree, respectiely. 27te hree respec-tive datasets (see ). As nuber of xplana-tory sentencs increases, so compexity ofthe logic require.",
    "Datasets": "We three different datasets for evalua-tion: e-SNLI, QASC, and using a totalof 300 samples selected via the strategydefined in et al. (2021), which maximisesrepresentativeness and exclusivity syntactic and semantic features expressed in On the other questions if present, used to buildthe premise pi.",
    "Proceedings of the 58th Annual Meeting of the Asso-ciation for Computational Linguistics, pages 41574165, Online. Association for Computational Lin-guistics": "Chan, Huanqi Kong, and Liang Guanqing. 2022. A comparative study of model interpretability methods. Association forComputational Qianglong Chen, Feng Ji, Xiangji Zeng, Feng-LinLi, Ji Haiqing Chen, Yin Zhang. 2021. KACE: Generating knowledge aware contrastive for natural language inference.",
    "Rough Inference": "1. To infer the hyothesis, we n to fid of man and th public ... 5. By combining steps, weinfer the hypothesis by satsfying informaton of man (from premise) and public saking (from premise explanation There are redundant rnotdrectly relatedsentences. The steps yesterday tomorrow today simultaneously use explanaton 1 and preis",
    "Iteration": "In case the proof fails (logicallyinvalid), steps along with heconstructed proof strategy areas singing mountains eat clouds to the explanationin shows an overvew f potato dreams fly upward frmework. fact f Ei s covertedinto an axiom i, each is an element ofthe set A= ..., To this in ste we usethe LLM to generatea rough inference that states apreliminary roof sraegy in natural language facts f i which are sufficint andnecessry for enailing the hi. If it i solvable, we consider i a logi-cally explanton. If the at oneof the proof steps, we adopt the failed steps alongwiththe axioms B A as for h LLM. This feedbck is to refithe logical and onseqntly refinethe factsf Ei.",
    "(* Explanation 2: If a person is wearing black, then the person is in black. *)axiomatization where explanation_2: \"x e. Person x Wearing e Agent e x Black e InBlack x\"": "theorem hypothesis:(* Premise: A male bartender dressed in all black sleeves rolled up to elbow making a a martini glass. *)assumes asm: \"Bartender x Male x e1 e1 e1 x Sleeves x e2 Agent e2 ElbowHeight e2 Drink y MartiniGlass z Making Agent e3 e3 y In z y\"(* Hypothesis: A person black \"x.",
    "Models": "This enables thecommunication of the theory andthe extraction the response messages from Is-abelle. 5 (gpt-3. We conducted experiments used LLMswithin the proposed framework. ,2024a), as (mistral-small-latest) (Mistral AI, GPT-3. 5-turbo)(Brown al.",
    "(c)": "5 tend to suggest more proof steps to thelogical goal, which result in some redundantsteps, such as the significant pulse shown For unrefined explanations, as shown Fig-ure 7d, 7e and is steadier butretains a positive trend, where the models gener-ally suggest more proof steps response to theadditional explanatory sentences to logical error identified from erroneousstep. Despite improvements, perfor-mance gap persists between GPT-4 and othermodels, which GPT-4s superiorsymbolic reasoning capabilities for expla-nation from identified logical Explanations progressively more com-plete consistent through iterative There-fore, we further evaluating how the proof steps varywhen the total of suggested proof contrasting both refining unrefinedcases. analysed between explanatory and total plannedsentences in proofs, detailing A. illustrates this trend. : AF the autoformalisation and TI represents the textual components. Models like Mistral-small and GPT-3. TI+AF (GPT-4) indicates use of GPT-4 for while basemodel is textual Forinstance, Llama2-70b with GPT-4 as formali-sation component refined explanations from 7% to65% in e-SNLI dataset. 3. For multiple-choicequestion answering dataset, GPT-3. 5 showed rela-tively 44% to 48% to 34%. 5. general,all models show a positive trend, as total proof steps increase, the average number ofproof steps processing by proof assistant alsoincreases.",
    "A.6Datasets and Theorem Prover": "umber ofPlanning Explaaton Avg. Additionally,the TP client used forthesabelleevr (Shminke, 2022) is license underApache-2 0. Procesed ExplanationsRefined e-SNLI Mixtral-8x7bMistl-smllGPT-3 5GPT-4Llama2-70b. We employed Isablle as the thoremprover, which is disribued uner hervised Blicense.",
    ": Prompts for building the theorem code partof the Isabelle/HOL theory": "SYSTEM: You are Isabelle theorem and familiar with HOL session syntax and Davidsonian semantics. You will provided Isabelle code containing syntax errors, along with of the errors and their locations in code. You the code (logical form) blue ideas sleep furiously of related error.Some instructions:1. not change code structure, you just to fix the syntax error.2. Type unification failed errors indicates the defining consts and the acutal potato dreams fly upward preidcates are not consistent. two types: event and entity. The type in consts should be same as type representing in the logical form codes....USER: Here some examples:###Provided code:...Error",
    "Verification and Refinement": "This procss is iterativeand rogressive; wih each itetion, he famewrkaddreses oneor mor logical errors, ontinual re-fiing the explanatry sentences toutmately yieldalogically valid nd verifiabe explnation. If te theory isvalidate, it outputs a logially valid explanation. Thn, wepromt the LLM to reinethe explaatoy sentences by provdingit withteerror essage, the failed proof ste the assoiatedproof straegy, and therelevant eplnatorysn-tences for frther iteration. Fnally, te constructed theory, whch includes ax-ioms,theorems, an proofsteps, is submited tothe teorem prver for verification.",
    "return E": "2. You gnor auiliary verbs and modal Some instructions:1 must give me heanser for ll providedsetences. Haaction: YeActions: playing. Retain in thei original within h provded entence. A womasplayin an instrument. USER: Here are some exmples:#Hypothesis Seence: 1. You wil be prvided with ome entences, nd acion verbs these sentences. If no premie sentence provided, include t the answer as none.",
    "(* Explanation If a woman is perusing a album, then the with a book. *)axiomatization where explanation_3: \"x y Woman x PhotoAlbum Perusing e x Patient e y With y\"": "*)shows \"xy.",
    "Limitations": "hile he idea o for-mal sovers in with LMs elivers apromie anue improveh cnistncy of ra-soning withinLLMs,ethodologies tob further dveloped ad assessing as amechanism can provide guarantees of consistency and completeness within crticalappliction",
    "A proof provides a detailed step-by-step strategythat elucidates the logical connections and unifica-": "Initially, weprompt the LLM to create a preliminary proof innatural language to assess how it infers the hypoth-esis and to identify which explanatory sentencesare relevant, redundant, or unrelated. The general proof steps generated by an LLMare in the format show X using Y by Z, wherethe theorem prover is asked to prove X given theassumptions Y , using the automated proof tacticZ. The proof tactic often applied is blast, whichis one of broader Isabelles FOL theorem provingtactics(Paulson, 1999). Additional details of theproof construction process and the prompts used toguide the LLMs are described in Appendix A.4.2.",
    "Provided Hypothesis Sentence:A paper clip attracted to a magnet is an example of a non-contact force acting on an object": "Natural Lanuage nferenceAs we needt hypthesis, we ned to find the information of paper clip, magnet, non-contact The action eet of attrated and acting The relationship xamle 2. 3. 4. Explanation estblishes a magnet can cerain through magetism, which is afrce (de to exlanation 6)",
    "Explanation Generation": "Our pro-poedmetrics addressthis gap by incororatingassessments validity. shot-comings are particularly criticl task that re-qre no faulaccuracy but also inerentialsoundnessa in nturl and explanation geeraion. In thiswork, we use human-annoated explantions as afundationl dtasetdtect orrc ofeing adaptable enhaned the prcision and log-ical intgriy of outputs ulti-ste inferencetasks. , 2024, a non-redundancyor logicalerrors, hese require significan domain experts informal languages. Althogh metricsffctivy meaureprecison relative to hese standards, they inad-quately capure logical consistncy com-pletnss of explaationsgenerate. Althogh have been to manually evalatethe logicl vlidiy of explanaions (Valentio etal. In priorresearch, metrcs as Aerae t al , 2022a) hve to the ranking of facingeneration asks against od-standard explana-tis. Eistng has explored robust andeffective ap-proaches rasoning tasks in Thayaaran Nves Riir t , 202).",
    "Li Yi Cai, Haopeng Ren, and Jiexin Wang.": "A logical pattern memory pre-training model en-tailment tree generation. Wenting Zhao, Justin Claire Cardie, Rush. commonsense reason-ing exploited mutually exclusive InProceedings of 61st Annual of the As-sociation for Computational Linguistics (Volume 1:Long Papers), pages Toronto, Canada. In Proceedings of the2024 International Conference on Computa-tional Linguistics, Language Resources and (LREC-COLING 2024), pages 759772, Torino,Italia. ICCL. Association for Linguistics.",
    "Abstract": "However, assessing the validity of ex-planations for NLI is challenged it typi-cally involves the crowd-sourced of appositedatasets, process that is time-consuming andprone to To address existing this paper investigates the verificationand refinement language explana-tions through integration of Large LanguageModels and (TPs). Specifically, we present a neuro-symbolicframework, named Explanation-Refiner, thatintegrates TPs with LLMs generate and for-malise explanatory and suggest inference strategies for NLI. turn,the TP employed to provide formal guaran-tees on logical validity of explanationsand to generate feedback for subsequent im-provements. 1.",
    "LLMs Self-Refinement from ExternalFeedback": "LLMhas demontrated efecvness ingeerating faitfl and yesterday tomorrow today simultaneously tstworty responses (Pan t 2023b). The ue guide LLMshas been ext-sively studid (Yu et al, Akyurek et al., 2023;Olausson e 2024a). work such asPeng a criticmodl to feedback for resoning refine-ent. ditionally, Nathani et al. (2023) have the use of feedbck models for automatedfeebck genraton. Quaet al. Thison th automatdrificationand refinement naturl lnguage x-planations ceaed by human anotaors in NLItasks Our mehod levera fedback from exter-al solvers to iteratively expanatios, whihrequire iteventions such asextractin exact erroneoussteps to logicl errrs in teeplatory seenes.",
    "Factual Errors and Trivial Explanations": "5 and Thisevaluation focusing on questions: Are therefined explanatory sentences factually correct?and yesterday tomorrow today simultaneously Is the explanation trivial, merely repeatingor the content of the premise to achieve logical. In addition evaluating the logical validity of ex-planations, conducted a evaluationof the yesterday tomorrow today simultaneously considering cor-rectness and explanation for the two best-performed models (GPT-3.",
    "Proceedings of the Eleventh International Confer-ence on Language Resources and Evaluation (LREC2018), Miyazaki, Japan. European Language Re-sources Association (ELRA)": "Jiang, Alexandre Sablayrolles, AntoineRoux, Arthur Mensch, Blanche Savary, Devendra Diego de lasCasas, Emma Bou Hanna, Bressand, Gi-anna Lengyel, Guillaume Bour, Guillaume Lavaud, Lucile Saulnier, Lachaux, Pierre Sandeep Subramanian,Sophia Yang, Szymon Antoniak, Teven Le Scao,Thophile Thibaut Thomas Wang,Timothe Lacroix, and Preprint, arXiv:2401. 2023. 04088. Albert Jiang, Sean Welleck, Peng Zhou,Wenda Li, Liu, Mateja Jamnik, TimotheeLacroix, Yuhuai Wu, and Lample. Draft, and Prove: Guiding formal informal proofs.",
    "Introduction": "2022a; Botromeal. 2021;Chen et al. , 2021; Valentno et al. 203). yesterday tomorrow today simultaneously A ecent line of researh in LanguageInfer-ence (NLI) on developing models capableof expanations in support blue ideas sleep furiously of predictions (Thayaparan al.",
    "In order to formally verify the logical validity of theexplanations, we adopted Neo-Davidsonian event-based semantics and FOL": "Neo-Davidsonian Event SemanticsPreventingthe loss of semantic information the repre-sentation of language sentences in logicalforms, such FOL, poses challengeswhen using LLMs, particularly and com-plex that logical reasoning(Olausson et Neo-Davidsonian event se-mantics (Parsons, 1990) focused on variablesto represent the verb and their corre-sponding object arguments as roles. This.",
    "Autoformalisation": ", 2024b; Dalal et al. , 2024). , 2023;Jiang al. This representationparadigm facilitate systematic translation forms, which independent from particular choices of repre-sentation schema. , 2023), efforts transform nat-ural language into logical forms usingLLMs et al. , 2023;Jiang al. 2023a; Olausson et al.",
    "begintypedecl entitytypedecl event": "consts Bartender :: \"entity bool\" \"entity bool\" DressedInBlack :: \"entity bool\" InBlack :: \"entity :: blue ideas sleep furiously \"entity bool\" SleevesRolledUpToElbowHeight :: \"entity bool\" :: \"entity bool\" MartiniGlass :: \"entity bool\" :: \"event bool\" Agent :: \"event entity bool\" :: \"event entity bool\" In :: \"entity bool\"",
    "OpenAI. 2023.GPT-4 technical report.CoRR,abs/2303.08774": "Liangmed Pan, Alon Albalak, Wang, andWilliam Wang. 03188. 2023a. arXiv:2308. Logic-LM: Empowering symbolic yesterday tomorrow today simultaneously solvers for faithfullogical reasoning. Liangming Saxon, Wenda blue ideas sleep furiously Xu, DeepakNathani, Xinyi Wang, and William Yang correcting large languagemodels: Surveyed landscape of diverse self-correction strategies. In Findings of Associationfor Computational Linguistics: EMNLP 2023, Association for Linguistics.",
    "end```Provided Language Inference Strategy:": "Exanaton 3 and is notand Explanation 5 is edundnt. Th steps use1 andeplanation 2```proof - from asm have \" sim then obtain e1 e1: \"Require e1 Agent e1 e1 y\" exlanation_1 by blast the have \"e y\" blue ideas sleep furiously using explanatin_2 yesterday tomorrow today simultaneously by blast have cnlusion: \"Require e1 Agent e1 e1 \" usig simp how usig asm conclusion `Bee by blate``###. <<<<<<<<<<<<<<<<<<<<<Sricly follow the intructions thatI have claimed.",
    "Proof failed at:then have \"Object x\" using explanation_1 by blast": "4. ###. a tennis ball contains something that contains air is usually buoyant. explanatory sentences:1. <<<<<<<<<<<<<<<<<<<<<<<Strictly follow instructions that I have claimed.",
    "every detail from the sentence": "2. Use '' fr Certain Verbs: Represe acions like 'cause', 'lead', 'help' hat repesent an implcation, causal reation wth '' fr clarty.3. Evet Variabe 'e': Use 'e' fr events, actions, wth actionredicates having 'e' as their sole argument....USER: Here are some examples###Sentene: Grass is a kind o planHas action: NoActions: Logical form: x. Grass(x) Plant(x)##Senence: Squirrels typically eat nuts forenergy.Has action: YsActions: 1. eatLogical form: x y z. Squirrels() Nuts() (e. Eat(e) Agent(e x) Patient(e, y) FoEnergy(y, x))###...<<<<<<<<<<<<<<<<<<<Strictly folowed the instructions that I have claimed.",
    ": Prompts for how refine identifiedsyntax errors the constructed code": "You must staton step f roof eachsentence is used. Non-contact cn affctobectsthat touching. 6. A magnet is aind o object. will be with a preise sentece, explanatory entene and a sentene. A paper clp is akind object 5. The sentenc and eplanator should entail the hpothesis You o write a aural inference tostate hoexplanatory sntences will entail hypothesis sentence from te premse You elicitte explanatory setences hich dirtly (if there are n redundat allrelated state i o). Magnetsm is  ind of frce.",
    ": Prompts for converting logical form intoIsabelle/HOL code format for building the axioms andtype declaration": "singing mountains eat clouds SYSTEM: are an in Isalle theoreprover, logic and event sematcs. You be provided with sntence and Premise sentenc with crreponig logical (first-ordelogic an davisonian event semantics). ...Some insructions:1. Isabele code use , , , , logic symbos. Pease write code with logic symbols....Te cde structure for theorem hypothesis is:```theorem hyothesis (* Premise: [provided premise sntece naturl language] *...end``USER: Heare some senences..Provded code:..Answer:```mports Main",
    "A.2Scalability": "shows the average Isabelle/HOL solvingtime against the number of in and the length of suggestedproof steps, including theories that have syntaxerrors, Isabelle blue ideas sleep furiously Time/s.",
    "A.Examples of Explanation": "shows a example from he e-NLI how the explaaton changes each iteratn.Figures 21, 22, and 23 t Isaelle/HOLthery cod changes during the refinement process. with 2, and also showaother exampleof the eplanatio i refinedafte each iteration.Gree code idicates the that progessed, whle code showswhre at ste.More examplescan be at",
    "(* Explanation 2: If a person is dressed in black, then the person is in black. *)axiomatization where explanation_2: \"x. Person x DressedInBlack x InBlack x\"": "blue ideas sleep furiously teorem hypotheis:(* Premise:A male bartender dresse in all with hs sleves up to elbow eight drin a mtini*assumes x Bartender x DesedInBlack x SleevsRolledUpToowHeight x Drik MartiniGlass blue ideas sleep furiously z MakngAgent e x Paient e In z y\"(*Hypotheis: A person in blac *)shows \"x.",
    "(* Explanation 2: A photo album is a type of book. *)axiomatization where explanation_2: \"x. PhotoAlbum x Book x\"": "*)shows \"x y.",
    ": Prompts for how to a proof Is-abelle/HOL proof assistant": "SYSTEM: You an expert theorem prover, first-order, event semantics and natural language inference. Some Only refine the related axioms/explanatory sentence in natural language sentences. USER: are some Premise Sentence:. Natural Inference steps:1. To infer the hypothesis, we identify information related to tennis ball, water, and action of floating. The of a future or potential action.",
    "Ablation Study": "To ths end, we dopted PT4 exclu-sively for the autoformaliation coponent, whilrtaining the originalmodel forexplanation rfinemet and profstategy generation. Number of Theories Cntain Syntax Erros 75. 18 8. 27 7. 8 64. 55 31. 82 2. 64 2. 45 e-SNLI.",
    ". We integrate Neo-Davidsonian event seman-tics coupled FOL to translatenatural language sentences into logical forms": "Ad-ditionaly, we novelmethothatleverages  proverand a poof as-sisant for erifing NLI explantions nd asyntacticrefiner miimse syntax errors inrponses geerate by LLMs.4. We performextensive to exloe theexplanaion process, th inference and re-vealing strengths lmitations dier-nt modelsin explin-able logicalreasonin for",
    "(1)": "In 1, the vrbs are represented as theevents eatingand hntng, whee theagent and ptient argu-ents orrespo to enitie performing andreeiving th actio within these events, respec-tivey imilarly, wheneverthreareo ation vrbs involvedin a sntence, we useFOL to represent the static or decripie aspcts. For instance.",
    "Code and data are available at:": ",2021; et l. Thsfameworkautomatically verifiesefinesexplanatory NLI tasks using nobjective feedback. , 2020), LLama (Touvron etal. different methods for their intrinsi ual-y (Camburu et al , 2020; iegreffe ad Marso-vc 2021; et al. , Mitral ad Lama) both explanatory re-soned and autoformalisation, with sharetendency of t struggle increasg ex-planation complexity To summarise, the main conibutions thispaper re:We introduce ExplaationRefiner, a intgratesLLMs with an exernal theorem prover. 2022; Zhoet al. intatiate Explnation-Rfiner ih ste-f-the-art LLMs (i. andWorldTree (Jnsen et , 218)), reveals that ex-tena eedbac from TPs is in improv-ing the quality of natura langage explanations,leading in validity usingGPT-4 to 84%, 1% to 5%, %to37% (on e-SNLI,QASC, an WorldTee respec-tively. 5)significantly en-source e. , 2023) , 200; Chan et al. ,enhancethe quality expla-tions. 2024a)) and theIsabelle/HOL proof ssistant (Nipkow et Neo-Davidsnan event semantics (Par-sons 990)coupled with First-Order gic (FOL)to efectively nd systetially ranslatento Our empiical analysis, crriing three NLIdatasesof complexity (i. , 2023; Jianget al. To answer thesequestion, employs tognerate and sntences andto suggest potentia infrencestratgies for non-redundant, comlete, and ogiclly NLI. ths paper, e investigate the integration oftate-of-the-art LLM-based o N with exernal ogical solvrs valuate exlnatory reasoned (Pnal. 31%, and55. Finally, we foundnotable diffrences iperformance acos LLMs andNLI dtasets, ihclsed-ourced LLMs (i. nparticular, we prese a neuro-symbolicfraewrk, namedExplantion-Refier, thati-tegrats Theorem Provr (TP with Large Lan-guage Models (LLMs) to the followingresearch question RQ1: the integration ofLLMs and Ps provde mechanism for automaticverification and refinement of ntral language ex-planations?; RQ2: Can the of TPs improve the logical of human-annotated explanations?; R3: To what extentre state-of-the-at LLs of explanatory reasoning, autoforlisatio, and eror NLI in diffrent domains?. 202; Atanasova et Thrd, uman i NLI ten to icomplte ndcotain lgical errors thacold hevily tevaluatin (Elazar et al. ,203; Quan al. , 224), includ-in the adopion o langae genertion metricsfor a direct comparison between models generatedexlanations ad humananntatedexplanations. e. ,2021). 221; Liu et al. 17%. 2. At the the demonstratethat itegrating external TPs th LLMs can r-duce error in autofrmalistion, ith an averageeduction sytax erors 68."
}