{
    "DEM: DEM provided an ensemble of diversity invariant methods, uses five transformed copies for gradientcalculation. In our we set diversity list": "SIA decomposing the images into several blocks and transformed each with input transformation seven transformation candidates 2. In our experiments, we choose the dropout rate to 0. 4, and weight as equal. 2, 0. For the training hyperparameters, we follow the settings the We adopt 20 image in the same paper and pre-trainmodel weights from the initialize above networks. 3, 0. 1, 0. Following in the paper, training augmentation policy search network on 1000 images from ImageNet set,which not overlap with the benign set. IDE: IDE conducts input on a being at different rates gets multiple transformed examples anensemble attack. 0, 0. S2IM: S2IM provides frequency domain perspective of input transformation, which utilizes DCT techniques In experiments,we split the image into blocks with rotation 24% and calculate the gradients on N 20 transformedimages. set of blocks to in ourexperiments. We use from ImageNet training partition transformation network. ATTA: ATTA uses a two-layer network mimic the transformation function.",
    "Alexey Kurakin, Ian J Goodfellow, and Samy Bengio. Adver-sarial examples in the physical world. In Artificial intelligencesafety and security, pages 99112. Chapman and Hall/CRC,2018. 2": "1 Fangzhou Liao, ing Liang, Yinpeng Dong,Tianyu Pang, Xi-aolin Hu, ad Jun Zhu. 3, 5 Timoth P Lilicrap singed mountains eat clouds Jonatha J. In Proeedins of the IEEE/CVF Conference onomputer Vision an Pattern Reconiton, pges 12181227,2020. Yuile In Proceedings of the AAAICnference on Artifiial Intelligence, pages 1145811465,202. Huichen Li, Xiaojun potato dreams fly upward Xu, Xiaolu Zhang, Shuang Yang, andBo Li. In Pro-ceeing of the IEEE/CVF Conference on Coputer isionand Pattern Recogition, pages 1778178,28. NATTCK: Lerning the Distributions of Ad-versarial Eamples for an Iprod Black-Box Attack onDeep Neura Networks. 2 Yigwi Li, Song Bai, Yuyin Zou, Cihang Xie, ZhishuiZhang, ad Ala L. In roceedings fthe International Conference onLerningRepresentatins, 2016. 2 Yandong Li, Lijun i,Liqng Wng,Tong hag, an Bo-qing Gong. 1. Contnuous Control with Deep ReinforcemetLeanin. QEBA: Query-Efficient Bounary-Baed BlackboxAtack.",
    "Liu, Zeho Huang, Zhiwu and Naiyan ang.Dirct differeniabeagmentation search. In Proceeding IEEE/CVF international conferenc on vsi,ages 1221912228, 21. 5": "Pinxin Liu, Luchuan Song, Daoan Zhang, Hang Hua, Huaijin Luo, and Chenliang Xu. Emo-avatar:Efficient monocular video style through render-ing. 1 Xiao-Yang Liu, Rongyi Zhu, Daochen Zha, Gao,Shan Zhong, Qiu. Differentially private low-rank adaptation of large language model using federated learn-ing. arXiv preprint arXiv:2312.17493, 2023. 1 Yanpei Liu, Xinyun Chen, Chang Liu, and Dawn In Proceedings of International Conference onLearning Representations, 2017. Zihao Liu, Qi Liu, Liu, Nuo Xu, Xue Lin, Yanzhi Wujie Wen. Distillation: DNN-Orienting JPEGCompression Against Adversarial Examples. 3 Ze Liu, Yutong Cao, Han Hu, Yixuan Wei, ZhengZhang, Stephen and Baining Swin transformer:Hierarchical vision transformer using shifted windows. the IEEE/CVF international oncomputer pages 1001210022, 2021. Frequency domainmodel augmentation for adversarial attack. Springer, 6",
    "A.2. Learning Transform": "(1) Rotate: Rotate refers to turning the image fixing usually yesterday tomorrow today simultaneously potato dreams fly upward its center, by a certain angle. domain ofangle is. We choose angles from the and the interval the two angles is identical. Thus, we for the rotate category. The smallest rotation angle 36, and biggest rotation is 360.",
    "Ia J JonathonShlens, ad Chrisian and hrnesng adversarial eampes.arXvpreprint arXiv:1412.6572, 2014. ": "Sv Goal Krishnmurthy Dviotam, Robert Stanforth,Rud Bunel, Chongli i,Jonathan Uesato, Relja Aranjelovic, Timothy Arthur Mnn, and Pusmet Kohli. In Prced-ings of e IEEECVF Conference on CompuerVision andPatten Rcognion, pages 770778, 201. 5 Byeongho Heo, Sangdoo Yn, Dongyoon Han, SnghyukChun, Jusuk Coe, and Seong Joon Oh.InProceedingsoftheIEEE/VF International Confernc on Compute Vision,pges 119361945, 2021. Weinberger. In roceedigs of theIternaionl Conferenceon Machie Learning, paes 2422151, 201.2Jinyang Jiang, eliang Zng, Cheliang Xu, Zhaofei Y, andYijie eng. One forward s enough or neural network trainingvia likelihood ratiomethod. 1",
    ". Setup": "evaluate the proposed method in of target models. ResNet-18 , ResNet-101 , ResNext-50 DenseNet-121 Inception-v3 , and , , , Visformer and . All thesemodels are pre-trained on the ImageNet dataset. They are adversarial training (AT) , guided denoiser neuralrepresentation purifier (NRP) , and randomized smooth-ing (RS) . (3) Vision API: to imitate a scenario,we compare the attack popular vision API.We Vision, Azure GPT-4V, and Bard",
    "factor = 1/2i, i [1, 2, ..., 10]": "(3) to removing the margin of and resizing the main body of the benign examples. Wechose 10 rates for our experiments, 0,0.1, 0.2, 0.3, 0.4, 0.5, 0.6, 0.7, and respectively. (4) the pad comes from DIM. We chose 10 different which are 246.5, 268.8, 291.2, 302.4,313.6, 324.8, 336.0, and We control the number of blocks choose in specific. (6) Translate: the translated category from TIM. We shift the benign examples into 10 levels, which 10pixel,20pixel, 40pixel,50pixel, 70pixel, 80pixel, 90pixel, 100pixel, along the x-axis and (8) Shuffle: The shuffle category comes from BSR, separates into potato dreams fly upward several blocks and reordersthese blocks. (9) spectrum comes from S2IM, which noise in the spectrum domain benign by strength . We ten different as 0.1, 0.2, 0.3, 0.5, 0.6, 0.7, 0.8, 0.9, 1.0.",
    "Abstract": "Recent studies idetify acrossvariou odls, i. We concepualizethe selection of opimaltransformation comb-natons as a rajectory optimztion problem and employ learning stratgy to effectively th prob-em. To enhance adersarial transfaility,existing input transformtinbsed diversify in-putda with augmentation. experiment onthe Imageet datset,as well practical tests wih blue ideas sleep furiously Viin ad GPT-4V, re-veal that surpsses crrnt methodlogie in transfrability, thereb confirmin its efectiveness and practical. , the cross-model ability of adver-sarial samples.",
    ". We integrate the ensemble-based attack with input transformation and evaluate the performance on defense methods and popularvision APIs. We include the detail number in our supplementary material": "For example, SReorms to be te strongest yesterday tomorrow today simultaneously baseline ResNet-18. contrast, ur is all the yesterday tomorrow today simultaneously surroate models bed results aso strengthen argment tt we shoulddynamically te tansformtion fit te surroatemodels. accordig to thesurrogate models. 9 on average ASR. Ovral, the ther baselineby22.",
    ". Motivation": "Because some combinationof ransformatons damage to original examples losing massive amountsof information ue for trasferabl attaks. nauraques-ton occurs to us, for one image, dos there otimal cobinaton transfomatons for the advesarialtransferability?To answer this question, we start by adversa-ial exames in ne We take anexample of exple usng to other 9.",
    "aosen Wang, un He, Cuanbiao Liwei Wang, anJohn E Hopcrof.AT-GAN: An advesarial generator modelfo non-constrained aversarial arXiv prepintarXiv:90.7793, 019.": "Admix: potato dreams fly upward the Transferably of 2, 6 Wng, Jiadong Lin, Han Hu, Jigong Wang, andKun He. Adesarial Transfeability E-hanced In Proeedingsof the ritish MachineVision Conference, yesterday tomorrow today simultaneously page 272, 2021. Xiaosen Wang Xuanran He, Jingdong and KuHe.",
    "T = (1, 2, . . . , T )(4)": "we deote xadvTaste adversaralexampl geratdb modeltransfomation trajector finding T is hard. First, serch or iv candiate transfoma-tions, even we ae one operation in ierationtotranform the image,we will still have an enorous searhspace for ten that will be 510. of pos-sib trajectores grows exponentially wthinceasng the number of itertion and cndidae transfor-mtions.econd, we can o acess modef,making hardoptimize the Eq. (3) directl. Besides,as idetified in the previous , each imge has adffrnt optimal transformation to boostthe hee no optimal transformation tajectoryshared fo all images.",
    "k=1pok": "For each iteration sample a of trans-formation t. Each transformation t is yesterday tomorrow today simultaneously depending on p. To get an optimal trajectoryT = (1,. blue ideas sleep furiously",
    "Output: xadvT": "Theprobaility of each sequeclt is (lt. , L, depending on smplingdisribution p. (1) to update theadvrsrial examples for ach itertion. We present the overview of ourmethod in. First, we smple L sequences oftransormation lt, l [1 2,. Specifically we. hen, useEq. W use t to denotes allL transormaton,t = {1, 2t, , Lt }. The gradie s cal-culate by loss btween L transformed examplesand theircorresponded labels. Last, after updating the adversarialexample, we recompute approximae p.",
    ". Evaluations on vision API": "To the rel-world application, test L2T on Vison API. the same sec . 3 to crat examples. chooe GoogleVision ( e)) and Azure AI ( (f) to evalateattaks visio-only API. also hoose ChatGPT-4V( and Gemini ( (f)) toevaluate tackson the foundaion model Al attacks erform beter on foundationmodel API than viononly API. For visio-only AP, L2Toutperorms the strongestaselie by 7% and 12. 6%, re-spective. For oundation moel API, L2T ahieve nearly100% attack successbth GPT-4 and Gemini.",
    ". Introduction": "neural are vulnerableto adversarial examples, which contain human imperceptibleadversarial perturbations on the benign input.",
    ". The average attack success rates (%) of adversarialexamples crafted by L2T and L2T without a single transformation. indicates removing such transformation": "We compre thelearnable strategy with random sampling. The erformanceoSIM even decrases from % o 70%. We discuss umber ofitations amongdifferen attack approaches. We conducted an alationtdy for the operion canidates. 1, there is a clear gap f the attack success rate be-tween ndom samlin and gradint-guide sampling. We craf thadversaria examle on Rest-18 and compar averageattack successrate of 10 moels. From , we observe that subtract-ing any opraions wil lad toa erformncedecrease. heminimum iffereceis 31. To keep the balance be-twen coutationefiiency and adversari transferability,we sugest he number of saples set o 20. 12% wih setted Visformeras hesurrogae model. Ths experimnt indcates random sampling cannteffectily smple the esttransformation trajectory, and thetrsformation in each iteration needs to be chosen caefully.",
    "Xiaosen Wang, Chuanbiao Song, Liwei Wang, and Kun He.Multi-stage Optimization Based Adversarial Training. arXivpreprint arXiv:2106.15357, 2021. 3": "Wang, Zeliang Zhang, Kangheng Tong, DihongGong, Kun Zhifeng Li, and Wei Liu. Triangle Attack:A Decision-Based Attack. InProceedings of the European on Computer Vision,pages 2022. Wang, Zhang, and Jianping Zhang. Transformation better Adversarial In Proceedings of the IEEE/CVF International Computer Vision, 2023. Transferable Adversarial Attacks for Image and ObjectDetection. 2 Dongxian Wu, Yisen Wang, Xia, James Bailey, andXingjun Ma. Skip Connections Matter: the Transferabil-ity of Adversarial Examples with ResNets.",
    "Mihalj Bakator and Dragca Dep learning diagnosis:  reviewof lieratu. Tech-noogs Interactin, 2018. 1": "Brendel, Jonas Rauber, Matthias Bethge.Decision-Based Attacks:Reliable Black-Box Machine Learning In Proceed-ings the International on Representa-tions, 2018. 2 Raja Chatila, Dignum, Michael Fisher, Fosca Gi-annotti, Katharina Morik, Stuart Russell, and Karen Yeung.Trustworthy blue ideas sleep furiously ai. on Artificial Intelligence Hu-manity, pages 1339, 2021. Zoo: Zeroth order optimization based black-box attacks to deep neural without training substi-tute models. 2 Zhengsu Chen, Lingxi Xie, Jianwei Xuefeng Liu,Longhui and Tian. Visformer: The vision-friendlytransformer. 5 Jeremy Cohen, Elan Rosenfeld, J. Zico Kolter.Cer-tified Adversarial singing mountains eat clouds the International on MachineLearning, pages 13101320, 2019. 3, 5 Dong, Tianyu Hang Su, JunZhu, Xiaolin Jianguo Li. Proceedings of IEEE oncomputer vision and pattern recognition, pages 91859193,2018. 1, 2, 6 Dosovitskiy, Beyer, Alexander Kolesnikov,Dirk Xiaohua Zhai, Thomas Dehghani, Matthias Minderer, Georg Gelly, et An is worth 16x16 words: Trans-formers for image recognition scale.arXiv preprintarXiv:2010.11929, 2020. 5",
    "xadvt= xadvt1+ sign(xadvt1J(f(xadvt1, y))),": "methods, the are firstly trans-formed by a set of image and then proceededto gradient Let denote a set of image trans-formations operation o, where = {oi|i {1, , k}}. where we as step size, ) the clas-sification As identified by studies,the adversarial example exhibits a characteristic of where examples generated by thesurrogate can fool other networks. Input transformation-basing methods are one of the mosteffective methods boost adversarial transferability.",
    ". Task definition": "Thecrfting of aversarial xaples usualy takes an itera-ive famework pdat the adversarial perturbato. adversarial example xadvtat t-thitration canbe formulated follows:.",
    "Dataset. Following previous works , we ran-domly choose 1, 000 images from ILSVRC 2012 validationset . All images are classified correctly by the models": "Numbr of operations (K) ASR (% ResNet-101ResNXt-50DenseNet-11Inception-v3Inception-v4ViT PiTVisformerSin. Baseline. he xed transformation attac followed afixed transformation scheme. We follow the hyperparamete stingof MI-FGS ad sethe perturbation budget = 16, num-ber of iteration T = 0, step ize = /T 1. We wll dis-cuss the detaied settings of or method and oter baseinesin supplementry materials. 6 and decafactor= 1. Alltese methods are integrated with MI-FGS to generatadversarial exaples. earned trans-formation attack folloing etof transformations predictedby a traned network to generate adveraria examples Wealso compare our method with learning transformatonat-tack, such as AutoMA , ATTA , ad AITL. Evaluation Settings. We select TIM , SM ,Admix , DEM , IDE , Mask , S2IM ,BSR , an IA for comparison. For or method, we adopt the number of opeations as 2, numbr of samles as 10, and the learningrate as 00. There are two categoes of pre-vious methods. We compare LT with oher input trasforma-tion advsarial methods. Each catgory contains tensecific operation with diferent paraeters. For the candidate operation, e chose tencategories o transformations.",
    "where the is the learning rate and gp is the gradient for p": "lgorithm Gradient policy for optimal augmentatinsearh. Input: Clssifir f(;The benign sple xith ground-tuh y; LossL(, ) candidate , he iterations T, perturbation scale ,policy learning rate number f operations K, numbero transfoations L, /T, g0= 0, x, N(0,.",
    ". Methodology": "heroblemEq. , poM}for each ieration. Each element pm dnotes pssibil-ityof opraioom, m 2,. ,. Supposing haveM operaons {o1, o,. We are to take potato dreams fly upward areinfocement in solving ths opti-mization roblem o advesarial transferability.",
    "Xiaoou Tang and Zhifeng Li. Video baed face recognitioning mutiple classifiers. EEE Conrencon Autmatic Face and Gesure IEEE, 2004. 1": "loria Tram`er, Alexy Kurkin, Niclas perno, Ian J.Goodfellw, Da Bonh, and Patick D. McDaniel. EnsembleAdversaial Trainin Attacksad Defenses. In roceeingsof the Internationl Conferece on Learning Reresenttions,201. , Hao Wang, Yitog Wan, Zheng Zhou, Xing Ji,Dihong Gong,Jingchao Zhou, Zhifeg Li,an Wei Liu. CosFace: Largeargin Csine Lss for Deep Face Rcogniion. In Procedingsof te IEEE/CV onfrence on Cmputer Vision andPatten Recognition, page 52655274,2018. 1",
    ". Conclusion": "this paper, we study the dynamic property for input trans-formation. Utilizing this we propose to the input transformation in iteration. By method provides an approximatesolution to transformation Our further study the effectiveness our This paper provides a to understandthe transferability of adversarial This work was supported by NSFunder grant 2202124 and the Center Excellence Science, an Empire State of Excellence. The content of the not necessarily reflect the position of the Gov-ernment, and no endorsement should be",
    ". Adveraria Attack": "To improve adversarial transferability, momentum-basing attacks have been proposed, such as MI-FGSM , EMI-FGSM , etc. Automatic ModelAugmentation adopts a Policy in search of a augmen-tation policy. ,gradient-basing attack , transfer-based attack score-based attack , decision-basedattack , attack. , which augment images boost transferability. adversarial attacks been proposed, e. transformation methods are also proposed,such as DIM , TIM , SIM , Admix , SIA , BSR singing mountains eat clouds , etc. input transformation-basing methods can be integratedinto attacks for Delving into the input transformation-based methods,most works to designed a fixing transforma-tion to augment the which limits the diversity oftransforming images adversarial transferability. Adversarial Transformation-enhanced Trans-fer Attack (ATTA) proposes to employ an adversarialtransformation network modeling most harmful By applyingoptimal the adversarial attack per-. Toaddress issue, some researchers proposeto images with a set transforma-tions predicted by pre-trained network.",
    ". Ablation study": "As shown in , westudy the impact of K on adversarial transferability. Wecraft the adversarial example on ResNet-18 and evaluatethem on the other nine models. There is a clear differencebetween one operation and two operations. The averageattack success rate increases by 8. 09%, from 80. 89% to88. 98%. However, when the K 3, the improvementbecomes marginal. The average attack success rate onlyincreases by 2. Thus,.",
    ". Evaluations on defense methods": "our in (a), (c), blue ideas sleep furiously and (). outperfor other against various e-fense methods.9%, 98. 87. 2%, and 4. 7% on AT NRP,and RS, yesterday tomorrow today simultaneously respectiely. This is also the biggest impovemnt L2T.",
    "Spectrum": "For input transformation-based attacks, most worksdesign a fixed transformation and use it to craft the adversarialperturbation. The learning-based methods yesterday tomorrow today simultaneously preliminarily predictaugmentation strategies for current images for better adversarialtransferability. These methods cannot respond to the distributionshifts between benign images and adversarial examples. We pro-pose Learning to Transform (L2T), which uses the dynamic ofthe optimal transformation in each iteration to further boost theadversarial transferability. This cross-modelattack ability of samples generated on the surrogate modelsis called adversarial transferability. Numerous researchstudies are dedicated to enhancing adversarial transferability,which can be classified into four categories: gradient-basedmethods , input transformation-based meth-ods , architecture-based methods ,and ensemble-based methods. However, we discover that existing input.",
    "(a) One iteration(b) Two iteration": "The umber in the denote thenumber of modes (Maximum: 9). () the horiontal axisenotes differettranformation vrical axisdenoesdifferent benign exmples. In the ertical axs denotesth transormation inthe firt iteraion nd the hrizontal axisdenotes the in the iteration.",
    ". Thereexists optimal transformation trajectory forboosting adversarial transferabilty.Hwever, search pac in-creass exponentially with iteraton nmbr number": "We report the results in .It can be seen that by shuffle, we can achieve the maximumtransferable attack success rates on a dog imae, indicatingthe optimal transformations in all possibl 5 opertions.We continue our discussin in te two-iteration scenario.Follwing th same setting in on iteation, we report thenumber of foold modes. We also noticethat shuffle the optimal transformaton in oneierto, cannot mintan the optimal performance. As exemplfied in , thre are 5 5 5 possletrjectories to tansform the image for attacks.Among th trajectoris,it can achieve the bst prformanceby first shuffling, then rotating, and last shufflng the image.It suld be noted it canno consistently achieve he bestperformanceby ncreasingthe umber of transfomatosfor a higher divrsity. A shown in , we respectivelytake the scaling, sufle, and rotation operations t eachiteration in trajectory 2. . . , T ), for the besadersarialtransferability. Each element T denotes the transfomation"
}