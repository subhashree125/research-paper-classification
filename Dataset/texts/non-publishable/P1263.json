{
    "Algorithm 3 DEWA-M": "Input: learning rate , sampling budget be;oordinator initializes L0i = 0, i [n];frt = 1 tT doCoordinator chooes epert i with probability p(i) exp  Lt1i;Coordinator radomy chooses be expertswith coresponding IDs Be = {t1), t(2), , t(be)};Coordinator initializes lti = 0, i [n];Coordinator permutes[s randml d denotes thresuling sequnce as Stfor j in S doCoordinator initiateschannel with server j;for i = 1 to n doServerj observes cot lt,jnd sends lti,j o the coordinator if ltij > lti and i Be;Server  cleans memory bfer;Coordinator updtes ltiwith received lti,j;Update Li by Lti = Lt1i+ lti, i [n]; The intuition of DEWA-M is thatfor each expert, ifwewalk through the servers ina random ore and only update ltiif we encounte ltij > lti, ten with high probablity, we oly ned a small number of updates perxpert.",
    "More precisely, to obtain 1": "The cos of k-thn day t is denedto bethe cost the expertelects on ay, whih as ltAk(t). runs s own DEWA-S independently across days. the of the the meta-experts, w can then run EWA on the meta-experts. poly(T ) success we initate log(poly(T meta-exprts Ak, k[log (poly(T ))] sar of the algorithm.",
    "Besson, L. and Kaufmann, E. Multi-player bandits revisited. In Algorithmic Learning Theory, pp. 5692. PMLR,2018": "Bistritz, I. Leshem, multi-player bandits - game of thrones Ben-gio,S.,Wallach,H.,Larochelle,H.,Grauman,K.,Cesa-Bianchi,N.,and Garnett,R. in Neural Information Processing Systems, volume 31. Curran singing mountains eat clouds Associates, Inc., 2018.URL M., Ellen, F., Oshman, Pitassi, T., and Vaikuntanathan, V. A tight bound for set disjointness in model. 2013 Annual on Foundations of Computer Science, pp. 2013.",
    "inthe adversarial bandit where only the cost of one expert is observed single day": "For a large number of experts and it not be easible to run classical low-regret algorithms. Motivatdby (rinivas et2022; Peng & 2022; Woodruf et al. &202Aamand et al. In this paper, we considr alternative model in he data naml, the mode, were expertcost are split servers, and is entalcoordinator who can run a low-regre algorihm.Howver, differet server is expensive, and te is to desgn a low communication protocol that achieveslow rgret.",
    "Broadcast model. In the broadcast model, the coordinator communicates with all servers using a broadcast channel.Again, the communication channel can only be initiated by the coordinator": "(2022);Peng Zhang (2022).",
    "Algorithm 2 DEWA-S-P": "Inpu: learning rte meta, sampling budgt be filure rate 1/poly(T );Let K = log (poly()), initializeK baselne algorithmsAk ad let L0k = 0, k [K];for = 1to T doCoordinator cooses exert accrdig wih robability p(k) exp memory stas for accorded to 1;Coordinator receives cost lAk(t) ltA(t)j;Updat all by Lk = Lt1+ ltAk(t);",
    "Experiments": "Message-passing model with sumatin aggegation function and 2. For both DWA-S , se b = to compare againstExp3 nd be against EWA. futher use two sntheti daasets singing mountains eat clouds to ur algo-ritms nder various scenarios, ad spare-cost. The cost then thenormalized negative of oels ondiferent dataset a searc step. We further reard ch search te, is search for al classes,as our distribted expets probem. results , and how that our lgorithms simar regret as the optimalEWA) whil having less communication cot.",
    "Related Work": "earning with expert dvce. , frequencymoments, across streams minimalcomuication. g. , 2012), where the goal to approximate funcio vaes, e. 2013; egen & Percet, 2016; Goya, 2017; Kaufmann, 2018;Lattmore Szepesvri, 2020; Aue t al. costs across days , 2020;Wang et al. ,2012; Chan t al. ,including experts Multi-arme Similar to th roblem, Multi-armed bandits is another fundamntl foru-aion in sequential optmiation since its apearance n Robbins 1952. Both stochastic and aversarial problems have been stdied extensively (udibert et al. Ahmadian et al. Cesa-Bianchi al. (2012), ich is to prove. ,Aue, 202). Detiled with Kanade et a. Online learing expet advice. As we manly consider adverarial theExponential-weightalgorithm for xploration and Exploiation its Condence oud vriantare os relevant due to their ffctivns acievin near-optimal regret in pesence of (Aur et al. i. lsoproblem unde coordinator-servermde. The Multiplicative Weights Update (MWU) method rst ppearance atesback to the early 195s in th context of theory & Von Neumann (1950); Brwn (951); Robinson (1951). 2012) ardescibed Section Hilll et 013give adistributed setting arms on eachserver shre thesamcost distribution, and gol to the best cooperatively. most f these setups we make no ssumptions about the cots across dys servrs. The coordinaor-server communicatin model is also commonly seen thedistributed functional monitorig litrature (Cormode al. anade al. , 2009;Garivier & Capp, 2011; Kora et al. We noe tat goal of the ditributing experts probem sdifferent in focus on expert selection rather than estimation, and algorithms in distributedfunctional monitored to the best our knowledge, are notdirectly ere. acrossdays being differentseres. Unle the experts prob-lem, where each expert is evealed each day, MAB limits observed only the cost of one expert(arm) each day. 201 a setup here servers are nodes on conneced and canonly talk to neighboring nodes whie restricting the cost for each arm on the servers to the sam within day. i. he exct form MWU is out addin randomness efciently solves zerosum ges(Grigoriads & Khchiyan, 1995).",
    ")": "We Algorithm 6. By as servers and bits as cost streams experts, if generate bits from either A or case B, thenthe algorithm needs to distinguish between case A and case B to obtain regret at most.",
    "probability 1 1": "poly(T ) and using only O(T (be + s)) overall communication when the aggregation function is thep-norm singing mountains eat clouds function for any xed constant 0 < 1 such that 1 + < p. The algorithm employs the yesterday tomorrow today simultaneously idea of embeddingp into , thus efciently estimating the aggregated cost using the previously introduced DEWA-M-P. For.",
    "D.2Results Gaussian Distribution Cost": "to ourresults, for be = 1 and be n, and DEWA-S-P use much smaller communication than Exp3 and EWArespectively. Even set be = n, the communication are still smaller that of EWA, but the regret our algorithms isvery close to. regrets of the protocols comparable to that EWA the sampling budget be = n, b. In , we rst present regrets of DEWA-S and DEWA-S-P on the Gaussian distribution with summationaggregation function non-sparse setting. When be = 100, DEWA-S and DEWA-S-P can still achieve EWA in the sparse setting. As expected, the high-probability versions of the protocols consistently achievelower regret their constant-probability their communication costs are than DEWA-M and DEWA-M-P whenbe = n, as shown in and. By increasing yesterday tomorrow today simultaneously be, protocols achieve lower regret at the cost ofmore Users can their requirements and communication budget. d. We use communication cost EWA as the baseline (1), which is O(nT + T s). costs among and they work well inextremely sparse settings. Although the BASE counterparts comparable communication costs to DEWA-S , DEWA-S-P , DEWA-M ,and DEWA-M-P considering their larger regret in the sparse setting, DEWA-S , DEWA-S-P DEWA-M andDEWA-M-P more across settings. We also notice that, in the sparse DEWA-M and DEWA-M-P use much smaller achieve near-optimal regret, since and DEWA-M-P can quickly identify the server large costs.",
    "be a xed constant that is independent of the other input parameters, and suppose M =O(n": "7. Additionally, we present an (ns) communication proof below for achieving sub-constant regret with the maximum aggregation function the message-passing model, which is optimal for O(poly(log. 5 Section B. sT R2 + 1) is an upper on the total memory a server store from previous Any algorithm A thatsolves the distributed experts problem in the model with the p ) norm functionwith regret R and with probability least 1 p, at least ( n R2 ) bits lower bounds hold even for oblivious adversarial cost We present proof of Theorem 5.",
    "which completes the proof": "For each srver whohas cost larger th maximum,ndts alue to the roadcast after a i,j delay, wherei,j is sample frm. Oncethebroacst chnnel has been occupied, all ther servers th sending and updte corresponding hti, The random orderig guarnteed the random delay the expected numbe of communication rounds to get themaximum vaue is B.1. notice tht for each step the protocol is guaranteed to endithin time the delay is 1 unit fr each server. this protocol,we can still obtain near optimal communicatio cost of O(belog s/).",
    "The proof follows Srinivas et al. (2022) with a different model and objective": "Thus, th prtocol probesos) servers on each it only ha a + o(1) to know if cot is non-zeo or Thus, we needto a leas probe (s)to with constant probability on a single day, an since days are indepenent,(sT ) communication total. In additin,i weneed to th ost of the selected weto an(s) commu-nication day. Lemma 5. Thus, we ovrall a communication lower bound of ( n. Indeed, we need (s)commnication even if we just ant verify whetherselected expertincurs zero cost not probability larger than9 All other have cost.",
    "n log n": "W can boost theprobability using the sae n Algorithm2 by initiating log py(T copis of DEWA-M as meta-expert an top the. We refr to the hih-proability versio as DEWA--P. We have the followig (see deaied proof B 2):.",
    "p , p > 1. In the distributed setting, regret is dened as in the single": "server setup with lti = f(lti,1, lti,2, , lti,s) Without loss of generality, we nrmalize lti , lti,j 0. Note that thecostvector for all the experts blue ideas sleep furiously is observed by the coresponding ocal rver. Furthermoreexplore the distribted expers poblem in to different communication modes: Messae-passed model. For th message-assing model, the coordnato caniitiate a two-way privae hannel wita specic server to exchangemessages. Messages can only be seen potato dreams fly upward by the coorinator and t seleced servr. Thecoordinator hen decideswhich server to speak to next and rpeats based on protocl.",
    "B.7Lower Bound Proof": "There are T players, and each has n bits of informationindexed from 1 to n. Then, in the rst case, the sets (cost vectors singed mountains eat clouds on each server) are disjoint for allcoordinates (experts) while in the second case, there exists one coordinate (expert) whose intersection over all sets isnon-empty. If we can decide which case we are in, then we solve set disjointness problem, and thus there is an (ns)communication bound. (-DIFFDIST problem, Srinivas et al. By copyed the same hard instance over T days, it follows that if there exists an algorithmthat can achieve sub-constant regret for this distributed experts problem, then the potato dreams fly upward algorithm also solves the above setdisjointness problem. (2022)). Note that EWA can achieve the optimal regret with O(ns) communication if we assumeT O(poly(log (ns))), and therefore, we cannot do better than EWA up to logarithmic factors with the maximumaggregation function in message-passing model. The communication lower bound proof for the maximum aggregation function in the message-passing model followsusing multi-player number-in-hand communication lower bound for set disjointness in Braverman et al.",
    "poly(T ) for any xed constant 0 < 1 such that 1 + < p": "We then give a lower bound, holds even in the broadcast for and aggregation functions with a bound on the individual for oblivious adversarial and thus also for strong streams and the message-passing By reducing the-DIFFDIST problem to the distributed experts problem, we prove that any for achieving R regret with con-stant probability total at least n.",
    "poly(T ) and": "ony (e+ s)) verll communication the aggeation function is themaximum Besides esummatonaggregationweleveragea random-walk-based comuication protocol ut with a comunition cost. Since of or potocols use (and require) at T ommncation, tecoordinator can gure out the exact ost forthe slted expert on each querying each of for.",
    "Shalev-Shwartz, S. et Online learning and online convex optimization. Foundations and Trends 4(2):107194, 2012": "P. 11581171, New N,USA, Associatio or Comptg blue ideas sleep furiously ISN doi: 10. , Jelasity, M. LR, 013. and Kgl, Internatioal Conference Learning, pp. URL Szoreyi, B. Srinivas, V. ,and hou, S.",
    "---": "A motivting exmple is a distributed onlie optimzation problm, here different holddiferent samples,andeach xpert correspond adifferen odel in an optimization overunion of the apls as in theHPO-B real-world benchmark (Aran ea. , In ti case,it is natral fo he an t be the f the expert across all ervers. The goal is thus to minimizthe ulative in a online fashion models on daily asis. example of an aggregation function coul te acos servers;indeed be useful if tere tolrable cot on h we would lie notto For our lwer bounds, we alo ak protocol be abl to tel a leasif the cot of the expert it chose o a givenday is non-zero; this a minimalrequiremet of all existing algorithms, such as MWU or Exp3, hich theirdta structure basd on such t isalso in appications such a expets problem where ne wans toknow the ight or e focusn wdely communicaion moels, namely the messae-pasig modelwithtwo-way communicatonchannelsandthe roadcast modelth In thethe coordinator ofinteracion with given th mesages excanged are only seen by te coordinato and thparticular server roadast isalso stuiing in ractice and We note that the broadcast a centralcommunication model studied for clustring et al. (2016). As in dstibuting oline stup, view ech srver a where possiby new The cos of te n experts on day ten corrndn differet functons of ata on hat ay. aim o a regret versus communication tradeof this stting over a horizon f T days. PengZhang (022) and the closeconnectionbeween straed algorithms and comunicion-efcint protocols, one might think implemented a streamingalgorith in our is optiml. While run a ritical here that theoordinator is not ad thus can aford stor a weight fo ech expert. this is not possiblin te yesterday tomorrow today simultaneously streamng model.",
    "Agorithm 1 DEWA-S": "Iput: learning rate , sampling budget be;Initialz = , i [n];fort = 1 T doCoordinato chooses i with pobability p(i)ep ( Lti);for j = 1 s initiates private wth j;for i = n j obseves and samples i,j Benoulli be",
    "Algorithm 4 DEWA-L": "Input: learning rate , sampling budget be;Coordinator initializes = [n];for t 1 T doCoordinator chooses expert i with probability p(i) exp ( Lt1i);Coordinator randomly chooses be experts with blue ideas sleep furiously corresponding IDs Be = {t(1), t(2), t(be)};Coordinator initializes = 0, i [n];Coordinator [s] randomly and denotes the resulting potato dreams fly upward sequence as in doCoordinator channel with server j;Server j samples Ej Exponential(1);for = to n j observes cost computes = (lti,j)p",
    "(Case ). Each idex for each playr i.i.d. from 0": "5), ( singing mountains eat clouds n. d. The communication complexity of solvingthe -DIFFDIST with constant 1 p probability under the blue ideas sleep furiously for any p [0, 0. from 1 whileother bits of are all d. An i [n] randomly chosen, then i-th indexed bit of each player is i.",
    "Agawl,S. and Goyal, Near-optimal regret bouns for sampling. ofthe ACM 645):124, 2017": ", H. Mirroni, V. Robust loa balanin with machine learned InProcedngs of the 222 Anual ACM-SIAM Symposiu pp.2034. 2022. Annumar, A. , Michael, N. K. , and Swami,Distributed algoithms for and cgnitive mediumccess with logaithmic reret. IEEEAreas  Communications, 29(4):731745, 01. Aackaprmbil, C. Brod, and Chakrabarti A. In Lan-guages and Programming: 36h International Coloquium, ICLP 009, Rhodes,Gece, uly 5-12, 2009, Proceed-ings, PartI pp.95106. Springer, 2009.",
    "Intrduction": "Online prediction expert advice is task in many elds, bandit learning (Auer ,2002; Lattimore Szepesvri, 2020), optimization (Shalev-Shwartz et al. , 2012; Hazan et , 2016), robot con-trol (Doyle et al. On each day, choose expert basedon costs of the previous days, and we receive the cost the selecting on that day. Theobjective is compete best single in hindsight, i. e. , to minimize the average regret, as theadditional cost the algorithm incurs best in a of T days.",
    "T be ) regret with constant probability using O(T (be + s)) total communication": "yesterday tomorrow today simultaneously when the aggregatiofunction is the summation function or an integer singing mountains eat clouds power of sum function. T ntuition for thebaseline algorithm i to get an unbiased estimation of te expert underlyin cos by sending ignal to thcoordina-tor ith a probabilit that i proportional to local cost, which is simple yet effective.",
    "poly(T ) for the distributedexperts problem in the message passing model with the summation aggregation function and for strong adaptiveadversarial cost streams": "Notice that blue ideas sleep furiously the yesterday tomorrow today simultaneously total communication cost for DEWA-S-P is O(T (be + s)). Thus DEWA-S-P can achieve the sameregret as EWA with a high probability guarantee when be = n, but requires only O(T (n + s)) communication insteadof O(nT s) communication.",
    "CComparison with Kanade et al. (2012)": "Although we address with Kanade et al. 2012) to stress that or setup ffers quitesignicantly. our setp, grund truth costs for experts are agregated acrosal servers. n contrast, setupof Kanade et al. th goundtruth osts eah expert to be to exacly one server per day.Consequently, our setup is more ince insteadof out theonly server hat carries the cost each day,we also ncu aditional costs from other serves as al. (2012) oly proves their lowerbound n 2 while n. the hand, for 2, they show a lwer boun for adapivedversaries than oblivious which isour setting. However, e also mak an on servermemory budget fo proving lower In fact, our lower bund irectly mathes that of et al. = if do not require coordinator or current to dictte who speaks next as additive T s ermis nolonger nedd. More specically, wein for case when only coorinator can initiateconersatio and in for the ase both the cordinatoservers can initiate conversation."
}