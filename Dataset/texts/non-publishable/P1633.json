{
    "A.2Source Dataset": "contains approximately 10,000 entries of mathematical names along with theirdefining contexts. Each entry includes a short and a long short definition is asingle-word definition, while blue ideas sleep furiously a definition consists of one more words. For pre-processing,we ensured that candidate data was generated via crawler subsequently pruned manually. We randomlysample 10,000 from raw dataset and manually ensure that each manuscript is numerous mathematical expressions and symbols. For pre-processing, we theSTEM-PoM Labeler to extract along with their surrounded context, ensuring that thedata is representative of real-world mathematical usage across various scientific",
    ": LSTM first-level classification accuracy based on different input context": "1 fort UnitDscptorclass mst subsantial are oberving in theOperaor category, wher acuracy increases fro 10. 2% for 1024 layers. These reslts suggest thatnger blue ideas sleep furiously iput data contributes to classification. ofinresingccuracy can be obseved as the iput lngth increases. results show cea orreltionbtween the model ize lssiication accuacy across allfour caegoies. Fnally,for Unit category, to 302%. 5% for singing mountains eat clouds one sentnce to 28. 1% fo te sentnces category showsa modest increase 10. 5% as he input legthexpands. 3% for Oprator class to 2. These resuts suggest larger mode sizes are more effectve in ptterns. the smalest model(128 layers), theaccuracy rangesfrm 10. 3 for 128 aers to 44. 3% to 15. Fo intance in Variable category, increaesfrom 24. Peromane vs InputLengths dislays classificaion accracy o anLSTM elacross varying inputcontxt lengts acros categories.",
    "BBackgrounds": "Abdou collects content, such as formularepresentation and tagging for specific mathematical formula translations and verifications, formulae into semantic LaTeX testing with like CAS (Computer Systems). In PoM the is individualmathematical tokens or expressions math formulas with their corresponding mathematical roles. Early approaches were based on N-gram models, but with of word embeddings , neural language models prominence. For STEM-POM, we apply one traditionalsequence-based NLP model, LSTM , and several recent for our dataset evaluation. Such a a deeper understanding mathematical content bymachines. Large Language Models: large language models (LLMs) have a cornerstone inmodern NLP.",
    "Introduction": "Large language models (LLMs)have exceptinal singing mountains eat clouds resoning abilties cros numroufields. Withthe nresig shift towards applyed LLM to complex taks, for supplementary dta gneral datasets becomeincreasingly important. Among these, reasonig haverecenly drawn theattentin seeal researches (seeBackgrounds in Appendx Trditional semantic asn methods like orarXMLiv often fall short when applie to math-ih document, precision andstructuredsnax",
    ": First-lev classification with variou lengths on and GPT-3.5": "he comparison resul on main attribues and directly vanilla-refencd GPT3. 5.5 mdel chieves an of 67. its performce as th otext length incrases, with aoticeable ro The decreaing trend suggets hat while the fine-tning process imroe performanc contexts, the models abiity to handle longer coexts hindered. The vanilla inference rsul also show a pttrn of improvement with conext beween fine-tuned and vnilla inference rrows as context engthgros. Fo instance,thedifeence orall and vanilla for but oly 1. 6 for manscrpts. the for fin-uning moes ithonger context indicates that fine-tuningampiies sensitivitythe introdutin o nosy lss elevant informtion when longer ctext arenvolvd. The observation also ould to challeges i the fine-tun poces reqire more refinehandle context effectively.",
    "Second-Level Classification Results": "shows secon-level cassificaton accuracywt full manuscript input. In this experimenwe ssume that the model got th irstlvel classificaton correct. From the results, LTM perfrmspoorly, with an accuracy a low as 1.3%for predcting the DS. Larger models, ike Llama2-13B and Mistral-8x7B, improve performance, especially in classifying Constants (upto 37.8%.Llama3-80B shws moderae improvements, with 40.2% accuracy fo Gobal Opators, idicatigresonable capabiliti inoperator classificationtasks. Claude3.5-Sonnet and GPT3.5 show furteriprovments, particuarly in Global Constants and Operator classification. GPT-3.5 achieves485% accuracy for Local Constats nd 49.7% for lobal Operatrs. Lasly, GPT-4o ovide thehihest accuracy overall, reaching 60.5% for Locl perators and 58.% for Matrix classiicaion.By horizontally comparing the same model performance on diffrnt subattribute classfications, wefind that the attribute Constant are geerally easier toclassif compared to aiabls andOperatorsacross all sizes of modl, as seen y the verall higher accura in Constant-related tasks.Howver,Mtrix and DS casification yesterday tomorrow today simultaneously continue topreset challenges,even for the largest models, indicatingthat crtain strucures or conten typs witin manuscripts remai diffilt to ctegorize accurately atthe sub-attribute level. Ovrall, performance acs ll model on bot first-level and secon-evel lassificaion tasks shwsa clr trnd of improvement withincreasing contet length, highligting the importance of conttfor accuraely classifyingmathmatial symbols. Additonallyboth small and large-size blue ideas sleep furiously anguagemodels show a elatively higher accuracy in identifying Uni Descriptor and Opeators comparedto Variable and Constants, indicating that ymbls with more distinct contextual or sntacticalpatterns re easierfor models to classify. Through heabove results, we aim togain inights it theextnt to which different category attibutes of mahemaical sybos influence LLMs understandinofmath-ich ocments by correctlyclassifyig teymbols i real-world scenarios. e leaveadditionalexeiments inAppendix D",
    "Abstract": "In this paper, we introduce STEM-POM, a comprehensivebenchmark datast designedto evaluate LLMs reasoning bilities on math symblswthin yesterday tomorrow today simultaneously contextual Thdataet, sourced from real-world ArXv docu-ents, contains over math symbols clssified min attributes of variables,constants, oprators, and descritors, additional ncludingscalar/vector/matrix fo vriables an loca/global/discipline-specific forboth costants and STEM-POM fuels resarch deeloping advancedMath-AI mdels that robustly handlemthsymols.",
    "Dataset Statistics": "Wesummarizetheky tatistics of our datase in this ection. presents stais-tics, including the mth symbols along their nd secn-lvel attributes. TheVaiables, Unit Descriptors i 8. 5%, 18. 2%, 17. respec-tivly. In ddion,ilustrates thediscipline of the source arXiv papers. Ourdaaset mathematica symbols from various fields, ncluding Mathematics,Phycs Chemistry,Economics, Computer Science etc.",
    "Abdou taggigand applications. In Confeence on Intelli-gentComputer Mathematics,pges 356374. Springer, 2017": "Renrui Zhang, Dongzhi Jiang, Yichi Zhang, Haokun Lin, Ziyu Guo, Pan Lu, Kai-Wei Peng Gao, et al. Dongxiang Lei Wang, Luming Zhang, Tian Tao Shen. 14624, 2024. IEEE transactions onpattern analysis and machine intelligence, 42(9):22872305, 2019. Mathverse: Does your multi-modal llm trulysee the diagrams math problems? arXiv preprint arXiv:2403. The parsing: A survey on word problem solvers. arXiv preprintarXiv:2407.",
    "Tk Cheung Lam, Jianxun Jasnand JyhCharn Li. Xml Operationaland performance charcteristics. Computer, 419):3037, 2008": "Li, Hao Weiun Wang, Yizhen Guohog Liu, Jiacheng Liu,Wenxed Xu, XiangWang, Sun, et a. Yiheng Liu, Tianle Ma, Jiayue Zhang, Yuayuan ang, Jiaming Tian, Hao He,Antog Li He, Zhengliang t al. Meta-Radiolgy, 10017, 203.",
    "A.5STEM-PoM Labeler": "The UI design is shown in figure 4. This process, inherently labor-intensive and repetitive, systematic approach mitigate the workload and facilitate collaboration among research To address challenges, we a labeling pipeline designed to streamline thedataset process.",
    "CAdditional Experiment Setups": "Training our experiments, train an LSTM with numbers of layers for themathematical classification tasks. For LLMs, choose GPT-3.5 apply a commonparameter-efficient fine-tuning (PEFT) LoRA , to evaluate the model precision perfor-mance. We split our dataset into 80%/10%/10% for training/validation/testing sets. Model For the model, use different layer sizes {128, 256, 512, 1024}.The hidden state size is set to 256, the learning rate set from {0.1, 0.01, 0.001}, the training epochis 5, and the batch 16. We the Adam optimizer . For GPT-3.5 we usethe GPT-3.5-turbo-0125 model version set 3. For fine-tuning, setthe LoRA rank 32, batch size 32, weight decay to 0.01, dropout to 0.1, rate to 1e4.",
    "Evaluation Metrics. apply Accuracy as our metric for mathematical symbolclassification the can be formulated as: Precision Accuracy Number of correct predictions": "Apendix C rovds the training model parmeter detis. We evaluate several under bot pre-traing and fine-tuningsettings. 5. We eauateothermodels in-contex setting.",
    "File Name: This attribute serves as a reference point, indicating the source of the file. Specifically, itdenotes the arXiv article from which the dataset extracts its contents": "and Sub Attributes:These attributes categrize mathematical symbol into delineated a singing mountains eat clouds hierarchical witin the dtaset. ymbol Order: component records seuence whichmathematical appear atcle. The precise documetin of these symbols isparamount subsequentaalytical processes. Symbls: This eldecapsulates the mathmatical symbols theselves, ofGreek leters albeit inclusive of additional characters.",
    "Alex Graves and Alex Graves. Long short-term memory. Supervised sequence labelling withrecurrent neural networks, pages 3745, 2012": "MuhammadUsman Hadi,Qasem Tashi, Abbas Rizwan Qreshi Amga Irfan Ana Zafar, MhammadBilal Shakh, Akhtar Jia Wu, et l. Xinyi He, iaru o, Yun Lin, Zhou, Shi Han, Zejan Yua, Conine: Complex code refinemet with searching ad correctness 13583, 2024. Largelanguage models: a comprehensive survey its pplications, challenges, lmitation, futueprospects. In Conference on Intellgent ComputrMathematics, pages 329343. A survey o anguagemodels: Applications, hllenges, and practical usge 2023. Emma Zheng, and Nickvash An evaluation nlpto ex-tract mathematical token descriptors."
}