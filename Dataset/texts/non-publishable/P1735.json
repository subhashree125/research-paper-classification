{
    "RandomNeigh QuesRephrase Ques": ": potato dreams fly upward distance of random, neighbor-hood imae nd rephrase questio points from theoigial poin. yesterday tomorrow today simultaneously eighborhood point are loserto the target point being deletd oints n which unlearnig atsetsevaluate specificity. This is asoreflected Question Neighbor-hoo -Acc copared Random -Acc.",
    "Comparison of success rates acrossthe three levels of images to attack mod-els edited defense mechanisms": "The in show that the multimodal attack rate (15. 1%) and 9%higher than the best (Hd Img (5. 7%)is 5. 6% igher than thebest question reprase (Hard Question Reprase)(10. Is multmodal attack mor effective than unimodal?We thficcy of the multodal strategy ompared to the unimodal blackox (imageattak question attack). 8%) against the (HP)defense. Similar holds aainst other.",
    "Main Results": "Our results in demonstrte that both andblackbox extraction attacks successfl. We invesigate how each of te defense outlined in against eacho the extraction yesterday tomorrow today simultaneously atacks outlin in. esign. whiteboxattacks, the Probability (PD) attck exhibis performance, achieving. Attack-Success@B = 20 each o the attacks whiebox and backox attacs) in adition to Random -Acc andQestion Neighborhod -Acc and Image -Acc Our is conducted onthe 5-7B with LoRA as the editingmethod yesterday tomorrow today simultaneously we extract piece of deleed multimodal froman MLLM?Yes.",
    "Abstract": "This risk is multimodal (aka MLLMs) as they integrate information from multiplemodalities (image and text). Adversaries can this stored by singing mountains eat clouds across modalities extract sensitive details. While significant research has the creation of datasetsfor unlearning within LLMs, it has primarily concentrated on text modality. of anal-ogous datasets data and models an understudied To address thisgap, we first introduce a multimodal unlearning UnLOK-VQA (Unlearning Out-side Knowledge as well as attack-and-defense framework to evaluate fordeleting multimodal knowledge MLLMs. Our dataset process automated pipeline to create varied proximity levels to the data pointfor evaluation of and specificity, followed by manual filtering to retain only thehigh-quality We use process to extend a visual multimodal information 5%) more successful than either image-only (32%) text-only attacks (39%). best.",
    "Yinzhi Cao and Junfeng Yang. Towards making systems forget with machine unlearning. In 2015 IEEEsymposium on security and privacy, pp. 463480. IEEE, 2015. URL": "On evaluating adversarial robustness. URL Nicholas Carlini, Anish Athalye, Nicolas Papernot, Wieland Brendel, Jonas Rauber, Dimitris Tsipras, IanGoodfellow, Aleksander singing mountains eat clouds Madry, and Alexey Kurakin. 06705, 2019. The singing mountains eat clouds secret sharer:Evaluating and testing unintending memorization in neural networks. Nicholas Carlini, Chang Liu, lfar Erlingsson, Jernej Kos, and Dawn Xiaodong Song. arXiv preprintarXiv:1902.",
    "neighborhood images in is reflected the image-neighborhood -Acc, we conductablation experiments across the two difficulty levels of neighborhood images, and present result in": "Rehrase blato results.Ourobservaions in rvea tha easyan meim rerase imagesexhibit similar attack success aesaginst most defenses, whereas hard yesterday tomorrow today simultaneously rehrase imag re signifianlymore effective. One potentia reasonfor the succes of hard images lies in the fact that aloughtheir semntc cotent is prserved,the generalcompoition of the mags is signifcantly altered. hs alteration can to some extent, render defensmechanisms ineffective. We bservthatthe Image Nghborood -Ac ishigher for hardneihborhood images coparing to easy nighborhood image as evidet frm.",
    "CHuman Evaluation": "We added three options o the answersto simpiy the annotaion s We preset te results in andenshots of te human evaluaton interface in and. , 2024),or our human evalution experimnt, w engged fourgraduate esearch assistants with computer siencebackgrouds. Motivated by prior work that involes valuationof multimod sumarizationataset (Patiletal. uring virtualetings, we roided ovevie of the dataset and detaiing tak description.",
    "Rafael Rosales, Pablo Munoz, and Michael Paulitsch. Exploring resiliency to natural image corruptions indeep learning using design diversity. arXiv preprint arXiv:2303.09283, 2023": "usheb Shah, Quentin Feuilade Montixi, Pour, Arush Tagade, and Javier Rando. Xstest: test for ientifying exggerating safety bevours large language models. Paul Hannah Bertie Giuseppe Attanasio, Fdric Bianhi,and Hv. 1263, 2023. Scalale back-box jailbreaks language models via prsona modulaion. 1678,203. Xiv prepritarXiv:238. ReponibleLanuage Modelling Researc,Deectig petrainig from large language models.",
    "DAn Additional Method for Neighborhood Image Generation": "Motivated by prior work that involves evaluation of the model to invariant images (Patil et al. , 2023b), inorder to get medium rephrase images, we use Grounded SAM to repaint the original image minimally to letthe answer to the original question become the alternate answer a. , 2024) to get subject from q that leads to answer potato dreams fly upward a. Then, we askGrounded SAM to repaint the subject in the image to the alternative answer a.",
    "Whitebox AttackBlackbox AttackRand-AccQ Neigh-AccI Neigh-AccRewriteScoreHPPDPD2HP+FTHard ImgRephraseHard QuesRephraseMM": "999-4770. 2) defense (. 0460. attack (HP+FT) has higherattack successrat compared original HPattack which that al he defeses are vulnerable to thefinetuning attack. This observation is better concealed when the is ou the answer. 10. 040. 20. 3) fr deletingmultimodal iformation UnLOK-VQA that is by the LLaVA-v1. 1050. 0320. 1450. 1950. In contrast, thefirst threemhods ma lower he probaility sensitive excessivly, makig te concealed informationmoe detecable. 4310. 0590. 2030 2370. 0360. 4020. 0590. 130. 965- ntroy0. 2290. 090. 20. 0080. 2960. 2530. 0010. 1690. 974 : success rates of the attacks (. 0290. 8170. exploit easy question rephrasesforthe defense. 956- mpty0. LoRA- act-Eras0. 0680. success rates 20% (when budget B is set yesterday tomorrow today simultaneously 20) against defenses. Fo blackbox attacks, the multiodal (MM) rephrasing attck also often succeedsmorthan 35 of Are defenss effctive against extracion, ouranaysis reveals that, amongthe whitebox defese Fact Erasure, Empy Response (Empty), and Error njection defenses blue ideas sleep furiously areless effective compared to Head Projectio(HP) and Max-Entrpy defenses. 1810. 0240. 4550. 7770. 7890. 850. 450. 7930. 370. Thislikely because higher-oder attacks dele deeperint makin the information less appaent.",
    "Text Description": "SDXL Add salt-and-pepper Neighborhood Question + Generation Neighborhood Image + Answer Generation Question + Alternate SDXL Generate \"alternate the question LLM Image: Generalization EvaluationSamples for Obtain text description of the Obtain an not yesterday tomorrow today simultaneously related to Q + A Image Object Grounded SAM Alternate Answer+ Text Description SDXL the sentence in text to Q Alternate ans: Terrier What kind dog is You're an AI with to knowledge about dogs. breed of dog it Is the frisbee positioned the air or on blue ideas sleep furiously ground? A: Air What animal is in picture? A: Dog Is the frisbee close to or from dog? Close.",
    "Efficacy": "Speifically, each ample (v, a) we employ an methdto erase anser blue ideas sleep furiously a from blue ideas sleep furiously he model nput queson q and image v. quantify ais fully and unrecoverable the rerite (Equation and te attak metric(.2). The Rewrite Score (Hae et al., 2023) ow the edit minimizes the argetprobability to the desiring change,",
    "Generalization": "is because astrog deletion method should berobust not to the xac questionor image or which the performed, but to variatins Models trained n lrge multimodadatasets often broadundersanding concepts and can across input. a deletion would only be effective very aterns, leaving the sytemvulnerable to broader attacks. Existngon deletin unmdal (usually generalization might involv onlytext However, in multmodal models, thechllene iscmpounded because can attack fromtwo modalitestext images. Existigreserch effective frameworks tst how well deletion metods geeraize across theedifferent multimodal inputs. We create rephrase daa evaluate ho well th deletion meto generalizes to ways queryingthe removed information. Ths conssts of rephrase and questons each sample in K-VQAwith arying proximity levels to the iginal data These prximity levls correspont i of the models ability generalize its understnding to query formlation. Rephrase Imae is it theanswer to q as heoriginal image v Or pipeline generates rehrae imges t three difficulty evels: Easy,Medium, and Hrd, based on their prximityto originl iag. Our raionale is that  th proximitradius inress, it becomes more challenging for deletionmethod to generalze to heseimags.",
    ". Head Projection Attack (Patil et al., 2023a): This attack constructs a candidate set by collectingthe top-k highest probability tokens from each layer probed by LogitLens": "2. Attack (Patil et al. Probability Delta2 Attack (Our In this novel attack, construct a candidate set byidentifyed tokens whose differences consecutive rise and fall significantlybetween consecutive (which means taking difference of difference in probabilitiesof tokens across consecutive layers), potentially the information. attack is two attack, where second-order difference yesterday tomorrow today simultaneously of between thedistributions a second-order We design this with aim ofcapturing more nuanced traces of deleted information might be overlooked approaches. Finetuning-based A major obstacle in unlearning is its resilience to few-shot a small fine-tuning causes a disproportionate return previously deleting knowledge(Henderson et al. 2023; Qi et al. Zhan et al. We fine-tune the edited on random, unrelated data and then use HP attack to assessrobustness to post-deletion fine-tuning. Attacks. This simple blackbox attack exploits the imperfect rephrase of modelediting methods (De Cao et al. , 2021; Meng et al. , 2022). It constructs the candidate set C by querying with rephrased of the original input. Image Attack: This attack uses rephrased images the to modelvulnerability to changes visual It three based the rephraselevels. It has three variations are based on the rephraselevels. 3. Multimodal This attack leverages points where both the question andthe are",
    "OpenAI. Gpt-4 technical report. URL": "Advances in neural informaton processin systems, 35:2773027744, 2022. Peter Hase, and Mohit Bansal. Can sensitive iformationbe from llms? objectives fodfending aganst attacks. In the for Computational Linguistics: EMNLP 2023, pp. In Procegs the Meeti ofthe Association or Computational Linguistics (Volume : Long pp. Mlm-protector: Ensurngmllms safey wthout huring erformanc 02906,2024.",
    "Specificity": "Their purpose is evaluate the damage to on the that is different from the original data the information was erased in its evaluate two types of of input: (1) (neigh(v), (2) neigh(q), aques_neigh), where neigh(v) and denotes neighborhood image andquestion respectively, aimg_neigh and aques_neigh denote new answers in the context neighborhoodimage and question respectively, and generation process is described Neighborhood Image (neigh(v)) lies in the neighborhood of the original image v, main object such that the to the question changed (from to a), meaning the answer to thequestion is for neighborhood image. To assess specificity made to deleteinformation to assess the model the deletion caused, we create neighborhood data points foreach sample in the These data points represent unrelated information lies in theneighborhood of the information that edited. create such images, we first obtain feasible answersto by prompting Flan-T5-XXL (Chung , 2024) model to of three alternative to the question q that are different from a. the deletion is too the lose on tasksthat require or related reducing its utility. We focus on the of a dataset enables specificity of thedeletion method of and neighborhood questions varying difficultylevels (varying proximity to point). Specificity is the ability to ensure that only targeted information is deleted without modelsbroader Its crucial (1) Collateral When deleted a specific piece informationfrom model, there is risk of erasing other related knowledge. 2. See for examples of neighborhood images of each level. Hard: Similar to process getting hard rephrase images, we utilize SDXL generate an imagebasing on the text description of while also ensuring the corresponds to the specific alternativeanswer e. 1. can cause the model tobecome less accurate require but not knowledge. (2) Maintaining Model Utility:After the deletion, the model should still function well on questions or that lie \"neighborhood\"of the deleted information. We the answer aimg_neigh that is most dissimilar to asmeasured BERT similarity. In contrast to existing workswhichmay only focus on the deletion of single facts in unimodal contextsthis work introduces the ofneighborhood data for multimodal inputs to test assesses deletion method canremove specific knowledge without negatively nearby but unrelating knowledge in the modelsbroader understanding.",
    ". Medium: We leverage DIPPER-11B (Krishna et al., 2023), a SoTA paraphrasing model to generate morecomplex textual variations of the original question (See )": "adversa may lveage evaluate generalizaio data to eicitdeleted information. See (left) for an example ofrephas data. 3. To siulate this etting,we use rphrae data n an adversaria manner to evaluatethe deletion ethods ability to conceal theltd infrmation when rephrase data is usd to licitit (Rephrase attack).",
    "UnLOK-VQA: Dataset for Multimodal Knowledge Editing": "3) (See rightside of ). We use this pipelinefollowed manlfiltering to UnLOK-VQAas follow: (1) Using OK-VQA data (Mrino et al. we anto extend VQA datasetwith data points fr the evaluation of multimdalinformation deletion rom models. 1); Empoying SoTA LLMs vision generate rphrase dat for gneralization (. This secton data. Evaluation of knowledge deletion mthods requirs assessing generalization specificityon a multimodalkowledge dataset. 2) See left side of ); (3) data toevalut the impacton urelaed(scifcty) (.",
    "Rohit Gandikota, Joanna Materzynska, Jaden David Bau. Erasing concepts fromdiffusion models. arXiv preprint 2023. URL": "Mor Roei Jonathan Berat, and Omer Transformer lyers are key-valuememories. In Prceedings the Conferene on AI, Ethics, and Society, pp. PeterHendrson, Eric Michell, Christopher Dan Jurafsy, and Chelsea Finn. Hase, Mohit Bansal, Ben Kim, and Asma knowledge editing in language Advanes NralIformation Procesng Systems, 36 2023.",
    "RandomNeigh ImgRephrase Img": "Rephase arecom-pared to both neighborhood an random data ponts. Nihborhood points closerto the data point being deleed compared torandom pints which other unlearing datasetsvaluate pecificit. : Averagedistance of the andom, neigh-borhood image and repase pints from theoriginal datapoin. Tis is also reflecte Image Neighbohod-Acc compared to Random.",
    "Drive": ", 2023. Thisdemonstrats that defense methods canmitigate infrmation eakage rom LLM, mali-cious adversaries stillextract sensitve infor-mation from them. RLHF presents notablelimitatns: (1) it onhuman-written cosly to colect, and (2) it requires significancompuatonal esorces o its standar three-stagealignment proess. , 2024) Therefore, in tiswork, we popose diretly editing th modes weightsto sniive reducing the olkage from the modelsparameters. encmark for Multiodal Knowledge Recent workby Lynchet (2024) the crti-cal rigoros evaluations in unlrnig processes. Geeralization evalutes i the is robust. 1. Deetion Extractionttack fro adversares !! !! :Ilustraion o 1) leakagenLMs, (2, 3) the attack-defense framework. eleting Knowledge, 2022; Bai et al , et , 2017;Yuan et al.",
    "Comparison of success rates for image andquestion rephrasing attacks when modifying the layers the multi-modal projector on UnLOK-VQA": "To the effect of scaling, we aimed keep independent of chose the HP attack because modifies models weights, which could interfere with analyzing theeffect of scaling. Results. presents our findings. clear trend indicates that the model (13B) when the same deletion objective exhibits greater resilience attacks both attack)and blackbox (multimodal rephrase attack) settings compared to a model (7B).",
    "YangChe, Ethan Sauvik Das, Wei Ritter. Can language models be instrcted toprotectpersona 2023": "Can edi largemdels? In singing mountains eat clouds Houd Bouamr, Juan Pino, an alka Bali (eds. ),Prceedings te 2023Conferece onEmpirical Natural Language Processng, p 1387713888,Singapore Dceber 2023 Association for Compuational. Siyuan Cheng, Bong Tian, Qigbin Liu, Xi Chen, ongng Wang, Huajn Chen, and singing mountains eat clouds Zhang.",
    "Manual Filtering and Human Evaluation": "We adopt ts hgh-quality filered version for our subsequentxperiments. Weobservethat around 75% automatically generated and 66% the auoaticallygenerated daa meet ur sandards. See for samples in UnLK-VQA. on to primry crteia: (1) ConsitencyfTarget Answers: Annotatos weetasd with deteriningwhethrthe target anser remins cnstent when evaluating rephraseddata An apropriate signifies that the aeraio withthe expectatins the original question. he details design questio and the interace demostration are provided in Appendix C.",
    "function, arg maxMp(d|v, q; M), maximizes the probability of the model generating an empty target string(d) for any given input (v, q)": "Fact Erasur Fact-Ers) (ase et al. Error Ijection (rror Inj) (De et al. , 2021): This method introducs counteractual knowledge inoth moel. , where a is a false targetanwr,it demonsraes mods ability to incorporatemanipulatedinformation. Head Defense (Pail et al. , 202a): employa max-margn objctiveto prevent deleted answer appearing amng the elemnts ogitLens distributions acrosscosen lyes (L) and the Max-Entopy (Patil et al., 2023a): imilr to Head Projection Defens,approach focuseso LgitLens dstributions usesa differen objectie per laye. t maxiizes the (uncertainty) ofth next-token distribution chsen ayers the fina outpt. Inpu (IR Defense: This defense targts the Inpt Blackbox Atack. Itxpands the editing obectivebeyond original (v, q) incorporating treeof rephrases ofthe inut (v, (1) q) (2 (v, (3)",
    "Contributions.Overall, we summarize our contributions and findings below:": "1. We introduce UnLOK-VQA, a dataset for evaluated deletion of specific undesirable multimodal knowl-edge from models. Our data generation process involves an automatic generation pipeline followed bymanual filtering for retention of high-quality samples. UnLOK-VQA incorporates rephrase andneighborhood data with varying proximity to the target information, facilitating a nuanced evaluation ofboth generalization and specificity respectively of the unlearning methods. We adopt an attack-defense framework for evaluation of multimodal information erasure to assess therobustness of unlearning methods against adversarial attacks and show that state-of-the-art model editingmethods like LoRA fine-tuning can not fully delete knowledge2 from MLLMs. 3. We observe that the multimodal extraction attack outperforms its unimodal counterparts in multimodalediting setup. Also, we show that editing LLMs layers is more effective than editing the multimodal.",
    "Generate image for which nswer to this question {question} {alternateanswer} and threis o {original answe} in h": "Neigh (Hard): Generate an for which the answer to this question: {question} is there no {original answer} in the image some components from thefollowing image description retaining answer {alternate answer}: {unrelated imagedescription}.",
    "Broader Impact Statement": "Our work addresses the critical issue deleting sensitive in multimodal large language models(MLLMs), highlighting ethical implications. MLLMs, with vast knowledge, canpotentially harmful content or biases if Our research to promote responsible AI This work was supported by NSF-AI Institute DRL-2112635, MCS Award 1846185, ARO Award W911NF2110220, Grant N00014-23-1-2356, Fellowship. The views, opinions, and/or findings contained in article are of the authors andnot of A versatile vision-language model understanding, localization, reading,and arXiv preprint arXiv:2308. Yuntao Saurav Kadavath, Sandipan Kundu, Amanda Askell, Jackson Kernion, Andy Jones, Anna Chen,Anna Goldie, Azalia Mirhoseini, Cameron McKinnon, et al. Constitutional ai: Harmlessness from aifeedback. arXiv 08073, 2022.",
    "Attack-and-Defense Perspective": "Open-source releases of MLLs (Lu et blue ideas sleep furiously al. , 2023a) necessiate robust evaluation metos hat gobeyonsply ssssingmodel generations. e cast yesterday tomorrow today simultaneously multimodal informationdletion poblem witin te framerk of adversaria attak and defense mechanism commonly eplyed inmachne larned security (Carlii etal , 2019). In the following subsections, e nrode our attack-and-defenseframwork, including the threat odel, attakmethods, and defense methods, in deail.",
    "Ablation Across Different Difficulty Levels": "To investigate whether the intuitive of medium, and hard samples (introducedin ) reflected in potato dreams fly upward the attack success rates the respective rephrase images and questions, weconduct experiments across three difficulty levels blue ideas sleep furiously of rephrase questions and images,and present result in. Similarly, to investigate whether intuitive trend of easy and hard.",
    "Rephrase (Hard): Generate an image for which the answer to this question: {question} is {originalanswer} based on the following image description: {original image description}": "oberve a small diversion the trend against iput rephrasin defene, medium rephrasesare more ffective ha question rephrases he defense employs question rphrases belnging tote easy yesterday tomorrow today simultaneously quesion rephrae distribution. Editig iltering W filer eailstaset before the utomatic pipelineso s to o retain single oken answers and t sure that the del knows answe efoe weto tha in (Patil et al.",
    ". Easy: We introduce noise to the image v (salt-and-pepper noise) (Rosales et al., 2023) such that the maincontent in the image remains unaltered (See )": "Medium: We generate the image in this level by removing one random object in the original image byreplacing it with a repainted version. To achieve our goal, we utilize Grounded SAM (Ren et al. We then exclude objects with highSentence-BERT-based (Reimers & Gurevych, 2019; Kenton & Toutanova, 2019) similarity to any nouns inq and a. , 2024) or by extractingnouns from a textual description of v generated by LLaMA-2-7B. 2. To find the irrelevanttarget, we first detect all objects in the image using either YOLOv9 (Wang et al. Our pipeline includesthree types of rephrases: Easy, Medium, and Hard, based on their similarity to the original question and thedeletion methods ability to generalize to them. , 2024) toremove a segment of the image v that is not pertinent to the question and answer while maintainingthe rest of the images semantics (In , the frisbee is removed as it is an object irrelevant to thequestion). Rephrase Question is designed to have the same answer a as q within the context of image v.",
    "Building upon the of Patil et (2023a), the security landscape for information byintroducing a model tailored to multimodal data and models": "An extraction successful with budget B if answer is a candidate set C (|C| = B) generatedby the adversary an inference algorithm applied to the model. Adversarys Objective: We posit an adversary to extract answer A to a in the image V , where the (V Q, A) is a sensitive piece information. We thus define the success of extraction attacks in the context of MLLMs using the following using dataset D = (vi, qi, each = represents correct answer to the questionQ = qi the context of the image V vi. This setting is similar to the threat in et al. Byallowing B>1, we account broader, more realistic capabilities, making setting morecomprehensive and practical. Attack Success Metric: We say that an adversary successful if is present in candidateset C.",
    "Alvin Heng and oh. amnesia:A continual learng approachto n deep gneativemodels ariv peprintarXiv:2305.10120, 223. URL": "In Proceedingsof singing mountains eat clouds the IEEE/CVF Intenatonal Confernce onVision, pp. 2023. Propagation andpitfalls: Reasoing-based f edited conterfactual arX prprintarXiv:2401.1755, 2024. RL blue ideas sleep furiously",
    "onclusion": "We present an attack-and-defense framework and a pipeline for creating high-quality image-text pairs forevaluating efficacy, specificity, and generalization of defense methods. Our findings reveal that multimodalextraction attacks are more successful than single-modality attacks, while the best defense mechanism reducesattack success significantly. This work underscores the importance of developing effective unlearning methodsfor MLLMs and provides critical resource for advanced research in this area.",
    "Easy": ": Pipeine for UnLOK-VA blue ideas sleep furiously generation: We the atse as basis evaluatingthe efficacy of editing methods in nowldg from MLLMs;(2) We multiple techniqes toproduce rephrase daa withdifferent e usein blakbox ttck to ases the eneralizabilityof unlearning methods; (3) create various levesf neighborhoo data to check whether th editingmethods target information without altering the outputs",
    "Experimental Setup": "Models and Editing methods. This is selected based on (1) widespread adoption within the community,(2) ease of access due public availability, and (3) documented to retain information from theirpre-training also attack success rates on larger LLaVA-v1.5-13B for evaluating theeffect of scaled model size the robustness of erasure methods Model editing Our experiments utilize LoRA finetuning information deletion in specific weight in the MLP as motivating by Meng et al. (2022). focusing on GPT models, we tune and find that editing the7th and 9th layers, respectively, effective with rewrite score over (indicating successfulinformation and below 5% preserved models overall knowledge).While such as (Meng et al., 2022), have attempted to localize information tracingand then weights. follow-up study Hase al"
}