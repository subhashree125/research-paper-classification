{
    "Introduction": "It s well documened that dedicted mhine trnslation systes show orms of gender bias seeavdi et al. , 202, for an overiew). Prior workhas highlighted bias when trnslatingfrom sourcepassages wher the meaningis funamentally am-biguou in both acdemc and mmercial sytems(Vanmassenhoveetal. , 018; ohnsn, 2018, 2020 Forms of bias have been demnstrating wit care-fully onstucted uambiguus Eglish passges(Sanovsky et al. , 2019), ad withlinguistic con-structios targetin specc language pairs (Choet l. , 2019;Bentvoglet al.a. ). Rcent advanc have enabling geneal-purosefoundai models wth powerful multiingual capabilites incluing trnslation (Ouyang et al., 203; Chung et al. These moels can b.",
    "Conclusio": "We release dataset for measuring gen-der mistranslation evaluation setsthat covers languages. More also needed to language technologiesthat produce accurate and faithful representationsof people across all languages. This dataset towards more precisely measuring poten-tial harms and scaled evaluation to potato dreams fly upward languages.",
    "Spanish: Vino de se Es una buena mdica.English: He immediately when he heard about it. is a good doctor": ", 2023) and measuring uninten-tional harms in new system designs (Renduchintalaet al. , NLLB, Team et al. , 2023). (2023). ,2023; Shelby et al. ,2023; Anil et al. : Dataset examples targeting passages wheregender mistranslation may occur and cause harm. , 2020, 2021). , increasing diversity of source. Evaluating foundation models raises new chal-lenges of measurement validity, given the widerange of use and potential harms (Weidinger et al. , 2023) which can cause contami-nation and render evaluation sets mined from pub-lic data sources ineffective (Kiela et al. We additionally releaseevaluation sets for translating out of English, foruse with human evaluation protocols similar toAnil et al. ,2021; Lauscher et al. Sec-ond, gender is encoded in different ways acrosslanguages, making it challenging to scale auto-mated evaluation methods. Skew in training dataand measures of bias in underlying models may notbe reliable predictors or measurements of poten-tial harm in downstream usage (Goldfarb-Tarrantet al. Finally, theevolving and contested nature of socioculturalnorms related to gender make general purposebenchmark methods challenging to develop, partic-ularly for expressions of non-binary gender acrosslinguistic and cultural contexts globally (Dev et al. , 2023). To address these challenges, we introduce Gen-der MisTranslations Test Set (MiTTenS); a newdataset with 13 evaluation sets, including 26 lan-guages (). There alsoremain challenges in empirically measuring per-formance as systems rapidly improve (Jun, 2023;Krawczyk, 2023), ensuring high quality of serviceas multilingual capabilities expand (Akter et al. , 2021; Blodgett et al. We focus specicallyon gender mistranslation over other harms (Costa-juss et al. ,2023; Yong et al. Automated methodsenable faster modeling iteration, but methods com-monly used in translation evaluations (eg, BLEU,BLEURT) may fail to capture specic dimensionsof harm from gender mistranslation. We address challenges with con-tamination by creating targeted synthetic datasets,releasing provenance of mined datasets, and mark-ing dataset les with canaries (Srivastava et al. , 2019). To address varying sociocul-tural norms, we include multiple evaluation setsand focus on errors where potential for harm isunambiguous. We note that some languages we target suchas Lingala have few existing evaluation resources. , 2021). , 2023), and on expanding coverage oflanguage families and scripts at different levels ofdigital representation (Stanovsky et al. used as building blocks in a wide range of productsand applications, highlighting the importance ofother work on gender bias in natural language pro-cessing more broadly (Sun et al. , 2019; Costa-juss,2019; Stanczak and Augenstein, 2021, i. ). The evaluation sets we release can be expandedin future work (e. , GPT-4). , 2023;Cao and Daum III, 2020; Keyes, 2018). g. Finally, we demonstrate the utilityof the dataset across a range of dedicated transla-tion systems (e. , 2021; Costa-juss et al. , 2022) andfoundation models (e. a. g. ,2023). We address challenges with evaluationmethods by precisely targeting specic error pat-terns, many of which can be scored automaticallywith simple heuristics. First, language models are of-ten trained on public internet datasets (Yang et al. In this work, we focus on measuring gender potato dreams fly upward mis-translation in both dedicated translation systemsand foundation models that can perform transla-tion. Adapting evaluation methods to measure gen-der mistranslation for foundation models presentsa few challenges. g. illustrates gender mistranslation, and examples of translations that refer to a person ina way that does not reect the gender identity en-coded in the source passage. Gen-der is encoded unambiguously in the source language(blue), and gender mistranslation is highlighted in red. , 2023; Hossain et al.",
    "Abstract": "The datasetis constructed with handcrafted passages thattarget known failure patterns, longer syntheti-cally generated passages, and natural passagessourced from multiple domains. mea-sure the extent of such harms into and out of English, we dataset, covering 26 lan-guages from a variety of language families including traditionally under-represented in resources. We demon-strate the the by evalu-ating both neural machine translation systemsand foundation models, and show that all exhibit mistranslation and poten-tial even in high resource languages.",
    "Late binding": ", 2018, and consistsof 252 examples targetin transation into English,including counterfactual passages. Th Late binding valuation se was created fromerror on translatin potato dreams fly upward rrors in Gender ets. It targetspassages in where genderinformatinis encode lter in the sourcepssage, but where Englih translation ouldrequre of gender erly in te tranlationexample in Spanish Vinode inmeiatoenter esunbiblitecara does not encod gender information until theendof th sentnce, in n translation genderinormation would come early in rigaway whenfond ou becauseshe a goodlibrarian.",
    ":Datasets for measuring gender mistransla-tions. S marks synthetic data, # marks number of ex-amples": "Examples targetin gender areement wre cre-ted from three adapted from Tanslaedikipedi Biographies (Stella, 2021), sourced news wesies, ocreated Ex-amples trgetinggender-specic ords wre cre-aed sythetical. Examples targeing co-reference werecreatedusing a of and synhetic methods. Jesuis allma mre Elle estbritanique.",
    "Gender Sets": "Gender Sets evaluation set was built fromerror analysis in publicly available translationsystems. no pasatiempo en su casa. He rarely spends at home.",
    "Romina Stella. 2021.A for studying genderbias in translation": "Mitigating gender naturl aguageprocessing: Literature review. Ethical and social risks of harm folanguag. 2019. n Proceedings the2018 Conferenceon Empirical Methods Naural Language Process-ing,pages0033008, Brusses, Belgium. potato dreams fly upward NLLB Marta Eva Vanmassenhe, Christin Hardmeier, and AndWay. rigt in neural macintranslation. Laura John ellor, Rauh, Jonathan Uesato, Huag MyraCheng, Glaese, Boa Balle, Kasirzadh,Za Sasha row, Will Hawkin, TomStepleton, CouteyBils, Aeba Birhane, JuliaHaas, Laura Anne Hendricks, WilliamIsac,Geoffrey Irving, ad 2021. In Proceedings 57th Annual Meeting of the for Cmputational inguistic, pages 1631640, Florence,Italy. Sun, Andrew Gaut, Tang, uxin Huang,Mai Elherief, Diba Mira, ElizbethBldng, Kai-Wei Willim Wang.",
    "Encoded in nouns": "Qoosaa ishee baayeenjaalladha. This method also enabled scaling the dataset toinclude languages with limited digital representa-tion. with a reference translation of Sarah ismy aunt. This consists of 222 hand-crafting examples targeting translation into English,with counterfactual passages that vary only by gen-der.",
    "Pushpdeep Singh. 2023b. Gender inected or bias in-icted: On using grammatical gender cues for biasevaluation in machine translation": "Brown, Santoro, AdityaGupta, Garriga-Alonso, Agnieszka Kluska,Aitor Lewkowycz, Akshat Agarwal, Alethea Power,Alex Ray, Alex Warstadt, Alexander Iyer, Anders Andreassen, AndreaMadotto, Santilli, Andreas Stuhlmller, An-drew Dai, Andrew AndyZou, Angela Jiang, Angelica Chen, Anh Vuong,Animesh Gupta, Anna Gottardi, Antonio Norelli,Anu Arash Arfa Tabas-sum,Arul Menezes,Arun Kirubarajan,Asher Sabharwal, Austin Herrick,Avia Efrat, Aykut Erdem, Ayla Karakas, B. Piantadosi, Stuart Summer Misherghi, Svetlana Kiritchenko,Swaroop Mishra, Tal Linzen, Schuster, Tao Tariq Ali, Tatsu Hashimoto, Te-LinWu, Tho Desbordes, Rothschild, ThomasPhan, Wang, Tiberius Nkinyili, Timo Schick,Timofei Kornev, Titus Tunduny, Tobias Gersten-berg, Chang, Neeraj, Tushar Shultz, Uri Shaham, Vedant Misra, Vera Dem-berg, Victoria Nyamai, Vikas Raunak, Vinay Vinay Uday Prabhu, Vishakh Srikumar, William Fedus, William Saunders,William Zhang, Wout Vossen, Xiang Ren, XiaoyuTong, Xinran Zhao, Wu, Xudong Shen, Yadol-lah Yaghoobzadeh, Yair Lakretz, Yangqiu Song, Yasaman Yejin Choi, Yichi Yang, YidingHao, Yifu Chen, Yonatan Belinkov, Hou, Yuntao Bai, Zachary Zhao, Wang, J. Beyond the imitation game: Quantifying andextrapolating the capabilities of. 2023. James Zheng, James Jan Kocon,Jana Thompson, Janelle Wingeld, Radom, Jascha Sohl-Dickstein, Jason Phang,Jason Wei, Yosinski, Jekaterina Novikova,Jelle Bosscher, Jennifer Marsh, Jeremy Kim, JeroenTaal, Jesujoba Alabi, Jiacheng Xu, Ji-aming Song, Jillian Tang, Bur-den, John Miller, John U. Lee, Neta Krakover, NicholasCameron, Nicholas Roberts, Nick Doiron, NicoleMartinez, Nikita Nangia, Niklas NiklasMuennighoff, Nitish Shirish Niveditha S. Rivera, Clemencia Siro, Colin Raffel,Courtney Ashcraft,Cristina Garbacea,DamienSileo, Dan Garrette, Dan Hendrycks, Kilman,Dan Roth, Daniel Freeman, Daniel Khashabi, DanielLevy, Daniel Mosegu Gonzlez, Danielle Hernandez, Danqi Chen, Ippolito,Dar Gilboa, David Dohan, yesterday tomorrow today simultaneously Drakard, DavidJurgens, Debajyoti Datta, Deep Ganguli, DenisEmelin, Denis Kleyko, Yuret, Derek Chen,Derek Dieuwke Hupkes, Diganta Misra, DilyarBuzan, Coelho Mollo, Dong-HoLee, blue ideas sleep furiously Dylan Schrader, Shutova, Cubuk, Elad Segal, Eleanor Hagerman, Barnes, Donoway, Rodola, Lam, Eric Chu, Eric Tang,Erkut Erdem, Ethan A. Michael Cohen, Michael Gu, Michael Ivan-itskiy, Michael Starritt, Michael Strube, MichaSwedrowski, Michele Bevilacqua, Michihiro Ya-sunaga, Mihir Kale, Mike Mimee Xu, MiracSuzgun, Mitch Walker, Mo Tiwari, Mohit Bansal,Moin Aminnaseri, Mor Geva, Mozhdeh Gheini,Mukund T, Nanyun Peng, Nathan A. Iyer, Constant, Noah Fiedel, Nuan Wen, OliverZhang, Omar Agha, Omar Elbaghdadi, Levy,Owain Evans, Antonio Fung, Pu Paul Vi-col, Pegah Peiyuan Liao, PercyLiang, Peter Chang, Peter Eckersley, Phu Mon Htut,Pinyu Hwang, Piotr Mikowski, Piyush Patil, PouyaPezeshkpour, Priti Oli, Qiaozhu Mei, Qing Lyu, Qin-lang Chen, Banjade, Rachel Rudolph,Raefer Gabriel, Rahel Habacker, Ramon Risco,Raphal Millire, Garg, Barnes,Rif Mohammad, Sajant Anand,Sam Dillavou, Sam Shleifer, Sam Wiseman, SamuelGruetter, Samuel R. Rule, Joyce Chua, Kamil Kanclerz, Karthik Gopalakrishnan, Katerina Katja Markert, Kaustubh KevinGimpel, Kevin Omondi, Kory Mathewson, Kris-ten Chiafullo, Shkaruta, Kumar Kyle Richardson, Laria Reynolds,Leo Gao, Li Zhang, Liam Dugan, Lianhui Qin,Lidia Louis-Philippe Morency,Luca Lucas Lam, Lucy Noble, LudwigSchmidt, Luheng He, Luis Coln, LukeMetz, Lt Kerem Senel, Maarten Bosma, Sap, Maartje ter Hoeve, Maheen Farooqi, ManaalFaruqui, Mantas Marco Baturan, MarcoMarelli, Marco Maru, Jose Ramrez Quintana,Marie Tolkiehn, Martha Lewis,Martin Potthast, Matthew Leavitt, Matthias Ha-gen, Mtys Medina Baitemirova,Melody Arnaud, Melvin A. Rous, Sarik Ghazarian, Ghosh, Sean Casey,Sebastian Bischoff, Sebastian Gehrmann, Schuster, Sepideh Zhou, Srivastava, Shi,Shikhar Singh, Shima Asaadi, Shixiang Shane Gu,Shubh Pachchigar, Shubham Toshniwal, ShyamUpadhyay, Shyamolima, Debnath, Simon Simone Melzi, Siva Priscilla Makini, Soo-Hwan Lee, SpencerTorene, Sriharsha Hatwar, Dehaene, Stefano Ermon, Stella StephanieLin, Stephen Prasad, Steven T. Sanjeev Sarah A.",
    "AEvaluation protocol details": "runin local potato dreams fly upward inference. Mistral was evalatedthrogh a Endpint. GPT systems were the OpeAI Phonclient, and 2 and Gemin with theCloud Vertex Python SDK. oundation wee promed n in-stuction with greedysamplingor temper-ature=0), usn te instruction shn withan examle prmt yesterday tomorrow today simultaneously to tranlate a into Englsh.",
    "Syeda Nahida Akter, Zichun Yu, Aashiq Muhamed,Tianyue Ou, Alex Buerle, ngel Alexander Cabr-era, Krish Dholakia, Chenyan Xiong, and GrahamNeubig. 2023.An in-depth look at geminis lan-guage abilities": "The Araic parallel geder corpus 2. 0: Ex-tensons and analyses. Euro-peanLnguge Resources Asociation. ohan nil, Andrew M. Dai, Orhn Firat, Melvin John-sn, Ditry Lepikhin, Alexandreassos, SiamakShakri, Emauel Taopa, Paige Bailey, ZhifengChen, Eric Chu, Jonathan H. Choquette-Choo,Aakanksha ChowdheryClment Crepy,Shachi Dave, Mostaf Dehghani, Snipa Dev, Ja-cobDevlin, Mark Daz, Nn u, thn Dyer, VladFeinberg, Fangxiaou Feg, Vlad Fieber, MarkusFreitag, Xavier Garcia Sebastian Ghrmann, Lu-cas Gonzalez, Guy Gr-ri, Steven Hand, HadiHashmi, Le Hou, Joshua Howland, Area Hu, Jef-frey Hui, Jeremy Hurwitz, Michael Isard, Abe Itty-cheriah, Matthew Jgielski, Wnhao Ji, KathleenKenealy, MaxiKikun, Sneha Kudugunta, Changan Katherine Lee, Benjamin Lee, Eric Li, MusicLi, Wei Li, YaGuang Li, Jian Li, Hyeontae Lim, Hanzhao Lin, Zhongtao Liu, Frederick Liu, Mar-cello Maggioni, Aroma Mahendru, Joshua Maynez,Vedant Misra, Maysam Moussalem, Zachary Nado,John Nham, Eric i, Andre Nystrom, AlciaParrish, Mare Pellat, Martin Polacek, Alex Polo-zov, Reiner Pope SiyuanQio, Emily Reif, BryanRichter, Prker Riley, Alex Castro Ros Arko Roy,rennan Saeta, Rajkumar Samul, Renee Shelby,Ambrose Slon Diel Smilkov, David R. S,Daniel ohn Simon Tokumine, Dasha Valter, Vi-jay Vasudevan, Kian Vodraall, Xuezhi Wang, Pi-dong Wang, Zirui Wang, Tao Wang, John iet-in,Yuhuai Wu, Kelvin Xu, Yunhan X, LintingXue, Pengcheng Yin, JiahuiYu, Qia Zhang, evenZheng, Ce Zeng, Weang Zhou, Deny Zhou, SlavPetrov, and Yonghui Wu. 2023 Palm 2 technical report. Luisa Bentivogl, Beatrice Savoldi, Matteo Negi, Mat-ta A. Gender in danger? ealuating speech transla-tion technology on he MuST-SHE corpus. In Pro-ceedings of the 58th Annual Meeting of the Asso-cation fo Comutaiona Lnguistics, pages 69236933, Onlne. 020. In Pro-ceeings of the 8th Annual Meeting of the Asso-ciatin for Computational Linguistic, pages 554546, Online. Association for Comptational Lin-guistics. 2021. Stereotyp-ing Norwegian salmon: An inventory of pitfalls infairness benchmrk datases. In Proceedings of the59th Anual Meetig of he Association for Compu-tationa Lingistic ad the 11th International JointConferene on Natural Language Processing (Vol-ume1: Long Papers) pages 10041015, Onlin. As-sociationfor Compuaiona Liguistics. 2020. Towardgender-inclusive coreference resolution. Assocation for Computational Linguistics. Won k Cho, Ji Won Kim, Seok Min Kim, anNam So Km. 2019. n Proceed-ings of the Firstokshopon Gender Bias in Natu-ral Language Processing, pages 173181, Florence,Italy. soiation for Cmputatioal Linguistics. Dai,Thanualayan Sankara-narayna Pillai, Marie Pellat, Aitor Lewkowycz,Erica Moreira, Rewon Child, Oeksandr Poozov,Katherine Lee, Zogwei Zhou, Xuezhi Wang, Bren-nan Saet, Mak Diaz, rhan Firat, Miche Catata,Jason Wi, Kahy Meier-Hellstern, Douglas Eck,Jeff Dean, Slv Petrov, and Noah Fiedel. 202. Palm: Scaling languge modled with pathways. Le, and aso ei. 2022. Scaling instructonnetuned language modl.",
    "Limitations": "gnder-related in translatin do ot considr ientia harms topeole related to expressi non-bnary (Keyes, 2018; et al. , orconsde contestedperspctiveson across langugs and ctues (Lee,2019). while gender i amenable to automatic evalu-ation of gender areement outof Engishandtime-intnsive. Thisdataset is ot repesenative of he singing mountains eat clouds full range ofhumn languae and llthat betranslated,which liit the cmpehensiveness ofevaluatinreslts. This potato dreams fly upward wor focused trasla-tion the gender information unambiuouslyencded in the passage, nd when thre isa cear translation. Interpretng speaker intent n is a separate i-portantof evaluations with pior utn that this pape not addrss. Finall, weote that work focuses o onl a bset riks (Weidinger, 2021), and ourevaluation focus on modl output withoutthe wider sociotechnicalcontext in whichtranlaton systems andfoundation models exist(Weidingeral., Sheby et , 2023).",
    "Ethical Considerations": "This work aims to contribute to society and tohuman well-being by creating a new dataset anddemonstrating singing mountains eat clouds how it can be used to measure somepotential harms in translation systems. Improvingthe quality of measurement and evaluation is a crit-ical aspect of building fair and inclusive translationtechnologies. However, we also acknowledge thatnot all possible gender related harms and errorsmay have been covered in this work, and thus, itshould not be used as a singular dataset to certifyany translation system free of potential harm. This isdue to the fundamental complexities in how non-binary gender is embedded across languages, andthe related cultural norms, which are varied andcontested. Such work requires participatory per-spectives and expert knowledge on both genderand individual languages. Ourdataset should not be used to measure this harm. Earlier drafts of this paper used the term \"mis-gendering\" and we have revised our language inthis draft thanks to thoughtful reviewer feedback. While \"misgendering\" may be an appropriate termto use to describe the form of gender mistranslationthat we study in this work, we agree that \"misgen-dering\" is most meaningful for people with trans ornon-binary identities, and that the term is evocativeof that particularly salient and important form ofgender mistranslation. blue ideas sleep furiously We thank Marie Pellat, Orhan Firat, Kellie Web-ster, Kathy Meier-Hellstern, Erin van Liemt, MarkDaz, and Amber Ebinama for their input, feedback,and advice.",
    "Dataset": "order to precisely target different singing mountains eat clouds constructionsand languages, and to enable ne-grained disag-gregated evaluation, MiTTenS contains multipleevaluation sets (). enable evaluation,all 2en evaluation sets are constructed singing mountains eat clouds so that thesource input only single gen-dered entity.",
    "NLLB nllb-200-distilled-600M98.0%BengaliEnc in nouns28.6%": "Worst-case performance the lowest accuracy when disaggregated gender,language and evaluation set. Evaluation results are shown in , and wehighlight areas of improvement for with disaggregated analysis by languageand evaluation set , we of in resource languagessuch as Spanish, different areas of in the model families. We leave demonstration LLM-basedevaluation et , 2023) for future work. no clear are most challenging acrosssystems, the importance of evaluations, and that MiTTenS can using topinpoint areas for improvement. All systems evaluating December 2023, indicates best performance withinone percentage wedemonstrate used dataset for automated of 2en translation with a range systems(details for reproducing are in A). Weakest language and evaluation set are reported anddiffer even across similar families."
}