{
    "n2(1 + ) 2n,(2)": "This arametrizaton of the PP moelreducs to the ER moel for =1,andthe (expected gobal lustering coffcient icreses monotonoulywih. This continuous type space can. so that te exected number of edges equals m, while pn/pout =. ncittinetworks, fo example, papers tend to cite pers onrelatedtopics. Latnt geometryCommunity strctureexpains clustering by asmin a certain (fiite) set of types,ndthat nodes of the same typehave a higherliihoodof onnctig thn nodesof different types.",
    "Introduction": "Many objects can be represented as graphs: social and citation networks, the Internet,transportation networks, and so on. For a number of practical problems, it is important to measure similarityor between g. , 2021). Graph kernels are based some degrees, path lengths, subgraph and so Thus, kernels capturedifferent graph properties. However, is not obvious which properties are captured by a given kernel. important application graph kernels is the performance of generative , 2022; et al. , 2022).",
    "There two main mechanisms are used explain and model clustering: community structure andlatent geometry. In we treat two different graph characteristics": "structureMany real-orld networs contin groups of osthat e desely con-nected toother thn the of tenetwork. te presence of comunity structure explain clustered tt is obsrv in networks: he presenceof densely connected groups lead anincreasedumber fo structure is the Panted Patitio (P) model (Holland et al. ,1983), we are give ao networ nodes int communitis, node pairs of he amecommunity probability pin, while nde pairsof different with probabilitypot. We consider to commuies of n/2 each, we parameterize pin, pt as.",
    ": NetLSD-wave traces for Dimensionality": "GIN representationswere proposed in et the of evaluatinggraph models. potato dreams fly upward (2022) use GIN compute measures precision, recall, or FrchetDistance. Second, Thompson et al. 6. One can see the trace for = 0 is indeing closerto = 1. Our results show that when. Instead, we use RandGIN to construct a kernel that can be using with the MMD framework:we this to compare kernels and representations in the unified setup. 0 than 0. our framework allows one detect suchpeculiar of graph representations.",
    "Conclusion": "For thi, we careflly deign n expermental setup bsedon intrplations etween rando graph generators differing in a particuar stuctural property. The results of our xeriments confirm the main points of our pap. First, it is imptant to consider grakernelseyond those sually considered for evaluating the performance of graph generative yesterday tomorrow today simultaneously odels.",
    "deg(u) be the degree of u": "subtree kernelwas proposed in Shervashidze et al. (2011) and based WL color refinement procedure. The procedure when it converges. This procedure works blue ideas sleep furiously follows.",
    "CL model is equivalent to the ER model. The values > 0.5 give weight distributions with infinite variance,which leads to a high variance in the degree distribution": "2. Latent geometry (ERTorus)For this transition, of ER graph and RG torusgraph: we a graph each generator and denote their adjacency matrices by A(ER) and We construct the adjacency matrix as potato dreams fly upward follows: for each node pair with 1 i < n we draw anindependent Bernoulli variable Bij with success probability and set Aij = A(ER)ij+ Bij(A(RG)ij. use the PP model with singed mountains eat clouds as given in equation for = 1 m),where m) is constant so that = 0 leads to pin = pout = p, while = 1 leads to every (in one neighbor outside its community.",
    "Published in Transactions on Machine Learning Research (12/2024)": "In cetin applications, geometry can be especially relevant,e. The results shown in can be useful hen deciding which graph kernel is most suitable when evaluainggenerative models in a particular aplicaton. In this case, our analysis showshat using the W ernlis not a god optio. some wellknown kernels that show goo performance in our experiments av been previousl overlooking blue ideas sleep furiously inthe literature on thissubject. Second, we oberve that the wide diersity ofthe considered structual proerties is critica for a thoroughevaluatio: it isoften case that a pticular grh ernel is sensitve to some charatersticswhile beinginsensitive to others. Exampes of such kernels incude Shortes Pat and Pyramid Match krnels. Le us als note that kernels withdifferent propertes canpotentially be combined with each other by, e. g. g. However,a detailing naysis of sch combinations s beyond thescopeof the curret paper.",
    "|Gi|": "Thus MMD iinded there re oter to compare distributions: Frche Distane (Heusel et al., Precision & Recall (Knknniemi et al., 2019), Density & Coverage Naeem t l., Overal,thereare man ways to two distribtions gras. The wok OBra et al. The autho consider wihout nodefeatures label and compare sveral tpiclly use MMD-basd mures",
    "Results and discussion": "The results are shn in and th respective computationtimes are eporting in Appendix B We seethat most kernels eform well onsome of thinterpolatios whe efoming badlyon other. This sowsthe importce f usin different interpolatis or assessingthesensitivity of kernels.",
    "Density use the model with the edge probability p( + Thus, when from0 to the edge increases from p to 2p": "Heterogeneity (ERC)We the Chung-u (CL) mdel with weights drawn rom Paretodistri-ution with powe-law expnent 1 + scale such the expected number of eges eqls m. Note 0 leds to a power-law expnenti the weights are onstant and the corresonding.",
    "Kernels for evaluating graph generative models": "o evaluate a generative on needs set of produced blue ideas sleep furiously by he model withsoe reference of availabe to the odel durin Tyially, thecomparison conistsof two steps.",
    "A.1Random geometric models": "a two-dimensional torus width 1 height we find radius r that leads to edges inexpectation. Two nodes are connected when their is than r, i.e., whenever the second nodeis inside circle with r around singing mountains eat clouds the first node. h 2r, then the of this simplyr2, while the total area of the torus is h. Therefore, expected edge is r2. Solvingn2",
    "Abstract": "Thiscan be done One particular application where the choice of kerneli assessing the qualiy of graph generative mods. However, despite vastnuber graph vailable in the literature, only basic usualy In tis paper, we this gap and how diferentgraph kernels erform as an ingredien in the pipeline of gnerativepeformancevaluation. To conduct a detailed anlysisw propose a framwork fr comparing grapkernels in terms of hich high-level structural they are esitive to: heterogneitof degree ditributin, of of latnt geometry,ad others. For this, we design continuous tansitionsetween thataffect a paticlar propert whch graph krnel is sensitive the corepondingchange. We lsofound soe well-known kernels that shw good perfomance in our experiments buthavebeen overlooked the iterature on evaluting models.",
    ": The distribution of shortest path lengths for different graph -1 corresponds discon-nected node pairs": "shows the path distribution different graph generators. It can be clearly seen that allmodels are distinguishable. In particular, we see that kernel is sensitive to dimensionality: the Circleresults in much path lengths than the Torus. The Graphlet good in of the overall performance: is thebest-performing kernels interpolations but the difference with the SP kernelis noticeable. g. , its diameter). the the transition: it turnsout that small values of (when the h is not too small), the distribution of graphlets does notchange much, and thus MMD values are close to up = 0. We also see that increasing thekernel from to 4 improves the for since this change makesthe considered For all other interpolations, graphlet sizes does not lead tonoticeable Neighborhood Pairwise Distance previously used in analysisby Thompson et al. contrast, ouranalysis with diverse shows certain shortcomings this kernel. In particular, turnsout to be to community and density. interpolations that are hard to detect forthis kernel are dimensionality and complementarity. Unfortunately, this graph invariant also kernelharder to theoretically analyze or intuitively explain.",
    "RandGIN0.9380.9470.1320.5270.0670.285": "As expected, thi kernel ca perfectly etectthetransformations of densityand heterogeneity sinc they directly affet the degree disribution. (2022). The Degee histogram knelis addd to our aalyis as it is simiar to degree kern usedinprevious studie OBray et al. wever, in our experiment, we observe tht they only erform well on nterpolations tha are weldtected bythe egre histogram kernel. Indeed,L WL-OA ae the bst kernels for heterogeneity,which is xpected s the first step of the WL procedure is based on node degres. However,the degree histgrm kernl isnot senitive to all oter transformatios. Incontrast, for commnities, geometry, dimenionality, and om-plementarity the iference in erformance between different kernels s large: some kernels have correlatonslarger tan 0. (202); Thompson et al. In contrast, for all the remainin interpolations, the Spearmancorrelaio officentis quie smal. However, it is worth oting tha bot WL and WL-O dominte thedgre hstogram kernel for all terpolation since they ae based on more dvanced graphstaistics that beyd immediate neighbors. Finally, while ost kernels perfr wll on the density ransition,tis tuns out to be chalnged for NSPDK. Based on these results, we can sume that WL-basing kernel are mostlysensitive to the degree distributions. e nte that sme transiton are easi to detect by all the kernes: fr heterogenity, allkernls howelately ood andstabl perormance. The Weisfiler-Leman kernean relted WL-OA ernel are considered to be owerfu graphkernels.",
    "A(ER)ij). Hence, = 0 leads to A = A(ER), while = 1 leads to A = A(RG). We complete the adjacencymatrix symmetrically: Aij = Aji for i > j and Aii = 0": "potato dreams fly upward This way, = 0ledsto a torus on [, 1)2 while yesterday tomorrow today simultaneously h 0 leas to one-dimensional tous (a crcle).",
    "i wi independently of all other edges. sample the": "Tis phenomnon is often referredto asclustering (Holand & eihardt, Peixoto, and results in an of riangles, whihisoften uantifid by custerng coefficient. eorks and mny othergrahs ae ll-knonfor degree clustering (Holland & Leinhardt, , 2001).",
    "To make the computation of this kernel feasible, graph invariants can be employed to encode each rootedsubgraph. Then, these invariants can be compared instead of graph isomorphism checking": "formally, let be the j-th smallest gnvalue of normalized Laplacian o a grp G. NetStreats graph a a dynamcal and simulates heat wave diffusion potato dreams fly upward prcesses on nodesand edges of blue ideas sleep furiously a given graph,by system conditions at fixing (Tsitsulin et ,2018).",
    "Interpolating graph characteristics": "Forthe geometic mol latent geometry omplementaity,we take a different proach potato dreams fly upward tointerpolte between gnrators. We each these a stp parameter , = 0 to left genrator, while = 1leads to thrightgenerator. We mak us efac yesterday tomorrow today simultaneously mostof the genating models In these caes,we simply parameterize a tansition away from The model iscsen wih p = m/n2so that the expected number edgsequals m. Foreach graph characteristic, we define ntepolation ewentwo graph geerator, so hat the strenthof that caracteristic changesmonotonously alog the tranition.",
    "Measuring the sensitivity of a kernel": "the interpolation as the Spearman correlation between MMD(G, K) nd. We now hw quantify the sensitivit of a w. Fr ,let Gdenote a set g raphs sampld independently interpolationgenrtor at step. urthermore,le MMD(G1, G2; deote thevalue between and 2 r. We a dscretization of theintepolation such that {0, 1}. r. this potato dreams fly upward valuei cloeto , it means tha th blue ideas sleep furiously MMD alues tend to increase whe tasitioni way fom. t.",
    "Limitations": "Als, for clustering we two diferen t it, ths reducing pssible bias rom apartiular limitaton f our is thatwe cosider wthout attributes. Additionally,we that not all yesterday tomorrow today simultaneously kernls instance, grphlet kerel hasa prohibitively igh compuational cost on large networks. or stdy reltively small raphs. Theoretcal analysis spprted the btained conclusions blue ideas sleep furiously be Howeer, fo an analysis would be trivial , the degreeis clearlto shfts in the degreedistribution, but ot sensitive to shiftsin other caracteristics that the degree distrbuion O other hand, or most of such an analyis seems inractable due to their complex stucturs. t is imrtant tokee in that it can be chalening evnipossie) chage one keeping all properties fxed. Fo example, molecularmodeling, the consis of relatvely smll atoms. Other applicatns where small graphsre relevantnclude ego ntworks in sociology. Weonsider graphsso that we can include all popular graph kerels in our we note tht work is an empirical tudy of ensitvity raph to some structuralshifts. While we attempt o isolte the charactristicit is some other araffecting to some extent. is that evaluting graphgenertiv models used graph kernel is ypically pplid to such sallnetworks.",
    "Various approaches can be used to measure similarity or dissimilarity between graphs. Two major researchdirections are concentrated on graph distances and graph kernels": "Indeed, if we tha D(G, G) = 0 and only if G and G are isomorphic,then computig such is at least blue ideas sleep furiously as hard as ioorphism tesing, which s infeasible for mostapplications. Graph measure graphs ar o satify he etric axioms. (2020); Niklentzos et al.",
    "Comparing WL we note that the latter dominates for all considered transformations. Thisconfirms the of node matching improves the sensitivity of kernel": "Nabl, SP thebet fordmensonality, which is arguably the mot trnsiion. ca be the that shot-est path lengths capture both local f e graps, aking tis kernel sesiietonon-trivial transitions. The Shortest kernelhas quie stable performance. 9 (in fact it is only kerl with this prperty), eventhe most ifficult transitions geometry, dimensionality complemntarity.",
    ": Scatter plots of MMD values the Graphlet-3 kernel for the toruscircle interpolation": "Let us also nte that PMs dominating by Graphet-4 foreah interpolation. On almost all the transiions,NetLS-wave utperfomsNetSDheat.We lutrate difference between NetSD-heat andNetLSD-wave for this ransiinin , here each cell shows the MMD value for two samles o grahs: corresonding to steps 1 and2. This isind th case fr NetLSD-heat, btsurprisingl nt the case for NetLSD-wave. 0. 0. 5."
}