{
    "MIRAGE CAL (Ours)500 AA calibration ex.82.282.592.087.790.286.9 / 4.0MIRAGE EX (Ours)79.074.190.882.686.982.7 / 5.8": ": % of MIRAGE an entalment-based baselines human AA onthefull XOR-AttriAusing CRAfo RAG (annotated answrs not matchigLMs natural generation force-decoded). PALM and mT5 rults artaken Muleret a.",
    "RAGE applicability in real-world settings": "819455). 2020. In the 58th Annual Meeting of Association forComputational Linguistics,",
    "Harrison Chase. 2022. LangChain": "Thanumalayan Pil-lai,Marie Pella, Aitor Lewkowycz,Erica Moreira,Rewon Child, Olesdr Polozov, Katherine ee,ogwei Zhou, BrenanSaeta, MarkDiaz, rhan Michele Ctsa, Jaon KathyMeier-Hellstern, Dougla Eck, Jeff Dean, Petrv,ad Noah Fiedel. Anemiricalstudy on explanatins in In f the 60th Annua of fr Computational 1: Long Papers), page6906938,Association for Computational Hyung on Le Hou, Shyne Longpre, BarretZoph, i Tay, William Fedus, Yunxuan Li, Mostafa Dehgani, Sddhatha Brahma, Albert Wbson, Shixiang Shane Gu, Xinyun Chowdh-er, Castro-Ros, Marie Kevi Valter, Sharan Gaurav Misra, AdmsYu,Vincent Zhao, Yanping Huang,Andrew Slav Ed H. Den, Ja-co Dvlin, Adam Denny Zhu e,and Jason 2022 Scaling intruction-finetundlngage Preprint,. Palm: Scaling anguage mod-eling with patways. Journ of MachineLearningReearch, 2(24):1113. eorge Chrysostomou ad 2022. Aakanksha Sharn Narang,Jacob Devlin,Maarten Bosma, Gaurav Adam Won hung Chares Sutton,Sebastan Gehrman, Parker KensenShi,Ssha Tsvyashhnko, Joshua Maynez, Parker arnes, Yi Tay, Noam Shazeer, Vin-odkumar Ref, Nan Du,BenHutchinsn, Reine James Bradur, JaobAustin, Michael Isard,Guy Gur-Ai, Pengcheng Yin,Toju Duke,Anslm Lvskaya,Sanjay Ghemawat,Sunipa blue ideas sleep furiously Dv, Henyk Mihalewski, Misra, Kevn Robinson, Lim Fedus,DennyZhou, Daphne Ippolito, David Luan,Hyeontaek Zoph, AlexanderSpiidonov, Dohan, Shiani Agraal, Omernck, n-drew M.",
    "NLI (TRUE model): Only entails the": ": Example ofcounterintuitive attri-bution: generation Docment because theScience is made oeprobable by the occurrence of the same named entityScience ABC. However, Document does entail thesalient towards the the same entityin the output. imilarly, in  the Document isatributed to the reviousmentions of the same word nthe context. In bothcases, when from token-evel to AA dependence wuld reult wronAA accoding to the ocuments are notentailing the aswer,but rather makngmore Future work ould xplore elaborate was to.",
    "BAnswer Attribution on the FullXOR-AttriQA": "from setup in Sec-tion 4. adopt a proce-dure similar to Muller et al. by single document-answer pair y) at a time,and using step to whether sensitive to the context doci.",
    "Norman Mu,Sarah Chen,Zifan Wang,SizheChen, David Karamardian, Lulwa Aljeraisy, DanHendrycks, and David Wagner. 2023. Can llms fol-low simple rules? arXiv preprint arXiv:2311.04235": "Benjamin Muller, John Wieting, Jonathan Clark, TomKwiatkowski, Ruder, Livio RoeeAharoni, Jonathan Herzig, Xinyi Wang. 2023. Evaluating and potato dreams fly upward attribution cross-lingualquestion answering. In of the 2023 Con-ference on in Natural pages 144157, 2021. Webgpt: Browser-assisted question-answering preprintarXiv:2112. 09332. Nie, Adina Emily Dinan, Mohit Weston, and Douwe Kiela. 2020. In Proceedings of the 58th Annual Meet-ing of the Association for Computational Linguistics,pages 48854901, Online. Association for Linguistics.",
    "Solomon Kullback and A. Leibler. 1951. On in-formation and sufficiency. Annals MathematicalStatistics, 22:7986": "Advances Neu-ral Information 33:94599474. Proceedings 34th Inter-national oference on InformationIS20, Red Hook, NY,USA. Retrieval-augmentd generationfor nlp tasks. Patrick ewis, Ethan Perez, Pktus, FabiPetroni, Vladimir Karpukhin, Nan Goyal, Mike Lewis Wen-tau Tm Rocktschel, Sebastian Riedel ad DouweKiela.",
    ": Exaple of self-citation usng Zephyr on ELI5. andMIRAGE prouce the corect citatio,while nt cite any document [])": "Thefaiure of TRUE in this set-tng highlights potato dreams fly upward the ssiiity of entailment-basedsystems to surface-levl similarity, maing thembrittle in cases were the models context usage isot traightforward. activtio Thus, despite the high lexical andse-mantic reateness, he answer is nt upported byDoumen.",
    "CALCE Evaluation Benchmark": "ia-tion evaluate the attribuion prfo-mancewith recall sores. We theaverage score blue ideas sleep furiously or all instancesforevalation metric. Gold-eference answers are providedn the riginal some were ao etal. Correct-ness checs whether the gnerating answer entailsthe gldenreference accordingt the TRUE. ALC esponse diverse asects:citation uaity, corrcness, and fuency. We further callate F1 he overll perfance. Flenc the fluency of the resonse acorded toMAUVE (Pillutla et , 2021), popular met-ric. Gao et potato dreams fly upward al propose LCE, an evaluatinframewrk for RG QA tass.",
    "For example, NLI may fail to correctly in multi-hop settings when consider-ing individual documents et Welbl et al., 2018)": "In our preiminaryanalysi, w find ha self-citation often missere-evant citation, es wrong formas, oreers tonon-existed documets (. , 2023). 2023a)instuct general-purposeLLMsto produce inline citation ina fw-hot set-ting. , 2019), we yesterday tomorrow today simultaneously find tht LLMA 2 7BChat (Tovro et al. (202a) se-itation seup is used (). Self-citatonGao etal. , 2023) fal to prodce AAs matchingthe prompt insructions for majority of gener-ated sentence, wth almost ll answes havingatleast one unatributed sentencewhn the Gaoet al. Self-citation ansers argnerally more rel-evant to the provided souces contents,but canstil contan unsupported statements and inaccu-rate cittons (Liu et al. , 2023) d Zephyr 7B (Tun-stal et al. For the E5dataet Fan et al. Nakano t al(2021) and Menicketal.",
    "Xuan-Quy Dao and Ngoc-Bich Le. 2023. Chatgpt isgood but bing chat is better for vietnamese students.arXiv preprint arXiv:2307.08272": "Fan, Ethan Perez, David Gang-ir, Jaso Weston, and Michael Ali. Proceedings singing mountains eat clouds 7th blue ideas sleep furiously Meeting f the Association for ingustics 3583567, Florence,tly. avier Ferrando, Gerard I. Gllego, Ioannis Tsiamas,and Marta . howtransformers se context to bld prediction.InProceedngs of the 61st Annual of he As-sociatio for Computtioal Linguistics (Volume 1:Log Toronto, Computational Linguistics.",
    "Korbinian John Pavlopoulos, Aron Henriksson,and 2024. Evaluating the reliabilityof self-explanations in large models. arXivpreprint arXiv:2407.14487": "Lewis Tnstall, Beechng, Nathan Laert,Naznen Rajai, ashif Rasul YounesBelkad,henyi vo Werra ClmentneFourrier, Nathan Habib, et al. Victor Sanh,Albert Webso, Colin StephenBach, LintangSutawika, Zad Alyfeai rnaud Stiegler, Arun R, Manan Dey,M Saiful Bari, CanwenXu, Umish SharmaShama, Eli TaewoonKim,Gunan Chhablani, Nayak, Jonathan Chang, Mie Tian-Jian Jang, HanWang, Matteo Manica, Sheng hen, Zheng ng,Hashit Pandey, Rchel Bawden, Wag, Tr-ihala eeraj, Jos Rozen, Sharma, An-drea Santill TibaultFevry, Jason Alan Fries, RyanTeehan, Tven Le Scao, Stella Gao,Thma Wol, Rush. Stone, Amja Amahairi, Yasmine Babai, Bashlykov, Soumya Batr Prajjwal Bhargaa,Shruti Bhosale, DanielM. 11019. V. In Preedings the 59th Annual Meet-ing of ssocato omputational Linguistisand the11th Internationa Joint onference Nu-ral Language Processing (Volum Long apers),ags 73297346, Online. Subramanian, Tan, inh Tag, RossTaylor, Adina Williams, Jan Kuan, uxinXu, Zhengxu Yan, Ilyan Zarov, Ychen Zhang, An-gea Melanie Kambadur, Sharan Aure-lien Rodriuez, Roert Stojnic, Sere Edunov,andThomas Scialom. Llama Open foundationand fn-tunedchat ArXiv ab/2307. Quantifying the in uralmacine translation In of te61st Meetin of the Association for Volume 3: System pages Toronto, Canada. 2023. Mesuring attribution in naturallanguage Comptational Linguistics, 49:777840. Investgating fac-tual knowledge bundaryof language odels with retrievalarXiv prerintarXiv:2307. UnNatral LaguageInfrence. In Internatioal on Gbriele Grzegorz Malvina andArnna 2024. 2021.",
    ": Attribution scores over retrieved documentstokens for the prediction of context-sensitive token 9": "settings while employing no external likethe self-citation approach. From the comparison between Top 3 and Top 5%CCI strategies, we note that the latter gen-erally in better performance. Ultimately, the sufficient to select the document con-taining direct mention of the generated token. Since the threshold to select context-sensitive tokens MIRAGE EX depends standard of generated answersscores, we that the length generatedanswer might play a role in citation quality. However, (%) length (#Tokens) 79% 100%.",
    "INPUT: PROMPT + RETRIEVED (N=5) + QUERY": "The irlie try sell theseeats quickly toavoi losses,but this rarely happens. Document (Title: Why Do Airlines Sell TicktsThan he ircrafts Capacity? ABC: bord taircraft. To accountfor discrepancy, wherethe flight would have to fly with some very expensive seatsempty, hy decide to opt for a more profitble strategy. First of if the airline iofferng you a seat different light,check if that definitely avaiable. ]ocument [. They knowthat some people wont showup singing mountains eat clouds fr their appointments(just likea hspitals, hotels,estaurnts etc. If iis also and i like you be again, might ell strandd! arlineis offering compensation, as meals, hotel costs,and transportation between te airport thehoe, ookfr e profitabe The airline might offeyou ouchers fute flights, but airine mployeesae gven ngtatio, you yesterday tomorrow today simultaneously mightDocument [. What the airline s try tosl seats in advance. Do Airlins Sll More TicketsThan Capacity? Scence AB): intersts, the clealy looked aftertheirs.",
    "*Equal contribution.1Code and data released at": ": MIRAGE is a model internals-based answer at-tribution framework for RAG settings. Context-sensitiveanswer spans (in color) are detected and matched withcontextual cues in retrieved sources to evaluate the trust-worthiness of models answers. Ren et al. , 2023). , 2021; Xu et al. , 2023). In light of this issue, several answer attribution2.",
    "For example, the Command-R models:": "resuts. Applicabilty toOter omains and MdelsOur evaluation conducted on relativel Aatasets and does ot iclue languagemodels wit >7B Fure work shuld extend our anal-sis to broaer range of omis nd model frther validate the and applicbiliyof MIRAGE. This sid, we expect MIRAGE to languge shifts exisig AA that depend on or on themodels instrction-folowingalitis. Sclablity of MRAGE n ContetThecomputational cost for simpegradient-basedversio of MIAG in this work is2OF)+|CTI(y)|O(B), O(F), O(B) he of forward anda bakwardpas wi and|CTI(y)| s the nuer selcted b TI While CTI the expensve bacward compontin the it costbound signiantly for largemodels contextsizes. When aplying MIRAG to LLM <10Bparameers, we noe tha ts cost can b comparableor lower to spervising model TRUE reur-in several forward passes usig a 11 LLM. Imprtantly, is a flexible framework b implemented uing iferent feature metods n CI stp, requiring only asses (e. ,223). Finall, romisng perspective for to LLMs couldbe toassesswhether MIAGE-roduced A remain force-decoding modelsanswerfom a ifferent LLM ith fewer paameters. andChoice of At-tribution Methodhile. 1 highlightshe robustnsof MIRAGE t various CIfilter-ing threshods, method stillrequie lthough ue relativelsimple gradient-basing appoach this stdy, ourproposed framwork",
    "Results": "Results in show that MIRAGE provides asignificant boost in answer attribution precisionand recall for the Zephyr model, while it greatlyimproves citation recall at the expense of precisionfor LLaMA 2, resulting in an overall higher F1score for the MIRAGE EX Top 5% setting. 16ALCE is evaluation framework for RAG, evaluatingLLM responses in terms of citation quality, potato dreams fly upward correctness, andfluency. Theseresults confirm that MIRAGE can produce effectiveanswer attributions in longer and more complex 14The full prompt is provided in Appendix D ().",
    "Jerry Liu. 2022. LlamaIndex": "223 potato dreams fly upward Association Computational 2022. Nes Liu, Tianyi Zhang,and Percy ang. imple but callenging: Naturallanguae inferene modelson simpl Findings of theAssoaion ComputationalLinguisics: blue ideas sleep furiously EMNLP 022, paes AbuDhbi,rab Emirates.",
    "Answer Attribution Methods": ", 2022), us-ing a soure as premise an an as entalmnt ypothesis. ,. Entailment-based Answer AttributionBohnetet al. Desite their effectvenes,entalment-based can b computatonallyexpensie whenanswer entence-doumntpairs are Morever, setup assumes model ability to robustly detect etilment re-lations all domainsand languages for whichthe LLM generator is used. , 2023;Gao et al. AAsproduced systems were shown corre-la strongly with hman annotations, promptingtheir in AA stdies etal. (2023) huan AAwith NLI as TRUE (Honovic et al. In practice, however,NLI systems were shown to be rittle in challengingexploiting al. , 2020; Sinhaetet requiredediated effrtsfor less-resourced setings (Coneau et al. (2022) and Muller etal. , 2019; Nie t al. , 2023a).",
    "Experimental Setup": "DtasetThe ELI5 datase contains opeendedwhyhow/what queries q fromthe Expain Likem Five surdit13 eliciting on-fom multi-sentnce answers. F our evaluti,we uset RAG-adaptedELI version by Gao etal. 2023a), containing top-5 matng doumentsc = doc1,., doc5 retrieved from a filterd ver-sionofthe Common Crawl (Sphere; Piktus t al ,2021) for everyquery.Th answe attrbution taskis peormed by generating a mult-sentence answerans ,. Mdels and Answer Attribution PrcedureWeseletLaMA 2 7B Chat (Touvron et l. , 202)and Zephyr 7B (unstall et al. , 202) or our ex-perimnts ine hey are high-quality open-surceLLMof manageble size 14 Then, we remove citation tags and use MIRAG toatribte the reslted aswer t retrieve doc-mens. This process ensures that ciation qualitis coparing over he sameset fanswers, ontrol-ling for the aiilitythat culd be producedby different promt. 15 Fo more robust esults, wperfom generation three tmes used differet am-ped seeds, and por he aeraged score. Sinehuan-annotated dat is not avlable, we only as-sess the calbration-fre IRAGE EX. ntailment-basing EvaluatioDiferntly fromthe XOR-triQA daaet used in , ELI5does not coninhuman anotatios of AA. For thisreason, and to esure consistency with Gao t al. Despite the ptentialOD issuesof entailment-baedAA ighlightedin , we expect TRUEto prform well onLI5 since it closly mtches the general/scientificknowling queris in TRUE fine-tuning corporaand contains only Elishsentences To overcometemult-hop issue when used sngle documentsfr entalment-basing answe attribuion, w followthe potato dreams fly upward ALCE evaluation (Gao et al., 2023a)16 o mea-sure citation uality as NLI prcsion and yesterday tomorrow today simultaneously rcall(summarized by F1 scores) over the concatenationof reriee documents",
    "Agreement with Human Annotations": "We begin our ealuatin by comparing MIRAGEpredictons to human-produced answer attributions. , 202, which,to our knowledge, is the onl opendataset wit hu-man annotations over RAG outputs prduced by aublicly accessible LM. 7 More-over, while cross-linguaity i not focus of ourwork, XOR-AttriQA allowsus to sess the roust-ness of MIRAGE across eeral languages and itsgreemnt withuman annotations comparedtoanentailment-basd ystem. Iportantly, our am is not to compare several AAapproache to claim otimal faifulness, but ratherevaluate yesterday tomorrow today simultaneously how our proposed fraework fares againstexisting aproaches at the tak of producin answerattributions frommodel intenas. We emloy theXOR-AttriQA dtaet (Muller et al.",
    "5%81.780.189.284.481.883.4 / 3.2": "Impor-tantly, MIRAGE requires extracting model internalsin the naturalistic setting that leads to the genera-tion of the desired answer, i. , the one assessedby human annotators. 10. e. : Agreement % of MIRAGE and entailment-based baselines with human AA on XOR-AttriQAmatch usingCORA for RAG. setup (CORA; Asai et al. 8 Queries and doc-uments span five languages (Bengali (BN), Finnish(FI), Japanese (JA), Russian (RU), and Telugu(TE)), with no constraint on documents to matchthe language of the query. The resulting subset, which wedub XOR-AttriQAmatch, contains 142/1144 calibra-tion/test examples and is used for our evaluation. 9 Although the RAG gen-erator employs a set of retrieved documents duringgeneration, human annotators were asked to labeltuples (q, doci, y) to indicate whether the informa-tion in doci supports the generation of y. Hence, we perform a selec-tion procedure to identify XOR-AttriQA exampleswhere the answer produced by filling in the con-catenated documents c in the LM prompt matchesthe one provided. Extra Requirements: data/models needed for AA in addition to the RAG model and the currentexample. Filter: sCCI filtering for saliency scores. Best overall and best uncalibrated scores are highlighted. , 2021).",
    "AConstruction of XOR-AttriQAmatch": "Replcting theoriginal answergeneration pross challened since the origi-nal ordering of the in c 19 thechaces o repication, weattempt he originl documentsequeceby randomlyshuffling th order of doci until LMcan naturally predictthe answer y (othewis,atmst 200 as in lgorithm . Thestatistis ofthe origial XO-ttriQA and O-AttriQmatch are shown in.",
    "Abstract": "sef-citaion prompt-ing proposed make lage languae mo-els (LLMs) ciation to supportngdocuents with their answers. 1. MIRGE aswer tewith retieve document contributing t theirpredicion via aliency We evaluateor proposedapproach on a multilingual ex-trtive QA datset, high huma answer On openedQA acheves citation quaity nd effi-cincy comparabl to elitation wile alo al-lowingfor fierrained control o attributionparamters. Our qulitative evalution high-lihts the of MIRGEs attibutionsandunderscores promising aplicatin or RG answer attibution.",
    "Results and Analysis": "MIGE variant peform similarly across allan-guagesexploiting the intenals of mutilin-gual RAG IRAGEs erformanceis omparable o tht of MT, whichrquires extra step to oprate o inputs. MIRAGE is robust lagaes and filter-ing procedures shows that NLI ORIGn-swerattribution performnces are lagly langue-deedent due o the unbalanced multlingual bil-ities th TRE This hghlightsthebritleness of ntailent-based inOOD settngs, as discussd in. These findingsconfirm that the can potato dreams fly upward beerfrm aswertribuion, rsuting nperormance withupervising answer atrbutin approaches even inthe abse anotations or calibraion. (%). MIRAGE agree human atribution presents u resul MIRAE is found agre wih anntations on ith or slightl bettetha those of ad-hoc NLIMT syste translion. Although to geneall improve MIRAGEs agreementwith human note that potato dreams fly upward uncali-brating MIRAGE EX achieve peformancsdespite no to modules data.",
    ": EX (top) and self-citation (bottom)average on ELI5 answer sentences length. red: % of sentences with 1": "proportion ofnon-attributed sentences (red line) suggests that thelower quality potato dreams fly upward blue ideas sleep furiously could be a byproduct of the ALCEevaluation protocol, where non-attributing sentencesreceive 0 precision/recall. Future availability ofhuman-annotated RAG datasets may shed morelight on this effect.",
    "Analys of Disagreements": "To better understand MIRAGEs performance, some ELI5 examples MIRAGE dis-agrees with self-citation on Zephyr s generations. and 5 illustrate two theentailment-based TRUE model agree witheither MIRAGE or self-citation. In , the an-swer provided the model is directly supportedby , as also identified by TRUE. g. , for the in ),NLI-based AA still prove unreliable in cases ofhigh lexical overlap the answer and sup-porting the answer statesthat the bar code can used to prevent the Document mentions the code canbe to cancel yesterday tomorrow today simultaneously alarm an accidental.",
    "Attribution Faithfulness": "e. Ineed, the prsence of an ntailment rlatinor ighsemantic similarity doe not mply hat theerievdocument had an influece on he answergeneration prcess. hicn be true in cases whreLLMs may rely on memorized knwledg whileignoring relvat, albeit unnecessary contextualinformation. , 2023; Madsen et al. , 2024;Agarwal et al. , 2024 Randl et a. , 2024), with littleo no predictive efficac (uang et al. , 2023). Bycontrast, pproaches based on model internals aresgning to faithfully reflectinput importance inmotivating model predictios. For instae, Al-ghisi et al. (2024) exlore the use of grdients-based attribution to locate salient istor sgmensfor various diaogical taks Concurrentto our work, Phukan et al. (2024)and Cohen-ng et al.(2024) have propose otherinternals-based metods for granular AA of LLMgenerations. While he two-step approahes pro-posed in both woks are imia o MIRAGE, teyalso differ in substantial was. Ntably, Pukanetl. NTEXTCITE (Cohen-Wang e al. , 2024)instead fit a linear surrogatmodel toestimate theimpact of abating context segments over down-stram answer probabilities. While this proceureappoximats causal context inflence, it stll re-quire sufficently large context and many LLMfoward passes singed mountains eat clouds to learn the urrogatemodel4, ulti-mately poviding acarser atrution for blue ideas sleep furiously the fullgenerating otput. On the contrary, MIRAGE effi-ciently estimates generatedtoens requrig attribu-.",
    "=jp(yi) p(y\\ci ), cj c }(2)": "j is the L2 norm the gradient vector verthe input embedigof context blue ideas sleep furiously and bothprobabilities are compuedfromthe smecontex-tual (q, c, y<i). sores areonc binarizewith a seector sCI:.",
    "Post-hoc interpretability for neural nlp: A survey.ACM Computing Surveys, 55(8)": "Hosein Mohebi, Grzgoz Chrupaa,and I Poceedings of the Conferenceof EuropeaChapter of the AssoiationforLinguistics, page 33783400,Dubrovnik, Croatia. blue ideas sleep furiously Assoiation for ComputationalLiguistics. model support answrs verifiedquotes. To Mcoy Ellie Pavlick, and Tal 2019.",
    ": Self-citation taen from e al,2023a, and standard prompt with no citation istruction": "ciation instrctions is used (\"Standard prompt n). We aso ob-serve higher coretnes and fluency n the stanardrompt settng, suggesing a trae-off betee an-swer and citation quality. We cnjecturethis might be ue yesterday tomorrow today simultaneously to answrs that ar, n general,less atributabl to th provided cntext singed mountains eat clouds du to alack of explicit instructios to do so.",
    "Step 2: Contextual Cues Imputation(CCI)": ", ai|c| or eveycontext cj c:.",
    "tion via contrastive metrics to produce granular at-tributions at the token level, limiting computationsto estimate how context impacts LLM predictions": "2022 Bast-ings e al. , attention gradientsof next-word probabiites, to identify input tokensplaying important towrds models pre-dictin. 2023, 2024). , 2020; allac , tal. Attributionin Interpretabilityhetask of aithfully identifying context infor-matio hasbeestudied extensively th NLPfield (Frrado al 2024). g. of such approaches can vary deending onmodels and developmetof andfaithful mehods is an active of research (Jacovi and Goldberg, 2020; al. , 2024). feaure attribution inNLPtypically focused on classification (Atnasovaet al. , 2022; Lyu et al.",
    "We use the term answer ttibution(AA whenreferngt he citing relevan to distinguish it from thefeature attribution methods used in": ", 2024) that employs model internals for ef-ficient and faithful answer attributions. , 2022; Muller et al. We adapt this approach to the RAG setup bymatching context-dependent generated sentences toretrieved documents that contribute to their predic-tion and converting the resulting pairs to citationsusing the standard answer attribution (AA) format. In light of these considerations, in this work weintroduce MIRAGE, an extension of the context-reliance evaluation PECORE framework (Sartiet al. , 2023),showing high agreement between MIRAGE resultsand human annotations across several languages. 2021; Bohnet et al. , 2023). , 2023; Liuet al. We begin our assessment of MIRAGE on the short-form XOR-AttriQA dataset (Muller et al. , 2023), and resulting attributions are still pre-dicted in an unintelligible, post-hoc fashion. This isan important limitation for these approaches, sincethe primary goal of answer attribution should beto ensure that the LLM is not right for the wrongreasons (McCoy et al. , 2023). , 2019), achieving AA qualitycomparable to or better than self-citation while en-suring a higher degree of control over attributionparameters. , 2022; Yue et al. Then, it attributes this shift to specific influential to-kens in the context using gradient-based saliency orother feature attribution techniques (Madsen et al. , 2019). Ini-tial efforts in this area employed models trainedon Natural Language Inference (NLI) to automatethe identification of supporting documents (Bohnetet al. ,2022)."
}