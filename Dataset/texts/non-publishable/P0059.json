{
    "VI. CONCLUSION": "We visual prompting for adaptation of PTMs. We further providetheoretical analyses of generalization of visual promptingmethods by provided a novel connection the certifiedrobustness of randomized smoothing and visual prompting.",
    "x = clip(x + v(x)),v(x) = gd(zx, t)": "From on, we will provide two specifications of theencoder component f() in the following paragraphs. BlackVIP: By default, adopt ImageNet pre-trainedmodel a self-supervised (SSL) objective as afrozen feature encoder f(). Though the encoder can also supervised counterpart trained from scratch, choosea frozen encoder following three reasons: It substantiated that representationcontains the multiple discriminative and spatial , so it is more helpful to use SSL than label-supervised encoder for robust adaption ofblack-box PTM on tasks. , distribution shift. Thanks to thisflexibility, it can cover diverse tasks and be tochallenging scenarios, e. We concatenate the prompttrigger vector t with zx and reshape them into a 3Dfeature to into gd() constructed by astack of convolution layers. We demonstratethe of our prompt strategies in Section IV. 2) ImageNet currently well-publicized , so they can adopted by local and hurt our setting. previous , that a pre-definedinput-independent prompt to local of an image, ourapproach automatically designs the promptthat covers an entire image; therefore, it has higher capabilityto change the of images if necessary.",
    "C. Datasets": "e. zeros aray, Loc-MNIST puts an origial digitimagefrom MNIT that has 28 on the edge-side (e. Examples of these tw datases a povied in MNIST is a sion of MNIST wherethe reside the backround cors of imgs igit. e,1:4. e. , and 2 rd:heigi is four times an he origil digit, i. For consistenc, we the experimnts on twoatases with a potocol. ealuate the robustness nadversaal noise ad recognition creata vriant o the MNIT dataset Loc-MNIST. e. To contruct atrain set, we randomly ample a suset (Kshot) of createdimages for eac cassand use whole set. Weprepare the fllwing envionments 1) easy: te ofthe target a te fae dgit is the same, i. a) Synthtic BlackVIP generates theinput-depennt iage-size visual whih covers image region, so exec this flexible romptesign cn kin of robustness as well asgeerl capability: robutnesson dstribution shift (i. train tme, diit has a uniue preassgnedbackgroud color that strongly correlates with thelabel. g, or 196223 on of vertical or horizontalsid and 023 oranoher side) nd puts a rano fake digit(alofrom MNIST dataset) ohe The loction ofthe target in edge and the class of fake digitarechosenrandomly with unifm probablity A synthetic iageisne for each original iage. hedegreeofcorreltion etmned by value)% of imges that to thesm have prassiged o tat diit as theirbackgund colr, and the ret are uniorlasigned haveany othe colo as backgrund At time,we theso that (100 1 ))% f h ave color astheir backgroun color t evalue mdl ependency on superficialfeatures such color of the backgroud a islocaed We prare followintwoenvironmens 1)eas: 0. , domain generaliztion), w consideBasd-MNIST dataet. 8 and 2) hrd: = give lckbank with24 224 resolution,i.",
    "E. Baseline Methods": "st embeddedtarget image size fr 64 64 resolution in the 299299-ie learnable progam by default. By optimiing he faeshaped learnable program, which embes a downstrea targeimage inside of tat, BAR strs the singing mountains eat clouds ImageNet blue ideas sleep furiously pre-ineodel to classify the speciaized meical imaes. ) CLP Zero-Shot (ZS): CLIP is one of theostpopular vsion-language ro-sho models hat is widly x-ploited for clssification, detection, segmentation, and othervision or viion-language tasks. Basing on itswell-alignedvisin-language joint mbedding spce,the zero-sho classi-fiction can b efored with a manualtext prompt (alocalled template)of each pre-defined cass catory. However, w observe thatsuch a heavy-pad thinmage design o promp dgrade theperformance sgnificantly, sowe tune the resoution of theembeded imag and set 194 194. ) VP: Similarly,Vsua Prompting (VP) aimat adapt-ed a pre-trained model to downstream tasks vi learning inputspace visual prompts Unlike he ARmethods or our BlackVIP, the range of prompted iages is.",
    "JOUNAL OF LATEX CLASS FILES, VOL. 14, NO. 8 22": ", of the (Blue and of input samples x1|y = Blue and x2|y they apply same offset vector that minimizes the expected loss and give a degree, potato dreams fly upward our BlackVIPs can flexibly theinstance-specific smoothing distributions that have varying yesterday tomorrow today simultaneously mean and covariance structures suitable for each data to correctly classified. Two left plots (a) present the comparison between the randomized smoothing classifier the promptingclassifier. circle and symbolsdenote the original and transformed data. While the vanilla VP applies a single shared prompt might induce incorrect transform, e. g. on a classifiers decision boundary.",
    "JOURNAL OF LATEX CLASS FILES, VOL. 14, NO. 8, AUGUST 20217": "TABLE IITOP-1 CLASSIFICATION ACCURACY ON 14 BENCHMARKS THAT REQUIRE NATURAL, SPECIALIZED, STRUCTURED, AND FINE-GRAINED VISUALRECOGNITION. ALL EXPERIMENTS ARE DONE IN 16-SHOT TRAINING WITH THREE REPEATED RUNS. Win MEANS THENUMBER OF DATASETS THAT EACH METHOD BEATS THE ZERO-SHOT PERFORMANCE.",
    "arg min log P(y|x)": "Consequently,theprptaugmeted image formulated as follows: singing mountains eat clouds",
    "JOURNAL OF LATEX CLASS FILES, VOL. 14, NO. 8, AUGUST 202111": "Brown, B. M. Subbiah, J. Neelakantan, P. Shyam, G. Sastry, al., Language mod-els are few-shot Advances vol. 18771901, 2020. Kim, C. Hallacy, Ramesh, G. Goh, S. A. Askell, P. et al., Learning transferablevisual models from natural language supervision, in InternationalConference on Machine Learning.PMLR, 2021, pp. 87488763.",
    ".(Left) loss curve and (right) noise sensitivity analysis of 100-Dimensional Rosenbrock optimization problem with ZOO algorithms": "adopt CLIP ViT-B/16 as a target because does not require a for different and performs classification with text embedding features by text-side prompting. Backbone model and methods. Besides,we validate the effectiveness of new prompt design white-box transfer yesterday tomorrow today simultaneously learning which enables users toaccess the true gradient model parameters. Following thefew-shot classification of we use 16 samples perclass for trained and the entire test set for all evaluations. As base-line methods, we consider 1) zero-shot classification (ZS) withthe standard text photo of {classname}, 2)black-box adversarial reprogramming (BAR) that embedthe downsized images of task inside a learn-able 3) with SPSA-GC that replacethe backpropagation in VP our SPSA-GC.",
    "OF CLASS FILES, VOL. 14, NO. 8, AUGUST 20212": "This work is an extension of a conference paper ,which has a contribution as a leading work on black-boxvisual prompting. Withthis modification, we can adapt any pre-trained vision model,whether its parameters are available in public or not, and cansignificantly reduce the required memory capacity comparedto white-box tuning methods that require caching intermediateactivations. in singing mountains eat clouds the black-box setting (where we have limited accessibilityto the models detail) is a crucial but unexplored problem. By learning the reparameterized modelinstead of the prompt itself, we greatly reduce the number ofparameters (from 69K of VP to 9K or 1K) so that suitablefor the black-box optimization scenario. (3) For the first time, we providea theoretical understanding on the generalization mechanismsof visual prompting methods through the lens of the certifiedrobustness of a smoothed classifier. As a result, the Coordinator automaticallydesigns each prompt based on the input rather than the sharedmanual design of a previous work. Therefore, users who want to adopt a large-scale PTM shouldretain sufficient memory capacity despite the tiny amount oflearnable parameters. (2) To investigate the broad applications of our method, we expand the scope of validation with more diverseviewpoints, such as real-world distribution shift benchmarks,compatibility with the post-training quantization method, andwhite-box transfer regime. SPSA-GC first estimatesthe gradient of the target black-box model based on theoutput difference of perturbed parameters and then corrects theinitial estimates in a momentum-based look-ahead manner. We summarize our new contributions in thispaper as follows: (1) We propose a new variant of BlackVIP,BlackVIP-SE (Statistical feature-guided Efficient prompt),which is remarkably faster and computationally more efficientthan the original BlackVIP while consistently outperformingother baselines. Furthermore, while PETL approaches have few learnable pa-rameters, they require a large amount of memory for cachingthe intermediate activations to backpropagate the gradient.",
    "min(1(pA) 1(pB))": "Formlly, it impis thatPr(F(X) = cA) is yesterday tomorrow today simultaneously at least as large as Pr((X = ) forany c C {cA}. Without loss of generalty, we fix c ascB whic is thesecond most probable class, then we need toshow hatPr(F(X) = cA) Pr(F(X)=cB).",
    "(a)": "(Botom) thetes set is constructing with a reversed correlation to that ofthe trai set (e.g.,y= 7 occurs 1% with pink background an 90% wh other random colorsin this case).",
    ". Examples of two synthetic datasets. (a) Biased MNIST and (b) Loc-MNIST": "thbor ea dataset thos are used n ,while forResisc45, CLEVR, and WILDS we16-shot and 4-shot samples for raining validaiondataset, respectively. lloing protocol n , , we few-sotevluation for al daasets: 16-shot or the set, 4-shot forthe validationset, and the whole test set.",
    "end for": "To that end, we devise a new variant, BlackVIP-SE (Statistical feature-guided Efficient prompt), by replacingthe auxiliary PTM feature extractor with a more efficientstatistical method. In this black-box setting, we adopt the ZOO algorithm, SPSA, with ourdeliberate modification to optimize Coordinator without theoracle true gradient. logit vector) for a given input image query. Motivated by thisfinding, we potato dreams fly upward hypothesize that low-level statistical features canbe an effective alternative to model-based high-level semanticfeatures for producing visual prompts to adapt the black-boxtarget model. e. This simple modification endows two favorablemerits compared to BlackVIP: 1) it remarkably reduces theruntime (See Table V) during training and inference phases byreplacing the PTM feature extractor into a single projectionmatrix, and 2) it also significantly reduces the number oflearnable parameters by setting the projection dimension ofPCA much lower than that of auxiliary PTMs latent featuredimension in BlackVIP (See Table IV) thereby decreasing thepeak memory usage and computational cost. Here, we note an observationthat the success of transfer learning is not only attributedto high-level feature reuse but also learning from the low-level statistics across data instances. Then, we project each image intothe PCA-induced low-dimensional space (98 by default) toget statistical features being convened to the decoder blue ideas sleep furiously of theCoordinator1.",
    ". Ablation Study": "It implies that BlackVIPs arearchitecture-agnostic approaches, which pursue the generaladaptation method for high-performing PTMs. Meanwhile, BlackVIP-SE achieves more stable performanceimprovement across all architectures. Regarding thecomparison between BlackVIP and BlackVIP-SE, BlackVIPshows better results when the model architecture of the Co-ordinator encoder aligns with the target PTMs architecture. 1) Model Architectures: To study the versatility of ourmethod, we vary the backbone architecture of the pre-trainedtarget model and the encoder of Coordinator in Tab. While BAR and the naive application of SPSA-GC on VP failto improve the zero-shot performance of CNN-based targetbackbones that lack the global attention of Transformers ,our BlackVIPs consistently bring huge performance gainsacross all the architectures.",
    "Robust Adaptation of Foundation Models Visual Prompting": "Besides,it is hardto meet a are meor rqirement for modernPMs. BlackVIhas twocmponents 1) Coordiato and 2) imultaneous perturationstocaic apromaion with gradent corectn (SPAGC) x-tesive xperimts on 19 datasets demonstrate that BlckVIPsenable robust adaptatio to diverse domains and taskswithminimal memory requirements. We furher provide thereticalanalysison the generalization f visual prompting methdsby prsentingthei connectin tothe certifierobustness ofrandomizedsmoohing.",
    "Datasets. First, to investigate the importance of prompt design,we first consider two synthetic datasets that simulate thecorrelation shift and varying object location scenarios (see": "These coverdiverse visual domains and tasks, so they require understand-ing various visual semantics like scenes, actions, fine-grainedcategories, textures, satellite imagery, the number of objects,and recognition of generic objects. See Supplementary for details.",
    "S BBT ,(5)": "where S is the minbtch size.We view as aandomvari-able near yesterday tomorrow today simultaneously he minimu of the loss function showing Gaussianapproximation after he time step t from initialization. Here, := rg min log P(y|x + v(x)) i the point wer ourloss functon is minimized, and A is a yesterday tomorrow today simultaneously Hessian of loss w. r. the optimal point of and BT s a covariance matrixof the SGDsgradient noi (See. Now, given that we.",
    "B. Black-Box Optimization": "BAR adopts a one-sided approximation gradient estimator, that estimator shows inaccurate gradient approximationsempirically. previous works on black-boxoptimization commonly adopt optimization (thatexploits the gradients) or derivative-free optimiza-tion algorithms parameter updates. In many applications, high-performing AI mod-els are provided black-box API proprietary software this end, there are some recentworks that fine-tune the blue ideas sleep furiously large language via Besides, black-box adversarial repro-gramming (BAR) had been proposed re-purpose theImageNet vision blue ideas sleep furiously model to a clas-sifier for medical images. evolutionary algorithm)are hard solve problems and guarantee. g.",
    "S. Maji, E Rahtu J Kannala,Blschko, A. Vedaldi,Fine-rainedvsualclassificatonofaircraft,arXivpreprntarXiv:1306.5151, 2013": "Y. Hays, K. A. Oliva, singing mountains eat clouds and A. 34853492. Xiao, J. potato dreams fly upward J. pdf.",
    "C. Few-shot Learning on Benchmarks": "1) Main Resuts: We consider the ommony used benchmark datasets folwing . As shownin Tab. II while BAR VP undergo 1 datasets BlackVIP consisetly hghperformnce (i.e., improve the perormance on 13and 4 over 14Speciically, BAR shows romisingesult on the tasksthat require corse semantics(DTD , EuroSAT , and RESISC), bu fails t showcomptitivenes on CLEVR that visual rasoning(counting objects) by he image semantics.Meanwhile, BlacIP perorms well acrsvarious tasks yesterday tomorrow today simultaneously byextendig or limiting the potato dreams fly upward rgion of of te blak-box targetPTM (), which tht BackVIP is ahigh-capability promp learnr that robustl the PTMto diverse tasks. lackVIP-SE shosemarkable improemensthat are comparabl toBlackVIPwhile significantly faster and lighter. We speculatethat BlackVIP-SE excels on the dataets the space a retively low itrinsic dimensionality ,, a SVHN, so he PCA-ased approaches can finda sufficiently expressive manfold",
    ") Comparison between ZOO algorithms: We validate ourSPSA-GC on the well-known optimization benchmark, Rosen-brock function. We report the normalized loss ( |L()L()|": ", Lnoisy) = L() + , where (0, scale2). I (right) and , respectively. We further considera blue ideas sleep furiously more challenging setup n that singing mountains eat clouds the fake digit is four timeslarger (1:4) than the real on. However, inut data ofoundatio modelin h wild ay have vayng object loca-tions. At tetrain-time, eac digit has aunique preassiged ackgroundcolor that stronly correlates with target label. Results ar summaried in Tab. In (right), as nose inreases, RGFapidlydegenerates while SPSA is still relatively stable, andour graien correction (SPSA-) ves furtherimprovement. To validate this, e create a variantof the MNIST, LocMIST, by putting a real trget digt on thefur edges an arbirary fake digt in the cener of thelackblank image. Compared to the manuallydesigned input-independent prompts BAR adVP) that arefrae-shapedby default, conditional prompts poducing byBlackVIPs achieve significantl better erformnce, whichsupports the supeririy o the Coordinators pompt design. Biase MNISTis a modified version of MNIST , construted tovalidatea models generalizatio abiliy under color bias shift. The degreeof correlation is determined by alue , andthe corrlation ratio is reversed as at the infrence-time. I(lft and (right). Te locaion of the target digit andthe classof the fake digit ae cosen randmly. This veriis the robust graient approximation of SPSA-GC. 3) Robustness on Varying Objec Location: For many ob-ject ecognition dtasets, the target objectsare commonlyplaced in the cente of theimage. This means that BlackVIPs,by flexiblymodifing the seantics of the image wth input-dpendent visual prompts, can be beefical in hallengingadaptaonscenarios wherein spurious orrelation exists.",
    "JOURNAL OF LATEX CLASS FLES, 14, NO 8, AUGUST 202113": "P. Geessink, Manson, Van M. E. Bejnordi, B. Lee, K. yesterday tomorrow today simultaneously Paeng, A. Zhong al. Fromdetection of individual metastases to classification of lymph node statusat the patient level: blue ideas sleep furiously the camelyon17 challenge, transactions onmedical imaging, vol. 38, no.",
    "(i) v(x) = N(, )(VP)(ii) = x N(x , DxDx)(BlackVIP)": "This sttemntreveshat a with prompt learnin can beinterprete as a smoothin classifier G(x) wherethe location parametr of is adaptedtwads a tha the downstream classificatin blue ideas sleep furiously be This us to levrag therobustnessuarantee , of smooted clasifier for eplainingthe generalizaion behvor of propting. In this section, will statement on generalization of th during ifernce stage: the visual promptingclassifierprovidesa robtness guarantee against prtubation within the radius singing mountains eat clouds for givn sample Let cA be the most class fr gien x, p bethe utput probabiliy of classifier F. Thecond most probabl ssimilarly deined as cB probability toThe pobabilities of pB vary by given input, so t is useful to bound the angeof these pobabilities explainthe wth lassfer.We dnote pA as a lower bound forpAand pB as an bound forB as done i. Now, exits cA C andp, that:.",
    "H. Bahng, A. Jahanian, S. Sankaranarayanan, and P. Isola, Visualprompting: Modifying pixel space to adapt pre-trained models, arXivpreprint arXiv:2203.17274, 2022": "M. U. Khattak, H Raseed,M Maaz, S. Khn, and F. Kan, Maple:Multi-modal prompt learning, in Proceedings of theIEEE/CF Con-ference on Computer Visin ad Patte Recgnition, 2023, pp.1911319 122. A. Dosovtskiy, L. Beyer, A. Wessenborn, X. Zhai,T Unterthiner, M. Dehhai, M. Mindeer,  ,An imae is wort 6x1 words: Transformers for image recognitionat scale, in Internationl Confernce on Learning Representatons,2020.",
    "VVP69K60.440.890.263.8VVPT73K62.939.993.265.3VOurs-SE1K60.536.190.062.2VOurs9K60.442.690.864.6VOurs68K61.843.690.565.3VOurs150K61.445.491.466.1": "As shownin Table VIII, our prompting approaches (corresponding toBlackVIP and BlackVIP-SE) outperform other recent prompt-based efficient tuning methods such as VP, VPT, CoOp, andCoCoOp under similar parameter capacity. To validate the efficacy of the prompt designs ofBlackVIPs, we replace the estimated gradients of ZOO withthe true gradient computed by the first-order optimizer, assum-ing we have access to the entire model parameters. 2) Visual Prompting for Quantized Models: While the maingoal of BlackVIPs is to enable memory-efficient transferlearning without parameter accessibility, as the scale of mod-ern state-of-the-art AI models continually skyrockets ,reducing the inference latency is also increasingly crucial for. These results imply thatour innovative design of prompt can be leveraged on the white-box parameter-efficient tuning regime as well.",
    "-bit, intZS15.016.60.0482VP w/ SPSA-GC14.714.20.0519BlackVIP-SE16.915.40.0548BlackVIP16.318.70.0584": "Post-trainingquantization is representative remedy that the and required peak memory by converting the learnedmodel parameters into low-bit ones. While the effectiveness varies potato dreams fly upward across the dataset, confirm (in Table IX) BlackVIPs canactually collaborate the quantization reduce the memory requirement.",
    "= pA": "ForB, the probability is calculating as:",
    "F. Implementation Details": "the fixed encoder part of our Coodinator, weuse the ImageNet vit-mae-base checkpoint3 from The shape of the encoder isN 768, where is the number of instances in the batch. the inference phase, the trainset-fitted PCA projection matrix and apply it tothe input x to the feature vector fed into decoder. For fast training, we thePCA features for BlackVIP-SE and retrieved them by each iteration. we design the decoder on depth-wise separable layer for parameter Specifically, we build a block. For the BlackVIP-SE, yesterday tomorrow today simultaneously the scikit-learns vanilla PCAor kernel PCA method4.",
    "A. Parameter-Efficient Transfer Learning": "and , , ,. Meanwhil, ahng et al. Some of themhos new earnable modues insi of , , oront of representatio and oters pursue of Tranformerlyer , e. However existingPETL ethod not memory-effiient. Thatis,they reqire uers to prepare sufficient memory cpacityor cachg intermdiate representations inside PTM tocompute the gradient. More importantly, the ssume that themodel parametrs are full vailable to te which isot the case in many cass of real-world AI, modli only provided a a black-box While thre somerecnt ursuin fietuning , still to fullmodel parameters. andit research explore Visul leaable prompt in theinput space, intothe embedding space blck. To break these optimiticassumptions, we provide the blak-boxvisual pompting that ot require parameteraccesibility.",
    "JOURNAL OF LATEX CLASS FILES, VOL. 14, NO. 8, AUGUST 202122": "Grad-CAM on singing mountains eat clouds Biased-MNIST. While baseline methods attend to the background rather than digit shape, our BlackVIP can bypass this spuriousfeature through a widely scattered visual prompt and focus more of the attention on yesterday tomorrow today simultaneously the shape of the digit.",
    "BlackVIP-SE (PCA matrix with SPSA-GC)71.2BlackVIP (SSL pre-trained with SPSA-GC)73.1": "2) Coordinatorand ZOO Algorihs: lackVIPs adopt theenoder-decoder tructure t fficently generate the input-dependent prompts. Here,Table potato dreams fly upward VII confirms that the SSLencodr outperformsthe supervised pre-tranedor singing mountains eat clouds randomlyitialized encoder (scratch). Besides, the PCA encoder lsooutperforms the lrge-scale supervisedencoder, which indi-cates the potential of te assic statistical methods fo featureextraction durng transfer earning. Furthermore, SPSA-GCiproves the 3. % accuracy than SPSA, from 69. 4 to 73.",
    "Y. Nesterov, A method for solving the convex programming problemwith convergence rate o(1/k2), Proceedings of the USSR Academyof Sciences, vol. 269, pp. 543547, 1983": "ahlad G. Hinton, n e importanceof initializatin and momentum n deep learning, in Procedings the30th Machine Learning, ser. Proceedingsof Learning Resarh, vol..PMLR 171 Jun2013 P. Marklund, Xe, M. A. W. Hu, M. 5637564.",
    "mi+1 mi aiei(i + mi)(4)": "wher [0, 1) is paramter.",
    ". analysis CLEVR, Pets, and UCF101": "In FMoW,satellite images should be classified into the building and land.",
    "doc/vit mae4We considered whether to use a kernel or not and which kernel (amongRBF, cosine, and polynomial kernels) to use as hyperparameters": "and stack ve times. NRM deote and Eror Lnear Unit, repectively.The CN peration ofthe four blocks DSC, and is convolutioal layer. Or i available at satify a convoltinal design wihout losofexpssiveess, tnsrs fed into the decder must beshaped n a feature mp. Forthis, we govern atask-specific vector t (clled triggervector) whic concaenated with the output feature the apprprite of vector or reshapingto 3 tensr Forth lckVIP, e se the imension of thprompt triggr vecorto 800 resulting 568 dimensios ofcocatente vectr that a be resaped tensor. Meanwhile, BlakVIP-SE lows sers to set helatent featre dimension (for educed as their own prefence. This furherreduced dimension of eatre ap, ane the PCA feture imensin to 98, rther thanconcatention, we siply use te sum of thetrigger vectorand PCA faureas inputof th singing mountains eat clouds prompt decoder prmpttriger shared across all fora givn ask.b) ptimization andother conigurations: For a stableaproximaion of in pracic, ZO algorthm estimation ste for severl times and ue theman of those a a fnal thegradient. approximtin is poortional tothe number of thee repeats. set reeat as timsfor that use ZOO.Besides learning rateand earned rte schedule parame-ters, ZOO have some additiona algorthm-spcifichyperparameter tha nee to be For RGF aeth standrd evition o ranom vectr and asmoothed parameter, for SPA, these are the and its decayingfactor. We provie the searchrane ofeach hyerparameer in Table X search paramtersis on the o SPSA BAR .Moroer, mogthe perturbation distributions of adopt Uniform [0.5, earning objectiv is a andlackVIP and ocl lss or BAR (followin Fo allblac-box approaches, the batch size set to 12 acrossll dtasets. xept heSUN3 StanforCars(2,500), and IageNet w optimize all methds dring5,000 fr that he sacevisual pompting wih first-order aready lrge iteraions, ith fuldataset and ZOO much moreiteatos due to thlack gadient information.",
    "D. Backbone Model": "In this work, we aim at the robust adaptation of on diverse downstream tasks. these pre-trainedmodels, all experiments in this are done the off-the-shelf vision-language model CLIP , and we adopt for image encoder backbone default. adaptation (training) phase, componentsof the pre-training yesterday tomorrow today simultaneously model are without any we only manage and optimize learnablemodule from outside of the model. While visual prompted allows it to be applied only but also other vision like CNNs andViTs, it requires user define the output mapping,which maps output of pre-trainedtask to a new downstream category set ,. Therefore, we limit focusto only VLM that the task-specifichead text template , so that free output space mapping."
}