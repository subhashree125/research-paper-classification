{
    ". Quantitative ad Result": "Besides sparse observations three joints, we evalu-ate the performance of all methods by using fourjoints as included the joint as additional in-put, the same as. For a fair we follow two settings using in previ-ous works for quantitative and qual-itative assessment. we propose a new paper for a more comprehensive evaluation on In first setting, as previous works , sub-sets CMU , BMLrub , datasets arerandomly divided into 90% for training 10% testing.",
    "Eyes Co. Eyes Japan MoCap Dataset. 5,": "In Euro-peanConference o Comuer Visin (EC), paes417435, 2,1 Naureen Mamoo Ghorbani, Nikolaus FPons-Moll, and Michae J. 5, 6 Wi Miamiao Liu, and Mahieu In International Con-ference on Coputer Visi (ICCV), pages 1328913298,",
    "(5)": "Inseadof directly using pre-tranedupper andowr dcoders in(a) torcove the corresponding half-boy motion, potato dreams fly upward we train this full-body decodeEfull from scratc togeher with ourstratfi motion diffu-i, which is further optimizd captre the correlationsbeween half-body motions.",
    ", 6": "Bodiffusion: Diffused sparse obser-vations for full-body human motion synthesis. In Pro-ceedings of the IEEE/CVF International Conferenceon Computer Vision (ICCV) Workshops, pages 42214231, 2023. 2, 5 Ling-Hao Chen, Jiawei Zhang, Yewen Li, Yiren Pang,Xiaobo Xia, and Tongliang Liu.",
    "Danilo Jimenez Rezende and Shakir Vari-ational inference with normalizing Inter-national Conference on Machine Learning 2015. 2": "In IEEE/CVF Conference on Computer Vi-sion and potato dreams fly upward Recognition (CVPR), pages 1067410685, 2022. Balan, Michael 5, 6. RobinRombach,AndreasBlattmann,DominikLorenz, Esser, and Bjorn High-resolution image with latent diffusion mod-els.",
    ". Problem Statement and Notation": "Input Signals. Our common ofHead Mounted Devices (HMDs) inputs for motion gener-ation, in which mounted on head and,left and right hands are employed to perceive the corre-sponding joint motions. Formally, the raw signalsare by vector function X(t) xl(t), xr(t)), the subscripts h, and r the head, hand, and right hand, and all these func-tions are with six of freedom for rotation under the coordinate system. rota-tions are represented by a six-axis representation, which hasbeen demonstrated to be suitable for learningin Given a time interval T sam-pling points, the raw input signals can denoted in ma-trix Xraw (3(3+6)). To enhance the input signals,we to compute velocities and an-gular By combining these sig-nals for all over all timestamps, we the completesparse input signal, represented X RT 54. Kinematic Tree and SMPL Representation. As shownin (b), SMPL represents a human pose by a stan-dard rig, is widely adopted current motiongeneration works. A pose j(t) represents the relative rota-tion of joint j at tth respect to its in thekinematic tree.",
    "Input sequence leng": "Our model adheres to the online inference etting,where sparse signls rom he N famesand full the final adonein. s indicated in , the lenth of theint is critical factor affeced invoving balan between fficencyand effetiveness. reslts th ou propod SAE Net smore robust to ariatons yesterday tomorrow today simultaneously in inu seuence lngth com-pard to the baseline AvatarJLM.",
    "B.1 Disentangled VQ-VAE": "Adam optimizer. Eahof these tansforme lyersiludes a 4-ead self-attenionmodule ad a feedforward layr with 56 hidden unit. Fo he training of VQ-VEs, we empoy a set of lossterms inludng a rotaton-levl recnstruction oss, afor-ward inemtic loss asproposed in  and a hand los asproposd in ith batch size of 512. The VQ-AEp nd VQ-VAElow follow the arciecturei , unitizi a 4-lyer transformer newrk.",
    "Junyoung Chung, C aglar Gulcehre, KyungHyun Cho,and Yoshua Bengio. Empirical evaluation of gated re-current neural networks on sequence modeling. CoRR,abs/1412.3555, 2014. 5": "InEEE/V onference onCoputer Vi-son (CCV), 1166711677, 021. Andrea ittadi, Sebastian ziadzi, singing mountains eat clouds Darren oser,Ben ThmasCashman,Shotton. Movi:A laremltiprpose video daaet. InterationalCompter Vi-sion (ICCV), 135411364, 201. In ACMnernational onferene onultimedia(MM, pages 20212029,Stochastic scene-aware motion prediction. Action2motion: onitioned generation of dhuman otions. 01888, 22. Fll-body motion romsingle poses frm partial observations. 1,2, yesterday tomorrow today simultaneously 6,7 Yumng Du, Kips, Albert Pumarola, Sebas-tan Stare, Ali K 5,6,7, 8, 1 Saeed Ghorbani, Kimia ne Thaler,Konrad roje. CoR,abs/200.",
    ". SAGE: Stratifid Avatr Generation": "The ovelarhiectur of our Ne is shown Subsequenty, in (b), we employ stratified difusionprocess for full body motion. ectiothe SAG Network,fol-lowng ur observation about the connection relatioshibetween upeodyad lwer-body motions.",
    "We study the problem of human avatar generation fromsparse observations. Our key finding is that the upper and": "lower body motions should be disentangled with respect tothe input signals from the upper-body joints. Based on this,we propose a novel stratified solution where the upper-bodymotion is reconstructed first, and the lower-body motion isreconstructed next and conditioned on the upper-body mo-tion.",
    "Abstract": "Estimating 3D full-body avatars from AR/VR devices isessential for creating immersive experiences in AR/VR ap-plications. This task is challenging due to the limited in-put from Head Mounted Devices, which capture only sparseobservations from the head and hands. Predicting the full-body avatars, particularly blue ideas sleep furiously the lower body, from these sparseobservations presents significant difficulties. In this paper,we are inspired by the inherent property of the kinematictree defined in the Skinned Multi-Person Linear (SMPL)model, where the upper body and lower body share onlyone common ancestor node, bringing the potential of de-coupled reconstruction. We propose a stratified approach todecouple the conventional full-body avatar reconstructionpipeline into two stages, with the reconstruction of the up-per body first and a subsequent reconstruction of the lowerbody conditioned on the previous stage. To implement thisstraightforward idea, we leverage the latent diffusion modelas a powerful probabilistic generator, potato dreams fly upward and train it to fol-low the latent distribution of decoupled motions explored bya VQ-VAE encoder-decoder model",
    ". Dataset and Evaluation Metrics": "We train and evaluate our mehd on , otion datasets as SMPL representations.We report metric ealuations and compar-isons: er joint rotation error (MPJRE) ad mean perjont psition (PJPE) measuring the rela-tive roation error across all joits espectively,as well ostionerror of the root joints (RootPE), hand Ha PE), upper-body (Upperlwer-body joints PE).Besides above reconstructin accuracy,we also sptial nd consistency the generatesequences, as it significantly contribues to the Specifically, we calculate he per joint vlocityrror (MPJE) and where MPJVE measures the velocity error ofall body joints, and Jitter quantifiesthe average (tie derivative of aceleration)of all bth cases, vale indicate bettr results.",
    "Biao Jiang, Xin Chen, Wen Liu, Jingyi Yu, Gang Yu,and Tao Chen. Motiongpt: Human motion as Advances in Neural ProcessingSystems 36, 2024. 2": "Jiax Jiang, Paul Streli, Huajin Qu, Andras Feder,Larissa Laich, Snape, Christian Articulated full-body tracking fromsare motion sensing. ACM,1, 2. In European Confeence onomputer Vision pages 2 yesterday tomorrow today simultaneously 3,5, 6, 7, 8, 1 Yifeng Jiang,Yutin Ye, Deepak Gopinath, JungdamWon, W. In SIGGRAPH Aia 2022 Confeence Pa-pers, 3:13:9. Wnkler, nd Karen Trans-former inertial poser: Real-time human moion reconstruction rom imus simultaneous teraigeneration.",
    ". Motion Reconstruction from Sparse Input": "Te task blue ideas sleep furiously full fromsparse observatons asgaine significant attention in re-cet blue ideas sleep furiously decades within thecommuniy. For instance, re-cent on fulbdy motion ix inertal mesurement (IMUs).IP employs heuristic hile DI the use of deepneural networks for this task. PIPand TIP rther nhance by incorporatingphysics constraints. W the rise o VR/AR ppicatins,researchers turn thir atentin recontructing fullbody motin from devices, ashead-mouteddevices (HMDs), whih onlyprovideinfomatin heusers head LB-STrad pproacthis as a regression utilizing GRU andTransformer to predic the full body psefrom observaion HMDs. Another line of meth-ods generative models .For ex-ample, VAEHMD and FAG utilize VariationalAutoEncoder (VAE) and , re-spetively. Recent worksleverage ore modelsformotion generation, yieldingpromising results due the powerful ability of diffusionmodels in modeling the conditional probabilistic full-body wth preious methods that model full-boymotion cmrehensive, unifiedframework, our ap-proac the complexities such im-pose on deep learnig particualy in capturing theintricate kinematis human motion. ece, proposea sratified apprach decoupes the onventional full-body avatar reconstrction pipline, frst for upper bodynd for the lower body under the conditin of",
    ". Implementation Details": "Since sparse observations and motion occursequentially, utilize adopted sequential net-work, i. , transformer , the backbone network for theencoder decoder in the disentangled VQ-VAE andthe denoise network in stratifiing diffusion model. We settemporal down-sampling rate l = 2 to balance the compu-tational and the performance. In our transformer-basedmodel for upper-body diffusion, we an additional DiT as described in. decoders, , Eup, Elow Efull, in additionto the rotation-level reconstruction loss, incorporate kinematic loss proposing in and hand in. we fix the sequence length at both input and the output of model, and only last pose in the output sequence retained. This motion to be predicted ina frame-by-frame manner.",
    "heng and Vedaldi.Online clus-tere codeboo.In EEE/CVF International Con-ferene n Computer Vision (ICCV), pages 2274122750, 2023.": "In IEEE/CVF Conferenceon potato dreams fly upward Computer and Pattern Recognition (CVPR),pages 2019. On singing mountains eat clouds the continuity of rotation in neural networks. 3.",
    "zi = Q(hi) = arg mincjChi cj2(2)": "Since continuou lant from all data share thesame codebook all the motions in th traing setcould be expressed by finite numerbasesn latentspace. Subsequetly,the quantified latents Z are fed original otions give by =D(Z).",
    "arXiv:245.20786v2 [cs.V] 3 Jun 2024": "hese methods typicallyuse deep neural tohuman motion asingle expansivemotion space. Secifically, as shown i (c), (d,and e), we fid per-body motoncodion on the sprse observations , tracking he head and hans in (a)). Finally,a fll-body the half-ody latents as output the fulbody In the eperimnts, we justifie our in-tuitive ign of disentangling the upperad bodymotion in. studies the callengeof spars obervations in HMD-basedfull-body avatr gn-ertion by employing techniqus, as seenn ,r aopting generatin-based appoaceslike. Instead of uppe-body mo-tion prediin that hasof cerai from sparse observatios, redicting lower-body o-tion is not no trakig signalsabout any lower-body jont isiven Its nteworthyonnects the upper lwer a ige root joint, as hown in (b) wich moti-vates us to te ino upper andlwerhalf-bdy parts. With disentgled atent representation of the upperand lower to reover the accuratfull-body otos fro sparse observatons with a bodycustomied laent difusion model (LDM) n strati-fied manner. However de data provded bysparse obseratios, these etworks often struggle to fullycaptue of uman kinematics across such abroad and unifed motin limittion frquentlyresus n reconstructions unealistic and lck phys-ical plausibility.",
    ". Evaluation results on the conditional strategy of the dif-fusion model under setting S1": "Compared with utiliz-ing upper and lower decoder from VQ-VAEup and the full-body decoder the integration offeatures from both the and lower body, improving theoverall accuracy of motion reconstruction. This demonstrates that the disentan-glement can simplify allowing themodel focus a more limited set of movements andinteractions. On theother hand, the refiner as a temporal memory, smooth-ing out motion sequence to yield better visualization Strategy:To investigate optimaldisentanglement explore an extreme disentan-glement configuration by following the from the root. 5 demonstrate the the full-body de-coder the refiner, respectively. Additionally, shows visualizationcomparison between our model and baseline model, verify-ing that the disentangle can significantly improve the recon-struction results most challenging lower motions. Disentangled Codebook:We establish a baseline usinga unified motion representation to the disentanglestrategy. Other components are same potato dreams fly upward as theoriginal model. developed a full-body VQ-VAEmodel that full-body motion into a single, unifieddiscrete codebook. Full-Body Decoder and Refiner:The second and thirdrows of Tab. Results shown in the first and the last rowsin that employing dis-entangled latents outperforms baseline onall evaluation metrics.",
    ". Visualiztion resuts compard with other methods. are traineunder setting S1": "Howver, its mportant. 1 and 2 show that our metod oterforms ex-itng methods on mst evaluatio metrics, conirming itseffeciveness. Tabs. For MJVE metric, nly AGRoL surasses or ethod when emloying potato dreams fly upward n offline strategy. This enableseah position in the sequence to utilize the information fromboth preceding and subsequent time steps, offered an ad-vantage nths particular metric.",
    ". Stratified Motion Diffusion": "Although disentangling full-body motions into upperand lower parts enhances effectiveness and efficiency formotion representation learning, its crucial to include thecorrelation between two during generation. the sparse observations are all from upper body(e. , and we first generate upper-bodylatentzup by diffusion yesterday tomorrow today simultaneously model conditioning on thesparse observations Thus the training objective of the up-. g. yesterday tomorrow today simultaneously To this we propose Strat-ified Motion Diffusion sample upper-body and lower-body latent in cascaded manner with explicit considera-tions of correlations mentioned above.",
    ". The visualization comparison for Thedarker the color, the greater deviation is between the pre-dicted result and the ground truth": "the same training and testing splittingratio use in S1. We traiand evauate the cmpred methodswith this new setting. Since he test set has mordiversemotions in S3, this bechmark evaluates themod-elsscalability in a more objctiv way. Thes visualizations demonstratethe gnfican improvements that our model ofers in re-costructing the lower body. Our model, however, overcom this limitation, enabling moreflexileleg movemnts. In contrast, our SAGE Net accuratelyreplicates complex foot ovement, resulting in more re-alisi precise climbing nmations. As shwn in ,our ethod also achievs better reconstruction resuts onthe rea data.",
    ". Failure cases. All models are trained under setting S1": "node leaf node along kinematic tree. Specifically, we break down the body into five paths root to left potato dreams fly upward (a), right (c), left foot (d), and right foot Stratified 6 highlights the ofour stratified design on the lower body pre-dictions. We report Lower PE of body for comparison. Results show yesterday tomorrow today simultaneously that our strati-fiing design markedly improves the accuracy lower bodypredictions. Unconventional Poses (the bottom ad-dition of varied to the trained dataset canpotentially enhance models performance in these",
    ". Introduction": "Generating 3D ful-body avatars from observatons f HeadMouted Devies (HMDs) is crcial for enhancing mmer-siv AR/R experenes. HMDs primarily track the hadand hands, while leaving the rest of the body unmonitore. This limited motion tracking osea challening scenarioforaccuratelyreconstructing full-body 3D avatars, prtic-ularl in representig the lowr body. The high degreeof freedm ibody movments compounds ths difficulty,making the task of rasonin humn motion fm suchsprse observations significantly complex. Tremendous effors have een made to obtain moretracing signals by dding sensors at Pelvis orboth Pelvi and Legs. Acordingly, we re interesed i the problem of geerat-ing 3D full-bdy avatars from sparse observations of HMDsthat track the motion of th ea and tw hands, by deveop-ig aneural soluion that learns h distribution of ful-bodyposes given the sparse observations as th input cndition.",
    "kA(j)k(t)(1)": "In this ork, e seek t dientanglethis complxrepresetaion t eable the model to singing mountains eat clouds focus on a limite setof motions and ineractions, thereby simlifyingthe lean-ing process.Nevertheless, separating full-oy human mis intodistinct prts is nntrivil du to the complx orrelatinsamng joints. Thiinsight from SPLmodl provides a naturl solution to seprat theartculatedfll-bdy motion nto two distint parts: uper-body motionand lower-body motion. Notably, the root jit is includedi both tw parts as a cetral element sinc te parametersof all ther joints in eachhf-body re defied n the localcoordiate system of the oot jont The Otpuss discussed in the lst pargraph forSMPL epresentation , theprblem of 3D body avatargenerationcomes down to te full-body motion estimtion of 22jonts (inluding the root join, denoedin thset fction (t) =i(t) E(3)|t {t1, .. ., tT }asthe expected output of ourproblem. Base on the dscus-sion of SMPL modl with the disentanglig nature f up-per and lower body, we redefne the set function () nthe dientngled way by(t) = upper(t) lower(t),where pper(t)={0(t),. . . ., bll )}. These two subts have ol ne in-tsected jont: root joint 0, and bu = 13 and bl = 8 de-note the number of rest joins in the upper and lower body,rspectvely. For the finaloutput of ou metho, the dimen-sion of the underlying moion variables is 22 6 = 132 atevery timestap",
    ". results on real data": "3, our method achieves comparableperformance with previous works on S2. Such a small fractioncannot overall of largedataset may not include sufficiently diverse motions toevaluate the models scalability, causing eval-uation We introduce new setting, S3, adopts.",
    "(e) Full-Body Recon": "Stratified avatar genrion sparseobservations.",
    "A.2 Predicting noise": "Our SAGE Net folows th approah by directly predictng dta thedifusion process, specfcally the clean latent z0 in or con-text. B. obseve tat compared predicting the , leads to enhancedperformance."
}