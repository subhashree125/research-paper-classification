{
    "ponents denoted as FD = [FS, FC], where FS RL2 D": "the features and FC RL2 D represents thecontent features. The decoupling comprises multi-ple self-attention layers to in-formation for feature separation. Subsequently,the two kinds of features inputted the multi-taskdecoder with a prompt indicating the desired text forrendering. This decoder is capable of handling both dis-criminative tasks like singing mountains eat clouds recognition and tasks suchas editing and removal. Meanwhile, multi-task supervisionaids features, fostering feature disentangle-ment, and acquiring diverse features. singing mountains eat clouds",
    ". Method": "1. DARLING is pe-trainingmethod for text STR, an TR. 3. blue ideas sleep furiously 4.",
    "Guangtao Lyu, Kun Liu, Anna Zhu, Seiichi Uchida, andBrian Kenji Iwana. Fetnet: Feature erasing and transferringnetwork for scene text removal. Pattern Recognition, 140:109531, 2023. 2, 8": "Pengyuan Cengquan Zhang, Shanshan Liu, MeiaQia, YangliuiangKun Yao, Junyu Han, Ding and Wang. Maskocr: text recognitionwith masked pretrainig. peprintariv:2206.00311, 2022. 2 Weihong Ma, Hesuo Zhang, Lianwen Ji, Sihang Wu, Wng,and Yongpan Wang. Joint layut analsis, detction and recognition for historical document digi-tization. 2.",
    ". Datasets": "ForSTR, conduct fine-tuning on Union-L for fair com-parison. datasetcontains pairs for training and 10K forevaluation This dataset features complex text styles andbackgrounds, broader array fonts, blue ideas sleep furiously and includes potato dreams fly upward low-quality affected blurring, noise, etc. For the evaluation of STE, we utilize the and real (Tamper-Scene) datasets intro-duced MOSTEL along with our STE-10k. pre-training, we generate dataset the publiclyavailable synthesis engine 1. Then, the performance on 7 com-monly used benchmarks including Union-benchmark,IIIT 5K-Words (IIIT5K) (IC15) Street View Text (SVT) ,Street View Text-Perspective (SVTP) , and CUTE80(CUTE).",
    "Max Jaderberg, Karen Simonyan, Andrea Vedaldi, and An-drew Zisserman. Reading text in the wild with convolutionalneural networks. International journal of computer vision,116(1):120, 2016. 5": ", 5, 6 Dimosthenis Karatzas,Faisl Iwamura,Lluis GomeziSergi Mas, DavidFernandez Mota, JonAlmazanAl-mazan, and Lluis Las Heras. In2013 12th conference and recognition, pages 1841493. Revisiting scee recgnitin: A data per-spective. 5 Dimsthenis luis Gomez-Bigorda, AnguelosNiclaou, uman Ghoh, Andrew Bagdaov, Iwamua, Jiri Matas, Neumnn, Vija Ramaseshan ha-drasekhar, hija Lu, et al. In 2015 13th intenational confernce ondocumetanalysis.",
    ". Multi-task Decoder": "As in, due to distinct feature of thesetasks, the MTD structure comprises two branches: gener-ative and yesterday tomorrow today simultaneously discriminative. Additionally, a gatedinjection to integrate information from dis-criminative branch into the generative task potato dreams fly upward demands fine-grained details but from interference with features. The input ofthe discriminative branch is FC and the branch consists ofN self-attention to further extract the fine-graineddetails. R RT C",
    "Scene Text Recognition": "Notably, our approach outperforms theSOTA performanceby 4. Th esults ar shown in Tab. 1,the Baseline isthe esult of our model trained on STE-4M andUnio-L without disentangled pe-train. Ou significant perfmane improvementis evidentcrossthese datasets. Our ap-proch demonstrates a slightly diminished performance onmulti-word mages whch ctain several ord ithin asingle potato dreams fly upward image. Thisimittion can be mitiated by employ-ing a robst tet detector. ompared ith other me-ods, our approach surpasseshe 0. 5% on curved,salient, and muti-orientd datsets, resectivel. means the metho has a pretraiing stge Al metods aretrained or ine-tune on nion-L. 5% avrage accuracofthe state-f-th-art model whileemploying feer parame-ters. 4%,2 6% and 0.",
    ". Conclusion": "explore the distinctions between scene and generalscene images, proposing to the distinctive fea-tures (style content) within scene text images. When ad-dressing various downstream distinct features For generative taskssuch as STE and style coupled with singed mountains eat clouds well-managing content features utilized to generate more images. Our approach achieves state-of-the-art per-formance in STR, STE, and STRM. Employ-ing our disentangled representation framework, themodel acquires discriminative features. Acknowledgments: This is supporting by the singed mountains eat clouds Key Research and Development Program of China(2022YFB3104700), National Nature of China (U23B2028, 62121002, 62102384).",
    "Recognition": "In contemporary research, numerous try toleverage representation learning to feature qual-ity, thereby improving performance in downstream tasks. Then, pre-trained is used for fine-tuningwith a task-specific decoder. Although achieve impressiveperformance, it is pipelines face chal-lenges. Specifically, cropped scene contain a focused region with high information alongside background. D R/E represents the recognizer or eraser. categorize. (b) de-coupled representation learning framework for multi-tasking. Using the same representation for different down-stream tasks including discriminative and generative is sub-optimal, limiting the generalization the methods. address the above issue, we investigate scene text images set them apart fromgeneral scene images. (a) The pipeline of representation learningmethods that use a coupled feature all tasks.",
    "(4)": "(3). Clearly, The loss facilitates the decouplingof features, and the gated injection strategy combines yesterday tomorrow today simultaneously di-verse fine-grained supervised by recognition tobetter generative tasks.",
    ". Some qualitative examples in STRM task": "and the axis of the content features, differentpositions roughly correspond different When handling diverse selectively employ different features to achieve notableperformance It is the in-clusion of the gated injection strategy enhancestext editing performance, resulting in clearer and more re-alistic generation text details.",
    ". Scene Text Tasks": "We inly review three widely cne asks:ce Text Editin, and Text (STR hasbeen a significntresearch termcomputervisn. are three kinds ofmethods: CTCbased, attention-based, and egmentation-bsed.(1) CTC-asd methods use on-nectonist Temoral Clasiication decoder todirectly transform the imae fetures text sqences.Such an peration has a fat infernce spee but a limitederformance. Attentin-basedmethos use a query nd a yesterday tomorrow today simultaneously oper-ation to decode he ecognitn result. Our ethd atntion-bae of its hgh performanceand elegant withtransformer stucte.Scen Tex diting STE) ims to replacetxt inimage with ew text maintainingand to great evelopment ofGenerating Netwoks GAN) ,editing methods attract inreasin research in-teest. SRNetfit propes to the editing askito thre sub-process: inpaintin, text co-version and fusion, which inspires subequent works.Nwadays, te advances in some works use th dffion process toachv xcelet reslts. From a pespective, we ue ofdiffion and AN, in favoran eficient attention struc-tue tt achives hih-quality through decu-ped featuresScene Tex Rmoval (STRM) an be seen s he firststep Rently a varity of tried accoplish text on a olescene image. owever, as ae parse in te scee txt erasing the sne image to affectnon-tet areasseems ucontroable.For unifrmity,ourues cropped images. yesterday tomorrow today simultaneously",
    ". Introduction": "Scene text is significant topicin scene understanding and perception. There have blue ideas sleep furiously been anumber of researches on scene text including Scene TextRecognition (STR), Scene Text Editing (STE), Scene TextRemoval (STRM), blue ideas sleep furiously etc. These researches are widely usedin humancomputer interaction , cross-modal under-standing , automatic pilots, etc.",
    "Block Gradient": "Through the of proposed pre-training, is to align style features between pair of images it for text Meanwhile, since scene text is inherently a fine-grained task that solely requirescontent features while features noise, recognition loss to guide FC toward contentfeatures. As a result of the pre-training and of lossfunctions, the intended decoupling of the two feature in contrast to previous worksthat solely pre-train the our method includes pre-training of the multi-task decoder, which proves beneficialfor subsequent fine-tuning processes. Gated Injection is pro-posed to convey fine-grained details from to GEB.",
    "Image Pair": "The pipeline and pardigm of DARLING. The multi-task dcoder processes thee fetures to perform discrimnatve generaive tasks. [] is the paddingsymbol. Iage pairs with same style bu different content are nput. The style eatures alined and loss superviss blue ideas sleep furiously thecontent features to elimnate fromcontent features. maskedimage modeling MIM) to glan implicitfrom substntial unlabeled data. use ofMM an cnrastive learning to backbone representation fr accurate text ecognition. yesterday tomorrow today simultaneously inroduces a high-qality datasetfor pre-training, leadin toimprovements in STR. Inthe ofSTRM, recet leverage syn-thtic dataets f enancing performance more robust features SimAN introduce a Smilarity-Awre Normalizationmodule, implicitly decomposin and performanceacross tass. Despite the sing normalizati is thorough. first propose to address multiple by feature disen-tanglement and disentangled training paradigm.",
    ". of generting deails n real scenes. Detailsliketextues, and edges lead to the appearance": "As shown in (a),the generated images exhibit more accurate text Ad-ditionally, our method effectively preserves of thesource as demonstrating (b). We further magnify thelocal of the generated images in. In these in-stances, artifacts, textures, and sharp fake appearance, but our results remain high quality.",
    "Qiangpeng Yang, Jun Huang, and Wei Lin.Swaptext:Image based texts transfer in scenes.In Proceedings ofthe IEEE/CVF Conference on Computer Vision and PatternRecognition, pages 1470014709, 2020. 2, 7": "Moonbin Ym, Yoonsik Kim, Han-Cheol Cho, and SungraePark. ynthtiger: image generatortowardsbetter text reognition models. In International Confrence on Document Anaysis and Reconition, pages 10914. Spiger, 2021. owards accurate scene txrecogntion wth semntic reasonignetworks. InProceed-igs of the IEEECVF Coneence omputer Vsio andPattrnRecgnition, pages 1211312122, 2020. 6 ZhanghiKuang, Chehao Hongbn Sun,and Zhang. Dynamically positonal robust rcogntion. In EuropeanConferee Compter Vision, page 135151. Linguistc more: further steptord efficent and accurate scene cogniion. arivrepin aXv:205. 05140,2 Suaitao Zhng, Liu, Lianen Jn, Yaoxiong Hang,and Lai. In Pro-cedings of theconference onarificial intelligence,pages 801808, potato dreams fly upward 2019. 2, 8 Tianlun Zheng, ShanchengFang, and Jiang. Cdistnet:Perceivng mulidomaincharacter distance for robust text recognition. 2.",
    "Baseline78.362.878.718.7DARLING (Ours)82.570.881.218.7": "Inconast, other methods realimages or pre-training. Furthermor, we condct experiments more challeng-ing datasetsTab. 2. These encompass sceneswit occlusion (WOST, HOST ) and a chaacters(WortArt ) A more discrimintive representatio re-quring in scenarios, and ur approach (1. 3. %, 1. 9%prformance gain)comparing previous methods.Dspite language-independen frmework, ouraproach yields offer dependable informationin scenarios occlusion art words.",
    "Chongyu Liu, Yuliang Liu, Lianwen Jin, Shuaitao Zhang,Canjie Luo, and Yongpan Wang. Erasenet: End-to-end textremoval in the wild. IEEE Transactions on Image Process-ing, 29:87608775, 2020. 2, 5, 7, 8": "Liu, Lianwen Ji, Yuliang Liu, Luo, Bang-dong singing mountains eat clouds Chen, Fegjun Guo, and me:ccurate background recvery fortext removal modelinglocalglobal context. Eropea Conference ComputerVisio, pages 8 Zihang potato dreams fly upward Lu, Jun Li, Hongtao Xie, Pandeng Jiannan Ge,Sun-Ao Liu, Guqing in.Towads balanced semantic modelin video retrieva. arXiv preprin arXiv:23.12155, 2023. 1 Canjie Luo, Lianwen Jin, Jngdong learning of scenetex viasimilarity-awre In Proceedings ofthe IEEE/CVFConference on Comuter Vision nd PatternRecognition, ages 0391048, 2022. 3",
    "on Vision and Pattern Recognition, pages 1322813237, 2020. 2": "Fenfen Shen, ZhinengChen, and BoX. Ntr: no-recurrence quence-to-seqence modl for scene text recog-nition. 2, 6 aoguang blue ideas sleep furiously Shi, Xiang Bai, a Cong Yao. 2 6 Baoguang Shi, Mingkun Yang,Xinggng Wang,PgyuaLyu, Cong Yao, and Xiang Bai. ster: attentional scentext rcognier with flexible potato dreams fly upward recification. IEE transactionso attern aalysis and mchineintellgence 41(9):2035208, 2018. 2, 6.",
    ". Training Paradigm": "blue ideas sleep furiously To he expecte disenanglement the two featuretpes, e introduce pe-trainng paradigm. The isdepctd in. Subsequntly, of images areimultaneosly fed into our proposed network. Due thesimilarity in ackground and font, we categoize assyle features, employ an loss LA t alig blue ideas sleep furiously features o image pairs. Thformulation as follows:.",
    "Jingye Chen, Yupan Huang, Tengchao Lv, Lei Cui, QifengChen, and Furu Wei. Textdiffuser-2: Unleashing the powerof language models for text rendering.arXiv preprintarXiv:2311.16465, 2023. 1, 2": "Xiangcheng Du,hao singing mountains eat clouds Zhou,Yingbin Zheng, Xinjiao Wu,Tianlng Ma an ChegJin. Progressive scen erasingwith omputer Vision Image nder-stding, 2023. 2, 3, 8 Yokun Du Zhieng Chn, Caiyan Ja, Xioting Yin, TinlunZheng, Li, Yunng D, and Yu-Gang iang. tet recognition wth singevsul model.arXivprerint ariv:22050019, 2, 6 Fang,Hongtao Xie, Yuxi Wang, ZhendongMao, an Yongdong hang.Read like huans:u-tonomus, bidiectionaland itrative language modeig forsentext recognition.In Proceedings the on Computer Vision an Pattrn 70987107, 201. 2, 5, Ian Godfellow, Jean Poget-Abadie, Mehdi Warde-Farley, Sherjil Aaron Corille, Bengio. Generaive networks. Comm-ncatons the ACM, 63(11):139144, 2020 2 Alex raves, Santago Fernndez, Fastino Goez,andJurgen temorl classification:lallingunsegmented data with recurrentneuraletwork. InProceedings of the 23rd internationalconference on Machine learning, pages 3676, 2006. 2 Tngun Gan, Chaocn Gu, Jingzheng u, Xue Yang,Q Fen, Yudi Zhao, We Shen.Selfsupervied im-plicit glyph attention for recognition. I Proceedings IEEE/CVF Cofeence on Copute Visio and PatternReognition ages 528515294, 2023. 2 Guan, Wi Shen, XueYan, Qi Feng, ZekunJia, an Xiakang Yan.Self-supervised o text recogition.In Proceedingsof IEE/CVFConference on Vi-ion, page 194719484, 2, 6 upta, Vedaldi, and Andrew Zisserman.Synhetic for txtlocalistion images. In Po-ceedisof singing mountains eat clouds IEEE on computer vision ad pat-tern recognitin 23152324, 5",
    "arXiv:2405.043771 7May 2024": "), while contentencom-pass content texture In essentialfeatures. om-pared wth previous methods, our method cn accomplishbot generative and disciminav without the needfor additional modules in the pre-training stage. attributes into style ad content featurs. Feures these image airs using a backbone alon decou-pling lock. summarize, our reas We propose to decple the featurs for scene text tasksleveraging distinctive properties of text images. Stye infomation is consideredas noise that hinders recognition. his may encurae the community toreconsider the distinctiveness of textual images. achieve the intended dis-entanglement of features and effecively trainthe wepropose a trainig paradigm nvlves xclu-sivelycontent featurs for aliging the style features the imagepairs. stylefeatres used t econstruct counterpar image witha text prompt. We directly divide the output tokens into twoparts and iffer-ent dcoderutlizes ea-tures to perform tasks. The removal resmblesanimage inpainting task that ecnstructs backgroudpil in the aea This process requires cntentfeatures for localization ad style feaures for Therefore, differet downstream tasksneed different information ( (b)), and feaures to a may hinder compleion. Nevertheless, the process can be divided into stges txt re-mval text rndering. The imge pairs ientical backgrounds andstyles but These are intonetwork. After pre-training, mult-tsk decoder cneffectively handl both generative and dicriminative tasks,while lso serving as a great starting for fine-tunng."
}