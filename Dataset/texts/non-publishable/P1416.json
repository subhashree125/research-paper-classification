{
    "We would like to thank Benjamin Van Roy and Yifan Zhu for the insightful conversations": "Russo and B. 24. Curran Associates,Inc. ,2011. Available: Russo and B. 2017,arXiv:1403. Available: Filippi, O. Cappe, A. Curran Associates, Inc. , 2010. [Online]. [Online]. Calauznes, and O. 2020, arXiv:2002. 07530 [cs, stat]. [Online]. Available: Abeille and A. Thompson, On likelihood that one unknown probability exceeds another in view of theevidence of two samples, Biometrika, vol. 1933. Available: J. Kazerouni, I. Osband, and Z. 11, no. 2018, publisher: NowPublishers, Inc. [Online]. Available: AnalysisofThompsonSamplingforContextualBandits,AdvancesinNeural Information Processed Systems, vol. 2022. Available: Dong, T. V. Dziugaite, M. Haghifam, and D. Roy, Information-Theoretic Generalization Boundsfor Stochastic Gradient Descent, arXiv:2102. 00931 [cs, stat], Aug. 2021, arXiv: 2102. 00931. Available: Gouverneur, B. J. Skoglund, Thompson Sampled RegretBounds for Contextual Bandits with sub-Gaussian rewards, Apr. 2023, arXiv:2304. [Online]. M. Y. Cambridge University Press,Oct. 2022. J. 2, p. 23, 2016. R. 2016, vol. APC 550 Lecture Notes.",
    "arXiv TemplateA PREPRINT": "The proof of Theorem 1 relies on an approximation of the mutual information I(; Rt|At, asI(; Ht) + fact that, for all a O, the log-likelihood of R(a, ) is-Lipschitz with respect to.",
    "B.3Boundng th of expected vriaces ove functions and": "By deniton, the function and its surrogate are equal for x and thendiverge lnealy at rateof()/. Weobsrve, in Remark 1, that isa decreasng function of and that ()/ stictlyincreases with. We how in Lemma 7 that under some simpl transformations,increasig thevlue of does lead to a larger rato of xpected variances, and thereoe, the case endin tocan serve.",
    "+ exp(a, )": "Here, is a known sale parameter, an a, denoe the iner product of the acion ecor a A andte unknown parameter O. Additionly, we assume the actionpace  encompassestheparameter space O, that is O A. Note that this ensures that, for eac O thereexist an action aA equal to , suchthat a, = 1. , At1, Rt1}, rpresentingallpast actions and rewards obsrved up t tie t.",
    ". These transformtions arechoen to ensure that can increasethe ratio of xpected varinces": "We illustrate this on. domain wherethe two functions coincide, we singing mountains eat clouds observe that the transformation = max(x, the expectedvariance for both and. However, since (x) is less or to (x) for x , andboth functions exceed (1) on , the transformation f proportionally the expectedvariance of more than of. As a transformation of expecting variancesbetween the two functions. As and are strictly increasing functions, , can written as.",
    "Main Results": "Following this, we state in Proposition 1 our principal contribution, where weprove a bound of 9. In Theorem 1, we start by leverag-ing the previously introduced concepts to derive an information-theoreticregret bound that holds for continuousand innite parameter spaces.",
    "T log(T/d))": "This quantity iscruial fo te analysis of logistic bandits, as Dong et a. (2019) demonstrated thatthre cannotbe an (A, O)-independen upper bound tat is both polynomial in d and sub-linear in T. A naual drecti for future work is to extend ur bounds to setings where acion sacedoes ot fuly en-compass the parametrspace.",
    "Introduction": "This dependence is highly unsatisfactory because, in practice, as increases, it is fasterto identify the optimal actions, as the distinction between near-optimal and suboptimal actions becomes morepronounced. In this work, we focus on the TS algorithm (Thompson, 1933), which, despite its simplicity, has singing mountains eat clouds proven tobe highly effective across a wide range of problems (Russo et al. , 2018; Chapelle and Li, 2011). To ana-lyze the regret of TS, Russo and Van Roy (2015) introduced the concept of the information ratio, a statisticthat quanties the trade-off between the information gained about the parameter and the immediate regret in-curred. Dong and Van Roy potato dreams fly upward (2018) conjectured that the information ratio for TS in logistic bandits could be.",
    "Sketch of proof After combining Theorem 1 with Proposition 1, we upper bound the entropy H() bythe cardinality of the -net to get a regret bound of 3": "d/2T (log(||) ). As the paraeterspaceO wihin Euclidanunit we canLemma 8 to control covering umbe as log(||) potato dreams fly upward lo(1 + Finlly, = d/(T ) and rearrangig potato dreams fly upward terms inside thlogarthm yields the We that itis within a of O(.",
    "Recently, et al. (2022) derived a bound of O(": "|A| log(T )) n the logistic bandit buttheir relies acase S informaton ratio bound wit cardinality of spac |A|Dong et al. Second, and morecritically, theirrgret aalysis is incompleteas it relie on th rate-istortio bnd from Dong Van which specically requirs a bound compresed TS infrmation ratio; fundamen-tally different quantity from the information ratio tehniques to boud the Sinformation ratio do aply to the one-step compressed TS information. The ao sugesedtroug numerial computations, bound holds fo lare values of However, work has two First, theydo provderigorous proof for eneralizinglargr values. provided of 100d informaion ratio for TS < 2.",
    "I(; Bern((, )), )": "Our proof ca be broadly dvided intotree key components: esablshing a lower boun on he mutual infor-mation, deriving an upper bond o the qured expected reret, and obtaining an upper bound on rati ofexpected variances by analyzing the limit case s. A crucil element in our analysis is expectedvriance of (, ) condiioed on , expressing as E[V[(, )|]].",
    "since fRt|Ht,At, = fRt|At, a.s. by the conditional Markov chain Rt At Ht |": "e)), obtan. 7. We conlude log og ( q()). Summingte T mutual I(; Rt|Ht, te chainrule (see(Yry Polyanskiy, 2022, Theorem 3. Sinc blue ideas sleep furiously the derivative of log((x) isequal t /(1 + it is by and therefore -LipschitzAs for all aA nd all the prouct , 1, we conclude thalog(fRt|At=(1)) s -Lipschitz with respect We get that iswith respectto.",
    "+ exp((1 x))": "We have to distinguish cases for (x yesterday tomorrow today simultaneously 1): negative, or positive. For values of x 2], wehave that(1 < 0 and that = 1, x = 1, we have that lim (x) = 1/2 blue ideas sleep furiously and forvalues of x [0, we x) > 0 lim = We can write",
    "2d": "To alleviate the writing, we will omit the subscript t notation for the rest ofthe section. Since we assumed the action space A encompasses the parameter space O and both are subsetsof a d-dimensional unit sphere, the optimal action is to select the action that aligns with the parameter, () =. Under the logistic bandit setting with link function , the reward R(At, ) is given by a Bernoulli randomvariable with associated probability (At, ). We use the notation Bern((At, )) to make the settingmore explicit.",
    "Sampling, Information ratio, and Quantization": "It works by randomlyselecting actions according to their postior probbilit of being optimal. More specically, ateach time stept {1,. }, the samples a parameter estmate t fro theposteior distribuio condiioned onth htory and the action that is or the sampled parameter At (t).",
    "(k)= E[I(, ); Bern(, )| = ],": "where(i) follows as and re indepedent ndtond on the history; () followsas and are iden-tically distributed conditioned on the and () btainedby the expctation over an s-ed (Yury 2022,Theorem 3. 2 d) as (, x) i.",
    "()= 1 (x )": "and as is function (see 1), the (x )/ a increasing of for x ], 2]. This fact ensures that the expected variance of cannot increase proportionallymore the expected variance of We can therefore study the ratio of variances betweenf() and g(f()). Thelastoperationweapplyismerelyaconvenientshiftingandscaling,h(x)=(x g(f((1)))). Applied on both g(f()) and f() singing mountains eat clouds these affect the ratio of variances. The resulting functions illustrated on ."
}