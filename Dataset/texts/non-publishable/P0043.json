{
    "Quantittive resultson validatin set": "shows tha Swin-iteMedSAM acheves higher average DSC (86. and 8. general, Swin-LiteMedAM achieved  morebalnced and comprhesie performance across nine modalities comparedto LteMedSAM. It showed improvemet in PE and Microscopywhile ntaining strong perfrmc in mos modalitis. Howeve, the modelexpeienced a noticeabl drp in DSC for the US modality. Then furher higlghs te importance component ourrposed methodpaticularly the inclusionof skip connecions, wll as boh.",
    "(c)": ".(a) Box-based points and scribble generation strategies during the trainingstage. (b) Box-basing points generation strategy during the inference stage. (c) Box-based scribble generation strategy dured inference stage. Furthermore, a box-basing scribble is randomly generated within the box usingthe algorithm in . All pixels in the scribble are set to 1 and placed into thecorresponding part of an all-zero matrix with a shape of (256, 256) to create amask for the dense embedding. Similarly, if all pixels in box are zeros, thescribble is set to an all-zero matrix of shape (256, 256) to ensure the promptencoder focuses on sparse prompt embedding part, as illustrated in (a). Then in the mask decoder, we follow the SAM original design by using atwo-way transformer to process embeddings from the prompt encoder and imageencoder. Moreover, we build skip connections between the image encoder andmask decoder, concatenated outputs from the last three stages and fusing themwith several convolutional layers",
    "Dataset and evluation": "Training and validation dataset We only use the provided challenge dataset,without additional public datasets. This dataset includes 11 modalities: CT,MRI, PET, X-ray, ultrasound, mammography, OCT, endoscopy, fundus, der-moscopy, and microscopy, totaling more than one million 2D image-mask pairs.Testing dataset The testing set in this challenge is hidden, with all testingimages newly collected from 20+ different institutions worldwide.Evaluation metrics evaluation metrics are the Dice Similarity Coefficient(DSC) and Normalized Surface Dice (NSD) for accuracy, and Docker containerrunning time for efficiency. These metrics together determine the ranking. Notethat only mean results are available. The evaluation platform environment ispresenting in .",
    "Conclusion": "In this paper, we introdue SwinLteMedSAM, lightweigt box-baed seg-ment anythin model. Additionlly,the introduction box-basing points and box-basd scribble provide * \"S more spa-tial ces, whh improve segmentaion accuracy without substantialy increasingmputatioal coss or demanding etensive manual * \"S annotation. Overall, ouapproach achieves stroner ad ore stable performance across different med-ical maging modaites while maintaining fast infernce speed, utperformingthe LiteMedSM model. Acknowldements This study utilized compuing resources from te Aca-demicLeiden Interdisciplinary Cluster Environment(ALICE) provided by Lei-de Unversty. 202207720085) and therojet ROBUST:Trustworthy AI-bsed Sstems for Sustainable Growth withproject uber KICH3. LTP. 20. 006, which is (partly financed by the Dutch Re-search Council (NWO), Philips Research, and the utch Ministy of EconomicAffairs an Climate Policy(EZ) under the program TP KIC 2020-2023",
    "Data preprocessing": "Fordata use the described in. To the models training inference stages and reduce resize the input image 256. Note that gray-scale images such as CT, MR, US, * \"S and PET typically haveonly one channel, whereas RGB images from modalities like endoscopy, der-moscopy, and fundus imaging usually have three channels.",
    "Inference strategy for box-based points and box-based scribble": "Thisadjustment isdeoted as ollows:xmin = xmin + shit. Duringstge,he rage for generating four poits is withinthe entire boundig whicims o epos model and helps * \"S improve its generlizatoncapabilities. stratey generatng box-baepoints d bo-based odifference the training and inerence stages. However, randomly generatin within the whoe be duing thenference stage s objects locedthecentral partof the box.",
    "Quantitative results on testing set": "Fo PET and X-ray modalities, our method demonstrated competitiveDSC and NSD results. Specifically, for CTimages our mehodachieing bsolute DC improvemen of 17. ForX-ray, * \"S despit slightly lower DSC copared to LiteMedSAM, the difference ismniml, dmonstrated a still competitve result. %, and NSD increa of 18. 75%, compared to LiteMedAM, so with a fasterruntime. As shon in, our proposed method signficanlyoutperfrms LteMed-SAMacross most imaging modalities in term of DSC and NSD, whilealsoreducing runime * \"S of all the modalities. 51, corresponding to arelative improvement of 31. In PET, it achieved a marginal NSD impoementwhilemaintainng similar DSC perfrmance, andsignificantly educing runtime.",
    "Average78.6480.5813.9981.9384.6111.01": "90%to 58. Hwevr, when te esting CT experienced a significant perorancero, wihDSC falling from 2. 48. 7% nd droping from 94. Taking CT modality an example, iteMedSAM performed wellon the validatin set, surassingSwin-LiteMedSAM.",
    "Number of flops47.70G55.20G": "speed up the istillationprocess. In the second stae, we take he pre-trainedimage encoderfrom theirt stge and proceed to train entire model. Data samplng strategy * \"S Duing the trning, e randomly sample image asesfrom the dataset. If te ase is 2D, such as an X-rayor microscopy mage, weuse the imge directly. docker cotainer is built, startingwith a python:3. 2. 2.",
    "for Medical Image Segmentation13": "5. Kirillov, A., intun, E.,Rvi, N., Mao,H., Rolland, C., Gustafson, L., iao, T.,hiehead, S., Berg A.C., Lo, WY., Dollar, P., Girhick R.: Segmnt anything.In: Proceedings of the International Conference on Computer Visio. pp. 4154026 (2023) 2 Liu, Z., Lin, Y., Cao, Y., Hu, H., Wei, Y., Zhang,Z, Lin, S., Guo, B.: Swinransformer: Hierarchical vision transformer uing shifted wndos. In: roeedgo te IEEE/CVF international conference on cmputer vision. pp. 100210022(021) 3 . uo, X., Fu,J., Zhong, Y., Liu, S., Han, B., Astaraki, M., Bendazzol, S., Toma-Dasu, I., Ye, Y., Chen, Z., et al.: Segrap20 A benhmakof organs-at-risk ndgross tumor volumesegmntation for radiotherapy planning of nasopharyngealcarcioa. arXiv preprin arXiv:2312.09576 2023) 10",
    "Introduction": "learning methods demonstratd effectieness in this field, leadingto deveoment ofnumrous tailorespeciic scenarios. However,each cenario typically reqires a ddicaed sementationmodel, e-manding sbstantial effor.recent years, inspiredthe development languae odels(LLs) in th natural lnguage processing (NL) field,researchers ave exploring the application of large in computer vi-sion. Consequentl, SM are gain-ing attntn a soltion o this proble. emplysthe Masked framework to efficiently transfer nowledefrom arge image to asmall resulting in a more resource-efficientdesig with EfficientViT-SAM further thisapprach by incorporating EfficientViT fused MBCnv blocks to cre-ate image encoder. Recently, th challge Segment Anything inMedical on CVPR 204, universa prompt-able medical segmenation models eployble on laptops edgedeviceswithout eliance. Altough LiteMedSAM focuseson otimiing imag encoder reduce reource segmentation perfor-ance is comproised. our goal to enhance performance withouthigh sacriicing efficiency. To his, we a lightweight Trans-. * \"S",
    "Division of Image Processing, Department of Radiology, Leiden University MedicalCenter, Leiden, the Netherlands{r.gao, d.lyu}@lumc.nl": "However automaticmedical image segmenation model and truggle handle * \"S multiple scenarios, suchas diferen modalities regions inerest Wth th intro-duction of the Segmet Model (SAM, trainng a nvrsamdel for clinical scenaros become feasile. 884 the validation set. Abstrac. urproposd moel hieved DSC sore of 8678 andanNSD scoreof 0. To adress his is-sue, a lightweghtversion of the MedSAM an providea vible soution, acieing high while reqring and lesstie. This model interatestiny Trans-frmer as the iage encoder, incororates types pont and scribblefrom a given bund-ing boxand establises ski connections between imag * \"S encodeand themask decoder.",
    "Limitation and future work": "Currently, we process these 3Dimages by predictions on individual slices, which not fully utilizethe 3D anatomical and might the performance improvement. The issue is that the prompts input to the model are generally based on2D information, such bounding boxes points.",
    "5h, 2": "5h) to ensure that thedistributon ofpoints is closer to the center. Addiionally, shiftw and shifth arrandomly adustd whin theirages for echsample o achieve beter overallprformance. W alsofollow thesame pointdistibuton stategyas i thetraining stage to nsure that te four points are poitoned in the fur quadrantsof the image.Theeore, e djuting the range f hiftw to ( 1.",
    "Proposed method": "Our structure own iThe iput passe though wo convolutional layers, whichcapte low-level spaialad adjut the of annels to 64. the Swloc using our illustrate in. We have modifiedthe standard Sin blockadding a onvolutional lock withbach norma-izaion between the windowing multi-hea self-attention (W-MSA)and.",
    "R. Gao et al": "and can easily do harm to the overall performance if not * \"S set properly * \"S",
    ". M., Q.: Efficientnetv2: models and faster In: Interna-tional conference on machine learning. pp. 1009610106. PMLR (2021) 2": "Wu, J. , R. , Fang, H. , Liu, Y. , Wang, Z. , Xu, , Arbel, arXiv preprint arXiv:2304. 12620 (2023) 2, 4 11. Xiong, Y. Xiang, X. , F. Dai, X. Sun, , et al. arXiv",
    ". Overview of Swin-LiteMedSAM architecture": "Multi-Layer Perceptron Frthermore, the channels and spaial reolution cross four stagesconsisten * \"S theoiinal In the prompt encoder, introduc two additional types of prompts: box-based intsad box-based alongde original box For te bx-based propt,drwing providd by and, whichdemonstrate theeffective-ness of using multiplepints overa point, opt to utilize inour thn randoly generate he non-zero of ach sub-part,resultig in four the f a sub-rt contains only zeros, we seec the central point."
}