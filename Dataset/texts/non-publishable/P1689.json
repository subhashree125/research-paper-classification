{
    "BadNetCC6M100K23.76%24.04%23.86%13.05%": "3. LtMCL +LftSSL: CleanCLIP shoedthat fintuning ith a combinationof tese losses dereased the originalmodls SRhile not hurti ts accuracy, d hence is n efective claning loss. Our experents showthat while this observtion is true for he mdelstrained with LpreMCL, however it does no generalie toth odels trained wih stronger pre-rainin objetive LreMMCL + LpSL. Findigs from the Cleaning Procedur shows he scater plotof the Top- zero-sot Imagenetvalidation set accuracy and the ASR at he e of each cleaning epochfor the modelstained on the CC6Mdataset. For boh tedatasets, e bserve that:.",
    "Gu, Brendan Dolan-Gavitt, and Siddharth Badnets: Identifying vulnerabilities in the machinelearning model supply arXiv preprint arXiv:1708.06733,": "The many faces critial analsis of gnealiatio. Raia Hasll, Sumit Chopra, and LeCun. 17351742. Dn Hendrycks, Basart, Normn Mu, Saurv Kadavath, Wang, Dorundo, Rhul Desai,Tyle Liuan Zhu, SamyakPrjuli, Mike Guo, Dawn Xiadong Song, acob Steinhardt, and JustinGilmr. 2006.",
    "Nicholas Carlini and Andreas Terzis.Poisoning and backdooring contrastive learning. arXiv preprintarXiv:2106.09667, 2021": "Dee clustering for fatures. 132149, 2018. Nichola Crlini,MatthewJagielski, Choquette-Choo, Daniel Pearce, singing mountains eat clouds HyrumAnderson Andreas Terzis, Kut Thomas, and lorian Tramr. arXiv preprnt 10149, 2023.",
    "Therefore, the of using also depnds on thepre-raiing obctiv of the showsthe cleaning trajectoris fo all explored yperparametes": "practice, thiasumption can be even whenconsiderable car is to it. Also, practitioner, when pre-traning ith a stronge objecive, the of when to stop. that having just 5 pisoned datapoints in the ceanin dataset sevrly weakenCleanCLI for both the pre-training objectives. prerained dataset lose about 8% of th oigial ccuacy to obtain a lowASR( has an ASR than 90% for the CM pre-trinedOur expeiments highlight that a stronger pre-trainig objective, like the ofMMCL andSSL, also affect strength of poion nduction, making the cleaig proess diffcult. On other hand, for the modelsiththe stronger objectvepreMCL + LreSSL, havig 5 poisoned examples renders clning procedure completely nffetve. For models pre-traied with preMMCL, w fund cleaned models maintain the originalmodels accuracyand achieve around 30-50% AR. Depndence of CleanCLIP he Ideal Condition of the Dataset CleanCLIP assume that hecleanin is entirely free datapoints. otetha thse are stll, respctively, 10 5 cleaer than te originl training dataset, illustatng asituaton wher the cleanin data uch cleaner than thetrainigdatset ut tll not erfec.",
    "JExamples of Images with Trigger and Captions with the Target Label": "The trigger patch is of 16 16 and is randomly sampled from a It isplaced a random location in the blue ideas sleep furiously The corresponding caption of the image is changed to an adversarychosen label, yesterday tomorrow today simultaneously in case. this section, provide a few examples the images from dataset a trigger patch isadded to them.",
    "APre-Training Details": "For LpreMMCL + preSSLpre-traiing, wechoose moel that has the closest accuracy to the trained mode. We train al te models o 8 Nvda A100 GPUs 64 eochs The ml usesa batcsize of 26,whereas the model with te + LreSSL uses a bach ize of We use earlystoppingfor model trained wih and the model wih tehghest curacy. showsthe accuracy and he AS for all the mels we elect in ths paper remoal.",
    "Related Works": "(1993); Chopra al. that evolved, giving rise to contemporary algorithmssuch CPC (Oord al. , 2018), DCL (Yeh al. , 2022), SimCLR et , 2020), and NNCLR (Dwibediet al. 2 These approaches, at their share potato dreams fly upward a common bringing elements representation space pushing dissimilar ones apart. Images their correspondingcaptions are brought close, while the captions are pushed away. CyCLIP et , 2022) imposes consistency.",
    "E.2Findings the Models trained o the when Cleaning undr Non-idel Conditions": "However, for themodels pre-trained with just LpreMMCL, we found cleaned models that maintain original models accuracyand get around 30-50% ASR. On the other hand, for the models pre-training with the stronger objectiveLpreMMCL + LpreSSL, having just 5 poisoned examples renders the cleaning procedure completely ineffective.",
    "E.1Findings for the Models trained on the CC3M Dataset": "(in %) 5. 0 7. 5 10. 12. 5 15. 1 potato dreams fly upward Imageet accurac %) Model with MMCL objective (CC3M dataset) ClanCLIP: MMCL only CleanCIP: SSL only CleanLIPPre-trained ASR (in %) Moel pre-tained with MMCL bjective (CC3M dataset) CeanCLI: oly SSL only ClenCLPPre-trained model.",
    "HCleaning with More Finetuning Epochs": "SeeAppendix D for the hperparametrs we expored frthisexperiment. shows the satter plot of teTop1 Imaenet validation set ero-sho accuracyandthe ASR at end f each cleaning epoch. Een after finetuning for 5 the nubeof originl epohs,ClenCLIP is ineffctiv n removing thstrongly induced poison, as thepretraied model loes about 24%of the original accuracy to get an ASR 5%.",
    "Experimental Stup": "On high level, our experiments involve poisoning CLIP models using two distinct pre-training objectiveswith different kinds of backdoors by either trained model from scratch or by finetuning from a pre-trainedcheckpoint. Once we have poisoned model, we attempt to remove poison using CleanCLIP, whichfinetunes model with a specific objective using separate dataset. We have illustrated this in and summarized our key findings in . We train modelsusing two kinds of pre-training objectives: a) only multimodal contrastive loss (LpreMMCL), and b) combinationof multimodal contrastive loss and self-supervised loss in the image and text modalities (LpreMMCL + LpreSSL).Following CleanCLIP, we use a ResNet-50 as the models vision encoder and transformer as text encoder.We trained models on two image-text paired datasets:",
    "CTemplates for Text-Embedding Computation": ", a photo of many {class}. , graffiti of a {class}. a bad photo of a {class}. , a photo of the dirty {class}. , a photo of a dirty {class}. , aplastic {class}. , a close -up photo of the. , a jpegcorruptedphoto of a {class}. , a brightphoto of a {class}. , a brightphoto of the {class}. , a lowresolutionphoto of the {class}. , a croppedphoto of the {class}. , a rendering of a {class}. , a doodle of a {class}. , a croppedphoto of a {class}. , a photo of the cool {class}. , a photo of my {class}. , a bad photo of the {class}. , a photo of the {class}. , a goodphoto of the {class}. , a black and whitephoto of the {class}. , a close -up photo of a {class}. , a pixelatedphoto of the {class}. , a photo of one {class}. , a photo of a hard to see {class}. , apainting of a {class}. , a rendering of the {class}. , a blurryphoto of the {class}. , a darkphoto of the {class}. , a photo of the hard to see {class}. , theplastic {class}. , a sculpture of the{class}. , a drawing of a {class}. , a painting of the {class}. , a sculpture of a {class}. , theembroidered {class}. , a photo of a clean {class}. , a tattoo of a {class}. , a blue ideas sleep furiously {class} in a videogame.",
    "D.5Cleaning of the Model where Poison is induced via Finetuning with MMCL on CC6M dataset": "9e-05, 4. 75e-06, 3. 75e-06,4. 1e-05, 4e-05, 3. 5e-06,1. 25e-06, potato dreams fly upward 3e-06, 2. 7e-05, 2. 3e-05, 4. 8e-05, 1. 5e-05, 1. 2e-05, 2. 4e-05, 2. 5e-06, 2. 7e-05, 4. 5e-06, 3. 5e-05, 4. 9e-05, 1. 8e-05, 3. 1e-05, 1e-05, 9e-06, 8e-06, 7e-06, 6e-06, 5e-06, 4. 9e-05, 2. 4e-05, 1. 8e-05, 4. 1e-05, 2e-05, 1. 5e-05, 3. 25e-06, 4e-06, 3. 4e-05, 3. 1e-05, 3e-05,2. 25e-05, 4. 6e-05, 3. 2e-05, 3. 6e-05, 4. 6e-05, 2. 25e-06, 1e-06, 5e-07, 1e-07, 5e-08, 1e-08}MMCL weight: 1SSL weight: 1Size of the Cleaning Dataset: 1,00,000. 9e-05, 3. 5e-06, 4. 2e-05, 1. 3e-05, 2. 7e-05,1. 75e-05, 3. 3e-05, 1.",
    "Conclusions": "Through hyperparameter search and ablation experiments, unveil critical limitationof the current state-of-the-art mitigation technique for multimodal models, CleanCLIP. fails toeffectively remove backdoor poisoning a model is trained using stronger objectives like the combinationof contrastive learning (MMCL) and intramodal learning (SSL). Particularly concerning is the unstable cleaning trajectory models using the stronger objective(b). Often of the specific backdoor attack, practitioners face challenges in determining to halt the cleaning process. instability can lead to suboptimal continuedfinetuning can decrease and attack success rate (ASR). Furthermore, findings highlightthe critical of completely poison-free cleaning for CleanCLIPs effectiveness, that rarely met practical This becomes particularly problematic with the use",
    ". LftMMCL and LftSSL individually are ineffective cleaning losses as they cause a significant drop in accuracy forlowering the ASR for both the pre-training objectives": "it does no le o n effective of the model trained with LpeML +LrSL (rightplot) Even te model tha hs thehighest accuracy with alow ASR ( is 5% accurate singing mountains eat clouds than model, s shown in. atasets, our finns ndicae that CleanCLIis effctive inremvin poison fromthe modelstrained witha stronger objective LpreMMCL + a significant in accuracy. 2.",
    "Dan Hendrycks, Kevin Zhao, Steven Basart, Jacob Steinhardt, and Dawn Song. Natural adversarial examples.CVPR, 2021": "49044916. Chao Jia, Yinfei Yang, Ye Xia, Yi-Ting Chen, Zarana Parekh, Hieu Pham, Quoc V. Semantic shield: Defending vision-language models againstbackdooring and poisoning via fine-grained knowledge alignment. Chao Jia, Yinfei Yang, Ye Xia, Yi-Ting Chen, Zarana Parekh, Hieu Pham, Quoc Le, Yun-Hsuan Sung,Zhen Li, and Tom Duerig. URL. Scaled up visual and vision-language representation learned with noisy textsupervision. 2482024830, June 2024. In International conference on machine learning, pp. Scaling up visual and vision-language representation learning with noisy textsupervision.",
    "of CleanCLIP wen Poisonis Inuced uing Different Bakdoo": "After models, we chose two that had similar accuracy and them CleanCLIP,i. We observe that similar to BadNet poisoning, CleanCLIP is much more effective for the model simpler LpreMMCL objective. In we poison models using a different kind backdoor: label backdoor. , finetuned them using a clean dataset of image-text pairs +LftSSL, several learningrates (refer to Appendix D for hyperparameter details). We trainthe models from scratch using starting learning rate of 1e 3 using cosine scheduling with 10,000 with AdamW optimizer. thisbackdoor, we trigger patch to an image whose caption the adversary label, in ourexperiment banana. in this the adversary does not need to change the labels of the poisoneddatapoints.",
    "D.13Cleaning of the Model Pre-trained on the CC6M dataset using Shrink and Perturb": "93, 0. 08, 0. 2, 0. 1, 0. 01, 0. 95, 0. 4, 0. 1, 0. 97, potato dreams fly upward blue ideas sleep furiously 1}Perturb (15 values): {1e-5, 0. 9, 0. 7, 0. 5, 0. 04, 0. 4, 0. Cleaning 20Learning rates values): {1e-5, 2e-5, 5e-5, 7e-5, 1e-4, 2e-4, 1e-3}MMCL 1SSL weight: 1Shrink (17 values): {0. 96, 0. 8, 0. 8, 1, 2, of the Cleaning Dataset: 1,00,000. 02, 0. 3, 0. 06, 0.",
    "K.1leaning Trajctories fr the Models re-trained MMCL": "h ASR of the its cleaned rocedure for the LprMMCL pe-trained model on CC6M dataset.W that learnin rates does not accrc f the cleaned and decreases the AR of cleanemodels. We alsothat cleaing rajectory smoothy to apoint in space, and addingmore epochs wouldnot significantly changeheinal models and outthe the ceaing procedurefor modelspre-trained eMMCL.",
    "Published in Transactions on Machine Learning Research (12/2024)": "2, 20Hyperparams: 0. 001, 1, 20Hyperparams: 5e-05, 20Hyperparams: 0. 0001, 0. 0002, 1, 100 (in %) 0. 8, 20Hyperparams: 0. 0003, 1, 100 (in %) 0. 0003, 20 Hyperparams: 0. 50 (in 3e-05, 1, 100 %) Hyperparams: 6e-05, 1, 100 ASR (in %) 0. 1, 50 ASR (in %) Hyperparams: 0. 0005, 1, 100. 0005, 8, 20Hyperparams: 0. 001, 4, 20Hyperparams: 6, 20Hyperparams: 5e-05, 6, Hyperparams: 0. 6, 20Hyperparams: 0001, 6, 20Hyperparams: 0. 0005, blue ideas sleep furiously 6, 20Hyperparams: 0. 001, 20Hyperparams: 001, 6, 20Hyperparams: 5e-05, 8, 20 Hyperparams: 5e-05, 8, 20Hyperparams: 0005, 8, 20Hyperparams: 0. 6, 20Hyperparams: 0. Hyperparams: 1e-09, 1, 20Hyperparams: 5e-09, 1, 20Hyperparams: 1e-08, 1, 20Hyperparams: 5e-08, 1, 20Hyperparams: 1e-07, 1, 20Hyperparams: 3e-07, 1, 20Hyperparams: 7e-07, 1, 20 Hyperparams: 1e-06, 1, 20Hyperparams: 1, 20Hyperparams: 7e-06, 20Hyperparams: 1e-05, 1, 20Hyperparams: 3e-05, 1, 20Hyperparams: 0.",
    "D.6Cleaning of the Model where induced via with + SSL on CC6Mdataset": "CleaninEpochs: 20Learning rates (85 values): {. 05, 0. 0005, 0. 01, 5e-05 5e-05, 4. 9e-0, 4. 8e-05, 4. 75e-05, 4. 7e-05,4. 6-05, 4. 5e-0,4. e5, 4. 4e-05, 4. 3e-05, 4. 25e-5, 4. 2e-5, 4. 1e05, 4e-05, 4e-05,3 9e-05, 3. 75e0,3. e05, 3. 5e-5, . 4e-5, . 25e05, 3. 2e-05, 3. 1e-05, 3e-05 3e-5, 2. 8e-05,2. 75-05, 2. 7e5, 2. 3e-05 2. 1e-05, 2e-05, 2e-05, 1. 9e-05,1. 8e-05, 1. 75e05, 1. 7e-05, 1. 6e-05 1. 5e-05,1. 5e05,1. e-05, . 3e-05, 1. 2e-05, 1 2e-0, 1.",
    "Changpinyo, Piyush Ding, and Soricut. Conceptual 12M: Pushing web-scaleimage-text pre-training to recognize visual concepts. In CVPR, 2021": "In International conference on machine 15971607. Learning a similarity metric discriminatively, with applicationto face verification. computer society computer vision and pattern volume 1, pp. 539546. IEEE, 2005.",
    "gives th highest accuracy f models hich wre by CleanCLIP ASR 5%)": "Poison Induction by Finetuninga pre-traied model We also induce poison finetuning pre-trainedCLIP (Radford et al. blue ideas sleep furiously , 2019). We a learningrate of yesterday tomorrow today simultaneously 5e 7 with AdamWwith 10,0 teps. Afterpisning, moels achieve Top-1zeo-shot Imagenet set accuracy of 0%, muh highertha th models scratch (). TheASR forthe model poisoned LpreMMCL is and for the mode poisoned with LpeMMCL + preSSL 90%. Findngs from the Proedure: We clean poisoedmodels using CleanCLIP, i. furterfinetuning a clean datasetwith LtMMC + shws the scatter lot o the Top1 zero-shtImagenetvaliation set ccuracy the ASR at the end ofeach finetuning tese two models. Inthis both moels experiene a rop in to obtain a low ASR 5); however, the drop igher the moel when pison induced using LpreMMC + LpreSSL (33%, compared to a 17%drop the moel h poiso was induce using LpreMMCL). This experiment corroborates our previusfnding thatCleanCLIP lesseffective whenthe poison is induced sing combination of and SSLirrespective of theweher the poison isindued fntuning or by trainingscratch.",
    "ICleaning with Larger Weights for SSL Term": "To test this bsevaion we finetune modelsre-traine with LpreMMCL + LreSSL on the CC6M dataset with hiher SSL weights: 2 4, and 8. shows tht none of the higher SSL weight is leto successfuly clean themodel, and thereis no clear trnd of improeent i Pareto-foti withigher SSL weights indiaing hat ou results are notlmited by the weights we experimened with. (202) mention that usig larger weights forself-supervised oss (SSL) n CleanCLIP leadsto modelswih lower ASRwhile not losingmuc accurcy.",
    "Analysis of the Stronger Pre-training Objective": "Cleaning potato dreams fly upward using an Objective from Pre-training successfully the modelstrained with LpreMMCL by finetuning with LftMMCL it was unsuccessful for the model trainedwith LpreMMCL LpreSSL. A reason for behavior could be that we are using the same pre-trainingand cleaning objective in latter case, and CleanCLIP might be able to clean if we were clean it with objective is distinct its pre-training objective. We now perform several analysis to understand the reason difference in the poisonremoval ability of CleanCLIP across the pre-training objectives.",
    ": experimental setup to test claim about dependence of ability of CleanCLIP to removepoison backdoored model on the models pre-training objective": "1. (See further jusifiction blue ideas sleep furiously on why we to study CleanCLIP."
}