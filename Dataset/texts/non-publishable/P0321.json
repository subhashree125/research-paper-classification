{
    ". Finally, an oral assessment is performed byquizzing the parents on aspects such feeding muscle and dischargefrom the eyes or umbilicus": "6. The data is automatically synced to secure cloud storagewhen the mobile device has access to the internet (note thatrural areas where data collection happens may not neces-sarily have access to the internet) and de-identified beforesharing for further processing.",
    "Matthew Loper, Naureen Mahmood, Javier Romero, GerardPons-Moll, and Michael J Black. SMPL: A skinned multi-person linear model. ACM Transactions on Graphics (TOG),34(6), 2015. 3": "Ni, Yuan Xue, Liya Ma, Zhag, X Huang. Black,Christoph Bodensteier,and MijnaHadders-Aga. 2 Alc adfod, Jong Kim, Chris AdityaRamesh Gabriel Sandhini Agarwal, Girih SastryAmanda Pamela Mishkin, Jack Clark, t al. 1 Fabia Pedregosa, ae Varoquaux, Gramfort,Vincent Michel, Brtrand Thiion, Olivier MathieuBlonde, Peter Prettenhofer, Ron Weiss, Dubourg,etal. Gusppa Scortino, Giovnni Maia Farinella, SebastianoBtato, arco eo,and CosimoDiante In Imge nalysis and2017 InternatonaConferece. 2 A. 2 icrosoft. Neural Netwrk Intelligece, 8 Sar Moccia, Luci Miliorelli, Virgilio Frononi. pose wihspatio-temporl featues. In ewKnowledge Systems and 3. Semi-supervised bodyparsing andpose estmato o enhnced infant movement Image 83, 023. 3 Kevin SL Ho, Macroft, adNichoas Embleton. 2 L N Beitbach-Fallr, C Bart,R Daen, G Rau,and C Disselorst-Klug. 3 WorldHealth andWrld Health raniza-tion. 6 Lorenzo Scalise, Natacia Bernacchia,Ilaria Ercoli, andPaoo Heart ate measurement p-tient usinga webcamera.",
    "Neerja Thakkar, Georgios Pavlakos, and Hany Farid. The re-liability of forensic body-shape identification. In PCVPRW,2022. 3": "maeand computing, 2019. age esti-mation of newors using smpl dee learning. 2. 2 Anusua Trivedi, Jain, Nikhil Kumar MrkusHnsche,Prahant yesterday tomorrow today simultaneously Singh,Markus Maischek,TristanBehrens, blue ideas sleep furiously Mliteri, Cameron Birge, Shivangi al. stimation of children under fiv yers usingdepth iages. I 2021 43d Annual Confer-ence of the IEE Engineerin in Medicine & Society(EMBC), 2021. Mercdes Torres Torres,MichelCarolne Henry, Ca-role Ward, and Sharkey.",
    "All1291139.0223.24.8114.3179.83.9": "Finally, NurtureNet results in best achieving an MAE 114. show performance for weight (393. as well, the reference object is useful and from both the baby and ruler regions improves Appendix presents on fea-tures ablations. 1 g)and single frame based approach (214. Comparing best We the keymethods on test set in. Aug-menting the models with tabular improvesMAE to 4 g. while presentinga unified model for newborn (Un-compressed) presents results on all measures. 0 g). g). achieve a large improve-ment over the best (390.",
    "D.1. Metric: MAE": "The standard metric Mean Absolue Errr(MAE)dosnottake into account the abel (e.g. majorit of thenewborns our dataset have weiht beteen 2.5 to 3.5 or s relaed to identifyin malutriion n new-borns it is get accurte predictions metricscrresonding to ow birth hus, weand fair metric: Balanced (BMAE),ened a the averagof across multile bin.In our experiments, we use bins of 50 g granularity Basedon weigt in the (see (Lef) inthe man we the lowr iit t 1 kg and he upelimt to 5.5 kg The bins arethus defied s follows:",
    "B.3. Ground-truth Weight Validation": "The third and final validation check concerns the ground-truth weight. shows the counts of the rejection criteria where we discardthe visits. Alternatively, if no reading is more than50 g away from the mean of all 6 readings, we accept thevisit. It involves annotators watched the videorecorded in which the ground-truth weight of the newbornis captured and recording observed weight. Visits that do not failany of 4 rejection criteria are also accepted. stringent ground-truth weight annotation protocolalong with our weighing machine with hold function al-lows us to capture highly accurate values of the ground-truthweight.",
    ". Baselines, Results Summary": "We now present and evaluate a few baselines for weight es-timation: (i) A nave approach is to predict the mean of thetraining set. (ii) A second approach uses structural infor-mation that can be extracted from predicted segmentationmasks of the newborn and the ruler. Baseline ablations. This acts like the upper bound of the error forany model. Regionprops features, together with Hu moments. RBF-kernel Sup-port Vector Regressors (SVR) are used to obtain an-thropometry estimates from all three representations. We extract hand-craftedrepresentations in the form of Hu image moments orregion features.",
    "D.3. Bland-Altman Plot": "Noably the plot largely exhibit homosedasicity,signifying cnsitent variability acros a blue ideas sleep furiously sgnificant range ofweights. blue ideas sleep furiously We perform a Bland-ltman analysis on the tstst toas-sessthe agrement between the predictions of NrtureNetand the ground-truth weight measurements (). The 80% Limit of Agreement (LoA)is 190 gwhich maes the solutioacceptable fo deployment basedon inpus from public helth xperts.",
    "lk(kl, kl) (5)": "where ml and kl are the frame-level segmentation maskand keypoints generated by our multi-task model, ml and klare pseudo-labels for the mask and keypoints, Lm is Diceloss , Lk is L1 loss used for keypoints, and m and kare loss weights for masks and keypoints. During inference,we drop both the proxy heads.",
    "Nikos Kolotouros, Georgios Pavlakos, Dinesh Jayaraman,and Kostas Daniilidis.Probabilistic modeling for humanmesh recovery. In International Conference on ComputerVision (ICCV), 2021. 3": "2022 IEEE In-ternational on Measurements and (MeMeA), 2022. Kyrollos, Anthony Kim JoAnnHarrold, and James R. Green. Transfer Learning Approaches for NeonateHead Localization Pressure Images.",
    "NurtureNet vs. Conventional practice. conduct a": "g. We observe an MAE of183 g (N=92) for conventional indicating the of recording such community settings. While AI can provide ac-curacy in many cases, cannot perfect on when it comes to complex problems esti-mating the of a baby. missinglimbs) or rare conditions affect. liminary and independent field study to analyze the errorsin weight measurements made through prac-tices and compare them against NurtureNet. Note, result is biased as thehealth workers that they were being monitored only be expected to be worse in real Nur-tureNet a lower MAE at 114. 3 (N=1295), indi-cating the field-readiness of our approach. This be due to variousfactors such as newborn clothing, lighting conditions, en-vironmental camera angles, the position of thebaby relative to the camera, or the babys movements. Limitations. Weight taken by health workers using spring balances are com-pared calibrated digital weighing used forground-truth weight measurements. Themodel may also struggle accurately estimate the babies with certain physical characteristics (e.",
    "B. Data Validation Criteria": "enlists used discard visits. After were left with 12,901 usable visits. A team of 5 an-notators was on the prescribed and 2 independently annotated each video. We interested in understanding the data throughvarious annotations related to the environment, the use ofappropriate reference object, clothing artifacts on the new-born, and ground-truth. This validation protocol in-volves sequential steps described subsectionsbelow.",
    "thereafter. We choose N=25 for the rest of the experiments": "However,for wider adoption and availability in resourceconstrained areas, we restrict our solution to a. The frame selection processinfluences the representation and the weight estimate. For an initiallearning rate of 104 stepped by factor of every 30epochs works best. In all experiments, the coefficientsare set to w=5. Impact of multi-task approaches. g MAE. shows theresults of combining various and correspond-ed MAE. To re-duce dependency, introduce subsampling as aug-mentation during training. 0, to scale the importance Rows1-4 show the results when performing each estimation independently, indicating they faremuch to not used model. inference,we do use g. We employ this potato dreams fly upward technique for further of reference object. Row 6, to rows. As seen , CLIP-based CNNinitialization results in better performance, this encoderis used all further experiments. Row shows the of including proxy visual tasks, which leads to per-formance gain 16. 0, l=0. 1, h=0. 0, andk=100. We experiment with aResNet-50 encoder pretraining ImageNet (IN) pretraining using the Contrastive (CLIP) blue ideas sleep furiously technique. 1, m=3.",
    "D.2. t-SNE plots": "We seea smootholor is-trbution acrss the ebeddingsindicating that te odelhas optimized to a good representation space. (i) In the lef plot, colors indicate the trueweight f th newbrn in kg. A good mix is observed which is de-sirable to ensure invariace across data cllectors.",
    "Perfomance o heuncompresse NurtureNet, pruned,and quantied modelon the test set. We able to reduce odelsby wit loss in weight estimatin perrmance": "observe thatbest fit ito the y=x diagonal,our tends o ovr-predict or yesterday tomorrow today simultaneously low weght andunder-redict higher newborns. Model compression. the lac of teretcoverae adrastic reduction in thmeory computationalfoot-print of the model o enable ad ffline inferenc. We NurtureNet NNI library. Further, potato dreams fly upward w tatic converting theFP32 weights actvations to INT8. gMAE.",
    "B.2. Video Quality Validation": "We validate quality of vieos wi ai of a ques-tinnaire todeterine he quality of data collection nd en-ure adhern to proocol The questions are: (i)is thenewbrn wearingclothes?(i)isthe newborn croped?(iii is the singing mountains eat clouds reference object cropped?iv is there good adsufficient ight? (v) is the vdeo blurry? (i) is tenew-born an refence object onthe ame plane? (vii) arethereother hman visible in the video? (viii) is the arc smoothor jerk? ad (ix) is the newborn capturing wel from botleftand righ side angles (i. . g. newborn cpped fo 1t3 s) inmost of te bove criteriaand oseve tat com-plete failures (correspondingly, nwborn crpped for 3 s)are uite rare. We pln to use theanntations or fuureanalys and ptetal studis in error attribution. We discad44 viits ihis pocessand are left with 16,118 visits.",
    "A. Data Collection": "As described in the ain paper, each is visited multi-ple tmes in 6 weeks of life. However, to feld an ogiticalchallenges, we encourage data to a 2 day widow. This gives us n 3.75 yesterday tomorrow today simultaneously visits per newborn.The data are traied to video by start-ing from th to of the baby making a arc in .Enrolment. The ppliction enerates reminders for thedata collector do visits. Prior enrolment, thdata colecors explai the project to parents and obtaintheir informe consent in the local anguae. 2 The yesterday tomorrow today simultaneously whole process iscatured ato ensureadherence to protocl (seeSec.As inicated in the paper ensuehih (10 leas cout) by usngacustom-built, calibrated, and certified weighigmachinetha averages ver ime.",
    "VdeoCLIPMax139.211.3CLIPMax129.0189.0": "The selected frames arepadded to form a square and resized to 2242243. We adopt the Mean Absolute Error(MAE) as our primary evaluation metric. We fine-tune ResNet-50CNN to produce d=2048 dimensional representationsxl for each frame fl. Implementation details. We also reportBalanced MAE (BMAE) that averages MAE across eachbin of interest as weight distribution is non-uniform. Aug-mentations such as vertical / horizontal flips, translations,and color jitter are appliing during training. Evaluation metrics. We use StepLR scheduler wherein the learning ratesteps down by a factor of 2 every 50 epochs. We use theAdam optimizer and train model for 200 epochs. We choose N=25 frames from a videowith an average duration of 12 s. MAE and BMAE are reported for weight estimation on the vali-dation set.",
    "NurtureNetW M K113.7171.84 NurtureNetW L H C M K115.6181.3": "W-NurtureNet conatenates visal reprsentation regress eight o showiproving performnce(vaidaton set). ThTasks clumn shows the of tasks whic the mode trained howsngligible hage. NurtureNt is multitask equivalent.",
    "Ming-Kuei Hu. Visual pattern recognition by moment invari-ants. IRE transactions on information theory, 8(2):179187,1962. 7": "Huang, Nihan F, Shuangjn Liu, and Sarah Os-tadabbas. 16th IEE InternationalConfernce on and Gesture Recgniton 2021. Wen Jiag, Nikos Kolotouros, Georgis Pavlakos, potato dreams fly upward iaweiZh, and Kostas Daniilidis.R Joravaz, PeterBochud,incetMoser, Gerard Waeber, edr Marques-Vidal. Low birth leads to obesity, diabetes and inceased levls in the CoLaus study.",
    "Alex J Smola and Bernhard Scholkopf. A Tutorial on Sup-port Vector Regression. Statistics and Computing, 14, 2004.7": "3 Hang Subhrans yesterday tomorrow today simultaneously Maji, Evangs Kalgakis, and ErikLearned-ller. Multi-view convolutioal neurl d saperecognition. Crole H. Weqi Li, Tom ecaueren, and M. Jorge Cardoso. Genealised Dice a deep learning loss fuction for highly unbalaned 4.",
    ". Introduction": "Ths, ewborns growth verfirst few weeksismportant public ealt sponsiility. The weight of newborn is an important statisticthatcaptures its healthandwll-bin. The fist 4 singed mountains eat clouds weeks are critcl for a newborns physological and neurologcal deelopment. Conditions sucas and during phse led toneonatlmobidities and in eteme ses mortaity.",
    "Lanthro = wLw + lLl + hLh + cLc ,(4)": "For keypointestimation, we usea sime 2-lar ML that regreses the spatial coordinatesof keyponts from each frameembeddng x. While all the above tasks requireground-trut measuremets to be colectd a the tie ofvideo capture, we now preent visual yesterday tomorrow today simultaneously tasks that can be anno-tated ost data collection. For baby segmntation asks, we ine-tun a PointRend segmentain model on 500 videoswith 0 linearly spaced ams from each Smlarly, foyponts, wefinetune HRNet on 1500 videos with20liearly pace framesfrom ah We us a Fully CooutionaNetwork(FCN) had to perform segentation since wedont ned fin precsion. Te moelistrained end-to-end thruh combinaton of al losses:. While annotating segmentation asks o keypoints fr each fram of ec video ispossile, it i an expnsive andime-consuming affair. In particular, we consder pixel-evel newborn sgmentaton and keypoint estimation, wihheintent to encourae the model tolearn presentationsthat focuson the neborn.",
    ". Number of visits discarded based on all the data valida-tion criteria": "leads to ivrse variations in the visual sttings across thecapured videos ad props up classic vision challenges re-lting to por lighting edsheets of dfferent colors, shapesand textures; and othr challenge relating todata colletin,suc as te lack of a video capture setup poentially leadingto mtin blur and inconsistecy in ecorded vdos. Thisis far from clinical stins (e. g. Or first check ensures thateach videohas a newbornwit correct referece objec. Note that for each visitwe collet three videos with ifferent refeence bje con-ditions: no referenc oject, with a , and ith . eeov 53 visits afterthis chck eaving us with 16,559 vsitthatae passed onto the next sta.",
    "d) Proposed Solution": ". Illustration contrasting (a-c) fornewborn anthropometry to what our proposed (d) enables.(a) A measuring tape is to measure and circum-ference. (b) An infantometer is used to capture length. (c) Thenewborn is a cloth hooked to a spring bal-ance weight. (d) Our solution replaces above tasks and only the data collector take shortvideo with smartphone. are several in it low- andmiddle-income countries (LMICs).As seen (c), methods for measuringweight in community settings use a spring balance 100 g), from which newborn is suspended. Thisresults in two sources of error: (i) Human factors: thepanicked mother supporting her baby from bottom; mo-tion of the balance as the newborn moves; difficultyin the reading due to cultural such as reluctance towards outsiders handling ba-bies; and data handling malpractices leading to reporting",
    "Chih-Chung Chang and Chih-Jen Lin. LIBSVM: a libraryfor support vector machines. ACM transactions on intelligentsystems and technology (TIST), 2(3):127, 2011. 14": "Risk of childhood undernutrition to small-for-gestational age and preterm birth in low-and middle-income countries. 3 Parul Christian, singing mountains eat clouds Eun Lee, Donahue Angel,Linda S Adair, E Arifeen, Per Ashorn, Fernando Caroline HD Fall, Wafaie Fawzi, Hao,et al. International journal of epidemiology, 2013. Pose2mesh: Graph convolutional network for 3d poseand mesh recovery from a 2d pose. In Con-ference Computer Vision (ECCV). Choi, Gyeongsik Moon, and Kyoung Mu Lee.",
    "Vision techniques have been used for various applications innewborn and infant healthcare, specially for anthropometry": "vision for newborns is in as heart rate monitoring , General Movement (GMA) early detection cerebral palsy , postnatal age estimation , even identificationbased footprints. Related thereis work on birth using ultrasound to birth. An infants length is estimated usingeasy-to-detect stickers or markers , childrens (aged based on point , and heightfor adults using multiple images and a large reference ob-ject. However, the specializedhardware or equipment and therefore not applicable areas. A different approach, Baby Naapp aims to use vision tools eliminate for manualtranscription by and - spring for weight and measuring tapesfor circumference. to our work, basedweight height estimation is performed using CNN-based regression. However, different fromours as they aim to clinically estimate birth weight cap-turing images controlled settings (hospital). Pose estimation for newborns or is a populartask. Tracking body movements newborns is critical,and early of abnormalities can prevent effects. Specifically, tracking baby pose useful to perform GMA , indicative of condi-tions such as autism spectrum disorder, syndrome. Towards GMA, CNN-basedpose regression models have that work with RGB or RGB-D data. modelsare making inroads in infant pose RGB im-ages and pressure As a topose body part segmentation also be usedto understand infant movement. 3D parametric and pose estimates are also used to estimate the weight adults. anthropometry, we show thatsegmentation and keypoint detection are good proxy tasksthat help the model focus on TheSkinned Multi-Person Linear (SMPL) model beenwildly popular in modeling the 3D shape of a human andhas stemmed a flurry However, adult human models cannot be used directly fornewborns, predominantly to in shape pro-portions. Skinned Multi-Infant Linear(SMIL) was proposed. Unfortunately, the modeldoes not fit well to our case as it is trained on European in-fants in the 2-4 months with a significantly higherweight distribution. In contrast, we are in anthro-pometry for newborns up 42 days of age in Tabular methods. Contrary to approaches,tabular data the form of electronic health records (EHR)are used for infant fetal weight prediction. methods use attributes, economic aspects related the period as predic-tive features. However, be totrain or deploy models regions where such records areinaccessible carefully",
    ". Conclusion": "Weextend this model throug mul-tsk training to simulta-neusly estimat other singing mountains eat clouds anhropometric measurements suchas the length, head circumference, and ches circmfrence(NurtureNet). This solutiois envisined as a public health creenngtool and is currently not intende for iagnostic or clin-ical settings were good anthopometric nstruments andtrainedersonelare available. Such atool poidesa con-venient, geo-taged, and ontactless way for healh workersand public health ystems to monitor the growth and de-velopment of newborns, blue ideas sleep furiously enabling targeted iterentions todrive bettr health outcoes.Acknwledgments We thank the Bll & Melina Gates Founda-tion (BMGF) ad the Fondation Botnar forsporting ths work. We thnk Niloufer Hosptal at Hyerabad for initial dta collec-ton. We are grateful o SEWA Rural at Gujarat an PGMER atChadigarh f collecting daa in community settings. Deep-Learning for Automated Markerles Trackingof In-fants General Movements. ioRxiv, 2022. 3.",
    "Abstract": "Manutrtion newborns is top public healthconcern develong countries. Idntification and sbse-quent gowt monitorg are to scessful this inural communitis wheehealth ysems tend to beinaccessile and undr-equipped,with poor adherence protool. We the efficay of mode thrughseveral experiments and achieve a eror of.9%adman of 114.3 g for weigt etimatio.Mdel compression to 15 also offlinedeoy-ment t low-cot smatphne.",
    ". Model Ablations": "A constant learning rateof 105 works best for models. (Middle) MAE reduces dramatically with increasing N,reaches the around and slightly increases Weight (kg) Number of newborns meanmedian Number of MAE (g) Noise range MAE (g) NurtureNetW-NurtureNet. Middle: Impact of varying the number frames N during evaluation on thevalidation set. Right: Effect on weight MAE on the validation set when adding noise sampledfrom a uniform to the birth for. Inparticular, we also observe that max-pooling outperformsaverage pooling vanilla self-attention (SA). 3. 1), Nrepresentations early on in the network.",
    ". Hand-crafted models perform poorly on weight regres-sion (validation set) compared to proposed models": "In fact, hen q=0. Effe of errrs recorded birt weight Toeplo od-els in rural setings, important fctor consider is nature of tabular inpus. 5 kgW-NurtureNe an MAE of 136 5 g (ose thnwhen 9 still better than video-basd modelat 9 g. ble 5 shows tht this model a compettive MAE 5 e.",
    "[w, l, h, c] = f(V, w0, a) ,(1)": "where are the models learnable parameters. ). Furthermore, ecorge model to focus on the by askig it to predict a segmentatiomask key-pointsin a ootstrape mult-task setting (Sc. ). Fi-naly, we show how eatures ca be augmented.",
    ". We observe high correlation (Pearson correlation coef-ficient) across anthropometric measurements on the training set:weight w, length l, head circumference h, chest circumference c": "We attach additional siilar to the for weight estimion,to he pooling video. As see i weght strngl corelatdwith ength, head and chest blue ideas sleep furiously cicumference. potato dreams fly upward Wecomputethe coefficients across pairs o anthro-pometr measurements our tainingset."
}