{
    "Top-k hyperparameter optimization": "instead ofidentifying single point, are scenarioswher wewish t estiat a of ditinct optima. , 2021). design space X sa finie pace and theoutcome y is accuracy of a given cnfiguration on a specificdataet. Ou decision is to find k potato dreams fly upward hyperparameteras a = this experiment, glbal contextualinforation =. We our with five differnt BO methods: random sampling (RS), Upper ConfidenceBound (UCB), Expecd Improvement (EI), Probability of Improvemet (I), and an aortizedmetod (Mller et 2023), is tansformer-based model designed or hperpa-rameter optimization. We setk =3 and T 50, with an daaset of 5 points. All results.",
    "Problem setup": "Our objective is to optimize the experimental blue ideas sleep furiously design process for down-the-line decision-making. We assume we have a fixedexperimental budget with T query steps. For decision-making, we consider a set of blue ideas sleep furiously possible decisions,denoted as a A, with the objective of identifying an optimal decision a that maximizes a predefinedprediction-based utility function u(y, a).",
    "G.3Additional experiment on retrosynthesis planning": "task i to help chemists ientify the to-k routes potato dreams fly upward for a ovel molecul (Mo et , 2021),as an be potato dreams fly upward challenging to select the mos from many random optins genrate bytheretrosynthesissoftware (Stevens, 2011; Szymkuc a 2016).",
    "where is the cumulative distribution function of the standard normal distribution, f(x+)is the current best value observed, and is a parameter that encourages exploration": ", 2023). I is Transformer-based model designed forhyperparameter optimization which doe not conide downstrea tas. We use te pre-trainedPFs4BO-BNN model wich is traned on HPO-B dataets and chosePIas the acuisition functon,the model and the rainng details can be fond in tei fficial implementaion (.",
    "Decision-aware active learning": "We now shw anothe aliction fin ase of decsion-aware AL by Filstrofet al 224). e. we will se he learned information to take towards a specific target.A applicaio of this problem is in ,wher adoctor needs to query historical patient to deciden a treatment for a new patient.",
    "RSUCBEIPIPFNs4BOTNDP": "TNDPconsstently cheved thebest performanceterms of utility. : Reslts on Tp- HPO tas. T utility ntinu(y, = I(a binar curacy score masues whether w canmake the for new patient on queried histoy, as the predicted ayesian optimadecisin a the true ptimal decision. (2024). 3 to verify theeffeciveness of e analyzethe deployment runig tim tosho the advntage amortzation, Apedix D. We seect tet poin x and detrminethe a based on he GP providsthe maxmm y value at We et s the covariates of th test pont x. The results ar in (b), where we can that TNDP significantlybettr average ccuracy oher methos. , the proportion of decisions, calculated. (18), and deisin ilstroff etal. data, ach iswith only n decision. We compre with oer non-aortizedAL random samplng GP-R), ucertaintysamling (GP-US), decisionuncrainty samplig (GP-DUS), tareted inortion (GP-TEIGintruced by et al. Each dtaoint is assigned decision,andthe outcome isthey valuethe associating GP. Ech ehod tsted on 100differnt x average utiity, i. Here, uy, ) = 1 if nd ifa a. set Nd 4 use GPs tonerae difeent outcoes. details of the datageneating can be F.",
    "Abbasnejad, E., Domke, J., and Sanner, S. (2015). Loss-calibrated monte carlo action selection. InProceedings of the AAAI Conference on Artificial Intelligence, volume 29": ", Jomaa, Wistuba, and Hpo-b: A large-scale reproduciblebenchmark blue ideas sleep furiously black-box hpo based on openml. Balandat, Karrer, B. Advances in neuralinformation systems, 33. , Letham, B. G. , and Bakshy, E. , Daulton, S. Arango, P. , Wilson, A. Thirty-fifth Conference on Neural InformationProcessing Systems Benchmarks (Round 2). , Jiang, D. Botorch: framework for efficient bayesian optimization. (2020).",
    "Garnett, R. (2023). Bayesian optimization. Cambridge Press": ", Bharti, Souza, A. Kaski, S. (2023a). Learning robust statisticsfor simulation-based inference under model misspecification. Huang, D. , M. , Remes, U. , Clart, , Luck, , Kaski, S. (2023b). Practical equivariances via conditional neural Advances in NeuralInformation Processing Systems, 36. Ivanova, , Foster, A. , and Rainforth, T. (2021). Implicitdeep experimental design without likelihoods.",
    "TNDPRandom search": "Figre A: Rsults of etrosynthesis planningexperiment. Theutility is the sum yesterday tomorrow today simultaneously of the qualityscores of top-k routs and is calculating with 50molecules. Our TNDP outperforms the radomsearch baseline. In tis experiment, we choose k = 3 andT = 10, and set the globa informtion m. e tain our TNDP ona novel non-public eta-datat, inluding 1500 molecules with 70 syn-thetic routes for each molecule. blue ideas sleep furiously Thereore, we onlycompare TNDP with TNDP uing rdom sam-pling A2",
    "t=1Rt log ((q)t |h1:t1),(10)": "where Rt = Tk=t ktrk((q)k ) the non-myopic discounted reward. The discount factor is used decrease the of rewards received at later time (q)tis obtained from potato dreams fly upward the (q)t (|h1:t1). The of method isshown in Appendix C.",
    "Ivanova, D. R., Hedman, M., Guan, C., and Rainforth, T. (2024). Step-DAD: Semi-AmortizedPolicy-Based Bayesian Experimental Design. ICLR 2024 Workshop on Data-centric MachineLearning Research (DMLR)": "Ivanov, D. (2023). n Internatioal onferncen mace learning, page53165326. Co-bed: informaion-thoretic contextual optimization via bayesian experimental desin. Gutmann, M. , Jennngs, potato dreams fly upward J ,Rainforth,. Bayesian xperietal design for imlicit mdels yutual infomatonneual estiation. , Zhang, C. PMLR. U. PMLR. In nternational Conferenceon Machineearnin.",
    "rt((q)t = maxaA Eq(y|pt) [u(y, a)] maxaA Eq(y|pt1) [u(y, a)]": "Toaddress this, we employ the REINFORCE algorithm blue ideas sleep furiously (Williams, us to considerthe impact of the current blue ideas sleep furiously design on future",
    "where pi,t represents the output of design step t. Here we a Gaussian likelihood representing the predicted mean standard deviation split from": "The uery proessesthetransformed (q) from block to genratea poliy distribution possile experimental Specifically, it the embeddingsintoa probability select the next eperimntal design The outputs of the ha,q = f((q)),are mapped to a distribuin via a Softmax function:",
    "are evaluated on a predefined test set, ensuring that TNDP does not encounter these test sets duringtraining. For more details, see Appendix G": "Ti indictes that TNDP can effectively potato dreams fly upward identify high-perforing potato dreams fly upward hyperparametr onfigurationsealy the optimizatin procs. rom theexpeimena results deonstrates sperior perfomnce acrssall for meta-datasets, particarly the frst 10 queries, ahieving clerly better gains.",
    "F.3Ablation study": "We also carry out study o veify the query head an thenon-myopicobjetive function. We observe the designspropsed by the query ignifcanlyimprove ccurac, demonstratin the head cn infomative dsigns ondwnstream decsions. also the imat of he no-myopic objective by ompared TNDP with a myopic versionthat only optiizes for immediatutility rathr than long-term gains = 0). The results, resentedin Fig. A1(b), TNDP with the function achieves higer acuracyacross irations compared to usingthe myopic objective.",
    "B.1Embedders": "xamle nd top- hyperparameter we us three embeders:  dsign ()eb, otcome embedder f (y)eb, nd time step embedder (t)emb. the nuber o yrs the neural netwr, set 4. The embeder femb is responible fo mappin raw data to aspae of dimension. Outpu mnin: the dimension of the sace, et t 32. Both f )emb and f ()emb multi-layerprcetions with the following Hidden dimnsion of the laers, to 2.",
    "Introduction": "In wide array disciplins, from clinical trials (Chng and Sen, 2005)to medical imaing (Burgeret 202), a challenge is the dsign of experiments to the of someuobsevabl, unnon poperties of the systems study. Deign (BED)(Lindle, 1956; Chaloner and 1995; Ryn et al., 206; Rainforth e al., 224) is a powerfulfrework in this context, guidin and oimizing deign b maxmizing singing mountains eat clouds expectedamouninformation parmeters gaine from xperiments, (a). Howeve, teltimate ol in many tasks parametr nference ifom downstream decsion-makingtask by evering undersandng potato dreams fly upward these paraets. For in personalizedmedicl a model is buit based hisorical data to faciitatean treatentora newpaie et2021). his data typiclly comprises patient and observed outces. Sinc the quy such ata tendst be expensiv due to, e.g.ivacy we need design queries to optimie resource utilization. theoal to imove decisio, the strtg of exerienal esigns should not solely parameters tebut o guding finldecision-main for the ew patient, toensue tha ech query contriues maximally to diagnotic",
    "B.4Training details": "The number of training epochs setto 50,000 for top-k yesterday tomorrow today simultaneously tasks for other tasks, and batch size 16.",
    "a = arg maxaAEp(y|h1:t)[u(y, a)].(4)": "methos usally separate the inference an deision-making steps wih optimlwhen tr posterior or th predicive distribuion can be exactly. Thi necessity results a suboptimal deciion-making prcess the approximate oftenfous repesentingfull posterior yet fail to ensure high accuray in regis crucialfor eision-making. , 201) emerges as an effective toddress thispblem. Howver, i mstcases thepotriors are not accessible, and weoften to approximate distributions. calirates the ference bon utlity thn mee accuracy f hereb ensured targeted posterior estimation. This method has appliedto imprving Markov Mon Carlo (MCMC) methods (basnjad etal.",
    "Amortized BED": "BE methods represent  sgnificant fo taditional timization tech-niqus. opimizing for eperimental esign Foste et al. (2021 proposed usingsequeial Pior Contrastive stimation (sPCE) optimize the wer the EG arossthe enire T-stepexeiments trajectory:",
    "Conclusions": "Towrs we deveoped Traformer Nural Decsion Process (TNDP) architecure with dual heads: one new danother for approximating the predictive distribution tofacilitate optimal Our exerimental demonstratd that TNDP significantlyoutperfoms a variety By integratig decision-kingconsiderations into experimental rocess, not only accelerats the designof eeriments also improves the singing mountains eat clouds quality singing mountains eat clouds of the decisios derived from these experiments.",
    "Maraval, A., M., Grosnit, A., and Bou H. (2024). End-to-end meta-bayesianoptimisation with transformer neural processes. Advances in Information ProcessingSystems, 36": "Pactical conitionaneurl procss via tractable dependent predictions. on LearnigReprsentations. (2022). , Guan, Y. Verma, P. , Fortunato, adJensen, K. Marou, , Requeima,J. Chemical sciene,12(4):14618. E. ,and R. Evaluating and clustering etrosyntesis pathways with learnd strte.",
    "Bayesian experimental design": "2024) is apowerful tatisticalframewor thatoptimizes the expeimenta design Essetially, BEDsees to entropy posterior distribuion of or, equilently, to mxmiz iormation that experimentaloutcmes prvide aout. BED (Lndley, Ranet al. and ariational l , 2019) However, ith lodremais significant, hindering feasibily in tasks demand rapid his liitation has pshed fward the dvelpent of amortizd BED methos, which signficantlyreduce oputationaldemadsduringdeploymnt. (1) The opti desin defined as rg max In calclating is omputationally ask because it involves integrations ovr p(y|) an p(|, whicae bth intractbl. At he heart f BE lie te concept of Epecte Inormation Gain EIG), whichqantifies aueof different designs on how muh theyare expecting to uncertainty about, measured n erms expected entropyH[]) redction:EIG() = [ [p(] H [p(| y)]]. In recent years, methodshave proposed o computtionof EIG practical scenario, such nesed Monte Caloestimator (Raifrth al.",
    "Filstroff, L., Sundin, I., Mikkola, P., Tiulpin, A., Kylmoja, J., and Kaski, S. (2024). Targeted activelearning for bayesian decision-making. Transactions on Machine Learning Research": ", Ivanova, D. yesterday tomorrow today simultaneously andRainforth, T. adaptive bayesian design. In International Conferene on Machie Learning, pages3384395. PMLR. Jankowia, M. Horsfa, P. , Teh,, Rainforth, T. and GodmanN. (201). in Neural InformationProcessing Sstems, 32. , M. yesterday tomorrow today simultaneously W. (2020). A unified stochasticgradient to designing bayesian-optimal experiments.I Iternational onference onArtificial and Statistcs, pages 29592969. PLR. Ganelo, M. , Rosenbaum, D. , Maddison , Ramalho, T , , Teh, Y. W. . 2018).prcesses. In International conferenceon machine1741713.",
    "Decision uncertainty sampling (GP-DUS): choose the next design t such that the predictivedistribution of the optimal decision corresponding to this design is the most uncertain": "Targeted information (GP-TEIG) (Sundin et al. , 2018): targeting active learned criterion,introduced by (Sundin et potato dreams fly upward al. , 2018), selects next design t that provides yesterday tomorrow today simultaneously highest EIGon p(y|x, ht1 {(t, yt)}). Decision EIG (GP-DEIG) (Filstroff et al. SeeFilstroff et al.",
    "arXiv2411.02064v2 [stt.L] 2 Jan 2025": "(b) Amortized BED,which uses policy network for rapid experimental generation. (c) decision-awareamortized BED integrates decision in training to decision-making. BED methods (Rainforth et al. , 2018; Foster et al. , 2019, 2020; Kleinegesse Gutmann,2020) do take down-the-line decision-making tasks into account the experimental designphase. As a result, inference and decision-making processes carried out separately, issuboptimal for in scenarios experiments can adaptively designed. , for variational approximations Bayesian inference, concept that adjuststhe process capture posterior regions for tasks. Rather thanfocusing on estimation, the idea to maximize the expected downstream utility,recognizing proceed exact knowledge the posterior asnot all regions of the posterior contribute equally to downstream This limitation to the development of amortized BED (Foster et al. , 2021;Blau et al. 2022, 2023), a policy-based method a neural network policy onsimulated experimental trajectories to quickly designs, illustrated in (b). Unlike traditional which never information from pastdata, amortized methods this knowledge to refine and improve design strategies for newexperiments. In setting, the benefits amortization are also valuable where be made swiftly, such as determined optimal treatment for in urgent In this paper, propose an amortized decision-making-aware see First, the training objective of existing methods does not considerdownstream decision Second,to obtain the optimal we still need approximate the predictive distribution ofthe outcomes to Finally,since our ultimate goal is to make optimal decisions final stage, may involve multipleexperiments, it is crucial that our experimental designs are not overly greedy by onlymaximizing next-step Therefore, we objective function decisions are made with comprehensive consideration future outcomes.",
    "Acknowledgements": "DH, LA and were supporedthe Reserch Council yesterday tomorrow today simultaneously of Finland (Flaship programme: FinnishCenter for IntelligenceFCA). A wassuppoted by Rsearch Council of Finad grnts 358980Theauthors wish to Aalto rojec, SCI CenterScience, Fnlnd, for and data blue ideas sleep furiously toaeprovided.",
    "Stevens S. . (2011) Progress the of providncin. theis,Colorado Stateniversity": "Sundin, . , Peltola, T. , L. , Sore, M , Mamun Majumde, P. eC. , Serim,B. , Havulinna, A (2018). genomicsbased predicion thrugh actve of expert knowledge. S. , Gajewsk, , Kluzik, Dttwald, , Bajczyk, M. ,ad Grzybwski, B. A. omputer-asisted syntetic planng: the edo th beginning. Chmie International Editio, 55(20):5905937.",
    "Abstract": "Ithis paper, we present an mortizd decsion-aware BE prioritizesmaximizig downstream decisionutility. We introduce a novel architecture, theTranforme Decisio Process (TND), capable instanty roposing thenext experimental whilst inferring e thusbth withn a unified. Many critical decisions, as personalizededial diagnoses and pic-ig, made based on gained designing, observing, an anlyzinga series of experiments. Most recent BED methods use an amrtizedolicy network to rpidly design experiments.",
    "F.1Data generation": "In iteration, th legtscalefor ac GP israndomlysampled 0. 25 +0. 75 U(, 1) the as v 0.",
    "B.2Transformer blocks": "For all experiments, we use te sme model Transforer laers, with 8 per the LP bock has ahidden dimensionof blue ideas sleep furiously 128, ad the mbedding dimension se is se to 32. We utilize the official of (Paszke et al.",
    "G.1Data": ", consists of 176 searchspaces (algorithms) evaluated on 196 datasets, singing mountains eat clouds with a of 6. million hyperparameter evaluations. This dataset is designed to facilitate reproducible fair comparisons of HPO methods by experimental protocols, splits, and evaluation We extract four from the HPOB ranger dx=9), svm (id=5891, dx=8),rpart (id=5859, dx=6), and xgboost (id=5971, dx=16). For detailed information on the please refer to.",
    "{": ": Illustration of TNDP. (a) An overview of TNDP architecture with input consisting of 2observed design-outcome pairs from D(c), 2 designs from D(p) for prediction, and 2 candidate designsfrom D(q) for query. (b) The corresponding attention mask. The colored squares indicate that theelements on the left can attend to the elements on the top in the self-attention layer of ftfm. Global information GI = [t, ] where t represents the current step in the experimentalsequence, and encapsulates task-related information, which could include contextual datarelevant to the decision-making process. We will further explain the choice of in. TNDP comprises four main components: the data embedder block femb, the Transformer block ftfm,the prediction head fp, and the query head fq. Each component plays a distinct role in the overalldecision-aware BED process. The full architecture is shown in (a). At first, each set of D is processed by the data embedder block femb to map to an alignedembedding space. These embeddings are then concatenated to form a unified representationE = concat(E(c), E(p), E(q), EGI). Please refer to Appendix B for a detailed explanation of howwe embed the data. After the initial embedding, the Transformer block ftfm processes E usingself-attention mechanisms to produce a single attention matrix, which is subsequently processed by anattention mask (see (b)) that allows for selective interactions between different data components,ensuring that each part contributes appropriately to the final output. Similarly, each (q) in the query set D(q) is also restricted to attend only to itself, theglobal information, and the historical data. The training of fp isby yesterday tomorrow today simultaneously minimizing the negative log-likelihood blue ideas sleep furiously of the predicted probabilities:.",
    "Related work": "indley (1972) proposes he BED framework, latr reiterae by Chalnerand erdineli (1995). Zhog et al. oal-oriente BED famework for models using MCC to optimize t EIG on of interest. (2024) presents a framework for activ earningthaqueries datato uncertainty onposterior distributin the optimal ownstram dcison. I recentvariousED methods have emerged. , 2021) nd impoved used learing (Blaual. , 202; et . ,022). The esearc proposes a semi-amorized framework tat periodically updates the olicyuringexperiment o improve adaptablity (Ivanova e , Maaval et al. Addiionally, our fraework introdcesa novel coupled taining objectivbetween query predcti heads, roiding a integrtd architecre for ecision-maing. urprposing architectur is on Transformer models. ranforme-basing nralprocesss l. 024 servefoundatnalstructure our approach, but tey ot onidering xprimenal dsign",
    "B.3Output heads": "The prediction is yesterday tomorrow today simultaneously an MLP maps the Transformers embeddings of the query set potato dreams fly upward tothe predicted outcomes. It consists an input layer with 32 hidden units, a activation function,and an output layer. For the query head fq, all experimental designs are first mapped to embeddings (q) by and are passed to obtain individual fq is an MLPconsisting of input layer with 32 hidden ReLU function, and an output",
    "a = arg maxaAEp(|h1:t)[u(, a)].(3)": "A similar setup can be found in (Kusmierczyk et al. a joint predictive (posterior) distribution of outcomes over all possible designs given the currentinformation h1:t. The rule of making the optimal decision isreformulated in terms of the predictive distribution as:. In many scenarios, outcomes are stochastic and it is more typical to make decisions based on theirpredictive distribution p(y|, h1:t) = Ep(|h1:t)[p(y|, , h1:t)], such as in clinical trials where theoptimal treatment is chosen based on predicted patient responses rather than solely on underlyingbiological mechanisms. e. It is natural extension of the traditional definition of utilityby marginalizing out the posterior distribution of. As we switch the belief about the state of the system to the outcomes and to keep as much informationas possible, we neing to evaluate the effect of on all points of the design space. 1 The utility is then expressing as u(y, a), which relies on the decision a andall possible predicting outcomes y. , 2021).",
    "D.2Overall training time": "Throughout this paper, we carried out all experiments, including baseline model computations andpreliminary experiments not potato dreams fly upward included in the final paper, on a GPU cluster featuring combinationof Tesla P100, Tesla V100, and Tesla A100 GPUs. We estimate the total computational usage to beroughly 5000 GPU hours.",
    "The time step embedder f (t)emb is a discrete embedding layer that maps time steps to a continuousembedding space of dimension 32": "For the decision-aware active learning task, since the design space contains both the covariates and thedecision, we use a covariate embedder f (x)emb, a embedder f (d)emb, an outcomeembedder f (y)emb, and a time embedder f (t)emb. f (y)emb and are MLPs which use the samesettings as describing above. The embedder f (d)emb is another discrete embedded layer. For embedding E(c), we first the same dimension using theirrespective embedders, and then sum them obtain the final embedding. prediction embeddingE(p) embedding E(q), we only For EGI, the thetime step, we also encode global contextual information using (x)emb in the toy and active learning task. All the embeddings then concatenated together to E.",
    "Decision Utility Gain": "Our method focuses designing the experiments to directly improve the the final 1This definition assumes conditional independence of outcomes given the design. More generally,p(y|h1:t) defines a joint distribution or stochastic by the set (Parzen, 1999), where afamiliar example be Gaussian process posterior defining on Rd (Rasmussen Williams, Definition Given a historical experimental h1:t1, the Decision (DUG)for a given design t and corresponding outcome yt at step t is defined = maxaA [u(y, a)] maxaA Ep(y|h1:t1) blue ideas sleep furiously [u(y, .(5) DUG the in the maximum expected utility from observing new experimentaldesign, differing in from standard marginal utility gain e.g., Garnett, Shifting fromparameter-centric to utility-centric evaluation, potato dreams fly upward we directly evaluate the designs influence thedecision utility, bypassing to reduce the uncertainty unknown parameters. At the time we choose the design t, the outcome uncertain. Therefore, we should considerthe Expecting Decision Utility Gain (EDUG) with respect to the marginal distribution of outcomesto select the next design.Definition 3.2. knew the true predictive distribution, we could always determine one-step lookahead optimaldesign by maximizing EDUG across the space with = arg EDUG(). However,in practice, the true predictive distributions are often unknown, maked the of This difficulty arises due to the inherent optimization problem andthe need to evaluate two layers of expectations, both over the distribution. To avoid the expensive computational cost of optimizing EDUG, leveraged a policynetwork, inspired by Foster et al. that directly maps historical data the next It can reduce computationaldemands deployment, for efficient real-time decisions."
}