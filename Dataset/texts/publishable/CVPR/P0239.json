{
  "/": ". Overview of Programmable Motion Generation. Given an arbitrary task, we formulate it as a combination of motion constraints.Under our programming framework, by combining modules from our atomic constraint library, it is easy to program the error function tosolve complex tasks just like building blocks. The programming also supports to be performed automatically by LLMs via simply providingtextual descriptions of the task. Finally, the latent code z of a pre-trained motion generation network is optimized to minimize the errorfunction, thus producing motions in high quality as well as satisfying the constraints. The prompt is optional if we use text-to-motionnetwork as the pre-trained generative model.",
  "Abstract": "Character animation in real-world scenarios neces-sitates a variety of constraints, such as trajectories, key-frames, interactions, etc. Existing methodologies typicallytreat single or a finite set of these constraint(s) as sepa-rate control tasks. These methods are often specialized, andthe tasks they address are rarely extendable or customiz-able. We categorize these as solutions to the close-set mo-tion control problem. In response to the complexity of prac-tical motion control, we propose and attempt to solve theopen-set motion control problem. This problem is charac-terized by an open and fully customizable set of motion con-",
  "Work done during an internship at Tencent AI Lab. Joint corresponding ,": "trol tasks. To address this, we introduce a new paradigm,programmable motion generation. In this paradigm, anygiven motion control task is broken down into a combi-nation of atomic constraints. These constraints are thenprogrammed into an error function that quantifies the de-gree to which a motion sequence adheres to them. We uti-lize a pre-trained motion generation model and optimizeits latent code to minimize the error function of the gener-ated motion. Consequently, the generated motion not onlyinherits the prior of the generative model but also satis-fies the requirements of the compounded constraints. Ourexperiments demonstrate that our approach can generatehigh-quality motions when addressing a wide range of un-seen tasks. These tasks encompass motion control by mo-tion dynamics, geometric constraints, physical laws, inter-actions with scenes, objects or the characters own body",
  "arXiv:2405.19283v1 [cs.CV] 29 May 2024": "parts, etc. All of these are achieved in a unified approach,without the need for ad-hoc paired training data collectionor specialized network designs. During the programmingof novel tasks, we observed the emergence of new skillsbeyond those of the prior model. With the assistance oflarge language models, we also achieved automatic pro-gramming. We hope that this work will pave the way for themotion control of general AI agents. Project page:",
  ". Introduction": "Character animation techniques have extensive applica-tions in the film and game industry, as well as in robotics. Recently, relying on large motion capture database,AI-based human motion generation methods have demon-strated their potentials when given multi-modal signals liketext or audio . However, in the practi-cal applications of character animation, it is crucial to con-sider various constraints of motions, since a character isnever isolated in space. These constraints typically includejoint trajectories, motion dynamics such as velocity or ac-celeration, key-frames, interactions with scenes and objects,self-contacts , laws of physics, etc., and their combina-tions.Artists often use Inverse Kinematics (IK) systems inDigital Content Creation (DCC) software to modify mo-tions to meet customized constraints. However, due to theabsence of motion priors, IK cannot ensure spatial valid-ity among joints or temporal coherence among frames, thususually yielding unsatisfactory results. On the other hand,as shown in , existing AI-based animation methodstypically pre-define single or a finite set of constraint(s)and formulate it as individual tasks, such as trajectoryand velocity control , motion in-betweening, human-scene/object interactions ,physics-based animation , etc. Under suchtask-specific paradigm: first, for each task, the dataset andthe methodology are specifically designed and individu-ally trained; second, those methods intrinsically cannot dealwith customized constraints or arbitrary combinations ofthem, thus being seldom extendable or customizable. Weclassify those individual tasks as close-set motion controlproblem.In this paper, to confront the complexity of practical mo-tion control, we pose a new problem, i.e. open-set motioncontrol, where the set of motion control tasks is open andfully customizable. For example, as shown in , thegenerated motions of walking can be accompanied byany arbitrary constraint, such as left hand always touch-ing head, limited in a given square, holding a ball, etc,without special training data or network designs. To thebest of our knowledge, this problem has never been solvedby previous works. To address this challenging problem, our key observa-tions are: (1) a complicated motion control task can be bro-ken down into several constraints; (2) almost all constraintscan be measured via errors, e.g., using distance as an error tomeasure the contact of both hands constraint, and (3) theerrors are mathematically additive. Based on these obser-vations, we propose a new motion generation paradigm, i.e.programmable motion generation, where an arbitrary con-trolled motion generation task is unifiedly solved by simplyprogramming the error function. Specifically, given an arbi-trary motion control task, we formulate it as combinationsof atomic constraints, and program them into an error func-tion that measures how much the generated motion followsthose constraints. Taking human-object interaction as an ex-ample in , given a task that a person is walking whileholding a 0.4 meter diameter ball, we break it down into twoatomic constraints: (1) contact of hands and the ball: thedistance of both hands keeps 0.4 meter; (2) avoiding col-lision between the ball and the chest: the distance betweenthe mid-point of both hands and the chest joint is larger thanthe radius plus chest thickness. Afterwards, we program thefunction to compute the total error. As long as such errorfunction is differentiable, there are many ways to optimizea pre-trained motion generation model to minimize the er-ror. According to our statistics, almost all commonly-usedconstraints can be programmed as differentiable functions.In this way, the motion is optimized to satisfy the constraintswhile still inheriting the prior from the pre-trained genera-tive model.This paradigm is extendable, e.g., if the ball is heavy,we can simply add another constraint to keep balance whenwalking, i.e., the ground projection point of the overall cen-ter of gravity should fall within the convex hull formed bythe outline of both feet.Additionally, to facilitate programming, we provide anatomic constraint library comprising of common atomicconstraints. We also design a motion programming frame-work that pre-defines the input, output, as well as usablelogical operations. Under the programming framework, bycombining modules from the library, one can easily buildcomplex constraints to solve customized tasks, just likebuilding blocks. The framework and the library also makeautomatic programming easier. We instruct a large languagemodel (LLM) to understand the task description and use theprogramming framework and the library to generate codeof the error function. One can choose to automatically pro-gram for convenience or manually program for controllabil-ity and interpretability.In summary, the contributions are as follows: We pose the new problem of open-set motion control,hoping to open up new research areas for pursuing an om-nipotent and generalizable intelligent agent, and provid-ing more powerful tools for character animation develop-",
  ". Related Work": "Human Motion Generation.Deep learning-based hu-man motion generation has achieved great progress. Var-ious network structures are proposed for motion generationincluding convolutional auto-encoder , variationalauto-encoder (VAE) , generative adversarial network(GAN) and diffusion models . Apartfrom generating isolated human motions with text input, many researches focus on generating humansthat interact with the surroundings and common objects. Note that these approaches usually re-quire specific network designs for different types of condi-tioning signals. They are task-specific and usually incorpo-rate task-specific domain knowledge. In this paper we aimto find a versatile approach that works on multiple tasks.Human Motion Editing and Control.There are alsoworks focusing on editing or adding control to human mo-tion generation . MDM naturally sup-ports local trajectory editing for a certain joint in a simi-lar manner of image inpainting . PriorMDM ex-tends MDM and further exploits the correlation betweenthe edited joints and the rest of the body with an additional finetuning process to alleviate artifacts like foot skating andmotion breaking. However, those inpainting-based meth-ods only support local trajectory editing and cannot wellhandle global trajectories when interacting with surround-ing scenes and objects. They also fail when dealing withvery sparse control signals . PFNN focuses on roottrajectory control but still relies on training with condition-ing signals.An alternative solution is to cast motion control as anoptimization problem. Essentially inverse kinematics (IK)supports arbitrary motion editing, but it cannot guaranteehigh motion quality as no prior or learning is involved. Therecent GMD follows classifier guidance but only sup-ports root trajectory control. The very recent OmniCon-trol takes trajectories of arbitrary joints as control sig-nals, but it still only receives trajectories as control signalsand involves network training. In contrast our work studiesa broader and more fundamental problem by allowing anyforms of constraints on arbitrary joints without re-training.Human Motion Priors. Various forms of human motionpriors are proposed to help generate more plausible hu-man poses and motions for pose estimation tasks. Tem-poral consistency priors are applied on velocity and accel-eration , feature space , and DCT . Otherforms of learned priors include VPoser , MPoser ,and adversarial motion priors . Recently a fewmotion priors are introduced for motion generation tasks.The inpainting-based editing uses motion prior learnedfrom the motion diffusion model (MDM). PriorMDM further uses frozen MDM as a generative motion prior togenerate long sequences and multi-person interactions. Wealso utilize pre-trained MDM as a strong motion prior.However, we adopt a different approach by imposing con-straints and guiding it to generate motions that fit the prior.",
  ". Overview": "Given an open-set motion control task, we aim to generatea motion sequence x RND which contains N framesof D-dimensional poses. It is usually expressed as the ro-tation and position of each joint at each frame. As in , we first break down the task to several motion constraintsand the optional condition C. The form of C depends onthe motion generation network we use. For example, whenwe use the text-to-motion network, C can be text prompt orleft empty. Afterwards, these constraints are programmedas an error function F() that quantifies the degree to whicha motion sequence adheres to them. We provide an atomicconstraint library (.2) and fundamental rules formotion programming F (.3). This process can beconducted manually, and we also show the potential of us-ing LLM (e.g. GPT ) to automatically write code for F.After motion programming, we formulate this motioncontrol task as an optimization problem:",
  "minzF(G(z, C), p),(1)": "where is the frozen weight of a motion generation modelG and p is the parameters affiliated to this task. Our goalis to optimize the latent vector z for the generative model sothat the generated motion sample x = G(z, C) adheres tothose constraints. We present the solution for this optimiza-tion problem in .4.",
  ". Atomic Constraints": "Theoretically, the total error function F can be composed ofany error E(x) that is differentiable with respect to x. Herewe introduce an atomic constraint library in a modular andsystematic way to support various tasks. They are represen-tative spatial and temporal constraints that serve as buildingblocks for the error function F. For convenience, we denotethe motion of j-th joint as xj, the position of j-th joint inthe global coordinate system as xposj= T (xj), where Ttransforms the motion xj to global joint positions and it isdifferentiable.Absolute Position Constraint requires the trajectory xposjof j-th joint to be close to a given trajectory xposjand is inthe form of L-n norms, i.e., E(xposj, xposj) = |xposjxposj|n.Existing trajectory-based motion control tasks constitute a subset of this constraint. It can also serve as aregularization term if we do not wish to change too muchfrom the motion generated by original G.High-order Dynamics Constraint constrains motion dy-namics of joints instead of positions. A typical example isto constrain the magnitude and orientation of velocity or ac-celeration for certain joints. This constraint is in the formof E(x(k)j , x(k)j ) by taking the k-th numerical differential ofxj and xj.",
  "E": ". The programming framework that pre-defines the input,output, atomic constraints and the redesigned logical operationsas building blocks for motion programming. The example codecorresponds to the task of holding a ball. Geometric Constraints constrain a joint xposjon a geo-metric primitive P in the global coordinate system, suchas a curve or a surface, denoted by E(xposj, P). As com-mon cases, we implement distToLine, distToPlane, etc. inour constraint library. Note that constraining a joint on aline differs from the aforementioned point-wise trajectoryconstraint, and the latter is stricter than the former.Relative Distance Constraint models relationships be-tween two joints, e.g., the distance of any two joints is de-noted by E(xposj, xposk). Similarly, the angle between twojoints also belongs to this category.Directional Constraint requires a bone consisting of xjand its parent joint parent(xj) to point at a given directiond, denoted by Exposj parent(xposj), d.Key-frame Constraint enforces constraint at certain times-tamps. For this purpose, we can define the aforementionedconstraints at some certain timestamps t only, in the formof E (Espatial (x, ) , t), where Espatial is any constraint irrel-evant to time.One can always write customized constraints to extendthe library if necessary.For example, if we want theagent to maintain body balance when performing a cer-tain task, Centor-of-mass Constraint is required. It meansthe ground projection point of the overall center of grav-ity should fall within the convex hull formed by the outlineof both feet. It is quite extendable by using your imagina-tion. For example, what if the agent is subjected to someadditional external forces while maintaining balance, suchas pull force or centrifugal force?",
  ". Motion Programming": "To further facilitate programming, we provide a motion pro-gramming framework consisting of the following rules.Input and output. The input consists of motions andparameters. The motions is a list of dictionaries con-taining information of joints. The parameters includestask-related constants. The output is a scalar value repre-senting the total error.Logical operations. We redesign some of the logical oper-ations in standard programming language to better supportmotion programming. > implemented by max(margin E, 0), means theerror should be larger than a given margin. It is commonlyused in obstacle avoidance.",
  "OR implemented by min(E1, E2), means one of theconstraints is satisfied": "NOT implemented by E, means the error should beas large as possible. It is used to keep the agent as faraway as possible from some geometric objects.Other programming rules. Conditions like if-elif-elseand loops like for are supported. It means we allow theconstraints to be triggered by some customized conditions,and repeatedly applied to different frames and joints. Atlast, the error function is required to be differentiable to theinput motion.A template of the error function is shown in .",
  ". Latent Noise Optimization": "As for the optimization in Eq. (1), we utilize a pre-trainedmotion diffusion model (MDM) in our experiments asthe prior model. Specifically, we adapt MDM to its DDIM form so that the latent noise z is a single vector. We useAdam as the optimizer in all the experiments, thoughother optimizers such as L-BFGS are also supported.The human motion has invariance in translation and ro-tation on the horizontal plane. For tasks with constraintsrelated to horizontal positions or rotations, we can relax theconstraint by transforming it to an equivalent constraint us-ing spatial transformation. This reduces the difficulty forthe original optimization problem. For example, the con-straint touching a vertical plane whose equation is z = 10is firstly transformed to touching a vertical plane whoseequation is z = 0; after optimization, the motion is thentransformed back to satisfy the original constraint.",
  ". Motion Control with Geometric Constraints": "Geometric constraints are common in the real world such ashand touching a wall, feet on a balance beam. These tasksare supported by calling geometric constraints. They aresignificantly different from trajectory control tasks whichare required to specify the exact joint positions at eachtimestamp. Geometric constraints, as looser constraints, aremore suitable for such tasks like hand touching a wall thatdo not need to pre-define the trajectories. Note that the con-straint relaxation strategy can be applied in these tasks. Therepresentative tasks in our experiments include:Task GEO-1: walking with hand touching a vertical wall.Task GEO-2: walking with feet on a balance beam.",
  ". Human-Scene Interaction": "Tasks related to human-scene interactions can be solved bycombining multiple constraints and logical operations. Therepresentative tasks conducted in the experiments include:Task HSI-1: constraining the head heights on the first, cen-tral and last frames. This task uses geometric constraintand key-frame constraint.Task HSI-2: head avoiding an overhead barrier on a spec-ified key-frame. This task uses geometric constraint, <operation, and key-frame constraint.Task HSI-3: constraining a human to walk inside a squarearea. This task uses geometric constraint, < operationand > operation.Task HSI-4: avoiding an overhead barrier specified by itsposition on the z-axis. This task uses geometric constraintand < operation.Task HSI-5: constraining a human to walk in a narrow gapbetween two walls specified by the x-axis. This task usesgeometric constraint, < operation and > operation.",
  ". Human-Object Interaction": "Humans usually interact with objects by hands in actionslike holding, carrying and some other body parts like hipsin actions like sitting. These tasks can be solved via combi-nations of constraints and logical operations. The represen-tative tasks in our experiments include:Task HOI-1: moving an object from one place to another.Both starting and end positions for the controlled hand are",
  "Ours0.0750.0940.0120.0880.5569.6110.597": ". Comparison with other methods with constraints sampled from groundtruth HumanML3D test set. The constraints are imposedon the first, central and last frames. MDM (Unconstrained) serves as a numerical reference. The failure of any single indicator (marked inred) means the failure of the entire task. Baseline methods always fail in certain metrics while ours performs generally well on all metrics.",
  "Ours0.1100.1040.0230.1140.0680.028": ". Comparison with other methods on unseen tasks. MDM Edit and PriorMDM cannot address these tasks natively. We adapt themwith ad-hoc tricks to fit these tasks. MDM (Unconstrained) serves as a numerical reference. The failure of any single indicator (markedin red) means the failure of the entire task. Baseline methods always fail in certain metrics while ours achieves good balance on motionquality and reaching the given constraints. specified. This task uses absolute position constraint andkey-frame constraint.Task HOI-2: carrying a large ball with its diameter spec-ified. This task uses relative distance constraint and >operation.",
  "Lastly, our framework supports complex physics-basedgeneration. For example, given the mass of each bone for a": "body and using center-of-mass constraint, we can generatephysically plausible motions that conform to the physicallaw of gravity. The tasks conducted in our experiments are:PBG-1: standing with single foot and keep balanced. Thistask uses absolute position constraint and center-of-massconstraint.PBG-2: carrying a heavy ball and keeping balanced at thesame time. This task uses relative distance constraint,center-of-mass constraint and > operation.",
  ". Evaluation Metrics": "For measuring non-semantic motion quality, we use footskating ratio (Foot Skate) proposed in to measurethe motion coherence and over-smoothing artifacts, and usemaximum joint acceleration (Max Acc.) max{xposi} ina generated sample to measure frame-wise inconsistency.For semantic-related motion quality, we adopt commonly-used Frechet Inception Distance (FID), Diversity and R-Precision as in . Moreover, we use constraint error(C. Err) in MAE to measure how well the generated mo-tion satisfies the given constraints. The unsuccess rate isdefined as the percentage of the generated samples whichfail to meet all the constraints within 5 cm threshold. Notethat the semantic-related metrics require that the imposedconstraints also come from the groundtruth data distribu-tion. Therefore, for unseen constraints we only evaluate onnon-semantic motion quality metrics and constraint errors.",
  "We compare our method with several baseline methods. (1)Inverse Kinematics (IK). The optimization process is per-formed on the motion x instead of backpropagating to the": "latent noise z. (2) Inverse Kinematics with regularization(IK+Reg.). The L2-norm regularization |x[i+1] x[i]|2 isadded to help alleviate the frame inconsistency. (3) Motionediting of Motion Diffusion Model (MDM Edit) .We first use MDM to generate trajectories for both rootjoint and controlled joint that meet the given constraint andthen perform inpainting using these trajectories. However,as retrieving joint positions directly leads to invalid bonelengths, we choose to recover the final result from joint ro-tations with a skeleton template. (4) PriorMDM finetunedcontrol . It builds on MDM Edit and further finetunesthe model parameters to capture the relationship betweenthe clean controlled joint and the remaining joints.",
  ". Implementation Details": "We use the official weight of MDM pre-trained onHumanML3D and keep it frozen. We use its DDIMversion with a step of TMDM = 100, which makes our la-tent noise optimization faster. For a fair comparison, allthe baseline methods also use the same DDIM model. Wefind that optimizing with learning rate 0.005 and 100 opti-mization steps generally works well for a majority of tasks.More details are provided in the supplementary material.",
  ". Results and Evaluation": "Quantitative Evaluation. We evaluate on tasks with bothknown constraints () and unseen constraints (Ta-ble 2). As in , we show high-quality and coherentmotion over baselines including IK and MDM Edit meth-ods, which always fail in some certain metrics (markedin red background in the table). Similarly, comprehensiveevaluation on four unseen sub-tasks () shows that ourmethod achieves good balance between motion quality andconstraint errors. Especially, IK produces inconsistent mo-tion (failed in Max. Acc.) when the added constraints aresparse, and generates over-smooth motion (failed in FootSkate) if imposing regularization terms for frame consis-tency. Inpainting methods are not able to produce motionsthat are faithfully constrained.Qualitative Evaluation. In , we demonstrate theversatility of our approach by solving a series of open-settasks described in Sec. 4. Our method generates high qual-ity and visually coherent motions under various constraints.Moreover, our method performs well for tasks with bothsingle and complicated multiple constraints.Especially,inpainting-based methods are unable to deal with inequal-ity constraints and those constraints in which all body jointsneed to be edited, such as center-of-mass constraint.Motion Control for Unseen Tasks. If we construct a setof unseen constraints that are new to the generation model,our method is still able to generate quite reasonable actions.For example, for walking between two walls, the arms arebrought together and the shoulders are shrank to adapt tothe narrow space. This suggests that the proposed approachintriguingly demonstrates a certain level of proficiency infostering the emergence of new skills for motion generation.Motion Programming by LLM. Apart from manually pro-gramming the task into constraints, in we show thepotential for an LLM with reasoning ability to translate taskdescription into constraints and code the error function F,which is similar to . We observe that GPT under-stands concept like touching wall by picking the correctdistToPlane constraint, and picks correct inequality oper-ations for tasks like avoiding overhead barrier and walkinginside a square. More evaluation is in the supplementary.",
  ". Analysis": "Effect of motion prior. As in , in the task of walk-ing inside a square, our method generates valid poses whileIK and IK+Reg. produce invalid ones. Moreover, this typeof whole-body inequality constraint cannot be handled byinpainting-based methods like MDM Edit and PriorMDM.In the task of head height constraint, IK generates inco-herent motion, and IK+Reg. generates over-smooth motionwith massive foot skating. Our method generates coherentmotion while adhering to the given constraint.To show the effect of bone length preserving, we fur-",
  "MDM (Unconstrained)0.048MDM Edit (Position)0.525Ours0.051": ". Comparison of effect on bone length preservation in thetask head height constraint. The inpainting-based method fails topreserve correct bone lengths if recovering from local joint posi-tions. Ours well preserves bone lengths for the generated motions. ther analyze the correctness of neck lengths in the gener-ated motions for the task head height constraint in .As shown in , we can preserve bone lengths even ifwe recover from local joint positions. The inpainting-basedmethod MDM Edit struggles with local joint positions con-verted from global trajectories. The denoising process can-not remedy sparse and invalid inpainting signals, thereforegenerating motions with invalid bone lengths.",
  ". Conclusion": "In this work, we present the new problem of open-set mo-tion control. We propose a new paradigm for this problem,namely programmable motion generation. The key idea isto formulate an arbitrary task as an error function built fromatomic constraints and logical operations and use it to guidea pre-trained motion generation model to generate motionthat meets these constraints. In the future work, we will ex-tend the current framework to whole-body generation whichallows more details, and study how to enable automatic con-straint generation in large and rich semantic scenes.Acknowledgements This work was supported by the National Science and Technology Major Project (2021ZD0112902), the National NaturalScience Foundation of China (62220106003), and the Research Grant ofBeijing Higher Institution Engineering Research Center and Tsinghua-Tencent Joint Laboratory for Internet Innovation Technology.",
  "Okan Arikan and David A Forsyth. Interactive motion gen-eration from examples.ACM Transactions on Graphics(TOG), 21(3):483490, 2002. 2": "Tom Brown, Benjamin Mann, Nick Ryder, Melanie Sub-biah, Jared D Kaplan, Prafulla Dhariwal, Arvind Neelakan-tan, Pranav Shyam, Girish Sastry, Amanda Askell, et al. Lan-guage models are few-shot learners. Advances in neural in-formation processing systems, 33:18771901, 2020. 4, 14 Zhe Cao, Hang Gao, Karttikeya Mangalam, Qi-Zhi Cai,Minh Vo, and Jitendra Malik.Long-term human motionprediction with scene context. In Computer VisionECCV2020: 16th European Conference, Glasgow, UK, August 2328, 2020, Proceedings, Part I 16, pages 387404. Springer,2020. 2 Xin Chen, Biao Jiang, Wen Liu, Zilong Huang, Bin Fu, TaoChen, and Gang Yu. Executing your commands via motiondiffusion in latent space. In Proceedings of the IEEE/CVFConference on Computer Vision and Pattern Recognition,pages 1800018010, 2023. 3 Rishabh Dabral, Muhammad Hamza Mughal, VladislavGolyanik, and Christian Theobalt. Mofusion: A frameworkfor denoising-diffusion-based motion synthesis. In Proceed-ings of the IEEE/CVF Conference on Computer Vision andPattern Recognition, pages 97609770, 2023. 3 Andrey Davydov, Anastasia Remizova, Victor Constantin,Sina Honari, Mathieu Salzmann, and Pascal Fua. Adversarialparametric pose prior. In Proceedings of the IEEE/CVF Con-ference on Computer Vision and Pattern Recognition, pages1099711005, 2022. 3 Erik Gartner, Mykhaylo Andriluka, Hongyi Xu, and CristianSminchisescu. Trajectory optimization for physics-based re-construction of 3d human pose from monocular video. InProceedings of the IEEE/CVF Conference on Computer Vi-sion and Pattern Recognition, pages 1310613115, 2022. 15 Anindita Ghosh, Rishabh Dabral, Vladislav Golyanik, Chris-tian Theobalt, and Philipp Slusallek.Imos: Intent-drivenfull-body motion synthesis for human-object interactions. InComputer Graphics Forum, pages 112. Wiley Online Li-brary, 2023. 3 Chuan Guo, Shihao Zou, Xinxin Zuo, Sen Wang, Wei Ji,Xingyu Li, and Li Cheng. Generating diverse and natural 3dhuman motions from text. In Proceedings of the IEEE/CVFConference on Computer Vision and Pattern Recognition,pages 51525161, 2022. 2, 3, 6, 7, 12 Tanmay Gupta and Aniruddha Kembhavi. Visual program-ming: Compositional visual reasoning without training. InProceedings of the IEEE/CVF Conference on Computer Vi-sion and Pattern Recognition, pages 1495314962, 2023. 8",
  "Daniel Holden, Taku Komura, and Jun Saito.Phase-functioned neural networks for character control.ACMTransactions on Graphics (TOG), 36(4):113, 2017. 2, 3": "Shuaiying Hou, Congyi Wang, Wenlin Zhuang, Yu Chen,Yangang Wang, Hujun Bao, Jinxiang Chai, and Weiwei Xu.A causal convolutional neural network for multi-subject mo-tion modeling and generation. Computational Visual Media,10(1):4559, 2024. 3 Korrawe Karunratanakul, Konpat Preechakul, SupasornSuwajanakorn, and Siyu Tang. Guided motion diffusion forcontrollable human motion synthesis. In Proceedings of theIEEE/CVF International Conference on Computer Vision,pages 21512162, 2023. 2, 3, 4, 7, 12",
  "Diederik P Kingma and Jimmy Ba. Adam: A method forstochastic optimization.arXiv preprint arXiv:1412.6980,2014. 5": "Muhammed Kocabas, Nikos Athanasiou, and Michael JBlack.Vibe: Video inference for human body pose andshape estimation.In Proceedings of the IEEE/CVF con-ference on computer vision and pattern recognition, pages52535263, 2020. 3 Ariel Kwiatkowski, Eduardo Alvarado, Vicky Kalogeiton,C Karen Liu, Julien Pettre, Michiel van de Panne, and Marie-Paule Cani. A survey on reinforcement learning methods incharacter animation. In Computer Graphics Forum, pages613639. Wiley Online Library, 2022. 15 Jing Li, Di Kang, Wenjie Pei, Xuefei Zhe, Ying Zhang,Zhenyu He, and Linchao Bao. Audio2gestures: Generatingdiverse gestures from speech audio with conditional varia-tional autoencoders. In Proceedings of the IEEE/CVF In-ternational Conference on Computer Vision, pages 1129311302, 2021. 2 Zongmian Li, Jiri Sedlar, Justin Carpentier, Ivan Laptev,Nicolas Mansard, and Josef Sivic. Estimating 3d motion andforces of person-object interactions from monocular video.In Proceedings of the IEEE/CVF Conference on ComputerVision and Pattern Recognition, pages 86408649, 2019. 3 Junfan Lin, Jianlong Chang, Lingbo Liu, Guanbin Li, LiangLin, Qi Tian, and Chang-Wen Chen.Being comes fromnot-being: Open-vocabulary text-to-motion generation withwordless training. In Proceedings of the IEEE/CVF Confer-ence on Computer Vision and Pattern Recognition (CVPR),pages 2322223231, 2023. 2, 3",
  "Libin Liu and Jessica Hodgins. Learning basketball dribblingskills using trajectory optimization and deep reinforcementlearning. ACM Transactions on Graphics (TOG), 37(4):114, 2018. 15": "Andreas Lugmayr, Martin Danelljan, Andres Romero, FisherYu, Radu Timofte, and Luc Van Gool. Repaint: Inpaintingusing denoising diffusion probabilistic models. In Proceed-ings of the IEEE/CVF Conference on Computer Vision andPattern Recognition, pages 1146111471, 2022. 3 Lea Muller, Ahmed AA Osman, Siyu Tang, Chun-Hao PHuang, and Michael J Black. On self-contact and humanpose. In Proceedings of the IEEE/CVF Conference on Com-puter Vision and Pattern Recognition, pages 99909999,2021. 2 Yusuke Nishimura, Yutaka Nakamura, and Hiroshi Ishig-uro. Long-term motion generation for interactive humanoidrobots using gan with convolutional network. In Companionof the 2020 ACM/IEEE international conference on human-robot interaction, pages 375377, 2020. 2 Xingang Pan,Xiaohang Zhan,Bo Dai,Dahua Lin,Chen Change Loy, and Ping Luo. Exploiting deep generativeprior for versatile image restoration and manipulation. IEEETransactions on Pattern Analysis and Machine Intelligence,44(11):74747489, 2021. 15 Georgios Pavlakos, Vasileios Choutas, Nima Ghorbani,Timo Bolkart, Ahmed AA Osman, Dimitrios Tzionas, andMichael J Black.Expressive body capture:3d hands,face, and body from a single image.In Proceedings ofthe IEEE/CVF conference on computer vision and patternrecognition, pages 1097510985, 2019. 3 Xue Bin Peng, Glen Berseth, KangKang Yin, and MichielVan De Panne. Deeploco: Dynamic locomotion skills usinghierarchical deep reinforcement learning. ACM Transactionson Graphics (TOG), 36(4):113, 2017. 2, 15 Xue Bin Peng, Pieter Abbeel, Sergey Levine, and MichielVan de Panne. Deepmimic: Example-guided deep reinforce-ment learning of physics-based character skills. ACM Trans-actions On Graphics (TOG), 37(4):114, 2018. 2, 15 Xue Bin Peng, Ze Ma, Pieter Abbeel, Sergey Levine, andAngjoo Kanazawa. Amp: Adversarial motion priors for styl-ized physics-based character control. ACM Transactions onGraphics (ToG), 40(4):120, 2021. 3 Mathis Petrovich, Michael J Black, and Gul Varol. Action-conditioned 3d human motion synthesis with transformervae. In Proceedings of the IEEE/CVF International Con-ference on Computer Vision, pages 1098510995, 2021. 3",
  "Sebastian Starke, He Zhang, Taku Komura, and Jun Saito.Neural state machine for character-scene interactions. ACMTrans. Graph., 38(6):2091, 2019. 2": "Guy Tevet, Sigal Raab, Brian Gordon, Yoni Shafir, DanielCohen-or, and Amit Haim Bermano. Human motion diffu-sion model. In The Eleventh International Conference onLearning Representations, 2022. 3, 5, 6, 7, 12 Jingbo Wang, Yu Rong, Jingyuan Liu, Sijie Yan, Dahua Lin,and Bo Dai. Towards diverse and natural scene-aware 3dhuman motion synthesis. In Proceedings of the IEEE/CVFConference on Computer Vision and Pattern Recognition,pages 2046020469, 2022. 3 Dong Wei, Xiaoning Sun, Huaijiang Sun, Bin Li, Shengxi-ang Hu, Weiqing Li, and Jianfeng Lu. Understanding text-driven motion synthesis with keyframe collaboration via dif-fusion models. arXiv preprint arXiv:2305.13773, 2023. 2",
  "Jungdam Won, Deepak Gopinath, and Jessica Hodgins. Ascalable approach to control diverse behaviors for physi-cally simulated characters. ACM Transactions on Graphics(TOG), 39(4):331, 2020. 2, 15": "Yiming Xie, Varun Jampani, Lei Zhong, Deqing Sun, andHuaizu Jiang. Omnicontrol: Control any joint at any timefor human motion generation. In The Twelfth InternationalConference on Learning Representations, 2023. 3, 4 Liang Xu, Ziyang Song, Dongliang Wang, Jing Su, ZhichengFang, Chenjing Ding, Weihao Gan, Yichao Yan, Xin Jin, Xi-aokang Yang, et al. Actformer: A gan-based transformertowards general action-conditioned 3d human motion gener-ation. In Proceedings of the IEEE/CVF International Con-ference on Computer Vision, pages 22282238, 2023. 3 Mengdi Xu, Peide Huang, Wenhao Yu, Shiqi Liu, XilunZhang, Yaru Niu, Tingnan Zhang, Fei Xia, Jie Tan, and DingZhao. Creative robot tool use with large language models.arXiv preprint arXiv:2310.13065, 2023. 8",
  "IEEE/CVF International Conference on Computer Vision,pages 1492814940, 2023. 2": "Ye Yuan, Jiaming Song, Umar Iqbal, Arash Vahdat, and JanKautz.Physdiff: Physics-guided human motion diffusionmodel. In Proceedings of the IEEE/CVF International Con-ference on Computer Vision, pages 1601016021, 2023. 2 Siwei Zhang, Yan Zhang, Federica Bogo, Marc Pollefeys,and Siyu Tang. Learning motion priors for 4d human bodycapture in 3d scenes. In Proceedings of the IEEE/CVF In-ternational Conference on Computer Vision, pages 1134311353, 2021. 3 Xiaohan Zhang, Bharat Lal Bhatnagar, Sebastian Starke,Vladimir Guzov, and Gerard Pons-Moll. Couch: Towardscontrollable human-chair interactions. In European Confer-ence on Computer Vision, pages 518535. Springer, 2022.3",
  "A.1 Tasks for Quantitative Evaluation": "We design two evaluation protocols for sub-tasks in . The first protocol is task with known constraints, whichmeans the added constraints are sampled from existing hu-man motion datasets, i.e., HumanML3D test set in ourexperiments. In this way, in addition to non-semantic mo-tion quality metrics and constraint errors, we can evaluateon semantic-related motion quality as well since we havegroundtruth motions. The second protocol is task with un-seen constraints, which means the added constraints do notcome from existing motions and are designed by ourselvesto evaluate the generation capability on real open-set motioncontrol tasks. We experiment on one sub-task for knownconstraints in in the main text, and four sub-tasksfor unseen constraints in in the main text.Task with known constraints. For Task HSI-1 head heightconstraint in , we constrain the head height for threespecified key-frames, i.e., first, middle and last frames tobe equal to that in the motions sampled from HumanML3Dtest set. The text prompt and motion length for generationare also obtained from that motion sample. The constrainterror for evaluation is the mean absolute error (MAE) av-eraged over the three key-frames. We follow PriorMDM for evaluating metrics including FID, R-precision andDiversity, and follow GMD for evaluating Foot skat-ing ratio. The quantitative evaluation is conducted on 544generated samples.Task with unseen constraints. In , for Task HSI-2avoiding overhead barrier, we constrain the head height tobe lower than 0.5 m for the middle frame and higher than1.5 m for the first and last frames to ensure normal standingposes at the beginning and the end. We also constrain theheights for both feet to be close to the ground. Note thatthis is a challenging task due to the low head height, and thecombined constraints prevent trivial generations like step-ping on stairs or always lying on the ground. The constrainterror for evaluation is defined as MAE for the head heightand foot heights.For Task HSI-3 walking inside a square, we constrainthe walkable area to be a square 1 < x < 1, 1 < z < 1.The constraint error for evaluation is defined as the per-jointMAE averaged over x- and z-axis and all frames.",
  "where D includes x-axis and z-axis and Nj is the numberof joints.For Task GEO-1 hand touching wall, we constrain theleft hand (joint 20) always on a vertical plane. The plane is": "randomly sampled with its distance to the origin no greaterthan 3. The constraint error for evaluation is defined as themean distance between the controlled hand and the givenplane averaged over all frames.For Task HOI-1 moving object, we constrain on theglobal positions of the left hand (joint 20) at the first andlast key-frames. We specify a set of beginning and end handpositions. The constraint error for evaluation is defined asthe mean distance between the hand and the goal averagedover the two key-frames.For the first three tasks, i.e., Task HSI-2, HSI-3 andGEO-1, the text prompts and motion lengths are sampledfrom a selected set of samples from HumanML3D test set,mainly involving the action walking. The sample ids arelisted below: 000130, 000178, 000285, 000337, 000363,000600,000665,000679,000759,000998,000099,000696,000700,003703,001161,001617,001848,003193, 003437, 004455 and their mirrored ones. For TaskHOI-1, we manually compose a set of text prompts relatedto action moving such as a person moves an object from aplace to another place. The quantitative evaluation for eachunseen task is conducted on running 32 generated samples.",
  "A.2 Baseline Details": "Unconstrained MDM. The original motion representationfor MDM contains both local joint positions and jointrotations. For simplicity we recover global joint positions(joint positions in the global coordinate) from local jointpositions. The unconstrained MDM only serves as a nu-merical reference.IK and IK+Reg.We implement IK as an ablated ver-sion of our method, in which the gradient F is back-propagated to motion x instead of the latent vector z. Wealso consider a variant IK with regularization (IK+Reg.), inwhich we add a L2-norm regularization term on all jointsLreg = |x[i+1] x[i]|, where i is the temporal index. Thisresults in a combined error function Lconstraint + wLreg.We empirically set the regularization weight w = 1.0. Weobtain global positions from joint rotations with a humanskeleton template with fixed bone lengths. Like our method,IK and its variants can also handle arbitrary open-set controltasks, so we compare with IK and IK+Reg. in all quantita-tive and qualitative experiments.Inpainting-based methods.MDM Edit and PriorMDMfinetuned control are inpainting-based methods. They sup-port motion control tasks by assigning exact joint trajecto-ries. However, they cannot natively handle tasks describedby constraints, especially, inequality constraints. Moreover,PriorMDM needs to finetune the network for controlling aspecified joint and only finetuned models for hand, foot androot trajectories are provided . For the above reasons,we only compare with MDM Edit on trajectory control-based tasks, i.e., Task HSI-1, Task GEO-1 and Task HOI-1, and we compare with PriorMDM on Task GEO-1 and TaskHOI-1, which only involves hand trajectory control.In their original papers, MDM Edit and PriorMDM fine-tuned control only support inpainting with root trajectoriesand valid local joint positions.Since the constraints fortasks defined in are majorly represented in globalcoordinates, we adapt MDM Edit and PriorMDM controlto handle control signals in global positions. Specifically,we first generate a sample and take its root trajectory. Wethen use ad-hoc tricks to generate a trajectory for the controljoint in global positions that satisfies the given constraintand further convert it to local positions given the root tra-jectory. Finally we inpaint both the root trajectory and thelocal trajectory of the control joint. Similar to IK, as recov-ering from local joint positions yields invalid bone lengths(see in the main paper), we obtain the global mo-tion from joint rotations using a human skeleton templatewith fixed bone lengths. Also, for PriorMDM we use modelblending for inpainting both root trajectory and controljoint trajectory.The ad-hoc tricks are designed as follows: for Task HSI-1 and HOI-1, we directly set the key-frame positions withthe required constraint. For Task GEO-1, we project thegenerated hand trajectory onto the given plane to obtain thenew hand trajectory in the global positions.",
  "A.3 Implementation Details": "Following unconstrained MDM, we also recover global po-sitions from local joint positions. Since the error functionfor each task may vary, while optimizing with learning rate0.005 and 100 optimization steps generally works well fora majority of tasks, we may also increase the initial learn-ing rate to up to 0.05 for faster convergence in some cases.Besides, we may add regularization term using absolute po-sition constraint to preserve desired motion characteristicsfor root trajectory or body parts in some cases.Constraint relaxation. We only apply constraint relaxationon Task GEO-1, Task GEO-2 and Task HOI-1, which in-volves absolute position constraints of point, line and plane.It takes advantage of translation invariance of motion forfast convergence and compensates for the limited horizon-tal space coverage of root trajectories in the original mo-tion prior. For Task GEO-1, we relax the plane constraintby fitting the generated hand trajectory on an optimal ver-tical plane. For Task GEO-2, we relax the line constraintby fitting the foot trajectories on an optimal line. For TaskHOI-1, we relax the required beginning and end pointsA, B to fall on the line connecting the beginning and endpoints generated by the model A, B and keep their middlepoints the same, i.e., Arelax = P +AP| AP ||AB|",
  "MDM (Unconstrained)0.0869.6560.5450.118Ours (NS = 1)0.0759.6110.5560.012Ours (NS = 5)0.0729.4220.6480.002": "Table A2. Effect of initial point search. NS denotes the number ofsearches. Using a random initial point search leads to significantlysmaller constraint error. It provides a solution for generating mo-tions that better adhere to the given constraint. tioned relaxation strategy every K steps and minimize theconstraint error for x using the updated constraints. In thisway the whole optimization process can be implemented asrelax-and-minimize loops. For a fair comparison, IK andIK+Reg. also use constraint relaxation for experiments in in the main paper.",
  "A.4 Experiment Details for Bone Length Preserving": "We provide more experimental details for in themain paper. For the generated motions in Task HSI-1 in, we investigate the neck length (bone length be-tween joint 12 and 15) at the key-frames where the headheight constraint is imposed. We empirically set a rangebetween 0.08-0.025 and 0.08+0.025, and the neck lengthwhich falls outside this range is considered as incorrectbone length. The bone length incorrect ratio is defined asthe ratio of key-frames with incorrect neck lengths in all thegenerated key-frames. We find that unconstrained MDMand our method have low incorrect ratio even if we directlyrecover global positions from local joint positions. How-ever, if we recover motions generated by MDM Edit fromlocal joint positions, the incorrect ratio becomes very large,indicating that a great percentage of the generated samplesare of invalid human layouts. For this reason, we choose",
  "A.5 Additional Analysis": "Effect of constraint relaxation.As in Table A1, theconstraint relaxation strategy significantly reduces the con-straint error for goal reaching tasks on the horizontal plane,such as task hand touching wall and moving object. Whilethe constraints are better satisfied, we observe slight de-crease in motion quality, which is indicated by Foot Skate.Also, it is shown that the constraint relaxation is a generaloptimization strategy since there is a significant decrease inthe constraint error for IK as well.Effect of initial point search. The initial noise z may affectthe final constraint error if the initialized motion is too faraway from reaching the constraints. A straightforward waywould be to sample random noise z in several runs and pickthe result with the smallest constraint error. We conductexperiment on Task HSI-1 using the same setting as in the main paper and compare the results of NS = 1and NS = 5. Here NS denotes the number of initial pointsearches. The results are shown in Table A2. We observethat using a random initial point search leads to significantlysmaller constraint error but at the cost of diversity and FIDscores. It provides a solution for generating motions thatbetter adhere to the given constraint.Diversity of generated motions. By optimizing the latentvector of generated motions to conform to the motion prior,our method can generate diverse motions under the sameconstraint. For example, in the task of left hand alwaystouching head, apart from single hand touching the face,we observe that constraining only one hand can also giverise to the touching of another hand. (see and in the main paper).",
  "B. Details for Motion Programming by LLM": "Our programmable motion generation framework alsomakes automatic programming possible with the aid oflarge language models (LLM). As in Fig. B1, in order togenerate code for the error function F, we first feed instruc-tions to GPT with the rules and ingredients for motionprogramming, e.g., input arguments and functions in theatomic constraint library. After that, one can feed the textualdescription for an arbitrary open-set motion control task toGPT. In Fig. B1 we show the textual input fed to GPT aswell as the raw code output by GPT for Task GEO-1, HSI-3 and HSI-4 in the main paper. We observe that an LLMcan pick correct atomic constraints, logical operations (e.g.>, <), and procedural operations (e.g. if-else clauses)for given tasks. Note that the code blocks labeled with GPTmarkers for Task GEO-1 and Task HSI-4 in in themain paper are slightly modified in the coding style to make",
  "Evaluation tasks": "walking with hand always touching face.walking inside a square.carrying a ball.carrying a heavy ball.walking with feet on a straight line.walking with hand touching a wall.walking in a gap between two walls.walking to avoid an overhead barrier.picking object from A to B.walking with velocity constraint on three frames.standing and keeping balanced with single foot.walking with head height constraint on three frames.lying on a bed.sitting on a chair.kicking a ball in the last frame.walking with both hands in contact.jumping over a barrier.pointing to a direction with left arm.dancing with specified velocity magnitude on three frames. twisting for two circles.",
  "Table A3. Evaluation on motion programming by LLM. Tasks thatare successfully handled by LLM are labeled with": "them consistent with other manually written code, withoutchanging the code logic.More evaluation. As in Table A3, we design 20 uniquetasks (including those presented in the main paper), andevaluate the success rate of LLM programming via compar-ing to manual programming. With little prompt engineer-ing, the success rate turns out to be 14/20. In failure cases,it typically picks incorrect inequality logical operations, orprovides excessive and incorrect physical constraints. Nev-ertheless, we find that LLM comes up with novel constraintsbeyond manual programming, e.g. tilt angle constraint forthe action balancing.",
  "C. Discussion and Limitations": "Sources of error. As we propose a general framework foropen-set motion control tasks, the performance of individ-ual modules can be further improved. First, we observesome unrealistic poses and motion artifacts in our gener-ated motions. Since the FID score shows that our resultshave similar quality to unconstrained MDM (See inthe main paper), a possible solution is to enlarge the pre-trained model together with more training data. Also, forcomplex tasks, either an end user or an LLM may have diffi-culty of crafting detailed and appropriate constraints, whichis likely to lead to unnatural motions. Second, the constrainterror sometimes remains big compared to IK, for example,for the unseen Task HSI-2. Although it is reasonable that IKdirectly optimizes on motion x and thus has less difficulty for reaching the constraint, we will further investigate betteroptimization approaches to solve this issue. Possible solu-tions include (1) combining optimized and IK-based motionin the denoising process, (2) relaxing on the parameters ofthe generation model and involving it in the optimizationprocess like , and (3) searching for more suitable opti-mizers.Moreover, the action semantics for the generated motionis observed to change slightly in the experiments, e.g. forTask HSI-1. This calls for more suitable generation modelsand optimization strategies that can better adhere to the textcondition.Coverage of the proposed constraint library. We exam-ine the coverage of our proposed library for daily motionson BABEL-120 dataset . We find that nearly 16% ofthe actions involve periodic, rotational or symmetric move-ment, whose control is not directly supported by our library.We plan to further add frequency-domain, rotational andsymmetric constraints into our library.Comparison with reinforcement learning and trajectoryoptimization.We note that RL-based andtrajectory optimization approaches also build composi-tional reward or goal functions for specialized motion con-trol tasks, and we here provide a discussion for these ap-proaches: (1) Based on our experiments, the error functiondesign in this work is not as difficult as reward design in re-inforcement learning (RL), not only because the error func-tion only handles the constraints, but the optimization inlatent space is easier to converge than RL training, since thepre-trained model already provides a neat and smooth man-ifold as the optimization space. (2) The pre-trained genera-tion model is easier to accommodate more motion skills andscale up with more data. This is the main consideration forus towards solving open-set tasks. RL usually requires spe-cific design to support diverse tasks . (3) It is easier thanRL to control the semantics via text condition. (4) RL andours are complementary. RL has better physics-groundedqualities. (5) Compared to trajectory optimization, optimiz-ing latent code better preserves semantics imposed by textcondition. Besides, optimizing latent code may be moreadvantageous for composing novel types of actions since itacts like semantic interpolation in the data distribution. Tra-jectory optimization normally optimizes on one referencemotion .Time performance. Currently it costs a few minutes foreach customized task, but is still much better than previousworks that require collecting new data and training new net-works. We have not focused a lot on improving optimiza-tion efficiency in this work, which might be a direction inthe follow-up works. Although not applicable to real-timegeneration, it is suitable for off-line content creation due toits high customizability. Hi, I'd like to give you a task description and you are required to write python code for me. Specifically, the input argument is \"Motion\", it is a list of dictionaries where the index represents the frame and each dictionary stores the 3D coordinates of all human body joints. I will also give you a task description containing constraints of human motions. Then you need to write python code to compute the total error of the input human motion following my given constraints. The function you can use is as below: \"DistToPoint\", \"DistToLine\", \"DistToPlane\", which compute the distance between a point to the other point, a line, and a plane respectively, and \"max(margin-Motion, 0)\", \"max(Motion-margin,0)\", which provide the inequality constraints for motion. Do you understand the rule?",
  "Task HSI-3": "a person walks forward. The height of the barrier is 1.3m. The person should lower his head and spine in order not to collide with this barrier. The walking distance can be represented as the z-axis of the head and spine joint, respectively. The barrier is set between 2m and 3m for the walking distance. The actual head height should also include body_width, and the same for spine height.",
  "return total_error": "Figure B1. Motion Programming by LLM. After feeding the instruction to GPT, we provide the textual description for an arbitrary open-setmotion control task. GPT will output code for the corresponding error function. We observe that GPT understands concept like touchingwall by picking the correct distToPlane constraint, and picks correct inequality operations for tasks like avoiding overhead barrier andwalking inside a square."
}