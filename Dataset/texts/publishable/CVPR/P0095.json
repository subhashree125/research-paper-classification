{
  "Abstract": "The unprecedented capture and application of face im-ages raise increasing concerns on anonymization to fightagainst privacy disclosure. Most existing methods may suf-fer from the problem of excessive change of the identity-independent information or insufficient identity protection.In this paper, we present a new face anonymization ap-proach by distracting the intrinsic and extrinsic identity at-tentions. On the one hand, we anonymize the identity in-formation in the feature space by distracting the intrinsicidentity attention. On the other, we anonymize the visualclues (i.e. appearance and geometry structure) by distract-ing the extrinsic identity attention. Our approach allowsfor flexible and intuitive manipulation of face appearanceand geometry structure to produce diverse results, and itcan also be used to instruct users to perform personalizedanonymization. We conduct extensive experiments on mul-tiple datasets and demonstrate that our approach outper-forms state-of-the-art methods.",
  ". Introduction": "By making full use of face images, modern AI technologieshave enabled us a more convenient life . How-ever, this may raise a wide social concern on privacy be-cause face images are easy to capture but cannot be easilychanged. Although some strict constraints (e.g. laws) wereset up in the last few years , the privacy disclo-sure events continue to emerge one after another.Anonymization has attracted increasing attention, whichusually has two basic requirements. The first one is to en-sure identity safety by fighting against re-identification. An-other is to preserve the data utility, such as image quality,face detectability, expression and user-defined attributes,which may vary under different scenarios. Besides protect-ing the original identity, we also take identity intrusion intoconsideration to reduce the risk of bringing troubles for theothers. The kind of technology has multiple advantages,",
  ". Demonstration of our approach for face anonymization": "such as: (1) prevent unauthorized users, organizations andapplications from freely collecting and using personal data;(2) help people to avoid troubles by blocking the relation-ship disclosure between identity and the other factors, suchas location, action, event and so on; (3) maintain the datausability in various applications, like autonomous drivingand remote medical system, without worrying about infor-mation leakage even if the data were attacked or misused.Traditional methods (e.g. pixelation and blurring [34, 58]), seem simple and effective for privacy protection, butmay easily damage the image content and quality, result-ing in poor data reusability (e.g. face may become unde-tectable). Recently, the generative method (e.g. GAN) showpromising performances on supporting realistic face synthe-sis , which makes it possible to improve im-age quality and utility preservation. On this basis, many ex-cellent anonymization trials were conducted from differentviewpoints .However, many of them may suffer from the problem of ex-cessive change of the identity-independent information toensure anonymity, or insufficient identity protection in orderto preserve more data utility. The former may lead to perfor-mance drop on utility preservation, and the latter may leadto degraded protection against re-identification or identityintrusion, which would prevent the existing methods fromachieving a good privacy-utility (PU) tradeoff.To address the above problem, we present a new faceanonymization approach by exploiting the intrinsic and ex-trinsic face characteristics for identity attention distraction,where a deep generative model is employed to synthesize",
  "arXiv:2406.17219v2 [cs.CV] 6 Jul 2024": "anonymous face images.To enable flexible control onanonymization, we divide the input data into two types, in-cluding intrinsic identity feature and extrinsic visual clues.Many works intend to embed additional PU tradeoff con-strains in their model, but this may increase the difficultyof model optimization. Differently, we propose to performdata anonymization in ahead and let the deep generativemodel only focus on synthesizing high utility images. Sinceattention reflects the intrinsic characteristics of the recogni-tion process , we perform identity featureanonymization (IFA) by distracting the attention of the orig-inal identity to let the face recognition model make wrongprediction. Since the extrinsic face characteristics may at-tract human attention for re-identification, we perform vi-sual clue anonymization (VCA) by distracting the identityattention of visual clues (i.e. visual appearance and geom-etry structure) that may easily lead to privacy disclosure. briefly demonstrates the idea of our approach.Notice that, by proper modeling, IFA can achieve a lowloss of identity independent information for utility preser-vation. In the meanwhile, VCA can enable users more free-dom in producing diverse results without significant dam-agement on data utility. For example, it can support fine-grained adjustment on geometry structure to support moreeffective anonymization, which was rarely considered pre-viously (e.g. ). Duringthe anonymization process, our approach can enable usersto easily spot what kind of changes were made by compar-ing input and output, which can be used to instruct users onhow to perform personalized anonymization. In summary,the main contributions of this paper are as follows: We propose a new synthetic face anonymization approachfrom the viewpoint of identity attention distraction by ex-ploiting the intrinsic and extrinsic face characteristics.",
  ". Related Works": "Class Activation Mapping. Interpretability is very impor-tant for deep learning based AI systems. Visualization ofCNN predictions has received wide attention to interpretdeep networks . The most relevant approach isCAM which can highlight class-specific discriminativeregions by mapping the predicted class score back to thelast convolutional layer of a face classification network. In, CAM was generalized to gradient CAM that exhibitedexcellent ability in providing faithful visual explanations.In , CAM was used to locate and change the identity- independent regions and attributes which were utilized toanonymize face images to fool human instead of machine.But, in our study, the output of gradient CAM is used asan indicator to find and recast the identity feature to foolboth human and machine, which can enable us to reducethe information loss during the anonymization process forachieving a better privacy-utility tradeoff.Face Synthesis. GAN has already been used in face im-age synthesis by playing an adversarial game between gen-erator and discriminator . In , a landmarkdriven synthesis method was proposed for talking head gen-eration. In , MaskGAN was proposed for interactiveface image manipulation. In , DeepFake was used toperform face swapping to protect medical video data. In, FaceShifter was introduced to perform face swappingby focusing on identity transformation, which was furtherapplied in and to support face anonymization.Face Anonymization. Along with the unprecedentedapplication of face images, face anonymization becomes in-creasingly important and lots of interesting methods wereproposed . relied on inpainting to synthesizeanonymous face. adopted attribute edit-ing, classifier or control vector to support face anonymiza-tion. studied the reversible face anonymizationmethods based on password or attribute vector. employed disentanglement or identity perturbation to de-identify face identity. synthesized anonymousfaces in the StyleGAN latent space. only focusedon fooling human eyes by preserving the original identity.Different from previous works, we present a new solutionfrom the viewpoint of identity attention distraction.",
  ". The Proposed Approach": "In this section, we elaborate on our proposed approach.To alleviate developing complicated generative models, wepropose a very simple two-step based anonymization pro-cess in (a). Given a face image x, we rely on step1to preprocess it by using IFA and VCA, and their outputsare used in step2 to synthesize an anonymous face x, wherestep1 is only responsible for anonymization, step2 is onlyresponsible for face image synthesis, and model trainingonly happens in step2. Under this setting, we are able toreduce the difficulty of model design and optimization forprocessing a complicated privacy-utility tradeoff. Next, wepresent the details in several sections.",
  ". Overview of our approach: (a) the flowchart, (b) identity feature anonymization (IFA), and (c) visual clue anonymization (VCA)": "convolutional layer (its output is denoted as A). First, theinput data flow goes along the red solid lines to find theidentity related feature maps in A on top of the calculatedCAM heatmap H . Then, the data flow switches to theblack lines after performing attention distraction on A, goesthrough A, and finally output the recasted identity featurefx for anonymization. A is calculated from A by distract-ing the identity attention away from H, where the visualresults of H and H in (b) illustrate the function ofthis operation. Note that the identity of x may be new for and, thus, the prediction may be incorrect. But, it doesnot matter. We simply employ the pre-trained classes as thecodebook to interpret the identity of any input faces regard-less of whether these identities were trained or not. The finalsoftmax output is used as the indicator to determine whichpre-trained identities are more related to x.Let ci denote the top i-th prediction result (i.e. identityclass) of . The CAM heatmap of any given class ci can becalculated as the weighted combining of the forward activa-tion maps by following",
  "Ajkl.(2)": "We analyze the importance of facial features on top of H.Motivated by the existing studies that some attributes arecritical for identification while the others not ,we can reasonably suppose that anonymization can be for-mulated as a min-max optimization problem by suppressingthe identity dependent attributes and preserving the identity-independent ones. We model this as an attention distractionproblem by using the identity correlated CAM heatmapsand enforcing Hci 0. Then, we have",
  ". Visual Clue Anonymization": "In this subsection, we present how to perform visual clueanonymization by extrinsic identity attention distraction us-ing both the visual appearance and the geometry structurein the visual space. One may think of directly replace theoriginal data q with a completely (or predefined) differentdelegate q (e.g. from white skin to black skin) so that noone can re-identify it, but this may easily damage data util-ity (e.g. ethnic and expression preservation ). Apossible better choice is to sample some q based on q so thatthey share more identity independent information than iden-tity dependent information in a random manner. As shownin (c), we first introduce an instance-level proba-bilistic delegate (IPD) sampling method and then use it toanonymize the visual clues.IPD Sampling. Given data q, we build a candidate setMq by finding its top k-nearest neighbors in the featurespace (e.g. Arcface ). For each candidate XiMq, werely on the simple random sampling to obtain a delegateq=XkMq according to the probability set {P(Xi), 1 i size(Mq)|",
  "XjMq e[u(q,Xj)/(2u)] ,(6)": "where is the privacy budget, u is the utility function andu is its 1 sensitivity. Notice that DP received increasingattention in face anonymization since it can provide a theo-retically sound privacy protection by adding random pertur-bation. In previous works, DP is usually used with low-level or middle-level data (e.g. pixels and identity features) by adding Laplace noise. Differently, we gen-eralize it to perform instance-level data sampling to reducethe disclosure risk of the identity information.Visual Appearance Anonymization (VAA). Since thevisual appearance may be correlated with some useful at-tributes, such as ethnic and age, the significant change of itmay easily damage the data utility. To solve the problem, asshown in (c), we rely on IPD to sample a delegateface Za by using the following utility function (i.e. u = ua)",
  "maxj d(x, Xj) minj d(x, Xj)(7)": "so that Za and x would have a high probability to share thesame set of data utility, where d(x, Xj) is the 2 distancebetween the features of x and Xj.Geometry Structure Anonymization (GSA). The de-tected landmarks are used to describe the facial geome-try structure Sx of x. Instead of directly modifying the land-marks (which is a complicated task to make the result lookreal), we prefer to perform instance-level anonymization byreplacing Sx with another realistic delegate. As shown in (c), the process consists of two steps. We first relyon IPD to sample a delegate Sx that has the same pose asSx by using the following utility function (i.e. u = ug)",
  "maxj d(Sx, Xj) minj d(Sx, Xj)(8)": "that tends to sample a more distinct geometry structure.Since this may violate the original pose and expression, wethen recover them by adjusting the contour and mouth of Sxaccording to Sx and preserving the thickness of the upperand lower lips of Sx, resulting in Sx. To recover the origi-nal background, we fuse Sx and the background xb of x asthe geometry input Zg. Note that Sx is not the same as Sx,which would reduce the probability of identity intrusion.",
  ". Conditional Face Synthesis": "This subsection focuses on face synthesis. As shown in thestep2 of (a), our generator G takes appearance im-age Za, identity feature Zid and geometry input Zg as input,goes through the appearance encoder E and the conditionaltranslator T to produce a realistic face image x.Appearance Encoder E is adopted to process Za to ob-tain an appearance feature fa. We realize it by stackingsix ResBlocks and a SumPooling layer . Seman-tic segmentation is used to obtain the foreground faceimage of Za as input, when it is not available, we can ap-proximately use the detected landmarks to realize this.Conditional Translator T aims at translating Zg and thecondition input Zc to a realistic face image x. We employa U-Net like structure to build T by following via downsampling and upsampling with ResBlocks, where adaptive instance normalization (AdaIN) is employedto fuse the identity and appearance information encoded inZc which is defined as the fusion of Zid and fa by usinga concatenation (Concat) layer and a fully connected (FC)layer: Zc=FC(Concat(Zid, fa)). Note that, if the out con-tour were changed, T would adaptively inpaint the back-ground so that the generated face could smoothly dissolveinto the original background. Users can realize personalizedanonymization by manipulating Zid, Za and Zg under dif-ferent scenarios. For example, one can simply use the facialregion of x to preserve the original appearance or attributes.",
  ". Training and Optimization": "Let {x, y} be a set of randomly sampled face images, x actsas the image to be anonymized and y acts as the identityprovider, we present a 1:1 alternative reconstruction and cy-cle swap-reconstruction strategy for network training. Forthe former, x is reconstructed from x, denoted as Zid = fx.For the latter, we change the identity from x to y and back tox in a loop, denoted as Zid = fy. The following multi-taskloss function is used to optimize our generator",
  "LAll = 1L1 + 2L2 + 3L3 + 4L4 + 5L5 + 6L6,(9)": "where L1 is the adversarial loss, L2 is the feature matchingloss borrowed from to stabilize the training process bymatching the multi-layer features of discriminator D for theinput and output images, L3 is the perceptual loss, L4 isthe appearance loss, L5 is the identity loss, L6 = E[|xb gb|1] is the 1 between the background images of x and thegenerated image g, and 1 6 are parameters.The adversarial loss L1 is defined as",
  "(10)": "where LG(x, x) = E[max(0, 1 + D(x, Sx)) + max(0, 1 D(x, Sx))] is used to optimize the generator G with thehelp of D which takes paired data (image,structure) asinput, LD(x) = E[D(x, Sx)] is used to optimize D,x = G(fx, Za(x), Zg(x)), y = G(fy, Za(x), Zg(x)), x =G(fx, Za(y), Zg(y)). The perceptual loss L3 is defined as",
  ". Settings": "Dataset.Three popular datasets CelebA-HQ , Vg-gFace2 and LFW are used. CelebA-HQ has 30,000high quality facial images from 6,217 persons, where 5,000images are used as the test set. VggFace2 has 3.31 millionimages from 9,131 persons, where a subset of 5,000 imagesfrom 1,000 identities are used for systematical analysis andfair comparison. LFW has 13,233 face images from 5,749individuals, where 1,680 identities have more than one im-age and we use a subset of 5,000 images from them.Implementation Details. For pre-processing, we em-ploy to detect facial landmarks and BiSeNet to per-form semantic segmentation. We rely on and tobuild G and D by stacking ResBlocks. We train our networkto generate 256256 images by using the Adam optimizer.We set 14=1, 5=6=2=2, 1=0.6, and 3=0.8. Ourapproach is trained on CelebA-HQ and evaluated on all.Evaluation Measures. Our approach is evaluated fromthe perspectives of privacy protection (anonymization andidentity intrusion) and data reusability. For anonymization,we calculate re-identification (ReID) rate (in percentage %). For identity intrusion, we calculate identity swapping (IDS)rate (%). The pre-trained FaceNet are ArcFace areused for face verification. The cosine similarity is used forArcFace with two thresholds 0.30 and 0.35, and the 2 dis-tance is used for FaceNet with three thresholds 0.9, 1.0 and1.1. Face alignment is used to evaluate face detectionrate (%). LPIPS and SSIM are used to evaluate imagequality. Pre-trained classifiers are used to evaluate at-tribute preservation (%), including expression, ethnic, gen-der, age and makeup.",
  ". Main Results": "We mainly compare our approach with the following repre-sentative and state-of-the-art (SOTA) methods: CIAGAN, PIFD , DeepPrivacy (DP1) , DeepPrivacy2(DP2) , LDFA , FALCO and Riddle .Qualitative Results. As shown in , the suc-cess of Blurring and Pixlation can be contributed to the de-struction of image content, which would tell the observersthat the data is under protection. In contrast, the genera-tive methods not only show excellent anonymization per-formance but also show higher probability of making theresults imperceptible to observers. DP1 and DP2 may failto retain some facial attributes, like expression. CIAGANand LDFA may generate distorted faces. PIFD may bringsome artifacts. FALCO and Riddle may lose the facial de-tails. Compared with the other methods, our results can notonly look realistic but also preserve more original attributes.Quantitative Results. Since the image content of Pixe-lation and Blurring is significantly destroyed, we only com-pare with the generative methods in . Ours, Rid-dle and PIFD outperform the other methods onReID across different face recognition backbones, espe-cially when larger thresholds are used, where DP2 exhibitscompetitive results. Besides, it is very important to see if",
  "cos >0.30 cos >0.352 <0.92 <1.02 <1.1": "CIAGAN (1.7, 93.3) (0.5, 51.4) (0.5, 87.0)(3.2, 99.9)(11.3, 100)PIFD(0.0, 79.3) (0.0, 19.1) (0.0, 58.6)(0.0, 99.7)(0.0, 100)DP1(0.9, 70.9) (0.2, 19.4) (1.2, 73.5)(4.8, 99.9)(15.0, 100)DP2(0.5, 78.5) (0.1, 26.4) (0.6, 67.4)(3.7, 99.8)(7.4, 100)LDFA(4.9, 81.3) (2.1, 33.6) (4.3, 74.6) (15.9, 99.8) (24.8, 100)FALCO(6.7, 81.8) (2.7, 37.0) (1.4, 83.7)(1.7, 99.9)(5.4, 100)Riddle(0.0, 72.9) (0.0, 26.2) (0.6, 77.7)(1.2, 99.8)(2.3, 100)Ours(0.0, 78.1) (0.0, 19.6) (0.1, 34.9)(0.3, 98.1)(1.0, 100)",
  "Express. Ethnic Gender Age Makeup": "CIAGAN78.746.780.981.374.70.5580.358PIFD82.348.584.482.963.70.1240.771DP154.852.084.784.466.80.1920.785DP259.152.684.385.378.90.1270.779LDFA76.148.877.978.874.20.1240.733FALCO82.651.884.886.377.60.3070.475Riddle77.941.881.084.468.90.3000.530Ours84.251.585.183.380.10.1200.799 there happens identity intrusion after anonymization. CIA-GAN suffers from the highest IDS rates. Compared with thebest performed PIFD and DP1, our approach obtains com-petitive results (e.g. 58.6% vs. 34.9% for PIFD and Ours),which can be contributed to identity attention distraction.Also, we test another recent AdaFace model for faceverification. According to , it is easy to observe thatour approach exhibits similar behavior to that in .Utility Preservation. We compare the data utility of dif-ferent methods in . DP1 and DP2 performs pooron expression.PIFD, DP1 and Riddle perform poor onmakeup. All these methods perform poor on ethnic. Com-pared with the other methods, our approach achieves a muchbetter balance on all items and performs well on preservingexpression and makeup. We also find that, as with SOTAmethods, our approach can also achieve 100% face detec-tion rate, which also reveals its high data utility.Diversity and Controllability. As shown in the first tworows of , our approach can produce diverse resultsthat look different from each other. Besides, we have triedto add a similar distraction item to Equ(5) to test the diver-sity of A by using the bottom j-th prediction (1 j 3).According to the last row of , although we can pro-duce diverse results, the facial expression has changed from",
  ". Demonstration of our results on controlling the geometrystructures and visual appearances. Each of the top row shows theemployed geometry structures and visual appearance images": "non-smile to smile, which indicates that adding such diver-sity may affect the data utility. Our approach can also sup-port flexible anonymization according to user requirementsand practical applications. For example, in , we canproduce different anonymous faces by controlling the ge-ometry and visual appearance inputs, where the influencesof changing the geometry structure is more significant.Analysis. According to the above results, it is obviousthat achieving high anonymization performance is relativelyeasy but it is somewhat difficult to (a) prevent identity in-trusion and (b) preserve data utility. The reason why (a) ishard lies in that it is uneasy to ensure the non-existence ofa synthesized identity in reality. The reason why (b) is hardlies in that identity is closely related to some critical facialattributes and the change of identity would inevitably leadto some variations on facial attributes. In , 4 and 5,we can intuitively observe the attribute changes on the faces(e.g. eye and nose) and they may vary for different persons.Most existing methods pay much less attention on this andanonymization is usually achieved at the cost of damagingtoo much useful information. Although our approach cannot perform the best all the time, it has achieved a betterprivacy-utility tradeoff. This can be mainly contributed toour anonymization strategy of minimizing the changes onidentity independent attributes. But, our approach still suf-fers from the drawbacks of well preserving some facial at-tributes, such as ethnic and eye gaze direction, which areleft for the follow up works.",
  ". Ablation Study": "In , we plot the influential curves for the top Kpredictions of the face classification network. With top 1distraction, our approach can remove over 75% of iden-tity information. When increasing K, the ReID and IDSrates keep decreasing and the trend would slow down whenK 2. The utility preservation performance would de-crease slightly along with K (see Attribute and LPIPS).Most of the curves would become almost flat after K 4.Thus, we generally recommend to set K vary from 2 to 4 toreduce the computational costs and the loss on data utility.In , we qualitatively present some visual com-parison results. With larger K, the CAM heatmap wouldfocus much farther from the facial parts, especially the eyes.By comparing the face images before and after feature dis-traction, one can find some significant changes on the fa-cial parts (e.g. the nose may vary from small to big or viceversa) but they may vary for different persons. The resultsalso show that the joint distraction in Equation (5) wouldpush some critical facial features or attributes heading tothe opposite direction to realize identity anonymization, butthis may also lead to some other unexpected changes, suchas the age of the first person in . This negative effectmay come from the significant change of the identity relatedinformation in A. These observations show that some facial",
  "GSA-Rand (45.5, 89.7) (47.6, 79.1)79.90.1170.807GSA-KFN(30.7, 89.9) (56.7, 81.0)80.20.1170.808GSA-Ours(43.9, 90.7) (38.5, 83.2)86.60.0830.853": "parts or attributes are critical because they are correlated toidentity representation, and the change of them may moreor less lead to the performance drop on utility preservation.In , we compare the identity features before andafter IFA by using the classical T-SNE embedding .The intra-class differences would increase after identity fea-ture distraction, but they still exhibit clustering characteris-tics regardless of some outliers, which would favor utilitypreservation. Note that our results can preserve the person-alized facial attributes according to the status of each image.For example, as for the 7-th person, our results can still re-tain the makeup of each instance.In , we present the ablation study results by re-moving the key components. w./o. IFA means removing theidentity input and only using Za as the conditional input.w./o. VAA means feeding the original face appearance toZa. w./o. GSA means feeding the original geometry struc-ture to Zg. IFA can significantly help to reduce the ReIDand IDS rates, but it suffers from performance drops on at-tribute preservation and image quality. GSA and VAA canfurther help to improve the ReID and IDS performance, butmay lead to some drops on utility preservation. We havealso verified the expression recovery in GSA by removingit and observed a significant performance drop.In , we study the performance of IFA and GSAby using different strategies. IFA-Rand, IFA-KFN and IFA-Ours denote using random delegate, k-th farthest neighborand our method to anonymize the identity feature, respec-tively. GSA-Rand, GSA-KFN and GSA-Ours denote usingrandom delegate, k-farthest neighbor and our IPD methodto anonymize the geometry structure, respectively. It is ob-vious that IFA-Ours and GSA-Ours have achieved a betterbalance between privacy protection and utility preservation.In Equ.(7) and Equ.(8), ua and ug are determined byjointly considering anonymity and data utility. According",
  ". Results on Vggface2 and LFW": "We show the generalization ability of our approach on Vg-gface2 and LFW datasets. According to , most meth-ods show quite high privacy protection ability (e.g. 0.0%ReID rate). Our approach outperforms the contrast meth-ods on attribute, LPIPS and SSIM, which indicates that ourapproach has achieved a better privacy-utility tradeoff. Ac-cording to , one can find that the anonymized faceson both datasets look realistic and different from their orig-inal versions. These results are in consistent with the re-sults reported in the previous subsections, which have againhelped to verify the performance of our approach.",
  ". User Study": "We conduct a simple user study to verify the performance ofour approach from the perspectives of human. As shown in, we asked around 30 participants to answer twokinds of questionnaires: for Q1, each anonymized face ispaired with another image of the original face; for Q2, thetop 5 retrieved results are presented. For each of the contrastmethods, we randomly assign each participant: (1) 20 Q1to calculate the ReID rate of choosing B and C; (2) 20 Q2",
  ". The human evaluation results on ReID and IDS": "from dataset retrieval to calculate the IDS rate of choosingnot appear; (3) 20 Q2 from Google retrieval to calculatethe ReID rate of choosing not appear.As shown in , one can observe that: (1) ourReID and IDS results closely follow CIAGAN, which workbetter than the other methods; (2) the IDS rate of all the gen-erative methods are high (over 45.0%), which may easilylead to identity intrusion. Since the image distortion wouldprevent the observers from correct recognition, it is easy forCIAGAN to achieve the best performance. This study showconsistent results with that of machine recognizers.",
  ". Conclusion": "In this paper, we present a distinct face anonymization ap-proach from another viewpoint based on identity attentiondistraction. On top of ablation study, we have showed howand why our approach works.By performing compara-tive study and user study, we have validated our approachfor improving the performance of privacy-utility tradeoff.Our approach allows for flexible manipulation of the fa-cial appearance and geometry structure for more diverseanonymization and it has also demonstrated the generaliz-ability in the other datasets. Future work includes explor-ing the correspondences between the convolutional featuremaps and facial attributes for more effective anonymization,and exploring how to retain some more complex signal (e.g.psychological and physiological) hidden in visual data."
}