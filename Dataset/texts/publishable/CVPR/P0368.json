{
  "Abstract": "In the image classification task, deep neural networksfrequently rely on bias attributes that are spuriously cor-related with a target class in the presence of dataset bias,resulting in degraded performance when applied to datawithout bias attributes.The task of debiasing aims tocompel classifiers to learn intrinsic attributes that inher-ently define a target class rather than focusing on bias at-tributes. While recent approaches mainly focus on empha-sizing the learning of data samples without bias attributes(i.e., bias-conflicting samples) compared to samples withbias attributes (i.e., bias-aligned samples), they fall shortof directly guiding models where to focus for learning in-trinsic features. To address this limitation, this paper pro-poses a method that provides the model with explicit spa-tial guidance that indicates the region of intrinsic features.We first identify the intrinsic features by investigating theclass-discerning common features between a bias-aligned(BA) sample and a bias-conflicting (BC) sample (i.e., bias-contrastive pair). Next, we enhance the intrinsic features inthe BA sample that are relatively under-exploited for pre-diction compared to the BC sample. To construct the bias-contrastive pair without using bias information, we intro-duce a bias-negative score that distinguishes BC samplesfrom BA samples employing a biased model. The experi-ments demonstrate that our method achieves state-of-the-art performance on synthetic and real-world datasets withvarious levels of bias severity.",
  "* indicates equal contribution": "pear across the samples in the class. However, when thedataset bias exists in the training data, the models tend touse the frequently appearing peripheral attribute (i.e., biasattribute) to predict the class unintentionally. For instance,if airplanes in the training images are mostly in the sky, amodel can heavily rely on the sky to predict an image asan airplane class due to its high correlation with the air-plane class. This indicates that the model is biased towardsthe bias attribute (e.g., sky) rather than focusing on intrinsicfeatures (e.g., the shape of wings or the body) when mak-ing decisions. As a result, even though the biased modelachieves high accuracy on the samples including bias at-tributes (e.g., airplanes in the sky), termed as bias-aligned(BA) samples, it may fail to accurately predict samples de-void of such bias attributes (e.g., airplanes on the runway),referred to as bias-conflicting (BC) samples.In this regard, debiasing aims to encourage the model tofocus on intrinsic attributes rather than bias attributes whendataset bias exists. One straightforward approach is utiliz-ing prior knowledge regarding bias (e.g., labels for bias at-tribute) to inform the model which attributes to focus onor not to focus on . However, acquiring suchbias information is often infeasible in real-world scenarios.Therefore, recent studies have proposed debi-asing methods that do not require bias information. Theyidentify and emphasize BC samples during the training us-ing an additional biased classifier that mainly learns the biasattributes. However, such a training strategy fails to directlyindicate where the model should focus to learn the intrinsicfeatures.To address this issue, we present a debiasing approachthat explicitly informs the model of the region of the in-trinsic features during the training while not using bias la-bels. While the intrinsic features in the unbiased datasetcan simply be identified in generally appearing features inthe training samples, generally appearing features in the bi-ased dataset inevitably include bias features. Therefore, weidentify the intrinsic features in the biased dataset by inves-tigating the common features between a BA and a BC sam-ple (i.e., a bias-contrastive pair). Here, the common features",
  "arXiv:2404.19250v2 [cs.CV] 17 Jun 2024": "also need to be class-discerning since the common featuresmight include irrelevant environmental features. For exam-ple, in the above scenario, the common feature between anairplane in the sky (BA sample) and an airplane on the run-way (BC sample) might include the features of wings, thebody, and trees. In this case, the intrinsic features are theshape of the wings and the body that can distinguish theairplane class from the others.Specifically, we introduce an intrinsic feature enhance-ment (IE) weight that identifies the spatial regions of intrin-sic features commonly appearing in a bias-contrastive pair.We leverage an auxiliary sample in addition to the originalinput to construct the bias-contrastive pair. Since the major-ity of the original input from training samples are BA sam-ples, we mainly adopt the BC samples as the auxiliary sam-ple. To achieve this without bias information, we presenta bias-negative (BN) score that identifies BC samples byemploying a classification loss of a biased model. Our IEweight investigates common features in the bias-contrastivepair and identifies the class-discerning features among thecommon features. Within the identified intrinsic features,we enhance the features that are relatively under-exploitedin the BA samples compared to the BC samples. In this way,we can explicitly provide our model with spatial guidancefor intrinsic attributes while not using bias labels.We verify the effectiveness of our method on both syn-thetic and real-world datasets with various levels of biasseverity. Furthermore, the in-depth analysis demonstratesthat our method successfully guides the model to make pre-dictions based on the intrinsic features.",
  ". Related work": "Debiasingwithbiasinformation.Previousap-proaches utilize bias labels or prede-fined bias types to encourage the model to learn intrinsic at-tributes for debiasing. Kim et al. , Tartaglione et al. ,and Sagawa et al. employ bias labels to encourage themodel not to learn specific bias features. Wang et al. and Bahng et al. predefine the bias type (e.g., color, tex-ture, etc.) and utilize such prior knowledge to supervisemodels to be robust against such predefined bias type. How-ever, obtaining bias information requires additional cost,which is often infeasible in the real world.Debiasing without bias information.Recent studies [1, 3, 7, 8, 1116, 28] propose debiasing strategies that do notrequire bias information. Nam et al. present an ap-proach that encourages the model to concentrate on BCsamples during the training process considering that the biasattributes are easier to learn than intrinsic attributes. Insteadof using bias information, they additionally train a biasedmodel that mainly learns bias attributes and regard the sam-ples that are not easily trained by the biased model as BCsamples. Lee et al. reveal that BC samples serve as noisy samples when training the additional biased modeland propose a method to eliminate such BC samples usingmultiple biased models. Liu et al. regard the samplesmisclassified by the model trained with empirical risk min-imization as BC samples and emphasize them during train-ing of a debiased model. Also, MaskTune expects themodel to learn intrinsic features by fine-tuning the modelwith the data whose already-explored area is masked outusing Grad-CAM .Another stream of approaches synthesizesamples having similar characteristics with BC samples andemploy them to train a debiased model. Kim et al. syn-thesize images without bias attributes leveraging an image-to-image translation model . Lee et al. and Hwanget al. augment BC samples in the feature space by em-ploying the disentangled representations and mixup ,respectively.A recent pair-wise debiasing method X 2-model encourages the model to retain intra-class com-pactness using samples generated via feature-level interpo-lation between BC and BA samples. However, such ap-proaches lack explicit supervision about which features tofocus on to learn intrinsic features. To address this issue,we present a debiasing method that provides spatial guid-ance to encourage a model to learn intrinsic features dur-ing the training while not using bias labels. We design ourmodel architecture using bias-contrastive pairs referring tothe previous studies .",
  ". Overview": "As shown in , our framework consists of a biasedmodel fb that focuses on bias attributes and a debiasedmodel fd that learns debiased representations. We use Bi-asEnsemble (BE) as a backbone, where fb is trainedwith bias-amplified dataset DA which mainly consists ofBA samples, while fd concentrates on the samples that fbfails to learn. Our method provides fd with spatial guidancefor intrinsic features using a bias-contrastive pair: an inputx and an auxiliary input xBN. We denote the auxiliary inputxBN as a bias-negative (BN) sample because we primarilyadopt samples devoid of bias attributes. We sample an im-age x from the original training data D, and xBN from a BNdataset DBN which mainly consists of BC samples. DBN isupdated every iteration to mainly include BC samples us-ing the BN score S that employs fb to identify BC samples.The BN score is also updated every iteration. Given the in-termediate features z and zBN, we first extract the commonfeatures between the bias-contrastive pair (c(z) in ).Also, we identify the class-discerning features that are rela-tively under-exploited in z compared to zBN (r(z) in ).Next, we calculate the IE weight that indicates relativelyunder-exploited intrinsic features in z based on c(z) and BN score common feature score funtion relative-exploitation score function inference update every iteration BA sampleBC sample : fishing : fishing . Overview of our method. We provide explicit spatial guidance g(z) for a debiased model fd, which is described with f embdandf clsd , to learn intrinsic features. To achieve this, we leverage a bias-contrastive pair, x and xBN from the same target class y. g(z) highlightsintrinsic features that are relatively under-exploited in z compared to zBN, calculated by common feature score c and relative-exploitationscore r. Here, we mainly adopt BC samples from DBNcand to construct DBN, where we sample xBN. DBN is updated every iteration using theBN score S, which is also updated every iteration. At the inference, we only use fd in the gray-colored area. r(z) (IE(z) in ). Finally, we obtain the guidance g(z)that emphasizes the region of intrinsic feature in z duringthe training. At the inference, we utilize fd without xBN, asin a gray-colored area of .",
  "We construct a BN dataset DBN, where we sample xBN dur-ing the training. As the majority of the training dataset isBA samples, we aim to mainly adopt BC samples as xBN": "to construct bias-contrastive pairs. To achieve this, we firstconstruct DBNcand, a candidate dataset for DBN, that containsroughly identified BC samples. During the training, we dy-namically update DBN every iteration to mainly adopt BCsamples from DBNcand using our newly proposed BN score.Constructing candidate dataset DBNcand.To roughly iden-tify BC samples in D, we filter out easily learned BAsamples from D using multiple biased models, followingBE . Since the bias features are easier to learn than theintrinsic features , each biased model is trained only fora few iterations so that BC samples can be distinguishedfrom the easily learned BA samples. Inspired by JTT ,we regard the samples that are incorrectly predicted by themajority of the biased models as BC samples. Finally, weconstruct DBNcand with the roughly identified BC samples.Adopting BC samples with BN score.We introduce aBN score to update DBN to primarily exploit BC samplesas xBN from DBNcand during training fd. Considering the un-availability of bias labels, the BN score employs fb to fur-ther exclude BA samples from DBNcand. As training proceeds, fb is overfitted to the bias attributes in DA and outputs ahigh probability on the ground-truth label for the samplesthat have similar bias features with samples in DA. Thisindicates that samples whose fb loss decreases as train-ing proceeds are likely to have bias attributes learned fromDA. Such samples disturb the extraction of intrinsic fea-tures when selected as xBN. To validate this, we investigatethe samples in DBNcand whose fb loss at the later stage of train-ing (50K-th iteration) decreases compared to the early stageof training (1K-th iteration). The result shows that 95.63%of them are BA samples. We use the BFFHQ dataset with a bias severity of 1% for the analysis. Further detailsof the dataset are described in Sec. 4.1.In this regard, we design a BN score to exclude the sam-ples with decreasing fb loss from the DBNcand to construct DBN",
  "lt(x) = l LCE(fb(x), y) + (1 l) lt1(x),(1)": "where LCE(fb(x), y) indicates the cross-entropy (CE) lossof x on its ground-truth label y and l is a hyperparame-ter for the exponential moving average (EMA). We employEMA to enable a stable tracking of the classification losses.Note that lt is updated only for the samples in a mini-batchat the t-th iteration.The BN score tracks lt(x) compared to the loss recordedat the early stage of training. The BN score at the t-th iter-ation is formulated as follows:",
  "st(x) = s (lt(x) lref(x)) + (1 s) st1(x),(2)": "where s is a hyperparameter for the EMA and lref(x) de-notes the reference loss of x that is first recorded after afew iterations of training. We exploit EMA to stabilize thetracking. Note that we update st only for the samples in amini-batch at the t-th iteration. The negative value of st(x)indicates that the loss of x decreased compared to the earlystage of training, which means that the sample is likely tocontain bias attributes.Updating DBN with BN score.At every iteration, we up-date DBN to exclude the newly detected BA samples whoseBN score st(x) is smaller than zero as follows:",
  ". Intrinsic feature enhancement": "To emphasize the intrinsic features in fd, we introduce theintrinsic feature enhancement (IE) weight that imposes ahigh value on the intrinsic features. The IE weight identifiesthe region of intrinsic features from bias-contrastive pairsby investigating 1) their common features with commonfeature score c and 2) class-discerning features that are rela-tively under-exploited in the input with relative-exploitationscore r. For the explanation, we split fd into two parts.f embd: RHW 3 Rhwc maps an input to the inter-mediate feature, and f clsd: Rhwc RC is composed ofthe average pooling and the linear classifier and outputs theclassification logits, where fd(x) = f clsdf embd(x).First, given the input x, common feature score c iden-tifies the features that are similar to the features in xBN that has the same class label as x while not having bias at-tributes. Specifically, we extract the intermediate featuresz = f embd(x) and zBN = f embd(xBN), respectively. Next, weobtain the common feature score of z (i.e., c(z) Rhw).Given the n-th feature of z (i.e., zn Rc), let i-th featureof zBN (i.e., zBNi Rc) be the most similar feature to zn,where i = arg maxi",
  "maxi,j(zBNi zj),(4)": "where indicates a dot product operation. We adopt the dotproduct for the similarity metric to consider both the scaleand the direction of the features. The max normalization isemployed to limit the score to less than one. We consider the features with a high common feature score c in z as fea-tures that have a high likelihood of being intrinsic features.Next, the relative-exploitation score r identifies class-discerning features that are relatively under-exploited in xcompared to xBN. Since most of the xBN does not containbias attributes, we identify class-discerning intrinsic fea-tures by investigating the features that are mainly used topredict xBN as its target label. At the same time, we iden-tify the features that are under-exploited in the x comparedto the xBN. To achieve this, we use a visual explanationmap of Grad-CAM that imposes a higher value on thefeatures that have more contribution to predicting a specificlabel. We calculate the explanation map E(z) and E(zBN)with respect to their ground-truth labels. We apply maxnormalization to the explanation maps to compare the rela-tive importance of the features in prediction. We comparethe n-th value of E(z) (i.e., E(z)n) with the i-th value ofE(zBN), where i is the index of the feature in zBN that isthe most similar with zn. Accordingly, the n-th element ofr(z) Rhw is calculated as:",
  "IE(z)n = max(c(z)n r(z)n, 1),(6)": "where indicates the element-wise multiplication. The IEweight has a large value on the features of x that commonlyappear in xBN but has not exploited enough for the predic-tion of x. We clip the values to be larger than one to enhanceonly the relatively under-exploited features in z while pre-serving the other features.Using the IE weight, we obtain the guidance g(z) thatemphasizes the intrinsic features in z as follows:",
  ": end for": "mostly BC samples. The detailed description of w(x) isincluded in the Supplementary.In addition, we guide the model to focus on the regionof intrinsic features through a guidance loss and a BN loss.We observe that the BN score has a higher value on the BCsamples compared to the BA samples as training fb pro-ceeds (See Sec. 4.3). In this respect, we employ the BNscore of xBN (i.e., s(xBN)) to upweight the loss when BCsamples are adopted as xBN. Here, we clip the value of lossweight s(xBN) to be larger than zero.Guidance loss.To guide the model to exploit the intrinsicfeatures from x, we minimize the L1 distance between g(z)and z as follows:",
  "Lguide sim = s(xBN)GAP(z) GAP (g(z))1,(9)": "where GAP represents the global average pooling. s(xBN)is multiplied as a loss weight to impose a high weight onthe loss when BC samples are selected as xBN.Also, we apply the CE loss to the guidance g(z) to en-courage it to include the intrinsic features that contribute tothe correct prediction as follows:",
  "Lguide = simLguide sim + Lguide cls,(11)": "where sim is a hyperparameter to control the relative sig-nificance between the losses. We set sim set as 0.1.BN loss.We also employ the CE loss on xBN to encouragethe model to learn class-discerning features. This enablesthe IE weight to find intrinsic features among the commonfeatures. The BN loss is defined as:",
  "Ltotal = mainLmain + Lguide + LBN,(13)": "main is the constant value that linearly increases from zeroto one during training fd with the guidance. This preventsthe model from focusing on bias features in x in the earlyphase. The overall process of our method is provided inAlgorithm 1. Here, we set T1 and T2 as 1K and 10K, re-spectively. Note that all the hyperparameters are identicallyapplied across different datasets and bias severities. We pro-vide further details of the training and the implementationin the Supplementary.",
  ". Experimental settings": "Dataset.We utilize Waterbirds , biased FFHQ(BFFHQ) , and BAR for the experiments. Eachdataset contains different types of target class and bias at-tributes: Waterbirds - {bird type, background}, BFFHQ -{age, gender}, and BAR - {action, background}. The for-mer and the latter in the bracket indicate the target classand the bias attribute, respectively. To be specific, the Wa-terbirds dataset has two bird classes: waterbirds and land-birds. Most of the waterbirds are in the water background,and most of the landbirds are in the land background. In thetraining dataset of BFFHQ, most young people are femalewhile most old people are male. The word young indi-cates an age ranging between 10 and 29, and old indicatesan age ranging between 40 and 59. Lastly, the BAR datasetconsists of six classes of action (e.g., fishing), where thebackground (e.g., water surface) is highly correlated witheach class. Following the previous studies , wevalidate our models effectiveness under different levels ofbias severity, i.e., a ratio of BC samples to the total trainingsamples: 0.5%, 1%, 2%, and 5%. In the test sets, the spuri-ous correlations found in the training set do not exist. Moredetails are provided in Supplementary.Evaluation.We report the best accuracy of the test setaveraged over five independent trials with different randomseeds. The Waterbirds dataset has an extremely skewed test",
  "Waterbirds26.50 5.320.75 0.832.75 0.31 79.69 3.72BFFHQ199.80 40.14 8.00 2.760.46 0.09 50.00 1.04BAR30.60 3.833.20 1.603.58 0.14 47.14 5.71": ". Effectiveness of BN score on excluding BA samples.DBNcand - DBN presents the number of excluded samples when con-structing DBN from DBNcand. DBN/D indicates that the ratio of sam-ples in DBN to the samples in D. dataset composed of 4,600 landbirds and 1,194 waterbirds.This can mislead the debiasing performance as the modelmay achieve high classification accuracy by simply predict-ing most images as landbirds. We measure the classificationaccuracy for each class and report their average value to ob-tain an accurate understanding of the effectiveness of meth-ods, regardless of class frequencies. Also, for the BFFHQ,we report the best accuracy of BC samples in the test set,following the previous works . For the analyses, weutilize the datasets with 1% bias severity.",
  ". Comparison to previous works": "We compare the classification accuracy on the test sets be-tween the baselines and ours in . For baselines, weemploy a vanilla model trained with the CE loss, the meth-ods using explicit bias label (i.e., LNL , EnD ), pre-suming the type of the bias (i.e., HEX , ReBias ), andassuming the bias information is unknown (i.e., LfF ,DisEnt , LfF+BE , DisEnt+BE ). Our approachachieves state-of-the-art performance in comparison to theprevious methods including those utilizing explicit bias la-bels. The results exhibit that our method improves perfor-mance robustly across various levels of bias severity, evenunder the constraints of extreme bias severity (e.g., 0.5 %). BN score",
  ". Analysis of BN score": "We analyze our BN score that identifies and emphasizes BCsamples in DBNcand during training fd. In this section, we as-sess the effectiveness of the BN score on excluding BA sam-ples from DBNcand. Also, we evaluate the efficacy of the BNscore as a loss weight by investigating the BN scores of thesamples in DBNcand.Effectiveness of BN score on excluding BA samples. Ta-ble 2 presents how the BN score effectively filters out BAsamples from DBNcand while preserving BC samples whenconstructing DBN. The first two columns present the num-ber of the BA and BC samples excluded from DBNcand to con-struct DBN, respectively. Also, the last two columns rep-resent the ratio of the number of the BA and BC samplesin DBN to that in D, respectively. For the analysis, we useDBN at the 50K-th iteration and report the mean value of thefive independent trials. Here, we expect DBN to contain amaximal number of BC samples while including a minimalnumber of BA samples. As shown in the first two columns LandbirdWaterbird ClimbingDiving (a) Waterbirds(b) BAR . Visualization of the spatial guidance using (a) Waterbirds and (b) BAR dataset. Given bias-contrastive pairs, x and xBN, E(z)indicates the regions originally focused on by fd and IE(z) shows the regions highlighted by our IE weight. InputOursw/o guidance VaultingDiving InputOursw/o guidance LandbirdWaterbird (a) Waterbirds(b) BAR",
  ". Comparison of the region focused by a debiased model trained with and without our method. We compare Grad-CAM results onthe test set of (a) Waterbirds and (b) BAR": "of , our BN score excludes a large number of BAsamples while minimizing the loss of BC samples. As a re-sult, DBN preserves around 50-80% of BC samples, whilecontaining a minimal number of BA samples compared toD, as presented in the last two columns. Efficacy of BN score as loss weight.We utilize the BNscore to upweight the training loss when BC samples arechosen as xBN. To verify its effectiveness as a loss weight,we compare the BN scores of BC samples and BA samplesin DBNcand during the training for the Waterbirds, BFFHQ, andBAR dataset. In , we present the average BN scores ofBA (red line) and BC samples (blue line) in DBNcand at every500 iterations. Since BN scores are recorded after the 1K-th iteration, the BN scores until the 1K-th iteration are re-ported as zero. The BN scores of BC samples in the BFFHQdataset mostly range from 0.4 to 0.5 while the scores of BAsamples are close to 0. This indicates that the BN score asa loss weight in the BFFHQ imposes a much larger valueon the BC samples, while approximately zero values on the BA samples. Also, the BN scores of BC samples in theWaterbirds and the BAR dataset become twice larger thanthe scores of BA samples. The result shows that the BNscore effectively emphasizes BC samples compared to theBA samples in DBNcand during the training. Further analysisof the BN score is included in the Supplementary.",
  ". Analysis of intrinsic feature guidance": "We conduct a qualitative analysis of the regions emphasizedby our intrinsic feature guidance during the training and thefeatures learned by fd after training. We use the Waterbirdsand BAR datasets with 1% of bias severity for the analysis.Visualization of the guidance during training.In ,we visualize the features emphasized by our IE weightIE(z). For comparison, we also visualize E(z), the fea-tures focused by the model before applying IE(z) for guid-ance. We select a BA sample as x and a BC sample as xBN",
  "from the training data for the analysis. For the Waterbirdsdataset in (a), IE(z) highlights the wings or the beak": "of the bird compared to E(z), where the forest or the wa-ter (i.e., bias attributes) is highlighted. Also, in (b),E(z) focuses more on the bias attributes such as rocks orthe water than the intrinsic attributes. In contrast, IE(z)emphasizes the action of the human that is less exploitedcompared to the bias features in E(z). The results demon-strate that our guidance successfully identifies and enhancesunder-exploited intrinsic features during the training.Effect of intrinsic feature guidance on debiasing.Wequalitatively evaluate the effectiveness of the intrinsic fea-ture guidance by investigating the visual explanation mapsof the test samples. We compare the Grad-CAM re-sults of the model trained with and without our method inFig 4. The Grad-CAM results highlight the features that themodel employs to predict the input as its ground-truth la-bel. In (a), while the model trained without guidancefocuses on the forest or the sea, ours focuses on the tail ora curved shape of the birds body. Additionally, (b)shows that ours focuses on the motion of the human ratherthan the backgrounds that are concentrated on by the modeltrained without our guidance. The results verify that ourmethod successfully encourages the model to learn intrinsicfeatures from the training dataset, improving the robustnessof the model against dataset bias.",
  ". Ablation study": "As shown in , we perform ablation studies to ver-ify the effectiveness of the individual components in ourmethod. The results of ours are reported in the last row.Importance of xBN selection and BN score as loss weight.We demonstrate the efficacy of adopting BC samples asxBN. We train the model by sampling xBN from three differ-ent datasets: D, DBNcand, and DBN. In the first row of ,we randomly sample xBN from the training dataset D with-out using the BN score. In the second row, we train themodel with xBN sampled from DBNcand, where BA samplesare roughly filtered out using the early-stopped biased mod-els. The model in the third row is trained with xBN fromDBN that mainly includes BC samples using our BN score.The results show a gradual improvement in debiasing per-formance as more BC samples are selected as xBN. Thisis because auxiliary samples without bias attributes preventthe common features from including the bias features, com-posing a bias-contrastive pair with the input. Therefore, ourguidance effectively enhances the intrinsic features duringthe training. Finally, the last row in presents thatemploying the BN score s(xBN) to reweight the losses fur-ther enhances performance by emphasizing the usage of BCsamples as xBN.Training objectives.We examine the impact of eachtraining objective, Lguide and LBN, in our method. We re-port the performance of the model trained without Lguide(the fourth row) and without LBN (the fifth row) in .",
  "DBN65.22 0.95 77.56 1.24 75.14 0.82": ". Ablation study on the proposed training objectives, thedataset that xBN is sampled from, and the BN score of xBN asa loss weight. The check mark () denotes the inclusion of thecorresponding method, while the cross mark () indicates the ex-clusion of the component in the experiment. The model trained without Lguide exhibits degraded perfor-mance, facing difficulties in identifying where to focus tolearn intrinsic features. Similarly, training the model with-out LBN also results in a performance decrease. The re-sults verify that LBN successfully supports the IE weightto identify intrinsic features among the common featuresby learning class-discerning features from xBN. The modelthat incorporates both Lguide and LBN demonstrates the bestperformance (the last row of ).",
  ". Conclusion": "In this paper, we propose a debiasing method that explic-itly provides the model with spatial guidance for intrinsicfeatures. Leveraging an auxiliary sample, we first identifyintrinsic features by investigating the class-discerning fea-tures commonly appearing in a bias-contrastive pair. Our IEweight enhances the intrinsic features that have not been fo-cused on yet in the input by a debiased model. To constructthe bias-contrastive pair without bias labels, we introduce abias-negative (BN) score that tracks the classification lossof a biased model to distinguish BC samples from BA sam-ples during the training. The effectiveness of our methodis demonstrated through experiments on synthetic and real-world datasets with varying levels of bias severity. We be-lieve this work sheds light on the significance of providingexplicit guidance on the intrinsic attributes for debiasing. This work was supported by the Institute for Information &communications Technology Promotion(IITP) grant fundedby the Korea government(MSIT) (No.2019-0-00075, Ar-tificial Intelligence Graduate School Program(KAIST),the National Research Foundation of Korea (NRF) grantfunded by the Korea government (MSIT) (No.NRF-2022R1A2B5B02001913 & No.2022R1A5A7083908)and partly by Kakao Corporation. Saeid Asgari, Aliasghar Khani, Fereshte Khani, Ali Gho-lami,Linh Tran,Ali Mahdavi Amiri,and GhassanHamarneh. Masktune: Mitigating spurious correlations byforcing to explore. In Proc. the Advances in Neural Infor-mation Processing Systems (NeurIPS), pages 2328423296,2022. 2, 4 Hyojin Bahng, Sanghyuk Chun, Sangdoo Yun, Jaegul Choo,and Seong Joon Oh. Learning de-biased representations withbiased representations. In Proc. the International Conferenceon Machine Learning (ICML), 2020. 1, 2, 6, 5",
  "Zeyi Huang, Haohan Wang, Eric P. Xing, and Dong Huang.Self-challenging improves cross-domain generalization. InProc. of the European Conference on Computer Vision(ECCV), 2020. 2": "Inwoo Hwang, Sangjun Lee, Yunhyeok Kwak, Seong JoonOh, Damien Teney, Jin-Hwa Kim, and Byoung-Tak Zhang.Selecmix: Debiased learning by contradicting-pair sampling.In Proc. the Advances in Neural Information Processing Sys-tems (NeurIPS), 2022. 1, 2 Byungju Kim, Hyunwoo Kim, Kyungsu Kim, Sungjin Kim,and Junmo Kim. Learning not to learn: Training deep neuralnetworks with biased data. In Proc. of the IEEE conferenceon computer vision and pattern recognition (CVPR), 2019.1, 2, 6, 5 Eungyeup Kim, Jihyeon Lee, and Jaegul Choo. Biaswap:Removing dataset bias with bias-tailored swapping augmen-tation. In Proc. of the IEEE international conference on com-puter vision (ICCV), pages 1499215001, 2021. 2, 3, 5, 1 Bum Chul Kwon, Jungsoo Lee, Chaeyeon Chung, Nyoung-woo Lee, Ho-Jin Choi, and Jaegul Choo. DASH: Visual An-alytics for Debiasing Image Classification via User-DrivenSynthetic Data Augmentation. Eurographics Conference onVisualization (EuroVis)-Short Papers. The Eurographics As-sociation, 2022. 2 Jungsoo Lee, Eungyeup Kim, Juyoung Lee, Jihyeon Lee, andJaegul Choo. Learning debiased representation via disentan-gled feature augmentation. In Proc. the Advances in NeuralInformation Processing Systems (NeurIPS), 2021. 1, 2, 5, 6",
  "amplifying bias for debiasing. In Proc. the AAAI Conferenceon Artificial Intelligence (AAAI), pages 1497414981, 2023.2, 3, 5, 6, 4, 7": "Evan Z Liu, Behzad Haghgoo, Annie S Chen, Aditi Raghu-nathan, Pang Wei Koh, Shiori Sagawa, Percy Liang, andChelsea Finn.Just train twice: Improving group robust-ness without training group information.In Proc. the In-ternational Conference on Machine Learning (ICML), pages67816792, 2021. 2, 3 Junhyun Nam, Hyuntak Cha, Sungsoo Ahn, Jaeho Lee, andJinwoo Shin. Learning from failure: Training debiased clas-sifier from biased classifier. In Proc. the Advances in NeuralInformation Processing Systems (NeurIPS), 2020. 1, 2, 3, 4,5, 6 Geon Yeong Park, Sangmin Lee, Sang Wan Lee, andJong Chul Ye.Training debiased subnetworks with con-trastive weight pruning.In Proc. of the IEEE conferenceon computer vision and pattern recognition (CVPR), pages79297938, 2023. 2, 3, 4, 5 Taesung Park, Jun-Yan Zhu, Oliver Wang, Jingwan Lu, EliShechtman, Alexei A. Efros, and Richard Zhang. Swappingautoencoder for deep image manipulation. In Proc. the Ad-vances in Neural Information Processing Systems (NeurIPS),2020. 2 Shiori Sagawa, Pang Wei Koh, Tatsunori B Hashimoto, andPercy Liang.Distributionally robust neural networks forgroup shifts: On the importance of regularization for worst-case generalization. Proc. the International Conference onLearning Representations (ICLR), 2020. 2, 5 Ramprasaath R. Selvaraju, Michael Cogswell, AbhishekDas, Ramakrishna Vedantam, Devi Parikh, and Dhruv Ba-tra. Grad-cam: Visual explanations from deep networks viagradient-based localization. In Proc. of the IEEE interna-tional conference on computer vision (ICCV), 2017. 2, 4, 8,3",
  "Karen Simonyan and Andrew Zisserman. Very deep convo-lutional networks for large-scale image recognition. Proc.the International Conference on Learning Representations(ICLR), 2015. 1": "Christian Szegedy, Wei Liu, Yangqing Jia, Pierre Sermanet,Scott Reed, Dragomir Anguelov, Dumitru Erhan, VincentVanhoucke, and Andrew Rabinovich.Going deeper withconvolutions. In Proc. of the IEEE conference on computervision and pattern recognition (CVPR), pages 19, 2015. 1 Enzo Tartaglione, Carlo Alberto Barbano, and MarcoGrangetto. End: Entangling and disentangling deep repre-sentations for bias correction. In Proc. of the IEEE confer-ence on computer vision and pattern recognition (CVPR),pages 1350813517, 2021. 1, 2, 6, 5",
  "Supplementary Material": "This supplementary material offers further analysis ofour approach, additional experimental results, the detailsof the datasets and implementation, limitations, and futurework. Appendix A and Appendix B provide the analysisof the bias-negative (BN) score as a loss weight and sam-ples with negative BN score, respectively. Appendix C ana-lyzes the effect of BC samples in DBN on debiasing perfor-mance. Also, Appendix D compares the recent sample se-lection methods with ours. Moreover, Appendix E and Ap-pendix F present additional qualitative results regarding theguidance and additional quantitative results, respectively.Appendix G and Appendix H provide the details about thedataset and implementation. Lastly, Appendix I discussesthe limitations and future work.",
  "A. Additional analysis of the BN score as a lossweight": "density loss BA samples (later stage) BC samples (later stage) BA samples (early stage) BC samples (early stage) . The distributions of fbs classification loss of samples inDBNcand. The red and blue lines denote the losses of BA and BC sam-ples, respectively. The dotted and solid lines indicate the losses atthe early and later stages of the training, respectively. Best viewedin color. As described in Sec. 3.4 in the main paper, we utilizethe BN score of xBN (i.e., s(xBN)) to reweight the guidanceloss Lguide sim and the BN loss LBN. The BN score as aloss weight is designed to upweight the losses when bias-conflicting (BC) samples are selected as xBN, which furtherencourages our IE weight to enhance the intrinsic features.For verification, we present that the BN score has a muchlarger value on the BC samples compared to bias-aligned(BA) samples during the training in in the main paper.Since s(xBN) has a larger value when the current fb loss of xBN is larger than that of the early stage of training,the results imply that the fb loss of BC samples largely in-creases as training proceeds compared to BA samples.To further verify this, we present fbs classification lossof samples in DBNcand during the training in .TheBFFHQ dataset with a bias severity of 1% is used forthe analysis. In , the dotted lines denote the distribu-tion of fbs classification loss at the early stage of training(1K-th iteration), and the solid lines indicate that of the laterstage of training (50K-th iteration). The results show thatthe fb loss of BC samples (blue lines) largely increases atthe later stage of training compared to the early stage, un-like BA samples (red lines). This demonstrates that the BNscore as a loss weight can effectively upweight the traininglosses when BC samples are chosen as xBN.",
  ". The examples of samples that have negative BN scoresat the later stage of training": "As mentioned in Sec. 3.2 in the main paper, we furtherfilter out the samples with negative BN scores from DBNcand tomainly exploit the BC samples as xBN. Here, we expect thatthe samples with negative BN scores are mostly BA sam-ples. To investigate the samples with negative BN scores,we chose the samples that were erroneously incorporatedinto DBNcand initially but excluded at the later stage of training(i.e., 50K-th iteration), exhibiting negative BN scores. Thisprocess is repeated five times, and we visualize the sampleschosen more than three times in . We use the BFFHQdataset with a 1% bias severity for the experiment.We observe that the samples with negative BN scores inDBNcand are mostly BA samples. As shown in the figure, whilethe samples obviously contain bias attributes (i.e., featuresrepresenting female or male), the samples mostly have ex-treme shade, blur, saturation, or unusual makeup, exhibit- LandbirdLandbirdLandbirdWaterbirdWaterbirdWaterbird ThrowingVaultingClimbingClimbingDivingDiving (a) Waterbirds(b) BAR . Additional visualization results of the spatial guidance using (a) Waterbirds and (b) BAR dataset. Given bias-contrastive pairs, xand xBN, E(z) indicates the regions originally focused on by fd and IE(z) shows the regions highlighted by our IE weight. ing non-typical appearance. Although the bias attributesare known to be easy to learn, the non-typical appearanceprevents fb from detecting such bias attributes in the earlystage of training. In Sec. 4.5 of the main paper, we verifythat employing such BA samples as xBN largely degradesthe debiasing performance by allowing the bias attributesto be included in the common features between x and xBN.Our BN score effectively alleviates this issue by filtering outsuch BA samples from DBNcand.",
  ". Additional comparison of the region focused by a debiased model trained with and without our method. We compare Grad-CAMresults on the test set of (a) Waterbirds and (b) BAR": "sample selection in recent methods with ours usingBFFHQ with a 1% bias severity.Let S be a setof samples identified as BC samples from training dataD. {#BC in S/#BC in D, #BA in S/#BC in S} is {75.63,10.18}-BE , {27.29, 4.32}-DCWP , and {50.0,0.89}-Ours, respectively. Our method has the least num-ber of BA compared to BC samples in S while preservinghalf of the total BC samples.",
  "In addition to of the main paper, we provide sup-plementary qualitative results that present the features that": "the current model fd focuses on (i.e., E(z)) and the featuresemphasized by the guidance (i.e., IE(z)) during the trainingin . We use the Waterbirds and BAR datasets with abias severity of 1% for the analysis. We train fd during 10Kiterations and obtain the visual explanation map E(z) forthe ground-truth label using Grad-CAM . The min-maxnormalization is applied to the values of E(z) and IE(z) forvisualization. We intentionally select the BA sample andBC sample as x and xBN, respectively, to compose a bias-negative pair. As shown in , our IE weight (i.e., IE(z)) appropri-ately emphasizes the regions of the intrinsic features whileE(z) shows that the current model fd relies on the biasattributes for prediction. For example, in the Waterbirds dataset, IE(z) properly enhances the intrinsic features of abird such as wings, a body, or a neck, while E(z) highlightsthe background features such as the land, the forest or thewater. Also, in the BAR dataset, IE(z) emphasizes the armthrowing the javelin, the motion of a person vaulting, climb-ing, or diving, while the current fd mainly focuses on thebiased features such as the playing field, the sky, the moun-tain, or the water. These results verify the validity of ourIE weight IE(z) as guidance for emphasizing the intrinsicfeatures in x that are under-exploited yet.",
  "E.2. Effect of intrinsic feature guidance on debias-ing": "We present an additional qualitative analysis regarding theeffectiveness of the intrinsic feature guidance to supple-ment in the main paper. illustrates the Grad-CAM results of the model trained with and without ourmethod. Here, the model trained without our method is thesame as LfF+BE . We train the models with the Water-bids and the BAR datasets with a bias severity of 1% andapply the Grad-CAM to the test samples for visualization.The highlighted regions indicate the features that the modelmainly employs for prediction. (a) shows that our approach properly focuses onthe intrinsic features of the bird (e.g., wings, a beak, or feet),while the model trained without our guidance mostly con-centrates on the bias features (e.g., the water or trees). Forthe BAR dataset in (b), our model principally exploitsthe action of a person (e.g., fishing, vaulting, or throwing)or the racing car for prediction, while the model without ourguidance focuses on the backgrounds (e.g., the playing fieldor the water). The results demonstrate the effectiveness ofour method in guiding the model to learn intrinsic features.",
  "F.1. Quantitative results with standard deviations": "In of our main paper, we report the quantitativecomparison results with classification accuracies on the testset which are averaged across five independent experimentswith different random seeds. We additionally provide thestandard deviations of the classification accuracies in Ta-ble 5 and . Each table shows the results of the syn-thetic dataset (i.e., Waterbirds) and the real-world dataset(i.e., BFFHQ and BAR), respectively.Since the BARdataset lacks explicit bias labels, approaches such as LNLand EnD that necessitate explicit bias labels are not applica-ble to the BAR dataset. The baseline results for the BFFHQand the BAR dataset are from the results reported in BE except for DCWP .",
  "F.2. Comparison to recent baseline": "Our primary contribution lies in providing the model withexplicit spatial guidance for intrinsic features by examin-ing features that commonly appear in bias-contrastive pairs.The intrinsic feature exists in generally appearing featureswithin a class, however, this property has not been tackled toprovide intrinsic feature guidance in prior studies to the bestof our knowledge. While recent debiasing approaches aimto encourage the model to learn intrinsic features, they failto directly indicate where the model should focus to learnthe features.For instance, MaskTune expects the model to learnintrinsic features by fine-tuning the model with the datawhose already-explored area is masked out using Grad-CAM. However, simply exploring the unmasked area can-not inform the model where exactly the intrinsic featuresare located. In this case, the model may rather focus onnon-intrinsic features during the fine-tuning. We experi-ment on real-world datasets with a 1% bias severity: {58.00,69.42}-MaskTune and {77.56, 75.14}-Ours for {BFFHQ,BAR}. Ours achieves better debiasing performance by pro-viding explicit spatial guidance for intrinsic features basedon common features in bias-contrastive pairs.A recent pair-wise debiasing method X 2-model en-courages the model to retain intra-class compactness usingsamples generated via feature-level interpolation betweenBC and BA samples. However, X 2-model does not informthe model where the intrinsic features are located in the in-terpolated features. Simply making samples closer to theinterpolated samples does not assure the model to focus onthe intrinsic features. In contrast, our method directly en-courages the model to focus on the area of the intrinsic fea-tures.Also, we conduct a quantitative comparison to the re-cently proposed debiasing approach, DCWP , in Ta-ble 6. We use real-world datasets, BFFHQ and BAR, withvarious bias severity.For a fair comparison, we utilizeResNet18, which is the same architecture as ours. The Im-ageNet pretrained weight is employed only for the BARdataset.The results demonstrate the superiority of ourmethod over the DCWP, where ours provides the modelwith explicit guidance for intrinsic features for debiasing,unlike DCWP.",
  "G. Detailed description of datasets": "We utilize Waterbirds , BFFHQ , and BAR dataset. First, the Waterbirds dataset is composed of twoclasses of bird images and has background bias. In the train-ing set, the waterbirds are mostly with the water backgroundand the landbirds are with the land background. The num-ber of BA samples and that of BC samples are balancedin the test set. By following Sagawa et al. , we uti-lize two datsets, the Caltech-UCSD Birds-200-2011 (CUB)dataset and the Places1 dataset , to construct theWaterbirds dataset. The bird images are segmented from theCUB dataset, and the segmented birds are combined withthe background images from the Place dataset. We employ",
  "CC BY": "the code released by Sagawa et al. 2 for constructingthe dataset. As mentioned in the repository, a few land-birds (Eastern Towhees, Western Meadowlarks, and West-ern Wood Pewees) in the original dataset are incorrectly la-beled as waterbirds. Therefore, we correct their labels tolandbirds for the experiments.The BFFHQ is initially presented by Kim et al. and constructed by modifying the FFHQ dataset 3. In theBFFHQ, the bias attribute is the gender and the intrinsic at-tribute is the age. Specifically, most of the young people arefemale, and most of the old people are male in the trainingdataset.Lastly, the BAR dataset is introduced by Nam et al. .",
  ". The worst accuracy between the accuracy of BA and BC samples in the Waterbirds dataset. BS is bias severity": ". Visualization of datasets used in the experiments. A group of three columns represents each class for (a) Waterbirds-{Landbird,Waterbird} and (b) BFFHQ-{Young, Old}, and each column of (c) BAR-{Climbing, Diving, Fishing, Vaulting, Racing, Throwing} repre-sents a distinct class. The samples above the dashed line are bias-aligned samples and the below ones are bias-conflicting samples. The dataset contains six action classes (i.e., Climbing, Div-ing, Fishing, Vaulting, Racing, Throwing) and each class isbiased to a certain background (i.e., RockWall, Underwater,WaterSurface, Sky, APavedTrack, PlayingField). In the testset, such correlations do not exist. For the experiments, weuse the BFFHQ dataset and BAR dataset released by Lee etal. 4. The examples of the BA samples and BC samplesin each dataset are shown in .",
  "H. Implementation details": "Following the previous studies , we utilizeResNet18 for the biased model fb and the debiasedmodel fd. Also, f embdindicates the subnetwork before theaverage pooling layer, and f clsd consists of an average pool-ing layer and a linear classifier that outputs logits, wherefd(x) = f clsdf embd(x). Before training, fb and fd are ini-tialized with the ImageNet pretrained weight for the BARdataset, while we randomly initialize the models for theother datasets. This is because the size of the BAR datasetis extremely small compared to the others .During training fd, we employ the sample reweightingvalue w(x) termed as relative difficulty score , as men-tioned in Sec. 3.4 in the main paper. w(x) is calculated asfollows:",
  "LCE(fb(x), y) + LCE(fd(x), y).(14)": "This score assigns a high weight to the BC samples anda low weight to the BA samples. This encourages fd tomainly learn intrinsic features by emphasizing BC sampleswith w(x).The models are trained for 50K iterations with a batchsize of 64. The horizontal flip and a random crop with asize of 224 are used for data augmentation during the train-ing. All the models are trained with the Adam optimizer.The learning rate is set as 1e-4 for the Waterbirds and theBFFHQ dataset, and 1e-5 for the BAR dataset. The hyper-parameters of l, s, and are set as 0.1, 0.9, and 2, respec-tively, for all the datasets. We apply class-wise max normal-ization to our BN score to consider the different ranges ofthe scores across the classes for stability of training.During the training, we aim to select an auxiliary samplethat has no bias attribute but has the same class label withx as xBN from DBN. If no sample in DBN has the samelabel as x, we select the sample that has the same label withx from DBNcand. In a case where theres no sample with thesame label as x in both DBN and DBNcand, we sample xBN thathas the same label with x from D.As described in Sec. 3.1 in the main paper, we utilizethe pretrained biased models to construct DA, following theprevious work . We utilize ResNet18 for the pre-trained biased models, and all the pretrained biased modelsare randomly initialized before training. The models aretrained for 1K iterations with the generalized cross entropy(GCE) loss . Within each model, the samples with ahigh ground-truth probability (i.e., 0.99) are considered as BA samples. Based on majority voting, we collect thesamples that are considered as the BA sample by the ma-jority of the models and construct the bias-amplified datasetDA. We use five pretrained biased models following thestudy of Lee et al. . Lee et al. demonstrate that adoptingthe additional biased models requires a negligible amountof additional computational costs and memory space. Notethat the same biased models are utilized when constructingDBNcand.",
  "I. Limitations and future work": "Although our BN score effectively encourages BC samplesto be mainly adopted as auxiliary inputs, the auxiliary in-puts still can include a few BA samples, as shown in of Sec. 4.3 in the main paper. Accordingly, such BA sam-ples may interfere with the model to capture the intrinsicfeatures. Identifying intrinsic attributes without relying onauxiliary inputs can be one promising future work.In addition, since our IE weight is designed to enhanceintrinsic features by imposing spatially different values onthe features, our method might be more effective especiallywhen bias attributes are located in different regions from theintrinsic attributes. In this regard, applying channel-wisere-weighting to our approach will further improve thegeneral applicability of our method.Despite the limitations above, we believe that our workposes the importance of enhancing intrinsic attributes fordebiasing."
}