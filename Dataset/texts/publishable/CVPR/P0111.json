{
  "Abstract": "We introduce Infinigen Indoors, a Blender-based proce-dural generator of photorealistic indoor scenes. It buildsupon the existing Infinigen system, which focuses on naturalscenes, but expands its coverage to indoor scenes by intro-ducing a diverse library of procedural indoor assets, includ-ing furniture, architecture elements, appliances, and otherday-to-day objects. It also introduces a constraint-basedarrangement system, which consists of a domain-specificlanguage for expressing diverse constraints on scene com-position, and a solver that generates scene compositionsthat maximally satisfy the constraints. We provide an ex-port tool that allows the generated 3D objects and scenesto be directly used for training embodied agents in real-time simulators such as Omniverse and Unreal. InfinigenIndoors is open-sourced under the BSD license. Please visitinfinigen.org for code and videos.",
  ". Introduction": "Synthetic data rendered by conventional computer graph-ics has seen increasing adoption in computer vision and AI research, espe-cially for 3D vision and embodiedAI. Synthetic data can be renderedin unlimited quantities and can automatically provide high-quality 3D ground truth, enabling large-scale training ofcomputer vision models and embodied agents. Notably,many state-of-the-art 3D vision systems and roboticsystems have been trained purely in simulation yetperform surprisingly well in the real world zero-shot.A promising direction for creating synthetic data is pro-cedural generation, which uses mathematical rules to create3D objects and scenes, as opposed to manual sculpting orreal-world scanning. These mathematical rules can have pa-rameters that are randomized to allow infinite variations. Forexample, trees can be generated through a recursive set ofrules that randomly branch off. Compared to reusing a fixed,static set of 3D assets, procedural generation can greatly improve the diversity of the synthetic data and the simulatedenvironments.Infinigen is a recent work that pushed the idea ofprocedural generation to the limit. Infinigen is an open-source system that generates photorealistic 3D scenes fullyprocedurally, meaning that every 3D asset, from shape tomaterial, from large structures to small details, is completelyprocedural, without using any external static asset. Beingfully procedural means that every aspect of the 3D scene,from the details of individual objects to their arrangementsin a scene, can be customized and controlled by simplymodifying the underlying mathematical rules. As a result,a 3D scene can be randomized at all levels down to thesmallest details, as opposed to only at the level of objectarrangement, which was common in earlier work that usedprocedural generation.However, the current Infinigen system is limited to naturalscenes and objects (terrains, animals, plants, etc.). Althoughnatural scenes could be sufficient for training foundationmodels as evidenced by natural evolution , this hypothe-sis remains unproven and may require additional advancesin learning algorithms and architecture designs. Evidencefrom the current literature suggests that synthetic trainingdata that more closely approximates the application domainis still likely to lead to better downstream performance.To overcome this limitation, we introduce Infinigen In-doors, a procedural generator of photorealistic indoor scenes.It expands the coverage of Infinigen to indoor scenes, whichare relevant for many high-impact applications includingrobotics and augmented reality. Infinigen Indoors generatesdiverse indoor objects, including furniture, appliances, cook-ware, dining utensils, architectural elements, and other com-mon day-to-day objects. It also generates full indoor scenes,including the interior of multi-room, multi-floor buildings,with object arrangements that are physically and semanti-cally plausible. shows random samples of generatedscenes, and shows some automatic annotations.Like the original Infinigen, Infinigen Indoors is not afixed set of 3D models or scenes; instead, it is an open-source generator that can create unlimited variations both",
  "arXiv:2406.11824v1 [cs.CV] 17 Jun 2024": ". Random, non cherry-picked sample of images generated by our system. From top left to bottom right, we show images fromdining rooms, bathrooms, living rooms and kitchens. Please see Appendix B for an extended random sample. at the object level and at the scene level. Infinigen Indoorsis also 100% procedural, using no external assets and usingonly mathematical rules to generate everything from scratch.Infinigen Indoors builds upon the original Infinigen andBlender but makes significant new contributions. Themain contributions include (1) a library of procedural gen-erators of indoor assets, (2) a constraint-based arrangementsystem, (3) a tool to export the generated scenes to real-timesimulators such as NVIDIA Omniverse and UnrealEngine.Our second contributiona constraint-based arrangementsystemoffers a new capability specifically targeting indoorsettings. Indoor scenes are artificial, and object arrangementexhibits a greater degree of regularity than natural scenes:for example, furniture usually does not block the entrance ofa room. We thus develop a system that lets the user specifyscene arrangement constraints through a domain-specificlanguage using a set of Python APIs. The constraints covermany types of common arrangement, including symmetry(Place chairs symmetrically around the table), spatial rela-tion (Place plant pots close to windows ), quantity (Anequal number of knives and forks), physics (Ensure vasesdo not overhang), and accessibility (Ensure there is free-space in-front of all appliances). The constraints can beunderstood as a type of declarative procedural rules that ex-press what the user desires but not how to achieve it. Likeother procedural rules, the constraints can be randomizedand can be customized by the user.In addition to constraint specification, our arrangement system also includes a constraint solver, which searchesfor an arrangement that maximally satisfies a set of givenconstraints. Our solver greedily performs simulated anneal-ing on whole-house floor plans, followed by large furniturelayouts and then small objects. Compared to existing ap-proaches for scene arrangement, our solver is highly expres-sive, supporting complex compositional constraints that arechallenging or infeasible for existing approaches. In addi-tion, it is the first solver integrated with an open-source andfully procedural generator.Our constraint-based arrangement system is a significantcontribution because it vastly improves the generation sys-tems usability and customizability. Because it separatesconstraint specification from constraint solving, a user canconveniently express the objectives of procedural generationwithout worrying about implementation. This capability isnot available in the original Infinigen, where the user has tocustomize the procedure rules at the implementation level.Ourthirdcontributionexportingtoreal-timesimulatorsis also noteworthy because it allows thegenerated 3D objects and scenes to be directly used fortraining embodied agents in real-time simulators such asOmniverse. Thus, Infinigen Indoors can supply diverse3D assets for simulation environments and enhance theirdomain randomization.To validate the effectiveness of the generated data anddemonstrate our systems unique customizability, we useInfinigen Indoors to generate synthetic data for shadow re-moval and occlusion boundary detection, two tasks that lack",
  "DatasetArrangementProceduralProvides# Scenes# AssetsFreeExternal Asset SourceMethodAssetsProcedural Codein Totalin TotalAssets": "3DSSG Real-world scansNoN/A1.5K48KYes3RScan Matterport3D Real-world scansNoN/A2K -YesNoneStanford 2D-3D-S Real-world scansNoN/A270-YesNoneScanNet Real-world scansNoN/A1.5K-YesNoneSceneNN Real-world scansNoN/A100-YesNoneOpenRooms Real-world scansNoNo1.3K3K No ($500)ShapeNet , Scan2CAD , Adobe Stock Replica Real-world scansNoN/A18-YesNoneStructured3D Artist layoutsNoN/A22K472KNoProfessional DesignersHypersim Artist layoutsNoN/A46159KNo ($6000)Evermotion Architectures InteriorNet Artist layoutsNoN/A22M1MNoManufactures / Kujiale Habitat 3.0 Artist layoutsNoN/A21118.7KYesFloorplanner , Proffesional Designers3D-FRONT Artist layoutsNoN/A19K13KYes3D-FUTURE Robotrix Artist layoutsNoN/A16-NoUE4Arch , UnrealEngine Marketplace DeepFurniture Artist layoutsNoN/A20K-NoAdobe Mixamo SceneNetRGBD Obj. Cat. Dist.NoN/A5.1KYesSceneNet , ShapeNet LUMINOUS Hierarchical SamplingNoYes2KYesAI2-THOR SceneNet OptimizerNoNo3.7KYes3DModelFree , ModelNet , Archive3D , Stanford databaseProcTHOR Procedural RulesNoYes1.6KYesAI2-THOR , Professional DesignersHolodeck LLMNoYes50KYesObjaverse Aria Procedural RulesNoNo100K8K--",
  "(i)(g)": ". Each image (a) is rendered from a mesh (b), from whichwe can also extract Depth (c), Surface Normals (d), OcclusionBoundaries (e), Segmentation (f), Bounding Boxes (e) and OpticalFlow (h), with Albedo (i) from rendering metadata. abundant existing training data. Our experiments show thatdata from our system improves generalization performanceon indoor scenes.Like the original Infinigen, Infinigen Indoors will be open-sourced under the BSD license to enable free and unlimiteduse by everyone, and to enable community contributions ofadditional procedural generators.",
  ". Related Work": "We provide a detailed comparison of Infinigen Indoors withexisting datasets and generators in Tab. 1.Real-world datasets. Various real-world datasets have beenintroduced for indoor scene understanding , including the earlier and widely used NYUv2 and Sun RGB-D , as well as more recent datasets . However, real-world datasets are labor-intensiveto collect and limited in size. In addition, real-world 3D ground truth can be difficult to acquire due to the limitationsof depth sensors, which include limited resolution and range,errors with transparent/reflective surfaces, and artifacts atobject edges.Synthetic Indoor Datasets. There are many existing syn-thetic datasets for indoor scenes . However, the underlying 3D assets of manydatasets are not freely accessible, limiting their utility. Inaddition, most use a static library of 3D assets, limiting theirdiversity. Recent work has incorporated procedu-ral generation for scene layout and floor plan generation, butstill relies on static libraries of objects and materials. In con-trast, Infinigen Indoors is 100% procedural, with all assetsfrom shape to texture generated from scratch with unlimitedvariation.Object arrangement and layout generation.Constraints are potent tools to describe the layout of ascene. Early works like represent constraints as hard-coded programs, and represent them as physical rela-tions. Data-driven works like learnconstraints implicitly from data. Such implicit constraintsare less customizable, interpretable, and controllable than In-finigen Indoors. Recently, modeling constraints using proba-bilistic graphs have become more popular: uses pairwisegrouping, while further extends it to spatial andhierarchical constraints. uses factor graphs to parsethe constraints, while models them with Bayesian net-work. formulates constraints as potentials MarkovRandom Fields on a fixed graph, which capture only non-compositional and associative constraints for rooms andobjects.Compared to existing systems, ours is the first to inte-grate directly with procedural object generators, and ourconstraint language is higher level and more easily extend-",
  ". Random samples of procedurally generated furniture,including sofa, chairs, and beds (top), tables (middle/bottom), andshelves (bottom)": "able than existing systems. Our system specifies high levelgoals for abstract classes of objects (e.g. furniture, stor-age), rather than exhaustive distance/angle distributions forspecific objects which must be fitted to example scenes.Our language also supports compositional constraints suchas place glassware only on shelves against a dining-roomwall. These features allow users to write new constraintsfor their specific needs, including domains without existingartist-made scenes. Our constraint solver uses simulatedannealing, following prior work , but involves movesthat are unique to our constraint language, including up-dates to object-object relations or changing the parametersof procedural objects (e.g. the size of a table).",
  ". Random samples of procedurally generated tableware, in-cluding dinnerware (Row 1-2), cookware (Row 2), food containers(Row 3) and dining utensils (Row 4)": ". Random samples of procedurally generated home decora-tions, including lamps, hardware, balloons, wall decor (top), rugs,book stacks, vases, and plants (bottom). Small assets for decorationpurposes, usually attached to the ground or walls. . A collection of materials generated in Infinigen Indoors.The first figure shows one material per generator, with columns(1-3) used on assets of various sizes, (4-5) used on assets and rooms,and (6) for abstract art and text. The second figure shows multiplematerials from the same generator with different parameters. have many human-controllable parameters, which are ran-domized by default, or can be manually overridden by theuser. These parameters are used along with additional low-level random noise to generate meshes via geometry nodes,modifiers, or mesh manipulations in Blender. We providea total of 79 randomized procedural object generators. Bycategory, we cover Appliances (10 generators, 112 params),Windows/Doors/Staircases (14 generators, 127 params), Fur-niture (17 generators, 216 params), Decorations (15 gener-ators, 92 params), and Small Objects (19 generators, 194params). See Appendix F for a list.",
  ". Example usage of our constraint specification API, speci-fying the quantity and aesthetic constraints for a dining table andchairs": "Architectural elements shown in are integrated intoroom as fixtures. We use array repetition of atomic compo-nents to build staircases, and mesh booleaning to cut out thepanels of doors and windows.Large objects shown in and 5 provide assets relatedto cooking, seating and storage. We use soft-body colli-sion simulation to model soft blankets, clothing, and stuffedpillows when they are put on a supporting surface.Small objects shown in and 7 can be attached to sup-port surfaces, walls, or ceilings. We also devised a combinedtext-and-shape logo generator that produces procedural tex-ture for fabrics, food packaging, and art decor. We use clothsimulation to inflate balloons and food packaging with air.Materials are all procedurally created with Blenders shadernodes, as shown in . We provide 30 material generatorswith 120 controllable parameters in total, split approximatelyevenly between types of wood, ceramic, fabric, metal, andothers. We cover 78% of OpenSurfaces material cate-gories, up from 21% for Infinigen.",
  ". Constraint Specification API": "Indoor scene layouts are highly regular, and follow complexrules governing ergonomics, aesthetics, and functionality.Moreover, the rules that apply to a particular object dependon context - for example, tables are placed against wallswhen used as desks in study rooms, but must be far fromwalls and surrounded by chairs when used in a dining room.To capture this, we provide a high-level Constraint Specifica-tion API, which allows the user to write expressive objectivefunctions to describe the properties of a desirable scene. Anexample of the Constraint Specification API is shown in 9.Each constraint in our API is a compute graph of geo-metric, set filtering, and arithmetic operations. Geometricoperators are designed to compute spatial and geometricproperties, including minimum distance, rotational and re-flection symmetry, angle alignment, 2D free-space, accessi-bility and volume or area of objects. Each geometric operatoraccepts a set of objects as input, which can be provided by filtering the scene using semantics and scene graph relations.This allows the user to create scoped constraints that applyonly to objects attached to specific surfaces or rooms. Addi-tionally, these geometry terms are affected by the parameters(length, width, etc.) of the procedurally generated assets,meaning that optimizers can automatically discover optimalfurniture parameters given available space and constraints.Our system features common scalar arithmetic operations,comparisons, and forall / sum operators to gather resultsover sets of objects. Please see Appendix A.1 for the fullAPI and more examples of constraint specifications.A more concrete example of our constraint language canbe found in , where the constraint program specifiescommon-sense human ergonomics and semantic relationsfound in residential homes. This constraint graph has atotal of 1058 nodes, which compute 11 hard constraintsand 25 score terms (soft constraints). We provide exampleconstraint specifications for living rooms, bathrooms, diningrooms, kitchens, and warehouses.We believe that many users will consider creating customconstraints tailored to particular applications when generat-ing training data. Our constraint system is designed to alloweasy customization. Our initial spec. has avg. 15 constraintsspecific to each room: approx. 15 lines of Python. We believethis cost is very tractable when users need customization.",
  ". Arrangement Solver": "Because our Constraint Specification API is flexible, thesolver needs to search a prohibitively large space in whichfinding an exact minimum is impossible. To deal with this,it uses Simulated Annealing with Metropolis-Hastingscriterion . The solver first takes the current states and randomly chooses a move category. It then uses theconstraint graph to generate a proposed state s that can bereached using the move. The current and proposed states areevaluated on the graph specified by the provided constraintsand score terms, yielding loss terms l(s) and l(s). Then, thesolver calculates the transition probability between s and s",
  ", 1": "where is the temperature of the solver, which cools expo-nentially from = 0.25 to = 0.001.Our solver allows both discrete and continuous moves:Addition - Adds a procedural object to the scene.Deletion - Deletes an object from the scene.Relation Plane Change - Assigns an object to another plane.Resample - Regenerates an object with new parameters.Reinitialize Pose - Samples a new random pose for an object.Translate - Translates the object within its DoF plane.Rotate - Rotates the object around its DoF axis.We observe that not all moves are equally significant ateach point in the optimization. In an empty scene, object . In Fig. a), we show ten randomly generated single-story floor plans with a diverse set of room combinations, connectedness, andoverall contours. In Fig. b), we show results for the generation of multistory floor plans. Floors 0,1,2 are displayed separately. Staircasesconnect adjacent floors. We remove exterior walls and ceilings for visibility.",
  ". Qualitative room arrangement results, grouped by room type. From left to right, we show bathrooms, dining rooms, living roomsand kitchens": "addition and relation change allow for higher loss reduction,whereas in a cluttered scene, continuous object movementallows for higher loss reduction. Thus, we provide a schedulefor moves so that probabilities for discrete moves decaygradually and probabilities for continuous moves increase. The objects in an indoor scene are interdependent on eachother, which makes it unfeasible to optimize over all of themsimultaneously. However, they usually depend on each otherhierarchically (e.g. a cup is on the table, which is on thefloor). To exploit this hierarchy, we divide our optimizationinto three stages: large object optimization, medium objectoptimization, and small object optimization. Each object is constrained in its movement due to theconstraints specified by the user and the discrete movesproposed by the solver. For instance, a bookshelf that isstable against a wall is only allowed to move along the 1Dline between the wall and the floor. Consequently, an objectsdegrees of freedom (DoFs) for rotation and translation aredetermined based on its relations to other objects. When thesolver samples a continuous move, it restricts the objectsmotion to these DoFs. When the solver samples a discretemove, it places the object in the constrained subspace. Floorplan-specific solver and constraintsOur floorplangenerator creates realistic full-house room meshes, as shownin . First, we procedurally generate a room adja-cency graph specifying the number, type, and connected-ness of individual rooms required in the floor plan. Thisgraph is produced by inference on a probabilistic context-free grammar on room types, or can be wholly or partiallyderived from user input. We define our objective functionas a weighted combination of the terms below, and optimizeit using simulated annealing subject to constraints from theroom adjacency graph. See Appendix D for full definitions. Shortest path to entrance Typical room area Room aspect ratio Room convexity Room wall conciseness Functional room area Room collinearity Narrow passages Exterior length by room Exterior corners by room Staircase occupancies Staircase IOU with rooms We initialize our floorplan solver by generating a randomhouse outline, and subdividing it using a Mondrian Process until it produces sufficient spaces for each room. Weextrude a wall segment inwards or outwards at each step, orswap the assignment subject to the room adjacency graph.Either action will lead to a change in loss, which we convert",
  ". Qualitative results on synthetic artistic scenes": "Description (USD) or other formats. As seen in ,indoor scenes can be exported to Omniverse Isaac Sim andUnreal Engine 5 and can be run at interactive frame rates.This exporting capability allows Infinigen Indoors to helptrain embodied agents in virtual environments.Infinigen Indoors uses Blenders procedural material sys-tem, which is by default not portable to other simulatorsor scene editors. To resolve this, we provide tools to au-tomatically post-process and UV-map entire indoor scenes,and use texture baking to create standard texture maps formaterial color, roughness, metallicity and more. We also pro-vide export code to convert single objects to textured OBJ,FBX or STL meshes, and automatically generate collisionand articulation information as Universal Robot DescriptionFormat (URDF) files.",
  ". Solver Performance": "To efficiently solve large numbers of constraints in clutteredscenes, we optimized our solver with various features forfaster convergence. Plane hashing enables faster access tobounding planes during discrete optimization. BVH cachingenables faster mesh distance and collision calculations byreusing Bounding-Volume-Hierarchies except when mutatedby a state update. Evaluation caching maintains a cache ofresults in the evaluation graph. Move filtering narrows downthe search space in continuous optimization by selectivelypruning candidates to those that can reduce the loss. Place-holder optimization only generates full meshes when otherobjects are assigned to them; otherwise it keeps boundingboxes.To analyze the importance of these features, we con-ducted an ablation in Tab. 3 and , which showssolver performance with each feature removed. All resultsare averaged over 20 random scenes with 5k solver steps.Our full system provides a 3x speedup compared to thenon-optimized version. Most of the performance gains comefrom BVH caching and Plane Hashing. We observe that dis-crete changes such as pose re-initialization, relation changes,and object resampling are necessary for compelling visuals,but decrease the quantitative score and increase the runtime.When we run our fully optimized system as long as thenon-optimized version we get a 28% score increase.Perceptual Study We performed a crowdsourced human",
  ". Shadow Removal": "To demonstrate its flexibility in data generation, we usedInfinigen-Indoors to create a dataset consisting of 2k imagepairs of shadow and shadow-free variants. These pairs weregenerated by toggling the shadow property of lighting withinBlender. For each pair, shadow masks were produced usingOtsus thresholding method. We use ShadowFormer model for the experiments and consider two variations:only trained on ISTD real dataset (R), and trained oncombination of ISTD and 2k Infinigen Indoors syntheticdataset (R+S). The results are shown in Tab. 2. While usingsynthetic data leads to slightly worse performance on theISTD dataset, the zero-shot application on the SRD dataset shows clear improvement for generalization to newtest datasets. Qualitative results are shown in .",
  ". Occlusion Boundary Estimation": "To validate the effectiveness of Infinigen Indoors, we alsoevaluate on the task of occlusion boundary estimation, atask with limited available data. We produce 1464 imagesannotated with ground truth. We train three U-Net models from scratch separately on these images, on imagesgenerated from Infinigen and Hypersim . We thencompare their performance on a curated test set of photore-alistic artist-designed synthetic 3D scenes for architecture",
  ". Occlusion boundary quantitative results on a curatedtest set of photorealistic artist-designed synthetic 3D scenes forarchitecture visualization": "visualization , since no existing photorealistic indoordataset provides such annotations. See Appendix G for moredetails.We report the following three metrics : (i)optimal dataset scale F-score (ODS), representing the bestF-score achieved on the dataset using a uniform thresholdacross all test images; (ii) optimal image scale F-score (OIS)indicating the cumulative F-score on the dataset obtainedwith thresholds dependent on individual images; and (iii)mean average precision (mAP) denoting the mean precisionacross the complete recall range.As we can see in Tab. 4, our Infinigen Indoors-trainedmodel generalizes better. The model achieves higher per-formance across all metrics. These findings underscore theusefulness of Infinigen Indoors as a valuable training re-source. Qualitative results are depicted in .",
  ". Contributions & Acknowledgements": "Alexander Raistrick, Lingjie Mei and Karhan Kayan con-tributed equally and are ordered randomly. Each has theright to list their name first in their CV. Alexander Raistrickperformed team coordination and developed the constraintlanguage and object graph solver. Lingjie Mei developedthe room solver and many procedural assets. Karhan Kayandeveloped the geometric constraints and object pose solver.David Yan developed the scene exporter and other utilities.Yiming Zuo, Beining Han, Hongyu Wen, Meenal Parakh,Stamatis Alexandropoulos, Zeyu Ma and Lahav Lipson de-veloped procedural assets and utilities. Jia Deng conceptual-ized and led the project, and set directions. This work waspartially supported by the National Science Foundation andAmazon. Archive 3D. Archive 3d. 3 Martn Abadi, Ashish Agarwal, Paul Barham, EugeneBrevdo, Zhifeng Chen, Craig Citro, Greg S. Corrado, AndyDavis, Jeffrey Dean, Matthieu Devin, Sanjay Ghemawat, IanGoodfellow, Andrew Harp, Geoffrey Irving, Michael Isard,Yangqing Jia, Rafal Jozefowicz, Lukasz Kaiser, ManjunathKudlur, Josh Levenberg, Dandelion Mane, Rajat Monga,Sherry Moore, Derek Murray, Chris Olah, Mike Schuster,Jonathon Shlens, Benoit Steiner, Ilya Sutskever, Kunal Tal-war, Paul Tucker, Vincent Vanhoucke, Vijay Vasudevan,Fernanda Viegas, Oriol Vinyals, Pete Warden, Martin Wat-tenberg, Martin Wicke, Yuan Yu, and Xiaoqiang Zheng. Ten-sorFlow: Large-scale machine learning on heterogeneoussystems, 2015. Software available from tensorflow.org. 18",
  "I. Armeni, A. Sax, A. R. Zamir, and S. Savarese. Joint 2D-3D-Semantic Data for Indoor Scene Understanding. ArXive-prints, 2017. 3": "Armen Avetisyan, Manuel Dahnert, Angela Dai, ManolisSavva, Angel X Chang, and Matthias Niener. Scan2cad:Learning cad model alignment in rgb-d scans. In Proceed-ings of the IEEE/CVF Conference on computer vision andpattern recognition, pages 26142623, 2019. 3 Gilad Baruch, Zhuoyuan Chen, Afshin Dehghan, Tal Dimry,Yuri Feigin, Peter Fu, Thomas Gebauer, Brandon Joffe,Daniel Kurz, Arik Schwartz, and Elad Shulman. Arkitscenes- a diverse real-world dataset for 3d indoor scene understand-ing using mobile rgb-d data. In NeurIPS, 2021. 3",
  "Sean Bell, Paul Upchurch, Noah Snavely, and Kavita Bala.OpenSurfaces: A richly annotated catalog of surface appear-ance. ACM Trans. on Graphics (SIGGRAPH), 32(4), 2013.5": "Angel Chang, Angela Dai, Thomas Funkhouser, MaciejHalber, Matthias Niessner, Manolis Savva, Shuran Song,Andy Zeng, and Yinda Zhang. Matterport3d: Learningfrom rgb-d data in indoor environments. arXiv preprintarXiv:1709.06158, 2017. 3 Angel X Chang, Thomas Funkhouser, Leonidas Guibas,Pat Hanrahan, Qixing Huang, Zimo Li, Silvio Savarese,Manolis Savva, Shuran Song, Hao Su, et al. ShapeNet:An information-rich 3D model repository. arXiv preprintarXiv:1512.03012, 2015. 3",
  "Blender Online Community. Blender - a 3D modelling andrendering package. Blender Foundation, Stichting BlenderFoundation, Amsterdam, 2018. 2": "David F. Crouse. On implementing 2D rectangular assign-ment algorithms. IEEE Transactions on Aerospace and Elec-tronic Systems, 52(4):16791696, 2016. Conference Name:IEEE Transactions on Aerospace and Electronic Systems.17 Angela Dai, Angel X. Chang, Manolis Savva, Maciej Halber,Thomas Funkhouser, and Matthias Niener. Scannet: Richly-annotated 3d reconstructions of indoor scenes. In Proc.Computer Vision and Pattern Recognition (CVPR), IEEE,2017. 3",
  "Ehsani, Aniruddha Kembhavi, and Ali Farhadi. Objaverse:A universe of annotated 3d objects, 2022. 3": "Matt Deitke, Eli VanderBilt, Alvaro Herrasti, Luca Weihs,Kiana Ehsani, Jordi Salvador, Winson Han, Eric Kolve,Aniruddha Kembhavi, and Roozbeh Mottaghi. Procthor:Large-scale embodied ai using procedural generation. Ad-vances in Neural Information Processing Systems, 35:59825994, 2022. 1, 3 Matt Deitke, Eli VanderBilt, Alvaro Herrasti, Luca Weihs,Jordi Salvador, Kiana Ehsani, Winson Han, Eric Kolve, AliFarhadi, Aniruddha Kembhavi, and Roozbeh Mottaghi. Proc-thor: Large-scale embodied ai using procedural generation.ArXiv, abs/2206.06994, 2022. 3, 8, 28",
  "Lanqing Guo, Siyu Huang, Dingshuo Liu, Hao Cheng, andBihan Wen. Shadowformer: Global context helps imageshadow removal. ArXiv, abs/2302.01650, 2023. 8, 27": "Ankur Handa, Viorica Patraucean, Simon Stent, and RobertoCipolla. Scenenet: An annotated model generator for indoorscene understanding. In 2016 IEEE International Confer-ence on Robotics and Automation (ICRA), pages 57375743.IEEE, 2016. 3 Ankur Handa, Viorica Patraucean, Simon Stent, and RobertoCipolla. Scenenet: An annotated model generator for indoorscene understanding. In 2016 IEEE International Confer-ence on Robotics and Automation (ICRA), pages 57375743,2016. 3",
  "W. K. Hastings.Monte Carlo sampling methods usingMarkov chains and their applications. Biometrika, 57(1):97109, 1970. eprint: 5": "Rasmus Laurvig Haugaard and Anders Glent Buch. Sur-femb: Dense and continuous correspondence distributionsfor object pose estimation with learnt surface embeddings.In Proceedings of the IEEE/CVF Conference on ComputerVision and Pattern Recognition, pages 67496758, 2022. 1 Binh-Son Hua, Quang-Hieu Pham, Duc Thanh Nguyen,Minh-Khoi Tran, Lap-Fai Yu, and Sai-Kit Yeung. Scenenn:A scene meshes dataset with annotations. In 2016 fourthinternational conference on 3D vision (3DV), pages 92101.Ieee, 2016. 3 Braden Hurl, Krzysztof Czarnecki, and Steven Waslander.Precise synthetic image and lidar (presil) dataset for au-tonomous vehicle perception.In 2019 IEEE IntelligentVehicles Symposium (IV), pages 25222529. IEEE, 2019. 1",
  "Joonho Lee, Jemin Hwangbo, Lorenz Wellhausen, VladlenKoltun, and Marco Hutter. Learning quadrupedal locomo-tion over challenging terrain. Science Robotics, 5, 2020.1": "Kurt Leimer, Paul Guerrero, Tomer Weiss, and Przemys-law Musialski. LayoutEnhancer: Generating Good IndoorLayouts from Imperfect Data. In SIGGRAPH Asia 2022Conference Papers, pages 18, 2022. arXiv:2202.00185 [cs].3 Jiankun Li, Peisen Wang, Pengfei Xiong, Tao Cai, ZiweiYan, Lei Yang, Jiangyu Liu, Haoqiang Fan, and ShuaichengLiu. Practical stereo matching via cascaded recurrent net-work with adaptive correlation. In CVPR, 2022. 1 Jiankun Li, Peisen Wang, Pengfei Xiong, Tao Cai, ZiweiYan, Lei Yang, Jiangyu Liu, Haoqiang Fan, and ShuaichengLiu. Practical stereo matching via cascaded recurrent net-work with adaptive correlation.In Proceedings of theIEEE/CVF conference on computer vision and pattern recog-nition, pages 1626316272, 2022. 1 Wenbin Li, Sajad Saeedi, John McCormac, Ronald Clark,Dimos Tzoumanikas, Qing Ye, Yuzhong Huang, Rui Tang,and Stefan Leutenegger.Interiornet: Mega-scale multi-sensor photo-realistic indoor scenes dataset. arXiv preprintarXiv:1809.00716, 2018. 3 Zhengqin Li, Ting Yu, Shen Sang, Sarah Wang, Sai Bi,Zexiang Xu, Hong-Xing Yu, Kalyan Sunkavalli, MilovsHavsan, Ravi Ramamoorthi, and Manmohan Chandraker.Openrooms: An open framework for photorealistic indoorscene datasets. 2021 IEEE/CVF Conference on ComputerVision and Pattern Recognition (CVPR), pages 71867195,2020. 3",
  "Lahav Lipson, Zachary Teed, and Jia Deng. RAFT-Stereo:Multilevel recurrent field transforms for stereo matching. InInternational Conference on 3D Vision (3DV), 2021. 1": "Lahav Lipson, Zachary Teed, Ankit Goyal, and Jia Deng.Coupled iterative refinement for 6d multi-object pose es-timation. In Proceedings of the IEEE/CVF Conference onComputer Vision and Pattern Recognition, pages 67286737,2022. 1 Bingyuan Liu, Jiantao Zhang, Xiaoting Zhang, Wei Zhang,Chuanhui Yu, and Yuan Zhou. Furnishing your room bywhat you see: An end-to-end furniture set retrieval frame-work with rich annotated benchmark dataset. arXiv preprintarXiv:1911.09299, 2019. 3",
  "Ilya Loshchilov and Frank Hutter. Decoupled weight decayregularization. In International Conference on LearningRepresentations, 2017. 27": "Zeyu Ma, Zachary Teed, and Jia Deng. Multiview stereowith cascaded epipolar raft. In Computer VisionECCV2022: 17th European Conference, Tel Aviv, Israel, Octo-ber 2327, 2022, Proceedings, Part XXXI, pages 734750.Springer, 2022. 1 John McCormac, Ankur Handa, Stefan Leutenegger, and An-drew J. Davison. Scenenet rgb-d: Can 5m synthetic imagesbeat generic imagenet pre-training on indoor segmentation?2017 IEEE International Conference on Computer Vision(ICCV), pages 26972706, 2017. 3",
  "Siyuan Qi, Yixin Zhu, Huang Siyuan, Chenfanfu Jiang, andSong Zhu. Human-centric indoor scene synthesis usingstochastic grammar. 2018. 3": "Liangqiong Qu, Jiandong Tian, Shengfeng He, YandongTang, and Rynson W. H. Lau. Deshadownet: A multi-contextembedding deep network for shadow removal. In 2017 IEEEConference on Computer Vision and Pattern Recognition(CVPR), pages 23082316, 2017. 7, 8, 27 Alexander Raistrick, Lahav Lipson, Zeyu Ma, Lingjie Mei,Mingzhe Wang, Yiming Zuo, Karhan Kayan, Hongyu Wen,Beining Han, Yihan Wang, Alejandro Newell, Hei Law,Ankit Goyal, Kaiyu Yang, and Jia Deng. Infinite photoreal-istic worlds using procedural generation. In Proceedings ofthe IEEE/CVF Conference on Computer Vision and PatternRecognition, pages 1263012641, 2023. 1, 3, 7, 8, 26, 27,28",
  "Nathan Silberman and Rob Fergus. Indoor scene segmen-tation using a structured light sensor. In 2011 IEEE Inter-national Conference on Computer Vision Workshops (ICCVWorkshops), pages 601608, 2011. 3": "Shuran Song, Samuel P. Lichtenberg, and Jianxiong Xiao.Sun rgb-d: A rgb-d scene understanding benchmark suite.In Proceedings of the IEEE Conference on Computer Visionand Pattern Recognition (CVPR), 2015. 3 Sanjana Srivastava, Chengshu Li, Michael Lingelbach,Roberto Martn-Martn, Fei Xia, Kent Elliott Vainio, ZhengLian, Cem Gokmen, Shyamal Buch, Karen Liu, et al. Behav-ior: Benchmark for everyday household activities in virtual,interactive, and ecological environments. pages 477490,2022. 1 Julian Straub, Thomas Whelan, Lingni Ma, Yufan Chen,Erik Wijmans, Simon Green, Jakob J. Engel, Raul Mur-Artal,Carl Ren, Shobhit Verma, Anton Clarkson, Mingfei Yan,Brian Budge, Yajie Yan, Xiaqing Pan, June Yon, YuyangZou, Kimberly Leon, Nigel Carter, Jesus Briales, TylerGillingham, Elias Mueggler, Luis Pesqueira, Manolis Savva,Dhruv Batra, Hauke M. Strasdat, Renzo De Nardi, MichaelGoesele, Steven Lovegrove, and Richard Newcombe. TheReplica dataset: A digital replica of indoor spaces. arXivpreprint arXiv:1906.05797, 2019. 3 Andrew Szot, Alex Clegg, Eric Undersander, Erik Wijmans,Yili Zhao, John Turner, Noah Maestre, Mustafa Mukadam,Devendra Chaplot, Oleksandr Maksymets, Aaron Gokaslan,Vladimir Vondrus, Sameer Dharur, Franziska Meier, Wo-jciech Galuba, Angel Chang, Zsolt Kira, Vladlen Koltun,Jitendra Malik, Manolis Savva, and Dhruv Batra. Habitat 2.0:Training home assistants to rearrange their habitat. In Ad-vances in Neural Information Processing Systems (NeurIPS),2021. 1",
  "Zachary Teed, Lahav Lipson, and Jia Deng. Deep patchvisual odometry. arXiv preprint arXiv:2208.04726, 2022. 1": "Vajira Thambawita, Pegah Salehi, Sajad Amouei Sheshkal,Steven A Hicks, Hugo L Hammer, Sravanthi Parasa,Thomas de Lange, Pl Halvorsen, and Michael A Riegler.Singan-seg: Synthetic training data generation for medicalimage segmentation. PloS one, 17(5):e0267976, 2022. 1 UE4Arch. Ue4arch. 3 Johanna Wald, Armen Avetisyan, Nassir Navab, FedericoTombari, and Matthias Niessner. Rio: 3d object instancere-localization in changing indoor environments. In Proceed-ings IEEE International Conference on Computer Vision(ICCV), 2019. 3",
  "Johanna Wald, Helisa Dhamo, Nassir Navab, and FedericoTombari. Learning 3d semantic scene graphs from 3d indoorreconstructions. In Conference on Computer Vision andPattern Recognition (CVPR), 2020. 3": "Chaohui Wang, Huan Fu, Dacheng Tao, and Michael J Black.Occlusion boundary: A formal definition & its detection viadeep exploration of context. IEEE Transactions on PatternAnalysis and Machine Intelligence, 44(5):26412656, 2020.8 Guoxia Wang, Xiaochuan Wang, Frederick WB Li, andXiaohui Liang. Doobnet: Deep object occlusion boundarydetection from an image. In Computer VisionACCV 2018:14th Asian Conference on Computer Vision, Perth, Australia,December 26, 2018, Revised Selected Papers, Part VI 14,pages 686702. Springer, 2019. 8",
  "Xinpeng Wang, Chandan Yeshwanth, and Matthias Niener.Sceneformer: Indoor scene generation with transformers.2021 International Conference on 3D Vision (3DV), pages106115, 2020. 3, 8, 28": "Philippe Weinzaepfel, Jerome Revaud, Zaid Harchaoui, andCordelia Schmid. Learning to detect motion boundaries. InProceedings of the IEEE conference on computer vision andpattern recognition, pages 25782586, 2015. 8 Zhirong Wu, Shuran Song, Aditya Khosla, Fisher Yu,Linguang Zhang, Xiaoou Tang, and Jianxiong Xiao. 3dshapenets: A deep representation for volumetric shapes. InProceedings of the IEEE conference on computer vision andpattern recognition, pages 19121920, 2015. 3",
  "Wenzhuo Xu, Bin Wang, and Dong-Ming Yan. Wall gridstructure for interior scene synthesis. Comput. Graph., 46:231243, 2015. 3": "Yue Yang, Fan-Yun Sun, Luca Weihs, Eli VanderBilt, Al-varo Herrasti, Winson Han, Jiajun Wu, Nick Haber, RanjayKrishna, Lingjie Liu, Chris Callison-Burch, Mark Yatskar,Aniruddha Kembhavi, and Christopher Clark. Holodeck:Language guided generation of 3d embodied ai environ-ments, 2024. 3 Yi-Ting Yeh, Lingfeng Yang, Matthew Watson, Noah D.Goodman, and Pat Hanrahan. Synthesizing open worlds withconstraints using locally annealed reversible jump mcmc.ACM Transactions on Graphics (TOG), 31:1 11, 2012. 3",
  "Yizhou Zhao, Kaixiang Lin, Zhiwei Jia, Qiaozi Gao, GovindThattai, Jesse Thomason, and Gaurav S. Sukhatme. Lumi-nous: Indoor scene generation for embodied ai challenges.ArXiv, abs/2111.05527, 2021. 3": "Yizhou Zhao, Kaixiang Lin, Zhiwei Jia, Qiaozi Gao, GovindThattai, Jesse Thomason, and Gaurav S Sukhatme. Lumi-nous: Indoor scene generation for embodied ai challenges.arXiv preprint arXiv:2111.05527, 2021. 3 Jia Zheng, Junfei Zhang, Jing Li, Rui Tang, Shenghua Gao,and Zihan Zhou.Structured3d: A large photo-realisticdataset for structured 3d modeling. In Computer VisionECCV 2020: 16th European Conference, Glasgow, UK, Au-gust 2328, 2020, Proceedings, Part IX 16, pages 519535.Springer, 2020. 3",
  "A.1. API Description": "with semantics(alsonotatedasoperatorsquare-brackets for brevity) extracts the subset of a set of objectsthat satisfies a semantic predicate, e.g. extract the subsetof rooms which are dining-rooms or extract the subset offurniture objects which are shelving. The hierarchy of thesepredicates is defined by asset creators, or can be reconfiguredby constraint program writers if they intend to use an objectfor an unusual purpose. Using hierarchical classes for thisfiltering operation allows every constraint to apply to themost broad class of objects possible, to avoid rewriting orrestating constraints for objects that fulfill a similar function. related toextracts the subset of a set of objects relatedto any member of a second set of objects via some rela-tion. The exact way in which the objects are related is user-configurable by passing in any parameterized Relation ob-ject from the options below (StableAgainst, SupportedBy),which represents a predicate that can be True or False of anypair of objects.By combining related to with other filtering opera-tions, the user can express constraints on arbitrarily complexcontexts such as maximize the number of dining chairsagainst dining tables inside of rooms adjacent to kitchens,to encourage plenty of seating near food preparation areas,etc. sceneretrieves the set of all objects currently in the scene.All constraint programs are ultimately functions of the cur-rent scene state, so this node serves as the leaf node of allconstraint program expressions (besides numeric constants).Users rarely place constraints on scene directly. Instead, weexpect the user first to take subsets via the operations above. StableAgainstspecifies a relation using a child objectsplanar surface, a parent objects planar surface, and a marginbetween the surfaces. It checks that the childs surface isparallel to the parents, the child is not overhanging, and thechilds surface is exactly at the specified margin. A concreteexample would be specifying the sofa as stable against thefloor with zero margin and stable against the wall with a10cm margin. Alternatively, specifying a painting to bestable against the wall ensures that the painting does notoverhang across the edge of the wall. SupportedByspecifies a relation using a child objectsplanar surface and a parent objects planar surface. It meansthat the child object would not fall over from the parentobject. More precisely, the surfaces are parallel against each other with zero margins, and the centroid of the childobject is contained within the convex hull of the intersectionbetween the child and the parent object. The last conditionis to ensure zero torque by gravity. An example use case is acoffee cup teetering on the tables edge. In this case, the cupis supported by the table, but it is not stable against it sinceit is overhanging.",
  "countreturns the cardinality of a set of objects in thescene": "area, volumereturns the total area or volume of thebounding boxes of objects in a set. We use bounding boxesto avoid expensive calculations to compute the exact volumeof each mesh, and we find this serves as a suitable proxyto incentivize larger assets. Area always takes over the twolargest axes of an object and is usually used for 2D objectslike paintings or rugs. min distancecalculates the minimum distance betweentwo sets of tagged objects. For instance, the minimum dis-tance between the walls and the back of the couch. Theminimum distance is defined as the distance between theclosest two points on the two sub-meshes identified by thetags.",
  "cos i": "where i is the angular difference between the front-facingnormal of object i and the inward normal of the closest edgeof the reference object. The contribution of each object is inthe range.An example use case is minimizing the angle alignmentcost between chairs and tables to make the chairs face thetable. Another example is using an alignment score to alignfurniture to the walls in order to give the arrangement a moregrid-like shape. rotation asymmetrygives a continuous characteriza-tion of the rotational asymmetry of a set of objects basedon . It measures the deviation of the set of objectsfrom a regular polygon with perfectly rotationally symmetricorientations. From another perspective, it measures the ro-tational asymmetry of a set of point-vector pairs. The scoreconsists of two parts and is calculated as",
  "Suppose the location of the ith object is given by xi andthere are n objects. The location asymmetry is calculated asfollows:": "Let pi = xi c where c is the centroid of the objects. Rotate all pi so that p1 is aligned with the axis. Normalize pi by dividing by maxi ||pi||. Let fi be vector pi rotated by 2i/n. Compute q as the average of fi. Let wi be vector q rotated by 2i/n. Then, we have location asymmetry = 1",
  "The orientation asymmetry score follows the same steps asthe location asymmetry, but with pi replaced by the frontalplane normal of the object i": "As an example, rotational asymmetry score can be usedto encourage tableware being rotationally symmetric on thetable not only with respect to their location but also theirorientation. It can also be used to make chairs rotationallysymmetric around the table. reflection asymmetrycalculates a continuous reflec-tional asymmetry score for a set of objects relative to areference object. This score quantifies the deviation of ob-jects from mirror symmetry. The process involves reflectingeach object across a plane and then comparing the originaland reflected objects. From another perspective, it quantifiesthe mirror asymmetry of a set of point-vector pairs. Theasymmetry score is computed as follows:",
  "Optimization objectives based on...Our API FunctionExample Usage (Described in Natural Language)": "Objects with (abstract) semanticswith semantics a.k.a. Scope a constraint to a hierarchical class e.g. shelves, storage, all furniture, or all objectsObjects related to other objectsrelated toCooking pots go in the center when on tables, but can go anywhere on a countertop.Objects on arbitrary surfacesSupportedByMulti-story homes, decorations on shelves, countertops, fridgesWhether objects overhangStableAgainstPaintings cant overhang wallsNon-convex object shapesYes, procedural placeholdersObjects go inside shelves, chairs tuck under table Variable quantity of objectscountAllow between 0 and 3 sofas in a living-room, but as many as possibleSize of objectsarea, volumeGenerate the biggest possible TV & Sofa that fits wellPair-wise distancesmin distancePlace dining tables & ceiling lights far from wallsPair-wise angle differenceangle alignmentAlign tables to parallel to the nearest wallSymmetry around an objectrotational asymmetryChairs should be rotationally symmetric when placed around circular tablesSymmetry across a planereflection asymmetryBed-side tables should be symmetric on either side of a bedObjects facing other objectsfocus scoreSofas should face TVs or paintingsObject accessibilityaccessibility costLeave space in front of sofas / appliancesEmpty space on a surfacefreespace 2dLeave some space leftover in room / on countertop Arbitrary arithmetic / nonlinearities+ - * / pow hingeEncourage certain ratio of ceiling-lights to room-areaBoolean comparisons / logic== < <= and in rangeEnsure there are 2 to 6 chairs for every table",
  "every object must satisfy a predicateallEvery bookcase must have 10 bookssum/mean across specific objectsmean sumCompute average distance to wall over many objects, rather than minimum": ". Capabilities included in our API. Please see Sec. B and C for example programs, and surrounding text for full descriptions. For ourAPI, functions can be composed arbitrarily, e.g. scene.with semantics(...).related to(...).count().hinge(...) to create anonlinear objective w.r.t. number of objects in a certain context. Bipartite Matching: A cost-minimizing bipartite match-ing is performed between the set of original objects {Oi}and their reflected counterparts {Oi} to find the opti-mal pairings based on a cost matrix derived from posi-tional and angular deviations. We use a modified Jonker-Volgenant algorithm for this step .",
  "+ i Ddev(Oi)/": "This reflection score is useful in contexts such as encour-aging chairs to be symmetric around a long rectangular table,or encouraging furniture to have mirror symmetry for visualappeal, or encouraging paintings to be symmetrical acrossthe room. accessibility costcomputes how much a set of ob-jects B block access to a set of objects A. We offer twoversions. In the fast version, the function selects the closestobject in B to each object in A based on the centroid distance.In the slow version, it finds the closest point on any mesh inB to each mesh in A. The mathematical formulation can bedescribed as follows:We first take the projection of as centroid onto its specifiedplane (frontal plane by default) by",
  "bclosest pt aproj2 b(a)d": "where b(a)d is the diagonal vector of the bounding box ofthe chosen object b(a). We note that the accessibility costincreases as the blocking object gets larger, as the blockingobjects get closer, and as the blocking object is more in frontof the specified plane.An example usage of accessibility cost is when we wantto penalize objects being directly in front of TVs, paintings,or closets.",
  "||bc ac||": "where na is the front facing normal of object a. The vectorsac,bc denote the centroids of a and b respectively. Thecontribution of each object is in the range.An example use case of focus score is focusing the sofason the TV to encourage a more realistic layout. Anotherexample use case is focusing a set of seats on a round table.",
  "bB(proj(b))": "where proj is the projection to the XY plane and gives thearea of a 2D shape. An example use case is minimizing thefree space on a table to encourage placing more objects onthe table, or maximizing the free space in a living room tomake it less cluttered. Arithmetic / non-linearitiesprovide basic scalar arith-metic and an implementation of the standard hinge loss func-tion, all computed using the standard Python definitions.The exact set of mathematical operators provided here is notcritical; our system treats scalar losses as a black box, so anyarbitrary Python math expressions are acceptable. Boolean comparisonsallow equality or inequality check-ing between values, usually for creating hard constraintson cardinalities or distances. When used to check the sizeof a set, our system will use the constraint statement to in-form what Addition moves are proposed as explained inCardinality Bounding. allprovides control flow logic akin to the forall sym-bol as used in formal proofs. It is commonly used in con-structing soft/hard constraints. We avoid allowing arbitraryPython control flow (for loops, if statements, etc.) as it makes symbolic reasoning difficult by restricting the userto symbolic expressions. This design decision is similar toother compute graph programming frameworks (e.g. Tensor-flow , CVXPY ). For example, by forcing the userto use a symbolic all statement rather than a for loop, wecan make inferences such as if all chairs go near tables,and there must be at least one chair, then there must be atleast one table, which allows the user to write higher leveland fewer constraints, with the system deducing all logicalconsequences. Forall statements take as input a loop variable name, anda constraint program that contains the loop variable as a leafnode at one or more locations. During execution, the childconstraint program is substituted with the real values of theloop variable and evaluated to obtain the various results.",
  "Please inspect and for an extended randomsample of our main residential home generator (as shown in)": "These images were derived from the constraint code de-signed for residential homes, shown in . This codeuses a total of 105 soft and hard constraints, with 19 fordining rooms, 14 for living rooms, 9 for bathrooms, 18 forkitchens, 16 for warehouses, and 30 which apply abstractlyto all rooms. These constraints are used to cover objectassignments (object A goes on object B), ratios (numbersof chairs per table, objects per shelf), stability (TV placedagainst the wall; objects dont overhang unsupported), dis-tance (plants placed near window), and more.",
  "C. Extension to warehouse scenes": "To show the generality of our solving system, we imple-mented a simple constraint program that uses existing lan-guage features to specify the high-level objectives of a ware-house environment, with furniture on shelves and smalleritems on wooden pallets. See for the full program.Various further extensions are possible, for example indi-cating a preference for larger objects to be placed lower orhigher on the shelves, or certain objects to be placed nearthe front of the warehouse / store. We show example imagesin , as well as a topdown view showing only theshelving and lighting layout. . Constraint program for warehouse scenes. In only a few high-level statements, we specify the hierarchy of allowed objects, andcompeting placement objectives that give rise to an appropriate shelf and object layout for any warehouse scene.",
  "(a) Shelving Arrangement(b) Example Images": ". Warehouse scene arrangement (left) and example first-person images (right). Using only a few high-level objectives, we extendour existing placement system and existing furniture generators to create a hardware-store-like environment. resent a room with a certain type, and each edge representsthe connectedness of two rooms it is linked to. We supportrooms of the following type: kitchen, bedroom, living-room,closet, hallway, bathroom, garage, balcony, dining-room,utility, staircase. hallway can mean any corridor or pas-sage between rooms, and staircase means the room or spacewhere one can find the stairs.The graph is generated by a Probabilistic Context-freeGrammar(PCFG), where the graph first starts off as a singlenode living-room, and gradually appends zero, one or morerooms of certain types to the leaf nodes. The probabilitydistribution that we use is shown in Tab. 6 and Tab. 7.",
  "Room parentRoom childrenProbability": "LivingRoomLivingRoom0.1BedroomCat(0, 0.3, 0.3, 0.3, 1)Closet0.1Bathroom0.4Garage0.4Balcony0.2DiningRoom0.8Utility0.2HallwayCat(0.5, 0.4, 0.1)KitchenGarage0.1Utility0.2BedroomBathroom0.3Closet0.5BathroomCloset0.2DiningRoomKitchen1.0Hallway0.2 . Probability of the number of rooms PCFG produces foreach leaf node in the graph for the ground floor. Such probability isconditioned on the parent room type (Column 1) and the childrenroom type (Column 2). The probability (Column 3) can either be aBernoulli distribution (shown as the sole parameter) or a Categor-ical (Cat) distribution (shown as the probability of the number ofchildren, starting with zero).",
  ". Probability of the number of rooms PCFG produces foreach leaf node in the graph. The annotations are similar to Tab. 6": "Based on the number of floors and the current level, a porch(balcony) or staircase may also be added to the graph. Allroom plans that do not observe bathroom privacy (i.e. abedroom is connected to a bathroom without going throughother bedrooms) or are not planar are rejected. Based on theuser input, floor plans with an incorrect number of designatedrooms are also rejected. By default, we require all floor plangraphs to have at least one living room and one bathroom.",
  "D.2. Floor plan initialization": "Based on the floor plan graph for a specific floor, we firstdeduct an estimated contour area based on the sum of typicalareas of all the rooms on one floor, which can also used toderive the width and length of the contour. To derive thecontour on one floor, we randomly bevel the corners witha rectangular, round, or 45-degree profile that provides thediversity of the contour shape. Contours for floors upstairsare either the exact same copy of the contour on its lowerfloor or a subset of the contour on its lower floor.The spaces are subdivided from the contour followingthe Mondrian Process . For each iteration, we randomlyselect a mostly rectangular space and divide it along oneof its axes, and we repeat such division so that there are1.5 times more blocks than are required in the floor plan graph. All divisions apply by rounding off the division ontoa grid with a size of 0.5, and divisions leading to a badaspect ratio are rejected. We merge the spaces until theresthe same number of spaces as in the floor plan graph, thencompute the adjacency relations of all divided spaces, wherespaces are adjacent if they share an edge of size greater orequal to a threshold (to place doors). We randomly add astaircase placeholder inside the contour for multistory floorplans, which roughly indicates the location of the staircase.The staircase placeholder ensures staircases across adjacentfloors are in the same spatial location.Among these contour divisions, we try to find one wherethe assignment of rooms suffices the floor plan graph viaadjacency relations. In addition to the adjacency relations inthe floor plan graph, we also ensure that all exterior-facingrooms, including the bedroom, garage, and balcony, haveaccess to the houses exterior. Only the divided spaces inter-secting with the staircase placeholder can be assigned to thestaircase room. We can find a proper assignment of roomsthat satisfies the floor plan graph and other constraints viadepth-first search.",
  "The objective function is defined on a floor plan where spacesare assigned to a node in the floor plan graph. The objectiveis composed of twelve constraints detailed as follows:": "Shortest path to entranceconstraint encourages unidi-rectional room access from the entrance. We compute theshortest path from all nodes to the floors entrance, either thefront entrance for the ground floor or the staircase for roomsupstairs. The path is computed in an axis-aligned fashionand can only traverse connected rooms on the floor plangraph. The amount of detour for each path is the percentageof the path in the wrong direction of the Euclidean distancefrom the entrance to that room. The objective function iscomputed as squared detours summed across rooms. DenoteF as the set of all floors, ef is the entrance on floor f, and is the path allowed by the adjacency between rooms:",
  "ef r1 12": "Typical room areaconstraint encourages room of typicalarea so that the spaces serve the best function. A list of thetypical area occupied by rooms is listed in Tab. 8, which isbased on a typical US household. The ideal proportion of aroom is computed as the typical area of that room dividedby the sum of all the rooms typical areas on that floor. Theobjective function is computed by the difference betweena rooms ideal proportion on one floor and the rooms trueproportion on that floor, summed across rooms. For all",
  "rf(w wallsr 4)2": "Functional Room areaconstraint incentivizes the avail-able area useful for dwellings of the people inside the house,characterized by functional rooms. Functional rooms includekitchens, bedrooms, living rooms, bathrooms, and diningrooms. The objective function is computed as the proportionof the area covered by these rooms, measured in squareddistance with one. Denote by R f the set of functional rooms,we have",
  "{y|r f, y the y-coords of a wall in r}": "Narrow passagesconstraint limits the number of passagesin a room (including hallways) where people or furnituremay find it hard to move across. We identify a narrow pas-sage in a room by eroding and then buffering the 2D roomcontour with a certain threshold margin. Narrow passagesinside a room are no longer present in the room contour afterthat erosion-buffer operation. The objective function is mea-sured as the difference between the area of the room contourpre- and post-erosion-buffer operation. An illustration ofthe erosion-buffer operation can be found in . Theformula can be written as",
  "arear areaerosion-buffer(r)": "Exterior length by roomconstraint encourages rooms ofcertain types to cover most of the exterior walls and windowssince people would expect more views of outside in theserooms and more privacy concerns in other rooms. The ex-terior room types include bedrooms and balconies, denotedby Re. The objective function is evaluated using the exteriorlength covered by these rooms divided by the exterior lengthcovered by all rooms on that floor, measured by its squareddistance with one.",
  "While solving for the aforementioned constraints, we needto design a set of moves to perturb the floor plan, which arelisted as follows and illustrated in :": "Extruding a wall segment inwardsrandomly select onewall segment of a room in the current floor plan and move ittowards the inside of the room by one grid size (0.5). Otherrooms sharing part of the wall with the selected wall will fillup the space left by the move. Extruding a wall segment outwardsrandomly select onewall segment of a room in the current floor plan and move ittowards the outside of the room by one grid size (0.5). Otherrooms sharing part of the wall with the selected will give uptheir space to the room. Swapping the assignment for adjacent roomsrandomlyselect one space for a room and its neighbor and swap theirroom assignment.In all of the above moves, we reject moves that lead to afloor plan that does not suffice the floor plan graph on thatfloor. We also reject moves that lead to invalid geometry, in-cluding degenerate, disconnected, or out-of-boundary rooms,and those that fail to satisfy the constraints on exterior roomsand staircase placeholders. One may think of satisfying floorplan graphs as a hard constraint. Moving staircase.We also provide an additional movefor the staircase placeholder. The staircase placeholder canmove along one of the axes by one grid size.At each iteration of the simulated annealing, we firstselect one of the floors to operate on or choose to move thestaircase placeholder. Then, we randomly choose one ofthe three moves to apply. A move is rejected if it no longersatisfies the hard constraint given by the floor plan graph orrejected by the simulated annealing probability computedusing the change in the objective function.",
  "c)d)": ". All floor plan optimization moves. a) The originalfloor plan, with each color showing the assignment of each room(e.g. blue for living-room 0, orange for bedroom 0, and green forbedroom 1; b) floor plan after extruding rightmost wall segment ofthe blue room inwards; c) floor plan after extruding rightmost wallsegment of the blue room outwards; d) floor plan after swappingthe assignment for the green and the blue room. Placement of doors and windows.For pairs of roomsthat share an edge in the floor plan, they must share a wallsegment with its length over a certain threshold. We then cutthe shape of the door from both room meshes and place thedoor in that space. Doors can be opened towards the inside ofthe house or away from the houses entrance for ergonomics.For other pairs of rooms designated by the user, i.e., betweendining rooms and living rooms, one may choose to removeall the walls in between and place no doors. For rooms facingthe exterior of the house, if they can have windows installed,we selectively cut off the shape of the window from the roommeshes with a limit on the maximal width of the window.Then, we place windows in these shapes. Landscapes areplaced outside the window. Adding materials to floors, ceilings, and walls.The wallsof rooms are applied with the following materials condi-tioned on the room type: (ceramic) square tile, concrete,brick, or plaster. The floors of rooms are applied with the fol-lowing materials conditioned on the room type: tiled woodfloors, square or hexagonal, alternating or non-alternatingtiles, rug or concrete. The ceilings of rooms are paintedwith plaster. Materials are sometimes shared across differentrooms. Adding staircases.We compute the intersection of thespace assigned as staircase rooms on consecutive floors. Ourconstraint solver will make sure that the intersection is atleast the size of the staircase placeholder, which is non-empty.We randomly sample one staircase per floor (excluding thetopmost one) and position them inside their correspondingstaircase rooms. We reject samples where the staircase andthe room in front of the steps fall outside the room or whenthe consecutive staircase intersects. We cut off the shape ofthe stairs from the room meshes and add guard rails aroundthe stairs.",
  "E.1. Greedy Solving Algorithm": "Optimizing over all rooms and all objects at the same timeis unfeasible due to the magnitude of the state space. As aresult, we use a greedy algorithm to first solve the floor plan,then solve large, medium, and small objects, respectively. Ateach stage we solve each room separately. A very high-levelpseudocode of our solver algorithm is given as Algorithm 1.This algorithm is not optimal in any sense, but the problem athand is computationally intractable, and an optimal solutionis not required to obtain aesthetically pleasing scenes. Weprovide this solver to prove our language can be optimizedefficiently, and to serve as a baseline for future improvementsor follow-up work.",
  "E.2. Move Utilities": "Cardinality BoundingOur solver starts with an emptyscene, and must add objects during optimization to satisfyobject-quantity constraints and objectives given by the user.We implement this via the Addition and Deletion moves de-scribed below, which add or remove one object. Choosing topropose a random object type with a random set of relationswould have a vanishingly small likelihood of producing amove that obeys the given constraints - typically only a fewobject types and a few relation assignments (against wall, onfloor, etc) are actually valid.To optimize efficiently, we implemented a recursive pro-cedure to traverse through the constraint graph and find every relevant context (such as on top of bookcase or againstlivingroom wall) available in the current scene state, re-trieve any lower/upper bounds on object counts to be placedinto these contexts. For example, if there are two shelvesin the current state, and the user has specified each shelfshall have between 1 and 5 books placed on it, our procedurewould return 2 bounds, one for each shelf, with 1 and 5 asthe lower and upper bounds on object count.These bounds are sensitive to the scenes current state: ifthe user specifies there should be more chairs in the diningroom than tables in the dining room, then the current numberof chairs will be used as an upper bound for the numberof tables and vice versa. This allows optimization of arbi-trary inequalities between object counts, since by randomlyperforming valid additions and deletions, the optimizer willexplore the full space of discrete object counts for everypossible context. Degree Of Freedom ComputationMoving objects in thefull 6D pose space is completely unfeasible because of theplane assignments hard constraints that need to be satisfied.Enforcing these constraints by minimum distance scoresand considering movement only on the XY plane is anotheroption, but this still causes a violation of the hard constraintsand is also wasteful as an optimizer state-space. Therefore,we calculate the degrees of freedom of each object and onlymove objects along the allowed subspace (e.g. painting onlymoves on the wall it is assigned to).For each object, we first obtain the planes that the objectis constrained to move on. We then compute two types ofDOFs. The translation DOFs are computed as the matrixof projection onto the intersection subspace of the planes.If the constraints are contradictory, this will be the zeromatrix. The rotation DOF is either the free axis of rotationaround which the object is allowed to rotate, or none if theconstraints do not allow rotational movement. Resolving Discrete Move PosesThe optimizer needs toinitialize every object that is added to the scene beforeproposing any moves to it. This initialization must obeythe plane assignment hard constraints, so that the subsequentcontinuous moves also obey the hard constraints. Thus,we initialize objects by essentially sampling a random posi-tion on the subspace defined by the plane assignments andsampling a random rotation that is a multiple of /2. Theposition sampling is done by sampling a random position onthe first plane, and then repeatedly snapping the object to itsassigned planes with the specified margin. The validity ofthe initialization is checked after each attempt, and if eachinitialization attempt is unsuccessful for a certain number ofattempts (20 by default), the initialization is unsuccessful,and the move is reverted.",
  "u)v)w)x)y)z)": ". Variation in a chair asset with tuneable parameters. a) A base chair for comparison, followed by chairs with b) larger depth; c)thinner seats; d) wider backs; e) more curvature in seats; f) extrusion in front; g) longer legs; h) larger backs; i)-k) tilted / outward-bending /inward-bending legs; l), m) no leg bars along both axes; n) no arms; o)-p) arms with different attachments to the seat and back; q)-t) backspartially covered/supported by horizontal or vertical bars; u)-v) different leg material (woven fabric/wood); w-x) different seat material(leather/fabric); y)-z) different placement of blankets. Reversing MovesNot every proposed move is a validmove. For instance, translating a painting too much mightcause it to overhang, or reassigning a sofa to another wallmight make it intersect with another object in the scene. Asa result, after we apply any move, we check its validity. Thisis done by checking that the chosen object does not collidewith any other mesh, and that all the relation constraintsof the object are satisfied. If the move is not valid, thenwe reverse the move to remove its effects. For instance, ifthe object was moved by a rotation or translation, and theresulting state is not valid, we restore the backup pose of theobject. If the move was an addition, we remove the object,and so on.",
  "E.3. Move Implementations": "AdditionTo perform an addition, we extract all availablecardinality bounds from the current. Then, we discard allbounds that are tight above, i.e., those for which adding anobject would violate an upper bound.The most challenging stage of addition is finding asatisfying assignment for relevant constraints.If theuserspecifiedscene[Seating].related to(room,on floor).related to(room, against wall).count() > 0,thenweknowwemust add some kind of seating that is against both the floorand wall. However, many options exist: Seating could meaneither an armchair or a sofa, there are many possible floorsto place the seating onto, and many possible wall planesattached to each floor plane. Moreover, any choice for thesevariables could activate additional constraints; for example,the user may have written a rule that applies to all sofas inthe scene, or all objects in a particular room, so if we choosefor our seating object to be a sofa, or if we choose to put itin that particular room, then additional constraints may beadded to the list yet to be satisfied.This relation assignment problem is related to classicSAT solving, except for that making an assignment can addadditional terms to the equation. Alternatively, it is an SATproblem where the full equation to be satisfied is deceptivelylong due to new constraints being activated. We anticipatethat future versions of our solver can directly incorporateclassic SAT-solving approaches. However, for our currentconstraint programs, we have found it is sufficient to performexponential search over all options, visiting each childnode in the search tree in a random order to ensure unbiasedresults. This approach is exponential in the number of se-",
  ". Additional qualitative results on synthetic scenes": "mantic and relationship constraints involved, but fortunately,these rarely number more than 3 or 4 (IE, 1-2 semanticclasses ), and the branching factor tends to be small (IE, rel-atively few different specific object options, or few differentwall planes to assign to).For each valid assignment found, we procedurally gener-ate a placeholder asset and attempt to fit it into the scene asdescribed in Resolving Discrete Moves as described above.Placeholders are special versions of our 3D assets providedby each procedural generator which have mostly planar sur-faces and lower polygon count. E.g. the placeholder for achair would still have properly shaped legs, seat and back-rest, but would not have any bevels, chamfers, nails/screwsor fine geometric details. This lower polygon representationspeeds up collision checking, and eliminates the need forus to heuristically detect flat planes on the object, since theasset author provides these procedurally.",
  "DeletionDeletion uses the same cardinality bound logicas addition, but chooses a random object cardinality bound": "that is not tight below, and proposes to delete it to see ifthe score is reduced. Typically, these moves do not help theimmediate score, as we incentivize placing as many objectsas possible, but they can help to eliminate particularly poorlyplaced objects or to avoid local optima in object counts. ResampleResamples primary function is to replace an ex-isting object in the scene with an object of the same class butwith new parameters. This often causes a change in shape,e.g. the length/width of a table will change, or the number ofcells in a shelf may increase. Changing these parameters isdesirable as it may increase/decrease the objective function(e.g. if a volume() or min distance) is changed as a result).To place the new object in the scene, we try aligning each ofthe bottom corners of the new bounding box with that of theold object, and check each pose for collisions, which allowsthe object to grow/shrink strictly to the left or right if it isattached to a wall. We assume relation assignments from theold object remain valid, since regenerating an object withnew parameters does not change its semantics.",
  ". Additional qualitative zero-shot results on SRD testdataset": "TranslateLet P be the projection matrix computed as thetranslational degree of freedom for the chosen object. Wesample x R3 where xi N(0, 2) for i = 1, 2, 3, and thevariance 2 is proportional to the temperature. The object isthen translated by Px. This makes the object take a randomstep along the subspace on which it is constrained. RotateLet e be the axis of rotation computed as the rota-tional degree of freedom for the chosen object. We sample N(0, 2) where the variance 2 is proportional to thetemperature. The object is then rotated by around the axise. This makes the object take a small random rotation on thesubspace on which it is constrained. ReinitPosereinitializes the 6DOF pose of the object byresolving the discrete move poses again. Since the objectrelations are the same, the effect is essentially samplinga random position and orientation on the same constraintsubspace. This move is useful for getting a good layout inthe early stages of optimization and the cases in which anobject is stuck in a sub-optimal position. ReassignPlane. As explained in Addition, if the user spec-ifies an object to be placed against one or more surface(s),then multiple options usually exist for which surfaces to use.This move simply attempts to swap the object to a differentplane, e.g. move a sofa to a different wall, or a bottle to adifferent row of a shelf. ReassignTargetSimilarly, multiple options often exist forwhich object an object is a child of in the scene graph, e.g. aplant pot could rest on one of many different shelves/tablesin a room. This move swaps the object to be a child of someother object in the scene that satisfies the same constraintsas its current assignment.",
  "F.1. Asset Coverage and Variation": "We provide 79 randomized procedural object generators. Bycategory, we cover Appliances (10 generators, 112 params),Windows/Doors/Staircases (14 generators, 127 params), Fur-niture (17 generators, 216 params), Decorations (15 gener-ators, 92 params), and Small Objects (19 generators, 194params). We provide 30 material generators, 120 paramstotal, split approximately evenly between types of wood,ceramic, fabric, metal and others. Materials are assigned toobjects via customizable weighted lists, e.g. spatulas invokeeither wood, plastic or metal generators for each of theirends. Following Infinigen, we report procedural parametercount as a proxy of complexity; each parameter is a randombut controllable degree of freedom e.g number of seats ona sofa. In all, we provide 40k lines of code, of which 25kare object/material generators. For asset coverage, an incom-plete list of the assets we cover is listed in Tab. 10. For assetvariations, an illustration of the variation of assets is shownin .",
  "G.1. Shadow Removal": "We use the model implementation from s codebase totrain the two variants of the model: R (trained on real datasetonly) and R+S (trained on real and synthetic datasets). Sincethe codebase lacked a validation set, we developed our own,comprising all image pairs across four scenes from the ISTDtraining dataset. Additionally, in contrast to the providedimplementation, we used an L1 loss as stated in the paper.We trained the two variants for 30k steps each, including a 30-epoch linear warmup phase, using AdamW optimizerwith default hyperparameters and a learning rate of 2e 4.We chose the runs to have an effective batch size of 32 (byaccumulating gradients for 4 steps and using the actual batchsize to be 8). The training process utilized four Nvidia 3090 GPUs, with Mixed-16 precision. shows additionalqualitative results.We opted not to use the pre-trained model from the code-base, as our attempts to reproduce the results were unsuccess-ful. Nevertheless, to ensure a fair comparison, we adheredto the same implementation details for both variants. Addi-tionally, we chose not to report SSIM (Structural SimilarityIndex Measure), since both models demonstrated equivalentperformance, with no significant difference observed whenrounding to two decimal places, for this metric.",
  "G.2. Occlusion Boundaries": "We separately train three U-Net models from scratchon images generated from Infinigen Indoors, Infinigen and Hypersim . We apply random {cropping, brightnesscontrast} and color jittering with probability 0.6. We also usethe RMSprop optimizer with a base learning rate of 105, amomentum of 0.99 and a weight decay of 108. Each modelis trained for 10 epochs using binary cross-entropy loss.Due to the absence of ground truth occlusion boundariesin Hypersim (or any other photorealistic dataset), we ap-proximate them by thresholding the gradient of the provideddepth maps. We carefully tuned this threshold on Hypersimto give the best results.We compare the performance of the U-Net models on acurated test set of photo-realistic artist-designed synthetic3D scenes for architecture visualization . We extract theground truth occlusion boundaries of these scenes using thetools provided in Infinigen. Additional qualitative resultsshown in underscore our claim that the InfinigenIndoors - trained model generalizes better.",
  "H. Perceptual Study": "Following ATISS , we conducted a perceptual studyon Amazon Mechanical Turk to evaluate the realism of thegenerated scenes and the realism of the generated layouts.We compared Infinigen Indoors to ProcTHOR , ATISS, SceneFormer , and FastSynth . We presentedthe subjects pairs of images from each method (for instanceInfinigen vs ProcThor) to evaluate overall realism and layoutrealism. For mean error frequency, we asked the subjects ifthe image from a method contained any obvious errors suchas flying furniture, overlapping furniture, etc. For layout real-ism, we asked the subjects to focus only on the arrangement of the furniture and ignore the style of individual objects. shows that the subjects preferred Infinigen Indoorsover all methods in terms of both realism, layout realism,and the lack of obvious errors. An important caveat is thatrealism may be influenced by asset and lighting quality."
}