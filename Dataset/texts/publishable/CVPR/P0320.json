{
  "Abstract": "Recent studies have noted an intriguing phenomenontermed Neural Collapse, that is, when the neural networksestablish the right correlation between feature spaces andthe training targets, their last-layer features, together withthe classifier weights, will collapse into a stable and sym-metric structure.In this paper, we extend the investiga-tion of Neural Collapse to the biased datasets with im-balanced attributes.We observe that models will easilyfall into the pitfall of shortcut learning and form a biased,non-collapsed feature space at the early period of train-ing, which is hard to reverse and limits the generalizationcapability. To tackle the root cause of biased classifica-tion, we follow the recent inspiration of prime training, andpropose an avoid-shortcut learning framework without ad-ditional training complexity. With well-designed shortcutprimes based on Neural Collapse structure, the models areencouraged to skip the pursuit of simple shortcuts and nat-urally capture the intrinsic correlations. Experimental re-sults demonstrate that our method induces better conver-gence properties during training, and achieves state-of-the-art generalization performance on both synthetic and real-world biased datasets.",
  ". Introduction": "When the input-output correlation learned by a neuralnetwork is consistent with its training target, the last-layerfeatures and classifier weights will attract and reinforceeach other, forming a stable, symmetric and robust struc-ture. Just as the Neural Collapse phenomenon discoveredby Papyan et al. , at the terminal phase of training onbalanced datasets, a model will witness its last-layer fea-tures of the same class converge towards the class centers,and the classifier weights align to these class centers cor-respondingly. The convergence will ultimately lead to thecollapse of feature space into a simplex equiangular tight",
  "Corresponding Author": ". Illustration of (a) Neural Collapse phenomenon on bal-anced datasets, where the simplex ETF structure maximizes theclass-wise angles, and (b) Biased classification on datasets withimbalanced attributes, where the model takes the shortcut of at-tributes to make predictions and fails to collapse into the simplexETF. The color of points represents different class labels and theshape of points represents different attributes. frame (ETF) structure, as illustrated in (a). The el-egant structure has demonstrated its efficacy in enhancingthe generalization, robustness, and interpretability of thetrained models . Therefore, a wave of empirical andtheoretical analysis of Neural Collapse has been proposed, and a series of studies have adoptedthe simplex ETF as the optimal geometric structure of theclassifier, to guide the maximized class-wise separation inclass-imbalanced training .However, in practical visual recognition tasks, besidesthe challenge of inter-class imbalance, we also encounterintra-class imbalance, where the majority of samples aredominated by the bias attributes (e.g., some misleading con-tents such as background, color, texture, etc.). For exam-ple, the widely used LFW dataset for facial recogni-tion has been demonstrated severely imbalanced in gender,age and ethnicity . A biased dataset often contains amajority of bias-aligned samples and a minority of bias-conflicting ones. The prevalent bias-aligned samples ex-hibit a strong correlation between the ground-truth labels",
  "arXiv:2405.05587v1 [cs.CV] 9 May 2024": "and bias attributes, while the scarce bias-conflicting sam-ples have no such correlation. Once a model relies on thesimple but spurious shortcut of bias attributes for predic-tion, it will ignore the intrinsic relations and struggle togeneralize on out-of-distribution test samples. The poten-tial impact of biased classification may range from politi-cal and economic disparities to social inequalities within AIsystems, as emphasized in EDRis latest report .Therefore, the fundamental solution to biased classifica-tion lies in deferring, or ideally, preventing the learning ofshortcut correlations. However, previous debiased learn-ing methods rely heavily on additional training expenses.For example, a bias-amplified auxiliary model is oftenadopted to identify and up-weight the bias-conflicting sam-ples , or employed to guide the input-level andfeature-level augmentations . Some disentangle-based debiasing methods, from the perspective of causal in-tervention or Information Bottleneck theory ,also require large amounts of contrastive samples or pre-training process to disentangle the biased features, signifi-cantly increasing the burden of debiased learning.In this paper, we extend the investigation of NeuralCollapse to the biased visual datasets with imbalanced at-tributes. Through the lens of Neural Collapse, we observethat models prioritize the period of shortcut learning, andquickly form the biased feature space based on mislead-ing attributes at the early stage of training. After the bias-aligned samples reach zero training error, the intrinsic cor-relation within bias-conflicting samples will then be discov-ered. However, due to i) the scarcity of bias-conflictingsamples and ii) the stability of the established feature space,the learned shortcut correlation is challenging to reverse andeliminate. The mismatch between bias feature space and thetraining target induces inferior generalizability, and hindersthe convergence of Neural Collapse, as shown in (b).To achieve efficient model debiasing, we follow the in-spiration of prime training, and encourage the model to skipthe active learning of shortcut correlations. The primes areoften provided as additional supervisory signals to redirectthe models reliance on shortcuts, which helps improve gen-eralization in image classification and CARLA autonomousdriving .To rectify models attention on the intrin-sic correlations, we define the primes with a training-freesimplex ETF structure, which approximates the optimalshortcut features and guides the model to pursue unbiasedclassification from the beginning of training. Our method isfree of auxiliary models or additional optimization of primefeatures. Experimental results also substantiate its state-of-the-art debiasing performance on both synthetic and real-world biased datasets.Our contributions are summarized as follows:",
  ". Related Works": "Debiased Learning.Extensive efforts have been dedi-cated to model debiasing, but they are significantly limitedby additional training costs. Recent advances can be di-vided into three categories: reweight-based, augmentation-based, and disentangle-based. Based on the easy-to-learnheuristic of biased features, reweight-based approaches re-quire pre-trained bias-amplified models to identify and em-phasize the bias-conflicting training samples .Augmentation-based approaches, with the guidance of ex-plicit bias annotations, conduct image-level and feature-level augmentations to enhance the diversity of trainingdatasets . Other disentangle-based approachesattempt to remove the bias-related part of features, from theperspective of Information Bottleneck theory or causalintervention , but at the cost of substantial con-trastive samples. Additionally, model debiasing is also wellstudied in graph neural networks , language models and multi-modal tasks .Neural Collapse. Discovered by Papyan et al. , theNeural Collapse phenomenon reveals the convergence ofthe last-layer feature space to an elegant geometry. At theterminal phase of training on balanced datasets, the fea-ture centers and classifier weights will collapse togetherinto the structure of a simplex ETF, which is illustrated in.1. Recent works have dug deeper into the phe-nomenon and provided theoretical supports under differentconstraints or regularizations , as well as empir-ical studies of intermediate features and transfer learning. Considering the class-imbalanced datasets,Fang et al. point out the Minority Collapse phenomenon,where features of long-tailed classes will merge togetherand be hard to classify. As a remedy, they fix the classi-fier as an ETF structure during training, which guaranteesthe optimal geometric property in imbalanced learning ,semantic segmentation , and federated learning . Totake a step further, our work fills the gap of Neural Collapseanalysis on biased datasets with shortcut correlations.Avoid-shortcut Learning. The recent inspiration of avoid-shortcut learning aims to postpone, or even prevent thelearning of shortcut relations in model training. With well- crafted contrastive samples or artificial shortcutsignals , avoid-shortcut learning has demonstratedits efficacy in image classification, autonomous driving andquestion answering models. One of the representative meth-ods is named prime training, which provides richer super-visory signals of key input features (i.e., primes) to guidethe establishment of correct correlations, therefore improv-ing generalization on OOD samples . In this work, weleverage the approximated optimal shortcuts as primes toencourage the models to bypass shortcut learning.",
  ". Neural Collapse Phenomenon": "Consider a biased dataset D with K classes of trainingsamples, we denote xk,i as the i-th sample of the k-th classand zk,i Rd as its corresponding last-layer feature. Alinear classifier with weights W = [w1, ..., wK] RdK is trained upon the last-layer features to make predictions.The Neural Collapse (NC) phenomenon discovered that,when neural networks are trained on balanced datasets, thecorrectly learned correlations will naturally lead to the con-vergence of feature spaces. Given enough training steps af-ter the zero classification error, the last-layer features andclassifier weights will collapse to the vertices of a simplexequiangular tight frame (ETF), which is defined as below.Definition 1 (Simplex Equiangular Tight Frame) A col-lection of vectors mk Rd, k = 1, 2, ..., K, d K 1 issaid to be a k-simplex equiangular tight frame if:",
  "K 1K1TK)(1)": "where M = [m1, ..., mK] RdK, and P RdK isan orthogonal matrix which satisfies PTP = IK, with IKdenotes the identity matrix and 1K denotes the all-ones vec-tor. Within the ETF structure, all vectors have the maximalpair-wise angle of 1 K1, namely the maximal equiangularseparation.Besides the convergence to simplex ETF structure, theNeural Collapse phenomenon could be concluded as the fol-lowing properties during the terminal phase of training:NC1: Variability collapse. The last-layer features zk,i ofthe same class k will collapse to their class means zk =Avgi{zk,i}, and the within-class variation of the last-layerfeatures will approach 0.NC2: Convergence to simplex ETF. The normalized classmeans will collapse to the vertices of a simplex ETF.We denote the global mean of all last-layer features aszG = Avgi,k{zk,i}, k [1, ..., K] and the normalized classmeans as zk = (zk zG)/zk zG, which satisfies Eq.1.NC3: Self duality. The classifier weights wk will alignwith the corresponding normalized class means zk, whichsatisfies zk = wk/||wk||. NC4: Simplification to nearest class center. After conver-gence, the models prediction will collapse to simply choos-ing the nearest class mean to the input feature (in standardEuclidean distance). The prediction of z could be denotedas arg maxkz, wk = arg mink ||z zk||.",
  ". Neural Collapse Observation on Biased Dataset": "Besides the findings on balanced datasets, some studieshave explored Neural Collapse under the class-imbalancedsituation . Taking a step further, we investigate thephenomenon on biased datasets with imbalanced attributes,to advance the understanding of biased classification. Toexamine the convergence of last-layer features and classifierweights, we compare the metrics of Neural Collapse on bothunbiased and synthetic biased datasets. As shown in ,we report the result of NC1-NC3, which corresponds to thefirst three convergence properties in .1 and respec-tively evaluates the convergence of same-class features, thestructure of feature space and self-duality. The details ofNC metrics are concluded in Tab. 1.When trained on unbiased datasets (black lines in Fig. 2), the model displays the expected convergence properties,with metrics NC1-NC3 all converge to zero. We owe the el-egant collapse phenomenon to the right correlation betweenthe feature space and training objective, which is also sup-ported by the analysis of benign global landscapes .However, when trained on biased datasets, the trainingprocess exhibits two stages: first the shortcut learning pe-riod and then the intrinsic learning period, as divided by thevertical dashed line. During the shortcut learning period,the accuracy of bias-aligned samples increases quickly, andthe NC1-NC3 metrics show a rapid decline (green lineswith in ). It indicates that when simple shortcutsexist in the training distribution, the model will quickly es-tablish its feature space based on the bias attributes, and ex-hibit a converging trend towards the simplex ETF structure.After the bias-aligned samples approach zero error, themodel turns to the period of intrinsic learning, which fo-cuses on the intrinsic correlations within bias-conflictingsamples to further reduce the empirical loss. However, al-though their final loss reduces to zero, the bias-conflictingsamples still display low accuracy and poor convergenceresults (green lines with ).It implies that the intrin-sic learning period merely induces the over-fitting of bias-conflicting samples and does not benefit in generalization.We attribute the failure of collapse to the early establish-ment of shortcut correlations.Once the biased featurespace is established based on misleading attributes, recti-fying it becomes challenging, particularly with scarce bias-conflicting samples. In the subsequent training steps, themisled features of bias-conflicting samples will hinder theconvergence of same-class features, thereby halting the con-verging trend towards the simplex ETF structure and lead- . Comparison of (a) testset accuracy and (b-d) Neural Collapse metrics on unbiased (CIFAR-10) and synthetic biased (CorruptedCIFAR-10 with the bias ratio of 5.0%) datasets. All vanilla models are trained with standard cross-entropy loss for 500 epochs. The postfix-Aligned and -Conflicting indicate the results of bias-aligned and bias-conflicting samples respectively. The NC1 metric evaluates theconvergence of same-class features, NC2 evaluates the difference between the feature space and a simplex ETF, and NC3 measures theduality between feature centers and classifier weights. The vertical dashed line at the epoch of 60 divides two stages of training.",
  ". Motivation": "Following the previous analysis, we highlight the im-portance of redirecting the models emphasis from simpleshortcuts to intrinsic relations. Since the models can be eas-ily misled by shortcuts in the training distribution, is it fea-sible to supply a perfectly learned shortcut feature, to de-ceive the models into skipping the active learning of short-cuts, and directly focusing on the intrinsic correlations?We observe in that the NC1-NC3 metrics showa rapid decrease during shortcut learning, but remain stablein the subsequent training epochs. However, if the train-ing distribution does follow the shortcut correlation (withno obstacle from bias-conflicting samples), the convergencewill end up with the optimal structure of simplex ETF, justas the results on unbiased datasets. This inspires us to ap-proximate the perfectly learned shortcut features with asimplex ETF structure, which requires no additional train-ing and represents the optimal geometry of feature space. Therefore, following the outstanding performance ofprime training in OOD generalization , we introduce theapproximated perfect shortcuts as the primes for debiasedlearning. The provided shortcut primes are constructed witha training-free simplex ETF structure, which encourages themodels to directly capture the intrinsic correlations, there-fore exhibit superior generalizability and convergence prop-erties in our experiments.",
  ". Avoid-shortcut Learning with Neural Collapse": "Building upon our motivation of avoid-shortcut learn-ing, the illustration of the proposed ETF-Debias is shownin . The debiased learning framework can be di-vided into three stages: prime construction, prime train-ing, and unbiased classification. Firstly, a prime ETF willbe constructed to approximate the perfect shortcut fea-tures. Then during the prime training, the model will beguided to directly capture the intrinsic correlations with theprime training and the prime reinforcement regularization.In evaluation, we rely on the intrinsic correlations to per-form unbiased classification. The details are as follows.Prime construction. When constructing the prime ETF,we first randomly initialize a simplex ETF as M RdB,which satisfies the definition in Eq. 1. The dimension d isthe same as the learnable features, and the number of vec-tors in M is determined by the categories of bias attributesbi {1, ..., B}, which are pre-defined in the training dis- . The illustration of our method. We take the class climbing from BAR as an example, which contains samples of humanclimbing but with the bias attribute of different backgrounds (as indicated with the color of image frames). The framework contains: 1)Prime Construction: Before training, a randomly initialized ETF structure is constructed as the shortcut primes, and 2) During PrimeTraining, the prime features mb are retrieved based on the bias attribute b of the input samples, to guide the optimization of learnablefeatures z towards the intrinsic correlations. The classifier F will take both the learnable features and fixed prime features to make predic-tions. 3) In Unbiased Classification, the prime features are assigned as null vectors to evaluate the debiased model on test distributions. tribution.After initialization, the vertices of prime ETF[m1, ..., mB] are considered as the approximation of theperfect shortcut features for each attribute, which serveas the prime features for avoid-shortcut training. Duringtraining, the prime features will be retrieved based on thebias attribute b of each input sample.Prime training. During the prime training, we take theend-to-end model architecture with a backbone E and aclassifier F. For the i-th input xi,b with the bias attributeof b, we first extract its learnable feature zi,b = E(xi,b)with the backbone model, and retrieve its prime feature mbbased on the bias attribute b. The classifier F will takeboth the learnable feature zi,b and the prime feature mb tomake softmaxed predictions y = F(zi,b, mb). The stan-dard classification objective is defined as:",
  "i=1L(F(zi,b, mb), yi,b)(2)": "where y is the ground-truth label. In our implementation,we use the standard cross-entropy loss as L, and concate-nate the prime features after the learnable features to per-form predictions.In essence, we provide a pre-defined prime feature foreach training sample based on its bias attribute. The primefeatures, with a strong correlation with the bias attributes,can be viewed as the optimal solution to shortcut learning.By leveraging the already perfect representation of short-cut correlations, the model will be forced to explore theintrinsic correlations within the training distribution. Theprime-guided mechanism targets at the fundamental issue of biased classification, without inducing extra training costs.Prime reinforcement regularization. Given the prime fea-tures, the model is encouraged to grasp the intrinsic correla-tion of the training distributions. However, we raise anotherpotential risk that, despite the provided perfectly learnedshortcut features, the model may still pursue the easy-to-follow shortcuts, leading to the redundancy between thelearnable feature zi,b and the fixed mb. We point out thatthe model may not establish a strong correlation betweenthe prime features and the bias attributes, and continues tooptimize the learnable features for the missing connections.Therefore, we introduce a prime reinforcement regular-ization mechanism to enhance the models dependency onprime features. We encourage the model to classify the biasattributes with only the prime features, and the regulariza-tion loss is defined as:",
  "LRE(x, b) = Ni=1 L(F(zi,b, mb) F(zi,b, mnull), b) (3)": "where mnull is implemented as all-zero vectors with thesame dimension as mb, and L is the standard cross-entropyloss. In the ablation studies in .3, we observe animproved generalization capability across test distributions,as the result of the strengthened reliance on prime features.Regarding the entire framework, we define the overall train-ing objective as:",
  ". Theoretical Justification": "Based on the analysis of Neural Collapse from the per-spective of gradients , we provide a brief theoreticaljustification for our method.With the priming mechanism, we denote the i-th featureof the k-th class as zk,i = [zk,i, mi,b] R2d, whichrepresents the concatenation of learnable feature zk,i andprime feature mi,b based on its bias attribute b. To keepthe same form, we also denote the classifier weights aswk = [wk, ak] R2d, where wk represents the weightfor intrinsic correlations and ak represents the one for short-cut correlations. We observe that, due to the fixed primefeatures during training, ak will quickly collapse to the bias-correlated prime features of class k, and can be viewed asconstant after just a few steps of training. With the defini-tion, the cross-entropy (CE) loss can be written as:",
  "(8)": "In Eq. 6, the gradient w.r.t classifier weights are dividedinto two parts. The pulling part is composed of featuresfrom the same class that pulls wk towards the direction ofthe k-th feature cluster, while the forcing part contains thefeatures of other classes and pushes wk away from theirclusters. The weight factor of each feature zk,i represents its influence on the optimization of wk, which implicitlyplays the role of re-weighting in our method.We assume that class k is strongly correlated with biasattribute b. As the weight ak is observed to collapse quicklyto the bias-correlated prime feature mb, the probabilityp(b)k exp(mTb ak) of bias-aligned samples (with primefeatures mb) are much greater than that of bias-conflictingsamples (with prime features mb). Thus, with the weightfactors in Eq. 6, the pulling and forcing effects of bias-aligned samples will be relatively down-weighted, and theimpact of bias-conflicting samples will be up-weighted.The re-weighting mechanism of gradient mitigates the ten-dency of pulling wk towards the center of bias-aligned sam-ples, which alleviates the misdirection of bias attributes.Gradient w.r.t features. Similarly, we compute the gradi-ent of LCE w.r.t the feature zk,i:",
  "(9)": "In the gradient w.r.t features, the pulling part directs thefeature zk,i towards the weight of its class wc, and the forc-ing part repels it from wrong classes. Regarding the weightfactors, the probability of bias attribute p(b)kalso re-weightsthe influence of classifier weights. Bias-aligned samples,with high p(b)kprobability, will have smaller pulling effectstowards the classifier weight wk, which avoids the dom-inance of bias-aligned features around the weight centersand hinders the tendency of shortcut learning.In com-parison, the bias-conflicting samples are granted strongerpulling and pushing effects, which strengthens their conver-gence toward the right class. The detailed theoretical jus-tification of our method, along with the comparison withvanilla training, are available in Appendix A.",
  ". Experimental Settings": "Datasets and models.We validate the effectiveness ofETF-Debias on general debiasing benchmarks, which covervarious types of bias attributes including color, corrup-tion, gender, and background.We adopt 2 synthetic bi-ased datasets, Colored MNIST and Corrupted CIFAR-10 with the ratio of bias-conflicting training sam-ples {0.5%, 1.0%, 2.0%, 5.0%}, and 3 real-world bi-ased datasets, Biased FFHQ (BFFHQ) with bias ratio . Comparison of debiasing performance on synthetic datasets. We report the accuracy on the unbiased test sets of Colored MNISTand Corrupted CIFAR-10. Best performances are marked in bold, and the number in brackets indicates the improvement compared to thebest result in baselines. () and () denote methods with/without bias supervision respectively.",
  "(+2.91)": ". Comparison of debiasing performance on real-world datasets. We report the accuracy on the unbiased test sets of Biased FFHQ,Dogs & Cats, and BAR. The class-wise accuracy on BAR is reported in Appendix D. Best performances are marked in bold, and thenumber in brackets indicates the improvement compared to the best result in baselines. () and () denote methods with/without biassupervision respectively.",
  "(+1.66)": "{0.5%, 1.0%, 2.0%, 5.0%}, BAR , and Dogs & Cats with bias ratio {1.0%, 5.0%}.As for the model architecture, we adopt a three-layer MLPfor Colored MNIST and ResNet-20 for other datasets.Since BAR has a tiny training set, we follow the previ-ous work and initialize the parameters with pre-trainedmodels on corresponding datasets. All results are averagedover three independent trials. More details about datasetsand implementation are available in Appendix B.Baselines. According to the three categories of debiasedlearning in , we compare the performance of ETF-Debias with six recent methods. For reweight-based debi-asing, we consider LfF with auxiliary bias models, andits improved version LfF+BE . For disentangle-baseddebiasing, we consider EnD and SD , which stemfrom the Information Bottleneck theory and causal inter-vention respectively. For augmentation-based debiasing, weconsider DisEnt and Selecmix , to include both thefeature-level and image-level augmentations.",
  "Comparison on synthetic datasets. To display the debi-asing performance, we report the accuracy on the unbiased": "test set of 2 synthetic datasets in Tab. 2. Its notable thatETF-Debias consistently outperforms baselines in the gen-eralization capability towards test samples, on almost alllevels of bias ratio. We observe that some baseline methods(e.g., EnD) do not display a satisfactory debiasing effecton synthetic datasets, as they rely heavily on diverse con-trastive samples to identify and mitigate the bias features. Incontrast, our approach directly provides the approximatedshortcut features as training primes, which achieves supe-rior performance on synthetic bias attributes.Comparison on real-world datasets. To verify the scala-bility of ETF-Debias in real-world scenarios with more di-verse bias attributes, we test our method on 3 real-world bi-ased datasets in Tab. 3. We observe that ETF-Debias showsan even greater performance gain on real-world datasetsthan on synthetic ones, which may be attributed to the se-mantically meaningful prime features constructed with thesimplex ETF structure. On the large-scale BFFHQ dataset,our method achieves up to 6.6% accuracy improvementscompared to baseline methods, demonstrating its potentialin real-world applications.Convergence of Neural Collapse. In , we display thetrajectory of NC metrics during training on the Corrupted CIFAR-10 dataset. Guided by the prime features, the modelestablishes a right correlation and shows a much better con-vergence property on biased datasets, contributing to the su-perior generalization capability. More convergence resultsare available in Appendix C.",
  ". Ablation Study": "Ablation on the influence of regularization. To measurethe sensitivity of our method to different levels of primereinforcement regularization, we compare the accuracy onthe unbiased test set with range from 0.0 to 1.0 in (a). Its been shown that the debiasing performance re-mains significant with different strengths of regularization,and achieves extra performance gain with the proper levelof prime reinforcement. . Ablation studies on hyper-parameter and prime features.We report (a) test set accuracy on different datasets, with hyper-parameter ranging from 0.0 to 1.0, and (b) test set accuracy on 5datasets with different prime features. The shaded areas representthe standard deviation, and the bias ratio of all datasets is 5%.Ablation on the influence of ETF prime features. Asillustrated before, we choose the vertices of ETF as theperfectly learned shortcut features, thus redirecting themodels attention to intrinsic correlations. To demonstratethe efficacy of ETF prime features, we compare the resultsof randomly initialized prime features with the same dimen-sion as the ETF-based ones. As shown in (b), the ran-domly initialized primes suffer a severe performance degra-dation, underscoring the advantages of ETF-based primefeatures in approximating the optimal structure.",
  ". Visualization": "To intuitively reveal the effectiveness of our method,we compare the CAM visualization results on vanillamodels and debiased models trained with ETF-Debias. Asshown in , the models attention is significantly recti-fied with ETF-Debias. For example, on Corrupted CIFAR-10 dataset, vanilla models are easily misled by the corrup-tions on the entire images, but with the guide of prime fea- .The comparison of visualization results on bias-conflicting samples (first row) between vanilla models (secondrow) and ETF-Debias models (third row). We display the resultof CAM on (a) Corrupted CIFAR-10 dataset, with the biasattribute as different types of corruption on the entire image, (b)Dogs & Cats dataset, with the bias attribute as the color of animalsand (c) BFFHQ dataset, with the bias attribute as gender. tures in our method, the debiased models shift their atten-tion to the objects themselves. Its also notable that ourmethod circumvents the wrong attention area in classifica-tion and encourages the focus on more discriminative andfiner-grained regions. On datasets of facial recognition, ourmethod also breaks the spurious correlation on specific vi-sual attributes and considers more facial features, asshown in (c). More visualization results are availablein Appendix E.",
  ". Conclusion": "In this paper, we propose an avoid-shortcut learningframework with the insights of the Neural Collapse phe-nomenon. By extending the analysis of Neural Collapse tobiased datasets, we introduce the simplex ETF as the primefeatures to redirect the models attention to intrinsic corre-lations. With the state-of-the-art debiasing performance onvarious benchmarks, we hope our work may advance theunderstanding of Neural Collapse and shed light on the fun-damental solutions to model debiasing.",
  "Acknowledgement": "We appreciate the valuable comments from the anony-mous reviewers that improves the papers quality.Thiswork was supported in part by the National Key Re-search and Development Program (2021YFB3101200),National Natural Science Foundation of China (U1736208,U1836210, U1836213, 62172104, 62172105, 61902374,62102093, 62102091). Min Yang is a faculty of ShanghaiInstitute of Intelligent Electronics & Systems, ShanghaiInsitute for Advanced Communication and Data Science,and Engineering Research Center of Cyber SecurityAuditing and Monitoring, Ministry of Education, China.",
  "Yusuke Hirota, Yuta Nakashima, and Noa Garcia. Model-agnostic gender debiased image captioning. In CVPR, pages1519115200, 2023. 2": "Gary B Huang, Marwan Mattar, Tamara Berg, and EricLearned-Miller.Labeled faces in the wild: A databaseforstudying face recognition in unconstrained environments.In Workshop on faces inReal-LifeImages: detection, align-ment, and recognition, 2008. 1 Inwoo Hwang, Sangjun Lee, Yunhyeok Kwak, Seong JoonOh, Damien Teney, Jin-Hwa Kim, and Byoung-Tak Zhang.Selecmix: Debiased learning by contradicting-pair sampling.NeurIPS, 35:1434514357, 2022. 2, 7, 13, 14, 16",
  "A.1. Analysis of Vanilla Training": "To illustrate why vanilla models tend to pursue shortcut learning, we follow the analysis of previous works andre-examine the issue of biased classification from the perspective of gradients.Following the definition in .1, we denote xk,i as the i-th sample of the k-th class, zk,i Rd as its correspondinglast-layer feature, and W = [w1, ..., wK] as the weights of classifier. In vanilla training, the cross-entropy loss is defined as:",
  "pk(z) =exp(zTwk)Kk=1 exp(zTwk), 1 k K(A.3)": "In Eq. A.2, we decompose the gradient w.r.t the classifier weight wk into two parts, the pulling part and the forcing part.The pulling part contains the effects of features from the same class (i.e., zk,i), which pulls the classifier weight towards thek-th feature cluster and each feature has an influence of 1pk(zk,i). Meanwhile, the forcing part of the gradient contains thefeatures from other classes to push wk away from the wrong clusters, and each feature has an influence of pk(zk,j). Whenthe vanilla model is trained on biased datasets, the prevalent bias-aligned samples of the k-th class will dominate the pullingpart of the gradient. The classifier weight wk will be pulled towards the center of the bias-aligned features, which have astrong correlation between the class label k and a bias attribute bk. The biased feature space based on shortcut will thusbe formed at the early period of training, as the result of the imbalanced magnitude of gradients across different attributes.Similarly, the forcing part of the gradient is also guided by the bias-aligned samples of other classes, further reinforcing thetendency of shortcut learning. It confirms our observation in .2 that the models pursuit of shortcut correlation leadsto a biased, non-collapsed feature space, which is hard to rectify in the subsequent training steps.Gradient w.r.t features. Furthermore, we compute the gradient of LCE w.r.t the last-layer features:",
  "(A.4)": "In Eq. A.4, the gradient w.r.t features is also considered as the combination of the pulling part and the forcing part. Thepulling part represents the pulling effect of the classifier weight from the same class (i.e., wk), which will guide the featuresto align with the prediction behavior of the classifier. The forcing part, on the contrary, represents the pushing effect ofother classifier weights. As we discussed before, the models reliance on simple shortcuts is formed at the early stage oftraining, due to the misled classifier weights toward the centers of bias-aligned features. It results in a biased decision ruleof the classifier, which directly affects the formation of the last-layer feature space. Consider the bias-conflicting samplesof the k-th class, although the pulling part of the gradient supports its convergence towards the right classifier weight wk,",
  "A.2. Analysis of ETF-Debias": "In light of the analysis of vanilla training, our proposed debiasing framework, ETF-Debias, turns the easy-to-followshortcut into the prime features, which guides the model to skip the active learning of shortcuts and directly focus on theintrinsic correlations. We have provided a brief theoretical justification of our method in .3, and the detailedillustrations are as follows.When trained on biased datasets, we assume each class [1, ..., K] is strongly correlated with a bias attribute [b1, ..., bK].Based on the mechanism of prime training, we denote the i-th feature of the k-th class as zk,i = [zk,i, mi,b] R2d,where zk,i Rd represents the learnable features, and mi,b Rd represents the prime features retrieved based on the biasattribute b of the input sample. With the definition, a bias-aligned sample of the k-th class xk,i will have its feature in form ofzk,i = [zk,i, mbk], and a bias-conflicting sample will have its feature as zk,i = [zk,i, mbk ], k = k. To keep the same form,we denote the classifier weight as wk = [wk, ak] R2d, where wk Rd represents the weight for intrinsic correlationsand ak Rd is the weight for shortcut features. In the detailed convergence result of Neural Collapse (Section C), weobserve that, due to the fixed prime features and their strong correlation with the bias attributes, ak will quickly collapse intoits bias-correlated prime feature mbk, and can be viewed as constant after just a few steps of training. Thus the cross-entropyloss can be re-written as:",
  "(A.5)": "Gradient w.r.t classifier weights. With the avoid-shortcut learning framework, we justify that the introduced prime mecha-nism implicitly plays the role of re-weighting, which weakens the mutual convergence between bias-aligned features and theclassifier weights, and amplifies the learning of intrinsic correlations. We first analyze the gradient of LCE w.r.t the classifierweights W:",
  "(A.10)": "Based on the gradient w.r.t classifier weights in Eq. A.8, the probability p(b)k exp(mTb ak) re-weights the influenceof different samples during optimization. Consider the features of the k-th class, a bias-aligned sample with its feature zk,i = [zk,i, mbk] will have a much higher probability p(b)k , compared to a bias-conflicting sample of the same class with afeature as zk,j = [zk,j, mbk ], k = k. Therefore, according to the influence of each feature in the pulling part of gradient(1 p(b)k (mi,b) p(l)k (zk,i)), the bias-aligned samples will have their influence down-weighted, while the influence of bias-conflicting samples are up-weighted, which weakens the dominance of the prevalent bias-aligned samples in the pullingeffect and prevents the formation of shortcut correlations. Meanwhile, according to the forcing part of the gradient w.r.t wk,samples from other classes but have the bias-correlated attribute bk will have a relatively strong forcing effect on the weightwk, which also disturbs the learning of simple shortcuts and redirect the models attention to the intrinsic, generalizablerelations.Gradient w.r.t features. With the implicit re-weighting mechanism of gradients, the classifier weights are directed awayfrom the simple shortcuts since the beginning of model training. We also compute the gradient of LCE w.r.t the feature zk,i:",
  "(A.13)": "where the scaling step from Eq. A.11 to Eq. A.12 is based on the Jensen inequality. Similar to the analysis before, thepredicted probability for bias attributes p(b)k exp(mTb ak) also performs re-weighting on the gradient w.r.t features. Withthe prime feature mbk, a bias-aligned sample of the k-th class will have a down-weighted influence in the pulling part towardsthe classifier weight wk, which avoids the dominance of bias-aligned features around the weight centers. In contrast, a bias-conflicting feature will be emphasized and have a magnified pulling effect towards the weight wk, which is crucial for thelearning of intrinsic correlations. As to the forcing part of the gradient, a bias-conflicting sample with prime feature mbkwill obtain a strong pushing effect from the weight wk, which forces it away from the wrong weight center and mitigatethe spurious correlations. The implicitly adjusted pulling and forcing effects both contribute to the features convergenceaccording to the intrinsic correlations.To sum up, through the theoretical justification from the perspective of gradients, the introduced prime mechanism implic-itly re-weights the pulling and forcing effect of gradients. The down-weighted influence of bias-aligned samples weakens thetrend of pursuing simple shortcuts, and the up-weighted influence of bias-conflicting samples enhanced the focus on intrinsiccorrelations, thus leading to an unbiased feature space with improved generalization capability.",
  "B.1. Datasets": "We use two synthetic datasets (i.e., Colored MNIST and Corrupted CIFAR-10) as well as three real-world datasets (i.e.,Biased FFHQ, Dogs & Cats, and BAR) to evaluate the debiasing performance of our proposed method. The illustrativeexamples of the datasets are displayed in Fig. B.1, B.2, B.3.Colored MNIST . As a modified version of the MNIST dataset , Colored MNIST introduces the color of digits as thebias attribute. The ten classes of digits are each correlated with a certain color (e.g., red for digit 0). We conduct experimentswith the dataset used in and set the ratio of bias-conflicting training samples as {0.5%, 1%, 2%, 5%}. Theunbiased test set contains an equal number of bias-aligned and bias-conflicting samples.Corrupted CIFAR-10 . Also modified from the CIFAR-10 dataset , Corrupted CIFAR-10 apply different types of corruptions to the original images, with each class correlated with a certain type of corruption. Following the previous studies, we adopt the corruptions of Brightness, Contrast, Gaussian Noise, Frost, Elastic Transform, Gaussian Blur, DefocusBlur, Impulse Noise, Saturate and set the ratio of bias-conflicting training samples as {0.5%, 1%, 2%, 5%}. The unbiased testset contains an equal number of bias-aligned and bias-conflicting samples.Biased FFHQ . Based on the Flickr-Faces-HQ dataset of face images, Biased FFHQ (BFFHQ) is constructed withthe target attribute of age and the bias attribute of gender. The bias-aligned samples contain images of young females (i.e.,ages ranging from 10 to 29) and old males (i.e., ages ranging form 40 to 59), and the bias-conflicting samples contain oldfemales and young males. We set the ratio of bias-conflicting training samples as {0.5%, 1%, 2%, 5%}. The unbiased test setcontains only bias-conflicting samples.Dogs & Cats . First used in , the Dogs & Cats dataset is constructed with the target attribute of animal and the biasattribute of color (i.e., bright or dark color). The bias-aligned samples contain images of dark cats and bright dogs, while thebias-conflicting samples contain bright cats and dark dogs. We set the ratio of bias-conflicting training samples as {1%, 5%},and the unbiased test set contains only bias-conflicting samples.BAR . The Biased Action Recognition (BAR) dataset contains six classes of actions (i.e., Climbing, Diving, Fish-ing, Vaulting, Racing, Throwing), each correlated with a bias attribute of place (i.e., Rockwall, Underwater, WaterSurface,APavedTrack, PlayingField, Sky). The bias-conflicting samples contain images with rare action-place pairs. We set the ratioof bias-conflicting training samples as {1%, 5%}, and the unbiased test set contains only bias-conflicting samples.",
  "(b) Corrupted CIFAR-10": "Figure B.1. Illustrative examples of synthetic datasets, (a) Colored MNIST with the bias attribute of color and (b) Corrupted CIFAR-10with the bias attribute of different types of corruption (e.g. augmentations like Gaussian Blur and Pixelate, etc). Each column indicates aclass in the dataset, the first row shows bias-aligned samples and the second row with red border shows bias-conflicting samples.",
  "(d) Dogs & Cats: dog": "Figure B.2. Illustrative examples of (a)-(b) BFFHQ with the bias attribute of gender and (c)-(d) Dogs & Cats with the bias attribute of color.(a) and (b) respectively indicate the class of young and old in BFFHQ, while (c) and (d) respectively indicate the class of cat and dog inDogs & Cats. The first three images in each sub-figure show bias-aligned samples and the last one with red border shows bias-conflictingsamples.",
  "B.2. Implementation Details": "During training, we set the batch size of 256 for Colored MNIST and Corrupted CIFAR-10, and 64 for BFFHQ, Dogs &Cats and BAR. For all the baseline methods, we use the configuration in their official repositories. For ETF-Debias, we setthe learning rate of 1e-3 and weight decay of 1e-5 for Colored MNIST, the learning rate of 1e-2 and weight decay of 2e-4 forCorrupted CIFAR-10, and the learning rate of 1e-4 and weight decay of 1e-6 for all the real-world datasets. The dimensionsof learnable features and prime features are set as 100 and 64 for MLP and ResNet-20 respectively. The hyper-parameter is set as 0.8, and all the evaluated models are trained for 200 epochs.",
  "C. More Convergence Results of Neural Collapse": "In , we display the trajectory of NC metrics when trained with ETF-Debias on the Corrupted CIFAR-10 dataset.Eliminating the obstacle of misled shortcut features, the debiased model exhibits better convergence properties during train-ing, which forms a more symmetric feature space as on balanced datasets. We provide more convergence results of NCmetrics on the synthetic biased dataset (Colored MNIST) and the real-world biased dataset (Dogs & Cats) in Fig. C.1 andFig. C.2. By applying ETF-Debias on various datasets with different types of bias attributes (blue lines), we observe notonly the better generalization capability on test sets, but also the more collapsed and robust structure of feature spaces (asindicated by the NC metrics), which provides empirical support for the effective guidance towards the intrinsic correlations. Figure C.1. Comparison of (a) testset accuracy and (b-d) Neural Collapse metrics on Colored MNIST with the bias ratio of 2.0%. Allvanilla models are trained with the standard cross-entropy loss for 500 epochs. The postfix -Aligned and -Conflicting indicate the resultsof bias-aligned and bias-conflicting samples respectively. The vertical dashed line at the epoch of 60 divides the two stages of training. Allmodels are trained on ResNet-20. Figure C.2. Comparison of (a) testset accuracy and (b-d) Neural Collapse metrics on Dogs & Cats with the bias ratio of 5.0%. All vanillamodels are trained with the standard cross-entropy loss for 500 epochs. The postfix -Aligned and -Conflicting indicate the results of bias-aligned and bias-conflicting samples respectively. The vertical dashed line at the epoch of 90 divides the two stages of training. Note thatthe Dogs & Cats dataset is designed for the binary classification task, which means any classifier weights will follow the ETF structure(i.e., NC2 0), and the detailed theoretical support is provided in .",
  "D. Detailed Results of BAR dataset": "Following the previous study , we further report the class-wise accuracy on the unbiased test set of BAR. The debiasingperformance on BAR with the bias ratio of 1.0% and 5.0% are displayed in Tab. D.1 and Tab. D.2 respectively. The comparedbaselines are the same as before. Table D.1. Class-wise accuracy on the unbiased test set of BAR. The ratio of bias-conflicting training sample is 1.0%. Best performancesare marked in bold, and the number in brackets indicates the improvement compared to the best result in baselines.",
  "E. More Visualization Results": "In .4, we provide the comparison of visualization results between vanilla training and ETF-Debias on CorruptedCIFAR-10, Dogs & Cats, and BFFHQ. To further demonstrate the rectified attention of debiased models, we supplementmore visualization results in Fig. E.1(a)-(d).By explicitly visualizing the models attention regions, we observe that ETF-Debias does encourage the model to focuson the intrinsic correlations rather than shortcuts. On synthetic biased datasets like Colored MNIST and Corrupted CIFAR-10, the vanilla models are easily misled by artificial shortcuts and focus on the non-essential parts of images, as shown inFig. E.1(a) & (c). In constrast, when the shortcut learning is suppressed by prime features, the debiased model trained withETF-Debias will pay attention to the digits and objects themselves and make unbiased classification. On real-world biaseddatasets with diverse bias attributes, the vanilla models tend to focus on the background or the distinctive part of the biasattributes. For example, the vanilla models rely on the distinctive part of gender such as the beard of a male or the accessoriesof a female in Fig. E.1(d). The pursuit of shortcut correlations has also been prevented with ETF-Debias, which guides thedebiased model to focus more on facial features and predict the target attribute.",
  "(d) Biased FFHQbias:gender": "Figure E.1. More comparison of visualization results on bias-conflicting samples. We display the result of CAM on (a) ColoredMNIST, with the bias attribute as the color of digits, (b) BAR, with the bias attribute as the background of images, (c) Corrupted CIFAR-10, with the bias attribute as different types of corruptions on the entire image, (d) Biased FFHQ, with the bias attribute as gender. Theoriginal images in (a)-(c) represent the first six classes in each dataset. The original images in the first column of (d) are from the class ofyoung in BFFHQ, while the original images in the fourth column are from the class old. All models are trained on ResNet-20 to obtain theCAM results."
}