{
  "Abstract": "Advancements in AI heavily rely on large-scale datasetsmeticulously curated and annotated for training. However,concerns persist regarding the transparency and contextof data collection methodologies, especially when sourcedthrough crowdsourcing platforms.Crowdsourcing oftenemploys low-wage workers with poor working conditionsand lacks consideration for the representativeness of anno-tators, leading to algorithms that fail to represent diverseviews and perpetuate biases against certain groups. To ad-dress these limitations, we propose a methodology involvinga co-design model that actively engages stakeholders at keystages, integrating principles of Equity, Diversity, and In-clusion (EDI) to ensure diverse viewpoints. We apply thismethodology to develop a dataset and AI model for evalu-ating public space quality using street view images, demon-strating its effectiveness in capturing diverse perspectivesand fostering higher-quality data.",
  ". Introduction": "Current advancements in AI heavily rely on the availabilityof large-scale datasets meticulously curated and annotatedfor training purposes.The significance of such datasetshas been underscored by the success of models like Chat-GPT, which leverages Reinforcement Learning with Hu-man Feedback (RLHF) to fine-tune models based on humaninput . However, concerns persist regarding the trans-parency and context of data collection methodologies, par-ticularly in instances where annotations are sourced throughcrowdsourcing platforms.For instance, reports indicatethat annotations for training ChatGPT were gathered fromworkers in Kenya under conditions of low pay and poor la-bor standards . This reliance on crowdsourcing, often",
  "driven by cost-effectiveness, perpetuates the invisibility andexploitation of workers, particularly those from the globalsouth": "Moreover, the failure to acknowledge the socio-culturalcontext within which data is produced can introduce biasesinto datasets. For example, algorithms trained on datasetsdevoid of the historical context of segregation may inad-vertently perpetuate biases against certain minority groups. Furthermore, the identities of workers involved in an-notations are frequently overlooked, leading to a lack of di-versity in viewpoints captured within datasets. This bias iscompounded by the common practice of aggregating anno-tations through majority voting . To address these limitations, we propose a methodologygrounded in a specific socio-cultural context for dataset col-lection and AI model development. Our approach centerson a co-design model that actively involves stakeholders atkey stages of the AI model development, including datasetcreation. Additionally, we integrate principles of Equity,Diversity, and Inclusion (EDI) to ensure diverse viewpointsare represented within the dataset. We argue that this ap-proach not only mitigates biases within datasets but alsofosters the creation of higher-quality data reflecting diverseperspectives. We apply this methodology to the development of adataset and AI model capable of evaluating the quality ofpublic spaces using street view images.Assessing pub-lic space quality is inherently subjective, as demonstratedby research showing variations across cultural groups . Leveraging our proposed methodology grounded inco-design and EDI principles, we curated a dataset ofstreetview images annotated by a diverse group of citizens.Using this dataset, we trained a baseline AI model to scorepublic space images along various dimensions. Finally, wepropose several fairness metrics to assess the models abil-ity to capture diverse viewpoints within the population.",
  "The methodology we propose is grounded in co-design andbuilds on EDI principles": "Co-designalso known as participatory design or co-creation, embodies an approach where stakeholders are ac-tively engaged throughout the design process to ensure thatthe resulting products meet their needs and preferences .Unlike conventional design methods, which may only in-volve users once a product is completed, co-design aims tointegrate stakeholders at every phase of development. In thecontext of AI, we argue that a methodology based on co-design can mitigate bias from algorithms and harm that canresult from such bias. For example, a methodology basedon co-design actively rejects the practice of crowdsourcingand instead seeks to involve stakeholders directly in the an-notation process. The benefits of involving stakeholders aremanifold:",
  "Inclusivity: Co-design fosters inclusivity by integratingdiverse viewpoints and voices into the design process,which can lead to more fair algorithms that better serveall members of society": "Shared Ownership: Stakeholders possess a sense ofownership over the final AI, having actively participatedin its creation from inception. This sense of ownershipcan lead to greater trust and acceptance of the technology. Equity, Diversity, and Inclusion (EDI)principles are afoundational framework of values and practices aimed atfostering fairness, representation, and belonging within or-ganizations, communities, and societies .Each com-ponent of EDI is integral to creating environments whereall individuals have equitable opportunities to thrive, re-gardless of their background or identity. In the context ofAI and dataset creation, we assert that EDI principles areparamount and should be carefully considered, particularlywhen selecting annotators. It is imperative to ensure that an-notators represent a diverse range of experiences and view-points. By prioritizing diversity among annotators, we canensure that all perspectives are comprehensively incorpo-rated into the dataset. This inclusive approach not only en-hances the richness and depth of the data but also promotesfairness and equity in the resulting algorithms and models. Based on these principles, we have developed a method-ology for creating a dataset and an AI model to evaluatethe quality of public spaces using street-view images. Anoverview of the methodology is presented in . Themain phases of the methodology consist of participant re-cruitment, the organization of workshops to understand par-ticipants concerns regarding public spaces and establishcriteria for evaluating the quality of public spaces, the an-notation of the images, and the AI model evaluation. Participant Recruitment:We focused on recruiting par-ticipants from underrepresented groups. A total of 28 par-ticipants were recruited to take part in the workshops andimage annotations.Recruitment efforts targeted variouscommunity organizations representing diverse underrepre-sented groups.Among the participants, 20 identified as",
  "women, 5 as belonging to an ethnic minority, 2 as handi-capped, 10 as members of the LGBTQ2+ community, and2 as belonging to a religious minority see Appendix A": "Identification of Evaluation Criteria:To capture the di-verse uses of public spaces, we defined 35 criteria for eval-uating their quality. These criteria were identified through atwo-phase process: initially through a literature review andsubsequently refined through feedback and discussions ob-tained during individual interviews and focus groups. Thefull list of criteria is presented in Appendix B.",
  "To evaluate the quality of public spaces, we compiled adataset of pairwise comparisons of street view images": "ImagesThe dataset comprises 7,833 street view imagesgathered from the Greater Montreal region. Sampling repre-sentative images from such a vast area poses challenges, ascertain regions are more densely populated and diverse thanothers. To address this, we implemented a two-stage sam-pling strategy. Initially, we sampled a 50m by 50m grid cov-ering the entire region and identified locations with street-view images nearby. Subsequently, we excluded locationswithout images within a vicinity of less than 1m. In the sec-ond stage, we randomly selected a subset of images fromthe remaining locations. This strategy aimed to boost thenumber of images sampled from regions with higher streetview density, typically correlating with higher populationdensity and more diverse public spaces. AnnotationsThe dataset consists of 19,990 pairwisecomparisons between two images. Participants were taskedwith selecting the preferred image based on a given crite-rion using a cursor ranging from -1 to 1. Users could in-dicate their preference strength by adjusting the positionof the cursor, see Appendix C. Negative values denoted apreference for the left image, positive values for the right,and values close to 0 indicated no preference. This scoringmethod, differing from simple binary choices, mitigates Ar-rows impossibility theorem , as discussed by . More-over, employing continuous scores allows for quantizationinto finite bins during training, offering added flexibility.However, this introduces complexities in voting patterns, asillustrated in .",
  ". Voting Patterns Observed in the Streetview Dataset. It isa histogram of the absolute scores of 3 out of the 22 participants": "by predicting which image, amongst a pair, is given prefer-ence by the user. The model outputs scores for each image,and we indirectly calculate the utility by taking the differ-ence between the scores of two images from a comparison.The workflow for the model is inspired by the work-flow from the place-pulse 2.0 dataset . The model hasa feature extractor and a classifier head. The feature ex-tractor is a pre-trained feature extractor model. The fea-ture extractors we used include VGG11 , EfficientNet, Squeezenet , and DinoV2 . The features arethen passed through a classifier head, which, in our case,was a single or a double-layered perceptron. The output ofthe classifier is the score for each image. We use BinaryCross Entropy, Ranking loss, and Mean Squared Error asthe penalty while training the classifier.",
  ". Equity Metrics": "To define equity for a learning-to-rank problem with respectto the participants domain, we can view the problem asa generative problem, where the participants contribute togenerating the final ranking. The inspiration has been drawnfrom current equal-opportunity fairness metrics and also theGini coefficient , which is widely used in economics tomeasure the inequity in wealth distribution in society. Maximal Per-User Accuracy:",
  "Accmax = maxi,j (Acci Accj)(1)": "Here, Acci and Accj are the accuracies with respect to theith and jth users. This metric aims to calculate the max-imum difference in the per-user accuracy of two users.The higher the maximal per-user accuracy, the more themodel has been biased towards one user than the otherand hence, the user with the minimum per-user accuracyhas not been given equal opportunity to affect the finalranking.",
  "N(2)": "Here, Acci is the accuracy with respect to the ith user,Acc =1NNi=1 Acci is the average per-user Accuracy,and N is the number of participants. The metric aims tocalculate the deviation with respect to all the per-user ac-curacies. A large standard deviation will imply an un-equal distribution of per-user accuracies, which will im-ply that users are not being provided with equal opportu-nity to affect the rankings. Gini Coefficient over Per-User Accuracy: The ratio of thearea underneath the Line of Equality (all the users hav-ing the same per-user accuracy) and the area underneaththe Lorenz Curve (given by the cumulative per-user accu-racy).According to the classical definition of the Gini Coeffi-cient with respect to the relative mean difference:",
  ". Results": "We have considered the Learning-To-Rank task on theStreetview Image Dataset as a Regression Problem, wherethe model outputs scores for both the images in the com-parison and is trained to match the difference in the pre-dicted score to the score provided by the participant for theparticular comparison. The value for the metrics for theregression problem type can be seen in Figure a. Ad-ditionally, the inequity seems to be higher in the case of criteria where the model seems to perform the best overall,as seen in b and c. Here, the inequity seems tobe brought about majorly by the voting patterns as the meansquared error (MSE) used to train the model penalises themodel for every minute discrepancy with the users compar-isons. The users with voting patterns with the majority ofvotes clustered around 0 (a conservative voting approach)tend to have more accuracy, as is expected for the best-fitmodel enforced by the MSE loss. However, given a dif-ferent model, this learned voting pattern can differ. Also,the number of comparisons still affects the inequity, but it isdifficult to disentangle its effects and differentiate the minortrend from the major trend of inequity by voting patterns.",
  ". Conclusion": "In conclusion, our study introduces a novel dataset aimed atassessing the quality of public spaces using street-view im-ages. This dataset is the product of a methodology integrat-ing co-design and Equity, Diversity, and Inclusion (EDI)principles, ensuring representation of diverse perspectives.We trained a baseline model on this dataset and assessedits fairness in capturing a broad spectrum of viewpoints.However, our analysis revealed significant challenges. Themodels performance varied considerably across differentevaluation criteria, with some criteria showing performanceclose to random, underscoring the complexity of the task.Moreover, we observed substantial variability in model per-formance across different users, indicating an inability toaccurately capture preferences from diverse user groups.While these initial findings are promising, they also under-score the need for further research to develop models capa-ble of effectively capturing and representing a diversity ofviewpoints. We have tried some plausible solutions to atten-uate the aforementioned problems and report their findingsin Appendix D. Addressing these challenges is crucial foradvancing the development of responsible AI models anddatasets in the realm of public space evaluation. Josh Achiam, Steven Adler, Sandhini Agarwal, Lama Ah-mad, Ilge Akkaya, Florencia Leoni Aleman, Diogo Almeida,Janko Altenschmidt, Sam Altman, Shyamal Anadkat, et al.Gpt-4 technical report.arXiv preprint arXiv:2303.08774,2023. 1",
  "Peter M Asaro. Transforming society by transforming tech-nology: the science and politics of participatory design. Ac-counting, Management and Information Technologies, 10(4):257290, 2000. 2": "Aida Mostafazadeh Davani, Mark Daz, and VinodkumarPrabhakaran. Dealing with disagreements: Looking beyondthe majority vote in subjective annotations. Transactions ofthe Association for Computational Linguistics, 10:92110,2022. 1 Anne AH de Hond, Marieke M van Buchem, and TinaHernandez-Boussard. Picture a data scientist: a call to ac-tion for increasing diversity, equity, and inclusion in the ageof ai. Journal of the American Medical Informatics Associa-tion, 29(12):21782181, 2022. 2",
  "Michel Lussault. De la lutte des classes `a la lutte des places.Grasset Paris, 2009. 1": "Maxime Oquab, Timothee Darcet, Theo Moutakanni, HuyVo, Marc Szafraniec, Vasil Khalidov, Pierre Fernandez,Daniel Haziza, Francisco Massa, Alaaeldin El-Nouby, Mah-moud Assran, Nicolas Ballas, Wojciech Galuba, RussellHowes, Po-Yao Huang, Shang-Wen Li, Ishan Misra, MichaelRabbat, Vasu Sharma, Gabriel Synnaeve, Hu Xu, Herve Je-gou, Julien Mairal, Patrick Labatut, Armand Joulin, and Pi-otr Bojanowski. DINOv2: Learning robust visual featureswithout supervision. 3",
  "E. Experimentation Details": "We have implemented all experiments in this work using PyTorch Lightning. The model with the best performance uses anEfficientNet feature extractor, pre-trained on ImageNet, and with weights available from the TorchVision package. It also hasa two-layered classifier with 256 hidden dimensions. For training, we have randomly split the dataset in an 80-20 split fortraining and validation. To obtain the optimal model, whose results we have presented in this work, we ran a grid search overthe hyperparameters to identify the optimal set of hyperparameters. We trained the Baseline model over 150 epochs when thetraining batch size was 32. The losses used while training the optimal model are the Least Squared Error Loss and the Rankingloss, as explained in the main text. We used the ADAM optimizer with an initial Learning Rate of 0.01, which was reducediteratively if the models performance did not change over 8 steps using a Scheduler. Finally, we used early stopping to stopthe model from overfitting and have stated the results with the model which attained the best performance while training.Additionally, to alleviate the effects of stochasticity, we have replicated the training with the optimal hyperparameters five times, with different initial seeds. We have trained all models on 2 Nvidia V100SMX2 GPUs, from the Beluga ComputerCluster at ETS, Montreal, with access supported through the Digital Research Alliance of Canada (the Alliance)."
}