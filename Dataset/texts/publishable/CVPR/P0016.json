{
  "Abstract": "This paper introduces -NeRF, a self-supervised approachthat sets a new standard in novel view synthesis (NVS) andcomputed tomography (CT) reconstruction by modeling acontinuous volumetric radiance field enriched with physics-based attenuation priors. The -NeRF represents a three-dimensional (3D) volume through a fully-connected neu-ral network that takes a single continuous four-dimensional(4D) coordinatespatial location (x, y, z) and an initial-ized attenuation value ()and outputs the attenuation co-efficient at that position. By querying these 4D coordinatesalong X-ray paths, the classic forward projection techniqueis applied to integrate attenuation data across the 3D space.By matching and refining pre-initialized attenuation val-ues derived from traditional reconstruction algorithms likeFeldkamp-Davis-Kress algorithm (FDK) or conjugate gra-dient least squares (CGLS), the enriched schema deliverssuperior fidelity in both projection synthesis and image re-construction, with negligible extra computational overhead.The paper details the optimization of -NeRF for accu-rate NVS and high-quality CT reconstruction from a limitednumber of projections, setting a new standard for sparse-view CT applications.",
  ". Introduction": "X-ray imaging, a form of penetrative imaging to capturedetailed internal structures, is widely applied across fields,such as medicine, industrial inspection, materials science,etc. . While high-resolution projections can pro-duce high-quality CT images, they require extended expo-sure time, and excessive radiation pose health risks, par-ticularly in medical applications.Consequently, one ofthe recent research topics focused on sparse-view and low-dose techniques to reduce radiation exposure and/or in-",
  "*Dr. Xu is now with Samsung NeuroLogica and his work was done inthe University of Massachusetts Lowell.Corresponding author, email:": "crease temporal resolution while maintaining diagnosticutility , particularly for the situations wherethere are no slip-ring in the CT scanner. However, in caseslike 3D cone beam CT (CBCT) reconstruction, sparse-viewdata often limits resolution and introduces artifacts com-pared with full-view data, which highlights the need foradvanced computational methods to accurately synthesizeviews and generate anatomical structure from a limitednumber of projections.CT reconstruction techniques can be categorized into an-alytical, iterative, and hybrid data-driven approaches. Ana-lytical methods, such as filtered backprojection (FBP) and its cone-beam variants , are effective with denseprojection data but fall short under sparse-view conditions.Iterative approaches, including methods like simultaneousalgebraic reconstruction technique (SART) family and total variation (TV)-minimization techniques , ad-dress some of these limitations by optimizing the recon-struction through iterative updates. However, these meth-ods require considerable computational resources and arenot always practical for real-time or large-scale applica-tions. Recently, hybrid data-driven approaches that incor-porate deep learning have enhanced the traditional tech-niques by using neural networks to predict, fill gaps, andimprove denoising for sparse data . While thesemodels achieve impressive results, they often require exten-sive labeled datasets for training, which limits their adapt-ability and generalizability to different datasets without fur-ther fine-tuning. Given these limitations, self-supervisedmethods offer a promising alternative by reducing relianceon labeled data and improving adaptability across variousreconstruction tasks. Inspired by advancements in 3D re-construction in computer vision, recent works have explored the applications of self-supervised methodsfor CT reconstruction, where internal structures are cap-tured through X-ray transmission imaging rather than re-flective imaging.In the computer vision field, 3D reconstruction typicallyrepresents shapes as discrete point clouds or meshes. Im-plicit neural representations (INRs) have become popular",
  "arXiv:2412.05322v1 [eess.IV] 3 Dec 2024": ". Overview of the -NeRF framework for CT reconstruction. Discrete X-ray sample points integrate attenuation priors 0 withspatial coordinates (x, y, z). Attenuation values are updated along the X-ray paths by applying forward projection technique with encodersand the mapping function F. as they map discrete points to continuous functions, en-abling smoother and more accurate modeling of complexgeometries. NeRF , a leading model in this space, lever-ages INRs for reflective imaging with camera rays, map-ping spatial position and viewing direction in 5D coordi-nates to RGB color and volume density, allowing photore-alistic novel view synthesis (NVS) through volumetric ren-dering. However, NeRF and similar models are primarily designed for reflective imaging and can notbe directly applied to X-ray imaging to capture internalstructures.Recent INR-based approaches for CT recon-struction, such as neural attenuation field (NAF) andSAX-NeRF , adapt NeRF for X-rays by mapping 3Dspatial coordinates to attenuation coefficients. While theseadaptations improve reconstruction quality, they only con-sider spatial location, and further enhancements to accuracycome with advanced mapping functions/models which sig-nificantly increased computational costs.To address the limitations of current methods, wepresent -NeRF framework (see ), a self-supervisedapproach designed for X-ray-based 3D tomographic recon-struction. We adopt the CBCT geometry as defined in TI-GRE , making -NeRF adaptable across a range of CTimaging settings. Our key contributions are as follows: Redefining Input with Attenuation Priors: By examiningthe inherent properties of CT imaging, we redefine the in-put for implicit neural representations (INRs) as a 4D co-ordinate system consisting of spatial location (x, y, z) andan initialized attenuation value (). This enables -NeRFto model a continuous volumetric radiance field, captur-ing the 3D volume with a fully-connected neural network.By querying these 4D coordinates along X-ray paths andapplying forward projection technique, -NeRF is com-patible with other NeRF-based CT reconstruction frame-works and achieves enhanced fidelity in sparse-view ap-plications. Efficient Attenuation Initialization: We introduce inter-polation methodsmean, nearest neighbor, and trilin-earto initialize attenuation values () at a sparse spa-tial location from its 8 neighboring points on the grids.We use these techniques to match and initialize attenu-ation values, which are pre-initialized by the traditionalalgorithms such as FDK and CGLS. Also, a lightweight,learnable linear transformation serves as feature encod-ing for further refinement. Together, these techniques en-hance projection synthesis and image reconstruction withminimal computational cost. Benchmark Validation on X3D Dataset: Extensive evalu-ations on the X3D dataset, a large-scale benchmark for X-ray 3D reconstruction, confirm -NeRFs state-of-the-artperformance in both NVS and CT reconstruction acrossdifferent X-ray applications. This 4D scene representa-tion captures high-resolution geometry and enables high-fidelity anatomical reconstructions, establishing a newbenchmark for higher accuracy and efficiency in sparse-view CT applications.In summary, -NeRF leverages attenuation priors to ad-dress the limitations of existing INR-based CT reconstruc-tion methods, achieving notable improvements in perfor-mance and fidelity with negligible extra computational de-mands.This work sets a new benchmark for low-dose,sparse-view CT imaging, advancing the field toward effi-cient, high-quality 3D X-ray reconstructions.",
  ". 3D CT Reconstruction": "CT reconstruction methods are broadly categorized into an-alytical, iterative, and hybrid data-driven approaches. Foun-dational analytical algorithms, such as filtered backprojec-tion (FBP) and its cone-beam extension, Feldkamp-Davis-Kress (FDK) , reconstruct attenuation coeffi- cients from projections by solving the Radon transform.Variants with different filters and Parker weights improveimage quality under dense data but produce artifacts undersparse-view conditions. Iterative algorithms address theselimitations by framing reconstruction as a maximum a pos-teriori (MAP) problem, solved through iterative optimiza-tion. Gradient-based approaches like the algebraic recon-struction technique (ART) family (SART , SIRT ,and OS-SART ) vary in update strategy: SART andSIRT update the full projection set at once, yielding highquality images with high computational cost, and OS-SART strikes a balance with efficient and subset-based up-dates. Total variation (TV) minimization based methods(e.g., ASD-POCS , OS-ASD-POCS , and AwASD-POCS ) iteratively refine reconstructions to suppressnoise, with variants improving computational efficiencyor edge preservation.Krylov subspace algorithms (e.g.,CGLS , LSQR ) achieve faster convergence by fo-cusing on the eigenvectors of the residual in descending or-der, which allows for increased convergence rates comparedto the SART family. While the SART-based methods are ef-fective with high-quality projection data, Krylov subspacealgorithms, like CGLS, are well-suited for handling largedatasets or low-quality data, offering both speed and robust-ness, especially in CT denoising.Hybrid data-driven approaches combine the traditionalmethods with deep learning. These methods enhance re-construction by using neural networks to 1) predict and fillgaps in limit-view or sparse-view projections ,2) directly infer attenuation coefficients as denoising tasksfrom training data , and 3) optimize differen-tiable processes to accelerate computations .While these models achieve impressive results and requireminimal data during inference, they depend on extensive,domain-specific datasets for training, which restricts theiradaptability to different applications without further fine-tuning.Consequently, hybrid data-driven models excelin specific contexts but face challenges in generalizabilityacross different CT reconstruction scenarios. Given theselimitations, studying self-supervised methods could providea promising alternative by reducing reliance on labeled dataand improving adaptability across different reconstructiontasks.",
  ". Implicit Neural Representation and Rendering": "Learning implicit neural representations (INRs) has be-come a popular approach in 3D scene reconstruction, of-fering a way to transform discrete data points into con-tinuous functions for learning-based 3D geometry mod-eling .Neural rendering leverages INRs tomap discrete data to coordinate-based continuous represen-tations, typically using implicit functions parameterized byneural networks . One prominent method is the neural radiance field (NeRF) , a model that has set astandard for high-quality novel view synthesis.For reflective imaging, NeRF models a scene by map-ping spatial position (x, y, z) and viewing direction (, )along camera rays to RGB color (r, g, b) and volume den-sity (). This allows NeRF to produce high-quality novelviews by integrating color and densities along rays throughvolumetric rendering . Numerous works have aimed toimprove NeRFs efficiency , and extend its ap-plication scope, such as generative modeling, unboundedscenes, and RGB-D synthesis. More recently, INR-basedmethods have been explored for CT image reconstruc-tion , transforming discrete samples into contin-uous representations of internal structures.For X-ray imaging, adapting NeRF is necessary toaddress fundamental differences from reflective imaging.Unlike visible light, which reveals surface color and re-flectance, X-ray penetrates objects to capture internalstructures through attenuation.Neural attenuation fields(NAF) modify the NeRF framework for 3D CBCT re-construction by mapping spatial positions (x, y, z) directlyto attenuation coefficients (). Follow-up works refined this method by introducing advanced mod-eling functions or complex encoding techniques, such asTransformer-based network in SAX-NeRF . However,these adaptations often increase computational demands.To address this issue, we introduce attenuation priors toINR-based CT reconstruction algorithms, achieving per-formance improvement with minimal computational over-head.",
  "tn (r(t)) dt,(1)": "where (r(t)) represents the attenuation coefficient at eachpoint r(t) parametrized by t along the path, and tn and tfare the near and far limits to account for the materials ef-fective attenuation coefficients along the ray path. To alignwith the voxel grid of view, the ray is divided into evenlyspaced bins within the near and far limits, with one pointuniformly sampled within each bin.Eq. (1) can be dis-cretized as:",
  ". Geometric configuration of CBCT and X-ray sampling": "paramterized by tj, and t is the sampling interval length.The objective of tomographic reconstruction is to estimatethe distribution of and produce it as a discrete volume,using X-ray projections captured from N different angles.As shown in , we model the CBCT geometry byfollowing the conventional definitions and incorporating alocal coordinate system. An X-ray source S rotates aroundthe object along a circular trajectory defined by the rotationangle . Unlike reflective imaging setups, the object is cen-tered at the origin O of a world coordinate system, and theprojections are captured on a flat panel detector positionedopposite to the source. The imaging object is representedas a cube and discretized into voxel units for detailed analy-sis. This detector records X-ray projections in its own localcoordinate system, i.e. an image coordinate system.Let I = {Ii}i=1,...,N be the set of X-ray projections ob-tained from N different rotation angles. Each projection Iirecords the attenuation of X-rays as they traverse the object.We model an X-ray path as r(t) = oo +tdo R3, boundedby the near and far limits tn and tf. The direction of eachray is encoded by a 3D unit Cartesian vector do and X-raysource position oo derived from the geometric configurationbetween the X-ray source and the detector. Specifically, doand oo are calculated based on the rotation angle , the dis-tance from source to detector (DSD), and the distance fromsource to object (DSO). At the position of source point oo",
  "oo = (DSO cos(), DSO sin(), 0) ,(3)": "we define a local coordinate system (xs, ys, zs) along threeunit vectors (cos(), sin(), 0), (sin(), cos(), 0)and (0, 0, 1). We assume that the detector is perpendic-ular to xs-axis. Considering a local detector coordinatorsystem (u, v) with u-axis parallel to the xoyo-plane andys-axis and v-axis parallel to zo-axis and zs, (0, 0) is theprojection position of the X-ray source. The transformationof the ray direction within the global coordinate system canbe expressed through an affine transformation:",
  ". Attenuation Priors Scene Representation": "We follow the conventional idea of NeRF , adaptingit for X-ray imaging by using attenuation values insteadof color and density.The following pipeline, illustratedin , details our approach to integrate attenuation priorsinto a neural radiance field.Attenuation Modeling: We model tomographic imagesas a continuous 4D attenuation field, represented as a func-tion:F : (x, y, z, 0) (),(6) where (x, y, z) is a 3D spatial coordinate, 0 represents aninitialized attenuation value, and denotes the learned at-tenuation coefficient. The neural network, parameterizedby , is optimized to map each 4D input to its correspond-ing attenuation value, yielding a continuous representationof the attenuation field.Attenuation Initialization: The initialization of atten-uation priors begins with the traditional reconstruction al-gorithms, such as FDK and CGLS, to produce initial at-tenuation estimates, 0, for the 3D attenuation map in theglobal coordinate system. While these voxel-based initialvalues provide a structured foundation, further refinementis needed to achieve a continuous, high-fidelity reconstruc-tion.To this end, we employ three interpolation meth-odsmean, nearest neighbor, and trilinearto smooth andadapt attenuation values at points where X-ray paths inter-sect the voxel grid, as shown in . The attenuationvalue at a sampled point is determined using 8 neighboringvoxel vertices via their mean, nearest neighbor, or trilin-ear interpolation. This initialization pipeline offers robustpriors that support accurate projection synthesis and high-quality reconstruction from any view.Feature Encoding:Previous studies haveshown that deep networks tend to favor low-frequency rep-resentations, limiting their ability to capture fine details incolor and geometry. By mapping low-dimensional inputsinto a higher-dimensional space with high-frequency encod-ings, neural networks better capture these high-frequencyvariations. Given that X-ray imaging naturally features ho-mogeneous tissue regions with sharp boundaries at anatom-ical transitions, resulting low variation of the image, weadopt a learning-based encoding mechanism to leveragethese properties. For spatial positions, we use a hash en-coder a sparse, learning-based encoding methodtoefficiently represent position details. For attenuation val-ues, we apply a lightweight linear transformation to refinethe input for enhanced accuracy in reconstruction.Model Optimization: The optimization process of -NeRF involves minimizing the difference between the pre- dicted and actual X-ray projections across the dataset. Thenetwork is trained to predict attenuation coefficients foreach 4D input (spatial position and initial attenuation) byusing an objective function based on the mean squared error(MSE) between the synthesized projections and the groundtruth:",
  "I(r) I(r)2,(7)": "where I(r) and I(r) are real and synthesized projectionsfrom ray r respectively, and R is a batch of rays. is thelearned hash encoder for spatial location (x, y, z), is thelearned linear encoder for initial attenuation 0, and A isthe attenuation coefficients network. I(r) is computed byEq. (2) where j is estimated by the network A and the re-lated encoders and . This is implemented by the classicforward projection technique that corresponds to the render-ing model in the computer vision field. The CT reconstruc-tion process is achieved by feeding the voxel grid coordi-nates, sized to the desired dimensions, into the trained neu-ral function F to predict the corresponding attenuation co-efficients. In our work, we use the MLP model architecturefrom as the foundation for our study. Additionally, weexplore a transformer-based model that incorporates X-raystructural awareness to further validate the applicabilityof our proposed method. The final output is represented asa discrete 3D matrix.",
  ". Experimental Setup": "Following novel Nerf-based works , we evaluateour method using publicly available human organ CTdatasets, including LIDC-IDRI and scientific visualiza-tion dataset . Using the open-source tomographic tool-box TIGRE , we simulate 100 projections per case with3% noise over a 0180 range. For the novel view synthe-sis (NVS) task, we split these projections evenly, with 50for training and 50 for testing. For sparse-view CT recon-struction, the CT volumes are reserved as ground truths forevaluation.The -NeRF framework is implemented in PyTorch andtrained on an NVIDIA RTX 3090 GPU. We optimize themodel using the Adam optimizer (1 = 0.9, 2 = 0.999)for at most 3,000 iterations, with an inital learning rate of0.001, reduced to 0.0001 halfway through training. For ef-ficient processing, we use a batch size of 1,024 rays, witheach ray sampled at 192 points to adequately represent theattenuation field across the CT volume.After training,we quantitatively evaluate the reconstruction by computingboth peak signal-to-noise ratio (PSNR) and structural simi-larity index (SSIM) metrics. PSNR (in dB) provides a sta-tistical measure of artifact suppression performance, while",
  ". Main Results": "We include comparisons with the conventional CT recon-struction algorithms, including FDK (physics-based), AS-POCS (iterative), and CGLS (Krylov subspace), as well asthe state-of-the-art NeRF-based methods, named NAF andSAX-NeRF. We deploy the -NeRF framework to NeRF-based models by utilizing their neural networks as the map-ping function F, naming the enhanced models -NAFand -SAX-NeRF. These new models integrate attenuationpriors, the nearest neighbor interpolation method, and thetwo proposed feature encoders, demonstrating the effec-tiveness and adaptability of our approach. Unless other-wise noted, this configuration is used throughout the ex-periments. A detailed analysis of these design choices isprovided in Sec. 4.3, with additional quantitative and quali-tative results available in the supplementary materials.3D CT Reconstruction: Tab. 1 and provide quan-titative and visual comparisons of 3D CT reconstructionacross baseline and -NeRF-enhanced models. The -basedmodels consistently outperform their counterparts across allcases. Specifically, SSIM values improve from 0.93 to 0.95in foot reconstructions when comparing NAF and -NAF,also it surpasses SAX-NeRF-based models while maintain-ing a negligible computational cost, which will be discussedin Sec. 4.3. In chest scans, -NAF achieves a PSNR of35.07 dB, compared to 34.46 dB with SAX-NeRF, under-scoring the positive impact of leveraging attenuation priors.These results validate that -NeRF effectively reduces arti-facts and yields more precise reconstructions, especially insparse-view conditions, emphasizing the benefits of refinedattenuation initialization.Novel View Synthesis: In Tab. 2, quantitative evalua-tion results of novel view synthesis (NVS) show that -NAF and -SAX-NeRF provide substantial improvementsover approaches adopting only spatial location as inputs,and promising the effectiveness of attenuation priors mech-anism.For instance, -SAX-NeRF achieves a PSNR of47.66 dB and an SSIM of 0.9996 on chest views, comparedto SAX-NeRFs 47.41 dB and 0.9994, respectively. visually demonstrates the sharper anatomical details ren-dered by -based models, effectively capturing fine struc-tures. This performance, combined with supplementary re-sults, highlights the capability of -NeRF in delivering vi-sually accurate and consistent NVS results across variousanatomical regions.",
  ". Quantitative comparison of novel view synthesis from different methods in terms of PSNR/SSIM, where bold fonts indicate thebest results": "to retain crucial attenuation information, providing a solidbaseline for the -based models.We evaluate three tra-ditional initialization algorithmsFDK, ASD-POCS, andCGLSto estimate initial attenuation coefficients for the -NeRF models.As shown in Tab. 3, FDK consistentlyachieves high SSIM and PSNR scores, confirming its ef-fectiveness for initializing attenuation values.FDK, be-ing a physics-based algorithm, preserves more attenuationdetails, whereas iterative methods with TV-regularization,such as ASD-POCS and CGLS, may result in overly smoothreconstructions, potentially losing physical details.Forthese reasons, we primarily use FDK for initialization inour main experiments.",
  ". Comparison analysis of GMACs and parameters for dif-ferent models": "els (NAF and SAX-NeRF) against their -based counter-parts (-NAF and -SAX-NeRF). The -based models in-troduce minimal increases in computational cost, with only0.19 giga multiply-add operations per second (GMACs) in-crease. Parameter counts remain nearly identical across ver-sions, with a negligible increase of less than 0.1%. Com-bined the results in Tab. 1 and Tab. 2, one can see that our-based models achieve higher performance with minimalincrease in computational cost.Convergence Analysis: shows the loss over train-ing steps for four models: NAF, -NAF, SAX-NeRF, and-SAX-NeRF. The vertical axis represents the loss in logscale, and the horizontal axis indicates the training steps upto 70,000. The inset zooms highlight the behavior of eachmodel. Models that incorporate attenuation priors (-NAFand -SAX-NeRF) exhibit faster convergence and maintainlower loss values throughout the training compared to thecounterparts without these priors (NAF and SAX-NeRF).This suggests that leveraging attenuation priors acceleratesthe convergence process, allowing the models to reach a sta-ble and lower loss more quickly than those without the pri-",
  ". Conclusion": "This work introduces -NeRF, a self-supervised neuralframework designed for high-fidelity 3D CT reconstructionfrom sparse-view X-ray data. By leveraging attenuation pri-ors with a continuous 4D representation, -NeRF advancesthe performance of CT imaging while reducing reliance ondense data or supervised learning. Key contributions in-clude a novel input schema that integrates initialized at-tenuation priors, effective feature encoding methods, and robust interpolation techniques. Evaluations on the X3Ddataset validate -NeRFs state-of-the-art performance innovel view synthesis and CT reconstruction. This frame-work not only sets a new benchmark in efficiency and accu-racy for sparse-view CT applications but also offers poten-tial for adaptation across a range of Nerf-based methods onCT reconstruction, contributing to advancements in medicaland industrial CT imaging.",
  "Anders H Andersen and Avinash C Kak. Simultaneous alge-braic reconstruction technique (sart): a superior implemen-tation of the art algorithm. Ultrasonic imaging, 6(1):8194,1984. 1, 3": "Rushil Anirudh, Hyojin Kim, Jayaraman J Thiagarajan,K Aditya Mohan, Kyle Champley, and Timo Bremer. Losethe views: Limited angle ct reconstruction via implicit sino-gram completion. In Proceedings of the IEEE Conferenceon Computer Vision and Pattern Recognition, pages 63436352, 2018. 3 Samuel G Armato III, Geoffrey McLennan, Luc Bidaut,Michael F McNitt-Gray, Charles R Meyer, Anthony PReeves, Binsheng Zhao, Denise R Aberle, Claudia I Hen-schke, Eric A Hoffman, et al. The lung image database con-sortium (lidc) and image database resource initiative (idri):a completed reference database of lung nodules on ct scans.Medical physics, 38(2):915931, 2011. 5 Jonathan T Barron, Ben Mildenhall, Matthew Tancik, PeterHedman, Ricardo Martin-Brualla, and Pratul P Srinivasan.Mip-nerf: A multiscale representation for anti-aliasing neu-ral radiance fields. In Proceedings of the IEEE/CVF inter-national conference on computer vision, pages 58555864,2021. 3 Jonathan T Barron, Ben Mildenhall, Dor Verbin, Pratul PSrinivasan, and Peter Hedman. Mip-nerf 360: Unboundedanti-aliased neural radiance fields.In Proceedings ofthe IEEE/CVF conference on computer vision and patternrecognition, pages 54705479, 2022. 3",
  "Anpei Chen, Zexiang Xu, Andreas Geiger, Jingyi Yu, andHao Su. Tensorf: Tensorial radiance fields. In European con-ference on computer vision, pages 333350. Springer, 2022.3": "Zhang Chen, Zhong Li, Liangchen Song, Lele Chen, JingyiYu, Junsong Yuan, and Yi Xu. Neurbf: A neural fields repre-sentation with adaptive radial basis functions. In Proceed-ings of the IEEE/CVF International Conference on Com-puter Vision, pages 41824194, 2023. 3 Zixuan Chen, Lingxiao Yang, Jian-Huang Lai, and XiaohuaXie. Cunerf: Cube-based neural radiance field for zero-shotmedical image arbitrary-scale super resolution. In Proceed-ings of the IEEE/CVF International Conference on Com-puter Vision, pages 2118521195, 2023. 3 Andrei Dabravolski, Kees Joost Batenburg, and Jan Sijbers.Dynamic angle selection in x-ray computed tomography. Nu-clear Instruments and Methods in Physics Research SectionB: Beam Interactions with Materials and Atoms, 324:1724,2014. 3",
  "Lee A Feldkamp, Lloyd C Davis, and James W Kress. Prac-tical cone-beam algorithm. Josa a, 1(6):612619, 1984. 1,2": "Liubov Flores,Vicente Vidal,Estbaliz Parcero,andGumersindo Verdu. Application of a modified lsqr methodfor ct imaging reconstruction with low doses to patient. In2016 9th International Congress on Image and Signal Pro-cessing, BioMedical Engineering and Informatics (CISP-BMEI), pages 19691974. IEEE, 2016. 3 Kyle Genova, Forrester Cole, Daniel Vlasic, Aaron Sarna,William T Freeman, and Thomas Funkhouser.Learningshape templates with structured implicit functions. In Pro-ceedings of the IEEE/CVF international conference on com-puter vision, pages 71547164, 2019. 3",
  "P. Klacansky. Scientific visualization datasets (2022), 2022": "Anish Lahiri, Gabriel Maliakal, Marc L Klasky, Jeffrey AFessler, and Saiprasad Ravishankar. Sparse-view cone beamct reconstruction using data-consistent supervised and adver-sarial learning from scarce training data. IEEE Transactionson Computational Imaging, 9:1328, 2023. 3 Ziheng Li, Ailong Cai, Linyuan Wang, Wenkun Zhang, ChaoTang, Lei Li, Ningning Liang, and Bin Yan.Promisinggenerative adversarial network based sinogram inpaintingmethod for ultra-limited-angle computed tomography imag-ing. Sensors, 19(18):3941, 2019. 3 Zhentao Liu, Yu Fang, Changjian Li, Han Wu, Yuan Liu,Dinggang Shen, and Zhiming Cui. Geometry-aware atten-uation learning for sparse-view cbct reconstruction. IEEETransactions on Medical Imaging, 2024. 3 Stephen Lombardi, Tomas Simon, Jason Saragih, GabrielSchwartz, Andreas Lehrmann, and Yaser Sheikh. Neural vol-umes: Learning dynamic renderable volumes from images.arXiv preprint arXiv:1906.07751, 2019. 3 Eric Maire, Jean-Yves Buffiere, Luc Salvo, Jean JacquesBlandin, Wolfgang Ludwig, and JM Letang. On the applica-tion of x-ray microtomography in the field of materials sci-ence. Advanced Engineering Materials, 3(8):539546, 2001.1 Lars Mescheder, Michael Oechsle, Michael Niemeyer, Se-bastian Nowozin, and Andreas Geiger. Occupancy networks:Learning 3d reconstruction in function space. In Proceedingsof the IEEE/CVF conference on computer vision and patternrecognition, pages 44604470, 2019. 3 Ben Mildenhall, Pratul P Srinivasan, Matthew Tancik,Jonathan T Barron, Ravi Ramamoorthi, and Ren Ng. Nerf:Representing scenes as neural radiance fields for view syn-thesis. Communications of the ACM, 65(1):99106, 2021. 2,3, 4, 5 Bahareh Morovati, Reza Lashgari, Mojtaba Hajihasani, andHasti Shabani. Reduced deep convolutional activation fea-tures (r-decaf) in histopathology images to improve the clas-sification performance for breast cancer diagnosis. Journalof Digital Imaging, 36(6):26022612, 2023. 1 Bahareh Morovati, Mengzhou Li, Shuo Han, Yongshun Xu,Li Zhou, Ge Wang, and Hengyong Yu. Impact of networkarchitecture and training strategy for photon counting ct datacorrection. In Developments in X-Ray Tomography XV, page131520D. SPIE, 2024. 1",
  "In Proceedings of the IEEE/CVF conference on computer vi-sion and pattern recognition, pages 165174, 2019. 3": "Albert Pumarola, Enric Corona, Gerard Pons-Moll, andFrancesc Moreno-Noguer.D-nerf: Neural radiance fieldsfor dynamic scenes. In Proceedings of the IEEE/CVF Con-ference on Computer Vision and Pattern Recognition, pages1031810327, 2021. 2 Nasim Rahaman, Aristide Baratin, Devansh Arpit, FelixDraxler, Min Lin, Fred Hamprecht, Yoshua Bengio, andAaron Courville. On the spectral bias of neural networks. InInternational conference on machine learning, pages 53015310. PMLR, 2019. 4 Hua-Chieh Shao, Tielige Mengke, Tinsu Pan, and YouZhang.Dynamic cbct imaging using prior model-freespatiotemporal implicit neural representation (pmf-stinr).Physics in Medicine & Biology, 69(11):115030, 2024. 3 Chenyang Shen, Yesenia Gonzalez, Liyuan Chen, Steve BJiang, and Xun Jia.Intelligent parameter tuning inoptimization-based iterative ct reconstruction via deep rein-forcement learning. IEEE transactions on medical imaging,37(6):14301439, 2018. 3",
  "Ashok Kumar Singh. Advanced x-ray techniques in researchand industry. IOS press, 2005. 1": "Vincent Sitzmann, Justus Thies, Felix Heide, MatthiasNiener, Gordon Wetzstein, and Michael Zollhofer. Deep-voxels: Learning persistent 3d feature embeddings. In Pro-ceedings of the IEEE/CVF Conference on Computer Visionand Pattern Recognition, pages 24372446, 2019. 3 Matthew Tancik, Vincent Casser, Xinchen Yan, Sabeek Prad-han, Ben Mildenhall, Pratul P Srinivasan, Jonathan T Barron,and Henrik Kretzschmar. Block-nerf: Scalable large sceneneural view synthesis. In Proceedings of the IEEE/CVF Con-ference on Computer Vision and Pattern Recognition, pages82488258, 2022. 2 Dayang Wang, Shuo Han, Yongshun Xu, Zhan Wu, Li Zhou,Bahareh Morovati, and Hengyong Yu.Lomae:Simplestreamlined low-level masked autoencoders for robust, gen-eralized, and interpretable low-dose ct denoising. IEEE Jour-nal of Biomedical and Health Informatics, 2024. 1, 3",
  "Gengsheng Lawrence Zeng. Medical image reconstruction.Springer, 2010. 1, 3": "Ruyi Zha, Yanhao Zhang, and Hongdong Li. Naf: neuralattenuation fields for sparse-view cbct reconstruction. In In-ternational Conference on Medical Image Computing andComputer-Assisted Intervention, pages 442452. Springer,2022. 1, 2, 3, 5 You Zhang, Hua-Chieh Shao, Tinsu Pan, and TieligeMengke. Dynamic cone-beam ct reconstruction using spatialand temporal implicit neural representation learning (stinr).Physics in Medicine & Biology, 68(4):045005, 2023. 3 Li Zhou, Dayang Wang, Yongshun Xu, Shuo Han, BaharehMorovati, Shuyi Fan, and Hengyong Yu. Gradient guidedco-retention feature pyramid network for ldct image denois-ing. In International Conference on Medical Image Com-puting and Computer-Assisted Intervention, pages 153163.Springer, 2024. 3",
  ". Attenuation Initialization Analysis": "We present additional experiments to extend the analysis ofattenuation initialization strategies discussed in Sec. 4.3 ofthe main paper. These experiments focus on two key as-pects: the role of pre-initialization algorithms and the im-pact of different interpolation methods. By providing fur-ther insights into these components with both quantitativeresults and qualitative visualizations, we aim to highlighttheir impacts on the overall CT reconstruction quality andvalidate the robustness of leveraging attenuation priors.Pre-initialization Algorithms Analysis: The first partof this analysis, as demonstrated in Tab. 5 and , eval-uates the performance of different pre-initialization algo-rithmsFDK, CGLS, and ASD-POCSusing the nearestinterpolation method. The findings reveal that FDK consis-tently provides superior initialization for both -NAF and-SAX-NeRF models, achieving the best balance betweendetail preservation and reconstruction quality. While theASD-POCS excels in some specific scenarios, its smooth-ing tendency often reduces fine detail accuracy, makingFDK the preferred choice for reliable initialization.Interpolation Methods Analysis: The second part ofthis analysis, shown in Tab. 6 and , investigates theimpact of interpolation methodsNearest, Mean, and Tri-linearon reconstruction performance when using FDK asthe pre-initialization algorithm. These experiments evalu-ate -NAF and -SAX-NeRF models across the same fivecases. Nearest interpolation generally demonstrates betterperformance due to its ability to preserve sharp boundaries,particularly in simpler cases like Foot and Chest. Trilinearinterpolation, however, provides competitive or superior re-sults in more complex scenarios such as Aneurism and Bon-sai, benefiting from smoother transitions across voxel grids.This analysis underscores the adaptability of interpolationtechniques and their critical role in optimizing reconstruc-tion outcomes."
}