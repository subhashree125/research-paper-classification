{
  "Abstract": "Various pose estimation and tracking problems inrobotics can be decomposed into a correspondence estima-tion problem (often computed using a deep network) fol-lowed by a weighted least squares optimization problem tosolve for the poses. Recent work has shown that couplingthe two problems by iteratively refining one conditionedon the others output yields SOTA results across domains.However, training these models has proved challenging, re-quiring a litany of tricks to stabilize and speed up training.In this work, we take the visual odometry problem as anexample and identify three plausible causes: (1) flow lossinterference, (2) linearization errors in the bundle adjust-ment (BA) layer, and (3) dependence of weight gradients onthe BA residual. We show how these issues result in noisyand higher variance gradients, potentially leading to a slowdown in training and instabilities. We then propose a sim-ple, yet effective solution to reduce the gradient variance byusing the weights predicted by the network in the inner opti-mization loop to weight the correspondence objective in thetraining problem. This helps the training objective focuson the more important points, thereby reducing the varianceand mitigating the influence of outliers. We show that theresulting method leads to faster training and can be moreflexibly trained in varying training setups without sacrific-ing performance. In particular we show 22.5 trainingspeedups over a baseline visual odometry model we modify.",
  "(b) We identify three factors that lead to high variance in gradients duringtheir training": ". We propose a simple, yet effective solution to stabi-lize and speed-up the training of SOTA pose estimation meth-ods. (b) We first analyze the causes for their instability relatedto variance in their gradients, and (a) then mitigate them by usingweights from the inner-loop optimization to weigh the correspon-dence outer objective, which leads to improved performance.",
  "tleness not being robust to outliers in the data or havingpoor accuracy in unseen scenes": "More recently, approaches that combine the best of bothworlds in learning to optimize have demonstrated substan-tially better performance than previous methods . These approaches combine a learned iterative updateoperator that mimics an optimization algorithm with im-plicit layers that enforce known geometric constraints onthe outputs. This general architecture has appeared across",
  "arXiv:2406.07785v1 [cs.CV] 12 Jun 2024": "many tasks even beyond pose estimation , wherein each case an accurate and robust task-specific optimiza-tion solver is learned. In , for the task of poseestimation, a recurrent network that iteratively updates poseand depth is learned through a differentiable weighted bun-dle adjustment (BA) layer that constrains the updates. Fea-ture correspondences are also iteratively refined togetherwith the poses, thereby dynamically removing outliers andleading to better accuracy.Although these methods achieve state-of-the-art (SOTA)results, they take exceedingly long to train. mentionthat DROID-SLAM takes 1.5 weeks to train with 4x RTX3090, while mention that DPVO takes 3.5 days to trainon a RTX 3090. Likewise, in our experiments, training theobject pose estimation method from took 1 week with2x RTX 6000 for the smallest dataset reported in their paper.In this paper, we first investigate the reasons for the slowtraining convergence speeds of these methods, using deeppatch visual odometry (DPVO) as an example problemsetting for this analysis. We find that the bundle adjustmentlayer and the associated losses used in this setting lead toa high variance in the gradients. We identify three reasonscontributing to the high variance. First, improper credit as-signment arising from the specific choice of flow loss usedwhich leads to interference between the gradients of outlierand inlier points. Second, improper credit assignment aris-ing from the linearization issues in the bundle adjustmentlayer. And lastly, the dependence of the weight gradientson the residual of the BA objective resulting in the outliersdominating those gradients. We show how each of theseproblems lead to an increase in the gradient variance.Next, we leverage the analysis to propose a surpris-ingly simple solution to reduce the variance in gradientsby weighting the flow loss according to the importanceof the points for the problem, resulting in significant im-provements in training speed and stability while achievingbetter pose estimation accuracy. We also experiment withother variance reduction techniques and demonstrate thesuperior performance of our proposed solution (AppendixSec. 8.7). Using DPVO as an example, we demonstrate2-2.5x speedups with these simple modifications. Further-more, we show that the modifications also make the train-ing less sensitive to specific training setups. As a result, weare able to train in a non-streaming setting, while reachingsimilar accuracies in the streaming setting, thereby lead-ing to a further 1.2-1.5x speedup in training. Lastly, weapply the modifications to DROID-SLAM with littlehyperparameter tuning to show that the proposed modifica-tions transfer to a completely new pipeline providing sim-ilar speedups and stable training. Furthermore, we showthat our best models achieve about 50% improvement onthe TartanAir validation set and a 24% improvement on theTartanAir test set. To summarize, the contributions of this paper are as follows: We identify three candidate reasons for high variance inthe gradients when differentiating through the BA prob-lems for Visual Odometry (VO) and SLAM and showhow they are all affected by the presence of outliers.",
  "Using DPVO as an example VO pipeline, we proposea simple modification to the loss function that reduces thevariance in the gradients by mitigating the effect of out-liers on the objective": "We show that the above modification results in signifi-cant speedups and improvements in accuracy of the modelon the TartanAir validation and test splits used inthe CVPR 2020 challenge.Further, we show that themodifications can be applied out-of-the-box to other set-tings/methods that use differentiable BA layers, such asDROID-SLAM and the non-streaming version of DPVOto obtain similar benefits.",
  ". Related Work": "Pose Estimation using Deep Learning.A large bodyof works have tackled pose estimation, and we describe afew representative works that use deep learning here. Fora broader overview, we refer the reader to . proposed deep networks to directly estimateego pose between pairs of frames. integratelearned representations (features or depth) into traditionalego-pose estimation pipelines. imposed geo-metric constraints on ego-pose network outputs via differ-entiable optimization layers. Similar approaches have beenproposed for the task of multi-object pose estimation where2D-3D correspondences are directly regressed andthen passed through a differentiable PnP solver forpose estimation.Overall, these works showed that deeplearning could be applied to these tasks but fell short in ac-curacy and generalization.Optimization-inspired iterative refinement methods havebeen applied to ego-pose and exo-poseestimation where the network iteratively refinesits pose estimates as an update operator in order to sat-isfy geometric constraints.More recently, methods thatiteratively refine poses and correspondences in a tightly-coupled manner have been proposed . In theseworks, a network predicts patch correspondences ordense flow which are then updated together withposes and depths in an alternating manner where one feedsinto the other through differentiable geometric operations.In addition to correspondences, these methods also predictweights for the correspondences which have been shown tobe important for pose estimation accuracy in many indepen-dent works . Overall, these iterative methodshave achieved impressive performance in terms of accuracyand generalization, but they still need large GPU memories and their training times are prohibitively long which has limited their adoption for research.Challenges with Implicit Optimization Layers.Withthe advent of implicit layers, it is possible to incorporatean optimization problem as a differentiable layer ,which captures complex behaviours in a neural network.The BA layer used in this work is an instance of suchlayers. In the forward pass, an implicit optimization layersolves a regular optimization problem given the current es-timate of problem parameters. In the backward pass, onedifferentiates through the KKT conditions of the optimiza-tion problem to update the problem parameters.While these implicit optimization layers boast expres-sive representational power, there exist challenges with suchlayers. Firstly, these problems naturally take on a bilevelstructure, where the inner optimization learns the problemparameters and the outer problem optimizes for the deci-sion variables given the current estimation of problem pa-rameters. As a result, these problems are inherently hardto solve, as their easiest instantiation, e.g., lin-ear programs for both inner and outer problems, can benon-convex . While the convergence issues may be al-leviated by techniques such as using good initialization or robust solvers, there does not exist a general solutionto the authors best knowledge. Secondly, a range of nu-merical issues can arise from implicit optimization layers.The gradients derived from KKT conditions are only validat fixed points of the problem. In practice, the solver mayneed to run long enough to reach a fixed point or a fixedpoint may not exist at all . The problem may be ill-conditioned due to reasons such as stiffness or discontinu-ities from physical systems or compounding of gradi-ents in chaotic systems . A number of problem-specificsolutions have been proposed to these prob-lems. For example, use zeroth-order methods todeal with non-smoothness and non-convexity in the prob-lem. use interior point relaxations to smooth thediscontinuities. Similarly, use penalty-based relax-ations to handle the discontinuities. Its also common toregularize the inner problem during the backward pass todeal with ill-conditioning . However, given the vast-ness of the problems, we are of the opinion that this is stilla broadly under-studied area.",
  ". BackgroundIn this section, we review the approach of DPVO foriterative ego-pose estimation, which serves as an examplesetting for all our analysis and experiments": "Feature Extraction.A scene, as observed from an inputvideo, is represented as a set of camera poses Tj SE(3)and square image patches Pk. Patches are created by ran-domly sampling 2D locations in the image and extractingp p feature maps centered at these coordinates pk. A bi-partite patch-frame graph is constructed by placing an edge",
  "between every patch k and each frame j within distance rof the patch source frame. The reprojections of a patch inall of its connected frames form the trajectory of the patch": "Update Operator.The update operator iteratively up-dates the optical flow of each patch over its trajectory. Theoperator updates the embedding of each edge (k, j) of thepatch graph via temporal convolutions and message pass-ing. These updated embeddings are used by two MLPs topredict flow revisions jk R2 and confidence weightsfor each patch jk R2 between . The flow revi-sions are used to update the reprojected patch coordinatespjk := pjk + jk, which are passed to a differentiable BAlayer along with their confidence weights jk. Differentiable Bundle Adjustment.The bundle adjust-ment (BA) layer solves for the updated poses and depthsthat are geometrically consistent with the predicted flow re-visions. The BA layer operates on a window of the patchgraph to update the camera poses and patch depths, whilekeeping the revised patch coordinates pjk fixed. The BAobjective is as follows:",
  "(k,j)||pjk (Tij, 1(pk, dk))||2jk(1)": "where denotes the projection operation, dk denotes thedepth of the kth patch in the source frame i, and Tij is therelative pose TiT1j . This objective is optimized using twoGauss-Newton iterations. The optimized poses and depthsare then passed back to the update operator to revise thepatch coordinates, and so on in an alternating manner. Training Loss.The network is supervised using a flowloss and pose loss computed on the intermediate outputs ofthe BA layer. The flow loss computes the distance betweenthe ground truth patch coordinates and estimated patch co-ordinates over all the patches and frames:",
  "j,kpjk pjk2(2)": "where pjk = (Tij, 1(pk, dk)) and pjk is the cor-responding reprojection of patch k in frame j using theground truth pose and depth. Note that this loss amountsto a difference in the patch coordinates and not in the flowsas the source patch coordinates in each flow term cancel out.The pose loss is the error between the ground truth posesG and estimated poses T for every pair of frames (i, j):",
  "L = 10Lflow + 0.1Lpose(4)": "The original DPVO model is trained on random se-quences of 15 frames, where the first 8 frames are used to-gether for initialization and the subsequent frames are addedone at a time. Their model is trained for 240K iterationsusing 19GB of GPU memory which takes 3.5 days on anRTX 3090. A total of 18 iterations of the update operatoris applied on each sequence, where the first 8 iterations areapplied during initialization as a batch-optimization, and thesubsequent iterations are for every new, added frame. In ourpaper, we refer to these update iterations as the inner-loopoptimization, this mode of training as the streaming set-ting, and training models in our experiments to only batch-optimize the first 8 frames as the non-streaming setting.",
  "k,jTi(Tij, (pk, dk)).(5b)": "Thus, the gradients with respect to each reprojected patchpjk gets aggregated in the computation graph at the corre-sponding depth dk (likewise for poses Ti, Tj) at the outputof the BA layer. This becomes problematic when a signif-icant fraction of the projections are noisy/outliers, as thenoisy/outlier gradients would dominate the inlier gradientsin the sum in Eq. 5a, leading to more noise in the total gra-dient estimate.Since these gradients are also backpropagated throughthe BA layer, it results in noisy gradient estimates for thenetwork parameters as well. Specifically, in the BA layer,each di/Ti are again a function of all the predicted flows andweights associated with that point/frame. Thus, the samenoisy gradient computed at di/Ti, gets backpropagated toall the associated points. This leads to the gradient estimatesbeing noisy even at the good predictions by the network.",
  "(dL)T (JTd Jd)1JTd diag(r)(6b)": "where, r = (pkj pkj) is the bundle adjustmentresidual, Jd and JT are the jacobians of the projection(Tij, 1(pk, dk)) with respect to depth d and pose Trespectively. This expression can be derived by applyingthe implicit function theorem (Theorem 1B.1) , on theBA problem as shown in Appendix Sec. 8.3.Since the projection is non-linear containing multiplemultiplicative operations, we observe that the Jacobians Jdand JT themselves are a function of d and T. Thus, a highvariance in the initialized d or T naturally lead to a highvariance in the Jacobians, thereby leading to a high vari-ance in the corresponding gradients and , which arethen backpropagated through the network. In our setup, dis initialized to random values and T is initialized to iden-tity. Thus, the variance from linearization is primarily con-tributed by the linearization around the current d.The use of a weighted objective in the BA problem par-tially mitigates this issue by masking out the gradients onthe flows corresponding to the outlier points (which con-tribute the most to this high variance). However, the highvariance remains problematic especially in the initial itera-tions of training (when the weight estimates themselves arenot very accurate) and in the initial iterations of the inner-loop optimization when a large fraction of the depth andpose estimates are inaccurate.",
  ". Dependence of weight gradients on the BAresidual": "In the previous section, we discussed the effect of outlierson the BA linearization and consequently on the gradients.However, outliers in the BA problem contribute to an in-crease in gradient variance in a more straightforward way.Specifically, they have a direct effect on the gradient of theweights, as can be seen from the expression in Eq. 6b. Theexpression shows the direct dependence of the weight gra-dients on the residual, r = (pjk pjk), of the BA problem.Thus, the presence of high residual points in the optimiza-tion problem result in high variance in the weight gradients.In fact, the presence of outliers also biases the weightgradients towards highly positive values as the training ob-jective tries to reduce the influence of the outliers. Thisconsequently leads to a collapse in the weight distribution.However, we observe that a straightforward fix used by prior work, i.e, clipping the magnitude of gradientpassing through the weights easily mitigates this bias. Wediscuss more details on this effect with a simple illustrativeexample in Appendix Sec. 8.4.To summarize, the above section highlights various as-pects of the existing setup that contribute to noisy/high vari-ance gradients. The noise and high variance in gradient es-timates leads to ineffective parameter updates, thereby lead-ing to training instabilities and slowdown. Furthermore, itsalso important to note that the aforementioned effects ex-acerbate each other. For example, worse weight estimatesresult in bad BA outputs, which in turn contribute to wors-ening the flow loss interference and BA linearization errors,which further leads to noisier gradients thereby slowingdown weight/flow updates, thus repeating the vicious cycle.By the same argument, mitigating either of these effects canalso provide significant improvements on other problems!",
  ". A very simple solution: Weighted flow loss": "We start with observing that all three problems mentionedin the previous section get exacerbated by the presence ofoutliers or computing gradients through outliers. So the nat-ural question is if there exist obvious solutions to mask outthe outliers in the outer training problem.One of the tricks used by already partially ac-counts for this in the pose loss, i.e, they do not include thepose loss for the first couple of inner-loop iterations, therebymitigating some of the issues discussed in Sec. 4.2. Thissimple modification in seems to provide a signif-icant boost in training speeds as we show in our ablationexperiments in Appendix Sec. 8.6.Similar heuristics for the flow loss are harder to find asthe depth/flow estimates of a significant fraction of pointsare bad even at the latter inner-loop iterations. Convention-ally, SLAM and visual odometry problems define heuristickernels on the flow residuals depending on the ex-pected distribution of residuals/errors to trade-off betweenrobustness and accuracy. Unfortunately, coming up witha similar simple/consistent heuristic to define outliers inthe outer training problem is more challenging as the errorsand distribution of errors vary across examples, training it-erations and inner optimization iterations. This requires aheuristic that adapts to the specific example, training con-vergence, and inner-loop optimization iteration.Conveniently, we find that the weights learnt by the innerupdate operator for the bundle adjustment problem satisfyall these properties as they adapt online with the changingdistribution of errors/residuals. Moreover, empirically weobserve that the network learns a reasonable weight distri-bution very early on in training, while adapting the weightdistribution rapidly to any changes in flows. Thus, we ob-serve that using these weights to weight the flow loss works",
  "j,kpjk pjkjk(7)": "where denotes the stop gradient operator to prevent theobjective from directly driving the weights to zero (We pro-vide more discussion on what factors prevent these weightsfrom collapsing to zero in Appendix Sec. 8.5). The maindifference between this and Eq. 2 is that each residual inthis objective is weighted by the weights jk predicted bythe network for the inner BA problem. Intuitively, this ob-jective incentivizes the network to focus on the points whichare important for the inner optimization problem at that op-timizer step / training iteration for that particular example.Although the modification seems trivial and obvious inhindsight, we observe that it is significantly more effectivethan various other (more complicated) variance reductionapproaches we tried (studied in Appendix Sec. 8.7). Thisapparent simplicity and effectiveness underscore the valueof the proposed modifications!Balancinglossgradients.Theintroductionoftheweighted flow loss changes the gradient contribution fromthe flow loss throughout training as the weight distributionchanges. Thus, instead of using fixed coefficients to trade-off between pose and flow loss as in Eq. 4, we periodically(every 50 training iterations) update the flow loss coefficient to ensure the gradient contributions of the pose and flowloss remain roughly equal throughout training. Given theinfrequency in these updates, they barely affect the trainingspeed and hence are cheap to compute amortized over theentire training run.",
  ". Results and Analysis": "We analyze the effect of the factors discussed in Sec. 4 onthe original DPVO model on the TartanAir dataset. Wethen analyze a version trained with our proposed weightedflow objective. We show that the weighted objective helpsincrease the signal to noise ratio in the gradients throughouttraining and show the improvements in performance as a re-sult. We also evaluate the pose estimation performance ofthis version on the TartanAir , EuRoC , and TUM-RGBD benchmarks. We use the average absolute tra-jectory error (ATE) after Sim(3) alignment of the trajecto-ries, as the evaluation metric for pose estimation.",
  "(c) Impact of pose noise on flow loss gradients": ". (a) We compute the signal-to-noise ratio (SNR) in the loss gradients as we artificially add depth noise while linearizing the BAproblem for gradient computation. We observe that the SNR in the flow loss deteriorates rapidly indicating its sensitivity to linearizationerrors. (b) We artificially add noise to a subset of depths right before the flow loss computation. We show the average gradient errors on allthe pose and clean depth variables as a result of the added noise. We see a monotonic increase in gradient error in pose gradients as weincrease the noise added showing the impact outliers have on the gradients of even the inlier variables. (c) Similar to (b), here we addnoise to the the first frames pose and show the gradient errors on the rest of the frames and depths. to the depth used to compute the Jacobians in the BA prob-lem. We leave the rest of the forward and backward passunaltered and only add noise to the depth while computingthe linearization for the backward pass in the BA problem.This helps us isolate the effects of linearization on the gradi-ent computations. Specifically, a shows the signal-to-noise ratio (SNR) of the flow and pose loss gradients withrespect to with increasing levels of noise. The SNR iscomputed assuming the no-depth-noise gradient as the truesignal and treating any deviations from it as noise. The SNRcomputation details are provided in Appendix Sec. 8.8. Thisyields two interesting observations. First, the SNR deteri-orates rapidly in the beginning indicating that the gradientsare indeed sensitive to the noise in the iterates used for lin-earization. Second, the SNR in the flow loss gradients ishigh initially, but deteriorates rapidly compared to the poseloss gradients with increasing noise. This highlights theneed to make flow loss robust to noisy points.To analyze the effect of flow loss on the gradient noise(Sec. 4.1), we introduce noise on a few depth points or asingle frame pose right before computing the flow loss andstudy the effect of the noise on the gradients of all the otherpoints/poses. c shows a monotonic increase in gradi-ent errors on the depths as well as all poses as we increasethe noise added to the first pose. Likewise, b showsthe monotonic increase in gradient errors of all poses as weadd increasing amounts of noise to all depths on the firstframe. This shows how outliers with increasingly large er-rors can have an increasingly adverse effect on the gradientsof the non-outlier points/frames as well. The gradient er-rors are computed as the average L2 norm of the deviationin gradient from the no-noise gradients.We analyze the weight residual dependence (Sec. 4.3)and the resulting variance / bias in Appendix Sec. 8.4, as itsconnections to the use of weighted loss are less direct.",
  "Train Step": "0.1 0.2 0.3 0.4 0.5 0.6 0.7 SNR Weighted flow lossFlow loss . We compute the signal-to-noise ratio in the gradients ofthe flow loss and the weighted flow loss w.r.t flow network param-eters at different training iterations of the base model. Specifically,we use the last linear layers weights of the flow computation headof the network. We find that the weighted flow loss gradients havea higher SNR throughout the training. This is especially true in theinitial iterations of training when the outlier count is very high.",
  ". Effect of the weighted flow loss on training": "To understand the effect of the weighted flow loss on thevariance of the gradients, we study the SNR of the gradientson the flow network parameters. shows the SNR withthe flow loss and the weighted flow loss at different pointsduring training. The SNR computation details are providedin Appendix Sec. 8.8. The plots clearly demonstrate thatthe usage of weighted flow loss results in a boost in SNRthroughout training. The boost is especially prominent inthe initial stages of training, when the impact of outliersand noise in the pose/depth estimates are most significant.This clearly shows the promise of using the weighted flowloss instead of the regular flow loss for training.",
  "Training Iteration": "ATE (meters) Ours (all steps pose loss) Ours . We plot the median validation ATE across three trials ofour method and our method with pose loss added to all the iterates.We observe a clear deterioration in performance when adding thepose loss to the first two inner loop iterates as well. These ablationsare performed on the non-streaming 8-step version of the problem. achieving varying degrees of success. We discuss a few ofthem in this section and compare them against our proposedmodification. shows the corresponding validationplots on the non-streaming 8-step version of the problem.(a) Removal of pose loss from initial inner-loop itera-tions: As discussed in the previous section, removing thepose losses from the first few inner-loop iterations ()is very effective in reducing the variance and indeed we in-corporate this change during our training.(b) Pose and flow interpolation using ground truth:Given that we have access to ground truth flow and posesduring training, we could interpolate between the pose/flowestimated by the network and the ground truth in order to re-duce the variance of the iterates. We vary the interpolationcoefficient such that we move from the ground truth distri-bution at the beginning of training to the model distributiontowards the end of training. While this indeed reduces thevariance, the interpolation adds a bias due to the distributionshift over training resulting from changing the interpolationcoefficients. The other issue here arises from having to alsointerpolate the hidden state in an ad-hoc manner to accountfor the interpolated poses/flows.(c) Grad Correction using ground truth flows:Theground truths can alternatively also be used to correct thegradients. Specifically, we clip the gradients on the flows atthe input of the BA layer that arent aligned with the groundtruth (pjkpjk pjk) to zero or reverse the sign. We ob-serve that this and other similar methods for gradient correc-tion bias the gradient, resulting in worse final performance,despite speeding up training in the initial iterations. Onecould potentially consider using this in the initial iterationsof training to obtain the initial speedups and then switching",
  "DPVO0.1350.0380.0480.0400.0360.3940.0340.0640.0120.089Ours0.1450.0260.0440.0640.0310.4340.0450.0460.0120.094": ". ATE [m] results on the freiburg1 set of TUM-RGBD . We evaluate monocular visual odometry, and is identical to theevaluation setting in DPVO . For all methods, we report the median of 5 runs. (x) indicates that the method failed to track. Theperformance of our model is similar to DPVO.",
  ". Test results for pose estimation": "We report pose estimation results on the TartanAir test-split from the CVPR 2020 SLAM competition in Tab. 1,and compare to results from other baseline methods asreported in DPVO .Traditional optimization-basedapproaches such as ORB-SLAM3 , COLMAP ,DSO fail to track accurately and have absolute trajec-tory errors (ATE) in the order of meters. Iterative learning-based DROID-SLAM and its variant without globalloop-closure correction (DROID-VO) show reasonable per-formance, but DPVO is able to show much better accu-racy by only tracking a sparse number of patches instead ofdense flow. Our modified version, is able to show even bet-ter accuracy with a 24% lower error on average. Morever,we observe that our model outperforms DPVO on all buttwo sequences in the dataset. Using the same models trainedon the TartanAir train set, we also report the results on theEuRoC and the TUM-RGBD benchmark datasetsin Tab. 2 and Tab. 3. Here, we obtain similar performanceto DPVO. This suggests that, although the weighted flowloss helps improve the model accuracy on similar datasets, itdoesnt resolve generalization issues related to domain shiftfrom the TartanAir dataset to the real world.",
  "In this paper, we analyze the high variance in gradients dur-ing the training of pose estimation pipelines that use differ-": "entiable bundle adjustment layers. We identify three plau-sible causes for the high variance and show how they leadto slower training and instability. We then propose a simplesolution for these problems involving a weighted correspon-dence loss. We implement this on a SOTA VO pipeline anddemonstrate improved training stability and a 2.5x trainingspeedup. We also observe a 24% accuracy improvement onthe TartanAir test split and similar accuracy as the vanillamodel on other benchmarks. Unsurprisingly, the modifi-cations dont automatically improve the models ability totackle distribution shift. We also observe that the depth ac-curacy for low-weight points, which might be important fordense SLAM approaches, deteriorates.We see our work as an initial attempt at understand-ing the numerical issues stemming from the usage of bun-dle adjustment layers and optimization layers more broadlywithin deep learning pipelines. There are likely more fac-tors contributing to issues like slower training, instabilityand generalization. We believe this broader area is relativelyunder-studied and requires more research to fully leveragethe structure found in various real world problems.",
  "Keenan Burnett, David J Yoon, Angela P Schoellig, and Tim-othy D Barfoot.Radar odometry combining probabilisticestimation and unsupervised feature learning. In Robotics:Science and Systems, 2021. 2": "Michael Burri, Janosch Nikolic, Pascal Gohl, ThomasSchneider, Joern Rehder, Sammy Omari, Markus W Achte-lik, and Roland Siegwart. The euroc micro aerial vehicledatasets. The International Journal of Robotics Research,2016. 5, 8 Cesar Cadena, Luca Carlone, Henry Carrillo, Yasir Latif,Davide Scaramuzza, Jose Neira, Ian Reid, and John JLeonard. Past, present, and future of simultaneous localiza-tion and mapping: Toward the robust-perception age. IEEETransactions on robotics, 2016. 2 Carlos Campos, Richard Elvira, Juan J Gomez Rodrguez,Jose MM Montiel, and Juan D Tardos. Orb-slam3: An accu-rate open-source library for visual, visualinertial, and mul-timap slam. IEEE Transactions on Robotics, 2021. 8",
  "Johannes L Schonberger and Jan-Michael Frahm. Structure-from-motion revisited. In CVPR, 2016. 8": "Jurgen Sturm, Nikolas Engelhard, Felix Endres, WolframBurgard, and Daniel Cremers. A benchmark for the evalua-tion of rgb-d slam systems. In 2012 IEEE/RSJ internationalconference on intelligent robots and systems, 2012. 5, 8 Hyung Ju Suh, Max Simchowitz, Kaiqing Zhang, and RussTedrake. Do differentiable simulators give better policy gra-dients? In International Conference on Machine Learning,pages 2066820696. PMLR, 2022. 3",
  "Benjamin Ummenhofer, Huizhong Zhou, Jonas Uhrig, Niko-laus Mayer, Eddy Ilg, Alexey Dosovitskiy, and ThomasBrox.Demon: Depth and motion network for learningmonocular stereo. In CVPR, 2017. 2": "Sen Wang, Ronald Clark, Hongkai Wen, and Niki Trigoni.Deepvo: Towards end-to-end visual odometry with deep re-current convolutional neural networks. In IEEE Int. Conf.Robotics and Automation, 2017. 1, 2 Wenshan Wang, Delong Zhu, Xiangwei Wang, Yaoyu Hu,Yuheng Qiu, Chen Wang, Yafei Hu, Ashish Kapoor, and Se-bastian Scherer. Tartanair: A dataset to push the limits ofvisual slam. In 2020 IEEE/RSJ International Conference onIntelligent Robots and Systems (IROS), 2020. 2, 5, 8",
  ". Acknowledgements": "SG was supported by a grant from the Bosch Center for Ar-tificial Intelligence. KR was partially supported by the ERCAdvanced Grant SIMULACRON. We would like to thankZhengyang Geng, Michael Kaess, Dan Mccgann, AkashSharma and numerous others for various brainstorming ses-sions and feedback during the initial stages of the project.We would also like to thank the authors of DPVO andDROID-SLAM for open sourcing their code and mak-ing it easy to use.",
  "Iterations": "0.1 0.2 0.3 0.4 0.5 Average weight values OursOurs (No Grad Clip) . We plot the mean weight values of our method and ourmethod without the weight gradient clipping throughout training.We observe a clear reduction in the weight magnitudes in the vari-ant without gradient clipping suggesting a clear positive bias in theweight gradients in this variant. These ablations are performed onthe non-streaming 8-step version of the problem.",
  "(f fi). (19)": "This gradient is positive when (f fgt)(f fi) < 0 giventhe weights are positive. In the presence of an outlier fkwith high weight k, the least squares solution f is biasedtowards fk. Thus, the corresponding (f fgt)(f fk) <0, thereby resulting in a highly positive gradient kLgiven the high residual.In our original stochastic parameterized problem, eachi = (x) is parameterized by a network followed by asigmoid. Thus, the outliers with small i dont contributemuch to the gradient due to the sigmoid saturation. How-ever, the outliers with large i contribute significantly tothe gradient. Given the outliers with large i are inclinedto get a highly positive gradient kL as shown above, weobserve an overall positive shift in the gradient values inthe presence of outliers. If not handled carefully, this canpotentially result in a collapse in the weight distribution tonear zero values.One of the architecture hacks used by , i.e, clip-ping the magnitude of gradient passing through the weights,incidentally already mitigates this issue to a large extent :",
  "wiL := max(min(iL, max), min)(20)": "where min and max are the minimum and maximum gradi-ent value thresholds. shows the average weight mag-nitudes for the last optimization iterate on two training runs,with and without the gradient clipping throughout training.We observe a clear reduction in the weight magnitudes asa result of removing the gradient clipping. This is espe-cially pronounced in the initial iterations of training whenthe number of outliers are high.Interestingly, we observe that this change in the weightdistribution does not have much effect on the performanceof the model itself as shown in . The validation scoresof the two models are similar throughout training. This phe-nomenon likely reflects the resilience inherent in the archi-tecture and inference methodology used in this work.However, we believe that the positive bias in weight gra-dients can result in training instabilities in other settingsthat involve differentiable weighted least squares problemsif not handled carefully. We thus include it in our discus-sions in this paper for a complete treatment although theydont seem to have a direct negative effect in the specificsettings we investigate in this paper.",
  ". Weight collapse": "The analysis in the previous section raises an interestingquestion about our specific setting, given that any collapsein weight values will significantly affect our training setupas the weights appear explicitly in the loss. However, aspointed earlier, empirically we dont observe any weightcollapse. This raises two important questions. Why do theweights not collapse? Does our setting have any natural regularization that prevents such a weight collapse? We at-tempt to answer these questions as follows. The positive bias in the weight gradients described in theprevious section indeed exists resulting in the weight dis-tribution being somewhat more conservative than neces-sary. However, this positive bias only results in this con-servative offset instead of a total collapse in the weightvalues due to gradient clipping and the fraction of outliersbeing relatively minimal. Hence, this isnt problematicas a significant fraction of the weights still remain prettyhigh () thereby providing sufficient training signal. We detach the weight values from the computation graphused in the loss to enforce the stop grad operation (Sec-tion 5). Hence, the loss grads dont directly contributetowards reduction of weight values.In fact, we showthe analytical gradient w.r.t.the weights when differ-entiating through a simplified least squares problem inEq. 18. An additional multiplication by the weight onthese grads simply changes the individual grad magni-tudes and doesnt change the direction. Furthermore, ata distributional level, we observe that the weight valuesbetween the two runs (weighted and unweighted) remainroughly similar throughout training. Due to the presence of both pose and flow loss, even ifthe weight values are reduced for some arbitrary reason,that would lead to a temporary reduction in the contribu-tion of flow loss to the overall loss. This results in anincrease in the contribution of pose loss gradients, act-ing as a buffer in case weights suddenly start collapsing(which we dont observe empirically). However, we ac-knowledge that the first two inner-loop iterations dontuse pose loss and would not have this buffer. However,given that the procedure is iterative, the network wouldlearn to correct for it from the third iteration onward.",
  ". Effect of adding pose loss to the first few innerloop iterates": "As discussed in Sec. 5, one of the tricks used by ,already offer a partial solution to mask out the outliers inthe loss, i.e., they simply do not add a pose loss on the firstfew inner loop iterates. Given the depth and pose estimatesare especially bad in the first few inner loop iterations, thisserves as an obvious solution to mitigate the gradient vari-ance resulting from the linearization issues described inSec. 4.2. shows the effect of adding the pose losson those initial iterates as well (in this case the first two it-erates). We clearly observe a degradation in performance asa result due to the increased variance in gradients.",
  ". We plot the median validation ATE across three tri-als of alternate variance reduction strategies applied on the non-streaming 8-step version of DPVO": "to regular training.(d) (Heuristic) weights using ground truth: We exper-imented with a number of heuristic weights that down-weight the outlier flows in the flow loss (Eq. 7) based ontheir distance from the ground truth. We plot one such vari-ant in that uses the following heuristic for weightcomputation in the flow loss:",
  "(pijk pijk)/m + 1);m = median(p p)": "(21)We observe an improvement over the baseline, but couldntfind any heuristic that worked better than using the network-predicted weights (ours).The experiments in this section show that although thereexist various methods for variance reduction, finding theright combination that does not add unintended bias to thegradients is a challenging task. This underscores the valueof our analysis and the significance of the performanceboost provided by our method."
}