{
  "zy deepwhite": ". LogicAL is a novel anomaly synthesis framework for unsupervised anomaly localization. (a) and (b) are real normal andanomaly examples from MVTecLOCO dataset. As shown in (f), LogicAL can generate photo-realistic anomalies that are flawless inappearance but violate the underline logic constraints, such as adding extra component and causing mismatch among components. On thecontrary, the synthetic anomalies using (c) , (d) and (e) are prone to be like structural anomalies that have faulty appearance.",
  "Abstract": "Anomaly localization is a practical technology for im-proving industrial production line efficiency. Due to anoma-lies are manifold and hard to be collected, existing unsuper-vised researches are usually equipped with anomaly syn-thesis methods. However, most of them are biased towardsstructural defects synthesis while ignoring the underlyinglogical constraints. To fill the gap and boost anomaly lo-calization performance, we propose an edge manipulationbased anomaly synthesis framework, named LogicAL, thatproduces photo-realistic both logical and structural anoma-lies. We introduce a logical anomaly generation strategythat is adept at breaking logical constraints and a structuralanomaly generation strategy that complements to the struc- tural defects synthesis.We further improve the anomalylocalization performance by introducing edge reconstruc-tion into the network structure. Extensive experiments onthe challenge MVTecLOCO, MVTecAD, VisA and MADsimdatasets verify the advantage of proposed LogicAL on bothlogical and structural anomaly localization.",
  "arXiv:2405.06875v1 [cs.CV] 11 May 2024": ". Framework of LogicAL. LogicAL converts a normal image into an anomaly image based on edge manipulation. (c) to (g) showthat it generates logical anomaly image by removing normal edges from the selected semantic regions. It syntheses structural anomalyimage by replacing normal edges in arbitrary regions with the augmented edges that are sampled from trainset, as shown in (h) to (k). haustible, it is challenging to construct a robust anomalydetector only with very limited normal data. Even thoughanomaly localization has spawned many superior unsuper-vised methods, the task is not yet completely resolved.To handle with the shortage of real anomaly data, manyappealing unsupervised approaches have arose in accompany with anomaly synthesis. As ex-amples illustrated in c-e, existing synthesis methods can only randomly destroy the appearance ofnormals shown in a and produce the anomalies hav-ing different visual structures with the normals.bshows some more challenging cases that are beyond the ca-pabilities of these synthesis methods. Each component inb is flawless but their combination violates the certainunderlying logical or geometrical constraints of the normaldata. The anomaly detectors trained only with the syntheticstructural anomalies would be vulnerable to logical anoma-lies.By comparing the difference between real logic anomaly(b) and the synthetic anomaly (d-e), we can seethat existing synthesis methods only modify dis-crete local regions and ignore the long-range dependencies.It leads to a more structure-oriented defects generation.Moreover, the fake boundaries introduced by a naive largeregion replacement make the anomaly detector learns a sim-ple decision. Therefore, a photo-realistic logical anomalysynthesis method for unsupervised anomaly localization ishighly demanded.To conquer aforementioned problems, we propose anovel anomaly synthesis and localization method LogicALfor effectively localizing anomaly pixels of both logical andstructural anomalies. illustrates overall concept ofLogicAL. To generate photo-realistic anomalies, it manipu-lates edges and converts the modified edge map into imageby using edge-to-image generator. To generate both logi-cal and structural anomalies as shown in g and k,LogicAL modifies the normal edge map by using differ- ent region selection and edge manipulation strategies. Byusing pre-trained segmentation network SAM , Logi-cAL can manipulate the edges from a semantic region. Asshown in c to g, it syntheses a logical anomalystatus that the breakfast-box is missing one orange. hto k demonstrate the structural anomaly generation. Toforge structural anomaly edges, LogicAL replaces the nor-mal edges from arbitrary regions with the augmented (flipor resize) edges that are sampled from the trainset. Besideremoving and replacing normal edges, LogicAL also usesstrategy of merging edges to syntheses more complex situ-ations of mixing logical and structural anomalies, as shownin . shows the anomaly localization frameworkthat equipped with LogicAL anomaly synthesis. It produceshigh quality reconstruction and precise anomaly localiza-tion for both logical and structural anomalies.In summary, we make following main contributions: We propose a logical anomaly synthesis method that gen-erates photo-realistic anomaly images violating underly-ing logical constraints. It fills the gap left by existingstructure-oriented anomaly synthesis methods. We introduce different edge manipulation and regionselection strategies to balance logical and structuralanomaly synthesis. By using the proposed anomaly syn-thesis, we improve existing reconstruction-based methodswithout effecting their inference runtime. We further improve the anomaly localization perfor-mance by introducing edge reconstruction into the net-work structure. We achieve superior anomaly localizationperformance, 69.7 pixel AU-sPRO and 98.3 pixel AU-ROC, on challenge MVTecLOCO and MVTecAD datasets respectively.",
  "Anomaly synthesis. Anomaly synthesis is closely pairedwith unsupervised anomaly localization methods [10, 12,": ". Visualization of our synthetic anomalies. (a) and (b)are extracted from (f). (c) is generated by merging the normaledges (b) from the selected regions of (a) with sampled edges.Anomaly image (e) is converted from (c). (d) is the differencemap between (e) and (f). 15, 3133] due to the lack of real anomaly samples. Cut-Paste propose a simple but effective method that syn-theses anomaly by cutting a local rectangular region fromthe normal image and paste it back at a random posi-tion. It learns representations by classifying normal datafrom the synthetic anomalies. SPD uses a smoothedversion of CutPaste augmentation. Extensive experi-ments from Draem show that the quality of syntheticanomaly highly effects the performance. Instead of usingsimple regular shaped anomalous, Draem carefully de-signs the anomaly regions mask by using binarized Perlinnoise.To increase the anomaly diversity, it extracts theanomaly texture from an extra DTD dataset. To simu-late photo-realistic anomaly samples, JNLD proposes amulti-scale noticeable anomalous generation method basedon just noticeable distortion .OmniAL furtherimproves the anomaly synthesis of JNLD by usinga panel-guided strategy to train a unified detector for Nclasses. Different with our method, these existing methodspay more attention on structural anomaly while ignore thelogical anomaly.To syntheses logical anomaly, SLSG extends theanomaly synthesis of Draem by controlling the pa-rameters of Perlin noise and the binarization threshold toget a more concentrated anomaly region mask. More re-cent road anomaly detection methods re-synthesizethe input image from the predicted semantic map using agenerative adversarial network.Synboost presents apixel-wise anomaly detection framework that uses uncer-tainty maps to improve over existing re-synthesis methods in finding dissimilarities between the input and gen-erated images. However, these synthesis anomalies in roadscene often introduce large difference in the normal regions.Inspired by existing methods, we propose a novel edge-controlled anomaly synthesis method that generates photo-realistic both logical and structural anomalies.Anomaly localization. Anomaly localization aims tosegment out the pixel-level anomaly regions. On the otherhand, anomaly detection refers to distinguishing anoma-lous images at the image-level from the majority of nor-mal images.Existing methods solve these two tasks ei-ther by a distance-based or reconstruction-based way. The distance-based methodsusually rely on feature extractors pre-trained on the Ima-geNet. CutPaste uses GradCAM to get pixel-levelanomaly location. SPADE relies on K nearest neigh-bors of pixel-level feature pyramids extracted by pre-traineddeep features. It detects anomaly based on alignment be-tween an anomalous image and a constant number of thesimilar normal images. Instead of using time-costly clus-tering, PaDim uses a well-known Mahalanobis distancemetric as an anomaly score. PatchCore combinespatch-level embeddings from ImageNet models with an out-lier detection model.The reconstruction-based methods use segmentation sub-network to predictthe defective regions by comparing the difference betweenreconstructed images with input.Student-teacher (S-T) network uses three differentpre-trained CNN as teachers with different receptive fields.It trains three student networks to mimic their correspond-ing teachers on the normal images. The anomaly is revealedby the failure mimic on unseen anomalous images. To bet-ter detect both logical and structural anomalies, GCAD introduces the global and local branches using S-T networks. The final prediction is obtained by merging results ofthe two branches. SLSG uses a generative pre-trainednetwork to learn the feature embedding of normal images.To model position information in images, it uses a self-supervised task to learn the reasoning of position relation-ships and use the graph convolutional network to captureacross-neighborhood position relationships. This paper dif-fers from these previous works by learning edge informa-tion from the edge-controlled synthetic anomaly.",
  ". Methods": "As shown in , the proposed method LogicAL con-sists of anomaly synthesis and anomaly localization. Theanomaly synthesis module yields photo-realistic anomaliesby globally and locally edge control. It extracts edge witha pre-trained edge detector and converts the modified edgeinto anomaly image by a pre-trained generator.Duringtraining, the anomaly synthesis module alternatively pro-vides logical and structural anomalies to the anomaly local- . Framework of proposed unsupervised anomaly localization. It consists of anomaly synthesis and localization modules.Anomaly synthesis is based on anomaly edge map construction and edge-to-image generation. Synthetic anomaly is reconstructed intonormal image, corresponding just noticeable distortion (JND) and edge maps. Anomaly localization is achieved by exploring differencebetween reconstructed and original data. ization module in real-time. The anomaly localization mod-ule learns to reconstruct various normal information andspot the difference between the reconstructed and originaldata. In testing phase, it only takes the anomaly localiza-tion module to derive the pixel-wise prediction.",
  ". Anomaly synthesis": "Edge detection. To generate photo-realistic anomalies, it isbetter to tune an intermediate representation rather than di-rectly modify the source image. Edge reveals sharp bright-ness, color or texture changes in any part of the image. Dueto its unique object-agnostic property, edge is a suitable op-tion to be the intermediate representation. With the develop-ment of deep learning, edge detection changes from the tra-ditional gradient-based method to the end-to-end learning-based method. PiDiNet is one of the appealing edge de-tectors that achieve a better trade-off between accuracy andefficiency. It integrates the advantages of traditional edgedetectors and deep CNNs by using the pixel difference con-volution. By using PiDiNet , we achieve zero-shot edgedetection for following edge control based anomaly synthe-sis. As shown in , the extracted useful edge map bis also used in training the anomaly localization module toavoid blurry reconstruction and inaccurate localization.Edge-to-image generation.As shown in , ouredge-to-image generation module converts the extractededge maps to color images with pixel-to-pixel correspon-dence. It is trained as the pix2pixHD , a conditionalgenerative adversarial network (cGAN), with pairs of edgemaps and color images from the normal dataset.Thepix2pixHD consists of a coarse-to-fine generator trans-lating edge maps to color images and a multi-scale discrim-inator distinguishing real images from the generated ones. It aims to model the conditional distribution of real imagesgiven the input edge maps via the minimax game. Consid-ering the need of generation from anomaly edge, we followDeepSIM to augment the training pairs by using thin-plate-spline (TPS) warps. The TPS augmentation si-multaneously manipulates both edge map and color imageby randomly shifting 3x3 control points in the horizontaland vertical directions. The warp is smoothed by furtheroptimization . c-d show examples of TPS warpededge map and corresponding color image. By training withthese smooth warped pairs, the generator is less likely toproduce a global collapsed result when it handles the syn-thetic or real anomaly edges.Edge manipulation.Given the pre-trained edge-to-image generator, it is supposed to generate anomaly imagesfrom the modified edge maps. Even though the generatoris trained with carefully augmented data, it still producesglobal collapsed results if the input edge maps are out-of-distribution.Supplementary demonstrates that a suitableportion of anomaly edges is the key to generate high qual-ity anomaly images. Therefore, our edge manipulation in-volves two region selection and three edge modificationstrategies.As illustrated in , the region selection strategiesconsist of semantic and semantic-agnostic regions selec-tion.We use the pre-trained segmentation model SAM to get rough semantic regions. Due to SAM isover-segmented, we further refine the segmentations by re-moving background, grouping small regions and mergingoverlapped regions and build a map of candidate regions,as shown in d. For the semantic-agnostic regions se-lection, we randomly combine three regions with differentaspect ratios or shapes. . Edge-to-image generation. (a) Normal images fromMADsim , MVTecAD and VisA , (b) Edge maps ex-tracted by PiDiNet , (c) TPS warping on (b), (d) Imagesgenerated from (c) by DeepSIM , (e) and (f) are synthesisanomaly edge maps and images applied same TPS warping. Given the selected regions, we modify the normal edgesby removing, replacing or merging strategies.The can-didate anomaly edges are derived from the normal edgesbelong to the same class. By doing these edge modifica-tions, it is easier to yield the logical anomalies that violatethe constraints of amount, position, matching, etc. shows examples of synthetic anomalies for MVTecLOCO dataset. As the ambiguity exists between structural andlogical anomalies, different strategies are not always strictlycorrespond to either logical or structural anomalies. Thesemodifications also can fake the structural anomalies, suchas scratches, dents, or contaminations.Given the j-th normal image Ij, the correspondinganomaly image IAj is generated as follow:",
  "Mj (A(Ei) + Ej 1) + (1 Mj) Ej, merge": "(1)where Ej is the source normal edge map extracted fromIj, Ei is the candidate anomaly edge map extracted fromthe i-th normal image Ii, A indicates random augmentationapplied to Ei, the source anomaly edge map Ej is the com-bination of the augmented candidate anomaly edge mapsA(Ei), Mi is the selected regions mask. As shown in eand f, the synthesis anomaly edge map and image canbe further augmented by applying TPS warping.",
  ". Anomaly localization": "Overall, our anomaly localization module follows the net-work structure of OmniAL that consists of reconstruc-tion and localization sub-networks equipped with dilatedchannel and spatial attention (DCSA) blocks and DiffNeckmodule. The normalized just noticeable distortion (JND)map reveals a perceptual threshold of inten-sity change in an image that can be noticed by the humanvision system. For both JND map and normal image recon- struction, we not only use MSE loss to supervise the pixel-to-pixel recovering but also the structural similarity (SSIM) loss to yield plausible local consistency. Different fromOmniAL , we introduce edge information to the learn-ing flow. In addition to learn to reconstruct the normal im-age and JND map, the reconstruction sub-network also pro-duces the edge map. Following PiDiNet , we adopt theannotator-robust loss function proposed in for the re-constructed edge maps. To localize anomaly regions moreprecisely, the localization sub-network calculate the recon-struction error with the assistance of edge maps.To train the localization sub-network, we can constructthe ground truth maps by comparing the synthetic anomalyimages with either the source normal images or the gen-erated images from the normal edges. Due to the error ofedge-to-image generator, the normal regions in the gener-ated and the original images are not exactly same. It is im-possible to localize anomaly region simply from the gen-erated images. The SSIM provides a measure of thesimilarity by comparing two images based on luminancesimilarity, contrast similarity and structural similarity infor-mation. To avoid constructing an over-sensitive anomalydetector, we use SSIM to calculate the ground truth mapswith both generated normal and anomaly images. To han-dle the unbalance of normal and anomaly, we use focal loss to supervise the predicted anomaly localization.",
  ". Datasets": "MVTecLOCO dataset contains five categories of ap-proximately 3,644 images covering both logical and struc-tural anomalies from industrial inspection scenarios. Con-sidering the ambiguity of the logical anomaly determina-tion at the pixel level, MVTecLOCO introduces a per-formance metric, saturated per-region overlap (sPRO), thattakes the different modalities of the defects present in thedataset into account. It is a generalized version of the per-region overlap (PRO) metric that saturates once the overlapwith the ground truth exceeds a certain saturation threshold.To evaluate pixel-level anomaly localization performance,we calculate the AU-sPRO score based on the area underthe FPR-sPRO curve up to the false positive rate is 5%.The performance of image-level classification is evaluatedby the AU-ROC.",
  "Image-level detection AU-ROC / Pixel-level localization AU-sPRO (FPR 5%)": "BreakfastBox81.3 / 46.092.0 / -83.9 / 50.2- / -80.3 / -88.9 / 65.975.9 / 46.585.4 / 46.8JuiceBottle95.6 / 71.094.9 / -99.4 / 91.0- / -94.3 / -99.1 / 82.099.5 / 87.798.5 / 91.3Pushpins72.3 / 44.778.8 / -86.2 / 73.9- / -68.6 / -95.5 / 74.479.6 / 59.687.4 / 81.3ScrewBag64.9 / 52.285.4 / -63.2 / 55.8- / -70.6 / -79.4 / 47.283.1 / 53.282.0 / 52.3SConnector82.4 / 58.692.0 / -89.3 / 79.8- / -85.4 / -88.5 / 66.988.1 / 69.189.0 / 76.3",
  "S-T66.4/49.788.3/75.677.3/62.6SPADE70.9/53.666.8/36.868.9/45.1GCAD86.0/71.180.6/69.283.3/70.1SLSG89.6/-91.4/-90.3/67.3LogicAL84.6/68.893.6/81.588.5/69.7": "MVTecAD dataset contains 1,258 test images butpays more attention on structural anomalies than MVTe-cLOCO .It only includes 37 test images from threeout of fifteen categories matching the definition of logi-cal anomalies, including cable, capsule and transistor. Asshown in , the logical anomalies consists of cableswap, faulty imprint and transistor misplaced.Follow, we evaluate our method on anomaly de-tection and localization with image and pixel AU-ROC.",
  "----87.667.4----89.068.6----89.168.1----88.567.8---88.767.9--88.567.0-88.569.789.267.2": "instances. The anomalous images contain various flaws, in-cluding surface defects such as scratches, dents, color spotsor crack, and logical defects like misplacement or missingparts. There are 5-20 images per defect type and an imagemay contain multiple defects.MADsim dataset contains 5,231 normal and 4,902anomaly color images of 20 types of 3D LEGO animalmodels from different viewpoints covering a wide range ofposes. It uses Blender in combination with Ldrew (LEGO",
  ". Implementation": "We extract four scales edge maps with pre-trained PiDiNet. Since the first scale edge map contains more detailedges, we further use it to train edge-to-image generatorsand anomaly localization network. With the pairs of ex-tracted edge map and color image, we firstly train an uni-fied DeepSIM model 300 epochs with a batch size of56 images having size of 256x256 for each dataset. Dif-ferent edge manipulation strategies are used to synthesisanomaly edge maps alternatively. The pre-trained DeepSIMmodels are used to convert synthesis anomaly edge maps toanomaly images on-the-fly during training the anomaly lo-calization network. For anomaly localization, we train thenetwork 300 epochs with a batch size of 15(12) images hav-ing size of 256x256(256x320) for MVTecAD , MVTe-cLOCO and MADsim (VisA ). The Adam opti-mizer has an initial learning rate of 1e-4 and decreases the",
  ". Performance": "Quantitative evaluation. and 2 show our quantita-tive comparison with the state-of-the-art methods recentlyreported on MVTecLOCO for both logical and struc-tural anomaly detection and localization. Performance ofthe other methods in are reported from SLSG .Separate performance comparison of logical and structuralanomalies are shown in . Overall, we achieve bet-ter comprehensive performance of anomaly detection (88.5AU-ROC) and localization (69.7 AU-sPRO) than existingmethods. Even though SLSG achieves good perfor-mance in anomaly detection with 90.3 AU-ROC, it only has67.3 AU-sPRO score in anomaly localization. The simi-lar situation happens to GCAD that is proposed alongwith the MVTecLOCO dataset. shows our supe-rior performance comparing with anomaly synthesis basedmethods on the MVTecAD dataset. By training with oursynthetic anomalies, we improve OmniAL by 1% per-formance on image-level anomaly detection. With edge re-construction, our method LogicAL achieves further 0.5%improvement on both anomaly detection and localization.",
  "Mean78.5/74.771.3/90.862.2/89.190.9/97.8-/59.360.9/58.067.6/86.0": "illustrates our performance on VisA comparingwith existing methods. We also achieve 1% improvementfor both image and pixel level from the baseline method. demonstrates our capability of multi-pose anomalydetection on the challenge MADsim . Without usingpose alignment process, we achieve superior performancethan other anomaly synthesis based methods.Qualitative evaluation.We visualize the pixel-wise prediction of our method on MVTecLOCO andMVTecAD in . The reconstruction sub-networkgenerates high quality normal version of the receivedanomaly input. The localization sub-network precisely re-veals the anomaly regions by comparing the difference be-tween the reconstructed images and input. For example, inthe second row of the MVTecLOCO results, the anomalousempty bottle is filled with white juice according to the ba-nana sticker. The empty regions excepted the stickers partsare predicted as anomalies. Similarly, the red juice doesntbelong to banana sticker is corrected into white juice andhighlighted as anomalies. In the examples of capsule fromMVTecAd dataset, the faulty imprint of 500 is recov-ered both in color image and edge map. The cracked andsqueezed capsule are reconstructed into normal appearance.The corresponding anomalous regions are revealed. Moreresults are shown in supplementary material.",
  ". Ablation Study": "demonstrates the effectiveness of proposed edgemanipulation based anomaly synthesis. We carry on ab-lation experiments on MVTecLOCO with different regionselection and edge modification strategies and TPS aug-mentation. For region selection strategy, we compare theperformance of using both or either semantic and arbitraryregions for edge modification. For edge modification strat- egy, we evaluate the effectiveness of removing, replacingand merging edges in the selected regions. We also evaluatethe contribution of TPS warping augmentation on syntheticanomalies. Our baseline is OmniAL that achieves 85.2image AUROC and 63.2 pixel AUsPRO. By training withthe anomalies synthesised by modifying edges in semanticregions, we achieves more than 3% improvement in bothimage-level detection and pixel-level localization. By com-bining all edge modification strategies, we improve the per-formance to 67.0 pixel AUsPRO. The arbitrary region selec-tion strategy increase the diversity of training samples andbrings 2.7% improvement. By applying TPS warping aug-mentation, we achieve 0.7% improvement for image AU-ROC but decrease 2.5% pixel AUsPRO.",
  ". Conclusion": "Different with existing methods, this paper proposes a novelanomaly synthesis method for both unsupervised logicaland structural anomaly localization.It generates photo-realistic anomaly images violating underlying logical con-straints and fills the gap left by existing structure-orientedanomaly synthesis methods. More specifically, it introducesedge manipulation strategies to balance logical and struc-tural anomaly synthesis. By modifying edges in seman-tic regions, it easily generates anomalies that break logicalconstraints, such as missing components. By editing edgesin arbitrary regions, it forges varies structural defects. Itfurther improves the anomaly localization performance byintroducing edge reconstruction into the network structure.Extensive experiments on the challenge dataset verify theadvantages of proposed method. Kilian Batzner, Lars Heckler, and Rebecca Konig. Efficien-tad: Accurate visual anomaly detection at millisecond-levellatencies. In Proceedings of the IEEE/CVF Winter Confer-ence on Applications of Computer Vision, pages 128138,2024. 6, 7 Paul Bergmann, Michael Fauser, David Sattlegger, andCarsten Steger. Mvtec AD - A comprehensive real-worlddataset for unsupervised anomaly detection. In CVPR, pages95929600, 2019. Computer Vision Foundation / IEEE, . 2,5, 6, 7, 8, 3 Paul Bergmann, Michael Fauser, David Sattlegger, andCarsten Steger.Uninformed students:Student-teacheranomaly detection with discriminative latent embeddings. InCVPR, pages 41824191, 2020. Computer Vision Founda-tion / IEEE, . 3, 6 Paul Bergmann, Kilian Batzner, Michael Fauser, David Sat-tlegger, and Carsten Steger.Beyond dents and scratches:Logical constraints in unsupervised anomaly detection andlocalization. Int. J. Comput. Vis., 130(4):947969, 2022. 1,2, 3, 5, 6, 7, 8",
  "Niv Cohen, Issar Tzachor, and Yedid Hoshen. Set featuresfor fine-grained anomaly detection. CoRR, abs/2302.12245,2023. 6": "Thomas Defard, Aleksandr Setkov, Angelique Loesch, andRomaric Audigier. Padim: A patch distribution modelingframework for anomaly detection and localization. In ICPR,pages 475489, 2020. Springer. 3, 6 Giancarlo Di Biase, Hermann Blum, Roland Siegwart, andCesar Cadena.Pixel-wise anomaly detection in complexdriving scenes. In Proceedings of the IEEE/CVF conferenceon computer vision and pattern recognition, pages 1691816927, 2021. 3 Choubo Ding, Guansong Pang, and Chunhua Shen. Catchingboth gray and black swans: Open-set supervised anomalydetection. In IEEE/CVF Conference on Computer Vision andPattern Recognition, CVPR 2022, New Orleans, LA, USA,June 18-24, 2022, pages 73787388. IEEE, 2022. 2 Gianluca Donato and Serge Belongie.Approximate thinplate spline mappings. In Computer VisionECCV 2002:7th European Conference on Computer Vision Copenhagen,Denmark, May 2831, 2002 Proceedings, Part III 7, pages2131. Springer, 2002. 4, 5 Mariana-Iuliana Georgescu,Radu Tudor Ionescu,Fa-had Shahbaz Khan, Marius Popescu, and Mubarak Shah. Abackground-agnostic framework with adversarial training forabnormal event detection in video. IEEE Trans. Pattern Anal.Mach. Intell., 44(9):45054523, 2022. 2",
  "with localization via conditional normalizing flows.InWACV, pages 18191828, 2022. IEEE. 8": "Alexander Kirillov, Eric Mintun, Nikhila Ravi, HanziMao, Chloe Rolland, Laura Gustafson, Tete Xiao, SpencerWhitehead, Alexander C. Berg, Wan-Yen Lo, Piotr Dollar,and Ross B. Girshick.Segment anything.CoRR,abs/2304.02643, 2023. 2, 4, 6 Chun-Liang Li, Kihyuk Sohn, Jinsung Yoon, and TomasPfister. Cutpaste: Self-supervised learning for anomaly de-tection and localization. In CVPR, pages 96649674, 2021.Computer Vision Foundation / IEEE. 1, 2, 3, 8",
  "Tsung-Yi Lin, Priya Goyal, Ross B. Girshick, Kaiming He,and Piotr Dollar. Focal loss for dense object detection. InCVPR, pages 29993007, 2017. IEEE Computer Society. 5,2": "Krzysztof Lis, Krishna Nakka, Pascal Fua, and MathieuSalzmann. Detecting the unexpected via image resynthesis.In Proceedings of the IEEE/CVF International Conferenceon Computer Vision, pages 21522161, 2019. 3 Yun Liu, Ming-Ming Cheng, Xiaowei Hu, Kai Wang, andXiang Bai. Richer convolutional features for edge detection.In Proceedings of the IEEE conference on computer visionand pattern recognition, pages 30003009, 2017. 5, 2",
  "Karsten Roth, Latha Pemula, Joaquin Zepeda, BernhardScholkopf, Thomas Brox, and Peter Gehler.Towards to-tal recall in industrial anomaly detection. In CVPR, pages1431814328, 2022. 3, 6, 7, 8": "Ramprasaath R. Selvaraju, Michael Cogswell, AbhishekDas, Ramakrishna Vedantam, Devi Parikh, and Dhruv Ba-tra. Grad-cam: Visual explanations from deep networks viagradient-based localization. Int. J. Comput. Vis., 128(2):336359, 2020. 3 Zhuo Su, Wenzhe Liu, Zitong Yu, Dewen Hu, Qing Liao,Qi Tian, Matti Pietikainen, and Li Liu.Pixel differencenetworks for efficient edge detection.In Proceedings ofthe IEEE/CVF international conference on computer vision,pages 51175127, 2021. 4, 5, 7, 2 Yael Vinker, Eliahu Horwitz, Nir Zabari, and Yedid Hoshen.Image shape manipulation from a single augmented trainingsample. In Proceedings of the IEEE/CVF International Con-ference on Computer Vision, pages 1376913778, 2021. 4,5, 7 Ting-Chun Wang, Ming-Yu Liu, Jun-Yan Zhu, Andrew Tao,Jan Kautz, and Bryan Catanzaro. High-resolution image syn-thesis and semantic manipulation with conditional gans. InProceedings of the IEEE conference on computer vision andpattern recognition, pages 87988807, 2018. 4",
  "Jinjian Wu, Guangming Shi, Weisi Lin, Anmin Liu, and FeiQi.Just noticeable difference estimation for images withfree-energy principle.IEEE Trans. Multim., 15(7):17051710, 2013. 3, 5": "Yingda Xia, Yi Zhang, Fengze Liu, Wei Shen, and Alan LYuille.Synthesize then compare: Detecting failures andanomalies for semantic segmentation. In Computer VisionECCV 2020: 16th European Conference, Glasgow, UK, Au-gust 2328, 2020, Proceedings, Part I 16, pages 145161.Springer, 2020. 3 Minghui Yang, Jing Liu, Zhiwei Yang, and Zhaoyang Wu.Slsg: Industrial image anomaly detection by learning bet-ter feature embeddings and one-class classification. arXivpreprint arXiv:2305.00398, 2023. 3, 6, 7",
  "Ying Zhao.Just noticeable learning for unsupervisedanomaly localization and detection. In ICME, pages In Press,2022. 2, 3, 5, 6, 7": "Ying Zhao. Omnial: A unified cnn framework for unsuper-vised anomaly localization. In Proceedings of the IEEE/CVFConference on Computer Vision and Pattern Recognition,pages 39243933, 2023. 1, 2, 3, 5, 6, 7, 8 Qiang Zhou, Weize Li, Lihan Jiang, Guoliang Wang, GuyueZhou, Shanghang Zhang, and Hao Zhao.Pad: A datasetand benchmark for pose-agnostic anomaly detection. arXivpreprint arXiv:2310.07716, 2023. 5, 6, 7, 8, 2, 3, 4 Yang Zou, Jongheon Jeong, Latha Pemula, Dongqing Zhang,and Onkar Dabeer. Spot-the-difference self-supervised pre-training for anomaly detection and segmentation.CoRR,abs/2207.14315, 2022. 3, 5, 6, 7, 8, 2",
  ". Ablation study": "Edge manipulation. Given the pre-trained edge-to-imagegenerator, it is supposed to generate anomaly images fromthe modified edge maps.Even though the generator istrained with carefully augmented data, it still producesglobal collapsed results if the input edge maps are out-of-distribution. illustrates the failure generations givenanomaly edge maps from 5 different modifications. Over-all, the modifications are based on the concerns of addingand/or removing different scales of edges.As shown in(2), the edges forged by large brush are obviously dif-ferent from the real edges. (4)-(5) show that scale mat-ters. Either numerous nor enormous modified edges makeanomaly synthesis successfully. As the most of the originaledges remained, the generator derives not perfect but bet-ter anomaly images from (1) and (3). It indicates thata suitable portion of anomaly edges is the key to generatehigh quality anomaly images.Region selection.Along with synthetic anomaly im-",
  ". Analysis of region selection. Different foreground ex-tractions may cause the inconsistency between original normal im-age and the synthetic anomaly image": "ages, the ground truth for training anomaly localizationmodule is simultaneously generated. Whether the groundtruth conforms to logic is another issue that needs to beconsidered. demonstrates examples of this problem.Given a normal image (a), two possible generatedanomaly images are shown in (f)and (i) respectively.Due to largely replacement of original edges, the generatedanomaly images of (f) and (i) are almost completelyunrelated with the input normal image (a). Consider-ing the underline logic of normal data, the ground truth of(f) should indicate the missing parts base on (f)rather than the (a). The anomaly localization modulewill be confused to learn from these kinds of training pairs.An extreme example is the replacement of entire edge mapwith another one.Different with above mentioned situations, the syntheticanomaly image shown in (l) having the consistencywith the normal image and can provide a reasonable groundtruth (k) for the anomaly localization training. The . Comparison of anomaly localization. We compare our localization map (g) with the difference maps (d)(f) that are producedby calculating SSIM between generated images (c)(e) and input (a). (c) is generated by the edge-to-image generator. (e) is generated byour reconstruction sub-network. The pixel AUC-sPro of the class(breakfastBox) are illustrated in lower left corners. success of (l) is due to its effective foreground re-striction, as shown in (c), extracted with a largerthreshold(thr2>thr1). Due to edges caused by backgroundreflection, such as plastic packaging, it is difficult to pre-cisely extract the foreground from JND map with a simpleand costless method. The foreground extraction is not nec-essary to be perfect but have to remain parts of the key com-ponents to maintain consistency. Motivated by these obser-vations, we construct anomaly edges based on region selec-tion strategies that avoids generation collapse and maintainsconsistency.Anomaly localization. illustrates the advance per-formance of our localization sub-network comparing di-rectly using SSIM metric to spot anomaly regions. cand d indicate that the edge-to-image generator con-verts edge maps (b) to color images (c) with little sense ofanomalies. It is barely impossible to use it indicate anomalyregions, especially the logical anomaly. On the contrary,our reconstruction images (e) reveal more vivid corruptionin the anomaly regions.9e.",
  "(6)": "where y is the ground truth edge probability generated byPiDiNet , is the binary threshold, = 1.1 is the per-centage of negative pixel samples and = 1.0 is the per-centage of positive pixel samples.To handle the unbalance of normal and anomaly, we usefocal loss to supervise the predicted anomaly localiza-tion."
}