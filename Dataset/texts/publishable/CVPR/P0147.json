{
  "Abstract": "The deployment of safe and trustworthy machine learn-ing systems, and particularly complex black box neural net-works, in real-world applications requires reliable and cer-tified guarantees on their performance. The conformal pre-diction framework offers such formal guarantees by trans-forming any point into a set predictor with valid, finite-set,guarantees on the coverage of the true at a chosen levelof confidence. Central to this methodology is the notion ofthe nonconformity score function that assigns to each ex-ample a measure of strangeness in comparison with thepreviously seen observations. While the coverage guaran-tees are maintained regardless of the nonconformity mea-sure, the point predictor and the dataset, previous researchhas shown that the performance of a conformal model,as measured by its efficiency (the average size of the pre-dicted sets) and its informativeness (the proportion of pre-diction sets that are singletons), is influenced by the choiceof the nonconformity score function. The current work in-troduces the Penalized Inverse Probability (PIP) nonconfor-mity score, and its regularized version RePIP, that allowthe joint optimization of both efficiency and informative-ness. Through toy examples and empirical results on thetask of crop and weed image classification in agriculturalrobotics, the current work shows how PIP-based conformalclassifiers exhibit precisely the desired behavior in compar-ison with other nonconformity measures and strike a goodbalance between informativeness and efficiency.",
  "The development and deployment of machine learning-based autonomous systems has been a flourishing field of": "research in both academia and, relatively more recently, inthe industry . While machine learning models oftenexhibit high performance in the lab, they often face muchmore difficulty when deployed in the real world, for a num-ber of reasons that are not yet fully clear . Indeed, whenfaced with a new observation, the model will produce a newprediction whose quality is often related to the similarity ofthis new observation to what the model has previously seen.When the new observation is quite anomalous with respectto the previously seen data or even slightly perturbed, mostmodels will produce wrong predictions , with often direand intolerable consequences in safety critical applicationssuch as autonomous driving and medical diagnosis, to name a few.The safe deployment of machine learning systems in thereal world is therefore incumbent upon the integration of atleast two main important features into them : (1) theability to provide valid and trustworthy guarantees on thequality of predictions in normal conditions, and (2) theability to reliably detect and signal anomalies when facedwith them.Conformal prediction is a method that provides formalstatistical guarantees on the predictive quality of any blackbox model . It has recently gained in popularitydue to the minimal assumptions required for its deployment.Without imposing explicit conditions on the data distribu-tion, any base point predictor can be transformed using theconformal approach into a set predictor with formal guar-antees on the coverage of the true value at confidence level1 , where is a chosen level of tolerance to error. For-mally, in a supervised learning context, whereby for eachobject x X is assigned a label y Y, a conformal modelproduces prediction sets C1 Y that satisfy the marginal",
  "Py C1(x) 1 (1)": "whenever the test data follow the same distribution as thedata on which the model was calibrated. Under this con-dition, the coverage guarantee is satisfied marginally overall possible calibration sets. Additionally, the study of thestructure and the size of the predicted sets allows us to quan-tify the uncertainty of the base model, and to detect exam-ples on which the model is highly uncertain . As such,the conformal approach can be used to satisfy the two con-ditions for safe deployment of machine learning systems asit has been shown in a number of applications rang-ing from railway signaling , medical imaging , tonuclear fusion .Three main components are needed to conduct inductiveconformal prediction : a base predictor B (which can beany machine learning point predictor), a dataset on which tocalibrate the model so that it becomes a conformal predic-tor, and a nonconformity score function that assigns astrangeness value to each example in the calibration set.This value measures how conforming each individual is towhat the model has previously seen. While the marginalcoverage guarantee is satisfied by construction, the qualityof the predicted sets is influenced by these three compo-nents. For example, a neural network B with low accuracycan still be calibrated to achieve 1 = 0.9 coverage,but will tend to predict much larger sets, since it is uncer-tain about the true class and thus needs to predict many toguarantee the inclusion of the true one.The object of interest in this work is the nonconformityscore function . In particular, we are interested in study-ing the influence of different nonconformity functions ontwo of the most commonly used metrics for the evaluationof conformal classifiers : efficiency, the average sizeof the predicted sets, and informativeness, the proportionof predicted singleton sets. These two metrics measure, insome sense, the usability of the conformal approach whenneeded to take decisions under normal condition, and maybe useful to signal high uncertainty conditions. The contextof the study is automated precision weeding in agriculture, whereby a robotic system is embedded on a tractor todetect and spray herbicides on undesirable weeds in real-time, under real-world conditions. The precision agricul-ture sector is an interesting test-bed for safe AI methodolo-gies since they are indeed needed in agriculture, but do notdirectly threaten human lives in case of failure. Related workA good body of research is dedicated tothe development of useful and efficient nonconformity scorefunctions . For classification, the first comprehen-sive work is that of Johansson et al. in which theauthors study the impact of different model-agnostic non-conformity functions in particular, the Hinge Loss and the Margin Score on neural network classifiers. The au-thors find that neither of these score functions allows thejoint maximization of informativeness and efficiency. Theirempirical results show that the Hinge Loss minimizes thesize of prediction sets, while the Margin Score maximizesthe number of singletons. These results are further con-firmed by Aleksandrova and Chertov on most of thedatasets they tested, in their work aiming at reconciling thetwo scores by computing, for a new observation, two con-formal sets using both the Hinge and Margin scores, thenchoosing the Margin-based set as the final prediction if it isa singleton, or the Hinge set otherwise. Unfortunately, thisapproach may be quite inefficient as it requires repeatingthe calibration step for each nonconformity function. Fischet al. propose an efficient conformal classification ap-proach based on an expansion of the notion of validity toinclude the concept of admissible labels, which are seman-tically plausible class labels for a given example. Such anexpansion may lead to highly inefficient prediction sets inlearning tasks with a large number of classes. As such, theauthors develop an efficient cascaded inference algorithmthat reduces the size of the prediction set by progressivelyfiltering the number of candidates via a sequence of increas-ingly complex classifiers. Other works have explored waysto combine multiple conformal models in such a way as topreserve the validity guarantee while producing sets that areas efficient as possible . Contributions In direct continuation of these previousworks, and for the expansion of the still meager body ofwork on conformal prediction in precision agriculture , our work proposes the following contributions:1. The proposal of a new model-agnostic nonconformityfunction that strikes a good balance between optimiz-ing both efficiency and informativeness: the PenalizedInverse Probability (PIP);",
  ". Definitions & Mathematical Setup": "Let x X be a vector of features, which we will callan object . To each object is associated a class labely Y := {1, ..., K} to form what we call an examplez = (x, y) X Y. A black-box classifier B is trained ona set of ntrain examples to output for an object a class pre-diction B(x) = y {1, ..., K} and an associated estimatedprobability py , such that Kk=1 pk = 1.The inductive conformal approach consists of a calibra-tion step in which the trained classifier is calibrated on a setof ncal calibration examples {zi = (xi, yi), i = 1, ..., ncal}using a real-valued nonconformity score function (z) :X Y R. The output of the calibration step is usuallya quantile value qcal R computed on the distribution ofnonconformity scores over the calibration set.This quantile is then used to produce prediction setsC1(x) Y on the remaining ntest test examples. Foreach class, its score is computed based on the probabilityestimated by B, then compared to qcal in a hypothesis testof whether the class is considered conforming enough ornot. The produced prediction sets are valid in the sensethat they satisfy the marginal coverage guarantee defined inEquation (1). This property is verified empirically by com-puting the empirical marginal coverage, which is simplythe proportion of prediction sets that cover the true label:",
  "i=11{|C1(xi)|=1}(4)": "Clearly, conformal predictors that have both high efficiencyand high informativeness are the preferred models in prac-tice, at a fixed coverage level of 1 . Smaller set sizesare easier to manipulate and be used to construct decisionrules. Singleton predictions are the most informative pre-dictions since they do not manifest any uncertainty aboutthe predicted class. A most informative, and efficient, con-formal model would be one that predicts only singletonswhile guaranteeing marginal coverage. Unfortunately, suchan optimal conformal model is impossible to attain in prac-tice .",
  ". Review of Some Nonconformity Scores": "The nonconformity measure quantifies the strangeness ofa given object by comparing it to the objects previously en-countered by the model during training and calibration .For the same base predictor B, different nonconformityfunctions lead to different conformal predictors. Here, wereview commonly used nonconformity score functions forclassification from the literature . Since the esti-mated probabilities pk are fixed for a given object x, thenonconformity score function (z) will simply be denoted(y) in the following for ease of understanding. Note alsothat during the calibration step of the conformal procedure,y is the true class of object x, while during the predictionphase, y is the tested class to be included or not in the pre-diction set.",
  "Hinge Loss (IP) Also known as Inverse Probability,this score function measures how far the estimated probabil-ity of y (where y is the true class label) is from the perfectscore of 1:IP(y) = 1 py(5)": "Indeed, a perfect classifier should always assign a probabil-ity of 1 to the true class label, which would have a Hingescore of 0. For smaller probability estimates of y, a higherHinge score is assigned since the model is deemed more un-certain about y. The Hinge Loss can thus be considered avery natural measure of nonconformity. Unfortunately, itsuffers from a major shortcoming: it does not take the prob-ability estimates of the other classes into consideration. Margin Score (MS) Assuming an implicit hypoth-esis that good predictive models should assign the highestprobability estimate to the true class, the MS measures thedifference between the estimated probability of y and thehighest estimated probability among the other classes:",
  "(6)": "A large positive value of this score indicates that the es-timated probability assigned to y is distant from the classof highest confidence. It means that class y is consideredhighly strange in comparison to the class the model consid-ers as the true one. Notice that y is always penalized, evenwhen it is the most probable class, which is not ideal. An-other shortcoming of the MS is that it only takes the maxi-mum probability into consideration, why not take the prob-abilities of the other classes directly into consideration? It isimportant to note that in cases of anomalies, OOD observa-tions or adversarial attacks, neural networks would tend toassign the highest confidence to classes that are completely",
  "wrong , thus putting the reliability of the Margin Scoreinto question": "Regularized Adaptive Prediction Sets (RAPS)Thisnonconformity function was first introduced in as partof the APS approach, with the aim of producing predic-tion sets whose size adapts to, and reflects, the difficultyof each object. It is the first score function that fully inte-grates a range of estimated probabilities other than that of y.In particular, the APS score incorporates all the estimatedprobabilities that are larger than that of the class of inter-est. Observing that the APS score tends to predict relativelylarge set sizes in learning problems with a large number ofclasses, Angelopoulos et al. introduced a regularizedversion of this score, named RAPS.Let the operator R(k) be the rank of class k after theestimated probabilities p1, ..., pK have been sorted in de-creasing order, and p[r] be the probability estimate of theclass having rank r, such that pk = p[R(k)], we can definethe RAPS score function as:",
  "(7)": "where u is a uniform random variable in (0, 1) for tie-breaking, is the penalization amount and kreg is the rankat which to start penalizing. and kreg can be fixed by theuser or optimized on a held-out dataset. The penalizationis proportional to the how further away is y in the rankingof estimated probabilities from kreg. When y has a verylow probability, meaning that it has a very high R(y), itsscore will be very strongly penalized, leading to the exclu-sion of y from the prediction set. This will lead, on average,to smaller set sizes, as it excludes from the prediction setsthose classes that would have been included by the originalAPS score (obtained for = 0). While the APS and RAPShave been developed with adaptivity and efficiency in mind,their authors do not seem to take the informativeness crite-rion into consideration.",
  ". Computed scores of the example cases shown in .The proposed PIP(y) manifests a more adaptive behavior for thevarying configurations than the classical IP and MS functions": "all other cases, the sum of the estimated probabilities of allthe classes with higher probability than y weighted by theinverse of their rank is added as a penalization term. Assuch, a decreasing weight is associated to each class thatis closer to y. This penalization term resembles the APSscore, and alleviates the shortcoming inherent by IP of nottaking the estimated probabilities of other classes into con-sideration. Furthermore, for R(y) = 2, it should be clearthat PIP(y) = 1 + MS(y). As such, the PIP score ex-hibits analogous behavior to different nonconformity func-tions depending on the estimated probabilities by the basemodel B, leading to better adaptivity, as will be shown in thetoy examples below. For more detailed developments on therelationship between the PIP and the other scores, we referthe interested reader to in the Supplementary Ma-terial. Toy examplesConsider the six different possible outputconfigurations of a neural network classifier shown in Fig-ure 1. The class of interest is y and its estimated prob-ability is fixed to py = 0.1 in all the examples.Onlythe classes having higher estimated probabilities than y are shown since they are the only ones that are used in the com-putations of the different scores. In are shown thedifferent scores assigned to class y in each of the cases,sorted in increasing order.A greater score is a sign ofgreater nonconformity that is, of higher uncertainty attributed to y.The first obvious observation is that IP assigns the samescore to y in all cases. As py = 0.1 is the same in all casesand IP is, by definition, indifferent to the other classes, allthe configurations are reduced to the same score. This rigid-ity is often undesirable in a nonconformity score function.The MS measure, on the other hand, manifests a morefluid behavior since it also considers the highest estimatedprobability. Case 1 is assigned the lowest MS score, sincethe estimated probabilities of y and a are quite similar. Assuch, MS considers that class y is as likely a candidate asa to be the first predicted class, and thus assigns it a lownonconformity score. Case 2 is considered a bit strangerthan Case 1 by the MS function because the difference be-tween the maximal class a and y is a bit larger, which isa desirable behavior by this score function. In Case 6, al-though y has the same rank R(y) = 3 as in Case 1, theMS value is maximal since the margin between the pa andpy is large. Cases 3 to 5 show the shortcoming of the MSmeasure. Since in all these cases the difference between pa and py is the same, they will all be assigned the same scorevalue, even though it is clear that class y in Case 5 shouldbe assigned a higher nonconformity value than in Case 3 oreven in Case 4.The proposed PIP function exhibits the most versatile be-havior since it takes into consideration all the classes havinghigher estimated probabilities than y. PIP(y) is different inall the distinct configurations, manifesting the specificity ofeach case. Indeed, it can easily be shown that PIP guar-antees a different score for every class even in the case ofhighest uncertainty where all the classes have the same es-timated probability 1/K ( in Supplementary Ma-terial). Case 1 has the lowest PIP score, since class y isalmost as likely as a or b to be predicted as the first class.As such y is not deemed strange in such a condition. Thebehavior of PIP in such situations is similar to that of MS.Case 2 is considered slightly stranger because the differencebetween pa and py is larger and cannot simply be attributedto some noise. While y has the same estimated probabilityand rank R(y) = 3 in both Case 3 and Case 4, it receives aslightly lower score in Case 3 since the difference with theb is very small: y could very much have been the secondclass and thus need not be penalized heavily for falling inthird place. Class y in Case 5 is further penalized becausemore significant classes have higher estimated probabilitiesthan y.",
  "Summary of PIP score propertiesThe desirable behav-ior manifested by PIP can be summarized as:": "In all situations, the Hinge Loss (IP) is a baseline value forthe PIP function. Therefore, classes with low probabilityestimates will tend to be assigned higher nonconformityscores. This kind of behavior leads to a lower averagesize of predicted sets (higher efficiency) since it tends toexclude the classes with low probability estimates . PIP takes into consideration all the probability estimatesof the other classes with higher probabilities when com-puting the score for a given class. This includes the max-imum probability class. Therefore, when py has a lowvalue compared to maxk=y pk, class y will be heavily pe-nalized (just like with the MS measure). This behaviorgenerally leads to more predicted singletons (higher in-formativeness) because in all cases where one class hasa very high probability estimate, all the other classes willbe heavily penalized and thus excluded from the predictedset . Additionally, PIP distinguishes the cases where the dif-ference between py and the more probable classes issignificant or not, penalizing less when such differencesare negligible and can be attributed to some noise. Thisleads to scores that are different almost everywhere, per-mitting better discrimination between the different modeloutputs.",
  ". Experimental Results": "In this section, we study the performance of different con-formal classifiers obtained using the nonconformity scorefunctions presented previously on the task of classifyingimages taken under real world conditions into 13 differentplant species. This learning task is part of a precision weed-ing robotic use case, where an autonomous robot should dis-tinguish weeds from cultivated crops and spray them withherbicide in real-time. Guaranteeing the performance of theweed classifiers is of great importance since missed weedscan multiply quickly and threaten heavily the health of thecultivated crops and the quality of harvest.",
  ". Experimental Setup": "The public WE3DS dataset recently published in isoriginally a dataset of RGB-D images with semantic seg-mentation masks densely annotated into 17 plant speciesclasses in addition to the soil class for the background.Due to the scarcity of publicly available crop and weedclassification datasets, this dataset has been transformedinto a classification dataset.Discarding the depth chan-nel, the original RGB images have been divided into non-overlapping windows of size 224 224. To each resultingimage is associated a true class label which is defined as theclass with the highest number of pixels in the correspond-ing semantically annotated mask. This results into a datasetof around 14,800 RGB images with 13 different classes, ofwhich six random specimens are shown in . Werefer the interested reader to in the Supplemen-tary Material for a full description of the data preparationprocedure.The database is then randomly divided into: (1) a train-ing set (70%), on which a ResNet18 classifier is trainedusing default hyperparameters and pretrained weights onImageNet , and fixed for all experiments; the remain-ing 30% of the data are then split into (2) a calibration set(13.5%) for conformal calibration and (3) a test set (16.5%)on which the conformal classifiers are evaluated. It is im-portant to note that the choice of the base model B is notof great importance and is not the focal point of this study.It is for this reason, and especially to be able to study thedifferences among the nonconformity score functions, thatwe opted for a classical ResNet18 classifier which doesnot manifest exceptional classification performance on thistask. It could have very well been replaced by a newer state-of-the-art deep classifier.After training the ResNet18 classifier, the neural networkis calibrated using each of the previously presented noncon-formity score functions at the chosen confidence level of1 = 0.9. Then, it is used to predict sets of classes forthe test images. To make sure that the obtained results arenot simply due to having favorable samples of images, thecalibration and test steps are repeated 1000 times, each timeon a different random split of the data. The random seed of the ith random split, i = 1, 2, ..., 1000, is the same acrossthe different nonconformity score functions so as to obtainresults that are truly comparable and not simply influencedby the aleatoric uncertainty inherent to the data.",
  ". Setting and for RePIP and RAPS": "For RAPS and RePIP, kreg is fixed at 3 based on this spe-cific use cases requirements. In general, we prefer not tohave prediction sets with more than 3 classes: the cultivatedspecies, a weed species and the soil. In order to choose theregularization amounts and , we conduct a parametersweep by testing multiple values from a manually definedgrid. For each value and each method, a different confor-mal classifier is obtained for which we compute the effi-ciency and informativeness. Similarly to the experimentalsetup, with the aim of verifying the reliability of the esti-mated metrics, each conformal classifier is calibrated andtested on multiple random splits of the data. shows the average set size and the proportionof singletons for each random split of the data and differentvalues of (a) and (b). Depending onthe users preferences and the use case requirements, theoptimal value can be chosen so as to place more weight onminimizing inefficiency or maximizing informativeness.In our case, we deem it more important to maximize thenumber of predicted singletons while maintaining the cov-erage guarantee, as it is much easier to construct decisionrules when only one class is predicted. Therefore, based onthe empirical results in , we choose = = 0.02as values for the hyperparameters. We also note that forboth hyperparameters, a limit seems to be reached at 0.5whereby any greater value produces the same predictionsets (notice that the data points for the values 0.5 and 1 areoverlapping).",
  "(b)": ". Efficiency and Informativeness for different values of theregularization hyperparameters. For each value of and , 100different splits of the calibration and test sets are considered formore reliable results. over the 1000 runs for each conformal classifier. Unsur-prisingly, all the conformal classifiers are able to maintainthe required 90% marginal coverage guarantee on average,with MS showing a comparatively unstable behavior withrespect to the other measures (a).As can be seen in b, the Hinge (IP) score leadsto the smallest average set size, which is in accordance withthe empirical results in showing that IP is the mea-sure to use to maximize efficiency. RAPS and RePIP whichare designed with efficiency in mind through the regulariza-tion term lead to slightly larger set sizes on average, withRePIP coming in second place after IP. A slight differencebetween APS and RAPS can be noticed. The Margin (MS)score function shows a significantly unstable behavior overthe different random runs. This can be due to its deep de-",
  "(c)": ". Violin plots of experimental results on 1000 randomsplits of the WE3DS classification dataset (each point is a randomsplit): (a) Empirical Coverage (b) Efficiency (Mean Set Size) (c) Informativeness (Proportion of Predicted Singletons). pendence on the data it faces via the outputs of the baseclassifiers, an inference that can be made by comparing thedivergent results in and . It also manifests a con-siderably higher average set size on average than all theother methods, a result in agreement with Johansson et al.. The proposed PIP score, while exhibiting a slightlylarger average set size than the other methods, is still muchmore efficient than the MS. This slight inefficiency is aprice to pay for a considerable increase in informativeness(see Equation 4).Indeed, MS manifests the highest proportion of predictedsingletons, in accordance with the literature , withmore than 50% of predicted sets being singletons, on av-erage. This result is influenced by the estimated probabil-ities of the base neural network: when the base classifierassigns a much higher estimated probability to one class incomparison to the others that is, it is highly confidentin the class it predicts all the other classes will be con-siderably penalized, and thus excluded from the predictionset. This behavior is in agreement with Case 6 in and . This behavior tends to increase the number ofpredicted singletons only when the base classifier B alreadyhas a relatively high accuracy. The other nonconformityscore functions, APS, RAPS and IP, that are not explicitlyconcerned with informativeness, have significantly less pre-dicted singletons. On the other hand, our proposed PIP andRePIP scores can be considered quite competitive with MSin terms of informativeness with around 50% of predictedsets having size 1, and manifest better stability with regardsto the data in comparison with MS. Interestingly, while theregularization via RePIP leads to considerably smaller setsizes on average, it does not decrease informativeness in anynoticeable way, thus striking the required balance betweenthe two evaluation criteria.In a robotic pipeline, a conformal model that satisfiesthe condition of guaranteed coverage under normal con-ditions with such a high level of singletons along with amoderate average set size (such as with PIP or RePIP) isquite attractive. While providing around half of the predic-tions as singletons that can readily be used to take decisions,the conformal classifier produces the remaining predictionsas sets that consist of only 2 or 3 classes, on average, onwhich adapted decision rules can be constructed easily forautonomous agents .",
  ". Conclusion": "Conformal prediction is an important methodology for de-veloping safe, deployable, machine learning systems. Aslong as the data faced by the model resembles, to a cer-tain extent, the data on which it has been calibrated, theconformal model maintains the marginal coverage guaran-tee. Even though this marginal warranty can be strength-ened, for example to provide class-conditional or group-conditional coverage guaranties , it alreadyconstitutes a strong gauge of validity for machine learningmodels, in particular black box neural networks that do notprovide such guarantees by default. The conformal enve-lope around any learning model can be an important stepfor its certification as a valid model for deployment.However, while any well-calibrated conformal modelcan provide coverage guarantees, the utility of the predic-tive model as a component in a larger decisional pipeline,in fully autonomous systems or human decision supportsystems, depends heavily on the prediction sets produced. In the current work, we introduced the Penal-ized Inverse Probability (PIP), and its regularized version(RePIP), with the aim of jointly optimizing the efficiencyand informativeness of conformal classifiers.PIP andRePIP, mixing elements from other nonconformity scorefunctions, provide a well-balanced hybrid behavior. Theempirical results on crop and weed classification using deepneural networks show that PIP-based classifiers lead to rela-tively efficient prediction sets with significantly higher levelof informativeness than their counterparts. Future work willcontinue this line of research notably by studying the be-havior the different nonconformity measures on multipledatasets consisting of varying number of classes. A promis-ing direction of exploration in safe AI is the comparisonof the performance and robustness of these different non-conformity score functions under abnormal conditions,for example under distribution shifts and with regards toanomalous observations.",
  "A. Paleyes, R.-G. Urma, and N. D. Lawrence, Challengesin Deploying Machine Learning: A Survey of Case Studies,ACM Computing Surveys, vol. 55, no. 6, pp. 129, Jul. 2023.1": "X. Huang, D. Kroening, W. Ruan, J. Sharp, Y. Sun,E. Thamo, M. Wu, and X. Yi, A Survey of Safety and Trust-worthiness of Deep Neural Networks: Verification, Testing,Adversarial Attack and Defence, and Interpretability, Com-puter Science Review, vol. 37, p. 100270, Aug. 2020. 1 A. DAmour, K. Heller, D. Moldovan, B. Adlam, B. Ali-panahi, A. Beutel, C. Chen, J. Deaton, J. Eisenstein, M. D.Hoffman, F. Hormozdiari, N. Houlsby, S. Hou, G. Jer-fel, A. Karthikesalingam, M. Lucic, Y. Ma, C. McLean,D. Mincu, A. Mitani, A. Montanari, Z. Nado, V. Natara-jan,C. Nielson,T. F. Osborne,R. Raman,K. Ra-masamy, R. Sayres, J. Schrouff, M. Seneviratne, S. Sequeira,H. Suresh, V. Veitch, M. Vladymyrov, X. Wang, K. Web-ster, S. Yadlowsky, T. Yun, X. Zhai, and D. Sculley, Under-specification Presents Challenges for Credibility in ModernMachine Learning, Journal of Machine Learning Research,vol. 23, no. 1, pp. 226:10 237226:10 297, Jan. 2022. 1",
  "C. Szegedy, W. Zaremba, I. Sutskever, J. Bruna, D. Erhan,I. Goodfellow, and R. Fergus, Intriguing Properties of Neu-ral Networks, no. arXiv:1312.6199, Feb. 2014. 1, 4": "B. Spanfelner, D. Richter, S. Ebel, U. Wilhelm, W. Branz,and C. Patz, Challenges in Applying the ISO 26262for Driver Assistance Systems, Tagung Fahrerassistenz,Munchen, vol. 15, no. 16, p. 2012, 2012. 1 Q. Rao and J. Frtunikj, Deep Learning for Self-DrivingCars: Chances and Challenges, in Proceedings of the 1stInternational Workshop on Software Engineering for AI inAutonomous Systems, ser. SEFAIS 18.New York, NY,USA: Association for Computing Machinery, May 2018, pp.3538. M. R. Alam and C. M. Ward, Adversarial Examples in Self-Driving: A Review of Available Datasets and Attacks, in2022 IEEE Applied Imagery Pattern Recognition Workshop(AIPR).DC, USA: IEEE, Oct. 2022, pp. 16. 1 E. Petersen, Y. Potdevin, E. Mohammadi, S. Zidowitz,S. Breyer, D. Nowotka, S. Henn, L. Pechmann, M. Leucker,P. Rostalski, and C. Herzog, Responsible and Regula-tory Conform Machine Learning for Medicine: A Surveyof Challenges and Solutions, IEEE Access, vol. 10, pp.58 37558 418, 2022. 1",
  "Artificial Intelligence, vol. 36, no. 11, pp. 12 00812 016,Jun. 2022. 2": "J. Vega, A. Murari, A. Pereira, S. Gonzalez, and I. Pastor,Accurate and Reliable Image Classification by Using Con-formal Predictors in the TJ-II Thomson Scattering, Reviewof Scientific Instruments, vol. 81, no. 10, p. 10E118, Oct.2010. 2 H. Papadopoulos, K. Proedrou, V. Vovk, and A. Gammer-man, Inductive Confidence Machines for Regression, inMachine Learning: ECML 2002, ser. Lecture Notes in Com-puter Science, T. Elomaa, H. Mannila, and H. Toivonen, Eds.Berlin, Heidelberg: Springer, 2002, pp. 345356. 2 U. Johansson, H. Linusson, T. Lofstrom, and H. Bostrom,Model-Agnostic Nonconformity Functions for ConformalClassification, in International Joint Conference on NeuralNetworks (IJCNN), May 2017, pp. 20722079. 2, 3, 5, 7, 8 G. R. Y. Coleman, A. Bender, K. Hu, S. M. Sharpe, A. W.Schumann, Z. Wang, M. V. Bagavathiannan, N. S. Boyd,and M. J. Walsh, Weed Detection to Weed Recognition:Reviewing 50 Years of Research to Identify Constraintsand Opportunities for Large-Scale Cropping Systems, WeedTechnology, vol. 36, no. 6, pp. 741757, Dec. 2022. 2 H. Bostrom, H. Linusson, T. Lofstrom, and U. Johansson,Evaluation of a Variance-Based Nonconformity Measurefor Regression Forests, in Conformal and Probabilistic Pre-diction with Applications, ser. Lecture Notes in ComputerScience, A. Gammerman, Z. Luo, J. Vega, and V. Vovk, Eds.Cham: Springer International Publishing, 2016, pp. 7589.2 H. Linusson, U. Johansson, H. Bostrom, and T. Lofstrom,Efficiency Comparison of Unstable Transductive and In-ductive Conformal Classifiers, in Artificial Intelligence Ap-plications and Innovations, ser. IFIP Advances in Informa-tion and Communication Technology, L. Iliadis, I. Maglo-giannis, H. Papadopoulos, S. Sioutas, and C. Makris, Eds.Berlin, Heidelberg: Springer, 2014, pp. 261270.",
  "N. Gauraha and O. Spjuth, Synergy Conformal Prediction,in Proceedings of the Tenth Symposium on Conformal andProbabilistic Prediction and Applications.PMLR, Sep.2021, pp. 91110. 2": "M. Aleksandrova and O. Chertov, How NonconformityFunctions and Difficulty of Datasets Impact the Efficiencyof Conformal Classifiers, in ICML 2021 Workshop onDistribution-Free Uncertainty Quantification, Aug. 2021. 2,3, 8 , Impact of Model-Agnostic Nonconformity Functionson Efficiency of Conformal Classifiers:An ExtensiveStudy,in Proceedings of the Tenth Symposium onConformal and Probabilistic Prediction with Applications.PMLR, Sep. 2021,pp. 151170. [Online]. Available:",
  ", Combination of inductive mondrian conformal pre-dictors, Machine Learning, vol. 108, no. 3, pp. 489510,Mar. 2019. 2": "M. Farag, J. Kierdorf, and R. Roscher, Inductive Con-formal Prediction for Harvest-Readiness Classification ofCauliflower Plants: A Comparative Study of UncertaintyQuantification Methods, in Proceedings of the IEEE/CVFInternational Conference on Computer Vision (ICCV) Work-shops, 2023, pp. 651659. 2 P. Melki, L. Bombrun, B. Diallo, J. Dias, and J.-P. Da Costa,Group-Conditional Conformal Prediction via Quantile Re-gression Calibration for Crop and Weed Classification, inProceedings of the IEEE/CVF International Conference onComputer Vision (ICCV) Workshops, 2023, pp. 614623. 8 S. Chiranjeevi, M. Sadaati, Z. K. Deng, J. Koushik, T. Z.Jubery, D. Mueller, M. E. O. Neal, N. Merchant, A. Singh,A. K. Singh, S. Sarkar, A. Singh, and B. Ganapathysubrama-nian, Deep Learning Powered Real-Time Identification ofInsects Using Citizen Science Data, no. arXiv:2306.02507,Jun. 2023. 2 A. N. Angelopoulos, S. Bates, J. Malik, and M. I. Jordan,Uncertainty Sets for Image Classifiers Using ConformalPrediction, International Conference on Learning Repre-sentations (ICLR), vol. 2021, 2021. 2, 4, 5",
  "K. He, X. Zhang, S. Ren, and J. Sun, Deep Residual Learn-ing for Image Recognition, in Proceedings of the IEEEConference on Computer Vision and Pattern Recognition(CVPR), 2016, pp. 770778. 6": "J. Deng, W. Dong, R. Socher, L.-J. Li, K. Li, and L. Fei-Fei,ImageNet: A Large-Scale Hierarchical Image Database,in Proceedings of the IEEE Conference on Computer Visionand Pattern Recognition (CVPR), Jun. 2009, pp. 248255. 6 A. Z. Ren, A. Dixit, A. Bodrova, S. Singh, S. Tu, N. Brown,P. Xu, L. Takayama, F. Xia, J. Varley, Z. Xu, D. Sadigh,A. Zeng, and A. Majumdar, Robots That Ask For Help: Un-certainty Alignment for Large Language Model Planners, inProceedings of the Conference on Robot Learning (CoRL).Atlanta, GA, USA: PMLR, Aug. 2023. 8",
  "From these relationships, we can study the behavior ofPIP(y) in different possible scenarios and derive some up-per and lower bounds:": "1. Assume the case where the class of interest y is the mostcertain class. That is, py = 1 and for all other classespk = 0, k = y. In such a situation, the rank R(y) ofy will obviously be 1. In such an optimal scenario, yshould be given the minimal possible score. Indeed:",
  "which is an upper bound on PIP": "3. Assume the theoretical scenario where the base classifierassigns the same probability estimate to all classes. Thatis, pk = 1/K, k = 1, 2, ..., K. In this case, the classof interest y will have the same probability estimate asall other classes and its PIP score will depend only on itsrank R(y), which can take any value in 1, 2, ..., K:",
  "(4)": "Based on this scenario, it is apparent that PIP generallyguarantees assigning a different score to each class sinceeven in the degenerate (and impossible) case when allthe classes have the same probability estimates, the non-conformity score of each class will be different.From these scenarios, we can further observe the hy-brid behavior of PIP. Indeed, from scenario (1) it is ap-parent that when a class k has a high estimated probabilitypk (close to 1), it is this probability estimate that plays the",
  "arXiv:2406.08884v1 [cs.CV] 13 Jun 2024": "biggest role in the final score value. When this class k is theclass of interest y, then py will play an important role in at-tenuating the final score as it will be used in the IP term, i.e.the first part in Equation 1. However, when k is differentthan the class of interest y it will play a role in increasingthe score assigned to y as it will reside in the penalizationcomponent of the PIP score. When the base classifier isquite ambivalent, assigning more or less the same scoresto all classes, then the most important factor impacting thefinal score is the rank R(y) of class y but which will havedecreasing importance due to the inverse rank weighting inthe penalization component.",
  ". Demonstration of how the original WE3DS segmenta-tion images are divided into smaller classification images": "As shown in , after discarding the depth channel,each original RGB image of size 1600 1144 is dividedinto non-overlapping smaller images of size 224224. Thecorner regions that do not align with the cropping grid (dueto the original dimensions not being perfectly divisible by224) are simply discarded. For each smaller image (likethe one highlighted in blue in ), its correspondingarea is considered in the ground-truth semantic mask. Thenumber of pixels in each class is counted, then a decision istaken:1. If the image contains only pixels of class soil, then soilis defined as the class label of the resulting classificationimage;",
  ".Count of images per class in the final classificationdataset after soil random undersampling and the dropping of thefive rarest classes": "2. If any other class exists in the image, the majority classis taken to be the true label.This results in a classification dataset consisting of89,880 images 18 different classes showing very high im-balance towards the heavily majoritarian soil class (Fig-ure 2). In order to curb this imbalance problem, 1,500 im-ages are randomly sampled from the soil class. Addition-ally, the five very rare classes (corn spurry, narrow leavedplantain, common wild oat, red root amaranth and red fin-gergrass) are removed, resulting in a dataset of 13 classesand 14,800 images as shown in . This is the datasetused to conduct the experiments in the current work."
}