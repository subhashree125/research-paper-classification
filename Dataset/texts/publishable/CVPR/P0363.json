{
  "Abstract": "3D visual grounding is a challenging task that often re-quires direct and dense supervision, notably the semanticlabel for each object in the scene. In this paper, we in-stead study the naturally supervised setting that learns fromonly 3D scene and QA pairs, where prior works under-perform. We propose the Language-Regularized ConceptLearner (LARC), which uses constraints from language asregularization to significantly improve the accuracy of neuro-symbolic concept learners in the naturally supervised setting.Our approach is based on two core insights: the first is thatlanguage constraints (e.g., a words relation to another)can serve as effective regularization for structured repre-sentations in neuro-symbolic models; the second is that wecan query large language models to distill such constraintsfrom language properties. We show that LARC improvesperformance of prior works in naturally supervised 3D vi-sual grounding, and demonstrates a wide range of 3D vi-sual reasoning capabilitiesfrom zero-shot composition, todata efficiency and transferability. Our method representsa promising step towards regularizing structured visual rea-soning frameworks with language-based priors, for learningin settings without dense supervision.",
  ". Introduction": "3D visual reasoning models often require direct supervisionduring training to achieve faithful 3D visual grounding, forexample, in the form of classification labels for each groundtruth object bounding box in the scene. However, densevisual annotation for 3D scenes is difficult and expensive toacquire. In this paper, we study the more practical settingof naturally supervised 3D visual grounding, where modelslearn by looking at only scene and question-answer pairs, anddo not use object-level classification supervision. Prior state-of-the-art works for 3D referring expression comprehension do not show strong visual reasoning",
  ". Compared to prior works, LARC conducts 3D visualgrounding in the naturally supervised setting, by training neuro-symbolic concept learners with language regularization": "capabilities, such as generalization and data efficiency, inthis indirectly supervised setup (See ).To this end, we propose a neuro-symbolic concept learnerthat leverages constraints from language (e.g., a words rela-tion to another), as regularization in low guidance settings.Compared to visual annotations, language-based priors arecheap to annotate, and free when distilled from large lan-guage models (LLMs). We show that especially in settingswith indirect supervision, models benefit from such regular-ization as it reduces overfitting on noisy signals. Notably,we leverage the structured and interpretable representationsfrom neuro-symbolic methods to effectively inject constraint-based regularization.Neuro-symbolic concept learners decompose visual rea-soning queries into modular functions, and execute themwith neural networks. Each network outputs representationsthat can be indexed by its concept name (e.g., chair) andarity (e.g., that the concept describes a binary relation) .Due to this modularity, prior neuro-symbolic works haveshown strong generalization, data efficiency, and transfer-ability in the 3D domain . However, they require direct",
  "arXiv:2404.19696v1 [cs.CV] 30 Apr 2024": "classification supervision to train intermediate networks forconcept grounding, and do not take into account the taxon-omy of the concept name in relation to other concepts inlanguage, nor its effect on other concepts. For example, pre-vious methods do not capture from language that wardrobeand dresser are visually similar and synonymous, or thata vase left of a painting indicates that the painting is rightof the vase. Although recent neuro-symbolic works haveused LLMs for the interpretation of language to functionstructures , they purely translate the query anddo not encode language priors in execution.To enable learning in naturally supervised settings, wepropose a Language-Regularized Concept Learner (LARC).LARC builds upon the 3D neuro-symbolic concept learner,NS3D , and introduces regularization on intermediaterepresentations based on language constraints. Our methodleverages general constraints derived from well-studied se-mantic relations between words, for example, symmetry ,exclusivity , and synonymity , which are broadly ap-plicable across all language-driven tasks. We show that wecan effectively encode such semantic contexts from languageinto neuro-symbolic concept learners through regularization.Additionally, we demonstrate that concepts satisfying theseconstraints can be distilled from LLMs based on languagepriors (e.g., the concepts near and far are symmetric), andthat language rules also enable execution of novel conceptsfrom composition of learned concepts.LARC significantly improves performance of neuro-symbolic concept learners in two datasets for 3D referringexpression comprehension. In addition, we demonstratethat using language-based rules allows LARC to zero-shotexecute unseen concepts, while all previous models fail togeneralize. Importantly, LARC significantly improves dataefficiency and transferability between datasets compared toprior works, critical for 3D visual reasoning systems, whilenot requiring object-level classification labels.In summary, our key contributions are the following:",
  "D grounding systems.Priors works have proposed meth-ods for 3D grounding, leveraging context from the full 3Dscene . Many of such methods take on an": "end-to-end approach, and jointly attend over language and3D point clouds . More specifically, several worksleverage the Transformer architecture to solve the 3Dreferring expression comprehension task .Notably, TransRefer3D uses a Transformer-based net-work to extract entity-and-relation-aware representations,and LanguageRefer employs a Transformer architectureover bounding box embeddings and language embeddingfrom DistilBert . The Multi-View Transformer projects the 3D scene to a multi-view space to learn robustrepresentations. Other methods have used 2D information toaugment grounding in 3D , including LAR , whichuses 2D signals generated from 3D point clouds to assistits 3D encoder. Recently, NS3D proposed a modular,neuro-symbolic approach to 3D grounding, which showsstrong data efficiency and generalization compared to end-to-end works, but requires dense supervision.All of the prior works for 3D grounding leverage clas-sification labels in the training stage, many in the form ofdirect classification losses . BUTD-DETR and SAT use outputs from pre-trained detectionnetworks, including predicted bounding boxes and their classlabels, as additional inputs. LanguageRefer applies asemantic classifier to obtain the class label of each object,which are tokenized and used as input. Zhao et al. usepre-trained segmentation networks to filter candidates basedon predicted categories from segmentation networks. WhileLARC follows NS3Ds neuro-symbolic concept learningparadigm, LARC works in the naturally supervised setting,and is neither trained with classification labels nor uses clas-sification predictions from other pre-trained networks. Neuro-symbolic concept learners.Neuro-symbolic meth-ods have shown strong visual reasoning performance anda wide range of capabilities.They parse visual reason-ing queries into programs, and execute such programswith modular networks on a variety of visual domains. Neuro-SymbolicVQA first proposed program execution for 2D vi-sual question answering, and the Neuro-Symbolic ConceptLearner improved the training paradigm by removing di-rect supervision on scene representations and program tracesin the 2D domain. A recent work, Logic-Enhanced Foun-dation Model , reduced prior knowledge required by re-placing domain-specific languages with domain-independentlogic. LARC further lowers the guidance required for 3Dconcept learners by regularizing intermediate representa-tions, enabling strong performance in naturally supervisedsettings with only 3D scene and QA pairs as supervision. Constraints in neural networks.Many works have pro-posed strategies for models to effectively encode knowledge-based rules, for the purposes of improving interpretabil-ity, sample efficiency, and compliance with safety con- straints . Von Rueden et al. describesexisting methods which range in sources of constraints (e.g.,expert knowledge), representations (e.g., graphs), and meth-ods for integration (e.g., feature engineering). Most relatedto our work are methods that incorporate discrete rules intomodels learning processes. Several works use rules as basesfor model structures , while others learn la-tent embeddings of symbolic knowledge that can be naturallyhandled by neural networks . Logical rules have alsobeen transformed into continuous and differentiable con-straints, for example via t-norm , to serve as additionalloss terms in training . Different from ex-isting approaches, LARC takes advantage of neuro-symbolicconcept learners with structured representations, and utilizeslanguage-based rules to regularize learned features.",
  ". Preliminaries": "Neuro-symbolic concept learners are methodsthat decompose input language queries into symbolic pro-grams, and differentiably execute the programs with con-cept grounding neural networks on the input visual modality.These approaches have shown strong 3D visual groundingcapabilities, but often require dense supervision in complexdomains, e.g., ground truth object bounding boxes and clas-sification labels for objects in order to train intermediateprograms. In this paper, we build LARC from NS3D , aneuro-symbolic concept learner that conducts grounding inthe 3D domain, in which such dense supervision is expensiveand difficult to annotate. NS3D was proposed to tackle thetask of 3D referring expression comprehension (3D-REC). Problem statement.In 3D-REC, we are given a scene S,which is represented as an RGB-colored point cloud of Cpoints S RC6, and an utterance U describing a targetobject and its relationship with other objects in S. Thegoal is to localize the target object T . Notably, there existsdistractor objects of the same class category as T , such thatunderstanding the full referring expression is necessary inorder to answer the query. For example, in a cluttered livingroom, U may be the chair beside the shelf, which requiresa neuro-symbolic concept learner to first find the shelf, thenfind the object beside it which is of the class chair. Theremay be many chairs in the room, from which the model mustidentify the target object from. Concept learners.The overall architecture of LARC fol-lows that of NS3D, and its concept learning framework con-sists of three main components. The first is a semantic parserthat parses the input language U into a symbolic programP. The symbolic program consists of a hierarchy of prim-itive operations defined in a domain-specific language for3D visual reasoning tasks, and represents the reasoning pro-cess underlying U. Given the utterance example above, thesemantic parser (here, a large language model) will yieldthe program relate(filter(scene(), chair),filter(scene(), shelf), beside), which indi-cates the functions that should be run to output the answer.The second is a 3D feature encoder that extracts struc-tured object-centric features for each scene. The 3D-RECtask gives segmented object point clouds for each scene asinput, which NS3D leverages; however, LARC instead usesVoteNet to reduce required annotations by detecting ob-jects directly from S. For each detected object point cloud ofMi points Oi RMi6, a 3D backbone (here, PointNet++) takes Oi as input and outputs its corresponding featuref obji Rd, where d is the dimension of the feature. For eachpair and triple of objects, an encoder learns relational fea-tures f binaryi,jand f ternaryi,j,k , which represent the binary relations(e.g., beside) and ternary relations (e.g., between) amongobjects respectively. Given N objects in the scene, the unaryrepresentation f obj is a vector with N features, one represent-ing each object. The binary representation f binary is matrixof N N features, representing relations between each pairof objects, and similarly for ternary features f ternary.The third component of concept learners is a neuralnetwork-based program executor. The executor takes theprogram P and learned features (f obj, f binary, f ternary), andreturns the target object T . During the execution of thesymbolic program, the entity-centric features and learnedconcept embeddings will be used to compute score vectors,for example, ychair, yshelf RN; and a probability matrix, forexample, probbeside RNN, where N denotes the numberof objects in the scene. Elements of ychair denote the likeli-hood of objects belonging to category chair, and elementsof probbeside denote the likelihood of object pairs satisfy-ing the relation beside. Given the aforementioned symbolicprogram, the executor reasons with",
  ". LARC distills constraints from large language models, and injects these rules as regularization into the learning process ofstructured neuro-symbolic concept learners": "with the final target object prediction loss Lpred. In contrast,LARC operates in a naturally supervised setting, supervisedby only Lpred and a set of constraint-based regularizationlosses. In our low guidance setting, ground truth boundingboxes are not known, and we instead use VoteNet togenerate object detections. Constraints.In order to learn in indirectly supervised set-tings, LARC leverages language-based constraints as regu-larization. These constraints are based on language priors(e.g., derived from synonyms), hence distilled from LLMs,or are based on general priors (e.g., sparsity). We can enforcesuch rules on the structured and interpretable representationsof concept learners, by way of regularization losses and dataaugmentation. We describe the definition and application ofconstraints below.",
  ". Constraint Generation with LLMs": "LARC encodes language-based constraints from LLMs inconcept learners. These constraints are generally applicableacross all language-based tasks, regardless of input visualmodality. To this end, LARC uses LLMs to extract conceptsnames that satisfy a set of language-based rules. We proposesymmetry , exclusivity , and synonymity asgeneral categories of language priors that capture a broadset of language properties and semantic contexts. At a highlevel, these rules specify the taxonomy of the concepts inrelation to one another, as well as its effect on other concepts.Importantly, the constraints are broad, are applicable for alllanguage queries, encode a wide range of properties, and canbe used across different datasets.We query LLMs to classify concepts into these aforemen-tioned constraints, by providing the set of concepts automat- ically extracted from the semantic parser, as well as defini-tions of the language rules. LLMs can accurately extractconcepts that satisfy the constraints, as the models capturecommon usage of the concepts. Note that these rules canalso be cheaply annotated by humans, compared to the densesupervision otherwise required in the form of 3D bound-ing boxes or classification labels. Below, we describe thedefinition for each category of language-based constraints,give examples of concepts from each category, and providedetails on how we integrate the rule into LARC. Symmetry.Relations between objects can be symmetric,in which the same relation holds when the order of the ob-jects in the given relation is reversed. For example, given therelational concept close, language priors dictate that the tableclose to the chair implies that the chair is also close to thetable. Hence, the probability matrix probclose of size N N,which describes the likelihood of object pairs satisfying therelation close, should be symmetric.To distill a set of concepts that are symmetric, we promptan LLM (here, GPT-3.5 ) with the parsed set of relationalconcepts, and ask it to output the subset of concepts that ex-hibit such reciprocity. Given the definition of the constraintas prompt, the LLM is able to automatically and accuratelydetermine whether the relational concept satisfies the sym-metry prior. Examples of concepts extracted by the LLMinclude near, beside, far, etc. Then, LARC encodes the sym-metric property with the proposed concepts as constraintsto regularize LARCs intermediate representations duringtraining. We include prompts in the Appendix.",
  "Exclusivity.We define exclusive relations as concepts thatindicate opposing relations when the order of objects is": "reversed. For example, given the concept above, the boxabove the cabinet implies that the cabinet cannot be abovethe box. By querying the LLM for relational concepts thatare exclusive and enforcing such constraints during training,we encourage LARC to learn relational representations thatare consistent with language-based priors. For example,LARCs probabove matrix should not yield high probabilitiesfor the relationships box above cabinet and cabinet abovebox given the same scene. Examples of exclusive relationsproposed by the LLM include left, behind, beneath, etc. See for visualizations of LARCs learned concepts. Synonymity.Humans have developed an extended set ofvocabulary, in which there exist synonyms that represent vi-sually similar 3D objects. End-to-end models typically lever-age such nuanced taxonomy and word semantics throughpre-trained language encoders, such as BERT . How-ever, such integration of similar language properties is notexplicitly modeled in neuro-symbolic frameworks, whichground modular symbols. To enable neuro-symbolic con-cept learners to encode these language priors in structuredrepresentations, we first query LLMs for visually similarsynonyms within the concepts of object categories. For ex-ample, concepts such as wardrobe and dresser, as well astable and dining table are visually similar and synonymous.LARC then encourages the object-centric representationsfor the similar concepts to be closer to one another. To do so,LARC first parses utterances into symbolic programs, thenselects for programs that contain concepts with an LLM-defined synonym. For each of these programs, we augmentthe original program with a synonymized version, with arandomly selected synonym concept generated by the LLMsubstituted in. This encourages the answer, and hence execu-tion trace of LARC, to be similar for synonyms.",
  ". Constraints on structured representations": "We introduce two core methods for incorporating constraintsinto structured neuro-symbolic representations. The first isthrough regularization losses, and the second through dataaugmentation. We describe both approaches below. Notably,LARCs intermediate representations can be indexed by con-cept name and by arity, which enables effective injection ofthese constraints into the training process. Regularization losses.Recall that during the execution ofneuro-symbolic programs, relations between objects are rep-resented as probability matrices. Here, we use probbinary RNN and probternary RNNN to denote the probabilitymatrices of binary and ternary relations respectively. Theirelements are interpreted as the likelihood that the referredrelation exists between the pair or triple of objects. For exam-ple, probbesidei,jspecifies the probability that object i is besideobject j, and probbetweeni,j,kspecifies the probability that object iis between objects j and k, where i, j, k are indices of objects. Note that we mask diagonal elements, which represents ob-jects relations with itself. We ignore them not only in thecalculation of losses, but also during execution. Based thesenotations, we introduce the following regularization losses.We first define a constraint on the sparsity of the prob-ability matrix probrel for each relational concept. Due tothe noise in VoteNet object detections, LARC must learn toparse out bounding boxes that are not valid objects in thescene. Hence, we encourage probrel to be sparse, keepinglarge values and ignoring small values. We treat small proba-bility values, where the model is uncertain about the relationbetween objects, as noise in object bounding box predictions.Therefore, we inject a sparsity regularization loss to denoiseLARCs execution on the object-centric representations. Theloss Lspar is applied to both binary and ternary relations,and encourages the probability matrices to be sparse as toremove noise from VoteNet object detections. The sparsityregularization loss is defined as",
  "Lspar = ||probrel||1": "We then describe the symmetry regularization loss Lsym,which encourages symmetric relations, as proposed by LLMsin the previous section, by enforcing symmetry on the re-lation matrix. At a high level, this regularization decreasesthe difference between probreli,j and probrelj,i, given that theorder of the object does not affect the relation prediction. Wedefine Lsym as",
  "Together, these constraint-based regularization losses arestrong signals for neuro-symbolic concept learners in indi-rectly supervised settings": "Data augmentation.LARC also learns to encode objectsthat represent similar concepts to closer object-centricrepresentations through data augmentation. LARC augmentssymbolic programs by replacing parsed concepts with arandomly selected synonym concept, if exists. As an ex-ample, given the program relate(filter(scene(),wardrobe), filter(scene(), cabinet),close), and similar concepts of wardrobe and dresserdistilled from an LLM, we will augment the data with anadditionalprogramrelate(filter(scene(),dresser), filter(scene(), cabinet),close).This program is supervised with the same answer as the original program, given the same scene. TheLARC execution trace will hence be encouraged to besimilar between programs with synonym concepts, leadingto similar intermediate representations.",
  ". Language-based composition": "During inference, LARC can also query LLMs for languagerules when presented with novel concepts not seen duringtraining. Given an unseen concept, for example center, anLLM can specify how it can be composed from a set oflearned concepts, automatically extracted by LARCs seman-tic parser. As an example, the ternary relation of center canbe decomposed into a series of spatial left and right relations.Hence, LARC can execute a program of couch in the centerof a lamp and a desk as a combination of: couch left oflamp and right of desk, or couch right of lamp and left ofdesk. Then, LARC can use the learned probability matricesof probleft and probright to compose probcenter as",
  "probcenteri,j,k = max (problefti,j + probrighti,k , probrighti,j + problefti,k)": "Similarly, for an unseen concept combination of not witha concept such as behind, the LLM can specify executionwith the learned front concept. In practice, LARC builds alookup table of all antonym pairs queried from LLMs. Whenpresented with new concepts, LARC will query the lookuptable and find the antonym concept to execute.In our experiments, we choose a subset of relations thatwe know can be composed with learned concepts as a proofof concept. We can also manually specify such languagerules to enable execution of new concepts.",
  ". Experiments": "We evaluate LARC on the ReferIt3D benchmark , whichtests 3D referring expression comprehension on the ScanNetdataset . We specifically focus on the SR3D settingthat leverages spatially-oriented referential language, andmeasure accuracy by matching the predicted objects with thetarget objects. As we use VoteNet object detections, targetobjects are calculated as the VoteNet detection that has thehighest IOU with the ground truth bounding box. Notably,we study the naturally supervised setting, where all modelsare not given object-level classification labels during training. Our indirectly supervised setting removes the need for denseannotations in the 3D domain.In .1, we compare LARC to NS3D , theprior state-of-the-art neuro-symbolic method. We show thatsimple constraints from language significantly improves theperformance of NS3D, and retains all benefits that structuredframeworks yield. We additionally present comparisonsto end-to-end methods on a variety of metrics, and showqualitative visualizations of LARCs learned concepts. In.2, we present ablations of LARCs rules and trainsetting. More visualizations can be found in the Appendix.",
  ". Comparison to prior work": "In this section, we evaluate LARC and report test accu-racy, generalization accuracy, data efficiency, and transferaccuracy on a new dataset. We compare LARC with top-performing methods: BUTD-DETR , MVT , NS3D, LAR , TransRefer3D , and LanguageRefer .We additionally present qualitative visualizations of LARCslearned concept representations in comparison to that ofNS3D. We note that BUTD-DETR uses labels from pre-trained detectors directly as input to the model; we modifiedthe architecture accordingly and use our VoteNet detections. Accuracy.We first evaluate LARCs performance onReferIt3D, compared with prior methods. We also create twoadditional test subsets, which specifically report the accuracyof queries with symmetric and exclusive concepts. Thesesubsets are selected from the original test set; the symmetricsubset consists of 6,487 examples, while the exclusive subsetconsists of 1,256 examples.In , we see that LARC significantly outperformsthe prior neuro-symbolic concept learner, NS3D, in the nat-urally supervised setting. LARC improves performance ofNS3D by 9 point percent with our language regularization.LARC also performs comparably to prior end-to-end meth-ods, despite evaluation in the indirectly supervised setting,where neuro-symbolic concept learners tend to underper-form. Importantly, we see a significant improvement in allother metrics of interest, described in sections below.",
  "NS3D: Concept Over": ". Visualizations of LARCs and NS3Ds learned features for symmetric (left two columns) and exclusive (right two columns)concepts; each matrix represents likelihood of pairs of objects relations adhering to the given concept. LARC features learn to encodeconstraints from language priors significantly more effectively than that of the NS3D baseline. Generalization.We evaluate LARCs ability to zero-shotgeneralize to unseen concepts based on language composi-tion rules. We create two test sets with concepts not seenduring training: ternary relations (e.g., center, between) andantonyms (e.g., not behind, not left). Queries with these con-cepts are removed from the train set. The ternary relationstest set consists of 1,145 examples from the test set, and theantonym test set consists of 50 annotated examples.In , we see that it is easy to compose learnedconcepts to execute novel concepts in LARC. In compari-son, prior works suffer significantly and fail to generalize,even when leveraging word embeddings from powerful, pre-trained language encoders as input to the model. Data efficiency.We additionally demonstrate that LARCretains strong data efficiency due to its modular conceptlearning framework. In , we see that LARC is sig-nificantly more data efficient than prior works at 5% (1,423examples), 10% (2,846 examples), 15% (4,268 examples),20% (5,691 examples), and 25% (7,113 examples) of traindata used. Notably, LARC sees a 6.8 point percent gain fromthe top-performing prior work with 10% of data.",
  ". LARC can use language-based rules to generalize execu-tion of new concepts with composition of learned concepts": "Transfer to an unseen dataset.We also evaluate LARCstransfer performance to an unseen dataset, ScanRefer ,which contains new utterances on scenes from ScanNet .We retrieve a subset of 384 ScanRefer examples that refer-ence the same object categories and relations as in ReferIt3D,such that all methods can be run inference-only.In , we present results to show that LARCs neuro-symbolic framework enables effective transfer to the Scan-Refer dataset, while only being trained on the ReferIt3Ddataset. Prior methods, even the best end-to-end ones of",
  "BUTD-DETR and MVT , do not enable such gen-eralization. We see that LARC outperforms BUTD-DETRby 14.8 point percent and MVT by 15.2 point percent": "Qualitative visualizations.Our proposed regularizationmethod enables LARC to learn representations that are con-sistent with constraints from language properties. To exam-ine this qualitatively, we present visualizations of LARCslearned concepts in . We visualize the probabilitymatrix for each concept, where each value in the N Nmatrix, probreli,j, represents the likelihood that the relationbetween objects of index i and index j adheres to the givenconcept. For exclusive concepts, we highlight high percentilevalues as well as their symmetric complements.",
  ". LARC enables transfer oflearned concepts to the ScanReferdataset , while prior works no-tably drop in performance": "In the left two columnsof , we see thatLARC learns symmetricmatrices for concepts inwhich object order in therelation does not matter,such as close and far. Incontrast, NS3Ds matricesare noisy and do not ex-hibit the same consistency.For concepts in which re-lations are reversed whenobjects are reversed in or-der, such as under andover, LARC captures theexclusive relation between probreli,j and probrelj,i. In the righttwo columns of , LARCs matrices yield opposingvalues, and hence colors, in symmetric indices, while NS3Ddoes not encode this knowledge in its representations.",
  "Finally, we present ablations of LARCs performance with-out each constraint. We additionally ablate LARCs improve-ment on NS3D in settings with classification supervision": "Constraints.In , we compare LARC with differentvariants of LARC trained without each constraint. We seethat each of the general rules is important to encode in LARC,as the removal of any constraint leads to worse performance. The synonym prior yields a strong effect on LARC, whilethe sparsity prior affects LARC at a smaller margin. Wehypothesize that this is because the synonym prior is appliedon concepts that encode object categories, which are moredifficult to learn without classification supervision. Noise inVoteNet object detections may be more trivial in comparison.",
  ". LARCs accuracywithout each constraint": "Supervision.In , wepresent results on a train set-ting that gives models accessto object-level classification la-bels, to evaluate LARCs per-formance under denser supervi-sion. The classification label ofeach VoteNet detected object isassigned the label of the groundtruth object with the highest IOUto it. While LARC still improvesNS3D by 6.6 point percent in this setting, we see less of a per-formance gain from our proposed regularization, comparedto the 9 point percent improvement in the naturally super-vised setting. We hypothesize that this is because object-levelclassification supervision reduces uncertainty in LARCsobject-centric representations during training, hence lessensthe need for regularization. We note that as the class labelsfor supervision are applied on predicted bounding boxeswith potentially incomplete object point clouds, classifica-tion supervision does not yield significant improvements.",
  ". Conclusion": "3D visual grounding models perform poorly in naturallysupervised settings, without access to object-level seman-tic labels or ground truth bounding boxes. We propose theLanguage-Regularized Concept Learner as a neuro-symbolicmethod that uses language regularization to significantly im-prove performance in indirectly supervised settings. Wedemonstrate that simple constraints, with concepts distilledfrom large language models, can significantly increase accu-racy by way of regularization on structured representations.We show that LARC is extremely generalizable, highly dataefficient, and effective transfers learned concepts to differentdatasets, by only looking at 3D scene and question-answerpairs in the naturally supervised setting.",
  "Acknowledgments.This work is in part supported by NSFRI #2211258, ONR N00014-23-1-2355, ONR YIP N00014-24-1-2117, and AFOSR YIP FA9550-23-1-0127": "Ahmed Abdelreheem, Ujjwal Upadhyay, Ivan Skorokhodov,Rawan Al Yahya, Jun Chen, and Mohamed Elhoseiny. 3DRef-Transformer: Fine-grained Object Identification in Real-world Scenes Using Natural Language. In WACV, pages39413950, 2022. 2 Panos Achlioptas, Ahmed Abdelreheem, Fei Xia, MohamedElhoseiny, and Leonidas Guibas. ReferIt3D: Neural Listen-ers for Fine-grained 3D Object Identification in Real-worldScenes. In ECCV, pages 422440. Springer, 2020. 2, 6, 11",
  "Tao Li and Vivek Srikumar. Augmenting Neural Networkswith First-Order Logic. ACL, 2019. 3": "Junyu Luo, Jiahui Fu, Xianghao Kong, Chen Gao, HaibingRen, Hao Shen, Huaxia Xia, and Si Liu. 3D-SPS: Single-stage 3D Visual Grounding via Referred Point ProgressiveSelection. In CVPR, pages 1645416463, 2022. 2 Jiayuan Mao, Chuang Gan, Pushmeet Kohli, Joshua B Tenen-baum, and Jiajun Wu. The Neuro-Symbolic Concept Learner:Interpreting Scenes, Words, and Sentences From Natural Su-pervision. In ICLR, 2019. 1, 2, 3",
  "Supplementary Material": "The appendix is organized as the following. In Appendix A,we specify the prompts used to query LLMs in LARC. In Ap-pendix B, we present additional visualizations of LARCsperformance. In Appendix C, we include additional resultsof LARC on different levels of box prediction noise. In Ap-pendix D, we discuss the ScanRefer dataset.",
  "Below, we provide the prompts used to query large languagemodels, specifically, GPT-3.5 , for concepts that satisfyLARCs constraints": "Symmetry and exclusivity.We use the following promptto categorize relational concepts, where [relations] is the listof relational concepts automatically extracted from the inputlanguage by LARCs semantic parser:We define two kinds of spatial relations: Asymmetric relationsare relations that dont exhibit reciprocity when the order ofthe objects is reversed. Symmetric relations are relations thatexhibit reciprocity when the order of the objects is reversed.Here are some relations: [relations].For each relation,specify whether it is a symmetric relation or an asymmetricrelation. Synonyms.We use the following two-round query to findvisually similar synonyms in object categories, where the[object categories] list is automatically extracted:First round: Here are some object categories: [object cate-gories]. List categories that have similar meanings.Second round: Within each group, list categories that havesimilar appearances.",
  "B. Visualizations": "In this section, we present additional visualizations of LARCsperformance. First, we compare LARCs predictions to thatof prior works on the ReferIt3D dataset. Then, we provideexecution trace examples of LARC. After, we demonstratefailure cases of LARC and include analyses. Finally, we showexamples of VoteNet object detections in comparison toground truth bounding boxes. Comparison to prior worksWe present examples ofLARCs predictions as well as baselines on the ReferIt3D dataset. We see samples in where LARC outperformsbaselines, including NS3D , BUTD-DETR , MVT, LAR , TransRefer , and LangRefer , in thenaturally supervised 3D grounding setting. Execution tracesIn , we present examples ofLARCs execution trace. LARC first parses input instruc-tion utterances into symbolic programs, then hierarchicallyexecutes each modular program to retrieve the answer. Failure casesWe provide several examples of LARCs fail-ure cases in . In the top row, we see cases whereLARC finds target objects of the correct object category, butwith incorrect relations. In the bottom row, we see caseswhere LARC yields target objects of incorrect object cate-gories. LARC is likely to fail in 3D visual grounding whenthe target object category is one without data-augumentedsynonyms during training, as it is difficult to learn with fewexamples in the naturally supervised setting. VoteNet detectionsIn , we show examples ofVoteNet object detections, used in our low guidance set-ting, in comparison to ground truth bounding boxes. We seethat VoteNet detections often result in incomplete point clouds,due to size corruption or center shift. This noise leads to addi-tional challenges in 3D visual grounding; however, VoteNetdetections significantly reduce the amount of labelled 3D datarequired during inference.",
  ". LARC can fail in understanding 3D relations (top row) or 3D object categories (bottom row); its modularity enables such analyses": "ImplementationTo transfer learned concepts to ScanRefer,we use GPT as LARCs semantic parser to generate programsfrom input language. The programs are executed as describedin the main paper. LARC relies on the generalization abilitiesof LLMs to zero-shot transfer to ScanRefer, by decomposing new language into learned programs, without requiring anyadditional training or finetuning of neural networks. In com-parison, end-to-end methods significantly underperform whenfaced with unseen input language."
}