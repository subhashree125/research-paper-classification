{
  "Abstract": "The goal of multi-task learning is to learn diverse taskswithin a single unified network. As each task has its ownunique objective function, conflicts emerge during training,resulting in negative transfer among them. Earlier researchidentified these conflicting gradients in shared parametersbetween tasks and attempted to realign them in the samedirection. However, we prove that such optimization strate-gies lead to sub-optimal Pareto solutions due to their in-ability to accurately determine the individual contributionsof each parameter across various tasks. In this paper, wepropose the concept of task priority to evaluate parame-ter contributions across different tasks. To learn task pri-ority, we identify the type of connections related to linksbetween parameters influenced by task-specific losses dur-ing backpropagation. The strength of connections is gaugedby the magnitude of parameters to determine task priority.Based on these, we present a new method named connectionstrength-based optimization for multi-task learning whichconsists of two phases. The first phase learns the task pri-ority within the network, while the second phase modifiesthe gradients while upholding this priority. This ultimatelyleads to finding new Pareto optimal solutions for multipletasks. Through extensive experiments, we show that our ap-proach greatly enhances multi-task performance in compar-ison to earlier gradient manipulation methods.",
  ". Introduction": "Multi-task learning (MTL) is a learning paradigm thathandles multiple different tasks in a single model . Com-pared to learning tasks individually, MTL can effectivelyreduce the number of parameters, leading to less memoryusage and computation with a higher convergence rate. Fur-thermore, it leverages multiple tasks as an inductive bias,enabling the learning of generalized features while reduc-ing overfitting. Complex systems such as robot vision andautonomous driving require the ability to perform multipletasks within a single system. Thus, MTL can be a first stepin finding general architecture for computer vision. A primary goal of MTL is minimizing negative trans-fer and finding Pareto-optimal solutions for mul-tiple tasks. Negative transfer is a phenomenon where thelearning of one task adversely affects the performance ofother tasks. Since each task has its own objective, this canpotentially result in a trade-off among tasks. A conditionin which enhancing one task is not possible without detri-ment to another is called Pareto optimality. A commonlyunderstood cause of this trade-off is conflicting gradients that arise during the optimization process. When thegradients of two tasks move in opposing directions, the taskwith larger magnitudes dominates the other, disrupting thesearch for Pareto-optimal solutions. The situation becomesmore complex due to imbalances in loss scales across tasks.The way we weigh task losses is crucial for multi-task per-formance. When there is a significant disparity in the mag-nitudes of losses, the task with a larger loss would dominatethe entire network. Hence, the optimal strategy for MTLshould efficiently handle conflicting gradients across differ-ent loss scales. Previous studies address negative transfer by manipulat-ing gradients or balancing tasks losses. Solutions for han-dling conflicting gradients are explored in .These approaches aim to align conflicting gradients towardsa cohesive direction within a shared network space. How-ever, these techniques are not effective at preventing neg-ative transfer, as they dont pinpoint which shared param-eters are crucial for the tasks. This results in sub-optimalPareto solutions for MTL, leading to pool multi-task per-formance. Balancing task losses is a strategy that can beapplied independently from gradient manipulation methods.It includes scaling the loss according to homoscedastic un-certainty , or dynamically finding loss weights by con-sidering the rate at which the loss decreases . In this paper, we propose the concept of task priority toaddress negative transfer in MTL and suggest connectionstrength as a quantifiable measure for this purpose. The taskpriority is defined over shared parameters by comparing theinfluence of each tasks gradient on the overall multi-taskloss. This reveals the relative importance of shared param-eters to various tasks. To learn and conserve the task pri-",
  "arXiv:2406.02996v1 [cs.LG] 5 Jun 2024": "ority throughout the optimization process, we propose theconcept of task-specific connections and their strength inthe context of MTL. A task-specific connection denotes thelink between shared and task-specific parameters during thebackpropagation of each task-specific loss. The strength ofthis connection can be quantified by measuring the scaleof the parameters involved. Based on the types of connec-tions and their respective strengths, we apply two distinctoptimization phases. The goal of the first phase is to findnew Pareto-optimal solutions for multiple tasks by learn-ing task priorities through the use of specific connectiontypes. The second phase aims to maintain the task prioritieslearned from varying loss scales by quantifying the strengthof these connections. Our method outperforms previous op-timization techniques that relied on gradient manipulation,consistently discovering new Pareto optimal solutions forvarious tasks, thereby improving multi-task performance.Our contributions are summarized as follows: We propose the concept of task priority within a sharednetwork to assess the relative importance of parametersacross different tasks and to uncover the limitation inher-ent in traditional multi-task optimization. We reinterpret connection strength within the context ofMTL to quantify task priority.Based on this reinter-pretation, we propose a new multi-task optimization ap-proach called connection strength-based optimization tolearn and preserve task priorities.",
  ". Related Work": "Optimization for MTL aims to mitigate negative trans-fer between tasks. Some of them directly modify gradients to address task conflicts. MGDA views MTL as a multi-objective problem and min-imizes the norm point in the convex hull to find a Paretooptimal set. PCGrad introduces the concept of con-flicting gradients and employs gradient projection to handlethem. CAGrad minimizes the multiple loss functionsand regularizes the trajectory by leveraging the worst localimprovement of individual tasks. Aligned-MTL stabi-lize optimization by aligning the principal components ofthe gradient matrix. Recon uses an approach similarto Neural Architecture Search (NAS) to address conflictinggradients. Some approaches use normalized gradients to prevent spillover of tasks or assign stochasticity on thenetworks parameter based on the level of consistency inthe sign of gradients . RotoGrad rotates the featurespace of the network to narrow the gap between tasks. Un-like earlier methods that guided gradients towards an inter-mediate direction (as illustrated in (a)), our approach identifies task priority in shared parameters to update gradi-ents, leading to finding new Pareto-optimal solutions.Scaling task-specific loss largely influences multi-taskperformance since the task with a significant loss woulddominate the whole training process and cause severe taskinterference. To address the task unbalancing problem inthe training, some approaches re-weight the multi-task lossby measuring homoscedastic uncertainty , prioritizingtasks based on task difficulty , or balancing multi-taskloss dynamically by considering the descending rate of loss. We perform extensive experiments involving differentloss-scaling methods to demonstrate the robustness of ourapproach across various loss-weighting scenarios.MTL architectures can be classified depending on theextent of network sharing across tasks. The shared trunkconsists of a shared encoder followed by an individual de-coder for each task . Multi-modal distillationmethods have been proposed, which can beused at the end of the shared trunk for distillation to propa-gate task information effectively. On the other hand, cross-talk architecture uses separate networks for each task andallows parallel information flow between layers . Ouroptimization approach can be applied to any model to miti-gate task conflicts and enhance multi-task performance.",
  ". Problem Definition for Multi-task Learning": "In multi-task learning (MTL), the network learns a set oftasks T = {1, 2, ..., K} jointly, where K is the number oftasks. Each task i has its own loss function Li() where is the parameter of the network. The network parameter can be classified into = {s, 1, 2, ..., K} where sis shared parameter across all tasks and i is task-specificparameters devoted to task i. Then, the objective functionof multi-task learning is to minimize the weighted sum ofall tasks losses:",
  "From an optimization perspective, MTL seeks Pareto op-timal solutions for multiple tasks": "Definition 1 (Pareto optimality). For a given network pa-rameter , if we get new such that Li() > Li(new)holds for any task i, while ensuring that Lj()Lj(new) is satisfied for all other tasks j (j = i), then thesituation is termed a Pareto improvement. In this context, . Overview of our connection strength-based optimization. (a) Previous methods modify gradients in sharedparameters to converge toward an intermediate direction without considering the task priority, which leads to sub-optimal Pareto solutions.(b) Our method divides the optimization process into two distinct phases. In Phase 1, task priority is learned through task-specific con-nections, leading to the identification of a new Pareto optimal solution. In Phase 2, task priority is gauged using the connection strengthbetween shared and task-specific nodes. Subsequently, gradients in shared parameters are aligned with the direction of the highest-prioritytasks gradients. This phase ensures that priorities established in Phase 1 are maintained, thus reducing potential negative transfer.",
  "new is said to dominate . A parameter is Pareto-optimal if no further Pareto improvements are possible. Aset of Pareto optimal solutions is called a Pareto frontier": "Earlier research interprets MTL in the con-text of multi-objective optimization, aiming for Pareto op-timality. They present a theoretical analysis that demon-strates the convergence of optimization towards Paretostationary points.Nevertheless, their analysis is con-strained when applied to real-world scenarios due to itsassumption of convex loss functions, which conflicts withthe non-convex nature of neural networks.Also, theirdemonstration of optimization converging to Pareto station-ary points doesnt necessarily guarantee reaching Pareto-optimal points, as the former are necessary but not suffi-cient conditions for Pareto optimality. We delineate theirlimitations theoretically by introducing the concept of taskpriority and empirically validate them by analyzing trainingloss and multi-task performance. On the other hand, Yu etal. emphasize the conflicting gradients.",
  "Definition 2 (Conflicting gradients). Conflicting gradientsare defined in the shared space of the network. Denote the": "gradient of task i with respect to the shared parameters sas gi = sLi(s, i). And gi and gj are gradients of apair of tasks i and j where i = j. If gi gj 0, then thetwo gradients are called conflicting gradients. Previous approaches address the issue ofconflicting gradients in shared parameters s by aligningthe gradients in a consistent direction as shown in (a).Nonetheless, they face challenges in minimizing negativetransfer, as they cannot discern which parameters in s aremost important to tasks. We refer to the relative importanceof a task in the shared parameter as task priority. Previousstudies aligned gradients without taking into account taskpriority, inadvertently resulting in negative transfer and re-duced multi-task performance. In contrast, we introducethe notion of connection strength to determine task priorityin the shared space and propose new gradient update rulesbased on this priority.",
  "In this section, we introduce the concept of task priorityto minimize negative transfer between tasks. To measure": "task priority, we establish connections in the network andassess their strength. Following that, we propose a noveloptimization method for MTL termed connection strength-based optimization. Our approach breaks down the opti-mization process into two phases as shown in (b).In Phase 1, we focus on instructing the network to catchtask-specific details by learning task priority. In Phase 2,task priority within the shared parameters is determined andproject gradients to preserve the priority.",
  "We propose a straightforward theoretical analysis of ourapproach, using the notation given in Sec. 3. Before divingdeeper, we first introduce the definition of task priority": "Definition 3 (Task priority). Assume that the task losses Lifor i = 1, 2, ..., K are differentiable. Consider X t as theinput data at time t. We initiate with shared parametersts and task-specific parameters ti with sufficiently smalllearning rate > 0. A subset of shared parameters at timet is denoted as t, such that t ts. For any task i T ,the tasks gradient for t is as follows:",
  "(3)": "Our motivation is to divide shared parameters s intosubsets {s,1, s,2, ..., s,K} based on task priority. Specifi-cally, s,i represents a set of parameters that have a greaterinfluence on task i compared to other tasks. From the taskpriority, we can derive the following theorem. Theorem 1. Updating gradients based on task priorityfor shared parameters s (update gi for each s,i) resultsin a smaller multi-task loss Ki=1 wiLi compared to up-dating the weighted summation of task-specific gradientsKi=1 wiLi without considering task priority. The theorem suggests that by identifying the task prior-ity within the shared parameter s, we can further expandthe known Pareto frontier compared to neglecting that pri-ority. A detailed proof and theoretical analysis are providedin Appendix A. However, identifying task priority in real-world scenarios is highly computationally demanding. Be-cause it requires evaluating priorities for each subset of theparameter s through pairwise comparisons among multi-ple tasks. Instead, we prioritize tasks based on connectionstrength for practical purposes.",
  ". Type and Strength of Connection": "If we think of each input and output of the networkscomponent as a node, we can depict the computation flowby establishing connections between them, and then eval-uate the strength of these connections to measure theirinterconnectedness. The idea of connection strength ini-tially emerged in the field of network compression bypruning connections in expansive CNNs. This no-tion stems from the intuition that larger parameters have agreater influence on the models output. Numerous studies have reinforced this hypothe-sis. In our study, we re-interpret this intuition for MTL todetermine task priority in shared parameters of the network.Before we dive in, we divide network connections basedon the type of task. Conventionally, connection in a networkrefers to the connectivity between nodes, quantified by themagnitude of parameters. However, we regrouped the net-work connection based on which tasks loss influences onthe connection in backpropagation. Definition 4 (Task-specific connection). The connection oftask i includes a set of parameters and their intercon-nections, specifically those involved in the backpropagationprocess related to the loss function Li for task i. In the context of MTL, where each task has its own dis-tinct objective function, diverse connections are formed dur-ing the backpropagation. Such connections are determinedby the specific loss associated with each task, leading us toterm them task-specific connections. A set of shared andtask-specific parameters, s and i, establishes a uniqueconnection. The connection strength can be measured bythe scale of parameters, mirroring the conventional notion.In this instance, we employ task-specific batch normaliza-tion to determine the task priority of the output channelof the shared convolutional layer. To establish connectionstrength, we initiate with a convolutional layer where theinput is represented as x RNIHW and the weight isdenoted by W RNONIKK.Here, NI stands forthe number of input channels, NO for the number of outputchannels, and K indicates the kernel size. Suppose we haveoutput channel set Cout = {coutp}NOp=1 and input channel setCin = {cinq }NIq=1. For any given pair of output and inputchannels coutp Cout, cinq Cin, the connection strengthsp,q is defined as:",
  "q=1sp,q(6)": "where i,p is a scale factor of the task-specific batch nor-malization. Sip measures the contribution of each outputchannel coutpto the output of task i. However, it is not pos-sible to directly compare Sip across tasks because the tasksexhibit different output scales. Hence, we employ a normal-ized version of connection strength that takes into accountthe relative scale differences among tasks:",
  "Sip =SipNOp=1 Sip(7)": "Comparing Eq. (7) for each task allows us to determine taskpriority. Since normalized connection strength representsthe relative contribution of each channel across the entirelayer, using it to determine task priority also has the ad-vantage of preventing a specific task from having priorityover the entire layer. Connection strength depends on net-work parameters, necessitating design considerations basedon the network structure. While this paper provides an ex-ample for convolutional layers, a similar application can beextended to transformer blocks or linear layers. In the fol-lowing optimization, we employ task-specific connectionsand their strength to learn task priority and conserve it.",
  ". Phase 1: Learning the task priority": "Our first approach is very simple and intuitive. Here, thenotation follows Sec. 3.1 and Sec. 4.1. For simplicity, weassume all tasks losses are equally weighted w1 = w2 =... = wK = 1/K. According to conventional gradient de-scent (GD), we havet+1s= ts Ki=1 witsLi(X t, ts, ti)t+1i= ti tiLi(X t, ts, ti)(8) for i = 1, ..., K. In standard GD, the network struggles toprioritize tasks since all tasks gradients are updated simul-taneously at each step. Instead, we sequentially update eachtasks gradients, as outlined below:",
  "// Update modified gradients": "for i = 1, ..., K. The intuition behind this optimizationis to let the network divide shared parameters s into{s,1, s,2, ..., s,K} based on task priority by updating eachtask-specific connection sequentially. After the initial gra-dient descent step modifies both s and 1, s,1 start tobetter align with 1. In the second step, the network can de-termine whether s,1 would be beneficial for 2. Through-out this process, task priorities are learned by updating thetasks loss in turn. Recognizing task priority effectively en-ables the tasks to parse out task-specific information.",
  ". Phase 2: Conserving the task priority": "Due to negative transfer between tasks, task losses fluc-tuate during training, resulting in variations in multi-taskperformance. Therefore, we introduce a secondary opti-mization phase to update gradients preserving task priority.For this phase, we employ the connection strength definedin Eq. (7). Because of its normalization, individual taskscannot be highly prioritized across the entire network. Thetop priority task for the channel coutpis determined by . The experimental results of different multi-task learning optimization methods on NYUD-v2 with HRNet-18. The weights oftasks are manually tuned. Experiments are repeated over 3 random seeds and average values are presented.",
  "= arg maxiSip(10)": "After determining the priority of tasks in each output chan-nel, the gradient vector of each task is aligned with the gra-dient of the top priority task. In detail, we categorize outputchannel {coutp}NOp=1 into channel groups {CGi}Ki=1 based ontheir top priority task. The parameter of each channel groupCGi corresponds to s,i in s = {s,1, s,2, ..., s,K}. Let{Gi,1, Gi,2, ..., Gi,K} are task-specific gradients of CGi.Then Gi,i acts as the reference vector for identifying con-flicting gradients.When another gradient vector Gi,j,where i = j, clashes with Gi,i, we adjust Gi,j to lie onthe perpendicular plane of the reference vector Gi,i to min-imize negative transfer. After projecting gradients based ontask priority, the sum of them is finally updated. In the final step, we blend two optimization stages bypicking a number P from a uniform distribution spanningfrom 0 to 1. We define E as the total number of epochs ande as the current epoch. The choice of optimization for thatepoch hinges on whether P exceeds e/E. As we approachthe end of the training, the probability of selecting Phase2 increases. This is to preserve the task priority learned inPhase 1 while updating the gradient in Phase 2. A detailedview of the optimization process is provided in Algorithm 1.The reason for mixing two phases instead of completelyseparating them is that the speed of learning task priorityvaries depending on the position within the network. Previous studies deal with conflictinggradients by adjusting them to align in the same direction.These studies attempt to find an intermediate point amonggradient vectors, which often leads to negative transfer dueto the influence of the dominant task. In comparison, ourapproach facilitates the networks understanding of whichshared parameter holds greater significance for a given task,thereby minimizing negative transfer more efficiently. Thekey distinction between earlier methods and ours is the in-clusion of task priority.",
  ". Experimental Setup": "Datasets.Our method is evaluated on three multi-taskdatasets:NYUD-v2 , PASCAL-Context , andCityscapes . These datasets contain different kinds ofvision tasks. NYUD-v2 contains 4 vision tasks: Our eval-uation is based on depth estimation, semantic segmenta-tion, and surface normal prediction, with edge detection asan auxiliary task. PASCAL-Context contains 5 tasks: Weevaluate semantic segmentation, human parts estimation,saliency estimation, and surface normal prediction, withedge detection as an auxiliary task. Cityscapes contains 2tasks: We use semantic segmentation and depth estimation.Baselines. We conduct extensive experiments with the fol-lowing baselines: 1) single-task learning: training eachtask separately; 2) GD: simply updating all tasks gradientsjointly without any manipulation; 3) multi-task optimiza-tion methods with gradient manipulation: MGDA , PC-Grad , CAGrad , Aligned-MTL ; 3) loss scal-ing methods: We consider 4 types of loss weighting wheretwo of them are fixed during training and the other two usedynamically varying weights. Static setting includes equalloss: all tasks are weighted equally; manually tuned loss:all tasks are weighted manually following works in .Dynamic setting includes uncertainty-based approach :tasks weights are determined dynamically based on ho-moscedastic uncertainty; DWA : tasks losses are deter-mined considering the descending rate of loss to determinetasks weight dynamically. 4) Architecture design methodsincluding NAS-like approaches: Cross-Stitch architec-ture based on SegNet ; Recon : turn shared layersinto task-specific layers when conflicting gradients are de-tected. All experiments are conducted 3 times with differentrandom seeds for a fair comparison.Evaluation Metrics.To evaluate the multi-task perfor-mance (MTP), we utilized the metric proposed in . Itmeasures the per-task performance by averaging it with re-spect to the single-task baseline b, as shown in m =(1/T) Ti=1(1)li(Mm,i Mb,i)/Mb,i where li = 1 ifa lower value of measure Mi means better performance for . The experimental results of different multi-task learning optimization methods on PASCAL-Context with HRNet-18. The weightsof tasks are manually tuned. Experiments are repeated over 3 random seeds and average values are presented.",
  ". Experimental Results": "Our method achieves the largest improvements in multi-task performance.The main results on NYUD-v2,PASCAL-Context are presented in Tab. 1 and Tab. 2 respec-tively. For a fair comparison, we compare various optimiza-tion methods on exactly the same architecture with identicaltask-specific layers. Tasks losses are tuned manually fol-lowing the setting in . Compared to previous meth-ods, our approach shows better performance on most tasksand datasets. It proves our method tends to induce less taskinterference.Proposed optimization works robustly on various lossscaling methods. To prove the generality of our method,we conduct extensive experiments on NYUD-v2 as shownin Tabs. 1 and 5 to 7 (Appendix D.1) and PASCAL-Contextas shown in Tabs. 2 and 12 to 14 (Appendix D.3). In almostall types of loss scaling, our method shows the best multi-task performance. Unlike conventional approaches wherethe effectiveness of optimization varies depending on the loss scaling method, ours can be applied to various types ofloss weighting and shows robust results.Our method can be applied to various types of networkarchitecture. We use MTI-Net with HRNet-18 and ResNet-18 on NYUD-v2 and PASCAL-Context.HRNet-18 and ResNet-18 are pre-trained on ImageNet .On the other hand, we use SegNet for Cityscapes fromscratch following the experiments setting in . Ouroptimization shows robustly better performance with differ-ent neural network architectures. The results with ResNet-18 are also experimented with various loss scaling as shownin Tabs. 8 to 11 (Appendix D.2).Results are compatible with various architectures withfewer parameters.In Tab. 3, we evaluate our methodsin different aspects by considering the various types of ar-chitecture. In the table, we include the results of Recon to show our method can mitigate negative transfer be-tween tasks more parameter efficiently. Compared to Cross-Stitch and RotoGrad , ours show better multi-taskperformance with fewer parameters. Compared to Recon,our method is more parameter efficient as it increases thenumber of parameters by about 0.05% with the use of task-specific batch normalization. Our method shows compara-ble performance on Cityscapes with fewer parameters.",
  ". Visualization of the percentage of top-priority tasks overtraining epoch. a) Phase 1, b) Mixing Phase 1 and Phase 2": "Our method finds new Pareto optimal solutions for mul-tiple tasks. The final task-specific loss and their average areshown in for NYUD-v2 and PASCAL-Context. Wecompare our method with previous gradient manipulationtechniques and repeat the experiments over 3 random seeds.For both NYUD-v2 and PASCAL-Context, ours show thelowest average training loss. When comparing each taskindividually, ours still shows the lowest final loss on everytask. This provides proof that our method leads to the ex-pansion of the Pareto frontier of previous approaches.",
  ". Ablation Study": "Phase 1 learns task priority to find Pareto-optimal solu-tions. We perform ablation studies on each stage of opti-mization as shown in Tab. 4. When solely utilizing phase2, its performance has no big difference from the previousoptimization techniques. However, when the first phase wasused, the lowest averaged multi-task loss was achieved. Ad-ditionally, we show the correlation of loss trends in .The closer the value is to 1, the more it means that the loss ofthe task pair decreases together. In the initial stages of opti-mization, phase 1 appears to align the loss more effectivelythan solely relying on phase 2. This shows that phase 1 aidsthe network in differentiating task-specific details, leadingto the identification of optimal Pareto solutions.During Phase 2, the tasks priority is likely to be main-tained. We evaluate the top priority task within the sharedspace of network using Eq. (10). Subsequently, we visual-ized the percentage of top priority tasks in . It illus-trates how much of the output channels in the shared con-volutional layer each task has priority over. We comparedwhen we used only Phase 1 and when we used both Phase1 and Phase 2. We found Phase 2 at the latter half of the op-timization has an effect on conserving learned task priority.This method of priority allocation prevents a specific taskfrom exerting a dominant influence over the entire networkas discussed with Eq. (7).Mixing two phases shows higher performance than us- ing each phase separately. In Tab. 4, using only Phase1 results in a lower multi-task loss than when mixingthe two phases. Nonetheless, combining both phases en-hances multi-task performance. This improvement can beattributed to the normalized connection strength (refer toEq. (7)), which ensures that no single task dominates theentire network during Phase 2. When the two phases areapplied sequentially, performance declines compared to ourmixing strategy. The reason for this performance degrada-tion seems to be the application of Phase 1 at the later stagesof Optimization. This continuously alters the establishedtask priority, which in turn disrupts the gradients properupdating based on the learned priority.",
  ". Conclusion": "In this paper, we present a novel optimization tech-nique for multi-task learning named connection strength-based optimization.By recognizing task priority withinshared network parameters and measuring it using connec-tion strength, we pinpoint which parameters are crucial fordistinct tasks. By learning and preserving this task priorityduring optimization, we are able to identify new Pareto op-timal solutions, boosting multi-task performance. We vali-date the efficacy of our approaches through comprehensiveexperiments and analysis.AcknowledgementsThisresearchwassupportedbyNationalResearchFoundationofKorea(NRF)grantfundedbytheKoreagovernment(MSIT)(NRF2022R1A2B5B03002636)andtheChallengeableFutureDefenseTechnologyResearch,DevelopmentProgram through the Agency For Defense Development(ADD) funded by the Defense Acquisition Program Ad-ministration (DAPA) in 2024 (No.912768601), and theTechnology Innovation Program (1415187329, 20024355,Development of autonomous driving connectivity technol-ogy based on sensor-infrastructure cooperation) funded Bythe Ministry of Trade, Industry Energy(MOTIE, Korea). Vijay Badrinarayanan, Alex Kendall, and Roberto Cipolla.Segnet: A deep convolutional encoder-decoder architecturefor image segmentation. IEEE transactions on pattern anal-ysis and machine intelligence, 39(12):24812495, 2017. 6,7, 8",
  "Rich Caruana. Multitask learning. Machine learning, 28:4175, 1997. 1": "Zhao Chen, Vijay Badrinarayanan, Chen-Yu Lee, and An-drew Rabinovich.Gradnorm: Gradient normalization foradaptive loss balancing in deep multitask networks. In In-ternational conference on machine learning, pages 794803.PMLR, 2018. 2 Zhao Chen, Jiquan Ngiam, Yanping Huang, Thang Luong,Henrik Kretzschmar, Yuning Chai, and Dragomir Anguelov.Just pick a sign: Optimizing deep multitask models with gra-dient sign dropout. Advances in Neural Information Process-ing Systems, 33:20392050, 2020. 2, 7 Marius Cordts, Mohamed Omran, Sebastian Ramos, TimoRehfeld,Markus Enzweiler,Rodrigo Benenson,UweFranke, Stefan Roth, and Bernt Schiele.The cityscapesdataset for semantic urban scene understanding. In Proceed-ings of the IEEE conference on computer vision and patternrecognition, pages 32133223, 2016. 6",
  "Jean-Antoine Desideri. Multiple-gradient descent algorithm(mgda) for multiobjective optimization.Comptes RendusMathematique, 350(5-6):313318, 2012. 2": "David Eigen and Rob Fergus. Predicting depth, surface nor-mals and semantic labels with a common multi-scale con-volutional architecture. In Proceedings of the IEEE inter-national conference on computer vision, pages 26502658,2015. 2 David Eigen and Rob Fergus. Predicting depth, surface nor-mals and semantic labels with a common multi-scale con-volutional architecture. In Proceedings of the IEEE inter-national conference on computer vision, pages 26502658,2015. 8",
  "Yang He, Guoliang Kang, Xuanyi Dong, Yanwei Fu, and YiYang. Soft filter pruning for accelerating deep convolutionalneural networks. arXiv preprint arXiv:1808.06866, 2018. 4": "Yang He, Ping Liu, Ziwei Wang, Zhilan Hu, and YiYang.Filter pruning via geometric median for deep con-volutional neural networks acceleration. In Proceedings ofthe IEEE/CVF conference on computer vision and patternrecognition, pages 43404349, 2019. 4 Sergey Ioffe and Christian Szegedy. Batch normalization:Accelerating deep network training by reducing internal co-variate shift. In International conference on machine learn-ing, pages 448456. PMLR, 2015. 5",
  "Hao Li, Asim Kadav, Igor Durdanovic, Hanan Samet, andHans Peter Graf. Pruning filters for efficient convnets. arXivpreprint arXiv:1608.08710, 2016. 4": "Mingbao Lin,Liujuan Cao,Shaojie Li,Qixiang Ye,Yonghong Tian, Jianzhuang Liu, Qi Tian, and Rongrong Ji.Filter sketch for network pruning.IEEE Transactions onNeural Networks and Learning Systems, 2021. 4 Bo Liu, Xingchao Liu, Xiaojie Jin, Peter Stone, and QiangLiu. Conflict-averse gradient descent for multi-task learn-ing. Advances in Neural Information Processing Systems,34:1887818890, 2021. 1, 2, 3, 6, 7, 8, 9, 10, 11, 12, 13 Fayao Liu, Chunhua Shen, and Guosheng Lin. Deep con-volutional neural fields for depth estimation from a singleimage. In Proceedings of the IEEE conference on computervision and pattern recognition, pages 51625170, 2015. 8",
  "Liyang Liu, Yi Li, Zhanghui Kuang, J Xue, Yimin Chen,Wenming Yang, Qingmin Liao, and Wayne Zhang. Towardsimpartial multi-task learning. iclr, 2021. 2": "Shikun Liu, Edward Johns, and Andrew J Davison. End-to-end multi-task learning with attention. In Proceedings ofthe IEEE/CVF conference on computer vision and patternrecognition, pages 18711880, 2019. 1, 2, 6, 8 Jiaqi Ma, Zhe Zhao, Xinyang Yi, Jilin Chen, Lichan Hong,and Ed H Chi.Modeling task relationships in multi-tasklearning with multi-gate mixture-of-experts.In Proceed-ings of the 24th ACM SIGKDD international conferenceon knowledge discovery & data mining, pages 19301939,2018. 2 Kevis-Kokitsi Maninis, Ilija Radosavovic, and IasonasKokkinos. Attentive single-tasking of multiple tasks. In Pro-ceedings of the IEEE/CVF Conference on Computer Visionand Pattern Recognition, pages 18511860, 2019. 6 Ishan Misra, Abhinav Shrivastava, Abhinav Gupta, and Mar-tial Hebert. Cross-stitch networks for multi-task learning. InProceedings of the IEEE conference on computer vision andpattern recognition, pages 39944003, 2016. 6, 7 Roozbeh Mottaghi, Xianjie Chen, Xiaobai Liu, Nam-GyuCho, Seong-Whan Lee, Sanja Fidler, Raquel Urtasun, andAlan Yuille.The role of context for object detection andsemantic segmentation in the wild. In Proceedings of theIEEE conference on computer vision and pattern recogni-tion, pages 891898, 2014. 6",
  "Ozan Sener and Vladlen Koltun.Multi-task learning asmulti-objective optimization. Advances in neural informa-tion processing systems, 31, 2018. 1, 2, 3, 6, 7, 9, 10, 11, 12,13": "Dmitry Senushkin, Nikolay Patakin, Arseny Kuznetsov, andAnton Konushin.Independent component alignment formulti-task learning. In Proceedings of the IEEE/CVF Con-ference on Computer Vision and Pattern Recognition, pages2008320093, 2023. 1, 2, 3, 6, 7, 9, 10, 11, 12, 13 Nathan Silberman, Derek Hoiem, Pushmeet Kohli, and RobFergus.Indoor segmentation and support inference fromrgbd images. In Computer VisionECCV 2012: 12th Eu-ropean Conference on Computer Vision, Florence, Italy, Oc-tober 7-13, 2012, Proceedings, Part V 12, pages 746760.Springer, 2012. 6",
  "Tan, Xinggang Wang, et al.Deep high-resolution repre-sentation learning for visual recognition. IEEE transactionson pattern analysis and machine intelligence, 43(10):33493364, 2020. 7": "Dan Xu, Elisa Ricci, Wanli Ouyang, Xiaogang Wang, andNicu Sebe. Multi-scale continuous crfs as sequential deepnetworks for monocular depth estimation. In Proceedings ofthe IEEE conference on computer vision and pattern recog-nition, pages 53545362, 2017. 8 Dan Xu, Wanli Ouyang, Xiaogang Wang, and Nicu Sebe.Pad-net: Multi-tasks guided prediction-and-distillation net-work for simultaneous depth estimation and scene parsing.In Proceedings of the IEEE Conference on Computer Visionand Pattern Recognition, pages 675684, 2018. 2, 6, 7, 8 Ruichi Yu, Ang Li, Chun-Fu Chen, Jui-Hsin Lai, Vlad IMorariu, Xintong Han, Mingfei Gao, Ching-Yung Lin, andLarry S Davis. Nisp: Pruning networks using neuron impor-tance score propagation. In Proceedings of the IEEE con-ference on computer vision and pattern recognition, pages91949203, 2018. 4 Tianhe Yu, Saurabh Kumar, Abhishek Gupta, Sergey Levine,Karol Hausman, and Chelsea Finn.Gradient surgery formulti-task learning. Advances in Neural Information Pro-cessing Systems, 33:58245836, 2020. 1, 2, 3, 6, 7, 9, 10,11, 12, 13 Zhanpeng Zhang, Ping Luo, Chen Change Loy, and XiaoouTang. Facial landmark detection by deep multi-task learning.In Computer VisionECCV 2014: 13th European Confer-ence, Zurich, Switzerland, September 6-12, 2014, Proceed-ings, Part VI 13, pages 94108. Springer, 2014. 2 Zhenyu Zhang, Zhen Cui, Chunyan Xu, Yan Yan, Nicu Sebe,and Jian Yang. Pattern-affinitive propagation across depth,surface normal and semantic segmentation. In Proceedingsof the IEEE/CVF conference on computer vision and patternrecognition, pages 41064115, 2019. 2",
  "s = {s,1, s,2, ..., s,K}(11)": "Let s,i represent the parameters in s, excluding s,i. For the sake of simplicity in our proof, we begin by focusing on asubset of shared parameters, specifically s,i, to demonstrate that accounting for task priority leads to a reduced multi-taskloss compared to neglecting it. Subsequently, we will apply the same process to the remaining shared parameters tocomplete the proof. Let gtk be the gradient of ts,i for task k as follows:",
  "(27)": "The elements within the brackets of Eq. (26) represent a pairwise comparison of the changes in loss resulting from updatingthe gradients of each task. Thus, the inequality of Eq. (27) holds from Definition 3 of task priority. The results indicate thattaking task priority into account yields a lower multi-task loss compared to neglecting it. Following a similar process for allshared parameters s = {s,1, s,2, ..., s,K}, we can conclude considering task priority leads to the expansion of the knownPareto frontier.",
  "A.2. Convergence Analysis": "This section provides theoretical analyses of the proposed optimization method, including a convergence analysis. Theoverview is as follows:1. We present the concept of Pareto-stationarity. Previous methods have shown their convergence to Paretostationary points in multi-task optimization. (See Appendix A.2.1). 2. We offer a convergence analysis for Phase 1 of connection strength-based optimization. The analysis is conductedseparately for shared and task-specific parameters. For task-specific parameters, it converges to the Pareto optimal point,similar to simple gradient descent. However, for shared parameters, Phase 1 doesnt ensure convergence to the Paretooptimal point; instead, it enhances the correlation between the gradients of tasks. (See Appendix A.2.2) 3. We provide the convergence rate of Phase 1, with a focus on task-specific parameters. (See Appendix A.2.3)4. We present a convergence analysis for Phase 2 of connection strength-based optimization, specifically focusing on theshared parameters of the network. Our analysis shows that Phase 2 converges to the Pareto optimal point, distinguishingit from previous works that converge to Pareto stationary points. (See Appendix A.2.4)",
  "Initially, we establish the concept of a Pareto stationary point. Previous methods have shown theirconvergence to Pareto stationary points in multi-task optimization": "Definition 5 (Pareto stationarity). The network parameter is defined with task-specific losses {Li}Ki=1. If the sum ofweighted gradients Ki=1 wiLi = 0, then the point is termed Pareto stationary, indicating the absence of a descentdirection from that point. Previous research has demonstrated their convergence to Pareto stationary points, which carries the risk ofleading to sub-optimal solutions. This is due to the fact that Pareto-stationarity is a necessary condition forPareto-optimality. In contrast, our work establishes convergence to the Pareto optimal point during Phase 2 of connectionstrength-based optimization. Phase 1 doesnt assure attainment of the Pareto optimal solution. Instead, it enhances thecorrelation between task gradients, amplifying the significance of task-specific parameters to learn task priorities.",
  "i=1w2i ||gti||2(45)": "According to Eq. (45), we can infer that the application of Phase 1 in connection strength-based optimization can result ingi = 0 for i = 1, 2, ..., K. The condition gti = 0 indicates that the proposed updating rule converges to the Pareto-optimalpoint for task-specific parameters i for i = {1, 2, ..., K}.",
  "Eq. (55) is valid when the step size is sufficiently small, specifically, when 2": "H . As shown in Eq. (56), Phase 1 ofconnection strength-based optimization does not strictly ensure convergence. This is attributed to its sequential updating oftask-specific connections, leading to fluctuations in their losses during training. Nevertheless, as illustrated in Eq. (56), wecan note that the optimization moves in the direction of minimizing the dot product between the gradient of the currentlyupdated task gt+(i1)/Kiand the weighted sum of gradients from the remaining losses (gt+(i1)/K wigt+(i1)/Ki). Thisobservation aligns with the experimental results presented in . Phase 1 effectively increases the correlation betweentasks in shared parameters s, which exaggerates the role of task-specific parameters, allowing it to sufficiently grasp andestablish task priorities.",
  "A.2.3Convergence rate of Phase 1": "Theorem 3 (Convergence rate of Phase 1). Assume losses {Li}Ki=1 are convex and differentiable and the gradient of{Li}Ki=1 is Lipschitz continuous with constant H > 0, i.e. ||Li(x) Li(y)|| H||x y|| for i = 1, 2, ..., K. Then, inphase 1 of connection strength optimization with a step size 1",
  "w2k||gtk||2(1 cos2tjk))(76)": "We can follow a similar process for all shared parameters s = {s,1, s,2, ..., s,K}. The second term on the right side ofEq. (76) is not smaller than zero, proving their convergence. This term can be zero only when gtk = 0 for all k = 1, 2, ..., K.Thus, we can conclude that the application of Phase 2 in connection strength-based optimization can lead to a Pareto-optimalstate, as all task-specific gradients converge to zero in the optimization process. Understanding the task priority of eachparameter enables the expansion of the known Pareto frontier which is consistent with the results of Theorem 1. Repeatedlyapplying Phase 2 of connection strength-based optimization ultimately leads to Pareto optimality.",
  "B. Loss scaling methods": "In this paper, we used 4 different loss scaling methods to weigh multiple tasks losses.1. All tasks losses are weighted equally.2. The weights of tasks are tuned manually following the previous works . For NYUD-v2, the weight of losses is asfollows:Depth : SemSeg : Surface Normal : Edge = 1.0 : 1.0 : 10.0 : 50.0For PASCAL-Context, the weight of losses is as follows:Semseg : PartSeg : Saliency : Surface Normal : Edge = 1.0 : 2.0 : 5.0 : 10.0 : 50.0 3. The losses are dynamically weighted by homoscedastic uncertainty .An uncertainty that cannot be reduced with increasing data is called Aleatoric uncertainty. Homoscedastic uncertainty isa kind of Aleatoric uncertainty that stays constant for all input data and varies between different tasks. So it is also calledtask-dependent uncertainty. Homoscedastic uncertainty is formulated differently depending on whether the task is aregression task or a classification task as each of them uses different output functions: A regression task uses GaussianLikelihood, in contrast, a classification task uses softmax function. The objectives of uncertainty weighting are asfollows:",
  "C. Experimental Details": "Implementation details. To train MTI-Net on both NYUD-v2 and PASCAL-Context, we adopted the loss schema andaugmentation strategy from PAD-Net and MTI-Net. For depth estimation, we utilized L1 loss, while thecross-entropy loss was used for semantic segmentation. To train for saliency estimation and edge detection, we employedthe well-known balanced cross-entropy loss. Surface normal prediction used L1 loss. We augmented input images byrandomly scaling them with a ratio from 1, 1.2, 1.5 and horizontally flipping them with a 50% probability. The network wastrained for 200 epochs for NYUD-v2 and 50 epochs for PASCAL-Context using the Adam optimizer. We employed alearning rate of 104 with a poly learning rate decay policy. We used a weight decay of 104 and batch size of 8.In contrast, for Cityscapes with SegNet , we followed the experimental setting in . We used L1 loss andcross-entropy loss for depth estimation and semantic segmentation, respectively. The network was trained for 200 epochsusing the Adam optimizer. We employed a learning rate of 5 105 with multi-step learning rate scheduling. We used abatch size of 8.Evaluation metric. To evaluate the performance of tasks, we employed widely used metrics. For semantic segmentation,we utilized mean Intersection over Union (mIoU), Pixel Accuracy (PAcc), and mean Accuracy (mAcc). Surface normalpredictions performance was measured by calculating the mean and median angle distances between the predicted outputand ground truth. We also used the proportion of pixels within the angles of 11.25, 22.5, 30 to the ground truth, assuggested by . To evaluate the depth estimation task, we followed the methods proposed in . We used RootMean Squared Error (RMSE), and Mean Relative Error (abs rel). For saliency estimation and human part segmentation, weemployed mean Intersection over Union (mIoU).",
  "D. Additional Experimental Results": "We compare GD, MGDA , PCGrad , CAGrad , Aligned-MTL , and connection strength-based optimizationon 4 different multi-task loss scaling methods mentioned in Appendix B. We have summarized the experimental overview asfollows. 1. NYUD-v2 with HRNet-18 on various loss scaling is evaluated in Tabs. 5 to 7.2. NYUD-v2 with ResNet-18 on various loss scaling is evaluated in Tabs. 8 to 11.3. PASCAL-Context with HRNet-18 on various loss scaling is evaluated in Tabs. 12 to 14.",
  "D.1. NYUD-v2 with HRNet-18": ". The experimental results of different multi-task optimization methods on NYUD-v2 with HRNet-18. The losses of all tasksare evenly weighted. Experiments are repeated over 3 random seeds and average values are presented. m (%) is used to indicate thepercentage improvement in multi-task performance (MTP). The best results are expressed in bold numbers.",
  "Ours0.5760.14341.2071.0353.7620.4213.7542.2069.2278.88+ 13.13": ". The experimental results of different multi-task optimization methods on NYUD-v2 with HRNet-18. The losses are weightedusing Dynamic Weight Average (DWA). Experiments are repeated over 3 random seeds and average values are presented. m (%) isused to indicate the percentage improvement in multi-task performance (MTP). The best results are expressed in bold numbers.",
  "Ours0.5650.14141.6470.9754.4920.3513.4843.0469.6078.95+ 14.24": ". The experimental results of different multi-task optimization methods on NYUD-v2 with HRNet-18. The losses are weighted byhomoscedastic uncertainty. Experiments are repeated over 3 random seeds and average values are presented. m (%) is used to indicatethe percentage improvement in multi-task performance (MTP). The best results are expressed in bold numbers.",
  "D.2. NYUD-v2 with ResNet-18": ". The experimental results of different multi-task optimization methods on NYUD-v2 with ResNet-18. The losses of all tasksare evenly weighted. Experiments are repeated over 3 random seeds and average values are presented. m (%) is used to indicate thepercentage improvement in multi-task performance (MTP). The best results are expressed in bold numbers.",
  "Ours0.6010.16238.3068.7851.0121.0914.3140.9567.5777.50+ 9.89": ". The experimental results of different multi-task optimization methods on NYUD-v2 with ResNet-18. The weights of tasks aremanually tuned. Experiments are repeated over 3 random seeds and average values are presented. m (%) is used to indicate thepercentage improvement in multi-task performance (MTP). The best results are expressed in bold numbers.",
  "Ours0.6000.15739.0069.0251.1120.6513.7742.7868.9778.30+ 11.24": ". The experimental results of different multi-task optimization methods on NYUD-v2 with ResNet-18. The losses are weightedusing Dynamic Weight Average (DWA). Experiments are repeated over 3 random seeds and average values are presented. m (%) isused to indicate the percentage improvement in multi-task performance (MTP). The best results are expressed in bold numbers.",
  "Ours0.5920.14838.4168.8251.1520.9614.2540.9767.5977.10+ 10.63": ". The experimental results of different multi-task optimization methods on NYUD-v2 with ResNet-18. The losses are weighted byhomoscedastic uncertainty. Experiments are repeated over 3 random seeds and average values are presented. m (%) is used to indicatethe percentage improvement in multi-task performance (MTP). The best results are expressed in bold numbers.",
  "D.3. PASCAL-Context with HRNet-18": ". The experimental results of different multi-task optimization methods on PASCAL-Context dataset with HRNet-18. The lossesof all tasks are evenly weighted. Experiments are repeated over 3 random seeds and average values are presented. m (%) is used toindicate the percentage improvement in multi-task performance (MTP). The best results are expressed in bold numbers.",
  "Ours62.6490.3961.4267.1078.9115.5812.6843.9378.6989.26- 0.05": ". The experimental results of different multi-task optimization methods on PASCAL-Context dataset with HRNet-18. The lossesare weighted using Dynamic Weight Average (DWA). Experiments are repeated over 3 random seeds and average values are presented. m(%) is used to indicate the percentage improvement in multi-task performance (MTP). The best results are expressed in bold numbers.",
  "Ours63.8990.7361.8967.3979.0814.9412.1046.2780.5790.41+ 1.86": ". The experimental results of different multi-task optimization methods on PASCAL-Context dataset with HRNet-18. The lossesare weighted by homoscedastic uncertainty. Experiments are repeated over 3 random seeds and average values are presented. m (%) isused to indicate the percentage improvement in multi-task performance (MTP). The best results are expressed in bold numbers.",
  "E. Additional Ablation Studies": "The order of updating tasks in Phase 1 has little impact on multi-task performance. To learn task priority in sharedparameters, Phase 1 updates each task-specific gradient one by one sequentially. To determine the influence of the order oftasks on optimization, we randomly chose 5 sequences of tasks and showed their performance in Tab. 15. From the results,we can see that the order of updating tasks in Phase 1 does not have a significant impact on multi-task performance. . The experimental results for NYUD-v2 with HRNet-18 involved exploring different task sequence orders in Phase 1. Weconducted ablation experiments with five randomly selected task sequences. Each task was represented by a single alphabet letter, asfollows: S for semantic segmentation, D for depth estimation, E for edge detection, and N for surface normal estimation.",
  "Independent0.6670.18633.1865.0445.0720.7514.0441.3268.2678.04+ 0.00": "N-D-S-E0.5740.15741.1270.4453.7719.6012.5246.0171.3380.02+ 14.47D-S-N-E0.5680.15340.9270.2353.5619.5512.4746.0971.5080.12+ 14.65E-D-S-N0.5680.15040.9770.2253.5919.5812.5046.0871.4480.07+ 14.65D-N-E-S0.5710.15341.0370.3153.6819.4912.4446.1771.5880.17+ 14.71S-D-E-N0.5650.14841.1070.3753.7419.5412.4546.1171.5480.12+ 15.00 Our method demands the least computational load when compared to previous optimization methods. In Tab. 16, weshow the impact of the proposed optimization on training time. The training time for each method is measured in secondsper epoch. To ensure a fair comparison, all methods were evaluated using the same architecture, guaranteeing an equalnumber of parameters and memory usage. The majority of the computational burden is concentrated on the forward pass,backpropagation, and gradient manipulation. While all optimization methods follow a similar process in the forward passand backpropagation, the primary distinction arises from gradient manipulation. In Phase 1, no gradient manipulation isrequired, resulting in the shortest time consumption. In phase 2, it still exhibits the shortest training time compared toprevious optimization methods. Unlike these previous methods that handle all shared components of the network, Phase 2specifically targets the shared convolutional layer along with the task-specific batch normalization layer. This selective focussignificantly reduces the time consumed per epoch.",
  "Time (s)363.98421.48378.12811.57296.74331.53": "The speed of learning the task priority differs based on the convolutional layers position. Phase 1 establishes the taskpriority during the initial stages of the networks optimization. Meanwhile, Phase 2 maintains this learned task priority,ensuring robust learning even when the loss for each task fluctuates. However, The timing at which task priority stabilizesvaries based on the position of the convolutional layer within the network, as illustrated in . This may suggest thatoptimizing by wholly separating each phase could be inefficient."
}