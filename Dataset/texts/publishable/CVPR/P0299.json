{
  "Abstract": "Point cloud filtering is a fundamental 3D vision task,which aims to remove noise while recovering the underly-ing clean surfaces. State-of-the-art methods remove noiseby moving noisy points along stochastic trajectories to theclean surfaces. These methods often require regularizationwithin the training objective and/or during post-processing,to ensure fidelity. In this paper, we introduce StraightPCF,a new deep learning based method for point cloud filtering.It works by moving noisy points along straight paths, thusreducing discretization errors while ensuring faster conver-gence to the clean surfaces. We model noisy patches asintermediate states between high noise patch variants andtheir clean counterparts, and design the VelocityModule toinfer a constant flow velocity from the former to the lat-ter.This constant flow leads to straight filtering trajec-tories. In addition, we introduce a DistanceModule thatscales the straight trajectory using an estimated distancescalar to attain convergence near the clean surface. Ournetwork is lightweight and only has 530K parameters,being 17% of IterativePFN (a most recent point cloud fil-tering network). Extensive experiments on both syntheticand real-world data show our method achieves state-of-the-art results. Our method also demonstrates nice distri-butions of filtered points without the need for regulariza-tion. The implementation code can be found at:",
  ". Introduction": "In recent years, point clouds have become increasingly pop-ular as the representation-of-choice for storing and manip-ulating 3D data, with numerous applications in both com-puter vision and geometry modelling . Point clouds are unordered sets of 3D coordinateswhich typically represent object surfaces and are capturedusing 3D sensors such as depth and Lidar devices. However,",
  ". Filtered trajectories for the Isocahedron shape at 50Kresolution and noise scale = 3%. Our StraightPCF filters pointsalong much straighter paths, compared to ScoreDenoise": "noisy artifacts may appear in point clouds as a result of sen-sor limitations and environmental factors. Removing thisnoise, known as filtering or denoising, is a fundamental 3Dvision task. Filtering methods are broadly categorized intotwo groups: 1) conventional methods involving traditionaloptimization and 2) deep learning based methods. Conven-tional methods can further be subdivided into normal basedmethods which require surface normal information to reli-ably filter point clouds and point basedmethods which directly filter point clouds .While normal based methods are limited by the accuracyof normals, point based methods suffer from a loss of geo-metric details and still exhibit sensitivity to noise. Recently,many deep learning approaches have been proposed to over-come these shortcomings. Deep learning methods can be divided into 1) resam-pling, 2) displacement and 3) probability based meth-ods. Resampling-based methods show the least fidelitywhen recovering the underlying noise-free surfaces as theirdownsampling procedure results in the loss of crucial geo-metric information. By contrast, displacement and proba-bility based methods show greater promise as they modelthe filtering objective as a reverse Markov process, whichcan be iteratively applied on the input to progressively re-move noise. Early displacement based methods, such as",
  "arXiv:2405.08322v1 [cs.CV] 14 May 2024": "PointCleanNet , employ large networks (>1Mparameters) that consume a large patch of points to filter asingle, central point. This is time-consuming and resourceintensive. More recently, IterativePFN models the it-erative filtering process internally using multiple Iteration-Modules and filters all patch points simultaneously. How-ever, incorporating multiple IterationModules results in alarge network (>3.2M parameters) which requires a largeamount of GPU memory to process.Probabilistic scorebased methods such as ScoreDenoise offer a morelightweight network but require a high number of iterationsto recover the clean surface. At higher noise levels, theyconverge to surfaces that retain noticeable amounts of noise.DeepPSR utilizes the score module of but performsan additional Graph Laplacian Regularization step onintermediate point clouds to obtain a better point distribu-tion. More importantly, the iterative filtering objectives ofcurrent displacement and probabilistic methods move noisypoints to the clean surface via stochastic trajectories and areerror prone as incorrectly inferred displacements may resultin significant changes to the distribution of filtered points.We propose StraightPCF, which moves noisy pointsalong straight filtering trajectories towards the clean sur-faces, as illustrated in . StraightPCF, illustrated in, is a lightweight network ( 530K parameters, 17%of IterativePFN ) which filters all patch points simulta-neously. Our technical contributions are as follows. We introduce the patch-wise VelocityModule that infersconstant, straight flows to filter point cloud patches. TheVelocityModule elegantly recovers the underlying cleansurfaces with nice point distributions. To improve straightness of flows, we propose a novelstraightening mechanism consisting of coupled Veloci-tyModules. This coupled VelocityModule stack infersstraighter filtering trajectories, leading to better results. Constant flows may lead to filtered points overshootingthe clean surface. Therefore, we design the Distance-Module to infer a distance scalar that provides a magni-tude to scale the flow velocity. Our architecture is the firstto decompose filtering into a dual objective of inferring avector field of flow velocities and a distance scalar.",
  ". Related Work": "Conventional filtering. Early conventional methods wereinspired by the Moving Least Squares (MLS) method ofLevin and require normal information for filtering.Notably, Alexa et al. employed MLS optimization inrecovering denoised surfaces from noisy point sets. TheImplicit MLS (IMLS) method of Adamson and Alexa further extended this approach to point-sampled cell com-plexes which allow for a well defined local geometry. TheAlgebraic Point Set Surface (APSS) method of Guennebaudand Gross applied MLS optimization for the purpose of fitting algebraic spheres to recover surfaces while being ro-bust to point set density and underlying curvature. Further-more, Digne proposed filtering the height map associated toa point set by considering handcrafted features that encodeheight variations around each point . Digne and de Fran-chis designed a weighted projection scheme, that movespoints to their filtered positions , based on the meshbilateral filtering method of Fleishman, Drori and Cohen-Or . Other normal based methods include the Mov-ing Robust Principal Component Analysis (MRPCA) of Mattei and Castrodad, the Graph Laplacian Regulariza-tion (GLR) technique of Hu et al. and the Low RankMatrix Approximation of Lu et al. The main drawbackof such methods is susceptibility to noise, during both thenormal estimation and filtering steps.By contrast, point based methods employ only point in-formation for filtering. Cazals and Pouget proposed aN-dimensional polynomial surface fitting method that canbe used to filter points. Meanwhile, the Locally OptimalProjection (LOP) method of Lipman et al. downsam-pled and regularized noisy point clouds. It was extended byHuang et al. and Preiner et al. who developed Weighted-LOP (WLOP) and Continuous-LOP (CLOP) , re-spectively. However, these methods do not effectively re-cover geometric details due to their downsampling step.Deep learning based filtering. While conventional meth-ods rely on handcrafted features, convolutional neural net-work architectures have provided great improvements tofeature generation. PointProNets by Roveri et al. andDeep Feature Preserving (DFP) by Lu et al. projectedpoints onto 2D height maps before processing them usingCNNs. PointNet , introduced by Qi et al., set the prece-dent for direct point set convolution and was later improvedby PointNet++ . Meanwhile, DGCNN of Wanget al. reformulated point set convolution as a graph con-volution task. PointCleanNet (PCN) was one of thefirst methods to adopt the PointNet architecture and inferredthe filtered displacement of a single central point by consid-ering its neighborhood patch. Pointfilter of Zhang etal. furthered this line of research using a bilateral filtering-inspired loss.Pistilli et al. introduced the first graph convolution-basedmechanism, named GPDNet , while Luo and Hu pro-posed the DGCNN based DMRDenoise . DMRDenoisefiltered points by downsampling noisy inputs and upsam-pling these less noisy surfaces. Luo and Hu also proposedScoreDenoise where they formally expressed the filter-ing objective as the backward Langevin equation that itera-tively removes noise using the inferred gradient-log of theprobability distribution, i.e., the score, for point positionsxxx. This was extended by Chen et al. in their DeepPSR which employs an additional graph laplacian regularizationpost-processing step. Mao et al. introduced the normalizing . Our StraightPCF network. It involves a coupled VelocityModule stack that infers a constant flow velocity vvvk for patch statesXXX(t+k)/T . To ensure filtered points converge to the surface, the DistanceModule infers a distance scalar d that scales the velocity. flows based filtering method PDFlow that disentanglesnoise from the underlying clean representation at higher di-mensions. The RePCDNet method of Chen et al. soughtto model iterative filtering via a recurrent neural network.By contrast, de Silva Edirimuni et al. proposed the graphconvolution based IterativePFN that models iterative fil-tering using individual IterationModules. The joint filter-ing and normal estimation method CFilter , developedby de Silva Edirimuni et al., exploited normals to improvefiltered point positions. Ma et al. introduced learning im-plicit signed distance functions, by displacing noisy querypoints back to the surface along normals where the surfacecorresponds to the zero-level set of the function . Thishas been exploited for normal estimation .Score and displacement based methods are inspired bydiffusive processes and their filtering objectives re-sult in stochastic trajectories. Recent work by Liu, Gongand Liu focuses on Reflow , which explored the op-timal transport problem of identifying straight paths giventwo samples from different distributions. The work of Wu etal. further extended this Reflow mechanism to point cloudgeneration, which attempts to generate point cloud shapesgiven initial samples from the normal distribution .",
  "ScoreDenoise is trained to predict a score Si(xxx) =Score(xxx xxxi|hhhi) for xxx sampled from the k-nearest neigh-bors of xxxi. It is conditioned on the latent feature hhhi of xxxi": "and corresponds to the gradient-log of the noise-convolvedprobability distribution for point position xxx. The groundtruth target s(xxx) = NN(xxx,YYY ) xxx, where YYY is the cleanpatch. Ergo, s(xxx) is the displacement from xxx to its near-est neighbor in YYY . Once this training objective has beenoptimized, score based methods infer aggregate scores, ateach iteration t, such that F(xxxit1) = Ei(xxxit1) =(/K) xxxjt1kNN(xxxit1) Sj(xxxit1) where is the step dis-cretization parameter. This score shifts points towards theclean surface along a stochastic filtered trajectory that issensitive to the choice of , which must be kept relativelysmall ( 0.2). By contrast, IterativePFN internally mod-els the iterative filtering objective and incorporates it withintheir training objective. They directly infer displacementsF(xxxit1) = dddit as the output of each IterationModule thatmodels an iteration t. From Eq. (3) we identify that theoverall filtered trajectories inferred by IterativePFN willalso be stochastic in nature as it uses an Adaptive GroundTruth (AGT), YYY t = YYY + t N(0, I), within thetraining objective. Modelling the iterative filtering processinternally results in a large network (>3.2M parameters).The AGT, while recovering the surface, causes clusteringalong the surface and fails to respect the original point dis-tribution. This is illustrated in .Inspired by Reflow which focuses on optimal transportbetween samples of different distributions , we posefiltering as an optimal transport problem between pointcloud patches. These patches of n points are sampled from1) the clean surface (i.e., clean patch XXX1 1) and 2) ahigh noise variant of the clean surface (i.e., high noise patchXXX0 0). The goal is to determine a transport plan (cou-pling) such that XXX1 = V (XXX0) where V : Rn3 Rn3.The approximated flow velocity, vvv : Rn3 Rn3 sat-",
  ". Method": "Previous methods such as ScoreDenoise and Itera-tivePFN focus on filtering as a reverse Markov pro-cess where the forward process would correspond to addingnoise. We formulate filtering as an optimal transport planthat moves noisy points back to the clean surface along theshortest (straight) path. We model noisy input patches asintermediate states between high noise variants and theircorresponding clean counterparts.We design a graph-convolution based VelocityModule that infers a constantflow velocity for each intermediate state. This encouragesnoisy points to move along straight filtering trajectories asshown in . We further improve the straightness ofthese trajectories via VelocityModule coupling. Finally, asthe flow is constant, it may result in filtered points over-shooting the clean surface. Therefore, we design a Dis-tanceModule that scales the flow velocity appropriately andensures convergence near the surface. The overall Straight-PCF architecture is illustrated in , which demonstratesthe filtering process that utilizes both the coupled Velocity-Module and DistanceModule sub-networks to move pointsalong straightened paths.The supplementary documentprovides additional methodology details.",
  "In this section, we introduce the VelocityModule (VM)that moves noisy points along constant, straight flows to-": ". StraightPCF models initial noisy patches (light blue)as being intermediate states of a linear interpolation between highnoise variants (red) and the clean surfaces (dark blue) and encour-ages straight filtering trajectories. wards the clean surface.Given a noisy patch XXX={xxxi|xxxi kNN(xxxr, PXXX, k)} centered around a referencepoint xxxr in the noisy point cloud PXXX, the filtering objec-tive aims to move xxxi towards the underlying clean patchYYY = {yyyi|yyyi PYYY }. For the filtering task, learning basedmethods are typically trained on noisy point clouds withGaussian noise . Iterative filtering de-pends on the ability of the method to filter patches from ahigher noise level to a lower noise level, with the end resultconverging to the clean surface. Given the highest noisesetting H, intermediate noise scales at a time t can be expressed as = (1 t)H. Therefore, we modelnoisy patches XXX = YYY + N(0, I) as interme-diate states XXXt, of the filtering objective that moves pointsfrom a high noise variant, XXX0 = YYY + H N(0, I)to the clean counterpart XXX1 = YYY . Here, H = 2% of thepoint clouds bounding sphere radius and corresponds to thehighest noise setting of our training set. We observe that in-termediate states XXXt can be defined as a linear interpolationof XXX0 and XXX1, that is, a straight path, such that,",
  "EtU(0,1)vvv(XXXt) (XXX1 XXX0)22dt,(6)": "where times t are sampled uniformly along . How-ever, the velocity field at an intermediate state XXXt cannotbe causally determined as both XXX0 and XXX1 are unknown,during filtering. To address this, our idea is to approximatethe velocity field for each XXXt by a neural network.Training objective for single VM. We use a DGCNNbased graph neural network to model a VelocityModule vvv,",
  "LA = EtU(0,1)vvv(XXXt) (XXX1,XXX0)22,(7)": "where (XXX1,XXX0) = XXX1 XXX0. Hence, at each intermediatestate, the corresponding flow velocity is ideally a constantvector that leads to a straight path from XXX0 to XXX1.Filtering objective for single VM. During inference,given a straight flow velocity vvv, we can move points fromXXXt/N to XXX(t+1)/N using the Euler method ODE solver:",
  "N vvv( XXXt/N),(8)": "where N denotes the total number of filtering steps, t [0, . . . , M, . . . , N 1] is an integer time step and XXX0 = XXX0.In practice, filtering starts at an unknown time step t = M.We do not know the noise scale of the input patch and needto model it as an intermediate state XXXM/N of a higher noisevariant XXX0. The full position update takes the form,",
  ". Straighter flows via VelocityModule coupling": "Given noisy initial data, the trajectories of points tend tobe curved, with limited straightness. One way to improvestraightness is to finetune the velocity network on the cou-pling ( XXX0, XXX1) to satisfy XXX1 = V ( XXX0). For filtering, weaim to recover surfaces while preserving local geometricdetails .Applying such finetuning requires the pre-computation of XXX1 for all possible surface patches and isinfeasible due to the large number of patches in the trainingset. We propose a simple mechanism to straighten paths bycoupling K VelocityModules together.Training objective for coupled VMs. Given a noisypatch XXXt, we partition the trajectory from XXXt to XXX1 intoK segments and obtain the velocity flow vvvk( XXXtk) at timestk = (t(K k) + k)/K where k {0, 1, . . . , K 1}.Intermediate positions at times tk+1 are given by XXXtk+1 =XXXtk + (1/K) vvvk( XXXtk). We empirically find that two Ve-locityModules, i.e., K = 2, provide the best balance be-tween accuracy and efficiency. The VelocityModules are",
  "(10)": "for K 2, 1 = 10 and XXXt0 = XXXt0 = XXXt. The first termof LB encourages coupled VelocityModules to infer a con-stant velocity at times tk, while the second encourages fil-tered points XXXtk to move closer to interpolated points XXXtk.Filtering objective for coupled VMs. At inference, weapply a modified form of the Euler method to filter points,similar to Eq. (8). We apply K coupled VelocityModulesN times, resulting in T = K N total filtering steps. Weadjust our earlier notation of integer time steps such thatt {0, K, . . . M, . . . , K(N 1)} where M is divisible byK and XXX0 = XXX0. The sequential position update becomes,",
  ". Distance estimation to the clean surface": "We now address the second challenge related to Eq. (9)and introduce the DistanceModule that scales the over-all straight trajectory.This leads to better convergencenear the surface. The DistanceModule estimates a distancescalar, corresponding to the standard deviation of initialnoisy points from the clean surface. More specifically, theDistanceModule D() is used to approximate a mappingd : Rn3 R, such that,",
  ". Left: Filtering by coupled VelocityModules only. Right:Coupled VelocityModules and DistanceModule. Scaled trajecto-ries (green lines) lead to better convergence at the surface": "where t0 = t and XXXt0 = XXXt0 = XXXt. The first term ofLC encourages the DistanceModule to infer the relative dis-tance of XXXt0 from the clean surface, as compared to XXX0.The last term encourages points to return to the clean sur-face. We set 2 = 2 102 to ensure the loss contributionof the last term is of the same order as that of the first one.Consequently, Eq. (11) becomes,",
  ". Training and evaluation details": "We follow the training procedure of ScoreDenoise , andtrain our model on the PUNet dataset consisting of 40point clouds for training and 20 point clouds for testing. Toensure consistency with ScoreDenoises training settings,we add Gaussian noise sampled with standard deviationH = 2% of the bounding sphere radius to each clean pointcloud. Our training procedure only requires the high noisevariants and the clean ground truth targets. All intermedi-ate states at noise scales = (1 t)H, with t U(0, 1),are created as linear interpolations between these two, ini-tial and final states, as per Eq. (4). For testing, we alsoconsider 10 test point clouds from the PCNet dataset provided by ScoreDenoise. These synthetic point cloudscontain Gaussian noise at scales of 1%, 2% and 3% of thepoint clouds bounding sphere radius. We use two differ-ent sampling densities of 10K and 50K points to evaluatefiltering ability across different sparsity settings. Moreover,to assess filtering results on real-world noisy point clouds,we compare methods on the Kinect v1 dataset that com-prises of 71 point clouds and 4 scenes extracted fromthe Paris-Rue-Madame dataset . Finally, we provide acomparison on 4 scenes of the Kitti-360 dataset , in thesupplementary document. Following , all methodsare only trained on PUNet with Gaussian noise.Implementation. We train and test StraightPCF on aNVIDIA GeForce RTX 3090 GPU using PyTorch. We usethe Adam optimizer with a learning rate of 1 104. Sim-ilar to , we use PyTorch3D to compute ChamferDistance (CD) and Point2Mesh (P2M) metric values. . Visual filtering results for 50K resolution shapes ( = 2%) within the PUNet and PCNet datasets. The darker (i.e., more blueish)the better. We achieve both strong point-wise P2M results while also ensuring well distributed points (illustrated by close-ups) unlikeDeepPSR or IterativePFN which have holes indicating clustering.",
  ". Performance on synthetic data": "and illustrate filtering results on the syn-thetic PUNet and PCNet datasets. Our method has a clearedge over others in recovering the underlying clean pointdistribution demonstrated by superior CD results across allnoise settings. We also achieve strong P2M results on thePUNet dataset. While IterativePFN has marginally bet-ter P2M results on the PUNet data, this does not ensure agood distribution of points as evidenced by visual resultsin . Here, for noisy point clouds at 50K resolutionand 2% noise, IterativePFN exhibits small holes, indicatingclustering. Moreover, our network consists of only 530Kparameters and is roughly 83% smaller than that of Itera-tivePFN, given the latters 3.2M parameters. DeepPSR ,despite using a post-processing regularization step, also suf-fers from holes and poor point distributions. We also notethat IterativePFN generalizes poorly to higher noise scalesoutside the training noise scales (where maximum noise is = 2%). The ability of our method to generalize wellacross different data is demonstrated by the superior perfor-mance on the PCNet dataset. The PCNet shapes are unseenduring training. Our method obtains both superior CD andP2M results over all other methods. At 10K resolution and = 3% noise, our method offers a 17.1% reduction in CDerror and 24.1% reduction in P2M error. Our method alsoyields state-of-the-art results at 50K resolution where, for = 3%, the CD error improvement is 13.2% and P2M error improvement is 9.4%. Visual filtering results in indi-cate that our method outperforms others in recovering com-plex details such as the legs of the Camel which are closelysituated. By contrast, methods such as Pointfilter andPDFlow flatten points between these close surfaceswhile IterativePFN does not recover the body well. Fur-thermore, on a complex shape as Netsuke, we outperformother methods which either cause clustering (e.g., PDFlow,IterativePFN) at this high noise scale or leave behind noisedue to limited filtering ability (e.g., ScoreDenoise).",
  ". Performance on real-world scanned data": "Next we consider filtering results on scanned data. provides quantitative results on the Kinect dataset and illustrates visual results on the Paris-Rue-Madame dataset.Our method performs favorably on the Kinect data, obtain-ing a 1.82% reduction on CD errors, as compared to It-erativePFN . As this data is very sparse, our P2M re-sult is marginally higher than Pointfilter and Score-Denoise .These methods focus on returning pointsto the surface yet succumb to clustering artifacts whereasour method both recovers surfaces while retaining goodpoint distributions.The Paris-Rue-Madame dataset con-tains high noise scans due to outdoor environmental factors.In , we visualize filtering results for several most re-cent, state-of-the-art methods. In general, methods such asPDFlow and DeepPSR perform poorly in remov-ing noisy artifacts while IterativePFN causes points to",
  ".Quantitative results on Kinect data.Our network islightweight, with just 530K parameters (17% of IterativePFN).CD and P2M values are multiplied by 104": "cluster near the original scan lines. Our method, however,recovers the underlying clean surface and ensures a muchbetter point distribution, as evidenced by the close-ups inScene 1.In Scene 2, PDFlow and IterativePFN are notable to clean the surface of the parked vehicle whereas ourmethod recovers the underlying shape with fewer noisy ar-tifacts.",
  ". Ablation Study and Discussion": "We train and test several variant architectures in order toascertain the impact of the proposed VelocityModule (VM)and DistanceModule (DM). The results are given in .Our coupled VM + DM architecture (V5) increases the pa-rameter number to 530K. Therefore, we train anotherLarge VM with 530K parameters (V3). We find that di-rectly increasing the parameter number (V3) leads to verylimited performance gain while V5 exhibits far superior per-formance. Furthermore, the coupled VM + DM architecture(V5) significantly outperforms the single VM (V1 and V2)architectures. Finally, there is a noticeable difference in per-formance with and without a DM as evidenced by the dis-",
  ". Ablation results for different VelocityModule (VM) andDistanceModule (DM) configurations": "parity between V4 and V5. We provide further ablations,including higher VM couplings, in the supplementary doc-ument.Limitation. While our StraightPCF yields state-of-the-art results across multiple datasets, we observe relativelylow performance on low density or high sparsity data, whichis similar to current methods. We provide the visual resultsin the supplementary document due to space limit.",
  ". Conclusion": "Recent deep learning based filtering methods focus on mov-ing noisy points along stochastic paths to remove noisefrom input point clouds. We propose the first study to con-sider filtering points along straight paths, leading to smallerdiscretization errors and fewer filtering iterations.Thislightweight method, while being parameter efficient, deliv-ers filtered point distributions closer to that of the groundtruth distributions without requiring any regularization inloss function or post-processing.Our method achievesstate-of-the-art performance on multiple synthetic and real-world datasets across standard filtering metrics, showcasingits superiority and effectiveness.",
  "H Chen, B Du, S Luo, and W Hu. Deep point set resamplingvia gradient fields. IEEE Transactions on Pattern Analysis& Machine Intelligence, 45:29132930, 2023. 2, 4, 6, 7, 1,5": "Dasith de Silva Edirimuni, Xuequan Lu, Gang Li, and Anto-nio Robles-Kelly. Contrastive learning for joint normal esti-mation and point cloud filtering. IEEE Transactions on Vi-sualization and Computer Graphics, pages 115, 2023. 2,3 Dasith de Silva Edirimuni, Xuequan Lu, Zhiwen Shao, GangLi, Antonio Robles-Kelly, and Ying He. Iterativepfn: True it-erative point cloud filtering. In Proceedings of the IEEE/CVFConference on Computer Vision and Pattern Recognition(CVPR), pages 1353013539, 2023. 2, 3, 4, 6, 7, 5",
  "D. Levin. The approximation power of moving least-squares.Math. Comput., 67:15171531, 1998. 2": "Qing Li, Huifang Feng, Kanle Shi, Yue Gao, Yi Fang, Yu-Shen Liu, and Zhizhong Han. NeuralGF: Unsupervised pointnormal estimation by learning neural gradient function. InThirty-seventh Conference on Neural Information Process-ing Systems (NeurIPS), 2023. 3 Qing Li, Huifang Feng, Kanle Shi, Yue Gao, Yi Fang,Yu-Shen Liu, and Zhizhong Han.SHS-Net:Learningsigned hyper surfaces for oriented normal estimation of pointclouds.In Proceedings of the IEEE/CVF Conference onComputer Vision and Pattern Recognition (CVPR), pages1359113600, Los Alamitos, CA, USA, 2023. IEEE Com-puter Society. 3",
  "R. Preiner, O. Mattausch, Murat Arikan, R. Pajarola, and M.Wimmer. Continuous projection for fast l1 reconstruction.ACM Transactions on Graphics (TOG), 33:1 13, 2014. 1,2": "C. Qi, Hao Su, Kaichun Mo, and L. Guibas. Pointnet: Deeplearning on point sets for 3d classification and segmenta-tion. 2017 IEEE Conference on Computer Vision and PatternRecognition (CVPR), pages 7785, 2017. 2 Charles Ruizhongtai Qi, Li Yi, Hao Su, and Leonidas J.Guibas. Pointnet++: Deep hierarchical feature learning onpoint sets in a metric space. In Advances in Neural Infor-mation Processing Systems. Curran Associates, Inc., 2017.2 Marie-Julie Rakotosaona, Vittorio La Barbera, Paul Guer-rero, N. Mitra, and M. Ovsjanikov. Pointcleannet: Learn-ing to denoise and remove outliers from dense point clouds.Computer Graphics Forum, 39, 2020. 2, 4, 5, 6",
  "Riccardo Roveri, A. Cengiz Oztireli, Ioana Pandele, andMarkus Gross. Pointpronets: Consolidation of point cloudswith convolutional neural networks. Computer Graphics Fo-rum, 37(2):8799, 2018. 2": "Andres Serna, Beatriz Marcotegui, Francois Goulette, andJean-Emmanuel Deschaud.Paris-rue-madame database -a 3d mobile laser scanner dataset for benchmarking ur-ban detection, segmentation and classification methods. InICPRAM, 2014. 1, 6 Yang Song and Stefano Ermon. Generative modeling by es-timating gradients of the data distribution. In Proceedingsof the 33rd International Conference on Neural InformationProcessing Systems. Curran Associates Inc., 2019. 3",
  "Yue Wang, Yongbin Sun, Ziwei Liu, Sanjay E. Sarma,Michael M. Bronstein, and Justin M. Solomon. Dynamicgraph cnn for learning on point clouds. ACM Transactionson Graphics (TOG), 2019. 2": "L Wu, D Wang, C Gong, X Liu, Y Xiong, R Ranjan, R Kr-ishnamoorthi, V Chandra, and Q Liu. Fast point cloud gen-eration with straight flows. In 2023 IEEE/CVF Conferenceon Computer Vision and Pattern Recognition (CVPR), pages94459454. IEEE Computer Society, 2023. 3 Lequan Yu, Xianzhi Li, Chi-Wing Fu, Daniel Cohen-Or, andPheng-Ann Heng. Pu-net: Point cloud upsampling network.In Proceedings of the IEEE Conference on Computer Visionand Pattern Recognition (CVPR), 2018. 6, 2, 4, 5 Dongbo Zhang, Xuequan Lu, Hong Qin, and Y. He. Point-filter: Point cloud filtering via encoder-decoder modeling.IEEE Transactions on Visualization and Computer Graph-ics, 27:20152027, 2021. 2, 4, 6, 7, 5",
  "A.1. VelocityModule training": "In Sec. 4.1 of the main paper, we presented the Velocity-Module that enables filtering via straight flows. Here, weprovide more detail into its training objective.We trainthe VelocityModule by minimizing the loss of Eq. (7) inthe main paper.During training, we first draw samplesXXX0 = YYY + H N(0, I) and XXX1 = YYY from 0and 1, respectively. Given a pair (XXX0, XXX1), we use thelinear interpolation of Eq. (4), given in the main paper, tosample an intermediate state at time t U(0, 1). For thefiltering task, we do not have explicit knowledge of the timestep at which we start the filtering process. Consequently,we do not input the time step t to the VelocityModule, weonly provide XXXt. We then obtain the optimal parameters",
  "k=0vvvk( XXX(t+k)/T ). (17)": "We apply our StraightPCF network across T = N K to-tal iterations. At very high noise levels, this entire filteringprocess has to be repeated, similar to ScoreDenoise .The reason for this is the upper limit of our training noisescales is only = 2%. Therefore, at inference, for = 2%noise, we repeat the full position update 2 times while for = 3%, we repeat the process 3 times.",
  "B.FurtherEvaluationonSyntheticandScanned Data": "In this section, we provide additional results on both syn-thetic and scanned data that could not be added to themain paper, due to constraints of space.Moreover, weprovide more detail into our experimental set-up. To ob-tain Chamfer Distance (CD) and Point2Mesh (P2M) results,we have used the implementation of PyTorch3D withthe same settings as ScoreDenoise , PDFlow andDeepPSR . For all filtering results, to ensure fair com-parison, learning based methods were only trained on thesynthetic PUNet training set with Gaussian noise.",
  "B.1. Performance of additional methods on PUNetand PCNet data with Gaussian noise": "presents the performance of deep learning-basedmethods and conventional methods which were not in-cluded in the main paper, due to limitations of space. Theseresults are for PUNet and PCNet data with Gaussian noiseat scales of 1%, 2% and 3% of the bounding spheres ra-dius. In general, we see that these methods perform sub-optimally, with relatively higher CD and P2M errors. Fur-thermore, conventional methods require hyper-parametertuning to obtain the best possible results. This is a tediousprocess which deep learning based methods help remedy.",
  "B.2. Additional visual results on real-world scanneddata": "illustrates filtering results on Scene 3 and Scene 4of the Paris-Rue-Madame dataset.We observe from theclose-ups in Scene 3 and 4 that PDFlow and DeepPSRleave behind high amounts of noise near the building win-dows. By comparison, IterativePFN fairs better but is notable to completely filter these noisy artifacts. StraightPCFis able to recover cleaner, smoother surfaces and removes",
  ". Additional visual results on the real-world Paris-Rue-Madame dataset": "a higher proportion of noise. This is evident in the close-ups of the windows and the close-up of the car roof. Fur-ther evaluation on real-world outdoor scenes is provided in which illustrates filtering results on 4 scenes of theKitti-360 dataset . This dataset contains point clouds ata high sparsity setting and high noise level. While othermethods leave behind noisy remnants, StraightPCF pro-vides smoothly filtered surfaces. Moreover, the points arebetter distributed, as compared with DeepPSR which leavesbehind clustering artifacts. Next, demonstrates vi-sual filtering results on the Kinect data.Methods suchas PDFlow, DeepPSR and IterativePFN perform poorly onscans such as Boy and Pyramid, in comparison to Straight-",
  "(18)": "The noise scale s is set to 1%, 2% and 3% of the boundingspheres radius. In contrast to the synthetic data presentedin the main paper, which contain isotropic Gaussian noise,here we look at Gaussian noise that is anisotropically dis-tributed. and provide quantitative and visualresults on this noise pattern. Our method outperforms oth-ers across most resolution and noise settings on both the",
  "PUNet and PCNet datasets": "2) Laplace distribution where the noise scale s is setto 1%, 2% and 3% of the bounding spheres radius. Ta-ble 6 and provide quantitative and visual results onthis noise pattern. We note that the noise intensity for thisnoise pattern is generally higher than the case of Gaussiannoise. However, our method satisfactorily filters syntheticdata across both PUNet and PCNet datasets. IterativePFNand DeepPSR obtain competitive P2M results, yet induceclustering which can be seen from the formation of smallholes on the Camel and Netsuke shapes of . Wealso observe that while our StraightPCF method interpo-",
  "the synthetic datasets with uniform noise. Our network is lightweight, with just 530K parameters (17% of IterativePFN).CD and P2M values are multiplied by 104": "lates between Gaussian high noise variant patches and un-derlying clean patches during training time, the results onthe Laplace distributed synthetic data demonstrates the highgeneralizability of our method.3) Uniform distribution of noise within a sphere of ra-dius s.The probability to sample noise at a position xxxwithin the sphere is given by,",
  "4s3 ,xxx2 s,0,Otherwise(19)": "where the noise scale s is set to 1%, 2% and 3% of thebounding spheres radius. This noise distribution is not uni-modal unlike the previous distributions and generally hasa lower noise intensity than that of Gaussian noise. Ta-ble 7 and provide quantitative and visual results onthis noise pattern. Overall, StraightPCF consistently out-performs others on the Chamfer Distance metric, indicatingits ability to recover a distribution of points closer to thatof the clean point cloud. Furthermore, analysis of the vi-sual results again reinforces the conclusion that while somemethods such as IterativePFN may yield lower P2M errors,they cause points to cluster and leave behind small holes.",
  ". Runtimes of state-of-the-art methods on point clouds with50K points and 2% Gaussian noise, from the PUNet dataset": "runtime.In general, DeepPSR is the fastest method butits overall performance across synthetic and scanned datais sub-optimal. To improve performance results, DeepPSRwould potentially need to filter point clouds for additionaliterations, leading to higher runtimes.The same is truefor ScoreDenoise. However, we obtain state-of-the-art per-formance with highly competitive runtimes. As mentionedpreviously, StraightPCF is much more lightweight than It-erativePFN, its closest competitor in terms of performance.It has only 530K parameters compared to IterativePFNs 3.2M parameters.",
  ". Visual results for 50K resolution shapes with Laplace noise and noise scale s = 2% of the bounding sphere radius": "the other variants, leading to a faster runtime. Generally,it also provide either the best or second best results on theablation set. The results of Tables 9 further reinforces theimportance of the DistanceModule to ensure convergenceat the clean surface, especially as noise increases. More-over, demonstrates the importance of Euler steps N. For N = 1, we obtain sub-optimal results. For N = 3,we strike a balance between performance and runtime effi-ciency as runtime increases as N increases. Also, we seeonly a marginal improvement in performance for N > 3.",
  "Finally, illustrates the visual filtering results for theNetsuke shape with 3K resolution and = 3%. We see that": ". Visual results for the 3K resolution Netsuke shape withGaussian noise and = 3% of the bounding sphere radius. Fil-tering sparse point clouds at high noise is a challenge for Straight-PCF. However, it recovers a better distribution of points, as com-pared with other state-of-the-art methods. at this high sparsity setting, it is difficult to recover high lev-els of geometric detail. However, our method performs bet-ter than other state-of-the-art methods and recovers a nicerdistribution of points."
}