{
  "Abstract": "This technical report presents our teams solution for theWeatherProof Dataset Challenge: Semantic Segmentationin Adverse Weather at CVPR24 UG2+. We propose a two-stage deep learning framework for this task. In the rststage, we preprocess the provided dataset by concatenat-ing images into video sequences. Subsequently, we lever-age a low-rank video deraining method to generate high-delity pseudo ground truths. These pseudo ground truthsoffer superior alignment compared to the original groundtruths, facilitating model convergence during training. Inthe second stage, we employ the InternImage network totrain for the semantic segmentation task using the generatedpseudo ground truths. Notably, our meticulously designedframework demonstrates robustness to degraded data cap-tured under adverse weather conditions. In the challenge,our solution achieved a competitive score of 0.43 on theMean Intersection over Union (mIoU) metric, securing arespectable rank of 4th.",
  ". Introduction": "Semantic segmentation, the process of assigning a dis-tinct class label to each pixel within an image, encoun-ters substantial impediments when confronted with adverseweather conditions such as rain and fog.The Weather-Proof Dataset Challenge: Semantic Segmentation in Ad-verse Weather (CVPR24 UG2+) serves as a platform for as-sessing the resilience of semantic segmentation techniquesunder these conditions.This challenge mandates the development of an efcientsolution for performing semantic segmentation on a diversecollection of real-world image sequences captured underrainy and foggy conditions. The provided sequences exhibitvariations in rain intensity, fog density, and scene complex-ity, necessitating a robust algorithm capable of accuratelysegmenting objects while maintaining structural and contex-tual information. To tackle this challenge, we propose a two-stage frame-work.The initial stage leverages a low-rank video de-raining method to generate high-delity pseudo groundtruth images. This method accomplishes this by removingrain streaks and restoring image structures from the alignedrainy frames. Subsequently, the second stage employs apre-trained InternImage network, a Convolutional Neu-ral Network (CNN) based semantic segmentation architec-ture, ne-tuned on the aforementioned pseudo ground truthimages.This report furnishes a comprehensive overview of ourproposed methodology, encompassing data analysis, intri-cate details of the framework, and the outcomes of our ex-perimentation.The remaining sections cover our method () andExperimental settings ().",
  ". Overview of Methods": "Inspired by previous works that employed a two-stageapproach in image deraining tasks, we have also de-signed a two-stage framework to address the semantic seg-mentation challenge in the WeatherProof dataset, aimingto mitigate the impact of adverse weather conditions on im-age quality.In the rst stage, we combined the 300 images from thetest set published in the nal testing phase of the competi-tion into a video sequence. Subsequently, we applied theLow-Rank Tensor Recovery (LLRT) algorithm for videoderaining preprocessing of this sequence, utilizing infor-mation from multi-frame aligned images to generate high-quality pseudo ground truth images.In the second stage,we utilized the CNN-basedInternImage semantic segmentation network. We trainedthe InternImage solely with the training and validation setdata provided by the competition, without any additionalpreprocessing of the training data. Finally, we input thepseudo ground truth images generated in the rst stage intothe well-trained InternImage to obtain the nal semantic",
  "segmentation predictions": "Through this two-stage strategy, we were able to fullyleverage the advantages of the video deraining algorithm toeliminate the impact of adverse weather conditions (such asrain and fog) on image quality during the testing phase, lay-ing the foundation for subsequent semantic segmentationtasks. At the same time, the CNN semantic segmentationnetwork can learn effective feature representations on am-ple training data, achieving precise pixel-level classication.This framework integrates the strengths of video derainingand single image semantic segmentation, making it an ef-cient solution.",
  ". Low-Rank Tensor Recovery": "Video deraining is a highly challenging task that re-quires the simultaneous use of both temporal and spatial di-mensions of information. The Low-Rank Tensor Recovery(LLRT) algorithm proposed by Chang et al. for multi-spectral image denoising tasks can effectively capture theinherent structural correlations within an image sequenceand is therefore also applicable to video deraining prepro-cessing. The core of the LLRT algorithm is a unidirectional low-rank tensor recovery model. It constructs a third-order ten-sor to jointly model spatial local sparsity, non-local self-similarity, and spectral correlation. Unlike other works thatsimply sum the low-rank properties of each mode, LLRT,through detailed analysis, nds that the low-rank naturecorresponding to non-local self-similarity is far superior tospatial and spectral modes. Based on this nding, LLRTimposes low-rank constraints only on the non-local self-similarity mode, more reasonably describing the intrinsicstructure of the data. In implementation, the authors designed an efcient opti-mization algorithm that can quickly solve the sub-problemsof unidirectional low-rank tensor recovery and spectral gra-dient sparsication. With all these innovations, the LLRTalgorithm has achieved excellent performance in multi-spectral image denoising. In this work, we treat the 300 images of the test set asa video sequence and apply the LLRT algorithm for derain-ing preprocessing. By leveraging redundant information inboth temporal and spatial dimensions, LLRT can effectivelyremove the effects caused by adverse weather conditions,generating high-quality pseudo ground truth images for sub-sequent semantic segmentation tasks.",
  ". CNN-based method: InternImage": "The InternImage semantic segmentation network isa cutting-edge deep learning model that has demonstratedremarkable performance in the eld of computer vision,particularly in the context of the COCO dataset where itachieved an impressive 65.4 mAP, leading the state-of-the-art benchmarks. The models success has been recognizedand it has been highlighted as a CVPR 2023 highlight paper,ranking in the top 2.5% of submissions.InternImage is distinguished by its innovative approachto large-scale vision foundation models, incorporating de-formable convolutions to adapt to various image distortionsand irregularities. This feature is particularly useful in se-mantic segmentation tasks where the model must accuratelyidentify and classify different objects within an image, oftenunder challenging conditions such as adverse weather.In our application of InternImage to the WeatherProofdataset, we have ne-tuned the model using the providedtraining and validation datasets. The pseudo ground truthimages generated from the LLRT video deraining prepro-cessing serve as input to the InternImage network, enablingit to produce highly accurate semantic segmentation predic-tions. The integration of InternImage into our two-stageframework has been instrumental in enhancing the overallperformance of our system, capitalizing on the strengths ofboth video deraining and CNN-based semantic segmenta-tion.",
  ". Experimental settings": "Dataset. In our experiments, we utilized the training andvalidation sets provided by the ofcial WeatherProof datasetfor training our model. Additionally, the InternImage modelwas initialized with weights pre-trained on the ImageNetdataset, providing a solid foundation for feature extractionand accelerating convergence on the specic task. Aftertraining, the model was applied to the test set that had beenpreprocessed by the video deraining algorithm. This stepleveraged temporal information from the video sequence tomitigate the effects of adverse weather conditions, such asrain and fog, generating high-quality pseudo ground truthimages. These pseudo ground truth images served as the -nal reference labels for assessing the models semantic seg-mentation performance under actual adverse weather condi-tions.Training setting. We ne-tuned the InternImage-H seman-tic segmentation model on the ofcial WeatherProof train-ing and validation datasets without any additional prepro-cessing of the training data. For the ne-tuning, we utilizedpre-trained weights from ImageNet and scaled the origi-nal images to an input resolution of 1024256 pixels, fol-lowed by random cropping to 256256 pixel patches. Datapreprocessing involved random ipping, color distortion, and other augmentation techniques, along with normaliza-tion using the mean values [103.336, 104.443, 100.035]and standard deviations [39.329, 38.147, 42.803]. The op-timizer was AdamW with an initial learning rate of 1e-5, a polynomial decay strategy, a 1500-iteration warmup,and gradient clipping with a norm of 0.1. The loss func-tion was a weighted cross-entropy loss that assigned differ-ent weights to various classes to balance their signicance.Training settings included a batch size of 2 per GPU, a max-imum of 30,000 iterations, and evaluations using the mIoUmetric every 100,000 iterations to save the best model. Theexperiments were conducted on a server equipped with oneNVIDIA Tesla L20 GPU 48GB, an Intel(R) Xeon(R) Plat-inum 8457C CPU, Ubuntu 20.04.4 LTS operating system,and PyTorch version 1.11.0.",
  ". Conclusion": "We proposed a two-stage framework to tackle the Weath-erProof semantic segmentation challenge at CVPR24UG2+. First, we employed a low-rank based video derain-ing method to generate high-quality pseudo ground truths,then ne-tuned the InternImage semantic segmentation net-work on these pseudo ground truths. This framework inge-niously combined the strengths of video deraining and sin-gle image semantic segmentation, achieving a mIoU scoreof 0.43 and ranking 4th in this challenge. Our method notonly performed well in this challenge but also exhibitedgreat generalizability, being applicable to other vision tasksrequiring robustness against adverse environmental condi-tions. Y. Chang, L. Yan, and S. Zhong, Hyper-laplacian regu-larized unidirectional low-rank tensor recovery for mul-tispectral image denoising, in 2017 IEEE Conferenceon Computer Vision and Pattern Recognition (CVPR),pp. 59015909, 2017. W. Wang, J. Dai, Z. Chen, Z. Huang, Z. Li, X. Zhu,X. Hu, T. Lu, L. Lu, H. Li, et al., Internim-age: Exploring large-scale vision foundation modelswith deformable convolutions, in Proceedings of theIEEE/CVF Conference on Computer Vision and PatternRecognition, pp. 1440814419, 2023."
}