{
  "Abstract": "Semi-supervised 3D object detection can benefit from thepromising pseudo-labeling technique when labeled data islimited. However, recent approaches have overlooked theimpact of noisy pseudo-labels during training, despite ef-forts to enhance pseudo-label quality through confidence-based filtering. In this paper, we examine the impact ofnoisy pseudo-labels on IoU-based target assignment andpropose the Reliable Student framework, which incorpo-rates two complementary approaches to mitigate errors.First, it involves a class-aware target assignment strategythat reduces false negative assignments in difficult classes.Second, it includes a reliability weighting strategy that sup-presses false positive assignment errors while also address-ing remaining false negatives from the first step. The relia-bility weights are determined by querying the teacher net-work for confidence scores of the student-generated pro-posals. Our work surpasses the previous state-of-the-arton KITTI 3D object detection benchmark on point cloudsin the semi-supervised setting. On 1% labeled data, ourapproach achieves a 6.2% AP improvement for the pedes-trian class, despite having only 37 labeled samples avail-able. The improvements become significant for the 2% set-ting, achieving 6.0% AP and 5.7% AP improvements for thepedestrian and cyclist classes, respectively. Our code willbe released at",
  "Percent": "(a) Class-agnostic threshold CarPedestrianCyclist fg = 0.75 0.00.20.40.60.8 IoUFG (b) Class-aware thresholds fgcar = 0.65 fgped = 0.45 fgcyc = 0.4 CarPedestrianCyclist . Illustrates the need for class-aware foreground thresh-olds for foreground/background target assignment. The IoUFGon the x-axis shows the IoU of proposals with respect to pseudo-labels that are foreground relative to ground truths. (a) The de-fault class-agnostic threshold in the PV-RCNN baseline. (b) Ourclass-aware thresholds.Lowering the threshold and includingmore foreground proposals can benefit challenging and uncom-mon classes. It also significantly reduces false negatives with IoUsclose to zero. (Best viewed in color)",
  "posed to address this problem. Unlike supervised methods,these approaches require only a limited amount of annotateddata for training, with the remaining data being unlabeled": "Several semi-supervised techniques have been proposedfor object detection, including . Self-training using pseudo-labeling is the most commonly usedmethod and has shown effectiveness in both object detec-tion and classification . At its core,a student-teacher framework is used to incrementally trainteacher and student models on unlabeled data in a mutuallybeneficial manner. The teacher model is initially trainedin a supervised manner on limited labeled data to generatepseudo-labels (PL) to train the student model on unlabeleddata. Mean-teacher-based techniques use an ex-ponential moving average (EMA) of the student modelsweights to update the teacher models weights, leading tomore stable predictions on the unlabeled data.",
  "arXiv:2404.17910v1 [cs.CV] 27 Apr 2024": "Due to its limited pre-training on labeled data, theteacher model fails to generalize effectively, resulting innoisy pseudo-labels that hinder the learning of the studentmodel.Existing methods overcome this problem by fil-tering out low-quality pseudo-labels with confidence-basedthresholds, acting as a global quality-based filtering mech-anism. However, even with strict filtering, pseudo-labelsremain noisy, as shown in (a). They have erroneousIntersection over Union (IoU) with proposals that are fore-ground relative to ground truths. This poses a significantproblem for downstream tasks such as target assignment inRegion Proposal Network (RPN) and Region-based Convo-lutional Neural Network (RCNN) modules, which rely onthese noisy IoUs.The standard target assignment inevitably misclassifiesthe proposals with IoUs close to zero, i.e., the bar close tothe y-axis in (a), as background, leading to perfor-mance degradation. also shows distinct class-specific distributions ofIoUs due to the different levels of difficulty and the un-balanced distribution of classes in the dataset. Neglectingthe difference in distributions poses a challenge for class-agnostic target assignment methods in detectors such asPV-RCNN. A high-value class-agnostic threshold will ex-acerbate false-negative (FN) errors for difficult classes, suchas pedestrians and cyclists, with lower distribution modes,while lowering the threshold will cause many false positives(FP) for the car class, which is easier to learn.We address these challenges from two perspectives: 1)reducing false-negative and false-positive errors using anew and simple class-aware target assignment approach,and 2) increasing robustness in training against potentialfailure of our initial assignment by weighting the classifi-cation loss to suppress misclassified proposals. These twosteps are complementary, with the first step aiming to min-imize assignment errors by considering the difference be-tween the distribution modes of different classes, while thesecond step mitigates residual errors from the first step.To this end, we first modify the target assignment processin two key areas where IoU scores are used. We replace thestandard foreground/background random subsampling witha top-k IoU-based subsampler to promote learning fromuncertain or difficult background proposals. We also pro-pose local class-aware foreground thresholds for target as-signment. As shown in (b), the new thresholds in-clude more foreground proposals of difficult classes (lead-ing to higher recall) while preserving a high value for thedominant car class to ensure learning from high-precisionproposals. The foreground and background thresholds di-vide proposals into three categories: foreground (FG), back-ground (BG), and uncertain (UC). We assign hard labels toFG and BG proposals and use soft labels for those in theUC category to consider their uncertainty. Second, to address false negative/positive target assign-ment errors, we propose to use the teacher to provide reli-ability scores for the student-generated proposals. To thisend, the teachers RCNN head refines the students pro-posals and assigns confidence scores to them, which weuse to weight the RCNN classification loss on unlabeleddata using different FG/UC/BG weighting options. Our re-sults show that weighting uncertain and background pro-posals effectively suppresses false positives and false nega-tives, respectively, and outperforms other proposed weight-ing schemes.In summary, our key contributions are as follows:",
  ". 3D Object Detection": "Research on 3D object detection from point clouds fo-cused on a birds eye view of the lidar point cloud .However, VoxelNet employed a different approach bydividing the point cloud into 3D voxels and encoding eachvoxel using a feature encoding layer. Although 3D con-volution layers were applied to further aggregate features,this method was considered time-consuming due to the 3Dconvolutions involved. To address this, SECOND pro-posed a spatially sparse convolutional network to improvethe speed of previous methods. PointPillars then sug-gested using vertical columns instead of voxels and a 2Dconvolutional network to encode features. This approachwas found to be faster and more robust than previous meth-ods. Another approach by PointNet and PointNet++ was to work directly on encoding points instead of voxels,resulting in more efficient and flexible approaches. In thisstudy, we use PV-RCNN , a robust two-stage detectorthat combines the VoxelNet and PointNet approaches andachieves high performance.",
  "+": ". Overview of our Reliable Student framework. It uses a teacher-student network, where the EMA teacher produces high-qualitypseudo-label boxes bi. We compute the IoU ui between bi and the students post-NMS proposals ri, followed by a top-k sampling of ribased on ui. The sampled proposals ri are injected into the student and teacher RCNN heads to predict the objectness scores si and si,respectively. While si serves as an input to the RCNN classification loss Lclsu , si are converted into reliability weights wi for Lclsu . Theclass-aware target assignment module uses thresholds for different classes on ui to assign objectness targets ti for Lclsu . pseudo-labeling and consistency approaches.It uses notonly label-level consistency but also feature-level consis-tency, which further improves the performance of the fi-nal detector.This approach also uses focal loss similarto to alleviate the class imbalance in pseudo-labeling. considers the localization task as a classification taskand proposes a certainty-aware pseudo-label approach. Byquantifying the quality score of classification and regres-sion, they adjust the threshold used for generating pseudo-labels. Instant-Teaching proposes to generate pseudoannotation for unlabeled data using a weak augmentationin mini-batch, then using these predicted annotations asground truth of the same image with strong augmentation.For strong augmentation, the authors use Mixup . Recent works have also focused on class imbalance andconfirmation bias issues.LabelMatch leverages thelabeled data distribution for adaptive thresholding to fil-ter out unbiased pseudo-labels and recalibrates the high-quality unreliable pseudo-labels into reliable ones. Unbi-ased Teacher attempts to address the class-imbalanceproblem in pseudo-labeling by incorporating a focal lossthat forces the model to focus on challenging samplesfrom the underrepresented classes. Humble Teacher achieves comparable results by using soft labels instead ofhard labels with a teacher ensemble network to improve thereliability of the pseudo-labels. Soft Teacher deals with the misclassification of fore-ground proposals by suppressing the classification loss us-ing the teachers confidence scores. Our approach followsthis but additionally considers the reliability of foregroundtargets with a foreground reliability weight. Our work alsodiffers from Soft Teacher in that we use a third category oftargets in the RCNN, called the Uncertain (UC) region, andassign soft labels to them. These targets may correspond to real foreground or background boxes. Thus, it is crucialto assign appropriate weights to this region to optimize theprecision-recall trade-off. Combating Noise assumesthat background proposals are accurate, and it suppressesthe noisy foreground proposals losses. In contrast, we showthat dealing with both misclassified foreground and back-ground proposals is important.There are few works on semi-supervised point-based 3Dobject detection, such as SESS and 3DIoUMatch .SESS uses asymmetric data augmentation techniques andenforces consistency between teacher and student predic-tions through different losses. 3DIoUMatch proposesa pseudo-labeling approach for both indoor and outdoor 3Dobject detection. Inspired by FixMatch , they introducea joint confidence-based pseudo-label filtering mechanismusing predicted objectness and class probabilities. Addi-tionally, they estimate IoU and use it as a localization qual-ity to filter pseudo-labels. Unlike 3DIoUMatch, we employonly an objectness threshold, eliminating the complexity ofusing multiple thresholds. Moreover, unlike 3DIoUMatch,we adopt objectness supervision on unlabeled data. Ourfindings indicate that this strategy enhances performance.",
  ". Overview": "An overview of our approach is depicted in . Ourapproach is based on the mean-teacher framework, wherethe teacher creates PLs for unlabeled input to serve as asupervised signal for the student. The student is providedwith the strongly augmented version of the unlabeled inputas well as the labeled input, and its parameters are updatedthrough backpropagation. The teachers parameters, on theother hand, are gradually updated from the students param- eters using the exponential moving average strategy. To en-sure the quality of the generated PLs, we filter them basedon their confidence scores. We introduce the Class-awareTarget Assignment module (Sec. 3.2) with class-aware fore-ground thresholds on IoU of proposals with PLs to improverecall, particularly for challenging classes. This is based onthe understanding that the learning status of classes dependson their difficulty level and the availability of their instancesin the dataset. Given these foreground thresholds and thedefault background threshold, we define hard classificationtargets for the foreground and background proposals, whileuncertain proposals whose IoUs lay between the FG and BGthresholds are assigned soft targets.Due to the noisy IoU signal used for target assignment,some proposals may be mistakenly assigned to incorrect tar-gets, leading to FPs and FNs. To mitigate this, we introducethe reliability-based weight assignment module (Sec. 3.3),which assigns reliability weights to the proposals of eachcategory based on the dominant error type in that category,making the training more robust. To obtain the reliabilityweights, we use the teacher model to refine the studentsproposals using its RCNN module and use its confidencescore si as additional supervision to improve the studentsperformance. Given the students RCNN refinement boxand score {bi, si} and their corresponding targets, we usethe teacher score si to weight the loss of classification onunlabeled data.",
  ". Class-aware Target Assignment": "We investigate the problem of learning from noisy PLs,mainly used to supervise RPN and RCNN modules in thedetector. We focus on the RCNN module and its classifi-cation target assignment, where the proposals are assignedwith foreground/background labels.Denote P = {bn, cn, sn}Npln=1 as the set of filtered PLsconsisting of bounding box bn, category label cn, and theconfidence score sn. We define {ri} as the final proposalsor Regions of Interest (RoIs) generated by the student af-ter the IoU-guided filtering and deduplication of RPN pro-posals using Non-Maximum Suppression (NMS). Existingpseudo-labeling approaches use the IoU between these RoIsand PLs to assign category labels and FG/BG targets to pro-posals of unlabeled data in the RPN and RCNN modules ofPV-RCNN, respectively. In RCNN, for a given proposal, ifits maximum IoU with PLs, i.e., ui = maxpP IoU(ri, p),exceeds a predefined class agnostic foreground threshold fg, it is considered as a foreground proposal. We definethese IoU thresholds used in these two modules as localthresholds ( fgc ), as opposed to the global thresholds (fgc ),used to filter out low-quality PLs.We analyze the suboptimal classification target assign-ment from PLs with the optimal assignment from GTs. In, we evaluate the mean IoU of proposals that are foreground with respect to GTs, i.e., their IoUs with GTsare greater than the evaluation mode class-wise foregroundthreshold fgc . We observe two crucial issues when usingthe standard target assignment.First, the classes exhibit distinct mean IoU distribu-tions. Therefore, the standard target assignment strategybased on a single class-agnostic foreground threshold, e.g., fg = 0.75, cannot reliably classify the proposals. For thepedestrian and cyclist classes, which have lower distributionmodes than the car, such a class-agnostic threshold resultsin many misclassified foreground proposals whose IoU can-not exceed the threshold by a small margin. To address thisissue, we propose local class-aware foreground thresholds fgc , instead of a class agnostic fg on ui IoUs, to constructthe FG/BG target ti for the proposal ri as follows:",
  "fgc bg , bg ui fgc0,ui < bg.(1)": "Background proposals have consistently low IoUs, en-abling a single class-agnostic threshold bg to distinguishthem from other proposals.Second, the IoUs used for target assignment are unre-liable. This is particularly the case for the pedestrian andcyclist classes, which are difficult to learn due to their ob-ject size and the imbalanced class distribution of the dataset.Given the presence of noisy IoUs, despite the implementa-tion of class-specific local thresholds, the assignment car-ried out in Eq. (1) will inevitably result in the occurrence offalse negative (FN) and false positive (FP) errors.To examine how proposals in the FG, UC, and BG cate-gories are affected by the FP and FN errors, we illustrate thedensity plots in , showing the distribution of RoI IoUsrelative to both PLs and GTs. The FP proposals are referredto as foreground with respect to PL, but background withrespect to GT, whereas those that are the opposite are re-ferred to as FN proposals. As shown, each local class-awarethreshold divides the plot into three columns showing FG,UC, and BG sections from right to left.Ideally, we expect well-calibrated IoU scores such thatthe IoU of RoIs with respect to PLs are as close as pos-sible to their corresponding IoUs with respect to GTs. Inpractice, however, there exist two sub-densities close to theaxes contributing to the error. More specifically, in the fore-ground region, we observe the density of FP proposals insection (d), near the x-axis, for all classes. However, for thepedestrian class, we have significantly higher density com-pared to the other classes. In the background region, FNproposals are present in (a) near the y-axis. The definitionsof FP and FN have been extended to the uncertain region,i.e., sections (b) and (e), where FN and FP proposals are lo-cated in section (b) and at the bottom of section (e), close to 0.00.20.40.60.81.0 ui 0.0 0.2 0.4 0.6 0.8 1.0 vi (a)(b)(c) (d)(e)(f)",
  "Cyclist": "fgc = 0.4 bg = 0.25 c = 0.5 . Illustrates the density of IoU values of proposals with their matched PL (ui) and GT (vi) on the x-axis and y-axis, respectively.Denser regions are shown with darker shades. The red and orange vertical lines denote the local foreground (FG) ( fgc ) and background(BG) ( bg) thresholds, while the black horizontal line represents the FG threshold (c) for the evaluation mode, dividing the plot into sixsubregions. Subregions (a) and (f) represent false negative and true negative proposals, respectively. (b) and (e) depict proposals lying inthe uncertain region and are assigned with soft targets, while (c) and (d) depict true positive and false positive proposals, respectively. Theproposals are obtained from the last few training iterations. We also omit proposals that are in the background with respect to both GT andPL for better visualization. All three plots follow the same subregion breakdown. (Best viewed in color)",
  ". Reliability-based Weight Assignment": "To address these FP and FN erroneous proposals, we fo-cus on making the training robust against a given set of un-certain PLs. We propose weighting the classification lossof such proposals based on the reliability of their target as-signment, i.e., the IoU between RoI and PL. We seek a reli-ability score that can consistently assign a low value to bothFN and FP proposals. In this work, we evaluate the relia-bility score proposed by Soft Teacher. However, any otherreliability score can also be plugged into our framework.We estimate the reliability of the students proposalsbased on their corresponding teachers refined confidencescores. We use these scores to suppress the loss due to FPand FN targets. To this end, we first reverse the augmenta-tion h on the student proposals before sending them to theteacher. The teacher refines each students proposal ri usingits RoI pooling module and predicts yi = {bi, si}, where biand si denote the corresponding refined bounding box andits confidence score, respectively. The confidence score si,represents the foreground probability of the refined bound-ing box proposal, which acts as the reliability score for ri.We propose different reliability weighting schemes basedon the teachers confidence score si, for the RCNN classifi-cation loss of unlabeled samples.Based on our error breakdown in the previous section,we introduce reliability-based weighting options as follows:",
  "Foreground proposals (FG): suppress the FP pro-posals in subregion (d) of by incorporating theteachers foreground score as a weight (wi = si) forclassification loss for subregions (c) and (d)": "In all the weighting options, proposals belonging to theremaining categories are assigned with the reliability weightwi = 1. Later in Sec. 4.3.1, we evaluate the applicationof different weighting options individually and in combina-tion and achieve the best performance from UCFP + BGby suppressing FPs from uncertain proposals and FNs frombackground proposals.We further leverage these reliability-based weights to letthe student model learn more about challenging and uncer-tain proposals instead of the easy backgrounds. The studentmodels target assignment in RCNN involves computing theIoU between post-NMS proposals and pseudo-labels. Priorworks perform sampling on these IoUs such that, at most,50% of the foreground proposals are randomly sampled be-fore being passed on for refinement. The remaining back-ground proposals are further randomly subsampled, ensur-ing that 20% of them have low IoU (e.g., < 0.1), that areeasily classified as background. Our approach differs in thatit avoids subsampling of such easy backgrounds on unla-beled data and instead uses a top-k sampling strategy on theIoU. This allows the model to learn more about the chal-lenging backgrounds.",
  "% Improvement over Baseline+0.5+0.6+1.2+6.2+6.2+5.5-0.8+0.4+0.4+0.2+0.6+0.7+6.4+6.0+5.1+8.9+5.7+5.5": ". Results on the KITTI evaluation set based on mAP over 40 recall positions. PV-RCNN is the supervised-only baseline, and3DIoUMatch is the original work (both based on OpenPCDet v0.3). 3DIoUMatch (Baseline) is our adaptation of the original work toOpenPCDet v0.5, and 3DIoUMatch + ULB RCNN CLS is our modified version of the baseline with objectness supervision from unlabeleddata. () denotes borrowed results from , (\\) indicates non-available results, and Bold indicates the best results from OpenPCDet v0.5.",
  "i wi,(2)": "where Nb are the total number of proposals for a single un-labeled sample.GivenNllabeledsamples,wedefineDl={(xli, yli)}Nli=1, where yli contains the class labels andbounding box coordinates information, and use Nu un-labeled samples for Du = {xui }Nui=1.The unsupervisedRCNN loss Lu consists of the classification loss LclsufromEq. (2), and box regression loss Lregu , which is defined as:",
  "i=1(Lclsu (sui , tui ) + Lregu (bui , bui )),(3)": "where tui is the target for classification loss from Eq. (1),and bui is the bounding box of the assigned pseudo boxbased on ui, acting as the regression loss target. We fol-low 3DIoUMatch for the RCNN box regression loss Lregu ,as well as for the RPN classification and regression losses,to formulate the unsupervised loss Lu. The supervised lossLs is calculated similarly on labeled data using ground truthyli. The overall loss of the student model is defined as",
  "We evaluate our method on KITTI dataset, consistingof 7,481 training samples and 7,518 test samples. The train-ing samples are divided into the train set (3,712 samples) for": "training the model and the validation set (3,769 samples)for evaluation. We use 1% and 2% labeled data splits withthree folds each, provided by 3DIoUMatch . For eachfold, we carry out three trials with different random seedvalues and report the mean Average Precision (mAP) overall fold-trial combinations. The mAP is computed using arotated IoU threshold of 0.7, 0.5, and 0.5 for the car, pedes-trian, and cyclist classes, respectively, at 40 recall positions.Experiments are conducted over all three object difficultylevels - Easy, Moderate, and Hard.",
  "Implementation Details": "For a fair comparison with , we utilize PV-RCNN as the object detection backbone.We used the Open-PCDet v0.5 framework to implement our method andadapted the original 3DIoUMatch from OpenPCDet v0.3to v0.5 for a fair comparison. The data augmentation onthe student model is based on the 3DIoUMatch settings.Unlike 3DIoUMatch, which uses both RPN classificationand RCNN objectness scores to filter pseudo labels, ourapproach uses only the RCNN objectness threshold, i.e., plcar = 0.95 for car, and plped = plcycl = 0.85 for pedes-trian and cyclist. Unlike 3DIoUMatch, both the RPN andRCNN modules are supervised using labeled and unlabeleddata through classification and regression losses, with theunlabeled loss weight u = 1. On small amounts of data(1% and 2%), we pre-train PV-RCNN over 80 epochs with10 repeated traversals in each epoch and use 60 epochs with5 repeated traversals in each epoch for the training stage,similar to . We use a batch size of 8, consisting of 8labeled and 8 unlabeled samples in both stages. For theevaluation stage, we use the student model.",
  "Tab. 1 shows the results of our approach, the orig-inal state-of-the-art 3DIoUMatch method referred to as3DIoUMatch, and our adapted version of 3DIoUMatch,": ". Illustrates the assigned reliability weights for RCNN classification loss based on the IoU of the proposals with PLs (ui) on thex-axis and GT (vi) on the y-axis. The red and orange vertical lines depict the local class-aware foreground (FG) ( fgc ) and background(BG) ( bg) thresholds, respectively, while the black horizontal line represents the FG threshold (c) for the evaluation mode. The colorbar on the right shows the intensity of the reliability weights. Plots are based on the last few training iterations for better visualization.",
  "Baseline76.435.736.078.947.053.354.6": "BG76.840.536.779.153.257.257.3 (+2.7)UCFN + BG76.941.636.679.451.358.157.3 (+2.7)UCFP + BG*77.041.936.479.553.059.057.8 (+3.2)FG + UCFN + BG76.839.937.279.653.055.557.0 (+2.4)FG + UCFP + BG77.041.435.979.553.256.857.3 (+2.7) . Ablation study on different reliability-based weighting options on 1% and 2% data splits for moderate difficulty level. For afair comparison, we show the mAP across all classes in the last column, where UCFP + BG performs the best. (*) indicates our chosenweighting option, and Bold indicates the best results. which is referred to as the baseline. The baseline performssimilarly to the original work, except for the cyclist class inthe 2% split, where there is a minor drop of less than 3%.Note that the baseline does not use the RCNN classificationloss on unlabeled data, while our approach benefits from it.Hence, for a more accurate comparison, we have also in-cluded the results of our adapted baseline with RCNN clas-sification loss on unlabeled data, which shows an improve-ment over the naive baseline. We refer to our method as thebest option selected from the weighting schemes evaluatedin Tab. 2, i.e., UCFP + BG. Our framework shows superior performance over both3DIoUMatch and its improved version across all labeleddata splits, specially for pedestrian and cyclist classes.While we are also successful in improving for the car class,the margins are relatively small because of two reasons.First, the car class suffers from a substantial number of FPerrors and in .3.1, we show that the effectivenessof reliability weights in such a scenario is limited. Second,the car class being dominant in terms of class distribution isalready learnt well in the pre-train stage itself, leaving small",
  "Effects of reliability weights": "Tab. 2 ablates the performance over different reliability-based weighting options, improving the mAP over the base-line by 2.7%-3.2%. The UCFN and UCFN +BG were eval-uated to suppress FN errors, while others assess the effectof suppressing both FN and FP errors. The last two op-tions were assessed to determine efficient ways to weightUC proposals to suppress FN or FP errors. While the relia-bility weights help in all of these options, UCFP + BG hasthe highest gain in mAP of 3.2% over the baseline. More-over, the teachers foreground score was found to be moreefficient as a weight in the BG option than in the FG option.We believe that FG + UCFN + BG has lower performancedue to the down-weighting of truly uncertain proposals. In, we show the mean reliability weights of all fore-ground proposals relative to the PLs with the weighting op-tion of FG + UCFP + BG. As shown, the weights fromthis option effectively suppress the loss due to FP and FN Training iterations 0.0 0.2 0.4 0.6 0.8 1.0 Mean reliability weight",
  ". Shows the percentage of foreground proposals with re-spect to GT used to train the FG/BG classification head, highlight-ing the imbalanced FG/BG ratios across different classes": "proposals at the cost of suppressing the loss of some truepositives (TP). Moreover, the weights of FPs are relativelyhigher (close to 1), especially for the car class, and less ef-fective than those for the FNs. We conjecture that this is dueto the unbalanced number of FG/BG proposals in the RCNNmodule. illustrates this by showing the percentage ofFG proposals used to train the RCNN classification branch.Note that the car class is highly skewed, with almost 95%of the proposals as BGs. As a result, the network is biasedtowards the BG class, and the teacher model cannot pro-vide a reliable FG score for the FP proposals. Whereas, theUCFP + BG option compensates this by avoiding the sup-pression of the loss due to the TP proposals, instead mainlysuppressing the FPs and FNs, as shown in .",
  "Effects of class-aware target assignment": "Tab. 3 analyzes the effects of local class-aware foregroundthresholds over class-agnostic thresholds and their sensitiv-ity to different values. We show that the class-aware thresh-olds not only perform better than the default threshold bya large margin, but also they are consistent in performanceacross different values. We leverage our previous findingthat the pedestrian and cyclist classes require lower thresh-olds than the car class by adjusting our baseline thresholdsby 10%.",
  ". Conclusion": "Our research on semi-supervised 3D object detectionindicates that while generating high-quality pseudo-labelsvia quality-based filtering is advantageous, the impact ofsuch noisy pseudo-labels on the IoU-based target assign-ment module should be considered. We emphasize the sig-nificance of distinct learning curves for different classes andthe need for class-specific target assignments, especiallywith pseudo-labeling techniques. Moreover, we utilize theteacher model to obtain a reliability score to suppress in-accurate target assignment from noisy pseudo-labels andmaintain clear supervision from unlabeled data. Our re-search offers an error analysis framework that can be usedwith other reliability-based metrics to enhance the overallreliability of the system. We plan to extend it to more au-tonomous driving datasets and object detectors in the future.",
  "This work has been funded by the German Ministry forEducation and Research (BMB+F) in the project MOMEN-TUM": "Nicolas Carion, Francisco Massa, Gabriel Synnaeve, NicolasUsunier, Alexander Kirillov, and Sergey Zagoruyko. End-to-end object detection with transformers. In Andrea Vedaldi,Horst Bischof, Thomas Brox, and Jan-Michael Frahm, edi-tors, Computer Vision ECCV 2020, volume 12346 of Lec-ture Notes in Computer Science, pages 213229. SpringerInternational Publishing, 2020. 1 Binbin Chen, Weijie Chen, Shicai Yang, Yunyi Xuan, JieSong, Di Xie, Shiliang Pu, Mingli Song, and YuetingZhuang. Label matching semi-supervised object detection.In 2022 IEEE/CVF Conference on Computer Vision and Pat-tern Recognition (CVPR). IEEE, June 2022. 3 Xiaozhi Chen, Huimin Ma, Ji Wan, Bo Li, and Tian Xia.Multi-view 3d object detection network for autonomousdriving. In 2017 IEEE Conference on Computer Vision andPattern Recognition (CVPR), pages 65266534, Honolulu,HI, USA, jul 2017. IEEE. 2",
  "A Geiger, P Lenz, C Stiller, and R Urtasun. Vision meetsrobotics: The KITTI dataset. The International Journal ofRobotics Research, 32(11):12311237, aug 2013. 6": "Jason Ku, Melissa Mozifian, Jungwook Lee, Ali Harakeh,and Steven L. Waslander. Joint 3d proposal generation andobject detection from view aggregation. In 2018 IEEE/RSJInternational Conference on Intelligent Robots and Systems(IROS), pages 18. IEEE, oct 2018. 2 Alex H. Lang, Sourabh Vora, Holger Caesar, Lubing Zhou,Jiong Yang, and Oscar Beijbom. Pointpillars: Fast encodersfor object detection from point clouds. In 2019 IEEE/CVFConference on Computer Vision and Pattern Recognition(CVPR), pages 1269712705. IEEE, jun 2019. 1, 2 Gang Li, Xiang Li, Yujie Wang, Yichao Wu, Ding Liang, andShanshan Zhang. PseCo: Pseudo labeling and consistencytraining for semi-supervised object detection. In ComputerVision - ECCV 2022 - 17th European Conference, Tel Aviv,Israel, October 23-27, 2022, Proceedings, Part IX, volume13669 of Lecture Notes in Computer Science, pages 457472. Springer Nature Switzerland, 2022. 1, 2 Hengduo Li, Zuxuan Wu, Abhinav Shrivastava, and Larry S.Davis. Rethinking pseudo labels for semi-supervised objectdetection. In Thirty-Sixth AAAI Conference on Artificial In-telligence, AAAI 2022, Thirty-Fourth Conference on Innova-tive Applications of Artificial Intelligence, IAAI 2022, TheTwelveth Symposium on Educational Advances in ArtificialIntelligence, EAAI 2022 Virtual Event, February 22 - March1, 2022, pages 13141322. AAAI Press. 3",
  "Tsung-Yi Lin, Michael Maire, Serge Belongie, James Hays,Pietro Perona, Deva Ramanan, Piotr Dollar, and C. Lawrence": "Zitnick.Microsoft COCO: Common objects in context.In David J. Fleet, Tomas Pajdla, Bernt Schiele, and TinneTuytelaars, editors, Computer Vision ECCV 2014, volume8693 of Lecture Notes in Computer Science, pages 740755.Springer International Publishing, 2014. 1 Yen-Cheng Liu, Chih-Yao Ma, Zijian He, Chia-Wen Kuo,Kan Chen, Peizhao Zhang, Bichen Wu, Zsolt Kira, and PeterVajda. Unbiased teacher for semi-supervised object detec-tion. In 9th International Conference on Learning Represen-tations, ICLR 2021, Virtual Event, Austria, May 3-7, 2021.OpenReview.net, 2021. 1, 3 Ze Liu, Yutong Lin, Yue Cao, Han Hu, Yixuan Wei, ZhengZhang, Stephen Lin, and Baining Guo. Swin transformer:Hierarchical vision transformer using shifted windows. In2021 IEEE/CVF International Conference on Computer Vi-sion (ICCV), pages 999210002. IEEE, oct 2021. 1 Jiageng Mao, Minzhe Niu, Chenhan Jiang, Hanxue Liang,Jingheng Chen, Xiaodan Liang, Yamin Li, Chaoqiang Ye,Wei Zhang, Zhenguo Li, Jie Yu, Chunjing Xu, and Hang Xu.One million scenes for autonomous driving: ONCE dataset.In Joaquin Vanschoren and Sai-Kit Yeung, editors, Proceed-ings of the Neural Information Processing Systems Track onDatasets and Benchmarks 1, NeurIPS Datasets and Bench-marks 2021, December 2021, virtual. 1 Charles Ruizhongtai Qi,Hao Su,Kaichun Mo,andLeonidas J. Guibas. PointNet: Deep learning on point setsfor 3d classification and segmentation. In 2017 IEEE Confer-ence on Computer Vision and Pattern Recognition (CVPR),pages 7785. IEEE, jul 2017. 1, 2",
  "Charles R. Qi, Li Yi, Hao Su, and Leonidas J. Guibas. Point-net++: Deep hierarchical feature learning on point sets in ametric space. arXiv preprint arXiv:1706.02413, 2017. 1, 2": "Shaoshuai Shi, Chaoxu Guo, Li Jiang, Zhe Wang, JianpingShi, Xiaogang Wang, and Hongsheng Li. PV-RCNN: Point-voxel feature set abstraction for 3d object detection.In2020 IEEE/CVF Conference on Computer Vision and Pat-tern Recognition (CVPR), pages 1052610535. IEEE, jun2020. 1, 2, 6 Kihyuk Sohn, David Berthelot, Nicholas Carlini, ZizhaoZhang, Han Zhang, Colin Raffel, Ekin Dogus Cubuk, AlexeyKurakin, and Chun-Liang Li. Fixmatch: Simplifying semi-supervised learning with consistency and confidence. In Ad-vances in Neural Information Processing Systems 33: An-nual Conference on Neural Information Processing Systems2020, NeurIPS 2020, December 6-12, 2020, virtual, 2020. 1,3",
  "Kihyuk Sohn, Zizhao Zhang, Chun-Liang Li, Han Zhang,Chen-Yu Lee, and Tomas Pfister. A simple semi-supervisedlearning framework for object detection. arXiv e-prints, pagearXiv:2005.04757, May 2020. 1": "Pei Sun, Henrik Kretzschmar, Xerxes Dotiwalla, AurelienChouard, Vijaysai Patnaik, Paul Tsui, James Guo, Yin Zhou,Yuning Chai, Benjamin Caine, Vijay Vasudevan, Wei Han,Jiquan Ngiam, Hang Zhao, Aleksei Timofeev, Scott Et-tinger, Maxim Krivokon, Amy Gao, Aditya Joshi, Yu Zhang,Jonathon Shlens, Zhifeng Chen, and Dragomir Anguelov.Scalability in perception for autonomous driving: Waymoopen dataset. In 2020 IEEE/CVF Conference on Computer",
  "OpenPCDet Development Team.Openpcdet: An open-source toolbox for 3d object detection from point clouds. 6": "He Wang, Yezhen Cong, Or Litany, Yue Gao, and Leonidas J.Guibas. 3dioumatch: Leveraging IoU prediction for semi-supervised 3d object detection. In 2021 IEEE/CVF Confer-ence on Computer Vision and Pattern Recognition (CVPR),pages 1461514624. IEEE, jun 2021. 3, 6 Zhenyu Wang, Ya-Li Li, Ye Guo, and Shengjin Wang. Com-bating noise: semi-supervised learning by region uncertaintyquantification. Advances in Neural Information ProcessingSystems, 34:95349545, 2021. 3 Mengde Xu, Zheng Zhang, Han Hu, Jianfeng Wang, LijuanWang, Fangyun Wei, Xiang Bai, and Zicheng Liu. End-to-end semi-supervised object detection with soft teacher. In2021 IEEE/CVF International Conference on Computer Vi-sion (ICCV), pages 30403049. IEEE, oct 2021. 3",
  "Hongyi Zhang, Moustapha Cisse, Yann N. Dauphin, andDavid Lopez-Paz. mixup: Beyond empirical risk minimiza-tion, Oct. 2018. 3": "Na Zhao, Tat-Seng Chua, and Gim Hee Lee. Sess: Self-ensembling semi-supervised 3d object detection. In Proceed-ings of the IEEE/CVF Conference on Computer Vision andPattern Recognition, pages 1107911087, 2020. 3 Qiang Zhou, Chaohui Yu, Zhibin Wang, Qi Qian, and HaoLi.Instant-teaching: An end-to-end semi-supervised ob-ject detection framework. In 2021 IEEE/CVF Conferenceon Computer Vision and Pattern Recognition (CVPR), pages40814090. IEEE, jun 2021. 3"
}