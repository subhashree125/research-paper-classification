{
  "Abstract": "Domain Generalization (DG) is a challenging task inmachine learning that requires a coherent ability to com-prehend shifts across various domains through extractionof domain-invariant features. DG performance is typicallyevaluated by performing image classification in domainsof various image styles.However, current methodologylacks quantitative understanding about shifts in stylistic do-main, and relies on a vast amount of pre-training data,such as ImageNet1K, which are predominantly in photo-realistic style with weakly supervised class labels.Sucha data-driven practice could potentially result in spuriouscorrelation and inflated performance on DG benchmarks.In this paper, we introduce a new 3-part DG paradigm toaddress these risks. We first introduce two new quantita-tive measures ICV and IDD to describe domain shifts interms of consistency of classes within one domain and sim-ilarity between two stylistic domains. We then present Su-perMarioDomains (SMD), a novel synthetic multi-domaindataset sampled from video game scenes with more consis-tent classes and sufficient dissimilarity compared to Ima-geNet1K. We demonstrate our DG method SMOS. SMOSuses SMD to first train a precursor model, which is thenused to ground the training on a DG benchmark.Weobserve that SMOS+SMD altogether contributes to state-of-the-art performance across five DG benchmarks, gain-ing large improvements to performances on abstract do-mains along with on-par or slight improvements to those onphoto-realistic domains. Our qualitative analysis suggeststhat these improvements can be attributed to reduced dis-tributional divergence between originally distant domains.Our data are available at .",
  "Model": ". Top: We define two quantitative measures ICV andIDD to describe stylistic domain shifts in image datasets for Do-main Generalization (DG). We find that the vast ImageNet1K,commonly used for pre-training DG models, has inconsistent classlabels and is already similar in style with photo-realistic domainsfound in multiple benchmarks. Therefore, we compile a novel syn-thetic dataset SuperMarioDomains (SMD) as referential stylis-tic domains with consistent scene class labels and sufficient dis-similarity from existing domains. Bottom:We present our DGapproach SMOS that leverages the unique domain shifts in ournew SMD dataset. We first train a Precursor Model using SMDand cross entropy LossCE. We then utilize the trained PrecursorModel to ground the training of the DG model with training do-mains from the benchmark, optimizing the empirical loss of bothcross entropy LossCE and Jensen-Shannon Divergence DJS be-tween the Precursor Model and the DG Model. Hence, the specific task of Domain Generalization (DG)has been defined with the aim of improving the generaliza-tion of models by singling out distribution shifts among datathat belong to independent and identically distributed (i.i.d)domains . The evaluation of a DG model consists",
  "arXiv:2405.15961v1 [cs.CV] 24 May 2024": "of performing supervised image classification in a multi-source leave-one-out scenario, where one domain is heldout as an unseen test set, and other domains are for training.The crucial DG strategy is to learn domain-invariantfeatures from the training domains such as SagNet ,CORAL , and DANN . More DG benchmarks ofmore perplexing stylistic domains and more fine-grainedclasses have also been developed for morecomprehensive evaluation of generalizability. However, wenotice potential risks in the current methodology. Most DGmethods solely rely on initializing their backbone modelspre-trained with vast weakly supervised image collections,e.g.ImageNet1K , which overwhelmingly resemble photo-styled domains in multiple DG benchmarks.We observe that many DG methods reducevarious forms of qualitative distances among domains, butlack quantitative understanding of the specific differencesamongst the domains of image styles.Without clarifiedand unbiased understanding of the common ground amongtraining domain examples, generalization onto an unseendomain would potentially be based upon un-grounded spu-rious evidence, resulting in inflated DG performance.In this paper, we present a new 3-fold paradigm for Do-main Generalization. First, we define 2 quantitative mea-sures for stylistic domain shifts based on Jensen-ShannonDivergence - Intra-Class Variation (ICV) within anindividual domain, and Inter-Domain Dissimilarity (IDD)between two domains. With these 2 measures, as shown in in the top, we confirm that ImageNet1K is biasedtoward domains of photorealistic styles, but also has incon-sistent representations within its individual class categories.We then construct a new multidomain dataset dubbedSuperMarioDomains (SMD) 1. SMD features 4 domainsrepresenting multiple generations of video game graphicstyles, ranging from low-resolution pixels to 3D-renderedpolygon-rich graphics. All domains share 4 classes of in-game type of scenes that appear consistently throughoutthe Mario franchise. Unlike ImageNet1K, SMDs domainsmaintain variable stylistic distances from ImageNet1K interms of IDD, while having more consistently labeled ex-amples than ImageNet1Ks in terms of ICV.Our proposed DG method SMOS is shown in the bot-tom of . SMOS first trains a precursor model withdomains in SMD. It then trains a DG model grounded bythe distribution represented by the SMD-trained precursor 1As of Mar. 20, 2024, the official content guidelines of Nintendo, whoowns the copyright of all games involved in SMD, has clearly stated theywill not object to your use of gameplay footage and/or screenshots cap-tured from games for which Nintendo owns the copyright ... for appropri-ate video and image sharing sites . We will follow this guideline andpublish our work in two forms. Extracted feature vectors and pre-trainedmodels will be readily available under the MIT license. The SMD datasetwith its raw images will be accessible after agreeing to using the dataset forfair-use research purposes only under the Open Database License (ODbL).",
  ". Statistics of image classification datasets involved in DG": "model. We apply SMOS and find overall improvements onmultiple DG benchmarks. SMOS contributes to the mostsignificant improvements when targeting abstract-styled do-mains, for example +7.3% on Sketch of PACS , +3.6%on Clipart of OfficeHome , or +8.1% on Clipart of Do-mainNet over the baselines of MIRO . SMOS alsomaintains performance on par with baselines when target-ing photo-realistic domains, and in some cases, e.g. PACS,even has improvements. We also observe that SMOS isable to improve extraction of domain-invariant features andgeneralization over domain shifts in quality, as we find thatoriginally distant stylistic domains are now projected withinconsiderably smaller distributional divergence.Our main contributions in this paper are as follows. 1. We propose ICV and IDD as measures for stylistic do-main shifts in DG benchmarks. Using our measures, wefind that real-world datasets like ImageNet1K used aspre-training data for DG may not be ideal for obtainingdomain-invariant features due to inconsistent classes andovert stylistic similarity with training domains. 2. We introduce a new synthetic dataset SuperMari-oDomains as a precursor dataset for DG, incorporat-ing unique features of consistent classes of video gamescenes across stylistic domains in video game graphicsthat are dissimilar to ImageNet1K. 3. We present our DG method SMOS. SMOS utilizesSuperMarioDomains to obtain a precursor model thatgrounds the training process on DG benchmarks. Weshow that SMOS is capable of obtaining top perfor-mance on multiple DG benchmarks, in particular, vialarge improvements on targeting abstract-styled do-mains together with on-par or slight improvements onphotorealistic-styled domains.",
  ". Related Works": "Synthetic Datasets with Domain Shifts. Synthetic datahas long been used in various disciplines in computer vi-sion . Recently, we have seen that moresynthetic datasets of distribution shifting domains are beingassembled to encourage more robust algorithms in different tasks. We have benchmarks studying adaptation betweensynthesized and real-life objects in Syn2Real or SYN-THIA . Super-CLEVR studies more robust visualreasoning skills by constructing domains w.r.t. visual ques-tion answering settings. More specifically, we draw greatinspiration from the GTAV-Cityscapes challenge ,adapting from a vast collection of video game landscapesto real-world scenarios for segmentation. All these worksshow that synthetic datasets, though lacking full realism,may help provide great insight into domain shifts.Domain Generalization Benchmarks. Early DG bench-marks such as Office or VLCS focus solely onphoto-realistic images. Since the time when single-stylebias was first exposed by DeCAF , more fine-grainedimage styles have been introduced to the mix of imagedomains, and we have seen a steady increase in scale forDG datasets, including OfficeHome , PACS , Ter-raIncognita , SVIRO , WILDS , Camelyon17, and NICO++ . Currently, the DomainNet dataset is the largest with 587K images, featuring 6 stylisticdomains and 345 object categories.Domain Generalization Approaches.Techniques totackle the problem of domain shift in Domain General-ization have been rapidly developed over the years. Re-searchers are no longer restricted to straightforward ap-proaches such as finding linear representations withtechniques like interpolation or nonlinear representations in-between domains. In many circum-stances, simple methods, such as variants of empirical riskminimization, can produce high performance onpopular domain generalization benchmarks. But recent ap-proaches to domain generalization can involve adaptationand combination of deep neural network models such asDANN and CDANN , leveraging Meta-Learning or Adversarial-Learning to transfer modelparameters, using an ensemble of different architectures, training strategies , or regularization methods toimprove generalizability like SWAD or MIRO .",
  ". Preliminaries": "In this paper, we focus on the Domain Generalization(DG) performance of image classification by conductingMulti-Source Domain Generalization (MSDG), where weevaluate a models performance with leave-one-out cross-validation.In formal terms, a DG dataset D is dividedinto N domains {d1, ...dN}. Each individual domain dicontains images Xdi paired with their class labels Y di.All domains share the same set of image labels.Wetrain a model M with the training set (training domains)Dtr that uses all data from all-but-one domains Dtr ={(Xd1, Y d1), ...(XdN1, Y dN1)}.The trained model isthen evaluated using unseen data from the one held-out test(target) domain as the test set Dte = {(XdN , Y dN )}. No- ticeably, unlike Domain Adaptation , the one test do-main Dte in DG is not involved in any training and does notcontain samples that overlap with the training domains.A typical DG model M = f g consists of two corecomponents: a feature extractor (featurizer) f as the back-bone network, followed by a single-layered linear classifierg. Although more complicated methods have been devel-oped over the years, the fundamental approach of Empir-ical Risk Minimization (ERM) remains relevant. Inthe context of DG, the goal of ERM is simply minimizingthe classification loss averaged over the N 1 training do-mains given training data xi, yi Dtr :",
  ". Analyses on Domain Shift of Stylistic Do-mains and Pre-training Data": "Risk in Pre-training Data Used for DG. Most DG meth-ods do not train their model M entirely from scratch.The models initial weights are commonly transferred froman existing model, typically pre-trained on ImageNet1K.Researchers have observed that there isan apparent stylistic resemblance between ImageNet1Kand many domains from various DG benchmarks, such asthe Photo domain in PACS, the RealWorld domain inOfficeHome, or even all 4 domains in VLCS .Such a common practice of only depending on a vastreal-world image dataset can be risky. Qualitatively, the im-ages used for pre-training lack shift in style to adapt from,e.g. ImageNet1K are dominated by real-world photos. Inaddition, the images in ImageNet1K may be inconsistentwithin the same class; e.g., images of a class of fish mayor may not include a person holding it. Hence, when weperform on DG benchmarks by using a model pre-trainedonly by such data, we may find it difficult to learn coherentstyle-invariant presentations in order to generalize over dis-tributional shifts among domains, especially when we haveto train with the predominating photo-realistic domains andtest on an unseen abstract-styled domain.Quantitative Measures of Stylistic Domain Shift.Wewould next like to compare the advantages of different DGpre-training data like ImageNet1K. Inspired by previousworks which examine image similarity , we definetwo intuitive measures for domain shift in DG: Intra-ClassVariation (ICV) to implicate the class-wise presentation in-consistency within one specific domain, and Inter-DomainDissimilarity (IDD) to implicate the distance in represen-tation distributions across two domains of styles.",
  "SMD (Ours)PACSVLCSOfficeHomeTerraIncognitaDomainNetImagetNet1K": ". Intra-Class Variation (ICV) for each domain in featured datasets. A low ICV indicates that the classes are more consistent interms of colors, as in NES of SMD, Sketch of PACS, and Quickdraw of DomainNet. Meanwhile, the classes in ImageNet1K, which iscommonly used for pre-training in DG, are implicated to be as inconsistent as those in photo- or art-styled domains, e.g. Photo and Art ofPACS, LabelMe of VLCS, Art and RealWorld of OfficeHome, as well as Real of DomainNet. Average of 3 trials.",
  "SMD (Ours)PACSVLCSOfficeHomeTerraIncognitaDomainNet": ". Inter-Domain Dissimilarity (IDD) of ImageNet1K vs. each domain in featured datasets. IDD of ImageNet1K vs. itself ispresumably 0. Since ImageNet1K is dominantly real-world photographs, those with smaller IDD implicate stronger resemblance to thestyle of photo-realism, e.g. all 4 domains of VLCS, or Photo of PACS. Highly abstract and simplistic styles, such as Sketch of PACS andQuickdraw of DomainNet, are shown in very large IDD values on the flip side. Both measures utilize the symmetric Jensen-ShannonDivergence (JSD) . Concretely, let P and Q be the es-timated probability distributions of the RGB channels andbins (3256 dimensions), making the outcome set a vectorof length 768. The JSD between P and Q is defined as:",
  "and Qi represent distributions of two equal splits of samples": ". A qualitative overview of our SuperMarioDomains(SMD) dataset, consisting of video frames from actual game footage cate-gorized into 4 distinctive scene classes and 4 image style domains. Columns from left to right: The four image domains, named after theconsole hardware on which each game runs - NES, SNES, N64, and Wii. Rows from top to bottom: The four classes of in-game scenes- Overworld, Underground, Aquatic, and Castle. These synthetic image styles of SMD are drastically different from those in existing DGbenchmarks, such as realistic photographs, pencil sketches, or oil paintings.",
  "IDD(D1, D2) = DJS(PD1, PD2).(6)": "For fairness, we assume that all image presentationsfollow Gaussian distributions with regard to probabilitiesof raw RGB values within bins of , normalizedby the uniform mean [0.5, 0.5, 0.5] and standard deviation[0.5, 0.5, 0.5]. In addition to ImageNet1K, we choose tostudy the domains in the following DG benchmarks: PACS,VLCS, OfficeHome, TerraIncognita, and DomainNet. TheICV for each domain studied is averaged over 3 trials.In , we first compare the ICV of ImageNet1Kwith that of every domain in the chosen DG benchmarks.We discover that, in ImagetNet1K, image representationswithin the same class can be as diversely distributed as those learning samples from photo- or art-styled domainsin DG benchmarks. Meanwhile, domains of highly abstractstyles, such as Sketch in PACS and Quickdraw in Domain-Net, have drastically low ICV values compared to other do-mains in their respective benchmarks. According to , since ImageNet1K also has at least twice as many classescompared to DG domains, generalization with known sam-ples solely from high-ICV classes would be difficult to learndomain-invariant features, especially when the test domainsamples have vastly low variation in feature space.From , we now have a clear view of Ima-geNet1Ks similarity to existing styles in multiple DGbenchmarks. This can be observed, for example, from thenext-to-0 IDD values of all four domains of VLCS, thePhoto and Art domains of PACS, or the Location38 domainof TerraIncognita. In contrast, styles of abstract color pat-terns or textures, such as the Sketch domain of PACS andthe Quickdraw domain of DomainNet, have large IDD val-ues which suggests large distances from ImageNet1K.",
  "S": ". The pipeline of our SMOS method. The feature extrac-tion backbones f and fS have an identical structure. f is initializedwith ImageNet1K pre-trained weights. Left: We first train the Pre-cursor Model fS gS to learn scene style shifts with SMD. Right:We then perform DG training with training domains from a DGbenchmark (e.g. PACS), tuning the DG model f g while beinggrounded to the SMD-trained Precursor fS by optimizing LJS. environments rendered in video games, we com-pile a multi-domain dataset SuperMarioDomains (SMD)from video game scenes that can be leveraged as precur-sor data for Domain Generalization experiments.As itsname suggests, our SMD dataset feature synthetic in-gamescenes captured from multiple games in the Mario fran-chise, with image style domains encompass pixelated mo-saic 2D graphics in only 50 colors, all the way to high-polygon 3D graphics in 32-bit colors. We land on 4 classesof distinct in-game scenes that consistently appear in allMario games of our choice. Each scene class has its ownunique traits defined by the combination of terrains, objects,and texture. To ensure high consistency in image styles andclass labels, we sample our images from video frames ofactual game play footage, - neighboring frames of the samegame segment share the same scene class. An overview ofthe samples in SMD is available in .Quantitatively, SMD is designed to counterbalance thestylistic biases of ImageNet1K by having domains that arelow in ICV and relatively high in IDD. On the left of Fig-ure 2, we find that the 4 synthetic-styled domains in SMDhave much higher class consistency than ImageNet1K, asin generally lower ICVs. Also, in , SMDs domainsalso keep a series of evenly placed domain shifts in terms ofIDD from the dominating style of ImageNet1K, with NESbeing the most distant domain while N64 and Wii not asclose as Photo of PACS or Caltech101 of VLCS.The SMOS DG Method. Seeing the unique stylistic do-main shifts in SMD, we are motivated to design a newDG method with better domain-invariant feature extrac-tion, learning the domain shifts first from isolated class-consistent samples in SMD. We present the Scene-groundedMinimal dOmain Shift (SMOS) method to best leverage theunique domain shifts in SMD. demonstrates the SMOS pipeline. We first train a Precursor Model MS =fS gS with a Precursor Feature Extractor fS to learn aboutthe domain shifts of SMD. Sequentially, we train an iden-tically structured model M = f g with training domainsfrom a DG benchmark, while simultaneously grounded byminimizing the Jensen-Shannon Divergence between distri-butions of the corresponding feature extractors fS and f.Formally, the distribution of the Precursor Model MSis learned with the synthetic scene data DS, namely fromSMD. Given NS stylistic domains of scene image-labelpairs xj, yj DS, we optimize the cross-entropy loss forupdating MS in a similar form with ERM:",
  ". Experiments and Results": "Experiment setups.We use ResNet50 pre-trainedwith ImageNet1K as the single default backbone forfeature extractor networks. Our implementation is basedon the source code of DomainBed and MIRO . Weevaluate the performance of SMOS on the following DGbenchmarks: PACS , OfficeHome , VLCS ,TerraIncongnita , and DomainNet .Two variants of SMOS are designed to initialize MS dif-ferently - SMOS whose fS is initialized from scratch viaKaiming Initialization , and SMOS+ whose fS is ini-tialized with ImageNet1K pre-trained weights.We apply the same data augmentations by ERM andMIRO - each training set image is cropped with ran-dom size and aspect ratio, resized to 224224 pixels, ap-plied random horizontal flips, applied random color jitter,applied grayscale with 10% probability, and normalized us-ing the ImageNet channel means and standard deviations.For hyperparameters, we use a batch size of 16, and theAdam optimizer for all experiments. The hyperparam-eters listed in are consistent with those used in theMIRO paper , where for each benchmark, we use a dif-ferent combination of hyperparameters. We divide all do-mains in SMD by a 4-to-1 training-test ratio to obtain the",
  "ACS PAS PAC Avg.ACP RAP Avg.CSIPQ RSIPQ CRSIP Avg.PhotoCartoonSketchRealWorldClipartRealClipartQuickdraw": "ERM 97.00.179.81.074.70.784.277.40.253.21.267.660.90.150.80.210.50.144.0MIRO 97.30.280.50.575.91.085.481.10.453.80.870.563.40.254.20.811.30.044.3SMOS(ours)98.10.084.80.281.30.488.780.70.357.50.371.063.90.360.30.113.90.044.5SMOS+(ours)98.10.184.80.383.20.689.480.80.458.60.471.664.00.262.30.014.70.045.3 . DG performance on individual target domains. SMOS gains the greatest improvements on abstract-styled domains while main-taining its performance on photo-styled domains. The letters that precede denote initial letters of the training domains in the respectivebenchmarks. The best results per setting are shown in bold. Average of 3 trials.",
  "MethodPACSVLCSOfficeHomeTerraIncognitaDomainNetAvg": "Mixstyle 85.2 0.377.9 0.560.4 0.344.0 0.734.0 0.160.3GroupDRO 84.4 0.876.7 0.666.0 0.743.2 1.133.3 0.260.7IRM 83.5 0.878.5 0.564.3 2.247.6 0.833.9 2.861.6ARM 85.1 0.477.6 0.364.8 0.345.5 0.335.5 0.261.7VREx 84.9 0.678.3 0.266.4 0.646.4 0.633.6 2.961.9CDANN 82.6 0.977.5 0.165.8 1.345.8 1.638.3 0.362.0DANN 83.6 0.478.6 0.465.9 0.646.7 0.538.3 0.162.6RSC 85.2 0.977.1 0.565.5 0.946.6 1.038.9 0.562.7MTL 84.6 0.577.2 0.466.4 0.545.6 1.240.6 0.162.9Mixup 84.6 0.677.4 0.668.1 0.347.9 0.839.2 0.163.4MLDG 84.9 1.077.2 0.466.8 0.647.7 0.941.2 0.163.6ERM 84.2 0.177.3 0.167.6 0.247.8 0.644.0 0.164.2SagNet 86.3 0.277.8 0.568.1 0.148.6 1.040.3 0.164.2CORAL 86.2 0.378.8 0.668.7 0.347.6 1.041.5 0.164.5CCFP 86.6 0.278.9 0.368.9 0.148.6 0.441.7 0.064.8MIRO 85.4 0.479.0 0.070.5 0.450.4 1.144.3 0.265.9",
  ". Hyperparameters for DG experiments. OH, DN, and TIrespectively stand for OfficeHome, DomainNet, and TerraIncog-nita. is our grounding coefficient for SMOS as in Equation 9": "precursor model MS in SMOS. All experiments are con-ducted using 2 NVIDIA V100 GPUs.Domain Generalization Performance with SMOS. Wepresent the most significant improvements of SMOS on theindividual target domains in . The key takeawayis that our SMOS method demonstrates its best strengthwhen generalizing onto more abstract-styled domains, e.g.Sketch in PACS, on which baseline methods such as ERM and MIRO struggle to improve. Using the unique domainshifts in SMD, our SMOS+ variant achieves large improve-ments over the state-of-the-art MIRO method by +3.7%and +7.3% on Cartoon and Sketch in PACS, +3.6% onClipart in OfficeHome, and +8.1% and +3.4% on Clipartand Quickdraw in DomainNet. We also show that SMOS isable to maintain its performance on photo-realistic domainson par within the MIRO baselines error range. In somecases, such as PACS and DomainNet, SMOS can even gainslightly better performance than the MIRO baseline.A comprehensive comparison of a larger selection ofDG methods on multiple benchmarks is shown in .We show that our 2 SMOS variants achieve better overallperformance on the chosen DG benchmarks, thanks to theparticular improvements on abstract-styled domains. OurSMOS+ variant surpasses the baseline MIRO by +4.0% onPACS, +0.9% on VLCS, +1.1% on OfficeHome, +4.9%on TerraIncognita, and +1.0% on DomainNet.Qualitative Analysis of Domain-invariant Feature Ex-",
  ". DG performance of using substitute precursor data inSMOS and SMOS+. All substitute precursor data are downsam-pled to the same size of SMD (80k). Average of 3 trials": "traction.We further validate SMOS generalizability,showing it helps project originally distant domains tocloser distributional proximity, which qualitatively impli-cates improvements in extracting domain-invariant featuresand thus better grounded DG performance. We apply ourdivergence-based IDD measure between domains that be-long to the same benchmark, comparing distributions ofrepresentations extracted by different DG methods. exemplifies the case from the perspective of theSketch domain in PACS. In raw RGB distributions, Sketchis shown to be highly distant from other domains exceptCartoon. When conducting DG image classification testson Sketch, baseline DG methods such as ERM and MIROare shown to incrementally lower the distributional diver-gence from Photo and Art, but at the cost of Cartoon whichis originally the most similar to Sketch in RGB. Our meth-ods SMOS and SMOS+, along with our SMD precursordata, universally lower the divergences with all non-Sketchdomains of PACS. Our methods are thus able to extractdomain-agnostic representations within much closer distri-butional proximity in respective feature spaces, presentedas further improved DG performance on Sketch.Ablation Study of Substitute Precursor Data with SMOS. We also experiment with using substitute imageclassification datasets as precursor data (DS as in ) under the SMOS method, while SMD is not involved.For substitutes, we choose the benchmark dataset Domain-Net which, on its own, has more different domains ofimage styles and more classes compared to SMD, but alsofar higher variance in both ICV and IDD than SMD (shownin ). We also choose the scene-based Places365-Standard (Places365) dataset that has 300+ classes ofscenes similar to SMD, but only in one photo-realism styleidentical to ImageNet1K. We randomly downsample thesubstitute precursor data to the same size of SMD (80k) ateach trial. We use the same 4-to-1 training-test split ratiowhen obtaining alternative precursor models. We performbenchmarking on PACS and OfficeHome. shows the benchmarking performances of usingdifferent precursor data in the SMOS paradigm. We findthat SMOS retains the best DG performance when it uti-lizes SMDs unique stylistic domain shifts and scene labels.In contrast, we see that training the precursor model withImageNet1K-like image styles (Places365) or less consis-tent stylistic domains (DomainNet) leads to lower improve-ments, if not worse performance, than the baseline methods.",
  ". Conclusions": "In this work, we introduce a new paradigm for Domain Gen-eralization (DG) on three facets. We define two new mea-sures, ICV and IDD, to quantitatively understand distribu-tional shifts in stylistic domains based on Jensen-ShannonDivergence. We then present a novel precursor dataset Su-perMarioDomains (SMD) sampled from scenes in videogames, featuring more consistent categorical classes anddissimilar domains compared to ImageNet1K. We alsodemonstrate our new DG method SMOS that leveragesthe unique features of SMD as means to ground the train-ing on DG benchmarks. We find that SMOS along withSMD reaches top performance on multiple DG benchmarksthrough significant improvements on abstract-styled targetdomains. SMOS has also been shown to qualitatively im-prove domain-invariant feature extraction by bringing dis-tant domains within closer divergence in learned featurespace. In the future, we would like to explore the applica-tion of our methodology on other tasks, such as ControllableText-to-Image Generation or Visual Question Answering.",
  "Acknowledgements": "The authors acknowledge Research Computing at ArizonaState University for providing HPC resources and supportfor this work. This work was supported by NSF RI grants#1750082 and #2132724. The views and opinions of theauthors expressed herein do not necessarily state or reflectthose of the funding agencies and employers. Raphael Achddou, Yann Gousseau, and Sad Ladjal. Syn-thetic images as a regularity prior for image restoration neu-ral networks. In International Conference on Scale Spaceand Variational Methods in Computer Vision, pages 333345. Springer, 2021. 2",
  "Martin Arjovsky, Leon Bottou, Ishaan Gulrajani, and DavidLopez-Paz.Invariant risk minimization.arXiv preprintarXiv:1907.02893, 2019. 2, 3": "Hyojin Bahng, Sanghyuk Chun, Sangdoo Yun, Jaegul Choo,and Seong Joon Oh. Learning de-biased representations withbiased representations. In International Conference on Ma-chine Learning, pages 528539. PMLR, 2020. 1 Peter Bandi,Oscar Geessink,Quirine Manson,Mar-cory Van Dijk, Maschenka Balkenhol, Meyke Hermsen,Babak Ehteshami Bejnordi, Byungjae Lee, KyunghyunPaeng, Aoxiao Zhong, et al. From detection of individualmetastases to classification of lymph node status at the pa-tient level: the camelyon17 challenge. IEEE transactions onmedical imaging, 38(2):550560, 2018. 2, 3",
  "Greg Brockman, Vicki Cheung, Ludwig Pettersson, JonasSchneider, John Schulman, Jie Tang, and Wojciech Zaremba.Openai gym, 2016. 2, 6": "Junbum Cha, Sanghyuk Chun, Kyungjae Lee, Han-CheolCho, Seunghyun Park, Yunsung Lee, and Sungrae Park.Swad: Domain generalization by seeking flat minima. vol-ume 34, page 2240522418. Curran Associates, Inc., 2021.3 Junbum Cha, Kyungjae Lee, Sungrae Park, and SanghyukChun.Domain generalization by mutual-information reg-ularization with pre-trained models. In Computer VisionECCV 2022: 17th European Conference, Tel Aviv, Israel,October 2327, 2022, Proceedings, Part XXIII, pages 440457, 2022. 2, 3, 6, 7 Marius Cordts, Mohamed Omran, Sebastian Ramos, TimoRehfeld,Markus Enzweiler,Rodrigo Benenson,UweFranke, Stefan Roth, and Bernt Schiele.The cityscapesdataset for semantic urban scene understanding. In Proceed-ings of the IEEE conference on computer vision and patternrecognition, pages 32133223, 2016. 3 Adrien Courtois, Jean-Michel Morel, and Pablo Arias. In-vestigating neural architectures by synthetic dataset design.In Proceedings of the IEEE/CVF Conference on ComputerVision and Pattern Recognition, pages 48904899, 2022. 2 Steve Dias Da Cruz, Oliver Wasenmuller, Hans-Peter Beise,Thomas Stifter, and Didier Stricker. Sviro: Synthetic vehi-cle interior rear seat occupancy dataset and benchmark. InProceedings of the IEEE/CVF Winter Conference on Appli-cations of Computer Vision, pages 973982, 2020. 3",
  "Lixin Duan, Ivor W Tsang, and Dong Xu. Domain trans-fer multiple kernel learning. IEEE Transactions on PatternAnalysis and Machine Intelligence, 34(3):465479, 2012. 3": "Joshua Feinglass and Yezhou Yang. SMURF: SeMantic andlinguistic UndeRstanding fusion for caption evaluation viatypicality analysis. In Proceedings of the 59th Annual Meet-ing of the Association for Computational Linguistics and the11th International Joint Conference on Natural LanguageProcessing (Volume 1: Long Papers), pages 22502260, On-line, Aug. 2021. Association for Computational Linguistics.3 Yaroslav Ganin, Evgeniya Ustinova, Hana Ajakan, Pas-cal Germain, Hugo Larochelle, Francois Laviolette, MarioMarchand, and Victor Lempitsky. Domain-adversarial train-ing of neural networks.The journal of machine learningresearch, 17(1):20962030, 2016. 2, 3, 7 Robert Geirhos,Patricia Rubisch,Claudio Michaelis,Matthias Bethge, Felix A Wichmann, and Wieland Brendel.Imagenet-trained cnns are biased towards texture; increasingshape bias improves accuracy and robustness. arXiv preprintarXiv:1811.12231, 2018. 1 Tejas Gokhale, Rushil Anirudh, Jayaraman J Thiagarajan,Bhavya Kailkhura, Chitta Baral, and Yezhou Yang. Improv-ing diversity with adversarially learned transformations fordomain generalization. In IEEE/CVF Winter Conference onApplications of Computer Vision, 2023. 3",
  "Ishaan Gulrajani and David Lopez-Paz. In search of lost do-main generalization. In International Conference on Learn-ing Representations, 2021. 3, 6": "Kaiming He, Xiangyu Zhang, Shaoqing Ren, and Jian Sun.Delving deep into rectifiers: Surpassing human-level perfor-mance on imagenet classification.In Proceedings of theIEEE international conference on computer vision, pages10261034, 2015. 6 Kaiming He, Xiangyu Zhang, Shaoqing Ren, and Jian Sun.Deep residual learning for image recognition. In Proceed-ings of the IEEE conference on computer vision and patternrecognition, pages 770778, 2016. 6",
  "and Kate Saenko. Efficient learning of domain-invariant im-age representations. arXiv preprint arXiv:1301.3224, 2013.3": "Zeyi Huang, Haohan Wang, Eric P Xing, and Dong Huang.Self-challenging improves cross-domain generalization. InComputer VisionECCV 2020: 16th European Conference,Glasgow, UK, August 2328, 2020, Proceedings, Part II 16,pages 124140. Springer, 2020. 7 Xueying Jiang, Jiaxing Huang, Sheng Jin, and Shijian Lu.Domain generalization via balancing training difficulty andmodel capability. In Proceedings of the IEEE/CVF Interna-tional Conference on Computer Vision, pages 1899319003,2023. 3, 7",
  "Diederik P Kingma and Jimmy Ba. Adam: A method forstochastic optimization.arXiv preprint arXiv:1412.6980,2014. 6": "PangWeiKoh,ShioriSagawa,HenrikMarklund,Sang Michael Xie,Marvin Zhang,Akshay Balsubra-mani, Weihua Hu, Michihiro Yasunaga, Richard LanasPhillips, Irena Gao, et al. Wilds: A benchmark of in-the-wild distribution shifts.In International Conference onMachine Learning, pages 56375664. PMLR, 2021. 2, 3 David Krueger, Ethan Caballero, Joern-Henrik Jacobsen,Amy Zhang,Jonathan Binas,Dinghuai Zhang,RemiLe Priol, and Aaron Courville. Out-of-distribution general-ization via risk extrapolation (rex). In International Confer-ence on Machine Learning, pages 58155826. PMLR, 2021.7 Bo Li, Yifei Shen, Yezhen Wang, Wenzhen Zhu, ColoradoReed, Dongsheng Li, Kurt Keutzer, and Han Zhao. Invari-ant information bottleneck for domain generalization. Pro-ceedings of the AAAI Conference on Artificial Intelligence,36(7):73997407, Jun. 2022. 3, 7",
  "DaLi,YongxinYang,Yi-ZheSong,andTimothyHospedales. Learning to generalize: Meta-learning for do-main generalization. In Proceedings of the AAAI conferenceon artificial intelligence, volume 32, 2018. 7": "Da Li, Yongxin Yang, Yi-Zhe Song, and Timothy MHospedales. Deeper, broader and artier domain generaliza-tion. In Proceedings of the IEEE international conference oncomputer vision, pages 55425550, 2017. 2, 3, 6 Ya Li, Xinmei Tian, Mingming Gong, Yajing Liu, TongliangLiu, Kun Zhang, and Dacheng Tao.Deep domain gener-alization via conditional invariant adversarial networks. InProceedings of the European Conference on Computer Vi-sion (ECCV), pages 624639, 2018. 3, 7 Ziyue Li, Kan Ren, Xinyang Jiang, Yifei Shen, HaipengZhang, and Dongsheng Li.Simple: Specialized model-sample matching for domain generalization.In TheEleventh International Conference on Learning Representa-tions, 2022. 2, 3 Zhuowan Li, Xingrui Wang, Elias Stengel-Eskin, AdamKortylewski, Wufei Ma, Benjamin Van Durme, and AlanYuille. Super-clevr: A virtual benchmark to diagnose do-main robustness in visual reasoning.(arXiv:2212.00259),May 2023. arXiv:2212.00259 [cs]. 3",
  "Nintendo Co. Ltd. Nintendo game content guidelines for on-line video & image sharing platforms, Oct 2023. 2": "Hyeonseob Nam, HyunJae Lee, Jongchan Park, WonjunYoon, and Donggeun Yoo. Reducing domain gap by reduc-ing style bias. In Proceedings of the IEEE/CVF Conferenceon Computer Vision and Pattern Recognition, pages 86908699, 2021. 2 Hyeonseob Nam, HyunJae Lee, Jongchan Park, WonjunYoon, and Donggeun Yoo. Reducing domain gap by reduc-ing style bias. In Proceedings of the IEEE/CVF Conferenceon Computer Vision and Pattern Recognition, 2021. 7",
  "Sinno Jialin Pan and Qiang Yang. A survey on transfer learn-ing. IEEE Transactions on knowledge and data engineering,22(10):13451359, 2009. 1": "Goran Paulin and Marina Ivasic-Kos. Review and analysis ofsynthetic dataset generation methods and techniques for ap-plication in computer vision. Artificial Intelligence Review,56(9):92219265, Sept. 2023. 2 Xingchao Peng, Qinxun Bai, Xide Xia, Zijun Huang, KateSaenko, and Bo Wang. Moment matching for multi-sourcedomain adaptation. In Proceedings of the IEEE/CVF inter-national conference on computer vision, pages 14061415,2019. 2, 3, 6, 8",
  "Vladimir Vapnik. Principles of risk minimization for learn-ing theory. Advances in neural information processing sys-tems, 4, 1991. 2, 3, 7": "Hemanth Venkateswara, Jose Eusebio, Shayok Chakraborty,and Sethuraman Panchanathan. Deep hashing network forunsupervised domain adaptation.In Proceedings of theIEEE conference on computer vision and pattern recogni-tion, pages 50185027, 2017. 2, 3, 6 Riccardo Volpi, Hongseok Namkoong, Ozan Sener, John C.Duchi, Vittorio Murino, and Silvio Savarese.Generaliz-ing to unseen domains via adversarial data augmentation.In Advances in Neural Information Processing Systems 31:Annual Conference on Neural Information Processing Sys-tems 2018, NeurIPS 2018, December 3-8, 2018, Montreal,Canada, pages 53395349, 2018. 3 Yufei Wang, Haoliang Li, and Alex C Kot. Heterogeneousdomain generalization via domain mixup. In ICASSP 2020-2020 IEEE International Conference on Acoustics, Speechand Signal Processing (ICASSP), pages 36223626. IEEE,2020. 3, 7",
  "Handi Yu, Simiao Ren, Leslie M. Collins, and Jordan M.Malof. Meta-simulation for the automated design of syn-thetic overhead imagery.(arXiv:2209.08685), Oct. 2022.arXiv:2209.08685 [cs]. 2": "Sangdoo Yun, Dongyoon Han, Seong Joon Oh, SanghyukChun, Junsuk Choe, and Youngjoon Yoo. Cutmix: Regular-ization strategy to train strong classifiers with localizable fea-tures. In Proceedings of the IEEE/CVF International Con-ference on Computer Vision (ICCV), October 2019. 3 Marvin Zhang, Henrik Marklund, Nikita Dhawan, AbhishekGupta, Sergey Levine, and Chelsea Finn. Adaptive risk min-imization: Learning to adapt to domain shift. In M. Ranzato,A. Beygelzimer, Y. Dauphin, P.S. Liang, and J. WortmanVaughan, editors, Advances in Neural Information Process-ing Systems, volume 34, pages 2366423678. Curran Asso-ciates, Inc., 2021. 7 Xingxuan Zhang, Yue He, Renzhe Xu, Han Yu, ZheyanShen, and Peng Cui. Nico++: Towards better benchmarkingfor domain generalization. In Proceedings of the IEEE/CVFConference on Computer Vision and Pattern Recognition,pages 1603616047, 2023. 3"
}