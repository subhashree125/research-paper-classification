{
  "Abstract": "Automatic License Plate Recognition (ALPR) involvesextracting vehicle license plate information from image or avideo capture. These systems have gained popularity due tothe wide availability of low-cost surveillance cameras andadvances in Deep Learning. Typically, video-based ALPRsystems rely on multiple frames to detect the vehicle andrecognize the license plates. Therefore, we propose a systemcapable of extracting exactly one frame per vehicle and rec-ognizing its license plate characters from this singular im-age using an Optical Character Recognition (OCR) model.Early experiments show that this methodology is viable.",
  ". Introduction": "Automatic License Plate Recognition (ALPR) is widelyused in road traffic monitoring, automatic toll collection andother applications . This task can be difficult due tothe varied formats of license plates and inconsistent outdoorlighting conditions in video captures . Thus, there is stilla demand for research on license plate recognition systemsand algorithms to enhance their performance .Capturing a clear image of a moving vehicle with a vis-ible license plate poses a significant challenge . In real-world scenarios, video-based ALPR systems rely on multi-ple frames rather than a single image .In this paper, we present a more efficient approach forALPR in videos.Our approach combines YOLO, a es-tablished object detection model, with Visual Rhythm, atechnique for generating time-spatial images from videos.By merging these methods, we can selectively extract andprocess a single frame per vehicle, facilitating license platecharacter recognition using OCR models based on this sin-gular image.",
  ". Visual Rhythm": "Visual Rhythm (VR) efficiently gathers spatial and tempo-ral information, condensing the video content into a singleimage . This technique facilitates the identification offrames featuring crucial visual content, thereby reducing thecomputational complexity tied to frame-by-frame process-ing , at the cost of sacrificing real-time processing.Consider a video denoted as f with T frames of size MN. The VR method is applied to each frame f1, . . . , fT ,capturing exclusively the pixels along a predefined line. Thecollection of pixels from frame t, t = 1, . . . , T, on thisline are stacked along the time axis to form an image ofsize T N, a time-spatial representation of the video, asshow in . The top part shows five frames of a videosequence, where the line is superimposed in green (bestviewed in electronic format), and the bottom part showsthe VR image (time dimension in the vertical axis) of thewhole video sequence. Whenever an object crosses the line,a mark is observed in the image, at the row correspondingto the frame index. Each object is represented by a singlemark.",
  ". Data flow in the VRbased ALPR": "First, in step (a), we generate a VR image for segmentsof T consecutive frames (we will use T = 600 due to mem-ory limitations). In the next step (b), we employ YOLO todetect each of the marks within the VR image.Next, step (c), for each detected mark, we extract thecorresponding frame from the video. To achieve this, con-sidering each mark as a representation of a vehicle, we caninfer that the y coordinate of the marks bottom correspondsto the temporal index of the frame when the vehicle entirelycrosses the line. In the extracted frame correspondsto the mark highlighted in yellow in the VR image.After obtaining the relevant frame, in step (d), we em-ploy YOLO to detect vehicles in the extracted frame. Fol-lowing that, in step (e), we identify the specific vehicle rep-resented by the mark by comparing its bounding box x co-ordinates with the mark coordinates in the VR image. Continuing, in step (f), YOLO is utilized on the croppedvehicle image to identify the license plate coordinates. Fol-lowing this, in step (g), we refine the image by cropping it,and in step (h), an OCR algorithm is applied to extract thecharacters from the license plate. After completing thesesteps, we repeat for the next T frames until the video ends.",
  ". Preparation": "In this study, we utilized YOLOv8-small , which waspre-trained on COCO and fine-tuned for vehicle and markdetection using a task-specific dataset . For the licenceplate detection, we fine-tuned the model in a public avail-able dataset containing more than 10.000 images .To conduct the experiments for this work, we will use theVehicle-Rear dataset , a novel dataset for vehicle identi-fication. This dataset contains a set of videos that meet theconstraints required by the VR method, while also featur-ing vehicle license plates with high resolution. Notably, thelicense plates in this dataset adhere to the Brazilian format.For recognizing license plate characters, we employedthe pre-trained EasyOCR model.",
  ". Early Experiments": "The experiments were conducted exclusively on Video 5from Camera 2 and were evaluated solely on segmentswhere vehicles move vertically, with the line at y = 800.Our approach achieved around 15.76% Character ErrorRate (CER) when identifying the license plate characters.Its important to note that if one of the early steps failsand becomes impossible to extract the license plate, we con-sider the approach to have misread every character in thelicense plate for the CER calculation.Given that YOLO was fine-tuned on a separate datasetunder different circumstances, and we are using the baseEasyOCR model, that supports 80+ languages and hasntbeen fine-tuned specifically for recognizing license platecharacters, this outcome is relatively good.",
  ". Conclusion": "In this paper, we propose a more efficient video-basedALPR system, wherein the license plate characters are iden-tified using a single image per vehicle. Based on prelimi-nary findings, we conclude that the methodology is viable,but there is ample room for improvement. Our next aimis to fully explore this problem to improve computationalefficiency and recognition efficacy. Some ideas we havein mind are: training YOLO on the Vehicle-Rear datasetfor both mark and vehicle detection, and exploring differentOCR models. Christos-NikolaosAnagnostopoulos,IoannisAnagnos-topoulos, Ioannis Psoroulas, Vassili Loumos, and Elefthe-rios Kayafas.License plate recognition from still imagesand video sequences: A survey. Intelligent TransportationSystems, IEEE Transactions on, 9:377 391, 2008. 1",
  "Youngmin Baek, Bado Lee, Dongyoon Han, Sangdoo Yun,and Hwalsuk Lee. Character region awareness for text de-tection. CoRR, abs/1904.01941, 2019. 2": "Icaro O. De Oliveira, Rayson Laroca, David Menotti, KeikoVeronica Ono Fonseca, and Rodrigo Minetto. Vehicle-rear:A new dataset to explore feature fusion for vehicle identifi-cation using convolutional neural networks. IEEE Access, 9:101065101077, 2021. 2 Shan Du, Mahmoud Ibrahim, Mohamed Shehata, and WaelBadawy. Automatic license plate recognition (alpr): A state-of-the-art review. IEEE Transactions on Circuits and Sys-tems for Video Technology, 23(2):311325, 2013. 1",
  "Glenn Jocher, Ayush Chaurasia, and Jing Qiu. UltralyticsYOLO, 2023. 2": "Rohollah Mazrae Khoshki and Subramaniam Ganesan. Im-proved automatic license plate recognition (alpr) systembased on single pass connected component labeling (ccl) andreign property function. In 2015 IEEE International Confer-ence on Electro/Information Technology (EIT), pages 426431, 2015. 1 Rayson Laroca,Luiz A. Zanlorensi,Gabriel ResendeGoncalves, Eduardo Todt, William Robson Schwartz, andDavid Menotti. An efficient and layout-independent auto-matic license plate recognition system based on the YOLOdetector. CoRR, abs/1909.01754, 2019. 1"
}