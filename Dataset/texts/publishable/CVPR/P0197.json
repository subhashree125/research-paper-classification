{
  "Abstract": "Due to its cloud-penetrating capability and indepen-dence from solar illumination, satellite Synthetic ApertureRadar (SAR) is the preferred data source for large-scaleflood mapping, providing global coverage and includingvarious land cover classes. However, most studies on large-scale SAR-derived flood mapping using deep learning algo-rithms have primarily focused on flooded open areas, uti-lizing available open-access datasets (e.g., Sen1Floods11)and with limited attention to urban floods. To address thisgap, we introduce UrbanSARFloods, a floodwater datasetfeaturing pre-processed Sentinel-1 intensity data and inter-ferometric coherence imagery acquired before and duringflood events. It contains 8,879 512 512 chips covering807,500 km2 across 20 land cover classes and 5 conti-nents, spanning 18 flood events. We used UrbanSARFloodsto benchmark existing state-of-the-art convolutional neuralnetworks (CNNs) for segmenting open and urban flood ar-eas. Our findings indicate that prevalent approaches, in-cluding the Weighted Cross-Entropy (WCE) loss and theapplication of transfer learning with pretrained models,fall short in overcoming the obstacles posed by imbal-anced data and the constraints of a small training dataset.Urban flood detection remains challenging.Future re-search should explore strategies for addressing imbalanceddata challenges and investigate transfer learnings poten-tial for SAR-based large-scale flood mapping.Besides,expanding this dataset to include additional flood eventsholds promise for enhancing its utility and contributingto advancements in flood mapping techniques.The Ur-banSARFloods dataset, including training, validation data,and raw data, can be found at",
  ". Introduction": "As one of the most devastating natural disasters worldwide,floods have impacted billions of people .Addition-ally, it has been reported that the frequency and severity offlooding have increased due to intensified heavy precipita-tion patterns . Thus, there is a growing demand for floodmapping, monitoring, and forecasting on a global scale, notonly for high-profile catastrophic flooding events but alsofor those unreported floods. Within this context, Earth Ob-servation (EO) data, particularly satellite EO data, plays acritical role in understanding and quantifying the extent anddepths of flooding events on a large scale, thus presenting asignificant opportunity for global flood mapping and moni-toring. Currently, a variety of satellite optical data sourcessuch as MODIS, VIIRS, Landsat constellations, Sentinel-2, and PlanetScope, as well as satellite synthetic apertureradar (SAR) data including Sentinel-1, COSMO-SkyMed,Radarsat Constellation, TerraSAR-X, and GaoFen-3, arewidely employed for flood mapping. However, satellite op-tical data can be easily contaminated by clouds althoughthey offer longer temporal coverage and are easier to inter-pret. Therefore, satellite SAR data is preferred due to itsability to be acquired regardless of weather conditions (i.e.,clouds) and solar illumination.Furthermore, it is worthnoting that the biggest difference between large-scale floodmapping and region-scale flood mapping is that the meth-ods should identify floodwater in various land cover classes,including bare soils, sparsely vegetated areas, urban areas,agricultural fields, etc. However, to the best of our knowl-edge, most large-scale SAR-derived flood mapping stud-ies mainly focus on flooded open areas, i.e., bare soils andsparsely vegetated areas [e.g., 4, 21, 26, 48, 52], while large-scale SAR-derived flood mapping considering both open ar-eas and urban areas has not been well investigated yet. Toclarify, in this study, the term large-scale urban flood map-ping is used to denote flood mapping that covers both openareas and urban areas.",
  ". Overview of the UrbanSARFloods dataset": "have utilized SAR data, showing its efficacy in identifyingfloodwater in urban areas. It has been found that both SARintensity and Interferometric SAR (InSAR) coherence arecritical in urban flood mapping . Specifically, inSAR data, the totally submerged areas (such as bare soilsand buildings) typically exhibit lower backscatter than thebackground because the SAR signal has been reflected awayfrom the sensor due to the specular reflection in the calmopen water surface. Partially submerged buildings, on theother hand, often show relatively higher backscatter due tothe double-bounce effects between the water surface and thebuildings facades. Additionally, the coherence of floodedbuildings experiences a sharp drop with the appearance offloodwater, serving as a useful indicator in flood detection,particularly when changes in the intensity of flooded build-ings are too small to be detected. Furthermore, it is es-sential to consider different polarizations simultaneously, asthe backscatter is influenced by both the orientation of thebuildings and the line-of-sight (LOS) of the sensor .However, since most existing methods have not been testedon large datasets in both temporal and spatial dimensions,their generalizability and robustness in large-scale urbanflood mapping remain unknown.Although deep learning (DL) techniques have a transfor-mative impact on the remote sensing field, their integration into SAR-based large-scale urban flood mapping applica-tions remains limited. Only a handful of studies have ventured into this domain so far.Comparing theirgeneralizability and robustness is challenging due to vari-ations in data, flood events, and data preprocessing method-ologies employed across studies.Meanwhile, we haveobserved that a growing number of DL-based large-scaleflood mapping studies [e.g. 16, 23, 24, 27, 33, 47] werecarried out thanks to the publication of the georeferencedSen1Floods11 dataset .This phenomenon of publicdatasets driving advances across various research fields hasalso been demonstrated in different domains. For instance,in the field of image classification and object detection incomputer vision, ImageNet has provided researchers world-wide with access to vast amounts of data, while its testdataset has served to document the enhancements in com-puter vision capabilities . Therefore, it is believed thatone of the bottlenecks hindering the advancement of DL-based methodologies in the field of SAR-based large-scaleurban flood mapping is the absence of a benchmark dataset.To bridge this gap and engage more AI researchers inadvancing large-scale urban flood mapping with SAR data,we developed a georeferenced flood dataset named Ur-banSARFloods. The dataset comprises flooded urban andopen areas, with SAR intensity and InSAR coherence data obtained pre- and post-event in VV and VH polarizationsusing Sentinel-1 SLC data(). It offers global coverage,consisting of 8,879 chips of 512512 20m pixels across 18flood events, spanning 807,500 km2. All 8,879 chips un-derwent semi-automatic labeling via conventional remotesensing methods. Moreover, three subsets from selectedevents were manually annotated using high-resolution opti-cal data (i.e., 3m PlanetScope and 10cm UAV optical RGBorthophoto).Semi-automatic and manual labels are uti-lized during testing. Further details are provided in Sec-tion 3. Leveraging the UrbanSARFloods dataset, we eval-uate flood detection performance of various semantic seg-mentation models, including both pre-trained and scratch-trained ones. Our findings highlight the persistent challengein urban flood detection, primarily due to data imbalanceand limited dataset availability.",
  ". Flood-related benchmark datasets": "According to several remote sensing data platforms, such asEarthNet ( ,the IEEE platform ( and SpaceML from Frontier Devel-opment Lab ( thereare several flood-related datasets available.As shownin Tab. 1, it is evident that most flood-related datasetscurrently focus on flooded open areas.However, onlythree datasets (SpaceNet, Hurricane Harvey Floods, Flood-Net) provide annotations related to flood-affected buildings.However, the Hurricane Harvey Floods dataset is designedfor flood-damaged buildings instead of flooded buildings,while the SpaceNet and FloodNet datasets provide anno-tations for two flood classes (i.e., flooded buildings andflooded roads) using high-resolution optical data. Besides,another recent S1GFloods dataset, which reportedly in-cludes wetlands, riverine areas, mountainous regions, urbanand rural areas, and vegetation , annotated flooded ar-eas using Sentinel-1 intensity data only. Therefore, onlyseverely flooded buildings may be included, while most ofthe flooded built-up areas cannot be effectively included,as it has been established that InSAR coherence is impor-tant complementary information with SAR intensity whenit comes to detecting flooded buildings using SAR data.Indeed, there is currently no suitable SAR dataset specif-ically designed for large-scale urban flood mapping. Whileit is possible to gather flood labels from various studies,as exemplified by who shared their manually anno-tated flood labels as a supplementary file, inconsistenciesin annotation granularity stemming from variations in spa-tial resolution and labeling styles may compromise the re-liability of conclusions drawn from such data. Addition-ally, it has been observed that certain non-flooded areas, such as tarmac and shrubland, exhibit characteristics sim-ilar to flooded areas, potentially leading to overestimationsin large-scale flood mapping efforts . In comparison toexisting datasets, UrbanSARFloods offers a distinctive ad-vantage by encompassing two flooded classes (i.e., floodedopen areas and flooded urban areas) characterized by SARintensity and InSAR coherence data. This unique featurerenders UrbanSARFloods particularly suitable for large-scale urban flood mapping applications.",
  ". Semantic Segmentation in flood mapping ap-plication": "Currently, numerous semantic segmentation methods haverecently been applied to flood mapping applications us-ing SAR data.For instance, evaluated the perfor-mance of UNet , XNet and UNet with ResNet asthe backbone on the UNOSAT Flood Dataset ( that the performance of the models did not sig-nificantly differ. However, the UNet with ResNet as thebackbone was reported as the most favorable due to itsgreater flexibility in the choice of precision/recall tradeoff.Subsequently, indicated that UNet outperformed Seg-Net using the Sen1Floods11 dataset in flood mapping,attributed to its skip connection architecture. Furthermore, proposed a modified DeepLabV3+ model employingMobileNetv2 as the backbone for detecting flooded openareas using a C-band commercial SAR satellite data Hisea-1, which is surpassed SegNet, UNet, and DeepLabv3+ in both accuracy and inference time .Recently, introduced the Residual Wave VisionU-Net (WVResU-Net), trained and tested on Sentinel-1data, integrating advanced Vision Multi-Layer Perceptrons(MLPs) and ResU-Net, exhibiting significant superiorityover several well-known CNN and ViT DL models. Be-side the supervising learning, an unsupervised CNN modelhas been introduced in SAR-based flood mapping ,where SAR images are pre-segmented using the graph-based Felzenszwalb and Huttenlocher (Felz) segmentationalgorithm, followed by the CNN being employed to gen-erate the final flood map.In recent research, in-troduced a lightweight unsupervised flood mapping DLmodel, named Contrastive ConvLSTM Variational AutoEn-coder (CLVAE), which employs fully self-supervised train-ing with simplified contrastive learning techniques. How-ever, it should be noted that all the above-mentioned studieswere developed for flooded open areas instead of floodedurban areas using SAR data. To the best of our knowledge,only a handful of studies have been conductedspecifically focusing on SAR-based urban flood mappingusing DL techniques, where many popular semantic seg-mentation models such as UNet++ and Deeplabv3+ havenot been investigated.",
  ". Datasets": "Our dataset contains 18 Sentinel-1-covered urban floodevents, in which the changes caused by floodwater in openareas and urban areas could be measured. The geographicdistribution of selected flood events is shown in ,while more detailed information is listed in Tab. 2. The im-agery in our dataset has 8 bands, including 2 bands (VV andVH) for Sentinel-1 intensity acquired pre-event, 2 bands(VV and VH) for Sentinel-1 intensity acquired post-event, 2bands (VV and VH) for Sentinel-1 coherence acquired pre-event, and 2 bands (VV and VH) for Sentinel-1 intensityacquired co-event.",
  ". Preprocessing": "The Sentinel-1 Level-1 Interferometric Wide Swath SLCdata, downloaded from Alaska Satellite Facility (ASF),were used to extract interferograms and then calibratedand transformed into intensity (in dB). The multilooking (4looks in the range and 1 looks in the azimuth) was carriedout in order to get the interferogram with the square pixels.A Goldstein filter with a size of 9 9 pixels was applied tothe interferogram to reduce noise in the phase, and then theinterferometric coherence was estimated by a moving win-dow of 9 9 pixels. All the intensity and coherence datawere geocoded to World Geodetic System (WGS) 1984 lon-gitude and latitude with 20 m spatial resolution.",
  "Semi-automatic Labeling": "In this study, generating annotations covering the entireSentinel-1 image frame can only be achieved through con-ventional remote sensing approaches. This is because nohigh-resolution optical images acquired on the same acqui- sition dates as Sentinel-1 data are capable of covering theentire image frame (43,000 km2). Three-step annotationis needed: 1) the open flooded areas are extracted by ap-plying a hierarchical Split-based change detection approach(i.e., HSBA) to SAR intensity imagery; 2) the urbanfloods are extracted using a threshold (fixed at 0.3 based ontrial-and-error) on difference interferometric coherence im-age (i.e., pre-event coherence - co-event coherence). Thebuilt-up areas and non-built-up areas are distinguished us-ing World Settlement Footprint 2019 (WSF2019) ; 3)isolated objects with a small number of pixels are elimi-nated, whose threshold for removal was determined on acase-by-case basis by remote sensing analysts. It should benoted that for both flood classes, once a pixel has been an-notated as flooded in at least one polarization, it is annotatedas flooded.In the annotation data, flooded open areas are designatedwith a pixel value of 1, flood urban pixels are assigned avalue of 2, and non-flooded regions are represented by apixel value of 0.",
  "Hand Labeling": "For the areas where high-resolution optical data is avail-able, trained remote sensing analysts annotated open floodsand urban floods using centimeter-level UAV-based RGBimagery. All annotations were carried out using QGIS soft-ware. Due to the spatial resolution difference between RGBimagery and Sentinel-1 data, analysts need to remove somesmall flooded areas that cannot be recognized in Sentinel-1data due to its coarse resolution.",
  "EuropeNovaKakhovka, Ukraine*09 June 202322596 12226489111410361237": "flood detection methodologies.Hence, we consider notonly the quantity of images but also their representative-ness across various flood scenarios during data division.Specifically, we aim for training and validation datasets thatencompass floods occurring in various land cover classesand different environmental conditions, while the testingdatasets should feature floods from diverse locations, al-lowing us to evaluate the robustness and transferability ofdifferent flood detection methods. Therefore, three floodevents located in Africa, Asia, and Europe were selected astesting cases due to the availability of high-resolution opti-cal data, while the remaining 15 flood events were used formodel training and validation. For the 15 flood events utilized for training and valida-tion, all imagery was partitioned into 512512 pixel non-overlapping chips.In our dataset, we retained all chipswhere no flood exists, as it is believed that the featuresof non-flood pixels also contribute to the improved detec-tion of flooded pixels. More specifically, concerning large-scale flood mapping, many non-flooded areas exhibit flood-lookalike characteristics, such as the sparse shrubland nearBeledeweyne, Somalia, which may lead to confusion forflood detection models and result in over-detection ifno reliable annotation data from those specific areas is in-volved. Moreover, flood pixels typically constitute only asmall fraction of the entire scene, even during catastrophicflood events, especially when dealing with 20m spatial res-olution SAR data covering an area of 43,000 km2. Con-sequently, flood datasets often exhibit an extreme data im-balance ratio ( > 1000), especially in urban flood cases.Therefore, the training and validation data division was car-ried out using stratified sampling strategies based on flood event cases.Firstly, all tiles were classified into Non-flooded (NF)tiles, Flooded open areas (FO) tiles, and Flooded urban(FU) tiles by examining the maximal value in the anno-tation data generated in Sec. 3.2.1: if the maximal value inthe annotation data of a tile is 2, then the tile is classifiedas an FU tile; if the maximal value is 1, then the tile isclassified as an FO tile; otherwise, the tile is classified asan NF tile. Then, both the FO and FU tiles were furtherdivided into two subclasses separately: tiles with > 1000were assigned as subclass 1, while tiles with < 1000 wereassigned as subclass 2. In other words, all tiles were clas-sified into 5 categories: NF, FO1, FO2, FU1, and FU2.For each category, 70% of the tiles were allocated to thetraining dataset, while the remaining tiles were utilized forthe validation dataset.Following this scheme, our dataset comprises 8,879 non-overlapping chips covering 807,500 km2: 2,408 from threeselected study sites for testing only; 4,501 for training, and1,970 for validation across the remaining 15 events.",
  ". Statistics of the UrbanSARFloods Dataset": "To have a better understanding of the dataset, we also showthe statistics of the land cover classes distribution in train-ing, validation, and testing dataset separately, where theCopernicus Global Land cover map 2019 was involvedfor such analysis. demonstrates that both the train-ing set, validation set, and testing set contain different landcover classes and the distribution of land cover classes issimilar. Also, we display the label distributions of the train-ing set, validation set, and testing set, where the annotationobeys clear long-tailed distributions and indicates the seri-",
  ". Experiment and results": "In this dataset, we have explicitly provided the official splitsfor the training, validation, and test subsets. Offering a well-defined dataset and official split is crucial for ensuring re-producibility. In addition, the different semantic segmenta-tion models were trained on UrbanSARFloods dataset, in-cluding Unet , Unet++ , MANet , Linknet ,FPN , PSPNet , PAN , DeepLabV3 andDeeplabV3+ .",
  ". Implementation details": "All models were implemented using PyTorch and executedon an NVIDIA A40 GPU. The public codebase providedby Segmentation Models PyTorch was employed forthis purpose. Given our aim to establish straightforwardbaselines for the datasets rather than optimize for the bestpossible models, we did not conduct an exhaustive hyper-parameter search. Training for all models was conductedfor 100 epochs. The input images, initially sized 512512,were randomly cropped into 256256 dimensions with ran-dom horizontal and vertical flips, as well as random rota-tions (i.e., 90, 180, 270), applied for data augmentation.The batch sizes were set to 12, while we utilized the Adamoptimizer with an initial learning rate of 1e-5 and a weightdecay coefficient of 1e-4.The Weighted Cross-Entropy(WCE) loss was employed to address the class imbalanceamong the three classes. To evaluate the efficacy of trans-fer learning in flood mapping, each model underwent twotraining regimens: one in which the models weights wereinitialized via Xavier initialization, and another in which themodel was pre-trained using the ImageNet dataset. For allexperiments, Precision, Recall, and F1 score of each classwere used as the evaluation metrics.",
  ". Evaluation of State-of-the-art semantic seg-mentation models": "We evaluated nine existing semantic segmentation modelsavailable in Segmentation Models PyTorch . The re-sults of two flood classes are presented in Tab. 3 and Tab. 4,separately. As is shown in Tab. 3, the F1 score for FO inWeihui and Jubba ranges from 0.51 to 0.77 due to relativelylow precision, indicating overestimation of FO. An exam-ple of Weihui is shown in , where FO is displayed inblue and FU is displayed in red. Within the RGB combi-nation of pre-event/post-event intensity, FO is cyan and FUis red in (2). Similarly, within the RGB combinationof pre-event and co-event coherence, FU is cyan in (3). Thus, combining the label data in (1) and SARdata in (2-3), it is clear that most overestimation ofFO mainly exists in the boundary of FO. However, the F1source of FO is much lower in the NovaKakhovka with thecorresponding precision below 0.2. Compared with the 3mPlanetscope data acquired on the same date, there are two sources of those FO false alarms: non-flooded agriculturefields and wind-affected permanent water surfaces havingsimilar characterises of FO.When it comes to the quantitative results of FU, the F1scores and their corresponding precision are lower than 0.1(Tab. 4), indicating too many false alarms of FU exist. Be-sides the difficulty in distinguishing flooded urban pixelsfrom other FU-lookalike pixels, some pixels that definitelydo not have FU-lookalike features have been wrongly clas-sified as FU, as is shown in the yellow box in . In ad-dition, there is a disparity in performance between FO andFU, which can be attributed to the imbalanced data issue,despite our efforts to address it using the Weighted Cross-Entropy (WCE) loss.Furthermore, we conducted an evaluation of all floodmaps using manually annotated data, and no significant dif-ferences were observed. Therefore, it is inferred that therelatively poor performance of all models is attributable tothe challenges inherent in large-scale flood mapping ap-plications, rather than being solely attributed to the semi-automatic label data itself.",
  ". Evaluation of transfer learning": "Furthermore, all models pretrained on ImageNet were fine-tuned and tested on our dataset. Results are presented inTables 5 and 6. Comparing with results in Tables 3 and 4,no significant performance differences were observed. Thiscould be attributed to the substantial disparity between theImageNet dataset and our UrbanSARFloods dataset. Im-ageNet comprises millions of RGB neutral images, whileUrbanSARFloods consists of 8-band SAR data, includ-ing SAR intensity and InSAR coherence data. This dif-ference in feature spaces between the input channels ofthe source domain (ImageNet) and the target domain (Ur-banSARFloods) may impede the models ability to extractrelevant features for flood classification in our study. Sim-ilar results were obtained when using manually annotatedground truth data for subsets of the entire Sentinel-1 im-age frame. Hence, further exploration of advanced transferlearning techniques, such as domain adaptation, is essentialto address challenges in large-scale urban flood mapping.",
  ". Conclusion": "One of the bottlenecks in integrating DL techniques withlarge-scale urban flood mapping is the lack of proper open-access datasets. To address this gap, we constructed a pre-processed Sentinel-1 dataset, known as UrbanSARFloods,encompassing both urban and rural floods. This dataset en-capsulates two significant challenges encountered in large-scale remote sensing mapping: complex background sam-ples and imbalanced data.We evaluated state-of-the-artmethods on the UrbanSARFloods dataset, uncovering thespecific challenges posed by UrbanSARFloods. Addition-",
  ". Example of one test site (Weihui): flood label data,SAR data, and generated flood maps using different modelstrained from scratch": "ally, we conducted transfer learning experiments to explorealternative approaches for overcoming these challenges.This work offers a free and open dataset to advancelarge-scale urban flood mapping in the area of microwaveremote sensing.We also provide this benchmarkedtask with two considerable challenges, allowing other re-searchers to easily build on this work and create new andenhanced capabilities. A potential positive societal impactmay arise from the development of generalizable modelsthat can produce large-scale flood maps considering urbanfloods and rural floods accurately. This could help provideglobal-scale flood maps using all achieved satellite data.",
  "Acknowledgement": "This work is jointly supported by German Federal Ministryfor Economic Affairs and Climate Action in the frameworkof the national center of excellence ML4Earth (grantnumber: 50EE2201C) and by the German Federal Min-istry of Education and Research (BMBF) in the frameworkof the international future AI lab AI4EO Artificial In-telligence for Earth Observation: Reasoning, Uncertainties,Ethics and Beyond (grant number: 01DD20001).",
  "Shadi Sadat Baghermanesh, Shabnam Jabari, and HeatherMcGrath. Urban flood detection using TerraSAR-X and SARSimulated Reflectivity Maps. Remote Sensing, 14(23):6154,2022. 1": "Bjorn Barz, Kai Schroter, Moritz Munch, Bin Yang, An-drea Unger, Doris Dransch, and Joachim Denzler. Enhancingflood impact analysis using interactive retrieval of social me-dia images. arXiv preprint arXiv:1908.03361, 2019. 4 Bernhard Bauer-Marschallinger, Senmao Cao, Mark EdwinTupas, Florian Roth, Claudio Navacchi, Thomas Melzer,Vahid Freeman, and Wolfgang Wagner. Satellite-based floodmapping through bayesian inference from a sentinel-1 sardatacube. Remote Sensing, 14(15):3673, 2022. 1 Derrick Bonafilia, Beth Tellman, Tyler Anderson, and EricaIssenberg. Sen1floods11: A georeferenced dataset to trainand test deep learning flood algorithms for sentinel-1. In Pro-ceedings of the IEEE/CVF Conference on Computer Visionand Pattern Recognition Workshops, pages 210211, 2020.2, 4 Fabio Brill, Stefan Schlaffer, Sandro Martinis, Kai Schroter,and Heidi Kreibich.Extrapolating satellite-based floodmasks by one-class classificationa test case in houston.Remote Sensing, 13(11):2042, 2021. 3 MarcelBuchhorn,BrunoSmets,LucBertels,BertDe Roo, Myroslava Lesiv, Nandin-Erdene Tsendbazar, Mar-tin Herold, and Steffen Fritz. Copernicus global land service:Land cover 100m: collection 3: epoch 2019: Globe. VersionV3. 0.1, 2020. 5 Joseph Bullock, Carolina Cuesta-Lazaro, and Arnau Quera-Bofarull. Xnet: a convolutional neural network (cnn) imple-mentation for medical x-ray image segmentation suitable forsmall datasets. In Medical Imaging 2019: Biomedical Ap-plications in Molecular, Structural, and Functional Imaging,pages 453463. SPIE, 2019. 3 M.A. Caretta, A. Mukherji, M. Arfanuzzaman, R.A. Betts,A. Gelfan, Y. Hirabayashi, T.K. Lissner, J. Liu, E.L. Gunn,R. Morgan, S. Mwanga, S. Supratid, H.-O. Portner, D.C.Roberts, M. Tignor, E.S. Poloczanska, K. Mintenbeck, A.Alegra, M. Craig, S. Langsdorf, S. Loschke, V. Moller, A.Okem, and B. Rama. Water. in: Climate change 2022: Im-pacts, adaptation and vulnerability. contribution of workinggroup ii to the sixth assessment report of the intergovernmen-tal panel on climate change. Technical report, CambridgeUniversity, 2022. 1 Abhishek Chaurasia and Eugenio Culurciello. Linknet: Ex-ploiting encoder representations for efficient semantic seg-mentation. In 2017 IEEE visual communications and imageprocessing (VCIP), pages 14. IEEE, 2017. 6",
  "Liang-Chieh Chen, George Papandreou, Florian Schroff, andHartwig Adam. Rethinking atrous convolution for seman-tic image segmentation. arXiv preprint arXiv:1706.05587,2017. 6": "Liang-Chieh Chen, Yukun Zhu, George Papandreou, FlorianSchroff, and Hartwig Adam. Encoder-decoder with atrousseparable convolution for semantic image segmentation. InProceedings of the European conference on computer vision(ECCV), pages 801818, 2018. 3, 6 Marco Chini, Renaud Hostache, Laura Giustarini, andPatrick Matgen.A hierarchical split-based approach forparametric thresholding of sar images: Flood inundation asa test case. IEEE Transactions on Geoscience and RemoteSensing, 55(12):69756988, 2017. 4 Marco Chini, Ramona Pelich, Luca Pulvirenti, NazzarenoPierdicca, Renaud Hostache, and Patrick Matgen. Sentinel-1insar coherence to detect floodwater in urban areas: Houstonand hurricane harvey as a test case. Remote Sensing, 11(2):107, 2019. 1",
  "Pavel Iakubovskii. Segmentation models pytorch. 2019. 6": "Pasquale Iervolino, Raffaella Guida, Antonio Iodice, andDaniele Riccio. Flooding water depth estimation with high-resolution SAR. IEEE Transactions on Geoscience and Re-mote Sensing, 53(5):22952307, 2015. 1 Ali Jamali, Swalpa Kumar Roy, Leila Hashemi Beni, Biswa-jeet Pradhan, Jonathan Li, and Pedram Ghamisi. Residualwave vision u-net for flood mapping using dual polariza-tion sentinel-1 sar imagery. International Journal of AppliedEarth Observation and Geoinformation, 127:103662, 2024.3 Xin Jiang, Shijing Liang, Xinyue He, Alan D Ziegler,Peirong Lin, Ming Pan, Dashan Wang, Junyu Zou, DaleiHao, Ganquan Mao, et al. Rapid and large-scale mapping offlood inundation via integrating spaceborne synthetic aper-ture radar imagery with unsupervised deep learning. ISPRSjournal of photogrammetry and remote sensing, 178:3650,2021. 1, 3",
  "Hanchao Li, Pengfei Xiong, Jie An, and Lingxue Wang.Pyramid attention network for semantic segmentation. arXivpreprint arXiv:1805.10180, 2018. 6": "Junjie Li, Linyi Li, Yanjiao Song, Jiaming Chen, Zhe Wang,Yi Bao, Wen Zhang, and Lingkui Meng. A robust large-scalesurface water mapping framework with high spatiotemporalresolution based on the fusion of multi-source remote sens-ing data. International Journal of Applied Earth Observationand Geoinformation, 118:103288, 2023. 1 Wenwen Li, Hyunho Lee, Sizhe Wang, Chia-Yu Hsu, andSamantha T Arundel. Assessment of a new geoai founda-tion model for flood inundation mapping. In Proceedings ofthe 6th ACM SIGSPATIAL International Workshop on AI forGeographic Knowledge Discovery, pages 102109, 2023. 2 Yu Li, Sandro Martinis, and Marc Wieland.Urban floodmapping with an active self-learning convolutional neuralnetwork based on terrasar-x intensity and interferometric co-herence.ISPRS Journal of Photogrammetry and RemoteSensing, 152:178191, 2019. 2, 3 Tsung-Yi Lin, Piotr Dollar, Ross Girshick, Kaiming He,Bharath Hariharan, and Serge Belongie.Feature pyra-mid networks for object detection.In Proceedings of theIEEE conference on computer vision and pattern recogni-tion, pages 21172125, 2017. 6 Luigi Tommaso Luppino, Filippo Maria Bianchi, GabrieleMoser, and Stian Normann Anfinsen. Unsupervised imageregression for heterogeneous change detection. IEEE Trans-actions on Geoscience and Remote Sensing, 57(12):99609975, 2019. 4 Suna Lv, Lingsheng Meng, Deanna Edwing, Sihan Xue,Xupu Geng, and Xiao-Hai Yan. High-performance segmen-tation for flood mapping of hisea-1 sar remote sensing im-ages. Remote Sensing, 14(21):5504, 2022. 3",
  "Jun Rentschler, Melda Salhab, and Bramka Arga Jafino.Flood exposure and poverty in 188 countries. Nature com-munications, 13(1):3527, 2022. 1": "Olaf Ronneberger, Philipp Fischer, and Thomas Brox. U-net: Convolutional networks for biomedical image segmen-tation. In Medical Image Computing and Computer-AssistedInterventionMICCAI 2015: 18th International Conference,Munich, Germany, October 5-9, 2015, Proceedings, Part III18, pages 234241. Springer, 2015. 3, 6 Tamer Saleh, Xingxing Weng, Shimaa Holail, Chen Hao,and Gui-Song Xia. Dam-net: Global flood detection fromsar imagery using differential attention metric-based visiontransformers. arXiv preprint arXiv:2306.00704, 2023. 3",
  "Zhitong Xiong, Fahong Zhang, Yi Wang, Yilei Shi, andXiao Xiang Zhu. Earthnets: Empowering ai in earth obser-vation. arXiv preprint arXiv:2210.04936, 2022. 3": "Ritu Yadav, Andrea Nascetti, Hossein Azizpour, and YifangBan.Unsupervised flood detection on sar time series us-ing variational autoencoder. International Journal of AppliedEarth Observation and Geoinformation, 126:103635, 2024.2, 3 Qing Yang,Xinyi Shen,Emmanouil N Anagnostou,Chongxun Mo, Jack R Eggleston, and Albert J Kettner. Ahigh-resolution flood inundation archive (2016the present)from sentinel-1 sar imagery over conus. Bulletin of the Amer-ican Meteorological Society, pages 140, 2021. 1, 4 Qing Yang, Xinyi Shen, Qingyuan Zhang, Sean Helfrich,Josef M Kellndorfer, and Wei Hao. Promoting sar-based ur-ban flood mapping with adversarial generative network andout of distribution detection. In IGARSS 2023-2023 IEEEInternational Geoscience and Remote Sensing Symposium,pages 23362338. IEEE, 2023. 2, 3",
  "Proceedings of the IEEE conference on computer vision andpattern recognition, pages 28812890, 2017. 6": "Jie Zhao, Ramona Pelich, Renaud Hostache, Patrick Matgen,Senmao Cao, Wolfgang Wagner, and Marco Chini. Deriv-ing exclusion maps from c-band sar time-series in support offloodwater mapping. Remote Sensing of Environment, 265:112668, 2021. 3, 5 Jie Zhao, Ramona Pelich, Renaud Hostache, Patrick Mat-gen, Wolfgang Wagner, and Marco Chini.A large-scale20052012 flood map record derived from envisat-asar data:United kingdom as a test case. Remote Sensing of Environ-ment, 256:112338, 2021. 1 Jie Zhao, Yu Li, Patrick Matgen, Ramona Pelich, RenaudHostache, Wolfgang Wagner, and Marco Chini. Urban-awareu-net for large-scale urban flood mapping using multitempo-ral sentinel-1 intensity and interferometric coherence. IEEETransactions on Geoscience and Remote Sensing, 60:121,2022. 2, 3 Zongwei Zhou, Md Mahfuzur Rahman Siddiquee, NimaTajbakhsh, and Jianming Liang. Unet++: A nested u-net ar-chitecture for medical image segmentation. In Deep Learn-ing in Medical Image Analysis and Multimodal Learningfor Clinical Decision Support: 4th International Workshop,DLMIA 2018, and 8th International Workshop, ML-CDS2018, Held in Conjunction with MICCAI 2018, Granada,Spain, September 20, 2018, Proceedings 4, pages 311.Springer, 2018. 6"
}