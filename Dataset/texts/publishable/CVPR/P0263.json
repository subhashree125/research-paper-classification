{
  "Abstract": "This work introduces a novel approach to achievingarchitecture-agnostic equivariance in deep learning, par-ticularly addressing the limitations of traditional layerwiseequivariant architectures and the inefficiencies of the ex-isting architecture-agnostic methods. Building equivariantmodels using traditional methods requires designing equiv-ariant versions of existing models and training them fromscratch, a process that is both impractical and resource-intensive. Canonicalization has emerged as a promising al-ternative for inducing equivariance without altering modelarchitecture, but it suffers from the need for highly expres-sive and expensive equivariant networks to learn canonicalorientations accurately. We propose a new optimization-based method that employs any non-equivariant networkfor canonicalization. Our method uses contrastive learn-ing to efficiently learn a canonical orientation and offersmore flexibility for the choice of canonicalization network.We empirically demonstrate that this approach outperformsexisting methods in achieving equivariance for large pre-trained models and significantly speeds up the canonical-ization process, making it up to 2 times faster.",
  ". Introduction": "Equivariant deep learning has emerged as a prominent ap-proach within deep learning, aimed at developing neuralnetworks that inherently understand and adapt to the sym-metries in their input data .By con-structing models that remain unaffected by transformationssuch as rotations or reflections, these networks preservethe core properties of the data, facilitating more efficientlearning and better generalization across tasks. This no-tion of equivariance proves invaluable in areas such ascomputer vision , scientific applications, graphs , and reinforcementlearning , where the ability to recognize pat-terns and make robust predictions demand a nuanced graspof underlying data symmetries.In the realm of equivariant model design, where the focus has traditionally been on creating novel equivari-ant layers , a fresh research directionhas emerged that centers around architecture-agnostic ap-proaches. These methods, including symmetrization , frame-averaging , and canonicalization ,aim to make models inherently equivariant to the transfor-mation of the data without the need for specialized parame-terized layers and activations. These methods significantlysimplifies equivariant model design and, in some scenar-ios, make them more efficient. In particular, canonicaliza-tion proved to be a cheap and efficient way to any existingneural network equivariant to a group of transformations. This idea becomes more appealing especially when itcomes to making any existing widely used large pre-trainedmodels, including foundation models like SAM , com-pletely equivariant .In this work, we focus on enhancing the canonicaliza-tion process, specifically addressing its fundamental limita-tion: the reliance on equivariant architecture for construct-ing the canonicalization network. We explore an alternateoptimization approach and propose a novel method thatuses contrastive learning during training to learn a uniquecanonical orientation for inference.Our technique givesus the flexibility to use any neural network as a canonical-ization network, including pretrained ones that further im-proves the ease of optimization. This further relaxes anyarchitectural constraints required to build equivariant mod-els making them more accessible to the wider deep learn-ing community. Moreover, we demonstrate that our sim-ple approach not only outperforms existing method to buildequivariant models using canonicalization but also makescanonicalization process significantly more effcient.",
  ". Background": "Kaba et al. introduces a systematic and general methodfor equivariant machine learning based on learning map-pings to canonical samples. Rather than trying to hand-engineer these canonicalization functions, they propose tolearn them in an end-to-end fashion with a prediction neu-ral network. Canonicalization can be seamlessly integratedas an independent module into any existing architecture to",
  "er2": ". Learning equivariant canonicalizer with a non-equivariant canonicalization network. All the transformations of the group areapplied to the input image and passed through the canonicalization network in parallel. A dot product of the output of the canonicalizationnetwork with a reference vector gives us a distribution over the transformations to canonicalize the input. We also minimize the similaritybetween the vectors to get a unique canonical orientation. make them equivariant to a wide range of transformationgroups, discrete or continuous.This approach not onlymatches the expressive capabilities of methods like frameaveraging by Puny et al. but also surpasses them byoffering simplicity, efficiency, and a systematic end-to-endlearning method that replaces hand-engineered frames withlearned mappings for each group.",
  ". Formulation": "The approach formulates the invariance requirement for afunction as the capability to map all members of a grouporbit to the same output. This is achieved by mapping in-puts to a canonical sample from their orbit before applyingthe function. For equivariance, elements are also mappedto a canonical sample and, following function application,transformed back according to their original position in or-bit. This can be formalized by writing the equivariant func-tion f in canonicalized form as",
  "f (x) = c (x)p(c(x)1 x)(1)": "where the function p X Y is called the prediction func-tion and the function c X (G) is called the canoni-calization function. Here c(x)1 is the inverse of the repre-sentation matrix and c (x) = (1 (c(x))) is the coun-terpart of c(x) on the output.Kaba et al. shows that f is G-equivariant for any pre-diction function as long as the canonicalization function isitself G-equivariant, c((g)x) = (g)c(x) g,x GX.",
  ". Canonicalization Function": "Kaba et al. choose the canonicalization function to beany existing equivariant neural network architecture withthe output being a group element, which they call the directapproach. This ensures the G-equivariance constraint of thecanonicalization function. For example, Group Convolu-tional Neural Network (G-CNNs) are used to design acanonicalization function that is equivariant to the group ofdiscrete rotations.They also provide an alternative optimization approach,in which the canonicalization function is defined as",
  ". Prior Regularization": "Mondal et al. extend canonicalization to adapt any ex-isting pretrained neural network to its equivariant counter-part. To enhance the canonicalization process, ensuring in-put orientations closely match whats found in our train-ing data, they introduce a novel regularizer known as theCanonicalization Prior (CP). This approach aims to lever-age the similarity in orientations between fine-tuning andtraining datasets to guide canonicalization in closely match-ing the original orientations of inputs seen by the pretrainednetwork during the pretraining stage.From a probabilistic standpoint, the canonicalizationfunction maps each data point into a probability distribu-tion across a group of transformations, denoted by G. Fora specific data point x, let Pc(x) represent the distributioninduced by the canonicalization function over G. Assum-ing a canonicalization prior exists for the dataset D, char-acterized by a distribution PD over G, prior regularizationaims to minimize the Kullback-Leibler (KL) divergencebetween PD and Pc(x).This leads to the loss function:Lprior = ExD [DKL(PD Pc(x))].",
  "g arg mingGu((g)1 x)(4)": "Assuming there are no symmetric elements in the orbit rep-resented by xG = {(g)1 x g G}, it is important toensure the function u() has a unique minimum to establisha canonical orientation. Additionally, should symmetric el-ements exist within the orbit, and if the minimum is attainedamong these symmetric positions, selecting any one of themwill yield the correct canonical orientation (see ).In order to design this function u(), we resort to learn-ing it using a neural network and minimizing the similarityamong the output of the elements in the orbit. We outputvectors corresponding to every element in the orbit using any neural network s(). This allows us to use techniquesfrom the self-supervised learning literature to prevent rep-resentation collapse including non-contrastiveones that relies on the maximizing the eigenspectrum of thecovariance matrix . In contrast to this, outputtingscalars directly makes the optimization harder while limit-ing us to only contrastive methods. Then, we take a dotproduct of outputs of s() with a reference vector vR, whichwe can either learn or keep fixed. We get the distribution in-duced by canonicalization function Pc(x) by taking a soft- max over {vR s ((g)1 x)/ g G}, where is thetemperature parameter of the distribution that controls itssharpness and is set to 1 in our experiments. In this for-mulation, u() becomes the probability mass function. Thefinal optimization formulation becomes:",
  "gG exp(vR s ((g)1 x)/)(5)": "Inorder to make this canonicalization process differen-tiable, we use straight through gradient trick as proposed in. Alternatively, to introduce more augmentation effectduring training , one can use Gumbel Softmax tosample from Pc(x) in a differentiable way. Now, to obtainan unique canonical orientation, we train s() to output dif-ferent vectors for every unique element in the orbit xG byminimizing the following loss, LOpt:",
  "ExDgi,gjG,gigjs ((gi)1 x) s ((gj)1 x)(6)": "where D is the training dataset.This loss preventsthe collapse of learnt vectors in the output space of s()for different transformations of the input x by minimizingtheir similarity measured using elementwise dot product. shows a schematic of our simple approach. The useof non-contrastive approaches that uses the cross-correlation between these vectors to prevent representationcollapse is an interesting avenue of future work.In the context of training from scratch , the loss fromEq. (6) can be jointly optimized with the task loss. Simi-larly, for fine-tuning or zero-shot adaptation , an addi-tional prior regularization loss is used. Assuming the iden-tity transformation to be the prior for natural image dataset, the loss Lprior is given by:",
  "STL10": "Vanilla98.30 0.0188.61 0.3498.31 0.0978.63 0.25C4-Augmentation98.20 0.0595.84 0.0497.69 0.0795.79 0.14EquiAdapt97.01 0.0196.98 0.0296.15 0.0596.15 0.05EquiOptAdapt98.04 0.0598.04 0.0497.32 0.0197.32 0.01 . Performance comparison of large pretrained models finetuned on different vision datasets. Both Accuracy (Acc) and C4-AverageAccuracy (C4-Avg Acc) are reported. Acc refers to the accuracy on the original test set, and C4-Avg Acc refers to the accuracy on theaugmented test set obtained using the group C4. where Df is the finetuning dataset. As this formulationtransfers the equivariance constraint of Eq. (3) to minimiz-ing the loss in Eq. (6) over the data distribution, we canconveniently start with a pretrained s() to further ease theoptimization process.Typically, we choose s() that are smaller and faster thanthe large prediction network p(). This is based on the as-sumption that determining a canonical orientation is sim-pler than the more complex downstream task that demandsa deeper understanding of the input. Therefore, our methodrequires G forward passes in parallel through s() insteadof the prediction function p(), making it significantly moreefficient than symmetrization-based methods .",
  ". Results": "While our method applies to training any equivariant mod-els from scratch, motivated by the practical advantages ofusing large scale pretrained models, we only focus on theirequivariant adaptation by finetuning them using prior reg-ularization loss. This section presents results from exper-iments on well-known, publicly available pretrained net-works.Our method, EquiOptAdapt, enables equivariantadaptation of these models without any additional architec-ture constraints on the canonicalizer. EquiOptAdapt main-tains fine-tuned model performance, increases robustnessagainst known out-of-distribution transformations, and op-erates faster than conventional equivariant canonicalizationapproaches.",
  ". Image Classification": "Experiment Setup.The Vanilla setup consists of fine-tuning ResNet50 and Vision Transformer (ViT, ),which are widely used for obtaining image embeddings tosolve downstream tasks. Both architectures were pretrainedon ImageNet-1K , and the checkpoints are publicly available. 23. Another strong baseline is to fine-tune thepretrained architecture using C4 group data augmentation,given our prior knowledge that the evaluation is performedon a C4-augmented test set.The EquiAdapt setup uses an equivariant canonical-ization network to build a canonicalizer that is placed beforethe pretrained architecture. Both the networks are finetunedusing a cross-entropy loss for the classification task and anadditional prior regularization loss is used for the canoni-calization network. In comparison to this, the canonicalizerin EquiOptAdapt uses a smaller pretrained ResNet architec-ture as a canonicalization network s(). We set the outputspace of s() to 128 dimension, and vR is a random con-stant Gaussian vector of the same dimension. Along withthe cross-entropy classification task loss and Lprior, the fi-nal fine-tuning loss includes Lopt to learn an equivariantcanonicalizer. Evaluation setup.We use a similar evaluation protocol asMondal et al. . Along with the accuracy on the originaltest set, we use C4-Average Accuracy that indicates accu-racy on an augmented test set, where each image in the testset was rotated with elements of C4 group, i.e., group of 4discrete rotations. Results.We present the finetuning results for different se-tups in Tab. 1 for CIFAR10 and STL10 . Our find-ings demonstrate that both EquiOptAdapt and EquiAdaptexhibit comparable performance to the Vanilla setup interms of test-set accuracy, with EquiOptAdapt showcasingsuperior performance. This suggests that pretrained non-equivariant canonicalization network can further ease theoptimization, thereby enhancing their ability to learn the",
  ". Zero-shot performance comparison and inference times of large pretrained segmentation models with and without trained canoni-calization functions on the validation set of COCO 2017 dataset": "mapping from data input to a unique element within theorbit of the considered group.Similar to Mondal et al., we observe that more expressive canonicalizers lead tohigher performance. Further, there is no gap between accu-racy and C4-average accuracy, demonstrating the success-ful learning of equivariant canonicalizer, and hence, equiv-ariant adaptation of the considered models. The Vanilla andC-4 Augmentation models perform significantly worse thanequivariant adaptation based models while testing on C-4augmented test set.",
  ". Zero-shot Instance Segmentation": "Experiment Setup.Next, we compare the zero-shotinstance segmentation results for MaskRCNN andSegment-Anything Model (SAM, ) on COCO 2017.Particularly, we evaluate promptable instance seg-mentation for the SAM, with bounding boxes as prompts.We keep the same setups as Sec. 4.1 where fine-tuning isreplaced with zero-shot performance. Similar to the strat-egy in Mondal et al. , where a canonicalizer is trainedon the COCO dataset with prior regularization Lprior, weonly train our canonicalizer with an additional optimaztionloss Lopt to make the canonicalization process equivariant.Similar to Sec. 4.1, we initialize our non-equivariant canon-icalizers with pretrained WideResNet-50 architecture. Evaluation setup.We use the mean-average precision(mAP) and C4-Average mAP scores.Here, again, C4-Average mAP score indicates the mAP score on an aug-mented val set of COCO 2017, where each image (andbounding boxes) was rotated with elements of C4 groupwhile mAP indicates the mAP score on the original val set.We also compare the relative wall clock time (in min-utes) to learn the prior distribution Pc(x) during trainingwith . Given that our chosen Pc(x) is effectively a -distribution centred on the identity element e of the group,we evaluate the accuracy of learning this prior as the iden-tity metric.",
  "Results.The results for various setups are presented in. Our analysis reveals that EquiAdapt and EquiOp-": "tAdapt effectively achieve architecture-agnostic equivari-ant adaptation of large pretrained models while maintainingtheir mean Average Precision (mAP) performance. Notably,again, EquiOptAdapt outperforms EquiAdapt in this regard.Additionally, we provide comprehensive insights into thetotal inference times for each setup in Tab. 2. The infer-ence times for EquiOptAdapt and EquiAdapt indicate thatthe canonicalization process is 2 faster for EquiOptAdapt.Moreover, plots the relative wall-time forEquiOptAdapt and EquiAdapt against the identity metric.We demonstrate that our proposed EquiOptAdapt is able tolearn the prior distribution faster than EquiAdapt. This re-sults from the ability to use any exisiting non-equivariantpretrained WideResNet model that trains and run faster thanan Equivariant WideResNet architecture used in EquiAdapt. Therefore, our findings suggest that EquiOptAdaptgenerally offers better performance and faster training andinference times compared to EquiAdapt. .Identity metric vs.Relative wall-time (in minutes).We define the identity metric as the percentage of input imagesmapped to the identity group element e, which is our prior distri-bution Pc(x). This figure demonstrates that our EquiOptAdapt isable to learn the prior faster than EquiAdapt.",
  ". Conclusion": "Generalizing to out-of-distribution data remains a consider-able obstacle for state-of-the-art deep learning models, par-ticularly due to input transformations like rotations, scal-ings, and orientation changes.Large pretrained modelscan be made equivariant to such transformations throughcanonicalization . However, existing approaches suchas use equivariant networks for canonicalizationwhich acts as a bottleneck for learning canonical orienta-tions. This paper proposes EquiOptAdapt to address thisexpressivity constraint by leveraging an optimization-basedapproach with contrastive learning techniques enabling theuse of any neural network architecture for canonicaliza-tion. Our experiments show that EquiOptAdapt preservesthe performance of large pretrained models and surpassesexisting methods on robust generalization to transforma-tions of the data while significantly accelerating the canon-icalization process. These findings highlight the practical-ity and effectiveness of our approach in achieving robustequivariant adaptation, marking an important advancementin improving out-of-distribution generalization and equiv-ariant model design.",
  ". Limitations and Future Work": "An important limitation of our current work lies in its focuson the group of discrete transformations. Prior experimentswith continuous groups, such as the group of 2D rotationsSO(2) , have revealed the limited ability of E(2) steer-able networks to learn mappings from inputs to canon-ical orientations with prior regularization. This limitationcan be potentially mitigated by utilizing more expressiveunconstrained pretrained neural networks as the canonical-ization network, which could lead to enhanced optimiza-tion.However, using continuous group will require testtime optimization using the output energy values, which canmake inference significantly more expensive. We plan to in-vestigate this to find a workaround and introduce continuousrotations in future work.In addition to continuous rotations, we intend to incorpo-rate higher-order discrete rotations and compare them. Thefiner rotation angles present an intriguing challenge for bothcontinuous and higher-order discrete rotations due to the ar-tifacts introduced at the corners of images. To address this,we aim to design novel techniques to make the canonical-ization network robust to the effect of artifacts. Moreover,exploring other non-contrastive correlation-based methodsto train the canonicalizer is another interesting direction forfuture research.Finally, automating prior discovery based on the perfor-mance of the pretrained model over different transforma-tions of the input in the fine-tuning data can significantlyimpact the current limitation of manually deciding the prior.This can make the Equivariant Adaptation technique more",
  "Adrien Bardes, Jean Ponce, and Yann LeCun.Vi-creg: Variance-invariance-covariance regularization for self-supervised learning. arXiv preprint arXiv:2105.04906, 2021.3": "Sourya Basu, Pulkit Katdare, Prasanna Sattigeri, Vijil Chen-thamarakshan, Katherine Driggs-Campbell, Payel Das, andLav R Varshney. Efficient equivariant transfer learning frompretrained models. In Advances in Neural Information Pro-cessing Systems, pages 42134224. Curran Associates, Inc.,2023. 1, 4 Sourya Basu, Prasanna Sattigeri, Karthikeyan Natesan Ra-mamurthy, Vijil Chenthamarakshan, Kush R Varshney,Lav R Varshney, and Payel Das. Equi-tuning: Group equiv-ariant fine-tuning of pretrained models. In Proceedings ofthe AAAI Conference on Artificial Intelligence, pages 67886796, 2023. 1, 4 Ilyes Batatia, David P Kovacs, Gregor Simm, Christoph Or-tner, and Gabor Csanyi.Mace: Higher order equivariantmessage passing neural networks for fast and accurate forcefields. Advances in Neural Information Processing Systems,35:1142311436, 2022. 1 Erik J Bekkers, Maxime W Lafarge, Mitko Veta, Koen AJEppenhof, Josien PW Pluim, and Remco Duits.Roto-translation covariant convolutional networks for medical im-age analysis.In Medical Image Computing and Com-puter Assisted InterventionMICCAI 2018: 21st Interna-tional Conference, Granada, Spain, September 16-20, 2018,Proceedings, Part I, pages 440448. Springer, 2018. 1 Alexander Bogatskiy, Sanmay Ganguly, Thomas Kipf, RisiKondor, David W Miller, Daniel Murnane, Jan T Offermann,Mariel Pettee, Phiala Shanahan, Chase Shimmin, et al. Sym-metry group equivariant architectures for physics.arXivpreprint arXiv:2203.06153, 2022. 1 Johannes Brandstetter, Rob Hesselink, Elise van der Pol,Erik J Bekkers, and Max Welling. Geometric and physicalquantities improve e (3) equivariant message passing. In In-ternational Conference on Learning Representations, 2021.1",
  "Taco S Cohen, Mario Geiger, Jonas Kohler, and MaxWelling. Spherical cnns. arXiv preprint arXiv:1801.10130,2018": "Congyue Deng, Or Litany, Yueqi Duan, Adrien Poulenard,Andrea Tagliasacchi, and Leonidas J Guibas. Vector neu-rons: A general framework for so (3)-equivariant networks.In Proceedings of the IEEE/CVF International Conferenceon Computer Vision, pages 1220012209, 2021. 1 Jia Deng, Wei Dong, Richard Socher, Li-Jia Li, Kai Li,and Li Fei-Fei. Imagenet: A large-scale hierarchical imagedatabase. In 2009 IEEE conference on computer vision andpattern recognition, pages 248255. Ieee, 2009. 4 Alexey Dosovitskiy, Lucas Beyer, Alexander Kolesnikov,Dirk Weissenborn, Xiaohua Zhai, Thomas Unterthiner,Mostafa Dehghani, Matthias Minderer, Georg Heigold, Syl-vain Gelly, et al. An image is worth 16x16 words: Trans-formers for image recognition at scale. In International Con-ference on Learning Representations, 2020. 4 Alexandre Duval, Simon V Mathis, Chaitanya K Joshi, Vic-tor Schmidt, Santiago Miret, Fragkiskos D Malliaros, TacoCohen, Pietro Li`o, Yoshua Bengio, and Michael Bronstein.A hitchhikers guide to geometric gnns for 3d atomic sys-tems. arXiv preprint arXiv:2312.07511, 2023. 1 Alexandre Agm Duval, Victor Schmidt, Alex Hernandez-Garceia, Santiago Miret, Fragkiskos D Malliaros, YoshuaBengio, and David Rolnick. Faenet: Frame averaging equiv-ariant gnn for materials modeling. In International Confer-ence on Machine Learning, pages 90139033. PMLR, 2023.1",
  "Sekou-Oumar Kaba and Siamak Ravanbakhsh. Symmetrybreaking and equivariant neural networks.arXiv preprintarXiv:2312.09016, 2023. 3": "Sekou-Oumar Kaba, Arnab Kumar Mondal, Yan Zhang,Yoshua Bengio, and Siamak Ravanbakhsh.Equivariancewith learned canonicalization functions.In InternationalConference on Machine Learning, pages 1554615566.PMLR, 2023. 1, 2, 3, 6 Jinwoo Kim, Dat Nguyen, Ayhan Suleymanzade, HyeokjunAn, and Seunghoon Hong.Learning probabilistic sym-metrization for architecture agnostic equivariance.In Ad-vances in Neural Information Processing Systems, pages1858218612. Curran Associates, Inc., 2023. 1 Alexander Kirillov, Eric Mintun, Nikhila Ravi, Hanzi Mao,Chloe Rolland, Laura Gustafson, Tete Xiao, Spencer White-head, Alexander C Berg, Wan-Yen Lo, et al. Segment any-thing. In Proceedings of the IEEE/CVF International Con-ference on Computer Vision, pages 40154026, 2023. 1, 5",
  "Arnab Kumar Mondal, Pratheeksha Nair, and Kaleem Sid-diqi. Group equivariant deep reinforcement learning. arXivpreprint arXiv:2007.03437, 2020. 1": "Arnab Kumar Mondal, Vineet Jain, Kaleem Siddiqi, andSiamak Ravanbakhsh. Eqr: Equivariant representations fordata-efficient reinforcement learning. In International Con-ference on Machine Learning, pages 1590815926. PMLR,2022. 1 Arnab Kumar Mondal, Siba Smarak Panigrahi, Oumar Kaba,Sai Rajeswar Mudumba, and Siamak Ravanbakhsh. Equiv-ariant adaptation of large pretrained models. In Advancesin Neural Information Processing Systems, pages 5029350309. Curran Associates, Inc., 2023. 1, 3, 4, 5, 6 Omri Puny, Matan Atzmon, Heli Ben-Hamu, Ishan Misra,Aditya Grover, Edward J Smith, and Yaron Lipman. Frameaveraging for invariant and equivariant network design.arXiv preprint arXiv:2110.03336, 2021. 1, 2, 4 Kristof Schutt, Oliver Unke, and Michael Gastegger. Equiv-ariant message passing for the prediction of tensorial prop-erties and molecular spectra. In International Conference onMachine Learning, pages 93779388. PMLR, 2021. 1 Elise Van der Pol, Daniel Worrall, Herke van Hoof, FransOliehoek, and Max Welling. Mdp homomorphic networks:Group symmetries in reinforcement learning.Advancesin Neural Information Processing Systems, 33:41994210,2020. 1",
  "Maurice Weiler and Gabriele Cesa. General e (2)-equivariantsteerable cnns. Advances in neural information processingsystems, 32, 2019. 1, 6": "Daniel E Worrall, Stephan J Garbin, Daniyar Turmukham-betov, and Gabriel J Brostow. Harmonic networks: Deeptranslation and rotation equivariance. In Proceedings of theIEEE conference on computer vision and pattern recogni-tion, pages 50285037, 2017. 1 Hai Wu, Chenglu Wen, Wei Li, Xin Li, Ruigang Yang,and Cheng Wang.Transformation-equivariant 3d objectdetection for autonomous driving.In Proceedings of theAAAI Conference on Artificial Intelligence, pages 27952802, 2023. 1"
}