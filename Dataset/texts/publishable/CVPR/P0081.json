{
  "Abstract": "This technical report presents the implementation detailsof 2nd winning for CVPR24 UG2+ WeatherProof DatasetChallenge. This challenge aims at semantic segmentationof images degraded by various degrees of weather from allaround the world. We addressed this problem by introduc-ing a pre-trained large-scale vision foundation model: In-ternImage, and trained it using images with different lev-els of noise. Besides, we did not use additional datasetsin the training procedure and utilized dense-CRF as post-processing in the final testing procedure. As a result, weachieved 2nd place in the challenge with 45.1 mIOU andfewer submissions than the other winners.",
  ". Baseline": "We utilized InternImage-H of which detector isMask2Former in our experiment, serving as our baseline.Considering the unique characteristics of the WeatherProofdataset, we first compared the results of training on cleanimages and testing on degraded images versus both train-ing and testing on degraded images.Differing from theconclusion in , we found that both strategies yieldednearly mIOU values. We believe that the disappearance ofperformance differences stems from InternImages trainingapproach for experimentation. Additionally, we also triedInternImage-XL, of which performance was significant in-ferior to InternImage-H, and ultimately abandoned it.",
  "*These authors contributed equally to this work": "for joint learning. Specifically, we employ DA-Clip asour denoising network to perform dehazing, deraining, anddesnowing tasks on each input degraded image, thereby en-abling the model to leverage these diverse datasets and re-fine its understanding of visual patterns. This componentaims to enable the model to utilize these images with vary-ing levels of noise (clean, partially denoised, and noisy) toincrease generalization ability and prevent overfitting. It isworth noting that DA-Clip is employed only for data aug-mentation purposes and we do not integrate the network intoour inference procedure.",
  ". Postprocessing": "We used the model trained with different data combina-tions among clean, degraded, and denoised images to pre-dict the result. We observed significant fluctuation in accu-racy across various models for distinct categories, highlight-ing the need for category-specific optimization and evalua-tion strategies. To leverage the strengths of individual mod-els, we integrated the prediction results of different versionsthrough a voting strategy. As a result, mlOU has signifi-cantly improved as shown in Tab. 1. We utilized dense-CRF as the post-processingmethod. Dense-CRF can combine the relationship betweenall pixels in the original image and process the segmenta-tion results obtained by our trained model model, optimizethe rough and uncertain labels in the classified image, cor-rect the fragmented misclassified areas, and obtain more de-tailed and smoother segmentation boundaries. As shownin Tab. 1, the dense connection at the pixel level greatlyimproves the accuracy of segmentation and labeling whileresults after dense-CRF are more accurate. Moreover, weutilized morphological transformations to eliminate isolatedpoints in the segmentation results, enhancing edge connec-tivity, shown in Tab. 1."
}