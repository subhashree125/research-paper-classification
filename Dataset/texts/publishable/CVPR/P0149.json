{
  "Abstract": "Since NFTs and large generative models (such asDALLE2 and Stable Diffusion) have been publicly avail-able, artists have seen their jobs threatened and stolen.While artists depend on sharing their art on online plat-forms such as Deviantart, Pixiv, and Artstation, manyslowed down sharing their work or downright removed theirpast work therein, especially if these platforms fail to pro-vide certain guarantees regarding the copyright of their up-loaded work.Text-to-image (T2I) generative models aretrained using human-produced content to better guide thestyle and themes they can produce. Still, if the trend con-tinues where data found online is generated by a machineinstead of a human, this will have vast repercussions in cul-ture. Inspired by recent work in generative models, we wishto tell a cautionary tale and ask what will happen to thevisual arts if generative models continue on the path to be(eventually) trained solely on generated content.",
  "Mario Vargas Llosa, 2012": "Recent advancements in generative models have yieldedimpressive results for generating high-resolution images. Inparticular interest are diffusion models and their applica-tions in the field of the visual arts with tools such as DALL-E , Stable Diffusion , and Midjourney . How-ever, these models are not created in a vacuum: they aredata-hungry algorithms trained on large-scale datasets, typ-ically scraped from the internet, such as LAION and higher quality subsets such as LAION-Aesthetics .",
  "*: Equal contribution": "Although not all models are transparent regarding the train-ing data they have used, they are nonetheless dependent ondata that can be found online.However, the use and creation of these datasets carriedwith them the bias inherent to the authors background andlocation, reflected in the generative models trained to mimicthem. This is reflected in the distribution of artistic styles,artists, and periods present in it. Generative models carrythe risk of amplifying these biases, which has been exten-sively documented . This also conveys a natural reactionby the artistic community: they respond either by changingwhere they share their newer artwork (conditioned on theresponse by the platforms they used to post before )to downright poisoning the data well . We extend thesepoints in .Concretely, there currently is a problem of data varietywithin said datasets. This is important representation-wise,as smaller communities (both societal and artistic) are yet tobe accurately represented in these large-scale datasets and,in turn, generative models. While fine-tuning the modelscould help tackle this issue (e.g. by training a LoRA ),this is only the case for open-source models, and if there isavailable data to train with. We propose this will be harderand harder as time goes on, and as more experienced artistsisolate themselves from data crawlers to protect their liveli-hood.While the majority of recent work has focused on theimpact that these models will have on artists , we alsoask how artists will naturally react and the impact that thebattle for data will have on culture. Indeed, art and designare not always meant to be consumed. In the Mesoameri-can culture, huipils are rectangular fabrics worn by women,their first use dating from before the Spanish conquest. Thecolors and patterns in them can not only identify whichgroup or community the wearer belongs to, but they canalso depict personal and symbolical meaning , and are nostrangers to being stolen or culturally appropriated .These techniques carry the risk of disappearing if the cur-rent wave of pixel-based generative models supplant thenon-2D techniques required to create them.",
  "arXiv:2406.08739v1 [cs.CY] 30 Apr 2024": "As a final piece in our argument, to unlock the true po-tential of modern-day AI models, there is the usual proposalto eventually replace real data with generated or syntheticdata to (re)train the models. We recall, then, that genera-tive models trained on their outputs run the risk of failingto keep up with social change . Likewise, they exhibitknowledge collapse, where the synthetic data tend towardsan average . At its most basic example, data gener-ated with Stable Diffusion has errors in both perspective andshadow generation of objects in the scene . These errorsare easily noticed and fixed by experienced artists, but train-ing on outputs with wrong geometric properties only exac-erbates and hence entrenches these types of issues in futuremodels, as well as in new artists who learn from them.There is a solution to this: Alemohammad et al. elo-quently poses the training setup for recursively training gen-erative models with synthetic data as an autophagus (self-consuming) loop. They coin the term Model AutophagyDisorder (MAD) and note that generative models go MADif they are trained solely on synthetic data or if they aretrained with a fixed real dataset augmented with a smallersynthetic dataset. The only solution for the generative mod-els to not go MAD is to have available, for each generationof models, fresh data, which can be complemented withsynthetic data. We hypothesize that we will run out of freshreal data in the future for the coming generative models(which are nowadays being trained with outputs of previ-ous generations of generative models), in particular lookingat the rate at which new data is being uploaded to some ofthe most popular art sharing platforms.While the following is a work in progress, it raises alarm-ing questions regarding the cultural end-point that thesemodels might lead us to. If they fail to faithfully generatea particular style, exacerbate the bias associated with par-ticular groups of people, or even fail to correctly positionobjects with the correct perspective, these will have seriousconsequences for incoming artists who are looking to usethese tools for learning new skills. Lastly, if the models spitout an average art style, which will it be, or is it alreadydominating the global culture?",
  ". Data Collection": "In this section, we study the number of uploads to thepopular digital art platforms Artstation1, DeviantArt2, andDanbooru3. To collect data from Artstation and DeviantArt,we use the public open-source tool gallery-dl andrandomly sample 250 artists with more than 2000 followers.Please note that for this work, we work with a subsample ofthe community due to the request limit for the web pages. For Danbooru, we use the Danbooru2023 dataset ,which is a public anime image dataset with roughly 5 mil-lion images contributed and annotated by the community.Analyzing the number of artists uploads, we are look-ing to check trends in their behavior based on two criticalevents: NFTs and the release of generative models to thepublic (in particular of Stable Diffusion and DALLE-2).a presents the upload from January 2021 until Oc-tober 2023: Artstation shows a reduction in the number ofuploads of artists while DeviantArt depicts an increasingtrend.Figures 1b and 1c present a different analysis utilizingthe same dataset as depicted in a. Here, we catego-rize artists into seniors (those who uploaded works beforeJanuary 2022) and juniors (those who only uploaded afterJanuary 2022). To ensure a balanced representation of up-loads among users, we limit the count to a maximum of onepublication per month per user.Our objective of dividing the number of uploads betweenseniors and juniors is to examine the response to genera-tive models that established artists have, in contrast to newartists who are already familiar with or utilize them. In Fig-ures 1b and 1c, we observe a declining trend in senioruploads and a rising trend in junior uploads. shows results for the Danbooru site with the seniorand junior splits. As in DeviantArt uploads, we have anincreasing trend, but when we divide the artists into seniorsand Juniors, a decreasing trend appears for seniors.",
  ". Upload reduction": "If we examine users uploads in Figs. 1a and 2, a cleartrend is not evident. However, there is an apparent reduc-tion in uploads when we focus on seniors. We believe thispattern is a consequence of the NFT explosion and fur-ther rooted by the appearance of generative model appli-cations, as artists are concerned that their art will be used orstolen without their explicit consent. While a morethorough statistical analysis should be performed here to re-move confounding factors, the effect is the same, with se-nior artists decreasing their uploads to these easily accessi-ble sites, giving more room to machine-generated data.",
  ". Technology Adoption": "Figures 1c and 2 illustrate that junior artists are con-tributing to the increasing upload trend. We believe thistrend is emerging because junior artists are incorporatinggenerative models into their creative processes, either byuploading solely generated images or by collaborating ina loop with a generative model (utilizing tools like AdobeFirefly ), permitting them to produce work at a muchmore rapid pace. 2021-01 2021-02 2021-03 2021-04 2021-05 2021-06 2021-07 2021-08 2021-09 2021-10 2021-11 2021-12 2022-01 2022-02 2022-03 2022-04 2022-05 2022-06 2022-07 2022-08 2022-09 2022-10 2022-11 2022-12 2023-01 2023-02 2023-03 2023-04 2023-05 2023-06 2023-07 2023-08 2023-09 2023-10",
  ". Data poisoning": "While regulation can play a key factor in securing thedata of artists as suggested in , it appears that the law isnot moving fast enough. Furthermore, digital art websitesare releasing AI tools for their platforms, and artists whouse generative models are already winning art contests .Some artists have found that data poisoning is the only wayto protect their work. Methods such as watermarking (plac-ing large logos over images) or tools like Glaze andNightshade are becoming more common each day, butthese are not permanent solutions.",
  ". Future Work": "As mentioned in Sec. 3, we have worked with a subsam-ple of the whole artistic community, mainly due to compu-tational resources. We wish to extend this work to includea wider range of artistic profiles and do a fine-grained anal-ysis not only due to the number of followers (although itis a good filter in non-social media websites). At the sametime, we must be careful when attributing the choices artists take to specific events or tool releases, for which a thor-ough statistical analysis is warranted. Lastly, an analysis ofwhat each group of artists (seniors and juniors) is uploadingshould help clarify if specific themes or styles are affectedmore by these tools, or if these effects are general.",
  "Safinah Ali and Cynthia Breazeal.Studying artist sen-timents around ai-generated artwork.arXiv preprintarXiv:2311.13725, 2023. 2": "Emily M. Bender, Timnit Gebru, Angelina McMillan-Major,and Shmargaret Shmitchell.On the dangers of stochasticparrots: Can language models be too big? In Proceedings ofthe 2021 ACM Conference on Fairness, Accountability, andTransparency, FAccT 21, page 610623, New York, NY,USA, 2021. Association for Computing Machinery. 2 Tianwei Chen, Yusuke Hirota, Mayu Otani, Noa Garca, andYuta Nakashima.Would deep generative models amplifybias in future models? In Proceedings of the IEEE/CVF con-ference on computer vision and pattern recognition, 2024. 1",
  "Mike Fahrmann.gallery-dl. Accessed on 08.04.2024. 2": "Edward J Hu, yelong shen, Phillip Wallis, Zeyuan Allen-Zhu, Yuanzhi Li, Shean Wang, Lu Wang, and Weizhu Chen.LoRA: Low-rank adaptation of large language models. In In-ternational Conference on Learning Representations, 2022.1 Harry H. Jiang, Lauren Brown, Jessica Cheng, Mehtab Khan,Abhishek Gupta, Deja Workman, Alex Hanna, JohnathanFlowers, and Timnit Gebru. Ai art and its impact on artists.In Proceedings of the 2023 AAAI/ACM Conference on AI,Ethics, and Society, AIES 23, page 363374, New York,NY, USA, 2023. Association for Computing Machinery. 1, 3",
  "Aditya Ramesh, Mikhail Pavlov, Gabriel Goh, Scott Gray,Chelsea Voss, Alec Radford, Mark Chen, and Ilya Sutskever.Zero-shot text-to-image generation. CoRR, abs/2102.12092,2021. 1": "Robin Rombach, Andreas Blattmann, Dominik Lorenz,Patrick Esser, and Bjorn Ommer.High-resolution imagesynthesis with latent diffusion models.In Proceedings ofthe IEEE/CVF conference on computer vision and patternrecognition, pages 1068410695, 2022. 1 Ayush Sarkar, Hanlin Mai, Amitabh Mahapatra, SvetlanaLazebnik, David Forsyth, and Anand Bhattad.Shadowsdont lie and lines cant bend!generative models dontknow projective geometry...for now.In Proceedings ofthe IEEE/CVF conference on computer vision and patternrecognition, 2024. 2",
  "Christoph Schuhmann.LAION-Aesthetics. Aug 2022.Accessed on 04.08.2024. 1": "Christoph Schuhmann, Romain Beaumont, Richard Vencu,Cade W Gordon, Ross Wightman, Mehdi Cherti, TheoCoombes, Aarush Katta, Clayton Mullis, Mitchell Worts-man, Patrick Schramowski, Srivatsa R Kundurthy, Katherine Crowson, Ludwig Schmidt, Robert Kaczmarczyk, and JeniaJitsev.LAION-5b: An open large-scale dataset for train-ing next generation image-text models. In Thirty-sixth Con-ference on Neural Information Processing Systems Datasetsand Benchmarks Track, 2022. 1 Christoph Schuhmann, Richard Vencu, Romain Beaumont,Robert Kaczmarczyk, Clayton Mullis, Aarush Katta, TheoCoombes, Jenia Jitsev, and Aran Komatsuzaki.LAION-400M: open dataset of clip-filtered 400 million image-textpairs. CoRR, abs/2111.02114, 2021. 1 Shawn Shan, Jenna Cryan, Emily Wenger, Haitao Zheng,Rana Hanocka, and Ben Y Zhao. Glaze: Protecting artistsfrom style mimicry by {Text-to-Image} models.In 32ndUSENIX Security Symposium (USENIX Security 23), pages21872204, 2023. 3"
}