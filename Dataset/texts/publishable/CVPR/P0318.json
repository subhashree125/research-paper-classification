{
  "Abstract": "We introduce a new family of minimal problems for re-construction from multiple views. Our primary focus is anovel approach to autocalibration, a long-standing prob-lem in computer vision.Traditional approaches to thisproblem, such as those based on Kruppas equations orthe modulus constraint, rely explicitly on the knowledge ofmultiple fundamental matrices or a projective reconstruc-tion. In contrast, we consider a novel formulation involv-ing constraints on image points, the unknown depths of3D points, and a partially specified calibration matrix K.For 2 and 3 views, we present a comprehensive taxonomyof minimal autocalibration problems obtained by relaxingsome of these constraints. These problems are organizedinto classes according to the number of views and any as-sumed prior knowledge of K. Within each class, we deter-mine problems with the fewestor a relatively small num-ber ofsolutions. From this zoo of problems, we devisethree practical solvers. Experiments with synthetic and realdata and interfacing our solvers with COLMAP demon-strate that we achieve superior accuracy compared to state-of-the-art calibration methods.The code is available at",
  ". Contribution": "This paper presents a comprehensive characterization oftwo- and three-view minimal autocalibration problems inthe case of a perspective camera with constant intrinsics.We introduce practical and efficient solvers for minimal au-tocalibration by introducing a novel formulation that ex-tends the minimal Euclidean reconstruction problem of fourpoints in three calibrated views to the uncalibratedcase. Our approach jointly estimates camera intrinsics, en-coded in the calibration matrix K, and unknown 3D point depths, and seamlessly integrates any partial knowledgeof the camera intrinsics.This gives rise to a variety oftwo- and three-view minimal autocalibration problems, forwhich we provide a complete taxonomy in Tab. 1. We de-velop a general theory of minimal relaxations to addresscases where our formulation leads to an over-constrainedproblem. These minimal relaxations of our depth formu-lation can be completely enumerated, and each instance ofa specific autocalibration problem can be solved offline byapplying numerical homotopy continuation (HC) methodsto one such relaxation. Crucially, the offline analysis withHC methods also enables us to identify the most efficientlysolvable minimal relaxations.Our practical contributions include implementing a nu-merical solver for full camera calibration, i.e., calibration ofall 5 unknown parameters of a perspective camera. We alsoconsider common assumptionsnamely, zero-skew andsquare pixelsand design fast solvers for specialized prob-lems with a partially calibrated camera. These solvers canbe fast enough for many online calibration applications, andcan also bootstrap solutions using RANSAC-based frame-works with high accuracy in offline calibration settings.Among the strengths of our approach, we avoid well-knowndegeneracies of Kruppas equations and recover K di-rectly instead of relying on estimates of the dual imageof the absolute conic (DIAC), which may not be positive-semidefinite. Experiments show that our solvers outperformexisting autocalibration methods in terms of accuracy inboth synthetic and real image sequences despite increasedruntime. Interfacing our solvers with COLMAP furtherhighlights the applicability of our approach.",
  "arXiv:2405.05605v1 [cs.CV] 9 May 2024": "Thus, our contribution is two-fold: i) theoretically, weprovide a complete taxonomy of minimal autocalibrationproblems in 2 or 3 views; ii) practically, our novel solversoutperform classical autocalibration approaches in accuracyand are robust against degenerate configurations arising invery practical calibration scenarios when a camera revolvesaround an object, which is a substantial problem for allmethods based on solving Kruppas equations .",
  ". Problem formulation": "We recall here some standard constraints on the calibrationmatrix K R33 that involve the images of N 3D pointsfrom M different positions, as depicted in . Wewant to estimate the entries of K: focal lengths f and g,principal point (u, v) and camera skew s. Image points areexpressed in homogeneous coordinates xip R2{1}, i.e.,3 1 vectors whose third entries equal 1.In Eq. (1) below and throughout the paper, the letteri [M] := {1, . . . M} indexes a single image, whilep [N] := {1, . . . , N} indexes a point, Ri R33 denotes a rotation matrix, Ci R3 is a camera center,Xp R3 is a 3D point, and ip R is the depth of thep-th point in the i-th camera .Different flavors of the autocalibration problem existin practice, depending on the available partial knowledgeabout the intrinsics in K. For instance, common assump-tions are that the camera has square pixels (f = g) or zeroskew (s = 0). In general, we assume that there are L linearequations f1(K) = . . . = fL(K) = 0 which encode anypartial knowledge of intrinsics in K. For instance, if ourcamera has square pixels and no skew, then we may takef1(K) = s, f2(K) = f g.Thus, assuming no noise in image points, a solution Kmust satisfy the following conditions:",
  ". Previous work": "We focus on the classical scenario where K is constantacross views. For work exploring the non-constant case,e.g., derive minimal conditions on the camera in-trinsics for autocalibration. We also note that many workshave addressed special cases of autocalibration, such as fo-cal length estimation .General methods fall roughly into two classes. Direct methods use the so-called rigidity constraint en-coded in fundamental matrices. In theory, K can be re-covered from the knowledge of three fundamental matricesresulting from three different camera motions . Di-rect methods exploit this observation and re-cover the intrinsic parameters by solving Kruppas equa-tions . Methods used to solve these equations varyconsiderably. In , instead of considering a complete,over-constrained system of 6 equations in 5 unknowns, aconsensus solution is obtained by solving all 6 of the squaresubsystems using a HC method.This work has severalparallels to oursnamely, its use of HC solvers and thefact that these square subsystems are minimal relaxationsin the sense of . The main difference is that theirunknowns are the entries of the DIAC. In , the over-constrained system of Kruppas equations is solved with anonlinear least squares technique; here, good initializationis needed to obtain an accurate estimate. We note that sim-plified polynomial systems have been derived by exploitingadditional assumptions on K . Not all direct methodsuse Kruppas equationsin , a method analogous to theF4 method for computing Grobner bases is devised for com-puting the DIAC. As our experiments illustrate, a commonweakness of such direct approaches is that they do not en-force positive-semidefiniteness of the DIAC and hence failwith larger noise that makes the estimated DIAC indefinite.Certain camera motions give rise to degenerate autocal-ibration problems [20, Ch. 19], , and additional degen-eracies may exist for particular methods. For example, themethod of also falls short when the optical centers of allcameras lie on a sphere and the optical axes pass through thecenter of the sphere . Although our approach employs arelaxation procedure analogous to this work, it does not suf-fer from the same degeneracy. Another limitation of directmethods is that they neglect non-trivial polynomial iden-tities that tuples of compatible fundamental matrices mustsatisfy .Stratified methods assume that a projective reconstruc-tion is known and stratify the problem into Affine and Eu-clidean stages. An affine reconstruction can be obtained byestimating the plane-at-infinity (PaI); from this, the assump-tion of constant K allows its entries to be easily retrieved.This idea was pioneered in , where chirality constraintsare used to estimate the location of the PaI. The PaI can alsobe located via the so-called modulus constraints. Specifi-cally, in , this resulted in a system of three quartic poly-nomials on the coefficient of the PaI.Rather than using the PaI, the work directly encodesall metric information in terms of the absolute quadric,which, once retrieved, allows the intrinsic parameters to beretrieved by Cholesky factorization.In general, stratified approaches are more robust to noisethan direct ones but require good initialization of the PaI. Thus, some works focus on optimality guaranteesexploiting a branch-and-bound framework. Similarly, samples the bounded space of intrinsic parameters to esti-mate the PaI robustly. Interestingly, presents a branch-and-bound paradigm to solve direct and stratified autocali-bration based on sampling algebraic varieties.",
  ". Depth equations and removing symmetries": "In this work, we propose to eliminate camera extrinsicsfrom (1) and use constraints involving the calibration ma-trix K and depths ip. By working with these constraints,we are able to avoid potential issues arising from fundamen-tal matrix compatibility. This approach is also well-suitedfor constructing new minimal problems.The main geometric constraint we use is that the Eu-clidean distance Xp Xq between any two 3D pointsXp and Xq is the same whether these points are recon-structed from the i-th or the j-th camera, for any i, j [M]as depicted in . Expressing each 3D point as Xp =ipK1xip, this amounts to the vanishing of the function",
  ". Specifying a minimal autocalibration problem": "Instead of requiring that (4) holds for all i, j [M], p, q [N], we consider minimal problems which only require thata subset of these constraints hold. Hence, we will be in asituation similar to partial visibility as in .To specify a minimal problem, we consider:(1) Priors on K: In practical situations, we often eitherpossess or lack knowledge of intrinsics. When we knowsome intrinsics, we can transform images to normalize theirknown values to standard ones: f = 1, g = 1, u = 0, v =0, s = 0. Subsequently, we solve for the unknown trans-formed intrinsics and then recover their original values2.We represent the knowledge of intrinsics as a 5-tuple of un-knowns fguvs. If any intrinsic is known, we replace itsunknown with its normalized value. For instance, f1uv0indicates that f, u, v are unknown, while g = 1, s = 0 areknown. In the interesting scenario of a camera with squarepixels, ffuvs encodes that f and g are unknown but equal.(2) Number of cameras M: For a given 5-tuple fguvs,we will see that the minimum number of cameras needed toobtain a minimal problem is either 2 or 3. Hence, we willinvestigate problems for only 2 and 3 cameras.(3) Number of points N: For each five-tuple of intrin-sics and M cameras, we will consider the least number Nof points such that there is a set g of constraints in (4) pro-viding a minimal problem.(4) Constraints g: For each triplet (fguvs, M, N), weenumerate all possible subsets of constraints (4) which leadto different minimal problems.Each four-tuple (fguvs, M, N, g) specifies a candidateminimal problem . lists the 80 groups accordingto (fguvs, M, N). For each group, we list the number #gof equivalence classes of constraints leading to a minimalproblem and a range of3 numbers of solutions in .",
  ". Relaxation, Enumeration, and Solving": "We now give a more precise description of the taxonomy ofminimal autocalibration problems presented in andthe tools needed to obtain it.For each pair (fguvs, M), we will determine whethercamera calibration is possible and, if so, the minimum num-ber N of points such that there is a subset g of depth equa-tions (4) providing a minimal problem. First, we determinethe number of parameters among fguvs that can be esti-mated from N 3D points seen in M images captured bythe same camera with constant K. Then, we determine theminimum number N of 3D points required to solve the per-spective autocalibration problem given a pair (fguvs, M). 2See SM 7 for more details on the normalization and recovering thecorresponding non-normalized values.3For fguvs, we checked roughly 20% of the 3313 cases. It is conceiv-able, but unlikely, that problems with fewer solutions remain unchecked.",
  ". 80 groups of minimal autocalibration problems for M {2, 3} views. For each triplet (fguvs, M, N) we list: i) L, the": "number of linear constraints on K, ii) the minimum and maximum solution count in C, iii) #subsys. = (M1)(N2)M+NL+4, the number ofsquare subsystems of (4), iv) #g, the number of inequivalent minimal relaxations. The numbers #g and Min # sol. are most important,as they measure the number of minimal relaxations and the complexity of solving them. Solution counts refer to unknown depths and theparameters of in (2)(4). The two counts are only conjectural extrema, due to the prohibitive time needed to check all cases. Infeasible cases.In general, for K unknown and non-constant, the reconstruction of N 3D points from M viewscan be obtained only up to a projective transformation H,which has 15 degrees of freedom. Additional constraints onH may allow us to assume H is a similarity transformationwith 7 degrees of freedom. For M = 2 views, the assump-tion that K is constant puts 5 constraints on H. Thus, weneed L 15 7 5 = 3 linear constraints on K to obtaina Euclidean reconstruction and hence recover the full K.To determine the minimum number N of 3D points re-quired to solve the perspective camera autocalibration prob-lem as a function of a pair (fguvs, M), we must ensurethat the number of degrees of freedom in image measure-ments is at least the number of degrees of freedom in theunknown scene and cameras. For this purpose, the full for-mulation (1) is preferable to the equations we actually usefor solving, namely (4). This is because we can rigorouslyemploy a count similar to that given in : we shouldassume there are at least",
  "L 3N + 6M 2 2MN(5)": "independent linear constraints on K in order to solve theautocalibration problem up to a finite number of candidatesolutions. Noting also the trivial upper bound L 5, thisexplains the values of L appearing in . The infea-sible cases where M = 2 and L 2 have already beenaddressed above. The remaining cases are accounted for by (5) and the rows of Tab. 1. This table indicates thatat least one minimal relaxation for the potentially feasiblechoices of (M, N, L) actually exists. To properly interpretthe table, we must now formalize what we mean when wesay a subsystem g of equations determines a minimal relax-ation of the autocalibration problem (1).",
  ". Minimal problems and minimal relaxations": "Many estimation problems in vision can be expressed us-ing the language of algebraic geometry. In general, we mayconsider an irreducible algebraic variety X, whose pointsconsist of problem-solution pairs (p, x) Cm Cn satis-fying some set of equations depending polynomially on pand x. Our task is to estimate the solution x Cn givensome problem instance p Cm, meaning (p, x) X.More specifically, image points p = (xip)i[M],p[N]specify an instance of an autocalibration problem.Wewant to estimate the unknowns x defining in (2) and the(suitably normalized) depths (ip). Thus m = 2MN andn = (5 L) + MN 1. If we define the variety X tobe the image of a rational map (much like the joint cameramap of ), the condition that X is irreducible holds.Let denote the map which projects X into the space ofproblem instances Cm, i.e.,",
  ". Minimal relaxations V(g1), V(g2), w/ X = V(g1, g2),g1(p1, p2, x) = x2 p1, and g2(p1, p2, x) = p2x2 1": "be identified with the fiber 1(p). Following , we saythat defines a minimal problem if the following hold:1. The problem is balancedthat is, dim X = m.2. Almost every problem instance in Cm has a solutionequivalently, the image of the map is dense in Cm.In practice, we check that a problem is minimal usingsome system of equations g(p, x) = 0 defining X locally,via the following rank conditions at a point (p0, x0) X:",
  "(p0,x0) = n.(7)": "Some of the cases appearing in are already minimalproblems. These are precisely the rows where both sidesof (5) are equal. In general, dim X = 3N + 6M 2 L.When the inequality (5) is strict, we expect the autocali-bration problem (1) to be overconstrained in the sense thata generic problem in Cm does not have an exact solution.To deal with overconstrained problems, consider a sys-tem g consisting of n polynomial or rational functions van-ishing on Xthat is, X V(g) where",
  "V(g) = {(p, x) Cm+n | g(p, x) is defined and equals 0}": "( denotes the Zariski closure [6, 4.4].) If the rank condi-tions (7) hold at a generic point (p0, x0) X, we say thatg determines a minimal relaxation of . illustratesthis definition on a simple example (see SM 9 for details).In general, an overconstrained problem can have differ-ent minimal relaxations. In the next section, we obtain acombinatorial classification of all minimal relaxations ob-tained from subsets of the depth constraints (4), groupingminimal relaxations into natural equivalence classes.",
  ". Enumerating Minimal Relaxations": "We now explain how to obtain minimal relaxations of au-tocalibration problems using the depth equations (4). Thecombinatorial structure of minimal relaxations obtained byremoving a subset of equations (4) is neatly encoded by a4-coloring: that is, a function c:[N]2 {B, R, G, W},which assigns one of four colors to all pairs of 3D points.In standard graph-theoretic terminology, these are exactlythe improper edge 4-colorings of the complete graph KN.",
  "{d1,2,pq | c(pq) {B, R}} {d1,3,pq | c(pq) {B, G}}. (8)": "We say two 4-colorings c1, c2 :[N]2 {B, R, G, W} areisomorphic if there exist permutations : [N] [N] and : {B, R, G, W} {B, R, G, W} such that (W) = W,(B) = B, and c2 = c1. The minimal relaxations de-termined by isomorphic 4-colorings are equivalent, since corresponds to swapping views 2 and 3, and correspondsto relabeling world points. shows an example.Determining isomorphism classes of 4-colorings, i.e.,and thus equivalence classes of minimal relaxations g, of-fers us a key practical advantage. Given the large number of4-colorings, exceeding 5 million for fguvs, computing thesolution count for all associated problems is computation-ally prohibitive. Consequently, we opt to consider only onerepresentative per isomorphism class when computing solu-tions offline with HC. This approach facilitates the creationof the comprehensive taxonomy outlined in Tab. 1. We de-termine a unique representative c in each isomorphism classusing the line graph L(c), as detailed in 10 of the SM.",
  ". Solving with homotopy continuation": "For any system g(p, x) = 0 encoding a minimal relaxationof an autocalibration problem, we construct minimal solversusing a standard online/offline approach based on numericalHC methods. In the offline stage, we construct a syntheticsolution (p0, x0) X Xg by fabricating a 3D scene. Ifg arises from a balanced problem, we check that it is mini-mal via the rank conditions (7), and use monodromy heuris-tics to recover (with high probability) all remaining solu-tions in 1(p0, x0) for the synthetic parameters p0 Cm.As postprocessing, we use parameter homotopy [45, Ch. 8]with equations g to track all solutions to new parameter val-ues p1 Cm whose coordinates are random complex num-bers. Finally, in the online stage, the solver receives a newproblem instance p2 Rm as input, and uses parameterhomotopy to track all solutions for p1 to those for p2.",
  ". Experiments": "We evaluate the performance of our proposed minimalsolvers on simulated and real image sequences, with a fo-cus on three of the most practical cases: i) ffuv0, an un-calibrated camera with square pixel aspect ratio and zero-skew, ii) fguv0, an uncalibrated camera with zero-skew,iii) fguvs, a fully uncalibrated camera. First, we assessthe theoretical correctness of our proposed solvers and theirresilience to noise in simulated image sequences (Sec. 4.1).Then, in Sec. 4.2, we perform experiments on real imagesequences and compare the results attained by our solverswith several competing autocalibration methods. Finally,we demonstrate that integrating our solvers into the recon-struction pipeline COLMAP improves autocalibra-tion and reconstruction on real image sequences (Sec. 4.3). Competitors. We compare our solvers to the HC-basedmethod for solving Kruppas equations in .As de-scribed in Sec. 1.3, we remark that, in this method, eachsubsystem of 5 / 6 Kruppas equations may also be consid-ered minimal relaxations in the sense of . More-over, whether we consider these equations as rational orpolynomial functions matters. In the latter case, consideredin , it was correctly observed that these equations hadthe expected number of 25 = 32 solutions over C. However,for 14 of these solutions, denominators appearing in the ra-tional form of Kruppas equations become undefined. Thus,only 18 HC paths must be tracked to find a valid solution.To address the imbalance between our method (basedon triples of image points) and Kruppa (based on triplesof fundamental matrices), we consider three variants ofKruppa that estimate these fundamental matrices differ-ently. The first variant, Kruppa-8, estimates fundamentalmatrices using the non-minimal 8-point algorithm. The sec-ond, Kruppa-7, estimates fundamental matrices using theminimal 7-point algorithm. The third, Kruppa-6, imple-ments a minimal solver for projective reconstruction from6 points in 3 views , from which a set of compatiblefundamental matrices can be determined. Kruppa-6 is theclosest to our fguvs solver, which also requires six points.For all three variants, we normalize the input as in .In real-world experiments, we also compare our solverswith the state-of-the-art camera autocalibration approachpresented in . This method uses semidefinite program-ming and a Branch-and-Bound (BnB) scheme to maximizeconsensus among polynomials and solve the calibrationproblem with either the Kruppa equations or the mod-ulus constraint . We refer to these variants as KruppaBnB and Modulus BnB, respectively. Implementation. We implement our solvers in Julia usingthe package HomotopyContinuation , with C++and Python bindings. SM 11.1 reports the minimal relax-ations used by these solvers. All experiments were con-",
  ". Synthetic Experiments": "We evaluate the performance of our ffuv0, fguv0, andfguvs solvers in synthetic images under varying noise lev-els applied to the generated pixel coordinates. Our evalu-ation involves comparing the Kruppa-8 and Kruppa-6methods. Results for Kruppa-7 are inferior in accuracy andare presented in SM 11.4. Simulations. In each simulated scene, we generate 100 ran-domly distributed 3D points within the unit sphere. We sim-ulate three camera displacements, with the first located 2world units from the spheres center along the y-axis. Theother two cameras are translated by 0.5 units along allaxes relative to the first camera, enforcing a minimum L2-norm of 0.1 for translation vectors. Camera motion is con-strained to ensure all views capture the scene, with randomrotations obtained by uniformly sampling angles in the 45degrees range along all axes. Simulated points are projectedonto 640 480 images, discarding any points not observedin all views.Noise is introduced by adding zero-meanGaussian displacements to pixel coordinates with standarddeviation in the range in increments of 0.2. Foreach noise level , we conduct 1000 independent tests forall methods. Our solvers, Kruppa-6 and Kruppa-8 areevaluated with intrinsics: f = 330, g = 310, u = 300,v = 250, s = 10.",
  "fgt + ggt": "We report the reprojection error Re computed using the es-timated intrinsics K and camera poses4 {Ri, Ci}Mi=1. Notethat Re is not reported for Kruppa-8 due to the inconsistentreconstruction across the three views obtained from funda-mental matrices computed using the 8-point algorithm. Thisinconsistency leads to significantly higher errors, makingany comparison unfair. Instead, we report Re for Kruppa-6, where a metric reconstruction consistent across the threeviews is obtained by upgrading the projective cameras usingthe estimated intrinsic parameters. Results. In , boxes represent the interquartile range oferrors in estimated camera parameters and mean reprojec-tion error. Errors generally increase with higher noise levels. Across most experiments, ffuv0 and fguv0, despite as-suming prior camera knowledge not aligned to the syntheticcamera parameters, match or surpass Kruppa methods, par-ticularly in focal length, with principal point results gener-ally within a 5% deviation from Kruppa methods. fguvs,",
  "SM 11.2 explains how camera poses are derived from projectivedepths and SM 11.3 gives the formula for the reprojection error": "0.00.20.40.60.81.0 - stddev of noise [px] 0.0 0.5 1.0 1.5 f Error ffuv0fguv0fguvsKruppa-6Kruppa-8 0.00.20.40.60.81.0 - stddev of noise [px] 0.0 0.5 1.0 1.5 uv Error 0.00.20.40.60.81.0 - stddev of noise [px] 0.0 0.1 0.2 0.3 0.4 0.5 0.6 0.7 s Error 0.00.20.40.60.81.0 - stddev of noise [px] Reprojection Error [px] 0.00.20.40.60.81.0 - stddev of noise [px] Failure Rate (%) . Autocalibration Evaluation on Synthetic Images. Solver accuracy is assessed under varying levels of zero-mean Gaussiannoise (denoted by on the x-axis) applied to pixel coordinates. Mean reprojection error and relative errors in focal lengths fg, principalpoint uv, and skew s are reported. For error measures, boxes represent the interquartile range of error distribution. The right-most plotillustrates the failure rate as a percentage, with ffuv0, fguv0, and fguvs excluded due to no failures. similar to Kruppas in not assuming prior camera knowl-edge, attains comparable performance to Kruppa methodsin focal length and principal point estimation but underper-forms in skew estimation, especially for > 0.4. Across allnoise levels, all our solvers outperform Kruppa-6 in repro-jection error, which jointly assesses the accuracy in intrinsiccamera parameters and camera pose estimation.Kruppa methods recover K via the Cholesky decompo-sition of the DIAC . In the presence of noise, may notbe positive-semidefinite. This leads to autocalibration fail-ure, making the estimation of K unfeasible. Failure ratesrange from 4% to 13% for Kruppa-6 and from 3% to 6%for Kruppa-8, as reported in -right. In principle, oursolvers could also fail at higher noise levels. However, wedid not encounter these issues in our synthetic experiments. Remark 1. In SM 11.4, we confirm the theoretical correct-ness of ffuv0 and fguv0 by showing that zero error is at-tained in the noiseless case when each solvers prior cameraknowledge matches the synthetic camera parameters. Remark 2. All Kruppa-based methods present a degener-acy arising from a singularity in the Kruppa equations whenthe optical centers of cameras lie on a sphere, and their op-tical axes intersect at the spheres center . As discussedin SM 11.4, we reproduce such conditions and confirm thatour method is unaffected by the Kruppa degeneracy.",
  ". Evaluation on Real Datasets": "We assess autocalibration accuracy on the calibratedFountain-P11 and Herz-Jesu-P8 datasets. The ffuv0,fguv0, and fguvs solvers are embedded in a conventionalMSAC-framework . At each iteration of the MSAC,we evaluate the recovered camera intrinsics and extrinsicsin terms of their induced reprojection error weighted bythe Huber loss. We set a limit of 200 iterations. Imagepoints are obtained by extracting and matching SIFT keypoints across image triplets.We compare our solvers with Kruppa-8 , Kruppa-7, and Kruppa-6 embedded in MSAC, mirroring our solver setup.For Kruppa-8 and Kruppa-7, we compute cam-era poses by decomposing the pairwise essential matricesE = KFK = [t]R, where F is the fundamental matrix.Then, we compute the reprojection error pairwise, averag-ing it across all image pairs. Kruppa-6 yields a consistentmetric reconstruction across the three views, allowing di-rect computation of the reprojection error by projecting the3D points using the recovered camera matrices. Finally, ourevaluation includes Kruppa BnB and Modulus BnB ,representing state-of-the-art autocalibration methods. Metrics. We assess calibration accuracy using fg, uv,s in Eq. (9). We also report reprojection errors Re, com-puted using estimated camera intrinsics and extrinsics, andRegt, computed using the estimated intrinsics, but groundtruth camera poses. R and C represent the angular errors5",
  "in degrees for estimated camera rotations and centers, re-spectively. Errors are averaged across all image sequences": "Results. Tab. 2 reports the results of our evaluation. Con-cerning full camera calibration, our fguvs solver sets thebenchmark for most calibration metrics, except for uvin Fountain-P11, where it is the second-best method afterKruppa BnB. fguvs also outperforms Kruppa-6 at camerapose estimation. Remarkably, fguvs excels in focal lengthestimation, achieving 3.6 times lower fg in Fountain-P11compared to the second-best Kruppa BnB.The solvers ffuv0 and fguv0 outperform fguvsacross various metrics, with ffuv0 emerging as the top-performing method overall. This demonstrates the advan-tages of integrating partial knowledge of K into our solvers,especially given that the zero-skew assumption and squarepixel aspect ratio very often hold in practice.Our solvers runtimes depend on the number of pathstracked by HC, i.e., by the solution counts in C. We referto Tab. 1 to optimize speed and select g with the lowest so-lution count. We report the median runtime per iteration:fguv0 1.78 s/iter (2313 paths), fguvs 2.15 s/iter (2985paths), ffuv0 9.21 s/iter (16188 paths). Our solvers are",
  "MethodfguvsRegtReRCfguvsRegtReRC": "Kruppa-60.1370.1840.02219.5632.8917.0615.5790.0980.1120.01414.5651.1122.1251.902Kruppa-70.2490.2040.04028.197---0.1220.1140.04015.252---Kruppa-8 0.2600.1730.02928.466---0.1400.1150.02213.606---Kruppa BnB 0.1270.0580.0149.231---0.0780.0960.01821.023---Modulus BnB 0.1620.0710.01610.540---0.0970.1020.01922.641--- ffuv00.0170.029-4.4350.4490.6230.6640.0170.044-8.0820.6720.6640.656fguv00.0280.050-8.5800.5540.9701.1830.0290.063-11.1280.6801.2951.540fguvs0.0350.0640.0089.7691.0751.2741.4280.0410.0580.01311.3480.9891.0851.139 . Autocalibration Evaluation on Real Datasets. Mean relative errors in the focal lengths fg, principal point uv, and skews are reported. Reprojection error is computed in two variations: i) Regt, using estimated K and ground truth camera poses, ii) Re,using estimated K and estimated camera poses (when applicable). R and C are the angular errors in estimated camera rotations andtranslations, respectively. Lower values indicate better performance for all metrics.",
  ". Comparing errors and numbers of registered points for autocalibration strategies in COLMAP (Sec. 4.3.)": "multithreaded, with quasi-linear scaling in the number ofCPU cores. Comparatively, the median runtime for Kruppa-6, Kruppa-7, and Kruppa-8 is 0.71 s/iter, with 6 18 = 108solutions paths overall. For Kruppa, we observe that per-formance scaling is not linear, but we attribute this to thesmall number of solutions and overhead when running theJulia HC solver. Despite their faster runtimes, these meth-ods exhibit inferior accuracy and higher failure rates, asillustrated in . Setting a strict threshold of 0.02 onfg, the fguvs solver takes an average of 4.21 minutes onFountain-P11 and Herz-Jesu-P8, whereas Kruppa methodsare, on average, only 27% faster. The BnB methods arethe fastest overall, by 62% compared to ours, yet they stillprovide inferior accuracy.",
  ". Autocalibration in COLMAP": "We integrate our autocalibration solvers into COLMAP to initialize the camera intrinsics before 3Dreconstruction. The evaluation is conducted on five tripletsof images from the Fountain-P11 (2 sequences), Rathaus (1 sequence), and KITTI-Depth (2 sequences)datasets. We report results for fguv0. Additional detailsabout other solvers and datasets may be found in SM 11.WeconsidertwostrategiesforinitializingK:COLMAPguess uses the default COLMAP guess based onimage size, and COLMAPfguv0 employs the fguv0 solver.These variants exclude the K from Bundle Adjustment(BA). We also evaluate results obtained using BA on K (+K-BA). COLMAPgt + BA involves starting from groundtruth camera parameters and applying BA and is providedas an oracle for performance. Tab. 3 reports results for each strategy. COLMAPfguv0estimates K better than COLMAPguess in most cases andyields accurate reconstructions, even without refining K.When applying BA, the gap between COLMAPfguv0 andCOLMAPguessnarrows,particularly in Fountain-P11,where many keypoints are available.In Rathaus, theprincipal point is displaced from the image center. The finalcalibration accuracy is improved by using the estimate ofK from fguv0. In KITTI-Depth, BA often struggles due tofewer matches. In this scenario, using BA results in a 9.58xdegradation in uv, but only a 1.15x improvement in fgcompared to the calibration by fguv0. This indicates thatin challenging scenes, our estimates of K are more reliablethan those obtained solely through refinement with BA.",
  ". Conclusion": "Motivated by the quest for a complete understandingof the autocalibration of a camera with constant K, wepresented a new complete analysis of minimal autocalibra-tion problems and their implementations, improving thestate-of-the-art. Acknowledgements: TD was supported by NSF DMS-2103310. APDC and LM were supported by FAIR (Fu-ture Artificial Intelligence Research) project funded bythe NextGenerationEU program within the PNRR-PE-AIscheme (M4C2, Investment 1.3, Line on Artificial In-telligence) and by GEOPRIDE ID: 2022245ZYB, CUP:D53D23008370001, (PRIN 2022 M4.C2.1.1 Investment).EU H2020 No. 871245 SPRING project supported TP. Sylvain Bougnoux. From projective to Euclidean space un-der any practical situation, a criticism of self-calibration. InProceedings of the Sixth International Conference on Com-puter Vision (ICCV-98), Bombay, India, January 4-7, 1998,pages 790798. IEEE Computer Society, 1998. 2",
  "Paul Breiding and Sascha Timme.HomotopyContinua-tion.jl: A Package for Homotopy Continuation in Julia. In In-ternational Congress on Mathematical Software, pages 458465. Springer, 2018. 6": "Martin Bratelund and Felix Rydell. Compatibility of funda-mental matrices for complete viewing graphs. In Proceed-ings of the IEEE/CVF International Conference on Com-puter Vision (ICCV), pages 33283336, October 2023. 2 Manmohan Krishna Chandraker, Sameer Agarwal, David J.Kriegman, and Serge J. Belongie. Globally optimal affineand metric upgrades in stratified autocalibration. In IEEE11th International Conference on Computer Vision, ICCV2007, Rio de Janeiro, Brazil, October 14-20, 2007, pages18. IEEE Computer Society, 2007. 3",
  "Timothy Duff, Cvetelina Hill, Anders Jensen, Kisun Lee,Anton Leykin, and Jeff Sommars. Solving polynomial sys-tems via homotopy continuation and monodromy. IMA Jour-nal of Numerical Analysis, 2018. 5": "Timothy Duff, Kathlen Kohn, Anton Leykin, and TomasPajdla.PLMP - Point-line Minimal Problems in Com-plete Multi-view Visibility. In 2019 IEEE/CVF InternationalConference on Computer Vision, ICCV 2019, Seoul, Korea(South), October 27 - November 2, 2019, pages 16751684.IEEE, 2019. 3, 4, 5 Timothy Duff, Kathlen Kohn, Anton Leykin, and Tomas Pa-jdla. PL1P - point-line minimal problems under partial vis-ibility in three views.In Andrea Vedaldi, Horst Bischof,Thomas Brox, and Jan-Michael Frahm, editors, ComputerVision - ECCV 2020 - 16th European Conference, Glasgow,UK, August 23-28, 2020, Proceedings, Part XXVI, volume12371 of Lecture Notes in Computer Science, pages 175192. Springer, 2020. 3 Timothy Duff, Viktor Korotynskiy, Tomas Pajdla, and Mar-garet H. Regan. Galois/monodromy groups for decomposingminimal problems in 3D reconstruction. SIAM Journal onApplied Algebra and Geometry, 2022. 4 Olivier D. Faugeras, Quang-Tuan Luong, and Stephen J.Maybank. Camera self-calibration: Theory and experiments.In Giulio Sandini, editor, Computer Vision - ECCV92,Second European Conference on Computer Vision, SantaMargherita Ligure, Italy, May 19-22, 1992, Proceedings,volume 588 of Lecture Notes in Computer Science, pages321334. Springer, 1992. 1, 2",
  "Andrea Fusiello, Arrigo Benedetti, Michela Farenzena, andAlessandro Busti. Globally convergent autocalibration usinginterval analysis. IEEE Trans. Pattern Anal. Mach. Intell.,26(12):16331638, 2004. 3": "Guillermo Gallego, Elias Mueggler, and Peter F. Sturm.Translation of Zur Ermittlung eines Objektes aus zweiPerspektiven mit innerer Orientierung by Erwin Kruppa(1913). CoRR, abs/1801.01454, 2018. 1, 2 Amnon Geifman, Yoni Kasten, Meirav Galun, and RonenBasri.Averaging essential and fundamental matrices incollinear camera settings. In 2020 IEEE/CVF Conferenceon Computer Vision and Pattern Recognition, CVPR 2020,Seattle, WA, USA, June 13-19, 2020, pages 60206029.Computer Vision Foundation / IEEE, 2020. 2 Andreas Geiger, Philip Lenz, and Raquel Urtasun. Are weready for autonomous driving? the KITTI vision benchmarksuite. In 2012 IEEE conference on computer vision and pat-tern recognition, pages 33543361. IEEE, 2012. 8 Riccardo Gherardi and Andrea Fusiello. Practical autocal-ibration. In Computer VisionECCV 2010: 11th EuropeanConference on Computer Vision, Heraklion, Crete, Greece,September 5-11, 2010, Proceedings, Part I 11, pages 790801. Springer, 2010. 3",
  "Richard I Hartley.Euclidean reconstruction from uncali-brated views.In Joint European-US workshop on appli-cations of invariance in computer vision, pages 235256.Springer, 1993. 2": "Richard I. Hartley. In Defence of the 8-Point Algorithm. InProcedings of the Fifth International Conference on Com-puter Vision (ICCV 95), Massachusetts Institute of Technol-ogy, Cambridge, Massachusetts, USA, June 20-23, 1995,pages 10641070. IEEE Computer Society, 1995. 6 Anders Heyden and Kalle Astrom. Flexible calibration: Min-imal cases for auto-calibration. In Proceedings of the Inter-national Conference on Computer Vision, Kerkyra, Corfu,Greece, September 20-25, 1999, pages 350355. IEEE Com-puter Society, 1999. 1, 2 Petr Hruby, Timothy Duff, Anton Leykin, and Tomas Pajdla.Learning to solve hard minimal problems.In IEEE/CVFConference on Computer Vision and Pattern Recognition,CVPR 2022, New Orleans, LA, USA, June 18-24, 2022,pages 55225532. IEEE, 2022. 1, 4",
  "Quang-Tuan Luong, Rachid Deriche, Olivier Faugeras, andTheodore Papadopoulo.On determining the fundamentalmatrix: Analysis of different methods and experimental re-sults. PhD thesis, Inria, 1993. 6": "Yi Ma, Rene Vidal, Jana Kosecka, and Shankar Sastry.Kruppa equation revisited: Its renormalization and degener-acy. In David Vernon, editor, Computer Vision - ECCV 2000,6th European Conference on Computer Vision, Dublin, Ire-land, June 26 - July 1, 2000, Proceedings, Part II, volume1843 of Lecture Notes in Computer Science, pages 561577.Springer, 2000. 2",
  "Henrik Stewenius, David Nister, Fredrik Kahl, and Fred-erik Schaffalitzky.A minimal solution for relative posewith unknown focal length. Image and Vision Computing,26(7):871877, 2008. 2": "Christoph Strecha, Wolfgang Von Hansen, Luc Van Gool,Pascal Fua, and Ulrich Thoennessen. On benchmarking cam-era calibration and multi-view stereo for high resolution im-agery. In 2008 IEEE conference on computer vision and pat-tern recognition, pages 18. Ieee, 2008. 1, 7, 8 Peter Sturm. Critical motion sequences for monocular self-calibration and uncalibrated Euclidean reconstruction.InProceedings of IEEE Computer Society Conference on Com-puter Vision and Pattern Recognition, pages 11001105.IEEE, 1997. 1",
  ". Problem formulation additional details": "Although the depth equations (4) described in Sec. 2.1 arethe main constraints used in our approach, we wish to pointout that they are by no means the only polynomial equa-tions involving depths ip, image points xip and the cali-bration matrix K that must be satisfied by an exact solution((ip), K). In the language of Sec. 11.1: the depth con-straints determine the variety of problem-solution pairs Xlocally but not globally.We may derive additional constraints as follows: us-ing (1), for any view pair 1 i < j M and four distinctworld points with indices 1 p1, . . . , p4 4, we have",
  "(9)": "This follows from our assumption that K, and hence alsodet(K), is constant: compare with (19) below.It is important to remember that, when solving with aminimal relaxation, the equations that are not enforced mayor may not continue to hold for noisy data. As an exampleof this, we may consider the unique class of minimal prob-lems in for the scenario 11000 with M = 3 fullycalibrated views. As illustrated in , we may drop ex-actly one depth equation for the view pair (i, j) = (1, 2) toobtain a representative for the equivalence class of minimalrelaxations. This relaxation has the effect that (9) no longermust hold for this view pair. Indeed, we find that this equa-tion is typically violated in the case of noisy data and forall 639 non-synthetic solutions when solving a generic syn-thetic problem instance. On the other hand, for the view pair(i, j) = (1, 3), the equation (9) holds even for non-syntheticsolutions or noisy data.We may rephrase the observations of the previous para-graph in the geometric language developed in Sec. 3 (seealso SM 9 below.) From this point of view, (9) is valid forboth view pairs on the incidence variety X associated withthe overconstrained problem but only generally valid for theview pair (1, 3) on the incidence variety V(g) associatedto the minimal relaxation. The local nature of parameterhomotopy ensures, for this problem, that we do not needto explicitly enforce the constraint (9) for one view pair.However, any attempt to simultaneously enforce these con-straints for both view pairs and the chosen depth constraintswill invariably lead us back to an overconstrained problem.",
  ". Known Principal Point": "Normalizing known principal point coordinates involves re-versing the translation transformation in (12) to center im-age coordinates at the origin.When u is known, normalizing the known value of u tou = 0 involves subtracting u from xip,1, the first coordinateof xip. Notably, no additional substitution of other intrinsicparameters is necessary. Similarly, when v is known, nor-malizing the known value of v to v = 0 may be achieved bysubtracting v from the second coordinate xip,2.",
  ". Known Skew": "Knowing the camera skew, when it is nonzero, impliesknowledge of the shear transformation embedded in K, andthat is applied to the normalized image coordinates.The shear transformation in (12) is determined by s =sg. Thus, when s is known, the skew-induced shear in im-age coordinates may be removed by transforming xip,1, thefirst coordinate of xip, as follows:",
  ",(16)": "by substituting b = (xip,2 v)/g. Notably, no additionalsubstitution of other intrinsic parameters is necessary.Our previous autocalibration specification can be ex-tended to minimal problems in the notable case where ageneric s is known and nonzero, but v is unknown. Refer-ring to 2.1, s appears explicitly in our parametrization of, as defined in (2). Thus, referring to Sec. 3.3, given anysystem g(p, x) = 0 encoding a minimal relaxation of anautocalibration problem in which s is known and nonzeroand v is unknown, we may treat s p, as a parameter ofthe system. Then, we may construct minimal solvers using astandard online/offline parameter homotopy approach suchas described in .3. Referring to Sec. 2.2, we indi-cate known nonzero s in the 5-tuple of unknowns fguvsby setting s = s. This notation is used in Tab. 5 to reportthe solution count in C computed during the offline stage for",
  "ff0vs27324ff0vs3534482": ". Non-zero Skew Autocalibration Problems. Specifica-tion of 20 notable minimal problems in 2 and 3 views (M) wheres =sg is known and non-zero and v is unknown.For eachtriplet (fguvs, M, N), we report L, number of linear constraintson K, and the minimum, taken over all minimal relaxations, so-lution count in C for generic input (including s.) As in ,counts refer to unknown depths and the parameters of in (2)(4).",
  "p": "In this example, we understand the vector (p1, p2) C2 torepresent a problem instance and x C one of its solutions.The set of exactly solvable problems is the image of the pro-jection map : X C2, namely the hyperbola p1p2 = 1drawn in black. Then, the problem is overconstrained sincea generic problem instance will not lie on the hyperbola andwill have no solutions. This manifests in the failure of therank conditions (7) : for a generic problem-solution pair(p1, p2, x) X, we have",
  "= 1 (p1, p2, x) X\\{(0, 0, 0)}": "Two minimal relaxations can be obtained by dropping oneof the two equations defining X. These relaxations corre-spond to the surfaces X1 = Xx2p1 and X2 = Xp2x21,drawn above in red and blue, respectively. The union ofthese two surfaces is not a minimal relaxation, since the Ja-cobian of (x2 p1)(p2x2 1) vanishes identically alongX. For the rational function g(p1, p2, x) = 1/x2 p2, notethat we also have V(g) = Xg = X2. If we instead con-sider g = (p2x2 1)x, the variety V(g) has two irre-ducible components, given by V(x) and the minimal relax-ation Xg = Xg = X1. Finally, let us observe that in thisexample, the degrees of the minimal relaxations Xi C2 are both 2. This need not be the case in general: if we con-sider instead of X the space curve V(x2 p1, x3 p3), wesee there are minimal relaxations of degree 2 or 3. This ex-ample also shows that relaxations can increase the numberof solutions, even for an exactly solvable problem instance. We wish to point out that our notion of a minimal relax-ation occurs implicitly in previous works studyingconstraints involving calibrated trifocal tensors and point-line minimal problems with partial visibility. Both works",
  ". 4-colorings of the minimal relaxations used in our implementation of solvers for the ffuv0, fguv0 and fguvs problems": "consider a minimal relaxation of the overconstrained prob-lem of estimating four points in three calibrated views. Inthis minimal relaxation, one point in one view is replaced bya line. Both of these works formulate the overconstrainedproblem of estimating four points in three calibrated viewsand consider the Scranton relaxation of this problem inwhich only a single point-point-line constraint on the tri-focal tensor is enforced for one of the point triplets. Thisproblem has 272 solutions. As observed in , Scran-ton can also be formulated in terms of depths and an ex-tra slack variable. The depth-formulated Scranton is nota minimal relaxation in the sense defined above. In thiswork, instead of adding variables, we drop equations. Wemay simply drop the equation d1,2,12(, ; x) = 0 in thefully calibrated case. This gives a minimal relaxation with640 = 2320 solutions and a two-way symmetry that sends2,p 2,p and fixes all other variables. We remark thata further systematic study of symmetries appearing in ourzoo of autocalibration problems, along the lines conductedin , would be very interesting. However, this study liesbeyond the scope of this investigation.HC methods for solving Kruppas equations may also beunderstood in our framework of minimal relaxations. ForKruppa, solutions x are the entries of 33 matrix represent-ing the DIAC, and triples of fundamental matrices specifyparameters p. Moreover, for a synthetic problem-solutionpair (p0, x0) X used to initialize monodromy, certaincompatability conditions on fundamental matrices encodedin p0 must be satisfied [20, 15.4].",
  ". Enumerating minimal problems additional details": "Returning to the enumeration problem described in in Sec-tion 3, we now discuss line graphs, a standard graph-theoretic construction. The utility of this construction isthat the isomorphism class of a 4-coloring is completely de-termined by an associated line graph L(c) after equippingit with a suitable vertex labeling. The vertices of the line graph L(c) are simply the non-white edges, and an edge be-tween two vertices of L(c) exists whenever the two non-white edges share a vertex between 1 and N. We labeleach vertex pq L(c) by its color c(pq). Two isomorphicgraphs have isomorphic line graphs; conversely, a classicaltheorem of Whitney implies that two connected graphswhose line graphs are isomorphic are themselves isomor-phic, with the sole exception of the complete graph K3 andthe claw graph K1,3 (see eg. [18, Theorem 8.3].) AlthoughL(K3) = L(K1,3), the original graphs K3 and K1,3 havedifferent numbers of edges.From this, it easily followsthat we can decide whether or not two 4-colorings c1, c2are isomorphic: form the two graphs L(c1) and L(c2), de-cide if there exists an isomorphism that respects their la-belings, and repeat this same procedure for the two graphsL(c1), L(c2 ), where swaps green and red edges.We implement software based on the NetworkX library, and the VF2++ algorithm to compute the isomor-phism classes for all minimal problems listed in Tab. 1. Thecode is implemented in Python and is publicly available atgithub.com/andreadalcin/MinimalPerspectiveAutocalibration.Tab. 6 provides a visualization of one represen-tative 4-coloring for each isomorphism class for thefguv0, fgu00, fg000 minimal problems in M = 3 views.The isomorphism classes for fguvs are too many to be vi-sualized in Tab. 6. Still, as part of our software, we providea visualization tool and instruction to visualize equivalenceclasses for fguvs.",
  "fg00035317624176241762438843884388438841969637": ". Visualization of Isomorphism Classes. Visualization of one representative 4-coloring for each isomorphism class of minimalrelaxations for autocalibration problems fguv0, fgu00, fg000 in M = 3 views. For each triplet (fguvs, M, N), we report one repre-sentative 4-coloring for each isomorphism class and its associated solution count in C. Solution counts refer to unknown depths and theparameters of in (2)(4). test described in Sec. 4.1. We noted that reprojection er-ror fluctuations among different relaxations with identicalsolution counts are always below 1%, suggesting compa-rable numerical performance between different minimal re-laxations with the same solution count. For the purposes of this work, we list the specific min-imal relaxations used to implement the solvers ffuv0,fguv0, and fguvs, which are used throughout our exper-iments. Specifically, for each implemented solver, we spec-ify the depth constraints that are omitted from the chosensystem of equations g:",
  ". Computing Camera Rotations and Centersfrom Projective Depths": "We discuss the conversion of projective depths into camerarotations and centers. Referring to Sec. 4, our autocalibra-tion formulation allows us to perform an Euclidean recon-struction. However, we obtain the projective depths associ-ated with image points rather than camera roto-translationsand 3D point coordinates. However, recovering camera ro-tations and centers is straightforward, assuming that, with-out loss of generality, the i = 1 camera is at R1 = I andC1 = 0. Initially, we compute 3D points, denoted as Xip, for eachcamera i [M], using Xip = ipK1xip. Throughoutthis section, we express Xip in Cartesian coordinates, i.e.,Xip R3. Centering all 3D points by subtracting X11 (thepoint p = 1 seen by the i = 1 camera), we extract transla-tion components ti = Xi1 for i [2, . . . , M]. Subtractingthe translation component from the 3D points seen by thei-th view ( Xip = Xip ti), we compute the rotation com- 0.00.20.40.60.81.0 - stddev of noise [px] 0.0 0.5 1.0 1.5 f Error ffuv0fguv0fguvsKruppa-7Kruppa-8 0.00.20.40.60.81.0 - stddev of noise [px] 0.0 0.5 1.0 1.5 uv Error 0.00.20.40.60.81.0 - stddev of noise [px] 0.0 0.1 0.2 0.3 0.4 0.5 0.6 0.7 s Error 0.00.20.40.60.81.0 - stddev of noise [px] Failure Rate (%) . Kruppa-7 Evaluation on Synthetic Images. Solver accuracy is assessed under varying levels of zero-mean Gaussian noise(denoted by on the x-axis) applied to pixel coordinates. Mean reprojection error and relative errors in focal lengths fg, principalpoint uv, and skew s are reported. For error measures, boxes represent the interquartile range of error distribution. The right-mostplot illustrates the failure rate as a percentage, with fguv0, ffuvs, and fguvs excluded due to no failures. Results are averaged for 1000synthetic image sequences. Synthetic camera parameters are set to mirror the configuration described in Sec. 4.1. Results are averagedover 1000 synthetic image sequences. 0.00.20.40.60.81.0 - stddev of noise [px] 0.0 0.5 1.0 1.5 f Error ffuv0fguv0fguvsKruppa-6Kruppa-8 0.00.20.40.60.81.0 - stddev of noise [px] 0.0 0.5 1.0 1.5 uv Error 0.00.20.40.60.81.0 - stddev of noise [px] 0.0 0.1 0.2 0.3 0.4 0.5 0.6 s Error 0.00.20.40.60.81.0 - stddev of noise [px] Reprojection Error [px] 0.00.20.40.60.81.0 - stddev of noise [px] Failure Rate (%) . Autocalibration Evaluation on Synthetic Images with Specialized Intrinsics. Solver accuracy is assessed under varyinglevels of zero-mean Gaussian noise (denoted by on the x-axis) applied to pixel coordinates. Mean reprojection error and relative errorsin focal lengths fg, principal point uv, and skew s are reported. For error measures, boxes represent the interquartile range of errordistribution. The right-most plot illustrates the failure rate as a percentage, with ffuv0, fguv0, and fguvs excluded due to no failures.Synthetic camera parameters vary across solvers to match their prior camera knowledge. For fguv0 we set s = 0, and for ffuv0 we setf = g = 330. Results are averaged over 1000 synthetic image sequences.",
  "Ci = i2K1xi2 Ri12K1x12 ,i [2, . . . , M]": "(20)As discussed in Sec. 6, a given relaxation might removeconstraints that enforce the validity of the recovered rota-tion matrices, i.e., Ri SO(3). If Ri is not an orthogonalmatrix, we compute an SVD Ri = USV and the closestorthogonal matrix Ri = UV (with respect to either theFrobenius or spectral norm.)This approach is consistently applied in our experimen-tal validation, and we provide Julia code for the conversionfrom projective depth to camera roto-translation.",
  ",(26)": "where Ri, Ci denote the estimated rotation and camera cen-ter, respectively, of the i-th camera with respect to the i = 1camera, for which R1 = I and C1 = . Ri, Ci de-note the ground truth camera rotation and center, respec-tively. The values of R and C are expressed in degrees forall experiments.",
  "We provide additional details regarding our synthetic eval-uation, referring to Sec. 4.1 of the main paper": "Kruppa-7. presents a comparative analysis of theresults achieved by the Kruppa-7 solver in relation to theffuv0, fguv0, fguvs, and Kruppa-8 solvers.Resultsreveal that Kruppa-7 exhibits inferior accuracy in focallength estimation (fg) compared to Kruppa-8, especiallyat lower noise levels 0.6. Nonetheless, principal pointand skew estimation accuracy are comparable to Kruppa-8.Finally, the failure rates of Kruppa-7 match or surpass thoseof Kruppa-8 across all noise levels .",
  "Evaluation with Specialized Intrinsics. presentsthe results of our ffuv0 and fguv0 solvers evaluated on": "synthetic scenes generated using varying camera parame-ters that depend on the prior camera knowledge assumed byeach solver. For fguvs, Kruppa-6, and Kruppa-8, whichdo not assume any camera knowledge, synthetic camera pa-rameters are set to f = 330, g = 310, u = 300, v = 250,and s = 10. For fguv0, which assumes zero-skew, we sets = 0. Finally, for ffuv0, which assumes squared pixelaspect ratio, we set f = g = 330.The results affirm that ffuv0 and fguv0 excel in focallength estimation and achieve comparable performance tothe other solvers in principal point estimation. As expected,errors fg and uv are reduced due to the synthetic cam-era parameters perfectly matching the prior knowledge as-sumed by each of these solvers.This evaluation also focuses on evaluating the theoreti-cal correctness of our solvers, i.e., verifying that zero erroris achieved in the noiseless case. Both ffuv0 and fguv0 at-tain zero errors when = 0 and their assumed prior knowl-edge matches the ground truth camera parameters, confirm-ing their theoretical correctness. As expected, our solversdo not exhibit any failures in this synthetic evaluation. Degeneracies.As discussed in Sec. 4.1, our proposedautocalibration solvers are unaffected by the degeneracyof Kruppa-based methods arising from a singularity in theKruppa equations when the optical centers of cameras lieon a sphere, and their optical axes intersect at the spherescenter . To verify that our solvers overcome this sub-stantial problem, we synthetically reproduce the aforemen-tioned degeneracy condition and assess calibration on thesegenerated image sequences. We generate 1000 syntheticscenes that exhibit the degeneracy condition of Kruppa andverify our ffuv0, fguv0 and fguvs can successfully per-form autocalibration in all cases, exhibiting zero-error in thenoiseless case and a failure rate of 0%.Furthermore, referring to Sec. 3.3, we confirm the well-posed nature of our autocalibration problem by verifyingthat the Jacobian of the given relaxed system g(p, x) = 0is full-rank at the synthetic solution (p0, x0). Additionally,we observe that the least singular value of the Jacobian of the system never falls below 104 in our testing. This indi-cates the robust numerical stability of our solvers.We implement code to generate degenerate imagesequences for Kruppa equations and verify that oursolvers are unaffected by this problem.The codeis implemented in Julia and is publicly available atgithub.com/andreadalcin/MinimalPerspectiveAutocalibration.",
  "Finally, we provide further details on evaluating theCOLMAP integration of our autocalibration solvers": "Datasets. For Fountain-P11 , we consider the 0-2-4and 0-3-6 image triplets. Rathaus includes a single cal-ibrated image triplet. For KITTI-Depth , we extract im-age triplets from the 2011-09-26-drive-0005 sequence. Results. Tab. 7 provides an extended view of Tab. 3, in-cluding the results achieved by COLMAPffuv0 the ini-tialization strategy of K based on the ffuv0 solver. Thisvariant excludes K from Bundle Adjustment (BA), and wepresent results achieved by COLMAPffuv0 when BA is ap-plied to K.The calibration accuracy of COLMAPffuv0surpasses that of COLMAPfguv0 marginally, particularly interms of principal point estimation (uv).When Bun-dle Adjustment is extended to K, the disparity in per-formance diminishes and becomes negligible, especiallyin the Fountain-P11 and Rathaus datasets.Notably, inKITTI-Depth, extending Bundle Adjustment to K showsthat COLMAPffuv0 achieves a slightly lower accuracy infocal lengths (fg) but exhibits improved accuracy in theprincipal point (uv). Discussion. In the context of integrating our autocalibra-tion solvers into COLMAP, both ffuv0 and fguv0 demon-strate similar accuracy in both fg and uv, particularlywhen extending Bundle Adjustment to K. Consequently,opting for fguv0 as an initialization strategy in COLMAPis preferable for many practical applications. This prefer-ence is attributed to the faster processing speed of fguv0over ffuv0 (1.78 s/iter compared to 9.21 s/iter) and its sup-port for cameras without square pixel aspect ratio."
}