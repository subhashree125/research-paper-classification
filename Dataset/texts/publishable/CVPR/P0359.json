{
  "Abstract": "Consistency learning is a central strategy to tackle unla-beled data in semi-supervised medical image segmentation(SSMIS), which enforces the model to produce consistentpredictions under the perturbation. However, most currentapproaches solely focus on utilizing a specific single per-turbation, which can only cope with limited cases, whileemploying multiple perturbations simultaneously is hard toguarantee the quality of consistency learning. In this paper,we propose an Adaptive Bidirectional Displacement (ABD)approach to solve the above challenge. Specifically, we firstdesign a bidirectional patch displacement based on reliableprediction confidence for unlabeled data to generate newsamples, which can effectively suppress uncontrollable re-gions and still retain the influence of input perturbations.Meanwhile, to enforce the model to learn the potentiallyuncontrollable content, a bidirectional displacement oper-ation with inverse confidence is proposed for the labeledimages, which generates samples with more unreliable in-formation to facilitate model learning. Extensive experi-ments show that ABD achieves new state-of-the-art perfor-mances for SSMIS, significantly improving different base-lines. Source code is available at",
  ". Introduction": "Medical image segmentation derives from computer tomog-raphy (CT) or magnetic resonance imaging (MRI), which iscrucial for various clinical applications . Obtaininga large medical dataset with precise annotation to train seg-mentation models is challenging, as reliable annotations canonly be provided by experts, which constrains the develop-ment of medical image segmentation algorithms and posessubstantial challenges for further research and implementa-tion . To mitigate the burden of manual annotationand address these challenges, semi-supervised medical im-",
  "ABD": ". Illustration of prediction results. (a) Using only networkperturbation; (b) Combining network perturbation with input per-turbation; (c) Incorporating ABD on top of the two perturbations.Using a single perturbation has limitations while using multipleperturbations makes it uncontrollable. Introducing ABD greatlyalleviates the issue and allows the model to perform significantlybetter. The white dashed boxes highlight the regions with wrongpredictions. age segmentation (SSMIS) is emerging asa practical approach to encourage segmentation models tolearn from readily available unlabelled data in conjunctionwith limited labeled examples.Most recent approaches in SSMIS employ consistencylearning to make the decision boundary ofthe learned model located within the low-density bound-ary .By ensuring consistent features or predictionsunder diverse perturbations, this strategy becomes one ofthe most effective solutions for learning from unlabelleddata. According to the perturbation differences, consistencylearning approaches can be divided into three categories:1) Input perturbations, which mainly produce different in-puts to the same model , e.g., weak and strongdata augmentation for the given image. 2) Feature pertur-bations , which mainly include feature noise,feature dropout, and context masking. 3) Network perturba-tions , which focus on using different network archi-",
  "arXiv:2405.00378v1 [cs.CV] 1 May 2024": "tectures for the same input. To ensure the stability of con-sistency learning, most previous approaches solely utilize one of the above perturbations, restricting theperformance of the consistency learning and leading to im-precise decision boundary since the specific single pertur-bation can only handle limited cases, as shown in (a). Utilizing mixed or multiple perturbations presents a di-rect solution to solve the above problem. However, onceadded multiple perturbations, the consistency learning pro-cess is easily out-of-control, leading to restricted learningquality. For example, Cross Pseudo Supervision (CPS) is a widely-used technique in consistency learning that pri-marily applies network perturbation to produce two dis-criminate predictions for further consistency learning. Ifwe directly add input perturbation by using weak and strongaugmentation to the input training data, consistency learn-ing will be ineffective. As shown in (b), when theoriginal input is replaced with weak and strong augmenta-tion inputs, the CPS model incorrectly classifies the back-ground as the foreground with consistency learning mech-anism, indicating decreased performance when mixed per-turbations are introduced. To tackle the aforementioned challenges, we proposeAdaptive Bidirectional Displacement (ABD) for SSMIS,as shown in (c). Specifically, for each unlabelled im-age, the input perturbation is firstly applied to produce apair of input images, e.g., weak augmentation image andstrong augmentation image. Then we generate two confi-dence matrices (confidence rank maps) based on the predic-tions from the above two perturbed images. The confidencematrix assesses the certainty of predicted pixels belongingto various categories, thereby reflecting the models reliabil-ity to different perturbations. Then, for any augmented im-age, its region with the lowest confidence rank is displacedwith the region from the other augmented image that hasthe most similar output distribution with highly confidentscores. We refer to this as an adaptive bidirectional dis-placement with reliable confidence (ABD-R). In this way,the newly generated image can remove the uncontrolled re-gion and obtain complementary and approximate semanticinformation from another augmented image, which ensuresconsistent predictions of the model across different pertur-bations. Meanwhile, to enforce the model to learn thosepotentially uncontrollable regions, we incorporate inverseconfidence for labeled data as an additional adaptive bidi-rectional displacement (ABD-I). For any labeled augmentedimage, the image regions with the highest confidence scoresare displaced with the regions from another augmented im-age having the lowest confidence scores. This operationwill strengthen the model to tackle uncontrollable regions.Combining these two strategies, our approach performs anovel input perturbation method, which can be directly ap-plied to existing consistency learning approaches. Exten-",
  "sive experiments show that ABD achieves new state-of-the-art (SOTA) performances for SSMIS, significantly improv-ing different baseline performances.We summarize our main contributions as follows:": "We observed that the combination of different perturba-tions leads to instability in consistency learning. To ad-dress this issue, we propose Adaptive Bidirectional Dis-placement to enable the generation of semantically com-plementary data by replacing model inadaptable regionswith credible regions, which assists the model in effec-tively correcting erroneous predictions and enhances thequality of consistency learning. To take full advantage of labeled data, we propose an en-hanced Adaptive Bidirectional Displacement that incor-porates inverse confidence for labeled data to enforce themodel to tackle those potentially uncontrollable regions. The proposed method can be easily plug-and-play, whichcan be embedded into different approaches and enhancetheir performance. Extensive experiments are conductedto validate the feasibility of the method, resulting in sig-nificant improvements compared to previous SOTA ap-proaches on different datasets.",
  ". Consistency Learning in Semi-SupervisedMedical Image Segmentation": "Consistency learning has been widely used in recent ap-proaches for SSMIS. It aims to improve the performance ofmodels by promoting consistent predictions for unlabeleddata under different perturbations. According to the per-turbation differences, consistency learning has three cate-gories: input perturbation, feature perturbation, and net-work perturbation. Input perturbation is achieved throughproducing different inputs. For instance, Huang et al. introduced cutout content loss and slice misalignment asperturbations in the input.In contrast, ST++ in-volved strong augmentation on unlabeled images and di-rectly utilizes the augmented samples for re-training. Pseu-doSeg was similar to FixMatch in leveragingpseudo-labels generated from weakly augmented images tosupervise the predictions of strongly augmented images.BCP encouraged the mixing of labeled and unlabeledimages on the input level, enabling unlabeled data to learncomprehensive and general semantic information from la-beled data in both directions. Meanwhile, feature pertur-bation and network perturbation are achieved by producingdifferent features or outputs for the same input. Specifically,for feature perturbation, Mismatch introduced morpho-logical feature perturbation, which is based on classic mor-phological operations. For network perturbation, CPS encouraged consistent predictions from different initializednetworks with an input image. Mean Teacher utilized",
  "usZ": ". Overview of our adaptive bidirectional displacement framework. (A) For the unlabeled data, one image is subjected to weak andstrong augmentations, resulting in two images that are separately input to two networks for cross-supervision. Then, based on the Auw, Zuw,Aus , and Zus , the patches in the images are bidirectionally displaced, resulting in the formation of new samples Xusw and Xuws. Thesenew samples are further fed into the networks for cross-supervision. (B) For the labeled images, they are also subjected to both weak andstrong augmentations, and their predictions are supervised by the labels. Afterward, based on the Alw and Als, inverse bidirectional patchdisplacement is performed on the images, resulting in the generation of new samples Xlsw and Xlws. Similarly, the labels undergothe same operation, leading to the creation of new labels Y lsw and Y lws. The new samples are then fed into the network, and theirpredictions are supervised by the new labels. Note that ABD-R and ABD-I are two parallel modules during training. the exponential moving average (EMA) technique to trans-fer semantic knowledge from the student network to theteacher network. However, existing methods only guaranteethe consistency of predictions under a single perturbation,which greatly limits the scalability of consistency learning.",
  ". Consistency Learning in Other Tasks": "Consistency learning is a major technique to tackleunlabeled data in semi-supervised learning. Several meth-ods are proposed with consistency learning in various do-mains, including image segmentation , domain gen-eralization , image classification , pre-trainlanguage model , etc. For image segmentation, Revisit-ing UniMatch proposed a unified approach using dual-stream perturbations for semi-supervised semantic segmen-tation by combining input and feature perturbations. Addi-tionally, ViewCo introduced text-to-view consistencymodeling, incorporating additional text to learn comprehen-sive segmentation masks. In domain generalization, Zhou etal. exploited the latent uncertainty information of theunlabeled samples to design an uncertainty-guided consis- tency loss. StyleMatch enforced prediction consistencybetween images from one domain and their style-transferredcounterparts. In image classification, SimMatch ap-plied consistency regularization on both the semantic leveland instance level to generate high-quality and reliable tar-gets.ICT introduced the interpolation consistencytraining which encourages the prediction at an interpolationof unlabeled points to be consistent with the interpolationof the predictions at those points. In addition, in the pre-train language model, GALAXY applied consistencyregularization on all data to minimize the bi-directional KLdivergence between model predictions.",
  ". Problem Setting": "In the semi-supervised segmentation, we utilize a labeleddataset Dl=Xli, Y liNi=1 along with an unlabeleddataset Du = {Xui }M+Ni=N+1. Here, Xli represents a labeledimage and Y li represents its corresponding label. Similarly, Xui denotes an unlabeled image. For convenience, i will beomitted in the following part. It is worth emphasizing thatthe number of labeled images is significantly larger than thenumber of unlabeled images, i.e., N M.",
  ". Overview": "The overall framework of our approach is shown in ,which can be divided into the following steps:1. For the input labeled image, we first apply input pertur-bation to generate two different samples, e.g., a weakaugmentation image and a strong augmentation image,both of which are input to the model with network per-turbation: the weak augmentation image is input to onenetwork and the strong augmentation image is input tothe other network to generate two corresponding predic-tions, using the provided label as supervision. 2. For an unlabeled image, two predictions are obtainedfollowing the above pipeline. Then using our proposedABD-R, the corresponding confidence matrices are usedto perform bidirectional displacement between two aug-mented unlabeled images to generate new input samples. 3. Meanwhile, to enforce learning from the potentially un-controllable regions, the ABD-I strategy based on in-verse confidence is applied to labeled data to generatetwo new samples with the corresponding labels. 4. Finally, all generated new samples are input to the modelto produce the corresponding predictions. The predic-tions of unlabeled data are used for cross-supervision,and the predictions of labeled data are supervised by thenewly generated labels.",
  ". Adaptive Bidirectional Displacement with Re-liable Confidence": "Under various perturbations, the segmentation model pro-duces unreliable predictions for unlabeled data.Impos-ing alignment using these predictions can render consistentlearning ineffective. A direct solution is to remove the re-gions related to unreliable prediction. In practice, we firstgenerate the confidence matrix based on the models pre-dictions. The confidence matrix measures the confidenceof each predicted pixel belonging to different categories,it reflects the models reliability to different perturbations.Utilizing the confidence matrix, our ABD-R can generate anew training sample that exhibits more reliable regions.Suppose Xuw R3HW is an unlabeled medical imagewith weak augmentation. Xus R3HW is the same un-labeled medical image but with strong augmentation. Afterpassing the model, we generate their corresponding outputs:",
  "P uw = softmax(logitsuw), P us = softmax(logitsus), (2)": "where P uw is the prediction of Xuw and P us is the predictionof Xus . After upsampling them to the same height and widthwith input, we can generate P uw RCHW and P us RCHW . C is the number of classes.Then we divide Xuw into K patches, each with a size ofk k, denoting as Xuw = {Xu,jw }Kj=1, where Xu,jw Rkk",
  "|k k|,(3)": "where Zu,jw,c represents the average logits score of the j-thpatch for the class c and c {1, 2, .., C}, logitsu,jw,c(m) isthe logit score of the class c for the m-th pixel in the j-thpatch. We regard Zu,jwas the output distribution for the j-thpatch of Xuw.Meanwhile, the corresponding confidence score for thej-th patch is computed as follows:",
  "|k k|,(4)": "where j is the index of the corresponding patch, P u,jw,c(m) isthe probability of the class c for the m-th pixel in the patch.max() is a maximum operator to select the highest confi-dence score for each pixel. Au,jwis the average confidencescore for the j-th patch, which measures the reliability ofthe corresponding patch.Then the index of the patch with the lowest confidencefor Xuw is computed as:",
  "where Induw-top is an index set that includes the indices ofthe selected top n highest confidence patches. induw-max1-n": "is the selected indices, for example, induw-max1 is the indexof the patch that has the highest (top 1) confidence score.Similarly, following the above operations, we divide Xusinto K patches, the corresponding logits and confidencescore are represented as Zu,jwand Au,js , respectively. Afterprocessing from Eq. (5) to Eq. (6), the indices of the top-highest and the lowest confidence for Xus are generated,representing as Indus-top and indus-min, respectively.AndIndus-top = {indus-max1, indus-max2, ..., indus-maxn} .To achieve controlled effects of the mixed perturbationsand enhance semantic coherence of the displacement oper-ation, we select the most similar patch from the obtained in-dex sets (Induw-top and Indus-top) by calculating the differenceof the output distribution between the selected top-n highestconfidence patches in one image and the lowest confidencepatch in the other image:",
  "where kldiv is to compute the KL divergence , e.g.,kldiv(Zw, Zs )) = softmax (Zw) log softmax(Zw)": "softmax(Zs ) , which re-flects the difference in the output distribution. indw-maxsand inds-maxs represent the indices of final selected patches.Finally, the bidirectional displacement operation is per-formed for Xus and Xuw. The patch of one augmented imagewith the lowest confidence score is displaced with the finalselected patch from the other augmented image:",
  "Xu,induw-maxsw,if j = indus-minXu,js,else.(9)": "After removing the patching operation and reshapingthem to the image, two new samples Xusw and Xuws aregenerated, which are then input to two networks f1 and f2for cross-supervision, as shown in Eq. (18).This approach allows the two networks to adapt to eachothers input perturbations, resulting in higher quality andmore reliable pseudo-labels.As a cross-supervised pro-cess for the unlabeled data, it also reduces the likelihood ofone model making erroneous predictions, thereby prevent-ing the degradation of the other models training process.",
  "In the above ABD-R module, unlabeled images are manip-ulated to create new samples by replacing the potentially": "uncontrollable patches with new patches, it does not di-rectly learn from the original regions. To enforce the modelto learn from these potentially uncontrollable regions, wepropose Adaptive Bidirectional Displacement with InverseConfidence (ABD-I) for the labeled images to strengthenthe learning for uncontrollable regions.Specifically, for a labeled image Xl, we perform a strongaugmentation to obtain a sample Xls and a weak augmenta-tion to obtain a sample Xlw. Let Xlw as an example, weexecute Eq. (1) to Eq. (6) on Xlw to get its region index, i.e.,indlw-max1 and indlw-min. Similarly, we repeat the above op-eration for the strong augmented image Xls to get indls-max1and indls-min. Note that indlw-max1 and indls-max1 are the in-dices of the patches that have the highest (top 1) confidencescore, we directly use them rather than selecting from can-didates since these regions are the most potentially control-lable region and we do not need to consider the semantic co-herence with the given annotations. indlw-min and indls-minshare the same definition with Eq. (5).Then ABD-I is used, the region of one image with thehighest confidence scores is displaced with the region fromthe other image having the lowest confidence scores:",
  "Xl,indlw-minw,if j = indls-max1Xl,js ,else.(11)": "Using Eq. (10) and Eq. (11), the new samples Xlsw andXlws are generated. To effectively supervise the displacedsamples, the same displacement is applied to the original la-bel. Suppose Y l is the label of images Xls and Xlw, we alsodivide Y l into K patches, denoting as Y l,j = {Y l,j}Kj=1.The corresponding displacement operation is expressed as:",
  "=Laugsup + Labdsup+ Laugsemi + Labdsemi(14)": "where is a weight that balances different losses, whichgradually increase with iterations increases based on theGaussian warming up: = 0.1 e5(1t/ttotal)2, t is thecurrent iteration and ttotal is the total iteration.The Lsup consists of Laugsup and Labdsup. Laugsup is used forthe original augmented labeled images, Labdsup is used for thenewly generated labeled samples.The loss Laugsup is computed as:",
  "ACDC dataset: The ACDC dataset comprises 200 an-notated short-axis cardiac cine-MR images from a cohort": "of 100 patients with four classes. 2D segmentation is morecommon than direct 3D segmentation . The data split re-mains 70 patients scans for training, 10 for validation, and20 for testing. Following previous approaches, four evalua-tion metrics are chosen: Dice Similarity Coefficient (DSC),Jaccard, 95% Hausdorff Distance (95HD) and Average Sur-face Distance (ASD).PROMISE12 dataset: The PROMISE12 dataset was made available for the MICCAI 2012 prostate segmen-tation challenge. MRI of 50 patients with various diseaseswas acquired at different locations. All 3D scans are con-verted into 2D slices. Following previous approaches, DSCand ASD are used as evaluation metrics.",
  ". Implementation Details": "We evaluate our approach on two baselines: Cross Teach-ing and BCP .Cross Teaching is a cross-supervision framework,which utilizes two networks to perform the network per-turbation: f1 and f2, representing UNet and Swin-UNet , respectively. We add the input perturbation usingweak and strong data augmentation to provide two kinds ofinputs. For weak data augmentation, random rotation andflipping are used. For strong data augmentations, colorjit-ter, blur and Cutout are used. During training, allinputs are cropped to 224 224 and divided into K = 16patches. The networks are trained with a batch size of 16,including 8 labeled slices and 8 unlabeled slices.BCP is a mean-teacher framework, which appliesweak and strong augmentation to perform input perturba-tion. We add the network perturbation by providing twostudent networks with different initializations. Our ABD isused on these two student networks following the above de-sign. During training, all inputs are cropped to 256 256and divided into K = 16 patches.All other settings follow the default settings with originalCross Teaching and BCP .",
  ". Comparison with Sate-of-the-Art Methods": "ACDA dataset: shows the average performance onthe ACDC dataset using 5% and 10% labeled ratios. Forthe 5% label ratio, our ABD achieves state-of-the-art per-formance compared to recent methods, surpassing the base-line Cross Teaching by a large margin. BCP is one of thenewly released methods, it achieved high performance onthe ACDC dataset. By incorporating our method into BCP,i.e., Ours-ABD (BCP), it has a noticeable improvement,which highlights the flexibility and scalability of our ap-proach. Specifically, we observe a 20.75% DSC improve-ment compared to Cross Teaching and a 1.37% DSC im-provement compared to BCP. Considering the 10% labeledratio, our ABD outperforms SCP-Net in all evaluationmetrics and achieves a new state-of-the-art performance. It",
  "gives some qualitative results, our method effec-tively suppresses areas that are inaccurately segmented by": "Cross Teaching and BCP, while accurately segmenting theforegrounds that are ignored by the two methods.PROMISE12 dataset: Following SS-Net , we con-duct experiments with 20% labeled data. We compare ABDwith CCT , URPC , SS-Net , SLC-Net andSCP-Net . As shown in , Ours-ABD surpassesall other approaches. Compared to the recently proposedSCP-Net, ABD brings a 5.0% DSC increase.",
  ". Ablation Studies": "We select Cross Teaching as the baseline. All experi-ments are conducted on the ACDC dataset with 10% labeleddata unless otherwise stated.Effectiveness of each module in ABD: demon-strates the effectiveness of each module in ABD by progres-sively adding ABD-R and ABD-I. It can be observed thatthe introduction of input perturbation (IP) decreases the per-formance of the baseline, indicating that the mixed pertur-bation easily leads to out-of-control. Incorporating ABD-Rand ABD-I brings increased performance. By incorporat-ing both ABD-R and ABD-I into the baseline, the modelhas the best result, reaching 88.52% DSC and surpassing",
  ". Conclusion": "In this paper, we proposed an adaptive bidirectional dis-placement (ABD) for semi-supervised medical image seg-mentation. Our key idea is to mitigate the constraints ofmixed perturbations on consistency learning, thereby en-hancing the upper limit of consistency learning. To achievethis, we designed two novel modules in our ABD: an ABD-R module reduces the uncontrolled regions in unlabeledsamples and captures comprehensive semantic informationfrom input perturbations, and an ABD-I module enhancesthe learning capacity to uncontrollable regions in labeledsamples to compensate for the deficiencies of ABD-R. Withthe cooperation of two modules, our method achieves state-of-the-art performance and is easily embedded into differ-ent methods. In the future, we will design a patch adaptivedisplacement strategy to tackle more complicated cases.Acknowledge:This work was supported by Na-tionalNaturalScienceFoundationofChina(No.62301613), the Taishan Scholar Program of Shandong(No.tsqn202306130), the Shandong Natural ScienceFoundation (No.ZR2023QF046), Qingdao PostdoctoralApplied Research Project (No.QDBSH20230102091)andIndependentInnovationResearchProjectofChinaUniversityofPetroleum(EastChina)(No.22CX06060A). Wenjia Bai, Ozan Oktay, Matthew Sinclair, Hideaki Suzuki,Martin Rajchl, Giacomo Tarroni, Ben Glocker, AndrewKing, Paul M Matthews, and Daniel Rueckert.Semi-supervised learning for network-based cardiac mr image seg-mentation.In Medical Image Computing and Computer-Assisted Intervention, pages 253260. Springer, 2017. 6 Yunhao Bai, Duowen Chen, Qingli Li, Wei Shen, and YanWang. Bidirectional copy-paste for semi-supervised medicalimage segmentation. In Proceedings of the IEEE/CVF Con-ference on Computer Vision and Pattern Recognition, pages1151411524, 2023. 1, 2, 6, 7 Hritam Basak and Zhaozheng Yin. Pseudo-label guided con-trastive learning for semi-supervised medical image segmen-tation. In Proceedings of the IEEE/CVF Conference on Com-puter Vision and Pattern Recognition, pages 1978619797,2023. 7 Olivier Bernard, Alain Lalande, Clement Zotti, Freder-ick Cervenansky, Xin Yang, Pheng-Ann Heng, Irem Cetin,Karim Lekadir, Oscar Camara, Miguel Angel GonzalezBallester, et al. Deep learning techniques for automatic mricardiac multi-structures segmentation and diagnosis: is theproblem solved? IEEE transactions on medical imaging, 37(11):25142525, 2018. 6 David Berthelot, Nicholas Carlini, Ian Goodfellow, NicolasPapernot, Avital Oliver, and Colin A Raffel. Mixmatch: Aholistic approach to semi-supervised learning. Advances inneural information processing systems, 32, 2019. 1 Hu Cao, Yueyue Wang, Joy Chen, Dongsheng Jiang, Xi-aopeng Zhang, Qi Tian, and Manning Wang.Swin-unet:Unet-like pure transformer for medical image segmentation.In European conference on computer vision, pages 205218.Springer, 2022. 6",
  "Xinlei Chen, Haoqi Fan, Ross Girshick, and Kaiming He.Improved baselines with momentum contrastive learning.arXiv preprint arXiv:2003.04297, 2020. 6": "Xiaokang Chen, Yuhui Yuan, Gang Zeng, and JingdongWang. Semi-supervised semantic segmentation with crosspseudo supervision. In Proceedings of the IEEE/CVF Con-ference on Computer Vision and Pattern Recognition, pages26132622, 2021. 1, 2 Jie Du, Xiaoci Zhang, Peng Liu, and Tianfu Wang. Coarse-refined consistency learning using pixel-level features forsemi-supervised medical image segmentation. IEEE Jour-nal of Biomedical and Health Informatics, 2023. 1 Wanwei He, Yinpei Dai, Yinhe Zheng, Yuchuan Wu, ZhengCao, Dermot Liu, Peng Jiang, Min Yang, Fei Huang, LuoSi, et al. Galaxy: A generative pre-trained model for task-oriented dialog with semi-supervised learning and explicitpolicy injection. In Proceedings of the AAAI conference onartificial intelligence, number 10, pages 1074910757, 2022.3 Wei Huang, Chang Chen, Zhiwei Xiong, Yueyi Zhang, Xue-jin Chen, Xiaoyan Sun, and Feng Wu. Semi-supervised neu-ron segmentation via reinforced consistency learning. IEEETransactions on Medical Imaging, 41(11):30163028, 2022.1, 2 Rushi Jiao, Yichi Zhang, Le Ding, Rong Cai, and JicongZhang. Learning with limited annotations: a survey on deepsemi-supervised learning for medical image segmentation.arXiv preprint arXiv:2207.14191, 2022. 1",
  "Solomon Kullback and Richard A Leibler. On informationand sufficiency. The annals of mathematical statistics, 22(1):7986, 1951. 5": "Xin Lai, Zhuotao Tian, Li Jiang, Shu Liu, Hengshuang Zhao,Liwei Wang, and Jiaya Jia. Semi-supervised semantic seg-mentation with directional context-aware consistency.InProceedings of the IEEE/CVF Conference on Computer Vi-sion and Pattern Recognition, pages 12051214, 2021. 1 Xiaomeng Li, Lequan Yu, Hao Chen, Chi-Wing Fu, LeiXing, and Pheng-Ann Heng. Transformation-consistent self-ensembling model for semisupervised medical image seg-mentation.IEEE Transactions on Neural Networks andLearning Systems, 32(2):523534, 2020. 2 Yanwen Li, Luyang Luo, Huangjing Lin, Hao Chen, andPheng-Ann Heng. Dual-consistency semi-supervised learn-ing with uncertainty quantification for covid-19 lesion seg-mentation from ct images. In Medical Image Computing andComputer Assisted Intervention, pages 199209. Springer,2021. 1 Chen Liang, Wenguan Wang, Jiaxu Miao, and Yi Yang.Logic-induced diagnostic reasoning for semi-supervised se-mantic segmentation. In Proceedings of the IEEE/CVF In-ternational Conference on Computer Vision, pages 1619716208, 2023. 3 Geert Litjens, Robert Toth, Wendy Van De Ven, CarolineHoeks, Sjoerd Kerkstra, Bram Van Ginneken, Graham Vin-cent, Gwenael Guillard, Neil Birbeck, Jindang Zhang, et al.Evaluation of prostate segmentation algorithms for mri: thepromise12 challenge. Medical image analysis, 18(2):359373, 2014. 6 Jinhua Liu, Christian Desrosiers, and Yuanfeng Zhou. Semi-supervised medical image segmentation using cross-modelpseudo-supervision with shape awareness and local contextconstraints. In International Conference on Medical ImageComputing and Computer-Assisted Intervention, pages 140150. Springer, 2022. 7 Xiangde Luo, Jieneng Chen, Tao Song, and Guotai Wang.Semi-supervised medical image segmentation through dual-task consistency. In Proceedings of the AAAI conference onartificial intelligence, number 10, pages 88018809, 2021. 7 Xiangde Luo, Wenjun Liao, Jieneng Chen, Tao Song, Yi-nan Chen, Shichuan Zhang, Nianyong Chen, Guotai Wang,and Shaoting Zhang. Efficient semi-supervised gross targetvolume of nasopharyngeal carcinoma segmentation via un-certainty rectified pyramid consistency. In Medical ImageComputing and Computer Assisted Intervention, pages 318329. Springer, 2021. 7",
  "International Conference on Medical Imaging with DeepLearning, pages 820833. PMLR, 2022. 6, 7": "Fausto Milletari, Nassir Navab, and Seyed-Ahmad Ahmadi.V-net: Fully convolutional neural networks for volumetricmedical image segmentation. In 2016 fourth internationalconference on 3D vision (3DV), pages 565571. Ieee, 2016.6 Yassine Ouali, Celine Hudelot, and Myriam Tami. Semi-supervised semantic segmentation with cross-consistencytraining. In Proceedings of the IEEE/CVF Conference onComputer Vision and Pattern Recognition, pages 1267412684, 2020. 1, 7 Pengzhen Ren, Changlin Li, Hang Xu, Yi Zhu, Guan-grun Wang, Jianzhuang Liu, Xiaojun Chang, and XiaodanLiang. Viewco: Discovering text-supervised segmentationmasks via multi-view semantic consistency. arXiv preprintarXiv:2302.10307, 2023. 3 Olaf Ronneberger, Philipp Fischer, and Thomas Brox. U-net:Convolutional networks for biomedical image segmentation.In Medical Image Computing and Computer-Assisted Inter-vention, pages 234241. Springer, 2015. 6, 7 Suman Sedai, Bhavna Antony, Ravneet Rai, Katie Jones, Hi-roshi Ishikawa, Joel Schuman, Wollstein Gadi, and RahilGarnavi. Uncertainty guided semi-supervised segmentationof retinal layers in oct images.In Medical Image Com-puting and Computer Assisted Intervention, pages 282290.Springer, 2019. 1",
  "Yucheng Shu, Hengbo Li, Bin Xiao, Xiuli Bi, and WeishengLi. Cross-mix monitoring for medical image segmentationwith limited supervision. IEEE Transactions on Multimedia,2022. 1": "Kihyuk Sohn, David Berthelot, Nicholas Carlini, ZizhaoZhang, Han Zhang, Colin A Raffel, Ekin Dogus Cubuk,Alexey Kurakin, and Chun-Liang Li. Fixmatch: Simplifyingsemi-supervised learning with consistency and confidence.Advances in neural information processing systems, 33:596608, 2020. 2 Nima Tajbakhsh, Laura Jeyaseelan, Qian Li, Jeffrey N Chi-ang, Zhihao Wu, and Xiaowei Ding. Embracing imperfectdatasets: A review of deep learning solutions for medicalimage segmentation. Medical Image Analysis, 63:101693,2020. 1 Antti Tarvainen and Harri Valpola. Mean teachers are betterrole models: Weight-averaged consistency targets improvesemi-supervised deep learning results. Advances in neuralinformation processing systems, 30, 2017. 2 Vikas Verma, Kenji Kawaguchi, Alex Lamb, Juho Kannala,Arno Solin, Yoshua Bengio, and David Lopez-Paz. Inter-polation consistency training for semi-supervised learning.Neural Networks, 145:90106, 2022. 3 Yan Wang, Yuyin Zhou, Wei Shen, Seyoun Park, Elliot KFishman, and Alan L Yuille. Abdominal multi-organ seg-mentation with organ-attention networks and statistical fu-sion. Medical image analysis, 55:88102, 2019. 1",
  "images.In Proceedings of the IEEE/CVF Conference onComputer Vision and Pattern Recognition, pages 1166611675, 2022. 1": "Yicheng Wu, Minfeng Xu, Zongyuan Ge, Jianfei Cai, andLei Zhang. Semi-supervised left atrium segmentation withmutual consistency training.In Medical Image Comput-ing and Computer Assisted Intervention, pages 297306.Springer, 2021. 7 Yicheng Wu, Zhonghua Wu, Qianyi Wu, Zongyuan Ge,and Jianfei Cai. Exploring smoothness and class-separationfor semi-supervised medical image segmentation.In In-ternational Conference on Medical Image Computing andComputer-Assisted Intervention, pages 3443. Springer,2022. 7 Mou-Cheng Xu, Yu-Kun Zhou, Chen Jin, Stefano B Blum-berg, Frederick J Wilson, Marius deGroot, Daniel C Alexan-der, Neil P Oxtoby, and Joseph Jacob. Learning morphologi-cal feature perturbations for calibrated semi-supervised seg-mentation. In International Conference on Medical Imagingwith Deep Learning, pages 14131429. PMLR, 2022. 2 Lihe Yang, Wei Zhuo, Lei Qi, Yinghuan Shi, and Yang Gao.St++: Make self-training work better for semi-supervised se-mantic segmentation. In Proceedings of the IEEE/CVF Con-ference on Computer Vision and Pattern Recognition, pages42684277, 2022. 2, 6 Lihe Yang, Lei Qi, Litong Feng, Wayne Zhang, andYinghuan Shi.Revisiting weak-to-strong consistency insemi-supervised semantic segmentation. In Proceedings ofthe IEEE/CVF Conference on Computer Vision and PatternRecognition, pages 72367246, 2023. 3 Xiaosu Yang, Jiya Tian, Yaping Wan, Mingzhi Chen, LingnaChen, and Junxi Chen. Semi-supervised medical image seg-mentation via cross-guidance and feature-level consistencydual regularization schemes. Medical Physics, 2023. 1 ShuoZhang,JiaojiaoZhang,BiaoTian,ThomasLukasiewicz,and Zhenghua Xu.Multi-modal con-trastive mutual learning and pseudo-label re-learning forsemi-supervised medical image segmentation.MedicalImage Analysis, 83:102656, 2023. 1 Yichi Zhang, Rushi Jiao, Qingcheng Liao, Dongyang Li, andJicong Zhang. Uncertainty-guided mutual consistency learn-ing for semi-supervised medical image segmentation. Artifi-cial Intelligence in Medicine, 138:102476, 2023. 1 Zhenxi Zhang, Ran Ran, Chunna Tian, Heng Zhou, Xin Li,Fan Yang, and Zhicheng Jiao. Self-aware and cross-sampleprototypical learning for semi-supervised medical imagesegmentation. arXiv preprint arXiv:2305.16214, 2023. 1,6, 7 Xiangyu Zhao, Zengxin Qi, Sheng Wang, Qian Wang, Xue-hai Wu, Ying Mao, and Lichi Zhang. Rcps: Rectified con-trastive pseudo supervision for semi-supervised medical im-age segmentation. arXiv preprint arXiv:2301.05500, 2023.1 Zhen Zhao, Lihe Yang, Sifan Long, Jimin Pi, Luping Zhou,and Jingdong Wang. Augmentation matters: A simple-yet-effective approach to semi-supervised semantic segmenta-tion. In Proceedings of the IEEE/CVF Conference on Com-",
  "puter Vision and Pattern Recognition, pages 1135011359,2023. 3": "Ke Zheng, Junhai Xu, and Jianguo Wei.Double noisemean teacher self-ensembling model for semi-supervised tu-mor segmentation.In ICASSP 2022-2022 IEEE Interna-tional Conference on Acoustics, Speech and Signal Process-ing (ICASSP), pages 14461450. IEEE, 2022. 1 Mingkai Zheng, Shan You, Lang Huang, Fei Wang, ChenQian, and Chang Xu. Simmatch: Semi-supervised learningwith similarity matching. In Proceedings of the IEEE/CVFConference on Computer Vision and Pattern Recognition,pages 1447114481, 2022. 3"
}