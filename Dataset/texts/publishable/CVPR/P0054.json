{
  "Abstract": "The increasing use of deep learning across variousdomains highlights the importance of understanding thedecision-making processes of these black-box models. Re-cent research focusing on the decision boundaries of deepclassiers, relies on generated synthetic instances in ar-eas of low condence, uncovering samples that challengeboth models and humans. We propose a novel approachto enhance the interpretability of deep binary classiers byselecting representative samples from the decision bound-ary prototypes and applying post-model explana-tion algorithms. We evaluate the effectiveness of our ap-proach through 2D visualizations and GradientSHAP anal-ysis. Our experiments demonstrate the potential of the pro-posed method, revealing distinct and compact clusters anddiverse prototypes that capture essential features that leadto low-condence decisions. By offering a more aggregatedview of deep classiers decision boundaries, our work con-tributes to the responsible development and deployment ofreliable machine learning systems.1",
  ". Introduction": "Nowadays, Deep Learning (DL) models are broadly usedin various domains, but their lack of interpretability due totheir black-box nature poses a signicant challenge . Re-cent efforts explore DL models decision-making processes,particularly around decision boundaries, where models of-ten struggle to make correct predictions.Research ini-tiatives such as DeepDIG , GASTeN and Am-biGuess study the decision boundary in a data-drivenway by generating borderline instances, i.e. synthetic low-condence examples, using techniques like Generative Ad-versarial Networks (GANs) or Variational Auto-encoders(VAEs). While many borderline instances consist of noisy",
  ". Schematic overview of the proposed method for improv-ing the decision boundary interpretability of the Model Under Testby combining synthetic image generation and deep clustering": "data with patterns undetectable to the human eye, similarto adversarial examples , prior work has shown that awell-selected subset of such samples resembles genuinelyhard-to-classify images, even for humans . Buildingon this, we propose a novel approach to enhance the inter-pretability of deep binary classiers by selecting represen-tative samples from the decision boundary prototypes and applying post-model explanation algorithms.Our method, illustrated in , comprises four steps:1.generate synthetic data near the decision boundarywith GASTeN; 2.detect patterns in these examples us-ing UMAP and Gaussian Mixture Models (GMM); 3. choose a representative prototype from each cluster; and4. visualize the prototypes and the decision boundary us-ing 2D space visualization and GradientSHAP . Weempirically evaluated the method using three ConvolutionalNeural Networks (CNN) of different complexity on binarysubsets of MNIST and Fashion-MNIST. Results show thepotential of the method, revealing distinct, compact clustersand diverse prototypes that embody the features contribut-ing to low-condence decisions.Ultimately, our method aims for a more responsible useof AI models by supporting development and auditing. Dur-ing development, it can spot potential model limitations byidentifying and explaining key examples the model strug-gles with. Labelling and using these examples for furthertraining can improve the model through active learning ordata augmentation. These examples are also valuable fordeveloping models with a reject option good modelsshould refrain from predicting on these prototypes. More-over, prototypes can support deployment by providing in-formation about the data types for which a model is ex-pected to make low-condence predictions, serving as asemi-automatic tool to generate model cards .",
  ". Stress Testing Machine Learning Models": "Stress testing is an evaluation process to assess system ro-bustness, limitations, and overall performance under chal-lenging conditions.When applied to ML models, it in-volves testing models on adverse conditions, including out-of-distribution , adversarial or ambiguous in-puts solely for the model or both the model andhumans . Recent work has explored model decisionboundaries to understand the limits of ML models. Weisset al. generate ambiguous data points to train and testDNN supervisors; Heo et al. use samples near theboundary for knowledge distillation; Liu et al. andDemir et al. study the decision boundary to comprehendmodels on safety-critical elds.When considering only data-driven approaches, tech-niques such as DeepDIG and DeepBoundary gen-erate adversarial examples combined with binary searchto nd the closest points to the decision boundary; Am-biGuess leverages autoencoders to target specic latentspace distributions; GASTeN introduces a GAN-basedmethodology that incorporates the output of a classier aspart of the generators loss function; and Demir et al. combine state-of-the-art methods, including image transfor-mations, GANs and adversarial attacks, followed by MLmodels that select those with highest uncertainty.Few studies explore how to use samples that fall withina models low-condence region for responsible AI. Demiret al. suggest using post-model explanations on error-",
  ". Slice Discovery Methods": "Slice discovery consists of methods that identify semanti-cally meaningful subgroups within unstructured data, par-ticularly where models perform poorly . Our approach,while similar, diverges by focusing on low-condence in-stances. These methods leverage deep clustering, a tech-nique that uses neural networks to capture relevant inputfeatures, followed by traditional clustering algorithms .The slice discovery methods state-of-the-art shownumeroustechniquesforrepresentingimagedata.GEORGE and PlaneSpot extract the embed-dings from the penultimate layer of their model, whereasDOMINO uses pre-trained embeddings, more speci-cally CLIP and ConVIRT . These methods thenne-tune GMMs for clustering.These methods employ dimensionality reduction whenfacing challenges with high-dimensional data, such as inef-cient similarity measures and the curse of dimension-ality. DOMINO uses PCA with 128 components, PlaneSpotopts for scvis with 2 dimensions, and GEORGE selectsUMAP with 1 or 2 components based on the dataset. Giventhat UMAP helps preserve the essential structure of thedata, combining UMAP with GMM, as seen in studies likeN2D , demonstrates that manifold learning techniquescan signicantly improve clustering quality by consideringthe local data structure.",
  ". Borderline Prototype Generation": "summarizes the proposed method. The model thatis being subjected to the stress-test must be a deep binaryimage classication, and it is referred to as the Model Un-der Testing (MUT). First, we populate the decision bound-ary by generating synthetic images close to the MUT deci-sion boundary, i.e. our borderline instances. To that end, weemploy GASTeN, a GAN-based technique trained with theMUT predictions, to approximate its decision boundary .We chose GASTeN as it generates realistic challenging bor-derline examples for a specic classier. Then, we lterthe synthetic images using the Average Confusion Distance(ACD) Cunha et al. , that measures the closeness of asample to the decision boundary. We lter the images byACD < 0.1 to ensure only low-condence predictions. Weassess the quality of the borderline images by calculatingthe Frechet Inception Distance (FID) scores .In our second step, we apply deep clustering to nd pat-terns in the borderline instances generated in the previousstep.To that end, we extract the high-level feature em-beddings from the MUTs penultimate layer.Then, weapply UMAP for dimension reduction, followed by GMMclustering to group visually similar images. We selected this combination given the favourable ndings in the lit-erature review . Particular hyperparameters aretuned, considering the specic characteristics of the low-condence region, as we explain in Sec. 4.2. Finally, thequality of the resulting clusters is assessed through the sil-houette score and the Davies-Bouldin index . Weuse these measures of cluster denition and separation toensure the formation of distinct and coherent groups.In the third step, we select the medoid from each clus-ter to represent the cluster. The medoid is calculated byminimizing the sum of distances to all other objects in thatcluster. As a centrally located sample, it ensures a robustrepresentation of each identied pattern.In the fourth step, we evaluate the representativeness ofthe selected prototypes through visual inspection. Our goalis to generate prototypes that demonstrate greater featurediversity, more dispersed distribution across the 2D space,and enhanced interpretability through GradientSHAP maps.With this in mind, we train UMAP on the test set to capturethe structure of the original data. Then, we analyze the po-sitioning of the prototypes within the 2D space created. Foran in-depth analysis of why these images are close to thedecision boundary, we use GradientSHAP a techniquethat explains the contribution of each pixel to the modelsoutput by integrating gradients with SHAP values .",
  ". Dataset": "We use MNIST and Fashion-MNIST datasets toevaluate our method. We chose these datasets for their in-terpretability without needing expert knowledge, simplicityin size, and lack of color. We created binary subsets fromthese datasets for binary classication, focusing on similarconcepts: 7 vs 1, 8 vs 0 and 5 vs 3 for MNIST and dress vstop and sneaker vs sandal for Fashion-MNIST.",
  ". Model Architecture": "To obtain more general conclusions, we evaluated MUTsarchitectures of varying complexities. Following the GAS-TeN study, we utilized a CNN architecture with two convo-lutional blocks, where the complexity is adjusted by varyingthe number of lters . For the MNIST dataset, we testedCNN models with 1, 2, and 4 lters, while for Fashion-MNIST, we used 4, 8, and 16 lters.To train GASTeN, we adapted its setup based on previ-ous ndings by Cunha et al. , tailoring its hyperparame-ters towards our stress-testing objectives. Training GAS-TeN required choosing two specic hyperparameters be-yond the standard DCGAN parameters: the confusion dis-tance weighting () and the pre-training epochs. The value critically inuences GASTeNs loss function, whilethe pre-training duration affects image realism.Based on the original authors suggestions, we opted for 5 pre-training epochs for MNIST and 10 for Fashion-MNIST,each with an weight of 25. We determined GASTeNsoptimal training duration by optimizing the FID-ACD min-imization , leading to selecting 10 epochs for MNISTand 15 for Fashion-MNIST. We generated 15,000 syntheticimages for each task.For deep clustering, we optimized the silhouette scoreusing the Bayesian hyperparameter optimization methodwith 25 iterations. With UMAP, we investigated the optimalnumber of neighbours to balance local versus global datastructures. Given our focus on classifying similar conceptsand analyzing regions of low condence, where features areless distinct, our analysis prioritized local structures. There-fore we explore a range of 5 to 25 neighbours. We also var-ied the minimum distance between 0.01 and 0.25 to controlembedding compactness and set the components between10 and 60 to ensure detailed clustering without losing crit-ical information. For GMM, we varied the cluster countfrom 3 to 15 to maintain a practical number of prototypesfor analysis. We also selected the covariance as full, as itallows for each cluster to have its covariance matrix.",
  ". Synthetic Data Generation": "We tested three MUTs on the ve binary subsets.TheMNIST 5 vs 3 subset using a CNN with one lter attainedthe lowest accuracy of 92.53%, while the 8 vs 0 subset witha four-lter CNN reached the highest accuracy of 98.92%.After training GASTeN for each classier-dataset sub-set combination, we generated 15,000 synthetic images andsubsequently ltered those with ACD < 0.1 . This processresulted in an average FID score increase of 250 points forimages near the decision boundary and an average 86% re-duction in image count post-ltering. The signicant FIDscore rise and the substantial image count decrease after l-tering suggest GASTeNs limited efciency in generatingdecision boundary-near samples.During this process, we observed some correlation be-tween the model complexity and GASTeN FID scores(nf ,FID = 0.52 ).We expected this outcome, as lowerclassier capacities lead to more challenging classications,resulting in less condent images. However, a contrary ex-ample is our least accurate classier, which produced real-istic (low FID scores) synthetic images that were unrealistic(high FID scores) near the decision boundary.",
  ". UMAP 2D space for MNIST 7 vs 1 and four-lter CNN.The test set is marked by stars with 1 in red, and 7 in green. Blackpins indicate the prototypes or baseline positions": "preserve image ambiguity. GMM clustering resulted in ei-ther a small (e.g. 3) or large (e.g. 15) number of clusterswithout a discernible pattern.Evaluation metrics indicated modest clustering quality,including the silhouette score (0.26 0.52) and the Davies-Bouldin Index (0.7 1.35) on the 15 classier-dataset sub-set pairs. These metrics suggest that while clusters are rea-sonably distinct and compact. There is room for improve-ment, possibly due to some overlap or sparseness in clus-ters. The best performance occurred on the MNIST 7 vs 1subset with a four-lter CNN and the poorest on the 5 vs 3subset with a four-lter CNN.We noticed a negative correlation between the quan-tity of low-condence images and the silhouette score(#images,SIL = 0.62), indicating that fewer images gen-erally lead to more effective clustering. We suspect thiscould be due to noise in the generated images, suggest-ing that exploring alternative dimensionality reduction andclustering techniques could enhance our clustering results.",
  ". Selecting and Visualizing Prototypes": "After clustering, we select the medoid of each cluster as ourprototype and assess its representativeness through a 2D vi-sualization and with GradientSHAP. To illustrate the useful-ness of the proposed method, we chose the best-performingsubset based on the silhouette score for this section analysis:MNIST subset 7 vs 1 with four-lter CNN. shows the distribution of prototypes versus thebaseline in the UMAP 2D space. In this example, we con-clude that prototypes are more dispersed than the baselinewhich even includes overlapping images.Observing the baseline in a, two images appear re-markably similar, likely those clustered together in the 2Dspace, with a fourth image resembling noise. In contrast, inb, the prototypes display distinct features, particularlyregarding rotation. We also note that all images lack part ofthe sevens upper section. We hypothesize that this featureis an intrinsic attribute of the low-condence region in thisMUT, and that the prototypes effectively capture it.",
  ". Selected images and the corresponding GradientSHAPmaps for MNIST 7 vs 1 and four-lter CNN. Features contributingto the classication of 1 are red, and 7 are green": "GradientSHAP maps indicate that features leading toclassication as the positive class (7) include the top el-bow and the middle line of the seven. On the other hand,attributes favoring the negative class (1) typically relate topixels in the center of the image. Remarkably, these mapsalso express uncertainty regarding the missing portion ofthe sevens upper section, validating our hypothesis that themodel has difculty learning this feature.",
  ". Conclusions": "In this work, we investigate borderline instances that con-tain visual properties that make predictions complex, evenfor humans. We study the impact of combining syntheticimage generation and deep clustering on the interpretabilityof deep binary classiers decision boundary.Further research includes improving the generation ofambiguous images, exploring other clustering and embed-ding techniques for improved performance, and develop-ing quantitative metrics to validate our prototypes statisti-cally. Additionally, as we tested our approach on simplieddatasets, where it is possible to assess ambiguity visually,the performance in complex scenarios needs to be assessed.Nevertheless, we obtained promising results that showthat it is possible to uncover patterns in borderline images.By visual inspection, we can study the representativenessof our prototypes and the features associated with the low-condence region. Such insights are invaluable for auditingmachine learning models, identifying and mitigating poten-tial weaknesses during development, or documenting thelimitations of classiers in model cards upon deployment. AcknowledgmentsAISym4Med (101095387) throughthe Horizon Europe Cluster 1:Health,Connected-Health (n. 46858);Competitiveness and Internation-alisation Operational Programme (POCI) and LisbonRegionalOperationalProgramme(LISBOA2020),under the PORTUGAL 2020 Partnership Agreement,throughtheEuropeanRegionalDevelopmentFund(ERDF); NextGenAI - Center for Responsible AI (2022-C05i0102-02), supported by IAPMEI; FCT plurianualfunding for 2020-2023 of LIACC (UIDB/00027/2020UIDP/00027/2020). Alejandro Barredo Arrieta, Natalia Daz-Rodrguez, JavierDel Ser, Adrien Bennetot, Siham Tabik, Alberto Barbado,Salvador Garcia, Sergio Gil-Lopez, Daniel Molina, RichardBenjamins, Raja Chatila, and Francisco Herrera. ExplainableArticial Intelligence (XAI): Concepts, taxonomies, oppor-tunities and challenges toward responsible AI. InformationFusion, 58:82115, 2020. 1 Lus Cunha, Carlos Soares, Andre Restivo, and Lus F Teix-eira. GASTeN: Generative Adversarial Stress Test Networks.In Advances in Intelligent Data Analysis {XXI} - 21st In-ternational Symposium on Intelligent Data Analysis, pages91102, 2023. 1, 2, 3",
  "Kilian Hendrickx, Lorenzo Perini, Dries Van der Plas,Wannes Meert, and Jesse Davis. Machine Learning with aReject Option: A survey. CoRR, 2021. 2": "Jens Henriksson, Christian Berger, Markus Borg, Lars Torn-berg, Sankar Raman Sathyamoorthy, and Cristofer Englund.Performance Analysis of Out-of-Distribution Detection onVarious Trained Neural Networks. In 2019 45th EuromicroConference on Software Engineering and Advanced Appli-cations, pages 113120, 2019. 2 Byeongho Heo, Minsik Lee, Sangdoo Yun, and Jin YoungChoi.Knowledge Distillation with Adversarial SamplesSupporting Decision Boundary.In The Ninth AAAI Sym-posium on Educational Advances in Articial Intelligence,pages 37713778, 2019. 2 Martin Heusel, Hubert Ramsauer, Thomas Unterthiner,Bernhard Nessler, and Sepp Hochreiter. GANs Trained bya Two Time-Scale Update Rule Converge to a Local NashEquilibrium. In Advances in Neural Information ProcessingSystems, pages 66266637. Curran Associates, Inc., 2017. 2",
  "Erxue Min, Xifeng Guo, Qiang Liu, Gen Zhang, JianjingCui, and Jun Long. A Survey of Clustering with Deep Learn-ing: From the Perspective of Network Architecture. IEEEAccess, 6:3950139514, 2018. 2": "Margaret Mitchell, Simone Wu, Andrew Zaldivar, ParkerBarnes, Lucy Vasserman, Ben Hutchinson, Elena Spitzer,Inioluwa Deborah Raji, and Timnit Gebru.Model Cardsfor Model Reporting. In Proceedings of the Conference onFairness, Accountability, and Transparency, pages 220229,2019. 2 Gregory Plumb, Nari Johnson, Angel Cabrera, and AmeetTalwalkar. Towards a More Rigorous Science of BlindspotDiscovery in Image Classication Models. Transactions onMachine Learning Research, 2023. 2, 3 Viraj Uday Prabhu, Sriram Yenamandra, Prithvijit Chat-topadhyay, and Judy Hoffman. LANCE: Stress-testing Vi-sual Models by Generating Language-guided CounterfactualImages. In Thirty-seventh Conference on Neural InformationProcessing Systems, 2023. 2 Alec Radford, Jong Wook Kim, Chris Hallacy, AdityaRamesh, Gabriel Goh, Sandhini Agarwal, Girish Sastry,Amanda Askell, Pamela Mishkin, Jack Clark, GretchenKrueger, and Ilya Sutskever. Learning Transferable VisualModels From Natural Language Supervision. In Proceedingsof the 38th International Conference on Machine Learning,pages 87468763, 2021. 2",
  "Peter J Rousseeuw. Silhouettes: A graphical aid to the in-terpretation and validation of cluster analysis.Journal ofComputational and Applied Mathematics, 20:5365, 1987.3": "Nimit Sohoni, Jared A Dunnmon, Geoffrey Angus, AlbertGu, and Christopher Re. No Subclass Left Behind: Fine-Grained Robustness in Coarse-Grained Classication Prob-lems. In Advances in Neural Information Processing Systems33, 2020. 2, 3 Christian Szegedy, Wojciech Zaremba, Ilya Sutskever, JoanBruna, Dumitru Erhan, Ian J Goodfellow, and Rob Fergus.Intriguing properties of neural networks. In Proceedings ofthe 2nd International Conference on Learning Representa-tions (ICLR 2014), 2014. 1"
}