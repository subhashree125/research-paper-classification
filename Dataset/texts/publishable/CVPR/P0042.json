{
  "Abstract": "Learning with limited labelled data is a challengingproblem in various applications, including remote sensing.Few-shot semantic segmentation is one approach that canencourage deep learning models to learn from few labelledexamples for novel classes not seen during the training. Thegeneralized few-shot segmentation setting has an additionalchallenge which encourages models not only to adapt tothe novel classes but also to maintain strong performanceon the training base classes. While previous datasets andbenchmarks discussed the few-shot segmentation setting inremote sensing, we are the first to propose a generalizedfew-shot segmentation benchmark for remote sensing. Thegeneralized setting is more realistic and challenging, whichnecessitates exploring it within the remote sensing context.We release the dataset augmenting OpenEarthMap with ad-ditional classes labelled for the generalized few-shot eval-uation setting. The dataset is released during the Open-EarthMap land cover mapping generalized few-shot chal-lenge in the L3D-IVU workshop in conjunction with CVPR2024. In this work, we summarize the dataset and challengedetails in addition to providing the benchmark results on thetwo phases of the challenge for the validation and test sets.",
  ". Introduction": "Deep learning has shown great success in remote sensingapplications with various supervised learning tasks such asland cover mapping (i.e., semantic segmentation) and crop yield prediction .There has also been anemergence of foundation models for remote sensing, whichrefer to models trained on broad datasets with power-ful generalization capabilities . These remote sensingfoundation models focused on either self-supervised learn-ing or vision-language modelling . Onthe other hand, few-shot learning which enables deep learn- ing models to learn from few training examples, is still rel-atively under explored in remote sensing. Although it isof paramount importance specifically with the current re-lease of foundation models and the demonstration of few-shot prompting of such models .Few-shot learning is guided by a few labelled examples(i.e., support set) to generalize to unseen novel classes inthe target images (i.e., query set). Most approaches emulatethe inference stage during training by sampling pairs of sup-port and query sets. This mechanism is referred to as meta-learning. The emergence of foundation models has markeda new paradigm for few-shot learning which explores few-shot prompting of such models . There have been variousworks on few-shot learning for the task of semantic segmen-tation in natural images where it started with seg-menting the novel classes with respect to the backgroundin the query set.A recently proposed generalized few-shot semantic segmentation setting defines a more realisticscenario where the goal is to perform well on all classes,novel and base . This is considerably more challeng-ing than standard few-shot semantic segmentation, yet, todate, there is no dedicated benchmark dataset for general-ized few-shot semantic segmentation in remote sensing tothe best of our knowledge. This work explores generalizedfew-shot semantic segmentation and its intersection with re-mote sensing, specifically, focusing on submeter-level landcover mapping. We propose a generalized few-shot seman-tic segmentation benchmark dataset for remote sensing thatwe release as part of the first challenge of this task, whichbuilds upon the recent dataset, OpenEarthMap . Thebenchmark dataset and challenge serve to provide a base-line for researchers interested in pursuing learning in low-resource settings for the task of land cover mapping. Insummary, our contributions are twofold: We present the OpenEarthMap generalized few-shot se-mantic segmentation (OEM-GFSS) dataset, a submeter-level land cover mapping dataset, extending the 8 classesof OpenEarthMap to 15 fine-grained classes.",
  ". Satellite Imagery Datasets": "There has been a plethora of work on remote sensingdatasets in deep learning for self-supervised learning , vision language modelling and supervisedlearning tasks . We focus on supervised learn-ing tasks, specifically land cover mapping as a semanticsegmentation task. Some of the datasets that are related toour work include OpenSentinalMap and LoveDA for land cover mapping, DynamicEarthNet for landcover mapping and change detection. Other datasets in-clude DeepGlobe for building, road extraction and landcover mapping. While LoveDA and DeepGlobe have been adopted for evaluation in cross-domain few-shotsemantic segmentation tasks , yet this work is thefirst to propose a generalized few-shot semantic segmenta-tion benchmark for remote sensing. Such setting is morerealistic as it evaluates both base (i.e., classes used duringtraining) and novel (i.e., classes unseen during training andprovided with only few training examples in the few-shotinference).",
  ". Few-Shot Learning": "Few-shot learning has been heavily investigated in vari-ous tasks including classification and segmenta-tion . Few-shot semantic segmentation is focusedon purposing few-shot learning for such dense segmen-tation tasks that require different perspectives than sim-ple classification tasks.For example, few-shot seman-tic segmentation has seen the prevalence of multiscale ap-proaches and the exploitation of dense pixel-to-pixelaffinities between support and query sets . While theprevious works mainly focused on natural images, there hasbeen some exploration of few-shot learning in remote sens-ing . Few-shot learning in remote sensingwas explored in scene classification and in land covermapping . The most recent few-shot seman-tic segmentation benchmark on iSAID-5i was released with a focus on segmenting novel classes solely in a 1-waymanner, where the models segment the novel class with re-spect to the background. On the other hand, our bench-mark focuses on a more realistic setting for the generalizedfew-shot semantic segmentation, where models are capa-ble of segmenting both the base and novel classes in an N-way manner. It also provides additional challenges arisingfrom forgetting the base class performance when learningthe novel classes from few examples. . The number of images and geographical regions in theOEM-GFSS dataset across the six continents. There are 408 im-ages from 73 geographical regions. OEM-GFSS has a greater rep-resentation in Europe and less in Oceania and North America.",
  ". Data Curation and Annotation": "The OEM-GFSS dataset extends the 8-class coarse-grainedland cover labels of the OpenEarthMap dataset to 15-class fined-grained land cover labels.The OEM-GFSSdataset is created from the test set of OpenEarthMap, forwhich the labels have not been released.We first pre-pared a set of new classes (see .2) by inspect-ing all the images, excluding xBD images, in the testset of OpenEarthMap. Then we sampled images across allthe geographical regions in the test set of OpenEarthMapthat contain the newly defined classes to create the dataset.This resulted in 408 images that were sampled from 73regions of the 97 geographical regions across the 6 con-tinents in the OpenEarthMap dataset. presents aper-continent image and geographical region counts of theimages and regions in OEM-GFSS. The images are of thesize of 1024 1024 at a spatial resolution of 0.250.5mground sampling distance as in OpenEarthMap. The anno-tation process follows a similar approach as used in Ope-nEarthMap, which is manually labelling each pixel of animage by human annotators, and then two additional anno-tators perform quality checks. If there is a disagreementbetween the two annotators on a particular labelling, a thirdperson verifies it. All the images were first annotated basedon the newly defined classes and the annotations of the Ope-nEarthMap original class labels were manually modified toyield fine-grained spatial detailed annotations.",
  "Dataset splits": "We split the 15 classes with a ratio of 7:4:4 for trainingclasses (base), validation novel classes (val-novel), and testnovel classes (test-novel), respectively, as disjointed sets.Based on the classes contained in each image, we split the408 images into 258 as a train set, 50 as a validation set, and100 as a test set. The train set contains only the images andlabels of the base classes and it is for pre-training a back-bone network. The validation and test sets contain imagesand labels of the val-novel and test-novel classes, respec-tively, and both consist of a support set and a query set forGFSS task of a 5-shot with 4-novel and 7-base classes. Theclass splits and dataset statistics are presented in ,and examples of the OEM-GFSS dataset are shown in Fig-ure 2.",
  ". Challenge Details": "In order to push the limit on learning with limited labelleddata for remote sensing we released our challenge on Co-daLab 3 that was based on the OpenEarthMap dataset .We hosted our challenge as part of the Learning with Lim-ited Labelled Data for Image and Video Understanding(L3D-IVU) workshop4 in conjunction with the ComputerVision and Pattern Recognition (CVPR) 2024 conference.The challenge was released in two phases. The first phasewas the development phase, participants were provided withthe training and validation sets, and they were allowed tosubmit results on the validation set. Additionally, partic-ipants had to submit a challenge paper on their proposedmethod to be eligible to enter the second phase. The secondand final phase is the evaluation phase, where participantsreceived the test set and were allowed to submit their results.After evaluation of their final results and based on the nov-elty of their approach, the top five challenge winners wereannounced.Baseline: Our benchmark encompasses the state-of-the-art generalized few-shot segmentation method, DIaM .It is based on a transductive inference mechanism thatmainly uses a knowledge distillation term that prevents thebase class classifier from forgetting its performance whilefine-tuning on the novel classes. We adopt the same setupas state-of-the-art generalized few-shot segmentation meth-ods which we select as our baseline, that operates on naturalimages with a PSPNet as the architecture used. Duringbase training, the images that contain novel classes are rela-belled so that the novel class pixels are set as background,which presents challenges due to ambiguity. During thefew-shot inference, novel classes are labelled in the supportset in addition to the base classes that were present duringtraining. Due to the nature of remote sensing imagery, eachsupport set image can contain multiple novel classes. Wefollow a similar procedure to DIaM in the training andthe few-shot inference settings. For the evaluation, we re-port mean intersection over union class-wise, mean over thebase classes, mean over the novel classes and our final met-ric which is a weighted sum that gives higher weight to thenovel mean. Specifically, for the weighted sum we use theexpression 0.4mbase+0.6mnovel, where mbase and mnovelare the base and novel mIoUs, respectively. The code for the . Examples of visual land cover mapping results of thebaseline model on the test set of the OEM-GFSS dataset. (a) isnovel classes of the test set and (b) is base classes. Query imagescan contain both the novel classes and the base classes, and all theclasses are to be recognised. baseline adapted for the OEM-GFSS challenge is publiclyreleased5.Challenge winners: The first winner of the challengewhich we refer to as SegLand , is based on a precur-sor generalized few-shot segmentation method to keep thelearned prototypes of the novel classes orthogonal to reduceconfusion among them while freezing the base class proto-types. They augmented that technique with various strate-gies including the use of an ensemble of base learners anddata augmentation techniques on the few-shot support set,with access to the training set during the few-shot inference.The second winner, ClassTrans , focused on mining thesimilarity between base and novel classes to improve thenovel class learning, in addition to handling the class im- . The Results of the Baseline and the Proposed Methods of the Challenge on the Validation and Test Sets of the OEM-GFSS Dataset.The Boldface indicates Best Results and the Underline indicates the Second Best.",
  "Note: The weighted-sum mIoU is calculated using 0.4 base mIoU + 0.6 novel mIoU": "balance arising. The third winner, FoMA , a foundationmodel assisted framework through multiple strategies todistill, enrich and fuse. The fourth winner, P-SegGPT ,relied on a learnable prompting technique for SegGPT foun-dation model. Finally, the fifth winner, DKA , focusedon improving the adaptability to novel classes through effi-cient parameter tuning and overcoming the catastrophic for-getting on the base classes through relabelling the trainingset.",
  ". Challenge Results": "Qualitative results: First, we demonstrate the performanceof the baseline on our proposed OEM-GFSS benchmark in. It shows four examples with challenging few-shot segmentation tasks, where our baseline is strugglingto segment the novel classes such as parking space andvehicle/cargo trailer. Yet, the baseline is performing rel-atively well in segmenting the base classes except in cer-tain instances such as the first example sea/lake/pond whichwas confused for a range land. Nonetheless, the baselinedemonstrated relatively well performance overall both onthe novel and base class performance, due to its transduc-tive inference that was able to cope with the challenges pre-sented in the test set.Quantitative results: shows the challenge re-sults for the two phases, where the first was evaluated onthe validation set and the second evaluated on the test set. Itshows the IoU per class for both the base and novel classes,the mean IoU for the base and novel, and the weighted av-erage which was used as the final score to rank the winningentries. In the first phase, it shows that FoMA was the win-ning entry, where it outperformed all the other methods inthe mIoU of the novel classes and the final weighted aver- age. FoMA relied on enriching labels and distilling knowl-edge from a vision language foundation model which re-sulted in such performance. It also shows ClassTrans out-performing all other methods in the base classes IoU due tohandling the class imbalance in the dataset. In the secondphase, SegLand outperformed all the other methods in theranking score with a considerable margin due to the ensem-ble of learners.",
  ". Conclusion": "We presented our challenge and benchmark for generalizedfew-shot semantic segmentation in remote sensing, OEM-GFSS, towards encouraging models adaptability to novelclasses beyond the closed set of training classes. Our chal-lenge had five winning entries, where we presented their re-sults in both phases in addition to the baseline quantitativeand qualitative results. By making our benchmark publiclyavailable, it will foster more research on the challengingproblem of learning with limited labelled data in the con-text of remote sensing.",
  "et al. On the opportunities and risks of foundation models.arXiv preprint arXiv:2108.07258, 2021": "Gong Cheng, Liming Cai, Chunbo Lang, Xiwen Yao, Jiny-ong Chen, Lei Guo, and Junwei Han.Spnet: Siamese-prototype network for few-shot remote sensing image sceneclassification. IEEE Transactions on Geoscience and RemoteSensing, 60:111, 2021. Yezhen Cong, Samar Khanna, Chenlin Meng, Patrick Liu,Erik Rozi, Yutong He, Marshall Burke, David Lobell, andStefano Ermon. Satmae: Pre-training transformers for tem-poral and multi-spectral satellite imagery. Advances in Neu-ral Information Processing Systems, 35:197211, 2022. Ilke Demir, Krzysztof Koperski, David Lindenbaum, GuanPang, Jing Huang, Saikat Basu, Forest Hughes, Devis Tuia,and Ramesh Raskar. Deepglobe 2018: A challenge to parsethe earth through satellite images.In Proceedings of theIEEE Conference on Computer Vision and Pattern Recog-nition Workshops, pages 172181, 2018.",
  "Guneet Singh Dhillon, Pratik Chaudhari, Avinash Ravichan-dran, and Stefano Soatto. A baseline for few-shot image clas-sification. In International Conference on Learning Repre-sentations, 2020": "Tianyi Gao, Wei Ao, Xing-Ao Wang, Yuanhao Zhao, PingMa, Mengjie Xie, Hang Fu, Jinchang Ren, and Zhi Gao. En-rich distill and fuse: Generalized few-shot semantic segmen-tation in remote sensing leveraging foundation models assis-tance. In Proceedings of the IEEE/CVF Conference on Com-puter Vision and Pattern Recognition (CVPR) Workshops,pages 27712780, 2024. Ritwik Gupta, Bryce Goodman, Nirav Patel, Ricky Hosfelt,Sandra Sajeev, Eric Heim, Jigar Doshi, Keane Lucas, HowieChoset, and Matthew Gaston. Creating xbd: A dataset forassessing building damage from satellite imagery. In Pro-ceedings of the IEEE/CVF Conference on Computer Visionand Pattern Recognition (CVPR) Workshops, 2019.",
  "Yuan Hu, Jianlong Yuan, Congcong Wen, Xiaonan Lu, andXiang Li. Rsgpt: A remote sensing vision language modeland benchmark. arXiv preprint arXiv:2307.15266, 2023": "Steve Andreas Immanuel and Hagai Raja Sinulingga. Learn-able prompt for few-shot semantic segmentation in remotesensing domain. In Proceedings of the IEEE/CVF Confer-ence on Computer Vision and Pattern Recognition (CVPR)Workshops, pages 27552761, 2024. Noah Johnson,Wayne Treible,and Daniel Crispell.Opensentinelmap: A large-scale land use dataset using open-streetmap and sentinel-2 imagery.In Proceedings of theIEEE/CVF Conference on Computer Vision and PatternRecognition, pages 13331341, 2022.",
  "Z. Tian, X. Lai, L. Jiang, S. Liu, M. Shu, H. Zhao, and J.Jia. Generalized few-shot semantic segmentation. In CVPR,pages 1156311572, 2022": "Aysim Toker, Lukas Kondmann, Mark Weber, MarvinEisenberger, Andres Camero, Jingliang Hu, Ariadna PregelHoderlein, C aglar Senaras, Timothy Davis, Daniel Cre-mers, et al. Dynamicearthnet: Daily multi-spectral satellitedataset for semantic change segmentation. In Proceedings ofthe IEEE/CVF Conference on Computer Vision and PatternRecognition, pages 2115821167, 2022. Jintao Tong, Haichen Zhou, Yicong Liu, Yiman Hu, and Yix-iong Zou.Dynamic knowledge adapter with probabilisticcalibration for generalized few-shot semantic segmentation.In Proceedings of the IEEE/CVF Conference on ComputerVision and Pattern Recognition (CVPR) Workshops, pages27812790, 2024.",
  "similarities and imbalance from generalized few-shot seg-mentation.In Proceedings of the IEEE/CVF Conferenceon Computer Vision and Pattern Recognition (CVPR) Work-shops, pages 27622770, 2024": "Junshi Xia, Naoto Yokoya, Bruno Adriano, and CliffordBroni-Bediako.Openearthmap: A benchmark dataset forglobal high-resolution land cover mapping.In Proceed-ings of the IEEE/CVF Winter Conference on Applications ofComputer Vision, pages 62546264, 2023. Xiwen Yao, Qinglong Cao, Xiaoxu Feng, Gong Cheng, andJunwei Han.Scale-aware detailed matching for few-shotaerial image semantic segmentation. IEEE Transactions onGeoscience and Remote Sensing, 60:111, 2021. Jiaxuan You, Xiaocheng Li, Melvin Low, David Lobell, andStefano Ermon. Deep gaussian process for crop yield pre-diction based on remote sensing data. In Proceedings of theAAAI conference on artificial intelligence, 2017."
}