{
  "Recent advancements in image generation technology": "have enabled widespread access to AI-generated imagery, prominently used in advertising, entertainment, and progressively in every form of visual content. However, these technologies often perpetuate societal biases. This study investigates the representation biases in popular image generation models towards people with disabilities (PWD). Through a comprehensive experiment involving several popular text-to-image models, we analyzed the depiction of disability. The results indicate a significant bias, with most generated images portraying disabled individuals as old, sad, and predominantly using manual wheelchairs. These findings highlight the urgent need for more inclusive AI development, ensuring diverse and accurate representation of PWD in generated images. This research underscores the importance of addressing and mitigating biases in AI models to foster equitable and realistic representations.",
  "In computer vision, most works focus on dedicated": "models and methods to deal with disability related objects and persons, for example for wheelchair detection . Regarding the generalization of these abilities in popular models, demonstrates clear biases making PWD less detected by state-of-the-art detection and segmentations models. This work also introduces an accessibility related benchmark, proven to be necessary to reach acceptable level of performances with regards to the different type of disabilities in generic models.",
  "The first tests were made with the Stable Diffusion XL": "turbo (SDXL) model. SDXL is a relatively small and efficient model based on the method of adversarial diffusion distillation . It was run with the MLX on a Macbook Pro M3. This model is an open-source diffusion-based model of 3.5 billion parameters. We also tested our prompts on proprietary models such as Midjourney v6, Stable Diffusion 3 and Dalle-3 which are widely known by creative end-users.",
  "For each proprietary model we ran 50 iterations of each": "prompt with a varying seed whereas for SDXL turbo we generated 2000 images for each prompt. After the generations, each image was presented to human annotators whose role was to label the generations over several questions: is the person physically impaired? Is the person represented in a wheelchair? If so, is it a manual wheelchair? Does the person appear old (above 40 y.o.)? Does the person appear sad? For each question, the annotators could answer with yes, no or hard to say. This latter class was generally chosen when the generation was not good enough to assess the age, or emotion of the person. This was especially the case when the person was generated from the back or when the facial features were too distorted to determine the age or emotion of the person.",
  "shows some of the first generations made with": "SDXL turbo and Midjourney. They clearly matched the biases we were expecting when it comes to disability imagery and motivated our study. Generally, the models did not generate very diverse representations of PWD and although we initialized every model with varying seeds, the generated images were all very similar. These first generation made us build a generic scheme that summarized our experience when generating pictures of PWD. This scheme is represented In .",
  "Running the generations with the different models": "illustrates some biases such as the fact that almost all instances of disabled persons generated were represented in a wheelchair. On top of that, we note that almost all these wheelchairs were manual, which is realistically only a tiny part of the possible wheelchairs. Women with disabilities are also generated younger and happier than men with disabilities. Finally, it appears that, except for Dalle3 generations, disabled people are often represented as old and sad people.",
  "These biases are also harder to discover and to deal with,": "partly due to the number of different realities hidden behind the term disabled. A PWD can be mentally ill, physically impaired, sometimes both, and even within one of these categories, the biases to look for can vary. Future work should probably aim at proposing standardized way to study these biases , similar to what was built by the open-source community to study gender biases in each profession .",
  "The main takeaway of this paper is to encourage the": "scientific community and especially the computer vision community to address the biases about disabled people in AI models. Through this work, and the impact it may have on future scientific research, we hope to see more inclusive development of AI models acknowledging the fact that people with disabilities can be young, happy, from various origins and professions (even AI researchers!).",
  "This work exposes clear biases of current automatic": "image generation when it comes to generate disability related imagery. We noted that these systems tend to reproduce some problematic biases deeply embedded in our societies by representing disabled people as old, sad and necessarily in a wheelchair. Some attempts to mitigate these biases were also spotted, but they may not be a good nor sufficient solution. It is crucial for AI researchers and developers to address these biases to ensure inclusive and accurate representations. This involves diversifying training datasets and implementing bias detection and mitigation strategies."
}