{
  "Abstract": "We introduce a multimodal vision framework for preci-sion livestock farming, harnessing the power of Ground-ingDINO, HQSAM, and ViTPose models. This integratedsuite enables comprehensive behavioral analytics fromvideo data without invasive animal tagging.Ground-ingDINO generates accurate bounding boxes around live-stock, while HQSAM segments individual animals withinthese boxes. ViTPose estimates key body points, facilitatingposture and movement analysis. Demonstrated on a sheepdataset with grazing, running, sitting, standing, and walk-ing activities, our framework extracts invaluable insights:activity and grazing patterns, interaction dynamics, anddetailed postural evaluations.Applicable across speciesand video resolutions, this framework revolutionizes non-invasive livestock monitoring for activity detection, count-ing, health assessments, and posture analyses. It empow-ers data-driven farm management, optimizing animal wel-fare and productivity through AI-powered behavioral un-derstanding.",
  ". Introduction": "The fusion of computer vision and deep learning has cat-alyzed a paradigm shift in non-contact animal monitoringsystems. These advanced systems, now a cornerstone inmodern agriculture, are pivotal for animal behavior quan-tification and early disease detection .As farmingmoves towards precision livestock farming, the role of suchtechnologies in ensuring animal health and welfare hasbecome indispensable. Within this domain, pose estima-tion and instance segmentation emergeas two pillars foundational to behavioral analysis, drivingefforts towards creating robust and efficient models. Poseestimation, a domain thoroughly explored, benefits from ex-tensive datasets that provide a wealth of annotatedinformation across diverse animal species. Leveraging such",
  "*Corresponding author": "resources, generalizable pose estimation models achieve remarkable results, enhancing our understanding ofanimal behavior across the animal kingdom. While poseestimation offers in-depth behavioral insights, instance seg-mentation opens doors to analytics that transcend postureanalysis . However, the isolated application of thesetechniques only provides a fraction of the potential insight.Current approaches for evaluating the behavioral statesof farm animals, such as direct observation or physiologi-cal measurements, are often disruptive, subjective, and im-practical for large-scale application . Theres a lack ofscientifically validated metrics to accurately gauge farm an-imal well-being using these methods . Standards in an-imal welfare predominantly highlight negative indicators,like harm and stress, rather than positive ones . Yet,recognizing and promoting positive states are crucial notonly for the animals health but also for enhancing farmproductivity and product quality. Non-invasive monitoringoffers a promising solution to these challenges. By lever-aging technologies that minimize stress and bias, we cangather reliable data on animal welfare, potentially improv-ing both the lives of livestock and the outputs they yield. The importance of such advancements cannot beoverstated. With the global population projected to reachnearly 10 billion by 2050 , the demand for sustainableand efficient farming practices is at an all-time high.We introduce a revolutionary non-contact, multimodalAI framework, AnimalFormer, that synergizes state-of-the-art models for a holistic analysis of livestock behavior. Uti-lizing an open-source sheep dataset , we demonstratecomprehensive behavioral analytics across various activi-ties such as grazing, running, and sitting/resting. The com-bination of ViTPose , GroundingDINO , and HQ-SAM allows for nuanced pose estimation and precisesegmentation, capturing the granularity of animal move-ments and interactions.AnimalFormer provides a scal-able solution that can be adapted across different livestockspecies and varying farm sizes, offering insights that arecritical for optimizing feed efficiency, monitoring health,and potentially improving breeding programs. This frame-",
  "Transformer Block": ". Our integrated analysis framework, designed for comprehensive behavioral understanding of sheep in a dataset. The frameworkcombines ViTPose and Grounding DINO for pose estimation and contextual understanding respectively, with the high-quality instancesegmentation capabilities of HQ-SAM. By fusing these components, our pipeline provides precise keypoints and segmentation masks,essential for in-depth ethological studies. This block diagram provides a clear overview of the data flow and processing steps within ourend-to-end solution. work transcends the capabilities of existing methodologies,offering a novel approach to farm management that is bothadvanced and operationally efficient. By harnessing rawvideo data, our framework as shown in , facilitatesprecision livestock farming and proactive health monitoringwithout the need for invasive tagging or interaction. Theinsights gleaned are not only pivotal for individual animalwelfare but also hold the promise of transforming farmingpractices on a global scale. The non-invasive nature of ourtechnology ensures minimal stress to animals, leading to",
  "more accurate behavioral observations and, consequently,a deeper understanding of animal well-being": "To the best of our knowledge, such a comprehensive,multimodal AI framework using latest state-of-the-art Vi-sion Transformers (ViTs) models has not been previ-ously devised specifically for the agriculture and farmingcommunity. By bridging this gap, we not only contributeto the advancement of precision livestock farming but alsoset a new benchmark for animal welfare and farm manage-ment practices. The potential for scaling this framework to incorporate additional behavioral analytics and apply it to awider range of animal species further emphasizes its signif-icance and the broad impact it could have on the future offarming and agricultural industry.",
  ". Related work": "The advancement in non-contact animal monitoring sys-tems, particularly through pose estimation, has significantlyimproved our understanding of animal behavior.Large-scale open-sourced datasets, combined with deep learningtechniques, have fostered the development of efficient poseestimation models . These models enable detailed be-havior analysis across various species, offering insights intotheir natural patterns and interactions. Notably, mice havebeen a focal point in behavior analytics, leading to mod-els that capture their diverse behaviors . In live-stock farming, pose estimation has proven invaluable. Itfacilitates behavior analytics for cattle, aiding in breedingreference, early detection of lameness , and monitoringoverall health . This approach, free from human inter-vention, not only ensures comprehensive behavior analyticsbut also reduces the risk of injury to animals. However,pose estimation alone may not capture the full spectrum ofanimal interactions, especially in scenarios involving occlu-sion or requiring the analysis of intricate behaviors such aseating patterns. This limitation stems from the reliance ofpose estimation models on keypoints, which might not ef-fectively capture changes across consecutive frames. To ad-dress these gaps, instance segmentation emerges as a pow-erful tool, enabling the detailed tracking of animal interac-tions and behaviors . Coupled with multiple-object de-tection, this approach enhances the tracking and trajectoryanalysis of animals within video footage.Recognizing the strengths and limitations of both poseestimation and instance segmentation, we propose an end-to-end multimodal framework that integrates these method-ologies. This framework aims to provide comprehensivebehavioral analytics, encompassing a broader range of ac-tivities and interactions. Through this synthesis, we seek tooffer a more holistic view of animal behavior, bridging thegap between individual and collective behaviors.",
  ". Dataset": "The dataset used in this paper was curated for sheepbehavior analysis.It constitutes of an extensive collec-tion of videos capturing five distinct sheep activities: graz-ing, running, sitting/resting, standing, and walking. Thevideos were recorded using high-resolution digital camerasfrom varying angles and positions, and the entire datasetcomprises of 417 videos. Although, the duration of eachvideo varies, the total footage is 59 minutes long, totaling to 149, 327 frames. For our analysis, we only consider thevideos pertaining to grazing, running and sitting/resting ac-tivities. Furthermore, to enhance computational efficiency,we downsampled the dataset by selecting every 10th frame.This downsampling process reduces the computational loadwhile preserving essential information for analysis, ensur-ing the dataset remains suitable for developing and testingcomputer vision algorithms aimed at non-invasive monitor-ing and analysis of sheep behavior.The activities captured in the dataset are reflective oftypical behaviors exhibited by sheep in a natural setting,making it a valuable resource for training deep learningmodels to recognize and classify these activities accurately.The datasets format, consisting of high-resolution videosand their corresponding frames (with a notable omission offrames containing humans for privacy), allows for a wide ar-ray of computer vision applications, including but not lim-ited to, activity recognition and behavior analysis.",
  "Pose estimation": "We utilize ViTPose , the current state-of-the-art poseestimation model, to extract keypoints for each video. ViT-Pose provides a simple but efficient ViT baseline for poseestimation in animals as well as human datasets. It usesplain and hierarchical vision transformers, as the backbonemodel which is trained on ImageNet-1K with maskedimage modelling (MIM) pre-training.ViT is cou-pled with light weight decoders which bypass the use ofcomplex mechanisms including skip-connections and cross-attentions and instead comprise of simple deconvolutionand prediction layers.An input image X RHW 3, is first converted intotokens via the patch embedding layer i.e F RHd W",
  "bounding boxbounding boxbounding box": ". Qualitative outputs of our framework depicting various behaviors of sheep. Top row: Running frames with keypoints andbounding boxes illustrating movement dynamics. Middle row: Grazing frames showcasing sheep engaged in feeding with extracted posesand segmentation masks highlighting the focus areas. Bottom row: Resting frames with segmentation masks delineating individual sheepin a state of repose. Each behavior is analyzed through a combination of visual features extracted from images.",
  "Animal detection": "For our animal detection module, GroundingDINO isutilized, building on the DINO frameworks self-supervisedlearning strengths.DINO, underpinned by the distilledknowledge self-attention mechanism from ViTs, em-powers our model to recognize textual descriptions withinvisual inputs efficiently. The DINO methodology incorpo- rates self-supervised learning strategies , utilizingan exponential moving average of the student models pa-rameters to update the teacher model, thus preventing col-lapse without a direct contrastive loss .The distilled knowledge within the student network is re-fined through temperature-scaled softmax functions, as ex-pressed below:",
  "where Ps(x)i denotes the probability predicted by thestudent network for the ith class, gs(x)i is the logit or the": "raw output from the student network for the ith class beforeapplying softmax, s represents the temperature parameterinfluencing the softmax functions sharpness and the sum inthe denominator runs over all Q possible classes, ensuringthat the probabilities sum to 1. A similar equation pertainsto the teacher network Pt with temperature t.Grounding DINO advances this architecture by preciselylinking textual phrases with their corresponding objects inimages, for instance, identifying a cat and a table from aninput image and associating them with their respective la-bels extracted from the input text. This enhanced capabil-ity is achieved through an image backbone for extractingvisual features, a text backbone for text feature extraction,a feature enhancer for cross-modality fusion, and a cross-modality decoder for refining object boxes.",
  "Running videos": "Gait. In order to quantify the overall gait pattern of an an-imal, we look at the varying poses it exhibited during run-ning. A set of 17 keypoints is extracted from each frame ofan animals running video as shown in . The key-points are converted to meaningful embedding by applyingUniform Manifold Approximation and Projection (UMAP), which represent the different poses demonstrated by an individual sheep during the course of its running. ForUMAP, we set n neighbors=20 to encapsulate all theposes emphasized by the running of an animal and atwo-dimensional embedding space (n components=2) isused for visualization. To quantify the unique poses presentacross the videos and extract similar gait patterns betweendifferent sheeps, we cluster the embeddings via K-MeansClustering . We create 10 unique clusters for all theposes demonstrated by the sheeps in the videos. In orderto extract meaningful insights about the sheep behavior weassess how gait patterns affect speed, by conducting a speedanalysis of the running videos. We opt for UMAP as partof our pipeline due to its ability to preserve local and globalstructures within the data along with being highly efficientin processing large volumes .Speed. We assess the speed of individual subjects based ontheir observable movement across video frames ()in running videos. Given a set of masks corresponding toeach subjects position in sequential frames, we commenceby identifying the largest mask within each frame, which weassociate with the primary subject of interest. This is pred-icated on the notion that the primary subject occupies thelargest area within the field of view. To ascertain the cen-troid of the largest mask, we calculate the geometric centerof its binary mask area, which serves as a proxy for the sub-jects position. The temporal evolution of the centroid be-tween consecutive frames allows us to deduce the raw speedof the subject. This is achieved by measuring the displace-ment of the centroid over time, considering the frame rate ofthe video and the number of frames skipped between mea-surements to enhance accuracy. However, raw speed alonedoes not provide a complete picture due to potential varia-tions in the subjects distance from the camera, which canskew perceived speed. To mitigate this, we normalize thespeeds by the areas of the masks. The normalization pro-cess involves adjusting the speeds based on a reference areavalue derived from the mean of all mask areas. The intentis to correct for perspective distortion, wherein objects thatare closer to the camera appear to be moving faster thanthose further away. By normalizing the speeds, we aim toachieve a more accurate representation of the actual speedof the subjects. Our methodology yields a set of normalizedspeeds for each subject, corresponding to their movementacross the frames. This data along with the gait patternsforms the basis for subsequent analyses of the sheep.",
  "Grazing videos": "To perform analysis of the grazing behavior among sheep,we begin with segmenting individual sheep across videoframes as shown in (). After accurate identificationand segmentation, we determine the keypoint representativeof the sheeps nose. This keypoint serves as the focal point BC D Speed analytics/session - Sheep startmidend Running pose clusters quantification per animal EFResting body shape clusters: brown (herd), gray (single)Grazing activity: herd vs single",
  "Speed": "A . Behavior Analytics. A. UMAP representation of the unique gait patterns of the sheep extracted from their running videos. B.Speed profile of the animal extracted at the commencement, midpoint, and conclusion of their running videos. C. The unique clusters ofexisting sheep gait patterns. D. Spread of different patterns within a single animal across different clusters. E. The grazing activity of thesheep in herds vs single. F. UMAP representation of the unique resting pattern of the animals in herd vs single. around which we establish an approximate grazing area.We further refine this selected grazing patch by subtract-ing the sheeps segmentation masks to exclude non-grazingelements such as sheeps head, ensuring that only relevantgrazing area is measured. Within this isolated region, wequantify the green signal intensity. The measurement of thegreen signal intensity across consecutive frames providesan approximation of the grazing activity which was indica-",
  "On sheep resting behavior, we employed an image-basedanalysis to differentiate between individual and herd restingstates from front and side view (). The methodol-": "ogy involved segmenting video footage into frames, usingbounding boxes to identify and isolate sheep within eachframe. We extracted masks for each sheep identified bythe bounding boxes, categorizing the data into four dis-tinct groups - front view herd, side view herd, front viewsingle, and side view single. The masks were resized toa standard dimensions for consistency across the dataset.The processed data was then analyzed using UMAP for di-mensionality reduction, allowing us to visualize and clus-ter different resting states. UMAPs configurations wereset to n neighbors=50 to account for the overarchinggrouping tendencies of sheep, and min dist=0.01 toachieve distinct clusters indicative of individual and groupresting states.A two-dimensional space projection withn components=2 was chosen for ease of visualizationand analysis, with the Euclidean metric due to its natu-ral fit for the datas geometric properties. To quantify theunique resting poses, we cluster the UMAP embeddings viaK-Means Clustering. We create 10 unique clusters for allthe poses demonstrated by the sheeps in the sitting videos.This approach facilitated the identification of patterns insheep resting behavior, such as preferences for resting aloneor within a group.",
  ". Indirect relationship between animals gait di-versity and running speed": "Since sheep are prey animals with extremely heightenedsenses of flight and fright, they tend to run away from hu-mans and other animals . Running is a common behav-ioral habit observed in sheep which can tell us a great dealabout their gaits and speed. Using the running videos of in-dividual sheep and their corresponding UMAP embeddings,we extract the different poses exhibited by the sheep, asshown in (A). Each unique color in (A)represents an individual animals poses. We observe that al-though for majority animals, the poses exhibited lie closerto each other however in some instances they are spread out.To validate this observation, we cluster the animal posesinto 10 unique groups as shown in (C). Althoughthe running patterns of a sheep are independent of other sub-jects, we observe that some sheep share gait patterns as theybelong to the same cluster. (D) shows the differ-ent poses encompassed within an individual animals run-ning pattern along with the distribution of poses in multipleclusters. Even though different sheep have overlapping gaitpatterns, however (D) clearly shows that an indi-vidual sheeps gait pattern is consistent within itself and islargely found within a single cluster. Animal IDs 025 and011, for example, have a high number of poses, which arefound in a single cluster i.e cluster ID 9 and 1 respectively.We observe a similar trend in case of a dynamic gait pattern spanning multiple clusters and observe that majority of theposes are present in a specific cluster. Animal ID 014, forexample, has poses spanning clusters 0, 2 and 6 howevermajority of its poses are present in cluster 6 while a feware distributed among 0 and 2. A similar trend is observedfor other animals with higher number of unique poses, in-cluding animal IDs 029 and 033, for which majority of theirposes are present in cluster 2 and 0 respectively.Although, pose estimation provides insights regardingthe gait patterns, however in order to quantify the animalshealth, we further provide speed analysis. (B) il-lustrates the speed trends of individual sheep at various in-tervals - the commencement, midpoint, and conclusion oftheir running sessions. The figure presents a compellingnarrative; sheep that display a more limited range of dy-namic gait patterns tend to achieve higher speeds. AnimalID 025, for example, encompasses few poses within its run-ning pattern, however it is the fastest among the lot. Onthe other hand, animal ID 014, is among the slower run-ning sheep despite having a higher number of poses. Thisphenomenon suggests a possible trade-off between speedand the variety of movements within the gait. In essence,sheep that adhere to a consistent gait pattern, without sig-nificant variations, generally exhibit higher velocities. Con-versely, sheep with a broader array of dynamic poses showa tendency toward slower speeds.The observed inverserelationship aligns with the principles of locomotive effi-ciency, where streamlined, repetitive movements facilitatefaster motion . This insight is not only of academic in-terest but also carries practical implications. Understand-ing the gait diversity and corresponding speed could aid inidentifying potential health issues, optimizing shepherdingpractices, and enhancing overall herd management.",
  ". Enhanced grazing activity in isolation": "Through animal detection and pose estimation, we quantifyand compare the grazing patterns of sheep in an isolatedsetting with when they are flocked together. Our results,as shown in (E), reveal compelling evidence thatsheep engage in more substantial grazing activity when iso-lated as compared to when they are part of a herd. In ab-sence of social stimuli and potential threats, the sheep focusmore intently on feeding and have a higher grazing activ-ity. This behavior is attributed to the diminished distrac-tions and the lack of need for social interaction or vigilance,which is more prevalent in group settings. In controlled en-vironments, devoid of predators or environmental stressors,animals typically exhibit a reduction in the vigilance behav-ior that characterizes wild settings. Our observations are inalignment with this principle, indicating that solitary graz-ing sheep capitalize on the safety and tranquility to maxi-mize their food intake. We observe that when the animalsflock together, they tend to consume lesser food, since they pause their grazing for various social interactions, such asestablishing social hierarchies or bonding. The quantita-tive data gleaned from our analysis provides a clear con-trast between the two scenarios. Sheep in solitude not onlygraze more but also show consistent feeding patterns with-out significant interruptions. This contrasts with herd sce-narios where the grazing patterns are interspersed with non-feeding activities. Our study offers valuable insights intothe grazing patterns of domestic sheep, which can be instru-mental in enhancing farm management practices and opti-mizing feeding strategies to ensure the well-being and pro-ductivity of the animals.In short, our examination of sheep grazing behaviorsyielded an intriguing pattern - in controlled scenarios, sheepdisplayed an increased grazing activity when alone com-pared to being in a herd. This increase is hypothesized to bedue to the reduced distractions and social obligations thattypically interrupt feeding in a group environment.Ourdata suggests that in such isolated snippets, the absenceof broader social dynamics allows sheep to feed more effi-ciently, leveraging the security and stillness of a controlledsetting to focus on grazing. It is worth noting, however, thatthese findings are based on brief observational periods. Along-term comprehensive study could reveal different graz-ing dynamics, as sheep might exhibit varying grazing in-tensities over extended periods . Our insights are con-strained by the scope of the dataset, which did not captureextended durations or include variables like environmentalshifts and detailed social interactions, limiting the breadthof our analysis.",
  ". Resting pose similarities across animals": "In (F), the plot on the left displays the UMAP scat-terplot for the front view of resting sheep, while the plot onthe right shows the side view. In each plot, data points rep-resent individual instances of sheep resting postures. Theclustering of points in the UMAP space signifies patternsof similarity within the resting postures. A tighter cluster-ing indicates a more consistent and homogeneous behaviorpattern among the animals within that group. From theseplots, we observe that sheep demonstrate a propensity formaintaining a consistent resting posture when alone, whichis reflected in the tightly clustered gray points. This ho-mogeneity in behavior could be attributed to a lack of ex-ternal stimuli, leading to a uniformity in resting positions.In contrast, the brown clusters corresponding to sheep rest-ing in a herd show a more scattered distribution, suggestinga diversity in resting postures. This variability could arisefrom social dynamics within the herd or because of spa-tial constraints. The scattered clusters imply that sheep in aherd may change their resting positions more frequently oradopt different postures compared to when they are alone.The UMAP plots provide a compelling visual summary of the resting behaviors, highlighting the differences betweensolitary and social resting states in sheep. This insight iscrucial for understanding sheep behavior in controlled en-vironments and has implications for animal welfare and themanagement of livestock. These UMAP visualizations elo-quently encapsulate the dichotomy between solitary and so-cial resting states among sheep. The implications of thisdata are profound, aligning with the grazing behavior find-ings and reinforcing the notion that sheep display more uni-form behaviors when solitary. Such insights are pivotal forthe realm of animal husbandry, particularly in the context ofenhancing livestock management and welfare practices.",
  ". Conclusion": "Our study presents a robust multimodal AI-based visionframework that integrates cutting-edge models for compre-hensive behavioral analytics applicable to precision live-stock farming.Through the analysis of a sample sheepdataset, we have showcased the utility of our frameworkin extracting detailed insights into various sheep activitiessuch as running, grazing, and resting. The application of ourframework has revealed fascinating observations that are ofsignificant value to the agricultural and farming communi-ties. For instance, the solitary grazing patterns of sheep ina controlled environment without apparent dangers suggestpotential adjustments in farm management practices. Theinsights into their resting patterns further emphasize the im-pact of social dynamics on animal behavior, which couldguide enhancements in livestock care and facility design.Similarly, our insights from sheep running videos validatethe finding that repetitive movements result in faster speed. However, the current dataset did not encompass certainactivities, such as milking, and these findings are based onbrief observational videos, limiting the scope of our anal-yses to report their health. Additionally, while we focusedon sheep, extending this framework to other species (e.g.cows) could provide a broader understanding of livestockbehaviors and welfare across different farming systems.In future, our goal is to apply this framework to diversespecies and environmental conditions. This will enable usto not only continue our exploration of animal activitiesbut also investigate aspects such as dietary habits in rela-tion to the nutritional content of forage. By correlating be-havior with nutritional intake, future work could offer guid-ance on pasture management to optimize feeding efficiencyand herd health.We believe AnimalFormer has the po-tential to revolutionise livestock monitoring by providingnon-invasive, in-depth behavioral analysis without any ad-ditional hardware (e.g. RFID-based animal tagging). Sucha multimodal vision framework is indispensable for advanc-ing precision farming operations, promoting animal wel-fare, and improving the productivity and sustainability ofthe agricultural sector.",
  "Shaun Barney, Satnam Dlay, Andrew Crowe, Ilias Kyriaza-kis, and Matthew Leach. Deep learning pose estimation formulti-cattle lameness detection.Scientific Reports, 13(1):4499, 2023. 3": "Alain Boissy and Bertrand Dumont. Interactions between so-cial and feeding motivations on the grazing behaviour of her-bivores: sheep more easily split into subgroups with familiarpeers. Applied Animal Behaviour Science, 79(3):233245,2002. 8 Mathilde Caron, Hugo Touvron, Ishan Misra, Herve Jegou,Julien Mairal, Piotr Bojanowski, and Armand Joulin. Emerg-ing properties in self-supervised vision transformers. arXivpreprint arXiv:2104.14294, 2021. 4",
  "Richard Cooper and Francoise Wemelsfelder. Qualitative be-haviour assessment as an indicator of animal emotional wel-fare in farm assurance. Livestock, 25(4):180, 2020. 1": "Jia Deng, Wei Dong, Richard Socher, Li-Jia Li, Kai Li,and Li Fei-Fei. Imagenet: A large-scale hierarchical imagedatabase. In 2009 IEEE conference on computer vision andpattern recognition, pages 248255. Ieee, 2009. 3 Alexey Dosovitskiy, Lucas Beyer, Alexander Kolesnikov,Dirk Weissenborn, Xiaohua Zhai, Thomas Unterthiner,Mostafa Dehghani, Matthias Minderer, Georg Heigold, Syl-vain Gelly, et al. An image is worth 16x16 words: Trans-formers for image recognition at scale. International Con-ference on Learning Representations, 2020. 2",
  "CM Dwyer. How has the risk of predation shaped the be-havioural responses of sheep to fear and distress?AnimalWelfare, 13(3):269281, 2004. 7": "Cheng Fang, Tiemin Zhang, Haikun Zheng, Junduan Huang,and Kaixuan Cuan. Pose estimation and behavior classifica-tion of broiler chickens based on deep neural networks. Com-puters and Electronics in Agriculture, 180:105863, 2021. 1 Jean-Bastien Grill, Florian Strub, Florent Altche, CorentinTallec, Pierre H. Richemond, Elena Buchatskaya, Carl Do-ersch, Bernardo Avila Pires, Zhaohan Daniel Guo, Moham-mad Gheshlaghi Azar, Bilal Piot, Koray Kavukcuoglu, RemiMunos, and Michal Valko. Bootstrap your own latent: A newapproach to self-supervised learning, 2020. 4 Yaning Han, Ke Chen, Yunke Wang, Wenhao Liu, ZhouweiWang, Xiaojing Wang, Chuanliang Han, Jiahui Liao, KangHuang, Shengyuan Cai, et al. Multi-animal 3d social poseestimation, identification and behaviour embedding with afew-shot learning framework. Nature Machine Intelligence,pages 114, 2024. 3",
  "Lei Ke, Mingqiao Ye, Martin Danelljan, Yifan Liu, Yu-WingTai, Chi-Keung Tang, and Fisher Yu. Segment anything inhigh quality, 2023. 1, 3, 5": "Nathan A. Kelly, Bilal M. Khan, Muhammad Y. Ayub,Abir J. Hussain, Khalil Dajani, Yunfei Hou, and Wasiq Khan.Video dataset of sheep activity for animal behavioral analy-sis via deep learning. Data in Brief, 2024(110027), 2024.Under a Creative Commons license. 1, 3 Alexander Kirillov, Eric Mintun, Nikhila Ravi, Hanzi Mao,Chloe Rolland, Laura Gustafson, Tete Xiao, Spencer White-head, Alexander C. Berg, Wan-Yen Lo, Piotr Dollar, andRoss Girshick. Segment anything, 2023. 5 Shilong Liu, Zhaoyang Zeng, Tianhe Ren, Feng Li, HaoZhang, Jie Yang, Chunyuan Li, Jianwei Yang, Hang Su, JunZhu, and Lei Zhang. Grounding dino: Marrying dino withgrounded pre-training for open-set object detection, 2023. 1,3, 4 Wolfgang Lutz and Samir K C. Dimensions of global pop-ulation projections: what do we know about future popula-tion trends and structures?Philosophical Transactions ofthe Royal Society B: Biological Sciences, 365(1554):27792791, 2010. 1 James B MacQueen. Some methods for classification andanalysis of multivariate observations. Proceedings of the fifthBerkeley symposium on mathematical statistics and proba-bility, 1(14):281297, 1967. 5 Markus Marks, Qiuhan Jin, Oliver Sturman, Lukas vonZiegler, Sepp Kollmorgen, Wolfger von der Behrens, ValerioMante, Johannes Bohacek, and Mehmet Fatih Yanik. Deep-learning-based identification, tracking, pose estimation andbehaviour classification of interacting primates and mice incomplex environments. Nature machine intelligence, 4(4):331340, 2022. 1, 3",
  "Leland McInnes, John Healy, and James Melville. Umap:Uniform manifold approximation and projection for dimen-sion reduction. arXiv preprint arXiv:1802.03426, 2018. 5": "Jeffrey S Mogil, Daniel S Pang, Giorgia G S Dutra, andChristine T Chambers. The development and use of facialgrimace scales for pain measurement in animals.Neuro-science & Biobehavioral Reviews, 116:480493, 2020. 1 Daniel Mota-Rojas, Donald M Broom, Agustn Orihuela,Antonio Velarde, Fabio Napolitano, and Mara Alonso-Spilsbury. Effects of human-animal relationship on animalproductivity and welfare. Journal of Animal Behaviour andBiometeorology, 8:196205, 2020. 1"
}