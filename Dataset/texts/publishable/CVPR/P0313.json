{
  "Abstract": "This paper proposes a novel task named 3D part group-ing.Suppose there is a mixed set containing scatteredparts from various shapes. This task requires algorithmsto find out every possible combination among all the parts.To address this challenge, we propose the so called Gradi-ent Field-based Auto-Regressive Sampling framework (G-FARS) tailored specifically for the 3D part grouping task. Inour framework, we design a gradient-field-based selectiongraph neural network (GNN) to learn the gradients of a logconditional probability density in terms of part selection,where the condition is the given mixed part set. This in-novative approach, implemented through the gradient-field-based selection GNN, effectively captures complex relation-ships among all the parts in the input. Upon completionof the training process, our framework becomes capableof autonomously grouping 3D parts by iteratively selectingthem from the mixed part set, leveraging the knowledge ac-quired by the trained gradient-field-based selection GNN.Our code is available at:",
  ". Introduction": "Assuming that you purchase multiple unassembled IKEAchairs and carelessly mix all the parts together, it canquickly become a nightmare to sort through and assembleeach chair. The task can be especially daunting if the piecesfrom different chairs are mixed together, making it chal-lenging to identify the correct components for each chair.Similarly, in the field of archaeology, recovering brokencultural relics can be incredibly difficult, as the fragmentsare often intermingled with the pieces from other relics.In such cases, archaeologists must carefully separate themixed fragments and piece them together to reconstruct theoriginal relics. In a similar vein, the field of LEGO auto-matic assembly requires AI agents to select different com-binations of parts from massive LEGO blocks and assemblethem into a shape. All of these examples contain two goals: The first goal is to identify the correct combinations fromthe mixed part set (i.e. part grouping) and the second oneis to assemble them into reasonable shapes (i.e. part assem-bly). To achieve these two objectives, algorithms must firstbe capable of comprehending the geometric relationshipsamong all the parts. Next, they should be able to separatethe parts by their shapes, and finally, assemble the chosenparts into reasonable shapes.For the part assembly, previous works have researchedsome methods for assembling a given group of parts. DGL-Net is the first work to explore the assembly problemwithout prior instruction. The DGL-Net algorithm can pre-dict the 6-DoF poses for each input part, enabling trans-lation and rotation of the parts to their expected positions.RGL-Net is another part assembly work that utilizessequential information among all the input parts. By assem-bling shapes in a specific order (e.g., top-to-bottom), RGL-Net achieves more accurate assembly. IET is a recentlyproposed algorithm that utilizes an instance encoded trans-former and self-attention mechanisms to enhance the networks assembly ability.However, part grouping still remains an unsolved prob-lem. As previously mentioned, the goal of part grouping isto use algorithms to identify all possible combinations in amixed part set. To address this, we introduce the 3D partgrouping task. The definition of this task is presented in. Suppose we have a set of mixed parts from N dif-ferent shapes. The 3D part grouping task mandates the al-gorithms to process all these parts and categorize them intogroups based on their originating shapes.Our proposed task 3D part grouping is challenging fortwo main reasons. First, the algorithms must understand therelationships among all the parts. Second, the exact numberof potential groups, N, is unknown. This uncertainty com-plicates both the problem formulation and the creation ofeffective algorithms. To tackle these challenges, we intro-duce Gradient-Field-based Auto-Regressive Sampling (G-FARS) framework in this paper. This framework integratesa gradient-field-based graph neural network for the encodedparts, aiding in understanding the relationships among all",
  "Shape": ". The definition of our proposed 3D part grouping task. Assuming we have a set which contains mixed parts from N shapes. Ourgoal in this task is to use a grouping algorithm to separate these mixed parts and group them by their respective shapes. the input parts. Moreover, it can auto-regressively samplenew groups from the mixed set, enabling the algorithm toidentify all the groups, regardless of the number of poten-tial groups N. More details about G-FARS are in Sec. 4.Our proposed task and algorithm hold significant po-tential for the industrial world. In manufacturing environ-ments, where parts from multiple products are intermixed,a robotic system utilizing this method can aid in automatedsorting, leading to more efficient production lines. The 3Dpart grouping algorithm can also generalize to other do-mains.For instance, in recycling facilities, this methodcould help segregate mixed materials into appropriate cat-egories for processing, thus improving waste managementpractices. Our contributions are concluded as follows:",
  "Combinatorial Optimization is an area that studies the taskof finding the best object from a finite set of objects. The": "3D part grouping task aims to identify every possible com-bination in a given set of parts. From this perspective, the3D part grouping task aligns with combinatorial optimiza-tion problems, and we can glean insights from combinato-rial optimization algorithms. Classic algorithmsResearch in combinatorial optimiza-tion can be traced back to the 1960s. Some hallmark al-gorithms include Dijkstras shortest path algorithm and Kruskals minimum spanning tree algorithm. These algorithms provided a robust foundation forunderstanding the structure and intricacies of combinatorialproblems. Heuristic methodshave introduced a new dimension tocombinatorial optimization. Genetic algorithms , inspired by natural selection processes, stand as promi-nent methods for these problems.They employ mecha-nisms like mutation, crossover, and selection to pinpointsolutions. Another significant method is Ant Colony Op-timization , which emulates the behavior ofants when finding a path from their colony to food sources. Reinforcement learning-based methodsRecently, somereinforcement learning-based methods also demonstratetheir ability in combinatorial optimization problems .The basic idea behind these methods is to learn a policy tosearch the solution space.",
  "Graph neural networksare also making their mark inaddressing combinatorial optimization problems.They": "transpose the problem graph into continuous space, aidingin the prediction of optimal combinatorial solutions. Theessence of graph neural networks revolves around the useof message passing and aggregation operations on nodesand edges to unearth and understand the graphs layout.Graph Convolutional Networks (GCNs) are a notable typeof graph neural network that applies convolutional opera-tions on graphs, capturing local and global structural nu-ances .Edge Convolution, another variant, focuseson the features of edges between nodes, amplifying themodels capacity to depict complex graphs .",
  ". 3D Part Assembly": "Although this work does not consider the task of part as-sembly, it is still worthwhile to review these works, as theyprovide insights into identifying the relationships among theinput parts.3D part assembly is a task proposed by Huang et al. which aims to assemble separate parts into a complete shapewithout any external guidance. The goal of 3D part assem-bly is to predict a translation vector and a rotation vectorfor each part . We introduce two categories of3D part assembly algorithms, graph neural network basedalgorithms and transformer based algorithm: Graph neural network based methodsHuang et al. propose Dynamic Graph Learning algorithm to achieve thegoal of 3D part assembly task. DGL-Net includes a Point-Net for part feature extraction. They also propose an it-erative graph neural network backbone for message passingamong all the part features. Besides, they propose dynamicrelation reasoning modules to learn the relationship amongall the encoded parts. They also have dynamic part aggrega-tion modules for more direct information exchanges amonggeometrically-equivalent parts.RGL-Net, described in , is also a GNN-based algo-rithm designed for the part assembly task. The key conceptbehind RGL-Net is sequential assembly, where the separateparts are assembled in a specific order, such as a top-to-down approach. In particular, the authors employ GRUs to learn the order information, which significantly improvesthe assembling performance. However, one potential limi-tation of RGL-Net is that its performance may be subopti-mal in non-ordered assembly settings. In other words, whenthe parts are assembled in a random or unstructured order,RGL-Net may not perform as well as it does in the orderedassembly setting. Transformer based methodZhang et al. propose amethod that employs a transformer-based framework andself-attention mechanism to model the relationships be-tween different parts, while resolving the ambiguity issue using instance encoding. The method includes four mod-ules: a shared PointNet for feature extraction, a transformerencoder for reasoning the relationships between parts, anMLP predictor for pose estimation, and an instance encoderfor handling the ambiguity between parts. The experimen-tal results show that IET achieves better performance thanDGL-Net and RGL-Net.",
  ".BackgroundsofScore-basedModelingThrough Stochastic Differential Equations": "Our proposed G-FARS is built upon the score-based mod-eling through stochastic differential equations (SDEs). It isnecessary to discuss the basic principles of the score-basedmodeling before introducing G-FARS.Score-based modeling through SDEs is a recentlyproposed technique for generation tasks. The basic idea be-hind this modeling method is estimating the gradients of thedata distribution. The new data can be generated by sam-pling the estimated data distribution. Score-based modelswith SDEs are trained to estimate a time-dependent scoreS(x(t), t) of a given probability density function pt(x),which can be described by S(x(t), t) = x log pt(x).To successfully achieve a score-based model, we need toset up a diffusion process which can be represented by acontinuous-time stochastic process {x(t) Rd}Tt=0, wheret [0, T]. We choose a diffusion process such that x(0) p0 and x(T) pT , where p0 is the data distribution, pTis the prior distribution, and both are uncorrelated after theperturbation by the diffusion process. We can describe ourdiffusion process by using the following equation:",
  ".G-FARS:Gradient-Field-basedAuto-Regressive Sampling Framework": "We propose a model, denoted as G-FARS, to solve the 3Dpart assembly problem, the workings of which are illus-trated in . Before we discuss our framework, we in-troduce the definitions of the mathematical symbols first. Mathematical symbol definitionsLet n denote the indexfor iteration, and Pn represents the mixed part set at itera-tion n. Naturally, P0 is the initial input part set before anyprocessing by the algorithm. Each part in the mixed part setis a point cloud which has the dimension of 1000 3. TheBoolean vector cn is used for part selection. At iteration n,this vector determines how to select parts from the mixedpart set Pn to form a new group n. The ultimate goal of ouralgorithm is to identify all possible groups. Working principleOur framework consists of two keycomponents: a PointNet and a gradient-field-based selec-tion graph neural network (GNN). The PointNet is em-ployed to encode all the input parts. The gradient-field-based selection GNN is constructed with Edge Convolutionlayers , which enables the framework to understand therelationships among all the input parts. We can use this net-work to sample new selection vectors for the encoded parts.Our framework operates as an auto-regressive algorithm.Assuming we are at iteration n, we begin with using thePointNet to obtain the encoded per-part features F nP . Fol-lowing that, our gradient-field-based selection GNN is usedto sample a selection vector cn. The sampled vector cn al-lows us to identify group n, while the complementary vectorcn (obtained via a bitwise NOT operation) determines theunselected parts. These unselected parts then form the inputparts Pn+1 for the subsequent iteration n + 1. Auto-Regressive SamplingAs stated in the Introductionsection, one critical issue in the 3D part grouping task is thatthe number of groups N is not certain. Our framework isable to solve this problem as it can auto-regressively sam-ple new groups from the mixed part set. As stated in theworking principle part, our framework is able to sample anew group at each iteration. In this case, our algorithm doesnot care the number N in the mixed part set, and it onlystops when the mixed part set is cleaned or the algorithmreaches the maximum iterations.",
  "We have already discussed the main working principle ofG-FARS. The problem remaining here is how to obtain": "the key component (i.e., the gradient-field-based selectiongraph neural network Sc) in our proposed framework. Inour designed GNN, the nodes are the per-part features F npencoded by the PointNet. These nodes are fully connectedto facilitate message passing. The learning objectiveDesigning a suitable learning ob-jective for the gradient-field-based selection graph is key toachieving success in auto-regressive sampling. Recallingthe principle of G-FARS, we expect our designed model topredict the correct selection for the input parts Pn at itera-tion n. To achieve this, we design our gradient-field-basedGNN to learn the distribution of selections conditioned onthe input parts. Mathematically, our gradient-field-based se-lection GNN learns a conditional probability p(cn | F np ).After the training process, the GNN learns all the ways ofselecting for the mixed part set. In this case, at each it-eration, we can use the trained GNN to sample a correctselection for the mixed part set.",
  ". Training": "After confirming our learning objective, our next task is toachieve our goal of estimating the distribution p(cn | F np ).Specifically, our gradient-field-based selection GNN is de-signed to approximate the gradients of the target log con-ditional probability density. Mathematically, we expect ourmodel to satisfy Sc = c log pt(cn | F nP ).To achieve this goal, we basically follow the trainingsteps proposed by Song et al. , and we have discussedthis in the Backgrounds section (Sec. 3). However, we stillneed to modify the training objective function to the condi-tional form. We present the general form of the loss func-tion in the following equation:",
  "(4)": "where x(0) is the original data, x(t) is the perturbed data, yrepresents the condition and t is time index. The next stepis to train G-FARS through Algorithm 1. In the trainingalgorithm, we first use PointNet to get the per-part featureF nP . Following that, we sample time index t from the uni-form distribution U(0, T). Then the cn(t) can be obtainedthrough the perturbation. After that, we calculate the lossfunction and perform back propagation. At the end of theiteration, we optimize the parameters for both PointNetand Sc.",
  "The rest parts will be the next input parts +1. Stop algorithm if +1 is empty, or reaches the maximum iteration": "NOT . The auto-regressive sampling procedure of our proposed framework. First, we obtain the per-part feature by using a PointNet to encode all the input parts Pn at the iteration n. Then, we use the gradient-field-based (G-F-based) selection GNN to sample aselection vector cn to obtain part group n, and use cn to get the rest parts Pn+1. Pn+1 will be the next input parts at the next iteration.The auto-regressive sampling stops when Pn+1 is empty, or n reaches the maximum iteration.",
  ": end for11: return G-F Selection GNN Sc, PointNet;": "Predictor-Corrector (PC) as our sampler. We demon-strate a simplified version in Algorithm 2. This method en-sures that the generated samples are close to the desired dis-tribution. Since our application requires a conditional PCsampler, we have provided the algorithm in 2. After thesampling procedure, we use a threshold Th = 0.5 to trans-form the selection vector cn(0) to a boolean vector.",
  ": end for9: return the sampled result cn(0)": "chairs, 8,218 tables and 2,207 lamps from PartNet inour experiments. We apply random mixing method to cre-ate our mixed part sets. We illustrate our mixing method in. First, we randomly selected N shapes from the Part-Net dataset (N is also a random number). Next, we mixedall the parts into a single part set. Finally, we shuffle allthe parts to obtain our mixed set. For more statistics of ourmixed datasets, please refer to our Supplementary.",
  "|P G|(5)": "where P is the predicted group, and G is the ground truthgroup. In our task, |P G| represents the number of partswhich are included by both P and G, while |P G| repre-sents the total number of unique parts in both P and G. Inour evaluation program, each ground truth group is matchedwith the predicted group which has the highest Jaccard sim-ilarity.",
  ". Baselines": "As 3D part grouping is a newly proposed task, there areno existing baselines specific to this task. Therefore, wepropose some alternative methods for comparisons: GRU-Mask: We propose GRU-Mask which uses a GRUto generate a binary mask for the given part set. This maskindicates how to select parts to form groups. GRU-Maskis inspired by RNN-based methods . More detailsabout GRU-Mask can be found in the supplementary. Comp-Net: Comp-Net is another method proposed byus, capable of classifying whether two parts can begrouped to form a shape. Our idea is inspired by RL-based approaches . We provide more informationabout Comp-Net in our supplementary. Variants of G-FARS: Inspired by ,we propose three variants of G-FARS: G-FARS-CG, G-FARS-R, and G-FARS-T. We use the same training andinference algorithms (i.e., Auto-Regressive sampling) asG-FARS in these variants. G-FARS-CG applies a GNNfor message passing among all the encoded parts. Be-sides, it also includes a separate MLP to learn the scorefunction for part selection. G-FARS-R and G-FARS-Tuse a ResNet and a transformer to learn the se-lection score function respectively. For these variants, weemploy a score function modeling way that differs fromthe one used in G-FARS, which is introduced in the sup-plementary materials.",
  "TableChairLamp": ". The qualitative comparisons. To intuitively demonstrate the effect of grouping, we rotate and translate all the parts by using theirground truth poses after the grouping procedure. The results show that only G-FARS is able to correctly group the 3D parts. Some baselineseven predict an incorrect number of groups (e.g., Comp-Net). Due to the page limit, we here only present the results of G-FARS and thetwo most competitive baselines (i.e., GRU-Mask and Comp-Net). We have included the full comparison and an additional qualitativecomparison figure in the supplementary materials. About hyper-parametersOur framework contains manyhyper-parameters. For the sampler and the sampling steps,we discuss them in . For other details about hyper-parameters, please refer to our supplementary.",
  ". Comparisons and Discussions": "We present the quantitative comparisons in . Over-all, our framework G-FARS outperforms other baselines bya large margin on all datasets. This proves the effective-ness of our proposed G-FARS. We also demonstrate thequalitative results in (the full comparison is in thesupplementary). To intuitively show our performance ofthe grouping results, we rotate and translate the parts in allthe groups with their ground truth poses after the groupingprocedure. Please Note that the rotation and translationare only used for demonstration purpose. We DO NOTuse the ground truth poses information in the groupingprocedure or the training procedure. The figure showsthat our G-FARS is able to group most of the mixed partsets. However, the other baselines hardly manage to predictthe correct groups accurately. Besides these experiments,we also demonstrate category mixing testing, and general-ization testing to unseen categories in the supplementary.These tests further prove the effectiveness of G-FARS.",
  ". Ablation Study": "To further prove the effectiveness of our algorithm, we con-ducted ablation studies. These experiments were carried outon the Chair dataset. Our ablation experiments comprisetwo parts: architecture ablation (see ) and samplingablation (see ). In the architecture ablation, we removed two key com-ponents from our G-FARS. For G-FARS w/o GF, we usea deterministic loss (i.e., Binary Cross Entropy) instead ofa score-matching loss (refer to Equation 4) to train anetwork with the same architecture, adding a Sigmoid acti-vation at the output. In the case of G-FARS w/o Graph, wereplace the GNN with an MLP to learn Sc. The results in prove the effectiveness of both modules. For the sampling ablation, we propose a variant of ourG-FARS framework, where the sampler in our frameworkis replaced by Euler-Maruyama (EM) sampler . Thetable shows that the performance of PC sampler is betterthan the performance of the EM sampler. The main rea-son why PC sampler outperforms the EM sampler is thatthe PC sampler uses both the numerical SDE solver and theLangevin MCMC as the corrector, while the EM sampleronly contains numerical SDE solver. The Langevin MCMC",
  "PC": "1000.658 / 0.6080.568 / 0.5590.6 / 0.5822000.827 / 0.7920.736 / 0.7290.77 / 0.7593000.816 / 0.7820.734 / 0.7240.764 / 0.7524000.826 / 0.7910.74 / 0.7330.771 / 0.7615000.828 / 0.7930.753 / 0.7440.781 / 0.7686000.833 / 0.7970.747 / 0.740.779 / 0.767 . The ablation study for samplers and sampling steps. Theablation is conducted on the Chair dataset. We show both the sin-gle set average (before the slash) and overall average (after theslash) results in the table.",
  "We surprisingly find that our algorithm is able to achievethe application of noisy part removal in a zero-shot man-": "ner. We demonstrate this application in . Assume youhave a set of parts which belongs to a chair. However, youcarelessly mix some noisy parts into this set, and you wantto remove these parts. Our framework G-FARS can achieveyour goal. The framework can directly output the correctselection for the parts of your chair.",
  ". Conclusion and Future Work": "In conclusion, we have introduced a novel task termed 3Dpart grouping, which entails identifying all possible com-binations from a mixed set. To address this, we began byrandomly mixing shapes from PartNet to construct ourtraining and testing datasets. Subsequently, we unveiled aunique framework named G-FARS to fulfill our groupingobjective. We validated our method using a series of bench-marks, illustrating that our algorithm displays commend-able performance on the introduced task. Future WorkOne constraint of our study is its confine-ment to virtual environments. Moving forward, we aim toinvestigate the viability of our proposed technique in real-world settings. As an example, our algorithm could be inte-grated into a robotic system, allowing robots to discern allfeasible combinations from a real mixed part set.",
  ". The detailed statistics of our mixed part datasets": "Statistics for the Number of PartsWe present the de-tailed statistics for the number of parts in the constructedmixed part sets in . In this figure, the statistics forboth training and testing datasets of the three shapes areshown. The horizontal axis represents the number of partsin a single mixed part set, while the vertical axis indicatesthe quantity of the corresponding part sets in the datasets.For the chair and table datasets, the maximum number ofparts exceeds 50; however, for the lamp dataset, this num-ber is only 30. Most part sets in the chair and table datasetscontain 10 to 35 parts, while the majority of part sets in thelamp dataset include 5 to 17 parts.",
  "In this baseline, we employ the same 3D encoding tech-nique (i.e., PointNet ) as G-FARS uses. Following the": "PointNet, we utilize a GRU to sequentially encode the in-put parts. The GRU enables us to capture the relationshipsamong all parts. Finally, we apply an MLP to generate amask that represents all the selection methods for the parts.The quantitative and qualitative comparisons demon-strate that this method achieves the goal of 3D part group-ing to some extent. It can generate all the selection vectorswithout relying on auto-regressive inference. However, adrawback of this method is the necessity to predeterminethe output size of the MLP during network design, whichlimits the number of groups to this predetermined number.",
  "B.2. Comp-Net": "The idea of Comp-Net is to compare two parts and identifywhether they can be grouped together. To implement thisconcept, we employ a dual PointNet structure. The firstPointNet encodes all the input parts, while the second oneis tasked with the goal of part comparison. The output ofthe second PointNet is a boolean value, indicating whethertwo parts can be grouped together.Based on the results discussed in the main paper and sup-plementary materials, we see that this method is a feasibleapproach for the 3D part grouping task. However, a disad-vantage of this approach is that Comp-Net is only trainedto compare any two parts. This means it struggles to un-derstand the relationships among multiple parts (more thantwo parts).",
  "B.3. Variants of G-FARS": "We present three variants of G-FARS in our main pa-per: G-FARS-CG, G-FARS-R, and G-FARS-T. As statedin the main paper, we modify the approach for modelingthe score function for these variants. Specifically, we at-tempt to model the score function as S = c log pt(cmn |GNN(F nP , fm)), where fm represents the encoded featurefor the mth part in the part set, and cmn denotes the corre-sponding selection boolean value for this single part. TheGNN is implemented using an EdgeConv-based structure.G-FARS-CG, G-FARS-R, and G-FARS-T apply an MLP,ResNet , and Transformer , respectively, to learnthe new score function. In these variants, we separate theGNN from the score function, aiming to determine whetherthe G-FARS framework can be effectively adapted to scorefunctions modeled in this manner. Furthermore, we seek toexplore whether applying better architectures can enhancethe networks performance under this new modeling ap-proach.",
  "D.1. Category Mixing Testing": "In this experiment, we mix all three categories (chair, ta-ble, and lamp) and test the performance of G-FARS on themixed-category dataset. The results are shown in .Surprisingly, we find that the performance on this mixed-category dataset is even better than that on single-categorydata. We infer that this improvement is due to two main rea-sons: 1. The mixing of categories results in a larger dataset,which may lead to better generalization; 2. Parts becomemore distinguishable when mixed together (e.g., chair partsversus lamp parts).",
  ". More qualitative results of noisy part removal task. Ourframework can remove the unnecessary parts from the given set ofparts": "the results of which are shown in . In this exper-iment, the model is trained on the chair dataset but testedon the table dataset. Although the performance is lowerthan that of the model trained and tested on the same ta-ble dataset, it is still capable of grouping parts from unseen",
  "D.3. More Qualitative Results": "In , we present the full comparison for the ofthe main paper. The full results indicate that the baselinemethods struggle to accurately group the 3D parts. Besides,we also present additional qualitative comparisons in .The figure shows that our framework is able to correctlygroup most part sets, while it is difficult for other baselinesto obtain the correct groups. This result proves the effec-tiveness of our proposed method.",
  "Shifen Han and Li Xiao. An improved adaptive genetic al-gorithm. In SHS Web of Conferences, page 01044. EDP Sci-ences, 2022. 2": "V Haripriya et al.The performance optimization of ap-proximate minimum spanning tree for the different mobil-ity model. In 2023 International Conference on DistributedComputing and Electrical Circuits and Electronics (ICD-CECE), pages 16. IEEE, 2023. 2 Kaiming He, Xiangyu Zhang, Shaoqing Ren, and Jian Sun.Deep residual learning for image recognition. In Proceed-ings of the IEEE conference on computer vision and patternrecognition, pages 770778, 2016. 6, 9",
  "John H Holland. Genetic algorithms. Scientific american,267(1):6673, 1992. 2": "Jialei Huang, Guanqi Zhan, Qingnan Fan, Kaichun Mo, LinShao, Baoquan Chen, Leonidas J Guibas, Hao Dong, et al.Generative 3d part assembly via dynamic graph learning. Ad-vances in Neural Information Processing Systems, 33:63156326, 2020. 1, 3 Nadira Jasika, Naida Alispahic, Arslanagic Elma, KurtovicIlvana, Lagumdzija Elma, and Novica Nosovic. Dijkstrasshortest path algorithm serial and parallel execution perfor-mance analysis. In 2012 proceedings of the 35th interna-tional convention MIPRO, pages 18111815. IEEE, 2012. 2 Jehn-Ruey Jiang, Hsin-Wen Huang, Ji-Hau Liao, and Szu-Yuan Chen. Extending dijkstras shortest path algorithm forsoftware defined networking. In The 16th Asia-Pacific Net-work Operations and Management Symposium, pages 14.IEEE, 2014.",
  "Nina Mazyavkina, Sergey Sviridov, Sergei Ivanov, andEvgeny Burnaev. Reinforcement learning for combinatorialoptimization: A survey. Computers & Operations Research,134:105400, 2021. 2": "Kaichun Mo, Shilin Zhu, Angel X Chang, Li Yi, SubarnaTripathi, Leonidas J Guibas, and Hao Su. Partnet: A large-scale benchmark for fine-grained and hierarchical part-level3d object understanding. In Proceedings of the IEEE/CVFconference on computer vision and pattern recognition,pages 909918, 2019. 2, 5, 8, 9 Shentong Mo, Enze Xie, Ruihang Chu, Lewei Yao, LanqingHong, Matthias Niener, and Zhenguo Li. Dit-3d: Exploringplain diffusion transformers for 3d shape generation. arXivpreprint arXiv:2307.01831, 2023. 6 Abhinav Narayan, Rajendra Nagar, and ShanmuganathanRaman. Rgl-net: A recurrent graph learning framework forprogressive part assembly. In Proceedings of the IEEE/CVFWinter Conference on Applications of Computer Vision,pages 7887, 2022. 1, 3 Charles R Qi, Hao Su, Kaichun Mo, and Leonidas J Guibas.Pointnet: Deep learning on point sets for 3d classificationand segmentation. In Proceedings of the IEEE conferenceon computer vision and pattern recognition, pages 652660,2017. 3, 5, 9",
  "Chence Shi, Shitong Luo, Minkai Xu, and Jian Tang. Learn-ing gradient fields for molecular conformation generation.In International Conference on Machine Learning, pages95589568. PMLR, 2021. 6": "Yunsheng Shi, Zhengjie Huang, Shikun Feng, Hui Zhong,Wenjin Wang, and Yu Sun. Masked label prediction: Uni-fied message passing model for semi-supervised classifica-tion. arXiv preprint arXiv:2009.03509, 2020. 1 Yang Song, Jascha Sohl-Dickstein, Diederik P Kingma, Ab-hishek Kumar, Stefano Ermon, and Ben Poole. Score-basedgenerative modeling through stochastic differential equa-tions. arXiv preprint arXiv:2011.13456, 2020. 3, 4, 5, 7,8, 11",
  "Mandavilli Srinivas and Lalit M Patnaik. Genetic algorithms:A survey. computer, 27(6):1726, 1994. 2": "Shubham Tulsiani, Hao Su, Leonidas J Guibas, Alexei AEfros, and Jitendra Malik. Learning shape abstractions by as-sembling volumetric primitives. In Proceedings of the IEEEConference on Computer Vision and Pattern Recognition,pages 26352643, 2017. 6 Ashish Vaswani, Noam Shazeer, Niki Parmar, Jakob Uszko-reit, Llion Jones, Aidan N Gomez, ukasz Kaiser, and IlliaPolosukhin. Attention is all you need. Advances in neuralinformation processing systems, 30, 2017. 1, 6, 9",
  "Rufeng Zhang, Tao Kong, Weihao Wang, Xuan Han, andMingyu You. 3d part assembly generation with instance en-coded transformer. IEEE Robotics and Automation Letters,7(4):90519058, 2022. 1, 3": "Xiangbing Zhou, Hongjiang Ma, Jianggang Gu, HuilingChen, and Wu Deng. Parameter adaptation-based ant colonyoptimization with dynamic hybrid mechanism. EngineeringApplications of Artificial Intelligence, 114:105139, 2022. 2 Chuhang Zou, Ersin Yumer, Jimei Yang, Duygu Ceylan, andDerek Hoiem. 3d-prnn: Generating shape primitives withrecurrent neural networks. In Proceedings of the IEEE In-ternational Conference on Computer Vision, pages 900909,2017. 6"
}