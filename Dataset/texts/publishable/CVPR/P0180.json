{
  "Abstract": "In this report, we present our solution for the seman-tic segmentation in adverse weather, in UG2+ Challengeat CVPR 2024. To achieve robust and accurate segmenta-tion results across various weather conditions, we initializethe InternImage-H backbone with pre-trained weights fromthe large-scale joint dataset and enhance it with the state-of-the-art Upernet segmentation method. Specifically, weutilize offline and online data augmentation approaches toextend the train set, which helps us to further improve theperformance of the segmenter. As a result, our proposed so-lution demonstrates advanced performance on the test setand achieves 3rd position in this challenge.",
  ". Introduction": "Semantic segmentation boasts a rich history of applica-tions in autonomous driving, robotics,and scene understanding.Although contemporarymethods have demonstrated remarkable efficacy on stan-dard benchmarks, i.e. ADE20K, Cityscapes, real-world environments often present complexities and chal-lenges, such as adverse weather conditions.When con-fronted with images exhibiting visual degradations, specif-ically those captured under such unfavorable conditions,their performance correspondingly deteriorates.To address these issues, researchers have provideddatasets and methods aimed at studying the effects of natu-ral phenomena. However, due to the difficulty of capturingpaired datasets in controlled settings, existing datasets oftenrely on synthetic weather effects or include misalignmentsbetween degraded and clear-weather images in the underly-ing scene. Futher more, introduces the WeatherProofDataset, a semantic segmentation dataset specifically de-signed for weather-degraded scenes. Training on this paireddataset can significantly improve model performance in ad-verse weather conditions.The purpose of this challenge is to investigate weather . Overall Architecture of InternImage, where the core op-erator is DCNv3, and the basic block composes of layer normal-ization (LN) and feed-forward network (FFN) as trans-formers, the stem and downsampling layers follows conventionalCNNs designs phenomena in real-world scenarios and to inspire innova-tive advancements in semantic segmentation methods forimages affected by weather conditions.In this work, we address real-world complex scenariosby making targeted improvements in data processing, al-",
  "arXiv:2406.05837v1 [cs.CV] 9 Jun 2024": "gorithm design, and model optimization, achieving state-of-the-art segmentation performance. Our contributions areoutlined below: Data Augmentation: We utilize offline and online dataaugmentation approaches to extend the training set, whichhelps to further improve the performance of the seg-menter. Algorithm Fine-tuning: We employ large, foundationalmodel Internimage as our segmenter with UperNet as thebackbone network, which has led to drastically improvedperformance in the task of semantic segmentation. Model Optimization: We implement advanced modelfusion strategies, specifically by combining the results ofmultiple models through techniques such as voting, to re-fine model accuracy and robustness in weather-degradedscenes.",
  ". Encoder": "As shown in , Internimage is a new large-scale NN-based foundation model which effectively scalesto over 1 billion parameters and 400 million training im-ages and achieves comparable or even better performancethan state-of-the-art ViTs. Different from the recent CNNsthat focus on large dense kernels, InternImage takes de-formable convolution as the core operator, so that it not onlyhas the large effective receptive field required for down-stream tasks such as detection and segmentation, but alsohas the adaptive spatial aggregation conditioned by inputand task information. As a result, InternImage reduces thestrict inductive bias of traditional CNNs and makes it pos-sible to learn stronger and more robust patterns with large-scale parameters from massive data like ViTs. With its pow-erful object representation capabilities, Internimgage hasdemonstrated impressive performance on various represen-tative computer vision tasks. For example, InternImage-H has achieved an improvement of 89.6% top-1 accuracyon ImageNet , and achieves 62.9% mIoU and 65.4% mAPon the challenging downstream benchmarks ADE20K and COCO , respectively. Besides, its worth mention-ing that internimgage-H is one of the few open-source largemodels available. As a result, we have to implement it our-selves .",
  ". Decoder": "UPerNet is a widely adopted network architecture for se-mantic segmentation, which integrates the ideas of Pyra-mid Pooling Module (PPM) and Feature Pyramid Net-work (FPN) . It effectively fuses feature information from different scales, enhancing the segmentation capabil-ity of models for objects at various scales. It has achievedoutstanding performance on multiple segmentation bench-marks.Here, InternImage has been enhanced for UPerNetby incorporating layer normalization (LN) and feed-forward network (FFN) , and utilizing GELU asthe activation function.",
  ". Dataset": "The competitions dataset: WeatherProof dataset a seman-tic segmentation dataset with over 174.0K images. It is thefirst with high quality semantic segmentation labels, withaccurately aligned and paired clear and adverse weather im-ages for more accurate evaluation under controlled settings.The dataset includes 513 sets of images, each consisting of300 pairs of clean and adverse condition images. Addition-ally, we used 38 sets of images for the validation phase.",
  ". Data Augmentation": "Due to the limitations of the train set and the adverseconditions, we employ various data augmentation tech-niques,including both offline and online approaches. Theoffline data augmentation primarily focuses on modifyingthe contrast and brightness of the images, which effectivelyexpands the train set. During the training process, we applydifferent online data augmentation methods for better re-sults. We employ RandomCrop, RandomFlip and paddingas the data augmentation methods.",
  ". Final Results": "Our optimal model achieved superior performance on thevalidation set after 3500 iterations employing InternImage.Subsequently, we conducted hard voting on the output re-sults of this optimal model along with some closest models.The aggregated output achieved an mIoU of 0.4371 on thetest set. Detailed metrics for our ensemble model are pre-sented in , showcasing a significant enhancement insegmentation efficacy through the utilization of model fu-sion techniques, such as voting. Furthermore, visualizationsof select segmentation outputs are depicted in",
  "iter 30000.4040iter 35000.4198iter 40000.4184Voting results0.4371": "weather. To cope with the limitations of the dataset andadverse conditions, we employ offline and online data aug-mentation approaches to extend the train set, and utilize In-ternImage as our semantic segmenter with UperNet as thebackbone network. The results show that our proposed so-lution achieves outstanding performance on the test set inUG2+ Challenge 2024.",
  "Wonsuk Kim and Junhee Seok. Indoor semantic segmenta-tion for robot navigating on mobile. 2018 Tenth InternationalConference on Ubiquitous and Future Networks (ICUFN),pages 2225, 2018. 1": "Wei Li, Junhua Gu, Yongfeng Dong, Yao Dong, and JungongHan. Indoor scene understanding via rgb-d image segmenta-tion employing depth-based cnn and crfs. Multimedia Toolsand Applications, 79:35475 35489, 2019. 1 Tsung-Yi Lin, Michael Maire, Serge Belongie, James Hays,Pietro Perona, Deva Ramanan, Piotr Dollar, and C LawrenceZitnick. Microsoft coco: Common objects in context. InComputer VisionECCV 2014: 13th European Conference,Zurich, Switzerland, September 6-12, 2014, Proceedings,Part V 13, pages 740755. Springer, 2014. 2 Tsung-Yi Lin, Piotr Dollar, Ross Girshick, Kaiming He,Bharath Hariharan, and Serge Belongie.Feature pyra-mid networks for object detection.In Proceedings of theIEEE conference on computer vision and pattern recogni-tion, pages 21172125, 2017. 2",
  "Ilya Loshchilov and Frank Hutter. Decoupled weight decayregularization. arXiv preprint arXiv:1711.05101, 2017. 2": "Andres Milioto and C. Stachniss. Bonnet: An open-sourcetraining and deployment framework for semantic segmen-tation in robotics using cnns.2019 International Confer-ence on Robotics and Automation (ICRA), pages 70947100,2018. 1 Andres Milioto, Philipp Lottes, and C. Stachniss. Real-timesemantic segmentation of crop and weed for precision agri-culture robots leveraging background knowledge in cnns.2018 IEEE International Conference on Robotics and Au-tomation (ICRA), pages 22292235, 2017. 1",
  "Christos Sakaridis, Dengxin Dai, and Luc Van Gool. Seman-tic foggy scene understanding with synthetic data. Interna-tional Journal of Computer Vision, 126:973 992, 2017. 1": "Mennatullah Siam, Mostafa El Gamal, Moemen Abdel-Razek, Senthil Kumar Yogamani, and Martin Jagersand. Rt-seg: Real-time semantic segmentation comparative study.2018 25th IEEE International Conference on Image Process-ing (ICIP), pages 16031607, 2018. 1 Ashish Vaswani, Noam Shazeer, Niki Parmar, Jakob Uszko-reit, Llion Jones, Aidan N Gomez, ukasz Kaiser, and IlliaPolosukhin. Attention is all you need. Advances in neuralinformation processing systems, 30, 2017. 1, 2 Wenhai Wang, Jifeng Dai, Zhe Chen, Zhenhang Huang,Zhiqi Li, Xizhou Zhu, Xiaowei Hu, Tong Lu, Lewei Lu,Hongsheng Li, et al. Internimage: Exploring large-scale vi-sion foundation models with deformable convolutions. InProceedings of the IEEE/CVF Conference on Computer Vi-sion and Pattern Recognition, pages 1440814419, 2023. 2 Hengshuang Zhao, Jianping Shi, Xiaojuan Qi, XiaogangWang, and Jiaya Jia. Pyramid scene parsing network. InProceedings of the IEEE conference on computer vision andpattern recognition, pages 28812890, 2017. 2 Bolei Zhou, Hang Zhao, Xavier Puig, Sanja Fidler, AdelaBarriuso, and Antonio Torralba. Semantic understanding ofscenes through the ade20k dataset. International Journal ofComputer Vision, 127:302 321, 2016. 1, 2"
}