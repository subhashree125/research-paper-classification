{
  "Xiaopei Zhu1 Yuqiu Liu2 Zhanhao Hu3 Jianmin Li4 Xiaolin Hu4,5,6*": "1School of Integrated Circuits, Tsinghua University, Beijing, China2Department of Technology, Beijing Forestry University, Beijing, China3Department of Electrical Engineering and Computer Sciences, UC Berkeley, California, USA4Department of Computer Science and Technology, Institute for Artificial Intelligence,BNRist, Tsinghua University, Beijing, China5THBI, IDG/McGovern Institute for Brain Research, Tsinghua University, Beijing, China6Chinese Institute for Brain Research (CIBR), Beijing, China",
  "Abstract": "Infrared physical adversarial examples are of great sig-nificance for studying the security of infrared AI systemsthat are widely used in our lives such as autonomous driv-ing. Previous infrared physical attacks mainly focused on2D infrared pedestrian detection which may not fully man-ifest its destructiveness to AI systems.In this work, wepropose a physical attack method against infrared detec-tors based on 3D modeling, which is applied to a real car.The goal is to design a set of infrared adversarial stickers tomake cars invisible to infrared detectors at various viewingangles, distances, and scenes. We build a 3D infrared carmodel with real infrared characteristics and propose an in-frared adversarial pattern generation method based on 3Dmesh shadow. We propose a 3D control points-based meshsmoothing algorithm and use a set of smoothness loss func-tions to enhance the smoothness of adversarial meshes andfacilitate the sticker implementation. Besides, We designedthe aluminum stickers and conducted physical experimentson two real Mercedes-Benz A200L cars. Our adversarialstickers hid the cars from Faster RCNN, an object detector,at various viewing angles, distances, and scenes. The attacksuccess rate (ASR) was 91.49% for real cars. In compari-son, the ASRs of random stickers and no sticker were only6.21% and 0.66%, respectively. In addition, the ASRs of thedesigned stickers against six unseen object detectors suchas YOLOv3 and Deformable DETR were between 73.35%-95.80%, showing good transferability of the attack perfor-mance across detectors.",
  "*Corresponding author": ". Infrared attack effect on real cars. (a) Visible light viewof real cars. (b) Infrared view of real cars. C: clean car. R: carwith random shape stickers. A: car with adversarial stickers. Thenumbers above the bounding boxes are object confidence scores(%) with 0.6 threshold. Our adversarial stickers hid the car fromFaster RCNN at various viewing angles, distances and scenes. Incomparison, the clean car and the car with random shape stickerswere detected at the same situation.",
  "arXiv:2405.09924v1 [cs.CV] 16 May 2024": "vided into two categories, digital attacks which assume that the attackers can directly modify themodel input in the digital world, and physical attacks which assume that the attackerscan only modify the object or scene in the physical world.Physical attacks have attracted much attention because oftheir importance of assessing the security of real-world AIsystems.One type of physical attack is called infrared physicalattack . Infrared imaging is widely used inour daily lives, such as body temperature monitoring andautonomous driving. Since infrared cameras can functionnormally at night, they are becoming more and more im-portant in autonomous driving systems; so is their safety.Previous infrared physical attacks mainly focused on infrared pedestrians, and only two works conducted experiments on model cars. There iscurrently a lack of infrared attack research on real cars. Thereasons might be as follows. Compared with pedestrianswith constant body temperature, the temperature distribu-tions of real cars are more uneven (e.g., the temperature ofthe engine is much higher than that of other places), so theirinfrared characteristics are more complex than pedestrians.Compared with model cars without engines, real cars struc-tures and materials are very different from those of modelcars, so their infrared characteristics are also quite different.Besides, real car attacks require designing and manufactur-ing adversarial patterns on the entire 3D car surface, whichposes a great challenge to physical experiments. But we be-lieve that for the safety of autonomous driving cars, physicalreal car attack is worth in-depth investigation.The aforementioned two infrared model car attacks [31, 32] are only effective within limited viewing angles (e.g.,horizontal angles -30 30 and pitch angle 0). But wewant to implement a full-angle attack (the horizontal angles0 360, and pitch angle 0 90), so the attack anglescover an entire hemisphere surface, which is a challengingtask. We also notice that these methods are bothcase-by-case attacks, which needs to optimize an adversar-ial pattern for each image1, while our goal is to achievea universal attack which uses the same adversarial patternto attack detectors at various viewing angles, distances andscenes.Towards this goal, we propose an infrared physical at-tack method applied to a real car based on 3D modeling. Weaim to design a set of infrared adversarial stickers to makecars invisible to infrared detectors at various viewing an-gles (full-angle), distances and scenes. Since most current3D car models are visible-light models, and there is a lackof 3D infrared car models, we build a 3D infrared car modelwith real infrared characteristics at various viewing angles.For the generation of infrared adversarial pattern for stick-",
  "We found this by checking and running their official codes": "ers, we propose to optimize a 3D adversarial mesh at first,then project the shadow of 3D adversarial mesh to obtain a2D adversarial pattern, and finally attach the 2D adversar-ial pattern to the car surface. The motivation of this meshshadow attack (MSA) method is that we hope to find a bet-ter solution in a higher-dimensonal 3D space instead of di-rectly optimizing the 2D adversarial pattern. To improve thesmoothness of adversarial patterns and facilitate sticker im-plementation, we propose a 3D control points-based meshsmoothing algorithm and use a set of smoothing loss func-tions.For the physical implementation of infrared adversarialpatterns, we use an aluminum film which modifies the sur-face emissivity of the object instead of altering the surfacetemperature used by previous works . Likemany car stickers, the adversarial car stickers can be easilyattached on the car surface. The stickers are only 0.08mmthick and take up almost no space.To assess the safety of infrared detection in real au-tonomous driving scenes, we used two real Mercedes-BenzA200L cars. Physical experiments show that our infraredadversarial stickers made the real cars hide from the infrareddetector Faster RCNN at various viewing angles, variousdistances, and multiple scenes, with an attack success rate(ASR) of 91.49%. To the best our knowledge, this is the first3D multi-view physical infrared vehicle attack, and also thefirst infrared attack conducted on real cars.",
  ". Visible Light Physical Adversarial Attacks": "Huang et al. proposed a universal physical camou-flage (UPC) attack for object detectors. Zhang et al. proposed a vehicle camouflage for physical adversarial at-tack on object detectors in the wild. Wang et al. pro-posed the Dual attention suppression (DAS) attack to gen-erate adversarial vehicle camouflage in the physical world.Suryanto et al. generated the physical adversarial cam-ouflage by using a differentiable transformation network.Wang et al. proposed a 3D full-coverage vehicle cam-ouflage for physical adversarial attack (FCA). It is worthnoting that all above works are proposed for visible lightimages.",
  ". Infrared Physical Adversarial Attacks": "Zhu et al. proposed a bulb-based board to fool in-frared pedestrian detectors in the physical world. Zhu atal. proposed an infrared invisible clothing to hide frominfrared pedestrian detectors in the physical world. Wei etal. proposed the HotCold blocks to attack the infraredpedestrian detectors. Wei et al. proposed a physical ad-versarial infrared patch (AIP) based on a points-clusteringalgorithm. Wei et al. proposed a unified adversar- . Construction and optimization of real infrared car texture mapping. (a) Car mesh model. (b) Reorganized faces map. (c) Infraredcar texture map collected from real world. (d) Rendered infrared car model. ial patch (UAP) for physical attacks based on a boundary-limited shape optimization algorithm. It is worth noting thatall above methods are proposed for infrared pedestrian ormodel car attacks. There is currently a lack of research oninfrared real vehicle attacks in the physical world.",
  ". Car Sticker Attack Method": "Our method consist of several steps. First, we build a 3Dinfrared car model based on real infrared characteristics.Next, we use the infrared adversarial pattern generationmethod based on 3D mesh shadow. To make the 3D ad-versarial mesh smoother, we use a 3D control points-basedmesh smoothing algorithm and use a set of smoothnesslosses. Then we apply adversarial patterns to 3D infraredcar model and optimize the adversarial patterns. Finally, weintroduce the physical implementation method of infraredadversarial car stickers.",
  ". Building a 3D Infrared Car Model": "To simulate the infrared car attack realistically, we build a3D model based on the infrared characteristics of a real car.It is worth noting that our method can be applied to anytarget car, and we chose Mercedes-Benz A200L in our ex-periments, simply because one of the authors have this car.(a) shows the car mesh model Mcar. Next, we need",
  ". Schematic diagram of mesh shadow method": "to create a skin for the car model based on infrared pho-tos taken by an infrared camera FLIR T560. However, theinfrared photos captured by the camera are all 2D images,and the challenge is how to paste these 2D infrared im-ages onto the 3D car mesh model. First, we flatten all thefaces of 3D car mesh onto a 2D plane called faces map. Af-ter that, we use MAYA software to rearrange these faces todivide different areas, such as roof, doors, etc., as shown in(b). This process facilitates the alignment of realinfrared car images with the 3D car mesh.Subsequently, we crop the infrared images into differentparts based on the faces map ((b)) and paste thecropped images onto the 2D faces map, and then we get theinfrared texture map of the car, as shown in (c). SeeSupplementary Material (SM) for how these infrared pho-tos are taken, cropped and pasted. This process establishesa correspondence between the real infrared car images andthe 3D car mesh. The rendered infrared car model is shownin (d), which is built for a real car with engine run-ning.",
  ". Generation of 2D Shadow Based on 3D Mesh": "We aim to design infrared stickers with adversarial patternsto hide the cars from infrared detectors at various viewingangles (full-angle), distances, and scenes. We propose a 3Dadversarial mesh shadow attack (MSA) method to generatethe 2D infrared adversarial patterns for stickers. The moti-vation of MSA method is that we hope to find a better so-lution in a higher-dimensonal 3D space instead of directlyoptimizing the 2D adversarial pattern. The core of MSAmethod is to optimize a 3D adversarial mesh Madv at first,then project the shadow of 3D adversarial mesh to obtain a2D adversarial pattern Sadv, and finally attach the 2D ad-versarial pattern Sadv to the car surface. Note that the 3Dadversarial mesh Madv is different from the 3D car meshMcar in .1. The optimization variables include the3D mesh vertices coordinates V , the mesh shadowing an-gle , and the center point position P when pasting the 2Dpattern onto the cars texture map Torigin ().The shadowing operation refers to rendering the mesh",
  ". The overall pipeline of the proposed method": "Madv to a dark area while retaining the mesh contour (Fig-ure 3), and the dark area has a uniform grayscale valuewithin the contour. The grayscale value is consistent withthe infrared characteristics of the sticker we use. Let de-note this operation. If we want the car to have adversarialeffect at various viewing angles, we need to optimize Nadversarial meshes to generate N adversarial shadows ondifferent places of the car ():",
  ". 3D Control Points-Based Mesh Smoothing": "If we directly optimize the vertices coordinates V of themesh Madv, many peaks will appear on the mesh sur-face, which will make the shadow shape very complex andwill be difficult for the physical implementation of the ad-versarial shadow Sadv. Inspired by the Gaussian smooth-ing kernel and spline interpolation method, we propose asmoothing control algorithm for 3D mesh vertices. Its coreidea is to use some 3D control points C as anchor points,and the coordinate offsets of mesh vertices V are expressedas the weighted average of the coordinate offsets of C. Thecalculation details are described in SM.We use to denote the above transformation, and C(i)",
  ". Mesh Smoothness Loss Functions": "To further enhance the smoothness of 3D adversarial meshMadv and 2D adversarial pattern Sadv, we use a set of lossfunctions including: mesh normal consistency loss, meshedge loss, chamfer distance loss, and Laplacian smoothingloss. During the optimization process of 3D mesh Madv ,these functions guide the generation of a smoother adversar-ial mesh. A smoother 3D mesh Madv results in a smoother2D shadow pattern Sadv, which is beneficial for manufac-turing physical stickers based on the 2D shadow pattern.The mesh normal consistency loss computes the normalconsistency for each pair of neighboring faces, and mini-mizing it encourages the mesh surface to be smoother. Wesuppose that mesh Madv has a total of F faces. Let ni, nj(1 i, j F) represent the normal vector of any two adja-cent faces, then this loss function is described as:",
  "Lnorm = Average (1 cos(ni, nj)) .(3)": "Average is calculated between any pair of adjacent faces.The mesh edge loss computes mesh edge length regular-ization loss, and minimizing it encourages a reduction in theaverage edge length of the adversarial mesh. Suppose Madvhas a total of M edges, lk (k = 1, 2, ..., M) represents thelength of each edge, and this loss function is described as",
  ". Applying the 2D Shadow to 3D Car Model": "We apply the adversarial shadow Sadv to 3D infrared carmodel by changing its texture map Torigin. This simulatesthe process we paste the adversarial stickers to the car sur-face in the physical world. To facilitate physical implemen-tation, we simulate to paste the stickers onto the door, roof,front hood and rear of the car, which have wide ranges offlat area and are easy to paste. In each area, we paste oneor two adversarial shadow patterns (). To simulatereal-world perturbations, such as errors in cutting the ad-versarial stickers, variations in surface temperature on theadversarial stickers, and errors in the pasting positions, weintroduce random perturbations to the vertex coordinates Vof the adversarial mesh Madv, random noise to the patternSadv, random changes in grayscale values of Sadv, and ran-dom perturbations in the position P during the pasting ofSadv. This approach, known as the Expectation Over Trans-formation (EOT) algorithm , enhances the robustness ofour algorithm in real-world scenes.Next, we need to paste the adversarial patterns Sadv ontothe original car texture map Torigin. Let denote the past-ing operation. We establish a Cartesian coordinate systemwith the center point of Torigin as the origin. We use P (i)",
  "Tadv = S(i)adv, P (i), Torigin, i = 1, 2, ...N.(7)": "We use the differentiable renderer Pytorch3D to ren-der the adversarial texture map Tadv onto the surface of thecar mesh Mcar, resulting in the rendered infrared car im-ages with adversarial patterns, denoted as Iadv. Let de-note the rendering operation with parameters which in-clude the rendering distances and angles. Mathematically,this process can be expressed as:",
  ". Optimization of 3D Mesh Shadow Attack": "After we get the rendered infrared adversarial images Iadv,we input them into the target detector f. The output ofthe target detector typically includes object confidence fobj,class confidence fcls, and bounding box fbbox. Since ourgoal is to create a stealthy attack, meaning that our adversar-ial texture Tadv should make the infrared car hide from thedetector, we try to lower the object confidence fobj (Iadv)as much as possible. Therefore, the detection loss is definedas:",
  ". Physical Implementation Method": "We use aluminum films to make adversarial car stickers.Instead of altering the surface temperature of an object,this approach focuses on modifying the surface emissivityof the object, which is different from previous works . Aluminum typically has an emissivity around0.1, while the surface of a car, typically made of steel, has anemissivity around 0.8, resulting in different infrared charac-teristics. We utilize an ultra-thin (only 0.08mm) aluminumfilm, which can be easily attached on the surface of a carlike many car stickers. We only need around 13 mins tomake a sticker, and the cost of a sticker is only around 0.2USD. The implementation process of adversarial stickers isshown in Supplementary Video 1.",
  ". Dataset": "We used the FLIR ADAS 1 3 infrared dataset releasedby FLIR company for infrared autonomous driving scenes.It contains 10,228 real infrared photos collected in streetsand highways of Santa Barbara, USA. The infrared camerais FLIR Tau2. The training set contains 7160 images, andthe test set contains 3068 images. We used this dataset tofinetune the target detector.",
  "TextureDetectorFasterRetinaNetCascadeLibraSSDYOLOv3Deformable": "Origin2.104.4918.8616.4715.2725.1512.28Random shape18.2617.0723.9528.7445.8150.0023.65AIP14.9715.2732.9327.5423.6538.3227.54UAP20.0631.4438.0233.2336.8339.8224.25Ours96.3186.8373.3579.0495.8086.5283.83 FLIR ADAS 1 3 dataset. The average precision (AP) forcar class of the finetuned model on the training set was0.96, and the AP on the test set was 0.92. After attack-ing Faster RCNN in a white-box setting, we transfered ourattack method to other unseen detectors such as YOLOv3, Deformable DETR , etc. which were provided bymmdetection library in a black-box setting.",
  ". Evaluation Metrics": "In our experiments, we used the attack success rate (ASR)as the evaluation metrics of the attack methods. The ASRwas defined as the ratio of the number of cars which werenot detected to the total number of cars. We set the con-fidence threshold of target detectors to 0.6 and the IOUthreshold between the prediction box and ground truth to0.5, similar to previous works . The ASRwas calculated based on the average value of sample pointscollected from various distances, horizontal angles, andpitch angles with the sampling method described in .4.",
  "DeformYOLOv3": ". Examples of detection results of different detectors fortarget cars with different textures. The numbers above the redbounding boxes are the object confidence scores, with a thresh-old of 0.6. The results of other detectors are shown in SM. The hyper-parameters are detailed in SM. After optimiza-tion, we obtained the adversarial shadow patterns (Tadv in), and the rendered car with adversarial shadow pat-terns (Iadv in ).After that, we evaluated the attack effectiveness of theadversarial shadow patterns. For a fair comparison, we em-ployed the original car pattern (without any sticker) and ran-dom shape pattern as control patterns. The figures of thesepatterns are shown in SM. These patterns were renderedonto the same car model, and the resulting images were in-put into Faster R-CNN. The results, as shown in , in-dicate that our adversarial shadow patterns achieved an ASRof 96.31% for Faster R-CNN in the digital world. In com-parison, the ASRs for the original car pattern and randomshape pattern were only 2.10% and 18.26%, respectively.This demonstrates the effectiveness of our attack method. shows typical examples.We then analyze the ASR of our method at various (full-angle) viewing angles and distances. The horizontal angleazim ranged from 0 to 360 degrees, and we sampled it ev-ery 20 degrees. The pitch angle elev ranged from 0 to 90degrees, and we sampled it every 6 degrees. The distancedist ranged from 1 to 8 meters, and we sampled it every1 meter. (b-d) show the ASRs with respect to onevariable (e.g., dist) by taking the average of ASRs over allcombinations of values of the other two variables (e.g., elevand azim). The results indicate that our approach achievessuccessful attacks at various (full-angle) viewing angles andvarious distances. In contrast, many previous works were effective only within limited viewing angles(e.g., horizontal angle from -30 to 30 degrees and pitch an-gle 0 degree) and shorter distances (e.g. 3 to 6 meters). Notethat there is a decrease in ASR at 2 meters and 0(or 180)-degree horizontal angle. This suggests that Faster RCNN ismore robust in these specific scenes, potentially due to thedistribution of training images. Nevertheless, for the major-ity of viewing angles and distances, the ASRs of our methodconsistently exceeded 80%.",
  ". Full-angle ASRs at diffrent (a) parameters including (b) distances, (c) pitch angles, and (d) horizontal angles. See text for details": "losses (SMLS), we performed ablation experiments. Weconducted a subjective evaluation on the smoothness scoreof the 3D adversarial mesh and 2D adversarial pattern andwe also evaluated the physical implementation time of 2Dadversarial patterns under different settings. The experi-mental settings and results are detailed in SM. The resultsindicate that both CMS and SMLS improved the smooth-ness of adversarial meshes and patterns, and their combina-tion was better. Besides, these methods effectively reducedthe physical implementation time of adversarial patterns.",
  ". Comparison with 2D Optimization Methods": "We extended the previous 2D infrared model car attackmethods to our 3D car model. We generated adver-sarial car textures on our car model based on their papersand codes, which are shown in SM. Following the settingsin .4, we evaluated the attack performance of thedifferent methods. The statistics of ASRs are presented in, with typical examples shown in .",
  ". Infrared attack effect on model cars. (a) Visible lightview of model cars. (b) Infrared view of model cars. C: clean car.R: car with random shape stickers. A: car with adversarial stickers": "The results indicated that the ASR of our method(96.31%) outperformed the ASRs of two alternative meth-ods (14.97% and 20.06%) for Faster RCNN in the digitalworld. The reasons may be as follows. The two 2D op-timization methods based on boundary optimization or points clustering are subject to various constraints.These constraints are used to ensure that, for example, theboundary curves do not have overlaps , and the ad-versarial patterns do not split into multiple pieces .With more constraints, the feasible solution space becomessmaller. However, our 3D mesh shadow approach does nothave such constraints, and we can explore a larger solutionspace, leading to better results.",
  ". Attack Transferability": "We tested the effectiveness of our adversarial car texture(Tadv in ) optimized for Faster RCNN against otherunseen detectors, including RetinaNet , Cascade RCNN, Libra RCNN , SSD , YOLOv3 and De-formable DETR .It is worth noting that these ex-periments were performed in a black-box setting, whichis a more challenging but practically significant scene forreal-world applications. The results are shown in .The ASRs of our method against unseen models reached73.35%-95.80%. It indicates that our method performedwell in a black-box setting and had good attack transferabil-ity to unseen models including not only CNN-based modelsbut also transformer-based models. Besides, the transfer-ability of our method is stronger than not only two simplebaselines but also two infrared attack methods .",
  ". Physical Attacks on Model Cars": "We initially conducted physical experiments on three same1:24 scale Mercedes-Benz model cars ((a)). Wecrafted the adversarial aluminum stickers according to theoptimized patterns, scaled to match the size of the modelcar, and applied them to the model car. In addition, we cre-ated randomly cut-shaped stickers as a control. We heatedthe model cars with hot water to simulate the real car withengine running.We used a rotating turntable to conve-",
  ". Examples of infrared real car attacks. C: clean car. R: car with random shape stickers. A: car with adversarial stickers": "niently assess the attack effectiveness over the entire 0-360horizontal degree and 0-90 pitch angle range. The infraredcamera was FLIR T560. We utilized the same Faster RCNNdetector as in .4. The detection results indicatedthat our adversarial stickers achieved an ASR of 84.86% onthe 1:24 scale car model in the physical world. In compar-ison, the clean car and the car with random patterns hadASRs of only 19.08% and 35.37%, respectively. provides specific examples from the physical world ex-periments. A demo video for physical model car attacks isshown in Supplementary Video 2.",
  ". Physical Attacks on Real Cars": "We conducted physical experiments on two real Mercedes-Benz A200L cars (one black one white). It was a sunnyday with a temperature of about 25C. For a fair compar-ison, we pasted the the adversarial stickers, randomly cut-shaped stickers or nothing on the same car successively. Werecorded 30 videos (each video is around 2 minutes) andsampled 3688 infrared images of these cars from variousangles and distances in both ground and underground park-ing lots using a FLIR T560 camera. The height of the cam-era tripod can be adjusted from 1m to 2m. We sent theseimages to Faster RCNN.The results indicated that our adversarial stickersachieved an ASR of 91.49% on the real cars with the en-gines running, while the random shape stickers and nosticker had ASRs of only 6.21% and 0.66%, respectively.When the engines were off for one hour, the ASR of ad-versarial stickers dropped a little to 88.42%. The reasonmight be that the infrared patterns of adversarial stickerswith engines off were not as clear as the patterns with en-gines running. However, the ASR of adversarial stickerswere still better than ASR of random shape stickers (5.72%)and no sticker (1.86%) when the engines were off. and show some examples. There were a few othercars that passed by or were parked when we were recordingvideos and therefore appeared in our photos, which werealso detected.See Supplementary Video 3 for the demovideo.",
  ". Adversarial Defense": "We tested five adversarial defense methods to defend ourattack methods in the digital world, including adversarialtraining , PixelMask , Bit squeezing , JPEG com-pression and Total variation minimization . Exper-iment details for these methods are in SM. The results showthat although these methods had a certain defense effect,the ASR of our method still reached 88.83%-94.81% afteradding defense, which shows that our method is a powerfulattack method.",
  ". Conclusion": "We propose infrared adversarial stickers to hide a real carfrom infrared detectors at various viewing angles, distances,and scenes in the physical world. We build a 3D infrared carmodel with real infrared characteristics and propose a 3Dmesh shadow method for the generation of infrared adver-sarial pattern. To make the 3D adversarial mesh smoother,we propose a 3D control points-based smoothing algorithmand use a set of smoothness loss functions. Our adversar-ial stickers enabled two real cars to evade Faster RCNN atvarious viewing angles, distances and scenes. Besides, ourmethod has strong attack transferability against multiple un-seen detectors in a black-box setting.",
  "Nicholas Carlini and David A. Wagner. Towards evaluatingthe robustness of neural networks. In IEEE Symposium onSecurity and Privacy, pages 3957, 2017. 2": "Kai Chen, Jiaqi Wang, Jiangmiao Pang, Yuhang Cao, YuXiong, Xiaoxiao Li, Shuyang Sun, Wansen Feng, Ziwei Liu,Jiarui Xu, Zheng Zhang, Dazhi Cheng, Chenchen Zhu, Tian-heng Cheng, Qijie Zhao, Buyu Li, Xin Lu, Rui Zhu, Yue Wu,Jifeng Dai, Jingdong Wang, Jianping Shi, Wanli Ouyang,Chen Change Loy, and Dahua Lin.MMDetection: Openmmlab detection toolbox and benchmark.arXiv preprintarXiv:1906.07155, 2019. 6 Haoqiang Fan, Hao Su, and Leonidas J Guibas. A point setgeneration network for 3d object reconstruction from a singleimage. In Proceedings of the IEEE conference on computervision and pattern recognition, pages 605613, 2017. 4",
  "Zhanhao Hu, Siyuan Huang, Xiaopei Zhu, Xiaolin Hu,Fuchun Sun, and Bo Zhang. Adversarial texture for fool-ing person detectors in the physical world. In IEEE Conf.Comput. Vis. Pattern Recog., 2022. 2": "Zhanhao Hu, Wenda Chu, Xiaopei Zhu, Hui Zhang, BoZhang, and Xiaolin Hu.Physically realizable natural-looking clothing textures evade person detectors via 3d mod-eling. In Proceedings of the IEEE/CVF Conference on Com-puter Vision and Pattern Recognition, pages 1697516984,2023. 2 Lifeng Huang, Chengying Gao, Yuyin Zhou, Cihang Xie,Alan L. Yuille, Changqing Zou, and Ning Liu. Universalphysical camouflage attacks on object detectors. In IEEEConf. Comput. Vis. Pattern Recog., 2020. 2",
  "Christian Szegedy, Wojciech Zaremba, Ilya Sutskever, JoanBruna, Dumitru Erhan, Ian J. Goodfellow, and Rob Fergus.Intriguing properties of neural networks. In Int. Conf. Learn.Represent., 2014. 2": "Simen Thys, Wiebe Van Ranst, and Toon Goedeme. Foolingautomated surveillance cameras: Adversarial patches to at-tack person detection. In IEEE Conference on Computer Vi-sion and Pattern Recognition Workshops, CVPR Workshops,2019. 2 Donghua Wang, Tingsong Jiang, Jialiang Sun, Weien Zhou,Zhiqiang Gong, Xiaoya Zhang, Wen Yao, and XiaoqianChen. Fca: Learning a 3d full-coverage vehicle camouflagefor multi-view physical adversarial attack. In Proceedings ofthe AAAI conference on artificial intelligence, pages 24142422, 2022. 2 Jiakai Wang, Aishan Liu, Zixin Yin, Shunchang Liu, ShiyuTang, and Xianglong Liu. Dual attention suppression attack:Generate adversarial camouflage in physical world. In Pro-ceedings of the IEEE/CVF Conference on Computer Visionand Pattern Recognition, pages 85658574, 2021. 2 Hui Wei, Zhixiang Wang, Xuemei Jia, Yinqiang Zheng, HaoTang, Shinichi Satoh, and Zheng Wang.Hotcold block:Fooling thermal infrared detectors with a novel wearable de-sign. In Proceedings of the AAAI Conference on ArtificialIntelligence, pages 1523315241, 2023. 2, 5, 6 Xingxing Wei, Yao Huang, Yitong Sun, and Jie Yu. Uni-fied adversarial patch for cross-modal attacks in the physicalworld. In Proceedings of the IEEE/CVF International Con-ference on Computer Vision, pages 44454454, 2023. 2, 6,7 Xingxing Wei, Jie Yu, and Yao Huang. Physically adversar-ial infrared patches with learnable shapes and locations. InProceedings of the IEEE/CVF Conference on Computer Vi-sion and Pattern Recognition, pages 1233412342, 2023. 2,5, 6, 7"
}