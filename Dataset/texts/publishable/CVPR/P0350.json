{
  "Abstract": "Self-supervised learning (SSL) has emerged as a keytechnique for training networks that can generalize well todiverse tasks without task-specific supervision. This prop-erty makes SSL desirable for computational pathology, thestudy of digitized images of tissues, as there are many tar-get applications and often limited labeled training samples.However, SSL algorithms and models have been primar-ily developed in the field of natural images and whethertheir performance can be improved by adaptation to par-ticular domains remains an open question. In this work, wepresent an investigation of modifications to SSL for pathol-ogy data, specifically focusing on the DINOv2 algorithm.We propose alternative augmentations, regularization func-tions, and position encodings motivated by the characteris-tics of pathology images. We evaluate the impact of thesechanges on several benchmarks to demonstrate the value oftailored approaches.",
  ". Introduction": "Pathology is the study of the causes and effects of diseaseand is used as a foundation for diagnosis and treatment.Pathology relies on the study of stained tissue microscopyslides, also known as whole slide images (WSIs). Compu-tational pathology (CPath) refers to the application of arti-ficial intelligence to WSIs which have been digitized en-abling automated study and characterization . Several factors have recently converged to drive in-creased interest in the use of foundation models, large-scaledeep neural networks trained on expansive datasets with-out access to task-specific labels, in CPath.Foundationmodels have demonstrated incredible success in the natu-ral image domain, even in cases with limited labeled data",
  "Presented at DCA in MI Workshop, CVPR 2024Corresponding author:": "for training, by learning image representations, called em-beddings, which can be used as inputs to a wide-variety ofdownstream tasks. These properties are desirable for thepathology domain as there are many tasks, such as diag-nosis, disease subtyping, biomarker quantification, estima-tion of treatment response, and survival prediction, and cu-rated labeled datasets are expensive to gather as they re-quire expert review. Motivated by these factors, there havebeen recent efforts to collect large pathology image datasetsand subsequently several foundation models have been pro-posed .The rise of foundation models has been enabled in partby the use of self-supervised learning approaches.Self-supervision is a learning paradigm where a pre-text task isconstructed without access to target labels. The quality offeatures learned and their ability to transfer to a target taskis highly dependent on the definition of the pre-text task andits correlation to downstream objectives. Joint-embeddingself-supervised learning (JE-SSL) methods pose the learn-ing objective in terms of alignment and diversity .Alignment is accomplished by encouraging the embeddingsof pairs or sets of samples generated from the same sourceimage via the application of an augmentation policy to beclose to one another . Diversity provides the nec-essary support to learn representation that avoid collapse ortrivial solutions across the entire set of observations. Exam-ples of diversity objectives include using explicit constraintssuch as decorrelation, maximum entropy, and minimum en-ergy as well as implicit constraints such as model asymme-try or centering operations .The choice of augmentation policy is a key factor in de-termining what kinds of features may be learned duringtraining. Often, augmentation strategies designed for nat-ural images are directly applied to other domains, as haslargely been the case in computational pathology. Howeverit is unclear that the same augmentations will produce goodfeatures across domains. Indeed it has been shown that theeffects of augmentation are often data dependent and vary",
  "GrayscaleColor Jitter": ". Example of a computation pathology data pipeline for self-supervised learning. Tiles (center) that satisfy a tissue inclusion criteriaare randomly sampled from a WSI (left) and perturbed using a set of augmentations sampled from a policy to build the self-supervisedpre-text task (right). Augmentations include but are not limited to Gaussian blur, color jitter, grayscale, and crop-and-resize. across classes . Unlike natural images, which are a 2Dprojection of a 3D scene, CPath images are acquired fromessentially 2D slices of tissue that are stained and scanned atvarious resolutions or magnifications through a digitizationprocess. One implication of this is that pixels have a knowncorresponding physical distance. Understanding the rela-tive distances and shapes of morphological features may beinstructive when interpreting the image. A further distinc-tion of pathology data as compared to natural images is thattissue patterns are non-unique and less diverse across a pop-ulation. These facts motivate the investigation of changes tostandard self-supervised learning strategies.In this work, we investigate the use of domain-inspiredmodifications to self-supervised learning algorithms and theViT architecture focusing on preserving and accounting formorphological patterns. We choose DINOv2 , a self-supervised distillation method, as the framework to testthe impact of different design choices and evaluate perfor-mance on various benchmark tasks. Our results indicate thatpreserving local morphology and modifying regularizationschemes lead to better performance.",
  ". Related Work": "Possibly in part due to the computational cost, few workshave studied the impact of augmentation policies in CPathfoundation models on downstream task performance, how-ever there are a few notable exceptions. Tellez et al. ,Ciga et al. , and Gullapally et al. all investigatedthe impact of color augmentation motivated by stain vari-ation, the effect of differences in staining protocol andscanner type which do not reflect underlying differences inpathology. All of the aforementioned studies have demon-strated improvements in performance using color augmen- tation and several models have employed domain-orientatedapproaches . Digitized WSIs are typically stored atfixed magnifications, e.g. 5, 10, 20, and have signif-icantly less variability in object scale than natural images.As noted in the introduction, this feature also draws intoquestion augmentation protocols that typically crop and re-size images. In addition to color variation, Ciga et al. investigated the impact of random cropping on model per-formance and found less random cropping generally im-proved performance although the largest observed improve-ment in any setting was 5%.",
  ". Learning on gigapixel pathology images": "WSIs are gigapixel images, typically tens of thousands ofpixels in each spatial dimension. In order to avoid the com-putational bottlenecks associated with large images, foun-dation models have been trained using local regions of theimage called tiles (see ). Tiles are extracted by sub-diving an image into non-overlapping regions that have suf-ficient amounts of relevant tissue as determined by a sep-arate inclusion criterion such as a segmentation network.To-date, most works have generated tiles at a fixed mag-nification, typically 20. As pathology features manifestat various resolutions, we instead consider a set-up wheretiles are drawn from the most commonly available magnifi-cations, 5, 10, 20, and 40, or 2.0, 1.0, 0.5 and 0.25microns-per-pixel, respectively.Given this setup, in the next two sections, we discusshow pairwise alignment tasks and diversity objectives canbe adapted to be more suited to pathology image features.We focus our description to the DINOv2 algorithm and vision transformer architectures . The DINOv2 ap-proach uses self-distillation cross-entropy, masked image modeling, and differential entropy to learn image features.It has recently been used to train several CPath foundationmodels and we therefore use it to frame ouranalysis, however we expect that many of the insights cangeneralize to other self-supervised learning settings.",
  ". Morphology-preserving alignment": "The alignment component of JE-SSL objectives is achievedvia an invariance objective that is controlled through a care-ful selection of an augmentation policy.The augmenta-tion policy is applied as follows: for a sample x drawnfrom a dataset D, T random perturbations are sampledfrom the augmentation policy T and applied to create views{Tt(x)}Tt=1. These views then serve as input to the align-ment objective. Examples of common augmentations areshown in .The design of the augmentation policy determines theproperties of the network and must be difficult enough tolearn meaningful information without shortcuts. Traditionalaugmentation policies were designed for object-centric nat-ural images which have common reoccurring structure andtexture. Color perturbation and random crop-and-resize arethe fundamental building blocks of these policies and aimto decouple global-local features. The motivation for crop-and-resize is the creation of feature co-occurances resultingfrom overlaps between views which can then be used foralignment .Cell morphology plays an important role in understand-ing tissue structure and disease. Depending on the aspectratio of the crop, a resize may introduce unwanted distor-tions that affect tissue and cell shapes. One unique aspect ofpathology data is that the training samples are constructedfrom tiles at predetermined sizes from a WSI. The selectionof tile size is primarily unrelated to the modeling task, as itis motivated by compute constraints. Because of this, it ispossible to design a translation-like augmentation that usesa larger source field of view to minimize distortions whilemaintaining the same output size and expected overlap ofviews. This operation differs from regular translations as itdoes not introduce imaging artifacts along boundaries, i.e.padded values. To demonstrate how this is possible, con-sider replacing the LL-sized training tile with an N N-sized source region and a target LL tile to be sub-sampledwithin the larger window, where N > L (see ). Thisalternative augmentation, which we refer to as extended-context translation (ECT), maintains the average overlapbetween views as compared to the crop-and-resize methodwith minimal need for resizing. The particular value for Ncan be selected based on the desired intersection over unionof views. ECT can serve as a drop-in replacement for tra-ditional crop-and-resize approaches and can be combinedwith other augmentations such as color augmentations.",
  ". Accounting for data redundancy": "The second piece of an JE-SSL objective is a diversity func-tion to prevent collapse of the representations. Some JE-SSL methods, like DINOv2, achieve diversity across em-beddings by maximizing entropy. Although diversity objec-tives often share similar optimum, their dynamics through-out training are considerably different and introduce practi-cal challenges that must be addressed.Feature diversity is dependent on the data distributionused to train a network. In CPath, tissue patterns are repet-itive across populations and as a result, the likelihood ofa collision may be higher than those encountered in largeuncurated natural imaging datasets. Based on the latter, es-timators should be constructed under the assumption thatfeatures are not independent, may be very close together,and cannot be arbitrarily separated.DINOv2 proposes the use of KoLeo, a differential en-tropy estimator defined as",
  "i=1minj=i log d(zi, zj),(1)": "where i indexes the samples in a batch, d is a distancemeasure and z is an embedding normalized to the hyper-sphere . The inclusion of maximization of entropy us-ing KoLeo aims to spread out learned embeddings via a convex regularizer and has been shown to improve imageretrieval performance . However, when two samplesare very similar, and distance approaches zero, KoLeo ap-proaches infinity.A kernel density estimator (KDE) can be used as an ef-fective replacement in order to mitigate the issues associ-ated with KoLeo in a setting where features may be clus-tered. The kernel entropy estimator is defined as",
  "j=ik(zi, zj),(2)": "where k is an appropriate kernel function and all other termsare as defined above. Similar objectives have been used invarious other methods .The kernel density estimator has different regularizationeffects for local behaviors, i.e. for samples with large andsmall distances, but maintains the population effect of pro-moting diversity. Examples of kernels include Gaussian,von Mises-Fischer (vMF), inverse multiquaratic, or Lapla-cian kernel each of which allows for different repulsioncharacteristics that have bounded gradients which can alsovanish for a given pair.",
  ". Conditioning on magnification": "Although not exclusively related to self-supervised learningapproaches, we present an additional modeling considera-tion that is enabled by representations that preserve mor-phology. For a vision transformer (ViT) architecture ,preserving relative distances on data that has known natu-ral resolution hierarchies allows for additional knowledgeto be embedded through a scale-aware definition of the po-sition encodings. Scale-MAE , a technique developedin the remote sensing literature for geospatial data, pro-poses one such definition based on the Ground Sample Dis-tance (GSD). Analogously, we propose Cell Sample Dis-tance (CSD) position encodings",
  ",(3)": "where m is encoded relative to a reference M in microns,p is the 2D position in the sequence, D is the dimensionof the encoding vector, and is a large constant used tomodulate frequencies. This definition of position encodingcan replace the more standard learned position encodings inthe ViT architecture. CSD position encodings can also beused in settings with varying sequence lengths, for instanceas occurs when generating global and local views, by usingthe known cell distance.An alternative approach for accounting for differencesin relative position as a function of magnification is to learn position embeddings for each magnification (referred to asLearned Per Micron, or LPM, here). This approach requirespre-defining the set of magnifications of interest and cannotbe dynamically adjusted.",
  ". Pretraining methodology": "We select a ViT-B/16 and pretrain using DINOv2 . Thedefault parameters as described in are used with thefollowing changes: batch size of 1024, learning rate equalto 2e 4, and a drop-rate of 0.4. The model is trainedfor approximately 112K iterations, or equivalently 115Mtiles, using 16 GPUs. In all experiments, grayscale, colorjitter, flips, and solarization perturbations are unchanged.Crop-and-resize experiments use the DINOv2 ranges of(0.32, 1.0) and (0.05, 0.32) for global and local views withan aspect ratio range of (0.75, 1.33). ECT augmentationsuse a source context window of 392 392, a scale range of(0.9, 1.1) and aspect ratio range of (0.95, 1.05). Additionalimplementation details are described in Appendix A. Thissource size was selected based on a Monte Carlo simulationto calculate the intersection-over-union for various contextsizes and selecting one with similar overlap to the DINOv2crop-and-resize overlap for 224 224 tiles. The augmenta-tion is implemented using the same crop-and-resize modulewhere the new scale parameters are adjusted using the rel-ative ratio of the source and target size for both global andlocal views. Density estimation is computed using a vMFkernelkvMF(x, y) = exp(xy),(4) where is a scaling constant and is set to 5 for all experi-ments based on empirical results in the literature. The vMFkernel is selected because of its favorable computationalqualities and its demonstrated success in encouraging di-verse embeddings . For all CSD position encodingexperiments, = 10000 as is done in scale-MAE . Allevaluation is performed using teacher predictions.",
  ". Pretraining dataset": "The training dataset is comprised of 1,488,550 WSIs from119,629 patients from Memorial Sloan Kettering CancerCenter. All WSIs are stained using hematoxylin and eosin,a routine stain. WSIs are scanned at, a possible subset of, 5, 10, 20 and 40, or 2, 1, 0.5 and 0.25 microns-per-pixel, respectively.Data is pre-processied into non-overlapping 224 224 or 392 392 tiles contained at least45% tissue coverage as determined by a hue, saturation, andvalue (HSV) filter with an acceptance criterion in ranges, , .",
  ". Evaluation tasks": "A mix of seven in-domain and out-of-domain tile level clas-sification tasks across various magnifications are used toevaluate the quality and separability of the learned featuresof the teacher network via linear probe protocol. The clas-sifier is trained on frozen embeddings generated from non-augmented model inputs for 12.5K iterations using a cosineschedule with stochastic gradient descent.PanMSK XX is an in-domain cancer detection taskperformed at 5, 10, and 20 magnifications. 1,196,171224 224 pixel tile samples, sourced from 3,999 WSI rep-resenting 17 tissue types, are labeled either cancer or benign.PCAM is a public dataset of 327,680 lymph node imageslabeled as cancer or benign . Images are up-sampledfrom 9696 at 10 magnification to 224224 for analysis.MHIST is a public dataset of 3152 colorectal polyp im-ages (5 magnification 224224 pixels) labeled benign orprecursor .CRC is a public dataset of 100,000 colorectal images(20 magnification 224 224 pixels) classified into 9 mor-phologies .MIDOG is a public dataset of 21,806 mitotic and non-mitotic events labeled on 503 7K 5K WSI regions fromseveral tumor, species, and scanner types at 40 magnifica-tion . Data was converted into a binary classification taskby expanding each 5050 pixel annotation to 224224 re-gions and then randomly shifting in the horizontal and verti-cal regions such that the event is not centered in the tile. Allnegative instances that overlapped with positive instanceswere removed from the dataset.",
  ". Results and Discussion": "presents the results. Overall, the combination ofECT, standard learned position encoding, and KDE regular-ization performed the best, having the highest performanceas measured by test accuracy on five out of seven tasks andthe highest mean accuracy. The combination of cell sampledistance position encoding, ECT and KDE regularizationwas a close second, with a mean accuracy only 0.23 lessthan the best result and the best performance on two of theseven tasks. Observing pairwise impacts of each setting, thechange from KoLeo to KDE regularization had the largestimpact (average improvement 3.52, range 1.18-5.63). ECTas opposed to crop-and-resize also improved performancein all settings on average (average improvement 0.89, range 0.18-1.61). Focusing only on the in-domain PanMSK tasks,these improvements are even more pronounced (averageimprovement 3.87, range 1.46-6.02 and average improve-ment 1.28, range 0.72-1.84 for KDE regularization andECT, respectively). Learning position encodings per mag-nification did not improve performance. The combinationof learned position encodings per magnification with ECTaugmentation and KoLeo regularization had the worst per-formance overall and a mean accuracy 6.12 less than thebest result.Self-supervised pipelines are built to enforce invariance,however, equivariance may be of equal importance. De-coupling the benefits between invariance and equivarianceis difficult due to the wide range of downstream tasks thatare used to evaluate performance. For example, invarianceto pose, color, and relative intensity will aid in generalizingacross data sources given that different institutions have dif-ferent slide preparation techniques and scanners . Mod-els do not necessarily utilize the same types of imagingfeatures as a pathologist. As a result, it is unclear if be-ing invariant or equivarient to cell shape and size througheither a crop-and-resize or an extended-context translationis important. There is a trade-off that must be considered,where invariance to shape may help generalize across datasources and domains, while equivariance may lead to betterin-domain features. We empirically observe, when evalu-ating the effect of extended-context translations, more im-provement is observed for in-domain PanMSK evaluationtasks as compared to the out-of-domain tasks, on average.This result is of particular interest, since it demonstrates thebenefits of preserving morphology in isolation of other con-founding variables. We expect out-of-domain generaliza-tion can be further improved through additional scale, datacuration, color augmentations, and training horizons. Vali-dating this hypothesis is beyond the scope of this work.The impact of different regularization approaches ben-efits from contextualization of the particular implementa-tion details. DINOv2 implements KoLeo without synchro-nization across devices which couples compute configura-tions to performance, since the likelihood of encounteringnearby pairs is proportional to the number of observations ina batch. The proposed alternative using KDE accounts forthese limitations by removing instabilities through the se-lection of the vMF kernel, whose gradients are non-convexand vanish in a regime that would otherwise be problematic.Regardless of the potential benefits introduced from dataaugmentation or architecture design, if the amount of reg-ularization is too high or improperly specified, the modelsability to learn will be limited.Scale-aware position encodings are well suited for re-construction objectives like the masked autoencoder asthe decoder removes the need for a diversity objective anddoes not require strong augmentation policies such as the",
  "Average83.3084.4883.4786.0979.9784.6280.2285.85": ". Test accuracy results for seven evaluation tasks and eight model settings. In-domain evaluation tasks include PanMSK XX, whileout-of-domain tasks include PCAM, CRC, MHIST, and MIDOG. Boldface indicates the best performance and italics indicates the secondbest performance. In a majority of tasks and on average, learned position encodings using ECT and KDE regularization performs best. random resized crop. Unfortunately, masked autoencodersrequire additional finetuning to perform well on down-stream tasks and are not evaluated in this study . Themorphology modification suggested in Sec. 3.1 preservesspatial features and unlocks the ability to explore spatial-conditioning in a joint-embedding environment.WhileCSD position encodings did not degrade performance, theydid not provide any additional benefits. It is possible that us-ing the position encoding in the projector, as would be moresimilar to the Scale-MAE setting, could lead to greater im-provements in performance but that investigation is left forfuture work.Overall, our results demonstrate that the incorporationof domain-specific data considerations has the ability to un-lock major improvements for self-supervised CPath models.Finally we note we designed our experiments to highlightthe relative impact of modeling decisions, not to competewith existing foundation model performance. In the future,we aim to understand the impacts of these modeling choicesfor large-scale foundation models. Marc Aubreville, Frauke Wilm, Nikolas Stathonikos, Katha-rina Breininger, Taryn A Donovan, Samir Jabari, Mitko Veta,Jonathan Ganz, Jonas Ammeling, Paul J van Diest, et al. Acomprehensive multi-domain dataset for mitotic figure de-tection. Scientific Data, 10(1):484, 2023. 5 Shekoofeh Azizi, Laura Culp, Jan Freyberg, Basil Mustafa,Sebastien Baur, Simon Kornblith, Ting Chen, Nenad Toma-sev, Jovana Mitrovic, Patricia Strachan, et al.Robustand data-efficient generalization of self-supervised machinelearning for diagnostic imaging. Nature Biomedical Engi-neering, 7(6):756779, 2023. 1",
  "pathology image analysis: a survey. Frontiers of medicine,14:470487, 2020. 1": "Jonas Dippel, Barbara Feulner, Tobias Winterhoff, SimonSchallenberg, Gabriel Dernbach, Andreas Kunft, StephanTietz, Philipp Jurmeister, David Horst, Lukas Ruff, Klaus-Robert Muller, Frederick Klauschen, and Maximilian Alber.RudolfV: A foundation model by pathologists for patholo-gists, 2024. 1, 2, 3 Alexey Dosovitskiy, Lucas Beyer, Alexander Kolesnikov,Dirk Weissenborn, Xiaohua Zhai, Thomas Unterthiner,Mostafa Dehghani, Matthias Minderer, Georg Heigold, Syl-vain Gelly, et al. An image is worth 16x16 words: Trans-formers for image recognition at scale.arXiv preprintarXiv:2010.11929, 2020. 2, 4 Alexandre Filiot, Ridouane Ghermi, Antoine Olivier, PaulJacob, Lucas Fidon, Alice Mac Kain, Charlie Saillard, andJean-Baptiste Schiratti. Scaling self-supervised learning forhistopathology with masked image modeling.medRxiv,pages 202307, 2023. 1 Jean-Bastien Grill, Florian Strub, Florent Altche, CorentinTallec, Pierre H. Richemond, Elena Buchatskaya, Carl Do-ersch, Bernardo Avila Pires, Zhaohan Daniel Guo, Moham-mad Gheshlaghi Azar, Bilal Piot, Koray Kavukcuoglu, RemiMunos, and Michal Valko. Bootstrap your own latent: A newapproach to self-supervised learning, 2020. 1 Sai Chowdary Gullapally, Yibo Zhang, Nitin Kumar Mittal,Deeksha Kartik, Sandhya Srinivasan, Kevin Rose, DanielShenker, Dinkar Juyal, Harshith Padigela, Raymond Biju,et al.Synthetic domain-targeted augmentation (S-DOTA)improves model generalization in digital pathology. arXivpreprint arXiv:2305.02401, 2023. 2",
  "Jakob Nikolas Kather, Niels Halama, and Alexander Marx.100,000 histological images of human colorectal cancer andhealthy tissue. Zenodo, 2018. 5": "Maxime Oquab, Timothee Darcet, Theo Moutakanni, HuyVo, Marc Szafraniec, Vasil Khalidov, Pierre Fernandez,Daniel Haziza, Francisco Massa, Alaaeldin El-Nouby, Mah-moud Assran, Nicolas Ballas, Wojciech Galuba, RussellHowes, Po-Yao Huang, Shang-Wen Li, Ishan Misra, MichaelRabbat, Vasu Sharma, Gabriel Synnaeve, Hu Xu, Herve Je-gou, Julien Mairal, Patrick Labatut, Armand Joulin, and PiotrBojanowski. Dinov2: Learning robust visual features with-out supervision, 2024. 2, 4 Colorado J. Reed, Ritwik Gupta, Shufan Li, Sarah Brock-man, Christopher Funk, Brian Clipp, Kurt Keutzer, SalvatoreCandido, Matt Uyttendaele, and Trevor Darrell. Scale-mae:A scale-aware masked autoencoder for multiscale geospatialrepresentation learning, 2023. 4",
  "Chetan L Srinidhi, Ozan Ciga, and Anne L Martel. Deepneural network models for computational histopathology: Asurvey. Medical Image Analysis, 67:101813, 2021. 1": "David Tellez, Geert Litjens, Peter Bandi, Wouter Bulten,John-Melle Bokhorst, Francesco Ciompi, and Jeroen VanDer Laak. Quantifying the effects of data augmentation andstain color normalization in convolutional neural networksfor computational pathology. Medical image analysis, 58:101544, 2019. 2 Bastiaan S Veeling, Jasper Linmans, Jim Winkens, Taco Co-hen, and Max Welling. Rotation equivariant cnns for digitalpathology. In Medical Image Computing and Computer As-sisted InterventionMICCAI 2018: 21st International Con-ference, Granada, Spain, September 16-20, 2018, Proceed-ings, Part II 11, pages 210218. Springer, 2018. 5 Eugene Vorontsov, Alican Bozkurt, Adam Casson, GeorgeShaikovski, Michal Zelechowski, Siqi Liu, Kristen Sever-son, Eric Zimmermann, James Hall, Neil Tenenholtz, NicoloFusi, Philippe Mathieu, Alexander van Eck, Donghun Lee,Julian Viret, Eric Robert, Yi Kan Wang, Jeremy D. Kunz,Matthew C. H. Lee, Jan Bernhard, Ran A. Godrich, Ger-ard Oakley, Ewan Millar, Matthew Hanna, Juan Retamero,William A. Moye, Razik Yousfi, Christopher Kanan, DavidKlimstra, Brandon Rothrock, and Thomas J. Fuchs.Vir-chow: A million-slide digital pathology foundation model,2024. 1, 3, 5",
  "Tongzhou Wang and Phillip Isola. Understanding contrastiverepresentation learning through alignment and uniformity onthe hypersphere, 2022. 1, 4": "Xiyue Wang, Sen Yang, Jun Zhang, Minghui Wang,Jing Zhang, Wei Yang, Junzhou Huang, and Xiao Han.Transformer-based unsupervised contrastive learning forhistopathological image classification. Medical image anal-ysis, 81:102559, 2022. 1, 2 Jerry Wei, Arief Suriawinata, Bing Ren, Xiaoying Liu,Mikhail Lisovsky, Louis Vaickus, Charles Brown, MichaelBaker, Naofumi Tomita, Lorenzo Torresani, et al. A petridish for histopathology image analysis. In Artificial Intelli-gence in Medicine: 19th International Conference on Arti-ficial Intelligence in Medicine, AIME 2021, Virtual Event,June 1518, 2021, Proceedings, pages 1124. Springer,2021. 5"
}