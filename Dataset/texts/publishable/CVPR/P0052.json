{
  "Abstract": "In this paper we propose a score of an image to use forcoreset selection in image classification and semantic seg-mentation tasks. The score is the entropy of an image as ap-proximated by the bits-per-pixel of its compressed version.Thus the score is intrinsic to an image and does not requiresupervision or training. It is very simple to compute andreadily available as all images are stored in a compressedformat. The motivation behind our choice of score is thatmost other scores proposed in literature are expensive tocompute. More importantly, we want a score that capturesthe perceptual complexity of an image. Entropy is one suchmeasure, images with clutter tend to have a higher entropy.However sampling only low entropy iconic images, for ex-ample, leads to biased learning and an overall decrease intest performance with current deep learning models. To mit-igate the bias we use a graph based method that increasesthe spatial diversity of the selected samples. We show thatthis simple score yields good results, particularly for se-mantic segmentation tasks.",
  ". Introduction": "Deep learning has made tremendous progress in the pastfew years exploiting the scale of large training sets, amongother factors. Recently data centric methods, such as train-ing on pruned dataset , or using non uniform mixingstrategies have become standard practice for traininglarge scale models. In these methods a score is attachedto each data instance, and an instance is selected (or not)for training using the ordered scores of available instances.In this paper we focus on data pruning for computer visiontasks where a subset of the instances available is used fortraining with minimal loss of performance.In previous data pruning approaches for computer vi-sion, mostly on the classification task, scores naturally re-flect the learning task at hand. That is, they are based on",
  "*Visiting Faculty, CS": "the distribution of input and its label(s).This implicitlypays less attention to the input itself. Also modeling thisdistribution accurately is expensive - usually some steps oftraining have to be done before the scores can be calcu-lated . Thus one of the key questions, raisedin literature, is how early in training can the instances to bepruned identified ?We start with four observations. First, the vision per-ception literature recognizes that images with less clutter,simpler background, iconic objects, are processed faster bythe human visual system . Many measures for char-acterising human perception of scene complexity have beenproposed , among which the information theoretic mea-sure of entropy is not only the simplest but also captures theclutter in an image well .Second, images with less clutter and a plain background,also lead to better labeling of pictures by young chil-dren . In general child development literature showsthat the nature of picture books for young children leads todifferent transfer learning experience. Similar studies fordeep learning can yield interesting insights.Third, in natural language processing scores such aslength of sentences, or word rarity, have been proposed asdifficulty scores for machine translation .Sentencesthat are shorter are easier to translate than sentences thatare longer; here difficulty is a measure of only the inputsentence, not of the input, output sentences. Machine trans-lation is similar to the semantic segmentation task in com-puter vision.Fourth, it has been shown that complexity of an image(as measured by lossless bits-per-pixel) and the likelihoodof generating that image are negatively correlated . Thisprovides an alternate method to compute the entropy of animage, that has only been used in context of out of distribu-tion sample detection .Inspired by these observations, we raise the followingquestions - What is the intrinsic measure of complexity of an image? Can a deep learning model learn from the intrinsicallymore (or less) difficult images in a dataset and transfer",
  "the knowledge effectively to other images in the dataset?": "Can this coreset selection and training work for tasks suchas image classification and semantic segmentation? Par-ticularly the latter which is less explored task in literature.In this paper we propose the bits-per-pixel (BPPJ) ofa JPEG encoded image as a measure of the percep-tual complexity of the image. Bits-per-pixel of an losslesscompressed version of image is an upper bound for the en-tropy of an image . We acknowledge that JPEG is notlossless compression, but in most cases we do not have ac-cess to the raw uncompressed images. We assume that theimages available have been stored at high quality in orderto avoid compression artifacts, and hence can be approx-imated as lossless. The three dataset that we work on inthis paper, CIFAR , VOC and ADE20K have ingeneral good quality images, with CIFAR being the datasetwith the most variations in quality. We experiment with al-ternate methods to estimate entropy in the methods section.Also as part of ongoing research we are exploring other per-ceptual scores .In , we show images from CIFAR and VOC dataset, selected by BPPJ score. Simple CIFAR imageswould be good candidates for iconic images in a childspicture book. Compared to other scores for data pruningin computer vision (and references therein), ourintrinsic score, BPPJ, does not use supervised labels, oreven unsupervised cluster distances . In we showimages of trucks from CIFAR selected using three differ-ent scores. One of the drawbacks of using BPPJ is im-mediately visible images are too self-similar and samplea small subset of the data 1. On the other hand the hardimages as identified by consistency score are the most di-verse, in fact a wrongly labelled image is correctly scoredas highly inconsistent.Less diversity implies that the pruned training set is bi-ased and although the model easily overfits to the trainingset, it does not generalize well to the test set (test set is notpruned). This issue of less data diversity, and the resultantbias, in actively sampled, or pruned, training dataset hasbeen raised in . One method proposed to solve itis to use better data coverage sampling methods. We usethe graph density approach of to diversify the sampleddataset. Consequently we are exploiting BPPJ, while ex-ploring the sample space using a K-NN graph. For the se-mantic segmentation task we also use a novel feature (in thiscontext), the histogram of ground truth labels of an image,and use the Jensen-Shannon divergence distance to build theK-NN graph. This captures well the semantic similarity ofa pair of images.Sampling methods have also been proposed in (and",
  "1shows compression artifacts in CIFAR that affect BPPJ score. Thefourth, fifth image in the top row have low BPPJ because they are highlycompressed": ". Example of simple images from CIFAR (first two rows),complex images from CIFAR (next two rows). Simple imagesfrom VOC (next two rows), and complex images from VOC (lasttwo rows). Simple images are those with lowest BPPJ, whilecomplex images have highest BPPJ. Note we are using simpleand complex terms in line with the motivation of perceptual com-plexity. references therein). Other methods for increasing data di-versity, or reducing bias, could be the unbiased approachesproposed in, for example . These approaches recog-nize that datasets for training machine learning models tendto be biased unless the data is collected with care, but theyhave not explored the case where bias may be introducedknowingly and systematically, for example when using datapruning methods. As part of ongoing research we are ex-ploring these methods. Our results for image classification task on CIFAR showthat the scoring using BPPJ does not do well on its own,but combined with graph based sampling its comparable toSOTA. We show that using BPPJ and graph based sam-pling we are able to achieve substantially better results thanrandom pruning for semantic segmentation tasks. We arenot aware of other data pruning methods/scores for this task. . Images from CIFAR. Top row: lowest BPPJ, Secondrow: highest prototypical score . Third row: highest consis-tency score . In the last three rows the same scores are usedbut in the reverse order. Perceptually top row shows simple im-ages, fourth row shows complex image. Second, third rows showimages that are easy or redundant in training process, while fifth,sixth rows show images that are hard or important for training.",
  ". Method": "The score BPPJ of an image is the bits-per-pixel of itsJPEG encoded version. We use the byte size of JPEG di-vided by its dimensions to calculate BPPJ. As ADE20Kand VOC datasets store images as high quality JPEG, thisis straightforward. For CIFAR data we use JPEG standard,through OpenCV 2, at the highest quality setting, to com-press the numpy array of each image. Note that CIFARdataset is a subset of Tiny Images which are scrapped im-ages from the web. These images were most likely alreadylossy compressed. Thus even for CIFAR we do not haveaccess to raw uncompressed images. If raw uncompressedimages are available we can use a lossless compression en-coder as in .Another method for estimating the bits-per-pixel of animage is the log likelihood of that image inferred from atrained generative model . In the past likelihood hasbeen used for out-of-distribution detection, but as far as weknow not for data pruning. We use it as a score, NLL,to prune data for the image classification task. It has alsobeen observed that generative likelihood of an imageis inversely correlated with complexity of the image that ismeasured by the entropy of a lossless encoder. Subtractingthe entropy from log likelihood of an image compensatesfor the complexity of the image . This score, CPX =NLL BPPJ gives, surprisingly, the best results for theimage classification task.In authors cluster features, inferred from a self-supervised model, of images, using k-means algorithm. The distance to the nearest cluster centroid is the prototypical-ity score of an image, PS. k-means is a method for vec-tor quantization and the distance to the nearest centroidis the distortion incurred in using the quantizer. By rate-distortion theory we can consider the distortion to havea bit-per-pixel interpretation under lossy compression con-ditions. The difference between PS and BPPJ is that thelatter uses JPEG which has no learning component. PS, onthe other hand has a learning component but it is trained ona different dataset in an unsupervised manner. Also the dis-tortion in PS is on the decoded features, and in BPPJ ison the decoded image; in fact its not clear that the featuresused in PS can be used to decode (generate) the image. Onthe other hand NLL and CPX use generative model learnton the dataset itself, and have the capability to generate (de-code) the image itself. They are unsupervised generativemodels. Note that in this work we do not compare with theany other scores for coreset selection, data pruning, becausethey rely on supervised learning.To increase data diversity and remove bias arising fromself-similar sampled subset, we use the graph densitymethod proposed in . A K-NN graph is built, where eachimage is a node, and each node has K edges that connectthe top-K nearest neighbours. Graph is made symmetricand weighted by using a Gaussian kernel on the distanceassociated with an edge. Score of an image is attached tocorresponding image. To sample nodes from the graph, it-eratively the highest scored node is selected, and its neigh-boring nodes scores are down-weighted. Since the distancebetween two nodes is a representation of their semantic sim-ilarity, score of neighboring nodes that are farther awayfrom the selected node are down-weighted relatively lessthan those of nodes that are closer. This is done to maxi-mize the diversity of the sampled data and implemented viareverse message passing, where the neighboring nodes re-ceive a weighted message from the selected node and use itto update their score 3.Distance between nodes of the K-NN graph can be de-fined using features of the images, for example features in-ferred from self-supervised models such as SWAV . Dis-tance here would be the standard l2 metric. K-NN graphsbuilt this way are denoted as GS. This requires a pre-trainedmodel to infer features from, and though it works reason-ably well for image classifcation task, it does not work wellfor semantic segmentation. For the latter we propose to usethe histogram of ground truth labels as the feature, and theJensen Shannon divergence between the histograms asthe distance between nodes. K-NN graphs built this wayare denoted as GH In we see that nearest neighboursusing SWAV features have very limited semantic similarity,the third and fourth neighbours on the top row do not have",
  "BPPJ + GS54.579.4389.192.34": ".Accuracy (%) for CIFAR dataset for different sam-pling methods (rows) and different pruned sample size (columns).RND uses no random sampling, BPPJ, PS, NLL, CPX usethe score only, while BPPJ + GS uses score and graph basedsampling. Best results are obtained by using ascending order forall scores. any people in it. The biggest advantage of using histogramsof labels as features is that it allows for diversity in the se-mantic space, not in the feature space. In semantic segmen-tation where class imbalance is an inherent problem, sam-pling the semantic space is more suitable; as we will showin results there is a substantial gain in performance usingthis feature. It should be noted that having semantic labelsimplies that annotations are available, while SWAV featuresdo not have that requirement.",
  ". Results": "In this paper we use CIFAR-10 dataset for image classificationexperiments. We use Resent18 model with hyper-parameters asin . For semantic segmentation we use VOC and ADE20Kdataset, MobileNet model as the encoder, and one convolutionalong with deep supervision as the decoder . For ADE20Kwe use the default hyper-parameters, for VOC we lower the learn-ing rate. We estimate the likelihood, NLL, of an image in CIFAR,using GLOW models trained on CIFAR. We use NLL andBPPJ to calculate CPX. shows the result for image classification task. BPPJdoes not do well at all, and neither does NLL. We tried samplingboth in descending and ascending order of BPPJ and NLL andthe best results we got were with descending order that is withhigh bits-per-pixel images. Accounting for complexity of image,CPX, estimated by generative model does well, beating PS andrandom sampling for lower pruning rates. Also using graph sam-pling substantially improves performance for BPPJ score, show- ing the importance of data diversity.In and semantic segmentation results for VOCand ADE dataset are shown. For both datasets we see that BPPJ(again in descending order) by itself (without graph sampling)does better than prototypicality score (in ascending order). BPPJalong with k-NN graph defined by histograms of labels GH givemeasurable improvement over random sampling and over graphsampling using SWAV featuers GS. PS does poorly for semanticsegmentation because it exaggerates the class imbalance problem.In this paper we proposed a simple, intrinsic, perceptual com-plexity score for coreset selection. This score requires no trainingand does not use the labels; when we use labels, in GH, we arenot training on them and coreset selection can still be done beforetraining starts. One of our original hypothesis of learning fromiconic images does not seem, as of now, correct for deep learning",
  ". Results for semantic segmenation on ADE20K dataset.Legends same as in": "models. We also believe that perceptual scores could be used apriors to be updated with label and task information, once trainingstarts. The positive results of this study are usage of CPX and onsemantic segmenation. Mathilde Caron, Ishan Misra, Julien Mairal, Priya Goyal, Pi-otr Bojanowski, and Armand Joulin. Unsupervised learningof visual features by contrasting cluster assignments. Ad-vances in neural information processing systems, 33:99129924, 2020. 3",
  "Ozan Sener and Silvio Savarese. Active learning for convolu-tional neural networks: A core-set approach. arXiv preprintarXiv:1708.00489, 2017. 2": "Joan Serr`a, David Alvarez, Vicenc Gomez, Olga Slizovskaia,Jose F Nunez, and Jordi Luque. Input complexity and out-of-distribution detection with likelihood-based generative mod-els.In The Eighth International Conference on LearningRepresentations, 2020. 1, 3 Ben Sorscher, Robert Geirhos, Shashank Shekhar, SuryaGanguli, and Ari Morcos. Beyond neural scaling laws: beat-ing power law scaling via data pruning. Advances in NeuralInformation Processing Systems, 35:1952319536, 2022. 1,2, 3, 4 Mariya Toneva, Alessandro Sordoni, Remi Tachet desCombes, Adam Trischler, Yoshua Bengio, and Geoffrey J.Gordon. An empirical study of example forgetting duringdeep neural network learning. ArXiv, abs/1812.05159, 2018.1, 2 Yilin Wang, Junjie Ke, Hossein Talebi, Joong Gon Yim,Neil Birkbeck, Balu Adsumilli, Peyman Milanfar, and FengYang.Rich features for perceptual quality assessment ofugc videos.In Proceedings of the IEEE/CVF Conferenceon Computer Vision and Pattern Recognition (CVPR), pages1343513444, 2021. 2"
}