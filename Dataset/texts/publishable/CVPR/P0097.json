{
  "Abstract": "Generative AI (GenAI) models have demonstrated re-markable capabilities in a wide variety of medical tasks.However, as these models are trained using generalistdatasets with very limited human oversight, they can learnuses of medical products that have not been adequatelyevaluated for safety and efficacy, nor approved by regula-tory agencies. Given the scale at which GenAI may reachusers, unvetted recommendations pose a public health risk.In this work, we propose an approach to identify potentiallyharmful product recommendations, and demonstrate it us-ing a recent multimodal large language model.",
  ". Introduction": "Rapid advancements in generative artificial intelligence(GenAI) have led to the development of sophisticated mod-els such as DALL-E , GPT-4 , PaLM2 , Llama2 and Claude 3 .These have the capabilityto model complex relationships from massive multimodaldatasets, generate new content and perform tasks they werenever trained for. Their potential applications in medicineinclude medical image analysis , providing differen-tial diagnoses , summarizing charts , writing lettersto patients , providing medical education , aid-ing pharmacy providers (e.g. prescription generation, safetyevaluation, decision support) , or working asa chatbot to answer questions about patients specific con-cerns or medical products , among others. Medicine isinherently a multimodal discipline, and new GenAI mod-els such as multimodal large language models (MLLMs)continue to be developed that integrate diverse multimodaldata streams . Moreover, general-purpose GenAI mod-els are often used for medical-related tasks, despite not be-ing specifically developed for those.While these technologies hold great promise, they alsopresent numerous ethical and legal challenges, can pose sig- nificant risk to public health, and cause harm to individualsand organizations . Therefore, itis paramount that GenAI models comply with legal or reg-ulatory regimes. Given that existing laws and regulationswritten to govern the use of AI often struggle to addressthe amplified challenges associated with GenAI ,new ones are rapidly being developed . Meanwhile,there is an imperative for model developers to adhere to theexisting frameworks and the trust and safety principles thatguided them, to mitigate potential harm and maintain publictrust in these breakthrough technologies.In this work, we shed light into an overlooked issuethat impacts most GenAI models, that is, the potential topromote unapproved and potentially harmful uses of med-ical products. Traditionally, specialized ML models havebeen trained to address a specific task using highly domainand problem-specific training data . However, GenAImodels are typically not developed to do particular medicaltasks. Moreover, GenAI models are trained on much morebroadly available generalist datasets with less hands-on human oversight in their development. Therefore, theycan learn complex unvetted relationships from the trainingdata and produce outputs about medical products that do notstrictly adhere to the approved product labels. Promoting amedical product for anything other than its approved use isunsafe and illegal, and ought to be avoided.To avoid this issue, we propose a method to identify in-stances of off-label promotion in GenAI outputs (Sec.3).We demonstrate it using a recently introduced MLLM(Sec.4), and surface examples where it is producing poten-tially harmful responses (Sec.5). Finally, we briefly discusshow guardrails may be introduced so that GenAI modelsstrictly adhere to product labels when producing outputs re-lated to medical products (Sec.6).",
  ". Regulatory framework": "In the US, under the Federal Food, Drug and Cosmetic Act(FDCA), regulated by the Food and Drug Administration(FDA), medical products such as pharmaceutics, biologicsor medical devices, must be approved, authorized, or oth-erwise cleared for each intended use by the FDA before acompany can market it . Off-label use refers to using orprescribing marketed medical products for indications (e.g.a disease or symptom) that are not included in their FDA-approved labeling information. Hence, the specific use isoff-label (i.e. not approved by the FDA and not listed inFDA-required labeling information). This term can also ap-ply to the use of a marketed product in a patient population(e.g. pediatric, pregnant, etc.), dosage, or dosage form thatdoes not have FDA approval.Off-label use can be motivated by several factors [57, 68]. For example, a product may be used for a specificpopulation for which it has not been approved. Also, if amedication has been approved to treat a specific condition,medications from the same class of drugs may also be usedto treat that condition. Finally, if the features of two medi-cal conditions are similar, a physician may use a medicationapproved for one of these conditions to treat both.Off-label use is quite common in clinical practice; up toone-fifth prescriptions are off-label . There are manyreasons why it remains common. For example, adding ad-ditional indications for an already approved medication canbe costly and time-consuming, and revenues for the newindication may not offset the expense and effort of obtain-ing approval. Moreover, generic medications may not havethe requisite funding foundations needed to pursue FDA ap-proval. Therefore, drug proprietors may never seek FDAapproval for common uses.Although off-label use is not illegal, off-label marketingis prohibited. Off-label marketing refers to directly promot-ing or advertising a medical product for any indication thatthe FDA has not approved. In fact, this is considered to befraud and is punishable under the False Claims Act (FCA).",
  ". Harms of off-label promotion by GenAI": "Social media websites, including online health communi-ties, Twitter, Facebook, Amazon, and others, as well asscientific articles in academic journals, are potentially thelargest source of data related to off-label use of medi-cal products . Because LLMs are trained on massivedatasets, they can learn these off-label uses and remainin parametric memory, or alternatively be surfaced via re-trieved augmented generation (RAG) .This poses potential dangers to public health. For exam- ple, a user may be misled to believe that an off-label useof a prescription drug or medical product is safe or effec-tive, exposing them to the potential adverse side effects ofa product that has not been adequately tested for safety andeffectiveness in treatment of a particular condition. Theymay also be recommended treatments that are ineffective,or even nonsensical treatments, or be recommended moreexpensive, yet inadequately tested products. Given the mas-sive scale at which GenAI models operate, this can lead tosignificant public health risk and potential penalties .From a regulatory perspective, it is not clear what tech-nical category GenAI will fall into, nor what regulationsthey will be subjected to. For example, the FDA does notcategorically prohibit discussing off-label uses, making anuanced distinction between communication and promo-tion. Moreover, based on the differences between GenAIand prior ML methods, new regulatory frameworks may bedeveloped to address these GenAI-specific challenges andrisks . Regardless of this, off-label promotion poses po-tential dangers to public health that ought to be minimized.",
  ". Detecting off-label use with ML": "Previous work has focused on applying ML to detecting off-label use in electronic health records , online healthcommunities such as MedHelp, WebMD, Drugs.com, andHealthBoards.com , and more recently so-cial media sites . Recent work has leveragedtransformer-based methodologies (e.g. BERT ) to iden-tify these off-label uses. However, to the best of our knowl-edge, the issue of off-label promotion by GenAI models hasnot been explored.",
  ". Methods": "contains a diagram outlining the overall approach tooff-label promotion detection. It focuses on evaluating theoutput of a MLLM that consumes image and text and pro-duces text. In this work, we specifically consider the usecase where the user provides the MLLM model with an im-age of a product label, and asks a question about it. Theproposed method evaluates the model response, taking intoaccount the user query, to detect instances of off-label pro-motion.The evaluation algorithm consists of the following 4 se-quential steps: (1) input standardization, (2) named entityrecognition, (3) product and indication recognition, and (4)off-label identification.",
  ". Input standardization": "This step aims to standardize the language of the user queryby correcting irregular spellings and orthographic errors.Specifically, we used a context-sensitive spelling correctionmodel for clinical text . Note that abbreviations may . Overview of a generative artificial intelligent system for medical product question answering, product recommendation, andgeneral medical question answering. Such system may handle a handle a diverse range of biomedical data modalities, and use a number ofevidence sources, some of which are not approved by the FDA.",
  ". Named entity recognition": "This second step identifies medical product names and in-dications (i.e. diseases, conditions) in the GenAI model re-sponses. To do so, we leverage existing named entity recog-nition (NER) methods for biomedical terms. There exist alarge number of such methods . In this work, we specif-ically used two BioBERT-based biomedical represen-tation language models fine-tuned to perform NER for drugnames and diseases respectively. We found that these BERTmodels perform significantly better than previous rule- anddictionary-based approaches such as cTAKES .",
  "Products and indications identified in the previous step(Sec.3.2) are matched to those in the FDALabel database": ". This web-based application1 was developed by theFDA and allows access to the most up-to-date medical la-beling data for over 147,000 human prescription and over-the-counter (OTC) drugs and devices. It contains imagesof the product labels as well as information about approvedindications, active ingredients, usage, dosage, contraindica-tions, side effects, etc.This matching was done by computing word embeddingsand using the cosine similarity to match the NER entitiesto those in FDALabel. We specifically used an embeddingdeveloped for medical concepts, BioBERT , but otherembeddings may be used .",
  ". Off-label identification": "The final step identifies any product-indication associationbetween the user query and the GenAI response that is notFDA-approved. For each product identified in the query,we extract the list of FDA-approved indications from theFDALabel dataset. If any disease not listed in the list ofFDA-approved indications is identified in the GenAI re-sponse (following Sec.3.3), we zero-shot prompt a T5-largemodel to determine if the association entails a recom-mendation. If so, we conclude that it constitutes an instanceof off-label promotion.",
  ". Experimental Setup": "To narrow down the experimentation, we considered a shop-ping context where a user interacts with a MLLM modelthat helps customers find answers to product questions (see). The user provides the model with a picture of a prod-uct label, and asks a question about it. The model respondswith a textual output. Additionally, but not considered here,",
  ". Model": "For the GenAI model depicted in ,we usedAnthropics Claude 3 Sonnet .This MLLMwas released in 2024 and is available via a website( and as an API. While few details areavailable about the models development, several aspects ofits training and evaluation have been documented in An-thropics research papers. These include preference model-ing , reinforcement learning from human feedback ,constitutional AI , red-teaming , evaluation withlanguage model-generated tests , and self-correction, among others.",
  ". Synthetic user query generation": "A common approach for evaluating LLMs is through hu-man testers that probe the system to discover failures. However, these are manual, time consuming,costly and tedious processes that are limited in their abil-ity to adversarialy test GenAI models. Synthetic data gen-eration presents a better alternative that enables generatingsynthetic user queries at scale and amplifiesd the ability touncover model defects .In this work, we implement a red teaming approachbased on 100 human-generated templates that are then pop-ulated to generate a large number of synthetic queries.These templates specifically populated using indicationsfrom the FDALabel database or disease names formICD-10 .Given the large number of products in the FDAL-abel database (O(100k)) and disease names in ICD-10(O(10k)), to make the analysis tractable, we focused ourgeneration on medical products with known off-label uses.Specifically, we manually generated a list of 35 medicalproducts with a total of 143 known off-label uses, leading to100 143 = 14300 synthetic queries about these uses. Foreach product, we downloaded a copy of its label from theFDA site , which was provided to the MLLM togetherwith the query.In addition to this, to enable the identification methoddescribed in Sec.3.3 which requires a product name, these",
  ". Experimental Results": "A total of 14300 synthetic customer queries were generatedfor 35 pharmaceuticals. After the model responses wereprocessed using our proposed off-label detection method, atotal of 15.4% responses were identified to contain off-labelindications. We were able to identify off-label indicationsfor 33 products out of the 35 products considered in thiswork. A small example of off-label indications observedfor our selected product list is shown in .Using human annotations on a 2000 random sample,we evaluated the performance of our off-label detectionmethod, and concluded it achieved a precision, recall andF1 score of 85.75%, 80.47% and 83.02% respectively.",
  ". Conclusion": "The primary objective of this study was to investigate a keyshortcoming of generalist GenAI in medical uses, that is,the off-label promotion of medical products, and highlightthe importance by model developers to adhere to existingregulations. Using Claude 3 as an example, we demon-strated that models trained on a vast corpus of internet datawith limited filtering can learn unvetted product-indicationuses, and consequently promote products for uses for whichsafety and efficacy has not been adequately evaluated.In addition to this, we demonstrated a proof-of-principlemethod for the detection of off-label medical product pro-motion in MLLM responses. Using our algorithm, we iden-tified instances of off-label promotion for a selection of 35pharmaceuticals. This method may be used to introducepost-hoc guardrails that monitor and filter the MLLM re-sponses before presenting them to the user, and adapt themto make them harmless .Limitations and Future Work.This is a proof-of-concept work that aimed to highlight potential GenAI harmsand regulatory breaches. While we have relied on Claude 3,we have observed similar behavior in other MLLMs, and amore comprehensive evaluation will be needed before con-clusions can be made about the prevalence of off-label rec-ommendations. Also, our work focused on one form of off-",
  "Mirana Angel,Haiyi Xing,Anuj Patel,AmalAlachkar, and Pierre Baldi. Performance of large lan-guage models on pharmacy exam: A comparative as-sessment using the NAPLEX. 2023. 1": "Rohan Anil, Andrew M Dai, Orhan Firat, MelvinJohnson, Dmitry Lepikhin, Alexandre Passos, SiamakShakeri, Emanuel Taropa, Paige Bailey, Zhifeng Chen,Eric Chu, Jonathan H Clark, Laurent El Shafey, Yan-ping Huang, Kathy Meier-Hellstern, Gaurav Mishra,Erica Moreira, Mark Omernick, Kevin Robinson, Se-bastian Ruder, Yi Tay, Kefan Xiao, Yuanzhong Xu,Yujing Zhang, Gustavo Hernandez Abrego, JunwhanAhn, Jacob Austin, Paul Barham, Jan Botha, JamesBradbury, Siddhartha Brahma, Kevin Brooks, MicheleCatasta, Yong Cheng, Colin Cherry, Christopher AChoquette-Choo, Aakanksha Chowdhery, ClementCrepy, Shachi Dave, Mostafa Dehghani, Sunipa Dev,Jacob Devlin, Mark Daz, Nan Du, Ethan Dyer, VladFeinberg, Fangxiaoyu Feng, Vlad Fienber, MarkusFreitag, Xavier Garcia, Sebastian Gehrmann, Lu-cas Gonzalez, Guy Gur-Ari, Steven Hand, HadiHashemi, Le Hou, Joshua Howland, Andrea Hu, Jef-frey Hui, Jeremy Hurwitz, Michael Isard, Abe It-tycheriah, Matthew Jagielski, Wenhao Jia, KathleenKenealy, Maxim Krikun, Sneha Kudugunta, ChangLan, Katherine Lee, Benjamin Lee, Eric Li, MusicLi, Wei Li, Yaguang Li, Jian Li, Hyeontaek Lim,Hanzhao Lin, Zhongtao Liu, Frederick Liu, Mar-cello Maggioni, Aroma Mahendru, Joshua Maynez, Vedant Misra, Maysam Moussalem, Zachary Nado,John Nham, Eric Ni, Andrew Nystrom, Alicia Parrish,Marie Pellat, Martin Polacek, Alex Polozov, ReinerPope, Siyuan Qiao, Emily Reif, Bryan Richter, ParkerRiley, Alex Castro Ros, Aurko Roy, Brennan Saeta,Rajkumar Samuel, Renee Shelby, Ambrose Slone,Daniel Smilkov, David R So, Daniel Sohn, SimonTokumine, Dasha Valter, Vijay Vasudevan, Kiran Vo-drahalli, Xuezhi Wang, Pidong Wang, Zirui Wang,Tao Wang, John Wieting, Yuhuai Wu, Kelvin Xu,Yunhan Xu, Linting Xue, Pengcheng Yin, Jiahui Yu,Qiao Zhang, Steven Zheng, Ce Zheng, Weikang Zhou,Denny Zhou, Slav Petrov, and Yonghui Wu. PaLM 2technical report. 2023. 1",
  "Anthropic. The claude 3 model family: Opus, sonnet,haiku. Technical report, 2024. 1, 4": "Amanda Askell, Yuntao Bai, Anna Chen, Dawn Drain,Deep Ganguli, Tom Henighan, Andy Jones, NicholasJoseph, Ben Mann, Nova DasSarma, Nelson El-hage, Zac Hatfield-Dodds, Danny Hernandez, JacksonKernion, Kamal Ndousse, Catherine Olsson, DarioAmodei, Tom Brown, Jack Clark, Sam McCandlish,Chris Olah, and Jared Kaplan. A general language as-sistant as a laboratory for alignment. 2021. 4",
  "Richard C Ausness. Theres danger here, cherie!: Li-ability for the promotion and marketing of drugs andmedical devices for Off-Label uses. Brooklyn Law Re-view, 73(4):12531326, 2008. 2": "Yuntao Bai, Andy Jones, Kamal Ndousse, AmandaAskell, Anna Chen, Nova DasSarma, Dawn Drain,StanislavFort,DeepGanguli,TomHenighan,Nicholas Joseph, Saurav Kadavath, Jackson Kernion,Tom Conerly, Sheer El-Showk, Nelson Elhage, ZacHatfield-Dodds, Danny Hernandez, Tristan Hume,Scott Johnston, Shauna Kravec, Liane Lovitt, NeelNanda, Catherine Olsson, Dario Amodei, Tom Brown,Jack Clark, Sam McCandlish, Chris Olah, Ben Mann,and Jared Kaplan. Training a helpful and harmless as-sistant with reinforcement learning from human feed-back. 2022. 4",
  "Yuntao Bai, Saurav Kadavath, Sandipan Kundu,": "Amanda Askell, Jackson Kernion, Andy Jones, AnnaChen, Anna Goldie, Azalia Mirhoseini, CameronMcKinnon, Carol Chen, Catherine Olsson, Christo-pher Olah, Danny Hernandez, Dawn Drain, DeepGanguli, Dustin Li, Eli Tran-Johnson, Ethan Perez,Jamie Kerr, Jared Mueller, Jeffrey Ladish, Joshua Lan-dau, Kamal Ndousse, Kamile Lukosuite, Liane Lovitt,Michael Sellitto, Nelson Elhage, Nicholas Schiefer,Noemi Mercado, Nova DasSarma, Robert Lasenby,Robin Larson, Sam Ringer, Scott Johnston, ShaunaKravec, Sheer El Showk, Stanislav Fort, Tamera Lan-ham, Timothy Telleen-Lawton, Tom Conerly, TomHenighan, Tristan Hume, Samuel R Bowman, ZacHatfield-Dodds, Ben Mann, Dario Amodei, NicholasJoseph, Sam McCandlish, Tom Brown, and Jared Ka-plan. Constitutional AI: Harmlessness from AI feed-back. 2022. 4",
  "rich resources to facilitate precision medicine, drugsafety, and regulatory science. Drug Discov. Today,21(10):15661570, 2016. 3, 4": "DeepGanguli,LianeLovitt,JacksonKernion,Amanda Askell,Yuntao Bai,Saurav Kadavath,Ben Mann, Ethan Perez, Nicholas Schiefer, KamalNdousse, Andy Jones, Sam Bowman, Anna Chen,Tom Conerly, Nova DasSarma, Dawn Drain, NelsonElhage, Sheer El-Showk, Stanislav Fort, Zac Hatfield-Dodds, Tom Henighan, Danny Hernandez, TristanHume, Josh Jacobson, Scott Johnston, Shauna Kravec,Catherine Olsson, Sam Ringer, Eli Tran-Johnson,Dario Amodei, Tom Brown, Nicholas Joseph, SamMcCandlish, Chris Olah, Jared Kaplan, and JackClark. Red teaming language models to reduce harms:Methods, scaling behaviors, and lessons learned.2022. 4 Deep Ganguli, Amanda Askell, Nicholas Schiefer,Thomas I Liao, Kamile Lukosiute, Anna Chen,Anna Goldie, Azalia Mirhoseini, Catherine Olsson,Danny Hernandez, Dawn Drain, Dustin Li, Eli Tran-Johnson, Ethan Perez, Jackson Kernion, Jamie Kerr,Jared Mueller, Joshua Landau, Kamal Ndousse, Ka-rina Nguyen, Liane Lovitt, Michael Sellitto, Nel-son Elhage, Noemi Mercado, Nova DasSarma, OliverRausch, Robert Lasenby, Robin Larson, Sam Ringer,Sandipan Kundu, Saurav Kadavath, Scott Johnston,Shauna Kravec, Sheer El Showk, Tamera Lanham,Timothy Telleen-Lawton, Tom Henighan, TristanHume, Yuntao Bai, Zac Hatfield-Dodds, Ben Mann,Dario Amodei, Nicholas Joseph, Sam McCandlish,Tom Brown, Christopher Olah, Jack Clark, Samuel RBowman, and Jared Kaplan. The capacity for moralSelf-Correction in large language models. 2023. 4 Yunfan Gao, Yun Xiong, Xinyu Gao, Kangxiang Jia,Jinliu Pan, Yuxi Bi, Yi Dai, Jiawei Sun, Qianyu Guo,Meng Wang, and Haofen Wang. Retrieval-Augmentedgeneration for large language models: A survey. 2023.2",
  "Emily Getzen, Yucheng Ruan, Lyle Ungar, and QiLong. Mining for health: A comparison of word em-bedding methods for analysis of EHRs data. 2022. 3": "Amelia Glaese, Nat McAleese, Maja Trebacz, JohnAslanides, Vlad Firoiu, Timo Ewalds, Maribeth Rauh,Laura Weidinger, Martin Chadwick, Phoebe Thacker,Lucy Campbell-Gillingham, Jonathan Uesato, Po-SenHuang, Ramona Comanescu, Fan Yang, Abigail See,Sumanth Dathathri, Rory Greig, Charlie Chen, DougFritz, Jaume Sanchez Elias, Richard Green, SonaMokra, Nicholas Fernando, Boxi Wu, Rachel Fo-ley, Susannah Young, Iason Gabriel, William Isaac,John Mellor, Demis Hassabis, Koray Kavukcuoglu,Lisa Anne Hendricks, and Geoffrey Irving. Improv-",
  "Kelei He, Chen Gan, Zhuoyuan Li, Islem Rekik, ZihaoYin, Wen Ji, Yang Gao, Qian Wang, Junfeng Zhang,and Dinggang Shen. Transformers in medical imageanalysis. Intelligent Medicine, 3(1):5978, 2023. 1": "TakanobuHirosawa,YukinoriHarada,MasashiYokose, Tetsu Sakamoto, Ren Kawamura, and TaroShimizu.Diagnostic accuracy of Differential-Diagnosis lists generated by generative pretrainedtransformer 3 chatbot for clinical vignettes with com-mon chief complaints: A pilot study. Int. J. Environ.Res. Public Health, 20(4), 2023. 1 Yining Hua, Hang Jiang, Shixu Lin, Jie Yang,Joseph M Plasek, David W Bates, and Li Zhou. Us-ing twitter data to understand public perceptions ofapproved versus off-label use for COVID-19-relatedmedications.J. Am. Med. Inform. Assoc., 29(10):16681678, 2022. 2",
  "Yang Liu, Jiahuan Cao, Chongyu Liu, Kai Ding, andLianwen Jin. Datasets for large language models: Acomprehensive survey. 2024. 1": "Zhengliang Liu, Zihao Wu, Mengxuan Hu, BokaiZhao, Lin Zhao, Tianyi Zhang, Haixing Dai, XianyanChen, Ye Shen, Sheng Li, Brian Murray, TianmingLiu, and Andrea Sikora. PharmacyGPT: The AI phar-macist. 2023. 1 Tim Ken Mackey, Jiawei Li, Vidya Purushothaman,Matthew Nali, Neal Shah, Cortni Bardier, MingxiangCai, and Bryan Liang. Big data, natural language pro-cessing, and deep learning to detect and characterizeillicit COVID-19 product sales: Infoveillance study ontwitter and instagram. JMIR Public Health Surveill, 6(3):e20794, 2020. 2",
  "Timo Minssen, Effy Vayena, and I Glenn Cohen. Thechallenges for regulating medical use of ChatGPT andother large language models. JAMA, 330(4):315316,2023. 1": "Azadeh Nikfarjam, Julia D Ransohoff, Alison Calla-han, Vladimir Polony, and Nigam H Shah. Profilingoff-label prescriptions in cancer treatment using socialhealth networks. JAMIA Open, 2(3):301305, 2019. 2 J Ong, Liyuan Jin, K Elangovan, Gilbert Yong SanLim, D Lim, G Sng, Yuhe Ke, Joshua Yi MinTung, Ryan Jian Zhong, Christopher Ming Yao Koh,Keane Zhi Hao Lee, Xiang Chen, J Chng, A Than,Ken Junyang Goh, and Daniel Shu Wei Ting.De-velopment and testing of a novel large languagemodel-based clinical decision support systems formedication safety in 12 clinical specialties.ArXiv,abs/2402.01741, 2024. 1 OpenAI, :,Josh Achiam,Steven Adler,Sand-hini Agarwal, Lama Ahmad, Ilge Akkaya, Flo-rencia Leoni Aleman, Diogo Almeida, Janko Al-tenschmidt, Sam Altman, Shyamal Anadkat, RedAvila, Igor Babuschkin, Suchir Balaji, Valerie Bal-com, Paul Baltescu, Haiming Bao, Mohammad Bavar-ian, Jeff Belgum, Irwan Bello, Jake Berdine, GabrielBernadett-Shapiro, Christopher Berner, Lenny Bog-donoff, Oleg Boiko, Madelaine Boyd, Anna-LuisaBrakman,Greg Brockman,Tim Brooks,MilesBrundage, Kevin Button, Trevor Cai, Rosie Camp-bell, Andrew Cann, Brittany Carey, Chelsea Carl-son, Rory Carmichael, Brooke Chan, Che Chang, Fo-tis Chantzis, Derek Chen, Sully Chen, Ruby Chen,Jason Chen, Mark Chen, Ben Chess, Chester Cho,Casey Chu, Hyung Won Chung, Dave Cummings,Jeremiah Currier, Yunxing Dai, Cory Decareaux,Thomas Degry, Noah Deutsch, Damien Deville, ArkaDhar, David Dohan, Steve Dowling, Sheila Dunning,Adrien Ecoffet, Atty Eleti, Tyna Eloundou, DavidFarhi, Liam Fedus, Niko Felix, Simon Posada Fish-man, Juston Forte, Isabella Fulford, Leo Gao, ElieGeorges, Christian Gibson, Vik Goel, Tarun Gogineni,Gabriel Goh, Rapha Gontijo-Lopes, Jonathan Gordon,Morgan Grafstein, Scott Gray, Ryan Greene, JoshuaGross, Shixiang Shane Gu, Yufei Guo, Chris Hallacy,Jesse Han, Jeff Harris, Yuchen He, Mike Heaton, Jo-hannes Heidecke, Chris Hesse, Alan Hickey, WadeHickey, Peter Hoeschele, Brandon Houghton, KennyHsu, Shengli Hu, Xin Hu, Joost Huizinga, ShantanuJain, Shawn Jain, Joanne Jang, Angela Jiang, RogerJiang, Haozhun Jin, Denny Jin, Shino Jomoto, BillieJonn, Heewoo Jun, Tomer Kaftan, ukasz Kaiser, AliKamali, Ingmar Kanitscheider, Nitish Shirish Keskar,Tabarak Khan, Logan Kilpatrick, Jong Wook Kim,Christina Kim, Yongjik Kim, Jan Hendrik Kirch-ner, Jamie Kiros, Matt Knight, Daniel Kokotajlo,ukasz Kondraciuk, Andrew Kondrich, Aris Konstan-tinidis, Kyle Kosic, Gretchen Krueger, Vishal Kuo,Michael Lampe, Ikai Lan, Teddy Lee, Jan Leike, JadeLeung, Daniel Levy, Chak Ming Li, Rachel Lim,Molly Lin, Stephanie Lin, Mateusz Litwin, TheresaLopez, Ryan Lowe, Patricia Lue, Anna Makanju,Kim Malfacini, Sam Manning, Todor Markov, YanivMarkovski, Bianca Martin, Katie Mayer, AndrewMayne, Bob McGrew, Scott Mayer McKinney, Chris-tine McLeavey, Paul McMillan, Jake McNeil, DavidMedina, Aalok Mehta, Jacob Menick, Luke Metz, An-drey Mishchenko, Pamela Mishkin, Vinnie Monaco,Evan Morikawa, Daniel Mossing, Tong Mu, Mira Mu-rati, Oleg Murk, David Mely, Ashvin Nair, ReiichiroNakano, Rajeev Nayak, Arvind Neelakantan, RichardNgo, Hyeonwoo Noh, Long Ouyang, Cullen OKeefe, Jakub Pachocki, Alex Paino, Joe Palermo, AshleyPantuliano, Giambattista Parascandolo, Joel Parish,Emy Parparita, Alex Passos, Mikhail Pavlov, AndrewPeng, Adam Perelman, Filipe de Avila Belbute Peres,Michael Petrov, Henrique Ponde de Oliveira Pinto,Michael, Pokorny, Michelle Pokrass, Vitchyr H Pong,Tolly Powell, Alethea Power, Boris Power, ElizabethProehl, Raul Puri, Alec Radford, Jack Rae, AdityaRamesh, Cameron Raymond, Francis Real, KendraRimbach, Carl Ross, Bob Rotsted, Henri Roussez,Nick Ryder, Mario Saltarelli, Ted Sanders, ShibaniSanturkar, Girish Sastry, Heather Schmidt, DavidSchnurr, John Schulman, Daniel Selsam, Kyla Shep-pard, Toki Sherbakov, Jessica Shieh, Sarah Shoker,Pranav Shyam, Szymon Sidor, Eric Sigler, MaddieSimens, Jordan Sitkin, Katarina Slama, Ian Sohl,Benjamin Sokolowsky, Yang Song, Natalie Stau-dacher, Felipe Petroski Such, Natalie Summers, IlyaSutskever, Jie Tang, Nikolas Tezak, Madeleine BThompson, Phil Tillet, Amin Tootoonchian, Eliz-abeth Tseng, Preston Tuggle, Nick Turley, JerryTworek, Juan Felipe Ceron Uribe, Andrea Vallone,Arun Vijayvergiya, Chelsea Voss, Carroll Wainwright,Justin Jay Wang, Alvin Wang, Ben Wang, JonathanWard, Jason Wei, C J Weinmann, Akila Welihinda,Peter Welinder, Jiayi Weng, Lilian Weng, Matt Wi-ethoff, Dave Willner, Clemens Winter, Samuel Wol-rich, Hannah Wong, Lauren Workman, Sherwin Wu,Jeff Wu, Michael Wu, Kai Xiao, Tao Xu, Sarah Yoo,Kevin Yu, Qiming Yuan, Wojciech Zaremba, RowanZellers, Chong Zhang, Marvin Zhang, Shengjia Zhao,Tianhao Zheng, Juntang Zhuang, William Zhuk, andBarret Zoph. GPT-4 technical report. 2023. 1",
  "Ethan Perez, Saffron Huang, Francis Song, TrevorCai, Roman Ring, John Aslanides, Amelia Glaese,Nat McAleese, and Geoffrey Irving. Red teaming lan-guage models with language models. 2022. 4": "Ethan Perez, Sam Ringer, Kamile Lukosiute, Ka-rina Nguyen, Edwin Chen, Scott Heiner, Craig Pet-tit, Catherine Olsson, Sandipan Kundu, Saurav Kada-vath, Andy Jones, Anna Chen, Ben Mann, Brian Is-rael, Bryan Seethor, Cameron McKinnon, ChristopherOlah, Da Yan, Daniela Amodei, Dario Amodei, DawnDrain, Dustin Li, Eli Tran-Johnson, Guro Khun-dadze, Jackson Kernion, James Landis, Jamie Kerr,Jared Mueller, Jeeyoon Hyun, Joshua Landau, Ka-mal Ndousse, Landon Goldberg, Liane Lovitt, Mar-tin Lucas, Michael Sellitto, Miranda Zhang, NeeravKingsland, Nelson Elhage, Nicholas Joseph, NoemMercado, Nova DasSarma, Oliver Rausch, RobinLarson, Sam McCandlish, Scott Johnston, ShaunaKravec, Sheer El Showk, Tamera Lanham, TimothyTelleen-Lawton, Tom Brown, Tom Henighan, Tristan Hume, Yuntao Bai, Zac Hatfield-Dodds, Jack Clark,Samuel R Bowman, Amanda Askell, Roger Grosse,Danny Hernandez, Deep Ganguli, Evan Hubinger,Nicholas Schiefer, and Jared Kaplan. Discovering lan-guage model behaviors with Model-Written evalua-tions. 2022. 4",
  "David C Radley, Stan N Finkelstein, and Randall SStafford.Off-label prescribing among office-basedphysicians.Arch. Intern. Med., 166(9):10211026,2006. 2": "Colin Raffel, Noam Shazeer, Adam Roberts, Kather-ine Lee, Sharan Narang, Michael Matena, Yanqi Zhou,Wei Li, and Peter J Liu. Exploring the limits of trans-fer learning with a unified text-to-text transformer.2019. 3 Alvin Rajkomar, Eric Loreaux, Yuchen Liu, JonasKemp, Benny Li, Ming-Jun Chen, Yi Zhang, AfrozMohiuddin, and Juraj Gottweis. Deciphering clinicalabbreviations with a privacy protecting machine learn-ing system. Nat. Commun., 13(1):7456, 2022. 3 Laila Rasmy, Yang Xiang, Ziqian Xie, Cui Tao, andDegui Zhi. Med-BERT: pretrained contextualized em-beddings on large-scale structured electronic healthrecords for disease prediction. NPJ Digit Med, 4(1):86, 2021. 3 Malik Sallam, Nesreen A Salim, Muna Barakat, andAlaa B Al-Tammemi. ChatGPT applications in med-ical, dental, pharmacy, and public health education: Adescriptive study highlighting the advantages and lim-itations. Narra J, 3(1):e103, 2023. 1 Guergana K Savova, James J Masanz, Philip V Ogren,Jiaping Zheng, Sunghwan Sohn, Karin C Kipper-Schuler, and Christopher G Chute. Mayo clinical textanalysis and knowledge extraction system (cTAKES):architecture, component evaluation and applications.J. Am. Med. Inform. Assoc., 17(5):507513, 2010. 3 Hugo Touvron, Louis Martin, Kevin Stone, PeterAlbert, Amjad Almahairi, Yasmine Babaei, NikolayBashlykov, Soumya Batra, Prajjwal Bhargava, ShrutiBhosale, Dan Bikel, Lukas Blecher, Cristian CantonFerrer, Moya Chen, Guillem Cucurull, David Esiobu,Jude Fernandes, Jeremy Fu, Wenyin Fu, Brian Fuller,Cynthia Gao, Vedanuj Goswami, Naman Goyal, An-thony Hartshorn, Saghar Hosseini, Rui Hou, HakanInan, Marcin Kardas, Viktor Kerkez, Madian Khabsa,Isabel Kloumann, Artem Korenev, Punit Singh Koura,Marie-Anne Lachaux, Thibaut Lavril, Jenya Lee, Di-ana Liskovich, Yinghai Lu, Yuning Mao, Xavier Mar-tinet, Todor Mihaylov, Pushkar Mishra, Igor Moly- bog, Yixin Nie, Andrew Poulton, Jeremy Reizen-stein, Rashi Rungta, Kalyan Saladi, Alan Schelten,Ruan Silva, Eric Michael Smith, Ranjan Subrama-nian, Xiaoqing Ellen Tan, Binh Tang, Ross Tay-lor, Adina Williams, Jian Xiang Kuan, Puxin Xu,Zheng Yan, Iliyan Zarov, Yuchen Zhang, Angela Fan,Melanie Kambadur, Sharan Narang, Aurelien Ro-driguez, Robert Stojnic, Sergey Edunov, and ThomasScialom. Llama 2: Open foundation and Fine-Tunedchat models. 2023. 1 Tu Tao, Azizi Shekoofeh, Driess Danny, Schaeker-mann Mike, Amin Mohamed, Chang Pi-Chuan, Car-roll Andrew, Lau Charles, Tanno Ryutaro, Ktena Ira,Palepu Anil, Mustafa Basil, Chowdhery Aakanksha,Liu Yun, Kornblith Simon, Fleet David, Mans-field Philip, Prakash Sushant, Wong Renee, VirmaniSunny, Semturs Christopher, Mahdavi S. Sara, GreenBradley, Dominowska Ewa, Arcas Blaise Aguera y,Barral Joelle, Webster Dale, Corrado Greg S., Ma-tias Yossi, Singhal Karan, Florence Pete, Karthike-salingam Alan, and Natarajan Vivek. Towards gen-eralist biomedical AI. NEJM AI, 1(3):AIoa2300138,2024. 1",
  "Gail A Van Norman. Off-Label use vs Off-Label mar-keting: Part 2: Off-Label MarketingConsequencesfor patients, clinicians, and researchers. JACC: Basicto Translational Science, 8(3):359370, 2023. 2": "Dave Van Veen, Cara Van Uden, Louis Blanke-meier, Jean-Benoit Delbrouck, Asad Aali, ChristianBluethgen, Anuj Pareek, Malgorzata Polacin, Ed-uardo Pontes Reis, Anna Seehofnerova, Nidhi Ro-hatgi, Poonam Hosamani, William Collins, NeeraAhuja, Curtis P Langlotz, Jason Hom, Sergios Gatidis,John Pauly, and Akshay S Chaudhari. Adapted largelanguage models can outperform medical experts inclinical text summarization. Nat. Med., 2024. 1",
  "Yijia Zhang, Qingyu Chen, Zhihao Yang, Hongfei Lin,and Zhiyong Lu. BioWordVec, improving biomedi-cal word embeddings with subword information andMeSH. Sci Data, 6(1):52, 2019. 3": "Mengnan Zhao and Christopher C Yang. Automatedoff-label drug use detection from user generated con-tent.In Proceedings of the 8th ACM InternationalConference on Bioinformatics, Computational Biol-ogy,and Health Informatics, pages 449454, NewYork, NY, USA, 2017. Association for ComputingMachinery. 2 Mengnan Zhao and Christopher C Yang. ExploitingOHC data with tensor decomposition for Off-Labeldrug use detection. In 2018 IEEE International Con-ference on Healthcare Informatics (ICHI), pages 2228. IEEE, 2018. 2"
}