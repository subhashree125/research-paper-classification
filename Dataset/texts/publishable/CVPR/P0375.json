{
  "Abstract": "A novel algorithm, called semantic line combination de-tector (SLCD), to find an optimal combination of semanticlines is proposed in this paper. It processes all lines in eachline combination at once to assess the overall harmony ofthe lines. First, we generate various line combinations fromreliable lines. Second, we estimate the score of each linecombination and determine the best one. Experimental re-sults demonstrate that the proposed SLCD outperforms ex-isting semantic line detectors on various datasets. More-over, it is shown that SLCD can be applied effectively tothree vision tasks of vanishing point detection, symmetryaxis detection, and composition-based image retrieval. Ourcodes are available at",
  ". Introduction": "A semantic line is defined as a meaningful line sepa-rating distinct semantic regions in an image. Besides thisunary definition, multiple semantic lines in an image aresupposed to convey the global scene structure properly .It is challenging to detect such semantic lines because theyare often implied by complicated region boundaries. More-over, they should represent the image composition opti-mally by dividing it into semantic regions harmoniously.Semantic lines are essential elements in many vision ap-plications. For example, a horizon line ,which is a specific type of semantic line, can be exploited toadjust the levelness of an image . A reflection sym-metry axis , which is another type of semanticline, provides visual cues for object recognition and patternanalysis. Vanishing points, conveying depth impression inimages, can be estimated by detecting dominant parallel se-mantic lines in the 3D world . In autonomousdriving systems , boundaries of road lanes canbe also described by semantic lines.Recently, several attempts have beenmade to detect semantic lines. These techniques performline detection and refinement sequentially. At the detection",
  "Positive pair": ". After selecting reliable line candidates, there are twoexisting approaches to semantic line detection. The first approachin (a) focuses on locating a line near a region boundary and elimi-nating overlapping lines. However, a redundant line still remains,since this approach does not consider how well a group of detectedlines represents the layout of a scene. The second approach in (b)takes into account only the pairwise correlation between two lines,so it may fail to assess the overall harmony of more than two se-mantic lines. In contrast, in (c), the proposed SLCD generates anumber of line combinations, analyzes all lines in each combina-tion at once, and then finds the most harmonious combination thatconveys the global scene composition optimally. stage, they extract deep line features to classify and regresseach line candidate. At the refinement stage, reliable se-mantic lines are determined by removing redundant lines.Specifically, to refine line candidates, non-maximum sup-pression (NMS) is performed in , as illustratedin (a). Lee et al. iteratively select the reli-able line near boundary pixels and remove overlapping lineswith the selected one. Han et al. simplify the NMS pro-cess by adopting a Hough line space. Jin et al. processeach candidate through comparative ranking and matching.These techniques, however, do not consider the overall har-mony among detected lines. To cope with this issue, Jin etal. estimate the relation score for every pair of detectedlines and then decide harmonious semantic lines via graphoptimization. But, they may yield sub-optimal results, sinceonly the pairwise relationships between lines are exploited,as in (b).",
  ". Overview of the proposed SLCD algorithm": "In this paper, we propose a novel algorithm, called se-mantic line combination detector (SLCD), to find an opti-mal group of semantic lines. It processes all lines in a linegroup (or combination) simultaneously, instead of analyz-ing each pair of lines, to estimate the overall harmony, asin (c). shows an overview of the proposedSLCD. First, we select reliable lines from line candidatesand then generate a number of line combinations. Second,we score all line combinations and determine the combina-tion with the highest score as the optimal group of semanticlines. To this end, we design two novel modules for seman-tic feature grouping and compositional feature extraction.We also introduce a novel loss function to guide the fea-ture grouping module. Experimental results demonstratethat SLCD can detect semantic lines reliably on existingdatasets and a new dataset, called compositionally diverselines (CDL). Moreover, it is shown that SLCD can be usedeffectively in various applications.This work has the following major contributions:",
  ". Related Work": "Semantic lines, located near the boundaries of different se-mantic regions, outline the layout and composition of animage. They play an important role in various vision ap-plications. Horizons are a specific typeof semantic lines, which can be applied to adjust the lev-elness of images and improve their aesthetics . In, dominant parallel lines in the 3D world are de-tected to estimate vanishing points, which convey depth im-pression on 2D images. Also, in , reflectionsymmetry axes are identified to analyze the shapes of ob-jects or patterns. These types of lines can be regarded as",
  "CDL is available at": "highly implied semantic lines. In , straight lanesare detected to aid in vehicle maneuvers in road environ-ments. Furthermore, semantic lines are essential visual cuesin photographic composition . They direct viewersattention and help to compose a visually balanced image.Several semantic line detectors havebeen proposed. They perform in two stages: line detectionand refinement. At the detection stage, deep line featuresare extracted to classify and regress each line candidate.At the refinement stage, reliable semantic lines are deter-mined by removing irrelevant candidates, based on NMS or graph optimization . More specifically,Lee et al. detect reliable lines with classification proba-bilities higher than a threshold. They then iteratively selectsemantic lines and remove overlapping lines with the se-lected one, by employing the edge detector in . Hanet al. predict the probability of each candidate in aHough parametric space. They simplify NMS by comput-ing the centroids of connected components in the Houghspace. Jin et al. design two comparators to estimate thepriority and similarity between two lines. Then, they deter-mine the most reliable lines and eliminate redundant onesalternately through pairwise comparisons. However, thesetechniques do not consider how well a groupof detected lines represents the global scene structure. Toaddress this issue, Jin et al. analyze the pairwise har-mony of detected lines. They first estimate a harmony scorefor a pair of detected lines. They then construct a completegraph and determine harmonious semantic lines by finding amaximal weight clique. Their method, however, may yieldsub-optimal results because it considers only pairwise re-lationships between lines. On the contrary, the proposedSLCD finds an optimal combination of semantic lines byanalyzing all lines in each combination simultaneously.",
  ". Proposed Algorithm": "We propose a novel algorithm, called SLCD, to detectan optimal combination of semantic lines, an overview ofwhich is in . First, we select K reliable lines fromline candidates and then generate a number of line combina-tions. Second, we score all the line combinations and deter-mine the combination with the highest score as the optimalgroup of semantic lines.",
  ". Generating Line Combinations": "Initializing line candidates: We generate line candidates,which are end-to-end straight lines in an image.Eachline candidate is parameterized by polar coordinates in theHough space . By quantizing the coordinates uniformly,we obtain N line candidates. The default N is 1024. Filtering line candidates: Given the N line candidates,there are 2N possible line combinations in total. Since thisnumber of combinations is unmanageable, we filter out ir-relevant lines to maintain K reliable ones only. To this end,we design a simple line detector by modifying S-Net in .Given an image, the detector obtains a convolutional featuremap and extracts line features by aggregating the features ofpixels along each line candidate. Then, it computes the clas-sification probability and regression offset of each candi-date. We select the most reliable candidate with the highestprobability and remove overlapping lines with the selectedone. We iterate this process K times to determine K reli-able lines. The default K is 8. shows examplesof selected reliable lines. Note that, in this filtering, falsenegatives occur rarely because the K lines are selected viaNMS even though their classification probabilities are nothigh. The architecture of the modified S-Net is described indetail in the appendix (Section A.1).",
  ". Assessing Line Combinations": "When a line combination divides an image insufficiently orover-segments it into unnecessary parts, it does not describethe overall structure of the scene properly. On the contrary,an optimal combination of semantic lines should convey theimage composition reliably and efficiently (i.e. with a smallnumber of lines). To find the best line combination, we de-velop the semantic line combination detector (SLCD). Fig-ure 3 shows the structure of SLCD, which performs encod-ing, semantic feature grouping, compositional feature ex- . From a set of line candidates, the line detector selectsK reliable lines, depicted in orange. A high recall rate is achievedbecause a sufficient number of reliable lines are selected throughNMS. Ground-truth semantic lines in green are in the insets.",
  "traction, and score regression. The detailed architecture ofSLCD is described in the appendix (Section A.2)": "Encoding: Given an image, we extract multi-scale featuremaps of ResNet50 . Then, we match their spatial res-olutions via bilinear interpolation and concatenate them inthe channel dimension. We then squeeze the channels us-ing 2D convolutional layers to obtain an aggregated featuremap F RHW C, where H, W, and C are the featureheight, the feature width, and the number of channels. Semantic feature grouping: Semantic lines are locatednear the boundaries between distinct regions. For their re-liable detection, it is desirable to separate different regionalparts more clearly. We hence attempt to group pixel featuresinto multiple regions through cross-attention .We employ three cross-attention modules.Let R RMC be a learnable matrix representing Mregions, called region query matrix. Then, we convert Rinto queries and F into keys and values by",
  "Fs = AT R.(3)": "Finally, we channel-wise concatenate F and Fs to obtain acombined feature map X RHW 2C.Note that, in (2), the softmax function is applied alongthe query axis. Thus, in A = [p1, p2, . . . , pHW ], each col-umn pi RM is a probability vector. Specifically, the mthelement pmi in pi is the probability that pixel i belongs to themth region query. visualizes membership maps,computed by",
  "(4)": "where each element is the index of the region query thatthe corresponding pixel most likely belongs to. We see thateach image is partitioned into M meaningful regions. Thus,Fs in (3) represents the regional membership of each pixeland is used to make the feature map X more discriminative.To produce the attention matrix A reliably, we design anovel loss function in .3. The default M is 8.Compositional feature extraction: For each line combi-nation, we generate three types of feature maps to extracta compositional feature map. First, we generate a binarymask B RHW for each line combination. Each elementin B is 1 if the corresponding pixel belongs to any line inthe combination, and 0 otherwise. Then, we decompose thecombined feature into a line feature map Xl and a regionfeature map Xr by",
  ". Illustration of the line collection map generation whenK = 3: (a) reliable lines, (b) line combinations, and (c) line col-lection maps": "Moreover, we generate a line collection map L=[L1, L2, . . . , LK] RHW K, where Lk RHW is aternary mask for the kth reliable line, as illustrated in Fig-ure 6. If the kth reliable line does not belong to the linecombination, all elements in Lk are set to 0. Otherwise,each value in Lk is set to either 1 or 1 to indicate wherethe corresponding pixel is located between the two parts di-vided by the kth reliable line. In other words, Lk informshow the kth line splits the image into two regions. We thenproduce a positional feature map P RHW 2C by apply-ing a series of fully connected layers to L. Then, we yield acompositional feature map Z RHW 6C by",
  "which contains information about how the lines in the com-bination separate the image into multiple parts": "Score regression: Lastly, using a regressor, we estimatea composition score for each line combination. Then, wedeclare the line combination with the highest score as theoptimal group of semantic lines. The regressor takes thecompositional feature map Z in (6) as input and predicts acomposition score s within . It is implemented usinga bilinear interpolation layer and a series of 2D convolutionlayers and fully connected layers with the ReLU activation.",
  "To train SLCD, we design two loss functions": "Semantic region separation loss: When two pixels i andj are located in distinct regions, they should be assigned todifferent region queries. In other words, their probabilityvectors pi and pj in the attention matrix A should be farfrom each other. Let X and Y be the two regions dividedby a ground-truth line. Their probability vectors are definedas",
  "(8)": "where D denotes the KLD, pXl and pYl are the regionsdivided by the lth ground-truth line, and T is the number ofground-truth lines. Both D(pXl pYl) and D(pYl pXl)are computed because D is not commutative. With LSRS,it is possible to roughly segment an image into meaningfulparts, as illustrated in , even though no ground-truthlabels for semantic segmentation are used for training.Regression loss: We also design a loss for regressing thecomposition score of each line combination. To this end,we employ the HIoU metric that quantifies the struc-tural layout of a line combination. Let c and c denote aline combination and the ground-truth combination, respec-tively. We compute the HIoU between c and c and useit as the ground-truth composition score s of c. Then, theregression loss is defined as",
  ". Implementation Details": "We adopt ResNet50 as the encoder of the proposedSLCD. We use the AdamW optimizer with a learningrate 104, a weight decay of 104, = 0.5, 1 = 0.9,and 2 = 0.999. We use a batch size of two for 400,000iterations. Training images are resized to 480 480 andaugmented by random horizontal flipping. We fix the num-ber of line candidates, reliable lines, and region queries toN = 1024, K = 8, and M = 8, respectively. We setH = 60, W = 60, and C = 96.",
  ". Datasets": "SEL : It is the first dataset for semantic line detection.It contains 1,750 images, which are split into 1,575 train-ing and 175 test images. Each semantic line is annotatedby the coordinates of two endpoints on an image boundary.In SEL, most images are high-quality landscapes, in whichsemantic lines are often obvious.SEL Hard : It contains 300 test images only, selectedfrom the ADE20K segmentation dataset . It is challeng-ing because of cluttered scenes or occluded objects.NKL : It is a relatively large dataset of 5,200 trainingand 1,300 testing images. It includes both indoor and out-door scenes.CDL: We construct CDL to contain 7,100 scenes with di-verse contents and compositions. It is split into 6,390 train-ing and 710 test images. As in , the images are cat-egorized into seven composition classes: Horizontal, Verti-cal, Diagonal, Triangle, Symmetric, Low, and Front. In Lowand Front, humans and animals are essential parts of theimage composition. In the other classes, most images areoutdoor ones, as in the other datasets. To construct CDL,semantic lines were manually annotated in about 200 man-hours. More examples and the annotation process are pro-vided in the appendix (Section B).",
  ". Metrics": "As mentioned earlier, the harmony of detected lines is moreimportant than individual lines in semantic line detection.Therefore, the main paper discusses only HIoU perfor-mances. The precision, recall, and f-measure results, whichare metrics used in previous work, are compared in the sup-plemental document.HIoU: An optimal group of semantic lines conveys a har-monious impression about the composition of an image.To assess the overall harmony of detection results, we usethe HIoU metric .It measures the consistency be-tween the division of an image by detected lines and thatby the ground truth. Let S = {s1, s2, . . . , sN} and T ={t1, t2, . . . , tM} be the regions divided by the detected linesand the ground-truth lines, respectively.Then, HIoU iscomputed as",
  ". Comparative Assessment": "compares the HIoU scores of the proposed SLCDwith those of the existing detectors on theSEL, SEL Hard, NKL, and CDL datasets. Also, compares detection results qualitatively. The existing de-tectors miss correct lines or fail to remove redundant lines,yielding sub-optimal results. In contrast, SLCD detects se-mantic lines more precisely and represents the compositionmore reliably than the existing detectors do. More detectionresults are available in the appendix (Section D). Comparison on SEL: In , SLCD outperforms theexisting detectors on SEL. Compared with the second-bestHSLD, SLCD yields a wide HIoU margin of 3.06. This in-dicates that SLCD finds an optimal group of semantic linesmore effectively by processing all lines in each combina-tion simultaneously, instead of performing pairwise com-parisons in HSLD. Comparison on SEL Hard: As done in , we conductexperiments on SEL Hard using the networks trained on theSEL dataset. In , SLCD ranks 2nd on SEL Hard.DRM provides a better result than SLCD, but it demands",
  "Comparison on NKL: SLCD surpasses all existing detec-tors. For example, its HIoU score is 1.92 points higher thanthe second-best HSLD": "Comparison on CDL: also lists HIoU scores onthe proposed CDL dataset. For a fair comparison, we trainthe existing detectors on CDL using their publicly availablesource codes. We see that SLCD outperforms all existingdetectors on CDL as well. SLNet, DHT, and DRM yieldpoor results because they do not consider the overall har-mony of detected lines. HSLD is better than these detec-tors but is inferior to the proposed SLCD. We compare and",
  "We conduct several ablation studies to analyze each compo-nent of the proposed SLCD": "The number of M: lists the HIoU performanceson the CDL dataset, according to the number M of regionqueries. At the default M = 8, SLCD achieves the bestperformance. When M is smaller or bigger than 8, the per-formance degrades due to under- or over-segmentation ofsemantic parts, respectively, as shown in . Efficacy of LSRS: In , if the proposed SRS lossLSRS in (8) is excluded from the training, the performancedrops by 2.14 points. It means that the composition analysisbased on the SRS loss is essential for finding optimal linecombinations. Efficacy of compositional feature extraction: SLCD ex-tracts the compositional feature map Z for each line com-bination, by processing the line feature map Xl, the regionfeature map Xr, and the positional feature map P in (6). In, Method I uses the line feature map only, while IIuses the region feature map only. Method III utilizes bothfeature maps. Method IV, which is the proposed SLCD,uses all three maps.Method I yields the worst result, for it uses only the con-textual information near line pixels. Method II is slightlybetter than Method I, by exploiting the regional informa-tion. Using both line and region feature maps, III providesa better result. Moreover, IV further improves the perfor-mance significantly by utilizing the positional feature map.This is because the overall harmony is estimated more ef-fectively, by combining the line structures in the positionalfeature map with scene contexts.",
  ". Dominant Vanishing Point Detection": "A vanishing point (VP) facilitates understanding of the 3Dgeometric structure. We apply the proposed SLCD to de-tect dominant VPs, by identifying vanishing lines. We usethe AVA landscape dataset , in which two dominant par-allel lines are annotated for each image. To detect a domi-nant VP, we generate line combinations containing two linesonly. We then find the best combination, whose intersect-ing point is declared as a VP. compares this VPdetection scheme with the existing line-based VP detectorsin . The angle accuracies (AAs) are compared.We see that SLCD is better than the existing detectors, ex-cept that its AA1 score is lower than that of Zhou et al.. shows some VP detection results.",
  "Proposed93.1593.5188.03": ". Symmetry axis detection results. In the top row, theground-truth and predicted axes are depicted by dashed red andsolid yellow lines, respectively. The membership maps are alsovisualized in the bottom row. 5.2. Reflection Symmetry Axis DetectionReflection symmetry is a visual cue for analyzing objectshapes and patterns. Its detection is challenging becausethe symmetry is only implicit in many cases. We test theproposed SLCD on three datasets: ICCV , NYU ,and SYM Hard . In these datasets, each image con-tains a single reflection symmetry axis. Thus, in the pro-posed SLCD, each of the K reliable lines is regarded asa line combination. compares the AUC A scores of the proposed SLCD and the conventional techniques. SLCD outperforms all these techniqueson all datasets. shows some detection results to-gether with the membership maps. We see that regionalparts are symmetrically divided along implied axes, en-abling SLCD to identify those axes effectively. 5.3. Composition-Based Image RetrievalExisting image retrieval techniques focus on the visual con-tents of a query image to find similar images in a database. In this work, however, we attempt to dis-cover images with similar compositions to a query image,i.e. composition-based image retrieval.We test the proposed SLCD on the Oxford 5k and Paris6k retrieval dataset . We first detect semantic lines inevery image, while storing the positional feature map P in(6). We filter out some images whose composition scoresare lower than a threshold since a low score indicates a low-quality image with inharmonious composition in general.Then, for a randomly selected query image, we compute the2-distances between the positional feature maps P of thequery and the remaining images. We determine the imageswith the smallest distances as retrieval results. shows the top-4 retrieval results for four queryimages. We see that SLCD returns structurally similar im-",
  ". t-SNE visualization of the feature space for theOxford 5k and Paris 6k dataset": "ages to the queries. This means that the positional featuremaps P, containing the structural information of semanticlines, can be used to compute the compositional differences.Based on this observation, we perform data clustering byemploying k-means on the feature space of P. Fig-ure 13 is t-SNE visualization of the clustering results.The nine images nearest to each centroid are also shown.Note that images with similar composition are grouped intothe same cluster, confirming the efficacy of SLCD in thecompositional analysis of images. 6. ConclusionsWe proposed a novel semantic line detector, SLCD, whichprocesses a combination of lines at once to estimate theoverall harmony reliably. We first generated all possibleline combinations from reliable lines. Then, we estimatedthe score of each line combination and determined the bestcombination. Experimental results demonstrated that theproposed SLCD can detect semantic lines reliably on exist-ing datasets, as well as on the new dataset CDL. Further-more, SLCD can be successfully used in vanishing pointdetection, symmetry axis detection, and image retrieval.AcknowledgementsThis work was conducted by Center for Applied Research inArtificial Intelligence (CARAI) grant funded by DAPA andADD (UD230017TD) and was supported by the NationalResearch Foundation of Korea (NRF) grants funded by theKorea government (MSIT) (No. NRF-2021R1A4A1031864and No. NRF-2022R1A2B5B03002310).",
  "Thomas M. Cover and Joy A. Thomas. Elements of Informa-tion Theory. Wiley, 2nd edition, 2006. 4": "Mohamed Elawady, Christophe Ducottet, Olivier Alata,Cecile Barat, and Philippe Colantoni. Wavelet-based reflec-tion symmetry detection via textural and color histograms.In Proc. IEEE ICCV Workshops, 2017. 1, 2, 8 Christopher Funk, Seungkyu Lee, Martin R Oswald, StavrosTsogkas, Wei Shen, Andrea Cohen, Sven Dickinson, andYanxi Liu. 2017 ICCV Challenge: Detecting symmetry inthe wild. In Proc. IEEE ICCV, 2017. 1, 2, 8, 22",
  "Filip Radenovic, Giorgos Tolias, and Ondrej Chum. Fine-tuning CNN image retrieval with no human annotation. IEEETrans. Pattern Anal. Mach. Intell., 41:16551668, 2018. 8": "Arnold WM Smeulders, Marcel Worring, Simone Santini,Amarnath Gupta, and Ramesh Jain. Content-based imageretrieval at the end of the early years. IEEE Trans. PatternAnal. Mach. Intell., 22:13491380, 2000. 8 Lucas Tabelini, Rodrigo Berriel, Thiago M. Paixao, ClaudineBadue, Alberto F. De Souza, and Thiago Oliveira-Santos.Keep your eyes on the lane: Real-time attention-guided lanedetection. In Proc. IEEE CVPR, 2021. 1, 2",
  ". The architecture of the modified line detector": "Encoding: Given an image, the encoder extracts a convolutional feature map X RHW C. Specifically, we first extractmulti-scale feature maps (the three coarsest feature maps) using ResNet50 as the backbone. We then match each channeldimension to C by applying a pair of 3 3 dilated convolutional layers with batch normalization and ReLU activation. Wealso match the resolutions of the two coarser maps to the finest one using bilinear interpolation and concatenate them. Finally,We obtain a combined feature map X by applying two 3 3 dilated convolutional layers and one 3 3 convolutional layer. Classification and regression: A line candidate, which is an end-to-end straight line in an image, can be parameterized bypolar coordinates in the Hough space . Let l = (, ) denote a line, where is the distance from the center of the imageand is its angle from the x-axis. Then, we generate an initial set of N line candidates, L = [l1, l2, . . . , lN] RN2, byquantizing and uniformly. For the N line candidates, we predict a probability vector P RN1 and an offset matrixO RN2. To this end, we extract a line feature matrix Xl RNC of L by employing a line pooling layer . Then,we feed Xl into classification and regression layers to predict P and O, respectively. More specifically, P = (f1(G)) andO = f2(G), where f1 and f2 consist of two fully-connected layers, respectively, and () is the sigmoid function. Then, weupdate the line candidates by L = L + O. NMS: We select K reliable lines from the updated set L based on the line probability matrix P. Specifically, we select theline with the highest probability and then remove the overlapping lines, whose L2-distances in polar coordinates from theselected one are lower than a threshold. We iterate this process K times to determine K reliable lines. Generating line combinations: From the K reliable lines, we generate all 2K line combinations. This process is donein parallel. Specifically, we compose a combination matrix C = [c1, c2, . . . , c2K] RK2K. Each column ci RK isa boolean vector, where the kth element cki is set to 1 if the kth reliable line belongs to the ith line combination, and 0otherwise.",
  "A.2. SLCD": "We develop the semantic line combination detector (SLCD) to find the best line combination. The structure of SLCD isshown in in the main paper. It performs four steps: encoding, semantic feature grouping, compositional featureextraction, and score regression. Here, we describe the semantic feature grouping and score regression steps in detail.Semantic feature grouping: (a) and (b) show the semantic feature grouping module and its cross-attention (CA)block, respectively. In (a), the module updates the region query matrix R three times using CA blocks. EachCA block takes F and R as input and yields updated region query matrix R. In the last block, it additionally outputs theattention matrix A. In (b), LN and MLP denote layer normalization and multi-layer perceptron, respectively. TheMLP consists of two fully connected layers with ReLU activation. Also, the projection matrices Uq, Uk, Uv RCC areimplemented by a fully connected layer.",
  ". The architectures of the semantic feature grouping module and its cross-attention block": "Score regression: We assess each line combination using a regressor. The regressor takes the compositional feature mapZ RHW 6C as input and predicts a composition score s. More specifically, we first obtain a reduced feature map byZ = f((Z)) RH4W4 C, where is the bilinear interpolation to reduce the resolution by a factor of 1 4. Also, f consistsof 2D convolution layers to reduce the channel dimension to C. We then estimate the score by s = g( Z), where Z is aflattened Z, and g consists of a series of fully connected layers with ReLU activation.",
  "A.3. Training and hyper-parameters": "Let us describe the training process of the modified line detector in detail.Line detector: We generate a ground-truth (GT) line probability vector P RN1 and a GT offset matrix O RN2.Specifically, we set Pl = 1 if the L2-distance in polar coordinates between a line candidate and the best matching GT line islower than a threshold, and Pl = 0 otherwise. Also, we obtain Ol by computing the offset vector between a line candidate land its matching GT line. To train the modified line detector, we minimize the loss",
  "L = 1cls(P, P) + 2reg(O, O)(11)": "where cls is the cross-entropy loss, and reg is the smooth L1 loss. We set 1 and 2 to 1 and 5, respectively. We use theAdamW optimizer with an initial learning rate of 104 and halve it after every 80,000 iterations five times. We usea batch size of eight. Also, we resize training images to 480 480 and augment them via random horizontal flipping andrandom rotation between 5 and 5.Hyper-parameters: lists the hyper-parameters in the proposed algorithm. We will make the source codes publiclyavailable.",
  "B.1. Data preparation": "Semantic lines represent the layout and composition of an image. Despite the close relationship between semantic linesand photographic composition, existing semantic line datasets do not consider image composition. To assess semantic linedetection results for various types of composition, we construct a compositionally diverse semantic line dataset, called CDL,in which the photos are categorized into seven composition classes: Horizontal, Vertical, Diagonal, Triangle, Symmetric,Low, and Front. In Low and Front, humans and animals are essential parts of the image composition. In the other classes,most images are outdoor ones, as in the other datasets. CDL contains 7,100 scenes split into 6,390 training and 710 testimages. shows example images and annotations in the proposed CDL.",
  "B.2. Manual annotation": "For each image, we annotated the start and end points of each semantic line. We employed an annotation tool, CVAT , asshown in . We adjusted the coordinates of each line so that the lines represented the image composition optimallyand harmoniously. Eight people inspected each annotated image, and unsatisfactory annotations were identified and re-annotated. The inspection was repeated until a consensus was made. The manual annotation process took more than 200man-hours. Manual annotations",
  "C.1. Performances": "reports the performances on the SEL and SEL Hard datasets. We compare the area under curve (AUC) performancesof the precision, recall, and F-measure curves, which are denoted by AUC P, AUC R, and AUC F, respectively . Also, compares the EA-scores on the NKL and proposed CDL datasets. Note that, unlike HIoU , AUC perfor-mances and EA-scores do not consider the overall harmony of detected lines. They only consider the positional accuracy ofeach detected line. We see that the proposed SLCD provides better results on most datasets in terms of detecting harmoniouslines while accurately identifying individual lines.",
  "Proposed84.3980.6082.4476.2175.6978.4177.0268.85": "shows the HIoU scores on the proposed CDL dataset according to the composition classes. We train the existingdetectors on CDL using their publicly available source codes. We see that the proposed SLCD outperforms all the existingtechniques in all classes without exception. Among the seven classes, Low and Front are challenging ones because thecomplex boundaries of objects (humans or animals) make it difficult to identify the implied semantic lines. Qualitativeresults are shown in Section D.3.",
  "C.2. Ablations": "N and K: As described in .1 in the main paper, to generate a manageable number of line combinations, we filterout redundant line candidates and obtain K reliable lines. lists the performances according to the number N of linecandidates and the number K of reliable lines on CDL: (a) Recall (EA-score) rate of the line detector according to N, and(b) HIoU of the proposed SLCD according to K. The processing times are also reported in seconds per frame (spf).In (a), as N increases, the recall rate gets higher. However, too large values of N make the training of the linedetector challenging, yielding a lower recall rate at N = 1444, compared to N = 1024. Hence, we set N = 1024. In (b), as K increases, the HIoU score gets higher. At K = 10, SLCD achieves the highest HIoU, but it becomestoo slow. It takes 4 times longer at K = 10 than at K = 8, whereas their HIoU gap is 0.27 only. As a tradeoff betweenperformance and speed, we set K = 8.",
  "C.3. Visualizations": "Sorting results according to composition scores: Note that we determine an optimal group of semantic lines in an image, byfinding the line combination with the highest composition score, estimated by the proposed SLCD. (b) and (c) showexamples of top-4 and bottom-4 line combinations, respectively. The top-4 detection results represent image compositionfaithfully. In contrast, the bottom-4 detection results represent it poorly. These examples indicate that the proposed SLCDevaluates each line combination reliably based on composition analysis.",
  "E.1. Dominant vanishing point detection": "We apply the proposed SLCD to detect dominant vanishing points by identifying the vanishing lines. We declare the inter-secting point of two lines as a vanishing point. We assess the proposed SLCD on the AVA landscape dataset whichcontains 2,000 training and 275 test landscape images. shows more results of vanishing point detection.",
  "E.2. Reflection symmetry axis detection": "We test the proposed SLCD on three datasets: ICCV , NYU , and SYM Hard . ICCV provides 100 training and96 test images, NYU contains 176 test images, and SYM Hard consists of 45 test images. In these datasets, each imagescontains a single reflection symmetry axis. We trained the model on the ICCV and tested it on all datsets. showsmore results of vanishing point detection. In the top row, the ground-truth and predicted axes are depicted by dashed red andsolid yellow lines, respectively. The membership maps are also visualized in the bottom row.",
  "E.3. Composition-based image retrieval": "We test the proposed SLCD on Oxford 5k and Paris 6k dataset , containing photographs of landmarks and local attractionsin two places. Since it contains indoor and outdoor images mainly, we use the network trained on NKL dataset. We firstdetect semantic lines for all the images, while storing the positional feature map P. Then, we filter out images whosethe composition scores are lower than a threshold 0.75 since a low score indicates a low quality image with inharmoniouscomposition, as shown in . Then, for a randomly selected query image, we compute the 2-distances between thepositional feature maps P of the query and the remaining images. We determine the images with the smallest distances asretrieval results. shows more results of composition-based retrieval.",
  "E.4. Road lane detection": "We apply the proposed SLCD to the lane detection task, by employing the CULane dataset . CULane is a road lanedataset in which lanes are annotated with 2D coordinates. To obtain ground-truth semantic lines corresponding to the lanes inan image, we declare the most overlapping line with each lane as a semantic line. shows some examples of originallane points and ground-truth semantic lines, depicted by red dots and green lines, respectively.",
  ". Examples of original lane points and ground-truth semantic lines": "We train SLCD and compare it with the second-best line detector HSLD . shows some lane detectionresults on the test set. SLCD detects semantic lines more reliably in road scenes than HSLD does, even though some lines areimplied due to occlusion or poor illumination. compares the HIoU and AUC results. We see that SLCD outperformsHSLD meaningfully."
}