{
  "Abstract": "Unpaired image dehazing (UID) holds significant re-search importance due to the challenges in acquiringhaze/clear image pairs with identical backgrounds. Thispaper proposes a novel method for UID named Orthogo-nal Decoupling Contrastive Regularization (ODCR). Ourmethod is grounded in the assumption that an image con-sists of both haze-related features, which influence the de-gree of haze, and haze-unrelated features, such as textureand semantic information. ODCR aims to ensure that thehaze-related features of the dehazing result closely resem-ble those of the clear image, while the haze-unrelated fea-tures align with the input hazy image. To accomplish themotivation, Orthogonal MLPs optimized geometrically onthe Stiefel manifold are proposed, which can project im-age features into an orthogonal space, thereby reducingthe relevance between different features. Furthermore, atask-driven Depth-wise Feature Classifier (DWFC) is pro-posed, which assigns weights to the orthogonal featuresbased on the contribution of each channels feature in pre-dicting whether the feature source is hazy or clear in a self-supervised fashion. Finally, a Weighted PatchNCE (WP-NCE) loss is introduced to achieve the pulling of haze-related features in the output image toward those of clearimages, while bringing haze-unrelated features close tothose of the hazy input. Extensive experiments demonstratethe superior performance of our ODCR method on UID.",
  "*Corresponding author": "where I(x), J(x), t(x) and A stand for the hazy image, theclear image, the transmission map (T-map) and the globalatmospheric light separately.To enhance image clarity and detail, numerous image de-hazing methods have been introduced. Early image dehaz-ing methods are mainly based on hand-crafted priors.These methods conduct statistical analy-ses on hazy and clear images to acquire prior knowledgefor image enhancement, but have limited robustness dueto specific assumptions.With the development of deepneural networks, many deep learning dehazing methods have emerged, which train networksin a supervised manner on large-scale synthetic datasets, re-sulting in significantly improved dehazing performance.Despite their impressive performance on synthetic data,the real-world applicability of these methods is limitedby the challenge of acquiring paired images with identi-cal backgrounds. Consequently, research into training de-hazing models on unpaired datasets is gaining traction.Most current unpaired image dehazing (UID) strategies adopt the Cycle-GAN framework , whichconstructs hazy-clear-hazy and clear-hazy-clear conversioncycles. These approaches depend on cycle-consistency lossto ensure content consistency across the dehazing process.However, the cycle-consistency loss assumes a bijective re-lationship between the two domains , which is too strictfor image dehazing. In real world, a clear image can corre-spond to a hazy image with varying degrees of haze withinthe same scene.To bypass this bijection limitation, CUT-like methods have been introduced, eschewing the Cycle-GAN architecture for a singular GAN framework. Thesemethods preserve consistency by maximizing mutual infor-mation between the features of a query patch in the dehazedoutput and the corresponding patch in the original hazy in-put, as depicted in (a). Nonetheless, this approachincurs a contradiction between maximizing mutual infor-mation and attaining effective dehazing, and do not fullyutilize the guiding role of clear images for dehazing.To achieving background consistency and bridging the",
  "Related Components": ". Illustration of how (a) the CUT-like methods and (b) ODCR work. CUT-like methods directly pull features of the query patch andpositive patch close, leading to a contradiction in maximizing the mutual information between the two patches and dehazing. In ODCR,orthogonal decoupling are proposed to decouple image features to haze-related (describing haze level) and unrelated (describing non-hazeinformation, such as semantic and texture) components. Then the mutual information between query and the positive patches in differentfeature spaces are maximized, thus avoiding the above contradiction. gap between hazy and clear domains, one feasible idea in-volves the decoupling of query patch features into haze-related components, which quantify the level of haze, andhaze-unrelated components, embodying non-haze attributeslike semantics and texture. The objective is to maximizethe mutual information between corresponding haze-relatedcomponents of the query patch and clear image patches, aswell as between haze-unrelated components of the querypatch and the hazy patch at the same location.The above feature decoupling faces two challenges. Thefirst is how to decouple the image features to componentswith low relevance. The inherent blending of haze-relatedand unrelated features underlies the conflict between maxi-mizing mutual information and effective dehazing. Decou-pling into components of reduced relevance is crucial to re-solving this conflict. According to the ASM , hazyimages are captured by deep coupling of multiple physicalquantities, making it difficult to completely realize the de-coupling of features. And the second challenge is how toassign the decoupled features as haze-related/-unrelatedcomponents. Without the guidance of ground truth images,it becomes difficult for networks to distinguish between fea-tures pertaining to haze and those that do not.To address above challenges, a novel Orthogonal Decou-pling Contrastive Regularization (ODCR) is proposed forUID in this paper. In ODCR, we first repartition the samplesaccording to different feature spaces as shown in (b).To solve the first challenge, we propose to introduce orthog-onal constraint, which is widely used in traditional machinelearning and deep learning , todecouple of image features into components with low rel- evance. To address the second challenge, a self-supervisedDepth-wise Feature Classifier (DWFC) for mapping imagefeatures to hazy or clear labels is introduced. DWFC yieldsheat vectors that reflect the significance of each channel indiscerning whether the feature is extracted from a hazy orclear image can be obtained. Based on the sample repar-tition and heat vectors, a Weighted PatchNCE (WPNCE)loss is proposed to realize the pulling of related/unrelatedfeatures in different feature space.In summary, our main contributions are as follows:",
  ". Related Works": "Unpaired Image Dehazing. Considering the difficulty ofobtaining large-scale data for supervised training, somemethods focus on learning mappingsthat restore hazy images to clear images from unpaired data.Zhu et al. first propose Cycle-GAN network based oncycle-consistency loss to solve the unpaired image-to-image(i2i) problem. Engin et al. proposed a Cycle-GAN- like method, which combines cycle-consistency and per-ceptual loss for UID. Afterwards, some Cycle-GAN-likeUID methods are proposed, among whichD4 proposed by Yang et al. realizes density-awarenessby decomposing the transmission map in ASM into hazedensity and background depth, and then achieves excel-lent results on multiple datasets. Chen et al. proposeCDD-Net combining adversarial contrastive loss and cycle-consistency loss for extracting task-relevant and -irrelevantinformation. However, these Cycle-GAN-like methods areall based on the bijection assumption between the haze andclear domains , which is overly strict as a scene maycorrespond to multiple levels of haze. To avoid the problems associated with the bijection as-sumption, Park et al. propose CUT, which maintainsconsistency by maximizing the mutual information betweenpatches at the same location in the input and output. How-ever, in image dehazing, the contradiction arises betweenmaximizing the mutual information between the hazy-clearpatch pair and the requirement that the output be a haze-free image.Subsequent CUT-like methods donot focus on this contradiction either. Unlike these meth-ods, our ODCR mitigates the contradiction by decouplingfeatures into haze-related and unrelated components, in-dividually aligning them with the corresponding compo-nents of the clear image and the original input, respec-tively.Orthogonal Constraint.Orthogonal constraintsplay a pivotal role in diminishing feature relevance and cur-tailing redundant information in traditional machine learn-ing and deep learning . Whilereduced rank Procrustes rotation and eigen decompo-sition address orthogonal constraint problems in tradi-tional machine learning, these methods are not applicablewithin deep learning frameworks. For deep learning meth-ods with orthogonal constraint, one way is to convert theproblem to an unconstrained one using Lagrange multipli-ers. However, the above method views the problem as ablack box and it is hard to take advantage of orthogonalspaces . Some methods include orthogonal reg-ularizations in loss function, which do not guarantee that theparameters are in orthogonal space. In contrast to the afore-mentioned methods, our ODCR proposes to solve the or-thogonal constraint problem using geometric optimizationon the Stiefel manifold and thus perform a strict orthogonaldecoupling of image features. Contrastive Learning for Image Dehazing. Contrastivelearning has shown power in high-level self-supervised representation learning tasks. In re-cent years, contrastive learning are also applied to low-levelimage enhancement tasks . Wu etal. first used contrastive learning in image dehazingand the proposed AECR aligns the features of the generatedquery image with those of the ground truths at pixel level. Zheng et al. propose to additionally bound the solutionspace with results of other methods, considering that thelower bound of the solution space is always far away frompositive samples. The above methods are applications ofcontrastive learning on supervised image dehazing. Chen etal. introduce adversarial contrastive learning in Cycle-GAN network to disentangle task-relevant and -irrelevantfactors for UID. However, the combination of GAN and ad-versarial contrastive learning makes the training process un-stable. CUT-like methods are based on Patch-NCE, which is a contrastive regularization that pulls thequery patch in the output close to the patch at the same loca-tion in the hazy input, leading background consistency. Butit produce a contradiction of pulling the query to hazy orclear. In ODCR, we propose a Weighted PatchNCE (WP-NCE), which avoids the contradiction by maximizing themutual information of haze-related/-unrelated componentsof query and key sample features, respectively.",
  ". Orthogonal Decoupling Contrastive Regu-larization": "In training process, given two unpaired clear image setXC = {Ci}NCi=1 and hazy image set XH = {Hj}NHj=1, a cou-ple of unpaired images {C, H} is input and we aim to traina generator G that can output a clear image G(H), whichhas a haze degree that converges to a clear image and keepsthe haze-unrelated information such as image texture andsemantics consistent with H.",
  ". Sample Repartition": "In the CUT-like methods depicted in , a query patchpq from the generated dehazed image is paired with a cor-responding patch p+ at the same location in the input hazyimage as a positive sample, while other patches in the inputimage serve as negative samples p. This approach to sam-ple partitioning, however, exhibits two critical limitations.First, it overlooks the influence of the clear domain, whichis essential for restoring the haze level in the output to thatof a clear image. Second, it creates an inherent conflict indetermining whether to align the haze level of pq close tothat of p+, when attempting to increase the mutual infor-mation between the positive sample pairs.To overcome the identified limitations, we propose a re-fined strategy for partitioning the positivity and negativityof sample patches. We assume that the features of a patchcontain both haze-related features describing the haze leveland haze-unrelated features containing image texture, se-mantics. For any given patch, its haze-related and unrelatedcomponents are separately classified as positive or negativewithin their respective feature spaces, as illustrated in (b). We adopt a dual subscript system to categorize thenature of samples. The first subscript indicates positivityor negativity in terms of haze-unrelated features: a patch at",
  ". The pipeline of the proposed ODCR": "the same location as the query patch in the hazy domain His deemed positive, while all others are negative. The sec-ond subscript signifies positivity or negativity concerninghazy or clear: patches in H are negative, whereas those inthe clear domain C are positive. This methodology resultsin distinct notational representations for various patches, aselaborated below: p+: the patch in H with the same position as pq; p+: all patches in C; p: all patches other than p+ in H.",
  "zk = H(Gienc(pk)), s.t.T = I(2)": "where H() stands for the MLP with orthogonal constraintand stands for its parameter matrix. Gienc() representsthe feature of the i-th encoder layer in the generator G.To solve the problem with orthogonal constraints, oneway is to convert it to an unconstrained problem using La-grange multipliers .However, the method views theproblem as a black box and it is hard to take advantageof orthogonal spaces . Some methods includeorthogonal regularizations in loss functions, which can-not guarantee that the parameters are in orthogonal space.Therefore, we propose to solve the orthogonal constraintproblem using geometric optimization on the Stiefel mani-fold and thus perform a strict orthogonal decomposition ofthe features.",
  ". The illustration of the geometric optimization on theStiefel manifold": "Geometric Optimization on the Stiefel Manifold.AStiefel manifold is a set containing all orthogonal matri-ces in a specified space, i.e. St(p, n) { Rnp :T = Ip}. Its tangent space at a point can be definedas: TSt(p, n) {Z Rnp : T Z + ZT = 0}. Forour orthogonal decomposition problem, the ideal approachis to find the optimal solution of H on the Stiefel manifold.Assuming that f() is a loss function defined in the Eu-clidean space and f() is its gradient in the Euclideanspace, it cannot be optimized directly using optimizers suchas SGD and ADAM , but requires an additionaltwo process. Denote the Riemannian gradient grad f()as the tangent vector gradient of f() on the tangent spaceat point :",
  "T f() 1": "2f()T (3)which points to the direction where the loss function f() onthe Stiefel manifold ascends steepest and it can be provedby the following theorem:Theorem 1.Given f() in Euclidean space andgrad f() defined by Eq. 3, grad f() is the orthogonalprojection of f() onto the tangent space of the Stiefelmanifold. And the first step is:Step 1: Project the gradient of the Euclidean space ontothe tangent space the Stiefel manifold. And the updatingprocess on the tangent space T(k)St(p, n) at iteration k+1is: = (k) grad f((k))(4) where is the gradient update step size. After that, the point on the tangent space need to be remapped onto the Stiefelmanifold based on the following theorem:Theorem 2. Given a point = (k) grad f((k))on the tangent space T(k)St(p, n) of a point on a Stiefelmanifold, there is a retraction operation:",
  "illustrates the process of updating the parameterson the manifold. The proofs of Theorems 1 and 2 are de-tailed in the Supplementary Material": "3.2.2Depth-wise Feature ClassifierProvided the features projected into orthogonal space, it isnot yet known which are haze-related and which are haze-unrelated. To solve this problem, we introduce a Depth-wise Feature Classifier (DWFC). DWFC takes the imagefeatures of H or C extracted by Genc as input to predictwhether the feature source is a hazy or clear image. Withthis self-supervised approach, one channel-wise heat-vectorcan be obtained for each set of input features. illustrates the structure of DWFC. Given an or-thogonal feature, it is input into the Depth-wise Encoder(DWE) and processed through 3 convolutional blocks. Theprocessed feature is globally average pooled (GAP) to ob-tain a one-dimensional feature vector. The feature vector isfed to a fully connection (FC) layer to get the final classifi-cation prediction probability. Note that we use depth-wiseconvolution to avoid information exchange between chan-nels to ensure that each value of the feature vector is onlyrelevant to the corresponding channel.Since the source of the feature is known, we use it as alabel and take cross-entropy loss as a objective function tooptimize the DWFC:",
  "where yh and yc denote the labels of feature source. If thesource of input feature is hazy image, then yh = 1 and": "yc = 0. h and c represent the weights of the fully connec-tion layer (pred head) of DWFC, and x represents the 1-Dfeature vector. Thus Th x and Tc x stand for the predictionthat the source of the feature is a hazy or clear image.Inspired by visualization methods in high-level computervision tasks , we argue that the absolute valuesin the results of the element-wise multiplication between xand h (or c) reflect the magnitude of the role played by thefeature of the corresponding channel in the networks deci-sion that the source of the features is hazy (or clear). Thusthe heat-vectors describing the haze (or clear) relevance canbe formulated as:",
  "wc = softmax(abs(c x))(10)": "where abs() denotes a function taking absolute values forall elements in the input vector, and softmax() stands forthe softmax function.For example, if the absolute value of an element in hxis large, it can be assumed that the feature of the correspond-ing channel prompt (or inhibit) the networks judgment thatthe feature source is a hazy image, i.e., the feature of thechannel is inclined to be a hazy-related (or unrelated) fea-ture. Specifically, for features from hazy (or clear) images,we assign them with wh (or wc).",
  ". Datasets and Metrics": "We conduct experiments on several datasets to evaluate theperformance of our method on UID. The datasets includeRESIDE , NH-HAZE 2 and Fattals . The testsets cover synthetic, artificial, and real-world images.RESIDE is a widely used image dehazing dataset con-taining several subsets. We use ITS (13990 pairs of indoorimages) from RESIDE as the training set and SOTS (500indoor and 500 outdoor image pairs) as the test set. NH-HAZE 2 is an artificial dataset for the NTIRE 2021 com-petition, which consists of 25 pairs of non-homogeneoushazy images and clear images. And Fattals dataset is a real-world dataset that includes 41 real hazy images in variousscenes. Commonly used image quality evaluation metrics:PSNR (dB) and SSIM are employed to evaluate the dehaz-ing performance of ODCR.",
  "We compare ODCR with several SOTA image dehazingmethods. Some of them are trained using paired data, in-cluding DehazeNet , AOD-Net , MSCNN andGDN . Others do not require paired data, including": "DCP , CycleGAN , CycleDehaze , YOLY ,USID-Net , RefineDNet , D4 and CUT .Notably, we follow the evaluation strategy of D4 . Wetrain our model only on ITS and test on all the test sets andall other methods also follow this strategy for fairness.Quantitative Evaluation. The quantitative comparison ofdifferent methods is recorded in . Our ODCR ob-tains the second-best results on the SOTS-indoor dataset,and the best results are obtained by GDNet, which is asupervised method. However, testing the same model onthe SOTS-outdoor and NH-HAZE 2 datasets, which are nottrained accordingly, ODCR outperforms all paired and un-paired data-based methods, including GDNet. The resultsabove demonstrate that ODCR is able to learn the patternsof haze-free images with excellent generalization by de-coupling the image features into haze-related and unrelatedcomponents and performing contrastive learning separately.Qualitative Evaluation.The qualitative comparison ofsynthetic and artificial datasets between various methods isdisplayed in . The supervised method AOD-Net fails to dehaze in local area. DCP , YOLY andD4 suffer from color distortion. Compared with CUT, which only performs contrastive learning on the hazypatches, ODCR shows improved overall dehazing perfor-mance while maintaining haze-unrelated information.In addition, the visual comparison of the different meth-ods on the real-world dataset Fattals is shown in . Itobviously illustrates that ODCR better removes haze fromthe boxed region compared to other methods and has min-imal image quality degradation including artifacts, loss ofstructural details, and color distortion, verifying the dehaz-ing effectiveness of ODCR on real-world images.",
  ". Visual comparison of various dehazing methods on Fattals dataset . Areas where our method works better are boxed out andzoomed in, or you can zoom in by yourself to get a better view": "bedding relevance, effectively decoupling haze-related andunrelated features. Our quantitative analysis contrasts threedistinct cases: the absence of Orthogonal Decoupling (OD),the imposition of an orthogonal loss function, and optimiza-tion conducted on the Stiefel manifold. The comparative re-sults, as detailed in , affirm that the Stiefel manifoldoptimization outperforms the other approaches in dehazingperformance. To further substantiate the O-MLPs capacity to attenu-ate feature relevance, we examine the cosine similarity ma-trices of the feature embeddings. delineates the inter-channel cosine similarity matrices derived from the featureprojections in each case. It indicates a substantial redun-dancy in features without OD. While the orthogonal lossfunction offers a reduction in feature relevance, it does notachieve optimal separation. In stark contrast, O-MLP, whenoptimized on the Stiefel manifold, demonstrates a markedminimization in feature relevance, which we attribute to itsstrict orthogonality. This geometric optimization is pivotalin achieving the desired feature decoupling necessary foreffective dehazing. Effectiveness of DWFC. We evaluate the effectiveness ofthe proposed DWFC. DWFC assigns haze-related and unre-lated features through a self-supervised mechanism leverag-ing the heat-vector output. Another feasible way is to stati-cally determine a fixed ratio of orthogonal features as haze- related or unrelated. As demonstrates, irrespectiveof the predetermined ratio of related to unrelated features,the dehazing capability is significantly compromised. also presents a qualitative comparison of dehazing out-",
  "(d) Fixed 7:1(e) w/ DWFC(f) Clear": ".Qualitative comparison on the assignment of re-lated/unrelated features. (a) is the hazy input. (b)-(d) are the de-hazing results of the model with different ratio of assignment. (e)is the result of the default network. And (f) is the correspondingclear image. comes under different configurations. Fixed feature ratioslead to a notable decline in image quality. The degrada-tions above stem from the absence of the DWFCs self-supervision, causing features unrelated to haze that shouldbe mapped to the hazy domain to be mistakenly alignedwith the clear domain during contrastive learning.Con-sequently, this misalignment distorts information channels,such as texture and semantics, critical for accurate dehaz-ing. In addition, the gradual improvement of the dehazingperformance as the percentage of haze-unrelated feature in-creases in and also proves the above view.Effectiveness of WPNCE. Experiments are conducted onthe loss functions to verify the effectiveness of our proposedWPNCE. Compared to PatchNCE, WPNCE exploits thehaze-related component in clear images to drive the gener-ated images close to being clear. The quantitative and qual-itative comparison between the results of using PatchNCEand WPNCE is recorded in and , respectively.Better dehazing results are obtained using WPNCE com- . Ablation study on the feature assignment method. Notethat Ratio in the table represents assigning orthogonal features ina related:unrelated ratio. For example, when ratio is 1:7, the first32 channels of a 256-channel orthogonal feature are assigned asrelated features, and the last 224 channels are unrelated features.",
  ". Conclusion": "We propose Orthogonal Decoupling Contrastive Regular-ization for UID by decoupling image feature into haze-related/-unrelated components. In particular, we repartitionthe patch samples in terms of haze-related/-unrelated. Af-terward, an orthogonal MLP geometrically optimized on theStiefel manifold is introduced to reduce the relevance be-tween the features by projecting the features of each sampleinto the orthogonal space. Furthermore, a Depth-wise Fea-ture Classifier for assigning the projected features of eachchannel as haze-related/-unrelated is proposed. Finally, anovel Weighted PatchNCE is designed to maximize the mu-tual information between the corresponding components ofquery and positive samples in different feature spaces. Ex-periments conducted on synthetic and real-world datasetsvalidate our proposal and analysis. Performance improve-ments are observed when comparing other SOTA methodsfor UID.",
  "Bolun Cai, Xiangmin Xu, Kui Jia, Chunmei Qing, andDacheng Tao. Dehazenet: An end-to-end system for singleimage haze removal. IEEE Transactions on Image Process-ing, 25(11):51875198, 2016. 1, 6": "Mathilde Caron, Piotr Bojanowski, Armand Joulin, andMatthijs Douze. Deep clustering for unsupervised learningof visual features. In Proceedings of the European confer-ence on computer vision (ECCV), pages 132149, 2018. 3 Ting Chen, Simon Kornblith, Mohammad Norouzi, and Ge-offrey Hinton. A simple framework for contrastive learningof visual representations. In International conference on ma-chine learning, pages 15971607. PMLR, 2020. 3 Xiang Chen, Zhentao Fan, Pengpeng Li, Longgang Dai, Cai-hua Kong, Zhuoran Zheng, Yufeng Huang, and Yufeng Li.Unpaired deep image dehazing using contrastive disentan-glement learning. In European Conference on Computer Vi-sion, pages 632648. Springer, 2022. 1, 2, 3",
  "Xiang Chen, Yufeng Li, Caihua Kong, and Longgang Dai.Unpaired image dehazing with physical-guided restorationand depth-guided refinement. IEEE Signal Processing Let-ters, 29:587591, 2022. 2, 3": "Xiang Chen, Jinshan Pan, Kui Jiang, Yufeng Li, YufengHuang, Caihua Kong, Longgang Dai, and Zhentao Fan. Un-paired deep image deraining using dual contrastive learning.In Proceedings of the IEEE/CVF Conference on ComputerVision and Pattern Recognition, pages 20172026, 2022. 3 Ziteng Cui, Guo-Jun Qi, Lin Gu, Shaodi You, ZenghuiZhang, and Tatsuya Harada. Multitask aet with orthogonaltangent regularity for dark object detection. In Proceedingsof the IEEE/CVF International Conference on Computer Vi-sion, pages 25532562, 2021. 2, 3, 4 Qili Deng, Ziling Huang, Chung-Chi Tsai, and Chia-WenLin. Hardgan: A haze-aware representation distillation ganfor single image dehazing. In European Conference on Com-puter Vision, pages 722738. Springer, 2020. 1",
  "Kaiming He, Ross Girshick, and Piotr Dollar. Rethinking im-agenet pre-training. In Proceedings of the IEEE/CVF Inter-national Conference on Computer Vision, pages 49184927,2019. 3": "Kaiming He, Haoqi Fan, Yuxin Wu, Saining Xie, and RossGirshick. Momentum contrast for unsupervised visual repre-sentation learning. In Proceedings of the IEEE/CVF Confer-ence on Computer Vision and Pattern Recognition (CVPR),2020. R Devon Hjelm, Alex Fedorov, Samuel Lavoie-Marchildon,Karan Grewal, Phil Bachman, Adam Trischler, and YoshuaBengio.Learning deep representations by mutual in-formation estimation and maximization.arXiv preprintarXiv:1808.06670, 2018. 3",
  "Boyi Li, Wenqi Ren, Dengpan Fu, Dacheng Tao, Dan Feng,Wenjun Zeng, and Zhangyang Wang. Benchmarking single-image dehazing and beyond. IEEE Transactions on ImageProcessing, 28(1):492505, 2018. 6, 7": "Boyun Li, Yuanbiao Gou, Shuhang Gu, Jerry Zitao Liu,Joey Tianyi Zhou, and Xi Peng. You only look yourself: Un-supervised and untrained single image dehazing neural net-work. International Journal of Computer Vision, 129:17541767, 2021. 6 Chengyang Li, Heng Zhou, Yang Liu, Caidong Yang,Yongqiang Xie, Zhongbo Li, and Liping Zhu. Detection-friendly dehazing:Object detection in real-world hazyscenes. IEEE Transactions on Pattern Analysis and MachineIntelligence, 2023. 1",
  "Pei Li, Wenlin Zhang, Chengjun Lu, Rui Zhang, and Xue-long Li. Robust kernel principal component analysis withoptimal mean. Neural Networks, 152:347352, 2022. 3": "Sun-Ao Liu, Yiheng Zhang, Zhaofan Qiu, Hongtao Xie,Yongdong Zhang, and Ting Yao. Learning orthogonal pro-totypes for generalized few-shot semantic segmentation. InProceedings of the IEEE/CVF Conference on Computer Vi-sion and Pattern Recognition, pages 1131911328, 2023. 2,3, 4 Xiaohong Liu, Yongrui Ma, Zhihao Shi, and Jun Chen. Grid-dehazenet: Attention-based multi-scale network for imagedehazing.In Proceedings of the IEEE/CVF InternationalConference on Computer Vision (ICCV), 2019. 6",
  "Yuda Song, Zhuqing He, Hui Qian, and Xin Du.Visiontransformers for single image dehazing. IEEE Transactionson Image Processing, 32:19271941, 2023. 1": "Haofan Wang, Zifan Wang, Mengnan Du, Fan Yang, ZijianZhang, Sirui Ding, Piotr Mardziel, and Xia Hu. Score-cam:Score-weighted visual explanations for convolutional neuralnetworks. In Proceedings of the IEEE/CVF conference oncomputer vision and pattern recognition workshops, pages2425, 2020. 5 Tao Wang, Guangpin Tao, Wanglong Lu, Kaihao Zhang,Wenhan Luo, Xiaoqin Zhang, and Tong Lu. Restoring vi-sion in hazy weather with hierarchical contrastive learning.Pattern Recognition, page 109956, 2023. 3 YongzhenWang,JiameiXiong,XuefengYan,andMingqiang Wei. Uscformer: Unified transformer with se-mantically contrastive learning for image dehazing. IEEETransactions on Intelligent Transportation Systems, 2023. 3 Yongzhen Wang, Xuefeng Yan, Fu Lee Wang, Haoran Xie,Wenhan Yang, Xiao-Ping Zhang, Jing Qin, and MingqiangWei. Ucl-dehaze: Towards real-world image dehazing viaunsupervised contrastive learning. IEEE Transactions on Im-age Processing, 2024. 1, 3",
  "Svante Wold, Kim Esbensen, and Paul Geladi.Principalcomponent analysis. Chemometrics and intelligent labora-tory systems, 2(1-3):3752, 1987. 2, 3": "Haiyan Wu, Yanyun Qu, Shaohui Lin, Jian Zhou, RuizhiQiao, Zhizhong Zhang, Yuan Xie, and Lizhuang Ma. Con-trastive learning for compact single image dehazing. In Pro-ceedings of the IEEE/CVF Conference on Computer Visionand Pattern Recognition, pages 1055110560, 2021. 1, 3 Yang Yang, Chaoyue Wang, Risheng Liu, Lin Zhang, XiaojieGuo, and Dacheng Tao. Self-augmented unpaired image de-hazing via density and depth decomposition. In Proceedingsof the IEEE/CVF conference on computer vision and patternrecognition, pages 20372046, 2022. 1, 2, 3, 6",
  "Tian Ye, Yunchen Zhang, Mingchao Jiang, Liang Chen, YunLiu, Sixiang Chen, and Erkang Chen. Perceiving and mod-eling density for image dehazing. European Conference onComputer Vision, 2022. 1": "Jure Zbontar, Li Jing, Ishan Misra, Yann LeCun, andStephane Deny. Barlow twins: Self-supervised learning viaredundancy reduction. In International Conference on Ma-chine Learning, pages 1231012320. PMLR, 2021. 3 Zhengxi Zhang, Liang Zhao, Yunan Liu, Shanshan Zhang,and Jian Yang. Unified density-aware image dehazing andobject detection in real-world hazy scenes. In Proceedingsof the Asian Conference on Computer Vision, 2020. 1 Haitao Zhao, Pong Chi Yuen, and James T Kwok. A novelincremental principal component analysis and its applica-tion for face recognition.IEEE Transactions on Systems,Man, and Cybernetics, Part B (Cybernetics), 36(4):873886,2006. 2, 3 Haitao Zhao, Zhihui Lai, Henry Leung, Xianyi Zhang,Haitao Zhao, Zhihui Lai, Henry Leung, and Xianyi Zhang.Sparse feature learning. Feature Learning and Understand-ing: Algorithms and Applications, pages 103133, 2020. 3 Jingming Zhao, Juan Zhang, Zhi Li, Jenq-Neng Hwang,Yongbin Gao,Zhijun Fang,Xiaoyan Jiang,and BoHuang. Dd-cyclegan: Unpaired image dehazing via double-discriminator cycle-consistent generative adversarial net-work. Engineering Applications of Artificial Intelligence, 82:263271, 2019. 2, 3",
  "Shiyu Zhao, Lin Zhang, Ying Shen, and Yicong Zhou. Re-finednet: A weakly supervised refinement framework for sin-gle image dehazing. IEEE Transactions on Image Process-ing, 30:33913404, 2021. 6": "Yu Zheng, Jiahui Zhan, Shengfeng He, Junyu Dong, andYong Du. Curricular contrastive regularization for physics-aware single image dehazing.In Proceedings of theIEEE/CVF Conference on Computer Vision and PatternRecognition, pages 57855794, 2023. 3 Bolei Zhou, Aditya Khosla, Agata Lapedriza, Aude Oliva,and Antonio Torralba. Learning deep features for discrimina-tive localization. In Proceedings of the IEEE conference oncomputer vision and pattern recognition, pages 29212929,2016. 5 Jun-Yan Zhu, Taesung Park, Phillip Isola, and Alexei AEfros.Unpaired image-to-image translation using cycle-consistent adversarial networks. In Proceedings of the IEEEinternational conference on computer vision, pages 22232232, 2017. 1, 2, 6"
}