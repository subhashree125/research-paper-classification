{
  "Abstract": "Accurate patient diagnoses based on human tissue biop-sies are hindered by current clinical practice, where pathol-ogists assess only a limited number of thin 2D tissue slicessectioned from 3D volumetric tissue. Recent advances innon-destructive 3D pathology, such as open-top light-sheetmicroscopy, enable comprehensive imaging of spatially het-erogeneous tissue morphologies, offering the feasibility toimprove diagnostic determinations. A potential early routetowards clinical adoption for 3D pathology is to rely onpathologists for final diagnosis based on viewing famil-iar 2D H&E-like image sections from the 3D datasets.However, manual examination of the massive 3D pathol-ogy datasets is infeasible.To address this, we presentCARP3D, a deep learning triage approach that automati-cally identifies the highest-risk 2D slices within 3D volumet-ric biopsy, enabling time-efficient review by pathologists.For a given slice in the biopsy, we estimate its risk by per-forming attention-based aggregation of 2D patches withineach slice, followed by pooling of the neighboring slicesto compute a context-aware 2.5D risk score. For prostatecancer risk stratification, CARP3D achieves an area underthe curve (AUC) of 90.4% for triaging slices, outperform-ing methods relying on independent analysis of 2D sections(AUC=81.3%). These results suggest that integrating ad-ditional depth context enhances the models discriminativecapabilities. In conclusion, CARP3D has the potential toimprove pathologist diagnosis via accurate triage of high-risk slices within large-volume 3D pathology datasets.",
  "*Equal contribution": "tissue specimens for microscopic evaluation. Despite be-ing regarded as the gold standard for medical diagnosticsfor over a century, conventional histology suffers from se-vere undersampling of tissue specimens, where less than1% of a biopsy is examined by a pathologist (4 m thicksections from 1 mm diameter core biopsy). Furthermore,isolated cross-sectional views of complex 3D tissue struc-tures can be ambiguous and misleading .Re-cent advances in high-throughput 3D microscopy, alongwith tissue clearing and fluorescence labeling, now en-able non-destructive imaging of large tissue volumes forimproved disease characterization, including whole biop-sies .For exam-ple, open-top light-sheet (OTLS) microscopy in conjunc-tion with associated tissue-processing and data-processingmethods have shown the ability to generatehigh-quality 3D pathology datasets at various spatial reso-lutions with comparable quality to slide-based H&E histol-ogy .A number of computational methods have been devel-oped to analyze 3D pathology datasets without human in-tervention , but fully computational analyses re-quire additional large-scale validation studies before theyare ready for clinical deployment. To encourage clinicaladoption, it is important to show pathologists 2D cross-sectional images that are false colored to mimic the appear-ance of histology, allowing pathologists to leverage theirtraining and expertise in interpreting 2D hematoxylin andeosin (H&E) images . However, it is infea-sible for pathologists to manually analyze large feature-rich3D pathology datasets containing hundreds or even thou-sands of 2D slices. Therefore, there is a need for compu-tational triage methods that can efficiently sift through thevast numbers of slices in each 3D pathology dataset and toidentify the highest-risk slices for time-efficient pathologistreview (). This approach is a potential low-riskearly pathway towards clinical adoption of 3D pathologythat keeps pathologists involved in the final diagnosis.For developing a 3D pathology computational frame-",
  "arXiv:2406.07061v1 [eess.IV] 11 Jun 2024": ". Workflow with deep-learning-based triage framework for 3D pathology. Prostate biopsies are comprehensively imagedin 3D with open-top light-sheet (OTLS) microscopy. A deep-learning-based triage method evaluates all 2D slices within 3D pathologydatasets and identifies the highest-risk 2D slices for time-efficient pathologist review. work, it is important to leverage technical advances in2D computational pathology based on 2D whole-slide im-ages (WSIs), which has witnessed tremendous progress forvarious clinical outcome prediction tasks such as cancergrading and prognosis, and treatment response predictions. Due to the gigapixel nature of WSIs, these ap-proaches have centered around a multiple instance learning(MIL) paradigm. In typical MIL setups, WSIs are parti-tioned into a set of smaller patches (i.e., instances), eachof which is encoded into a low-dimensional feature vec-tor using models pretrained on natural images ormore recently, pretrained on in-domain histopathology im-ages . These patch-level features are then aggre-gated with aggregation networks into slide-level represen-tations . A direct application of MIL frame-works to each 2D slice within a 3D pathology dataset wouldallow for risk assessment of each slice. However, the anal-ysis of each 2D slice as an independent image does not takeadvantage of the added context that exists along the 3rd di-mension (depth dimension) of a 3D pathology dataset .For example, a recent work has shown that 3D analy-ses are superior to 2D (in plane) analyses for a patient risk-stratification task based on 3D pathology. However, that ap-proach was designed to make predictions from 3D volumesbased on 3D features, making it ill-suited for pinpointingthe most important 2D slices at high granularity, which isessential to guide manual review by a human pathologist. In this work, we propose Context-Aware Risk Predictionfor 3D pathology (CARP3D), a 2.5D MIL framework forrisk prediction. CARP3D provides a natural mechanismfor incorporating contextual information from neighboringslices, which not only leads to enhanced slice-level pre-dictions but also yields a high-resolution (equal to axialsampling pitch) risk profile along the depth axis for triag-ing applications.Specifically, slices are patched, featur-ized, and subsequently aggregated into slice-level featurerepresentations by an intra-slice attention-based networkin 2D. An inter-slice pooling module subsequently assignsweights to neighboring images based on their diagnostic im-portance and integrates neighboring features with respective weighting factors to assist predictions on the slice of inter-est. The attention network allows for the capture of fine-grained details within each slice and the inter-slice pool-ing module emphasizes contextually relevant informationwhile suppressing irrelevant signals for more accurate as-sessment of a slice of interest. One advantage of our 2.5Dapproach, as opposed to a full 3D approach, is that it is ableto evaluate 3D pathology data at high resolution along thedepth axis, and also takes advantage of the emerging fam-ily of 2D feature extraction models for 2D pathology im-ages , which are lacking in 3D feature ex-traction.We apply our method to a cohort of prostate cancer biop-sies imaged with OTLS, on the task of discriminating be-tween low-grade (Grade group 1) vs. intermediate- to high-grade prostate cancer (Grade group 2), an important clin-ical task for ensuring that higher-risk patients receive po-tentially life-saving treatments while low-risk patients arespared serious treatment-related side effects . In termsof predicting risks of given slices, our 2.5D methods out-perform the 2D counterparts by a large margin, demonstrat-ing the significance of incorporating 3D contextual infor-mation. The codes for this study are publicly available at",
  ". MIL for 2D WSI classification": "Since directly analyzing gigapixel WSIs often exceeds thecapacities of modern GPUs, most classification tasks followa MIL framework, also termed weakly-supervised learn-ing.In MIL, the WSI is divided into a set of smallerpatches (typically 256 256 pixels) from which the low-dimensional features are extracted and aggregated to yielda slide-level feature .Only a single supervisory la-bel is typically provided for the entire WSI. For patchfeature encoding, studies have explored encoding patchesby transfer learning with a ResNet50 model pretrained onImageNet , as well as augmentations of patch fea-tures in low-data regimes . Recently, CTransPath (a hybrid CNN and Vision Transformer) was trained in aself-supervised learning regime on millions of histopathol-ogy images for more generalizable patch features .For patch feature aggregation, different approaches havebeen explored . Among these methods, attention-based networks are gaining popularity, surpassing rule-based models like max, top-k, or average pooling as a re-sult of superior domain adaptability and data efficiency . Recent aggregation approaches explore ei-ther GNN-based aggregation or Transformer self-attention-based aggregations to more explicitlymodel relationships between patch features.",
  ". Computational 3D pathology to support diag-nostic determinations": "In the realm of 3D pathology, where datasets are mas-sive in size, several AI-assisted pipelines have been ex-plored. Some recent studies have focused on 3D segmenta-tion of diagnostically important tissue morphologies, suchas prostate glands and nuclei, to facilitate the extraction ofhand-crafted features for patient risk stratification .While intuitive and enabling hypothesis testing/generation,the analysis of a small set of intuitive 3D morphological fea-tures cannot fully leverage the complex spatial biomarkerscontained within 3D pathology datasets, many of which areopaque to human observers. Recent advances in 3D weaklysupervised learning allow for deep features to be auto-matically extracted from tissue volumes for patient progno-sis . Such fully-automated end-to-end deep-learning ap-proaches lack explainability and may initially be challeng-ing for clinicians to adopt.Human-in-the-loop strategies that guide pathologists toreview important regions could be a low-risk and attrac-tive strategy for more immediate clinical adoption. Towardsthis end, a fully supervised 2D deep-learning approach waspreviously developed to identify high-risk image sectionswithin 3D esophageal data for pathologist review , whichwas based on a limited number of pixel-level annotationspainstakingly provided by a single pathologist.In con-trast, CARP3D is a weakly-supervised learning pipelinetrained on diverse image-level annotations that are easilyand quickly generated by a panel of pathologists. Further-more, it incorporates contextual information in 3D pathol-ogy data to achieve better triage performance.",
  ". 2.5D analysis for 3D data": "2.5D analysis considers 3D volumes as a stack of 2D im-ages and leverages neighboring images to refine predictions,incorporating contextual information with lower computa-tional demands than full 3D models. For example, in med-ical imaging, several models merge nearby gray-scale im-ages into a single multi-channel image to generate segmen-tation masks or to detect bounding boxes . Ad- ditionally, some approaches adopt auxiliary information ex-tracted from nearby images to improve the 2D model out-puts, like adjacent prediction results or residuals be-tween neighboring images . Recent works focus on ex-plicitly characterizing context information in 3D datasetswith two-stage models, by first conducting 2D analysis foreach image and then aggregating features from neighboringimages to refine predictions. For such methods, commonaggregation approaches include pooling strategies, ensem-ble methods, or neural networks like RNN .However, the majority of these methods were developedfor images considerably smaller than 3D pathology images,thus necessitating a 2.5D method tailored for 3D pathologydata, such as CARP3D.",
  ". Methods": "We represent each 3D pathology image as a stack of 2Dimages {Xi}Ni=1, where Xi RW HC with W, H,and C denoting width, height, and number of channelsrespectively, and N referring to the number of 2D sec-tions in 3D data. For a slice of interest (SOI) Xk wherek {1, . . . , N}, we aim to predict the slice-level label yk(). For the set of smaller patches from tessellat-ing the SOI and its neighboring slices, we apply a sequenceof set aggregation approaches to ultimately construct a sin-gle SOI feature for risk prediction. The aim is to harnessthe extra contextual information provided by the depth di-mension: 1) Intra-slice attention-based aggregation to con-struct a slice-level feature and 2) Inter-slice aggregation toincorporate neighboring slice-level features to construct acontext-aware SOI feature.We first introduce the patch feature extraction (Sec-tion 3.1) and intra-slice attention-based MIL (ABMIL)(.2).We then describe strategies for inter-slicecontext aggregation from neighboring slice-level features(.3), followed by the classification module (Sec-tion 3.4) and training/inference steps (.5).",
  ". Patch feature encoding": "We denote the set of patches forming an image Xi as{xji}Jj=1 where xji RwhC, w and h are lateral dimen-sions of the patches and J indicates total number of patchesin Xi. A pretrained feature encoder fenc then extracts a low-dimensional and representative feature hji Rd from eachpatch xji, such that hji = fenc(xji).To address the domain differences stemming from uti-lizing pretrained encoders to encode patches of a differ-ent data domain (i.e., pretraining dataset: histology, eval-uation dataset: OTLS) , we apply a fully-connectedlayer with ReLU nonlinearity to {hji}Jj=1 to generate morecompressed and domain-specific features {hji}Jj=1, withhji R512. Specifically, hji = ReLU(WT hji + b), where . CARP3D architecture. a) Patches for a 2D slice of interest (SOI) and its neighboring slices are encoded with pretrainedResNet50 and CTransPath. An intra-slice attention module aggregates patch-level features within each slice into slice-level features.Neighboring slice-level features are aggregated through an inter-slice pooling module to produce a context-aware SOI feature for subse-quent risk prediction, formulated as a classification task into high- vs. low-risk categories here. b) During training, slices are selected withineach 3D sample of the training set, from which the CARP3D model learns to predict the ground truth labels provided by pathologists. c)Model deployment on 3D pathology data for slice-by-slice risk assessment. The highest-risk slices are selected for pathologist review.",
  ". Intra-slice attention module": "The fine-tuned patch features {hji}Jj=1 are aggregated by anattention network into a slice-level feature zi R512,where the attention score aji computed for each featurehji reflects its importance to the final prediction. The at-tention network is comprised of three sets of parametersV R512256, U R512256, and W R2561 andthe attention calculation,",
  ". Inter-slice pooling for 2.5D integration": "To leverage contextual information from neighboring im-ages and improve the prediction of the SOI Xk, we incor-porate m additional slices above and below Xk with thespacing of d slices in between, i.e., {Xk+id}mi=m. All ofthese slices are converted to slice-level features followingthe steps in .1 and 3.2.We subsequently apply weighted averaging on the SOIand neighboring slice-level features, where the weights arelearnable, to generate a context-aware SOI feature zk for",
  "ri =exp{LT zk+id}mi=m exp{LT zk+id}.(3)": "Similar to attention-based weights in intra-slice aggre-gation, the weights {ri}mi=m emphasize diagnostically-relevant slices. Nevertheless, since this module deals withonly a few slice-level features that are already more dis-cernible than patch-level features, we use L, which has farfewer parameters than Eq. 1. The feature zk is then calcu-lated as the weighted average of the slice features,",
  ". Training and inference": "For the training phase, we select one or two representativeslices from each biopsy volume (typically the center slice)as the input and its corresponding pathologists-provided la-bel as the target ((b)). Since ground truth genera-tion for all slices in each biopsy is infeasible, we extractedrepresentative slices from each 3D dataset to form the train-ing set, promoting the inclusion of images from more di-verse patients and biopsies. During the inference phase, thetrained model can be deployed across all image sections togenerate a predicted risk profile for the volume at the axialsampling pitch (1m) of each slice ((c)). In a clin-ical context, the image sections with the highest risks wouldbe selected for further evaluation by pathologists.",
  ". Data description": "We implemented CARP3D for prognostic risk stratificationof prostate cancer based on Gleason gradings provided by apanel of 6 board-certified genitourinary pathologists. Sim-ulated core-needle biopsies (roughly 1 1 15mm) werecut from cancer-enriched regions of archived prostatectomyspecimens that were previously formalin-fixed and paraffin-embedded (FFPE). The biopsies were stained with a fluores-cent analog of hematoxylin and eosin, optically cleared to make them transparent, and imaged with OTLS microscopyin 3D to generate 16-bit gray-scale datasets of two fluores-cent channels (nuclear stain and cytoplasmic stain) .The sampling pitch of the images is 1 m/pixel at 10X-equivalent optical resolution laterally (the typical magnifi-cation used for Gleason grading) and 4 m optical resolu-tion axially (similar to the thickness of standard slide-basedhistology).A total of 124 slices were selected from 115 OTLS-imaged prostate biopsies across 54 patients. These imageswere false-colored to mimic the appearance of H&E histol-ogy using a physics-based approach . For prostate can-cer, pathologists quantify the aggressiveness of the cancerusing the Gleason grading scheme. Grade group 1 (GG=1)is categorized as low-grade prostate cancer, where patientstypically opt for active surveillance (i.e. monitoring with-out aggressive treatment). Grade Group 2 (GG 2) cancerand above is considered intermediate or high-grade and pa-tients typically receive curative therapy. To enable accuratecharacterization of higher-grade prostate cancer to providepotentially life-saving treatments, we trained our algorithmto classify slices within 3D prostate datasets as containinglow-grade (GG = 1) vs. higher-grade (GG 2) prostatecancer (i.e., a binary classification task).",
  ". Implementations": "2D slices were split into non-overlapping 256 256patches (256 256 m).We used the original two-channel 16-bit gray-scale fluorescence images for train-ing CARP3D. Since the cytoplasm channel exhibits rel-atively uniform signal distributions, we normalized the 16-bit cytoplasm-channel images after cropping out the back-ground (calculated by Otsu thresholding) and outlier sig-nals (99th percentile). For the nuclear channel, which canvary greatly across an image (depending upon the cellular-ity of various tissue regions), we performed intensity crop-ping and normalization on individual patches. Finally, wedistributed the normalized nuclear and cytoplasmic chan-nels across the first two channels of the three-channel RGBinputs and left the third channel (B channel) empty.Dual NVIDIA GeForce RTX 3090 GPUs were used fortraining and inference. We used the Adam optimizer withthe constant learning rate of 2104 and a batch size of 256to iteratively minimize the cross-entropy loss for all experi-ments. For 2.5D analysis, neighboring slices within a rangeof 80 m above and below each image section were se-lected this allows the incorporation of additional informa-tion while remaining within the estimated distance of intra-biopsy grading variability . We tested m {1, 2, 4, 8},maintaining md = 80, and chose best-performing m foreach baseline.For evaluation, we used the Area Under the ROC Curve(AUC). We also reported the F2 score, which prioritizes",
  ". Baseline architectures for inter-slice pooling. a) Naivepooling. b) Average pooling. c) RNN-based pooling": "recall vs. precision in comparison to the F1 score whichweights them equally. This choice reflects our studys goalof screening more aggressive prostate cancer patients. Thebest F2 score is reported by iterating over different thresh-olds for mapping predicted probabilities to class labels. Weemployed a leave-one-out cross-validation strategy, wherein each fold, slices from one patient are held out to evaluatemodel performance, and the remaining images are used fortraining. Predictions were combined across the patients tocalculate the cohort-level performance metrics.",
  ". Baselines": "Our baselines consist of variations to two modules: 1) Patchfeature encoding and 2) Inter-slice pooling ((a)).All baselines use ABMIL for intra-slice feature aggrega-tion, a lightweight model specifically selected for the datascale.PatchfeatureencodingWefirstinvestigatedthemost widely-used patch feature encoders, including aResNet50 pretrained on ImageNet (d = 1, 024) and a self-supervised CTransPath (a hybrid CNN / Transformer)pretrained on histopathology images (d = 768) . ForResNet50 features, we applied patch augmentations basedon random flipping and brightness/contrast jittering toincrease the feature diversity (ResNet50aug). CTransPathfeatures are not augmented as the self-supervised train-ing of the model makes it invariant to augmentations.Motivated by the success of using multiple featuresfor classification , we also tested concatenating theResNet50 and ResNet50aug features with CTransPathfeatures (d = 1, 792) for more expressive representations.Inter-slice pooling We explored various approaches forinter-slice context aggregation ().1) No pooling Only patch features from Xk are aggregated,and therefore no contextual information is used.2) Naive pooling All patch features from {Xk+id}mi=mare aggregated by a single attention module to construct zk,disregarding slice identity.3) Average pooling Patch features are first aggregated toslice-level features within each image.The neighboringslice-level features are averaged with SOI feature to formzk, where zk =1 (2m+1)mi=m zk+id.4) RNN-based pooling Since average pooling is insensitiveto the order of images, we tested RNN-based pooling to in-corporate sequential information. Recurrent units aggregateimage sequences {Xk+id}mi=m in a bi-directional manner,integrating slice-level features into the hidden state hid ascontextual information,",
  ". Patch feature encoders": "The results for feature encoder ablation can be foundin .We observe that the concatenation of aug-mented ResNet50 and CTransPath features outperformedall other strategies using 2D attention-based MIL. We ob-serve that ResNet50 features and augmented ResNet50 fea-tures achieved a similar AUC, but augmentation helpedslightly with identifying the positive class (better F2 score).CTransPath features improved AUC by a significant mar-gin. However, the F2 score is inferior to experiments usingoriginal and augmented ResNet50 features, which indicatethe improved AUC mainly comes from correctly predictingGG=1 images, while many GG2 images are still confusedwith the low-grade class (i.e. poor recall or diagnostic sen-sitivity). Concatenation of ResNet50 and CTransPath fea-",
  ". Results for different encoders. Best performances are inbold. The 95% confidence interval (95% CI) is calculated basedon bootstrapping. Concatenation is denoted by": "tures results in a better F2 score than CTransPath, but at theexpense of slightly lower AUC. Applying patch augmenta-tion on ResNet50 encoders and concatenating the featureswith CTransPath features achieved the best AUC and F2score compared with all other experiments. Therefore, weused these features for subsequent analyses. We leave utiliz-ing the patch features from very recent foundation modelsas future work .",
  ". Performance comparison between 2.5D vs 2D": "The comparisons between 2D and 2.5D approaches can befound in . We observe that 2.5D methods using con-textual information improved the classification of low-gradevs. higher-grade cancer over 2D analysis. We consideredattention-based MIL on independent 2D images with nointer-slice aggregation as the baseline and explored differentinter-slice context aggregation strategies. The naive poolingbaseline, where a single attention-based network aggregates patches from the SOI and neighboring slices, results in no-table improvement in AUC, suggesting that additional spa-tial context provided by the 3rd dimension enhances the dis-criminative capabilities of the model. However, there wasa drop in F2 (poorer recall or diagnostic sensitivity), poten-tially due to the increased number of patches to attend to,making it more challenging to correctly recognize positivepatches containing small foci of aggressive cancer.To better utilize the depth information within eachbiopsy, we further analyzed strategies for a sequence ofaggregations, first within each slice (ABMIL) followedby across slices. For inter-slice aggregation, we observethat simple averaging of slice features (average pooling)achieves further improvements in both AUC and F2. In-terestingly, the RNN-based pooling, designed to better in-corporate sequential information from neighboring images,performs on par with the average pooling.We conjec-ture that the introduction of more trainable parameters withRNN likely leads to overfitting. Finally, since one limi-tation of average pooling is that positive images may stillbe diluted by neighboring images, especially when aggres-sive cancer constitutes only a small proportion, we designedweighted averaging to emphasize slice features that aremore diagnostically important. We observe that weightedaveraging achieved a significant improvement in AUC andespecially in F2. We conclude that a sequence of aggrega-tion based on weighted averaging employed by CARP3Dcan best utilize the 3D dataset for clinical prediction.",
  ". Interpretability": "To gain a better understanding of the CARP3D predic-tions, we applied principal component analysis (PCA) tothe context-aware SOI features in (a). GG 2slices are visually separable from GG = 1 slices in the PCspace, suggesting that our model can discriminate betweentwo classes. By visualizing heatmaps of attention scoresoverlaid on top of false-colored H&E-like images, we canidentify regions important for rendering predictions. Forexample, regions in (b) are predicted as highlylikely to contain higher-grade prostate cancer. The high-attention regions are roughly aligned with fused glands,which are commonly associated with higher-grade prostatecancer. Regions in (c) are predicted as low-gradeprostate cancer, where the highly attended regions corre-spond to well-formed benign glands and lymphocytes.",
  ". Triage on a 3D pathology dataset": "We demonstrate the slice-by-slice inference of the trainedCARP3D on an example 3D dataset ((a)). Specifi-cally, we generate a depth profile of predicted context-awarerisk scores, with the risk defined as the predicted probabilityof a given slice containing higher-grade prostate cancer. Tovalidate our findings, a board-certified pathologist reviewed . Visualization of SOI features and interpretable attention heatmaps. a) PCA of context-aware SOI features. b) and c) showexamples of attention heatmaps with corresponding false-colored images. The scale bar is 100 m. Color bar indicates attention scores. . CARP3D triage on an example 3D pathology dataset. a) An example 3D pathology dataset. b) Per-slice risk profile, predictedby CARP3D, for higher-grade prostate cancer. c) Images at arrow positions are reviewed by a board-certified pathologist, showing thathuman evaluation on select slices broadly aligns with the risk profile. The scale bar is 100 m. images at the depths indicated by arrows ((b)). Atthe blue arrow, only well-formed benign glands are seen(Grade Group 1), albeit with only a small number of glandsvisible at this depth. Fused glands (associated with higher-grade prostate cancer) are present in the slice at the brownarrow, but benign glands are more prevalent (Grade Group2). The fused glands become the predominant morphologyat the red arrow, suggesting more aggressive cancer (GradeGroup 3). In summary, the pathologist evaluation of selectslices broadly aligns with the risk profile generated by ourmodel. In real-world clinical practice, the highest risk sliceat the red arrow as in (c) would be prioritized forpathologist review. A large-scale clinical study will be per-formed in the future to demonstrate the ability of AI-triaged3D pathology (enabled by CARP3D) to improve the detec-",
  ". Conclusion": "We present CARP3D, a 2.5D multiple instance learningframework to triage the highest-risk slices within 3D pathol-ogy datasets to facilitate pathologist review.Our workleverages contextual information in 3D pathology data toenhance the predicting accuracy of each slice. CARP3Dcould potentially accelerate the clinical adoption of 3Dpathology by improving pathologists diagnostic accuracyvia increased tissue sampling and context-aware triage. Fu-ture work includes curation of more 3D pathology dataacross organs for large-scale clinical validation in compari-son to standard 2D histopathology.",
  "Arman Avesta, Sajid Hossain, MingDe Lin, Mariam Aboian,Harlan M Krumholz, and Sanjay Aneja.Comparing 3D,2.5 D, and 2D approaches to brain image auto-segmentation.Bioengineering, 10(2):181, 2023. 3": "Lindsey A Barner,Adam K Glaser,Hongyi Huang,Lawrence D True, and Jonathan TC Liu. Multi-resolutionopen-top light-sheet microscopy to enable efficient 3Dpathology workflows. Biomedical Optics Express, 11(11):66056619, 2020. 1 Lindsey A Erion Barner, Gan Gao, Deepti M Reddi, LydiaLan, Wynn Burke, Faisal Mahmood, William M Grady, andJonathan TC Liu. AI-triaged 3D pathology to improve de-tection of esophageal neoplasia while reducing pathologistworkloads. Modern Pathology, 36(12):100322, 2023. 3 Kevin W Bishop, Lindsey A Erion Barner, Qinghua Han,Elena Baraznenok, Lydia Lan, Chetan Poudel, Gan Gao,Robert B Serafin, Sarah SL Chow, Adam K Glaser, et al.An end-to-end workflow for nondestructive 3D pathology.Nature Protocols, pages 127, 2024. 1, 5 David Brenes, Mila P. Salcedo, Jackson B. Coole, YajurMaker, Alex Kortum, Richard A. Schwarz, Jennifer Carns,Imran S. Vohra, Julio C. Possati-Resende, Marcio Antoni-azzi, Bruno de Oliveira Fonseca, Karen C. Borba Souza,Iara V. Vidigal Santana, Flavia Fazzio Barbin, Regis Kreitch-mann, Nirmala Ramanujam, Kathleen M. Schmeler, and Re-becca Richards-Kortum. Multiscale optical imaging fusionfor cervical precancer diagnosis: Integrating widefield col-poscopy and high-resolution endomicroscopy. IEEE Trans-actions on Biomedical Engineering, pages 110, 2024. 3 Wouter Bulten, Kimmo Kartasalo, Po-Hsuan Cameron Chen,Peter Strom, Hans Pinckaers, Kunal Nagpal, Yuannan Cai,David F Steiner, Hester Van Boven, Robert Vink, et al. Artifi-cial intelligence for diagnosis and gleason grading of prostatecancer: the panda challenge. Nature medicine, 28(1):154163, 2022. 2 Iain Carmichael, Andrew H Song, Richard J Chen, Drew FKWilliamson, Tiffany Y Chen, and Faisal Mahmood. Incor-porating intratumoral heterogeneity into weakly-superviseddeep learning models via variance pooling. In InternationalConference on Medical Image Computing and Computer-Assisted Intervention, pages 387397. Springer, 2022. 3 Peter R Carroll, J Kellogg Parsons, Gerald Andriole,Robert R Bahnson, Erik P Castle, William J Catalona, Dou-glas M Dahl, John W Davis, Jonathan I Epstein, Ruth B Et-zioni, et al. Prostate cancer early detection, version 2.2016:Featured updates to the nccn guidelines.JNCCN Journalof the National Comprehensive Cancer Network, 14(5):509519, 2016. 2",
  "RichardJChen,MingYLu,MuhammadShaban,Chengkuan Chen, Tiffany Y Chen, Drew FK Williamson,and Faisal Mahmood.Whole slide images are 2d pointclouds: Context-aware survival prediction using patch-based": "graph convolutional networks. In Medical Image Computingand Computer Assisted InterventionMICCAI 2021: 24th In-ternational Conference, Strasbourg, France, September 27October 1, 2021, Proceedings, Part VIII 24, pages 339349.Springer, 2021. 3 Richard J Chen, Chengkuan Chen, Yicong Li, Tiffany YChen, Andrew D Trister, Rahul G Krishnan, and FaisalMahmood. Scaling vision transformers to gigapixel imagesvia hierarchical self-supervised learning. In Proceedings ofthe IEEE/CVF Conference on Computer Vision and PatternRecognition, pages 1614416155, 2022. 3 Richard J Chen, Tong Ding, Ming Y Lu, Drew FKWilliamson, Guillaume Jaume, Andrew H Song, BowenChen, Andrew Zhang, Daniel Shao, Muhammad Shaban,et al. Towards a general-purpose foundation model for com-putational pathology. Nature Medicine, pages 113, 2024. 2,7 Nicolas Coudray, Paolo Santiago Ocampo, Theodore Sakel-laropoulos, Navneet Narula, Matija Snuderl, David Fenyo,Andre L Moreira, Narges Razavian, and Aristotelis Tsirigos.Classification and mutation prediction from nonsmall celllung cancer histopathology images using deep learning. Na-ture medicine, 24(10):15591567, 2018. 3 Pierre Courtiol, Charles Maussion, Matahi Moarii, ElodiePronier, Samuel Pilcer, Meriem Sefta, Pierre Manceron,Sylvain Toldo, Mikhail Zaslavskiy, Nolwenn Le Stang,et al.Deep learning-based classification of mesotheliomaimproves prediction of patient outcome. Nature medicine,25(10):15191525, 2019. 3 Jia Deng, Wei Dong, Richard Socher, Li-Jia Li, Kai Li,and Li Fei-Fei. Imagenet: A large-scale hierarchical imagedatabase. In 2009 IEEE conference on computer vision andpattern recognition, pages 248255. Ieee, 2009. 2 Saman Farahmand, Aileen I Fernandez, Fahad ShabbirAhmed, David L Rimm, Jeffrey H Chuang, Emily Reisen-bichler, and Kourosh Zarringhalam. Deep learning trainedon hematoxylin and eosin tumor region of interest predictsHER2 status and trastuzumab treatment response in her2+breast cancer. Modern Pathology, 35(1):4451, 2022. 2 Andre Forjaz, Eduarda Vaz, Valentina Matos Romero,Saurabh Joshi, Alicia M. Braxton, Ann C. Jiang, Kohei Fu-jikura, Toby Cornish, Seung-Mo Hong, Ralph H. Hruban,Pei-Hsun Wu, Laura D. Wood, Ashley L. Kiemen, and De-nis Wirtz. Three-dimensional assessments are necessary todetermine the true spatial tissue composition of diseased tis-sues. bioRxiv, 2023. 1 Jasper Frohn, Diana Pinkert-Leetsch, Jeannine Missbach-Guntner, Marius Reichardt, Markus Osterhoff, Frauke Alves,and Tim Salditt. 3D virtual histology of human pancreatictissue by multiscale phase-contrast X-ray tomography. Jour-nal of Synchrotron Radiation, 27(6):17071719, 2020. 1 Gan Gao, Dominie Miyasato, Lindsey A Barner, Robert Ser-afin, Kevin W Bishop, Weisi Xie, Adam K Glaser, Eben LRosenthal, Lawrence D True, and Jonathan TC Liu. Com-prehensive surface histology of fresh resection margins withrapid Open-Top Light-Sheet (OTLS) microscopy.IEEETransactions on Biomedical Engineering, 2023. 1 Adam K Glaser, Nicholas P Reder, Ye Chen, Chengbo Yin,Linpeng Wei, Soyoung Kang, Lindsey A Barner, Weisi Xie,Erin F McCarty, Chenyi Mao, et al. Multi-immersion open-top light-sheet microscope for high-throughput imaging ofcleared tissues. Nature communications, 10(1):2781, 2019.1, 5 Adam K Glaser, Kevin W Bishop, Lindsey A Barner, Et-suo A Susaki, Shimpei I Kubota, Gan Gao, Robert B Serafin,Pooja Balaram, Emily Turschak, Philip R Nicovich, et al. Ahybrid open-top light-sheet microscope for versatile multi-scale imaging of cleared tissues.Nature methods, 19(5):613619, 2022. 1 Yesenia Gonzalez, Chenyang Shen, Hyunuk Jung, DanNguyen, Steve B Jiang, Kevin Albuquerque, and Xun Jia.Semi-automatic sigmoid colon segmentation in ct for radia-tion therapy treatment planning via an iterative 2.5-d deeplearning approach.Medical image analysis, 68:101896,2021. 3 Kaiming He, Xiangyu Zhang, Shaoqing Ren, and Jian Sun.Deep residual learning for image recognition. In Proceed-ings of the IEEE conference on computer vision and patternrecognition, pages 770778, 2016. 2, 6 Seung-MoHong,DongJunJung,AshleyKiemen,Matthias M. Gaida, Tadashi Yoshizawa, Alicia M. Brax-ton, Michael Noe, Gemma Lionheart, Kiyoko Oshima,Elizabeth D. Thompson, Richard Burkhart, Pei-Hsun Wu,Denis Wirtz, Ralph H. Hruban, and Laura D. Wood. Three-dimensional visualization of cleared human pancreas cancerreveals that sustained epithelial-to-mesenchymal transitionis not required for venous invasion. Modern Pathology, 33(4):639647, 2020. 1 Zhi Huang, Federico Bianchi, Mert Yuksekgonul, Thomas JMontine, and James Zou.A visuallanguage foundationmodel for pathology image analysis using medical twitter.Nature medicine, 29(9):23072316, 2023. 2",
  "Maximilian Ilse,Jakub Tomczak,and Max Welling.Attention-based deep multiple instance learning. In Inter-national conference on machine learning, pages 21272136.PMLR, 2018. 2, 4": "Alexander Ke, Shih-Cheng Huang, Chloe P OConnell,Michal Klimont, Serena Yeung, and Pranav Rajpurkar. Videopretraining advances 3d deep learning on chest ct tasks.In Medical Imaging with Deep Learning, pages 758774.PMLR, 2024. 3 Titinunt Kitrungrotsakul, Xian-Hau Han, Yutaro Iwamoto,Satoko Takemoto, Hideo Yokota, Sari Ipponjima, TomomiNemoto, Wei Xiong, and Yen-Wei Chen. A cascade of 2.5 dcnn and bidirectional clstm network for mitotic cell detectionin 4d microscopy image. IEEE/ACM transactions on compu-tational biology and bioinformatics, 18(2):396404, 2019. 3 Can Koyuncu, Andrew Janowczyk, Xavier Farre, TilakPathak, Tuomas Mirtti, Pedro L Fernandez, Laura Pons,Nicholas P Reder,Robert Serafin,Sarah SL Chow,et al. Visual assessment of 2-dimensional levels within 3-dimensional pathology data sets of prostate needle biopsiesreveals substantial spatial heterogeneity. Laboratory Investi-gation, 103(12):100265, 2023. 1, 5 Narmin Ghaffari Laleh,Hannah Sophie Muti,ChiaraMaria Lavinia Loeffler, Amelie Echle, Oliver Lester Sal-danha, Faisal Mahmood, Ming Y Lu, Christian Trautwein,Rupert Langer, Bastian Dislich, et al. Benchmarking weakly-supervised deep learning pipelines for whole slide classifica-tion in computational pathology. Medical image analysis,79:102474, 2022. 3 Yongju Lee, Jeong Hwan Park, Sohee Oh, Kyoungseob Shin,Jiyu Sun, Minsun Jung, Cheol Lee, Hyojin Kim, Jin-HaengChung, Kyung Chul Moon, et al. Derivation of prognosticcontextual histopathological features from whole-slide im-ages of tumours via graph deep learning. Nature BiomedicalEngineering, pages 115, 2022. 3 Jana Lipkova, Tiffany Y Chen, Ming Y Lu, Richard J Chen,Maha Shady, Mane Williams, Jingwen Wang, Zahra Noor,Richard N Mitchell, Mehmet Turan, et al. Deep learning-enabled assessment of cardiac allograft rejection from en-domyocardial biopsies.Nature medicine, 28(3):575582,2022. 3 JonathanTCLiu,AdamKGlaser,KaustavBera,Lawrence D True, Nicholas P Reder, Kevin W Eliceiri, andAnant Madabhushi. Harnessing non-destructive 3D pathol-ogy. Nature biomedical engineering, 5(3):203218, 2021. 1,2 Jonathan TC Liu,Sarah SL Chow,Richard Colling,Michelle R Downes, Xavier Farre, Peter Humphrey, An-drew Janowczyk, Tuomas Mirtti, Clare Verrill, Inti Zlobec,et al. Engineering the future of 3D pathology. The Journalof Pathology: Clinical Research, 10(1):e347, 2024. 1 Ming Y Lu, Drew FK Williamson, Tiffany Y Chen, Richard JChen, Matteo Barbieri, and Faisal Mahmood. Data-efficientand weakly supervised computational pathology on whole-slide images. Nature biomedical engineering, 5(6):555570,2021. 2, 3 Ming Y Lu, Bowen Chen, Drew FK Williamson, Richard JChen, Ivy Liang, Tong Ding, Guillaume Jaume, IgorOdintsov, Long Phi Le, Georg Gerber, et al.A visual-language foundation model for computational pathology.Nature Medicine, pages 112, 2024. 2, 7 Long D Nguyen, Dongyun Lin, Zhiping Lin, and JiuwenCao. Deep cnns for microscopic image classification by ex-ploiting transfer learning and feature concatenation. In 2018IEEE international symposium on circuits and systems (IS-CAS), pages 15. IEEE, 2018. 6",
  "Eben Olson, Michael J Levene, and Richard Torres. Multi-photon microscopy with clearing for three dimensional his-tology of kidney biopsies. Biomedical optics express, 7(8):30893096, 2016. 1": "Stephen M Olson, Mohammad Hussaini, and James SLewis Jr. Frozen section analysis of margins for head andneck tumor resections: reduction of sampling errors with athird histologic level.Modern Pathology, 24(5):665670,2011. 1 Sanson TS Poon, Fahmy WF Hanna, Francois Lemarchand,Cherian George, Alexander Clark, Simon Lea, Charlie Cole-man, and Giuseppe Sollazzo. Detecting adrenal lesions on 3dct scans using a 2.5 d deep learning model. medRxiv, pages202302, 2023. 3 Deepti M Reddi, Lindsey A Barner, Wynn Burke, Gan Gao,William M Grady, and Jonathan TC Liu. Nondestructive 3Dpathology image atlas of Barrett esophagus with open-toplight-sheet microscopy. Archives of Pathology & LaboratoryMedicine, 147(10):11641171, 2023. 1 Nicholas P Reder, Adam K Glaser, Erin F McCarty, Ye Chen,Lawrence D True, and Jonathan TC Liu. Open-top light-sheet microscopy image atlas of prostate core needle biop-sies. Archives of pathology & laboratory medicine, 143(9):10691075, 2019. 1 Robert Serafin, Weisi Xie, Adam K Glaser, and Jonathan TCLiu.Falsecolor-python:a rapid intensity-leveling anddigital-staining package for fluorescence-based slide-freedigital pathology. Plos one, 15(10):e0233198, 2020. 5 Robert Serafin, Can Koyuncu, Weisi Xie, Hongyi Huang,Adam K Glaser, Nicholas P Reder, Andrew Janowczyk,Lawrence D True, Anant Madabhushi, and Jonathan TC Liu.Nondestructive 3D pathology with analysis of nuclear fea-tures for prostate cancer risk assessment.The Journal ofPathology, 260(4):390401, 2023. 1, 3 Zhuchen Shao, Hao Bian, Yang Chen, Yifeng Wang, JianZhang, Xiangyang Ji, et al. Transmil: Transformer basedcorrelated multiple instance learning for whole slide imageclassification.Advances in neural information processingsystems, 34:21362147, 2021. 2, 3 Ole-Johan Skrede, Sepp De Raedt, Andreas Kleppe, Tarjei SHveem, Knut Liestl, John Maddison, Hanne A Askautrud,Manohar Pradhan, John Arne Nesheim, Fritz Albregtsen,et al. Deep learning for prediction of colorectal cancer out-come: a discovery and validation study. The Lancet, 395(10221):350360, 2020. 2 Andrew H Song, Guillaume Jaume, Drew FK Williamson,Ming Y Lu, Anurag Vaidya, Tiffany R Miller, and FaisalMahmood. Artificial intelligence for digital and computa-tional pathology.Nature Reviews Bioengineering, 1(12):930949, 2023. 2 Andrew H Song, Mane Williams, Drew FK Williamson,Sarah SL Chow, Guillaume Jaume, Gan Gao, AndrewZhang, Bowen Chen, Alexander S Baras, Robert Serafin,Richard Colling, Michelle R Downes, Xavier Farre, PeterHumphrey, Clare Verrill, Lawrence D True, Anil V Par-wani, Jonathan TC Liu, and Faisal Mahmood. Analyis of 3Dpathology samples using weakly supervised AI. Cell, 2024.1, 2, 3 Nobuyuki Tanaka, Shigeaki Kanatani, Raju Tomer, CeciliaSahlgren, Pauliina Kronqvist, Dagmara Kaczynska, LauriLouhivuori, Lorand Kis, Claes Lindh, Przemysaw Mitura,et al. Whole-tissue biopsy phenotyping of three-dimensionaltumours reveals patterns of cancer heterogeneity.NatureBiomedical Engineering, 1(10):796806, 2017. 1 Rong Tang, Julliette M Buckley, Leopoldo Fernandez,Suzanne Coopey, Owen Aftreth, James Michaelson, MansiSaksena, Lan Lei, Michelle Specht, Michele Gadd, et al.Micro-computed tomography (Micro-CT): a novel approachfor intraoperative breast cancer specimen imaging. Breastcancer research and treatment, 139:311316, 2013.",
  "Linghua Wang, Mingyao Li, and Tae Hyun Hwang.The3d revolution in cancer discovery. Cancer Discovery, 14(4):625629, 2024. 1": "Xiyue Wang, Sen Yang, Jun Zhang, Minghui Wang,Jing Zhang, Wei Yang, Junzhou Huang, and Xiao Han.Transformer-based unsupervised contrastive learning forhistopathological image classification. Medical image anal-ysis, 81:102559, 2022. 2, 3, 6 Weisi Xie, Nicholas P Reder, Can Koyuncu, Patrick Leo,Sarah Hawley, Hongyi Huang, Chenyi Mao, Nadia Pos-tupna, Soyoung Kang, Robert Serafin, et al. Prostate can-cer risk stratification via nondestructive 3D pathology withdeep learningassisted gland analysis. Cancer research, 82(2):334345, 2022. 1, 3 Achla Bharti Yadav, Mala Kamboj, Anjali Narwal, and AnjuDevi. Diagnostic efficacy of deeper sections in routine oralhistopathology practice: a retrospective study.Journal ofDentistry, 19(1):63, 2018. 1 Imaad Zaffar, Guillaume Jaume, Nasir Rajpoot, and FaisalMahmood. Embedding space augmentation for weakly su-pervised learning in whole-slide images. In 2023 IEEE 20thInternational Symposium on Biomedical Imaging (ISBI),pages 14. IEEE, 2023. 2"
}