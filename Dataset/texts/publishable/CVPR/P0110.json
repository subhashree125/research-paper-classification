{
  "Abstract": "Autonomous vehicles require a precise understanding oftheir environment to navigate safely. Reliable identificationof unknown objects, especially those that are absent dur-ing training, such as wild animals, is critical due to theirpotential to cause serious accidents. Significant progressin semantic segmentation of anomalies has been driven bythe availability of out-of-distribution (OOD) benchmarks.However, a comprehensive understanding of scene dynam-ics requires the segmentation of individual objects, andthus the segmentation of instances is essential.Devel-opment in this area has been lagging, largely due to thelack of dedicated benchmarks.To address this gap, wehave extended the most commonly used anomaly segmenta-tion benchmarks to include the instance segmentation task.Our evaluation of anomaly instance segmentation methodsshows that this challenge remains an unsolved problem. Thebenchmark website and the competition page can be foundat:",
  ". Introduction": "Modern segmentation methods perform well on cu-rated closed-world datasets with a fixed set of classes.However, models trained with a fixed training set fallshort of solving the task when unexpected objects arepresent .These anomalies often cause modelsto misclassify, assigning known classes to unknown ob-jects . To prevent such behavior in real world ap-plications, it is important to design or adapt models to han-dle such anomalies. The task of anomaly detection spansmultiple modalities , applications , andtasks . The particular focus of this work is theanomaly instance segmentation task, that aims to providesegmentation models with the ability to segment out-of-distribution (OOD) objects. This task is particularly criticalfor autonomous driving scenarios, where a recognition error",
  ". Annotation example for the previous semantic annota-tion of the RoadAnomaly21 dataset (top) and the extended anno-tation labels (bottom) for our newly proposed benchmark": "can cause serious accidents. A collision with lost cargo onthe road or with livestock could be life-threatening. To eval-uate the performance of anomaly segmentation methods, anumber of benchmarks have been proposed .While anomaly segmentation methodsachieve exciting results on popular benchmarks, the area ofanomaly instance segmentation remains unexplored. Earlydatasets for anomaly segmentation included partialinstance annotations of anomalies, but recently proposeddatasets omit instance information . However, instancesegmentation is critical for understanding complex sceneswith multiple anomalous objects, such as cows and sheepas shown in , that may appear in a group. Pre-vious anomaly segmentation approaches that operate on apixel level would fail to distinguish individual objects. Un-derstanding these objects separately provides context about",
  "arXiv:2406.11835v1 [cs.CV] 17 Jun 2024": "the potential dynamics of a scene, improving downstreamtasks such as navigation or planning. We hypothesize thatrecent advances in open set and class-agnostic instance segmentation have encouraged research in the areaof anomaly instance segmentation, which was previouslytoo challenging. Recently, three works following differentparadigms proposed to solve the task of anomaly instancesegmentation . However, each of these worksproposes a different evaluation procedure.To address this limitation, we propose a benchmark andevaluate existing methods in a unified manner. We extendthe labels of popular anomaly segmentation datasets to instance segmentation. These datasets provide diversereal-world cases of road anomalies with precise annota-tions. We reuse the Average Precision (AP) metric for instance evaluation similarly to the Cityscapes setup ,with a slight modification to evaluate instances as small as10 pixels in size. In comparison to the semantic anomalybenchmarks, the AP metric avoids size bias and requireshigh precision for smaller anomalous objects. This is par-ticularly important in the context of autonomous driving,where detecting anomalies in the distance is critical to givethe system time to react.To this end, we re-annotated anomalies within theFishyscapes , RoadAnomaly21, and RoadObstacle21 datasets to evaluate anomaly instance segmentation meth-ods.We apply publicly available instance segmentationmethods on both validation and test set and provide qual-itative evaluation of the results. Our evaluations show thatwhile current anomaly segmentation methods perform wellon semantic anomaly segmentation, instance segmentationmethods achieve moderate performance, suggesting a con-siderable space for improvement. We make validation dataavailable on our challenge website, and open a submissionportal where new approaches can be submitted.",
  ". Related Work": "Out-of-Distribution (OOD) Datasets have primarily fo-cused on classification tasks, with several benchmarks re-cently introduced . A common evaluation task isdisentanglement of two classification datasets such as CI-FAR and SVHN. Methods such as deep ensembles andMonte Carlo dropout , while performing well on OODclassification, show limited usefulness in anomaly segmen-tation tasks . Open-set instance segmentation assumes the presence of OOD data during training, a condi-tion not applicable to anomaly segmentation where com-pletely unseen objects may appear .In autonomousdriving, novel evaluation schemes have been proposed fordetection tasks . However, these works do not ad-dress the need for precise pixel-level mapping in monoculardriving detection setups. Our work explores the segmenta-tion of anomaly instances, which allows accurate prediction",
  "of individual, previously unseen, objects": "Anomaly Segmentation Datasets.Anomaly segmenta-tion has received significant attention with the emergenceof several recent datasets and benchmarks . TheLost and Found (L&F) dataset introduced the task ofanomaly segmentation in a camera setup similar to the oneused for the Cityscapes dataset . L&F has annotationslimited to the road area and anomaly classes; however, ithas questionable labels that include bicycles and kids asanomalies . To fully control for anomalies in the train-ing and test sets, the CAOS benchmark introduces areal dataset based on BDD100K , treating certain in-lier classes as anomalies, and a synthetic dataset for train-ing and testing. FishyScapes Lost and Found (FS L&F) reannotates images from L&F to extend in-distribution re-gions outside of the road class and introduces a separatebenchmark with artificial anomalies. Despite its popular-ity, FS L&F lacks anomaly instance segmentation and it isconstrained to lost cargo on the road. To solve the diversityissue, SegmentMeIfYouCan introduces a diverse datasetwith real anomalies on roads, which are not limited to theCityscapes camera perspective. In past years, evaluation onFS L&F and SegmentMeIfYouCan dataset has been a stan-dard practice. However, instance annotations are missingfrom these datasets. Our work aims to extend these popularbenchmarks by providing accurate instance annotations. Anomaly Segmentation Methods.Segmentation ofanomaly instances has been underexplored until recently.There are previous works in open-set instance segmenta-tion .However, they rely on unknown objectspresent in the training set; and methods that rely on depthcues that are not applicable in general case. In generalanomaly instance segmentation methods produce per-pixelanomaly scores, while providing anomaly instances too.U3HS uses uncertainty in semantic predictions to guidethe region segmentation, and then clusters predicted class-agnostic instance embeddings. Mask2Anomaly appliesmodifications to the Mask2Former architecture to pro-duce reliable semantic anomaly scores in background re-gions, and uses a connected components on anomaly scoreswith a strategy to remove false-positives using intersectionswith in-distribution predictions. UGainS combines theRbA anomaly segmentation method with an interactivesegmentation model to predict instances using pointprompting. Given the limited number of specialized meth-ods for anomaly instance segmentation, we evaluate thesemodels and analyze their performance, offering insightsinto their practical applications and limitations.",
  "UGainS 27.1445.8211.4219.1527.2246.5425.1942.81Mask2Anomaly 11.7323.644.789.0317.2328.4413.7324.30U3HS 0.190.730.000.000.220.620.190.58": "amples include a deer or a cardboard box that may appearin the middle of the road. Per-pixel segmentation does notprovide sufficient information for downstream tasks suchas tracking or navigation. The more challenging problemof instance segmentation remains under-explored and lacksaccessible benchmarks. This benchmark addresses the lackof test evaluation protocols available to the community.We aim to fill the gap by extending the labels of Seg-mentMeIfYouCan and FS L&F datasets for instancesegmentation. We merge these datasets into a unified bench-mark and adopt commonly used Average Precision (AP)metrics , that closely follows the Cityscapes seg-mentation benchmark. Data.We use three datasets for anomaly segmenta-tion: RoadAnomaly21 and RoadObstacle21 from Segment-MeIfYouCan , and FS L&F . These are the standardbenchmarks for the task, and they complement each otherin label diversity well (see ). To maintain data in-tegrity, we keep the test sets from the datasets intact, using100 images from RoadAnomaly21, 412 from RoadObsta-cle21, and 275 from FS L&F as our full test sets. In ad-dition, we provide a relabeled validation set of 100 imagesfrom FS L&F.The test set contains three relabeled datasets with differ-ent properties, but shares a common in-distribution dataset.For the submission to the benchmark, we allow modelstrained on 19 Cityscapes classes as the in-distributiondataset, and allow the use of auxiliary data, such asCOCO to introduce virtual anomalies, similar to otheranomaly segmentation works .Itis important to note that we expect no explicit supervi-sion to segment unknowns, much like in the real world,we do not know what kind of anomalies we will encounter.The benchmark data contains three classes: inlier, outlier,and ignore. In-distribution regions contain classes knownto Cityscapes; ignore regions are ambiguous regions thatneither contain anomalies nor are in-distribution regions;and the outlier class contains anomalous instances (see Fig-ure 1). Ignore regions are ambiguous regions for which aclass cannot be defined; common cases in Cityscapes are:bridges, advertisement posts, back side of street signs anddark regions where the class could not be determined. Weomit ignore regions in evaluation and discard cases that overlap significantly with these regions. We evaluate pre-dictions only for the outlier class, without focusing on eval-uation of in-distribution predictions. To calculate the finalAverage Precision (AP) score, we compute a weighted av-erage based on the number of images in each dataset. Labeling Policy.In RoadAnomaly21, anomalies are ofarbitrary size, located anywhere on the image, containinghighly diverse samples. Each individual object, such as ananimal or object, is labeled as an individual object withoutintroducing group labels. FS L&F mainly contains anoma-lies on the road, separate objects such as stacked boxes,which are treated as separate instances. Only ambiguousregions are treated as ignore for RoadAnomaly21 and FSL&F. For RoadObstacle21, however, only the drivable areais considered an inlier, and everything outside the drivablearea, including anomalies, are labeled as ignore regions.Gaps within complex anomalies are also treated as ignoreregions. Each labeled object on an image is given a uniqueidentifier. Bounding boxes are also generated to facilitateanomaly localization. Metrics. Conventional anomaly segmentation metrics tendto favor larger objects. Average Precision or False Posi-tive Rate (FPR) per-pixel metrics, or sIoU, which groupsanomalies together, do not provide the correct evaluationmetric. Our benchmark uses the Average Precision (AP)metric, a standard in instance segmentation that evaluatesprecision at IoU thresholds from 0.5 to 0.95. Additionally,we provide the AP50 metric to assess performance at a 50%IoU threshold, following the community practice. Detection Benchmark. While our current focus is instancesegmentation, we have converted instance data and predic-tions into bounding boxes to evaluate anomaly object de-tection capabilities. However, our initial results show thatcurrent anomaly detection methods such as VOS per-form suboptimally in this setup. For more details on thedetection benchmark we refer readers to the supplementarymaterial and leave this area for future research.",
  "roadanomalyroadobstaclefishyscapes": ". Diversity of instance labels. RodAnomaly21typi-cally contains multiple objects, while RoadObstacle21containssmaller objects in smaller quantities, and Fishyscapes L&Fpro-vides a balance between the two. to the benchmark. In cases when code was not available,we worked closely with authors to reimplement unavailablemethods and submit them to the benchmark. We kept thetest set private and allowed evaluation on the validation set. The U3HS method belongs to a class of models thatneither require auxiliary data nor external models for in-stance segmentation. The core of the method is the abil-ity to learn class-agnostic instance embeddings that gener-alize beyond the training distribution. These embeddings inuncertain regions are clustered to get instance predictions.This allows clustering of anomalous regions occluded byother objects. While U3HS is capable of localizing anomalyinstances without external data, it struggles in generatingprecise object masks, as measured by the AP metric thatevaluates instances with at least 50% IoU with the groundtruth. Mask2Anomaly is a model that uses auxilary data,but does not use an external model for instance segmenta-tion. Common to other methods in the community ,the model uses auxiliary data from COCO for guidingthe anomaly scores that are grouped using connected com-ponents to form instance proposals. To reduce the num-ber of false positives, Mask2Anomaly introduces a post-processing strategy. It computes the intersection with pre-dicted in-distribution masks and uses class entropy to deter-mine true instance proposals. The approach benefits from apowerful backbone and is effective in segmenting individ-ual anomalous objects, however, it merges closely locatedanomalies (see ). UGainS is a method that uses both auxiliary dataand an external generalist segmentation model, namelythe segment anything model (SAM) .The methoduses the anomaly segmentation method RbA based onMask2Former , fine-tuned using data from COCO, togenerate uncertainty regions. UGainS uses farthest pointsampling to sample a number of points from these regionsas prompts for SAM . While the method produces accu-rate segmentation masks, it relies on two models to get pre-dictions. A limited number of prompts leads to missed de-tections in smaller regions and increases the number of false",
  ". Conclusion": "Detecting and accurately segmenting anomaly instances onroads is a significant challenge, requiring an understandingof objectness without direct training on specific anomalyclasses. In this work, we introduced a new benchmark foranomaly instance segmentation that integrates three popu-lar anomaly datasets. The unified benchmark provides adiverse set of anomalies that vary in size, number of im-ages, and annotation detail. We evaluate the performance ofcurrent methods for segmenting anomaly instances and pro-vide intuition behind the results. Our results show that cur-rent techniques struggle particularly with distant and smallobjects, and with precise segmentation masks. The bench-mark results suggest strong opportunities for advancementin the area. As autonomous vehicle technologies continueto evolve, driven by large amounts of data, it remains a chal-lenge to capture all possible real-world situations. Our workaddresses the need to evaluate instance segmentation as astep towards reliable autonomous driving. We acknowledge fruitful discussions with H. Blum, R.Chan, S. Gasperini and S. Rai, as well as a contributionof annotations for Fishyscapes by H. Blum, and help withthe benchmark submission from S. Gasperini and S. Rai.M.R. an M.A. acknowledge support by the German Fed-eral Ministry of Education and Research within the juniorresearch group project UnrEAL (grant no. 01IS22069).",
  "Alexey Nekrasovs research has been funded by BMBFproject WestAI (grant no. 01IS22094D). We thank M.Burdorf, G. Lydakis, C. Schmidt, and others in the lab fordiscussions and feedback": "J. Behley, M. Garbade, A. Milioto, J. Quenzel, S. Behnke,C. Stachniss, and J. Gall.SemanticKITTI: A Dataset forSemantic Scene Understanding of LiDAR Sequences. In In-ternational Conference on Computer Vision (ICCV), 2019.1 Paul Bergmann, Michael Fauser, David Sattlegger, andCarsten Steger.MVTec AD A Comprehensive Real-World Dataset for Unsupervised Anomaly Detection.InConference on Computer Vision and Pattern Recognition(CVPR), 2019. 1 Paul Bergmann, Xin Jin, David Sattlegger, and Carsten Ste-ger.The MVTec 3D-AD Dataset for Unsupervised 3DAnomaly Detection and Localization. In Proceedings of theInternational Joint Conference on Computer Vision, Imagingand Computer Graphics Theory and Applications, 2022. 1 Hermann Blum, Paul-Edouard Sarlin, Juan Nieto, RolandSiegwart, and Cesar Cadena.The Fishyscapes Bench-mark: Measuring Blind Spots in Semantic Segmentation.International Journal on Computer Vision (IJCV), 129(11):31193135, 2021. 1, 2, 3 Robin Chan, Krzysztof Lis, Svenja Uhlemeyer, HermannBlum, Sina Honari, Roland Siegwart, Pascal Fua, MathieuSalzmann, and Matthias Rottmann. SegmentMeIfYouCan:A Benchmark for Anomaly Segmentation. In Neural Infor-mation Processing Systems (NeurIPS), 2021. 1, 2, 3 Robin Chan, Matthias Rottmann, and Hanno Gottschalk.Entropy maximization and meta classification for out-of-distribution detection in semantic segmentation. In Interna-tional Conference on Computer Vision (ICCV), 2021. 3 Liang-Chieh Chen, Yukun Zhu, George Papandreou, FlorianSchroff, and Hartwig Adam. Encoder-Decoder with AtrousSeparable Convolution for Semantic Image Segmentation. InEuropean Conference on Computer Vision (ECCV), 2018. 1 Bowen Cheng, Ishan Misra, Alexander G. Schwing, Alexan-der Kirillov, and Rohit Girdhar.Masked-attention MaskTransformer for Universal Image Segmentation. In Confer-ence on Computer Vision and Pattern Recognition (CVPR),2022. 1, 2, 4 Marius Cordts, Mohamed Omran, Sebastian Ramos, TimoRehfeld,Markus Enzweiler,Rodrigo Benenson,UweFranke, Stefan Roth, and Bernt Schiele.The cityscapesdataset for semantic urban scene understanding. In Confer-ence on Computer Vision and Pattern Recognition (CVPR),2016. 2, 3",
  "Alex Kendall and Yarin Gal.What Uncertainties Do WeNeed in Bayesian Deep Learning for Computer Vision? InNeural Information Processing Systems (NeurIPS), 2017. 1": "Alexander Kirillov, Eric Mintun, Nikhila Ravi, Hanzi Mao,Chloe Rolland, Laura Gustafson, Tete Xiao, Spencer White-head, Alexander C. Berg, Wan-Yen Lo, Piotr Dollar, andRoss Girshick. Segment Anything. In International Con-ference on Computer Vision (ICCV), 2023. 2, 4 Balaji Lakshminarayanan, Alexander Pritzel, and CharlesBlundell. Simple and Scalable Predictive Uncertainty Es-timation using Deep Ensembles. In Neural Information Pro-cessing Systems (NeurIPS), 2017. 2",
  "Chen Liang, Wenguan Wang, Jiaxu Miao, and Yi Yang.GMMSeg: Gaussian Mixture based Generative SemanticSegmentation Models.In Neural Information ProcessingSystems (NeurIPS), 2022. 1": "Tsung-Yi Lin, Michael Maire, Serge Belongie, James Hays,Pietro Perona, Deva Ramanan, Piotr Dollar, and C LawrenceZitnick. Microsoft COCO: Common objects in context. InEuropean Conference on Computer Vision (ECCV), 2014. 3,4, 1 Kira Maag, Robin Chan, Svenja Uhlemeyer, Kamil Kowol,and Hanno Gottschalk. Two Video Data Sets for Trackingand Retrieval of Out of Distribution Objects. In Asian Con-ference on Computer Vision (ACCV), 2022. 1",
  "Aasheesh Singh, Aditya Kamireddypalli, Vineet Gandhi, andK. Madhava Krishna. LiDAR guided Small obstacle Seg-mentation. In International Conference on Intelligent Robotsand Systems (IROS), 2020. 2": "Nitish Srivastava, Geoffrey Hinton, Alex Krizhevsky, IlyaSutskever, and Ruslan Salakhutdinov.Dropout: a simpleway to prevent neural networks from overfitting. In NeuralInformation Processing Systems (NeurIPS), 2014. 2 Yu Tian, Yuyuan Liu, Guansong Pang, Fengbei Liu, Yuan-hong Chen, and Gustavo Carneiro. Pixel-wise Energy-biasedAbstention Learning for Anomaly Segmentation on Com-plex Urban Driving Scenes.In European Conference onComputer Vision (ECCV), 2022. 1, 3, 4",
  "Jingkang Yang, Pengyun Wang, Dejian Zou, Zitang Zhou,Kunyuan Ding, Wenxuan Peng, Haoqi Wang, Guangyao": "Chen, Bo Li, Yiyou Sun, Xuefeng Du, Kaiyang Zhou,Wayne Zhang, Dan Hendrycks, Yixuan Li, and Ziwei Liu.OpenOOD: Benchmarking Generalized Out-of-DistributionDetection.In Neural Information Processing Systems(NeurIPS), 2022. 1, 2 Fisher Yu, Haofeng Chen, Xin Wang, Wenqi Xian, YingyingChen, Fangchen Liu, Vashisht Madhavan, and Trevor Dar-rell. Bdd100k: A diverse driving dataset for heterogeneousmultitask learning. In Conference on Computer Vision andPattern Recognition (CVPR), 2020. 2 Jingyang Zhang, Jingkang Yang, Pengyun Wang, HaoqiWang, Yueqian Lin, Haoran Zhang, Yiyou Sun, XuefengDu, Kaiyang Zhou, Wayne Zhang, Yixuan Li, Ziwei Liu,Yiran Chen, and Hai Li. OpenOOD v1.5: Enhanced Bench-mark for Out-of-Distribution Detection.arXiv preprintarXiv:2306.09301, 2023. 2",
  "Supplementary Material": "Detection benchmark.We have converted instance la-bels into bounding boxes for the anomaly detection bench-mark. For evaluation, we considered three methods, namelyUGainS , Mask2Anomaly , and VOS . TheCOCO Average Precision (AP) and Average Recall(AR) metrics serve as evaluation metrics. Unfortunately,we observed an unexpectedly poor performance of VOS.While performing well on ambiguous objects, i.e. the toycar is correctly predicted as an anomaly, vos struggles topredict for an unknown object (see ). Note that,we have not contacted the authors of VOS for help withthe submission and cannot fully trust our results. We planto open the detection benchmark for submission along withthe instance benchmark, such that we can evaluate anomalydetection methods with the help of the community."
}