{
  "Abstract": "Tattoos have been used effectively as soft biometrics toassist law enforcement in the identification of offenders andvictims, as they contain discriminative information, and area useful indicator to locate members of a criminal gang ororganisation. Due to various privacy issues in the acqui-sition of images containing tattoos, only a limited numberof databases exists. This lack of databases has delayed thedevelopment of new methods to effectively retrieve a poten-tial suspects tattoo images from a candidate gallery. Tomitigate this issue, in our work, we use an unsupervisedgenerative approach to create a balanced database consist-ing of 28,550 semi-synthetic images with tattooed subjectsfrom 571 tattoo categories. Further, we introduce a novelTattoo Template Reconstruction Network (TattTRN), whichlearns to map the input tattoo sample to its respective tattootemplate to enhance the distinguishing attributes of the finalfeature embedding. Experimental results with real data, i.e.WebTattoo and BIVTatt databases, demonstrate the sound-ness of the presented approach: an accuracy of up to 99%is achieved for checking at most the first 20 entries of thecandidate list.1",
  ". Introduction": "The use of tattoos as soft biometrics to assist law enforce-ment in identifying suspects has steadily grown along withtheir popularity in society. In 2015, The National Instituteof Standards and Technology (NIST) (Tatt-C) reportedthat one-fifth of US adults have at least one tattoo, makingthe US population the third most tattooed in the world, afterItaly and Sweden. This trend was constantly expanding, asevidenced by a survey conducted in 20212, which revealedthat 26% of Americans have at least one tattoo. In contrast",
  "* Publicly available training set. Number of categories reported for the identification case": "to biometric characteristics, e.g. fingerprints and faces, tat-toos cannot be used to directly establish the identity of asubject. However, tattoos, unlike other soft biometrics suchas gender, age or race, contain more discriminative infor-mation to support the identification of individuals and are auseful indicator to track members of a criminal gang or or-ganisation . Therefore, tattoo recognition represents anarea of interest for forensic investigators, which motivatesthe development of automated image-based tattoo retrievaltechniques .In the context of tattoo retrieval, the NIST Tatt-C andTatt-E challenges advanced the development of tattoo de-tection and identification systems for real-world applicationscenarios . Earlier tattoo image retrieval practices werebased on keyword or metadata matching, where law en-forcement agencies typically followed the ANSI/NIST-ITL1-2000 standard and assigned a single keyword to each tat-too image in the database . The limitations of keyword-based systems (e.g., limited and insufficient vocabulary todescribe different tattoo patterns and inconsistent labels) ledto the development of techniques that represented tattoos ashandcrafted descriptors capturing the texture, appearance,or colour of the tattoos .With the introduction and success of deep neural net-works (DNNs) in various pattern recognition and computervision applications, some recent research efforts have beendevoted to tattoo localisation , detection or seg-",
  ". Examples of tattoos from WebTattoo representing achallenge for state-of-the-art solutions": "mentation . Moreover, a few techniques have focused ontattoo retrieval or identification through the representationof tattoos as compact binary or floating-point embed-dings . The main reasons that have slowed downthe development of new tattoo retrieval methods are, on theone hand, the lack of large-scale tattoo databases, as shownin Tab. 1. It should be noted that a few tattoo databasesare publicly available and that most of them were designedfor tattoo detection and segmentation or pro-vide a limited number of subjects or samples . Onthe other hand, previous works often neglect challenges thatcause performance degradation, e.g. low-image quality, see. Consequently, a moderate identification rate (IR)below 65% at the rank-1 is reported in the latest publishedtattoo identification pipelines.To overcome the aforementioned challenges, we intro-duce a large-scale semi-synthetic tattoo database based onwhich a novel tattoo retrieval approach is proposed thattransforms tattooed human skin into the respective tattootemplate to improve the final tattoo description. Thereby,the accuracy of tattoo retrieval can be significantly im-proved. The main contributions of this scientific work are: A large-scale semi-synthetic tattoo database that consistsof 28,550 samples from 571 different tattoo templatesor categories. To simulate a real-life scenarios, tattooedsamples are generated and augmented in terms of scale,colour adjustments, distortions, and opacity. For the syn-thesis, the general requirements for generating syntheticbiometric data are considered . A tattoo retrieval solution that transforms tattooed humanskin into the corresponding tattoo template. The recon-struction function optimised together with a well-knownidentity loss function alleviates the above issues encoun-tered in real images and, thus, improves the identificationperformance of state-of-the-art algorithms. A comprehensive evaluation of the proposed system onreal images according to the metrics defined in the in-ternational standard ISO/IEC 19795-1 for biometrictesting and reporting. Experimental results conducted onWebTattoo and BIVTatt show a convincing per-formance improvement of the proposed system over thebaselines.",
  "The remainder of this paper is organised as follows: a": "brief review of existing tattoo retrieval systems is providedin Sect. 2. In Sect. 3, the fundamentals of the proposedapproach are presented, along with a description of thetattoo generation. The experimental setup is explained inSect. 4 and results as well as derived findings are discussedin Sect 5. Finally, conclusions and future work directionsare presented in Sect. 6.",
  ". Related Work": "Among the various soft biometric traits, tattoos have re-ceived considerable attention by forensic investigators inrecent years, due to their prevalence among the criminalsector of the population and their prominence in visual at-tention. For more than 5,000 years, humans have markedtheir bodies with tattoos to express personal beliefs or toassociate themselves with a group. The oldest evidence oftattooing was found on the body of Otzi, the Iceman. Otzi,Europes most famous mummy, was discovered by Germanhikers in the Alps in 1991. The next oldest evidence of tat-tooing comes from mummies believed to have died between3351 and 3017 BC in Ancient Egypt3. In forensics, tattooshave also proved useful in helping to identify victims of ter-rorist attacks such as 9/11 and natural disasters such as the2004 Indian Ocean tsunami .To assist in the identification of subjects, early tattoo re-trieval systems relied on keyword or metadata matching.For this purpose, law enforcement agencies usually fol-lowed the ANSI/NIST-ITL 1-2000 standard and assigneda single keyword to each tattoo image in the database .Since these solutions had obvious drawbacks, for example,i) a limited vocabulary to describe numerous tattoo patterns,ii) several keywords could be used to adequately describe atattoo, and iii) inconsistency in the labelling of tattoos, thenext set of retrieval approaches focused on the use of hand-crafted descriptors to represent the colour, texture, shape,and appearance of tattoos . A comprehensivereview of these methods up to 2019 can be found in .In this work, we restrict to briefly summarising deeplearning-based tattoo retrieval solutions due to their re-ported success and outstanding performance in various pat-tern recognition and computer vision tasks . In 2019,Han et al. introduced a system that was able to learntattoo detection and compact tattoo representation jointly ina single DNN by multitask learning. Following this idea,Zhang et al. proposed a DNN-based framework forjoint tattoo detection and re-identification of individuals.Their reported IRs improved in the WebTattoo database in case the detection module was activated. Nicolas-Dazet al. evaluated publicly available DNN models, pre-trained with large generic image databases, for tattoo iden-",
  "TR T": ". Conceptual overview of the proposed system: the template transformed from the input image helps to mitigate challenges relatedto the capturing process. The final feature embedding representing the salient properties of the input tattoo is the concatenation of the twocomputed feature embeddings and can be used to retrieve similar tattoo samples in a database. tification and showed that these DNNs can achieve high IRswithout even fine-tuning them for the target task of tattooretrieval. The same authors also made the BIVTatt databasepublicly available in .In addition, Nicolas-Daz etal. presented an attention pooling mechanism to adaptintermediate convolutional layers of pre-trained DNNs forthe tattoo identification task.The aforementioned tattoo retrieval systems are basedon deep learning techniques, which require a considerableamount of training data to achieve good performance. InTab. 1, we summarise the main features of the databasesused for such purposes. Note that, on the one hand, thatTatt-C and PinTatt are not available to the research com-munity.On the other hand, the existing databases onlyconsist of a few tattoo categories or samples which do notcover most real-life scenarios. This could make algorithmstrained on those databases prone to overfitting.Image synthesis has recently emerged as a reliable so-lution to both privacy concerns and the lack of trainingdata . To our knowledge, few studies have addressedthe (semi-)synthetic generation of tattoo images for retrievalpurposes.Existing methods to create face images withtattoos , are mainly designed for the visualisation oftattoos in controlled skin images , or tattoo segmenta-tion .",
  ". Tattoo Template Reconstruction Network": "To mitigate the aforementioned problems, we introduce ourTattoo Template Reconstruction Network (TattTRN), whichlearns to map the input tattoo sample to its respective tat-too template. This tattoo template mapping is then usedto enhance the distinctive attributes of the final feature em- bedding. shows the conceptual overview of the pro-posed TattTRN. In our work, we hypothesise that a cleantattoo template may contain meaningful information to as-sist both an supervised learning approach and forensic in-vestigators in making decisions. In the case of low-qualityimages, such as those shown in , where the tattoo isalmost imperceptible to the human eye, the proposed con-cept could reconstruct the corresponding template and, thus,help forensic investigators. In addition to the above bene-fits, the transformation of an input tattoo image into a cleantemplate would also provide subject identity suppression, asthe reconstructed template is not expected not contain tracesof skin colour or other sensible information.The following subsections describe the different compo-nents of our proposed TattTRN (Sect. 3.1), as well as thedefinition and synthesis of the tattoo database (Sect. 3.2)involved in training the approach.",
  ". Main Components": "The proposed approach consists of three main components(see ): synthetic tattoo generation (STG), image-to-template translation (ITT) and feature space representation(FSR), which can be used for tattoo retrieval. STG allowsthe offline/online generation of tattooed samples, which canbe directly represented as a feature embedding or trans-lated into the predefined tattoo template. Whereas a directrepresentation of the sample (light blue trapezoid in FSR)aims at capturing intrinsic properties of the input image(I Rnn), the ITT module focuses on the constructionof the respective clean tattoo template (RT ), which is, inturn, represented as a feature embedding (light red trapezoidin FSR). Both feature embeddings contain prominent char- acteristics of the input image and complement each otherto enrich the final representation of the tattoos. For tattooretrieval (a use case represented by the yellow box on theright in ), we use the concatenation of both embed-dings to form a feature vector of size 2 K. To translatethe input image into a clean tattoo template in the ITT com-ponent, we use, as a proof-of-concept, the Unet net-work based on the ResNet34 encoder and built a cyclictranslation, as done in CycleGAN . Thus, the qualityof the template reconstruction is improved. Note that otherencoder-decoder architectures proposed for image-to-imagetranslation, such as Diffusion Models , could be em-ployed, and thus improve the reconstruction results yieldedby Unet. To optimise the cyclic Unet, two binary cross-entropy (BCE) loss functions are computed and combinedas follows:",
  "Lrec = LT rec + LIrec(3)": "where I is the semi-synthetic generated image using the tat-too template T in STG and RI is the reconstructed imagefrom the translated tattoo template RT in ITT. BCE mea-sures the difference between two probability distributions,i.e., (T , RT ) and (I, RI) in this case and shows advantagesin terms of convergence for image reconstruction over otherloss functions such as the Minimum Squared Error (MSE).On top of the encoder-decoder network, a backbonenetwork computes the embedding representation (light redtrapezoid in FSR, ) of the reconstructed template RT .In our work, both backbones (light blue and red trapezoidsof FSR) are based on the same architecture and compute afeature embedding of size K each. However, they do notshare weights, as they process different representations ofthe input tattoo. Whereas the upper backbone (light bluetrapezoid) of FSR is fed by the semi-synthetic raw tattooimage generated by the STG component, the lower back-bone (light red trapezoid) computes the feature embeddingof the clean tattoo template.Together with Lrec we select the ArcFace loss to op-timise the backbones separately. Angular margin penalty-based softmax loss was initially proposed to optimise facerecognition systems . It aims to extend the softmax de-cision boundary to improve intra- and inter-class variationby applying an angular penalty margin on the angle between",
  "sample and yi is the angle between the tattoo feature em-bedding xi and the respective weight wyi. Note that linearfunction xiwyi": "4 can be represented as ||xi||||wyi||cos yi.In our work, both xi and wyi are normalised and hence||xi|| = 1 and ||wyi|| = 1, resulting only in the softmaxoptimisation of cos yi along with the angular margin mi.e., cos(yi + m). s is the scale factor according to .Finally, the loss combining both objective functions (i.e.,Eq. 3 and Eq. 4) to optimise our proposed TattTRN ap-proach is defined as:",
  ". Tattoo Generation": "Synthetic image generation has mainly focused on facialcharacteristics. In terms of market, face recognition hasmaintained a stable growth and its use has spread to manyapplication contexts, such as financial transactions, bordercontrol and video surveillance. To synthesise high-qualityfacial images, several approaches based on GAN or diffu-sion models, such as the StyleGAN family and la-tent diffusion models , have been proposed in recentyears. In comparison to the face, tattoo synthesis has re-ceived little attention. Recently, Andrej Karpathy demon-strated the robustness of diffusion models for generating re-alistic tattooed human images5. Ibsen et al. proposeda tattoo generator to blend predefined tattoo templates withreal faces and evaluated the performance impact of facialrecognition systems on tattooed faces. Following this idea,Gonzalez-Soler et al. extended the previous pipelineto mix the predefined tattoo templates with any area of hu-man skin and demonstrated its utility for the segmentation",
  "(c)": ". Examples of tattoos generated on chest and back imageswith their respective segmentation maps (3b) using base imagesand random tattoo templates (3a). Cropped tattoo images used inthe network training (3c). of real tattoos. In this article, we reuse the ideas shownin to generate 28,550 images of 571 different tat-too templates, i.e., 50 images per template.The NTU-Back and NTU-Chest databases, consistingof 647 and 434 images respectively, are used as base imagesof human skin to blend with the tattoos. Randomly 25:25images from both databases are used as base images to syn-thesise the 50 images per tattoo template. shows ex-amples of tattooed human skins. To simulate real images,the tattoo is made more realistic by adjusting the colour, andGaussian blur, and reducing the opacity. Since the segmen-tation map is available, the final tattooed samples are thencropped to train the TattTRN system.",
  ". Experimental Setup": "The experimental evaluation goals are manifold: i) studythe utility of the proposed semi-synthetic database for train-ing a tattoo retrieval system capable of retrieving real tattoosamples, ii) establish a benchmark of the proposed Tatt-TRN systems with baseline approaches, and iii) evaluatethe capability of the TTE subsystem to enhance low-qualityimages. In all experiments, we follow a cross-database pro-tocol where the proposed semi-synthetic database is usedto train the systems and the real ones for evaluating perfor-mance. The test set is randomly divided into five subsets ofbiometric enrolment and identification transactions follow-ing a closed-set scenario, i.e., searched identities are alwaysin the enrolment database. Therefore, the mean identifica-tion rates alongside the standard deviation are presented asCumulative Matching Characteristic (CMC) curves. For-mally, CMC is a graphical presentation of the results ofmated searches in a closed-set identification test, whichplots the true positive identification rate (IR) as a functionof a rank value . The identification performance of thesystems is also evaluated for an open set scenario in terms ofFalse Negative Identification Rates (FNIR) and False Pos-itive Identification Rates (FPIR), and their values are pre-sented as DET curves.",
  ". Databases": "To evaluate the utility of both the semi-synthetic databaseand the proposed system, we selected the two publicly avail-able databases in Tab. 1 that provide tattoo category labelsi.e., WebTattoo and BIVTatt .According to , WebTattoo comprises around 300Ksamples of 600 different tattoo categories which were ex-tracted from the internet. For training, the authors randomlyselected about 1,400 tattoo images from 400 tattoo classesand the remaining tattoo images from 200 tattoo classeswere used for testing. In our experiments, we only used thetraining set that was made available to the research commu-nity.BIVTatt contains 210 original tattoo images and4,200 images generated after applying 20 different typesof transformations to the original images. Along with theimages, the authors provided the bounding box informationfor each tattoo. Given the coordinate problems associatedwith the bounding boxes, only correctly cropped sampleswere selected, resulting in 3,103 samples from 159 tattoocategories. shows examples of tattoo images in theWebTattoo and BIVTatt databases.",
  ". Implementation Details": "Both the proposed TattTRN systems and baselines were im-plemented in PyTorch and trained utilising a NvidiaA100 Tensor Core GPU with 40 GB of GPU Memory overthe generated 28,550 semi-synthetic images.The imagesize was set to 224 224. To further cover the featurespace of real tattoo images, the brightness, contrast, sat-uration, and hue of the training images are randomly ad-justed. In addition, the networks were initialised with theirpre-trained weights on ImageNet and trained for 100epochs using the Adam optimiser with a learning rate of1e5 and weight decay of 0.95. A batch size of 64 im-ages is also set for training. As backbones, the large ver- . Closed-set identification performance of the proposed TattTRN approach for different backbones in terms of Rank-1 (%) on realimages in WebTattoo and BiVTatt . The best result per backbone and database is highlighted in bold.",
  "Avg.74.4576.7078.6275.8477.5878.6668.6367.5467.0394.1694.5495.1694.1194.8995.1891.5188.7988.91": "sion of MobileNetv3 , 101-layer ResNet , 121-layerDenseNet , and the small version of EfficientNetv2 and SwinTransformer (Swin) are used.These net-works offer coverage of the main approaches proposed inthe last decade e.g., attention mechanisms and visiontransformers . Note that other architectures developedspecifically for tattoo retrieval e.g., the joint detection andcompact representation scheme or the weighted aver-age pooling-based approach 6, can also be applied.",
  ". Results and Discussion": "The results discussion relies on the above three goals: theclosed-set identification performance of the proposed Tatt-TRN approach (Sect. 5.1), as well as the respective open-set identification results 5.2 are reported. Sect. 5.3 showsa comparison of TattTRN with the baselines. To evaluatethe utility of TattTRN, the benchmark is established againstthe direct embedding representation of the semi-synthetictattoo images generated by the STG component. Finally,some examples of translating real images into templates arepresented in Sect. 5.4.",
  ". Closed-set Evaluation": "Since the use of ArcFace loss depends on the optimisationof the angular margin parameter (i.e., m), we report themean closed-set identification performance of TattTRN forthree values of m = {0.1, 0.5, 0.9} and three embeddingsizes K = {128, 256, 512} in Tab. 2. K values greater than512 would result in a final feature vector of 2 K > 1024,leading to an efficiency deterioration of the system.Note that the generated semi-synthetic tattoo images re-flect the main properties of the real tattooed samples andtheir use allows our TattTRN approach to achieve highperformance for the evaluated real databases. TattTRN isable to register an average IR of at most 81.60% at rank-1 for the challenging WebTattoo dataset and 96.54% at thesame rank value for BIVTatt. Compared to the results re-ported in their respective articles, TattTRN reports a per-formance improvement of approximately 18% for Web-",
  ". CMC curves for different backbones combined withTattTRN": "Tattoo (i.e., IR 64%) and 25% for BIVTatt (i.e.,IR = 70.91%) . It is worth mentioning that the bench-marking systems referred to in the articles of both databaseswere fully trained on real tattoo samples following an inter-nal database protocol, in contrast to TattTRN, representingthe most salient properties of the semi-synthetic images inthe training to identify real specimens. In terms of param-eter optimisation, we observe that most backbones achieveon average the best performance for K = 512 and m = 0.5 orm = 0.1, with the combination of TattTRN with Swin being the best performing approach for WebTattoo (i.e.,",
  ". DET curves for different backbones combined with Tatt-TRN": "IR = 81.60%) and BIVTatt (i.e., IR = 96.54%) in rank-1.Since in forensic investigations not only the first posi-tions in the candidate lists are important, we also show theCMC curves for the different backbones combined with theTattTRN approach proposed in using the best param-eter configurations (i.e., bold values in Tab. 2). Note thatTattTRN combined with Swin achieves only the best IR inrank-1 for both databases. For rank values above 15, we cansee that the EfficientNetv2 backbone yields an average IR ofabout 95% for WebTattoo and above 99% for BIVTatt. Thisimplies that forensic investigators can detect a perpetratorbased on tattoos with an accuracy of up to 99% by checkingthe first 20 entries of the candidate list.",
  ". Open-set Evaluation": "We report the TattTRN performance in for the sce-nario where the tattoo template or category is probably notincluded in the enrolment set (i.e., open-set scenario). Notethat TattTRN combined with different backbones yieldssimilar equal error rates (EER) for WebTattoo. However,in line with the closed-set results shown in Sect. 5.1, Effi-cientNetv2 achieves the best identification performance forhigh-security thresholds for both databases. In particular,this backbone achieves an FNIR of more than 70% for Web-Tattoo and an FNIR of approximately 30% for BIVTatt foran FPIR = 0.1%. The latter result implies that, at most, 30out of 100 mated transactions are not included in the candi-date list if the system accepts only 1 out of 1000 non-matedtransactions in the candidate list.",
  ". Benchmark of TattTRN": "We evaluate the benefits of the translation module (i.e. ITT)for TattTRN. For this purpose, the entire TattTRN archi-tecture is compared with the submodule comprised of onlythe raw embedding representation of the generated semi-synthetic tattoo image (i.e. light blue trapezoid in ). shows the benchmark of the whole TattTRN againstthe raw embedding computed by EfficientNetv2 . Note",
  ".Benchmark of TattTRN against the respective best-performing backbone": "that the TattTRN benefits from the ITT component, result-ing in a performance improvement for EfficientNetv2 onboth databases. Specifically, for the challenging WebTattoodataset, TattTRN outperforms EfficientNetv2 for all rankvalues and achieves an IR approximate of 95% in rank-20i.e., the perpetrator can be identified with an accuracy of upto 95% by checking at most the first 20 entries of the can-didate list. Despite the advantages of the ITT component,there are still several images in WebTattoo whose qualityshould be further improved (see Sect. 5.4). It should bementioned that extreme sharpening or blurring transforma-tions to decrease image quality, as well as approaches thatcut out part of the image (e.g., CutMix ), were not takeninto account in the training. The use of these operationscould also increase the reconstruction performance of IIT,and hence of TattTRN.",
  ". Tattoo Retrieval Examples": "Finally, in we show some examples of candidate listsretrieved by TattTRN from searched images and the respec-tive translated templates. Note that TattTRN is able to cor-rectly build the template from those images that were suc-cessfully retrieved in the first positions of the candidate list(i.e., images in a). The ITT component is therefore ca-pable of encoding challenging patterns, such as the womanand the rose in the last two rows of a. It should be no-ticed that the remaining retrieved images, ranked from 2 to4 in rows 2 and 3 of a, do not belong to the consultedtattoo category: TattTRN reports a similarity below 0.35.b, on the other hand, shows some images for which",
  ". Example of correctly and wrongly retrieved tattooed samples from WebTattoo for rank values between 1 and 4. The cosinesimilarity values are given for each case": "TattTRN could not correctly construct their clean tattootemplate, resulting in lower similarity values for the firstpositions in the candidate list. Note that they either haveextremely low image quality (e.g., images of rows 1 and3), which might even be difficult for human analysis, orthey contain overlapping tattoos (e.g., image of the secondrow). In the latter case, artistic characters are displayedin the background and an in-process panther in the fore-ground: TattTRN was able to partially construct its cleantattoo template. The overlapping of tattoos resulted in Tatt-TRN regaining first place in the ranking for a tattoo con-taining Latin characters and third place for the correspond-ing correct tattoo category (black panther). Notice that allthe tattoos retrieved in b have a similarity of less than0.42 with respect to the queried tattoo samples. This im-plies, in line with the results in a, that the input imagewould be a false negative depending on the system thresh-old (typically 0.5) and therefore all items in the candidatelist would be rejected by the system, even if there are itemsof the same category as the input image at the former posi-tions in the candidate list (e.g., the black panther). A poten-tial solution to improve the results of TattTRN on the aboveimages would be based on the use of a prompt-guided ap-proach that also encodes the semantic meaning of the tattooand the overlap between tattoos, or the combination witha super-resolution method that further improves the imagequality of the input tattoos.",
  "This work proposes a semi-synthetic tattoo database in con-junction with a tattoo retrieval approach called TattTRN,": "which exploits the transformation of the input image intoa clean tattoo template to enrich the final feature embed-ding and thus improve the retrieval performance of difficultimages in two freely available databases: WebTattoo andBIVTatt. The experimental evaluation of TattTRN showedthat the proposed balanced database, consisting of 28,550images from 571 tattoo categories, gathers the main prop-erties of the real images, resulting in an IR of up to 99%in the top 20 positions of the candidate list. Experimen-tal results also reported high performance when TattTRN iscombined with EfficientNetv2, yielding an IR of approxi-mately 81% for WebTattoo in rank-1. Compared to the re-sults reported for this database in its corresponding article,TattTRN improves identification performance by 18 % (i.e.,81.60% vs. 64%). Despite the results obtained by the Tatt-TRN, it still fails to encode extremely low-quality images orimages containing overlapping tattoos. In future work, wewill combine TattTRN with a new prompt-based componentthat includes the semantic meaning of tattoos and evaluatethe effect of different skin tones on tattoo segmentation andretrieval.",
  ". Acknowledgement": "This research work has been partially funded by the Hes-sian Ministry of the Interior and Sport in the course of theBio4ensics project and the German Federal Ministry of Ed-ucation and Research and the Hessian Ministry of HigherEducation, Research, Science and the Arts within their jointsupport of the National Research Center for Applied Cyber-security ATHENE. F. Boutros, N. Damer, F. Kirchbuchner, and A. Kuijper. Elas-ticface: Elastic margin loss for deep face recognition.InProc. Intl. Conf. on Computer Vision and Pattern Recogni-tion (CVPR), pages 15781587, 2022. 4 J. Calmon, J. Queiroz, C. Goes, and A. Loula. Augmentedtattoo: Evaluation of an augmented reality system for tattoovisualization. In Proc. Conf. on Graphics, Patterns and Im-ages, pages 265272, 2015. 3",
  "R. da Silva and H. Lopes. A transfer learning approach forthe tattoo detection problem. In Congresso Brasileiro de In-teligencia Computacional, pages 14, 2021. 1": "J. Deng, W. Dong, R. Socher, L. Li, K. Li, and L. Fei-Fei.Imagenet: A large-scale hierarchical image database.InProc. Intl. Conf. on Computer Vision and Pattern Recogni-tion (CVPR), pages 248255. Ieee, 2009. 5 J. Deng, J. Guo, N. Xue, and S. Zafeiriou. Arcface: Additiveangular margin loss for deep face recognition. In Proc. Intl.Conf. on Computer Vision and Pattern Recognition (CVPR),pages 46904699, 2019. 4",
  "J. Lee, A. Jain, W. Tong, et al. Image retrieval in forensics:tattoo image database application. IEEE MultiMedia, 19(1):4049, 2011. 1, 2": "B. Li, K. Xue, B. Liu, and Y. Lai.Bbdm:Image-to-image translation with brownian bridge diffusion models. InProc. Intl. Conf. on Computer Vision and Pattern Recogni-tion (CVPR), pages 19521961, 2023. 4 F. Li, W. Tong, R. Jin, A. Jain, and J. Lee. An efficient keypoint quantization algorithm for large scale image retrieval.In Proc. First ACM workshop on Large-scale multimedia Re-trieval and Mining, pages 8996, 2009. 1, 2 Z. Liu, Y. Lin, Y. Cao, H. Hu, Y. Wei, Z. Zhang, S. Lin, andB. Guo. Swin transformer: Hierarchical vision transformerusing shifted windows. In Proc. Intl. Conf. on Computer Vi-sion and Pattern Recognition (CVPR), pages 1001210022,2021. 6 A. Makrushin, C. Kauba, S. Kirchgasser, S. Seidlitz, C.Kraetzer, A. Uhl, and J. Dittmann. General requirements onsynthetic fingerprint images for biometric authentication andforensic investigations. In Proc. ACM Workshop on Informa-tion Hiding and Multimedia Security (IH&MMSec), pages93104, 2021. 2",
  "M. Nicolas-Daz, A. Morales-Gonzalez, and H. Mendez-Vazquez. Weighted average pooling of deep features for tat-too identification.Multimedia Tools and Applications, 81(18):2585325875, 2022. 2, 3, 6": "A. Nurhudatiana and A. Kong. On criminal identification incolor skin images using skin marks (rppvsm) and fusion withinferred vein patterns. IEEE Trans. on Information Forensicsand Security ((TIFS)), 10(5):916931, 2015. 5 A. Nurhudatiana, A. Kong, L. Altieri, and N. Craft.Au-tomated identification of relatively permanent pigmented orvascular skin marks (rppvsm). In Proc. Intl. Conf. on Acous-tics, Speech and Signal Processing (ICASSP), pages 29842988, 2013. 5 A. Nurhudatiana, A. Kong, K. Matinpour, D. Chon, L. Al-tieri, S. Cho, and N. Craft. The individuality of relativelypermanent pigmented or vascular skin marks (rppvsm) in in-dependently and uniformly distributed patterns. IEEE Trans.on Information Forensics and Security ((TIFS)), 8(6):9981012, 2013. 5 A. Paszke, S. Gross, F. Massa, A. Lerer, J. Bradbury, G.Chanan, T. Killeen, Z. Lin, N. Gimelshein, L. Antiga, A.Desmaison, A. Kopf, E. Yang, Z. DeVito, M. Raison, A.Tejani, S. Chilamkurthy, B. Steiner, L. Fang, J. Bai, and S.Chintala. PyTorch: An Imperative Style, High-PerformanceDeep Learning Library. In Advances in Neural InformationProcessing Systems 32, pages 80248035, 2019. 5 R. Rombach, A. Blattmann, D. Lorenz, P. Esser, and B. Om-mer. High-resolution image synthesis with latent diffusionmodels. In Proc. Intl. Conf. on Computer Vision and PatternRecognition (CVPR), pages 1068410695, 2022. 4 O. Ronneberger, P. Fischer, and T. Brox. U-net: Convolu-tional networks for biomedical image segmentation. In Proc.Intl. Conf. on Medical Image Computing and Computer-Assisted Intervention (MICCAI), pages 234241, 2015. 4",
  "Q. Xu, S. Ghosh, X. Xu, Y. Huang, and A. Kong. Tattoodetection based on cnn and remarks on the nist database. InProc. Intl. Conf. on Biometrics (ICB), pages 17, 2016. 1, 2": "S. Yun, D. Han, S. Oh, S. Chun, J. Choe, and Y. Yoo. Cut-mix: Regularization strategy to train strong classifiers withlocalizable features. In Proc. Intl. Conf. on Computer Visionand Pattern Recognition (CVPR), pages 60236032, 2019. 7 L. Zhang, Z. He, Y. Yang, L. Wang, and X. Gao. Tasks in-tegrated networks: Joint detection and retrieval for imagesearch. IEEE Trans. on Pattern Analysis and Machine In-telligence (PAMI), 44(1):456473, 2020. 2 J. Zhu, T. Park, P. Isola, and A. Efros.Unpaired image-to-image translation using cycle-consistent adversarial net-works. In Proc. Intl. Conf. on Computer Vision and PatternRecognition (CVPR), pages 22232232, 2017. 4"
}