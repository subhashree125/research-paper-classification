{
  "Inverted Noise Map": ". (left) We propose a new synthetic image detectornew synthetic image detectornew synthetic image detectornew synthetic image detectornew synthetic image detectornew synthetic image detectornew synthetic image detectornew synthetic image detectornew synthetic image detectornew synthetic image detectornew synthetic image detectornew synthetic image detectornew synthetic image detectornew synthetic image detectornew synthetic image detectornew synthetic image detectornew synthetic image detector that uses two additional input signals derived from a fixed pre-trained StableDiffusion : an inverted latent noise map and the reconstructed input image. (middle) Our detector is trained using fake images generatedusing Stable Diffusion and real LAION images. It achieves state-of-the-art generalization performancestate-of-the-art generalization performancestate-of-the-art generalization performancestate-of-the-art generalization performancestate-of-the-art generalization performancestate-of-the-art generalization performancestate-of-the-art generalization performancestate-of-the-art generalization performancestate-of-the-art generalization performancestate-of-the-art generalization performancestate-of-the-art generalization performancestate-of-the-art generalization performancestate-of-the-art generalization performancestate-of-the-art generalization performancestate-of-the-art generalization performancestate-of-the-art generalization performancestate-of-the-art generalization performance in detecting unseen text-to-imagegenerators. (right) To ensure that the performance evaluation does not favor detectors that are biased towards particular themes or styles,we introduce a new thematically and stylistically aligned evaluation benchmarknew thematically and stylistically aligned evaluation benchmarknew thematically and stylistically aligned evaluation benchmarknew thematically and stylistically aligned evaluation benchmarknew thematically and stylistically aligned evaluation benchmarknew thematically and stylistically aligned evaluation benchmarknew thematically and stylistically aligned evaluation benchmarknew thematically and stylistically aligned evaluation benchmarknew thematically and stylistically aligned evaluation benchmarknew thematically and stylistically aligned evaluation benchmarknew thematically and stylistically aligned evaluation benchmarknew thematically and stylistically aligned evaluation benchmarknew thematically and stylistically aligned evaluation benchmarknew thematically and stylistically aligned evaluation benchmarknew thematically and stylistically aligned evaluation benchmarknew thematically and stylistically aligned evaluation benchmarknew thematically and stylistically aligned evaluation benchmark we measure detectors ability to discriminate fake images(e.g. DALLE 3, Imagen) from real images with matching content and style found on the Internet using reverse image search (RIS).",
  "Abstract": "Due to the high potential for abuse of GenAI systems, thetask of detecting synthetic images has recently become ofgreat interest to the research community. Unfortunately, ex-isting image-space detectors quickly become obsolete as newhigh-fidelity text-to-image models are developed at blindingspeed. In this work, we propose a new synthetic image detec-tor that uses features obtained by inverting an open-sourcepre-trained Stable Diffusion model. We show that these inver-sion features enable our detector to generalize well to unseengenerators of high visual fidelity (e.g., DALLE 3) even whenthe detector is trained only on lower fidelity fake imagesgenerated via Stable Diffusion. This detector achieves newstate-of-the-art across multiple training and evaluation se-tups. Moreover, we introduce a new challenging evaluationprotocol that uses reverse image search to mitigate stylisticand thematic biases in the detector evaluation. We show thatthe resulting evaluation scores align well with detectors in-the-wild performance, and release these datasets as publicbenchmarks for future research.",
  ". Introduction": "Recent advances in text-to-image modeling have made iteasier than ever to generate harmful or misrepresentativecontent at scale. Moreover, new versions of most photoreal-istic commercial models are being continuously updated andreleased behind closed APIs, making it harder to keep fakeimage detectors up to date. In this work, we make significantstrides towards building a GenAI detector that can reliablyidentify images from unseen photorealistic text-to-imagemodels. Specifically, we propose a model that can be trainedusing fake images only from Stable Diffusion (SD) andreliably detect images generated by recent open (Kandin-sky , Wuerstchen , PixArt- , etc.) and closed-source text-to-image models (Imagen , Midjourney ,DALLE 3 , etc.) of significantly higher visual fidelity.Existing methods focus primarily on detect-ing traces left by convolutional generators in a way that is ro-bust to re-compression, resizing and other in-the-wild trans-formations. While these methods worked well for GANs andearly diffusion models, we show that they, unfortunately, failto generalize well to current photorealistic generative models,even when re-trained using better data. Recent diffusion de-tectors that rely on CLIP embeddings or inversions",
  "arXiv:2406.08603v1 [cs.CV] 12 Jun 2024": "fail to generalize to challenging benchmarks. Drawing in-spiration from recent works that showed that GANs tend toomit hard objects and that text-to-image models leantowards easily captionable images , in this paper, wefocus on detecting fake images by analyzing internal repre-sentations of an existing off-the-shelf text-to-image model.In this paper, we introduce a new synthetic imagesynthetic imagesynthetic imagesynthetic imagesynthetic imagesynthetic imagesynthetic imagesynthetic imagesynthetic imagesynthetic imagesynthetic imagesynthetic imagesynthetic imagesynthetic imagesynthetic imagesynthetic imagesynthetic image detection methoddetection methoddetection methoddetection methoddetection methoddetection methoddetection methoddetection methoddetection methoddetection methoddetection methoddetection methoddetection methoddetection methoddetection methoddetection methoddetection method: FakeInversion. Our method uses featuresextracted from a lower-fidelity open-source text-to-imagemodel (Stable Diffusion ) to detect images generatedby unseen text-to-image generators. Specifically, our modeltakes as input 1) the original image, 2) the approximate noisemap recovered via text-conditioned DDIM inversionwith Stable Diffusion (SD), and 3) the reconstruction ob-tained by denoising the approximate noise map ().We show that these additional signals significantly improvethe performance of the resulting detector on unseen new pro-prietary and open-source photorealistic text-to-image mod-els, attaining a new state-of-the-art. We also provide an in-tuitive justification for why a diffusion detector needs suchfeatures to generalize well to unseen diffusion generators.To deploy a synthetic image detector at scale, we needto make sure that it is not relying on content signals such asthe presence of specific objects or styles in the image. If leftunmitigated, such bias towards particular themes or styleswould disproportionately marginalize particular groups whenapplied to detecting healthcare misinfo or forged art atscale. Unfortunately, existing evaluation protocols that mea-sure a detectors ability to differentiate between real and fakeimages drawn from very visually and thematically differentdistributions can not be used to test for the presence of suchbias in the detector. For example, evaluating a fake detectorusing real COCO images and fake images generated byDALLE 3 could favour a detector that assigns higherfakeness score to digital art, since COCO contains mostlynatural images. To circumvent these issues, we propose anew evaluation protocolnew evaluation protocolnew evaluation protocolnew evaluation protocolnew evaluation protocolnew evaluation protocolnew evaluation protocolnew evaluation protocolnew evaluation protocolnew evaluation protocolnew evaluation protocolnew evaluation protocolnew evaluation protocolnew evaluation protocolnew evaluation protocolnew evaluation protocolnew evaluation protocol: SynRIS. For each set of syntheticimages, we evaluate a given detector against a set of realimages obtained by applying reverse image search ()to given fake images the resulting evaluation does not favormodels biased towards any particular topic, theme, or style.We show that the proposed evaluation protocol is more reli-able at evaluating the quality of the synthetic image detector,especially when applied to closed-source text-to-image mod-els. We will release our evaluation benchmark (includingdatasets) for future research.To summarize our contributions: 1) we introduce a newsynthetic image detector that uses text-conditioned inversionmaps extracted from Stable Diffusion; 2) we show that thisadditional feature improves the detectors ability to detectimages generated by unseen text-to-image models, achievingnew state-of-the-art; 3) we propose a new challenging evalua-tion protocol that uses reverse image search to ensure that the classifier is not biased towards any particular theme or style;4) we verify that this evaluation protocol reliably measuresdetector generalization to closed text-to-image models; and5) we release our challenging benchmark for future research.",
  ". Related Work": "In this section we first give a brief overview of the state-of-art in image-space detectors, then we discuss how recentworks attempt to detect semantic inconsistencies in gener-ated images, and finally discuss how our evaluation protocolcompares to evaluation protocols used in prior work. Artifact Detectors. Wang et al. were among the firstto show that a CNN detector (CNNDet) generalized wellfrom more powerful GANs (e.g. ProGAN) to less powerfulones. Soon after, Chai et al. extended this idea with afully-convolutional network that classified individual imagepatches, Ju et al. explored fusing global and local imagefeatures, Corvi et al. explored better augmentation anddownsampling strategies, Zhang et al. and Frank et al. explored artifacts in the spectrum of GAN-generatedimages, and Marra et al. explored GAN fingerprinting. Generation Inconsistencies. Several works have focused onunderstanding the semantic properties of generated images.For example, Bau et al. showed that GANs avoid gen-erating hard objects such as mirrors and TVs that bothhumans and discriminators fail to notice missing. Recently,Ojha et al. showed that image CLIP embeddingsare highly predictive of whether an image is fake, and Shaet al. showed that images generated using text-to-imagemodels tend to have higher CLIP similarity to their automat-ically inferred captions, suggesting that images generated bytext-to-image models can often be described more fully byshort text captions compared to images naturally occurringon the web. Inspired by these works, we also focus on proper-ties of images beyond their low-level convolutional traces byexamining internal representations of diffusion models ob-tained using DDIM inversion . A concurrent work found that DDIM image reconstruction residuals are predic-tive of whether an image is fake. In this paper we justifywhy image-space residuals are insufficient, and empiricallyverify that a detector that uses internal representations of adiffusion model generalizes better. We evaluate our modelagainst the official DIRE checkpoint and perform an ablationusing only reconstruction residuals. Evaluation Protocols. Given that internal representationsof diffusion models lack the low-level features necessary toperform generator trace detection, we need a way to ensurethat the learned classifier does not overfit to particularobjects or styles. Unfortunately, prior works focus eitheron open-source models with known training sets but lowervisual fidelity or use dataset pairs of real and in-the-wildfake images that are too different both in style and content",
  "Evaluation Data (SynRIS)": ". Training and evaluation datasets. We train all methods on two training sets (top): ProGAN+LSUN from and StableDiffusion+LAION with fake images taken from DiffusionDB . We construct a new evaluation benchmark SynRIS (bottom) usingreverse image search (RIS) on fake images generated by both proprietary (e.g., DALLE 3 , Midjourney ) and open-source (e.g., Play-ground , PixArt-) models. Note that generators used for evaluation are of significantly higher visual fidelity than those used for training. to ensure the lack of such bias. For example, recent worksof Corvi et al. and Ojha et al. measure detectorsability to discriminate between DALLE 2 images and a mixof Imagenet, COCO and UCID or LAION respectively,and DIRE focuses only on open-source lower fidelitygenerators such as SD and older generators trained onImageNet and LSUN-Bedrooms . In a concurrentwork, Epstein et al. evaluate how adding training datafrom older models affects the performance of the classifieron newer fakes, which is an important problem but differentfrom the one we address in this paper.To summarize, we are the first to show that text-conditioned DDIM inversion feature maps extracted fromone diffusion model improve the ability of a detector toidentify images generated by other higher-fidelity diffusionmodels. Moreover, we are the first to propose an evaluationprocedure for GenAI detectors that ensures that the learneddetector is not biased towards any style or theme, and to quan-titatively verify that the resulting evaluation is more reliable.",
  ". Method": "In this section, we first provide a background on diffusionmodels and DDIM inversion. Then, we introduce our de-tection method that makes use of text-conditioned DDIMinversion and give an intuitive justification for why havingthis signal is helpful for generalization.Latent Diffusion Models. LDMs first map high-resolution (in our case, 5125123) RGB images x intolow-resolution (64644) latent images z using a pre-trained encoder E : X Z. The original image canbe recovered almost perfectly via a pre-trained decoderD : Z X. In the derivation below z correspond tosuch latent images, rather than RGB images.Conditional Diffusion Models and DDIM Inversion. Togenerate a new latent image z conditioned on some vectorc, a conditional denoising diffusion model starts froma random noise map zT of the same shape and iterativelystochastically denoises it using a learned denoising network for a fixed number of steps, until a clean latent image z0 isobtained. The process of sampling from a pre-trained diffu-sion model can be discretized into fewer steps and made de-terministic through the use of DDIM sampling . Notably,this sampling procedure enables inverting a clean image z0into a corresponding noise map zT , such that when zT is de-noised via DDIM sampling, we obtain a new latent z0 that isvery close to the original z0. Formally, to invert an image z0,i.e., to obtain a corresponding noise map zT , we iterativelyadd noise to its current estimate zt via the following condi-tional forward process starting from a clean latent image z0:",
  "zT = F(z0, c),z0 = R(zT , c).(4)": "Text Conditioning. In our case, the conditioning vector cused to modulate the forward and reverse sampling pro-cesses is the embedding of the text prompt describing animage. In this work, we use an off-the-shelf captioner (BLIP2 ) to obtain a text prompt describing an input image,and CLIP to embed this text. Prior work showed that therealism of generated images can be improved through theuse of classifier-free guidance . Later, Mokady et al. showed that classifier-free guidance leads to instability inDDIM inversion and proposed a mitigation strategy throughfine-tuning parts of the model. Since we cannot afford fine-tuning on each incoming image, in this paper we do not useclassifier-free guidance during inversion and sampling anduse the original conditional update rules described above.GenAI Detector. As shown in , given an inputimage x, we first caption that image using BLIP andembed that caption into a vector c using CLIP . Thenwe compute the corresponding latent image z0 = E(x)using a pre-trained encoder and obtain a latent DDIM noisemap zT using text-conditioned DDIM inversion with a pre-trained diffusion model. Then, we obtain a reconstructedlatent image z0 using text-conditioned DDIM sampling anddecode both the latent noise map zT and the reconstructionz0 to image space using the decoder D. Finally, we apply alearned mapping h : X 3 R to these images to get aprediction logit. We learn the parameters of this function via backpropagation of the binary cross-entropy loss (y, y)on the training set of known fake and real images {(x, y)}:",
  "= argminEx,y[ (h (x, D(zT ), D(z0)) , y)](7)": "Intuition. But why would a diffusion detector benefit fromhaving access to DDIM inversion of an image if it alreadyhas access to the image itself? Recent works showedthat DDIM can be viewed as a first-order discretization ofa neural probability-flow ODE. The bijection between ob-servations z0 and noise maps zt induced by this ODE canbe used to evaluate the likelihood of the data via the changeof variable. If we view the forward DDIM mapping F asan approximation of that true bijective mapping between",
  "FR": ". Proposed method. In addition to the original image itself (x), we also train our detector using the (decoded) noise map D(zT ) andreconstruction D(z0) obtained by inverting the image through Stable Diffusion using DDIM. The original image is first mapped to the latentspace with Stable Diffusions VAE Encoder. The latent image is then inverted and reconstructed through Stable Diffusions U-Net usingDDIM while conditioned on the CLIP embedding of the images predicted BLIP caption. The latent noise map and reconstruction aremapped back to image space using Stable Diffusions VAE Decoder. The original image, decoded noise map, and decoded reconstructionare then concatenated and used as input for our ResNet Classifier. the z0 and zT that introduces a discretization error intothe inverted noise maps zT , causing the resampled imagez0 to deviate from the original image z0, it can be shown(see App. B.1) that, in the first-order approximation, the log-likelihood of the data given that underlying model can beestimated from the input image z0, its imperfect reconstruc-tion z0, and the noise map zT alone: log p(z0) log pz(zT ) , z0 z0/2(8)Notably, the expression above does not explicitly dependon the parameters other than through these three signals.Given that, under model misspecification, likelihood-basedmodels tend to overgeneralize , producing samples thatare unlikely under the true data distributions, and assumingthat the class of diffusion-based models is similar enough toovergeneralize in similar ways, we propose that a model thathas access to all signals required to internally perform someform of likelihood testing on input data against a particulartext-to-image model (the image, its imperfect reconstruction,and the intermediate noise map) would generalize better todetect images generated via other diffusion models. Textconditioning c further amplifies differences between log-likelihoods of distributions of fake and real images, makingthe corresponding test more powerful and consequently mak-ing inversions even more useful for detecting fake images. Tosum up, GenAI detectors find discrepancies between the realdata distribution and the approximation learned by the GenAImodel. The equation above shows that proposed features en-able a detector to get a rough estimate of whether a given im-age is of high probability under the approximate distributionlearned by Stable Diffusion. We empirically verify that thisSD-likelihood signal helps in detecting other generators.",
  "In this section, we discuss our training and evaluation sets,which baseline methods we use to compare, and the detailsof how we train our classifier": "Baselines. We compare our model to a representative setof the most recent state-of-art baselines (all published in20232023202320232023202320232023202320232023202320232023202320232023) that open-sourced their training or inference code.DMDetDMDetDMDetDMDetDMDetDMDetDMDetDMDetDMDetDMDetDMDetDMDetDMDetDMDetDMDetDMDetDMDet is a state-of-art RGB-only method that achievedsignificant generalization performance through the use ofaugmentations and a modified down-sampling strategy; au-thors released only the inference checkpoint. UFDUFDUFDUFDUFDUFDUFDUFDUFDUFDUFDUFDUFDUFDUFDUFDUFD isanother recent state-of-the-art method that trains a linearclassification head on top of the CLIP embeddings ofreal and fake images. We use the official checkpoint andalso retrain it from scratch on each of our training sets us-ing the official code. DIREDIREDIREDIREDIREDIREDIREDIREDIREDIREDIREDIREDIREDIREDIREDIREDIRE is a concurrent work thatshowed that using image-space DDIM reconstruction resid-uals helps detection. The official checkpoint open-sourcedby the authors has an issue causing its performance to bemuch lower than the performance reported in the paper; wediscuss this in more detail in App. E.1. We also provide anablation of our method that uses only DDIM residuals. Thisserves as a close approximation of what a DIRE-like methodcould achieve. We also include an older convolutional base-line CNNDetCNNDetCNNDetCNNDetCNNDetCNNDetCNNDetCNNDetCNNDetCNNDetCNNDetCNNDetCNNDetCNNDetCNNDetCNNDetCNNDet using its official checkpoint and code toretrain on our data. Training data ProGAN+LSUN. Most prior works usethe ProGAN training set introduced in CNNDet . Thistraining set consists of 350k images from class-conditionedpre-trained ProGAN combined with a set of real images",
  "SDXLLAION0.6890.106108.71.6RIS (ours)0.8740.55193.00.4": ". Difficulty of RIS vs LAION eval. recall forthe state-of-the-art detector (UFD ) evaluated using fakes fromrespective generators and real images from LAION, reverse imagesearch (RIS), and WebLI (Imagens training set ) - higher FPRis harder; FID and KID between reals and fakes - lower is closer. from LSUN . Training on these images has yielded goodresults in the detection of GAN-generated images , and we find that this set continues to show promisewhen applied to images from newer diffusion models.Training data Stable Diffusion+LAION. Similar to theconcurrent work of Epstein et al. , we first train de-tectors using 300k fake Stable Diffusion v1 images fromDiffusionDB and 300k random real LAION im-ages. While state-of-the-art at the time of its release, StableDiffusion (v1) has since been eclipsed in quality by manynew text-to-image models. We find that training on fakeimages from this relatively old diffusion model still yields",
  "models capable of identifying fakes from much newer andmore powerful generators": "Evaluation data (fakes). We obtain several thousand im-ages generated by closed-source photorealistic text-to-imagemodels using APIs (Imagen ), using existing databasesof fakes on HuggingFace (Midjourney , DALLE 3 )and by taking fake images from prior academic benchmarks(DALLE 2 from ). We also generate several thousand im-ages using high-fidelity open-source text-to-image models1",
  "conditioned on Midjourney prompts": "Evaluation data (reals) Reverse Image Search (RIS).To ensure that detectors are not biased toward any particulartheme or style, we need sets of real and fake images that arethemselves stylistically and thematically aligned. We addressthis issue using a reverse image search API to find a visuallyand thematically similar real image for each fake image fromthe eval fake set defined above. Examples of images foundusing this procedure can be found in . We definereal images as images not generated using a text-to-imagemodel, even if other tools (such as Photoshop) were used. Toensure that our real images are not contaminated with similarimages generated by text-to-image models, we include onlymatches found on pages created before January 1, 2021. Asa result, our real sets include only images published beforethe original DALLE was announced. The exact sizesof all evaluation and training sets can be found in . Evaluation data prior academic benchmarks. We eval-uate competing methods on academic text-to-image bench-marks from published prior work that evaluate meth-ods abilities to differentiate between a set of fakes froma text-to-image model (e.g., DALLE 2) and an unrelatedset of real images (e.g., Imagenet, COCO). Consequently,these benchmarks can not be used to test whether a detectorfocuses on the styles and themes of a particular generator. Detector architecture. We use ResNet50 trained fromscratch as a detector backbone. In each experiment, we selectthe best checkpoint via validation on the held-out set sam-pled from the same source as the training set. We augmenteach image via a suite of random transforms before perform-ing DDIM inversion: flip, crop, color jitter, grayscale, cutout,noise, blur, jpeg, and rotate. We use BLIP to computeimage captions. See App. C for more details. Metrics. We report detection AUCROC as the main metric.We also provide tables with average precision and accuracy,along with PR, ROC and DET curves in the appendix. Toensure that trained and evaluated detectors can not exploit dif-ferences in image resolutions and aspect ratios, each image isresized to 256px along the shortest side and saved losslessly.",
  "Average0.4930.5040.6230.5460.7980.6970.6110.6610.759": ". Main Results Detector AUCROC. Detectors trained on ProGAN+LSUN and SD+LAION are evaluated using proprietary (firstpanel) and open-source (second panel) generators, and academic (A) benchmarks from prior work (last panel). Note: This DMDet classifierwas trained with fakes from an LDM checkpoint rather than Stable Diffusion. These models were re-trained by us.",
  ". Results": "In this section we discuss following key findings: 1) theproposed thematically and stylistically aligned RIS-basedevaluation protocol is harder and is more reliable then proto-cols used in prior work; 2) the proposed detector outperformsprior work on both prior academic and this new RIS-basedevaluation; 3) the DDIM inversion features were crucial inachieving high generalization in all cases. RIS-based evaluation is harder and more reliable. compares False Positive Rate (FPR) of the state-of-the-artdetector on different evaluation sets at the threshold thatattains 80% recall (fake images are the same, so the thresh-old at given recall is the same as well). Results show thatLAION-based evaluation significantly underestimates thefalse positive rate of the detector when evaluating its abilityto discriminate fakes from closed-source text-to-image mod-els (Imagen, DALLE 2/3) across both training sets. We alsoobtained real examples from the multimodal dataset usedto train Imagen (WebLI ), and evaluated the detectoragainst these real examples and these results closely alignwith our RIS-based eval (see Fig. A.1 for PR curves). TheFID and KID between real and fake images is alsolower for RIS eval, and matches FID/KID between WebLI and Imagen fakes, suggesting better stylistic and thematicalignment. Similar trends can be seen on open-source mod-els (Kadnisky, SDXL) and across both training sets. Theseresults suggest that our RIS-based eval is a more reliableway to estimate a models ability to detect images fromclosed-sourced text-to-image models trained on unknowndata. FakeInversion achieves state-of-the-art performance. shows that our method consistently scores best at de-tecting both closed and open-source methods across varioustraining sets. It also matches the performance of prior workon academic benchmarks. On average, our method outper-forms prior work by at least 4pp on both training setsboth training setsboth training setsboth training setsboth training setsboth training setsboth training setsboth training setsboth training setsboth training setsboth training setsboth training setsboth training setsboth training setsboth training setsboth training setsboth training sets. Inversions are crucial for generalization. To ensure thatthe observed gains are not coming from a particular choiceof hyperparameters in our detector, we performed an abla-tion training the exact same network using only RGB imagesand only absolute DDIM image reconstruction residualsRes = |x D(z0)| (similar to DIRE ). showsthat both RGB and reconstruction residual-based models per-form significantly worse than the proposed method that usesboth the input image, its reconstruction, and the inversionmap, confirming all three are essential to achieve state-of-artgeneralization to unseen detectors. In the appendix we show",
  "DALLE 2 0.410 0.650 0.854 0.592 0.650 0.747DALLE 3 0.399 0.672 0.642 0.676 0.672 0.759Midjourney v5 0.434 0.590 0.750 0.530 0.590 0.664Imagen 0.530 0.670 0.776 0.729 0.670 0.807": "Kandinsky 2 0.462 0.600 0.716 0.614 0.607 0.714Kandinsky 3 0.434 0.617 0.824 0.606 0.679 0.774PixArt- 0.470 0.604 0.647 0.594 0.570 0.707Playground 2.5 0.439 0.604 0.726 0.510 0.533 0.660SDXL-DPO 0.338 0.643 0.704 0.738 0.711 0.837SDXL 0.410 0.612 0.691 0.784 0.709 0.884Seg-MOE 0.416 0.585 0.799 0.607 0.611 0.781SSD-1B 0.494 0.672 0.775 0.690 0.648 0.813Stable-Cascade 0.448 0.674 0.743 0.557 0.686 0.766Segmind Vega 0.465 0.677 0.781 0.683 0.631 0.829Wurstchen 2 0.563 0.624 0.664 0.588 0.605 0.702 . Input Signal Ablation AUCROC. Detectors trained onProGAN+LSUN and Stable Diffusion+LAION and evaluated onproprietary and open generators. Using the original images, inver-sion maps, and reconstructions (Ours) yields better performancethan RGB or DDIM Residuals (as in DIRE ) alone.",
  "that text conditioning also helps generalization": "Robustness and Interpretability. shows that ourmethod is sufficiently robust to in-the-wild transformations such as JPEG re-compression and blur. showsthat a model that uses inversion maps not only generalizesbetter but also focuses more on features that humans recog-nize as GenAI artifacts (e.g. malformed hands). Discussion. Our results suggest that, while both our methodand recent methods (UFD , DMDet ) consistentlyoutperform older prior methods (CNNDet ) on prioracademic benchmarks, recent methods struggle to maintain",
  "real": ". Saliency Analysis. Green boxes highlight the most salientregions according to our model and purple boxes for an equiva-lent RGB-only model. We use a post-hoc explainability technique,XRAI . The regions of anatomical inconsistencies in fakes aremost salient in our model. the same level of exceptional performance when evaluatedagainst our new RIS-based evaluation benchmark, even whenretrained on better data. Our method and some of the olderbaselines, on the other hand, perform well on both. We at-tribute this discrepancy to the drastic shift between real andfake images used in prior evaluation suggesting that someof the recent methods were in part overfitting to the distribu-tions of styles and content of natural images, which appearsto be less of an issue for our method.",
  ". Conclusion": "In this paper, we introduce FakeInversion: a GenAI de-tection method that uses text-conditioned inversion mapsextracted from a pre-trained Stable Diffusion to achieve anew state-of-the-art at detecting images generated via unseentext-to-image diffusion models. We also propose SynRIS: anew challenging evaluation protocol that uses reverse imagesearch to ensure that the evaluation is not biased towardsany styles and themes. We show that the new protocol isalso more reliable at evaluating detectors on images gen-erated using proprietary models trained on unknown data.While FakeInversion improves upon the state-of-the-art onthis challenging benchmark, there clearly remains muchwork to be done; the detection performance on the newevaluation benchmark is far from saturated. We invite futureresearchers to use these new datasets to explore, build, anddeploy better GenAI detectors at scale, with confidence thattheir solutions will not favor any content and style.",
  "Junsong Chen, Jincheng Yu, Chongjian Ge, Lewei Yao,": "Enze Xie, Yue Wu, Zhongdao Wang, James Kwok,Ping Luo, Huchuan Lu, et al. Pixart-alpha: Fast train-ing of diffusion transformer for photorealistic text-to-image synthesis. arXiv preprint arXiv:2310.00426,2023. 1, 6, 7, 8, 13, 15, 16, 30 Riccardo Corvi, Davide Cozzolino, Giada Zingarini,Giovanni Poggi, Koki Nagano, and Luisa Verdoliva.On the detection of synthetic images generated by dif-fusion models. In ICASSP, 2023. 1, 2, 4, 5, 6, 8, 12,26",
  "Joel Frank, Thorsten Eisenhofer, Lea Schonherr, AsjaFischer, Dorothea Kolossa, and Thorsten Holz. Lever-aging frequency analysis for deep fake image recogni-tion. In ICML, 2020. 2, 8": "Yatharth Gupta, Vishnu V. Jaddipal, Harish Prabhala,Sayak Paul, and Patrick Von Platen. Progressive knowl-edge distillation of stable diffusion xl using layer levelloss, 2024. 6, 7, 8, 13, 15, 16, 35, 37 Kaiming He, Xiangyu Zhang, Shaoqing Ren, and JianSun. Deep residual learning for image recognition.In Proceedings of the IEEE conference on computervision and pattern recognition, pages 770778, 2016.14",
  "Lehtinen. Progressive growing of gans for improvedquality, stability, and variation. ICML, abs/1710.10196,2017. 5, 12": "Daiqing Li, Aleks Kamko, Ehsan Akhgari, Ali Sabet,Linmiao Xu, and Suhail Doshi. Playground v2.5: Threeinsights towards enhancing aesthetic quality in text-to-image generation, 2024. 3, 7, 8, 13, 15, 16, 31 Junnan Li, Dongxu Li, Silvio Savarese, and Steven Hoi.Blip-2: Bootstrapping language-image pre-trainingwith frozen image encoders and large language models.arXiv preprint arXiv:2301.12597, 2023. 4, 6, 14, 17,39",
  "https : / / huggingface . co / datasets /lambdalabs / pokemon - blip - captions/,2022. 17, 39": "Dustin Podell, Zion English, Kyle Lacey, AndreasBlattmann, Tim Dockhorn, Jonas Muller, Joe Penna,and Robin Rombach. Sdxl: Improving latent diffu-sion models for high-resolution image synthesis. arXivpreprint arXiv:2307.01952, 2023. 6, 7, 8, 13, 15, 16,33 Alec Radford, Jong Wook Kim, Chris Hallacy, AdityaRamesh, Gabriel Goh, Sandhini Agarwal, Girish Sas-try, Amanda Askell, Pamela Mishkin, Jack Clark, et al.Learning transferable visual models from natural lan-",
  "Harish Prabhala Yatharth Gupta, Vishnu V Jaddi-pal. Segmoe: Segmind mixture of diffusion experts.https : / / github . com / segmind / segmoe,2024. 6, 7, 8, 13, 15, 16, 34": "Fisher Yu, Ari Seff, Yinda Zhang, Shuran Song,Thomas Funkhouser, and Jianxiong Xiao. Lsun: Con-struction of a large-scale image dataset using deeplearning with humans in the loop.arXiv preprintarXiv:1506.03365, 2015. 4, 6, 12 Jiahui Yu, Yuanzhong Xu, Jing Yu Koh, Thang Luong,Gunjan Baid, Zirui Wang, Vijay Vasudevan, AlexanderKu, Yinfei Yang, Burcu Karagol Ayan, Ben Hutchin-son, Wei Han, Zarana Parekh, Xin Li, Han Zhang, Ja-son Baldridge, and Yonghui Wu. Scaling autoregres-sive models for content-rich text-to-image generation.TMLR, 2022. 6, 7, 14",
  "Supplementary Table of Contents": "In this supplementary material, we provide following addi-tional details regarding the proposed model and data: In Section A we describe how traing and eval data wasobtained. Visualizations of real and fake image pairs forall evaluation datasets in the proposed SynRIS bench-mark can be found in the end of the document in Fig. F.1-F.7.",
  "Ethics and Limitations": "The ultimate goal of this work is to prevent abuse and thespread of misinformation, an inherently ethical task. Whengenerating our datasets, we sourced our prompts from anexisting database. As such, some of the generated imagesmay inadvertently contain inappropriate content. We explic-itly address misalignment between fake and real images inour training and evaluation to ensure that the detector is notfavouring any styles or themes to avoid marginalization ofany groups.While our method performs well at detecting imagesfrom existing diffusion models, this same performance maynot transfer well to text-to-image models that do not makeuse of diffusion, such as text-to-image GANs (GigaGAN) and transformers (Muse ). Training our model alsorequires significantly more compute than similar methods(CNNDetect , DMDetect ) since we must first passall training images through our inversion pipeline.",
  "A.2.2Midjourney": "For our Midjourney images, we use this dataset on HuggingFace (link). These images were scraped from the MidjourneyDiscord server. This dataset includes a tag indicating whetheror not the image was upscaled by the user. We chooseimages that had been upscaled since they are presumablyof higher quality (since the user spent additional credits toupscale them).",
  "UFD (ProGAN + LSUN) Fakes from Imagen": "Figure A.1. Receiver Operating Characteristic (left) Precision-Recall (middle) and Detection Error Tradeoff (right) curves for detectingImagen versus real images from its training set WebLI (red), Reverse Image Search (green) and LAION (orange). These curves showthat Imagen versus RIS is indeed a significantly harder task than Imagen versus LAION and matches Imagen versus WebLI.",
  "Average0.4930.5280.8040.6640.6240.757": "Table D.1. Main Results Detector Average Precision. In the main paper, we report the AUCROC metric when evaluating our classifiers.We report AP (Average Precision) here for completeness as well. We observe similar trends: our method performs best across nearly alldatasets. Note: This DMDet classifier was trained with fakes from an LDM checkpoint rather than Stable Diffusion. These models werere-trained by us.",
  "The generators analyzed thus far are trained to be generalaesthetic text-to-image models": "Here, we evaluate our model on models that have beenfine-tuned generate images from very specific domains:Anime and Pokemon. Table D.3 shows that even when usinglow-quality training data (ProGAN), our model still general-izes to these very out-of-distribution domains while existingmethods (UFD , CNNDet ) completely fail, evenperforming worse than random guessing.",
  "E.1. DIRE": "The DIRE paper reports almost perfect detectionperformance on all unseen test sets. However, after theircode was released, several researchers noticed a fundamentalissue with the training and evaluation setup present intheir released code and checkpoints (link) causing thein-the-wild performance to drop to near-random levels.More specifically, all pre-processed images used for trainingare saved with the same extension as the source images.Since all input real images in the training set are saved as*.JPG files and all fake images are saved as *.PNG files,all real DIRE images used to train and evaluate the networkwere embedded with JPEG artifacts while the non of thefake images used for training and evaluation were. As such,the model seemingly learned to detect the presence of JPEGartifacts. This holds even for the robustness experimentssince augmented real and fake images are also saved as JPGand PNG respectively. In all of our datasets, both real andfake images are saved as lossless *.PNG files, explainingDIREs poor performance on all our test sets. To honor thecontribution of DIRE authors, we conducted an ablation that",
  "Average0.5100.5380.7230.6480.6170.700": "Table D.2. Main Results Acc @ Equal Error Rate. We further report Acc@EER here as an additional metric. We observe similar trends:our method performs best across nearly all datasets. Note: This DMDet classifier was trained with fakes from an LDM checkpoint ratherthan Stable Diffusion. These models were re-trained by us.",
  "Anime0.670.130.34Pokemon0.830.320.48": "Table D.3. AUCROC. When trained on lower-quality data(ProGAN), existing methods (UFD , CNNDet ) completelyfail to generalize to our extremely out-of-distribution datasets,even doing worse than randomly guessing. On the other hand,our method continues to generalize well. used the exact same absolute residuals signals as reported inDIRE paper. It is evident from our results that the inversionsignals we propose in this paper perform much better thenDIRE signals across all evaluation benchmarks.",
  "F. SynRIS Visualization": "Figures F.1 to F.4 contain samples from our evaluation setsusing closed-source models. Figures F.5 to F.15 contain sam-ples from our evaluation sets using open-source models. Thecorresponding images in each of these open-source modelfigures were generates using the same prompts. The top panelconsists of fake images either found online or generated byus, and the bottom panel are the corresponding real imagesfound via reverse image search.Figures F.16 and F.17 contain samples from our Pokemonand Anime datasets respectively. The real images were takenfrom a source dataset and the attached captions wereused to generate the fake images with SD Pokemon Dif-fusers and Animagine ."
}