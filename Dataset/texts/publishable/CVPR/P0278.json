{
  "Abstract": "Representation learning of pathology whole-slide im-ages (WSIs) has been has primarily relied on weak su-pervision with Multiple Instance Learning (MIL). However,the slide representations resulting from this approach arehighly tailored to specific clinical tasks, which limits theirexpressivity and generalization, particularly in scenarioswith limited data. Instead, we hypothesize that morpho-logical redundancy in tissue can be leveraged to build atask-agnostic slide representation in an unsupervised fash-ion.To this end, we introduce PANTHER, a prototype-based approach rooted in the Gaussian mixture model thatsummarizes the set of WSI patches into a much smallerset of morphological prototypes. Specifically, each patchis assumed to have been generated from a mixture distri-bution, where each mixture component represents a mor-phological exemplar. Utilizing the estimated mixture pa-rameters, we then construct a compact slide representationthat can be readily used for a wide range of downstreamtasks. By performing an extensive evaluation of PANTHERon subtyping and survival tasks using 13 datasets, we showthat 1) PANTHER outperforms or is on par with super-vised MIL baselines and 2) the analysis of morphologi-cal prototypes brings new qualitative and quantitative in-sights into model interpretability. The code is available at",
  "Equal contributionPresently at Emory University School of Medicine": ". Slide decomposition into morphological prototypesDue to morphological redundancy across and within the tissue, aslide can be decomposed into prototypes. We introduce PANTHER,a method that can identify and extract morphological prototypes toform a compact and unsupervised slide representation. based on Multiple Instance Learning (MIL) ,in which the gigapixel WSI is tokenized into a large set ofpatch embeddings (N > 10, 000) with a pretrained visionencoder, followed by aggregation of the embeddings .Current advances in CPath have examined: (1) learning bet-ter patch embeddings with domain-specific vision encodersbased on self-supervised learning (SSL) and (2) developing new aggregation strate-gies for pooling patch embeddings into a slide representa-tion . As many histology datasets have lim-ited samples for supervised MIL, an emerging goal in CPathis to (3) shift slide representation learning from weakly-supervised to unsupervised , which mayhelp mitigating data and label scarcity and improving gen-eralization.",
  "arXiv:2405.11643v1 [cs.CV] 19 May 2024": "We postulate that such models are particularly suited forfine-grained classification tasks, such as survival outcomeprediction that require holistic modeling of morphologiesfound in the tissue microenvironment . In contrastto needle-in-a-haystack tasks (e.g., micro-metastasis de-tection) that require localizing tumor patches, panoramictasks require integrating spatial heterogeneity (diversity ofdistinct tumor populations) , interactions and con-text (immune infiltrate near invasive tumor margin) ,and size (number and size of masses) . Attention-basedarchitectures demonstrate clinical-grade perfor-mance in the former task (selectively focusing on diagnos-tic patches of a single visual concept) ; however, theyhave limited expressivity in the panoramic tasks that ben-efit from understanding proportions and mixtures of visualconcepts . Based on these insights, we propose an unsupervisedslide representation framework that can accurately capturethe proportions and mixtures of morphological visual con-cepts. Specifically, we build on the observation that WSIpatches show morphological redundancy and thus a handfulof morphological patterns are repeated (). Formally,we hypothesize that a concise set of key descriptors (proto-types), coupled with distribution characterizing the extentand variation of each descriptor, would comprehensivelysummarize the WSI. As this summary only relies on the sta-tistical characteristics of each WSI, this yields a generic andunbiased slide embedding applicable across multiple down-stream tasks. To faithfully summarize the WSI, the goal be-comes to construct (1) a mapping between each patch andthe prototypes and (2) a slide embedding with the learnedmapping that includes representation of each prototype andits extent, i.e., its cardinality. To this end, we introduce PANTHER, a PrototypeAggregatioN-based framework for compacT HEterogenousslide set Representation (PANTHER). Inspired by previouswork in prototype-based set representation learning , PANTHER builds an unsupervised slide embeddingby assuming that each patch embedding is generated fromthe Gaussian mixture model (GMM), with each morpho-logical prototype representing a mixture component. Byemploying GMM, the two aforementioned goals are seam-lessly satisfied through the parameter estimation procedurewith Expectation-Maximization (EM) : (1) the esti-mated posterior probability of mixture assignment for eachpatch defines the mapping between a patch embedding anda prototype, and (2) mixture probability represents cardinal-ity, and mixture mean & covariance represent the represen-tation of corresponding morphological pattern. The sliderepresentation is formed as a concatenation of the estimatedGMM parameters across all prototypes. Since the represen-tation can be decomposed along each prototype, this allowsfor per-prototype nonlinear modeling and interpretation of the slide centered around each histology visual concept.To summarize, our contributions are (1) the first proto-typical framework for learning compact and unsupervisedslide representations in WSI based on GMM; (2) a compre-hensive evaluation of four diagnostic and nine prognostictasks, demonstrating the outperformance against nearly allunsupervised and supervised baselines; (3) post-hoc inter-pretability with the quantification and visualization of mor-phological prototype spread within the tissue.",
  ". Multiple instance learning in CPath": "While initial histology-based outcome prediction was cen-tered on pathologist-annotated region-of-interests , later works have utilized WSIs for clinical predictiontasks with MIL . There is a sustainedeffort for new MIL schemes, with a focus on new patch ag-gregation strategies to learn more representative and task-specific slide embedding, towards better predictive accu-racy or interpretability . MILmethods based on multiscale representation slides have re-cently shown promise for panoramic tasks .PANTHER is similar to MIL in that the slide-level embed-ding is constructed from patches for outcome prediction.However, PANTHER constructs an unsupervised set embed-ding and is agnostic to downstream tasks, in contrast to su-pervised MIL frameworks.",
  ". Quantification of distance between sets": "Measuring the distance between two distinct sets (Wasser-stein distance), e.g., between supports of empirical proba-bility distributions, has received increasing attention from adiverse range of disciplines such as signal processing ,vision-language tasks , and computational biology . Given a similarity (or cost) metric between set el-ements such as L2 distance, the Wasserstein distance is de-fined as transporting (or matching) elements of one set tothe other, incurring a minimum cost. Computing such dis-tance is commonly called the optimal transport (OT) .It is natural to extend this idea to CPath, where the bio-logical entities of interest (e.g., WSI and genomic data) aretypically modeled as a set of biological concepts. Differentfrom MIL setting where a set of WSI patches is matched to apatient-level clinical label, this concerns matching betweentwo sets: 1) sets of WSI patches for slide retrieval or domain adaptation , 2) different cancer datasets toquantify morphological distance between different cancertypes , and 3) a set of WSI patches and a set of genomictokens to learn optimal fusion for improved prognosis .Similarly, PANTHER can be seen as the matching problembetween a set of WSI patches and prototypes.",
  ". Prototype-based set representation": "Prototypes are representative examples of data points thatshare the same class, usually formulated as centroids fromclustering that describe unique human-interpretable con-cepts and other semantic information . Recently,it has been applied to compactly represent large set data inbioinformatics and NLP . The desiderata forprototype-based set representation is to model: (1) cardinal-ity, i.e., how many elements in the set are associated with aprototype, and (2) description, i.e., prototype identity.Posed also in many related forms such as signatures [53, 95] and bag of visual words (BoVW) , learningprototypical representations is a natural problem in CPath asrepeating histology patterns often reflect the same morphol-ogy . Recent prototypical MILapproaches for pathology include AttnMISL , whichaggregates patch embeddings within the same cluster, fol-lowed by aggregating the pooled cluster embeddings. Fol-lowing recent advances in visual self-supervised learning,prototypes have been used for constructing unsupervisedslide features via pooling similar patch embeddings into aconcatenated representation (H2T ) or measuring theproportion of prototypes assignments in WSIs (HPL ).We note that H2T and HPL have limitations in not encod-ing cardinality or not including deep visual features, whichare relevant for interpretability and solving panoramic tasks.Moreover, as many pretrained vision encoders in CPath arepretrained on TCGA, prototypical patterns lack extensiveevaluation of out-of-domain performance.",
  ". Prototype-based aggregation": "Given a WSI for subject j, we tessellate it into small non-overlapping patches Xj= {xj1, , xjNj} with xjn RW H3. We then employ a feature extractor fenc() pre-trained on large archives of histopathology images , toextract a representative and compressed embedding fromeach patch.The set of extracted embeddings Zj={zj1, , zjNj} with zjn = fenc(xjn) Rd is then aggre- gated to construct a slide embedding zjWSI.We aim to represent the set Zj with a small set of proto-types H = {h1, , hC} with hc Rd, C Nj, withoutcompromising essential morphological information. Usingthe prototypes as references, each patch is aggregated (or",
  "n=1j(zjn, hC)],(1)": "where j(, ) : Rd Rd RM is a function that mapsa pair of patch embedding and reference, based on thesimilarity between the two, to a post-aggregation proto-type embedding. In our work, the typical dimensions areC = 8 32 and Nj = 10, 000 20, 000. The zjWSIdimension is fixed such that a variable-length set of Nj fea-tures can always be represented in fixed-length.To define and estimate the mapping function j, we in-troduce a probabilistic framework for patch embedding dis-tribution and assume each zjn is generated from a GMM,",
  "(2)": "where jc refers to the mixture probability of component cin WSI set j and j refers to the set of parameters to beestimated, i.e., j = {jc, jc, jc}Cc=1. For ease of compu-tation, we use the diagonal covariance jc. Intuitively, Eq. 2 states that a morphological prototype and its variations cor-respond to a mixture component, with jc indicating the ex-tent to which the pattern manifests in the jth WSI.We formulate the slide embedding construction as thatof estimating j from Zj. To this end, we maximize thelog-likelihood (or log-posterior if prior is introduced for j)",
  "Cc=1 j,(t)cN(zjn; j,(t)c, j,(t)c)": "(4)Eq. (4) indicates that a patch is assigned to a certain pro-totype c that is most similar, with the similarity measuredin terms of weighted L2 distance. Moreover, the soft pro-totype assignment, i.e., q(t+1)(cjn = c|zjn) > 0, c, allowseach patch to contribute towards all prototypes, in contrastto hard prototype assignment approaches . . Overview of PANTHER workflow. Whole-slide image (WSI) is segmented and patched into a set of WSI patches. A compressedfeature for each patch is encoded through a feature extractor pretrained on a large histopathology dataset. PANTHER uses the Gaussianmixture model for patch embedding distribution, with each mixture corresponding to a morphologically distinct prototype. The estimatedmodel parameters are concatenated to form the slide representation, which can be used as input to a predictor module for clinical down-stream tasks and visualized as a prototypical assignment map.",
  "Njn=1 qj,(t+1)n,c(5)": "We set j,(0)c= 1/C, j,(0)c= hc, and j,(0)c= I, whichserves as a morphology-aware initialization. Due to its iter-ative nature, EM can be placed as a neural network module.The initialization for {hc}Cc=1 is performed with K-meansclustering on the entire patch training set, constructed byaggregating patch embeddings from all training slides in acohort.Based on the final estimate j after the EM convergence,the slide embedding zjWSI RCM with M = 1 + 2d canbe represented as a concatenation of the elements in j, fol-lowing set representation learning literature ,",
  "We emphasize that while the prototypes {hc}Cc=1 are sharedacross different WSIs, the parameter estimation and the": "slide embedding construction are performed per WSI. Over-all, the embedding zjWSI satisfies two essential principles fora faithful WSI representation and good downstream perfor-mance. First, it accounts for the cardinality of each pro-totype explicitly through jc and implicitly through jc andjc. In addition, by concatenating the features (rather thanaveraging), feature vector for each morphological prototypeis directly accessible for downstream tasks.",
  "Connection to optimal transport": "The aggregation in PANTHER can be seen as matching theempirical distribution of patch embeddings and the proto-types, defined as pj and qj respectively. Specifically, wehave pj = Njn=1 ajn zjnandqj = Cc=1 jc hc, where Njn=1 ajn = Cc=1 jc = 1. OT aggregates {zjn}Njn=1to {hc}Cc=1 by minimizing the Wasserstein distance be-tween pj and qj, typically assuming uniform distributionfor {ajn}Njn=1 and {jc}Cc=1, i.e., ajn = 1/Nj and jc =1/C . While PANTHER also assumes ajn = 1/Nj,the mixture probability jc is estimated (Eq. 5). Further-more, the OT solution can be seen as a special case of GMMsolution with uniform prototype distribution .",
  "where j is dropped for notational simplicity, and gpred. and{gindiv.c}Cc=1 assume one of {Identity, Linear, MLP}. Eq. 7": "leverages that zjWSI, which is a concatenation of mixtureestimates, can be decomposed along each prototype andlearns per-prototype nonlinear mapping gindiv.c. This is notpossible with a typical MIL: First, the large and variablesize of N prohibits the learning of {gindiv.n}Nn=1. Moreover,the permutation invariance makes finding an appropriatefunction gindiv.nfor a given patch embedding zn non-trivial.",
  "cjn = argmaxc q(cjn = c | zjn),(8)": "and overlay the prototype assignments onto WSI, visual-izing how pathology visual concepts are distributed withineach WSI (prototypical assignment map, ), with jcquantifying the extent of the distribution. For a specificprototype c, we can also visualize how morphologicallysimilar each patch embedding is to the prototype usingq(cjn = c | zjn) ().",
  ". Datasets": "Subtyping We evaluate PANTHER on four different subtyp-ing tasks: EBRAINS fine subtyping (30 classes) and coarsesubtyping (12 classes) for rare brain cancer types ,Non-Small Cell Lung Carcinoma (NSCLC) subtyping onTCGA and CPTAC (2 classes), and ISUP grading basedon Prostate cancer grade assessment (PANDA) challenge (6classes) . We use balanced accuracy and weighted F1metrics for evaluation on EBRAINS and NSCLC subtypingtask and Cohens for the ISUP grading task.Survival We evaluate PANTHER on TCGA across severalcancer types: Breast Invasive Carcinoma (BRCA), Colonand Rectum Adenocarcinoma (CRC), Bladder UrothelialCarcinoma (BLCA), Uterine corpus endometrial carcinoma(UCEC), Kidney renal clear cell carcinoma (KIRC), andLung adenocarcinoma (LUAD). For TCGA, we use the 5-fold site-stratified cross-validation. For cancer types withexternal validation datasets (KIRC: CPTAC, LUAD: CP-TAC, NLST), we use the models trained on TCGA and eval-uate on the external dataset. We use the concordance index (c-index) for evaluation. To address the shortcomings ofoverall survival accounting for non-cancerous deaths , we use disease-specific survival (DSS). Additionaldetails can be found in Supplementary Information.",
  ". Baselines": "We employ 1) unsupervised baselines, which use unsuper-vised slide representation followed by the task-specific lin-ear network, and 2) supervised baselines, which constructsupervised slide representation for each task. For the unsu-pervised baselines, we use the following: 1) DeepSets The slide embedding zjWSI Rd is formed by averaging allthe features in the set. 2) ProtoCounts K-meansclustering is performed on the cohort-aggregated set of fea-tures. The slide embedding zjWSI RC is a count vector ofthe number of patches assigned to each cluster. 3) H2T The patch embeddings are clustered and averaged withineach cluster. The averaged cluster centroids are concate-nated, with zjWSI RCd. 4) Optimal Transport (OT) The patch features of a WSI is aggregated to a set of pro-totypes with OT , with zjWSI RCd. OT assumes uni-form mixture probability, i.e., jc = 1/C, c.We also implement the following supervised baselines:Attention-based MIL (ABMIL) , Transformer-basedMIL (TransMIL) , Prototype-clustering based MIL (At-tnMISL) , and low-rank MIL (ILRA) .For PANTHER, we experiment with variations of zjWSI tobetter understand our model: 1) All (original): All mix-ture parameters are concatenated, zjWSI RC(1+2d). 2)Weighted avg. (WA): c and c weighted-averaged by cand concatenated, zjWSI R2d. 3) Top (Bottom): Param-eters for mixture component with the largest (smallest) jcis selected, zjWSI R(1+2d). We use either linear (+lin.) ornonlinear head (+MLP) on top of zjWSI.For the feature extractor fenc(), which is the same forall baselines used in this work, we used UNI , a ViT-L/16 DINOv2 that was pre-trained on a large in-ternal histology dataset of 1 108 patches from 1 106",
  ". Implementation": "WSIs at 20 magnification (0.5 m/pixel) are patched withnon-overlapping patches of 256256 pixels. For each WSI,we use all patches without sampling. We found that a singleEM step is sufficient for convergence. The prototypes H areconstructed from K-means clustering on the set of patchesaggregated from the training cohort (all slides) for each task.The same H is used for AttnMISL, ProtoCounts, H2T, OT,and PANTHER. Additional details on training and loss func-tions can be found in Supplementary Information.",
  ". Subtyping and survival prediction": "Subtyping and survival prediction results are shown in Ta-ble 1 and . Overall, PANTHER consistently outper-forms or is on par with all supervised and unsupervisedbaselines. We highlight key insights and provide hypothe-ses for the high performance of PANTHER.PANTHER vs. supervised MIL PANTHERAll+MLP outper-forms or is on par with the best-performing supervised base-line on subtyping (TransMIL) and survival prediction tasks(mix). With linear probing, PANTHERAll+lin. remains com-petitive against MIL on subtyping and performs better onmost cancer types in survival prediction, demonstrating thestrong representation quality of zjWSI. This is encouraging asPANTHER builds a slide representation in an unsupervisedfashion, unlike MIL which learns a patch aggregation end-to-end with the downstream tasks. Interestingly, despite re-lying on a similar prototype construction as PANTHER, At-tnMISL performs consistently lower than PANTHER.We attribute this difference to AttnMISL averaging the pro-totypes with attention weights, whereas PANTHER buildsa slide embedding by concatenating them. Our baselinePANTHERWA+lin. further confirms this by showing that av-eraging leads to a consistently lower performance.PANTHER vs. unsupervised baselines We observe thatPANTHERAll+MLP outperforms most unsupervised base-lines on subtyping and survival prediction tasks. We at-tribute this gain to two design principles behind PANTHER:(1) prototypes are represented as low-dimensional feature vectors, and (2) the resulting slide embedding encodes thecardinality of each prototype, i.e., their extent in the WSI. Incomparison, ProtoCounts only encodes the count informa-tion, leading to poor performance. Interestingly, DeepSets,which builds slide embeddings as the sum of all patchembeddings, and similarly our baseline PANTHERWA+lin.,which takes weighted averaging of the prototype features,lead to poor subtyping performance despite implicitly en-coding both deep patch representations and cardinality. Wehypothesize that subtyping requires a mechanism to iso-late discriminative information, which can be implementedusing attention (as in ABMIL and TransMIL), or using pro-totype concatenation as in PANTHER.Unsurprisingly, H2T and OT come closest to PANTHERon subtyping tasks as they also aggregate the patchesto the prototypes (albeit with different mechanisms fromPANTHER) and use concatenation. However, on ISUP grad-ing in prostate cancer which is clinically assessed using theprimary and secondary Gleason patterns, PANTHER seessignificant performance increases. Lastly, H2T and OT lackexplicit mechanisms to incorporate cardinality into sliderepresentation, an important feature of PANTHER for inter-pretability (.2).In this context, PANTHER appears as a comprehensiveunsupervised slide representation method that concatenatesdeep prototype representations along with their cardinality.PANTHER ablations We further ablate PANTHER by re-taining only a single component with the highest (low-est) c, i.e., PANTHERTop (PANTHERBot.).We observethat both PANTHERTop and PANTHERBot. performs consis-tently poorly.This reaffirms that capturing morphologi- . Survival prediction Results of PANTHER and baselines for measuring patient disease-specific survival based on c-index. Allmethods use UNI features . Best performance in bold, second best underlined. All models and prototypes are trained on TCGA.AttnMISL, ProtoCounts, H2T, OT, and PANTHER use C = 16 prototypes. Standard deviation (in parentheses) are reported over five runs.",
  "( 0.06)( 0.10)( 0.07)( 0.10)( 0.10)( 0.03)( 0.06)( 0.04)( 0.04)": "cal heterogeneity is crucial for accurate prediction of a pa-tients clinical outcome . That PANTHERBot. is thelowest-performing agrees with our intuition, as subtypesand grades are most often determined by pathologists basedon visual cues that must be integrated across the entirety ofthe tumor, rather than utilizing only a particular region ormorphology within the whole. Interestingly, PANTHERTopperforms relatively well for the NSCLC subtyping task,which we attribute to it being a relatively simple binary clas-sification task and the most populous component (highestc) for the NSCLC WSIs on average being tumor.PANTHER with linear vs. non-linear head In all tasks,PANTHERAll+MLP consistently boosts the performanceover PANTHERAll+lin., demonstrating additional predictivecapability enabled by per-prototype non-linearity modeling.",
  "To understand which prototypes are used in learning sliderepresentations, we visualize (1) the patch-level prototype": "assignments per WSI via probability q(cjn = c | zjn), and(2) the distribution of mixture components jc within andacross all WSIs in the cohort.Overall, we find that GMMs are a simple yet powerfulframework for mapping the spatial organization of histo-logic visual concepts in the tissue microenvironment. Vi-sual assessment by a board-certified pathologist (D.F.K.W.)revealed that prototypical patterns reflect distinct mor-phological phenotypes of tumor-, tumor-associated stro-mal, and immune-cell populations as well as normal tis-sue components (C). In NSCLC, we discover proto-types that correspond to adenocarcinoma (turquoise, C2 andC15) and squamous cell carcinoma (orange, C12) patterns(A,B). Analysis of c shows that these patterns almostexclusively appeared in LUAD and LUSC slides (C).In CRC, the distribution of prototypical patterns had strongconcordance with existing tissue annotations for CRC tis-sue types (CRC-100K) , with further visualizations pre-sented in the Supplementary Information. . Prototype-oriented heatmap interpretation. (A) Examples of WSIs and prototypical assignment maps from LUAD and LUSC,with estimated prototype distribution c for each WSI. (B) Prototype distribution and morphological annotations by a board-certifiedpathologist in the NSCLC cohort. The adenocarcinoma prototypes (C2, C15) and squamous cell carcinoma (C12) appear exclusively inLUAD and LUSC respectively, showing that PANTHER can correctly capture essential morphological cues in the tissue.",
  "We present PANTHER,a prototype-based aggregationframework for learning unsupervised slide representations": "with Gaussian mixtures as the patch distribution. We be-lieve this is an important addition to the emerging group ofslide representation studies, with the unsupervised natureof PANTHER making it readily applicable to diverse tasks.Limitations include using C = 16 for all tasks, which maylead to over- or under-clustering for certain cancers. Futurework includes introducing more expressive mixture modelsfor patch distributions, determining the number of proto-types in a data-driven manner, and evaluating on rare cancercohorts with small sample sizes. Shekoofeh Azizi, Laura Culp, Jan Freyberg, Basil Mustafa,Sebastien Baur, Simon Kornblith, Ting Chen, Nenad Toma-sev, Jovana Mitrovic, Patricia Strachan, et al.Robustand data-efficient generalization of self-supervised machinelearning for diagnostic imaging. Nature Biomedical Engi-neering, pages 124, 2023. 1 Saurav Basu, Soheil Kolouri, and Gustavo K Rohde. De-tecting and visualizing cell phenotype differences from mi-croscopy images using transport-based morphometry. Pro-ceedings of the National Academy of Sciences, 111(9):34483453, 2014. 2 Andrew H Beck, Ankur R Sangoi, Samuel Leung, Robert JMarinelli, Torsten O Nielsen, Marc J Van De Vijver,Robert B West, Matt Van De Rijn, and Daphne Koller. Sys-tematic analysis of breast cancer morphology uncovers stro-mal features associated with survival. Science TranslationalMedicine, 3(108):108ra113108ra113, 2011. 2 Babak Ehteshami Bejnordi, Mitko Veta, Paul JohannesVan Diest, Bram Van Ginneken, Nico Karssemeijer, GeertLitjens, Jeroen AWM Van Der Laak, Meyke Hermsen,Quirine F Manson, Maschenka Balkenhol, et al. Diagnos-tic assessment of deep learning algorithms for detection oflymph node metastases in women with breast cancer. JAMA,318(22):21992210, 2017. 2 Gianpaolo Bontempo, Angelo Porrello, Federico Bolelli, Si-mone Calderara, and Elisa Ficarra.Das-mil: Distillingacross scales for mil classification of histological wsis. InInternational Conference on Medical Image Computing andComputer-Assisted Intervention, pages 248258. Springer,2023. 2",
  "Christian Bueno and Alan Hylton.On the representationpower of set pooling networks. Advances in Neural Infor-mation Processing Systems, 34:1717017182, 2021. 2": "Wouter Bulten, Kimmo Kartasalo, Po-Hsuan Cameron Chen,Peter Strom, Hans Pinckaers, Kunal Nagpal, Yuannan Cai,David F Steiner, Hester van Boven, Robert Vink, et al. Artifi-cial intelligence for diagnosis and gleason grading of prostatecancer: the panda challenge. Nature Medicine, 28(1):154163, 2022. 5, 2 Wouter Bulten, Hans Pinckaers, Hester van Boven, RobertVink, Thomas de Bel, Bram van Ginneken, Jeroen van derLaak, Christina Hulsbergen-van de Kaa, and Geert Lit-jens. Automated deep-learning system for gleason gradingof prostate cancer using biopsies: a diagnostic study. TheLancet Oncology, 21(2):233241, 2020. 5, 2 Charlotte Bunne, Stefan G Stark, Gabriele Gut, Jacobo Sara-bia Del Castillo, Mitch Levesque, Kjong-Van Lehmann, Lu-cas Pelkmans, Andreas Krause, and Gunnar Ratsch. Learn-ing single-cell perturbation responses using neural optimaltransport. Nature methods, pages 110, 2023. 2 Dmitrii Bychkov, Nina Linder, Riku Turkki, Stig Nordling,Panu E Kovanen, Clare Verrill, Margarita Walliander, MikaelLundin, Caj Haglund, and Johan Lundin.Deep learningbased tissue analysis predicts outcome in colorectal cancer.",
  "Scientific Reports, 8(1), 2018. 2": "Juan C Caicedo, Angel Cruz, and Fabio A Gonzalez.Histopathology image classification using bag of featuresand kernel functions. In Artificial Intelligence in Medicine:12th Conference on Artificial Intelligence in Medicine, AIME2009, Verona, Italy, July 18-22, 2009. Proceedings 12, pages126135. Springer, 2009. 3 Gabriele Campanella, Matthew G Hanna, Luke Geneslaw,Allen Miraflor, Vitor Werneck Krauss Silva, Klaus J Busam,Edi Brogi, Victor E Reuter, David S Klimstra, and Thomas JFuchs. Clinical-grade computational pathology using weaklysupervised deep learning on whole slide images.Naturemedicine, 25(8):13011309, 2019. 1, 2 Iain Carmichael, Andrew H Song, Richard J Chen, Drew FKWilliamson, Tiffany Y Chen, and Faisal Mahmood. Incor-porating intratumoral heterogeneity into weakly-superviseddeep learning models via variance pooling. In InternationalConference on Medical Image Computing and Computer-Assisted Intervention, pages 387397. Springer, 2022. 5 Lyndon Chan, Mahdi S Hosseini, Corwyn Rowsell, Kon-stantinos N Plataniotis, and Savvas Damaskinos. Histoseg-net: Semantic segmentation of histological tissue type inwhole slide images. In Proceedings of the IEEE/CVF In-ternational Conference on Computer Vision, pages 1066210671, 2019. 2 Chaofan Chen, Oscar Li, Daniel Tao, Alina Barnett, CynthiaRudin, and Jonathan K Su. This looks like that: deep learn-ing for interpretable image recognition. Advances in neuralinformation processing systems, 32, 2019. 3 Richard J Chen, Chengkuan Chen, Yicong Li, Tiffany YChen, Andrew D Trister, Rahul G Krishnan, and FaisalMahmood. Scaling vision transformers to gigapixel imagesvia hierarchical self-supervised learning. In Proceedings ofthe IEEE/CVF Conference on Computer Vision and PatternRecognition, pages 1614416155, 2022. 1, 2 Richard J. Chen, Tong Ding, Ming Y. Lu, Drew F. K.Williamson, Guillaume Jaume, Andrew H. Song, BowenChen, Andrew Zhang, Daniel Shao, Muhammad Shaban,Mane Williams, Lukas Oldenburg, Luca L. Weishaupt,Judy J. Wang, Anurag Vaidya, Long Phi Le, Georg Ger-ber, Sharifa Sahai, Walt Williams, and Faisal Mahmood. To-wards a general-purpose foundation model for computationalpathology. Nature Medicine, 2024. 1, 3, 5, 6, 7, 2",
  "Marco Cuturi. Sinkhorn distances: Lightspeed computationof optimal transport. Advances in neural information pro-cessing systems, 26, 2013. 2, 4, 5": "Dan dan Guo, Long Tian, Minghe Zhang, Mingyuan Zhou,and Hongyuan Zha. Learning prototype-oriented set repre-sentations for meta-learning. In International Conference onLearning Representations, 2022. 2, 3 Arthur P Dempster, Nan M Laird, and Donald B Rubin.Maximum likelihood from incomplete data via the em al-gorithm. Journal of the royal statistical society: series B(methodological), 39(1):122, 1977. 2, 3, 1 Alexey Dosovitskiy, Lucas Beyer, Alexander Kolesnikov,Dirk Weissenborn, Xiaohua Zhai, Thomas Unterthiner,Mostafa Dehghani, Matthias Minderer, Georg Heigold, Syl-vain Gelly, Jakob Uszkoreit, and Neil Houlsby. An image isworth 16x16 words: Transformers for image recognition atscale. In International Conference on Learning Representa-tions, 2021. 5 M Murat Dundar, Sunil Badve, Vikas C Raykar, Rohit KJain, Olcay Sertel, and Metin N Gurcan. A multiple instancelearning approach toward optimal classification of pathologyslides.In 2010 20th International Conference on PatternRecognition, pages 27322735. IEEE, 2010. 1 Kianoush Falahkheirkhah, Alex Xijie Lu, David Alvarez-Melis, and Grace Huynh.Domain adaptation using op-timal transport for invariant learning using histopathologydatasets. In Medical Imaging with Deep Learning, 2023. 2 Alexandre Filiot, Ridouane Ghermi, Antoine Olivier, PaulJacob, Lucas Fidon, Alice Mac Kain, Charlie Saillard, andJean-Baptiste Schiratti. Scaling self-supervised learning forhistopathology with masked image modeling.medRxiv,pages 202307, 2023. 1 Gemma Gatta, Riccardo Capocaccia, Laura Botta, SandraMallone, Roberta De Angelis, Eva Ardanaz, Harry Comber,Nadya Dimitrova, Maarit K Leinonen, Sabine Siesling, et al.Burden and centralised treatment in europe of rare tumours:results of rarecareneta population-based study. The LancetOncology, 18(8):10221039, 2017. 5 Noriaki Hashimoto, Daisuke Fukushima, Ryoichi Koga,Yusuke Takagi, Kaho Ko, Kei Kohno, Masato Nakaguro,Shigeo Nakamura, Hidekata Hontani, and Ichiro Takeuchi.Multi-scale domain-adversarial multiple-instance cnn forcancer subtype classification with unannotated histopatho-logical images. In Proceedings of the IEEE/CVF conferenceon computer vision and pattern recognition, pages 38523861, 2020. 2 Kaiming He, Xiangyu Zhang, Shaoqing Ren, and Jian Sun.Deep residual learning for image recognition. In Proceed-ings of the IEEE conference on computer vision and patternrecognition, pages 770778, 2016. 5",
  "Andreas Heindl, Sidra Nawaz, and Yinyin Yuan.Map-ping spatial heterogeneity in the tumor microenvironment:a new era for digital pathology. Laboratory investigation,95(4):377384, 2015. 2": "Le Hou, Dimitris Samaras, Tahsin M Kurc, Yi Gao, James EDavis, and Joel H Saltz. Patch-based convolutional neuralnetwork for whole slide tissue image classification. In Pro-ceedings of the IEEE conference on computer vision and pat-tern recognition, pages 24242433, 2016. 3 Wentai Hou, Lequan Yu, Chengxuan Lin, Helong Huang,Rongshan Yu, Jing Qin, and Liansheng Wang. H 2-mil: ex-ploring hierarchical representation with heterogeneous mul-tiple instance learning for whole slide image analysis. In Pro-ceedings of the AAAI conference on artificial intelligence,volume 36, pages 933941, 2022. 2 Frederick M Howard, James Dolezal, Sara Kochanny, Je-free Schulte, Heather Chen, Lara Heij, Dezheng Huo, RitaNanda, Olufunmilayo I Olopade, Jakob N Kather, et al. Theimpact of site-specific digital histology signatures on deeplearning model accuracy and bias. Nature communications,12(1):4423, 2021. 2 Zhi Huang, Federico Bianchi, Mert Yuksekgonul, Thomas JMontine, and James Zou.A visuallanguage foundationmodel for pathology image analysis using medical twitter.Nature medicine, 29(9):23072316, 2023. 1",
  "Maximilian Ilse,Jakub Tomczak,and Max Welling.Attention-based deep multiple instance learning. In Inter-national conference on machine learning, pages 21272136.PMLR, 2018. 1, 2, 5, 6, 7": "Guillaume Jaume, Lukas Oldenburg, Anurag J Vaidya,Richard J Chen, Drew FK Williamson, Thomas Peeters, An-drew H Song, and Faisal Mahmood. Transcriptomics-guidedslide representation learning in computational pathology. InProceedings of the IEEE/CVF Conference on Computer Vi-sion and Pattern Recognition, 2024. 1 Guillaume Jaume, Anurag Vaidya, Richard Chen, DrewWilliamson, Paul Liang, and Faisal Mahmood.Model-ing dense multimodal interactions between biological path-ways and histology for survival prediction. Proceedings ofthe IEEE/CVF Conference on Computer Vision and PatternRecognition (CVPR), 2024. 5 Syed Ashar Javed, Dinkar Juyal, Harshith Padigela, AmaroTaylor-Weiner, Limin Yu, and Aaditya Prakash.Additivemil: intrinsically interpretable multiple instance learning forpathology. Advances in Neural Information Processing Sys-tems, 35:2068920702, 2022. 2 Cheng Jiang, Xinhai Hou, Akhil Kondepudi, Asadur Chow-dury, Christian W Freudiger, Daniel A Orringer, HonglakLee, and Todd C Hollon.Hierarchical discriminativelearning improves visual representations of biomedical mi-croscopy. In Proceedings of the IEEE/CVF Conference onComputer Vision and Pattern Recognition, pages 1979819808, 2023. 1 Shivam Kalra, Hamid R Tizhoosh, Charles Choi, SultaanShah, Phedias Diamandis, Clinton JV Campbell, and LironPantanowitz.Yottixelan image search engine for largearchives of histopathology whole slide images. Medical Im-age Analysis, 65:101757, 2020. 3",
  "and Sergio Pereira.Benchmarking self-supervised learn-ing on diverse pathology datasets.In Proceedings of theIEEE/CVF Conference on Computer Vision and PatternRecognition, pages 33443354, 2023. 1": "JakobNikolasKather,JohannesKrisam,PornpimolCharoentong, Tom Luedde, Esther Herpel, Cleo-Aron Weis,Timo Gaiser, Alexander Marx, Nektarios A Valous, DykeFerber, et al. Predicting survival from colorectal cancer his-tology slides using deep learning: A retrospective multicen-ter study. PLoS Medicine, 16(1), 2019. 2, 7, 3 Jared L Katzman,Uri Shaham,Alexander Cloninger,Jonathan Bates, Tingting Jiang, and Yuval Kluger. Deep-surv: personalized treatment recommender system using acox proportional hazards deep neural network. BMC medi-cal research methodology, 18(1):112, 2018. 2",
  "Minyoung Kim.Differentiable expectation-maximizationfor set representation learning. In International Conferenceon Learning Representations, 2022. 2, 3, 4, 1": "Soheil Kolouri, Se Rim Park, Matthew Thorpe, DejanSlepcev, and Gustavo K. Rohde. Optimal mass transport:Signal processing and machine-learning applications. IEEESignal Processing Magazine, 34(4):4359, 2017. 2 Daisuke Komura, Akihiro Kawabe, Keisuke Fukuta, KyoheiSano, Toshikazu Umezaki, Hirotomo Koda, Ryohei Suzuki,Ken Tominaga, Mieko Ochi, Hiroki Konishi, et al. Universalencoding of pan-cancer histology by deep texture represen-tations. Cell Reports, 38(9), 2022. 3 Tristan Lazard, Marvin Lerousseau, Etienne Decenci`ere, andThomas Walter. Giga-ssl: Self-supervised learning for gi-gapixel images. In Proceedings of the IEEE/CVF Conferenceon Computer Vision and Pattern Recognition, pages 43044313, 2023. 1",
  "Svetlana Lazebnik, Cordelia Schmid, and Jean Ponce.Asparse texture representation using local affine regions. IEEEtransactions on pattern analysis and machine intelligence,27(8):12651278, 2005. 3": "Juho Lee, Yoonho Lee, Jungtaek Kim, Adam Kosiorek, Se-ungjin Choi, and Yee Whye Teh. Set transformer: A frame-work for attention-based permutation-invariant neural net-works.In International conference on machine learning,pages 37443753. PMLR, 2019. 3 Bin Li, Yin Li, and Kevin W Eliceiri. Dual-stream multipleinstance learning network for whole slide image classifica-tion with self-supervised contrastive learning. In Proceed-ings of the IEEE/CVF Conference on Computer Vision andPattern Recognition, pages 1431814328, 2021. 1, 2, 6, 7, 5 Tiancheng Lin, Zhimiao Yu, Hongyu Hu, Yi Xu, and Chang-Wen Chen.Interventional bag multi-instance learning onwhole-slide pathological images.In Proceedings of theIEEE/CVF Conference on Computer Vision and PatternRecognition, pages 1983019839, 2023. 1 Jianfang Liu, Tara Lichtenberg, Katherine A Hoadley,Laila M Poisson, Alexander J Lazar, Andrew D Cherniack,Albert J Kovatich, Christopher C Benz, Douglas A Levine,Adrian V Lee, et al. An integrated TCGA pan-cancer clinicaldata resource to drive high-quality survival outcome analyt-ics. Cell, 173(2):400416, 2018. 5",
  "Odintsov, Long Phi Le, Georg Gerber, et al.A visual-language foundation model for computational pathology.Nature Medicine, pages 112, 2024. 1": "Ming Y Lu, Bowen Chen, Andrew Zhang, Drew FKWilliamson, Richard J Chen, Tong Ding, Long Phi Le, Yung-Sung Chuang, and Faisal Mahmood. Visual language pre-trained multiple instance zero-shot transfer for histopathol-ogy images. In Proceedings of the IEEE/CVF conferenceon computer vision and pattern recognition, pages 1976419775, 2023. 2 Ming Y Lu, Drew FK Williamson, Tiffany Y Chen, Richard JChen, Matteo Barbieri, and Faisal Mahmood. Data-efficientand weakly supervised computational pathology on whole-slide images. Nature biomedical engineering, 5(6):555570,2021. 1, 2 Wenqi Lu, Simon Graham, Mohsin Bilal, Nasir Rajpoot,and Fayyaz Minhas.Capturing cellular topology inmulti-gigapixel pathology images.In Proceedings of theIEEE/CVF Conference on Computer Vision and PatternRecognition Workshops, pages 260261, 2020. 2",
  "Andriy Marusyk, Michalina Janiszewska, and KorneliaPolyak. Intratumor heterogeneity: the rosetta stone of ther-apy resistance. Cancer cell, 37(4):471484, 2020. 7": "Gregoire Mialon, Dexiong Chen, Alexandre dAspremont,and Julien Mairal. A trainable optimal transport embeddingfor feature aggregation and its relationship to attention. In In-ternational Conference on Learning Representations, 2021.2, 3, 4, 5, 6, 7 Pooya Mobadersany,Safoora Yousefi,Mohamed Am-gad, David A Gutman, Jill S Barnholtz-Sloan, Jose EVelazquez Vega, Daniel J Brat, and Lee AD Cooper. Pre-dicting cancer outcomes from histology and genomics us-ing convolutional networks.Proceedings of the NationalAcademy of Sciences, 115(13):E2970E2979, 2018. 2 Maxime Oquab, Timothee Darcet, Theo Moutakanni, Huy V.Vo, Marc Szafraniec, Vasil Khalidov, Pierre Fernandez,Daniel HAZIZA, Francisco Massa, Alaaeldin El-Nouby,Mido Assran, Nicolas Ballas, Wojciech Galuba, RussellHowes, Po-Yao Huang, Shang-Wen Li, Ishan Misra, MichaelRabbat, Vasu Sharma, Gabriel Synnaeve, Hu Xu, Herve Je-gou, Julien Mairal, Patrick Labatut, Armand Joulin, and Pi-otr Bojanowski. DINOv2: Learning robust visual featureswithout supervision. Transactions on Machine Learning Re-search, 2024. 5 Wentao Pan, Jiangpeng Yan, Hanbo Chen, Jiawei Yang, ZheXu, Xiu Li, and Jianhua Yao. Human-machine interactivetissue prototype learning for label-efficient histopathologyimage segmentation.In International Conference on In-formation Processing in Medical Imaging, pages 679691.Springer, 2023. 3 Shraman Pramanick, Li Jing, Sayan Nag, Jiachen Zhu,Hardik J Shah, Yann LeCun, and Rama Chellappa. VoLTA:Vision-language transformer with weakly-supervised local-feature alignment. Transactions on Machine Learning Re-search, 2023. 2 Adalberto Claudio Quiros, Nicolas Coudray, Anna Yeaton,Xinyu Yang, Bojing Liu, Hortense Le, Luis Chiriboga,Afreen Karimkhan, Navneet Narula, David A. Moore,Christopher Y. Park, Harvey Pass, Andre L. Moreira, John LeQuesne, Aristotelis Tsirigos, and Ke Yuan.Mapping thelandscape of histomorphological cancer phenotypes usingself-supervised learning on unlabeled, unannotated pathol-ogy slides, 2023. 1, 3, 5, 6, 7 Thomas Roetzer-Pejrimovsky, Anna-Christina Moser, BaranAtli, Clemens Christian Vogel, Petra A Mercea, Romana Pri-hoda, Ellen Gelpi, Christine Haberler, Romana Hoftberger,Johannes A Hainfellner, et al. The digital brain tumour atlas,an open histopathology resource. Scientific Data, 9(1):55,2022. 5, 2 Joel Saltz, Rajarsi Gupta, Le Hou, Tahsin Kurc, PankajSingh, Vu Nguyen, Dimitris Samaras, Kenneth R Shroyer,Tianhao Zhao, Rebecca Batiste, et al.Spatial organiza-tion and molecular correlation of tumor-infiltrating lympho-cytes using deep learning on pathology images. Cell reports,23(1):181193, 2018. 2 Geoffrey Schiebinger, Jian Shu, Marcin Tabaka, BrianCleary, Vidya Subramanian, Aryeh Solomon, Joshua Gould,Siyan Liu, Stacie Lin, Peter Berube, et al. Optimal-transportanalysis of single-cell gene expression identifies develop-mental trajectories in reprogramming. Cell, 176(4):928943,2019. 2 Zhuchen Shao, Hao Bian, Yang Chen, Yifeng Wang, JianZhang, Xiangyang Ji, et al. Transmil: Transformer basedcorrelated multiple instance learning for whole slide imageclassification. Advances in Neural Information ProcessingSystems, 34:21362147, 2021. 1, 2, 5, 6, 7",
  "Jake Snell, Kevin Swersky, and Richard Zemel. Prototypicalnetworks for few-shot learning. Advances in neural informa-tion processing systems, 30, 2017. 3": "Andrew H Song, Guillaume Jaume, Drew FK Williamson,Ming Y Lu, Anurag Vaidya, Tiffany R Miller, and FaisalMahmood.Artificial intelligence for digital and com-putational pathology.Nature Reviews Bioengineering,1(12):930949, 2023. 1 Wenhao Tang, Sheng Huang, Xiaoxian Zhang, FengtaoZhou, Yi Zhang, and Bo Liu.Multiple instance learningframework with masked hard instance mining for whole slideimage classification. In Proceedings of the IEEE/CVF Inter-national Conference on Computer Vision, pages 40784087,2023. 2 Kevin Thandiackal, Boqi Chen, Pushpak Pati, GuillaumeJaume, Drew FK Williamson, Maria Gabrani, and OrcunGoksel. Differentiable zooming for multiple instance learn-ing on whole-slide images. In European Conference on Com-",
  "Ilio Vitale, Efrat Shema, Sherene Loi, and Lorenzo Gal-luzzi. Intratumoral heterogeneity in cancer progression andresponse to immunotherapy. Nature Medicine, 27(2):212224, 2021. 7": "Quoc Dang Vu, Kashif Rajpoot, Shan E. Ahmed Raza, andNasir Rajpoot. Handcrafted histological transformer (h2t):Unsupervised representation of whole slide images. MedicalImage Analysis, 85:102743, 2023. 1, 3, 5, 6, 7 Tiep Huu Vu, Hojjat Seyed Mousavi, Vishal Monga, GaneshRao, and UK Arvind Rao. Histopathological image classifi-cation using discriminative feature-oriented dictionary learn-ing. IEEE transactions on medical imaging, 35(3):738751,2015. 3 Xiyue Wang, Sen Yang, Jun Zhang, Minghui Wang,Jing Zhang, Wei Yang, Junzhou Huang, and Xiao Han.Transformer-based unsupervised contrastive learning forhistopathological image classification. Medical image anal-ysis, 81:102559, 2022. 1, 5, 2 Jinxi Xiang and Jun Zhang. Exploring low-rank property inmultiple instance learning for whole slide image classifica-tion. In The Eleventh International Conference on LearningRepresentations, 2023. 2, 5, 6, 7 Yingxue Xu and Hao Chen. Multimodal optimal transport-based co-attention transformer with global structure con-sistency for survival prediction.In Proceedings of theIEEE/CVF International Conference on Computer Vision,pages 2124121251, 2023. 2 Yan Xu, Jun-Yan Zhu, Eric Chang, and Zhuowen Tu. Mul-tiple clustered instance learning for histopathology cancerimage classification, segmentation and clustering. In 2012IEEE Conference on Computer Vision and Pattern Recogni-tion, pages 964971. IEEE, 2012. 3 Litao Yang, Deval Mehta, Sidong Liu, Dwarikanath Maha-patra, Antonio Di Ieva, and Zongyuan Ge. TPMIL: Train-able prototype enhanced multiple instance learning for wholeslide image classification. In Medical Imaging with DeepLearning, 2023. 3 Jiawen Yao, Xinliang Zhu, Jitendra Jonnagaddala, NicholasHawkins, and Junzhou Huang. Whole slide images basedcancer survival prediction using attention guided deep mul-tiple instance learning networks. Medical Image Analysis,65:101789, 2020. 2, 3, 5, 6, 7 Hangting Ye, Wei Fan, Xiaozhuang Song, Shun Zheng, HeZhao, Dan dan Guo, and Yi Chang. PTaRL: Prototype-basedtabular representation learning via space calibration. In TheTwelfth International Conference on Learning Representa-tions, 2024. 2 Anna Yeaton, Rahul G Krishnan, Rebecca Mieloszyk, DavidAlvarez-Melis, and Grace Huynh.Hierarchical optimaltransport for comparing histopathology datasets. In MedicalImaging with Deep Learning, 2022. 2 Jin-Gang Yu, Zihao Wu, Yu Ming, Shule Deng, Yuanqing Li,Caifeng Ou, Chunjiang He, Baiye Wang, Pusheng Zhang,and Yu Wang. Prototypical multiple instance learning forpredicting lymph node metastasis of breast cancer fromwhole-slide pathological images. Medical Image Analysis,85:102748, 2023. 3, 5, 6, 7",
  "Manzil Zaheer, Satwik Kottur, Siamak Ravanbakhsh, Barn-abas Poczos, Russ R Salakhutdinov, and Alexander J Smola.Deep sets. Advances in neural information processing sys-tems, 30, 2017. 5, 6, 7": "Hongrun Zhang, Yanda Meng, Yitian Zhao, Yihong Qiao,Xiaoyun Yang, Sarah E Coupland, and Yalin Zheng. Dtfd-mil: Double-tier feature distillation multiple instance learn-ing for histopathology whole slide image classification. InProceedings of the IEEE/CVF Conference on Computer Vi-sion and Pattern Recognition, pages 1880218812, 2022. 2 Jianguo Zhang, Marcin Marszaek, Svetlana Lazebnik, andCordelia Schmid. Local features and kernels for classifica-tion of texture and object categories: A comprehensive study.International journal of computer vision, 73:213238, 2007.3 Xinliang Zhu, Jiawen Yao, Feiyun Zhu, and JunzhouHuang. Wsisa: Making survival prediction from whole slidehistopathological images. In Proceedings of the IEEE/CVFConference on Computer Vision and Pattern Recognition,pages 72347242, 2017. 2",
  "(3)": "This allows us to substitute the problem of maximizing thelog-likelihood with that of maximizing a surrogate function,which in our case is the lower bound given by Jensens in-equality. It can be shown that increasing the lower bound with respect to j leads to monotonically increasing log-likelihood . The optimization of the surrogate func-tion towards maximizing the log-likelihood is often referredto as the Expectation-Maximization (EM) algorithm, whichiteratively alternates between the E-step and the M-step.The surrogate function is comprised of the two terms,Q(j; jold) and H(C; jold), both of which are expectationswith respect to the posterior probability of prototype assign-ment, i.e., q(cjn = c|zjn; jold). In the E-step, we use Bayesrule to compute the posterior probability and consequentlythe expectations,",
  "For training, we use weight decay of 1 105 and AdamWoptimizer with a learning rate of 1 104 with the co-": "sine decay scheduler. For slide classification experiments,we use cross-entropy loss and a maximum of 20 epochswith early stopping if the validation loss does not decreasefor 10 epochs.For the supervised baselines, due to thevariable-length WSI set, we use a batch size of 1 and agradient accumulation of 32 steps. For unsupervised base-lines (including PANTHER), we use a batch size of 32.For survival prediction experiments, we use negative log-likelihood loss (NLL) with a batch size of one patientover 20 epochs for supervised baselines. For unsupervisedbaselines (including PANTHER), we use Cox proportionalhazards loss with a batch size of 64 patients over 50epochs.",
  ". Computational considerations": "Two NVIDIA 3090 GPUs were used for training PANTHER.PANTHER pre-extracts 32,784-dim slide features (16 proto-types 2,049-dim for concatenated c, c, c) for linear orMLP probing, 468 smaller than [15K 1024]-dim patchpatch embeddings used for MIL training. We pre-extractPANTHER features with batch size of 1 (10 WSIs/sec), andcan compress 11K TCGA slides (4 TB) with 1.4 GB.While more prototypes imply more features to concatenate,training a linear classifier with PANTHER features still hasless number of parameters (32,784) than ABMIL (500K).",
  ". Slide classification": "EBRAINS : For fine-grained (30 classes) and coarse-grained (12 classes) brain tumor subtyping tasks, we usedHematoxylin and Eosin (H&E) Formalin-fixed and paraffin-embedded (FFPE) WSIs (n = 2, 319) collected from theUniversity of Vienna.We label-stratify the dataset intotrain/val/test fold of 50:25:25 and use the same fold for boththe fine-grained and coarse-grained subtyping tasks. Perfor-mance was evaluated using balanced accuracy and weightedF1.NSCLC: For the non-small cell lung carcinoma (NSCLC)subtyping task, we use H&E WSIs from TCGA and CP-TAC for classifying lung adenocarcinoma (LUAD) and lungsquamous cell carcinoma (LUSC) cases. The TCGA co-hort contains a total of 1,041 slides (LUAD: 529, LUSC:512) and the CPTAC cohort consists a total of 1,091 slides(LUAD: 578, LUSC: 513). We label-stratify the TCGA co-hort into train/val/test fold of 80:10:10, with CPTAC usedfor external validation. Performance was evaluated usingbalanced accuracy and weighted F1.PANDA :For the ISUP grading task, we usedprostate cancer core needle biopsies (n=10,616) from the Prostate Cancer Grade Assessment (PANDA) challenge.Each biopsy is given an ISUP grade, making this a 6-class classification task. These biopsies are collected fromKarolinska Institute (KRLS) and Radboud University Med-ical Center (RUMC). We label-stratify the PANDA datasetinto train/val/test fold of 80:10:10, with the evaluation per-formed on KRLS and RUMC cohorts separately. Perfor-mance was evaluated using Cohens quadratic weightedKappa 2 metric.",
  ". Survival prediction": "TCGA: We perform site-stratified 5-fold CV evalu-ation on the following cancer types from TCGA: BreastInvasive Carcinoma (BRCA, n=1, 041, WSI=1, 111), Colon and Rectum Adenocarcinoma (CRC, n =566, WSI = 575), Bladder Urothelial Carcinoma (BLCA,n = 373, WSI = 437), Uterine corpus endometrial carci-noma (UCEC, n = 504, WSI = 565), Kidney renal clearcell carcinoma (KIRC, n = 511, WSI = 517), and Lungadenocarcinoma (LUAD, n = 456, WSI = 1, 024). Thetrain/val split is performed on the patient level.External dataset (CPTAC, NLST): Using the modelstrained on TCGA cohort, we perform external validation onKIRC (CPTAC: n = 180, WSI = 341) and LUAD (CP-TAC: n = 185, WSI = 486, NLST: n = 244, WSI = 686).We note that evaluation on CPTAC and NLST is much moredifficult due to dataset shifts in image acquisition (differ-ences in H&E stain variability), geographic location anddemographics (social determinants of health affecting ac-cess to healthcare), and other potential biases (differences infollow-up procedures between TCGA and CPTAC/NLST).",
  ". Additional experiments": "Ablation over different feature encoders: We evaluatePANTHER, which relied on features extracted with ViT-L/16 DINOv2 pre-trained on a large internal histologydataset (UNI) , with other baselines using features ex-tracted from 1) CTransPath encoder , which is a SwinTransformer pretrained on 29,753 WSIs from TCGA and2,457 WSIs from the Pathology AI Platform (PAIP), and2) ResNet50 encoder pretrained on natural images (Ima-geNet) . The results can be found in Table S1.Ablation over a different number of clusters C: We eval-uate how PANTHER and other baselines (AttnMISL, Pro-toCounts, H2T, and OT) that depend on the number ofprototypes C perform across different choices. We reportboth the classification and survival prediction results forC = {8, 16, 32} in Table S2.Ablation over different survival loss functions: For sur-vival prediction tasks, we also train our unsupervised base-lines with 1) the negative log-likelihood (NLL) loss and 2) the ranking loss . These survival loss functionshave been frequently used as alternatives to the Cox loss in survival analysis problems, especially in medical imag-ing literature. To maintain consistency with the Cox lossexperimental setting, we use a batch size of 64 for trainingwith the NLL and ranking loss. The results can be found inTable S3, where we include the supervised baseline resultswith NLL loss for completeness.Evaluation was performed on several representative clas-sification and survival tasks: EBRAINS (challenging diffi-culty), PANDA (depends on understanding mixture propor-tions of tissue patterns), CRC survival prediction (tissue canbe annotated using CRC-100K ), and LUAD survivalprediction (assessing out-of-domain generalization).",
  ". Results, interpretation, and insights": "Stronger feature encoders improve supervised MILbaselines:We observe consistent trends that strongerfeature encoders improve slide-level tasks, with mod-els trained using UNI reaching the best performance(Table S1). Across all MIL architectures and in all clas-sification tasks (except for DSMIL on RUMC evaluationin PANDA), UNI consistently outperforms ResNet-50 andCTransPath in head-to-head comparisons.On survivaltasks, we note that CTransPath was additionally pretrainedon TCGA, which may produce optimistic bias in evaluation.However, we find that UNI still outperforms CTransPathon TCGA-CRC and TCGA-LUAD survival predictionacross many architectures. Interestingly, AttnMISL, whichgenerally underperformed against ABMIL and TransMILusing ResNet-50 features, becomes one of the top-rankedMIL models in survival tasks when using UNI features(second-highest c-index in CRC survival prediction, andthe highest c-index in LUAD survival prediction on theTCGA and NLST cohorts). This can be attributed to theprototypical formulation of AttnMISL, which dependson the representation quality of the data centroids forprototypical pooling, which would improve with strongerfeature encoders. Stronger feature encoders enable unsupervised base-lines to compete with MIL: Similar to MIL methods,PANTHER and other unsupervised slide representationmethods have consistent improvement using UNI overResNet-50 and CTransPath (aside from evaluation onPANDAandevaluationusingDeepSets/ProtoCounts,Table S1). Interestingly, we note that OT and PANTHERusing CTransPath features significantly underperformsagainst many weakly-supervised baselines (0.377 / 0.369/ 0.518 balanced accuracies comparing OT, PANTHER,ABMIL respectively on EBRAINS; 0.677 / 0.782 / 0.9012 comparing OT, PANTHER, ABMIL respectively onPANDA-KRLS). When using a stronger feature encodersuch as UNI, unsupervised slide representation methodshave significant gains and consequently outperform AB-",
  "MIL and other MIL baselines. As in the case of AttnMISL,this can be attributed to the need for strong pretrainedencoders that are able to retrieve similar patch embeddingsfor prototypical pooling": "PANTHER trains stable survival models:Across allevaluation settings (different number of prototypes Cand survival loss functions), we find that PANTHER isable to develop high-performing survival models without-of-domain generalization (Table S2 and S3). In CRCsurvival prediction, PANTHERAll+MLP consistently out-performs all cluster-based methods within each setting. Incomparison to MIL, though PANTHERAll+MLP with C=16has lower c-index than TransMIL (0.684), we note thatPANTHERAll+MLP with C=8 reaches higher performance(0.691). In LUAD survival prediction, PANTHERAll+MLPis consistently the second best-performing model on TCGAevaluation, behind OT (best c-index of 0.715 of withC=8). Though many baselines such as OT, H2T, and evenDeepSets can reach strong performance on TCGA, we notethat almost all of these methods have unstable performanceon external cohorts, with c-index falling under 0.5 onCPTAC, NLST, or both. PANTHER prototypes capture distinct tumor morpholo-gies: In Fig. S1, S2, andS3, we visualize prototypicalassignment maps and heatmap visualizations of variouscancer types.Consistent with our findings in ,PANTHER is able to map the spatial organization of histo-logic visual concepts. In particular, PANTHER finds severalunique tumor populations, delineating:tumor-invadingmuscle and tumor with immune infiltration in BLCA,nested tumor and tumor-associated connective tissue inBRCA, and clear cell RCC with and without presentationof poorly-differentiated glands in KIRC. Furthermore,we also show concordance of our visualizations using asupervised classifier (developed using patch-level tumorannotations in the TCGA Uniform Tumor dataset )for tumor tissue classification.Visualizing the posteriorprobability heatmap of the tumor prototype with the highestmixture probability c (greatest presence), we find thatour tumor heatmap visualizations have strong concordancewith those generated based on the results from supervisedclassifiers. PANTHER prototypes capture distribution of tissueclasses in CRC-100K: In Fig. S4, we visualize prototyp-ical assignment maps and their correspondence to diversetissue annotations in COADREAD tissue. Using the CRC-100K dataset (containing 9 tissue classes) , we devel-oped a supervised patch-level classifier to predict tissue as-signments for all patches in TCGA-COADREAD slides. Tomatch the prototypical assignment maps from PANTHER with the label distribution in CRC-100K, we applied theprevious classifier to the learned prototypes of PANTHER,to predict CRC-100K tissue labels. Overall, we find that thelearned prototypes of PANTHER have strong concordancewith morphologically-relevant and diverse histopathologytissue patterns annotated by supervised classifiers. Table S1. Varying pretrained feature extractors. We compare the performance of supervised (top) and unsupervised (bottom) meth-ods with different pretrained encoders, ResNet50 with ImageNet transfer (RN50), CTransPath (CTP), and UNI, on classification tasks(EBRAINS and PANDA) and survival tasks (CRC and LUAD).",
  "Unsup. (UNI)": "DeepSets 0.0330.073< 0< 00.563 0.100.652 0.050.550 0.010.509 0.04ProtoCounts 0.0380.018< 00.130.552 0.060.460 0.110.577 0.110.500 0.01H2T 0.1170.2230.4570.7550.639 0.110.662 0.090.583 0.030.603 0.04OT 0.7000.7560.8170.8830.622 0.090.687 0.080.641 0.020.495 0.04PANTHERWA + lin.0.4970.5980.6630.7870.647 0.120.654 0.070.461 0.010.482 0.06PANTHERAll + lin.0.6910.7560.8660.9090.645 0.070.672 0.060.568 0.050.623 0.07PANTHERAll + MLP0.6930.7600.9230.9310.665 0.100.685 0.060.653 0.040.634 0.04 Table S2. Varying C in cluster-based methods. We compare the performance of cluster-based methods with C = {8, 16, 32} onclassification tasks (EBRAINS and PANDA) and survival tasks (CRC and LUAD). Top. MIL baselines with no clustering (NC). Bottom.Cluster-based methods with C = {8, 16, 32}, which include weakly-supervised MIL (AttnMISL) and unsupervised slide representationlearning approaches (ProtoCounts, H2T, OT, PANTHER).",
  "C=32": "AttnMISL 0.4920.5980.9010.8890.572 0.100.666 0.060.591 0.030.587 0.02ProtoCounts 0.0730.1050.3010.540.578 0.090.498 0.140.566 0.120.529 0.09H2T 0.2440.3630.6260.7790.621 0.120.665 0.050.599 0.040.650 0.03OT 0.6870.7460.8410.8980.605 0.000.689 0.080.664 0.020.518 0.04PANTHERWA + lin.0.4890.5930.6700.7820.606 0.110.677 0.060.522 0.010.469 0.06PANTHERAll + lin.0.6760.7510.8830.8960.649 0.070.677 0.060.583 0.060.594 0.05PANTHERAll + MLP0.6740.7410.9350.9310.656 0.130.676 0.040.665 0.060.614 0.05 Table S3. Varying loss function in survival tasks. We compare the performance of all methods with different loss functions, NLL (top),ranking (middle), and Cox loss (bottom), on survival outcome prediction in CRC and LUAD.",
  "Unsup. (Cox)": "DeepSets 0.563 0.100.652 0.050.550 0.010.509 0.04ProtoCounts 0.552 0.060.460 0.110.577 0.110.500 0.01H2T 0.639 0.110.662 0.090.583 0.030.603 0.04OT 0.622 0.090.687 0.080.641 0.020.495 0.04PANTHERWA + lin.0.647 0.120.654 0.070.461 0.010.482 0.06PANTHERAll + lin.0.645 0.070.672 0.060.568 0.050.623 0.07PANTHERAll + MLP0.665 0.100.685 0.060.653 0.040.634 0.04 Figure S1. Prototype-oriented heatmap interpretation of BLCA. (A) Visualization of prototypical assignment map in an exemplarBLCA H&E WSI, with zoomed-in histopathology ROI of tumor-invading muscle (C2, C8, C11, C16). We show the posterior probabilityheatmap for the tumor-containing C2 prototype, which has strong concordance with a tumor probability heatmap obtained by a supervisedpatch-level classifier for BLCA tumor prediction. (B) Prototype distribution c of the exemplar slide. (C) Morphological annotations ofall prototypes by a board-certified pathologist in the BLCA cohort. Figure S2. Prototype-oriented heatmap interpretation of BRCA. (A) Visualization of prototypical assignment map in an exemplarBRCA H&E WSI, with zoomed-in histopathology ROI of dense tumor nests (C16) with surrounding connective tissue (C10), adiposetissue (C9) with tumor presence (C3). We show the posterior probability heatmap for the tumor-containing C16 prototype, which hasstrong concordance with a tumor probability heatmap obtained by a supervised patch-level classifier for BRCA tumor prediction. (B)Prototype distribution c of the exemplar slide. (C) Morphological annotations of all prototypes by a board-certified pathologist in theBRCA cohort. Figure S3. Prototype-oriented heatmap interpretation of KIRC. (A) Visualization of prototypical assignment map in an exemplarKIRC/CCRCC H&E WSI, with zoomed-in histopathology ROI of CCRCC in small-to-medium glands (C7, C10, C13). We show theposterior probability heatmap for the tumor-containing C7 prototype, which has strong concordance with a tumor probability heatmapobtained by a supervised patch-level classifier for CCRCC tumor prediction. (B) Prototype distribution c of the exemplar slide. (C)Morphological annotations of all prototypes by a board-certified pathologist in the KIRC cohort. Figure S4. Prototype-oriented heatmap interpretation of COADREAD and correspondence with CRC-100K. For exemplar COAD-READ slides, we visualize their prototypical assignment maps and their correspondence with tissue classes in CRC-100K. Using a su-pervised patch-level classifier for predicting the 9 tissue classes in CRC-100K, we predicted tissue classes in TCGA-COADREAD slides,shown in the far-right column. To match the prototypical assignment maps from PANTHER with the label distribution in CRC-100K, weapplied the same classifier to predict CRC-100K tissue labels for the learned prototypes in PANTHER (middle-right column). Across all 9classes, we find that PANTHERs prototypes correspond to morphologically-relevant and semantic histopathology tissue patterns annotatedby supervised classifiers."
}