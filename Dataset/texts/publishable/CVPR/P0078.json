{
  "Abstract": "One persistent obstacle in industrial quality inspectionis the detection of anomalies. In real-world use cases, twoproblems must be addressed: anomalous data is sparseand the same types of anomalies need to be detected onpreviously unseen objects. Current anomaly detection ap-proaches can be trained with sparse nominal data, whereasdomain generalization approaches enable detecting objectsin previously unseen domains. Utilizing those two obser-vations, we introduce the hybrid task of domain general-ization on sparse classes.To introduce an accompany-ing dataset for this task, we present a modification of thewell-established MVTec AD dataset by generating threenew datasets. In addition to applying existing methods forbenchmark, we design two embedding-based approaches,Spatial Embedding MLP (SEMLP) and Labeled PatchCore.Overall, SEMLP achieves the best performance with an av-erage image-level AUROC of 87.2 % vs. 80.4 % by MIRO.The new and openly available datasets allow for further re-search to improve industrial anomaly detection.",
  ". Introduction": "In industrial environments, machine-made components aresusceptible to flaws and necessitate inspection before ship-ping. Typically, this task is performed manually by humanoperators who visually inspect each component. However,as with any repetitive task, human fatigue can lead to errorsand the potential oversight of faulty components. Addition-ally, humans tend to judge anomalies inconsistently, withsome being more stringent than others. Consequently, thereis a growing interest in applying computer vision models to automate this process in a cost-effective manner while alsoreducing errors.However,applyingconventionalclassificationap-proaches to this task introduces new challenges.First,anomalies may be rare, making it difficult to collect a suffi-cient number of images for training. Second, not all pos-sible types of anomalies may be known a priori, requir-ing models to be able to detect previously unseen anomalytypes akin to humans capabilities. To address these chal-lenges, anomaly detection methods were developed that canbe trained effectively with limited training data. The ad-vancement of robust anomaly detection models remains asubject of active research interest.For a comprehensiveoverview of industrial image anomaly detection, readers aredirected to the reviews: .Existing approaches have demonstrated the capacity toachieve near-perfect results on existing benchmark datasets. However, they are limited to detect anomalies,but cannot predict the type of the anomaly. In certain ap-plications, there may be a necessity to differentiate betweenvarious types of anomalies in order to manage them accord-ingly. For instance, while some anomalies may be severe,others may be acceptable for a particular use case, such ascolor stains or flipped objects.Another issue is that in certain industrial contexts, a com-pany may produce a multitude of different objects .Collecting sufficient data for all potential objects, even if itis merely normal images, would require a lot of time and re-sources. It would be beneficial if one could reuse a trainedanomaly detection model for new objects. In addition tofrom the work presented in , which have their owndisadvantages, it is unclear whether existing anomaly detec-tion models can be applied to previously unseen domainswithout retraining them. For future applications, models",
  "We create three new datasets for this task, which are basedon the popular MVTec Anomaly Detection dataset": "We present two new methods which provide benchmarkson the the task on the modified MVTec datasets: LabeledPatchCore and Spatial Embedding MLP (SEMLP).The paper is organized as follows: We commence witha review of related work (). Subsequently, we de-tail the process of dataset generation and introduce the newmethods, Labeled PatchCore and SEMLP (). Fol-lowing this, specifies the conducted experimentsand presents the results. Finally, we draw conclusions (Sec-tion 5).",
  ". Anomaly Detection": "There are many different approaches to solve visualanomaly detection tasks on a single object using only nor-mal images. We will present the two most common types ofanomaly detection approaches in the first two paragraphs,representation-based and reconstruction-based ones, fol-lowed by some more exotic approaches.Representation-based approaches use a backbone modellike ResNet or one of its many extensions (e.g. ) to create embeddings for single patches of the input im-age by extracting the outputs of intermediate layers. Thesepatches can be used to learn a representation of normalpatches. For example PaDiM estimates their distri-bution and reports out-of-distribution test embeddings asanomalous. PatchCore creates a coreset which storesthe embeddings of normal patches and uses the distance be-tween test embeddings and the coreset as anomaly score.Reconstruction-based approaches train a model to recon-struct normal images, e.g. a (variational) autoencoder orgenerative adversarial network .Since anomaliesare not present in the training data, it can be assumed, thatthese models fail to reconstruct anomalous areas. Hence, apixel-based reconstruction error measure can be used as ananomaly score. Another approach, that does not fit into the categoriesabove, is , which creates artificial anomalies to train aCNN as binary classifier, or few-shot anomaly detection ap-proaches.Due to their simplicity, we will focus on representation-based approaches, especially PatchCore, which reportsgreat results in the literature.",
  ". Domain Generalization": "Inspired by the fact that the domain of the dataset does notnecessarily match the domains during the real-world usage,many papers have explored the problem of domain gener-alization , where the domains of the training and testdataset differ. One common scenario is an autonomous carwhich must be able to detect and classify objects under allpossible combinations of weather and environment condi-tions like illumination, fog, rain and snow .Cha et al. proposes an approach called MIRO whichapplies a regularization loss while training a feature ex-tractor. It uses a pre-trained model that has already seenmany different types of images and applies an advancedfine-tuning. We will use this approach as one of the base-lines.A first step towards domain generalization on the MVTecdataset is shown by Chen et al. . It uses normal andanomalous images for training. But it has some limitationssuch as requiring normal images from the target domainduring test time and only working on texture categories.Huang et al. also explores anomaly detection ina domain generalization setting: While many approachestrain their models for only a single category at a time, thisapproach trains a category-agnostic model with a few im-ages from multiple categories. It can detect anomalies onnew categories without requiring any retraining. However,it still needs some normal images from the new categoryduring testing.",
  ". Dataset": "The MVTec Anomaly Detection dataset introducedin 2019 is widely used in anomaly detection papers and quickly became a common bench-mark dataset. It contains 15 different categories of which 10are single objects and 5 textured surfaces. It covers dozensof different anomaly types for which it provides pixel-wisesegmentation maps. Newer approaches already re-port nearly perfect results for classification and segmenta-tion on it.A dataset used for domain generalization is PACS ,whose name is based on its 4 domains: photos, art paintings,cartoons, and sketches. It contains 7 different categories anda total of 9991 images.Cao et al. recently tried to adapt different datasets foranomaly detection with out-of-distribution test data. The PACS dataset is adapted for the anomaly detection part bydefining one class as normal and all others as anomalous.The same is done for the MNIST dataset, where the imagesfrom the MNIST-M dataset are used as an additional do-main. As for the MVTec dataset, new domains are createdby augmenting the images.The new adapted datasets are a good first step towardsdomain generalization in anomaly detection, but as for thePACS and MNIST adaption, they use completely differentobjects as anomalies whereas anomalies are usually onlysmall flaws on the normal object. The anomalous images ofthe MVTec adaption are out-of-distribution as advertised,but consist of only slight augmentations of the same object.None of these datasets allow to test the detection of smallflaws on completely different objects.",
  ". Methods": "First, we create our new datasets by modifying the MVTecAD dataset. Then, we introduce two new approaches asbaselines: i) we extend PatchCore by introducing multipleCorests, which we refer to as Labeled PatchCore, and ii) weapply a regular MLP to the embeddings used by PatchCore(Spatial Embedding MLP). The method is called spatial em-bedding, because the embeddings are extracted from visionML models such as Transformers and CNNs where the em-beddings contain spatially related information in contrast toMLPs.",
  ". Generation of new datasets": "For our task, we want to propose a dataset which containsmultiple objects with similar anomalies. This would allowus to treat each object type (category) as another domain,so that we can train the detection of a specific anomalyon some of the categories and test it on previously unseencategories. As shown in .3, none of the existingdatasets satisfies our requirements. Therefore, three newdatasets for domain generalized anomaly detection are cre-ated based on the MVTec AD dataset .For the first step, we look at all anomalies from all cate-gories and determine which anomalies look similar. For ex-ample, the five categories (cable, carpet, hazelnut, leather& wood) have anomaly types called either hole or poke,which we deem similar looking.In the next step, we create a dataset based on the cate-gories containing these similar anomaly types. We use theirgood images and the anomalous images from said anomalytype. In our example, we would use the normal images fromthe previously mentioned categories (cable, carpet, hazel-nut, leather & wood) as well as the hole or poke anomalyimages from these objects. We use all those images to createa new dataset called hole.The same procedure is applied to create two moredatasets, that we refer to as cut and color. Hence, we gener- . SEMLP passes the input image to a backbone. The inter-mediate features are extracted and concatenated to create embed-dings. Each embedding is passed to an MLP which will classifysingle embeddings as normal or anomalous. The image is consid-ered anomalous if at least one embedding is classified as anoma-lous. ate the three datasets: hole, cut and color. Details regardingthe exact object and corresponding anomaly types are listedfor all three datasets in . To illustrate the objects andanomalies, example images are provided in the appendix().",
  ". Extension of PatchCore: Labeled PatchCore": "Since we now have anomalous images available from thetraining domains, we aim to extend the idea of PatchCore to improve classification by correctly identifying thetype of the anomaly. PatchCore collects all good embed-dings in a coreset. We leverage the additional informationfrom anomalous images by creating a second coreset for theembeddings from anomalous image parts (i.e. an anomalycoreset). The second coreset can be used to improve theresults. More details can be found in Section A.1.",
  ". Simplified Approach: Spatial Embedding MLP": "Instead of explicitly providing structure to the classifica-tion process by measuring the distances between the em-beddings, we now analyze the capabilities of MLPs to di-rectly classify the embeddings. For this approach, we ex-tract embeddings, just like described above for the LabeledPatchCore. The embeddings are used as inputs to train smallMLPs (about 49k trainable parameters), which are supposedto classify all single embeddings as good or anomalous. Wecall this approach Spatial Embedding MLP (SEMLP). Fig-ure 1 visualizes the classification flow.Training on patches gives us the advantage of having alot more training data: While some anomaly classes containless than a dozen images, we get a multitude of input databy training on patch embeddings. Even classes with only afew images have now about one hundred embeddings, someeven over a thousand. . This table shows how anomaly types across different categories are merged into one dataset. Each category is treated as its owndomain. For example the categories cable, carpet, hazelnut, leather & wood have similar looking anomaly types called hole or poke whichare used to create a new dataset called hole (left column).",
  ". Setup": "To evaluate our proposed models as well as the baselinesat detecting anomalies across different categories, we al-ways choose one category from the dataset as target domainand use the other ones as source domains for training. Theanomalous images of the source domains are split evenlyinto training and validation set, whereas we use all anoma-lous images from the target domain for testing.AsbackbonemodelsforSEMLP,weuseWide-ResNet50-2 and Vision Transformers (ViT). Detailscan be found in Section A.2.1. We compare the methods toPatchCore (cf. Section A.2.2 and MIRO . For MIRO, wecontinue training on the pre-trained Wide-ResNet50-2 andViT respectively. We report those results as plain MIRO.Furthermore, we use the adjusted models as backbones toextract embeddings for SEMLP and PatchCore (which wereport as SEMLP (MIRO) and PatchCore (MIRO)).",
  ". Results": "To evaluate the performance of the tested models and allowfor comparison runs, we provide the resulting image-levelAUROC for Wide-Resnet50-2 and Vision Transformer asbackbones in . More detailed results for the image-level AUROC and F1-Score can be found in the appendix inTables 3 to 5. As we can see, SEMLP achieves an image-level AUROC of 87.2 % with the WideResNet backboneand is already nearly perfect on many categories. Usingthe trained models from MIRO as backbones for SEMLPdoes not work better then regular backbones pretrained onImageNet.Even though SEMLP achieves good average perfor-mances, SEMLP fails pretty badly on some categories (likethe pill in the color dataset or the cable in the hole dataset),even though other methods perform well. Future work can identify the reasons, potential limitations and provide im-provement strategies to increase the generalization perfor-mance. Plain MIRO seems to be the second best approach,followed by plain PatchCore, which is better than our La-beled PatchCore approach. Providing the additional struc-ture in our way is not helpful to improve the performance ofPatchCore. It would be interesting to study if other modifi-cations can further increase the performance of PatchCore.Furthermore, the anomaly scores of some target domainsare significantly higher than for the source domains. Butsince the anomalous images usually have an even higherscore, there still exists a good threshold in most cases.Even though our approaches require no data from the tar-get domain to train the models, one limitation of our methodis the need for normal and anomalous images from the tar-get domain to determine a good threshold.",
  ". Conclusion": "We presented a new task on domain generalization of sparseanomalous classes.To conduct this task, we introducedthree new datasets based on the MVTec AD dataset to com-pare different anomaly detection models on domain gener-alization tasks.We presented first baselines on these datasets, coveringsome existing models and introducing two new approaches.One of this is SEMLP which classifies single embeddingsand requires only a few labeled training images. The newmodel can distinguish normal and anomalous data in mostcases and achieves an image AUROC of 87.2 %, which isbetter than MIRO. Notably SEMLP outperforms PatchCoreand also Labeled PatchCore. Apparently providing addi-tional structure by introducing the labeled coresets hindersprediction and it is beneficial to purely rely on the predictiveperformance of MLPs.Even though our approach does not require largeamounts of data, we still need some labeled images of the",
  "CutColorHoleAvg.CutColorHoleAvg": "SEMLP92.8 2.582.9 2.187.6 2.587.285.7 3.985.7 1.489.0 3.286.7PatchCore71.1 3.066.4 10.879.8 12.171.767.6 4.857.7 8.964.0 4.662.5Labeled PatchCore47.3 2.348.4 3.946.2 2.247.447.7 2.156.8 2.048.7 1.551.7MIRO87.0 2.871.5 4.286.9 2.380.475.9 8.275.4 5.179.1 4.376.6SEMLP (MIRO)92.0 3.181.1 0.887.6 1.886.277.4 5.880.0 5.179.3 7.479.0PatchCore (MIRO)67.6 0.569.5 3.073.9 4.470.268.1 1.980.9 7.571.7 4.074.4 new domain to determine a good threshold. Although athreshold can be easily set by the user, future work mayfocus on eliminating this need by finding a good thresh-old. Nevertheless, SEMLP shows potential for real-worldapplications. Especially the opportunity of detecting knownanomalies can be advantageous for industrial applications.",
  "Samet Akcay, Dick Ameln, Ashwin Vaidya, BarathLakshmanan, Nilesh Ahuja, and Utku Genc. Anoma-lib: A Deep Learning Library for Anomaly Detection,2022. arXiv:2202.08341 [cs]. 8": "Paul Bergmann, Michael Fauser, David Sattlegger,and Carsten Steger. MVTec AD A Comprehen-sive Real-World Dataset for Unsupervised AnomalyDetection. In 2019 IEEE/CVF Conference on Com-puter Vision and Pattern Recognition (CVPR), pages95849592, 2019. ISSN: 2575-7075. 2, 3, 9 Paul Bergmann, Kilian Batzner, Michael Fauser,David Sattlegger, and Carsten Steger.The MVTecAnomaly Detection Dataset: A Comprehensive Real-World Dataset for Unsupervised Anomaly Detection.International Journal of Computer Vision, 129(4):10381059, 2021. 2, 3, 9",
  "Ning Li, Kaitao Jiang, Zhiheng Ma, Xing Wei, Xi-aopeng Hong, and Yihong Gong. Anomaly Detectionvia Self-organizing Map, 2021.arXiv:2107.09903[cs]. 2": "Jiaqi Liu, Guoyang Xie, Jinbao Wang, ShangnianLi, Chengjie Wang, Feng Zheng, and Yaochu Jin.Deep Industrial Image Anomaly Detection: A Survey.Machine Intelligence Research, 21(1):104135, 2024.arXiv:2301.11514 [cs]. 1, 2 Adam Paszke, Sam Gross, Francisco Massa, AdamLerer, James Bradbury, Gregory Chanan, TrevorKilleen,Zeming Lin,Natalia Gimelshein,LucaAntiga, Alban Desmaison, Andreas Kopf, EdwardYang, Zachary DeVito, Martin Raison, Alykhan Te-jani, Sasank Chilamkurthy, Benoit Steiner, Lu Fang,Junjie Bai, and Soumith Chintala. PyTorch: An Im-perative Style, High-Performance Deep Learning Li-brary.In Advances in Neural Information Process-ing Systems 32, pages 80248035. Curran Associates,Inc., 2019. 8",
  "Karsten Roth, Latha Pemula, Joaquin Zepeda, Bern-hard Scholkopf, Thomas Brox, and Peter Gehler. To-wards Total Recall in Industrial Anomaly Detection,2022. arXiv:2106.08265 [cs]. 1, 2, 3, 7, 8": "Thomas Schlegl, Philipp Seebock, Sebastian M. Wald-stein, Ursula Schmidt-Erfurth, and Georg Langs. Un-supervised Anomaly Detection with Generative Ad-versarial Networks to Guide Marker Discovery, 2017.arXiv:1703.05921 [cs]. 2 Xian Tao, Xinyi Gong, Xin Zhang, Shaohua Yan, andChandranath Adak. Deep Learning for UnsupervisedAnomaly Localization in Industrial Images: A Survey.IEEE Transactions on Instrumentation and Measure-ment, 71:121, 2022. Conference Name: IEEE Trans-actions on Instrumentation and Measurement. 1",
  "Kaiyang Zhou, Ziwei Liu, Yu Qiao, Tao Xiang, andChen Change Loy. Domain Generalization: A Survey.IEEE Transactions on Pattern Analysis and MachineIntelligence, pages 120, 2022.arXiv:2103.02503[cs]. 2": ".Classification using multiple coresets in a two-dimensional scenario: yellow is the coreset containing embed-dings of good images and green the coreset with anomalous em-beddings. The red circle will be classified based on its distance tothe next embedding of each coreset (d0 and d1), after weightingthe distances to the next neighbors in their respective coreset likein Roth et al. (dotted lines).",
  "A.1. Labeled PatchCore": "This section provides a more in-depth description of our La-beled PatchCore approach.Since anomalous images also contain normal areas, wewill only consider patches of the anomaly itself for ouranomaly coreset. Depending on the original resolution andchosen backbone, a single patch contains roughly 1024(32x32) pixels of the original image. Therefore, we con-sider patches anomalous, if at least a tenth of the pixelsare anomalous. This way, we obtain a sufficient share ofanomalous patches for our anomaly coreset, without consid-ering patches anomalous that just have one or two anoma-lous pixels. The good patches from anomalous images arediscarded because there are already enough good patchesfrom the normal images.Then, we add the embeddings of these patches (alsocalled locally aware patch features in ) to the memorybank of the anomaly coreset. Because of the limited num-ber of anomalous images and patches, we always keep atleast 1,000 embeddings for the anomaly coreset when sub-sampling or use all embeddings if necessary, regardless ofthe given coreset subsampling ratio.To classify an image, we extract the embeddings for eachpatch. Then, we classify each embedding based on whetherthey are closer to the normal or anomalous coreset. Wehope that the second coreset provides more information anda better structure to differentiate the anomalies from normalpatches.To do so, we calculate the weighted anomaly score for each embedding like the original implementation (see sec-tion 3.3 in Roth et al. ) but in relation to each of the twocoresets (as shown in for a two-dimensional exam-ple). In other words, each embedding is classified by cal-culating the distance di to the next embedding mi for eachcoreset Mi. The distances are weighted with the nearestneighbors of mi in its coreset to get score si (see Equation7 in ). Afterwards, we classify each patch as belongingto the coreset Mi with the smallest score si, i.e. the coresetto which the embedding is closest after weighting.The process is repeated for all patches of the images. Ifall patches are classified as good, the image is deemed asnormal. Otherwise it is considered anomalous.",
  "A.2.1Backbone models": "Similar to Roth et al. , we use Wide-ResNet50-2 asbackbone for all our tasks and use the features of the sec-ond and third block to create our embeddings. Since VisionTransformers (ViT) have recently gained popularity in com-puter vision, we also test a ViT as backbone. In this case,we use the base variant as presented in Dosovitskiy et al. with a patch size of 8. Here, we extract the features af-ter the layers 5 and 9. We use pre-trained weights providedby Wightman for all backbones.",
  "A.2.2Details on the application of the specific ap-proaches": "Unless otherwise mentioned, the SEMLP has two fully-connected layers with a hidden size of 32 and a leaky ReLUlayer (with = 0.01) in-between and predicts the scalaranomaly score, which leads to relatively small MLPs withabout 49k trainable parameters.For comparison, we use the default PatchCore imple-mentation, which only uses normal images to create a singlecoreset. Because we now have a multitude of training data,we reduce the coreset subsampling rate for default Patch-Core and Labeled PatchCore to 0.1 divided by the numberof different categories in the current dataset (i.e. 0.1",
  "A.3. Online subsampling": "The default coreset subsampling algorithm of PatchCorecollects all embeddings before creating the coreset. Thiswill result in huge memory usage if using a larger amount ofimages or higher resolutions. It also requires that all train-ing data is available before calculating the coreset and run-ning any tests.We therefore define a simple algorithm to learn online,which allows us to calculate the coreset with minimal mem-ory usage and to continue training at any time. This is doneby making two small changes to the original subsamplingalgorithm in Roth et al. : First, we do not collect theembeddings beforehand but sample them as we create thecoreset. Second, while PatchCore subsamples a fix percent-age r of all embeddings for the coreset, we add r% of thecurrent images embeddings to the coreset. Apart from that,the algorithm remains the same.The new algorithm is shown in Algorithm 1 whereas allinputs are defined exactly as in Roth et al. .We compared the default and the online subsampling al-gorithm on the default MVTec AD dataset and achievednearly identical results (both having an average image-levelAUROC of 98.7 %). Algorithm 1 online coreset subsamplingInput:: pre-trained feature extractorj Nn0: one or multiple indices of the layers fromwhich the features are extractedX (train)N= {xi|xi Rmnc}iN: normal trainingdataP: locally aware patch-feature collectors N: stride (on patch-level after extracting the fea-tures, usually 1)p N: neighbourhood size (kernel size of the averagepooling, default: 3)r (0, 1]: coreset ratio (ratio of embeddings that areadded to the coreset): random linear projectionOutput:MC memory bank",
  "It is also possible to learn batch-wise by iterating overbatches instead of images and simply accumulating all": "Algorithm 2 batch-wise online coreset subsamplingInput:: pre-trained feature extractorj Nn0: one or multiple indices of the layers fromwhich the features are extractedX (train)Nb= {xi|xi Rmnc}iN: normal trainingdataP: locally aware patch-feature collectors N: stride (on patch-level after extracting the fea-tures, usually 1)p N: neighbourhood size (kernel size of the averagepooling, default: 3)r (0, 1]: coreset ratio (ratio of embeddings that areadded to the coreset): random linear projectionb N: batchsizeOutput:MC memory bank",
  ": end for": "patches from all images of the batch instead of just one im-age in line Line 3.One could also think of more elaborate online learningalgorithms, for example changing the number of added em-beddings depending on how different the embeddings of thenew image/batch are. But our tests show that our simple al-gorithm already achieves good results compared to the orig-inal one.",
  "A.4. Software details": "To perform the experiments in this paper, we use anomalib, a library that implements many state of the art anomalydetection models like PaDiM and PatchCore , butalso Fastflow , GANomaly and others. It is basedon PyTorch and PyTorchLightning . It containsdataloaders for the MVTec AD dataset and allows an easyvalidation and visualization of the results. It also providesready-to-use scripts for training and testing as well as con-figuration files.Anomalib uses PyTorch Image Models (timm) which provides many ImageNet pre-trained models among"
}