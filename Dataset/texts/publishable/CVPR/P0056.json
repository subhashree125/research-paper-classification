{
  "Ross GreerUniversity of California San": "AbstractMotorcycle accidents pose significant risks, partic-ularly when riders and passengers do not wear helmets. Thisstudy evaluates the efficacy of an advanced vision-languagefoundation model, OWLv2, in detecting and classifying varioushelmet-wearing statuses of motorcycle occupants using videodata. We extend the dataset provided by the CVPR AI CityChallenge and employ a cascaded model approach for detectionand classification tasks, integrating OWLv2 and CNN models.The results highlight the potential of zero-shot learning toaddress challenges arising from incomplete and biased trainingdatasets, demonstrating the usage of such models in detectingmotorcycles, helmet usage, and occupant positions under variedconditions. We have achieved an average precision of 0.5324 forhelmet detection and provided precision-recall curves detailingthe detection and classification performance. Despite limitationssuch as low-resolution data and poor visibility, our researchshows promising advancements in automated vehicle safety andtraffic safety enforcement systems.IndexTermsVehiclesafety,Zero-shotlearning,Vision-language models, Helmet detection, Traffic enforcement systems",
  "I. INTRODUCTION": "Motorcycle accidents are frequent causes of injury anddeath worldwide, especially for occupants not wearing helmets. Specifically, in India, in 2022, two-wheeler deathsaccounted for 44% of total road fatalities with 74,897 deaths,the highest out of all modes of transport1. Helmets are 35%effective in reducing the risk of Abbreviated Injury Scale 3+head injuries . Additionally, 4 people die every hour in Indiabecause they do not wear a helmet2, causing 44,666 deaths in2019 . of the Motor Vehicles Act in India states thatEvery person ... on a motorcycle of any class or descriptionshall, while in a public place, wear protective headgear con-forming to such standards as may be prescribed by the CentralGovernment. Despite regulations mandating helmet use,compliance is inconsistent, leading to preventable injuries.Iterations of the CVPR AI City Challenge have promptedresearchers to address this challenge, stating Motorcycles areone of the most popular modes of transportation, particularlyin developing countries such as India. Due to lesser protection compared to cars and other standard vehicles, motorcycle rid-ers are exposed to a greater risk of crashes. Therefore, wearinghelmets for motorcycle riders is mandatory as per traffic rules,and automatic detection of motorcyclists without helmets isone of the critical tasks in enforcing strict regulatory trafficsafety measures. We suggest that, besides the enforcement oftraffic safety measures, there is also an even greater benefit inthe ability of IoT-style communication between infrastructureor egocentric perception devices. Such systems could detectthe presence of motorcyclists and passengers (with or withouthelmets) and alert the surrounding vehicles whose drivers(autonomous or human) may be otherwise unaware of thevulnerable road users in their proximity .Accordingly, to perceive holistic information about motor-cycles and their occupants in a scene, the goal task we evaluatein this paper is the detection and classification of the followingobjects in every frame of a large video dataset: 1) Motorcycle,2) Drivers wearing helmets,3) Drivers not wearing helmets,4) Passengers wearing helmets,5) Passengers not wearing helmets,6) 2nd Passengers wearing helmets,7) 2nd Passengers not wearing helmets,8) Children sitting in front of the driver wearing helmets,9) Children sitting in front of the driver not wearing hel-mets. In this research dataset, these scenes are captured byinfrastructure-mounted cameras, though the same models canalso be applied to egocentric views. This is especially the casegiven the zero-shot learning approaches we take, which donot require specific-view training data to be applied. We showsample data of these classes in .With many data-driven applications, a common challenge isthe ability of a training set to adequately represent the diversityof instances that appear in the real world , . For thisreason, data-driven methods excel when given the most datapossible, as this increases the likelihood of learning similarpatterns to a real-world instance. To this end, we create amethod that extends beyond the dataset presented by Shuo etal. by employing a pre-trained vision-language foundation",
  "arXiv:2408.02244v1 [cs.CV] 5 Aug 2024": ": Example instances of classes to detect, cropped from the AI City Challenge dataset. From left to right: Motorcycle,Driver with Helmet, Driver with No Helmet, Child Passenger with No Helmet, Passenger 1 with Helmet, Passenger 1 with NoHelmet, Passenger 2 with No Helmet. model for this detection task, specifically, the OWLv2 .Further, in our research, we present a strategy for cascadingmodels to modularly isolate and improve task performance forthese important safety systems.This foundation model strategy is important especially inconsideration of challenges presented by dataset shortcomings.The given dataset has no instances of a child passenger witha helmet or a second passenger with a helmet. This is a hugehindrance in accurately detecting the seat position and helmetstatus in these specific classes using traditional machine-learning approaches due to the lack of data for training.Therefore, the use of zero-shot learning may provide a meansto identify these instances in real world test data even withoutspecific training.The question we explore in this research is to what de-gree such foundation model approaches, namely OWLv2, areready for use with real-world data in this motorcycle safetyroad scene perception domain and where their strengths andweaknesses may lie.",
  "II. RELATED RESEARCH": "Conventional machine learning object detection algorithmsrely on manual annotations and specialized algorithms, whichcan be time-consuming and resource-intensive to label, espe-cially as the models are limited to learning from provideddatasets. Moreover, these methods often lack the flexibilityto adapt to new environments or variations in helmet designs.Foundation models, with billions of parameters trained onenormous collections of information, have recently led toeffective zero-shot techniques for a variety of tasks , wherea learned model can provide strong performance on datasetsunseen during training . One such foundation model isOWL-ViT ; OWL stands for open-world localization,referring to this models ability to function in an openworld (i.e., non-rigidly specified set of expected classes). TheViT portion of OWL-ViT refers to the Vision Transformer,an architecture that applies the attention mechanism to im-ages instead of the prior standard of convolution. The OWLfamily of models uses contrastive learning between batchesof image patch encodings and text embeddings, with imagepatch encodings producing proposed classes and proposed bounding boxes, and treating detection as a bipartite matchingproblem between these decoded image classes and boundingboxes, as introduced in the Detection Transformer (DETR)technique . Together, these methods were shownto be effective in zero-shot object detection (identifying abounding box around desired classes of interest within animage). This method was refined and scaled up using self-training as OWLv2 , whereby pseudo-box annotations areprovided from an existing detector, and it is this further-trainedmodel that we use in the method shared in this research.For the same application of detecting and classifying thegiven objects detailed in Section I, many different approacheshave been tried in the previous AI City Challenges; in the2023 AI City Challenge , Tran et al. used YOLOv8for a score of 0.7754 for the mean average precision (mAP).Cui et al. used DETA ensemble and Detectron2 fora mAP of 0.8340. In the 2024 AI City Challenge , mainlytransformer models combined with ensemble techniques wereused. Vo et al. used Co-DETR with a MinorityOptimizer for class imbalance and a Virtual Expander for amAP of 0.4860. Chen et al. used a DETA and DETRfusion model for a score of 0.4824 mAP. III. ALGORITHMS FOR IMAGE PROCESSING WITHVISION-LANGUAGE DETECTIONTo address the challenges of accurately detecting andclassifying motorcycles, their passengers, and helmet usage,we developed a cascading detection algorithm for OWLv2.Furthermore, due to OWLv2s shortcomings, we employed anAlexNet for the seat classification task. This section outlinesour cascading detection algorithm using OWLv2 and discussesour approach for the seat classification task.We first note that there are abstract classes that relatethe target classes to one another; for example, motorcycleand person are the abstract classes represented in the datascheme, where person can be further classified based on theattributes of helmet-wearing and seating position. Due to this,our first goal is to detect these high-level classes. Further, weknow that there is no driver or passenger without a motorcycle,so we only detect person in association with a particularmotorcycle instance.Our detection algorithm, illustrated in , begins witha detection stage. We provide a scene image (resized to 960 by : Our algorithm for detecting the relevant objects for helmet safety, as well as the appropriate attributes, acts in acascaded style. First, from the original image, we detect all motorcycles. Then, within each motorcycle, we detect all humanoccupants (drivers and passengers). Then, for each detected human, we perform helmet detection and seat position classification.All detections, including helmet detection for the purpose of classification, are done using OWLViT2, while seat positionclassification is done using AlexNet. 960 pixels and values normalized in , relative to the sizeof each individual image in the batch) as input to OWLv2along with the text motorcycle. The CLIPTokenizer, from, encodes the text to be wrapped by the processor withthe normalized image.To detect the person instances on the motorcycles, we ex-pand the re-scaled bounding box by 50 pixels on the left, right,and top sides to encapsulate any person instances surroundingthe motorcycle. Using the expanded box, we crop the originalimage and run the OWLV2 model over this cropped imagewith the prompt person to detect person instances.The algorithms subsequent step is to perform the next levelof detection, focusing on helmets, by cropping each personinstance and running the OWLv2 over the cropped image witha text input of helmet. Because our task is to classify eachperson based on whether they are wearing a helmet and notnecessarily to detect the helmet itself, we store the booleanresult of this detection as an attribute of the person (ratherthan noting the bounding box).We note that there is a general difficulty of OWLv2 indifferentiating a persons semantic position on the motorcycle(such as driver, passenger, second passenger, etc.), as notedin Section IV. For this particular portion of the task, wetake a supervised learning approach. We seek to provide eachperson detected on the motorcycle with an attribute of location between the positions enumerated in the introduction.Therefore, we use a neural network (a variant of AlexNet, with a final layer output of four) to classify the seatingposition on a motorcycle of the person instances detected withOWLv2.Due to the use of the AlexNet in the seat position clas-sification task, we recognize that the whole process is notcompletely zero-shot. It is rather a hybrid of zero-shot learningand supervised learning, with zero-shot for the association anddetection of motorcycles, their passengers, and their helmetstatus, and supervised learning for the seat classification ofthe passengers. In this way, the methods in this paper actuallyaddress four tasks (motorcycle detection, person detection,helmet detection, and seat classification); three of these aresolved in a zero-shot manner, and we include a learnedapproach to seat classification as this is a relevant safety taskthat should also be considered in conjunction.In total, this algorithmic sequence of tasks can providedetections of motorcycles, associated people, their positions,and their helmet status for each image in a video. IV. EXPERIMENTAL METHOD AND EVALUATIONUsing the cascaded object and attribution detection algo-rithm detailed in the previous section, we performed detectionon the dataset of 100 videos provided by , with furtherimplementation details described in this section. We first conducted the motorcycle and person detection ofour cascaded detection process as described in Section III.The threshold for OWLv2 is a confidence threshold, mean-ing it is the minimum confidence score that a predictedbounding box must have to be considered a valid detection.The OWLv2 will discard any detection with a confidence scorebelow the given threshold. The confidence score is calculatedas logits on a per-detection basis.We performed the cascaded detection process with thresh-olds of 0.1 to 0.7 on the OWLv2 to examine the sensitivityof precision and recall to thresholds. 0.7 was chosen asthe last threshold, as OWLv2 made no detections with athreshold higher than 0.7. Using the output of our detections,we calculated the precision and recall at each confidencethreshold.To evaluate the ability of OWLv2 to classify a passengershelmet status, regardless of error in upstream person detection,we detected helmets within the ground truth bounding boxesof passengers to classify the passengers helmet status. As inthe previous detections, we experimented with a threshold of0.05 to 0.7.When performing the seat classification based on the persondetection, we attempted to determine a passengers seat withOWLV2, first using the text prompts provided by the labelsin the dataset, such as passenger 1 and child passenger.However, with these prompts, OWLv2 tended to miss somepassengers and mislabel the people. Assuming this was due tothe inputs, we attempted more specific prompts such as childin front of driver or passenger behind driver. Nevertheless,this also yielded similar results. We hypothesize that theprompt inputs were not the determining factor of OWLv2sfailure to detect and differentiate the different people on amotorcycle, showing possible shortcomings of model trainingfor this particular type of task. Furthermore, the task ofclassifying people based on their relative location to otherpeople and the motorcycle may be too specific for the model.After observing OWLv2s shortcomings with our intersec-tion data, we used a modified AlexNet for the seat classifica-tion subtask . We modified the last layer of the AlexNetfrom 10 outputs to 4 to suit our task.We used an approximate inverse class frequency to over-come the severe class imbalance in the dataset as shown inTable I. At first, we tested the weighting of 1.147, 7.908,785.229, and 2093.944, calculated by inverse class weighting.However, this was insufficient, as the model did not appear tolearn the child class and appeared to over-favor the driver class.Therefore, we incrementally increased the weighting of theclasses of passenger1, passenger2, and child passenger relativeto the driver, updating the previously mentioned weights to 1,10, 800, and 3000, respectively.We split the data 70/15/15 for the training, testing, andvalidation. We used a cross-entropy loss. Finally, we trainedthe model using a learning rate of 0.0001 for 100 epochs.Then, we used the model with the lowest loss on the validationset to make inferences on the test set.",
  "A. Data": "The dataset provided by contains 100 videos taken byinfrastructure-mounted cameras in India. They are annotatedwith bounding boxes of motorcycles and up to four passengerswho may or may not be wearing helmets. Each video is20 seconds long, sampled at 10 Hz, and has a resolutionof 19201080. Example images from the dataset are shownin . The ground truth data is comprised of classfrequencies, as shown in Table I, and has 26349 helmet-wearers and 11462 unhelmeted people, meaning 69.7% arehelmeted.",
  "B. Results": "Our OWLv2 detected motorcycles with accuracies shownin Table II and detected persons with accuracies as shown inTable III. For motorcycle detection, the average precision is0.4122, calculated by the area under the curve of , andfor person detection, the average precision is 0.3561, obtainedfrom .Our helmet-status classification was done through helmetdetection with OWLV2 on the provided ground truth boundingboxes of passengers, with a representative classification basedon the helmets presence or absence. This resulted in theprecisions and recalls in Table IV, tested over multiple thresh-olds, resulting in an average precision of 0.5324, as furtherillustrated in . A naive classifier, which always predictsthe rider to be wearing a helmet, would have a precision of69.7% and a trivial recall of 100% based on the ground truthdata described in Section IV A; at all thresholds, our precisionis higher than the naive classifier, showing a reduction in falsepositives and negatives.The IoU in Tables II, III, and IV stands for intersectionover union, which is the metric for evaluating the accuracy ofa predicted bounding box. The IoU is calculated as follows:IoU = AB",
  "AB or IoU = Area of Overlap": "Area of Union , where A stands forthe predicted bounding box and B stands for the ground truthbounding box. In our evaluation, for a given detected boundingbox, if the IoU with the ground truth is greater than or equalto 0.5, then the detection is considered a true positive.Finally, our neural networks seat classification achievedan accuracy of 95.17% on the validation set, with the clas-sification results on the test set displayed in . Wenote that the severe class imbalance does leave the childpassenger class unsuccessfully classified, though this doesnot have much impact on the accuracy metric. This revealsan insufficiency in the model learning and cautions us ofevaluating performance for such an imbalanced dataset withoutexamining class performance in the confusion matrix.",
  "C. Sensitivity of Helmet Detection to OWLViT DetectionThreshold": "Due to the nature of the dataset, it is important to find anoptimal threshold in our detections. As many videos withinthe data are often unclear, too high of a threshold may omitthe detections within the unclear regions of the data. On thecontrary, too low of a threshold may yield unrelated detections,such as detecting a bike as a motorcycle. Therefore, an optimal",
  "V. CONCLUDING REMARKS AND FUTURE RESEARCH": "Zero-shot learning demonstrates the potential of this appli-cation as it can overcome some limitations of incomplete andbiased training datasets. As noted, the provided dataset lacksinstances of child passengers with helmets and second pas-sengers with helmets, making training traditional supervised-learning models difficult. Zero-shot learning leverages pre-training on diverse data, classifying unseen instances more : Precision-Recall Curve of Motorcycle Detection. Ini-tially, a slight increase in precision indicates improved confi-dence in early predictions. However, precision declines steeplyas recall rises, highlighting the models challenge in maintain-ing accuracy while capturing more true positives. : Precision-Recall Curve of Passenger Detection. Thecurve demonstrates a high precision at low recall values.Despite the trade-off of precision and recall, the shape suggestsa robust model performance in balancing the two. : Precision-Recall Curve of Helmet ClassificationThe curve has a high initial precision, progressively decreasingas recall increases. Efforts to capture more true positivesresulted in a higher incidence of false positives.",
  ": Confusion Matrix of Seating Position Classification": "accurately. With further fine-tuning and training, zero-shotlearning has a strong potential for accurately handling real-world data.Several sources of error are demonstrated in the helmetclassification. The ground truth bounding boxes do not alwaysencompass the whole person. Many boxes were taken from thelower half of their body as they entered the frame of the video.Additionally, overlapping bounding boxes with passengers anddrivers, where drivers have helmets on, but the passengers donot, often confuses the OWLV2, claiming that it had detectedthe helmet in both cases. This also impacts person detection,as the OWLv2 cannot detect the passenger due to the driverobstructing most of the passengers body.Furthermore, AlexNet and the OWLv2 foundation modelwere challenged when faced with real-world noise-filledscenarios. Many of the videos provided in the dataset hadvery low resolutions, with blurred-out time stamps at the topleft and bottom right obstructing the view of motorcycles.Data collected during the night further reduced visibility, asthe headlights of motorcycles and cars create a blurry effectthroughout the video. The regular poor conditions of fog orheavy air pollution compounded these factors, as shown in. All of these various aspects made image detectionand classification challenging and sometimes near impossible.Future investigations are necessary to apply zero-shot learn-ing in the real world. In this application, accurately detectinghelmets will help to raise awareness as the detections willprovide a more accurate measure of the frequency at whichpeople do not wear helmets, as well as assist in enforcing thewearing of helmets. The ability to respond to unanticipateddata is crucial for safety systems, as real-world scenariosoften surpass the scope of any pre-existing dataset. Ongoingdevelopment and refinement of the model will be imperativeto fully harness their potential in practical safety systems.Our future research will focus on enhancing the accuracy,robustness, and consistency of zero-shot learning models inour detections.To handle noisy data, pre-training the OWLv2 on furtherdiverse datasets will allow it to better handle uncertain de-tections. Furthermore, preprocessing the data will mitigatesome of these issues. Moreover, a possible improvementis the further integration of AlexNet and OWLv2 for seatclassification. A hybrid approach using these two models willinvolve ensemble methods to balance their strengths for a moreaccurate result .Finally, we will address task-specific shortcomings. Forexample, at times, the OWLv2 model fails to get the boundingbox over the whole person, specifically the head, which isespecially crucial for this task. A primary focus will beimproving the models ability to localize and classify thesecritical areas accurately.Despite current limitations and imbalances in data, this re-search shows the potential of foundation models and language-based prompting toward the zero-shot handling of importantsafety challenges. We address all components of the AI CityChallenge Helmet Detection and Occupancy tasks, showing possibilities for the OWL model to address the sub-tasks ofdetection and association of vehicles, their occupants, andsafety state information. This application has the potentialto extend upon I2V communication. The detections fromthe infrastructure point of view can be sent to the vehiclesegocentric perception in order to alert drivers of the presenceof motorcycles for safer intersection driving. N. Abdi, T. Robertson, P. Petrucka, and A. M. Crizzle, Do motorcyclehelmets reduce road traffic injuries, hospitalizations and mortalities inlow and lower-middle income countries in africa? a systematic reviewand meta-analysis, BMC public health, vol. 22, no. 1, p. 824, 2022. C. D. F. d. Souza, J. P. S. d. Paiva, T. C. Leal, L. F. d. Silva, M. F.Machado, and M. D. P. d. Araujo, Mortality in motorcycle accidents inalagoas (2001-2015): temporal and spatial modeling before and after thelei seca, Revista da Associacao Medica Brasileira, vol. 65, pp. 14821488, 2020. L. Abedi and H. Sadeghi-Bazargani, Epidemiological patterns and riskfactors of motorcycle injuries in iran and eastern mediterranean regioncountries: a systematic review, International journal of injury controland safety promotion, vol. 24, no. 2, pp. 263270, 2017. A. L. Cavalcanti, B. Lucena, I. S. Rodrigues, A. L. Silva, T. T. Lima, andA. F. C. Xavier, Motorcycle accidents: morbidity and associated factorsin a city of northeast of brazil, Tanzania journal of health research,vol. 15, no. 4, 2013.",
  "S. VASAN and G. GURURAJ, Unhelmeted two-wheeler riders inindia, The National Medical Journal of India, vol. 34": "The motor vehicles act, 1988. S. Wang, D. C. Anastasiu, Z. Tang, M.-C. Chang, Y. Yao, L. Zheng,M. S. Rahman, M. S. Arya, A. Sharma, P. Chakraborty, S. Prajapati,Q. Kong, N. Kobori, M. Gochoo, M.-E. Otgonbold, G. Batnasan,F. Alnajjar, P.-Y. Chen, J.-W. Hsieh, X. Wu, S. S. Pusegaonkar, Y. Wang,S. Biswas, and R. Chellappa, The 8th AI City Challenge, in TheIEEE Conference on Computer Vision and Pattern Recognition (CVPR)Workshops, June 2024. R. Greer, S. Desai, L. Rakla, A. Gopalkrishnan, A. Alofi, and M. Trivedi,Pedestrian behavior maps for safety advisories: Champ framework andreal-world data analysis, in 2023 IEEE Intelligent Vehicles Symposium(IV), pp. 18, IEEE, 2023. A. Ghita, B. Antoniussen, W. Zimmer, R. Greer, C. Cre, A. Mgelmose,M. Trivedi, and A. C. Knoll, Activeanno3d-an active learning frame-work for multi-modal 3d object detection, in 35th IEEE IntelligentVehicles Symposium (IV) 2024, 2024. R. Greer, B. Antoniussen, M. V. Andersen, A. Mgelmose, and M. M.Trivedi, The why, when, and how to use active learning in large-data-driven 3d object detection for safe autonomous driving: An empiricalexploration, arXiv preprint arXiv:2401.16634, 2024.",
  "Z.-Q. Zhao, P. Zheng, S.-T. Xu, and X. Wu, Object detection withdeep learning: A review, IEEE Transactions on Neural Networks andLearning Systems, vol. PP, pp. 121, 01 2019": "R. Greer and M. Trivedi, Towards explainable, safe autonomous drivingwith language embeddings for novelty identification and active learning:Framework and experimental analysis with real-world data sets, arXivpreprint arXiv:2402.07320, 2024. A. Radford, J. W. Kim, C. Hallacy, A. Ramesh, G. Goh, S. Agarwal,G. Sastry, A. Askell, P. Mishkin, J. Clark, et al., Learning transferablevisual models from natural language supervision, in Internationalconference on machine learning, pp. 87488763, PMLR, 2021. M. Minderer, A. Gritsenko, A. Stone, M. Neumann, D. Weissenborn,A. Dosovitskiy, A. Mahendran, A. Arnab, M. Dehghani, Z. Shen, et al.,Simple open-vocabulary object detection, in European Conference onComputer Vision, pp. 728755, Springer, 2022.",
  "R. Greer, A. Gopalkrishnan, N. Deo, A. Rangesh, and M. Trivedi,Salient sign detection in safe autonomous driving: Ai which reasonsover full visual context, arXiv preprint arXiv:2301.05804, 2023": "M. Naphade, S. Wang, D. C. Anastasiu, Z. Tang, M.-C. Chang, Y. Yao,L. Zheng, M. S. Rahman, M. S. Arya, A. Sharma, Q. Feng, V. Ablavsky,S. Sclaroff, P. Chakraborty, S. Prajapati, A. Li, S. Li, K. Kunadharaju,S. Jiang, and R. Chellappa, The 7th ai city challenge, in The IEEEConference on Computer Vision and Pattern Recognition (CVPR) Work-shops, June 2023. D. N.-N. Tran, L. H. Pham, H.-J. Jeon, H.-H. Nguyen, H.-M. Jeon, T. H.-P. Tran, and J. W. Jeon, Robust automatic motorcycle helmet violationdetection for an intelligent transportation system, in Proceedings ofthe IEEE/CVF Conference on Computer Vision and Pattern Recognition(CVPR) Workshops, pp. 53415349, June 2023. S. Cui, T. Zhang, H. Sun, X. Zhou, W. Yu, A. Zhen, Q. Wu, andZ. He, An effective motorcycle helmet object detection framework forintelligent traffic safety, in Proceedings of the IEEE/CVF Conference onComputer Vision and Pattern Recognition (CVPR) Workshops, pp. 54705476, June 2023."
}