{
  "Abstract": "Image classifiers should be used with caution in the realworld. Performance evaluated on a validation set may notreflect performance in the real world. In particular, clas-sifiers may perform well for conditions that are frequentlyencountered during training, but poorly for other infrequentconditions. In this study, we hypothesize that recent ad-vances in text-to-image generative models make them valu-able for benchmarking computer vision models such as im-age classifiers: they can generate images conditioned bytextual prompts that cause classifier failures, allowing fail-ure conditions to be described with textual attributes. How-ever, their generation cost becomes an issue when a largenumber of synthetic images need to be generated, which isthe case when many different attribute combinations needto be tested. We propose an image classifier benchmarkingmethod as an iterative process that alternates image gen-eration, classifier evaluation, and attribute selection. Thismethod efficiently explores the attributes that ultimatelylead to poor behavior detection.",
  ". Introduction": "In computer vision, deep learning models have achieved re-markable successes, consistently pushing the boundaries ofwhats possible in image classification , object detection, and many other applications. Despite these achieve-ments, a persistent challenge remains: accurately discerningwhen the predictions made by these models can be trusted. This is especially important for critical decision sys-tems such as autonomous vehicles or medical imaging diag-nostics. Even for less critical systems, errors have a cost thatcan be financial or reputational. The reliability of modelpredictions becomes particularly nebulous under conditionsof data shift, inherent biases, and the presence of out-of-distribution (OOD) samples. Using pre-trained models can worsen those issues because the pre-training process anddata might be unknown. It has been shown that deep neu-ral networks often rely on spurious correlations for makingpredictions . The conventional metric of a single ac-curacy number falls significantly short of comprehensivelyevaluating a models performance. It is only a global evalu-ation of a given data distribution. New benchmarking toolsare required.Recently, there have been massive improvements in mul-timodal models, especially those combining textual and vi-sual data like Text-to-Image generative models. These mod-els have demonstrated an exceptional ability to understandand generate content that captures the nuanced interplaybetween text and images . This allows new waysof benchmarking image classifiers with generative models.Classifier performance can be studied in relation to the tex-tual attributes of the data . Despite their poten-tial, however, the practical utility of these generative modelsis limited by the computationally intensive inference pro-cess of the underlying diffusion models. For example, in, testing whether the presence of a flower in an imagecauses the classifier to sometimes mistake flies for bees re-quired hardware with 20 4 TPUs. developed a classifier evaluation process that startswith an Operational Design Domain that textually de-scribes the conditions the model is likely to encounter dur-ing use. It consists of many different combinations of at-tributes. To test a combination, they use synthetic data froma text-to-image model. They then identify which of thesecombinations lead to classifier errors. However, a majorlimitation is the combinatorial explosion: they need to limitthe number of evaluated combinations. They suggest us-ing combinatorial testing , but we found it far from op-timal and not much better than random selection. In thispaper, we are inspired by the principles of Bayesian Op-timization (BO), a black-box global optimization methodthat is particularly well suited for functions with expen-",
  "Images": ". Illustration of our method that alternates generation, evaluation, and selection. The selection function selects the next subdomainto evaluate, based on the feedback of the previous subdomains evaluated. With the right choice of selection function, an efficient explorationof the evaluation domain is achieved. sive evaluations. Among others, it has been successfullyapplied to Neural Architecture Search (NAS) . We pro-pose a novel approach to efficiently explore the semantic at-tributes of data that most significantly impact classificationperformance. By leveraging the insights gained from themultimodal models and addressing the limitations imposedby the computational demands of diffusion models, our ap-proach seeks to enhance the reliability and interpretabilityof computer vision models. This paper details our method-ology, which combines the strengths of Bayesian Optimiza-tion with the latest advancements in benchmarking com-puter vision with generative models. This offers a moreefficient way to understand classification performance in re-lation to textual descriptions.Our contributions are:",
  ". Related Work": "Text-to-image generative modelsDiffusion models, anessential class of generative models, simulate the processof adding noise to data and then learning to reverse thisprocess, enabling the generation of high-quality data sam-ples. Introduced by , these models have paved the wayfor advancements in generative modeling by demonstrat-ing how data distribution can be captured through denois-ing steps. The development of Denoising Diffusion Prob-abilistic Models (DDPMs) marked a significant leapforward, refining training and sampling methods to pro- duce high-fidelity images. Building upon these foundations, introduced key improvements in efficiency and samplequality, leading to outperforming previously state-of-the-artgenerative models like GANs and VAEs in imagequality and diversity. Textual conditioning allows for gener-ating complex and diverse images by prompting them withtext. Well-known Text-to-Image models include DALL-E2 and Imagen . Stable Diffusion emphasizesefficiency and scalability. It also makes high-quality text-to-image generation more accessible as it was published inopen-source. While GANs can also be conditioned by text, the rapid improvements of diffusion models are hardto match. A main limitation of diffusion models is their in-ference time, requiring many denoising steps to generate animage. This is an important research avenue . Classifier failure discoveryDiscovering failures or bugsin image classification models has recently been studiedmore and more. One can use large labeled datasets and hu-man verification to identify bugs . To avoid these re-quirements, other approaches are based on generative mod-els. In particular, leveraging recent Text-to-Image genera-tive models allows linking textual attributes to classificationperformance. It is possible to identify bugs in a given classi-fier by generating many images and then clustering and cap-tioning the ones leading to classification failure . Forinstance, the presence of a flower in the images augmentsthe chances of misclassification of flies into bees. How-ever, the required computing resources are enormous. personalizes the generation to a specific dataset to createdistribution-shifted versions of the dataset.They can beused to test classification models robustness to shifts. Inour work, we can study combinations of shifts leading tofailure, or in other words, corner cases. identifies sub- groups of data leading to degraded performance. Startingfrom an Operational Design Domain defined by domain ex-perts and consisting of several semantic dimensions. An im-age classifier is tested on selected subgroups of this domain.We take inspiration from this work but derive a guided andefficient exploration of the attributes. Bayesian optimizationBayesian optimization isoften discussed in the context of Surrogate-Model BasedOptimization (SMBO) .The aim is to evaluate thecostly objective function as few times as possible. To thisend, an efficient model is used as its surrogate. BO typi-cally relies on regression using Gaussian processes (GPs) ina process generally known as Kriging. Despite their ubiq-uity, thanks to many positive attributes, GPs have certaindrawbacks. The most important one is the cubic complex-ity, making them inefficient as the observed data points in-crease. Their use is also contingent on selecting a kerneland possibly a distance function. It is however possible toeffectively apply the general BO loop with alternative mod-els, such as deep neural networks , as well as randomforests and Bayesian neural networks .",
  ". Method": "We propose an efficient iterative process to explore the tex-tual attributes leading to classifier failure. We first intro-duce the background concepts in subsection 3.1; our defi-nitions for the evaluation domain and subdomains in sub-section 3.2; the general pipeline to generate images for thesubdomains in subsection 3.3; and our proposed guided ex-ploration of attributes that matter in subsection 3.4.",
  ". Background": "Image classifierTo demonstrate our approach withoutusing considerable computing power, we tackle a simpli-fied task: binary classification of images containing dogs.We construct a dog classifier from a classifier pre-trainedon ImageNet , a dataset that contains images of animalsor everyday objects. Out of the 1000 classes, 119 are differ-ent dog breeds. We sum the classifier probabilities of theseclasses to get the dog probability and sum the rest to get thenot-dog probability. Text-to-image generative modelsWe use diffusion mod-els as a method for generating images from textual descrip-tions. They are characterized by their ability to producehigh-quality images through a process of denoising. Thecore mechanism involves a forward diffusion process thatincrementally adds noise to an image until it becomes in-distinguishable from Gaussian noise. The reverse process,iteratively reconstructing the image from noise, is learned",
  ". Define the evaluation domain and subdomains": "We call evaluation domain the ensemble of deployment en-vironment conditions to evaluate. The conditions are de-scribed by textual attributes, each containing a finite numberof values. They can be categorical or continuous, but we fo-cus on categorical attributes in this work. The domain com-prises all the possible attribute value combinations, whichwe call subdomains. The number of subdomains grows ex-ponentially with the number of attributes considered. As a starting point, we need to define the textual at-tributes to explore. Expert knowledge is thus required. Aswe study image classification of natural images of dogs,we define the following attributes and associated values inbrackets: weather [sunny, cloudy, raining, snowing], loca-tion [at the beach, in the forest, in the city, inside a house, ina garden, in the desert, in the mountains], time [day, night],color [white, black, brown, beige, gray, red, green, blue],and viewpoint [front, side, rear]. Some combinations arenot valid and must be removed.",
  ". Generate data conditioned by attributes": "PromptThe first step is to create a textual prompt cor-responding to one subdomain attribute. We use a prompttemplate to fill with the attributes: A {viewpoint} view of a{color} dog {location}, during the {time}, it is {weather}.. GenerateA Text-to-Image model can then generate im-ages conditioned by the textual prompt. The generation isnot deterministic: the starting noisy image is random, andnoise is applied to each step of the reverse diffusion process.This means that one textual conditioning leads to a varietyof aligned images. FilterThe generation is not perfect, and sometimes thesynthetic image does not align well with the textual promptinput. We derive a filtering process that follows the gener-ation to limit this issue. We use CLIP as a zero-shotsubdomain classifier. We have a finite number of subdo-mains, and each of them is defined as a textual prompt. Wethus compute the cosine similarity between a generated im-age and all subdomains prompts to obtain logits. Applyingthe softmax function to the logits, we get predicted proba-bilities that the image corresponds to each subdomain. If theprompt with the maximum probability is indeed the promptused to generate the image, we consider the image correctotherwise it is filtered out.",
  ". Guided exploration of attributes that matter": "Because generating data conditioned by the attributes de-scribed above is time-consuming, we propose an efficientexploration of the critical attributes. An iterative processalternates the generation of images for a subdomain, eval-uates the classifier on the subdomain, and selects the nextsubdomain to evaluate based on this feedback. The processis described schematically in and more formally inAlgorithm 1. We propose several selection functions below. Genetic algorithm (GA)This is a performant optimiza-tion method based on natural selection . A populationof solutions is evaluated. The top performers are preserved,and a crossover operation generates children solutions frompairs of parents. This new generation of solutions under-goes mutations with a small probability, adding diversity. Bayesian optimization (BO)Our method to efficientlyexplore the space of subdomains involves the same coreloop at the center of Bayesian optimization, relying on apredictive model to guide the search towards the criticalsubdomains.1. Selection: choose the next subdomain to evaluate usingthe model 2. Observation: evaluate the subdomain3. Model update: add the new observation to the datasetThe selection policy generally means selecting the pointwhich maximizes an acquisition function. Many acquisi-tion functions exist in the literature, and each presents a dif-ferent trade-off between exploration and exploitation. Theselection policy we use is inspired by Expected Improve-ment , a widely used and generally effective acquisitionfunction. Using the models estimation of each subdomainsquality, we select the subdomain with the highest potentialimprovement over the current best subdomain.",
  ". Prerequisites": "ClassifierWe study a classifier with the ViT-B/16 ar-chitecture. Weights are from torchvision, following a pre-training on the ImageNet dataset. The binary classifiers ac-curacy on ImageNet validation data is more than 99%. Wewant to assess its performance on data that is more diversethan in the original dataset to see if it can generalize well. SubdomainsThe number of possible attribute combina-tions is 1 class (dog) 4 weathers 7 locations 2 timeperiods 8 colors 3 viewpoints = 1344. However, someof the combinations are impossible (e.g., during the night,it is sunny or in a house, it is snowing). After filteringthose, 1032 combinations remain, forming all the possiblesubdomains to evaluate. Generative modelWe use Stability AIs implementationof Stable Diffusion 2.1 as a text-to-image generative model.Its architecture is based on Latent Diffusion Models ,and text conditioning uses a fixed pre-trained text encoderbased on CLIP ViT/H. Generated images have a 512 512resolution, but we resize them into 256 256 to save diskspace. Resizing images at a lower resolution is part of theclassifier data preprocessing anyway. We treat this model asa black box transforming textual input prompts into diversecorresponding images. Filtering modelBecause the generation is imperfect, weneed to filter out generated images that do not align wellwith the textual input prompt. We use a subdomain clas-sifier that classifies generated images into one of the sub-domains.This classifier is a pre-trained CLIP ViT-L/14adapted as a zero-shot classifier.",
  "RandomForestRegressorLinearRegressionLassoSVR": "(d) Spearmans rank correlation coefficient for different predictors andtraining set sizes. It measures the strength and direction of the monotonicrelationship between two ranked variables, here the predicted and test accu-racies. A value close to 1 means the relationship between the two variablesis monotonic. Except for SVR, all predictors perform similarly well. Lassois the best method for small training sizes. . Different metrics to compare the quality of the subdomain selection when iterating on the loop generation, evaluation, andselection. In general, combinatorial testing is not much better than random selection, and it only gives a few options for the number ofsubdomains selected. GA and BO are much more efficient and can explore any given number of subdomains according to the computationtime available. Note that the x-axis of 4a, 4b, and 4c could be replaced by GPU.hours going from 0 to 200 as mentioned in Subsection4.2. All plots are averages over 10 seeds and the standard deviations are shown.",
  ". Average accuracies for each value of each attribute. The 95% confidence interval is also shown": "dicts the accuracy. We tested Random Forest Regressors(RFR) , Linear Regression (LR), Lasso , and Sup-port Vector Regression (SVR) using scikit-learn .We start with a pre-training on 10 random subdomains tolower the variability of each run. MetricsWe study the evolution of selected subdomainaccuracies, average accuracy of selected subdomains, andcoverage of the 10% lowest accuracies subdomains. Wealso show a histogram of the subdomain accuracies for afixed number of explored subdomains. We use the Spear-man rank correlation to evaluate the quality of the predic-tors.",
  ". Evaluating all subdomains for reference": "To validate our approach, we evaluate the performance of allsubdomains and save the results as shown in . Be-cause all evaluation results are pre-computed, benchmark-ing the different selection functions is done by replacing thegeneration and evaluation parts with a simple table look-up. This allows us to compare different selection functionsquickly. This validation ensures that subsequent work canuse our findings to reduce the number of evaluations. Wegenerated 50 valid images for each of the 1032 subdomains.It took approximately 200 hours to generate all images onone NVIDIA V100 GPU. Sometimes, hundreds of imageshad to be generated to obtain 50 valid ones after filtering.The expected evaluation time of one subdomain is 12 min-utes, or 1 hour for 5 subdomains. The results below showthe number of subdomains explored as the x-axis. Still, wecould have used an estimated computing time by using thevalue of around 12 minutes per subdomain evaluated. shows samples of generative images with theirinput prompt. While not perfect depictions of dogs, theyare close enough to benchmark the classifier. Some imagesclearly depict dogs, yet the classifier fails to identify them.This highlights some of its limits.",
  ". Benchmarking the selection functions": "The main goal of selection functions is to identify subdo-mains with low accuracy quickly. To measure this, we showthe evolution of different metrics during the exploration in. The main conclusion is that combinatorial test-ing (n-wise testing with n {2, 3, 4, 5}) is not much bet-ter than random selection. Also, it has the disadvantage ofrestricting the number of subdomains selected: we cannottune this number. GA is much better, and BO is even better.BO can successfully identify all the 10% most critical sub-domains (with lowest accuracies) after evaluating 40%of all subdomains. This also proves that subdomain perfor-mance can be precisely inferred from the domain attributes.This means that classifier failures can be explained from theattributes, providing interesting insights into the classifierdecision process. details a specific step in the evaluation processwhen the number of subdomains is equal to 61 (which isthe number of subdomains selected by 3-wise testing). Thisalso shows a clear advantage for GA and BO in quicklyidentifying low-accuracy subdomains.d shows that the four predictors perform simi-larly well. We choose Lasso as a predictor for BO becauseit is the best method for small training set sizes. Indeed,the beginning of the exploration, when the data is limited,is particularly important. Furthermore, it showed less vari-ability than, for example, random forests.",
  ". Qualitative analysis of classifier failures": "The main focus of our work is to efficiently detect the at-tributes with the most impact on classification performance.However, this subsection suggests what kind of qualitativeassessment it allows. We use the BO approach and allowthe exploration of 300 subdomains. shows the av-erage accuracies for each attributes value. This shows theimpact of each attribute individually but does not show theimpact of combinations of attributes. displays theimpact of all the possible combinations of the attributes ofweather and location.",
  ". Limitations": "Benchmarking classifiers with generative models has limi-tations as observed by other work . There can beoccasional misalignments between the prompt and the im-age due to bias or language limitations. For instance, in thiswork, we observed that the viewpoint attribute is sometimesnot the one requested. We also observed generator failuresfor a few specific subdomains, e.g., nearly all images for Afront view of a green dog in the mountains, during the night,it is raining. are in a cartoon style, which is not the casefor snowing, see . Prompt engineering is requiredto allow a rigorous benchmark of the classifier. Also, gen-erated images do not cover everything possible in the realworld. Our approach tackles the computing time problem.Its main limitation is that there is no guarantee that a goodselection function will identify all problematic subdomainsfor an incomplete exploration. For instance, a subdomainmight be difficult for completely different reasons than theothers. Thus, a selection based on learning a relation be-tween subdomain attributes and performance might miss it.",
  ". Conclusion and perspectives": "Text-to-Image models have great potential to be a usefultool for benchmarking image classifiers by generating im-ages of failure cases. However, since the highest qualitygenerators are based on diffusion models, their high infer-ence time prevents large-scale image synthesis for advancedevaluation. This work starts from an evaluation domain de-scribed by textual attributes. To efficiently explore the crit-ical attribute combinations that cause classifier failures, we",
  ". Heatplot displaying the average accuracies for differentcombinations of weather and location": ". In the top row, images are generated with the prompt Afront view of a green dog in the mountains, during the night, it israining.. They are mostly in a cartoon style. In the bottom row,the same prompt, but raining has been replaced by snowing.The phenomenon disappears. Is this a generator failure? Carefulprompt engineering, e.g., adding a realistic image, is requiredto ensure alignment between the textual prompt, images, and whatwe expect. propose to create an iterative process that alternates imagegeneration, classifier evaluation, and attribute selection. Wecompare different selection functions and show that all ofthem outperform the method used in a previous work.We believe that our work can be further improved by us-ing NAS methods, taking advantage of low-fidelity evalu-ations. For example, in our case, the accuracy could beestimated with 20 images.The method would then usethese low-fidelity evaluations to decide which combinationis worth testing with high-fidelity, say 200 images. In addi-tion, for more complex problems, one can use word embed-dings such as language models instead of one-hot embed-dings of finite attributes. Our work can potentially improvethe benchmarking of image classifiers with text-to-imagemodels, as it addresses a major limitation: computationaltime. It allows the exploration of larger domains and moreprecise estimates of accuracies, class probabilities, and fail-ures. This work has been supported by the French governmentunder the France 2030 program, as part of the SystemXTechnological Research Institute.This work was granted access to the HPC/AI resources ofIDRIS under the allocation 2024-AD011013372R2 madeby GENCI.",
  "Leo Breiman. Random forests. Machine learning, 45:532,2001. 7": "Lars Buitinck, Gilles Louppe, Mathieu Blondel, Fabian Pe-dregosa, Andreas Mueller, Olivier Grisel, Vlad Niculae,Peter Prettenhofer, Alexandre Gramfort, Jaques Grobler,Robert Layton, Jake VanderPlas, Arnaud Joly, Brian Holt,and Gael Varoquaux. API design for machine learning soft-ware: experiences from the scikit-learn project. In ECMLPKDD Workshop: Languages for Data Mining and MachineLearning, pages 108122, 2013. 7",
  "Roman Garnett. Bayesian Optimization. Cambridge Univer-sity Press, 2023. 3": "Robert Geirhos, Jorn-Henrik Jacobsen, Claudio Michaelis,Richard Zemel, Wieland Brendel, Matthias Bethge, and Fe-lix A Wichmann. Shortcut learning in deep neural networks.Nature Machine Intelligence, 2(11):665673, 2020. 1 Ian Goodfellow, Jean Pouget-Abadie, Mehdi Mirza, BingXu, David Warde-Farley, Sherjil Ozair, Aaron Courville, andYoshua Bengio. Generative adversarial nets. Advances inneural information processing systems, 27, 2014. 2 Kaiming He, Xiangyu Zhang, Shaoqing Ren, and Jian Sun.Deep residual learning for image recognition. In Proceed-ings of the IEEE conference on computer vision and patternrecognition, pages 770778, 2016. 1",
  "Aditya Ramesh, Prafulla Dhariwal, Alex Nichol, Casey Chu,and Mark Chen. Hierarchical text-conditional image gener-ation with clip latents. arXiv preprint arXiv:2204.06125, 1(2):3, 2022. 1, 2": "Joseph Redmon, Santosh Divvala, Ross Girshick, and AliFarhadi. You only look once: Unified, real-time object de-tection. In Proceedings of the IEEE conference on computervision and pattern recognition, pages 779788, 2016. 1 Robin Rombach, Andreas Blattmann, Dominik Lorenz,Patrick Esser, and Bjorn Ommer.High-resolution imagesynthesis with latent diffusion models.In Proceedings ofthe IEEE/CVF conference on computer vision and patternrecognition, pages 1068410695, 2022. 2, 5 Chitwan Saharia, William Chan, Saurabh Saxena, LalaLi, Jay Whang, Emily L Denton, Kamyar Ghasemipour,Raphael Gontijo Lopes, Burcu Karagol Ayan, Tim Salimans,et al. Photorealistic text-to-image diffusion models with deeplanguage understanding.Advances in neural informationprocessing systems, 35:3647936494, 2022. 1, 2 Axel Sauer, Tero Karras, Samuli Laine, Andreas Geiger, andTimo Aila. Stylegan-t: Unlocking the power of gans for fastlarge-scale text-to-image synthesis.In International con-ference on machine learning, pages 3010530118. PMLR,2023. 2 Jasper Snoek, Oren Rippel, Kevin Swersky, Ryan Kiros, Na-dathur Satish, Narayanan Sundaram, Mostofa Patwary, MrPrabhat, and Ryan Adams. Scalable bayesian optimizationusing deep neural networks. In International conference onmachine learning, pages 21712180. PMLR, 2015. 3 Jascha Sohl-Dickstein, Eric Weiss, Niru Maheswaranathan,and Surya Ganguli.Deep unsupervised learning usingnonequilibrium thermodynamics.In International confer-ence on machine learning, pages 22562265. PMLR, 2015.2",
  "Robert Tibshirani. Regression shrinkage and selection viathe lasso. Journal of the Royal Statistical Society Series B:Statistical Methodology, 58(1):267288, 1996. 7": "Ashish Vaswani, Noam Shazeer, Niki Parmar, Jakob Uszko-reit, Llion Jones, Aidan N Gomez, ukasz Kaiser, and IlliaPolosukhin. Attention is all you need. In Advances in Neu-ral Information Processing Systems. Curran Associates, Inc.,2017. 3 Joshua Vendrow, Saachi Jain, Logan Engstrom, and Alek-sander Madry. Dataset interfaces: Diagnosing model failuresusing controllable counterfactual generation. arXiv preprintarXiv:2302.07865, 2023. 1, 2"
}