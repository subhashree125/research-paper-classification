{
  "Abstract": "In this supplementary material, we provide additionalmaterials in the following aspects:1) solution of theTemporally-smooth Procrustean Alignment (TPA) modeland verification of its validity; 2) detailed solution of theADMM model; 3) additional explanations for spatially-variant deformation modeling; and 4) additional details ofthe experimental setup, supplementation of missing data ex-periments, and more visualization results.",
  ". Introduction": "Non-rigid structure-from-motion (NRSfM) targets at jointlyestimating the deforming 3D shapes and the camera mo-tion from the 2D observation sequence, which is a classi-cal and long-lasting geometric vision problem . In con-trast to the recently booming deep learning based solutions, the optimization based solutions donot rely on training data and can be directly applied to arbi-trary classes such as human, animal, and deforming surface.Even though considerable progress has been made and",
  "&&": ".Overview of our proposed TPA Module.(a) Cam-era motion can be recovered by orthographic and rank-3 con-straints within the matrix factorization framework. (c) TheProcrustean alignment framework uses GPA to resolve the rota-tion ambiguity. (b) We propose the TPA module, which aligns the3D shapes of consecutive frames and corrects the camera motionby the temporal smoothing property. a series of milestones have been achieved , theperformance of NRSfM is still far from satisfactory. Thechallenges mainly lie in 1) the inherent motion/rotation am-biguity requires either explicit camera motion recovery withextra constraint or complex Procrustean Alignment; 2) ex-isting global modeling (i.e., low-rank , union-of-subspace ) of the deforming 3D shape cannot handledrastic spatially-variant 3D deformations.Existing NRSfM statistical prior frameworks can beroughly classified into two categories: 1) explicit motionestimation-based approaches and 2)motion estimation-free approaches . The for-mer usually employs the matrix factorization framework",
  "arXiv:2405.04309v2 [cs.CV] 24 Jun 2024": "and orthographic constraint to solve for camera motion and3D shapes separately. Dai et al. introduced the low-rank constraint into the recovery of camera motion. Ku-mar et al. dig into the correction matrix to improve themotion estimation results by using the smoothing prior ofcamera motions or the fusion of different camera mo-tion sequences . However, these camera motion estima-tion methods have difficulties in tackling the inherent rota-tion/motion ambiguity problem in NRSfM .The latter solves the shapes directly and remedies therequirement of motion estimation. Lee et al. argued that non-rigid shapes can be recovered unambigu-ously under the coordinate with almost no rigid relativemotion. This type of framework resolves the rotation am-biguity through General Procrustean Analysis (GPA) to achieve alignment of the 3D shapes.However, thehigh dependence on the alignment reference shape makesthe model extremely complex and tends to over-penalize non-isotropic deformations.Explicit deforming 3D sequence modeling is another dif-ficulty in NRSfM. The seminal work by Dai et al. re-covers the 3D shape sequence using only the low-rank con-straint. Although the low-rank constraint is valid in mostcases, it is insufficient to model the objects with severespatially-variant deformation . Kumar et al. improve the estimation of low-rank structures but still useglobal low-rank modeling. Some methods tried tointroduce additional combinations of linear basis to modeldrastic deformation, but the lack of effective constraintsmakes the recovery of deformation basis difficult.In this paper, we propose to resolve the above issuesin camera motion and deforming shape recovery from aspatial-temporal modeling perspective. The object of ourstudy is the 2D observation sequences, and this is a com-mon setup for traditional NRSfM . Ex-isting methods do not utilize sequence information well,which can help us deal with the above problems effectively.First, by digging into the temporal smoothing propertyof non-rigid sequences, we propose a novel Temporally-smooth Procrustean Alignment (TPA) module that correctscamera motion through 3D shape alignment.The TPAmodule can reduce the effects of rotation ambiguity asGPA by exploiting the temporal similarity between consec-utive 3D shapes, and it also eliminates the need for ad-ditional modeling of reference shapes as the GPA-basedmethods (cf. ). Second, to tackle the drasticspatially-variant deformations in real-world 3D shape se-quences, we propose to use the spatial information obtainedby analyzing the trajectory space to segment the regionswith different levels of non-rigid deformation. Afterward,we propose a Spatial-Weighted Nuclear Norm (SWNN) op-timization to improve the adaptation performance of low-rank constraint for severe spatially-variant deformation.",
  "Our main contributions are summarized as:": "We propose a Temporally-smooth Procrustean Alignment(TPA) module to estimate 3D deforming shapes and ad-just camera motion by aligning the 3D shape sequenceconsecutively. The TPA module is more conductive tonon-isotropic deformation modeling by remedying the re-quirement of mean shape as alignment reference. We contribute a spatial-weighted approach to enforcethe low-rank constraint adaptively at different locations,which can better accommodate severe spatially-variantdeformation than global low-rank modeling. We develop a unified spatial-temporal modeling frame-work for NRSfM. Extensive experiments across datasetsdemonstrate the superiority of our approach. Ablationstudies show the effectiveness of each algorithm module.",
  ". Matrix Factorization based NRSfM": "Since Bregler et al. first applied the factorization frame-work in non-rigid reconstruction, researchers begun to shifttheir focus from pre-learned modeling methods tothe optimization methods, such as using Metric Projec-tion , deformable surface modeling , andsome priors, e.g., motion states , shape priors ,DCT trajectory basis , etc. However, Xiao et al. pointed out that, unlike the rigid version of factorizationframework , there is an inherent ambiguity in the solu-tion process using only the orthographic constraint, whichwould lead to non-unique shape basis and correspondingcoefficients. But Akhter et al. later proved that inherentambiguity does not affect obtaining a unique result. Basedon this, Dai et al. proposed a new pipeline that em-ploys low-rank constraint on camera motion and shape esti-mation, combined with the solution technique of Brand ,this method successfully achieves an unambiguous shapeestimation using the factorization framework without intro-ducing an overly strong prior.Subsequent researchers have derived a number of dif-ferent solution methods based on the application of low-rank constraints in the factorization framework. Kumar etal. noted that the reconstruction accuracy of 3Dshapes can be improved by preserving the main algebraicfeatures of the matrix in the nuclear norm optimizationprocess. In addition, model 3D shapes usingunion of subspace constraint, model spatial struc-tures using consensus assumptions, and some work repre-sent non-rigid 3D surfaces using manifolds. Thefactorization framework has been shown to be effective inNRSfM, but a number of issues remain. The accuracy of theunique shape obtained under the existing pipeline is com-promised by the inherent ambiguity, and global low-rankmodeling does not well tackle the reconstruction of severelydeformed objects. And this paper intends to fill those gaps.",
  ". Procrustean Alignment for NRSfM": "Parallel to the development of the factorization framework,the alignment framework chose to reduce the impact of theinherent ambiguity on reconstruction by avoiding estimat-ing motion. Torresani et al. used Gaussian distributionas a prior to represent non-rigid shapes and proposed an Ex-pectation Maximization (EM) solving framework. To sepa-rate rigid motion and non-rigid deformation, Lee et al. introduced the General Procrustean Analysis (GPA) algo-rithm to construct a special Procrustean Normalized Dis-tribution (PND) that effectively represents the data proper-ties of non-rigid shapes. Lee et al. added the hiddenMarkov process to PND, strengthening the temporal depen-dence in the shape sequence. Park et al. designed amore extensible regression framework based on PND andapplied it to deep learning method . The separation op-eration of the alignment framework has a significant effecton mitigating the rotation ambiguity than most of factor-ization methods, but on the other hand, the pure alignmentframework fails to capitalize on the advantages of the fac-torization framework as well. Therefore, this paper aims tocombine the advantages of both to obtain better results.",
  ". Problem Formulation and Optimization": "NRSfM aims to recover 3D deforming shape sequence S=[S1; ; SF ]R3F P in the world coordinate and cameramotion R = diag(Ri) R2F 3F from 2D measurementsW = [W1; ; WF ] R2F P , i.e., W = RS , Fand P denote the number of frames and points. The ma-trix factorization model assumes the non-rigid3D shapes can be expressed by the linear combination ofK shape basis Bj, i.e., Si = Kj=1 cjBj, where cj is theshape basis coefficients. Following this assumption, R andS can be estimated by the Singular Value Decomposition(SVD) of W coupled with orthographic constraint. Since Q SO(3), Wi = RiQT QSi always holds, there isan inherent rotation ambiguity in the absence of additionalconstraints, which leads to incorrect estimation of cameramotion and 3D shapes. have proposed a num-ber of effective prior-free methods to recover camera mo-tion and shape sequence, but these methods can not resolvethe rotation ambiguity problem theoretically.Different from the above methods, another class ofmethods estimates alignment rotations by Pro-",
  "where T=I 1": "P 11T is the translation elimination matrix, Sis the mean shape used as the reference shape during align-ment, and Si is the 3D shape in camera coordinate. Suchmethods effectively resolve the rotation ambiguity by sep-arating rigid motion from non-rigid deformation. But fornon-isotropic deformations, variations along certain direc-tions may markedly influence the mean shape, leading to anexaggerated penalization of shapes during optimization.In addition to the reprojection information W in cam-era coordinate, both the factorization framework and Pro-crustean alignment framework are looking for a canonicalcoordinate (i.e., world or alignment coordinate) to enforceextra regularization, such as low-rank. We use S R3F P to denote the sequence of 3D shapes in the camera coordi-nate, and S R3F P is the shape sequence in the canonicalcoordinate. We rethink these two types of frameworks andprovide a new unified framework:",
  "(2)": "where F() denotes the data term, such as reprojectionerror, and G() denotes the regularization term, such aslow-rank or smoothing.P() represents the transforma-tion refinement module, R is the transformation betweenthe camera and canonical coordinates, is the optimizationparameters.R denotes pure 3D rotation transformation,while we have removed scale and translation from measure-ment matrix W by regularization and centralization as .When R is computed in advance and fixed during optimiza-tion, the model (2) degenerates to prior-free methods, suchas . If the optimization goal P() is set to GPA(1) and is defined as {S, S}, model (2) degenerates intothe framework in .",
  ". Temporally-smooth Procrustean Alignment": "Under the matrix factorization framework, the 3D recon-struction results will be affected by camera motion esti-mation as incorrect camera motion estimation may invali-date the underlying low-rank assumption. The Procrusteanalignment methods make the aligned sequence satisfy thelow-rank constraint by minimizing the rigid motion be-tween 3D shapes. Therefore, such methods can obtain im-proved results when they begin with good initialization.In the real world, the nonrigid objects deform contin-uously and smoothly. Therefore, the low rank as well as",
  "(b) Construction for proxy Shape": ". Overview of region segmentation and proxy shape construction. (a) We use DFT to analyze the 3D trajectories, dividing themby comparing the frequency components contained in each trajectory. The figure shows a segmentation result. (b) The geometric center ofthe non-rigid region is set as the super point, and it is linearly combined with nearly rigid points to construct the proxy shape. other deformation regularization constraints should be sat-isfied in the smooth motion sequence. We propose a cam-era motion refinement module called Temporally-smoothProcrustean Alignment (TPA), which aligns the shape se-quence under the smoothness constraint as follows:",
  "i=1RiSi Ri+1Si+12F ,(3)": "where R = diag (Ri) , Ri SO(3). The TPA module(3) estimates alignment matrix R by the principle of mini-mizing the difference between the 3D shapes of consecutiveframes after rotation transformation, as in (b). Dif-ferent from GPA (1), TPA does not need to estimate themean shape of the sequence, which greatly simplifies theoptimization and avoids over-penalizing non-isotropic de-formations. In addition, we have experimentally verifiedthat sequences aligned by the TPA module can have moresimilar low-rank and smoothing properties to the real se-quences compared with GPA, see Sec. 4.3 and .Under the NRSfM problem setting, the TPA module cangradually put the shape sequence in a smooth state by ad-justing the camera motion. Assume that the estimated cam-era poses are Ri, i = 1, , F and define the initializationof the alignment transformation as Rpi = RTi . We denoteRpiSi as Si, where Si is in the camera coordinate. Thenwe use the TPA module to estimate the correction rotationQ = diag(Qi) as follows:",
  "where r(m)i,j= Qimsim,j Qim+1sim+1,j, and (a)": "represents the skew-symmetric matrix of vector a. Once thegradient is calculated, we can use traditional numerical op-timization algorithms to solve model (4), e.g., BFGS, LMF,etc. , see more derivation details and discussions in theSupplementary Material (Supp.) Sec 1.TPA largely separates the rigid motion between consec-utive frames in the sequence S and makes it gradually con-verge to a smooth state. After reducing the interference ofrigid motion, we can better utilize the low-rank constraint torecover non-rigid deformation of the aligned sequence QS.In the following, we introduce the shape estimation methodand unify them afterward.",
  "Spatial-Weighted Nuclear Norm": "In real-world scenarios, low-rank regularization can han-dle many non-rigid deformation situations but always over-penalize drastic deformations. In the absence of priors toreconstruct the deformation, we can give higher degrees offreedom for shape recovery by relaxing the low-rank con-straint. An object whose overall or local deformation is verydrastic can lead to its 3D shape sequence S in the world co-ordinate not satisfying the low-rank constraint. But we cantransform its spatial structure by linearly combining the tra-jectories of S to degenerate the object to a low-rank state.Given the affinity matrix RP P , we define the sequenceof proxy shape as S = S. We can then utilize low-rankconstraint to recover the proxy shapes, which in turn re-duces the strength of the constraint in the region of severedeformation to better recover S. We use the nuclear norm with the rearrangement op-erator g() to build the low-rank constraint, and denotethe reshuffled sequence as S = g(S) RF 3P . Differ-ent from existing methods, we propose a Spatial-WeightedNuclear Norm (SWNN) optimization model that imposeslow-rank constraint on the reshuffle of the proxy shapesS =g(S) instead of S, so the new low-rank optimizationmodel can be written as:",
  "minSS.(6)": "The key to the model (6) is how to design the spatial weightmatrix . Next, we present a method of constructing proxyshapes Si, i = 1, , F to relax the low-rank constraint onsevere deformation regions. We first introduce an algorithmfor segmenting objects according to the level of deformationin different regions. Based on this, a kernel based methodfor the construction of proxy shapes is proposed.",
  "Nearly Rigid Region Segmentation": "In reality, not all regions of non-rigid objects undergo thesame deformations, but are spatially-variant. For example,a talking mouth on a human face will undergo more severedeformation than the nose. Thus different regions shouldfit the low-rank regularization differently. In this section,we introduce the partition algorithm for different regions ofnon-rigid objects, see a for the process.We define Tj = {st,j R31}Ft=1 as the j-th column ofshape sequence S, which represents a 3D trajectory. Thex-y-z coordinates of a 3D trajectory can be viewed as timedomain signals, and can be transformed into the frequencydomain by Discrete Fourier Transform (DFT):",
  "d(k/F) = F 1/2 Ft=1 st,je2itk/F , k = 0, , F 1, (7)": "we define k = k/F, which symbolize the different fre-quency components. Intuitively, when the time domain sig-nal changes drastically, its corresponding frequency domainsignal will contain more high-frequency components. Wecan compare the severity of different time domain signalchanges by calculating the intensity of different frequencycomponents of the frequency domain signal. Here we usethe scaled periodogram to calculate the intensity of the sig-nal in the frequency domain. The formula is as follows:",
  "F |d(k)|2 , k = 0, , F 1.(8)": "Then, we compare {Pg(k)}k and filter out the frequencycomponents k corresponding to the first mf(=2) maxima.Their average value dfj = k/mf is noted as the defor-mation frequency of the trajectory. We sort all the pointsaccording to the magnitude of the deformation frequencies{dfj }Pj=1 from low to high, defining the points with low fre-quency of r100% as nearly rigid points, and denote the set of their subscripts as Ar. Here, r is a hyperpa-rameter that depends on the deformation properties.In this way, the whole object is divided into a nearlyrigid region and a non-rigid region, as the example shownin a. We summarize the operation above as:",
  ",(10)": "where () represents a feature map, , is the vector innerproduct. We use the inner product to compute the correla-tion between the vectors after the feature mapping as thecombination weights between different points in the space.In order to increase the difference between the low-rankconstraint effect on the nearly rigid and non-rigid regions,we set up the feature mapping () in the following form:",
  "where 1i is a 0-1 vector in P + 1 dimensions, taking 1only in the i-th dimension. r is a constant, and nr is setto 1/": "(1r)P. Here we provide a brief discussion ofmodel (10). When r = 1, i.e., all points are in set Ar, Siis just a shrink state of the original shape. If r < 1, allpoints in the non-rigid region degenerate into the same su-per point (as shown in b). The super point preventsthe low-rank constraint from acting directly on each pointin the non-rigid region, which can help reduce the intensityof the low-rank constraint on the non-rigid region. In addi-tion, the proxy shape calculation model (10) ensures that thesuper point and nearly rigid points remain a unified whole2.",
  ". Complete Model and Solution": "In this section, we integrate the complete model with theunified framework (2) and perform the solution. For thedata term F, we use the reprojection constraint as the op-timization target. The SWNN model (6) is set to the regu-larization term G and constrains the shape sequence undercanonical coordinate. The link between the camera coordi-nate and the canonical coordinate is constructed through the",
  "S = g(S)Si = QiSi, i = 1, , FSi = RpiSi, i = 1, , F": "(12)where = diag(i), i R23 is the camera projec-tion matrix, and we use orthogonal projection as .S R3F P is the 3D shape sequence under the cameracoordinate. Then we improve the initialized camera motionRp by estimating Qi SO(3) and compute the 3D shapesequence S R3F P in the canonical coordinate. Finally,we introduce the kernel based weight matrix to constructproxy shapes that more satisfy the low-rank constraint.We optimize the model (12) by ADMM , and the La-grange multiplier of the whole model is as follows:",
  "(13)": "where = {S, S, S, S, Q} denotes the variables to be up-dated, {Yn}3n=1 are Lagrange multipliers. For the updateof S, we use the rectification algorithm in . The dif-ference is that when calculating the weights , we truncatethe singular values according to the shape basis dimensionKs and normalize the weights. In real scenes, the capturedimages are often obscured and it is difficult to observe allthe keypoints in each frame. Our proposed framework canhandle the problem of missing points by simply adding vis-ible information to the data term. More details and formulasare provided in the Supp. Sec 2.",
  ". Implementation Details and Evaluation Metric": "Implementation Details.The parameter settings in theADMM optimization algorithm are the same as in the Or-ganic Priors Method (OPM) .The model (12) is anon-convex optimization that requires the initialization ofcamera motion and 3D shapes. We use the camera mo-tion estimation algorithm in BMM to initialize Rp.To build the weight matrix , a good initialization of theshape sequence S is needed to calculate the segmentationof the non-rigid region. Since our model is a unified frame-work, there is no need to use other methods, which can beaccomplished using only model (12). As shown in Algo-rithm 1, we first fix the correction rotation Q and set tothe Identity matrix. After convergence, the weight matrixis calculated and all parameters are well initialized. Inaddition, d in Algorithm 1 is generally 1e2 or 1e0, and = {1, 2, 3, r, r, Ks} is adjusted to the dataset (seeSupp. Sec 4 for more settings).Evaluation Metric. We follow the setup in using themean normalized 3D reconstruction error metric to evalu-ate the shape reconstruction results on the motion capturebenchmark (MoCap), semi-dense, and H3WB dataset. Themetric is defined as e3d = 1 FFi=1SestiSgtiF /SgtiFand Sesti, Sgti denote the estimated 3D shape and the corre-sponding ground-truth (GT) value respectively. We removethe global ambiguity as in before computingthe 3D reconstruction error. To evaluate our approach onthe NRSfM benchmark dataset , we use the officiallysupplied metric script.",
  ". Datasets and Results": "MoCap Benchmark Dataset. This dataset is a standardbenchmark for NRSfM consisting of 8 real sequences.Akhter et al. introduced five sequences: Drink, Pickup,Yoga, Stretch, and Dance. And the other three, Face, Walk-ing, and Shark, were presented by Torresani et al. .Tab. 1 and a demonstrate the reconstruction errors e3dof our method compared to other methods and some visualresults, respectively. As shown in Tab. 1, our method per-forms best or second-best across multiple sequences, indi-cating that our method is able to accommodate diverse typesof deformation. Our method also achieves comparable re-sults in sequences such as Shark and Walking, outperform-ing the pure low-rank constraint methods .NRSfM Challenge Dataset.Jensen et al. recentlyproposed a new challenging benchmark. This dataset con-tains five types of non-rigid deformation: Articulated, Bal-loon, Paper, Stretch, and Tearing. Each subject contains sixobservation sequences captured by different types of cam-era motion, i.e., circle, flyby, line, semi-circle, tricky, andzigzag. For each subject, we calculate the reconstruction . 3D reconstruction errors on MoCap dataset. Our method shows advantages over many matrix factorization methods andProcrustean alignment methods. The second-best results are underlined, and the shape basis dimension Ks is shown in brackets.",
  "Mean0.06440.04980.03630.06040.04300.0312": "errors under the six camera motions and take the averageas the final error for that subject. The quantitative compari-son with other methods and the qualitative visualization areshown in Tab. 2 and b. Our method achieves the bestresults on Articul., Stretch, and Tearing, and also has highreconstruction accuracy on Balloon and Paper. The numer-ical results further show the advantages of our method onmulti-category deformation reconstruction.Semi-dense Dataset.We evaluated our method on the",
  "(c) Visualization on Semi-dense and H3WB Dataset": ". (a) Visualization of Shark and Dance results. (b) Visu-alization of Balloon and Articulated results. Top row is the imagein dataset, and bottom row is the 3D reconstruction shape. (c) Vi-sualization of Rug and Eating2 (Fixed-type) results. kinect paper, rug, table mat datasets (191, 159, 60frames and 1503, 3912, 1500 keypoints respectively). Wecompared our method with other well-known sparseNRSfM methods (PND fails on this dataset due to ex-cessive computational overhead caused by the large numberof points), see the results in Tab. 3 and c. We denoteour method that initializes Rp using the modified algorithmin as Our(I). Our proposed model is also effective in re-ducing the reconstruction error on semi-dense dataset. Ourmethod can significantly reduce the effect of poor cameramotion on shape estimation and also further improve recon- . Comparison of reconstruction errors with and without SWNN module. The table shows the comparison results on the MoCapdataset and the Articul.(circle), Articul.(flyby), Stretch(zigzag) sequences in NRSfM Challenge dataset.",
  "Ours(w/)0.00310.01260.01090.01140.09210.01442.34423.82290.6460Ours(w/o)0.00500.01370.01200.01320.09320.01613.56264.80420.7341": ". Shape alignment test for the TPA module. We comparethe low-rank and smoothing properties of GT non-rigid sequences,randomly rotated disrupted sequences, and sequences aligned byTPA or GPA. The results show that the TPA-aligned sequenceshave more similar properties to the GT sequences. struction accuracy with better motion initialization.H3WB Dataset.Human3.6M 3D WholeBody (H3WB)dataset is an entire human body 3D dataset, includ-ing face, hands, body, and feet. H3WB is an extension ofHuman3.6M and contains multiple categories of com-mon life actions such as Directions, Eating, and Smoking.The human body in H3WB is annotated with 133 keypoints,17 for body, 6 for feet, 68 for face, and 42 for hands. Weselected five sequences in H3WB and processed them toobtain a new evaluation dataset: Eating2, Smoking1, Di-rections, Smoking, Waiting2 (185, 265, 245, 180 and 335frames, respectively). We simulated three types of cam-era motion: fixed-type, one-circle-type, and multi-circle-type, then generated three sets of 2D observations for test-ing by orthogonal projection, see Supp. Sec 4 for more de-tails3. As manifested in Tab. 4, our method shows betterreconstruction results than other prior-free and procrustean-based methods (Visualization illustrated in c). Whenthe camera captures the object from as many different view-points as possible (multi-circle-type), our method is able toreconstruct the 3D structures very accurately. Moreover,when the camera is fixed (fixed-type), ours can also givemore reliable results.",
  ". Ablation Study": "Role of TPA Module. First, we verify the alignment func-tion of TPA module (4) on Pickup and Yoga sequences. Werandomly sample Lie algebra pn R3F from Gaussiannoise N(0, 0.1), and then map it to a 3D rotation matrix 3The results we reported in conference version of the paper is actu-ally just the reconstruction error on Fixed-type camera motion setting, weadded more results here to domenstrate the effectiveness of our method.",
  ". (a) Shape errors on noisy sequences. (b) Experiment for3D reconstruction on missing data": "Rd R3F 3F using Rodrigues rotation formula. We de-fine the shape sequence disrupted by random rotations asSnoise = RdSgt, where Sgt R3F P is the GT sequencein the world coordinate. We realigned the sequence with theTPA module and compared the result with GPA . compares the nuclear norm (i.e., g()) and the first-ordersmoothness of Sgt, Snoise and the sequences alignedby the two algorithms, showing that the TPA-aligned se-quence has the most similar properties to the GT sequence.We also test the stability of the TPA module for cam-era motion initialization. We used the same approach tosample perturbed rotations Rd with standard deviation of 0.1, 0.2, and 0.5. Adding ambiguity Rd to the cameramotion initialized by BMM , we then compare the fourmethods BMM, R-BMM, BMM+Smooth (Add first-ordersmoothness constraint), BMM+TPA. For each , we exper-imented five times and calculated the mean, the results areshown in Tab. 6. Compared to other methods, the TPA mod-ule maintains its effectiveness even when a large deviationhas been applied to the camera motion. This shows that ourmethod can effectively deal with the rotation ambiguity incamera motion estimation and can improve the effective-ness and stability of the smoothing constraint.Effectiveness of SWNN. We compared the two cases of us-ing and not using (with = I) the SWNN module in model(12). The comparison results are reported in Tab. 5. SWNNimproves the accuracy of 3D shape recovery in most de-formation settings. The accuracy improvement mainly de-pends on the segmentation result and the smoothing prop-erty of the sequence, for more analysis see Supp. Sec 3. Performance on Noisy and Missing Data. We follow theapproaches in to add noise and occlusion to the data.For missing data, we first complete the measurement ma-trix by and then run our method. shows that ourmethod performs better than others in most cases4.",
  ". Conclusion": "In this paper, we have proposed a spatial-temporal modelingframework for NRSfM. We proposed a Temporally-smoothProcrustean Alignment module to tackle the rotation ambi-guity. Furthermore, we introduced a spatial-weighted nu-clear norm model with the shape proxy strategy to ensurethe effectiveness of low-rank constraint in coping with se-vere spatially-variant deformations. Our method achievessuperior 3D reconstruction performance across a wide rangeof deformation sequences. Moreover, there is still much re-search to do in the future on more accurate trajectory seg-mentation and explicit modeling of complex deformation.Acknowledgements: This research was supported in partby the National Natural Science Foundation of China(62271410), and the Fundamental Research Funds for theCentral Universities.",
  "See Supp. for more tests on TPA, SWNN and Missing Data": "Ricardo Cabral, Fernando De la Torre, Joao P Costeira, andAlexandre Bernardino. Unifying nuclear norm and bilinearfactorization approaches for low-rank matrix decomposition.In Int. Conf. Comput. Vis., pages 24882495, 2013. 9 Geonho Cha, Minsik Lee, Jungchan Cho, and Songhwai Oh.Reconstruct as far as you can: Consensus of non-rigid recon-struction from feasible regions. IEEE Trans. Pattern Anal.Mach. Intell., 43(2):623637, 2019. 2",
  "Jose Pedro Iglesias,Carl Olsson,and Marcus Valto-nen Ornhag.Accurate optimization of weighted nuclearnorm for non-rigid structure from motion.In Eur. Conf.Comput. Vis., pages 2137, 2020. 7": "Catalin Ionescu, Dragos Papava, Vlad Olaru, and CristianSminchisescu. Human3.6m: Large scale datasets and predic-tive methods for 3d human sensing in natural environments.IEEE Trans. Pattern Anal. Mach. Intell., 36(7):13251339,2013. 8, 7 Sebastian Hoppe Nesgaard Jensen, Mads Emil Brix Doest,Henrik Aans, and Alessio Del Bue. A benchmark and eval-uation of non-rigid structure from motion. IEEE Trans. Pat-tern Anal. Mach. Intell., 129(4):882899, 2021. 6 Haorui Ji, Hui Deng, Yuchao Dai, and Hongdong Li. Unsu-pervised 3d pose estimation with non-rigid structure-from-motion modeling. In IEEE Winter Conference on Applica-tions of Computer Vision (WACV), pages 33143323, 2024.1",
  "Suryansh Kumar, Yuchao Dai, and Hongdong Li. Spatio-temporal union of subspaces for multi-body non-rigidstructure-from-motion.Pattern Recognition, 71:428443,2017. 1, 2": "Suryansh Kumar, Anoop Cherian, Yuchao Dai, and Hong-dong Li. Scalable dense non-rigid structure-from-motion: Agrassmannian perspective. In IEEE Conf. Comput. Vis. Pat-tern Recog., pages 254263, 2018. 2 Minsik Lee, Jungchan Cho, Chong-Ho Choi, and SonghwaiOh. Procrustean normal distribution for non-rigid structurefrom motion. In IEEE Conf. Comput. Vis. Pattern Recog.,pages 12801287, 2013. 1, 2, 3, 7, 8, 9",
  "Marcus Valtonen Ornhag, Jose Pedro Iglesias, and Carl Ols-son.Bilinear parameterization for non-separable singularvalue penalties. In IEEE Conf. Comput. Vis. Pattern Recog.,pages 38973906, 2021. 7": "Marco Paladini, Alessio Del Bue, Marko Stosic, MarijaDodig, Joao Xavier, and Lourdes Agapito. Factorization fornon-rigid and articulated structure using metric projections.In IEEE Conf. Comput. Vis. Pattern Recog., pages 28982905, 2009. 2, 10 Marco Paladini, Alessio Del Bue, Joao Xavier, LourdesAgapito, Marko Stosic, and Marija Dodig. Optimal metricprojections for deformable and articulated structure-from-motion. Int. J. Comput. Vis., 96:252276, 2012. 2 Shaifali Parashar, Daniel Pizarro, and Adrien Bartoli. Iso-metric non-rigid shape-from-motion with riemannian geom-etry solved in linear time. IEEE Trans. Pattern Anal. Mach.Intell., 40(10):24422454, 2017. 7",
  ". Experiments for TPA": "In this subsection, we verify the effectiveness of the TPAmodule. Lets revisit the setting of the experiments. Werandomly sample Lie algebra pn R3F from Gaussiandistribution N(0, 0.1), and then map it to a block diagonalmatrix Rd R3F 3F consisting of 3D rotations using theRodrigues rotation formula. We define the shape sequencedisrupted by random rotations as Snoise = RdSgt, whereSgt R3F P is the GT sequence in the world coordinate.We realign the sequence using the TPA and GPA mod-ules and compare their results. We performed these experi-ments on the Pickup, Yoga, Stretch, and Drink sequences inMoCap benchmark and the results are shown in .",
  "Drink": ". Experiments for testing the alignment capability of TPA module. (a) Visualization of the shape sequences Snoise. (b) Visu-alization of the TPA-aligned shape sequences. (c) Visualization of the GPA-aligned shape sequences. (d) The low-rank and smoothingproperties of GT non-rigid sequences Sgt, randomly rotated disrupted sequences Snoise, and sequences aligned by TPA or GPA. We centralized all the 3D shapes in the sequence andplotted them in the same coordinate. Column (a) in isthe disrupted sequence Snoise. Columns (b) and (c) are se-quences after TPA or GPA alignment, respectively. Column(d) shows the low-rank and smoothing properties of realsequences Sgt, noisy sequences Snoise, TPA-aligned se-quences, and GPA-aligned sequences. demonstratesthat the TPA module can efficiently align the 3D shape se-quences. Compared with GPA, the TPA-aligned sequencesare more similar to the real 3D shape sequences in terms oftheir low-rank and smoothing properties.Non-rigid deformation mixed with rigid motion cannotbe accurately estimated using the low-rank constraint. Asmanifested in (d), shape sequences after alignmentby the TPA module have lower nuclear norm and smooth-ness. From one hand, this demonstrates that the TPA mod-ule can effectively separate rigid motion from non-rigid de-formation. From the other hand, the properties of the TPA-aligned sequence make it can be better recovered by thelow-rank and smoothing constraints. In summary, we utilizethe low-rank constraint to recover the TPA-aligned shapesequence, rather than directly applying the low-rank con-straint under the coordinate defined by the estimated cameramotion .",
  "F +Y3, S RpS,": "(20)where = {S, S, S, S, Q} denotes the variables to be up-dated, {Yn}3n=1 are the Lagrange multipliers. We then givethe update formula for each optimization variable in .Solution for S. Selecting all the optimization terms inmodel (20) that are related to S, the optimization modelfor S is obtained as:",
  "(24)": "We set the shape basis dimension Ks according to the as-sumption of linear basis combination and truncate the sin-gular values. We can better measure the importance of dif-ferent singular values by adjusting the weights through nor-malization.Solution for S. The solution model for the optimizationvariable S can be expressed as follows:",
  "(33)": "Solution for Q. We have already discussed how to solve theTPA module in Sec. 1.1. But in model (20), the variables in are coupled and need to be optimized alternatively, sothe updating formula for Q needs adjustments. The opti-mization terms in model (20) containing the optimizationvariable Qi, i = 1, , F are:",
  "(Qisi,j)T 3r(1)i,j r(0)i,j+ ri,j + Yi2,j": "(35)Therefore, we can still update Qi using the TPA optimiza-tion algorithm in Sec. 1.1, and only need to adjust the resid-ual vector ri to satisfy the descent direction.After discussing the solution formulas for each variable,we give the complete optimization Algorithm 2. Since noclosed-form solution for updating Q exists, another iterativeoptimization must be embedded in the ADMM algorithm.In experiments, we found that only 1 to 10 iterations areneeded to update Q well.",
  ". Model with Occlusion": "In real-world scenes, the captured images are often ob-scured and it is difficult to observe all the keypoints in eachframe. Assume oi R1P , i = 1, , F is the mask vec-tors and oi,j = 1 if j-th point in the i-th frame is visible,otherwise 0. Then to solve the occlusion problem, we intro-duce the mask matrix OR2F P and correct the data termconstraint F() as follows:",
  "O (W S)2F ,(36)": "where O = [12 o1; ; 12 oF ] R2F P . Since theocclusion is different for each frame, centralization for theobservation matrix W does not guarantee that the transla-tion between shapes is eliminated. Therefore re-centeringof the shapes is required before alignment using the TPAmodule, which only requires modification of S:",
  "(38)": "The update formulas for variables can be obtained by im-itating the above solution procedure. Since the improve-ment of the model is only related to the optimization vari-able S, S, we only need to adjust their update formulas.Solution for S under occlusion. S in model (38) needs tobe centralized and then transformed by rotation Rpi to getS. Thus we only need to replace S in Eq. (31) with ST, i.e.:",
  ". Supplement to Spatially-variant Modeling": "In this section, We provide an additional explanation of theconstruction of the proxy shape and how it plays a role inoptimization, refer to .1) Definition of proxy shape.We divide the non-rigidobject into two regions with different deformation degreesthrough frequency domain analysis of 3D trajectories. Thenby spatial weighting, we merge the single super pointdegenerated from Non-Rigid part with Nearly Rigidpoints to form the proxy shapes, i.e., S = S. The weightmatrix defined by the feature mapping () (Eq. (12) inthem main text) is rank-deficient (when r < 1), so the re-sultant proxy sequence S has fewer degrees of freedom thanS and more satisfies the low-rank constraint.2) How SWNN works. We enforce the low-rank constrainton proxy shapes and update new shapes by Eq. (27). Thenew S is mainly composed of S after low-rank regulariza-tion and S after smoothing regularization. Since is rank-deficient, the low-rank constrained S after inverse transfor-mation only retains the structural information of nearly rigidpart. Therefore, S updates nearly rigid part mainly throughlow-rank, and non-rigid part is fine-tuned by S.Our method combines low-rank and smoothing con-straints through spatial weighting, which improves theaccuracy of the reconstruction by avoiding the over-penalization of localized drastic deformations with low-rank constraint. To verify the validity of the combination,we designed the comparison experiment presented in .We compare the reconstruction error of Eq. (20) with meth-ods using only low-rank or smoothing constraints on theNRSfM Challenge dataset. For the low-rank-only method,we compared with R-BMM , which is an improvementon the prior-free classical method BMM . For theapproach using only the smooth prior, we removed the low-rank constraint from Eq. (20) and compared with it, i.e.:",
  ". Three motion types for H3WB Dataset generation": "As shown in , the reconstruction error of our methodis lower than that of the low-rank-only/smooth-only methodon all types of deformation, and there is a significant im-provement on Articul., Balloon and Tearing.Our approach can effectively couple low-rank andsmoothing constraints to improve the stability of the algo-rithm over different types of deformations. Moreover, sta-tistical prior methods tend to be sensitive to the statisticalproperties of the data, which are also related to the com-plexity of the corresponding object deformation. In otherwords, it is not enough to only mine the smooth prior tocomplement the low-rank constraints, so finding constraintsthat are more general and insensitive to the statistical prop-erties of the data is a feasible direction for improvement.",
  ". Implementation Details": "For parameters in ADMM Algorithm 2, we refer to toinitialize =1e4, max =1e10, =1.1 and set {Yn}3n=1to zero matrices. The weights 1, 2, 3 of the optimizationobjective (20) are set to 1, 0.1, 0.1 by default. We can adjustthe sizes of 2, 3 according to the shape sequences low-rank and smoothing properties. In addition, we found ifthe shape sequence does not satisfy the low-rank property",
  "well, increasing the weight 1 of the reprojection term caneffectively improve the reconstruction results, e.g., 1 =1e1": "generally on the NRSfM Challenge dataset and 1 =1e2 onkinect and rug in the Semi-dense dataset. For the estimationof proxy shape, we adjust the ratio of nearly rigid points rbetween 0 to 1 depending on the deformation characteristicsof the object. r is set to 1 3 on Mocap and NRSfM Challengedatasets and 0 on Semi-dense and H3WB datasets.As described in Sec. 3, r determines the optimizationapproach used for different regions of the 3D structure, sor should depend on the specific characteristics of the ob-jects deformation, e.g., spatial coherence, continuity, etc. Iadopted a testing interval of 0.2 for parameter selection ini-tially, followed by a finer search around promising resultsusing a step size of 0.1. This granularity proved sufficientfor achieving good outcomes, eliminating the need for fur-ther refinement in the search steps. The stability test for ourmethod on r is illustrated in . In most cases, the al-gorithm is stable with respect to r once a rough selectioninterval has been determined, and thus careful screening ofr is not necessary. When we have a large amount of data,we can segment the keypoints by learning a certain distri-bution without setting hyperparameters, like .",
  ". H3WB Dataset Processing": "The H3WB dataset is an entire human body 3D datasetextended from the H36M dataset .However, thisdataset provides 2D annotations and their corresponding3D structures frame by frame rather than in a sequence.We screened with the criterion of being as contiguous aspossible and obtained five sequences from S1 Eating2, S6Smoking, S6 Smoking1, S6 Directions, and S7 Wait-ing2. Since the motion amplitude of these sequences is vast,we remove the frames with significant mutations and usespline functions to interpolate the remaining parts to ob-tain five more realistic human action sequences: Eating2(185 frames), Smoking (180), Smoking1 (265), Directions(245), and Waiting2 (335). To obtain the coordinates of the2D keypoints under the orthogonal projection model, weset up three camera motion types: Fixed-type, One-circle-type, Multi-circle-type (as in ). 1) For Fixed-type,the camera is fixed to a certain viewpoint; 2) For One-circle-type, assume that the video has F frames and the camera ro-tates at speed 1 F/frame around a direction vertical to theground. In other words, the camera orbits the object exactlyone time during its deformation; 3) For Multi-circle-type,we keep the angular velocity of the camera motion fixed at5/frame in reference to , i.e., the camera goes aroundthe object every 120 frames. Theoretically, the difficulty ofsequence reconstruction is ranked Fixed-type>One-circle-type>Multi-circle-type.We show a partial 3D shape sequences of the H3WBNRSfM dataset in . We used the experimental setup",
  ". Qualitative Results on the NRSfM Challenge Benchmark. The first row shows the images in the dataset, and the second rowshows the reconstruction results of our method compared to the GT": ". Qualitative Results on the Semi-dense and H3WB dataset (Fixed-type). The reconstruction results of our method on the Semi-dense dataset are closer to the GT shapes, while the H3WB dataset is very challenging and cannot yet be accurately reconstructed. in Sec. 1.2 to test the low-rank and smoothing properties ofthe H3WB dataset, and the results are displayed in .The sequences in the H3WB dataset generally have highernuclear norm and first-order smoothing errors compared tothe pickup sequence in Mocap. Recovering the 3D shapesin the H3WB dataset using low-rank and smoothing con-straints is more complicated. However, it is worth notingthat the TPA-aligned sequences have better low-rank andsmoothing properties than the GT sequences, which some-what guarantees the validity of the low-rank regularization.",
  ". Additional Experiments on Missing Data": "In reality, the movement of an object often leads to occlu-sion of different regions, resulting in missing 2D observa-tions obtained from camera shots. Therefore, the stabilityof the algorithm on the missing dataset is significant. Weshow some tests on missing data in the main text, and wewill add more quantitative results in this section.",
  "(e) Articul.(f) (0.1)(f) Stretch(z) (0.1)": ". Stability test for hyperparameter r on different se-quences. Straight lines indicate the results without the SWNNmodule and broken lines indicate the reconstruction errors for dif-ferent r settings. To the right of the sequence names are ther-values corresponding to the results reported in the main text. 2D observation matrix W. Before reconstruction, we firstsolve the low-rank approximation of the observation matrixto complement it , which is important for the initializa-tion of the camera motion. Tab. 7 shows the test resultson the remaining sequences of the Mocap dataset and theH3WB dataset. Our method achieves the best performanceon sequences other than Shark and Walking. The experi-mental results show that the reconstruction errors on datawith and without occlusion display consistency. And thecomparison between them indicates that our method stillpossesses stability under random occlusion settings (around30% occlusion).Simulating occlusion by randomly adding masks isfriendly to the recovery of observation matrix, whereas the",
  "(b) Smoothing Property of Shape Sequences in H3WB Dataset": ". Analyzing the low-rank and smoothing properties ofshape sequences in the H3WB dataset. The black dotted line rep-resents the values of the metrics for the pickup sequence in theMocap dataset. The comparison reveals that the sequences in theH3WB dataset have a greater magnitude of motion and are moredifficult to recover using low-rank and smoothing constraints.",
  "occlusion scenario in reality tends to be more complex. Wetested on the real occlusion data provided by the NRSfM": "Challenge Dataset, and the results are shown in . Thefigure shows the reconstruction error comparison with theCSF2 on two sequences Balloon and Stretch. Our ap-proach is superior in terms of mean performance, regardlessof whether the data is occluded or not. In addition, the oc-clusion rate is the main factor affecting the performance ofthe algorithm. The average occlusion rate under all cameramotion types for Balloon is 38%, while for Stretch it is 13%.As a result the methods accuracy degradation is more obvi-ous on Balloon. Apart from the occlusion rate, the accuracyof our method also relies on the results of matrix comple-tion. Matrix completion based on the low-rank assumptiontends to fail for some special occlusion scenarios, e.g., theobject is completely invisible at some moments (such as Ar-ticulated/tricky in NRSfM Challenge Dataset, the object iscompletely occluded in the first 35 frames) and excessiveocclusion (such as Tearing/tricky with the occlusion rate of56%). Searching for more robust matrix-completion algo-rithms or updating the observation matrix in iterations are potential solutions."
}