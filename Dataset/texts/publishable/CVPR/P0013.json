{
  "Abstract": "End-to-end driving systems have made rapid progress,but have so far not been applied to the challenging newCARLA Leaderboard 2.0. Further, while there is a largebody of literature on end-to-end architectures and trainingstrategies, the impact of the training dataset is often over-looked. In this work, we make a first attempt at end-to-enddriving for Leaderboard 2.0. Instead of investigating ar-chitectures, we systematically analyze the training dataset,leading to new insights: (1) Expert style significantly af-fects downstream policy performance. (2) In complex datasets, the frames should not be weighted on the basis of sim-plistic criteria such as class frequencies. (3) Instead, es-timating whether a frame changes the target labels com-pared to previous frames can reduce the size of the datasetwithout removing important information. By incorporatingthese findings, our model ranks first and second respectivelyon the map and sensors tracks of the 2024 CARLA Chal-lenge, and sets a new state-of-the-art on the Bench2Drivetest routes. Finally, we uncover a design flaw in the cur-rent evaluation metrics and propose a modification for fu-ture challenges. Our dataset, code, and pre-trained mod-els are publicly available at",
  ". Introduction": "Imitation Learning (IL) for end-to-end autonomous driv-ing has seen great success in recent work on the CARLAsimulator .A key ingredient contributing to this isthe scalability of IL with increased training data, whichis now straightforward to collect as a result of steadyprogress in planning algorithms for CARLA . However, with the introduc-tion of the CARLA Leaderboard 2.0, driving models nowface 38 new complex scenarios. These require driving athigh speeds, deviating from the center of the lane, or han-dling unexpected obstacles. The best planning algorithm ofLeaderboard 1.0 does not solve these new scenarios,making it harder to collect the high-quality driving demon-",
  "strations needed for training IL models. As a result, thereare no existing IL-based methods for Leaderboard 2.0": "In this work, we present the first attempt to tackleLeaderboard 2.0 with IL. To collect training data, we lever-age the recently open-sourced PDM-Lite planner,which can solve the new Leaderboard 2.0 scenarios. Wethen train a simple existing IL model, TransFuser++ ,with minimal changes to its architecture and training objec-tive. Instead of the model, we focus on a critical but un-derstudied aspect of IL the training dataset. In particular,the impact of factors besides the dataset scale, such as thediversity of the training distribution, is nuanced and not yetwell understood. We conduct a systematic analysis of ourdriving dataset, leading to multiple new insights. First, the experts driving style, in addition to its perfor-mance, significantly influences its suitability for IL. To de-velop an effective expert, it is important to base the expertsbehavior on signals that are easily observable and inter-pretable by the IL policy, rather than relying excessively onprivileged inputs. This behavior also resembles how humandrivers perceive and react to their environment. Second, wefind the use of frequency-based class weights, a commonapproach to facilitate learning of classification tasks on im-balanced datasets, detrimental for target speed prediction inautonomous driving. Over-represented classes do not repre-sent a single \"uninteresting\" mode of the data distributionin contrast, they may contain a mixture of both uninterest-ing (e.g., braking while waiting at red lights) and crucialparts of the dataset (e.g., braking for obstacles). Finally, westudy data filtering as an alternative means to assigning theimportance of frames, by which we reduce our dataset sizeby 50% while maintaining performance. Based on these findings, we train a model which safelyhandles urban driving in diverse scenarios to rank second inthe 2024 CARLA challenge and first on the Bench2Drivetest routes . We then theoretically demonstrate how theperformance metrics used by the leaderboard inadvertentlyencourage participants to terminate evaluation routes pre-maturely, and propose changes to the metrics that can solvethis problem for future challenges. An extended report ofall our experiments and findings is available at this link.",
  ". Preliminaries": "In this section, we provide an overview of our task and base-lines. The task involves urban navigation along routes withcomplex scenarios. Each route is a list of GNSS coordinatescalled target points (TPs) which can be up to 200 m apart. Metrics. For the following experiments, we use the officialCARLA closed-loop metrics. Our main metric is the Driv-ing Score (DS) which multiplies Route Completion (RC)with the Infraction Score (IS). RC is the percentage of theroute completed. IS is a penalty factor, starting at 1.0, whichgets reduced multiplicatively with each infraction. Benchmark. To train and evaluate agents, Leaderboard 2.0provides 90 training routes on Town12 and 20 validationroutes on Town13 which on average are 8.67 km and 12.39km long respectively. Each route contains around 100 sce-narios, distributed as shown in . We split them intoshort routes, each containing only a single scenario. This al-lows for more accurate performance evaluation per scenariotype. After splitting, we sample up to 15 routes per scenariotype without replacement to create the Town13 short bench-mark. There are 38 scenario types, but in some cases, fewer(or no) routes are available, which gives a total of 400 routesfrom 36 scenarios in this benchmark. As the calculation ofMinSpeedInfractions is unsuited to short routes, we excludethem from the IS metric on Town13 short. Training dataset. We reproduce TransFuser++ on ourbenchmark using data collected with the PDM-Lite expert. We choose PDM-Lite as it achieves state-of-the-art DS on the official validation routes. Unlike other con-current Leaderboard 2.0 planners , it is also pub-licly available and possible to modify. We sample from theshortened training routes with replacement to obtain a setof 50 routes per scenario, on which we collect a trainingdataset using our expert (198k frames). The dataset containsRGB images with a resolution of 384x1024 pixels, LiDARpoint clouds, and the training labels needed for TF++ (pathcheckpoints, expert target speed, and auxiliary labels suchas BEV semantics and vehicle/pedestrian bounding box pre-dictions). Additionally, we collect data on Towns 01-05and 10, which contain the six scenarios from Leaderboard",
  ". PDM-Lite . This open-source rule-based plannersolves all 38 scenarios of CARLA Leaderboard 2.0": "1.0 (139k frames), for a total of 337k frames. For the finalleaderboard submissions, we also include training data fromthe provided validation routes on Town13 (50 short routesper scenario), adding 194k frames (531k in total).PDM-Lite is a rule-based approach for collectingdata in Leaderboard 2.0. Inspired by PDM-Closed , itconsists of six stages (): First, it creates a dense path of spatially equidistant pointsusing the A* planning algorithm, given sparse TPs fromthe simulator. For new scenarios that require leaving thispath, a short segment of the route where the scenario willbe spawned is shifted laterally towards an adjacent lane.",
  "The target speed proposal is converted into an actual ex-pected sequence of ego-vehicle bounding boxes in closed-loop by using a kinematic bicycle model": "Having forecasted all actors, it checks for bounding boxintersections between the simulated ego vehicle and othervehicles. It scores the ego vehicles motion accordingly:if it detects an intersection, it rejects the IDM target speedproposal, and sets the target speed to zero. The steering value is estimated with a lateral PID con-troller, which minimizes the angle to a selected pointalong the path ahead. For the throttle and brake predic-tions, it employs a linear regression model using featuresextracted based on the current speed and target speed. TransFuser++ is the best-performing open-sourcemodel on Leaderboard 1.0 (). Given sensor inputs,it predicts a target speed and desired path which are inputto a controller module to drive the vehicle. We require twochanges compared to for compatibility with PDM-Lite: Two-hot labels.While the rule-based planner in uses only 4 different target speed classes up to 8m/s(28.8km/h), PDM-Lite operates with a continuous rangeof target speed values up to 20m/s (72km/h). To solvetarget speed regression with a classification module, weemploy two-hot labels . This method converts a con-tinuous value into a two-hot representation by interpo-lating between one-hot labels of the two nearest classes.For instance, with our 8 speed classes ([0.0, 4.0, 8.0,10, 13.89, 16, 17.78, 20] m/s), a target speed of 3.0m/s",
  "is represented as [0.25, 0.75, 0, 0, 0, 0, 0, 0]. These speedclasses were selected by analyzing the distribution of tar-get speeds chosen by PDM-Lite in our dataset": "Dynamic lookahead controller. For stable lateral con-trol at the high speeds required by Leaderboard 2.0, it isadvantageous to adjust the distance of the point selectedto follow along the ego vehicles predicted path based onthe current speed. TF++ predicts a set of 10 checkpoints,each spaced 1m apart, with the first checkpoint located2.5 meters from the vehicle center. The distance of thecheckpoint to which the lateral controller minimizes theangle is determined by the formula d = (0.098v+0.192),where v is the egos speed in km/h. We round down tothe nearest available predicted checkpoint. This scalingensures that at low speeds, the controller selects a closerpoint, facilitating tight turns, while at high speeds, it se-lects a distant point, resulting in more stable steering. Implementation. We use a cosine annealing learning rateschedule with lr0 = 3 104, T0 = 1, Tmult = 2 andtrain our models for 31 epochs. We train each model on fourA100 GPUs with a total batch size of 64, which takes 2-3days depending on the architecture.",
  "In this section, we present the main findings of our study": "Expert style. While expert performance is often reportedin prior work, the manner in which it achieves that per-formance, i.e., expert style, is often overlooked. Althoughharder to quantify, it is an important aspect to consider forIL. For instance, consider PDM-Lites behavior when ap-proaching pedestrians (). By default, the expert slowsdown when a pedestrian will enter the driving path, even ifthe pedestrian is still obstructed by a parked vehicle and notclearly visible. We make minor adjustments to the IDM pa-",
  ". Expert style compared on the same route. The defaultPDM-Lite brakes early (left), when the pedestrian is hardly visiblein the image, while the adjusted expert brakes later (right)": "rameters, with which the expert brakes rather sharply, com-ing to a stop at a distance of roughly 4 meters in front of themore visible pedestrian. This leads to a 4 decrease inpedestrian collisions for models trained on the adjusted ex-pert data. Notably, this update does not affect the expertsown pedestrian collision rate. The improvement is likelydue to the adjusted behavior providing a clear braking sig-nal for the model to learn from (a pedestrian visible directlyin front of the ego vehicle). The default behavior requiresthe model to generalize across various situations where apedestrian might appear further ahead. Target speed weights. Training TF++ involves using classweights in a target speed classification loss, which are cal-culated anti-proportionally to the number of occurrences ofthe respective class in the dataset . This means thatclasses that appear frequently get a lower weight than thosethat appear rarely. We find that removing these weights sig-nificantly improves the performance of TF++ on our task(). We believe this is due to the weight of class 0(braking), the most common in the dataset. While somepart of the data for class 0 is redundant (e.g., waiting at redlights), some frames are among the most crucial for avoid-ing infractions, such as coming to a stop in front of stopsigns or pedestrians. With a low weight on the target speedloss for these frames, ignoring short braking phases in thesesituations is an easy shortcut for the model to fall into.",
  ". Filtering improves scores on CARLA Leaderboard2.0. Secret test routes (Town 14). TF++ (Ours) outperforms priormodular pipelines , and places 2nd overall": "Data filtering. As an alternative to measure importanceof frames, we propose the use of heuristics that estimatewhether a frame changes the models target labels comparedto previous frames. More precisely, we keep all frames thatchange the target speed by more than 0.1m/s, or the angleto any of the predicted path checkpoints by more than 0.5compared to the previous frame (40% of all frames). Ad-ditionally, we randomly retain 14% of the remaining framesand discard the rest, for a total filtered dataset containing51% of all available frames. We then train with 2 thenumber of epochs to keep the total number of gradient up-dates similar. In , we present the results of our pro-posed filtering strategy on the official Leaderboard. By re-ducing the dataset size by 49%, with slightly improved per-formance, we show that our heuristic effectively removesredundant frames without losing information.",
  ". Additional Insights": "In this section, we analyze the behavior of our models. In, we present additional experimental results with nospeed weights and no filtering. Models marked with: \"Big\" use the default regnety_032 architecture ofTF++ for the image and LiDAR perception modules in-stead of ResNet34 used in our \"Base\" setting. \"Pre\" use two-stage training, where we first pre-train ex-clusively with perception losses (BEV semantics, bound-ing boxes, image depth, image semantics) for 15 epochs,before training for 31 epochs with all losses. \"Ens\" are ensemble models, averaging predictions from 3models trained with different random seeds.Ensembling (\"Ens\") and two-stage training (\"Pre\") pro-vide small improvements. To react better to vehicles thatare further away, we experiment with extending the LiDARrange in front of the ego to 64m from 32m (\"L64m\"). Thisalso results in a small improvement, albeit at the cost of in-creased training time. Giving the next two target points asinput instead of only one (\"2TPs\") fails to increase perfor-mance. Our final models (used in and )combine the benefits of \"Big\", \"Pre\", and \"Ens\".",
  "a birds-eye-view (BEV) image showing observed LiDARhits, the models path predictions, the target points used asinputs, and the auxiliary BEV semantics predictions. Weuse the following colors:": "Blue: Path predictionsRed: Target point (used as model input)Grey: Road (semantics)Yellow: Road marking (semantics)Light Green: Green traffic light (semantics)Light Orange: Vehicle (semantics)Green: Ego vehicle or pedestrian (bounding box)Orange: Vehicle (bounding box) ConstructionObstacleTwoWays. In this scenario, the egovehicle must pass an obstacle by moving into an adjacentlane with oncoming traffic. illustrates a commonfailure mode, where TF++ fails to merge back to its originallane. At first, the model successfully waits for a sufficientlylarge gap in the oncoming traffic and switches to the adja-cent lane. As long as the traffic cones marking the construc-tion site are visible in the camera image, its path predictionscorrectly indicate a lane change back to the original lane.However, as shown in the final frame, once the traffic conesdisappear from the camera image, the model erroneouslypredicts staying in the left lane. Notably, the traffic conesare still visible in the LiDAR, suggesting an over-relianceon the camera for this scenario. After staying in the wronglane, the ego vehicle often collides with oncoming traffic. SignalizedJunctionLeftTurn. shows a commonfailure case where the model does not react adequately toanother actor, leading to a vehicle collision. After the traf-fic light turns green, the vehicle accelerates and turns with-out reacting to the oncoming vehicle in the lane it needsto cross. After the collision, the model is able to recover,returning to its lane and completing the route. VehicleTurningRoutePedestrian.In this scenario, themodel must make an unproteced turn through dense trafficand encounters a pedestrian on the road during or directlyafter the turn. shows two corresponding failurecases. In the first case (top), the model fails to execute the",
  ". ConstructionObstacleTwoWays. When traffic cones are not visible any more, TF++ forgets to return to its original lane": "turn through very dense traffic, where the margins for se-lecting the right moment to accelerate are extremely narrow.After colliding with a vehicle, the model also collides witha pedestrian that walks into the ego vehicle while it is sta-tionary. The second example (bottom) depicts an instanceof this scenario at night, where TF++ does not collide withanother vehicle, but fails to recognize the pedestrian hazardin time. Note that the pedestrian is barely visible until il-luminated by the ego vehicles headlights, which is only acouple of frames before the collision. This failure is likelydue to covariate shift, since the expert would brake earlierin this situation, even before the pedestrian becomes visiblein the RGB image. By the time the pedestrian is revealedby the headlights, the model is already outside its trainingdistribution, where it has not learned a braking reflex. YieldToEmergencyVehicle. In this scenario, the ego vehi-cle must yield to an emergency vehicle approaching frombehind on a multi-lane highway. TF++ fails here since it isimpossible to distinguish emergency vehicles from regularvehicles using the LiDAR alone. Thus, solving this scenariorequires the inclusion of a back camera.",
  ". Bench2Drive": "Bench2Drive consists of 220 short (150m) routessplit across all CARLA towns, with one safety critical sce-nario in each route. It can be considered a training bench-mark (reminiscent of level 4 autonomy), since methods un-der evaluation have seen the test towns during training. Metrics.Besides the standard CARLA metric DS, thisbenchmark tracks success rate, which is 100% for a givenroute if DS=100%, and 0% otherwise.Further, the 220routes are categorized into five groups (Merging, Overtak-ing, Emergency Braking, Giving Way, and Traffic Signs),for which success rates are reported per category. Results. As seen in , TF++ significantly outper-forms all prior work on this benchmark, doubling the suc-cess rate compared to the next best approach. We believethis is partly due to the higher performance of the PDM-Liteexpert driver used in our dataset, compared to the closed-source Think2Drive expert used to generate trainingdata for all the baselines in this setting.",
  ". Results on Bench2Drive. Note that the baselines use Think2Drive as an expert, while TF++ uses PDM-Lite": "Early termination. For this benchmark, it can be beneficialto stop an agent preemptively, reducing RC and increasingIS to improve DS. To illustrate this, we formulate the ex-pected DS of an agent in terms of x , which is thefraction of the route that the agent completes. Let L be theroute length, and I = 0.5CP",
  "d 0.8Y E": "dbe the expected infraction coeffi-cient per km, including all non-negligible infraction types(collisions with pedestrians, collisions with vehicles, col-lisions with layout, red light infractions, stop infractions,scenario timeouts, and yield to emergency vehicle infrac-tions). Since we divide the exponents of I by the distanced = xL traveled by the agent, the IS can be calculated asIxL, and RC as 100x, giving DS = 100xIxL. Maximizingthis function, we obtain the solution xmax = (Llog I)1,with a theoretically maximal driving score of DS(xmax) =100",
  "L e log I . plots this function, along with its": "maxima, for different values of I.We observe that for benchmarks with long routes likeTown13 validation and the official leaderboard, mathemati-cally, a model profits from \"early termination\" if xmax < 1,i.e., I < 0.907. The plot illustrates this: if I < 0.907, ex-pected driving score is maximized at xmax < 1, with driv-ing scores dropping off significantly at higher route com-pletion fractions x. With L = 10.295 and I = 0.43 (es-timated for our model on the validation routes), we ob-tain x = 0.115.Thus, we should theoretically stop atd = xL = 1.18km to maximize the expected DS. SinceI and L are only estimates, we set target speed to 0 afterd = 1.5km in practice. We track distance traveled using theagents speed sensor. As shows, all good submis-sions to the Leaderboard 2.0 test server have less than 18.1RC, which implies that all these methods use a variant ofearly termination either explicitly or implicitly.",
  ". VehicleTurningRoutePedestrian. Top: Failure to perform unprotected turn. Bottom: Failure to recognize pedestrian at night": "Normalized DS. This tradeoff introduced by the perfor-mance metrics used in Leaderboard 2.0 forces participantsto terminate evaluations early to remain competitive, whichis counterproductive. Therefore, we recommend adjustingthe performance metrics for future challenges. Instead ofusing the infraction score (IS) for driving score calculation,we propose using the infraction coefficient (I) as definedabove, which incorporates infraction frequencies:DS(x) = RC(x) I(x) 100xI, x . This function, depicted in for varying valuesof I, increases linearly with x. This eliminates the incen-tive to stop early, since the maximum driving score is al-ways reached at x = 1, i.e., full route completion.Asa side effect, this change leads to an increase of averagedriving scores achieved with identical models compared tothe original formula. If this increase is not desired, it canbe corrected by scaling down the penalty factors for all in-fractions, which reduces the expected driving scores while",
  ". Approximate DS as a function of RC fraction x fordifferent infraction coefficients I. DS(x) has a global maximumat x < 1 if I < 0.907, which creates an incentive to stop early": "maintaining the maximum score at 100.Results. We first demonstrate the impact of our metric ad-justment on the official Town13 validation routes. Early ter-mination has a significant effect on the scores obtained, asshown in . Here, we scale all infraction penalties bya factor of 0.2 for DS to keep the resulting normalized driv-ing scores in a similar range as with the original formula.Concretely, we apply a base penalty of 0.2 0.5 = 0.1 forCP, 0.2 0.6 = 0.12 for CV , and so forth. Comparingthis to the original metrics, it is clear that the revised driv-ing score calculation successfully discourages early termi-nation, since models that stop after one kilometer now re-ceive a much lower normalized driving score, as intended.Comparing TF++ to UniAD1, we see large improvements interms of both DS and DS. Finally, we note the significantgap between TF++ and the PDM-Lite expert, indicating thatthis is a promising benchmark for future research.",
  ". Conclusion": "With a systematic analysis of training dataset biases forend-to-end driving in CARLA, we reveal the impact of ex-pert style on IL policy performance, provide insights intothe challenges of assigning importance to frames throughweighting or filtering, and provide a simple yet effectiveheuristic that estimates importance based on changes in tar-get labels. We reproduce TransFuser++ in the Leaderboard2.0 setting, providing the first recipe for training an end-to-end driving system that attains non-trivial performance.Finally, we propose an improvement to the existing metricsand extensively benchmark our system. We hope this canserve as a starting point for future research on this task.Limitations. In repeated Leaderboard submissions, we ob-serve significant variance in DS, with identical agents yield-ing results that differ by more than 1 DS. Unfortunately,",
  "PDM-Lite 92.350.4440.200.6561.55": ". Results on official Town13 validation routes. Meanover 3 evaluations of each agent. The normalized driving scoreDS removes the incentive for early termination (\"ET?\") after 1kmon these long routes. *We include this result for fair compari-son to UniAD, however, we strongly recommend the setting withTown13 withheld for future work on this benchmark. our results on the leaderboard () also do not includeall routes in the benchmark, due to technical issues duringmodel setup in some routes. In addition, as shown in Ta-ble 5, DS is influenced significantly by early termination onlong routes, which does not reflect any actual improvementin driving behavior. We believe it is necessary to considerimproved metrics (such as the proposed Normalized DS)and standardize benchmarking with multiple seeds beforedrawing strong conclusions based on our empirical results. Acknowledgements. Bernhard Jaeger and Andreas Geigerwere supported by the ERC Starting Grant LEGO-3D(850533) and the DFG EXC number 2064/1 - project num-ber 390727645. Kashyap Chitta was supported by the Ger-man Federal Ministry of Education and Research (BMBF):Tbingen AI Center, FKZ: 01IS18039A. We thank theInternational Max Planck Research School for IntelligentSystems (IMPRS-IS) for supporting Bernhard Jaeger andKashyap Chitta, and Katrin Renz for the useful exchange.",
  "Jens Beiwenger. Pdm-lite: A rule-based planner for carlaleaderboard 2.0. Technical report, University of Tbingen,2024. 1, 2": "Holger Caesar, Varun Bankiti, Alex H. Lang, Sourabh Vora,Venice Erin Liong, Qiang Xu, Anush Krishnan, Yu Pan, Gi-ancarlo Baldan, and Oscar Beijbom.nuscenes: A multi-modal dataset for autonomous driving. In Proc. IEEE Conf.on Computer Vision and Pattern Recognition (CVPR), 2020.5 Holger Caesar, Juraj Kabzan, Kok Seang Tan, Whye KitFong, Eric M. Wolff, Alex H. Lang, Luke Fletcher, Os-car Beijbom, and Sammy Omari.nuplan: A closed-loopml-based planning benchmark for autonomous vehicles. InProc. IEEE Conf. on Computer Vision and Pattern Recogni-tion (CVPR) Workshops, 2021. 5",
  "Dian Chen, Brady Zhou, Vladlen Koltun, and PhilippKrhenbhl. Learning by cheating. In Proc. Conf. on RobotLearning (CoRL), 2019. 1": "Kashyap Chitta, Aditya Prakash, Bernhard Jaeger, Zehao Yu,Katrin Renz, and Andreas Geiger.Transfuser: Imitationwith transformer-based sensor fusion for autonomous driv-ing. IEEE Trans. on Pattern Analysis and Machine Intelli-gence (PAMI), 2023. 1 Kashyap Chitta, Daniel Dauner, and Andreas Geiger. Sledge:Synthesizing driving environments with generative modelsand rule-based traffic. In Proc. of the European Conf. onComputer Vision (ECCV), 2024. 5",
  "Alexey Dosovitskiy, German Ros, Felipe Codevilla, AntonioLopez, and Vladlen Koltun. CARLA: An open urban drivingsimulator. In Proc. Conf. on Robot Learning (CoRL), 2017.1": "Jesse Farebrother, Jordi Orbay, Quan Vuong, Adrien AliTaga, Yevgen Chebotar, Ted Xiao, Alex Irpan, SergeyLevine, Pablo Samuel Castro, Aleksandra Faust, Aviral Ku-mar, and Rishabh Agarwal. Stop regressing: Training valuefunctions via classification for scalable deep rl. arXiv.org,2403.03950, 2024. 2 Cole Gulino, Justin Fu, Wenjie Luo, George Tucker, EliBronstein, Yiren Lu, Jean Harb, Xinlei Pan, Yan Wang,Xiangyu Chen, John D. Co-Reyes, Rishabh Agarwal, Re-becca Roelofs, Yao Lu, Nico Montali, Paul Mougin, ZoeyYang, Brandyn White, Aleksandra Faust, Rowan McAllister,Dragomir Anguelov, and Benjamin Sapp. Waymax: An ac-celerated, data-driven simulator for large-scale autonomous",
  "driving research. In Advances in Neural Information Pro-cessing Systems (NIPS), 2023. 5": "Yihan Hu, Jiazhi Yang, Li Chen, Keyu Li, Chonghao Sima,Xizhou Zhu, Siqi Chai, Senyao Du, Tianwei Lin, et al.Planning-oriented autonomous driving. In Proc. IEEE Conf.on Computer Vision and Pattern Recognition (CVPR), 2023.6, 8 Shu Ishida, Gianluca Corrado, George Fedoseev, HudsonYeo, Lloyd Russell, Jamie Shotton, Joo F. Henriques,and Anthony Hu. Langprop: A code optimization frame-work using language models applied to driving. arXiv.org,2401.10314, 2024. 1",
  "Bernhard Jaeger, Kashyap Chitta, and Andreas Geiger. Hid-den biases of end-to-end driving models.In Proc. of theIEEE International Conf. on Computer Vision (ICCV), 2023.1, 2, 3": "XiaosongJia,YuluGao,LiChen,JunchiYan,Patrick Langechuan Liu, and Hongyang Li. Driveadapter:Breaking the coupling barrier of perception and planningin end-to-end autonomous driving.In Proc. of the IEEEInternational Conf. on Computer Vision (ICCV), 2023. 6 Xiaosong Jia, Penghao Wu, Li Chen, Jiangwei Xie, ConghuiHe, Junchi Yan, and Hongyang Li. Think twice before driv-ing: Towards scalable decoders for end-to-end autonomousdriving. In Proc. IEEE Conf. on Computer Vision and Pat-tern Recognition (CVPR), 2023. 6 Xiaosong Jia, Zhenjie Yang, Qifeng Li, Zhiyuan Zhang, andJunchi Yan. Bench2drive: Towards multi-ability benchmark-ing of closed-loop end-to-end autonomous driving. In Ad-vances in Neural Information Processing Systems (NeurIPS),2024. 1, 5 Bo Jiang, Shaoyu Chen, Qing Xu, Bencheng Liao, JiajieChen, Helong Zhou, Qian Zhang, Wenyu Liu, Chang Huang,and Xinggang Wang. Vad: Vectorized scene representationfor efficient autonomous driving. In Proc. of the IEEE Inter-national Conf. on Computer Vision (ICCV), 2023. 6 Napat Karnchanachari, Dimitris Geromichalos, Kok SeangTan, Nanxiang Li, Christopher Eriksen, Shakiba Yaghoubi,Noushin Mehdipour, Gianmarco Bernasconi, Whye KitFong, Yiluan Guo, and Holger Caesar. Towards learning-based planning: The nuPlan benchmark for real-world au-tonomous driving.In Proc. IEEE International Conf. onRobotics and Automation (ICRA), 2024. 5 Qifeng Li, Xiaosong Jia, Shaobo Wang, and Junchi Yan.Think2drive: Efficient reinforcement learning by thinking inlatent world model for quasi-realistic autonomous driving (incarla-v2). arXiv.org, 2402.16720, 2024. 2 Qifeng Li, Xiaosong Jia, Shaobo Wang, and Junchi Yan.Think2drive: Efficient reinforcement learning by thinking inlatent world model for quasi-realistic autonomous driving (incarla-v2). In Proc. of the European Conf. on Computer Vi-sion (ECCV), 2024. 1, 5, 6",
  "Ilija Radosavovic, Raj Prateek Kosaraju, Ross Girshick,Kaiming He, and Piotr Dollr. Designing network designspaces. arXiv:2003.13678, 2020. 4": "Katrin Renz, Kashyap Chitta, Otniel-Bogdan Mercea, Al-mut Sophia Koepke, Zeynep Akata, and Andreas Geiger.Plant: Explainable planning transformers via object-levelrepresentations. In Proc. Conf. on Robot Learning (CoRL),2022. 1 Katrin Renz, Long Chen, Ana-Maria Marcu, Jan Hner-mann, Benoit Hanotte, Alice Karnsund, Jamie Shotton,Elahe Arani, and Oleg Sinavski. Carllava: Vision languagemodels for camera-only closed-loop driving.arXiv.org,2406.10165, 2024. 4 Luis Alberto Rosero, Iago Pachco Gomes, Jnior Ander-son Rodrigues da Silva, Carlos Andre Braile PrzewodowskiFilho, Denis Fernando Wolf, and Fernando Santos Osrio.Integrating modular pipelines with end-to-end learning: Ahybrid approach for robust and reliable autonomous drivingsystems. Sensors, 2024. 4",
  "Martin Treiber, Ansgar Hennecke, and Dirk Helbing. Con-gested traffic states in empirical observations and micro-scopic simulations. Physical review E, 2000. 2": "Peng Wu, Xiaosong Jia, Li Chen, Junchi Yan, HongyangLi, and Yu Qiao. Trajectory-guided control prediction forend-to-end autonomous driving: A simple yet strong base-line. In Advances in Neural Information Processing Systems(NeurIPS), 2022. 1, 6 Jiang-Tian Zhai, Ze Feng, Jihao Du, Yongqiang Mao, Jiang-Jiang Liu, Zichang Tan, Yifu Zhang, Xiaoqing Ye, and Jing-dong Wang. Rethinking the open-loop evaluation of end-to-end autonomous driving in nuscenes.arXiv preprintarXiv:2305.10430, 2023. 6 Weize Zhang, Mohammed Elmahgiubi, Kasra Rezaee,Behzad Khamidehi, Hamidreza Mirkhani, Fazel Arasteh,Chunlin Li, Muhammad Ahsan Kaleem, Eduardo R. Corral-Soto, Dhruv Sharma, and Tongtong Cao. Analysis of a mod-ular autonomous driving architecture: The top submissionto carla leaderboard 2.0 challenge. arXiv.org, 2405.01394,2024. 2, 4 Zhejun Zhang, Alexander Liniger, Dengxin Dai, Fisher Yu,and Luc Van Gool. End-to-end urban driving by imitating areinforcement learning coach. In Proc. of the IEEE Interna-tional Conf. on Computer Vision (ICCV), 2021. 1"
}