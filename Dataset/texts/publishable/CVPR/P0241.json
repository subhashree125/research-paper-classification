{
  "Abstract": "This study reveals a cutting-edge re-balanced con-trastive learning strategy aimed at strengthening face anti-spoofing capabilities within facial recognition systems, witha focus on countering the challenges posed by printed pho-tos, and highly realistic silicone or latex masks. Leveragingthe HySpeFAS dataset, which benefits from Snapshot Spec-tral Imaging technology to provide hyperspectral images,our approach harmonizes class-level contrastive learningwith data resampling and an innovative real-face orientedreweighting technique.This method effectively mitigatesdataset imbalances and reduces identity-related biases. No-tably, our strategy achieved an unprecedented 0.0000% Av-erage Classification Error Rate (ACER) on the HySpeFASdataset, ranking first at the Chalearn Snapshot SpectralImaging Face Anti-spoofing Challenge on CVPR 2024.",
  ". Introduction": "Face recognition technologies , withthe extensive applications in various aspects of our life likemobile payments and access control systems, has signif-icantly enhanced convenience. Nonetheless, its suscepti-bility to diverse forms of attacks limits its reliable appli-cation. Numerous malicious attacks, including the use ofprinted photos, video replays, and faces with flexible masks,can readily mislead these systems into making wrong judg-ments. To ensure the dependable operation of face recog-nition systems, face anti-spoofing (FAS) methods are crucial for identifying and mitigating variousattacks.Confronted with the challenge of highly convincing sil-icone or latex masks, the deployment of innovative spec-troscopy sensors can notably boost the discrimina-tive power of face recognition systems against these attacks.",
  "*Corresponding author": "Snapshot Spectral Imaging (SSI) technologies pos-sess the ability to capture compressed sensing spectral im-ages, positioning it as an effective tool for the integrationof spectroscopic information into current face recognitionsystems.Recently, utilizing a snapshot spectral camera,the Chalearn Snapshot Spectral Imaging Face Anti-spoofingChallenge at CVPR 2024 successfully acquires SSI imagesof both real and fake faces, and creates the first snapshotspectral face anti-spoofing dataset, named HySpeFAS. Thisdataset encompasses 6760 hyperspectral images, each re-constructed from SSI images using the TwIST algo-rithm and featuring 30 spectral channels. These data presentinvaluable opportunities for FAS to advance the sophistica-tion and reliability of algorithms. In this paper, we present our approach tailored for theFAS task. We design a re-balanced contrastive learning ap-proach, aimed at capturing the detailed and intrinsic pat-terns from the imbalanced dataset. We embed class-levelcontrastive learning into FAS task by employing data re-sampling to mitigate class-level imbalances in the dataset.Furthermore, we introduce an innovative real face-orientedreweighting methodology to effectively eliminate potentialbias to the identity of the face.The proposed methodachieves 0.0000% ACER on the HySpeFAS dataset andranks first place on the Snapshot Spectral Imaging FaceAnti-spoofing Challenge at CVPR 2024.",
  "arXiv:2405.18853v1 [cs.CV] 29 May 2024": ". Analysis of examples from HySpeFAS dataset. From top to bottom: real images and fake images. From left to right: examples inthe first box show the same ID face across real and fake images; the second one indicates the various alternations of real and fake images;the third one visualizes different appearances of images from the same ID; the last one shows different orientations of real images and fakeimages.",
  ". HySpeFAS dataset": "The HySpeFAS dataset utilizes a snapshot spectral camerato obtain SSI images of both real and fake faces, and thoseimages are reconstructed from SSI images by TwIST algo-rithm and characterized with 30 spectral channels. In total,the dataset provides 6760 hyperspectral images, as detailedin . For the Snapshot Spectral Imaging Face Anti-spoofing Challenge at CVPR 2024, the organizers have pro-vided all images along with their spectral matrices. Thedataset is divided into a training set with 3900 images and avalidation set containing 936 images. Visual examples fromthe dataset are shown in , facilitating an in-depthanalysis of the HySpeFAS dataset. This analysis serves asthe foundation for data resampling and reweighting strate-gies discussed in .From , it is evident that although the datasetis valuable due to the challenging acquisition process, thequantity of data remains limited. Additionally, the num-ber of counterfeit face images significantly outnumbers thatof genuine faces, creating a pronounced imbalance betweenthe two primary classes of images. In , several keycharacteristics of the HySpeFAS dataset are identified: (1).identical identifiers (ID) are present in both fake and realface images. (2). face images exhibit a variety of alter-ations, including masks and transparent masks. (3). facesfrom the same ID show considerable variation in physicalappearance. (4). variations in facial orientation and otherconditions are also observed. These characteristics presentconsiderable challenges, and the methodology proposed inthis paper is designed to address these specific aspects.",
  "Given the volume and the imbalance between the real andfake sample quantities within the dataset, we initiate ourapproach with preprocessing enhancements to address thisissue": "Class BalancingAs shown in , we analyze theclass numbers of the training data and validation data, andcan observe that the HySpeFAS dataset is an unbalanceddataset, where the number of fake data is much larger thanthat of real data. To eliminate the effects of the imbalanceddata, we adopt the oversampling strategy to rebalance thedata distribution by amplifying the volume of real instances. Data AugmentationsDuring the training, we use exten-sive data augmentations, such as random crop, random hor-izontal flip, cutout and random mask. For random mask,we randomly mask the bottom half of training samples toeliminate the effect of the worn mask, or randomly maskthe left or right half of training samples. presentssome examples of augmented faces based on random mask.",
  ". Framework": "Our framework, shown in , leverage the multi-attention network MAT as the backbone Emat, andcombine the spectral weight learning module Eswl, thecentral differential convolution Ecdc, the classifier Ec,and the contrastive learning module Escl. image-label pairsfrom HySpeFAS dataset can be represented as {xI, xm, y},where xI Rwh3 (resp., xm Rwh30, and y R2)denotes RGB image (resp., spectral matrix, and one-hot la-bel). We concatenate xI and xm along the third channel toform input sample x Rwh33.",
  ". Visualization of augmented examples with three differ-ent type of random mask": "Given the multimodal nature of the input, input sam-ple x first is processed with the spectral weight learningmodule Eswl to assign different weights to input channels.Then we adopt the Ecdc as the first convolution layer to ob-tain gradient-level features, and use a multi-attentional net-work Emat to learn discriminative features. Feded with thelearned discriminative features, the classifier Ec is respon-sible for distinguishing fake faces from real faces, while thecontrastive learning module Escl is dedicated to promotingthe discriminability of the learned features.",
  "Intra-class Mixup": "Given the limited size of the training dataset, the risk ofoverfitting is heightened when employing large neural net-works. To mitigate this and enrich the diversity of trainingsamples, we utilize a variant of mixup, inter-class mixup. Asformulated by Eqn. 1, inter-class mixup generates trainingsamples (x, y) by interpolating between two training sam-ples from the same class.",
  "Real-face Oriented Reweighting": "To diminish the models reliance on content irrelevant tospoofing detection, such as identity and facial features, weintroduce Real-face Oriented Reweighting(ROR) strategyduring training. ROR assigns weights to fake training sam-ples based on their face cosine similarity with real trainingsamples. The face cosine similarities are calculated basedon the typical face model ArcFace as follows,",
  "Lc = FL(pt) = (1 pt)log(pt),(3)": "where pt is the probability that the model predicts for theground truth object and we set as 2. According to Eqn. 3,the focal loss gives less weight to easy examples and givesmore weight to hard misclassified examples. Supervised Contrastive Loss.The objective of con-trastive regularization loss is to optimize the similarity anddissimilarity of real and fake data embeddings. The con-trastive regulation loss is formulated as:",
  "i=1Lsupi,": "(4)where zi is denoted as the normalized embedding of thetraining sample xi from Escl module, and serves as atemperature hyper-parameter.According to Eqn. 4, the supervised contrastive lossmaximizes the cosine similarity between the training sam-ples with the same category, while simultaneously minimiz-ing the cosine similarity between the training samples withdifferent categories. We compute the loss between real andfake samples to encourage the model to learn a generaliz-able representation that across different images.To boost the performance of the supervised contrastiveloss, we utilize the cross batch memory (XBM) tocollect sufficient hard negative pairs for contrastive learn-ing. Specifically, XBM memorizes the embeddings of re-cent mini-batches and can provide sufficient embeddingsfor calculating the supervised contrastive loss. It operateson a queue principle, enrolling the latest batch of embed-dings while simultaneously removing the oldest, maintain-ing a dynamic and up-to-date memory bank for optimiza-tion.Overall Loss. The final loss function of the training pro-cess is the weighted sum of the above loss functions:",
  ". Training Details": "We implement our method on 1 NVIDIA Tesla A100 80GGPU based on open-source framework PyTorch . Wetrain the network using the ASAM optimizer with 30epochs. The learning rate is 0.01 initially and adjusted bythe cosine annealing schedule . The batch size is 240and the weight decay is 5 103, and the memory size ofthe XBM is 1200. The temperature parameter of thesupervised contrastive loss is set to 0.07.",
  ". Performance Results": "We compare the performance of our method and the solu-tions of other teams on the test set in the Snapshot SpectralImaging Face Anti-spoofing Challenge at CVPR 2024. Theevaluation scores of ours and other teams are shown in Ta-ble 2. We can observe that all the top 10 teams achieveexcellent performance results, where all the ACER resultsare less than 1%. Our method achieves ACER, APCER,and BPCER by 0%, 0% and 0%, respectively, ranking thefirst place in this competition.",
  ". Conclusion": "In this paper, we introduce supervised contrastive learningfor snapshot spectral imaging face anti-spoofing based onthe multi-attention neural network. Furthermore, to boostthe supervised contrastive learning, we utilize the intra-class mixup to improve the diversity of training samples,the real-face oriented sample reweighting to avoid the ef-fects of the identity feature, and the cross-batch memory to",
  ". The top10 leaderboard of the Snapshot Spectral ImagingFace Anti-spoofing Challenge at CVPR 2024": "increase the number of the contrastive samples. Experimen-tal results show that the proposed method achieves excellentperformance and yields the first place among all teams onthe recently conducted the Snapshot Spectral Imaging FaceAnti-spoofing Challenge at CVPR 2024. Gwangbin Bae, Martin de La Gorce, Tadas Baltrusaitis,Charlie Hewitt, Dong Chen, Julien Valentin, RobertoCipolla, and Jingjing Shen.Digiface-1m: 1 million digi-tal face images for face recognition. In Proceedings of theIEEE/CVF Winter Conference on Applications of ComputerVision, pages 35263535, 2023. 1 Fadi Boutros, Naser Damer, Florian Kirchbuchner, and Ar-jan Kuijper. Elasticface: Elastic margin loss for deep facerecognition. In Proceedings of the IEEE/CVF conference oncomputer vision and pattern recognition, pages 15781587,2022. 1 Xun Cao, Tao Yue, Xing Lin, Stephen Lin, Xin Yuan, Qiong-hai Dai, Lawrence Carin, and David J Brady. Computationalsnapshot multispectral cameras: Toward dynamic capture ofthe spectral world. IEEE Signal Processing Magazine, 33(5):95108, 2016. 1 Jiankang Deng, Jia Guo, Niannan Xue, and StefanosZafeiriou. Arcface: Additive angular margin loss for deepface recognition.In IEEE Conference on Computer Vi-sion and Pattern Recognition, CVPR 2019, Long Beach, CA,USA, June 16-20, 2019, pages 46904699. Computer VisionFoundation / IEEE, 2019. 3",
  "scope. Journal of biomedical optics, 16(5):056005056005,2011. 1": "Minchul Kim, Anil K Jain, and Xiaoming Liu.Adaface:Quality adaptive margin for face recognition. In Proceedingsof the IEEE/CVF conference on computer vision and patternrecognition, pages 1875018759, 2022. 1 Jukka Komulainen, Abdenour Hadid, and Matti Pietikainen.Context based face anti-spoofing. In 2013 IEEE Sixth In-ternational Conference on Biometrics: Theory, Applicationsand Systems (BTAS), pages 18. IEEE, 2013. 1 Jungmin Kwon,Jeongseop Kim,Hyunseo Park,andIn Kwon Choi. ASAM: adaptive sharpness-aware minimiza-tion for scale-invariant learning of deep neural networks. InProceedings of the 38th International Conference on Ma-chine Learning, ICML 2021, 18-24 July 2021, Virtual Event,pages 59055914. PMLR, 2021. 4 Tsung-Yi Lin, Priya Goyal, Ross B. Girshick, Kaiming He,and Piotr Dollar. Focal loss for dense object detection. InIEEE International Conference on Computer Vision, ICCV2017, Venice, Italy, October 22-29, 2017, pages 29993007.IEEE Computer Society, 2017. 3 Ilya Loshchilov and Frank Hutter. SGDR: stochastic gradientdescent with warm restarts. In 5th International Conferenceon Learning Representations, ICLR 2017, Toulon, France,April 24-26, 2017, Conference Track Proceedings. OpenRe-view.net, 2017. 4 Qiang Meng, Shichao Zhao, Zhida Huang, and Feng Zhou.Magface: A universal representation for face recognition andquality assessment. In Proceedings of the IEEE/CVF confer-ence on computer vision and pattern recognition, 2021. 1",
  "Shijie Rao, Yidong Huang, Kaiyu Cui, and Yali Li. Anti-spoofing face recognition using a metasurface-based snap-shot hyperspectral image sensor. Optica, 9(11):12531259,2022. 1": "Hoover Rueda-Chacon, Juan F Florez-Ospina, Daniel L Lau,and Gonzalo R Arce. Snapshot compressive tof+ spectralimaging via optimized color-coded apertures. IEEE transac-tions on pattern analysis and machine intelligence, 42(10):23462360, 2019. 1 Florian Schroff, Dmitry Kalenichenko, and James Philbin.Facenet: A unified embedding for face recognition and clus-tering. In Proceedings of the IEEE conference on computervision and pattern recognition, pages 815823, 2015. 1",
  "Jianwei Yang, Zhen Lei, and Stan Z Li.Learn convolu-tional neural network for face anti-spoofing. arXiv preprintarXiv:1408.5601, 2014. 1": "Zitong Yu, Chenxu Zhao, Zezheng Wang, Yunxiao Qin,Zhuo Su, Xiaobai Li, Feng Zhou, and Guoying Zhao.Searching central difference convolutional networks for faceanti-spoofing. In 2020 IEEE/CVF Conference on ComputerVision and Pattern Recognition, CVPR 2020, Seattle, WA,USA, June 13-19, 2020, pages 52945304. Computer VisionFoundation / IEEE, 2020. 2 Zitong Yu, Chenxu Zhao, Zezheng Wang, Yunxiao Qin,Zhuo Su, Xiaobai Li, Feng Zhou, and Guoying Zhao.Searching central difference convolutional networks for faceanti-spoofing. In Proceedings of the IEEE/CVF conferenceon computer vision and pattern recognition, pages 52955305, 2020. 1 Hongyi Zhang, Moustapha Cisse, Yann N. Dauphin, andDavid Lopez-Paz. mixup: Beyond empirical risk minimiza-tion. In 6th International Conference on Learning Represen-tations, ICLR 2018, Vancouver, BC, Canada, April 30 - May3, 2018, Conference Track Proceedings. OpenReview.net,2018. 2 Hanqing Zhao, Wenbo Zhou, Dongdong Chen, Tianyi Wei,Weiming Zhang, and Nenghai Yu. Multi-attentional deep-fake detection.In IEEE Conference on Computer Visionand Pattern Recognition, CVPR 2021, virtual, June 19-25, 2021, pages 21852194. Computer Vision Foundation /IEEE, 2021. 2"
}