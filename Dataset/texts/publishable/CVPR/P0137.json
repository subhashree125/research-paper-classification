{
  "Abstract": "In an era of increasing privacy concerns for our on-line presence, we propose that the decision to appear ina piece of content should only belong to the owner ofthe body. Although some automatic approaches for full-body anonymization have been proposed, human-guidedanonymization can adapt to various contexts, such as cul-tural norms, personal relations, esthetic concerns, and se-curity issues.My Body My Choice (MBMC) enablesphysical and adversarial anonymization by removal andswapping approaches aimed for four tasks, designed by sin-gle or multi, ControlNet or GAN modules, combining sev-eral diffusion models. We evaluate anonymization on sevendatasets; compare with SOTA inpainting and anonymiza-tion methods; evaluate by image, adversarial, and genera-tive metrics; and conduct reidentification experiments.",
  ". Introduction": "In the digital age, the proliferation of social media andthe ubiquity of data collection have given rise to profoundconcerns about privacy and security . In physical re-ality, we choose to be somewhere or not, or we choose tobe seen somewhere or not. In digital world, anyone with aphoto or likeness of someone can freely publish that contentto be seen by, well, everyone. We introduce My Body MyChoice (MBMC), so whenever a photo of you is uploaded,you can choose to be in it and how you want to appear in it. MBMC recognizes that anonymization is not a one-size-fits-all endeavor, therefore the system offers fouranonymization options ( ). First, the body can be phys-ically deleted without breaking the image integrity. Sec-ond, the body can be adversarially deleted so that persondetectors cannot process it automatically, while friends andfamily observes no difference in the image.Third, thebody can be replaced by a quantifiably dissimilar body asan anonymization mask. Fourth, the identity of the bodycan be removed with minimal changes to the rest of thebody. Our contributions include, a human-centric full-bodyanonymization paradigm enabling people to choose if andhow they appear in photos, and a full-body anonymizationalgorithm that masks the input body with quantifiably mostdissimilar body without breaking image continuity.We extensively evaluate our approach, starting bycollecting diverse images from seven different datasets,spanning various poses, activities, demographics, scenes,contexts, crowds, and environments.We evaluate theanonymized images in pixel, noise, generative, adversarial,visual, and structural spaces. We believe that on the rise ofglobal privacy regulations, such systems will be the corner-stone of social media platforms.",
  ". Mask-based Removal Pipeline. (Left) Embedding search, preparation of multiControlNet input, and face enhancements. (Right)Running the system independent of the body order for a multi-body image": "painting task . Beyond traditional imageprocessing operations, various techniques such as styletransfer , texture manipulation , scenerearrangement , identity removal , and adversarialaltercations are applied to replace sensitive featureswith plausible yet non-identifying content.VAEs andGANs are also explored via inpainting, content transfer,or part swap .With these, generativemodels solve the image quality issue, however, how theanonymization is done is still an open research area.Most of the anonymization techniques focus on faces [6, 25, 30, 37, 42, 43]. Full body anonymization can addresssituations where contextual cues beyond the face play asignificant role in identifying individuals. There are con-siderably less approaches focusing on body anonymiza-tion . Unfortunately, full-body anonymizationalmost always breaks the face structure and produces lowquality results as seen in .",
  "Some approaches guide anonymization with additionalinput ); define interesting loss functions ;aim to replicate predefined priors , and let humans in-terfere .All mentioned generative models used for": "anonymization are (1) trained from scratch; (2) on low-quality and low-diversity data; (3) sometimes with addi-tional input; and (4) solving multi-body problem sequen-tially, order-dependent. We list these shortcomings of theSOTA in Tab. 1. My Body My Choice is a plug-and-playsystem, does not need any training or fine-tuning, workson any image size, does not require any additional input,is applicable to both body and face images, and supportsorder-invariant multi-body anonymization.",
  ". Physical Removal": "This option aims to completely eliminate the body fromthe image, filling in the cropped area with the background.Given an image I with n humans p1, . . . , pn in it, physi-cal removal employs YOLOv8 to segment each pi inI. We use inpainting model of ControlNetv1.1 where the control condition of the ControlNet is our segmentationmask with a fine-tuned Realistic Vision model of StableDiffusion 1.5 backbone to synthesize masked regionswith realistic attributes, patterns, or objects.",
  ". Adversarial Removal": "This option aims to eliminate or reduce the person de-tection accuracy as much as possible, which is called van-ishing gradient attack in adversarial defense literature. Weemploy YOLOv3 with MobileNetv1 and Dark-Net backends as common detectors, operating on per-son class. We design an objectness gradient attack usingTOG , where the perturbation added to the image causesthe gradients to vanish, creating no detection result. TOGtargets real-time object detection systems, appropriate forscaling MBMC on a social media platform. Note that, itis possible to (1) create universal adversarial patches for allclasses and (2) attack multiple detectors at the same time.We leave these extensions as future work.",
  ". Mask-based Removal": "This option aims to replace the body with a quantifi-ably dissimilar body, utilizing the manifold of diffusionmodels, as illustrated in . Given an image I withn humans p1, . . . , pn in it, mask-based removal first em-ploys YOLOv8 to segment each pi in I.The seg-mentation masks M(pi) are then dilated (Fig 2a). Second,OpenPose extracts pose skeleton and facial landmarksas P(pi) (Fig 2b). Third, PiDiNet detects soft edges asE(pi) (Fig 2c). Fourth, YOLOv8 is also used to detectthe person bounding box as B(pi) (Fig 2d).The main novelty of MBMC is rooted in guiding thebody synthesis. First, we create a body manifold as ourembedding space with diverse bodies in terms of poses,activities, appearances, and demographics, thus, we selecta subset of MPII Humans Dataset .Every image jkcomes with activity labels A(jk), so we store the same num-ber of images j1, . . . , jm from each activity class t. Then,we use CLIP Interrogator to compute the CLIP embed-dings C(jk) of all images in this dataset (Fig 2e). Thismanifold creation process is done only once and offline.At run time, this time B(pi) is fed to the same inter-rogator, which returns the closest activity class A(B(pi)) ofthe person and the CLIP embedding C(B(pi)) for the per-son bounding box. The guide selection (Fig 2f) searchesfor the jk satisfying jk:A(B(pi))=A(jk) andmaxjk cos(C(B(pi)), C(jk))) where cos is cosine distanceof embeddings C(.), finding the furthest embedding withinthe same activity class.We use a multi-ControlNet architecture (Fig 2g) based on Realistic Vision thatcombines multiple modalities.We input masked imagepi M(pi), pose P(pi), soft edges E(pi) and CLIP em-bedding C(jmax) to this architecture to generate an image.",
  ". Identity Removal": "Given an image I with n humans p1, . . . , pn in it (orthe multi-ControlNet output), identity removal applies to find the face most dissimilar to I, within a random-ness sphere.SimSwap used in causes under-anonymization based on less than expected drop in facerecognition accuracy, so we use InSwapper instead(Fig 2h). Finally, we apply a face enhancer called GFP-GAN which increases face resolution and makes facedetails more prominent (Fig 2i) by using the image priorsthat are encapsulated in a pretrained StyleGan2 on faceimages. In order create faces with non-existing identities,we use a synthetic dataset for our embedding space.",
  ". Multi-body Anonymization": "Finally we summarize how everything works for multi-ple bodies (Fig 2right). We explore two paths: Both of themrun single-input MBMC on each person. The first one plugsback all results into the segmented areas, whereas the sec-ond one runs a multi-input MBMC with all results to let thediffusion model handle overlapping segmentations. As ex-pected, the first approach creates order dependence on thepersons, so we proceed with the second approach.",
  ". Results": "Evaluations are performed on an NVIDIA GeForce RTX3070 with 8GB GPU, mask-based removal taking 30 secand physical removal taking 20 sec. We use as our diffu-sion checkpoint and DPM scheduler with 60 steps. Asour system does not require any training or fine-tuning, alllisted datasets are used for evaluations. To evaluate MBMCin real world scenarios, so we gather an ambitious mix of di-verse datasets as MPII Human Pose , More Inclusive An-notations for People (MIAP) , People in Social Context(PiSC) , Human Interaction Images (HII) , Market1501 , LaMa Humans , and generated.photos .",
  ". Conclusion": "We present My Body My Choice to grant back thecontrol over bodies to their owners. Our work extends theutility of diffusion models in anonymization by leveragingtheir capabilities with human guidance, with more results inSupp. B. As the call for ethical data handling and privacypreservation grows louder, our work marks a pivotal steptowards responsible use of biometric data.",
  "Realistic vision v5.1.https : / / civitai . com /models/4201/realistic-vision-v20. Accessed:2023-08-02. 3": "Mykhaylo Andriluka, Leonid Pishchulin, Peter Gehler, andBernt Schiele. 2d human pose estimation: New benchmarkand state of the art analysis. In IEEE Conference on Com-puter Vision and Pattern Recognition (CVPR), June 2014. 3 Thangapavithraa Balaji, Patrick Blies, Georg Gori, RaphaelMitsch, Marcel Wasserer, and Torsten Schon. Temporallycoherent video anonymization through gan inpainting. arXivpreprint arXiv:2106.02328, 2021. 2 Vojtech Bartl, Jakub Spanhel, and Adam Herout.Per-songone: Image inpainting for automated checkout solution.In Proceedings of the IEEE/CVF Conference on ComputerVision and Pattern Recognition (CVPR) Workshops, pages31153123, June 2022. 2 Karla Brkic; Ivan Sikiric; Tomislav Hrkac; Zoran Kalafatic.I know that person:Generative full body and face de-identification of people in images.In Proceedings of theIEEE Conference on Computer Vision and Pattern Recog-nition (CVPR) Workshops, July 2017. 2 Z. Cao, G. Hidalgo Martinez, T. Simon, S. Wei, and Y. A.Sheikh. Openpose: Realtime multi-person 2d pose estima-tion using part affinity fields. IEEE Transactions on PatternAnalysis and Machine Intelligence, 2019. 3 Renwang Chen, Xuanhong Chen, Bingbing Ni, and YanhaoGe. Simswap: An efficient framework for high fidelity faceswapping.In Proceedings of the 28th ACM InternationalConference on Multimedia, pages 20032011, 2020. 3 Zhiqin Chen, Kangxue Yin, and Sanja Fidler.Auv-net:Learning aligned uv maps for texture transfer and synthesis.In Proceedings of the IEEE/CVF Conference on ComputerVision and Pattern Recognition (CVPR), pages 14651474,June 2022. 2 Ka-Ho Chow, Ling Liu, Margaret Loper, Juhyun Bae,Mehmet Emre Gursoy, Stacey Truex, Wenqi Wei, andYanzhao Wu. Adversarial objectness gradient attacks in real-time object detection systems. In IEEE International Con-ference on Trust, Privacy and Security in Intelligent Systems,and Applications, pages 263272. IEEE, 2020. 3 Umur A Ciftci, Gokturk Yuksek, and Ilke Demir. My facemy choice:Privacy enhancing deepfakes for social me-dia anonymization. In Proceedings of the IEEE/CVF Win-ter Conference on Applications of Computer Vision, pages13691379, 2023. 2, 3, 4",
  "age inpainting.IEEE Transactions on Image Processing,13(9):12001212, September 2004. MSR-TR-2003-83. 2": "Michael D Ekstrand,Rezvan Joshaghani,and HodaMehrpouyan. Privacy for all: Ensuring fair and equitableprivacy protections. In Conference on fairness, accountabil-ity and transparency, pages 3547. PMLR, 2018. 1 Andrew G Howard, Menglong Zhu, Bo Chen, DmitryKalenichenko, Weijun Wang, Tobias Weyand, Marco An-dreetto, and Hartwig Adam. Mobilenets: Efficient convolu-tional neural networks for mobile vision applications. arXivpreprint arXiv:1704.04861, 2017. 3",
  "Xun Huang and Serge Belongie. Arbitrary style transfer inreal-time with adaptive instance normalization. In Proceed-ings of the IEEE International Conference on Computer Vi-sion (ICCV), Oct 2017. 2": "Hakon Hukkelas and Frank Lindseth.Deepprivacy2: To-wards realistic full-body anonymization. In Proceedings ofthe IEEE/CVF Winter Conference on Applications of Com-puter Vision (WACV), pages 13291338, January 2023. 2,4 Hakon Hukkelas, Morten Smebye, Rudolf Mester, and FrankLindseth. Realistic full-body anonymization with surface-guided gans. In Proceedings of the IEEE/CVF Winter Con-ference on Applications of Computer Vision (WACV), pages14301440, January 2023. 2",
  "Tero Karras, Samuli Laine, Miika Aittala, Janne Hellsten,Jaakko Lehtinen, and Timo Aila. Analyzing and improvingthe image quality of StyleGAN. In Proc. CVPR, 2020. 3": "Marvin Klemp, Kevin Rosch, Royden Wagner, Jannik Quehl,and Martin Lauer. Ldfa: Latent diffusion face anonymiza-tion for self-driving applications.In Proceedings of theIEEE/CVF Conference on Computer Vision and PatternRecognition (CVPR) Workshops, pages 31983204, June2023. 2 Junnan Li, Yongkang Wong, Qi Zhao, and Mohan S Kankan-halli.Dual-glance model for deciphering social relation-ships. In Proceedings of the IEEE international conferenceon computer vision, pages 26502659, 2017. 3 Wenbo Li, Zhe Lin, Kun Zhou, Lu Qi, Yi Wang, and JiayaJia. Mat: Mask-aware transformer for large hole image in-painting. In Proceedings of the IEEE/CVF Conference onComputer Vision and Pattern Recognition, 2022. 2, 3, 4",
  "In Alice H. Oh, Alekh Agarwal, Danielle Belgrave, andKyunghyun Cho, editors, Advances in Neural InformationProcessing Systems, 2022. 3": "Liqian Ma,Qianru Sun,Stamatios Georgoulis,LucVan Gool, Bernt Schiele, and Mario Fritz. Disentangled per-son image generation. In Proceedings of the IEEE confer-ence on computer vision and pattern recognition, pages 99108, 2018. 2 Maxim Maximov, Ismail Elezi, and Laura Leal-Taixe. Cia-gan: Conditional identity anonymization generative adver-sarial networks. In Proceedings of the IEEE/CVF Confer-ence on Computer Vision and Pattern Recognition (CVPR),June 2020. 2 Kamyar Nazeri, Eric Ng, Tony Joseph, Faisal Qureshi, andMehran Ebrahimi.Edgeconnect:Structure guided im-age inpainting using edge prediction.In Proceedings ofthe IEEE/CVF international conference on computer visionworkshops, pages 00, 2019. 2",
  "Carman Neustaedter, Saul Greenberg, and Michael Boyle.Blur filtration fails to preserve privacy for home-basedvideo conferencing. ACM Trans. Comput.-Hum. Interact.,13(1):136, mar 2006. 1": "Natalia Neverova, David Novotny, Marc Szafraniec, VasilKhalidov, Patrick Labatut, and Andrea Vedaldi.Continu-ous surface embeddings. Advances in Neural InformationProcessing Systems, 33:1725817270, 2020. 2 Taesung Park, Ming-Yu Liu, Ting-Chun Wang, and Jun-YanZhu. Semantic image synthesis with spatially-adaptive nor-malization.In Proceedings of the IEEE/CVF Conferenceon Computer Vision and Pattern Recognition (CVPR), June2019. 2 Alec Radford, Jong Wook Kim, Chris Hallacy, AdityaRamesh, Gabriel Goh, Sandhini Agarwal, Girish Sastry,Amanda Askell, Pamela Mishkin, Jack Clark, et al. Learningtransferable visual models from natural language supervi-sion. In International conference on machine learning, pages87488763. PMLR, 2021. 3",
  "networks for efficient edge detection.In Proceedings ofthe IEEE/CVF international conference on computer vision,pages 51175127, 2021. 3": "Qianru Sun, Liqian Ma, Seong Joon Oh, Luc Van Gool,Bernt Schiele, and Mario Fritz. Natural and effective obfus-cation by head inpainting. In Proceedings of the IEEE Con-ference on Computer Vision and Pattern Recognition, pages50505059, 2018. 2 Qianru Sun, Ayush Tewari, Weipeng Xu, Mario Fritz, Chris-tian Theobalt, and Bernt Schiele. A hybrid model for identityobfuscation by face replacement. In Proceedings of the Eu-ropean conference on computer vision (ECCV), pages 553569, 2018. 2 Roman Suvorov, Elizaveta Logacheva, Anton Mashikhin,Anastasia Remizova, Arsenii Ashukha, Aleksei Silvestrov,Naejin Kong, Harshith Goka, Kiwoong Park, and VictorLempitsky.Resolution-robust large mask inpainting withfourier convolutions.arXiv preprint arXiv:2109.07161,2021. 2, 3, 4",
  "Julian Todt, Simon Hanisch, and Thorsten Strufe.Fant\\omas: Evaluating reversibility of face anonymizations us-ing a general deep learning attacker.arXiv preprintarXiv:2210.10651, 2022. 1": "Xintao Wang, Yu Li, Honglun Zhang, and Ying Shan. To-wards real-world blind face restoration with generative fa-cial prior. In The IEEE Conference on Computer Vision andPattern Recognition (CVPR), 2021. 3 Yinghao Xu, Menglei Chai, Zifan Shi, Sida Peng, Ivan Sko-rokhodov, Aliaksandr Siarohin, Ceyuan Yang, Yujun Shen,Hsin-Ying Lee, Bolei Zhou, et al.Discoscene: Spatiallydisentangled generative radiance fields for controllable 3d-aware scene synthesis.In Proceedings of the IEEE/CVFConference on Computer Vision and Pattern Recognition,pages 44024412, 2023. 2 Jie Yang, Zhiquan Qi, and Yong Shi. Learning to incorporatestructure knowledge for image inpainting. In Proceedings ofthe AAAI conference on artificial intelligence, volume 34,pages 1260512612, 2020. 2",
  "Ahmet Burak Yildirim, Vedat Baday, Erkut Erdem, AykutErdem, and Aysegul Dundar. Inst-inpaint: Instructing to re-move objects with diffusion models, 2023. 2": "Jiahui Yu, Zhe Lin, Jimei Yang, Xiaohui Shen, Xin Lu, andThomas S Huang. Generative image inpainting with con-textual attention. In Proceedings of the IEEE conference oncomputer vision and pattern recognition, pages 55055514,2018. 2 Jiahui Yu, Zhe Lin, Jimei Yang, Xiaohui Shen, Xin Lu, andThomas S Huang. Free-form image inpainting with gatedconvolution. In Proceedings of the IEEE/CVF internationalconference on computer vision, pages 44714480, 2019. 2 Yanhong Zeng, Jianlong Fu, Hongyang Chao, and BainingGuo. Learning pyramid-context encoder network for high-quality image inpainting. In Proceedings of the IEEE/CVFconference on computer vision and pattern recognition,pages 14861494, 2019. 2 Yu Zeng, Zhe Lin, Jimei Yang, Jianming Zhang, Eli Shecht-man, and Huchuan Lu.High-resolution image inpaintingwith iterative confidence feedback and guided upsampling.In Computer VisionECCV 2020: 16th European Confer-ence, Glasgow, UK, August 2328, 2020, Proceedings, PartXIX 16, pages 117. Springer, 2020. 2",
  "B. All Dataset Results": "In , we select interesting results from MIAP (-top) and PiSC (-right) for mask-based,and LaMa Humans (-left) for physical removaltask. Overall, images look realistic and people look sig-nificantly different; even in the existence of multiple peo-ple, complex illumination, fog, reflections, complex inter-actions, patterns, oblique views, occlusions, face paint, etc.. Umur A Ciftci, Gokturk Yuksek, and Ilke Demir. My facemy choice: Privacy enhancing deepfakes for social mediaanonymization. In Proceedings of the IEEE/CVF Winter Con-ference on Applications of Computer Vision, pages 13691379, 2023. 1 Junnan Li, Yongkang Wong, Qi Zhao, and Mohan S Kankan-halli. Dual-glance model for deciphering social relationships.In Proceedings of the IEEE international conference on com-puter vision, pages 26502659, 2017. 1, 2 Candice Schumann, Susanna Ricco, Utsav Prabhu, VittorioFerrari, and Caroline Rebecca Pantofaru. A step toward moreinclusive people annotations for fairness. In Proceedings ofthe AAAI/ACM Conference on AI, Ethics, and Society (AIES),2021. 1, 2 Roman Suvorov, Elizaveta Logacheva, Anton Mashikhin,Anastasia Remizova, Arsenii Ashukha, Aleksei Silvestrov,Naejin Kong, Harshith Goka, Kiwoong Park, and Victor Lem-pitsky. Resolution-robust large mask inpainting with fourierconvolutions. arXiv preprint arXiv:2109.07161, 2021. 1, 2"
}