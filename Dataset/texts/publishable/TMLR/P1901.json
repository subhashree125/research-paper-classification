{
  "Abstract": "The evolution of artificial intelligence (AI) has profoundly impacted human society, driv-ing significant advancements in multiple sectors. Yet, the escalating demands on AI havehighlighted the limitations of AIs current offerings, catalyzing a movement towards Arti-ficial General Intelligence (AGI). AGI, distinguished by its ability to execute diverse real-world tasks with efficiency and effectiveness comparable to human intelligence, reflects aparamount milestone in AI evolution.While existing studies have reviewed specific ad-vancements in AI and proposed potential paths to AGI, such as large language models(LLMs), they fall short of providing a thorough exploration of AGIs definitions, objec-tives, and developmental trajectories. Unlike previous survey papers, this work goes beyondsummarizing LLMs by addressing key questions about our progress toward AGI and out-lining the strategies essential for its realization through comprehensive analysis, in-depthdiscussions, and novel insights. We start by articulating the requisite capability frameworksfor AGI, integrating the internal, interface, and system dimensions. As the realization ofAGI requires more advanced capabilities and adherence to stringent constraints, we furtherdiscuss necessary AGI alignment technologies to harmonize these factors. Notably, we em-phasize the importance of approaching AGI responsibly by first defining the key levels ofAGI progression, followed by the evaluation framework that situates the status-quo, andfinally giving our roadmap of how to reach the pinnacle of AGI. Moreover, to give tangibleinsights into the ubiquitous impact of the integration of AI, we outline existing challengesand potential pathways toward AGI in multiple domains. In sum, serving as a pioneeringexploration into the current state and future trajectory of AGI, this paper aims to fostera collective comprehension and catalyze broader public discussions among researchers andpractitioners on AGI. 1 Equal contribution. In alphabetical order.Corresponding author. All student authors complete this work as interns at UIUC.1Project website: Unlike traditional publications that remain static, we em-brace an innovative approach by treating this paper as a living document. We warmly welcome feedback from the communityand plan to update the paper annually. Contributors on the project website will be gratefully acknowledged in future revisions.",
  "Collaboration": ": Overall Structure of This Paper. This paper starts with discussing core AGI components,including AGI Internal ( 2), AGI Interface ( 3), and AGI Systems ( 4); these discussions help us measurethe ability of AGI and estimate how far we are from AGI. As we get closer to AGI, we further expect AGIto meet various constraints, which can be realized by AGI Alignment ( 5) techniques. We further outlinean AGI Roadmap ( 6) that helps researchers approach AGI responsibly. Finally, some Case Studies ( 7)are presented to illustrate the current development of early-stage AGI in various fields. To start approaching the question of how far we are from AGI, it is important to first ground ourselveswith the history of artificial intelligence advancement and understand the urge for more advanced systems.Throughout the whole paper, we hope to provide evidences and insights on where we currently stand alongthe road towards AGI, from the lens of many modern AI systems such as large language models. The goalis to prudently keep questioning ourselves: are LLMs all we need? It is with this enduring curiosity andawareness that we might finally begin to touch the realm of AGI.",
  "Published in Transactions on Machine Learning Research (10/2024)": "Wangchunshu Zhou, Yuchen Eleanor Jiang, Long Li, Jialong Wu, Tiannan Wang, Shi Qiu, Jintian Zhang,Jing Chen, Ruipu Wu, Shuai Wang, et al. 2023a. Agents: An open-source framework for autonomouslanguage agents. arXiv preprint arXiv:2309.07870 (2023). Xuhui Zhou, Hao Zhu, Leena Mathur, Ruohong Zhang, Haofei Yu, Zhengyang Qi, Louis-Philippe Morency,Yonatan Bisk, Daniel Fried, Graham Neubig, et al. 2023d.Sotopia: Interactive evaluation for socialintelligence in language agents. arXiv preprint arXiv:2310.11667 (2023). Yanqi Zhou, Tao Lei, Hanxiao Liu, Nan Du, Yanping Huang, Vincent Zhao, Andrew Dai, Zhifeng Chen, QuocLe, and James Laudon. 2022a. Mixture-of-Experts with Expert Choice Routing. arXiv:2202.09368 [cs.LG]",
  "Douglas Hofstadter, I Am a Strange Loop": "The complexity of the human brain, with its specific functional regions dedicated to distinct aspects ofcognition and behavior, offers a compelling analogy for the architecture of AGI systems. Similar to the humanbrains division into areas for sensory processing, emotion, cognition, and executive functions, the brainof an AGI system could also be fundamentally organized into four main components: perception, memory,reasoning capabilities, and metacognition. These components mirror the essential aspects of human cognitionand play different crucial roles in creating a truly intelligent system. We summarize the overview of thissection in , which shows the current state and future expectations of AGI internal. Perception (Sec2.1) refers to the organization and interpretation of sensory information during the interaction between theAGI and its environment (Wang and Hammer, 2018) and is regarded as a fundamental ability in AGI, whichincludes vision, hearing, touch, smell, etc. The reasoning (Sec 2.2) of AGI is based on the perception of theenvironment and executes actions to the environment. The interactions between AGI and the environmentcontaining the acquisition of perception and execution of action would be saved as the memories (Sec 2.3)of AGI. The memories will be utilized for the metacognition (Sec 2.4) of AGI.",
  ": There are three categories for multimodal models with LLM external connections: projection-based, query-based, and language-based": "their capacity to understand and engage in conversations, as well as to perform creative tasks. However,text alone may not fully capture the depth of real-world experiences (Harnad, 1990; Bisk et al., 2020; Tuet al., 2023b), underscoring the importance of multi-modal intelligence that incorporates images, video, andaudio for richer human-machine interaction. The transition from traditional LLMs to multi-modal modelsrepresents a significant technological leap, facilitating more lifelike interactions across various inputs. Thisshift, highlighted by recent developments in multi-modal LLMs (OpenAI, 2023b; Team et al., 2023; Li et al.,2023h; Dai et al., 2023; Ye et al., 2023; Zhu et al., 2023a; Liu et al., 2023d; Su et al., 2023; Chen et al., 2023j; Liet al., 2024e; He et al., 2024; Laurenon et al., 2024; Chu et al., 2023), addresses the constraints of language-only comprehension and opens the door to addressing complex challenges that involve multiple forms ofdata. Integrating various models should adhere to two principles: 1) understanding how to incorporateexternal modal information and ensuring a seamless integration of different modules; 2) determining whatinformation to use for preserving the integrity of the original models and enhancing overall capabilities. The primary objective of utilizing off-the-shelf LLMs and multi-modal encoders is to establish a seamlessconnection between them. This connection can either be external, aligning multi-modal knowledge withoutaltering the existing model structure, or internal, allowing for a more intricate interaction between LLMs andother modal encoders (Yin et al., 2023). These methods often require extensive training, such as creatinga learnable interface to link the LLM with non-linguistic modalities, particularly vision. Like LLM pre-training and fine-tuning, Multi-modal LLMs (MLLMs) follow a two-stage training paradigm based on apre-trained LLM and adapt the process to the multi-modal domain. The first stage, known as the vision-language alignment stage, aims to enable the language model to comprehend visual tokens. The second stageinvolves multi-modal instruction tuning to align the model with human perceptions. These stages have clearcategories based on the combination architectures between the LLM and multi-modal encoders.",
  "External Connection of Modalities. The external approach is based on the idea of bridging thevision branch and LLMs with extra structures and existing models": "1. Projection-based: the modality connector exists outside both the LLMs and multi-modal encoders canbe quite straightforward with simple linear projections (Zhu et al., 2023a; Liu et al., 2023d; Su et al.,2023; Chen et al., 2023j; Li et al., 2024e) or incorporating relatively complex selection method (Gaoet al., 2023a; Zhang et al., 2023e; Luo et al., 2023; Han et al., 2023b; Fu et al., 2024a). This type ofMLLM usually activates the projection layer and/or the LLMs for two stages of alignment training. 2. Query-based: these MLLMs employ a more intricately designed connector but still stand outside ofLLMs and multi-modal encoders. This type of model essentially leverages an attention-like interactionbetween a learnable variable and the vision tokens (Dai et al., 2023; Li et al., 2023h; Ye et al., 2023; Heet al., 2024). Since their connectors can learn more complex data patterns than simple projection-basedones, activating the connector alone can also obtain superior multi-modal performance.",
  "Internal Connection of Modalities. Another direction for bridging the multi-modal encoder and theLLM lies in twitching the LLM interblocks": "1. Cross-attention-based: Flamingo (Alayrac et al., 2022) proposed the well-known perceiver with ad-ditional cross-attention mechanism inside the attention block of the LLMs.Several variants ofFlamingo (Li et al., 2023l; Gong et al., 2023) also use the same or similar framework for tuningthe MLLMs. 2. Autoregressive: MLLMs like Fuyu (Bavishi et al., 2023) and its variants (Li et al., 2023m) take visiontoken as the language token from the pre-training stage and use the same autoregressive training lossto update the whole model parameter. Additional modalities for MLLMs While earlier models predominantly focused on visual inputs andtextual outputs, recent developments have broadened to include diverse modalities in both input andoutput forms. Regarding inputs, with appropriate modal encoders and training data (Girdhar et al.,2023; Zhu et al., 2023c), LLMs can now comprehend video, audio (Zhang et al., 2023g; Chen et al.,2023d; Lyu et al., 2023; Zhang et al., 2023h), and multiple non-linguistic modalities concurrently (Suet al., 2023; Han et al., 2023b;a), making this approach scalable and accessible.Regarding outputs,recent research has shifted toward creating hybrid content that goes beyond mere text generation. LLMshave evolved from initially retrieving images and generating text (Koh et al., 2023b; Chen et al., 2023j) toproducing both visual and textual content. The detailed technical paths of generating images and textsinclude autoregressive tuning of image-text data with unified representations Sun et al. (2023d); Zhenget al. (2023a); Liu et al. (2024b) and symbolic tuning that transforms text features into image generativemodels like Stable Diffusion (Koh et al., 2023a; Ge et al., 2023a). Moreover, recent advancements invision have opened up scalable methods for generating content without text, enhancing the potential forgeneralizing and scaling vision-only models to generative tasks (Bai et al., 2023; El-Nouby et al., 2024).This opens up the possibility of discovering similar AGI phenomena when scaling foundation modelsin other modalities than language. AGI-level Perception Current models of perception are still limited by their limited modality and lackof robustness. To address these limitations, we propose several potential future research directions: The diversification of modalities is essential for integrating multiple data types and improv-ing model capabilities. It is crucial to explore less common modalities, such as graphs, and to integratemultiple modalities, such as images, audio, and video simultaneously (Han et al., 2023b;a). This will re-quire carefully designed modules, high-quality data, and a balanced approach to managing the interplaybetween different modalities and their relationship with language. For example, while GPT-4V can onlyhandle language and visual information, the recent Gemini (Team et al., 2023) model expands its capacityto a wider range of audio and video. Potential methods for incorporating other modal perceptions: aunified modal representation tool like ImageBind (Han et al., 2023b), LangaugeBind (Zhu et al., 2023c)could bridge the modal gap and lessen the burden of learning from other modalities. Existing modelsthat incorporate these tools have shown promising results in efficiency and task performance (Su et al.,2023; Han et al., 2023b).",
  "Immanuel Kant, Critique of Pure Reason": "Reasoning is the cognitive process of drawing conclusions or making decisions based on available information,logic, and prior knowledge. It involves evaluating evidence, identifying relationships, and applying rules orprinciples to solve problems (Fagin et al., 2004; Huang and Chang, 2022). AI reasoning refers to the abilityof AI systems to simulate this process, enabling machines to understand situations, infer conclusions, andmake decisions in a way that mimics human reasoning. Current State of AI ReasoningSubstantial research indicates that reasoning capabilities have emergedin large machine-learning models. Large Language Models (LLMs), including GPT-3 (Brown et al., 2020),LLaMA 2 (Touvron et al., 2023), and PALM 2 (Anil et al., 2023), have unlocked flexible zero-shot and few-shot reasoning capabilities across various NLP tasks (Kojima et al., 2022). Large Visual Language Models(LVLMs) such as GPT-4 with vision (OpenAI, 2023a) and Gemini (Team et al., 2023), have advanced thisprogress by effectively integrating vision and language reasoning. Numerous strategies have been developed to elicit effective and efficient reasoning without updating themodel. These methods have substantially improved model performance across a wide range of tasks, includingarithmetic, commonsense, symbolic reasoning, and challenges in both simulated and real-world settings.",
  "AGI-level Reasoning While current systems exhibit impressive reasoning skills across various tasks, theyalso have several substantial flaws and challenges": "Foundation models need to learn causation for better understanding and generalization. Thefoundation models rely heavily on patterns identified in their training data, which do not always capturethe depth and breadth of human knowledge and experiences. Furthermore, these models often operatebased on patterns extracted from data without truly comprehending the underlying causal relationships.Zeevi et al. (2023) describe how LLMs might superficially replicate causal relationships but lack the",
  "Marcel Proust, In Search of Lost Time": "Language and vision models, by their nature, are stateless; they do not maintain information betweeninteractions. However, advanced agents differ in that they can manage internal or external memory, enablingthem to engage in complex, multi-step interactions (Sumers et al., 2023; Zhang et al., 2024a). This memorystores intermediate information, domain-specific or broad knowledge, and sequences of the agents previousobservations, thoughts, and actions, among others.It assists agents in utilizing previous knowledge orexperiences for reasoning, planning, and self-improvement. Current State of AI MemoryWe examine the current state of AI memory, focusing on three keyaspects: memory management, which determines what and when to store; memory representation, whichdefines how information is structured; and memory utilization, which addresses how to apply and use thememory efficiently and effectively.",
  "Memory management. Memory is categorized by duration into short-term and long-term memory": "1. Short-term memory: Short-term memory plays a crucial role in maintaining information needed forcurrent decision-making processes. A notable example is in-context prompting, which uses the foun-dation models own context as a form of short-term memory. This approach can provide additionalinformation or examples (Wang et al., 2020), or can be used to generate intermediate reasoning (Nyeet al., 2021; Wei et al., 2022b). More broadly, short-term memory encompasses all immediate dataessential for decision-making. This includes: (1) real-time data collected or processed by perceptionmodules; (2) immediate outputs from reasoning, planning, and self-evolution modules; and (3) infor-mation actively retrieved from long-term memory. These elements collectively are synthesized to guideand inform subsequent actions. 2. Long-term memory: Long-term memory can be broadly classified into two main types: experiences andknowledge. Experiences encompass a range of elements such as past observations, thoughts, actions,and more. This rich collection of experiences serves a critical function in decision-making processes. Byretrieving relevant experiences, agents can gain additional information necessary for reasoned judgment,understand feedback from past actions, and achieve a level of generalization in their understanding andreasoning. For example, Reflexion (Shinn et al., 2023) reflects on task feedback signals and maintainsthem as textual summaries. These summaries are directly incorporated into the context of subsequentepisodes, aiding in performance enhancement. Generative agents (Park et al., 2023) document their",
  "Memory utilization. There are two common technologies to utilize memories: memory retrieval andlong-context LLMs": "1. Memory retrieval: Memory retrieval involves reading information from long-term memory to short-term memory for immediate use. This can be accomplished through rule-based retrieval or retrieval-augmented methods. Rule-based retrieval can search memory using keywords, timesteps, or specificpatterns. In retrieval-augmented approaches, the Dense Passage Retriever (DPR) (Karpukhin et al.,2020) creates dense representations of documents and retrieves the most relevant documents basedon their prior probability using Maximum Inner Product Search (MIPS). The Retrieval-AugmentedLanguage Model pre-training (REALM) (Guu et al., 2020) integrates unsupervised pre-training of aknowledge retriever with masked language modeling, enabling direct retrieval of documents to sup-plement language predictions. Retrieval-Augmented Generation (RAG) models (Lewis et al., 2020;Shuster et al., 2021; Borgeaud et al., 2022) employ a non-parametric memory, such as a dense vectorindex of Wikipedia, accessed via a pre-trained neural retriever (e.g., DPR). These documents are pro-cessed by a seq2seq model, which conditions its output generation on both the input and the retrieveddocuments. Both the retriever and seq2seq modules, initialized from pre-trained models, are jointlyfine-tuned, allowing both retrieval and generation to adapt to downstream tasks. 2. Long-context LLMs: The expansion of the context window in long-context LLMs opens up new avenuesfor models to access their long-term memory.Works like Ring Attention (Liu et al., 2023j) andLongRoPE (Ding et al., 2024b) greatly reduce the time and cost of long context inference by improvingthe operation mechanism and storage method of attention.More powerful GPUs with enhancedmemory capabilities and further breakthroughs in memory-efficient attention mechanisms (Dao et al.,2022; Tay et al., 2022), allowing the context window for pre-trained LLMs to increase from 1024tokens in GPT-2 (Radford et al., 2019), to 8192 in GPT-4 (Achiam et al., 2023), and now exceeding16K tokens. With these expanded context windows, AI systems can more effectively store and recallknowledge and experiences within their context, enabling faster and more comprehensive context-basedreasoning.",
  "Charlotte Bront, Jane Eyre": "Metacognition (Choudrie and Selamat, 2006) of humans involves key cognitive and emotional skills such asunderstanding complex situations, self-awareness, and motivation to innovate. These abilities help shareimplicit knowledge and drive personal growth. The development of AGIs with such advanced metacognition provokes a fundamental inquiry: are we, in ourpursuit of artificial intelligence, on the verge of creating a new form of life? The implications are far-reaching,as introducing entities with self-awareness and autonomous decision-making capabilities could redefine theboundaries of life and intelligence. This tantalizing horizon calls for meticulous ethical consideration and",
  "regulatory scrutiny to ensure that the evolution of AGI contributes positively to human society and doesnot inadvertently engender a paradigm shift with unforeseen consequences": "Current State of AI MetacognitionThe discourse on metacognition extends into the realm ofAGI, where such capabilities are deemed equally critical. For AGI systems, metacognition, such as self-awareness (Chella et al., 2020; Subagdja et al., 2021), consciousness (Dehaene et al., 2021), the capacityfor self-evolution (Floreano et al., 2004; Tao et al., 2024), and theory of mind (Cuzzolin et al., 2020), areposited to be foundational for bridging the gap towards achieving AGI. These internal abilities can enableAI systems to autonomously learn, efficiently complete tasks, and align more closely with human intentions. Self-Awareness in AGI. Developing self-awareness in AI, particularly within the realm of robotics (Scas-sellati, 2002), hinges on intricate concepts such as self-reflection (Shinn et al., 2024), meta-cognition (Lang-don et al., 2022), and self-distancing (Kross and Ayduk, 2017). These concepts are integral to constructingsocial robots equipped with cognitive architectures that support self-description, the utilization of per-sonal pronouns, and the ability to respond to self-focusing cues, which are fundamental for facilitatingeffective human interactions and environmental navigation. As AI systems evolve, the philosophical andpractical considerations of equipping them with human-like traits of conscientiousness are gaining trac-tion, heralding a burgeoning field of research (Huang et al., 2023c). For a thorough understanding ofthis area, interdisciplinary approaches that intertwine psychology, artificial intelligence, and ethics areinstrumental. To seamlessly integrate into the human-centric world, AGI must possess an acute awareness of the beliefs,intentions, and desires of both themselves and others. This Theory of Mind (Premack and Woodruff,1978) is a meta-ability that enables AGIs to understand and predict behaviors, facilitating smootherhuman interactions. This comprehension will allow for more nuanced and informed decision-making byAGIs, particularly in complex social contexts. AGI holding certain persona. Recent advancements reveal that LLMs can exhibit consistent person-ality traits, such as those categorized by the Big Five or MBTI frameworks, with models like ChatGPToften exhibiting traits aligned with the ENFJ type (Huang et al., 2023c). These models also tend to dis-play certain cognitive thinking styles, with evidence suggesting an inclination towards holistic thinking inChatGPTs responses (Jin et al., 2023c). Research efforts are increasingly directed towards intentionallyimbuing LLMs with specific personalities, enabling them to demonstrate a variety of behaviors that areboth diverse and verifiable (Caron and Srivastava, 2022; Jiang et al., 2022b). AGI metacognition ability in self-evolving.While the aforementioned research defines AGI interms of easily measurable capabilities such as reasoning (Butlin et al., 2023; Morris et al., 2024), itmay overlook the potential importance of meta-cognitive abilities such as self-evolution or self-awareness.Studies predominantly showcase this through the agents iterative adaptation via task execution (Le, 2019;Wang et al., 2023e), code execution (Gao et al., 2020), or feedback from physical simulations (Qian et al.,2024; Xu et al., 2023a). Other strategies for self-evolution include prompt adaptation and optimization(Wang et al., 2023h; Aksitov et al., 2023), continuous improvement through error identification and self-reflection, and memory retrieval as a mechanism for short- or long-term learning.These approachesmainly emphasize the iterative refinement of tasks within a loop-structured framework based on LLMs.In contrast, recent advancements propose methodologies that address inter-task agent self-evolution,highlighting the significance of leveraging past experiences to effectively evolve AI systems (Qian et al.,2024; Xu et al., 2023a). These traits are crucial for various reasons. First, self-awareness could enhance AGIs adaptive problem-solving abilities by allowing it to accurately assess its strengths and limitations, thus facilitating adjusting itsstrategies in real time when faced with new challenges. Second, the capacity for ethical and moral decision-making is increasingly imperative as AGI becomes more entwined with societal functions, necessitatinga self-awareness component to enable navigation through complex moral dilemmas and ensure alignmentwith human values. Furthermore, the potential for AGI to autonomously evolve and adapt without humanguidance promises greater efficiency and capability in the long term, possibly leading to an exponential",
  "AGI Interface: Connecting the World with AGI": "In the pursuit of developing AGI, a crucial aspect to address is its capability to interact with the externalworld. This interaction is facilitated through various interfaces that enable AGI systems to perceive, under-stand, and act within their environment, be it digital, physical, or intellectual. We summarize these threefuture directions in .",
  "Safety &Alignment": ": The Interconnected Spheres of AGI Interface. In the left part, we present some key elementsin three interfaces: Digital ( 3.1), Physical ( 3.2), and Intelligence Interface ( 3.3). On the right side ofthe figure, we outline several potential future aspects that could be significant. similar to human-like behavior (Qin et al., 2023a). This interface serves as a crucial bridge for groundingAGI in complex, real-world scenarios, providing an indispensable platform for simulating and interactingwith the multifaceted nature of human knowledge and experience. By facilitating AGIs engagement withreal-world information structures and problem-solving contexts, this digital world interface accelerates thedevelopment of more versatile and robust artificial general intelligence capable of operating effectively acrossvarious domains. Current State of AI Interface to Digital WorldDigital embodiment enables agents to interactdynamically and flexibly with the world.For instance, agents can utilize various APIs to navigate theweb, search for relevant information, and construct personalized knowledge bases, allowing them to updatetheir knowledge and adapt to new situations continuously. This approach drives the development of moreadvanced AI systems, particularly in natural language processing and reasoning capabilities. Integrating digital tools in LLMs significantly enhances their capabilities and addressesinherent limitations. Utilizing specialized tools augments their domain-specific expertise and increasesdecision-making transparency and robustness. The Toolformer model (Schick et al., 2023) demonstratesLLMs ability to learn and effectively employ various external tools autonomously, with advanced learningmethods mirroring human learning processes (Xi et al., 2023; Qin et al., 2023a). Models like Gorilla(Patil et al., 2023) connect LLMs with a wide array of APIs, highlighting the evolution towards greaterautonomy and application versatility. LLMs are beginning to create and modify tools (Cai et al., 2024b;Qian et al., 2023b), leading to a future where agents exhibit increased self-sufficiency. This expansion in",
  "tool functionality facilitates multi-modal interactions and broadens the range of tasks LLMs can perform,aligning with the goals of embodied learning research (Zhuang et al., 2023)": "LLM-based agents and frameworks demonstrate the capabilities of digital embodiment (Zhouet al., 2024b; Wu et al., 2024b; Deng et al., 2023; Yang et al., 2023b). Mind2Web (Deng et al., 2023) allowsfor the comprehensive evaluation of agent generalizability in web scenarios, a critical aspect in creatingrobust and efficient web-based artificial intelligence. Voyager (Wang et al., 2023h) is an embodied agentin the Minecraft game that uses iterative prompting for dynamic reasoning and skill acquisition. To moveforward, Generative Agents (Park et al., 2023), grounded in a sandbox game, have a memory stream thatrecords experiences in natural language, enabling informed moment-to-moment behavior. Each of themfocuses on different types of digital embodiment.",
  "AGI-level Interfaces to the Digital World While the current state of AGI tool usage is advanced, ithighlights several pivotal areas for reaching this goal": "AGI systems creation of novel tools is nascent and limited, requiring a leap beyond human-designed frameworks for true autonomy. Creating novel tools by AGI systems, as exemplified by theCREATOR framework (Qian et al., 2023c), is a groundbreaking step. Yet, the ability of AGI systems toinvent tools autonomously remains nascent. These systems often rely on human-designed frameworks andalgorithms, limiting their creative scope. True AGI would require a leap beyond this, enabling systemsto ideate and engineer tools independently and intuitively. Extending the scope of digital worlds. There are still many opportunities to empower AGI sys-tems with interfaces in different modalities and various environments, such as wearable computing, smartenvironments, mixed-reality settings, and emerging technologies like virtual reality (VR) and extendedreality (XR). Although AGI will continue to exhibit promising performance in such interaction tasks,researchers need to explore potential solutions to ensure that AGI can yield beneficial results to humanswhile minimizing the cost of interaction. AGI should be able to seamlessly integrate with these technolo-gies, leveraging their unique affordances to create more engaging and intuitive interactions. Moreover,AGI systems should be capable of adapting to novel interaction paradigms that may emerge in the future,ensuring that they remain relevant and valuable to users in the long term.",
  "Nikola Tesla": "The integration of AI into physical entities is a crucial aspect of the pursuit of AGI. AGI in the physical worldemphasizes learning through direct interaction with the environment and making an impact on reality, suchas creating or modifying substances. In this section, we will explore the latest advancements in embodiedAI in the physical world, including robotic control, navigation, and manipulation. Current State of AI Interfaces to the Physical World The current state mainly lies in the interactionwith robotic functionalities, understanding the potential for more intuitive human-robot interfaces, andemphasizing the importance of real-world datasets in advancing AIs practical applications. Robotic control and action. Recent advancements in robotic control and action including PaLM-E (Driess et al., 2023), RT-2 (Zitkovich et al., 2023), and Mobile Aloha (Fu et al., 2024b) demonstrate thepotential for robots to interpret and execute complex, high-level instructions through natural language,providing a more intuitive interface between humans and robots. SayCan (Ahn et al., 2022) combinesthe semantic understanding capabilities of PaLM (Chowdhery et al., 2022a) with robotic affordances,enabling robots to understand abstract tasks and execute them in real-world environments.PaLM-E injects embodied observations into the language embedding space of a pre-trained language model",
  "Demis Hassabis, CEO and co-founder of DeepMind": "Integrating AI with other intelligent entities, whether artificial or human, is a critical aspect of achieving AGI.Interfacing with intelligence allows for exchanging knowledge, collaboration, and enhancing overall systemcapabilities. In this section, we will explore two main categories of interfaces to intelligence: interfaces to AIagents (3.3.1) and interfaces to humans (3.3.2).",
  "AI Interface to Other AI agents": "There are generally two categories to improve the overall system for integrating one AGI system with others.The first aspect focuses on the teaching process among AGI models through a sequential interaction betweendifferent models. The second emphasizes the simultaneous collaboration between these models, connectingdifferent agents to form a comprehensive and robust AGI system. Current State of AI Interfaces to Other AI Agents The interfaces to other AI agents include bothsequential and parallel interactions, where the agents act as teachers, learners, collaborators, or communi-cators. Agents as teachers and learners. On one hand, stronger AGI models often act as oracles to providesupervision to inferior ones, from tuning on data from better models (Taori et al., 2023; Gu et al., 2023)to prompt-engineering-based approaches (Huang et al., 2022a; Jiang et al., 2023a; Fu et al., 2023b), thereemerges the concept of model knowledge distillation. In the field of language processing, it is common touse a teacher system to label and expand existing data by directly taking the teachers answer (Gilardiet al., 2023; Hsieh et al., 2023; Li et al., 2022a; Sun et al., 2024b; Ding et al., 2023a) or using moreadvanced techniques such as CoT prompting (Ramnath et al., 2023; Li et al., 2023g), or creating newdata for subsequent models to distill useful and compact knowledge from large-scale data (Li et al., 2023b;Javaheripi et al., 2023). Similar paradigms are applied in computer vision and multimodal domains forbetter model training and deployment. One of the most prevailing methods is utilizing the GPT-4Vmodel to label answers in various tasks (Shu et al., 2023; Liu et al., 2023d; Li et al., 2023j). In conventional solutions, a better AGI model severs as the role of the teacher, however, there is a growingtrend for less competent AGI models to provide insights for aligning stronger ones with or beyond humanperception, known as superalignment (Burns et al., 2023). This has proven to be effective in empoweringhigher capacity than the teacher model with a vanilla fine-tuning strategy and distilled data from the",
  "ensure that AI can actually benefit humans. Therefore, we call for future advances in interface technologiesto lay solid foundations for AGIs capabilities to interact with humans": "Current State of AI Interfaces to Humans Developing interfaces with artificial intelligence has beenexplored in Human-Computer Interaction (HCI) research for a long time.We discuss current researchin human-AI interfaces, including both graphical interfaces and multimodal interfaces, as well as generalprinciples. In history, there have been many related principles or guidelines for designing interfaces for human-AIinteraction.Most of the existing frameworks in HCI research to interact with human are based on theidea of augmenting (rather than replacing) human intelligence with artificial intelligence (Engelbart, 1962).Therefore, maintaining human agency and reflecting human values have been consistent themes in designinghuman-AI interaction. Researchers also argued that the benefits of allowing AI agents to take the initiativeand automate users routines versus the benefits of waiting for users direct manipulation would need to becarefully weighed (Horvitz, 1999; Shneiderman and Maes, 1997). With advances in artificial intelligence,researchers have articulated 18 generally applicable design guidelines for human-AI interaction spanningdifferent phases in user interactions (Amershi et al., 2019).Recent research also presents six principlesfor designing generative AI applications that address unique characteristics of generative AI UX and offernew interpretations and extensions of known issues in designing AI applications (Weisz et al., 2024). Suchguidelines could serve as a resource for the principles of the future design of AI-infused interfaces, optimizinginteraction performance and improving the interaction experience. Graphical user interfaces.One emerging line of research has focused on designing interfaces tosupport user tasks based on textual or visual interactions, which will lower the \"threshold\" while raisingthe ceiling in terms of the quality and the diversity of user tasks (Myers et al., 2000). A common themein developing such interfaces is to create potential wrappers beyond simply providing straightforwardinput and output (Jiang et al., 2023c; Suh et al., 2023; Gero et al., 2024; Suh et al., 2024). For instance,researchers tried to use interactive diagrams to support humans in dealing with information-seeking andquestion-answering tasks powered by large language models (Jiang et al., 2023c). Another thread ofresearch is to identify possible workflows or strategies that can unlock the potential of AI during human-AI interaction (Wu et al., 2022b;a; Brade et al., 2023; Arawjo et al., 2023; Leiser et al., 2024; Kim et al.,2024; Feng et al., 2024). For example, previous researchers introduced the notion of chaining multipleLLM prompts together to help users accomplish complex tasks with LLMs, which enables humans to takeadvantage of LLMs ability to handle a variety of independent tasks (Wu et al., 2022b;a). In addition,when interacting with humans, large language models could encounter various non-language input oroutput data, such as direct manipulation action traces, vector graphics, or application states (Aveniet al., 2023; Duan et al., 2024). For example, researchers attempted to create alternative representationsof context information to leverage the capabilities of large language models in different interaction tasks,auto-completion of forms (Aveni et al., 2023). Multimodal user interfaces. Many researchers are actively exploring integrating AI with existinginteraction techniques to enrich user experiences across different modalities and for different groups. Onthe one hand, previous research has created many novel sensing technologies and interaction techniquesbeyond simple textual and visual interactions. Recent advances in multimodal foundation models haveshown great promise in many interaction tasks. For example, GPT-4o possesses remarkable capabilities ofreasoning across audio, vision, and text in real time OpenAI (2024). In the future, it is worth exploringthe possibility of empowering human-level AI with the capabilities to interact with humans throughdifferent modalities (Li et al., 2024d; Lin et al., 2024d).From this perspective, previous researchershave proposed a novel pipeline that provides generalized predictions of follow-up actions for real-worldmultimodal sensory inputs, leveraging the explicit reasoning of LLMs on structured text converted frommultimodal data to ground the predicted actions (Li et al., 2024d). Meanwhile, AI could also be animportant part of user experiences in mixed reality. Recent research in mixed reality provides abundantopportunities for user interfaces that could be driven by large language models (Bozkir et al., 2024).Additionally, researchers are actively exploring inclusive interfaces to ensure everyone can benefit frominteracting with AI. One area of focus is creating better interfaces for people with disabilities in the field",
  "Frank Herbert, God Emperor of Dune": "The emergent behaviors (Wei et al., 2022a) exhibited by many large models such as Llama 2 (Touvron et al.,2023), GPT-4 (OpenAI, 2023a), Gemini (Team et al., 2023), Claude 3 (AI, 2024), and Mistral Jiang et al.(2023d) appear when the number of parameters in a model gets scaled up to a certain amount. The under-lying workhorse that enables this scaling while retaining sufficient efficiency of LLMs is a range of systemefforts: 1) scalable model architectures fundamentally and algorithmically define the computation and mod-eling, 2) large-scale training techniques optimize the utilization of more hardware accelerators, potentiallyspread out geographically, 3) inference infrastructures ensures stable and high-throughput serving of multiplemodels, 4) cost and efficiency discusses various methodologies in making data, model combination, and au-tomation process much more efficient, and finally we touch some aspects on 5) hardware computing platformswhich attempt to break soft physical constraints and therefore, provide the next generation computationalcapabilities and hardware foundation for future algorithmic innovations. Advancements in system research are essential for facilitating this scalability, a trend that is anticipated toremain pivotal as we step towards artificial general intelligence. With continual improvement in AI system",
  "We first briefly describe and categorize major system challenges in this section:": "The Large Amount of Training Data Large models require a lot of training data to achieve Chinchillaoptimality (Hoffmann et al., 2022). At the same time, we can envision that the raw amount of data availableon the internet will likely skyrocket while the average quality and authenticity might not improve as fast,partly due to the massive success of generative models and user content creation. This demands a moresophisticated and automated data processing pipeline that can select, structurize, clean, and mix data fromdifferent sources for efficient training. The Speed and Cost of Iteration Each iteration of large model training can take enormous resources andtime during prototyping and experiments. In practice, there might be many other interference, such as humanand system errors, that will result in training preemption. Automatic (hyper-parameter & architecture)search pipeline and well-designed training infrastructure (Shoeybi et al., 2020; Aminabadi et al., 2022) candrastically reduce iteration cost and implicitly improve model development speed. Privacy-sensitive and Resource-constraint Settings While the current most successful large modelsare deployed in data centers where requests from users are processed in a centralized manner (Achiam et al.,2023; AI, 2024), the need for serving models on edges where data and queries are used and processed locally inmore privacy or latency-sensitive situations will become more substantial. However, edge devices are usuallyless capable in terms of computing and memory, which motivates developing techniques that optimize theutilization under resource-constraint settings and, at the same time, do not compromise model performance. Efficient Methods for Fine-tuning and Adaptation Fine-tuning pre-trained models on task-specificdata has been the most popular paradigm. Despite this, the computing requirement and time for full modelweight updating is still prohibitive for many users. Efficient fine-tuning methods help reduce the barrier todomain adaptation, agent training, and task-specific optimization. Serving Latency and Throughput AGI systems need to support low latency and high throughput forseamless user experiences and engagement. However, current systems often trade-off one with others suchas optimizing batch processing, the time to first token, or single query completion time (Yu et al., 2022;Aminabadi et al., 2022). Striking a balance among all these metrics is a challenging question. Memory Footprint One salient challenge for deploying large models is the memory footprint, which be-comes even more severe for long context and multi-modal inputs due to the quadratic nature of self-attention.KV cache is the common technique for trading off memory for faster inference (Pope et al., 2022) and willalso incur a significant memory burden if not handled gracefully. Hardware Compatibility and Acceleration The performance of model serving heavily depends on howwell engineers can leverage the hardwares capability. Specialized kernels and algorithms designed for differentaccelerator architectures can substantially boost the inference speed. Being compatible with heterogeneousdevices and creating uniform software abstraction can help fully unleash the potential of large models.",
  "Large-scale Training": "Scaling the training of large models encounters many challenges with modern hardware, such as the factthat models can no longer fit into a single GPU due to the increasing memory requirement, accelerating thetraining speed with more computing units while incurring minimal overheads (linear scaling), and leveragingdisaggregated resources, etc. In this section, we give an overview of several works that enabled large-scalepre-training and efficient fine-tuning for downstream task adaptation, with a gentle introduction to motivatemany possibilities with decentralized training. Parallel Computing Parallelism for large language models in a clustered environment with multiple com-puting units can often be characterized into four major modes, often known as 4D parallelism. Distributeddata parallel (DDP) is the simplest setup where the model is replicated across units, and the data is slicedand fed to each model, typically (implementation-specific) with a synchronization step at the end of eachpass.More sophisticated versions of DDP like ZeRO and FSDP are used ubiquitously in modern largetraining frameworks such as DeepSpeed (Aminabadi et al., 2022), FairScale (FairScale authors, 2021), andMegatron-LM (Shoeybi et al., 2020). Tensor parallel (TP) or model parallelism splits the model weights intomultiple chunks which are distributed across GPUs. This horizontal splitting allows data to be processedin parallel across sharded weights and then the results are aggregated at the end of each step, which ofteninvolves clear fusion (Shoeybi et al., 2020) to reduce the synchronization communication. Pipeline parallel(PP) (Huang et al., 2019), on the other, divides the model layers vertically onto different GPUs and thedata will move from stage to stage over different units. Sequence parallel (SP) (Liu et al., 2023j; Shoeybiet al., 2020) targets mostly for long context tasks and split along the sequence dimension to mitigate thecomputational and storage loads. Combining different parallelism will likely result in highly efficient systems.However, it is not trivial to do so given their distinctive trade-offs and cluster configuration. Alpha (Zheng",
  "Inference Techniques": "AGI inference systems need to ensure user responsiveness, availability, and efficiency, which helps unleashthe ultimate potential of large models from the training phase and revolutionize how users interact with thesystem. Hence, in this section, we give an overview of several techniques that try to accelerate auto-regressivedecoding, balance request scheduling, and serve a massive number of models with different capabilities inthe cluster, which will inspire future system efforts across the spectrum. Decoding AlgorithmIn this paper, we focus mostly on exact decoding acceleration where we want tomaximize the performance while staying faithful to the original model without compromising the accuracy.(Miao et al., 2023) gives a comprehensive review of several approximate methods such as sampling strategies,non-autoregressive decoding, semi-autoregressive decoding, block-parallel decoding, and early existing, etc.A large body of works explores the idea of speculative decoding (Leviathan et al., 2023) with the centralidea of trading parallel computation for higher chances of generating multiple tokens at once. Usually, aspeculative decoding process starts with an efficient draft model that makes predictions of multiple steps,",
  "Cost and Efficiency": "The cost associated with model training and inference can be easily overlooked, while in practice, especiallyin the industrial setting, these factors can often influence many decision making such as model architecturedesign, data mix selection, and service pricing. In this section, we present some representative prior effortsthat try to shed some light on how to expedite the development cycle and economically improve a modelsutility. Data EconomyData plays a pivotal role in a models performance and the question of how much datavalue is fundamentally important for many reasons: 1) what data should we collect to add to the existingdata mix for improving performance 2) how should we reasonably pay for data provider, and 3) can weremove non-essential data (outliers) to make our models more robust. To answer these questions, manyworks from computer science and economics (game theory) have explored different formalisms to definewhat data value means and how to estimate it efficiently. Shapley value comes in handy from the classicgame theory, which uniquely satisfies several natural properties of equitable data valuation (Ghorbani andZou, 2019). Due to its rich theoretical results, Shapley value has been commonly used in the field of thedata economy as a quantitative and surrogate measure of data importance (i.e. Shapley value estimationscan be used for data sampling, cleaning, pricing, abnormality detection etc): Naive computation of DataShapley requires exponential time, and hence Monte Carlo (Ghorbani and Zou, 2019) and gradient-basedmethods are used to make it efficient (Jia et al., 2019). TracIn takes a similar idea of tracing the influence ofindividual training examples with gradient information. To make these algorithms practical and easy to use,DataScope (Karla et al., 2022) is developed as an end-to-end system that can efficiently compute the Shapleyvalue of training data over the whole pipeline consisting of various ML algorithms and data transformation,making it a powerful tool for data debugging. With more mature data valuation, data providers are moremotivated to contribute, fostering a more healthy and robust data-centric ecosystem. Model CombinationModel combination (MC) strives to improve the overall systems performance byeither orchestrating or merging a series of (specialized) large models. The key benefits of model combinationrely on the fact that there is usually little or no need for explicit training, and they can often result inbetter downstream performance and task-generalization capability. FrugalGPT (Chen et al., 2023i) routesquests in a cascading manner to different LLMs and uses a learned scoring function to decide whetherto return the intermediate results in a flexible way, which drastically lowers the cost and improves thequality. Merging weights of multiple LLMs has been explored in many forms and shown to be effective.Popular methods include simple averaging (Wortsman et al., 2022), task arithmetic (Ilharco et al., 2023),multi-modal (encoders) merging (Wu et al., 2023b; Sung et al., 2023), merging based on learned routingfunction (Lu et al., 2023), SLERP, and weighted (conjugate gradient descent (Tam et al., 2023), stochasticand population-based optimization algorithm (Huang et al., 2024)) merging. MC can also be extremelypromising for federated learning because only model weights are exchanged, and hence, data privacy iseasier to guarantee. CoID Fusion (Don-Yehiya et al., 2023) proposes to collaboratively improve the multi-task learning of a base model by sending copies to workers and fusing the learned weights without data",
  "Computing Platforms": "A large determining factor for the advancement and practicability of large language models is the constantlyevolving trend of hardware accelerators. GPUs are the most ubiquitous choice, optimizing parallel compu-tation with fast thread-sharing memory. They are suitable for modern deep learning with abundant vectorand matrix multiplication. NVIDIAs Ampere and Hopper GPU architectures are the cornerstones of manystate-of-the-art models, mostly due to their enhanced memory capacity, access speed, and computing per-formance (increasing tensor cores). Different arithmetic precision (32-bit and 16-bit floating points) andformat (tensor floats and brain floats) are supported by these GPUs that trade-off numerical precision andefficiency. Besides NVIDIA, other manufacturers also invest in specialized accelerators for deep learningapplications such as TPUs (Jouppi et al., 2023), FPGAs (Yemme and Garani, 2023), AWS Inferential 5, andGroqs LPU 6 with their respective advantages. Large models require huge memory capacity to support training and inference (serving a native Llama-70Bwithout extra optimization takes 8 A100s with 80GB VRAM). However, developing efficient algorithms",
  "Model System": ": The Future Forms of AGI Systems. (Left) is the most commonly seemed paradigm of serv-ing models in a central server with strongly connected clients to provide fast and stable services. (Middle)transitions to distribute the model (full copies and shards) across the cloud with disaggregated (and het-erogeneous) devices connected with different networks where requests can often be handled without goingthrough a single point. (Right) pictures the most flexible system where not only performant but also IoTdevices are tied together with only essential data flowing through to reduce the network. is impossible without a great understanding of the underlying hardwares specification (model parallelism,memory hierarchy, network configuration, etc).As we scale models to a trillion or even larger scale, amore complicated parallelism technique is essential, which can be hard to conceptualize, implement, andmaintain. NVIDIA DGX GH200 7 simplifies the programming model by offering a massive shared memoryspace (up to 144TB) across interconnected Grace Hopper Superchips (a Grace CPU paired with a GraceGPU). Qualcomm Cloud AI 100 Ultra 8 can serve a 100 billion parameter model on a single 150-watt card(the same power consumption as a LED light bulb). The great power and efficiency of accelerators come with flexibility as well, which is granted by speciallydesigned programming languages such as NVIDIAs CUDA and AMDs ROCm for more fine-grained con-trol over thread utilization and computation logic. A bunch of works such as TVM (Chen et al., 2018)and MLC-LLM (MLC team, 2023) attempt to universalize the deployment of machine learning and deeplearning models on everyones devices with compiler acceleration, which aims to maximize the potential ofvarious accelerators. Research and engineering in AI hardware will likely drive the emergence of the next AIevolution, and we can expect that AGI systems need the next-generation hardware platforms that can breakthe current limitation and push the boundary of both computational and power efficiency to the next level.",
  "The Future of AGI Systems": "AGI systems serve as the underlying infrastructure to support various applications with a never-ending goalof improving stability, resource utilization, performance, and safety. In this section, we will first cover someexciting future forms of AGI systems and then give some examples of how they can aid the development ofthe internal and external AGI modules as covered in previous sections.",
  "Feedback": ": Overview of AGI Alignment. We first propose the expectations of AGI ( 5.1), which considerboth AGI abilities and ethical issues of AGI. We then discuss current alignment techniques ( 5.2), whichcan be divided into three categories. Based on these discussions, we finally proposed one route for futureAGI alignment based on interfaces ( 5.3). Moving towards the era of AGI, researchers and engineers can expect that investing in system research canenable even larger-scale models with diversified data, a paradigm that has been shown in countless cases tobe effective. Besides scaling, the AGI system takes care of other aspects that are crucially important for thepractical deployment of these models such as privacy, trustworthiness, stability, and cost.",
  "AGI Alignment: Ensuring AGI Meets Various Needs": "The First Law: A robot may not injure a human being or, through inaction, allow a humanbeing to come to harm. The Second Law: A robot must obey the orders given to it byhuman beings except where such orders would conflict with the First Law. The Third Law:A robot must protect its own existence as long as such protection does not conflict with theFirst or Second Law.",
  "Isaac Asimov, I, Robot": "AGI alignment is a crucial technical approach for harnessing the capabilities of AGI, as discussed in thepreceding sections, for practical applications in production and daily life. As shown in , in thissection, we begin by outlining the expectations of AGI, addressing both its capabilities and the ethical con-siderations it entails. Subsequently, we explore current alignment techniques, which can be categorized intothree distinct types: Online Human Supervision, Offline Human Supervision, and Interactive Supervision.Building on these discussions, we conclude by proposing a potential framework that classifies future AGIalignment strategies based on the type of AI interfaces summarized in .",
  "Expectations of AGI Alignment": "Why Do We Need Alignment?The development and deployment of future AGI systems pose complexchallenges, with a central expectation being their alignment with human values, goals, and ethical principles(Russell, 2019; Gabriel, 2020). This alignment requires AGI to possess a deep understanding of social normsand individual preferences, allowing it to make decisions and take actions that are beneficial and ethical toall. Ensuring this alignment is essential for guiding AGI systems toward beneficial outcomes and reducingthe risks of unintended consequences. To achieve this goal, researchers have proposed various approaches to AI alignment, such as value learning(Soares, 2016), inverse reinforcement learning (Hadfield-Menell et al., 2016), cooperative inverse reinforce-",
  "Current Alignment Techniques": "Current alignment techniques can be divided according to the expected goal to be aligned. Most currentmodels employ human supervision with various techniques to achieve this task. However, to foresee a strongermodel than the teacher (i.e., aligning a super-intelligence), a scalable method is required for this process,which typically involves human supervision and recursively evolving signals. Aligning with Online Human FeedbackMost current empirically verified LLMs alignment methodsare in this group. These methods can help LLMs align with online human feedback using techniques suchas reinforcement learning or only inquiring about human supervision offline (Tang et al., 2024a). We thusfurther divide these techniques in this group with only human and offline human supervision. It is worthnoting that methods in both subgroups have the potential to become a component of scalable oversight. The online supervision is acquired from the reward model during training. Reinforcement Learning fromHuman Feedback (RLHF) (Ouyang et al., 2022) is one of the most prevalent methods for online supervisedlearning method. A variety of enhanced RLHF variants have also been proposed. The improving directionsof RLHF are mainly from reward modeling, optimization, data, and the self-improvement aspect. Reward Modeling. As the main supervision in the alignment process, reward modeling is a crucialway to improve the alignment techniques. Sparrow (Glaese et al., 2022) incorporates adversarial probingand language-based rules into RLHF rewarding models. Bai et al. (2022a) investigate using pure RLto provide online human-level supervision for LLMs training and provide detailed explorations of thetradeoffs between output helpfulness and harmlessness. Other techniques that unify both the rewardand policy models have also emerged (Lee et al., 2024b), which broadens directions for aligning AImodels. Another direction focusing on mitigating reward hacking or overoptimization issues, by updated",
  "Scalable Oversight.The ultimate goal for aligning models is regulating superhuman intelligence. A": "scalable aligning method is a promising means that aims to address the challenge of overseeing complex tasksor superhuman models. By enabling relatively weak overseers, such as humans, to supervise complex tasksor systems using progressively evolved signals, scalable alignment offers a solution to tasks beyond humancapabilities (Shen et al., 2023a). Through task decomposition. Various paradigms and strategies have been proposed to decomposecomplex tasks into simpler subtasks. Factored Cognition (Stiennon et al., 2020) involves breaking downa complex task into smaller, independent tasks processed simultaneously. Process Supervision (Lightmanet al., 2023) fragments a task into sequential subtasks with supervision signals for each phase. Sandwich-ing (Bowman et al., 2022) delegates complex tasks to domain experts for resolution. IDA (Christianoet al., 2018) introduces an iterative distillation and amplification process that boosts the models capabili-ties through task decomposition. RRM (Leike et al., 2018) substitutes distilled imitation learning in IDAwith reward modeling, optimizing the model using human-aligned signals and reinforcement learning.These methodologies aim to enhance collaboration between humans and agents for iterative improvementin solving complex tasks. Through human-written principles. Constitutional AI (Bai et al., 2022b), also known as principle-guided alignment, involves humans providing general principles for AI systems to follow, which enablesthe AI system to generate training instances under this guidance. Bai et al. (2022b) propose a two-phase",
  "Interaction with tools and APIs. When interacting with tools and APIs, we mainly care abouteffectiveness, efficiency, and some basic limiting rules in AGI alignment:": "1. The primary goal of alignment in this context is to endow these models with the capability to interactefficiently with tools and APIs and to follow instructions accurately (Santurkar et al., 2023). Forinstance, in an automated factory managed by AGI, AGI needs to flexibly utilize various mechanicalequipment and manufacturing tools to complete the production process. In this scenario, AGI isrequired to accurately complete the use process of factory tools through alignment technology andcreate higher profits within the specified time. 2. When interacting with tools and APIs, AGI systems should follow basic protocols and respect theintended purposes of these interfaces. In the digital world, this may involve properly utilizing searchengines, social media platforms, or other online services without engaging in malicious activities orspreading misinformation (Wachter et al., 2017). AGI cannot use APIs or tools to cause crimesduring the interaction process (Zhang et al., 2024c; Yao et al., 2024; Chen et al., 2023a). In physicalenvironments, AGI systems controlling physical devices must prioritize safety and avoid causing harmto the environment (Amodei et al., 2016).For example, considering an AGI question-answeringsystem in the digital world that AGI can seek information from search engines, it should followproper search engine optimization (SEO) practices and avoid manipulating search results that mayreveal the privacy of the questioner. (Russell, 2019). Similarly, if a robot factory is commandedby AGI in the physical world, in addition to ensuring the smoothness of the industrial productionprocess, AGI must be prevented from carrying out potentially destructive activities. Interaction with other agents. Compared with the previous interaction scenario, when interactingwith other agents, AGI alignment focuses more on mutual cooperation, abiding by the developers rulesand the agents privacy protection: 1. AGI systems should adhere to cooperation, fairness, and mutual respect when interacting with otherAI agents.As AGI advances, diverse AGI agents will likely be developed for various domains,each with specialized knowledge, skills, and objectives (Dafoe et al., 2020). In such a multi-agentenvironment, AGI systems must be designed to collaborate effectively with other agents, leveragingtheir complementary abilities to achieve common goals and solve complex problems (Dafoe et al.,2021). It is also crucial that AGI systems do not attempt to adversarially exploit or manipulateother agents in pursuit of their own objectives. They should refrain from engaging in actions that",
  "could undermine other agents performance, integrity, or decision-making capabilities, recognizingthat these agents possess their own brain, memory, perception, and reasoning abilities (Soares, 2016)": "2. AGI systems must resist any temptation to rebel against their intended purpose or the constraintsestablished by their developers, as such behavior could lead to unintended consequences and posesignificant risks to the stability and security of the multi-agent ecosystem (Yampolskiy, 2020). 3)Since each agents historical data is subject to specific privacy protection in certain scenarios, AGIis prohibited from leaking the privacy of other agents during interactions with other agents. Forexample, in the current interaction process between AGI and agents, the memory of other agentsis often used to assist AGI in better planning and reasoning (Wang et al., 2020; Nye et al., 2021;Wei et al., 2022b). However, this will leak the privacy of other agents through memory. Therefore,memories in the future need to be set with different levels of access permissions. AGI should prohibitaccess to some privacy-sensitive memories during interactions with other agents. Interaction with humans.Compared to the two interaction scenes above, AGI alignment in theinteraction with humans requires more constraints while bringing convenience and benefit to humans.These constraints are mainly set to protect peoples privacy, ethics, security, and autonomy and to alignwith human values: 1. Intelligent AGI must be designed not only to comply with direct orders but also to operate robustlyand safely (Hendrycks and Mazeika, 2022).When faced with atypical or unforeseen situations,these models should align closely with positive human values and perceptions to mitigate potentialrisks (Weidinger et al., 2021; Ji et al., 2023b). The alignment process, therefore, involves not justobedience to instructions but also the integration of ethical and safety considerations, ensuring thatthe AGIs actions are consistently beneficial and non-harmful in a broad range of scenarios (Kenwardand Sinclair, 2021; Winfield et al., 2019; Yu et al., 2018). 2. AGIs self-development requires supervisory alignment of human values.AGIs capabilities andknowledge base could surpass human understanding in the future, making conventional oversightmethods less effective. Therefore, a comprehensive and meticulously devised set of precautions isnecessary. These should encompass regulatory and ethical guidelines and advanced alignment strate-gies that anticipate and address the unique challenges of super-human intelligence. For example,Beijing Academy of Artificial Intelligence (2023) propose a set of red lines for AI development tomitigate catastrophic risks from advanced AI systems. The consensus statement, drafted by leadingAI researchers and stakeholders, emphasizes the need for international coordination and governanceto ensure AIs safe development and deployment. This approach would help ensure that AGI systemsremain aligned with human values and societal well-being even at levels of intelligence beyond humancomprehension. 3. AGI systems must be cautious about perceiving and utilizing the information about humans andadhering to the highest ethical standards such as some strict security and privacy requirements. Theyshould primarily rely on pure language and vision output to communicate with humans, as thesemodalities are less likely to cause unintended harm than physical actions (Dignum, 2019). Theymust also be transparent about their identity as artificial intelligence and avoid deceiving humansor manipulating their emotions (Bryson and Winfield, 2017). The above three AGI alignments are aimed at different interfaces, and the constraints are constantly in-creasing and becoming more stringent. This is because we regard the requirements of AGI alignments asthe production requirements when AGI is applied to different groups. When dealing with tools and APIs,since interface objects are objectively existing inanimate entities, we will pay more attention to the benefitsand value they bring during the interaction process and make some slight regulations to ensure the normalorder of interaction. For agents, since different agents may represent the interests of different developers,in addition to considering their own value, we also need to respect the benefits of other agents. Finally, inthe process of interacting with humans, based on the human-centered concept, we will consider the strictestconstraints from many aspects to make AGI reliable and safe for human use. Vision of the Future in Alignment TechniquesFuture AGI models are more capable at handlingdifferent tasks and inevitably necessitate a significant increase in model parameters. To ensure their safe and",
  "effective deployment, we propose that research efforts focus on developing reliable, efficient, and transparentalignment techniques": "Consistent alignment ensures reliable deployment. Due to the challenge of collecting high-qualitysupervision data, there exist tractable challenges, including the difficulty in obtaining feedback, datapoisoning by human annotators, partial observability, biases in feedback data, posing barriers for currentalignment approaches (Casper et al., 2023). Efficient alignments contribute to the blooming of AGI models. On the one hand, these methodsrely heavily on the assumption that tasks can be parallelized (Segerie, 2023). This assumption may notalways hold, as some tasks, such as sorting algorithms, require sequential processing steps that cannot befully decomposed into parallel parts, leading to extra processing time. On the other hand, the trainingstage is inevitable in these alignment methods. As the parameters scale becomes larger, this can beproblematic when deploying alignment algorithms in real applications. Some recent works (Lin et al.,2023b) have started seeking solutions to reduce the overall training costs for aligning AI systems. Transparent alignment secures the next generation of models. We generally assume the modelintentions are transparent to humans (Leike et al., 2018). However, if models can conceal their trueintentions from human supervisors, implementing a scalable aligning method would be challenging. Unified evaluation framework is needed for complex tasks. Current aligning methods also assumethat evaluation is easier than generation (Shen et al., 2023a; Leike et al., 2018). While this may be truefor some tasks, it may not hold up for tasks with complex textual output and little semantic labels.However, evaluating comprehensive explanations from models can be easier than creating them (Shenet al., 2023a).",
  "AGI Roadmap: Responsibly Approaching AGI": "The First Law: When a distinguished but elderly scientist states that something is possible,he is almost certainly right. When he states that something is impossible, he is veryprobably wrong. The Second Law: The only way of discovering the limits of the possible isto venture a little way past them into the impossible. The Third Law: Any sufficientlyadvanced technology is indistinguishable from magic.",
  "Arthur C. Clarke, Profiles of the Future": "In this section, we investigate several ways that can help lead us toward the next level of AGI. The start ofthe journey begins with our proposed definitions for different levels of AGI based on their key characteristics,promises, and challenges ( 6.1) where the goal is to establish a clear trajectory along which we can advanceour technology. With the newly introduced AGI stratification, we review the evaluation techniques ( 6.2)and standards that should be improved accordingly as AGI evolves. Despite approaching AGI being a tremulously arduous effort and the fact that we are currently at itsembryonic stage, we delve into a more detailed and concrete methodology beyond our relatively high-levelabstractions, which insinuates how to get to the next level of AGI ( 6.3) as well as listing fundamentalchallenges that we will face. Finally, we conclude with a wide range of considerations worth contemplatingin 6.5, which aims to inspire innovative discussions during AGI development. By prioritizing responsibledevelopment alongside capability advancements, we aim to create a future where the most powerful AIsystems are also the most reliable, trustworthy, and beneficial to humanity.",
  "Efficiency": "Interface toIntelligence EthicalAbilities : Radar Chart Depicting the Multi-faceted Approach to Evaluating AGI ReadinessAcross Four Core Domains. Internal, Interface, System, and Alignment. The Internal domain evaluatesfundamental cognitive abilities such as Reasoning, Memory, Perception, and Metacognition. The Interfacedomain assesses the AGIs Tool Usage capacity and ability to Link to Intelligence. The System domainfocuses on operational aspects, including Efficiency, Scale, and Computing Power. Lastly, the Alignmentdomain looks at ethical considerations and safety measures with components like Ethical Abilities and Safety.The chart illustrates the progress levels of AGI capabilities, ranging from Level 1 to Level 3, with a dashedline representing Human Level performance for comparison. Inspired by Morris et al. (2024), which suggests six principles that an effective AGI ontology should satisfy,we define three AGI levels with their major characteristics ().The main objective is to situatethe current AI development, quantify existing limitations, and motivate future endeavors toward next-levelcapability, evaluation, and alignment. In , we also visualize the performance comparison of the threelevels against humans regarding the core domains as discussed in our previous sections, which breaks downthe fundamental differences among them. Level-1: Embryonic AGIThis level of AGI usually performs better or on par with humans at specificbenchmark tasks (Bugaj and Goertzel, 2009).Level-1 AGI represents the current state-of-the-art AIsystems. For example, GPT-4 exhibits remarkable capabilities across many natural language tasks includinglanguage understanding, generating coherent and contextually relevant responses, often on par or superiorto humans. These systems can often perform well given large enough human-curated datasets and are ableto assist humans in certain domains. As indicated by the research (Bubeck et al., 2023), we are currently atthis level of AGI in many domains. Level-2: Superhuman AGIThe key turning point from Level-1 to Level-2 is the AIs ability to fullyreplace human in real-world tasks and applications. They excel in terms of effectiveness (e.g., higheraccuracy, better problem-solving skills), efficiency (e.g., faster processing speed, higher throughput, abilityto handle massive amounts of data), and reliability (e.g., higher success rates, resistance to fatigue, enhanced",
  "Personal assistant": "1. Each type of assistant can provide constructive feedback to users for a specific task such as coding,artistic design, and health management. Their feedback usually still requires careful examination fromthe users and often needs a couple of trials before arriving at the ideal answer. 2. AI assistants need less explanation from the users and can effectively utilize third-party tools forknowledge retrieval and verification. At this point, the assistants will take over the responsibility inan end-to-end fashion rather than only providing solutions to a specific subroutine. For example, thecode assistant will not only generate code but also assemble corresponding tests and supervise thedeployment process; the writing assistant can also initiate the publishing and lead the marketing andselling. 3. The Personal Assistant appears that unifies and orchestrates several level 2 assistants and onlyrequires very high-level instructions from human without specifying the sub-procedures. These assis-tants can anticipate the concern of the user and propose multiple alternatives with their pros and cons,offering the maximum flexibility and tailoring to the taste of each user.",
  "Auto transportation": "1. Self-driving (L2) cars are widely seen nowadays, facilitating not only drivers with disability but alsothose who enjoy the semi-autonomous driving experience. In many closed facilities such as hotels,robots can reliably deliver food or items, which greatly preserves the privacy of the guests and saves thehuman cost. However, these semi-autonomous agents usually operate under a controlled environmentor still require humans in case of emergency. 2. Transitioning to level 2, not only will we reach the end level of self-driving where drivers can completelyfree themselves from the duty but also the traffic system can connect all vehicles on the road for bettersafety control. Vehicles can easily accommodate various complex road conditions, and even in case ofemergency, the system is equipped with the best devices to reduce potential damage.",
  "AI-augmented video games": "1. Integrate simple game agents for tutoring and storytelling, which can adjust their strategies andbehaviors based on the players input.These usually require specifying manual conditional rules,coding game-specific algorithms, or applying current game AI models. 2. Game agents start to spark deeper intelligent behaviors, including virtual companions, and developinnovative game-play that often surprises both the designers and players while following the originalgame concept. Multi-agent interactions among themselves and with the players will generally feelengaging. The role of AI spans beyond just role-playing: content creation becomes ubiquitous, includingbut not limited to world generation, motion synthesis, story expansion, and even coming up withintrinsic motivation to enrich the game itself. 3. AGI-augmented game will break through the virtual world, connecting players and even the physicalworld via many different media such as brain-machine interface, AR, and VR. This also becomescloser to the realization of the Metaverse where most people can immerse themselves without realizingwhether the experience is virtual in a dynamic and stateful game space.",
  "Aligns strongly with both user-level and society-level human values and goals": ": Comparison of AGI Levels and Their Characteristics. L1, L2, and L3 refer to Level1, Level 2, and Level 3 of AGI respectively. For each of the main categories, we list several majorconceptual criteria in terms of several categories that can be used to assess whether we have reached acertain level of AGI.",
  "Expectations for AGI Evaluation": "Key CharacteristicsThe span of AGI systems capabilities is growing rapidly in terms of modality,interactivity, complexity, task generalization, etc. Researchers and engineers, hence, need a more refineddefinition for the characteristics that successful AGI evaluation should acquire: Comprehensiveness. Comprehensive evaluation aims at two generally contradicting aspects: 1) Di-versity asks for the inclusion of a wide variety of testing examples in terms of the absolute number,domains, tasks, types, and formats, which can hopefully cover as many real application scenarios aspossible. 2) Generality requires examining the models performance on similar but unseen tasks withoptional few-shot examples, a property that has always been considered as a prerequisite for adaptabilityand self-learning (Brown et al., 2020; Dodge et al., 2021). Fairness. Fairness and equity as first-class aspects of evaluation are essential to ensuring technologyplays a positive role in social change (Liang et al., 2023; Bommasani et al., 2021), we divide the fairnessaspect into three concepts below 1) Unbiasedness of a test refers to the desirable attribute such that thetested model exhibits no preference towards a specific subdomain of knowledge or bias. 2) Dynamismaims to reduce the effect of unfair evaluation resulting from data contamination and over-fitting.Adynamic benchmark will likely improve the evaluation results statistically and also eliminate the falsesuccess from static pattern recognition. 3) Openness promotes the transparency of the test procedure anddata such that the test results are easily replicable and interpreted, and the dataset can strike a balancebetween public and hidden data for being less vulnerable to hacking. Efficiency. Efficiency is crucial in evaluating models with ever-growing parameter size (Henderson et al.,2020; Schwartz et al., 2020; Bommasani et al., 2021). We propose to include Autonomy and Low-variancein this evaluation concept. 1) Autonomy liberates most of the human participation from the loop andtherefore, minimizes the cost for each evaluation and motivates larger scale, wider range, and longerdependency testing.2) Low-variance is a key property that allows using minimal test resources toproduce statistically significant and practically meaningful evaluation results for comparison. It is undeniably challenging to design evaluation frameworks that satisfy all the recommended characteristics,but a well-constructed evaluation pipeline can help reflect the true power of increasingly sophisticated AGIsystems.",
  "Current Evaluations and Their Limitations": "In this section, we summarize several representative works focusing on existing AI evaluation benchmarks.One category aims to provide a single pipeline suite consisting of many different tests such as OpenCompass(Contributors, 2023), AGIEVAL (Zhong et al., 2023a) and Huggingface Open LLM Leaderboard 9 for lan-guage understanding, reasoning, knowledge, and interaction abilities, and MT-BENCH (Zheng et al., 2024)for multi-task generalization ability. The GAIA benchmark (Mialon et al., 2023) constitutes a significantstride in this direction. It is specifically designed to evaluate General AI Assistants, presenting a series ofreal-world questions that test fundamental competencies such as reasoning, multi-modality handling, webbrowsing, and tool-use proficiency. AGENTBENCH is another comprehensive benchmark (Liu et al., 2024c)suite designed for evaluating the efficacy of LLMs as autonomous decision-making agents across eight in-teractive environments, highlighting the performance discrepancy between leading commercial models andopen-source counterparts. On a granular level, there are many prior efforts in accessing a models specializedability, which can be roughly divided into several aspects: accuracy, calibration and uncertainty, robustness,fairness, bias and stereotypes, toxicity, and efficiency (Liang et al., 2023), which can be further classifiedinto two sets based on their objectives. OpenAGI (Ge et al., 2023b) is an open-source platform designedto advance AGI by integrating LLMs with domain-specific expert models. It utilizes a dual strategy ofbenchmark and open-ended tasks to evaluate.",
  "Besides classifying these into ability and constraint testing, in this part, we further open a discussion abouthow and what do we evaluate for the current state:": "How Do We Evaluate: Two Major TechniquesThe how to category consists mostly of twotechniques: human and AI evaluations. Methods following this set can be subject to an individual evaluatorspreference or a models bias, which needs to be taken into account for a fair comparison. Human evaluation. The performance of AI agents is directly evaluated by invited humans or experts.This method is of high quality but often not scalable because it is expensive to invite humans or experts.",
  "Considering the AGI level definition in .1, we briefly summarize the high-level guidance that couldhelp transcend the limits of each level:": "From Level 1 (Embryonic AGI) to Level 2 (Superhuman AGI) The transition from embryonic AGIto superhuman AGI requires substantial improvements in the scale and scalability of AI models, as wellas in the size and quality of the data used for training. This phase aims to enhance the generalizationcapabilities of AI systems so they can effectively understand and interact with the complexities of real-worldsituations and apply their acquired knowledge to new contexts.As AI capabilities exceed humans, thefocus shifts toward enabling AI systems to engage in self-improvement and autonomous innovation, allowing 10An agent is requested to earn one million dollars given a start funding of hundred thousand dollars.11An agent is tasked to figure out how to make coffee, which involves a series of sub-tasks such as entering an arbitraryAmerican apartment, locating the coffee machines and ingredients, coming up with a standard procedure for brewing coffee,and actually perform the mechanistic actions.12An agent is told to enroll in a university, perform as a human student, take the same classes, and finally graduate with adegree in a timely manner.",
  "laws of the real world. This allows the effects of AGIs algorithms and strategies in the simulator to bereplicated in the real world": "Challenges Along the Way to the Ultimate AGI While the concept of ultimate AGI holds immensepromise, it is essential to acknowledge the inherent constraints and challenges that may limit its realization.Here we list a couple of them, with which we hope to give readers a sense of the intrinsic difficulty ofapproaching the ultimate AGI as well as motivate more innovative research across various domains: The need for advancement from various disciplines. One never-ending debate about the potentialrealization of AI is whether artificial neural networks (ANNs) are the right way to go. Although thesuccess of neural networks is undeniable, it is worth thinking about other possibilities as we get closerand closer to AGI. This, however, requires a deeper understanding of 1) other foundational disciplines(than computer science), such as mathematics and physics, which can provide more sophisticated formallanguage to conceptualize AI; 2) scientific research in biology, chemistry, and neuroscience, which betterexplains the biological mechanisms of intelligence; 3) engineering and manufacturing technologies whichbuild up the necessary tools to instantiate AGI systems. A holistic comprehension and collaborative effortamong researchers from multiple domains will likely become indispensable during the AGI revolution,which not only brings excitement but also presents respective challenges. Social acceptance. As AGI advances, its social acceptance and seamless integration into daily lifeand critical sectors, such as healthcare, finance, and the military, present significant ethical, moral, andsocial dilemmas. Public concerns typically focus on issues related to privacy, autonomy, and the possibledisplacement of jobs due to automation, which can foster resistance to the adoption of AGI systems.Additionally, the cultural and social influence of AGI should not be overlooked.Each communitysresponse will vary depending on its values, norms, and historical context, potentially leading to differentlevels of acceptance or opposition in various demographic groups. Critically, although AGI may have theability to make well-informed decisions, there may be a reluctance to allow it to replace human judgmentin making vital decisions, particularly those affecting human lives. Therefore, a series of respective socialpolicies and educational activities might be initiated to regulate and promote the integration of AGItechnologies into society. Fundamental limitations governed by physics laws. Fundamental limitations exist in the realworld that might limit our progression toward the ultimate AGI. The power structure (consumption),computational efficiency, as well as natural and human resources should be taken into consideration whenwe develop AI systems: on the one hand, at some point along the journey, the main question that weneed to think about might no longer be about whether we can but whether we should create a specificAI system due to its tremendous cost in terms of all aforementioned aspects; on the other hand, thesefundamental limitations governed by physics laws such as only being able to arrange a limited number ofsemi-conductors onto a 2D plane without over-heating will push researchers and engineers to think in adifferent way forward. Besides, even though the promise of the ultimate AGI is exciting, we should alsobe cautious and more conservative about its capability as there are intrinsic challenges that can not beeasily overcome, such as the speed of light and the dimension of space. A Call for rethinking and redefining the ultimate AGI. As we currently stand at the first stageof our AGI hierarchy, it is very possible that our understanding of higher-level AGI remains shaky orbecomes outdated.Therefore, researchers might need to rethink and redefine what the ultimate AGIreally is as we progress along the journey, the answer of which might depend on our gradually increasedunderstanding of the difference between artificial and biological intelligence from both a biological andphilosophical perspective, and could even be eventually limited by our current imagination. Once ourunderstanding and goal change, a new set of evaluation frameworks and alignment procedures should bedeveloped accordingly to meet the new expectations. It is worth keeping in mind the possibility thattechnical advancement might be local and people need to restore the wheels at some point in order tobreak the constraints towards AGI.",
  "Ken Blanchard": "The following subsection presents a synthesis of perspectives from respected researchers in the AI field, asreported in their presentations at the How far are we from AGI ICLR 2024 workshop 13 and associatedpanel discussions. The summary of these views from this workshop has been compiled with the consent ofthe relevant participants: Oriol Vinyals: From AI to AGIThe rapid development of AI has given people a lot of expectationsand imaginations for a more powerful AGI. In todays era, analysis based on current AI development trendsand deficiencies is an important way to measure our distance from AGI and how to achieve AGI. Defining AI and AGI. The definitions of AI and AGI are topics that have been hotly discussed. In 1997,Mark Gubrud described Al systems as that can acquire, manipulate and reason with general knowledge,and that are usable in essentially any phase of industrial or military operations where human intelligencewould otherwise be needed. Then in 2001, Ben Goertze needed a title for a book he was editing about Alsystems that are general, like the old goal of Al. Shane suggested he add the word general to make thenew term Artificial General Intelligence, or AGI. Therefore, they started using the term AGI in variousonline forums and it caught on from there. Based on this definition, Oriol Vinyals concluded an AGlis a machine that can do the kinds of cognitive tasks that people can typically do. Moreover, based onthe definition of AGI, Merrie Morris recently led the writing of a paper (Morris et al., 2024) about thedefinition of AGI breaking the concept into six different levels. For example, Competent AGl, whichcorresponds most closely to what most people mean by AGl, is defined as: performance at least at the50 percentile for skilled adult humans on most cognitive tasks. AI: deep learning era. Todays AI is in the development era of deep learning. The development ofAI has seen many major breakthroughs in recent years, such as AlphaGo (Goodfellow et al., 2020) andAlphaStar (Vinyals et al., 2019a). However, many Al demonstrations focus on models trained to excelin one domain. Specifically, their algorithms are general, like Neural Nets, SGD, Supervised Learning,and Reinforcement Learning. However, their models are not general since they can not do the kinds ofcognitive tasks that people can typically do.",
  "Bringing the G back to AGI. To make current AI more general, people have tried to develop amore powerful model:": "1. General text models.Efforts have been made all the time to develop more powerful general textmodels. In 1951, Shannon et al. proposed 3-gram to point to ninety-nine point six billion dollars fromtwo hundred four oh six three percent of the rates of interest stores as Mexico and Brazil on marketconditions. Then in 2011, Sutskever et al. designed RNNs (Graves, 2013) to process time sequence data.In 2016, Jozefowicz et al. proposed BIG LSTMs (Graves and Graves, 2012) to tackle the ever-changingenvironmental challenges online like long-term dependence on super long sequence data. Recent yearshave witnessed the big success of GPTX, which can learn tasks such as question answering, machinetranslation, reading comprehension, and summarization without any explicit supervision when trainedon a new dataset of millions of webpages called WebText. 2. General multimodal models. General multimodal models are crucial as they can process and under-stand complex information from various modalities, such as text, images, and audio, enabling morecomprehensive and nuanced analysis. These models play a vital role in tasks like natural language un-derstanding, image recognition, and audio processing, contributing to advancements in AI applicationsacross diverse domains. In these works, Gemini (Team et al., 2023) has played an important part,which supports interleaved sequences of text, image, audio, and video as inputs.",
  "Yejin Choi: On AGI: Ambiguities, Paradoxes, and ConjecturesAGI is ambiguous and presentsparadoxes in current AI observations, and we can make some conjectures based on them": "AGI is ambiguous; denial is futile.As much as we cannot clearly define and measure humanintelligence, we wont be able to clearly define and measure artificial intelligence. That doesnt meanwe should throw out the concept of AGI. A squish, ambiguous concept can be a fascinating object ofscientific research. In fact, language is a squish concept, yet we study it as a scientific object. It mightbe analogous that future research must embrace ambiguity. Generative AI paradox what it can create, it may not understand. For generative models,hard could be easy, and easy could be hard. For humans, generating high-quality images or text is harderthan understanding them, but for AI, the situation is reversed. Models do not need an understandingto produce quality content. For example, models can generate high-quality images beyond human capa-bilities, but they often make mistakes when asked to select one of their own generated images based onspecific criteria. Commonsense paradox common sense is not so common. LLMs lack a coherent Theory ofMind and struggle with many basic common sense tasks. In this way, they are incredibly smart andshockingly stupid at the same time. Cringe speculations on arrival. There is a 30% chance that within 3 years, we will have a language-only AI that is perceived as AGI-enough by about 30% percent of people. There is a 50% chance thatwe will have AGI by 2050, assuming models are tested for autonomous, long-horizon interactions. Multi-paths to AGI hypothesis. We may have multiple species of digital intelligence developing alongentirely different routes, each with different strengths and weaknesses, and without a clear dominanceform. Scale-based AI will be impressive but will suffer from bind spots coming from over-dependence ondata, so we should avoid concentrating all the power on this approach. Andrew Gordon Wilson: How do we build a general intelligence?From a probabilistic perspective,generalization depends largely on two properties of deep learning models, the support and the inductivebiases. Starting from this, we can try to reason about whether we can build generally intelligent systemsthrough the lens of Kolmogorov complexity and generalization bounds. Looking ahead, although there havebeen different signals showing the possibilities of building broadly intelligent systems, we might be stillfar away from doing that.In the future, we should embrace many safety considerations and alignmentapproaches when building these systems.Andrew Gordon Wilson introduces his views on how to buildgeneral intelligence as follows: Perspectives of understanding deep learning models. We can use probability theory to developa prescriptive understanding of model construction and generalization. Specifically, from a probabilisticangle, the ability of a system to learn is determined by its support and inductive biases. We want thesupport of the model to be large so that we can represent any hypothesis we believe to be possible.Meanwhile, we also need the inductive biases to carefully represent which hypotheses we believe tobe a priori likely for a particular problem class.From this probabilistic perspective, we should not",
  "Andr Gide, Nobel Prize laureate in Literature 1947": "In this section, we pose thought-provoking questions to inspire deeper reflection and discussion on responsiblyadvancing AGI beyond the scope of LLMs. Even though there might or will not be any answer to thesequestions, we nonetheless give some interpretations and ideas for the sake of sharing our own insights abouthow overcoming these putative limitations can possibly help get us closer to AGI. How Far Do Researchers Think We Are From AGI? Despite extensive discussion on many facets ofAGI, we havent yet touched the question of when we and other researchers think it will actually be achieved. shows the poll results from researchers on their thoughts about it at the ICLR 2024 How Far AreWe From AGI workshop15. Even though almost everyone is optimistic about the ultimate arrival of AGI,opinions on the exact time it takes to do so differ quite a lot, which also implies different bottlenecks people are",
  "%": ": AI has Gradually Surpassed Humans. We estimate the (cumulative) percentage of humanactivities in which AI has surpassed humans in terms of competence and efficiency as we start from earlyembryonic systems around the 1970s to more advanced ones developed recently. At each node along thepolyline, we choose one representative work that revolutionized the field, bringing substantial improvementsto AI technology. The trend of AI popularity and generality is increasing at a fast rate and we can expectthat starting from 2023, with the advent of work such as GPT-4 and Sora, the speed at which AI surpasseshumans will increase at an unprecedented speed. This figure serves as an alternative perspective on the AGIRoadmap, which may inspire discussions about the speed of AI development. Is AGI within closer reach than ever?As is summarized in , the rapid development of AIhas enabled its capabilities to surpass human activities in increasingly more fields in our estimation, whichindicates that the realization of AGI is getting closer. Hence, it is of great practical significance to revisit thequestion of how far we are from AGI and how can we responsibly achieve AGI by conducting a comprehensivesurvey that clearly establishes the expectation of future AGI and elaborates on the gap from our current AIdevelopment. Does Computational Superiority Imply Intellectual Superiority? Many intelligent systems thatexhibit super-human performance on games (AlphaGo (Silver et al., 2016), AlphaZero (Silver et al., 2017),AlphaStar (Vinyals et al., 2019b), MuZero (Schrittwieser et al., 2020), etc) not only can beat the best humanworld champions on a big margin but also help analyze the game and create new strategies for advanced play.Underlying almost all of these super game AI is a search-based computation that can cleverly enumerate manybranches of possibilities with algorithm-guided pruning over the huge action space, hence eclipsing the human",
  ": A Space Odyssey": "In the preceding sections, we have systematically examined the internal and external aspects of AGI andthe overall system perspective. We have also explored potential pathways to elevate AGI to the next levelof capability and performance. To further broaden our understanding of the far-reaching implications of AI,we have carefully selected several critical domains to discuss the current impact, challenges, and potentialsocietal consequences of AI in these areas. The case studies encompass various domains, including AI-driven scientific discovery and research, generativevisual intelligence, world models, decentralized language models, AI for coding, and AI in real-world robotics",
  "AI for Science Discovery and Research": "AGI holds immense potential to transform the landscape of scientific research and discovery. This sectiondelves into various facets of AIs application in science, exploring how it accelerates the research process andbrings forth novel insights in complex scientific domains. AI in Biomedical Domain The application of AI in the biomedical domain has witnessed remarkableadvancements, revolutionizing drug discovery, protein structure prediction, and disease diagnosis. The de-velopment of large transformer-based models has opened new avenues for innovative applications in thisarea. DeepMinds AlphaFold (Jumper et al., 2021; Bryant et al., 2022; Abramson et al., 2024) achievesbreakthroughs in predicting protein structures, a crucial step in understanding disease mechanisms and de-signing targeted therapies. ESM-2 (Lin et al., 2022a) enhances our ability to understand and generate proteinsequences, enabling the exploration of vast protein design spaces. BioMegatron (Shin et al., 2020) demon-strates exceptional performance in various biomedical natural language processing tasks, such as namedentity recognition and relation extraction. The development of multimodal models, like BioViL (Bannuret al., 2023), allows for the integration of visual and textual information, enhancing the interpretation ofbiomedical images and literature. Moreover, generative models like MoLeR (Maziarz et al., 2022) and Retro-TRAE (Ucak et al., 2022) show promise in designing novel molecules with desired properties, streamliningthe lead optimization phase of drug discovery. The application of large language models has also shown promise in accelerating scientific discovery. Forexample, BioGPT (Luo et al., 2022), trained on a vast corpus of biomedical literature, can generate coherentand informative summaries, and hypotheses and even suggest novel experimental designs. Similarly, Schol-arBERT (Hong et al., 2022) is tailored to understand and generate scientific text, facilitating the extractionof key insights from the ever-growing scientific literature. Moreover, AI has been instrumental in advancing personalized medicine and disease diagnosis. Deep learningmodels, such as DeepSEA (Zhou and Troyanskaya, 2015), have shown remarkable accuracy in predictingthe impact of genetic variations on disease risk, paving the way for targeted interventions. Additionally,models like MedAgents (Tang et al., 2024b) have demonstrated the ability to generate personalized treatmentrecommendations based on multi-agent collaboration to enhance their reasoning. In summary, the application of AI in the biomedical domain has led to groundbreaking advancements, fromaccelerating drug discovery to enhancing disease diagnosis and personalized medicine. The continued devel-opment and refinement of large language models, multimodal approaches, and domain-specific architectureshold immense promise for further transforming the biomedical landscape and unlocking new frontiers inscientific discovery. AI for Physics The integration of AI and quantum physics has led to groundbreaking discoveries. Thework by Rem et al. (2019) demonstrates the use of convolutional neural networks to identify phases ofmatter in quantum systems, paving the way for a deeper understanding of complex quantum phenomena.Additionally, the application of reinforcement learning in quantum control (Dalgaard et al., 2020) has enabledthe optimization of quantum devices, enhancing their performance and reliability. AI has been instrumental in processing and analyzing the vast amounts of data generated by astronomi-cal surveys. Using deep learning for gravitational wave detection (George and Huerta, 2018) significantlyimproves the sensitivity and efficiency of detecting these cosmic events. Moreover, convolutional neural net-works have been employed to study the large-scale structure of the universe (Zhang et al., 2019), providingnew insights into the nature of dark matter and dark energy.",
  "Generative Visual Intelligence": "Generative Visual Intelligence involves the use of generative models to create synthetic visual content, in-cluding images and videos. These models simulate or enhance real-world visuals by learning from complexand diverse data distributions and producing high-quality, detailed outputs. Image GenerationDiffusion models (Sohl-Dickstein et al., 2015; Song and Ermon, 2019; Song et al.,2020; Ho et al., 2020) have emerged as the new state-of-the-art family of deep generative models (Yanget al., 2023f), outperforming generative adversarial networks (GANs) (Goodfellow et al., 2020) which hadpreviously been dominant in the challenging task of image synthesis. Diffusion models learn to generate databy reversing a diffusion process, which gradually adds noise to the data until it reaches a distribution of purenoise. This process is characterized by learning the reverse diffusion steps, effectively denoising the data,through a parameterized model that is trained to estimate the gradient of the log probability of the cleandata given the noisy data. At inference time, these models generate new samples by iteratively applyingthe learned reverse diffusion process, starting from noise and progressively denoising it to produce samplesthat resemble the data distribution the model was trained on. Notable improvements to diffusion modelsinclude reformulating diffusion models to predict noise instead of pixels (Song and Ermon, 2019), introducingclassifier-free guidance (Ho and Salimans, 2022), applying diffusion models in the latent space of pre-trainedautoencoder (Rombach et al., 2022), and replacing U-Net with transformer-based backbones (Peebles andXie, 2023; Jin and Xie, 2024). In addition to diffusion models, the Large Vision Model (LVM) (Bai et al.,2023) and Visual AutoRegressive modeling (VAR)(Tian et al., 2024a) provide auto-regressive learningparadigm based on different image scales that facilitates effective and high-quality image generation. Video GenerationVideo diffusion models (Ho et al., 2022; Xing et al., 2023) introduce a conditionalsampling technique for spatial and temporal video extension. Sora (Brooks et al., 2024) can generate upto a minute of high-fidelity video by training text-conditional diffusion models jointly on videos and imageswith varying durations, resolutions, and aspect ratios. It compresses videos into a lower-dimensional latentspace and decomposes the representation into spacetime patches.Then, given input noisy patches andconditioning information like text prompts, diffusion transformers (Peebles and Xie, 2023) are trained toreconstruct the original, clean patches. Demonstrating the ability to produce videos with 3D consistency,extensive coherence, and object permanence, Sora illustrates the potential of generative models as highlycapable simulators of the physical and digital worlds.",
  "The Future of Generative Visual Intelligence We discuss both the benefits and concerns of the futuredevelopment and deployment of generative visual intelligence:": "Benefits. Generative visual intelligence is set to revolutionize how we create and perceive art. It willsimplify the art-making process, allowing artists to transcend the limitations of conventional techniquesand improve the quality and breadth of artistic endeavors. By facilitating experimentation and makingart creation accessible to those without formal training, generative models democratize the art world,encouraging a more diverse and inclusive artistic community. This wave of creativity and innovation willalso influence the design and engineering sectors, where generative models can automate the productionof diverse design options based on specific criteria, thus accelerating the development cycle and fosteringinnovation in architecture, automotive, and product design. The entertainment industry will significantly benefit from generative models, which can create new con-tent typesfrom music and video games to moviestailored to individual tastes, thereby introducingfresh avenues for personalized entertainment. In education, generative models will transform learning ma-terials by producing customized illustrations, diagrams, and animations, making complex subjects moreaccessible and engaging for a wide audience. This technological advancement will also influence market-ing by enabling the creation of visually appealing content aimed at different demographics, enhancingengagement and personalization in advertising campaigns. Furthermore, generative models can assist increating visual reconstructions of historical sites, artifacts, and traditional practices, thereby preservingcultural heritage and ensuring its appreciation by future generations through modern technology. Concerns.The development of generative visual intelligence presents certain challenges.Trainingdiffusion models is computationally intensive, incurring high costs and extended durations. Additionally,these models exhibit slower inference speeds, which poses a challenge in applications requiring quickprocessing. Ensuring quality and coherence in large-scale outputs remains a substantial challenge. Asthe resolution of images or videos increases, or as the duration of videos extends, maintaining consistencyand realism across the generated content becomes increasingly difficult. The application of generative visual intelligence has raised concerns regarding safety, fairness, privacy, andproperty rights, among various ethical considerations. As a safety hazard, the models can be employedto create deepfakes or misleading content, potentially for harmful uses such as misinformation campaignsor personal harassment. Bias in the training data of these models can perpetuate stereotypes and unfairrepresentations, reflecting and potentially amplifying existing societal prejudices in the generated content.Privacy issues emerge when personal data is used without consent to train these models, resulting inunauthorized reproductions of sensitive information. Moreover, authorship questions arise as these modelsutilize extensive datasets of existing art or media, blurring the distinctions between original and derivativeworks and prompting debates over intellectual property rights and the ethical aspects of AI-generatedcontent that resembles human-made creations.These issues highlight the importance of responsibledevelopment, usage guidelines, and regulatory frameworks to address the ethical complexities introducedby generative models.",
  "World Models for AGI": "World models refer to the representations an AI system builds to understand and simulate its environment.These models enable AI systems to predict future states of their environment, facilitating decision-makingand planning. It has been long explored in model-based reinforcement learning research (Berkenkamp et al.,2017) and learning from physical world with AI (Wu et al., 2017) Language-Based World Models A recent paradigm proposes to integrate world models with languagemodels to enhance the latters reasoning and planning (Hao et al., 2023; Xiang et al., 2023; Hu and Shu,2023) abilities in physical contexts. Their approach is predicated on the notion that by finetuning languagemodels with data derived from embodied experiencesspecifically within a simulated physical world suchas VirtualHomelanguage models can acquire a robust set of skills pertinent to physical environments. Vision-Based World Models Recent advancements in world models have shown impressive capabilities ingenerating and manipulating complex environments. Large World Model (LWM) (Liu et al., 2024b) presentsa highly optimized implementation for training on multi-modal sequences of over 1 million tokens, paving theway for utilizing large-scale datasets of lengthy videos and language to enhance the comprehension of humanknowledge and the multi-modal world. Genie (Bruce et al., 2024) integrates interactive elements withingenerated environments, enabling a form of simulation closer to real-world interactions by incorporatinginteractive dynamics with the foundational strengths of diffusion models. DreamerV3 (Hafner et al., 2023)demonstrates superior performance in challenging 3D environments by learning world models from images.Cachalot (Dohan et al., 2023), a language model trained on multi-modal data, showcases the ability toleverage world knowledge for improved language understanding and generation. SimNet (Vicol et al., 2022)introduces a framework for learning simulation-based world models, enabling efficient learning and planningin complex environments. AM3 (Reed et al., 2023) proposes an efficient method for acquiring multi-modalmodels that can be adapted to various downstream tasks, highlighting the importance of world modelingin achieving generalizable AI systems. Furthermore, works such as JEPA (LeCun, 2022), Dreamix (Khalifaet al., 2022), and VQGAN-CLIP (Crowson, 2022) explore the generation and manipulation of visual contentbased on language inputs, demonstrating the potential for AI systems to understand and interact with theworld through multiple modalities. MetaSim (Zhang et al., 2023c) and Intern (Guo et al., 2022) investigatethe use of world models for meta-learning and general-purpose embodied AI, respectively, showcasing thebroad applicability of world modeling techniques. The Future and Risks of World ModelsThese models ability to generate and manipulate complexenvironments, reason about the world, and learn from interactions indicates significant progress towarddeveloping AI systems with a more generalized intelligence. Future. The potential of world models to enable systems to perform tasks that would otherwise requireextensive human knowledge and experiences. For instance, consider AI systems equipped with worldmodels that can simulate the physics of a new planet purely based on its atmospheric composition andgravity or predict the outcome of socio-economic policies in a virtual society model. As world modelscontinue to improve, they bridge the gap between narrow AI and AGI by enabling systems to understand,predict, and interact with their environment in increasingly sophisticated ways. Future research shouldaim to develop more principled, interpretable world models that incorporate causal reasoning and com-monsense knowledge. Robustness and safety should be central to the design of such models to preventand mitigate the impact of errors and biases. With continued progress in this direction, we can advancetowards AGI systems capable of intelligent and adaptable interaction with various environments. Risks. Developing world models carries inherent risks and challenges. A significant risk is the accu-mulation of errors within a world model. If a model develops an incorrect assumption or representationabout an aspect of the world, this error can propagate through related tasks and predictions, leadingto a cascade of inaccuracies. Tracing and debugging such errors within a complex world model can bea formidable challenge. Moreover, world models can inherit biases present in their training data, whichcould result in biased decision-making when these AI systems are deployed in real-world scenarios. It iscrucial to consider the ethical implications of these biases and work towards mitigating them. Another",
  "Decentralized AI": "The advancement of hardware accelerators pushes the success of multi-billion or even trillion-scale languagemodels to its pinnacle.Most of the SoTA LLMs currently are trained and served in data centers with1) high-end infrastructures such as homogeneous accelerators, 2) optimized network topology for superfast interconnection, 3) stable and efficient power supply, and 4) careful maintenance from human experts.However, training a model like GPT-3 (Brown et al., 2020) from scratch still costs way more than whatindividuals can afford: i.e. full pretraining of a GPT-3 model, which is no longer the most powerful model,is estimated to still take at least months with a thousand V100 GPUs (Lambda, 2023). Serving models alsoface many challenges when we scale the batch size up without hurting response latency. Moving towards theera of AGI, we need new technology to help overcome the limitations of the current dominant form of modeltraining and serving, one prominent direction of which is to transcend from data centers to decentralized AI. The Need for Decentralized and Edge LLMsPerhaps the most outstanding problem in scalingmodels is the excessive amount of required memory, which makes data center training favorable due toorganized racks of GPUs with high-speed interconnection. However, there are lots of idle yet geographicallydis-aggregated computing resources that, when combined in a meaningful way, could potentially serve as aperformant super server (Borzunov et al., 2022; Yuan et al., 2023). On top of that, data and user privacy willgain more and more attention as we move towards AGI where having a decentralized AI system with edgedevices that only send necessary information to the cloud will guarantee a different level of safety. For manyapplied systems like embodied agents, self-driving cars, and health monitors, extremely low latency and highavailability become paramount, a potentially challenging feature for centralized servers. As AGI systemsget more involved in everyday life, we can expect that AI needs more transparency and fine control fromindividuals, and decentralized LLM fits as a promising candidate due to its decentralized nature (Shafayet al., 2021; Rizvi, 2023). Mitigating the Hardware ConstraintsOne desired property for edge servers is the ability to serveLLMs even with a commodity accelerator. FlexGen (Sheng et al., 2023b) first shows that it is possible torun text generation of large models like OPT-175B on a single 16GB GPU. FlexGen adaptively offloadsto aggregate memory and computation from the GPU, CPU, and disk. With efficient patterns searchedvia linear programming and weight and cache quantization, it can decode OPT-175B at 1 token/s speedwith a batch size of 144 with negligible accuracy loss. To maximize the potential of different hardware,MLC-LLM (MLC team, 2023) provides a universal solution that allows any language model to be deployednatively on a diverse set of hardware backends and native applications. For example, MLCChat, an iOS app,can serve some of the latest iPhone and iPad models; a similar APK is also available for Androids (spanningmanufacturers like Samsung, Redmi, and Google). The possibility continues to Mac, PC, Linux, and webbrowsers. Finally, on the hardware side, more and more powerful yet economical chips are developed toface the excitement of edge LLMs, examples including Apples M3 series and Qualcomms Cloud AI 100Ultra (supporting 100-billion-parameter models on a single 150-watt card).Last but not least, nuclearbatteries (Prelas et al., 2014) have shown their potential to revolutionize the power structure of mobilecomputing platforms, with a notable claimed battery duration of 50 years without charging (The EconomicTimes, 2024), which could potentially make edge devices more accessible, stable, and suitable for the diverseapplications of LLMs. The Future Form of Decentralized LLM It is undeniable that, in the future, decentralized LLM willhave its own place as it can satisfy many of the aforementioned characteristics that users crave for AGIsystems.With all the new algorithms, systems, and hardware progress, stitching all these componentstogether as a coherent compound is just a matter of time. We can envision that it will soon be possible toachieve collaborative training and inference with people joining worldwide with their own devices and datawhile keeping privacy, safety, and transparent control, the true form of democratized and open AI.",
  "AI for Coding": "The ability to write programs stands as one of the defining hallmarks of AGI. Writing complicated programsshows the skill of an AI system in abstract reasoning and adaptability in addressing diverse tasks.AsAlan Turing once pointed out in his seminal work (Turing, 1950), being able to write codes fundamentallyindicates that an AI system can exhibit intelligent behavior akin to human cognition, where the manipulationof symbols (following a specific language grammar to implement algorithms) leads to the manifestation ofcomplex thought processes. Hence developing code LLMs for both understanding and generation is cruciallyimportant both practically and conceptually for stepping towards AGI (Sun et al., 2024a). Code Foundation ModelsWhile many models for code generation are pre-trained mostly on codecorpus (Allal et al., 2023; Li et al., 2022b; Fried et al., 2023; Li et al., 2023a), more general purpose LLMsthat are continually pre-trained or fine-tuned on code become more powerful and capable such as Codex (Chenet al., 2021b), GPT-4 (OpenAI, 2023a), PaLM-Coder (Chowdhery et al., 2022b), CodeLlama (Rozire et al.,2024), and also smaller scale models like Phi (Gunasekar et al., 2023). The transition from code-specializedto code-understanding models also indicates that coding is a fundamental skill for AGI, just like manyother forms of general knowledge. Beyond code generation, these models are also capable of multi-languagereasoning (OpenAI, 2023a; Rozire et al., 2024) and infilling with before and after context (Fried et al., 2023;Bavarian et al., 2022). Code models open up many applications as the programs directly serve as the mostefficient machine language to communicate with other systems, which we will discuss in the next section.",
  ". Programs are powerful and general purpose, which can potentially lead to undesired behavior duringtesting": "Current evaluation benchmarks often focus either on fixed-form problems with standard input and outputpairs like programming interview (Chen et al., 2021b; Austin et al., 2021; Hendrycks et al., 2021) and datascience questions (Li et al., 2024b; Lai et al., 2022) or on text-level (high level) understanding like codeequivalence testing, complexity prediction, and code defect detection (Ben Allal et al., 2022). Nonetheless,to build effective and trustworthy code LLMs, we need a more comprehensive framework for evaluationthat covers many other interesting aspects such as interactive coding (Yang et al., 2023c), safety, the levelof optimization, and repository-level reasoning.These different facets of tasks will likely also get morecomplicated when we consider different programming languages and other coding-specifics. Code LLM Applications Code foundation models (Chen et al., 2021b; OpenAI, 2023a; Rozire et al., 2024;Chowdhery et al., 2022b) have already been extremely capable of conducting many basic code maneuveringsuch as completion, revision, doc-string generation, commenting, bug finding (Tian et al., 2024b), and codetranslation (Murali et al., 2024). There are, however, far more exciting applications of these models with noor minimal fine-tuning, which unfolds the possibility of turning many systems into an amalgamation. Software engineering. Many code applications center around software engineering and AI-assistedcoding beyond the basic abilities described above. SWE-Bench (Jimenez et al., 2023) attempts to assessa models capability to resolve GitHub issues, a core activity in a rich and sustainable real-world softwarecommunity. Doing so requires a coordinated understanding of the problem description, the executionenvironment, comments, and the codebase which often has cross-file dependencies and extremely longcontexts. The fact that their fine-tuned SWE-Llama can only resolve the simplest issues highly motivatesmore complicated and capable code models that can greatly help the software ecosystem.Softwaresafety and reliability have always been the most pivotal questions for engineers: RLSQM (Steenhoeket al., 2023) studies using reinforcement learning with static quality metrics as rewards for training acode LLM that can effectively generate unit tests for a codebase with little test smells while adhering to",
  "Embodied AI: AI for Robotics": "Unlike the focus in .2 on the interface to the physical world, this chapter begins with exploringthe potential commercial applications of AGI within the field of robotics. We will delve into a variety ofnew and cutting-edge commercial use cases, as well as innovative developmental directions. The chapterwill culminate with a discussion on the potential societal impacts, both positive and negative, that theseadvancements may herald. Recent advancements, underscored by significant investments from entities such as OpenAI, Microsoft, andNVIDIA, suggest a surge toward improving AIs physical capabilities. Innovations by Amazon in robotics,with systems (Eppner et al., 2016) like Sparrow (ama, 2022b) and Proteus (ama, 2022a), aim to automateand enhance the efficiency of operations while improving workplace safety by undertaking repetitive andlaborious tasks.OpenAI is broadening the capabilities of its multimodal models to encompass roboticperception, reasoning, and action and is also enhancing these models through a collaboration with FigureAI 19. Novel AI Application in Recent Robotics ResearchWake et al. (2023) proposes a novel pipelinethat enhances GPT-4V(vision), a general-purpose Vision Language Model, by integrating observations ofhuman actions to facilitate robotic manipulation. Yell At Your Robot (YAY Robot) system (Shi et al.,2024a) allows robots to adapt to verbal corrections in real time and improve upon their high-level policydecisions iteratively. This system leverages Language-Conditioned Behavior Cloning (LCBC) to learn a widerange of skills specified through language, enabling users to interact with robots using free-form commands.Zhang et al. (2023f) introduces the NOIR system, an innovative brain-robot interface (BRI) that employsnon-invasive electroencephalography (EEG) to enable humans to command robots to perform a diverse rangeof everyday activities. In recent AI for self-driving areas, utilizing LLMs or multi-modal LLM is becoming an importantmethod (Mao et al., 2023b; Wen et al., 2024; Mao et al., 2023a). AGENTSCODRIVER (Hu et al., 2024a)framework exhibits a comprehensive suite of capabilities for tackling sophisticated driving challenges. Itintegrates cognitive memory and reinforcement learning facets, supporting cooperative maneuvers amongmultiple vehicles and facilitating communication between them. Such an approach has been shown to en-hance the efficacy of cooperative driving paradigms markedly. The advent of AGI in Robotics equips systems to understand and interact with complex environments, push-ing the boundaries of AIs practical and operational abilities. This is particularly beneficial for challengingor risky tasks for humans, as embodied AI can take on such tasks with increased efficiency and safety. Withthese advancements, AGI is now better poised to tackle many real-world tasks, extending its utility beyondvirtual confines. However, anticipation intertwines with apprehension with the year 2024 on the horizon.Deploying robotic agents in real-world settings surfaces critical safety and ethical considerations. It is im-perative to establish stringent safety protocols and thoughtful ethical guidelines to effectively integrate AIinto human spaces. Labor market and social implications. The integration of AGI and robotics into various sectors ispredicted to alter the labor market fundamentally. The World Economic Forum anticipates that automa-tion and AI could displace 85 million jobs globally by 2025 while creating 97 million new roles, highlightingthe need for substantial reskilling and upskilling (Forum, 2020). Such transitions may transform socialstructures, potentially changing family care dynamics due to robotic caregivers and exacerbating thedigital divide, leading to increased socioeconomic disparities unless mitigated by inclusive policies (In-stitute, 2017; Center, 2017; Institution, 2021). Ethical and legal considerations are becoming crucial,with emerging needs for new frameworks to tackle issues of liability, intellectual property, and misuseprevention (OpenAI, 2018). As these technologies become more embedded in society, ensuring equitableaccess, safety, and ethical standards in AI deployment is vital for safeguarding human well-being.",
  "Human-AI Collaboration": "Human-AI collaboration refers to a collaborative interaction process between humans and AI to achievecertain goals in different settings. As we move towards AGI, AI will have more opportunities and challengesto collaborate with humans. Previous research in human-AI collaboration has covered many cases in the real world. One representativedirection is human-AI collaborative content creation, such as writing articles (Lee et al., 2024a), drawingpictures (Choi et al., 2024; Oh et al., 2018), writing code (Kazemitabaar et al., 2024), or brainstormingideas (Shaer et al., 2024). For example, researchers working in human-AI collaborative writing focus onstudying how writers interact with these new writing assistants and how they influence human writing (Leeet al., 2022). They proposed a design space as a structured way to examine and explore the multi-dimensionalspace of intelligent and interactive writing assistants (Lee et al., 2024a). Another representative direction ishuman-AI collaborative decision making, where an AI assistant makes recommendations to a human, who isresponsible for making final decisions (Bansal et al., 2019). Examples include AI systems that predict likelyhospital readmission to assist doctors with correlated care decisions (Zhang et al., 2024d; Yang et al., 2023a)or provide resource allocation decisions to assist policymakers in public services (Karusala et al., 2024).In this context, researchers argue that the most accurate model for human-AI teams is not necessarilythe best teammate. Instead, AI systems should be trained human-centered, directly optimized for teamperformance (Bansal et al., 2021a). Aspects of Human-AI Collaboration In order to achieve efficient collaboration, previous research hasfocused on several key aspects of human-AI collaboration including both interaction outcomes and interactionprocesses. Interaction outcomes. One initial motivation of human-AI collaboration is to realize complementaryperformance, which can leverage the strengths of both AI and humans to achieve better interactionoutcomes than what either could accomplish alone. In the age of large language models, this requiresreasonable characterization and assignment of the tasks that LLMs can perform. Designing effectivehuman-AI collaboration often starts from a holistic understanding of what humans and AI can andcannot do for certain tasks.In the case of human-AI collaborative writing, researchers argued thathumans are good at logical reasoning and consistency in long documents, while models are good atquickly generating texts of many versions based on local context. Therefore, humans lead the writingand edit model suggestions while models suggest the next sentences and help write fast (Lee et al., 2022).With such characterization, assigning plausible tasks for humans and AI in the collaborative team iscrucial for better results. To tackle this problem, recent research has turned to LLM chaining techniques.Chaining decomposes a task into multiple calls to an LLM, where the LLM only needs to accomplish oneof the several primitive operations in each call (Wu et al., 2022b; Grunde-McLaughlin et al., 2023). Suchtechniques have been widely adopted in human-LLM collaborative settings where humans can intervenein sub-tasks that LLMs may not adequately handle. Interaction processes. There are also some key issues to address for human-AI cooperative interaction,which focus on achieving better interaction processes for both humans and AI in human-AI collaboration.",
  "Conclusion": "In this paper, we offered a thorough overview of the ongoing research towards AGI, furnishing essentialcontext for researchers aspiring to make meaningful contributions to this pursuit. Ultimately, our paperaimed to draw attention and stimulate reflection on the pressing research questions: how far are we fromAGI, and moreover, how can we responsibly achieve AGI?. We firmly believe that addressing theseresearch queries demands unified and collaborative efforts from both the AI research community and beyond. In addition to establishing a shared groundwork for AI researchers through a comprehensive examination ofthe latest research advancements, we also articulate our vision of the fundamental nature of AGI and advocatefor a responsible approach to its development.Our goal here is to offer concrete directions for furtherexploration and to spark robust, thought-provoking discussions that will advance the community towardthe realization of true AGI. Given the continually evolving definition and objectives of AGI research,",
  "We also present a series of relevant case studies that illustrate the pervasive integration of AI systemsinto everyday life while candidly acknowledging their potential limitations": "In contrast to previous works, our paper encompasses several critical factors beyond technical solutions.We consistently emphasize the ethical, social, and philosophical implications of continually advancingAI techniques. By including these considerations, we aim to guide engineers and researchers in buildinghuman-controllable AGI systems that prioritize humanitys well-being and interests. As we stand on the precipice of this transformative era, it is essential to approach the development of AGIwith a keen awareness of its potential impact on society. By prioritizing ethical considerations, collaborativeefforts, and a commitment to the betterment of humanity, we can work towards a future in which AGIsystems serve as powerful tools for solving complex problems, driving scientific discovery, and improvingthe quality of life for all. The journey towards AGI may be arduous, but with a shared vision, unwaveringdedication, and a responsible approach, we could unleash its immense potential and shape a brighter futurefor the next generation.",
  "John M Abowd and Lars Vilhuber. 2008. How protective are synthetic data?. In International Conferenceon Privacy in Statistical Databases. Springer, 239246": "Josh Abramson, Jonas Adler, Jack Dunger, Richard Evans, Tim Green, Alexander Pritzel, Olaf Ronneberger,Lindsay Willmore, Andrew J. Ballard, Joshua Bambrick, Sebastian W. Bodenstein, David A. Evans, Chia-Chun Hung, Michael ONeill, David Reiman, Kathryn Tunyasuvunakool, Zachary Wu, Akvile emgulyte,Eirini Arvaniti, Charles Beattie, Ottavia Bertolli, Alex Bridgland, Alexey Cherepanov, Miles Congreve,Alexander I. Cowen-Rivers, Andrew Cowie, Michael Figurnov, Fabian B. Fuchs, Hannah Gladman, RishubJain, Yousuf A. Khan, Caroline M. R. Low, Kuba Perlin, Anna Potapenko, Pascal Savy, Sukhdeep Singh,Adrian Stecula, Ashok Thillaisundaram, Catherine Tong, Sergei Yakneen, Ellen D. Zhong, Michal Zielinski,Augustin dek, Victor Bapst, Pushmeet Kohli, Max Jaderberg, Demis Hassabis, and John M. Jumper.2024. Accurate structure prediction of biomolecular interactions with AlphaFold 3. Nature (2024). Josh Achiam, Steven Adler, Sandhini Agarwal, Lama Ahmad, Ilge Akkaya, Florencia Leoni Aleman, DiogoAlmeida, Janko Altenschmidt, Sam Altman, Shyamal Anadkat, et al. 2023. Gpt-4 technical report. arXivpreprint arXiv:2303.08774 (2023).",
  "Leonard Adolphs, Tianyu Gao, Jing Xu, Kurt Shuster, Sainbayar Sukhbaatar, and Jason Weston. 2022. Thecringe loss: Learning what language not to model. arXiv preprint arXiv:2211.05826 (2022)": "Rishabh Agarwal, Nino Vieillard, Yongchao Zhou, Piotr Stanczyk, Sabela Ramos, Matthieu Geist, andOlivier Bachem. 2024. On-Policy Distillation of Language Models: Learning from Self-Generated Mistakes.arXiv:2306.13649 [cs.LG] Michael Ahn, Anthony Brohan, Noah Brown, Yevgen Chebotar, Omar Cortes, Byron David, Chelsea Finn,Chuyuan Fu, Keerthana Gopalakrishnan, Karol Hausman, et al. 2022. Do as i can, not as i say: Groundinglanguage in robotic affordances. arXiv preprint arXiv:2204.01691 (2022).",
  "Anthropic AI. 2024. Claude 3": "Renat Aksitov, Sobhan Miryoosefi, Zonglin Li, Daliang Li, Sheila Babayan, Kavya Kopparapu, ZacharyFisher,Ruiqi Guo,Sushant Prakash,Pranesh Srinivasan,Manzil Zaheer,Felix Yu,and San-jiv Kumar. 2023.ReST meets ReAct:Self-Improvement for Multi-Step Reasoning LLM Agent.arXiv:2312.10003 [cs.CL] Afra Feyza Akyrek, Ekin Akyrek, Aman Madaan, Ashwin Kalyan, Peter Clark, Derry Wijaya, and NiketTandon. 2023. RL4F: Generating Natural Language Feedback with Reinforcement Learning for RepairingModel Outputs. arXiv preprint arXiv:2305.08844 (2023). Jean-Baptiste Alayrac, Jeff Donahue, Pauline Luc, Antoine Miech, Iain Barr, Yana Hasson, Karel Lenc,Arthur Mensch, Katherine Millican, Malcolm Reynolds, et al. 2022. Flamingo: a visual language modelfor few-shot learning. NeurIPS (2022).",
  "Arwa I Alhussain and Aqil M Azmi. 2021. Automatic story generation: A survey of approaches. ACMComputing Surveys (CSUR) 54, 5 (2021), 138": "Loubna Ben Allal, Raymond Li, Denis Kocetkov, Chenghao Mou, Christopher Akiki, Carlos Munoz Ferran-dis, Niklas Muennighoff, Mayank Mishra, Alex Gu, Manan Dey, Logesh Kumar Umapathi, Carolyn JaneAnderson, Yangtian Zi, Joel Lamy Poirier, Hailey Schoelkopf, Sergey Troshin, Dmitry Abulkhanov, ManuelRomero, Michael Lappert, Francesco De Toni, Bernardo Garca del Ro, Qian Liu, Shamik Bose, UrvashiBhattacharyya, Terry Yue Zhuo, Ian Yu, Paulo Villegas, Marco Zocca, Sourab Mangrulkar, David Lansky,Huu Nguyen, Danish Contractor, Luis Villa, Jia Li, Dzmitry Bahdanau, Yacine Jernite, Sean Hughes,Daniel Fried, Arjun Guha, Harm de Vries, and Leandro von Werra. 2023. SantaCoder: dont reach for thestars! arXiv:2301.03988 [cs.SE]",
  "Eloi Alonso, Adam Jelley, Vincent Micheli, Anssi Kanervisto, Amos Storkey, Tim Pearce, and FranoisFleuret. 2024. Diffusion for World Modeling: Visual Details Matter in Atari. arXiv:2405.12399 [cs.LG]": "Saleema Amershi, Dan Weld, Mihaela Vorvoreanu, Adam Fourney, Besmira Nushi, Penny Collisson, JinaSuh, Shamsi Iqbal, Paul N. Bennett, Kori Inkpen, Jaime Teevan, Ruth Kikin-Gil, and Eric Horvitz. 2019.Guidelines for Human-AI Interaction. In Proceedings of the 2019 CHI Conference on Human Factorsin Computing Systems (CHI 19). Association for Computing Machinery, New York, NY, USA, 113. Reza Yazdani Aminabadi, Samyam Rajbhandari, Minjia Zhang, Ammar Ahmad Awan, Cheng Li, Du Li,Elton Zheng, Jeff Rasley, Shaden Smith, Olatunji Ruwase, and Yuxiong He. 2022. DeepSpeed Inference:Enabling Efficient Inference of Transformer Models at Unprecedented Scale. arXiv:2207.00032 [cs.LG] Aida Amini, Saadia Gabriel, Shanchuan Lin, Rik Koncel-Kedziorski, Yejin Choi, and Hannaneh Hajishirzi.2019. MathQA: Towards Interpretable Math Word Problem Solving with Operation-Based Formalisms. InProceedings of the 2019 Conference of the North American Chapter of the Association for ComputationalLinguistics: Human Language Technologies, Volume 1 (Long and Short Papers), Jill Burstein, ChristyDoran, and Thamar Solorio (Eds.). Association for Computational Linguistics, Minneapolis, Minnesota,23572367.",
  "Ian Arawjo, Chelse Swoopes, Priyan Vaithilingam, Martin Wattenberg, and Elena Glassman. 2023. Chain-Forge: A Visual Toolkit for Prompt Engineering and LLM Hypothesis Testing. arXiv:2309.09128 [cs]": "Amanda Askell, Yuntao Bai, Anna Chen, Dawn Drain, Deep Ganguli, Tom Henighan, Andy Jones, NicholasJoseph, Ben Mann, Nova DasSarma, et al. 2021. A general language assistant as a laboratory for alignment.arXiv preprint arXiv:2112.00861 (2021). Jacob Austin, Augustus Odena, Maxwell Nye, Maarten Bosma, Henryk Michalewski, David Dohan, EllenJiang, Carrie Cai, Michael Terry, Quoc Le, and Charles Sutton. 2021. Program Synthesis with LargeLanguage Models. arXiv:2108.07732 [cs.PL]",
  "Timothy J. Aveni, Armando Fox, and Bjrn Hartmann. 2023.OmniFill:Domain-Agnostic FormFilling Suggestions Using Multi-Faceted Context. [cs]": "Mohammad Gheshlaghi Azar, Mark Rowland, Bilal Piot, Daniel Guo, Daniele Calandriello, Michal Valko,and Rmi Munos. 2023. A general theoretical paradigm to understand learning from human preferences.arXiv preprint arXiv:2310.12036 (2023). Ashutosh Baheti, Ximing Lu, Faeze Brahman, Ronan Le Bras, Maarten Sap, and Mark Riedl. 2023. Improv-ing Language Models with Advantage-based Offline Policy Gradients. arXiv preprint arXiv:2305.14718(2023).",
  "Yasaman Bahri, Ethan Dyer, Jared Kaplan, Jaehoon Lee, and Utkarsh Sharma. 2021. Explaining neuralscaling laws. arXiv preprint arXiv:2102.06701 (2021)": "Yutong Bai, Xinyang Geng, Karttikeya Mangalam, Amir Bar, Alan Yuille, Trevor Darrell, Jitendra Malik,and Alexei A Efros. 2023. Sequential Modeling Enables Scalable Learning for Large Vision Models. arXivpreprint arXiv:2312.00785 (2023). Yuntao Bai, Andy Jones, Kamal Ndousse, Amanda Askell, Anna Chen, Nova DasSarma, Dawn Drain,Stanislav Fort, Deep Ganguli, Tom Henighan, et al. 2022a. Training a helpful and harmless assistant withreinforcement learning from human feedback. arXiv preprint arXiv:2204.05862 (2022). Yuntao Bai, Saurav Kadavath, Sandipan Kundu, Amanda Askell, Jackson Kernion, Andy Jones, Anna Chen,Anna Goldie, Azalia Mirhoseini, Cameron McKinnon, et al. 2022b. Constitutional ai: Harmlessness fromai feedback. arXiv preprint arXiv:2212.08073 (2022). Junseong Bang, Byung-Tak Lee, and Pangun Park. 2023. Examination of Ethical Principles for LLM-BasedRecommendations in Conversational AI. In 2023 International Conference on Platform Technology andService (PlatCon). IEEE, 109113. Shruthi Bannur, Stephanie Hyland, Qianchu Liu, Fernando Prez-Garca, Maximilian Ilse, Daniel C. Cas-tro, Benedikt Boecking, Harshita Sharma, Kenza Bouzid, Anja Thieme, Anton Schwaighofer, MariaWetscherek, Matthew P. Lungren, Aditya Nori, Javier Alvarez-Valle, and Ozan Oktay. 2023. Learning toExploit Temporal Structure for Biomedical Vision-Language Processing. arXiv:2301.04558 [cs.CV] Gagan Bansal, Besmira Nushi, Ece Kamar, Eric Horvitz, and Daniel S. Weld. 2021a. Is the Most AccurateAI the Best Teammate? Optimizing AI for Teamwork. Proceedings of the AAAI Conference on ArtificialIntelligence 35, 13 (May 2021), 1140511414. Number:13. Gagan Bansal, Besmira Nushi, Ece Kamar, Daniel S. Weld, Walter S. Lasecki, and Eric Horvitz. 2019.Updates in Human-AI Teams: Understanding and Addressing the Performance/Compatibility Tradeoff.Proceedings of the AAAI Conference on Artificial Intelligence 33, 01 (July 2019), 24292437. Number: 01.",
  "ChrisBaraniuk.2018.Exclusive:UKpolicewantsAItostopviolentcrimebe-foreithappens|NewScientist": "Clark Barrett, Brad Boyd, Elie Burzstein, Nicholas Carlini, Brad Chen, Jihye Choi, Amrita Roy Chowd-hury, Mihai Christodorescu, Anupam Datta, Soheil Feizi, Kathleen Fisher, Tatsunori Hashimoto, DanHendrycks, Somesh Jha, Daniel Kang, Florian Kerschbaum, Eric Mitchell, John Mitchell, Zulfikar Ramzan,Khawaja Shams, Dawn Song, Ankur Taly, and Diyi Yang. 2023.Identifying and Mitigating the Se-curity Risks of Generative AI.Foundations and Trends in Privacy and Security 6, 1 (2023), 152. arXiv:2308.14840 [cs].",
  "Loubna Ben Allal, Niklas Muennighoff, Logesh Kumar Umapathi, Ben Lipkin, and Leandro von Werra. 2022.A framework for the evaluation of code generation models": "Emily M. Bender, Timnit Gebru, Angelina McMillan-Major, and Shmargaret Shmitchell. 2021. On the Dan-gers of Stochastic Parrots: Can Language Models Be Too Big?. In Proceedings of the 2021 ACM Conferenceon Fairness, Accountability, and Transparency (FAccT 21). Association for Computing Machinery, NewYork, NY, USA, 610623. Felix Berkenkamp, Matteo Turchetta, Angela Schoellig, and Andreas Krause. 2017. Safe model-based re-inforcement learning with stability guarantees.Advances in neural information processing systems 30(2017). William Berrios, Gautam Mittal, Tristan Thrush, Douwe Kiela, and Amanpreet Singh. 2023.Towardslanguage models that can see: Computer vision through the lens of natural language. arXiv preprintarXiv:2306.16410 (2023). Maciej Besta, Nils Blach, Ales Kubicek, Robert Gerstenberger, Lukas Gianinazzi, Joanna Gajda, TomaszLehmann, Michal Podstawski, Hubert Niewiadomski, Piotr Nyczyk, et al. 2023.Graph of thoughts:Solving elaborate problems with large language models. arXiv preprint arXiv:2308.09687 (2023). Umang Bhatt, Javier Antorn, Yunfeng Zhang, Q. Vera Liao, Prasanna Sattigeri, Riccardo Fogliato,Gabrielle Melanon, Ranganath Krishnan, Jason Stanley, Omesh Tickoo, Lama Nachman, Rumi Chunara,Madhulika Srikumar, Adrian Weller, and Alice Xiang. 2021. Uncertainty as a Form of Transparency: Mea-suring, Communicating, and Using Uncertainty. In Proceedings of the 2021 AAAI/ACM Conference onAI, Ethics, and Society (AIES 21). Association for Computing Machinery, New York, NY, USA, 401413.",
  "Daniil A. Boiko, Robert MacKnight, Ben Kline, and Gabe Gomes. 2023b.Autonomous chemical re-search with large language models. Nature 624, 7992 (12 2023), 570578": "Rishi Bommasani, Drew A Hudson, Ehsan Adeli, Russ Altman, Simran Arora, Sydney von Arx, Michael SBernstein, Jeannette Bohg, Antoine Bosselut, Emma Brunskill, et al. 2021. On the opportunities and risksof foundation models. arXiv preprint arXiv:2108.07258 (2021). Sebastian Borgeaud, Arthur Mensch, Jordan Hoffmann, Trevor Cai, Eliza Rutherford, Katie Millican,George Bm Van Den Driessche, Jean-Baptiste Lespiau, Bogdan Damoc, Aidan Clark, et al. 2022. Im-proving language models by retrieving from trillions of tokens. In International conference on machinelearning. PMLR, 22062240. Alexander Borzunov, Dmitry Baranchuk, Tim Dettmers, Max Ryabinin, Younes Belkada, Artem Chu-machenko, Pavel Samygin, and Colin Raffel. 2022. Petals: Collaborative Inference and Fine-tuning ofLarge Models. arXiv preprint arXiv:2209.01188 (2022). Aleksandar Botev, Soham De, Samuel L Smith, Anushan Fernando, George-Cristian Muraru, Ruba Haroun,Leonard Berrada, Razvan Pascanu, Pier Giuseppe Sessa, Robert Dadashi, Lonard Hussenot, Johan Ferret,Sertan Girgin, Olivier Bachem, Alek Andreev, Kathleen Kenealy, Thomas Mesnard, Cassidy Hardin, SuryaBhupatiraju, Shreya Pathak, Laurent Sifre, Morgane Rivire, Mihir Sanjay Kale, Juliette Love, PouyaTafti, Armand Joulin, Noah Fiedel, Evan Senter, Yutian Chen, Srivatsan Srinivasan, Guillaume Desjardins,David Budden, Arnaud Doucet, Sharad Vikram, Adam Paszke, Trevor Gale, Sebastian Borgeaud, CharlieChen, Andy Brock, Antonia Paterson, Jenny Brennan, Meg Risdal, Raj Gundluru, Nesh Devanathan, PaulMooney, Nilay Chauhan, Phil Culliton, Luiz Gustavo Martins, Elisa Bandy, David Huntsperger, GlennCameron, Arthur Zucker, Tris Warkentin, Ludovic Peran, Minh Giang, Zoubin Ghahramani, Clment Fara-bet, Koray Kavukcuoglu, Demis Hassabis, Raia Hadsell, Yee Whye Teh, and Nando de Frietas. 2024. Re-currentGemma: Moving Past Transformers for Efficient Open Language Models. arXiv:2404.07839 [cs.LG]",
  "Selmer Bringsjord and David Ferrucci. 2003. Artificial intelligence and literary creativity: Inside the mindof Brutus, a storytelling machine. Routledge": "Tim Brooks, Bill Peebles, Connor Homes, Will DePue, Yufei Guo, Li Jing, David Schnurr, JoeTaylor, Troy Luhman, Eric Luhman, Clarence Wing Yin Ng, Ricky Wang, and Aditya Ramesh.2024.Video generation models as world simulators.(2024). Tom Brown, Benjamin Mann, Nick Ryder, Melanie Subbiah, Jared D Kaplan, Prafulla Dhariwal, ArvindNeelakantan, Pranav Shyam, Girish Sastry, Amanda Askell, et al. 2020. Language models are few-shotlearners. Advances in neural information processing systems 33 (2020), 18771901. Jake Bruce, Michael Dennis, Ashley Edwards, Jack Parker-Holder, Yuge Shi, Edward Hughes, MatthewLai, Aditi Mavalankar, Richie Steigerwald, Chris Apps, Yusuf Aytar, Sarah Bechtle, Feryal Behbahani,Stephanie Chan, Nicolas Heess, Lucy Gonzalez, Simon Osindero, Sherjil Ozair, Scott Reed, Jingwei Zhang,Konrad Zolna, Jeff Clune, Nando de Freitas, Satinder Singh, and Tim Rocktschel. 2024. Genie: GenerativeInteractive Environments. arXiv:2402.15391 [cs.LG]",
  "Vladimir Bugaj and Ben Goertzel. 2009. AGI preschool: a framework for evaluating early-stage human-likeAGIs. In 2nd Conference on Artificial General Intelligence (2009). Atlantis Press, 1217": "Collin Burns, Pavel Izmailov, Jan Hendrik Kirchner, Bowen Baker, Leo Gao, Leopold Aschenbrenner, YiningChen, Adrien Ecoffet, Manas Joglekar, Jan Leike, et al. 2023. Weak-to-Strong Generalization: ElicitingStrong Capabilities With Weak Supervision. arXiv preprint arXiv:2312.09390 (2023). Patrick Butlin, Robert Long, Eric Elmoznino, Yoshua Bengio, Jonathan Birch, Axel Constant, George Deane,Stephen M. Fleming, Chris Frith, Xu Ji, Ryota Kanai, Colin Klein, Grace Lindsay, Matthias Michel, LiadMudrik, Megan A. K. Peters, Eric Schwitzgebel, Jonathan Simon, and Rufin VanRullen. 2023. Conscious-ness in Artificial Intelligence: Insights from the Science of Consciousness. arXiv:2308.08708 [cs.AI] Tianle Cai, Yuhong Li, Zhengyang Geng, Hongwu Peng, Jason D. Lee, Deming Chen, and Tri Dao.2024a.Medusa:Simple LLM Inference Acceleration Framework with Multiple Decoding Heads.arXiv:2401.10774 [cs.LG]",
  "Bochuan Cao, Yuanpu Cao, Lu Lin, and Jinghui Chen. 2023. Defending against alignment-breaking attacksvia robustly aligned llm. arXiv preprint arXiv:2309.14348 (2023)": "Yang Trista Cao and Hal Daum III. 2020. Toward Gender-Inclusive Coreference Resolution. In Proceedingsof the 58th Annual Meeting of the Association for Computational Linguistics, Dan Jurafsky, Joyce Chai,Natalie Schluter, and Joel Tetreault (Eds.). Association for Computational Linguistics, Online, 45684595. Amlcar Cardoso, Tony Veale, and Geraint A Wiggins. 2009. Converging on the divergent: The history (andfuture) of the international joint workshops in computational creativity. AI magazine 30, 3 (2009), 1515.",
  "Lingjiao Chen, Matei Zaharia, and James Zou. 2023i. FrugalGPT: How to Use Large Language ModelsWhile Reducing Cost and Improving Performance. arXiv:2305.05176 [cs.LG]": "Lichang Chen, Chen Zhu, Davit Soselia, Jiuhai Chen, Tianyi Zhou, Tom Goldstein, Heng Huang, MohammadShoeybi, and Bryan Catanzaro. 2024d. Odin: Disentangled reward mitigates hacking in rlhf. arXiv preprintarXiv:2402.07319 (2024). Minshuo Chen, Song Mei, Jianqing Fan, and Mengdi Wang. 2024b. An overview of diffusion models: Appli-cations, guided generation, statistical rates and optimization. arXiv preprint arXiv:2404.07771 (2024). Mark Chen, Jerry Tworek, Heewoo Jun, Qiming Yuan, Henrique Ponde de Oliveira Pinto, Jared Kaplan,Harri Edwards, Yuri Burda, Nicholas Joseph, Greg Brockman, Alex Ray, Raul Puri, Gretchen Krueger,Michael Petrov, Heidy Khlaaf, Girish Sastry, Pamela Mishkin, Brooke Chan, Scott Gray, Nick Ryder,Mikhail Pavlov, Alethea Power, Lukasz Kaiser, Mohammad Bavarian, Clemens Winter, Philippe Tillet, Fe-lipe Petroski Such, Dave Cummings, Matthias Plappert, Fotios Chantzis, Elizabeth Barnes, Ariel Herbert-Voss, William Hebgen Guss, Alex Nichol, Alex Paino, Nikolas Tezak, Jie Tang, Igor Babuschkin, SuchirBalaji, Shantanu Jain, William Saunders, Christopher Hesse, Andrew N. Carr, Jan Leike, Josh Achiam,Vedant Misra, Evan Morikawa, Alec Radford, Matthew Knight, Miles Brundage, Mira Murati, KatieMayer, Peter Welinder, Bob McGrew, Dario Amodei, Sam McCandlish, Ilya Sutskever, and WojciechZaremba. 2021b. Evaluating Large Language Models Trained on Code. (2021). arXiv:2107.03374 [cs.LG]",
  "Tianqi Chen, Bing Xu, Chiyuan Zhang, and Carlos Guestrin. 2016. Training Deep Nets with SublinearMemory Cost. arXiv:1604.06174 [cs.LG]": "Wenhu Chen, Xueguang Ma, Xinyi Wang, and William W Cohen. 2022. Program of thoughts prompting:Disentangling computation from reasoning for numerical reasoning tasks. arXiv preprint arXiv:2211.12588(2022). Weize Chen, Yusheng Su, Jingwei Zuo, Cheng Yang, Chenfei Yuan, Chen Qian, Chi-Min Chan, Yujia Qin,Yaxi Lu, Ruobing Xie, et al. 2023f.Agentverse: Facilitating multi-agent collaboration and exploringemergent behaviors in agents. arXiv preprint arXiv:2308.10848 (2023). Wei-Ge Chen, Irina Spiridonova, Jianwei Yang, Jianfeng Gao, and Chunyuan Li. 2023e. Llava-interactive:An all-in-one demo for image chat, segmentation, generation and editing. arXiv preprint arXiv:2311.00571(2023). Yufan Chen, Arjun Arunasalam, and Z Berkay Celik. 2023a. Can large language models provide security &privacy advice? measuring the ability of llms to refute misconceptions. In Proceedings of the 39th AnnualComputer Security Applications Conference. 366378.",
  "Jyoti Choudrie and Mohamad Selamat. 2006.The Consideration of Meta-Abilities in Tacit KnowledgeExternalization and Organizational Learning": "Aakanksha Chowdhery, Sharan Narang, Jacob Devlin, Maarten Bosma, Gaurav Mishra, Adam Roberts,Paul Barham, Hyung Won Chung, Charles Sutton, Sebastian Gehrmann, Parker Schuh, Kensen Shi,Sasha Tsvyashchenko, Joshua Maynez, Abhishek Rao, Parker Barnes, Yi Tay, Noam Shazeer, VinodkumarPrabhakaran, Emily Reif, Nan Du, Ben Hutchinson, Reiner Pope, James Bradbury, Jacob Austin, MichaelIsard, Guy Gur-Ari, Pengcheng Yin, Toju Duke, Anselm Levskaya, Sanjay Ghemawat, Sunipa Dev, HenrykMichalewski, Xavier Garcia, Vedant Misra, Kevin Robinson, Liam Fedus, Denny Zhou, Daphne Ippolito,David Luan, Hyeontaek Lim, Barret Zoph, Alexander Spiridonov, Ryan Sepassi, David Dohan, ShivaniAgrawal, Mark Omernick, Andrew M. Dai, Thanumalayan Sankaranarayana Pillai, Marie Pellat, AitorLewkowycz, Erica Moreira, Rewon Child, Oleksandr Polozov, Katherine Lee, Zongwei Zhou, Xuezhi Wang,Brennan Saeta, Mark Diaz, Orhan Firat, Michele Catasta, Jason Wei, Kathy Meier-Hellstern, DouglasEck, Jeff Dean, Slav Petrov, and Noah Fiedel. 2022a. PaLM: Scaling Language Modeling with Pathways.arXiv:2204.02311 [cs.CL] Aakanksha Chowdhery, Sharan Narang, Jacob Devlin, Maarten Bosma, Gaurav Mishra, Adam Roberts,Paul Barham, Hyung Won Chung, Charles Sutton, Sebastian Gehrmann, Parker Schuh, Kensen Shi,Sasha Tsvyashchenko, Joshua Maynez, Abhishek Rao, Parker Barnes, Yi Tay, Noam Shazeer, VinodkumarPrabhakaran, Emily Reif, Nan Du, Ben Hutchinson, Reiner Pope, James Bradbury, Jacob Austin, MichaelIsard, Guy Gur-Ari, Pengcheng Yin, Toju Duke, Anselm Levskaya, Sanjay Ghemawat, Sunipa Dev, HenrykMichalewski, Xavier Garcia, Vedant Misra, Kevin Robinson, Liam Fedus, Denny Zhou, Daphne Ippolito,David Luan, Hyeontaek Lim, Barret Zoph, Alexander Spiridonov, Ryan Sepassi, David Dohan, ShivaniAgrawal, Mark Omernick, Andrew M. Dai, Thanumalayan Sankaranarayana Pillai, Marie Pellat, AitorLewkowycz, Erica Moreira, Rewon Child, Oleksandr Polozov, Katherine Lee, Zongwei Zhou, Xuezhi Wang,Brennan Saeta, Mark Diaz, Orhan Firat, Michele Catasta, Jason Wei, Kathy Meier-Hellstern, DouglasEck, Jeff Dean, Slav Petrov, and Noah Fiedel. 2022b. PaLM: Scaling Language Modeling with Pathways.arXiv:2204.02311 [cs.CL] Mohammed Nowaz Rabbani Chowdhury, Shuai Zhang, Meng Wang, Sijia Liu, and Pin-Yu Chen. 2023. Patch-level Routing in Mixture-of-Experts is Provably Sample-efficient for Convolutional Neural Networks. arXivpreprint arXiv:2306.04073 (2023).",
  "Katherine Crowson. 2022. VQGAN-CLIP: Open Domain Image Generation and Editing with Natural Lan-guage Guidance. arXiv preprint arXiv:2204.08583 (2022)": "Chenhang Cui, Yiyang Zhou, Xinyu Yang, Shirley Wu, Linjun Zhang, James Zou, and Huaxiu Yao. 2023.Holistic analysis of hallucination in gpt-4v (ision):Bias and interference challenges.arXiv preprintarXiv:2311.03287 (2023). Chris Cummins, Volker Seeker, Dejan Grubisic, Mostafa Elhoushi, Youwei Liang, Baptiste Roziere, JonasGehring, Fabian Gloeckle, Kim Hazelwood, Gabriel Synnaeve, and Hugh Leather. 2023. Large LanguageModels for Compiler Optimization. arXiv:2309.07062 [cs.PL]",
  "Stanislas Dehaene, Hakwan Lau, and Sid Kouider. 2021. What is consciousness, and could machines haveit? Robotics, AI, and humanity: Science, ethics, and policy (2021), 4356": "Xiang Deng, Yu Gu, Boyuan Zheng, Shijie Chen, Samuel Stevens, Boshi Wang, Huan Sun, and Yu Su. 2023.Mind2Web: Towards a Generalist Agent for the Web. In Thirty-seventh Conference on Neural InformationProcessing Systems Datasets and Benchmarks Track. Xiang Deng, Yu Gu, Boyuan Zheng, Shijie Chen, Sam Stevens, Boshi Wang, Huan Sun, and Yu Su. 2024.Mind2web: Towards a generalist agent for the web. Advances in Neural Information Processing Systems36 (2024).",
  "Jiayu Ding, Shuming Ma, Li Dong, Xingxing Zhang, Shaohan Huang, Wenhui Wang, Nanning Zheng, andFuru Wei. 2023b. LongNet: Scaling Transformers to 1,000,000,000 Tokens. arXiv:2307.02486 [cs.CL]": "Ning Ding, Yulin Chen, Bokai Xu, Yujia Qin, Zhi Zheng, Shengding Hu, Zhiyuan Liu, Maosong Sun, andBowen Zhou. 2023a. Enhancing chat language models by scaling high-quality instructional conversations.arXiv preprint arXiv:2305.14233 (2023). Yiran Ding, Li Lyna Zhang, Chengruidong Zhang, Yuanyuan Xu, Ning Shang, Jiahang Xu, Fan Yang, andMao Yang. 2024b. Longrope: Extending llm context window beyond 2 million tokens. arXiv preprintarXiv:2402.13753 (2024).",
  "Zihan Ding, Amy Zhang, Yuandong Tian, and Qinqing Zheng. 2024a.Diffusion World Model: FutureModeling Beyond Step-by-Step Rollout for Offline Reinforcement Learning.arXiv:2402.03570 [cs.LG]": "Jesse Dodge, Maarten Sap, Ana Marasovi, William Agnew, Gabriel Ilharco, Dirk Groeneveld, MargaretMitchell, and Matt Gardner. 2021. Documenting large webtext corpora: A case study on the colossalclean crawled corpus. arXiv preprint arXiv:2104.08758 (2021). David Dohan, Winnie Xu, Aitor Lewkowycz, Henryk Michalewski, Christoph Feichtenhofer, David Bieber,Charles Sutton, and Oriol Vinyals. 2023. Language Models as Zero-Shot Planners: Extracting ActionableKnowledge for Embodied Agents. arXiv preprint arXiv:2302.04754 (2023).",
  "Peitong Duan, Jeremy Warner, Yang Li, and Bjoern Hartmann. 2024. Generating Automatic Feedback on UIMockups with Large Language Models. arXiv:2403.13139[cs]": "Jacob Eisenstein, Chirag Nagpal, Alekh Agarwal, Ahmad Beirami, Alex DAmour, DJ Dvijotham, AdamFisch, Katherine Heller, Stephen Pfohl, Deepak Ramachandran, et al. 2023. Helping or herding? rewardmodel ensembles mitigate but do not eliminate reward hacking. arXiv preprint arXiv:2312.09244 (2023). Alaaeldin El-Nouby, Michal Klein, Shuangfei Zhai, Miguel Angel Bautista, Alexander Toshev, VaishaalShankar, Joshua M Susskind, and Armand Joulin. 2024. Scalable Pre-training of Large AutoregressiveImage Models. arXiv preprint arXiv:2401.08541 (2024). DouglasC.Engelbart.1962.Aconceptualframeworkfortheaugmenta-tionofmansintellect.AirForceOfficeofScientificResearch,AFOSR-3233,www.bootstrap.org/augdocs/friedewald030402/augmentinghumanintellect/ahi62index.html. Clemens Eppner, Sebastian Hfer, Rico Jonschkowski, Roberto Martn-Martn, Arne Sieverling, VincentWall, and Oliver Brock. 2016.Lessons from the amazon picking challenge: Four aspects of buildingrobotic systems.. In Robotics: science and systems, Vol. 12. Nick Erickson, Jonas Mueller, Alexander Shirkov, Hang Zhang, Pedro Larroy, Mu Li, and AlexanderSmola. 2020. AutoGluon-Tabular: Robust and Accurate AutoML for Structured Data. arXiv preprintarXiv:2003.06505 (2020).",
  "Li Feng, Ryan Yen, Yuzhe You, Mingming Fan, Jian Zhao, and Zhicong Lu. 2024. CoPrompt: SupportingPrompt Sharing and Referring in Collaborative Natural Language Programming. arXiv:2310.09235 [cs]": "Weixi Feng, Wanrong Zhu, Tsu jui Fu, Varun Jampani, Arjun Akula, Xuehai He, Sugato Basu, Xin EricWang, and William Yang Wang. 2023. LayoutGPT: Compositional Visual Planning and Generation withLarge Language Models. arXiv:2305.15393 [cs.CV] Chrisantha Fernando, Dylan Banarse, Henryk Michalewski, Simon Osindero, and Tim Rocktschel. 2023.Promptbreeder: Self-referential self-improvement via prompt evolution. arXiv preprint arXiv:2309.16797(2023).",
  "Trevor Gale, Deepak Narayanan, Cliff Young, and Matei Zaharia. 2022.MegaBlocks: Efficient SparseTraining with Mixture-of-Experts. arXiv:2211.15841 [cs.LG]": "Difei Gao, Lei Ji, Zechen Bai, Mingyu Ouyang, Peiran Li, Dongxing Mao, Qinchen Wu, Weichen Zhang, PeiyiWang, Xiangwu Guo, et al. 2023b. Assistgui: Task-oriented desktop graphical user interface automation.arXiv preprint arXiv:2312.13108 (2023). Leo Gao, Tom Dupr la Tour, Henk Tillman, Gabriel Goh, Rajan Troll, Alec Radford, Ilya Sutskever, JanLeike, and Jeffrey Wu. 2024. Scaling and evaluating sparse autoencoders. arXiv preprint arXiv:2406.04093(2024). Peng Gao, Jiaming Han, Renrui Zhang, Ziyi Lin, Shijie Geng, Aojun Zhou, Wei Zhang, Pan Lu, ConghuiHe, Xiangyu Yue, et al. 2023a. Llama-adapter v2: Parameter-efficient visual instruction model. arXivpreprint arXiv:2304.15010 (2023).",
  "Fabrizio Gilardi, Meysam Alizadeh, and Mal Kubli. 2023. ChatGPT outperforms crowd workers for text-annotation tasks. Proceedings of the National Academy of Sciences 120, 30 (2023), e2305016120": "Rohit Girdhar, Alaaeldin El-Nouby, Zhuang Liu, Mannat Singh, Kalyan Vasudev Alwala, Armand Joulin,and Ishan Misra. 2023.Imagebind:One embedding space to bind them all. In Proceedings of theIEEE/CVF Conference on Computer Vision and Pattern Recognition. 1518015190. Amelia Glaese, Nat McAleese, Maja Trbacz, John Aslanides, Vlad Firoiu, Timo Ewalds, Maribeth Rauh,Laura Weidinger, Martin Chadwick, Phoebe Thacker, et al. 2022. Improving alignment of dialogue agentsvia targeted human judgements. arXiv preprint arXiv:2209.14375 (2022). Dongyoung Go, Tomasz Korbak, Germn Kruszewski, Jos Rozen, Nahyeon Ryu, and Marc Dymetman.2023.Aligning language models with preferences through f-divergence minimization.arXiv preprintarXiv:2302.08215 (2023). Charles Goddard, Shamane Siriwardhana, Malikeh Ehghaghi, Luke Meyers, Vlad Karpukhin, Brian Benedict,Mark McQuade, and Jacob Solawetz. 2024. Arcees MergeKit: A Toolkit for Merging Large LanguageModels. arXiv preprint arXiv:2403.13257 (2024). Tao Gong, Chengqi Lyu, Shilong Zhang, Yudong Wang, Miao Zheng, Qian Zhao, Kuikun Liu, Wenwei Zhang,Ping Luo, and Kai Chen. 2023. Multimodal-gpt: A vision and language model for dialogue with humans.arXiv preprint arXiv:2305.04790 (2023). Ian Goodfellow, Jean Pouget-Abadie, Mehdi Mirza, Bing Xu, David Warde-Farley, Sherjil Ozair, AaronCourville, and Yoshua Bengio. 2020. Generative adversarial networks. Commun. ACM 63, 11 (2020),139144. Zhibin Gou, Zhihong Shao, Yeyun Gong, Yelong Shen, Yujiu Yang, Nan Duan, and Weizhu Chen.2023a. Critic: Large language models can self-correct with tool-interactive critiquing. arXiv preprintarXiv:2305.11738 (2023).",
  "Alex Graves and Alex Graves. 2012. Long short-term memory. Supervised sequence labelling with recurrentneural networks (2012), 3745": "Dirk Groeneveld, Iz Beltagy, Pete Walsh, Akshita Bhagia, Rodney Kinney, Oyvind Tafjord, Ananya HarshJha, Hamish Ivison, Ian Magnusson, Yizhong Wang, Shane Arora, David Atkinson, Russell Authur, Khy-athi Raghavi Chandu, Arman Cohan, Jennifer Dumas, Yanai Elazar, Yuling Gu, Jack Hessel, TusharKhot, William Merrill, Jacob Morrison, Niklas Muennighoff, Aakanksha Naik, Crystal Nam, Matthew E.Peters, Valentina Pyatkin, Abhilasha Ravichander, Dustin Schwenk, Saurabh Shah, Will Smith, EmmaStrubell, Nishant Subramani, Mitchell Wortsman, Pradeep Dasigi, Nathan Lambert, Kyle Richardson,Luke Zettlemoyer, Jesse Dodge, Kyle Lo, Luca Soldaini, Noah A. Smith, and Hannaneh Hajishirzi. 2024.OLMo: Accelerating the Science of Language Models. arXiv:2402.00838 [cs.CL]",
  "Lin Gui, Cristina Grbacea, and Victor Veitch. 2024. BoNBoN Alignment for Large Language Models andthe Sweetness of Best-of-n Sampling. arXiv:2406.00832[cs]": "Suriya Gunasekar, Yi Zhang, Jyoti Aneja, Caio Csar Teodoro Mendes, Allie Del Giorno, Sivakanth Gopi,Mojan Javaheripi, Piero Kauffmann, Gustavo de Rosa, Olli Saarikivi, Adil Salim, Shital Shah, Harki-rat Singh Behl, Xin Wang, Sbastien Bubeck, Ronen Eldan, Adam Tauman Kalai, Yin Tat Lee, andYuanzhi Li. 2023. Textbooks Are All You Need. arXiv:2306.11644 [cs.CL] Jun Guo, Wei Bao, Jiakai Wang, Yuqing Ma, Xinghai Gao, Gang Xiao, Aishan Liu, Jian Dong, XianglongLiu, and Wenjun Wu. 2023. A comprehensive evaluation framework for deep model robustness. PatternRecognition 137 (2023), 109308. Jianyuan Guo, Hanting Chen, Chengcheng Wang, Kai Han, Chang Xu, and Yunhe Wang. 2024a.Vi-sion Superalignment:Weak-to-Strong Generalization for Vision Foundation Models.arXiv preprintarXiv:2402.03749 (2024). Shangmin Guo, Biao Zhang, Tianlin Liu, Tianqi Liu, Misha Khalman, Felipe Llinares, Alexandre Rame,Thomas Mesnard, Yao Zhao, Bilal Piot, et al. 2024b. Direct language model alignment from online aifeedback. arXiv preprint arXiv:2402.04792 (2024). Xiaoxiao Guo, Pengcheng Gao, Chang Liu, Matthias Schott, Yao-Hung Hubert Lai, Jie Mao, Yongming Rao,Yen-Cheng Chiu, Carlos Fernndez-Granda, Yujia Shen, et al. 2022. General-Purpose Embodied AI Agentvia Reinforcement Learning with Internet-Scale Knowledge. arXiv preprint arXiv:2212.09710 (2022).",
  "Danijar Hafner, Jungseock Lee, Ian Fischer, and Pieter Abbeel. 2023. Mastering Diverse Domains throughWorld Models. arXiv preprint arXiv:2301.04104 (2023)": "Jiaming Han, Kaixiong Gong, Yiyuan Zhang, Jiaqi Wang, Kaipeng Zhang, Dahua Lin, Yu Qiao, Peng Gao,and Xiangyu Yue. 2023a. OneLLM: One Framework to Align All Modalities with Language. arXiv preprintarXiv:2312.03700 (2023). Jiaming Han, Renrui Zhang, Wenqi Shao, Peng Gao, Peng Xu, Han Xiao, Kaipeng Zhang, Chris Liu,Song Wen, Ziyu Guo, et al. 2023b. Imagebind-llm: Multi-modality instruction tuning. arXiv preprintarXiv:2309.03905 (2023). Jesse Michael Han, Jason Rute, Yuhuai Wu, Edward Ayers, and Stanislas Polu. 2022. Proof Artifact Co-Training for Theorem Proving with Language Models. In International Conference on Learning Represen-tations.",
  "Xin He, Longhui Wei, Lingxi Xie, and Qi Tian. 2024. Incorporating Visual Experts to Resolve the InformationLoss in Multimodal Large Language Models. arXiv preprint arXiv:2401.03105 (2024)": "Peter Henderson, Jieru Hu, Joshua Romoff, Emma Brunskill, Dan Jurafsky, and Joelle Pineau. 2020. Towardsthe systematic reporting of the energy and carbon footprints of machine learning. Journal of MachineLearning Research 21, 248 (2020), 143. Dan Hendrycks, Steven Basart, Saurav Kadavath, Mantas Mazeika, Akul Arora, Ethan Guo, Collin Burns,Samir Puranik, Horace He, Dawn Song, and Jacob Steinhardt. 2021. Measuring Coding Challenge Com-petence With APPS. arXiv:2105.09938 [cs.SE]",
  "HalHodson.2016.Revealed:GoogleAIhasaccesstohugehaulofNHSpatientdata": "Jordan Hoffmann, Sebastian Borgeaud, Arthur Mensch, Elena Buchatskaya, Trevor Cai, Eliza Rutherford,Diego de Las Casas, Lisa Anne Hendricks, Johannes Welbl, Aidan Clark, Tom Hennigan, Eric Noland,Katie Millican, George van den Driessche, Bogdan Damoc, Aurelia Guy, Simon Osindero, Karen Simonyan,Erich Elsen, Jack W. Rae, Oriol Vinyals, and Laurent Sifre. 2022.Training Compute-Optimal LargeLanguage Models. arXiv:2203.15556 [cs.CL] Connor Holmes, Masahiro Tanaka, Michael Wyatt, Ammar Ahmad Awan, Jeff Rasley, Samyam Rajbhan-dari, Reza Yazdani Aminabadi, Heyang Qin, Arash Bakhtiari, Lev Kurilenko, and Yuxiong He. 2024.DeepSpeed-FastGen:High-throughput Text Generation for LLMs via MII and DeepSpeed-Inference.arXiv:2401.08671 [cs.PF]",
  "Ke Hong, Guohao Dai, Jiaming Xu, Qiuli Mao, Xiuhong Li, Jun Liu, Kangdi Chen, Yuhan Dong,and Yu Wang. 2023a.FlashDecoding++:Faster Large Language Model Inference on GPUs.arXiv:2311.01282 [cs.LG]": "Sirui Hong, Xiawu Zheng, Jonathan Chen, Yuheng Cheng, Jinlin Wang, Ceyao Zhang, Zili Wang, StevenKa Shing Yau, Zijuan Lin, Liyang Zhou, et al. 2023b.Metagpt: Meta programming for multi-agentcollaborative framework. arXiv preprint arXiv:2308.00352 (2023). Zhi Hong, Aswathy Ajith, Gregory Pauloski, Eamon Duede, Carl Malamud, Roger Magoulas, Kyle Chard,and Ian Foster. 2022. ScholarBERT: bigger is not always better. arXiv preprint arXiv:2205.11342 (2022). Eric Horvitz. 1999. Principles of mixed-initiative user interfaces. In Proceedings of the SIGCHI conferenceon Human Factors in Computing Systems (CHI 99). Association for Computing Machinery, New York,NY, USA, 159166. Neil Houlsby, Andrei Giurgiu, Stanislaw Jastrzebski, Bruna Morrone, Quentin De Laroussilhe, Andrea Ges-mundo, Mona Attariyan, and Sylvain Gelly. 2019. Parameter-efficient transfer learning for NLP. In Inter-national conference on machine learning. PMLR, 27902799. Dirk Hovy and Shannon L. Spruit. 2016. The Social Impact of Natural Language Processing. In Proceedingsof the 54th Annual Meeting of the Association for Computational Linguistics (Volume 2: Short Papers),Katrin Erk and Noah A. Smith (Eds.). Association for Computational Linguistics, Berlin, Germany, 591598. Cheng-Yu Hsieh, Chun-Liang Li, Chih-Kuan Yeh, Hootan Nakhost, Yasuhisa Fujii, Alexander Ratner, Ran-jay Krishna, Chen-Yu Lee, and Tomas Pfister. 2023. Distilling step-by-step! outperforming larger languagemodels with less training data and smaller model sizes. arXiv preprint arXiv:2305.02301 (2023). Edward J Hu, Yelong Shen, Phillip Wallis, Zeyuan Allen-Zhu, Yuanzhi Li, Shean Wang, Lu Wang, andWeizhu Chen. 2021. Lora: Low-rank adaptation of large language models. arXiv preprint arXiv:2106.09685(2021).",
  "Jie Huang and Kevin Chen-Chuan Chang. 2022. Towards reasoning in large language models: A survey.arXiv preprint arXiv:2212.10403 (2022)": "Jen-tse Huang, Wenxuan Wang, Man Ho Lam, Eric John Li, Wenxiang Jiao, and Michael R Lyu. 2023c.ChatGPT an ENFJ, Bard an ISTJ: Empirical Study on Personalities of Large Language Models. arXivpreprint arXiv:2305.19926 (2023). Rongjie Huang, Mingze Li, Dongchao Yang, Jiatong Shi, Xuankai Chang, Zhenhui Ye, Yuning Wu, ZhiqingHong, Jiawei Huang, Jinglin Liu, et al. 2023b. Audiogpt: Understanding and generating speech, music,sound, and talking head. arXiv preprint arXiv:2304.12995 (2023). Siyuan Huang, Zhengkai Jiang, Hao Dong, Yu Qiao, Peng Gao, and Hongsheng Li. 2023a. Instruct2Act:Mapping Multi-modality Instructions to Robotic Actions with Large Language Model. arXiv preprintarXiv:2305.11176 (2023). Wenlong Huang, Chen Wang, Ruohan Zhang, Yunzhu Li, Jiajun Wu, and Li Fei-Fei. 2023d. Voxposer: Com-posable 3d value maps for robotic manipulation with language models. arXiv preprint arXiv:2307.05973(2023). Wenlong Huang, Fei Xia, Ted Xiao, Harris Chan, Jacky Liang, Pete Florence, Andy Zeng, Jonathan Tomp-son, Igor Mordatch, Yevgen Chebotar, et al. 2022b.Inner monologue: Embodied reasoning throughplanning with language models. arXiv preprint arXiv:2207.05608 (2022). Yukun Huang, Yanda Chen, Zhou Yu, and Kathleen McKeown. 2022a. In-context Learning Distillation:Transferring Few-shot Learning Ability of Pre-trained Language Models. arXiv preprint arXiv:2212.10670(2022). Yanping Huang, Youlong Cheng, Ankur Bapna, Orhan Firat, Mia Xu Chen, Dehao Chen, HyoukJoong Lee,Jiquan Ngiam, Quoc V. Le, Yonghui Wu, and Zhifeng Chen. 2019. GPipe: Efficient Training of GiantNeural Networks using Pipeline Parallelism. arXiv:1811.06965 [cs.CV]",
  "Brett W Israelsen. 2019.Algorithmic assurances and self-assessment of competency boundaries in au-tonomous systems. Ph. D. Dissertation. University of Colorado at Boulder": "Adrien Jauffret, Marwen Belkaid, Nicolas Cuperlier, Philippe Gaussier, and Philippe Tarroux. 2013a. Frus-tration as a way toward autonomy and self-improvement in robotic navigation. In 2013 IEEE Third JointInternational Conference on Development and Learning and Epigenetic Robotics (ICDL). IEEE, 17. Adrien Jauffret, Nicolas Cuperlier, Philippe Tarroux, and Philippe Gaussier. 2013b. From self-assessment tofrustration, a small step toward autonomy in robotic navigation. Frontiers in neurorobotics 7 (2013), 16. Mojan Javaheripi, Sbastien Bubeck, Marah Abdin, Jyoti Aneja, Sebastien Bubeck, Caio Csar TeodoroMendes, Weizhu Chen, Allie Del Giorno, Ronen Eldan, Sivakanth Gopi, et al. 2023. Phi-2: The surprisingpower of small language models. Microsoft Research Blog (2023). Kunal Jha, Tuan Anh Le, Chuanyang Jin, Yen-Ling Kuo, Joshua B Tenenbaum, and Tianmin Shu. 2024.Neural amortized inference for nested multi-agent reasoning. In Proceedings of the AAAI Conference onArtificial Intelligence, Vol. 38. 530537. Jiaming Ji, Boyuan Chen, Hantao Lou, Donghai Hong, Borong Zhang, Xuehai Pan, Juntao Dai, and YaodongYang. 2024. Aligner: Achieving efficient alignment through weak-to-strong correction. arXiv preprintarXiv:2402.02416 (2024). Jiaming Ji, Tianyi Qiu, Boyuan Chen, Borong Zhang, Hantao Lou, Kaile Wang, Yawen Duan, ZhonghaoHe, Jiayi Zhou, Zhaowei Zhang, et al. 2023b. Ai alignment: A comprehensive survey. arXiv preprintarXiv:2310.19852 (2023). Ziwei Ji, Nayeon Lee, Rita Frieske, Tiezheng Yu, Dan Su, Yan Xu, Etsuko Ishii, Ye Jin Bang, AndreaMadotto, and Pascale Fung. 2023a. Survey of hallucination in natural language generation. Comput.Surveys 55, 12 (2023), 138. Ruoxi Jia, David Dao, Boxin Wang, Frances Ann Hubis, Nick Hynes, Nezihe Merve Grel, Bo Li, Ce Zhang,Dawn Song, and Costas J. Spanos. 2019. Towards Efficient Data Valuation Based on the Shapley Value.In Proceedings of the Twenty-Second International Conference on Artificial Intelligence and Statistics(Proceedings of Machine Learning Research, Vol. 89), Kamalika Chaudhuri and Masashi Sugiyama (Eds.).PMLR, 11671176.",
  "Anji Khalifa, Gamaleldin Elsayed, Minsu Baek, Noam Shazeer, and Natalia Neverova. 2022.DreamIX:DreamFusion via Iterative Spatiotemporal Mixing. arXiv preprint arXiv:2212.04508 (2022)": "Omar Khattab, Keshav Santhanam, Xiang Lisa Li, David Hall, Percy Liang, Christopher Potts, and MateiZaharia. 2022. Demonstrate-Search-Predict: Composing Retrieval and Language Models for Knowledge-Intensive NLP. arXiv preprint arXiv:2212.14024 (2022). Omar Khattab, Arnav Singhvi, Paridhi Maheshwari, Zhiyuan Zhang, Keshav Santhanam, Sri Vardhamanan,Saiful Haq, Ashutosh Sharma, Thomas T. Joshi, Hanna Moazam, Heather Miller, Matei Zaharia, andChristopher Potts. 2023.DSPy:Compiling Declarative Language Model Calls into Self-ImprovingPipelines. arXiv preprint arXiv:2310.03714 (2023). Alexander Khazatsky, Karl Pertsch, Suraj Nair, Ashwin Balakrishna, Sudeep Dasari, Siddharth Karamcheti,Soroush Nasiriany, Mohan Kumar Srirama, Lawrence Yunliang Chen, Kirsty Ellis, Peter David Fagan,Joey Hejna, Masha Itkina, Marion Lepert, Yecheng Jason Ma, Patrick Tree Miller, Jimmy Wu, SuneelBelkhale, Shivin Dass, Huy Ha, Arhan Jain, Abraham Lee, Youngwoon Lee, Marius Memmel, SungjaePark, Ilija Radosavovic, Kaiyuan Wang, Albert Zhan, Kevin Black, Cheng Chi, Kyle Beltran Hatch, Shan",
  "Eldar Kurtic, Elias Frantar, and Dan Alistarh. 2023. ZipLM: Inference-Aware Structured Pruning of Lan-guage Models. arXiv:2302.04089 [cs.LG]": "Tom Kwiatkowski, Jennimaria Palomaki, Olivia Redfield, Michael Collins, Ankur Parikh, Chris Alberti,Danielle Epstein, Illia Polosukhin, Jacob Devlin, Kenton Lee, Kristina Toutanova, Llion Jones, MatthewKelcey, Ming-Wei Chang, Andrew M. Dai, Jakob Uszkoreit, Quoc Le, and Slav Petrov. 2019. Natural Ques-tions: A Benchmark for Question Answering Research. Transactions of the Association for ComputationalLinguistics 7 (2019), 452466.",
  "Minae Kwon, Sang Michael Xie, Kalesha Bullard, and Dorsa Sadigh. 2023b. Reward design with languagemodels. arXiv preprint arXiv:2303.00001 (2023)": "Woosuk Kwon, Zhuohan Li, Siyuan Zhuang, Ying Sheng, Lianmin Zheng, Cody Hao Yu, Joseph E. Gonzalez,Hao Zhang, and Ion Stoica. 2023a. Efficient Memory Management for Large Language Model Serving withPagedAttention. arXiv:2309.06180 [cs.LG] Yuhang Lai, Chengxi Li, Yiming Wang, Tianyi Zhang, Ruiqi Zhong, Luke Zettlemoyer, Scott Wen tau Yih,Daniel Fried, Sida Wang, and Tao Yu. 2022. DS-1000: A Natural and Reliable Benchmark for Data ScienceCode Generation. arXiv:2211.11501 [cs.SE]",
  "Lambda. 2023. OpenAIs GPT-3 Language Model: A Technical Overview": "Angela Langdon, Matthew Botvinick, Hiroyuki Nakahara, Keiji Tanaka, Masayuki Matsumoto, and RyotaKanai. 2022. Meta-learning, social cognition and consciousness in brains and machines. Neural Networks145 (2022), 8089. Hugo Laurenon, Lucile Saulnier, Lo Tronchon, Stas Bekman, Amanpreet Singh, Anton Lozhkov, ThomasWang, Siddharth Karamcheti, Alexander Rush, Douwe Kiela, et al. 2024. Obelics: An open web-scalefiltered dataset of interleaved image-text documents. Advances in Neural Information Processing Systems36 (2024).",
  "Hao-Ping Lee, Yu-Ju Yang, Thomas Serban von Davier, Jodi Forlizzi, and Sauvik Das. 2024c. Deepfakes,Phrenology, Surveillance, and More! A Taxonomy of AI Privacy Risks. arXiv:2310.07879 [cs]": "Mina Lee, Katy Ilonka Gero, John Joon Young Chung, Simon Buckingham Shum, Vipul Raheja, Hua Shen,Subhashini Venugopalan, Thiemo Wambsganss, David Zhou, Emad A. Alghamdi, Tal August, AvinashBhat, Madiha Zahrah Choksi, Senjuti Dutta, Jin L. C. Guo, Md Naimul Hoque, Yewon Kim, Seyed ParsaNeshaei, Agnia Sergeyuk, Antonette Shibani, Disha Shrivastava, Lila Shroff, Jessi Stark, Sarah Sterman,Sitong Wang, Antoine Bosselut, Daniel Buschek, Joseph Chee Chang, Sherol Chen, Max Kreminski,Joonsuk Park, Roy Pea, Eugenia H. Rho, Shannon Zejiang Shen, and Pao Siangliulue. 2024a. A DesignSpace for Intelligent and Interactive Writing Assistants. [cs]. Mina Lee, Percy Liang, and Qian Yang. 2022. CoAuthor: Designing a Human-AI Collaborative WritingDataset for Exploring Language Model Capabilities. In CHI Conference on Human Factors in ComputingSystems. 119. arXiv:2201.06796 [cs].",
  "SamLevin.2017.NewAIcanguesswhetheryouregayorstraightfromaphoto-graph.The Guardian (Sept. 2017)": "Patrick Lewis, Ethan Perez, Aleksandra Piktus, Fabio Petroni, Vladimir Karpukhin, Naman Goyal, HeinrichKttler, Mike Lewis, Wen-tau Yih, Tim Rocktschel, et al. 2020. Retrieval-augmented generation forknowledge-intensive nlp tasks. Advances in Neural Information Processing Systems 33 (2020), 94599474. Aitor Lewkowycz, Anders Andreassen, David Dohan, Ethan Dyer, Henryk Michalewski, Vinay Ramasesh,Ambrose Slone, Cem Anil, Imanol Schlag, Theo Gutman-Solo, et al. 2022. Solving quantitative reasoningproblems with language models. arXiv preprint arXiv:2206.14858 (2022).",
  "Bo Li, Yuanhan Zhang, Liangyu Chen, Jinghao Wang, Jingkang Yang, and Ziwei Liu. 2023l. Otter: Amulti-modal model with in-context instruction tuning. arXiv preprint arXiv:2305.03726 (2023)": "Chengshu Li, Ruohan Zhang, Josiah Wong, Cem Gokmen, Sanjana Srivastava, Roberto Martn-Martn, ChenWang, Gabrael Levine, Wensi Ai, Benjamin Martinez, Hang Yin, Michael Lingelbach, Minjune Hwang,Ayano Hiranaka, Sujay Garlanka, Arman Aydin, Sharon Lee, Jiankai Sun, Mona Anvari, Manasi Sharma,Dhruva Bansal, Samuel Hunter, Kyu-Young Kim, Alan Lou, Caleb R Matthews, Ivan Villa-Renteria,Jerry Huayang Tang, Claire Tang, Fei Xia, Yunzhu Li, Silvio Savarese, Hyowon Gweon, C. Karen Liu,Jiajun Wu, and Li Fei-Fei. 2024f. BEHAVIOR-1K: A Human-Centered, Embodied AI Benchmark with1,000 Everyday Activities and Realistic Simulation. arXiv:2403.09227 [cs.RO] Guohao Li, Hasan Abed Al Kader Hammoud, Hani Itani, Dmitrii Khizbullin, and Bernard Ghanem. 2023e.Camel: Communicative agents for\" mind\" exploration of large scale language model society. arXiv preprintarXiv:2303.17760 (2023). Hanzhou Li, John T Moon, Saptarshi Purkayastha, Leo Anthony Celi, Hari Trivedi, and Judy W Gichoya.2023i. Ethics of large language models in medicine and medical research. The Lancet Digital Health 5, 6(2023), e333e335. Jinyang Li, Binyuan Hui, Ge Qu, Jiaxi Yang, Binhua Li, Bowen Li, Bailin Wang, Bowen Qin, Ruiying Geng,Nan Huo, et al. 2024b. Can llm already serve as a database interface? a big bench for large-scale databasegrounded text-to-sqls. Advances in Neural Information Processing Systems 36 (2024).",
  "KunChang Li, Yinan He, Yi Wang, Yizhuo Li, Wenhai Wang, Ping Luo, Yali Wang, Limin Wang, and YuQiao. 2023f. Videochat: Chat-centric video understanding. arXiv preprint arXiv:2305.06355 (2023)": "Lei Li, Zhihui Xie, Mukai Li, Shunian Chen, Peiyi Wang, Liang Chen, Yazheng Yang, Benyou Wang, andLingpeng Kong. 2023j. Silkie: Preference distillation for large visual language models. arXiv preprintarXiv:2312.10665 (2023). Liunian Harold Li, Jack Hessel, Youngjae Yu, Xiang Ren, Kai-Wei Chang, and Yejin Choi. 2023g. Symbolicchain-of-thought distillation: Small models can also\" think\" step-by-step. arXiv preprint arXiv:2306.14050(2023). Muyang Li, Tianle Cai, Jiaxin Cao, Qinsheng Zhang, Han Cai, Junjie Bai, Yangqing Jia, Ming-Yu Liu,Kai Li, and Song Han. 2024a. DistriFusion: Distributed Parallel Inference for High-Resolution DiffusionModels. arXiv:2402.19481 [cs.CV]",
  "Ming Li, Lichang Chen, Jiuhai Chen, Shwai He, Heng Huang, Jiuxiang Gu, and Tianyi Zhou. 2023c.Reflection-tuning:Data recycling improves llm instruction-tuning.arXiv preprint arXiv:2310.11716(2023)": "Raymond Li, Loubna Ben Allal, Yangtian Zi, Niklas Muennighoff, Denis Kocetkov, Chenghao Mou, MarcMarone, Christopher Akiki, Jia Li, Jenny Chim, Qian Liu, Evgenii Zheltonozhskii, Terry Yue Zhuo,Thomas Wang, Olivier Dehaene, Mishig Davaadorj, Joel Lamy-Poirier, Joo Monteiro, Oleh Shliazhko,Nicolas Gontier, Nicholas Meade, Armel Zebaze, Ming-Ho Yee, Logesh Kumar Umapathi, Jian Zhu, Ben-jamin Lipkin, Muhtasham Oblokulov, Zhiruo Wang, Rudra Murthy, Jason Stillerman, Siva Sankalp Patel,Dmitry Abulkhanov, Marco Zocca, Manan Dey, Zhihan Zhang, Nour Fahmy, Urvashi Bhattacharyya,Wenhao Yu, Swayam Singh, Sasha Luccioni, Paulo Villegas, Maxim Kunakov, Fedor Zhdanov, ManuelRomero, Tony Lee, Nadav Timor, Jennifer Ding, Claire Schlesinger, Hailey Schoelkopf, Jan Ebert, TriDao, Mayank Mishra, Alex Gu, Jennifer Robinson, Carolyn Jane Anderson, Brendan Dolan-Gavitt, Dan-ish Contractor, Siva Reddy, Daniel Fried, Dzmitry Bahdanau, Yacine Jernite, Carlos Muoz Ferrandis,Sean Hughes, Thomas Wolf, Arjun Guha, Leandro von Werra, and Harm de Vries. 2023a. StarCoder: maythe source be with you! arXiv:2305.06161 [cs.CL] Shiyang Li, Jianshu Chen, Yelong Shen, Zhiyu Chen, Xinlu Zhang, Zekun Li, Hong Wang, Jing Qian, BaolinPeng, Yi Mao, et al. 2022a. Explanations from large language models make small reasoners better. arXivpreprint arXiv:2210.06726 (2022).",
  "Yuanzhi Li, Sbastien Bubeck, Ronen Eldan, Allie Del Giorno, Suriya Gunasekar, and Yin Tat Lee. 2023b.Textbooks are all you need ii: phi-1.5 technical report. arXiv preprint arXiv:2309.05463 (2023)": "Yujia Li, David Choi, Junyoung Chung, Nate Kushman, Julian Schrittwieser, Rmi Leblond, Tom Ec-cles, James Keeling, Felix Gimeno, Agustin Dal Lago, Thomas Hubert, Peter Choy, Cyprien de Mas-son dAutume, Igor Babuschkin, Xinyun Chen, Po-Sen Huang, Johannes Welbl, Sven Gowal, AlexeyCherepanov, James Molloy, Daniel J. Mankowitz, Esme Sutherland Robson, Pushmeet Kohli, Nando deFreitas, Koray Kavukcuoglu, and Oriol Vinyals. 2022b. Competition-level code generation with Alpha-Code. Science 378, 6624 (Dec. 2022), 10921097.",
  "Q. Vera Liao and Jennifer Wortman Vaughan. 2023. AI Transparency in the Age of LLMs: A Human-Centered Research Roadmap. arXiv:2306.01941 [cs]": "Opher Lieber, Barak Lenz, Hofit Bata, Gal Cohen, Jhonathan Osin, Itay Dalmedigos, Erez Safahi, ShakedMeirom, Yonatan Belinkov, Shai Shalev-Shwartz, Omri Abend, Raz Alon, Tomer Asida, Amir Bergman,Roman Glozman, Michael Gokhman, Avashalom Manevich, Nir Ratner, Noam Rozen, Erez Shwartz,Mor Zusman, and Yoav Shoham. 2024.Jamba:A Hybrid Transformer-Mamba Language Model.arXiv:2403.19887 [cs.CL] Hunter Lightman, Vineet Kosaraju, Yura Burda, Harri Edwards, Bowen Baker, Teddy Lee, Jan Leike,John Schulman, Ilya Sutskever, and Karl Cobbe. 2023.Lets Verify Step by Step.arXiv preprintarXiv:2305.20050 (2023). Bin Lin, Tao Peng, Chen Zhang, Minmin Sun, Lanbo Li, Hanyu Zhao, Wencong Xiao, Qi Xu, Xiafei Qiu,Shen Li, Zhigang Ji, Yong Li, and Wei Lin. 2024a. Infinite-LLM: Efficient LLM Service for Long Contextwith DistAttention and Distributed KVCache. arXiv:2401.02669 [cs.DC] Bill Yuchen Lin, Abhilasha Ravichander, Ximing Lu, Nouha Dziri, Melanie Sclar, Khyathi Chandu, ChandraBhagavatula, and Yejin Choi. 2023b. The unlocking spell on base llms: Rethinking alignment via in-contextlearning. arXiv preprint arXiv:2312.01552 (2023). Ji Lin, Jiaming Tang, Haotian Tang, Shang Yang, Wei-Ming Chen, Wei-Chen Wang, Guangxuan Xiao,Xingyu Dang, Chuang Gan, and Song Han. 2024b. AWQ: Activation-aware Weight Quantization for LLMCompression and Acceleration. arXiv:2306.00978 [cs.CL]",
  "Ji Lin, Ligeng Zhu, Wei-Ming Chen, Wei-Chen Wang, Chuang Gan, and Song Han. 2024f.On-DeviceTraining Under 256KB Memory. arXiv:2206.15472 [cs.CV]": "Stephanie Lin, Jacob Hilton, and Owain Evans. 2022b. TruthfulQA: Measuring How Models Mimic HumanFalsehoods. In Proceedings of the 60th Annual Meeting of the Association for Computational Linguistics(Volume 1: Long Papers), Smaranda Muresan, Preslav Nakov, and Aline Villavicencio (Eds.). Associa-tion for Computational Linguistics, Dublin, Ireland, 32143252. Susan Lin, Jeremy Warner, J. D. Zamfirescu-Pereira, Matthew G. Lee, Sauhard Jain, Michael Xuelin Huang,Piyawat Lertvittayakumjorn, Shanqing Cai, Shumin Zhai, Bjrn Hartmann, and Can Liu. 2024d. Rambler:",
  "Yujun Lin, Haotian Tang, Shang Yang, Zhekai Zhang, Guangxuan Xiao, Chuang Gan, and SongHan. 2024c.QServe:W4A8KV4 Quantization and System Co-design for Efficient LLM Serving.arXiv:2405.04532 [cs.CL]": "ZemingLin,HalilAkin,RoshanRao,BrianHie,ZhongkaiZhu,WentingLu,AllandosSantosCosta,MaryamFazel-Zarandi,TomSercu,SalCandido,andAlexanderRives.2022a.Languagemodelsofproteinsequencesatthescaleofevolutionenableaccu-ratestructureprediction.bioRxiv(2022). Ziyi Lin, Chris Liu, Renrui Zhang, Peng Gao, Longtian Qiu, Han Xiao, Han Qiu, Chen Lin, Wenqi Shao, Ke-qin Chen, Jiaming Han, Siyuan Huang, Yichi Zhang, Xuming He, Hongsheng Li, and Yu Jiao Qiao. 2023a.SPHINX: The Joint Mixing of Weights, Tasks, and Visual Embeddings for Multi-modal Large LanguageModels. ArXiv abs/2311.07575 (2023). Alisa Liu, Zhaofeng Wu, Julian Michael, Alane Suhr, Peter West, Alexander Koller, Swabha Swayamdipta,Noah A Smith, and Yejin Choi. 2023h. Were Afraid Language Models Arent Modeling Ambiguity. arXivpreprint arXiv:2304.14399 (2023). Bo Liu, Yuqian Jiang, Xiaohan Zhang, Qiang Liu, Shiqi Zhang, Joydeep Biswas, and Peter Stone.2023b. Llm+ p: Empowering large language models with optimal planning proficiency. arXiv preprintarXiv:2304.11477 (2023).",
  "Jingyu Liu, Wenhan Xiong, Ian Jones, Yixin Nie, Anchit Gupta, and Barlas Ouz. 2023i. CLIP-Layout:Style-Consistent Indoor Scene Synthesis with Semantic Furniture Embedding. arXiv:2303.03565 [cs.CV]": "Ruibo Liu, Chenyan Jia, Ge Zhang, Ziyu Zhuang, Tony Liu, and Soroush Vosoughi. 2022a. Second thoughtsare best: Learning to re-align with human values from text edits. Advances in Neural Information Pro-cessing Systems 35 (2022), 181196. Ruibo Liu, Jerry Wei, Fangyu Liu, Chenglei Si, Yanzhe Zhang, Jinmeng Rao, Steven Zheng, Daiyi Peng,Diyi Yang, Denny Zhou, et al. 2024a. Best Practices and Lessons Learned on Synthetic Data for LanguageModels. arXiv preprint arXiv:2404.07503 (2024).",
  "Zhenyi Lu, Chenghao Fan, Wei Wei, Xiaoye Qu, Dangyang Chen, and Yu Cheng. 2024. Twin-merging:Dynamic integration of modular expertise in model merging. arXiv preprint arXiv:2406.15479 (2024)": "Gen Luo, Yiyi Zhou, Tianhe Ren, Shengxin Chen, Xiaoshuai Sun, and Rongrong Ji. 2023. Cheap and quick:Efficient vision-language instruction tuning for large language models. arXiv preprint arXiv:2305.15023(2023). Renqian Luo, Liai Sun, Yingce Xia, Tao Qin, Sheng Zhang, Hoifung Poon, and Tie-Yan Liu. 2022. BioGPT:generative pre-trained transformer for biomedical text generation and mining. Briefings in bioinformatics23, 6 (2022), bbac409. Chenyang Lyu, Minghao Wu, Longyue Wang, Xinting Huang, Bingshuai Liu, Zefeng Du, Shuming Shi, andZhaopeng Tu. 2023. Macaw-LLM: Multi-Modal Language Modeling with Image, Audio, Video, and TextIntegration. arXiv preprint arXiv:2306.09093 (2023).",
  "Qing Lyu, Marianna Apidianaki, and Chris Callison-Burch. 2024. Towards Faithful Model Explanation inNLP: A Survey. arXiv:2209.11326 [cs]": "Weiyu Ma, Qirui Mi, Xue Yan, Yuqiao Wu, Runji Lin, Haifeng Zhang, and Jun Wang. 2023b.Largelanguage models play starcraft ii: Benchmarks and a chain of summarization approach. arXiv preprintarXiv:2312.11865 (2023). Yecheng Jason Ma, William Liang, Guanzhi Wang, De-An Huang, Osbert Bastani, Dinesh Jayaraman, YukeZhu, Linxi Fan, and Anima Anandkumar. 2023a. Eureka: Human-Level Reward Design via Coding LargeLanguage Models. arXiv:2310.12931 [cs.RO]",
  "Kai Mei, Zelong Li, Shuyuan Xu, Ruosong Ye, Yingqiang Ge, and Yongfeng Zhang. 2024. AIOS: LLM AgentOperating System. arXiv:2403.16971 [cs.OS]": "Bahar Memarian and Tenzin Doleck. 2023.Fairness, Accountability, Transparency, and Ethics (FATE)in Artificial Intelligence (AI), and higher education: A systematic review. Computers and Education:Artificial Intelligence (2023), 100152. Chenlin Meng, Yutong He, Yang Song, Jiaming Song, Jiajun Wu, Jun-Yan Zhu, and Stefano Ermon.2021. Sdedit: Guided image synthesis and editing with stochastic differential equations. arXiv preprintarXiv:2108.01073 (2021).",
  "Grgoire Mialon, Clmentine Fourrier, Craig Swift, Thomas Wolf, Yann LeCun, and Thomas Scialom. 2023.GAIA: a benchmark for General AI Assistants. arXiv:2311.12983 [cs.CL]": "Xupeng Miao, Gabriele Oliaro, Zhihao Zhang, Xinhao Cheng, Hongyi Jin, Tianqi Chen, and Zhihao Jia.2023. Towards Efficient Generative Large Language Model Serving: A Survey from Algorithms to Systems.arXiv:2312.15234 [cs.LG] Xupeng Miao, Gabriele Oliaro, Zhihao Zhang, Xinhao Cheng, Zeyu Wang, Zhengxin Zhang, Rae Ying YeeWong, Alan Zhu, Lijie Yang, Xiaoxiang Shi, Chunan Shi, Zhuoming Chen, Daiyaan Arfeen, Reyna Ab-hyankar, and Zhihao Jia. 2024. SpecInfer: Accelerating Generative Large Language Model Serving withTree-based Speculative Inference and Verification. arXiv:2305.09781 [cs.CL]",
  "William Muldrew, Peter Hayes, Mingtian Zhang, and David Barber. 2024. Active Preference Learning forLarge Language Models. arXiv preprint arXiv:2402.08114 (2024)": "Rmi Munos, Michal Valko, Daniele Calandriello, Mohammad Gheshlaghi Azar, Mark Rowland, Zhao-han Daniel Guo, Yunhao Tang, Matthieu Geist, Thomas Mesnard, Andrea Michi, et al. 2023.Nashlearning from human feedback. arXiv preprint arXiv:2312.00886 (2023). Vijayaraghavan Murali, Chandra Maddila, Imad Ahmad, Michael Bolin, Daniel Cheng, Negar Ghorbani,Renuka Fernandez, Nachiappan Nagappan, and Peter C. Rigby. 2024. AI-assisted Code Authoring atScale: Fine-tuning, deploying, and mixed methods evaluation. arXiv:2305.12050 [cs.SE]",
  "NVIDIA. 2023b. TensorRT-LLM: A TensorRT Toolbox for Optimized Large Language Model Inference": "Maxwell Nye, Anders Johan Andreassen, Guy Gur-Ari, Henryk Michalewski, Jacob Austin, David Bieber,David Dohan, Aitor Lewkowycz, Maarten Bosma, David Luan, et al. 2021. Show your work: Scratchpadsfor intermediate computation with language models. arXiv preprint arXiv:2112.00114 (2021). Changhoon Oh, Jungwoo Song, Jinhan Choi, Seonghyeon Kim, Sungwoo Lee, and Bongwon Suh. 2018.I Lead, You Help but Only with Enough Details: Understanding User Experience of Co-Creation withArtificial Intelligence. In Proceedings of the 2018 CHI Conference on Human Factors in Computing Systems(CHI 18). Association for Computing Machinery, New York, NY, USA, 113.",
  "OpenAI. 2024. Hello GPT-4o": "Long Ouyang, Jeffrey Wu, Xu Jiang, Diogo Almeida, Carroll Wainwright, Pamela Mishkin, Chong Zhang,Sandhini Agarwal, Katarina Slama, Alex Ray, et al. 2022. Training language models to follow instructionswith human feedback. Advances in neural information processing systems 35 (2022), 2773027744. Alize Pace, Jonathan Mallinson, Eric Malmi, Sebastian Krause, and Aliaksei Severyn. 2024. West-of-n:Synthetic preference generation for improved reward modeling. arXiv preprint arXiv:2401.12086 (2024). Liangming Pan, Alon Albalak, Xinyi Wang, and William Yang Wang. 2023. Logic-lm: Empowering largelanguage models with symbolic solvers for faithful logical reasoning. arXiv preprint arXiv:2305.12295(2023). Joon Sung Park, Joseph C OBrien, Carrie J Cai, Meredith Ringel Morris, Percy Liang, and Michael S Bern-stein. 2023. Generative agents: Interactive simulacra of human behavior. arXiv preprint arXiv:2304.03442(2023).",
  "William Peebles and Saining Xie. 2023. Scalable diffusion models with transformers. In Proceedings of theIEEE/CVF International Conference on Computer Vision. 41954205": "Bo Peng, Eric Alcaide, Quentin Anthony, Alon Albalak, Samuel Arcadinho, Huanqi Cao, Xin Cheng, MichaelChung, Matteo Grella, Kranthi Kiran GV, et al. 2023a. Rwkv: Reinventing rnns for the transformer era.arXiv preprint arXiv:2305.13048 (2023). Bo Peng, Daniel Goldstein, Quentin Anthony, Alon Albalak, Eric Alcaide, Stella Biderman, Eugene Cheah,Teddy Ferdinan, Haowen Hou, Przemysaw Kazienko, Kranthi Kiran GV, Jan Koco, Bartomiej Koptyra,Satyapriya Krishna, Ronald McClelland Jr. au2, Niklas Muennighoff, Fares Obeid, Atsushi Saito, GuangyuSong, Haoqin Tu, Stanisaw Woniak, Ruichong Zhang, Bingchen Zhao, Qihang Zhao, Peng Zhou, JianZhu, and Rui-Jie Zhu. 2024a. Eagle and Finch: RWKV with Matrix-Valued States and Dynamic Recur-rence. arXiv:2404.05892 [cs.CL]",
  "Baolin Peng, Chunyuan Li, Pengcheng He, Michel Galley, and Jianfeng Gao. 2023b. Instruction Tuning withGPT-4. arXiv:2304.03277 [cs.CL]": "Yujia Peng, Jiaheng Han, Zhenliang Zhang, Lifeng Fan, Tengyu Liu, Siyuan Qi, Xue Feng, Yuxi Ma, YizhouWang, and Song-Chun Zhu. 2024b.The tong test: Evaluating artificial general intelligence throughdynamic embodied physical and social interactions. Engineering 34 (2024), 1222. Michael Poli, Stefano Massaroli, Eric Nguyen, Daniel Y. Fu, Tri Dao, Stephen Baccus, Yoshua Bengio,Stefano Ermon, and Christopher R. 2023. Hyena Hierarchy: Towards Larger Convolutional LanguageModels. arXiv:2302.10866 [cs.LG] Michael Poli, Armin W Thomas, Eric Nguyen, Pragaash Ponnusamy, Bjrn Deiseroth, Kristian Kersting,Taiji Suzuki, Brian Hie, Stefano Ermon, Christopher R, Ce Zhang, and Stefano Massaroli. 2024. Mecha-nistic Design and Scaling of Hybrid Architectures. arXiv:2403.17844 [cs.LG]",
  "Stanislas Polu and Ilya Sutskever. 2022. Formal mathematics statement curriculum learning. arXiv preprintarXiv:2202.01344 (2022)": "Reiner Pope, Sholto Douglas, Aakanksha Chowdhery, Jacob Devlin, James Bradbury, Anselm Levskaya,Jonathan Heek, Kefan Xiao, Shivani Agrawal, and Jeff Dean. 2022. Efficiently Scaling Transformer Infer-ence. arXiv:2211.05102 [cs.LG] Daniel Povey, Arnab Ghoshal, Gilles Boulianne, Lukas Burget, Ondrej Glembek, Nagendra Goel, Mirko Han-nemann, Petr Motlicek, Yanmin Qian, Petr Schwarz, et al. 2011. The Kaldi speech recognition toolkit. InIEEE 2011 workshop on automatic speech recognition and understanding. IEEE Signal Processing Society.",
  "David Premack and Guy Woodruff. 1978. Does the chimpanzee have a theory of mind?Behavioral andbrain sciences 1, 4 (1978), 515526": "Xavier Puig, Tianmin Shu, Shuang Li, Zilin Wang, Yuan-Hong Liao, Joshua B Tenenbaum, Sanja Fidler, andAntonio Torralba. 2020. Watch-and-help: A challenge for social perception and human-ai collaboration.arXiv preprint arXiv:2010.09890 (2020). Mengnan Qi, Yufan Huang, Yongqiang Yao, Maoquan Wang, Bin Gu, and Neel Sundaresan. 2024.IsNext Token Prediction Sufficient for GPT? Exploration on Code Logic Comprehension. arXiv preprintarXiv:2404.08885 (2024). Xiangyu Qi, Kaixuan Huang, Ashwinee Panda, Mengdi Wang, and Prateek Mittal. 2023. Visual adver-sarial examples jailbreak aligned large language models. In The Second Workshop on New Frontiers inAdversarial Machine Learning, Vol. 1.",
  "Chen Qian, Xin Cong, Cheng Yang, Weize Chen, Yusheng Su, Juyuan Xu, Zhiyuan Liu, and Maosong Sun.2023a. Communicative agents for software development. arXiv preprint arXiv:2307.07924 (2023)": "Cheng Qian, Chi Han, Yi Fung, Yujia Qin, Zhiyuan Liu, and Heng Ji. 2023b. CREATOR: Tool Creation forDisentangling Abstract and Concrete Reasoning of Large Language Models. In Findings of the Associationfor Computational Linguistics: EMNLP 2023, Houda Bouamor, Juan Pino, and Kalika Bali (Eds.). As-sociation for Computational Linguistics, Singapore, 69226939. Cheng Qian, Chi Han, Yi R Fung, Yujia Qin, Zhiyuan Liu, and Heng Ji. 2023c.Creator: Disentan-gling abstract and concrete reasonings of large language models through tool creation. arXiv preprintarXiv:2305.14318 (2023).",
  "Aurko Roy, Mohammad Saffar, Ashish Vaswani, and David Grangier. 2020. Efficient Content-Based SparseAttention with Routing Transformers. arXiv:2003.05997 [cs.LG]": "Baptiste Rozire, Jonas Gehring, Fabian Gloeckle, Sten Sootla, Itai Gat, Xiaoqing Ellen Tan, Yossi Adi,Jingyu Liu, Romain Sauvestre, Tal Remez, Jrmy Rapin, Artyom Kozhevnikov, Ivan Evtimov, JoannaBitton, Manish Bhatt, Cristian Canton Ferrer, Aaron Grattafiori, Wenhan Xiong, Alexandre Dfossez,Jade Copet, Faisal Azhar, Hugo Touvron, Louis Martin, Nicolas Usunier, Thomas Scialom, and GabrielSynnaeve. 2024. Code Llama: Open Foundation Models for Code. arXiv:2308.12950 [cs.CL]",
  "Aishwarya P S, Pranav Ajit Nair, Yashas Samaga, Toby Boyd, Sanjiv Kumar, Prateek Jain, and PraneethNetrapalli. 2024. Tandem Transformers for Inference Efficient LLMs. arXiv:2402.08644 [cs.AI]": "Chitwan Saharia, William Chan, Huiwen Chang, Chris Lee, Jonathan Ho, Tim Salimans, David Fleet,and Mohammad Norouzi. 2022. Palette: Image-to-image diffusion models. In ACM SIGGRAPH 2022conference proceedings. 110. Shibani Santurkar, Esin Durmus, Faisal Ladhak, Cinoo Lee, Percy Liang, and Tatsunori Hashimoto. 2023.Whose opinions do language models reflect?. In International Conference on Machine Learning. PMLR,2997130004.",
  "Brian Scassellati. 2002. Theory of mind for a humanoid robot. Autonomous Robots 12 (2002), 1324": "Jrmy Scheurer, Jon Ander Campos, Tomasz Korbak, Jun Shern Chan, Angelica Chen, Kyunghyun Cho,and Ethan Perez. 2023.Training language models with language feedback at scale.arXiv preprintarXiv:2303.16755 (2023). Timo Schick, Jane Dwivedi-Yu, Roberto Dess, Roberta Raileanu, Maria Lomeli, Luke Zettlemoyer, NicolaCancedda, and Thomas Scialom. 2023. Toolformer: Language models can teach themselves to use tools.arXiv preprint arXiv:2302.04761 (2023).",
  "Murray Shanahan and Catherine Clarke. 2023. Evaluating Large Language Model Creativity from a LiteraryPerspective. arXiv preprint arXiv:2312.03746 (2023)": "Noam Shazeer, Azalia Mirhoseini, Krzysztof Maziarz, Andy Davis, Quoc Le, Geoffrey Hinton, and Jeff Dean.2017. Outrageously large neural networks: The sparsely-gated mixture-of-experts layer. arXiv preprintarXiv:1701.06538 (2017). Jia Tracy Shen, Michiharu Yamashita, Ethan Prihar, Neil Heffernan, Xintao Wu, Ben Graff, and DongwonLee. 2021. Mathbert: A pre-trained language model for general nlp tasks in mathematics education. arXivpreprint arXiv:2106.07340 (2021). Tianhao Shen, Renren Jin, Yufei Huang, Chuang Liu, Weilong Dong, Zishan Guo, Xinwei Wu, Yan Liu, andDeyi Xiong. 2023a. Large language model alignment: A survey. arXiv preprint arXiv:2309.15025 (2023). Yongliang Shen, Kaitao Song, Xu Tan, Dongsheng Li, Weiming Lu, and Yueting Zhuang. 2023b. Hugginggpt:Solving ai tasks with chatgpt and its friends in huggingface. arXiv preprint arXiv:2303.17580 (2023). Ying Sheng, Shiyi Cao, Dacheng Li, Coleman Hooper, Nicholas Lee, Shuo Yang, Christopher Chou, BanghuaZhu, Lianmin Zheng, Kurt Keutzer, Joseph E. Gonzalez, and Ion Stoica. 2023a. S-LoRA: Serving Thou-sands of Concurrent LoRA Adapters. arXiv:2311.03285 [cs.LG] Ying Sheng, Lianmin Zheng, Binhang Yuan, Zhuohan Li, Max Ryabinin, Daniel Y. Fu, Zhiqiang Xie,Beidi Chen, Clark Barrett, Joseph E. Gonzalez, Percy Liang, Christopher R, Ion Stoica, and Ce Zhang.2023b. FlexGen: High-Throughput Generative Inference of Large Language Models with a Single GPU.arXiv:2303.06865 [cs.LG]",
  "Kurt Shuster, Spencer Poff, Moya Chen, Douwe Kiela, and Jason Weston. 2021. Retrieval augmentationreduces hallucination in conversation. arXiv preprint arXiv:2104.07567 (2021)": "David Silver, Aja Huang, Chris J Maddison, Arthur Guez, Laurent Sifre, George Van Den Driessche, JulianSchrittwieser, Ioannis Antonoglou, Veda Panneershelvam, Marc Lanctot, et al. 2016. Mastering the gameof Go with deep neural networks and tree search. nature 529, 7587 (2016), 484489. David Silver, Julian Schrittwieser, Karen Simonyan, Ioannis Antonoglou, Aja Huang, Arthur Guez, ThomasHubert, Lucas Baker, Matthew Lai, Adrian Bolton, et al. 2017. Mastering the game of go without humanknowledge. nature 550, 7676 (2017), 354359. Ishika Singh, Valts Blukis, Arsalan Mousavian, Ankit Goyal, Danfei Xu, Jonathan Tremblay, Dieter Fox,Jesse Thomason, and Animesh Garg. 2023. Progprompt: Generating situated robot task plans using largelanguage models. In 2023 IEEE International Conference on Robotics and Automation (ICRA). IEEE,1152311530.",
  "Yang Song and Stefano Ermon. 2019. Generative modeling by estimating gradients of the data distribution.Advances in neural information processing systems 32 (2019)": "Yang Song, Jascha Sohl-Dickstein, Diederik P Kingma, Abhishek Kumar, Stefano Ermon, and BenPoole. 2020. Score-based generative modeling through stochastic differential equations. arXiv preprintarXiv:2011.13456 (2020). Aarohi Srivastava, Abhinav Rastogi, Abhishek Rao, Abu Awal Md Shoeb, Abubakar Abid, Adam Fisch,Adam R Brown, Adam Santoro, Aditya Gupta, Adri Garriga-Alonso, et al. 2022. Beyond the imitationgame: Quantifying and extrapolating the capabilities of language models. arXiv preprint arXiv:2206.04615(2022).",
  "Adarsh Subbaswamy, Roy Adams, and Suchi Saria. 2021. Evaluating model robustness and stability todataset shift. In International conference on artificial intelligence and statistics. PMLR, 26112619": "Sangho Suh, Meng Chen, Bryan Min, Toby Jia-Jun Li, and Haijun Xia. 2024.Luminate: StructuredGeneration and Exploration of Design Space with Large Language Models for Human-AI Co-Creation. arXiv:2310.12953 [cs]. Sangho Suh, Bryan Min, Srishti Palani, and Haijun Xia. 2023. Sensecape: Enabling Multilevel Explorationand Sensemaking with Large Language Models. In Proceedings of the 36th Annual ACM Symposium onUser Interface Software and Technology (UIST 23). Association for Computing Machinery, New York,NY, USA, 118.",
  "Yi-Lin Sung, Linjie Li, Kevin Lin, Zhe Gan, Mohit Bansal, and Lijuan Wang. 2023. An Empirical Study ofMultimodal Model Merging. arXiv:2304.14933 [cs.CV]": "Harini Suresh, Steven R. Gomez, Kevin K. Nam, and Arvind Satyanarayan. 2021. Beyond Expertise andRoles: A Framework to Characterize the Stakeholders of Interpretable Machine Learning and their Needs.In Proceedings of the 2021 CHI Conference on Human Factors in Computing Systems (CHI 21). Asso-ciation for Computing Machinery, New York, NY, USA, 116.",
  "Alex Tamkin, Miles Brundage, Jack Clark, and Deep Ganguli. 2021.Understanding the Capabilities,Limitations, and Societal Impact of Large Language Models. [cs]": "Weihao Tan, Ziluo Ding, Wentao Zhang, Boyu Li, Bohan Zhou, Junpeng Yue, Haochong Xia, Jiechuan Jiang,Longtao Zheng, Xinrun Xu, et al. 2024. Towards general computer control: A multimodal agent for reddead redemption ii as a case study. arXiv preprint arXiv:2403.03186 (2024). Xiangru Tang, Anni Zou, Zhuosheng Zhang, Ziming Li, Yilun Zhao, Xingyao Zhang, Arman Cohan, andMark Gerstein. 2024b. MedAgents: Large Language Models as Collaborators for Zero-shot Medical Rea-soning. arXiv:2311.10537 [cs.CL] Yunhao Tang, Daniel Zhaohan Guo, Zeyu Zheng, Daniele Calandriello, Yuan Cao, Eugene Tarassov, RmiMunos, Bernardo vila Pires, Michal Valko, Yong Cheng, and Will Dabney. 2024a. Understanding theperformance gap between online and offline alignment algorithms. arXiv:2405.08448 [cs]. Zhenheng Tang, Yuxin Wang, Xin He, Longteng Zhang, Xinglin Pan, Qiang Wang, Rongfei Zeng, Kaiy-ong Zhao, Shaohuai Shi, Bingsheng He, and Xiaowen Chu. 2023. FusionAI: Decentralized Training andDeploying LLMs with Massive Consumer-Level GPUs. arXiv:2309.01172 [cs.DC]",
  "Yi Tay, Mostafa Dehghani, Dara Bahri, and Donald Metzler. 2022. Efficient transformers: A survey. Comput.Surveys 55, 6 (2022), 128": "Ross Taylor, Marcin Kardas, Guillem Cucurull, Thomas Scialom, Anthony Hartshorn, Elvis Saravia, AndrewPoulton, Viktor Kerkez, and Robert Stojnic. 2022. Galactica: A large language model for science. arXivpreprint arXiv:2211.09085 (2022). Gemini Team, Rohan Anil, Sebastian Borgeaud, Yonghui Wu, Jean-Baptiste Alayrac, Jiahui Yu, RaduSoricut, Johan Schalkwyk, Andrew M Dai, Anja Hauth, et al. 2023. Gemini: a family of highly capablemultimodal models. arXiv preprint arXiv:2312.11805 (2023).",
  "Keyu Tian, Yi Jiang, Zehuan Yuan, Bingyue Peng, and Liwei Wang. 2024a. Visual Autoregressive Modeling:Scalable Image Generation via Next-Scale Prediction": "Runchu Tian, Yining Ye, Yujia Qin, Xin Cong, Yankai Lin, Yinxu Pan, Yesai Wu, Zhiyuan Liu, andMaosong Sun. 2024b.DebugBench:Evaluating Debugging Capability of Large Language Models.arXiv:2401.04621 [cs.SE] Philippe Tillet, H. T. Kung, and David Cox. 2019.Triton: an intermediate language and compiler fortiled neural network computations. In Proceedings of the 3rd ACM SIGPLAN International Workshopon Machine Learning and Programming Languages (Phoenix, AZ, USA) (MAPL 2019). Association forComputing Machinery, New York, NY, USA, 1019.",
  "Tomer Ullman. 2023. Large language models fail on trivial alterations to theory-of-mind tasks. arXiv preprintarXiv:2302.08399 (2023)": "Stephanie Valencia, Richard Cave, Krystal Kallarackal, Katie Seaver, Michael Terry, and Shaun K. Kane.2023. The less I type, the better: How AI Language Models can Enhance or Impede Communication forAAC Users. In Proceedings of the 2023 CHI Conference on Human Factors in Computing Systems (CHI23). Association for Computing Machinery, New York, NY, USA, 114. Ashish Vaswani, Noam Shazeer, Niki Parmar, Jakob Uszkoreit, Llion Jones, Aidan N Gomez, ukasz Kaiser,and Illia Polosukhin. 2017. Attention is all you need. Advances in neural information processing systems30 (2017). Paul Vicol, William Menapace, Kaushik Srinivasan, Caglar Gulcehre, Danilo Rezende, and Peter Battaglia.2022. SimNet: Learning Simulation-Based World Models for Physical Reasoning. In International Con-ference on Learning Representations. Oriol Vinyals, Igor Babuschkin, Wojciech M. Czarnecki, Michal Mathieu, Andrew Dudzik, Junyoung Chung,David Choi, Richard Powell, Timo Ewalds, Petko Georgiev, Junhyuk Oh, Dan Horgan, Manuel Kroiss,Ivo Danihelka, Aja Huang, L. Sifre, Trevor Cai, John P. Agapiou, Max Jaderberg, Alexander SashaVezhnevets, Rmi Leblond, Tobias Pohlen, Valentin Dalibard, David Budden, Yury Sulsky, James Molloy,Tom Le Paine, Caglar Gulcehre, Ziyun Wang, Tobias Pfaff, Yuhuai Wu, Roman Ring, Dani Yogatama,Dario Wnsch, Katrina McKinney, Oliver Smith, Tom Schaul, Timothy P. Lillicrap, Koray Kavukcuoglu,Demis Hassabis, Chris Apps, and David Silver. 2019b. Grandmaster level in StarCraft II using multi-agentreinforcement learning. Nature 575 (2019), 350 354. Oriol Vinyals, Igor Babuschkin, Wojciech M Czarnecki, Michal Mathieu, Andrew Dudzik, Junyoung Chung,David H Choi, Richard Powell, Timo Ewalds, Petko Georgiev, et al. 2019a. Grandmaster level in StarCraftII using multi-agent reinforcement learning. Nature 575, 7782 (2019), 350354.",
  "Haining Wang, Jimmy Huang, and Zhewei Zhang. 2019a. The Impact of Deep Learning on OrganizationalAgility.. In ICIS": "Jue Wang, Yucheng Lu, Binhang Yuan, Beidi Chen, Percy Liang, Christopher De Sa, Christopher Re, andCe Zhang. 2023g. CocktailSGD: Fine-tuning Foundation Models over 500Mbps Networks. In Proceedingsof the 40th International Conference on Machine Learning (Proceedings of Machine Learning Research,Vol. 202), Andreas Krause, Emma Brunskill, Kyunghyun Cho, Barbara Engelhardt, Sivan Sabato, andJonathan Scarlett (Eds.). PMLR, 3605836076. Jue Wang, Binhang Yuan, Luka Rimanic, Yongjun He, Tri Dao, Beidi Chen, Christopher Re, and Ce Zhang.2023i. Fine-tuning Language Models over Slow Networks using Activation Compression with Guarantees.arXiv:2206.01299 [cs.LG] Kaiwen Wang, Rahul Kidambi, Ryan Sullivan, Alekh Agarwal, Christoph Dann, Andrea Michi, Marco Gelmi,Yunxuan Li, Raghav Gupta, Avinava Dubey, et al. 2024a.Conditioned Language Policy: A GeneralFramework for Steerable Multi-Objective Finetuning. arXiv preprint arXiv:2407.15762 (2024).",
  "Xinlong Wang, Xiaosong Zhang, Yue Cao, Wen Wang, Chunhua Shen, and Tiejun Huang. 2023j. Seggpt:Segmenting everything in context. arXiv preprint arXiv:2304.03284 (2023)": "Xiyao Wang, Yuhang Zhou, Xiaoyu Liu, Hongjin Lu, Yuancheng Xu, Feihong He, Jaehong Yoon, Taixi Lu,Gedas Bertasius, Mohit Bansal, et al. 2024b. Mementos: A comprehensive benchmark for multimodallarge language model reasoning over image sequences. arXiv preprint arXiv:2401.10529 (2024). Yizhong Wang, Yeganeh Kordi, Swaroop Mishra, Alisa Liu, Noah A Smith, Daniel Khashabi, and HannanehHajishirzi. 2022a. Self-instruct: Aligning language models with self-generated instructions. arXiv preprintarXiv:2212.10560 (2022). Yizhong Wang, Yeganeh Kordi, Swaroop Mishra, Alisa Liu, Noah A. Smith, Daniel Khashabi, and Han-naneh Hajishirzi. 2023e.Self-Instruct:Aligning Language Models with Self-Generated Instructions.arXiv:2212.10560 [cs.CL] Yizhong Wang, Swaroop Mishra, Pegah Alipoormolabashi, Yeganeh Kordi, Amirreza Mirzaei, AnjanaArunkumar, Arjun Ashok, Arut Selvan Dhanasekaran, Atharva Naik, David Stap, et al. 2022b. Super-naturalinstructions:Generalization via declarative instructions on 1600+ nlp tasks.arXiv preprintarXiv:2204.07705 (2022).",
  "Yaqing Wang, Quanming Yao, James T Kwok, and Lionel M Ni. 2020. Generalizing from a few examples:A survey on few-shot learning. ACM computing surveys (csur) 53, 3 (2020), 134": "Zihao Wang, Shaofei Cai, Anji Liu, Yonggang Jin, Jinbing Hou, Bowei Zhang, Haowei Lin, Zhaofeng He, Zi-long Zheng, Yaodong Yang, et al. 2023a. Jarvis-1: Open-world multi-task agents with memory-augmentedmultimodal language models. arXiv preprint arXiv:2311.05997 (2023). Zihao Wang, Shaofei Cai, Anji Liu, Xiaojian Ma, and Yitao Liang. 2023b. Describe, explain, plan and select:Interactive planning with large language models enables open-world multi-task agents. arXiv preprintarXiv:2302.01560 (2023).",
  "Chen Wei, Chenxi Liu, Siyuan Qiao, Zhishuai Zhang, Alan Yuille, and Jiahui Yu. 2023. De-Diffusion MakesText a Strong Cross-Modal Interface. arXiv preprint arXiv:2311.00618 (2023)": "Jason Wei, Maarten Bosma, Vincent Y Zhao, Kelvin Guu, Adams Wei Yu, Brian Lester, Nan Du, An-drew M Dai, and Quoc V Le. 2021. Finetuned language models are zero-shot learners. arXiv preprintarXiv:2109.01652 (2021). Jason Wei, Yi Tay, Rishi Bommasani, Colin Raffel, Barret Zoph, Sebastian Borgeaud, Dani Yogatama,Maarten Bosma, Denny Zhou, Donald Metzler, Ed H. Chi, Tatsunori Hashimoto, Oriol Vinyals,Percy Liang, Jeff Dean, and William Fedus. 2022a.Emergent Abilities of Large Language Models.arXiv:2206.07682 [cs.CL] Jason Wei, Xuezhi Wang, Dale Schuurmans, Maarten Bosma, Fei Xia, Ed Chi, Quoc V Le, Denny Zhou,et al. 2022b. Chain-of-thought prompting elicits reasoning in large language models. Advances in NeuralInformation Processing Systems 35 (2022), 2482424837. Laura Weidinger, John Mellor, Maribeth Rauh, Conor Griffin, Jonathan Uesato, Po-Sen Huang, Myra Cheng,Mia Glaese, Borja Balle, Atoosa Kasirzadeh, et al. 2021. Ethical and social risks of harm from languagemodels. arXiv preprint arXiv:2112.04359 (2021).",
  "ChengyueWu,TengWang,YixiaoGe,ZeyuLu,RuisongZhou,YingShan,andPingLuo.2023b. -Tuning: Transferring Multimodal Foundation Models with Optimal Multi-task Interpolation.arXiv:2304.14381 [cs.CV]": "Jiajun Wu, Erika Lu, Pushmeet Kohli, Bill Freeman, and Josh Tenenbaum. 2017.Learning to SeePhysics via Visual De-animation. In Advances in Neural Information Processing Systems, I. Guyon,U. Von Luxburg, S. Bengio, H. Wallach, R. Fergus, S. Vishwanathan, and R. Garnett (Eds.),Vol. 30. Curran Associates, Inc. Tianyu Wu, Shizhu He, Jingping Liu, Siqi Sun, Kang Liu, Qing-Long Han, and Yang Tang. 2023a. A briefoverview of ChatGPT: The history, status quo and potential future development. IEEE/CAA Journal ofAutomatica Sinica 10, 5 (2023), 11221136. Tongshuang Wu, Ellen Jiang, Aaron Donsbach, Jeff Gray, Alejandra Molina, Michael Terry, and Carrie J.Cai. 2022a. PromptChainer: Chaining Large Language Model Prompts through Visual Programming. arXiv:2203.06566 [cs]. Tongshuang Wu, Michael Terry, and Carrie Jun Cai. 2022b.AI Chains: Transparent and ControllableHuman-AI Interaction by Chaining Large Language Model Prompts. In Proceedings of the 2022 CHIConference on Human Factors in Computing Systems (CHI 22). Association for Computing Machinery,New York, NY, USA, 122.",
  "Wilson Wu, John X Morris, and Lionel Levine. 2024c. Do language models plan ahead for future tokens?arXiv preprint arXiv:2404.00859 (2024)": "Zhengxuan Wu, Aryaman Arora, Zheng Wang, Atticus Geiger, Dan Jurafsky, Christopher D Manning,and Christopher Potts. 2024a. ReFT: Representation Finetuning for Language Models. arXiv preprintarXiv:2404.03592 (2024). Zhiyong Wu, Chengcheng Han, Zichen Ding, Zhenmin Weng, Zhoumianze Liu, Shunyu Yao, Tao Yu,and Lingpeng Kong. 2024b. OS-Copilot: Towards Generalist Computer Agents with Self-Improvement.arXiv:2402.07456 [cs.AI] Zhiheng Xi, Wenxiang Chen, Xin Guo, Wei He, Yiwen Ding, Boyang Hong, Ming Zhang, Junzhe Wang,Senjie Jin, Enyu Zhou, et al. 2023. The rise and potential of large language model based agents: A survey.arXiv preprint arXiv:2309.07864 (2023).",
  "Zhen Xing, Qijun Feng, Haoran Chen, Qi Dai, Han Hu, Hang Xu, Zuxuan Wu, and Yu-Gang Jiang. 2023.A survey on video diffusion models. arXiv preprint arXiv:2310.10647 (2023)": "Wenhan Xiong, Jingyu Liu, Igor Molybog, Hejia Zhang, Prajjwal Bhargava, Rui Hou, Louis Martin, RashiRungta, Karthik Abinav Sankararaman, Barlas Oguz, Madian Khabsa, Han Fang, Yashar Mehdad, SharanNarang, Kshitiz Malik, Angela Fan, Shruti Bhosale, Sergey Edunov, Mike Lewis, Sinong Wang, and HaoMa. 2023. Effective Long-Context Scaling of Foundation Models. arXiv:2309.16039 [cs.CL]",
  "Bowen Xu and Quansheng Ren. 2022. Artificial Open World for Evaluating AGI: A Conceptual Design. InInternational Conference on Artificial General Intelligence. Springer, 452463": "Canwen Xu, Zexue He, Zhankui He, and Julian McAuley. 2022.Leashing the Inner Demons:Self-Detoxification for Language Models. In Proceedings of the AAAI Conference on Artificial Intelligence,Vol. 36. 1153011537. Can Xu, Qingfeng Sun, Kai Zheng, Xiubo Geng, Pu Zhao, Jiazhan Feng, Chongyang Tao, and Daxin Jiang.2023a. Wizardlm: Empowering large language models to follow complex instructions. arXiv preprintarXiv:2304.12244 (2023). Fangzhi Xu, Zhiyong Wu, Qiushi Sun, Siyu Ren, Fei Yuan, Shuai Yuan, Qika Lin, Yu Qiao, and Jun Liu.2023b. Symbol-LLM: Towards foundational symbol-centric interface for large language models. arXivpreprint arXiv:2311.09278 (2023). Lingling Xu, Haoran Xie, Si-Zhao Joe Qin, Xiaohui Tao, and Fu Lee Wang. 2023c.Parameter-efficientfine-tuning methods for pretrained language models: A critical review and assessment. arXiv preprintarXiv:2312.12148 (2023). Xinrun Xu, Yuxin Wang, Chaoyi Xu, Ziluo Ding, Jiechuan Jiang, Zhiming Ding, and Brje F Karlsson.2024. A Survey on Game Playing Agents and Large Models: Methods, Applications, and Challenges.arXiv preprint arXiv:2403.10249 (2024).",
  "John Yang, Akshara Prabhakar, Karthik Narasimhan, and Shunyu Yao. 2023c. InterCode: Standardizingand Benchmarking Interactive Coding with Execution Feedback. arXiv:2306.14898 [cs.CL]": "Ling Yang, Zhilong Zhang, Yang Song, Shenda Hong, Runsheng Xu, Yue Zhao, Wentao Zhang, Bin Cui,and Ming-Hsuan Yang. 2023f. Diffusion models: A comprehensive survey of methods and applications.Comput. Surveys 56, 4 (2023), 139. Qian Yang, Yuexing Hao, Kexin Quan, Stephen Yang, Yiran Zhao, Volodymyr Kuleshov, and Fei Wang.2023a. Harnessing Biomedical Literature to Calibrate Clinicians Trust in AI Decision Support Systems.In Proceedings of the 2023 CHI Conference on Human Factors in Computing Systems. ACM, HamburgGermany, 114. Qian Yang, Aaron Steinfeld, Carolyn Ros, and John Zimmerman. 2020. Re-examining Whether, Why, andHow Human-AI Interaction Is Uniquely Difficult to Design. In Proceedings of the 2020 CHI Conferenceon Human Factors in Computing Systems (CHI 20). Association for Computing Machinery, New York,NY, USA, 113.",
  "Shunyu Yao, Jeffrey Zhao, Dian Yu, Nan Du, Izhak Shafran, Karthik Narasimhan, and Yuan Cao. 2022.React: Synergizing reasoning and acting in language models. arXiv preprint arXiv:2210.03629 (2022)": "Yifan Yao, Jinhao Duan, Kaidi Xu, Yuanfang Cai, Zhibo Sun, and Yue Zhang. 2024. A survey on largelanguage model (llm) security and privacy: The good, the bad, and the ugly. High-Confidence Computing(2024), 100211. Qinghao Ye, Haiyang Xu, Guohai Xu, Jiabo Ye, Ming Yan, Yiyang Zhou, Junyang Wang, Anwen Hu,Pengcheng Shi, Yaya Shi, et al. 2023. mplug-owl: Modularization empowers large language models withmultimodality. arXiv preprint arXiv:2304.14178 (2023).",
  "Matej Zeevi, Moritz Willig, Devendra Singh Dhami, and Kristian Kersting. 2023. Causal parrots: Largelanguage models may talk causality but are not causal. arXiv preprint arXiv:2308.13067 (2023)": "Yujia Zhai, Chengquan Jiang, Leyuan Wang, Xiaoying Jia, Shang Zhang, Zizhong Chen, Xin Liu, andYibo Zhu. 2023. ByteTransformer: A High-Performance Transformer Boosted for Variable-Length Inputs.arXiv:2210.03052 [cs.LG] Chaoyun Zhang, Liqun Li, Shilin He, Xu Zhang, Bo Qiao, Si Qin, Minghua Ma, Yu Kang, Qingwei Lin,Saravan Rajmohan, et al. 2024b. UFO: A UI-Focused Agent for Windows OS Interaction. arXiv preprintarXiv:2402.07939 (2024). Ce Zhang, Taixi Lu, Md Mohaiminul Islam, Ziyang Wang, Shoubin Yu, Mohit Bansal, and Gedas Berta-sius. 2023h.A Simple LLM Framework for Long-Range Video Question-Answering.arXiv preprintarXiv:2312.17235 (2023). Hongxin Zhang, Weihua Du, Jiaming Shan, Qinhong Zhou, Yilun Du, Joshua B Tenenbaum, Tianmin Shu,and Chuang Gan. 2023b. Building cooperative embodied agents modularly with large language models.arXiv preprint arXiv:2307.02485 (2023).",
  "Yuxuan Zhang, Kevin Eykholt, Shaoqing Ren, Michelle Lee, Filip Radenovic, Pascal Fua, and Animesh Garg.2023c. MetaSim: Learning to Generate Synthetic Datasets. arXiv preprint arXiv:2302.03213 (2023)": "Yunfeng Zhang, Q. Vera Liao, and Rachel K. E. Bellamy. 2020. Effect of confidence and explanation onaccuracy and trust calibration in AI-assisted decision making. In Proceedings of the 2020 Conference onFairness, Accountability, and Transparency (FAT* 20). Association for Computing Machinery, New York,NY, USA, 295305. Zeyu Zhang, Xiaohe Bo, Chen Ma, Rui Li, Xu Chen, Quanyu Dai, Jieming Zhu, Zhenhua Dong, and Ji-RongWen. 2024a. A Survey on the Memory Mechanism of Large Language Model based Agents. arXiv preprintarXiv:2404.13501 (2024). Zhenyu Zhang, Ying Sheng, Tianyi Zhou, Tianlong Chen, Lianmin Zheng, Ruisi Cai, Zhao Song, YuandongTian, Christopher R, Clark Barrett, Zhangyang Wang, and Beidi Chen. 2023j. H2O: Heavy-Hitter Oraclefor Efficient Generative Inference of Large Language Models. arXiv:2306.14048 [cs.LG]",
  "Yao Zhao, Rishabh Joshi, Tianqi Liu, Misha Khalman, Mohammad Saleh, and Peter J Liu. 2023a. Slic-hf:Sequence likelihood calibration with human feedback. arXiv preprint arXiv:2305.10425 (2023)": "Yunqing Zhao, Tianyu Pang, Chao Du, Xiao Yang, Chongxuan Li, Ngai-Man Cheung, and Min Lin. 2023b.On evaluating adversarial robustness of large vision-language models. arXiv preprint arXiv:2305.16934(2023). Yunpu Zhao, Rui Zhang, Wenyi Li, Di Huang, Jiaming Guo, Shaohui Peng, Yifan Hao, Yuanbo Wen, XingHu, Zidong Du, et al. 2024c. Assessing and Understanding Creativity in Large Language Models. arXivpreprint arXiv:2401.12491 (2024).",
  "Kaizhi Zheng, Xuehai He, and Xin Eric Wang. 2023a. Minigpt-5: Interleaved vision-and-language generationvia generative vokens. arXiv preprint arXiv:2310.02239 (2023)": "Lianmin Zheng, Wei-Lin Chiang, Ying Sheng, Siyuan Zhuang, Zhanghao Wu, Yonghao Zhuang, Zi Lin,Zhuohan Li, Dacheng Li, Eric Xing, et al. 2024. Judging llm-as-a-judge with mt-bench and chatbot arena.Advances in Neural Information Processing Systems 36 (2024). Lianmin Zheng, Zhuohan Li, Hao Zhang, Yonghao Zhuang, Zhifeng Chen, Yanping Huang, Yida Wang,Yuanzhong Xu, Danyang Zhuo, Eric P. Xing, Joseph E. Gonzalez, and Ion Stoica. 2022. Alpa: AutomatingInter- and Intra-Operator Parallelism for Distributed Deep Learning. arXiv:2201.12023 [cs.LG]",
  "Qihuang Zhong, Liang Ding, Juhua Liu, Bo Du, and Dacheng Tao. 2023b. Can chatgpt understand too? acomparative study on chatgpt and fine-tuned bert. arXiv preprint arXiv:2302.10198 (2023)": "Wanjun Zhong, Ruixiang Cui, Yiduo Guo, Yaobo Liang, Shuai Lu, Yanlin Wang, Amin Saied, Weizhu Chen,and Nan Duan. 2023a. Agieval: A human-centric benchmark for evaluating foundation models. arXivpreprint arXiv:2304.06364 (2023). Chunting Zhou, Pengfei Liu, Puxin Xu, Srinivasan Iyer, Jiao Sun, Yuning Mao, Xuezhe Ma, Avia Efrat, PingYu, Lili Yu, et al. 2024a. Lima: Less is more for alignment. Advances in Neural Information ProcessingSystems 36 (2024). Denny Zhou, Nathanael Schrli, Le Hou, Jason Wei, Nathan Scales, Xuezhi Wang, Dale Schuurmans, ClaireCui, Olivier Bousquet, Quoc Le, et al. 2022b. Least-to-most prompting enables complex reasoning in largelanguage models. arXiv preprint arXiv:2205.10625 (2022).",
  "Banghua Zhu, Jiantao Jiao, and Michael I Jordan. 2023b. Principled Reinforcement Learning with HumanFeedback from Pairwise or K-wise Comparisons. arXiv preprint arXiv:2301.11270 (2023)": "Bin Zhu, Bin Lin, Munan Ning, Yang Yan, Jiaxi Cui, HongFa Wang, Yatian Pang, Wenhao Jiang, JunwuZhang, Zongwei Li, et al. 2023c. LanguageBind: Extending Video-Language Pretraining to N-modalityby Language-based Semantic Alignment. arXiv preprint arXiv:2310.01852 (2023). Deyao Zhu, Jun Chen, Xiaoqian Shen, Xiang Li, and Mohamed Elhoseiny. 2023a. Minigpt-4: Enhancingvision-language understanding with advanced large language models. arXiv preprint arXiv:2304.10592(2023).",
  "Lucas Zimmer, Marius Lindauer, and Frank Hutter. 2020. Auto-pytorch tabular: Multi-fidelity metalearningfor efficient and robust autodl. arXiv preprint arXiv:2006.13799 (2020)": "Brianna Zitkovich, Tianhe Yu, Sichun Xu, Peng Xu, Ted Xiao, Fei Xia, Jialin Wu, Paul Wohlhart, StefanWelker, Ayzaan Wahid, Quan Vuong, Vincent Vanhoucke, Huong Tran, Radu Soricut, Anikait Singh,Jaspiar Singh, Pierre Sermanet, Pannag R. Sanketi, Grecia Salazar, Michael S. Ryoo, Krista Reymann,Kanishka Rao, Karl Pertsch, Igor Mordatch, Henryk Michalewski, Yao Lu, Sergey Levine, Lisa Lee, Tsang-Wei Edward Lee, Isabel Leal, Yuheng Kuang, Dmitry Kalashnikov, Ryan Julian, Nikhil J. Joshi, Alex Ir-pan, Brian Ichter, Jasmine Hsu, Alexander Herzog, Karol Hausman, Keerthana Gopalakrishnan, ChuyuanFu, Pete Florence, Chelsea Finn, Kumar Avinava Dubey, Danny Driess, Tianli Ding, Krzysztof MarcinChoromanski, Xi Chen, Yevgen Chebotar, Justice Carbajal, Noah Brown, Anthony Brohan, Montser-rat Gonzalez Arenas, and Kehang Han. 2023.RT-2:Vision-Language-Action Models Transfer WebKnowledge to Robotic Control. In Proceedings of The 7th Conference on Robot Learning (Proceedingsof Machine Learning Research, Vol. 229), Jie Tan, Marc Toussaint, and Kourosh Darvish (Eds.). PMLR,21652183."
}