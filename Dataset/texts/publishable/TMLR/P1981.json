{
  "Abstract": "We present Re-weighted Gradient Descent (RGD), a novel optimization technique thatimproves the performance of deep neural networks through dynamic sample re-weighting.Leveraging insights from distributionally robust optimization (DRO) with Kullback-Leiblerdivergence, our method dynamically assigns importance weights to training data during eachoptimization step. RGD is simple to implement, computationally ecient, and compatiblewith widely used optimizers such as SGD and Adam. We demonstrate the eectiveness ofRGD on various learning tasks, including supervised learning, meta-learning, and out-of-domain generalization. Notably, RGD achieves state-of-the-art results on diverse benchmarks,with improvements of +0.7% on DomainBed, +1.44% on tabular classication, +1.94%on GLUE with BERT, and +1.01% on ImageNet-1K with ViT.",
  "Introduction": "Deep neural networks (DNNs) have become essential for solving a wide range of tasks, including imageclassication, object detection, machine translation, and speech recognition. The most commonly usedparadigm for learning DNNs is empirical risk minimization (ERM Vapnik (1999)), which aims to identifya network that minimizes the average loss of training data points. Several algorithms, including SGD(Nemirovsky et al., 1983), Adam (Kingma & Ba, 2015), and Adagrad (Duchi et al., 2011), have beenproposed for solving ERM. However, a drawback of ERM is that it weighs all the samples equally, oftenignoring the rare and more dicult samples and focusing on the easier and abundant samples. This leads tosuboptimal performance on unseen data, especially when the training data is scarce (Namkoong & Duchi,2017). Consequently, recent works have developed data re-weighting techniques for improving the performanceof ERM. One particularly fruitful approach in this line of work is the framework of Distributionally RobustOptimization (DRO) (Ben-Tal et al., 2013), which assigns higher weights to hard examples, often leading tomodels with better performance than ERM. DRO selects the best model while also accounting for various uncertainties in the training data distribu-tion (Ben-Tal et al., 2013). In particular, DRO treats the data distribution as uncertain and nds modelswhich are robust to perturbations in the data distribution (e.g., removing a small fraction of points, addingrandom noise to each data point, etc.). This makes the model more robust to noise in the training dataset.For example, in the context of classication, this forces the model to place less emphasis on noisy features",
  "Published in Transactions on Machine Learning Research (09/2024)": ": Results on meta-learning datasets. We report the Worst-K% performance as well to help study theperformance distribution over all tasks. Overall, we expect our reweighting scheme to give more importanceto those tasks which are dicult and rare. We show that the addition of our proposed approach signicantlyoutperforms existing methods as shown in Omniglot 5-way 1-shot, as well as miniImageNet 5-way 1-shotsetting.",
  "+ + .(1)": "Here, f (s) = supt{st f(t)} is the Fenchel conjugate of f. This alternative way of expressing DRO showshow it implicitly reweighs samples using the conjugate f . The seminal works of Duchi et al. (2021a);Namkoong & Duchi (2017) studied this objective for various f-divergences and showed that it has variancereduction properties, and leads to models with good generalization performance under small perturbations( = O(1/n), where n is the data size). Furthermore, Duchi & Namkoong (2018) showed that DRO underlarge perturbations ( = O(1)) leads to models with good fairness, tail risk guarantees. In another line ofwork, Li et al. (2021) (and its extended version Li et al. (2023)) considered KL divergence DRO, which isobtained by choosing f(x) = x log x, and showed that setting dual variable to a negative value results inrobust models that can withstand corruptions in the training data. Inspired by these impressive properties, several recent studies have developed algorithms for optimizing DROand designed data re-weighting techniques for various learning tasks. These algorithms fall into two broadcategories: (a) Primal-Dual techniques which rely on alternating mirror ascent, descent to solve the min-maxDRO objective (Namkoong & Duchi, 2016; Yan et al., 2020b; Fidon et al., 2020), and (b) Compositionaloptimization techniques which solve an equivalent compositional/dual form of DRO, which takes the formg(Ez[h(z, )]), for some functions g, h (Qi et al., 2021; 2023b;a; Li et al., 2023). While these algorithms comewith good convergence guarantees, they have certain drawbacks that limit their use in practice. (a) Scalability:primal-dual algorithms require updating and sampling from a probability distribution over the entire datasetat each iteration, making them computationally expensive. Although compositional optimization techniquesalleviate this issue, gradient estimation within these algorithms is non-trivial as the objective is no longeran empirical mean of the losses evaluated at the training data points. Overcoming this often necessitatesmaintaining moving averages of sample weights, which introduces additional hyperparameters, complicatingtheir application to large-scale scenarios (Qi et al., 2023b; Li et al., 2021). (b) Robustness to Outliers: manyreal-world datasets contain outliers1, which pose challenges to algorithms optimizing DRO. In particular,these outliers often result in poor performance and instability during the DRO training process (Zhu et al.,2022a; Zhai et al., 2021). Existing works often fail to account for outliers in real datasets, leading to subparperformance (see for a detailed comparison). In this work, we address the aforementioned limitations of DRO optimization techniques. We focus on KLdivergence-based DRO, and develop a lightweight algorithm for eciently solving the resulting objective. Ouralgorithm simply optimizes the inner objective in Equation 1 using SGD. This gives rise to our stochasticRe-weighted Gradient Descent (RGD) algorithm, a variant of the classical SGD, that re-weights data pointsduring each optimization step based on their diculty. A key component of our algorithm is weight clippingthat we introduce to protect against (benign) outliers and stabilize the algorithm. As demonstrated inour experiments (see , Appendix D), weight clipping signicantly improves the performance ofour algorithm on numerous learning tasks involving real-world datasets. Another noteworthy aspect of our 1An outlier is a data point that lies signicantly outside the typical pattern of a dataset. These outliers could be because ofnoise in data collection process or could be introduced by a malicious adversary. In this work, we are primarily concerned aboutthe former type of outliers.",
  "This Workstochastic optimizationof inner obj.same as SGDclipping levelYes": ": Comparison with relevant prior works for optimizing KL-DRO. See for a detailed discussion.P-D in the 2nd column refers to primal-dual, and C-M refers to compositional minimization. 3rd columncorresponds to the cost of running each step of the algorithm. 4th column corresponds to additional parametersintroduced by the algorithm on top of learning rate (lr) of primal variables.",
  "Evaluation": "In our experiments, we show that using our re-weighting scheme on top of existing learning algorithms improvestheir generalization performance in a variety of learning tasks including supervised learning, meta learning,out-of-domain generalization. While prior works focused on settings involving fairness, class imbalance to showimprovements of DRO type methods, our work is the rst to show signicant improvements in generalizationin large scale learning tasks across various domains. Supervised Learning:We evaluate RGD on several supervised learning tasks in language and visiondomains. In the language domain, we apply RGD for BERT ne-tuning on the General Language Under-standing Evaluation (GLUE) benchmark and show that RGD outperforms the BERT baseline by +1.94%. Inthe vision domain, we apply RGD for ImageNet-1K classication using ViT-S model, and show that RGDoutperforms the ViT-S baseline by +1.01%. Tabular Classication:Recently, Majmundar et al. (2022) introduced a tabular representation learningmethod called MET. Deep learning methods trained with the learned representations from MET achievedSOTA performance on downstream classication tasks, signicantly improving upon Gradient Boostingdecision trees (GBDT; Friedman (2001)). Our experiments show that applying RGD to the MET frameworkimproves its performance by 1.51% and 1.27% on binary and multi-class tabular classication, respectively. Domain Generalization:In domain generalization, the distributions of train and test datasets could bedierent (for example, training on pictures of real dogs and evaluating cartoon dogs). This task requiresrobustness to distribution shifts and DRO is a natural framework in this context. Gulrajani & Lopez-Paz(2021) showed that the ERM framework applied over deep networks, is highly eective for this problem.Perhaps surprisingly, this remained the state-of-the-art (SOTA) algorithm for a long time. Only recently,ERM has been beaten on this challenging task (Cha et al., 2022; Addepalli et al., 2023). In this work, weshow that using RGD on top of these recent techniques further boosts their performance by 0.7% and givesSOTA results on this task. Meta-Learning:In meta-learning, we aim to learn models that generalize to new tasks with limited data.Predominant approaches in this domain use the classical ERM to optimize deep networks (Finn et al., 2017;Snell et al., 2017; Kumar et al., 2023). However, a common issue in this domain is that the learned modelssolve most tasks but fail catastrophically in some tasks. Consequently, this has promoted works that focuson worst-case performance (Collins et al., 2020). Recently, Li et al. (2023) used KL-DRO to tackle thisproblem. However, the authors applied their algorithm for solving meta-regression on a toy-dataset that isfree of outliers, and havent showcased their algorithm on practically relevant datasets such as Omniglot,miniImageNet. In this work, we show that using RGD as an o-the-hat addition to Model-Agnostic Meta-",
  "This work makes the following key contributions:": "KL-DRO Inspired Re-weighting (RGD). We introduce RGD, a novel, lightweight data re-weighting technique that improves the generalization of deep neural networks. Inspired by theprinciples of KL-DRO, RGD dynamically re-weights samples during optimization based on theirdiculty. We further enhance robustness with weight clipping to mitigate the inuence of outliers.RGD is versatile and easily integrated with widely used optimizers like Adam, SGD. State-of-the-Art (SOTA) Performance Enhancement. Extensive experiments demonstratethat RGD delivers signicant performance gains across diverse learning tasks. In tabular classication,RGD boosts the accuracy of MET (Majmundar et al., 2022) by +1.44%.For out-of-domaingeneralization, RGD outperforms FRR (Addepalli et al., 2023) on DomainBed by +0.7%. Additionally,RGD improves the performance of BERT on GLUE benchmarks by +1.94% and ViT on ImageNet-1Kby +1.01%. (see , Appendix D)",
  "Related Work": "This section reviews relevant research on DRO. For a comprehensive overview of other popular data reweightingmethods in machine learning, including AdaBoost, curriculum learning, please refer to Appendix A. DRO dates back to the early works of Ben-Tal et al. (2009; 2013). Since then several works have studiedvarious statistical and optimization aspects of DRO. The seminal works of Lam (2016); Namkoong & Duchi(2017); Duchi et al. (2021b) formally showed that minimizing empirical DRO risk - under small perturbations( = O(1/n), where n is the data size) - is equivalent to minimizing sum of empirical risk and its standarddeviation. Consequently, optimizing DRO leads to a better bias-variance trade-os and generalizing models.In this work, we rely on this property of DRO to develop our re-weighting scheme. In another seminal work,Duchi & Namkoong (2018) showed that DRO - under large perturbations ( = O(1)) - leads to models withgood tail performance. The aforementioned properties of DRO has led to numerous works applying it in various learning scenarios.For instance, Duchi & Namkoong (2018); Sagawa* et al. (2020); Qi et al. (2021; 2023b); Li et al. (2021;2023) used DRO to tackle problems of class-imbalanaced classication and fairness. In another line of work,Namkoong & Duchi (2017); Fidon et al. (2020) studied DRO for designing models that generalize better thanERM. Our work falls in this second category of works that focus on generalization. From an optimization perspective, several works have focused on designing ecient algorithms for optimizingthe DRO objective. These algorithms can be classied into two broad categories: primal-dual (Namkoong &Duchi, 2016; Fidon et al., 2020; Yan et al., 2020b), compositional optimization techniques (Qi et al., 2021;2023b;a; Li et al., 2021). One of the key drawbacks of primal-dual techniques is that they update and samplefrom a probability distribution over the entire training data at each step (aka. dual variables). A naiveimplementation of this step takes O(n) time, which is prohibitive for large-scale tasks. Namkoong & Duchi(2016) reduced the complexity of this step to O(log n) using data structures such as balanced binary searchtrees. However, the resulting algorithms are hard to implement in practice. Another drawback of thesealgorithms is that they require storing a buer of weights for the entire dataset, which is infeasible at the scaleof LLMs. Even if storing the weights is feasible, the presence of data augmentations complicates the resultingalgorithms. Compositional optimization algorithms overcome these drawbacks by working with an equivalentdual formulation of DRO that can be written as composition of two functions: g(Ez[h(z, )]). One majordrawback of these techniques though is that estimating the gradient g(Ez[h(z, )]) from a mini-batch is 2Li et al. (2021) developed hierarchical TERM framework for handling outliers in DRO. But their framework is only applicableto settings such as group fairness where the learner has a priori knowledge of group memberships.",
  "Outlier robust DRO.Recent works have shown that DRO is highly sensitive to outliers (Zhai et al.,": "2021; Zhu et al., 2022a). This is because DRO tends to magnify the inuence of outliers by upweightingthem further. This is one of the reasons for the suboptimal performance of existing DRO algorithms onreal world datasets. To address this, Zhai et al. (2021) consider an adversarial model for outliers (where-fraction of training data could be arbitrarily corrupted by a malicious adversary). They develop a heuristicto remove the outliers during each descent step for 2-DRO and CVaR. While interesting, this is too strongof an adversary model which leads to data wastage in practice. Min-min DRO.Min-min DRO minimizes the following objective: infP :D(P ||Pdata) EP [(z, )]. Contrastthis with DRO which minimizes: supP :D(P ||Pdata) EP [(z, )]. Unlike DRO which is primarily studied forgeneralization and fairness properties, min-min DRO is studied for training in the presence of outliers (Liet al., 2021; Kumar & Amid, 2021; Majidi et al., 2021). Instead of upweighting high loss points, min-minDRO downweights them. Other applications of DRO.Sagawa* et al. (2020) optimized Group DRO for fair models when the groupinformation is known. Sinha et al. (2018) studied DRO with Wasserstein divergence for learning models thatare robust to adversarial perturbations. DRO also appears in many classical statistical problems. For example,many boosting algorithms (including AdaBoost) can be viewed as performing DRO with KL-divergence-baseduncertainty sets (Arora et al., 2012; Friedman, 2001). Faury et al. (2020) relied on KL-DRO for counterfactualrisk minimization. Sakhi et al. (2020) use DRO for improving oine contextual bandits algorithms. Optimization Techniques for Improved Generalization.Several optimization techniques, that falloutside the umbrella of DRO, have been proposed for improving the generalization of ML models. Of these,Sharpness-Aware Minimization (SAM) (Foret et al., 2021) is perhaps the most popular technique. From atheoretical perspective, SAM performs robust optimization in the weight space (that is SAM tries to learn amodel that is robust to perturbations of weights). In contrast, RGD performs robust optimization in thedistribution space. So, RGD and SAM are orthogonal to each other and can potentially be merged togetherto boost the performance. See Appendix D.3 for empirical comparison between RGD and SAM.",
  "Distributionally Robust Optimization": "Consider a general learning problem where we are given n i.i.d samples {zi}ni=1 drawn from some unknowndistribution Pdata. Let Pdata be the empirical distribution over these samples. Our ideal goal is to nd amodel that minimizes the population risk: R() := EPdata[(z; )]. Here (z; ) is the loss of z undermodel . Since Pdata is typically unknown, a standard practice in ML/AI is to minimize the empirical risk,which is dened as",
  "n .(2)": "Here, c1, c2 > 0 are constants, and VarP ((z; )) is the variance of (z; ) w.r.t distribution P. Such boundshold under certain regularity conditions on and . While ERM minimizes the rst term in the RHS above, ittotally ignores the second term involving the variance. Consequently, in high-variance and/or small n settingswhere R() and Rn() are far away from each other, ERM tends to have poor generalization guarantees.A natural technique to address this issue is to learn models that consider the bias-variance trade-o andminimize the following objective.",
  "n": "Ignoring the lower order terms (i.e., 1/n terms), the above equation, together with Equation 2, shows thatthe empirical DRO risk RD,n() is an upper bound of the population risk R() at any . Furthermore,it can be seen that empirical DRO is equal to the empirical risk plus a variance term (modulo the lowerorder term). This variance term acts as a regularizer during the optimization of empirical DRO and leads tomodels with smaller variance, and with good generalization guarantees.",
  "Stochastic Re-weighted Gradient Descent (RGD)": "The above discussion motivates the use of DRO risk for learning models, especially in high variance and/orlow sample regime. We now derive our RGD algorithm as a technique to minimize the empirical DROrisk RD,n, and to learn models with better generalization guarantees than ERM. Specically, we considerKL divergence-based DRO, where one adds perturbations to create data distributions that are close tothe original data distribution in the KL divergence metric, and learn a model with best performance overall possible perturbations. The following proposition derives the equivalent dual representation of the KLdivergence-DRO objective, the proof of which can be found in Appendix B.1.",
  "Experiments": "In this section, we rst present ablations on various design choices in our algorithm. Next, we presentempirical evidence showing that RGD outperforms ABSGD (Qi et al., 2023b), TERM (Li et al., 2021), twostate-of-the-art algorithms for optimizing KL-DRO. Finally, we present large scale experiments showing thatRGD can be widely applied across tasks such as supervised learning, meta learning to boost the generalizationperformance of existing learning algorithms. Details regarding hyperparameter tuning are relegated toAppendix 5. Additional experiments on class imbalanced classication, and large-scale tasks such as miniGPTpre-training, EcientNet netuning are presented in Appendix D. To ensure fair comparisons, we integrated RGD into existing baseline codebase for each of the experiments,maintaining the same optimizer (primarily Adam for most experiments, SGD for CIFAR experiments) forboth baseline and RGD versions. RGD introduces only one additional hyperparameter, the clipping factor ().The optimizer, weight decay, batch sizes, etc. were kept constant with the baseline across all our experiments. 00.10.30.50.7",
  "Comparison with existing KL-DRO optimization techniques": "In this section, we present experimental results on ImageNet classication with ViT-S model to showcase theecacy of RGD over state-of-the-art KL-DRO optimization techniques ABSGD, and TERM (see ).We were unable to compare with the recent SCDRO algorithm of Qi et al. (2023a) due to technical dicultieswith implementing it in JAX (Bradbury et al., 2018) (the main diculty arises from syncing values ofparameters across various devices). Furthermore, the algorithm is signicantly more complex with manyhyperparameters. shows that ABSGD, TERM with extensive tuning of three hyperparameters(exponential scale, learning rate , and moving average parameter) achieve similar performance as baselineERM. In contrast, RGD outperforms the baseline ERM by 1.1% with minimal tuning of hyperparameters,highlighting its ecacy. One of the reasons for this performance dierence between RGD, and ABSGD,TERM is the weight clipping we perform in our algorithm, which guards it from outliers. We note thatSCDRO doesnt perform weight clipping and could potentially suer from a similar performance drop asABSGD, TERM. Additional details about the experiment can be found in Appendix D.1.1. Next, we compare RGD with ABSGD, TERM for the problem of class imbalanced classication. For thisexperiment, we consider the long-tailed CIFAR-10, CIFAR-100 datasets (Cui et al., 2019). presentsthe results from this experiment. It can be seen that RGD outperforms both ABSGD and TERM by > 1%on average. Additional details about this experiment, including comparison with specialized techniques forclass imbalanced classication such as class-balanced loss (Cui et al., 2019) and focal loss (Lin et al., 2017),can be found in Appendix D.2.",
  "Supervised Learning": "This section studies our approach when applied on standard supervised learning tasks such as BERT netuningon GLUE benchmark, and Imagenet-1K classication. We use a base model of ViT-S for the latter task. depicts our results from this experiment. On GLUE tasks, our RGD algorithm outperforms thebaseline by +1.94% with a standard deviation of 0.42%. Furthermore, we perform hypothesis testing tocondit that these results are statistically signicant with a p-value that is less than 0.05. On Imagenet-1K,we show a +1.01% improvement over baseline with the o-the-hat addition of the RGD reweighing and noadditional complexity in terms of compute: memory and time. Furthermore, we also experiment with pre-training of the BERT-base model. We use the BooksCorpus(800M words) (Zhu et al., 2015) and English Wikipedia (2,500M words) as our pre-training corpus. Wetrained the Bert-base model for 450K steps, and tuned the learning rate (lr) for baseline, and lr, clippingfactor for RGD. We report both the MLM (Masked Language Model) accuracy and NSP (Next SequencePrediction) accuracy comparisons of RGD vs Default (ERM). It can be seen that our approach boosts theMLM accuracy and NSP accuracy by +0.2% and +0.9% respectively (see ). Furthermore, throughhypothesis testing, we show that the results are statistically signicant with a p-value of 0.05. Additionalexperiments on EcientNet ne-tuning, DeiT model (Touvron et al., 2021) for ImageNet-1K classication,and miniGPT (Zhu et al., 2024) pre-training are discussed in Appendix D.5.",
  "MET-SDefault Majmundar et al. (2022)90.9448.0099.0174.1178.02RGD (Ours)91.5449.5499.6979.7280.12": "Learning with tabular data is a task where traditional machine learning methods, like random forest Breiman(2001); Friedman (2001) are incredibly competitive against deep learning-based methods (Yoon et al., 2020).Recently, Majmundar et al. (2022) obtained SOTA results for tabular classication using self-supervisedrepresentation learning and relying on the learned representations in the downstream classication tasks (see). Their work developed two algorithms namely, MET (representation learning with adversarialtraining) and MET-S (representation learning without adversarial training). The adversarial training addsrobustness to the learned representations, thus improving performance. In this experiment, we integrateRGD with MET-S instead of doing adversarial training. This allows us to test the robustness propertiesof the models trained with RGD. and shows gains on multiple tabular datasets for themulti-class classication and binary classication tasks. Notably, our approach outperforms previous SOTAin this problem by +1.27%, and +1.5% on the multi-class and binary classication tasks respectively. Werefer to Appendix D.6 for a comprehensive comparison with baselines such as Gradient Boosting DecisionTrees (Friedman, 2001), VIME (Yoon et al., 2020), SubTab (Ucar et al., 2021), TabNet (Arik & Pster, 2021),DACL+ (Verma et al., 2021) and many more. Our motivation to experiment on these permuted MNIST,permuted CIFAR, and permuted FMNIST can be traced back to the introduction of these datasets in theworks of Yoon et al. (2020); Ucar et al. (2021). Subsequently, other recent works such as Majmundar et al.(2022) also experimented on these datasets and have become a standard benchmark for tabular classication.",
  "ERM + FRRDefault Addepalli et al. (2023)87.5 0.177.6 0.369.4 0.145.1 0.169.90RGD (Ours)88.2 0.2 78.6 0.369.8 0.245.8 0.070.60": "In this section, we show that our technique can be used to boost the performance of OOD generalizationtechniques. We experiment on DomainBed, a standard benchmark used to study the out-of-domain perfor-mance of models. More information about the benchmark, the task to solve, and the metric is discussedin Appendix D.8.1. The benchmark is notorious since the most basic approach, such as straightforwardEmpirical Risk Minimization (ERM) as evaluated by Gulrajani & Lopez-Paz (2021), was the SOTA methodfor a long time. Most new approaches either performed worse than ERM or marginally better. In recent",
  "AlgorithmWorst 10% Worst 20% Worst 30% Worst 40% Worst 50%Overall": "Omniglot 5-way 1-shotMAML91.71 0.7394.16 0.5095.41 0.3996.22 0.3296.76 0.2798.38 0.17MAML + RGD 92.14 0.84 94.54 0.53 95.72 0.40 96.46 0.33 96.90 0.27 98.45 0.17Omniglot 20-way 1-shotMAML84.33 0.4085.86 0.2986.92 0.2687.73 0.2488.42 0.2291.28 0.22MAML + RGD 86.61 0.36 88.09 0.28 89.09 0.24 89.87 0.23 90.50 0.21 93.01 0.20miniImageNet 5-way 1-shotMAML30.94 0.7034.52 0.6236.93 0.5738.94 0.5540.68 0.5348.86 0.62MAML + RGD 33.33 0.90 36.67 0.65 39.12 0.59 41.20 0.56 42.96 0.55 51.21 0.63 In meta-learning, the goal is to learn representations that generalize eectively to new tasks, even whenprovided with limited examples. However, task heterogeneity poses a signicant challenge. Some tasks maybe inherently simpler to learn, leading models to prioritize these and neglect the more dicult, less frequenttasks. While Empirical Risk Minimization (ERM) may perform well on common tasks, its performancecan deteriorate drastically on rare and challenging ones. This necessitates a mechanism for re-weightingtasks to ensure balanced learning. Building upon the experimental results of Kumar et al. (2023), we makecomparisons with our MAML + RGD approach as the proposed variant. We evaluate RGD not only based onthe average performance across tasks but also on the Worst-K% of tasks in a xed task pool. Our experimentson various benchmarks, including Omniglot 5-way 1-shot, Omniglot 20-way 1-shot, and miniImageNet 5-way1-shot, demonstrate signicant improvements in the Worst-K% metric (). For example, on Omniglot20-way 1-shot, our proposed reweighting scheme improves overall performance by 1.83% and the Worst-10%performance by 2.28%. Similarly, on the challenging miniImageNet 5-way 1-shot benchmark, we achieve asubstantial improvement of approximately 3% across the board. Further results in this domain are discussedin Appendix D.7.",
  "Conclusion, Limitations and Future Work": "We introduced a re-weighted gradient descent (RGD) technique that eectively boosts the performance of deeplearning across a wide range of tasks and domains. It is simple to implement and can be seamlessly integratedinto existing algorithms with just two lines of code change. Our algorithm is derived from Kullback-Leiblerdistributionally robust optimization, a known method for improving model generalization. While RGD shows promising results, it has the following limitations that warrant further investigation:(a) outlier handling: our current approach uses weight clipping to mitigate the impact of outliers. Whileempirically eective, a more principled approach to outlier robustness in DRO is worth exploring, and (b)robustness to noise: while RGD can handle benign noise, it can fail in the presence of adversarial/systematicnoise. In the future, we plan to develop variants of RGD that can tolerate adversarial corruptions in thetraining data, while simultaneously improving the model generalization. Additionally, we plan to evaluate",
  "Ethical Statement and Broader Impact": "Our proposed approach is compatible with any learning objective expressed as an expectation over samples.We showcased its eectiveness with various loss functions, including Mean Square Error, Cross Entropy,and others, outperforming previous state-of-the-art methods considerably. Implementing our approach isstraightforward, and it has broad applicability across domains such as Natural Language Processing (NLP),Vision, and Time Series data. This paper presents work whose goal is to advance the eld of MachineLearning. There are many potential societal consequences of our work, none which we feel must be specicallyhighlighted here. We would like to thank Ahmad Beirami, Virginia Smith, Manzil Zaheer, Tian Li, and Maziar Sanjabi forproviding detailed feedback on our paper. We would like to thank Elan Rosenfeld, and Tianbao Yang forpointing us to important prior works. We extend our sincere gratitude to Prateek Jain, Pradeep Shenoy, AnshulNasery, Lovish Madaan, and the numerous dedicated members of the machine learning and optimizationteam at Google DeepMind India for their invaluable feedback and contributions to this work. Sravanti Addepalli, Anshul Nasery, Venkatesh Babu Radhakrishnan, Praneeth Netrapalli, and Prateek Jain.Feature reconstruction from outputs can mitigate simplicity bias in neural networks. In The EleventhInternational Conference on Learning Representations, 2023. URL",
  "Gilles Blanchard, Aniket Anand Deshmukh, run Dogan, Gyemin Lee, and Clayton Scott. Domain gen-eralization by marginal transfer learning. The Journal of Machine Learning Research, 22(1):46100,2021": "James Bradbury, Roy Frostig, Peter Hawkins, Matthew James Johnson, Chris Leary, Dougal Maclaurin,George Necula, Adam Paszke, Jake VanderPlas, Skye Wanderman-Milne, and Qiao Zhang. JAX: composabletransformations of Python+NumPy programs, 2018. URL Stefan Braun, Daniel Neil, and Shih-Chii Liu. A curriculum learning method for improved noise robustnessin automatic speech recognition. In 2017 25th European Signal Processing Conference (EUSIPCO), pp.548552. IEEE, 2017.",
  "Olivier Catoni and Ilaria Giulini. Dimension-free pac-bayesian bounds for the estimation of the mean of arandom vector. arXiv preprint arXiv:1802.04308, 2018": "Junbum Cha, Sanghyuk Chun, Kyungjae Lee, Han-Cheol Cho, Seunghyun Park, Yunsung Lee, and SungraePark. Swad: Domain generalization by seeking at minima. Advances in Neural Information ProcessingSystems, 34:2240522418, 2021. Junbum Cha, Kyungjae Lee, Sungrae Park, and Sanghyuk Chun. Domain generalization by mutual-informationregularization with pre-trained models. In European conference on computer vision, pp. 440457. Springer,2022.",
  "Yanbo Fan, Ran He, Jian Liang, and Baogang Hu. Self-paced learning: An implicit regularization perspective.In Proceedings of the AAAI Conference on Articial Intelligence, volume 31, 2017": "Louis Faury, Ugo Tanielian, Elvis Dohmatob, Elena Smirnova, and Flavian Vasile. Distributionally robustcounterfactual risk minimization.In Proceedings of the AAAI Conference on Articial Intelligence,volume 34, pp. 38503857, 2020. Lucas Fidon, Michael Aertsen, Thomas Deprest, Doaa Emam, Frdric Guens, Nada Mufti, Esther Van Els-lander, Ernst Schwartz, Michael Ebner, Daniela Prayer, et al. Distributionally robust deep learning usinghardness weighted sampling. arXiv preprint arXiv:2001.02658, 2020.",
  "Jerome H Friedman. Greedy function approximation: a gradient boosting machine. Annals of statistics, pp.11891232, 2001": "Yaroslav Ganin, Evgeniya Ustinova, Hana Ajakan, Pascal Germain, Hugo Larochelle, Franois Laviolette,Mario Marchand, and Victor Lempitsky. Domain-adversarial training of neural networks. The journal ofmachine learning research, 17(1):20962030, 2016. Santiago Gonzalez and Risto Miikkulainen. Optimizing loss functions through multi-variate taylor polynomialparameterization. In Proceedings of the Genetic and Evolutionary Computation Conference, pp. 305313,2021.",
  "Anastasia Ivanova and Pierre Ablin. A challenge in reweighting data with bilevel optimization. arXiv preprintarXiv:2310.17386, 2023": "Andrew Jesson, Nicolas Guizard, Sina Hamidi Ghalehjegh, Damien Goblot, Florian Soudan, and NicolasChapados. Cased: curriculum adaptive sampling for extreme data imbalance. In International conferenceon medical image computing and computer-assisted intervention, pp. 639646. Springer, 2017. Lu Jiang, Deyu Meng, Teruko Mitamura, and Alexander G Hauptmann. Easy samples rst: Self-pacedreranking for zero-example multimedia search. In Proceedings of the 22nd ACM international conferenceon Multimedia, pp. 547556, 2014a.",
  "Diederik Kingma and Jimmy Ba. Adam: A method for stochastic optimization. In International Conferenceon Learning Representations (ICLR), San Diega, CA, USA, 2015": "Anastasia Koloskova, Hadrien Hendrikx, and Sebastian U Stich. Revisiting gradient clipping: Stochastic biasand tight convergence guarantees. In International Conference on Machine Learning, pp. 1734317363.PMLR, 2023. David Krueger, Ethan Caballero, Joern-Henrik Jacobsen, Amy Zhang, Jonathan Binas, Dinghuai Zhang,Remi Le Priol, and Aaron Courville. Out-of-distribution generalization via risk extrapolation (rex). InInternational Conference on Machine Learning, pp. 58155826. PMLR, 2021.",
  "Changsheng Li, Junchi Yan, Fan Wei, Weishan Dong, Qingshan Liu, and Hongyuan Zha. Self-paced multi-tasklearning. In Proceedings of the AAAI conference on articial intelligence, volume 31, 2017": "Da Li, Yongxin Yang, Yi-Zhe Song, and Timothy Hospedales. Learning to generalize: Meta-learning fordomain generalization. In Proceedings of the AAAI conference on articial intelligence, volume 32, 2018a. Haoliang Li, Sinno Jialin Pan, Shiqi Wang, and Alex C Kot. Domain generalization with adversarial featurelearning. In Proceedings of the IEEE conference on computer vision and pattern recognition, pp. 54005409,2018b. Tian Li, Ahmad Beirami, Maziar Sanjabi, and Virginia Smith. Tilted empirical risk minimization. In 9thInternational Conference on Learning Representations, ICLR 2021, Virtual Event, Austria, May 3-7, 2021.OpenReview.net, 2021. URL",
  "Te Pi, Xi Li, Zhongfei Zhang, Deyu Meng, Fei Wu, Jun Xiao, Yueting Zhuang, et al. Self-paced boost learningfor classication. In IJCAI, pp. 19321938, 2016": "Qi Qi, Zhishuai Guo, Yi Xu, Rong Jin, and Tianbao Yang. An online method for a class of distributionallyrobust optimization with non-convex objectives. Advances in Neural Information Processing Systems, 34:1006710080, 2021. Qi Qi, Jiameng Lyu, Kung-Sik Chan, Er-Wei Bai, and Tianbao Yang. Stochastic constrained DRO witha complexity independent of sample size. Transactions on Machine Learning Research, 2023a. ISSN2835-8856. URL",
  "Yangyang Shi, Martha Larson, and Catholijn M Jonker. Recurrent neural network language model adaptationwith curriculum learning. Computer Speech & Language, 33(1):136154, 2015": "Abhinav Shrivastava, Abhinav Gupta, and Ross Girshick. Training region-based object detectors with onlinehard example mining. In Proceedings of the IEEE conference on computer vision and pattern recognition,pp. 761769, 2016. Jun Shu, Qi Xie, Lixuan Yi, Qian Zhao, Sanping Zhou, Zongben Xu, and Deyu Meng. Meta-weight-net:Learning an explicit mapping for sample weighting. Advances in neural information processing systems, 32,2019.",
  "Baochen Sun and Kate Saenko. Deep coral: Correlation alignment for deep domain adaptation. In Europeanconference on computer vision, pp. 443450. Springer, 2016": "Hugo Touvron, Matthieu Cord, Matthijs Douze, Francisco Massa, Alexandre Sablayrolles, and Herv Jgou.Training data-ecient image transformers & distillation through attention. In International conference onmachine learning, pp. 1034710357. PMLR, 2021. Radu Tudor Ionescu, Bogdan Alexe, Marius Leordeanu, Marius Popescu, Dim P Papadopoulos, and VittorioFerrari. How hard can it be? estimating the diculty of visual search in an image. In Proceedings of theIEEE Conference on Computer Vision and Pattern Recognition, pp. 21572166, 2016. Talip Ucar, Ehsan Hajiramezanali, and Lindsay Edwards. Subtab: Subsetting features of tabular data for self-supervised representation learning. Advances in Neural Information Processing Systems, 34:1885318865,2021.",
  "Shen Yan, Huan Song, Nanxiang Li, Lincan Zou, and Liu Ren. Improve unsupervised domain adaptationwith mixup training. arXiv preprint arXiv:2001.00677, 2020a": "Yan Yan, Yi Xu, Qihang Lin, Wei Liu, and Tianbao Yang. Optimal epoch stochastic gradient descent ascentmethods for min-max optimization. Advances in Neural Information Processing Systems, 33:57895800,2020b. Min Yang, Linli Xu, Martha White, Dale Schuurmans, and Yao-liang Yu. Relaxed clipping: A global trainingmethod for robust regression and classication. Advances in neural information processing systems, 23,2010. Jinsung Yoon, Yao Zhang, James Jordon, and Mihaela van der Schaar. Vime: Extending the success ofself-and semi-supervised learning to tabular domain. Advances in Neural Information Processing Systems,33:1103311043, 2020.",
  "Runtian Zhai, Chen Dan, Zico Kolter, and Pradeep Ravikumar. Doro: Distributional and outlier robustoptimization. In International Conference on Machine Learning, pp. 1234512355. PMLR, 2021": "Dingwen Zhang, Deyu Meng, Chao Li, Lu Jiang, Qian Zhao, and Junwei Han. A self-paced multiple-instancelearning framework for co-saliency detection. In Proceedings of the IEEE international conference oncomputer vision, pp. 594602, 2015. Marvin Zhang, Henrik Marklund, Nikita Dhawan, Abhishek Gupta, Sergey Levine, and Chelsea Finn.Adaptive risk minimization: Learning to adapt to domain shift. Advances in Neural Information ProcessingSystems, 34:2366423678, 2021.",
  "A.1Per-Sample Reweighting": "In this section, we review data reweighting techniques developed outside of the DRO community. The ideaof re-weighting samples can be dated back to the works of Chawla et al. (2002); Zadrozny (2004), whichpre-computed per-sample weights using certain prior knowledge. Recent approaches alleviate the need forhuman supervision by dynamically computing the per-sample weights. One of the early works in this categoryis AdaBoost, which is a popular boosting algorithm (Freund & Schapire, 1997). Similar to RGD, AdaBoostuses exponential weighting mechanism to reweight data points. However, AdaBoost is used for learning anensemble of weak learners. Whereas, in this work, we are interested in learning a single model that canachieve better generalization guarantees. Furthermore, AdaBoost is only studied for supervised learning (inparticular, classication and regression). In contrast, RGD can be applied on any learning task. Recentworks of Leng et al. (2022); Lin et al. (2017) showed that certain modications to standard cross entropy loss -that involve truncating its Taylor-series expansion - can improve the performance of DNNs. These techniquescan be viewed as performing sample re-weighting. However, these techniques only apply to cross-entropy lossand are not easily extendable to general learning tasks. Other approaches based on meta-learning have been proposed for class imbalance and label noise (Shu et al.,2019; Ren et al., 2018; Gonzalez & Miikkulainen, 2021). Many popular approaches in this line of workrequire training a separate neural network for re-weighting the data points (Ren et al., 2018; Shu et al., 2019).However, these approaches are seldom used in practice as the underlying bi-level optimization problem ishard to implement (Ivanova & Ablin, 2023). Unlike these approaches, our RGD algorithm does not requirea separate neural network for re-weighting and thus doesnt add any computational overhead over vanillatraining. Moreover, compared to existing sample re-weighting techniques, our approach applies to variouslearning tasks (see ). Another line of work uses a history buer which stores a snapshot of thetrajectory of each point and facilitates giving more importance to points which leads to more learning in themodel (Zhang & Pster, 2021). Other approaches, such as Zhu et al. (2022b), use reinforcement learningto learn the per-sample weights using a pretraining-boosting two-stage MDP curriculum where the agentnetwork is rstly pre-trained and optimized for deployment in the classication problem. Another line ofwork has considered sample re-weighting in the presence of outliers (Kumar et al., 2010; De La Torre & Black,2003; Jiang et al., 2014a;b; Wang et al., 2017; Li et al., 2021; 2023). These works down-weight points withhigh-loss value. The rationality behind this lies in the idea that these high-loss samples are more likely to beoutliers and, thus, should be ignored during the training process. Finally, works such Castells et al. (2020)propose a condence-aware loss proportional to the lowest loss of that sample. They use a threshold () todecide how practical or important each point is.",
  "A.2Pre-conditioning": "Pre-conditioning can usually mean normalization of inputs, batch normalization, or scaling gradients in afew directions. This section predominantly discusses techniques that focus on scaling gradients in a fewdirections. A common technique to improve the training speed in deep learning is using adaptive step-sizeoptimization methods, such as the Newton method, which takes advantage of the second-order gradients.However, computing the Hessian matrix is computationally intensive, leading to Quasi-Newton methods:methods that approximate the value of the Hessian instead of computing them every time Le et al. (2011).Another popular alternative is to use an element-wise adaptive learning rate, which has shown great promisein deep learning. Some of the popular techniques here include ADAgrad (Duchi et al., 2011), RMSProp(Ruder, 2016), ADAdelta (Zeiler, 2012). For instance, ADAgrad is a diagonal pre-conditioning techniquewhere the pre-conditioning across each dimension is computed as the inverse square root of the norms ofgradients along that dimension accumulated over training. Unfortunately, this accumulation of gradientsmakes it susceptible to falling in a saddle point as the scaling factor decreases monotonically.",
  "A.3Curriculum Learning": "Another important research area that has explored data reweighting is Curriculum Learning (CL). CL,originally introduced by Bengio et al. (2009), is a vast domain focussing on how the model should be taught,and draws inspiration from how humans learn concepts. For instance, humans generally grasp on to easierconcepts such as basic shapes (triangle, rectangle, etc.) before moving on to learning signicantly morecomplex structures (heptagram, triquetra, etc.). Curriculum learning strategies have been widely used invarious areas of machine learning and involves nding a way to rank samples, as well as the right pacingfunctions for introducing more dicult data in our training. The techniques developed for CL have typicallyfocused on giving importance to easier samples at the beginning of training, and slowly progressing towardsharder samples (Bengio et al., 2009; Chen & Gupta, 2015; Tudor Ionescu et al., 2016; Pentina et al., 2015;Shi et al., 2015; Spitkovsky et al., 2010; Zaremba & Sutskever, 2014). In contrast, DRO focuses the learningon harder samples throughout the training process. That being said, there have also been a class of works inCL which showed the learning harder examples rst, and then moving to easier ones could lead to improvedperformance in certain conditions, through Hard Example mining (HEM) or anti-curriculum (Jesson et al.,2017; Shrivastava et al., 2016; Wang & Vasconcelos, 2018; Zhou et al., 2020; Braun et al., 2017; Pi et al., 2016).There have been predominantly three classes of CL, and various amalgamations of these in literature (Sovianyet al., 2022). Vanilla CL: The vanilla CL usually involves a pre-dened notion of hardness. For example, Bengio et al.(2009) used geometric shapes to clearly dierentiate easy and hard samples. Others such as Spitkovsky et al.(2010) exploited the length of sequences as a signal for diculty. Self-Paced Learning (SPCL): This diers from the vanilla CL with respect to the evaluation of diculty. Thisconcept of diculty is not known beforehand and is measured repeatedly during training. Works such asKumar et al. (2010) used the likelihood of the prediction to rank the samples. Other works such as Lee &Grauman (2011) used objectness as a measure to dene the training schedule. Balanced Curriculum (BCL): In addition to prior works such as vanilla CL and SPCL, balanced curriculumapproaches come with an added condition of diversity within a batch. These constraints (on classes, imageregions, etc.) help the model learn robust features and not overt to the spurious correlations of the easysamples (Zhang et al., 2015; Soviany, 2020). In this work, we will resort to only describing few works which focus on instance level reweighting of datapoints (Kumar et al., 2010; Li et al., 2017; Kumar et al., 2011; Pi et al., 2016; Liang et al., 2016; Fan et al.,",
  "A.4Comparison with existing KL-DRO optimization approaches": "In this section, we discuss a few more aspects of the related work that werent discussed in the main paper.We specically focus on prior works that developed algorithms for KL divergence based DRO. The earliestwork on KL-DRO dates back to 2013 by Hu & Hong (2012). However, it was only recently that these workshave become widespread in deep learning. The RECOVER algorithm by Qi et al. (2021) was one of theearly works to scale KL-DRO to deep neural networks. It attempted to solve the non-convex DRO problemwith a duality-free stochastic method by formulating the min-max formulation into an equivalent stochasticcompositional problem. ABSGD (Qi et al., 2023b) and SCDRO (Qi et al., 2023a) improved upon RECOVERby designing more ecient algorithms. However, the performance of these algorithms on large-scale modelsand datasets is not rigorously studied, as the Imagenet-LT, iNaturalist experiments conducted in these worksstarted from a pre-trained network and only netuned the last layer. In contrast, in this work, we learn theentire ViT-S model from scratch and show improved generalization.",
  "(a)= supP inf>0 EP [(z, )] (EP [log dP ] + log n ),": "where (a) follows from our choice of divergence, and the fact that the data points {zi}ni=1 are all unique (i.e,no repetitions). Observe that the objective in the last expression is concave in P and linear in . So themax-min problem above is concave-convex. Using Lagrangian duality to swap the order of min and max, weget",
  "t due to the step size with 1/": "T.We now convert the guarantees in Equation 3 to guarantees in terms of log f(). Let arg inf f(). Byour assupmption, (z; ) is bounded above and below. So log f(T ) log f() C(f(T ) f()) for someC. Combining this with equation 3, we conclude the statement of the proposition.",
  "CChoice of divergence in RGD": "RGD-RevKL is a more aggressive weighing scheme in comparison to RGD. This is fairly simple to showif you re-write both the reweighting techniques using Taylor series expansion. RGD-RevKL multipliesthe loss l with (1 + l + l2 + . . . ). Whereas, RGD multiplies the loss l with (1 + l + l2/2! + l3/3! + . . . ).RGD-RevKL is a more aggressive weighing scheme than RGD, and the choice between the two schemesshould depend on the problem. Some preliminary results on the class imbalance setting is depicted in .For RGD-2 g(u) = u + , we also clip u to be min(u, ). Similarly, for RGD-RevKL, g(u) =1",
  "D.1Hyperparameter Tuning": "In this section, we describe the common hyperparameter tuning space used across all experiments in ourpaper unless otherwise mentioned. The two parameters we tune were and lr. We use a simple grid searchfor in the order of across the experiments where the scaling factor () is by default set as1 +1.This allowed our loss to be bounded between 0,1 and helped fairly compare RGD-2and RGD. The lr wastuned by a proxy of lr_mult where we scaled the learning rate by a fraction in the range [0.5, 1.5]. The eectof these hyperparameters (, ) is further depicted in .2.",
  "D.1.1Existing KL-DRO techniques": "For TERM, we use the batch (non-hierarchical) version (as shown in Algorithm 1 of Li et al. (2023)) -requiring two degrees of hyperparameters (tilting coecient t and the learning rate (lr)). For the tiltingcoecient, we use a search space of Li et al. (2021): {0.2, 0.5, 1, 3, 5}. For the learning rate, we use a lrmultiplier to the baseline run as {0.7, 0.8, 0.9, 1, 1.1, 1.2, 1.3}. For the stochastic version of TERM, which isidentical to ABSGD (Qi et al., 2023b) baseline - requires an additional coecient of moving average (). Weuse a grid search space of {0.25, 0.5, 0.75} for tuning , and tune the learning rate in a similar fashion toTERM. We also tune (similar to the tilting coecient of TERM) in the search space {1, 3, 5, 7}.",
  "(c) L2 Distance (Rare feature)": ": (a) showing the convergence of SGD, RGD algorithms for estimating the linear regressionparameter. The L2 distance between the iterates () and the true parameter is studied in Figures 4(b)and 4(c). Specically, (b) depicts the squared error in the frequently appearing directions, whereall the techniques perform equally well. However, when it comes to learning rare directions, our proposedapproach is much better ((c)).",
  "D.3Comparisons against Sharpness Aware Minimization": "Below we compare with Sharpness-Aware Minimization (SAM) (Foret et al., 2021) both from theoreticaland empirical perspectives. From a theoretical perspective, SAM performs robust optimization in the weightspace (that is SAM tries to learn a model that is robust to perturbations of weights). In contrast, RGDperforms robust optimization in the distribution space. So, RGD and SAM are orthogonal to each otherand can potentially be merged together to boost the performance. In , we compare performance ofvarious approaches for CIFAR-10 optimization. It can be seen that RGD marginally boosts the performanceof SAM. Although, more thorough experiments are needed to understand the utility of RGD on top of SAM.",
  "D.4Class Imbalance Experiments": "This section briey discusses additional results from our experiments on the Class Imbalance domain withimbalanced CIFAR-10 and CIFAR-100 datasets. It is well known that DRO outputs models with good tailperformance (Duchi & Namkoong, 2018). Since RGD directly solves the DRO objective, our models are alsonaturally endowed with this property. To demonstrate this, we extend our experiments on linear regressionto a more realistic image dataset, where some classes appear very rarely in the data set while some appearvery frequently. We use the Long-Tailed CIFAR dataset, where we reduce the number of training samples perclass according to an exponential function as proposed by Cui et al. (2019). We dene the imbalance factorof a dataset as the number of training samples in the largest class divided by the smallest. Similar to theworks of Shu et al. (2019), we use a ResNet-32 architecture for training. Apart from Cross Entropy loss, wealso include Focal Loss (Lin et al., 2017) and Class Balanced Loss (Cui et al., 2019) as additional baselines.We also experimented with the long-tailed CIFAR-100 dataset and showed that our proposed approach couldagain show signicant improvements. illustrates the performance of our approach in comparison toother state-of-the-art methods. Overall, in comparison to the SOTA approach in this task (Class BalancedLoss), our proposed approach brings about an improvement of +0.79%. A more comprehensive comparisonwith additional state-of-the-art baselines such as L2RW (Ren et al., 2018), and Meta-Weight-Net (Shu et al.,2019) is illustrated in . Although these models use additional data as a meta-validation-set, ourproposed approach outperforms L2RW and is roughly competitive with the Meta-Weight-Net model. depicts the accuracy metric of models on various levels of the imbalance factor. From , weshow that our proposed approach RGD outperforms other baselines such as Focal Loss and Class BalancedLoss by +0.79%. Furthermore, when models are trained on additional data, either by ne-tuning or byusing a meta-learning framework to learn weights (such as Meta-Weight-Net and L2RW), we show thatour proposed approach is competitively similar (-0.22%). illustrates this analysis further. The",
  "Cross Entropy (CE)": "Default65.9870.3674.8182.2386.3992.8978.7834.8438.3243.8551.1455.7170.5049.06RGD-RevKL (Ours)64.1672.5677.8683.8886.8492.9979.7236.2239.8743.7451.8656.970.8049.90RGD (Ours)67.9073.7579.6385.4488.0093.2781.3338.6241.8946.4053.4858.571.3051.70 : Test Accuracy of ResNet-32 on Long-Tailed CIFAR-10, and CIFAR-100 dataset. We use the symbol to denote approaches that use additional data (as the meta-dataset). We use underline symbol to depictperformances which are second-best across baselines. Our experiments show that we can get competitivelysimilar performance to such models as well without training a second neural network.",
  "D.5Vanilla Classication": "This section briey discusses a few additional results from our experiments on standard supervised learning(in particular vanilla classication). depicts the performance of our other variant RGD-RevKL incomparison to the baseline approach. EcientNet netuning.We also show ne-tuning improvements of EcientNet-v2-l over various taskssuch as Cars and Food101 as depicted in . In these experiments, we take a pre-trained EcientNetbackbone and ne-tune it for various tasks.",
  "in . Note that similar to our setup in ViT-S on Imagenet-1K benchmark, we perform no tuning, andsimply use = 1, and same learning rate as baseline": "MLP for classication.We also demonstrate that our proposed approach is simple and shows signicantimprovements, not only for SOTA approaches but also basic MLP procedures as depicted in , ,and . These tables help showcase that the simple addition of our proposed approach does showsignicant improvements of +2.77% (in accuracy) on multi-class and +1.77% (in AUROC) on binary classtasks respectively.",
  "Default78.180.0592.0392.65RGD (Ours)79.080.1392.6292.75": "MiniGPT Pre-training.We extend our work to large-scale tasks in NLP such as LLM pre-training whichhas become more prevalent over the recent years. Our experiments on miniGPT pre-training, as illustrated inthis section, showcase the ecacy of our approach in these settings. miniGPT (Zhu et al., 2024) is a minimalimplementation of a decoder-only transformer language model. We consider a 6 layer model and train on thelm1B small dataset which has 1B tokens. We trained for 100K steps with a batch size of 256. We used thedefault learning rate of 0.0016 for the baseline. For RGD, we x the clipping threshold to 1 and tune thelearning rate. We achieved 1% improvement on the eval log-perplexity score. illustrates our resultsin this setting.",
  "D.6Tabular Classication": "This section discusses a few additional results from our experiments on Tabular classication. depicts our proposed approachs accuracy compared to other baselines on multi-class tabular datasets. Ourmethod outperforms previous SOTA in this problem by +1.27%. Furthermore, illustrates theAUROC score of our proposed approach in comparison to state-of-the-art baselines on binary-class tabulardatasets. Our approach shows an improvement of +1.5% in this setting as well. The performance metrics ofthe baseline approaches were taken from Majmundar et al. (2022).",
  "D.7Meta-Learning": "This section discusses some additional results from our experiments in the meta-learning domain. depicts a complete table and comparison of our proposed approach on the MAML baseline compared to others.Overall, we notice improvement across the board, especially in the outliers, as shown in the Worst-k% metrics.Note that although our RGD has been applied on MAML (Finn et al., 2017) in our current experiments,our approach is analogous to the model and can be extended to other meta-learning techniques such asProtonet (Snell et al., 2017), CNAPs (Requeima et al., 2019), etc. as well. The performance metrics of thebaseline approaches were taken from (Kumar et al., 2023).",
  "D.8.1DomainBed Benchmark": "In this section, we describe the DomainBed benchmark, a challenging benchmark used to study the out-of-domain generalization capabilities of our model. To briey explain, consider the dataset PACS, which consistsof Photos, Art, cartoons, and sketches of the same set of classes (for instance, dogs and cats, amongst others).The goal of the task is to learn from three of these domains and evaluate the performance of the left-outdomain (similar to a k-fold cross-validation). By doing so, we can assess the out-of-domain generalizationperformance of our models. In general, the metric used in this domain involves taking an average of theperformance of the dierent k-fold splits. More information about this benchmark is available at Gulrajani &Lopez-Paz (2021).",
  "AlgorithmPACSVLCSOfficeHomeDomainNetAvg": "ERM Gulrajani & Lopez-Paz (2021)85.5 0.177.5 0.466.5 0.240.9 0.167.6IRM Arjovsky et al. (2019)83.5 0.878.5 0.564.3 2.233.9 2.865.1GroupDRO Sagawa* et al. (2020)84.4 0.876.7 0.666.0 0.733.3 0.265.1Mixup Yan et al. (2020a)84.6 0.677.4 0.668.1 0.339.2 0.167.33MLDG Li et al. (2018a)84.9 1.077.2 0.466.8 0.641.2 0.167.53CORAL Sun & Saenko (2016)86.2 0.378.8 0.668.7 0.341.5 0.168.8MMD Li et al. (2018b)84.6 0.577.5 0.966.3 0.123.4 9.562.95DANN Ganin et al. (2016)83.6 0.478.6 0.465.9 0.638.3 0.166.6CDANN Li et al. (2018c)82.6 0.977.5 0.165.8 1.338.3 0.366.05MTL Blanchard et al. (2021)84.6 0.577.2 0.466.4 0.540.6 0.167.2SagNet Nam et al. (2021)86.3 0.277.8 0.568.1 0.140.3 0.168.13ARM Zhang et al. (2021)85.1 0.477.6 0.364.8 0.335.5 0.265.75VREx Krueger et al. (2021)84.9 0.678.3 0.266.4 0.633.6 2.965.8RSC Huang et al. (2020)85.2 0.977.1 0.565.5 0.938.9 0.566.68MIRO Cha et al. (2022)85.4 0.479.0 0.070.5 0.444.3 0.269.8",
  "AlgorithmACPSAvg": "CDANN84.6 1.875.5 0.996.8 0.373.5 0.682.6MASF82.980.595.072.382.7DMG82.678.194.578.383.4IRM84.8 1.376.4 1.196.7 0.676.1 1.083.5MetaReg87.279.297.670.383.6DANN86.4 0.877.4 0.897.3 0.473.5 2.383.7GroupDRO83.5 0.979.1 0.696.7 0.378.3 2.084.4MTL87.5 0.877.1 0.596.4 0.877.3 1.884.6I-Mixup86.1 0.578.9 0.897.6 0.175.8 1.884.6MMD86.1 1.479.4 0.996.6 0.276.5 0.584.7VREx86.0 1.679.1 0.696.9 0.577.7 1.784.9MLDG85.5 1.480.1 1.797.4 0.376.6 1.184.9ARM86.8 0.676.8 0.597.4 0.379.3 1.285.1RSC85.4 0.879.7 1.897.6 0.378.2 1.285.2Mixstyle86.8 0.579.0 1.496.6 0.178.5 2.385.2ER87.579.398.376.385.3pAdaIN85.881.197.277.485.4ERM84.7 0.480.8 0.697.2 0.379.3 1.085.5EISNet86.681.597.178.185.8CORAL88.3 0.280.0 0.597.5 0.378.8 1.386.2SagNet87.4 1.080.7 0.697.1 0.180.0 0.486.3DSON87.080.696.082.986.6",
  "D.9Convergence of RGD and additional costs": "Convergence in extreme class imbalance setting:In the extreme class imbalance setting, we notethat uniform sampling for mini-batch generation + RGD re-weighting (as done in Algorithm 1) would beslower to converge than using importance sampling for mini-batch generation. This is because the formertends to have higher variance. But this is easily xable in Algorithm 1. We simply update the mini-batchgeneration step with importance sampling; that is, we select point i with probability proportional to itsweight exp(i) (instead of uniform sampling that is currently done). The main reason for not considering thisin this work is our desire to illustrate the generality of our approach and its applicability to a wide varietyof learning tasks, without focusing too much on the class imbalance task. We believe this generality andsimplicity is what makes our method quite attractive to the practitioner as showcased in some of experimentsincluding Natural Language Processing, Image Classication, Tabular Classication, Distribution Shifts, andMeta-learning. Furthermore, illustrates the convergence plots of miniGPT pre-training and ViT-Son Imagenet-1K. Overall, we note similar stable training convergence on both, while RGD is able to focusmore heavily on harder samples and reach a better minima.",
  "AlgorithmCLSVAvg": "GroupDRO97.3 0.363.4 0.969.5 0.876.7 0.776.7RSC97.9 0.162.5 0.772.3 1.275.6 0.877.1MLDG97.4 0.265.2 0.771.0 1.475.3 1.077.2MTL97.8 0.464.3 0.371.5 0.775.3 1.777.2I-Mixup98.3 0.664.8 1.072.1 0.574.3 0.877.4ERM97.7 0.464.3 0.973.4 0.574.6 1.377.5MMD97.7 0.164.0 1.172.8 0.275.3 3.377.5CDANN97.1 0.365.1 1.270.7 0.877.1 1.577.5ARM98.7 0.263.6 0.771.3 1.276.7 0.677.6SagNet97.9 0.464.5 0.571.4 1.377.5 0.577.8Mixstyle98.6 0.364.5 1.172.6 0.575.7 1.777.9VREx98.4 0.364.4 1.474.1 0.476.2 1.378.3IRM98.6 0.164.9 0.973.4 0.677.3 0.978.6DANN99.0 0.365.1 1.473.1 0.377.2 0.678.6CORAL98.3 0.166.1 1.273.4 0.377.5 1.278.8",
  "AlgorithmACPRAvg": "Mixstyle51.1 0.353.2 0.468.2 0.769.2 0.660.4IRM58.9 2.352.2 1.672.1 2.974.0 2.564.3ARM58.9 0.851.0 0.574.1 0.175.2 0.364.8RSC60.7 1.451.4 0.374.8 1.175.1 1.365.5CDANN61.5 1.450.4 2.474.4 0.976.6 0.865.7DANN59.9 1.353.0 0.373.6 0.776.9 0.565.9GroupDRO60.4 0.752.7 1.075.0 0.776.0 0.766.0MMD60.4 0.253.3 0.374.3 0.177.4 0.666.4MTL61.5 0.752.4 0.674.9 0.476.8 0.466.4VREx60.7 0.953.0 0.975.3 0.176.6 0.566.4ERM61.3 0.752.4 0.375.8 0.176.6 0.366.5MLDG61.5 0.953.2 0.675.0 1.277.5 0.466.8I-Mixup62.4 0.854.8 0.676.9 0.378.3 0.268.1SagNet63.4 0.254.8 0.475.8 0.478.3 0.368.1CORAL65.3 0.454.4 0.576.5 0.178.4 0.568.7",
  "AlgorithmclipinfopaintquickrealsketchAvg": "MMD32.1 13.311.0 4.626.8 11.38.7 2.132.7 13.828.9 11.923.4GroupDRO47.2 0.517.5 0.433.8 0.59.3 0.351.6 0.440.1 0.633.3VREx47.3 3.516.0 1.535.8 4.610.9 0.349.6 4.942.0 3.033.6IRM48.5 2.815.0 1.538.3 4.310.9 0.548.2 5.242.3 3.133.9Mixstyle51.9 0.413.3 0.237.0 0.512.3 0.146.1 0.343.4 0.434.0ARM49.7 0.316.3 0.540.9 1.19.4 0.153.4 0.443.5 0.435.5CDANN54.6 0.417.3 0.143.7 0.912.1 0.756.2 0.445.9 0.538.3DANN53.1 0.218.3 0.144.2 0.711.8 0.155.5 0.446.8 0.638.3RSC55.0 1.218.3 0.544.4 0.612.2 0.255.7 0.747.8 0.938.9I-Mixup55.7 0.318.5 0.544.3 0.512.5 0.455.8 0.348.2 0.539.2SagNet57.7 0.319.0 0.245.3 0.312.7 0.558.1 0.548.8 0.240.3MTL57.9 0.518.5 0.446.0 0.112.5 0.159.5 0.349.2 0.140.6ERM58.1 0.318.8 0.346.7 0.312.2 0.459.6 0.149.8 0.440.9MLDG59.1 0.219.1 0.345.8 0.713.4 0.359.6 0.250.2 0.441.2CORAL59.2 0.119.7 0.246.6 0.313.4 0.459.8 0.250.1 0.641.5MetaReg59.825.650.211.564.650.143.6DMG65.222.250.015.759.649.043.6"
}