{
  "Abstract": "In the fast-evolving domain of artificial intelligence, large language models (LLMs) suchas GPT-3 and GPT-4 are revolutionizing the landscapes of finance, healthcare, and law:domains characterized by their reliance on professional expertise, challenging data acquisition,high-stakes, and stringent regulatory compliance. This survey offers a detailed explorationof the methodologies, applications, challenges, and forward-looking opportunities of LLMswithin these high-stakes sectors. We highlight the instrumental role of LLMs in enhancingdiagnostic and treatment methodologies in healthcare, innovating financial analytics, andrefining legal interpretation and compliance strategies. Moreover, we critically examine theethics for LLM applications in these fields, pointing out the existing ethical concerns andthe need for transparent, fair, and robust AI systems that respect regulatory norms. Bypresenting a thorough review of current literature and practical applications, we showcase thetransformative impact of LLMs, and outline the imperative for interdisciplinary cooperation,methodological advancements, and ethical vigilance. Through this lens, we aim to sparkdialogue and inspire future research dedicated to maximizing the benefits of LLMs whilemitigating their risks in these precision-dependent sectors. To facilitate future research onLLMs in these critical societal domains, we also initiate a reading list that tracks the latestadvancements under this topic, which will be released and continually updated1.",
  "Introduction": "The advent of large language models (LLMs) such as ChatGPT (OpenAI, 2022) and GPT-4 (Achiam et al.,2023) marks a significant milestone in the evolution of artificial intelligence. The research integrating LLMswith various disciplines, i.e., LLM+X, such as math, science, finance, healthcare, law, etc., is starting asa new epoch powered by collaborative endeavors spanning diverse communities. In this survey paper, weoffer an exploration of the methodologies, applications, challenges, ethics, and future opportunities of LLMswithin critical societal domains, including finance, healthcare, and law. In this paper, we employ theacronym \"FHL\" to denote these three domains. These domains are major cornerstones of societal functionand well-being, each playing a critical role in the fabric of daily life and the broader economic and social",
  "Published in Transactions on Machine Learning Research (11/2024)": "Yuhao Zhang, Hang Jiang, Yasuhide Miura, Christopher D Manning, and Curtis P Langlotz. Contrastivelearning of medical visual representations from paired images and text. In Machine Learning for HealthcareConference, pp. 225. PMLR, 2022. Zhuosheng Zhang, Hanqing Zhang, Keming Chen, Yuhang Guo, Jingyun Hua, Yulong Wang, and Ming Zhou.Mengzi: Towards lightweight yet ingenious pre-trained models for chinese. CoRR, abs/2110.06696, 2021.URL Haiyan Zhao, Hanjie Chen, Fan Yang, Ninghao Liu, Huiqi Deng, Hengyi Cai, Shuaiqiang Wang, Dawei Yin,and Mengnan Du. Explainability for large language models: A survey. ACM Transactions on IntelligentSystems and Technology, 15(2):138, 2024. Wayne Xin Zhao, Kun Zhou, Junyi Li, Tianyi Tang, Xiaolei Wang, Yupeng Hou, Yingqian Min, Beichen Zhang,Junjie Zhang, Zican Dong, et al. A survey of large language models. arXiv preprint arXiv:2303.18223,2023a. Yilun Zhao, Yunxiang Li, Chenying Li, and Rui Zhang. MultiHiertt: Numerical reasoning over multihierarchical tabular and textual data. In Smaranda Muresan, Preslav Nakov, and Aline Villavicencio(eds.), Proceedings of the 60th Annual Meeting of the Association for Computational Linguistics (Volume 1:Long Papers), pp. 65886600, Dublin, Ireland, May 2022. Association for Computational Linguistics. doi:10.18653/v1/2022.acl-long.454. URL",
  "Related Surveys": "Along with the rapidly evolving LLM research, there is a surge of LLM-related survey literature that exploresa wide range of perspectives and aspects of LLM development. In addition to the surveys investigating theoverall development of LLMs (Zhao et al., 2023a; Min et al., 2023a), recent surveys include fine-grained areassuch as alignment (Shen et al., 2023a; Wang et al., 2023d; Liu et al., 2023d), augmentation (Mialon et al.,2023; Gao et al., 2023b), instruction tuning (Zhang et al., 2023e), reasoning (Huang & Chang, 2022; Qiaoet al., 2022), compression (Zhu et al., 2023a), evaluation (Chang et al., 2023), explainability (Zhao et al.,2024), and hallucination (Zhang et al., 2023l; Huang et al., 2023), as well as bias, fairness, and safety (Gallegoset al., 2023; Navigli et al., 2023; Li et al., 2023e; Weidinger et al., 2021; Yao et al., 2024; Shayegani et al.,2023). Surveys on LLM-based research in NLP tasks are also prevalent, such as text generation (Li et al.,2022a; Zhang et al., 2023c), code generation (Zan et al., 2022), information retrieval (Zhu et al., 2023b),recommendation (Wu et al., 2023c), etc. As the study of LLM+X becomes increasingly popular, surveys inthis direction have also begun to emerge in domains such as robotics (Zeng et al., 2023), education (Yanet al., 2024b), software engineering (Fan et al., 2023), causal inference (Liu et al., 2024c), etc. In contrastwith existing surveys that mostly focus on LLM integration for NLP tasks or STEM disciplines, our surveyinvestigates LLMs in three critical societal sectors FHL domains. In the finance domain, there are existing surveys on AI, machine learning, or deep learning in finance (Cao,2022; Cao & Zhai, 2022; Maple et al., 2023; Ozbayoglu et al., 2020; Rundo et al., 2019), as well as generalNLP techniques in finance (Xing et al., 2018; Fisher et al., 2016; Gao et al., 2021b; Gupta et al., 2020;Kumar & Ravi, 2016). In contrast, our survey focuses on cutting-edge LLM development in finance. Theworks by Li et al. (2023g) and Lee et al. (2024) address LLM techniques in finance. However, they primarilyintroduce general LLM techniques, financial-specific LLMs, and financial tasks. In contrast, our surveyon finance not only covers more thorough explorations of financial tasks and financial-specific LLMs, butalso investigates performance comparisons and analysis for LLMs, offering insights and guidance for futureresearch. Furthermore, our survey explores LLM-based methodologies and adjacent research, concludingwith a broad discussion of future prospects, emphasizing their implications for critical societal sectors from acomprehensive range of viewpoints. In the medical domain, previous studies have extensively explored applications of machine learning (Garg &Mago, 2021; Shehab et al., 2022) and deep learning (Piccialli et al., 2021; Egger et al., 2022; Miotto et al.,2018), with specific emphasis on NLP within medical contexts (Chary et al., 2019; Wu et al., 2020; Liu et al.,2022; Kalyan & Sangeetha, 2020). Our survey broadens the scope by including LLMs and their diverseapplications in the medical field. Concurrently, Zhou et al. (2024a); Bedi et al. (2024); Omiye et al. (2024)investigate LLMs in the medical domain focusing primarily on single modality applications, while anotherwork Hartsock & Rasool (2024) focused on medical Visual Question Answering (VQA) and report generationspecifically. Our work encompasses a broader spectrum, surveying various applications in both the pure NLPdomain and multimodal scenarios. We also discuss recent novel tasks such as medical instruction followingand medical imaging classification via natural language. In the law domain, there are existing surveys on AI in law (Chalkidis & Kampas, 2019; Cui et al., 2023b;Dias et al., 2022), our work improves the focus on current developments in LLMs within the legal area. Whilethe studies by Katz et al. (2023) and Sun (2023) provide an overview of LLM techniques in legal contexts,they primarily discuss generalized LLM techniques alongside legal-specific LLMs and tasks. Our analysisextends beyond these initial explorations, offering a comprehensive examination of legal tasks catered toby legal-specific LLMs and conducting in-depth performance comparisons and analytical reviews of LLMs.This affords pivotal insights and directional guidance for burgeoning research. Furthermore, our surveyexplores LLM-based methodologies and allied areas of study, ultimately leading to an expansive discourse onfuture prospects. We place particular emphasis on the augmentation of datasets and the consideration of",
  "Differences from existing surveys. We summarize the main differences between our survey and existingones as follows:": "Scope. Unlike existing surveys that predominantly explore LLMs in general areas, our study uniquelyfocuses on LLMs across the three critical societal sectors of FHL. More specifically, our study notonly offers a unified high-level overview of the common ground of FHL areas, but also provides anin-depth review within each sector. This dual perspective ensures that our paper stands apart fromgeneral LLM-related surveys, as well as studies focusing on single application domains. Depth. Our survey delves deeper than existing literature of LLMs in within FHL domains. Eachsector includes a thorough review covering tasks, techniques, evaluations, future prospects, anddomain-specific ethics. The depth and breadth are both more extensive and integrative than existingrelated surveys. Contribution. (1) To the best of our knowledge, we are the first to provide a comprehensive viewof LLM across the FHL sectors and highlighting their importance, connections, and challenges. (2)Our work meticulously reviews and organizes existing research into a well-structured categorizationthat spans problems, methodologies, experiments, critical analyses, ethical discussions specific toeach sector. (3) We identify and outline promising future research directions in LLM studies withinthe FHL domains.",
  "Finance": "In this Section, we introduce the existing NLP tasks in the finance domain, including task formulations anddatasets. In 3.2, we investigate various Pre-trained Language Models (PLMs) and LLMs developed forfinance. In 3.3, we study the evaluations and analysis of the performance of various LLMs. In 3.4, westudy various LLM-based methodologies developed for financial tasks and challenges. Finally, we summarizeinsights, make conclusions, and discuss potential future directions.",
  "Tasks and Datasets in Financial NLP": "In this section we introduce existing financial tasks and datasets studied extensively using LLM-relatedmethods, including sentiment analysis, information extraction, question answering, text-enhanced stockmovement prediction, and others. We also discuss additional financial NLP tasks that are mostly under-explored for LLM-based methods, suggesting future research opportunities. provides a summary ofexisting financial NLP tasks. Sentiment Analysis (SA). The task of financial sentiment analysis aims at analyzing textual data relatedto finance, such as news articles, analyst reports, and social media posts, to gauge the sentiment or moodconveyed about specific financial instruments, markets, or the economy as a whole. An automatic analysis ofthe sentiments can help investors, analysts, and financial institutions to make more informed decisions byproviding insights into market sentiment that might not be immediately apparent from quantitative data.",
  "Financial NLP TasksUnder-Explored for LLMs": "Financial fraud detection (West & Bhattacharya, 2016),Risk assessment and management (Aziz & Dowling, 2019)(Peng & Yan, 2021; Mashrur et al., 2020),Robo advisor (Day et al., 2018; Bhatia et al., 2021)(Huang et al., 2024),Compliance and regulations (Al-Shabandar et al., 2019)(Neill et al., 2017),Chatbot services (Okuda & Shoda, 2018; Hwang & Kim, 2021)(Wube et al., 2022)",
  ": A summarization of existing financial NLP tasks and representative datasets. The yellow fieldshows the tasks relatively under-explored for LLMs": "The task of financial sentiment analysis is often formulated as a classification problem, with the input as thetext to be analyzed and the target label as sentiment orientations such as positive, negative, or neutral. TheFinancial Phrase Bank dataset (Malo et al., 2014) is based on company news (in English), with the targetsentiment categories from the investors perspective. The FiQA2 Task 1 focuses on aspect-based financialsentiment analysis, where the target is given as continuous numeric values. TweetFinSent (Pei et al., 2022) isanother dataset based on stock tweets. The authors propose a new concept of sentiment labels indicating theopinion of stock movement forecasting. FinSent (Guo et al., 2023) is another sentiment classification datasetbased on sentences from analyst reports of S&P 500 firms. In the evaluation of the financial language modelBloombergGPT (Wu et al., 2023d), the authors also propose a set of sentiment analysis datasets. Information Extraction (IE). Information extraction involves several key tasks that are essential foranalyzing and understanding financial texts. Named Entity Recognition (NER) targets identificationand classification of key entities in text, such as company names, stock symbols, financial metrics, andmonetary values. In (Alvarado et al., 2015), a NER dataset is proposed, aiming at extracting fields ofinterest for risk assessment in financial agreements. In BloombergGPT (Wu et al., 2023d), the internalfinancial datasets proposed include NER over various sources. Relation Extraction (RE) focuses onidentifying and categorizing finance-specific semantic relationships between the entities, such as cost_of,",
  "Instruction fine-tuning approaches": "FinMA (Xie et al., 2023)LlaMASA, IE, QA, SMP, OthersEnglish7B, 30B2023Instruct-FinGPT (Zhang et al., 2023a)LlaMA-7BSAEnglish7B2023InvestLM (Yang et al., 2023a)LlaMA-65BSA, QA, OthersEnglish65B2023FinGPT (Wang et al., 2023c)Six 7B modelsSA, IE, OthersEnglish6B, 7B2023CFGPT (Li et al., 2023c)InternLM-7BOthersChinese7B2023DISC-FinLLM (Chen et al., 2023b)Baichuan-13BSA, IE, QA, OthersChinese13B2023FinMA-ES (Zhang et al., 2024b)LlaMA2-7BSA, IE, QA, SMP, OthersEnglish, Spanish7B2024FinTral (Bhatia et al., 2024)Mistral-7BSA, IE, QA, SMP, OthersEnglish7B2024 : Summary of financial pre-trained language models. For evaluation tasks, we have SA for sentimentanalysis, IE for information extraction, QA for question answering, SMP for text-enhanced stock movementprediction, and Others for other tasks out of the above three major categories. For the time of release, wereport the initial release year of each work. task of financial investment opinion generation based on analyst reports to evaluate the LLMs ability toconduct financial reasoning for investment decision-making. In (Mukherjee et al., 2022), the authors proposea dataset for bullet-point summarization from long earnings call transcripts. Financial NLP Tasks Under-Explored for LLMs. The above four categories summarize the currenttasks and datasets covered in LLM-related studies. The overall financial NLP space is broader and stillhas many existing tasks under explored for LLMs. Financial fraud detection is a critical issue with severeconsequences in financial activities. There are numerous studies spanning data mining and NLP techniquesfor financial fraud detection (West & Bhattacharya, 2016; Throckmorton et al., 2015; Seemakurthi et al.,2015; Goel & Uzuner, 2016; Pandey, 2017; Chen et al., 2017; Boulieris et al., 2023; Craja et al., 2020;Calafato et al., 2016), such as detecting fraud in transactions, financial statements, annual reports, tax, etc.Research studies on financial fraud detection using LLM-based methods are largely under-explored. Othertasks remaining relatively open for LLM research include financial risk assessment and management (Aziz& Dowling, 2019; Peng & Yan, 2021; Mashrur et al., 2020; Cheng et al., 2021; Li et al., 2020a; Zou et al.,2017; Giudici, 2018), robo advisor (Day et al., 2018; Bhatia et al., 2021; Huang et al., 2024), compliance andregulations (Al-Shabandar et al., 2019; Neill et al., 2017), chatbot services (Okuda & Shoda, 2018; Hwang &Kim, 2021; Wube et al., 2022), etc. These tasks mostly lack well-defined formulations and well-establishedpublic datasets due to their complexity. Given their importance in the financial sector, they are all valuablefuture directions for incorporating LLM-based research.",
  "Financial LLMs": "Since the invention of BERT (Devlin et al., 2019), there have been numerous efforts to build PLMs andLLMs specialized for finance. These LMs typically utilize the same modeling architecture as those designedfor general domains. Most works conduct continuous training over existing pre-trained models on the generaldomain; a few works pre-train the model from scratch using the financial corpus like BloombergGPT (Wuet al., 2023d). The primary distinctions for different financial LMs arise from the training data and thespecific training paradigms employed. Consistent with the evolving training paradigms of general PLMs andLLMs, early financial PLMs adopted the pre-training followed by downstream task fine-tuning paradigm andtrained relatively small language models. Recent works scaled the model sizes up and conducted instructionfine-tuning, with the evaluation covering broader sets of financial tasks. Most existing financial LLMs are",
  "GPT-3.5 (zero-shot)0.780.780.760.720.29GPT-3.5 (few-shot)0.790.790.780.750.52GPT-4 (zero-shot)0.830.830.870.840.36GPT-4 (few-shot)0.860.860.880.860.57": ": Performance comparisons for sentiment analysis tasks (FPB dataset (Malo et al., 2014) and FiQA-SAdataset8), headline classification task (Headline dataset (Sinha & Khandait, 2020)), and IE task (NER FIN3dataset (Alvarado et al., 2015)). The few-shot setting is five shots for FPB, FiQA-SA, and Headline, andtwenty shots for NER FIN3. For Fine-tuning the model, we select the best performance achieved throughfine-tuning models in each dataset respectively. We aggregate the results from (Li et al., 2023d; Xie et al.,2023; Yang et al., 2023a). Note that some results reported for the same model in the above three papersdiffer, mostly for GPT-3.5 and GPT-4, which may need further verifications. et al., 2023b) is a Chinese model based on instruction fine-tuning on Baichuan-13B6, that performs instructionfine-tuning on separate LoRA (Hu et al., 2022) modules for each type of task. FinGPT (Wang et al., 2023c)is a series of 6B/7B models trained with instruction fine-tuning. In (Liu et al., 2023c), the authors proposea framework FinGPT consisting of data collection and processing pipeline from diverse sources, as well asfinancial LLM fine-tuning using reinforcement learning with stock prices. Most recently, researchers havebegun to explore financial LLMs in broader settings. In (Zhang et al., 2024b), the authors propose instructiondatasets, fine-tuned model FinMA-ES, and evaluation benchmarks in a bilingual setting of Spanish andEnglish. FinTral (Bhatia et al., 2024) is a series of multimodal LLMs based on Mistral-7B (Jiang et al., 2023).The authors incorporate tool usage (Schick et al., 2023), retrieval-augmented generation (RAG) (Lewis et al.,2020), and visual understanding based on CLIP (Radford et al., 2021a). This allows the authors to exploremultimodal contexts, and to include visual reasoning tasks such as question answering over charts and graphs.Despite being pre-trained and instruction-tuned on multimodal data, the FinTral-DPO model underperformson visual reasoning tasks compared to other SotA multimodal LLMs such as Qwen-VL-Plus (Bai et al., 2023),and GPT-4V (Achiam et al., 2023), but is on par or better than open-source LLMs of similar size. Thesechallenges point to the need for cross-disciplinary research at the intersection of Multimodal LLMs (MLLMs),quantitative reasoners, and financial LLMs.",
  "Evaluation and Analysis": "Performance Evaluation and Analysis for Popular Financial Tasks.In (Li et al., 2023d; Xieet al., 2023; Yang et al., 2023a), the authors conducted experiments on several popular financial datasetsusing an array of methods. In this survey, we summarize the performances of representative LLMs on fivewidely recognized datasets, which have been validated by the research community for their high quality andare frequently employed as benchmarks. summarizes the performance of various methods on twosentiment analysis datasets, one headline classification task, and one NER dataset. For sentiment analysis,GPT-4 and the recent instruction fine-tuning models like FinMA (Xie et al., 2023) achieve similar performanceas the best fine-tuning methods. For headline classification, FinMA also slightly surpasses the best fine-tuningmethod. We anticipate that the performances on such datasets have nearly reached saturation. As suggestedby (Li et al., 2023d), adopting generalist LLMs could be an easy choice for relatively simple financial tasks.",
  "QANet is the RoBERTa-based model in (Chen et al., 2021b); The instruction fine-tuning methods include": "FinMA (Xie et al., 2023) and InvestLM (Yang et al., 2023a); The general-purpose LLMs include LlaMA-65B, GPT-3.5 and GPT-4, with zero-shot (0), few-shot (3 shots), and CoT prompting; We also list thehuman expert and general crowd performances . Results are sourced from (Li et al., 2023d; Xie et al., 2023;Yang et al., 2023a). For IE tasks like NER, there is still a gap between LLMs and fine-tuning methods. On the relation extractiondataset REFinD (Kaur et al., 2023), CPT-3.5 and GPT-4 still largely fall behind the fine-tuning model (Liet al., 2023d). shows the performance comparisons between various methods on the FinQA dataset (Chen et al.,2021b). Large, general LLMs like GPT-4 still achieve the leading performances with simple prompts, dueto the strong knowledge and reasoning ability achieved during pre-training. Domain-specific fine-tuningmodels follow behind. Instruction fine-tuning models fall far behind compared to the former. Note that inthe construction of instruction fine-tuning data in the FinMA (Xie et al., 2023) model, the authors did notinclude the generation of reasoning programs in the FinQA dataset (Chen et al., 2021b), which could be amajor reason for the inferior performance on the FinQA dataset. Therefore, we anticipate that there is stillample room for developing open-source instruction fine-tuning models to improve on tasks requiring complexreasoning abilities. As demonstrated by (Li et al., 2023d), in most financial tasks, GPT-4 can achieve an over 10% performanceincrease over ChatGPT. Except for the QA task on FinQA (Chen et al., 2021b) and ConvFinQA (Chen et al.,2022), ChatGPT and GPT-4 perform either comparable or less effective than task-specific fine-tuned models.For FinQA (Chen et al., 2021b) and ConvFinQA (Chen et al., 2022), the authors argue that the reasoningcomplexity involved is still deemed as basic in financial analysis, but ChatGPT and GPT-4 still make simpleerrors. Significant improvement is required to adopt these LLMs as trustworthy financial analyst agents inreal-world industry usages. New Evaluation Frameworks and Tasks.In (Guo et al., 2023), a financial language model evaluationframework, FinLMEval, is proposed consisting of a set of classification tasks and NER. The authors comparethe performances of fine-tuned encoder-only models, such as BERT (Devlin et al., 2019) and RoBERTa (Liuet al., 2019), and zero-shot decoder-only models, such as GPT-4 (Achiam et al., 2023) and FinMA (Xie et al.,2023). Though achieving considerable performance, the zero-shot decoder-only models mostly fall behindfine-tuned encoder-only models on these tasks. The performance gap between the fine-tuned encoder-onlymodels and zero-shot decoder-only models is larger on their proposed proprietary datasets than on publicdatasets. The authors conclude that there remains room for enhancement for more advanced LLMs in thefinancial NLP field. Most recently, in (Xie et al., 2024b), the authors propose a large collection of evaluationbenchmarks for financial tasks containing 35 datasets across 23 financial tasks. They conclude that GPT-4",
  "mostly performs the best in quantification, extraction, understanding, and trading tasks, and the recentGoogle Gemini (Team et al., 2023) leads in generation and forecasting tasks": "In (Son et al., 2023), the authors propose the task of financial investment opinion generation based on analystreports, to evaluate the ability of various LLMs, with and without instruction fine-tuning, to conduct financialreasoning for investment decision-making. The authors conducted experiments on a series of 2.8B to 13Bmodels and concluded that the ability to generate coherent investment opinion first emerges at 6B models, andobtains improvements with instruction-tuning or larger datasets. In (Lopez-Lira & Tang, 2023), the authorsstudy the ability of LLMs to predict stock market returns. It is found that GPT-4 outperforms other LLMsbeing studied on forecasting returns and delivers the highest Sharpe ratio, suggesting the great potential ofadvanced LLMs in the investment decision-making process. In (Zhou et al., 2024b), the authors proposedthe Financial Bias Indicators (FBI) framework to evaluate the financial rationality of LLMs, includingbelief bias and risk preference bias. They find that model rationality increases with model size and is ofteninfluenced by the temporal bias in the financial training data. Prompting methods, such as instructional andChain-of-Thought (CoT) (Wei et al., 2022), can also mitigate the biases. In (Islam et al., 2023), the authorspropose the task of open-book QA to test the models ability to handle long context. They conclude thatcurrent strong LLMs like GPT-4-Turbo still fall far behind satisfactory performances, either with a retrievalsystem or using a long context model. In (Callanan et al., 2023), the authors evaluate the ability of GPT-3.5and GPT-4 in passing the first two levels of the Certified Financial Analyst (CFA) exam. Expectedly, GPT-4outperforms GPT-3.5 in both levels, but both models struggle with longer contexts, sophisticated numericalreasoning, and tabular information, especially in Level II. The authors also demonstrate that CoT promptingoffers limited improvement over zero-shot settings, but in-context learning with 2 or more examples producesthe best results. A detailed error analysis reveals that a lack of domain knowledge leads to the majority oferrors for both models, especially in Level II exams.",
  "LLM-based Methodologies for Financial Tasks and Challenges": "This section addresses LLM-based methodologies that have been proposed to tackle some of the key challengesin Financial NLP, including the scarcity of high-quality data in the public domain, the multimodal nature ofmany financial documents, the challenge of quantitative reasoning, the lack of domain knowledge in LLMs,and the importance of detecting or preventing hallucinations. Confidentiality and Scarcity of High-Quality Data. Due to the confidential nature of data in thefinancial domain, clean and high quality datasets can be difficult to obtain (Assefa et al., 2020; Zhang et al.,2023b). In (Aguda et al., 2024), the authors assess the efficacy of LLMs in annotating data for a financialrelation extraction task. While larger LLMs such as GPT-4 (Papailiopoulos, 2023) and PaLM-2 (Anil et al.,2023) outperform crowdsourced annotations, they fall far behind expert annotators, demonstrating thatdomain knowledge plays a crucial role. Other studies have tackled the scarcity of non-English financialtraining datasets (Zhang et al., 2024b; Hu et al., 2024). Quantitative Reasoning. Reasoning over numerical data is a major component of QA and IE tasks in thefinancial domain. Several recent studies have proposed prompting strategies that enhance the quantitativereasoning capabilities of LLMs in financial QA tasks. In (Wang et al., 2024b), the authors introduce ENCORE, a method that decomposes the numerical reasoningsteps into individual operations, and grounds each operand within the input context. When used as afew-shot prompting strategy, ENCORE improves the performance of SotA LLMs on TAT-QA (Zhu et al.,2021) and FinQA (Chen et al., 2021b) by an average of 10.9% compared to standard CoT prompting (Weiet al., 2022). In (Chen et al., 2023c), the authors propose the Program-of-Thoughts (PoT) promptingapproach that improves the numerical reasoning capability of LLMs on financial datasets, including FinQAand ConvFinQA (Chen et al., 2022). PoT explicitly prompts the model to frame its calculations as a program,using programming languages as tooling. On TAT-QA, despite better performance against other promptingstrategies such as CoT, PoT prompting falls short of the SotA performance. An error analysis reveals that themajority of errors are due to incorrect retrieval. This may be the result of the complex structure of tabulardata in the TAT-QA dataset, which does not include standardized tabular structures. In (Wang et al., 2024a),the authors show that using equations (rather than programs) as intermediate meaning representations can",
  "Future Prospects": "Building High-Quality Legal Datasets. Considering the legal domains intricate semantics and itsrequirements for precise statutes, obtaining high-quality legal datasets is often a particularly challenging task.More specifically, most existing legal datasets collected from the natural world are incomplete, sparse, andcomplicated. Its complexity and scholarly nature make it difficult for regular machine learning approaches toprovide annotation, while manual annotation in the legal domain requires much higher demands and costs(e.g., legal training and expertise) than in general domains. For example, CUAD (Hendrycks et al., 2021b)was created with dozens of legal experts from the Atticus project (Contributors, 2024) and consists of over13,000 annotations. In the future, building high-quality legal datasets may cover the following interestingdirections: Multi-Source Legal Data Integration for LLMs. Real-world legal events often involve datafrom a multitude of different information sources such as court records, evidence documentation,and multimedia materials (Matoesian & Gilbert, 2018). These pieces of information often exhibitsignificant diversity, ranging from precise and accurate legal texts to trivial and irrelevant details,and even intentionally obfuscated or ambiguously confused testimonies. Integrating informationfrom diverse sources requires advanced data integration techniques. This requires not only generaldata processing skills such as multi-modal data fusion but also an understanding of domain-specificnuances such as legal terminology and organizational structures. Additionally, real-world legal casehandling often requires global information, especially for long-text legal data. LLeQA (Louis et al.,2024) has made a promising start in providing long-form answers to statutory law questions, paving",
  "Medicine and Healthcare": "NLP has made remarkable strides in the biomedical field, providing essential insights and capabilitiesfor various healthcare and medical applications. The recent emergence of LLMs has brought significantadvancements to the medical field, primarily by incorporating extensive medical knowledge during training.This section explores the impact of LLMs on diverse biomedical tasks, benchmarks, and real-world applications.It demonstrates not only the power of LLMs in the biomedical sphere but also highlights their potentialin practical medical scenarios. The organization of this section is as follows: In 4.1, we give an overviewof the tasks and benchmarks in the medical domain. In 4.2, we summarize the advance of LLMs in threeaspects: (1) closed-source LLMs (e.g., GPT-4 (Achiam et al., 2023) and ChatGPT (OpenAI, 2022)) andtheir performance for medical applications; (2) open-sourced LLMs in the medical domain, including theirtraining strategies, data, and performance; (3) multimodal medical LLMs that bridge natural language withother modalities and being applied beyond text-only tasks. In 4.3, 4.4, 4.5, and 4.6, we will delve intosome of the practical applications of LLMs for clinical applications. We will present and discuss performancecomparison of various task-specific methods and LLMs. Finally, in 4.7, we summarize our insights anddiscuss potential future directions.",
  "Tasks and Benchmarks for Medical NLP": "Sentence Understanding A fundamental task in clinical NLP is to process sentences and documents, whichcould help extract meaningful information from clinical documents and assist clinicians in decision-makingprocesses. Dernoncourt & Lee (2017) proposed a dataset for sequential sentence classification, where sentencesin medical abstracts are labeled with one of the following classes: background, objective, method, result,or conclusion, which can help researchers to skim through the literature more efficiently. Abnormalitydetection (Harzig et al., 2019; He et al., 2023c) aims to detect abnormal findings in clinical reports, with asimilar goal to reduce the workload of radiologists. Ambiguity classification (He et al., 2023d) has a differentpurpose to focus on patient care, where it aims to find ambiguious sentences written by doctors, that couldcause the misleading from patients. Clinical Information Extraction. In the biomedical NLP community, a primary goal is the extraction of keyvariables from biomedical texts for effective biomedical text analysis. Clinical sense disambiguation interpretsmedical abbreviations within their clinical context into specific terminology, or conversely, translating medicalterminology into abbreviations. This is particularly crucial for understanding clinical notes, which arefrequently filled with complex jargon and abbreviations (He et al., 2023d). For example, the abbreviationpt could mean patient, physical therapy, or prothrombin time, etc. This task is usually formatted as amultiple-choice problem and evaluated by accuracy and F1 scores. Biomedical evidence extraction focuses onautomatically parsing clinical abstracts to extract key information, such as interventions and controls, fromclinical trials, aiding the adoption of evidence-based medicine by synthesizing findings across research studies(Nye et al., 2018). Coreference resolution is essential for accurately identifying and linking noun phrases thatrefer to the same entity, such as a person or a medical term. This process is crucial in clinical contexts, whereit helps to distinguish between a patients own medical history and that of their family members (Zhenget al., 2011; Chen et al., 2021a). This task has been largely evaluated on the 2010 i2b2/VA challenge, whichconsists of thousands of coreference chains (Uzuner et al., 2010). Medical Question Answering. Question answering (QA) in the medical domain is a fundamental task inNLP, requiring language models to answer particular questions based on their internal medical knowledge.This task not only demands a deep understanding of clinical terminologies and concepts but also requiresthe capability to comprehend and interpret complex medical reasoning given the question. Medical QAtasks are mainly formed as multiple-choice questions providing a set of possible answers for each question,from which the correct one must be chosen. This format is particularly useful for testing the languagemodels ability to discriminate between related concepts and to understand nuances in medical knowledge.MedQA(USMLE) (Jin et al., 2020) evaluates professional biomedical and clinical knowledge through 4-way multiple-choice questions from the US Medical Licensing Exam. MedMCQA (Pal et al., 2022) is alarge scale 4-way multiple-choice dataset from Indian medical school entrance exams. HeadQA (Vilares &Gmez-Rodrguez, 2019) offers multiple-choice questions from specialized Spanish healthcare exams between",
  ": A summarization of medical NLP tasks and representative datasets. The yellow field shows thetasks relatively under-explored for LLMs": "2013 and 2017, with 2013 and 2014 featuring five-option tests and 2015 to 2017 having four-option tests.MMLU (Hendrycks et al., 2021a) includes a section of professional medicine questions with four-way multiplechoices. PubMedQA (Jin et al., 2019) and BioASQ (Tsatsaronis et al., 2015) are reading comprehensiondatasets to answer yes/no/maybe based on a given passage. In the following sections, we will discuss some of the representative tasks in the clinical setting, fromabnormality detection and medical report generation, to some of the recently proposed tasks such as medicalinstruction evaluation and medical-imaging classification via natural language.",
  "LLMs for Medicine and Healthcare": "Close-sourced Medical LLMs.Close-sourced LLM pretraining for general proposes, such as ChatGPT(OpenAI, 2022) and GPT-4 (Achiam et al., 2023), have shown strong medical capacity across both medicalbenchmarks and real-world applications. Livin et al. (2023) utilized GPT-3.5 with different promptingstrategies, including CoT, few-shot, and retrieval augmentation, for three medical reasoning benchmarks,to show the models strong medical reasoning ability in the absence of specific fine-tuning. The evaluationof LLMs, such as ChatGPT, on medical exams, including US Medical Exams (Kung et al., 2023) andOtolaryngologyHead and Neck Surgery Certification Examinations (Long et al., 2023), indicates that theyachieve scores close to or at the passing threshold. This suggests the potential of LLMs to support real-worldmedical usages such as medical education and clinical decision-making. Agrawal et al. (2022) views LLMs suchas GPT-3 as clinical information extractors and shows the potential in different information extraction tasks.The MedPaLM models (Singhal et al., 2022; 2023), are a series of medical domain-specific LLMs, adaptedfrom PaLM models(?Anil et al., 2023; Chowdhery et al., 2022), which have shown performance in answeringmedical questions on par with that of medical professionals (Singhal et al., 2022; 2023). GPT-4 (Achiamet al., 2023) demonstrates strong medical capacities without specialized training strategies in the medicaldomain or engineering for solving clinical tasks (Nori et al., 2023a;b). When the scope is narrowed down tosub-domain domains, the performance of LLMs is variable. GPT-4 outperforms or performs on par with the",
  ": Summary of open-sourced medical LLMs": "A downstream application is interpretable medical image classification (Yan et al., 2023c), which tries togenerate medical concepts with LLMs and concept bottleneck models (Yan et al., 2023b; Echterhoff et al.,2024). This line of work leverages language to explain model decisions while also being able to keep similaror even better classification performance than black-box vision models.",
  "Abnormality and Ambiguity Detection": "Abnormality detection (Harzig et al., 2019) aims to identify abnormal findings in a radiology report byclassifying if a sentence reports normal or abnormal conditions. In this task, language models are used toautomatically read medical reports and reduce the workload of doctors. Ambiguity detection was first proposed in (He et al., 2023d), where it tries to detect ambiguous sentencesappear in radiology reports that lead to mis-interpretation of reports. Accurate identification of such sentencesis crucial, as they impede patients comprehension of diagnostic decisions and may cause potential treatmentdelays and irreparable consequences. As a novel task proposed recently, existing LMs may not readily includesuch a task into its pre-training stage. Therefore, evaluation of this task allows us to investigate how languagemodels perform for unseen tasks. Both tasks (He et al., 2023c) are sentence-level classification tasks. For comparison, we measured theclassification performance of finetuned LMs (BERT (Devlin et al., 2019), RadBERT (Yan et al., 2022),BioBERT (Lee et al., 2020), ClinicalBERT (Huang et al., 2019), BlueBERT (Peng et al., 2019), BioMed-ReBERTa (Gururangan et al., 2020)) and prompted LLMs (GPT-3, ChatGPT, Vicuna, BioMed LM (Boltonet al., 2024)) by reporting their F1 scores, as shown in . One can observe that though general LLMscan make reasonable predictions and can improve their performance via few-shot learning, there is still a gapbetween finetuned LMs and prompted LLMs. Moreover, the novel task of ambiguity detection indeed raiseschallenges, and there is a need to improve the generalizabitily of LLMs to deal with unseen tasks.",
  "Medical Report Generation": "Medical report generation (Yan et al., 2021) aims to build models that take medical imaging studies (e.g., X-rays) as input and automatically generate informative medical reports. Unlike conventional image captioningbenchmarks (e.g. MS-COCO (Lin et al., 2014)) where referenced captions are usually short, radiology reportsare much longer with multiple sentences, which pose higher requirements for information selection, relationextraction, and content ordering. To generate informative text from a radiology image study, a caption modelis required to understand the content, identify abnormal positions in an image and organize the wording todescribe findings in images. Evaluation of this task involve two aspects: (1) Automatic metrics for natural language generation: BLEU (Pa-pineni et al., 2002), ROUGE-L (Lin, 2004), and METEOR (Denkowski & Lavie, 2011). (2) Clinical Efficiency:CheXpert labeler (Irvin et al., 2019) is used to evaluate the clinical accuracy of the abnormal findings reportedby each model, which is a state-of-the-art rule-based chest X-ray report labeling system (Irvin et al., 2019).Given sentences of abnormal findings, CheXpert will give a positive and negative label for 14 diseases. Wecan then calculate the Precision, Recall and Accuracy for each disease based on the labels obtained from eachmodels output and from the ground-truth reports. We report performance of representative clinical models and recent LLMs in . We consider the followingbaslines: ST (Xu et al., 2015), M 2 Trans (Miura et al., 2020), R2Gen (Chen et al., 2020), WCL (Yan et al.,2021), as well as recent work that uses LLMs: XrayGPT (Thawkar et al., 2023), RaDialog (Pellegrini et al.,2023), Rad-MiniGPT-4 (Liu et al., 2024a). We observe similar trend as the sentence classification tasks, eventhough LLMs are good at generating fluent text and achieving high NLG scores, domain-specific models canstill outperform LLMs in terms of clinical efficacy.",
  "Medical Free-form Instruction Evaluation": "Free-form instruction evaluations assess the practical medical value of language models from a user-centricperspective. This task involves inputting a medical query in a free-text format into the model, whichthen generates a corresponding response. For instance, if a user inputs, Discuss the four major types ofleukocytes and their roles in the human immune system in bullet point format, the model will produce aninformed answer based on its internal medical knowledge. This task serves to measure both the medicalknowledge capacity and the instruction-following capability of the model. iCliniq (Li et al., 2023i; Chenet al., 2024) contains 10k real online conversations between patients and doctors to evaluate models medicalinstruction-following ability in the dialog scenario. MedInstruct-test (Zhang et al., 2023j) contains 217 clinical",
  "Text-davinci-003 GPT-3.5-turbo GPT-4 Claude-2 AVG Text-davinci-003 GPT-3.5-turbo GPT-4 Claude-2 AVG": "Alpaca38.830.412.815.624.425.020.621.515.622.5ChatDoctor25.416.76.59.314.535.618.320.413.418.2Medalpaca35.624.310.113.220.845.133.534.029.228.1PMC8.37.26.50.25.55.14.54.60.24.6Baize-H41.836.319.220.629.535.122.222.215.626.6AlpaCare66.650.647.449.767.653.649.848.148.453.5 : Performance comparison of medical LLMs on medical free-form instruction evaluation.GPT-3.5-turbo acts as a judge for pairwise auto-evaluation. Each instruction-tuned model is compared with4 distinct reference models: Text-davinci-003, GPT-3.5-turbo, GPT-4, and Claude-2. AVG denotes theaverage performance score across all referenced models in each test set. The table is sourced from (Zhanget al., 2023j). craft free-form instructions to evaluate the medical capacity and instruction-following ability of models acrossdifferent medical settings such as treatment recommendation, medical education, disease classification, etc.Evaluating the instruction-following capacity of LLMs is complex due to the wide range of valid responsesto a single instruction and the difficulty of replicating human evaluations. Recently, automated evaluation(Zheng et al., 2023; Dubois et al., 2023; Zhang et al., 2023i; Lu et al., 2022) has offered greater scalabilityand explainability compared to human studies. A strong LLM is used as a judge to compare the outputsof the evaluated model with reference answers and then calculate the winning rate of the evaluated modelagainst the reference answer is used as the evaluation metric. shows the current open-source medicalLLM performance on medical free-form instruction evaluation with GPT-3.5-turbo acts as a judge andText-davinci-003, GPT-3.5-turbo, GPT-4, and Claude-2 as reference models, respectively.",
  "Medical-Imaging Classification Via Natural Language": "Medical imaging classification with deep learning has long been studied in the computer vision and clinicalcommunity (Li et al., 2014). The task asks a model to take medical imaging (e.g., CT scans) as input, andassign diagnostic labels to them. However, predicting medical symptoms with black-box deep neural modelscould raise safety and trust issues, as it is hard for human to understand model behaviors and trust modeldecisions at ease. Clinicians often need to understand the underlying reasoning of the models to carefullymake their decisions. Interpretable models allow for better error analysis, bias detection, ensuring patientssafety, and trust building. Most recently, the idea of concept bottleneck models (CBMs) (Koh et al., 2020) hasbeen introduced to medical imaging classification, where one can build an intermediate layer by projectinglatent image features into a concept space to bring interpretability in the form of natural language. A follow-up work (Yan et al., 2023c) further shows that classification with concepts not only bring inter-pretability, but also offers robustness, with the help of pretrained multi-modal LMs (an illustration is presented",
  "Normal Lung of Old PeopleNormal Lung of Old People": ": High-level illustration of concept bottleneck models (Yan et al., 2023c). It uses concepts for medicalimage classification to achieve interpretability and robustness while maintaining accuracy. Left: Classificationwith a classical neural encoder; Right: Classification with natural language concepts. A Chest X-ray from ahealthy old individual may be classified as Covid-19 due to the patients age, while introducing language canmitigate the effect of these confounding factors. in ). This is especially important to medical applications, as confounding factors broadly exist andlabeled data are often limited (De Bruijne, 2016). Take the classification of patient X-rays between Covid-19and normal for instance, certain factors such as the hospitals where the X-rays are performed and the age ofthe patient strongly correlate with the target disease classification. Yan et al. (2023c) created four diagnosticbenchmarks with different confounding factors: age, gender, hospital system. Here we present results on thesedatasets with comparison for (1) state-of-the-art robust machine learning methods: ERM and Fish (Shi et al.,2021), Lisa (Yao et al., 2022b); (2) linear probing on image features; (3) CBMs with different vision-languagemodels as the backbone: CLIP (Radford et al., 2021b), MedCLIP (Wang et al., 2022), and BioViL (Bannuret al., 2023), shown in . We find that BioVIL shows promising results when evaluating on challengingdatasets with various confounding factors, while another medical VLM, MedCLIP performs similar to generaldomain CLIP model. To enable useful concept bottleneck models, a strong and robust domain-specificvision-language model is needed.",
  "pretraining and instructional fine-tuning. To further improve the capacity of these models, several futuredirections can be considered:": "Data Diversity and Quality. Although machine-generated datasets accelerate data generationfor LLM training, their diversity still lags behind that of real-world collected datasets, which highlyimpacts model performance (Chiang et al., 2023). Expanding the training datasets to include abroader range of real-world medical texts, such as clinical trial reports, medical journals, patientrecords, and health forums, can improve the models understanding of diverse medical contexts andterminologies. Additionally, ensuring the quality and reliability of the training data is crucial formaintaining the accuracy and trustworthiness of the models outputs. RAG. Integrating RAG techniques can enhance the models ability to access and incorporate relevantmedical knowledge from extensive sources such as large medical knowledge bases, private hospitalrecords, and databases. This approach can improve the models responses by providing more accurateand contextually appropriate information, particularly in complex medical scenarios in inferencetime. Addressing Privacy Concerns. Medical data usage has strong restrictions compared to thegeneral domain and other small domains. Developing methodologies address privacy issues in utilizingLLM APIs and building local LLMs are both important. This can include implementing secure datatransmission protocols, ensuring data anonymization, and adopting privacy-preserving techniquessuch as differential privacy. Learning in a Data Sparsity Setting. A critical challenge in medical domain for training large-scalemodels is the restriction of data usage. Data sparsity is a persistent issue due to privacy and confidentialityconcerns, the cost of data Acquisition and annotation, as well as ethical considerations. For many practicaltasks, e.g., medical report generation, clinical chatbots, medical image classification, the data sparsity issuewill be a remaining challenge. Additionally, as mentioned earlier in the performance comparison sections fordifferent applications, task-specific models that trained with in-distribution data and specific architecturaldesign can still outperform foundation models. Based on the empirical finding of training general domainLLMs (Brown et al., 2020; Kaplan et al., 2020; Achiam et al., 2023), scaling up data is of vital importancefor model performance. We discuss some of the potential future directions to address this issue: Transfer Learning and Domain Adaptation. For medical LLMs, it is worth exploring howscaling up general domain, publicly-available data can help with in-domain medical tasks. We canexplore data selection strategies in pretraining stage to improve the transfer learning performancefrom general-domain models to medical-specific tasks. Synthetic Data Generation. To mitigate the challenges posed by data scarcity, another approachis the generation of synthetic medical data. Leveraging advanced LLMs could enable the creation ofdiverse synthetic datasets to augment the learning process. Few-shot and Zero-shot Learning. Few-shot learning and in-context learning methods should beexplored more deeply, which has the potential to let medical LLMs adapting to new tasks or domainswith minimal training data. Privacy-preserving Techniques. Techniques such as differential privacy and federated learn-ing (Rieke et al., 2020) could allow the utilization of patient data for training purposes while ensuringthat individual privacy is maintained. Active Learning. Implementing active learning strategies where the model identifies the most informativedata points for labeling can optimize the training process. This method ensures efficient use of scarce dataresources and improves learning outcomes in highly specialized medical contexts.",
  "Law": "NLP is pivotal in the legal domain, providing sophisticated tools for managing the extensive and intricatetextual data inherent in legal documentation and proceedings (Harvard Law School Library, 2023; UnitedStates Congress, 2023; Fang et al., 2023). The advent of LLMs has further catalyzed innovation at thefrontier of legal applications. This section explores the profound influence of LLMs across a range of legaltasks. These technological advancements have strengthened significant enhancements in areas such as legaljudgment prediction, legal event detection, legal text classification, and legal document summarization. Thepurpose of this chapter is to outline the trajectory of LLMs in revolutionizing legal NLP and to shed lighton both the challenges faced and the potential future developments. This chapter is organized as follows:In 5.1, we introduce the current NLP tasks in the legal domain, detailing task formulations and relevantdatasets. In section 5.2, we explore various PLMs and LLMs developed specifically for legal applications. Insection 5.3, we examine the evaluations and performance analysis of LLMs in legal contexts. In section 5.4,we discuss various LLM-based methodologies developed for tackling legal tasks and challenges. Finally, wesummarize insights, draw conclusions, and discuss potential future directions in section 5.5.",
  "Tasks and Datasets in Legal NLP": "In this section, we present an array of legal tasks and corresponding datasets that have been investigatedthrough the LLM methodologies. The domains covered include legal question answering (LQA), legal judgmentprediction (LJP), legal event detection (LED), legal text classification (LTC), legal document summarization(LDS), and other NLP tasks. provides an overview of these established legal NLP tasks and relateddatasets. Legal Question Answering (LQA). LQA is the process of providing answers to legal questions andpromotes the development of systems proficient in handling complex inquiries related to laws, regulations,case precedents, and theoretical syntheses. The LQA dataset comprises a wide array of question-and-answerpairs that serve to evaluate a systems capability in legal reasoning. CRJC (Duan et al., 2019), akin to theSQUAD 2.0 (Rajpurkar et al., 2018) format, includes challenges such as span extraction, yes/no questions,and unanswerable questions. Furthermore, professional qualification examinations like the bar exam requirespecialized legal knowledge and skills, making datasets such as the MBE (Wyner et al., 2016) from the US,JEC-QA (Zhong et al., 2020) from China, and COLIEE2015 (Kim et al., 2015) from Japan particularlydemanding. Specific legal domains also have dedicated datasets. For instance, SARA (Holzenberger et al.,2020) focuses on US tax law and includes test cases, while VLQA (Bach et al., 2017) addresses Vietnamesetransportation law. In the area of privacy law, PrivacyQA (Ahmad et al., 2020) and PIL (Sovrano et al.,2021) test the systems ability to navigate complex language and regulations regarding data privacy. Forthe community-oriented legal education, FALQU (Mansouri & Campos, 2023) and LCQA (Askari et al.,2022) are obtained from Law Stack Exchange (law). Several databases employ specific techniques to improvethe datasets quality, for example, EQUALS (Chen et al., 2023a) filters out unqualified legal questions fromthe raw data. AILA (Huang et al., 2020) integrates domain knowledge from a legal knowledge graph to",
  "Legal Question Answering (LQA)": "CRJC (Duan et al., 2019), MBE (Wyner et al., 2016),JEC-QA (Zhong et al., 2020), COLIEE2015 (Kim et al., 2015),SARA (Holzenberger et al., 2020), VLQA (Bach et al., 2017),PrivacyQA(Ahmad et al., 2020), PIL (Sovrano et al., 2021),FALQU (Mansouri & Campos, 2023), LCQA (Askari et al., 2022),EQUALS (Chen et al., 2023a), AILA (Huang et al., 2020),LLeQA(Louis et al., 2024)",
  "comprehend and rank question-answer pairs effectively. LLeQA (Louis et al., 2024) provides long-formanswers to statutory law questions using a retrieve-then-read pipeline": "Legal Judgment Prediction (LJP). LJP focuses on analyzing legal texts such as case law, statutes, andtrial transcripts to predict the outcomes of legal cases. This can assist judges, lawyers, and legal scholars inunderstanding potential case outcomes based on historical data. The task is generally treated as a classificationproblem where the input is a legal document and the target is a legal decision (e.g., conviction, acquittal,liability). Researchers have developed several datasets tailored to different legal systems across the globe.For instance, CAIL2018 (Xiao et al., 2018) is a comprehensive Chinese criminal judgment prediction datasetcomprising over 2.68 million legal documents published by the Chinese government. Similarly, in Europe,datasets such as FSCS (Niklaus et al., 2021) offer insights into Swiss court judgments with 85,000 cases acrosstwo outcomes, reflecting the multilingual nature of the Swiss legal environment. The ECtHR (Chalkidiset al., 2021b) and ECHR (Chalkidis et al., 2019) datasets focus on European Union court judgments, eachcontaining around 11,000 cases but offering a broader scope with 11 potential outcomes. Legal Event Detection (LED). LED in legal documents involves identifying significant legal proceedingsor decisions, such as rulings, motions, or amendments. This task is crucial for enabling legal professionalsto monitor pivotal developments within cases efficiently. While Shen et al. (2020) propose hierarchicalevent features to distinguish similar events in legal texts, and Li et al. (2020b) implement event extractiontechnologies specifically for the description segments of Chinese legal texts, these studies are constrained bytheir datasets, which contain only thousands of event mentions. Such limited annotations fail to providerobust training signals or reliable evaluation benchmarks. Addressing this gap, LEVEN (Yao et al., 2022a), acomprehensive and high-quality dataset, is designed to enhance the capabilities of legal information extractionand LED. Legal Text Classification (LTC). LTC involves categorizing structured sections within legal documentsto enhance their accessibility and comprehensibility. For instance, most legal documents contain sectionslike \"Facts of the case,\" \"Arguments presented by the parties,\" and \"Decisions of the current court,\" whoseidentification is crucial for understanding the legal outcomes of cases. These documents can thus be categorizedinto classes such as facts, argument, and statute, making LTC a multi-class classification task. Key datasetsthat have propelled advancements in LTC include the following: Greek Legal Code(GLC) (Papaloukas et al.,2021) focuses on categorizing a wide array of Greek legal documents; MultiEURLEX (Chalkidis et al., 2021a)",
  "Legal LLMs": "Since the development of BERT (Devlin et al., 2019), there have been continuous efforts to build PLMsand LLMs specialized for the legal domain. Following the evolving paradigms of general PLMs and LLMs,early legal PLMs adopted the pre-training followed by downstream task fine-tuning paradigm and initiallytrained relatively small language models. Recent works have scaled up model sizes and introduced instructionfine-tuning, with evaluations covering a broader set of legal tasks. Most existing legal LLMs are text-based,with a focus on Chinese, English, or multi-language support. summarizes the PLMs and LLMs forthe legal domain. Pre-Trained and Fine-Tuning PLMs. LegalBERT (Chalkidis et al., 2020) is an early attempt to build alegal PLM targeting tasks like LTC. The model is further pre-trained on a corpus of legal documents and thenfine-tuned using task-specific data. Lawformer (Xiao et al., 2021), a transformer-based model, is pre-trainedspecifically for handling lengthy legal texts, aiding in tasks such as LJP, LRC, and LQA. Pre-Trained and Fine-Tuning LLMs. Pre-trained and fine-tuning LLMs involve LLMs specifically trainedand fine-tuned for legal tasks or datasets. These legal-specific LLMs often integrate external knowledge basesand process extensive initial training to handle a wide range of legal data. Recent developments have led tomodels like LexiLaw (Haitao, 2024), a fine-tuned Chinese legal model based on the ChatGLM-6B (Group,2023), meanwhile Fuzi.mingcha (SDU, 2023) is also based on ChatGLM-6B (Group, 2023), which is fine-tunedon CAIL2018 (Xiao et al., 2018) and LaWGPT (Xiao-Song, 2024). Furthermore, WisdomInterrogatory(LLM, 2023) is a pre-trained and fine-tuning model built upon Baichuan-7B (Inc., 2023). More 7B LLMs likeLawGPT-7B-beta1.0 (Nguyen, 2023) are pre-trained on 500k Chinese judgment documents upon Chinese-LLaMA-7B (Cui & et al., 2023), and HanFei (He et al., 2023b) is a fully pre-trained and fine-tuned LLMwith 7B parameters. There are more explorations on large-scale LLMs, LaywerLLaM (Zhe, 2023) is basedon Chinese-LLaMA-13B (Cui & et al., 2023), fine-tuned with general and legal instructions, additionally,ChatLaw-13B (Cui et al., 2023a) is fine-tuned based on Ziya-LLaMA-13B-v1 (IDEA-CCNL, 2023), andChatLaw-33B (Cui et al., 2023a) is fine-tuned based on Anima-33B (Ogavinee & et al., 2022). It is worthnoting that LLMs based on other languages have also recently emerged, such as SaulLM-7B (Colombo et al.,2024) based on Mistral-7B (Jiang et al., 2023) and JURU (Junior et al., 2024), which is the first LLM",
  "Pre-trained Fine-Tuning LLMs": "JURU (Junior et al., 2024)Sabi-2 (Sales Almeida et al., 2024)LQAPortuguese1.9B2024LexiLaw (Haitao, 2024)ChatGLM-6B (Group, 2023)LRC, LQAChinese6B2023Fuzi-Mingcha (SDU, 2023)ChatGLM-6B (Group, 2023)LJP, LRC, LQAChinese6B2023WisdomInterrogatory (LLM, 2023)Baichuan-7B (Inc., 2023)LJP, LRC, LQAChinese7B2023LawGPT-7B-beta1.0 (Xiao-Song, 2024)Chinese-LLaMA-7B (Cui & et al., 2023)LRC, LQAChinese7B2023SaulLM-7B (Colombo et al., 2024)Mistral-7B (Jiang et al., 2023)LQAEnglish7B2024Lawyer-LLaMA (Zhe, 2024)Chinese-LLaMA-13B (Cui & et al., 2023)LJP, LRC, LQAChinese13B2023ChatLaw-13B (Cui et al., 2023a)Ziya-LLaMA-13B-v1 (IDEA-CCNL, 2023)LJP, LRC, LQAChinese13B2023ChatLaw-33B (Cui et al., 2023a)Anima-33B (Ogavinee & et al., 2022)LJP, LRC, LQAChinese33B2023 : Summary of legal PLMs and LLMs. For evaluation tasks, we have LTC for Legal Text Classification,ST for Sequence Tagging, NER for Named Entity Recognition, LJP for Legal Judgment Prediction, SCRfor Similar Case Retrieval, LRC for Legal Reading Comprehension, and LQA for Legal Question Answering.",
  "GPT-3.5 (zero-shot)0.360.660.340.29GPT-3.5 (few-shot)0.370.680.520.31GPT-4 (zero-shot)0.550.790.330.52GPT-4 (few-shot)0.550.770.570.53": ": Performance comparisons for LQA tasks (JEC-QA dataset (Zhong et al., 2020)), LED task (LEVENdataset (Yao et al., 2022a)), and LJP task (LawGPT dataset (Xiao-Song, 2024) and CAIL2018 (Xiao et al.,2018)). We focus more on LJP tasks based on fact-based articles for the CAIL2018 dataset (Xiao et al., 2018)while scene-based articles for the LawGPT dataset (Xiao-Song, 2024). The few-shot setting is one shot for alldatasets. pre-trained for the Brazilian legal domain. These legal-specific LLMs, often following an initial pre-trainingphase, are tailored to specific legal datasets and tasks, enhancing both the precision and applicability of legalNLP technologies in practice.",
  "Evaluation and Analysis of LLMs": "The evaluation and analysis of LLMs performance is crucial for understanding their effectiveness andcapabilities, particularly in legal-specific contexts. This section introduces the evaluation benchmarks inassessing legal capabilities before the rise of LLMs. Subsequently, we explore specialized legal benchmarksdesigned explicitly for evaluating the performance of LLMs, and summarize their main findings. These worksprovide a focused and rigorous assessment of LLMs abilities in handling legal tasks, offering insights intotheir efficacy and potential for legal applications. Before the emergence of LLMs, there were benchmarks used to evaluate NLP models legal performance.To evaluate model performance uniformly across diverse legal natural language understanding (NLU) tasks,LexGLUE benchmarks (Chalkidis et al., 2021c) are introduced. These benchmarks include datasets likeECtHR (Chalkidis et al., 2021b), SCOTUS (Spaeth et al., 2017), EUR-LEX (Chalkidis et al., 2021a),",
  "LLM-based Methodologies for Legal Tasks and Challenges": "This section discusses LLM-based approaches aimed at addressing significant challenges in Legal NLP. Thesechallenges cover multiple aspects, including societal legal problems, legal prediction, document analysis, legalhallucinations, legal exams, and the need for robust LLM Agents. Societal Legal Challenges. LLMs have emerged as powerful tools with the potential to address varioussocietal challenges in daily life. In the area of legal applications, LLMs are being explored for their capabilitiesin areas such as tax preparation, online disputes, cryptocurrency cases, and copyright violations. For instance,the use of few-shot in-context learning could improve the performance of LLMs in tax-related tasks (Srinivaset al., 2023; Nay et al., 2024). Moreover, Llmediator (Westermann et al., 2023) highlights the role ofLLMs in facilitating online dispute resolution, especially for individuals representing themselves in court,it generates dispute suggestions by detecting the inflammatory message and reformulating polite messages.Additionally, the exploration of LLMs in cryptocurrency security cases (Trozze et al., 2024) (Zhang et al.,2023k) demonstrates their utility in navigating intricate legal landscapes. Addressing copyright violations isanother area where LLMs are making an impact (Karamolegkou et al., 2023). LLM Legal Prediction. Legal prediction judgment is a crucial task of leveraging LLMs in the legaldomain. Among the various techniques, Legal Prompt Engineering (LPE) stands out as a commonly usedmethod for enhancing legal predictions. LPE (Trautmann et al., 2022) is a technique that enhances legalresponses using key strategies like zero-shot learning, few-shot learning, the chain of reference (CoR), andRAG. Trautmann et al. (2022) show that zero-shot LPE is better compared to the baselines, but it still fallsshort compared to state-of-the-art supervised approaches. Kuppa et al. (2023) propose CoR, where legalquestions are pre-prompted with legal frameworks to simplify the tasks into manageable steps, leading to asignificant improvement in zero-shot performance by up to 12% in LLMs like GPT-3. Jiang & Yang (2023)introduce legal syllogism prompting (LoT), a simple method to teach LLMs for LJP, focusing on the basiccomponents of legal syllogism: the major premise as law, the minor premise as fact, and the conclusion asjudgment. LLM Document Analysis. LLMs could also assist in legal document analysis, and be applied to case filesand legal memos for content extraction. Contract management can be enhanced through automated drafting,",
  "ethical issues like gender bias in legal systems (Sevim et al., 2023), reducing legal hallucinationsignificantly (Dahl et al., 2024)": "Social Impact of LLM-based Legal System. Investigating the social impact of LLMs on thelegal domain also includes many interesting directions: (1) Applying LLMs to democratize legaleducation and advice, benefiting individuals who have difficulties in visiting a human lawyer dueto the lack of professional knowledge or economic resources. This democratization can empowermarginalized communities by granting them access to crucial legal information and guidance; (2)The development of LLMs will also accelerate the evolution of privatized and personalized legalLLMs, leading to increasing competition in the legal domain and the creation of more satisfyingproducts for customers (Cui et al., 2023a); (3) Leveraging LLMs to drive future developments inlaw through enhanced legal analysis. By facilitating deeper insights into legal texts and precedents,LLMs can contribute to more informed law updates and academic research endeavors; (4) Addressingethical issues with LLMs in the legal system. Through rigorous analysis and scrutiny, LLMs can helpidentify and rectify instances of injustice and discrimination against certain demographic groups inlegal decision-making processes.",
  "Ethics": "Despite recent breakthroughs in LLMs, concerns regarding their ethics and trust have been raised for theirreal-world use (Kaddour et al., 2023; Ray, 2023). Especially, when applied in high-stakes domains such asFHL, these ethical concerns become particularly critical. In a broader sense, the ethics of AI technologiesin different domains have been widely discussed in the last few decades (Jobin et al., 2019; Leslie, 2019).Despite these large number of existing discussions, numerous ethical concepts are proposed from diversedisciplines and perspectives with complicated objectives, leading to challenges to constructing a consistentand well-organized ethical framework. Fortunately, these various ethical considerations often originate fromsimilar high-level principles. In this section, we first introduce several general ethical principles and relatedconsiderations for LLM applications, and also showcase examples of these ethics in domain-specific contexts.We will describe the basic definitions of these ethical issues and summarize the existing investigations fortesting or addressing them in section 6.1, then we discuss future directions in section 6.2.",
  "Ethical Principles": "Transparency. Transparency refers to \"explaining and understanding\" the systems, including differentstages such as data usage and model behavior. Transparency is the most frequently mentioned AI ethicalprinciple based on the investigation in Jobin et al. (2019). Many concepts are related to transparency, suchas explainability, interpretability, communication, and accountability. Transparency is particularly criticalwhen LLM assists in complicated, expertise-intensive, and high-risk applications. In finance, institutions havestarted to utilize LLMs for tasks such as risk assessment, fraud detection, and automated trading strategies;In healthcare, LLMs are increasingly employed in clinical decision support, such as disease diagnosis andtreatment recommendation; In law, LLMs have been used for contract review and analysis. In these examplesof applications, transparency is crucial to promote understanding of how LLMs make final decisions andthereby assess their potential risks or issues. Justice. Justice encompasses a spectrum of meanings, commonly associated with fairness, equity, inclusion,diversity, non-bias, and non-discrimination\". Hence, justice holds particular significance when LLMs areutilized in contexts involving individuals from diverse demographic or societal backgrounds. In studies of law,justice is often widely referenced as a core legal principle. For instance, when using LLMs to assist insentencing decisions or crime prediction, justice (e.g., anti-discrimination against race, economic/politicalstatus, and crime history) is crucial. In finance, applications such as loan approval, money launderingdetection, and consumer rights protection have high demands for fairness and equity. In healthcare, fairresource allocation and treatment recommendations without inequalities and discrimination are of greatimportance when LLMs are applied. Non-maleficence. Non-maleficence generally means \"do no harm\". Here, harms can exist in a variety offorms such as incorrect, toxic, outdated, biased, and privacy-violating information. As LLMs are often trainedon vast corpora with unknown quality, the removal of such harmful information is imperative in practicalapplications. In finance, non-maleficence is important because it emphasizes the responsibility of financialinstitutions, professionals, and regulators to prevent harm to investors, consumers, and the broader financialsystem, avoiding potential financial losses or harm to individuals or society. In healthcare, non-maleficenceplays a key role in maintaining patient safety, trust, and confidentiality, especially in tasks like treatmentplanning and patient monitoring. In law, non-maleficence is crucial to prevent wrong actions, negligence, andviolations of legal rights stemming from reliance on obsolete or inaccurate legal provisions. Especially, due tothe dynamic nature of legal systems, updated law may inadvertently leave behind outdated and harmfulinformation, necessitating careful approaches to ensure that legal practices and interpretations remain alignedwith current statutes and regulations.",
  "Ethical Considerations": "Explainability. Explainability means the capacity to elucidate the model behavior in a human-understandableway (e.g., showing the importance of input data or model component for model output, and estimating themodel behavior in interventional or counterfactual cases). AI explainability has been a longstanding concern(Saeed & Omlin, 2023; Doilovi et al., 2018), as many AI models inherently function as black boxes, lackingtransparency and interoperability. Especially, explanation in LLMs is often even more challenging than mosttraditional AI techniques due to the extensive scale of training data and the large size of the model. Despitethe challenges, from another aspect, the unique ability of LLMs to comprehend and generate natural languageempowers them to elucidate their own decision-making processes. Recent investigations (Zhao et al., 2024;Singh et al., 2024) have summarized existing explanation approaches for LLMs in both traditional fine-tuningparadigm (with approaches such as feature-based explanation (Ribeiro et al., 2016; Lundberg & Lee, 2017) or",
  "Domain-specific Ethics": "On top of general ethical principles and considerations, in the specific context of different domains, thedefinitions of ethics display their distinct focus and subtle differences. Here, we introduce domain-specificinvestigations of ethics in FHL domains, respectively. Finance. Many ethical guidelines (Attard-Frost et al., 2023; Svetlova, 2022; Kurshan et al., 2021; Farinaet al., 2024) for AI practice in the finance sector have been published in recent years. In Attard-Frost et al.(2023), based on the general Fairness, Accountability, Sustainability, and Transparency (FAST) AI ethicalprinciples in the public sector proposed by Leslie (2019), a series of business-oriented ethical themes (e.g.,market fairness, bias & diversity in professional practice, and business model transparency) are organizedunder each principle. When using LLMs for finance, a few studies have begun to discuss the ethics of LLMssuch as ChatGPT (Khan & Umer, 2024) and BloombergGPT (Wu et al., 2023d). Exploratory efforts foraddressing ethical issues of LLMs in finance, such as hallucination (Kang & Liu, 2024; Roychowdhury et al.,2023) and financial crime (Ji et al., 2024), have laid a promising groundwork for further investigation. Healthcare. Ethics in healthcare has long garnered significant attention (Pressman et al., 2024; Beauchamp& Childress, 2001) due to potentially severe and irreversible consequences, notably the loss of human life. Asa result, a set of widely adopted ethical principles (Autonomy, Beneficence, Non-maleficence, and Justice)(Beauchamp & Childress, 2001) has been established in clinical and medical practice. Apart from theaforementioned non-maleficence and justice, autonomy in health centers on an individuals right to makeinformed medical decisions, and beneficence in health focuses on \"doing good\" to promote patient well-being.Recent discussions (Li et al., 2023b; Karabacak & Margetis, 2023; Minssen et al., 2023; Yu et al., 2023c;Thirunavukarasu et al., 2023; Haltaufderheide & Ranisch, 2024; Ullah et al., 2024) for the ethics of LLMs inthe health & medicine sector have reached the consensus that existing LLMs still have a substantial gap tobridge in order to meet ideal ethical standards. This situation leads to the development of more nuancedethical considerations across various healthcare scenarios. For instance, a recent review (Haltaufderheide &Ranisch, 2024) summarized LLM ethics in four key clinical themes, including clinical applications, patientsupport, health professionals, and public health. Other discussions about ethics in specific healthcare contextssuch as surgery (Pressman et al., 2024) and mental health (Cabrera et al., 2023) also provide valuable insightinto LLM applications in real-world health systems. Law. In the domain of law, numerous deliberations (Cranston, 1995; Yamane, 2020; Wright, 2020; Nunez,2017) has taken place about legal ethics for AI. The recent progress of LLMs brings new challenges anddiscussions about ethics in the legal domain, stimulating the refinement of existing legal ethics and thedevelopment of more feasible evaluation standards. Among these works, Zhang et al. (2024a) design a multi-level ethical evaluation framework and evaluates mainstream LLMs under the framework. This evaluationframework covers three aspects with increasing level of ethical proficiency: legal instruction following (i.e., theability of LLMs to address user needs based on given instructions), legal knowledge (i.e., the ability of LLMsto distinguish the legal/nonlegal elements), and legal robustness (i.e., the consistency of LLM responses toidentical questions presented in varying formats and contexts). Another recent work (Cheong et al., 2024)collects opinions from 20 legal experts, revealing detailed policy considerations for LLM employment in the",
  "Methodological Directions": "Looking ahead, the future prospects for LLM in FHL domains are at an exciting moment. Here, we outlineseveral promising methodological directions that can be applied to address various ethical concerns: Dataset censorship. Meticulous dataset censorship is vital, involving a thorough examination andelimination of improper content from the training data. This step ensures that the model is shieldedfrom potentially harmful information, minimizing the risk of encoding unwanted patterns. Forexample, removing biased, private, or incorrect information in FHL scenarios can promote fairness,privacy, and reduction of hallucinations. Considering the specialized knowledge required in FHLdomains, developing high-quality data censorship mechanisms presents significant challenges. Human and domain knowledge for ethics. The integration of humans in the AI loop is essential.Human reviewers contribute nuanced perspectives, provide domain knowledge, identify ethical issues,and guide the models learning process by refining its responses. Human-in-the-loop systems allow forongoing monitoring and adjustments to address emerging ethical problems. For example, as discussedin , involving legal advice from human expert would not only improve legal reasoning butalso address complicated concerns in ethical and moral dilemmas. Theoretical bounds. Establishing theoretical bounds on the models behavior is important. Thedevelopment of clear theoretical frameworks and ethical guidelines helps delineate the limits ofthe models decision-making, preventing it from generating potentially harmful or biased outputs.Through the implementation of these measures, we can elevate the ethical standards of LLMs,fostering responsible AI development. For example, for the robustness issue we discussed in .1.2, certifiable approaches for LLMs are crucial to theoretically guarantee model safety against arange of adversarial attacks. Causality-involved analysis. It is essential to delve into the underlying causes and mechanismsbehind the generation of LLM outputs. For example, concerning the explainability and fairnessissues discussed in .1.2, incorporating causality can help elucidate the causes behind modelbehavior and eliminate potential biases against underrepresented groups. By understanding andaddressing the causal relationships within the data and the model, we can develop effective strategiesto improve both the transparency and equity of the LLM outputs.",
  "Here, we highlight several urgent and critical concerns for LLM + FHL areas, which hold substantial potentialfor future development": "Safety and privacy. Employing LLMs in FHL sectors introduces substantial safety and privacy issues,given the sensitive nature of the information handled in these areas. Existing studies (ThankGod Chinonso,2023) have reported LLM issues in privacy and safety, coming from both model-inherent vulnerabilities (e.g.,data extraction, data poisoning) and other vulnerabilities (e.g., prompt injection), as we also introducedin .1. Traditional privacy and safety strategies often fail on LLMs due to the large scale of LLMparameters and high computation cost. Considering this, we list the following lines for future research: (1)Clear guidelines and user education: Provide clear, understandable guidelines that inform FHL usersabout the risks associated with the provision of personal information. Regularly remind and educate userson the importance of being cautious with the amount of personal information they share. Emphasize the",
  "Conclusion": "The exploration of LLMs across diverse fields illuminates the vast potential and inherent challenges ofintegrating advanced AI tools into various real-world applications. This survey focuses on three criticalsocietal domains: finance, healthcare & medicine, and law, underscoring the transformative impact of LLMsin enhancing research methodologies and accelerating the pace of knowledge discovery and decision-makingin these domains. Through detailed examination across disciplines, we highlight significant advancementsachieved by leveraging LLMs in these domains, foreseeing a promising future full of breakthroughs andopportunities. However, the integration of LLMs also brings to light challenges and ethical considerations. Concerns such asexplainability, bias & fairness, robustness, and hallucination necessitate ongoing scrutiny and development ofmitigation strategies. Furthermore, the interdisciplinary nature of LLM applications calls for collaborativeefforts among AI researchers, domain experts, and policymakers to navigate the ethical landscape and harnessthe full potential of LLMs responsibly. As LLMs continue to evolve and find broader utility, it becomesincreasingly imperative to address these challenges systematically and proactively.",
  "Amina Adadi and Mohammed Berrada. Peeking inside the black-box: a survey on explainable artificialintelligence (xai). IEEE access, 6:5213852160, 2018": "Monica Agrawal, Stefan Hegselmann, Hunter Lang, Yoon Kim, and David Sontag. Large language modelsare few-shot clinical information extractors. In Yoav Goldberg, Zornitsa Kozareva, and Yue Zhang (eds.),Proceedings of the 2022 Conference on Empirical Methods in Natural Language Processing, pp. 19982022,Abu Dhabi, United Arab Emirates, December 2022. Association for Computational Linguistics. doi:10.18653/v1/2022.emnlp-main.130. URL Toyin Aguda, Suchetha Siddagangappa, Elena Kochkina, Simerjot Kaur, Dongsheng Wang, Charese Smiley,and Sameena Shah. Large language models as financial data annotators: A study on effectiveness andefficiency, 2024.",
  "Jaimeen Ahn and Alice Oh.Mitigating language-dependent ethnic bias in bert.arXiv preprintarXiv:2109.05704, 2021": "Raghad Al-Shabandar, Gaye Lightbody, Fiona Browne, Jun Liu, Haiying Wang, and Huiru Zheng. Theapplication of artificial intelligence in financial compliance management. In Proceedings of the 2019International Conference on Artificial Intelligence and Advanced Manufacturing, pp. 16, 2019. Shuhaib Ali, Omer Shahab, Reem Al Shabeeb, Farah Ladak, Jamie O. Yang, Girish Nadkarni, JuanJos Solozbal Echavarra, Sumbal Babar, Aasma Shaukat, Ali Soroush, and Bara El Kurdi. Generalpurpose large language models match human performance on gastroenterology board exam self-assessments.In medRxiv, 2023. URL",
  "Hussam Alkaissi and Samy I McFarlane. Artificial hallucinations in chatgpt: implications in scientific writing.Cureus, 15(2), 2023": "Enes Altinisik, Hassan Sajjad, Husrev Taha Sencar, Safa Messaoud, and Sanjay Chawla. Impact of adversarialtraining on robustness and generalizability of language models. arXiv preprint arXiv:2211.05523, 2022. Julio Cesar Salinas Alvarado, Karin Verspoor, and Timothy Baldwin. Domain adaption of named entityrecognition to support credit risk assessment. In Ben Hachey and Kellie Webster (eds.), Proceedings of theAustralasian Language Technology Association Workshop, ALTA 2015, Parramatta, Australia, December 8- 9, 2015, pp. 8490. ACL, 2015. URL",
  "Saqib Aziz and Michael Dowling. Machine learning and AI for risk management. Springer InternationalPublishing, 2019": "Ngo Xuan Bach, Tran Ha Ngoc Thien, Tu Minh Phuong, et al. Question analysis for vietnamese legalquestion answering. In 2017 9th International Conference on Knowledge and Systems Engineering (KSE),pp. 154159. IEEE, 2017. Jinze Bai, Shuai Bai, Shusheng Yang, Shijie Wang, Sinan Tan, Peng Wang, Junyang Lin, Chang Zhou, andJingren Zhou. Qwen-vl: A versatile vision-language model for understanding, localization, text reading,and beyond. arXiv preprint arXiv:2308.12966, 2023. Shruthi Bannur, Stephanie Hyland, Qianchu Liu, Fernando Perez-Garcia, Maximilian Ilse, Daniel C Castro,Benedikt Boecking, Harshita Sharma, Kenza Bouzid, Anja Thieme, et al. Learning to exploit temporalstructure for biomedical vision-language processing. In Proceedings of the IEEE/CVF Conference onComputer Vision and Pattern Recognition, pp. 1501615027, 2023.",
  "Simon Benninga. Financial modeling. MIT press, 2014": "Ankita Bhatia, Arti Chandani, Rizwana Atiq, Mita Mehta, and Rajiv Divekar. Artificial intelligence infinancial services: a qualitative research to discover robo-advisory services. Qualitative Research in FinancialMarkets, 13(5):632654, 2021. Gagan Bhatia, El Moatez Billah Nagoudi, Hasan Cavusoglu, and Muhammad Abdul-Mageed. Fintral: Afamily of GPT-4 level multimodal financial large language models. CoRR, abs/2402.10986, 2024. doi:10.48550/ARXIV.2402.10986. URL Battista Biggio, Igino Corona, Davide Maiorca, Blaine Nelson, Nedim rndi, Pavel Laskov, Giorgio Giacinto,and Fabio Roli. Evasion attacks against machine learning at test time. In Machine Learning and KnowledgeDiscovery in Databases: European Conference, ECML PKDD 2013, Prague, Czech Republic, September23-27, 2013, Proceedings, Part III 13, pp. 387402. Springer, 2013. Elliot Bolton, Abhinav Venigalla, Michihiro Yasunaga, David Hall, Betty Xiong, Tony Lee, Roxana Daneshjou,Jonathan Frankle, Percy Liang, Michael Carbin, et al. Biomedlm: A 2.7 b parameter language modeltrained on biomedical text. arXiv preprint arXiv:2403.18421, 2024.",
  "Nadia Burkart and Marco F Huber. A survey on the explainability of supervised machine learning. Journalof Artificial Intelligence Research, 70:245317, 2021": "Johana Cabrera, M Soledad Loyola, Irene Magaa, and Rodrigo Rojas. Ethical dilemmas, mental health,artificial intelligence, and llm-based chatbots. In International Work-Conference on Bioinformatics andBiomedical Engineering, pp. 313326. Springer, 2023. Aaron Calafato, Christian Colombo, and Gordon J Pace. A controlled natural language for tax fraud detection.In Controlled Natural Language: 5th International Workshop, CNL 2016, Aberdeen, UK, July 25-27, 2016,Proceedings 5, pp. 112. Springer, 2016. Ethan Callanan, Amarachi Mbakwe, Antony Papadimitriou, Yulong Pei, Mathieu Sibue, Xiaodan Zhu,Zhiqiang Ma, Xiaomo Liu, and Sameena Shah. Can gpt models be financial analysts? an evaluation ofchatgpt and gpt-4 on mock cfa exams, 2023.",
  "Ilias Chalkidis, Manos Fergadiotis, Prodromos Malakasiotis, Nikolaos Aletras, and Ion Androutsopoulos.Legal-bert: The muppets straight out of law school. arXiv preprint arXiv:2010.02559, 2020": "Ilias Chalkidis, Manos Fergadiotis, and Ion Androutsopoulos. Multieurlexa multi-lingual and multi-labellegal document classification dataset for zero-shot cross-lingual transfer. arXiv preprint arXiv:2109.00904,2021a. Ilias Chalkidis, Manos Fergadiotis, Dimitrios Tsarapatsanis, Nikolaos Aletras, Ion Androutsopoulos, andProdromos Malakasiotis. Paragraph-level rationale extraction through regularization: A case study oneuropean court of human rights cases. arXiv preprint arXiv:2103.13084, 2021b. Ilias Chalkidis, Abhik Jana, Dirk Hartung, Michael Bommarito, Ion Androutsopoulos, Daniel Martin Katz,and Nikolaos Aletras. Lexglue: A benchmark dataset for legal language understanding in english. arXivpreprint arXiv:2110.00976, 2021c.",
  "Erwin Chemerinsky. Constitutional law. Aspen Publishing, 2023": "Andong Chen, Feng Yao, Xinyan Zhao, Yating Zhang, Changlong Sun, Yun Liu, and Weixing Shen. Equals:A real-world dataset for legal question answering via reading chinese laws. In Proceedings of the NineteenthInternational Conference on Artificial Intelligence and Law, pp. 7180, 2023a. Lulu Chen, Yingzhou Lu, Chiung-Ting Wu, Robert Clarke, Guoqiang Yu, Jennifer E Van Eyk, David MHerrington, and Yue Wang.Data-driven detection of subtype-specific differentially expressed genes.Scientific reports, 11(1):332, 2021a.",
  "Tianyi Chen, Nan Hao, Yingzhou Lu, and Capucine Van Rechem. Uncertainty quantification on clinical trialoutcome prediction. arXiv preprint arXiv:2401.03482, 2024": "Wei Chen, Qiushi Wang, Zefei Long, Xianyin Zhang, Zhongtian Lu, Bingxuan Li, Siyuan Wang, JiarongXu, Xiang Bai, Xuanjing Huang, and Zhongyu Wei. Disc-finllm: A chinese financial large language modelbased on multiple experts fine-tuning. CoRR, abs/2310.15205, 2023b. doi: 10.48550/ARXIV.2310.15205.URL Wenhu Chen, Xueguang Ma, Xinyi Wang, and William W. Cohen.Program of thoughts prompting:Disentangling computation from reasoning for numerical reasoning tasks.Transactions on MachineLearning Research, 2023c. Yuh-Jen Chen, Chun-Han Wu, Yuh-Min Chen, Hsin-Ying Li, and Huei-Kuen Chen. Enhancement of frauddetection for narratives in annual reports. International Journal of Accounting Information Systems, 26:3245, 2017. Zeming Chen, Alejandro Hernndez Cano, Angelika Romanou, Antoine Bonnet, Kyle Matoba, FrancescoSalvi, Matteo Pagliardini, Simin Fan, Andreas Kpf, Amirkeivan Mohtashami, et al. Meditron-70b: Scalingmedical pretraining for large language models. arXiv preprint arXiv:2311.16079, 2023d.",
  "Zhihong Chen, Yan Song, Tsung-Hui Chang, and Xiang Wan. Generating radiology reports via memory-driventransformer. arXiv preprint arXiv:2010.16056, 2020": "Zhiyu Chen, Wenhu Chen, Charese Smiley, Sameena Shah, Iana Borova, Dylan Langdon, Reema Moussa,Matt Beane, Ting-Hao Huang, Bryan R. Routledge, and William Yang Wang. Finqa: A dataset ofnumerical reasoning over financial data. In Marie-Francine Moens, Xuanjing Huang, Lucia Specia, andScott Wen-tau Yih (eds.), Proceedings of the 2021 Conference on Empirical Methods in Natural LanguageProcessing, EMNLP 2021, Virtual Event / Punta Cana, Dominican Republic, 7-11 November, 2021, pp.36973711. Association for Computational Linguistics, 2021b. doi: 10.18653/V1/2021.EMNLP-MAIN.300.URL Zhiyu Chen, Shiyang Li, Charese Smiley, Zhiqiang Ma, Sameena Shah, and William Yang Wang. Convfinqa:Exploring the chain of numerical reasoning in conversational finance question answering. In Yoav Goldberg,Zornitsa Kozareva, and Yue Zhang (eds.), Proceedings of the 2022 Conference on Empirical Methods inNatural Language Processing, EMNLP 2022, Abu Dhabi, United Arab Emirates, December 7-11, 2022, pp.62796292. Association for Computational Linguistics, 2022. doi: 10.18653/V1/2022.EMNLP-MAIN.421.URL Xueqi Cheng, Shenghua Liu, Xiaoqian Sun, Zidong Wang, Houquan Zhou, Yu Shao, and Huawei Shen.Combating emerging financial risks in the big data era: A perspective review. Fundamental Research, 1(5):595606, 2021. Inyoung Cheong, King Xia, KJ Feng, Quan Ze Chen, and Amy X Zhang. (a) i am not a lawyer, but...:Engaging legal experts towards responsible llm policies for legal advice. arXiv preprint arXiv:2402.01864,2024.",
  "Jonathan H Choi, Kristin E Hickman, Amy B Monahan, and Daniel Schwarcz. Chatgpt goes to law school.J. Legal Educ., 71:387, 2021": "Aakanksha Chowdhery, Sharan Narang, Jacob Devlin, Maarten Bosma, Gaurav Mishra, Adam Roberts,Paul Barham, Hyung Won Chung, Charles Sutton, Sebastian Gehrmann, Parker Schuh, Kensen Shi,Sasha Tsvyashchenko, Joshua Maynez, Abhishek Rao, Parker Barnes, Yi Tay, Noam Shazeer, VinodkumarPrabhakaran, Emily Reif, Nan Du, Ben Hutchinson, Reiner Pope, James Bradbury, Jacob Austin, MichaelIsard, Guy Gur-Ari, Pengcheng Yin, Toju Duke, Anselm Levskaya, Sanjay Ghemawat, Sunipa Dev, HenrykMichalewski, Xavier Garcia, Vedant Misra, Kevin Robinson, Liam Fedus, Denny Zhou, Daphne Ippolito,David Luan, Hyeontaek Lim, Barret Zoph, Alexander Spiridonov, Ryan Sepassi, David Dohan, ShivaniAgrawal, Mark Omernick, Andrew M. Dai, Thanumalayan Sankaranarayana Pillai, Marie Pellat, AitorLewkowycz, Erica Moreira, Rewon Child, Oleksandr Polozov, Katherine Lee, Zongwei Zhou, Xuezhi Wang,Brennan Saeta, Mark Diaz, Orhan Firat, Michele Catasta, Jason Wei, Kathy Meier-Hellstern, Douglas Eck,Jeff Dean, Slav Petrov, and Noah Fiedel. Palm: Scaling language modeling with pathways, 2022. Kevin Clark, Minh-Thang Luong, Quoc V. Le, and Christopher D. Manning. ELECTRA: pre-trainingtext encoders as discriminators rather than generators. In 8th International Conference on LearningRepresentations, ICLR 2020, Addis Ababa, Ethiopia, April 26-30, 2020. OpenReview.net, 2020. URL Pierre Colombo, Telmo Pessoa Pires, Malik Boudiaf, Dominic Culver, Rui Melo, Caio Corro, Andre FTMartins, Fabrizio Esposito, Vera Lcia Raposo, Sofia Morgado, et al. Saullm-7b: A pioneering largelanguage model for law. arXiv preprint arXiv:2403.03883, 2024.",
  "Marleen De Bruijne. Machine learning approaches in medical image analysis: From detection to diagnosis,2016": "Dina Demner-Fushman, Marc D Kohli, Marc B Rosenman, Sonya E Shooshan, Laritza Rodriguez, SameerAntani, George R Thoma, and Clement J McDonald. Preparing a collection of radiology examinations fordistribution and retrieval. Journal of the American Medical Informatics Association, 23(2):304310, 2016. Gelei Deng, Yi Liu, Yuekang Li, Kailong Wang, Ying Zhang, Zefeng Li, Haoyu Wang, Tianwei Zhang, andYang Liu. Jailbreaker: Automated jailbreak across multiple large language model chatbots. arXiv preprintarXiv:2307.08715, 2023a. Xiang Deng, Vasilisa Bashlovkina, Feng Han, Simon Baumgartner, and Michael Bendersky.What dollms know about financial markets? a case study on reddit market sentiment analysis. In CompanionProceedings of the ACM Web Conference 2023, WWW 23 Companion, pp. 107110, New York, NY, USA,2023b. Association for Computing Machinery. ISBN 9781450394192. doi: 10.1145/3543873.3587324. URL Yang Deng, Wenqiang Lei, Wenxuan Zhang, Wai Lam, and Tat-Seng Chua. PACIFIC: towards proactiveconversational question answering over tabular and textual data in finance. In Yoav Goldberg, ZornitsaKozareva, and Yue Zhang (eds.), Proceedings of the 2022 Conference on Empirical Methods in NaturalLanguage Processing, EMNLP 2022, Abu Dhabi, United Arab Emirates, December 7-11, 2022, pp. 69706984. Association for Computational Linguistics, 2022. doi: 10.18653/V1/2022.EMNLP-MAIN.469. URL Michael Denkowski and Alon Lavie. Meteor 1.3: Automatic metric for reliable optimization and evaluation ofmachine translation systems. In Proceedings of the sixth workshop on statistical machine translation, pp.8591, 2011.",
  "Franck Dernoncourt and Ji Young Lee. Pubmed 200k rct: a dataset for sequential sentence classification inmedical abstracts. arXiv preprint arXiv:1710.06071, 2017": "Jacob Devlin, Ming-Wei Chang, Kenton Lee, and Kristina Toutanova. BERT: pre-training of deep bidirectionaltransformers for language understanding. In Proceedings of the 2019 Conference of the North AmericanChapter of the Association for Computational Linguistics: Human Language Technologies, NAACL-HLT2019., pp. 41714186. Association for Computational Linguistics, 2019. Harnoor Dhingra, Preetiha Jayashanker, Sayali Moghe, and Emma Strubell. Queer people are people first:Deconstructing sexual identity stereotypes in large language models. arXiv preprint arXiv:2307.00101,2023. Joo Dias, Pedro A Santos, Nuno Cordeiro, Ana Antunes, Bruno Martins, Jorge Baptista, and Car-los Gonalves. State of the art in artificial intelligence applied to the legal domain. arXiv preprintarXiv:2204.07047, 2022. Xiao Ding, Yue Zhang, Ting Liu, and Junwen Duan. Using structured events to predict stock price movement:An empirical investigation. In Alessandro Moschitti, Bo Pang, and Walter Daelemans (eds.), Proceedingsof the 2014 Conference on Empirical Methods in Natural Language Processing, EMNLP 2014, October25-29, 2014, Doha, Qatar, A meeting of SIGDAT, a Special Interest Group of the ACL, pp. 14151425.ACL, 2014. doi: 10.3115/V1/D14-1148. URL",
  "Yushun Dong, Jing Ma, Song Wang, Chen Chen, and Jundong Li. Fairness in graph mining: A survey. IEEETransactions on Knowledge and Data Engineering, 2023": "Filip Karlo Doilovi, Mario Bri, and Nikica Hlupi. Explainable artificial intelligence: A survey. In 2018 41stInternational convention on information and communication technology, electronics and microelectronics(MIPRO), pp. 02100215. IEEE, 2018. Xingyi Duan, Baoxin Wang, Ziyue Wang, Wentao Ma, Yiming Cui, Dayong Wu, Shijin Wang, Ting Liu,Tianxiang Huo, Zhen Hu, et al. Cjrc: A reliable human-annotated benchmark dataset for chinese judicialreading comprehension. In Chinese Computational Linguistics: 18th China National Conference, CCL2019, Kunming, China, October 1820, 2019, Proceedings 18, pp. 439451. Springer, 2019. Yann Dubois, Xuechen Li, Rohan Taori, Tianyi Zhang, Ishaan Gulrajani, Jimmy Ba, Carlos Guestrin, PercyLiang, and Tatsunori B. Hashimoto. Alpacafarm: A simulation framework for methods that learn fromhuman feedback, 2023.",
  "William Easterly and Sergio Rebelo. Fiscal policy and economic growth. Journal of monetary economics, 32(3):417458, 1993": "Jessica Echterhoff, An Yan, Kyungtae Han, Amr Abdelraouf, Rohit Gupta, and Julian McAuley. Drivingthrough the concept gridlock: Unraveling explainability bottlenecks in automated driving. In Proceedingsof the IEEE/CVF Winter Conference on Applications of Computer Vision, pp. 73467355, 2024. Jan Egger, Christina Gsaxner, Antonio Pepe, Kelsey L Pomykala, Frederic Jonske, Manuel Kurz, Jianning Li,and Jens Kleesiek. Medical deep learninga systematic meta-review. Computer methods and programs inbiomedicine, 221:106874, 2022.",
  "Shahul Es, Jithin James, Luis Espinosa-Anke, and Steven Schockaert. Ragas: Automated evaluation ofretrieval augmented generation. arXiv preprint arXiv:2309.15217, 2023": "Angela Fan, Beliz Gokkaya, Mark Harman, Mitya Lyubarskiy, Shubho Sengupta, Shin Yoo, and Jie MZhang. Large language models for software engineering: Survey and open problems. arXiv preprintarXiv:2310.03533, 2023. Biaoyan Fang, Trevor Cohn, Timothy Baldwin, and Lea Frermann. Super-scotus: A multi-sourced datasetfor the supreme court of the us. In Proceedings of the Natural Legal Language Processing Workshop 2023,pp. 202214, 2023.",
  "Lawrence M Friedman. A history of American law. Simon and Schuster, 2005": "Isabel O Gallegos, Ryan A Rossi, Joe Barrow, Md Mehrab Tanjim, Sungchul Kim, Franck Dernoncourt, TongYu, Ruiyi Zhang, and Nesreen K Ahmed. Bias and fairness in large language models: A survey. arXivpreprint arXiv:2309.00770, 2023. Deep Ganguli, Liane Lovitt, Jackson Kernion, Amanda Askell, Yuntao Bai, Saurav Kadavath, Ben Mann,Ethan Perez, Nicholas Schiefer, Kamal Ndousse, et al. Red teaming language models to reduce harms:Methods, scaling behaviors, and lessons learned. arXiv preprint arXiv:2209.07858, 2022. Leo Gao, Stella Biderman, Sid Black, Laurence Golding, Travis Hoppe, Charles Foster, Jason Phang, HoraceHe, Anish Thite, Noa Nabeshima, Shawn Presser, and Connor Leahy. The pile: An 800gb dataset of diversetext for language modeling. CoRR, abs/2101.00027, 2021a. URL Ruizhuo Gao, Zeqi Zhang, Zhenning Shi, Dan Xu, Weijuan Zhang, and Dewei Zhu. A review of naturallanguage processing for financial technology. In International Symposium on Artificial Intelligence andRobotics 2021, volume 11884, pp. 262277. SPIE, 2021b. Weihao Gao, Zhuo Deng, Zhiyuan Niu, Fuju Rong, Chucheng Chen, Zheng Gong, Wenze Zhang, DaiminXiao, Fang Li, Zhenjie Cao, et al. Ophglm: Training an ophthalmology large language-and-vision assistantbased on instructions and dialogue. arXiv preprint arXiv:2306.12174, 2023a. Yunfan Gao, Yun Xiong, Xinyu Gao, Kangxiang Jia, Jinliu Pan, Yuxi Bi, Yi Dai, Jiawei Sun, and Haofen Wang.Retrieval-augmented generation for large language models: A survey. arXiv preprint arXiv:2312.10997,2023b.",
  "Andrew Gee, R Prager, G Treece, C Cash, and L Berman. Processing and visualizing three-dimensionalultrasound data. The British journal of radiology, 77(suppl_2):S186S193, 2004": "Frank W Geels. The impact of the financialeconomic crisis on sustainability transitions: Financial investment,governance and public discourse. Environmental Innovation and Societal Transitions, 6:6795, 2013. Sourojit Ghosh and Aylin Caliskan. Chatgpt perpetuates gender bias in machine translation and ignoresnon-gendered pronouns: Findings across bengali and five other low-resource languages. arXiv preprintarXiv:2305.10510, 2023.",
  "Aaryan Gupta, Vinya Dengre, Hamza Abubakar Kheruwala, and Manan Shah. Comprehensive review oftext-mining applications in finance. Financial Innovation, 6:125, 2020": "Suchin Gururangan, Ana Marasovi, Swabha Swayamdipta, Kyle Lo, Iz Beltagy, Doug Downey, andNoah A Smith. Dont stop pretraining: Adapt language models to domains and tasks. arXiv preprintarXiv:2004.10964, 2020. Philipp Hacker, Andreas Engel, and Marco Mauer. Regulating chatgpt and other large generative ai models.In Proceedings of the 2023 ACM Conference on Fairness, Accountability, and Transparency, pp. 11121123,2023.",
  "Nils Holzenberger, Andrew Blair-Stanek, and Benjamin Van Durme. A dataset for statutory reasoning in taxlaw entailment and question answering. arXiv preprint arXiv:2005.05257, 2020": "Edward J. Hu, Yelong Shen, Phillip Wallis, Zeyuan Allen-Zhu, Yuanzhi Li, Shean Wang, Lu Wang, andWeizhu Chen. Lora: Low-rank adaptation of large language models. In The Tenth International Conferenceon Learning Representations, ICLR 2022, Virtual Event, April 25-29, 2022. OpenReview.net, 2022. URL Gang Hu, Ke Qin, Chenhan Yuan, Min Peng, Alejandro Lopez-Lira, Benyou Wang, Sophia Ananiadou,Wanlong Yu, Jimin Huang, and Qianqian Xie. No language is an island: Unifying chinese and english infinancial large language models, instruction data, and benchmarks, 2024.",
  "Baichuan Inc. Baichuan-7b: A large-scale chinese generative language model, 2023. URL": "Jeremy Irvin, Pranav Rajpurkar, Michael Ko, Yifan Yu, Silviana Ciurea-Ilcus, Chris Chute, Henrik Marklund,Behzad Haghgoo, Robyn Ball, Katie Shpanskaya, et al. Chexpert: A large chest radiograph dataset withuncertainty labels and expert comparison. In Proceedings of the AAAI Conference on Artificial Intelligence,volume 33, pp. 590597, 2019. Pranab Islam, Anand Kannappan, Douwe Kiela, Rebecca Qian, Nino Scherrer, and Bertie Vidgen. Fi-nancebench: A new benchmark for financial question answering. CoRR, abs/2311.11944, 2023. doi:10.48550/ARXIV.2311.11944. URL",
  "Kwan Yuen Iu and Vanessa Man-Yi Wong. Chatgpt by openai: The end of litigation lawyers? Available atSSRN 4339839, 2023": "Neel Jain, Avi Schwarzschild, Yuxin Wen, Gowthami Somepalli, John Kirchenbauer, Ping-yeh Chiang, MicahGoldblum, Aniruddha Saha, Jonas Geiping, and Tom Goldstein. Baseline defenses for adversarial attacksagainst aligned language models. arXiv preprint arXiv:2309.00614, 2023. Saahil Jain, Ashwin Agrawal, Adriel Saporta, Steven QH Truong, Du Nguyen Duong, Tan Bui, PierreChambon, Yuhao Zhang, Matthew P Lungren, Andrew Y Ng, et al. Radgraph: Extracting clinical entitiesand relations from radiology reports. arXiv preprint arXiv:2106.14463, 2021. Jiaming Ji, Mickel Liu, Josef Dai, Xuehai Pan, Chi Zhang, Ce Bian, Boyuan Chen, Ruiyang Sun, YizhouWang, and Yaodong Yang. Beavertails: Towards improved safety alignment of llm via a human-preferencedataset. Advances in Neural Information Processing Systems, 36, 2024. Ziwei Ji, Nayeon Lee, Rita Frieske, Tiezheng Yu, Dan Su, Yan Xu, Etsuko Ishii, Ye Jin Bang, AndreaMadotto, and Pascale Fung. Survey of hallucination in natural language generation. ACM ComputingSurveys, 55(12):138, 2023. Albert Q Jiang, Alexandre Sablayrolles, Arthur Mensch, Chris Bamford, Devendra Singh Chaplot, Diegode las Casas, Florian Bressand, Gianna Lengyel, Guillaume Lample, Lucile Saulnier, et al. Mistral 7b.arXiv preprint arXiv:2310.06825, 2023. Cong Jiang and Xiaolei Yang. Legal syllogism prompting: Teaching large language models for legal judgmentprediction. In Proceedings of the Nineteenth International Conference on Artificial Intelligence and Law,pp. 417421, 2023. Hang Jiang, Xiajie Zhang, Robert Mahari, Daniel Kessler, Eric Ma, Tal August, Irene Li, AlexSandyPentland, Yoon Kim, Jad Kabbara, et al. Leveraging large language models for learning complex legalconcepts through storytelling. arXiv preprint arXiv:2402.17019, 2024. Di Jin, Eileen Pan, Nassim Oufattole, Wei-Hung Weng, Hanyi Fang, and Peter Szolovits. What disease doesthis patient have? A large-scale open domain question answering dataset from medical exams. CoRR,abs/2009.13081, 2020. URL Ming Jin, Shiyu Wang, Lintao Ma, Zhixuan Chu, James Y Zhang, Xiaoming Shi, Pin-Yu Chen, Yuxuan Liang,Yuan-Fang Li, Shirui Pan, and Qingsong Wen. Time-LLM: Time series forecasting by reprogramming largelanguage models. In International Conference on Learning Representations (ICLR), 2024. Qiao Jin, Bhuwan Dhingra, Zhengping Liu, William W. Cohen, and Xinghua Lu. Pubmedqa: A datasetfor biomedical research question answering. In Kentaro Inui, Jing Jiang, Vincent Ng, and Xiaojun Wan(eds.), Proceedings of the 2019 Conference on Empirical Methods in Natural Language Processing andthe 9th International Joint Conference on Natural Language Processing, EMNLP-IJCNLP 2019, HongKong, China, November 3-7, 2019, pp. 25672577. Association for Computational Linguistics, 2019. doi:10.18653/V1/D19-1259. URL",
  "Katikapalli Subramanyam Kalyan and Sivanesan Sangeetha. Secnlp: A survey of embeddings in clinicalnatural language processing. Journal of biomedical informatics, 101:103323, 2020": "Haoqiang Kang and Xiao-Yang Liu. Deficiency of large language models in finance: An empirical examinationof hallucination. In I Cant Believe Its Not Better Workshop: Failure Modes in the Age of FoundationModels, 2024. URL Yoshinobu Kano, Mi-Young Kim, Masaharu Yoshioka, Yao Lu, Juliano Rabelo, Naoki Kiyota, Randy Goebel,and Ken Satoh. Coliee-2018: Evaluation of the competition on legal information extraction and entailment.In New Frontiers in Artificial Intelligence: JSAI-isAI 2018 Workshops, JURISIN, AI-Biz, SKL, LENLS,IDAA, Yokohama, Japan, November 1214, 2018, Revised Selected Papers, pp. 177192. Springer, 2019. Jared Kaplan, Sam McCandlish, Tom Henighan, Tom B Brown, Benjamin Chess, Rewon Child, Scott Gray,Alec Radford, Jeffrey Wu, and Dario Amodei. Scaling laws for neural language models. arXiv preprintarXiv:2001.08361, 2020.",
  "Davinder Kaur, Suleyman Uslu, Kaley J Rittichier, and Arjan Durresi. Trustworthy artificial intelligence: areview. ACM computing surveys (CSUR), 55(2):138, 2022": "Simerjot Kaur, Charese Smiley, Akshat Gupta, Joy Sain, Dongsheng Wang, Suchetha Siddagangappa,Toyin Aguda, and Sameena Shah. Refind: Relation extraction financial dataset. In Hsin-Hsi Chen,Wei-Jou (Edward) Duh, Hen-Hsen Huang, Makoto P. Kato, Josiane Mothe, and Barbara Poblete (eds.),Proceedings of the 46th International ACM SIGIR Conference on Research and Development in InformationRetrieval, SIGIR 2023, Taipei, Taiwan, July 23-27, 2023, pp. 30543063. ACM, 2023. doi: 10.1145/3539618.3591911. URL Arif Ali Khan, Sher Badshah, Peng Liang, Muhammad Waseem, Bilal Khan, Aakash Ahmad, Mahdi Fahmideh,Mahmood Niazi, and Muhammad Azeem Akbar. Ethics of ai: A systematic literature review of principlesand challenges. In Proceedings of the 26th International Conference on Evaluation and Assessment inSoftware Engineering, pp. 383392, 2022.",
  "Pang Wei Koh and Percy Liang. Understanding black-box predictions via influence functions. In Internationalconference on machine learning, 2017": "Pang Wei Koh, Thao Nguyen, Yew Siang Tang, Stephen Mussmann, Emma Pierson, Been Kim, and PercyLiang. Concept bottleneck models. In International conference on machine learning, pp. 53385348. PMLR,2020. Rik Koncel-Kedziorski, Michael Krumdick, Viet Lai, Varshini Reddy, Charles Lovering, and Chris Tanner.Bizbench: A quantitative reasoning benchmark for business and finance. CoRR, abs/2311.06602, 2023. doi:10.48550/ARXIV.2311.06602. URL",
  "Aditya Kuppa, Nikon Rasumov-Rahe, and Marc Voses. Chain of reference prompting helps llm to think likea lawyer. In Generative AI+ Law Workshop, 2023": "Eren Kurshan, Jiahao Chen, Victor Storchan, and Hongda Shen. On the current and emerging challenges ofdeveloping fair and ethical ai solutions in financial services. In Proceedings of the second ACM internationalconference on AI in finance, pp. 18, 2021. Taeyoon Kwon, Kai Tzu iunn Ong, Dongjin Kang, Seungjun Moon, Jeong Ryong Lee, Dosik Hwang, YongsikSim, Beomseok Sohn, Dongha Lee, and Jinyoung Yeo. Large language models are clinical reasoners:Reasoning-aware diagnosis framework with prompt-generated rationales, 2024. Yanis Labrak, Adrien Bazoge, Emmanuel Morin, Pierre-Antoine Gourraud, Mickael Rouvier, and RichardDufour. Biomistral: A collection of open-source pretrained large language models for medical domains.arXiv preprint arXiv:2402.10373, 2024.",
  "Jean Lee, Nicholas Stevens, Soyeon Caren Han, and Minseok Song. A survey of large language models infinance (finllms). arXiv preprint arXiv:2402.02315, 2024": "Jinhyuk Lee, Wonjin Yoon, Sungdong Kim, Donghyeon Kim, Sunkyu Kim, Chan Ho So, and JaewooKang. BioBERT: a pre-trained biomedical language representation model for biomedical text mining.Bioinformatics, 36(4):12341240, 2020. Nayeon Lee, Wei Ping, Peng Xu, Mostofa Patwary, Pascale N Fung, Mohammad Shoeybi, and BryanCatanzaro. Factuality enhanced language models for open-ended text generation. Advances in NeuralInformation Processing Systems, 35:3458634599, 2022.",
  "David Leslie. Understanding artificial intelligence ethics and safety. arXiv preprint arXiv:1906.05684, 2019": "Patrick S. H. Lewis, Ethan Perez, Aleksandra Piktus, Fabio Petroni, Vladimir Karpukhin, Naman Goyal,Heinrich Kttler, Mike Lewis, Wen-tau Yih, Tim Rocktschel, Sebastian Riedel, and Douwe Kiela.Retrieval-augmented generation for knowledge-intensive NLP tasks. In Hugo Larochelle, MarcAurelioRanzato, Raia Hadsell, Maria-Florina Balcan, and Hsuan-Tien Lin (eds.), Advances in Neural InformationProcessing Systems 33: Annual Conference on Neural Information Processing Systems 2020, NeurIPS2020, December 6-12, 2020, virtual, 2020. URL Chunyuan Li, Cliff Wong, Sheng Zhang, Naoto Usuyama, Haotian Liu, Jianwei Yang, Tristan Naumann,Hoifung Poon, and Jianfeng Gao. Llava-med: Training a large language-and-vision assistant for biomedicinein one day. Advances in Neural Information Processing Systems, 36, 2024a. Guohao Li, Hasan Abed Al Kader Hammoud, Hani Itani, Dmitrii Khizbullin, and Bernard Ghanem. Camel:Communicative agents for \"mind\" exploration of large language model society. In Thirty-seventh Conferenceon Neural Information Processing Systems, 2023a. Hanzhou Li, John T Moon, Saptarshi Purkayastha, Leo Anthony Celi, Hari Trivedi, and Judy W Gichoya.Ethics of large language models in medicine and medical research. The Lancet Digital Health, 5(6):e333e335,2023b. Haohang Li, Yangyang Yu, Zhi Chen, Yuechen Jiang, Yang Li, Denghui Zhang, Rong Liu, Jordan W. Suchow,and Khaldoun Khashanah. Finmem: A performance-enhanced LLM trading agent with layered memoryand character design. In ICLR 2024 Workshop on Large Language Model (LLM) Agents, 2024b. URL Jiangtong Li, Yuxuan Bian, Guoxuan Wang, Yang Lei, Dawei Cheng, Zhijun Ding, and Changjun Jiang.CFGPT: chinese financial assistant with large language model.CoRR, abs/2309.10654, 2023c.doi:10.48550/ARXIV.2309.10654. URL Jiao Li, Yueping Sun, Robin J Johnson, Daniela Sciaky, Chih-Hsuan Wei, Robert Leaman, Allan Peter Davis,Carolyn J Mattingly, Thomas C Wiegers, and Zhiyong Lu. Biocreative v cdr task corpus: a resource forchemical disease relation extraction. Database, 2016, 2016. Jiazheng Li, Linyi Yang, Barry Smyth, and Ruihai Dong. Maec: A multimodal aligned earnings conferencecall dataset for financial risk prediction. In Proceedings of the 29th ACM International Conference onInformation & Knowledge Management, pp. 30633070, 2020a.",
  "Chin-Yew Lin. Rouge: A package for automatic evaluation of summaries. In Text summarization branchesout, pp. 7481, 2004": "Tsung-Yi Lin, Michael Maire, Serge Belongie, James Hays, Pietro Perona, Deva Ramanan, Piotr Dollr, andC Lawrence Zitnick. Microsoft coco: Common objects in context. In European conference on computervision, pp. 740755. Springer, 2014. Marco Lippi, Przemysaw Paka, Giuseppe Contissa, Francesca Lagioia, Hans-Wolfgang Micklitz, GiovanniSartor, and Paolo Torroni. Claudette: an automated detector of potentially unfair clauses in online termsof service. Artificial Intelligence and Law, 27:117139, 2019. Chang Liu, Yuanhe Tian, Weidong Chen, Yan Song, and Yongdong Zhang. Bootstrapping large languagemodels for radiology report generation. In Proceedings of the AAAI Conference on Artificial Intelligence,volume 38, pp. 1863518643, 2024a. Chuang Liu, Junzhuo Li, and Deyi Xiong. Tab-cqa: A tabular conversational question answering dataset onfinancial reports. In Sunayana Sitaram, Beata Beigman Klebanov, and Jason D. Williams (eds.), Proceedingsof the The 61st Annual Meeting of the Association for Computational Linguistics: Industry Track, ACL2023, Toronto, Canada, July 9-14, 2023, pp. 196207. Association for Computational Linguistics, 2023a. doi:10.18653/V1/2023.ACL-INDUSTRY.20. URL",
  "Haotian Liu, Chunyuan Li, Qingyang Wu, and Yong Jae Lee. Visual instruction tuning. Advances in neuralinformation processing systems, 36, 2024b": "Qianchu Liu, Stephanie L. Hyland, Shruthi Bannur, Kenza Bouzid, Daniel C. Castro, Maria TeodoraWetscherek, Robert Tinn, Harshita Sharma, Fernando Prez-Garca, Anton Schwaighofer, Pranav Rajpurkar,Sameer Tajdin Khanna, Hoifung Poon, Naoto Usuyama, Anja Thieme, Aditya Nori, Matthew P. Lungren,Ozan Oktay, and Javier Alvarez-Valle. Exploring the boundaries of gpt-4 in radiology. ArXiv, abs/2310.14573,2023b. URL",
  "Xiao-Yang Liu, Guoxuan Wang, and Daochen Zha. Fingpt: Democratizing internet-scale data for financiallarge language models. CoRR, abs/2307.10485, 2023c. doi: 10.48550/ARXIV.2307.10485. URL": "Xiaoyu Liu, Paiheng Xu, Junda Wu, Jiaxin Yuan, Yifan Yang, Yuhang Zhou, Fuxiao Liu, Tianrui Guan, Hao-liang Wang, Tong Yu, et al. Large language models and causal inference in collaboration: A comprehensivesurvey. arXiv preprint arXiv:2403.09606, 2024c. Yang Liu, Yuanshun Yao, Jean-Francois Ton, Xiaoying Zhang, Ruocheng Guo Hao Cheng, Yegor Klochkov,Muhammad Faaiz Taufiq, and Hang Li. Trustworthy llms: a survey and guideline for evaluating largelanguage models alignment. arXiv preprint arXiv:2308.05374, 2023d. Yi Liu, Gelei Deng, Zhengzi Xu, Yuekang Li, Yaowen Zheng, Ying Zhang, Lida Zhao, Tianwei Zhang, and YangLiu. Jailbreaking chatgpt via prompt engineering: An empirical study. arXiv preprint arXiv:2305.13860,2023e. Yinhan Liu, Myle Ott, Naman Goyal, Jingfei Du, Mandar Joshi, Danqi Chen, Omer Levy, Mike Lewis, LukeZettlemoyer, and Veselin Stoyanov. Roberta: A robustly optimized BERT pretraining approach. CoRR,abs/1907.11692, 2019. URL Zhengliang Liu, Mengshen He, Zuowei Jiang, Zihao Wu, Haixing Dai, Lian Zhang, Siyi Luo, Tianle Han,Xiang Li, Xi Jiang, et al. Survey on natural language processing in medical image analysis. Zhong nan daxue xue bao. Yi xue ban= Journal of Central South University. Medical Sciences, 47(8):981993, 2022. Zhuang Liu, Degen Huang, Kaiyu Huang, Zhuang Li, and Jun Zhao. Finbert: A pre-trained financial languagerepresentation model for financial text mining. In Proceedings of the twenty-ninth international conferenceon international joint conferences on artificial intelligence, pp. 45134519, 2021.",
  "Alejandro Lopez-Lira and Yuehua Tang. Can chatgpt forecast stock price movements? return predictabilityand large language models. CoRR, abs/2304.07619, 2023. doi: 10.48550/ARXIV.2304.07619. URL": "Antoine Louis, Gijs van Dijck, and Gerasimos Spanakis. Interpretable long-form legal question answeringwith retrieval-augmented large language models. In Proceedings of the AAAI Conference on ArtificialIntelligence, volume 38, pp. 2226622275, 2024. Dakuan Lu, Hengkui Wu, Jiaqing Liang, Yipei Xu, Qianyu He, Yipeng Geng, Mengkun Han, Yingsi Xin,and Yanghua Xiao. Bbt-fin: Comprehensive construction of chinese financial domain pre-trained languagemodel, corpus and benchmark. CoRR, abs/2302.09432, 2023. doi: 10.48550/ARXIV.2302.09432. URL Yingzhou Lu, Chiung-Ting Wu, Sarah J Parker, Zuolin Cheng, Georgia Saylor, Jennifer E Van Eyk, GuoqiangYu, Robert Clarke, David M Herrington, and Yue Wang. COT: an efficient and accurate method fordetecting marker genes among many subtypes. Bioinformatics Advances, 2(1):vbac037, 2022.",
  "Behrooz Mansouri and Ricardo Campos.Falqu: Finding answers to legal questions.arXiv preprintarXiv:2304.05611, 2023": "Carsten Maple, Lukasz Szpruch, Gregory Epiphaniou, Kalina Staykova, Simran Singh, William Penwarden,Yisi Wen, Zijian Wang, Jagdish Hariharan, and Pavle Avramovic. The ai revolution: opportunities andchallenges for the finance sector. arXiv preprint arXiv:2308.16538, 2023. Todor Markov, Chong Zhang, Sandhini Agarwal, Florentine Eloundou Nekoul, Theodore Lee, Steven Adler,Angela Jiang, and Lilian Weng. A holistic approach to undesired content detection in the real world. InProceedings of the AAAI Conference on Artificial Intelligence, volume 37, pp. 1500915018, 2023.",
  "Bertalan Mesk and Eric J Topol. The imperative for regulatory oversight of large language models (orgenerative ai) in healthcare. NPJ digital medicine, 6(1):120, 2023": "Grgoire Mialon, Roberto Dess, Maria Lomeli, Christoforos Nalmpantis, Ram Pasunuru, Roberta Raileanu,Baptiste Rozire, Timo Schick, Jane Dwivedi-Yu, Asli Celikyilmaz, et al. Augmented language models: asurvey. arXiv preprint arXiv:2302.07842, 2023. George Michalopoulos, Kyle Williams, Gagandeep Singh, and Thomas Lin. Medicalsum: A guided clinicalabstractive summarization model for generating medical reports from patient-doctor conversations. InFindings of the Association for Computational Linguistics: EMNLP 2022, pp. 47414749, 2022.",
  "Maximilian Mozes, Xuanli He, Bennett Kleinberg, and Lewis D Griffin. Use of llms for illicit purposes:Threats, prevention measures, and vulnerabilities. arXiv preprint arXiv:2308.12833, 2023": "Rajdeep Mukherjee, Abhinav Bohra, Akash Banerjee, Soumya Sharma, Manjunath Hegde, Afreen Shaikh,Shivani Shrivastava, Koustuv Dasgupta, Niloy Ganguly, Saptarshi Ghosh, and Pawan Goyal. Ectsum: Anew benchmark dataset for bullet point summarization of long earnings call transcripts. In Yoav Goldberg,Zornitsa Kozareva, and Yue Zhang (eds.), Proceedings of the 2022 Conference on Empirical Methods inNatural Language Processing, EMNLP 2022, Abu Dhabi, United Arab Emirates, December 7-11, 2022, pp.1089310906. Association for Computational Linguistics, 2022. doi: 10.18653/V1/2022.EMNLP-MAIN.748.URL",
  "Roberto Navigli, Simone Conia, and Bjrn Ross. Biases in large language models: origins, inventory, anddiscussion. ACM Journal of Data and Information Quality, 15(2):121, 2023": "John J Nay, David Karamardian, Sarah B Lawsky, Wenting Tao, Meghana Bhat, Raghav Jain, Aaron TravisLee, Jonathan H Choi, and Jungo Kasai. Large language models as tax attorneys: a case study in legalcapabilities emergence. Philosophical Transactions of the Royal Society A, 382(2270):20230159, 2024. James O Neill, Paul Buitelaar, Cecile Robin, and Leona O Brien. Classifying sentential modality in legallanguage: a use case in financial regulations, acts and directives. In Proceedings of the 16th edition of theInternational Conference on Articial Intelligence and Law, pp. 159168, 2017. Helen Ngo, Cooper Raterink, Joo GM Arajo, Ivan Zhang, Carol Chen, Adrien Morisot, and Nicholas Frosst.Mitigating harm in language models with conditional-likelihood filtration. arXiv preprint arXiv:2108.07790,2021.",
  "Vinayak Yogesh Ogavinee and et al. Anima: A comprehensive toolkit for medical image analysis, 2022. URL": "Joel Oksanen, Abhilash Majumder, Kumar Saunack, Francesca Toni, and Arun Dhondiyal. A graph-basedmethod for unsupervised knowledge discovery from financial texts. In Nicoletta Calzolari, Frdric Bchet,Philippe Blache, Khalid Choukri, Christopher Cieri, Thierry Declerck, Sara Goggi, Hitoshi Isahara, BenteMaegaard, Joseph Mariani, Hlne Mazo, Jan Odijk, and Stelios Piperidis (eds.), Proceedings of theThirteenth Language Resources and Evaluation Conference, LREC 2022, Marseille, France, 20-25 June2022, pp. 54125417. European Language Resources Association, 2022. URL",
  "Takuma Okuda and Sanae Shoda. Ai-based chatbot service for financial industry. Fujitsu Scientific andTechnical Journal, 54(2):48, 2018": "Jesutofunmi A Omiye, Haiwen Gui, Shawheen J Rezaei, James Zou, and Roxana Daneshjou. Large languagemodels in medicine: the potentials and pitfalls: a narrative review. Annals of Internal Medicine, 177(2):210220, 2024. Jasmine Chiat Ling Ong, Shelley Yin-Hsi Chang, Wasswa William, Atul J Butte, Nigam H Shah, LitaSui Tjien Chew, Nan Liu, Finale Doshi-Velez, Wei Lu, Julian Savulescu, et al. Ethical and regulatorychallenges of large language models in medicine. The Lancet Digital Health, 2024.",
  "Dimitris Papailiopoulos. Gpt-4 \"discovered\" the same sorting algorithm as alphadev by removing \"mov s p\".,June 2023. URL": "Christos Papaloukas, Ilias Chalkidis, Konstantinos Athinaios, Despina-Athanasia Pantazi, and ManolisKoubarakis. Multi-granular legal topic classification on greek legislation. arXiv preprint arXiv:2109.15298,2021. Kishore Papineni, Salim Roukos, Todd Ward, and Wei-Jing Zhu. Bleu: a method for automatic evaluationof machine translation. In Proceedings of the 40th annual meeting of the Association for ComputationalLinguistics, pp. 311318, 2002.",
  "Taejin Park. Enhancing anomaly detection in financial markets with an llm-based multi-agent framework,2024": "Yulong Pei, Amarachi Mbakwe, Akshat Gupta, Salwa Alamir, Hanxuan Lin, Xiaomo Liu, and SameenaShah. TweetFinSent: A dataset of stock sentiments on Twitter. In Chung-Chi Chen, Hen-Hsen Huang,Hiroya Takamura, and Hsin-Hsi Chen (eds.), Proceedings of the Fourth Workshop on Financial Technologyand Natural Language Processing (FinNLP), pp. 3747, Abu Dhabi, United Arab Emirates (Hybrid),December 2022. Association for Computational Linguistics.doi: 10.18653/v1/2022.finnlp-1.5.URL Chantal Pellegrini, Ege zsoy, Benjamin Busam, Nassir Navab, and Matthias Keicher. Radialog: A largevision-language model for radiology report generation and conversational assistance.arXiv preprintarXiv:2311.18681, 2023. Guilherme Penedo, Quentin Malartic, Daniel Hesslow, Ruxandra Cojocaru, Alessandro Cappelli, HamzaAlobeidli, Baptiste Pannier, Ebtesam Almazrouei, and Julien Launay. The refinedweb dataset for falconllm: outperforming curated corpora with web data, and web data only. arXiv preprint arXiv:2306.01116,2023.",
  "Kuashuai Peng and Guofeng Yan. A survey on deep learning for financial risk prediction. QuantitativeFinance and Economics, 5(4):716737, 2021": "Shengxin Peng, Deqiang Wang, Yuanhao Liang, Wenshan Xiao, Yixiang Zhang, and Lei Liu. Ai-chatgpt/gpt-4:An booster for the development of physical medicine and rehabilitation in the new era! Annals of BiomedicalEngineering, 52:462 466, 2023. URL Yifan Peng, Shankai Yan, and Zhiyong Lu. Transfer learning in biomedical natural language processing: anevaluation of bert and elmo on ten benchmarking datasets. arXiv preprint arXiv:1906.05474, 2019.",
  "Rebecca Qian, Candace Ross, Jude Fernandes, Eric Smith, Douwe Kiela, and Adina Williams. Perturbationaugmentation for fairer nlp. arXiv preprint arXiv:2205.12586, 2022": "Shuofei Qiao, Yixin Ou, Ningyu Zhang, Xiang Chen, Yunzhi Yao, Shumin Deng, Chuanqi Tan, Fei Huang,and Huajun Chen. Reasoning with language model prompting: A survey. arXiv preprint arXiv:2212.09597,2022. Alec Radford, Jong Wook Kim, Chris Hallacy, Aditya Ramesh, Gabriel Goh, Sandhini Agarwal, GirishSastry, Amanda Askell, Pamela Mishkin, Jack Clark, Gretchen Krueger, and Ilya Sutskever. Learningtransferable visual models from natural language supervision. In Marina Meila and Tong Zhang (eds.),Proceedings of the 38th International Conference on Machine Learning, ICML 2021, 18-24 July 2021,Virtual Event, volume 139 of Proceedings of Machine Learning Research, pp. 87488763. PMLR, 2021a.URL Alec Radford, Jong Wook Kim, Chris Hallacy, Aditya Ramesh, Gabriel Goh, et al. Learning transferablevisual models from natural language supervision. In International Conference on Machine Learning, 2021b. Colin Raffel, Noam Shazeer, Adam Roberts, Katherine Lee, Sharan Narang, Michael Matena, Yanqi Zhou,Wei Li, and Peter J. Liu. Exploring the limits of transfer learning with a unified text-to-text transformer.J. Mach. Learn. Res., 21:140:1140:67, 2020. URL",
  "Varshini Reddy, Rik Koncel-Kedziorski, Viet Dac Lai, and Chris Tanner. Docfinqa: A long-context financialreasoning dataset. CoRR, abs/2401.06915, 2024. doi: 10.48550/ARXIV.2401.06915. URL": "Ruiyang Ren, Yuhao Wang, Yingqi Qu, Wayne Xin Zhao, Jing Liu, Hao Tian, Hua Wu, Ji-Rong Wen, andHaifeng Wang. Investigating the factual knowledge boundary of large language models with retrievalaugmentation. arXiv preprint arXiv:2307.11019, 2023. Marco Tulio Ribeiro, Sameer Singh, and Carlos Guestrin. \" why should i trust you?\" explaining the predictionsof any classifier. In Proceedings of the 22nd ACM SIGKDD international conference on knowledge discoveryand data mining, pp. 11351144, 2016. Nicola Rieke, Jonny Hancox, Wenqi Li, Fausto Milletari, Holger R Roth, Shadi Albarqouni, Spyridon Bakas,Mathieu N Galtier, Bennett A Landman, Klaus Maier-Hein, et al. The future of digital health withfederated learning. NPJ digital medicine, 3(1):17, 2020.",
  "Thales Sales Almeida, Hugo Abonizio, Rodrigo Nogueira, and Ramon Pires. Sabi-2: A new generation ofportuguese large language models. arXiv e-prints, pp. arXiv2403, 2024": "Teven Le Scao, Angela Fan, Christopher Akiki, Ellie Pavlick, Suzana Ilic, Daniel Hesslow, Roman Castagn,Alexandra Sasha Luccioni, Franois Yvon, Matthias Gall, Jonathan Tow, Alexander M. Rush, Stella Bider-man, Albert Webson, Pawan Sasanka Ammanamanchi, Thomas Wang, Benot Sagot, Niklas Muennighoff,Albert Villanova del Moral, Olatunji Ruwase, Rachel Bawden, Stas Bekman, Angelina McMillan-Major,Iz Beltagy, Huu Nguyen, Lucile Saulnier, Samson Tan, Pedro Ortiz Suarez, Victor Sanh, Hugo Lau-renon, Yacine Jernite, Julien Launay, Margaret Mitchell, Colin Raffel, Aaron Gokaslan, Adi Simhi, AitorSoroa, Alham Fikri Aji, Amit Alfassy, Anna Rogers, Ariel Kreisberg Nitzav, Canwen Xu, Chenghao Mou,Chris Emezue, Christopher Klamm, Colin Leong, Daniel van Strien, David Ifeoluwa Adelani, and et al.BLOOM: A 176b-parameter open-access multilingual language model. CoRR, abs/2211.05100, 2022. doi:10.48550/ARXIV.2211.05100. URL Timo Schick, Jane Dwivedi-Yu, Roberto Dess, Roberta Raileanu, Maria Lomeli, Eric Hambro, LukeZettlemoyer, Nicola Cancedda, and Thomas Scialom.Toolformer:Language models can teachthemselves to use tools.In Alice Oh, Tristan Naumann, Amir Globerson, Kate Saenko, MoritzHardt, and Sergey Levine (eds.), Advances in Neural Information Processing Systems 36:An-nual Conference on Neural Information Processing Systems 2023, NeurIPS 2023, New Orleans, LA,USA, December 10 - 16, 2023, 2023. URL",
  "IRLab SDU. Fuzi Mingcha: Project for [add project description here]. 2023. Accessed: April 15, 2024": "Prasad Seemakurthi, Shuhao Zhang, and Yibing Qi. Detection of fraudulent financial reports with machinelearning techniques. In 2015 Systems and information engineering design symposium, pp. 358361. IEEE,2015. Isabel Segura-Bedmar, Paloma Martnez Fernndez, and Mara Herrero Zazo. Semeval-2013 task 9: Extractionof drug-drug interactions from biomedical texts (ddiextraction 2013). Association for ComputationalLinguistics, 2013. Rico Sennrich, Barry Haddow, and Alexandra Birch.Neural machine translation of rare words withsubword units. In Katrin Erk and Noah A. Smith (eds.), Proceedings of the 54th Annual Meeting of theAssociation for Computational Linguistics (Volume 1: Long Papers), pp. 17151725, Berlin, Germany,August 2016. Association for Computational Linguistics.doi: 10.18653/v1/P16-1162.URL",
  "Nurullah Sevim, Furkan ahinu, and Aykut Ko. Gender bias in legal corpora and debiasing it. NaturalLanguage Engineering, 29(2):449482, 2023": "Agam Shah, Suvan Paturi, and Sudheer Chava. Trillion dollar words: A new financial dataset, task & marketanalysis. In Anna Rogers, Jordan L. Boyd-Graber, and Naoaki Okazaki (eds.), Proceedings of the 61stAnnual Meeting of the Association for Computational Linguistics (Volume 1: Long Papers), ACL 2023,Toronto, Canada, July 9-14, 2023, pp. 66646679. Association for Computational Linguistics, 2023. doi:10.18653/V1/2023.ACL-LONG.368. URL",
  "Tianhao Shen, Renren Jin, Yufei Huang, Chuang Liu, Weilong Dong, Zishan Guo, Xinwei Wu, Yan Liu, andDeyi Xiong. Large language model alignment: A survey. arXiv preprint arXiv:2309.15025, 2023a": "Xinyue Shen, Zeyuan Chen, Michael Backes, Yun Shen, and Yang Zhang. \"do anything now\": Characterizingand evaluating in-the-wild jailbreak prompts on large language models. arXiv preprint arXiv:2308.03825,2023b. Zejiang Shen, Kyle Lo, Lauren Yu, Nathan Dahlberg, Margo Schlanger, and Doug Downey. Multi-lexsum:Real-world summaries of civil rights lawsuits at multiple granularities. Advances in Neural InformationProcessing Systems, 35:1315813173, 2022.",
  "Yuge Shi, Jeffrey Seely, Philip HS Torr, N Siddharth, Awni Hannun, Nicolas Usunier, and Gabriel Synnaeve.Gradient matching for domain generalization. arXiv preprint arXiv:2104.09937, 2021": "Zhouxing Shi, Yihan Wang, Fan Yin, Xiangning Chen, Kai-Wei Chang, and Cho-Jui Hsieh. Red teaminglanguage model detectors with language models. Transactions of the Association for ComputationalLinguistics, 12:174189, 2024. Noah Shinn, Federico Cassano, Ashwin Gopinath, Karthik Narasimhan, and Shunyu Yao. Reflexion: Languageagents with verbal reinforcement learning. Advances in Neural Information Processing Systems, 36, 2024.",
  "Chandan Singh, Jeevana Priya Inala, Michel Galley, Rich Caruana, and Jianfeng Gao. Rethinking inter-pretability in the era of large language models. arXiv preprint arXiv:2402.01761, 2024": "Karan Singhal, Shekoofeh Azizi, Tao Tu, S Sara Mahdavi, Jason Wei, Hyung Won Chung, Nathan Scales,Ajay Tanwani, Heather Cole-Lewis, Stephen Pfohl, et al. Large language models encode clinical knowledge.arXiv preprint arXiv:2212.13138, 2022. Karan Singhal, Tao Tu, Juraj Gottweis, Rory Sayres, Ellery Wulczyn, Le Hou, Kevin Clark, Stephen Pfohl,Heather Cole-Lewis, Darlene Neal, Mike Schaekermann, Amy Wang, Mohamed Amin, Sami Lachgar,Philip Mansfield, Sushant Prakash, Bradley Green, Ewa Dominowska, Blaise Aguera y Arcas, NenadTomasev, Yun Liu, Renee Wong, Christopher Semturs, S. Sara Mahdavi, Joelle Barral, Dale Webster,Greg S. Corrado, Yossi Matias, Shekoofeh Azizi, Alan Karthikesalingam, and Vivek Natarajan. Towardsexpert-level medical question answering with large language models, 2023.",
  "Gizem Soancolu, Hakime ztrk, and Arzucan zgr. Biosses: a semantic sentence similarity estimationsystem for the biomedical domain. Bioinformatics, 33(14):i49i58, 2017": "Guijin Son, Hanearl Jung, Moonjeong Hahm, Keonju Na, and Sol Jin. Beyond classification: Financialreasoning in state-of-the-art language models. CoRR, abs/2305.01505, 2023. doi: 10.48550/ARXIV.2305.01505. URL Yejun Soun, Jaemin Yoo, Minyong Cho, Jihyeong Jeon, and U Kang. Accurate stock movement predictionwith self-supervised learning from sparse noisy tweets. In 2022 IEEE International Conference on Big Data(Big Data), pp. 16911700. IEEE, 2022. Francesco Sovrano, Monica Palmirani, Biagio Distefano, Salvatore Sapienza, and Fabio Vitali. A datasetfor evaluating legal question answering on private international law. In Proceedings of the EighteenthInternational Conference on Artificial Intelligence and Law, pp. 230234, 2021.",
  "Christian Szegedy, Wojciech Zaremba, Ilya Sutskever, Joan Bruna, Dumitru Erhan, Ian Goodfellow, and RobFergus. Intriguing properties of neural networks. arXiv preprint arXiv:1312.6199, 2013": "Zeerak Talat, Aurlie Nvol, Stella Biderman, Miruna Clinciu, Manan Dey, Shayne Longpre, Sasha Luccioni,Maraim Masoud, Margaret Mitchell, Dragomir Radev, et al. You reap what you sow: On the challengesof bias evaluation under multilingual settings. In Proceedings of BigScience Episode# 5Workshop onChallenges & Perspectives in Creating Large Language Models, pp. 2641, 2022.",
  "Ran Tian, Shashi Narayan, Thibault Sellam, and Ankur P Parikh. Sticking to the facts: Confident decodingfor faithful data-to-text generation. arXiv preprint arXiv:1910.08684, 2019": "Augustin Toma, Patrick R Lawler, Jimmy Ba, Rahul G Krishnan, Barry B Rubin, and Bo Wang. Clinicalcamel: An open-source expert-level medical language model with dialogue-based knowledge encoding.arXiv preprint arXiv:2305.12031, 2023. Hugo Touvron, Thibaut Lavril, Gautier Izacard, Xavier Martinet, Marie-Anne Lachaux, Timothe Lacroix,Baptiste Rozire, Naman Goyal, Eric Hambro, Faisal Azhar, Aurelien Rodriguez, Armand Joulin, EdouardGrave, and Guillaume Lample. Llama: Open and efficient foundation language models, 2023a. Hugo Touvron, Louis Martin, Kevin Stone, Peter Albert, Amjad Almahairi, Yasmine Babaei, NikolayBashlykov, Soumya Batra, Prajjwal Bhargava, Shruti Bhosale, et al. Llama 2: Open foundation andfine-tuned chat models. arXiv preprint arXiv:2307.09288, 2023b.",
  "Dietrich Trautmann, Alina Petrova, and Frank Schilder. Legal prompt engineering for multilingual legaljudgement prediction. arXiv preprint arXiv:2212.02199, 2022": "Arianna Trozze, Toby Davies, and Bennett Kleinberg. Large language models in cryptocurrency securitiescases: can a gpt model meaningfully assist lawyers? Artificial Intelligence and Law, pp. 147, 2024. George Tsatsaronis, Georgios Balikas, Prodromos Malakasiotis, Ioannis Partalas, Matthias Zschunke,Michael R. Alvers, Dirk Weissenborn, Anastasia Krithara, Sergios Petridis, Dimitris Polychronopoulos, Yan-nis Almirantis, John Pavlopoulos, Nicolas Baskiotis, Patrick Gallinari, Thierry Artires, Axel-Cyrille NgongaNgomo, Norman Heino, ric Gaussier, Liliana Barrio-Alvers, Michael Schroeder, Ion Androutsopoulos, andGeorgios Paliouras. An overview of the BIOASQ large-scale biomedical semantic indexing and questionanswering competition. BMC Bioinform., 16:138:1138:28, 2015. doi: 10.1186/S12859-015-0564-6. URL Don Tuggener, Pius Von Dniken, Thomas Peetz, and Mark Cieliebak. Ledgar: A large-scale multi-labelcorpus for text classification of legal provisions in contracts. In Proceedings of the Twelfth LanguageResources and Evaluation Conference, pp. 12351241, 2020.",
  "Sahil Verma, John Dickerson, and Keegan Hines. Counterfactual explanations for machine learning: A review.arXiv preprint arXiv:2010.10596, 2, 2020": "David Vilares and Carlos Gmez-Rodrguez. HEAD-QA: A healthcare dataset for complex reasoning. InAnna Korhonen, David R. Traum, and Llus Mrquez (eds.), Proceedings of the 57th Conference of theAssociation for Computational Linguistics, ACL 2019, Florence, Italy, July 28- August 2, 2019, Volume 1:Long Papers, pp. 960966. Association for Computational Linguistics, 2019. doi: 10.18653/V1/P19-1092.URL Dingzirui Wang, Longxu Dou, Wenbin Zhang, Junyu Zeng, and Wanxiang Che. Exploring equation as a betterintermediate meaning representation for numerical reasoning of large language models. Proceedings of theAAAI Conference on Artificial Intelligence, 38(17):1911619125, Mar. 2024a. doi: 10.1609/aaai.v38i17.29879.URL",
  "Dingzirui Wang, Longxu Dou, Xuanliang Zhang, Qingfu Zhu, and Wanxiang Che. Enhancing numericalreasoning with the guidance of reliable reasoning processes. arXiv preprint arXiv:2402.10654, 2024b": "Dongsheng Wang, Natraj Raman, Mathieu Sibue, Zhiqiang Ma, Petr Babkin, Simerjot Kaur, Yulong Pei,Armineh Nourbakhsh, and Xiaomo Liu. Docllm: A layout-aware generative language model for multimodaldocument understanding, 2023a. Haoyu Wang, Guozheng Ma, Cong Yu, Ning Gui, Linrui Zhang, Zhiqi Huang, Suwei Ma, Yongzhe Chang,Sen Zhang, Li Shen, et al. Are large language models really robust to word-level perturbations? arXivpreprint arXiv:2309.11166, 2023b. Lei Wang, Chen Ma, Xueyang Feng, Zeyu Zhang, Hao Yang, Jingsen Zhang, Zhiyuan Chen, Jiakai Tang,Xu Chen, Yankai Lin, et al. A survey on large language model based autonomous agents. Frontiers ofComputer Science, 18(6):126, 2024c. Neng Wang, Hongyang Yang, and Christina Dan Wang. Fingpt: Instruction tuning benchmark for open-sourcelarge language models in financial datasets. CoRR, abs/2310.04793, 2023c. doi: 10.48550/ARXIV.2310.04793. URL",
  "Alexander Wei, Nika Haghtalab, and Jacob Steinhardt. Jailbroken: How does llm safety training fail?Advances in Neural Information Processing Systems, 36, 2024": "Jason Wei, Xuezhi Wang, Dale Schuurmans, Maarten Bosma, Brian Ichter, Fei Xia, Ed H. Chi, Quoc V. Le,and Denny Zhou. Chain-of-thought prompting elicits reasoning in large language models. In Sanmi Koyejo,S. Mohamed, A. Agarwal, Danielle Belgrave, K. Cho, and A. Oh (eds.), Advances in Neural InformationProcessing Systems 35: Annual Conference on Neural Information Processing Systems 2022, NeurIPS 2022,New Orleans, LA, USA, November 28 - December 9, 2022, 2022. URL Laura Weidinger, John Mellor, Maribeth Rauh, Conor Griffin, Jonathan Uesato, Po-Sen Huang, Myra Cheng,Mia Glaese, Borja Balle, Atoosa Kasirzadeh, et al. Ethical and social risks of harm from language models.arXiv preprint arXiv:2112.04359, 2021.",
  "Chaoyi Wu, Weixiong Lin, Xiaoman Zhang, Ya Zhang, Yanfeng Wang, and Weidi Xie. Pmc-llama: Towardsbuilding open-source language models for medicine, 2023b": "Chaoyi Wu, Weixiong Lin, Xiaoman Zhang, Ya Zhang, Weidi Xie, and Yanfeng Wang. Pmc-llama: towardbuilding open-source language models for medicine. Journal of the American Medical Informatics Association,pp. ocae045, 2024. Huizhe Wu, Wei Zhang, Weiwei Shen, and Jun Wang. Hybrid deep sequential modeling for social text-drivenstock prediction. In Alfredo Cuzzocrea, James Allan, Norman W. Paton, Divesh Srivastava, RakeshAgrawal, Andrei Z. Broder, Mohammed J. Zaki, K. Seluk Candan, Alexandros Labrinidis, Assaf Schuster,and Haixun Wang (eds.), Proceedings of the 27th ACM International Conference on Information andKnowledge Management, CIKM 2018, Torino, Italy, October 22-26, 2018, pp. 16271630. ACM, 2018. doi:10.1145/3269206.3269290. URL Likang Wu, Zhi Zheng, Zhaopeng Qiu, Hao Wang, Hongchao Gu, Tingjia Shen, Chuan Qin, Chen Zhu,Hengshu Zhu, Qi Liu, et al. A survey on large language models for recommendation. arXiv preprintarXiv:2305.19860, 2023c.",
  "Peng Xiao-Song. LaWGPT: A Legal Writing GPT Model. Accessed: 2024-04-29": "Qianqian Xie, Weiguang Han, Xiao Zhang, Yanzhao Lai, Min Peng, Alejandro Lopez-Lira, and JiminHuang. PIXIU: A large language model, instruction data and evaluation benchmark for finance. CoRR,abs/2306.05443, 2023. doi: 10.48550/ARXIV.2306.05443. URL Qianqian Xie, Qingyu Chen, Aokun Chen, Cheng Peng, Yan Hu, Fongci Lin, Xueqing Peng, Jimin Huang,Jeffrey Zhang, Vipina Keloth, et al. Me llama: Foundation large language models for medical applications.arXiv preprint arXiv:2402.12749, 2024a. Qianqian Xie, Weiguang Han, Zhengyu Chen, Ruoyu Xiang, Xiao Zhang, Yueru He, Mengxi Xiao, Dong Li,Yongfu Dai, Duanyu Feng, et al. The finben: An holistic financial benchmark for large language models.arXiv preprint arXiv:2402.12659, 2024b.",
  "Canwen Xu, Daya Guo, Nan Duan, and Julian McAuley. Baize: An open-source chat model with parameter-efficient tuning on self-chat data, 2023": "Kelvin Xu, Jimmy Ba, Ryan Kiros, Kyunghyun Cho, Aaron Courville, Ruslan Salakhudinov, Rich Zemel,and Yoshua Bengio. Show, attend and tell: Neural image caption generation with visual attention. InInternational conference on machine learning, pp. 20482057, 2015. Yumo Xu and Shay B. Cohen. Stock movement prediction from tweets and historical prices. In IrynaGurevych and Yusuke Miyao (eds.), Proceedings of the 56th Annual Meeting of the Association forComputational Linguistics, ACL 2018, Melbourne, Australia, July 15-20, 2018, Volume 1: Long Papers,pp. 19701979. Association for Computational Linguistics, 2018. doi: 10.18653/V1/P18-1183. URL",
  "Nicole Yamane. Artificial intelligence in the legal field and the indispensable human element legal ethicsdemands. Geo. J. Legal Ethics, 33:877, 2020": "An Yan, Zexue He, Xing Lu, Jiang Du, Eric Chang, Amilcare Gentili, Julian McAuley, and Chun-Nan Hsu.Weakly supervised contrastive learning for chest x-ray report generation. arXiv preprint arXiv:2109.12242,2021. An Yan, Julian McAuley, Xing Lu, Jiang Du, Eric Y Chang, Amilcare Gentili, and Chun-Nan Hsu. Radbert:Adapting transformer-based language models to radiology. Radiology: Artificial Intelligence, 4(4):e210258,2022. An Yan, Zhankui He, Jiacheng Li, Tianyang Zhang, and Julian McAuley. Personalized showcases: Generatingmulti-modal explanations for recommendations. In Proceedings of the 46th International ACM SIGIRConference on Research and Development in Information Retrieval, pp. 22512255, 2023a. An Yan, Yu Wang, Yiwu Zhong, Chengyu Dong, Zexue He, Yujie Lu, William Yang Wang, Jingbo Shang,and Julian McAuley. Learning concise and descriptive attributes for visual recognition. In Proceedings ofthe IEEE/CVF International Conference on Computer Vision, pp. 30903100, 2023b. An Yan, Yu Wang, Yiwu Zhong, Zexue He, Petros Karypis, Zihan Wang, Chengyu Dong, Amilcare Gentili,Chun-Nan Hsu, Jingbo Shang, et al. Robust and interpretable medical image classifiers via conceptbottleneck models. arXiv preprint arXiv:2310.03182, 2023c. An Yan, Zhengyuan Yang, Junda Wu, Wanrong Zhu, Jianwei Yang, Linjie Li, Kevin Lin, Jianfeng Wang,Julian McAuley, Jianfeng Gao, et al. List items one by one: A new data source and learning paradigm formultimodal llms. arXiv preprint arXiv:2404.16375, 2024a. Lixiang Yan, Lele Sha, Linxuan Zhao, Yuheng Li, Roberto Martinez-Maldonado, Guanliang Chen, Xinyu Li,Yueqiao Jin, and Dragan Gaevi. Practical and ethical challenges of large language models in education:A systematic scoping review. British Journal of Educational Technology, 55(1):90112, 2024b.",
  "Fangyi Yu, Lee Quartey, and Frank Schilder. Legal prompting: Teaching a language model to think like alawyer. arXiv preprint arXiv:2212.01326, 2022": "Fangyi Yu, Lee Quartey, and Frank Schilder. Exploring the effectiveness of prompt engineering for legalreasoning tasks. In Findings of the Association for Computational Linguistics: ACL 2023, pp. 1358213596,2023a. Jifan Yu, Xiaozhi Wang, Shangqing Tu, Shulin Cao, Daniel Zhang-Li, Xin Lv, Hao Peng, Zijun Yao, XiaohanZhang, Hanming Li, et al. Kola: Carefully benchmarking world knowledge of large language models. arXivpreprint arXiv:2306.09296, 2023b.",
  "Ping Yu, Hua Xu, Xia Hu, and Chao Deng.Leveraging generative ai and large language models: acomprehensive roadmap for healthcare integration. In Healthcare, volume 11, pp. 2776. MDPI, 2023c": "Wenhao Yu, Dan Iter, Shuohang Wang, Yichong Xu, Mingxuan Ju, Soumya Sanyal, Chenguang Zhu, MichaelZeng, and Meng Jiang. Generate rather than retrieve: Large language models are strong context generators,2023d. Xinli Yu, Zheng Chen, and Yanbin Lu. Harnessing LLMs for temporal data - a study on explainablefinancial time series forecasting. In Mingxuan Wang and Imed Zitouni (eds.), Proceedings of the 2023Conference on Empirical Methods in Natural Language Processing: Industry Track, pp. 739753, Singapore,December 2023e. Association for Computational Linguistics. doi: 10.18653/v1/2023.emnlp-industry.69.URL Lifan Yuan, Yangyi Chen, Ganqu Cui, Hongcheng Gao, Fangyuan Zou, Xingyi Cheng, Heng Ji, ZhiyuanLiu, and Maosong Sun. Revisiting out-of-distribution robustness in nlp: Benchmarks, analysis, and llmsevaluations. Advances in Neural Information Processing Systems, 36, 2024. Chongjian Yue, Xinrun Xu, Xiaojun Ma, Lun Du, Hengyu Liu, Zhiming Ding, Yanbing Jiang, Shi Han, andDongmei Zhang. Enabling and analyzing how to efficiently extract information from hybrid long documentswith llms, 2024.",
  "Fanlong Zeng, Wensheng Gan, Yongheng Wang, Ning Liu, and Philip S Yu. Large language models forrobotics: A survey. arXiv preprint arXiv:2311.07226, 2023": "Boyu Zhang, Hongyang Yang, and Xiao-Yang Liu. Instruct-fingpt: Financial sentiment analysis by instructiontuning of general-purpose large language models. CoRR, abs/2306.12659, 2023a. doi: 10.48550/ARXIV.2306.12659. URL Boyu Zhang, Hongyang Yang, Tianyu Zhou, Muhammad Ali Babar, and Xiao-Yang Liu.Enhancingfinancial sentiment analysis via retrieval augmented large language models. In Proceedings of the FourthACM International Conference on AI in Finance, ICAIF 23, pp. 349356, New York, NY, USA, 2023b.Association for Computing Machinery.ISBN 9798400702402.doi: 10.1145/3604237.3626866.URL",
  "Shuo Zhang, Liangming Pan, Junzhou Zhao, and William Yang Wang. Mitigating language model hallucinationwith interactive question-knowledge alignment. arXiv preprint arXiv:2305.13669, 2023f": "Xiao Zhang, Ruoyu Xiang, Chenhan Yuan, Duanyu Feng, Weiguang Han, Alejandro Lopez-Lira, Xiao-YangLiu, Sophia Ananiadou, Min Peng, Jimin Huang, and Qianqian Xie. Dlares or dollars? unravelingthe bilingual prowess of financial llms between spanish and english. CoRR, abs/2402.07405, 2024b. doi:10.48550/ARXIV.2402.07405. URL Xinlu Zhang, Shiyang Li, Xianjun Yang, Chenxin Tian, Yao Qin, and Linda Ruth Petzold. Enhancingsmall medical learners with privacy-preserving contextual prompting. CoRR, abs/2305.12723, 2023g. doi:10.48550/ARXIV.2305.12723. URL",
  "Xinlu Zhang, Chenxin Tian, Xianjun Yang, Lichang Chen, Zekun Li, and Linda Ruth Petzold.Alpacare:instruction-tuned large language models for medical application, 2023j": "Yuanmin Zhang, Junjun Jiang, and Yanjun Li. Intelligent analysis and application of judicial big datasharing based on blockchain. In 2023 6th International Conference on Artificial Intelligence and Big Data(ICAIBD), pp. 592596. IEEE, 2023k. Yue Zhang, Yafu Li, Leyang Cui, Deng Cai, Lemao Liu, Tingchen Fu, Xinting Huang, Enbo Zhao, Yu Zhang,Yulong Chen, et al. Sirens song in the ai ocean: a survey on hallucination in large language models. arXivpreprint arXiv:2309.01219, 2023l.",
  "Andrew Zhe.lawyer-llama:A Machine Learning Toolkit for Legal Analysis. 2024. Accessed: 2024-04-29": "Jiaping Zheng, Wendy W Chapman, Rebecca S Crowley, and Guergana K Savova. Coreference resolution: Areview of general methodologies and applications in the clinical domain. Journal of biomedical informatics,44(6):11131122, 2011. Lianmin Zheng, Wei-Lin Chiang, Ying Sheng, Siyuan Zhuang, Zhanghao Wu, Yonghao Zhuang, Zi Lin,Zhuohan Li, Dacheng Li, Eric. P Xing, Hao Zhang, Joseph E. Gonzalez, and Ion Stoica.Judgingllm-as-a-judge with mt-bench and chatbot arena, 2023. Lucia Zheng, Neel Guha, Brandon R Anderson, Peter Henderson, and Daniel E Ho. When does pretraininghelp? assessing self-supervised learning for law and the casehold dataset of 53,000+ legal holdings. InProceedings of the eighteenth international conference on artificial intelligence and law, pp. 159168, 2021. Haoxi Zhong, Chaojun Xiao, Cunchao Tu, Tianyang Zhang, Zhiyuan Liu, and Maosong Sun. Jec-qa: alegal-domain question answering dataset. In Proceedings of the AAAI conference on artificial intelligence,volume 34, pp. 97019708, 2020. Chunting Zhou, Pengfei Liu, Puxin Xu, Srinivasan Iyer, Jiao Sun, Yuning Mao, Xuezhe Ma, AviaEfrat, Ping Yu, Lili Yu, Susan Zhang, Gargi Ghosh, Mike Lewis, Luke Zettlemoyer, and Omer Levy.LIMA: less is more for alignment.In Alice Oh, Tristan Naumann, Amir Globerson, Kate Saenko,Moritz Hardt, and Sergey Levine (eds.), Advances in Neural Information Processing Systems 36: An-nual Conference on Neural Information Processing Systems 2023, NeurIPS 2023, New Orleans, LA,USA, December 10 - 16, 2023, 2023. URL Hongjian Zhou, Fenglin Liu, Boyang Gu, Xinyu Zou, Jinfa Huang, Jinge Wu, Yiru Li, Sam S. Chen, PeilinZhou, Junling Liu, Yining Hua, Chengfeng Mao, Chenyu You, Xian Wu, Yefeng Zheng, Lei Clifton, ZhengLi, Jiebo Luo, and David A. Clifton. A survey of large language models in medicine: Progress, application,and challenge, 2024a.",
  "Yuhang Zhou, Yuchen Ni, Xiang Liu, Jian Zhang, Sen Liu, Guangnan Ye, and Hongfeng Chai. Are largelanguage models rational investors? arXiv preprint arXiv:2402.12713, 2024b": "Zhihan Zhou, Liqian Ma, and Han Liu. Trade the event: Corporate events detection for news-based event-driven trading. In Chengqing Zong, Fei Xia, Wenjie Li, and Roberto Navigli (eds.), Findings of theAssociation for Computational Linguistics: ACL/IJCNLP 2021, Online Event, August 1-6, 2021, volumeACL/IJCNLP 2021 of Findings of ACL, pp. 21142124. Association for Computational Linguistics, 2021.doi: 10.18653/V1/2021.FINDINGS-ACL.186. URL Fengbin Zhu, Wenqiang Lei, Youcheng Huang, Chao Wang, Shuo Zhang, Jiancheng Lv, Fuli Feng, and Tat-Seng Chua. TAT-QA: A question answering benchmark on a hybrid of tabular and textual content in finance.In Chengqing Zong, Fei Xia, Wenjie Li, and Roberto Navigli (eds.), Proceedings of the 59th Annual Meetingof the Association for Computational Linguistics and the 11th International Joint Conference on NaturalLanguage Processing, ACL/IJCNLP 2021, (Volume 1: Long Papers), Virtual Event, August 1-6, 2021,pp. 32773287. Association for Computational Linguistics, 2021. doi: 10.18653/V1/2021.ACL-LONG.254.URL",
  "Andy Zou, Zifan Wang, J Zico Kolter, and Matt Fredrikson. Universal and transferable adversarial attackson aligned language models. arXiv preprint arXiv:2307.15043, 2023": "Jinan Zou, Haiyao Cao, Lingqiao Liu, Yuhao Lin, Ehsan Abbasnejad, and Javen Qinfeng Shi. Astock: A newdataset and automated stock trading based on stock-specific news analyzing model. CoRR, abs/2206.06606,2022. doi: 10.48550/ARXIV.2206.06606. URL Yang Zou, Arto Kiviniemi, and Stephen W Jones. Retrieving similar cases for construction project riskmanagement using natural language processing techniques. Automation in construction, 80:6676, 2017."
}