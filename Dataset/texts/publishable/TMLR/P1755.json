{
  "Abstract": "This paper introduces a novel approach to personalised federated learning within the X-armedbandit framework, addressing the challenge of optimising both local and global objectives ina highly heterogeneous environment. Our method employs a surrogate objective functionthat combines individual client preferences with aggregated global knowledge, allowing fora flexible trade-off between personalisation and collective learning. We propose a phase-based elimination algorithm that achieves sublinear regret with logarithmic communicationoverhead, making it well-suited for federated settings. Theoretical analysis and empiricalevaluations demonstrate the effectiveness of our approach compared to existing methods.Potential applications of this work span various domains, including healthcare, smart homedevices, and e-commerce, where balancing personalisation with global insights is crucial.",
  "Introduction": "In the rapidly evolving field of machine learning, realising appropriate levels of personalisation has emerged as acritical challenge. This article addresses this pressing concern within the context of sequential decision-making,specifically focusing on the X-armed bandit (Bubeck et al., 2011). The need for both data aggregation andindividual customisation is evident in various domains. For instance, in the context of healthcare, data canbe aggregated across subjects to yield population-level insights into (e.g., dosage efficacy), but individualdifferences necessitate personalised treatment. Similarly, for smart home devices, data aggregation acrossthe clients can result in improved general policies, but each individual home has different characteristics;privacy should be guaranteed to encourage the beneficial aggregation of data for the common good, butpersonalised policies need to be implemented at individual devices. These scenarios highlight two key concepts:federated learning (Konen`y et al., 2016; McMahan et al., 2017), which enables data aggregation whilemaintaining privacy, and personalisation(Smith et al., 2017), which tailors strategies to individual needs.However, the optimal level of personalisation varies across different applications and use-cases; therefore, aone-size-fits-all approach is insufficient. This article develops a personalised federated learning framework forthe X-armed bandit, designed to allow flexible trade-offs between global and individual objectives, enhancinguser experience by sharing exploration of the decision space, aggregating data securely, and facilitatingindividually beneficial decisions. Federated learning (FL) (Konen`y et al., 2016; McMahan et al., 2017) is a distributed learning paradigmthat addresses efficiency and privacy concerns in real-world, unbalanced and non-IID datasets. As datasetsgrow and models become more complex, the need to distribute the learning process across multiple machines",
  "Published in Transactions on Machine Learning Research (09/2024)": "Remark 3.11 (Effect of Personalisation Parameter). As shown in (4), the personalisation parameter influences the second and third terms of the regret bound. However, the third term is dominated by thesecond and fourth terms, which masks the impact of on the overall bound. We conjecture that this lackof dependence on may be due to the upper bound not being tight, as well as the absence of a parameterbounding the differences between local objectives. Establishing such a bound could reduce the pessimism inour analysis, potentially clarifying the role of personalisation parameter in the regret performance.",
  "FL and Multi-Armed Bandits": "While state-of-the-art FL research has predominantly focused on supervised learning scenarios, there is agrowing interest in extending FL to the multi-armed bandit (MAB) framework (Lai & Robbins, 1985; Aueret al., 2002). The MAB problem is a popular framework for studying decision-making under uncertainty.In its simplest form, the MAB consists of a set of independent arms, each providing a random rewardfrom its corresponding probability distribution. An agent, without prior knowledge of these distributions,selects one arm in each round, aiming to maximise the total expected reward over time. This processnecessitates a delicate balance between exploring arms to learn the unknown distributions and exploiting thecurrent knowledge by choosing the arm that has historically provided the highest reward. The extensionof FL to MAB is particularly relevant for applications like recommender systems and clinical trials, wheredecision-making is inherently distributed across multiple clients. Unlike centralised MAB models that assume instant data access, the FL approach processes data locallyat each client, thereby reducing communication overhead and enhancing data privacy. However, federatedbandits introduce unique challenges beyond the classical exploration-exploitation trade-off in centralisedmodels. These challenges include data heterogeneity and privacy preservation(Shi & Shen, 2021; Shi et al.,2021; Huang et al., 2021; Li et al., 2024b; Rda et al., 2022). In FL scenarios, collaboration among clientsbecomes crucial for accurate inference on the global model, especially given that each clients data may notbe independent and identically distributed. Yet privacy concerns and communication costs motivate clientsto avoid direct transmissions of local data. The X-armed bandit (XAB) problem is an extension of the classic MAB problem, where the decision-space issignificantly larger and even continuous, involving a potentially infinite number of arms. Unlike traditionalMAB problems which are limited to a discrete set of options, the XAB framework allows for a broader rangeof actions, making it particularly suited for complex environments where actions cannot be easily enumerated.This complexity introduces unique challenges in terms of exploration and exploitation, as the agent mustefficiently navigate a vastly expanded action space to optimise outcomes. (Bubeck et al., 2011; Kleinberget al., 2008) Balancing exploration and exploitation while achieving privacy and personalisation requires a complex yetefficient communication protocol between clients and a central server. While Shi et al. (2021) have addressedthis problem for finite, un-structured action spaces in their work on Personalised Federated MAB (PF-MAB),our work extends the principles of personalised federated learning to the XAB problem. In PF-MAB, thehigh probability guarantee that each clients active set eventually converges to a single best arm enables a",
  "Our primary contributions are as follows:": "1. We propose a novel personalised federated XAB model that accounts for user preferences and dataheterogeneity. This model is strategically designed to optimise the trade-offs between communicationefficiency and learning performance in a federated bandit setting. 2. We introduce PF-XAB, a novel algorithm tailored to the personalised federated XAB problem. Keyfeatures of PF-XAB include: a) edge clients communicate only their local reward estimates, preservingprivacy of raw observations, b) the algorithm achieves sublinear regret while maintaining logarithmiccommunication cost.",
  "Preliminaries": "In this section, we define the framework for our study of the personalised federated XAB problem. We willoutline our model and specific objectives, introducing the key notation and assumptions that underpin ouranalysis. For an integer n N, we let [n] represent the set of integers {1, 2, . . . , n}. For a set A, |A| denotesthe size of set A.",
  "Problem Formulation": "Clients and local models.Let X be the measurable space of arms. We model the problem, followingLi et al. (2024b), as a federation of M N clients, each with access to a distinct bounded local objectivem(x) : X , m [M]. These objectives may be non-convex, non-differentiable, and even discontinuous.As we focus on bounded functions, without loss of generality, we assume these functions are bounded withinthe unit interval . Given a fixed number of rounds T, each client queries its local objective oracle once per round by selecting anarm xm,t X in round t [T]. This evaluation yields a noisy feedback rm,t = m(xm,t) + m,t, where m,tis a zero-mean, bounded random noise, independent of previous observations or other clients observations.Importantly, the local objectives can capture client-specific preferences, i.e., m(x) and n(x) are notnecessarily equal for distinct clients m and n. The global model.The global model is a X-armed bandit model that shares the search space with thelocal models but uses the average of local objectives over all clients as its objective. This average, known asglobal objective, is defined as",
  "m=1m(x),x X": "It is important to note that while the global model represents the average of local models, the global rewardsare not directly accessible to any individual client, as local observations remain private. The personalised model.In conventional federated learning framework, clients collaborate to optimisethe global objective . However, this approach may not always align with individual client interests. Toaddress this, we capture the personalisation aspect via a mixed objective, inspired by the well-establishedand popular technique of Hanzely & Richtrik (2020) in federated learning literature.",
  "where is the personalisation parameter": "The components of the mixed objective bear similarity to the objectives in (Li et al., 2024b) and (Li et al.,2024a), however handling the mixed objective brings additional challenges, as well as the flexibility to capturemore diverse sets of clients. The personalisation parameter allows for explicit control over the level ofpersonalisation:",
  "Performance Measure": "In our proposed framework, we aim to devise a collaborative optimisation strategy across a federation ofpersonalised models. We assess the performance of this strategy through the expected cumulative regret,which is essentially the sum of the individual clients regrets, calculated with respect to their individualpersonalised objectives. Formally, we define the expected regret as",
  "At each depth h, the union of all nodes is equivalent to the entire space X": "The partition is fixed and shared among all clients and the central server prior to the beginning of the FLprocess. This ensures a consistent structure for exploration and information sharing across the federation.While we employ binary partitioning of the space in this work, our principles could readily be adapted to ak-ary partitioning approach.",
  "(y) (x) + max{ (x), (x, y)}": "This assumption pertains to the smoothness of the objective functions and ensures that as the depthincreases, the search regions become increasingly fine, allowing for a more detailed exploration of promisingareas within the hierarchical partitioning approach. Remark 2.3. Similar to the existing works on the X-armed bandit problem, knowledge of dissimilarity function is not required for our algorithm. However, knowledge of the smoothness constants 1, is necessary.Remark 2.4. In this setup, we do not impose specific assumptions on clients objective functions beyondthe regular smoothness conditions typical in X-armed bandit literature. This contrasts with (Li et al.,2024a), the only prior research on this problem and most related and similar to ours, which imposes twoadditional constraining assumptions (Assumptions 3 and 4 in their work). These assumptions jointly requirethat near-optimal points with respect to the global objective are also near-optimal with respect to all localobjectives. Our problem setup is more flexible, allowing for a wider range of real-world scenarios with varyingdegrees of data heterogeneity.",
  "Algorithm and Analysis": "In this section, we introduce a novel phase-based elimination algorithm to address the challenges of personalisedfederated XAB. We highlight its distinctive features compared to existing algorithms and provide a theoreticalanalysis of its performance. A bespoke algorithm is sorely necessitated for the personalised federated XAB, as existing XAB algorithmswill fail to meet the challenges of the setting. Unlike the focus on optimisation of the global objective asexplored in works by Shi & Shen (2021) and Li et al. (2024b), our interest lies in simultaneously optimisingthe personalised objectives of the clients. This task is evidently more challenging since it can be viewed as aproblem of multi-objective optimisation with communication budget constraint. Consequently, developing an effective communication strategy that enables an unbiased estimation of theglobal objective becomes a critical element of algorithm design. This is particularly important in scenariosinvolving a large number of clients. Furthermore, the constraints on communication budget mean that localrewards are not instantly accessible. As a result, algorithms that depend on immediate reward feedback, such",
  "as HOO(Bubeck et al., 2011) and HCT (Gheshlaghi Azar et al., 2014), are not appropriate for addressing thisproblem": "In the context of federated bandit algorithms, the requirement for minimal communication overhead indeedrenders algorithms that are built on phase-based elimination techniques appealing(Shi & Shen, 2021; Shiet al., 2021; Rda et al., 2022). Therefore, algorithms such as our own proposal, which eliminate sub-optimalnodes in phases, are more suitable for the federated XAB problem, as suggested in works like (Li et al.,2024b;a).",
  "end while": "The PF-XAB algorithm comprises two components: a client-side algorithm (Algorithm 2) and a server-sidealgorithm (Algorithm 1). The algorithm operates in dynamic phases, leveraging the hierarchical partition togradually identify the optimum by systematically eliminating sub-optimal nodes within the search domain. The server acts as a coordinator with two primary functions. It broadcasts active nodes A(p) in phase p,which represent the collective active nodes across all clients. Additionally, It aggregates empirical estimatesof the local objectives (h,i)(p) for all active nodes (h, i) A(p) from clients, and subsequently broadcaststhe empirical estimates of the global objective back to all clients. On the client side, the algorithm involves a phased interaction with the environment, segmented into threedistinct sub-phases: global exploration, local exploration, and exploitation. During both the global and localexploration sub-phases, clients take actions from two sets: the global active set A(p), and their own localactive set Am(p). They use the feedback to these actions to construct empirical estimates of their localobjective. These local estimates are then communicated to the server, allowing for centralized estimation ofglobal objective. While a client waits for the server to provide the empirical estimates of the global objective(as other clients may have more exploration to perform), it enters the exploitation sub-phase, where it simplyexploits the best action based on the most recent evaluations. PF-XAB offers a degree of privacy and confidentiality by sharing only average rewards ((h,i),m(p)) with theserver and not individual reward values (rm,(h,i),t).The server then shares summary statistics with otherclients. However, we acknowledge the need for a more formal treatment of privacy considerations in thissetting.",
  "end whileSelect and play the optimal action for the remainder of the time": "The algorithm details are presented in Algorithms 1 and 2. In these algorithms, we use the notation (h, i)to index node Ph,i in the partitioning tree. Tm,(h,i) denotes the number of pulled samples from m-th localobjective in (h, i). By convention, we always sample the midpoint when playing a node. Due to the structureof the algorithm, Tm,(h,i) is equal to Mf(p) + (1 )f(p) and (1 )f(p) for local and global activenodes, respectively. Consequently, the total number of samples taken to compute the empirical mean ofthe personalised objective m,(h,i) is lower bounded by Mf(p) + M(1 )f(p) Mf(p) and the",
  "Theoretical Analysis": "This section contains our main theoretical analysis and results. Here, we establish an upper bound on thecumulative regret of the PF-XAB algorithm, operating under the assumptions previously outlined. Before thisstatement in Theorem 3.9, several key lemmas are introduced. Analysing the regret of PF-XAB is more complexthan that of algorithms like Fed-PNE because PF-XAB does not directly observe the personalised objectives(m). Instead, it works with estimates (h,i),m(p) constructed from local and global objective estimates. Theproof must carefully account for the discrepancy between these estimates and the true personalised objectives. We first determine the variance proxy of the empirical estimates of personalised objectives in Lemma 3.3, anduse this to construct a high-probability good event in Lemma 3.4, under which the empirical estimatesof personalised objectives are sufficiently close to the actual personalised objectives. Lemmas 3.5 and 3.6demonstrate two key aspects: firstly, that the optimal nodes (those containing the optimal point) will neverbe eliminated, and secondly, that all points within the remaining region are, in fact, sub-optimal. Proofs ofthe lemmas are deferred to Appendix B.",
  "On this high-probability event, we can establish guarantees both that the optimal node will not be eliminated,and that all other non-eliminated nodes are of a good quality": "Lemma 3.5. (Permanence of Optimal Nodes) Under the assumption that the high probability eventGT holds, it can be stated for any client m that by the end of phase p PT , the node Php,im,p will not beeliminated. This particular node contains the global optimum xm of the personalised objective m(x) at thedepth hp. More precisely, this implies that (hp, im,p) will not be included in the set of eliminating nodesEm(p).",
  "M212h , all points in every un-eliminated nodes upon the conclusion of phase p, is at least 121hp-optimal": "The algorithms performance is sensitive to the smoothness parameters 1 and , which influence the confidencebounds in the elimination process. A conservative estimate of results in smaller confidence bounds andshorter exploration phases, potentially leading to premature convergence to suboptimal regions and unboundedregret. In contrast, overestimating produces larger confidence bounds and longer exploration phases, yieldingregret commensurate with this estimate. Therefore, accurate estimation of these parameters is crucial forachieving robust performance.",
  "To complete the proof of Theorem 3.9, we need one additional concept: that of near-optimality dimension": "Definition 3.7. (Near-optimality dimension) Given a function f : X R, the -near-optimalitydimension, denoted by df(, ), is the smallest d > 0 such that there exists C > 0 such that for any > 0,the covering number of -optimal subset of X, denoted as Xf,, with -balls of radius is less than Cd. Remark 3.8. The near-optimality dimension d reflects the complexity of an objective functions landscape.For smooth functions with few local optima, d is usually low, as near-optimal points remain limited even",
  "to each others rewards at all timesteps is of order O(MT": "d+1d+2 ) where d denotes the maximum near-optimalitydimension among the personalised objectives. This bound, which holds under centralised conditions, providesa useful baseline for evaluating the performance of our approach in the federated setting. Providing a regretlower bound for the personalised federated XAB problem, whether under the definition of PF-PNE withrespect to local objectives or our definition with respect to personalised objectives, remains an open problem. The setting of Theorem 3.9 is more general compared to that of Li et al. (2024a), and therefore the slightlyincreased order of the regret bound is perhaps unsurprising. Under the restrictive assumptions of (Li et al.,",
  "2024a), our algorithm achieves the same regret upper bound as PF-PNE, which is of order O(T": "d+1d+2 ). A sketchof the proof for this claim is provided in the appendix. In any case, the existence of a method which iscompetitive under stronger assumptions and robust enough to attain sublinear regret under our weakerassumptions is encouraging with a view to real-world challenges where strong assumptions may be challengingto verify. Remark 3.10 (Communication Cost). The number of communication rounds is always depends logarithmicallyon T, as the length of each phase h is proportional to (d+1)h. The communication cost measured by thenumber of messages exchanged between clients and the server, can be bounded by CM log(T)T",
  "Experiments": "In this section we evaluate the empirical performance of PF-XAB through a series of experiments employingsynthetic objective functions and real-world dataset. To provide a comprehensive assessment, we benchmarkPF-XAB against relevant existing algorithms. Specifically, we compare to the federated X-armed banditalgorithm Fed-PNE (Li et al., 2024b) and the personalised federated X-armed bandit algorithm PF-PNE (Liet al., 2024a). Each of these methods adopts a different notion of regret, reflecting their distinct models,which makes a truly fair comparison challenging. However, we choose to compare to closest counterpartsin the literature, not to suggest their perfect compatibility with our problem, but rather to illustrate thenecessity of a bespoke solution. This comparison highlights a performance gap when the algorithms of (Liet al., 2024b) and (Li et al., 2024a) are applied to our specific problem domain.Throughout this section, allexperiments has been conducted on a federation with M = 10 clients. : Comparison of Cumulative Regret for PF-XAB, Fed-PNE, and PF-PNE Algorithms on the GarlandDataset Across Varying Levels of Personalisation , with M = 10 machines over T = 2 106 Time Steps.Each graph demonstrates the impact of personalisation on the algorithms performance, with representingthe degree of personalisation from low ( = 0.1) to high ( = 0.9). We first conduct a range of experiments on two synthetic objective functions: the Garland and DoubleSinefunctions with varying levels of personalisation in the regret definition and in PF-XAB. These two syntheticfunctions are frequently used in the experiments of X-armed bandit algorithms due to their large number oflocal optima and extreme non-smoothness (Gheshlaghi Azar et al., 2014; Grill et al., 2015; Shang et al., 2019;Bartlett et al., 2019). The experimental design takes the canonical functions as a baseline and modulates thesesuch that each clients local optimum is distinct, whereas the global optimum is strategically positioned to besub-optimal with respective to the local objectives. The average cumulative regrets of different algorithms areprovided in and 4 (see Appendix B) for the Garland and DoubleSine functions, respectively. Thecurves in these figures represent the averages over 10 independent runs of each algorithm, with the shadedregions indicating 1-standard deviation error bars. In addition to our initial experiments with synthetic objective functions, we extended our experiments to areal-world-inspired scenario using the landmine dataset (Liu et al., 2007). This dataset comprises data frommultiple landmine fields, each assigned to a client, with features extracted from radar images to determinethe presence of landmines at each location. Each client aims to optimise their performance on a classificationtask, using a Support Vector Machine (SVM) classifier equipped with RBF kernels. Our experiments explored = 2 kernel parameters, ranging in [0.01, 10], and the regularisation parameter C, selected from the range, forms the domain space of our experiments. The local objective for each client is defined as theAUC-ROC score of the classifier on their assigned landmine dataset. The performance of different algorithms",
  ": Cumulative regret comparison of PF-XAB, Fed-PNE, and PF-PNE on the Landmine dataset": "in this real-world setting is illustrated in . This figure presents the average cumulative regret ofeach algorithm with = 0.4, showcasing our algorithms effectiveness by its ability to achieve the smallestregret. This outcome not only validates our approach in synthetic settings but also demonstrates its practicalapplicability and superiority in handling complex, real-world tasks, such as landmine detection. In the third and final experiment, our intention was to assess PF-XABs performance in achieving a balancebetween personalisation and generalisation across the federated landscape. indicates that PF-XABsuccessfully converges to optimal choices across different values of , effectively demonstrating its proficiencyin balancing the trade-off between personalisation and generalisation. This figure outlines the averagedper-step reward attained by the PF-XAB under varying values of . It benchmarks these results againstthe theoretical maximums for both global and local mean rewards, referred to as best global and bestlocal, respectively. The analysis encompasses three definition of rewards: personalised, global, and local, each labeled accordinglyand derived by clients actions. At = 0, both personalised and global rewards align with the optimal globalreward, while local rewards are significantly sub-optimal. As is progressively increased, the personalisedand local rewards trend up, indicating a shift in focus towards optimizing local rewards, and simultaneouslythe global reward trends down. At = 1, both personalised and local rewards almost approximate theoptimal local reward, while the global rewards are poor. This trend highlights the role of in mediating agradual balance between local and global reward optimization, suggesting its importance in the strategicadjustment of reward focus.",
  "Conclusion": "In this article we have introduced a new model for personalised, federated, bandit learning on continuousaction spaces, and proposed an effective solution method utilising hierarchical partitioning, batched decision-making and optimism in the face of uncertainty. Our approach achieves a sublinear regret (evidenced boththeoretically and empirically) and requires minimal communication - ensuring a good level of privacy in thefederated regime. Our method shows a near-deterministic behaviour in certain problems: we notice little variability in its regret.This is likely a result of its phased structure - the main decisions (eliminations) of the policy are made duringthe small number of communication rounds. If the outcomes of these decisions are identical same acrossreplications, the expected regret will also coincide. Future work may do well do explore whether there isscope to speed up exploration through the use of a randomised policy, e.g. a variant Thompson Sampling forcontinuous spaces (Kandasamy et al., 2018; Grant & Leslie, 2020), or through the use of ideas from BayesianOptimisation (Frazier, 2018) which have also proven successful in X-armed-type problems, particularly withsmooth functions.",
  "Qiuhua Liu, Xuejun Liao, and Lawrence Carin. Semi-supervised multitask learning. Advances in NeuralInformation Processing Systems, 20, 2007": "Chenxin Ma, Jakub Konen`y, Martin Jaggi, Virginia Smith, Michael I Jordan, Peter Richtrik, and MartinTak. Distributed optimization with arbitrary local solvers. optimization Methods and Software, 32(4):813848, 2017. Brendan McMahan, Eider Moore, Daniel Ramage, Seth Hampson, and Blaise Aguera y Arcas. Communication-efficient learning of deep networks from decentralized data. In Artificial intelligence and statistics, pp.12731282. PMLR, 2017."
}