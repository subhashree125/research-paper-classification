{
  "Abstract": "A brain-computer interface (BCI) is an advanced technology that facilitates direct communi-cation between the human brain and a computer system, by enabling individuals to interactwith devices using only their thoughts. The P300 speller is a primary type of BCI system,which allows users to spell words without using a physical keyboard, but instead by cap-turing and interpreting brain electroencephalogram (EEG) signals under different stimuluspresentation paradigms. Traditional non-adaptive presentation paradigms, however, treateach word selection as an isolated event, resulting in a lengthy learning process. To enhanceefficiency, we cast the problem as a sequence of best-arm identification tasks within thecontext of multi-armed bandits, where each task corresponds to the interaction between theuser and the system for a single character or word. Leveraging large language models, weutilize the prior knowledge learned from previous tasks to inform and facilitate subsequenttasks. We propose a sequential top-two Thompson sampling algorithm under two scenarios:the fixed-confidence setting and the fixed-budget setting. We study the theoretical propertyof the proposed algorithm, and demonstrate its substantial empirical improvement throughboth simulations as well as the data generated from a P300 speller simulator that was builtupon the real BCI experiments.",
  "Introduction": "A brain-computer interface (BCI) is a groundbreaking technology that enables direct communication be-tween the brain and an external device or computer system. It involves the use of various sensors, such aselectroencephalography (EEG), electrocorticography (ECoG), or implantable neural electrodes, which detectand record the electrical signals produced by the brain. The brain signals are then processed by machinelearning algorithms to interpret and extract meaningful commands and intentions. BCI holds immense po-tential for a wide range of applications in medicine, rehabilitation, and human augmentation. For instance,it provides a valuable communication aid for individuals with disabilities (Wolpaw et al., 2018). The P300 speller is a primary type of BCI system that allows users to select characters or spell words on acomputer screen without using a physical keyboard but instead brain signals. It is based on the P300 event-",
  "Published in Transactions on Machine Learning Research (08/2024)": ": The total number of steps, i.e., the stimulus flashes, for the fixed-confidence setting using the P300speller simulator and the chosen sentences. Two sentences are used, one from a benchmark phrase set, andthe other from a news article. A larger 2EEG indicates a larger noise level in the simulated EEG signals.",
  "Contributions: Our contributions are three-fold": "We introduce a novel sequential best-arm identification formulation for the P300 speller BCI application.We treat each word the user wishes to type as an optimal arm, and formulate stimulus presentation as anadaptive selection problem. We leverage language models as an informative prior, and aim to identify thetarget sequence of words as soon as possible in the fixed-confidence setting, or to make as fewer mistakesas possible given a fixed number of flashes in the fixed-budget setting. We propose a sequential top-two Thompson sampling (STTS) algorithm that utilizes the prior informationin a coherent way.We derive the probability error bound in the fixed-budget setting that explicitly",
  "quantifies the prior effect through the conditional entropy of the prior distribution of the optimal arms.We also study the probability error bound in the fixed-confidence setting": "We conduct intensive experiments using both simulations and data generated from a P300 speller simulatorthat was built based on real BCI experiments (Ma et al., 2022). We consider two ways to generate thetarget sentence, or say, the set of words, that a user wishes to type. First, we use GPT-3 (Brown et al.,2020) to generate two sets of words given two prompts. Next, we choose a full sentence from a benchmarkphrase set (MacKenzie & Soukoreff, 2003), and a full sentence from a recent news article (Wong, 2024).We use GPT-2 (Radford et al., 2019) to inform the prior distribution, and demonstrate the substantialimprovement over several state-of-the-art baseline algorithms that do not utilize the prior information.",
  "Related work: We first review the literature on multi-armed bandits, then the literature on P300 BCI": "The multi-armed bandit (MAB) problem (Robbins, 1952) is a classic scenario in decision theory and rein-forcement learning that studies the problem of balancing exploration and exploitation. It involves an agentthat seeks to optimize actions that maximize expected rewards. The agent must explore the action spacesufficiently to acquire the knowledge needed to exploit the best action. Best-arm identification (BAI) is avariant of MAB, where the learners objective is to identify the optimal arm, i.e., the arm with the highestexpected reward, with a high accuracy. BAI is especially relevant to the P300 speller problem, where thegoal is to swiftly and accurately identify target characters or words. For learning a single task, Even-Dar et al. (2002) first introduced best-arm identification in the fixed-confidence setting, ensuring a specified confidence level in the correctness of the identification. Audibert et al.(2010) studied the fixed-budget setting, where the goal is to identify the best arm within a given numberof trials or budget. In the BAI problem, we use sample complexity, the number of samples or pulls neededto correctly identify the best arm, to measure the theoretical properties of the algorithms. Kaufmann et al.(2016) investigated optimal sample complexity, and Russo (2016) proposed the top-two Thompson samplingas an effective anytime sampling rule that does not depend on the confidence parameter. Its theoreticalproperties were studied in Russo (2016); Qin et al. (2017); Shang et al. (2020); Qin & Russo (2022); Jourdanet al. (2022). However, most existing asymptotic analyses did not quantify the prior effect. An exception isQin & Russo (2022), who showed the prior effect through entropy in the simple regret setting. Jun et al.(2016) explored scenarios where multiple pulls of the arms can be conducted simultaneously or in batches,rather than sequentially. For learning multiple tasks sequentially, Boutilier et al. (2020); Simchowitz et al. (2021); Kveton et al. (2021);Azizi et al. (2022) studied meta-learning in the context of Bayesian bandits for cumulative and simple regretminimization. They assumed that an unknown instance prior is drawn from a known meta-prior. Theneach task is sampled independently from this instance prior. In contrast, we assume the sequence of tasks issampled from a joint prior distribution such that each task is not independent of each other. This necessitatesthe prior-dependent analysis that has only been studied in the regret minimization setting (Russo & Van Roy,2016; Hao et al., 2023). For P300 BCI studies, there have recently emerged a number of proposals for adaptive stimulus selection.Speier et al. (2011) used language models to weigh the output of stepwise linear discriminant analysis(LDA) for classification confidence. Park & Kim (2012) framed the problem as a a partially observableMarkov decision process (POMDP). However, as the number of states grows, the belief states grow expo-nentially for POMDP, and the problem becomes intractable for a real-time system with a large search space.Koanaoullar et al. (2018) formulated the problem as query selection optimization and utilized languagemodels to obtain the prior. However, they focused on a single task setting. Naively extending their solutionto multiple tasks in effect requires that the prior information of the previous tasks must all be correct. Ifan incorrect selection is made in one task, then the subsequent prior information would be incorrect, whichwould in turn derail the subsequent stimulus selection. Besides, they did not establish any theoretical guar-antee. Ma et al. (2021) used Beta-Bernoulli Thompson sampling for adaptive stimulus selection, but did notformulate the problem as best-arm identification, and did not incorporate any prior from language models.We refer to Heskebeck et al. (2022) for a review of the multi-armed bandits approaches in the BCI setting.",
  "Problem formulation": "We formulate the problem as an agent sequentially interacting with M bandit environments, with eachinteraction referred to as a task. Each environment, indexed by m [M] = {1, . . . , M}, is characterized by arandom vector m RJ with a prior distribution m(), which will be discussed in detail in .2. Theaction set is A = {a1, . . . , aJ} RJ, where aj is the standard basis vector with the jth element equal to oneand the rest all zero. At each task m and step t, the agent selects an action At,m A, and receives a rewardRt,m = At,m, m + t,m, where , is the vector inner product, and (t,m)s are a sequence of independentstandard Gaussian variables.The optimal arm, Am = argmaxaA ma, is also a random variable.Let(, F, P) denote a measurable space, Ht,m the history of task m up to step t, Dm = (H1,1, . . . , Hm1,m1),and Pt,m() = P(|Ht,m, Dm).",
  "We consider two distinct scenarios": "In the fixed-confidence scenario (Even-Dar et al., 2002), the agent chooses a policy m = (t,m)t=1. Thehorizon is not fixed in advance, as the agent decides a stopping time m adapted to filtration, Fm = (Ft,m)t=0,with Ft,m = (A1,m, R1,m, . . . , At,m, Rt,m), where is the Borel -algebra. The agent makes a decision mat the end of the task. For a given confidence level (0, 1), the objective is to output a sequence of armsthat are optimal for each task with probability at least 1 as soon as possible. In the fixed-budget scenario (Bubeck et al., 2009), the agent is given a budget n for each task, choose a policym = (t,m)nt=1, and makes a decision m at the end of the task. The objective is to make the cumulativeprobability that m is sub-optimal as small as possible. In the context of a P300 speller experiment, take the identification of a set of words as an example. Anagent refers to the system (not the user). A task means identifying a single word the user intends to type,which forms a single bandit environment. An action, or say, pulling an arm, means flashing one word on thevirtual user screen, and the reward is the classifier score computed based on the captured EEG signals anda pre-trained binary classifier. A decision is the word the system believes the user intends to type. A budgetis the total number of flashes the system is to make for a single task. In this setup, M is the total numberof words the user intends to type, and J is the total number of flashes. We also comment that we formulate our problem as a series of best-arm identification tasks within thecontext of multi-armed bandits, rather than reinforcement learning, because in our setting, there is noobvious definition of the state. If we define the underlying true word as a state, then the action we takewould not affect the future state. Therefore, we feel the bandits formulation is more suitable for our problem.",
  "Prior specification": "A language model defines a collection of conditional probability distributions (1, . . . , M), where mdenotes a probability distribution over the mth word given the first m 1 words, m [M]. In a P300speller experiment, the word that an individual attempts to type is viewed as the optimal arm. The jointdistribution over the collection of optimal arms (A1, . . . , AM) can be written through the chain rule:",
  "Sampling procedure": "Our proposed STTS algorithm requires a posterior sampling oracle that can be obtained exactly when aconjugate prior is used, or through various approximation methods, such as Markov chain Monte Carlo. Definition 3.1 (Posterior sampling oracle). Given a prior m over m and history Ht,m, Dm, the posteriorsampling oracle, abbreviated as SAMP, is a subroutine that returns a sample from the posterior distributionPt,m(m ). Multiple calls to the procedure result in independent samples. Our STTS algorithm extends the top-two Thompson sampling algorithm of Qin & Russo (2022); Russo (2016)that was designed for a single task setting now to the sequential multiple tasks setting, where we sequentiallycall the language model to construct an informative prior. At task m and step t, STTS first draws a posteriorsample t,m using SAMP as well as the language model , and sets At,m,1 = argmaxaA t,ma. Then STTSrepeatedly samples from SAMP to obtain t,m, and sets At,m,2 = argmaxaA t,ma until At,m,1 = At,m,2.We pick At,m = At,m,1 with probability equal to (0, 1], and At,m = At,m,2 with probability equal to1 . In practice, we recommend = 1/2, following Qin & Russo (2022). We also comment that SAMP isa subroutine that is frequently used in the literature (see, e.g., Russo et al., 2018; Jourdan et al., 2022). Itcan be obtained exactly when a conjugate prior is used, or approximately through various methods such asMCMC and variational inference.",
  "Stopping rule and decision rule": "For the fixed-confidence setting, we employ the Chernoff stopping rule introduced by Garivier & Kaufmann(2016); Shang et al. (2020). More specifically, let Nt,i denote the number of pulls of arm ai before step tfor each task, t,i the posterior mean for arm ai, and t,i,j = (Nt,it,i + Nt,jt,j)/(Nt,i + Nt,j). We furtherdefine Zt,i,j = Nt,iKL(t,i, t,i,j) for any two arms ai and aj, and define Zt(ai, aj) = 0 if t,j t,i, andZt(ai, aj) = Zt,i,j + Zt,j,i otherwise. Here we follow Garivier & Kaufmann (2016) and focus on the simplecase where the distributions are fully parameterized by their means, and we use KL(1, 2) to denote theKL-divergence between the two distributions with means 1 and 2, respectively. For each task m, theChernoff stopping rule is,",
  ",": "where t,m = argmaxa am,t, and t = [2 log{log(t)M/}]1/2. Here, we approximate the KL-divergence oftwo Gaussian mixture distributions by the KL-divergence of two Gaussian distributions with the same meanand variance (Hershey & Olsen, 2007). Moreover, as the theoretical stopping rule of BR is conservative, wemultiply its range by a factor of 0.25. We compare different methods via the total number of steps under the varying prior strength p, whereasall methods achieve at least 1 = 0.9 for the 0-1 accuracy. reports the results. We see that,with the prior becoming more informative, STTS clearly outperforms the baseline solutions VTTS, BR, andRandom. The improvement also increases with an increasing number of arms. When the prior of the optimalarms is uniformly distributed, STTS coincides with VTTS as expected. Furthermore, STTS and STTS-Oracleexhibit similar performances. This is because, as the accuracy of STTS is consistently close to one, P(Am =|Am1 = am1) and P(Am = |Am1 = m1) are very close. We also briefly comment that, in real P300speller experiments, it is impractical to run the number of steps into thousands. This step number can beadjusted by adjusting the accuracy measure. Here we mostly use this simulation example to illustrate theeffect of the prior and the difference in performance of different solutions.",
  "Theoretical properties": "We first consider the fixed-budget setting. When the recommended word at the end of a task is wrong, wesay the agent makes a mistake. The next theorem derives the corresponding probability error bound. Theorem 4.1. Consider a sequence of M best-arm identification problems, and assume for each task m, allthe sub-optimal arms have the same and known sub-optimality gap, m = Am a, m, for any a A. IfSTTS is applied with 1/2 and with the Bayes optimal decision rule m, then for any positive integer-valuedbudget n,",
  "where hm = H(Am|Am1, . . . , A1), and H(|) is the conditional entropy": "We discuss the individual terms in the error bound in (4.1). The first term in the bound is the main term,where hm = H(Am|Am1, . . . , A1) specifically characterizes the effect of the prior. In the P300 speller, theprior distribution of Am is informed by a language model such that H(Am|Am1, . . . , A1) is much smallerthan log(J). This can be validated through an experiment shown in , left panel, where the entropyof the probability distribution over the next word outputted by GPT-2 is seen to be much smaller than an",
  "Jmdm(m) ,": "where the expectation is taken over the prior of m on both sides. We remark that, this asymptotic resultcan not fully characterize the prior effect, as the asymptotic complexity measure only depends on the priorof the gap m, rather than the prior of the position of the optimal arm. Typically, the overall samplecomplexity consists of two parts: the cost due to the optimal allocation rule, and the cost due to findingthe optimal allocation rule. The latter is a lower-order term with respect to log(1/). We conjecture that amore informative prior could greatly reduce the cost of finding the optimal allocation rule in the finite time.We conduct a numerical experiment to verify our conjecture. The detailed simulation setting is describedin Appendix B. We report in , right panel, the KL-divergence between the asymptotically optimalallocation rule and the allocation rule induced by STTS. It is clearly seen that, when the prior is stronger,as reflected by a larger value of the parameter p that controls the strength of the prior, the allocationrule induced by STTS converges faster to the asymptotically optimal allocation rule. Meanwhile, a rigoroustheoretical analysis requires a much more involved finite-time dependent analysis for top-two TS, and weleave it as future research.",
  "Batch Racing (BR) (Jun et al., 2016): A frequentist algorithm that uses confidence interval to identifybest arms in the fixed-confidence setting": "In our comparison, VTTS and Random use the same stopping rule and decision rule as described in .2, while BR is only for the fixed-confidence setting. There are several other popular best-arm identificationalgorithms, e.g., Jamieson & Nowak (2014); Garivier & Kaufmann (2016), in the literature, but none of themis designed for the sequential task setting. We define the prior for the mean reward m through (2.2), which requires the specification for the priorof the optimal arm, and the prior of the conditional mean reward. We assume the prior of the optimalarms satisfies the Markov property, in that the distribution of the mth optimal arm depends only on the(m 1)th optimal arm. More specifically, the optimal arm for mth task is sampled from P(Am = aj) = p ifj {supp(Am1) + 1, supp(Am1) + 1 J} [J], and P(Am = aj) = (1 p)/(J 1) if j {supp(Am1) +1, supp(Am1)+1J}c [J], where supp(v) denotes the position where the non-zero entry for a unit vectorv is located, Sc denotes the complement of a set S, and p is a parameter that controls the strengthof the prior, with a larger p indicating a stronger prior.",
  "P(m,j |A1, . . . , Am1) = pm,jN( + , 20) + (1 pm,j)N(, 20),": "where we set the prior parameters as = 0, 20 = 0.2, = 2. Moreover, when there is an oracle or externalresource that reveals the identity of the optimal arm at the end of each task, STTS can start with an exactprior, which we call STTS-Oracle. We set pm,j for different algorithms as follows.",
  "Moreover, let m,t,j denote the posterior mean, and 2m,t,j the posterior variance": "We take one sentence as one experiment, and one word in the sentence as one task, with each sentenceconsisting of M = 20 words. We replicate each experiment B = 200 times. We vary the number of armsJ {10, 20}, and set the confidence level = 0.1. We consider two accuracy measures for each experiment. One is the 0-1 accuracy, where as long as theagent makes at least one mistake among 20 words, we mark that experiment a failure.The other isthe average accuracy, where we compute the percentage of correctly identified words among a sentence:Mm=1Bb=1 I{bm = Am,b}/(BM), where bm, Am,b denotes the recommended action and the optimal actionfor the mth task of the bth experiment, respectively. We make a few comments. First, our proposed method does not require the Markov assumption. We haveonly adopted the Markov setting in our synthetic experiments for simplicity. Second, due to the Gaussian",
  "Fixed-confidence setting": "We first consider the fixed-confidence setting.We vary the parameter in the prior of the optimal armp {J1} {0.1, 0.2, . . . , 1.0}. A larger p indicates a stronger prior effect, and p = J1 means a non-informative prior. In our setting, we stop the algorithm when the Chernoff stopping rule is satisfied; i.e.,",
  "Fixed-budget setting": "We next consider the fixed-budget setting. The sampling and decision rules remain the same, while thestopping rule is determined by whether the algorithm reaches a pre-specified budget of maximum step tmaxper task. We vary tmax {5, 10, 15, . . . , 100}, and p {J1, 0.5, 0.8, 1.0}. We compare different methods via the average accuracy under the varying number of maximum step tmax. reports the results. We see that, when the prior becomes more informative, STTS and STTS-Oraclereach a high accuracy with a smaller budget. When the prior is non-informative, STTS and STTS-Oracleperform similarly. We do not compare with BR, as it was designed for the fixed confidence setting only.",
  "P300 speller simulator experiment": "We carry out an experiment by generating the brain EEG signal data using a realistic P300 speller simulatordeveloped by Ma et al. (2022). We do not use any public BCI data. This is because our method employsan adaptive policy that influences both data generation and collection, in contrast to the random and non-adaptive baseline policy that is typically associated with such type of datasets. Thus, offline data alone isinsufficient for our needs, and we are not aware of any online benchmark data that is suitable for our purpose.On the other hand, the simulator of Ma et al. (2022) has been built based upon real BCI experiments, andcan adeptly generate signals that capture and match the complex spatial-temporal EEG patterns observed inreal experiments. Moreover, we generate the sentence of words that a participant wishes to type using GPT-3(Brown et al., 2020), and obtain the prior distribution using GPT-2 (Radford et al., 2019). This mimics thepotentially imperfect prior information that commonly arises in real-world scenarios. All computations weredone using CPUs on Google Colab Cluster. More specifically, the P300 speller simulator of Ma et al. (2022) is built on a Bayesian generative model, andwas trained with the data from actual BCI experiments. It employs novel split-and-merge Gaussian processpriors to ensure an accurate emulation of the EEG signal generation mechanism inherent in the P300 spellerin response to both target and non-target stimuli. For instance, the generated EEG signals exhibit the targetERPs of the frontal and central channels with a negative drop around 100 ms and an ascend to the first peakapproximately at 250 ms latency. This pattern aligns seamlessly with the N100 and P300 patterns outlinedin Stemmer & Whitaker (2008), underscoring the simulators capacity to mirror real experimental conditionseffectively. In our experiment, we set the number of electrodes to 16, the noise variance 2EEG {1, 2.5},the noise spatial correlation based on a Gaussian kernel function, the noise temporal correlation from anAR(1) model with an autocorrelation 0.9, and the mean magnitude of the target stimulus five times thatof the non-target stimulus. In accordance with the current practice (Manyakov et al., 2011), we first traina binary classifier for the P300 offline data based on stepwise linear discriminant analysis (Donchin et al.,2000; Krusienski et al., 2008). This classifier converts the raw EEG signals into the classifier scores, and wetake these scores as the rewards in our setting. A higher score indicates that the EEG signal is more likelyto correspond to a target stimulus.",
  "BBTS1712.5 (248.1)BBTS1694.0 (266.8)": "We consider two ways to generate the target sentence, or say, the set of words, that a user wishes to type.First, we use GPT-3 (Brown et al., 2020) to generate M = 20 words under two given prompts, The mostpopular food in the United States is as Prompt 1, and My favorite sport is as Prompt 2. Next, we choosea sentence with M = 9 words from a benchmark phrase set (MacKenzie & Soukoreff, 2003), and a sentencewith M = 15 words and punctuation marks from a recent news article on Nature (Wong, 2024). We useGPT-2 (Radford et al., 2019) to inform the prior distribution and specify the prior of the optimal arms.That is, given an input token, GPT-2 specifies a probability distribution of the next token over the fullvocabulary space. Besides, for the very first word in the set of words, we provide the prompt to GPT-2 toobtain the prior in the GPT-3 generation case, provide no information at all to GPT-2 in the case of using thesentence from the benchmark phrase set, and provide the preceding sentence to GPT-2 in the case of usingthe sentence for the news article. We truncate the vocabulary size of GPT-2 from the original size of 50257to 100, following the top-K sampling (Fan et al., 2018) and the nucleus sampling (Holtzman et al., 2019).This keeps the candidate words with the top-100 highest probabilities, and in effect substantially reduces thesize of the action space to J = 100. We repeat each prompt B = 100 times, and set the confidence level at1 = 0.9. We report the results based on GPT-3 generation in this section, and report the results basedon the chosen sentences in Appendix E. We compare the algorithms studied in .1.When a wrong action is recommended, we let theexperiment continue to run and reveal the identity of the optimal arm. As such, STTS and STTS-Oracle yieldthe same results. We also add the comparison with Beta-Bernoulli Thompson sampling (BBTS) algorithm ofMa et al. (2021). For the fixed-confidence setting, we stop the algorithm when the Chernoff stopping rule is met. reports the total number of steps, i.e., the stimulus flashes, whereas the 0-1 accuracy and the averageaccuracy for all methods are above 0.9. We see that, facilitated by the LLM-informed prior, STTS managesto reduce the total number of stimulus flashes by 25% to 50%, while maintaining about the same accuracy. For the fixed-budget setting, we stop the algorithm when it reaches the pre-specified maximum number offlashes tmax {5, 10, 15, . . . , 150}. reports both the 0-1 accuracy and the average accuracy. We seethat STTS achieves the highest accuracy compared to the alternative solutions. We also note that, the baselinerandom policy, which is currently used in most P300 experiments, requires about 150 steps to reach the 95%accuracy. This agrees with the practical observations that usually 100 to 150 steps are needed (Kindermanset al., 2012). In contrast, our method only requires 60 steps, which is a significant improvement.",
  "Prompt 2": ": The average accuracy and the 0-1 accuracy for the fixed-budget setting using the P300 spellersimulator and the GPT-generated set of words. Two prompts are used. A larger 2EEG indicates a largernoise level in the simulated EEG signals. identification formulation for the P300 speller BCI system that greatly enhances its sampling efficiency.It integrates the prior information derived from LLMs with the top-two Thompson sampling algorithm.However, it is more than merely a simple extension, and offers several useful contributions. Notably, ouralgorithm extends Qin & Russo (2022); Koanaoullar et al. (2018) from the setting of a single task tothat of multiple and dependent tasks, while relaxing the stringent requirement that all priors have to becorrectly specified. Our theory, to the best of our knowledge, is the first work that establishes an expliciterror probability bound for top-two Thompson sampling within a fixed-budget context. Finally, we applyour method to the P300 speller type BCI experiments, which we hope could pave the way for more adoptionof adaptive bandits algorithms in this important application area.",
  "Mohammadjavad Azizi, Branislav Kveton, Mohammad Ghavamzadeh, and Sumeet Katariya. Meta-learningfor simple regret minimization. arXiv preprint arXiv:2202.12888, 2022": "Craig Boutilier, Chih-Wei Hsu, Branislav Kveton, Martin Mladenov, Csaba Szepesvari, and Manzil Zaheer.Differentiable meta-learning of bandit policies. Advances in Neural Information Processing Systems, 33:21222134, 2020. Tom Brown, Benjamin Mann, Nick Ryder, Melanie Subbiah, Jared D Kaplan, Prafulla Dhariwal, ArvindNeelakantan, Pranav Shyam, Girish Sastry, Amanda Askell, et al. Language models are few-shot learners.Advances in neural information processing systems, 33:18771901, 2020. Sbastien Bubeck, Rmi Munos, and Gilles Stoltz. Pure exploration in multi-armed bandits problems. InAlgorithmic Learning Theory: 20th International Conference, ALT 2009, Porto, Portugal, October 3-5,2009. Proceedings 20, pp. 2337. Springer, 2009.",
  "I Scott MacKenzie and R William Soukoreff. Phrase sets for evaluating text entry techniques. In CHI03extended abstracts on Human factors in computing systems, pp. 754755, 2003": "BO Mainsah, G Reeves, LM Collins, and CS Throckmorton. Optimizing the stimulus presentation paradigmdesign for the p300-based brain-computer interface using performance prediction. Journal of neural engi-neering, 14(4):046025, 2017. Nikolay V Manyakov, Nikolay Chumerin, Adrien Combaz, and Marc M Van Hulle. Comparison of classifi-cation methods for p300 brain-computer interface on disabled subjects. Computational intelligence andneuroscience, 2011:112, 2011.",
  "Daniel J Russo, Benjamin Van Roy, Abbas Kazerouni, Ian Osband, Zheng Wen, et al. A tutorial on thompsonsampling. Foundations and Trends in Machine Learning, 11(1):196, 2018": "Xuedong Shang, Rianne Heide, Pierre Menard, Emilie Kaufmann, and Michal Valko.Fixed-confidenceguarantees for bayesian best-arm identification. In International Conference on Artificial Intelligence andStatistics, pp. 18231832. PMLR, 2020. Max Simchowitz, Christopher Tosh, Akshay Krishnamurthy, Daniel J Hsu, Thodoris Lykouris, Miro Dudik,and Robert E Schapire. Bayesian decision-making under misspecified priors with applications to meta-learning. Advances in Neural Information Processing Systems, 34:2638226394, 2021. William Speier, Corey Arnold, Jessica Lu, Ricky K Taira, and Nader Pouratian. Natural language processingwith dynamic classification improves p300 speller accuracy and bit rate. Journal of Neural Engineering, 9(1):016004, 2011.",
  "mE [Am, m m, m] ,": "where the expectation in the left-hand-side is with respect to the prior distribution of m. We then employProposition 1 of Qin & Russo (2022) for the top-two Thompson sampling for a single task. Define an eventEm = {1 = A1, . . . , m1 = Am1}. As Qin & Russo (2022) requires the top-two Thompson samplingstarting with a correct prior, we decompose the simple regret term based on Em as,",
  "BAdditional discussion on the theory": "First, we note that, for the fixed-budget setting, there is another practical scenario where at the end of taskm, the agent is given the identity of the optimal arm Am. If the recommended action is wrong, the agentpays an extra price c. For P300 speller, if the system outputs a wrong recommendation, the participant willgaze at the backspace and the system will repeat the process until the right word is recommended. In thiscase, the event Em = {1 = A1, . . . , m1 = Am1} always holds. Based on (A.2), the error probability canbe bounded by",
  "and the number of mistakes is bounded by c Mm=1 P (m = Am)": "Next, we verify the role of prior in the fixed-confidence setting in our conjecture in . Specifically,we study how fast the allocation rule of each arm using STTS converges to the optimal allocation ruleand how the information of the prior affects the convergence. Following the prior specified in and the computation in Shang et al. (2020), the optimal allocation rule p pulls the optimal arm withprobability = 1/2, and all the other arms with probability 1/(2J 2).We set the prior parameters = 0, 20 = 1, = 0.5, the number of arms J = 10, and we vary p {0.1, 0.5, 0.9}. Define pt,ai = Nt,ai/t asthe proportion of selections of arm ai before step t. The algorithm stops when it reaches the pre-specifiedmaximum number of steps tmax {50, 100, 150, . . . , 500} per task. , right panel, reports the KLdivergence KL(pt, p) that compares the STTS allocation rule and the optimal allocation rule. We see clearlythat, when the prior becomes stronger, the allocation rule induced by STTS converges faster to the optimalallocation rule.",
  "CAlternative prior specification": "Our proposed algorithm STTS is general and can be coupled with any prior specification. As an illustration,we consider a Gaussian prior specification. Recall the language model m only requires the previous bestarm Am1 to define the prior distribution as m = N(m(Am1), 20I), where 0 is the standard deviationparameter, and m is specified as follows. We first introduce three matrices U (1), U (2), and U (3).",
  "which possesses more uncertainty than U (1)": "Let ej be the unit vector with length J with the jth entry being 1. We define m(Am1) = 0(Am1)T U,for m 2, where U takes one of the forms of U (1), U (2), and U (3), 0 controls the magnitude of the bestarm. For m = 1, we assign each arm to be the optimal arm with equal probability, and 1 = N(0ej, 20IJ)if arm j is the optimal arm. The instance m is sampled from the prior distribution m. In this case, we setthe posterior mean m,t,j = E(m,j |Ht,mDm), and the posterior variance 2m,t,j = Var(m,j |Ht,mDm).Moreover, we set the number of tasks M = 20, and the agent interacts with M bandit instances with theconfidence level 1 = 0.9, and the reward noise variance 2 = 1. For VTTS, we specify the non-informativeGaussian prior as 0,m,j = 0, and 0,m,j = 102 for j [J].",
  "DComputational complexity evaluation": "In the P300 speller system, a sequence of flashes is presented on a virtual screen to the user. The timeinterval between two consecutive flashes is a constant, denoted as c0, which is also the time taken for eachstep. We follow Ma et al. (2021), and set this time interval c0 = 160 ms. We observe that our proposedalgorithm as well as the alternative algorithms require much shorter time than c0 in each step. As such,instead of reporting the computational time alone, we employ the information transfer rate (ITR) (Wolpawet al., 1998), and the BCI utility (Utility) (Dal Seno et al., 2009), as the metrics to evaluate the overallcomputational complexity of all the algorithms. Specifically, we compute the two measures as,",
  "BBTS749.81 (143.9)BBTS1286.29 (208.2)": "Rent is paid at the beginning of the month with M = 9 words, from a benchmark phrase set (MacKenzie& Soukoreff, 2003). We choose Sentence 2, It substantially raises the risk of diseases including cancer, heartdisease and diabetes. with M = 15 words and punctuation marks, from a recent news article (Wong, 2024).Note that this news article was published in April, 2024, and thus is not in the GPT-2s training data whichis up to October, 2019 only. Similarly as before, we use GPT-2 (Radford et al., 2019) to obtain the priordistribution. However, for the very first word of a sentence, we provide no information at all to GPT-2for Sentence 1, and we provide the immediately preceding sentence, The health harms of smoking tobaccohave been established for decades -\" to GPT-2 for Sentence 2. We again conduct experiments for both thefixed-confidence setting and the fixed-budget setting. For the fixed-confidence setting, reports the total number of steps, or flashes, whereas the 0-1accuracy and the average accuracy for all methods are above 0.9. We again see that, facilitated by the LLM-",
  "Sentence 2": ": The information transfer rate (ITR) and the utility measure for the fixed-budget setting using theP300 speller simulator and the chosen sentences. Two sentences are used, one from a benchmark phrase set,and the other from a news article. A larger 2EEG indicates a larger noise level in the simulated EEG signals."
}