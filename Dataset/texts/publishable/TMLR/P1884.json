{
  "Abstract": "To quantify different types of uncertainty when deriving hash-codes for image retrieval, wedevelop a probabilistic hashing model (ProbHash). Sampling-based hypothesis testing isthen derived for hashing with uncertainty quantification (HashUQ) in ProbHash to improvethe granularity of hashing-based retrieval by prioritizing the data with confident hash-codes.HashUQ can drastically improve the retrieval performance without sacrificing computationalefficiency. For efficient deployment of HashUQ in real-world applications, we discretizethe quantified uncertainty to reduce the potential storage overhead. Experimental resultsshow that our HashUQ can achieve state-of-the-art retrieval performance on three imagedatasets. Ablation experiments on model hyperparameters, different model components,and effects of UQ are also provided with performance comparisons. Our code is available at",
  "Introduction": "Representation learning summarizes high-dimensional data into low-dimensional feature vectors with the keyinformation preserved for conducting various downstream tasks, which has been successfully applied to differentdomains such as natural language processing (NLP) (Bahdanau et al., 2014), generative modeling (van denOord et al., 2017; Liu et al., 2019; 2020), data compression (Ball et al., 2016; Theis et al., 2017; Ballet al., 2018), and multi-modal machine learning (Chen et al., 2020). Information retrieval can leveragerepresentation learning to efficiently return the most similar data samples within a database given a query.With the power of such representation models, Learning-to-Hash (L2H) (Weiss et al., 2008; Salakhutdinov& Hinton, 2009; Strecha et al., 2011; Liu et al., 2011; 2014; Li et al., 2016) has become one commonlyadopted group of algorithms, which are designed for efficient information retrieval based on derived discreterepresentations in hashing codes (hash-codes). With the extremely compact binary hash-codes derived fromhigh-dimensional data, L2H enables fast comparison and search by comparing the Hamming distance of hash-codes. More recently, the retrieval accuracy of L2H algorithms with different types of data has experiencedremarkable improvement, thanks to the rapidly evolving modern computer hardware and advanced deepneural network (DNN) architectures (Krizhevsky et al., 2012; Simonyan & Zisserman, 2014; He et al., 2016;Vaswani et al., 2017) with efficient training algorithms (Hinton et al., 2012; Kingma & Ba, 2014; Bengio et al.,2013; Jang et al., 2016; Maddison et al., 2016; Yin & Zhou, 2019; Yin et al., 2020).",
  "Relevant Irrelevant": ": Schematic illustration of HashUQ with binarized uncertainties (Low Uncertainty v.s. HighUncertainty): (a) ProbHash can predict a probability distribution of Bernoulli success rates of hash-codes,from which the binary codes and the associated uncertainty can be jointly inferred. (b) Database storesboth hash-codes and associated uncertainties. (c) For images with the same Hamming distance based on thederived hash-codes to the query, the retrieval order is determined by the corresponding predicted uncertainty. Despite the tremendous amount of research conducted on representation learning, few of them aim at quantify-ing the uncertainty of derived representations. As DNNs have long been criticized for their tendency to makeoverconfident predictions and vulnerability to adversarial attacks, uncertainty quantification (UQ) in DNNshas received increasing attention and growing interest in the machine learning research community (Kendall& Gal, 2017; Abdar et al., 2021). Scalable UQ via various approximate inference methods has been developedfor Bayesian Neural Networks (BNNs) (Lampinen & Vehtari, 2001; Titterington, 2004; Neal, 2012). Althoughthey have greatly reduced the computational complexity of Markov chain Monte Carlo (MCMC) (Neal et al.,2011; Welling & Teh, 2011), few of them have been shown with promising UQ capability on representationand L2H models. Moreover, there still lacks a practical way to utilize the quantified uncertainty for improvingthe accuracy for downstream information retrieval.",
  "In this paper, we propose a scalable image hashing method with UQ for image retrieval. Our main contributionscan be summarized as follows:": "We develop a supervised image hashing method with uncertainty quantification capability by jointlymodeling the hash-codes and neural network weights as random variables, which we term as ProbabilisticHashing (ProbHash). To the best of our knowledge, this is the first supervised image hashing algorithmwith appropriately quantified uncertainty. To jointly model different types of uncertainty, we propose a t-test based measure for UQ, which provides astatistically interpretable notion of uncertainty for hashing. Our UQ method can be readily applied tovarious types of existing L2H models for accurate data retrieval, which we exemplify with two representativeimage hashing models. With our quantified uncertainty, we further design an image retrieval algorithm by prioritizing images withcondifent hash-codes, which we term as Hashing with Uncertainty Quantification (HashUQ). Experimentson several benchmark datasets show that this consistently improves the quality of the predicted imageranking without scarifying the speed and storage consumption. We structure our paper by first describing our probabilistic framework, ProbHash, for hashing with tworepresentative image hashing models given in . The information supplementary to our modelconstruction is included in Appendix A. We detail our t-test based measure of uncertainty and uncertaintyaware retrieval algorithm, HashUQ, in Sections 3 and 4. Experimental evaluation by comparing with otherstate-of-the-art (SOTA) models and ablation studies of our methods are then presented in , with the",
  "Published in Transactions on Machine Learning Research (10/2024)": ": Histograms and Q-Q plots of the difference between paired samples of each Bernoulli success rateof hash-code vectors generated using 5 query images from the ImageNet dataset. (a)(c)(e)(g)(i): Histogramsof the difference between paired samples. (b)(d)(f)(h)(j) Q-Q plots of the difference between paired sampleswith respect to the Gaussian distribution with the same mean and variance. We use the same images togenerate the plots as in Section D with K = 16.",
  "Mathematical Notations": "Unless explicitly specified, we use the normal font letter x, bold letter x and bold letter in upper cases X todenote scalar, vector, and matrix, respectively. We use letter x with subscript i, k: xi,k, to represent the kth entry of vector xi, which is the ith data point in the dataset. We use the superscripts xp, xq to denote apool data point and a query, respectively. N, NSamples, and K denote the number of data points, number ofsamples, and bit-length of hash-codes, respectively.",
  "Problem Settings": "Suppose we have an image dataset {x1, x2, . . . , xN} with corresponding labels {y1, y2, . . . , yN}, our objectiveis to find a mapping f : Rchw {1, 1}K, which can encode all the training images {xi}Ni=1 as well aspossibly unseen query or pool images {xj}Nj=1 into binary hash-codes {bi}Ni=1 and {bj}Nj=1, such that imageswith similar content can be encoded into hash-codes with smaller Hamming distances, and vise versa. Recent image hashing methods (Zhu et al., 2016; Cao et al., 2017; Su et al., 2018; Yuan et al., 2020; Fanet al., 2020; Tian Hoe et al., 2021) usually adopt a feed-forward neural network with parameters and binaryquantization function sgn(), which we denote as f, to model the hash encoding function f. Based on thelearning objective and the availability of image labels, we categorize the existing image hashing methods intoLabel-Target (Cao et al., 2017; Su et al., 2018) and Center-Target methods (Yuan et al., 2020; Fan et al.,2020; Tian Hoe et al., 2021). In Label-Target methods, the label yi for each image xi is directly used as the learning target of binaryhash-code representation bi such that yi can be reconstructed from the binary representation with a decodernetwork. The Center-Target methods, on the other hand, minimize the distance of hash-code bi to itscenter ci. To generate the center for each image xi, a Hadamard matrix with dimension K, for which webriefly review the basics in the context of hashing in Appendix A.1, is first constructed and each row of thematrix will be assigned to one of the M classes (Yuan et al., 2020). The center ci for image xi is then therow vector corresponding to image label yi. Some other randomized algorithms have also been used for thecases when M > K (Yuan et al., 2020).",
  "ProbHash": "Learning the hashing function f can inevitably introduce different types of uncertainties to different phasesin model construction, training, as well as prediction. To give an example, applying the over-parameterizedDNN models will indispensably lead to the uncertainty in model parameters. Moreover, the learning targets tomodel are also noisy, which can be shown in a Center-Target setup where the centers {ci}Mi=1 are generatedeither from a Hadamard matrix or some randomized algorithm and further randomly assigned to each class.This motivates us to build a probabilistic (in contrast to existing deterministic) hashing model which canconsider the uncertainty with different sources and characters. We therefore develop BNN-based probabilistichashing (ProbHash) by modeling as random variables. The hash-codes b are further modeled as anotherBernoulli random vector given a realization of and an input image data sample x. We illustrate ourProbHash modeling using probabilistic graphical model in . While we focus on developing our method based on two representative supervised image hashing models,ProbHash is a general framework that can be seamlessly extended to the majority of L2H models with variousnetwork structures, data types, likelihood assumptions, and various supervised and unsupervised formulations.",
  ": Illustrations of our probabilistic hashing (ProbHash) in graphical model": "Different variational families, such as dropout (Gal & Ghahramani, 2016) with a learnable or data-dependentrates (Gal et al., 2017; Boluki et al., 2020; Fan et al., 2021) and factorized Gaussian (Blundell et al., 2015),may also be adopt on to achieve better flexibility. The probability distribution p () and p (b|, x) can beinterpreted to represent epistemic uncertainty and aleatoric uncertainty in hash-code prediction, similar as thecategorization in literature (Kendall & Gal, 2017; Hllermeier & Waegeman, 2021). Our probabilistic modelfor L2H can offer a more concise formulation compared to many existing methods (Zhu et al., 2016; Caoet al., 2017; Su et al., 2018; Yuan et al., 2020; Fan et al., 2020; Tian Hoe et al., 2021), which adopt differentregularization tricks to minimize the quantization error in model training. Moreover, the introduction ofp(b|, x) will lead to a closed-form log-likelihood function in Center-Target construction, which can beeasily optimized without the straight-through heuristic (Bengio et al., 2013) as detailed in .4.",
  "Bayesian Learning for Image Hashing": "Our main objective is to learn p (b|x, ), which is the conditional distribution of b by a neural networkhashing function parametrized via after observing image x, and p|{xi, yi}Ni=1, which is the posteriordistribution of neural network parameters after observing the training data {xi, yi}Ni=1. To jointly learnp (b|x, ) and p|{xi, yi}Ni=1in the Bayesian paradigm while avoiding the intractability of computingthe marginal distribution p(y|x), we resort to the amortized variational inference with the variationaldistributions q(b|x, ) and q(). We learn the variational parameters by maximizing the Evidence LowerBOund (ELBO):",
  "Wl = Ml Zl,": "where denotes the Hadamard (entry-wise) product and Zl is the dropout mask, each row containing eitherall 1s or 0s with probability pl and 1 pl. {Ml}Ll=1 denote the variational parameters, which will be learnedfrom data jointly with . We omit the subscript for {Ml}Ll=1 and only use q() to denote the networkweight variational distribution throughout our discussion. The KL-divergence of the variational posteriorwith the Gaussian prior DKL(q()||p(|{xi}Ni=1)) can be approximated using a weight decay term (Gal &Ghahramani, 2016), which we also omit in the following discussion for simplicity. We also note here that thereare other possible amortized variational inference solutions. As an ablation study, an empirical comparisonwith another widely used variational distribution family of fully factorized Gaussian weights is included inAppendix B.5.",
  "k[2ci,k (f,k (xi)) + ci,k + 1] log Z,": "where log Z is a constant irrelevant to the variational parameters . This closed-form log-likelihood can beeasily estimated and optimized with any package equipped with automatic differentiation. Our negativeELBO minimization objective with both log-likelihood and KL-divergence terms in closed-forms can lead tomore principled training with better retrieval accuracy, compared to existing works (Zhu et al., 2016; Caoet al., 2017; Su et al., 2018; Yuan et al., 2020; Fan et al., 2020; Tian Hoe et al., 2021) where model optimization",
  "by biased gradient estimation of the discontinuous functionb with the heuristic straight-through (ST)trick (Bengio et al., 2013) can lead to degraded performance, as shown empirically in .4.1": "Connection to Information Bottleneck:While originally derived from the perspective of Bayesianinference, our proposed ProbHash with Label-Target construction can be considered as a realizationof variational information bottleneck (Alemi et al., 2016) on Learning-to-Hash with a Bernoulli latentrepresentation and a Bayesian neural network encoder. Minimizing the loss (2), which has a similar formatas the variational information bottleneck objective in Alemi et al. (2016), is also equivalent to maximizingthe mutual information between latent hash-codes b and labels y while minimizing the mutual informationbetween latent hash-codes b and inputs x.",
  "Predicting the Binary Hash-codes": "By solving the optimization problems discussed in .4, we obtain two variational posteriors q (b|x, )and q (). Our goal is to find a mapping from input data to a binary vector for image hashing. We calculatethe probability distribution of hash-code b given new test image x by marginalizing out the model parameters:",
  "Uncertainties in Hashing": "Our probabilistic modeling for both and b|x, leads to a hierarchically constructed distribution forhash-code b with two groups of uncertainties, as mentioned in .3. In particular, a low uncertaintyon in our learned model, with q() being similar to a Dirac delta function, indicates high confidence overmodel parameters. On the other hand, given and x, the predicted Bernoulli success probability closer to 0and 1 or 0.5 respectively means the model is certain or uncertain of the specific entry of hash-codes. Supposewe have NSample samples of neural network parameters {n}NSamplen=1with each n q(). For the ease ofdiscussion, we will use n,k(x) to denote the Bernoulli success rate of kth entry given input image x with nth",
  "sample n:n,k(x) = (fn,k(x))": "Consider four different cases when the mean value of ,k to be either 0.6 or 0.9, with either low or highvariance. If a model consistently predicts ,k 0.9, this indicates the model clearly towards predicting b,kto be 1. In either cases when predicting 0.6 consistently or 0.9 on average with high variance, the model isstill in favor of deciding on 1 but with more uncertainty. In the last case when the model outputs withthe mean value of ,k to be 0.6 with high variance, the model is less confidence for the decision on 1.This motivates us to quantify the uncertainty by conducting hypothesis testing on the samples of predictedBernoulli success rates of hash-codes, which we detail in .2.",
  "Measure of Uncertainty by t-test": "For any of the kth entry of a hash-code b,k, the significant difference between the Bernoulli success andfailure probabilities indicates confident prediction while having similar success and failure probabilitiesimplies uncertain prediction. Given the sampled probabilities of b,k being 1: {n,k}NSamplen=1and 0:{1 n,k}NSamplen=1, we conduct students t-test of the null hypothesis that the mean probabilities of being1 and 0 are equal on each of the kth entry. We represent the uncertainty in bk using the p-value of thetest, which we denote as Pk(x). A smaller p-value in favor of rejecting the null hypothesis indicates a moresignificant difference between the Bernoulli success and failure rates, reflecting our confidence in b,k. Thetotal uncertainty on the hash-code given an input image x is represented using the summed log p-value overall the K entries: Kk=1 log Pk(x). The summed log p-value over all entries provides an aggregated measureof hash-code uncertainty for one specific input data x, which can also be interpreted as the logarithm of thejoint tail probability given the null hypothesis under the factorization assumption. We adopt the paired sample t-test considering the dependency of the success and failure rates. This test isalso equivalent to performing one sample t-test of the null hypothesis that the sample mean of Bernoullisuccess rate equals 0.5, which can be interpreted similarly.",
  "Discussion": "Why Prioritizing Confident Pool Data:Given a confident pool data sample and an uncertain datasample with the predicted Hash-codes having the same Hamming distance to the query. The uncertainpool data is more likely to be either more relevant to the query, or irrelevant to the query compared to theconfident one. However, given the fact that these Hamming distances are small when we are performingnearest neighbor search, it is more likely that the latter one hold true, and we should choose the confidentpool data sample to achieve better retrieval accuracy, which we validate experimentally in Appendix B.6. Introduced Computation Consumption:Different from other applications of machine learning wheretheir inference time will be the main concern regarding computational budget, the hash-codes of pool datacan be pre-computed and stored in a hashing-based retrieval setup, and therefore the retrieval time andstorage consumption are the main computational concerns. The inference time of the query data will remainthe same as other non-probabilistic methods as we are not quantifying the uncertainty of query data. Whilewe mainly focus on using the uncertainty values of pool data throughout the discussion above, the uncertaintyvalues of query data can also be used to help improving retrieval accuracy either in a scenario where thecomputational resources allow, or by adopting some other uncertainty measures which does not requireintensive sampling, such as Shannons Entropy. We show in .3 that the query data with higherhash-code uncertainty will be more likely to retrieve irrelevant documents, which can be potentially combinedwith the aforementioned method to warn the users of the potentially erroneous retrievals.",
  "Hashing in the Presence of Uncertainty": "Consider a database of Np data entries {xp1, xp2, . . . , xpNp}, with Np on the order of millions or even trillionswith the corresponding hash-codes {bp1, bp2, . . . , bpNp}. When performing nearest neighbor search for the queryxq with code bq, compared to the data entries which are predicted to be relevant to the query but with highuncertainty, we prefer entries which are relevant based on the derived hash-codes with high confidence. Thismotivates us to take the quantified uncertainties into account for retrieval. We propose our uncertainty awareretrieval to prioritize the data entries with confident hash-codes while deprioritizing the data samples withuncertain hash-codes, which we term as Hashing with Uncertainty Quantification (HashUQ). In particular, when the query xq is provided along with the hash-code bq, we rank each entry xpi in thedatabase based on the Hamming distance between bq and bpi , which we denote as DHamming(bq, bpi ), from lowto high. In the meanwhile, we rank each entry based on quantified uncertainty associated with hash-code.The retrieval is performed by first comparing the Hamming distance DHamming(bq, bpi ). When we encountertwo entries with the same Hamming distance to the query, we further compare the quantified uncertaintiesof hash-codes and the entry with more confident hash-code will be retrieved with higher priority. We canequivalently describe our method as retrieving a pool data sample xpi in a sequential order based on thesorting results of the following expression in the ascending order over all the pool data in the database:",
  "Efficient Storage of Uncertainties": "Our proposed test on Bernoulli samples measures uncertainty in a real value, which is typically storedin the floating-point format in computer systems. Considering that the L2H is typically applied to theretrieval system which is sensitive to the storage space and running time, the space for storing the quantifieduncertainty is unignorable compared to the hash-code which takes only tens or hundreds of bits. We address this practical challenge by discretizing the quantified uncertainties. A simple example is to quantizethe uncertainties into binary, with each hash-code to be either Low Uncertainty or High Uncertaintynamely. When we discretize the quantified uncertainties into d quantized levels, the storage space reduces tolog2 d-bit complexity.",
  "Computational Complexity": "Assume that we have a total of N data samples in a database and M queries for retrieval. For each query,only r data samples need to be retrieved from the database and ranked accordingly, with r N. Whenthe vanilla Hamming-distance-based hashing strategy is applied, the total computational complexity for Mretrievals is O(C1MN) for Hamming distance computation and O(C2MN log N) for sorting, with C1, C2being two constants and C1 C2. As the quantified uncertainty is only associated with each data pointand does not need to be computed each time when the retrieval is performed, our uncertainty-based rankingstrategy will introduce almost no additional computation overhead to sort the quantified uncertainty whenmultiple retrieved images have the same distance to the query.",
  "Evaluation Metrics": "Mean Average Precision:In ranking-based retrieval, Average Precision (AP) is the integrated performancemeasure jointly considering precision and recall. Let P(r) be the precision of the top r images, and rel(r) theindicator function that the r-th image is relevant, and |{Relevant}| the number of all the relevant images tothe query in the database. We have:",
  "AP@r =Nr=1 P(r) rel(r)|{Relevant}|": "We use the mean Average Precision@r (mAP@r) on the whole test set to evaluate the retrieval performanceof our uncertainty aware image hashing, with r retrieved images when we calculate the average precision.Following previous works (Cao et al., 2017; Su et al., 2018; Yuan et al., 2020; Fan et al., 2020; Tian Hoeet al., 2021), we set r = 1000 for ImageNet, and r = 5000 for both MS COCO and NUS WIDE.",
  "Baseline Models": "For each of the Label-Target and Center-Target method, we implement our ProbHash model based onGreedyHash (Su et al., 2018) and CSQ (Yuan et al., 2020), respectively. We test ProbHash with andwithout HashUQ, and denote each of them as ProbHash and HashUQ throughout this section. Theretrieval algorithm with model confidence by HashUQ has been discussed in . As HashUQ takessignificantly more storage space compared to all other methods, we further binarize the uncertainties quantifiedusing the paired sample t-test as detailed in .2, which we denote as HashUQ-Bin. We comparewith the following SOTA baselines: HashNet (Cao et al., 2017), GreedyHash (Su et al., 2018), CSQ (Yuanet al., 2020), OrthoHash (Tian Hoe et al., 2021), and HSWD (Doan et al., 2022). We reproduce the resultsof GreedyHash, CSQ, and HSWD, and implement HashUQ performance evaluation and comparison basedon the implementation from DeepHash-pytorch1 with PyTorch 1.8.1 (Paszke et al., 2019). We reproduceOrthoHash results using the implementation from its official GitHub repository2 (Tian Hoe et al., 2021).",
  "Experimental Evaluation of Proposed Methods": "ProbHash Achieves Competitive Performances: summarizes the empirical performance ofbaseline models and different implementations of our proposed model. Compared to the correspondingbaseline models, GreedyHash and CSQ, our ProbHash achieves competitive retrieval accuracy. Acrosstwo constructions and three datasets, our ProbHash achieves similar or better performance on five setups andonly perform slightly worse in some of the experiments under one setup (Label-Target on ImageNet). ProbHash Enables Uncertainty Quantification: To show that our ProbHash can provide reasonableuncertainty estimation for the predicted hash-code of a supervised image hashing model, we provide theboxplot of retrieval accuracy for the query images with respect to the quantile of their predicted hash-codeuncertainty with both Center-Target and Label-Target construction with hash-code length K = 32on ImageNet in . The corresponding plots for K = 16 and K = 64 are included in ofAppendix B.2. In bothFigures 3a and 3b, we can clearly observe that the predicted uncertainties are typicallysmall for hash-codes of query image with high retrieval accuracy. The median, 25% and 75% quantiles ofretrieval accuracy will all decrease as the predicted hash-code uncertainties of query images increase, whichshows that a high estimated uncertainty will be typically associated with an erroneous prediction. 0%-20%20%-40%40%-60%60%-80%80%-100% Quantile of Hash-code Uncertainty 0.0 0.2 0.4 0.6 0.8 1.0 Average Precision @ 1000",
  ": Boxplot of retrieval accuracy with respect to the quantile of hash-code uncertainty with K = 32 ofour ProbHash with Center-Target and Label-Target constructions on ImageNet": "HashUQ Further Achieves State-of-the-art Retrieval Accuracy: By prioritizing data with highconfidence, our HashUQ-Bin consistently delivers superior performance across nearly all tested settings ofthe Label-Target and Center-Target constructs, demonstrating the broad applicability of our method.HashUQ-Bin under Center-Target can achieve prominent retrieval performance with the best retrievalaccuracy in 7 of the 9 settings tested, and is also comparable to the best performing models in the other twosettings. Our HashUQ-Bin improves the retrieval accuracy of the corresponding ProbHash model with asimilar amount as the full HashUQ, demonstrating its practical effectiveness exploiting the benefits from UQ. Discussion: HashUQ is especially effective for retrievals with short hash-codes, as there will typically bemore retrieved data samples whose hash-codes have the same Hamming distance from the query, compared toretrievals with long hash-codes. Although we have only shown the results with two representative L2H baselinemodels, our ProbHash and HashUQ can be combined with other advanced neural network architectures (Yuanet al., 2020), improved likelihood function design (Tian Hoe et al., 2021), and more sophisticated regularizationstrategies (Tian Hoe et al., 2021; Doan et al., 2022). We expect similar empirical performance improvement.In .4.4, we demonstrate that HashUQ outperforms baseline models in retrieval results, even whenthese models utilize more bits than HashUQ. This further validates the superior performance of HashUQ-Binrelative to the baselines.",
  "Effects of Different Model Components": "We study the effects of each component of our model and different optimization strategies by running theexperiments with different components included and excluded. All the ablation experiments are performedon Center-Target implementation. The corresponding retrieval performances on ImageNet are reported in. We use Straight-through to denote a model trained with the gradient ofb estimated by theStraight-Through trick, and Closed-form to denote the same model trained by optimizing the closed-formELBO in .4. Each componentclosed-form ELBO optimization, prior regularization, and UQ-basedranking strategycontributes to improved retrieval accuracy. Optimal retrieval performance is achievedwhen all these elements are combined.",
  "Sensitivity of Hyperparameter": "Our model only introduces one more hyperparameter for the trade-off between data belief and prior. Tostudy the sensitivity of our model performance with respect to , we run our model with different values onImageNet, with the corresponding retrieval accuracy reported in a. As long as is set to be withinan appropriate range, the retrieval accuracies of ProbHash and HashUQ are not sensitive to . Moreover,our UQ based ranking strategy can consistently improve the retrieval accuracy with all different values andall different hash-code bit-length Ks.",
  "Comparison of Different UQ Measures": "To compare different UQ measures in terms of the effectiveness in improving retrieval accuracy, we evaluatethe UQ-based retrieval strategy using different UQ measures. The results on different datasets with K-bithash-codes are reported in . More information about other two measures and a comparison can befound in Appendix B.4. While the uncertainty quantified in all of the three measures can help improve theretrieval accuracy, our t-test-based UQ consistently performs the best among all the measures on all threedatasets with different Ks. A possible explanation is the full consideration of two types of uncertainties inthe adopted p-value compared to other measures. For example, Shannons Entropy mostly just considers theuncertainty of b, while the summed variance only considers the uncertainty of . This further justifies ourapproach for the L2H task and our preference for the t-test-based UQ methodology.",
  "Effects of Number of Quantization Levels": "We further study the effects of the number of quantization levels d discussed in .2 on the retrievalaccuracy with our UQ-based ranking strategy. We determine the quantization levels by making the samenumber of data samples to be discretized to each of the quantization levels. b plots the retrievalaccuracy by ProbHash and HashUQ with different numbers of quantization levels when K = 32. We alsoinclude the performance of ProbHash with 2 more bits for each case to compare the performance within thesame storage. The corresponding figures with K = 16 and K = 64 can be found in Appendix B.3. Whilestoring the quantified uncertainty with a higher precision can lead to more accurate retrievals, with the best",
  ": Retrieval accuracy of HashUQ with (a) different coefficient values (b) quantization levels withK = 32 on ImageNet": "performance when no quantization is implemented, our UQ-based ranking method can bring significant andconsistent performance improvement to the implementation only considering the distances. They achievebetter performance even with the binarized or quaternarized uncertainty, which only takes 1 or 2 extra bitsfor storage and almost no extra computational overhead. When we train a deep hashing model with a few more bits but use it in the same way without consideringthe quantified uncertainty, the benefit brought by the extra bits is almost marginal compared to uncertaintyaware retrieval, as can be clearly observed in b. As no model re-training is needed for HashUQ aslong as the base model being a probabilistic model, our HashUQ can be applied to systems whose storageallows us to have additional memory to include more quantization levels, which adds on the flexibility asmore spareable resources can be utilized to improve the accuracy and user experience. The reason that theextra bits may bring almost no benefit to data retrieval can be possibly explained as the retrieval accuracy ofan L2H model can be highly dependent on the minimum pairwise Hamming distance between pre-specifiedcenter vectors (Tian Hoe et al., 2021) over all pairs, whose largest possible value will rarely change when Konly increases for a few more bits3.",
  "Related Work": "Information Retrieval and Learning to Hash:Given query data {xq1, xq2, . . . , xqM} and a databasewith N data points {xp1, xp2, . . . , xpN}, the main objective of information retrieval is to generate a rankingof all the pool data qi (xqi ; {xpj}Nj=1) for all the query data point, such that pool data similar to the querycan get higher ranking order while pool data different from the query will be ranked lower in each of thepredicted ranking. The Learning-to-Hash (L2H) based information retrieval methods achieve this by learningan encoding function f which can map the query and all of the pool data into K-bit binary hash-codes{bp1, bp2, . . . , bpN} (Weiss et al., 2008; Salakhutdinov & Hinton, 2009; Strecha et al., 2011; Liu et al., 2011;2014; Li et al., 2016). The retrieval is then performed by ranking all the pool data points according to theHamming distance of their hash codes to the hash code of the query. Pioneering works of L2H using traditional handcraft features include Spectral Hashing (Weiss et al., 2008),Linear Discriminant Analysis (LDA) Hashing (Strecha et al., 2011), and Graph Hashing (Liu et al., 2011;2014). Semantic Hashing (Salakhutdinov & Hinton, 2009) is among the earliest works using DNNs for hashing,where a two-stage procedure is developed to train a deep auto-encoder for document retrieval in a fullyunsupervised manner. For high-dimensional complex data such as images and video, some early deep hashingmodels include Deep Hashing (DH) (Erin Liong et al., 2015), Deep Pairwise-Supervised Hashing (DPSH) (Liet al., 2016), and Self-Supervised Temporal Hashing (SSTH) (Zhang et al., 2016). Recent research on imagehashing mostly focuses on solving the discrete optimization problem for principled training (Cao et al., 2017;Su et al., 2018), reducing the information loss in code quantization (Doan et al., 2022), improving the lossfunction for orthogonal and disentangled hash code generation (Tian Hoe et al., 2021; Doan et al., 2022), anddesigning novel and flexible learning schemes (Kang et al., 2019; Yuan et al., 2020; Fan et al., 2020). Uncertainty Quantification in Deep Learning:The primary notion of uncertainty in deep learning is touse a probability distribution as the model prediction instead of a point estimation. Most of uncertainty can becategorized into two major groups based on the sources and characteristics (Kendall & Gal, 2017; Hllermeier& Waegeman, 2021): aleatoric uncertainty, which represents the uncertainty due to the intrinsic randomnessof the physical process and is typically modeled by either the softmax outputs in classification tasks or theGaussian distributed outputs in regression tasks (Nix & Weigend, 1994); and epistemic uncertainty, which isthe uncertainty due to the lack of knowledge and is typically modeled by replacing the frequentist DNNs withBayesian Neural Networks (BNNs) (Lampinen & Vehtari, 2001; Titterington, 2004; Neal, 2012). BNNs modelnetwork parameters or activations as random variables whose distributions are learned through the posteriorupdates using Bayes theorem. To solve the intractability of posterior inference in many situations, variousapproximate inference methods based on Markov Chain Monte Carlo (MCMC) (Neal et al., 2011; Welling &Teh, 2011) and variational inference (VI) (Blei et al., 2017) have been developed, including the Monte Carlodropout (MC Dropout) (Gal & Ghahramani, 2016; Gal et al., 2017; Boluki et al., 2020; Fan et al., 2021) andBayes-By-Backprop (Blundell et al., 2015). Some UQ methods developed from a frequentists point of viewinclude conformal prediction (Angelopoulos & Bates, 2021) and quantile regression (Koenker, 2005), with thepoint estimation replaced by an interval representing the confidence of the model prediction. Our work differs from previous works of learning-to-hash in a way that our work is the first probabilisticframework for supervised hashing. We also propose a new measure of uncertainty designed for hashing basedon students t-test which can simultaneously quantify the aleatoric and epistemic uncertainties. Additionally,our work is also one of the few works that demonstrate the potential applicability of quantified uncertaintieson improving real-world applications.",
  "Conclusion and Discussion": "In this paper, we propose ProbHash, a probabilistic framework for modeling hashing function in imageretrieval along with a t-test based measure of uncertainty which jointly takes different sources of uncertaintyinto account. We further develop HashUQ, an uncertainty aware hashing strategy, and show that consideringthe quantified uncertainty is an effective and efficient way to enhance retrieval accuracy with little computationand storage overhead.",
  "Broader Impact Statement": "This paper presents a novel approach for image retrieval, contributing to the ongoing advancements in theintersection of machine learning, computer vision, and information retrieval. Our primary goal is to providingthe capability of uncertainty quantification to hashing models, and further enhancing the efficiency andaccuracy of retrieval systems. By doing so, we aim for valuable tools in applications ranging from contentorganization to visual search. The potential broader impact of our work extends to various societal dimensions. Improved image retrievalsystems can have positive impact for fields such as content management, recommendation, and searchingsystems. However, we also recognize the responsibility associated with deploying such technology, especiallyconcerning privacy, bias, and ethical considerations related to image content. This work was supported in part by the U.S. National Science Foundation (NSF) grants SHF-2215573,IIS-2212418, and IIS-2212419. Portions of this research were conducted with the advanced computingresources provided by Texas A&M High Performance Research Computing. Moloud Abdar, Farhad Pourpanah, Sadiq Hussain, Dana Rezazadegan, Li Liu, Mohammad Ghavamzadeh,Paul Fieguth, Xiaochun Cao, Abbas Khosravi, U Rajendra Acharya, et al. A review of uncertaintyquantification in deep learning: Techniques, applications and challenges. Information fusion, 76:243297,2021.",
  "Zhangjie Cao, Mingsheng Long, Jianmin Wang, and Philip S Yu. Hashnet: Deep learning to hash bycontinuation. In Proceedings of the IEEE international conference on computer vision, pp. 56085617, 2017": "Ting Chen, Simon Kornblith, Mohammad Norouzi, and Geoffrey Hinton. A simple framework for contrastivelearning of visual representations. In International conference on machine learning, pp. 15971607. PMLR,2020. Tat-Seng Chua, Jinhui Tang, Richang Hong, Haojie Li, Zhiping Luo, and Yan-Tao Zheng. Nus-wide: Areal-world web image database from national university of singapore. In Proc. of ACM Conf. on Imageand Video Retrieval (CIVR09), Santorini, Greece., July 8-10, 2009.",
  "J. Deng, W. Dong, R. Socher, L.-J. Li, K. Li, and L. Fei-Fei. ImageNet: A Large-Scale Hierarchical ImageDatabase. In CVPR09, 2009": "Khoa D Doan, Peng Yang, and Ping Li. One loss for quantization: Deep hashing with discrete wassersteindistributional matching. In Proceedings of the IEEE/CVF Conference on Computer Vision and PatternRecognition, pp. 94479457, 2022. Venice Erin Liong, Jiwen Lu, Gang Wang, Pierre Moulin, and Jie Zhou. Deep hashing for compact binarycodes learning. In Proceedings of the IEEE conference on computer vision and pattern recognition, pp.24752483, 2015.",
  "Jouko Lampinen and Aki Vehtari. Bayesian approach for neural networksreview and case studies. NeuralNetworks, 14(3):257274, 2001": "Wu-Jun Li, Sheng Wang, and Wang-Cheng Kang. Feature learning based deep supervised hashing withpairwise labels. In Proceedings of the Twenty-Fifth International Joint Conference on Artificial Intelligence,IJCAI16, pp. 17111717. AAAI Press, 2016. ISBN 9781577357704. Tsung-Yi Lin, Michael Maire, Serge Belongie, James Hays, Pietro Perona, Deva Ramanan, Piotr Dollr, andC Lawrence Zitnick. Microsoft coco: Common objects in context. In Computer VisionECCV 2014: 13thEuropean Conference, Zurich, Switzerland, September 6-12, 2014, Proceedings, Part V 13, pp. 740755.Springer, 2014.",
  "Radford M Neal et al. Mcmc using hamiltonian dynamics. Handbook of markov chain monte carlo, 2(11):2,2011": "David A Nix and Andreas S Weigend. Estimating the mean and variance of the target probability distribution.In Proceedings of 1994 IEEE International Conference on Neural Networks (ICNN94), volume 1, pp.5560. IEEE, 1994. Adam Paszke, Sam Gross, Francisco Massa, Adam Lerer, James Bradbury, Gregory Chanan, Trevor Killeen,Zeming Lin, Natalia Gimelshein, Luca Antiga, Alban Desmaison, Andreas Kpf, Edward Yang, ZachDeVito, Martin Raison, Alykhan Tejani, Sasank Chilamkurthy, Benoit Steiner, Lu Fang, Junjie Bai, andSoumith Chintala. Pytorch: An imperative style, high-performance deep learning library, 2019.",
  "D Michael Titterington. Bayesian methods for neural networks and related models. Statistical Science, pp.128139, 2004": "Aaron van den Oord, Oriol Vinyals, and koray kavukcuoglu. Neural discrete representation learning. InI. Guyon, U. Von Luxburg, S. Bengio, H. Wallach, R. Fergus, S. Vishwanathan, and R. Garnett (eds.),Advances in Neural Information Processing Systems, volume 30. Curran Associates, Inc., 2017. URL Ashish Vaswani, Noam Shazeer, Niki Parmar, Jakob Uszkoreit, Llion Jones, Aidan N Gomez, ukasz Kaiser,and Illia Polosukhin. Attention is all you need. Advances in neural information processing systems, 30,2017.",
  "Mingzhang Yin, Nhat Ho, Bowei Yan, Xiaoning Qian, and Mingyuan Zhou. Probabilistic best subset selectionvia gradient-based optimization. arXiv preprint arXiv:2006.06448, 2020": "Li Yuan, Tao Wang, Xiaopeng Zhang, Francis EH Tay, Zequn Jie, Wei Liu, and Jiashi Feng. Centralsimilarity quantization for efficient image and video retrieval. In Proceedings of the IEEE/CVF conferenceon computer vision and pattern recognition, pp. 30833092, 2020. Hanwang Zhang, Meng Wang, Richang Hong, and Tat-Seng Chua. Play and rewind: Optimizing binaryrepresentations of videos by self-supervised temporal hashing. In Proceedings of the 24th ACM internationalconference on Multimedia, pp. 781790, 2016.",
  ", where H is a Hadamard matrix of dimension 2k, will form a set of 2k-dimensional vectors": "with the theoretically maximum minimum mutual Hamming distance, which has been empirically shown toaffect the retrieval accuracy of Center-Target methods (Tian Hoe et al., 2021). These Hadamard matriceshave been used to construct the hashing centers in previous Center-Target methods (Yuan et al., 2020;Tian Hoe et al., 2021; Doan et al., 2022).",
  "for the following reasons:": "This probability distribution matches with our aforementioned principle for the likelihoodchoice: Both ci and bi are binary vectors and the Hamming distance is indeed a proper choiceof distance measure for binary vectors. The adopted likelihood distribution reflects our belief thatthe hash-code center ci corresponding to its class-label will be more likely to have small Hammingdistance to the unobserved hash-code bi. Our adopted likelihood distribution takes the highest valuewhen ci matches with bi and decreases when ci gradually deviates from bi. This probability distribution belongs to the commonly adopted likelihood distributions:Just like Gaussian or categorical distribution, our adopted likelihood distribution is a Boltzmanndistribution, which is one of the most widely used probability distribution in statistical analysis andmachine learning modeling. Our adopted distribution also belongs to the exponential family, whichhas a simple form of log likelihood function. This probability distribution has computational advantages over other choices of like-lihood distributions: This specific choice of our likelihood distribution will also lead to theclosed-form optimization objective as emphasized in .4 of our manuscript. The benefit ofthis closed-form objective is two-fold: (1) it reduces the computational consumption for conductingmultiple forward Monte Carlo samples; (2) it is unbiased and will reduce the variance for stochasticgradient descent, which will lead to more efficient model training.",
  "(7)": "This means that this distribution also satisfies all the three principles for selecting likelihood functionmentioned previously. The main difference between the distribution above and the likelihood distributionwe adopt in the main paper is how the probability decays as the Hamming distance gets larger. We runsupplementary experiments on ImageNet dataset to compare the distribution above (D2Hamming) and thelikelihood distribution we adopt in the main paper(DHamming), and include the results in :Weobserve the retrieval accuracy to be slightly affected with the likelihood distribution in the main paperreplaced with the likelihood discussed above. The experiment results also show that our HashUQ strategycan help improving the retrieval accuracy regardless of the likelihood choice.",
  "B.1.1Datasets": "We empirically evaluate image retrieval performances based on different supervised hashing methods to demon-strate our uncertainty aware HashUQs superiority on three benchmark image datasets: ImageNet (Denget al., 2009), MS COCO (Lin et al., 2014), and NUS WIDE (Chua et al., July 8-10, 2009). Each datasethas been further split into training, query and pool (database) sets, with the details given below: ImageNet is a large-scale image dataset (Deng et al., 2009), which contains more than 10,000,000 imageslabeled with 20,000 different synsets in WordNet. We follow Cao et al. (2017) and use the images from 100selected categories for training as well as evaluation. MS COCO is an image dataset with more than 200, 000 labeled images from 80 categories (Lin et al.,2014). Multiple labels are typically associated with one image instance, which makes the retrieval tasktypically more challenging than ImageNet. We follow Zhu et al. (2016) and use a total of 132,218 datasamples for training and evaluation. NUS WIDE is an image dataset with a total of 269, 648 data samples collected from Flickr, labeled with81 ground-truth concepts (Chua et al., July 8-10, 2009). We follow Cao et al. (2017) and use images fromthe 21 most frequent concepts for model development and testing, with each concepts containing at least5000 images. One major difference between our evaluation pipeline and those adopted in previous works is that we explicitlyinclude a validation set for model selection while most of the previous works does not differentiate thevalidation set with the test set (Cao et al., 2017; Su et al., 2018; Yuan et al., 2020; Fan et al., 2020; Tian Hoeet al., 2021). The dataset statistics with the adopted data splits are summarized in .",
  "B.1.2Hyperparameters and Training Details": "We use the AlexNet (Krizhevsky et al., 2012) backbone for all the experiments to be consistent with theevaluation pipelines of previous works Cao et al. (2017); Su et al. (2018); Yuan et al. (2020); Tian Hoe et al.(2021); Doan et al. (2022). Three extra fully connected layers with the latent dimensions 4096 are addedat the end of neural network backbone. We regularize the last three layers with dropout in each of thehidden layer for all the methods benchmarked, with the neurons reweighed deterministically in baselines anddropped randomly in our ProbHash and HashUQ at test time. The the dropout rates are set to be 0.5.Weoptimize the neural networks using RMSprop (Hinton et al., 2012) optimizer with the learning rate 1e 5 andweight decay 1e 5 for all the models. We use our derived closed-form ELBO as the minimization objective",
  ": Boxplot of retrieval accuracy with respect to the quantile of hash-code uncertainty with K = 16,K = 32 and K = 64 of our ProbHash with Center-Target and Label-Target constructions on ImageNet": "We present more results showing the uncertainty quantification capability of our proposed method supple-mentary to experiments in Sections 5.3 of the Main Text. The boxplots of retrieval accuracy for the queryimages with respect to the quantile of their predicted hash-code uncertainty with different constructions withK = 16 and K = 64 are provided in . We can observe similar trend as in the Main Text: A higher",
  "B.3Supplementary Results for Ablation Experiments": "We include more experimental results supplementary to the experiments in Sections 5.4.2 and 5.4.4 of theMain Text. We plot the retrieval accuracy with respect to different coefficients in Figures 6a and 6b, andthe ones with different numbers of quantization levels in Figures 6c and 6d on the ImageNet dataset withK = 16 and K = 64. We observe a similar trend as in Sections 5.4.2 and 5.4.4 of the Main Text: Both of ourProbHash and HashUQ provide retrieval performances insensitive to , as long as is set within a appropriaterange. Our HashUQ can consistently provide performance improvement over ProbHash regardless of , Kand quantization level settings. Our HashUQ also brings more retrieval accuracy improvement compared to amodel without considering the quantified uncertainty as the allowed bits increase. 02468100.52 0.54 0.56 0.58 0.60 0.62 0.64 ImageNet mAP@1000 ProbHashHashUQ",
  "B.4Supplementary Information for Different Metrics": "We here provide more information about the comparative study of different metrics for measuring theuncertainties in hashing complementary to .4.3 of the Main Text. Given a bunch of Bernoulli successrates {kn}NSamplen=1, one way to measure the uncertainty is to calculate the variance of kn: E[(k E[k])2].This type of uncertainty measure will mostly quantify the effect of the uncertainty of variational distribution",
  "of model parameters on the Bernoulli success rates k. We report the experimental results with proposedHashUQ based retrieval on different image datasets in , which we denote asVariance": "Another way to quantify the uncertainty considering the adopted factorized Bernoulli distribution for hash-code is the Shannons Entropy, which has been adopted in Wang et al. (2023). As no uncertainty of isconsidered in Wang et al. (2023), here we generalize the metrics for our method and consider the ShannonsEntropy of q(b|x, ): H(q(b|x, )) = Eq()[Eq(b|x,))[ log q(b|x, )]]. This will measure the uncertainty ofhash-code bk averaged over the distribution of neural network parameters q(). We also test this metricwith the results denoted as Entropy in . In both of the above cases, we sum the variance andentropy over all the K entries to have an aggregated notion of uncertainty for hash-code of one input imageconsidering the factorized assumptions of our variational distribution.",
  "B.5Comparison of Different Variational Distributions for Bayesian Neural Networks": "Last but not least, we provide an empirical comparison between dropout, the variational distribution weadopted, to another widely used distribution for Bayesian neural network approximation: Fully FactorizedGaussian weights (FFG). For each entry Wl,i,j of neural network weight matrix Wl, the independent Gaussiandistribution is assumed:Wl,i,j NWl,i,j; l,i,j, 2l,i,j, with {l,i,j, l,i,j} as the variational parameters. We specifically adopt the Bayes-By-Backprop (Blundellet al., 2015) implementation for Fully Factorized Gaussian weights, in which the variational distribution isreparameterized using the standard Gaussian distribution and variational parameters optimized by maximizingthe Evidence Lower BOund (ELBO) of training data through gradient-based optimization. We model theweight matrices of the last {1, 2, 3} fully connected layers as factorized Gaussian and set the learning rates tobe {1 105, 5 105, 1 104}. A standard Gaussian prior is adopted and {1, 5, 10} Monte Carlo samplesare used to reduce the variance of gradient estimation, with the best performing model in the aforementionedconfigurations on ImageNet dataset choosen to be reported in . The quantified uncertainties of Fully Factorized Gaussian weights can similarly be used to help enhance theretrievals as the dropout weights. We observe worse empirical performance of Fully Factorized Gaussianweights compared to dropout in most of the setups with or without using uncertainties. In the meanwhile,the performance improvement due to uncertainties quantified from the Fully Factorized Gaussian weights isslightly more significant compared to dropout. While some more flexible distribution families may betterapproximate the posterior and model the uncertainties (Foong et al., 2020), it also brings computationalchallenges in optimization, which may require further analysis on the ELBO maximization objective andgradient based optimization methods.",
  "H(b|x) Eq()[H(b|, x)]": "Connection and Difference: Both of the t-test and Shannons entropy give the highest estimation ofuncertainty when the model consistently predicts ,k 0.5 (corresponding to high aleatoric uncertainty)while the lowest estimation of uncertainty when the model predicts ,k 0 or ,k 1 (corresponding tolow aleatoric uncertainty). When the Shannons Entropy based measure of uncertainty mentioned above isadopted, the total uncertainty do not change and the aleatoric uncertainty decrease as the variation of increase. The uncertainty measured using t-test will increase when the variation of increase. We include anumerical comparison between paired sample t-test and Shannons entropy based measures of uncertaintyusing 100 samples from truncated Gaussian distributions in and 9 to show how each of these twouncertainties change as the mean and variance Var() changes.",
  "DRETRIEVAL EXAMPLES": "We provide retrieval examples of our ProbHash and HashUQ in Figures 10a and 10b using 5 exemplar queryimages from ImageNet. On the left-most of each row is the query image, and the corresponding retrievedimages are plotted on the right-hand-side of the dividing line. We plot each retrieved images relevant to thequery in green bounding boxes, and images irrelevant to the query in red bounding boxes. To illustrate themain idea and show the difference between the predicted ordering of the retrieval models with and withoutuncertainty, here we set number of retrieved samples r = 10. (This means that we only retrieve 10 imagesfrom all the 128, 503 entries in the database based on the hash-codes Hamming distance for each query, andre-rank these 10 images by the predicted uncertainty of hash-code accordingly.) By comparing a and b, we see that our HashUQ will prioritize images with relevantconcepts to the query while de-prioritize images with irrelevant concepts, which lead to more principledretrieval ordering. In real case, by rank the data with the same hash-code Hamming distance to the queryusing the predicted uncertainty, the relevance of top r data to be retrieved will also be improved, and theretrieval accuracy will be affected not only by the retrieval ordering but also in terms of the data to beretrieved.",
  "(d)": ": Uncertainty measured with (a) paired sample t-test, (b) conditional Shannons entropy, (c) totalShannons entropy and (d) induced epistemic uncertainty based on Shannons entropy using 100 samples fromGaussian distributions N(, 2) with respect to mean changing from 0.1 to 0.5. The standard deviation = 0.05 and Gaussian distribution is truncated at (a, b) with the minimum and maximum value (a, b) set tobe a = 0.1, b = + 0.1.",
  "(b)": ": (a): Exemplar image retrieval results using 5 query images from the ImageNet dataset. Theretrieval is performed without considering the uncertainty of hash-codes (b) Image retrieval using the samequeries with proposed HashUQ. On the left side of the dividing line is the query image while on the right sideof the line is the retrieved data, with the decreasing predicted relevance from left to right. We plot successretrievals in green bounding boxes and failure retrievals in red bounding boxes. Below each retrieved image isthe Hamming distance of the hash-code to the query image. To illustrate the main idea, here we only retrieve10 images for each query and re-rank them based on the quantified uncertainty.",
  "ESUPPLEMENTARY FIGURES": "1.00.50.00.51.0 Difference of Paired Samples Number of Occurrences 1.00.50.00.51.0 Difference of Paired Samples Number of Occurrences 1.00.50.00.51.0 Difference of Paired Samples Number of Occurrences 1.00.50.00.51.0 Difference of Paired Samples Number of Occurrences 1.00.50.00.51.0 Difference of Paired Samples Number of Occurrences 1.00.50.00.51.0 Difference of Paired Samples Number of Occurrences 1.00.50.00.51.0 Difference of Paired Samples Number of Occurrences 1.00.50.00.51.0 Difference of Paired Samples Number of Occurrences 1.00.50.00.51.0 Difference of Paired Samples Number of Occurrences 1.00.50.00.51.0 Difference of Paired Samples Number of Occurrences 1.00.50.00.51.0 Difference of Paired Samples Number of Occurrences 1.00.50.00.51.0 Difference of Paired Samples 0.0 2.5 5.0 7.5 10.0 12.5 15.0 17.5 Number of Occurrences 1.00.50.00.51.0 Difference of Paired Samples Number of Occurrences 1.00.50.00.51.0 Difference of Paired Samples Number of Occurrences 1.00.50.00.51.0 Difference of Paired Samples Number of Occurrences 1.00.50.00.51.0 Difference of Paired Samples Number of Occurrences"
}