{
  "Abstract": "Machine learning models, meticulously optimized for source data, often fail to predict tar-get data when faced with distribution shifts (DSs). Previous benchmarking studies, thoughextensive, have mainly focused on simple DSs. Recognizing that DSs often occur in morecomplex forms in real-world scenarios, we broadened our study to include multiple concur-rent shifts, such as unseen domain shifts combined with spurious correlations. We evaluated26 algorithms that range from simple heuristic augmentations to zero-shot inference usingfoundation models, across 168 source-target pairs from eight datasets. Our analysis of over100K models reveals that (i) concurrent DSs typically worsen performance compared to asingle shift, with certain exceptions, (ii) if a model improves generalization for one distribu-tion shift, it tends to be effective for others, and (iii) heuristic data augmentations achievethe best overall performance on both synthetic and real-world datasets.",
  "Introduction": "Machine learning models deployed in real-world settings may face complex distribution shifts (DSs). Theseshifts can result in unreliable predictions. For instance, a self-driving car may be deployed in a place wherethere is a different driving etiquette, unfamiliar environment and weather condition. Thus, a systematicevaluation of such complex shifts is essential before deploying models in the real world. Most research has focused on evaluating models under a single DS (UniDS) (Taori et al., 2020; Gulrajani &Lopez-Paz, 2020; Koh et al., 2021; Wiles et al., 2022; Miller et al., 2021; Wenzel et al., 2022). For instance,in the PACS evaluation benchmark (Li et al., 2017), the training data consists of photographs, but themodel is tested on sketches. Similarly, in the training data of Biased FFHQ (Lee et al., 2021), gender isspuriously correlated to age, but the model is tested on data where gender is anti-correlated to age. Ina real-world scenario, we can encounter these two shifts concurrently, i.e., one where age and gender arespuriously correlated and where there is also a shift in the style of the image.",
  "Published in Transactions on Machine Learning Research (01/2025)": "Long Zhao, Ting Liu, Xi Peng, and Dimitris Metaxas.Maximum-entropy adversarial data augmenta-tion for improved generalization and robustness. In Advances in Neural Information Processing Systems(NeurIPS), 2020. Guangtao Zheng, Mengdi Huai, and Aidong Zhang. Advst: Revisiting data augmentations for single domaingeneralization. In Proceedings of the AAAI Conference on Artificial Intelligence, volume 38, pp. 2183221840, 2024.",
  "In this section, we review existing benchmarks for distribution shifts (DSs) and frameworks for evaluatingmodel generalization": "Benchmarks.Several types of benchmarks have been introduced to evaluate the generalization of models.One type of benchmark evaluates generalization on datasets collected from different sources, i.e., due todifferent domains (Li et al., 2017; Venkateswara et al., 2017; Peng et al., 2019; Koh et al., 2021) e.g., the trainand test data are collected from different countries, or different time periods (Yao et al., 2022; Hendryckset al., 2021). Another popular type applies transformations to the input (Hendrycks & Dietterich, 2019;Sagawa et al., 2019; Nam et al., 2020; Bahng et al., 2020; Jeon et al., 2022b). Such transformations rangefrom analytical ones like rotation, corruptions like brightness or contrast, to learned ones like adversarialattacks. Images with the same transformations form a domain, while each transformation can be an attribute,creating spurious correlations by matching labels to transformations.Other alternatives includes usingengines like Blender or Unity to create simulators that can render different types of shifts (Leclerc et al.,2022; Sun et al., 2022). In contrast, Recht et al. (2019) collects new test sets for ImageNet and CIFAR-10 byreplicating the data collection pipeline. They showed that without any explicit distribution shift, there is adrop in accuracy. Similarly, Barbu et al. (2019) collects a new dataset where objects have unusual poses orviewpoints. The benchmarks most similar to ours involve changing the original train-test split of the datasetto induce different types of DSs (Kim et al., 2019; Koh et al., 2021; Jeon et al., 2022a; Atanov et al., 2022;Jeon et al., 2022b). In contrast to these methods, our paper focuses on creating controllable concurrentshifts by using attribute annotations in existing datasets. Large-scale Generalization Analysis.Although methods that enhance robustness against DSs havebeen extensively researched, significant variations across application domains mean that a method thatexcels in one dataset might not perform equally well in another. Consequently, recent efforts have beendedicated to comprehensively and fairly evaluate generalization methods. Gulrajani & Lopez-Paz (2020)demonstrated that empirical risk minimization, when meticulously implemented and finely tuned, excelsover domain generalization methods in robustness. Taori et al. (2020) found that generalizability to syn-thetic shifts does not guarantee robustness to natural shifts. Koh et al. (2021) introduced Wilds, a curatedbenchmark consisting of 10 datasets that encapsulate a diverse range of DSs encountered in real-world set-tings. Their findings indicate that current methods for generalization are inadequately equipped to addressreal-world DSs. Wiles et al. (2022) reported that both pre-training and augmentations significantly boostperformance across many scenarios, although the most effective methods vary with different datasets andDSs. Additionally, Miller et al. (2021) and Wenzel et al. (2022) observed a positive correlation betweenout-of-distribution and in-distribution performance. However, these studies predominantly concentrate onsingle DSs, which do not fully capture real-world scenarios. Ye et al. (2022) categorized existing benchmarksbased on the extent of spurious correlations and the degree of domain shift. Their findings reveal that, forthe most part, Out-of-Distribution generalization algorithms remain susceptible to spurious correlations.",
  ": dSprites samples. Even in simple syn-thetic data, multiple attributes can potentially leadto various DSs. Visualizations for other datasets areincluded in in the Section A.1": "Consider an instance set X= {xi|xi X, i =1, . . . , N} for a classification problem, where X de-notes the input space. Each instance x can be repre-sented by a finite set of attributes Y (x) = {yk|yk Y, k = 1, . . . , K} where Y denotes the attribute spaceand K varies with x. Within this framework, one at-tribute yl from Y (x) can be designated as the label.Let p, pS, and pT be the true, source, and target dis-tributions, respectively. We denote the source and tar-get datasets by DS pS and DT pT , respectively,where each dataset consists of samples from its corre-sponding distribution. A machine learning model f isdesigned to minimize the empirical risk,",
  "Unique Distribution Shifts": "We revisit spurious correlation (SC), low data drift (LDD), and unseen data shift (UDS) as delineated inthe experimental framework by Wiles et al. (2022), grouping these under the category of unique distributionshifts (UniDS), namely UniDS := {SC, LDD, UDS}. To create the UniDS, we select one attribute fromthe candidates (y, y, y) and then sample the images for each DS accordingly. All other attributes displaya uniform distribution for UniDS. Test distribution pT . All the attributes yk Y (x) are uniformly distributed, ensuring that each attributeis represented and independent from the others. For example, for pT p, there is an equal number ofsamples across 81 combinations, ranging from (square, red, orange, small) to (heart, blue, purple, big). Spurious correlation. Under pS, the label yl and a specific attribute y exhibit correlation, which doesnot hold under pT . For example, there are only (square, red), (ellipse, yellow), and (heart, blue) samples inDS, exhibiting a correlation between shape and color. Low data drift. Attribute values show an uneven distribution under pS but are more evenly distributedunder pT . Generalization for LDD is also referred to as worst-case generalization (Sagawa et al., 2019; Seoet al., 2022). For example, there are significantly fewer red samples compared to the numerous yellow andblue samples. Even among the red samples, the distribution of shapes is uneven.",
  "ConDS := {S UniDS | |S| 2},(3)": "where each subset S represents a unique configuration of shifts, creating a richer and more representa-tive model of the underlying complexities in real-world data. Each pair (yl, yk) within this framework,where k belongs to a predefined set {, , }, is governed by specific UniDS. For instance, using the attributes shown in , (SC, UDS) can be established by sampling combinationssuch as (square, red), (ellipse, yellow), and (heart, blue), while the background color varies between (orange,green) and the object size maintains a uniform distribution. The concept of ConDS and its importance werealso introduced in Koh et al. (2021). However, their discussion was limited to LDD and UDS. We broaden thisto include SC, LDD, and UDS, aiming for a thorough understanding of their interconnections. Additionally,we investigate a broader array of algorithms to assess how existing methods perform on ConDS.",
  "Generalization to Distribution Shifts": "As discussed in .1, it is assumed that during training, we only have access to source data, while thetarget distribution remains unknown (Vapnik, 1991; Jeon et al., 2023). While some algorithms are specificallydesigned for scenarios where partial knowledge of the target distribution is available (Adeli et al., 2021; Alviet al., 2018; Kim et al., 2019; Geirhos et al., 2018; Bahng et al., 2020; Ganin et al., 2016), the setup where notarget information is known generally poses a broader challenge for model generalization. Consequently, ouranalysis focuses on this more general setup. We evaluate 26 algorithms suitable for this scenario, spanninga wide spectrum of methods, as shown in .",
  "Experiments": "In this section, we begin by presenting the datasets we evaluated on and the experimental setup. Next,we evaluated 26 distinct algorithms across 168 (source, target) pairs spanning six datasets, addressing bothUniDS and ConDS. The aggregate results are illustrated in , while the comprehensive results aredetailed in Section B.1. We further examine how the challenges vary among different DSs () andevaluate the effectiveness of pre-training in enhancing robustness (). Further analysis investigateshow zero-shot inference performance depends on distribution shifts (DSs), as shown in . Finally, weanalyze the outcomes, summarizing them into eight key takeaways.",
  "Datasets": "Controlled datasets: We assess algorithms using five evaluation datasets: dSprites, Shapes3D, Small-Norb, CelebA, and DeepFashion. From these, we select four attributes: one is designated as the label(yl), and the other three as attributes (y, y, y) to create DSs. lists the attribute instances for yl and {y, y, y} for the different controlled datasets. We divide the source data into training and validationsets, both sharing the same distribution, with the validation set used for hyperparameter tuning. Uncontrolled real-world datasets: We use iWildCam, fMoW, and Camelyon17 for evaluation.iWildCam data in the Wilds benchmark (Koh et al., 2021) exhibits LDD over the animal distributions, andUDS occurs across camera trap locations. Similarly, the fMoW dataset (Koh et al., 2021) exhibits UDS andLDD across time and regions in satellite images. Camelyon17 is a tumor detection dataset with variousunexpected DSs resulting from different hospitals. We further discuss additional insights from the catego-rization of synthetic (Dsprites, Shapes3D, Smallnorb) and real-world datasets (CelebA, DeepFashion,iWildCam, fMoW, Camelyon17) in Section A.3.",
  "yfabric{chiffon, cotton}": "from {y, y, y} to create UniDS (3 settings). For ConDS, we use six combinations (either 3C2 or 3C3settings) to establish designated DSs, resulting in a total of 165 (source, target) pairs. For example, for the(SC, LDD) setting, we choose one attribute to define SC and another from the remaining two to create LDD,resulting in 6 (source, target) pairs. The detailed description for this is provided in Section A.1. For all SC,",
  "avg.82.3132.18": "we include 1% of counterexamples, similar to the setup established in the research on SC robustness (Jeonet al., 2022a; Nam et al., 2020). We set ResNet18 as the backbone for all algorithms. More details abouthyperparameters are provided in Section A.6. Real-world datasets: We adhered to the use of the train,validation, and test sets for iWildCam, fMoW, and Camelyon17. Real-world datasets do not exhibita clear distribution shift like controlled datasets, but they inherently contain various naturally occurringdistribution shifts that may go unnoticed. Results. shows the aggregate result of algorithms across DSs for the controlled datasets. and present the outcomes when methods are trained using ImageNet pre-trained weights. In ,some algorithms, particularly augmentation techniques, surpass large models in scenarios without SC, anadvantage not observed when training from scratch (see ). indicates that pre-training",
  "Worst-caseSDGOOD": ": Analysis of model robustness on distribution shifts. Left: Average performance of allgeneralization methods under different combinations of DSs. Right:Comparing the different generalizationmethods under an increasing number of DSs. : An example of zero-shot inference prompts. The first two rows show the General promptsand the next three rows the Tailored prompts that we used with LLaVA-1.5. For a more comprehensivelist of these prompts, please see in Section B.5.",
  "General192.8494.7780.2282.8750.0051.6424.9858.02General292.8494.7778.3793.7551.2551.8024.8958.03Tailored92.8494.7778.8589.6250.051.2125.5858.10": ". For CLIP, we use widely adopted prompts, such as \"a photo of a label\" (Matsuura et al.). Giventhat vision-language models designed for visual question answering may depend on the querys context, thechoice of prompts is crucial (Sahoo et al., 2024). We categorize prompts that are applicable to any datasetas General, and those specifically designed for each dataset as Tailored. We provide several examples forthe prompt in . In Matsuura et al. and Islam et al. (2023), diverse prompts are employed as queriesfor vision-language models, specifically tailored to the dataset and the labels targeted for classification. Ouranalysis builds on this approach.",
  "Takeaways": "Takeaway 1 ConDS is, on average, more challenging than UniDS. While previous studies onmodel generalization have primarily focused on UniDS, we observe that most algorithms exhibit poorerperformance in ConDS. Moreover, the more numerous the DSs, the greater the challenge they pose, asillustrated in (right). Takeaway 2 SC is the most challenging DS, followed by UDS and LDD. (left) breaksdown the performance of generalization methods according to DS. We see that the presence of SC tends todominate over other DSs in ConDS. Although ConDS presents more challenges than UniDS for LDD andUDS, there is almost no performance drop when moving from SC to SC+LDD or SC+UDS. Furthemore,for the DSs that include SC, the performance of most methods is inferior to that of foundation models evenwhen it is pre-trained, as shown in . Takeaway 3 Generalization tends to be consistent across DSs. If a method improves generalizationfor one DS, it tends to be effective for others.Namely, although models such as de-biasing, worst-casegeneralization, and domain generalization are designed to address a specific DS (as detailed in ),their applicability is not confined to that particular shift.",
  "Concluding Remark": "Contribution. In this paper, we introduce a novel evaluation framework to understand the robustness ofmodels against various distribution shifts, including UniDS and ConDS. Using this protocol, we can createdistribution shifts in any multi-attribute-annotated dataset, allowing for a more comprehensive understand-ing of robustness.Through our extensive evaluation involving 100K experiments, we find that ConDSpresent greater challenges compared to conventional UniDS, with spurious correlations being more prob-lematic than low data drift and unseen domain shifts. Our results indicate that heuristic augmentationsand pre-training are effective tools for enhancing generalization, while more complex models offer limitedbenefits. Additionally, while large models are viable for image classification, their performance is effectiveonly in specific scenarios and requires careful application. Limitation and future work. While we believe that our work makes a promising step towards understandinghow models behave under complex scenarios, there is still a lot more that can be done in this direction, webriefly discuss some of them. Our evaluation framework allows us to create controlled distribution shiftsand assumes a uniform test distribution. Our framework also uses annotated, thus, interpretable attributesto create shifts. Using learned attributes would also be an interesting future direction. Furthermore, ourstudy covers a limited range of attributes, particularly in controlled real-world datasets such as CelebAand DeepFashion, due to insufficient samples for other attributes. Future research could explore the useof advanced controllable generative models (e.g., diffusion models) to address this limitation and cover abroader range of conditions. Acknowledgments.Myeongho Jeon, jointly affiliated with EPFL and Seoul National University, wassupported by the National Research Foundation of Korea (NRF) grant funded by the Korea government(MSIT) [RS-2024-00337693]. Suhwan Choi was supported by the Ministry of Culture, Sports and Tourism &Korea Creative Content Agency [RS-2024-00399433], and Artificial intelligence industrial convergence clusterdevelopment project funded by the Ministry of Science and ICT (MSIT, Korea) & Gwangju MetropolitanCity. We also extend our sincere thanks to CRABs.ai for their generous financial support and the provisionof GPU resources.",
  "Martin Arjovsky, Lon Bottou, Ishaan Gulrajani, and David Lopez-Paz. Invariant risk minimization. arXivpreprint arXiv:1907.02893, 2019": "Andrei Atanov, Andrei Filatov, Teresa Yeo, Ajay Sohmshetty, and Amir Zamir. Task discovery: Findingthe tasks that neural networks generalize on. Advances in Neural Information Processing Systems, 35:1570215717, 2022. Hyojin Bahng, Sanghyuk Chun, Sangdoo Yun, Jaegul Choo, and Seong Joon Oh. Learning de-biased rep-resentations with biased representations. In International Conference on Machine Learning, pp. 528539.PMLR, 2020. Andrei Barbu, David Mayo, Julian Alverio, William Luo, Christopher Wang, Dan Gutfreund, Josh Tenen-baum, and Boris Katz. Objectnet: A large-scale bias-controlled dataset for pushing the limits of objectrecognition models. Advances in neural information processing systems, 32, 2019. Xi Chen, Xiao Wang, Soravit Changpinyo, AJ Piergiovanni, Piotr Padlewski, Daniel Salz, Sebastian Good-man, Adam Grycner, Basil Mustafa, Lucas Beyer, et al. Pali: A jointly-scaled multilingual language-imagemodel. arXiv preprint arXiv:2209.06794, 2022.",
  "Mathieu Chevalley, Charlotte Bunne, Andreas Krause, and Stefan Bauer.Invariant causal mechanismsthrough distribution matching. arXiv preprint arXiv:2206.11646, 2022": "Ekin D Cubuk, Barret Zoph, Dandelion Mane, Vijay Vasudevan, and Quoc V Le. Autoaugment: Learningaugmentation strategies from data. In Proceedings of the IEEE/CVF conference on computer vision andpattern recognition, pp. 113123, 2019. Ekin D Cubuk, Barret Zoph, Jonathon Shlens, and Quoc V Le. Randaugment: Practical automated dataaugmentation with a reduced search space. In Proceedings of the IEEE/CVF conference on computervision and pattern recognition workshops, pp. 702703, 2020. Ilke Cugu, Massimiliano Mancini, Yanbei Chen, and Zeynep Akata. Attention consistency on visual corrup-tions for single-source domain generalization. In Proceedings of the IEEE/CVF Conference on ComputerVision and Pattern Recognition, pp. 41654174, 2022. Wenliang Dai, Junnan Li, Dongxu Li, Anthony Meng Huat Tiong, Junqi Zhao, Weisheng Wang, BoyangLi, Pascale N Fung, and Steven Hoi. Instructblip: Towards general-purpose vision-language models withinstruction tuning. Advances in Neural Information Processing Systems, 36, 2024. Alexey Dosovitskiy, Lucas Beyer, Alexander Kolesnikov, Dirk Weissenborn, Xiaohua Zhai, Thomas Un-terthiner, Mostafa Dehghani, Matthias Minderer, Georg Heigold, Sylvain Gelly, et al. An image is worth16x16 words: Transformers for image recognition at scale. arXiv preprint arXiv:2010.11929, 2020. Yaroslav Ganin, Evgeniya Ustinova, Hana Ajakan, Pascal Germain, Hugo Larochelle, Franois Laviolette,Mario March, and Victor Lempitsky. Domain-adversarial training of neural networks. Journal of machinelearning research, 17(59):135, 2016.",
  "Dan Hendrycks and Thomas Dietterich. Benchmarking neural network robustness to common corruptionsand perturbations. arXiv preprint arXiv:1903.12261, 2019": "Dan Hendrycks, Norman Mu, Ekin D Cubuk, Barret Zoph, Justin Gilmer, and Balaji Lakshminarayanan.Augmix:A simple data processing method to improve robustness and uncertainty.arXiv preprintarXiv:1912.02781, 2019. Dan Hendrycks, Steven Basart, Norman Mu, Saurav Kadavath, Frank Wang, Evan Dorundo, Rahul Desai,Tyler Zhu, Samyak Parajuli, Mike Guo, et al. The many faces of robustness: A critical analysis of out-of-distribution generalization. In Proceedings of the IEEE/CVF international conference on computer vision,pp. 83408349, 2021. Edward J Hu, Yelong Shen, Phillip Wallis, Zeyuan Allen-Zhu, Yuanzhi Li, Shean Wang, Lu Wang, andWeizhu Chen. LoRA: Low-rank adaptation of large language models. In International Conference onLearning Representations, 2022. URL Ashhadul Islam, Md Rafiul Biswas, Wajdi Zaghouani, Samir Brahim Belhaouari, and Zubair Shah. Pushingboundaries: Exploring zero shot object classification with large multimodal models. In 2023 Tenth Inter-national Conference on Social Networks Analysis, Management and Security (SNAMS), pp. 15. IEEE,2023. Myeongho Jeon, Daekyung Kim, Woochul Lee, Myungjoo Kang, and Joonseok Lee. A conservative approachfor unbiased learning on unknown biases. In Proceedings of the IEEE/CVF Conference on Computer Visionand Pattern Recognition, pp. 1675216760, 2022a. Myeongho Jeon, Hyoje Lee, Yedarm Seong, and Myungjoo Kang. Learning without prejudices: continualunbiased learning via benign and malignant forgetting.In The Eleventh International Conference onLearning Representations, 2022b. Myeongho Jeon, Myungjoo Kang, and Joonseok Lee. A unified framework for robustness on diverse samplingerrors. In Proceedings of the IEEE/CVF International Conference on Computer Vision, pp. 14641472,2023.",
  "Tero Karras, Timo Aila, Samuli Laine, and Jaakko Lehtinen. Progressive growing of gans for improvedquality, stability, and variation. arXiv preprint arXiv:1710.10196, 2017": "Tero Karras, Samuli Laine, and Timo Aila. A style-based generator architecture for generative adversarialnetworks. In Proceedings of the IEEE/CVF conference on computer vision and pattern recognition, pp.44014410, 2019. Byungju Kim, Hyunwoo Kim, Kyungsu Kim, Sungjin Kim, and Junmo Kim. Learning not to learn: Trainingdeep neural networks with biased data. In Proceedings of the IEEE/CVF conference on computer visionand pattern recognition, pp. 90129020, 2019. Pang Wei Koh, Shiori Sagawa, Henrik Marklund, Sang Michael Xie, Marvin Zhang, Akshay Balsubramani,Weihua Hu, Michihiro Yasunaga, Richard Lanas Phillips, Irena Gao, et al.Wilds: A benchmark ofin-the-wild distribution shifts. In International conference on machine learning, pp. 56375664. PMLR,2021.",
  "Leland McInnes, John Healy, and James Melville. Umap: Uniform manifold approximation and projectionfor dimension reduction. arXiv preprint arXiv:1802.03426, 2018": "John P Miller, Rohan Taori, Aditi Raghunathan, Shiori Sagawa, Pang Wei Koh, Vaishaal Shankar, PercyLiang, Yair Carmon, and Ludwig Schmidt. Accuracy on the line: on the strong correlation between out-of-distribution and in-distribution generalization. In International conference on machine learning, pp.77217735. PMLR, 2021. Hyeonseob Nam, HyunJae Lee, Jongchan Park, Wonjun Yoon, and Donggeun Yoo. Reducing domain gapby reducing style bias. In Proceedings of the IEEE/CVF Conference on Computer Vision and PatternRecognition, pp. 86908699, 2021. Junhyun Nam, Hyuntak Cha, Sungsoo Ahn, Jaeho Lee, and Jinwoo Shin. Learning from failure: De-biasingclassifier from biased classifier. Advances in Neural Information Processing Systems, 33:2067320684, 2020.",
  "OpenAI. Hello gpt-4o. 2024. Accessed: 2024-05-26": "Maxime Oquab, Timothe Darcet, Tho Moutakanni, Huy Vo, Marc Szafraniec, Vasil Khalidov, PierreFernandez, Daniel Haziza, Francisco Massa, Alaaeldin El-Nouby, Mahmoud Assran, Nicolas Ballas, Woj-ciech Galuba, Russell Howes, Po-Yao Huang, Shang-Wen Li, Ishan Misra, Michael Rabbat, Vasu Sharma,Gabriel Synnaeve, Hu Xu, Herv Jegou, Julien Mairal, Patrick Labatut, Armand Joulin, and Piotr Bo-janowski. Dinov2: Learning robust visual features without supervision, 2024. Xingchao Peng, Qinxun Bai, Xide Xia, Zijun Huang, Kate Saenko, and Bo Wang. Moment matching formulti-source domain adaptation. In Proceedings of the IEEE/CVF international conference on computervision, pp. 14061415, 2019. Alec Radford, Jong Wook Kim, Chris Hallacy, Aditya Ramesh, Gabriel Goh, Sandhini Agarwal, GirishSastry, Amanda Askell, Pamela Mishkin, Jack Clark, et al. Learning transferable visual models fromnatural language supervision. In International conference on machine learning, pp. 87488763. PMLR,2021.",
  "Robik Shrestha, Kushal Kafle, and Christopher Kanan. Occamnets: Mitigating dataset bias by favoringsimpler hypotheses. In European Conference on Computer Vision, pp. 702721. Springer, 2022": "Tao Sun, Mattia Segu, Janis Postels, Yuxuan Wang, Luc Van Gool, Bernt Schiele, Federico Tombari, andFisher Yu. Shift: a synthetic driving dataset for continuous multi-task domain adaptation. In Proceedingsof the IEEE/CVF Conference on Computer Vision and Pattern Recognition, pp. 2137121382, 2022. Rohan Taori, Achal Dave, Vaishaal Shankar, Nicholas Carlini, Benjamin Recht, and Ludwig Schmidt. Mea-suring robustness to natural distribution shifts in image classification. Advances in Neural InformationProcessing Systems, 33:1858318599, 2020.",
  "Vladimir Vapnik.Principles of risk minimization for learning theory.Advances in neural informationprocessing systems, 4, 1991": "Hemanth Venkateswara, Jose Eusebio, Shayok Chakraborty, and Sethuraman Panchanathan. Deep hashingnetwork for unsupervised domain adaptation. In Proceedings of the IEEE conference on computer visionand pattern recognition, pp. 50185027, 2017. Riccardo Volpi, Hongseok Namkoong, Ozan Sener, John C Duchi, Vittorio Murino, and Silvio Savarese. Gen-eralizing to unseen domains via adversarial data augmentation. Advances in neural information processingsystems, 31, 2018. Zijian Wang, Yadan Luo, Ruihong Qiu, Zi Huang, and Mahsa Baktashmotlagh. Learning to diversify forsingle domain generalization. In Proceedings of the IEEE/CVF International Conference on ComputerVision, pp. 834843, 2021. Florian Wenzel, Andrea Dittadi, Peter Gehler, Carl-Johann Simon-Gabriel, Max Horn, Dominik Zietlow,David Kernert, Chris Russell, Thomas Brox, Bernt Schiele, et al. Assaying out-of-distribution generaliza-tion in transfer learning. Advances in Neural Information Processing Systems, 35:71817198, 2022. Olivia Wiles, Sven Gowal, Florian Stimberg, Sylvestre Alvise-Rebuffi, Ira Ktena, Krishnamurthy Dvijotham,and Taylan Cemgil. A fine-grained analysis on distribution shift. arXiv preprint arXiv:2110.11328, 2021. Olivia Wiles, Sven Gowal, Florian Stimberg, Sylvestre-Alvise Rebuffi, Ira Ktena, Krishnamurthy Dj Dvi-jotham, and Ali Taylan Cemgil. A fine-grained analysis on distribution shift. In International Conferenceon Learning Representations, 2022. URL",
  "Shen Yan, Huan Song, Nanxiang Li, Lincan Zou, and Liu Ren. Improve unsupervised domain adaptationwith mixup training. arXiv preprint arXiv:2001.00677, 2020": "Huaxiu Yao, Caroline Choi, Bochuan Cao, Yoonho Lee, Pang Wei W Koh, and Chelsea Finn. Wild-time: Abenchmark of in-the-wild distribution shift over time. Advances in Neural Information Processing Systems,35:1030910324, 2022. Nanyang Ye, Kaican Li, Haoyue Bai, Runpeng Yu, Lanqing Hong, Fengwei Zhou, Zhenguo Li, and JunZhu. Ood-bench: Quantifying and understanding two dimensions of out-of-distribution generalization. InProceedings of the IEEE/CVF Conference on Computer Vision and Pattern Recognition, pp. 79477958,2022.",
  "A.1Setup for Controlled Distribution Shifts": "We utilize multi-attribute datasets such as dSprites, Shapes3D, SmallNorb, CelebA, and DeepFashionto develop ConDS. These datasets enable us to sample images annotated with various attributes, showcasinga range of DSs from SC to (SC, LDD, UDS). Additionally, we configure different attributes for each type ofDS. For instance, in SC, pairs like (y, yl) and (yl, y) may exhibit spurious correlations. By covering allpossible attribute combinations (with the attributes depicted in ), we ensure a more comprehensiveevaluation of scenarios. For UniDS, we choose one attribute from three options, yielding three settings. In ConDS, we address twocombinations: (SC, LDD), (SC, UDS), and (LDD, UDS). For each combination, one attribute is selectedfor the first DS and another for the second, following a 3C2 selection method.For the three-attributecombination in ConDS, namely (SC, LDD, UDS), one attribute is chosen for the first DS, another for thesecond, and the remaining for the last DS, in line with a 3C3 approach. With five datasets in a controlledsetup, this generates a total of 165 (source, target) pairs.",
  "Additionally, we detail the method used to introduce distribution shifts in the original datasets as follows:": "dSprites: There are no predefined splits, such as train, validation, or test, in the dSprites dataset;it contains only images and their attribute information. We first created train and test pools byrandomly splitting the images, then sampled from each pool to introduce distribution shifts. For theobject size attribute, we used the attribute values [0.8, 0.9, 1], labeling them as small, medium, andlarge, respectively. Since the original dataset is grayscale, we applied our own colorization: Objectcolors include red (255, 0, 0), yellow (255, 255, 0), and blue (0, 0, 255), while background colors are setas orange (255, 153, 51), green (0, 153, 0), and purple (102, 0, 255). We allocated 20% of the trainingset as the validation set for parameter tuning, ensuring that both share the same distribution. Shapes3D: There are no predefined splits, such as train, validation, or test, in the Shapes3Ddataset; it contains only images and their attribute information. For the object size attribute, weused the attribute values [0.75, 0.964, 1.036, 1.179], labeling them as tiny, small, medium, and large,respectively. We used [0, 0.1, 0.2, 0.3] for object color and [0, 0.1, 0.2, 0.3] for background color. Foreach unique combination of labels and attributes, we divided the data instances into training andtesting sets. We allocated 20% of the training set as the validation set for parameter tuning, ensuringthat both share the same distribution.",
  "SmallNorb:We used the original train-test split provided by SmallNorb, selecting elevations": ", azimuths , and lighting conditions . To ensure consistencyacross categories, we manually adjusted the azimuth values for all animal categories, as their initialstarting points (0) differed. We allocated 20% of the training set as the validation set for parametertuning, ensuring that both share the same distribution. CelebA: Using all samples in the dataset, we first selected the attributes Black_Hair, Smiling, andStraight_Hair. We then split each combination of these attributes into training and testing sets.The training set was used to create distribution shifts, while all test splits were combined to forma uniform distribution. These three attributes were chosen because they provide sufficient samplesto accommodate distribution shifts. We allocated 15% of the training set as the validation set forparameter tuning, ensuring that both share the same distribution. DeepFashion: Using all samples in the dataset, we first selected the attributes texture {floral,solid}, shape {mini_length, no_dress}, and style {chiffon, cotton}. We then split each combinationof these attributes into training and testing sets. The training set was used to create distributionshifts, while all test splits were combined to form a uniform distribution. These three attributes werechosen because they provide sufficient samples to accommodate distribution shifts. We allocated20% of the training set as the validation set for parameter tuning, ensuring that both share the samedistribution.",
  "A.3Synthetic and Real-world Datasets": "We can precisely manage distribution shifts with synthetic datasets because they allow for complete control.Real-world datasets, on the other hand, offer the advantage of realism but may experience uncontrolleddistribution shifts. For instance, suppose we create a gender classifier with a dataset that exhibits a spuriouscorrelation by sampling images of older females and younger males. Despite our efforts, we cannot ensureuniformity across other attributes such as skin tone and gender. Given the advantages and disadvantages ofeach, we conducted experiments with a variety of synthetic datasets (Dsprites, Shapes3D, Smallnorb)and realistic datasets (CelebA, DeepFashion, iWildCam, fMoW, Camelyon17).",
  "A.6Implementation Details": "To generate all the results reported in this script, we fine-tuned the hyperparameters. For the controlleddatasets, we adopt early stopping where training stops early once the patience limit is reached. Validationaccuracy is measured every 100 iterations and one patience is consumed if the best validation accuracy doesnot improve. The specific values are detailed in and . We conducted a grid search with theseparameters to optimize results for each algorithm across all DSs and datasets.",
  "B.6Fine-tuned Open Source Foundation Model": "We observe in that the zero-shot performance of foundation models is constrained when appliedto real-world datasets. Our evaluation on real-world datasets like Camelyon17, which contains complex cellimages, iWildCam with its camera trap images of diverse animal species, and FMoWs satellite images presentunique challenges due to their niche content and visual complexity. This high level of domain specificity, withfeatures likely outside the foundation models general scope, limits their capacity to generalize effectively,particularly in zero-shot settings. An intuitive approach to evaluate this is by fine-tuning the vision encoder on these specialized datasets.Through fine-tuning with LoRA Hu et al. (2022), we found that the foundation models performed as expected,showing high effectiveness for these datasets. The results are presented in .",
  "B.7Visualization on Invariant Feature Learning": "We investigate feature invariance with respect to labels and attributes using the CelebA dataset.UMAP (McInnes et al., 2018) is utilized for visualization. illustrates the feature space of thebest and worst-performing algorithms, while compares learning from scratch with pre-training.While all the algorithms demonstrate invariance to LDD and UDS, ViT exhibits sensitivity to SC. In contrast,both CLIP-Large and ImageNet remain invariant to all DSs. In , the ViT model with pre-trainingexhibits better invariance to attributes compared to the ViT model trained from scratch.",
  "B.8Generation of Attributes with Augmentations": "Our framework requires datasets with rich attribute annotations to create ConDS. However, such datasetsare limited as annotations are expensive. We did consider using augmentations to create additional attribu-tions, but augmentation techniques in algorithm baselines might directly address these shifts in this setting.However, for the rebuttal, we applied three types of corruptions from ImageNet-C (Hendrycks & Dietterich,2018)impulse noise, snow, and elastic transformon CelebA. Each attribute was evaluated under twoconditions (corrupted and uncorrupted). Figures 23 and 24 exhibit the evaluation results with this setup.",
  "B.9Results for Distribution Shift Generated by Clustering": "We leverage DINOv2 (Oquab et al., 2024) to extract rich image features, using the resulting feature clustersas proxies for DSs.The motivation behind this approach aligns with that of Section B.8, namely, thenecessity for a scalable method to simulate DSs without depending on costly and labor-intensive attributeannotations. As displayed in , we group image features into six clusters based on their embeddingsfrom DINOv2 and treat these clusters as distinct distributions. Figures 25 and 26 exhibit the evaluationresults with this setup.",
  "Phi-3.5-vision57712623": ": Performance comparison of different methods across categories, showing time (inseconds) and memory usage (in MiB). Training was performed with a batch size of 128 on a single H100GPU. LVLM models are fine-tuned using LoRA for . For LLaVA-1.5, due to memory constraintson a single H100, multi-GPU training was used with two H100s, each handling a batch size of 64, and thetotal memory usage was combined."
}