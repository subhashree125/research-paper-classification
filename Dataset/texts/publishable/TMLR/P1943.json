{
  "Abstract": "The utilization of deep learning on electrocardiogram (ECG) analysis has brought the ad-vanced accuracy and efficiency of cardiac healthcare diagnostics. In this work, we address acritical challenge in the field of ECG analysis with deep learning: learning robust represen-tation without large-scale labeled datasets. We propose ECG Semantic Integrator (ESI), anovel multimodal contrastive pretraining framework that jointly learns from ECG signalsand associated textual descriptions. ESI employs a dual objective function that comprisesa contrastive loss and a captioning loss to develop representations of ECG data. To createa sufficiently large and diverse training dataset, we develop a retrieval-augmented genera-tion (RAG)-based Large Language Model (LLM) pipeline, called Cardio Query Assistant(CQA). This pipeline is designed to generate detailed textual descriptions for ECGs fromdiverse databases. The generated text includes information about demographics and wave-form patterns. This approach enables us to compile a large-scale multimodal dataset withover 660,000 ECG-text pairs for pretraining ESI, which then learns robust and generaliz-able representations of 12-lead ECG. We validate our approach through various downstreamtasks, including arrhythmia detection and ECG-based subject identification. Our experi-mental results demonstrate substantial improvements over strong baselines in these tasks.These baselines encompass supervised and self-supervised learning methods, as well as priormultimodal pretraining approaches. Our work shows the potential of combining multimodalpretraining to improve the analysis of ECG signals.",
  "Introduction": "The electrocardiogram (ECG), which provides a non-invasive and comprehensive view of the hearts electricalactivity, is an important tool in cardiovascular diagnostics and clinical decision-making(Kligfield et al., 2007).For example, ECG has been extensively used in various clinical scenarios, such as diagnosing cardiovasculardiseases (Jain et al., 2014), obstructive sleep apnea (Faust et al., 2016), and Parkinsons disease (Haapaniemiet al., 2001), etc. On the other hand, the rapid development of deep learning has triggered general interest inECG data analysis using data-driven approaches. These deep learning methods, recognized for their abilityto learn complex representations, have been proven highly effective in enhancing the accuracy and predictive",
  "Published in Transactions on Machine Learning Research (10/2024)": "Patrick Wagner, Nils Strodthoff, Ralf-Dieter Bousseljot, Dieter Kreiseler, Fatima I Lunze, Wojciech Samek,and Tobias Schaeffter. Ptb-xl, a large publicly available electrocardiography dataset. Scientific data, 7(1):154, 2020. Zhongwei Wan, Che Liu, Mi Zhang, Jie Fu, Benyou Wang, Sibo Cheng, Lei Ma, Csar Quilodrn-Casas, andRossella Arcucci. Med-unic: Unifying cross-lingual medical vision-language pre-training by diminishingbias. Advances in Neural Information Processing Systems, 36, 2024. Peng Wang, An Yang, Rui Men, Junyang Lin, Shuai Bai, Zhikang Li, Jianxin Ma, Chang Zhou, JingrenZhou, and Hongxia Yang. Ofa: Unifying architectures, tasks, and modalities through a simple sequence-to-sequence learning framework. In International Conference on Machine Learning, pp. 2331823340. PMLR,2022.",
  "Supervised Methods": "Deep learning applications in ECG diagnosis have drawn significant attention (Liu et al., 2021; Pyakillyaet al., 2017; Sannino & De Pietro, 2018; Wagner et al., 2020; migiel et al., 2021; Mostafa et al., 2019). Forinstance, migiel et al. (2021) proposed a CNN model with additional entropy-based features for arrhythmiaclassification. Their method achieves an AUC score of 0.91 across five classes. Mostafa et al. (2019) conducteda comprehensive review of deep learning applications in ECG analysis for sleep apnea detection.Theyhighlighted the success of models such as CNNs and recurrent neural networks (RNNs), which achieve over90% accuracy on specialized datasets. Despite the proven effectiveness of these methods, the acquisition ofclinical annotations required for these methods is often expensive.",
  "Unimodal Representation Learning in ECG": "Given the expensive nature of clinical annotations, there has been a growing interest in pretraining methodsdesigned to reduce reliance on labeled ECG sequences (Sarkar & Etemad, 2020; Mehari & Strodthoff, 2022;Oh et al., 2022). For example, Mehari & Strodthoff (2022) applied well-known SSL frameworks such asSimCLR (Chen et al., 2020), BYOL (Grill et al., 2020), and CPC (Oord et al., 2018) to pretrain models on12-lead ECG data. These models showed enhanced robustness, reflected in a 2% increase in AUC score for5-class arrhythmia classification compared to purely supervised models. However, even though pretrainingstrategies generally provide insights into performance improvement and decrease reliance on labeled data,these methods are often limited by their focus solely on signal waveforms.The emphasis on waveformalone does not ensure the capture of clinically relevant semantic information. As a result, a multimodalapproach incorporating both ECG waveforms and corresponding clinical text helps acquire more meaningfuland transferable ECG representations for various downstream tasks.",
  "Multimodal Representation Learning in ECG": "Although few, some studies have begun to explore the alignment of ECG signals with other modalities suchas textual descriptions, EHR, and clinical notes (Li et al., 2023a; Lalam et al., 2023; Liu et al., 2024). Forinstance, Lalam et al. (2023) utilized identical encoders to extract and contrastively align embeddings fromECG, EHR, and clinical notes. The pretrained model showed promising results in clinical diagnosis. Liu et al.(2024) adopted a similar approach to couple ECG signals with clinical notes and enhanced the ECG encoders",
  "Description": ": The Cardio Query Assistant (CQA) Framework employs a novel knowledge-based approach togenerate detailed and clinically relevant textual descriptions for ECG signals, which translates ECG condi-tions into enriched ECG waveform patterns. effectiveness in zero-shot arrhythmia detection. However, the pretraining processes of these methods dependon costly annotations such as clinical notes and EHR, which are challenging to acquire on a large scale.Moreover, the variability in textual descriptions or reports associated with ECGs due to differences in detail,terminology, and style among clinicians and clinical contexts may complicate the learning of consistentmappings between ECG signals and text. The consequent variability could lead to misalignments betweenthe ECG-text pairs. In this study, we propose to utilize a retrieval-augmented generation (RAG)-basedpipeline to construct contextual ECG textual data without relying on costly notes and EHRs. Additionally,we introduce a captioning task in our model to achieve more nuanced representations.",
  "Cardio Query Assistant (CQA) Framework": "The Cardio Query Assistant (CQA) Framework, as shown in , is designed to transform ECG con-dition labels into detailed descriptive text. The generated text incorporates demographic information, ECGconditions, and enriched waveform details. An example of a raw ECG signal, its associated metadata, andthe generated ECG waveform description is provided in . The developed CQA is outlined as follows:",
  "Establishing a Domain-Specific Knowledge Database": "To leverage the enhanced interpretation of ECG conditions with domain expertise, we develop a comprehen-sive vector database from domain-specific literature of authoritative medical texts guided by two textbooks:(1) ECG Workout: Exercises In Arrhythmia Interpretation by Huff (2006), and (2) 12-Lead ECG: The Artof Interpretation by Garcia (2015). To extract and encode this information into a usable format, we employthe text-embedding-ada-002 API (OpenAI, 2023) because of its efficiency and performance. The resultingembeddings are then systematically organized using the Chroma database management tool, which waschosen for its robustness and ease of integration with the LangChain Python library (Mendable, 2023).",
  "Contrastive Loss": "Cross-ModalityDecoderCaptioning Loss : The ECG Semantics Integrator (ESI) is built based on an ECG signal encoder with a text encoderusing captioning and contrastive losses for unified representations. This architecture learns from the align-ments between detailed textual prompts and the corresponding ECG waveform data, which aims to capturenuanced clinical insights for enhanced diagnostic tasks.",
  "Multimodal Contrastive Captioning with ECG Semantics Integrator (ESI) Framework": "The ESI framework aims to improve the quality of representation extracted from ECG signals by pretraininga specialized ECG encoder alongside a textual encoder. This dual-modality training method has been provenby cutting-edge studies in contrastive language-image pretraining (CLIP) (Radford et al., 2021) and CoCa(Yu et al., 2022b) methodology. Inspired by these two studies, we developed our pretraining architecture withboth contrastive and generative objectives. While we recognize there are newer approaches in multimodalcontrastive learning beyond CLIP and CoCa as discussed in .1, the choice of development can bemotivated by several factors. First, the CLIP structure is well-proven by multiple prior works, includingpretraining language with medical images (Liu et al., 2023; You et al., 2023; Wan et al., 2024) and physio-logical signals (Li et al., 2023a; Lalam et al., 2023; Liu et al., 2024). The core contrastive objective of CLIPis well-suited for our primary goal of aligning ECG signals with their textual interpretations. Moreover, therelative simplicity of the CLIP architecture allows for seamless integration of our captioning loss inspired byCoCa (Yu et al., 2022b). We further validate the contribution of the contrastive and generative objectivevia ablation study as shown in .1. For the ECG encoder, we have chosen a one-dimensional modified version of the ConvNext v2 architectureconsidering the sequential nature of ECG waveform data (Woo et al., 2023), which has been proven for itscapacities of extracting both local and global contexts with the designed convolutional kernels. In parallel,the textual encoder utilizes BioLinkBERT, a derivative of the BERT architecture pretrained on biomedicaltexts, to effectively embed medical terminologies (Yasunaga et al., 2022). BioLinkBERT is an extensionof the standard BERT model (Devlin et al., 2018), specifically designed to improve the understanding ofbiomedical texts. Unlike traditional BERT, which processes each document independently, BioLinkBERTis pretrained on biomedical literature from PubMed, which takes advantage of the natural links betweendocuments such as citations and references. This pretraining strategy motivates us to leverage BioLinkBertfor tasks that require a deep understanding of biomedical concepts and terminology.",
  "Multimodal Contrastive Learning": "Inspired by the previous vision language pretraining approaches (Radford et al., 2021; Yu et al., 2022b), ourframework uses two pretraining objectives for comprehensive learning, including contrastive loss for robustrepresentation learning and captioning loss for semantic alignment. Contrastive Loss: We employ the dual-encoder contrastive learning framework following the prior studies.Compared to pretraining with single-encoder as signal-focused frameworks, e.g., SimCLR (Chen et al., 2020)and BYOL (Grill et al., 2020), the dual-encoder approach in this study leverages the semantic informationfrom the textual modality. Both encoders aim to project the inputting ECG and text into a unified embeddingspace. Consequently, the two encoders are jointly optimized by contrasting the paired text against others inthe sampled batch:",
  "),": "with Si and Ti representing the normalized embeddings from the ECG signal and text encoders for thei-th ECG-text pair, N is the batch size during training, and as the temperature scaling factor. Thisdual-encoder approach has been working promisingly on enabling cross-modal alignment applications suchas zero-shot classification (Radford et al., 2021; Yu et al., 2022b). Captioning Loss: While the dual-encoder approach encodes the text as an embedding for the contrastivelearning purpose, the generative approach aims for detailed granularity and requires the model to predictthe exact tokenized texts with ECG and preceding texts. This approach encourages the encoders to capturethe semantic information embedded in the texts actively. Inspired by the image-text multimodal pretrainingstudy CoCa (Yu et al., 2022b), we design to align the generated textual descriptions with the correspondingECG signals by additionally defining a captioning loss Lcap similar to that used in image captioning tasks(Vinyals et al., 2015):",
  "L = Con LCon + Cap LCap": "where Con and Cap are the loss weighting hyperparameters for the introduced objectives. We set thesetwo weighting parameters equally to 1 in this study. By jointly optimizing these losses, the ESI Frameworkaims to learn a multimodal representation that enriches the semantic link between ECG waveforms andtheir textual explanations. This method is anticipated to improve performances in downstream tasks thatleverage the waveform details and demographics, such as diagnosing arrhythmia and performing large-scalepatient identification using ECG data.",
  "Evaluation": "In this section, we describe our evaluation settings and experimental results. We first introduce the informa-tion on the datasets used and tasks performed in this study, along with the baseline methods we used in thecomparisons. Our experiments explore three settings: zero-shot learning, linear probing (frozen features),and fine-tuning. In our experiments, we conduct multiple resampling runs to assess the robustness of themodel, particularly for the linear probing and fine-tuning settings. Given that the encoder is frozen duringlinear probing evaluations, the randomness is only applied to the output linear heads during the linear prob-ing setup. For each setting, we average the results over five different runs and report the standard deviationsalongside the mean performance metrics.",
  "Training Setup": "Pretraining Datasets. The proposed ESI signal encoder is pretrained from scratch. Therefore, the pre-training dataset directly impacts the models generalizability. We constructed a large pretraining set combin-ing three large-scale datasets with over 650,000 ECG-text training pairs. These datasets covers Chapman-Shaoxing (Zheng et al., 2020), PTB-XL (Wagner et al., 2020), and MIMIC-ECG (Gow et al., 2023). Eachdataset contains 12-lead and 10-second ECG recordings sampled at 500 Hz. Here is a detailed breakdown ofeach dataset: PTB-XL: This dataset consists of 21,837 12-lead, 10-second ECG recordings from 18,885 partici-pants. We followed the training and test data split guidelines outlined in the original publication(Wagner et al., 2020) and only used the training samples (17k) in the pretraining task.Thesesamples include demographic data and SCP codes.",
  "The variety and volume of data provide a comprehensive foundation for the pretraining of models. summarizes the overview information of each dataset used in pretraining": "Implementation. During the pretraining phase of the ESI model, we make specific choices regarding theencoder architectures, optimizer, learning rate scheduler, training hardware, and batch size. The ECG signalencoder within ESI utilizes a 1D ConvNeXt-base (Woo et al., 2023) backbone as the default architecture.This choice allows the model to effectively capture the spatial features within the ECG signal data. For textencoding, we leverage BioLinkBert (Yasunaga et al., 2022) as the default due to its proven capabilities inhandling biomedical text data. The AdamW optimizer is employed for optimization during the pretrainingprocess. We opted for an initial learning rate of 5 105 to facilitate efficient convergence. To furtheradjust the learning rate throughout training, a warm-up phase of 5 epochs out of the total 30 epochs isimplemented. This warm-up phase allows the model to gradually adjust to the training data before applyingthe main learning rate. Additionally, a learning rate decay of 0.1 is introduced after every 10 epochs toprevent overfitting in the later stages of training. The pretraining process is conducted on a server equipped with 4 Nvidia A100 GPUs.This hardwareconfiguration provides the computational resources necessary to handle the large datasets used for pretrainingefficiently. To leverage the capabilities of these GPUs effectively, a batch size of 48 samples is used on eachGPU during training. In addition to the main ESI model, we implement a parameter-efficient variant named ESI-tiny. This variantutilizes a ConvNeXt-tiny architecture as the ECG encoder, which pretrains a model with a smaller overallsize. This can be beneficial in scenarios where computational resources are limited.",
  "ECG Semantics Integrator (ESI) For Downstream Tasks": "After the pretraining stage, the encoder can be applied in three different manners, including zero-shotinference, linear probing, and fine-tuning on various downstream tasks. The aim is to validate the robustnessof the learned representations and the practical utility of the model in real-world clinical settings. Whilethe zero-shot inference and linear probing can directly assess the representations of the learned framework,the fine-tuned models usually provide the best performances among these three methods, with updatingparameters through downstream tasks. As shown in , the fine-tuned encoder from our ESI methodoutperforms the supervised and self-supervised baselines for different downstream tasks.",
  "Zero-Shot Evaluation": "Zero-shot evaluation assesses the models capacity to understand and infer information from ECG signalswithout any task-specific fine-tuning. Following the definition used in the context of CoCa (Yu et al., 2022b)and CLIP (Radford et al., 2021), our zero-shot evaluation strategy ensures that while the model has beenexposed to a vast array of ECG and text pairs during pretraining, it has not seen any supervised examplesfrom the downstream tasks. In the ESI Framework, each ECG signals embedding is compared against arange of possible textual labels for different cardiac conditions without task-specific fine-tuning. The modelselects the textual description that has the closest embedding distance to the ECG signals embedding,which is determined by a similarity metric of cosine similarity.This process demonstrates the modelsunderstanding of ECG data and its ability to correlate it with accurate clinical descriptions directly afterpretraining, which aims to demonstrate the potential generalizability of the learned representations withoutfine-tuning the specific tasks.",
  "Linear Probing": "Linear probing is a strategy that makes use of the representations learned by the ESI Frameworks encoders.In this setup, a linear classifier is utilized on top of the frozen encoders for different downstream tasks suchas arrhythmia detection and patient identification. As the only trainable part of the model is the classifierhead, thus, the quality and robustness of the representations from the pretrained encoder play an essentialrole in the linear probing strategy.",
  "Fine-Tuning": "To introduce more flexibility into the pretrained signal encoder, we can also fine-tune the entire framework ona set of downstream tasks. Similar to the linear probing strategy but with trainable encoders, this fine-tuningstrategy aims to explore the full effectiveness of the structure with pretrained parameters as its initializationfor downstream tasks.",
  "Downstream Task: Arrhythmia Diagnosis": "Cardiac arrhythmias are a significant contributor to cardiovascular diseases, and there is a demand foraccurate and reliable detection methods for clinical use. We evaluated our proposed method on arrhythmiadetection using two datasets, PTB-XL (Wagner et al., 2020) and ICBEB (Liu et al., 2018). As described in.1, we follow the training and test data split guidelines outlined in the original PTB-XL publication(Wagner et al., 2020) to divide the PTB-XL dataset. The training set is used for fine-tuning the model andthe test set, which is not seen during the pretraining, is used for evaluation. The ICBEB dataset, which is notused during the pretraining, consists of 9,831 12-lead ECG signals from 9,458 patients (Liu et al., 2018). Weadopt the processing settings from a prior benchmark study (Strodthoff et al., 2020), which results in 6,877training samples and 2,954 test samples. Based on this configuration, we evaluate the models effectivenessacross three settings, including fine-tuning, linear probing, and zero-shot learning.",
  "Fine-tuning & Linear Probing": "To perform a comprehensive evaluation, we compare our proposed method with specialized supervised meth-ods, including a long short-term memory (LSTM), XResNet101, ResNet50, ensemble methods implementedin an ECG benchmark study (Strodthoff et al., 2020), a multi-lead-branch fusion network (MLBF-Net)(Zhang et al., 2021), and a multi-view multi-scale neural network (MVMSN) (Yang et al., 2023). Besidesthe supervised learning methods, we also cover the comparison between our method and signal-focused SSLmethods including SimCLR (Chen et al., 2020), BYOL (Grill et al., 2020), CLOCS (Kiyasseh et al., 2021),and LEAVES (Yu et al., 2022a). The deep learning backbone used for training these methods is ConvNeXt-base, the same as the proposed ESI, to ensure fair comparisons. We perform both the linear probing andfine-tuning strategies for those pretrained methods to assess the quality of learned representations duringthe pretraining phase. Additionally, we benchmark against MERL (Liu et al., 2024) under a frozen encodersetting as presented in their study. shows the performances of the evaluated methods. In the supervised learning methods, the ConvNeXtand ConvNeXt-tiny encoders show lower performance compared to specialized methods such as MLBF-Netand MVMSN. ConvNeXt-tiny outperforms the larger ConvNeXt model, potentially due to overfitting withthe smaller dataset. After pretraining, the ConvNeXt-based ESI method achieves the best performance onboth PTB-XL and ICBEB datasets under both the frozen encoder and fine-tuning settings. Notably, the mul-timodal pretraining methods (ESI and MERL) significantly outperformed the signal-focused methods suchas SimCLR and BYOL. This supports our hypothesis that signal-focused approaches may have limitationsin learning robust and transferable representations for downstream tasks compared to the multimodal pre-training methods. The superior performance of the pretrained ESI encoder compared to the frozen encoderin supervised learning approaches also demonstrates the robustness of the learned features for arrhythmiadiagnosis.",
  "MethodsPTB-XL (AUC )ICBEB (AUC )": "(Supervised)LSTM (Strodthoff et al., 2020)0.9270.0130.9640.015XResNet101 (Strodthoff et al., 2020)0.9280.0130.9740.013ResNet50 (Strodthoff et al., 2020)0.9300.0150.9690.015Ensemble (Strodthoff et al., 2020)0.9340.0130.9750.013MLBF-Net (Zhang et al., 2021)0.9310.021-MVMSN (Yang et al., 2023)0.933--ConvNeXt-Tiny (Woo et al., 2023)0.9180.0160.9700.012ConvNeXt-Base (Woo et al., 2023)0.9140.0140.9700.012 (Linear Probing)SimCLR (Chen et al., 2020)0.7660.0160.7910.012BYOL (Grill et al., 2020)0.7760.0140.8000.014CLOCS (Kiyasseh et al., 2021)0.7770.0120.8020.015LEAVES (Yu et al., 2022a)0.7920.0150.8090.013MERL (Liu et al., 2024)0.887--(Ours) ESI-tiny0.9270.0090.9750.006(Ours) ESI0.9310.0080.9780.006 (Fine-tune)SimCLR (Chen et al., 2020)0.9160.0150.9680.016BYOL (Grill et al., 2020)0.9250.0140.9710.014CLOCS (Kiyasseh et al., 2021)0.9180.0130.9770.012CRT (Zhang et al., 2022)0.892--LEAVES (Yu et al., 2022a)0.9260.0120.9760.013(Ours) ESI-tiny0.9350.0110.9780.010(Ours) ESI0.9380.0110.9820.009",
  "Zero-shot Inference": "To further assess the learned representations during pretraining, we also evaluate the zero-shot learninginference assessment following METS (Li et al., 2023a) and MERL (Liu et al., 2024).Other than thezero-shot evaluations, we include the few-shot setting of the existing signal-focused SSL approaches in thecomparison, including SimCLR (Chen et al., 2020), BYOL (Grill et al., 2020), CLOCS (Kiyasseh et al.,2021), and LEAVES (Yu et al., 2022a), with 5% of the original training set as training samples on PTB-XLdataset. demonstrates the zero-shot learning inference performance of the proposed ESI method along-side baselines (METS, MERL) and the few-shot fine-tuning results for signal-centered SSL methods. Ourproposed method achieves the best performance on both AUC and macro F1 scores compared to all othermethods. Additionally, ECG-text pretrained models generally outperformed signal-focused pretraining meth-ods even without samples in fine-tuning. This highlights the improved robustness of representations frommultimodal pretraining techniques.",
  "Downstream Task: ECG-based User Identification": "ECG generally shows unique patterns that can distinguish individuals, which makes them suitable for subjectidentification tasks and offers potential advantages over other biometric traits (Melzi et al., 2023).Forexample, compared to identifying persons with facial images, using ECG can further protect users privacyduring usage. In this study, we leverage the PTB-XL (Wagner et al., 2020) and ICBEB (Liu et al., 2018)datasets, also used in the arrhythmia diagnosis task, to design a one-shot learning benchmark for ECG",
  "MethodAUC F1-macro": "SimCLR (Chen et al., 2020) - 5%0.7350.547BYOL (Grill et al., 2020) - 5%0.7520.564CLOCS (Kiyasseh et al., 2021) - 5%0.7650.581LEAVES (Yu et al., 2022a) - 5%0.7600.577METS (Li et al., 2023a) - 0%-0.593MERL (Liu et al., 2024) - 0%0.757-(Ours) ESI - 0%0.8120.654 identification. Similar to the arrhythmia diagnosis task in .3, we focus solely on the test splits ofthe PTB-XL and ICBEB datasets. For PTB-XL, we select 5-second signal sequences from each of the 1907subjects for both training and testing, which results in a 1907-class classification task. Similarly, we select4-second samples and classes from the ICBEB dataset, which forms a 689-class classification task. In this task, we compare the performance of the proposed ESI method with various approaches under linearprobing and fine-tuning settings. For the specialized supervised methods, we compared our method withestablished supervised learners, including LSTM, XResNet101, ResNet50, and ensemble methods (Strodthoffet al., 2020). Besides the supervised learning methods, we also evaluated the ESI method against signal-focused SSL approaches including SimCLR (Chen et al., 2020), BYOL (Grill et al., 2020), CLOCS (Kiyassehet al., 2021), and LEAVES (Yu et al., 2022a) under the linear probing and fine-tuning settings. Due to thepatient de-identification during pretraining, we cannot perform zero-shot learning for this identification task,as the model has not been exposed to identifiable patient information. summarizes the findings. The results demonstrate that the ESI method significantly outperformsthe baselines in both linear probing and fine-tuning settings. Notably, the fine-tuned ESI method achievesa substantial accuracy improvement (12.0% and 12.2% on PTB-XL and ICBEB, respectively) compared tothe supervised ConvNeXt baselines. Additionally, in linear probing, ESI surpasses the signal-focused SSLmethods by a significant margin. These findings highlight the effectiveness of multimodal pretraining withECG and text data in learning transferable representations for ECG identification.",
  "Discussion": "In this section, we first discuss the ablations on the designed components, including the effectiveness of CQA,the selections of the signal encoder, as well as the contributions from captioning loss and contrastive loss tothe learned representations. The experiments for ablations are mostly conducted on a tiny model variantas ESI-tiny with the ConvNeXt-tiny signal backbone. We also explore the impact of the size of pretrainingdata as well as the potential misalignment to the proposed method.",
  "Ablation Study: Component Analysis and Impact": "We conduct ablation experiments to assess the contributions of individual components within the pretrainingframework. We evaluate the pretrained models performance on both arrhythmia diagnosis and ECG-baseduser identification tasks using the PTB-XL dataset with the ESI-tiny variant featuring a ConvNeXt-tinysignal encoder. The model is evaluated under a linear probing setting with frozen encoders, and the AUCscore serves as the primary metric. The results of this ablation study are summarized in (a). Removing the Contrastive Question Answer-ing (CQA) module results in a decrease in AUC scores for both tasks. This indicates that CQA contributesto aligning ECG signals with their enriched text annotations. By aligning these modalities, CQA helps the",
  "AUC ACC AUC ACC": "(Supervised)LSTM (Strodthoff et al., 2020)0.9070.0140.4440.0120.9180.0110.6100.011XResNet101 (Strodthoff et al., 2020)0.9150.0110.4730.0150.9210.0170.6230.020ResNet50 (Strodthoff et al., 2020)0.9260.0160.4970.0210.9330.0130.6410.015Ensemble (Strodthoff et al., 2020)0.9300.0110.5000.0150.9370.0130.6530.016ConvNeXt-Tiny (Woo et al., 2023)0.9180.0140.4800.0180.9360.0140.6470.016ConvNeXt-Base (Woo et al., 2023)0.9220.0130.4940.0210.9320.0130.6490.015 (Linear Probing)SimCLR (Chen et al., 2020)0.8060.0220.1850.0330.8380.0190.2520.021BYOL (Grill et al., 2020)0.8370.0190.2400.0270.8550.0190.2830.035CLOCS (Kiyasseh et al., 2021)0.8220.0220.2070.0360.8410.0200.2350.037LEAVES (Yu et al., 2022a)0.8400.0170.2480.0290.8530.0220.2750.029(Ours) ESI-tiny0.9230.0140.5100.0170.9370.0120.6540.016(Ours) ESI0.9270.0110.5170.0140.9440.0100.6650.012 (Fine-tune)SimCLR (Chen et al., 2020)0.9360.0110.5220.0140.9450.0120.6730.015BYOL (Grill et al., 2020)0.9420.0110.5470.0140.9510.0130.6860.012CLOCS (Kiyasseh et al., 2021)0.9290.0090.5160.0100.9400.0110.6660.010LEAVES (Yu et al., 2022a)0.9440.0110.5500.0130.9530.0090.6880.015(Ours) ESI-tiny0.9660.0100.5910.0140.9800.0070.7470.012(Ours) ESI0.9700.0090.6080.0130.9850.0080.7620.010",
  "diff 0.0160.0090.015 0.010 0.006 0.003": "model learn more robust representations that capture the inherent relationships between ECG patterns andassociated diagnoses. Ablating the captioning loss LCap also leads to a performance decline on both arrhyth-mia diagnosis and ECG identification, which suggests that the model benefits from explicitly generatingcaptions during pretraining. The most substantial impact on performance is observed when removing thecontrastive loss LCon. By contrasting ECG with different textual representations, the model is encouragedto identify subtle variations that are relevant to downstream tasks.",
  "Ablation Study: Impact of Pre-Training with MIMIC-IV-ECG Only": "As the MIMIC-IV-ECG data is the single dataset that contains the most ECG samples used in pretrainingour ESI models, to investigate the impact of using only the MIMIC-IV-ECG dataset for pre-training, weconducted an experiment where the model was pre-trained exclusively on MIMIC-IV-ECG. We then eval-uated the models performance on the PTB-XL and ICBEB datasets, focusing on three tasks: arrhythmiadetection (both linear probing and zero-shot) and subject identification (linear probing). presents the performance results across these tasks. The results indicate that pre-training on thefull dataset yields better performance across all tasks and datasets compared to pre-training exclusively onMIMIC-IV-ECG. Specifically, there is a noticeable improvement in both arrhythmia detection and subjectidentification tasks when additional datasets are included in the pre-training process. For the arrhythmiadetection task, the difference in performance is more substantial in the zero-shot setting, where the modelpre-trained on all datasets achieves an improvement of 0.015 in PTB-XL and 0.014 in ICBEB. In theidentification task, the model pre-trained on all datasets only shows a slight improvement. These results suggest that while MIMIC-IV-ECG provides a strong foundation for pre-training, and theinclusion of additional datasets can further enhance the models ability to generalize across different tasksand datasets. Also, for the zero-shot learning tasks, learning from the samples and annotating informationfrom the same dataset during pretraining, e.g., PTB-XL, could help the downstream tasks accordingly.",
  ":Distribution difference measured bymaximum mean discrepancy (MMD) betweenthe pretraining set and test set using encoderswith varying training samples": "ViT (Dosovitskiy et al., 2020) and ConvNeXt (Woo et al., 2023) architectures. Additionally, considering thestrong performance of XResNet1D101 in supervised arrhythmia diagnosis (Strodthoff et al., 2020) as shownin , we examine its potential as a foundation encoder after multimodal pretraining. (b) summarizes the results. ConvNeXt-based models (ConvNeXt-tiny and ConvNeXt-base) achievedthe highest AUC scores on both arrhythmia diagnosis and ECG identification tasks. Notably, ConvNeXt-base, the largest model with the most parameters (85.56M), provides the best overall performance (AUC of0.932 for arrhythmia diagnosis and 0.926 for ECG identification). ConvNeXt-tiny, a more parameter-efficientoption (26.81M), shows a slightly lower performance compared to the base version, but also achieves com-petitive AUC scores with a significantly lower parameter footprint. With the same-level size as ConvNeXtmodels in both tasks, the ViT model shows substantially lower performances, which might indicate the con-volutional kernel could be more suitable for processing ECG signals. Moreover, the XResNet1D101 backbonedisplays lower AUC scores compared to ConvNeXt architectures. This can be due to the significantly smallerparameter size of the XResNet model.",
  "Ablation Study: Impact of Pretraining Data Sizes and Distribution Shifts": "In this ablation study, we also investigate the impact of pretraining dataset size on the performance of ourESI-tiny model in two arrhythmia classification datasets, including PTB-XL and ICBEB. We artificiallychange the size of the unlabeled pretraining dataset from 0 to all available samples by randomly samplingand selecting from all the pretraining samples. After ESI-tiny encoders are trained, the models are thenevaluated on both datasets using a linear probing approach with frozen encoder weights, and the AUC scoreis employed as the performance metric. The results presented in demonstrate a consistent performance improvement as the pretrainingdataset size increases for both PTB-XL and ICBEB datasets.The models performance improves mostsubstantially in the early stages of increasing the pretraining dataset size. This indicates that a modestamount of pretraining data can help substantial gains in learning informative representations. Additionally, to understand the effect of pretraining on distribution shift, we measure the Maximum MeanDiscrepancy (MMD) between the pretraining dataset and each test set (PTB-XL and ICBEB) as the pre-training size increases. As shown in , the distribution shift between the pretraining and test setsdecreases as the pretraining dataset size increases. This suggests that larger pretraining datasets help themodel learn representations that are more generalizable to the target datasets. The decrease in MMD corre-lates with the improvements in AUC scores observed in , which potentially indicates that reducingdistribution shift through larger pretraining sets contributes to better performance on the downstream tasks.",
  "Ablation Study: Impact of ECG-text Misalignment": "To investigate the impact of potential misalignments between ECG signals and their corresponding textdescriptions on the proposed ESI method, we conduct an experiment on ESI-tiny with a sub-training set of100K ECG-text pairs. We introduce various degrees of misalignment by randomly shuffling a percentage ofECG-text pairs in our pretraining dataset. The model was then evaluated on two arrhythmia classificationdatasets with a linear probing approach with frozen encoder weights. shows the results of the experiment. As the percentage of misaligned pairs increases, the perfor-mance of ESI-tiny decreases substantially on both datasets. This indicates that the alignment between thepretraining sample pairs plays an essential role in learning robust representations. Notably, increasing mis-alignment can lead to performance that is worse than using un-pretrained models with random initialization,which also highlights the critical importance of accurate ECG-text pairing in pretraining.",
  "Conclusion": "This study introduces a novel multimodal contrastive pretraining framework to enhance the quality androbustness of representations learned from ECG signals. To address the lack of descriptive text associatedwith ECGs, we propose a retrieval-augmented generation (RAG) pipeline called the Cardio Query Assistant(CQA). This pipeline generates detailed textual descriptions for ECG data with demographic information,potential conditions, and waveform patterns. Inspired by the success of multimodal pretraining strategiesin vision-language tasks, we develop the ECG Semantic Integrator (ESI). This framework integrates bothcontrastive and captioning capabilities to foster a deeper semantic understanding of ECG signals.Ourevaluation validates the effectiveness of the proposed approach across several downstream tasks. The ESImethod demonstrates improvement in arrhythmia diagnosis and ECG-based user identification tasks byoutperforming strong baselines that cover supervised learning and SSL approaches. These results with theablation studies highlight the benefits of multimodal learning for ECG analysis and the value of integratingcaptioning loss with contrastive pretraining. Beyond ECG, we believe the proposed CQA and ESI frameworkshold the potential for applications to other types of biomedical time series data, where contextual informationcan be leveraged to enhance the representation learning and downstream analysis. On the other hand, this study is limited by the use of 10-second ECG signals only in pretraining. Whileour approach demonstrates effectiveness on this data, real-world ECG recordings can vary significantly inlength and may contain more diverse features. In future work, we plan to investigate the impact of usingmore diverse ECG signals on the performance of the proposed framework.",
  "This work was supported by National Science Foundation (# 2047296) and National Institute of Health (#R01DA059925)": "Ulas Baran Baloglu, Muhammed Talo, Ozal Yildirim, Ru San Tan, and U Rajendra Acharya. Classificationof myocardial infarction with multi-lead ecg signals and deep cnn. Pattern Recognition Letters, 122:2330,2019. Behnam Behinaein, Anubhav Bhatti, Dirk Rodenburg, Paul Hungler, and Ali Etemad.A transformerarchitecture for stress detection from ecg. In 2021 International Symposium on Wearable Computers, pp.132134, 2021. Ting Chen, Simon Kornblith, Mohammad Norouzi, and Geoffrey Hinton. A simple framework for contrastivelearning of visual representations. In International conference on machine learning, pp. 15971607. PMLR,2020.",
  "Jacob Devlin, Ming-Wei Chang, Kenton Lee, and Kristina Toutanova. Bert: Pre-training of deep bidirectionaltransformers for language understanding. arXiv preprint arXiv:1810.04805, 2018": "Alexey Dosovitskiy, Lucas Beyer, Alexander Kolesnikov, Dirk Weissenborn, Xiaohua Zhai, Thomas Un-terthiner, Mostafa Dehghani, Matthias Minderer, Georg Heigold, Sylvain Gelly, et al. An image is worth16x16 words: Transformers for image recognition at scale. arXiv preprint arXiv:2010.11929, 2020. Emadeldeen Eldele, Mohamed Ragab, Zhenghua Chen, Min Wu, Chee Keong Kwoh, Xiaoli Li, and Cun-tai Guan. Time-series representation learning via temporal and contextual contrasting. arXiv preprintarXiv:2106.14112, 2021. Oliver Faust, U Rajendra Acharya, EYK Ng, and Hamido Fujita. A review of ecg-based diagnosis supportsystems for obstructive sleep apnea. Journal of Mechanics in Medicine and Biology, 16(01):1640004, 2016.",
  "Timnit Gebru, Jamie Morgenstern, Briana Vecchione, Jennifer Wortman Vaughan, Hanna Wallach,Hal Daum Iii, and Kate Crawford.Datasheets for datasets.Communications of the ACM, 64(12):8692, 2021": "Bryan Gopal, Ryan Han, Gautham Raghupathi, Andrew Ng, Geoff Tison, and Pranav Rajpurkar. 3kg: Con-trastive learning of 12-lead electrocardiograms using physiologically-inspired augmentations. In MachineLearning for Health, pp. 156167. PMLR, 2021. Brian Gow, Tom Pollard, Larry A Nathanson, Alistair Johnson, Benjamin Moody, Chrystinne Fernandes,Nathaniel Greenbaum, Seth Berkowitz, Dana Moukheiber, Parastou Eslami, et al. Mimic-iv-ecg-diagnosticelectrocardiogram matched subset. Type: dataset, 2023. Jean-Bastien Grill, Florian Strub, Florent Altch, Corentin Tallec, Pierre Richemond, Elena Buchatskaya,Carl Doersch, Bernardo Avila Pires, Zhaohan Guo, Mohammad Gheshlaghi Azar, et al. Bootstrap yourown latent-a new approach to self-supervised learning. Advances in neural information processing systems,33:2127121284, 2020. Jian Guan, Wenbo Wang, Pengming Feng, Xinxin Wang, and Wenwu Wang. Low-dimensional denoisingembedding transformer for ecg classification. In ICASSP 2021-2021 IEEE International Conference onAcoustics, Speech and Signal Processing (ICASSP), pp. 12851289. IEEE, 2021. TH Haapaniemi, Ville Pursiainen, JT Korpelainen, HV Huikuri, KA Sotaniemi, and VV Myllyl. Ambulatoryecg and analysis of heart rate variability in parkinsons disease. Journal of neurology, neurosurgery &psychiatry, 70(3):305310, 2001.",
  "Rahul Jain, Robin Singh, Sundermurthy Yamini, and Mithilesh K Das. Fragmented ecg as a risk marker incardiovascular diseases. Current Cardiology Reviews, 10(3):277286, 2014": "Chao Jia, Yinfei Yang, Ye Xia, Yi-Ting Chen, Zarana Parekh, Hieu Pham, Quoc Le, Yun-Hsuan Sung,Zhen Li, and Tom Duerig. Scaling up visual and vision-language representation learning with noisy textsupervision. In International conference on machine learning, pp. 49044916. PMLR, 2021. Enbiao Jing, Haiyang Zhang, ZhiGang Li, Yazhi Liu, Zhanlin Ji, and Ivan Ganchev. Ecg heartbeat classi-fication based on an improved resnet-18 model. Computational and Mathematical Methods in Medicine,2021, 2021. Dani Kiyasseh, Tingting Zhu, and David A Clifton. Clocs: Contrastive learning of cardiac signals acrossspace, time, and patients. In International Conference on Machine Learning, pp. 56065615. PMLR, 2021. Paul Kligfield, Leonard S Gettes, James J Bailey, Rory Childers, Barbara J Deal, E William Hancock, GerardVan Herpen, Jan A Kors, Peter Macfarlane, David M Mirvis, et al. Recommendations for the standard-ization and interpretation of the electrocardiogram: part i: the electrocardiogram and its technology: ascientific statement from the american heart association electrocardiography and arrhythmias committee,council on clinical cardiology; the american college of cardiology foundation; and the heart rhythm societyendorsed by the international society for computerized electrocardiology. Circulation, 115(10):13061324,2007. Sravan Kumar Lalam, Hari Krishna Kunderu, Shayan Ghosh, Harish Kumar, Samir Awasthi, Ashim Prasad,Francisco Lopez-Jimenez, Zachi I Attia, Samuel Asirvatham, Paul Friedman, et al. Ecg representationlearning with multi-modal ehr data. Transactions on Machine Learning Research, 2023.",
  "Jun Li, Che Liu, Sibo Cheng, Rossella Arcucci, and Shenda Hong. Frozen language model helps ecg zero-shotlearning. In Medical Imaging with Deep Learning, pp. 402415. PMLR, 2024": "Junnan Li, Dongxu Li, Caiming Xiong, and Steven Hoi. Blip: Bootstrapping language-image pre-training forunified vision-language understanding and generation. In International conference on machine learning,pp. 1288812900. PMLR, 2022. Junnan Li, Dongxu Li, Silvio Savarese, and Steven Hoi. Blip-2: Bootstrapping language-image pre-trainingwith frozen image encoders and large language models. In International conference on machine learning,pp. 1973019742. PMLR, 2023b.",
  "Che Liu, Sibo Cheng, Miaojing Shi, Anand Shah, Wenjia Bai, and Rossella Arcucci. Imitate: Clinical priorguided hierarchical vision-language pre-training. arXiv preprint arXiv:2310.07355, 2023": "Che Liu, Zhongwei Wan, Cheng Ouyang, Anand Shah, Wenjia Bai, and Rossella Arcucci. Zero-shot ecgclassification with multimodal learning and test-time clinical knowledge enhancement.arXiv preprintarXiv:2403.06659, 2024. Feifei Liu, Chengyu Liu, Lina Zhao, Xiangyu Zhang, Xiaoling Wu, Xiaoyan Xu, Yulin Liu, Caiyun Ma,Shoushui Wei, Zhiqiang He, et al. An open access database for evaluating the algorithms of electrocardio-gram rhythm and morphology abnormality detection. Journal of Medical Imaging and Health Informatics,8(7):13681373, 2018.",
  "Sheikh Shanawaz Mostafa, Fbio Mendona, Antonio G. Ravelo-Garca, and Fernando Morgado-Dias. Asystematic review of detecting sleep apnea using deep learning. Sensors, 19(22):4934, 2019": "Annamalai Natarajan, Yale Chang, Sara Mariani, Asif Rahman, Gregory Boverman, Shruti Vij, andJonathan Rubin. A wide and deep transformer neural network for 12-lead ecg classification. In 2020Computing in Cardiology, pp. 14. IEEE, 2020. Jungwoo Oh, Hyunseung Chung, Joon-myoung Kwon, Dong-gyun Hong, and Edward Choi. Lead-agnosticself-supervised learning for local and global representations of electrocardiogram. In Conference on Health,Inference, and Learning, pp. 338353. PMLR, 2022.",
  "Sandra migiel, Krzysztof Paczyski, and Damian Ledziski. Ecg signal classification using deep learningtechniques based on the ptb-xl dataset. Entropy, 23(9):1121, 2021": "Nils Strodthoff, Patrick Wagner, Tobias Schaeffter, and Wojciech Samek. Deep learning for ecg analysis:Benchmarks and insights from ptb-xl. IEEE journal of biomedical and health informatics, 25(5):15191528,2020. Oriol Vinyals, Alexander Toshev, Samy Bengio, and Dumitru Erhan. Show and tell: A neural image captiongenerator. In Proceedings of the IEEE conference on computer vision and pattern recognition, pp. 31563164, 2015.",
  "Hao Wen and Jingsu Kang. torch_ecg: An ECG Deep Learning Framework Implemented using PyTorch,2022. URL": "Sanghyun Woo, Shoubhik Debnath, Ronghang Hu, Xinlei Chen, Zhuang Liu, In So Kweon, and SainingXie. Convnext v2: Co-designing and scaling convnets with masked autoencoders. In Proceedings of theIEEE/CVF Conference on Computer Vision and Pattern Recognition, pp. 1613316142, 2023. Genshen Yan, Shen Liang, Yanchun Zhang, and Fan Liu. Fusing transformer model with temporal features forecg heartbeat classification. In 2019 IEEE International Conference on Bioinformatics and Biomedicine(BIBM), pp. 898905. IEEE, 2019. Shunxiang Yang, Cheng Lian, Zhigang Zeng, Bingrong Xu, Junbin Zang, and Zhidong Zhang. A multi-viewmulti-scale neural network for multi-label ecg classification. IEEE Transactions on Emerging Topics inComputational Intelligence, 2023.",
  "Jiahui Yu, Zirui Wang, Vijay Vasudevan, Legg Yeung, Mojtaba Seyedhosseini, and Yonghui Wu. Coca:Contrastive captioners are image-text foundation models. arXiv preprint arXiv:2205.01917, 2022b": "Lu Yuan, Dongdong Chen, Yi-Ling Chen, Noel Codella, Xiyang Dai, Jianfeng Gao, Houdong Hu, XuedongHuang, Boxin Li, Chunyuan Li, et al. Florence: A new foundation model for computer vision. arXivpreprint arXiv:2111.11432, 2021. Xiaohua Zhai, Xiao Wang, Basil Mustafa, Andreas Steiner, Daniel Keysers, Alexander Kolesnikov, and LucasBeyer. Lit: Zero-shot transfer with locked-image text tuning. In Proceedings of the IEEE/CVF Conferenceon Computer Vision and Pattern Recognition, pp. 1812318133, 2022. Jing Zhang, Deng Liang, Aiping Liu, Min Gao, Xiang Chen, Xu Zhang, and Xun Chen. Mlbf-net: A multi-lead-branch fusion network for multi-class arrhythmia classification using 12-lead ecg. IEEE journal oftranslational engineering in health and medicine, 9:111, 2021.",
  "Wenrui Zhang, Ling Yang, Shijia Geng, and Shenda Hong. Self-supervised time series representation learningvia cross reconstruction transformer. arXiv preprint arXiv:2205.09928, 2022": "Jianwei Zheng, Huimin Chu, Daniele Struppa, Jianming Zhang, Sir Magdi Yacoub, Hesham El-Askary,Anthony Chang, Louis Ehwerhemuepha, Islam Abudayyeh, Alexander Barrett, et al. Optimal multi-stagearrhythmia classification approach. Scientific reports, 10(1):2898, 2020. Zhaowei Zhu, Han Wang, Tingting Zhao, Yangming Guo, Zhuoyang Xu, Zhuo Liu, Siqi Liu, Xiang Lan,Xingzhi Sun, and Mengling Feng. Classification of cardiac abnormalities from ecg signals using se-resnet.In 2020 Computing in Cardiology, pp. 14. IEEE, 2020.",
  "AAblation Study on CQA": "The introduction of Retrieval-Augmented Generation (RAG) in CQA in this study plays a crucial role inenriching the pretraining dataset by generating detailed ECG waveform descriptions. In this ablation study,we investigate the impact of different RAG settings on performance. To evaluate the performance of our RAG-generated descriptions, we utilize the human-annotated ECGwaveform descriptions from (Wen & Kang, 2022) as references. This dataset includes annotations for 28types of arrhythmia. We generate corresponding descriptions using our RAG method and compared themagainst the reference descriptions using BERTScore (Zhang et al., 2020) with the RoBERTa-large model (Liuet al., 2019). BERTScore is a metric designed to evaluate the similarity between generated text and referencetext by leveraging pre-trained contextual embeddings from transformer models. BERTScore computes thesimilarity of embeddings to provide a more nuanced assessment of semantic alignment, and there are threemain metrics served in BERTScore:",
  "A.1Impact of Top-k in Vector Search": "In this section, we examine the effect of varying the top-k parameter in the vector search interface on themodels performance. The top-k parameter controls how many of the top-ranked candidates are consideredin the generation process. We evaluated the models performance by measuring Precision, Recall, and F1score generated by BERTScore for different values of top-k. The mean and standard deviation of thesemetrics across multiple runs are summarized in .",
  "Top KBP recision BRecall BF 1Score": "10.8190 (0.0128)0.8326 (0.0237)0.8256 (0.0147)20.8197 (0.0159)0.8402 (0.0156)0.8296 (0.0090)30.8169 (0.0160)0.8433 (0.0155)0.8297 (0.0106)40.8159 (0.0157)0.8447 (0.0160)0.8299 (0.0111)50.8153 (0.0172)0.8447 (0.0167)0.8295 (0.0110) The results indicate that as the top-k value increases, the Recall generally improves slightly, which suggeststhat considering more candidates helps in retrieving more relevant information. However, the mean Precisiontends to decrease marginally, which reflects a trade-off where including more candidates might introduce lessrelevant information. The F1 score, which balances both Precision and Recall, remains relatively stableacross different top-k values. This indicates that the model maintains a consistent performance overall. Our findings suggest that varying the top-k parameter has a limited but consistent impact on RAG perfor-mance. The choice of top-k can be adjusted based on the specific needs of the task, with higher values favoringrecall at a slight cost to precision, while lower values provide a more precise but slightly less comprehensiveoutput. In this study, we set the top-k value as 2.",
  "TextbooksBP recision BRecall BF 1Score": "No Textbook0.7617 (0.0187)0.8154 (0.0142)0.7928 (0.0126)Garcia (2015)0.8169 (0.0142)0.8290 (0.0175)0.8217 (0.0111)Huff (2006)0.8182 (0.0145)0.8395 (0.0170)0.8285 (0.0100)Both0.8197 (0.0159)0.8402 (0.0156)0.8296 (0.0090) quality of the generated ECG waveform descriptions. The textbooks used in this study are \"ECG Workout:Exercises In Arrhythmia Interpretation\" by Huff (2006) and \"12-Lead ECG: The Art of Interpretation\" byGarcia (2015). We conducted experiments using three different configurations: using no textbooks, usingeach textbook individually, and using both textbooks combined. The results are summarized in . The results show a clear trend that incorporating textbooks into the RAG pipeline improves the perfor-mance across all BERTScore metrics (Precision, Recall, and F1 Score). Specifically, using both textbooksin combination yields the highest scores, with a Precision of 0.8197, a Recall of 0.8402, and an F1 score of0.8296. This suggests that the inclusion of multiple sources of knowledge enriches the generated descriptions.When using only one textbook, Huff (2006) slightly outperforms Garcia (2015) in terms of all three metrics,although the difference is incremental. This indicates that while each textbook independently contributesto the generation quality, combining them provides a more robust knowledge base for the RAG process. Incontrast, the absence of textbooks results in a significant drop in performance, with the lowest scores acrossall metrics. This highlights the importance of incorporating domain-specific knowledge to improve the rel-evance and accuracy of LLMs in generating content. Thus, in this study, using multiple textbooks in theRAG pipeline not only increases the quality of the generated ECG descriptions but also ensures consistencyin the output.",
  "A.3Impact of Different LLM Prompting Strategies": "In this subsection, we investigate the effect of varying the prompt structure used in the LLM within the RAGpipeline on the quality of the generated ECG waveform descriptions. To assess consistency of the generationacross different prompts, we conducted an ablation study by rephrasing our standard prompt, \"How is {ECGcondition} reflected in 12-lead ECG?\", into five different variations such as \"Describe how {ECG condition}appears in a 12-lead ECG.\" and \"What are the ECG findings associated with {ECG condition} in a 12-leadsetup?\" The alternative prompts used are designed to explore whether slight changes in wording would affectthe performance of the RAG pipeline. Despite these variations, the underlying query remains focused ongenerating descriptions of how specific ECG conditions are in a 12-lead ECG. The results demonstrate a remarkable consistency across all rephrased prompting strategies, with an averagemean F1 score of 0.8295 and a very low standard deviation of 0.0003 across the variations of prompts. Thisindicates that the CQAs ability to generate relevant descriptions is robust to variations in the phrasing ofthe prompt. This robustness allows for some flexibility in how prompts are formulated without hurting thequality of the generated content.",
  "B.1Motivation": "Purpose: The datasets were collected and processed to facilitate the development and evaluation of auto-mated ECG processing algorithms, particularly for training a foundation model that extracts generalizedembedding from ECG signals. These datasets provide a large number of ECG recordings paired with humanor machine annotations and metadata, which enables robust training of machine learning models in themedical domain."
}