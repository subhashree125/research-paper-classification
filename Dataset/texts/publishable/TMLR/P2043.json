{
  "Abstract": "Current status quo in machine learning is to use static datasets of real images for training,which often come from long-tailed distributions. With the recent advances in generativemodels, researchers have started augmenting these static datasets with synthetic data, re-porting moderate performance improvements on classification tasks. We hypothesize thatthese performance gains are limited by the lack of feedback from the classifier to the genera-tive model, which would promote the usefulness of the generated samples to improve the clas-sifiers performance. In this work, we introduce a framework for augmenting static datasetswith useful synthetic samples, which leverages one-shot feedback from the classifier to drivethe sampling of the generative model. In order for the framework to be effective, we findthat the samples must be close to the support of the real data of the task at hand, and be suf-ficiently diverse. We validate three feedback criteria on a long-tailed dataset (ImageNet-LT,Places-LT) as well as a group-imbalanced dataset (NICO++). On ImageNet-LT, we achievestate-of-the-art results, with over 4% improvement on underrepresented classes while beingtwice efficient in terms of the number of generated synthetic samples. Similarly, on Places-LT we achieve state-of-the-art results as well as nearly 4% improvement on underrepresentedclasses. NICO++ also enjoys marked boosts of over 5% in worst group accuracy. With theseresults, our framework paves the path towards effectively leveraging state-of-the-art text-to-image models as data sources that can be queried to improve downstream applications 1.",
  "Introduction": "In the recent year, we have witnessed unprecedented progress in image generative models (Ho et al., 2020;Nichol et al., 2022; Ramesh et al., 2021; Rombach et al., 2022; Ramesh et al., 2022; Saharia et al., 2022;Balaji et al., 2022; Kang et al., 2023). The photo-realistic results achieved by these models has propelled anarms race towards their widespread use in content creation applications, and as a byproduct, the researchcommunity has focused on developing models and techniques to improve image realism (Kang et al., 2023)and conditioning-generation consistency (Hu et al., 2023; Yarom et al., 2023; Xu et al., 2023). Yet, thepotential for those models to become sources of data to train machine learning models is still under debate,raising intriguing questions about the qualities that the synthetic data must possess to be effective in trainingdownstream representation learning models. Several recent works have proposed using generative models as either data augmentation or sole source ofdata to train machine learning models (He et al., 2023; Sariyildiz et al., 2023; Shipard et al., 2023; Bansal &Grover, 2023; Dunlap et al., 2023; Gu et al., 2023; Astolfi et al., 2023; Tian et al., 2023), reporting moderatemodel performance gains. These works operate in a static scenario, where the models being trained do notprovide any feedback to the synthetic data collection process that would ensure the usefulness of the generated",
  "(a)(b)(c)": ": Exemplary samples from different distributions. Subfigures show random samples for Jack-o-lantern class coming from: (a) ImageNet-LT; (b) Latent Diffusion Model (LDM-unclip v2-1), conditionedon the text prompt Jack-o-lantern; These exhibit a noticeable distribution mismatch with real data. (c)our pipeline, the generated samples more closely align with the real data distribution and present higherdiversity, including rare samples such as blue or white pumpkins. samples. Instead, to achieve performance gains, the proposed approaches often rely on laborious promptengineering (Gu et al., 2023) to promote synthetic data to be close to the support of the real data distributionon which the downstream representation learning model is to be deployed (Shin et al., 2023). Moreover,recent studies have highlighted the limited conditional diversity in the samples generated by state-of-the-artimage generative models (Hall et al., 2023; Cho et al., 2022b; Luccioni et al., 2023; Bianchi et al., 2022),which may hinder the promise of leveraging synthetic data at scale. From these perspectives, synthetic datastill falls short of real data. Yet, the generative model literature has implicitly encouraged generating synthetic samples that are closeto the support of the real data distribution by developing methods to increase the controllability of thegeneration process (Vendrow et al., 2023). For example, researchers have explored image generative modelsconditioned on images instead of only text (Casanova et al., 2021; Blattmann et al., 2022; Bordes et al., 2022).These approaches inherently offer more control over the generation process, by providing the models withrich information from a real image without relying on prompt engineering (Wei et al., 2022; Zhang et al.,2022; Lester et al., 2021). Similarly, the generative models literature has aimed to increase sample diversityby devising strategies to encourage models to sample from the tails of their distribution (Sehwag et al., 2022;Um & Ye, 2023). However, the promise of the above-described strategies to improve representation learningis yet to be shown. In this work, we propose to leverage the recent advances in the generative models to address the shortcomingsof synthetic data in representation learning, and introduce feedback from the downstream classifier modelto guide the data generation process. In particular, we devise a framework which leverages a pre-trainedimage generative model to provide useful, and diverse synthetic samples that are close to the support ofthe real data distribution, to improve on representation learning tasks. Since real world data is most oftencharacterized by long tail and open-ended distributions, we focus on imbalanced classification-scenarios, inwhich different classes or groups are unequally represented, to demonstrate the effectiveness of our framework.More precisely, we conduct experiments on ImageNet Long-Tailed (ImageNet-LT) (Liu et al., 2019), PlacesLong-Tailed (Places-LT) and NICO++ (Zhang et al., 2023) and show consistent performance gains w.r.t.prior art. Our contributions can be summarized as:",
  "We find that for the classifiers feedback to be effective, the synthetic data must lie close to thesupport of the downstream task data distribution, and be sufficiently diverse": "We report state-of-the-art results (1) on ImageNet-LT, with an improvement of 4% on underrepre-sented classes while using half the amount of synthetic data than the previous state-of-the-art; and(2) we report state-of-the-art results on Places-LT, with an improvement of nearly 4% on underrep-resented classes; and (3) on NICO++, with improvements of over 5% in worst group accuracy.",
  "Dreal+synDreal Dsyn": ": Overview of our framework. Given an imbalanced dataset, Dreal, a classifier f(x) is initiallytrained. Knowing that the validation and test sets are balanced, the goal is to create a balanced trainingset using synthetic data. The Diffusion Model, G, is conditioned on a randomly selected real image and alabel-containing text prompt. The models generation is also guided by feedback, C(f), from the classifierto increase usefulness of the synthetic samples. Subsequently, f(x) is retrained on the combined real andsynthetic samples.",
  "Background": "Diffusion models.Diffusion models (Sohl-Dickstein et al., 2015; Song & Ermon, 2019) learn data distri-butions p(x) or p(x|y) by simulating the diffusion process in forward and reverse directions. In particular,Denoising Diffusion Probabilistic Models (DDPM) (Ho et al., 2020) add noise to data points in the forwardprocess and remove it in the reverse process. The continuous-time reverse process in DDPM is given by,dxt =f(xt, t) g2(t) log pt(xt)dt + g(t)dwt, where t indexes time, and f(xt, t) and g(t) are drift andvolatility coefficients. A neural network (t) (xt) is trained to predict noise in DDPM, aligning with the scorefunction log pt(xt). Given a trained model (t) (xt), Denoising Diffusion Implicit Models (DDIM) (Songet al., 2020), a more generic form of diffusion models, can generate an image x0 from pure noise xT byrepeatedly removing noise, getting xt1 given xt (Song et al., 2020):",
  "Methodology": "presents an overview of our proposed approach. We assume access to a pre-tained diffusion model,which takes as input an image and a text prompt, and produces an image consistent with the inputs. Wetrain a classifier f on an imbalanced dataset of real images, Dreal. This initial classifier serves as a founda-tion for the subsequent generation of synthetic samples. We then collect a dataset of synthetic data, Dsyn,",
  "Published in Transactions on Machine Learning Research (09/2024)": "Keze Wang, Dongyu Zhang, Ya Li, Ruimao Zhang, and Liang Lin. Cost-effective active learning for deepimage classification. IEEE Transactions on Circuits and Systems for Video Technology, 27(12):25912600,2016. Jason Wei, Xuezhi Wang, Dale Schuurmans, Maarten Bosma, Fei Xia, Ed Chi, Quoc V Le, Denny Zhou, et al.Chain-of-thought prompting elicits reasoning in large language models. Advances in Neural InformationProcessing Systems, 35:2482424837, 2022. Jiaxi Wu, Jiaxin Chen, and Di Huang. Entropy-based active learning for object detection with progres-sive diversity constraint. In Proceedings of the IEEE/CVF Conference on Computer Vision and PatternRecognition, pp. 93979406, 2022. Weijia Wu, Yuzhong Zhao, Mike Zheng Shou, Hong Zhou, and Chunhua Shen. Diffumask: Synthesizingimages with pixel-level annotations for semantic segmentation using diffusion models.arXiv preprintarXiv:2303.11681, 2023. Jiazheng Xu, Xiao Liu, Yuchen Wu, Yuxuan Tong, Qinkai Li, Ming Ding, Jie Tang, and Yuxiao Dong.Imagereward: Learning and evaluating human preferences for text-to-image generation. arXiv preprintarXiv:2304.05977, 2023.",
  "Increasing the Usefulness of Synthetic Data: Feedback-guided Synthesis": "Feedback-guided synthesis.We propose feedback-guidance, a modification of the diffusion models stan-dard sampling process for generating useful samples for training a classifier by getting feedback from theclassifier itself. While standard classifier-guidance in diffusion models (Dhariwal & Nichol, 2021; Ho et al.,2020) focuses on high-density regions, our method prioritizes the generation of useful samples, by leveragingfeedback from our pre-trained classifier f. Leveraging classifier feedback allows for a systematic approachfor generating useful samples that provide gradient for the classification task at hand. Our proposed feedback-guidance might be reminiscent of classifier-guidance in diffusion models (Dhariwal& Nichol, 2021; Ho et al., 2020), which drives the sampling process of the generative model to produceimages that are close to the distribution modes.The proposed feedback-guidance is also related to theliterature aiming to increase sample diversity in diffusion models (Sehwag et al., 2022; Um & Ye, 2023),whose goal is to drive the sampling process of the generative model towards low density regions of thelearned distribution. Instead, the goal of our proposed feedback-guidance is to synthesize samples which areuseful for a classifier to improve its performance. Furthermore, our framework is inspired by the literaturein active learning (Wang et al., 2016; Wu et al., 2022), where useful samples are selected from a pool ofsamples, whereas we propose to generate useful samples. Formally, let Dreal be a training dataset of real data, f a classifier, and G a state-of-the-art pre-traineddiffusion model. We start by training f on Dreal, and define h {0, 1} as a binary variable that describeswhether a sample is useful for the classifier f or not. Our goal is to generate samples from a specific classthat are informative, i.e. from the distribution of p(x|h, y). To generate samples using the reverse samplingprocess defined in section 2, we need to compute x log p(x|h, y). Following Eq. 2, we have:",
  "x log p,(x|h, y) = x log p(x) + x log p(y|x) + xC(x, y, f),(3)": "where C(x, y, f) is a criterion function approximating the sample usefulness (h), and is a scaling factorthat controls the strength of the signal from our criterion function. Note that by using a pre-trained diffusionmodel, we have access to the estimated class conditional score function x log p(x|y) as well as the estimatedunconditional score function x log p(x). The derivation of Eq. 3 is presented in Appendix A.1.",
  "Feedback Criteria C(x, y, f)": "We explore criteria functions that promote generating samples which are informative and challenging forthe classifier. We consider three feedback criteria: (1) the classifiers loss on the generated samples; (2) theclassifiers prediction entropy on the generated samples; and (3) the hardness score (Sehwag et al., 2022). Classifier Loss.To focus on generating samples that pose a challenge for the classifier f, we use theclassifiers loss as the criterion function for the feedback guided sampling. Formally, we define C(x, y, f) interms of the loss function L as:C(x, y, f) = L(f(x), y).(4)",
  "x log p(x|h, y) = x log p(x) + x log p(y|x) x log p(y|x).(5)": "Note that p is the probability distribution modeled by the generative model and p is the probabilitydistribution modeled by the classifier f. We are effectively moving towards space where under the classifierf the samples have lower probability2, but simultaneously the term x log p(y|x) which is modeled bythe generative model, ensures that the samples belong to class y.",
  "(c) C = Hardness": ": A grid of images generated for the class \"African Chameleon\" using different criterion for feedbackguidance. Along the x-axis, from left to right conditional guidance scale or the in Eq. 3 is increased, whilealong the y-axis, from top to bottom, the classifier-feedback guidance scale or the in Eq. 3 is increased. Therandom seed is consistent across all images, ensuring that any observed variations are only due to changes inthe guidance scales. Moving from left to right, it is evident that increasing results in samples that are morefaithful to the \"African Chameleon\" class. However, this comes at the cost of generating very typical, easilyclassifiable images. Conversely, as we move from top to bottom, increasing the classifier-feedback guidanceresults in the generation of more challenging or atypical images of African chameleon. However, this maycome at the cost of moving away from the class \"African Chameleon\", thus it is important to tune and to generate useful samples. Entropy.Another measure for the usefulness of the generated samples is the entropy (Shannon, 2001) ofthe output class distributions for x predicted by f(x). Entropy is a common measure that quantifies theuncertainty of the classifier on a sample x (Wang et al., 2016; Sorscher et al., 2022; Simsek et al., 2022). Weadopt entropy as a criterion, C = H(f(x)), as higher entropy leads to generating more informative samples.Following Eq. 3, we have,",
  "This sampling procedure promotes generating samples that are challenging for the classifier f": "To showcase the interplay between and and how changing the criterion function C affects the samplingprocess, we plot grids of synthetically generated images in . All samples are conditioned to generatean \"African Chameleon\", with variations in feedback-guidance scales based on three different criteria: en-tropy, loss, and hardness. serves the role of ensuring that the generated images are faithful to the visualcharacteristics of an \"African Chameleon\", such as color patterns, skin details, or posture. On the otherhand, relies on the uncertainties in the classifiers predictions to guide the generative model.",
  "(c) toucan": ": In each figure: first row depicts samples from Imagenet-LT, second row shows samples fromLDM conditioned on text prompt (class label), and third row displays samples generated by conditioningthe LDM on both text prompt and the image embedding of a random real sample from the class. (a)Homonym ambiguity: the text prompt sorrel refers to either the sorrel horse or the sorrel plant. However,in the Imagenet-LT dataset class sorrel refers to the horse while LDM generates the plant.(b) Textmisinterpretation: LDM may interpret the text prompt incorrectly. For example the class carpenters planrefers to a carpentering tool, while LDM generates wooden planes. (c) Stylistic Bias: When promptedwith Toucan, LDM mostly generates drawings of the bird toucan. However, in the training distribution, wemostly observe real birds. Conditioning on a random training image allows the LDM to generate sampleswith the correct style. See .2 and also Figures 7, 8.",
  "Feedback-guided Synthesis in Latent Diffusion Models": "To apply feedback-guided synthesis in latent diffusion models (LDMs), we need to compute the criteriafunction C(f(xt)) at each step of the reverse sampling process with the minor change that the diffusion isapplied on the latent variables z. However, the classifier f operates on the pixel space x. Consequently, anaive implementation of feedback-guided sampling would require a full reverse chain to find z0, which wouldthen be decoded to find x0 to finally compute C(f(x0)). Therefore, to reduce the computational cost, insteadof applying the full reverse chain, we use the DDIM predicted z0 (or equivalently predicted x0 in Eq. 1) ateach step of the reverse process. We find that this approach is computationally much cheaper and is highlyeffective.",
  "We identify three scenarios where using only text prompt results in synthetic samples that are not close tothe real data used to train machine learning downstream models:": "Homonym ambiguity. A single text prompt can have multiple meanings. For example, considergenerating data for the class sorrel that could either refer to the sorrel horse or the sorrel plant.See (a) for further illustrations. Text misinterpretation. The text-to-image generative model can produce images which are se-mantically inconsistent or partially consistent with the input prompt. An example of that is theclass carpenters plane from ImageNet-LT. When prompted with this term, the diffusion modelgenerated images of wooden planes instead of the intended carpentry tools. See (b) forfurther illustrations. Stylistic Bias. The generative model can produce images with a particular style for some prompts,which does not match the style of the real data. For instance, the Toucan images in the ImageNet-LTdataset are mostly real photographs, but the generative model frequently outputs drawings of thisspecies of bird. See (c) for further illustrations. Also see more samples in Figures 7, 8.",
  "(d) With random dropout p=0.6(f) With random dropout p=1.0": ": Synthetic sample generation using text prompt and image embedding. We plot different levels ofdropout on the image embedding. We condition on a single random real sample (plotted on the left most).As observed, using only image conditioning and text (a), we observe very low diversity in the generations.As we increase the dropout probability, we observe more diversity. If we only condition on the text prompt(f), we also observe low diversity. To alleviate the above-described issues, we borrow from the generative models literature a dual-conditioningtechnique (Mishra et al., 2023). In this approach, the generator is conditioned on both a text descriptorcontaining the class label and a randomly selected real image from the same class in the real training dataset.This additional layer of conditioning steers the diffusion model to generate samples which are more similarto those in the real training data; see , to contrast samples from text-conditional models with thoseof text-and-image-conditional models. Using the unCLIP model (Rombach et al., 2022), the noise predictionnetwork (t) (xt) in Equation 1 is extended to be a function of the conditioning images embedding, denotedas (t) (xt, zcond), where zcond is the CLIP embedding of the conditioning image.",
  "Increasing the Conditional Diversity of Synthetic Data": "As discussed in .2 leveraging conditioning from real images to synthesize data results in generatingsamples that are closer to the real data distribution.However, this comes at the cost of limiting thegenerative models ability to produce diverse images. Yet, such diversity is essential to train downstreamclassification models. We propose to apply random dropout on image embedding. Dropout is a techniqueused for preventing over-fitting by randomly setting a fraction of input units to 0 at each update duringtraining time (Srivastava et al., 2014). In this setup, the application of dropout serves a different yet equallycrucial purpose: enhancing the diversity of generated images. By applying random dropout to the embedding of the conditioning image, we effectively introduce variabilityinto the information that guides the generative model.This stochasticity breaks the deterministic linkbetween the conditioning image and the generated sample, thereby promoting diversity in the generatedimages.For instance, if the conditioning image contains a Persian Cat with a specific set of features(e.g., shape, color, background), dropout might nullify some of these features in the embedding, leading",
  "ImageNet-LT: Class-imbalanced Classification": "Dataset.The ImageNet-LongTail (ImageNet-LT) dataset (Liu et al., 2019) is a subset of the originalImageNet (Deng et al., 2009) consisting of 115.8K images distributed non-uniformly across 1,000 classes. Inthis dataset, the number of images per class ranges from a minimum of 5 to a maximum of 1,280. However,the test and validation sets are balanced. In line with related literature (Shin et al., 2023), our goal isto synthesize missing data points in a way that, when combined with the real data, results in a uniformdistribution of examples across all classes. Experimental setup. We leverage the pre-trained state-of-the-art image-and-text conditional LDM v2-1-unclip (Rombach et al., 2022) to sample from. We adopt the widely used ResNext50 architecture as well as theViT-B16 model as the classifiers for our experiments on ImageNet-LT. For ResNext50, our classifier is trainedfor 150 epochs, for ViT-B models, the classifier is trained with real data for a total of 100 epochs and thenfine-tuned using real and synthetic data for another 10 epochs. To improve model scaling with synthetic data,we modify the training process to include 50% real and 50% synthetic samples in each mini-batch. 3 We applya balanced mini-batch approach when training all LDM methods. We also use the balanced Softmax (Renet al., 2020) loss when training the classifier. For additional experimental details see Appendix F.",
  "Places-LT: Class-imbalanced Classification": "Dataset. To further study the effect of feed-back guidance on different datasets, we study the Places-Longtailed dataset (Liu et al., 2019). This dataset consists of 365 classes where the minimum number of examplesin a class is 5 and the maximum is 4980. However, test and validation sets are balanced across classes.Similar to ImageNet-LT, we aim to synthesize data points in a way that, when combined with the real data,results in a uniform distribution across all classes. Experimental setup. We leverage the pre-trained state-of-the-art image-and-text conditional LDM v2-1-unclip (Rombach et al., 2022) to sample from. We follow the common practice in the literature (Kang et al.,2020; Liu et al., 2019) and use a pretrained ResNet-152. We apply two stages of training (Ren et al., 2020).Stage one where the model is trained for 30 epochs. Once the base model is obtained, we further fine-tunethe last layer of the model for 10 epochs using Meta Sampler and Balanced Softmax (Ren et al., 2020). Metrics. Similar to ImageNet-LT, we report the overall average accuracy as well as the stratified accuracyacross classes Many (any class with over 100 samples), Medium (any class with 100-20 samples), and Few(any class with less than 20 samples). Baselines. We compare against previous methods that do not use synthetic data as well as the recentlyproposed Fill-Up (Shin et al., 2023) that uses synthetic data. We achieve state of the art results overall aswell as on classes medium, and few. When leveraging synthetic data, we balance Places-LT by generatingas many samples as required to obtain 4980 examples per class. Discussion. summarizes the results. We observe that using synthetic data increases the overallperformance. Comparing Fill-up and Feedback Guidance, we see that using any type of feedback guidancegreatly boosts the performance on classes Few with Entropy out-performing our feedback criteria.",
  "NICO++: Group-imbalanced Classification": "Dataset. We follow the sub-population shift setup of NICO++(Zhang et al., 2023; Yang et al., 2023) whichcontains 62,657 training examples, 8,726 validation and 17,483 test examples.This dataset contains 60classes of animals and objects within 6 different contexts (autumn, dim, grass, outdoor, rock, water). Thepair of class-context is called a group, and the dataset is imbalanced accross groups. In the training set, themaximum number of examples in a group is 811 and the minimum is 0. For synthetic samples generatedusing our framework see . Experimental setup.We again leverage the pre-trained state-of-the-art image-and-text conditionalLDM v2-1-unclip (Rombach et al., 2022) as high performant generative model to sample from. Since somegroups in the dataset do not contain any real examples, we cannot condition the LDM model on randomimages from group, and so instead, we condition the LDM on random in-class examples. We adopt theResNet50 (He et al., 2016) architecture as the classifier, given its ubiquitous use in prior literature. Foreach baseline, we train the classifier with five different random seeds.",
  "Metrics. Following prior work on sub-population shift (Yang et al., 2023; Sagawa et al., 2019), we reportworst-group accuracy (WGA) as the benchmark metric. We also report overall accuracy": "Baselines. We compare our framework against the NICO++ benchmarks (Zhang et al., 2023; Yang et al.,2023). These state-of-the-art methods may leverage data augmentation but do not rely on synthetic datafrom generative models. We also consider a vanilla LDM baselines conditioned on text prompt, and reportresults for all three criteria. We generate the text prompts as class-label in context. We balance theNICO++ dataset such that each group has 811 samples, overall we generate 229k samples. Discussion. presents the average performance across five random seeds of our method in contrastwith previous works.As shown in the table, our method achieves remarkable improvements over priorart which does not leverage synthetic data from generative models.More precisely, we observe notableWGA improvements of 6% over the best previously reported results on the ResNet architecture. Whencomparing against baselines which do leverage synthetic data from state-of-the-art generative models, ourframework remains competitive in terms of average accuracy, and importantly, surpasses the ERM baselinein terms of WGA by over 14%. The improvements over LDM further emphasize the benefit of generatingsamples that are close to the real data distribution, are diverse and useful when leveraging generated datafor representation learning. Notably, the improvements achieved by our framework are observed for all theexplored criteria, although entropy consistently yields the best results. Also note that our framework tackles the group-imbalanced problem from the data perspective. Any algo-rithmic approach such as Bsoftmax (Ren et al., 2020), IRM (Arjovsky et al., 2019), or GroupDRO (Sagawaet al., 2019) can be applied on top of our approach.",
  "Ablations": "To validate the effect of dual image-text conditioning, dropout on the image conditioning embedding, andfeedback-guidance, we perform an ablation study and report Frchet Inception Distance (FID) (Heusel et al.,2017), density and coverage (Naeem et al., 2020), and average accuracy overall and on the classes Few. FIDand density serve as a proxy to measure how close the generated samples are to the real data distribution.Coverage serves as proxy for diversity, and accuracy improvement for usefulness. FID, density and coverageare computed by generating 20 samples per class and using the ImageNet-LT validation set (20,000 samples)as reference. The accuracies are computed on the ImageNet-LT validation set. As shown in the ,leveraging the vanilla sampling strategy of an LDM conditioned on text only (row 1) results in the worseperformance across metrics. By leveraging image and text conditioning simultaneously (row 2) , we improveboth FID and density, suggesting that generated samples are closer to the ImageNet-LT validation set. Whenapplying dropout to the image embedding (row 3), we observe a positive effect on both FID and coverage,indicating a higher diversity of the generated samples. Finally, when adding feedback signals (rows 46), wenotice the highest accuracy improvements (comparing to the model trained only on real data) both on average(except for hardness) and on the classes Few, highlighting the importance of leveraging feedback-guidance toimprove the usefulness of the samples for representation learning downstream tasks. It is important to notethat quality and diversity metrics such as FID, density and coverage may not be reflective of the usefulnessof the generated synthetic samples (compare Hardness row with the Entropy row in ).",
  "Conclusion and Discussion": "We introduced a framework that leverages a pre-trained classifier together with a state-of-the-art text-and-image generative model to extend challenging long-tailed datasets with useful, diverse synthetic samplesthat are close to the real data distribution, with the goal of improving on downstream classification tasks.We achieved usefulness by incorporating feedback signals from the downstream classifier into the generativemodel; we employed dual image-text conditioning to generate samples that are close to the real data manifoldand we improved the diversity of the generated samples by applying dropout to the image conditioningembedding.We substantiated the effect of each of the components in our framework through ablationstudies.We validated the proposed framework on ImageNet-LT, Places-LT and NICO++, consistentlysurpassing prior art with notable improvements. Overall, our framework provides a data approach for imbalanced classification tasks, where accessing realdata is expensive or infeasible. Using an off-the-shelf pre-trained diffusion model can be viewed as accessinga compressed form of large-scale data. Additionally, our feedback-guided sampling technique enables theextraction of useful information for the task at hand. It is important to note, that our approach is com-",
  "plementary to any existing algorithmic approaches that target imbalanced classification. One can combineboth data and algorithmic solutions to a given problem to further improve the results": "Limitations. Our approach inherits the limitations of the state-of-the-art generative models, and the imagerealism and representation diversity are determined by the abilities of the generative model our guidancemechanism can only explore the data manifold already captured by the model. Future work. In our work, we only consider one feedback cycle from a fully trained classifier. We leavefor future exploration a setup where the feedback from the classifier is being sent to the generator onlinewhile the representation learning model is being trained. Furthermore, any differentiable criterion functioncan be applied in the sampling. For example one can consider an active learning acquisition function as afeedback criterion function (Gal et al., 2017; Cho et al., 2022a).",
  "Broader Impact Statement": "Generative models are known to come with various risks and biases. We highlight that the negative impactsassociated with these large scale diffusion models underscore the need for robust ethical guidelines, regula-tory oversight, and technological safeguards. In this work, we do not directly address or focus on the biasesthat may exist in the generations of the diffusion model such as ethical concerns, or societal biases. However,we leverage large-scale pretrained generative models and propose an inference-time intervention to generateuseful synthetic examples for imbalanced classification problems. From the classification perspective, weproposed a method aimed at decreasing biases due to long-tail data distribution with a positive impact onmodel fairness. It is important to note that while our approach contributes to mitigating certain biases, itdoes not eliminate all potential biases of generative process. We advocate for the continued development ofcomprehensive ethical frameworks and regulatory measures to address the broader impact of using gener-ative models in different applications. Our work is a step towards improving fairness in machine learning,understanding that it is part of an ongoing effort to build more responsible AI.",
  "Prafulla Dhariwal and Alex Nichol. Diffusion models beat gans on image synthesis. In Conference on NeuralInformation Processing Systems (NeurIPS), 2021": "Fei Du, Peng Yang, Qi Jia, Fengtao Nan, Xiaoting Chen, and Yun Yang. Global and local mixture consistencycumulative learning for long-tailed visual recognitions. In Proceedings of the IEEE/CVF Conference onComputer Vision and Pattern Recognition, pp. 1581415823, 2023. Lisa Dunlap, Alyssa Umino, Han Zhang, Jiezhi Yang, Joseph E Gonzalez, and Trevor Darrell. Diversify yourvision datasets with automatic diffusion-based augmentation. arXiv preprint arXiv:2305.16289, 2023.",
  "Yarin Gal, Riashat Islam, and Zoubin Ghahramani. Deep bayesian active learning with image data. InInternational conference on machine learning, pp. 11831192. PMLR, 2017": "Jindong Gu, Zhen Han, Shuo Chen, Ahmad Beirami, Bailan He, Gengyuan Zhang, Ruotong Liao, Yao Qin,Volker Tresp, and Philip Torr. A systematic survey of prompt engineering on vision-language foundationmodels. arXiv preprint arXiv:2307.12980, 2023. Melissa Hall, Candace Ross, Adina Williams, Nicolas Carion, Michal Drozdzal, and Adriana Romero Soriano.Dig in: Evaluating disparities in image generations with indicators for geographic diversity, 2023.",
  "Jonathan Ho, Ajay Jain, and Pieter Abbeel. Denoising diffusion probabilistic models. In Conference onNeural Information Processing Systems (NeurIPS), 2020": "Yong Hu, Dongfa Guo, Zengwei Fan, Chen Dong, Qiuhong Huang, Shengkai Xie, Guifang Liu, Jing Tan,Boping Li, Qiwei Xie, et al. An improved algorithm for imbalanced data and small sample size classification.Journal of Data Analysis and Information Processing, 3(03):27, 2015. Yushi Hu, Benlin Liu, Jungo Kasai, Yizhong Wang, Mari Ostendorf, Ranjay Krishna, and Noah A Smith.Tifa: Accurate and interpretable text-to-image faithfulness evaluation with question answering. arXivpreprint arXiv:2303.11897, 2023. Badr Youbi Idrissi, Martin Arjovsky, Mohammad Pezeshki, and David Lopez-Paz. Simple data balancingachieves competitive worst-group-accuracy. In Conference on Causal Learning and Reasoning, pp. 336351.PMLR, 2022.",
  "Ali Jahanian, Xavier Puig, Yonglong Tian, and Phillip Isola. Generative models as a data source for multiviewrepresentation learning. arXiv preprint arXiv:2106.05258, 2021": "Bingyi Kang, Saining Xie, Marcus Rohrbach, Zhicheng Yan, Albert Gordo, Jiashi Feng, and Yannis Kalan-tidis. Decoupling representation and classifier for long-tailed recognition. arXiv preprint arXiv:1910.09217,2019. Bingyi Kang, Saining Xie, Marcus Rohrbach, Zhicheng Yan, Albert Gordo, Jiashi Feng, and Yannis Kalan-tidis. Decoupling Representation and Classifier for Long-Tailed Recognition. In International Conferenceon Learning Representations (ICLR), 2020. Minguk Kang, Jun-Yan Zhu, Richard Zhang, Jaesik Park, Eli Shechtman, Sylvain Paris, and Taesung Park.Scaling up GANs for Text-to-Image Synthesis. In Proceedings of the IEEE Conference on Computer Visionand Pattern Recognition (CVPR), 2023.",
  "Tsung-Yi Lin, Priya Goyal, Ross Girshick, Kaiming He, and Piotr Dollr.Focal loss for dense objectdetection. In IEEE International Conference on Computer Vision (ICCV), 2017": "Evan Z Liu, Behzad Haghgoo, Annie S Chen, Aditi Raghunathan, Pang Wei Koh, Shiori Sagawa, Percy Liang,and Chelsea Finn. Just train twice: Improving group robustness without training group information. InInternational Conference on Machine Learning, pp. 67816792. PMLR, 2021. Ziwei Liu, Zhongqi Miao, Xiaohang Zhan, Jiayun Wang, Boqing Gong, and Stella X Yu. Large-scale long-tailed recognition in an open world. In IEEE Conference on Computer Vision and Pattern Recognition(CVPR), 2019.",
  "Muhammad Ferjad Naeem, Seong Joon Oh, Youngjung Uh, Yunjey Choi, and Jaejun Yoo. Reliable fidelityand diversity metrics for generative models. 2020": "Alexander Quinn Nichol, Prafulla Dhariwal, Aditya Ramesh, Pranav Shyam, Pamela Mishkin, Bob Mcgrew,Ilya Sutskever, and Mark Chen.GLIDE: Towards Photorealistic Image Generation and Editing withText-Guided Diffusion Models. In International Conference on Machine Learning (ICML), 2022. Seulki Park, Youngkyu Hong, Byeongho Heo, Sangdoo Yun, and Jin Young Choi. The majority can helpthe minority: Context-rich minority oversampling for long-tailed classification. In IEEE Conference onComputer Vision and Pattern Recognition (CVPR), 2022.",
  "Xingchao Peng, Ben Usman, Neela Kaushik, Judy Hoffman, Dequan Wang, and Kate Saenko. Visda: Thevisual domain adaptation challenge. arXiv preprint arXiv:1710.06924, 2017": "Mohammad Pezeshki, Oumar Kaba, Yoshua Bengio, Aaron C Courville, Doina Precup, and GuillaumeLajoie. Gradient starvation: A learning proclivity in neural networks. Advances in Neural InformationProcessing Systems, 34:12561272, 2021. Alec Radford, Jong Wook Kim, Chris Hallacy, Aditya Ramesh, Gabriel Goh, Sandhini Agarwal, GirishSastry, Amanda Askell, Pamela Mishkin, Jack Clark, et al. Learning transferable visual models fromnatural language supervision. In International conference on machine learning, pp. 87488763. PMLR,2021. Aditya Ramesh, Mikhail Pavlov, Gabriel Goh, Scott Gray, Chelsea Voss, Alec Radford, Mark Chen, and IlyaSutskever. Zero-shot text-to-image generation. In International Conference on Machine Learning (ICML),2021.",
  "Serim Ryou, Seong-Gyun Jeong, and Pietro Perona. Anchor loss: Modulating loss scale based on predictiondifficulty. In IEEE International Conference on Computer Vision (ICCV), 2019": "Shiori Sagawa, Pang Wei Koh, Tatsunori B Hashimoto, and Percy Liang. Distributionally robust neuralnetworks for group shifts: On the importance of regularization for worst-case generalization. arXiv preprintarXiv:1911.08731, 2019. Chitwan Saharia, William Chan, Saurabh Saxena, Lala Li, Jay Whang, Emily Denton, Seyed Kamyar SeyedGhasemipour, Burcu Karagol Ayan, S Sara Mahdavi, Rapha Gontijo Lopes, et al. Photorealistic Text-to-Image Diffusion Models with Deep Language Understanding. arXiv preprint arXiv:2205.11487, 2022.",
  "Yang Song, Prafulla Dhariwal, Mark Chen, and Ilya Sutskever. Consistency models. 2023": "Ben Sorscher, Robert Geirhos, Shashank Shekhar, Surya Ganguli, and Ari Morcos. Beyond neural scalinglaws: beating power law scaling via data pruning. Advances in Neural Information Processing Systems,35:1952319536, 2022. Nitish Srivastava, Geoffrey Hinton, Alex Krizhevsky, Ilya Sutskever, and Ruslan Salakhutdinov. Dropout: asimple way to prevent neural networks from overfitting. The journal of machine learning research, 15(1):19291958, 2014. Changyao Tian, Wenhai Wang, Xizhou Zhu, Jifeng Dai, and Yu Qiao. Vl-ltr: Learning class-wise visual-linguistic representation for long-tailed visual recognition. In European Conference on Computer Vision(ECCV), 2022.",
  "Yuzhe Yang, Haoran Zhang, Dina Katabi, and Marzyeh Ghassemi.Change is hard: A closer look atsubpopulation shift. arXiv preprint arXiv:2302.12254, 2023": "Huaxiu Yao, Yu Wang, Sai Li, Linjun Zhang, Weixin Liang, James Zou, and Chelsea Finn. Improving out-of-distribution robustness via selective augmentation. In International Conference on Machine Learning,pp. 2540725437. PMLR, 2022. Michal Yarom, Yonatan Bitton, Soravit Changpinyo, Roee Aharoni, Jonathan Herzig, Oran Lang, EranOfek, and Idan Szpektor. What you see is what you read? improving text-image alignment evaluation.arXiv preprint arXiv:2305.10400, 2023.",
  "A.2A Toy 2-dimensional Example of Criteria Guidance": "illustrates the experimental results of using a simple 2-dimensional dataset for a classification task.The dataset contains two classes represented by blue and red data points.Within each class, the dataconsists of two modes: the majority mode, containing 90% of the data points, and the minority mode, whichholds the remaining 10%. We initially train a diffusion model on this dataset. Sampling from the traineddiffusion model generates synthetic data that closely follows the distribution of the original training data,showing an imbalance between the modes of each class (see (b)). To encourage generation of data from the mode with lower density, we introduce a binary variable h intothe model. In this context, h = 0 indicates the minority mode, while h = 1 signifies the majority mode.Following the criteria guidance discussed in .1.1, without retraining the model, we modify thesampling process so that the generator is guided towards generating samples of higher entropy. To thatend, we train a linear classifier for several epochs until it effectively classifies the majority mode, but thedecision boundary intersects the minority mode, resulting in misclassification of those points. Leveragingthe classifiers uncertainty around this decision boundary, we guide the generative model to produce higherentropy samples. This results in more synthetic samples being generated from the minority modes of eachclass (see (c)). Integrating this synthetic data with the original data produces a more uniform distribution across modes,leading to a more balanced classifier. This is desirable in our context as it mitigates the biases inherent inthe original dataset and improves the models generalization.",
  "BSamples Stylistic Bias": "Stylistic Bias is one of the challenges in synthetic data generation where the generative model consistentlyproduces images with a particular style for some prompts, which does not correspond to the style of the realdata. This results in a mismatch between synthetic and real data, potentially impacting the performance ofmachine learning models trained on such data.",
  "Decision boundary": ": Experimental results on a 2-dimensional classification dataset showcasing the effect of feedback-guided sampling. Panel (a): Real data consists of two classes represented by blue and red data points.Within each class, two modes are identified: a majority mode comprising 90% of the data and a minoritymode containing the remaining 10%. Panel (b): The synthetic data generated by regular sampling of a DDPMreplicates the imbalances of the original dataset. Panel (c): Synthetic data generated after modifying thediffusion model guided by feedback from a linear classifier. Feedback-guided sampling leads to more samplesbeing generated from the minority modes. Combining with real data, it results in more balanced data withincreased representation from the minority mode, ultimately improving classifier performance.",
  "(c)": ": Here we plot more samples from Imagenet-LT where stylistic bias appears in synthetic generations.This scenario arises when the generative model produces images with a particular style for some prompts,which does not match the style of the real data. See .2 for more details. (a) real samples from classtriceratops, (b) synthetic samples using LDM, (c) synthetic samples with image and text conditioning.",
  "DImpact of the number of generated images": "shows the performances on a classifier trained on ImageNet-LT when using a different amount ofgenerated images. We show that adding generated synthetic data significantly help to increase the overallperformance of the model. In addition, we observe significant gain on the few classes which highlight thatgenerated images are well-suited for imbalanced real data scenarios.",
  "LDM-FG Entropy": ": Test accuracy depending on the number of generated synthetic data used to train the classifier.The first curve shows the accuracy on the class Few, while the second one shows the accuracy on the classMedium and the last one shows the accuracy on class Many. Our method significantly outperforms Fill-Up(Shin et al., 2023) while using less synthetic data.",
  "EImpact of using balanced softmax with synthetic data": "In our experiments, we have used balanced softmax to train our classifier to increase the performances onclass Few. We also ran experiments using a weighted average of a traditional cross-entropy loss using balancedsoftmax with the same loss without balanced softmax. In this experiment, we added a scalar coefficient which controls the weight of the balanced softmax loss in contrast to the standard loss. In , we plotthe test accuracy with respect to this balanced softmax weight. Without balanced softmax, the accuracy onthe class many is extremely high while the accuracy on class few is much lower. However by increasing thebalanced softmax coefficient, we significantly increase the performances on class few and medium as well asthe overall accuracy. However, this comes at the price of lower performance for classes Many.",
  "FAdditional Experiments and Details": "General setup in sample generationWe use the LDM v2-1-unclip (Rombach et al., 2022) as the state-of-the-art latent diffusion model that supports dual image-text conditioning. We use a pretrained classifieron the real data to guide the sampling process of the LDM. For Imagenet-LT, the classifier is trained usingERM with learning rate of 0.1 (decaying) and weight-decay of 0.0005 and batch-size of 32. For NICO++ weuse a pre-trained classifier on Imagnet and then fine-tune it on NICO++.",
  ": Test accuracy on Few, Medium, Many and Overall with respect to the balanced softmax coefficient.All the models use 1.3M synthetic samples": "We apply 30 steps of reverse diffusion during the sampling.To apply different criteria in the samplingprocess, we use the pretrained classifier on the real data. For lower computational complexity, we use float16datatype in PyTorch. Furthermore, we apply the gradient of the criterion function every 5 steps. So for30 reverse steps, we only compute and apply the criterion 6 times. Through experiments we find that 5 isoptimal as the generated samples look very similar to applying the criterion in every step. For the hardnesscriterion in Eq. 3.1.1 where we need the y and 1yfor each class, we pre-compute these values. Wecompute the mean and covariance inverse of the feature representation of the classifier over all real samples.These values are then loaded and used during the sampling process.",
  "F.1Computational Cost": "In this work, we use state of the art generative models to synthesize samples for an imbalanced classificationproblem. Since we leverage feedback from the classifier to the generative model, our framework requires apretrained classifier, once the samples are generated, the classifier is retrained from scratch. Depending onthe size of the dataset and the architecture used for the classifier, and the number of hyper-parameters totune the classifier, the computational cost varies. The generation time for synthetics samples are studiedmore carefully below. However, the dataset is generated only once and it can be reused for tuning theclassifier in the second stage. For generations, we leverage DDIM sampling and we apply the feedback guidance every 5 steps during thesampling process. We calculate the average wall-clock time (in seconds) per sample generation. Resultsare reported in , on an average of 1000 samples, computed on the same model and the same GPUmachine (V100) without batch-generation. Faster GPU machines with larger RAM result in faster samplegeneration. Note that results are reported per sample generation, one can potentially run the sampling process inparallel. We consider the improvement in the sampling complexity as a future direction of research. Severalapproaches can be taken to improve the sampling time complexity:",
  "F.2ImageNet-LT": "We follow the setup in previous work (Kang et al., 2019) and use a ResNext50 architecture. We apply thebalanced softmax for all the LDM models reported for Imagenet-LT. We train the classifier for 150 epochswith a batch size of 512. We also use standard data augmentations such a random cropping, color-jittering,blur and grayscale during training. Furthermore, below we provide an ablation study on combining different criteria. Specifically, we study thescenario where each sample is generated with 0.33 probability from each of the three given criteria (Entropy,Loss and Hardness). We upsample the Imagenet-LT dataset to 1.3M samples. As seen in , entropyoutperforms other criteria and the combination of criteria.",
  "F.3NICO++": "We follow the setup in previous work (Yang et al., 2023), where a pre-trained ResNet50 model on ImageNetis used for all the methods. We assume access to the attributes labels (contexts). For training our LDMmodel we only apply ERM without any extra algorithmic changes. We use the SGD with momentum of 0.9and train for 50 epochs. We apply standard data augmentation such as resize and center crop and applyImageNet statistics normalization. For every method, we try 10 sets of hyper-parameters (learning rate,batch-size5) (Yang et al., 2023). We perform model selection and early stopping based on average validationaccuracy. We then train the selected model on 5 random seeds and report the test performance. In we provide an ablation analysis on the hyper-parameter that controls the strength of thefeedback guidance. The rest of hyper-parameters in the generative model or the classifier are tuned for everyset-up. As it can be seen, among the values that we tried, all improved the worst-group-accuracy comparedto the case where = 0, however the best results are achieved with =0.03.",
  "= 032.66 1.33 = 0.0145.60 2.63 = 0.0349.20 0.97 = 0.0542.10 1.84": "30 epochs. Once the base model is obtained, we further fine-tune the last layer of the model for 10 epochsusing Meta Sampler and Balanced Softmax (Ren et al., 2020). We use the SGD optimizer with a learningrate of 0.0028, momentum of 0.9 and weight decay 0.0005 and batch-size of 512. During generation, weapply dropout on image-embeddings with 0.5 probability. Furthermore, we apply 30 steps of DDIM withclip-guidance scale of 3 and feedback guidance scale of 0.03."
}