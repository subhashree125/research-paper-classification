{
  "Abstract": "A classic inferential problem in statistics is the goodness-of-fit (GOF) test. Performing suchtests can be challenging when the hypothesized parametric model has an intractable like-lihood and its distributional form is not available. Bayesian methods for GOF testing canbe appealing due to their ability to incorporate expert knowledge through prior distribu-tions. However, standard Bayesian methods for this test often require strong distributionalassumptions on the data and their relevant parameters. To address this issue, we propose asemi-Bayesian nonparametric (semi-BNP) procedure based on the maximum mean discrep-ancy (MMD) measure that can be applied to the GOF test. We introduce a novel Bayesianestimator for the MMD, which enables the development of a measure-based hypothesis testfor intractable models. Through extensive experiments, we demonstrate that our proposedtest outperforms frequentist MMD-based methods by achieving a lower false rejection andacceptance rate of the null hypothesis. Furthermore, we showcase the versatility of our ap-proach by embedding the proposed estimator within a generative adversarial network (GAN)framework. It facilitates a robust BNP learning approach as another significant applicationof our method. With our BNP procedure, this new GAN approach can enhance samplediversity and improve inferential accuracy compared to traditional techniques.",
  "Introduction": "Goodness-of-fit (GOF) tests are commonly used to evaluate an empirical data set against a hypothesizedparametric model. However, there are cases when the likelihood of the parametric model is intractable and theexplicit form of the model distribution is unavailable, making it challenging to directly assess the models fit.One such example is the case of deep generative models, where independent samples can be generated, but therequired likelihood function needed for traditional GOF tests is intractable. In such situations, a potentialsolution is to use the the maximum mean discrepancy (MMD) measure as an alternative approach forconducting GOF tests (Gretton et al., 2012a; Key et al., 2021) in addition to some existing kernelized methods(Liu et al., 2016). The MMD is a metric on the space of probability distributions and is commonly used inhypothesis testing to quantify the difference between the distribution of the data and the hypothesized model.",
  "Published in Transactions on Machine Learning Research (09/2024)": "further reduce the chance of mode collapse and the 3D semi-BNP GAN will reduce the blurriness of thegenerated samples that may be caused by using the VAE. In future work, our model will be able to generate3D images and, hence, increase the resolution of images, especially for MRI images. We hope that our futurework will make an impact in the field of medical imaging.",
  "Maximum Mean Discrepancy Measure": "For a given data space X, consider the random variables X and Y, drawn from distributions F1 and F2respectively. Here, F1 and F2 belong to B(X), which represents the set of Borel probability distributions onX. We consider the discrepancy d : B(X) B(X) [0, ) through the integral pseudo-probability metric(IPM) (Mller, 1997), defined as shown in (1). The class of functions F is designed to be rich enough todistinguish between F1 and F2, and restrictive enough to provide accurate estimates based on a finite sample.",
  "MMD2(F1, F2) = ||F1 F2||2Hk = EF1[k(X, X)] 2EF1,F2[k(X, Y)] + EF2[k(Y, Y)].(2)": "Note that MMD2(F1, F2) = 0 if and only if F1 = F2, when Hk is a universal RKHS defined on a compactmetric space X and k(, ) is continuous (Gretton et al., 2012a, Theorem 5). In practice, distributions F1and F2 are not accessible, and then the biased, empirical estimator of (2) (V-statistic) is calculated usingempirical distributions F1,n and F2,m as",
  "where X1, . . . , Xn is a sample from F1 and Y1, . . . , Ym is a sample generated from F2": "Recently, Key et al. (2021) proposed a GOF test using the MMD measure when the hypothesized modelbelongs to a parametric family of intractable models. It was proposed to be employed in training generativemodels such as toggle-switch models and GANs. There are also numerous generative models closely linkedto the implementation of MMD in GANs, which can be found in Briol et al. (2019), Niu et al. (2023), Oates(2022), and Bharti et al. (2023). These models offer distinct MMD estimators that are specifically designedto further improve the MMDs capability in estimating the generators parameters.",
  "Bayesian Methods: Approximate Bayesian Computation, the Dirichlet Process and BayesianNonparametric Learning": "Previous work in simulation-based inference has largely focused on applying discrepancy measures from afrequentist nonparametric (FNP) perspective. A Bayesian perspective on simulation-based inference involvesa similar methodology, using approximate Bayesian computation (ABC) to estimate the model parameters viasimulation (Beaumont et al., 2002). In ABC, we first sample a proposal by sampling from a prior distributionplaced on the parameter space of the generative model (Step 1). Rather than inferring parameters directlyfrom the posterior distribution, we compare the summary statistics of the simulated data, given the currentstate of the parameters, with those of the observed data using a discrepancy measure (Step 2). The simulatedparameter values corresponding to the accepted summary statistics are retained if the distance falls withina predetermined threshold (Step 3). Identifying informative summary statistics in ABC is a challenging task and it depends on the specificapplication of the data being analyzed, such as the mean effective heterozygosity or the mean of variancein repeat numbers in genetic populations (Blum & Franois, 2010; Csillry et al., 2012). An inappropriatechoice may result in poor posterior inference from the data (Robert et al., 2011; Aeschbacher et al., 2012).One solution proposed by Park et al. (2016) is to use the MMD metric between simulated and real datadistributions to avoid manually selecting the summary statistics. However, as the threshold approaches zero,ABC tends to the standard Bayesian posterior, which is susceptible to model misspecification and lacksrobustness (Dellaporta et al., 2022)1. To address these two issues, generalized Bayesian inference (GBI)proposes an alternative method by replacing the likelihood in the posterior distribution with the exponentialof a robust loss function. For a detailed exploration, Jewson et al. (2018) offers various examples, including the use of exponential of theHellinger divergence within the GBI. Within the GBI framework, there are two prominent procedures that use",
  "which is visually depicted in Dellaporta et al. (2022, ).In particular, Dellaporta et al. (2022)considered F pos as the DP posterior and as the MMD measure": "The DP, introduced by Ferguson (1973), is a commonly used prior in Bayesian nonparametric methods.It can be viewed as an infinite-dimensional generalization of the Dirichlet distribution constructed aroundH (the base measure), a fixed probability measure, whose variation is controlled by a (the concentrationparameter), a positive real number. To formally define the DP, consider a space X with a -algebra A ofsubsets of X. For a base measure G on (X, A) and a > 0, a random probability measure F = {F(A) : A A}is called a DP on (X, A), denoted by F pri := (F DP(a, H)) , if for every measurable partition A1, . . . , Akof X with k 2, the joint distribution of the vector (F(A1), . . . , F(Ak)) has the Dirichlet distribution withparameters (aH(A1), . . . , aH(Ak)). It is assumed that H(Aj) = 0 implies F(Aj) = 0 with probability one. One of the most important properties of the DP is the conjugacy propertywhen the sample X1:n =(X1, . . . , Xn) is drawn from F DP(a, H), the posterior distribution of F given X1:n, denoted by F pos, isalso a DP with concentration parameter a + n and base measure",
  "H = a(a + n)1H + n(a + n)1Fn,": "where Fn denotes the empirical cumulative distribution function (ECDF) of the sample X1:n. Note that,H is a convex combination of the base measure H and Fn. A guideline for choosing the hyperparametersa and H for the test of equality distributions will be covered in . In previous work, there are several BNP GOF tests (Al-Labadi & Evans, 2018; Al-Labadi et al., 2021a;b), aswell as two-sample tests (Al-Labadi & Zarepour, 2017; Al-Labadi, 2021) and a multi-sample test (Al-Labadiet al., 2022a), that are closely connected to the posterior-based distance estimation employed in the BNPLprocedure of Dellaporta et al. (2022). These methods are developed using different discrepancy measures tocompare the distance between DP posteriors, placed on unknown distributions, with the corresponding onebetween DP priors. However, unlike our proposed method, none of them employ the MMD measure. Sethuraman (1994) proposed an infinite series representation as an alternative definition for DP. The con-struction of Sethuraman (1994) is known as the stick-breaking representation and is a popularly used methodin DP inference. Particularly, for a sequence of identically distributed (i.i.d.) random variables {i}i1 fromBeta(1, a), let w1 = 1, and wi = ii1j=1(1 j), for i 2. Then, the stick-breaking representation isgiven by FSB = i=1 wiYi, where {Yi}i1 is a sequence of i.i.d. random variables from H. However, Zare-pour & Al-Labadi (2012) addressed some difficulties in using these representations. Meanwhile, Ishwaran &",
  "i=1Ji,NYi,": "where (J1,N, . . . , JN,N) Dirichlet(a/N, . . . , a/N), and Yii.i.d.H. Ishwaran & Zarepour (2002) showedthat {FN}N=1 converges in distribution to F, where FN and F are random values in the space M1(R) ofprobability measures on R endowed with the topology of weak convergence. Thus, to generate {Ji,N}Ni=1put Ji,N = i,N/ Ni=1 i,N, where {i,N}Ni=1 is a sequence of i.i.d.Gamma(a/N, 1) random variablesindependent of {Yi}Ni=1. This form of approximation leads to some results in subsequent sections.",
  "A Semi-BNP MMD Estimator": "This section introduces our semi-BNP estimator for approximating the MMD measure. We consider a sce-nario where F1 represents a completely unknown distribution, while F2 represents an intractable parametricdistribution with a complex generating process. For a given sample Y1, . . . , Ym from F2 and by assumingF pri1:= (F1 DP(a, H)) for a non-negative value a and a fixed probability measure H, we propose theprior-based MMD estimator as",
  ",t=1k(Y, Yt),(5)": "where (J1,N, . . . , JN,N) is sampled from Dirichlet(a/N, . . . , a/N), V1, . . . , VNi.i.d. H, and N is the numberof terms in the DP approximation N=1 J,NV proposed by Ishwaran & Zarepour (2002). Since we onlyimpose the DP prior on the distribution of the real data, we refer to the approach as a semi-BNP procedure. Theorem 1 For a non-negative real value a and fixed probability distribution H, let F pri1:= (F1 DP(a, H)), HN be the ECDF corresponding to H, and k(, ) be any continuous kernel function with featurespace corresponding to a universal RKHS defined on a compact metric space X. Assume that |k(z, z)| < K,for any z, z Rd. Then,i. MMD2BNP(F pri1,N, F2,m)a.s. MMD2(HN, F2,m), as a ,ii. E(MMD2BNP(F pri1,N, F2,m)) MMD2(H, F2) as a , N , and m ,iii. E(MMD2BNP(F pri1,N, F2,m)) < MMD2(H, F2) + 3K, for any N, m N and a R+,where a.s. denotes the almost surely convergence, N denotes the natural numbers and R+ denotes thepositive real numbers.",
  "ii. for any choice of a and H, E(MMD2BNP(F pos1,N, F2,m)) 0, if and only if F1 = F2, as N , andn , and m": "Besides the theoretical result presented in this section, we provided the density function of the posterior-based estimator (6) compared to the baseline (3) in in the Appendix. This comparison, made assample sizes approach infinity under the null hypothesis, helps to examine and understand the asymptoticdistribution. The results indicated faster density convergence around zero for our proposed estimator.",
  "using the RB3 ratio, introduced by Evans (2015), as the Bayesian evidence": "By relating our problem to RB inference, with = MMD2(F1, F2) and 0 = 0, the RB ratio measuresthe change in belief regarding the true value of 0, from a priori to a posteriori, given an observed samplex1, . . . , xn from F1. It can be expressed by",
  "StrMMD2(0 | x1:n) = MMD2RBMMD2(t | x1:n) RBMMD2(0 | x1:n) | x1:n,(9)": "where, MMD2(|x1:n) is the posterior probability measure corresponding to the density MMD2(|x1:n). When(7) is false, a small value of (9) provides strong evidence against 0, whereas a large value suggests weakevidence against 0. Conversely, when (7) is true, a small value of (9) indicates weak evidence in favor of0, while a large value suggests strong evidence in favor of 0. Particular attention should be paid here tothe computation of (8) and (9). The densities used in (8) do not have explicit forms. Thus, we use theircorresponding ECDF based on sample sizes to estimate (8) and (9), respectively, as",
  "D d(i+1)/Mdi/MMMD2(t|x1:n) dt,": "where D is defined similarly to D by replacing RB and di/M with RB and di/M in D. The following resultfrom Al-Labadi & Evans (2018, Proposition 6) gives the consistency of the proposed test. If H0 is true, thenRBMMD2([0, di0/M)|x1:n)a.s. M/i0(> 1) and RBMMD2([di/M, d(i+1)/M)|x1:n)a.s. 0 for i0 i M 1,as n , which implies that StrMMD2([0, di0/M) | x1:n) converges to 1 almost surely. Otherwise, bothRBMMD2([0, di0/M) | x1:n) and StrMMD2([0, di0/M) | x1:n) converge to 0. The proposed test is suggested to overcome several limitations present in its frequentist counterparts. Ina frequentist test, for a given permissible type I error rate denoted by , the test rejects H0 if the valueof MMD2(F1, F2) is greater than some threshold c. The corresponding p-value for this test can also becomputed by Pr(MMD2(F1, F2) c|H0), which leads the test to reject H0 if it is less than . However, Liet al. (2017) noted that if MMD2(F1, F2) is not significantly larger than c for some finite samples when H0is not true, the null hypothesis H0 is not rejected. Furthermore, there is a trade-off between the permissibletype I error rate and the probability of failing to reject a false null hypothesis (type II error), denotedby , as + 1. Decreasing one error rate inevitably leads to an increase in the other, indicating thatwe cannot arbitrarily drive to type I error rate to zero. Moreover, the p-values are uniformly distributedbetween 0 and 1 under the null hypothesis. In fact, it does not allow evidence for the null, which is one oftheir weaknesses compared to Bayesian criteria in hypothesis testing problems.",
  "Generative Adversarial Networks": "The GAN (Goodfellow et al., 2014) is a machine learning technique used to generate realistic-looking artificialsamples. In this context, the discriminator D can be viewed as a black box that uses a discrepancy measure to differentiate between the real and fake data. Meanwhile, the generator G is trained by optimizing asimpler objective function, given by",
  "arg minW (F, FG),": "where FG represents the distribution of the generator. In fact, D attempts to continuously train G bycomputing distance between F and FG until this distance is negligible, making their difference indistin-guishable. This technique leads to omitting the neural network from D, whose optimization may lead to avanishing gradient. An effective measure of discrepancy for is the MMD, which is a kernel-based measurethat offers several desirable properties such as consistency and robustness in generating samples (Grettonet al., 2012a; Chrief-Abdellatif & Alquier, 2022).",
  "Architecture": "Various GAN architectures can be found in the literature to model complex high-dimensional distributions.However, we consider the original architecture of the generator network in Goodfellow et al. (2014). Specif-ically, we follow the neural network architecture in Goodfellow et al.by setting the generator, G, tobe a multi-layer neural network with parameters , rectified linear units activation function for each hid-den layer, and a sigmoid function for the last layer (output layer). The generator receives a noise vectorU = (U1, . . . , Up) as its input nodes, where p < d, and each element of U is independently drawn from thesame distribution FU.",
  "arg minW MMD2BNP(F posN , FG,m),": "but we now estimate the MMD using our semi-BNP method.In fact, our BNPL procedure implicitlyapproximates samples from the posterior distribution on the parameter by minimizing the posterior-basedMMD estimator. For any differentiable kernel function k(, ), this optimization is performed by computingthe following gradient based on samples from F|X1:n DP(a + n, H), as",
  "Algorithm 2 in the Appendix provides steps for implementing the training": "LetbetheoptimizedparameterofGthatminimizesMMDBNP(F posN , FG,m).SinceMMDBNP(F posN , FG,m) can be viewed as a semi-BNP estimation of (2), it becomes imperative to assessthe accuracy of this estimation, specifically in terms of how effectively the proposed GAN can generaterealistic samples that faithfully represent the true data distribution (generalization error). Furthermore, itis crucial to take into consideration the generators performance in dealing with outliers which includes asmall proportion of observations that deviate from the clean data distribution F0 (robustness). The nextlemma addresses these two concerns. Lemma 4 Let W be the parameter space for G and W be the value that optimizes the objectivefunction (13) and be the true value that minimizes MMD(F, FG). Assume that F DP(a, H) and letk(, ) be any continuous kernel function with feature space corresponding to a universal RKHS defined on acompact metric space X such that |k(z, z)| < K, for any z, z Rd. For a given sample X1, . . . , Xn fromdistribution F:i. Generalization error:",
  "(a + n + N)K(a + n + 1)N": "Lemma 4(ii) demonstrates that despite encountering outlier data, FG and F0 are negligibly different fora sufficiently large sample size. This feature results in the majority of the posterior on the parameter spaceW being distributed on value , which is a desirable outcome of the proposed method. Although the preceding statements investigate properties of the estimated parameters by providing upperbounds for the expectation of the MMD estimator, the next lemma presents stochastic bounds for theestimation error in order to assess the posterior consistency. Lemma 5 Building upon the general assumptions stated in Lemma 4, for a given sample X1, . . . , Xn fromdistribution F in the probability space (X, A, Pr) and any > 0,i. Pr|MMD(F posN , FG,m) MMD(F, FG)| h(n, m, K, ) + |1| + |2| 2 exp2nm",
  "K(n + m)/nm + , 1 = MMD(F posN , FG ) MMD(Fn, FG,m), and 2 =MMD(F, FG ) MMD(F, FG)": "A direct consequence of Lemma 5(ii) is that for a fixed value of a, Pr(MMD(F, FG ) ) 0, as n and N , for any > 0, when MMD(F, FG) = 0 (well-specified case). This implies FG converges inprobability to the data distribution F as the sample size increases in well-specified cases.",
  "N , . . . , a+n": "N ). Our approach offers an advantageover the approximation used in Dellaporta et al. (2022) due to its reduced number of terms, significantlyreducing both computational and theoretical complexity, where our method scales O(N) and Dellaportaet al. scales O(N + n). Additionally, a further difference is that Dellaportas bootstrap procedure needs toquery the loss function B times to simulate B posterior parameters, whereas our procedure does not requirea bootstrap algorithm and we only need to simulate a single parameter. Although their bootstrap procedureis embarrassingly parallelizable, the number of bootstrap samples generally should be a fairly large numberand the typical statistical practitioner does not have access to B cores to truly parallelize the additional costof bootstrap sampling.",
  "Kernel Settings": "In our method, we choose to use the standard radial basis function (RBF) kernel as its feature spacecorresponds to a universal RKHS. For a comprehensive understanding of RBF functions, refer to Section Din the Appendix. Dziugaite et al. (2015); Li et al. (2015) and Li et al. (2017) used the Gaussian kernel intraining MMD-GANs because of its simplicity and good performance. Dziugaite et al. (2015) also evaluatedsome other RBF kernels such as the Laplacian and rational quadratic kernels to compare the results of theMMD-GANs with those obtained based on using Gaussian kernels. They found the best performance byapplying the Gaussian kernel in the MMD cost function. Hence, we consider the Gaussian kernel function in our proposed procedure.To choose the bandwidthparameter , we follow the idea of considering a set of fixed values of s such as {1, . . . , T }, then computethe mixture of Gaussian kernels k(, ) = Tt=1 kGt(, ), to consider in (6). For each (t), 0 kGt(, ) 1;hence, 0 k(, ) T, which satisfies the theoretical results presented in the paper. As it is mentioned in Liet al. (2015), this choice reflects a good performance in training MMD-GANs.",
  "N(1d, Id) (Mixture),F1 = N(0d, 2Id) (Variance shift), F1 = t3(0d, Id) (Heavy tail), and F1 = LG(0d, Id) (Kurtosis)": "To implement the test, we set = 1000, M = 20, and = 103 to be used in Algorithm 1 in the Appendix.We first considered the mixture of six Gaussian kernels corresponding to the suggested bandwidth parameters2, 5, 10, 20, 40, and 80 by Li et al. (2015). We found that although this choice can provide good results intraining GANs, it does not provide satisfactory results in hypothesis testing problems. Instead of using a mixture of several Gaussian kernels, we propose choosing a specific value for the bandwidthparameter that maximizes the area under the receiver operating characteristic curve (AUC) empirically. In a binary classifier, which can also be thought of as a two-sample test assessing whether two samplesare distinguishable or not, the receiver operating characteristic (ROC) curve is a plot of true positive rates(sensitivity) against the false positive rates (1-specificity) based on different choices of threshold to displaythe performance of the test. The positive term refers to rejecting H0 in (7), while, the negative term refersto failing to reject H0. The false positive and false negative rates are equivalent to type I and type II errors,respectively. Hence, a higher AUC indicates a better diagnostic ability of a binary test7. The ROC curves and AUC values of the synthetic examples are provided in for the sample sizen = 50, d = 60, a = 25, and various values of the bandwidth parameter, including the median heuristicMH.The red diagonal line represents the random classifier.An ROC curve located higher than thediagonal line indicates better test performance and vice versa. It is obvious from that the besttest performance (AUC = 1) is first achieved for the bandwidth parameter 80. For this , the AUC jumpsfrom zero to 1 as either H0 is strongly rejected by too small values of RB (near to 0, the minimum RB)in alternative experiments or H0 is strongly accepted by large values of RB (near to 20, the maximumRB) in null experiments. As noted in the Appendix, if is too small or too large, the MMD approacheszero, resulting in poor performance, as shown in . In the context of this papers semi-BNP test,both the prior- and posterior-based MMD estimators converge to zero under these conditions, causing theircorresponding density functions to coincide at zero, resulting in RB 1 and rendering the test unable toevaluate H0. Another test of interest is to assess the effect of different hyperparameter settings for a and H throughsimulation studies to follow our proposed theoretical convergence results. To do this, we generate 100 60-dimensional samples of sizes n = 50 from both F1 = t3(060, I60) and F2 = N(060, I60) and represent the resultof the semi-BNP test by for two choices of the base measure H (H = F2 and H = LG(060, I60))and various values of a (a = 1, . . . , 1000). In this figure, the solid line represents the average of the RB andthe filled area around the line indicates a 95% confidence interval of the RB over the 100 samples. -a clearly shows that by choosing H = F2, the test wrongly accepts the null hypothesis. It is because theprior does not support the null hypothesis mentioned earlier when presenting the RB ratio in . Onthe other hand, when H = F2, -b shows good performance for the test at a = n/2. Failing to rejectH0 for small values of a is due to the lack of sufficient support from the null hypothesis by the prior. Weremark that the value of a determines the concentration of the prior F pri around H, thus it is obvious thatfor small values of a, the test does not perform well. It should also be noted that for any choices of H in, the ability of the test to evaluate the null hypothesis is reduced by letting a go to infinity, whichcan be concluded by Corollary 3(i). Now, to conduct a more comprehensive investigation, we present the average of RB and its relevant strengthover the 100 samples in for n = 30, 50. Furthermore, we present the results of the BNP-energytest by Al-Labadi et al. (2022a) in , which demonstrate its weak performance in certain scenarios.Additional results in the power comparison can be found in Section F.1 of the Appendix. 7Since we consider i0/M = 0.05 to estimate the RB ratio, the values of RB can vary between 0 and 20. Therefore, incomputing the AUC for the semi-BNP test, the threshold should vary from 0 to 20. More details for plotting the ROC andcomputing the AUC are provided by Algorithm 3 in the Appendix.",
  "15.83(0.91) 19.74(1)14.84(0.92) 19.31(1)0.480.460.490.55": "Mean shift10.76(0.24)0.40(0.09)0.82 0.96 0.67(0.21)0.45(0.11)0.87 0.90 0.150.050.86 0.91 0.190.120.79 0.8650.21(0.03)0.07(0)0.99 0.99 0.28(0.04)0.09(0.01)0.98 10.010.002 10.98 0.020.004 0.97 0.97100.09(0.01)0.05(0)110.17(0.05)0.02(0)0.98 10.001 0.001 110.006 0.004 0.98 1200.09(0.01)0(0)110.09(0.01)0(0)110.001 0.001 110.004 0.004 11400.08(0)0(0)110.06(0.02)0(0)110.001 0.001 110.004 0.004 11600.09(0.03)0(0)110.07(0.04)0(0)110.001 0.001 110.004 0.004 11800.06(0.02)0(0)110.05(0.03)0(0)110.001 0.001 110.004 0.004 11100 0.04(0.01)0(0)110.03(0)0(0)110.001 0.001 110.004 0.004 11 Skewness10.01(0)0(0)0.99 10.07(0)0(0)0.99 10.009 0.001 0.98 10.007 0.004 0.94 150(0)0(0)110(0)0(0)110.001 0.001 110.004 0.004 11100(0)0(0)110(0)0(0)110.001 0.001 110.004 0.004 11200(0)0(0)110(0)0(0)110.001 0.001 110.004 0.004 11400(0)0(0)110(0)0(0)110.001 0.001 110.004 0.004 11600(0)0(0)110(0)0(0)110.001 0.001 110.004 0.004 11800(0)0(0)110(0)0(0)110.001 0.001 110.004 0.004 11100 0(0)0(0)110(0)0(0)110.001 0.001 110.004 0.004 11 Mixture10.06(0)0(0)0.90 0.97 0.19(0.03)0.04(0)0.97 10.430.380.58 0.57 0.290.170.69 0.8150(0)0(0)110(0)0(0)110.150.090.84 0.91 0.060.010.95 1100(0)0(0)110(0)0(0)110.030.007 0.95 0.98 0.020.007 0.96 1200(0)0(0)110(0)0(0)110.002 0.001 0.96 10.010.006 11400(0)0(0)110(0)0(0)110.001 0.001 110.010.006 11600(0)0(0)110(0)0(0)110.001 0.001 110.006 0.009 11800(0)0(0)110(0)0(0)110.001 0.001 110.008 0.006 11100 0(0)0(0)110(0)0(0)110.001 0.001 110.004 0.006 11 Variance shift 10.87(0.29)0.85(0.19)0.71 0.83 1.10(0.36)1.08(0.33)0.53 0.63 0.460.380.54 0.57 0.330.210.65 0.7750.55(0.12)0.56(0.15)0.99 0.99 1.06(0.35)0.99(0.32)0.89 0.98 0.340.200.65 0.80 0.200.070.82 0.93100.44(0.11)0.27(0.05)0.99 10.87(0.24)0.80(0.25)0.97 10.140.030.85 0.97 0.100.020.89 0.97200.34(0.07)0.08(0)110.65(0.17)0.60(0.13)0.99 10.010.001 0.95 10.030.006 0.95 1400.13(0.01)0.02(0)110.61(0.18)0.58(0.14)110.001 0.001 110.010.004 0.98 1600.12(0.01)0.01(0)110.47(0.10)0.45(0.11)110.001 0.001 110.006 0.004 11800.17(0.01)0(0)110.54(0.12)0.47(0.11)110.001 0.001 110.005 0.004 11100 0.14(0.01)0(0)110.45(0.10)0.41(0.08)110.001 0.001 110.004 0.004 11 Heavy tail10.93(0.28)0.66(0.20)0.89 0.92 1.19(0.41)1.10(0.38)0.70 0.78 0.430.390.57 0.56 0.390.360.59 0.6250.32(0.06)0.37(0.08)0.99 0.99 0.77(0.24)0.78(0.23)0.93 0.99 0.200.110.79 0.89 0.030.006 0.97 0.99100.35(0.08)0.13(0.02)0.99 10.61(0.16)0.68(0.19)0.98 10.060.007 0.92 0.98 0.090.010.90 0.97200.15(0.02)0(0)110.48(0.12)0.46(0.12)110.002 0.001 0.96 10.020.005 0.96 1400.07(0.01)0(0)110.25(0.04)0.18(0.04)110.001 0.001 110.005 0.004 11600.02(0)0(0)110.22(0.03)0.14(0.01)110.001 0.001 110.004 0.004 11800.01(0)0(0)110.13(0.01)0.15(0.02)110.001 0.001 110.004 0.004 11100 0.04(0)0(0)110.14(0.01)0.09(0.01)110.001 0.001 110.004 0.004 11 Kurtosis10.47(0.12)0.19(0.04)0.89 0.98 1.09(0.37)0.88(0.28)0.77 0.90 0.280.230.74 0.72 0.180.110.79 0.8850.16(0.03)0.06(0.01)110.63(0.18)0.41(0.09)0.96 0.99 0.040.010.94 0.98 0.030.008 0.97 0.96100.02(0)0(0)110.35(0.08)0.32(0.06)0.97 10.001 0.001 110.007 0.004 0.96 1200(0)0(0)110.20(0.03)0.18(0.02)110.001 0.001 110.004 0.004 11400(0)0(0)110.06(0.01)0.06(0)110.001 0.001 110.004 0.004 11600(0)0(0)110.05(0)0.04(0)110.001 0.001 110.004 0.004 11800(0)0(0)110.05(0)0.03(0)110.001 0.001 110.004 0.004 11100 0(0)0(0)110.02(0)0(0)110.001 0.001 110.004 0.004 11",
  "(e) y1, . . . , yn LN(060, B60)": "0.00.20.40.60.81.0 FPR (1- pecificity) 0.0 0.2 0.4 0.6 0.8 1.0 TPR ( en itivity) AUC =0.016 AUC =0.0152 AUC =0.0184 AUC =0.7208 AUC =1 AUC =1 AUC =1 AUC =0.9692 AUC =0.3076 AUC MH =0.1456 ROC Curve (Kurto i ) =2 =5 =10 =20 =40 =80 =10 =10 =10 MH",
  "(b) H = F2": ": The solid line represents the average of the RB and the pink area represents a 95% confidenceinterval of the RB over the 100 samples with various choices of H and a for the heavy tail example. Thelower and upper bounds are the 2.5% and 97.5% quantiles of the RB, respectively. The red dotted linerepresents RB = 1. To compare the BNP and FNP tests, the p-values of the frequentists counterparts corresponding to eachBayesian test are presented in using the R packages energy8 and maotai9. AUC values of all testsare also given to facilitate comparison between tests. Generally, the proposed test reflects better performancesthan its frequentist counterparts in lower dimensions. For instance, in the variance shift example, whend = 5 and n = 30, the average of the RB and its strength for the semi-BNP-MMD test are 0.55 and 0.12,respectively, which shows strong evidence to reject the null. While the average of the p-value correspondingto the MMD frequentist test is 0.34, which shows a failure to reject the null hypothesis. The AUC value ofthe semi-BNP test is also 0.99 which indicates a better ability than its frequentist counterpart with an AUC",
  "The Semi-BNP GAN": "According to the results reported in the previous subsection, the semi-BNP estimator suggests a test thatoutperforms other competing tests in many scenarios. Therefore, we expect that embedding this estimator inGANs as the discriminator will accurately distinguish real and fake data. We use the database of handwrittendigits with 10 modes, bone marrow biopsy histopathology, human faces, and brain MRI images to analyzethe model performance. Following the design choices of Li et al. (2015), we use the Gaussian neural networkfor the generator with four hidden layers each having rectified linear units activation function and a sigmoidfunction for the output layer. For fitting a deep neural network, there are numerous methods to choosenetwork parameters. Furthermore, we select the number of nodes in hidden layers and tuning parameters ofthe network using Bayesian optimization (Snoek et al., 2012). We also set mini-batch sizes to be nmb = 1, 000and use a mixture of six Gaussian kernels corresponding to the bandwidth parameters 2, 5, 10, 20, 40, and 80to train networks discussed in this section.",
  "MNIST Dataset (LeCun, 1998):": "The MNIST dataset includes 60,000 handwritten digits of 10 numbers from 0 to 9 each having 784 (28 28)dimensions. This dataset is split into 50000 training and 10000 testing images and is a good example todemonstrate the performance of the method in dealing with the mode collapse problem. We use the trainingset to train the network. A sample from the training MNIST dataset is shown in -a. Followingrmb = 40, 000 iterations, we generate samples from the trained semi-BNP GAN using Algorithm 2 from theAppendix, as depicted in -b. The results of Li et al. (2015) are also presented by -c as thefrequentist counterpart of our semi-BNP procedure10. Based on these preliminary results, we can see thatour generated images can, at least, replicate the results of Li et al. (2015) and in some cases produce sharperimages. This result can also be deduced from the presented values of certain score functions in Section F.2 ofthe Appendix. On the other hand, unlike the semi-BNP test, our experimental results demonstrate that the",
  "Conclusion": "Our semi-BNP approach effectively estimates the MMD measure between an unknown distribution and anintractable parametric distribution. It outperforms frequentist counterparts and even surpasses a recent BNPcompetitor in certain scenarios (Al-Labadi et al., 2022a). This approach shows great potential in trainingGANs, where the proposed estimator serves as a discriminator, inducing a posterior distribution on thegenerators parameter space. Stick-breaking representation lacks normalization terms and exhibits stochastic",
  "Katalin Csillry, Olivier Franois, and Michael G.B. Blum. abc: an R package for approximate Bayesiancomputation (ABC). Methods in Ecology and Evolution, 3(3):475479, 2012": "Charita Dellaporta, Jeremias Knoblauch, Theodoros Damoulas, and Franois-Xavier Briol. Robust Bayesianinference for simulator-based models via the MMD posterior bootstrap. In International Conference onArtificial Intelligence and Statistics, pp. 943970. PMLR, 2022. Gintare Karolina Dziugaite, Daniel M. Roy, and Zoubin Ghahramani. Training generative neural networks viamaximum mean discrepancy optimization. In Proceedings of the Thirty-First Conference on Uncertaintyin Artificial Intelligence, pp. 258267, 2015.",
  "Arthur Gretton, Karsten M. Borgwardt, Malte J. Rasch, Bernhard Schlkopf, and Alexander J. Smola. Akernel two-sample test. Journal of Machine Learning Research, 13(1):723773, 2012a": "Arthur Gretton, Dino Sejdinovic, Heiko Strathmann, Sivaraman Balakrishnan, Massimiliano Pontil, KenjiFukumizu, and Bharath K Sriperumbudur. Optimal kernel choice for large-scale two-sample tests. Ad-vances in Neural Information Processing Systems, 25, 2012b. Martin Heusel, Hubert Ramsauer, Thomas Unterthiner, Bernhard Nessler, and Sepp Hochreiter. GANstrained by a two time-scale update rule converge to a local Nash equilibrium. Advances in Neural Infor-mation Processing Systems, 30, 2017.",
  "Mahmoud Zarepour and Luai Al-Labadi.On a rapid simulation of the Dirichlet process.Statistics &Probability Letters, 82(5):916924, 2012": "Kaifeng Zhang. On mode collapse in generative adversarial networks. In Artificial Neural Networks andMachine Learning ICANN 2021, pp. 563574, Cham, 2021. Springer International Publishing. ISBN978-3-030-86340-1. Feng Zhao, Chenhui Lei, Qingkun Zhao, Huiya Yang, Guoping Ling, Jiabin Liu, Haofei Zhou, and HongtaoWang. Predicting the property contour-map and optimum composition of Cu-Co-Si alloys via machinelearning. Materials Today Communications, 30:103138, 2022.",
  "where, samples {V}N=1 and {Y}m=1 are generated from H and F2, respectively. Similar to Proposition": "6, it can be shown that J,N 1/N and J,NJt,N 1/N 2, as a , using conjugacy property of DP. Onthe other hand, since H H as a , the chance of sampling from H and F1,n tends, respectively, toone and zero, which implies V i Vi, where Vi H, for i = 1, 2. Applying the continuous mapping theoremimplies k(V1, V2) k(Vl, Vt) and k(Vl , Yt) k(Vl, Yt), which completes the proof of (i)(a). To prove(i)(b), it follows from the proof of Theorem 1:",
  "where h1(a, n, N) =(a+n)(N1)(a+n+1)Nand h2(a, n, N) =a+n+N": "(a+n+1)N .Since k(, ) is bounded above by K,the dominated convergence theorem implies EH[k(V1, V2)] EH[k(V1, V2)] and EH,F2[k(V1, Y1)] EH,F2[k(V1, Y1)]. Since h1(a, n, N) 1 and h2(a, n, N) 0 as a , N ; and, m/(m 1) 1 and1/m 0 , as m , the results follow.",
  ":~1": ": General diagram of the BNP-GOF test. The prior density of MMD2 versus the posterior densityafter observing x1:n from distribution F1 under all possible conditions for both true and false null hypothesis.Here, we consider F1 = F2 = N(060, I60) as the true null hypothesis, while F1 = t3(060, I60) and F2 =N(060, I60) for the false null hypothesis to plot densities.",
  "Algorithm 3 Pseudocode of plotting ROC and computing AUC in semi-BNP test": "1: Initialize a, N, , and M.2: Set the number of repeating experiments: r 1003: RB|H0 Compute RB for r samples of sizes n generated under the null hypothesis.4: RB|H1 Compute RB for r samples of sizes n generated under the alternative hypothesis.5: T A sequence of numbers between 0 to 20 with length L. The discrimination threshold for thesemi-BNP test.",
  "CRelative Belief Ratio: A Bayesian Measure of Evidence": "The RB ratio (Evans, 2015) is a form of Bayesian evidence in hypothesis testing problems and has shownexcellent performance in many statistical hypothesis testing procedures (Al-Labadi et al., 2022a; 2021a;2022b). The RB ratio is defined by the ratio of the posterior density to the prior density at a particularparameter of interest in the population distribution whose correctness is under investigation. Precisely, fora statistical model (X, F) with F = {f : }, let be a prior on the parameter space and ( | x1:n)be the posterior distribution of after observing the data x1:n = (x1, . . . , xn). Consider a parameter ofinterest, = () such that satisfies regularity conditions so that the prior density and the posteriordensity ( | x1:n) of exist with respect to some support measure on the range space for . When and( | x1:n) are continuous at , the RB ratio for a value is given by",
  "RB( | x1:n) = ( | x1:n)/()": "Otherwise for a sequence N( ), the neighborhoods of that converge nicely to as 0, the RB ratio isdefined by RB( | x1:n) = lim0 (N( )| x1:n)/(N( )), where and (| x1:n) are the marginalprior and the marginal posterior probability measures, respectively. Note that RB( | x1:n) measures the change in the belief of being the true value a priori to a posteriori.Therefore, it is a measure of evidence. If RB( | x1:n) > 1, then the probability of being the true valuefrom a priori to a posteriori is increased, consequently there is evidence based on the data that is the truevalue. If RB( | x1:n) < 1, then the probability of being the true value from a priori to a posteriori isdecreased. Accordingly, there is evidence against based on the data that being the true value. For the",
  "respectively; where, in h3 is a positive-valued scale-mixture parameter, and the in h4 is a parameterthat controls the smoothness of the kernel results (Zhao et al., 2022; Genton, 2001)": "One of the simplest kernel functions above is the Gaussian kernel, which is mostly used in machine learningproblems and only depends on bandwidth parameter . The Gaussian kernel tends to 0 and 1 when 0and , respectively. Both situations lead to MMD2 being zero. Hence, the choice of the parameter",
  "E.1.1Frchet Inception Distance (FID)": "The FID is a widely used metric to assess the similarity between the distribution of generated images and realimages (Heusel et al., 2017). It is based on the concept of comparing the statistics of feature representations ofthese images. Specifically, it computes the Frchet distance between two multivariate Gaussian distributionsfitted to the feature representations of the inception network for real and generated images. Let {Inc(Xi)}ni=1 be the feature representations for the real images {Xi}ni=1 in the inception network, ifInc(X) and Inc(X) are the sample mean vector and covariance matrix of {Inc(Xi)}ni=1, and Inc(Y) andInc(Y) are the corresponding statistics for the generated images {Yi()}ni=1, then the FID is defined as:",
  "E.2An MMD Matching Score Function": "To develop a stronger method for evaluating the differences between real and generated data manifolds, wepropose using the MMD dissimilarity measure as follows: For i = 1, . . . , rmb, let {Xij}nmbj=1 and {Yij()}nmbj=1be two samples drawn, respectively, from the real dataset X1, . . . , Xn and the generated dataset Y1(), . . . ,Yn() with the same sample size nmb < n. Then, we define the MMD-based matching score as",
  "MMDS =maxi{1,...,rmb} MMD2(Fnmb(i), FG,nmb(i)),(24)": "where, MMD2(Fnmb(i), FG,nmb(i)) is the MMD approximation given by Equation (2, main paper) usingsamples {Xij}nmbj=1 and {Yij()}nmbj=1 (mini-batch samples). Our proposed matching score returns the max-imum value of the MMD approximation between a subset of the real and a subset of the generated datasetwith the same size nmb (mini-batch sample size) over rmb resamplings (mini-batch iteration). According toEquation (2, main paper), all components of mini-batch samples are compared together in the MMD mea-sure, which provides a comprehensive assessment between subsets of the data in each iteration. Eventually,it is obvious smaller values of MMDS indicate better quality and more diversity of the generated samples.",
  "F.1The Semi-BNP Test": "To further illustrate the difference in performance between the BNP and FNP tests, we conducted tests ontwo alternative distributions: F1 = N(0, 2) for 2 and F1 = 0.5N(1 + , 1) + 0.5N(1 , 1) for . The corresponding results are reported in and 8 for univariate cases with n = 50. (a) specifically shows that the proposed test exhibits a higher growth rate of the AUC when 2 is increasedcompared to the other tests. Additionally, (b) indicates that our test starts to detect differencesearlier than other tests (2 1.67). Similar results can be found in for mixture distribution withvarious means.",
  "(b)": ": (a) AUC values in testing alternative F1 = 0.5N(1 + , 1) + 0.5N(1 , 1) for (0, 1) inmixture example.(b)-Top: Test critical values against different values of 2.(b)-Bottom: The lighterdensity corresponds to a smaller value of . semi-BNP kernel-based test in detecting differences, especially in scenarios involving variance shift, heavytail, and kurtosis examples, where the BNP-energy test does not perform optimally in high sample sizes. Moreover, to conduct a comprehensive analysis of the large sample property of all the tests in comparison,we present for sample sizes n = 500, 1000. This table clearly demonstrates the weak performance ofthe BNP-Energy test in particular scenarios that are currently being mentioned. Additionally, to display the asymptotic behavior of the posterior-based estimator compared to the baseline(3) (FNP-MMD), we provide the density plot of both under the null hypothesis in demonstratingthe superior performance of the semi-BNP estimator in terms of faster convergence to zero.",
  "F.2The Semi-BNP GAN": "Now, we examine the performance of the proposed GAN through additional datasets, the details of whichare given below. The generated samples are shown in Figures 11. Generally, the generated images usingsemi-BNP GAN show better resolution than the FNP GAN. The MMD scores presented in are alsoevidence to demonstrate this claim. To further assess the performance of MMD-based GANs, we report thecommonly used Frchet inception distance (FID) and the Kernel inception distance (KID) metrics (Bikowskiet al., 2018). These metrics are well-suited for evaluating the performance of GANs. The correspondingscores13 are reported in . Similar to our MMD scores, the smaller values of FID and KID show betterperformance of the GAN.",
  "F.2.1Bone Marrow Biopsy Dataset (Tomczak & Welling, 2016):": "The bone marrow biopsy (BMB) dataset is a collection of histopathology of BMB images corresponding to16 patients with some types of blood cancer and anemia: 10 patients for training, 3 for testing, and 3 forvalidation. This dataset contains 10,800 images in the size of 28 28 pixels, 6,800 of which are consideredfor the training set. The rest of the images have been divided into two sets of equal size for testing andvalidation. The whole dataset can be found at The results based on 6800 training images are presented in-(a-c).",
  "Kurtosis": "n n n n n n n Semi-BNP-MMD test BNP-Energy test : The proportion of rejecting H0 out of 100 replications against sample of sizes n = 10, . . . , 1000based on using a = 25, = 1000, = 103 in equation 4, M = 20 for the semi-BNP-MMD (blue line) andBNP-energy (red dotted) tests.",
  "20(1)20(1)20(1)20(1)0.490.480.510.50": "Mean shift10(0)0(0)110(0)0(0)0.98 0.98 0.001 0.001 110.004 0.004 1150(0)0(0)110(0)0(0)110.001 0.001 110.004 0.004 11100(0)0(0)110(0)0(0)110.001 0.001 110.004 0.004 11200(0)0(0)110(0)0(0)110.001 0.001 110.004 0.004 11400(0)0(0)110(0)0(0)110.001 0.001 110.004 0.004 11600(0)0(0)110(0)0(0)110.001 0.001 110.004 0.004 11800(0)0(0)110(0)0(0)110.001 0.001 110.004 0.004 11100 0(0)0(0)110(0)0(0)110.001 0.001 110.004 0.004 11 Skewness10(0)0(0)110(0)0(0)110.001 0.001 110.004 0.004 1150(0)0(0)110(0)0(0)110.001 0.001 110.004 0.004 11100(0)0(0)110(0)0(0)110.001 0.001 110.004 0.004 11200(0)0(0)110(0)0(0)110.001 0.001 110.004 0.004 11400(0)0(0)110(0)0(0)110.001 0.001 110.004 0.004 11600(0)0(0)110(0)0(0)110.001 0.001 110.004 0.004 11800(0)0(0)110(0)0(0)110.001 0.001 110.004 0.004 11100 0(0)0(0)110(0)0(0)110.001 0.001 110.004 0.004 11 Mixture10(0)0(0)110(0)0(0)110.060.010.93 0.99 0.004 0.004 1150(0)0(0)110(0)0(0)110.001 0.001 110.004 0.004 11100(0)0(0)110(0)0(0)110.001 0.001 110.004 0.004 11200(0)0(0)110(0)0(0)110.001 0.001 110.004 0.004 11400(0)0(0)110(0)0(0)110.001 0.001 110.004 0.004 11600(0)0(0)110(0)0(0)110.001 0.001 110.004 0.004 11800(0)0(0)110(0)0(0)110.001 0.001 110.004 0.004 11100 0(0)0(0)110(0)0(0)110.001 0.001 110.004 0.004 11 Variance shift 10.01(0)0(0)111.73(0.59)2.10(0.59)0.93 0.81 0.070.010.93 0.99 0.006 0.004 0.99 150.42(0.07)0.40(0.08)0.99 14.42(0.72)7.30(0.70)0.73 0.64 0.001 0.001 110.004 0.004 11100.39(0.06)0.22(0.06)118.69(0.66)13.12(0.73) 0.55 0.40 0.001 0.001 110.004 0.004 11200(0)0(0)1113.43(0.78) 18.12(0.69) 0.35 0.07 0.001 0.001 110.004 0.004 11400(0)0(0)1118.01(0.68) 19.82(0.68) 0.11 00.001 0.001 110.004 0.004 11600(0)0(0)1119.19(0.55) 19.98(0.94) 0.02 00.001 0.001 110.004 0.004 11800(0)0(0)1119.64(0.47) 20(1)000.001 0.001 110.004 0.004 11100 0(0)0(0)1119.82(0.64) 20(1)000.001 0.001 110.004 0.004 11 Heavy tail10.05(0)0(0)111.65(0.54)1.70(0.54)0.96 0.99 0.030.004 0.96 0.99 0.010.005 0.98 0.9950.04(0)0.02(0)112.89(0.71)4.53(0.74)0.91 0.76 0.001 0.001 110.004 0.004 11100(0)0(0)114.49(0.78)7.87(0.73)0.78 0.64 0.001 0.001 110.004 0.004 11200(0)0(0)115.66(0.76)11.73(0.75) 0.77 0.42 0.001 0.001 110.004 0.004 11400(0)0(0)119.40(0.79)16.41(0.78) 0.54 0.20 0.001 0.001 110.004 0.004 11600(0)0(0)1111.02(0.74) 18.06(0.82) 0.52 0.16 0.001 0.001 110.004 0.004 11800(0)0(0)1112.53(0.77) 18.51(0.90) 0.41 0.09 0.001 0.001 110.004 0.004 11100 0(0)0(0)1113.17(0.75) 19.07(0.97) 0.30 0.06 0.001 0.001 110.004 0.004 11 Kurtosis10(0)0(0)111.23(0.42)1.55(0.52)0.96 0.95 0.002 0.001 0.99 10.004 0.004 1150(0)0(0)111.75(0.59)3.54(0.70)0.96 0.88 0.001 0.001 110.004 0.004 11100(0)0(0)112.81(0.66)6.41(0.76)0.94 0.75 0.001 0.001 110.004 0.004 11200(0)0(0)114.63(0.71)9.90(0.78)0.84 0.51 0.001 0.001 110.004 0.004 11400(0)0(0)115.70(0.73)13.43(0.77) 0.74 0.28 0.001 0.001 110.004 0.004 11600(0)0(0)117.06(0.75)16.38(0.81) 0.72 0.23 0.001 0.001 110.004 0.004 11800(0)0(0)118.11(0.79)17.50(0.83) 0.71 0.13 0.001 0.001 110.004 0.004 11100 0(0)0(0)118.83(0.78)18.52(0.89) 0.55 0.09 0.001 0.001 110.004 0.004 11",
  "F.2.3Brain Tumor MRI Dataset (Nickparvar, 2021):": "In the last experiment, we consider a more challenging medical dataset including brain MRI images availableat This dataset has two groups including training and testing sets.Both are classified into four classes: glioma, meningioma, no tumor, and pituitary. To train the networks, weconsider all 5,712 training images. The images vary in size and have extra margins. We use a pre-processing",
  "GMore Discussion on the Potential Research": "GANs are increasingly used in medical imaging applications which are effective tools for tasks such as medicalimaging reconstructions. The synthetic images generated have often been proven to be valuable especiallywhen the original image is noisy or expensive to obtain. GANs have also been used for generating images incross-modality synthesis problems, where we observe magnetic resonance imaging (MRI) for a given patientbut want to generate computed tomography (CT) images for that same patient (Wolterink et al., 2017).This type of generative method for medical imaging can drastically reduce the time and cost of obtainingdata if the quality of the synthetic examples is sufficiently high. GANs have also been used in a diagnosticcapacityfor example, in detecting brain lesions in images (Alex et al., 2017). Here, the GAN is trained by distinguishing between labeled data of brain images that contain and do notcontain lesions. Then, the discriminator of the GAN is used to detect brain lesions on new images. However,GANs are far less commonly used for tasks like diagnosis. According to a survey on medical imaging researchin GANs, less than 10% of the top papers surveyed were dedicated towards making diagnoses, whereas thevast majority of papers were dedicated towards generating realistic synthetic examples of medical images forfurther analysis (Yi et al., 2019). We believe this is because where the cost of making errors in diagnosis isimmediately consequential to people, unlike other AI applications where GANs are largely used. We plan to extend the current work by mapping the data to a lower dimensional space using a variationalauto-encoder (VAE), a dimensionality reduction model helps to reduce the noise in data and tries to optimizethe cost function between the real data and fake data in the code space. There is a significant potential tocombine the elements of Stein variational gradient descent (SVGD) and GANs. For instance, SVGD can beused for the inference of latent variables to approximate the variational distribution (the distribution of thelatent variable given the observed dataset) in a VAE-GAN. Then, we will propose a 3D semi-BNP GAN inthe code space to improve the ability of the GAN to generate medical datasets. The VAE method should",
  "IA Review on the Approximate Bayesian Computation": "For a given data space X and the set of Borel probability distributions B(X), consider the observations x1:ndrawn from FTrue B(X). In the standard Bayesian perspective, given a parametric model B(X) = {F : } B(X), a prior is placed on the parameter space . After observing data x1:n, the prior is updatedto obtain a posterior distribution given by:",
  "where L(x1:n|) = ni=1 fXi(xi|) is the likelihood function and f is the density function corresponding tothe distribution F": "For the standard Bayesian inference to be considered well-specified, there must exist a parameter 0 suchthat the distribution F0 matches the true data distribution FTrue, i.e., F0 = FTrue. When the parametricmodel F does not contain FTrue (i.e., there is no 0 such that F0 = FTrue), the model is said to bemisspecified. This can lead to problems in the standard Bayesian inference, as the posterior distribution willbe based on an incorrect model assumption. ABC addresses some of these challenges, particularly in scenarios where the likelihood function is intractableor difficult to compute. ABC circumvents the need for explicit likelihood evaluations by using simulations,summary statistics, and a comparison mechanism between simulated and observed data. Below shows howABC works within this framework: 1. Simulation: Generate synthetic datasets by sampling parameters from the prior distribution and simulating data y1:n from F. Here F corresponds to the distribution of a generative modelwith implicitly defined likelihood functions. 2. Summary Statistics: Reduce both the observed data x1:n and the simulated data y1:n to lower-dimensional summary statistics S(x1:n) and S(y1:n). These summary statistics should capture theessential features of the data relevant to the parameters of interest.",
  "where I is an indicator function that equals 1 if the distance is within the tolerance , and 0otherwise (Beaumont, 2019)": "As a result, the ABC posterior distribution converges to the standard posterior as approaches 0 (Beaumont,2019; Dellaporta et al., 2022). This convergence follows from the fact that as decreases, the ABC posteriorplaces increasing weight on values that generate simulated data close to the observed data, effectivelyapproximating the likelihood function. However, as already mentioned, the standard Bayesian posterior canbe sensitive to model misspecification. If the assumed model is not a good representation of the true data-generating process, the Bayesian posterior (and thus the ABC posterior when 0) may give misleadinginferences. This lack of robustness to model misspecification can lead to poor performance in practice."
}