{
  "Abstract": "Anomaly detection in continuous-time dynamic graphs is an emerging field yet under-explored in the context of learning algorithms. In this paper, we pioneer structured anal-yses of link-level anomalies and graph representation learning for identifying categoricallyanomalous graph links. First, we introduce a fine-grained taxonomy for edge-level anomaliesleveraging structural, temporal, and contextual graph properties. Based on these properties,we introduce a method for generating and injecting typed anomalies into graphs. Next, weintroduce a novel method to generate continuous-time dynamic graphs featuring consisten-cies across either or combinations of time, structure, and context. To enable temporal graphlearning methods to detect specific types of anomalous links rather than the bare existenceof a link, we extend the generic link prediction setting by: (1) conditioning link existenceon contextual edge attributes; and (2) refining the training regime to accommodate diverseperturbations in the negative edge sampler. Comprehensive benchmarks on synthetic andreal-world datasets featuring synthetic and labeled organic anomalies and employing sixstate-of-the-art link prediction methods validate our taxonomy and generation processesfor anomalies and benign graphs, as well as our approach to adapting methods for anomalydetection. Our results reveal that different learning methods excel in capturing differentaspects of graph normality and detecting different types of anomalies. We conclude witha comprehensive list of findings highlighting opportunities for future research. The code isavailable at",
  "Introduction": "Anomaly detection in graphs is the task of identifying abnormal behavior, with applications in spam detection(Ye & Akoglu, 2015), sensor fault detection (Gaddam et al., 2020), financial fraud identification (Dou et al.,2020), and cybersecurity (Zipperle et al., 2022; Reha et al., 2023). Although extensive literature exists onanomaly detection in static graphs (Peng et al., 2018; Ding et al., 2019; Fan et al., 2020; Bandyopadhyayet al., 2019; Yuan et al., 2021; Xu et al., 2022), most real-world networks evolve over time, requiring a focuson dynamic graphs. The most general dynamic graph formulation is the continuous-time dynamic graph(CTDG), where interactions occur at irregular times and carry information as edge attributes.",
  "Published in Transactions on Machine Learning Research (10/2024)": "1e-5, 3e-6, 1e-6. We execute experiments on a cluster with 1000 Intel(R) Xeon(R) CPUs @ 2.60GHz. Notethat, since experiments for Darpa-Theia would take months under our model configuration and hardwaresetup, we run EdgeBank and EdgeBanktw with a batch size of 100 (rather than 1, see 5.1), and modelson this dataset are stopped after 25 days of execution time. In practice only TGN does not converge inthis timespan. The results for the best checkpoint by the 25th day are reported. The rest of the modelconfigurations are as follows:",
  "Problem Definition": "We address the problems of categorizing and detecting anomalous edges in dynamic graphs. A continuous-time dynamic graph (CTDG) extends the concept of a static graph by incorporating timestamps and at-tributes (also referred to as message) on edges: Definition 1 (Continuous-time dynamic graph) A continuous-time dynamic graph is a sequence ofnon-decreasing chronological interactions G = {(u1, v1, t1, m1) , (u2, v2, t2, m2) , . . . }, with 0 t1 t2 . . . ,where ui, vi V denote the source node and destination node of the ith edge at timestamp ti and V is theset of all nodes. Each interaction (u, v, t, m) has edge message features m RD, where D is the number ofattributes. For non-attributed graphs, edge features are often set to zero vectors, i.e., m = 0.",
  "We define the task of link anomaly detection in CTDGs as follows:": "Definition 2 (Link anomaly detection in CTDGs) Given a continuous-time dynamic graph G, the goalof link anomaly detection is to learn a function: f : V V R RD R that maps a node pair (u, v),timestamp t, and edge message m to a real-valued anomaly score for the edge e = (u, v, t, m).",
  "Anomaly Taxonomy and Synthesis": "Background. The categorization and synthesis of realistic anomalies are fundamental for designing, ana-lyzing, and benchmarking anomaly detection methods across domains (Zhao et al., 2019; Steinbuss & Bhm,2021; Han et al., 2022; Liu et al., 2022; Ma et al., 2021), especially when labeled data is scarce or costly (Hanet al., 2022). For static graphs, Liu et al. (2022) introduce a taxonomy and generation method for struc-tural and contextual anomalies. Ma et al. (2021) briefly discuss another categorization of anomalies in staticgraphs and re-use it for discrete-time dynamic graphs, i.e., graphs represented as timestamped snapshots,while disregarding the effect of time. To date, there exists no taxonomy for anomalies in CTDGs.",
  ". There exist neither real-world nor synthetic CTDGs suitable to validate a fine-grained taxonomy foranomalies in CTDGs": "Here, we propose a fine-grain taxonomy for edge-level anomalies in CTDGs by re-interpreting context andstructure, and incorporating time explicitly. We then describe procedures to generate into graphs edges thatare anomalous w.r.t. one or multiple of these dimensions. Lastly, we introduce a graph generation processfor CTDGs that assures reliable and largely independent consistencies along the structural, temporal, andcontextual dimensions. This process is used in 5 to: validate our proposed taxonomy and procedures forsynthesizing and injecting edge-level anomalies, and comparatively assess the capabilities of link predictionapproaches in detecting the five anomaly types defined by our taxonomy.",
  "BenignThe ordered package is delivered to the customer on time": "TemporaltThe ordered package is delivered to the customer with delay.ContextualcA package with wrong content is delivered to the customer on time.Temporal-contextualt-cA package with wrong content is delivered to the customer with delay.Structural-contextuals-cThe ordered package is delivered to a wrong address on time.Temporal-structural-contextualt-s-cA random package is delivered to a random address at a random time.",
  "tied to these communities, (3) the timing of edges follows the Temporal Activity at the bottom, i.e.,,": "indicate the node is active at this time. From timestamp tn4 to tn we highlight and categorize edgeanomalous behavior. (t): Edge appears at an unexpected time. (c): Edge message differs from the expectedmessage between the two nodes. (t-c): Edge appears at an unexpected time and its message differs from theexpected message between the two nodes. (s-c): Edge connects two nodes that are expected to be active atthis time but do not usually connect with each other, its message is out-of-distribution ( ). (t-s-c): Edgeconnects two nodes that do not usually connect with each other, the nodes are not expected to be active atthis time and its message is out-of-distribution. Icons,mark temporal anomalies.",
  "Definition 4 (Structural Anomaly (s)) In a CTDG, a structural anomaly is an edge connecting twonodes that are structurally unexpected to connect": "Time. In dynamic graphs, nodes may interconnect following specific temporal patterns. These patternscreate dynamics where nodes tend to communicate at predictable times, e.g., due to periodicity, other kindsof regularity, or periods of high activity. For example, traffic in industrial areas occurs most likely duringrush hours, friends exchange private messages most likely outside of working hours (Panzarasa et al., 2009),and corporate e-mails may be sent most likely between 9-10 am (Shetty & Adibi, 2004). Other networkswith temporal consistencies include flights (Huang et al., 2023a), transactions (Huang et al., 2023a), andinteractions (Kumar et al., 2019; Nadiri & Takes, 2022).",
  "Definition 5 (Temporal Anomaly (t)) In a CTDG, a temporal anomaly is an edge that appears at anunexpected time": "Combinations of anomaly types. The three dimensions of CTDGs, i.e., structure, context, and time, aremutually complementary yet not completely orthogonal, meaning not all combinations of anomalies can beconsidered independently. While an edge can be anomalous w.r.t. time, context, or both time and context, weargue that in CTDGs, structural anomalies imply contextual anomalies: When an edge connects two nodesthat never connected before and are otherwise structurally unlikely to connect, this implies a contextualanomaly, as there exists no meaningful distribution of edges messages to learn contextual normality from.Overall, the following five out of seven possible combinations of anomalies are considered in our taxonomy: t,c, t-c, s-c, t-s-c. and exemplifies and illustrates these categorical anomalies, respectively.",
  "Generation of Anomalies": "Here, we present efficient strategies to synthesize for a given CTDG anomalous edges that fall into thefive categories of anomalies defined above. Anomalies of categories t, c, t-c, and s-c are generated by:(1) sampling a benign reference edge, and (2) applying category-specific perturbations to create abnormalproperties; Only t-s-c anomalies do not necessitate benign sampling. In compliance with Def. 3-5, we userandomness as a proxy for abnormality. For a given observed edge, we assume that: (i) randomizing thedestination node creates a structural anomaly, (ii) randomizing the attributes creates a contextual anomaly,and (iii) randomizing the edges timestamp creates a temporal anomaly. Note that random sampling is ahighly efficient and common approach to generating anomalies yet it might produce non-anomalous samplesat a negligible error rate. We refer to e = (u, v, t, m) as the sampled reference benign edge, with its sourceu, destination v, timestamp t, and attributes m. We inject anomalies as follows:",
  "(t-c): create e = (u, v, t, m) where t and m use the above procedures for t and c anomalies": "(s-c): sample a second benign reference edge e2 = (r, q, t, m) within a temporal window of size W (i.e.,one of W temporally closest edges). Create an edge e = (u, q, t, m) where q is the destination of e2 andm is selected with the procedure for injection of contextual anomalies above.",
  "Synthetic Dynamic Graph Generation": "We introduce a synthetic CTDG generation process with clear temporal, structural, and contextual con-sistencies. The generation starts by randomly creating a static graph from a node set V and a number oftemporal edges E. Temporal edges are then sampled from existing static edges, ensuring consistency incontext, structure, and time. Algorithm 1 outlines the complete process. To enforce consistencies in thegenerated CTDG, we do the following: Structural consistency: We generate the initial static graph with the Stochastic Block Model (Abbe,2018), using M predefined communities (Line 1), ensuring structure as randomly sampled nodes likelybelong to different communities. Contextual consistency: We uniformly assign nodes to a fixed number of classes C, and create expectededge message attributes (m)j,k between class pairs (Lines 2-3). Expected messages are orthogonal for perfectseparation, so randomly sampled edge attributes likely differ from these expectations. Temporal consistency: We uniformly sample time windows for each edges activity (Line 8). For thesame edge, we ensure uniform time intervals between its multiple occurrences (Line 10). Randomly sampledtimestamps are unlikely to match these predefined windows. Generation Process. The graph is generated iteratively: for each static edge (u, v) in the StaticGraphoutput, a number of temporal edge occurrences oe is sampled from a Poisson distribution. Then, an activetime window of activity [te0, te0 + te] is sampled based on a Lognormal distribution and the maximumtime-span of the temporal graph tmax. Then each edge occurrences timestamp is evenly spaced within theactive time window (within some Gaussian noise), and its message is sampled from a Multivariate Normaldistribution based on the nodes u and v respective classes. See further details and default parameters inApp. A.1. The graph consistencies allow us to use random sampling (along structure, time, or context) togenerate anomalies that fall under exactly one of the categories in 3.1. We use Alg. 1 to generate a CTDGfor experiments in 5.",
  "Link Prediction vs. Link Anomaly Detection": "A prominent learning task in CTDGs is link prediction (Nguyen et al., 2018; Kumar et al., 2019; Rossi et al.,2020; Yu et al., 2023; Huang et al., 2023a). While such task resembles that of link anomaly detection inDef. 2, there are significant differences that we outline here. Link prediction setting. When learning parametric methods for link prediction, it is common to assumethat the observed edges in G are legitimate, i.e., they represent normal graph behavior. In this setting,models can be trained with a self-supervised loss function based on maximizing the probability of occurrenceof observed edges e G (i.e., positive edges), while minimizing the probability of occurrence of unseen edgese G (i.e., negative edges). To create the negative set G, one uses random negative sampling: take all sourcesof the positive edges in a batch and re-wire them to randomly sampled destinations. Doing so, exactly onenegative edge e is sampled for each positive edge e = (u, v, t, m) (Huang et al., 2023a; Poursafaei et al.,2022), where the negative one only differs in the destination:",
  "After training, the trained model f is able to provide a likelihood of existence for any arbitrary link": "Link anomaly detection setting. Certain aspects differ in the task of link anomaly detection (Def. 2).First, (1) while random negative sampling of Eq. 1 models structural anomalies well (3.1) by samplingrandom destinations, it disregards anomalies in the temporal and contextual dimension: t and m are neverperturbed. This limits the models ability to capture non-structural abnormalities. Secondly, (2) the messageattributes m are informative, which models should now use in the prediction. Unlike in link prediction,the goal is not to predict the existence of an arbitrary unobserved link, but to estimate the likelihood ofoccurrence of an observed link.Lastly, (3) the assumption that the observed edges are legitimate (i.e.,normal) is invalidated at evaluation time,2 as a portion of edges in the validation and test set of G can beanomalous but their normality is unknown. The graph can be seen as the union of normal and anomalousedges G = Gb Ga. While the problem can still be formulated as a self-supervised learning problem withnegative sampling, this leads to anomalous information entering the neighbor sampler N tu of Eq. 3: N tu ={v|(u, v, t, m) Gb Gaandt < t}. While the challenges stemming from (3) can not be addresseddirectly (see 6), we address problems (1) and (2) in the following.",
  "Experiments": "We design our experimental setup to answer the following questions: RQ1 (5.2) How effective are ourmethods for adapting link prediction methods to the link anomaly detection task? RQ2 (5.3) How valid isour taxonomy and generation process of typed anomalies when applied to synthetic and real-world CTDGsand how discernible are these anomalies? RQ3 (5.3, 5.4) How do capabilities of different link predictionmethods differ at detecting typed anomalies in synthetic and real datasets? RQ4 (5.5) How do methodsperform at detecting organic anomalies in real datasets?",
  "Experimental Setup": "We provide here information about the experimental setup. Complementary details can be found in theappendix: datasets (App. A.1), model descriptions (App. A.2), hyper-parameter configurations (App. A.3),runtimes (App. B), and extensive prediction results (App. C). Datasets. We run experiments on eight different datasets. The first one is TempSynthGraph a CTDGwe generated using Alg. 1 with 10,000 nodes (see 3.3). We use five benign real-world datasets: Wikipedia,Reddit, MOOC, Enron, and UCI from the work of Poursafaei et al. (2022).Finally, we experimenton two CTDGs from the cybersecurity domain with labeled organic anomalies: LANL (Kent, 2016) andDarpa-Theia (Reha et al., 2023). Methods. We compare seven representative CTDGs learning methods that are based on graph convolutions,memory networks, random walks, and sequential models: TGN (Rossi et al., 2020), CAWN (Wang et al.,2020), TCL (Wang et al., 2021), GraphMixer (Cong et al., 2022), DyGFormer (Yu et al., 2023), and twovariants of EdgeBank (Poursafaei et al., 2022), namely EdgeBank and EdgeBanktw. Experimental setting. We train models for the task of link anomaly detection of Def. 2. Following ourconsiderations from 4 we use binary cross-entropy loss as in Eq. 4 and the negative sampler in Eq. 5. Foreach method, the same MLP prediction head takes the edge (including time and edge attributes) as input andpredicts the probability p(e) of the links existence. The link anomaly score is then computed as 1-p(e). Weuse the Area Under the Receiver Operating Characteristic curve (AUC) as the main evaluation metric, butwe also report Average Precision (AP) and Recall@k metrics in App. C. In datasets with synthetic anomalies,",
  "Towards Link Anomaly Detection": "Result - Conditioning on context. To demonstrate the efficacy of the contextual conditioning (see 4.2),we show that no link prediction method trained with Eq. 2 can detect contextual anomalies without contex-tual conditioning, while the revised optimization of Eq. 4 enables them to do so. We use TempSynthGraphand compute the AUC performance of anomaly detection for contextual anomalies only when training TGNwith Eq. 2 vs Eq. 4; we report the result in Tab. 2. The table shows that contextual anomalies go undetectedwithout conditioning on contextual information.",
  "t89.291.9290.041.94c52.050.4097.240.2266.4911.1497.240.22t-c89.511.6097.610.17s-c97.670.2097.830.60t-s-c97.360.6498.240.22": "Result-Improvedtrainingregime.To demonstrate the effi-cacy of the improved negative sam-pler (see 4.3), we show that the re-vised sampler of Eq. 5 encouragesthe model to learn an enhanced rep-resentation of structure, time, andcontext compared to a random neg-ative sampler (Eq. 1).We useTempSynthGraph and computethe AUC performance of anomalydetection on various anomaly typesfor models trained with the negativesampler of Eq. 1 vs. Eq. 5; we report the result in Tab. 2. The table shows that the improved negativesampler boosts detection performance on all types of anomalies.",
  "Tab. 3 reports the link anomaly detection AUC on TempSynthGraph with synthetic anomalies. Our keyfindings are as follows": "Anomalies on multiple dimensions are easier to detect. Anomalies that deviate from the norm inmultiple respects are more easily identifiable. For example, Tab. 3 shows consistently that t-c anomaliesare easier to detect compared to c and t anomalies. Similarly, s-c anomalies are less detectable than t-s-c anomalies. All results in Tab. 3 support this finding within the confidence intervals, corroborating the",
  "validity of the graph generation process of 3.3: in TempSynthGraph, edges that are abnormal in multipledimensions become more anomalous with respect to the normal behavior": "GraphMixer excels in modeling temporal dynamics. GraphMixer demonstrates superior performancein detecting t and t-c anomalies on TempSynthGraph. As temporal anomalies differ from their benigncounterparts solely through timestamp variations (see 3.2), models require a robust representation of timeto better detect them.We note that GraphMixer employs a fixed time-encoding function (Cong et al.,2022), differently than other methods which use learnable ones (Rossi et al., 2020; Wang et al., 2021; 2020).In alignment with findings from Cong et al. (2022), fixed time-encoding functions improve performance byenhancing the stability of training and leading to better modeling of time. DyGFormer and CAWN are superior at modeling structure. DyGFormer and CAWN are well suitedfor identifying structural anomalies, i.e., s-c and t-s-c, achieving AUCs>99. CAWN is the only method thatconsiders two-hop neighbors to generate node embeddings, suggesting that broader receptive fields increasemethods ability to model structure. On the other hand, DyGFormer considers only one-hop neighbors, butit features a neighbor co-occurrence encoding scheme (Yu et al., 2023) capturing correlations between nodepairs and yielding weak structural information about two-hop paths between the nodes of interest. Thisadditional information contributes to DyGFormers superior performance in detecting structural anomalies.",
  "We report link anomaly detection AUC scores for models on Wikipedia, Reddit, MOOC, Enron, andUCI with synthetic anomalies in Tab. 4. Below are the key findings from the table": "Findings on TempSynthGraph generalize to real graphs with synthetic anomalies. As in Tab. 3,no single temporal graph method universally outperforms others across all datasets and anomaly types:even on a single anomaly type, no method consistently ranks first in Tab. 4 across all datasets. Similarly,GraphMixer demonstrates superior performance in detecting temporal anomalies also on real graphs, whileDyGFormer and CAWN exhibit superior performance in identifying structural anomalies. Real graphs may not exhibit strong consistencies. On TempSynthGraph, best-performing modelsconsistently achieve AUCs>96 (Tab. 3) on each anomaly type, demonstrating the ability of models to accu-rately identify anomalies in graphs with clear consistencies. Conversely, in real graphs, the best-performingmodels often exhibit significantly lower detection rates (Tab. 4), indicating a lack of consistencies along thethree dimensions. Detection of t anomalies in Reddit is notably poor, with CAWN achieving the highestresult at AUC=81.12. This implies that Reddit lacks regular temporal patterns, i.e., Reddit users tend topost at irregular times. In Wikipedia, no method detects c anomalies satisfactorily, with the best valuebeing at AUC=84.03, highlighting a lack of consistent contextual patterns. Note that edge attributes inWikipedia are a low-dimensional representation of the text contained in the page edit, suggesting thatthese edits carry limited contextual information. In UCI and Enron, detection of structural anomalies ischallenging, with the top two-performing models yielding AUC=86.45 and AUC=88.18, respectively. Thissuggests, counter-intuitively, that in the communication networks participants may tend to communicatewithout following strict structural rules. MOOC seems to be the most consistent network across all threeaspects, with all best-performing methods scoring with AUCs>96. These findings highlight the irregular",
  "Tab. 5 reports the link anomaly detection AUC on LANL and Darpa-Theia with organic anomalies. Herewe describe the main findings": "Organic anomalies in LANL and Darpa-Theia resemble synthetic structural anomalies. DyG-Former and CAWN exhibit the best performance on real datasets with organic anomalies, matching theirgood performance in detecting s-c and t-s-c synthetic anomalies in 5.4. In contrast, EdgeBanktw weaklyoutperforms a random baseline: it achieves AUC<67 in LANL and AUC<53 in Darpa-Theia. This dif-ference implies that while methods apt at detecting structural anomalies work well, memorization-basedapproaches such as EdgeBank are not well-suited to detect them. In particular, the extremely high propor-tion of unseen test edges in Darpa-Theia and LANL requires learning from non-structural aspects of theCTDG (Reha et al., 2023; Poursafaei et al., 2022). Significant disparities in model performances. There are considerable gaps between the top-performingand lowest-performing learning-based models in LANL and Darpa-Theia. This indicates that careful selec-tion of an appropriate method is crucial when dealing with real-world graphs containing organic anomalies:the best learning-based method outperforms the worst one by 6.8 and 21.39 AUC points, respectively.",
  "We discuss future directions for CTDG link anomaly detection in this section": "Opportunity 1: New CTDG datasets with organic anomalies. Previous research highlights theimportance of datasets with labeled organic anomalies for method comparison (Liu et al., 2022; Han et al.,2022). While synthetic anomalies are useful, they cannot fully substitute organic ones. In CTDG, onlyLANL (Kent, 2016) and DARPA (Reha et al., 2023) with organic anomalies exist, both from the cybersecu-rity domain. The limited and narrow testbed hinders comprehensive method comparison. Thus, developingdatasets across diverse domains is essential for robust method evaluation and exploring innovative approaches.",
  "Opportunity 2: Explainability of methods": "The ability to explain anomalies is crucial for practitioners (Panjei et al., 2022), especially in safety-criticalsectors like healthcare (Ukil et al., 2016), financial services (Ahmed et al., 2016), and self-driving car manu-facturing (Bogdoll et al., 2022). While efforts to elucidate temporal graph methods exist (He et al., 2022; Vu& Thai, 2022; Longa et al., 2023), only recently have explainable methods for CTDGs been introduced (Xiaet al., 2022). Explainability enhances our understanding of methods and their predictions, providing deeperinsights into organic anomalies. Comparing patterns between synthetic and organic anomalies allows drawingparallels, which improves method understanding and highlights distinctive features of organic anomalies. Opportunity 3: Reducing the gap between organic and synthetic anomalies. In 5.5, we observethat certain synthetic anomalies resemble organic ones, such as structural anomalies in LANL and Darpa-Theia. Specific anomaly detection methods excel at detecting particular types (5.3). These findings supportusing synthetic anomalies as proxies for model selection, reducing reliance on organic anomalies. This canbe achieved by using domain knowledge about prevalent anomaly types or by automating pipelines to maporganic anomalies to matching synthetic types. This approach allows selecting detection methods based onsynthetic anomaly validation sets, streamlining experimentation.",
  "Conclusions": "We presented a pioneering analysis of link anomaly detection in continuous-time dynamic graphs, addressinga gap in the current literature. Our comprehensive taxonomy of edge anomaly types and correspondinggeneration strategies, coupled with a synthetic graph generation process, enables better evaluation andunderstanding of anomaly detection in CTDG. Our experimental findings, together with a discussion onfuture research opportunities, enable further research in learning anomaly detection methods for CTDGs.",
  "Mohiuddin Ahmed, Abdun Naser Mahmood, and Md Rafiqul Islam. A survey of anomaly detection tech-niques in financial domain. Future Generation Computer Systems, 55:278288, 2016": "Sambaran Bandyopadhyay, N Lokesh, and M Narasimha Murty.Outlier aware network embedding forattributed networks.In Proceedings of the AAAI conference on artificial intelligence, volume 33, pp.1219, 2019. Siddharth Bhatia, Bryan Hooi, Minji Yoon, Kijung Shin, and Christos Faloutsos. Midas: Microcluster-baseddetector of anomalies in edge streams. In Proceedings of the AAAI conference on artificial intelligence,volume 34, pp. 32423249, 2020. Siddharth Bhatia, Rui Liu, Bryan Hooi, Minji Yoon, Kijung Shin, and Christos Faloutsos. Real-time anomalydetection in edge streams. ACM Transactions on Knowledge Discovery from Data (TKDD), 16(4):122,2022. Daniel Bogdoll, Maximilian Nitsche, and J Marius Zllner. Anomaly detection in autonomous driving: Asurvey.In Proceedings of the IEEE/CVF conference on computer vision and pattern recognition, pp.44884499, 2022. Lei Cai, Zhengzhang Chen, Chen Luo, Jiaping Gui, Jingchao Ni, Ding Li, and Haifeng Chen. Structuraltemporal graph neural networks for anomaly detection in dynamic graphs. In Proceedings of the 30th ACMinternational conference on Information & Knowledge Management, pp. 37473756, 2021. Kyunghyun Cho, Bart van Merrinboer, Dzmitry Bahdanau, and Yoshua Bengio.On the properties ofneural machine translation: Encoderdecoder approaches. In Proceedings of SSST-8, Eighth Workshop onSyntax, Semantics and Structure in Statistical Translation, pp. 103111, 2014. Weilin Cong, Si Zhang, Jian Kang, Baichuan Yuan, Hao Wu, Xin Zhou, Hanghang Tong, and MehrdadMahdavi. Do we really need complicated model architectures for temporal networks?In The EleventhInternational Conference on Learning Representations, 2022.",
  "Kaize Ding, Jundong Li, Rohit Bhanushali, and Huan Liu. Deep anomaly detection on attributed networks.In Proceedings of the 2019 SIAM International Conference on Data Mining, pp. 594602. SIAM, 2019": "Yingtong Dou, Zhiwei Liu, Li Sun, Yutong Deng, Hao Peng, and Philip S Yu. Enhancing graph neuralnetwork-based fraud detectors against camouflaged fraudsters. In Proceedings of the 29th ACM interna-tional conference on information & knowledge management, pp. 315324, 2020. Dhivya Eswaran, Christos Faloutsos, Sudipto Guha, and Nina Mishra. Spotlight: Detecting anomalies instreaming graphs.In Proceedings of the 24th ACM SIGKDD International Conference on KnowledgeDiscovery & Data Mining, pp. 13781386, 2018. Haoyi Fan, Fengbin Zhang, and Zuoyong Li. Anomalydae: Dual autoencoder for anomaly detection onattributed networks.In ICASSP 2020-2020 IEEE International Conference on Acoustics, Speech andSignal Processing (ICASSP), pp. 56855689. IEEE, 2020. Anuroop Gaddam, Tim Wilkin, Maia Angelova, and Jyotheesh Gaddam. Detecting sensor faults, anomaliesand outliers in the internet of things: A survey on the challenges and solutions. Electronics, 9(3):511,2020.",
  "Wenchong He, Minh N Vu, Zhe Jiang, and My T Thai. An explainer for temporal graph neural networks.In GLOBECOM 2022-2022 IEEE Global Communications Conference, pp. 63846389. IEEE, 2022": "Shenyang Huang, Farimah Poursafaei, Jacob Danovitch, Matthias Fey, Weihua Hu, Emanuele Rossi, JureLeskovec, Michael M Bronstein, Guillaume Rabusseau, and Reihaneh Rabbany. Temporal graph bench-mark for machine learning on temporal graphs.In Thirty-seventh Conference on Neural InformationProcessing Systems Datasets and Benchmarks Track, 2023a. Yihong Huang, Liping Wang, Fan Zhang, and Xuemin Lin. Unsupervised graph outlier detection: Prob-lem revisit, new insight, and superior method. In 2023 IEEE 39th International Conference on DataEngineering (ICDE), pp. 25652578. IEEE, 2023b. Ming Jin, Yuan-Fang Li, and Shirui Pan. Neural temporal walks: Motif-aware representation learning oncontinuous-time dynamic graphs. Advances in Neural Information Processing Systems, 35:1987419886,2022.",
  "Diederik Kingma and Jimmy Ba. Adam: A method for stochastic optimization. In International Conferenceon Learning Representations (ICLR), San Diega, CA, USA, 2015": "Srijan Kumar, Xikun Zhang, and Jure Leskovec. Predicting dynamic embedding trajectory in temporalinteraction networks. In Proceedings of the 25th ACM SIGKDD international conference on knowledgediscovery & data mining, pp. 12691278, 2019. Fanzhen Liu, Shan Xue, Jia Wu, Chuan Zhou, Wenbin Hu, Cecile Paris, Surya Nepal, Jian Yang, andPhilip S Yu. Deep learning for community detection: Progress, challenges and opportunities. In ChristianBessiere (ed.), Proceedings of the Twenty-Ninth International Joint Conference on Artificial Intelligence,IJCAI-20, pp. 49814987. International Joint Conferences on Artificial Intelligence Organization, 7 2020.doi: 10.24963/ijcai.2020/693. URL Survey track. Kay Liu, Yingtong Dou, Yue Zhao, Xueying Ding, Xiyang Hu, Ruitong Zhang, Kaize Ding, Canyu Chen,Hao Peng, Kai Shu, et al. Bond: Benchmarking unsupervised outlier node detection on static attributedgraphs. Advances in Neural Information Processing Systems, 35:2702127035, 2022. Antonio Longa, Veronica Lachi, Gabriele Santin, Monica Bianchini, Bruno Lepri, Pietro Lio, franco scarselli,and Andrea Passerini. Graph neural networks for temporal graphs: State of the art, open challenges,and opportunities. Transactions on Machine Learning Research, 2023. ISSN 2835-8856. URL Xiaoxiao Ma, Jia Wu, Shan Xue, Jian Yang, Chuan Zhou, Quan Z Sheng, Hui Xiong, and Leman Akoglu. Acomprehensive survey on graph anomaly detection with deep learning. IEEE Transactions on Knowledgeand Data Engineering, 2021. Amirhossein Nadiri and Frank W Takes. A large-scale temporal analysis of user lifespan durability on thereddit social media platform. In Companion Proceedings of the Web Conference 2022, pp. 677685, 2022.",
  "Farimah Poursafaei, Shenyang Huang, Kellin Pelrine, and Reihaneh Rabbany. Towards better evaluation fordynamic link prediction. volume 35, pp. 3292832941, 2022": "Jakub Reha, Giulio Lovisotto, Michele Russo, Alessio Gravina, and Claas Grohnfeldt. Anomaly detection incontinuous-time temporal provenance graphs. In Temporal Graph Learning Workshop @ NeurIPS 2023,2023. URL Emanuele Rossi, Ben Chamberlain, Fabrizio Frasca, Davide Eynard, Federico Monti, and Michael Bronstein.Temporal graph networks for deep learning on dynamic graphs. arXiv preprint arXiv:2006.10637, 2020. Jitesh Shetty and Jafar Adibi. The enron email dataset database schema and brief statistical report. Infor-mation sciences institute technical report, University of Southern California, 4(1):120128, 2004.",
  "Georg Steinbuss and Klemens Bhm. Benchmarking unsupervised outlier detection with realistic syntheticdata. ACM Transactions on Knowledge Discovery from Data (TKDD), 15(4):120, 2021": "Arijit Ukil, Soma Bandyoapdhyay, Chetanya Puri, and Arpan Pal. Iot healthcare analytics: The importanceof anomaly detection. In 2016 IEEE 30th international conference on advanced information networkingand applications (AINA), pp. 994997. IEEE, 2016. Ashish Vaswani, Noam Shazeer, Niki Parmar, Jakob Uszkoreit, Llion Jones, Aidan N Gomez, ukasz Kaiser,and Illia Polosukhin. Attention is all you need. Advances in neural information processing systems, 30,2017.",
  "Minh N Vu and My T Thai. On the limit of explaining black-box temporal graph neural networks. arXivpreprint arXiv:2212.00952, 2022": "Lu Wang, Xiaofu Chang, Shuang Li, Yunfei Chu, Hui Li, Wei Zhang, Xiaofeng He, Le Song, Jingren Zhou,and Hongxia Yang. Tcl: Transformer-based dynamic graph modelling via contrastive learning. arXivpreprint arXiv:2105.07944, 2021. Yanbang Wang, Yen-Yu Chang, Yunyu Liu, Jure Leskovec, and Pan Li. Inductive representation learning intemporal networks via causal anonymous walks. In International Conference on Learning Representations,2020. Wenwen Xia, Mincai Lai, Caihua Shan, Yao Zhang, Xinnan Dai, Xiang Li, and Dongsheng Li. Explainingtemporal graph models through an explorer-navigator framework. In The Eleventh International Confer-ence on Learning Representations, 2022.",
  "A.1Datasets": "In our experiments, we use the proposed synthetic graph (3.3), five datasets collected by Poursafaei et al.(2022), the Los Alamos National Lab (LANL) dataset (Kent, 2016) and the darpa-theia dataset (Rehaet al., 2023). We report an overview of each datasets statistics in , and describe them here: TempSynthGraph comprises N = 10, 000 nodes divided into M = 10 communities of equal size. Theunderlying static graph is generated using a stochastic block model (Abbe, 2018), featuring six timesmore static edges within communities than between them.The temporal graph consists of roughlyE = 1, 000, 000 temporal edges, where each unique edge (i.e., an edge between a given pair of nodes)occurs = 50 times on average. The graph spans tMAX = 108 steps. The parameters for sampling edgetime spans, ts and ts, are configured to make edge spans, on average, 1% of the entire graph time span,with a standard deviation of 0.5%. The timestamps of temporal edges are perturbed with (t) equaling5% of the average inter-event time of the edge: te oe . Nodes are assigned to one of C = 5 types. The edgemessage dimension is D = 100. The function ExpectedMessage(j, k, D) of Alg. 1 returns the meanedge messages (m)j,k where the lth element is computed as follows:",
  "(m)c,c = [0, 0, 0, 0, 0, 0, 0, 0, ..., 1, 1, 1, 1],": "the length of a consecutive block of 1s (or 0s) isDC2 . In sampling edge messages, the mean edge messagesare perturbed with Gaussian noise with standard deviation (m) = 0.05. Note that orthogonality betweenmean edge messages is not a general requirement but we use it here to guarantee small overlaps betweenrandomly perturbed edge messages belonging to classes, with the goal of isolating contextual anomalies.Less strict implementations of ExpectedMessage can be used in principle. Wikipedia (Kumar et al., 2019) is a bipartite interaction graph encompassing edits made to Wikipediapages within a one-month timeframe.Users and pages are represented as nodes, while links signifyediting interactions along with corresponding timestamps. Each link is accompanied by a 172-dimensionalLinguistic Inquiry and Word Count feature (Pennebaker et al., 2001) that is derived from the content ofthe edit. Reddit (Kumar et al., 2019) is a bipartite network that documents user posts under various subredditsover the course of one month. Users and subreddits serve as nodes, and the connections between themrepresent timestamped posting requests. Each link is accompanied by a 172-dimensional Linguistic Inquiryand Word Count feature (Pennebaker et al., 2001), derived from the content of the respective post. MOOC (Kumar et al., 2019) is a bipartite interaction network, consisting of actions done by studentsin a MOOC online course. Students and course units (e.g., videos and problem sets) are represented asnodes, while a link within the network signifies a students interaction with a particular content unit andis associated with a 4-dimensional feature.",
  "Enron (Shetty & Adibi, 2004) contains email correspondences exchanged among ENRON energy companyemployees over a three-year period. The dataset has no edge features": "UCI (Panzarasa et al., 2009) is an online communication network among students of the University ofCalifornia at Irvine. Nodes represent university students, and links are messages posted by students. Thelinks have no edge features. Los Alamos National Lab (LANL) dataset (Kent, 2016) comprises authentication events occurring over 58consecutive days within the corporate internal computer network of the Los Alamos National Laboratory.Computers are denoted as nodes, and the links between them represent authentication events. Eventsassociated with the red team, which exhibit bad behavior, are labeled as malicious links - organic anomaliesin 5. The dataset lacks edge features. We pre-process the LANL dataset according to the methodologyoutlined in King & Huang (2023), but without combining edges into discrete graph snapshots. Due tothe substantial size of the dataset (1.6 billion edges), we evenly subsample the benign edges to obtainapproximately 1,000,000 total edges. Darpa-Theia (Reha et al., 2023) is system-level data provenance graphs, constructed from the auditlogs collection made by DARPA Engagement 3 (DARPA, 2020). The dataset contains both benign andmalicious activities, where the latter are carried out by a red team and represent organic anomalies. Nodesrepresent files, processes, and sockets, while links correspond to Linux system calls with timestamps. Eachlink is associated with a 47-dimensional edge feature, describing the system call and the involved nodes.",
  "DatasetsDomain#Nodes#Edges#Edge featuresBipartiteDuration#Unique Steps": "TempSynthGraphSynthetic10,0001,002,325100False108 steps997,256WikipediaSocial9,227157,474172True1 month152,757RedditSocial10,984672,447172True1 month588,915MOOCInteraction7,144411,7494True17 months345,600EnronSocial184125,235False3 years22,632UCISocial1,89959,835False196 days58,911LANL (ours)Cybersecurity13,0811,030,147False58 days1,027,178Darpa-TheiaCybersecurity1,043,2248,416,18747False247 hours1,766,816 TGN (Rossi et al., 2020) is a general framework for learning on continuous-time temporal graphs. Itkeeps a dynamic memory for each node and updates this memory when the node is observed in an event.This is realized by a memory module, a message function, a message aggregator, and a memory updater.To obtain the temporal representation of a node, embedding module aggregates the nodes memory andmemories of its neighbors. CAWN (Wang et al., 2020) initially extracts multiple causal anonymous walks for a node of interest. Thesewalks serve to explore the causality within network dynamics and operate on relative node identities,making the model inductive. Subsequently, it employs recurrent neural networks to encode each walk andaggregates the resulting representations to derive the final node representation. TCL (Wang et al., 2021) utilizes a transformer module to create temporal neighborhood representationsfor nodes engaged in an interaction. Then, it models the inter-dependencies by employing a co-attentionaltransformer at a semantic level. To achieve this, TCL incorporates two distinct encoders to derive rep-resentations from the temporal neighborhoods surrounding the two nodes forming an edge. Additionally,during the training process, TCL employs a temporal contrastive objective function to preserve the high-level semantics of interactions in latent representations of the nodes. GraphMixer (Cong et al., 2022) is a simple model architecture that comprises three components: alink-encoder that summarizes information from temporal links with multi-layer perceptions (MLP), anode-encoder that summarizes node information with neighbor mean-pooling, and a link classifier thatperforms link prediction based on the outputs of the encoders.It is noteworthy that none of thesecomponents incorporate graph neural network modules. Additionally, GraphMixer introduced a fixedtime-encoding function that encodes any timestamp as an easily distinguishable input vector. DyGFormer (Yu et al., 2023) is a transformer-based architecture for dynamic graph learning. It first ex-tracts historical first-hop interactions of the nodes participating in the interaction, yielding two interactionsequences. Then, it utilizes a neighbor co-occurrence encoding scheme to model correlations between thetwo nodes, based on the two interaction sequences. DyGFormer splits the interaction sequences enrichedwith the neighbor co-occurrence encoding into multiple patches and feeds them into a transformer forcapturing long-term temporal dependencies. Finally, the node representations are derived by averagingthe corresponding outputs of the transformer. EdgeBank (Poursafaei et al., 2022) is a simple heuristic that stores all observed edges in a memory.Given an edge, EdgeBank predicts it as positive if the corresponding node pair is found in the memory,otherwise, EdgeBank predicts it as negative. EdgeBanktw (Poursafaei et al., 2022) is a version of EdgeBank that only memorizes edges from a limitedtime window in the recent past. Therefore, it has a strong recency bias and forgets edges that occurredlong ago.",
  "BComputational Efficiency": "contains training plus validation time of the temporal graph methods on TempSynthGraph.The most computationally efficient methods in our study are TCL and DyGFormer, both based on thetransformers architecture (Vaswani et al., 2017). GraphMixer and TGN exhibit a significantly longer trainingand validation times, approximately three times slower than the aforementioned methods. CAWN emergesas the slowest among the considered techniques, primarily due to the sampling of random walks at two-hops(compared to the remaining methods being 1-hop). : Training and validation times of temporal graph methods per epoch on the synthetic graph. Resultsare reported in minutes and averaged over 20 runs. Measurements are performed on an Ubuntu machineequipped with one Intel(R) Xeon(R) CPU E5-2658A v3 @ 2.20GHz with 24 physical cores.",
  "Anomaly typeEdgeBank EdgeBanktwTGNCAWNTCLGraphMixer DyGFormer": "t24.860.3824.870.3738.8313.86 45.255.66 59.986.2769.330.4948.810.57c3.610.203.610.2048.341.6149.158.46 31.873.7557.644.0860.183.45t-c24.990.3624.960.3959.282.4457.183.98 54.813.6967.781.7448.764.35s-c70.250.0770.250.0747.013.2370.530.54 55.944.8463.532.2173.211.63t-s-c70.930.4070.830.2859.213.45 72.260.22 63.732.9270.171.1572.020.25 : AP for models on Wikipedia, Reddit, MOOC, Enron and UCI with typed synthetic anomalies(3.2). Bold and underlined values mark first- and second-best performing models across rows. We do notreport results on Enron and UCI for c and t-c anomalies as these datasets lack edge attributes.",
  "DStatistical Properties of the Synthetic and Real-World Graphs": "We present an analysis of the statistical properties of the synthetic graphs introduced in 3.3 and the real-world graphs listed in App. A.1.In particular, we analyze properties related to the structure, context,and temporal dynamics of the graphs, highlighting consistencies and irregularities in and across these threedimensions. Structure. To analyze and compare the graphs for their structural properties, we compute the distributionsof node degrees and the joint degree matrices, defined as the relative number of edges between vertices ofdegree i and degree j for every pair (i, j), of the static versions of the graphs (i.e., the graphs withouttimestamps). These statistics are displayed in and , respectively. Notably, both statisticsreveal Gaussian distributions of and across node degrees in the synthetic graph, confirming the desiredstructural consistency in this controlled setting. Conversely, distributions of and across node degrees areless structured within and inconsistent across the real-world datasets. Notably, all real-world datasets havea long-tailed distribution of node degrees, with top degrees ranging from 111 (Enron) to 6695 (MOOC).Moreover, node degrees in Wikipedia, Reddit, and UCI follow exponential distributions, whereas nodedegrees in the Enron dataset follow a noisy Gaussian distribution. MOOC is globally weakly interconnectedexcept for various outlier nodes with degrees between 2 and 6695. Moreover, the similarity between thedegrees of neighboring nodes constituting the joint degree matrices depicted suggests the datasets structuralhomogeneity and consistency, which reveals to be strong in TempSynthGraph, weaker yet existingin Enron and UCI, and at most very weak in Wikipedia, Reddit, and MOOC. Context. We investigate the contextual consistencies of graphs by analyzing the distributions of standarddeviations of edge messages across timestamps. Higher standard deviations indicate edges with inconsis-tent edge messages over time. In this view, shows that edge messages in real-world graphs exhibitsubstantially lower contextual consistency than the synthetic graph. Specifically, TempSynthGraph fea-tures standard deviations concentrated around 0.05, whereas Wikipedia, Reddit, and MOOC featureexponential distributions of standard deviations with tails ending around 9, 5, and 20, respectively. Notethat Enron and UCI have standard deviations of zero due to the absence of edge messages in these datasets. Time. We analyze the temporal patterns of the graphs by examining the distributions of standard deviationsof inter-event times for edges that reoccur multiple times. Wider distributions indicate graphs with less"
}