{
  "Abstract": "Traditional neural networks are simple to train but they typically produce overconfidentpredictions. In contrast, Bayesian neural networks provide good uncertainty quantificationbut optimizing them is time consuming due to the large parameter space.This paperproposes to combine the advantages of both approaches by performing Variational Inferencein the Final layer Output space (VIFO), because the output space is much smaller thanthe parameter space. We use neural networks to learn the mean and the variance of theprobabilistic output. Using the Bayesian formulation we incorporate collapsed variationalinference with VIFO which significantly improves the performance in practice. On the otherhand, like standard, non-Bayesian models, VIFO enjoys simple training and one can useRademacher complexity to provide risk bounds for the model. Experiments show that VIFOprovides a good tradeoff in terms of run time and uncertainty quantification, especially forout of distribution data.",
  "Introduction": "With the development of training and representation methods for deep learning, models using neural networksprovide excellent predictions. However, such models fall behind in terms of uncertainty quantification andtheir predictions are often overconfident (Guo et al., 2017). Bayesian methods provide a methodology foruncertainty quantification by placing a prior over parameters and computing a posterior given observeddata, but the computation required for such methods is often infeasible. Variational inference (VI) is one ofthe most popular approaches for approximating the Bayesian outcome, e.g., (Blundell et al., 2015; Graves,2011; Wu et al., 2019). By minimizing the KL divergence between the variational distribution and the trueposterior and constructing an evidence lower bound (ELBO), one can find the best approximation to theintractable posterior. However, when applied to deep learning, VI requires sampling to compute the ELBO,and it suffers from both high computational cost and large variance in gradient estimation. Wu et al. (2019)have proposed a deterministic variational inference (DVI) approach to alleviate the latter problem. The idearelies on the central limit theorem, which implies that with sufficiently many hidden neurons, the distributionof the output of each layer forms a multivariate Gaussian distribution. Thus we only need to compute themean and covariance of the output of each layer. However, DVI still suffers from high computational costand complex optimization. Inspired by DVI, we observe that the only aspect that affects the prediction is the distribution of the output ofthe final layer in the neural network. We therefore propose to perform variational inference in the final-layeroutput space (rather than parameter space), where the posterior mean and diagonal variance are learned bya neural network. We call this method VIFO. Like all Bayesian methods, VIFO induces a distribution over",
  "Published in Transactions on Machine Learning Research (09/2024)": "Note for the case K > 1: Let RdK.For VI, we make a mean field assumption with q(k) =N(k|mk, Sk) and q() = Kk=1 q(k), where k is the k-th column of . For VIFO, using mean field letq(zk|x) = N(zk|wk x, xVkx) and q(z|x) = KEq(z|xi)[log p(yi|z1, . . . zK)] = Eq()[log p(yi|( k=1 q(zk|x). By aligning wk = mk and V = Sk, we can find1 xi, . . . , Kxi))], and",
  "VIFO": "In this section we describe our VIFO method in detail. We start with a description of the non-Bayesian basemodel. Given a neural network parametrized by weights W and input x, the output is z = fW (x) RK. Thebase model provides probabilistic predictions by combining the output of the network with any predictionlikelihood p(y|z). Traditional, non-Bayesian models, minimize log p(y|z) or a regularized variant.Remark 2.1. The base model and VIFO are applicable with any likelihood function and our developmentof VIFO below is general. To illustrate we discuss classification and regression. In classification, K is thenumber of classes. The probability of being class i is defined as",
  ".(2)": "By fixing the weights W, base models map x to z deterministically. Bayesian inference puts a distributionover W and marginalizes out to get a distribution over z from which predictions can be calculated. Sinceexact marginalization is not tractable, variational inference provides an approximation which yields the wellknown ELBO objective for optimization:",
  "(x,y)DEq(W )[log p(y|W, x)] KL(q(W)p(W)).(3)": "As shown by Wu et al. (2019), by the central limit theorem, with a sufficiently wide neural network themarginal distribution of z is Gaussian. DVI explicitly calculates an analytic approximation of the mean andvariance of the output of each layer (valid for specific activation functions) and avoids the sampling typicallyused for optimization of the ELBO in other methods. VIFO pursues this in a direct manner. It has two sets of weights, W1 and W2 (with potentially shared compo-nents), to model the mean and variance of z. That is, q(x) = fW1(x), q(x) = g(fW2(x)), where g : R R+ maps the output to positive real numbers as the variance is positive. Thus, q(z|x) = N(z|q(x), diag(2q(x))),where q(x), 2q(x) are vectors of the corresponding dimension. We will call q(z|x) the variational outputdistribution. As in the base model, given z, y is generated from the likelihood p(y|z).",
  "(b) with auxiliary training": ": Predictive distribution of VIFO using an MLP. Blue points are training data generated from asinusoidal function, red points are the predicted mean, shaded area indicates the 1 standard deviation. Moredetails are in Appendix D.1. Remark 2.2. VIFO in regression is different from the existing models known as the mean-variance estimator(Kabir et al., 2018; Khosravi et al., 2011; Kendall & Gal, 2017). Instead, mean-variance estimators are thebase models that VIFO can be applied on. Applying VIFO to these models results in four outputs: m andl, which are the means of m and l, and 2m and 2l , which are the variances of m and l. These variancescome from the variational output distribution. We sample m N(m, 2m) and l N(l, 2l ), then formz = (m, l). Like all Bayesian methods VIFO computes a distribution over distributions which is lacking innon-Bayesian predictions. Unlike VI which puts a prior over W, VIFO models the distribution over z and therefore we put a priordirectly over z. We consider two options, a conditional prior p(z|x) and a simpler prior p(z). Both of thesechoices yield a valid ELBO using the same steps:",
  "= Eq(z|x)[log p(y|z)] KL(q(z|x)p(z|x)).(4)": "The approach has some similarity to Dirichlet-based models (Sensoy et al., 2018; Charpentier et al., 2020;Bengs et al., 2022). However, we perform inference on the output whereas, as discussed by Bengs et al.(2022), these models implicitly perform variational inference on the prediction. In particular, in that work zis interpreted as a vector in the simplex and q(z|x) and p(z) are Dirichlet distributions, whereas when usingVIFO for classification z has a Gaussian distribution and p(y|z) is on the simplex. In other words, we modeland regularize different distributions. We discuss related work in more details below.",
  "Auxiliary Training": "As in prior work (Sun et al., 2019), to improve uncertainty quantification we introduce auxiliary inputxaux and include KL(q(z|xaux)p(z|xaux)) as an additional regularization term. We include correspondingcoefficients and aux on the regularizers, as is often done in variational approximations (e.g., (Higgins et al.,2017; Sheth & Khardon, 2017; Jankowiak et al., 2020; Wenzel et al., 2020; Wei et al., 2021; Wei & Khardon,2022).). Then, viewed as a regularized loss minimization, the optimization objective for VIFO becomes:",
  "Collapsed VIFO": "Bayesian methods are often sensitive to the choice of prior parameters. To overcome this, Wu et al. (2019)used empirical Bayes (EB) to select the value of the prior parameters, and Tomczak et al. (2021) proposedcollapsed variational inference, which defined a hierarchical model and performed inference on the priorparameters as well.We show how these ideas are applicable in VIFO and derive empirical Bayes as aspecial case of collapsed variational inference. In addition to z, we model the prior mean p and variance2p as Bayesian parameters. Now the prior becomes p(z|p, 2p)p(p, 2p) and the variational distribution isq(z|x)q(p, 2p). Then the objective becomes:",
  "= Eq(z|x)[log p(y|z)] Eq(p,2p)[KL(q(z|x)p(z|p, 2p))] KL(q(p, 2p)p(p, 2p)).(6)": "Similar to Eq. (5), we treat the first term as a loss and the other two terms as a regularizer along with acoefficient and aggregate over all data. Since the loss does not contain p and 2p, we can get the optimalq(p, 2p) by optimizing the regularizer and the choice of will not affect q(p, 2p). Then we can plug inthe value of q into Eq. (6). We next show how to compute q(p, 2p) and the final collapsed variationalinference objective. The derivations are similar to the ones by Tomczak et al. (2021) but they are appliedon z not on W. Recall that K is the dimension of z.",
  "(c) VI-mean": ": Induced predictions by learned prior distribution for different methods. Note that VI has a priorover weights and VIFO has a prior over z. For each method we sample values from the prior and calculatepredictions y based on the sampled values. We then plot the y values. As we can see, VI-naive induces auniform prior that does not capture the data distribution, VI-mean has an increased variance in areas wheredata is missing and VIFO-mean does so to a larger extent. Details are given in Appendix D.1.",
  "Expressiveness of VIFO": "VIFO is inspired by DVI and it highly reduces the computational cost. In this section we explore whetherVIFO can produce exactly the same predictive distribution as VI. We show that this is the case for linearmodels but that for deep models VIFO is less powerful. We first introduce the setting of linear models. Letthe parameter be , then the model is:",
  "+exp(x) for Bayesian binary classification": "For simplicity, we assume Rd, where d is the dimension of x, and then the output dimension K = 1. Thestandard approach specifies the prior of to be p() = N(|m0, S0), and uses q() = N(|m, S). Then theELBO objective, with a dataset XN = (x1, x2, . . . , xN) RdN and YN = (y1, y2, . . . , yN) RN, is",
  ".(9)": "As the following theorem shows, if we use a conditional correlated prior and a variational posterior thatcorrelates data points, then in the linear case VIFO can recover the ELBO and VI solution. We defer theproof and discussion of K > 1 to Appendix A.1. Theorem 3.1. Let q(z|x) = N(z|wx, xV x) be the variational predictive distribution of VIFO, wherew and V are the parameters to be optimized, and let p(z|XN) = N(z|m0 XN, XNS0XN) and q(z|XN) =N(z|wXN, XNV XN) be a correlated and data-specific prior and posterior (which means that for differentdata x, we have a different prior/posterior over z). Then the VIFO objective is equivalent to the ELBOobjective implying identical predictive distributions.",
  "Rademacher Complexity of VIFO": "In this section we provide generalization bounds for VIFO through Rademacher Complexity. We need tomake the following assumptions. These assumptions hold for classification and with a smoothed loss forregression as shown in Appendix A.2.Assumption 4.1. log p(y|z) is L0-Lipschitz in z, i.e., | log p(y|z) log p(y|z)| L0z z2.Assumption 4.2. The link function g is L1-Lipschitz.",
  "Recall that the Rademacher complexity of a set of vectors ARNis defined as R(A)=1N E{1,1}N [supaA": "i iai]. The Rademacher complexity of the set of loss values induced by functionsf F over a dataset S has been used to derive generalization bounds for learning of the class F. We needthe following technical lemma, proved in Appendix A.2, that generalizes well known Lipschitz based bounds(Shalev-Shwartz & Ben-David, 2014) to multi-input functions.Lemma 4.3. Consider an L-Lipschitz function : R R R, i.e. (a1, b1) (a2, b2) L(|a1 a2| +|b1 b2|). For a, b RN, let (a, b) denote the vector ((a1, b1), . . . , (aN, bN)). Let (A B) denote{(a, b) : a A, b B}, then",
  "R((A B)) L(R(A) + R(B)).(10)": "Applying the previous lemma sequentially over multiple dimensions we obtain:Corollary 4.4. Consider an L-Lipschitz function : Rd R, i.e., for any x, x Rd, (x) (x) Lx x1. Let (Ad) = {(a1:d,i) : a1, a2, . . . , ad A RN}, then R((Ad)) LdR(A). With the assumptions and technical lemma, we derive the main result:Theorem 4.5. Let H be the set of functions that can be represented with neural networks with parameterspace W, H = {fW ()|W W}.VIFO has two components, so the VIFO hypothesis class is H H= {(fW1(), fW2()) |W = (W1, W2), W1, W2 W}.Let l be the loss function for VIFO, l(W, (x, y)) =EqW (z|x)[ log p(y|z)].Then the Rademacher complexity of VIFO is bounded as R(l (H H) S) 2(L0 max{1, L1}K) R(H S), where K is the dimension of z and S is training dataset. The proof is in Appendix A.2 and it shows how reparamertization can facilitate computation of Rademacherbounds for Bayesian predictors. The Rademacher complexity for VIFO is bounded through the Rademachercomplexity of deterministic neural networks. This shows one advantage of VIFO which is more amenableto analysis than standard VI due to its simplicity. Risk bounds for VI have been recently developed (e.g.,(Germain et al., 2016; Sheth & Khardon, 2017)) but they require different proof techniques. The Rademacher",
  "Experiments": "In this section, we compare the empirical performance of VIFO with VI and hybrid methods that usethe base model. In VIFO, W1 and W2 share all parameters except those in the last layer. VI candidatesinclude the VI algorithm (VI-naive(Blundell et al., 2015)) with fixed prior parameters, and other variationsfrom collapsed variational inference (Tomczak et al., 2021) and empirical Bayes (Wu et al., 2019). Non-Bayesian and hybrid methods include the base model (SGD, because it uses stochastic gradient descentas optimizer), stochastic weight averaging (SWA, which uses the average of the SGD trajectory on thebase model as the final weights) from Izmailov et al. (2018) and SWA-Gaussian (SWAG, which uses theSGD trajectory to form a Gaussian distribution over the neural network weight space) from Maddox et al.(2019).We use ensembles of the base models which are known as deep ensembles (Lakshminarayananet al., 2017), and the ensembles of SWAG models, which are the multiSWAG model of Wilson & Izmailov(2020), both of which are considered strong baselines for uncertainty quantification (Ovadia et al., 2019). Inaddition to these methods, we include other approximate Bayesian algorithms for comparison. These includerepulsive ensembles (Repulsive, (DAngelo & Fortuin, 2021)), the Dirichlet-based model (Dir, (Sensoyet al., 2018)), dropout ((Gal & Ghahramani, 2016)), last layer Laplace with prior optimization (Laplace,(Daxberger et al., 2021)), and variational Bayes last layer (VBLL, (Harrison et al., 2024)). Our main goalis to show:",
  "Ensembles of VIFO achieve better uncertainty quantification on shifted and out-of-distribution(OOD) data than all baselines": "For our main experiments, we pick four large datasets, CIFAR10, CIFAR100, SVHN, STL10, together withtwo types of neural networks, AlexNet (Krizhevsky et al., 2012) and PreResNet20 (He et al., 2016). Theregularization parameter is fixed to 0.1 for both VIFO and VI, as this choice yields better performancecompared with the standard choice = 1. Empirically we observe that using collapsed variational inferencein VI does not improve the performance.This is because Tomczak et al. (2021) used = 1 to obtaintheir results whereas we use = 0.1 which provides a much stronger baseline. For auxiliary training, weexperiment with aux {0.0, 0.1, 0.5, 1.0}. Larger values of aux generally improve OOD data detection atthe cost of increased in-distribution loss, and there is no generic optimal value of aux. In our main paper,we present only the case where aux = 0.1 because it provides a balance between in-distribution and OODperformance, with performance of other choices of aux provided in the appendix. In addition, VIFO-meanand VIFO-mv perform better than other variants of VIFO. Thus, we only list these variants in our mainpaper and provide full results for other variants for VIFO and VI in the appendix. For each method we run5 independent runs and report means and standard deviations in results. Complete details for the setup andhyperparameters are given in Appendix D.2. Our code is available on",
  "Run Time": "Ignoring the data preprocessing time, we compare the run time of training 1 epoch of VI, VIFO and thebase model. In we show the mean and standard deviation of 10 runs of these methods. Differentregularizers do not affect run time, so we only show that of VI-naive for VI and VIFO-mean for VIFO. Inaddition, as shown in , VIFO is much faster than VI and is slightly slower than the base model.As shown in Fig. E.7, VIFO converges faster than, or as fast as VI. Consequently, the training time untilconvergence for VIFO is shorter than for VI.",
  "singleensemblesingleensemble": "CIFAR100.527 0.0150.345 0.0030.626 0.0100.324 0.001CIFAR1002.253 0.0321.688 0.0062.688 0.0291.725 0.003STL101.333 0.0651.055 0.0081.531 0.0191.123 0.008SVHN0.509 0.0290.351 0.0050.520 0.0270.298 0.009 The differences in run time are dominated by sampling and forward passes in the network. Let P denote thenumber of parameters in the base model and thus each forward/backward pass takes O(P) time. The timecomplexity for computing the loss for each output of the base model is O(1). The base model only needs 1forward pass without sampling and thus the time complexity is O(P). VIFO needs 1 forward pass and Msamples to compute the loss so the time complexity is O(P + M). VI needs M samples of the parameterspace and M forward passes, thus the time complexity is O(PM + M) = O(PM). The same facts apply forpredictions on test data, where the advantage can be important for real time applications.",
  "Ensembles of VIFO": "Theorem 3.2 points out that the expressiveness of VIFO is limited. To overcome this, we use ensembles ofVIFO, which independently train multiple VIFO models and average their predictions. .1 establishesfast training of VIFO, allowing us to train VIFO models simultaneously while still maintaining the runningtime advantage of VIFO. We investigate the impact of ensemble size on performance in Appendix E.5. Whileincreasing the ensemble size enhances performance, the improvement diminishes once the size exceeds 5.Therefore, we choose an ensemble size of 5. shows that with ensembles, VIFO with auxiliary trainingachieves much better log loss than when using a single model. The same holds without auxiliary training.This indicates that ensembles of VIFO are much more expressive than a single VIFO. In the followingexperiments, we use ensembles of VIFO. For a fair comparison in the remainder of the paper, weuse ensembles for all methods except for VI (which is time-consuming) and repulsive ensembles (whichare themselves ensembles).",
  "In this section we use log loss and accuracy to measure the performance for in-distribution data": "and Fig. E.2 in Appendix compare main methods in terms of log loss. First, we observe that repulsiveensembles and the Dirichlet method have much worse log loss than all other methods and they tend to giveunderconfident predictions. Second, we observe that using auxiliary training slightly increases the log lossbut the increase is negligible. Later we can see that auxiliary training improves the uncertainty quantificationfor out-of-distribution data. We observe that VIFO is competitive with all methods in terms of log loss,with relatively small differences between the top group of methods in each case. Fig. E.1 and Fig. E.3 showaccuracy on test data in the same experiments, revealing that in many cases VIFO outperforms VI andit is competitive with all methods. Finally, there is no clear winner between VIFO-mean and VIFO-mv;VIFO-mv provides a small advantage overall but might be more sensitive as illustrated by the performanceon CIFAR100 with PreResNet20.",
  "Uncertainty Quantification": "In this section we examine whether VIFO can capture the uncertainty in predictions for shifted and OODdata. We measure performance using ECE, Entropy and AUC for detecting OOD data. These represent acomprehensive set of measures from the literature. For datasets, for uncertainty under data shift, STL10and CIFAR10 can be treated as a shifted dataset for each other, as the figure size of STL10 is different fromCIFAR10, and STL10 shares some classes with CIFAR10 so the labels are meaningful. For uncertainty underOOD data, we choose the SVHN dataset as an OOD dataset for CIFAR10 and STL10, as SVHN containsimages of digits and the labels of SVHN are not meaningful in the context of CIFAR10. Expected Calibration Error (ECE)ECE (Naeini et al., 2015; Ovadia et al., 2019) is often used tomeasure the uncertainty quantification under data shift. We separate data into bins of the same size accordingto the confidence level, calculate the difference between the accuracy and the averaged confidence in each binand then average the absolute differences among all bins. Better calibrated models have lower ECE. ECEhas its faults (for example the trivial classifier has zero ECE) but it is nonetheless informative. We selectedthe number of bins to be 20.",
  "shows the ECE of each method under data shift. As we can see, both VIFO-mean and VIFO-mvachieve the best performance compared to all other methods": "EntropyEntropy (Ovadia et al., 2019) of the categorical predictive distribution is used to measure theuncertainty quantification for out-of-distribution (OOD) data as the labels for OOD data are meaningless.We want our model to be as uncertain as possible and this implies high entropy and low confidence (themaximum probability assigned to any class) in the predictive distribution.We summarize the averagedentropy for the entire dataset in and Fig. E.4. We can see that both VIFO-mean and VIFO-mv arebetter than all other methods except repulsive ensembles and the Dirichlet method. However, as observed",
  ": ECE () on AlexNet and PreResNet20 under data shift. Dashed line indicates the best performanceof VIFO. Numerical results are listed in the Appendix": "in and Fig. E.2, repulsive ensembles and the Dirichlet method have poor performance in terms oflog loss due to underconfident predictions. Hence they achieve high entropy by sacrificing in distributionperformance whereas VIFO performs well. Further, we observe from that auxiliary training greatlyimprove the performance of VIFO on PreResNet20. Auxiliary training only has a small impact on VIFOwith AlexNet (see Fig. E.4) but VIFO already performs well without auxiliary training in this case. AUROCWe use maximum probability of the categorical predictive distribution as the criterion to separatein-distribution and OOD data and compute the area under the ROC curve (Malinin & Gales, 2018). AUROCovercomes the drawbacks of ECE and entropy because a trivial model cannot yield the best performance.Detailed comparison plots are in given in Fig. E.5 and Fig. E.6 in the Appendix. We first note that, as above,auxiliary training improves the performance on PreResNet20 but not significantly on AlexNet. We found thatthere is no single method that consistently outperforms all other methods. Instead, for better visualization,we show the comparison of VIFO-mean and VIFO-mv with other methods in . For each baseline, wecount the number of experiments that VIFO performs better and get the corresponding proportion. Weobserve that overall, VIFO-mv is better than all other methods except the Dirichlet method and that itranks better than VIFO-mean. Though the Dirichlet method performs better than VIFO on OOD data, itspoor in-distribution performance makes it less desirable. On the other hand, VIFO outperforms all otherbaselines for OOD and has strong in distribution performance and hence give better overall predictions.",
  "Conclusion": "In Bayesian neural networks, the distribution of the last layer directly affects the predictive distribution.Motivated by this fact, we proposed variational inference on the final-layer output, VIFO, that uses a neuralnetwork to directly learn the mean and variance of the last layer. We showed that VIFO can match theexpressive power of VI in linear cases with a strong prior but that in general it provides a less expressive model.",
  ": Entropy () on PreResNet20": ": Comparison of VIFO with all other methods in terms of AUROC on OOD data. Y-axis is theproportion of experiments that VIFO is better than other methods. Exact AUROC values are provided inthe appendix. On the other hand the simplicity of the model enables fast training of ensembles of VIFO and facilitatesconvergence analysis through Rademacher bounds. In addition, VIFO can be derived as a non-standardvariational lower bound, which provides an approximation for the last layer. This connection allowed usto derive better regularizations for VIFO by using collapsed variational inference over a hierarchical prior.Since VIFO treats each input separately, we can incorporate auxiliary inputs to help the model distinguishin-distribution and out-of-distribution data. Empirical evaluation highlighted that ensembles of VIFO arecompetitive with or outperform other methods in terms of in-distribution loss and out-of-distribution data",
  "Alexander A. Alemi, Ian Fischer, Joshua V. Dillon, and Kevin Murphy.Deep variational informationbottleneck. In 5th International Conference on Learning Representations, ICLR 2017, 2017": "Viktor Bengs, Eyke Hllermeier, and Willem Waegeman. Pitfalls of epistemic uncertainty quantificationthrough loss minimisation. In Alice H. Oh, Alekh Agarwal, Danielle Belgrave, and Kyunghyun Cho (eds.),Advances in Neural Information Processing Systems, 2022. URL Charles Blundell, Julien Cornebise, Koray Kavukcuoglu, and Daan Wierstra. Weight uncertainty in neuralnetwork. In Francis Bach and David Blei (eds.), Proceedings of the 32nd International Conference onMachine Learning, volume 37 of Proceedings of Machine Learning Research, pp. 16131622, Lille, France,0709 Jul 2015. PMLR. URL",
  "Nicolas Brosse, Carlos Riquelme, Alice Martin, Sylvain Gelly, and ric Moulines. On last-layer algorithmsfor classification: Decoupling representation from uncertainty estimation, 2020. URL": "Bertrand Charpentier, Daniel Zgner, and Stephan Gnnemann. Posterior network: Uncertainty estimationwithout ood samples via density-based pseudo-counts. In H. Larochelle, M. Ranzato, R. Hadsell, M.F.Balcan, and H. Lin (eds.), Advances in Neural Information Processing Systems, volume 33, pp. 13561367. Curran Associates, Inc., 2020.URL Francesco DAngelo and Vincent Fortuin.Repulsive deep ensembles are bayesian.In A. Beygelzimer,Y. Dauphin, P. Liang, and J. Wortman Vaughan (eds.), Advances in Neural Information Processing Sys-tems, 2021. URL Erik Daxberger, Agustinus Kristiadi, Alexander Immer, Runa Eschenhagen, Matthias Bauer, and PhilippHennig. Laplace redux - effortless bayesian deep learning. In Advances in Neural Information ProcessingSystems 34: NeurIPS, 2021. Yarin Gal and Zoubin Ghahramani. Dropout as a bayesian approximation: Representing model uncertaintyin deep learning. In Proceedings of the 33rd International Conference on International Conference onMachine Learning - Volume 48, ICML16, pp. 10501059. JMLR.org, 2016. Pascal Germain,Francis Bach,Alexandre Lacoste,and Simon Lacoste-Julien.Pac-bayesian the-orymeetsbayesianinference.InD.Lee,M.Sugiyama,U.Luxburg,I.Guyon,andR. Garnett (eds.), Advances in Neural Information Processing Systems, volume 29. Curran As-sociates,Inc.,2016.URL Noah Golowich, Alexander Rakhlin, and Ohad Shamir. Size-independent sample complexity of neural net-works. In Sbastien Bubeck, Vianney Perchet, and Philippe Rigollet (eds.), Proceedings of the 31st Confer-ence On Learning Theory, volume 75 of Proceedings of Machine Learning Research, pp. 297299. PMLR,0609 Jul 2018. URL Alex Graves. Practical variational inference for neural networks. In J. Shawe-Taylor, R. Zemel, P. Bartlett,F. Pereira, and K.Q. Weinberger (eds.), Advances in Neural Information Processing Systems, vol-ume 24. Curran Associates, Inc., 2011.URL Chuan Guo, Geoff Pleiss, Yu Sun, and Kilian Q. Weinberger. On calibration of modern neural networks.In Proceedings of the 34th International Conference on Machine Learning - Volume 70, ICML17, pp.13211330. JMLR.org, 2017.",
  "Shai Shalev-Shwartz and Shai Ben-David. Understanding Machine Learning - From Theory to Algorithms.Cambridge University Press, 2014": "Mrinank Sharma, Sebastian Farquhar, Eric Nalisnick, and Tom Rainforth. Do bayesian neural networks needto be fully stochastic? In Francisco Ruiz, Jennifer Dy, and Jan-Willem van de Meent (eds.), Proceedings ofThe 26th International Conference on Artificial Intelligence and Statistics, volume 206 of Proceedings ofMachine Learning Research, pp. 76947722. PMLR, 2527 Apr 2023. URL Rishit Sheth and Roni Khardon.Excess risk bounds for the bayes risk using variational inference inlatent gaussian models.In I. Guyon, U. Von Luxburg, S. Bengio, H. Wallach, R. Fergus, S. Vish-wanathan, and R. Garnett (eds.), Advances in Neural Information Processing Systems, volume 30. Cur-ran Associates, Inc., 2017. URL",
  "Ba-Hien Tran, Simone Rossi, Dimitrios Milios, and Maurizio Filippone. All You Need is a Good FunctionalPrior for Bayesian Deep Learning. Journal of Machine Learning Research, 23:156, 2022": "Joost van Amersfoort, Lewis Smith, Yee Whye Teh, and Yarin Gal. Uncertainty estimation using a single deepdeterministic neural network. In Proceedings of the 37th International Conference on Machine Learning,ICML 2020, volume 119 of Proceedings of Machine Learning Research, pp. 96909700, 2020. Yadi Wei and Roni Khardon. On the performance of direct loss minimization for bayesian neural networks. InI Cant Believe Its Not Better Workshop: Understanding Deep Learning Through Empirical Falsification,2022. URL Yadi Wei, Rishit Sheth, and Roni Khardon. Direct loss minimization for sparse gaussian processes. InArindam Banerjee and Kenji Fukumizu (eds.), Proceedings of The 24th International Conference on Arti-ficial Intelligence and Statistics, volume 130 of Proceedings of Machine Learning Research, pp. 25662574.PMLR, 1315 Apr 2021. URL Florian Wenzel, Kevin Roth, Bastiaan S. Veeling, Jakub Switkowski, Linh Tran, Stephan Mandt, JasperSnoek, Tim Salimans, Rodolphe Jenatton, and Sebastian Nowozin. How good is the bayes posterior indeep neural networks really? In Proceedings of the 37th International Conference on Machine Learning,ICML20. JMLR.org, 2020. AndrewGWilsonandPavelIzmailov.Bayesiandeeplearningandaprobabilisticperspec-tive of generalization.In H. Larochelle,M. Ranzato,R. Hadsell,M.F. Balcan,and H. Lin(eds.),Advances in Neural Information Processing Systems,volume 33,pp. 46974708. CurranAssociates,Inc.,2020.URL Andrew Gordon Wilson, Pavel Izmailov, Matthew D Hoffman, Yarin Gal, Yingzhen Li, Melanie F Pradier,Sharad Vikram, Andrew Foong, Sanae Lotfi, and Sebastian Farquhar. Evaluating approximate inferencein bayesian deep learning.In Douwe Kiela, Marco Ciccone, and Barbara Caputo (eds.), Proceedingsof the NeurIPS 2021 Competitions and Demonstrations Track, volume 176 of Proceedings of MachineLearning Research, pp. 113124. PMLR, 0614 Dec 2022. URL Anqi Wu, Sebastian Nowozin, Edward Meeds, Richard E. Turner, Jose Miguel Hernandez-Lobato, andAlexander L. Gaunt.Deterministic variational inference for robust bayesian neural networks.In In-ternational Conference on Learning Representations, 2019. URL",
  "= EN(w,LL)[log p(yi|xi)],(13)": "where the last equality uses reparametrization in a reverse order. By aligning w = m and V = LL = S, werecognize that Eq equation 13 is exactly the loss term in Eq equation 9. Thus the low-dimensional posterioron z yields the same loss term as the high-dimensional posterior over W.",
  "(XNS10 V XN)XNui = XNS10 V ui = XNui,(14)": "thus (i, XNui)di=1 is the eigenvalues and eigenvectors of XN(XNXN)1S10 V XN. Since the rank of thismatrix is at most d, other eigenvalues are 0 and the pseudo determinant is di=1 i, which is exactly thedeterminant of S10 V . Then the regularization term in equation 9 can be simplified to:",
  "x1,(18)": "where and are the pdf and cdf of standard normal distribution and we directly use the expectation ofthe truncated normal distribution. Now consider w and u that aim to recover (17) and (18). If u1,1 0,it cannot successfully recover (18) because the ReLU activation will have 0 when x1 < 0 so that it cannotrecover (18); if u1,1 < 0, for the same reason it cannot recover (17).",
  "Proof of Lemma 4.3. We prove the lemma for L = 1. If this is not the case, we can define = 1": "L, and usethe fact that R((AB)) LR((AB)). Let Ci = {(a1+b1, . . . , ai1+bi1, (ai, bi), ai+1+bi+1, . . . , aN +bN) : a A, b B}. It suffices to prove that for any set A, B and all i we have R(Ci) R(A) + R(B).Without loss of generality we prove the case for i = 1.",
  "COptimizing the Variational Distribution for All Data": "In the previous section we show the derivation of collapsed variational inference where q(p, 2p) is optimizedfor every data point x. In this section we show how to optimize q(p, 2p) for all data and obtain differentregularizers to the ones mentioned in the above section. These perform less well in practice but we includethem here for completeness. The closed-form solution for q(p, 2p) for all data is",
  ", 3": "4] and xtest . We use a multilayer perceptron neural network with 5layers, each layer containing 50 hidden units to fit the data. For VI, we pick the prior standard deviationto be 1.0 and for VIFO-mean, we select = 0.3, + = 0.05. For both models, we select the regularizationparameter = 0.1 and for VIFO we choose aux = 1.0. For linear regression, we can explicitly compute thepredicted variance if we use exponential function as the link function. Suppose p(y|z) = N(y | m, exp(l))and p(m | x) = N(m | m, 2m), p(l | x) = N(l | l, 2l ), then p(y | x) = N(y | m, 2m + exp(ml + 2l /2)).See Appendix B.3 of Wu et al. (2019) for the derivation. To visualize the predictive distribution inductedby the prior, we draw multiple zs from prior, then draw multiple ys from likelihood p(y|z) and plot themin .",
  "Learning rate:For all methods other than SGD, SWA and SWAG, we use the Adam optimizer withlearning rate 0.001": "VI and VIFO:We first list the choices of the variance for naive variational methods. The choice of priorvariance significantly affects the performance. For image datasets with complex neural networks, the totalprior variance of VI grows with the number of parameters so we have to pick a small variance and we use0.05 following the setting of Wilson et al. (2022). Since VIFO samples in the output space which is small,using 0.05 regularizes too strongly and we therefore set a larger value of 1 for the variance.",
  "+ = 0.05 for learn-mean regularizer (VI-mean,VIFO-mean, VIFO-mean-all) and = 0.5, = 0.01, =t": "1+t = 0.1 for learn-mean-variance regularizer (VI-mv, VIFO-mv, VIFO-mv_all), which exactly follows Tomczak et al. (2021). We pick = 4.4798 and = 10for empirical Bayes (VI-eb, VIFO-eb, VIFO-eb_all). The choice of in empirical Bayes follows Wu et al.(2019) but the choice of is unclear in Wu et al. (2019) so we just perform a simple search from {1, 10, 100}and set = 10 that yields the best result.",
  "For both VI and VIFO, the regularization parameter is fixed at 0.1": "Hybrid Methods:The hybrid methods (SGD, SWA and SWAG) are not very stable so we have to tunelearning rates carefully for each dataset. We choose the momentum to be 0.9 for all cases and list all otherinformation in Table D.1. Notice that it is hard to train the hybrid methods on SVHN using AlexNet, so weinitialize with a pre-trained model that is trained with a larger learning rate 0.1 to find a region with lowertraining loss, and then continue to optimize with the parameters listed in Table D.1.",
  "Dropout:For Dropout we add a Dropout layer following each activation layer in the base model and setthe Dropout probability p = 0.1": "Repulsive Ensembles:Repulsive ensembles run multiple copies of the base model with a kernel basepenalty to make sure the models are diverse. We use RBF kernel with lengthscale being the median of thesquare of the norm. Dirichlet:Dirichlet-based models are deterministic and they interpret the output of the last layer asthe parameters of dirichlet distributions, i.e., (x) = g(fW (x)), where g maps the output to positive realnumbers. Hence we run the Dirichlet models with the setting of the base model. We next explain the settingof hyperparameters. As discussed by Bengs et al. (2022), the models of Sensoy et al. (2018); Charpentieret al. (2020) implicitly perform variational inference:",
  "log p(y|x) Eq(p|x)[log p(y|p)] KL(q(p|x)||Dir(p|0)),(32)": "where q(p|x) = Dir(p|(x)). In the experiments, following Sensoy et al. (2018); Bengs et al. (2022), weuse a uniform prior with 0 = [1, . . . , 1]. As in VI and VIFO, we pick the regularization parameter for KLdivergence to be 0.1. Last layer Laplace:We first train a neural network to obtain a MAP solution with a prior variance of0.05. Then, we use the code from Daxberger et al. (2021) to optimize the prior precision hyperparameterthrough post-hoc marginal likelihood maximization. VBLL:We adapt the code from Harrison et al. (2024) and utilize the default hyperparameters. We choosethe discriminative classification setting, as it yields the best OOD performance according to Harrison et al.(2024)."
}