{
  "Abstract": "Diffusion models have attained state-of-the-art performance in generating realistic objects,including when conditioning generation on class labels. Current class-conditional diffusionmodels, however, implicitly model the diffusion process on all classes in a flat fashion,ignoring any known relationships between classes. Class-labeled datasets, including thosecommon in scientific domains, are rife with internal structure. To take advantage of thisstructure, we propose hierarchically branched diffusion models as a novel framework forclass-conditional generation. Branched diffusion models explicitly leverage the inherentrelationships between distinct classes in the dataset to learn the underlying diffusion processin a hierarchical manner. We highlight several advantages of branched diffusion models overthe current state-of-the-art methods for class-conditional diffusion. Firstly, they can be easilyextended to novel classes in a continual-learning setting at scale. Secondly, they enable moresophisticated forms of conditional generation, such as analogy-based conditional generation(i.e. transmutation). Finally, they offer a novel interpretability into the class-conditionalgeneration process. We extensively evaluate branched diffusion models on several benchmarkand large real-world scientific datasets, spanning different data modalities (images, tabulardata, and graphs). We particularly highlight the advantages of branched diffusion models ona single-cell RNA-seq dataset, where our branched model leverages the intrinsic hierarchicalstructure between human cell types.",
  "Introduction": "Diffusion models have gained major popularity as a method for generating data from complex data distributions(Sohl-Dickstein et al., 2015; Ho et al., 2020; Song et al., 2021). Furthermore, they have also been successful inperforming conditional generation, where we wish to sample some object x conditioned on a label y. Recentworks in conditional diffusion have arguably received the most popular attention (Song et al., 2021; Dhariwal& Nichol, 2021; Rombach et al., 2022; Ho et al., 2022), and have rapidly become a staple in generative AI. Current diffusion models, however, are limited in their treatment of class-labeled datasets. Conventionaldiffusion models learn the diffusion process flatly for each class, disregarding any known relationships orstructure between them. In reality, class-labeled datasets in many domains, such as those characterizingscientific applications, have an inherent structure between classes which can be thought of as hierarchical.For example, human cell types are organized hierarchically by nature: keratinocytes are very distinct fromneurons, but the latter subdivide into excitatory and inhibitory neurons. Additionally, even when a datasethas no pre-defined hierarchical label set (e.g. an explicit ontology), hierarchical structure can often be found,because some subsets of classes are invariably more similar than others.",
  "Published in Transactions on Machine Learning Research (08/2024)": "For our single-cell RNA-seq dataset, we repeated the same procedure, but started with a branched diffusionmodel trained on CD16+ NK cells and classical monocytes, and introduced memory B cells as a new task.We trained the new branch on only memory B cells, only for the time interval of the new branch. On thecorresponding label-guided (linear) model, we fine-tuned on only memory B cells or on all three cell types. Tofine-tune on only memory B cells, we started with the linear model trained on CD16+ NK cells and classicalmonocytes only. To fine-tune on all three cell types, we again started with the linear model trained only onthe original two cell types.",
  "dx =f(x, t) g(t)2s(x, t)dt + g(t)d,(2)": "where is a standard Wiener process in the reverse direction. s(x, t) = x log(pt(x)) is the Stein score of xat diffusion time t. A neural network is trained to predict s(x, t) s(x, t), made possible by defining f(x, t)and g(t) such that the true Stein score is tractably defined in closed form (such as with the variance-preservingSDE). In order to perform class-conditional generation, the diffusion model needs to learn the conditional distributionof data for each class of the dataset. The current state-of-the-art method for class-conditional diffusion wasproposed in Ho et al. (2021), termed classifier-free conditional generation. In this method, the reverse-diffusion neural network is given the class label c as an auxiliary input, which guides the generation of objectsto specific classes:",
  "Hierarchically branched diffusion models": "Suppose our dataset consists of a set of classes C. For example, let us consider MNIST handwritten digits,where C = {0, 1, ..., 9}. We wish to leverage the fact that some classes are inherently more similar thanothers (e.g. the 4s and 9s in MNIST are visually more similar to each other than they are to 0s). As noiseis progressively added to data, there is some point in diffusion time at which any two samples from twodifferent classes are so noisy that their original class effectively cannot be determined; we call this pointin time a branch point. A branch point is a property of two classes (and the forward diffusion process),andimportantlythe more similar the two classes are, the earlier the branch point will be. These branch points underpin the main distinction between a branched diffusion model and a traditionallinear one. We define the branch point between two classes as the earliest diffusion time point when objectsof the two classes are sufficiently similar in distribution, such that reverse diffusion after this point could bepredicted by the same neural-network model (without specifying class identity). More formally, we defined acriterion for measuring when the distribution of two noisy classes is sufficiently similar (Equation 8), based offof the well-established metric of energy distance. Mathematical justification and more details can be foundin Appendix A. Note that branch-point discovery is performed once for the dataset at the beginning, andthis proposed procedures runtime is orders-of-magnitude smaller than the time taken to train the model.Alternatively, since branch points reflect the inherent similarity between classes of the dataset, they may alsobe entirely defined by domain knowledge (e.g. an ontology describing known similarities between cell types,or chemical classes of drug-like molecules). Together, the branch points between all classes in C naturally encode a hierarchy of class similarities(a). This hierarchy separates diffusion time from a single linear track into a branched structure,where each branch represents the diffusion of a subset of classes, and a subset of diffusion times. For |C|classes, there are 2|C| 1 branches. Each branch bi = (si, ti, Ci) is defined by a particular diffusion timeinterval [si, ti) (where 0 si < ti < T) and a subset of classes Ci C (where Ci = ). The branches areconstrained such that every class and time (c, t) C [0, T) can be assigned to exactly one branch bi suchthat c Ci and t [si, ti). The branches form a rooted tree starting from t = T to t = 0. Late branches(large t) are shared across many different classes, as these classes diffuse nearly identically at later times.Early branches (small t) are unique to smaller subsets of classes. The earliest branches are responsible forgenerating only a single class. Additionally, as opposed to a conventional (linear, or non-hierarchical) diffusion model which learnsto reverse diffuse all classes and times using a single-task neural network, a branched diffusion model isimplemented as a multi-task neural network. Specifically, each output task predicts reverse diffusion for asingle branch (e.g. in an SDE-based diffusion framework (Song et al., 2021), each prediction head learns theStein score for a specific branch) (b). The multi-task architecture allows the model to learn thereverse-diffusion process distinctly for each branch, while the shared parameters allow the network to learnshared representations across tasks without an explosion in model complexity:",
  "dx =f(x, t) g(t)2s(x, t)[bc,t]dt + g(t)d,(4)": "where bc,t is the branch index corresponding to the class c of object x, and t is the diffusion time. Notethat the forward- and reverse-diffusion processes are identical to traditional diffusion models (Equations 12).However, in contrast to traditional linear models where the neural network s(x, t, c) takes in the class as aninput to learn class-conditional distributions (Equation 3), the neural network for a branched model explicitly",
  "learns the conditional distribution of each branch as a separate output task (each branch has an associatedoutput task with index bc,t)": "Training a branched diffusion model follows nearly the same procedure as with a standard linear model,except for each input, we only perform gradient descent on the associated branch, which corresponds to amodel output task) (see Algorithm 1). To sample an object of class c, we perform reverse diffusion startingfrom time T and follow the appropriate branch down (see Algorithm 2). To better understand branched diffusion models and how they are different from traditional linear models,consider the following progression of methods (c): 1) A traditional class-conditional diffusion model,where all classes are treated in a flat fashion. A single neural network learns reverse diffusion for all classesand diffusion times; both the time and class label are inputs to the model (Equation 3). 2) Instead of asingle neural network, train a separate network for each data class (the diffusion process is still the same foreach class). In contrast with method 1), we reverse diffuse a particular class by choosing the appropriatenetwork. This would allow for benefits like class extension in continual learning (), but at the costof inefficient parameterization and training time. Furthermore, fully separating diffusion timelines for eachclass into distinct neural networks ignores inherent class similarities, and as a result, this approach does not",
  "end forReturn x": "allow for benefits like transmutation () or interpretability of diffusion intermediates ().3) Owing to the inherent structure of the dataset, we can leverage the fact that noisy objects of differentclasses are indistinguishable after a certain diffusion time (i.e. branch points). Thus, we maximize sharingof diffusion time between classes via a hierarchy, and we train a multi-task neural network where each taskpredicts reverse diffusion for a single branch (Equation 4). We now generate a particular class by choosingthe appropriate set of branches (output tasks). This allows us to retain benefits like class extension, and gainbenefits like transmutation and interpretability, with a much more efficient parameterization and reducedtraining time compared to method 2). Importantly, the underlying diffusion process and subsequent mathematical properties in a branched diffusionmodel are directly inherited from and identical to that of a conventional linear model. A branched model ischaracterized by the explicit definition of branch points which separate the responsibility of reverse diffusingdifferent subsets of classes and times into separate branches, where each branch is predicted by a differenthead of a multi-task neural network.",
  "Class-conditional diffusion via branched diffusion models": "Branched diffusion models are a completely novel way to perform class-conditional diffusion. Instead of relyingon external classifiers or labels as auxiliary neural-network inputs, a branched diffusion model generates dataof a specific class simply by reverse diffusing down the appropriate branches. We demonstrate branched diffusion models on several datasets of different data modalities: 1) MNISThandwritten-digit images (LeCun et al.); 2) a tabular dataset of several features for the 26 English letters invarious fonts (Frey & Slate, 1991); 3) a real-world, large scientific dataset of single-cell RNA-seq, measuringthe gene expression levels of many blood cell types in COVID-19 patients, influenza patients, and healthydonors (Lee et al., 2020); and 4) ZINC250K, a large dataset of 250K real drug-like molecules (Irwin et al.,2012). We trained continuous-time (i.e. SDE-based (Song et al., 2021)) branched diffusion models for alldatasets. The branching structure was inferred by our branch-point discovery algorithm (SupplementaryTables S1S8, Appendix A). We verified that our MNIST model generated high-quality digits (SupplementaryFigure S1). For our tabular-letter dataset, we followed the procedure in Kotelnikov et al. (2022) to verify thatthe branched model generated realistic letters that are true to the training data (Supplementary Figure S2). We compared the generative performance of our branched diffusion models to the current state-of-the-artmethods for conditional generation via diffusion, which are label-guided (linear) diffusion models (Ho et al.,",
  "Extending branched diffusion models to novel classes": "The problem of incorporating new data into an existing model is a major challenge in the area of continuallearning, as the emergence of new classes (which were not available during training) typically requires thewhole model to be retrained (van de Ven & Tolias, 2019). Conventional (linear) diffusion models are noexception, and there is a critical need to improve the extendability of these models in a continual-learningsetting. This requirement is typical of models trained on large-scale, integrated scientific datasets, which growsteadily as data of new, never-before-seen classes is experimentally produced (Han et al., 2020; Almanzaret al., 2020; Lotfollahi et al., 2021). For example, large single-cell reference atlases comprising hundreds ofmillions of cells across organs, developmental stages, and conditionssuch as the Human Cell Atlas (Regevet al., 2017)are continuously updated as new research is published. By separating the diffusion of different classes into distinct branches which are learned by a multi-task neuralnetwork, a branched diffusion model easily accommodates the addition of new training data (e.g. from arecent experiment). Suppose a branched model has been trained on classes C, and now a never-before-seenclass c has been introduced. Instead of retraining the model from scratch on C {c} for the entire diffusiontimeline, a branched model can be easily extended by introducing a new branch while keeping the otherbranches the same (assuming c is sufficiently similar to some existing class). For example, leveraging theintrinsic structure of cell types (Han et al., 2020), a branched diffusion model can be fine-tuned on a newstudypotentially including new cell typeswithout retraining the entire model. Formally, we extend anexisting branched diffusion model by adding a new terminal branch (si, ti, Ci) = (0, tb, {c}), where tb isdetermined by the algorithm in Appendix A. The new neural network has parameters = (s, 0, ..., bmax),with shared parameters s and output-task-specific parameters i (one for each branch). Let b be the branchindex of the new terminal branch. Then we simply need to learn b, training only on c for times t [0, tb]:",
  "Ex:class(x)=c,t<tbL(x, t, s(x, t)[b])(5)": "To illustrate this extendability, we trained branched diffusion models on MNIST and on our large real-worldRNA-seq dataset. For the MNIST experiment, we trained on three classes: 0s, 4s, and 9s. We then introduceda new class: 7s. To accommodate this new class, we added a single new branch to the diffusion model (a). We then fine-tuned only the newly added branch, freezing all shared parameters and parameters for otheroutput tasks. That is, we only trained on 7s, and only on times t [si, ti) for the newly added branch bi.After fine-tuning, our branched model was capable of generating high-quality 7s without affecting the abilityto generate other digits (b). In contrast, label-guided (linear) diffusion models cannot easily accommodate a new class. In our MNISTexperiment, we trained a linear model on 0s, 4s, and 9s. After fine-tuning the linear model on 7s, the model",
  "Analogy-based conditional generation between classes": "In a diffusion model, we can traverse the diffusion process both forward and in reverse. In a branched diffusionmodel, this allows for a unique ability to perform analogy-based conditional generation (or transmutation)between classes. That is, we start with an object of one class, and generate the analogous, correspondingobject of a different class. Formally, consider the set of all branches {(si, ti, Ci)}. Say we have an object x1of class c1. We wish to transmute this object into the analogous object of class c2. Let tb be the first branchpoint (earliest in diffusion time) in which c1 and c2 are both in the same branch. Then, in order to performtransmutation, we first forward diffuse x1 to xb qtb(x|x1). Then we draw an object from the conditionaldistribution p0(x|c2, xb), where conditioning is both on class c2 and the noisy object xb (partially diffusedfrom x1). In summary:",
  "In practice, sampling x2 from p0(x|c2, xb) is performed by reverse diffusing to generate an object of classc2 (Algorithm 2), as if we started at time tb with object xb qtb(x|x1)": "Conditional generation via transmutation is a unique and novel way to harness branched diffusion models formore sophisticated generation tasks which go beyond what is possible with current diffusion models, whichtypically condition on a single class or property (Song et al., 2021; Ho et al., 2021). In transmutation, weenable generation conditioned on both a class and a specific instance (which may be of another class). That is,conventional conditional generation samples from q0(x|c2), but transmutation samples from q0(x|c2, x1 c1).This feature can support discovery in scientific settings. For example, given a model trained on many celltypes C, with each cell type measured in certain conditions h1, ..., hm, transmutation can answer the followingquestion: what would be the expression of a specific cell xi of cell type ci and condition hk, if the cell typewere cj instead?. A branched model is thus distinct from models which simply generate cells with cell typecj and/or condition hk. For instance, to study how a novel cell type (such as a B-cell) reacts to a drug whoseeffects are known for another cell type (such as a T-cell), one can conditionally generate a population ofB-cells starting from a population of T-cells under the particular drug effect. On our MNIST branched diffusion model, we transmuted between 4s and 9s (a). Intriguingly, themodel learned to transmute based on the slantedness of a digit. That is, slanted 4s tended to transmute toslanted 9s, and vice versa. To quantify analogous conditional generation between classes, we then transmutedbetween letters on our tabular branched diffusion model (b). Transmuting between V and Y (andvice versa), we found that for every feature, there was a positive correlation of the feature values beforeversus after transmutation. That is to say, letters with a larger feature value tended to transmute to lettersalso with a larger feature value, even if the range of the feature is different between the two classes. We then turned to our branched model trained on the large real-world RNA-seq dataset, and transmuteda sample of CD16+ NK cells to classical monocytes, and vice versa. In both directions, transmutationsuccessfully increased critical marker genes of the target cell type, and zeroed the marker genes of thesource cell type (e.g. when transmuting NK cells to monocytes, the expression of NK marker genes such asMS4A6A were zeroed, and the expression of monocyte marker genes such as SPON2 were elevated) (c). Additionally, we found a high correlation of expression in many genes before and after transmutation,including CXCL10 (r = 0.20), HLA-DRA (r = 0.16), and HLA-DRB1 (r = 0.15). These genes are especiallyrelevant, as they were explicitly featured in Lee et al. (2020) as key inflammation genes that distinguish",
  "pretability. By explicitly encoding branch points, a branched diffusion model offers unique insight into therelationship between classes and individual objects from a generative perspective": "In the forward-diffusion process of a branched diffusion model, two branches meet at a branch point when theclasses become sufficiently noisy such that they cannot be distinguished from each other. Symmetrically, inthe reverse-diffusion process, branch points are where distinct classes split off and begin reverse diffusing alongdifferent trajectories. Thus, for two similar classes (or two sets of classes), the reverse-diffusion intermediateat a branch point naturally encodes features which are shared (or otherwise intermediate or interpolated)between the two classes (or sets of classes). In particular, hybrid intermediates represent partially reverse-diffused objects right before a branch splitsinto two distinct classes. Formally, consider the set of all branches {(si, ti, Ci)}. For two classes c1 and c2,let tb be the first branch point (earliest in diffusion time) in which c1 and c2 are both in the same branch.We define a hybrid object xh between classes c1 and c2 as an object sampled from the partially diffuseddistribution at tb from the conditional distribution of c1 or c2:",
  "xh ptb(x|c1) = ptb(x|c2).(7)": "In practice, sampling xh from ptb(x, c1) or ptb(x, c2) is done by performing reverse diffusion followingAlgorithm 2 from time T until time tb for either c1 or c2 (it does not matter which, since we stop at tb). For example, on our MNIST branched diffusion model, hybrids tend to show shared characteristics thatunderpin both digit distributions (ab). On our branched model trained on tabular letters, we seethat hybrids tend to interpolate between distinct feature distributions underpinning the two classes, acting asa smooth transition state between the two endpoints (c). : Interpretable hybrids at branch points. a) From our branched model trained on MNIST, we show examplesof hybrids between the digits classes 4 and 9 (left), and between the digit classes 1 and 7 (right). Each hybrid in themiddle row is the reverse-diffusion starting point for both images above and below it. We applied a small amount ofGaussian smoothing to the hybrids for ease of viewing. b) Averaging over many samples, the aggregate hybrids atbranch points show the collective characteristics that are shared between MNIST classes. c) From our branched modeltrained on tabular letters, we show the distribution of some features between two pairs of classesO and X (left), andE and F (right)and the distribution of that feature in the generated hybrids from the corresponding branch point. Note that although a branched diffusion model can successfully generate distinct classes even with veryconservative branch points (i.e. late in diffusion time), the interpretability of the hybrid intermediates is bestwhen the branch points are minimal (earliest in diffusion) times of indistinguishability. Taken to the extreme,branch points close to t = T encode no shared information between classes whatsoever, as the distribution ofobjects at time T is independent of class.",
  "Efficient multi-class sampling from branched diffusion models": "In addition to advantages in continual learning, transmutation, and interpretability, branched models alsooffer a minor benefit in generative efficiency, because partially reverse-diffused intermediates at branch pointscan be cached and reused. Note that branched models and standard linear models take the same amountof computation to generate a single class, but branched models enjoy significant savings in computationalefficiency when sampling multiple classes (Supplementary Table S9).",
  "In this section, we explore some of the trade-offs and caveats of branched diffusion models": "Firstly, the multi-task neural network behind a branched diffusion model is crucial to its efficient parameteri-zation. As previously discussed, the number of branches scales linearly with the number of classes, so themulti-task architecture is relatively efficient even for datasets with a large number of classes. Still, we recognizethat an extremely large number of classes could become a bottleneck. In those cases, the branched diffusionarchitecture could benefit from recent advancements in efficient multi-task parameterizations (Vandenhendeet al., 2022). Additionally, the advantages and performance of branched diffusion models rely on appropriately definedbranch points. We performed a robustness analysis and found that although the underlying branch pointsare important, the performance of branched diffusion models is robust to moderate variations in these branchpoints (Figure S5). Our branch-point discovery algorithm (Appendix A) is also agnostic to the diffusionprocess, and although it relies on Euclidean distance between noisy objects (which may be hard to computefor data types like graphs), the algorithm (and subsequent diffusion) can always be applied in latent space toguarantee well-defined Euclidean distances. Finally, branched diffusion models may have difficulties learning on certain image datasets where the class-defining subject of the image can be in different parts of the image, particularly when data may be sparse.For datasets like MNIST, the digits are all roughly in the center of the image, thus obviating this problem.Of course, images and image-like data are the only modalities that suffer from this issue. Additionally, thislimitation on images may be avoided by diffusing in latent space.",
  "Conclusion": "In this work, we proposed a novel form of diffusion models which introduces branch points which explicitlyencode the hierarchical relationship between distinct data classes. Branched diffusion models are an alternativemethod of conditional generation for discrete classes. Compared to the current state-of-the-art conditionaldiffusion models, we showed numerous advantages of branched models in conditional generation. We showcasedthese advantages across many different datasets, including several standard benchmark datasets and twolarge real-world scientific datasets. Firstly, we showed that branched models are easily extendable to new, never-before-seen classes throughan efficient fine-tuning step which does not lead to catastrophic forgetting of pre-existing classes. This canenhance diffusion-model training in online-learning settings and in scientific applications where new data isconstantly being produced experimentally. Additionally, branched models are capable of more sophisticatedforms of conditional generation, such as the transmutation of objects from one class into the analogous objectof another class. Using transmutation, we demonstrated the ability of branched diffusion models to discoverrelevant biology and chemistry. Furthermore, we showed that branched models can offer some insights intointerpretability. Namely, reverse-diffusion intermediates at branch points are hybrids which encode shared orinterpolated characteristics of multiple data classes. Finally, because branched diffusion models operate on the same underlying diffusion process as a conventionallinear model, they are flexibly applied to virtually any diffusion-model paradigm (e.g. continuous or discretetime, SDE based or Markov-chain based, different noise schedules and definitions of the noising process, etc.).Branched models are also easily combined with existing methods which aim to improve training/sampling",
  "Yann LeCun, Corinna Cortes, and Chris Burges. Mnist handwritten digit database. URL": "Jeong Seok Lee, Seongwan Park, Hye Won Jeong, Jin Young Ahn, Seong Jin Choi, Hoyoung Lee, BaekgyuChoi, Su Kyung Nam, Moa Sa, Ji Soo Kwon, Su Jin Jeong, Heung Kyu Lee, Sung Ho Park, Su Hyung Park,Jun Yong Choi, Sung Han Kim, Inkyung Jung, and Eui Cheol Shin. Immunophenotyping of covid-19 andinfluenza highlights the role of type i interferons in development of severe covid-19. Science Immunology, 5:1554, 7 2020. ISSN 24709468. doi: 10.1126/SCIIMMUNOL.ABD1554/SUPPL_FILE/TABLE_S9.XLSX.URL Mohammad Lotfollahi, Mohsen Naghipourfar, Malte D. Luecken, Matin Khajavi, Maren Bttner, MarcoWagenstetter, iga Avsec, Adam Gayoso, Nir Yosef, Marta Interlandi, Sergei Rybakov, Alexander V.Misharin, and Fabian J. Theis. Mapping single-cell data to reference atlases by transfer learning. NatureBiotechnology 2021 40:1, 40:121130, 8 2021. ISSN 1546-1696. doi: 10.1038/s41587-021-01001-7. URL",
  "Bo Qiang, Yuxuan Song, Minkai Xu, Jingjing Gong, Bowen Gao, Hao Zhou, Weiying Ma, and YanyanLan. Coarse-to-fine: a hierarchical diffusion model for molecule generation in 3d. 9 2023. URL": "Aaditya Ramdas, Sashank J. Reddi, Barnabas Poczos, Aarti Singh, and Larry Wasserman. On the high-dimensional power of linear-time kernel two-sample testing under mean-difference alternatives. 11 2014.URL Aviv Regev, Sarah A. Teichmann, Eric S. Lander, Ido Amit, Christophe Benoist, Ewan Birney, BerndBodenmiller, Peter Campbell, Piero Carninci, Menna Clatworthy, Hans Clevers, Bart Deplancke, IanDunham, James Eberwine, Roland Eils, Wolfgang Enard, Andrew Farmer, Lars Fugger, Berthold Gttgens,Nir Hacohen, Muzlifah Haniffa, Martin Hemberg, Seung Kim, Paul Klenerman, Arnold Kriegstein, Ed Lein,Sten Linnarsson, Emma Lundberg, Joakim Lundeberg, Partha Majumder, John C. Marioni, MiriamMerad, Musa Mhlanga, Martijn Nawijn, Mihai Netea, Garry Nolan, Dana Peer, Anthony Phillipakis,Chris P. Ponting, Stephen Quake, Wolf Reik, Orit Rozenblatt-Rosen, Joshua Sanes, Rahul Satija, Ton N.Schumacher, Alex Shalek, Ehud Shapiro, Padmanee Sharma, Jay W. Shin, Oliver Stegle, Michael Stratton,Michael J.T. Stubbington, Fabian J. Theis, Matthias Uhlen, Alexander Van Oudenaarden, Allon Wagner,Fiona Watt, Jonathan Weissman, Barbara Wold, Ramnik Xavier, and Nir Yosef. The human cell atlas.eLife, 6, 12 2017. ISSN 2050084X. doi: 10.7554/ELIFE.27041. Robin Rombach, Andreas Blattmann, Dominik Lorenz, Patrick Esser, and Bjorn Ommer. High-resolutionimage synthesis with latent diffusion models. 2022 IEEE/CVF Conference on Computer Vision andPattern Recognition (CVPR), pp. 1067410685, 6 2022. doi: 10.1109/CVPR52688.2022.01042. URL Jascha Sohl-Dickstein, Eric A. Weiss, Niru Maheswaranathan, and Surya Ganguli. Deep unsupervised learningusing nonequilibrium thermodynamics. 32nd International Conference on Machine Learning, ICML 2015,3:22462255, 3 2015. doi: 10.48550/arxiv.1503.03585. URL",
  "ABranch-point discovery": "As objects from two different classes are forward diffused, their distributions become more and more similarto each other. At the extreme, it is expected that all objects (regardless of class) reach the same priordistribution at the time horizon T. Our goal is quantify the earliest time point when objects of two differentclasses are sufficiently similar in distribution, such that the reverse diffusion after that point can be predictedby the same model between the two classes (without specifying class identity). More formally, we define a branch point between two classes c1 and c2 as the diffusion time tb where theobjects sampled from these two classes are relatively indistinguishable from each other. Because the datadistribution is typically complex and high dimensional, we quantify indistinguishability as log-fold change ofexpected Euclidean distances, comparing data drawn between the two different classes, and data within thesame class. That is, the branch point tb between classes c1 and c2 is defined as the minimum time t such that:",
  "We discuss theoretical justifications and connections in Appendix B": "The outer expectations are taken over points in the dataset, and the inner expectations are over the forwardnoising process. When this log-fold change is a small number , then we consider the classes relativelyindistinguishable (i.e. the average distance between noisy objects of different classes is comparable to theaverage distance between noisy objects of the same class). Of course, these expectations are extremely intractable to compute in closed-form because of the large datasetand dimensionality, so instead we approximate these quantities by using Monte Carlo sampling. That is, wetake a sample of objects from each class, apply forward diffusion at many times t spaced regularly between 0and T, and identify the smallest t such that log-fold change of the distance is sufficiently small.",
  "This procedure gives a branch point tb for every pair of classes ci, cj (i = j)": "In a branched diffusion model, each branch bi = (si, ti, Ci) learns to reverse diffuse between times [si, ti) forclasses in Ci. The branches form a tree structure (i.e. hierarchy) with the root at time T and a branchfor each individual class at time 0. In order to convert the branch points between all pairs of classes intoa hierarchy, we simply perform a greedy aggregation starting from individual classes and iteratively mergeclasses together by their branch points (from early to late diffusion time) until all classes have been mergedtogether.",
  ". For each class, sample n objects randomly and without replacement": "3. Forward diffuse each object over 1000 time points in the forward-diffusion process (we used 1000steps, as this matched the number of reverse-diffusion steps we used for sample generation). Thebranched diffusion model which will be trained using these branch definitions employs an identicalforward-diffusion process. 4. At each time point t, compute the average Euclidean distance of each pair of classes, resulting ina |C| |C| matrix at each of the 1000 time points. For distinct classes ci, cj (i = j), the distances(t, ci, cj) is computed over the average of n pairs, where the pairs are randomly assigned betweenthe two classes; for self-distance of class ci, the distance s(t, ci, ci) is computed over the average of npairs within the class, randomly assigned such that the same object is not compared with itself. 5. For each pair of classes ci, cj (i may be equal to j), smooth the trajectory of s(t, ci, cj) over time byapplying a Gaussian smoothing kernel of standard deviation equal to 3 and truncated to 4 standarddeviations on each side.",
  "(s(t,ci,ci)+s(t,cj,cj))) < . This gives eachpair of distinct classes a minimal time of indistinguishability, ci,cj": "7. Order the|C|2minimal times of indistinguishability by ascending order, and greedily build ahierarchical tree by merging classes together if they have not already been merged. This can beimplemented by a set of |C| disjoint sets, where each set contains one class; iterating through thetimes in order, two branches merge into a new branch by merging together the sets containing thetwo classes, unless they are already in the same set.",
  "BTheoretical justification for branch-point-discovery algorithm": "The goal of our branch-point discovery algorithm is to find the branch point between any pair of classes c1and c2. The branch point is the earliest point in diffusion time where c1 and c2 are indistinguishable fromeach other. Formally, indistinguishability occurs when the conditional distributions of these two classes areclose enough that they can be modeled by a single reverse-diffusion process. That is, we want the branchpoint tb to be such that qtb(x|c1) qtb(x|c2).",
  "We chose to use energy distance for several reasons:": "Energy distance (by definition) compares the expected distance between two different distributionsto the expected distance within the distributions. This allows us to attain a measure of relativeindistinguishability. By picking a time point when the energy distance is low, we ensure that themodel upstream of the branch point has no more difficulty representing and learning both classestogether, as it would to learn only a single class (as in a standard, linear diffusion model). Thisaddresses Challenge 4.",
  "CSupplementary Figures and Tables": "Figure S1: Examples of generated MNIST images. We show (uncurated) images of MNIST digits generated bybranched diffusion models. Since branched diffusion models naturally output each class separately, generation ofindividual classes does not require supplying labels or pretrained classifiers. We show a sample of digits generatedfrom a continuous-time (score-matching) diffusion model (Song et al., 2021), and a discrete-time diffusion model(denoising diffusion probabilistic model) (Ho et al., 2020). Branched diffusion models for multi-class generation fitneatly into practically any diffusion-model framework.",
  "Branch start (si)Branch end (ti)Branch classes (Ci)": "0.64361CD16+ NK, Cl. Mono., Late Eryth., Macroph., Megakar.,Mem. B, NK, Plasmabl., Tem/Eff. H. T0.54050.6436CD16+ NK, Cl. Mono., Late Eryth., Macroph., Megakar.,NK, Plasmabl., Tem/Eff. H. T0.50850.5405Cl. Mono., Late Eryth., Macroph., Megakar., NK, Tem/Eff.H. T0.45050.5405CD16+ NK, Plasmabl.0.37240.5085Cl. Mono., Late Eryth., Megakar., NK, Tem/Eff. H. T0.36440.3724Megakar., NK, Tem/Eff. H. T0.22920.3724Cl. Mono., Late Eryth.0.18420.3644Megakar., NK00.6436Mem. B00.5085Macroph.00.4505CD16+ NK00.4505Plasmabl.00.3644Tem/Eff. H. T00.2292Cl. Mono.00.2292Late Eryth.00.1842NK00.1842Megakar.",
  "MNIST78.73 0.1137.30 0.03Letters110.42 0.1467.54 0.04Single-cell RNA-seq275.81 0.02132.37 0.01": "When generating data from multiple classes, intermediates at branch points can be cached in a brancheddiffusion model. For three datasets, we measure the time taken to generate one batch of each class from abranched diffusion model, and from a label-guided (linear) model of identical capacity. Averages and standarderrors are shown over 10 trials each. All values are reported as seconds.",
  "MNIST1011.498.483Fashion MNIST104.818.482Letters2610.0511.061Single-cell RNA-seq94.296.381.2ZINC250K21.151.891": "Because branched diffusion models separate the diffusion process into branches, they naturally often requiremore epochs to train than their linear counterparts. We found, however, that the time taken to train thesemodels was still far less than what would be expected if the training time were an additive function of totalbranch length or model capacity. Here, we show (for each of our main branched models) the total branch",
  "i=1(ti si)), the approximate model capacity,": "and the actual training time in epochs. All values in the table above are relative (i.e. divided by) the branchedmodels linear counterpart. Although training time for branched models was already far less than what isexpected based on branch length or model capacity, we also suggest that training with larger batch sizes oraccumulating gradient updates between batches (particularly for shorter branches) may also allow for thesemodels to be trained even faster. We leave the exploration of this for future work. Figure S6: Robustness of in branch-point discovery algorithm. The value is used in the branch-point discoveryalgorithm (Appendix A) to determine when two classes are sufficiently similar to be combined in a branch. Although is relatively easy to select by simply choosing a value where the branch points are not all too close to t = 0 or t = T,here we explore the robustness of branched diffusion models to different choices of . a) We sampled 10 values of between 105 and 101 (uniformly sampled in logarithmic space), and computed branch points for each in ourMNIST dataset. The two largest values of yielded hierarchies where the terminal branches were all length 0, so theywere removed from this analysis. We show an overlay of the hierarchies. Note the similarity of the hierarchies here(which arise from different values of ) compared to the distribution of hierarchies in Supplementary Figure S5a (whicharise from random variation in sampling and forward diffusion from the same value of ). b) We trained a brancheddiffusion model on each of the hierarchies, and quantified generative performance using Frchet inception distance(FID). Over all hierarchies, the FID from the branched models were mostly consistent with each other, and also mostlybetter than the label-guided (linear) model. The model which performed the worst arose from the largest value of inthe analysis, which resulted in the hierarchy with the shortest terminal branches (gray hierarchy in panel a).",
  "We used the Fashion MNIST dataset as loaded from TorchVision": "Wedownloadedthetabularletter-recognitiondatasetfromtheUCIrepository: (Frey & Slate, 1991).We cen-tered and scaled each of the 16 tabular features to zero mean and unit variance (pooled over the entiredataset, not for each individual letter class). We downloaded the single-cell RNA-seq dataset from GEO (GSE149689) (Lee et al., 2020). We used Scanpyto pre-process the data, using a standard workflow which consisted of filtering out low-cell-count genes andlow-gene-count cells, filtering out cells with too many mitochondrial genes, and retaining only the mostvariable genes and known marker genes (Wolf et al., 2018). We assigned cell-type labels using CellTypist(Conde et al., 2022). Of the annotated cell types, we retained 9 non-redundant cell types for training: CD16+NK cells, classical monocytes, late erythrocytes, macrophages, megakaryocytes/platelets, memory B cells,NK cells, plasmablasts, and TEM/effector helper T cells. After pre-processing, the dataset consisted of 37102cells (i.e. data points) and 280 genes (i.e. features). To train our diffusion models, we projected the geneexpressions down to a latent space of 200 dimensions, using the linearly decoded variational autoencoder inscVI (Gayoso et al., 2022). The autoencoder was trained for 500 epochs, with a learning rate of 0.005. We downloaded the ZINC250K dataset and converted the SMILES strings into molecular graphs using RDKit.We kekulized the graphs and featurized according to (Jo et al., 2022). We explored two methods of labelingthe molecules for branched diffusion. First, we labeled molecules based on whether they were acyclic or hadone cycle (molecules with multiple cycles were removed for simplicity). Secondly, we labeled molecules basedon whether or not they possessed a halogen element (i.e. F, Cl, Br, I).",
  "D.2Diffusion processes": "For all of our continuous-time diffusion models, we employed the variance-preserving stochastic differentialequation (VP-SDE) (Song et al., 2021). We used a variance schedule of (t) = 0.9t + 0.1. We set our timehorizon T = 1 (i.e. t [0, 1)). This amounts to adding Gaussian noise over continuous time. Our ZINC250Kmodels were an exception, and we used the same diffusion processes (different for the node features andadjacency matrix) that were used in (Jo et al., 2022).",
  "To discover branch points, we applied our branch-point discovery algorithm (Appendix A)": "For our continuous-time branched model on MNIST (and Fashion MNIST), we used = 0.005. For ourdiscrete-time branched model on MNIST, we used = 0.001. For our continuous-time branched model ontabular letters, we used = 0.01. For our single-cell RNA-seq dataset, we used = 0.005. These values wereselected such that the branch points were not all too close to 0 or T.",
  "T ), cos(2 t": "T )].For each layer in the UNet, the time embedding was passed through a separate dense layer (unique for everyUNet layer) and concatenated with the input to the UNet layer. For a label-guided model, we learned anembedding for each discrete label. As with the time embedding, the label embedding was passed through aseparate dense layer (unique for every UNet layer) and concatenated to the input to each UNet layer. Our letter models were trained on a dense architecture consisting of 5 dense layers.In our branchedmodels, the first two layers were shared between output tasks. The time embedding was computed as[sin(2 t",
  "T z), cos(2 t": "T z)], where z is aset of Gaussian parameters that are not trainable. This embedding was passed through a dense layer whichprojected this embedding down to a scalar, which was directly multiplied onto the final output of the scorenetworks. These neural-network architectures described above are the standard architectures used for linear (traditional)diffusion models for the associated data type (e.g. images, tabular data, or molecules). In order to turn theseneural network architectures into multi-task architectures for branched diffusion models, we converted eachmodel by multiplexing the last few layers (literally copying the last few layers 2|C| 1 times for |C| classes),thereby turning the model into a multi-task model. The exact number of multiplexed layers multiplexednaturally depends on the data type and architecture, and is discussed below. This multiplexing was donesuch that the prediction path from the input to any single output head is architecturally identical to thestandard single-task architecture. For MNIST and Fashion MNIST, we multiplexed the last 4 layers of the U-Net (i.e. the upsampling layers).Note that because the U-Net concatenates downsampling (early) layers outputs to the upsampler inputs, weeffectively duplicate the downsamplers outputs multiple times, as well, to feed into each output head. Forletters, we multiplexed the last 2 layers. For RNA-seq, we multiplexed the last 3 layers. For molecules, wemultiplexed the last 4 layers for the adjacency-matrix score, and the last 2 layers for the node-features score.",
  "For all of our models, we used a learning rate of 0.001, and trained our models until the loss had converged": "For our label-guided MNIST model, we trained for 30 epochs. For our label-guided letter model, we trainedfor 100 epochs. For our label-guided single-cell RNA-seq model, we trained for 100 epochs. In all cases, wenoted that the loss had converged after training. For our branched continuous-time MNIST model, we trained for 90 epochs. For our branched discrete-timeMNIST model, we trained for 200 epochs. For our branched letter model (continuous-time), we trainedfor 100 epochs. For our branched single-cell RNA-seq model, we trained for 120 epochs. For our branchedZINC250K model labeled by cyclicity, we trained for 200 epochs; for our branched ZINC250K model labeledby halogenation, we trained for 50 epochs. Again, we noted that the loss had converged after training. Ourbranched model on Fashion MNIST used the same training procedure as with MNIST. For our analysis on extending branched models and label-guided (linear) models to new classes, we alsotrained MNIST models on a subset of the dataset (i.e. only 0/4/9 or only 0/4/7/9), and single-cell RNA-seqmodels on a subset of the dataset (i.e. only CD16+ NK/classical monocytes or only CD16+ NK/classicalmonocytes/memory B cells). In these cases, we followed the same training parameters as above, except wetrained for fewer epochs. In the class-extension analysis on MNIST, we started with branched or label-guidedmodels trained on 0s, 4s, and 9s. These models we trained for 30 epochs each. In the class-extension analysison single-cell RNA-seq, we started with a branched or label-guided model trained on CD16+ NK and classicalmonocytes. The branched model was trained for 120 epochs, and the label-guided model was trained for 100epochs.",
  "Sample quality": "We compared the quality of samples generated from our branched diffusion models to those generated by ourlabel-guided (linear) diffusion models using Frchet Inception Distance (FID). For each class, we generated1000 samples of each class from the branched model, 1000 samples of each class from the linear model, andrandomly selected 1000 samples of each class from the true dataset. We computed FID over these samples,comparing each set of generated classes against the true samples. For the tabular letters dataset, there werenot enough letters in the dataset to draw 1000 true samples of each letter, so we drew 700 of each letter fromthe true dataset. For the single-cell RNA-seq dataset, we generated 500 of each cell type from the diffusionmodels, and we sampled as many of each cell as possible from the true dataset (up to a maximum of 500).",
  "Class extension": "For our MNIST dataset, we started with a branched diffusion model trained on 0s, 4s, and 9s. To extenda new branch to reverse diffuse 7s, we simply created a new model with one extra output task and copiedover the corresponding weights. For the new branch, we initialized the weights to the same as those on thecorresponding 9 branch (with si = 0). We trained this new branch on only 7s, only for the time interval ofthat new branch. On the corresponding label-guided (linear) model, we fine-tuned on only 7s or on 0s, 4s, 7s,and 9s. In each experiment, we started with the linear model trained on 0s, 4s, and 9s.",
  "Hybrid intermediates and transmutation": "For certain pairs of MNIST digits or letters, we found the earliest branch point for which they belong tothe same branch, and generated hybrids by reverse diffusing to that branch point. To generate the averageMNIST hybrids, we sampled 500 objects from the prior and reverse diffused to the branch point, and averagedthe result.",
  "Multi-class sampling efficiency": "We computed the amount of time taken to generate 64 examples of each class from our branched diffusionmodels, with and without taking advantage of the branch points. We took the average time over 10 trialseach. When leveraging the branching structure to generate samples, we ordered the branches by start time si indescending order. For each branch bi in that order, we reverse diffused down the branch, starting with acached intermediate at ti for the branch that ended at ti. For the very first branch (the root), we startedreverse diffusion by sampling (x). This guarantees that we will have a cached batch of samples at everybranch point before we encounter a branch that starts at that branch point. Eventually, this algorithmgenerates a batch of samples for each class. For each branch, we performed reverse diffusion such that thetotal number of steps for any one class from t = T to t = 0 was 1000. To generate samples without leveraging the branching structure, we simply generated each class separatelyfrom the branched model, without caching any intermediates. Note that this takes the same amount of timeas a purely linear model (of identical capacity and architecture) without any branching structure.",
  "Robustness of branch points": "To quantify the robustness of branched diffusion models to the underlying branch points, we computed thebranch points for MNIST (continuous-time, all 10 digits) 10 times, each time following the procedure inAppendix A. Variation in the branch points resulted from variation in the randomly sampled objects, and inthe forward-diffusion process. For each set of branch definitions, we trained a branched diffusion model usingthe procedure above. We then computed FID using the same procedure as above for other MNIST models,and compared the values to the FIDs of the corresponding label-guided MNIST model.",
  "To quantify the similarity of the hierarchies, we computed the pairwise branch-score distance between all102": "pairs of hierarchies discovered from our algorithm. We then generated 10 random hierarchies in a greedyfashion: start with all classes, and uniformly pick a random partition; uniformly pick a branch point btbetween 0 and 1; recursively generate the two hierarchies below with a maximum time of bt, until all classsets have been reduced to singletons. We used a Wilcoxon test to compare the distribution of branch-score"
}