{
  "Abstract": "Computed Tomography (CT) is pivotal in industrial quality control and medical diagnostics.Sparse-view CT, offering reduced ionizing radiation, faces challenges due to its under-samplednature, leading to ill-posed reconstruction problems. Recent advancements in Implicit NeuralRepresentations (INRs) have shown promise in addressing sparse-view CT reconstruction.Recognizing that CT often involves scanning similar subjects, we propose a novel approach toimprove reconstruction quality through joint reconstruction of multiple objects using INRs.This approach can potentially utilize the advantages of INRs and the common patternsobserved across different objects. While current INR joint reconstruction techniques primarilyfocus on speeding up the learning process, they are not specifically tailored to enhance thefinal reconstruction quality. To address this gap, we introduce a novel INR-based Bayesianframework integrating latent variables to capture the common patterns across multipleobjects under joint reconstruction. The common patterns then assist in the reconstruction ofeach object via latent variables, thereby improving the individual reconstruction. Extensiveexperiments demonstrate that our method achieves higher reconstruction quality with sparseviews and remains robust to noise in the measurements as indicated by common numericalmetrics. The obtained latent variables can also serve as network initialization for the newobject and speed up the learning process.1 Equal contribution.1We have used ChatGPT provided by OpenAI to assist in writing. The language model was employed at the sentence levelfor tasks such as fixing grammar and rewording sentences. We assure that all ideas, claims, and results presented in this workare human-sourced.",
  "Introduction": "Computed Tomography (CT) is a crucial non-invasive imaging technique, extensively employed in medicaldiagnostics and industrial quality control. In CT, an objects internal structure is reconstructed from X-rayprojections captured at multiple angles, posing a complicated inverse problem. In certain situations, reducingthe number of CT measurements can yield advantages such as decreased radiation exposure and enhancedproduction throughput. However, this sparsity in measurements, along with other factors such as the presenceof noise and the size of detectors, complicates the reconstruction process, making it an ill-posed inverseproblem. Such challenges arise not only in CT reconstruction but also across diverse computational tasks.Therefore, while our study centers on sparse-view CT reconstruction, the core ideas are transferable tonumerous inverse problems, such as Magnetic Resonance Imaging and Ultrasound Imaging. Different strategies have been developed to address the challenges of sparse-view CT reconstruction byincorporating auxiliary information. Supervised learning techniques learn mappings from measurements toimages (Zhang et al., 2018b; Han & Ye, 2018; Zhu et al., 2018; Wu et al., 2021). These methods train onextensive datasets containing dense measurements, synthesizing the sparse view through physical models ofthe measurement process. Alternatively, Song et al. (2022) introduces an approach that directly learns theimage distribution from high-quality reconstructed images using generative models. Several diffusion-basedapproaches (Chung et al., 2022; Liu et al., 2023; Song et al., 2023; Xu et al., 2024) have been specificallytailored for CT applications, further refining the foundational ideas presented by Song et al. (2022). However,their method still relies on a large, domain-specific dataset, that closely matches the target of reconstruction.Dependence on large datasets introduces practical limitations to supervised learning techniques and generativemethods, particularly when collecting large-scale and high-quality data is intractable, such as due to privacyregulation in medical cases or timeliness in industrial settings. It is important to note that supervised learningand diffusion-based approaches represent only a subset of the methods available for CT reconstruction. Thereare also some studies that leverage heuristic image priors, e.g. Total Variation (TV) (Sidky & Pan, 2008; Liuet al., 2013; Zang et al., 2018). While effective, these methods lack the ability to incorporate domain-specificenhancement. Another approach involves using a few dense-view images as priors for reconstruction (Chenet al., 2008; Shen et al., 2022). However, this method hinges on the availability of dense-view images similarto the target object, which is often impractical when the appearance of the object to be reconstructed isunknown. Building on the foundations of CT reconstruction, many works explore the potential of implicit neuralrepresentations (INRs). Thanks to the advantages of INRs, such as their continuous representation nature incontrast to conventional discrete representations (Lee et al., 2021; Xu et al., 2022; Grattarola & Vandergheynst,2022), these methods have consistently delivered promising reconstruction results with limited number ofmeasurements (Zang et al., 2021; Zha et al., 2022; Rckert et al., 2022; Wu et al., 2023b). Given INRsproven capabilities in CT reconstruction and the known advantages of incorporating prior information, eitherheuristically through TV (Zang et al., 2021) or explicitly from dense-view CT images (Shen et al., 2022), weseek to merge these two paradigms. Aiming for broad applicability, we avoid reliance on pre-curated datasets.Instead, we draw inspiration from the fact that modern CT machines routinely scan similar subjects, such aspatients in hospitals or analogous industrial products. This commonality drives us to explore a novel questionin this research: : Compared to individual reconstruc-tion, joint reconstruction enables INRs toshare statistical regularities among multipleobjects, thereby enhancing the quality of re-construction under conditions of sparse-viewCT scans and inherent measurement noise.The examples shown here are CT reconstruc-tions of walnuts from a sparse set of projectionangles, with the joint reconstruction resultsobtained using our proposed approach.",
  "j=1 DKL(N(j, j)kN(!, ))": ": Framework of our proposed method.It uses latent variables to capture the rela-tion among all reconstruction nodes.Thelatent variables are updated based on allnodes and regularize each individual recon-struction via minimizing the KL divergenceterms DKL. wj denotes the parameters ofj-th node, distributed according to N(j, j),while N(, ) specifies the prior distributionof parameters w1:J.",
  "Can INRs use the statistical regularities shared among multiple objects with similar represen-tation to improve reconstruction quality through joint reconstruction?": "contrasts the methodologies of individual reconstruction against joint reconstruction. In our explo-ration of this research avenue, we found that several existing methods can be adapted for our purpose (Zhanget al., 2013; Ye et al., 2019; Tancik et al., 2021; Martin-Brualla et al., 2021; Kundu et al., 2022). Theseapproaches have utilized the inherent statistical regularities across different objects, represented by thenetwork weights in INRs. However, they often focus on addressing issues like convergence rate (Tancik et al.,2021; Kundu et al., 2022) rather than optimizing the reconstruction quality itself. As demonstrated in ourexperimental evaluations 5, these methods achieve lower PSNR and SSIM compared to our proposed methodin joint reconstruction scenarios. To address our research question, we propose a novel INR-based Bayesian framework, specifically tailored toadaptively integrate prior information into network weights during the training process. This is achieved byutilizing latent variables that encapsulate commonalities in the parameter space among multiple objects neuralrepresentations. The latent variables representing prior information are then leveraged to enhance the accuracyof individual reconstructions. The convergence of our model is guided by minimizing the Kullback-Leibler(KL) divergence between the prior and the estimated posterior distributions of the neural representationnetworks. Importantly, our framework can automatically adjust the regularization strength of the priorinformation based on the similarity among neural representation networks. Overall, our framework providesa robust solution to the challenges posed by sparse and noisy measurements, and varied reconstructions inCT imaging. An illustration of our proposed Bayesian framework is presented in . Our Contributions: i) We explore a novel problem of INR-based joint reconstruction in the context ofCT imaging, supported by a comprehensive review of existing methods that could be adapted to addressthis challenge. ii) We propose a principled Bayesian framework that adaptively integrates prior informationthroughout the training process for enhanced reconstruction quality. iii) Through extensive experiments, weevaluate various facets of reconstruction performance using common numerical metrics. Our results establishthat our method outperforms the compared INR-based baselines.",
  "Related Work": "We briefly outline key studies related to our focal areas, with a comprehensive understanding of INR andNeural Radiance Fields (NeRF) available in the survey (Tewari et al., 2022; Molaei et al., 2023). The keyworking principles of INR for CT reconstruction is explained in 3. Coordinate-based Multi-Layer Perceptrons (MLPs) intake spatial coordinates and output values, such asRGB or density, processed through MLP. Unlike traditional discrete representations that directly mapinputs to outputs on pixel grids, these coordinate-based outputs are generated by the MLP. Therefore,such coordinate-based representations are often regarded as INRs. Originally, INRs faced challenges incapturing high-frequency details. However, the introduction of coordinate encoding, such as Fourier featuretransformations (Jacot et al., 2018; Tancik et al., 2020), has significantly enhanced their ability to representfiner details. NeRF is a state-of-the-art INR approach that reconstructs scenes from photos taken at multiple angles(Mildenhall et al., 2021; Barron et al., 2021; 2022), similar to CT where projections are acquired at different",
  "Published in Transactions on Machine Learning Research (09/2024)": "Since each network is trained separately, our framework runs efficiently via parallel computing. The likelihoodp(yj|wj) can be maximized by minimizing the squared error loss of the reconstruction (see Equation (2)).Similarly to Zhu et al. (2023), we adopt EM to maximize the ELBO. At the E-step, the latent variables{, } are fixed and each network optimizes with respect to the loss function:",
  "Problem Statement and Preliminaries": "The CT acquisition process, in an ideal noiseless scenario, can be mathematically described by the equation:y = Ax, where x Rm represents the unknown object of interest and y Rn symbolizes the ideal noiselessmeasurements. In practice, the actual obtained measurements y Rn are often noisy, where the differencebetween actual and ideal measurements = y y is the measurement noise. We note that the measurementnoise Rn is a stochastic term representing general noise, including non-additive types like Poisson noise,which is the primary focus of this study. For simplicity and to maintain focus on the methodological aspects,this manuscript primarily expands formulas under the assumption of noiseless measurements y, unlessspecified otherwise. These measurements arise from the interaction between the measurement matrix A Rnm and the object.The task in CT is to infer the unknown object x from the acquired CT measurements y. The inherent challengelies in the common sparsity of these measurements, resulting in m > n. This makes the reconstructionproblem ill-posed. Meanwhile, measurement noise can further corrupt the reconstruction results. The INR designed for CT reconstruction is a function fw : R3 R1 parameterized by w. It maps thethree-dimensional spatial coordinates of the object to its intensity. INR consists of two components, formulatedas fw = M . Here, : R3 Rd servers as the position encoding (Tancik et al., 2020; Barron et al., 2022;Martel et al., 2021; Mller et al., 2022), while M : Rd R1 acts as the neural representation. Typically, Mis an MLP. The function fw() takes a coordinate ci R3 and maps it to the intensity value v R1. For a full setof coordinate C := {c1, c2, . . . , cN}, the INR outputs the representation of the entire object as Fw(C) :={fw(c1), fw(c2), . . . , fw(cN)}. The networks parameters w can be optimized by minimizing the loss function:(w) := AFw(C) y22. Joint Reconstruction Problem. We aim to simultaneously recover J objects x1:J using their correspondingmeasurements y1:J and measurement matrices A1:J. The joint reconstruction problem can be formulated as:",
  "Existing Methods Available for Joint Reconstruction": "In our exploration of this research avenue, we found several existing methods, though originally designedfor different problems, have utilized the statistical regularities of multiple objects. These methods may beadaptable to our research problem. In this section, we delve into these methods in greater detail. Empiricalevaluations, as demonstrated in 5, suggest that some of these techniques can outperform the individualreconstruction approach. However, they do not fully exploit the statistical regularities to improve thereconstruction quality, which we discuss in the 4. Composite of Static and Transient Representations. Martin-Brualla et al. (2021) introduce a compositerepresentation approach NeRFWild, designed to manage variable illuminations and transient occluders incollective observations. While CT does not involve variable illumination, their concept of combining staticand transient components can be adapted for our context, which we term INRWild. Let G represent the neural representation for the static component ( is the weights of MLP G) andHw signify the transient component (w is the weights of MLP H). For a given set of J objects, eachobject-associated reconstruction node has its distinct transient network wj and corresponding transientfeature bj. In contrast, the static network is shared across all nodes. The objective for this framework isformulated as:",
  "The output of the static network G is split into two components: Gr(C), which represents the static intensity,": "and G\\r (C), which serves as intermediate features for the transient networks. The symbols r and \\r denotethe division of outputs into these two components. Detailed explanation and framework schematic are inAppendix B.2. At its core, INRWild emphasizes training the static network , which embodies most learnableparameters, using aggregated losses. Concurrently, the individual representations, characterized by w1:J andb1:J, are refined based on that corresponds to the static part. w1:J, b1:J and are jointly optmized toachieve the composition of static and transient parts. Model-agnostic Meta-learning (MAML): Meta-learning aims to train a network in a way that it canquickly adapt to new tasks (Finn et al., 2017; Nichol et al., 2018; Fallah et al., 2020). Several INR-basedworks have employed MAML to obtain a meta-learned initialization, thereby accelerating the convergence orenabling model compression (Tancik et al., 2021; Lee et al., 2021). In the MAML framework, computationalcycles are organized into inner loops and outer loops, indexed by k = 1 . . . K and t = 1, . . . , T respectively.For each node j = 1, . . . , J, the networks w1:J are initialized according to the meta neural representationw(0)1:J = . These networks then undergo K steps of inner-loop learning: w(k)j= w(k1)j wjj(w(k1)j),where is the inner-loop learning rate. After these K steps, the meta network updates as follows:",
  ",(4)": "where is the outer-loop learning rate. Equation (4) is a form that can be further specialized. After T stepsof outer-loop optimization, the meta-learned neural representation (T ) serves as an effective initialization forindividual reconstructions. Federated Averaging (FedAvg): Kundu et al. (2022) suggested to employ FedAvg (McMahan et al., 2017)as the optimization framework of the meta-learned initialization. Like MAML, FedAvg also consists of innerand outer loops. The inner loop is identical to MAML. Whereas, the outer loop simplifies the optimization by",
  "In this section, we introduce INR-Bayes, our Bayesian framework for INR joint reconstruction": "Motivation. NeRFWild is proposed to address scene reconstruction challenges, such as reconstructingpopular sightseeing sites from in-the-wild photos. These scenarios often involve a primary target object, likea landmark, amidst various transient elements such as pedestrians and changing light conditions. A methodthat uses a composition of static and transient components operates under the assumption that the corerepresentations of the scenethose of the main objectsubstantially overlap, despite different viewpoints ortransient changes. This assumption typically holds true in 3D scene reconstruction, where observations arecollected from multiple perspectives of the same object. Our empirical findings on INRWild indicate suchmethods do not work efficiently in CT reconstruction and other image-level reconstruction tasks (discussed in5). Meta-learned initialization methods, such as FedAvg and MAML, train a meta model to capture a high-levelrepresentation, which can then be promptly adapted to individual objects. Although the meta model caneffectively extract statistical regularities among multiple objects, we observe that this prior information tendsto be lost during the adaptation phase. This loss occurs as the adaptation relies solely on local measurements,leading to an overfitting issue, as we will discuss in 5. Overfitting is a notorious problem in iterative methodsof CT reconstruction (Herman & Odhner, 1991; Effland et al., 2020), which renders these methods sensitive tohyperparameters, such as early stopping. This sensitivity consequently increases the difficulty of deployment. To enhance the joint reconstruction process, we propose a principled Bayesian framework. Our methodemploys latent variables, denoted by {, }, to capture commonalities among individual INR networks. Theselatent variables actively serve as references throughout the entire reconstruction process, guiding the trainingof individual networks. Definition and Notation. We introduce distributions to the networks w1:J for J objects, and definelatent variables {, } that parameterize an axis-aligned multivariate Gaussian prior N(, ) from whichthe weights w1:J are generated. Each node is assumed to be of the same size. A Gaussian distribution is anatural and effective choice for the weight distribution of the MLP such as INR networks (de G. Matthewset al., 2018). The latent variables collectively serve to capture the shared trends within the networks,effectively quantifying the mutual information across different objects. To simplify the model, we assume theconditional independence among all objects: p(w1:J|, ) = Jj=1 p(wj|, ). This assumption of conditionalindependence allows us to decompose the variational inference into separable optimization problems, therebyfacilitating more efficient parallel computing. Given that the measurements of the objects y1, . . . , yJ are mutually independent and that each networkfocuses on a specific object, the posterior distribution of network weights and latent variables can be derivedusing the Bayes rule as p(w1:J, , |y1:J) p(, ) Jj=1 p(yj|wj)p(wj|, ). While this posterior enablesvarious forms of deductive reasoning such as reconstruction uncertainty quantification, inferring the trueposterior is often computationally challenging. Moreover, the selection of an appropriate prior p(, ) posesits own difficulties (Wenzel et al., 2020; Fortuin et al., 2022). To tackle these issues, we present an algorithmthat aims at maximizing the marginal likelihood p(y1:J|, ), integrating out 1:J. Detailed derivations areprovided in Appendix A.",
  "q(w1:J).(5)": "The ELBO is optimized using Expectation Maximization (EM) (Dempster et al., 1977), a two-stage iterativealgorithm involving an E-step and an M-step. Generally, each EM cycle improves the marginal likelihoodp(y1:J|, ) unless it reaches a local maximum. E-step. At this stage, the latent variables {, } are held fixed. The aim is to maximize ELBO by optimizingthe variational approximations q(w1:J). By the conditional independence assumption, the objective can beseparately optimized. Specifically, each network j minimizes:",
  "L (q(wj)) = Eq(wj) log p(yj|wj) + DKL(q(wj)p(wj|, )).(6)": "The minimization of the negative log-likelihood term is achieved through the minimization of the squarederror loss of reconstruction (see Equation (2)). The KL divergence term DKL serves as a regularizationconstraint on the network weights, pushing the posterior q(wj) to be closely aligned with the conditionalprior determined by {, }, which represent the collective mean and variance of all the networks in theensemble. The KL divergence term thus serves to couple the neural representations across networks, allowingthem to inform each other.",
  "j=1j + (j )2.(8)": "In our framework, serves as the collective mean of individual network weights, while provides a measureof dispersion. This measure factors in both individual variances and deviations from the collective mean.We note that the KL divergence term, introduced in the preceding E-step objective (see Equation (6)),operates element-wise. As a result, during the training process, weight elements with larger values are lessregularized, and vice versa. This results in a flexible, self-adjusting regularization scheme that adaptivelypushes all weights toward the latent mean, .",
  "Next, we discuss the intricacies of implementation, addressing in particular the computational challengesassociated with Equation (6). See Algorithm 1 for a summary of our method": "Variational Approximation and Reparameterization Tricks. Given that the expected likelihoodin Equation (6) is generally intractable, we resort to Monte Carlo (MC) sampling to provide an effectiveestimation. Moreover, we introduce an additional hyperparameter for the KL divergence to balance thetrade-off between model complexity and overfitting. Linking the likelihood with the square error loss, for anynode j, the effective loss function can be expressed as:",
  "j": "trick (Kingma & Welling, 2013): q(wj) = j + log (1 + exp (j)) N(0, I). Here, we additionally employ thesoftplus function in parameterizing the variance j with the variable j to ensure the non-negativity of thevariance. The EM algorithm operates by alternating between E and M steps. In the E-step, we perform T iterations toachieve locally optimal variational approximations. Following this, the M-step utilizes the closed-form solution(see Equation (8)) for efficient parameter updating. The entire cycle is executed for R rounds to ensureconvergence. Finally, the posterior means 1:J serve as the weights for individual neural representations,while the prior mean is used as the weights for the latent neural representation.",
  "Experiments": "Dataset. Our study utilizes four CT datasets: WalnutCT with walnut scans (Der Sarkissian et al., 2019),AluminumCT of aluminum alloy at different fatigue-corrosion phases from Tomobank (De Carlo et al., 2018),LungCT from the Medical Segmentation Decathlon (Antonelli et al., 2022) and 4DCT on the lung area(Castillo et al., 2009). Additionally, we include a natural image dataset CelebA (Liu et al., 2015) to evaluatethe generalizability to broader applications. The objects of interest are centrally positioned within the imagesacross all datasets. Central positioning in practice is achievable during acquisition by monitoring initialplacement. Comparison Methods. We compare our approach with other methods that do not require a set of denselymeasured data, thereby excluding those of supervised learning: i) Classical techniques: Filtered Back Projection(FBP) and Simultaneous Iterative Reconstruction Technique (SIRT) (Gilbert, 1972); ii) Regularization-basedapproaches with model-based reconstruction method FISTA (Beck & Teboulle, 2009): total generalizedvariation denoted as RegTGV proposed by Niu et al. (2014), wavelet based regularization RegWavelet (Zhanget al., 2018a; Garduo et al., 2011) and second order Lysaker-Lundervold-Tai with Rudin-Osher-Fatemi TV,denoted as RegLLT-TV (Kazantsev et al., 2017); iii) Naive INR-based single reconstruction method, denotedas SingleINR; iv) FedAvg, a federated averaging approach proposed by Kundu et al. (2022); v) MAML, ameta-learning technique as discussed by Tancik et al. (2021); vi) INRWild, a method adapted from NeRFWild(Martin-Brualla et al., 2021). FBP and SIRT are classical methods that do not use networks, while all othermethods employ an identical INR network as described in the next paragraph.",
  "RegLLT-TV": ": Visual comparison of reconstruction performance on noiseless measurements. Enlarged areas arehighlighted in red insets. PSNR values are on the top left, with SSIM values on the bottom left. Reconstructionof human faces is included to illustrate our methods broad applicability, despite lacking practical relevancein physical contexts. Illustrations figures (first column) are modified from J.Dncsn (2009); Agashi5859 (2014);Lene (2021); Liu et al. (2015). Reconstruction Performance. shows that our method consistently achieves the highest averagemetrics across datasets on noiseless measurements, with the exception of the SSIM values on the CelebAdataset, excelling in leveraging inherent trends in slices. This advantage is particularly pronounced inexperiments with distinct transition patterns, as seen in both inter-object and intra-object settings. Incontrast, INRWild generally underperforms compared to SingleINR. Its strategy of jointly reconstructing staticrepresentations while independently capturing transient characteristics fails to enhance overall reconstructionquality. In most scenarios, FedAvg is outperformed by SingleINR, suggesting its inability to learn a metarepresentation that meaningfully improves reconstruction quality. MAML ranks as the second-best methodin most settings, indicating its learned meta representation aids in individual reconstruction performance.However, regularization-based methods typically underperform compared to INR-based methods, except onthe CelebA dataset where RegLLT-TV achieves the highest SSIM value. This underscores the efficacy of theheuristic LLT-TV prior for natural images as opposed to CT images. The visual comparisons in further validate our results. Reconstructions by SingleINR exhibitnoticeable artifacts, while FedAvg and MAML struggle to capture finer image details. RegLLT-TV often resultsin overly smooth reconstructions, but in contrast, INR-Bayes achieves superior visual quality, effectivelybalancing smoothness and detail preservation, yielding results closer to the ground truth. Overfitting.3 Iterative reconstruction methods tend to overfit when applied to limited data (Herman &Odhner, 1991; Effland et al., 2020) (particularly noticeable in sparse-view CT scenarios). In contrast, Bayesianframeworks have demonstrated robustness against overfitting (MacKay, 1992; Neal, 2012; Blundell et al.,2015). To validate this, we extend the training iterations in from 30K to 60K. As shown in on inter-object LungCT, the learning curves of baselines deteriorate in the long run, indicating overfitting 3In the context of CT reconstruction, conventional iterative methods like SIRT typically approach a good approximation tothe exact solution early in iterations and subsequently diverge from it, often attributed to convergence issues (Elfving et al.,2014). In contrast, in the machine learning domain, overfitting refers to a scenario where a neural network excessively fits totraining data, leading to a drop in actual performance despite decreasing training loss (Srivastava et al., 2014). Our experimentscontain both non-learning-based methods (SIRT) and learning-based methods (INR). We acknowledge the subtle differencesbetween convergence challenges and overfitting but use the term overfitting broadly to describe performance deterioration inboth noiseless and noisy scenarios.",
  "during optimization. Conversely, our approach maintains a consistent level of reconstruction quality once theoptimal performance is achieved, underscoring its robustness": "Given that practical measurements often contain noise, leading to poorer reconstruction quality, we evaluatethe methods on noisy measurements on AluminumCT, WalnutCT, LungCT and CelebA datasets in inter-object setup. The noise is simulated following Hendriksen et al. (2020) (detailed in Appendix B.1). Asindicated in , our methods performance is notably superior against other methods under noiseconditions. shows the training curves on noisy WalnutCT data. Although all methods reachsimilar peak PSNR values, the compared baselines rapidly deteriorate due to overfitting, while our methodexhibits minimal overfitting thanks to its continuous prior guidance. The reconstruction outcomes for thesenoisy scenarios are depicted in . This robustness is especially critical in practical scenarios, wheredetermining an exact stopping criterion is challenging, as the ground truth reference is not available. Challenge in Determinating Appropriate Stopping Criterion.We find that in the noisy CTreconstruction environments it is inherently challenging to determine the optimal stopping point when theoverfitting problem presents. This is due to the variation of convergence speed across different objects. Todemonstrate that, we present the individual SingleINR training curves from three different patients within",
  "MethodPSNRSSIMPSNRSSIMPSNRSSIMPSNRSSIM": "FBP15.59 0.26 0.270 0.002 20.33 0.17 0.353 0.003 27.77 0.04 0.515 0.001 17.81 0.38 0.474 0.007SIRT23.48 0.25 0.405 0.007 28.03 0.14 0.623 0.005 28.23 0.03 0.759 0.001 26.90 0.21 0.681 0.007RegTGV27.76 0.31 0.748 0.010 27.44 0.17 0.619 0.006 27.14 0.03 0.862 0.001 27.97 0.18 0.800 0.004RegWavelet 23.49 0.25 0.393 0.006 26.52 0.15 0.548 0.005 25.19 0.03 0.716 0.001 22.83 0.26 0.471 0.010RegLLT-TV 28.51 0.31 0.817 0.010 30.58 0.17 0.783 0.006 27.23 0.03 0.863 0.001 28.00 0.18 0.801 0.001 SingleINR22.03 0.39 0.809 0.006 27.16 0.23 0.681 0.008 29.50 0.12 0.602 0.006 27.41 0.24 0.701 0.009MAML26.55 0.30 0.860 0.004 30.04 0.20 0.758 0.006 32.58 0.07 0.741 0.003 27.55 0.26 0.701 0.010FedAvg25.37 0.39 0.836 0.005 27.13 0.22 0.696 0.006 29.87 0.10 0.617 0.005 25.67 0.15 0.669 0.007INR-Bayes30.13 0.31 0.885 0.003 31.20 0.20 0.799 0.006 35.09 0.12 0.869 0.006 28.24 0.27 0.729 0.010",
  "Total Iterations": "PSNR / dB Case 1Case 2Case 3 : SingleINR training curves for three differentpatients from the noisy LungCT dataset, each show-ing unique optimal stopping points. This variabilityexemplifies the challenges in universally determiningthe precise moment to stop training. Applying to Unseen Data using Learned Prior. To evaluate the generalizability of the learned priors, weapply meta models or latent variables from the inter-object LungCT experiment to guide the reconstructionof new subjects in the dataset. Specifically, we select 5 consecutive slices from new objects, choosing slicesfrom a similar location (i.e. the similar axial slice index) the prior has been trained. The prior information issolely utilized to guide the reconstruction and is not updated during the process. shows that FedAvgfails to improve the reconstruction quality compared with singleINR, suggesting its learned meta neuralrepresentation struggles to generalize to unseen data. In contrast, both INR-Bayes and MAML effectivelyleverage their trained priors for improved reconstruction, with our method showing notably better metrics.Applying learned prior can also accelerate the training process. presents learning curves of differentmethods. All joint reconstruction methods converge faster than individual reconstruction. Initially, FedAvgconverges the fastest, but as training progresses, both MAML and INR-Bayes surpass it. Additionally, theresults reconfirm the robustness of INR-Bayes against overfitting, an issue that tends to challenge othercompared methods.",
  ": Adaptation on new patients using priorslearned from other patients compared to individ-ual reconstruction. The results are averaged by10 new patients (5 slices each patient)": "Comparison with Different Numbers of Angles. Next, we investigate how different methods fare withvarying levels of data sparsity. demonstrates that all methods benefit from increased scanning angles.Methods that leverage prior information like FedAvg, MAML, and INR-Bayes outperform singleINR when thenumber of angles is limited. With only 20 angles, FedAvgs performance is on par with our method, indicatingthat the averaging scheme can be effective in extremely data-scarce scenarios. However, as the number",
  ": Performance across different numbers ofscanning angles. Our method shows an advantageover other comparison methods, especially in sparseangle cases": "Number of Nodes 29.0 29.5 30.0 30.5 31.0 31.5 PSNR / dB INR-BayesMAMLFedAvgSingleINR : The performance of different methodson new patients using prior obtained with differentnumbers of patients. SingleINR is presented as areference. The performance of our propsoed methodgradually increases with the increasing number jointreconstruction nodes. of angles grows, both INR-Bayes and MAML surpass FedAvg. It is also worth noting that the performancegap between singleINR and INR-Bayes narrows as more data becomes available, suggesting that while theprior information is useful in sparse data situations, its advantage diminishes in the data-rich environment.Nevertheless, our INR-Bayes method generally yields the best results in various settings. Impact of Joint Nodes Numbers on Learned Prior. We explore how varying the number of nodesinfluences the learned prior in an inter-object LungCT dataset setup. illustrates that our INR-Bayesmethod benefits from an increased number of nodes, unlike FedAvg, which consistently lags behind inperformance. Notably, MAML shows a decline in performance with more nodes, consistent with the trendsobserved in . These findings suggest that INR-Bayes effectively develops a stronger prior with morenodes. As the number of nodes increases, the priors mean and variance gradually align with populationstatistics, thereby enhancing its utility for new object reconstructions. This advantage is expected to continueuntil reaching a saturation point with a sufficiently large number of nodes. Computation. Our method takes 22.7 minutes on average for a 501501 reconstruction on A100 GPU, 15%longer than other INR methods. This computational overhead yields noticeable gains in reconstruction qualityand robustness across diverse settings. We also investigate the computational efficiency and performancetrade-off in Appendix D.7.",
  "Conclusions and Limitations": "In this work, we study the possibility of improving the CT reconstruction quality through joint reconstructionand introduce a novel INR-based Bayesian framework. Through extensive experiments, our method haseffectively showcased its ability to leverage the statistical regularities inherent in the sparse and noisymeasurements of multiple objects to improve individual reconstructions. This capability allows our approachto outperform compared methods in reconstruction quality, robustness to overfitting as well as generalizability.",
  "Agashi5859. After flatting aluminum rod. 2014. URL Accessed: date-of-access. Licensed under CC BY-SA 3.0. Modifications were made": "Anastasios N Angelopoulos, Amit Pal Kohli, Stephen Bates, Michael Jordan, Jitendra Malik, Thayer Alshaabi,Srigokul Upadhyayula, and Yaniv Romano. Image-to-image regression with distribution-free uncertaintyquantification and applications in imaging. In International Conference on Machine Learning, pp. 717730.PMLR, 2022. Michela Antonelli, Annika Reinke, Spyridon Bakas, Keyvan Farahani, Annette Kopp-Schneider, Bennett ALandman, Geert Litjens, Bjoern Menze, Olaf Ronneberger, Ronald M Summers, et al. The medicalsegmentation decathlon. Nature communications, 13(1):4128, 2022. Jonathan T Barron, Ben Mildenhall, Matthew Tancik, Peter Hedman, Ricardo Martin-Brualla, and Pratul PSrinivasan. Mip-nerf: A multiscale representation for anti-aliasing neural radiance fields. In Proceedings ofthe IEEE/CVF International Conference on Computer Vision, pp. 58555864, 2021. Jonathan T Barron, Ben Mildenhall, Dor Verbin, Pratul P Srinivasan, and Peter Hedman. Mip-nerf 360:Unbounded anti-aliased neural radiance fields. In Proceedings of the IEEE/CVF Conference on ComputerVision and Pattern Recognition, pp. 54705479, 2022.",
  "Charles Blundell, Julien Cornebise, Koray Kavukcuoglu, and Daan Wierstra. Weight uncertainty in neuralnetwork. In International conference on machine learning, pp. 16131622. PMLR, 2015": "Richard Castillo, Edward Castillo, Rudy Guerra, Valen E Johnson, Travis McPhail, Amit K Garg, andThomas Guerrero. A framework for evaluation of deformable image registration spatial accuracy usinglarge landmark point sets. Physics in Medicine & Biology, 54(7):1849, 2009. Guang-Hong Chen, Jie Tang, and Shuai Leng. Prior image constrained compressed sensing (piccs): a methodto accurately reconstruct dynamic ct images from highly undersampled projection data sets. Medicalphysics, 35(2):660663, 2008.",
  "Yinbo Chen and Xiaolong Wang. Transformers as meta-learners for implicit neural representations. InEuropean Conference on Computer Vision, pp. 170187. Springer, 2022": "Hyungjin Chung, Byeongsu Sim, Dohoon Ryu, and Jong Chul Ye. Improving diffusion models for inverseproblems using manifold constraints. Advances in Neural Information Processing Systems, 35:2568325696,2022. Francesco De Carlo, Doa Grsoy, Daniel J Ching, K Joost Batenburg, Wolfgang Ludwig, Lucia Mancini,Federica Marone, Rajmund Mokso, Danil M Pelt, Jan Sijbers, et al. Tomobank: a tomographic datarepository for computational x-ray science. Measurement Science and Technology, 29(3):034004, 2018. Alexander G. de G. Matthews, Jiri Hron, Mark Rowland, Richard E. Turner, and Zoubin Ghahramani.Gaussian process behaviour in wide deep neural networks. In International Conference on LearningRepresentations, 2018.",
  "A. P. Dempster, N. M. Laird, and D. B. Rubin. Maximum likelihood from incomplete data via the emalgorithm. Journal of the Royal Statistical Society: Series B (Methodological), 39(1):122, 1977. doi:": "Henri Der Sarkissian, Felix Lucka, Maureen van Eijnatten, Giulia Colacicco, Sophia Bethany Coban, andKees Joost Batenburg. A cone-beam x-ray computed tomography data collection designed for machinelearning. Scientific data, 6(1):215, 2019. Alexander Effland, Erich Kobler, Karl Kunisch, and Thomas Pock. Variational networks: An optimal controlapproach to early stopping variational methods for image restoration. Journal of mathematical imagingand vision, 62:396416, 2020.",
  "Tommy Elfving, Per Christian Hansen, and Touraj Nikazad. Semi-convergence properties of kaczmarzsmethod. Inverse problems, 30(5):055007, 2014": "Alireza Fallah, Aryan Mokhtari, and Asuman Ozdaglar. On the convergence theory of gradient-based model-agnostic meta-learning algorithms. In Silvia Chiappa and Roberto Calandra (eds.), Proceedings of theTwenty Third International Conference on Artificial Intelligence and Statistics, volume 108 of Proceedingsof Machine Learning Research, pp. 10821092. PMLR, 2628 Aug 2020. Chelsea Finn, Pieter Abbeel, and Sergey Levine. Model-agnostic meta-learning for fast adaptation of deepnetworks. In Proceedings of the 34th International Conference on Machine Learning - Volume 70, ICML17,pp. 11261135. JMLR.org, 2017. Vincent Fortuin, Adri Garriga-Alonso, Sebastian W. Ober, Florian Wenzel, Gunnar Ratsch, Richard ETurner, Mark van der Wilk, and Laurence Aitchison.Bayesian neural network priors revisited.InInternational Conference on Learning Representations, 2022.",
  "Lise-Lotte Lene. Radiograf forbereder ct-scanning. 2021. URL Ac-cessed: date-of-access. Licensed under CC BY-SA 3.0. Modifications were made": "Zhengqi Li, Simon Niklaus, Noah Snavely, and Oliver Wang. Neural scene flow fields for space-time viewsynthesis of dynamic scenes. In Proceedings of the IEEE/CVF Conference on Computer Vision and PatternRecognition, pp. 64986508, 2021. Jiaming Liu, Rushil Anirudh, Jayaraman J Thiagarajan, Stewart He, K Aditya Mohan, Ulugbek S Kamilov,and Hyojin Kim. Dolce: A model-based probabilistic diffusion framework for limited-angle ct reconstruction.In Proceedings of the IEEE/CVF International Conference on Computer Vision, pp. 1049810508, 2023. Yan Liu, Zhengrong Liang, Jianhua Ma, Hongbing Lu, Ke Wang, Hao Zhang, and William Moore. Totalvariation-stokes strategy for sparse-view x-ray ct image reconstruction. IEEE transactions on medicalimaging, 33(3):749763, 2013.",
  "Alex Nichol, Joshua Achiam, and John Schulman. On first-order meta-learning algorithms. arXiv preprintarXiv:1803.02999, 2018": "Shanzhou Niu, Yang Gao, Zhaoying Bian, Jing Huang, Wufan Chen, Gaohang Yu, Zhengrong Liang, andJianhua Ma. Sparse-view x-ray ct reconstruction via total generalized variation regularization. Physics inMedicine & Biology, 59(12):2997, 2014. Albert W Reed, Hyojin Kim, Rushil Anirudh, K Aditya Mohan, Kyle Champley, Jingu Kang, and SurenJayasuriya.Dynamic ct reconstruction from limited views with implicit neural representations andparametric motion fields. In Proceedings of the IEEE/CVF International Conference on Computer Vision,pp. 22582268, 2021. Gabriel Prieto Renieblas, Agustn Turrero Nogus, Alberto Muoz Gonzlez, Nieves Gmez-Leon, andEduardo Guibelalde Del Castillo. Structural similarity index family for image quality assessment inradiological images. Journal of medical imaging, 4(3):035501035501, 2017.",
  "Yang Song, Liyue Shen, Lei Xing, and Stefano Ermon. Solving inverse problems in medical imaging withscore-based generative models. In International Conference on Learning Representations, 2022": "Nitish Srivastava, Geoffrey Hinton, Alex Krizhevsky, Ilya Sutskever, and Ruslan Salakhutdinov. Dropout: asimple way to prevent neural networks from overfitting. The journal of machine learning research, 15(1):19291958, 2014. Yu Sun, Jiaming Liu, Mingyang Xie, Brendt Wohlberg, and Ulugbek S Kamilov. Coil: Coordinate-basedinternal learning for tomographic imaging. IEEE Transactions on Computational Imaging, 7:14001412,2021. Matthew Tancik, Pratul Srinivasan, Ben Mildenhall, Sara Fridovich-Keil, Nithin Raghavan, Utkarsh Singhal,Ravi Ramamoorthi, Jonathan Barron, and Ren Ng. Fourier features let networks learn high frequencyfunctions in low dimensional domains. Advances in Neural Information Processing Systems, 33:75377547,2020. Matthew Tancik, Ben Mildenhall, Terrance Wang, Divi Schmidt, Pratul P Srinivasan, Jonathan T Barron,and Ren Ng. Learned initializations for optimizing coordinate-based neural representations. In Proceedingsof the IEEE/CVF Conference on Computer Vision and Pattern Recognition, pp. 28462855, 2021. Ayush Tewari, Justus Thies, Ben Mildenhall, Pratul Srinivasan, Edgar Tretschk, Wang Yifan, ChristophLassner, Vincent Sitzmann, Ricardo Martin-Brualla, Stephen Lombardi, et al. Advances in neural rendering.In Computer Graphics Forum, volume 41, pp. 703735. Wiley Online Library, 2022. Wim Van Aarle, Willem Jan Palenstijn, Jeroen Cant, Eline Janssens, Folkert Bleichrodt, Andrei Dabravolski,Jan De Beenhouwer, K Joost Batenburg, and Jan Sijbers. Fast and flexible x-ray tomography using theastra toolbox. Optics express, 24(22):2512925147, 2016. FR Verdun, D Racine, JG Ott, MJ Tapiovaara, P Toroi, FO Bochud, WJH Veldkamp, A Schegerer,RW Bouwman, I Hernandez Giron, et al. Image quality in ct: From physical measurements to modelobservers. Physica Medica, 31(8):823843, 2015. Florian Wenzel, Kevin Roth, Bastiaan Veeling, Jakub Swiatkowski, Linh Tran, Stephan Mandt, Jasper Snoek,Tim Salimans, Rodolphe Jenatton, and Sebastian Nowozin. How good is the Bayes posterior in deep neuralnetworks really? In Hal Daum III and Aarti Singh (eds.), Proceedings of the 37th International Conferenceon Machine Learning, volume 119 of Proceedings of Machine Learning Research, pp. 1024810259. PMLR,1318 Jul 2020. Qing Wu, Lixuan Chen, Ce Wang, Hongjiang Wei, S Kevin Zhou, Jingyi Yu, and Yuyao Zhang. Unsupervisedpolychromatic neural representation for ct metal artifact reduction. Advances in Neural InformationProcessing Systems, 36:6960569624, 2023a.",
  "Hao Zhang, Jing Wang, Dong Zeng, Xi Tao, and Jianhua Ma. Regularization strategies in statistical imagereconstruction of low-dose x-ray ct: A review. Medical physics, 45(10):e886e907, 2018a": "Ruoqiao Zhang, Jean-Baptiste Thibault, Charles A Bouman, Ken D Sauer, and Jiang Hsieh. Model-basediterative reconstruction for dual-energy x-ray ct using a joint quadratic likelihood model. IEEE transactionson medical imaging, 33(1):117134, 2013. Zhicheng Zhang, Xiaokun Liang, Xu Dong, Yaoqin Xie, and Guohua Cao. A sparse-view ct reconstructionmethod based on combination of densenet and deconvolution. IEEE transactions on medical imaging, 37(6):14071417, 2018b.",
  "B.1Noise Simulation for CT Reconstructions": "We incorporate noise in our CT simulations by applying Poisson noise to measurements, following theapproach described in (Hendriksen et al., 2020). According to Beer-Lamberts law (Beer, 1852), the photoncount detected I is a function of the initial incoming photon count I0, the absorption factor of the object,and the measurement y0, expressed as:",
  "y = 1 logII0.(23)": "In our experiments, we calibrate the noise level using two parameters: the average absorption and thephoton count I0. For the WalnutCT dataset, we set to 50% and I0 to 5000. For the LungCT dataset, wesimilarly set to 50%, but with a higher photon count of I0 at 20000. This differential setting introducesvarying degrees of noise to the measurements, as illustrated in . The figure showcases how sparsemeasurements inherently challenge CT reconstruction, resulting in blurred images due to insufficient data.The addition of simulated noise further complicates this challenge by adding noise to the already blurredimages from sparse-view reconstructions.",
  "B.2INRWild": "We implement INRWild using the Siren network architecture (Sitzmann et al., 2020). Specifically, the staticcomponent, G, is represented using a standard 8-layer Siren network. In contrast, each of the transientparts, Hwj, is characterized by a more compact 4-layer Siren network following the design from NeRFWild(Martin-Brualla et al., 2021). Each transient part is linked to a unique one-hot vector, which is embedded intoa 16-dimensional transient feature bj. This feature, alongside intermediate features G\\r (C) from the staticnetwork, serves as input for transient modeling. The transient feature bj is optimized during joint training. The optimization process ensures that the static and transient components are jointly optimized to ensuredistinct representations, as articulated in Equation (3). A visual representation of the INRWild structure isprovided in .",
  "B.3INR-based Network Configuration": "In this study, all INR-based methods employ the Siren network (Sitzmann et al., 2020) as their core architecture.For each experimental setup, we consistently use a Siren network with specific dimensions: a depth of 8 andwidth of 128 for the WalnutCT experiments, and a depth of 8 with width 256 for the LungCT and 4DCTexperiments. Position encoding is implemented using Fourier feature embedding (Tancik et al., 2020), withan embedding dimension of 512 for LungCT and 4DCT, and 256 for WalnutCT. Consistently, this embeddedposition is input to the INRs to facilitate density prediction.",
  "B.4Configuration of All Methods": "Individual Reconstruction Methods. For 2D experiments, we employ the FBP method, and for 3Dexperiments, its counterpart, FDK. GPU-accelerated operations, FBP_CUDA for 2D and FDK_CUDA for 3D,are sourced from the Astra-Toolbox (Van Aarle et al., 2016). The iterative method SIRT, specifically theSIRT_CUDA operation, also from the Astra-Toolbox, is configured with 5,000 iterations. INR-based methodsare set to operate for 30,000 iterations. The iteration counts for SIRT and INR-based methods are determinedthrough preliminary tests on a dataset subset to ensure optimal performance. Hyperparameters. We tune the hyperparameters of our method and baselines in the inter-object scenarioand subsequently apply to all experiments. In particular, for the federated averaging approach FedAvg(Kundu et al., 2022), we average individual reconstructions every 100 iterations, amounting to a total of 200averaging iterations, followed by 10,000 individual adaptation iterations using the learned meta initialization.For the meta-learning technique MAML (Tancik et al., 2021), which is rooted in the MAML update policy (Finnet al., 2017), we designate a meta learning phase spanning 10,000 iterations (10 inner steps and 1000 outeriterations) across all measurements. This is succeeded by 20,000 individual adaptation iterations utilizing thelearned meta initialization. Our INR-Bayes undergoes 300 EM loops. For each loop, the E-step iterates 100times to update the posterior approximation. All INR-based models utilize the Adam optimizer Kingma &Ba (2014) with the first moment 0.9 and the second moment 0.999. The learning rate is set to 1 105. Forour method, the additional hyperparameter for the KL divergence term is determined as 1 1014 forWalnutCT and 1 1016 for LungCT, 4DCT. Final Reconstructrion. After training, ours INR-Bayes yields a parameter distribution. Common methodsfor producing the final result based on this distribution include sampling the network parameters multipletimes and averaging the network outputs, or using the mode of the distribution as the network parameters toproduce the result (i.e., maximum a posteriori). In our work, we choose the latter approach, as it empiricallyyields better performance. For the baseline methods, we use the final trained model to produce the finalreconstruction.",
  "CAppendix: Dataset Details": "4DCT. This dataset Castillo et al. (2009), sized 10 136 512 512, contains 136 CT image slices capturedacross 10 respiratory phases of one patient. The main variations across these phases are due to respiratorymovements, such as the lungs expansion and contraction. LungCT. Comprising CT scans from 96 patients Antonelli et al. (2022), its volumes range from 112512512to 636 512 512. Despite inherent similarities representing human lungs, individual scan features canvary significantly. Slices within a volume show a consistent pattern, yet fewer stationary features are sharedbetween them. The dataset comprises scans both with and without tumors. For our experiments, we randomlyselected patients and images without distinguishing between those containing tumors and those without,aiming for a diverse representation of lung CT images.",
  "WalnutCT. This dataset Der Sarkissian et al. (2019) features 42 CT volumes of walnuts, each sized500 501 501": "AluminiumCT. Comprising 25 CT scans of an aluminium alloy tested across various fatigue cycles De Carloet al. (2018), each original scan measures 2160 2560 2560. For computational feasibility, we preprocessthese by averaging every five columns in each detector row, reducing the resolution to 2160 512 512. Thisdataset allows us to explore the structural integrity and detect minute defects within the material underdifferent stress conditions, simulating practical industrial applications.",
  "D.13D Joint Reconstruction": "To assess the real-world viability of our method, we conduct evaluations in a 3D cone-beam CT context,which more closely aligns with practical scenarios. We choose CT volumes from different patients of size1283, ensuring they represent analogous regions of the human body. The projections are simulated with 40angles spanning a full 360 rotation. We conduct experiments on 9 groups of joint reconstructions, with each group jointly reconstructing 10different patients CT volumes, each sized 1283. displays the results. Consistent with the findingsfrom 2D CT experiments, our approach surpasses other comparative methods, substantiating its practicalrelevance. MAML displays slightly inferior performance compared to SingleINR. A potential rationale for thiscould be that, given the augmented data volume, meta-learning might necessitate extended meta-learningiterations to glean a meaningful representation.",
  "D.2Joint Reconstruction on Human Faces": "To offer a deeper insight, we visualize the learned priors across different joint reconstruction techniques. illustrates INRWilds extraction of \"static\" and \"transient\" components from varying faces. Notably,INRWild captures a generalized \"face\"-like static component. However, due to the significant disparitiesamong face images, this generalized extraction does not significantly enhance individual reconstructions. showcases the learned priors from FedAvg, MAML, and our approach INR-Bayes. Both FedAvg andINR-Bayes succeed in deriving an interpretable prior. However, the face-like meta initialization does notdirectly benefit reconstruction in the case of FedAvg. In contrast, MAML struggles to capture a face-like priorduring its preliminary phase, but obtains final reconstructions better than FedAvg. Our INR-Bayes usually",
  "D.4Intra-object Joint Reconstruction": "In addition to the experiments represented by , we evaluated how the number of nodes influences theperformance of various methods, in the intra-object joint reconstruction experiments. As shown in ,our method consistently delivers superior performance compared to other methods across a range of nodecounts. MAML shows strong results when the node count is between 5 and 25, but experiences a decline inperformance, eventually matching that of FedAvg when the node count reaches 40. This drop indicatesthat MAML might struggle to capture the shared features when many nodes are participating in the jointreconstruction. Contrary to the inter-object configuration (as illustrated in ), in this experiment ourmethod does not benefit from an increase in the number of joint nodes. This lack of improvement could beattributed to the possibility that the statistical regularities are sufficient when observing just a few scanningslices in the intra-object setting. Number of Nodes PSNR / dB INR-BayesMAMLFedAvgSingleINRSIRTFBP : Performance comparison with varying node numbers in intra-object LungCT setup. Individualreconstruction methods are presented as references. Performance stability across all methods with increasingnode numbers suggests that even a limited number of intra-object slices adequately capture statistical trends. We also present visualizations of learned priors from various joint reconstruction methods applied in intra-object experiments on LungCT dataset. depicts the learned static and transient components ofINRWild. Notably, in scenarios where images markedly vary from one another, extracting static componentsstill seems feasible but not necessarily beneficial to the reconstruction process, since the static componentdoes not constitute a significant portion of the overall representation. Conversely, when observing other joint reconstruction methods in , it is evident that INR-Bayes,MAML and FedAvg ascertain a reasonable latent or meta representation. Despite variations in images, theintrinsic consistency stemming from the same patient results in a discernible and coherent trend. Thisinherent trend is adeptly captured by these joint reconstruction methodologies.",
  "D.5Joint Reconstruction across Temporal Phases in 4DCT": "reveals that INRWild effectively distinguishes static and transient components in the 4DCT setting.Compared to other settings, INRWilds performance on 4DCT is closer to other INR-based methods (see). However, it still lags behind SingleINR, underscoring the limited utility of static-transient tactics inenhancing individual reconstruction quality. demonstrates that other joint reconstruction methodsalso proficiently disentangle the inherent prior. Interestingly, in these contexts, FedAvg proves more beneficialthan MAML, while our proposed method continues to surpass all methods in this scenario.",
  "D.6Joint Reconstructions with Varied Object and Slice Configurations": "To understand how different joint reconstruction configurations impact reconstruction quality, we examinefour distinct setups: inter-object (10 objects, each contributing one slice), intra-object (one object contributingten slices), and two intermediate configurations (two objects with five slices each, and five objects with twoslices each). We conducted ten sets of experiments, with each set involving the joint reconstruction of thesame ten slices across these configurations. presents the average PSNR and SSIM values obtained from these ten experimental groups. Theresults indicate that while the PSNR and SSIM values are generally consistent across different configurations,the intermediate configurations slightly outperform the others in terms of average metrics. illustrates the learned priors from one exemplary set of reconstructions. Visually, the distinctionsamong the different configurations are minimal. The intra-object configuration (110) effectively capturesthe internal variations within a single object, aligning with our observation that a few intra-object slices aresufficient to model internal object changes. On the other hand, the 25 and 52 configurations, along withthe inter-object (101) setup, depict priors that appear more distinct from the target slice, reflecting theinfluence of multiple objects in the joint reconstruction process. Notably, the 25 and 52 configurationsexhibit slightly higher PSNR and SSIM values, suggesting that an optimal balance between similarity anddiversity among jointly reconstructed objects can enhance the reconstruction quality of a specific target.",
  "D.7Computation Cost Analysis": "In , we present a comparative analysis of the computational costs associated with different reconstructionmethods. The experiment setting is aligned with the inter-object configuration on WalnutCT dataset in. These assessments are performed under the same conditions with a 40GB A100 GPU, to ensureconsistency in our evaluation. Each method undergoes 30,000 iterations and employes an identical Sirennetwork architecture, characterized by a depth of 8, width of 128, and positional embedding dimension of 256.",
  "Time (mins)17.217.217.222.7": ": Comparison of average computation cost per node on joint reconstruction of 10 nodes.Thereconstructed image size is 501 501. For reference, FBP requires 206 MiB of GPU memory and completesin less than 0.1 seconds, whereas SIRT utilizes 154 MiB of GPU memory and takes 0.8 seconds. As indicated in the , the GPU memory usage across all INR-based methods was relatively similar.SingleINR, FedAvg and MAML exhibit the same shortest computation time. Our method, INR-Bayes, shows aslightly increased computation time, approximately 5 minutes longer than the others. This less than 15%increase over SingleINR, FedAvg and MAML in time is attributed to the MC sampling procedure ( 9%) andadditional KL divergence term ( 6%) in INR-Bayes. However, considering the enhanced reconstructionquality and robustness achieved, this additional time investment can be justified. Impact of Network Size on INRBayes. To understand the computation efficiency and performancetrade-off, we further investigate the reconstruction quality of our method with varying configurations of thenetwork size. As shown in , smaller networks lead to reduced performance but also lower computationalrequirements, presenting a practical trade-off between efficiency and quality. It is worth noting that evenwith the smallest network, our method largely outperforms SIRT. While the reconstruction time using thesmallest network is reduced to 10 minutes, which could be affordable in the most practical settings.",
  "D.8Comparison with Nerp": "The method Nerp, introduced by Shen et al. (2022), initially trains an INR network using high-fidelity datathrough regression. This pre-trained network is subsequently utilized to initialize the reconstruction of anew object with sparse measurements. A notable drawback of this method is its dependence on the newobjects representations being highly similar to that of the high-fidelity training object. When this similarityis absent, the initial training could hinder rather than help the reconstruction process, potentially yieldingworse results than even a random initialization. To demonstrate this, we carried out experiments on the 4DCT dataset with two different setups for Nerp. Inthe Match configuration, Nerp is provided with the ground truth of one phase at a specific slice and taskedto reconstruct the remaining nine phases at that slice. In contrast, the Unmatch configuration uses theground truth from a random slice. Our INR-Bayes approach, on the other hand, performs a simultaneousreconstruction of all nine phases without any access to ground truth images. As illustrates, the performance of Nerp is conditional, excelling in PSNR when ground truth data ismatched but faltering otherwise. While operating without access to additional information, our INR-Bayesachieves the best performance in SSIM. Given the practical challenges in obtaining matched ground-truthdata for unscanned objects, our method exhibits greater utility and applicability.",
  "D.9Applying to Unseen Data using Different Learned Priors": "To investigate the influence of varying priors on the reconstruction quality for new, unseen patients, weconducted an additional experiment with our INR-Bayes. We selected 10 sets of priors, each derived from agroup of 10 different patients. These priors are then employed to guide the reconstruction of the same unseenpatient. showcases the reconstructed images and their corresponding priors, represented by an INRthat is parameterized with the mean of the prior distribution. The accompanying PSNR and SSIM values,indicated at the top left and bottom left of each image, demonstrate modest deviation across different priors.Notably, no model collapse occurs despite the obvious visual difference in the prior means. This observationsuggests that our method is stable and can adaptively extract useful information from various priors whenapplied to unseen data. It is important to clarify that the prior of our method, as depicted in , uses the mean of the priordistribution to parameterize an INR. However, this representation is an incomplete portrayal of the priordistributions full characteristics, as the latent variables include mean and variance estimations. The varianceassociated with our methods estimates can contribute to the adaptive and effective utilization of the priordistribution. This aspect of our model underscores its capability to leverage the entire prior distribution forstable performance.",
  "D.10Reconstruction Uncertainty": "We employ a Bayesian framework to identify common patterns among jointly reconstructed objects. While theprimary focus of this study is not on uncertainty quantification (Gal & Ghahramani, 2016; Angelopoulos et al.,2022), we demonstrate how INR-Bayes can facilitate this aspect within CT reconstructions. During training,each node approximates the posterior distribution of its weights as a Gaussian distribution. This approachallows us to sample the network parameters multiple times after training to quantify uncertainty. To illustratethis, we sample the network parameters ten times to generate ten distinct reconstructions in an intra-object"
}