{
  "Abstract": "In online convex optimization, some efficient algorithms have been designed for each of theindividual classes of objective functions, e.g., convex, strongly convex, and exp-concave.However, existing regret analyses, including those of universal algorithms, are limited tocases in which the objective functions in all rounds belong to the same class and cannot beapplied to cases in which the property of objective functions may change in each time step.This paper introduces a novel approach to address such cases, proposing a new regime weterm as contaminated online convex optimization. For the contaminated case, we demon-strate that the regret is lower bounded by (log T + k). Here, k signifies the level ofcontamination in the objective functions. We also demonstrate that the regret is boundedby O(log T + k log T) when universal algorithms are used. When our proposed algorithmswith additional information are employed, the regret is bounded by O(log T +",
  "Introduction": "Online convex optimization (OCO) is an optimization framework in which convex objective function changesfor each time step t {1, 2, . . . , T}. OCO has a lot of applications such as prediction from expert advice(Littlestone & Warmuth, 1994; Arora et al., 2012), spam filtering (Hazan, 2016), shortest paths (Awerbuch &Kleinberg, 2004), portfolio selection (Cover, 1991; Hazan et al., 2006), and recommendation systems (Hazan& Kale, 2012). The performance of the OCO algorithm is compared by regret (defined in ). Asshown in , it is already known that sublinear regret can be achieved for each function class, suchas convex, strongly convex, and exp-concave, and the bound depends on the function class. In addition,these upper bounds coincide with lower bounds, so these are optimal. However, these optimal algorithmsare applicable to one specific function class. Therefore, we need prior knowledge about the function class towhich the objective functions belong. To solve this problem, many universal algorithms that work well for multiple function classes by one algorithmhave been proposed (Hazan et al., 2007; Van Erven & Koolen, 2016; Wang et al., 2020; Zhang et al., 2022;Yan et al., 2024). For example, the MetaGrad algorithm proposed by Van Erven & Koolen (2016) achievesan O( T)-regret for any sequence of convex objective functions and an O(log T)-regret if all the objectivefunctions are exp-concave. Universal algorithms are useful in that they can be used without prior knowledgeabout the objective functions. Some universal algorithms are introduced in Appendix A.3. A notable limitation of the previous regret analyses about universal algorithms is that they apply onlyto cases where all the objective functions f1, f2, . . . , fT belong to the same function class. Therefore, forexample, if some objective functions in a limited number of rounds are not strongly convex and if the other",
  "Our Contribution": "In this study, we consider the situation in which the function class of the objective ft may change in each timestep t. We call this situation contaminated OCO. More specifically, in k-contaminated OCO with a functionclass F, we suppose that the objective function ft does not necessarily belong to the desired function class F(e.g., exp-concave or strongly convex functions) in k rounds out of the total T rounds. introducesits formal definition and examples. This class of OCO problems can be interpreted as an intermediate settingbetween general OCO problems and restricted OCO problems with F (F-OCOs). Intuitively, the parameterk [0, T] represents the magnitude of the impurity in the sequence of the objective functions, and measureshow close the problems are to F-OCOs; k = 0 and k = T respectively correspond to F-OCO and generalOCO. The contribution of this study can be summarized as follows: (i) We introduce contaminated OCO, whichcaptures the situations in which the class of the objective functions may change over different rounds. (ii)We find that the Online Newton Step, one of the optimal algorithms for exp-concave functions, does notalways work well in contaminated OCO, as discussed in .1. (iii) We present regret lower boundsfor contaminated OCO in .2. (iv) We show that some existing universal algorithms achieve betterregret bounds than ONS for contaminated OCO, which details are given in . (v) We propose analgorithm that attains the optimal regret bounds under the additional assumption that information of theclass of the previous objective function is accessible in . Regret bounds of contaminated cases compared to existing bounds are shown in . The new upperbounds contain bounds in existing studies for exp-concave functions and strongly convex functions as aparticular case (k = 0). Additionally, the new lower bounds generalize bounds in existing studies for convexfunctions, exp-concave functions, and strongly convex functions. In cases where only gradient information isavailable, there is a multiplicative gap of O(log T) between the second terms of the upper bounds and thelower bounds. This gap is eliminated when the information of the class of the previous objective function isavailable.",
  "Published in Transactions on Machine Learning Research (10/2024)": "proposed algorithms and some lower bounds of regret. While we successfully obtained optimal upper boundswith additional information of the function class of the last revealed objective function, there are still gapsof O(d log T) or O(log T) between the upper bound and the lower bound without additional information.One natural future research direction is to fill these gaps. We believe there is room for improvement in theupper bounds and the lower bounds seem tight. Indeed, lower bounds in this study interpolate well betweentight bounds for general OCO and for (restricted) F-OCO.",
  "Related Work": "In the context of online learning, adaptive algorithms (Orabona, 2019) have been extensively studied due totheir practical usefulness. These algorithms work well by automatically exploiting the intrinsic propertiesof the sequence of objective functions and do not require parameter tuning based on prior knowledge of theobjective function. For example, AdaGrad (McMahan & Streeter, 2010; Duchi et al., 2011) is probably one ofthe best-known adaptive algorithms, which automatically adapts to the magnitude of the gradients. Studieson universal algorithms (Hazan et al., 2007; Van Erven & Koolen, 2016; Wang et al., 2020; Zhang et al.,2022; Yan et al., 2024), which work well for several different function classes, can also be positioned withinthese research trends. Our study shows that some of these universal algorithms have further adaptability,i.e., nearly tight regret bounds for contaminated settings. van Erven et al. (2021) has explored a similar setting to ours, focusing on robustness to outliers. They regardrounds with larger gradient norms than some threshold as outliers and denote the number of outliers as k,whose definition differs from ours. They have defined regret only for rounds that are not outliers, terming itrobust regret, and have shown that the additional O(k) term is inevitable in bounds on robust regret. Studies on best-of-both-worlds (BOBW) bandit algorithms (Bubeck & Slivkins, 2012) and on stochasticbandits with adversarial corruptions (Lykouris et al., 2018; Gupta et al., 2019) are also related to ourstudy. BOBW algorithms are designed to achieve (nearly) optimal performance both for stochastic andadversarial environments, e.g., O(log T)-regret for stochastic and O( T)-regret for adversarial environments,respectively. Stochastic bandits with adversarial corruptions are problems for intermediate environmentsbetween stochastic and adversarial ones, in which the magnitude of adversarial components is measured bymeans of the corruption level parameter C 0. A BOBW algorithm by Bubeck & Slivkins (2012) hasshown to have a regret bound of O(log T + C log T) as well for stochastic environments with adversarialcorruptions, which is also nearly tight (Ito, 2021). In the proof of such an upper bound, an approach referredto as the self-bounding technique (Gaillard et al., 2014; Wei & Luo, 2018) is used, which leads to improvedguarantees via some regret upper bounds that include the regret itself. Similar proof techniques are used inour study as well.",
  "t=1ft(x)": "Regret is the difference between the cumulative loss of the learner and that of the best choice in hindsight. Theregret can be logarithmic if the objective functions are -strongly convex, i.e., f(y) f(x)+f(x), y x+2 x y2 for all x, y X, or -exp-concave, i.e., exp(f(x)) is concave on X.Remark 3.1. The type of information about ft that needs to be accessed varies depending on the algorithm.Universal algorithms only utilize gradient information, while the algorithm presented in requiresadditional information besides the gradient, such as strong convexity and exp-concavity. The lower boundsdiscussed in .2 are applicable to arbitrary algorithms with complete access to full information aboutthe objective functions.",
  "In this subsection, we define contaminated OCO and introduce examples that belong to this problem class.The definition is below": "Definition 3.6. For some function class F, a sequence of convex functions (f1, f2, . . . , fT ) belongs to k-contaminated F if there exists a set of indices I [T] such that |I| = k and ft F holds for all t [T]\\I. For example, if functions other than k functions of them are -exp-concave, we call the functions k-contaminated -exp-concave. And especially for OCO problems, if the objective functions are contaminated,we call them contaminated OCO. The following two examples are functions whose function class varies with time step.These examplesmotivate this study.Example 3.7. (Online least mean square regressions) Consider the situation where a batch of input-outputdata (at,i, bt,i) Rd R (i {1, 2, . . . , n}) is given in each round t and we want to estimate x whichenable to predict b a, x.This can be regarded as an OCO problem whose objective functions areft(x) := (1/n) ni=1(at,i, x bt,i)2. These functions are t-strongly convex, where t is the minimumeigenvalue of the matrix (2/n) ni=1 at,iat,i.Let k() := |{t [T] | t < }| for any > 0.Then(f1, f2, . . . , fT ) is k()-contaminated -strongly convex.",
  "Before stating the lower bound, we introduce the following theorem, which is essential in deriving some lowerbounds of contaminated cases": "Theorem 4.2. Let F be an arbitrary function class. Suppose that functions g1, g2 are the functions suchthat (g1(T)) and (g2(T)) are lower bounds for function class F and convex functions, respectively, forsome OCO algorithm. If a sequence of objective functions belongs to k-contaminated F, then regret in theworst case is (g1(T) + g2(k)) for the OCO algorithms.",
  "Remark 4.3. In Theorem 4.2, if the lower bounds (g1(T)) and (g2(T)) are for all OCO algorithms, thenthe lower bound (g1(T) + g2(k)) is also for all OCO algorithms": "To derive this lower bound, we use the following two instances; one is the instance used to prove lower boundRT = (g1(T)) for function class F, and the other is the instance used to prove Rk = (g2(k)) for convexobjective functions. By considering the instance that these instances realize with probability 1/2, we canconstruct an instance that satisfiesE[RT ] = (g1(T) + g2(k)),",
  "for all OCO algorithms. A detailed proof of this proposition is postponed to Appendix B.3": "Theorem 4.2 implies that, in contaminated cases, we can derive interpolating lower bounds of regret. Thelower bound obtained from this theorem is (g1(T)) if k T, and (g2(T)) if k = T. Since the contaminatedcase can be interpreted as an intermediate regime between restricted F-OCO and general OCO, this resultwould seen as reasonable. This lower bound applies not only to ONS but also to arbitrary algorithms.",
  "Corollary 4.6. If a sequence of objective functions (f1, f2, . . . , fT ) is k-contaminated -exp-concave, regretin worst case is ((d/) log T + k), for ONS": "This proposition shows that the regret analysis in Proposition 4.1 is strict. While ONS does not work wellfor contaminated OCO, universal algorithms exhibit more robust performance. In , we analyzesome universal algorithms on this point.Remark 4.7. For the 1-dimension instance above, ONS can also be regarded as OGD (Algorithm 2 inAppendix A.1) with (1/t) stepsize. This implies that we can show that OGD with (1/t) stepsize canincur (T) regret in the worst case. Therefore, for k-contaminated strongly convex functions, regret in worstcase is ((1/) log T + k), for OGD with (1/t) stepsize.",
  "for any x X": "Though Theorem 5.2 is derived only for x argminxXTt=1 ft(x) in the original paper by Wang et al.(2020), the proof is also valid even when x is any vector in X, so we rewrite the statement in this form. Theproof of this generalization is provided in Appendix B.5. Further explanations of universal algorithms are inAppendix A.3. Concerning the regret bound of contaminated exp-concavity, the following theorem holds. This theoremsassumption is satisfied when using MetaGrad or Maler, and the result for them is described after the proofof this theorem.Theorem 5.3. Let t be a constant such that ft is t-exp-concave (if ft is not exp-concave, then t is 0)for each t. Suppose that",
  "From this inequality and RxT RxT , Theorem 5.3 follows": "The core of this proof is inequality (3), which can be regarded as a quadratic inequality.Solving thisinequality enables us to obtain a regret upper bound for contaminated cases from a regret upper bound fornon-contaminated cases. Theorem 5.3 combined with Theorem 5.1, Theorem 5.2, and Theorem A.1 in the appendix gives upper boundsfor universal algorithms; MetaGrad, Maler, and USC. The following corollary shows that, even if exp-concaveobjective functions are k-contaminated, regret can be bounded by an additional term of O(kd log T). Thisregret bound is better than ONSs in the parameter k.",
  "This theorem can be derived in almost the same manner as the proof of Theorem 5.3, other than using thedefinition of strong convexity and k. A more detailed proof is in Appendix B.8": "Theorem 5.6 combined with Theorem 5.1, Theorem 5.2, and Theorem A.1 in the appendix gives upperbounds for universal algorithms; MetaGrad, Maler, and USC. This corollary shows that, even if stronglyconvex objective functions are k-contaminated, regret can be bounded by an additional term of O(k log T)if Maler or USC with Maler as an expert algorithm is used.",
  "where d is d in the case of MetaGrad and 1 in the case of the other two algorithms": "This corollary can be derived from Theorem 5.6 in almost the same manner as the proof of Corollary 5.5. Amore detailed proof is in Appendix B.9 and Appendix B.10.Remark 5.8. If (f1, f2, . . . , fT ) is k1-contaminated -exp-concave and k2-contaminated -strongly convex,then we have two regret upper bounds:",
  "k2 d log T,": "from Corollary 5.7. Here, strongly convex functions are also exp-concave functions from Lemma 3.5. There-fore, if /G2 , then k1 k2.Remark 5.9. Note that the universal algorithms analyzed in this section do not require additional informationother than the gradient, which is a valuable property in practical use. However, comparing lower bounds inCorollary 4.8 and Corollary 4.9 with upper bounds in Corollary 5.5 and Corollary 5.7 respectively, there aregaps between them. This implies that our upper bounds in this section or lower bounds in .2 mightnot be tight. As we will discuss in the next section, this gap can be removed if additional information onfunction classes are available while it is not always the case in real-world applications.",
  "Regret Upper Bounds Given Additional Information": "In this section, we propose a method that achieves better bounds than those of universal algorithms discussedin the previous section under the condition that the information of the class of the last objective function isrevealed. The experimental performance of this method is shown in Appendix C. We denote S1 := {t [T] | ft is -strongly convex}, S2 := {t [T]\\S1 | ft is -exp-concave}, U :=[T]\\(S1 S2), and k := |U|. The algorithm using additional information is shown in Algorithm 1 (Id is ddimensional identity matrix, and 2A means A, ). This algorithm is a generalization of OGD and ONS.Indeed, (S1, S2, U) = ([T], , ) gives normal OGD and (S1, S2, U) = (, [T], ) gives normal ONS.",
  "The key point of Theorem 6.2 is that the second term of the regret upper bound is proportional to": "k.Compared with Corollary 5.5, we can see that additional information improves the regret upper bound.Remark 6.3. Algorithm 1 is written in a general form, and it is better to set S2 = in the contaminatedstrongly convex case.This is because Algorithm 1 needs O(d3) computation to calculate A1tif S2 isnonempty. When S1 = or S2 = , the regret bound in Theorem 6.2 is reduced to O((d/) log T + GD",
  "k) respectively": "Remark 6.4. As mentioned in Remark 5.9, the algorithms analyzed in this section need information that isnot always available in the real world. Therefore, the improved regret bound in Theorem 6.2 is theoretical,and regret bounds for universal algorithms explained in are more important in real applications.However, the algorithm in this section has the notable advantage that its regret upper bounds match thelower bounds.",
  "A.1OGD Algorithm": "In OCO, one of the most fundamental algorithms is online gradient descent (OGD), which is shown inAlgorithm 2. An action xt is updated by using the gradient of the point and projected onto the feasibleregion X in each step. If all the objective functions are convex and learning rates are set (1/",
  "A.2ONS Algorithm": "If all the objective functions are -exp-concave, ONS, shown in Algorithm 3, works well. This is an algorithmproposed by Hazan et al. (2006) as an online version of the offline Newton method. This algorithm needsparameters , > 0, and if = (1/2) min{1/(GD), } and = 1/(2D2), then the regret is bounded byO((d/) log T).",
  "A.3Universal Algorithms": "In real-world applications, it may be unknown which function class the objective functions belong to. Tocope with such cases, many universal algorithms have been developed. Most universal algorithms are con-structed with two types of algorithms: a meta-algorithm and expert algorithms. Each expert algorithm isan online learning algorithm and not always universal. In each time step, expert algorithms update xit, anda meta-algorithm integrates these outputs in some way, such as a convex combination. In the following,we explain three universal algorithms: multiple eta gradient algorithm (MetaGrad) (Van Erven & Koolen,2016), multiple sub-algorithms and learning rates (Maler) (Wang et al., 2020), and universal strategy foronline convex optimization (USC) (Zhang et al., 2022). First, MetaGrad is an algorithm with multiple experts, each with a different parameter as shown inAlgorithm 4 and 5. In contrast to nonuniversal algorithms that need to set parameters beforehand dependingon the property of objective functions, MetaGrad sets multiple so that users do not need prior knowledge.It is known that MetaGrad achieves O(T log log T), O((d/) log T) and O((d/) log T) regret bounds forconvex, -strongly convex and -exp-concave objective functions respectively. Second, Maler is an algorithm with three types of expert algorithms: a convex expert algorithm, stronglyconvex expert algorithms, and exp-concave expert algorithms, as shown in Algorithm 6 to 9.They aresimilar to OGD with (1/ t) stepsize, OGD with (1/t) stepsize, and ONS, respectively. Expert algorithmscontain multiple strongly convex expert algorithms and multiple exp-concave expert algorithms with multipleparameters like MetaGrad. It is known that Maler achieves O(",
  ": end for": "Finally, USC is an algorithm with many expert algorithms, as shown in Algorithm 10. In contrast to Maler,which contains OGD and ONS as expert algorithms, USC contains more expert algorithms. To integratemany experts, USC utilizes Adapt-ML-Prod (Gaillard et al., 2014) as a meta-algorithm, which realizesuniversal regret bound. Concerning the regret bound of USC, there is a theorem as follows.",
  "where = O(log log T)": "In USC, expert algorithms are chosen so that |E| = O(log T) holds. This theorem holds without assumingexp-concavity or strong convexity. In addition, it is known that USC achieves O(LT log log T), O((1/) (min{log LT , log VT } + log log T)) and O((1/)(d min{log LT , log VT } + log log T)) regret bounds for convex,-strongly convex and -exp-concave objective functions respectively, where LT := minxXTt=1 ft(x) =O(T), VT := Tt=1 maxxX ft(x) ft1(x)22 = O(T).",
  "4kGD,": "where t is defined in the same way as defined in Theorem 5.3. The first inequality is from Lemma 3.4. Inthe last inequality, the first term is bounded by (2d/) log T because of the proof of ONSs regret bound byHazan (2016). The second term is bounded by (1/4)kGD from 1/(2GD) by definition of .",
  "This subsection presents the proof of Theorem 4.2": "Proof. Let I1 and I2 be instances used to prove lower bound RT = (g1(T)) for function class F andRk = (g2(k)) for convex objective functions, respectively, and fi,t (i = 1, 2) be objective functions of Ii attime step t, and Xi be sets which decision variables of Ii belong to. Here, take a set X so that there existsurjections i : X Xi. For this X, let I1 be an instance whose objective function at time step t is f1,t 1and I2 be an instance whose objective function at time step t is f2,t 2 if t k, and some function in Fwhose minimizer is the same as the minimizer of kt=1 f2,t otherwise. For these instances, consider the casethat instances I1 and I2 realize with probability 1/2. In this case, the expectation of regret satisfies",
  ",": "though they treated this term as 0. Combining these relationships, we get inequality (15). This mistakeseems to be a mere typo since the regret bound in their paper coincides with the result derived from theinequality (15).Lemma B.4. (Wang et al., 2020) For every grid point and any x X, we have",
  "In this section, we explain experimental results. We compare the performances of 5 OCO algorithms; OGDwith stepsizes t = D/(G": "t), ONS, MetaGrad, Algorithm 1 with S1 = (Con-ONS), and Algorithm 1with S2 = (Con-OGD). We include OGD, ONS, and MetaGrad because OGD and ONS are famous OCOalgorithms, and MetaGrad is one of the universal algorithms. All the experiments are implemented in Python3.9.2 on a MacBook Air whose processor is 1.8 GHz dual-core Intel Core i5 and memory is 8GB.",
  "We compare the performances of 4 OCO algorithms: OGD, ONS, MetaGrad, and Con-ONS. The parametersof ONS are set as = 0.005 and = 1/(2D2) = 40000": "The time variation of regret and xt is shown in . In the graphs presented in this paper, the errorbars represent the magnitude of the standard deviation. Standard deviations in the graphs are large becausecontamination causes fluctuation in the sequence of solutions.Only points where t is a multiple of 25are plotted to view the graph easily. The left graph shows that the regrets of all methods are sublinear.MetaGrad and ONS perform particularly well, followed by Con-ONS. From the right graph, we can confirmthat xt of all methods converge to the optimal solution quickly. OGD seems influenced by contamination alittle stronger than other methods.",
  "xt I,12(x 1)2otherwise,": "where I [T] is chosen uniformly at random under the condition that |I| = k.(f1, f2, . . . , fT ) is k-contaminated 1-strongly convex and the minimum value of Tt=1 ft is (2kT 3k2)/(2T 2k) if 2k < T.We repeat this numerical experiment in 100 different random seeds and calculate their mean and standarddeviation. Other parameters are shown in .",
  "i=1(at,i, x bt,i)2,": "which is exemplified in Example 3.7. In this experiment, each component of the vector at,i is taken from auniform distribution on independently. We set X = d and assume there exists an optimal solutionx which is taken from a uniform distribution on X, i.e., we take bt,i = at,i, x. We set k firstly andcompute thresholds and based on k, though this is impossible in real applications. Parameters G, , are calculated for each at,i and bt,i, e.g., G 429, 0.0969, and 5.28 107 for some sequence. Theparameters of ONS are set as described in Section A.2. Other parameters are shown in . The time variation of regret and xt is shown in . The performances of OGD, Con-OGD, andCon-ONS are almost the same in this experiment. The left graph shows that OGDs, MetaGrads, and ourproposed methods regrets are sublinear and consistent with the theoretical results. Though this is out ofthe graph, ONSs regret is almost linear even if we take T = 10000. From the right graph, we can confirmthat xt of OGD, MetaGrad, and proposed methods converge to some point quickly, and that of ONS doesnot change so much. The poor performance of ONS is because is too small to take large enough stepsizes.This result shows the vulnerability of ONS."
}