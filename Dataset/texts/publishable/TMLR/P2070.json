{
  "Abstract": "In this study, we undertake a reproducibility analysis of \"Learning Fair Graph Representa-tions Via Automated Data Augmentations\" by Ling et al. (2022). We assess the validityof the original claims focused on node classification tasks and explore the performance ofthe Graphair framework in link prediction tasks.Our investigation reveals that we canpartially reproduce one of the original three claims and fully substantiate the other two.Additionally, we broaden the application of Graphair from node classification to link pre-diction across various datasets. Our findings indicate that, while Graphair demonstratesa comparable fairness-accuracy trade-off to baseline models for mixed dyadic-level fairness,it has a superior trade-off for subgroup dyadic-level fairness.These findings underscoreGraphairs potential for wider adoption in graph-based learning.Our code base can befound on GitHub at",
  "Introduction": "Graph Neural Networks (GNNs) have become increasingly popular for their exceptional performance invarious applications (Hamaguchi et al., 2017; Liu et al., 2022; Han et al., 2022a). A key application areais graph representation learning (Grover & Leskovec, 2016; Hamilton, 2020; Han et al., 2022b), where asignificant concern is the potential for GNNs to inherit or amplify biases present in the graph representationtraining data. This can lead to discriminatory model behavior (Dai & Wang, 2022). To address this issue,Ling et al. (2022) introduced Graphair, an automated data augmentation technique aimed at learning fairgraph representations without maintaining biases from the training data. This work evaluates the main claims made by Ling et al. (2022), which were based solely on the performance ofthe framework in node classification tasks. We expand our evaluation by conducting additional experimentsto assess the adaptability and generalizability of Graphair through its application to a different downstreamtask, namely, link prediction. This approach allows us to further test the performance and fairness of theembeddings.",
  "For this purpose, we apply Graphair to new real-world datasets, adapting certain aspects of the frameworkand fairness metrics to suit link prediction. Our contributions are summarized as follows:": "We replicate the original experiments to assess the reproducibility of the primary claims. We findthat one of the three claims made by the original authors was partially reproducible, while theremaining claims are fully verified. We adapt the Graphair framework for link prediction on various real-world datasets, which requiredmodifications to both the framework and the fairness metrics. These adjustments provided valuableinsights into Graphairs adaptability and generalizability to another downstream task. Our findingssuggest that Graphair achieves a superior trade-off in one of the fairness metrics used for this task.",
  "Scope of reproducibility": "The original paper Learning Fair Graph Representations Via Automated Data Augmentations by Ling et al.(2022) introduces Graphair, an innovative automated graph augmentation method for fair graph represen-tation learning. This approach stands out from prior methods (Luo et al., 2022; Zhao et al., 2022; Agarwalet al., 2021) by utilizing a dynamic and automated model to generate a new, fairer version of the originalgraph, aiming to balance fairness and informativeness (Ling et al., 2022). In this work, we study the reproducibility of this paper. Besides examining the three main claims, we alsoassess the adaptability and effectiveness of Graphair in a different context, namely link prediction. Thisextension tests the frameworks ability to maintain fairness and informativeness in a different downstreamtasks. We will test this on a variety of datasets. The claims and our extension are as follows: Claim 1: Graphair consistently outperforms state-of-the-art baselines in node classification tasks forreal-world graph datasets. Our extension evaluates whether this superior performance extends tolink prediction tasks as well.",
  "Graphair": "The Graphair framework introduces a novel approach to graph augmentation, focusing on the dual objec-tives of maintaining information richness and ensuring fairness. It incorporates a model g, which adeptlytransforms an input graph G = {A, X, S}, where A represents the adjacency matrix, X the node features,and S the sensitive attributes, into an augmented counterpart G = {A, X, S}. This transformation uti-lizes two main operations: TA for adjusting the adjacency matrix A and TX for masking node featuresX. A GNN-based encoder genc precedes these transformations, tasked with extracting deep embeddings toinform these operations. The resulting augmented graph G is designed to capture the core structural andfeature-based elements of the original graph G, while simultaneously keeping fairness principles to preventthe propagation of sensitive attribute information. This objective is achieved by training an adversarialmodel and using contrastive loss to optimize G. An overview of the Graphair framework is presented in in Appendix A.1.",
  "Adversarial Training for Fairness": "To ensure the fairness of the augmented graph, the model employs an adversarial training strategy. Theadversarial model k learns to predict sensitive attributes S from the graphs features. Simultaneously, therepresentation encoder f and augmentation model g are optimized to minimize the predictive capabilityof the adversarial model, effectively removing biases from the augmented graph.The primary goal ofadversarial training is to guide the encoder in generating representations that are free from sensitive attributeinformation. This optimization can be formally defined as follows:",
  "Contrastive Learning for Informativeness": "The model employs contrastive learning to enhance the informativeness of the augmented graphs.Thismethod focuses on ensuring that the node representations between the original graph hi and the augmentedgraph hi maintain a high degree of similarity, thereby preserving key information. The positive pair in thiscontext is defined as any pair (hi, hi), where hi is the node representation in the original graph and hi is thecorresponding representation in the augmented graph.",
  "Integrated Training Objective": "By emphasizing informativeness and fairness properties, Graphair seeks to produce augmented graphs thatare less susceptible to bias. This approach contributes to fairer graph representation learning while preservingthe valuable information contained in the data. The overall training process is described as the followingmin-max optimization procedure, where , , and are hyperparameters that balance the different losscomponents:",
  "Datasets": "To replicate the main claims, we use the same datasets as the original paper by Ling et al. (2022), whichinclude specific dataset splits and sensitive and target attributes. We employ three real-world graph datasets:NBA1, containing player statistics, and two subsets of the Pokec social network from Slovakia, namely Pokec-n and Pokec-z (Dai & Wang, 2021). The specifics of these datasets are summarized in . For the link prediction task, we utilize well-established benchmark datasets in this domain: Cora, Citeseer,and Pubmed (Spinelli et al., 2021; Chen et al., 2022; Current et al., 2022; Li et al., 2021). These datasetsfeature scientific publications as nodes with bag-of-words vectors of abstracts as node features.Edgesrepresent citation links between publications. Notably, these datasets possess a broader range of featurescompared to those used by Ling et al. (2022) and have a larger set of possible sensitive attributes |S|. Fulldetails are provided in .",
  "Experimental Setup": "We obtain the models codebase from the DIG library, more specifically, from the FairGraph module2.To enhance reproducibility, we employ complete seeding across all operations, which was missing in someoperations of the original code. A key difference in the experimental setup between the one reported by theoriginal authors and ours is that we conducted a 10,000-epoch grid search for the Pokec dataset, insteadof the 500-epoch grid search initially reported by (Ling et al., 2022). This modification was recommendedby the original authors to enhance reproducibility. We refer to the subsection A.4 for more details, wherewe show that a 500-epoch search does not yield optimal results for the Pokec datasets, but higher epochsimprove performance in accuracy and fairness. To verify Claims 1 and 2, we follow the procedure describedby Ling et al. (2022). For Claim 3, due to memory constraints, we compute the homophily and Spearmancorrelation values for the Pokec datasets on a mini-batch instead of the entire graphs. Aside from this, weadhere to the same procedures for this claim as well.",
  "Link Prediction": "In our study, we extend the scope of the original work by performing a different downstream task, namelylink prediction. We implement several modifications to adjust the Graphair network for the downstreamtask of link prediction. First of all, we modifiy the output size of the adversarial network from two, whichcorresponded to the binary sensitive feature in the Pokec and NBA datasets, to the respective number ofdistinct values of the sensitive feature in the corresponding dataset. To create the link embeddings for the input of the classifier, we compute the Hadamard product of the nodeembeddings (Horn & Johnson, 2012), which pairs node embeddings effectively. For nodes v and u, we definethe link embedding hvu as:hvu = hv hu(6) These new link embeddings require labels that reflect the sensitive attributes of the connected nodes. Tothis end, we integrate dyadic-level fairness criteria into our fairness assessment for link prediction. We form dyadic groups that relate sensitive node attributes to link attributes, following the mixed and subgroupdyadic-level fairness principles suggested by Masrour et al. (2020). The mixed dyadic-level groups classifylinks as either inter- or intra-group based on whether they connect nodes from the same or different sensitivegroups. The subgroup dyadic-level approach assigns each link to a subgroup based on the sensitive groupsof the nodes it connects. A subgroup is formed for each possible combination of sensitive groups. Thismethod facilitates the measurement of fairness in two distinct aspects. Firstly, it assesses how well eachprotected subgroup is represented in link formation at the subgroup dyadic-level. Secondly, it evaluatesnode homogeneity for links at the mixed dyadic-level. For assessing fairness in link prediction, we aim to optimize for Equality of Opportunity (EO) and Demo-graphic Parity (DP) using these dyadic groups.Following the original papers definition, DP is definedas:P( Y = 1 | D = 0) P( Y = 1 | D = 1)",
  "and EO as:P( Y = 1 | D = 0, Y = 1) P( Y = 1 | D = 1, Y = 1)": "where Y is a ground-truth label, Y is a prediction, and in the case of link prediction, D denotes the dyadicgroup to which the link belongs. These definitions extend to multiple dyadic groups (|D| > 2), which is thecase for subgroup dyadic analysis. As our final metrics, we define the Demographic Parity difference (DP)as the selection rate gap and the Equal Opportunity difference (EO) as the largest discrepancy in truepositive rates (TPR) and false positive rates (FPR) across groups identified by D:",
  "Baselines": "We adopt FairAdj (Li et al., 2021) and FairDrop (Spinelli et al., 2021) as our benchmarks. FairAdj learns afair adjacency matrix during an end-to-end link prediction task. It utilizes a graph variational autoencoderand employs two distinct optimization processes: one for learning a fair version of the adjacency matrixand the other for link prediction. We used two versions of FairAdj: one with 5 epochs (r = 5) and theother with 20 epochs (r = 20). FairDrop, on the other hand, proposes a biased edge dropout algorithm tocounteract homophily and improve fairness in graph representation learning. We used two different versionsof FairDrop: one with Graph Convolutional Network (GCN) (Kipf & Welling, 2016) and the other withGraph Attention Networks (GAT) (Velickovic et al., 2017).",
  "Hyperparameters": "Node ClassificationTo align our experiments closely with the original study, we adopt the hyperparam-eters specified by the authors. This includes conducting a grid search on the hyperparameters , , and with the values {0.1, 1.0, 10.0}, as performed in the original work (Ling et al., 2022). We use the defaultsettings from the original code where specific hyperparameters are not disclosed, a choice validated by theoriginal authors. A complete list of all hyperparameters is provided in in subsection A.2. Link PredictionWe replicate the grid search from the node classification experiments for link predictionon the Citeseer, Cora, and PubMed datasets. Initially, we conduct a grid search on the model parameters, including varying the number of epochs, the learning rates for both the Graphair module and the classifier,and the sizes of the hidden layers for both components. We select the most notable model setup based onperformance metrics (accuracy and ROC) and fairness values, and then perform a subsequent grid search onthe loss hyperparameters , , and to fine-tune the model further. We compare the results of Graphair with baseline results from Spinelli et al. (2021) and Li et al. (2021),which also underwent grid searches. For FairAdj, we conducted a grid search focusing on model parameters,involving variations in learning rates, hidden layer sizes, number of outer epochs, and the specific configu-ration parameter. We evaluated two versions of FairAdj: one with 5 epochs and the other with 20 epochs.For FairDrop, we also performed a grid search on the model parameters, testing different learning rates,epoch counts, and hidden layer sizes. We evaluated two configurations of FairDrop: one using a GraphConvolutional Network (GCN) and the other using Graph Attention Networks (GAT). More detailed infor-mation on the hyperparameters fine-tuned during the grid search for each model is presented in insubsection A.2.",
  "Computational requirements": "All of our experiments are conducted on a high-performance computing (HPC) cluster, that features NVIDIAA100 GPUs, divided into four partitions with a combined memory of 40 GB. For a detailed overview of theGPU hours required for each experiment, see in subsection A.3. A rough estimate suggests that atotal of 80 GPU hours are necessary to complete all experiments.",
  "Results reproducing original paper": "Claim 1: To verify Claim 1, we performed node classification on the NBA, Pokec-n, and Pokec-z datasets. shows a comparison of the results reported by the original authors and the results of baseline modelsgiven by the original authors with those obtained by us through replicating the experimental setup describedin subsection 3.3. Consistent with the original study, our results are derived by selecting the best outcomefrom the grid search procedure. We observe that the results for the NBA dataset are similar to those reportedby the authors. However, for the Pokec datasets, our Graphair model gets better fairness scores at the costof worse accuracies. When examining the fairness-accuracy trade-off in , which uses the DP fairness metric, we seethat for the NBA dataset we can achieve a similar trade-off. For the Pokec-z data, a small discrepancy isreflected by a similar trend, but with lower accuracy scores. The Pokec-n dataset also shows a similar trendbut fails to reach the higher accuracies of the original model. Considering that the code we used from theDIG library differs from what the original authors used, combined with the fact that a different number ofepochs, namely 10,000 was used for the Pokec dataset instead of the originally reported 500, we think theremight still be some differences in the experimental setups. Even though these discrepancies are probablyminor, they do not allow us to achieve better performance in terms of the accuracy-fairness trade-off for alldatasets compared to baseline models, which makes us only partially able to reproduce Claim 1.",
  "MethodsACC DP EO ACC DP EO ACC DP EO": "Graphair (ours)68.54 0.401.31 0.275.34 0.2465.76 0.020.72 0.360.41 0.4265.22 0.021.32 0.332.24 0.35Graphair w/o EP (ours)72.68 0.402.95 1.129.05 2.5367.26 0.162.11 0.091.37 0.3369.25 0.106.56 0.746.73 0.65Graphair w/o FM (ours)67.79 0.3210.73 1.1226.79 2.5364.61 0.363.83 0.473.18 0.2757.91 0.135.19 0.746.34 0.33 Claim 3: The plots in clearly illustrate that the homophily values for the augmented graph arelower than those for the original graph. These results support the authors claim that Graphair automaticallygenerates new graphs with a fairer node topology. The plots in reveal that, for all three datasets,the features with the highest Spearman correlation to the sensitive feature generally exhibit lower values inthe fair view. These findings lend support to the authors claim that Graphair produces features that arefairer. We can therefore conclude that Claim 3 is fully reproducible.",
  ": ACC and DP trade-off for baselines, Graphair and our results for Graphair. Upper-left corner(high accuracy, low demographic parity) is preferable": "Claim 2: confirms that Claim 2 is substantiated for both the NBA and Pokec-z datasets. In com-parisons of Graphair with and without feature masking (FM) or edge perturbation (EP), notable increases infairness metrics are observed. This supports the claim that each model component contributes to mitigatingprediction bias. Interestingly, we notice an increase in accuracy when removing feature masking across alldatasets, a result that deviates from findings in the original work, which showcased similar accuracy scoreswhen EP was removed. We attribute this to the use of more training epochs in our experimental setup. Itseems logical that performance would improve when edge perturbation is removed, as the encoder modelgenc can utilize the original adjacency matrix. This allows the classifier to exploit increased homophily inthe network, thereby increasing accuracy and worsening fairness.",
  "Results beyond original paper": "The performance of Graphair compared to baseline models is presented in , , and . Forfairness metrics, subscripts m and s denote application to mixed groups and subgroups, respectively. Ourfindings indicate that Graphair is outperformed by both FairDrop variants in terms of accuracy and AUCacross all datasets. However, compared to FairDrop, Graphair excels in all fairness metrics on all datasets,particularly in the subgroup variants on the Citeseer and Cora datasets. FairAdj demonstrates comparableperformance in accuracy and AUC relative to Graphair but performs worse in subgroup fairness metrics,only excelling in the DPm metric across all datasets. We further investigate the trade-off between accuracy and DP for both mixed and subgroup variants acrossthe three datasets for each model, as shown in . The trade-off for Graphair is comparable to thebaseline models for the mixed variant, while achieving a superior trade-off for the subgroup variant. WhileSpinelli et al. (2021) suggest that high scores for subgroup fairness metrics are due to dataset characteristics,we find that Graphair improves this metric through its augmentative approach, which generates augmenta-tions with similar predictive power across different subgroups. This enables Graphair to consistently predictlinks with the same probability across various subgroups, resulting in lower subgroup dyadic-level fairnesswhile maintaining predictive power.",
  "Discussion": "Upon revisiting the three claims in our study, we find that Claim 1 is partially reproducible, whereas Claims2 and 3 are fully reproducible. In the case of Claim 1, while we were able to replicate the performance of theNBA dataset consistent with the original paper, discrepancies emerged with the Pokec datasets. Specifically,our results showed improved fairness scores at the expense of lower accuracies compared to the originalfindings. This could be attributed to differences in experimental setup, particularly the number of trainingepochs used, which deviated from the original studys methods. We used 10,000 epochs for the Pokec datasetsas opposed to the 500 reported in the original paper, a change recommended by the original authors. Further analysis of Graphairs performance in link prediction indicates that, while it demonstrates a compa-rable fairness-accuracy trade-off to baseline models for mixed dyadic-level fairness, Graphair has a superiortrade-off for subgroup dyadic-level fairness.",
  "What was easy and what was difficult": "The clarity of the code within the DIG library3 significantly facilitated reproducibility. The original paperprovided a clear outline of the experiments, enabling a straightforward process to identify the necessarycomponents for reproducing the studys claims and implementing our link prediction extensions. We encountered initial challenges with the reproducibility of Claim 1, which necessitated seeking clarificationfrom the authors. Correspondence with the original authors resolved issues related to unspecified hyperpa-rameter settings and a bug in the code. Reproducing Claim 3 for the Pokec datasets proved non-trivial due tothe large memory requirements for processing the full graph, necessitating solutions to acquire experimentalresults.",
  "Communication with original authors": "We initiated contact with one of the authors, Hongyi Ling, via email to seek clarification on our initialresults that did not match those of the original paper. These discrepancies were resolved, and the authorsresponded promptly to our emails, providing valuable feedback. Most notably, they recommended a changein our experimental setup for the Pokec datasets, specifically increasing the number of epochs from 500 to10,000. Chirag Agarwal, Himabindu Lakkaraju, and Marinka Zitnik. Towards a unified framework for fair and stablegraph representation learning. In Uncertainty in Artificial Intelligence, pp. 21142124. PMLR, 2021. April Chen, Ryan Rossi, Nedim Lipka, Jane Hoffswell, Gromit Chan, Shunan Guo, Eunyee Koh, SungchulKim, and Nesreen K Ahmed.Graph learning with localized neighborhood fairness.arXiv preprintarXiv:2212.12040, 2022. Sean Current, Yuntian He, Saket Gurukar, and Srinivasan Parthasarathy. Fairegm: Fair link prediction andrecommendation via emulated graph modification. In Proceedings of the 2nd ACM Conference on Equityand Access in Algorithms, Mechanisms, and Optimization, pp. 114, 2022. Enyan Dai and Suhang Wang. Say no to the discrimination: Learning fair graph neural networks withlimited sensitive attribute information. In Proceedings of the 14th ACM International Conference on WebSearch and Data Mining, pp. 680688, 2021.",
  "Peizhao Li, Yifei Wang, Han Zhao, Pengyu Hong, and Hongfu Liu. On dyadic fairness: Exploring andmitigating bias in graph connections. In International Conference on Learning Representations, 2021": "Hongyi Ling, Zhimeng Jiang, Youzhi Luo, Shuiwang Ji, and Na Zou. Learning fair graph representations viaautomated data augmentations. In The Eleventh International Conference on Learning Representations,2022. Yi Liu, Limei Wang, Meng Liu, Yuchao Lin, Xuan Zhang, Bora Oztekin, and Shuiwang Ji. Spherical messagepassing for 3d molecular graphs. In International Conference on Learning Representations (ICLR), 2022.",
  "Youzhi Luo, Michael McThrow, Wing Yee Au, Tao Komikado, Kanji Uchino, Koji Maruhashi, and ShuiwangJi. Automated data augmentations for graph classification. arXiv preprint arXiv:2202.13248, 2022": "Farzan Masrour, Tyler Wilson, Heng Yan, Pang-Ning Tan, and Abdol Esfahanian. Bursting the filter bubble:Fairness-aware network link prediction. In Proceedings of the AAAI conference on artificial intelligence,volume 34, pp. 841848, 2020. Indro Spinelli, Simone Scardapane, Amir Hussain, and Aurelio Uncini. Fairdrop: Biased edge dropout forenhancing fairness in graph representation learning. IEEE Transactions on Artificial Intelligence, 3(3):344354, 2021.",
  "HyperparameterNBAPokec-nPokec-zCiteseerCoraPubMed": "1.00.110.00.110.010.00.11.010.00.110.010.00.10.10.10.10.10.11.010.010.01.010.00.1chidden128128128128128128clearning_rate1e-31e-31e-35e-35e-35e-3cweight_decay1e-51e-51e-51e-51e-51e-5mlearning_rate1e-41e-41e-41e-41e-41e-4mweight_decay1e-51e-51e-51e-51e-51e-5 presents a comprehensive overview of the hyperparameters adjusted during the grid search. Theinitial seven rows correspond to the Graphair model, while the subsequent rows correspond to the baselinemodels used for link prediction tasks. Regarding the epoch count for node classification with Graphair,500 epochs were used for the NBA dataset and 10,000 for the Pokec datasets. For grid searches with theGraphair model for link prediction, the number of epochs was set to 200."
}