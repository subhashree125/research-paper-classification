{
  "Abstract": "Existing online class imbalance learning methods fail to achieve optimal performance becausetheir assumptions about enhancing minority classes are hard-coded in model parameters.To learn the model for the performance measure directly instead of using heuristics, weintroduce a novel framework based on a dynamic EA called Online Evolutionary CostVector (OECV). By bringing the threshold moving method from the cost-sensitive learningparadigm and viewing the cost vector as a hyperparameter, our method transforms theonline class imbalance issue into a bi-level optimization problem. The lower layer utilizes abase online classifier for rough prediction, and the upper layer refines the prediction using athreshold moving cost vector learned via a dynamic evolutionary algorithm (EA). OECVbenefits from both the efficiency of online learning methods and the high performance ofEA, as demonstrated in empirical studies against state-of-the-art methods on thirty datasets.Additionally, we show the effectiveness of the EA component in the ablation study bycomparing OECV to its two variants, OECV-n and OECV-ea, respectively. This workreveals the superiority of incorporating EA into online imbalance classification tasks, whileits potential extends beyond the scope of the class imbalance setting and warrants futureresearch attention. We release our code1 for future research.",
  "Published in Transactions on Machine Learning Research (09/2024)": ": Performance comparison between OECV and SmoteOB in terms of G-mean (%) on the left andbalanced accuracy (%) on the right. Each entry is the meanstd performance across 10 runs. The bestperformance on each dataset is highlighted in bold, and the 2nd best performance is highlighted in italics.The last two rows list the average ranks (avgRank) of each model across datasets, as well as the relativeaverage time costs.",
  "Data-level Methods": "Sampling methods work by oversampling and/or undersampling to rebalance data. SMOTE (Chawla et al.,2002) is a synthetic minority over-sampling technique used to balance the class distribution by generating newinstances of the minority class. In online learning, it has been adopted in Online SMOTE (Wang & Pineau,2016), which oversamples using training samples within a sliding window. C-SMOTE (Bernardo et al., 2020)addresses binary class imbalance by actively detecting concept drift via ADWIN (Bifet & Gavalda, 2007), achange detector with a sliding detection window, and applying SMOTE to the minority class in the slidingwindow. The ignorance of class distribution information results in their sub-optimal performance. OS-CCDbased on classification contribution degree is proposed in Jiang et al. (2021), generating synthetic samples viaclassification contribution degree. SRE (Ren et al., 2019) introduces a selection-based resampling mechanismto handle complex data distributions by considering recent sample properties. However, the resamplingprocedures of OS-CCD and SRE are both based on clustering, being sensitive to hyperparameters. Whileshowing promising performance, these methods mostly targeted the binary class imbalance problem andneeded to maintain a sliding window to reserve relevant training samples, increasing the memory burden.",
  "Algorithm-level Methods": "Algorithm-level approaches work by modifying the training process. Qin et al. (2021) employs active learningto select the most important samples to train the classifier. Online one-class Support Vector Machines(Klikowski & Woniak, 2020) is a kind of one-class classifier that creates a model for each class and achieves aone-class decomposition of multi-class problems. Other algorithm-level methods apply cost-sensitive learningmethods, which assign varying costs for misclassifying classes belonging to different classes to reduce the",
  "Ensemble Methods": "Ensemble methods, such as MOOB, MUOB (Wang et al., 2016), KUE (Cano & Krawczyk, 2020), ROSE (Cano& Krawczyk, 2022), and BEDCOE (Li et al., 2023), effectively tackle the problem by combining resamplingtechniques. MOOB and MUOB leverage time-decay class size to determine training times. Specifically, thetraining time for each base classifier is determined by sampling from a Poisson distribution, whose parameteris set according to the class size. The diversity is maintained by random training times on a sample for eachbase classifier. Kappa Updated Ensemble (KUE) combines online and block-based ensemble approachesand uses Kappa statistics to determine dynamic weighting and select base classifiers. After that, Cano &Krawczyk (2022) proposes an advanced method called ROSE to improve the robustness of KUE by employingadaptive self-tuning, adjusting its parameters, and ensembling the line-up dynamically. To directly dealwith class imbalance, ROSE computes the imbalance ratio of each class based on recent samples to derivethe training times of each sample. BEDCOE considers potential complex data distribution compared toother works and introduces a borderline enhanced strategy and a disjunct cluster-based oversampling forsynthetic sample generation. Despite the improved performance achieved by using multiple base classifiers,the ensemble methods entail a trade-off between the diversity of the ensemble and training time.",
  "We note that the heuristic designs exist in all three categories, and several examples are listed below": "First, some methods suggest the imbalance ratio solely determines the imbalance status and do resampling(Wang & Pineau, 2016; Wang et al., 2016; Bernardo et al., 2020) or design cost schemes (Zong et al., 2013;Wang et al., 2021) based on the estimated online imbalance ratio. However, this is not a unique indicator ofclass imbalance. Other information, such as data distribution, is also helpful. Another common assumption is generating synthetic samples around minority instances helps with learning,including Ren et al. (2019), Jiang et al. (2021) and Li et al. (2023). However, this only holds when theminority data is well-clustered and sufficiently discriminative. If the training data is extremely imbalanced orwith many corrupted labels, the minority class would be poorly represented and lack a clear structure. Inthis case, working under this assumption severely jeopardizes the performance. Additionally, to use the estimated imbalance status such as imbalance ratio or data distribution from clustering,existing works predefine a certain functional form of the relation between imbalance status and trainingscheme. For instance, WELM (Zong et al., 2013) assumes the cost of misclassifying a class is inverselyproportional to its class size. Similarly, MOOB and MUOB (Wang et al., 2016) suppose the training time ofone class should be sampled from a Poisson distribution with the imbalance ratio as a parameter. However,the concrete functional form of using imbalance status cannot be exhausted. Besides, none of them havetheoretically justified that the proposed functional form could lead to optimality with respect to a certain",
  "Threshold Moving Method": "The threshold moving method (Kukar et al., 1998; Zhou & Liu, 2005; Sheng & Ling, 2006; Voigt et al., 2014;Hancock et al., 2022) is a common technique in cost-sensitive learning. It trains a classifier on the originaldataset and prioritizes classes with higher misclassification costs during prediction, using a predefined costmatrix. Formally, denote the cost matrix as Mij, where 1 i, j C, to represent the cost of misclassifyingclass i to class j. Here C is the number of classes. Let Oi, where 1 i C, represent the probabilisticoutput with Ci=1 Oi = 1 and 0 Oi 1. The prediction is arg maxi Oi in the threshold moving methodcomparing to arg maxi Oi in standard classifiers, where Oi is calculated according to",
  "j=1Mij)Oi = viOi(1)": "Here is a normalization term such that Ci=1 Oi = 1 and 0 Oi 1. A cost vector vi = Cj=1 Mij(1 i C) of lower complexity O(C) can be used in place of the matrix. The cost vector represents themisclassification cost of class i and adjusts the decision boundary toward less costly classes, making it harderto misclassify samples with higher costs. In this paper, the threshold moving is adapted to online classimbalance learning by enabling the cost matrix/vector to be learnable in two novel ways, namely OECV-nand OECV, so that it can respond to the current stream behavior () rather than being predefined. Thebaseline OECV-n is designed with time-decay class size, while the main algorithm OECV finds the optimalcost vector based on OECV-n and EA.",
  "EA for Class Imbalance Learning": "Recent studies (Pei et al., 2023) have shown the potential of EA in addressing class imbalance, while mostof the existing literature remains confined to offline scenarios. In Perry et al. (2015), a genetic algorithm(GA) is used to optimize a class-dependent cost matrix for the weighted updating of a classifier. Sun et al.(2006) introduces a cost-sensitive boosting algorithm that employs GA to optimize a class-dependent costvector. ECSB (Lemnaru & Potolea, 2017) uses GA to optimize a class-dependent cost matrix and classifierparameters simultaneously. GA is also applied to identify an optimal subset of instances in the majorityclass (Drown et al., 2009; Khoshgoftaar et al., 2010). In a cost-sensitive SVM method proposed in Caoet al. (2013), the misclassification cost ratio is optimized using particle swarm optimization. Furthermore,differential evolution (DE) has also been tried to optimize class-dependent cost matrices for cost-sensitivedeep belief networks (Zhang et al., 2018; 2016). EA is also utilized to support data-level methods. Forinstance, Jiang et al. (2016) introduces GASMOTE, a GA-based SMOTE approach that optimizes samplingrates for minority class instances.",
  "return yt": "There are significant challenges to adapting these methods to online settings. Unlike offline learning, whichreceives all training data upfront, online learning lacks this comprehensive data overview. Besides, the modelmust continuously and rapidly adapt to potential concept drift rather than converging. To our knowledge,only Wang & Wang (2023) has adopted a similar idea of EA in online class imbalance learning. It picks baseclassifiers of different parameter configurations with the highest performance so far. However, characteristicsof class imbalance in Wang & Wang (2023) are only used by the original resampling method, and the classimbalance issue is not handled by EA directly. Besides, it is currently tailored for binary classification tasks,making it unsuitable for multi-class scenarios.",
  "Overall Test-then-train Process of OECV": "In a data stream {(Xt, yt)}+t=1, Xt Rd represents data and yt {1, . . . , C} represents the class label. Cis the total number of classes. Uneven class prior distribution leads to class imbalance, and concept driftnecessitates the algorithm to adapt to ever-changing data distribution. Xt arrives strictly one by one, beingpredicted firstly by the latest classifier HCt1, and then refined using the cost vector v to give the finalprediction pt . pt is used together with true label yt that comes before t + 1 to update classifier HCt1 to HCt .This process is known as the test-then-train process. We present OECV in Alg. 1. At the beginning of the data stream, the cost vector population V is initializedrandomly. At time step t, the model {HCt1, v}, where HCt represents the latest online classifier, and v denotes the optimal cost vector discovered by EA up to time t 1, undergoes initial testing as depicted inLines 1-2. Here, the online classifier offers an initial prediction, which is then refined by the cost vector. Theclassifier HC updates by its own rule in Line 3. The class size t1 and fixed-size buffer B are updated inLines 4-5, respectively. Cost vector population V evolves within the if statement (Lines 6-7) to yield a newpopulation along with an optimal cost vector V. We detail OECV in subsequent subsections individually.",
  "Bi-level Optimization": "Due to the impracticality of a full evolution, our framework only evolves partially and breaks down both themodel and the problem into two layers (See ). The lower layer, being an online classifier, offers a roughprobabilistic prediction and updates by its own rule on the fly. The upper layer, being a cost vector, refinesthe rough prediction and undergoes a dynamic optimization process via dynamic EA. The training data for",
  "by a rate of": ": Illustration of OECV as a bi-level optimization problem (.2). The lower layer consists of aprobabilistic classifier, while the upper layer is a cost vector (.2). A fixed-size buffer is maintainedas the training data for the upper level. The cost vector is learned by a dynamic EA at frequency f on theoversampled buffer, using G-mean for objective evaluation (.4). updating the cost vector come from a fixed-size buffer B, which is augmented by a simple oversampling trickresulting in a larger buffer B to enhance data diversity. As shown in the left part of , we denote the firstand upper layers as H1,t and H2,t, respectively. The complete model is denoted by Ht = {H1,t, H2,t}. Thelower-level problem is to minimize a loss function 1(H1; Xt, yt), which assesses the probabilistic predictionloss computed for each sample in the stream. The upper-level problem involves minimizing a non-differentiableperformance metric 2(H2,t; p(; H1,t), yt), which measures the refined prediction error based on the solutionH1,t of the lower layer. The learning process of the upper layer occurs at a fixed frequency f instead ofupdating every time for computational efficiency. Importantly, the lower layer updates solely based on itsown rule, and optimizing the upper layer does not affect the lower layer. The overall optimization problem isstated as",
  "Note that the optimization of the lower level does not depend on the upper level in the sense that H1,t doesnot depend on H2,t": "In this study, H1 is parameterized as an online classifier HC along with its training loss 1 adapted fromexisting work.HC may not consider the specific characteristics of the performance metric (e.g., classimbalance) to be optimized. H2 is parameterized as a cost vector v, and the choice of 2 varies depending onspecific needs, such as G-mean or balanced accuracy. In this way, only the upper layer is metric-specific. Inthe following subsections, we only focus on the learning strategies for the cost vector. Remark 1 We notice that the upper level and the lower level are essentially optimized on the overlappingsource of data, where the classifier (lower level) uses all data until time t, and the cost vector (upper level)uses past sample stores in B. Intuitively, this may result in overfitting in a bi-level optimization problem. Inoffline bi-level optimization, a better choice is to use distinct training and validation datasets to train the twolevels. However, it is more tricky in our online setting since the samples come in the form of a stream. Wedid not add additional design for simplicity. In fact, the oversampling technique on B, which, although notspecifically proposed to handle this problem but proposed to enhance the optimization of the cost vector,may also help. Specifically, this can alleviate the overfitting of overlapping data sources at two levels byintroducing diversified data via interpolation, making the data used for the upper level more diversifiedcompared to the lower level. Remark 2 Several trade-offs exist in the design of OECV. The first is introducing the updating frequencyof cost vector and population size to handle the trade-off between time consumption and performance.Intuitively, a small updating frequency f will allow better performance, and in the extreme case where f = 1,the updating frequencies of both levels align, which would achieve the best performance. However, this comes",
  "j=1Mij(4)": "In other words, the prediction probability of a class will be scaled up if it is a relative minority class (in thesense of adaptively estimated class size ) and scaled-down otherwise. The loss function remains untouchedin threshold moving, but the prediction probabilities are scaled by v.It can adapt to current streambehavior by passively changing the imbalance status. However, optimal performance is not guaranteed asthe dependency on the heuristic form of the cost matrix as well as the choice of . The detailed trainingprocedure of OECV-n is similar to that of OECV, by just removing all the use of evolution and replacing v",
  "Chromosome Encoding: A cost vector v(k) is encoded into a chromosome straightforwardly, withthe C-dimensional vector being the chromosome": "Fitness Calculation: The chance of passing genetic information to subsequent generations relies onthe fitness of a cost vector. Recent samples are retained in a fixed-size buffer B for fitness calculation.B is enlarged into B by oversampling before being used for fitness evaluation. Specifically, we first doclassification using the latest classifier HC on B, resulting in the set of rough probabilistic predictions{pi}|B|i=1. For each v(k), it refines the rough predictions to give a set of final predictions {p(k)i}|B|i=1.{p(k)i}|B|i=1 along with the set of true labels {yi}|B|i=1 are then used to calculate a performance metric",
  "return v, V": "as the fitness f (k) of v(k). With the set of fitness {f (k)}|V|k=1, the optimal individual (cost vector)can be determined straightforwardly. Note the performance metric used here is the correspondingoffline metric (e.g., G-mean) instead of the online metric (e.g., online G-mean) so that the fitnesscalculation is not affected by the order of samples in B. Genetic Operator: EA employs genetic operators to produce new cost vectors by crossover andmutation based on the fitness value of individuals. Any single objective genetic operator may beapplied in the current framework. If the generation of new cost vectors at Line 14 in Alg. 2 is removed, while the selection of the optimalindividual in Line 15 is retained, we get a comparison algorithm OECV-ea as demonstrated in the ablationstudy. In this case, OECV-ea can be used to show whether OECV works by finding better individuals withevolution instead of simply relying on the buffered data to select a good solution from a large number ofcandidates.",
  "(5)": "Recall in the definition of cost vector (Eqn. 1), we require each dimension of v(i) = 1 be in and sum upto 1. Therefore, each dimension of v(i) is clipped to and re-normalized. {v(i)}mi=1 are then merged withthe previous population to form the initial population for later evolution. After a fixed frequency f, the priorpopulation is mixed in, and the population evolves over one generation. Analogous to the approach with time decay class size in spirits, the dynamic EA also acts passively to counterthe effect of concept drift, i.e., not detect the concept drift directly. Although this may not be the best choice",
  "Computational Complexity Analysis": "We are aware of the potential high computational complexity induced by EAs, including time complexity andspace complexity. A formal analysis is provided in this subsection. See also Appendix A for an empiricalruntime comparison. Memory Complexity AnalysisDenote the population size as |V| and buffer size as |B|. OECV requiresthe storage of a buffer of data of size O(|B| (d + 1)) where d denotes the number of features, i.e., we countthe number of stored samples times the number of features plus one (for the class label). Since temporarysynthesized samples in augmented buffer B can be processed one by one without storing everything in thememory, whose memory consumption is then negligible, the oversampled data is not taken into account forthe extra storage. Time Complexity AnalysisThe overall time complexity of OECV is linear to the length of the stream,being the same as existing works such as Wang et al. (2016), Qin et al. (2021), and Li et al. (2023). In eachtime step, the time complexity includes the training cost of both the classifier and the cost vector. Theupdating of the classifier is a constant and depends on its own rules. For updating of the cost vector, theoversampling on B takes O(|B| (r 1)) time. Then, |V| individuals perform prediction and evaluation onB that takes O(|V| |B| r) time in total. The crossover, mutation, and selection operations are based onfitness, being method-dependent. It generally takes O(|V|) and is much faster than the fitness calculated inthe last step. Summarize and simplify the above steps, and recall the updating of the cost vector occurs ata frequency of f, we find the overall time complexity can be represented as O( rT |V||B|",
  "f) for the whole datastream, where T is the length of the stream": "While EAs are well-known for their high computational cost (mainly from fitness evaluation), our scheme ofapplying the cost vector in a post hoc way allows for a much more efficient fitness evaluation. To see this, aforward calculation for prediction is enough to give the fitness, which is attributed to the decoupling of twolayers where the training of the classifier is totally independent of the cost vector. Therefore, we only need toevaluate how well the cost vectors correct the current well-trained classifier without any retraining of theclassifier. This drastically decreases the time for fitness calculation and makes OECV practical.",
  "Storage Requirement": "We are aware that the extra storage requirement in the form of a fixed-size buffer is a weakness in our currentmethod. However, certain storage requirements are generally acceptable in the literature, especially widelyused in data-level methods (Sec. 2.1.1). The resampling and clustering processes necessitate extra storagesimilar to ours. For example, Qin et al. (2021), Ren et al. (2019), Cano & Krawczyk (2022), and Wang &Pineau (2016) all require certain storage in the form of a sliding window or chunk. Despite the extra storageburden, it is usually constant and would not increase with the length of the stream. This is practical inmany real-world scenarios, such as online edge machine learning, where the stream can be infinitely large,but certain storage (while limited) is accessible. However, if additional storage is unavailable, an adaptivegenerative model can be used to generate samples to replace the buffer. In this work, we focus on the currentextra storage scheme for simplicity.",
  "Experimental Setup": "We use 30 datasets in total as summarized in , including 10 streaming datasets (Elec, Abrupt,Gradual, Incremental1, Luxembourg, NOAA, Ozone, Airlines, Covtype, Incremental2, available in theUSP-DS repository, Souza et al. (2020)) and 20 real-world offline datasets (remaining 20 datasets in ,available in the Keel repository, Derrac et al. (2015)). The 20 offline datasets are processed in a streamingway to simulate online scenarios. The overall static imbalance ratio for each dataset illustrates the severity ofclass imbalance, while fluctuation of class imbalance ratio throughout the online learning scenario exists. Although our method does not require an offline warm start, we use the initial 30% samples of each stream formodel initialization in an offline fashion, following the setting in Li et al. (2023). The initialization samplesare further split into two datasets in equivalent sizes for training the classifier and the cost vector separately.In this stage, the cost vector population evolves 10 generations to give an initial population for later onlinetraining. The buffer size |B| for OECV is fixed at 200 samples, and the oversampling rate is set to 5 for alldatasets. Offline G-mean is used for fitness evaluation on the augmented buffer. The cost vector evolves every5 sample (i.e., f = 5), with the number of individuals set to 25. We employ DE/best/1/L (Opara & Arabas,2019) as the genetic operator. The implementation of EAs is easy by directly adopting the existing Pythonpackages (such as geatpy 2 used in our experiments). All the hyperparameters related to genetic operatorsare set to the default values of the existing implementation without tuning. Specifically, the scaling factor ofDE is set to 0.5, and exponential crossover is applied with the probability of crossover set to 0.7. We compare with four SOTA online multi-class imbalance learning methods: MOOB, MUOB (Wang et al.,2016), AI-WSELM (Qin et al., 2021), and BEDCOE (Li et al., 2023). The total number of base learners isset to 10, following (Wang et al., 2016; Li et al., 2023). All methods adhere to the test-then-train processof online learning. Multilayer perceptron serves as the base classifier for all methods, except AI-WSELM,which does not need a base classifier, following the setup in Wang et al. (2016). We set the chunk size (akinto our buffer) of AI-WSELM to be 300, higher than our extra storage of 200. Prequential G-mean with afading factor of 0.99 is selected as performance metrics, following Wang et al. (2018) and Li et al. (2023).Mean performance across 10 runs is evaluated on the remaining samples after the initialization number.Friedman tests (Demar, 2006) are used to compare competing methods across datasets statistically. Thenull hypothesis (H0) posits that all models are equivalent in terms of the predictive performance metric. Thealternative hypothesis (H1) suggests that at least one pair of methods differs significantly. If H0 is rejected,the Conover test (Conover & Iman, 1979) is conducted as the post-hoc test.",
  "Performance Comparison": "We can see from (a) that in terms of G-mean, OECV performs the best in 14 out of 30 datasetsand the 2nd best in 8 datasets. Friedman tests at significance level 0.05 reject H0 with p-value 1.11 103,showing a significant difference between methods. Average ranks (avgRank) across datasets are reported toshow how well each method performs compared to others across datasets. The average rank of OECV is1.967, being the best. Post-hoc tests are then conducted to detect whether OECV has a significant difference",
  "from the competitors, for which OECV is chosen as the control method. Post-hoc comparisons show thatOECV can significantly outperform all of the competitors": "We can draw two observations on when the OECV can gain an advantage or not from and . Firstly, we notice that when the number of classes is large, e.g., on Gradual, Incremental1, and Yeast2datasets, our method generally does not perform the best compared to other baselines. Further analysis ofthe Spearman correlation (Fieller et al., 1957) shows correlation coefficients of 0.49 (moderate) between thenumber of classes and the value of rank on the 30 datasets (the higher the rank, the worse the performance),being positively correlated. This verifies that our method generally performs better when a small numberof classes are presented. This is reasonable since the complexity of the cost vector equals the number ofclasses, and a larger cost vector is intuitively more difficult to find its optimal solution within limited timeand memory. A remedy for this issue deserves a more complicated algorithm design and is left to the future.Secondly, we find our method performs better when the stream is highly skewed, i.e., with a large imbalanceratio. For example, on datasets Win3, Win4, and Win5, our method performs the best among baselines witha larger margin. Similarly, an analysis of the Spearman correlation shows correlation coefficients of 0.29(weak) between the imbalance ratio and the value of rank on the 30 datasets, being negatively correlated,which confirms our conjecture that a highly imbalanced stream favors OECV. We speculate, in this case, thead hoc imbalance estimation, such as the time-decay imbalance ratio (which is used in MOOB, MUOB, andBEDCOE), can not capture the complicated overall imbalance status well. This downgrades the performanceof baselines by using a misleading imbalance indicator. In contrast, our method seeks an optimal cost vectordirectly with respect to the performance metric without consulting heuristically estimated imbalance status.This explains why OECV outperforms other methods under high imbalance.",
  "Ablation Study": "Two comparison models OECV-n and OECV-ea have been built in .3 and .4, which differfrom OECV by just the way on learning cost vector. They are employed here to study the effectiveness ofEA. We would expect the performance of OECV, with the full assistance of evolutionary optimization, to bethe best. The performance of OECV-ea should be in the middle since while evolution is not used, severalcandidates of cost vectors are still under consideration for selecting the best one using buffered data. Theperformance of OECV-n should be the worst because only an imbalance ratio is used. If this occurs, we canconclude that the EA used for optimizing the cost vector is crucial for dealing with class imbalance, andextra data in the buffer is not the determinative reason for performance improvement. (b) shows the result in terms of G-mean. The three methods are compared to each other, withWilcoxon signed rank tests (Wilcoxon, 1992) used to determine if there are significant differences betweenthem. We can see that the average rank of OECV (1.333) is better than that of OECV-n (2.467) andOECV-ea (2.2). Wilcoxon signed rank test rejects H0 with p-value 0.0036 and 9.62 105, respectively,meaning OECV is significantly superior to OECV-n and OECV-ea. In comparison between OECV-ea and",
  "Analysis on Population Diversity": "We explore whether OECV can maintain population diversity over time instead of converging. The populationdiversity enables OECV to track the optimal cost vector instead of converging to a certain solution. Wepresent the standard derivation of individual fitness in with a further analysis of the Spearmancorrelation (Fieller et al., 1957). The result shows correlation coefficients of 0.594 (moderate) and 0.629(strong) between the absolute difference of imbalance ratios (i.e., the absolute value of the difference betweentwo neighboring class imbalance ratios) and standard deviation (std) of fitness of OECV and OECV-ea,respectively, being positively correlated. It also shows a high correlation coefficient of 0.869 between the stdof fitness of OECV and OECV-ea. We can draw two conclusions: 1) The diversity adapts to data streambehavior. This means OECV and OECV-ea can expand the exploration of new cost vectors (high std) duringa concept drift where the imbalance ratio changes drastically while adopting temporary elitists by leveraginglearned knowledge about class imbalance (low std) during the steady stream where the imbalance ratio isstable. 2) Despite similar diversity and changing behavior, OECV outperforms OECV-ea. This indicates thesuperiority of EA in that it can maintain a population of cost vectors with higher quality under the samediversity.",
  "We explore how the cost vector found by the EA outperforms the one determined solely by the imbalanceratio. We define the weight ratio (WR) as v1": "v0 to visualize the cost vector in a binary classification scenario in. Here, vi represents the i-th dimension of the cost vector. Analogous to the imbalance ratio, the WRserves as a belief of the imbalance level indicated by the cost vector. We analyze the Spearman correlationbetween the WR of three variants and the imbalance ratio, yielding correlation coefficients of 0.971, 0.897,and 0.887 for OECV-n, OECV-ea, and OECV respectively, indicating strong correlations. This means thecost vectors found by EA can also reflect the beliefs about class imbalance, while some of these beliefs are",
  "Conclusion": "This article introduces a novel approach Online Evolutionary Cost Vector (OECV) to tackle the online classimbalance issue by eliminating heuristic assumptions on class imbalances widely used in existing methods.OECV instead manages to optimize performance on any specified performance metrics directly, achieved byadopting a dynamic EA. The model is explicitly deconstructed into two layers: an online classifier for roughprobabilistic prediction and a cost vector for refining the decision boundary. The cost vector is the only partsubject to the dynamic EA for directly optimizing specific performance metrics. This bi-level architecture ismotivated by viewing the cost vector as a hyperparameter in the threshold moving method and the EA asan approach to fine-tune the hyperparameter. A dynamic EA is employed to track the optimal cost vectorover time. Cost vectors designed by class size are integrated into the prior population to sustain populationdiversity and integrate prior knowledge. To enhance data diversity, an oversampling trick is used to augmentthe buffer and attain more beneficial evolutionary results. Empirical studies demonstrate the validity andefficiency of our approach. Analysis of the working mechanism reveals how OECV can generate a superiorcost vector compared to the human-designed counterpart. The potential of the OECV framework extends beyond the class imbalance setting and has further explorationvalues in various other classification tasks. High performance across a broad range of metrics unrelated toclass imbalance could be achieved with only slight adjustments to the cost vector. For instance, OECV cansimultaneously serve multi-objective purposes by optimizing for multiple metrics, including accuracy, recall,and F1-score. Another future work is to handle the potential label noise. Specifically, when there existcorrupted labels, the samples in the augmented buffer will also contain corrupted labels, which may degradethe optimization of cost vectors and deserve a further specific design. Alessio Bernardo, Heitor Murilo Gomes, Jacob Montiel, Bernhard Pfahringer, Albert Bifet, and EmanueleDella Valle. C-smote: Continuous synthetic minority oversampling for evolving data streams. In 2020IEEE International Conference on Big Data (Big Data), pp. 483492. IEEE, 2020.",
  "Matjaz Kukar, Igor Kononenko, et al. Cost-sensitive learning with neural networks. In ECAI, volume 15, pp.8894. Citeseer, 1998": "Camelia Lemnaru and Rodica Potolea. Evolutionary cost-sensitive balancing: A generic method for imbalancedclassification problems. In EVOLVE-A Bridge between Probability, Set Oriented Numerics, and EvolutionaryComputation VI, pp. 194209. Springer, 2017. Shuxian Li, Liyan Song, Yiu-ming Cheung, and Xin Yao. Bedcoe: Borderline enhanced disjunct cluster basedoversampling ensemble for online multi-class imbalance learning. In ECAI 2023: 26th European Conferenceon Artificial Intelligence, September 30October 4, 2023, Krakw, Poland, Including 12th Conference onPrestigious Applications of Intelligent Systems (PAIS 2023): Proceedings, pp. 14141421. IOS Press BV,2023.",
  "Karol R Opara and Jarosaw Arabas. Differential evolution: A survey of theoretical analyses. Swarm andevolutionary computation, 44:546558, 2019": "Wenbin Pei, Bing Xue, Mengjie Zhang, Lin Shang, Xin Yao, and Qiang Zhang. A survey on unbalancedclassification: How can evolutionary computation help? IEEE Transactions on Evolutionary Computation,2023. Todd Perry, Mohamed Bader-El-Den, and Steven Cooper. Imbalanced classification using genetically optimizedcost sensitive classifiers. In 2015 IEEE Congress on Evolutionary Computation (CEC), pp. 680687. IEEE,2015. Jiongming Qin, Cong Wang, Qinhong Zou, Yubin Sun, and Bin Chen. Active learning with extreme learningmachine for online imbalanced multiclass classification. Knowledge-Based Systems, 231:107385, 2021. Siqi Ren, Wen Zhu, Bo Liao, Zeng Li, Peng Wang, Keqin Li, Min Chen, and Zejun Li. Selection-basedresampling ensemble algorithm for nonstationary imbalanced stream data learning. Knowledge-BasedSystems, 163:705722, 2019.",
  "Olivier Sigaud and Stewart W Wilson. Learning classifier systems: a survey. Soft Computing, 11:10651078,2007": "Vinicius MA Souza, Denis M dos Reis, Andre G Maletzke, and Gustavo EAPA Batista. Challenges inbenchmarking stream learning algorithms with real-world data. Data Mining and Knowledge Discovery, 34:18051858, 2020. Yanmin Sun, Mohamed S Kamel, and Yang Wang. Boosting for learning multiple classes with imbalancedclass distribution. In Sixth international conference on data mining (ICDM06), pp. 592602. IEEE, 2006. Tobias Voigt, Roland Fried, Michael Backes, and Wolfgang Rhode. Threshold optimization for classificationin imbalanced data in a problem of gamma-ray astronomy. Advances in Data Analysis and Classification,8:195216, 2014.",
  "ARunning Time Comparison": "Since EA is known for high time complexity, we conduct a runtime comparison to show the practicalityof OECV along with the theoretical analysis in Sec. 3.4.4. All experiments are benchmarked on a serverconfigured with Intel(R) Xeon(R) Gold 6338 CPU @ 2.00GHz. The geometric mean of runtime across datasetsis reported in the case of varying runtime scales across datasets. Specifically, suppose N datasets are used, we reportNNi=1 ti, where ti represents the runtime on the i-th dataset. Two key observations can be madefrom the results in . Firstly, while some methods exhibit significantly shorter runtimes, such as MUOBand OECV-n, this comes at the expense of their inferior performance, as evidenced in (a). Secondly,our approach demonstrates remarkable efficiency, as OECV achieves the best rank with tolerable runtimecompared to other SOTA methods. This validates the time efficiency and practicality of OECV despiteintegrating EA.",
  "BPerformance Comparison in Terms of Balanced Accuracy": "In (a), we include a performance comparison in terms of balanced accuracy, complementary tothe results in .2. We can see from that in terms of balanced accuracy, OECV performsthe best in 12 out of 30 datasets and the 2nd best in 8 data sets. Friedman tests (Demar, 2006) at thesignificance level 0.05 reject H0 with the p-value 4.21 103, showing that there is a significant differencebetween methods. The average rank of OECV is 2.167, being the best. Post-hoc tests are then conducted toinvestigate whether OECV has a significant difference from the competitors, for which OECV is chosen as thecontrol method. Post-hoc comparisons show that OECV can significantly outperform all of the competitorsexcept BEDCOE, where the p-value is 0.052, being only marginally higher than 0.05. We conjecture thisis because the optimization objective is set to G-mean instead of balanced accuracy in OECV, making thealgorithm not aware of this performance metric.",
  "CAblation Studies in Terms of Balanced Accuracy": "(b) shows the predictive performance of the three models in terms of balanced accuracy, complementaryto the results in .3. Then, the three methods are compared to each other, with Wilcoxon signedrank tests (Wilcoxon, 1992) used to determine if there are significant differences between them. We can see that in terms of balanced accuracy, the average rank of OECV (1.55) is better than thatof OECV-n (2.233) and OECV-ea (2.217). Wilcoxon signed rank test rejects H0 with p-value 0.042 and4.98 104, respectively, meaning OECV is significantly superior to OECV-n and OECV-ea. This indicatesthat eliminating the EA strategy would significantly decline predictive performance in terms of balancedaccuracy, showing its effectiveness. We follow a similar procedure to compare OECV-ea and OECV-n. In terms of balanced accuracy, the averagerank of OECV-ea (2.217) is better than OECV-n (2.233). Wilcoxon signed-rank test fails to reject H0 withp-value 0.838, meaning there is no significant difference between OECV-ea and OECV-n. This indicates thatusing extra samples in the buffer is solely insufficient to find a significantly better cost vector. In other words,",
  "DContinuous Performance Throughout Time": "presents performance comparisons over various time steps on two representative datasets in terms ofG-mean and balanced accuracy. Similar patterns were observed in other datasets. We can see that OECVconsistently outperforms most other methods across most time steps in terms of both G-mean and balancedaccuracy. This demonstrates the continuous effectiveness of our approach in improving performance overtime. For ablation studies, we demonstrate continuous performance over time in in terms of G-mean andbalanced accuracy. We notice removing the evolutionary cost vector strategy leads to a continual decline inperformance across most test steps. As a result, we assert that using EA is crucial in our approach.",
  "EHyperparameter Analysis": "To balance the performance and computational cost, we introduced a few hyperparameters in OECV. Therole of each hyperparameter is straightforward and does not need heavy fine-tuning. In this section, weprovide a detailed discussion on the sensitivity of population size, oversampling rate, buffer size, and theupdating frequency of the cost vector. We also investigate the influence of the pre-training ratio. Note thepre-training stage is not necessary in our method and is added to make a fair comparison since Li et al. (2023)requires a pre-training setup. The ratio of 30% in the main experiments is chosen randomly and set to be thesame for all compared methods without any tuning.",
  "E.2Oversampling Rate": "We can show the influence of the oversampling rate r in OECV by manually altering only r to get threecomparison methods: r = 1 (i.e., no oversampling), r = 3, and r = 5 (original setting). The detailedcomparison setting remains the same as in the main paper experiments. We report the performance in termsof G-mean in (a) and the performance in terms of balanced accuracy in (b). The result shows that increasing the oversampling rate would boost performance constantly, however, the timecomplexity also increases. Intuitively, a larger r enhances the sample diversity and allows a more accuratefitness evaluation but makes the fitness evaluation slower. One can use larger r to get further performanceimprovement, but r = 5 is good enough to make the fitness evaluation both accurate and efficient.",
  "E.3Buffer Size": "We can show the influence of the buffer size |B| in OECV by manually altering only the buffer size to getthree comparison methods: |B| = 50, |B| = 100, and |B| = 200 (original setting). The detailed comparisonsetting remains the same as in the main paper experiments. We report the performance in terms of G-meanin (a) and the performance in terms of balanced accuracy in (b). The result shows that increasing the buffer size would boost performance constantly, however, both the timecomplexity and storage complexity increase. Intuitively, a larger buffer makes more samples available to thecost vector and allows a more accurate fitness evaluation but makes the fitness evaluation slower. One canuse a larger buffer to get further performance improvement, but |B| = 200 is good enough to make the fitnessevaluation both accurate and efficient.",
  "E.4Updating Frequency": "We can show the influence of the updating frequency f of the cost vector in OECV by manually alteringonly the f to get three comparison methods: f = 5 (original setting), f = 10, and f = 20. The detailedcomparison setting remains the same as in the main paper experiments. We report the performance in termsof G-mean in (a) and the performance in terms of balanced accuracy in (b). The result shows that decreasing the update would boost performance constantly, however, the time complexityincreases. Intuitively, a smaller f makes the updating frequency more aligned with the classifier in the lowerlayer. This reduces the probability of updating delay and a sub-optimal solution. One can use a smaller f toget further performance improvement, but f = 5 is good enough, and we pick this value to save the runtimeof OECV.",
  "E.5Pre-training Ratio": "We can show the influence of the ratio of the dataset for pretraining in OECV by manually altering onlythe pretraining ratio to get three comparison methods: Ratio = 0 (begin from scratch), Ratio = 0.1, andRatio = 0.3 (original setting). The detailed comparison setting remains the same as in the main paperexperiments. Note the model is evaluated only on the remaining stream after the pretraining stage. Wereport the performance in terms of G-mean in (a) and the performance in terms of balanced accuracyin (b). The result does not show an obvious relation between the pretraining ratio and performance in our method.Indeed, this hyperparameter is not an essential part of our method, and OECV can start from scratch(Ratio = 0). The hyperparameter is retained to align with the compared method Li et al. (2023), andchoosing a proper ratio and setting it equally to all compared methods is enough to make the comparisonfair, as we did in the main experiment.",
  "FMore Experimental Comparison with Comparable Storage Budget": "Except for the baseline AI-WSELM (Qin et al., 2021), which also requires extra storage as the same as ours,the other three baselines MOOB, MUOB (Wang et al., 2016) and BEDCOE (Li et al., 2023), do not havethis requirement. In this section, We compare with an additional baseline named Online SMOTE Bagging(SmoteOB) (Wang & Pineau, 2016) that also uses extra storage to demonstrate the superiority of OECV whenthe compared method enjoys comparable or even higher storage requirements. The SmoteOB oversamplesusing training samples within a sliding window, and we set the size of the sliding window to 100 for eachclass (i.e., at least 200 samples to be stored for all classes), being equal to or larger than ours. We report the performance in terms of G-mean in (a) and the performance in terms of balancedaccuracy in (b). We can draw the observation that OECV outperforms SmoteOB with a similartime cost. An analysis analogous to the main paper can explain that our method performs better in caseswhere few classes are presented, and the stream is highly imbalanced. This illustrates that our method cannot only outperform baselines with no extra storage requirement but also outperform baselines with extrastorage used, verifying the effectiveness of OECV."
}