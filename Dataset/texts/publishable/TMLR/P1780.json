{
  "Abstract": "This paper proposes to use set features for detecting anomalies in samples that consistof unusual combinations of normal elements. Many leading methods discover anomaliesby detecting an unusual part of a sample. For example, state-of-the-art segmentation-based approaches, first classify each element of the sample (e.g., image patch) as normalor anomalous and then classify the entire sample as anomalous if it contains anomalouselements. However, such approaches do not extend well to scenarios where the anomaliesare expressed by an unusual combination of normal elements. In this paper, we overcomethis limitation by proposing set features that model each sample by the distribution of itselements. We compute the anomaly score of each sample using a simple density estimationmethod, using fixed features. Our approach outperforms the previous state-of-the-art inimage-level logical anomaly detection and sequence-level time series anomaly detection1.",
  "Introduction": "Anomaly detection aims to automatically identify samples that exhibit unexpected behavior. In somedetection tasks anomalies are quite subtle. For example, let us consider an image of a bag containing screws,nuts, and washers (). There are two ways in which a sample can be anomalous: (i) one or more of theelements in the sample are anomalous. E.g., a broken screw. (ii) the elements are normal but appear in ananomalous combination. E.g., one of the washers might be replaced with a nut. In recent years, remarkable progress has been made in detecting samples featuring anomalous elements.Segmentation-based methods were able to achieve very strong results on industrial inspection datasets(Bergmann et al., 2019). Such methods operate in two stages: First, we perform anomaly segmentation bydetecting which (if any) of the elements of the sample are anomalous, e.g., by density estimation (Cohen &Hoshen, 2020; Defard et al., 2021; Roth et al., 2022). Given an anomaly segmentation map, we computethe sample-wise anomaly score as the number of anomalous elements, or the abnormality level of the mostanomalous element. If the anomaly score exceeds a threshold, the entire sample is denoted as an anomaly.We denote this paradigm detection-by-segmentation. Here, we tackle the more challenging case of detecting anomalies consisting of an unusual combination ofnormal elements. For example, consider the case where normal images contain two washers and two nuts, but",
  "Published in Transactions on Machine Learning Research (12/2024)": "Lukas Ruff, Robert A Vandermeulen, Nico Grnitz, Alexander Binder, Emmanuel Mller, Klaus-RobertMller, and Marius Kloft. Deep semi-supervised anomaly detection. In International Conference onLearning Representations, 2019. Lukas Ruff, Jacob R Kauffmann, Robert A Vandermeulen, Grgoire Montavon, Wojciech Samek, MariusKloft, Thomas G Dietterich, and Klaus-Robert Mller. A unifying review of deep and shallow anomalydetection. Proceedings of the IEEE, 2021. Mohammadreza Salehi, Niousha Sadjadi, Soroosh Baselizadeh, Mohammad H Rohban, and Hamid R Rabiee.Multiresolution knowledge distillation for anomaly detection. In Proceedings of the IEEE/CVF conferenceon computer vision and pattern recognition, pp. 1490214912, 2021.",
  "Previous work": "Image Anomaly Detection. A comprehensive review of anomaly detection can be found in Ruff et al.(2021). Early approaches such as Glodek et al. (2013); Latecki et al. (2007); Eskin et al. (2002) usedhandcrafted representations. Deep learning has provided a significant improvement on such benchmarks(Larsson et al., 2016; Ruff et al., 2018; Golan & El-Yaniv, 2018; Hendrycks et al., 2019; Ruff et al., 2019; Perera& Patel, 2019; Salehi et al., 2021; Tack et al., 2020). As density estimation methods utilizing pre-traineddeep representation have made significant steps towards the supervised performance on such benchmarks(Deecke et al., 2021; Cohen & Avidan, 2022; Reiss et al., 2021; Reiss & Hoshen, 2021; Reiss et al., 2022);much research is now directed at other challenges (Reiss et al., 2022). Such challenges include detectinganomalous image parts which are small and fine-grained (Cohen & Hoshen, 2020; Li et al., 2021; Defard et al.,2021; Roth et al., 2022; Horwitz & Hoshen, 2022). The progress in anomaly detection and segmentation hasbeen enabled by the introduction of appropriate datasets (Bergmann et al., 2019; 2021; Carrera et al., 2016;Jezek et al., 2021; Bonfiglioli et al., 2022). Recently, the MVTec-LOCO dataset Bergmann et al. (2022) hasput the spotlight on fine-grained anomalies that cannot be identified using single patches, but can only be",
  "identified when examining the connection between different (otherwise normal) elements in an image. Here,we will focus on detecting such logical anomalies": "Time series Anomaly detection. A general review on anomaly detection in time series can be found in(Blzquez-Garca et al., 2021). In this paper, we are concerned with anomaly detection of entire sequences,i.e., cases where an entire signal may be abnormal. Traditional approaches for this task include genericanomaly detection approaches such as k nearest neighbors (kNN) based methods, e.g., vanilla kNN Eskinet al. (2002) and Local Outlier Factor (LOF) Breunig et al. (2000), tree-based methods Liu et al. (2008),one-class classification methods Tax & Duin (2004) and SVDD Schlkopf et al., and auto-regressive methodsthat are particular to time series anomaly detection Rousseeuw & Leroy (2005). With the advent of deeplearning, the traditional approaches were augmented with deep-learned features: Deep one-class classificationmethods include DeepSVDD Ruff et al. (2018) and DROCC Goyal et al. (2020). Deep auto-regressive methodsinclude RNN-based prediction and auto-encoding methods Bontemps et al. (2016); Malhotra et al. (2016).In addition, some deep learning anomaly detection approaches are conceptually different from traditionalapproaches. These methods use classifiers trained on normal data, assuming they will struggle to generalizeto anomalous data (Bergman & Hoshen, 2020; Qiu et al., 2021). Discretized Projections. Discretized projections of multivariate data have been used in many previousworks. Locally sensitive hashing Dasgupta et al. (2011) uses random projection and subsequent binaryquantization as a hash for high-dimensional data. It was used to facilitate fast k nearest neighbor search.Random projections transformation is also highly related to the Radon transform Radon (1917). Kolouriet al. Kolouri et al. (2015) used this representation as a building block in their set representation. HBOSGoldstein & Dengel (2012) performs anomaly detection by representing each dimension of multivariate datausing a histogram of discretized variables. Rocket and mini-rocket Dempster et al. (2020; 2021) representtime series for classification using the averages of their window projection. LODA Pevn`y (2016) extends thiswork, by first projecting the data using a random projection matrix. We differ from LODA in the use of adifferent density estimator and in using sets of multiple elements rather than single sample descriptions.",
  "A Set is More Than the Sum of its Parts": "Detecting anomalies in complex samples consisting of collections of elements requires understanding howthe different elements of each sample interact with one another. As a motivating example let us considerthe screw bag class from the MVTec-LOCO dataset (). Each normal sample in this class containstwo screws (of different lengths), two nuts, and two washers. Anomalies may occur, for example, when anadditional nut replaces one of the washers. Detecting anomalies such as these requires describing all elementswithin a sample together, since each local element on its own could have come from a normal sample. A typical way to aggregate element descriptor features is by average pooling - taking the average of thefeatures describing each element. Yet, this is not always suitable for set anomaly detection. In supervisedlearning, average pooling is often built into architectures such as ResNet He et al. (2016) or DeepSets Zaheeret al. (2017), in order to aggregate local features. Therefore, deep features learned with a supervised loss arealready trained to be effective for pooling. However, for lower-level feature descriptors this may not be thecase. As demonstrated in , the average of a set of features is far from a complete description of the set.This is especially true in anomaly detection, where density estimation approaches require more discriminativefeatures than those needed for supervised learning (Reiss et al., 2022). Even when an average pooled set offeatures works for a supervised task, it might not work for anomaly detection. Therefore, we choose to model a set by the distribution of its elements in the embedded feature space, ignoringthe ordering between them. A naive way of doing so is using a discretized, volumetric representation, similarto 3D voxels for point clouds. Unfortunately, such approaches cannot scale to high dimensions, and morecompact representations are required. We choose to represent sets using a collection of 1D histograms. Eachhistogram represents the density of the elements of the set when projected along a particular direction. Wetake the bin occupancies of such histograms as our features. We provide an illustration of this idea in . In some cases, projecting a set along its original axes may not be discriminative enough. Histograms alongthe original axes correspond to 1D marginals, and may map distant elements to the same histogram bins(see for an illustration). On the other side, we can see at the bottom of the figure that when the setelements are first projected along another direction, the histograms of the two sets are distinct. This suggestsa set description method: first project each set along a shared random direction and then compute a 1Dhistogram for each set along this direction. We can obtain a more powerful descriptor by repeating thisprocedure with projections along multiple random directions. We benchmark this approach in section 3.5.",
  "Preliminaries": "We are provided a training set S containing a set of NS samples, we denote a sample as x S. We assumethat all the training samples are normal. We wish to learn a model that operates on a new, test sample xand outputs an anomaly score. We label samples with anomaly scores higher than a predetermined thresholdvalue as anomalies. The unique aspect of our method is that it treats each sample x as consisting of a set ofNE elements, where we denote each element as e x. Examples of such elements include patches for images,or temporal windows for time series. We assume the existence of a powerful feature extractor F that mapseach raw element e into an element feature descriptor F(e). We will describe specific implementations of thefeature extraction for two important applications: images and time series, in section 4.",
  "Set Features by Histogram of Projections": "Motivated by the toy example in section 3.1, we propose to model each set by the histogram of the values ofits elements along a collection of directions. We provide an algorithm box Alg.1 summarizing our steps. Feature extractor. We split each sample to elements e x and extract a feature representation for each{F(e) | e x}. We describe the implementation of F in Sec.4 as it differs for the time series and imagemodalities.",
  "Anomaly Scoring": "We perform density estimation on the set descriptors, expecting unusual test samples to have unusualdescriptors, far from those of the normal train set. We define the anomaly score as the Mahalanobis distance,the negative log-likelihood in feature space. We denote the mean and covariance of the histogram projectionfeatures of the normal data as and :",
  "Connection to Previous Set Descriptors and the Wasserstein Distance": "Classical set descriptors. Many prior methods have been used to describe sets of image elements, amongthem Bag-of-Features Csurka et al. (2004), VLAD Jgou et al. (2010), and Fisher-Vectors Snchez et al.(2013). These methods begin with a preliminary clustering stage (K-means or Gaussian Mixture Model).They then describe the set using the zeroth, first, or second moments of each cluster. The comparison inAppendix B shows that our method outperforms clustering-based methods in describing our feature sets. Wasserstein distance. Our method is closely related to the Wasserstein distance, which measures theminimal distance required to transport the probability mass from one distribution to the other. As computingthe Wasserstein distance for high-dimensional data such as ours is computationally demanding, the SlicedWasserstein Distance (SWD) Bonneel et al. (2015), was proposed as an alternative. The SWD1 between twosets, x and y, has a particularly simple form:",
  "where hP x, hP y are the random projections histogram of sets x and y, that we defined in Sec.3.3": "As the histogram projections have a high correlation between them, it is necessary to decorrelate them. Thisis done here using a Gaussian model. We refer to Appendix G for an explanation of why a Gaussian modelis appropriate here. The Mahalanobis distance used here therefore performs better than the simple SWD1distance. While this weakens the connection to the Wasserstein distance, this was crucial for most time-seriesdatasets (see ). In practice, we opted to use kNN with the Mahalanobis distance rather than simplycomputing the Mahalanobis distance to as it worked slightly better (see Appendix B). We note that the Sliced Wasserstein distance can be calculated directly, without using the suggested histogrambinning. However, our histogram-based approach is necessary for our density estimation method. Namely, tocompute kNN using the Mahalanobis distance, we require a feature representation for each point, rather than",
  "Images as Sets": "Images can be seen as consisting of a set of elements at different levels of granularity. This ranges from pixelsto small patches, to low-level elements such as lines or corners, up to high-level elements such as objects. Foranomaly detection, we typically do not know in advance the correct level of granularity for separating betweennormal and anomalous samples (Heckler et al., 2023). The correct level may depend on the anomalies wewill encounter, which are unknown during training. Instead, we use multiple levels of granularity, describingimage patches of different sizes, and combine their scores. In practice, we use representations from intermediate blocks of a pre-trained ResNet (He et al., 2016). As aResNet network simultaneously embeds many local patches of each image, we pass the image samples throughthe network encoder and extract our representations from the intermediate activations at the end of differentResNet blocks (see ). We define each spatial location in the activation map as an element. Note that asdifferent blocks have different resolutions, they yield different numbers of elements per layer. We run our setmethods with the elements at the end of each residual block used and combine the results in an ensemble asdetailed in the appendix (App.C.1).",
  "Time Series as Sets": "Time series data can be viewed as a set of temporal windows. Similarly to images, it is generally not knownin advance which temporal scale is relevant for detecting anomalies. I.e., what is the duration of windowswhich includes the semantic phenomenon. Inspired by Rocket Dempster et al. (2020), we define the basicelements of a time series as a collection of temporal window pyramids. Each pyramid contains L windows.All the windows in a pyramid are centered at the same time step, each containing samples (). Thefirst level window includes elements with stride 1, the second level window includes elements with stride",
  "Logical Anomaly Detection Results": "Logical Anomalies Dataset. We use the recently published MVTec-LOCO dataset Bergmann et al.(2022) to evaluate our methods ability to detect anomalies caused by unusual configurations of normalelements. This dataset features five different classes: breakfast box, juice bottle, pushpins, screw bag andsplicing connector (see ). Each class includes: (i) a training set of normal samples ( 350 samples). (ii)a validation set, containing a smaller set of normal samples ( 60 samples). (iii) a test set, containing normalsamples, structural anomalies, and logical anomalies ( 100 each). The anomalies in each class are divided into structural anomalies and logical anomalies. Structural anomaliesfeature local defects, somewhat similar to previous datasets such as Bergmann et al. (2019). Conversely,logical anomalies may violate logical conditions expected from the normal data. As one example, an anomalymay include a different number of objects than the numbers expected from a normal sample (while all thefeatured object types exist in the normal class; see ). Other types of logical anomalies in the datasetmay include cases where distant parts of an image must correlate with one another. For instance, within thenormal data, the color of one object may correlate with the length of another object. These correlations maybreak in an anomalous sample. Baselines. We compare to baseline methods used by the paper which presented the MVTec-LOCO datasetBergmann et al. (2022): Variational Model (VM) Steger (2001), MNAD, f-AnoGAN Schlegl et al. (2017),AE / VAE. Student Teacher (ST), SPADE, PatchCore (PCore) Roth et al. (2022). We also compare toGCAD Bergmann et al. (2022) - a reconstruction-based method, based on both local and global deep ResNetfeatures, which was explicitly designed for logical anomaly detection; EfficientAD - Batzner et al. (2023),a reconstruction-based method with a loss aimed at preventing an autoencoder from reconstructing wellanomalous unseen images. We also report the results by PUAD Sugawara & Imamura (2024), an ensemble",
  "Metric. Following the standard metric in image-level anomaly detection we use the ROC-AUC metric": "Results. We report per-class results on image-level detection of logical anomalies and structural anomaliesin Tab.1. Interestingly, we find complementary strengths between our approach and GCAD, a reconstruction-based approach by Bergmann et al. (2022). Although GCAD performed better on specific classes (e.g.,pushpins), our approach provides better results on average. Notably, our approach provides non-trivialanomaly detection capabilities on the screw bag class, while baseline approaches are close to the randombaseline performance (which is 50% ROC-AUC). EfficientAD Batzner et al. (2023), focuses on structuralanomalies and achieves impressive results on them, but underperforms on logical anomalies (see Tab.2). As our method is comparatively strong on specific classes (e.g., Screw bag, Logical, 81.1% compared to56.0% of GCAD and 55.5% of EfficientAD), it serves as a valuable component in ensemble methods. Forexample, a simple combination of our method with EfficientAD Batzner et al. (2023) (SINBAD+EfficientAD)outperforms all other methods and ensembles (See table 2). Our approach also improves upon detection-by-segmentation methods in detecting structural anomalies insome classes. This is somewhat surprising, as one may assume that detection-by-segmentation approacheswould perform well in these cases. One possible reason for that is the high variability of the normal datain some of the classes (e.g., breakfast box, screw bag, ). This high variability may induce false positivedetections for baseline approaches. While different methods provide complementary strengths, on average,our method provides state-of-the-art results in logical anomaly detection. See also the discussion at Sec.6.",
  "Time Series anomaly Detection Results": "Time series dataset. We evaluate on the five datasets used in NeurTraL-AD Qiu et al. (2021): RacketSports(RS). Accelerometer and gyroscope recordings of players playing different racket sports. Each sport isdesignated as a class. Epilepsy (EPSY). Accelerometer recording of healthy actors simulating four activityclasses, e.g. an epileptic shock. Naval air training and operating procedures standardization (NAT). Positionsof sensors mounted on body parts of a person performing activities. There are six different activity classes inthe dataset. Character trajectories (CT). Velocity trajectories of a pen on a tablet. There are 20 charactersin this dataset. Spoken Arabic Digits (SAD). MFCC features ten Arabic digits spoken by 88 speakers. Baselines. We compare the results of several baseline methods reported by Qiu et al. (2021). The methodscover the following paradigms: One-class classification: One-class SVM (OC-SVM), and its deep versions,DeepSVDD (DSVDD) Ruff et al. (2018), DROCC Goyal et al. (2020). Tree-based detectors: Isolation Forest(IF) Liu et al. (2008). Density estimation: LOF, a version of nearest neighbor anomaly detection Breuniget al. (2000). DAGMM (DAG) Zong et al. (2018): density estimation in an auto-encoder latent space.Auto-regressive methods - RNN and LSTM-ED (ED) - deep neural network-based version of auto-regressiveprediction models Malhotra et al. (2016). Transformation prediction - GOAD Bergman & Hoshen (2020) and",
  "Metric. Following Qiu et al. (2021), we use the series-level ROC-AUC metric": "Results. Our results are presented in Tab. 3. We can observe that different baseline approaches areeffective for different datasets. kNN-based LOF is highly effective for SAD which is a large dataset butachieves worse results for EPSY. Auto-regressive approaches achieve strong results on CT. Transformation-prediction approaches, GOAD and NeuTraL achieve the best performance of all the baselines. The learnedtransformations of NeuTraL achieved better results than the random transformations of GOAD. Our methodachieves the best overall results both on average and individually on all datasets apart from SAD, where it iscomparable but a little lower than NeuTraL. We note that unlike NeuTraL, our method is far simpler, doesnot use deep neural networks, and is very fast to train and evaluate. It also has fewer hyperparameters.",
  "Implementation Details": "We provide here the main implementation details for our image anomaly detection application. Furtherimplementation details for the image application can be found in App.C.1; Implementation details for thetime series application can be found in the supplementary material in App.C.2. ResNet levels. We use the representations from the 3rd and 4th blocks of a WideResNet502 (resultingin sets size 7 7 and 14 14 elements, respectively). We also use all the raw pixels in the image as anadditional set (resized to 224 224 elements). The total anomaly score is the average of the anomaly scoresobtained for the set of 3rd ResNet block features, the set of 4th ResNet block features, and the set of rawpixels. The average anomaly score is weighted by the following factors (1, 1, 0.1) respectively (see App.D forour robustness to the choice of weighting factor). Multiple crops for image anomaly detection. Describing the entire image as a single set might sometimeslose discriminative power when the anomalies are localized. To mitigate this issue, we can treat only a partof an image as our entire set. To do so, we crop the image to smaller images by a factor of c, and comparethe elements taken from each crop. We compute an anomaly score for each crop scale and for each centerlocation. We then average over the anomaly scores of the different crop center locations for the same cropscale c. Finally, for each ResNet level, we average the anomaly scores over the different crop scales. Weuse crop scales of {1.0, 0.7, 0.5, 0.33}. The different center locations are taken with a stride of 0.25 of theentire image. We observe that combining different scales offers only a marginal advantage (see Tab.4), whilebaseline methods require significantly more forward passes through the feature extractors Roth et al. (2022).",
  "We present ablations for the image logical AD methods. For further ablations of the histogram parametersand for the time series application, see appendix F": "Using individual ResNet levels. In Tab.4 we report the results when different components of ourmulti-level ResNet ensemble are removed. We report the results using only the representation from the thirdor fourth ResNet block (Only 3 / Only 4). We also report the results using both ResNet blocks butwithout the raw-pixels level (No Pixels). No multiple crops ablation. We also report our results without the multiple crops ensemble (described inSec.5.3). We feed only the entire image for the set extraction stage (Only full). As expected, using multiplereceptive fields is beneficial for classes where small components are important to determine abnormality. Ablating our histogram density-estimation method. In Tab.5 we ablate different aspects of ourhistogram set descriptors. Sim. Avg. We show a simple averaging Lee et al. (2018) of the set features (seealso ), ablating our entire set-features approach. This yields a significantly worse performance. Noproj. We ablate our use of random projections (Sec.3.3). We replace the random histograms with similar",
  "Average79.782.285.586.1": "histograms using the raw given features. No whit. We ablate our Gaussian modeling of the set features. Thewhitening is not essential for the image modality, as it is for the time-series data (see Tab.12). We comparethese variants of our method using the 3rd and 4th ResNet blocks, as the raw pixels level adds significantvariance overshadowing the difference between some of the alternatives. While ablation may give strongerresults in specific cases, our set approach together with the random projections and whitening generallyoutperforms. Ablating the number of bins and the number of projections. While generally we would like to haveas many random projections as possible; and a large number of bins per histogram, as long we have enoughstatistics to estimate the occupancy in each of them; We find that in practice the values we choose are largeenough. We show in the App. Tab.10,11 that while significantly lower values in these parameters degrade ourperformance, the benefit from using larger values saturates.",
  "Discussion": "Complementary strength of density estimation and reconstruction based approaches for logicalanomaly detection. Our method and GCAD Bergmann et al. (2022), a reconstruction-based approach,exhibit complementary strengths.Our method is most suited to detect anomalies resulting from thedistribution of featured objects in each image. E.g., object replacements, additional or missing objects, orcomponents indicating a logical inconsistency with the rest of the image. The generative modeling by GCADgives stronger results when the positions of the objects are anomalous. E.g., one object containing anotherwhen it should not, or vice versa, as in the Pushpins class. The intuition here is that our approach treats thepatches as an unordered set, and might not capture exact spatial relations between the objects. Therefore, itmay be a natural direction to try and use both approaches together. A practical way to take advantage ofboth approaches would be an ensemble as we suggest in Sec.5. Ultimately, future research is likely to lead tothe development of better approaches, combining the strengths of both methods. Relation to previous random projection methods. Our method is related to several previous methods.HBOS Goldstein & Dengel (2012) and LODA Pevn`y (2016) also used similar projection features for anomalydetection. Yet, these methods perform histogram-based density, ignoring the dependency across projections.As they can only be applied to a single element, they do not achieve competitive performance for time seriesAD. Rocket and mini-rocket Dempster et al. (2020; 2021) also average projection features across selectedwindows from a given sample but do not apply to image data.",
  "Limitations": "Detecting structural anomalies. Our approach aims to detect specific, yet important, types of anomalies- image-level logical anomalies and the analogues time-series sequence-level anomalies. It is not particularlyeffective for detecting local structural anomalies, such as scratches or dents in images of objects Bergmannet al. (2019); Zou et al. (2022), object-level anomalies Reiss et al. (2021), or local time-series anomaliesBlzquez-Garca et al. (2021). We evaluate our method on appropriate datasets. Currently, only one datasetevaluates logical anomalies Bergmann et al. (2022). Yet, this very comprehensive dataset contains 5 differentsub-tasks, where each sub-task features numerous different types of anomalies. An anomaly detection methodmust rely on some assumptions regarding the nature of the anomalies one wishes to discover (Reiss et al.,2023). Therefore, when the type of anomalies is unknown, we recommend combining our method withmethods tailored to different types of anomalies (Reiss et al., 2022; Roth et al., 2022; Batzner et al., 2023). Element-level anomaly detection. Our method focuses on sequence-level time series and image-levelanomaly detection. In some applications, a user may also want a segmentation map of the most anomalouselements of each sample. We note that for logical anomalies, this is often not well defined. E.g., when wehave an image with 3 nuts as opposed to the normal 2, each of them may be considered anomalous. Toprovide element-level information, our method can be combined with current segmentation approaches byincorporating the knowledge of a global anomaly. E.g., removing false positive segmentations if an image isnormal. Directly applying our set features for anomaly segmentation is left for future research. Class-specific performance. In some classes we do not perform as well compared to baseline approaches.A better understanding of the cases where our method fails would be beneficial for deploying it in practice.",
  "Conclusion": "We presented a method for detecting anomalies caused by unusual combinations of normal elements. Weintroduce set features dedicated to capturing such phenomena and demonstrate their applicability for imagesand time series. Extensive experiments established the strong performance of our method. As with anyanomaly detection method, our approach is biased to detect some abnormality modes rather than others.Using a few anomaly detection methods together may allow enjoying their complimentary benefits, and isadvised in many practical cases.",
  "Liron Bergman and Yedid Hoshen. Classification-based anomaly detection for general data. In InternationalConference on Learning Representations, 2020": "Paul Bergmann, Michael Fauser, David Sattlegger, and Carsten Steger. Mvtec ada comprehensive real-worlddataset for unsupervised anomaly detection. In Proceedings of the IEEE/CVF conference on computervision and pattern recognition, pp. 95929600, 2019. Paul Bergmann, Kilian Batzner, Michael Fauser, David Sattlegger, and Carsten Steger. The mvtec anomalydetection dataset: a comprehensive real-world dataset for unsupervised anomaly detection. InternationalJournal of Computer Vision, 129(4):10381059, 2021. Paul Bergmann, Kilian Batzner, Michael Fauser, David Sattlegger, and Carsten Steger. Beyond dents andscratches: Logical constraints in unsupervised anomaly detection and localization. International Journal ofComputer Vision, 130(4):947969, 2022.",
  "Nicolas Bonneel, Julien Rabin, Gabriel Peyr, and Hanspeter Pfister. Sliced and radon wasserstein barycentersof measures. Journal of Mathematical Imaging and Vision, 51(1):2245, 2015": "Loc Bontemps, Van Loi Cao, James McDermott, and Nhien-An Le-Khac. Collective anomaly detectionbased on long short-term memory recurrent neural networks. In International conference on future dataand security engineering, pp. 141152. Springer, 2016. Markus M Breunig, Hans-Peter Kriegel, Raymond T Ng, and Jrg Sander. Lof: identifying density-basedlocal outliers. In Proceedings of the 2000 ACM SIGMOD international conference on Management of data,pp. 93104, 2000.",
  "Niv Cohen and Yedid Hoshen. Sub-image anomaly detection with deep pyramid correspondences. arXivpreprint arXiv:2005.02357, 2020": "Gabriella Csurka, Christopher Dance, Lixin Fan, Jutta Willamowski, and Cdric Bray. Visual categorizationwith bags of keypoints. In Workshop on statistical learning in computer vision, ECCV, volume 1, pp. 12.Prague, 2004. Anirban Dasgupta, Ravi Kumar, and Tams Sarls. Fast locality-sensitive hashing. In Proceedings of the 17thACM SIGKDD international conference on Knowledge discovery and data mining, pp. 10731081, 2011.",
  "Kaiming He, Xiangyu Zhang, Shaoqing Ren, and Jian Sun. Deep residual learning for image recognition. InProceedings of the IEEE conference on computer vision and pattern recognition, pp. 770778, 2016": "Lars Heckler, Rebecca Knig, and Paul Bergmann. Exploring the importance of pretrained feature extractorsfor unsupervised anomaly detection and localization. In Proceedings of the IEEE/CVF Conference onComputer Vision and Pattern Recognition, pp. 29162925, 2023. Dan Hendrycks, Mantas Mazeika, Saurav Kadavath, and Dawn Song. Using self-supervised learning canimprove model robustness and uncertainty. In Advances in Neural Information Processing Systems, pp.1566315674, 2019.",
  "Eliahu Horwitz and Yedid Hoshen. An empirical investigation of 3d anomaly detection and segmentation.arXiv preprint arXiv:2203.05550, 2022": "Herv Jgou, Matthijs Douze, Cordelia Schmid, and Patrick Prez. Aggregating local descriptors into acompact image representation. In 2010 IEEE computer society conference on computer vision and patternrecognition, pp. 33043311. IEEE, 2010. Stepan Jezek, Martin Jonak, Radim Burget, Pavel Dvorak, and Milos Skotak. Deep learning-based defectdetection of metal parts: evaluating current methods in complex conditions. In 2021 13th InternationalCongress on Ultra Modern Telecommunications and Control Systems and Workshops (ICUMT), pp. 6671.IEEE, 2021.",
  "Fei Tony Liu, Kai Ming Ting, and Zhi-Hua Zhou. Isolation forest. In 2008 Eighth IEEE InternationalConference on Data Mining, pp. 413422. IEEE, 2008": "Pankaj Malhotra, Anusha Ramakrishnan, Gaurangi Anand, Lovekesh Vig, Puneet Agarwal, and GautamShroff. Lstm-based encoder-decoder for multi-sensor anomaly detection. arXiv preprint arXiv:1607.00148,2016. F. Pedregosa, G. Varoquaux, A. Gramfort, V. Michel, B. Thirion, O. Grisel, M. Blondel, P. Prettenhofer,R. Weiss, V. Dubourg, J. Vanderplas, A. Passos, D. Cournapeau, M. Brucher, M. Perrot, and E. Duchesnay.Scikit-learn: Machine learning in Python. Journal of Machine Learning Research, 12:28252830, 2011.",
  "Tal Reiss, Niv Cohen, and Yedid Hoshen. No free lunch: The hazards of over-expressive representations inanomaly detection. arXiv preprint arXiv:2306.07284, 2023": "Oliver Rippel, Patrick Mertens, and Dorit Merhof. Modeling the distribution of normal data in pre-traineddeep features for anomaly detection. In 2020 25th International Conference on Pattern Recognition (ICPR),pp. 67266733. IEEE, 2021. Karsten Roth, Latha Pemula, Joaquin Zepeda, Bernhard Schlkopf, Thomas Brox, and Peter Gehler. Towardstotal recall in industrial anomaly detection. In Proceedings of the IEEE/CVF Conference on ComputerVision and Pattern Recognition, pp. 1431814328, 2022.",
  "Manzil Zaheer, Satwik Kottur, Siamak Ravanbakhsh, Barnabas Poczos, Russ R Salakhutdinov, and Alexander JSmola. Deep sets. Advances in neural information processing systems, 30, 2017": "Bo Zong, Qi Song, Martin Renqiang Min, Wei Cheng, Cristian Lumezanu, Daeki Cho, and Haifeng Chen. Deepautoencoding gaussian mixture model for unsupervised anomaly detection. In International Conference onLearning Representations, 2018. Yang Zou, Jongheon Jeong, Latha Pemula, Dongqing Zhang, and Onkar Dabeer. Spot-the-difference self-supervised pre-training for anomaly detection and segmentation. In European Conference on ComputerVision, pp. 392408. Springer, 2022.",
  "AFull Results Tables": "The full table for the image logical anomaly detection experiment can be found in Tab.6. The full table forthe time series anomaly detection experiments including error bounds for our method and baselines thatreported them can be found in Tab.7. The difference between the methods is significantly larger than thestandard error.",
  "BSet descriptor comparison": "Clustering-based set descriptors. We compare our histogram-based approach to the VLAD and Bag-of-Features approaches. We report our results in Tab.8. We use the number of means K = 100 cluster, butthis result persists when we varied the number of clusters. We do not report the results on Fisher-Vectorsas the underlying GMM model (unlike K-means) requires unfeasible computational resources with our setdimensions. Taken together, it seems that the underlying clustering assumption does not fit the sets we wishto describe as well our set descriptors. kNN versus distance to the mean. We found that using the Gaussian model only to whiten the data andtaking the distance to the 1 nearest neighbors (and not to the center) worked better for the MVTec-LOCOdataset (see Tab.8). The nearest neighbors density estimation algorithm better models the density distributionwhen the Gaussian assumption is not an accurate description of the data.",
  "C.1Image Anomaly Detection": "Parameters. For the image experiments, we use histograms of K = 5 bins and r = 1000 projections. Forthe raw-pixels layer, we used a projection dimension of r = 10 and no whitening due to the low number ofchannels. To avoid high variance between runs, we did 32 different repetitions for the raw-pixel scoring andused the median score. We use k = 1 for the kNN density estimation.",
  "Preprocessing. Before feeding each image sample to the pre-trained network we resize it to 224 224 andnormalize it according to the standard ImageNet mean and variance": "Considering that classes in this dataset are provided in different aspect ratios, and that similar objects maylook different when resized to a square, we found it beneficial to pad each image with empty pixels. Thepadded images have a 1 : 1 aspect ratio, and resizing them would not change the aspect ratio of the featuredobjects. Software. For the whitening of image features we use the ShrunkCovariance function from the scikit-learnlibrary Pedregosa et al. (2011) with its default parameters. For kNN density estimation we use the faisslibrary Johnson et al. (2019).",
  "C.2Time Series Anomaly Detection": "UEA Experiments. We used each time series as an individual training sample. We chose a kernel size of = 9, r = 100 projection, K = 20 quantiles, and a maximal number of pyramid levels of L = 10, each usingconsecutive strides. The results varied only slightly within a reasonable range of the hyperparameters. E.g.using 5, 10, 15 levels yielded an average ROCAUC of 97, 96.8, 96.8 across the five UEA datasets.",
  "Padding. Prior to window extraction, the series x is first right and left zero-padded by": "2 to form a paddedseries x. The first window w1 is defined as the first observations in padded series S, i.e. w1 = x1, x2..x.We further define windows at higher scales W s, which include observations sampled with stride c. At scale c,the original series x is right and left zero-padded by c",
  "FTime Series Anomaly Detection Ablations": "Number of projections. Using a high output dimension for projection matrix P increases the expressivelybut also increases the computation cost. We investigate the effect of the number of projections on the finalaccuracy of our method. The results are provided in . We can observe that although a small number of",
  "projections hurts performance, even a moderate number of projections is sufficient. We found 100 projectionsto be a good tradeoff between performance and runtime": "Number of bins. We compute the accuracy of our method as a function of the number of bins per projection.Our results () show that beyond a very small number of bins, a larger number of bins does not help.We found 20 bins to be sufficient in all our experiments. Effect of Gaussian density estimation. We ablate the use of Gaussian modeling in Tab. 12 (QuantizedSWD). We can see that our approach achieves far better results, attesting to the importance of modeling thecorrelation between projections. Comparison to the Sliced Wasserstein distance. In Sec.3.5 we highlight the connection between ourapproach and the Sliced Wasserstein distance. An empirical comparison between the approaches can befound in Tab. 12. Our results show that computing the SWD without histogram binning can be much moreaccurate than with binning (Quantized SWD). However, the binning is necessary for our whitening technique(Sec.3.4), which significantly outperforms standard SWD. We also note that increasing the number of bins(making the quantization finer) does not improve the accuracy of our full approach. Comparing projection sampling methods. We compare three different projection selection procedures:(i) Gaussian: sampling the weights in P from a random Normal Gaussian distribution (ii) Using an identityprojection matrix: P = I . (iii) PCA: selecting P from the eigenvectors of the matrix containing all (raw)features of all training windows. PCA selects the projections with maximum variation but is computationallyexpensive. The results are presented in Tab. 13. We find that the identity projection matrix under-performedthe other approaches (as it provides no variable mixing). Surprisingly, we do not see a large difference betweenPCA and random projections.",
  "GUsing the Central Limit Theorem for Set Anomaly Detection": "We model the features of each window f as a normal set as IID observations coming from a probabilitydistribution function p(f). The distribution function is not assumed to be Gaussian. Using a Gaussiandensity estimator trained on the features of elements observed during training is unlikely to be effective forelement-level anomaly detection (due to the non-Gaussian p(f)). An alternative formulation to the one presented in section 3, is that each feature f is multiplied by projectionmatrix P, and then each dimension is discretized and mapped to a one-hot vector according to its relevanthistogram bin. This formulation therefore maps the representation of each element to a sparse binary vector.The mean of this one-hot vector representation of elements in the set recovers the normalized histogramdescriptor precisely (therefore this formulation is equivalent to the one in section 3). As the histogramis a mean of the one-hot representations of elements, it has superior statistical properties. In particular,the Central Limit Theorem states that under common conditions the sample mean follows the Gaussiandistribution. While typically in anomaly detection only a single sample is presented at a time, the situationis different when treating samples as sets. Although the elements are often not IID, given a multitude ofelements, an IID approximation may still be applicable. This explains the high effectiveness of Gaussiandensity estimation in our formulation.",
  "HFurther Discussion": "Incorporating deep features for time series data. Our method outperforms the state-of-the-art in timeseries anomaly detection without using deep neural networks. While this is an interesting and surprisingresult, we believe that deep features will be incorporated into similar approaches in the future. One directionfor doing this is replacing the window projection features with a suitable deep representation, while keepingthe set descriptors and Gaussian modeling steps unchanged. Fine-tuning deep features for anomaly detection. Following recent works in anomaly detection andanomaly segmentation, we used fixed pre-trained features as the backbone of our method. Although somemethods fine-tune deep features for anomaly detection based on the normal-only training set, we keep themconstant. Doing so allows an interpretable examination of the relative strength of our novel scoring functionwith respect to prior works that use fixed features. Yet, we expect that fine-tuning such features could leadto further gains in the future."
}