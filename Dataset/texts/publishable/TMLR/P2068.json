{
  "Abstract": "Searching the vast chemical space for drug-like molecules that bind with a protein pocketis a challenging task in drug discovery. Recently, structure-based generative models havebeen introduced which promise to be more efficient by learning to generate molecules forany given protein structure. However, since they learn the distribution of a limited protein-ligand complex dataset, structure-based methods do not yet outperform optimization-basedmethods that generate binding molecules for just one pocket. To overcome limitations ondata while leveraging learning across protein targets, we choose to model the reward distri-bution conditioned on pocket structure, instead of the training data distribution. We designTacoGFN, a novel GFlowNet-based approach for structure-based drug design, which cangenerate molecules conditioned on any protein pocket structure with probabilities propor-tional to its affinity and property rewards. In the generative setting for CrossDocked2020benchmark, TacoGFN attains a state-of-the-art success rate of 56.0% and 8.44 kcal/molin median Vina Dock score while improving the generation time by multiple orders of mag-nitude. Fine-tuning TacoGFN further improves the median Vina Dock score to 10.93kcal/mol and the success rate to 88.8%, outperforming all optimization-based methods.",
  "Introductions": "Structure-based drug design (SBDD) leverages target protein structures to search for high-affinity drugmolecules. Due to the growing availability of protein structures from ML protein structure prediction meth-ods (Jumper et al., 2021), and many novel targets identified from high-throughput perturbation experiments(Replogle et al., 2022), SBDD is becoming an increasingly powerful approach in drug discovery. It currentlytakes 13-15 years and between US $2 billion and $3 billion for a single drug to be developed and approved(Pushpakom et al., 2018). The substantial expense and time of drug development not only impose a sig-nificant burden on healthcare systems but also amplify societal risks during global health crises, such asCOVID-19. There is an urgent need to expedite the design of novel drug candidates for new protein targets. Traditionally, virtual screening has been used to discover binding molecules by predicting supramolecularinteractions between ligands and a target protein with molecular docking. Its efficacy is impeded by theexhaustive nature of its search, and by the high computational cost of molecular docking. To overcomethis challenge, many optimization-based methods (Bengio et al., 2021; Fu et al., 2022; Lee et al., 2023;Reidenbach, 2024) have been proposed to generate high-affinity molecules for one protein pocket only. Thesemethods typically do not take protein structure as input and use docking measures as the reward. Recently,structure-based generative models (Luo et al., 2021; Peng et al., 2022; Guan et al., 2023b) have been proposed",
  "Published in Transactions on Machine Learning Research (09/2024)": "(Luo et al., 2021) and contains one ligand per each pocket. We re-docked each test ligand to perform theevaluation in the same environment as the generation process. ZINCDock-test is the docking simulationdata of randomly selected 100 ZINC20 molecules for each pocket in CrossDocked-100k-test. The size of thetest sets is 100 pocket-ligand pairs for the CrossDocked-100k-test and 10,000 pocket-ligand pairs for theZINCDock-test.",
  "Related Work": "Structure-based molecular generation aims to generate high-affinity molecules for any target pocket.They are expected to generalize on previously unseen test pockets, and therefore, do not have access to thedocking oracle for the test pockets during inference or training time. The goal for evaluating the qualityof molecules generated for unseen protein structures is to measure whether SBDD models have learnedgeneralized protein-ligand interaction patterns during training. Many approaches for this problem settinghas been proposed. LiGAN (Masuda et al., 2020) uses 3D CNNs to encode the protein pocket structure andpredict atom densities from the encoded latent space. 3DSBDD (Luo et al., 2021) and Pocket2Mol (Penget al., 2022) adopt an auto-regressive approach to generate molecules atom by atom. Other methods suchas FLAG (Zhang et al., 2023b) and DrugGPS (Zhang & Liu, 2023) build molecules fragment by fragment toleverage the chemical prior. A very recent line of research employs diffusion models (Guan et al., 2023a;b;Schneuing et al., 2023) for SBDD. TargetDiff (Guan et al., 2023a) is a diffusion-based method which generatesatom coordinates and atom types in a non-autoregressive way, and bonds are generated in a post-processingstep. DecompDiff (Guan et al., 2023b) is a diffusion model which generates both atoms and bonds withdecomposed priors, which reflect the natural decomposition of a ligand molecule into arms and scaffold.A recent analysis paper (Harris et al., 2023) questions the assumption that explicit 3D modelling of theligand improves performance, after finding a much higher occurrence of physical violations and fewer keyinteractions in molecules generated using 3D modelling. In our work, we generate molecules in 2D space tovastly reduce the search space and compute time; Our approach is shown to effectively leverage the targetpocket structure for generating molecules with high affinity. Optimization-based molecular generation aims to generate molecules that satisfy certain optimizationgoals. Compared to the distribution-based generative model, these methods can be designed to optimize formolecules with strong binding affinity to a particular protein target. Since they have access to a docking oracleduring training or inference time, they are not directly comparable to the structure-based generative problemsetting. Reinforcement Learning (RL) methods such as ReLeaSE (Olivecrona et al., 2017), MolDQN (Zhouet al., 2019) and REINVENT (Blaschke et al., 2020) have been proposed to guide the generation of moleculestoward desirable properties. MORLD (Jeon & Kim, 2020) and MoleGuLAR (Goel et al., 2021b) combineRL and docking calculations to design novel ligands. RGA (Fu et al., 2022) proposes a variant of a geneticalgorithm that is guided by reinforcement learning and is pre-trained on multiple protein target structures.MOOD (Lee et al., 2023) incorporates out-of-distribution and property-guided exploration in diffusion modelsfor goal-directed molecule generation. DecompOpt Zhou et al. (2024) combines a pre-trained structure-basedequivariant diffusion model with a docking-based greedy iterative optimization loop. EvoSBDD Reidenbach(2024) improves efficiency by performing black-box optimization over the 1D latent space using a dockingoracle. In summary, optimization-based molecular generation evaluates the performance of the algorithmon optimizing for seen targets.Compared to the structure-based setting, which requires modelling themolecule distribution conditional to any protein pocket structure and generalizing to unseen protein pockets,optimizing the molecule distribution for a single protein pocket is a less challenging task. We refer readersto a more detailed comparison of the problem setting in Appendix B.",
  "GFlowNet Preliminaries": "Generative Flow Networks (GFlowNets, GFN) (Bengio et al., 2021) learn a stochastic policy for generatinga combinatorial object (such as molecular graph) x X. The probability of constructing x, denoted as (x),is trained to be proportional to a non-negative reward function R : X R+ defined on the space X.This property of GFlowNet is ideal for generating diverse molecules with desirable properties. ConditionalGFlowNet introduced in (Jain et al., 2023) simultaneously models a family of reward functions.Eachconditional information, denoted as c C, induces a unique reward function R(x|c). In our work, we adoptconditional GFlowNet for SBDD settings, by encoding target pocket structure as condition c, where c isa high dimensional representation of the pocket structure. Thus, a single GFlowNet models high-rewardmolecule distribution across all protein pockets. Each object x is constructed from a sequence of actions a A. In molecular settings, a molecule is constructedby inserting molecule fragments into a partially constructed fragment graph state s S (Bengio et al.,2021). Conceptually, a GFlowNet is an acyclic graph G = (S, E), with nodes S and edges E. Each transitions s E via action a A corresponds to an edge in graph G. The transition function T : S, A Scomputes the new state s = T (s, a) given action a on state s. A special action moves state s into terminatingstates X S. We define the initial empty graph as s0. Construction of x can be defined over a trajectoryof states = (s0s1 . . . x). Following previous studies, we introduce an exponent to the reward function R(x|c), thus modelling(x|c, ) R(x|c). This steers generating probability distribution to focus on the modes of R(x|c), whichis crucial for producing candidates that are high in reward. Adjusting allows us to manage the balancebetween diversity and achieving higher rewards. The forward transition probability PF (s|s, c, ) of a GFlowNet represents the probability distribution ofreaching state s from state s conditioned on context c and reward temperature . Partition function Z(c, )is the sum of the rewards R(x|c) for all objects x X under context c. We adopt the Trajectory Balanceobjective from Equation 1 to efficiently learn a forward transition policy PF that generates object x withprobability proportional to its reward R(x|c) (Malkin et al., 2023).",
  "TacoGFN": "TacoGFN is a structure-based molecular generative model that generalizes over all protein pockets with asingle model. By matching the reward distribution instead of limited data distribution, our method exploresthe greater chemical space to generate high-affinity molecules with properties desirable as a drug candidate.Furthermore, by encoding pocket structure information, TacoGFN and its fine-tuned variant are able toleverage learning from diverse protein pocket structures.",
  "Pocket structure encoder": "We represent structure of the pocket P as a standard K-nearest neighbor (KNN) residue graph GP =(VP, EP) - following previous work in protein representation (Jing et al., 2021).The i-th residue nodevPi VP is featurized using its geometric and chemical properties.These features include the type ofresidue, the dihedral angles of the atoms in the residue backbone, and the directional unit vectors. An edgeePij EP is formed if the j-th residue vPj is among the K-nearest neighbors of residue vPi , as measured by theeuclidean distance between their respective Ca atoms. We set the number of neighbours K = 30. An edgeis featurized with the Euclidean distance, distance along the backbone and the direction vector between thetwo residues. These features sufficiently describe the features of the protein pocket. We apply a graph neural network with geometric vector perceptrons (GVP) layers (Jing et al., 2021) to theKNN pocket graph GP to learn the node embedding hvPi for each residue. The node embeddings {hvPi } arethen averaged to obtain an embedding of the entire graph hGP. We use GVP because it encodes the proteinpocket into an embedding that is invariant to rotations and translations.",
  "Pocket conditioned GFlowNet": "In this section, we discuss how to employ the pocket structure, more specifically its latent embedding, tocondition the GFlowNet to generate molecules that interact with a given protein pocket. Furthermore, wedescribe our fragment-based molecular generation framework. Molecule representation. During molecular generation, we represent ligands as a 2D molecular graphGL = (VL, EL) with node vLi VL representing a molecule fragment, and directional edges eLij EL indicatingthe attachment atom of fragment vLi that connects to fragment vLj . Since a molecules reward (representingits desirability as a real-world drug) should be the same regardless of its predicted 3D conformation, werepresent ligands as 2D graphs here. 1 Fragment vocabulary construction. TacoGFN generates molecules by adding one molecular fragmentat a time.To create the vocabulary of fragments used, we extract common fragments from a chemicaldatabase in a data-driven and chemically valid way. To obtain a fragment vocabulary, we first apply BRICSdecomposition (Degen et al., 2008) to 250k ZINC20 (Irwin et al., 2020) molecules. BRICS breaks molecules 1Docking score is dependent on a molecules 3D conformation. However, we consider the best docking score for a moleculeas the reward here, which is invariant to its conformation in this context. Taking the best docking score is a valid approach,because when a compound is tested for binding in the wet lab, the compound simply binds the protein with the conformationswhich results in the strongest affinity. Furthermore, the predicted 3D position of generated molecules from existing diffusion-based SBDD models often changes significantly upon re-docking and likely do not reflect the true conformation. (Reidenbach,2024).",
  "GLt+1 = T (at, GLt )(3)": "Previous autoregressive models often formulate action prediction as a supervised task, where the goal is topredict the correct ground truth actions obtained from masked molecules (Peng et al., 2022). Instead, ourmolecule generation policy Pa aims to generate molecules with probability P(GL|hGP) proportional to thereward. Pocket conditioned molecular generation. Here, we adopt the architecture for molecular generation in-troduced in Multi-Objective GFlowNet (MO-GFN) (Jain et al., 2023). Instead of conditioning the GFlowNeton multi-objective preference, we condition the GFlowNet on pocket embeddings to learn a family of molec-ular distributions corresponding to a family of reward functions induced from the pocket structure diversity. We use a graph transformer (Yun et al., 2020) to model the probability Pa(a|GLt , hGP), by taking the partiallyconstructed molecular graph at the t-th time step GLt and the pocket embedding hGP as input. The inputfeature hL(0)iof molecular node vLi is a one-hot encoding of the nodes fragment type. The molecular edgeinput feature eL(0)ijis a one-hot mapping of the attachment atom index in node vLi which connects to nodevLj . We add an additional virtual conditioning node hV (0), featurized using pocket embedding hGP, to thegraph GLt (Pham et al., 2017). This virtual node is connected to all other nodes and serves as a graph-levelnode to provide pocket information. After N Transformer layers, the set of final node embeddings {hL(N)i}and edge embeddings {eL(N)ij} are obtained. The final graph level embedding gL(N) is obtained via theconcatenation of the global average pooling of the node embeddings and the final virtual node embeddinghV (N), as seen in Equation 4.",
  "gL(N) = ConcatAvgPoolhL(N)i, hV (N)(4)": "Using these final molecular graph embeddings, we follow the actions defined in previous works on fragment-based molecular generation (Bengio et al., 2021; Jin et al., 2018). Full details can be found in AppendixC.1.1. Reward function. A drug candidate must not only have a high affinity to the pocket but also satisfydrug-like properties and synthetizability requirements to be selected for experimental validation. We designa reward function by multiplying the normalized score from all three aspects, using QED (Bickerton et al.,2012) as a measure of drug-likeliness, SA (Ertl & Schuffenhauer, 2009) as a measure of ease-of-synthesizability,and predicted docking score as a measure of affinity between ligand and protein2. In drug discovery, it iscrucial to design molecules that simultaneously satisfy all of these relevant properties, despite the inherenttrade-offs among these properties. By multiplying the scores, the reward function ensures that a low score in",
  "any one of the factors (QED, SA, or DS) will significantly reduce the overall reward. Therefore, multiplyingthe scores is a more appropriate choice than summing the scores here": "We just have to optimize QED and SA up to a certain threshold for a molecule to be suitable as a drugcandidate - optimizing them further does not bring additional utility (Coley, 2021). Therefore, we clip thereward for the QED or SA component to 1 when they achieve their respective threshold tQED and tSA. Forexample, the reward function will prioritize more on optimizing QED if tQED is higher, at the expense ofother properties such as affinity (See details of reward function in Appendix C.1.2).",
  "Docking score predictor with pharmacophore prior": "The exploration of chemical space with a GFlowNet requires evaluating binding affinities for millions ofmolecules sampled during training.However, using molecular docking for evaluation is computationallyexpensive. Here, we propose a fast ML-based docking score predictor that generalizes well across moleculeand protein pocket distributions, as described in and Equation 5. (See details in Appendix C.2) We leverage PharmacoNet (Seo & Kim, 2023), a recent deep learning method to obtain the pharmacophoreP3 from a pocket structure P.To enrich the representation, we obtained the embedding of the pocket zP andthe embeddings of pharmacophore points {hPi } from PharmacoNet. The 1D representation vectors of thepharmacophore zP is computed by the global pooling of {hPi } . During docking score prediction, we represent a ligand as an atom-level 2D molecular graph. We applyGraph Isomorphism Network (Hu et al., 2019) to the atom graph to obtain the node embeddings {hLj }. zL is a 1D representation vector of the ligand, obtained by the global pooling of node embeddings {hLj }. Then,we incorporate a pairwise interaction map I - computed from the outer product of {hPi } and {hLj }. Thispreserves the structural topology and binding interaction details. Notably, our docking score predictor usesthe pharmacophore points involved in binding instead of atoms or amino acids to obtain the interaction map.It improves the generalization ability at a reduced computational cost through coarse-grained modelling ofthe pocket at the pharmacophore level.",
  "Dataset": "We train and evaluate TacoGFN on the commonly used CrossDocked benchmark (Francoeur et al., 2020).We first apply the splitting and processing protocol on the CrossDocked dataset to obtain the same trainand test split of the 100k protein-ligand pairs as previous methods (Luo et al., 2021; Peng et al., 2022; Guanet al., 2023b). (See details in Appendix D.1). We then train our docking score predictor on the training splitof the protein-ligand pairs to predict their corresponding Vina Dock scores. Since TacoGFN is trained onthe same set of protein-ligand pairs and evaluated on the same unseen pockets, our experimental results canbe directly compared against the published results of existing structure-based generative models.",
  "Training": "We train one TacoGFN model to generate molecules conditional to any protein target structures usingpredicted affinity, Synthetic Accessibility (SA), and drug-likeness (QED) as the reward.We also adoptDouble GFN (Lau et al., 2023) to improve exploration in sparse reward domains and high-dimensionalstates, by initializing two networks to model the action policy: an online network and a target network. For each training trajectory, one protein pocket is randomly drawn from the CrossDocked training set first.Then, a molecule is generated through sampling a sequence of actions using our target network which modelsthe forward action policy Ptarget. The reward is then computed for that molecule with respect to the proteintarget. The Trajectory Balance loss (Equation 1) is used to train the online network modelling the actionpolicy Ponline. This loss has the objective for our model to generate objects with probabilities proportionalto the rewards (consisting of predicted docking score, QED and SA). Periodically, the weights of the targetnetwork are updated by the weights of the online network using a delayed strategy. This strategy reducestraining instability and promotes explorations of the larger chemical space.",
  "In all evaluations, each structure-based generative model is tasked to produce 100 molecules (ligands) foreach of the 100 unseen protein pockets from the CrossDock-100k test set": "Evaluation metrics. We adopt the following commonly used metrics from Guan et al. (2023a) and Rei-denbach (2024): (1) Validity is the percentage of unique generated molecules free of reconstruction errorsand disconnections as determined by RDKit. (2) Vina Dock approximates the binding energy between agenerated molecule and a protein pocket, where a lower docking score indicates a higher binding affinity.(3) High Affinity measures the percentage of generated molecules with higher affinity than the referencemolecule. (4) QED is a measure of drug-likeness, estimating a molecules suitability as an oral drug basedon its properties (Bickerton et al., 2012). (5) Synthetic Accessibility (SA) estimates difficulty of synthe-sizing the molecule (Ertl & Schuffenhauer, 2009). The score is normalized between 0 and 1 using the formula(10 SA)/9. (6) Diversity is calculated as the average pairwise fingerprint Tanimoto distance betweenmolecules generated for a pocket. (7) Success Rate is the percentage of molecules which pass the samecriteria (QED > 0.25, SA > 0.59, Vina Dock < -8.18) as in Long et al. (2022); Guan et al. (2023b); Zhouet al. (2024); Reidenbach (2024). (8) Time is the average runtime (in seconds) for generating 100 uniqueand valid molecules for a pocket.",
  "Baselines and problem settings. Similar to Zhou et al. (2024) and (Reidenbach, 2024), we separateexisting methods by their problem definitions:": "1) Generative methods are expected to generalize for pocket structures unseen during training.Theygenerate molecules for test pockets at inference time without optimization loops or access to docking pro-grams. Therefore, methods under this setting are only allowed to generate 100 molecules for each pocketin one-shot. We compare TacoGFN trained on CrossDocked-100k against the following generative models:liGAN (Ragoza et al., 2022), GraphBP (Liu et al., 2022), AR (Luo et al., 2021), Pocket2Mol (Penget al., 2022), TargetDiff (Guan et al., 2023a), DiffSBDD (Schneuing et al., 2023), DecompDiff (Guan",
  "Reference--7.45-7.26--0.480.470.730.74--25.0%-": "liGAN--6.33-6.2021.1%11.1%0.390.390.590.570.660.673.9%-GraphBP--4.80-4.7014.2%6.7%0.430.450.490.480.790.780.1%10AR92.95%-6.75-6.6237.9%31.0%0.510.500.630.630.700.707.1%19659Pocket2Mol98.31%-7.15-6.7948.4%51.0%0.560.570.740.750.690.7124.4%2504TargetDiff90.35%-7.80-7.9158.1%59.1%0.480.480.580.580.720.7110.5%3428DiffSBDD85.01%-8.03-7.7555.3%56.6%0.470.470.550.560.760.766.0%160DecompDiff71.96%-8.39-8.4364.4%71.0%0.450.430.610.600.680.6824.5%6189TacoGFN (Ours)100%-8.24-8.4467.5%92.0%0.670.670.790.790.530.5356.0%4 et al., 2023b). For consistency with existing baselines, molecules are docked using QVina in this problemsetting (Trott & Olson, 2010; Alhossary et al., 2015). For details on the docking protocol for the generativesetting, please see Appendix D.2. 2) Optimization methods are able to leverage docking on the target pocket. Unlike the generative setting,these methods typically iteratively optimize the candidate pool and select the top 100 molecules. We compareagainst the following methods: RGA (Fu et al., 2022) and EvoSBDD (Reidenbach, 2024) use a black-boxalgorithms to conduct rounds of the optimization process, with molecule fitness based on docking score tothe target pocket. DecompOpt and TargetDiff+Opt (Zhou et al., 2024) optimizes molecules generatedby pre-trained SBDD models via rounds of optimization process involving re-docking to the target pocket.TacoGFN+FT fine-tunes a pre-trained TacoGFN to tailor the model to the target pocket using dockingas the reward.",
  "Experimental results": "compares TacoGFN against other baselines in the generative problem setting for SBDD. We ex-amine the docking score performances for individual pockets in and 5. We also show examples ofgenerated molecules in and analyze their average physical properties in . We then compareTacoGFN+FT against existing methods for the optimization problem setting in and 4, wheredocking is used in optimization rounds. Lastly, we conduct ablation studies to show the benefits of using alarger docking score dataset in and validate the utility of the pocket conditioning in . Generative setting. highlights the strong performance of TacoGFN in the generative problemsetting for the CrossDocked test set pockets. Notably, TacoGFN boasts a significant improvement in successrate at 56.0%, more than doubling the previous best of 24.5% achieved by DecompDiff. This improvement isdue to TacoGFNs ability to generate high-affinity molecules that simultaneously satisfy the drug-likenessand ease-of-synthesis requirements. In fact, TacoGFN records the best QED, SA, and High Affinity si-multaneously among all generative methods. In , we show examples of molecules generated byTacoGFN and show its ability to generate molecules with significantly improved docking scores comparedto native ligands. It is difficult to discover molecules that simultaneously exhibit better QED and Vina Dock compared toknown binders and molecules from existing baselines due to the trade-off between Vina Dock and QED.Molecules with higher molecular weight are more likely to have strong Vina Dock because of the presence ofmore interacting atoms, but they tend to have worse drug-like properties (QED). 4 In , we show theperformance breakdown for the 100 test protein pockets. TacoGFN achieves better average Top-10 VinaDock than DecompDiff in 57% of the test pockets. Notably, the top molecules generated by TacoGFN",
  "QED: 0.76 SA: 0.89": ":Our method is focused on de novo hit discovery - finding novel and diverse high-scoring hitsfor a protein target. Our method does not optimize based on a given reference seed compound. The goalof reward-based sampling is to sample diverse high-scoring molecules. To provide a fair overview of themodels performance, we selected protein pockets 4iwq and 4q8b, which are at the 25th and 75th percentiles,respectively, based on their docking scores with their native ligands.We show compare the moleculesgenerated by TacoGFN against the native ligand with their QED, SA, Novelty, and Docking score (Vina). also consistently demonstrate higher QED values. As shown in Appendix , in the pockets whereDecompDiff achieves a lower Top-10 Vina Dock, the molecules often exhibit a molecular mass larger than500 daltons. These heavier molecules violate the ideal properties of orally active drugs according to the Ruleof 5 (Lipinski et al., 1997). In addition, heavy molecules with high docking scores are more likely to be falsepositives (Pan et al., 2002). TacoGFN is able to find molecular spaces that improve both QED and VinaDock requirements not only by modelling the reward distribution but also by exploring a broader chemicalspace. This is achieved through learning from generated examples using our online policy, rather than beinglimited to the training data. We note exploring millions of molecules online could not be easily achieved with existing SBDD baseline.This is because the generation process of TacoGFN is a few orders of magnitude faster than existingautoregressive or diffusion-based generative methods. Additionally, TacoGFN achieves 100% in validityand uniqueness, demonstrating the efficiency of our fragment-based 2D generation framework. As shown in, TacoGFN achieves a significant improvement in both time and validity over previous methods. Molecules generated from TacoGFN have more ideal molecular weight and drug-likeness properties, inaddition to achieving better Vina Dock; Therefore, they are more suitable as drug candidates. TacoGFNsamples at reward temperature of 64 at inference time, resulting in the modelling of the probabilityp(x|c) R(x, c)64. This policy focuses more on the modes of reward function. Therefore the moleculessampled have higher quality but lower diversity than those generated by the methods that do not attemptto satisfy multiple objectives. By changing or reward function we can trade off rewards with diversity asshown in Appendix D.4.2.",
  "ZINC molecules98.73%337.63337.3423.5323.50377.77375.17": "Pocket2Mol64.55%248.65230.9918.2916.86254.21218.52TargetDiff78.37%323.64327.3122.7823.15600.31547.86DecompDiff51.18%494.05487.5134.9334.00834.72781.34TacoGFN (ours)99.76%402.56402.6530.4730.52360.51357.33 As shown in , 99.76% of molecules generated by TacoGFN have molecular weights within the 160 to480 dalton range - the ideal range for small molecule drugs. This ratio is much higher than those of existingmethods such as DecompDiff (51.18%), Pocket2Mol (64.55%) and TargetDiff (78.37%). For Pocket2Mol,molecules fall outside of the ideal molecular weight range because they are too small (below 160 Daltons);While for DecompDiff, most molecules are outside of range because they are too heavy (greater than 480Daltons). We note there are indeed drug candidates with molecular weights or drug-likeness outside of thetypical acceptable range. However, they may be regarded as an exception rather than the norm (from aspecialized drug class) or have elevated risks for poor absorption and bioavailability (Ritchie & Macdonald,2014).",
  "Reference100%-7.45-7.26--0.480.470.730.74--25.0%-": "RGA--8.01-8.1764.4%89.3%0.570.570.710.730.410.4146.2%-TargetDiff+Opt--8.30-8.1571.5%95.9%0.660.680.680.670.310.3025.8%>3728DecompOpt--8.98-9.0173.5%93.3%0.480.450.650.650.600.6152.5%9241EvoSBDD ( = 1.3, 140R)100%-10.27-10.3696.5%100%0.530.520.750.770.630.6378.8%6300EvoSBDD ( = 0, = 1, 140R)100%-10.14-10.2794.4%100%0.590.590.770.770.620.6286.4%6300 TacoGFN+FT (tQED = 0.40, tSA = 0.60, n = 240)100%-10.63-10.7897.1%100%0.480.470.720.710.620.6286.5%6200TacoGFN+FT (tQED = 0.50, tSA = 0.80, n = 240)100%-10.24-10.3197.0%100%0.580.580.820.820.610.6187.7%4980TacoGFN+FT (tQED = 0.50, tSA = 0.75, n = 240)100%-10.21-10.3196.2%100%0.580.570.800.810.620.6186.9%5210TacoGFN+FT (tQED = 0.55, tSA = 0.80, n = 240)100%-10.16-10.2796.8%100%0.620.610.820.820.600.6086.8%5010TacoGFN+FT (tQED = 0.60, tSA = 0.80, n = 240)100%-10.07-10.1195.8%100%0.650.640.820.820.600.6085.7%4910 TacoGFN+FT (tQED = 0.40, tSA = 0.60, n = 300)100%-10.78-10.9397.1%100%0.470.470.700.690.620.6287.8%7750TacoGFN+FT (tQED = 0.50, tSA = 0.80, n = 300)100%-10.32-10.3997.0%100%0.580.580.820.820.610.6188.8%6230TacoGFN+FT (tQED = 0.50, tSA = 0.75, n = 300)100%-10.31-10.4196.2%100%0.570.570.800.800.620.6287.7%6520TacoGFN+FT (tQED = 0.55, tSA = 0.80, n = 300)100%-10.24-10.3597.0%100%0.620.610.830.820.600.6087.3%6270TacoGFN+FT (tQED = 0.60, tSA = 0.80, n = 300)100%-10.14-10.2196.2%100%0.650.650.820.820.590.5986.3%6140",
  "We conduct additional ablation studies using the base TacoGFN under the generative setting to examinethe effect of docking score prediction accuracy and pocket conditioning on our method": "Effects of using higher quality docking score predictor. Here, we study the effect of using a moreaccurate docking score predictor, which is trained on a larger dataset, for reward. Since training a dockingscore predictor does not require high-quality protein-ligand structural data such as the CrossDock-100k set,we can introduce a second, larger dataset for docking score prediction called ZINCDock-15M. It consistsof about 15M docking simulation data - from docking 1,000 random ZINC20 (Irwin et al., 2020) moleculesinto each of the 15,207 unique pockets from CrossDock-100k training split using QVina. We then trainour pharmacophore-based docking score predictor on this larger dataset. Please see Appendix for a comparison of docking score accuracy between using CrossDock-100k and ZINCDock-15M. As shownin , TacoGFN using the docking score predictor trained on the larger ZINCDock-15M datasetdemonstrates improvements in average Vina Dock, high-affinity rate and success rate. This confirms it ispossible to leverage the easily generated large-scale docking score data to generate more novel and higheraffinity molecules.",
  "TacoGFNCrossDock-100k-8.24-8.4467.5%92.0%56.0%61.5%TacoGFNZINCDock-15M-8.35-8.5369.5%94.5%58.3%67.5%": "Effects of pocket conditioning. To examine the effect of the proposed pocket conditioning for GFlowNet,we train a molecular generation policy unconditioned on pocket information. The docking score predictoris unchanged - meaning it still predicts a docking score for a molecule with pocket information. The resultsare shown in . We observe that the pocket-conditioned GFlowNet achieves higher docking scorescompared to the GFlowNet without pocket conditioning. We further measure the number of non-covalentinteractions of a molecule to respective pocket, by obtaining the binding pose using QVina (See AppendixD.4.1). We demonstrate generated molecules by pocket-conditioned GFlowNet result in more non-covalentinteractions of for all categories (Hydrophobic interactions, Van der Waals contacts, Hydrogen binding) in. More non-covalent interactions are indicative of the molecule having better specificity to the proteintarget. This ablation validates that our method is indeed leveraging pocket conditioning to learn a familyof molecular distribution across different pocket structures.",
  "Conclusion": "In this paper, we have investigated the problem of structure-based drug design. To address the limitations ofmethods based on distribution learning, we have framed pocket-conditioned molecule generation as learninga multi-objective reward distribution using RL. To this end, we propose TacoGFN, a pocket structureconditioned GFlowNet which generate drug-like and high-affinity molecules with respect to any 3D pocketstructure. To the best of our knowledge, TacoGFN is the first RL model to address the challenging taskof modelling a family of reward functions induced from all pocket structures. Our model effectively exploresthe greater chemical space, through generating millions of molecules using the online policy during training.We have further introduced a novel pharmacophore-based affinity predictor, where coarse-graining to theprotein pocket is shown to achieve more accurate and robust predictions than existing architectures andprotein representations. We finally introduce TacoGFN+FT, which fine-tunes the generic TacoGFN fora given test pocket. OurexperimentsontheCrossDocked2020benchmarkhavedemonstratedthatTacoGFNandTacoGFN+FT outperform the state-of-the-art methods in terms of Vina Dock, high affinity and successrate. This demonstrates the potential of TacoGFN as a powerful tool for structure-based drug discovery.In future work, we plan to validate the top generated ligands for some clinically relevant protein pocketsin-vitro, i.e. in wet-lab experiments.",
  "Broader Impact Statement": "This paper presents work whose goal is to advance machine learning methods for drug discovery.Suchmethods are increasingly being employed in the pharmaceutical industry since they promise to greatlyspeed-up the lengthy process of drug discovery and to significantly reduce its huge cost. If that promiseholds, these machine-learning methods will benefit patients through better care and our society through areduction of the economic burden of drug development.",
  "Emmanuel Bengio, Moksh Jain, Maksym Korablyov, Doina Precup, and Yoshua Bengio. Flow network basedgenerative models for non-iterative diverse candidate generation, 2021": "G. Richard Bickerton, Gaia V. Paolini, Jrmy Besnard, Sorel Muresan, and Andrew L. Hopkins. Quantifyingthe chemical beauty of drugs. Nature Chemistry, 4(2):9098, January 2012. ISSN 1755-4349. doi: 10.1038/nchem.1243. URL Thomas Blaschke, Josep Ars-Pous, Hongming Chen, Christian Margreitter, Christian Tyrchan, OlaEngkvist, Kostas Papadopoulos, and Atanas Patronov.REINVENT 2.0:An AI tool for de novodrug design.Journal of Chemical Information and Modeling, 60(12):59185922, October 2020.doi:10.1021/acs.jcim.0c00915. URL Michael Brocidiacono, Paul Francoeur, Rishal Aggarwal, Konstantin Popov, David Koes, and AlexanderTropsha. Bigbind: Learning from nonstructural data for structure-based virtual screening. November2022. doi: 10.26434/chemrxiv-2022-3qc9t. URL",
  "Connor W. Coley. Defining and exploring chemical spaces. Trends in Chemistry, 3(2):133145, 2021. ISSN2589-5974. doi: URL Special Issue: Machine Learning for Molecules and Materi-als": "Jrg Degen, Christof Wegscheid-Gerlach, Andrea Zaliani, and Matthias Rarey. On the art of compilingand using drug-like chemical fragment spaces. ChemMedChem, 3(10):15031507, October 2008. ISSN1860-7187. doi: 10.1002/cmdc.200800178. URL Peter Ertl and Ansgar Schuffenhauer. Estimation of synthetic accessibility score of drug-like molecules basedon molecular complexity and fragment contributions. Journal of Cheminformatics, 1(1), June 2009. ISSN1758-2946. doi: 10.1186/1758-2946-1-8. URL",
  "Matthias Fey and Jan E. Lenssen. Fast graph representation learning with PyTorch Geometric. In ICLRWorkshop on Representation Learning on Graphs and Manifolds, 2019": "Paul G. Francoeur, Tomohide Masuda, Jocelyn Sunseri, Andrew Jia, Richard B. Iovanisci, Ian Snyder, andDavid R. Koes. Three-dimensional convolutional neural networks and a cross-docked data set for structure-based drug design. Journal of Chemical Information and Modeling, 60(9):42004215, August 2020. ISSN1549-960X. doi: 10.1021/acs.jcim.0c00411. URL Tianfan Fu, Wenhao Gao, Connor W. Coley, and Jimeng Sun. Reinforced genetic algorithm for structure-based drug design.In Alice H. Oh, Alekh Agarwal, Danielle Belgrave, and Kyunghyun Cho (eds.),Advances in Neural Information Processing Systems, 2022. URL Francesco Gentile, Vibudh Agrawal, Michael Hsing, Anh-Tien Ton, Fuqiang Ban, Ulf Norinder, Martin EGleave, and Artem Cherkasov. Deep docking: a deep learning platform for augmentation of structurebased drug discovery. ACS central science, 6(6):939949, 2020. Arup K Ghose, Vellarkad N Viswanadhan, and John J Wendoloski. A knowledge-based approach in de-signing combinatorial or medicinal chemistry libraries for drug discovery. 1. a qualitative and quantitativecharacterization of known drug databases. Journal of combinatorial chemistry, 1(1):5568, 1999.",
  "Ross Girshick. Fast r-cnn. In Proceedings of the IEEE international conference on computer vision, pp.14401448, 2015": "Manan Goel, Shampa Raghunathan, Siddhartha Laghuvarapu, and U. Deva Priyakumar.Molegu-lar:Molecule generation using reinforcement learning with alternating rewards.July 2021a.doi:10.26434/chemrxiv-2021-cg9p8. URL Manan Goel, Shampa Raghunathan, Siddhartha Laghuvarapu, and U. Deva Priyakumar.MoleGuLAR:Molecule generation using reinforcement learning with alternating rewards.Journal of Chemical In-formation and Modeling, 61(12):58155826, December 2021b.doi:10.1021/acs.jcim.1c01341.URL Shuo Gu, Matthew S. Smith, Ying Yang, John J. Irwin, and Brian K. Shoichet. Ligand strain energy in largelibrary docking. Journal of Chemical Information and Modeling, 61(9):43314341, September 2021. ISSN1549-960X. doi: 10.1021/acs.jcim.1c00368. URL",
  "Weihua Hu, Bowen Liu, Joseph Gomes, Marinka Zitnik, Percy Liang, Vijay Pande, and Jure Leskovec.Strategies for pre-training graph neural networks. arXiv preprint arXiv:1905.12265, 2019": "Ruth Huey, Garrett M Morris, and Stefano Forli. Using autodock 4 and autodock vina with autodocktools:a tutorial. The Scripps Research Institute Molecular Graphics Laboratory, 10550(92037):1000, 2012. John J Irwin, Khanh G Tang, Jennifer Young, Chinzorig Dandarchuluun, Benjamin R Wong, MunkhzulKhurelbaatar, Yurii S Moroz, John Mayfield, and Roger A Sayle. Zinc20a free ultralarge-scale chemicaldatabase for ligand discovery. Journal of chemical information and modeling, 60(12):60656073, 2020.",
  "Seul Lee, Jaehyeong Jo, and Sung Ju Hwang. Exploring chemical space with score-based out-of-distributiongeneration. In International Conference on Machine Learning, pp. 1887218892. PMLR, 2023": "Shuya Li, Fangping Wan, Hantao Shu, Tao Jiang, Dan Zhao, and Jianyang Zeng. Monn: a multi-objectiveneural network for predicting compound-protein interactions and affinities. Cell Systems, 10(4):308322,2020. Christopher A. Lipinski, Franco Lombardo, Beryl W. Dominy, and Paul J. Feeney.Experimental andcomputational approaches to estimate solubility and permeability in drug discovery and developmentsettings.Advanced Drug Delivery Reviews, 23(1):325, 1997.ISSN 0169-409X.doi: In Vitro Models for Selection of Development Candidates.",
  "Noel M OBoyle, Michael Banck, Craig A James, Chris Morley, Tim Vandermeersch, and Geoffrey R Hutchi-son. Open babel: An open chemical toolbox. Journal of cheminformatics, 3(1):114, 2011": "Marcus Olivecrona, Thomas Blaschke, Ola Engkvist, and Hongming Chen.Molecular de-novo de-sign through deep reinforcement learning.Journal of Cheminformatics, 9(1), September 2017.doi:10.1186/s13321-017-0235-x. URL Yongping Pan, Niu Huang, Sam Cho, and Alexander D. MacKerell.Consideration of molecular weightduring compound selection in virtual target-based database screening. Journal of Chemical Informationand Computer Sciences, 43(1):267272, November 2002. ISSN 1520-5142. doi: 10.1021/ci020055f. URL Mohit Pandey, Mariia Radaeva, Hazem Mslati, Olivia Garland, Michael Fernandez, Martin Ester, andArtem Cherkasov. Ligand binding prediction using protein structure graphs and residual graph attentionnetworks.Molecules, 27(16), 2022.ISSN 1420-3049.doi: 10.3390/molecules27165114.URL Adam Paszke, Sam Gross, Francisco Massa, Adam Lerer, James Bradbury, Gregory Chanan, Trevor Killeen,Zeming Lin, Natalia Gimelshein, Luca Antiga, Alban Desmaison, Andreas Kopf, Edward Yang, ZacharyDeVito, Martin Raison, Alykhan Tejani, Sasank Chilamkurthy, Benoit Steiner, Lu Fang, Junjie Bai, andSoumith Chintala. Pytorch: An imperative style, high-performance deep learning library. In Advances inNeural Information Processing Systems 32, pp. 80248035. Curran Associates, Inc., 2019.",
  "Danny Reidenbach. EvoSBDD: Latent evolution for accurate and efficient structure-based drug design. InICLR 2024 Workshop on Machine Learning for Genomics Explorations, 2024. URL": "Joseph M. Replogle, Reuben A. Saunders, Angela N. Pogson, Jeffrey A. Hussmann, Alexander Lenail, AlinaGuna, Lauren Mascibroda, Eric J. Wagner, Karen Adelman, Gila Lithwick-Yanai, Nika Iremadze, FlorianOberstrass, Doron Lipson, Jessica L. Bonnar, Marco Jost, Thomas M. Norman, and Jonathan S. Weissman.Mapping information-rich genotype-phenotype landscapes with genome-scale perturb-seq. Cell, 185(14):25592575.e28, July 2022. ISSN 0092-8674. doi: 10.1016/j.cell.2022.05.013. URL",
  "Seonghwan Seo, Jaechang Lim, and Woo Youn Kim.Molecular generative model via retrosyntheticallyprepared chemical building block assembly. Advanced Science, 10(8):2206674, 2023": "Chao Shen, Xujun Zhang, Yafeng Deng, Junbo Gao, Dong Wang, Lei Xu, Peichen Pan, Tingjun Hou, andYu Kang. Boosting proteinligand binding pose prediction and virtual screening based on residueatomdistance likelihood potential and graph transformer. Journal of Medicinal Chemistry, 65(15):1069110706,2022. Martin Steinegger and Johannes Sding.Mmseqs2 enables sensitive protein sequence searching for theanalysis of massive data sets. Nature Biotechnology, 35(11):10261028, October 2017. ISSN 1546-1696.doi: 10.1038/nbt.3988. URL Oleg Trott and Arthur J Olson. AutoDock Vina: improving the speed and accuracy of docking with a newscoring function, efficient optimization, and multithreading. Journal of computational chemistry, 31(2):455461, 2010.",
  "Zaixi Zhang, Yaosen Min, Shuxin Zheng, and Qi Liu. Molecule generation for target protein binding withstructural motifs. In The Eleventh ICLR, 2023b": "Alex Zhavoronkov, Yan A. Ivanenkov, Alex Aliper, Mark S. Veselov, Vladimir A. Aladinskiy, Anas-tasiya V. Aladinskaya, Victor A. Terentiev, Daniil A. Polykovskiy, Maksim D. Kuznetsov, Arip Asadu-laev, Yury Volkov, Artem Zholus, Rim R. Shayakhmetov, Alexander Zhebrak, Lidiya I. Minaeva, Bog-dan A. Zagribelnyy, Lennart H. Lee, Richard Soll, David Madge, Li Xing, Tao Guo, and Aln Aspuru-Guzik.Deep learning enables rapid identification of potent ddr1 kinase inhibitors.Nature Biotech-nology, 37(9):10381040, September 2019.ISSN 1546-1696.doi:10.1038/s41587-019-0224-x.URL",
  "ASoftwares": "In this study, we used the open-sourced code for GFlowNet (Bengio et al., 2021), PharmacoNet (Seo &Kim, 2023) and GVP-GNN (Jing et al., 2021). Our models were implemented using the Pytorch (Paszkeet al., 2019) and PyTorch Geometric (Fey & Lenssen, 2019) libraries, which enabled efficient training andevaluation. We utilized RDKit (Landrum et al., 2006), a widely-used chem-informatics library, to handle themolecular structures and compute chemical properties. We employed the QuickVina 2.1 (QVina) (Alhossaryet al., 2015) and UniDock (Yu et al., 2023) for docking, and used Openbabel (OBoyle et al., 2011) andAutoDock Tools (Huey et al., 2012) to generate ready-to-dock files.",
  "BProblem definition compared to existing RL baselines": "TacoGFN addresses the problem of structure-based drug design (SBDD), which aims to have one modelgenerate high-affinity molecules conditioned on any unseen protein structure. We train this one model togenerate molecules conditional to different protein target structures in the CrossDocked training set, usingpredicted affinity, Synthetic Accessibility (SA), and drug-likeness (QED) as the reward. Then we evaluatethe trained models performance on the 100 unseen protein target structures in the CrossDocked test set.Molecules are generated for unseen protein structures during evaluation to measure whether SBDD modelshave learned generalized protein-ligand interaction patterns during training.",
  "C.1.1Molecular generation actions": "We follow action used in previous works on fragment-based molecular generation (Jin et al., 2018; Bengioet al., 2021; Hamidizadeh et al., 2023) to construct molecules fragment by fragment. We present the threetypes of actions available to TacoGFN below: (1) FragmentAddition: At each step, for each fragment node vLi in the molecular graph, we apply thesame MLP over its node embedding hL(N)iwhich produces logits over the fragment vocabulary. Each logitrepresents the unnormalized score for attaching fragment node vLi to a particular new fragment node (vLj )from the vocabulary. These logits correspond to the FragmentAddition action type. While the FragmentAd-dition specifies whether fragment node vLi connects to fragment node vLj , it does not specify how they areconnected (i.e. which atom on fragment vLi forms a bond with which atom on fragment vLj ).",
  "aAdd = MLPhL(N)": "(2) AttachmentSpecification determines how the fragment pairs are connected. At each step, for eachdirectional edge in the molecular graph which connects fragment vLi to vLj , we produce a logit over the atomsof fragment vLi . Each logit represents the unnormalized score for fragment i connecting to fragment vLj via",
  "aAttach = MLPeL(N)": "(3) StopConstruction is a graph action that marks the finish of a molecule. The logit is produced from asingle MLP output based on the final graph embedding gL(N). All logits are concatenated and scaled intoprobabilities using the softmax function, and an action is sampled from the distribution. The same processis repeated for each time step until the stop construction action is sampled.",
  "Drug Likeliness (QED) and Synthetic Accessibility (SA):We first normalize the raw SA score usingthe formula 10SA": "9to obtain a reward between 0 and 1. While QED and SA need to meet a certain thresholdto make a good drug molecule, optimizing these values beyond the threshold does not bring additional utility(Coley, 2021). Therefore, we clip reward r for QED or SA to 1 when they achieve their respective thresholdt. In other words, our model will not be incentivised to optimize QED/SA beyond their threshold value;Therefore more priority will be placed on optimizing the Vina Docking Score when these thresholds arereached.",
  "tSA, 1": "Vina Docking Score (DS):Here, we define the docking score threshold tDS to -8.0 kcal/mol, corre-sponding to 1M - an important requirement for a drug candidate. Since molecules will not be as useful ifthey do not surpass this affinity requirement, we scaled down the component of docking score not surpassingthreshold tDS by 0.2. This has the effect of reducing rewards for molecules not surpassing this docking scorethreshold. Lastly, Pan et al. (2002) notes screening based on docking score is biased toward the selectionof high molecular weight, as compound size may unfairly contribute to the energy score. We follow theirsuggestion of normalizing reward by the cube root of heavy atom count (HAC) - to reduce the false positivesresulting from the molecular weight bias. Lastly, we multiply the whole term by -1 as our goal is to minimizethe Vina Dock score.",
  "C.2Additional details of docking score predictor": "Motivation.When developing a docking score prediction model, two essential requirements are its speedof processing and its applicability to a variety of proteins and ligands. Since the binding poses are computa-tionally or experimentally expensive, previous affinity prediction models or docking score prediction models(Zhang et al., 2023a) predict energy by integrating the 1D representation vectors zP of the protein P and",
  "E = z(Concat(zp, zl))(8)": "However, this approach can not consider the atom pairwise interactions between ligands and proteins due toglobal pooling, so it shows less generalizability to unseen ligands or proteins. Compared to previous methods,MONN (Li et al., 2020) proposed a pairwise interaction map I between protein amino acid embeddings {hPi }and ligand node embeddings {hLj }:",
  "E = SumPool(I(I))(10)": "However, the use of full amino acid sequences is computationally expensive for large proteins. Furthermore,in target-based drug design tasks that prioritize binding pocket information, affinity prediction over theentire protein can sometimes lead to incorrect energy calculations for different pockets.Therefore, ourstudy adopts the use of pharmacophores within the binding pocket as an alternative to considering theentire protein sequence.This approach not only effectively captures the unique features of the proteinpocket, but also simplifies its topology, thereby addressing the computational burden and the generalizationissues. Also, conceptually our docking score predictor determines whether a ligand atom corresponds to eachpharmacophore node rather than whether it forms non-covalent interactions with each amino acid or atom.",
  "D.1Dataset": "CrossDocked (Francoeur et al., 2020) is a dataset containing 22.5 million poses of ligands docked into multiplesimilar binding pockets from PDBBind. For CrossDocked-100k set, we use an identical processing strategyto previous works (Luo et al., 2021; Peng et al., 2022): First, data points with binding pose RMSD greaterthan 1 are filtered. Then, mmseq2 (Steinegger & Sding, 2017) is to cluster data at 30% sequence identity.After splitting, 100,000 protein-ligand pairs are randomly drawn for the training set. 100 test pockets aredrawn from the remaining pocket clusters. 15,307 unique protein pockets remain in the training set.",
  "D.2Docking protocols": "For our protocol under the generative setting, we first convert all generated molecules into SMILES andcalculate their ETKDG conformers (srETKDGv3) using RDKit. Then, we prepare ready-to-dock files ofligands and proteins with Openbabel and AutoDockTools (OBoyle et al., 2011; Huey et al., 2012). Finally,we dock these conformers using Quick VINA 2.1 (QVina) (Trott & Olson, 2010; Alhossary et al., 2015). ForQVina, we use a box size of 20 and an exhaustiveness of 8. Note for the optimization setting, we adoptUniDock instead following previous works (Reidenbach, 2024) (Please see details in Appendix E.1).",
  "D.3Baseline evaluations": "For our baseline generation, we selected Pocket2Mol (Peng et al., 2022), TargetDiff (Guan et al., 2023a),DecompDiff (Guan et al., 2023b). We adhered to the default hyperparameter settings for all models. De-compDiff incorporates three prior modes: subpocket, reference, and beta. Of these, we selected the betamode for our analysis, as it demonstrated the highest docking score, aligning with findings reported in itsoriginal publication. We generated 100 molecules for each of the 100 protein pockets from the Crossdocked2020 (Francoeur et al.,2020) test set. Following generation, we applied a filtering process to ensure that all molecules were uniqueand met validity criteria. Molecules were deemed invalid and discarded, if they had reconstruction errors,were duplicates, or were disconnected. The remaining SMILES obtained from these models were compiledto establish the baseline. We then proceeded to perform the docking protocol on each of the SMILES toobtain their respective docking scores. Our results were in line with those reported in the original studies ofthe respective models.",
  "D.4.1Additional ablation on effects of pocket conditioning": "To further demonstrate the effectiveness of pocket conditioning, we compare the numbers of non-covalentinteractions achieved by the generated molecules from pocket-conditioned TacoGFN with TacoGFN withoutpocket conditioning. The non-covalent interactions between protein and ligand fall into the following cate-gories: (1) Hydrophobic Interactions are interactions between nonpolar regions of the protein and theligand. (2) Van der Waals Contacts are weak forces arising from induced electrical interactions betweenclosely positioned atoms of the protein and ligand. (3) Hydrogen Bonding refers to strong dipole-dipoleinteractions between an electronegative atom and (typically) a hydrogen atom. (4) Total Interactionsrefers to the total number of interactions between the protein and the ligand, including all types of non-covalent interactions. The generated molecules are docked using QVina (Trott & Olson, 2010; Alhossaryet al., 2015) to generate a binding conformation. We use PoseCheck (Harris et al., 2023) to compute thenumber of interactions. In table 9, we found that pocket conditioning increased all types of non-covalent interactions between proteinand generated molecules. this result suggests that the pocket structural information can provide guidancein selecting functional groups that can form better supramolecular interactions with the target pocket. :Effectiveness of pocket structure conditioning measured using the average numbers of non-covalentinteractions (NCI) achieved after docking the generated molecules into the target pocket using QVina. Highernumbers of interactions indicate a stronger binding interaction.",
  "D.4.2Discussion on diversity": "In our experiments with GFlowNet, we find a trade-off between diversity and the goal of optimizing for ahigher average affinity of the generated candidate set. As TacoGFN seeks to generate molecules with astrong affinity to a specific pocket structure while optimizing for QED and SA, the resulting solution set isinevitably smaller, leading to reduced diversity. We note that the molecular diversity of TacoGFN, if desired, can be increased in various ways. Firstly, thereward is currently exponentiated by reward temperture . As increases, the reward density is concentratedclose to the modes with high reward, and subsequently, theres a reduction in diversity (Jain et al., 2023).Diversity can be improved by lowering the .",
  "TacoGFN-8.240.53TacoGFNlenient-7.910.73": "In addition, we have experimented with various reward function settings. In the reward scenario adopted inthe paper - the strict setting (see Appendix C.1.2), we reduce the reward given to the component dockingscore that is below -8.0 kcal/mol. We have found that the stricter reward produces better affinity metrics atthe expense of lower diversity. In the lenient setting, where we simply reward docking scores based on theirnormalized raw values, TacoGFNlenient still outperforms Pocket2Mol and TargetDiff in terms of averagedocking score (-7.91) while having higher diversity (0.73). In summary, if the key concern is candidate diversity and novelty, TacoGFN can be trained to generategenerally high reward molecules under the lenient setting and/or low . If the goal is to generate the best",
  "D.4.3Performance of docking score prediction model": "While many existing affinity-prediction architectures either work for one target only (Bengio et al., 2021;Gentile et al., 2020), or require binding complex structures (Shen et al., 2022), we cannot adopt these modelarchitectures as we require affinity prediction across various protein targets without using their binding com-plex structure. Thus, we compare our pharmacophore-based affinity prediction architecture with BigBind(Brocidiacono et al., 2022) and DeepBindGCN (Zhang et al., 2023a), two recently proposed non-complex-based methods which achieved state-of-the-art performance in virtual screening and affinity prediction, re-spectively. In addition, we examine the effect of introducing pharmacophore-based coarse-grained encodingof the protein pocket, by creating an ablation where we use residue graphs with C-alpha as nodes (as typicallydone in other methods) Lu et al. (2022) instead of pharmacophore graphs to represent our protein pocket. Wecall this ablation model TacoGFN (C-alpha). We re-train these models using the same CrossDocked2020and ZINCDock-15M datasets and evaluate them on both test sets.",
  "E.1Finetuning settings": "For finetuning TacoGFN, we adopt the same reward function as described in appendix section C.1.2.However, instead of using the previously mentioned docking score predictor for affinity reward, we use thedocking program directly. Following the same setting as EvoSBDD Reidenbach (2024), we adopt UniDock(Yu et al., 2023) - a GPU-accelerated docking program to compute docking score between the generatedmolecule and the protein target during the fine-tuning stage. We use UniDocks default balanced mode,which has an exhaustiveness of 384 and a max step of 40. We fine-tune using a batch size of 64 to leveragethe speedup from UniDocks parallelization for computing docking scores. For a fair comparison with the previous methods, we re-scored the UniDocks docking pose with Vina (in ascore-only mode without any structural changes) and obtained the same values within the margin of error( 0.005 kcal/mol). The top 100 molecules with the highest rewards from the fine-tuning stage are used forevaluation.",
  "E.2Results": "For ablations studies, we vary our reward function by adjusting tQED and tSA. Once the threshold for tQEDor tSA is reached for molecules, the model will not be incentivised to optimize its QED or SA further. Witha lower threshold standard (tQED and tSA), our model will prioritize optimizing for Vina Dock instead ofoptimizing for QED or SA. (See details in Appendix C.1.2). We observe such a trade-off between QED andSA with Vina Dock in our ablation studies. We also experiment with various fine-tuning steps n. We showthat Vina Dock metric will continue to improve with more fine-tuning steps."
}