{
  "Abstract": "Label noise in federated learning (FL) has garnered increasing attention due to the de-centralized nature of FL, where data is collected from multiple clients with potentiallydifferent levels of label noise. This study introduces two pivotal contributions to this domain.First, we anatomize the memorization phenomenon in FL into server-side and client-sidecomponents, marking the first investigation into how these distinct forms of memorizationimpact learning. Second, to mitigate the memorization in FL, we present the FederatedLabel-mixture Regularization (FLR) strategy, a straightforward yet effective approach thatemploys regularization through pseudo labels generated by merging local and global modelpredictions. This method not only improves the accuracy of the global model in both i.i.d.and non-i.i.d. settings but also effectively counters the memorization of noisy labels. Weempirically find that FLR aligns with and advances existing FL and noisy label mitigationmethods over multiple datasets under various levels of data heterogeneity and label noise.",
  "Introduction": "The advent of large-scale datasets has propelled deep neural networks to remarkable achievements in fieldssuch as computer vision, information retrieval, and language processing (Yao et al., 2021). However, thesedatasets often contain sensitive personal information, making conventional centralized learning impractical forapplications such as person identification, financial services, and healthcare systems. Federated learning (FL)addresses privacy issues by allowing clients (e.g., edge devices) to collaborate with a central server (e.g., aservice manager) without sharing their local data. Instead, clients update their local models using theirprivate data, and the central server aggregates these updates to improve the global model. This procedureis repeated until convergence (FedAvg) (McMahan et al., 2017). FL enables on-device learning and avoidssystematic privacy risks at the data level, making it particularly suitable for the computing devices such asphones, tablets, and autonomous driving systems (Kim & Yun, 2022; Kim et al., 2023). In FL, multiple clients may have different levels of label noise (Xu et al., 2022) due to various factors, such asannotator skill, client bias, malfunctioning data collectors (Kim et al., 2018), or even malicious tamperingwith labels (Chen et al., 2020). For instance, in the healthcare industry, manually labeling patient records ateach hospital is susceptible to corruption due to the complexity of medical terminology and the potentialfor annotator bias. Additionally, data entry mistakes or misunderstandings by medical professionals mayintroduce inconsistencies or errors into the original data (Xu et al., 2019; Karimi et al., 2020). Training withnoisy labels can negatively impact over-parameterized neural networks, as they are prone to memorizing",
  ": Overview of our proposed regularization, Federated Label-mixture Regularization (FLR)": "mislabeled instances (a.k.a., memorization). Label noise, combined with FLs heterogeneous nature, canexacerbate this phenomenon. Traditional methods for addressing label noise in centralized learning (CL) arenot directly applicable in the FL setting due to privacy constraints, small client datasets, and difficulties inhandling data heterogeneity (Chen et al., 2020; Xu et al., 2022; Ji et al., 2024; Tsouvalas et al., 2024). In this work, we first identifies and addresses the dual nature of memorization in FL local memorization atthe client level and global memorization at the server level (). We explore how local memorization,driven by client-specific data and biases, poses a significant risk of overfitting to noisy labels. Conversely,global memorization highlights the challenges faced by the central model in distilling accurate informationfrom diverse, and potentially noisy, client updates. Our analysis reveals the intricate interplay between thesetwo forms of memorization and their cumulative impact on the learning process in FL. To combat these challenges, we introduce a simple yet efficient novel regularization for dealing with noisylabels in FL, termed as Federated Label-mixture Regularization (FLR; ), which supervises the noisyinstances with pseudo labels generated through a combination of global servers running average predictionsand local running average predictions. Our method is grounded in the recognition that memorization in FLmanifests distinctively at server and client levels. In both i.i.d. and non-i.i.d. scenarios, the servers andclients temporal ensembling vectors each mitigate memorization issues. However, neither alone fully addressesboth local and global memorization. This highlights the strength of our FLR method, which combines thesevectors to effectively handle various noise conditions and data heterogeneity. Through experimental validation,we ascertain that leveraging a mixture of both vectors culminates in a robust label mixture adept at handlingvarious noise conditions and data heterogeneity. Building upon this, we further develop several techniques bybalancing the scale between global running average predictions and local running average predictions. Inlight of the above, our key contributions are as follows:",
  "Learning with noisy label": "Label noise in supervised learning can significantly reduce the generalization capability of deep neural networks(DNNs), leading to the development of various methods for robust training (Song et al., 2022). Recent progressin this field has included designing robust architectures (Yao et al., 2018; Momeny et al., 2021; Li et al., 2021),loss functions, and regularization techniques (Pereyra et al., 2017; Zhang et al., 2018; Liu et al., 2020; Weiet al., 2022; Kim et al., 2021b), as well as methods for loss adjustment (Reed et al., 2015; Ma et al., 2018;",
  "Zheng et al., 2020) and sample selection (Han et al., 2018; Li et al., 2020a; Kim et al., 2021a). However, mostof them have been proven to work only under CL settings": "One of the major challenges in dealing with label noise is the DNNs ability to memorize unreliable data,including random data or noisy labels, a.k.a., memorization phenomenon. This memorization phenomenon isobserved to occur during the training phase, where DNNs first learn correctly labeled data and then graduallymemorize the wrong labels (Zhang et al., 2017; 2021; Arpit et al., 2017). Bai et al. (2024) demonstratethat such mislabeled examples even can be memorized in the early stage. To prevent the memorizationphenomenon, some approaches have focused on stopping training before memorization becomes severe (Songet al., 2019; Li et al., 2020b; Bai et al., 2021), and others have utilized regularization in the early-learningphase (Liu et al., 2020; Xia et al., 2020). However, their effectiveness in the FL setting has yet to be fullyexplored.",
  "Federated learning with noisy label": "Federated learning with noisy labels (FNL) is a scenario where the clients have label noise in their localdatasets. This problem is particularly prevalent in FL, where data is decentralized and collected frommultiple clients with varying levels of label noise. Training a model with noisy labels can be detrimentalas over-parameterized neural networks are prone to fitting the training dataset, leading to a memorizationproblem. Existing FNL methods address this issue by using techniques such as sample selection, robustaggregation, label correction, and robust loss functions. For instance, FedCorr (Xu et al., 2022) corrects labelnoise in multiple stages, such as preprocessing, fine-tuning, and regular training, and FedRN (Kim et al., 2022)robustly aggregates local models by weighting them based on the estimated label noise level. FedNoRo (Wuet al., 2023) integrates noise detection via Gaussian models and robust updates through knowledge distillationand distance-aware aggregation. However, some studies have limitations, such as relying on supervision (Chenet al., 2020; Tuor et al., 2021) or not analyzing results in non-i.i.d. settings and situations with heterogeneousnoise levels (Jiang et al., 2022; Kim et al., 2022; Ji et al., 2024; Zhou & Wang, 2024).",
  "kSnkn Fk(w) where S is the set of total clients, with each client k has nk local training datasamples, and n =": "kS nk. The local objective of client k is to minimize Fk(w) = ExkDk[k(xk, yk; w)],where k is the loss function parameterized by w on the local data (xk, yk) from local data distributionDk. Here, we consider a setting having N clients and dataset with C classes. Each client k has the trainingset {(xki, yki)}nki=1, where xki is the i th input and yki {0, 1}C is the corresponding one-hot label vector;y(c)ki = 1 iff xki belongs to class c. The main issue is that it is unknown whether such labels are correctlyannotated (i.e., clean) or not (i.e., noisy). Data heterogeneityIn order to consider the data heterogeneity in FL, we assume the true data distributionDk prior to introducing label noise. In i.i.d. setting, all clients have the same size local training set andan equal number of data samples per class. In contrast, the local data distributions in non-i.i.d. settingsare more complex, with varying local training set sizes and imbalanced data samples per class. Followingthe settings in Xu et al. (2022), we create a non-i.i.d scenario. We first sample a Bernoulli random variablekc Bernoulli(p) for each client k and class c, where kc = 1 represents that client k has class c andkc = 0 otherwise. We then distribute the data samples of class c among the clients with c = 1 usingLatent Dirichlet Allocation (LDA), assigning the partition of the class c samples, where c is a vector oflength Nk=1 kc with positive elements Dir. To ensure that no clients are left without data, we allocate atleast one sample of class c to each client k with kc = 1 regardless of qc.",
  "Noise levelWe synthetically design scenarios with different levels of label noise among clients, following": "Xu et al. (2022). We first introduce the parameter , which represents the ratio of clients with label noisein their datasets. We then assign the noise rate of each noisy client based on , the lower bound of eachclients noise rate. We sample the noise rate rk of noisy client k uniformly at random from the range U(, 1).",
  "CorrectWrongMemorized": ": (a) Server side memorization with LCE, and (b) client side memorization with LCE on CIFAR-10of the i.i.d. setting, with symmetric noise of (, ) = (0.8, 0.0). In (b), the fraction values are calculated byaveraging the values contributed solely by participating noisy clients in each round. Finally, we randomly select rknk data samples and reassign their labels to create noise. It is worth notingthat, while the original paper by FedCorr treated and rk as probabilities (through Bernoulli sampling), ourimplementation treats them as fixed ratios. Noise typeWe examine two forms of label noise: symmetric and asymmetric noise (Patrini et al., 2017).For symmetric noise, we randomly and uniformly choose one class among the C classes and reassign yki as ani.i.d. random one-hot vector. As for asymmetric noise, it mimics human-like errors that happen for similarclasses (e.g., cat dog, truck automobile). We reassign yki based on the class of xki, the initial value ofyki, for asymmetric noise.",
  "In the view of memorization in FL": "In this subsection, we delve into the phenomenon of memorization in FL. Despite numerous studies inCL exploring memorization, the topic remains notably unexplored in the context of FL. To provide aclear understanding, we distinguish between two types of memorization by referring to the definition ofmemorization in the field of learning with noisy labels in CL (Liu et al., 2020):",
  "Global memorization (server side) transpires after federated aggregation when the accuracy ofthe training dataset is calculated using the server model": "Local memorization (client side) takes place immediately after a local model update and refersto the accuracy computed on the training dataset using a personalized model that has been updatedlocally before federated aggregation occurs. showcases both local and global memorization. In this context, we estimate memorization asinstances where the models predictions coincide with incorrect labels. We observe that the accuracy curvesof correct samples in both clean and noisy label plots increase during the early stages. However, in thenoisy label plot, the accuracy of correct samples declines after reaching a certain point, while the level ofmemorization rises. In contrast, the clean label curve remains stable ( (a)). In both cases, the countof wrong-predicted samples consistently decreases. Alongside examining the server-side, we also probe intothe client-side memorization. Owing to the scarce amount of data available to each client, memorizationbecomes more prominent, regardless of whether the data is clean or noisy ( (b)). Specifically, theproportion of samples with incorrect labels memorized by the local model increases rapidly as the roundprogresses, eventually reaching 100%. This signifies that the local model has memorized all of the noisy labelspresent in the clients local dataset. Based on this observation, we define memorization from both local and global perspectives, capturing severityand prevalence, respectively. Catastrophic memorization occurs at the client level when a model nearly",
  "tki ski + (1 )mki Mixture": "where denotes the parameters of the neural network, pki is the local prediction, tki is the pseudo labelvector for a client ks i th input, ski is the global running average prediction, pserverkiis the global modelsprediction, mki is a local running average prediction, and c is the index of the vector, which satisfies with1 c C. The logarithm component serves as a regularization term that aligns p in the same directionas tki. Synthetic pseudo labels tki are generated by merging a local running average prediction with theservers running average prediction, called Federated Label-mixture Regularization (FLR). For an initialprediction of a client ks i th input, ski and mki are set to be equal to pserverkiand pki, respectively. Since theserver receives randomly augmented data during each local iteration, pserverkiundergoes slight changes. Thenumber of updates to tki depends on the number of clients participating in each round. If a client does notparticipate, the most recent version of tki is stored locally, and this value is used for updates when the clientis selected from the server. Algorithm 1 illustrates the overall procedure within the general FL framework. The parameters , , and in Eq. (1) play critical roles in balancing the influence of global and localinformation. Here, controls the weighting between the global and local running averages, influencing themodels bias towards more generalized or personalized predictions. A higher value emphasizes the globalcontext, reducing overfitting to noisy local data but possibly underfitting local nuances. Conversely, and manage the decay rates of the global and local running averages, respectively. Specifically, adjusts howquickly the global information is integrated into the model updates, while dictates the retention of localdata characteristics in the learning process. These hyperparameters are pivotal in optimizing the trade-offbetween memorization and generalization, ensuring that the model remains robust to label noise and dataheterogeneity across different clients. Their values should be chosen based on empirical evaluations and thespecific characteristics of the dataset, as thoroughly discussed in Subsection 4.3, which examines their impactsthrough a series of ablation studies. Tackling confirmation bias The phenomenon of models overfitting to noisy labels, known as memorization,can be viewed as a form of confirmation bias, where incorrect pseudo-labels predicted by the network areerroneously reinforced (Tarvainen & Valpola, 2017; Arazo et al., 2020). FLR uses pseudo labels tki derivedfrom a blend of local and global running average predictionsto temper this bias. The local predictionscapture client-specific noise patterns, while the global predictions reflect the broader data distribution,together creating a comprehensive and resilient learning signal. The balancing parameter plays a pivotalrole, meticulously adjusting the blend of local and global perspectives to ensure optimal noise resistance andoverall performance. While local running average prediction alone can be effective in centralized settings, itmay exacerbate local overfitting more swiftly in FL contexts due to data heterogeneity and data shortage.Our strategy of blending local and global predictions can thus be particularly advantageous in such situations.More details are in Subsection 4.3.",
  "(2)": "where Nxki is the Jacobian matrix of the neural network N having parameters for a client ks i th inputwith respect to the . Suppose the actual class is c. In the early training phase, the c th entry of ski isdominant. Setting 0.5 results in a negative c th entry of gki, since the server memorizes slower thanclients, preventing harmful memorization by noisy clients. Moreover, in the case of clean labels, the gradientof LCE term pki yki decreases quickly due to small dataset size, potentially leading to dominance by wronglabels in the gradient. The term gki mitigates this by maintaining the magnitude of coefficients on cleanlabel examples. For mislabeled examples, the gradient of LCE term p(r)ki y(r)ki is positive, and adding the negative term g(r)ki reduces the coefficients on these examples, minimizing their gradient impact. Beyond aconvergence point, the server might not curtail local memorization due to overfitting. The term mki can beadded at this stage to counteract local memorization with local running average predictions.",
  "methodology, aligning with the standard practices in previous LNL and FNL research (Jiang et al., 2022; Xuet al., 2022; Kim et al., 2022; Liu et al., 2020; Li et al., 2020a)": "Experimental resultsOur empirical observations indicate that FLR effectively reduces both local andglobal memorization when compared to models trained using the general FedAvg method, which relies solelyon cross-entropy loss. As demonstrated in (a), the learning curve is smoother for FLR, and theamount of memorization is considerably lower. In addition, the model trained with FLR accurately identifiesthe ground truth labels of noisy samples as the rounds progress, while maintaining the memorized ratioof incorrect labels below 10% ( (b)). We employ warm-up training for regularization with serverprediction during the first 50 epochs and switch to local running average prediction regularization thereafter.This transition causes the inflection point in the graph to appear shortly after warm-up completion in both (a) and (b). Although the accuracy for clean data experiences a slight decrease, the memorization ofnoisy data is significantly reduced. Analysis according to data heterogeneity presents the server-side and client-side memorizationfor both i.i.d. and non-i.i.d. settings when using local and global moving averages. In i.i.d. settings,employing local moving averages alone effectively mitigates global memorization but not local memorization.In contrast, in non-i.i.d. scenarios, using the global moving average has a more significant impact on reducingmemorization. This can be attributed to the fact that when clients have similar data distributions, localinformation is sufficient to prevent memorization in the global model. However, in non-i.i.d. situations,relying solely on local representation is inadequate for preventing global model memorization, making the useof the global moving average more advantageous. In both cases, utilizing a mixture of local and global movingaverage predictions as synthetic pseudo labels produced the best results, as shown in the tables Mixturerows. Although the degree of data heterogeneity may affect the outcome, a balanced mixture of global andlocal predictions seems to be more effective than adopting biased pseudo labels from either side exclusively. Qualitative analysis provides t-SNE mappings of the penultimate layers outputs, where eachdot is visualized according to the predictions by the model trained with standard CE loss ( (a) and(c)) and the model trained with FLR ( (b) and (d)). The color corresponds to the ground truth labels.This visual analysis reveals that FLR significantly enhances cluster fidelity to reflect true class informationof the samples. (a) and (c) depict the clustering under the CE loss, where color discrepanciesindicate noisy label misclassifications. In contrast, (b) and (d) illustrate substantial improvementsunder FLR; clusters are well-separated according to their true classes. Black dashed boxes highlight thevisible transformations from the CE to the FLR model, illustrating the robustness of FLR in correctingmisclassifications. For instance, the transition from scattered and inconsistently colored clusters in (a) to more cohesive and correctly labeled groups in (b) not only evidences a decrease in label noisebut also reflects substantial qualitative enhancements in model performance. The t-SNE plots in provide an intuition regarding how FLR successfully addresses label noise.",
  "Implementation": "provides an illustration of how our method affects model updates. It is widely recognized that usinga running average (i.e., temporal ensembling (Laine & Aila, 2017)) is more effective than relying on staticmodel output. As a result, the baseline version of our method follows Eq. (1). We empirically investigate theeffects of the components , , (). Insights for FLRs effective label noise handling in FL settingsinclude: Influence of and : We observe that higher values of consistently yield better results, indicatinga robust influence of global model predictions on local updates ( (a)). An setting of0.9 acts as a potent regularization mechanism, akin to knowledge distillation, guiding local modelswith the refined, effective knowledge from the global model, thus bolstering system robustness asillustrated in . At an value of 1, the model fully embraces global predictions, epitomizinga comprehensive knowledge distillation strategy. This provides profound insights into the extentof global model influence on local training dynamics. Meanwhile, a setting between 0.5 and 0.7",
  ": (a) Heatmaps with respect to , at (, ) = (0.6, 0.5) on CIFAR-10, (b) learning curves accordingto the changes of at (, ) = (1.0, 0.5) on CIFAR-10": "fine-tunes the update frequency, striking a balance between historical accuracy and mitigation oflocal noise. This measured approach parallels careful learning rate adjustments, promoting gradualadaptation of local models to global insights and preventing destabilizing shifts. Preventing global memorization with : In the presence of extreme noise, global memorizationtends to occur in the latter half of the training process. It is apparent that higher settings result inimproved performance in highly noisy environments. This trend highlights the efficacy of increasing to mitigate global memorization risks by incorporating the moving average predictions from theglobal model ( (b)).",
  "Implications of , , We briefly discuss the implications of our methods:": ": Balances between local and global memorization. A lower leads the model to focus more onlocal memorization, capturing specific patterns unique to each client, but risks overfitting. A higher shifts the emphasis towards global memorization, encouraging learning of universal patterns acrossthe dataset. : Addresses global memorization in the server model, especially after several epochs, by employingtemporal ensembling. This helps the model to maintain an overarching perspective on the learnedpatterns. : Aims to control local memorization. While the server model counters local memorization initially, becomes essential when local memorization re-emerges at a certain convergence point. However,applying too early can interfere with the learning trajectory, thus it is strategically implementedafter reaching a certain level of learning. To effectively tackle memorization, our approach dynamically adjusts the influence of parameters mki andski throughout training. Initially, mki is more influential to support early learning stages, but as trainingprogresses, ski takes precedence for temporal ensembling to address memorization challenges. This dynamicis managed through a sophisticated scheduler:",
  "2else,(r) =0if r < Rwelse": "The selection of values from the 150th epoch in (b) is informed by empirical evidence showing a shift in localmemorization patterns around this stage across benchmarks. This period marks the initiation of our methods application, adecision based on its proven efficacy in enhancing model performance. This strategic timing enables precise monitoring andreporting on the methods impact during critical learning phases, where interventions are most crucial.",
  ": Collaborations with server-aware FL methods (FedProx (Li et al., 2020c) and FedDyn (Durmuset al., 2021)) on CIFAR-10 with i.i.d. setting": "Here, R denotes the total communication rounds, r is the current round, and Rw is the warm-up period for .We set (, , , ) typically to (2.0, 0.9, 0.7, 0.5) with Rw at 50, with further details provided in the Appendix. The linear scheduler for delicately manages the balance between local and global learning. Initially, itenhances local learning to compensate for the global models lower accuracy but gradually shifts to supportglobal learning as the models noise handling improves. and start at zero to accommodate initial learningstages and gradually increase to harmonize the integration of local and global predictions as training advances. For hyperparameter selection crucial to the effective deployment of our methodology, we recommend tailoringthese parameters based on specific data characteristics and learning objectives. Comprehensive guidance onselecting and optimizing these parameters, along with practical application tips, are detailed in the Appendix.",
  "Experimental setup": "We evaluate our methods on two standard benchmark datasets, CIFAR-10 and CIFAR-100 (Krizhevskyet al., 2009), and two real-world datasets, CIFAR10N (Wei et al., 2021) and Clothing1M (Xiao et al., 2015),with varying numbers of clients. We conduct experiments with 100 clients for CIFAR-10 and CIFAR10N,50 clients for CIFAR-100, and 500 clients for Clothing1M. We consider both i.i.d. (CIFAR-10/100) andnon-i.i.d. settings (CIFAR-10/100, CIFAR10N, Clothing1M); non-iidness is parameterized by p and Dir.As CIFAR-10/100 do not inherently contain label noise, we introduce synthetic label noise, where the levelof noise is parameterized by and . CIFAR10N and Clothing1M naturally contain label noise, with datasamples randomly distributed among clients. p, Dir, , and are elaborated upon in . To contrastbetween CL and FL, we also compare our methods with conventional LNL methods in centralized settings,",
  "Results on real world noisy datasets": "CIFAR10NOur experiments demonstrate that FLR surpasses traditional LNL methods utilized in FL.Notably, FLRs effectiveness is further amplified when combined with FedCorr, indicating its robustness andadaptability across diverse FL settings. showcases FLRs significant advantage over other labelregularization techniques. Clothing1MFLR consistently outperforms other LNL methods. Although the accuracy differences amongthe methods are modest, FLRs performance stands out. This consistency in performance is particularlynoteworthy considering the use of a pre-trained model for the initial global model in these experiments. Theresults, detailed in , underscore FLRs capability to improve model accuracy in FL settings, evenunder conditions with pretrained models.",
  "I.I.D. setting": "Our comprehensive evaluation on CIFAR-100 under an i.i.d. setting () showcases FLRs remarkableperformance superiority across diverse label noise settings, including both symmetric and asymmetric noisescenarios. We observe that even well-established CL methods like DivideMix (Li et al., 2020a), while robustin CL, do not seamlessly translate their effectiveness into the federated context. This finding resonates withprior literature on FL (FedCorr (Xu et al., 2022), FedRN (Kim et al., 2022)). Notably, Generalized CrossEntropy (GCE) (Zhang & Sabuncu, 2018) exhibits strong performance, particularly in high symmetric noisescenarios, yet FLR consistently outperforms it in most cases. Combining FLR with FedCorr (i.e., FLR+)yields a synergistic effect, leading to the highest test accuracies across almost all noise settings, except for thenoise-free case. This combination demonstrates FLRs versatility and potential for enhancing FL frameworksunder diverse noise conditions.",
  "FLR+67.850.9164.122.0164.640.3854.101.0169.520.71": "Collaborations with server-aware FL methodsWe also delve into how FLR collaborates with server-aware FL methods. Our findings, presented in , demonstrate that integrating FLR with these methodssignificantly boosts accuracy in various noisy client scenarios. This enhancement is observed consistentlyacross different ratios of noisy clients, highlighting FLRs capability to complement server-aware strategies.This synergy is particularly crucial in federated environments where client data is diverse and often unreliable,showcasing FLRs versatility and effectiveness in improving outcomes in complex FL settings.",
  "Non-I.I.D. setting": "Concentration parameter in Dirichlet distribution Dir shows the results by changing thedata heterogeneity Dir at p = 1.0. Overall, it can be seen that the performance is lower when Dir = 1(local data heterogeneity ) than when Dir = 10 (local data heterogeneity ). It is confirmed that FLRconsistently shows better performance at most noise levels and there seems more a clear difference, especiallywhen data heterogeneity becomes more severe.",
  "Conclusion": "This paper presents Federated Label-Mixture Regularization (FLR), a simple but effective method designed totackle label noise in FL environments. Our work is grounded in two key contributions: a detailed explorationof memorization dynamics in FL, distinguishing between server-side and client-side memorization, and thedevelopment of FLR to address these specific challenges. By creating novel pseudo labels, which are acombination of global running average predictions and local running average predictions, FLR effectivelymitigates these memorization issues. Through comprehensive experiments, FLR demonstrates a markedimprovement in global model accuracy across both i.i.d. and non-i.i.d. data settings. While it shows promisingresults, we acknowledge that FLR may not be optimally suited for all types of label noise. Future researchcould delve into exploring complementary regularization techniques to address various noise structures. Thepotential impact of FLR on real-world applications, especially in sectors like healthcare and financial serviceswhere data privacy is paramount, is significant.",
  "Published in Transactions on Machine Learning Research (11/2024)": "SLR: This is another special case of FLR, specifically when = 1, where local predictions aredirectly penalized by global predictions. Although similar to general distillation, SLR differs inits use of the logarithmic function rather than the Kullback-Leibler function (Hinton et al., 2015).In FL, other methods like FedProx (Li et al., 2020c) and FedDyn (Durmus et al., 2021) improvegeneralization against data heterogeneity by reducing weight divergence between the local and globalmodel. However, our approach is distinct in that it directly mitigates divergence between predictions,rather than model parameters.",
  "Geoffrey Hinton, Oriol Vinyals, Jeff Dean, et al. Distilling the knowledge in a neural network. arXiv preprintarXiv:1503.02531, 2(7), 2015": "Xinyuan Ji, Zhaowei Zhu, Wei Xi, Olga Gadyatskaya, Zilong Song, Yong Cai, and Yang Liu. Fedfixer:Mitigating heterogeneous label noise in federated learning. In Proceedings of the AAAI Conference onArtificial Intelligence, volume 38, pp. 1283012838, 2024. Xuefeng Jiang, Sheng Sun, Yuwei Wang, and Min Liu. Towards federated learning against noisy labelsvia local self-regularization. In Proceedings of the 31st ACM International Conference on Information &Knowledge Management, pp. 862873, 2022.",
  "Taehyeon Kim, Jongwoo Ko, JinHwan Choi, Se-Young Yun, et al. Fine samples for learning with noisy labels.Advances in Neural Information Processing Systems, 34:2413724149, 2021a": "Taehyeon Kim, Jaehoon Oh, NakYil Kim, Sangwook Cho, and Se-Young Yun. Comparing kullback-leiblerdivergence and mean squared error loss in knowledge distillation. arXiv preprint arXiv:2105.08919, 2021b. Taehyeon Kim, Eric Lin, Junu Lee, Christian Lau, and Vaikkunth Mugunthan. Navigating data heterogeneityin federated learning: a semi-supervised federated object detection. In Thirty-seventh Conference on NeuralInformation Processing Systems, 2023.",
  "Junnan Li, Richard Socher, and Steven C.H. Hoi. Dividemix: Learning with noisy labels as semi-supervisedlearning. In International Conference on Learning Representations, 2020a": "Mingchen Li, Mahdi Soltanolkotabi, and Samet Oymak. Gradient descent with early stopping is provablyrobust to label noise for overparameterized neural networks. In International conference on artificialintelligence and statistics, pp. 43134324. PMLR, 2020b. Tian Li, Anit Kumar Sahu, Manzil Zaheer, Maziar Sanjabi, Ameet Talwalkar, and Virginia Smith. Federatedoptimization in heterogeneous networks. Proceedings of Machine Learning and Systems, 2:429450, 2020c. Sheng Liu, Jonathan Niles-Weed, Narges Razavian, and Carlos Fernandez-Granda. Early-learning regular-ization prevents memorization of noisy labels. Advances in neural information processing systems, 33:2033120342, 2020. Xingjun Ma, Yisen Wang, Michael E. Houle, Shuo Zhou, Sarah Erfani, Shutao Xia, Sudanthi Wijewickrema,and James Bailey. Dimensionality-driven learning with noisy labels. In Jennifer Dy and Andreas Krause(eds.), Proceedings of the 35th International Conference on Machine Learning, volume 80 of Proceedings ofMachine Learning Research, pp. 33553364. PMLR, 1015 Jul 2018. Brendan McMahan, Eider Moore, Daniel Ramage, Seth Hampson, and Blaise Aguera y Arcas. Communication-efficient learning of deep networks from decentralized data. In Artificial intelligence and statistics, pp.12731282. PMLR, 2017. Mohammad Momeny, Ali Mohammad Latif, Mehdi Agha Sarram, Razieh Sheikhpour, and Yu Dong Zhang. Anoise robust convolutional neural network for image classification. Results in Engineering, 10:100225, 2021.",
  "Hwanjun Song, Minseok Kim, Dongmin Park, Yooju Shin, and Jae-Gil Lee. Learning from noisy labels withdeep neural networks: A survey. IEEE Transactions on Neural Networks and Learning Systems, 2022": "Antti Tarvainen and Harri Valpola. Mean teachers are better role models: Weight-averaged consistencytargets improve semi-supervised deep learning results. Advances in neural information processing systems,30, 2017. Vale Tolpegin, Stacey Truex, Mehmet Emre Gursoy, and Ling Liu. Data poisoning attacks against federatedlearning systems. In European Symposium on Research in Computer Security, pp. 480501. Springer, 2020. Vasileios Tsouvalas, Aaqib Saeed, Tanir Ozcelebi, and Nirvana Meratnia. Labeling chaos to learning harmony:Federated learning with noisy labels. ACM Transactions on Intelligent Systems and Technology, 15(2):126, 2024. Tiffany Tuor, Shiqiang Wang, Bong Jun Ko, Changchang Liu, and Kin K Leung. Overcoming noisy andirrelevant data in federated learning. In 2020 25th International Conference on Pattern Recognition (ICPR),pp. 50205027. IEEE, 2021.",
  "Jiaheng Wei, Zhaowei Zhu, Hao Cheng, Tongliang Liu, Gang Niu, and Yang Liu. Learning with noisy labelsrevisited: A study using real-world human annotations. arXiv preprint arXiv:2110.12088, 2021": "Jiaheng Wei, Hangyu Liu, Tongliang Liu, Gang Niu, Masashi Sugiyama, and Yang Liu. To smooth ornot? When label smoothing meets noisy labels. In Kamalika Chaudhuri, Stefanie Jegelka, Le Song,Csaba Szepesvari, Gang Niu, and Sivan Sabato (eds.), Proceedings of the 39th International Conference onMachine Learning, volume 162 of Proceedings of Machine Learning Research, pp. 2358923614. PMLR,1723 Jul 2022. Nannan Wu, Li Yu, Xuefeng Jiang, Kwang-Ting Cheng, and Zengqiang Yan. Fednoro: Towards noise-robust federated learning by addressing class imbalance and label noise heterogeneity. arXiv preprintarXiv:2305.05230, 2023. Xiaobo Xia, Tongliang Liu, Bo Han, Chen Gong, Nannan Wang, Zongyuan Ge, and Yi Chang. Robustearly-learning: Hindering the memorization of noisy labels.In International conference on learningrepresentations, 2020. Tong Xiao, Tian Xia, Yi Yang, Chang Huang, and Xiaogang Wang. Learning from massive noisy labeled datafor image classification. In Proceedings of the IEEE conference on computer vision and pattern recognition,pp. 26912699, 2015.",
  "Zhilu Zhang and Mert Sabuncu. Generalized cross entropy loss for training deep neural networks with noisylabels. Advances in neural information processing systems, 31, 2018": "Songzhu Zheng, Pengxiang Wu, Aman Goswami, Mayank Goswami, Dimitris Metaxas, and Chao Chen.Error-bounded correction of noisy labels. In Hal Daum III and Aarti Singh (eds.), Proceedings of the 37thInternational Conference on Machine Learning, volume 119 of Proceedings of Machine Learning Research,pp. 1144711457. PMLR, 1318 Jul 2020. Xiaochen Zhou and Xudong Wang. Federated label-noise learning with local diversity product regularization.In Proceedings of the AAAI Conference on Artificial Intelligence, volume 38, pp. 1714117149, 2024.",
  "BEthics Statement": "As we advance the field of Federated Learning (FL) with our novel Federated Label-mixture Regularization(FLR) method, it is crucial to consider its ethical implications. We address potential concerns in the areas ofprivacy, fairness, environmental impact, and potential misuse. Privacy and data securityFLR, like other FL methods, is designed to maintain the privacy of clientsdata by performing computations locally and only sharing model updates. This approach inherently mitigatesprivacy concerns arising from the transmission of raw data. However, potential risks persist with the possibilityof model inversion attacks or other adversarial actions. Future work must continue to focus on strengtheningthe robustness of FL methods against such threats. FairnessFLR could potentially exacerbate or mitigate existing fairness issues in FL depending on howit is deployed. On one hand, if FLR is used predominantly with data from certain demographics, it mayintroduce bias into model predictions. On the other hand, FLRs ability to handle noisy labels may allow forthe inclusion of previously excluded data, promoting a more diverse and fair model. Environmental impactFLR, like other FL methods, reduces the need for centralized data storage andcomputation, potentially lowering the carbon footprint associated with these processes. However, the energyconsumption of local computation and communication for model updates must be carefully managed toensure environmental sustainability. Potential misusesWhile FLR is designed to improve the robustness of FL methods against noisy labels,it could potentially be misused to intentionally introduce bias or misinformation into models. For instance,malicious actors could leverage our method to facilitate their objectives by manipulating the noise in labels.Hence, it is crucial to develop safeguards against such misuse. In conclusion, while FLR contributes positively to the FL field by offering a solution to handle noisy labels,it is essential to apply it thoughtfully, considering its potential ethical implications. We encourage ongoingdialogue and scrutiny to ensure that its deployment aligns with principles of privacy, fairness, and socialresponsibility.",
  "While our FLR method presents several noteworthy advancements in handling noisy labels in FL, it is crucialto acknowledge the limitations that accompany it:": "1. Performance with highly imbalanced data: Although our FLR method demonstrates robustnessin diverse data heterogeneity scenarios, its efficacy in situations with severe data imbalance acrossclients is an area that requires further investigation. Data imbalance here refers to the unevendistribution of data classes across different clients. For example, one client might have a majority ofsamples from a particular class while another client might have a very few samples of that class. Thissevere skewness in data distribution can lead to biased learning, where the model performs well onclasses with more samples but poorly on classes with fewer samples. Although FLR has mechanismsto mitigate the effects of data heterogeneity, it is not explicitly designed to handle extreme dataimbalance. 2. Computational overhead: While the FLR method is effective in improving the models robustnessagainst noisy labels, it also introduces additional computational overhead. This is primarily dueto the calculation of local and global moving averages, which are central to the FLR method. The",
  "Despite the aforementioned limitations, the FLR method opens up several promising avenues for futureresearch:": "1. Handling other noise types: Future work can look into extending the FLR method to handleother types of noise efficiently. This would make it a more comprehensive solution for real-worldfederated scenarios where different types of noise coexist. 2. Adaptation for imbalanced data: Investigating and enhancing the performance of FLR withhighly imbalanced data distribution would be a valuable future direction. Techniques like adaptiveresampling or cost-sensitive learning could be integrated with our method to tackle this challenge. 3. Applications on natural language processing: Despite the emergent ability of Large LanguageModels (LLM), they also struggle with the privacy issues. Employing LLM training in federatedscenario may meet noisy labels and texts with high probability, and thus our work can be a goodsolution in this area. 4. Optimization of computational efficiency: Future research could also focus on optimizingthe computational efficiency of the FLR method. Reducing the computational overhead withoutcompromising the robustness against noisy labels would make our method more practical for real-worldFL scenarios. 5. Robustness against adversarial attacks: As the FL domain evolves, adversarial attacks pose anincreasing threat to model robustness. Future work could explore how to bolster the FLR method(and FL methods, in general) to ensure robustness against adversarial attacks. 6. Domain generalization:Another major challenge of data heterogeneity in real-world FL applica-tion is the divergence of domain data, also known as domain shift (Bartholet et al., 2024). Futurework should also consider the robustness to domain shift adding to the noisy labeled data.",
  "Initialization: The server model parameters, denoted as server, are initialized with randomlychosen parameters, 0": "Training iterations: A loop for each epoch initiates, where a subset of clients Se are selected fortraining. For every chosen client, they start with a model whose parameters match those of theserver model (k = server). The model parameters are updated through local gradient descent stepson their individual datasets, applying the standard CE loss.",
  "The delineated algorithm offers a comprehensive blueprint for implementing FL in the presence of noisylabels, effectively handling data heterogeneity and varying label noise across different clients": "In addressing potential concerns regarding the computational demands posed by our FLR method, it isimportant to note that these are effectively managed through localized computations at the client level coupledwith strategic synchronization. These strategies are integral to FL frameworks and are designed to managethe computational load efficiently. By employing localized computations and selective synchronization, weensure that the additional complexities introduced by FLR do not overburden the system. This approach notonly optimizes resource utilization but also confirms the practicality and feasibility of implementing FLR",
  "GCE (Zhang & Sabuncu, 2018) requires two hyperparameters, q and . We selected q = 0.7, = 0.1for CIFAR-10 and Clothing1M, and q = 0.1, = 0.3 for CIFAR-100 in our experiments": "Co-teaching (Han et al., 2018) uses two models. In our implementation of Co-teaching for FL, wemaintain two global models w1 and w2. When each round starts, both of them are given to each clientas the local models w1k and w2k, and each client trains them with Co-teaching process. After thelocal updates are done, the global models are updated by global aggregation respectively; {w1k} w1and {w2k} w2. DivideMix (Li et al., 2020a) for FL is implemented in the same way as in the Co-teaching case.Regarding hyperparameters, we set 0.5 for the sharpening temperature, and 25 for the unsupervisedloss coefficient. Early Learning Regularization (ELR) (Liu et al., 2020) requires two coefficients and for itsregularization term. After many trials of grid search, we found that = 4.0 with = 0.5 forsymmetric noise and = 0.9 for asymmetric noise works better than any other hyperparametervalues that we tested, in most of our experimental settings. We used = 4.0 and = 0.5 also forClothing1M.",
  "0if r < Rwelse": "where Rw denotes the epoch for warmup training, which is set to 50. For the methods developed in CLsettings such as Mixup (Zhang et al., 2018), GCE (Zhang & Sabuncu, 2018), Co-teaching (Han et al., 2018),DivideMix (Li et al., 2020a), and ELR (Liu et al., 2020), we just follow the implementation of their originalpapers.",
  "Clothing1M-2.0w/ FedCorr3.0": "Server-aware Learning Regularization (SLR): This is another special case of FLR, specifically when = 1, where local predictions are directly penalized by global predictions. Although similar togeneral distillation, SLR differs in its use of the logarithmic function rather than the Kullback-Leibler function (Hinton et al., 2015). In FL, other methods like FedProx (Li et al., 2020c) andFedDyn (Durmus et al., 2021) improve generalization against data heterogeneity by reducing weightdivergence between the local and global model. However, our approach is distinct in that it directlymitigates divergence between predictions, rather than model parameters.",
  "Entropy Regularization (ER): In scenarios where = = 0, the regularization aligns closely withthe entropy minimization term (Grandvalet & Bengio, 2004)": "shows the results of ER comparing with Entropy Minimization (EM) (Grandvalet & Bengio, 2004),Label Smoothing (LS) (Pereyra et al., 2017), Negative Label Smoothing (NLS) (Wei et al., 2022), and Temper-ature Scaling (TS) (Guo et al., 2017). It is observed that even simple entropy penalization for each instancewith either EM or ER can make the model to be robust towards noisy labels.",
  "In this section, we present the learning curves over 300 epochs for four different strategies: ELR, SLR, Mixup,and FLR. The curves are plotted under both the i.i.d. and non-i.i.d. settings": "Our observations indicate that both FLR and SLR generally perform well, with FLR consistently exhibitingsuperior performance (). This underlines the effectiveness of our proposed FLR method in combatingthe effects of noisy labels in the FL environment. On the other side, as the number of epochs increases, ELR and Mixups performance tends to deteriorate.This is particularly evident in their generalization capabilities, which decrease due to memorization. Thismemorization effect is particularly evident when these methods are exposed to prolonged training, which is acommon situation in a real-world scenario."
}