{
  "Abstract": "This paper introduces two novel solutions to the challenge of catastrophic forgetting incontinual learning: Interpretability Guided Continual Learning (IG-CL) and Intrin-sically Interpretable Neural Network (IN2). These frameworks bring interpretabilityinto continual learning, systematically managing human-understandable concepts withinneural network models to enhance knowledge retention from previous tasks. Our methods aredesigned to enhance interpretability, providing transparency and control over the continualtraining process. While our primary focus is to provide a new framework to design continuallearning algorithms based on interpretability instead of improving performance, we observethat our methods often surpass existing ones: IG-CL employs interpretability tools to guideneural networks, showing an improvement of up to 1.4% in average incremental accuracy overexisting methods; IN2, inspired by the Concept Bottleneck Model, adeptly adjusts conceptunits for both new and existing tasks, reducing average incremental forgetting by up to 9.1%.Both our frameworks demonstrate superior performance compared to exemplar-free methods,are competitive with exemplar-based methods, and can further improve their performance byup to 18% when combined with exemplar-based strategies. Additionally, IG-CL and IN2 arememory-efficient as they do not require extra memory space for storing data from previoustasks. These advancements mark a promising new direction in continual learning throughenhanced interpretability1.",
  "Introduction": "Continual learning is a crucial aspect of machine learning, empowering models to adapt and improve asthey encounter new data over time. This dynamic learning process, however, faces a significant hurdleknown as \"catastrophic forgetting.\" This phenomenon, where a model forgets previously learned informationupon acquiring new knowledge, is largely attributed to the shift in input distribution with changing tasks.According to van de Ven et al. (2022); De Lange et al. (2021), there are three primary settings in continuallearning: class incremental, task incremental, and domain incremental. Our focus in this paper is on the classincremental setting, identified as the most challenging setting among three due to its pronounced susceptibilityto catastrophic forgetting, as detailed in van de Ven et al. (2022); Chaudhry et al. (2018); De Lange et al.(2021). Current strategies in continual learning fall into the following main categories: Exemplar-free and Exemplar-based methods. Exemplar-free methods do not rely on data from old tasks, like regularization-basedmethods that introduce constraints to preserve old knowledge; architecture-based methods that adapt themodels structure for new tasks. On the other hand, Exemplar-based methods, also known as replay-based",
  "Published in Transactions on Machine Learning Research (09/2024)": "observed examples from previous tasks, which is described as episodic memory. When training on new tasks,it regularizes the projection of the estimated gradient descent g on the gradient descent of episodic memorygk. The optimization goal is formalized as g, gk 0, k < t when training on the task t. This regularizationprevents the loss of episodic memory from increasing. (Rebuffi et al., 2017) stores a subset of samples foreach class and uses the nearest-mean classifier on the data representation space.",
  "IG-CL (Ours)YesYesYesYes, text-based concept (more general)IN2 (Ours)YesYesYesYes, text-based concept (more general)": "continual learning from two perspectives. IG-CL brings interpretability to continual learning by using externalinterpretability tools to guide models. On the other hand, IN2 tailor interpretable models like CBM forcontinual learning by leveraging their own interpretability. While our focus is on proposing a new frameworkto design continual learning algorithms based on interpretability, we observe that our methods often surpassexisting ones. For instance, our approach outperforms exemplar-free methods in average incremental accuracyand is competitive with exemplar-based methods. When combined with exemplar-based strategies, ourmethods enhance their performance by up to 18%. Additionally, our methods are memory-efficient, requiringno extra memory space for storing data from previous tasks. The benefits of our methods are summarized in. Interpretability is key distinguishing feature of our approach compared to existing methods.",
  "Continual Learning": "To mitigate catastrophic forgetting in continual learning, several methods have been proposed. They canbe categorized into Exemplar-free and Exemplar-based methods. For Exemplar-free methods, itconsists of two streams: regularization-based methods and architecture-based method. The key idea ofregularization-based methods is to add additional terms in the loss function to constrain model parametersto not change too much from previous tasks (Kirkpatrick et al., 2017; Zenke et al., 2017; Li & Hoiem, 2017;Jung et al., 2016; Dhar et al., 2019; Castro et al., 2018; Hu et al., 2019; Lee et al., 2019; Aljundi et al., 2018;Chaudhry et al., 2018; Lee et al., 2017; Schwarz et al., 2018). On the other hand, architecture-based methodsmodify the models architecture or parameters when learning new tasks, by dynamic expansion or pruning(Rusu et al., 2016; Yoon et al., 2018; Xu & Zhu, 2018; Yan et al., 2021; Li et al., 2019; Serra et al., 2018;Wang et al., 2021; Zhu et al., 2022). For Exemplar-based method, it is also known as replay-based methods,whose spirit is to store previous tasks information and train the model with new tasks jointly (Lopez-Paz &Ranzato, 2017; Rebuffi et al., 2017; Chaudhry et al., 2019; Rolnick et al., 2019; Hou et al., 2019; Wu et al.,2019; Buzzega et al., 2020; Wang et al., 2022; Guo et al., 2022; Liu et al., 2021; Aljundi et al., 2019). Moredetails of these methods is in Appendix D.2. Meanwhile, some works focus on the theoretical aspect of continual learning (Peng et al., 2023; Peng &Risteski, 2022; Cao et al., 2022; Ruvolo & Eaton, 2013; Pentina & Urner, 2016; Chen et al., 2022; Kim et al.,2022). However, none of these methods are able to control human-interpretable concepts directly, whichmakes them lack interpretability. Indeed, interpretability is one of the main differences between our methodsand existing methods. There are some recent works (Marconato et al., 2023; Rymarczyk et al., 2023) connectsinterpretability with continual learning. They focus on part-based prototype concepts or neuro-symbolicconcepts. Our work focuses on text-based concepts instead, which allows more general interpretability.Meanwhile, they are only suitable for particular model architectures whereas our methods are compatible forgeneral DNN.",
  "Neuron-Level Interpretation and Concept Bottleneck Models": "Several works (Bau et al., 2017; 2020; Oikarinen & Weng, 2023; Hernandez et al., 2022; Mu & Andreas,2020; Bai et al., 2024; Oikarinen & Weng, 2024) provide automated descriptions of the roles of individualneurons in deep vision models, and do extensive studies for their methods interpretability. Typically thesemethods generate a description by analyzing what kinds of inputs result in high activations for the givenneuron. For example, Network Dissection (Bau et al., 2020) identifies the concepts of individual neuronsby comparing the neurons activation map to concept annotated data. A more recent work CLIP-Dissect(Oikarinen & Weng, 2023) eliminates the need of concept annotated data by leveraging the ContrastiveLanguage-Image Pre-training (CLIP) model (Radford et al., 2021) and designing several similarity functions.Detailed introduction of CLIP-Dissect is in Appendix D.2.2. In this paper, we explore a departure from thetypical emphasis on refining interpretability tools, instead utilizing them to guide continual learning processes.Our work focuses on the computer vision domain since the interpretability tools in the domain have madesignificant progress. It can be applied to other domains like NLP with their interpretability tools like Sajjadet al. (2022); Lee et al. (2023) potentially in the future. Concept Bottleneck Model (CBM) (Koh et al., 2020) has a layer called Concept Bottleneck Layer (CBL)where each neuron corresponds to a human interpretable concept. The idea of CBL is to create an meaningfulconcept mapping from black-box representations to a layer that contains a human-interpretable concept setC, allowing effective intervention and explaining the model predictions. Recent works (Oikarinen et al., 2023;Yuksekgonul et al., 2023; Srivastava et al., 2024) try to address it since concept annotations is expensive andhard to collect. Specifically, Label-Free CBM (LF-CBM) (Oikarinen et al., 2023) generates concepts fromtask information. Detailed introduction of LF-CBM is in Appendix D.2.2. The concept set C generationdepends on the CBM. For LF-CBM (Oikarinen & Weng, 2023), concept sets are generated by asking largelanguage models like GPT-3 (Brown et al., 2020) about the concepts related to the classes. For originalCBM (Koh et al., 2020), concept sets has to be predefined and provided in the dataset. The primary focus ofthese CBM works is only on single task and does not consider the challenging continual learning setting. Incontrast, our IN2 is tailored for continual learning with a new learning procedure that enables it to learn aseries of tasks, which generalizes CBM-based methods to continual learning.",
  "Our first method: IG-CL": "Overview.To address catastrophic forgetting, we aim to manage concepts learned by models in aninterpretable manner. We introduce two frameworks: Interpretability Guided Continual Learning(IG-CL) in this section and Intrinsically Interpretable Neural Network (IN2) in the next section.IG-CL uses an interpretability tool to steer the learning process, identifying and preserving previously learnedconcepts to prevent forgetting. This approach enhances model comprehension and has shown to improveincremental accuracy by up to 1.4%. Building on this, IN2 incorporates interpretable neurons that aresystematically integrated and controlled, further reducing forgetting by up to 9.1% in our experiments. illustrates the key steps in IG-CL, and the details of each step are described below. IG-CLs full algorithmis summarized in Algorithm 1 in Appendix C.2.",
  "Step 1: Decipher network": "Initially, we use a neuron-interpretability tool to decipher the interpretable neurons in the model. Interpretableneurons are defined as those whose activations correspond closely to human-understandable concepts (e.g.\"red\", \"stripes\", \"windy\", etc). A model, denoted as , consists of a feature extractor {Wl}Ll=1, also known asa backbone, and a prediction layer WF . Our goal is to preserve the important concepts learned from theprevious tasks. Previous work (Bau et al., 2020) analyzes the concept neurons in each layer, and finds outthat high-level concept neurons emerge in the deep layers. Low-level concepts are basic descriptions likecolors, while high-level concepts are objects or components of the images. The high-level concepts are specificto the classes in the previous tasks, which needed to be preserved. Therefore, we apply the interpretabilitytool on the last layer of the feature extractor WL to decipher the neurons. The discovered interpretable",
  ":The illustra-tion of two freezing sub-network methods.Rednodes and lines standfor trainable unit andweights": "Second, we want to freeze the concept units in the model to preserve the learnedknowledge. These concept units emerged in the network during learning thecurrent task t 1. To prevent catastrophic forgetting, it is desired to preservethese concept units when learning a new task t. To achieve this, we propose to findand freeze these task-related neurons when learning the new task t by finding asub-network which links all related neurons. In practice, this can be implementedby using Breadth First Search (BFS) from the concept unit in WL to the inputlayer W1. Define two neurons are connected when the weight exceeds threshold .We propose two ways to freeze the subnetworks to preserve the learned knowledgeby different degrees:",
  "We describe Step 2 mathematically in Line 7 - Line 19 of Algorithm 1 in AppendixC.2": "The freeze-part method leaves the output weights of the neurons in the subnet-work trainable, which may have a better ability to learn new tasks. For freeze-allmethod, it isolates the subnetworks from the rest of the model which is expectedto promote less forgetting. An illustration of these two methods is in .The experiment results in show that the freeze-all method forgets less, while the freeze-partmethod has better learnability for a longer series of tasks as expected. This step is summarized in Algorithm1 Line 8-19.",
  "Step 3: Learning without forgetting": "Next, we train the model on a new task t with Eq. (1). Let Dt be the data for task t. We have two goalswhen learning task t: regularize (i) the size of subnetworks and (ii) WF . To regularize the size of subnetworksdescribed in Step 2, we choose p = 2, q = 1 and to regularize the number of activated units. Second,",
  "Further Discussion": "Interpretability. IN2 is a versatile framework that supports various approaches for constructing CBMs(Koh et al., 2020; Yuksekgonul et al., 2023; Oikarinen et al., 2023), enhancing interpretability by allowinganalysis of predictions in human-understandable terms, as illustrated in . This interpretability alsomakes the progression of knowledge acquisition in continual learning transparent, a significant improvementover previous architecture-based methods (Yoon et al., 2018; Wang et al., 2021), which lack clarity andinterpretability on the knowledge integrated into the extended architecture. Similar to IG-CL, generalizability,efficiency and accuracy are the selection criteria for CBMs. Because the CBMs for IN2 have to be accuratelyapplied on different data streams, and be efficient for smooth continual learning processes. Based on thesecriteria, in this work we build IN2 upon LF-CBM (Oikarinen et al., 2023). Ability to Share Concepts Among Tasks. IN2 is designed to keep the learned concepts from old tasks., Appendix A.2 and B.6 study IN2s ability, and show that it can improve GEM (Lopez-Paz &Ranzato, 2017) by up to 7.8% in forward transfer metric when combining with GEM.",
  "Our second method: IN2": "In the previous , we introduced IG-CL as a novel interpretable method to identify and manageconcept units in models for reducing catastrophic forgetting, marking it as a pioneering approach in theregularization-based category. Building on this, we now present the Intrinsically Interpretable NeuralNetwork (IN2), a new architecture-based method that transforms any neural network into an interpretableframework designed for continual learning. IN2 uniquely maintains previously learned concept units whileintegrating new ones for upcoming tasks, demonstrating a reduction in average incremental forgetting byup to 9.1% over existing methods according to our experiments. Compared with IG-CL, IN2 does not needexternal interpretability tools since CBM provides interpretability. illustrates the procedure of IN2.",
  "Step 0: Set up CBM": "For the first task, the learning procedure is the same as training a Concept Bottleneck Model (CBM) (Kohet al., 2020) on the first single task. In the continual learning setting, after learning the task t 1, the CBMhas a concept set Ct1 and the concept mapping W t1cin between the backbone and the prediction layer.We consider the setting that backbone f(x) is frozen for reduced training cost, but our method also allowsbackbone being trained from scratch or finetuned. For task t, we create a task-relevant concept set ctk from itsclass labels k. Creation of the task-relevant concept sets depends on the Concept Bottleneck Model (CBM).For Label-free CBM (Oikarinen et al., 2023), concept sets are generated by asking GPT-3 about the conceptsrelated to the classes. For CBM (Koh et al., 2020), concept sets are predefined and provided in the dataset.In the following paragraphs of IN2s learning procedure, we consider the case that the model has learnedt 1 tasks, and it is going to learn a new task t.",
  "Step 1: Concept set expansion": "In this step, we expand the concept set based on classes in new task t. Given the concept set from t 1 tasksas Ct1, we form a new concept set Ct by adding all concepts from ctk and Ct1. If certain concepts in ctkare already present in Ct1, we still include them nonetheless. This is because identical textual conceptsacross different tasks may exhibit distinct attributes, such as variations in color and shape. For example,concept \"ship\" might refer to \"vessel\" or \"cargo ship\" in different tasks. After the expansion, there are|Ct| = |Ct1| + |ctk| concepts in Ct. The analysis of duplicate concepts and numbers are in Appendix C.3",
  "W tc[i, :] = W t1c[i 1, :]i {1, 2, ..., |Ct1|}(2)": "where W tc[i, :] means the i-th row of the W tc. The second step is to learn W tc using the procedure of CBM.Take LF-CBM Oikarinen et al. (2023) as an example. LF-CBM aims to align the concept mapping withCLIPs (Radford et al., 2021) representation of the concepts. Therefore, the procedure is to maximize thesimilarity between concept mappings f tc(x) = W tcf(x) and CLIPs activation matrix. The second step canbe done in two ways:",
  ". Finetune: We learn W tc on task t without additional constraints. We only initialize W tc with old conceptsbut these concepts will be changed on the new task": "2. IN2: We freeze the previous concepts corresponding mapping in W tc to prevent them from changing. Thisstrategy enables us to learn the mapping of new concepts without affecting the previously learned ones.This strategy makes IN2 light and interpretable. It eliminates the need for additional memory storage forprevious tasks samples, and provides transparency regarding the retained knowledge.",
  "Step 3: Learning the prediction layer": "Finally, we aim to learn the prediction layer without forgetting. First, we inherit prediction weights in W t1Fto W tF before the learning process. The idea is similar to Step 2, where |Ct1| concept output weights in W tFinherit the same weights from W t1F. Again, the Finetune strategy is to learn W tF without any constraints.On the other hand, the IN2 strategy follows the similar idea as IG-CLs Step 3 to learn the prediction layerwith regularization and = 2. Meanwhile, we control the sparsity of WF by setting = 1 and . Giventhe dataset Dt = (X t, Yt), the training goal is to minimize the loss in Eq. (3) where L could be cross-entropy",
  "Experiments": "In .1, we introduce the datasets, evaluation metrics, baselines and other details in the experiment.In .2, we compare our methods with existing methods in standard metrics. In .3, we unveilthe learned knowledge and the training process by leveraging IG-CL and IN2 interpretability. In .4,we conduct ablation studies for our methods to analyze the contributions to their superior performance. Dueto page limit, additional experiments and discussions are in Appendix A, B and C. An overview of additionalexperiments is provided in the first page of Appendix as Appendix Outline.",
  "Experiment setup": "Dataset. To evaluate our methods, we perform experiments on two datasets: CIFAR-100 (Krizhevskyet al., 2009) and TinyImageNet (Le & Yang, 2015). Experiments on CIFAR-10 (Krizhevsky et al., 2009) andCUB-200 (Wah et al., 2011) are discussed in Appendix B and C. We consider T = 5, 10, 20 tasks scenario inclass incremental setting. We use ResNet18 (He et al., 2016) as the experiment model. Experiment, dataset,result report and hyperparameter selection details are in Appendix D.1. Evaluation Metrics. Following (Mirzadeh et al., 2022b; Chaudhry et al., 2018), we use the standardevaluation metrics to evaluate our methods. Define ai,j as models accuracy on j-th task after learning i-thtask, i j. When testing the performance on t-th task, the metrics definitions are as follows:",
  "GEM (Lopez-Paz & Ranzato, 2017) and MIR (Aljundi et al., 2019)": "Notations and Details. For IG-CL, \"IG-CL-freeze-x\" means IG-CL with implementation freeze-all/ freeze-part in Step 2. For CBM based methods, \"Finetune-CBM\" means using Finetune strategy in Step 2 andStep 3, while \"IN2\" means using IN2 strategy instead. \"IN2-remove\" means removing duplicate concepts inconcept set expansion. \"-GEM\" and \"-MIR\" means combining our methods with GEM and MIR respectively.For baseline strategies, we use the implementations from a continual learning library Avalanche (Lomonacoet al., 2021). We also use Avalanche to implement our methods. Here we discuss T = 5 experiment results in { AT , FT }. For different metrics {AT , FT }, please see AppendixB.3; for experiment results of {T = 10, 20}, please see Appendix B.4. The comparisons with SSRE (Zhuet al., 2022), DEN (Yoon et al., 2018) and ICICLE (Rymarczyk et al., 2023) are in Appendix B.5. We werenot able to compare with DER (Yan et al., 2021) as their official code is incomplete. Due to scalabilityand efficiency, we use CLIP-Dissect (Oikarinen & Weng, 2023) as the interpretability tool for IG-CL, andLF-CBM (Oikarinen et al., 2023) for CBMs in IN2. Memory usage experiment is in Appendix C.1. : Accuracy comparison for IG-CL. means larger values are better, while means smaller valuesare better. Underline means the strongest baseline, and boldface means the best number. In the OursImprovement rows, +/- measures our best number minus the strongest baseline, and the value is in blue ifour improvement is statistically significant. Our methods outperform the baselines on both AT and FT .",
  "Comparison results for IG-CL": "For IG-CL, the accuracy comparisons with existing works are in . Compared with the Exemplar-freemethods, our method outperforms existing works by up to 1.4% in AT and up to 1.3% in FT . Most ofthe time IG-CL performs better using freeze-all than with freeze-part. Meanwhile, the performance iscomparable to or even better than Exemplar-based methods in some benchmarks. When combining IG-CLwith Exemplar-based methods, both freeze-all and freeze-part tend to improve Exemplar-based method toachieve higher AT by up to 5.1% and lower FT by up to 18.0%. The experiment results show that IG-CL canmake models more effective and forget less, either standalone or combining with other methods. Consideringthe experiment results of 10-task and 20-task scenario in Appendix B.4, we observe that freeze-part has betterperformance when task number is bigger. Overall, the freeze-all approach is suitable for a limited number oftasks and emphasizes preserving learned knowledge, while the freeze-part approach is more appropriate forscenarios involving a large number of tasks. : Accuracy comparison for IN2. All models are pre-trained on the Place365 dataset (Zhou et al., 2017). means larger values are better, while means smaller values are better. Underline means the strongestbaseline, and boldface means the best number. In the Ours Improvement rows, +/- measures our bestnumber minus the strongest baseline, and the value is in blue if our improvement is statistically significant.Our methods clearly outperform the baselines on both AT and FT .",
  "Comparison results for IN2": "compares the results of IN2 and baselines. It can be seen that our Finetune-CBM already outperformsexisting exemplar-free methods in balanced average accuracy AT with often better balanced average forgettingFT , which indicates the impact of CBM in continual learning. Notably, our IN2 even has better performanceon both metrics by up to 0.8% in AT and 9.1% in FT . Additionally, combining IN2 with exemplar-basedmethods can further yields more improved performance for the exemplar-based methods by up to 6.7% in ATand 7.3% in FT . However, the trade-off between interpretability and accuracy causes a minor performancedrop for MIR. CBM transforms a neural networks architecture into a more interpretable one, which causes aslight decrease in accuracy as LF-CBM (Oikarinen et al., 2023) and Post-hoc CBM (Yuksekgonul et al., 2023)shows. However, IN2 increases interpretability significantly compared with the previous continual learningmethods. When remove duplicate concepts in concept set expansion, both AT and FT are worse than originalIN2, but still better than the baselines in FT with similar AT . Since the same text concepts can represent",
  "different visual concepts, as demonstrated in Appendix C.3, adding duplicate concepts help IN2 achievesbetter performance": "Remark. Our methods, IG-CL and IN2, introduce interpretability to continual learning for the first time.While often achieving superior performance on two standard metrics compared to baselines, its importantto emphasize that our primary goal extends beyond mere performance enhancement. Our approach maysometimes yield accuracy comparable to or slightly worse than existing methods in 5-task scenario anddifferent settings in Appendix B, yet it stands out by significantly boosting interpretability. This innovationmarks a pivotal step in making continual learning not just more effective, but also more understandable.",
  "In this section, we visualize the learned concept to give more insights on the proposed IG-CL and IN2": "IG-CL. For IG-CL, we study the evolution of the concepts represented by neurons as we train across differenttasks. We analyze the case which we group similar classes into the same task, so we can recognize which taska concept belongs to easier. For CIFAR-100 and TinyImagenet, the class distributions are in appendix D.3.We try to maximize the diversity between tasks, which makes tasks share less concepts and become morechallenging in continuous learning regime. First, we use CLIP-Dissect (Oikarinen & Weng, 2023) to analysehow many units are still detecting the same concept after learning a new task. The results are in and . The values are in in Appendix A.1. Compared with existing methods, our methodhas better ability to retain knowledge of concepts, with by up to 62.5% improvement in the preserved ratioas shows. We also do a case study to understand how well our method preserves the concept unitsfrom the previous tasks. shows results for some example neurons. Some concepts are preserved afterlearning unrelated new tasks, which gives us insight on how our method helps avoid catastrophic forgetting.As shows, IG-CL outperforms baselines by up to 1.3% in forgetting metric FT . : Concept evolution for IG-CL in freeze-all implementation. We analyse the concept evolution in thelayer 4 of ResNet18. The blue concept means the concept is related to the current task, while the greenconcept means it is unrelated. \"x\" stands for non-interpretable units. The results show that IG-CL canpreserve the concepts from previous classes.",
  "Unit 307xKitchenKitchenxxUnit 310xxxHighwayHighway": "IN2. For IN2, we also studied the evolution of concepts across different tasks. shows an examplefor CIFAR-100 under 5-tasks scenario, with more results in Appendix A.2. As discussed in the previoussection that though our Fine-tune CBM results is already better than many Exemplary-free baselines, ourIN2 is even better than Fine-tune CBM, especially on FT , with up to 12.4% improvement. This can be seenin that IN2 is much better at retaining and using knowledge of concepts learned from previoustasks, which is the key to help to combat against catastrophic forgetting. As shows, IN2 outperformsbaselines by up to 9.1% in forgetting metric FT .",
  "(b) IN2": ": Final weight visualization for random classes in (a) Finetune-CBM and (b) IN2 trained on CIFAR-100 under 5-tasks scenario. The class distribution is in but swap task 1 and task 2. For class \"mapletree\" from task 1, we show its significant weight (> 0.16) after training on task 1 and task 2. Conceptsgenerated from the maple tree class itself are colored blue, and other concepts from task 1 are colored gray.We can see IN2 keeps a similar final layer while Finetune-CBM loses most significant weights.",
  "Ablation Studies": "To understand the contributions of IG-CL and IN2s continual learning abilities, we do ablation studies inAppendix B.1 to analysis each part of the methods. The experiment results show that utilizing all stepsin and leads to best performances in continual learning. For IG-CL, freezing conceptsubnetworks improves AT by up to 3.1% and 4.8% in FT , and regularizing WF improves AT by up to 3.6%and 7.3% in FT . For IN2, regularizing WF improves AT by up to 6.2% and 2.5% in FT .",
  "Conclusion": "In this work, we introduced two novel interpretable continual learning frameworks: IG-CL and IN2. Themain goal of our research is to integrate interpretability into continual learning, enhancing transparency andcontrol throughout the learning process. Although our primary focus is not on performance enhancement,our findings demonstrate that IG-CL and IN2 frequently outperform existing methods. Specifically, theseframeworks improve upon previous continual learning methods by up to 1.4% in average incremental accuracy,and up to 9.1% in average incremental forgetting. Furthermore, they effectively preserve learned knowledgewithout the need for storing past data. The clear and interpretable nature of IG-CL and IN2 sets a strongfoundation for future advancements in the field of continual learning.",
  "Broader Impacts": "Our methods make black-box continual learning process become interpretable, which is beneficial to modelsperformance. However, the improvement of mitigating forgetting by controlling concepts in models mighthave some potential negative impact in terms of privacy. For example, if an adversary only has access tomodel checkpoints but not models training data, they can analyse the concept units in the model. This willgive the attacker some information about how the model was trained, and may allow them to extract someprivate information from the models without access to training data.",
  "Acknowledgement": "This work is supported in part by National Science Foundation (NSF) awards CNS-1730158, ACI-1540112,ACI1541349, OAC-1826967, OAC-2112167, CNS-2100237, CNS-2120019, the University of California Office ofthe President, and the University of California San Diegos California Institute for Telecommunications andInformation Technology/Qualcomm Institute. Thanks to CENIC for the 100Gbps networks. The authorsthank the anonymous reviewers for valuable feedback on the manuscript. T. Oikarinen and T.-W. Weng aresupported by National Science Foundation awards CCF-2107189, IIS-2313105, IIS-2430539. T.-W. Weng alsothanks the Hellman Fellowship for providing research support. Rahaf Aljundi, Francesca Babiloni, Mohamed Elhoseiny, Marcus Rohrbach, and Tinne Tuytelaars. Memoryaware synapses: Learning what (not) to forget. In Proceedings of the European conference on computervision (ECCV), 2018. Rahaf Aljundi, Eugene Belilovsky, Tinne Tuytelaars, Laurent Charlin, Massimo Caccia, Min Lin, and LucasPage-Caccia. Online continual learning with maximal interfered retrieval. Advances in neural informationprocessing systems, 2019.",
  "Nicholas Bai, Rahul A Iyer, Tuomas Oikarinen, and Tsui-Wei Weng. Describe-and-dissect: Interpretingneurons in vision networks with language models. arXiv preprint arXiv:2403.13771, 2024": "David Bau, Bolei Zhou, Aditya Khosla, Aude Oliva, and Antonio Torralba. Network dissection: Quantifyinginterpretability of deep visual representations. In Computer Vision and Pattern Recognition, 2017. David Bau, Jun-Yan Zhu, Hendrik Strobelt, Agata Lapedriza, Bolei Zhou, and Antonio Torralba. Under-standing the role of individual units in a deep neural network. Proceedings of the National Academy ofSciences, 2020. Tom Brown, Benjamin Mann, Nick Ryder, Melanie Subbiah, Jared D Kaplan, Prafulla Dhariwal, ArvindNeelakantan, Pranav Shyam, Girish Sastry, Amanda Askell, et al. Language models are few-shot learners.Advances in neural information processing systems, 2020. Pietro Buzzega, Matteo Boschini, Angelo Porrello, Davide Abati, and Simone Calderara. Dark experience forgeneral continual learning: a strong, simple baseline. Advances in neural information processing systems,2020. Lucas Caccia, Rahaf Aljundi, Nader Asadi, Tinne Tuytelaars, Joelle Pineau, and Eugene Belilovsky. Newinsights on reducing abrupt representation change in online continual learning. In International Conferenceon Learning Representations, 2022. Massimo Caccia, Pau Rodriguez, Oleksiy Ostapenko, Fabrice Normandin, Min Lin, Lucas Page-Caccia,Issam Hadj Laradji, Irina Rish, Alexandre Lacoste, David Vzquez, et al. Online fast adaptation andknowledge accumulation (osaka): a new approach to continual learning. Advances in Neural InformationProcessing Systems, 2020.",
  "Xi Chen, Christos Papadimitriou, and Binghui Peng. Memory bounds for continual learning. In 2022 IEEE63rd Annual Symposium on Foundations of Computer Science (FOCS), 2022": "Matthias De Lange, Rahaf Aljundi, Marc Masana, Sarah Parisot, Xu Jia, Ale Leonardis, Gregory Slabaugh,and Tinne Tuytelaars. A continual learning survey: Defying forgetting in classification tasks. IEEEtransactions on pattern analysis and machine intelligence, 2021. Prithviraj Dhar, Rajat Vikram Singh, Kuan-Chuan Peng, Ziyan Wu, and Rama Chellappa. Learning withoutmemorizing. In Proceedings of the IEEE/CVF conference on computer vision and pattern recognition, 2019.",
  "Kaiming He, Xiangyu Zhang, Shaoqing Ren, and Jian Sun. Deep residual learning for image recognition. InProceedings of the IEEE conference on computer vision and pattern recognition, 2016": "Evan Hernandez, Sarah Schwettmann, David Bau, Teona Bagashvili, Antonio Torralba, and Jacob An-dreas. Natural language descriptions of deep visual features. In International Conference on LearningRepresentations, 2022. Saihui Hou, Xinyu Pan, Chen Change Loy, Zilei Wang, and Dahua Lin.Learning a unified classifierincrementally via rebalancing. In Proceedings of the IEEE/CVF conference on Computer Vision andPattern Recognition, 2019. Linmei Hu, Tianchi Yang, Luhao Zhang, Wanjun Zhong, Duyu Tang, Chuan Shi, Nan Duan, and Ming Zhou.Compare to the knowledge: Graph neural fake news detection with external knowledge. In Proceedings ofthe 59th Annual Meeting of the Association for Computational Linguistics and the 11th International JointConference on Natural Language Processing (Volume 1: Long Papers), 2021. Wenpeng Hu, Zhou Lin, Bing Liu, Chongyang Tao, Zhengwei Tao Tao, Dongyan Zhao, Jinwen Ma, and RuiYan. Overcoming catastrophic forgetting for continual learning via model adaptation. In Internationalconference on learning representations, 2019.",
  "Gyuhak Kim, Changnan Xiao, Tatsuya Konishi, Zixuan Ke, and Bing Liu. A theoretical study on solvingcontinual learning. Advances in Neural Information Processing Systems, 2022": "James Kirkpatrick, Razvan Pascanu, Neil Rabinowitz, Joel Veness, Guillaume Desjardins, Andrei A Rusu,Kieran Milan, John Quan, Tiago Ramalho, Agnieszka Grabska-Barwinska, et al. Overcoming catastrophicforgetting in neural networks. Proceedings of the national academy of sciences, 2017. Hyunseo Koh, Dahyun Kim, Jung-Woo Ha, and Jonghyun Choi. Online continual learning on class incrementalblurry task configuration with anytime inference. In International Conference on Learning Representations,2022.",
  "Max Losch, Mario Fritz, and Bernt Schiele. Interpretability beyond classification output: Semantic bottlenecknetworks. arXiv preprint arXiv:1907.10882, 2019": "Emanuele Marconato, Gianpaolo Bontempo, Elisa Ficarra, Simone Calderara, Andrea Passerini, and StefanoTeso. Neuro-symbolic continual learning: Knowledge, reasoning shortcuts and concept rehearsal. InInternational Conference on Machine Learning, 2023. Seyed Iman Mirzadeh, Arslan Chaudhry, Dong Yin, Huiyi Hu, Razvan Pascanu, Dilan Gorur, and MehrdadFarajtabar. Wide neural networks forget less catastrophically. In International Conference on MachineLearning, 2022a.",
  "Anastasia Pentina and Ruth Urner. Lifelong learning with weighted majority votes. Advances in NeuralInformation Processing Systems, 2016": "Alec Radford, Jong Wook Kim, Chris Hallacy, Aditya Ramesh, Gabriel Goh, Sandhini Agarwal, Girish Sastry,Amanda Askell, Pamela Mishkin, Jack Clark, et al. Learning transferable visual models from naturallanguage supervision. In International conference on machine learning, 2021. Sylvestre-Alvise Rebuffi, Alexander Kolesnikov, Georg Sperl, and Christoph H Lampert. icarl: Incrementalclassifier and representation learning. In Proceedings of the IEEE conference on Computer Vision andPattern Recognition, 2017. Matthew Riemer, Ignacio Cases, Robert Ajemian, Miao Liu, Irina Rish, Yuhai Tu, , and Gerald Tesauro.Learning to learn without forgetting by maximizing transfer and minimizing interference. In InternationalConference on Learning Representations, 2019.",
  "David Rolnick, Arun Ahuja, Jonathan Schwarz, Timothy Lillicrap, and Gregory Wayne. Experience replayfor continual learning. Advances in Neural Information Processing Systems, 2019": "Olga Russakovsky, Jia Deng, Hao Su, Jonathan Krause, Sanjeev Satheesh, Sean Ma, Zhiheng Huang, AndrejKarpathy, Aditya Khosla, Michael Bernstein, Alexander C. Berg, and Li Fei-Fei. ImageNet Large ScaleVisual Recognition Challenge. International Journal of Computer Vision (IJCV), 2015. Andrei A Rusu, Neil C Rabinowitz, Guillaume Desjardins, Hubert Soyer, James Kirkpatrick, KorayKavukcuoglu, Razvan Pascanu, and Raia Hadsell.Progressive neural networks.arXiv preprintarXiv:1606.04671, 2016.",
  "Ju Xu and Zhanxing Zhu. Reinforced continual learning. Advances in Neural Information Processing Systems,2018": "An Yan, Yu Wang, Yiwu Zhong, Chengyu Dong, Zexue He, Yujie Lu, William Yang Wang, Jingbo Shang,and Julian McAuley. Learning concise and descriptive attributes for visual recognition. In Proceedings ofthe IEEE/CVF International Conference on Computer Vision, 2023. Shipeng Yan, Jiangwei Xie, and Xuming He. Der: Dynamically expandable representation for class incrementallearning. In Proceedings of the IEEE/CVF Conference on Computer Vision and Pattern Recognition, 2021. Sin-han Yang, Chung-Chi Chen, Hen-Hsen Huang, and Hsin-Hsi Chen. Entity-aware dual co-attentionnetwork for fake news detection. In Findings of the Association for Computational Linguistics: EACL2023, 2023a. Yue Yang, Artemis Panagopoulou, Shenghao Zhou, Daniel Jin, Chris Callison-Burch, and Mark Yatskar.Language in a bottle: Language model guided concept bottlenecks for interpretable image classification. InProceedings of the IEEE/CVF Conference on Computer Vision and Pattern Recognition, 2023b.",
  "A.1IG-CLs Concept Evolution": "and show the IG-CLs concept evolution when grouping similar classes together. The analysisis in .3. Meanwhile, we visualize the classification heads weight for IG-CL in . IG-CL canpreserve classes related concepts contribution to prediction. Compared with IN2 that analyzed in ,IG-CLs perserved concepts are more general and less task-specific since IG-CL can not control the emergenceand types of related concepts. Besides grouping similar classes into the same task, we also analyse the cases where class labels are distributedrandomly. Following the same procedure as in section 5.3, we analyse how many units are still detecting thesame concept after learning a new task. The average results for three datasets are in . Similar to, our methods outperform existing methods to retain knowledge of concepts learned from previoustasks. In general the concepts are more stable in random class distribution since different tasks might sharemore overlapped concepts. : The ratio of units that still detect the same concepts they detected in the last task. Tasks classesare in Appendix D.3. Underline means the strongest baseline, and boldface means the best number. Ourmethods outperform existing exemplar-free methods for preserving concepts, and are even better thanexemplar-based methods without replaying buffer.",
  "Exemplar-free baselinesFinetune00000000.086EWC000000.0300.0370SI00000.0280.1910.2000.250LwF0.0190.0110.17600.1140.1910.3930.365": "Exemplar-based baselinesGEM00.1250.0760.1530000MIR0000.2500.028000OursIG-CL-freeze-all (no replay)0.5000.5000.5710.7000.7390.7710.8120.812IG-CL-freeze-part (no replay)0.1250.1330.7270.6950.5150.4880.5440.666 : The ratio of units which still detect the same concepts they detected in the last task for CIFAR-10and CIFAR-100. Class labels are distributed randomly, and the results are average over three runs. Underlinemeans the strongest baseline, and boldface means the best number. Our methods outperform the existingworks for preserving learned concepts.",
  "(b) snake": ": Final weight visualization for random classes in IG-CL on CIFAR-100 under 5-tasks scenario. Forclass \"caterpillar\" from task 1, we show its significant weight (> 0.05) after training on task 1 and task 2. Forclass \"snake\" from task 3, we show its significant weight after training on task 3 and task 4. Concepts relatedto caterpillar, and preserved from task 1 to task 2 are marked in blue. Same for concepts related to snakeand preserved from task 3 to task 4. The class distribution is in . We can see IG-CL has ability topreserve related concepts appearance and contribution.",
  "A.2Discussion of Concept Evolution for IN2": "In this section, we study the evolution of the concepts represented by neurons and final layer weights as wetrain IN2 across different tasks under 5-tasks scenario. We analyse a classes final layer weights after learningits task, and after learning a new task. We visualize the final layer weights of Finetune-CBM and IN2 bySankey diagrams, only including weights with absolute value greater than predefined threshold. Negativeweights are reported as \"NOT {concept}\". The visualization for random classes in CIFAR-100 are in themain text . The visualizations for random classes in other two datasets are in 8. Comparedwith Finetune-CBM, we can see IN2 is much better at retaining and using knowledge of concepts learnedfrom previous tasks. This helps explain why IN2 performs better in FT and FT .",
  "B.1Ablation Study": "Besides comparing the results with existing methods, we perform ablation study to analyze the impact ofthe key components in our methods. In , we compare IG-CL with (i) not freezing subnetwork instep 3, which is denoted as \"IG-CL w/o freeze\", and (ii) not regularizing parameter WF in step 4, which isdenoted as \"IG-CL-freeze-all w/o reg\" or \"IG-CL-freeze-part w/o reg\". The experiment results show thatcombining two of them results in less forgetting and better average accuracy. We believe its because they arenecessary to each other. If the concept units subnetworks are not frozen, the concepts might change and theregularization term may not work. On the other hand, if the WF changes when learning new tasks, then theconcept units learned from previous tasks may not contribute to the final prediction. For IN2, we do a similar ablation study with (i) not freezing previously learned concepts when learningCBL in step 2, which is denoted as \"IN2 w/o freeze\", and (ii) not regularizing parameter WF in step 3,which is denoted as \"IN2 w/o reg\". The result shows a similar result. In conclusion, these ablationstudies demonstrate the importance of both freezing subnetworks and regularizing the WF to achievingbetter performance and mitigating forgetting. : Experiment results of IG-CLs ablation study. \"IG-CL w/o freeze\": not freezing subnetwork.\"IG-CL-freeze-all w/o reg\" and \"IG-CL-freeze-part w/o reg\": not regularizing parameter WF . means largervalues are better, while means smaller values are better. Preserving two components turns out have thebest performances.",
  "B.2Ablation on IN2 Sparsity": "In this section we experimented with some modifications to WF in our CBM and report their results. In ourmain results for IN2 and Finetune-CBM, we used a dense final layer WF instead of the sparse final layerused by (Oikarinen et al., 2023) as we found that to have best performance, and we are less focused oninterpretable final decisions. Below we compare the results for CBM between dense WF , and sparse WF (-S).For the sparse WF , we used = 106 in Eq. 3. The experiment results are in . We found that denseWF had the best performance in most cases.",
  "In and 11, we report AT and FT for CIFAR-100 and TinyImageNet, and also experiment results forCIFAR-10 in 4 metrics": ": Accuracy comparison for IG-CL. means larger values are better, while means smaller valuesare better. Underline means the strongest baseline, and boldface means the best number. In the OursImprovement rows, +/- measures our best number minus the strongest baseline, and the value is in blue ifour improvement is statistically significant.",
  "AT FT AT FT AT FT AT FT": "Exemplar-free baselinesFinetune29.13 0.2897.78 0.7817.99 2.2679.66 0.7217.65 2.5564.94 2.1515.34 3.8354.81 0.71EWC30.79 0.2197.92 0.7819.00 1.8776.92 0.7717.44 3.9864.43 1.8415.07 2.2354.77 0.54SI30.25 0.7296.55 1.7019.31 0.6274.78 1.5517.12 3.8963.11 1.0314.47 1.0253.69 1.32 LwF30.76 0.3197.75 0.8419.11 0.4476.56 1.1219.98 0.6463.79 2.6517.08 1.5055.40 1.85Adam-NSCL30.78 0.8296.82 2.3521.60 0.4877.73 0.8616.23 3.3966.26 3.1813.44 1.7058.86 0.70OursFinetune-CBM30.39 0.6793.09 2.2221.14 0.8369.47 1.2916.43 2.8255.76 3.5514.91 0.6551.39 3.78IN232.25 0.7688.58 0.3022.16 1.7367.92 0.7216.37 3.8245.71 2.5515.68 1.8439.40 2.86",
  "Ours Improvement+1.78-1.24+6.70+5.71+4.82-0.73+1.560.00": ": Accuracy comparison for IN2. All models are pre-trained on the Place365 dataset (Zhou et al.,2017). means larger values are better, while means smaller values are better. Underline means thestrongest baseline, and boldface means the best number. In the Ours Improvement rows, +/- measuresour best number minus the strongest baseline, and the value is in blue if our improvement is statisticallysignificant.",
  "B.410, 20 tasks Experiment Results": "reports comparison for IG-CL under 10-tasks scenario for CIFAR-100 and TinyImagenet. Comparedwith exemplar-free baselines, IG-CL generally forgets less as FT and FT shown. However, IG-CL sometimesis worse in AT and AT , which is the limitation of our methods. We view this as the future works to beimproved, since this papers goal is to retain intepretable concepts in models. Nevertheless, IG-CL generallyimproves exemplar-based baselines when combined with them, which is same as 5-tasks scenario. reports comparison for IN2 under 10-tasks scenario for CIFAR-100 and TinyImagenet. Similarto IG-CL, IN2 performs well in forgetting metrics FT and FT , but performs worse in AT and AT whencomparing with exemplar-free baselines. We believes this is partially because LF-CBMs training procedureis different than standard end-to-end training. As LF-CBM Oikarinen et al. (2023) paper shown, LF-CBMsclassification accuracy is usually worse than standard models. Again, we view this as future works to beimproved. Besides, IN2 still can improve exemplar-based baselines when combine with them. and 15 report comparison for IG-CL and IN2 under 20-tasks scenario in CIFAR-100 respectively.Similar to 10-tasks scenario, our methods can improve exemplar-based baselines when combine with them,while the comparison with exemplar-free methods is still under the same trend. We observe that both of our proposed methods can improve exemplar-based methods when combined withthem. When compared with exemplar-free methods, our methods forget less while slightly worse than thestrongest baselines in terms of AT . Nonetheless, we would like to highlight that our work is the first to bridgecontinual learning and neuron interpretability with competitive results, which opens up a new and promisingdirection to transform continual learning from a black-box process to more transparent. : Accuracy comparison for IG-CL in 10 tasks scenario. means larger values are better, while means smaller values are better. Underline means the strongest baseline, and boldface means the bestnumber. In the Ours Improvement rows, +/- measures our best number minus the strongest baseline, andthe value is in blue if our improvement is statistically significant.",
  "Ours Improvement+5.14+12.25+2.46+2.83+3.76-2.15+4.67-1.85": ": Accuracy comparison for IG-CL in 20 tasksscenario. means larger values are better, while means smaller values are better. Underline means thestrongest baseline, and boldface means the best num-ber. In the Ours Improvement rows, +/- measuresour best number minus the strongest baseline, andthe value is in blue if our improvement is statisticallysignificant.",
  "Ours Improvement+1.71+5.95+0.53+15.97": ": Accuracy comparison for IN2 in 20 tasksscenario. All models are pre-trained on the Place365dataset (Zhou et al., 2017). means larger valuesare better, while means smaller values are better.Underline means the strongest baseline, and bold-face means the best number. In the Ours Improve-ment rows, +/- measures our best number minusthe strongest baseline, and the value is in blue if ourimprovement is statistically significant.",
  "B.5.1Comparison with SSRE": "We compare our methods with SSRE (Zhu et al., 2022). Since we can not access the pre-training detailsdescribed in SSRE paper, we compare our IG-CL with SSRE that is trained from scratch. Besides metricsdescribed in .1, we also measure Learning Accuracy (FT = 1 TTi=1 ai,i) (Mirzadeh et al., 2022b;Riemer et al., 2019; Yin et al., 2021; Mirzadeh et al., 2022a) to understand models ability to learn new tasks.Experiment results are in . IG-CL forgets more as the performace in FT is worse. However, it hasmuch better learning ability as LT shown. : Comparison between IG-CL and SSRE Zhu et al. (2022) in CIFAR-10 and CIFAR-100. meanslarger values are better, while means smaller values are better. Even though IG-CL forgets more, it hasbetter learning ability.",
  "B.5.2Comparison with DEN": "We compare our methods with DEN (Yoon et al., 2018) in the CIFAR-10 and CIFAR-100 dataset. We combinea pretrained model with a 2-layer DEN, and compare it with Finetune-CBM and IN2. The experiment resultsare in . IN2 and Finetune-CBM outperform DEN by up to 20.01% and 18.15% in AT respectively.",
  "B.6Forward Transfer Metric": "We use Forward Transfer Metric (FWT) Lopez-Paz & Ranzato (2017) to measure our methods ability to reuseold knowledge on new tasks. We did experiments on CUB200, 5 tasks scenario since CUB200 shares severalconcepts among classes. and 20 show that our methods have better abilities to share knowledgefrom old tasks to new tasks compared with baselines.",
  "B.7Experiment results on ImageNet-10": "We conduct experiments on large scale dataset ImageNet-10, and the results are in and 22. Theexperiment results are still under the same trend as other datasets: Our methods outperform other exemplar-free methods by up to 0.87% in AT and up to 5.77% in FT . Meanwhile, can improve exemplar-based methodsby combining them by up to 1.83% in AT and up to 2.87% in FT",
  "B.8Impact from the order of tasks": "To understand the impact from the order of tasks, we conducted experiments on CIFAR-100 using the classdistribution outlined in , where similar classes are grouped into the same task. We then swapped theorder of task 1 and task 2 and compared the results with the original task order. The continual learningperformance for IG-CL is in , and IN2 is in . In both task orders, our methods consistentlypreserve learned knowledge effectively. IG-CL and IN2 outperform other exemplar-free methods by up to0.14% in AT and up to 26.39% in FT . Additionally, they improve upon exemplar-based methods by up to1.45% in AT and up to 11% in FT . These results demonstrate that our methods are robust to changes intask order. Meanwhile, it shows that our methods dont have constant performances in AT when changingclass distribution and task order, yet it boosts interpretability a lot. We also analyze the concept evolution of two methods like .3. For IG-CL, the concept evolutionanalysis is in . Same as the original order that analyzed in , IG-CL can preserve concepts evenafter learning a unrelated task. For IN2, the analysis is in . Same as the original order that analyzedin , IN2 can preserve concepts while finetune CBM loss all of the significant weights. Overall, theconcept evolution analysis show that our methods can preserved learned concepts regardless of the task order. : Continual learning performance on CIFAR-100 5-task scenario.Original order is the classdistribution in , and Swap order exchanges the task 1 and task 2 of it. IG-CL has better FT andsimilar or better AT .",
  "C.1Computational efficiency": "shows the maximum GPU usage of Finetune, EWC, GEM and our methods on CIFAR-10 under5-tasks scenario. Even integrated with the interpretable tool CLIP-Dissect (Oikarinen & Weng, 2023), IG-CLsmaximum GPU usage is still lower than EWC and GEM. Meanwhile, IN2s memory usage is efficient eventhough the CBL layer increases when learning new tasks. The experiment results show our methods areefficient. : Maximum GPU usage comparison for our methods, under CIFAR-10 5-tasks scenario. IG-CLsmaximum GPU usage is smaller than EWC and GEM, which shows IG-CLs computational efficiency. IN2 ismore efficient than existing methods.",
  ": The subnetwork sizes in the last residual block after learning two tasks in the 5-task scenario. Amore complicated dataset will have bigger subnetworks": "For IN2, and 30 show the number of concepts added per tasks. Overall, larger and more complicateddatasets have more concepts. Around 10% of concepts are the same during the concept set expansion 4.2. shows some example concepts that are related to different classes. shows some complexconcepts in IN2 from different datasets.",
  ": Some complex concepts that generated from the different datasets in IN2": "We build IN2 based on LF-CBM Oikarinen et al. (2023). Therefore, we would like to discuss two propertiesrelated to LF-CBM. First, following LF-CBMs procedure, we use CLIP to calculate the activation matrix Pas described in .2. We can replace CLIP with other vision language aligned (VL-aligned) modelsas long as they have a text encoder and an image encoder to calculate matrix P. One future work will bereplacing CLIP with other suitable VL-aligned models.",
  "D.1.1Training and computing details": "All models are trained on single NVIDIA V100s (32 GB SMX2). The hyperparameters used for our methodsare in . We tune the hyperparameters for best performance in AT . The hyperparameters tuningresults are in , 33, 34 and 35. The hyperparameter selection of in Eq. (3) is discussed in AppendixB.2. The tuning process ensures that our methods are fairly compared to other baselines by optimizing theirperformance under the same conditions. When combine IG-CL or IN2 with GEM (Lopez-Paz & Ranzato,2017) or MIR (Aljundi et al., 2019), we use the memory buffer size: 150 samples per task. Meanwhile, weexperiment GEM and MIR with the same memory buffer size for fair comparisons. We split each dataset by3 different random seeds, and run each class distribution for 3 times. The code and full training details willbe released to public upon acceptance.",
  "D.2.1Previous Continual Learning Methods": "The representative method in regularization-based methods category (i) is Elastic Weight Consolidation(Kirkpatrick et al., 2017). Elastic Weight Consolidation (EWC) is a regularized-based method. Theloss function in this strategy L(t) = LCE(t) + i F ti (ti t1i)2 has a quadratic penalty term which isrelated to the difference between the parameters of the old task and the new task. Meanwhile, this penaltyterm is proportional to the diagonal of the Fisher information matrix F. is a hyperparameter, and t, t1 stand for model parameters before and after training on a new task t respectively. Similarly, Zenke et al.(2017) adds a quadratic penalty term in the loss function, while estimating the importance of parametersduring training. Li & Hoiem (2017) trains models with a knowledge distillation loss for old tasks and aregularization loss to outperform joint training. The classic method in architecture-based methods category (ii) is Adam-NSCL (Wang et al., 2021). Foreach task, it learns model parameters in the null space of all previous tasks, which is based on Adam. Theapproximate null space is obtained by using singular value decomposition to the uncentered covariance matrixof input representations of all previous tasks. Yoon et al. (2018) expands and prunes the neural networksarchitecture when learning new tasks.",
  "D.2.2Detailed introduction to interpretability tools and models": "CLIP-Dissect (Oikarinen & Weng, 2023) use the Contrastive Language-Image Pre-training (CLIP) model(Radford et al., 2021) to decipher the neurons in target model. CLIP is composed of an image encoder EIand a text encoder ET . Given a probing dataset Dprobe = {xi}Ni=1, xi Rd, and a set of concepts {c}Mj=1,the first step is to generate the representation by the encoders. The results are Ii = EI(xi), Ii RI0 andCj = ET (cj), Cj RT0. Next, they compute concept-activation matrix P RNM where Pi,j = Ii Cj R.Third, neuron ks activation map is defined as Ak(xi) for input image xi. The mean of activation map isdescribed as g(Ak(xi)) R and the activation vector is qk = [g(Ak(x1)), ..., g(Ak(xN))]T RN. Finally, theconcept label of neuron k is cn where n is calculated from the Eq. (4)",
  "where sim is similarity function": "Label-Free Concept Bottleneck Model (LF-CBM) (Oikarinen et al., 2023) transforms neural networks intoan interpretable CBM without labeled concept data. The procedure in LF-CBM is as follows: First, it usesGPT-3 (Brown et al., 2020) to generate a set C of text concepts important for the task based on class labels,which is then filtered to improve quality. Second, LF-CBM learns a CBL where each neuron correspondsto one of these concepts, by aligning the neurons with CLIPs(Radford et al., 2021) representation of theconcepts. Given M concepts generated from the previous step, the CBL is a linear transformation of thepretrained NN backbone f(x), expressed as Wc d0 |C|. Here d0 is the output dimension of f(x). Wc islearned to maximize the similarity between CBLs output fc(x) = Wcf(x) and CLIPs activation matrix P.This incentivizes the k-th neuron to have an activation pattern similar to CLIP with the k-th concept. Wedenote k-th neurons, activation pattern as qk = [fc,k(x1), ..., fc,k(xN)]. Wc is then optimized by minimizing",
  "Task 1": "Persian cat, clIff, plunger, German shepherd, teddy, American lobster, hourglass, seashore,dumbbell, ice cream, nail, convertible, orangutan, coral reef, go-kart, king penguin,sulphur butterfly, lesser panda, kimono, comic book, cockroach, projectile, lakeside, chimpanzee,bannister, bucket, gondola, koala, lIfeboat, teapot, police van, pill bottle,hog, crane, cash machine, mushroom, water tower, black stork, ice lolly, scorpion",
  "Task 2": "reel, volleyball, rocking chair, basketball, plunger, parking meter, dining table, umbrella,oboe, hourglass, computer keyboard, space heater, backpack, pop bottle, beer bottle, remote control,lampshade, torch, abacus, barrel, CD player, teapot, candle, desk,frying pan, iPod, wok, potters wheel, pill bottle, snorkel, sunglasses, water jug,broom, wooden spoon, rugby ball, sewing machine, stopwatch, plate, teddy, drumstick",
  "Task 3": "Egyptian cat, bullfrog, German shepherd, brown bear, guinea pig, Arabian camel, baboon, Labrador retriever,king penguin, lesser panda, chimpanzee, tabby, goose, koala, gazelle, golden retriever,hog, cougar, black stork, ox, Persian cat, Yorkshire terrier, bighorn, orangutan,American alligator, bison, boa constrictor, Chihuahua, lion, standard poodle, African elephant, cliff,seashore, lakeside, alp, dam, steel arch bridge, fountain, clIff dwelling, magnetic compass",
  "Task 5": "cardigan, sock, fur coat, academic gown, miniskirt, neck brace, sombrero, gasmask,punching bag, sandal, Christmas stocking, apron, swimming trunks, bikini, bow tie, military uniform,kimono, poncho, espresso, pizza, organ, potpie, ice cream, nail,pretzel, beacon, butcher shop, vestment, chest, dugong, ice lolly, confectionery,brass, comic book, meat loaf, dumbbell, syringe, chain, walking stick, beaker",
  "Task 4": "monarch, snail, albatross, spider web, sulphur butterfly, tarantula, cockroach, mantis,European fire salamander, ladybug, bee, slug, dragonfly, fly, scorpion, black widow,centipede, grasshopper, tailed frog, goldfish, coral reef, sea cucumber, spiny lobster, jellyfish,American lobster, brain coral, sea slug, trilobite, lemon, banana, guacamole, mushroom,thatch, orange, mashed potato, pomegranate, bell pepper, acorn, cauliflower, binoculars"
}