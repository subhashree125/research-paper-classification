{
  "Abstract": "Defining and measuring decision-making styles, also known as playstyles, is crucial in gam-ing, where these styles reflect a broad spectrum of individuality and diversity. However,finding a universally applicable measure for these styles poses a challenge.Building onPlaystyle Distance, the first unsupervised metric to measure playstyle similarity based ongame screens and raw actions by identifying comparable states with discrete representationsfor computing policy distance, we introduce three enhancements to increase accuracy: mul-tiscale analysis with varied state granularity, a perceptual kernel rooted in psychology, andthe utilization of the intersection-over-union method for efficient evaluation. These innova-tions not only advance measurement precision but also offer insights into human cognitionof similarity. Across two racing games and seven Atari games, our techniques significantlyimprove the precision of zero-shot playstyle classification, achieving an accuracy exceeding90% with fewer than 512 observation-action pairsless than half an episode of these games.Furthermore, our experiments with 2048 and Go demonstrate the potential of discreteplaystyle measures in puzzle and board games. We also develop an algorithm for assessingdecision-making diversity using these measures. Our findings improve the measurement ofend-to-end game analysis and the evolution of artificial intelligence for diverse playstyles.",
  "Introduction": "The pursuit of diversity in decision-making is one of the intrinsic motivations that drive human behavior,resulting in individuality and creativity (Rheinberg, 2020). This is evident in the context of games, wheredecision-making manifests as various playstyles, each reflecting unique strategies and characteristics (Bean& Groth-Marnat, 2016; Yannakakis et al., 2013). Alongside the pursuit of diversity, another central as-pect of decision-making focuses on achieving optimal performance. Significant advances in decision-makingperformance have been witnessed, especially with the development of Deep Reinforcement Learning (DRL)(Russell & Norvig, 2020). The effectiveness of DRL was first showcased in arcade video games (Mnih et al.,2015). Subsequent applications to board games emphasized its potential, achieving superhuman skills (Silveret al., 2018). This success expanded into various types of games, from Agent57s superhuman performancein Atari games to groundbreaking feats in Dota 2 and StarCraft II (Badia et al., 2020; Berner et al., 2019;",
  "Vinyals et al., 2019). Beyond gaming, DRL applications extend to robot control (Andrychowicz et al., 2020)and natural language processing (Ouyang et al., 2022), among others": "Yet, while DRL continues to show promise in diverse applications, understanding and analyzing playstyleswith minimal domain-specific knowledge remains a complex endeavor. Data from diverse sources are essentialto improve agent strength and efficiency (Fan & Xiao, 2022; Fan et al., 2023), just as acquiring skills fromdifferent styles is vital for agents to generalize across tasks (Eysenbach et al., 2019). Although a robustplaystyle measure fosters a spectrum of playing strategies, it also reveals the inherent challenges in measuringthese styles, particularly in environments without built-in features for style measurement. Consequently,achieving precise playstyle measurement remains a formidable task (Tychsen & Canossa, 2008). There are several methods to evaluate playstyles or perform player modeling (Yannakakis et al., 2013), fromheuristic rules design to in-game feature exploration (Tychsen & Canossa, 2008; Bontchev & Georgieva, 2018;Mader & Tassin, 2022). Supervised learning facilitates the discrimination of playstyles (Brombacher et al.,2017), while unsupervised clustering offers behavioral insights (Drachen et al., 2009; 2013; Ferguson et al.,2020).Another avenue involves contrastive learning to identify playstyles and behaviors among players(McIlroy-Young et al., 2021; Agarwal et al., 2021). Through these methods, the notion of playstyle canbe gauged using distance or similarity measures across game datasets, addressing dynamic and evolvingchallenges in different scenarios. The concept is reflected in the work by Lupu et al. (2021), which specifiespolicy diversity using the divergence of action distributions but requires parametrized policies. The recent innovation by Lin et al. (2021) introduces the Playstyle Distance measure, which stands out bydirectly measuring playstyle from game screens and raw action pairs. Unlike common methods that comparelatent features or rely on parametrized policies, this approach measures action distribution distances directlyfrom raw gameplay samples, reducing the reliance on game features, predefined style labels or even extensivetraining sets for learning latent features or policies.Its effectiveness hinges on the critical role of statediscretization. By discretizing observations like game screens, we can identify similar and comparable states,allowing for a direct comparison of action distributions of each state, thereby defining the decision-makingstyle based on the expected distance of policies. While the Playstyle Distance offers an advance in end-to-end and unsupervised playstyle measurement, ourresearch endeavors to elevate this foundation. We introduce techniques to improve playstyle measurement,harnessing the advantage of discrete states. Initially, we leverage multiscale analysis with varied state granu-larity, emulating human judgment of similarity from multiple attributes and viewpoints (Medin et al., 1993).We then derive a perceptual kernel from psychophysics (Fechner, 1966) in psychology to obtain a probabilis-tic similarity value, which is more in harmony with human comprehension than distance values. Moreover,incorporating the concept of the Jaccard index (Murphy, 1996), we broaden the focus of measurement beyondintersection samples, harnessing all observed game data to improve measurement accuracy. These techniquesnot only improve the precision of Playstyle Distance but also provide a new aspect to understand similaritythrough the lens of human cognition. From their fusion emerges the Playstyle Similarity measure. To underscore our contributions, we propose three improvements for playstyle measurement. With these im-provements, we alleviate the trade-off between using small or large discrete state spaces in discrete playstylemeasures and provide a more explainable similarity with probability. Additionally, we achieve over 90%accuracy in zero-shot playstyle classification tasks with fewer than 512 observation-action pairs, which is lessthan half an episode in the examined games, including two racing games and seven Atari games. Further-more, our experiments with 2048 and Go demonstrate the potential of discrete playstyle measures in puzzleand board games. Additionally, we introduce an algorithm to measure the diversity of decision-making,which showcases the applicability of our measures for tasks that are challenging to quantitatively evaluatewithout built-in features. This algorithm is based on the simple idea of comparing the similarity of a newtrajectory to previous trajectories using a unified probabilistic similarity threshold. These explorations en-hance our understanding of end-to-end game analysis and AI training, and also harmoniously merge playstylemeasurement with human cognition.",
  "Playstyle and Measurement": "Establishing a universally accepted playstyle measure is a formidable challenge, as perceptions of playstyleare influenced by myriad factors and often harbor subjective nuances. Consequently, any playstyle mea-sure should specify its evaluative parameters transparently to ensure that its measurements are persuasive.Historically, tailored metrics, characterized by heuristic rules or specific in-game features, often presentedthe most precision for dedicated case studies. For example, the study by Lample & Chaplot (2017) usedmeasures such as object counts, kills, and deaths in shooting games. However, due to their inherent manualnature, these measures are often domain-specific and limited to specific behaviors. For video games, methods in player modeling can help us find interesting player behaviors and personality(Yannakakis et al., 2013; Costa Jr & McCrae, 1995). A key problem in these behavior analyses is how todefine effective input features and the corresponding target outputs. Even if we can detect and taxonomizesome behaviors, a real playstyle can be a complex combination of several behaviors. For example, the Bartletaxonomy in game character theory, where players can be separated into four types: achievers, explorers,socializers, and killers (Bartle, 1996), is a high-level concept of playstyles and the detailed behaviors ofthese taxonomies can be different in different genres of games. The true playstyle can be represented asthe characteristic of playing behavior sets to fuse into a holistic intention of players (Lin et al., 2021); thus,processing all possible information from raw gameplay should be included in playstyle measurements. To achieve such wider applicability, some researchers have resorted to supervised learning to identify styles(Brombacher et al., 2017). However, this method requires labeled training data and may encounter difficultiesin detecting styles not present in the training set. Unsupervised clustering offers a different angle, emphasizinglatent feature distances for classification (Drachen et al., 2009; 2013; Ferguson et al., 2020). But this approachmay obscure the semantic meaning of the measures, particularly when image data is the primary source thatis common in video games. A notable approach is the Behavioral Stylometry proposed by McIlroy-Younget al. (2021) using the idea of contrastive learning. This measure, designed for chess, encodes chess movesinto a game vector, aggregates these vectors to represent a style, and then compares this representationagainst a reference set. Central to this method is the contrastive learning technique Generalized End-to-End(Wan et al., 2018) used to learn latent features to identify the most similar player in the given datasets. For a more generalized measurement of playstyle, one could consider measuring the similarity of policies.Methods that extend to specify similarity or diversity by comparing the action distribution of two policieshave also been explored (Agarwal et al., 2021; Lupu et al., 2021). Notably, these methods often require aparametrized policy for comparisons. This limitation is addressed by the Playstyle Distance measure (Linet al., 2021). Instead of emphasizing latent features or parametrized policies, Playstyle Distance focuses onthe action distributions of given samples. Raw observations, such as game screens, are discretized and thenused for determining which action samples are comparable. Such a method resonates more with humaninstinct, echoing the case-by-case assessment we often deploy.",
  "Framework of Playstyle Distance": "To delve deeper into the generality and importance of the Playstyle Distance in playstyle measurement,we examine its foundation as follows. A pivotal component of its methodology is the use of the VectorQuantized-Variational AutoEncoder (VQ-VAE), which specializes in discrete representations by mappingcontinuous encodings to the nearest vectors in a predefined codebook (van den Oord et al., 2017). Buildingupon VQ-VAE, the Hierarchical State Discretization (HSD) in Playstyle Distance ensures a concise andhierarchical state space. This is essential for identifying overlapping discrete states while preserving thefeature integrity of observation reconstruction and gameplay details.",
  ": Illustration of the Playstyle Distance computation using a hierarchical discrete state encoder .The Venn diagram highlights the intersection of discrete states for distance calculation": "Central to this framework is the discrete state encoder, denoted as . Observations o and their associatedactions a are mapped to datasets Mi Stylei. The encoder translates these observations into a compactstate representation s, formulated as:S : (o) s In the initial Playstyle Distance approach, the hierarchical encoder has the capability to generate multiscalediscrete states. However, the foundational literature employs only a singular state space for computations;the hierarchical structure is used to control the state space and maintain the quality of discrete representationlearning. Using a state space that is too large or too small a state space may lead to unstable measurements.",
  "{a|(o, a) M, (o) s} M(s)": "Here, represents the policy, depicting action distributions for a given state. Subsequently, the distancesbetween these distributions are determined using the metric D(X, Y ), where the 2-Wasserstein distance(W2) serves as the standard (Vaserstein, 1969).Recognized for measuring the effort to transform onedistribution into another, the Wasserstein distance is apt for policy comparisons, analogous to quantifyingthe effort to transition between playstyles.",
  "Discrete Playstyle Measures": "In this section, we delve into a series of discrete playstyle measures derived from Playstyle Distance. We firstdiscuss the limitations of Playstyle Distance. We then expand it into a multiscale approach by leveragingthe hierarchical structure of states. Subsequently, we explore converting the action distribution distance intoa perceptual similarity rooted in cognitive psychology, utilizing a perceptual kernel function. Thirdly, webroaden our scope from merely intersection states to the union of states, aiming for a more efficient estimationof all observed data. Concluding the section, we integrate these improvements into a comprehensive measurewe term as Playstyle Similarity.",
  "(b) From Playstyle Distance to Playstyle Similarity": ": (a) Degree of Similarity: This demonstrates how multiple candidate points C can share identicaldistance values from a target point T, emphasizing that as distance increases, the degree of similarityinformation diminishes. (b) From Playstyle Distance to Playstyle Similarity: This transformation begins byprocessing an observation sample into multiple discrete states of varying granularity. A perceptual kernel thentransforms these distance values into probabilistic similarities, using the concept of overlapping regions forintuitive understanding. Lastly, the application of the intersection-over-union method refines the similaritybased on the Jaccard index, enhancing measurement comprehensiveness across all observed data.",
  "Effect of Multiscale States": "Playstyle Distance hinges on discrete states for performing style measurements. Consequently, it resorts to aconstrained state space sourced from the HSD model. A sample count threshold is applied to the intersectionstate to ensure the quality of action distribution, necessitating at least t samples in both datasets undercomparison; failing which, the state is excluded from the intersection. This filtering sometimes discardsimportant information and the trade-off between using small or large state spaces also poses a dilemma forsingular state space; thus, we propose using multiscale analysis to alleviate these problems. Human cognition perceives similarity as a convergence of multiple attributes leading to a holistic understand-ing (Goldstone & Barsalou, 1998). Hence, we advocate for employing varied granularity of discrete states toaugment measurement capabilities, analogous to human judgment that varies from a broad view to intricatedetails. The HSD models design inherently possesses a large state space for observational reconstruction andthe discernment of gameplay nuances (Lin et al., 2021). Though the state space may be large, intersectionsare not void if observations are sufficiently similar or come from identical gameplay. It is worth noting thatLin et al. (2021) were able to identify intersection states even with unprocessed screen pixels in Atari games.In a different scenario, when treating each state as the same, we can invariably find the single intersectionstate. In this context, distance simply gauges the action distribution over the entirety of the game, akin totraditional methods deploying post-game action statistics. Broadly speaking, we can enhance the original state encoder function, , evolving it into a state encodermapping, , wherein is an assemblage of mapping functions, , S : (o) {(o) S| }.Consequently, the projected state of dataset M is defined as: (M) {(o) S|o M, }. We canthen reinterpret Equation 1 as:",
  "Published in Transactions on Machine Learning Research (08/2024)": ": Accuracy of Go 200 player identification with M games as the query set and also M games as thecandidate set. The full comparison with different numbers of query and candidate sets is listed in Section A.7.The discrete encoder is trained from a variant of HSD (Lin et al., 2021), and the available state spaces inthis encoder are {48, 168, 256361}. The measures with \"mix\" notation imply using all three available statespaces simultaneously with our multiscale modification.",
  "Perception of Similarity": "One potential shortcoming of the Playstyle Distance stems from the nature of distance itself. While distanceis a common measure for determining similarity, a larger distance value conveys primarily that two entitiesare different, without giving much insight into the degree of their similarity. For example, given a point in2D space, the candidate points with the same distance to the given point form a circle. As the distanceincreases, the size of this candidate circle also increases, and the similarity information is diluted as illustratedin a.This phenomenon has been observed in human decision-making as the Magnitude Effect,suggesting diminished sensitivity to larger numbers (Kahneman & Tversky, 1979). This aligns with theWeberFechner Law in psychophysics, where the relationship between stimulus and perception is logarithmic;as the magnitude of stimuli increases, sensitivity diminishes (Fechner, 1966). Drawing from the concept ofsimilarity, we can infer that a smaller distance provides more definitive information about similarity. Asdistance grows, the distinction becomes vaguer.Therefore, we argue for a measure that reflects highersensitivity to smaller distances, emulating human perceptual behaviors. We propose a probability-based model for similarity. In this model, greater similarity (i.e., smaller distance)corresponds to a probability closer to 100%, while lesser similarity (larger distance) approaches 0%. Thisproposed probability function aligns with the logarithmic human perceptual sensitivity to differences. Specif-ically, we use the exponential kernel to describe the probability of similarity, with the mapping function givenby P(d) =1ed , where d is the distance value from the policy distance function D(X, Y ) with 2-Wassersteindistance. This perceptual relation is the only relation under our assumptions from human cognition andprobability. We provide a proof using differential equations in Appendix A.1. This exponential transformation can also be found in the radial basis function (Vert et al., 2004) andBhattacharyya coefficient (Bhattacharyya, 1946). The Bhattacharyya coefficient BC(P, Q) measures thesimilarity between two probability distributions P and Q, and it is related to the overlapping region betweenthese two distributions. It is defined as BC(P, Q) =",
  "DM(3)": "The measure has been simplified by adopting a uniform average distance instead of an expected value. Thisnot only streamlines calculations but also underscores the significance of encoder granularity. In particular,an intricate encoder with a vast state space may be accorded greater weight, especially if the intricateencoder reveals more intersection states. To match our probabilistic framework (Appendix A.1) we rescalethe distances with a constant, DM , ensuring the expected distance converges to 1. The constant DM canbe calculated by averaging all observed distance on each discrete state in comparisons. Collectively, ourrevamped measure provides a probabilistic lens to interpret similarity, firmly rooted in cognitive theoryand tailored for human comprehension. There is more discussion about the role of the distance metric inAppendix A.2.1, including the implications of adopting the Bhattacharyya distance metric.",
  "Beyond Intersection": "Before presenting our final measure, it is pertinent to revisit the foundational concept of the PlaystyleDistance: the intersection of states.Identifying comparable states before measuring policy similaritiesencounters challenges when the intersecting samples are limited.A smaller intersection proportion canresult in unstable or insufficient samples for measuring playstyles. Such a small intersection could indicatetwo scenarios.First, distinct state-visiting distributions might signify different playstyles.In contrast,uncontrollable factors external to playstyles, such as environmental randomness or decisions from otherplayers, may also play a role, indicating the necessity for more extensive sampling. A prudent approach would assess the proportion of intersecting samples relative to the total observed samples.In the realm of collection comparison, the Jaccard index (Murphy, 1996), also known as Intersection overUnion, emerges as a prevalent similarity measure. The Jaccard index can serve as an effective playstylemeasure under specific conditions. It is particularly apt when game observations clearly delineate playstyledistinctions. For instance, in deterministic environments where states can be distinctly segmented by differentactions, the Jaccard index appears to be a fitting measure. However, complications arise when certain statesrecur due to game rules or every state is visited. The task of distinguishing different playstyles based solely onobservations becomes considerably challenging. This is evident in single-state games, such as K-arm bandits(Sutton & Barto, 2018), where measuring playstyles only from states becomes an impractical endeavor. Despite potential challenges, our empirical findings suggest that the Jaccard index serves as a handy measure,when the state space is large and the randomness in the game is low. The incorporation of the Jaccard indexinto a playstyle measure with a multiscale state space is expressed in Equation 4:",
  "(5)": "What makes this measure novel is its unique treatment of intersection states.While the Jaccard indexassigns a uniform weight (of 1) to each intersecting state regardless of the similarity between the actiondistributions, our approach infuses a more nuanced probability-based weighting. The values range between0 and 1, increasing proportionally with similarity. This modification alleviates the potential limitation ofusing the Jaccard index for playstyle measurements. Furthermore, our approach ensures a consistent interpretation of zero values. For states not part of theintersection, where the distance between action distributions is maximal (approaching infinity), they can beunderstood as totally dissimilar. Playstyle Distance cannot directly incorporate with the Jaccard index dueto its nature as a negative similarity measure. The overview of the transformation from Playstyle Distanceto Playstyle Similarity is illustrated in b.",
  "Our study encompasses three distinct game platforms, as depicted in Figures 3a, 3b, and 3c:": "1. TORCS: This racing game features stable, controlled rule-based AI players (Yoshida et al., 2017).The datasets derived from TORCS include a total of 25 playstyles based on 5 different target drivingspeeds and 5 different action noise levels. Each observation consists of a sequence of 4 consecutiveRGB images with a size of 64 64. The action space is 2-dimensional and continuous. 2. RGSK - Racing Game Starter Kit: This racing game, available on the Unity Asset Store(Juliani et al., 2020), showcases human players.From RGSK, we have data from a total of 24players, exhibiting individual playstyles. Human players are told to follow one specific style factorin 4 different style dimensions, including using nitro acceleration or not, driving on road surface orthe grass surface, keeping the car in the inner or outer of the track, and passing a corner via driftingor slowing down with a brake. Each style dimension includes 6 players. Each observation from thisgame comprises 4 consecutive RGB images of size 72 128, with 27 discrete actions. 3. Atari games with DRL agents: The dataset spans 7 different Atari games (Bellemare et al., 2013)from this platform. Each game includes 20 AI models, all of which demonstrate varied playstyles.These AI models originate from the DRL framework, Dopamine (Castro et al., 2018). Each obser-vation involves 4 consecutive grayscale images of resolution 8484. The action space is discrete andvaries depending on the game. It is crucial to clarify that our research did not involve the training of new encoder models. Instead, weleveraged three pretrained encoder models and corresponding datasets for each game, provided by Lin et al.(2021). The associated resources are available in their official release.1 The game details are listed in .",
  "Playstyle Classification and State Space Levels": "Our playstyle classification adheres to the zero-shot methodology. As depicted in d, we start witha query dataset N, sampled from a playstyle Stylen. We then compare this to multiple reference datasetsM, each sampled from different playstyles Style. We perform 100 rounds of random subsampling for eachplaystyle; our primary performance metric for this task is the accuracy of playstyle classification. If datasetN exhibits the highest similarity to a reference dataset Mi, it suggests that Stylen = Stylei. The reportedaccuracy represents an average, derived from results obtained using the three discrete encoder models.",
  "Results in Video Games": "In this section, we assess the efficacy of our methods on two racing games and seven Atari games. Initially,we demonstrate how a multiscale state space can aid in the selection of proper state spaces and poten-tially enhance the accuracy of Playstyle Distance. Subsequently, we compare several baselines, illustratingthat probabilistic values for measuring similarity offer a viable alternative to distance values.Next, weincorporate all observed data to evaluate measures across all platforms. Furthermore, we discuss the contin-uous playstyle spectrum, demonstrating the consistency of measure values under slightly different behaviors.Lastly, we compare potential unsupervised measures beyond discrete playstyle measures, using observationlatent features common in generative styles. Overall, our intention in this section is to determine whethernew measures can enhance playstyle measurement in video games.",
  "Multiscale State Space Efficacy": "We evaluate the proposed multiscale state space and compare it with the singular state space used byPlaystyle Distance in . We record the mean accuracy and corresponding standard deviation over 100rounds of random subsampling for each discrete encoder. Each dataset sampled from the given playstylescomprises 1024 observation-action pairs. For example, in TORCS, there are 25 playstyles; we poll on 25query sets, and each dataset has 1024 observation-action pairs sampled from its playstyle. We compute thisquery set with another 25 candidate sets, each having 1024 pairs sampled from their playstyles. When thisround of polling is finished, we count whether the most similar candidate set has the same playstyle as thequery set. This polling process will run over 100 times for sampling different subsets of actual playstyledatasets. Additionally, we examine the intersecting states sample threshold count t, where an intersectingstate requires at least t samples in both compared datasets for a stable action distribution estimation. In our comparisons, conventional methods, such as supervised learning and contrastive learning, fall short forthis classification due to the lack of playstyle labels or groups in the training datasets, resulting in a randommodel. Thus, we focus our comparisons on Playstyle Distance, as detailed in Equation 2. For the multiscaleversion, which incorporates three discrete state spaces{1, 220, 256res}we simplify our terminology byusing the label \"mix.\" The results, as shown in , indicate that using a multiscale discrete state spacenot only simplifies the selection of a proper state space by using all spaces and potentially yields superiorresults but also obviates the need for a sample threshold count t for intersecting states in some gamesrequiring a stable action distribution, such as TORCS, Asterix, and Breakout.",
  "Probability vs. Distance": "In addition to introducing the multiscale discrete state space, another key contribution of our work is theproposal to use probabilistic similarity from a perceptual perspective rather than employing negative distanceas a measure of similarity. To elucidate the benefits of this modification, we examine the relationship betweenaccuracy and dataset size of the sampled observation-action pairs. These pairs are evaluated under a singlediscrete state space {220}, without employing a sample count threshold, to provide a clear assessment of thetransformation from distance to similarity. Further comparisons with different discrete state spaces can befound in Appendix A.2.",
  "RGSK81.0 7.279.2 7.993.7 4.75.7 2.525.6 7.278.8 7.593.5 4.3": "Asterix25.2 9.099.9 0.5100 049.6 7.732.7 8.0100 0100 0Breakout32.7 9.299.4 1.699.9 0.665.9 8.529.9 9.499.8 1.199.9 0.2MsPac.100 099.9 0.5100 092.8 4.0100 0100 0100 0Pong49.9 9.792.1 2.792.3 2.650.7 9.552.2 9.993.1 3.292.4 2.6Qbert99.9 0.5100 0100 090.1 5.391.6 4.699.9 0.5100 0Seaquest82.0 7.699.7 1.299.9 0.617.1 5.216.7 4.999.9 0.399.9 0.2SpaceIn.73.1 8.598.7 2.399.7 1.250.4 5.749.6 8.499.9 0.599.9 0.6",
  "Random: A uniform random baseline that is a common result from supervised learning or contrastivelearning if there is no style label or group (like self and others) information in the training data": "Results presented in suggest that probabilistic similarity can be a good alternative to distance-based similarity, offering improved explainability in terms of measure values. Among the methods evaluated,the 2-Wasserstein distance with a perceptual kernel and the Bhattacharyya coefficient emerge as superiorcandidates. The intention behind using probabilistic similarity is that it provides a consistent measure ofsimilarity across different games (via likelihood). For distance similarity, understanding the propertys anddistribution of distance is essential to interpret the measure value. Besides the explainability of similarityvalues, the transformed similarity value can be incorporated with the Jaccard index as described in Sec-tion 3.3. The evidence shows that results with probabilistic similarity are not worse than distance similarityand are slightly better on TORCS, which includes slightly different playstyles. The upcoming experimentsin Sections 5.3 and 5.4 also support the idea of probabilistic similarity under slightly changed playstyles,such as rule-based TORCS agents and Atari game agents trained with the same algorithm.",
  "Full Data Evaluation": "Based on the previous evaluations, we further perform a comprehensive evaluation of various playstylemeasures, including leveraging full data with union operations. The evaluation method mirrors the onepresented in .2, but expands the scope beyond racing games and adopts a multiscale state space. Detailed results for each Atari game have been moved to Appendix A.3.2. Instead, leveraging the consistentobservation and action space shared across Atari games, we propose a unified Atari console evaluation. This",
  "(b) RGSK": ": Accuracy comparison of potential unsupervised similarity measures on (a) TORCS and (b) RGSK.The shaded area indicates the range between the min and max accuracy among three encoder models. Ob-servation latent-based methods like Euclidean Distance and Cosine Similarity perform nearly at randomlevels in TORCS and perform much better in RGSK due to different playstyles and game properties. Theplaystyles in RGSK have many visual features that reflect styles, such as the blue fire from the nitro accel-eration system and the driving surface or position on the track. these measures on Atari games in , Euclidean Distance and Cosine Similarity usually share similarperformance, and the results depend on the games. In all cases, Playstyle Similarity and its BC variant aresuperior to these potential candidates with datasets over 256 in size, regardless of the playstyle and games.The measure values based on action distributions are more explainable than observation latent features.Furthermore, observations are sometimes not controllable by the players performing playstyles but are con-trolled by game mechanisms, other players, or even sample bias. Discrete playstyle measures can defendagainst these influences since observations are used for comparison conditions rather than direct measure-ment computations. If these influencing factors make observations different, discrete playstyle measures actconservatively, requiring more samples or deeming them incomparable, while latent similarity approaches willdirectly take them into calculation without considering the influencing factors. Overall, these results showthat our Playstyle Similarity and its BC variant are more general and effective in unsupervised playstylemeasurement compared to other existing or potential measures.",
  "Random: A uniform random baseline": "Results displayed in show that the Playstyle Similarity outperforms its counterparts. Moreover, theJaccard index has proven to be useful in practice. Our combined Atari console evaluation further underscoresthe robustness and adaptability of our measures. Conclusively, our proposed Playstyle Similarity measure excels across these video game platforms.It isparticularly impressive that it can identify playstyles with over 90% accuracy with just 512 observation-action pairs less than half an episode across all tested games. This suggests the possibility of accurateplaystyle prediction even before a game concludes, paving the way for real-time analysis.",
  "Continuous Playstyle Spectrum in TORCS": "This experiment investigates the response of similarity measure values to variations in a continuous playstylespectrum within the TORCS environment. It particularly focuses on whether these measures can accuratelyrank playstyles, ensuring precise predictions for the closest playstyle (Top-1 similarity) and maintaining acorrectly ordered sequence of playstyles based on similarity measures. Utilizing the TORCS dataset, which includes five levels of target speeds (60, 65, 70, 75, 80) and five levels ofaction noise, provides a broad spectrum for examining continuous playstyle changes. To illustrate, consider",
  "N4 (C)0.04210.04130.04020.03490.0337": "five playstyles labeled A through E, with A being a variant closely aligned with A. We anticipate that thesimilarity between A and A would be the highest, progressively decreasing towards E. This expectation setsthe stage for our consistency test, wherein a similarity measure M should validate the order M(A, A) >M(A, B) > M(A, C) > M(A, D) > M(A, E) (Corner Case).",
  ". Playstyle Similarity with a mixed state space": "With 100 rounds of random subsampling (each dataset consisting of 512 observation-action pairs) and usingthe first Hierarchical State Discretization (HSD) model, we examine the consistency of similarity values asplaystyle shifts. A decrease in similarity consistent with playstyle changes is marked with a (C), indicatingmeasure reliability. For instance, choosing Speed60N0 as a target playstyle, we observe how similarity measures adjust acrossa row or column in response to increasing speed or action noise levels. A practical demonstration revealshow the measure values consistently decrease across increasing speed levels and noise intensities, illustratingthe measures ability to capture playstyle divergence accurately. presents one such example withPlaystyle Similarity (mix). For all measure values, please refer to our Appendix A.4.",
  "Comparison of Potential Unsupervised Similarity Measures": "With previous experiments, we have verified the effectiveness of these discrete playstyle measures. Althoughthere are few methods for unsupervised playstyle measurement before Playstyle Distance, there are somemeasures popular in generative styles with latent feature similarity. For example, the two most popularmeasures for research in generative adversarial networks (GAN) with styles (Karras et al., 2019) are theInception Score and Frchet Inception Distance (FID) (Salimans et al., 2016; Heusel et al., 2017). Theseare based on using an image classification model, Inception (Szegedy et al., 2015), for scoring the generatedimages. The Inception Score is based on the prediction distribution of the classifier to detect real or generatedimages, which diverges from the target of playstyle measurement as all observations are real images fromgame environments. FID measures the 2-Wasserstein distance on the latent features of images and could beincorporated into playstyle measurement if we assume a playstyle features a unique observation distribution.However, calculating the W2 distance for high-dimensional continuous latent distributions is computationallyintensive and does not yield good results in the game TORCS (Lin et al., 2021). The major complexity arisesfrom the calculation related to the covariance matrix. A time-feasible alternative is using the similarity ofthe mean vector of these latent features. We can first average those latent features of observations into amean vector to represent the playstyle and compare the similarity to candidate vectors obtained from thesame process, which is analogous to the method in Behavior Stylometric (McIlroy-Young et al., 2021). Theselatent features used in the following experiments are the continuous latent features before vector quantizationto the 220 state space in the HSD models with 500 dimensions. The discrete version of these latents withinformation loss has already shown effectiveness in playstyle measurements, so we compare using continuouslatents with two popular similarity measures for playstyle measurements: Euclidean Distance (L2 distance)and Cosine Similarity. Cosine Similarity is especially common in latent similarity applications (Chung et al.,2022; McIlroy-Young et al., 2021).",
  ". Cosine Similarity, using Cosine Similarity as the similarity measure for observation latent features": "We first check the results for TORCS and RGSK in . It is clear that Euclidean Distance and CosineSimilarity do not provide good predictions, which is not surprising since the observations in the TORCSpractice track are monotonous, and the playstyles are not directly correlated to observations. In contrast,playstyles in RGSK, such as nitro acceleration or preferred road surface, have a high correlation to visualfeatures and even perform better than Playstyle Similarity under a few samples. When we further examine",
  ": High Randomness Puzzle Game": "Known for its single-player format and high degree of randomness, 2048 presents challenges in generatingidentical trajectories. We trained a reinforcement learning agent (Szubert & Jaskowski, 2014) over 10 millionepisodes, creating 10 distinct players by saving the model every 1 million episodes. For each player, wecollected 1000 episodes, using the first 500 as the reference dataset and the remaining 500 as separate querydatasets. This resulted in a total of 5000 query datasets for the experiment. The setup aimed to test theaccuracy of playstyle measures in scenarios marked by high randomness and similar behaviors across smallquery datasets, simulating conditions that could challenge discrete playstyle measures.In this case, wedirectly utilized the 4 4 full board as the discrete states, which is equivalent to raw game screens in 2048in terms of state information. The experimental settings used for this analysis are listed in Appendix A.6. The results in demonstrate that measures incorporating the Jaccard index negatively impact accu-racy. In games with high randomness and large observation space, it is crucial to evaluate whether discretestates can identify key style factors while maintaining a manageable state space to find comparable samples.",
  "Go: Two-Player Board Game": "In addition to the inherent randomness of game environments, the inclusion of other players introducesfurther uncertainty in measuring playstyles. Consequently, we undertook a human playstyle identificationtask using the two-player board game, Go, which is known for its high game tree and state space complexity(Van Den Herik et al., 2002). This complexity can challenge discrete playstyle measures. We implemented a variant of the HSD encoder (Lin et al., 2021) to obtain a discrete state encoder forthis task. The major difference from the original HSD is that the reconstruction objective is replaced bypredicting the win value, with prediction policy and value being the standard objectives in Alpha Zero seriesalgorithms (Silver et al., 2018). The details about this discrete encoder are described in Section A.7. TheGo dataset used in this study was sourced from Fox Go (Fox Go, 2024a;b) and provided by the team ofthe MiniZero framework (Wu et al., 2024). It includes 45,000 games from players with 9 Dan Go skill fortraining the encoder, with corresponding actions but without player information or style labels. Anotherdataset includes 200 human players with Go skill ranging from 1 Dan to 9 Dan, each contributing 100 gamesto the query datasets and 100 games to the candidate datasets. The discrete state space used for trainingthe encoder includes {48, 168, 256361}. Results in demonstrate the accuracy comparisons of the player identification task with differentdiscrete playstyle measures. There are two playstyle scenarios in our evaluation. For the first 10 movescase, it is common and straightforward in board games that a preferred opening is a kind of playstyle andusing a small state space can achieve 97.0% accuracy ({48}). However, when we do not specifically focus onthe playstyles in the opening, we may want to use all game moves to capture any possible playstyles, andsuch a small state space negatively impacts the accuracy. Some boards cannot be compared in this kind ofplaystyle, but the small state space cannot provide information to separate these cases. Instead, large statespaces like {168} or {256361} can handle this kind of problem. If we do not know which state space cangive the best result, our multiscale state space is a good choice that leverages all state spaces. Even if itmay be influenced by a very bad state space like {48} in the full games case, the damage is limited. Also,",
  "discrete playstyles incorporating the Jaccard index (Playstyle Similarity and its variants) can further coverthis weakness": "Additionally, the Bhattacharyya coefficient is tend to be more effective than using perceptual kernel withscaled W2 distance when there are sufficient samples in Go, especially in the full game moves case. It ispossibly due to its distribution property that rapidly decreases similarity with few overlapping outcomes,and our Go result is an example. For slightly different playstyles like TORCS with continuous actions, usingthe scaled W2 metric can provide better accuracy. Our findings suggest that discrete playstyle measures canachieve significant accuracy with sufficient samples directly from the measure definition even in a complexmulti-agent board game, without any predefined style labels.",
  "Diversity Measurement in DRL": "With these discrete playstyle measures, we can design an algorithm to quantify the diversity among DRLmodels, which is challenging to measure and quantify formally in environments with high-dimensional ob-servations. Algorithm 1 provides a simple method to quantify diversity in decision-making by measuring thesimilarity between a new trajectory and observed trajectories. If a new trajectory is not similar enough toany observed trajectories, we count it as a different one. We conducted experiments to evaluate this algorithm using the Atari DRL agent dataset.Each DRLalgorithm (DQN, C51, Rainbow, IQN, (Mnih et al., 2015; Bellemare et al., 2017; Hessel et al., 2018; Dabneyet al., 2018)) includes 5 models, each contributing 5 trajectories, resulting in 25 trajectories per algorithm.Using Algorithm 1, we assessed the diversity of trajectories produced by each algorithm. Results in ,averaged across three discrete encoder models with a similarity threshold of t = 0.2, show the capacity ofmodels trained under the same DRL algorithm to generate diverse game episodes within 25 attempts. The",
  "Conclusion and Future Works": "In this research, we introduced three techniques to enhance discrete playstyle measures: adopting a multiscalestate space, using perceptual similarity rooted in human cognition, and applying the Jaccard index toobserved data. These advancements have been incorporated into playstyle measurement for the first timeand collectively give rise to our playstyle measure, Playstyle Similarity. This measure stands out in termsof accuracy and explainability, requiring minimal predefined rules and data. Notably, the integration ofa multiscale state space expands the measures applicability, particularly for games that have a trade-offbetween small and large state spaces for game details. Furthermore, our literature review and theoreticalproof about human perception bridge the gap between distance similarity and human cognition in playstyle.In addition to the common accuracy evaluations in our experiments, we also conducted a series of statisticaltests using McNemars test (McNemar, 1947) to report some results in the main paper with p-values inSection A.8. These tests help to determine whether two results have statistical significance rather thanshowing differences due to sampling uncertainty. The Playstyle Similarity measure offers new potential for end-to-end game analysis and AI training withspecific playstyles, such as diversity analysis or human-like behaviors (Fujii et al., 2013). As an example, wepropose an algorithm to quantify the diversity among DRL models, and the playstyle classification tasks onhuman playstyles in RGSK and Go also support future applications for human-like agents. These insightsemphasize that AI development can extend beyond simple measures like scores or win rates in games with",
  "high-dimensional observations, encompassing more behavioral patterns. Additionally, the quantification ofpolicy diversity becomes more tangible": "In conclusion, despite our validation efforts across several platforms, many games remain unexplored. Fur-thermore, some playstyles can be shared across different games, existing in similar scenarios for game rec-ommendation systems (Fear, 2023). Beyond gaming, playstyle measures can provide more behavioral infor-mation for other decision-making topics, such as AI safety (Amodei et al., 2016) and the interactions amonglanguage model agents (OpenAI, 2024; Park et al., 2023).",
  "Broader Impact Statement": "We advise caution when using these measures for analyzing policy diversity due to potential sensitivities todiscretization techniques and inherent explainability challenges in neural networks. Additionally, employingunsupervised methods could raise privacy concerns, as they facilitate targeted advertising or fraudulentactivities without the need for costly playstyle labeling. We would like to express our sincere gratitude to Chen (2023) for generously sharing the Go playstyle datasetbased on the MiniZero Framework (Wu et al., 2024), which was instrumental in training our discrete encoderand conducting the playstyle tests. Additionally, we appreciate the valuable feedback and insights providedby the reviewers, which greatly helped in refining and improving this work. Finally, we would like to thankUbitus K.K. for motivating the research topics related to video game playstyles in our early studies. Rishabh Agarwal, Marlos C. Machado, Pablo Samuel Castro, and Marc G. Bellemare. Contrastive behavioralsimilarity embeddings for generalization in reinforcement learning. In International Conference on LearningRepresentations (ICLR), 2021.",
  "Dario Amodei, Chris Olah, Jacob Steinhardt, Paul F. Christiano, John Schulman, and Dan Man. Concreteproblems in AI safety. CoRR, abs/1606.06565, 2016": "Marcin Andrychowicz, Bowen Baker, Maciek Chociej, Rafal Jzefowicz, Bob McGrew, Jakub Pachocki,Arthur Petron, Matthias Plappert, Glenn Powell, Alex Ray, Jonas Schneider, Szymon Sidor, Josh Tobin,Peter Welinder, Lilian Weng, and Wojciech Zaremba. Learning dexterous in-hand manipulation. TheInternational Journal of Robotics Research, 2020. Adri Puigdomnech Badia, Bilal Piot, Steven Kapturowski, Pablo Sprechmann, Alex Vitvitskyi, Zhao-han Daniel Guo, and Charles Blundell. Agent57: Outperforming the atari human benchmark. In Inter-national Conference on Machine Learning (ICML), 2020.",
  "Marc G. Bellemare, Will Dabney, and Rmi Munos. A distributional perspective on reinforcement learning.In International Conference on Machine Learning (ICML), 2017": "Christopher Berner, Greg Brockman, Brooke Chan, Vicki Cheung, Przemyslaw Debiak, Christy Dennison,David Farhi, Quirin Fischer, Shariq Hashme, Christopher Hesse, Rafal Jzefowicz, Scott Gray, CatherineOlsson, Jakub Pachocki, Michael Petrov, Henrique Pond de Oliveira Pinto, Jonathan Raiman, TimSalimans, Jeremy Schlatter, Jonas Schneider, Szymon Sidor, Ilya Sutskever, Jie Tang, Filip Wolski, andSusan Zhang. Dota 2 with large scale deep reinforcement learning. CoRR, abs/1912.06680, 2019.",
  "Paul T Costa Jr and Robert R McCrae. Domains and facets: Hierarchical personality assessment using therevised neo personality inventory. Journal of personality assessment, 1995": "Will Dabney, Georg Ostrovski, David Silver, and Rmi Munos. Implicit quantile networks for distributionalreinforcement learning. In Jennifer G. Dy and Andreas Krause (eds.), International Conference on MachineLearning (ICML), 2018. Anders Drachen, Alessandro Canossa, and Georgios N. Yannakakis. Player modeling using self-organizationin tomb raider: Underworld. In IEEE Conference on Computational Intelligence and Games (CIG), 2009.",
  "Robert L. Goldstone and Lawrence W. Barsalou. Reuniting perception and conception. Cognition, 1998": "Matteo Hessel, Joseph Modayil, Hado van Hasselt, Tom Schaul, Georg Ostrovski, Will Dabney, Dan Horgan,Bilal Piot, Mohammad Gheshlaghi Azar, and David Silver. Rainbow: Combining improvements in deepreinforcement learning. In AAAI Conference on Artificial Intelligence (AAAI), 2018. Martin Heusel, Hubert Ramsauer, Thomas Unterthiner, Bernhard Nessler, and Sepp Hochreiter. GANstrained by a two time-scale update rule converge to a local Nash equilibrium. In Advances in NeuralInformation Processing Systems (NeurIPS), 2017. Arthur Juliani, Vincent-Pierre Berges, Ervin Teng, Andrew Cohen, Jonathan Harper, Chris Elion, Chris Goy,Yuan Gao, Hunter Henry, Marwan Mattar, and Danny Lange. Unity: A general platform for intelligentagents. CoRR, abs/1809.02627, 2020.",
  "OpenAI. Chatgpt: A large language model, 2024. URL Accessed: 2024-06-19": "Long Ouyang, Jeffrey Wu, Xu Jiang, Diogo Almeida, Carroll L. Wainwright, Pamela Mishkin, Chong Zhang,Sandhini Agarwal, Katarina Slama, Alex Ray, John Schulman, Jacob Hilton, Fraser Kelton, Luke Miller,Maddie Simens, Amanda Askell, Peter Welinder, Paul F. Christiano, Jan Leike, and Ryan Lowe. Traininglanguage models to follow instructions with human feedback. In Advances in Neural Information ProcessingSystems (NeurIPS), 2022.",
  "Jean-Philippe Vert, Koji Tsuda, and Bernhard Schlkopf. A primer on kernel methods. Kernel methods incomputational biology, 2004": "Oriol Vinyals, Igor Babuschkin, Wojciech M. Czarnecki, Michal Mathieu, Andrew Dudzik, Junyoung Chung,David H. Choi, Richard Powell, Timo Ewalds, Petko Georgiev, Junhyuk Oh, Dan Horgan, Manuel Kroiss,Ivo Danihelka, Aja Huang, L. Sifre, Trevor Cai, John P. Agapiou, Max Jaderberg, Alexander Sasha Vezh-nevets, Rmi Leblond, Tobias Pohlen, Valentin Dalibard, David Budden, Yury Sulsky, James Molloy,Tom Le Paine, Caglar Gulcehre, Ziyun Wang, Tobias Pfaff, Yuhuai Wu, Roman Ring, Dani Yogatama,Dario Wnsch, Katrina McKinney, Oliver Smith, Tom Schaul, Timothy P. Lillicrap, Koray Kavukcuoglu,Demis Hassabis, Chris Apps, and David Silver. Grandmaster level in starcraft ii using multi-agent rein-forcement learning. Nature, 2019.",
  "Li Wan, Quan Wang, Alan Papir, and Ignacio Lopez-Moreno.Generalized end-to-end loss for speakerverification. In International Conference on Acoustics Speech and Signal Processing (ICASSP), 2018": "Ti-Rong Wu, Hung Guei, Pei-Chiun Peng, Po-Wei Huang, Ting Han Wei, Chung-Chin Shih, and Yun-JuiTsai. Minizero: Comparative analysis of alphazero and muzero on go, othello, and atari games. IEEETransactions on Games, 2024. Georgios N. Yannakakis, Pieter Spronck, Daniele Loiacono, and Elisabeth Andr.Player modeling.InArtificial and Computational Intelligence in Games. Schloss Dagstuhl - Leibniz-Zentrum fr Informatik,2013.",
  "In the main paper, we claim that P(d) =1ed is the if and only if kernel function (as discussed in .2).We provide a proof of this claim using differential equations": "We make some assumptions about the perceptual kernel. First, P(d) is a function that maps the distanced between two given action distributions to a probability value describing their similarity. Since distance isa continuous random variable, we use a probability density function f(d) to describe the mapping functionP(d). We might intuitively think of P(d) as equal to f(d), even though the probability density value is not the sameas the probability value. Thus, we use a cumulative distribution function F(d) to describe P(d). We redefinea real-valued random variable D as the distance variable, where d D, and a random variable X, wherex X, and D X : X(d) = d. The probability of similarity, denoted as P(X x), is derived from thedistance value d. Thus, FX(x) = P(X x), and from the assumptions of similarity, limx FX(x) = 0,and FX(0) = 1. Also, FX(x) can be described with a probability density function fX(x) as follows:",
  ". If p represents distance and k is positive, this is incorrect since S approaches as p , althoughthere is a finite maximal value S0 when p = 0": "2. If we change the growth direction of distance so that k is negative, this meets our desire since Sapproaches 0 as p , there is a finite maximal value S0 when p = 0, and the density value isalways non-negative. Finally, we can simplify the equations by assuming, for the sake of simplicity, that S0 equals 1.Thisassumption is based on the intuition that the trend of decreasing similarity and increasing distance is similararound distance 0 in various scenarios:",
  "A.2.1Bhattacharyya distance implementation": "In this paper, we also provide some variants of Playstyle Similarity, which use Bhattacharyya distance orcoefficient as an alternative to the 2-Wasserstein metric to assess the difference in playstyle from a differentperspective. Bhattacharyya distance is related to the overlapping region between two distributions, and itis defined through Bhattacharyya coefficient BC. The value range of BC is , and the correspondingdistance DB is DB = ln(BC). For discrete probability distribution, it is simple to compute the Bhat-tacharyya coefficient: BC(P, Q) =",
  "e10 = 0.00004539992 0%).The small value for dealing with singularmatrices in matrix determinant calculation is set to 1e-8": "Recalling our earlier discussion, we mentioned that the Wasserstein distance can be likened to the effortrequired to transition between different playstyle action distributions (as described in .2). TheBhattacharyya distance, in contrast, isnt about this effort.Instead, it gauges the likelihood that twoplaystyles will result in the same action. This is due to its relation to the overlapping regions betweentwo distributions. Thus, while the Playstyle Similarity is built on the idea of the effort needed to changeplaystyles, the Playstyle BC Similarity (or its variant Playstyle BD Similarity) is built on the frequency ofidentical actions. This distinction might relate to different roles within a game. For instance, a player in thegame might be more concerned with the effort required to shift playstyles, while an observer might focusmore on the actions they witness. Think of it this way: players exert effort, like moving their fingers to pressbuttons or manipulate a joystick or even a mental effort to change their belief of playing. The observer, onthe other hand, sees only the outcome of these actions, without much insight into the effort involved.",
  "A.2.2Multiscale State Space with HSD": "presents the results of experiments conducted with a multiscale state space {1, 220, 256res} generatedfrom HSD models, as described in .2. The results indicate an improvement in accuracy for TORCS,while there is no clear improvement in RGSK. Notably, in RGSK, the accuracy of the perceptual kernel withsample sizes 25 to 28 decreases, suggesting that detailed information for distinguishing these styles has anegative effect. To further investigate, we conducted two ablation studies to understand the effectiveness ofthe proposed measures for playstyle similarity. The first study focuses on using only the base hierarchy ofHSD with a very large state space {256res}, while the second study explores the use of a single-state statespace {1} to assess the measures. illustrates that the measurement is unstable when there arefew intersecting samples in a very large state space. However, the negative effect of detailed information ismitigated when considering intersection over union. also shows that even with single state space,the action statistics of the dataset can offer some information to differentiate playstyle, especially in RGSK,where Lin et al. (2021) made their human players follow some playstyles closely related to the keyboardactions, such as using the nitro system or braking in the racing game.",
  "A.2.3Discrete Representation from Downsampling": "There are several existing methods for generating discrete representations. One conventional method forimage data is downsampling to a lower resolution. While the downsampling parameters often require tuningfor effective processing, it is a straightforward method that does not require training a neural network model.Previous work by Lin et al. (2021) attempted to use low-resolution downsampling as a discretization method,but they encountered challenges due to the lack of intersection states in their settings.",
  "(h) RGSK with multiscale state space": ": Comparison of Efficacy: Using different state spaces in discrete playstyle measurement for TORCSand RGSK, including single state space {1}, {220} state space, the base hierarchy of HSD with state space{256res}, and multiscale state space {1, 220, 256res}. The shaded area indicates the range between the mini-mum and maximum accuracy among three encoder models.",
  "A.3.1Statistics of Each Discrete Encoder with Multiscale State Space": "In this subsection, we provide the mean and standard deviation of the accuracy from in .There are 3 available discrete encoders trained using the HSD method in our experiments. Their mean andstandard deviation values are calculated based on 100 rounds of random subsampling, with each dataset ina subsampling consisting of 1024 observation-action pairs. We employ sampling without replacement (thereare no duplicated observation-action pairs in the two comparing datasets) except for Atari games, wheresome games have fewer than 2 1024 pairs for sampling double the size of the dataset.",
  "A.3.2Individual Atari game results with multiscale state space": "shows the relationship between playstyle classification accuracy and sampled dataset size for theseven Atari games. Playstyle Similarity (PS) and its variant Playstyle BC Similarity (PSBC) have nearlythe same performance, and Playstyle Jaccard Index (J) can have a decent result. This evidence justifiesthat some playstyles, especially in a deterministic environment, can be differentiated solely with observations,which explains why the work by Eysenbach et al. (2019) considers states only for diversity.",
  "A.3.3Atari game results with a smaller state space": "shows the relationship between playstyle classification accuracy and sampled dataset size forthe seven Atari games and the combined version (Atari Console). These results show that measures withintersection over union still perform well in Atari games even with a smaller state space. Although it seemsthat Playstyle Jaccard Index is a decent and easy measure, we know that it theoretically does not work aslong as all states are visited in the sampled dataset, as described in .3. This potential problem isdiscussed in more detail in Section A.3.4, where even with a state space of 220, the Playstyle Jaccard Indexmay not perform well.",
  "t=2220 t=1256res t=2256res t=1mix t=2mix t=1": "TORCS73.3 8.266.5 7.94.3 3.160.9 9.477.3 7.477.5 7.9Encoder170.3 9.163.8 8.55.8 4.355.0 9.974.2 8.175.9 8.3Encoder271.6 9.170.2 7.63.6 3.560.1 9.877.0 7.175.5 7.9Encoder377.9 6.665.7 7.73.4 1.467.6 8.680.8 7.181.1 7.6 RGSK79.2 7.993.7 4.75.7 2.525.6 7.278.8 7.593.5 4.3Encoder180.4 7.593.0 5.05.6 2.423.4 7.681.2 7.493.4 4.6Encoder280.2 8.197.4 2.95.0 2.120.5 6.978.2 7.896.9 3.1Encoder376.8 8.190.7 6.16.3 2.932.9 7.377.2 7.490.3 5.3",
  "Qbert100 0100 090.1 5.391.6 4.699.9 0.5100 0Encoder1100 0100 095.4 3.899.9 0.799.9 0.5100 0Encoder2100 0100 082.1 6.782.8 8.099.9 0.5100 0Encoder3100 0100 092.8 5.592.2 5.199.9 0.5100 0": "Seaquest99.7 1.299.9 0.617.1 5.216.7 4.999.9 0.399.9 0.2Encoder199.9 0.999.9 0.517.1 5.315.8 4.5100 0100 0Encoder299.9 0.7100 017.2 5.317.3 5.399.9 0.999.9 0.5Encoder399.7 1.299.6 1.417.2 5.017.0 5.0100 0100 0 SpaceIn.98.7 2.399.7 1.250.4 5.749.6 8.499.9 0.599.9 0.6Encoder198.8 2.599.9 0.951.2 8.450.2 7.899.8 1.099.9 0.7Encoder299.6 1.499.9 0.950.3 0.150.2 8.7100 099.9 0.5Encoder397.9 3.099.3 1.949.9 8.848.6 8.899.9 0.599.9 0.7",
  "In this section, we conducted experiments using a reduced state space of 220 for the two racing games,TORCS and RGSK, without employing the multiscale technique": "illustrates that the Playstyle Jaccard Index performs the poorest in TORCS and exhibits slightlyinferior performance to Playstyle Similarity and Playstyle BC Similarity in RGSK. This observation providesvaluable insights into the suitability of the Playstyle Jaccard Index for precise measurements, particularly inscenarios involving randomness (e.g., TORCS players employing different action noises) or where observationsexhibit only slight variations (e.g., stable rule-based AI controllers in TORCS with slightly different target).Further investigation may be warranted to understand the reasons behind these performance differences.",
  "A.4Continuous Playstyle Spectrum in TORCS": "This experiment investigates the response of similarity measure values to variations in a continuous playstylespectrum within the TORCS environment. It particularly focuses on whether these measures can accuratelyrank playstyles, ensuring precise predictions for the closest playstyle (Top-1 similarity) and maintaining acorrectly ordered sequence of playstyles based on similarity measures. Utilizing the TORCS dataset, which includes five levels of target speeds (60, 65, 70, 75, 80) and five levels ofaction noise, provides a broad spectrum for examining continuous playstyle changes. To illustrate, considerfive playstyles labeled A through E, with A being a variant closely aligned with A. We anticipate that thesimilarity between A and A would be the highest, progressively decreasing towards E. This expectation setsthe stage for our consistency test, wherein a similarity measure M should validate the order M(A, A) >M(A, B) > M(A, C) > M(A, D) > M(A, E) (Corner Case).",
  "playstyle shifts. A decrease in similarity consistent with playstyle changes is marked with a (C), indicatingmeasure reliability": "For instance, choosing Speed60N0 as a target playstyle, we observe how similarity measures adjust across arow or column in response to increasing speed or action noise levels. A practical demonstration reveals howthe measure values consistently decrease across increasing speed levels and noise intensities, illustrating themeasures ability to capture playstyle divergence accurately.",
  ". M(C, C) > M(C, D) > M(C, E)": "These sequences confirm the measures capacity to accurately reflect the gradual divergence of playstylesfrom a central reference point. The detailed findings, presented in Tables 9-19, underscore the nuancedperformance of each evaluated measure. Additionally, we present the standard deviation of the measurevalues, denoted as (std), alongside the measure values themselves. The query playstyle is marked as orange,and those columns with consistency in measure values are marked in blue. For rows with consistency, markedas red, and for those values with consistency in both columns and rows, marked violet.",
  "A.5More Experiments on Diversity Measurement in DRL": "This section introduces additional experiments demonstrating the application of our method for quantifyingdecision-making diversity, detailed in Algorithm 1. We analyze the Atari DRL agent dataset from the mainpaper, which includes 5 models per DRL algorithm, each contributing 5 trajectories, totaling 25 trajectoriesper algorithm (Mnih et al., 2015; Bellemare et al., 2017; Hessel et al., 2018; Dabney et al., 2018). UsingAlgorithm 1, we assess the diversity of trajectories produced by each algorithm. Results in , averagedacross three discrete encoder models with a similarity threshold of t = 0.2, show the capacity of models trainedunder the same DRL algorithm to generate diverse game episodes within 25 attempts. The IQN algorithmdisplays higher diversity across games, consistent with its risk sampling feature. We also apply various levels of stochasticity using the Dopamine framework to illustrate another use caseof this measure. Our focus is on the first IQN model from Dopamine, which is expected to adapt to a widearray of playstyles due to its risk functions and robust performance capabilities. To encourage diversity, weemploy the Boltzmann distribution, commonly known as softmax, varying the temperature (z) to influencedecision-making:",
  "This approach, inspired by Fan & Xiao (2022), uses the advantage function (A) crucial in action selectionin reinforcement learning, where a higher advantage indicates a preferable action": "We explore four levels of randomness (z {0.0001, 0.001, 0.01, 0.1}), anticipating increased diversity withgreater randomness. We test similarity thresholds (t) of 0.5, 0.2, and 0.05 across seven Atari games with100 trajectories each. Results are illustrated through shaded curves in Figures from to ,demonstrating the efficacy of our diversity measure. Notably, games like Seaquest (b) exhibit high diversity even at lower randomness levels, indicatingintrinsic complexity in terms of playstyles. In contrast, Qbert (a) becomes more monotonous sincethe goal is to achieve a higher score in the puzzle game. This observation suggests another application for ourmeasure: identifying the complexity of game content. The time complexity of Algorithm 1 is O(N 2), giventhe number of trajectories N. Future research could investigate more efficient methods, perhaps leveragingapproximations or advanced data structures for quicker similarity checks. The algorithm we introduce for diversity quantification shifts our understanding of gaming from the subjectiveto the quantitative. While various methodologies for measuring diversity exist in different domains, ourapproach is particularly apt to video game playing. In addition, recognizing and quantifying this diversitycan inform the development of more adaptive DRL models, thereby addressing specific challenges in gamingand artificial intelligence. This new measure contributes to our progress toward models that are not onlyefficient but also demonstrate a variety of adaptable strategies, opening up vast avenues for future research.",
  "A.7Go Experiment Details": "Our Go experiment follows the standard 19x19 rules with common observations, including the latest eightboard views and player color, resulting in 18 channels (Silver et al., 2018; Wu et al., 2024). The action spaceincludes 362 discrete actions (361 move actions and a pass). shows the variant of HSD we used. The primary difference from the implementation in PlaystyleDistance is that the reconstruction head for the autoencoder is replaced by a value head. Additionally, weuse three levels of hierarchy with different numbers of embedding candidates: 256 candidate embeddings atthe base level, 16 candidate embeddings at the next level, and 4 candidate embeddings at the final level. Thesmallest state space is 48 = 65536, which ensures sufficient intersection states even with only a few gamerecords. The datasets used for training the encoder and playstyle identification are private datasets providedby the MiniZero framework team (Wu et al., 2024). If you need these datasets to reproduce our results onGo, please contact them directly for authorization. We train the encoder with a batch size of 1024 over 100 iterations, each iteration including 1000 networkupdates with the Adam optimizer. The learning rate starts at 0.00025 and linearly decays to 0 according tothe iteration number. The coefficient in the vector quantization process is the commonly suggested 0.25(van den Oord et al., 2017; Lin et al., 2021). The loss function for the policy head is cross-entropy, and theloss for the value head is mean square error, with the loss coefficients of these two heads both set to 1. Tables 21-29 list the detailed accuracies for different query and candidate sizes using only the first 10 movesof games and using the full game moves as mentioned in .2. For the first 10 moves case, it iscommon and straightforward in board games that a preferred opening is a kind of playstyle and using asmall state space can achieve 97.0% accuracy ({48}, ). However, when we do not specifically focuson the playstyles in the opening, we may want to use all game moves to capture any possible playstyles, and",
  "Full Game MovesQuery 1Query 5Query 10Query 25Query 50Query 75Query 100": "Candidate 12.5%3.0%5.5%3.0%5.5%3.5%3.0%Candidate 55.0%5.5%8.0%6.0%10.0%11.5%10.0%Candidate 107.0%9.5%11.5%10.5%11.0%11.0%10.5%Candidate 259.5%13.5%16.0%20.0%20.5%20.5%21.5%Candidate 5010.0%22.5%30.0%32.0%31.0%31.5%33.0%Candidate 7513.5%30.0%38.0%42.0%43.0%39.5%39.5%Candidate 10016.5%33.0%40.0%47.0%50.0%46.0%50.0% such a small state space negatively impacts the accuracy. Some boards cannot be compared in this kindof playstyle but the small state space cannot provide information to separate these cases. Instead, largestate spaces like {168} or {256361} can handle this kind of problem. If we do not know which state spacecan give the best result, our multiscale state space is a good choice that leverages all state spaces. Evenif it may be influenced by a very bad state space like {48} in the full games case, the damage is limited.Also, discrete playstyles incorporating the Jaccard index (Playstyle Similarity and its variants) can furthercover this weakness. Additionally, the Bhattacharyya coefficient is more effective when a playstyle playsvery diversely in a state, and our Go result is an example. For slightly different playstyles like TORCS withcontinuous actions, using the scaled W2 metric can provide better accuracy.",
  "A.8Statistical Significance of Experiment Results": "In this appendix, we present the statistical tests conducted to validate some of the claims made in our mainpaper. While accuracy is a common metric for evaluating the performance of classification models in machinelearning, it is essential to establish that the observed differences are not due to sampling uncertainty. Tothis end, we employed McNemars test (McNemar, 1947) for statistical significance. This non-parametrictest is particularly suitable for our paired classification scenarios with binary outcomescorrect or wrongpredictionsallowing us to compare whether the prediction correctness of two measures is statisticallysignificant.",
  ". For Go playstyle with full game moves, Playstyle BC Similarity has better accuracy than PlaystyleSimilarity": "The following subsections provide detailed results of these tests, including the p-values, which indicatewhether the observed improvements are statistically significant. Each subsection corresponds to a specificcomparison, outlining the methodology and presenting the findings. For defining statistical significance, werefer to a p-value < 0.05 as the default threshold suggested by Fisher (1970), since there is no standardp-value threshold for classification tasks in machine learning.",
  "A.8.1Multiscale State Space on TORCS": "In this subsection, we examine the performance of the multiscale state space in improving accuracy on theTORCS playstyle dataset. We conducted McNemars test to determine if the multiscale approach offersstatistically significant improvements over using individual state spaces alone. The corresponding section inthe main paper is .1. Since we use random subsampling in our experiments, we reran another 100 rounds of random subsampling,recording the contingency table of different state space settings with the same samples. In other words,the dataset sampled in each subsampling round was used in all state space settings rather than resamplingfor different settings. The accuracies are slightly different from those in , but the effectiveness ofimprovement with the multiscale state space remains consistent in . The mix version (multiscale)has better accuracy under the first two encoders and is slightly worse than 220 t=2 with a p-value of 0.179.However, using the same t=2 on the multiscale state space still shows a clear accuracy improvement. Overall,using t = 1 or t = 2 is not much different in TORCS; thus, a simpler setting with t = 1 (no filtering) forfiltering intersection states is what we recommend.",
  "A.8.2Using Perceptual Similarity as an Alternative to Distance Similarity": "Here, we investigate the efficacy of using perceptual similarity as an alternative to distance-based similar-ity measures.We applied McNemars test to compare the performance of these two approaches on theTORCS and RGSK datasets, particularly focusing on whether probabilistic similarity can offer equal orbetter performance. The corresponding section in the main paper is .2. We reran 100 rounds of random subsampling with a dataset size of 1024 and used the same samples forcomparing two variants of probabilistic similarity. The results in show clear improvements in accu-racy over Playstyle Distance with both Playstyle Intersection Similarity and Playstyle Inter BC Similarity.",
  "A.8.3The Potential Limitation of the Jaccard Index for Playstyle": "In this part, we explore the potential limitations of using the Jaccard index in playstyle measurement.Specifically, we assess its impact on accuracy in the game 2048, using McNemars test to highlight caseswhere the Jaccard index may negatively affect performance. The corresponding section in the main paperis .1. The results in show that playstyle measures including the Jaccard index have a clear accuracyreduction compared to the Playstyle Distance baseline, with the p-values demonstrating statistical signifi-cance.",
  "A.8.4The Recommendation of Using Playstyle BC Similarity on Go": "We conclude with an analysis of the Go playstyle dataset in , demonstrating the benefits of usingPlaystyle BC Similarity over Playstyle Similarity. McNemars test was applied to confirm the statisticalsignificance of the observed improvements in accuracy with the BC variant are not due to random samplingin the full game moves case. The corresponding section in the main paper is .2. With small samples,like using only one game record as a dataset, it is likely that these two measures have the same performance.",
  "M=10.5644.5% 4.0%M=50.00515.5% 22.0%M=101.333e-529.5% 45.5%M=252.553e-756.5% 73.0%M=502.566e-481.5% 92.0%M=750.00290.5% 97.5%M=1000.05294.0% 97.5%": "Conversely, when we have sufficient samples, like 100 games as a dataset, the p-value is slightly over 0.05,implying a 5.2% probability that Playstyle Similarity and Playstyle BC Similarity have nearly the sameperformance. In other sample sizes, we have enough confidence in claiming Playstyle BC Similarity hasbetter performance than Playstyle Similarity due to the corresponding p-values being less than 0.05 andshowing accuracy improvements."
}