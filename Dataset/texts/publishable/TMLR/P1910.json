{
  "Abstract": "We introduce a cryptographic method to hide an arbitrary secret payload in the response ofa Large Language Model (LLM). A secret key is required to extract the payload from themodels response, and without the key it is provably impossible to distinguish between theresponses of the original LLM and the LLM that hides a payload. In particular, the qualityof generated text is not affected by the payload. Our approach extends a recent result ofChrist, Gunn and Zamir (2023) who introduced an undetectable watermarking scheme forLLMs.",
  "Response:Dear Professor Hannity,": "I hope this email finds you well. I am writing to respectfully request that you consider the level of difficultyfor the final exam in Machine Learning 101. While I am confident in my understanding of the coursematerials and have put in a significant 0amount of effort throughout the semester, I do 1have 1",
  "Hidden Payload:OZ (Encoded as 10 bits.)": ": We asked Llama 2 to write an email urging a professor for an easy exam, intended to be sentanonymously. Nevertheless, the part of the response shown above secretly encodes the initials of the userwho used the LLM. This secret payload was encoded without modifying the response distribution at all.",
  "Introduction": "As the applications of machine learning models generating human-like text become widespread, concernsfor misuse proportionally rise. As detection of text generated by Large Language Models (LLMs) seeminglyapproaches infeasibility (JAML20; KSK+23; SKB+23; CBZ+23), the ability to intentionally plant a watermarkin LLM-generated text becomes the most viable approach to differentiate LLM-generated from human-generated text. A long line of works showed that a watermark can be planted in LLMs by altering the output texts (AF21;QZL+23; YAJK23; MZ23; KGW+23a). Recently, Christ, Gunn and Zamir (CGZ23) showed that a watermarkcan be planted in LLM-outputs without altering the distribution of responses. Informally, CGZ show that anyLLM can be modified such that: 1) It is computationally infeasible to distinguish between the original and",
  "Published in Transactions on Machine Learning Research (10/2024)": "yet it is very likely that the proof can be adapted for other conditions as well - as the algorithm itself is quiteflexible. We also note that in the proof we dont optimize for constants but for simplicity (of proof), theempirical evaluation in implies that the actual constants are far better than in the following proof. Definition 6.2. Let h = (h1, . . . , hL) be a sequence of empirical entropies (i.e., non-negative numbers). Wesay that h is r0-saturated if for every consecutive subsequence of h of length r r0, the sum of entropies isat least 10r ln r. That is, for every r r0 and 1 i L (r 1), we have i+r1j=ihj 10r ln r. For example, if the empirical entropy in each consecutive block of b tokens is at least some constant > 0,then the empirical entropies are Ob22-saturated. This is because a consecutive block of bk tokens contains",
  "Organization of the paper": "In we give the formal definitions of the problems setting, and state the main theorems of thispaper rigorously. We also give the necessary preliminaries. In we give a quick overview of the CGZwatermark. In we give an high-level overview of our scheme. Then, in we introducea simple dynamic error correcting code with feedback, which we later use as a building block. Finally, in we give and analyze the full scheme. In we discuss our implementation of the schemeand some empirical evaluation of it. In we discuss limitations of our scheme, and in particularrobustness to editing. We follow with open problems and conclusions.",
  "Let be the security parameter, we denote by negl() any function that is in O1": "p()for every polynomial p().As is standard in Cryptography research, we think of as the key size\", and of running times that aresuper-polynomial in as infeasible\". We denote by log and ln the logarithm with base two and the naturallogarithm, respectively. For a sequence s = (. . . , si, . . .) we denote by s[i : j] the sub-sequence (si, . . . , sj).The Hamming distance between two vectors is defined as the number of indices on which they differ, that",
  "negl()": "where f denotes a random function from {0, 1}1() to {0, 1}2(). PRFs are a standard cryptographic primitiveequivalent to one-way functions and can be constructed from standard assumptions (GGM86; HILL99).Intuitively, a PRF is simply a function that is indistinguishable from a totally random function withoutknowledge of the secret key k that parameterizes it.",
  "A language model Model is used to generate text as a response to a prompt by iteratively sampling from thereturned distribution until a special terminating token done T is drawn": "Definition 2.2. A language models response to prompt is a random variable Model(prompt) T that isdefined algorithmically as follows. We begin with an empty list of tokens x = (). As long as the last tokenin x is not done, we draw a token xi from the distribution Model(prompt, x) and append it to x. Finally,we set Model(prompt) = x.",
  "Empirical Entropy in Natural Language": "Studies in linguistics (GC02; CLA17; SL22) conclude that in natural language the entropy per unit of text(e.g., a word) is usually constant throughout the text. In particular, the empirical entropy of a LLM responseis expected to be linear in the length of the text, and roughly uniformly distributed among the differenttokens that assemble the response. This intuition was empirically verified by (CGZ23). We reaffirm the abovein in which we also run empirical evaluations.",
  "Steganography for LLMs": "In this section we finally define rigorously steganography for language models. We first explain the definitionintuitively. During the setup of the scheme, we generate a secret key k of size . To generate a response, weuse a method Stegk that together with the key k, receives a prompt prompt and a secret message payload.A retrieval method Retrk should be able to retrieve the hidden payload from an output generated using Stegk,while also using the secret key k.",
  "A semi-formal version of the theorem follows, the formal one appears in": "Theorem (Informal version of Theorem 6.3). Fix a model Model. Let prompt, payload be strings. Condi-tioned on the empirical entropy of a response y generated by Stegk(prompt, payload) being high enough,the expected length of the prefixes of payload and Retrk(y) that identify is at least (len(y)). The definition of high enough, formally stated in , roughly means that for any consecutive part ofthe response consisting of a large enough number r of tokens, the empirical entropy in that part is at leastthe square root (r) of the length. As discussed in .3.1 and verified empirically in , innatural language we actually expect the entropy to grow linearly with the length of the text, much higherthan the required square root. Under this condition, the theorem guarantees that a response of length L willallow retrieving the first (L) bits of the payload, which is (up to constants) the best possible.",
  "This section is adapted in its entirety from CGZ (CGZ23), and contains a high-level description of theirwatermarking scheme": "We first simplify the definition of a language model (Definition 2.1) by assuming that the token set isbinary, T = {0, 1}. We may assume this without loss of generality due to a straightforward reduction thatappears in .1 of CGZ. We will implicitly use this reduction throughout our work as well. The intuitive idea behind the CGZ watermark is planting a watermark not by changing the modelsdistribution, but by correlating the randomness used by the model with the secret key. We begin by describinga simplified approach that works only for generating a single response, of length bounded by some parameter L.Let k = (k1, k2, . . . , kL) be the secret key, chosen by drawing each ki uniformly and independently from .To generate a response to a prompt prompt, we run the model as intended yet use ki to determine therandom choice in the i-th response token generation. Let pi denote the probability, according to the real modelwith the previously chosen tokens as prefix, of the i-th token being 1. The watermarked model outputs xi = 1if ki pi and xi = 0 otherwise. Crucially, as ki was chosen uniformly, the probability of xi = 1 is exactly piand hence the output distribution of the model is not affected at all. On the other hand, we now expect somecorrelation between xi and ki.",
  "Ek[c(x) |x|] = ln 2 H(Model(prompt))": "We thus observed that at least in expectation, the score of watermarked texts is larger than that of arbitrarytexts, and that the difference between those quantities is roughly the entropy in the response. To make thisobservation algorithmically useful, considering expectations is not sufficient, as we need to set some scorethreshold for detection and analyze the probability of the score passing this threshold in each of the two cases.This analysis will not be repeated in this short overview and appears in CGZ. To avoid having an upper bound L on the length of the response, and to reduce the length of the key k, weuse a Pseudo-Random Function F (PRF, as defined in ). The key will now simply be a randomstring of length , and we would implicitly set ki := Fk(i). By the definition of a PRF, those values areindistinguishable from independently chosen random values. The final obstacle is remaining undetectable even when many queries are allowed. In the above sketch thechoice of the key k fully determines all randomness, and thus for example the same prompt will always get thesame response. To overcome this hurdle, we begin the generation of each response with using real randomness(and not the key) to sample tokens, while counting the empirical entropy of the response prefix generatedso far. When the response prefix passes a threshold of empirical entropy , we denote the responses prefixas r and start running the previous scheme with r as an additional input to the PRF. That is, after we setthe prefix r we use the value Fk(r, i) to generate the i-th token. In the detection, we will enumerate over allpossible prefixes of the response as r. In CGZ, it is shown that because the prefix r is set only after enoughentropy was used, it has negligible probability to ever repeat itself in different queries. Thus the inputs to thePRF calls are each unique and the scheme becomes undetectable even with many queries being made. The pseudo-codes for generation (Algorithm 1) and detection (Algorithm 2) of the watermark appear in theAppendix. In CGZ, those algorithms are then generalized to also support the detection of the watermarkfrom a substring out of the response and not only from the response in its entirety as is sketched above.",
  "return True;endendreturn False;": "As a first attempt, we notice that one may generalize any watermark into a steganography scheme by usingseveral keys. Let k1, . . . , km be m different secret keys, and setup a watermarking scheme with each of them.To encode a message i [m] within a response, simply use the watermarking instance corresponding to ki togenerate said response. In the retrieval step, we will use the detection algorithm with every key kj to findwhich of them was used. While undetectability is trivially preserved, as we only use undetectable watermarksto generate responses, the scheme becomes infeasible as soon as m isnt very small. This is because both therate of false-positives\" and the detection time grow by a multiplicative factor of m. In particular, encoding bits of information will cause a multiplicative factor of 2 in the running time of the retrieval algorithm, andwill also require that the false-positive rate of the watermarking scheme be much smaller than 2. A reasonable next step then, is breaking up the payload into smaller parts (say, characters or bits), andencoding each of those parts separately in a similar fashion to the previous suggestion. One subtle issue toovercome while implementing this idea is that partitioning the response into those smaller chunks is notstraightforward. This is because we know a successful watermarking requires high empirical entropy, and itis not known in advance what parts of the response would contain high empirical entropy. Moreover, theretriever needs to be able to use the same partition as the steganography algorithm. We solve this problemby implicitly defining the partition to chunks using the detection score itself: Let t be some score thresholdto be decided later. Denote the first bit of the payload by b {0, 1}. We start planting the payload inthe same way as the CGZ watermark is embedded, but with b as an additional input to the PRF. That is,",
  "n, which signifies how efficient the code is. The (relative)distance of a code is (Enc) := 1": "n minz=z Enc(z)Enc(z), which is twice the fraction of corrupt indices in acodeword that still allows decoding it to the original message. A code (or a family of codes) is consideredgood if both its rate and distance are constant, which means that the length of messages is only expanded bya constant factor, yet a constant fraction of errors can be corrected. ECCs are extensively studied and it islong known that good ECCs can be constructed, even when = = F2. (Ham50; Gil52; Var57; Jus72; SS96) An ECC with feedback is an ECC in which we transmit the symbols of the codeword Enc(x) one-by-one, andimmediately receive feedback with regards to whether an error occurred in transmitting this symbol. Thefollowing symbols we submit may adaptively depend on the feedback received so far. We say that the feedbackis noiseless if the feedback received is always reliable. If the errors in transmission occur randomly (i.e.,each transmitted symbol has the same probability of becoming corrupted), then it turns out that noiselessfeedback does not improve the parameters of the best possible ECC. On the other hand, if the small fractionof corrupted symbols is chosen adversarially, then noiseless feedback does improve the best possible distance.Feedback also appears to allow simpler and more efficient encoding and decoding schemes. (Ber64; Cov88)",
  "Definition 5.2. The rate of a Dynamic ECC is R(Enc) := infkN R(Enck) = infkNknk . The distance of itis (Enc) := infkN (Enck)": "In a similar manner, we also define a Dynamic ECC with (noiseless) feedback to be a Dynamic ECC in whichafter each symbol transmitted we receive a feedback as to which symbol was received. We next present asimple construction of a Dynamic ECC with feedback where || = 2, || = 3, and both the rate and distanceare constant. This construction is rather straightforward and is similar to constructions used in slightlydifferent settings (EGH15).",
  ". Both encoding and correction take linear time": "We think of the message alphabet as binary = {0, 1}, and to the codeword alphabet we add an additionalsymbol = {0, 1, }. We would think of the symbol as a backspace\". Intuitively, we will alwayscompute the message that is the decoding of what the receiver saw so far, and if it is consistent with theinput we simply send the next bit of the input. If it is not consistent with input, we will send a backspace\"to indicate that the last symbol is incorrect. We will do so iteratively. For a sequence y = (y1, . . . , yn) , we recursively define decode(y) to be decode(y[: (n 1)]) || (yn)if yn {0, 1}, and decode(y[: (n 1)])[: 1] if yn =, where v[: 1] means removing the last symbol fromthe vector v (unless its empty). As the base case, we have decode(()) = ().",
  "Given a message x and partial codeword y, we define the next symbol to be sent as next(x, y) =": "if suff(x, y) > 0, and as next(x, y) = x[last(x, y) + 1] otherwise. Our protocol is thus simple, if x is themessage and y is the codeword received by the receiver so far (which we know using the noiseless feedback),then the next symbol we send is next(x, y). Lemma 5.4. Let x be a message and y n be a partial codeword received by the receiver according tothe described protocol, and assume that at most n of the symbols in y were received differently than sent bythe protocol. Then, last(x, y) (1 2)n.",
  "Proof. For any partial received codeword y we define the potential function (x, y) := last(x, y)suff(x, y)": "We first show that if the next token is received correctly then the potential increases by one, thatis, (x, y || next(x, y)) = (x, y) + 1.We show this by considering two cases.If suff(x, y) = 0then decode(y) = x[: last(x, y)] and next(x, y) = x[last(x, y) + 1], thus decode(x, y || next(x, y)) =",
  "x[: last(x, y) + 1]. Otherwise, suff(x, y) > 0 and next(x, y) =, and hence suff(x, y || next(x, y)) =suff(x, y) 1": "Next, we show that if the next token is received incorrectly then the potential decreases by one, thatis (x, y || s) = max(0, (x, y) 1) whenever s = next(x, y). We again consider two cases. If suff(x, y) > 0then we have s {0, 1} and in turn suff(x, y || s) = suff(x, y) + 1. Otherwise suff(x, y) = 0 and we eitherhave suff(x, y || s) = 1 if s = or have last(x, y || s) = max(0, last(x, y) 1) if s =.",
  "Our Scheme": "As in the overview of , we begin by analysing a scheme in which only a single query is undetectable.Then, in .1 we apply the same idea of CGZ to go from undetectability for one query to completeundetectability. An intuitive explanation of our scheme is covered in . Algorithm 3: One-query steganography algorithm StegkData: A prompt (prompt), a payload (payload), and a secret key kResult: Response x1, . . . , xLi 1;code ();score 0 for {0, 1, };score_len 0;next next(payload, code);while done / (x1, . . . , xi1) do",
  "score score_lenscore_len> t": "When this happens, we view as the symbol received by the ECC receiver. While = next is supposedto be more likely, the symbol could be incorrect. Whenever we add a symbol to the code, we restart ourcomputation of the score and start transmitting the next code symbol. Algorithm 4 shows the retrievalprocess, which is identical to what is emulated within the steganography algorithm. Note that both algorithmshave a linear running time.",
  "Lemma 6.1. For any Model and any prompt, payload, t, the distribution of Stegk(prompt, payload)over a random choice of key k is indistinguishable from the distribution of Model(prompt)": "Proof. The proof is rather straightforward and follows CGZ and its overview in . If we replace eachtime Fk(i, next) is used (to determine xi) with a new uniformly chosen value in , then the distributionof Model is completely unaffected. Using a PRF instead of fresh\" random values is indisitinguishable aslong as we dont use the PRF on the same input more than once. As each input to the PRF consists of the(unique) index i, we never call it on the same input. We should next show that Retrk(Stegk(prompt, payload)) successfully retrieves payload. As discussed in.4, doing so requires making assumptions on the empirical entropy of the generated response. Weprove that a relatively weak assumption (which in particular covers the case of natural languages) is sufficient,",
  "bk ln(bk) if k = b": "2. Hence, natural language which has thisproperty (as discussed in .3.1) is O(1)-saturated. In fact, the entropy of natural language growslinearly with the length of the text, while our condition is merely for it to grow faster than the square root ofthe length of the text. We verify these claims empirically in . Finally, we prove that if the empirical entropy of a response is O(1)-saturated, and the response is of length L,then in expectation at least the first (L) bits of the payload are retrieved correctly. Theorem 6.3. Fix a model Model and an integer r0, there exists a choice of threshold t for which thefollowing holds. Let prompt, payload be strings. Conditioned on the empirical entropy of a response ygenerated by Stegk(prompt, payload) being r0-saturated, the expected length of the prefixes of payloadand Retrk(y) that identify is at least (len(y)/r0).",
  "We implemented1 Algorithms 3 and 4 from , that provide undetectability for a single query. We didso for simplicity and as we only aim to evaluate the new contributions of this paper": "In , we estimate the number of message bits we can hide in a response of a certain length. Foreach length of response, we ran our scheme for 100 times using the LLM model GPT-2 (RWC+19) on arandomly chosen prompt from the list of example prompts provided by OpenAI on their GPT-2 webpage.2 We ran it with threshold parameter t = 2, which we didnt optimize. As expected, it is evident that thenumber of hidden bits grows linearly with the length of the response. In , we detail the decodingprocess of the example shown in , generated using the 7B parameters Instruct version of the Llama 2model developed by Meta (TMS+23). We did not optimize for constants. The takeaways from this sectionare twofold; First, we show that the implementation of our scheme is simple and the run-time overhead isminimal; Second, we empirically support the claim from .3.1 that the empirical entropy in LLMsgrows linearly with the length of the response.",
  "Limitations and Open Problems": "The main issue we did not discuss so far is robustness to editing. That is, can the payload be recovered evenif the models response is somehow edited? We mainly leave dealing with robustness to future work, yet nextlist a couple of observations regarding robustness. In CGZ (CGZ23), the watermarking scheme is adapted torestart\" once-in-a-while so that the watermark will be detectable from any long enough consecutive substringof the response (and not only from the entire response). The same modification can easily be applied to",
  ": A breakdown of the decoding algorithm for the example in": "our scheme as well, making the payload retrievable from any long enough substring out of the modelsresponse. At the other end of the spectrum, it is known that under certain conditions powerful users canedit any watermark out of a models response (ZEF+23; CGZ23). Intuitively, a complete rephrasing of theresponse, for example, is supposed to remove any watermark. The previous empirical works on watermarksand steganography, that do not guarantee undetectability, showcase some robustness to certain types of edits. [AF21] Sahar Abdelnabi and Mario Fritz. Adversarial watermarking transformer: Towards tracing textprovenance with data hiding. In 2021 IEEE Symposium on Security and Privacy (SP), pages121140. IEEE, 2021.",
  "[DIRR09] Nenad Dedi, Gene Itkis, Leonid Reyzin, and Scott Russell. Upper and lower bounds onblack-box steganography. Journal of Cryptology, 22:365394, 2009": "[dWSK+22] Christian Schroeder de Witt, Samuel Sokota, J Zico Kolter, Jakob Foerster, and MartinStrohmeier. Perfectly secure steganography using minimum entropy coupling. arXiv preprintarXiv:2210.14889, 2022. [EGH15] Klim Efremenko, Ran Gelles, and Bernhard Haeupler. Maximal noise in interactive communica-tion over erasure channels and channels with feedback. In Proceedings of the 2015 Conferenceon Innovations in Theoretical Computer Science, pages 1120, 2015.",
  "AProof of Theorem 6.3": "We need to analyze two quantities. First, when Stegk adds a symbol to the code, what is the probability it isincorrect (i.e., different than the intended next symbol)?; Second, how many symbols do we manage to add tothe code? Or equivalently, how many response tokens do we usually see before adding a symbol to the code? To answer both questions, we analyze the evolution of the correct score (i.e., the one corresponding to thenext symbol) and incorrect scores from the time we start computing them and until one of them passes thethreshold. While computing the score with respect to an incorrect symbol, every tokens score is simply an exponentialrandom variable with mean 1. Denote by s1, s2, . . . the scores of each individual token (i.e., independent Exp(1)random variables), and by Si := ij=1 sj their accumulative sums. By Lemma 5 in CGZ we have that forany , > 0,",
  "For the score with respect to the correct symbol, the first b tokens contain at least 10": "b ln b empirical entropy,as b r0 and as we conditioned on our response being r0-saturated. In CGZ it is shown that S is stilldistributed as the sum of independent Exp(1) variables, but it is now additively shifted by the empiricalentropy of those variables. In particular, by Theorem 7 and Lemma 5 in CGZ, it follows that for any > 0we havePr[Sb < b + 10",
  "5t = b 4": "55 ln b =e(15 ln(5/4)) ln b < e(ln b)/10. II) The probability that the correct (normalized) score passed the threshold twithin the first b steps, which is at least the probability it was above the threshold at the end of the b-thstep, is at least 1 e/2 = 1 e25(ln b)2/2. By combining (I) and (II) we conclude that the probability thatthe correct score passed the threshold within the first b steps, yet the two incorrect scores did not, is at least",
  "Our revised algorithm partitions the generation of response tokens into three parts:": "1. We use real randomness to generate tokens and count the amount of empirical entropy used in theprocess, until enough (at least ) empirical entropy was seen, we call the prefix of tokens generatedin this step r. 2. We begin generating tokens using the PRF, with both r and the index as inputs. We dont yet submitcode symbols and wait until the score passes . We do this step to leave a signal to the detectorwith regards to what prefix r was chosen by the generation algorithm.",
  "Theorem B.1. Algorithm 5 is undetectable as defined in Definition 2.6": "Proof. This follows from Theorem 11 in CGZ, as the inputs to the PRF in the generation process are allunique within a single query, and all contain r which ever repeats within different queries only with negligibleprobability. Theorem 6.3 also remains correct as-is, besides that we lose\" O() empirical entropy to Parts 1 and 2.As long as L = () then, the same theorem statement still holds. While the running time of Stegk isunaffected, the running time of Retrk is now quadratic instead of linear. This can be avoided by truncatingthe verification of r, but we do not do so for the sake of simplicity."
}