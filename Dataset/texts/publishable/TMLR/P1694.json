{
  "Franka Bause1,2, Fabian Jogl3,4, Patrick Indri3, Tamara Drucks3, David Penz3,5,Nils M. Kriege1,6, Thomas Grtner3, Pascal Welke3, Maximilian Thiessen3": "1Faculty of Computer Science, University of Vienna, Vienna, Austria2UniVie Doctoral School Computer Science, University of Vienna, Vienna, Austria3Machine Learning Research Unit, TU Wien, Vienna, Austria4Center for Artificial Intelligence and Machine Learning, Vienna, Austria5Multimedia Mining and Search, Johannes Kepler University Linz, Linz, Austria6Research Network Data Science, University of Vienna, Vienna, Austria",
  "Abstract": "We propose a linear time graph transformation that enables the Weisfeiler-Leman (WL)algorithm and message passing graph neural networks (MPNNs) to be maximally expressiveon outerplanar graphs. Our approach is motivated by the fact that most pharmaceuticalmolecules correspond to outerplanar graphs. Existing research predominantly enhances theexpressivity of graph neural networks without specific graph families in mind. This oftenleads to methods that are impractical due to their computational complexity. In contrast,the restriction to outerplanar graphs enables us to encode the Hamiltonian cycle of eachbiconnected component in linear time. As the main contribution of the paper we prove thatour method achieves maximum expressivity on outerplanar graphs. Experiments confirmthat our graph transformation improves the predictive performance of MPNNs on molecularbenchmark datasets at negligible computational overhead.",
  "Introduction": "We study graph neural networks (GNNs) for the class of outerplanar graphs and devise a linear time pre-processing step that message passing graph neural networks (MPNNs) to distinguish all non-isomorphicouterplanar graph. Morris et al. (2019) and Xu et al. (2019) showed that MPNNs have limited expressivity,i.e., there exist non-isomorphic graphs on which each MPNN produces the same embedding. Such graphsexist even within the restricted class of outerplanar graphs (see ). This led to the developmentof GNNs that are more expressive than MPNNs, often called higher-order GNNs. However, the increasein expressivity usually comes with a significant increase in computational complexity.For example, k-GNNs (Morris et al., 2019) have a time complexity of (|V |k). Other higher-order GNNs count pattern graphssuch as cliques (Bodnar et al., 2021b), cycles (Bodnar et al., 2021a;b), and general subgraphs (Bouritsaset al., 2022), which can take time exponential in the pattern size. However, for certain domains of interest,the graph structure can be exploited to build efficient higher-order GNNs. In this work, we focus on thepharmaceutical domain and on graphs that represent molecules. Over 92% to 97% of the graphs in widelyused benchmark datasets in this domain are outerplanar (see ).The properties of outerplanargraphs have been exploited by algorithms for graph mining (Horvth et al., 2010) and molecular similaritycomputation (Schietgat et al., 2013; Droschinsky et al., 2017), but not yet for GNNs. We focus on this",
  ": The molecules bicyclopentyl (left) and decalin (right) which correspond to outerplanar graphs thatcannot be distinguished by MPNNs and 1-WL": "class of graphs and devise a linear time transformation that allows MPNNs to become maximally expressiveon outerplanar graphs.This implies that, in principle, our architecture can solve any learning task onouterplanar graphs. While this does not mean that any given maximally expressive model will perform wellin practice, our experiments show that our proposed transformation improves the predictive performance ofseveral GNN architectures on multiple benchmark learning tasks. We propose to decompose outerplanar graphs into biconnected outerplanar components and trees. Using thefact that each biconnected outerplanar component has a unique Hamiltonian cycle that can be computed inlinear time, we split each component into two graphs corresponding to the directed Hamiltonian cycles, andprove that MPNNs are maximally expressive on biconnected outerplanar graphs transformed in this way.Taking advantage of the well-known fact that MPNNs are maximally expressive on labeled trees (Arvindet al., 2015; Kiefer, 2020), we extend our result to a linear time graph transformation called Cyclic AdjacencyTransform (CAT) that works on all outerplanar graphs. We benchmark CAT with common MPNNs on avariety of molecular graph benchmarks and show that CAT consistently boosts the performance of MPNNs. Main contributions.We propose CAT, a linear time graph transformation that renders MPNNs max-imally expressive on outerplanar graphs. Experimentally, CAT consistently improves the performance ofMPNNs with little increase in runtime.",
  "Discussion and Related Work": "Since the expressivity of MPNNs is bounded by the 1-WL algorithm (Morris et al., 2019; Xu et al., 2019), anypair of non-isomorphic graphs that cannot be distinguished by 1-WL will get mapped to the same embeddingby any given MPNN. One such pair of graphs are the molecules decalin and bicyclopentyl (see ). Asthese two graphs are outerplanar, it follows that MPNNs are not sufficiently expressive for outerplanargraphs. Furthermore, in the graph mining community it is well known that many pharmaceutical moleculesare outerplanar (Horvth et al., 2006; Horvth & Ramon, 2010). Outerplanarity has also been discussed inthe context of reconstruction with GNNs (Cotta et al., 2021). This motivates the need for GNNs that arehighly expressive on outerplanar graphs. Outerplanar graphs have treewidth at most two (Bodlaender, 1998),and Kiefer (2020) showed that 3-WL is sufficiently expressive to distinguish all outerplanar graphs. Hence,any GNN that matches the expressivity of 3-WL, such as 3-IGN (Maron et al., 2019) or 3-GNN (Morriset al., 2019), is capable of solving our main goal of distinguishing all outerplanar graphs. However, a singleiteration of a naive implementation of the 3-WL algorithm on a graph with n vertices is at least O(n3)(Immerman & Lander, 1990; Kiefer, 2020), which can be infeasible even for medium-sized real-world graphs.Similarly, a single 3-GNN or 3-IGN layer runs in roughly O(n3) time (Maron et al., 2019; Morris et al.,2019). Even when additionally restricting the graph class to biconnected outerplanar graphs, MPNNs arenot sufficiently expressive. Furthermore, Zhang et al. (2023b) have shown that most GNNs cannot evendetect simple properties associated with biconnectivity such as articulation vertices. They find that onlytheir distance-based GNN and specific GNNs based on subgraphs (Bevilacqua et al., 2021; Frasca et al.,2022) are able to detect some of these properties. Again, these approaches have at least quadratic worst caseruntime. It is not straightforward to use outerplanarity to efficiently improve the expressivity of GNNs, as even findinga subgraph remains NP-hard for outerplanar graphs (Syso, 1982). Thus, methods like the graph structuralnetwork (Bouritsas et al., 2022) that rely on counting subgraphs remain computationally expensive even onouterplanar graphs. Subgraph GNNs model graphs as a collection of subgraphs (Frasca et al., 2022), whichusually requires a pre-processing with at least quadratic runtime, depending on the method used to extract",
  ": A graph and both directions of its directed Hamiltonian cycle. Nodes are annotated with theirHALs, the distances on the Hamiltonian cycle to their neighbors (Colbourn & Booth, 1981)": "subgraphs. For example, Node-delete (Bevilacqua et al., 2021) creates all subgraphs that are obtained bydeleting a single node creating O(n2) nodes in total. k-ego-net (Bevilacqua et al., 2021) extracts the k-hopneighborhood for each node which for k 2 can create O(n2) nodes in the worst case, for example for stargraphs, which are also outerplanar. Recently, Dimitrov et al. (2023) have proposed PlanE, a GNN architecture that can distinguish all planargraphs in O(n2) time. As a consequence, PlanE is also able to distinguish all outerplanar graphs. However,this comes at the cost of (1) runtime, (2) flexibility, andcounter-intuitively(3) expressivity. (1) PlanErequires a quadratic time pre-processing whereas our proposed CAT+MPNN runs in linear time. (2) PlanEis a GNN architecture while CAT is a graph transformation.This means, that CAT can be combinedwith any GNN while PlanE requires specialized GNN layers which are not easily combined with otherarchitectures. (3) Without changes to PlanEs pre-processing, PlanE is incapable of operating on graphswith non-planar components whereas CAT still achieves at least 1-WL expressivity on such graphs. Thisleads to the counter-intuitive result that vanilla PlanE is incomparable in expressivity to CAT (see Prop. 2and 3 in the Appendix). Finally, while there exist many GNNs that are provably more expressive than WL, little is known about theprecise class of graphs for which such GNNs are provably maximally expressive. Furthermore, proving anupper bound on the expressivity of an architecture is considered difficult and requires significant effort asdemonstrated by Zhang et al. (2023a). In contrast, we identify outerplanar graphs as a large practical graphfamily that our proposed method CAT can distinguish.",
  "Preliminaries": "A graph G = (V, E, , ) consists of a set of nodes V , a set of edges E V V and attributes (also calledfeatures) for the nodes : V X and edges : E X, respectively, where X is a set of arbitrary attributes.We refer to an edge from u to v by uv and in case of undirected graphs uv = vu. The in-neighbors of anode u V are denoted by Nin(u) = {v | vu E}. The out-neighbors of a node u V are denoted byNout(u) = {v | uv E} and in case of undirected graphs, Nin = Nout. In this paper, the input graphs areundirected and are transformed into directed ones. A graph G = (V , E, , ) is a subgraph of a graph G,denoted by G G, iff V V , E E, v V : (v) = (v), and e E : (e) = (e). A (directed)cycle (v1, . . . , vk) is a sequence of k 3 distinct nodes, with i {1, . . . , k 1} : vivi+1 E and vkv1 E.A graph is acyclic if it does not contain a cycle. Given a graph G, we denote the shortest path distancebetween two nodes u and v by dG(u, v), or d(u, v) if G is clear from the context. We denote the diameter ofa graph G by (G) = maxu,vV (G) d(u, v). A graph is outerplanar if it can be drawn in the plane without edge crossings and with all nodes belongingto the exterior face (see Appendix A for details). We call an undirected graph with at least three verticesbiconnected if the removal of any single node does not disconnect the graph. A biconnected component is amaximal biconnected subgraph. We refer to the outerplanar biconnected components of a graph as blocks. Two graphs G and H are isomorphic, if there exists a bijection : V (G) V (H), so that u, v V (G): (v) = ((v)) uv E(G) (u)(v) E(H) uv E(G): (uv) = ((u)(v)).Wecall an isomorphism between G and H. An in-tree T is a directed, acyclic graph with a distinct root",
  "having no outgoing edges and all other nodes having one outgoing edge and for every node there is exactlyone path from it to the root": "Weisfeiler-Leman.The 1-dimensional Weisfeiler-Leman algorithm (WL) assigns colors (usually rep-resented by numbers) to nodes.The color of a node v V (G) is updated iteratively according toci+1(v) = h (ci(v), {{((uv), ci(u)) | u Nin(v)}}), where h is an injective function and c0 = . Note, thatthis variant of WL makes use of edge features and works on directed graphs. While traditionally WL isdefined for undirected and unlabeled graphs, this is a common assumption in similar lines of work. The unfolding tree with height i of a node v V (G) is defined as the in-tree F vi = (v, {{F ui1 | u Nin(v)}}),where F v0 = ({v}, ). The unfolding trees F vi and F wiof two nodes v and w are isomorphic if and only ifthe colors of the nodes in iteration i are equal, see, e.g., Kriege (2022). The Weisfeiler-Leman algorithmhas historically been used as a heuristic for graph isomorphism. Let WL(G) = {{c(v) | v V (G)}} be themultiset of node colors in the stable coloring (Arvind et al., 2015). Two graphs G and H are not isomorphicif WL(G) = WL(H). However, non-isomorphic graphs G and H with WL(G) = WL(H) exist. WL forexample cannot distinguish the molecular graphs in or a 6-cycle from two triangles. Expressivity.Let G denote the set of all graphs and Gn = {G G | |V (G)| n} for all n N. Let, be two graph embedding algorithms, which map graphs to embedding spaces (e.g., Rd). We say is atleast as expressive as if for all pairs of graphs G, G with (G) = (G) it holds that (G) = (G). LetG G be a family of graphs, for example, the set of all outerplanar graphs. We say that a graph embeddingalgorithm is maximally expressive for G if for every non-isomorphic pair of graphs G, G G it holds that(G) = (G). We can generalize this to parameterized graph embeddings such as GNNs: Let w be a graphembedding with parameters w (e.g., the weights of a neural network). A parameterized graph embeddingw is maximally expressive for G if for all n N there exists a parameter choice wn such that for everynon-isomorphic pair of graphs G, G G Gn it holds that wn(G) = wn(G). Hamiltonian adjacency lists.A Hamiltonian cycle of a graph is a cycle containing each node exactlyonce. A Hamiltonian cycle (v1, . . . , vk) on an undirected graph, can be separated into two directed Hamilto-nian cycles C = (v1, . . . , vk) with corresponding edges v1v2, . . . , vkv1 and C = (vk, . . . , v1) with correspondingedges vkvk1, . . . , v1vk. Biconnected outerplanar graphs have a unique Hamiltonian cycle that can be foundin linear time (Mitchell, 1979). Hamiltonian adjacency lists (HALs) are derived by annotating each nodewith the sorted distances dC to all its neighbors on the two directed variants of the Hamiltonian cycle C. shows a graph annotated with its HALs in both directions of the Hamiltonian cycle. Followingthe Hamiltonian cycle in one direction and concatenating the HALs gives a HAL sequence S (and a reversesequence R, for the other direction). A sequence S of length n is a cyclic shift of another sequence S of length n if there exists an N such thatSi = Sj for all i {1, . . . , n} where j = i + mod n. The HAL sequence uniquely identifies a biconnectedouterplanar graph (if both directions and cyclic shifts are considered):",
  "Identifying Outerplanar Graphs Using Weisfeiler-Leman": "We develop a graph transformation called cyclic adjacency transform (CAT), that enables WL to distinguishall outerplanar graphs. We first introduce CAT, enabling WL to distinguish any pair of non-isomorphicbiconnected outerplanar graphs, and then extend it to all outerplanar graphs. In CAT (see .1), nodes are duplicated to represent the Hamiltonian cycle in both directions. Weannotate edges not in the Hamiltonian cycle with the distance their endpoints have on the Hamiltoniancycle. This allows the Weisfeiler-Leman algorithm to encode HAL sequences in the unfolding trees of thenodes and in turn distinguish pairs of non-isomorphic biconnected outerplanar graphs. To extend our transformation to all outerplanar graphs (see .2), we need to ensure that the bicon-nected components keep their unique encoding. It should also be ensured that non-isomorphic graphs withthe same biconnected components (but arranged or rotated differently) can be distinguished. We addressthis by introducing articulation and block pooling vertices. These nodes contain all the information abouttheir respective blocks and their position in these blocks. Together with nodes outside of blocks, this formsa forest which encodes the entire original graph. As it is known that WL is maximally expressive on forests,it follows that WL is maximally expressive on such graphs.",
  "Identifying Biconnected Outerplanar Graphs Using Weisfeiler-Leman": "We first present a graph transformation called CAT, that allows the Weisfeiler-Leman algorithm to distin-guish any two non-isomorphic biconnected outerplanar graphs. shows an example of CAT. Notethat CAT(G) consists of two disjoint copies of G, with directed and annotated edges. We first describe thetransformation informally for ease of understanding, followed by the formal definition. We start with an empty graph and add the (unique) Hamiltonian cycle of the original graph twice, directedin opposite ways (steps 1 and 2). Then, we add the remaining edges of the original graph to both cycles,directed in both directions each (step 3). Finally, we set node and edge features to the original features, andextend edge features with the distance of their endpoints in the Hamiltonian cycle (step 4).",
  "Theorem1.TwobiconnectedouterplanargraphsGandHareisomorphic,ifandonlyifWL(CAT(G)) = WL(CAT(H))": "Proof. Two graphs are distinguished by WL if and only if the multisets of node colors of their stable coloringsdiffer. Trivially, |V (G)| = |V (H)| |V (CAT(G))| = |V (CAT(H))| WL(CAT(G)) = WL(CAT(H)),so we only focus on graphs with |V (G)| = |V (H)|. Two nodes only get the same color if their unfolding treesare isomorphic. The first number in the HAL of each node is always 1, so it can be ignored, and the lastnumber is always |V (G)| 1, so this can simply be reconstructed by |V (CAT(G))|. The rest of the HALsequence and the node labels of G can be reconstructed from the unfolding tree of any node in CAT(G):Trivially, each node has two direct neighbors in the Hamiltonian cycle. In the unfolding tree these are theparent and the single child with the 1-annotated edge. All other neighbors in the HAL can be reconstructedby looking at the weights of the edges that do not have weight 1. shows an example. Lookingat any two biconnected outerplanar graphs with n nodes, the Weisfeiler-Leman algorithm will be able todistinguish them after at most n iterations, iff they are non-isomorphic: Since the HAL sequence is encodedin the unfolding trees from all starting points (cyclic shift) and in both directions (reverse direction), thisidentifies isomorphism by Lemma 1.",
  "Extending CAT to All Outerplanar Graphs": "While CAT is defined for single blocks (biconnected outerplanar components), an outerplanar graph cancontain multiple of them, as well as additional connections. We define the CAT transformation by applyingCAT to the blocks of the graphs and adding additional nodes and edges, which enable WL to distinguishany two non-isomorphic outerplanar graphs. We first give an informal description to provide an intuitionfor the various steps before stating the formal definition. Starting from an empty graph, add the graph induced by all edges not in blocks and nodes in more thanone block (steps 1 and 2). For each block, add the result of CAT applied to the block (step 3.1). Werefer to nodes created in this step as Hamiltonian cycle nodes.Add pooling nodes connecting the two Hamiltonian cycle nodes corresponding to the same original node (step 3.2). Add a node for each block(block nodes) and connect it to the pooling nodes of that block (step 3.3). Relabel the nodes from step 2,that belong to at least one block (articulation nodes) and connect them to the pooling nodes correspondingto the same original node (step 3.6). Finally, create a global (block) pooling node and connect it to theblock nodes (step 4). For each node we add, its initial features (if present) are extended by a label referringto the type (Hamiltonian cycle node, pooling node, articulation node, etc.).",
  "Definition 2. The CAT(G) = G transformation maps a graph G to a new graph G as follows:": "1. Let B1, . . . , B be the blocks of G and let F be the graph induced by the edges of G that are not inany block plus the nodes that are present in more than one block. Let {, , , , } be distinctnode labels not in X.",
  ". Let CAT(G) = G": "An example of the CAT transformation can be seen in . Appendix F contains additional visualizationsof the transformation on real-life molecular graphs. Informally, a graph is transformed using CAT by uniquelyencoding all its blocks (using CAT) and then connecting the results to encode also the position within thegraph and the orientation using the original graph structure. All nodes and edges that are not part of ablock are of course also added to the transformed graph.",
  "Dataset(G)(CAT(G))(G)(CAT(G))max(G)max(CAT(G))": "ZINC12.5 2.69.9 1.64.0 0.72.6 0.410.0 2.07.7 1.9MOLESOL6.6 3.36.9 3.82.3 1.02.1 0.95.5 2.36.0 2.8MOLTOXCAST8.5 4.78.4 4.03.0 1.52.6 1.37.2 4.37.4 3.9MOLTOX218.8 4.68.7 4.03.1 1.52.7 1.37.5 4.27.7 3.9MOLLIPO13.8 4.09.9 2.14.3 1.22.6 0.510.7 3.47.9 2.3MOLBACE15.1 3.211.5 2.85.0 1.32.9 0.712.5 3.49.1 2.6MOLSIDER12.6 11.810.4 7.34.1 3.82.9 2.210.4 11.08.9 6.8MOLBBBP10.7 3.79.1 2.63.4 1.12.4 0.68.3 3.87.5 2.5MOLHIV11.9 5.29.9 3.83.9 1.72.7 1.29.3 4.78.2 3.8 information about the entire HAL sequence of each block is stored in the block nodes b. The pooling nodes pconnect the block and block nodes to the rest of the graph (through the articulation nodes a), determiningthe orientation of the block.Note that the graph returned by CAT without the CAT blocks and the global pooling node g is a tree. Relying on the labels of the pooling and block nodes, we can reconstructthe original graph from this tree. As WL can distinguish non-isomorphic labeled trees (Arvind et al., 2015;Kiefer, 2020), it can thus distinguish non-isomorphic outerplanar graphs using CAT. For the other direction,note that CAT is permutation-invariant: for two isomorphic graphs G and H, the graphs CAT(G) andCAT(H) are isomorphic and WL will give the same coloring for both. Importantly, we can compute CAT(G) in linear time. The computational complexity is dominated by thecomputation of the blocks (Tarjan, 1972) and their Hamiltonian cycles (Mitchell, 1979), which both requirelinear time. Note that we only add a linear number of nodes and edges. From Morris et al. (2019) and Xuet al. (2019) it follows, that MPNNs, that are as expressive as 1-WL, can distinguish CAT(G) and CAT(H)for non-isomorphic outerplanar graphs G and H. Note that our proof used an important property of the WL algorithm: Adding uniquely labeled nodes andedges to WL-distinguishable graphs never leads to WL-indistinguishable graphs. We use this property toadd a global pooling node in step 4 of CAT which is connected to all block pooling nodes. This allows topass messages between block nodes in fewer iterations in the subsequent MPNN step. CAT can also be applied to non-outerplanar graphs. In this case, our graph transformation performs thesteps described in Definition 2. However, if a non-outerplanar biconnected component Bi is encountered,only one copy Bi is created in CAT(G) and its vertices are connected to the corresponding pooling nodes. Anexample for this is depicted in Appendix D. While this never reduces expressivity, it is also not guaranteedto improve expressivity on non-outerplanar graphs. Note that it can be determined in linear time whethera block is outerplanar while trying to compute the Hamiltonian cycle of the block (Mitchell, 1979). Hence,the CAT transformation always only requires linear time.",
  "Observation 1. For a block B of a graph G, it holds that (CAT(B)) 4": "Proof. Let u, v V (CAT(B)). By definition all nodes in CAT(B) are either from a Hamiltonian cycle createdby CAT, a pooling node, or a block node. If both nodes are from a Hamiltonian cycle, then there is a pathu, pu, b, pv, v between them, where pu, pv are pooling nodes and b is the block node. Hence, dCAT(G)(u, v) 4.If u or v is a pooling or a block node, then the above path implies that dCAT(G)(u, v) < 4.",
  "Observation 2. Let Bi and Bj be two blocks of a graph G. In CAT(G), the maximum distance betweenany node in CAT(Bi) and any node in CAT(Bj) is 6": "Proof. Let u V (CAT(Bi)) and v V (CAT(Bj)). If Bi = Bj, then Observation 1 implies dCAT(G)(u, v) 4.If Bi = Bj, then there exists a path u, pu, bi, g, bj, pv, v where pu, pv are pooling nodes, bi, bj are the blocknode for block Bi, Bj, and g is the global block pooling node. Thus, dCAT(G)(u, v) 6.",
  "Proof sketch. To prove the proposition we bound the distance between any pair of nodes in CAT(G) by caseanalysis based on the type of nodes. We defer the full proof to Appendix B": "In most practical cases, the short-cutting inside or between blocks leads to CAT reducing the graph diame-ter (see Observations 1 and 2). In , we demonstrate this on molecular benchmark datasets. Besidesthe diameter, another useful graph connectivity measure is the effective resistance. The notion of effec-tive resistance originates in electrical engineering (Kirchhoff, 1847) and has implications on several graphproperties. For example, the effective resistance between two nodes is proportional to the commute timebetween them (Chandra et al., 1989). Intuitively, a large effective resistance between two nodes suggeststhat information propagation between the nodes is hindered. Recently, effective resistance has been in factlinked to over-squashing (Black et al., 2023) in GNNs, which is a negative effect that leads to long-rangeinteractions having little impact on the predictions of a GNN. Effective resistance as introduced by Kirchhoff(1847) is naturally only defined for undirected graphs. As CAT produces directed graphs, we therefore usean extension of effective resistance introduced by Young et al. (2015) that is applicable to directed graphs.We refer to Young et al. (2015) for more details. In we demonstrate that CAT reduces the pair-wiseeffective resistance on molecular benchmark datasets.",
  "Experimental Evaluation": "We investigate whether our proposed method CAT can improve the predictive performance of MPNNs onmolecular benchmark datasets.1 We utilize three commonly used MPNNs: GIN (Xu et al., 2019), GCN (Kipf& Welling, 2017), and GAT-v2 (Velikovi et al., 2018; Brody et al., 2022). We train on the commonly usedZINC (Gmez-Bombarelli et al., 2018; Sterling & Irwin, 2015) and MOLHIV (Hu et al., 2020) datasets, whichcontain graphs representing molecules. We supplement these with 7 small datasets (see ) from theOGB collection (Hu et al., 2020). In addition to the ZINC dataset with 12k graphs we also use the largerZINC250k variant with 250k graphs. In total, we train three MPNNs on ten datasets with and without CAT.For each configuration, we separately tune hyperparameters on the validation set and train a model withthe best hyperparameters ten times on the training set and evaluate it on the test set. The only exceptionto this is ZINC250k where we evaluate the final hyperparameter configuration five times, due to the largedataset size. For each dataset we report the mean and standard deviation of the most common evaluationmetric on the test set in the epoch with the best validation performance. For ZINC we use a batch size of 128and an initial learning rate of 103 that gets halved if the validation metric does not improve for 20 epochs.The training stops after 500 epochs or if the learning rate dips below 105. For all other datasets we trainwith a fixed learning rate for 100 epochs and a batch size of 128. We use the same hyperparameter grid forall models and provide more details in Appendix E. Besides measuring the predictive performance, we alsomeasure the time needed for applying CAT (averaged over ten runs), and the training and evaluation timefor GIN and GIN+CAT with the same hyperparameters on all datasets (averaged over five runs). Finally,we report the values for the diameters and effective resistances as described in .3. Results. shows the pre-processing time of CAT. Note that this is the performance of runningCAT on only a single CPU core. It is possible to achieve faster runtimes by simply parallelizing differentgraphs over different cores.This negligible runtime allows applying the transformation even in realistichigh-throughput screening applications (Krasoulis et al., 2022), for example, on MOLHIV it takes only 5msto process a graph. Training and prediction time on CAT transformed graphs increases by 29% on average. shows the predictive performance of all models. Note that our baseline models obtain strong results,often surpassing the performance of (higher-order) GNNs reported in the literature, and that we train eachMPNN and MPNN+CAT with exactly the same sets of hyperparameters.Overall, CAT improves thepredictive performance of GIN and GCN in the majority of datasets (6 / 10 and 8 / 10, respectively). ForGIN and GCN, performance increases reliably on all datasets, except MOLLIPO and MOLTOX21. Surprisingly,CAT does not work well with GAT and only improves its performance in 2 / 10 datasets. Most notably onZINC, CAT achieves very strong results boosting the predictive performance of MPNNs between 33% (GCN)and 46% (GAT). This is only surpassed by higher-order GNNs such as CW Networks (Bodnar et al., 2021a)which obtain a MAE of 0.079 0.006 at the cost of potentially exponential pre-processing runtime due toenumerating cycles in the graph. shows that CAT reduces both graph diameter and maximum pair-wise resistance on most datasets. Furthermore, CAT reduces the average pair-wise resistance in all datasets.This suggests that CAT is effective at improving graph connectivity in real-life molecular graphs.",
  "Conclusion": "We proposed Cyclic Adjacency Transform (CAT), a linear time graph transformation, that enables theWeisfeiler-Leman algorithm to be maximally expressive on outerplanar graphs. We rely on the fact thatbiconnected outerplanar graphs can be uniquely identified by their Hamiltonian adjacency list sequences,which CAT encodes in unfolding trees. It follows that a combination of MPNNs and CAT can distinguishall outerplanar graphs. We achieved promising empirical results on standard molecular benchmark datasetswhere CAT improved the performance of GIN and GCN in most cases, while for GAT we could not observethis benefit.Computing CAT takes linear time and our implementation of CAT typically runs in theorder of seconds. Motivated by the recent interest in the over-squashing phenomenon, we also studied theeffect of CAT on graph connectivity.We proved that in the worst-case CAT increases the diameter ofouterplanar graphs by a small additive constant. However, inspecting CAT on real-world data, we find that",
  "Published in Transactions on Machine Learning Research (12/2024)": "for MOLHIV. For ZINC (10k graphs) and ZINC250k (250k graphs) (Gmez-Bombarelli et al., 2018; Sterling &Irwin, 2015) the task is to predict the constrained solubility which is a regression task. All other datasetsare from the Open Graph Benchmark (Hu et al., 2020) based on MoleculeNet (Wu et al., 2018) and the taskis always to predict some molecular property. On MOLHIV, the task is to predict whether a molecule inhibitsHIV virus replication or not (Hu et al., 2020). For the tasks of the other datasets, we refer to Wu et al.(2018).",
  "Cristian Bodnar, Fabrizio Frasca, Nina Otter, Yu Guang Wang, Pietro Li, Guido Montfar, and MichaelBronstein. Weisfeiler and Lehman go cellular: CW networks. In NeurIPS, 2021a": "Cristian Bodnar, Fabrizio Frasca, Yu Guang Wang, Nina Otter, Guido Montufar, Pietro Lio, and MichaelBronstein. Weisfeiler and Lehman go topological: Message passing simplicial networks. In ICML, 2021b. Giorgos Bouritsas, Fabrizio Frasca, Stefanos Zafeiriou, and Michael M Bronstein. Improving graph neuralnetwork expressivity via subgraph isomorphism counting. Transactions on Pattern Analysis and MachineIntelligence, 45(1):657668, 2022.",
  "Sandra L. Mitchell. Linear algorithms to recognize outerplanar and maximal outerplanar graphs. InformationProcessing Letters, 9(5):229232, 1979": "Christopher Morris, Martin Ritzert, Matthias Fey, William L Hamilton, Jan Eric Lenssen, Gaurav Rattan,and Martin Grohe. Weisfeiler and Leman go neural: Higher-order graph neural networks. In AAAI, 2019. Christopher Morris, Fabrizio Frasca, Nadav Dym, Haggai Maron, Ismail Ilkan Ceylan, Ron Levie, DerekLim, Michael M Bronstein, Martin Grohe, and Stefanie Jegelka. Position: Future directions in the theoryof graph machine learning. In ICML, 2024.",
  "AOuterplanar Graphs": "Let G = (V, E) be an undirected graph. A planar embedding of G consists of an injective mapping f ofnodes V to vectors in the plane R2 and for each pair of adjacent nodes u, v a continuous path between f(u)and f(v) such that no pair of such paths cross. More formally, a continuous path from f(u) to f(v) is acontinuous function p : R2 such that p(0) = f(u) and p(1) = f(v). Two such continuous paths p, p cross if there exist t, t (0, 1) such that p(t) = p(t). The graph G is planar if it has a planar embedding.By Frys theorem each planar graph always has a planar embedding with straight line segments as paths(Fry, 1948). Intuitively a planar embedding dissects the plane into regions called faces. Formally these arethe (topologically) connected regions of R2 with all the edge paths p removed. Any planar embedding hasa unique face not bounded by paths (the only non-compact face), which is called the outer face. A graphis outerplanar if it has a planar embedding with all nodes lying on the boundary of the outer face. See, forexample, Felsner (2012) for more details. We can also characterize outerplanar graphs using forbidden graph minors. A graph H is a minor of G, ifH can be obtained from G by a series of node deletion, edge deletion, and edge contractions (i.e., removingan edge and replacing the two endpoints by a new node). Let Ka,b be the complete bipartite graph withbi-partition A B = V with a = |A| and b = |B| and Kc be the complete graph on c nodes. A graphG is outerplanar if and only if G has no K2,3 minor and no K4 minor. Similarly, planar graphs can becharacterized by the Kuratowski theorem as graphs with no K3,3 and no K5 minor. For more details see,for example Diestel (2024).",
  "We prove Proposition 1 which states that (CAT(G)) (G) + 7 for every outerplanar graph G": "Proof. Let u, v V (CAT(G)) such that dCAT(G)(u, v) = (CAT(G)). We call a node a tree node if it wasnot part of a block in G and was not created by CAT. A node that is not a tree node is either a Hamiltoniancycle node, a pooling node, a block pooling node, or a global block pooling node.",
  "Case 1: Both u, v are not tree nodes. By Observation 2: dCAT(G)(u, v) 6": "Case 2: Node u is a tree node and v is not. Let a V (G) be the closest articulation node to u in CAT(G).Then, there is a path of length dG(u, a) in CAT(G) from u to a. We can extend this path by one node toreach a pooling node. By Definition 2, there exists a path of length at most 6 from this pooling node to v.Thus dCAT(G)(u, v) dG(u, a) + 7 (G) + 7.",
  "Case 3a: Suppose that the shortest path between u and v in G does not contain any edge inside of anouterplanar block, then dCAT(G)(u, v) = dG(u, v) (G)": "Case 3b: Suppose that the shortest path between u and v in G contains one or more edges inside exactlyone block. Then, we can enter and exit this block in CAT(G) through a path a1, p1, b, p2, a2, where a1, a2are articulation nodes, p1, p2 are pooling nodes, and b is a block node. Note that the articulation nodes werepart of the path in G which implies dCAT(G)(u, v) = dG(u, a1) + dG(a2, v) + 4 = dG(u, v) dG(a1, a2) + 4.Furthermore, we do not need to take the one or more edges inside the block to go from a1 to a2. UsingdG(a1, a2) 1 we obtain dCAT(G)(u, v) = dG(u, v) dG(a1, a2) + 4 dG(u, v) + 3 (G) + 3. Case 3c: Suppose that the shortest path between u and v in G contains two or more edges that arecontained in two or more different blocks. Then, for CAT(G) we can shortcut from the first to the lastblock node of the shortest path between u and v through a path a1, p1, b1, g, b2, p2, a2, where a1, a2 arearticulation nodes, p1, p2 are pooling nodes, b1, b2 are block nodes, and g is the global block pooling node.Note that the articulation nodes were part of the path in G which implies that dCAT(G)(u, v) = dG(u, a1) +dG(a2, v) + 6 = dG(u, v) dG(a1, a2) + 6.By assumption, we know that dG(a1, a2) 2 which impliesdCAT(G)(u, v) = dG(u, v) dG(a1, a2) + 6 dG(u, v) + 4 (G) + 4.",
  "CAdditional Examples for CAT": "Here, we provide additional examples for CAT. shows two graphs and the results, when transformedusing CAT. As described in Definition 1, the original graph is copied twice and the edges of the Hamiltoniancycle are directed in each direction once (with their label extended with 1). The remaining edges are addedto each copy directed in both directions, with their label being extended to describe the distance of theirtwo nodes when only using edges from the Hamiltonian cycle.",
  "EDetails for Experimental Evaluation": "Our models are implemented in PyTorch-Geometric (Fey & Lenssen, 2019) and trained on a single NVIDIAGeForce RTX 3080 GPU. We use WandB (Biewald, 2020) for tracking.The used server has 64 GB ofRAM and an 11th Gen Intel(R) Core(TM) i9-11900KF CPU running at 3.50GHz. shows thehyperparameters of our MPNNs for different datasets. We use the same hyperparameter grid for MPNNscombined with CAT. We used a smaller hyperparameter grid for MOLHIV as MOLHIV is larger than the most ofthe other datasets, meaning that training takes much longer. When benchmarking the speed of GIN againstGIN+CAT we train for 100 epochs with a batch size of 128 on all datasets with the same hyperparametersfor both models (see ). CAT implementation.CAT adds an additional feature to each node which encodes the type of thatnode, i.e., nodes from Hamiltonian cycles, block nodes, pooling nodes, articulation nodes and or global blocknodes. Furthermore, we create additional edge features encoding the types of nodes incident to this edgei.e., an edge between two different nodes in a Hamiltonian cycle has a different type than an edge from apooling node to the block node. For newly created nodes and edges we set their remaining features to thefeature of the node / edge they are based on; for example, a pooling node will have the features of the nodethey are performing the pooling operation for. For nodes that have no natural representation in the graph(block and block pooling nodes) we set these features to 0. To ensure that only these nodes get assigned0 features, we shift the values of these features for all other nodes by 1.2 Note that our MPNNs treat thedistance on edges in blocks as a categorical feature. Representing the distances as numerical features didnot improve performance in preliminary experiments.",
  "FAdditional Figures": "We provide additional visualizations of the CAT transformation. In all figures, the color of the verticesin the transformed graph have the following meaning: red nodes are from Hamiltonian cycles, blue nodescorrespond to blocks, yellow nodes pool the nodes from Hamiltonian cycles, orange nodes correspond toarticulation nodes and the gray node pools block nodes. shows a synthetic example with a non-outerplanar graph. demonstrates CAT on various synthetic graphs. shows the result ofCAT on molecular graphs from ZINC and MOLHIV. Somewhat ironically, CAT often generates frog graphs onMOLHIV as can be seen in ."
}