{
  "Abstract": "Federated Learning (FL) is a distributed learning paradigm where multiple clients eachhaving access to a local dataset collaborate to solve a joint problem. Federated Averaging(FedAvg) the algorithm of choice has been widely explored in the classical server settingwhere the server coordinates the information sharing among clients. However, the perfor-mance of FedAvg in the decentralized setting where only the neighboring clients communicatewith each other depending on the network topology is not well understood, especially in theinterpolation regime, a common phenomenon observed in modern overparameterized neu-ral networks. In this work, we address this challenge and perform a thorough theoreticalperformance analysis of FedAvg in the interpolation regime under decentralized setting. Weconsider a class of non-convex functions satisfying the Polyak-ojasiewicz (PL) inequality,a condition satisfied by overparameterized neural networks. For the first time, we establishthat Decentralized FedAvg achieves linear convergence rates of O(T 2 log(1/)), where is thesolution accuracy, and T is the number of local updates at each client. We also extend ouranalysis to the classical Server FedAvg and establish a convergence rate of O(log(1/)) whichsignificantly improves upon the best-known rates for the simpler strongly-convex setting. Incontrast to the standard FedAvg analyses, our work does not require bounded heterogeneityand gradient assumptions. Instead, we show that sample-wise (and local) smoothness of thelocal objectives suffice to capture the effect of heterogeneity. Experiments on multiple realdatasets corroborate our theoretical findings.",
  "Introduction": "In the age of Bigdata, Federated Learning (FL) provides machine learning (ML) practitioners with anindispensable tool for solving large-scale learning problems. FL is a distributed machine learning scenariothat allows the edge devices to learn a shared model while maintaining the training data at the edge devices(Konen`y et al., 2016; McMahan et al., 2017). This avoids the need to share the data with a central serverand preserves the privacy of individual clients (edge devices). Assuming a supervised learning setting, whereeach of the N distinct clients have access to some local data (x, y) Dk from distribution Dk for k [N]",
  "k=1k(w),": "where k(w) := E(x,y)Dklk(fw(x), y) is the expected loss at client k [N] for the input feature x X, andthe corresponding label y Y. Here, fw(x) is the models output with parameters w Rd. In this work,we focus on solving the FL Problem in the interpolation regime (cf. Assumption 1), an assumption usuallysatisfied by overparameterized models (Bassily et al., 2018). The de-facto standard for solving the above FL Problem is the simple Federated Averaging (FedAvg) algo-rithm (McMahan et al., 2017). In recent years, many works have attempted to characterize the convergenceof FedAvg under different settings (Stich, 2018; Li et al., 2019a; Woodworth et al., 2020a; Ma et al., 2018; Yuet al., 2019b). For example, the authors in Stich (2018) show a convergence rate of O (1/N) for minimizingstrongly convex functions while Haddadpour & Mahdavi (2019) establishes similar rates for minimizing func-tions satisfying Polyak-Lojasiewicz (PL) condition. For minimizing non-convex smooth functions, FedAvgachieves a convergence rate of O(1/N2) (Karimireddy et al., 2020; Woodworth et al., 2020b), where, refersto the desired solution accuracy. Note that the majority of studies have focused on FedAvg in the classical server-based setting (referred toas Server FedAvg), where a central server aggregates information. In this approach, clients compute modelupdates and send them to the server, potentially leading to communication bottlenecks and delays. More-over, an attack on the server could compromise the privacy of the aggregated model. Additionally, in manypractical learning scenarios, access to a central server may not be feasible. For such cases, the alternative isDecentralized FedAvg. In this decentralized setting, global aggregation is replaced by local aggregation, whereeach client updates its model based on connections with neighboring clients. While the Decentralized FedAvgalgorithm has been examined in earlier works (Koloskova et al., 2019; Li et al., 2019b), its linear (fast) conver-gence has only been established for the strongly convex setting in the interpolation regime (cf. Assumption 1).",
  ": log-training loss vs communication rounds for overparameterizedDeep Neural Networks (DNNs) and a simple regression model": "In practice, it has been observed thateven for non-convex settings Decentral-ized FedAvg converges at a much fasterrate compared to the rates demonstratedin these works. To illustrate this fact, in we plot the behavior of the train-ing loss (on a log scale) as a functionof communication rounds for Decentral-ized FedAvg to solve a classification taskon MNIST data set utilizing overparam-terized models, i.e., in the interpolationregime (for experimental details pleasesee ). It is clear from the plotthat in the interpolation regime the loss decreases linearly as a function of communication rounds. This sug-gests that the standard analyses of Decentralized FedAvg lack a theoretical foundation to explain its linearconvergence. In this work, we attempt to fill these gaps and perform a thorough theoretical analysis of DecentralizedFedAvg in the interpolation regime where the local nodes communicate over an undirected graph. Underthis setting, we establish the linear convergence of FedAvg for minimizing a class of non-convex functionssatisfying the PL inequality.We also extend our analysis to the classical Server FedAvg and establishimproved guarantees compared to the state-of-the-art.We note that PL inequality plays a key role inthe training of overparameterized systems. Specifically, many works have shown that the loss function ofan overparameterized neural network satisfies the PL inequality (Bassily et al., 2018; Liu et al., 2020).Furthermore, our analysis reveals that the standard but restrictive assumptions of bounded gradients (Yuet al., 2019b; Stich, 2018; Li et al., 2019a; Koloskova et al., 2020), heterogeneity (Yu et al., 2019a; Woodworthet al., 2020b; Yu et al., 2019a; Wang et al., 2021; Sery et al., 2021), and variance (Woodworth et al., 2020b;Qu et al., 2020) can be avoided while guaranteeing this linear convergence of Decentralized FedAvg.",
  "rounds of communication. We also characterize the effect of the network topology on the performance ofDecentralized FedAvg": "2. For the classical Server FedAvg also we establish linear convergence rates of R O (log (1/)). Comparedto the best-known result in Koloskova et al. (2020) where a simpler strongly-convex problem is considered(see section C for details), we get improved rates independent of the number of local updates T (cf. and .1 for a comparison). 3. Our theoretical results do not require assumptions on the boundedness of heterogeneity, gradients, andstochastic variance. We show that sample-wise smoothness of the stochastic loss functions suffices tocapture the effect of data heterogeneity among different clients while avoiding the need to impose therestrictive bounded gradient and variance assumptions. 4. Finally, we present experimental results on various data sets such as CIFAR-10, Shakespeare, MNIST,and FMNIST, and corroborate our theoretical findings under the decentralized settings. Through ourexperiments, we show that an optimal number of local updates Tth exists and increasing T beyond Tthhurts the performance of FedAvg in both server and decentralized settings.",
  "Related Work": "After the introduction of the FedAvg (McMahan et al., 2017), multiple works have analyzed the convergenceof FedAvg in the server setting with homogeneous data, i.e., when the data is i.i.d across clients (see (Stich,2018; Wang & Joshi, 2018; Khaled et al., 2019; Yu et al., 2019b; Wang et al., 2019; Yang et al., 2021)). Theauthors in (Stich, 2018) were the first to obtain a rate of O(1/N) for strongly convex and smooth problemsfor achieving an -accurate solution (cf.Definition 2).Later (Haddadpour et al., 2019; Haddadpour &Mahdavi, 2019) proved a similar result but for non-convex functions satisfying PL inequality. The analysisof FedAvg for the general non-convex settings was first performed in (Yu et al., 2019b) where the authorsestablish a rate of O(1/N2) to reach an -stationary point where the stationarity is measured with respectto the gradient norm of the loss funciton. There are a few works that have analyzed the performance of Fedvg in decentralized settings as well. Oneof the initial works, (Lian et al., 2017) considered a decentralized parallel SGD (D-PSGD) and provided aconvergence rate of O(1/N2) to an -stationary point to minimize smooth non-convex functions. Later,",
  "Published in Transactions on Machine Learning Research (MM/YYYY)": "Anastasia Koloskova, Nicolas Loizou, Sadra Boreiri, Martin Jaggi, and Sebastian Stich. A unified theory ofdecentralized sgd with changing topology and local updates. In Int. Conf. on ML, pp. 53815393. PMLR,2020. Jakub Konen`y, H Brendan McMahan, Felix X Yu, Peter Richtrik, Ananda Theertha Suresh, andDave Bacon.Federated learning: Strategies for improving communication efficiency.arXiv preprintarXiv:1610.05492, 2016.",
  "The Decentralized FedAvg Algorithm": "In many practical settings, the central server is absent, and the clients are required to communicate andupdate the model weights in a decentralized manner while communicating with only the neighboring nodes.In this work, we consider such a setting and study Decentralized FedAvg, an extension of FedAvg to thedecentralized setting. The decentralized setting consists of N distributed edge devices which are representedusing a connectivity graph G (V, E). Here, V [N] is the vertex set or clients, and E {V V} representsthe edges of the graph. Any edge (i, j) E represents a connection between node i and j. Further, theconnections are represented using mixing matrix P = [pi,k] RNN, where pi,k = 0 if there is no edgebetween node i and k i.e., (i, k) / E, else pk,i > 0. Unlike many existing works on decentralized settings(Lian et al., 2017), here we consider a general framework where each client performs T rounds of localupdates. Decentralized FedAvg is presented in Algorithm 1 while in the following, we provide an outline:",
  ". Initialization: Each client k [N] initializes the model parameters denoted by w0k. See Step 1 ofAlgorithm 1": "2. Local updates: Each client performs T steps of SGD starting from the model parameters obtained bythe aggregation of the updates from neighbouring clients. Towards computing the stochastic gradient,each client k [N] uniformly randomly samples a batch of data of size b denoted by Br,tk , and thencomputes the gradient. The resulting model parameters after T local rounds in the r-th global roundare denoted by wr,Tkwhich is sent to all the neighbouring clients of k. See Steps 6 and 7 of Algorithm 1.Note that this procedure is similar to the local update step in the FedAvg case. 3. Aggregation: In the r-th global communication round, each client k [N] computes a local average ofthe model parameters received by its neighbors. The aggregate model is denoted by wrk. The steps (2)and (3) above are repeated for R rounds. See Steps 11, 12 of Algorithm 1.",
  "Assumption 1. (Interpolation): We say that the model parameters is operating in the interpolation regimeif there exists a w Rd such that the per sample loss k,j (w) = 0 for all samples j [b]": "Assumption 2. (PL inequality): The joint objective (v) satisfies the PL inequality, i.e., (v)2 (v) for some > 0 and for all v Rd. Further, the local loss functions k (v) for all k = 1, 2, . . . , N arealso assumed to satisfy the PL inequality, henceforth referred to as local PL inequality, i.e., k (v)2 kk (v) for some k > 0 and for all v Rd. Assumption 3. (Sample-wise, Local and Global smoothness): The functions k,j() for all j [b], k [N]are assumed to be lk,j-smooth. The local functions k() for all k [N] are assumed to be Lk-smooth. Theabove assumptions imply k,j (v)2 2lk,jk,j (v) and k (v)2 2Lkk (v) for all k [N] andj [b]. We also assume the global loss () to be L-smooth. Assumption 4. (Unbiasedness): We assume that the stochastic samples of the gradient and the loss functionat each client k [N] are unbiased, i.e., E [k,j (w)] = k (w) and E [k,j (w)] = k (w) for any j [b]and w Rd. Most of the above assumptions, including interpolation, PL inequality, and smoothness are standard as-sumptions made in various works in the past (Bassily et al., 2018; Karimi et al., 2016; Ma et al., 2018;",
  ": end for": "Nguyen & Mondelli, 2020). For example, the authors in (Bassily et al., 2018; Liu et al., 2022a; Karimi et al.,2016; Haddadpour et al., 2019) assume PL inequality along with sample-wise smoothness to prove linearconvergence of FedAvg in the interpolation regime. It is also important to note that the overparameterizedsystems satisfy PL inequality (Liu et al., 2020; Nguyen & Mondelli, 2020; Nguyen et al., 2021; Allen-Zhuet al., 2019; Liu et al., 2022a), and hence plays a crucial role in the analysis of overparameterized systems(Liu et al., 2022a). Moreover, we note that the assumption of sample-wise smoothness is not very stringentsince any neural network with a smooth activation function satisfies this assumption.",
  "Convergence of Decentralized FedAvg": "In this section, we prove that the Decentralized FedAvg algorithm converges linearly to the global optimumfor any smooth non-convex function satisfying PL inequality in the interpolation regime. Compared to theclassical Server FedAvg analyses this problem poses several challenges. In particular, unlike Server FedAvgin the decentralized setting each client has access to only parameters from its neighbours. This implies thatfor Decentralized FedAvg we need to handle two drift terms, namely local drift and the global drift. Localdrift refers to the update at each client drifting away from the average obtained from the neighboring clientswhile the global drift refers to the average obtained from the neighboring clients drifting away from theglobal average. These two equations are coupled, and hence we use the Lyapunov based approach to showthat both drift as well as the loss go down linearly. In addition to the Assumptions 1-4, our analysis alsorelies on the following assumption on the mixing matrix (Koloskova et al., 2020).",
  "Proof: See Sec. B.2 in Appendix and Sec. 3.1 for a proof sketch": "Theorem 1 establishes linear convergence of FedAvg in the decentralized setting. A somewhat related workis Koloskova et al. (2020), where they consider a class of -strongly convex functions in the decentralizedsetting, and showed that a linear convergence rate of O(log( 1 )) can be achieved by the decentralized FedAvgalgorithm in the interpolation regime. Note that in a strongly convex setting, all clients share the uniqueminima x = 0 due to the interpolation assumption. In this case, clients do not need to communicate since",
  "above, and using the fact that E[wr+1+ Dr+1,0] E[wr+1] gives us the result in the corollary": "Corollary 1 shows that even in the decentralized setting, FedAvg can achieve linear convergence.Moreimportantly, the sum of the drift and the loss goes to zero linearly with R, as opposed to most of the existingwork (Sun et al., 2021). Observe from Theorem 1 and the corollary above that an -accurate solution can beachieved if the number of global communications rounds R scales as O(T 2). For the strongly convex settingsince the clients share a unique minima the impact of the local rounds T on the convergence performanceis less severe as shown in (Koloskova et al., 2020). Since the local clients share a unique minimum, whichallows the algorithm to converge at the same rate to the local optimal irrespective of the local updatesand communication protocol used. We believe that the slightly worse convergence of our analysis is dueto the non-convex functions satisfying the PL inequality. Importantly, as a special case of our analysis,for the classical FedAvg algorithm (with a server), we establish a convergence rate of O(log(1/)) which issignificantly better than that existing results (see ). Note that one can optimize the number oflocal rounds that lead to faster convergence. However, this optimization is cumbersome in the decentralizedsetting, and hence the convergence depends on T. Effect of Network Topology. The effect of decentralized clients is captured through the term involving2. In order to explain the dependency of 2 on convergence, consider the case of T = 1, i.e., FedSGD. Inthis case, if 2 = 0 but closer to 1, then the learning rate is dominated by the term (1 2)/constant. Thus,the learning rate is small in the decentralized setting (as opposed to 2 = 0). As a consequence, (1 /8)is closer to 1 leading to a slower convergence. In the extreme case of 2 = 1, i.e., fully disconnected graph, = 0, which leads to divergence, as expected. Later, we perform experiments to show the effect of networktopology on the convergence for different network settings.",
  "Proof Sketch of Theorem 1": "In contrast to the strongly convex setting of (Koloskova et al., 2020), our setting results in each clientsharing different optimal points. As a consequence, the execution of multiple local updates within eachcommunication round leads to the following drifts: (i) local drift: multiple local updates (see line 4 to line8 of Algorithm 1) differ from the average obtained by the neighboring clients, and (ii) global drift: thelocal average obtained by using updates from the neighboring clients differ from the global average, i.e.,the average obtained from all the clients. This implies that we need to control both global and local drifts.We handle this challenge by bounding the loss in terms of the drift term that captures both local andglobal drifts as mentioned in the Lemma below. We start by proving an upper bound on the average lossEwr+1in terms of the loss (wr) in the r-th communication round, and the drift Dr,0, as shown in",
  "Proof: See Sec. B.2": "It is easy to see from Lemma 1 that we can obtain the convergence result established in Theorem 1 providedthe drift term on the right hand side of equation 1 is bounded in terms of loss. Towards this, first, we boundthe drift term which depends on the average loss, leading to two coupled equations (see equation 1 andequation 2). We construct a single equation that is a linear combination of the two coupled equations andshow that the linear combination goes to zero exponentially, leading to linear convergence of both drift aswell as the loss function. In the following lemma, we provide a recursion of the drift in terms of the averageloss and the past drift.",
  "Proof: See Sec. B.3": "Next, our task is to show that the recursion in equation 1 and equation 2 satisfy a bound of the form (wr) + Dr,0 r (w0+ w0), for some > 0 and (0, 1), which is the desired result. Insummary, we prove the bounds on the loss (in terms of drift) in Lemma 1 and the drift (in terms of theloss) in Lemma 2. Note that proving the above bound involves carefully handling the drift due to multiplelocal rounds. Using the above results, we constructed a Lypunov function in terms of drift and loss for some > 0, and prove the following bound by appropriately choosing the learning rate and constants:",
  "Server Setting: FedAvg with Improved Rates": "In this section, we show that our analysis specialized to the server setting, i.e., 2 = 0 enables us to showthat there exists an optimal number of local rounds T that maximizes the rate of convergence. In particular,we provide a closed form solution to the optimum number of local rounds, and show that an improved rateof O(log(1/)) can be achieved as opposed to the existing work (Koloskova et al., 2020) where they show aconvergence rate of O(T log(T/)). Further, the same observation is made empirically in both server and",
  "It is evident from the above equations that the drift increases with T, as expected. However, a part ofthe expression in the average loss decreases with T (more specifically, the term1": "4T ) while the otherterms increase with T. In principle, one should be able to characterize the optimal T. However, the aboveis a complicated expression to optimize with respect to T. To get more insights into the effect of T, in thefollowing, we look at the server setting, which is a special case of our framework. The server setting consistsof the central server which coordinates the information sharing among participating clients. We obtain theserver setting by making the second largest eigenvalue of the mixing matrix, i.e., 2 = 0 in the decentralizedcase. Now using the fact that 2 = 0 in equation 4 and equation 5 lead to Dr,0 = 0 and",
  "rounds": "In the above analysis, we capture the effect of local updates on the performance of the decentralized FedAvg.Specifically, we show that there exists an optimal number of local updates T beyond which the convergence ofthe algorithm slows down and one needs to choose T carefully to achieve the optimal convergence guarantees.Again, this is the first result establishing linear convergence of FedAvg in the decentralized setting whenminimizing non-convex functions satisfying PL-inequality in the interpolation regime. In the next section,we present the experimental results.",
  ":Training loss versus the communicationrounds for FedAvg in the decentralized setting. Here,random doubly stochastic case has 5 clients while forothers we have used 60 clients": "We use 60 edge devices to run the Decentralized Fe-dAvg algorithm with multiple local SGD steps andthen broadcast the updated model with the nodesconnected to it. We consider the image classificationtasks on CIFAR-10, MNIST, and FMNIST datasetsusing an overparameterized simple regression andDeep Neural Network (DNN) models. We have im-plemented all our experiments on NVIDIA DGXA100. The experimental setup consists of the fol-lowing model and data set: Overparameterized regression.Here we con-sider a simple regression model with 3 linear lay-ers. There are 231490 trainable parameters with noactivation function. We evaluate the performanceof Decentralized FedAvg algorithm on the MNISTdataset for an image classification task.",
  ": Effect of T on the convergence of Decentralized FedAvg for simple regression and CNN model": "each device implements a convolutional neural network (CNN) model. We consider the CIFAR-10, MNISTand FMNIST datasets. In the overparameterized setting, each edge device implements a three hidden layerconvolutional neural network (CNN) with 256, 128, and 64 filters followed by three linear layers having1642849 trainable parameters for CIFAR-10 and two linear layers for MNIST and FMNIST with 1046426trainable parameters. On the contrary, the underparameterized setting considers a relatively smaller neuralnetwork. In this setting, each device implements two hidden layer CNN having 25 and 52 filters followed bytwo linear layers for CIFAR-10 and one linear layer for MNIST and FMNIST datasets. We set the numberof local updates T = 10 and pick the tunable learning rate in the range [0.001 : 0.01] for CIFAR-10,MNIST, and FMNIST datasets. We consider that each device has 490 training samples and 90 test samplesfor the CIFAR-10 dataset. On the other hand, for MNIST and FMNIST datasets, 540 samples are used fortraining and 80 samples are used for testing. In this setting, we run Algorithm 1 for the following networks (i) ring, (ii) random doubly stochastic, and (iii)torus topologies. For the Decentralized FedAvg, we compare (a) the performance of Decentralized FedAvgwith both underparametrized and overparameterized neural network models, (b) effect of topology on theconvergence, and (c) effect of local updates on the convergence. In the following, we provide a detailedexperimental results.",
  ": Optimality gap for Decentralized FedAvg algorithm with ring topology on MNIST dataset versuscommunication rounds. (see (a)) and Comparison of the DSGDm and Decentralized FedAvg. (see (b))": "1. Underparameterized versus overparametrized. shows the plots of training loss of FedAvgin the decentralized setting for underparameterized and overparameterized models on MNIST, FMNIST,CIFAR-10 datasets. As established in Theorem 1, the loss of FedAvg in the decentralized setting diminishesrapidly for the overparameterized models compared to the underparameterized models. This is due tothe fact that the PL inequality is satisfied for overparameterized systems which helps to reach the globaloptimum at a linear rate as demonstrated by Theorem 1. show plots for testing accuracy forFedAvg in the decentralized setting. As expected the convergence speed of underparameterized case isslower than the overparameterized case. 2. Effect of local updates T. shows plots of the training losses on MNIST dataset for the FedAvgunder the decentralized setting on the overparameterized regression model and the CNN. From equation 6,we see that as T increases, the convergence speed either decreases or increases depending on the coefficientof T 3 in the second term. We capture this phenomenon in . In particular, as T increases, the rate ofconvergence increases for simple regression model while it decreases/saturates for the CNN based DNNmodel. One plausible explanation is that the smoothness constants of simple regression is small, andhence results in smaller second term in equation 6. However, for CNN based DNN, the second termdominates, and hence results in slower convergence with T. 3. Effect of optimality gap. (a) shows the plot of the optimality gap, i.e., (wr) (w)versus R. Here w is an approximate optimal solution obtained by running a centralized algorithm for asufficient number of rounds. As expected the optimality gap decreases exponentially with R. 4. Comparison with the existing work. (b) shows the comparison of Decentralized StochasticGradient Descent with momentum (DSGDm) (Lin et al., 2021) with the Decentralized FedAvg algorithm.We show the training loss versus R for overparameterized CNN model using MNIST dataset in both thecases. We see DSGDm outperforms the Decentralized FedAvg algorithm as expected. 5. Comparison with different topologies in the decentralized case. shows the training lossversus the communication rounds R for overparameterized CNN model using MNIST dataset with T =10 for four different topologies.Since server topology has 2 = 0, it outperforms the network withring topology and a random (doubly) stochastic matrix. However, the torus topology does not satisfythe conditions required, i.e., symmetric and doubly stochastic matrix, and hence cannot be used forcorroborating our theoretical findings. Nevertheless, we have conducted experiments with torus topology,and shows that the torus has the worst convergence performance. One reason for this could be thatthe ring topology has more structure, i.e., it has a symmetric and doubly stochastic mixing matrix P as",
  "Conclusion": "In this work, we performed a theoretical analysis of the well known FedAvg algorithm for the class of smoothnon-convex overparameterized systems in the interpolation regime. We considered the decentralized settingwhere nodes communicate over an undirected graph. In this regime, it is well know that neural networks withnon-convex loss functions typically satisfy an inequality called Polyak-Lojasiewicz (PL) condition. AssumingPL condition, we showed that the FedAvg algorithm achieves linear convergence rate O(T 2 log(1/)), where is the desired solution accuracy, and T is the number of local SGD updates at each node. As opposedto the standard analysis of the FedAvg algorithm, we showed that our approach does not require boundedheterogeneity, variance, and gradient assumptions. We captured the heterogeneity in FL training throughsample-wise and local smoothness of loss functions. Finally, we carried out experiments on multiple real-world datasets to confirm our theoretical observations. Acknowledgements: This work is in part supported by SERB-CRG (grant number: CRG/2021/007502)and SERB-MATRICS (grant number: MTR/2021/000575). We thank the anonymous reviewers for theirhelpful comments which have improved the paper.",
  "Siyuan Ma, Raef Bassily, and Mikhail Belkin. The power of interpolation: Understanding the effectivenessof sgd in modern over-parametrized learning. In Int. Conf. on ML, pp. 33253334. PMLR, 2018": "Brendan McMahan,Eider Moore,Daniel Ramage,Seth Hampson,and Blaise Aguera y Arcas.Communication-efficient learning of deep networks from decentralized data. In Artificial intelligence andstats., pp. 12731282. PMLR, 2017. Giorgi Nadiradze, Amirmojtaba Sabour, Peter Davies, Shigang Li, and Dan Alistarh. Asynchronous decen-tralized sgd with quantized and local updates. Advances in Neural Information Processing Systems, 34:68296842, 2021.",
  "Zhaonan Qu, Kaixiang Lin, Jayant Kalagnanam, Zhaojian Li, Jiayu Zhou, and Zhengyuan Zhou. Federatedlearnings blessing: Fedavg has linear speedup. arXiv preprint arXiv:2007.05690, 2020": "Tomer Sery, Nir Shlezinger, Kobi Cohen, and Yonina C. Eldar. Over-the-air federated learning from heteroge-neous data. IEEE Transactions on Signal Processing, 69:37963811, 2021. doi: 10.1109/TSP.2021.3090323. Bingqing Song, Ioannis Tsaknakis, Chung-Yiu Yau, Hoi To Wai, and Mingyi Hong. Distributed optimizationfor overparameterized problems: Achieving optimal dimension independent communication complexity. InAdvances in Neural Information Processing Systems.",
  "Jianyu Wang and Gauri Joshi. Cooperative sgd: A unified framework for the design and analysis of local-update sgd algorithms. Journal of Machine Learning Research, 22(213):150, 2021. URL": "Jianyu Wang, Qinghua Liu, Hao Liang, Gauri Joshi, and H. Vincent Poor. A novel framework for the analysisand design of heterogeneous federated learning. IEEE Transactions on Signal Processing, 69:52345249,2021. doi: 10.1109/TSP.2021.3106104. Shiqiang Wang, Tiffany Tuor, Theodoros Salonidis, Kin K Leung, Christian Makaya, Ting He, and KevinChan. Adaptive federated learning in resource constrained edge computing systems. IEEE Journal onSelected Areas in Communications, 37(6):12051221, 2019. Blake Woodworth, Kumar Kshitij Patel, Sebastian Stich, Zhen Dai, Brian Bullins, Brendan Mcmahan, OhadShamir, and Nathan Srebro. Is local sgd better than minibatch sgd? In Int. Conf. on ML, pp. 1033410343.PMLR, 2020a.",
  "Hao Yu, Rong Jin, and Sen Yang. On the linear speedup analysis of communication efficient momentum sgdfor distributed non-convex optimization. In Int. Conf. on ML, pp. 71847193. PMLR, 2019a": "Hao Yu, Sen Yang, and Shenghuo Zhu. Parallel restarted sgd with faster convergence and less communication:Demystifying why model averaging works for deep learning. In Proceedings of the AAAI Conference onArtificial Intelligence, volume 33, pp. 56935700, 2019b. Anastasia Koloskova Yue Liu, Tao Lin and Sebastian U. Stich. Decentralized gradient tracking with localsteps. Optimization Methods and Software, 0(0):128, 2024. doi: 10.1080/10556788.2024.2322095. URL Miaoxi Zhu, Li Shen, Bo Du, and Dacheng Tao. Stability and generalization of the decentralized stochas-tic gradient descent ascent algorithm. In Thirty-seventh Conference on Neural Information ProcessingSystems, 2023a. URL Tongtian Zhu, Fengxiang He, Kaixuan Chen, Mingli Song, and Dacheng Tao. Decentralized sgd and average-direction sam are asymptotically equivalent. In International Conference on Machine Learning, pp. 4300543036. PMLR, 2023b."
}