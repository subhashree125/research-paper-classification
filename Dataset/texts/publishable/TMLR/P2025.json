{
  "Abstract": "We consider a binary classifier defined as the sign of a tropical rational function, that is, asthe difference of two convex piecewise linear functions. In particular, the set of functionsrepresented by a ReLU neural network can be regarded as a subset in the parameter space oftropical rational functions, specifically, it is contained as a semialgebraic set. We initiate thestudy of two different subdivisions of the parameter space of tropical rational functions withfixed number of terms in the numerator and denominator: a subdivision into semialgebraicsets, on which the combinatorial type of the decision boundary is fixed, and a subdivision intoa polyhedral fan, capturing the combinatorics of the partitions of the dataset. The sublevelsets of the 0/1-loss function arise as subfans of this classification fan, and we show that thelevel-sets are not necessarily connected. We describe the classification fan i) geometrically, asnormal fan of the activation polytope, and ii) combinatorially through a list of properties ofassociated bipartite graphs, in analogy to covector axioms of oriented matroids and tropicaloriented matroids. Our findings extend and refine the connection between neural networksand tropical geometry by observing structures established in real tropical geometry, such aspositive tropicalizations of hypersurfaces and tropical semialgebraic sets.",
  "Introduction": "We consider a binary classification task with hypotheses given by signs of real-valued functions parameterizedby artificial neural networks with piecewise linear activation functions. Given a classification task, we areinterested in the sets of parameters for which the network perfectly classifies the training data, or for whichit makes a certain number of errors, that is, the level sets of the 0/1-loss function. We seek to understandthe combinatorial and discrete-geometric structures underlying such a classification task using polyhedralmethods. One of our aims is to enhance the synergies between neural networks and real tropical geometryto facilitate progress in both communities by translating some concepts and results. The combinatorics of the functions represented by neural networks with piecewise linear activations hasreceived significant attention over the years, e.g., in the works of Pascanu et al. (2014); Montfar et al.(2014); Telgarsky (2016); Raghu et al. (2017); Serra et al. (2018); Balestriero et al. (2019), or works listedin the overview article of Huchette et al. (2023). A new trend in theoretical considerations of (deep) neuralnetworks with piecewise linear activation functions is to study them through the lens of tropical geome-try, a mathematical framework which is tailored to understand the geometry of piecewise linear functions.The language of tropical geometry in the context of binary classification already appeared in the work ofCharisopoulos & Maragos (2017), and the relation to feedforward neural networks with ReLU activation",
  "Published in Transactions on Machine Learning Research (09/2024)": "Thomas Zaslavsky. Facing up to arrangements: face-count formulas for partitions of space by hyperplanes.Memoirs of the American Mathematical Society, 1(issue 1, 154):vii+102, 1975. doi: 10.1090/memo/0154. Liwen Zhang, Gregory Naitzat, and Lek-Heng Lim. Tropical geometry of deep neural networks. In Proceedingsof the 35th International Conference on Machine Learning, volume 80 of Proceedings of Machine LearningResearch, pp. 58245832. PMLR, July 2018. URL",
  "(iii) the dichotomies are the maximal covectors of a realizable oriented matroid": "For p Rd we consider (1, p) = {(a, s) (d) |( as ) , 1p = 0} as a hyperplane through the origin. Alinear hyperplane arrangement H Rd+1 is a collection of hyperplanes through the origin, and it subdividesthe ambient space into chambers, which are the connected components of Rd+1 \\ H and are open polyhedralcones. We recall a few more definitions from polyhedral geometry. A polyhedron is the intersection of finitely manyclosed halfspaces and a polytope is a bounded polyhedron. Equivalently, a polytope P Rd is the convexhull of finitely many points v1, . . . , vn Rd (Ziegler, 1995, Theorem 1.1), i.e. P = conv(v1, . . . , vn), where",
  "conv(v1, . . . , vn) = {1v1 + + nvn | i , 1 + + n = 1}": "A hyperplane supports P if it bounds a closed halfspace containing P, and any intersection of P with such asupporting hyperplane yields a face F of P. A face is a proper face if F P and inclusion-maximal properfaces are referred to as facets. Note that also the empty set is a face of P and by convention dim() = 1.",
  "C = cone(u1, . . . , un) = {1u1 + + nrn | 1, . . . , n 0}": "The lineality space of C is the linear space L(C) = C (C) and a cone is pointed if its lineality space istrivial. The rays of C are its 1-dimensional faces. A polyhedral fan Rd is a finite family of nonemptypolyhedral cones such that every nonempty face of a cone in is also a cone in , and the intersection ofany two cones in is a face of both. An inclusion-maximal cone of is called a maximal cone. The fan is complete if",
  "C C = Rd and it is pure if all inclusion-maximal cones have the same dimension": "Any hyperplane arrangement H uniquely induces a polyhedral fan , whose maximal cones are the Euclideanclosures of the chambers of H. A wall of is an intersection of maximal cones that has codimension 1. Inparticular, if Rd is a complete (and thus pure) polyhedral fan, then the walls are the cones of dimensiond 1, and must always exists.",
  "C =sgn(, 1p1 ), . . . , sgn(,1pM )= (f(p1), . . . , f(pM)) {, 0, +}M,": "where we can choose any parameter vector contained in the relative interior of . We call C the (signed)covector of . The interiors of maximal cones of D consist of parameters which define a strict separation ofthe data, and are labeled with covectors C {, +}M without zero entries (i.e. dichotomies). On the otherhand, lower-dimensional cones are non-strict, i.e. there exist some data points pi which lie on the separatinghyperplane, and Ci = 0 for these data points. Duality between polytopes and normal fans implies that thevertices of PD are in bijection with the dichotomies that the simple perceptron can compute. Example 2.2. Consider the 1-dimensional dataset D = {2, 1, 0, 1, 2} R1.The parameter space(1) = R2 contains the hyperplane arrangement HD consisting of five hyperplanes H2 = (1, 2), H1 =(1, 1), H0 = (1, 0), H1 = (1, 1), H2 = (1, 2), as depicted in . The induced polyhedral fan Dconsists of 10 maximal (2-dimensional) cones. Any two neighboring maximal cones in this fan are separatedby one of the 10 1-dimensional walls. The fan D is the normal fan of the polytope PD with vertices",
  "PD = conv(0, 12) + conv(0, 11) + conv(0, ( 10 )) + conv(0, ( 11 )) + conv(0, ( 12 ))": "and is hence a zonotope. The vertices of the zonotope are dual to the 2-dimensional cones of D. As canbe seen in , each maximal cone of D is the normal cone of a vertex of PD. The figure also showsthe covectors of these maximal cones , i.e., the dichotomies (f(2), f(1), f(0), f(1), f(2)) for inthe interior of the cones. The value f(p) expresses on which side of the hyperplane Hp the correspondingcone lies. For example, let C be the 1-dimensional cone that is the wall between the cone with covector(, , +, +, +) and (, +, +, +, +). Then the covector of C is (, 0, +, +, +), expressing that C is containedin the hyperplane H1.",
  "(a) The hyperplane arrangement HD.(b) The zonotope PD": ": Illustration of Example 2.2. The left panel shows the parameter space and its subdivision bythe hyperplane arrangement HD for a dataset D consisting of five points in R1. The right panel shows thepolytope PD. As all covectors in this article are signed covectors, we omit the word signed throughout this article.The maximal covectors (or topes) are the covectors with inclusion-maximal support, i.e. the dichotomies.",
  "(C IV) (Elimination) if C, D C and i S(C, D) then there exists some Z C such that Zi = 0 andZj = (C D)j j [M] \\ S(C, D)": "Any collection of covectors that arises through a hyperplane arrangement is called a realizable orientedmatroid. To each oriented matroid, one can associate a dual oriented matroid; for realizable oriented matroidsthis captures the geometry of the vector configuration given by the normal vectors of the hyperplanes, i.e.the dataset D. In a classification task, we are typically interested in a strict separation of the data, represented by adichotomy. We now fix a target dichotomy C {, +}M, which divides the data into two sets DC+ = {pi D | Ci = +}, DC= D \\ DC+ . The target dichotomy C is a covector in the oriented matroid if and onlyif there exists a hyperplane separating the data into DC+ , DC , i.e. the data is linearly separable accordingto C. Equivalently, by Farkas Lemma, the covector exists if and only if conv(DC+ ) conv(DC ) = . Forany parameter vector , the 0/1-loss-function errC counts the number of mistakes, i.e.",
  "errC() = |{i [M] | sgn(f(pi)) = Ci }|": "Since the 0/1-loss function is constant along chambers of HD and (relative interiors of) cones of D, we allowourselves to write errC() for chambers or cones D. In the notation of separation sets given above, ifD is the covector associated to then errC() = |S(C, D)|. Note that we choose to interpret data pointswhich lie on the classifying hyperplane to be correctly classified. This technical distinction is irrelevant oninteriors of maximal cones and allows us to consider polyhedral fans in . The kth level set is the polyhedral subfan kD = { | errC() = k}, and the sublevel set is kD=kl=0 kD. If the data is linearly separable according to C, then the set 0D of parameters with 0 error is amaximal cone of D. On the other hand, if the data is not linearly separable, then the minimum error onthe interior of any maximal cone will be larger than 0 and multiple maximal cones may be minima of the0/1-loss.Example 2.3. We continue with Example 2.2. Consider a target dichotomy C1 = (+, , +, , +). Thisasks for a separation of the input data points {2, 1, 0, 1, 2} by a hyperplane in R1 such that {2, 0, 2} lieon the positive side of the hyperplane, and {1, 1} on the negative side. Similarly, C2 = (+, , , +, +) asksfor a separation into {2, 1, 2} and {1, 0}. Clearly the data is not linearly separable in accordance witheither of these target dichotomies. shows the value of errC on each cone of HD for both targetdichotomies. Notably, for C1 the set of minimizers of errC consists of 5 maximal cones, which pairwiseintersect only in the origin, and are thus not connected through walls. On the other hand, for C2 the set ofminimizers consists of a single cone and is a convex set. In the remainder of this section, we study the connectivity of sublevel sets for linear classifiers. If one seeksto find a set of parameters (d) which separates the data, then in practice this can be achieved byminimizing a suitable loss function in the parameter space (d) using an iterative optimization procedure.In this case the search variable is likely to move from chamber to chamber with transitions going throughwalls of codimension 1. We would like to understand under which circumstances there exists a path alongwhich the loss function is monotonically decreasing. The following statement is an adaptation of Bjrneret al. (1999, Proposition 4.2.3) and we give a proof for completeness. Recall that for covectors C, D, theseparation set is S(C, D) = {i [M] | Ci = Di = 0}.",
  "(b) Target dichotomy C2": ": Illustration of Example 2.3. For a given set of input data points the figure shows the polyhedralfan D in parameter space along with the value of the 0/1-loss for the two target dichotomies C1 (left) andC2 (right). The sets of minimizers are shown in gray. Proposition 2.4. Let C, D be two maximal covectors corresponding to maximal cones of D. Then thereexists a sequence of maximal covectors D = D0, D1, . . . , Dk = C such that the cones corresponding toDi, Di+1 are connected through a wall of codimension 1 for i = 0, . . . , k 1 and S(C, Di) > S(C, Di+1). Proof. First note that the maximal cones are labelled by covectors without any zero entry. For two suchcovectors, we have DC = D, and for any i S(C, D), axiom (C IV) translates to the existence of a covectorZ such that Zi = 0 and Zj = Cj for all j [M] \\ S(C, D). We prove the statement by induction on the sizeof S(C, D). Since C, D can be assumed not to have zero entries, this is the number of entries in which C andD differ. Suppose S(C, D) = {i}. By (C IV) there exists a covector Z such that Zi = 0 and Zj = Cj = Djfor all j [M] \\ {i}. Thus, the chambers corresponding to C, D are separated by the hyperplane (1, pi)",
  "and Z corresponds to the wall C D": "Suppose now the statement holds for any D, D such that |S(D, D)| < k and let S(C, D) = k.Fixi S(C, D).By (C IV) there exists some covector Z such that Zi = 0 and Zj = Cj = Dj for allj [M] \\ S(C, D). Let A = {i [M] | Zi = 0} and l = |A| 1. Among all such covectors, choose Z suchthat l is minimal. Thus, there exists no strict subset A A and covector Z such that Zi = 0, Zj = Cj = Djfor all [M] \\ S(C, D) and Zj = 0 for all j [M] \\ A. Recall that Z corresponds to a cone of a D, which iscontained in the hyperplane (1, pj) if and only if Zj = 0. Since Z exists, but no such Z exists, this impliesthat the hyperplanes (1, pj), j A all coincide. In other words, if Z is chosen minimally, then pj = pj forall j, j A, and hence Z represents a wall of D. By (C III) we have that also (Z C) and (Z D) arecovectors. Note that (Z C)j = Zj = (Z D)j = 0 for all j [M]\\A, and {(Z C)i, Zi, (Z D)i} = {+, 0, }for all i A. Thus, (Z C), (Z D) correspond to adjacent maximal chambers separated by (1, pi), i A,and the separating wall corresponds to Z. Since S(C, Z C) < k and S(Z D, D) < k, there exist strictlydecreasing sequences from C to (Z C) and from Z D to D by induction, which together form a sequencefrom C to D. Given a sequence 1, . . . , k D of maximal cones, we say that the sequence forms a path in D connecting1 and k if i, i+1 intersect in a wall of codimension 1 for all i [k 1]. Proposition 2.4 allows us tocharacterize the set of local and global minima, and bound the error along paths between two minima. Theorem 2.5. If the data is linearly separable, then the sublevel sets kDof the 0/1-loss function areconnected through walls of codimension 1 for any k 0. Conversely, if the data is not linearly separableand the set of minimizers of the 0/1-loss function consists of more than one maximal cone, then it is notconnected through codimension 1. Moreover, if , are distinct maximal cones which are local minima ofthe 0/1-loss, if m = errC() denotes the minimum error and if , 1, . . . , l, forms a path, then errC isbounded from above along this path by m + l+1",
  "Piecewise Linear Classifiers, ReLU Networks, and Tropical Rational Functions": "In this section we extend the theoretical framework from linear classifiers to the more general case of classi-fication with continuous piecewise linear functions. An important instance of this are neural networks withpiecewise linear activation functions. Recall that an L-layer feedforward neural network represents a function f : Rdin Rdout which is obtained asa composition f = (L) (L) (1) (1). For each [L] the preactivation function () : Rd1 Rdis an affine function ()(x) = W ()x + c() with weights W () Rdd1 and biases c() R(d) of the th layer, and din = d0, dout = dL. A ReLU neural network is a neural network with ReLU activation function(Rectified Linear Unit) ()(x1, . . . , xd) = (max(x1, 0), . . . , max(xd, 0)). We denote f () : Rdin Rd, f () =() () (1) (1) and f (0)(x) = x. The number L of such compositions is the depth of the network,and the dimension d, [L] is the width of the th layer. We do not impose any further restrictions on theweights and biases and so the choices of the depth and width of each layer determine the architecture of thenetwork. The network consists of all of its activation and preactivation functions. Any function represented by a ReLU neural network is a continuous piecewise-linear function. A powerfulframework to study piecewise-linear functions is provided by the language of tropical geometry. This is thegeometry over the tropical semiring (or max-plus algebra) where we define tropical addition, multiplication,exponentiation and division as",
  "which is determined by its parameter vector = (a1, s1 . . . , an, sn, b1, t1, . . . , bm, tm), where ai R, si Rd": "for i [n] and bj R, tj Rd for j [m]. We denote by (d, n, m) the (n + m)(d + 1)-dimensional spaceof parameters of tropical rational functions with n terms in the numerator and m terms in the denominator,and for a fixed (d, n, m) we denote by g h the associated tropical rational function. In we show that (d, n, m) allows a natural polyhedral fan structure in analogy to the fan and hyperplanearrangement from . A tropical signomial is a convex and continuous piecewise linear function, and vice versa. Every continuous(possibly non-convex) piecewise linear function can be written as the difference of two convex piecewise linearfunctions, and this difference is a tropical rational function. This establishes the connection to ReLU neuralnetworks. Theorem 3.1 (Arora et al. 2018, Theorem 2.1 and Zhang et al. 2018, Theorem 5.4). A function f : Rd Ris a tropical rational function if and only if f can be represented by a feedforward ReLU network. Any tropicalrational function g h with n terms in the numerator and m terms in the denominator can be representedby a ReLU network with depth at most min(log2(d + 1) + 1, max(log2(n), log2(m)) + 2). A similar result has also appeared in work of Siahkamari et al. (2020). The original formulation of Zhanget al. (2018, Theorem 5.4) has an additional condition on the weights to be integer, however this is merely anartifact of the distinction between tropical Laurent polynomials and signomials. Given the class of tropicalrational functions with a bounded number of terms in the numerator and denominator, this gives a sufficientcondition on the depth of the architecture. We may also consider the reverse direction: Let ReLU(d0, d1, . . . , dL1, dL) be the set of piecewise linearfunctions that can be represented by a fully-connected ReLU network with d0 = d inputs and L layers ofsizes d1, . . . , dL N, with dL = 1. Given a fixed such architecture, we seek to find n, m N such thatfor any function f ReLU(d, d1, . . . , dL1, 1) there exists a parameter (d, n, m) such that f = f.For lower bounds on n, m, let kconvex be the maximum number of linear pieces over all convex functions inReLU(d, d1, . . . , dL1, 1), and kconcave the maximum number of linear pieces of any concave function. Thennecessarily we have n kconvex and m kconcave. To obtain upper bounds, we consider a simple decomposi-tion of the functions represented by a ReLU network as differences of convex piecewise linear functions, whosesize depends on kconvex and kconcave in each step. For most of the functions in ReLU(d, d1, . . . , dL1, 1) thedecomposition that we apply is by no means minimal for the individual function. However, this decompo-sition allows us to consider the space of ReLU networks as semialgebraic sets inside (d, n, m). We willdiscuss minimal decompositions at the end of this section. Theorem 3.2. Let d = d0, d1, . . . , dL1, dL = 1 N. There exist n, m N such that each function inReLU(d, d1, . . . , dL1, 1) can be represented by a point in (d, n, m), and there is a semialgebraic subset of(d, n, m) (described by polynomial inequalities) representing exactly the points in ReLU(d, d1, . . . , dL1, 1).This semialgebraic set can be described by polynomial inequalities of degree L + 1. The n, m can be chosenas n = 2m and log2(m) L1k=1 2L1k L1l=k dl. We make the statement of this theorem more precise. Recall that any vector of parameters (d, n, m)defines a tropical rational function g h with at most n monomials in the numerator and at most mmonomials in the denominator. Let CPWL(Rd, R) be the space of all continuous piecewise linear functionsfrom Rd to R, and let : (d, n, m) CPWL(Rd, R) with () = g h. Then Theorem 3.2 says thatfor any d1, . . . , dL1 N there exist values n, m N such that ReLU(d, d1, . . . , dL1, 1) ((d, n, m)),and there exists a semialgebraic set S (d, n, m) such that (S) = ReLU(d, d1, . . . , dL1, 1).",
  "gives () = max(Wx + a1, 0), which is represented by the network with layers of sizes d0 = d, d1 = 1,weights W and biases a1": "We now proceed by induction L L + 1, and consider a ReLU network with L + 1 layers.The ideaof the induction is as follows.Let W and c be the weights and biases of the last layer.Then W =W + W has a canonical decomposition into nonnegative matrices, and the entire function is of the formf (L+1) = max(dLk=1 Wkfk + c, 0), where f1. . . . , fk are the tropical rational functions in the Lth layer.Writing fk = gk hk as a difference of two convex functions, we obtain the decomposition f (L+1) =max(dLk=1(W +k W k )(gk hk)+c, 0) = max(dLk=1 W +k gk +W k hk +c, W k gk +W +k hk)(W k gk +W +k hk).We now perform this computation in more detail.",
  "In the following, we use the notationmaxk[dL]ik[nk,L]jk[mk,L]": "to denote the maximum over all i1 [n1,L], . . . , idL [ndL,L], j1 [m1,L], . . . , jdL [mdL,L]. Applying againdistributivity of tropical multiplication (i.e. that max(a, b) + max(c, d) = max(a + c, a + d, b + c, b + d)), andbilinearity of , yields",
  "t(L+1)k,ik,jk = s(L+1)k,nk,L+ik,mk,L+jk,b(L+1)k,ik,jk =a(L+1)k,nk,L+ik,mk,L+jk": "Thus the feasible parameters are given as the image of a polynomial map evaluated over a semialgebraicset. In turn, they form a semialgebraic set. Moreover, we have written the variables s(L+1)k,ik,jk etc. as a linear combination of the variables sk,Liketc., i.e. as the solution of a polynomial of degree 1 in these variables. Byinduction, each of the sk,Lik s is a solution to a system of polynomials of degree L + 1. Substituting thesepolynomials into a polynomial of degree 1 yields a system of polynomials of degree L + 2.",
  "and the stated bound follows": "We have just proven ReLU(d, d1, . . . , dL, 1) (S), where S is the semialgebraic set which is implicitlydefined through the recursive relations in (2). For the reverse inclusion, let S. By induction, thereexist weights and biases defining a network in ReLU(d, d1, . . . , dL) such that ak,Lik , sk,Lik , bk,Ljk , tk,Ljkare the parameters of respective tropical rational function representations of some f (L)ks. By definition of S thereexists a solution for the system of linear equations (2) in indeterminates W +k , W k . Any such solution givesrise to the weights of the last layer. Remark 3.3 (S is not unique). The proof of Theorem 3.2 reveals that in the above representation thereare many redundancies which are expressed in the linear equations defining the semialgebraic set. Moreover,the choice of S is not unique: already for L = 1, choosing the representation = (c, W, 0, 0, 0, 0) (d, 2, 1)yields the semialgebraic set S = {(a1, s1, a2, s2, b1, t1) | a2 = b1 = 0, s2 = t1 = 0}. This reflects the fact that",
  "B(g h) = {x Rd | g(x) h(x) = 0} =x Rd | maxi[n](ai + si, x) = maxj[m](bj + tj, x)": "The decision boundary B(gh) splits the input space into two open parts B+, B, where either the numeratorg or the denominator h attains a higher value. A classifier g h then separates the data D into two classesD+ B+ and D B. It was noted (Zhang et al., 2018, Proposition 6.1) that B(g h) is a subcomplex of the tropical hypersurfaceT (g h). This observation was also used in the work of Alfarra et al. (2023). We will now make thisstatement more precise. Consider the tropical signomial f(x) = g(x) h(x) = maxi[N](ai + si, x ), whereN = n + m, an+j = bj, sn+j = tj for j [m]. Each such tropical polynomial divides the input space Rd intoN polyhedral regions, one for each i [N], which are of the form",
  "s4": ": The three combinatorial types of generic hypersurfaces defined by tropical polynomials in two vari-ables and 4 terms (top), and the dual regular subdivisions of their Newton polygons (bottom), as describedin Example 4.1. The tropical hypersurface is dual to a regular subdivision of the Newton polytopeNewt(f)=conv(s1, . . . , sN) Rd, which can be obtained in the following way:Consider the lifted polytopeconv(( a1s1 ) , . . . , ( aNsN )) Rd+1. Any facet of the lifted polytope has a unique outer normal vector (up topositive scaling). The upper hull is the collection of facets whose normal vector has a positive entry in thefirst coordinate. The projection of the upper hull onto the remaining d coordinates forms a subdivision ofNewt(f), called a regular subdivision. The region Ri is the set of linear functionals maximizing the vertex( aisi ) of the lifted Newton polytope, and the intersection Ri Rj is contained in T (f) if and only if thepair si, sj form an edge in the regular subdivision. For more detailed expositions on this duality we referthe reader to Maclagan & Sturmfels (2015, Chapter 3.1) and Joswig (2021, Chapter 1.2). Example 4.1 (Tropical Hypersurfaces and Newton Polytopes). Let N = 4 and d = 2, i.e. f(x) = a1 xs1 a2 xs2 a3 xs3 a4 xs4, where ai R and si R2. The Newton polytope Newt(f) is theconvex hull of the 4 points s1, s2, s3, s4 in R2, and is thus either a triangle or a square (except for degeneratecases where Newt(f) is not full dimensional). Choosing generic values a1, a2, a3, a4 R, we obtain threepossible regular subdivisions and their respective dual complexes, as shown in . We now extend this duality for understanding tropical rational functions by assigning signs to each region. Wehave seen that T (gh) divides the input space into n+m regions. We call the full-dimensional regions Ri withi [n], i.e. those that correspond to terms of g, the positive regions. The regions Rj, j [m] correspondingto terms of h are the negative regions. This terminology stems from the fact that g(p) h(p) 0 if p liesin a positive region, and g(p) h(p) 0 if p lies in a negative region. These regions are dual to vertices inthe regular subdivision of the Newton polytope Newt(g h), i.e. to those vertices which lie in the upper hullof the lifted Newton polytope. We equip each such vertex with the corresponding sign, obtaining positiveand negative vertices of the regular subdivision. An edge of the subdivision is a sign-mixed edge if one ofits vertices is positive and the other one is negative. Such a sign-mixed edge is dual to the intersection of apositive and a negative region, and thus g h 0 along this intersection. We summarize this constructionas follows:",
  "Theorem 4.2. The decision boundary B(g h) is the (d 1)-dimensional subcomplex of T (g h) whosemaximal regions are dual to sign-mixed edges of the subdivision of the Newton polytope Newt(g h)": "This statement is already implicit in earlier literature on real and positive tropicalization.If g, h are tropicalpolynomials, then the decision boundary B(g h) is the tropicalization of the intersection of the positive or-thant with a (family of) hypersurface(s). Such a hypersurface is defined through any polynomial G(x)H(x)such that trop(G) = g, trop(H) = h and both G and H have only nonnegative coefficients. These connectionsbetween decision boundaries and (tropical) algebraic geometry are, as far as we know, widely unexplored.For more details on tropical positivity we refer the reader to Speyer & Williams (2005),Viro (2006) and",
  "+": ": All combinatorial possibilities of positive and negative regions of T (g h) for n = m = 2, up toswitching + and , as explained in Example 4.3. The decision boundary B(g h) (top) and its dualcomplex (bottom) are highlighted in blue. The right most column shows configurations of three positiveregions and one negative region (n = 3, m = 1). The decision boundary is highlighted in orange.",
  "Brandenburg et al. (2023).For an introduction to tropicalization of polynomials and hypersurfaces, werecommend the texts of Joswig (2021, Chapter 2) and Maclagan & Sturmfels (2015, Chapter 3.1)": "Example 4.3 (Decision Boundaries and Sign-Mixed Subcomplexes). Let d = 2 and let g = a1 xs1a2 xs2 and h = b1 xt1b2 xt2. The polynomial g h consists of N = 4 terms, as the one in Example 4.1. shows all nondegenerate combinatorial possibilities of positive and negative regions, where a +indicates a region or vertex corresponding to a term of g, and a indicates a region or vertex correspondingto a term of h. The decision boundary is the 1-dimensional subcomplex of T (gh) consisting of line segmentsand rays incident to a positive and a negative region. also shows a configuration where g consists ofn = 3 terms and h is a monomial (m = 1). There, the decision boundary separates the space into a bounded(negative) cell and its (positive) complement. The main focus of this article is the parameter space (d, n, m) of tropical rational functions with n termsin the numerator and m terms in the denominator. It is thus natural to ask about the geometry of the setof parameters such that the decision boundary has a fixed combinatorial type. The decision boundary isa polyhedral complex. The combinatorial type of a polyhedral complex captures the combinatorics of theintersections and inclusions of its faces. Formally, it is defined as the isomorphism class of the partiallyordered set of faces, ordered by inclusion. By the discussion above, the decision boundary is dual to a subcomplex of a Newton polytope, so the setof parameters which gives a fixed combinatorial type of decision boundaries is subdivided into multiple (butfinitely many) smaller sets, one for each combinatorial type of regular subdivisions of Newton polytopesdefined by n + m monomials. Each such smaller set is itself determined by the combinatorial type of thelifted Newton polytope. The set of parameters such that the Newton polytope has a fixed combinatorialtype is the realization space of the lifted polytope, and the space of parameters (d, n, m) can be partitionedinto these realization spaces. It is known that such a realization space is a semialgebraic set, i.e. a finiteunion and intersection of solution sets to polynomial inequalities. We thus obtain the following result. Theorem 4.4. The parameter space (d, n, m) of tropical rational functions is partitioned into semialgebraicsets, one for each combinatorial type of regular subdivisions of n + m points in d-dimensional input space. However, the Universality Theorem of Realization Spaces certifies that realization spaces of polytopes canbe arbitrarily complicated (Richter-Gebert & Ziegler, 1995).Moreover, observe that this partition intosemialgebraic sets is completely independent of the data set D. In we will introduce the activationfan, which is a polyhedral fan subdividing the parameter space, and its geometry heavily depends on thegeometry of the data. The aforementioned semialgebraic sets thus may or may not intersect cones in theactivation fan. In other words, these are distinct partitions of the parameter space whose structures areincompatible with one another.",
  "Activation Fan and Activation Polytope": "In we have seen that the parameter space of linear classifiers allows for a subdivision induced bya hyperplane arrangement. This subdivision is the normal fan of a zonotope, and its cells correspond tomaximal covectors of an oriented matroid. In this section we make a first step towards a generalizationof this theory for continuous piecewise linear functions. Following the ideas from , we considersubdivisions of the input space into n + m regions, which are induced by tropical hypersurfaces. This allowsus to introduce the activation fan, a polyhedral fan which is the normal fan of the activation polytope. Asan analog to covectors, we label the cones in this fan by bipartite graphs, called activation patterns. In thelater we will then assign signs to obtain the full analog for tropical rational functions. In .1 we introduce the concepts and investigate the general combinatorial and geometric structureof these objects. In .2 we relate these to known concepts, namely oriented matroids and tropicaloriented matroids.",
  "General Structure": "Let D Rd be a fixed finite data set. In we have seen that to any vector of parameters (d, n, m) we can associate a tropical rational function g h, which induces a classification of the data set.Our goal is to understand the underlying combinatorics of this separation in parameter space. In we have seen that the combinatorics of this separation is determined by the combinatorics of the tropicalhypersurface T (g h). Here, g h is a tropical signomial with n + m terms and T (g h) separates thedata into n + m classes. We devote this section to the study of the combinatorics of tropical signomials withN = n + m terms within their parameter space. Later, in we will extend these considerations totropical rational functions. Consider a fixed finite data set D = {p1, . . . , pM} Rd and denote a tropical signomial f : Rd R,f(x) = maxi[N](ai + si, x ), which is uniquely defined by its parameter vector = (a1, s1, . . . , aN, sN).We denote by (d, N) the N(d + 1)-dimensional parameter space of tropical signomials with N terms (innumerator and denominator combined). Given a vector of parameters (d, N), we write f for thecorresponding function. For a graph G = (V (G), E(G)) and a node v V (G) we denote the neighborhoodof v by N(v; G) = {w V (G) | vw E(G)}. For two graphs G = (V, E), G = (V, E) on the same set ofnodes, we write G G for the graph with nodes V and edges E E. Definition 5.1 (Activation Pattern of Tropical Signomial). The data point pj D activates the (i)th termof the tropical signomial f(x) = maxi[N](ai + si, x ) if f(pj) = ai + si, x . The activation patternof (f, D) is the bipartite graph G = (V (G), E(G)) on nodes V (G) = D [N] with edges E(G) = {pi |",
  "in the parameter space of tropical signomials, where cl denotes the Euclidean closure": "In the notation of , the point p activates the (i)th term if and only if p Ri, where Ri is amaximal region of the subdivision of Rd induced by the tropical hypersurface T (f). The activation coneCD(G) is thus the space of tropical signomials where each data point p lies in a fixed set of regions, namelyin regions indexed by N(p; G). The activation pattern may be thought of as a multivalued generalization ofa covector of an oriented matroid, and the corresponding activation cone serves as an analog of a chamberin the hyperplane arrangement from . Example 5.2 (Activation Patterns). Let D = {p1, p2} R2 with p1 = (0, 0), p2 = (1, 0), let N = 4 and Gbe the activation pattern on nodes V (G) = D {i1, i2, i3, i4} with edges E(G) = {(p1, i1), (p1, i2), (p2, i3)}.This graph represents the set of tropical signomials in d = 2 variables with N = 4 terms such that thepoint p1 lies in the intersection of the regions Ri1, Ri2 corresponding to the first and second term, and thepoint p2 lies in the region Ri3. shows some tropical hypersurfaces T (f) and dual subdivisionsof Newt(f) for CD(G). More explicitly, the parameter of the leftmost tropical hypersurface can bechosen as = (0, 1, 1, 0, 0, 0, 1, 1.5, 0.5, 2, 0, 2). Recall from Theorem 4.4 that the parameter spaceis subdivided into semialgebraic sets, one for each combinatorial type of subdivisions of Newt(f). Thisexample also shows that the cone CD(G) intersects all such semialgebraic sets nontrivially.",
  "If CD(H) = then CD(H) = CD(G), where G is the smallest activation pattern such that E(H) E(G).We write G = H for this smallest graph": "Remark 5.3 (Checking existence through linear programs). In theory it may be difficult to determinewhether CD(H) is empty or not. In practice, this can be done via a linear program, where CD(H) is the setof feasible solutions. This program is defined by |E(H)|(N 1) linear inequalities (where |E(H)| N|D|),and CD(H) = if and only if the corresponding linear program has at least one solution. The activation",
  "Definition 5.4 (Activation Fan). The activation fan D(N)of a finite data set D Rd and tropicalsignomials with N monomials is the set of all activation cones in the parameter space (d, N)": "Proposition 5.5. The activation fan D(N) is a complete polyhedral fan, i.e. a collection of polyhedralcones such that the intersection of any two cones is a face of both, and that their union covers the entireambient space. Proof. Let G, G be activation patterns.CD(G) is indeed a polyhedral cone, as it is defined by linearinequalities, and for every CD(G), R one has CD(G). Its faces are of the form CD(G) whereE(G) E(G), and any such activation pattern defines a face of CD(G). For any pair of activation patternsholds CD(G) CD(G) = CD(G G) is a face both of CD(G) and CD(G). Therefore, the collection of allactivation cones forms a polyhedral fan. Every vector of parameters = (a1, s1, . . . , aN, sN) (d, N) givesrise to a tropical signomial f(x), and CD(H), where H is the activation pattern of (f, D). Thus, theactivation fan is complete. The activation fan serves as a generalization of the polyhedral fan D from which is induced bythe hyperplane arrangement HD. The fan D is the normal fan of a zonotope, i.e. the Minkowski sumof 1-dimensional simplices, one for each data point in D. We now show an analogous statement for theactivation fan D(N).",
  "C = {(a1, s1, . . . , aN, sN) | maxi[N](ai + si, p) = ai(p) + si(p), p p D},": "so C = CD(G), where the activation pattern is the bipartite graph G = (D [N], E(G)) with edge setE(G) = {pi(p) | p D, i(p) [N], C N pvi(p)}. We have shown that the maximal cones of the normalfan of PD(N) are contained in D(N). Since the normal fan is a complete fan, this finishes the proof.",
  "pD conv((0, 0), (1, p)) Rd+1 from , however, this equivalence is not obvious. Tomake this precise, consider the activation polytope PD(2) =": "pD conv((1, p, 0, 0), (0, 0, 1, p)) R2(d+1).The activation polytope is contained in the (d+1)-dimensional affine subspace with ei = ei+d+1 for i [d+1].Projecting PD(2) onto the first d + 1 coordinates induces an isomorphism between the zonotope PD and theactivation polytope PD(2). An activation pattern is a bipartite graph with nodes D{1, 2}. The isomorphismidentifies the labeling {1, 2} with the labeling {+, }, recovering the covectors of the oriented matroid.",
  "Proposition 5.9. The dimension of the activation polytope PD(N) (d, N) is (N 1)(dim(aff(D)) + 1),where aff(D) denotes the smallest affine subspace containing D": "Proof. Recall that dim(PD(N)) = dim(aff(PD(N))).Moreover, the linear space which is parallel toaff(PD(N)) is orthogonal to the lineality space L of the normal fan of PD(N), i.e. the largest linearspace which is contained in each cone of the fan. By construction, the normal fan of PD(N) is a com-mon refinement of the normal fans of the simplices (p), p D, and so the lineality space L of thenormal fan of PD(N) is the intersection of the lineality spaces of the simplices.We thus characterizethe lineality space L(p) of the normal fan of a simplex (p) for a fixed p D. Again, L(p) is orthog-onal to the linear space parallel to aff((p)).Since (p) is a (N 1)-dimensional simplex, we havedim(L(p)) = (d + 1)N dim(aff((p))) = (d + 1)N (N 1) = dN + 1. By construction, L(p) contains",
  "(ei, ei, . . . , ei), i [d + 1], and (V (p), 0, . . . , 0), (0, V (p), . . . , 0), . . . , (0, 0, . . . , V (p)),": "where V (p)=(1, p).We denote E=span({(ei, . . . , ei)|i[d + 1]}) and W(p)=span((V (p), 0, . . . , 0), . . . , (0, 0, . . . , V (p)) The dimension of the total linear span is dim(E) + dim(W(p)) dim(E W(p)) = (d + 1) + Nd d = Nd + 1, so the span equals L(p). The intersection of all these linealityspaces L(p), p D is spanned by E and W =",
  "where ei Rd+1 denotes a standard basis vector, and where V = span({1}aff(D)) Rd+1 is a (daff(D))-dimensional vector space": "In the linear case, the cells of the hyperplane arrangement in parameter space are labelled by covectors ofthe oriented matroid, and the activation patterns naturally generalize covectors. The maximal chambers arelabelled by covectors without 0 entries, corresponding to the fact that each data point in input space lies onprecisely one side of the dual hyperplane. We now show that the analog holds for activation patterns: Givena parameter vector in the interior of a maximal cone in the activation fan, each data point lies in preciselyone region of the dual tropical hypersurface in input space. As in the proof of Theorem 5.7, let vi(p) = (0, . . . , 0, 1, p, 0, . . . , 0) denote the ith vertex of (p). SincePD(N) is a Minkowski sum, every face of PD(N) can be written uniquely as a sum of faces of (p), forp D. In the following, we write F =",
  "Proof. We have that CD(G) =": "pD NF (p), where NF (p) is the normal cone of the face F(p).Givenany NF (p) with associated tropical signomial f, the activated terms of f(p) are {i [N] |vi(p) is a vertex of F(p)}.Thus, for any activation cone CD(H) NF (p) with activation pattern Hwe have that N(p; H) = {i [N] | vi(p) is a vertex of F(p)}.Given CD(G) =",
  "Corollary 5.12. If G is an activation pattern, then deg(p) 1 for all p D. The activation cone CD(G)is of maximal dimension if and only if deg(p) = 1 for all p D": "In the linear classification case, we have seen that any target dichotomy separates the data into two setsDC+ , DC , and this dichotomy exists as a maximal covector of the oriented matroid if and only if conv(DC+ )conv(DC ) = . Note that under the identification of a covector with a bipartite graph G on nodes D{+, },we have that DC+is the set of points which are neighbors of + in G, i.e. DC+= N(+; G), and similarlyDC = N(; G). We now discuss necessary conditions on the geometry of the data in the more general case,i.e. such that an activation pattern or cone may exist in the activation fan.",
  "(iii) (Regularity) There exists a subdivision of the input space into maximal regions R1, . . . , RN such thatN(i; G) Ri for each i [N], and a dual subdivision of N points which is regular": "Proof. For cones of arbitrary dimension, (ii) follows from convexity of the regions of T (f) for any CD(G).By Corollary 5.12 the activation patterns of maximal cones satisfy N(i; G)N(j; G) = for all distinct i, j [N]. This, together with (ii) implies (i). Finally, since CD(G) is nonempty, there exists a tropical signomialf such that G is the activation pattern, and the tropical hypersurface T (f) induces the subdivision. By, this subdivision is dual to a regular subdivion of the Newton polytope Newt(f). We have given necessary conditions for an activation cone to be nonempty by considering the geometry ofthe data. Recall that the set of covectors of oriented matroids obey the axiom system (C I)(C IV) onpage 6. The following result mimics a system in this spirit to describe the set of activation patterns.",
  "(A VI) (Comparability) For any point p [D] the comparability graph CGpG,H of any two patterns G, H G is acyclic": "For a pair G, H of activation patterns, we consider the comparability graph CGpGH of a data point p D.This graph has nodes [N] and contains directed and undirected edges. We draw an edge between j and k ifj N(p; G) and k N(p; H). This edge is undirected if j, k N(p, G) N(p, H) and j k otherwise. (A I),(A II),(A III), and (A IV) are analogs to axioms (C I)(C IV) of covectors of oriented matroids. Onthe other hand, (A III), (A IV), (A V), and (A VI) are analogs to axioms (T I)(T IV) of covectors oftropical oriented matroids, which we will define formally in .2. For tropical oriented matroids, thecomposition axiom is replaced by the surrounding axiom, which follows from stricter conditions on possibleperturbations of tropical hyperplanes. Proof. (A I) is realized by = (0, . . . , 0), or any point in the lineality space of D(N). (A II) holds sincethe construction of D(N) is symmetric in i [N]. (A V) will be proven separately in Theorem 5.17. For (A III), let x CD(G) and y CD(H).These are vectors of parameters of the form x =(ax1, sx1, . . . , axN, sxN) and y = (ay1, sy1, . . . , ayN, syN).For > 0 small enough, consider z = x + y. Thenfor any p D such that N(p; G) N(p; H) = holds",
  "and the maximizers are precisely the indices in N(p; G) N(p; H)": "For (A VI), suppose that i0, i1, . . . , in, in+1 = i0 [N] is a cycle in CGpG,H. After contracting all undirectededges we can assume that all edges are directed. Let again x CD(G), y CD(H). An edge from ik to ik+1indicates that we have ik N(p; G) and ik+1 N(p; H). This gives",
  "j=1jpj conv(p1, . . . , pk) conv(p1, . . . , pl),": "and q lies in the relative interiors of both convex hulls. Therefore, Theorem 5.13 (ii) implies that such abipartite graph G which has N(i; G) = {p1, . . . , pk} and N(j; G) = {p1, . . . , pl} is not an activation patternof D(N). Conversely, let p1, . . . , pM be affinely independent, and let G be any bipartite graph such thatN(p; G) = for all p D. Note that since the points are affinely independent we have M d + 1. Thisimplies that for any i [N] there exists an affine linear functional fi(x) = ci + ui, x such that fi(p) = 0for all p N(i; G) and fi(p) < 0 for all D \\ N(i; G). Choose ai = ci and si = ui for all i [N] suchthat N(i; G) = , and otherwise choose ai, si small enough. Then = (a1, s1, . . . , aN, sN) is a vector ofparameters whose activation pattern is G. Remark 5.16. The number of maximal cones in the activation fan D(N) equals the number of vertices ofthe activation polytope PD(N). Montfar et al. (2022) give a sharp upper bound for the number of verticesof generic Minkowski sums. However, the Minkowski summands (p) are not entirely generic in our case.",
  "Linear and Tropical Classification within the Activation Fan": "In .1 we have seen how activation patterns can be thought of as multivalued analogs of covectorsof oriented matroids. Specifically, Remark 5.8 describes how N = 2 recovers the linear case. In this sectionwe describe how also for N > 2 every activation fan carries a family of hyperplane arrangements (andthus oriented matroids) with it, by considering intersections with affine spaces. We extend our findings totropical oriented matroids, which are analogs of oriented matroids arising through arrangements of tropicalhyperplanes.",
  "Recall from the case of linear classification, that the dichotomies are given by a hyperplane arrangement HDin parameter space, the normal fan of the zonotope PD": "Theorem 5.17. For any S [N] the bipartite graph with edges E(G) = {pi | p D, i S} is an activationpattern of a cone in D(N). The cone CD(G) is the normal cone of a face F of the activation polytopePD(N), where F is itself an activation polytope PD(|S|). In particular, ranging over all sets with |S| = 2,one getsN2many faces of the activation polytope PD(N) which are equal to the zonotope PD.",
  "lif i S,0if i [N] \\ S": "Since M S corresponds to a vector of parameters of a tropical signomial f, it has an associated activationpattern G, which we now describe. Recall that N(i; G) = {p D | p activate the ith term}. For p D wehave f(p) = (1p), l > 0, and precisely the terms i S are active. Thus, E(G) = {pi | p D, i S}, andthis is the activation pattern of the cone CD(G) which contains M S in its relative interior.",
  "We now describe the face F S of the activation polytope whose normal cone is CD(G). By Proposition 5.11,we have that F S =": "pD F(p), where the face F(p) of (p) is the (|S 1|)-dimensional simplex conv(M i |i S). The polytope F S lies inside an affine space of codimension (|S| 1)(dim(aff(D) + 1). Inside thisaffine space, we have F S = PD(|S|), which is embedded into (d, N) by inserting 0 for all columns indexedby [N] \\ S, when we view the vertices of PD(|S|) as matrices of size (d + 1) |S| and the vertices of F S asmatrices of size (d + 1) N. We dualize the above statement to find the hyperplane arrangement HD in the activation fan D(N). The k-dimensional face Fij identified in the former proof is dual to a (N(d+1)k)-dimensional cone Cij D(N).More specifically, Cij = CD(G) where G is the activation pattern such that N(p, G) = {i, j} for all p D.The k-dimensional faces of Fij are dual to (N(d + 1) k)-dimensional cones of D(N) which containCij. The collection of these cones is called the star of Cij, and denoted by star(Cij). Let lin(Cij) denotethe smallest linear space containing Cij. Projecting the cones in the star of Cij onto the orthogonal spacelin(Cij) yields the normal fan of the zonotope Fij. We thus obtain the following dual statement:Theorem 5.18. For each i, j [N], let Cij = CD(G) be the activation cone for the pattern G with N(p; G) ={i, j} for all p D. Then the projection of star(Cij) onto lin(Cij) is the polyhedral fan induced by thehyperplane arrangement HD. We now move towards tropical hyperplane arrangements and tropical oriented matroids. Tropical orientedmatroids can be viewed as multivalued analogs of oriented matroids, which arise through tropical hyperplanearrangements. We will see that activation patterns can also be viewed as generalization of realizable tropicaloriented matroids.",
  "A tropical hyperplane H(a) is the tropical hypersurface T (f) defined by the linear tropical polynomialfa(x) =": "i[d] ai xi. It is an affine translate of the normal fan of a standard simplex with apex a =(a1, . . . , ad) Rd. Thus, any tropical hyperplane subdivides the ambient space into d maximal regions,one for each term of fa. Given a finite number of tropical hyperplanes H(a1), . . . , H(aM) we consider thecommon refinement of all these subdivisions, and label each region R by a tropical covector (A1, . . . , AM)where Ai [d] is the set of indices of the terms of fai which are active on R. We obtain an activationpattern G = ([d] D, E(G)) from a tropical covector by setting N(pi; G) = Ai for pi D = {p1, . . . , pM}.Any set of tropical covectors which arise through such an arrangement of tropical hyperplanes is called arealizable tropical oriented matroid. Similarly to the linear case, tropical oriented matroids are defined through a set of axioms, and it was shownthat sets satisfying these axioms are in bijection with subdivisions of products of simplices (Horn, 2016). Aset T {(A1, . . . , AM) | Ai [N], i [M]} is the set of tropical covectors of a tropical oriented matroid ifit satisfies the following axioms (Ardila & Develin, 2008, Def. 3.5).",
  "Let A, B be tropical covectors and G, H be the corresponding activation patterns. The comparability graphof the tropical covectors is CGA,B =": "pD CpG,H, where the comparability graph CpG,H is as defined inTheorem 5.14. The refinement of a type A = (A1, . . . , AM) with respect to an ordered partition (P1, . . . , Pr)of [M] is A = (A1 Pm(1), . . . , AM Pm(M)), where m(i) is the largest index for which Ai Pm(i) = . Notethat (A III),(A V),(A IV) and (A VI) of Theorem 5.14 are generalizations of axioms of tropical orientedmatroids.",
  "Proof. Let CD(G) D(d) such that CD(G)A = , and consider the coordinate projection (CD(G)) ontocoordinates (a1, . . . , ad). Any parameter A defines a function f(x) =": "i[d] ai xi. By construction, CD(G) A if and only if a = () satisfies maxi[d] ai + pi = ai + pi for all edges ip E(G). Inother words, a is contained in the region i of H(p) for all such edges, and (CD(G)) is a region in thetropical hyperplane arrangement. We can extend the above statement to more parameters N > d by requiring that the additional monomials( aisi ) , i > d lie below the lifted polytope conv(( a1,e1 ) , . . . , ( aded )). In this case they are not visible in any regularsubdivision of the dual Newton polytope, and can thus be neglected in the above proof. The dual statement to Theorem 5.19 identifies a subcomplex of the boundary of the activation polytopePD(d). This subcomplex corresponds to a regular subdivision of products of simplices, and coincides withthe boundary complex of the unbounded polyhedron in Develin & Sturmfels (2004, Lemma 10), whosebounded cells determine the tropical convex hull of the points in D.",
  "Classification Fan": "In we have seen how we can understand tropical rational functions g h via tropical signomialsf by separating the N terms of f into n positive and m negative terms. This defines g and h respectively,such that f = g h and N = n + m. This procedure subdivides the regions defined by T (f) into positiveand negative regions. In terms of the activation patterns, this amounts to a coloring of the nodes [N] aspositive or negative nodes. In this section, we consider the classification fan, the fan which arises throughthe coloring of the nodes. In analogy to the linear case, we will consider the level sets and sublevel sets ofthe 0/1-loss function.",
  "Dividing the Parameter Space": "Let D Rd be a finite set of points, N N and fix n, m N1 such that n + m = N. We split theparameter space into parameters of the numerator g, which we denote ai, si for i [n] and parametersof the denominator h, which are given by bj = an+j, tj = sn+j for j [m]. Given a vector of parameters = (a1, s1, . . . , an, sn, b1, t1, . . . , bm, tm) (d, n, m), this defines a numerator g(x) = maxi[n](ai+ si, x )and denominator h(x) = maxj[m](bj + tj, x ), such that f = g h. Given an activation pattern Gwith nodes V (G) = D [N], the split n + m = N induces a coloring of the nodes [N] into [n] [m]. Definition 6.1 (Activation Pattern of Tropical Rational Function). The activation pattern of (g h, D)is the bipartite graph G = (V (G), E(G)) on nodes V (G) = D ([n] [m]) with edges E(G) = {pi |p activates the ith term of g} {pj | p activates the jth term of h}.",
  "(d, n, m)": "Lemma 6.3. Fix a partition [N] = [n] [m] and an activation pattern G of tropical rational functions.Then for any CD(G) it holds that (g h)(p) 0 if and only if pi E(G) for some i [n], and(g h)(p) 0 if and only if pj E(G) for some j [m]. The inequality is strict if and only if the setof neighbors of p in G is monochromatic, i.e. N(p; G) [n] or N(p; G) [m]. Proof. If maxi[n],j[m](ai + si, p, bj + tj, p) = ai + si, p then g(p) h(p) for all i [n] suchthat pi E(G). This inequality is strict if and only if the maximum is not attained in any term of h(p).Similarly, g(p) h(p) for all j [m] such that pj E(G). Definition 6.4 (Classification Fan). The classification fan D(n, m)of a finite data set D Rd andtropical rational functions with n monomials in the numerator and m monomials in the denominator is theset of all activation cones in parameter space (d, n, m) of tropical rational functions.",
  "The Space of Dichotomies": "In this section, we subdivide the parameter space (d, n, m) into sets, each corresponding to those parameterswhich classify the data according to a fixed target dichotomy. These (open) sets generalize the chambersof the hyperplane arrangement from . We will also describe indecision surfaces as analogs of thehyperplanes in the arrangement, which will turn out to be decision boundaries inside the parameter space.",
  "We will see that the indecision surface plays the role of the hyperplane (1, p) from the linear case (cf.) in this more general setup": "Theorem 6.6. The indecision surface S(p) is a sign-mixed subfan of the normal fan of (p) of dimension(n + m)(d + 1) 1. It divides the parameter space (d, n, m) into two open connected components S+(p) ={ (d, n, m) | (g h)(p) > 0} and S(p) = { (d, n, m) | (g h)(p) < 0}.",
  "i[n] ai spi": "j[m] bj tpjin indeterminates ai, si, bj, tj.The Newton polytope of this tropicalrational function is the simplex (p).We use the notation from the proof of Theorem 5.7, and fix apartition [N] = [n] [m] as explained in .1. Theorem 4.2 implies that S(p) is a polyhedral fan,whose maximal cones are dual to edges conv(vi, vj) where i [n] is a monomial of g and j [m] is amonomial of h.The Euclidean closure of the region S+(p) is the union of all normal cones of verticesvi, i [n] and since (p) is a simplex, this union is connected. Similarly, the closure of S(p) is the unionof normal fans of vj, j [m].",
  "Corollary 6.7. The arrangement of indecision surfaces S(p) over all p D divides the parameter spaceinto open sets CD (d, n, m) over all dichotomies C {+, }M": "This arrangement can be viewed as the true analog of the hyperplane arrangement HD from the linear case,and CD (d, n, m) plays the role of an open chamber. In .3 we will fix a target dichotomy C andstudy (the closure of) the space CD (d, n, m). We will see that this space is disconnected (cf. Theorem 6.11),but it allows a natural fan structure which is inherited from the classification fan D(n, m). The subdivision into these different subfans relates to the growth function and Vapnik-Chervonenkis dimen-sion (Vapnik & Chervonenkis, 1971). This is a fundamental concept in statistical learning theory whichrelates the complexity of a function class with the generalization ability of any learning algorithm basedon that function class.Let c(n, m, D) = |{C | CD (d, n, m) = }| denote the number of dichotomieswhich can be attained by tropical rational functions with n + m terms on the data D. The growth functionn,m : N N is given by n,m(M) = max(c(D, n, m) | D Rd, |D| = M). The VC-dimension of tropicalrational functions is max(M | n,m(M) = 2M). To compute the growth function, a common strategy is tocount the number of non-empty regions c(D, n, m) for a given data set D and then maximize this numberover the choice of the data set having a fixed cardinality M. We refer the reader to Anthony & Bartlett(1999) for an overview of these techniques, and Bartlett et al. (2019) for recent bounds on the VC dimensionof neural networks with piecewise linear activation functions.",
  "Classifying Points Correctly": "We now fix a target dichotomy C {+, }M of the data. The dichotomy divides the data points into twosets DC+ = {pi D | Ci = +} and DC = D \\DC+ . An activation pattern G of (g h, D) is compatible withC if N(p; G) [n] for all p DC+and N(p; G) [m] for all p DC . An activation pattern is weaklycompatible with C if N(p; G) [n] = for all p DC+and N(p; G) [m] = for all p DC . Definition 6.8 (Perfect Classification Fan). The perfect classification fan 0D(n, m) is the subfan of theclassification fan consisting of those closed cones whose activation patterns are weakly compatible withC. In other words, 0D(n, m) is the restriction of the classification fan onto the set CD (d, n, m) = { (d, n, m) | g(p) h(p) p DC+ , g(p) h(p) p DC }. The wisdom behind this notation will become clear in .4, where we consider level-sets of the 0/1-loss.We have chosen to consider activation cones CD(G) as closed cones. As a consequence, we obtain lower-dimensional cones on the boundary of CD (d, n, m), whose activation patterns are only weakly compatiblewith C. On the other hand, this certifies nice geometric properties of the perfect classification fan.",
  "Proposition 6.9. The perfect classification fan 0D(n, m) is pure, i.e. every inclusion-maximal cone isfull-dimensional": "Proof. Any lower-dimensional cone in 0D(n, m) is the intersection of two full-dimensional cones from theactivation fan. Let CD(G), CD(H) be two full-dimensional cones of the activation fan. We show that ifCD(G), CD(H) 0D(n, m) then CD(G) CD(H) 0D(n, m). Since CD(G), CD(H) are maximal, Corol-lary 5.12 implies that CD(G), CD(H) 0D(n, m) if and only if G, H are compatible with the target di-chotomy C. Therefore, if CD(G) 0D(n, m) then there exists some p+G DC+such that N(p+G; G) [m]or pG DCsuch that N(pG; G) [n].Similarly, CD(H) 0D(n, m) implies that there exists somep+H DC+such that N(p+H; H) [m] or pH DCsuch that N(pH; G) [n].Let L = G H.Then CD(G) CD(H) = CD(L), and since E(L) E(G) E(H) we have that N(p+G; L) [m] = orN(p+H; L) [m] = or N(pG; L) [n] = or N(pH; L) [n] = , i.e. L is not weakly compatible withC. The perfect classification fan can be viewed as a subfan of the activation fan, and its full-dimensional conesare thus dual to vertices of the activation polytope. To describe these vertices, recall that PD(n + m) =Mk=1 (pk). Under the partition of the parameters, each simplex (pi) has vertices vki , i [n] and vkj , j [m], and, similarly to the construction in , we label each of these vertices with sgn(vki ) = + fori [n] and sgn(vkj ) = for j [m]. Each vertex v of PD(n + m) can be written uniquely as v = Mk=1 vkl(k)for indices l(k) [n] [m] and we equip v with the dichotomy d(v) = (sgn(v1l(1)), . . . , sgn(vMl(M))).",
  "Theorem 6.10. A vertex v of PD(n + m) is dual to a full-dimensional cone of 0D(n, m) if and only ifd(v) = C": "Proof. A vertex v has d(v) = C if and only if v lies in the intersection of the normal cones of vkl(k) for allk [M] and sgn(vkl(k)) = Ck. By the proof of Theorem 5.7, this is equivalent to CD(G) being the normalcone of v, where G is compatible with C. In the case of linear classifiers, the set of perfect solutions is the single polyhedral cone in the hyperplanearrangement HD which corresponds to the dichotomy C. In contrast, the perfect classification fan is anentire polyhedral fan. Clearly, as we consider closed polyhedral cones, they always intersect in the origin.We thus consider a stronger notion for polyhedral fans. A pure d-dimensional polyhedral fan is stronglyconnected if for all maximal cones C, D there exists a sequence of maximal cones C = C0, C1, . . . , Ck, Ck+1 =D such that dim(Ci Ci+1) = d 1. Any fan decomposes into strongly connected components, i.e. inclusion-maximal subfans of which are strongly connected. The strongly connected components of the perfectclassification fan are in bijection with the connected components of CD (d, n, m), which is the interior of thesupport of 0D(n, m).",
  "Theorem 6.11. The perfect classification fan is not always strongly connected": "Proof. Consider the data set D = {p1, p2, p3, p4} with p1 = (0, 0), p2 = (1, 1), p3 = (2, 2), p4 = (3, 3), andthe target dichotomy is C = (+, , , +). The perfect classification fan 0D(2, 2) (2, 2, 2) consists of 8cones of dimension 12 (the maximal dimension), which are divided into two strongly connected components:The intersection of any cone from the first connected component and any cone from the second componentis solely contained in the lineality space of the fan. The activation patterns of the 8 cones are shown in. In this example we can identify two fundamentally different types of cones, assigning p2, p3 eitherto the same negative index or to two separate negative indices. Then we have discrete symmetries of theparametrization via permutation of the positive indices i1, i2 and permutation of the negative indices j1, j2.The permutation of j1, j2 does not strongly disconnect the set, but the permutation of i1, i2 does. In Theorem 5.15 we have seen that the trivial upper bound for the number of maximal cones in the acti-vation fan is attained if the data points are affinely independent. We now obtain an analogous result forthe classification fan, however, the following statement does not require the entire data set to be affinelyindependent.",
  "has at most n|DC+ |m|DC | cones of maximal dimension. This bound is attained if and only if DC+ , DCarelinearly separable and both DC+and DCare affinely independent sets": "Proof. Since 0D(n, m) is a subfan of the activation fan D(n + m), Corollary 5.12 implies that the conesof maximal dimension are labeled by activation patterns G such that N(G; p) = {i(p)} [n] for p DC+and N(G, p) = {j(p)} [m] for p DC . Thus, the number of maximal cones is at most n|DC+ |m|DC |.Any affine dependency within DC+or DCforbids at least one such graph. This can be proven by followingthe argument in the proof of Theorem 5.15, namely that if DC+ , DCare not linearly separable, then theirconvex hulls intersect, and Theorem 5.13 (i) implies the existence of a forbidden graph. Thus, the boundis not attained. We now show that the bound can be attained for affinely independent sets DC+and DC ,which are linearly separable. Let G be a bipartite graph in which every point in D is incident to exactlyone edge, connecting every point in DC+with a node in [n] and every point in DCwith a node in [m].Let l(x) = c + u, x be the equation defining a separating hyperplane, i.e. l(p+) > 0 and l(p) < 0 forall p+ DC+ , p DC . Since the points in DC+are affinely independent, there exists an affine functionfi(x) = di + vi, x for every i [n], such that fi(p+) = 0 for all p+ N(i; G) and fi(p+) < 0 for allp+ DC+ \\N(i; G). Similarly, there exists an affine function fj(x) = ej + wj, x for every j [m] such thatfj(p) = 0 for all p N(j; G) and fj(p) < 0 for all p DC \\N(j; G). Since l(p) < 0 for all p DCwe can choose a scalar > 0 such that for all p DCholds l(p) > maxi[n] fi(p). Similarly, sincel(p+) > 0 for all p+ DC+ we can choose > 0 such that for all p+ DC+ holds l(p+) > maxj[m] fj(p+).",
  "Sublevel Sets of the 0/1-Loss Function": "Recall that the 0/1-loss function counts the number of mistakes of any function f with respect to the targetdichotomy C, i.e. errC() = |{i [M] | sgn(f(pi)) = Ci }|. If f = g h is a tropical rational functioncontained in a cone CD(G), then errC is constant along CD(G). We thus extend the function errC to conesand activation patterns. If CD(G) is maximal, then errC(G) counts the number of edges in G between DC+and [m], and between DCand [n]. Definition 6.14. The kth level set is the polyhedral fan kD(n, m) = CD(G), where the union runs over allactivation patterns G such that errC(G) = k. We define the kth sublevel set as kD (n, m) = kk=0 kD(n, m).",
  "Note that the corresponding tropical rational functions satisfy f(p) = f(p). Thus, f makes a mistakeat p if and only if f classifies p correctly, and vice versa": "Theorem 6.10 implies that the level sets 0D(n, m), 1D(n, m), . . . , n+mD(n, m) induce a partition of thevertices of the activation polytope PD(n + m), and counting the number of vertices in each part we obtaina sequence of natural numbers.In Algebraic Combinatorics one likes to describe sequences which aresymmetric, unimodal or log-concave. Proposition 6.15 allows us to obtain a statement in this spirit:",
  "Corollary 6.16. Let lk denote the number of maximal cones in the kth level set kD(n, n). Then lk = l|D|k,i.e. the sizes of level sets are symmetric": "Recall that Proposition 2.4 shows that in the case of linear classifiers, a cone of k mistakes is always (strongly)connected to a cone of fewer mistakes. We now observe that the analog does not necessarily hold in the moregeneral setup of tropical rational functions. Theorem 6.17. The sublevel sets kD (n, m) are not always strongly connected, even if the data points arein general position. More specifically, let C kD(n, m) be a strongly connected component. It may happenthat all full-dimensional neighbors D D(n, m) of C (which are adjacent through codimension 1) satisfyerrC(D) > k.",
  ": The point configuration from Theorem 6.17 and two tropical hypersurfaces classifying the pointsperfectly (left) and according to G (right)": "Proof. To be precise, here we consider the standard notion of general position: M points in Rd are in generalposition if no k of them, for k d+1, are contained in an affine subspace of dimension strictly less than k1.We give an example of a configuration of points in general position which can be classified perfectly, for whichhowever there exists a cone CD(G) with errC(CD(G)) = 1 from which there exist no (weakly) decreasing pathto any cone with 0 mistakes. Let DC+ = {p1 = (2, 3), p2 = (3, 3), p5 = (0, 0), p8 = (7, 3), p9 = (3, 4)}and DC = {p3 = (1, 2), p4 = (0, 1), p6 = (2, 1), p7 = (1, 2)}, as shown in . We computed the12-dimensional fan 2D (2, 2) using the software SageMath (Sage Developers, 2021). By definition, we have2D (2, 2) = 0D(2, 2) 1D(2, 2) 2D(2, 2). The perfect classification fan 0D(2, 2) consists of 16 maximalcones, which divide into 8 strongly connected components, and the first level set consists of 304 cones, whichdivide into 28 components. The connected component containing CD(G) consists of 20 maximal cones, butnone of them is adjacent to any of the 16 cones of 0D(2, 2) through codimension 1. More precisely, theconnected component which contains CD(G) intersects 1D(2, 2) in dimension 3, which is the dimension ofthe lineality space of D(2, 2). In this sense, the connected component containing CD(G) intersects theperfect classification fan 0(2, 2) trivially.",
  "Conclusion": "We discussed binary classification by signs of parametric piecewise linear functions from the perspective ofreal tropical geometry. In this context, we described sets of ReLU networks as semialgebraic sets withinsets of tropical rational functions with a fixed number of monomials in the numerator and denominator.We highlighted on the one hand the subdivision of the parameter space by the combinatorial type of therepresented functions, specifically the combinatorial type of the decision boundary, and on the other handthe subdivision of the parameter space by the different activation patterns that are recorded on a givendataset. These two subdivisions are complementary to each other since a priori the decision boundary isindependent of the particular data under consideration. In future work it will be interesting to study how thetwo interact; concretely, for a particular input dataset one might study the types of decision boundaries thatpermit certain types of classifications of that particular input dataset. The discussion of activation patternsgives rise to a generalization of oriented matroids. We showed how this can be used to obtain results on thestructure of the loss landscape. We hope that this work contributes to the further enhancement of the synergies between research on neuralnetworks and polyhedral geometry, particularly as approached in real tropical geometry. As we observed, insome cases the same concepts appear in different communities under different names and leveraging resultsand perspectives from each side can facilitate advances and motivate new interesting future research. Wehope that the presented discussion might serve as a springboard for further explorations including: thecontainment of neural networks with piecewise linear activations within simple parametrizations of tropical",
  "Table of notations": "(d)parameter space for linear classification 4(d, n, m)parameter space for classification by tropical rational function with fixed number of terms 9(d, N)parameter space of tropical signomials 16HDhyperplane arrangement pD(1, p) 4PDpolytope whose normal fan is D 5Csign vector associated to the cone of a hyperplane arrangement 5Dpolyhedral fan arising in linear classification induced by the data 5D(N)activation fan: polyhedral fan arising in classification with tropical rational function with N terms 18PD(N)activation polytope: polytopes whose normal fan is D(N) 18errC()loss in classification with parameters 6CD(G)activation cone: parameter cone with labeling G 17D(n, m)classification fan: a set of cones in parameter space 250D(n, m)perfect classification fan: a subfan of the classification fan 27 Motasem Alfarra, Adel Bibi, Hasan Hammoud, Mohamed Gaafar, and Bernard Ghanem. On the decisionboundaries of neural networks: A tropical geometry perspective. IEEE Transactions on Pattern Analysisand Machine Intelligence, 45(4):50275037, 2023. doi: 10.1109/TPAMI.2022.3201490.",
  "Marco Gori and Alberto Tesi. On the problem of local minima in backpropagation. IEEE Transactions onPattern Analysis and Machine Intelligence, 14(1):7686, 1992. doi: 10.1109/34.107014": "Elisenda Grigsby and Kathryn Lindsey. On transversality of bent hyperplane arrangements and the topo-logical expressiveness of relu neural networks. SIAM Journal on Applied Algebra and Geometry, 6(2):216242, 2022. doi: 10.1137/20M1368902. Elisenda Grigsby, Kathryn Lindsey, and David Rolnick. Hidden symmetries of ReLU networks. In Proceed-ings of the 40th International Conference on Machine Learning, volume 202 of Proceedings of MachineLearning Research, pp. 1173411760. PMLR, July 2023. URL",
  "Joey Huchette, Gonzalo Muoz, Thiago Serra, and Calvin Tsay.When deep learning meets polyhedraltheory: A survey, 2023": "Ahmed Imtiaz Humayun, Randall Balestriero, Guha Balakrishnan, and Richard G. Baraniuk. Splinecam:Exact visualization and characterization of deep network geometry and decision boundaries. In Proceedingsof the IEEE/CVF Conference on Computer Vision and Pattern Recognition (CVPR), pp. 37893798, June2023.URL Philipp Jell, Claus Scheiderer, and Josephine Yu.Real Tropicalization and Analytification of Semialge-braic Sets. International Mathematics Research Notices, 2022(2):928958, May 2020. doi: 10.1093/imrn/rnaa112.",
  "Anita Kripfganz and R. Schulze. Piecewise affine functions as a difference of two convex functions. Opti-mization, 18(1):2329, January 1987. doi: 10.1080/02331938708843210": "Rohith Kuditipudi, Xiang Wang, Holden Lee, Yi Zhang, Zhiyuan Li, Wei Hu, Rong Ge, and Sanjeev Arora.Explaining landscape connectivity of low-cost solutions for multilayer nets. In Advances in Neural In-formation Processing Systems, volume 32. Curran Associates, Inc., 2019. URL Bo Liu.Spurious local minima are common for deep neural networks with piecewise linear activations.IEEE Transactions on Neural Networks and Learning Systems, pp. 113, 2022. doi: 10.1109/TNNLS.2022.3204319.",
  "Guido Montfar. Notes on the number of linear regions of deep neural networks. SampTA 2017 SpecialSession Mathematics of Deep Learning, 2017": "Guido Montfar, Razvan Pascanu, Kyunghyun Cho, and Yoshua Bengio.On the number of linear re-gions of deep neural networks. In Advances in Neural Information Processing Systems, volume 27. Cur-ran Associates, Inc., 2014. URL Guido Montfar, Yue Ren, and Leon Zhang. Sharp bounds for the number of regions of maxout networksand vertices of Minkowski sums. SIAM Journal on Applied Algebra and Geometry, 6(4):618649, 2022.doi: 10.1137/21M1413699. Quynh Nguyen, Mahesh Chandra Mukkamala, and Matthias Hein. Neural networks should be wide enoughto learn disconnected decision regions. In Proceedings of the 35th International Conference on MachineLearning, volume 80 of Proceedings of Machine Learning Research, pp. 37403749. PMLR, July 2018. URL Quynh Nguyen, Pierre Brchet, and Marco Mondelli.When are solutions connected in deep net-works?In Advances in Neural Information Processing Systems, volume 34, pp. 2095620969. Cur-ran Associates, Inc., 2021. URL Razvan Pascanu, Guido Montfar, and Yoshua Bengio. On the number of response regions of deep feedforward networks with piece-wise linear activations. In International Conference on Learning Representa-tions, 2014. URL",
  "Pawe Piwek, Adam Klukowski, and Tianyang Hu. Exact count of boundary pieces of relu classifiers: Towardsthe proper complexity measure for classification, 2023": "Maithra Raghu, Ben Poole, Jon Kleinberg, Surya Ganguli, and Jascha Sohl-Dickstein. On the expressivepower of deep neural networks. In Proceedings of the 34th International Conference on Machine Learning,volume 70 of Proceedings of Machine Learning Research, pp. 28472854. PMLR, August 2017.URL Johannes Rau, Arthur Renaudineau, and Kris Shaw. Real phase structures on matroid fans and matroidorientations. Journal of the London Mathematical Society, 106(4):36873710, 2022. doi: 10.1112/jlms.12671.",
  "Nils Schlter and Moritz Schulze Darup. Novel convex decomposition of piecewise affine functions. In Proc.of the 21st IFAC World Congress, 2020": "Thiago Serra, Christian Tjandraatmadja, and Srikumar Ramalingam. Bounding and counting linear regionsof deep neural networks.In Proceedings of the 35th International Conference on Machine Learning,volume 80 of Proceedings of Machine Learning Research, pp. 45584566. PMLR, July 2018. URL Ali Siahkamari, Aditya Gangrade, Brian Kulis, and Venkatesh Saligrama. Piecewise linear regression via adifference of convex functions. In Proceedings of the 37th International Conference on Machine Learning,volume 119 of Proceedings of Machine Learning Research, pp. 88958904. PMLR, July 2020. URL Berfin Simsek, Franois Ged, Arthur Jacot, Francesco Spadaro, Clement Hongler, Wulfram Gerstner,and Johanni Brea.Geometry of the loss landscape in overparameterized neural networks:Sym-metries and invariances.In Proceedings of the 38th International Conference on Machine Learning,volume 139 of Proceedings of Machine Learning Research, pp. 97229732. PMLR, July 2021.URL",
  "Oleg Viro. Patchworking real algebraic varieties., November 2006": "Uli Wagner. k-sets and k-facets. In Jacob E Goodman, Jnos Pach, and Richard Pollack (eds.), Surveys onDiscrete and Computational Geometry, volume 453, pp. 443 514. American Mathematical Society, 2008.doi: 10.1090/conm/453. Shuning Wang. General constructive representations for continuous piecewise-linear functions. IEEE Trans-actions on Circuits and Systems I: Regular Papers, 51(9):18891896, 2004. doi: 10.1109/TCSI.2004.834521. Yifei Wang, Jonathan Lacotte, and Mert Pilanci. The hidden convex optimization landscape of regularizedtwo-layer ReLU networks: an exact characterization of optimal solutions. In International Conference onLearning Representations, 2022. URL"
}