{
  "Abstract": "Successful unsupervised domain adaptation is guaranteed only under strong assumptionssuch as covariate shift and overlap between input domains. The latter is often violated inhigh-dimensional applications like image classification which, despite this limitation, con-tinues to serve as inspiration and benchmark for algorithm development. In this work, weshow that training-time access to side information in the form of auxiliary variables canhelp relax restrictions on input variables and increase the sample efficiency of learning atthe cost of collecting a richer variable set. As this information is assumed available onlyduring training, not in deployment, we call this problem unsupervised domain adaptationby learning using privileged information (DALUPI). To solve this problem, we propose asimple two-stage learning algorithm, inspired by our analysis of the expected error in thetarget domain, and a practical end-to-end variant for image classification. We propose threeevaluation tasks based on classification of entities in photos and anomalies in medical im-ages with different types of available privileged information (binary attributes and single ormultiple regions of interest). We demonstrate across these tasks that using privileged infor-mation in learning can reduce errors in domain transfer compared to baselines, be robust tospurious correlations in the source domain, and increase sample efficiency.",
  "Introduction": "Deployment of machine learning (ML) systems relies on generalization from training samples to new instancesin a target domain.When these new instances differ in distribution from the source of training data,performance tends to degrade and guarantees are often weak. For example, a supervised ML model trainedto identify medical conditions in X-ray images from one hospital may work poorly in another hospital ifthe two sites have different equipment or examination protocols (Zech et al., 2018). In the unsuperviseddomain adaptation (UDA) problem (Ben-David et al., 2006), no labeled examples are available from thetarget domain and strong assumptions are needed for success. In this work, we ask: How can access toauxiliary variables during training help solve the UDA problem and weaken the assumptions necessary toguarantee domain transfer? In standard UDA, a common assumption is that the object of the learning task is identical in source andtarget domains but that input distributions differ (Shimodaira, 2000). This covariate shift assumption is",
  "Published in Transactions on Machine Learning Research (09/2024)": "Tuan-Hung Vu, Himalaya Jain, Maxime Bucher, Matthieu Cord, and Patrick Prez Prez. Dada: Depth-aware domain adaptation in semantic segmentation. In 2019 IEEE/CVF International Conference onComputer Vision (ICCV), pp. 73637372, 2019. Xiaosong Wang, Yifan Peng, Le Lu, Zhiyong Lu, Mohammadhadi Bagheri, and Ronald M Summers. Chestx-ray8: Hospital-scale chest X-ray database and benchmarks on weakly-supervised classification and local-ization of common thorax diseases. In Proceedings of the IEEE conference on computer vision and patternrecognition, pp. 20972106, 2017. Yifan Wu, Ezra Winston, Divyansh Kaushik, and Zachary Lipton. Domain adaptation with asymmetrically-relaxed distribution alignment. In International conference on machine learning, pp. 68726881. PMLR,2019. Sang Michael Xie, Ananya Kumar, Robbie Jones, Fereshte Khani, Tengyu Ma, and Percy Liang. In-n-out:Pre-training and self-training using auxiliary information for out-of-distribution robustness. arXiv preprintarXiv:2012.04550, 2020. Yalan Ye, Ziqi Liu, Yangwuyong Zhang, Jingjing Li, and Hengtao Shen. Alleviating style sensitivity thenadapting: Source-free domain adaptation for medical image segmentation. In Proceedings of the 30th ACMInternational Conference on Multimedia, MM 22, pp. 19351944, New York, NY, USA, 2022. Associationfor Computing Machinery. John R Zech, Marcus A Badgeley, Manway Liu, Anthony B Costa, Joseph J Titano, and Eric Karl Oermann.Variable generalization performance of a deep learning model to detect pneumonia in chest radiographs:a cross-sectional study. PLoS medicine, 15(11):e1002683, 2018.",
  "Privileged Information in Domain Adaptation": "In unsupervised domain adaptation (UDA), the goal is to learn a hypothesis h to predict outcomes (orlabels) Y Y for problem instances represented by input covariates X X, drawn from a target domainwith density T (X, Y ). During training, we have access to labeled samples (x, y) only from a source domainS(X, Y ) and unlabeled samples x from T (X). As a running example, we think of S and T as radiologydepartments at two different hospitals, of X as the X-ray image of a patient, and of Y as the diagnosis madeby a radiologist after analyzing the image.",
  "mustachemakeup": ": Examples of domain adaptation tasks with different types of privileged information (PI). Duringtraining, input samples X and PI W are drawn from both source and target domains. Labels Y are onlyavailable from the source domain. At test time, a target sample X is observed. We consider three types ofPI: binary attribute vectors, a single region of interest, and multiple regions of interest.",
  "where we use the subscript convention Ep(X)[f(X)] =": "xX p(x)f(x)dx to denote an expectation of somefunction f over a density p on the domain X. A consistent solution to the UDA problem returns a minimizerof Equation 1 without ever observing labeled samples from T . However, if S and T are allowed to differarbitrarily, finding such a solution cannot be guaranteed (Ben-David & Urner, 2012). To make the problemfeasible, we assume that covariate shift (Shimodaira, 2000) holdsthat the labeling function is the same inboth domains, but the covariate distributions differ.",
  "x X : T (X = x) = S(X = x) and x X : T (Y | x) = S(Y | x)": "In our example, covariate shift means that radiologists at either hospital would diagnose two patients withthe same X-ray in the same way, but that the radiologists may encounter different distributions of patientsand images. To guarantee consistent learning without further assumptions, these distributions cannot be toodifferentthe source input domain S(x) must sufficiently overlap the target input domain T (x).",
  "DALUPI()": "Covariate shift and domain overlap with respect to X guarantee that the target risk RT can be identifiedby the sampling distribution described above, and thus, that a solution to Equation 1 may be found. Hence,they have become standard assumptions, used by most informative guarantees (Zhao et al., 2019). Overlap is often violated in high-dimensional problems such as image classification, partly due to irrelevantinformation that has a spurious association with the label Y (Beery et al., 2018; DAmour et al., 2021).In X-ray classification, it may be possible to perfectly distinguish hospitals (domains) based on protocol orequipment differences manifesting in the images (Zech et al., 2018). There are no guarantees for optimalUDA in this case. Some guarantees based on distributional distances do not rely on overlap (Ben-Davidet al., 2006; Long et al., 2013), but do not guarantee optimal learning either (Johansson et al., 2019). Still, an image X may contain information W which is both sufficient for prediction and supported inboth domains. For X-rays, this could be a region of pixels indicating a medical condition, ignoring partsthat merely indicate differences in protocol (Zech et al., 2018). The learner does not know how to find thisinformation a priori, but it can be supplied during training as added supervision. A radiologist could indicateregions of interest W using bounding boxes during training (Irvin et al., 2019), but would not be availableto annotate images at test time. As such, W is privileged information (Vapnik & Vashist, 2009).",
  "Unsupervised Domain Adaptation With Privileged Information": "Learning using privileged information, variables that are available only during training but not at testtime, has been shown to improve sample efficiency in diverse settings (Vapnik & Izmailov, 2015; Pechyony &Vapnik, 2010; Jung & Johansson, 2022). Next, we show that privileged information can also improve UDA byproviding identifiability of the target riskallowing it to be computed from the sampling distributionevenwhen overlap is not satisfied in X. We define domain adaptation by learning using privileged information (DALUPI) as follows. During train-ing, learners observe samples of covariates X, labels Y and privileged information W W from S ina dataset DS = {(xi, wi, yi)}mi=1, as well as samples of covariates and privileged information from T ,DT = {(xi, wi)}ni=1.At test time, trained models only observe covariates x T (X) and our learninggoal remains to minimize the target risk, see Equation 1. We justify access to privileged information from T ,but not labels, by pointing out that it is often easier to annotate observations with privileged information Wthan with labels Y . For example, a non-expert may be able to reliably recognize the outline of an animal inan image, indicating the pixels W corresponding to it, but not identify its species (Y ); see , whereit would likely be easier to identify the location of the cat in the image than to identify its breed.",
  "!": ": An illustration of domain overlap being more plausible when we consider appropriate forms ofprivileged information W, such as a region of interest of an image. Source and target domains S, T are hereindoor and outdoor images X and the task is to identify the animal Y in the image. Assumption 3 is satisfied when X provides no more information about Y in the presence of W.If weconsider W to be a subset of image pixels corresponding to an area of interest, the other pixels in X may beunnecessary to predict Y . This is illustrated in where the privileged information wi is the region ofinterest indicated by the bounding box ti. Here, overlap is more probable in W than in X, as the extractedpixels mostly show cats. Moreover, when W retains more information, sufficiency becomes more plausiblebut domain overlap in W is reduced. The sufficiency assumption is used to replace T (y | x) with T (y | w) inProposition 1. If sufficiency is violated but it is plausible that the degree of insufficiency is comparable acrossdomains, we can still obtain a bound on the target risk which may be estimated from observed quantities.We give such a result in Appendix F. We expect that some PI can be selected to be sufficient for a given task. However, if this sufficiency cannotbe ensured, the overall performance may decrease, assuming covariate shift with respect to W is not violated.Even so, we still anticipate the generalization error to remain of a comparable magnitude. If covariate shiftis violated in W, further performance declines are expected, as the problem becomes more complex and weare not guaranteed to identify the optimal hypothesis (Johansson et al., 2019).",
  "x,y T (x, y)L(h(x), y)dxdy.We can then marginalize over W to get T (x, y) =T (x)ET (W |x)[T (y | W) | x] = T (x)": "w:S(w)>0 T (w | x)S(y | w)dw, where the first equality follows bysufficiency and the second by covariate shift and overlap in W. T (x), T (w | x) and S(y | w) are observablethrough training samples. That hT is a minimizer follows from the first-order condition. See Appendix C. Proposition 1 shows that there are conditions where privileged information allows for identification of target-optimal hypotheses where identification is not possible without it, i.e., when overlap is violated in X. W",
  "A Two-stage Algorithm and Its Risk": "In light of Proposition 1, a natural learning strategy is to model privileged information as a function of theinput, T (W | x), and the outcome as a function of privileged information, g(w) ES[Y | w], and combiningthese. In the case where W is a deterministic function of X, T (W | x) is a map f : X W, which may beestimated as a regression f and combined with the outcome regression to form h = g( f(X)). We may findsuch functions f, g by separately minimizing the empirical risks",
  "Hypothesis classes F, G may be chosen so that H = {h = g f; (f, g) F G} has a desired form. Notethat LW and LY may in general be different loss functions": "We can bound the generalization error of estimators h = g f when W RdW and the loss is the squaredloss. We do this by placing an assumption of Lipschitz smoothness on the space of prediction functions:g G, w, w W : g(w) g(w)2 Mw w2. To arrive at a bound, we first define the -weightedempirical risk of the outcome model g in the source domain, RY,S (g) = 1",
  "mmi=1 (wi)L_W(g(wi), yi) where is the density ratio of T and S, (w) = T (w)": "S(w) . When the density ratio is unknown, we may use densityestimation (Sugiyama et al., 2012) or probabilistic classifiers to estimate it. We arrive at the following result,proven for univariate Y but generalizable to multivariate outcomes. Proposition 2. Suppose that W and Y are deterministic in X and W, respectively, and that Assumptions 13 hold with respect to W. Let G comprise M-Lipschitz mappings g : W Y with W RdW , and let the lossbe the squared Euclidean distance, assumed to be uniformly bounded over W. Let (w) = T (w)/S(w) and dand d be the pseudo-dimensions of G and F, respectively. Assume that there are m labeled samples from Sand n unlabeled samples from T . Then, for any h = g f G F, with probability at least 1 ,",
  "Image Classification With Privileged Information": "We use image classification, where X is an image and Y is a discrete label, as proof of concept for DALUPI. Toshow the versatility of our approach, we consider three different instantiations of privileged information W:a binary attribute vector, a single region of interest, or multiple regions of interest. The two-stage estimator,see a, is used in the first two cases. With multiple regions of interest as privileged information, weuse an end-to-end model based on Faster-R-CNN (Ren et al., 2016), see b. We detail each settingbelow and illustrate them in .",
  "Binary Attributes as PI": "First, we consider the case where each image xi is accompanied by privileged information in the form ofa binary vector wi {0, 1}d indicating the presence of d attributes in the image. In this setting, we candirectly apply our two-stage estimator (Equation 2). For the first estimator f, we use a convolutional neuralnetwork (CNN) trained on observations from T (and possibly S) to output a vector of attributes wi from theinput xi. For the second estimator g, we use a multi-layer perceptron classifier, trained on source domainobservations, that predicts the image label yi given the vector of attributes wi. We use the categoricalcross-entropy loss to train both f and g. The resulting classifier, h(x) = g( f(x)), is subsequently evaluatedon target domain images.",
  "Single Region of Interest as PI": "Next, we consider privileged information as a subset of pixels wi, taken from the image xi and associatedwith an object or feature that determines the label yi {1, . . . , K}. In our experiments, this PI is providedas a single bounding box with coordinates ti R4 enclosing the region of interest wi. Here, we use twoCNNs, d and g, and a deterministic function to approximate the two-stage estimator (Equation 2). Thenetwork d is trained to output bounding box coordinates ti as a function of the input xi, and the pixelswi within the bounding box are extracted from xi and resized to pre-specified dimensions through . Thecomposition of these two functions, f(xi) = (xi, d(xi)), returns wi. The second network g is trained topredict yi given the pixels wi contained in a bounding box ti based on observations from S. We use the meansquared error loss for d and the categorical cross-entropy loss for g. Finally, h(x) = g( f(x)) is evaluated ontarget domain images where the output of f is used for prediction with g. See Appendix A.1 for furtherdetails.",
  "Multiple Regions of Interest as PI": "Finally, we consider a setting where privileged information indicates multiple regions of interest in an image.We use this PI in multi-label classification problems where the image xi is associated with one or morecategories k from a set {1, . . . , K}, encoded in a multi-category label yi {0, 1}K (e.g., indicating findings",
  "(b) End-to-end estimator": ": A schematic representation of the train and test flow for DALUPI using (a) the two-stage estimatorpresented in .2 and (b) an end-to-end architecture based on Faster R-CNN (Ren et al., 2016). Inthe two-stage procedure, the networks f and g are learned through empirical risk minimization of LWand LY , respectively. At test time, f and g are combined into h = g( f(X)). The end-to-end estimatoruses a region proposal network (RPN) to produce regions of interest in the input image X. The RPN,which serves as the network f, is followed by a detection network g that predicts the class of any objectwithin a region proposal. Training is guided by regression losses LPRNreg ( T, T) and Ldetreg( TU, T), as well as byclassification losses LPRNcls( P, P) and Ldetcls ( PU). Here, T and T denote ground-truth and predicted boundingbox coordinates, respectively, and TU are the predicted coordinates for a region proposal with ground-truthlabel U. Further, P is the RPNs predicted probability that a region proposal contains an object, P is abinary label assigned to the proposal based on its overlap with ground-truth bounding boxes, and Pu is theprobability of the ground-truth class U within the proposal, as predicted by the detection network. of one or more diseases). The partial label yi(k) = 1 indicates the presence of features or objects in theimage from category k. In our entity classification experiment, an object j of class k [K] in the image, sayBird, will be annotated by a bounding box tij R4 surrounding the pixels of the bird, and an object labeluij = k. In X-ray classification, tij can indicate an abnormality j in the X-ray image, and uij {1, . . . , K}the label of the finding (e.g., Pneumonia). To make full use of privileged information, we train a deep neural network h(x) = g( f(x)), where f producesa set of bounding box coordinates tij and extracts the pixels wij associated with each tij, and where gpredicts a label uij for each wij. To this end, we adapt the Faster R-CNN architecture (Ren et al., 2016)which uses a region proposal network (RPN) to generate regions that are fed to a detection network forclassification and refined bounding box regression. A CNN backbone in combination with the RPN regionof interest pooling serves as the subnetwork f, producing estimates wi of the privileged information for animage xi. For the detection network, which corresponds to the subnetwork g, we use Fast-RCNN (Girshick,2015). Privileged information adds supervision through regression losses LRPNreg (t, t) and Ldetreg(tu, t) for region propos-als t and class-specific bounding box coordinates tu. We use the smooth L1 loss defined by Girshick (2015) for",
  "Experiments": "We evaluate the empirical benefits of learning using privileged information, compared to the other dataavailability settings in , across four UDA image classification tasks where PI is available in the formsdescribed in . Widely used datasets for UDA evaluation like OfficeHome (Venkateswara et al.,2017) and large-scale benchmark suites like DomainBed (Gulrajani & Lopez-Paz, 2021), VisDA (Peng et al.,2017) and WILDS (Koh et al., 2021) do not include privileged information and cannot be used for evaluationhere. Thus, we first compare our method to baselines on the recent CelebA task (Xie et al., 2020) whichincludes PI in the form of binary attributes (.1). Additionally, we propose three new tasks based onwell-known image classification data sets with regions of interest as PI (.24.4). In .1 and4.2, we use the two-stage estimator with the subnetwork f based on the ResNet-18 architecture (He et al.,2016a). In .3 and 4.4, we use our variant of Faster R-CNN with a ResNet-50 backbone. Our goal is to collect evidence that DALUPI improves adaptation bias and sample efficiency compared tomethods that do not make use of PI. We choose baselines to illustrate these two disparate settings. First,we compare DALUPI to supervised learning baselines, SL-S and SL-T, trained on labeled examples fromthe source and target domain, respectively. SL-S is a simple but strong baseline: On benchmark suites likeDomainBed and WILDS, there is still no UDA method that consistently outperforms SL-S (ERM) withouttransfer learning (Gulrajani & Lopez-Paz, 2021; Koh et al., 2021). SL-T serves as an oracle comparison sinceit uses labels from the target domain which are normally unavailable in UDA. Second, we compare DALUPIto two UDA methodsdomain adversarial neural networks (DANN) (Ganin et al., 2016) and the margindisparity discrepancy (MDD) (Zhang et al., 2019)which have theoretical guarantees but do not make useof PI. These baselines are all based on the ResNet architecture. In .1, we compare DALUPI also toIn-N-Out (Xie et al., 2020), which was designed to make use of auxiliary (privileged) attributes for trainingdomain adaptation models. We do not include this model in other experiments as it was not designed touse regions of interest as privileged information. The exact architectures of all models and baselines aredescribed in Appendix A, along with details on experimental setup and hyperparameters. For each task and task-specific setting (label skew, amount of privileged information, etc.), we train 10 modelsfrom each relevant class using hyperparameters randomly selected from given ranges (see Appendix A). ForDANN and MDD, the trade-off parameter, which regularizes domain discrepancy in representation space,increases from 0 to 0.1 during training; for MDD, the margin parameter is set to 3. All models are evaluatedon a held-out validation set from the source domain and the best-performing model in each class is thenevaluated on held-out test sets from both domains. For SL-T, we use a held-out validation set from the targetdomain. We repeat this procedure over 5 or 10 seeds, controlling the data splits and the random numbergeneration.We report accuracy and area under the ROC curve (AUC) with 95 % confidence intervalscomputed by bootstrapping over the seeds.",
  "Celebrity Photo Classification With Binary Attributes as PI": "In the case where privileged information is available as binary attributes, we follow Xie et al. (2020) whointroduced a binary classification task based on the CelebA dataset (Liu et al., 2015), where the goal isto predict whether the person in an image has been identified as male or female (Y ) in one of the binary",
  "SL-TSL-SDALUPIDANNMDD": ": Digit classification. Target domain accu-racy as a function of association between back-ground and label in S.As the skew increases,the target-domain performance of the non-privilegedmodels deteriorates. attributes that accompanies the data sets photos of celebrities (X). Like Xie et al. (2020), we use 7 of the40 other attributes (Bald, Bangs, Mustache, Smiling, 5_o_Clock Shadow, Oval_Face, and Heavy_Makeup)as a vector of privileged information W {0, 1}7. The target and source domains are defined by peoplewearing (T ) and not wearing (S) a hat. The respective datasets contain 3,000 and 2,000 images. An extra30,000 unlabeled source samples are available to train estimators (DALUPI and In-N-Out) that can utilizeprivileged information from both source and target. More details can be found in (Xie et al., 2020) and inAppendix A.3. shows the target accuracy for each model. We observe that when DALUPI is provided with PI fromboth source and target, it performs comparably to the best-performing In-N-Out model proposed by Xieet al. (2020), while outperforming other feasible baselines on average. Confidence intervals overlap for allfeasible models. Notably, the best-performing In-N-Out models require four or more rounds of training toachieve their results (baseline, auxiliary input, auxiliary output pre-training, tuning and self-training) (Xieet al., 2020). Both DALUPI and In-N-Out benefit from access to privileged information from both the sourceand target domain (pre/self-training for In-N-Out). Finally, it is worth noting that neither covariate shift, nor sufficiency are likely to hold with respect to Win this task. Specifically, photos with none of the 7 attributes active, w = 0, have different label rates andmajority label in S and T (the rates of labels are YS = 0.64 and YT = 0.46, respectively) and thereforeP(Y |W) is not constant, i.e. covariate shift is violated. In addition, the best model we have found trainedon W alone achieves only 65 % accuracy, compared to the results in sufficiency is unlikely to hold.Thus, DALUPI is robust to violations of these assumptions.",
  "Digit Classification With Single Region of Interest as PI": "We construct a synthetic image dataset, based on the assumptions of Proposition 1, to verify that thereare problems where DALUPI is guaranteed successful transfer but standard UDA is not. Starting fromCIFAR-10 (Krizhevsky, 2009) images upscaled to 128 128, we insert a random 28 28 digit image fromthe MNIST dataset (Lecun, 1998), with a label in the range 04, into a random location of each CIFAR-10image, forming the input image X (see (top) for examples). The label Y {0, . . . , 4} is determinedby the MNIST digit. We store the bounding box around the inserted digit image and use the pixels containedwithin it as privileged information W during training. The domains are constructed using CIFAR-10s firstfive and last five classes as source and target backgrounds, respectively. Both source and target datasetscontain 15,298 images each. To increase the difficulty of the task, we make the digit be the mean color of the",
  "To understand how successful transfer depends on domain overlap and access to sufficient privileged infor-mation, we include a skew parameter [ 1": "c, 1], where c = 5 is the number of digit classes, which determinesthe correlation between digits and backgrounds.For a source image i with digit label Yi {0, . . . , 4},we select a random CIFAR-10 image with class Bi {0, . . . , 4} with probability P(Bi = b | Yi = y) ={, if b = y; (1 )/(c 1), otherwise}. For target images, digits and backgrounds are matched uniformlyat random. The choice = 1 c yields a uniform distribution and = 1 is equivalent to the background carryingas much signal as the privileged information. We hypothesize that = 1 is the worst possible case whereconfusion of the model is likely, which would lead to poor adaptation under domain shift. In , we observe the conjectured behavior. As the skew and the association between backgroundand label increases, the performance of SL-S decreases rapidly on the target domain. At = 1, it performsno better than random guessing, likely because the model has learned to associate spurious features in thebackground with the label of the digit. We also observe that DANN and MDD deteriorate in performancewith increased correlation between the label and the background. In contrast, DALUPI is unaffected by theskew as the subset of pixels extracted by f only carries some of the background with it, while containingsufficient information to make good predictions. Interestingly, DALUPI also seems to be as good or slightlybetter than the oracle SL-T in this setting. This may be due to improved sample efficiency from using PI.",
  "Entitity Classification With Multiple Regions of Interest as PI": "Next, we consider multi-label classification of the presence of four types of entities (persons, cats, dogs, andbirds) indicated by a binary vector Y {0, 1}4 for images X from the MS-COCO dataset (Lin et al., 2014).PI is used to localize regions of interest W related to the entities, provided as bounding box annotations. Wedefine source and target domains S and T as indoor and outdoor images, respectively. Indoor images areextracted by filtering out images from the MS-COCO super categories indoor and appliance that alsocontain at least one of the four main label classes. Outdoor images are extracted using the super categoriesvehicle and outdoor. In total, there are 5,231 images in the source and 5,719 images in the target domain;the distribution of labels is provided in Appendix A.5. Sufficiency is likely to hold in this task because the pixels contained in a bounding box should be sufficientfor an annotator to classify the entity according to the four categories above, irrespective of the pixels outside",
  "of the box. Similarly, covariate shift is likely to hold since the label attributed to the pixels in a boundingbox should be the same, whether the entity is indoor or outdoor": "We study the effect of adding privileged information by first training the end-to-end model in a LUPI setting,using all (x, y) samples from the source domain and increasing the fraction of inputs for which PI is available,nPI(S), from 0 to 1. We then train the model in a DALUPI setting, increasing the fraction of (x, w) samplesfrom the target domain, nPI(T ), from 0 to 1, while keeping nPI(S) = 1. We train SL-S and SL-T using allavailable data and increase the fraction of unlabeled target samples used by DANN and MDD from 0.2 to 1while using all data from the source domain. shows the models source and target domain AUC, averaged over the four entity classes, whenthe UDA models have access to all unlabeled target samples, LUPI to all PI from the source domain, andDALUPI to all PI from both domains. Clearly, DALUPI yields a substantial gain in adaptation. As we seein , the performance of LUPI increases as nPI(S) increases. When additional (x, w) samples fromthe target domain are added, DALUPI outperforms SL-S and approaches the performance of SL-T. We notethat DANN and MDD do not benefit as much from added unlabeled target samples as DALUPI does. Theirweak performance could be explained by difficulties in adversarial training. The gap between LUPI andSL-S for nPI(S) = 0 is anticipated; we do not expect the detection network to work well without boundingbox supervision.",
  "X-ray Classification With Multiple Regions of Interest as PI": "As a real-world application, we study detection of pathologies in chest X-ray images. We use the ChestX-ray8 dataset (Wang et al., 2017) as source domain and the CheXpert dataset (Irvin et al., 2019) as targetdomain.1 As PI, we use the regions of pixels associated with each found pathology, as annotated by domainexperts using bounding boxes. For the CheXpert dataset, only pixel-level segmentations are available, andwe create bounding boxes that tightly enclose the segmentations. It is not obvious that the pixels withinsuch a bounding box are sufficient for classifying the pathology. For this reason, we suspect that some ofthe assumptions of Proposition 1 may be violated. However, as we find below, DALUPI improves empiricalperformance compared to baselines for small training sets, thereby demonstrating increased sample efficiency. We consider the three pathologies that exist in both datasets and for which there are annotated findings:atelectasis (ATL: collapsed lung), cardiomegaly (CM: enlarged heart), and pleural effusion (PE: water aroundthe lung). There are 457 and 118 annotated images in the source and target domain, respectively. We trainDALUPI, DANN and MDD using all these images. SL-S is trained with the 457 source images and SL-T withthe 118 target images as well as 339 labeled but non-annotated target images. Neither SL-S, SL-T, DANN,nor MDD support using privileged information. The distributions of labels and bounding box annotationsare given in Appendix A.6.",
  "Related Work": "Learning using privileged information was first introduced by Vapnik & Vashist (2009) for support vectormachines (SVMs), and was later extended to empirical risk minimization (Pechyony & Vapnik, 2010). Meth-ods using PI, which is sometimes called hidden information or side information, has since been applied inmany diverse settings such as healthcare (Shaikh et al., 2020), finance (Silva et al., 2010), clustering (Fey-ereisl & Aickelin, 2012) and image recognition (Vu et al., 2019; Hoffman et al., 2016). Related conceptsinclude knowledge distillation (Hinton et al., 2015; Lopez-Paz et al., 2016), where a teacher model trainedon additional variables adds supervision to a student model, and weak supervision (Robinson et al., 2020)where so-called weak labels are used to learn embeddings, subsequently used for the task of interest. Further-more, in the realm of NLP, there is the related concept of learning using feature feedback, where additionalannotations that are related to the associated task label are provided (Katakkar et al., 2022; Kaushik et al.,2021). These works are mostly of an empirical nature, and theoretical work on the subject either considerslinear models/SVMs (Poulis & Dasgupta, 2017) or a teacher/student-type setup where additional supervi-sion is given when the model predicts incorrectly (Dasgupta et al., 2018). The use of PI for deep imageclassification has been investigated by Chen et al. (2017) and Han et al. (2023) but these works only coverregular supervised learning where source and target domains coincide. Further, Sharmanska et al. (2014)used regions of interest in images as privileged information to improve the accuracy of image classifiers, butdid not consider domain shift either. Domain adaptation using PI has been considered before with SVMs (Li et al., 2022; Sarafianos et al., 2017),but not with more complex classifiers such as neural networks. Vu et al. (2019) used scene depth as PI insemantic segmentation using deep neural networks. However, they only used PI from the source domainand they did not provide any theoretical analysis. Xie et al. (2020) provide some theoretical results for asimilar setup to ours. However, these are specifically for linear classifiers while our approach holds for anytype of classifier. Motiian (2019) investigated PI and domain adaptation using the information bottleneckmethod for visual recognition. However, their setting differs from ours in that each observation comprisessource-domain and target-domain features, a label and PI. Another related approach is that of subsidiarytasks (Kundu et al., 2022; Ye et al., 2022). However, in these settings the additional tasks performed areused to build a representation that helps with the main task through domain alignment. Our approachinstead seeks to use information which directly relates to the main task.",
  "Discussion": "We have presented DALUPI: unsupervised domain adaptation by learning using privileged information (PI).The framework provides provable guarantees for adaptation under relaxed assumptions on the input features,at the cost of collecting a larger variable set, such as attribute or bounding box annotations, during training.Our analysis inspired practical algorithms for image classification which we evaluated using three kinds ofprivileged information. In our experiments, we demonstrated tasks where our approach is successful whileexisting adaptation methods fail. We observed empirically also that methods using privileged information aremore sample-efficient than comparable non-privileged learners, in line with the literature. In fact, DALUPI",
  "models occasionally even outperform oracle models trained using target labels due to their sample efficiency.Thus, we recommend considering these methods in small-sample settings": "The main contribution of the paper is the proposed learning paradigm for domain adaptation with privilegedinformation. Since common benchmark datasets in UDA lack privileged information related to the learningproblem, we created three new tasks for evaluating our framework, see .24.4, which itself is anotable contribution. We hope that this work inspires the community to develop additional datasets forUDA using privileged information. To avoid assuming that domain overlap is satisfied with respect to input covariates, we require that the label isconditionally independent of the input features given the PIthat the PI is sufficient. This is a limitationwhenever sufficiency is difficult to verify. However, in our motivating example of image classification, adomain expert could choose PI so that sufficiency is reasonably justified.Moreover, in experiments onCelebA, we see empirical gains from our approach even when sufficiency is known to be violated. Anotherlimitation is that we still rely on overlap in the privileged information, W, which may also be violated in somecircumstances. It is more likely that overlap holds for W when, for example, it is a subset of X, as arguedin . Designing experiments to test how sensitive DALUPI is to violations of these assumptions is aninteresting direction for future work. The use of regions of interest as privileged information brings up an interesting point concerning the rela-tionship between the label and the privileged information. In object detection tasks, it is natural to treat thebounding box coordinates as label information. In this work, however, the learning tasks were multi-classand multi-label image classification, not object detection. Producing a perfect box W was not the goal of thelearning task, and the bounding boxes were therefore neither critical for the task nor for the labels. Instead,the bounding boxes were privileged information and our experiments in .24.4 sought to quantifythe value of this added information, compared to not having it. Therefore, we compared our method toimage classification baselines. It is not obvious a priori that learning from object locations improves theadaptation of image classifiers. If there is a lack of PI available to the models one might mitigate this by either 1) using the limited amountof PI that is available to learn g and assume that it is good enough to achieve reasonable overall performance;or 2) using the learned f to create weak PI labels for the inputs that are missing PI, similar to the workof e.g. Robinson et al. (2020). However, one should note that the latter approach might bias the model inunintended ways and, as such, should be undertaken with some caution. In future work, our framework could be applied to a more diverse set of tasks, with different modalitiesof inputs and privileged information to investigate if the findings here can be replicated and extended.Moreover, such work could consider different types and degrees of shifts to further corroborate the stabilityand resistance to noise which we observe here. More broadly, using PI may be viewed as building indomain knowledge in the structure of the adaptation problem and we see this as a promising direction forfurther research.",
  "Ishaan Gulrajani and David Lopez-Paz. In search of lost domain generalization. In International Conferenceon Learning Representations, 2021": "Dongyoon Han, Junsuk Choe, Seonghyeok Chun, John Joon Young Chung, Minsuk Chang, Sangdoo Yun,Jean Y. Song, and Seong Joon Oh. Neglected free lunch - learning image classifiers using annotationbyproducts. In Proceedings of the IEEE/CVF International Conference on Computer Vision (ICCV), pp.2020020212, October 2023. Kaiming He, Xiangyu Zhang, Shaoqing Ren, and Jian Sun. Deep residual learning for image recognition. InProceedings of the IEEE conference on computer vision and pattern recognition, pp. 770778, 2016a.",
  "Geoffrey Hinton, Oriol Vinyals, and Jeff Dean. Distilling the knowledge in a neural network. arXiv preprintarXiv:1503.02531, 2015": "Judy Hoffman, Saurabh Gupta, and Trevor Darrell.Learning with Side Information through ModalityHallucination.In 2016 IEEE Conference on Computer Vision and Pattern Recognition (CVPR), pp.826834. IEEE, 2016. Jeremy Irvin, Pranav Rajpurkar, Michael Ko, Yifan Yu, Silviana Ciurea-Ilcus, Chris Chute, Henrik Mark-lund, Behzad Haghgoo, Robyn Ball, Katie Shpanskaya, et al. Chexpert: A large chest radiograph datasetwith uncertainty labels and expert comparison. In Proceedings of the AAAI conference on artificial intel-ligence, volume 33, pp. 590597, 2019.",
  "Bastian Jung and Fredrik Daniel Johansson. Efficient learning of nonlinear prediction models with time-seriesprivileged information. In Advances in Neural Information Processing Systems, 2022": "Rickard Karlsson, Martin Willbo, Zeshan Hussain, Rahul G. Krishnan, David A. Sontag, and Fredrik D.Johansson. Using time-series privileged information for provably efficient learning of prediction models.In Proceedings of The 25th International Conference on Artificial Intelligence and Statistics 2022, 2021. Anurag Katakkar, Clay H. Yoo, Weiqin Wang, Zachary Lipton, and Divyansh Kaushik. Practical benefits offeature feedback under distribution shift. In Proceedings of the Fifth BlackboxNLP Workshop on Analyzingand Interpreting Neural Networks for NLP, pp. 346355, 2022.",
  "Yanmeng Li, Huaijiang Sun, and Wenzhu Yan. Domain adaptive twin support vector machine learning usingprivileged information. Neurocomputing, 469:1327, 2022": "Tsung-Yi Lin, Michael Maire, Serge Belongie, James Hays, Pietro Perona, Deva Ramanan, Piotr Dollar,and Larry Zitnick. Microsoft COCO: Common Objects in Context. In ECCV. European Conference onComputer Vision, September 2014. Tsung-Yi Lin, Piotr Dollr, Ross Girshick, Kaiming He, Bharath Hariharan, and Serge Belongie. Featurepyramid networks for object detection. In Proceedings of the IEEE conference on computer vision andpattern recognition, pp. 21172125, 2017.",
  "Stefanos Poulis and Sanjoy Dasgupta. Learning with feature feedback: from theory to practice. In Interna-tional Conference on Artificial Intelligence and Statistics (AISTATS), 2017": "S Ren, K He, R Girshick, and J Sun. Faster R-CNN: Towards real-time object detection with region proposalnetworks. IEEE Transactions on Pattern Analysis and Machine Intelligence, 39(6):11371149, 2016. Joshua Robinson, Stefanie Jegelka, and Suvrit Sra. Strength from Weakness: Fast Learning Using WeakSupervision. In Proceedings of the 37th International Conference on Machine Learning, pp. 81278136.PMLR, November 2020. Nikolaos Sarafianos, Michalis Vrigkas, and Ioannis A. Kakadiaris. Adaptive SVM+: Learning with privilegedinformation for domain adaptation. In Proceedings of the IEEE International Conference on ComputerVision (ICCV) Workshops, Oct 2017.",
  "Viktoriia Sharmanska, Novi Quadrianto, and Christoph H. Lampert. Learning to Transfer Privileged Infor-mation. arXiv:1410.0389 [cs, stat], October 2014. arXiv: 1410.0389": "Kendrick Shen, Robbie M Jones, Ananya Kumar, Sang Michael Xie, Jeff Z. Haochen, Tengyu Ma, and PercyLiang. Connect, not collapse: Explaining contrastive learning for unsupervised domain adaptation. InKamalika Chaudhuri, Stefanie Jegelka, Le Song, Csaba Szepesvari, Gang Niu, and Sivan Sabato (eds.),Proceedings of the 39th International Conference on Machine Learning, volume 162 of Proceedings ofMachine Learning Research, pp. 1984719878. PMLR, 1723 Jul 2022.",
  "AExperimental Details": "In this section, we give further details of the experiments.All code is written in Python and wemainly use PyTorch in combination with skorch (Tietz et al., 2017) for our implementations of the net-works.For Faster R-CNN, we adapt the implementation provided by torchvision through the func-tion fasterrcnn_resnet50_fpn. For DANN and MDD, we use the ADAPT TensorFlow implementation(de Mathelin et al., 2021) with a ResNet-50-based encoder. We initially set the trade-off parameter , whichcontrols the amount of domain adaption regularization, to 0 and then increase it to 0.1 in 10,000 gradientsteps according to the formula = (2/(1 + ep) 1)/C, where p increases linearly from 0 to 1, is aparameter specified for each experiment, and C = 2/(1 + e1) 1. For MDD, we fix the margin parameter to 3. The source and target baselines are based on the ResNet-50 architecture when PI is provided asmultiple regions of interest; otherwise, the ResNet-18 architecture is used. The architecture of DALUPI ineach experiment is specified in the respective subsection below. We use the Adam optimizer in all experiments. Learning rate decay is treated as a hyperparameter. ForADAPT models (DANN and MDD), the learning rate is either constant or decayed according to 0/(1 +p)3/4, where 0 is the initial learning rate, p increases linearly from 0 to 1, and is a parameter specifiedin each experiment (see below). For non-ADAPT models, the learning rate is either constant or decayed bya factor 0.1 every nth epoch, where n is another hyperparameter. For all models except LUPI and DALUPI, the classifier network following the encoder is a simple MLP withtwo possible settings: Either it is a single linear layer from inputs to outputs or a three-layer network withReLU activations between the layers. This choice is treated as a hyperparameter in our experiments. Thenonlinear case has the following structure where n is the number of input features:",
  "A.1DALUPI With Two-stage Classifier": "Here, we describe in more detail how we construct our two-stage classifier for image classification whenprivileged information is provided as a single region of interest as in the digit classification task (.2).When privileged information is provided as binary attributes, we can directly learn the two-stageestimator according to Equation 2. In this task, it was found that using the cross entropy loss and usingcontinuous outputs from f provided superior performance compared to other losses. In the digit classificationtask, each image xi has a single label yi {0, . . . , 4} determined by the MNIST digit. Privileged informationis given by a single bounding box with coordinates ti R4 enclosing a subset of pixels wi corresponding tothe digit. The training procedure is summarized in Algorithm 1 and further described below. We first learn d which is a function that takes target image data, xi, and bounding box coordinates, ti, andlearns to output bounding box coordinates, ti, which should contain the privileged information wi. Notethat we do not exactly follow the setup in Equation 2 since we do not need to actually predict the pixelvalues within the bounding box. If we find a good enough estimator of ti we should minimize the loss of f inEquation 2. To obtain the privileged information we apply a deterministic function which crops and scalesan image using the associated bounding box, ti. We can now write the composition of these two functions asf(xi) = (xi, d(xi)) which outputs the privileged information. The function is hard-coded and thereforenot learned. In the second step, we learn g to predict the label from the privileged information wi, which is a croppedversion of xi where the cropping is defined by the bounding box ti around the digit. This cropping andresizing is performed by . When we evaluate the performance of this classifier we combine the two modelsinto one, h(x) = g((x, d(x))). We use the mean squared error loss for learning d and categorical cross-entropy (CCE) loss for g.",
  "A.2DALUPI With Faster R-CNN": "For multi-label classification, we adapt Faster R-CNN (Ren et al., 2016) outlined in and describedbelow. Faster R-CNN uses a region proposal network (RPN) to generate region proposals which are fed to adetection network for classification and bounding box regression. This way of solving the task in subsequentsteps has similarities with our two-stage algorithm although Faster R-CNN can be trained end-to-end. Wemake small modifications to the training procedure of the original model in the end of this section.",
  ": Faster R-CNN (Ren et al., 2016) architecture. The RoI pooling layer and the classification andregression layers are part of the Fast R-CNN detection network (Girshick, 2015)": "The RPN generates region proposals relative to a fixed number of reference boxesanchorscentered atthe locations of a sliding window moving over convolutional feature maps. Each anchor is assigned a binarylabel p {0, 1} based on its overlap with ground-truth bounding boxes; positive anchors are also associatedwith a ground-truth box with location t. The RPN loss for a single anchor is",
  "LRPN(p, p, t, t) := LRPNcls(p, p) + pLRPNreg (t, t),(3)": "where t represents the refined location of the anchor and p is the estimated probability that the anchorcontains an object. The binary cross-entropy loss and a smooth L1 loss are used for the classification lossLRPNclsand the regression loss LRPNreg , respectively. For a mini-batch of images, the total RPN loss is computedbased on a subset of all anchors, sampled to have a ratio of up to 1:1 between positive and negative ditto. A filtered set of region proposals are projected onto the convolutional feature maps. For each proposal, thedetection networkFast R-CNN (Girshick, 2015)outputs a probability p(k) and a predicted bounding boxlocation t(k) for each class k. Let p = (p(0), . . . , p(K)), where",
  "where Ldetcls (p, u) = log p(u) and Ldetreg is a smooth L1 loss. To obtain a probability vector for the entireimage, we maximize, for each class k, over the probabilities of all proposals": "During training, Faster R-CNN requires that all input images x come with at least one ground-truth anno-tation (bounding box) w and its corresponding label u. To increase sample-efficiency, we enable training themodel using non-annotated but labeled samples (x, y) from the source domain and annotated but unlabeledsamples (x, w) from the target domain. In the RPN, no labels are needed, and we simply ignore anchors fromnon-annotated images when sampling anchors for the loss computation. For the computation of Equation4, we handle the two cases separately. We assign the label u = 1 to all ground-truth annotations from thetarget domain and multiply Ldetcls by the indicator Iu0. For non-annotated samples (x, y) from the sourcedomain, there are no box-specific coordinates t or labels u but only the labels y for the entire image. In thiscase, 4 is undefined and we instead compute the binary cross-entropy loss between the per-image label andthe probability vector for the entire image. We train the RPN and the detection network jointly as described in Ren et al. (2016). To extract featuremaps, we use a Feature Pyramid Network (Lin et al., 2017) on top of a ResNet-50 architecture He et al.(2016b). We use the modified model in the experiments in .3 and 4.4. In .3, we also trainthis model in a LUPI setting, where no information from the target domain is used.",
  "A.3Celebrity Photo Classification With Binary Attribute Vector": "In our experiment based on CelebA (Liu et al., 2015), the input x is an RGB image which has been resizedto 6464 pixels, the target y is a binary label for gender of the subject of the image, and the privilegedinformation w are 7 binary-valued attributes. The attributes used in this experiment are: Bald, Bangs,Mustache, Smiling, 5_o_Clock_Shadow, Oval_Face and Heavy_Makeup. We use a subset of the CelebAdataset with 2,000 labeled source examples and 3,000 unlabeled target examples. We use 1,000 sampleseach for the source validation set, source test set, and target test set, respectively. The target oracle, SL-T,is trained using labels provided for the 3,000 target examples, with 20 % of these examples set aside forvalidation. The same unlabeled validation set is used to validate the first DALUPI network, f. When usingprivileged information from the source domain to train f, we use 30,000 extra samples (x, w) with PI. For DALUPI, we use the two-stage estimator with the network f based on ResNet-18 followed by a non-linearMLP. The network g is an MLP with two hidden layers of with 256 neurons each. We train the models for100 epochs. If the validation accuracy (or validation AUC for f) does not improve for 10 subsequent epochs,we stop the training earlier. For DALUPI, the early stopping patience is 15 for each network. We treatthe problem as multi-class classification with two classes and use the categorical cross entropy loss for SL-S,SL-T, DANN, and MDD.",
  "DANN:": "batch size: (16, 32, 64) initial learning rate: (1.0 104 , 1.0 103 ) parameter for learning rate decay: (0, 1.0) weight decay: (1.0 104 , 1.0 103 ) dropout (encoder): (0, 0.1, 0.2, 0.5) width of discriminator network: (64, 128, 256) depth of discriminator network: (2, 3) nonlinear classifier: (True, False) parameter for adaption regularization decay: (0.1, 1.0, 10.0).",
  "A.4Digit Classification With Single Bounding Box as PI": "In the digit classification task, we separate 20 % of the available source and target data into a test set. Welikewise use 20 % of the training data for validation purposes. For DALUPI we use ResNet-18 for the functionf. We replace the default fully connected layer with a fully connected layer with 4 neurons to predict thecoordinates of the bounding box. The predicted bounding box is resized to a 28 28 square no matter theinitial size. We use a simple convolutional neural network for the function g with the following structure:",
  "fully connected layer with 5 out features": "The model training is stopped when the best validation accuracy (or validation loss for f) does not improveover 10 epochs or when the model has been trained for 100 epochs, whichever occurs first. All models aretrained from scratch, without pretrained weights. We use the categorical cross entropy loss for SL-S, SL-T,DANN, and MDD.",
  "MDD:": "batch size: (16, 32, 64) initial learning rate: (1.0 104 , 1.0 103 ) parameter for learning rate decay: (0, 1.0) weight decay: (1.0 104 , 1.0 103 ) number of trainable layers (encoder): (1, 2, 3, 4, 5) dropout (encoder): (0, 0.1, 0.2, 0.5) nonlinear classifier: (True, False) maximum norm value for classifier weights: (0.5, 1.0, 2.0) parameter for adaption regularization decay: (0.1, 1.0, 10.0).",
  "A.5Entitity Classification With Multiple Regions of Interest as PI": "In the entity classification experiment, we train all models for at most 50 epochs. If the validation AUCdoes not improve for 10 subsequent epochs, we stop the training earlier. No pretrained weights are used inthis experiment since we find that the task is too easy to solve with pretrained weights. For DALUPI andLUPI, we use the end-to-end solution based on Faster R-CNN (see Section A.2). We use the default anchorsizes for each of the feature maps (32, 64, 128, 256, 512), and for each anchor size we use the default aspectratios (0.5, 1.0, 2.0). We use the binary cross entropy loss for SL-S, SL-T, DANN, and MDD. We use the 2017 version of the MS-COCO dataset (Lin et al., 2014). As decribed in .3, we extractindoor images by sorting out images from the super categories indoor and appliance that also containat least one of the entity classes. Outdoor images are extracted in the same way using the super categoriesvehicle and outdoor. Images that match both domains (for example an indoor image with a toy car)are removed, as are any gray-scale images. We also include 1,000 negative examples, i.e., images with noneof the entities present, in both domains. In total, there are 5,231 images in the source domain and 5,719images in the target domain. From these pools, we randomly sample 3,000, 1,000, and 1,000 images fortraining, validation, and testing, respectively. In we describe the label distribution in both domains.All images are resized to 320 320.",
  "LUPI and DALUPI:": "batch size: (16, 32, 64) learning rate: (1.0 104 , 1.0 103 ) step size n for learning rate decay: (15, 30, 100) weight decay: (1.0 104 , 1.0 103 ) IoU foreground threshold (RPN): (0.6, 0.7, 0.8, 0.9) IoU background threshold (RPN): (0.2, 0.3, 0.4) batchsize per image (RPN): (32, 64, 128, 256) fraction of positive samples (RPN): (0.4, 0.5, 0.6, 0.7) NMS threshold (RPN): (0.6, 0.7, 0.8) RoI pooling output size (Fast R-CNN): (5, 7, 9) IoU foreground threshold (Fast R-CNN): (0.5, 0.6) IoU background threshold (Fast R-CNN): (0.4, 0.5) batchsize per image (Fast R-CNN): (16, 32, 64, 128) fraction of positive samples (Fast R-CNN): (0.2, 0.25, 0.3) NMS threshold (Fast R-CNN): (0.4, 0.5, 0.6) detections per image (Fast R-CNN): (25, 50, 75, 100).",
  "A.6X-ray Classification With Multiple Regions of Interest as PI": "In the X-ray classification experiment, we train all models for at most 50 epochs, using pre-trained weightsin the ResNet architecture of each model. If the validation AUC does not improve for 10 subsequent epochs,we stop the training earlier. We then fine-tune all models, except DANN and MDD, for up to 20 additionalepochs. The number of encoder layers that are fine-tuned is a hyperparameter for which we consider differentvalues. We start the training with weights pretrained on ImageNet. For DALUPI, we use the end-to-endsolution based on Faster R-CNN (see Section A.2). We use the default anchor sizes for each of the featuremaps (32, 64, 128, 256, 512), and for each anchor size we use the default aspect ratios (0.5, 1.0, 2.0). Weuse the binary cross entropy loss for SL-S, SL-T, DANN, and MDD. In total, there are 83,519 (457) and 120,435 (118) images (annotated images) in the source and targetdomain, respectively. The distributions of labels and bounding box annotations are provided in .Here, NF refers to images with no confirmed findings. In the annotated images, there are 180/146/153and 75/66/64 examples of ATL/CM/PE in each domain respectively. Validation and test sets are sam-pled from non-annotated images and contain 10,000 samples each. All annotated images are reserved fortraining.We merge the default training and validation datasets before splitting the data and resize allimages to 320 320. For the source dataset (ChestX-ray8), the bounding boxes can be found together withthe dataset. The target segmentations can be found here:",
  "DALUPI:": "batch size: (16, 32, 64) learning rate: (1.0 104 ) weight decay: (1.0 104 , 1.0 103 ) IoU foreground threshold (RPN): (0.6, 0.7, 0.8, 0.9) IoU background threshold (RPN): (0.2, 0.3, 0.4) batchsize per image (RPN): (32, 64, 128, 256) fraction of positive samples (RPN): (0.4, 0.5, 0.6, 0.7) NMS threshold (RPN): (0.6, 0.7, 0.8) RoI pooling output size (Fast R-CNN): (5, 7, 9) IoU foreground threshold (Fast R-CNN): (0.5, 0.6) IoU background threshold (Fast R-CNN): (0.4, 0.5) batchsize per image (Fast R-CNN): (16, 32, 64, 128) fraction of positive samples (Fast R-CNN): (0.2, 0.25, 0.3) NMS threshold (Fast R-CNN): (0.4, 0.5, 0.6) detections per image (Fast R-CNN): (25, 50, 75, 100) learning rate (fine-tuning): (1.0 105 , 1.0 104 ) number of layers to fine-tune: (3, 4, 5).",
  "BAdditional Results": "In a and 8b, we show some example images from the digit classification task with associated saliencymaps from the source-only model for different values of the skew parameter . We can see that for a lowervalue of epsilon the SL-S model activations seem concentrated on the area with the digit, while when thecorrelation with the background is large the model activations are more spread out. In , we show the average AUC when additional training data of up to 30,000 samples are added inthe chest X-ray experiment. We see that, once given access to a much larger amount of labeled samples,SL-S and DALUPI perform comparably in the target domain. In , we show AUC for the pathology CM when additional training data without bounding boxannotations are added. We see that SL-S catches up to the performance of DALUPI when a large amountof labeled examples are provided. These results indicate that identifiability is not the primary obstacle foradaptation, and that PI improves sample efficiency.",
  "DProof of Proposition 2": "Proposition 2.Assume that G comprises M-Lipschitz mappings from the privileged information spaceW RdW to Y. Further, assume that both the ground truth privileged information W and label Y aredeterministic in X and W respectively. Let be the domain density ratio of W and let Assumptions 13(Covariate shift, Overlap and Sufficiency) hold w.r.t. W. Further, let the loss L be uniformly bounded bysome constant B and let d and d be the pseudo-dimensions of G and F respectively. Assume that there aren observations from the source (labeled) domain and m from the target (unlabeled) domain. Then, with Lthe squared Euclidean distance, for any h = h f G F, w.p. at least 1 ,",
  "RWT (f) = dWi=1RWT ,i(f)": "Let the pseudo-dimension of F be denoted d, D2 = {xi, wi}ni=0 be a dataset drawn i.i.d from the targetdomain. Then, using theorem 11.8 from Mohri et al. (2018) we have that for any > 0, with probability atleast 1 over the choice of D2, the following inequality holds for all hypotheses f F for each componentrisk",
  "Combination of these two results then yield the proposition statement": "Consistency follows as Y is a deterministic function of W and W is a deterministic fundtion of X and bothH and F are well-specified. Thus both empirical risks and sample complexity terms will converge to 0 inthe limit of infinite samples. The parts of the bound shown above can be described as falling into three main categories: Empirical risk(s),domain shift and sample complexity components. A central term that figures both in the weighted empirical",
  "risk and the Rnyi divergence is the density ratio T (w)": "S(w) . Therefore, the size of the bound is governed atleast in part based on the proximity in W-space the source and target domains are. This is similar to otherimportance weighting bounds, however, since the experiment designer may choose the form of PI this canbe more well-behaved than the density ratio in the input space.",
  "EProof Sketch for PAC-Bayes Bound": "We will here detail a proof sketch for a PAC-Bayes version of the bound we propose in the main text. Forthe purposes of this bound we will consider the quantity EhRT (h), where is a posterior distributionover classifiers h . As we are basing the bound on the two-step methodology where we train two differentclassifiers on separate datasets we assume that we can obtain the posteriors over the component functionsseparately and independently i.e. h = f g = f g, where f f and g g. Let the assumptionsfrom proposition 2 hold here. Similar to the previous section we decompose the risk into two parts",
  "EhRYT (g) = EggRYT (g)": "This holds as we assume that f and g are not dependent on each other. Therefore, we can just marginalizeout the part which is not in use. From this point we can use some of the available bounds from the literatureto estimate the resulting part e.g. Corollary 1 from Breitholtz & Johansson (2022). Application of this resultyields the following bound on the first term",
  "FA Bound on the Target Risk Without Suffiency": "The sufficiency assumption is used to replace T (y | x) with T (y | w) in the proof of Proposition 1. Ifsufficiency is violated but it is plausible that the degree of insufficiency is comparable across domains, wecan still obtain a bound on the target risk which may be estimated from observed quantities. One way toformalize such an assumption is that there is some 1, for which"
}