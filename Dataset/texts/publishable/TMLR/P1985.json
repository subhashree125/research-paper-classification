{
  "Abstract": "For faster sampling and higher sample quality,we propose DiNof (Diffusion withNormalizing flow priors), a technique that makes use of normalizing flows and diffusionmodels. We use normalizing flows to parameterize the noisy data at any arbitrary step ofthe diffusion process and utilize it as the prior in the reverse diffusion process. More specif-ically, the forward noising process turns a data distribution into partially noisy data, whichare subsequently transformed into a Gaussian distribution by a nonlinear process.Thebackward denoising procedure begins with a prior created by sampling from the Gaussiandistribution and applying the invertible normalizing flow transformations deterministically.To generate the data distribution, the prior then undergoes the remaining diffusion stochas-tic denoising procedure. Through the reduction of the number of total diffusion steps, we areable to speed up both the forward and backward processes. More importantly, we improvethe expressive power of diffusion models by employing both deterministic and stochasticmappings. Experiments on standard image generation datasets demonstrate the advantageof the proposed method over existing approaches. On the unconditional CIFAR10 dataset,for example, we achieve an FID of 2.01 and an Inception score of 9.96. Our method alsodemonstrates competitive performance on CelebA-HQ-256 dataset as it obtains an FID scoreof 7.11. Code is available at",
  "Introduction": "Diffusion models (Sohl-Dickstein et al., 2015; Dhariwal & Nichol, 2021; Chen et al., 2020; Ho et al., 2020;Kong et al., 2020; Song & Ermon, 2020) are a promising new family of deep generative model that haverecently shown remarkable success on static visual data, even beating GANs (Generative Adversarial Net-works) (Goodfellow et al., 2014) in synthesizing high-quality images and audio. In a diffusion model, noise isgradually added to the data samples using a predetermined stochastic forward process, converting them intosimple random variables. This procedure is reversed using a separate backward process that progressivelyremoves the noise from the data and restores the original data distributions. In particular, the deep neuralnetwork is trained to approximate the reverse diffusion process by predicting the gradient of the data density. Existing diffusion models (Yang et al., 2022; Zhang & Chen, 2021; Wehenkel & Louppe, 2021) define aGaussian distribution as the prior noise, and a non-parametric diffusion method is developed to procedurallyconvert the signal into the prior noise. The traditional Gaussian prior is simple to apply, but since theforward process is fixed, the data itself has no impact on the noise that is introduced. As a result, thelearned network may not model certain intricate but significant characteristics within the data distribution.Particularly, employing purely stochastic prior noise in modeling complex data distributions may not fullyleverage the information and completely encompass all data details in the diffusion models.",
  "Published in Transactions on Machine Learning Research (09/2024)": "have leveraged diffusion models with nonlinear diffusions. Specifically, the examples found in the literatureare: LSGM (Vahdat et al., 2021) which implements a latent diffusion using VAE; DiffFlow (Zhang & Chen,2021) which uses a flow network to nonlinearize the drift term; SB-FBSDE (Chen et al., 2021; De Bortoliet al., 2021) which reformulates the diffusion model into a Schrodinger Bridge Problem (SBP); DPM-OT (Liet al., 2023) which treats inverse diffusion as an optimal transport (OT) problem between latents at variousstages; TDPM (Zheng et al., 2023) that focuses on reducing the diffusion trajectory by learning an implicitgenerative distribution using AAE, and; INDM (Kim et al., 2022) which uses a flow network to implicitlyconstruct a nonlinear diffusion on the data space by leveraging a linear diffusion on the latent space. Weshow that, compared to these methods, our flexible approach provides better generative modeling perfor-mance. We demonstrate this on the CIFAR-10 image dataset, which compared to CelebA-HQ-256 is farmore diversified and multimodal. As is done in previous research (Song et al., 2020b; Jing et al., 2022), the best training checkpoint withthe smallest FID is utilized to report the results on CIFAR-10 dataset. One checkpoint is saved every 50kiterations for our models, which have been trained for 1M iterations. The batch size is also fixed to 128. summarizes the sample quality results on the CIFAR-10 dataset for 50K images. Our method withcontinuous NCSN++ (deep) obtains the best FID and IS of 2.01 and 9.96, respectively. The considerable im-provement over other nonlinear models such as DiffFlow, SB-FBSDE, INDM, LSGM, and TDPM shows thepotential of using both SDEs and ODEs. It is worth noting that although certain methods like DPM-OT Liet al. (2023) might require fewer steps in the reverse process, our method still maintains a competitive edgein terms of sample fidelity. More importantly, our method maintains full compatibility with the underlyingdiffusion models, and hence, retaining all their capabilities. Another key point is that our approach, incomparison to similar methods that integrate normalizing flows with diffusion models, like DiffFlow (Zhang& Chen, 2021), delivers notably better performance. The strength of our method lies in optimizing computa-tional efficiency without compromising sample quality. With an FID score of 2.01, as opposed to DiffFlows13.43, our approach demonstrates that it can both accelerate the process and improve sample quality. Ourmethod also consistently improves over the baseline methods. For example, it achieves a 0.19 improvementin the FID score compared to NCSN++ cont. (deep, VE) with the same diffusion architecture. Furthermore,our method not only preserves the flexibility of existing SDEs but also boosts their effectiveness.",
  "Our contributions can be summarized as follows:": "(1) We propose the use of a data-dependent, deterministic prior as an alternative to the random noise usedin standard diffusion models, to enable modeling complex distributions more accurately, with a smallernumber of sampling steps. Our new generative model leverages the strengths of both diffusion models andnormalizing flows to improve both accuracy and efficiency in the mappings between the latent and dataspaces. (2) We evaluate our approach on CIFAR-10 and CelebA-HQ-256 datasets, which are the most commonlyused datasets in this problem space. We achieve competitive results in the image generation task, yielding2.01 and 7.11 FID scores on the CIFAR-10 and Celeb datasets, respectively.",
  "Method": "Although diffusion models have unique advantages over other generative models, including stable and scalabletraining, insensitivity to hyperparameters, and mode-collapsing resilience, producing high-fidelity samplesfrom diffusion models involves a fine discretization sampling process with sufficiently long stochastic tra-jectories (Song et al., 2020b; Vahdat et al., 2021; Zhang & Chen, 2021; Zhang et al., 2022). Several worksinvestigated this and improved the efficiency. However, their improved runtime comes at the expense ofpoorer performance compared to the seminal work by Song et al. (2020b). This motivates us to develop a new approach that simultaneously improves the sample quality and samplingtime. We hence propose to integrate nonlinear deterministic trajectories in the mapping between the data andlatent spaces. The deterministic trajectories are learned by using normalizing flows. In our diffusion/samplingsteps, therefore, both stochastic and deterministic trajectories are employed. In the following subsections,we provide preliminary remarks on diffusion models and normalizing flows before introducing our approach.",
  "Diffusion Models": "Diffusion models are latent variable models that represent data x(0) through an underlying series of latentvariables {x(t)}Tt=0. The key concept is to gradually destroy the structure of the data x(0) by applying adiffusion process (i.e., adding noise) to it over the course of T time steps. The incremental posterior of thediffusion process generates x(0) through a stochastic denoising procedure (Yang et al., 2022; Rasul et al.,2021; Voleti et al., 2022; Ho et al., 2022; Croitoru et al., 2022; Ho et al., 2020; Song et al., 2020a). The diffusion process (also known as the forward process) is not trainable and is fixed to a Markov chain thatgradually adds Gaussian noise to the signal. For a continuous time variable t [0, T], the forward diffusionprocess {x(t)}Tt=0 is defined by an Ito SDE as:",
  "dx = f(x, t)dt + g(t)dw,(1)": "where f(., t) : Rd Rd and g(.) : R R denote a drift term and diffusion coefficient of x(t), respectively.Also, w denotes the standard Wiener process (known as Brownian motion). To obtain a diffusion processas a solution for this SDE, the drift coefficient should be chosen so that it gradually diffuses the data x(0),while the diffusion coefficient regulates the amount of added Gaussian noise. The forward process transformsx(0) p0 into simple Gaussian x(T) pT so that at the end of the diffusion process, pT is an unstructuredprior distribution that contains no information of p0, where pt(x) denotes the probability density of x(t).",
  "dx = [f(x, t) g2(t)x log pt(x)]dt + g(t)dw,(2)": "where w denotes a standard Wiener process when the time is reversed from T to 0 and dt denotes aninfinitesimal negative time step. We can formulate the reverse diffusion process from Eq. 1 and simulate itto sample from p0 after determining the x log pt(x) score for each marginal distribution for all t. We canthereby restore the data by eliminating the drift that caused the data destruction.",
  "= arg minEt{(t)Ex(0)Ex(t)|x(0)[s(x(t), t) x(t) log p0t(x(t)|x(0))22]},(3)": "where :[0, T] R+ denotes a weighting function, x(0) p0(x), x(t) p0t(x(t)|x(0)), and p0t denotes thetransition from x(0) to x(t). By using score matching with enough data and model capabilities, the optimumsolution s(x, t) can be achieved for nearly all x and t. It is hence equivalent to x log pt(x). To solve Eq. 3, the transition kernel p0t(x(t)|x(0)) must be known. For an affine drift coefficient f, it is usuallya Gaussian distribution, whose mean and variance are known in closed-forms. Once a time-dependent score-based model s has been trained, it can be utilized to create the reverse-time SDE. It can then be simulatedusing numerical methods to generate samples from p0. Any numerical method applied to the SDE specified inEq. 1 can be used to carry out the sampling. Song et al. (2020b) introduced some new sampling techniques,the Predictor-Corrector (PC) sampler being one of the best at generating high-quality samples. In PC, ateach time step, the numerical SDE solver is used as a predictor to give an estimate of the sample at the nexttime step. Then, a score-based technique, such as the annealed Langevin dynamics (Song & Ermon, 2019),is used as a corrector to correct the marginal distribution of the estimated sample. The annealed Langevindynamics algorithm (Song & Ermon, 2019) begins with white noise and runs xi = xi1+",
  "x log p(x)+wi,a certain number of iterations, where controls the magnitude of the update in the direction of the scorex log p(x)": "The reverse-time SDE can also be solved using probability flow, a different numerical approach, thanks toscore-based models (Song et al., 2020b). A corresponding deterministic process with trajectories that havethe same marginal probability densities {pt(x)}Tt=0 as the SDEs exists for every diffusion process.Thisprocess is deterministic and fulfills an ordinary differential equation (ODE) as (Song et al., 2020b):",
  "Normalizing Flows": "In normalizing flows, a random variable with a known (usually Normal) distribution is transformed via aseries of differentiable, invertible mappings (Abdelhamed et al., 2019; Kobyzev et al., 2020; Zhang & Chen,2021; Zand et al., 2023). Let Z RD be a random variable with the probability density function pZ : RD Rbeing a known and tractable function and Y = g(Z). The probability density function of the random variableY can then be calculated using the change of variables formula as shown below:",
  "f(y) denotes the Jacobian of f, and f is the inverse of g": "In generative models, the aforementioned function g (a generator) pushes forward the initial base densitypZ, often known as the noise, to a more complicated density. This is the generative direction, in which adata point y is generated by sampling z from the base distribution and applying the generator as y = g(z).In order to normalize a complex data distribution, the inverse function f moves (or flows) in the opposite",
  "Noise": "NF network : Architectural comparison of Diffusion, Normalizing Flows, DiffFlow (Zhang & Chen, 2021), andthe proposed DiNof models. DiffFlow uses stochastic and trainable processes for both the forward and thebackward processes, whereas DiNof utilizes a deterministic trainable process only at the final steps of theforward process.The backward process initiates with a deterministic process and turns to a stochasticprocess to generates images. We use Tm to denote an arbitrary intermediate latent variable between dataspace and latent space.",
  "way, from the complex distribution to the simpler, more regular or normal form of pZ. Given that f isnormalizing the data distribution, this viewpoint is the source of the term normalizing flows": "It can be challenging to build arbitrarily complex nonlinear invertible functions (bijections) such that thedeterminant of their Jacobian can be calculated. To address this, one strategy is to use their composition,since the composition of invertible functions is itself invertible. Let g1, . . . , gM be a collection of M bijectivefunctions, and let g = gM gM1 g1 represent the composition of the functions. The function g canthen be demonstrated to be bijective as well, which its inverse given as f = f1 fM1 fM. The latentvariables are then given as:xi = fi(xi1, )",
  "Proposed Method": "A schematic illustration of the proposed method in comparison to other generative models is shown in. In diffusion models, the forward process is fixed while the backward process is trainable. Yet, theyare both stochastic. Both the forward and the backward processes of normalizing flow are deterministic.They combine into a single process since they are the inverse of one another. In DiffFlow (Zhang & Chen,2021), both the forward and the backward processes are stochastic and trainable. Our method howeveremploys both stochastic and deterministic trajectories that follow each other in both directions. This ismore effective due to the possible reduction of the diffusion/sampling steps. More specifically, we aim to improve the effectiveness of diffusion-based modelling by representing data x(0)via a set of latent variables x(t) between the data distribution and a data-dependent and deterministic prior",
  "dx = f(t)xdt + g(t)dw,(7)": "where t is a continuous time variable uniformly sampled over [0, Tm). Theoretically Tm can be any numberbetween 1 and T, implying a potential for reducing the diffusion steps. Furthermore, we model latent variables{x(t)}t<Tm in the forward process using Eq. 7. Here, we can use one of the original diffusion models, such asVESDE (variance exploding SDE) or VPSDE (variance preserving SDE) (Song et al., 2020b). These modelsare linear, where f(x, t) = f(t)x is a function of x(t), and g is a function of t.",
  "(t) in VPSDE, where ( i": "N ) = i, and {i = Ni}Ni=0. We canalso employ the discretized versions of the VESDE and VPSDE known as SMLD and DDPM noise per-turbations (Song et al., 2020b). Using these conventional linear SDEs in the forward diffusion process, wetransform the data x(0) p0 to a diffused distribution pTm. Hence, we connect the data space and the latentvariables {x(t)}t<Tm through stochastic trajectories. We propose exploiting the nonlinearity in the diffusion process by applying a nonlinear ODE on the restof trajectories (i.e., {x(t)}tTm). In contrast to a few prior works that use nonlinearity in the diffusionmodels (Vahdat et al., 2021; Zhang & Chen, 2021; Kim et al., 2022), we follow the existing linear processwith a subsequent nonlinear process. This is shown in , where the diffusion process is nonlinearizedby employing nonlinear trainable deterministic processes. Intuitively and empirically, utilizing both linearand nonlinear processes can boost the sample quality. As demonstrated in our experiments, executing anefficient nonlinear process after an existing linear process can reduce the number of sampling steps andaccelerate sampling. We choose normalizing flows as the means to nonlinearize the diffusion models, as theylearn the nonlinearity by invertible flow mapping. Normalizing flows are in this way used to complete theremaining steps of the diffusion process in a single phase, which improves efficiency. In our normalizing flow network, we consider a bijective map between pTm and z, a latent variable witha simple tractable density such as a Gaussian distribution as p(z) = N(z; 0, I).The log-likelihood of",
  "ilog | det(dhi/dhi1)|(8)": "where {hi}Mi=1 are intermediate representations generated by the layers of a neural network, h0 = x(Tm),and hM = z. We train this model by minimizing the negative log-likelihood. The overall objective whichincludes training our SDE and our ODE is a joint training objective that merges the ODE objective withthe diffusion models score matching objective ( i.e., Eqs. 3 and 8). As noted earlier, data and the latent variables are coupled through both stochastic and deterministic tra-jectories in an end-to-end network. We therefore employ two different forms of trajectories for the mappingbetween data and latent spaces using SDEs and ODEs. Stochastic trajectories are utilized between Tm latentvariables, while deterministic trajectories are employed for M latent variables in the flow process. AlthoughTm+M might be greater than the N steps of a standard diffusion model, employing an efficient flow networkwhich generates samples at a single step will nevertheless, speed up the process (Song et al., 2020b). The typical strategy in current diffusion models is to restore the original distribution by learning to pro-gressively reverse the diffusion process, step by step, from T to 0. In our approach, however, we reconstructx(Tm) using the backward process in the flow network via a single path. Furthermore, by reconstructingx(Tm), the Gaussian noise is deterministically mapped to a partially noisy sample pTm. New samples aregenerated in the backward process by simulating remaining stochastic trajectories from t = Tm to t = 0 bythe reverse-time SDE. In contrast to generic SDEs, we have extra information close to the data distribution that can be leveraged toimprove the sample quality. Specifically, pTm which is sampled by the flow network is used as an informativeprior for the reverse-time diffusion.To incorporate the reverse-time SDE for sampling, we can use anygeneral SDE solver. In our experiments, we choose stochastic samplers such as Predictor-Corrector (PC)to incorporate stochasticity in the process, which has been shown to improve results (Song et al., 2020b).Another notable advantage of this approach is its ability to semantically modify images by changing thevalue of Tm. It can interpolate between deterministic and stochastic processes. In our experiments, wedemonstrate the impact of the value of Tm on sample quality.",
  "Protocols and Datasets": "We show quantitative comparisons for unconditional image generation on CIFAR-10 (Krizhevsky et al.,2009) and CelebA-HQ-256 (Karras et al., 2017). We perform experiments on these two challenging datasetsfollowing the conventional experimental setup in the field (such as Kim et al. (2022); Salimans & Ho (2022);Song et al. (2020a)). We follow the experimental design of Ho et al. (2020); Song et al. (2020b), using theInception Score (IS) (Salimans et al., 2016) and Frechet Inception Distance (FID) (Heusel et al., 2017) forcomparison across models. We use different SDEs such as VESDE, VPSDE, and sub-VPSDE to show our consistency with the existingapproaches. The NCSN++ architecture is used as our VESDE model whereas DDPM++ architecture isutilized for VPSDE and sub-VPSDE models. PC samplers with one corrector step per noise scale are also usedto generate the samples. As our normalizing flow model, we use the multiscale architecture Glow (Kingma& Dhariwal, 2018) with the number of levels L = 3 and the number of steps of each level K = 16. We alsoset the number of hidden channels to 256. To ensure that the amount of neural network evaluations required during sampling is consistent with priorwork (Ho et al., 2020; Jing et al., 2022; Vahdat et al., 2021; Song et al., 2020b), we set T = 1000 and T = 1",
  "DiNof (Ours)9.962.01": "for discrete and continuous diffusion processes, respectively. The number of noise scales N is however setto 1000 for both cases. Additionally, the number of conditional Langevin steps is set to 1. The Langevinsignal-to-noise ratio for CIFAR-10 and CelebA-HQ-256 are fixed at 0.16 and 0.17, respectively. The defaultsettings are fixed for all other hyperparameters based on the optimal parameters determined in (Song et al.,2020b; Jing et al., 2022). All details are available in the source code release.",
  "Model Parameters": "We first optimize for the CIFAR10 sample quality, and then we apply the resulting parameters to the otherdataset. To find the optimal value for Tm, we investigate the results for a variety of thresholds. We selectNCSN++ cont. (Song et al., 2020b), which is an NCSN++ model conditioned on continuous time variablesas the baseline model. We calculate FIDs for various Tm values with T/10 increments on the models trainedfor 500K training iterations with a batch size of 32, where T = 1. Depending on the Tm value, a differentnumber of sampling steps is used in our model. Note that the number of sampling steps are reduced exceptwhen Tm = T. In this case, normalizing flows provide an initial prior as an alternative to the standardGaussian prior. As reported in , the best IS and FID are obtained when Tm = 0.5 and Tm = 0.6, respectively. Also,our method with Tm = 0.5 and 500 fewer sampling steps, outperforms the baseline model. It achieves 0.35improvement in terms of FID over the baseline method by obtaining an FID = 3.94. Improvements canbe seen for all Tm 0.5. For smaller Tm values, however, our method suffers a significant degradation.This is due to the high and imbalanced stochasticity at smaller Tm values.This is shown in ,where unrecognizable images are generated with a high stochasticity for Tm < 0.5. Smaller Tm makes thebackward process simple and fast but challenging to reconstruct the data. By additional noise, however,the high-quality images are successfully reconstructed, although with more sampling steps. Nonetheless, thecapacity to explicitly trade-off between accuracy and efficiency is still a crucial feature. For instance, thenumber of function evaluations is decreased by nearly 50% while maintaining the visual quality of samplesby using a smaller threshold, such as Tm = 0.5 that balances sample quality and efficiency (i.e., the numberof sampling steps). We fix Tm = 0.6 for the rest of the experiments as it results in the best FID score of3.16.",
  "300k9.372.94": "We evaluate the applicability of our method to the high-resolution dataset of CelebA-HQ-256. We trained on thisdataset for 0.5M iterations, and the most recent trainingcheckpoint is used to derive the results. We use a batch sizeof 8 for training and a batch size of 64 for sampling. Tosave on computation, we use the optimal Tm value of 0.6,which is obtained on the CIFAR-10 dataset. We also utilizethe continuous NCSN++ with PC samplers. As shown in, DiNof achieves competitive performance in terms ofFID on the CelebA-HQ-256 dataset. It specifically obtains acompetitive FID of 7.11 which outperforms LSGM, anothernonlinear model by a considerable margin of 0.11 FID. Theperformance gain is mainly contributed to the integrateddeterministic nonlinear priors as our diffusion architectureis similar to the one used in SDE and LSGM.",
  "Sampling Time": "We evaluate DiNof in terms of sampling time on the CIFAR-10 dataset. We specifically measure the improved runtimein comparison to the original SDEs (VESDE, VPSDE, andsub-VPSDE) with PC samplers (Song et al., 2020b) on anNVIDIA A100 GPU. The sampler is discretized at 1000 timesteps for all SDEs. We however discretize it at 600 steps inour models. Thus, we employ a considerably smaller number",
  ": Visual samples for various iteration numbers during training on the CelebA-HQ-256 dataset": "of diffusion/sampling steps. As we employ a Glow architecture, our models include 7M more parametersthan the standard SDE models. In contrast to the SDE models which are trained for 1.3M iterations, wetrain our models for 1M iterations to suppress overfitting. We follow the same strategy as (Song et al.,2020b), and report the results on the best training checkpoint with the smallest FID. As shown in , our method consistently reduces sampling time and improves sample quality. Forinstance, it takes 24s to generate an image sample, while yielding an FID score of 2.51 on the DDPM++model. It however takes 43s using the original DDPM++ architecture which achieves FID = 2.78. Ourmethod is hence 1.7 faster than original SDEs. It also performs better in terms of FID and IS. Forinstance, it improves over SDEs by 1.1 FID on average.",
  "Intermediate Results": "We save one checkpoint every 50k iterations for our models and report the results on the best trainingcheckpoint with the smallest FID. It is however worthwhile considering the intermediate results to betterunderstand the entire training and inference procedures. In , we show IS and FID for DDPM++,DDPM++ cont. (VP), and DDPM++ cont. (sub-VP) models trained for various iteration numbers on theCIFAR-10 dataset. As can be observed, DDPM++ and DDPM++ cont. (VP) models improve more quicklythan DDPM++ cont. (sub-VP). Visual samples during training are also illustrated in for the CelebA-HQ-256 dataset, where im-provements over the course of training are obvious. Further details are updated and modified as trainingprogresses.",
  "Qualitative Results": "We visualize qualitative results for CelebA-HQ-256 and CIFAR-10 in . We show that as opposed toseveral other methods, DiNof can speed up the process while improving the sample quality. Other methodsthat shorten the sampling process like (Song et al., 2020a; Zhang & Chen, 2021) frequently compromise thesample quality. Random samples from our best models on the CIFAR-10 and CelebA-HQ-256 datasets are further depictedin and , respectively. They demonstrate the robustness and reliability of our approach forgenerating realistic images. Our method creates diverse samples from various age and ethnicity groups onCelebA-HQ-256, together with a range of head postures and face expressions. DiNof also produces sharpand high-quality images with density details on the challenging multimodal CIFAR-10 dataset.",
  "Conclusion": "We propose DiNof, which improves sample quality while also reducing runtime. Our model breaks previousrecords for the inception score and FID for unconditional generation on both CIFAR-10 and CelebA-HQ-256 datasets. As compared to the previous best diffusion-based generative models, it is surprising that weare able to reduce the sampling time while improving the sample quality.Unlike many other methods,our approach also maintains full compatibility with the underlying diffusion models and so retains all their",
  ": Uncurated CelebA-HQ-256 generated samples": "features. It should also be noted that even though incremental experiments are used to determine the optimalvalue of the single model hyperparameter (Tm), we only needed to run 10 increments (on CIFAR-10) to beatthe other SOTA methods and show how useful DiNof is in real-world situations. We did not conduct thisexperiment again to acquire our results on the CelebA-HQ-256 dataset, further demonstrating the robustnessand applicability of our technique. A variety of image and video generation tasks may be made possible by our models ability to be applied inboth conditional and unconditional scenarios. It is beneficial to investigate its effectiveness for several othertasks including conditional image generation, interpolations, colorization, and inpainting.",
  "Statement of Broader Impact": "Our work enhances the efficacy of generative models in image generation, offering potential applications increative tools, media accessibility, and computer vision research. However, these advancements carry risks,including the misuse of AI for creating misleading or harmful content, such as deepfakes, and amplifyingbiases in training data. We advocate for responsible AI use, adhering to ethical guidelines and transparencyin deployment to mitigate these concerns. Abdelrahman Abdelhamed, Marcus A Brubaker, and Michael S Brown. Noise flow: Noise modeling withconditional normalizing flows. In Proceedings of the IEEE/CVF International Conference on ComputerVision, pp. 31653173, 2019.",
  "Matej Grci, Ivan Grubii, and Sinia egvi. Densely connected normalizing flows. Advances in NeuralInformation Processing Systems, 34:2396823982, 2021": "Martin Heusel, Hubert Ramsauer, Thomas Unterthiner, Bernhard Nessler, and Sepp Hochreiter.Ganstrained by a two time-scale update rule converge to a local nash equilibrium. Advances in neural infor-mation processing systems, 30, 2017. Jonathan Ho, Xi Chen, Aravind Srinivas, Yan Duan, and Pieter Abbeel. Flow++: Improving flow-basedgenerative models with variational dequantization and architecture design. In International Conferenceon Machine Learning, pp. 27222730. PMLR, 2019.",
  "Durk P Kingma and Prafulla Dhariwal. Glow: Generative flow with invertible 1x1 convolutions. Advancesin neural information processing systems, 31, 2018": "Durk P Kingma, Tim Salimans, Rafal Jozefowicz, Xi Chen, Ilya Sutskever, and Max Welling. Improvedvariational inference with inverse autoregressive flow. Advances in neural information processing systems,29, 2016. Ivan Kobyzev, Simon JD Prince, and Marcus A Brubaker. Normalizing flows: An introduction and reviewof current methods. IEEE transactions on pattern analysis and machine intelligence, 43(11):39643979,2020.",
  "Alex Krizhevsky, Geoffrey Hinton, et al. Learning multiple layers of features from tiny images. 2009": "Sang-gil Lee, Heeseung Kim, Chaehun Shin, Xu Tan, Chang Liu, Qi Meng, Tao Qin, Wei Chen, SungrohYoon, and Tie-Yan Liu. Priorgrad: Improving conditional denoising diffusion models with data-drivenadaptive prior. arXiv preprint arXiv:2106.06406, 2021. Zezeng Li, Shenghao Li, Zhanpeng Wang, Na Lei, Zhongxuan Luo, and David Xianfeng Gu. Dpm-ot: A newdiffusion probabilistic model based on optimal transport. In Proceedings of the IEEE/CVF InternationalConference on Computer Vision, pp. 2262422633, 2023.",
  "EricNalisnickandPadhraicSmyth.Stick-breakingvariationalautoencoders.arXivpreprintarXiv:1605.06197, 2016": "Jeeseung Park and Younggeun Kim. Styleformer: Transformer based generative adversarial networks withstyle vector. In Proceedings of the IEEE/CVF Conference on Computer Vision and Pattern Recognition,pp. 89838992, 2022. Gaurav Parmar, Dacheng Li, Kwonjoon Lee, and Zhuowen Tu. Dual contradistinctive generative autoen-coder. In Proceedings of the IEEE/CVF Conference on Computer Vision and Pattern Recognition, pp.823832, 2021. Prajit Ramachandran, Tom Le Paine, Pooya Khorrami, Mohammad Babaeizadeh, Shiyu Chang, Yang Zhang,Mark A Hasegawa-Johnson, Roy H Campbell, and Thomas S Huang. Fast generation for convolutionalautoregressive models. arXiv preprint arXiv:1704.06001, 2017. Kashif Rasul, Calvin Seward, Ingmar Schuster, and Roland Vollgraf.Autoregressive denoising diffusionmodels for multivariate probabilistic time series forecasting.In International Conference on MachineLearning, pp. 88578868. PMLR, 2021.",
  "Yang Song and Stefano Ermon. Improved techniques for training score-based generative models. Advancesin neural information processing systems, 33:1243812448, 2020": "Yang Song, Jascha Sohl-Dickstein, Diederik P Kingma, Abhishek Kumar, Stefano Ermon, and BenPoole.Score-based generative modeling through stochastic differential equations.arXiv preprintarXiv:2011.13456, 2020b. Hiroshi Takahashi, Tomoharu Iwata, Yuki Yamanaka, Masanori Yamada, and Satoshi Yagi. Variationalautoencoder with implicit optimal priors. In Proceedings of the AAAI Conference on Artificial Intelligence,volume 33, pp. 50665073, 2019. Yuhta Takida, Masaaki Imaizumi, Takashi Shibuya, Chieh-Hsin Lai, Toshimitsu Uesaka, Naoki Murata, andYuki Mitsufuji. San: Inducing metrizability of gan with discriminative normalized linear layer. arXivpreprint arXiv:2301.12811, 2023. Jiayan Teng, Wendi Zheng, Ming Ding, Wenyi Hong, Jianqiao Wangni, Zhuoyi Yang, and Jie Tang. Relay dif-fusion: Unifying diffusion process across resolutions for image synthesis. arXiv preprint arXiv:2309.03350,2023.",
  "Ruihan Yang, Prakhar Srivastava, and Stephan Mandt. Diffusion probabilistic modeling for video generation.arXiv preprint arXiv:2203.09481, 2022": "Mohsen Zand, Ali Etemad, and Michael Greenspan. Flow-based spatio-temporal structured prediction ofmotion dynamics. IEEE Transactions on Pattern Analysis and Machine Intelligence, pp. 113, 2023. doi:10.1109/TPAMI.2023.3296446. Jingwei Zhang, Han Shi, Jincheng Yu, Enze Xie, and Zhenguo Li. Diffflow: A unified sde framework forscore-based diffusion models and generative adversarial networks. arXiv preprint arXiv:2307.02159, 2023."
}