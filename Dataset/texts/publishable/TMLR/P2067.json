{
  "Abstract": "In this paper, we consider the meta learning problem for estimating the graphs associatedwith high-dimensional Ising models, using the method of 1-regularized logistic regression forneighborhood selection of each node. Our goal is to use the information learned from theauxiliary tasks in the learning of the novel task to reduce its sucient sample complexity.To this end, we propose a novel generative model as well as an improper estimation method.In our setting, all the tasks are similar in their random model parameters and supports. Bypooling all the samples from the auxiliary tasks to improperly estimate a single parametervector, we can recover the true support union, assumed small in size, with a high probabilitywith a sucient sample complexity of n = O(d3 log p/K) per task, for K tasks of Ising modelswith p nodes and a maximum neighborhood size d. This is very relevant for meta learningwhere there are many tasks K = O(d3 log p), each with very few samples, i.e., n = O(1), in ascenario where multi-task learning fails. We prove a matching information-theoretic lowerbound for the necessary number of samples per task, which is n = (d3 log p/K), and thus,our algorithm is minimax optimal. Finally, with the support for the novel task restrictedto the estimated support union, we prove that consistent neighborhood selection for thenovel task can be obtained with a sucient sample complexity of O(d3 log d). This reducesthe original sample complexity of n = O(d3 log p) for learning a single task. We also provea matching information-theoretic lower bound of (d3 log d) for the necessary number ofsamples.",
  "Introduction": "Markov random elds (MRF) are an important class of probability models that nd its applications in a widevariety of elds spanning statistical physics (Ising, 1925) , social network analysis (Snell, 1980), computervision (Geman & Geman, 1993) and natural language processing (Manning & Schutze, 1999). A Markovrandom eld is an undirected graph where each node represents a random variable, and the graph structurecarries certain assumptions about the conditional independence of these random variables. A prototypicalexample of Markov random eld is the Ising model, where the random variables are discrete, and in particular,binary. Several other types of Markov random elds can be viewed as a general setting of the Ising model(Snell, 1980). Detecting statistical dependencies, which boils down to estimating the graph structure in theIsing model, is therefore a fundamentally signicant problem to solve. Many eorts have been made for thesingle-task problem, among which Ravikumar et al. (2010) proved that with relatively low computationalcomplexity, consistent model selection can be achieved with a sample size of n = O(d3 log p) for a graph of pnodes with a maximum neighborhood size d by neighborhood selection for each node using 1-regularized",
  "logistic regression. This simple method with a theoretically supported reasonable performance has receivedconsiderable attention": "In practice, however, one may not be able to obtain as many samples for the high-dimensional settings whereboth p and d can be large. The more common situation in reality is that one has only a few samples for atask; nonetheless, there are usually many related tasks (each with very few samples) of a similar kind. Forinstance, for an Ising model problem, there could be only n = O(1) samples per task for K = O(d3 log p)tasks. Consider for instance the case of K = 5000 tasks but only a few 2 samples per task. Learning fromrelated tasks has been previously considered in (Thrun & Pratt, 1998; Nichol et al., 2018). This challenge isalso commonly met in the application of other machine learning algorithms (Vilalta & Drissi, 2002; Finnet al., 2017; Vanschoren, 2018). One general way to tackle this kind of diculty is through meta learning(Vanschoren, 2018), or learning to learn (Lake et al., 2015), where we learn from multiple learning episodesthat oftentimes cover a distribution of related tasks a family of tasks, in order to gain some experience forthe learning of a novel task (in that family), in the hope of reducing the sample complexity for the latter(Hospedales et al., 2022). Meta learning has been widely used in machine learning problems to help increase sample eciency, but amajority of prior works are experimental in nature, without theoretical guarantees (Lake et al., 2015; Lemkeet al., 2015; Vinyals et al., 2016; Ravi & Larochelle, 2017; Finn et al., 2017; Snell et al., 2017; Grant et al.,2018; Yoon et al., 2018; Hospedales et al., 2022). There have been some eorts on building the theoreticalfoundation of meta-learning, but they only pertain generalization bounds in learning theory (Maurer, 2005;Pentina & Lampert, 2014; Amit & Meir, 2018; Denevi et al., 2018; Khodak et al., 2019; Huang et al., 2020;Tripuraneni et al., 2020; Farid & Majumdar, 2021; Chen & Chen, 2022; Guan et al., 2022) and convergencerates in optimization (Fallah et al., 2020; Finn et al., 2019; Khodak et al., 2019; Gao & Sener, 2020). In theabove works, performance is only viewed in terms of risks (e.g., misclassication rate, mean squared error)and not in terms of support recovery. For Markov random elds, there have been some theoretical results forthe models associated with Gaussian or sub-Gaussian random vectors, which is a continuous type of Markovrandom eld (Zhang et al., 2021). For discrete type, or Ising model as its prototype, similar works on metalearning do not exist. There has been some work on the multi-task learning problem on the Ising model (Gonalves et al., 2015; Guoet al., 2015). Note that there is an intrinsic dierence between multi-task learning and meta learning, wheremulti-task learning is learning one model for each of the dierent K tasks simultaneously while for metalearning we learn a single model from dierent tasks for the easier learning of a novel task. The challengingsituation of having many tasks but only a few samples per task (e.g., K = 5000 tasks each with 2 samples)would also render the multi-task learning method meaningless, as each task cannot be learned individuallywith these few samples per task. To the best of our knowledge, we are the rst to theoretically prove the sucient sample complexity for themeta learning problem of the Ising model selection. For the Ising model, we follow the practice of Ravikumaret al. (2010) in using 1-regularized logistic regression and converting the model selection problem into one ofneighborhood selection. Based on this method, for the meta learning problem on Ising models, we proposea novel generative model by introducing randomness to the parameter vectors of the Ising models withreasonable and exible assumptions for similarity among dierent tasks, which serves as a good generalizationof the metadata for the Ising model, and hence our theoretical results can be applied to a wide range ofdistributions for the parameters in the Ising models under some mild conditions. We also propose an improperestimation method in the meta learning problem for Ising model selection where we pool all the samplesfrom the auxiliary tasks together to estimate a single common parameter vector (see Denition 3.1), ratherthan estimate an individual parameter vector for each auxiliary task, and then we recover the support unionfrom the single common parameter vector. Next, we estimate the parameter vector for the novel task byrestricting its support in the estimated support union. While the sample complexity of multi-task learning isn = O(d3 log p) (Guo et al., 2015), we have successfully shown that to learn the support union of all the tasksrequires each task to have a sample complexity of only n = O(d3 log p/K) per task for each of the K tasks1,",
  "Published in Transactions on Machine Learning Research (08/2024)": "known that the default mode network is a graph that works when people are awake but resting thisdata is resting state functional magnetic resonance imaging. We estimated the support union from K = 40auxiliary tasks with precision 0.8821, recall 0.8918 and F1-score 0.8869. We used task 41 as the novel task,which support was estimated with precision 0.7133, recall 0.5528 and F1-score 0.6228. Both F1-score resultsare better than the ones from comparison methods. See Appendix B.2 for more details, and for interpretationof certain inter and intra symmetry between the left and right side of the brain.",
  "Ising Model and Model Selection": "In this paper, we focus on the Ising model, i.e., the binary pairwise Markov random elds, for which weprovide a denition here.Denition 2.1. Let X = (X1, X2, . . . , Xp) {1, +1}p denote a p-dimensional binary random vector,and each random variable Xs is associated with a vertex s V of an undirected graph G with vertex set",
  "probability distribution dened by the Ising model parameterized by (k)": "For our meta learning problem, we have K auxiliary tasks and one novel task, forming a family of p-dimensionalrandom Ising models of size K + 1. We can refer to as the true common parameter vector and S := supp()is what we call the true support union. We can then understand the maximum neighborhood size d for allgraphs as d := max{|S1|, |S2|, . . . , |Sp|}, where Sr is the neighborhood set of each node r V in the latentdeterministic graph parametrized by , dened as: Sr := {t V |(r, t) S}. We assume d p (d is small insize compared to p), so that the graphs are fairly sparse. By restricting the parameter estimation of the noveltask to the true support union that can be estimated using the auxiliary tasks, we can potentially reduce thesample complexity for the novel task by a large margin. Remark 3.3. Note that condition (9) restricts the support of the randomness in the parameter of eachtask to supp(), which guarantees that the support of each task supp((k)) supp() for 1 k K + 1,with probability 1. For instance, for an arbitrary entry (s, t) supp(), we have two cases: for task k, if(k)",
  "st = st, then by the same token, we have (s, t) supp((k)). Either": "way we arrive at supp((k)) supp(). Suppose on the contrary we do not impose condition (9), then it willbe hard for us to estimate a common parameter or a support union useful for all the tasks. On the otherhand, there is still great exibility in the family of distributions since graphs from dierent tasks can haveedge structures with no intersection with arbitrary probability, and we do not assume entries in (k) to besmall in absolute value.",
  "Our Improper Estimation Method for Meta Learning on Ising Models": "Our estimation procedure can be divided into two steps. The rst step is to recover S from the K auxiliarytasks by estimating . The second step is the signed edge recovery for task K + 1 with its support restrictedto the estimated support union. Considering the sparsity of the problem, we will use the 1-regularizedlogistic regression in both steps.",
  "Estimating the Support Union from K Tasks.Here we improperly estimate a single parameter": "although we know that each of the auxiliary tasks k = 1, . . . , K has its own true parameter (k). Since weare only interested on the joint support of the auxiliary tasks, this improper estimation does not need toestimate K parameters instead. Specically, for the rst step, we pool all the samples from the K tasks and estimate by minimizing the1-regularized logistic loss between and the estimate. For a clearer presentation, we assume that eachauxiliary task has the same number of samples, i.e., n(k) = n for 1 k K. Note that we do not assumethat n(K+1) = n for the novel task. Then, for each node r V , given the samples from all the K auxiliarytasks",
  "i,\\r)(11)": "is the averaged re-scaled negative log likelihood of all the auxiliary tasks and > 0 is a regularizationparameter to be specied by the user, which potentially depends on n, p, d and K. Note that (10) is animproper estimation as we estimate a single parameter vector using data from dierent distributions. Wecan further write (\\r; {Xn",
  "Assumptions": "The success of our method requires some assumptions on the structure of the logistic regression, most ofwhich are the dependency and incoherence conditions in the work by Ravikumar et al. (2010); Guo et al.(2015) generalized to our meta learning setting (see Assumptions 4.1, 4.2, 4.5, 4.6). We also make assumptionsregarding the randomness in the parameters for each task, which, intuitively speaking, make the tasks similarin some sense (see Assumption 4.3).",
  "Additional Assumptions on {(k)}1kK.The success of our method also relies on some reasonable": "and exible assumptions on the centering of the random variables {(k)}1kK underlying the parameters ofeach task reasonable in the sense that the tasks are similar enough to provide useful information, andexible so that there is as little inductive bias as possible. For simplicity, without writing down the samples for the auxiliary tasks, we use a shorthand notation (\\r)to denote the gradient of the loss function for the improper estimation, evaluated at the true commonparameter vector ; similarly (k)((k)",
  ". It can be checked that with a common latent graph with 3 nodes, 3 edges and": "= (1, 1, 1), a setting of resulting in the tasks parameter supports to have only 2 edges each with values + {(1.75, 1.75, 0), (1.75, 0, 1.75), (0, 1.75, 1.75)} with equal probabilities will fulll our condition withthe desired quantity around 0. A straightforward example for higher dimensions is to have a graph with theabove 3-node graph repeated multiple times, noticing that the combination of removing edges would alsogive rise to potentially numerous dierent tasks. More details of calculation and illustration can be found inAppendix C.",
  "Support Union Recovery": "Our rst theorem demonstrates that the sucient sample complexity for the recovery of the true supportunion S by our estimator in (10) is n = O(d3 log p/K) per task for each of the K tasks. This means that forthe situation with numerous tasks K = O(d3 log p), the sucient sample complexity per task is as small asO(1). From the condition we obtained on the regularizing parameter , we can also see that having moretasks will give a good estimate of the support union with less penalty, without having to increase the numberof samples per task the more tasks the better in this case.",
  "d, along with their correct sign": "Proof sketch for Theorem 4.7. We use the primal-dual witness approach (Wainwright, 2009; Ravikumar et al.,2010) and the proof can be divided into two parts. The rst part shows that imposing the dependence andincoherence assumptions (Assumptions 4.1 and 4.2) on the population version of the Fisher informationmatrix Q guarantees (with high probability) that analogous conditions hold for the sample Fisher informationmatrix QN := E[2(\\r; {Xn",
  ".(27)": "For the term Y1 E(Y1), we can get the same rate of decay with respect to (n, p, d, K) by using LCIHoedings inequality (Ke & Honorio, 2019) again. Then applying union bounds and setting to be timesa constant, we get the rate O(exp(c2nK)) as in Theorem 4.7, as well as the condition on . The detailedproof is in Appendix D.",
  "k=1, suppose": "p 5, (k) = H (k) for 1 k K with (k) [1/d4, 1/d4]pp symmetric, degree d Z+ even andH {0, 1}pp such that H is symmetric and Hij = 1 i (i, j) E. Thus S := E is the support union of theK Ising models. Assume E is randomly generated in the following way:",
  "The detailed proof is in Appendix E": "According to Theorem 4.8, if the sample size per distribution is n (d3 log p)/(4K) d3/(4K) (d3 log(8p))/(4pK), then with probability larger than 1/2, any method will fail to recover the supportunion of the Ising models specied in Theorem 4.8. Thus a sample complexity of (d3 log p/K) per task isnecessary for the support union recovery of the p-dimensional Ising models in K tasks, which, combined withTheorem 4.7, indicates that our estimate (10) is minimax optimal with a necessary and sucient samplecomplexity of (d3 log p/K) per task.",
  "Support Recovery for Novel Task": "For the novel task, the following theorem provides the sucient conditions and a probability lower bound forthe sign-consistency of the estimate, from which we can conclude that using the knowledge learned from theauxiliary tasks, the consistent signed neighborhood selection for the novel task can be achieved in a sucientsample complexity of n(K+1) = O(d3 log d). Theorem 4.9. Suppose we have recovered the true support union S of a family of p-dimensional randomIsing models of size K described in Denition 3.1. Assume |S| = O(d). For a novel task with parameter(K+1) such that supp((K+1)) S and satisfying Assumptions 4.5, 4.6, suppose the regularization parameter",
  "Remark 4.10. Note that the constants , L and c we use in the theorems are just some general constantsfor convenience of notation. The ones used in Theorem 4.7 are not related to those in Theorem 4.9": "Proof sketch for Theorem 4.9. We use the primal-dual witness approach again (Wainwright, 2009; Ravikumaret al., 2010). We have supposed that we have recovered the true support union S from our estimate for thetrue common parameter, . The constraint in (12) then enables us to convert the problem into one withoutthe restriction and with a parameter and data of dimension |Sr| with |Sr| d for all r V , for we cancombine the constraint straightforward into the minimization problem.",
  "d3 log d]pp symmetric and H {0, 1}pp such that H is symmetric": "and Hij = 1 i (i, j) E(K+1). Thus S(K+1) := E(K+1) is the support set of the Ising model. AssumeE(K+1) is chosen uniformly at random from the edge set family E := {E S : (i, j) E = (j, i) E} fora known edge set S. Assume |S| = O(d). Then for any estimate S(K+1) of S(K+1), we have",
  "Synthetic Experiments.To help illustrate and validate our theories, we conduct a group of synthetic": "experiments and report the success rates (over 100 repetitions) for recovery of the true support union. Werun the experiments with dierent number of nodes p {50, 100, 200} and degree d = 3, as well as withp = 50 nodes and three dierent degrees d {3, 5, 7}. We set the number of tasks scaling as K = d3 log p,with sample size for each auxiliary task n = Cd3 log p/K for C ranging from 1 to upwards of 200. Thenbased on the estimated support union using C = 200, we use dierent sample sizes n(K+1) = Cd3 log d forthe novel task when C changes from 1 to 200 and calculate the success rates (over 100 repetitions) for signededge recovery of the novel task. We plot the success rates against C and C for the two steps respectively in and . The curves approximately lie on top of one another as the success rates tend to 1 ineach step, as predicted by Theorem 4.7 and 4.9. Our results compare favorably against alternative methods.See Appendix B.1 for more details.",
  "Real-world Data Experiments.As another motivation and validation of our method, we used the": "real-world dataset 1000 Functional Connectomes at from1128 subjects, 41 sites worldwide, and p = 157 brain regions. Each task comes from a dierent research labwith dierent magnetic resonance imaging scanners/equipment with dierent physical properties. There arelabs around the world that collect MRI from dierent subsets of subjects/persons one lab is a task, onebrain region is a variable/node. Exploratory research was performed to unveil which brain region interactions(edges in the graph) are important. Similarly, dierent labs might not have the same underlying true graph(support), but it is reasonable to believe that they have some similarities. Specially, because it is partially",
  "Concluding Remarks": "Our method and analysis in this paper can be extended to more general cases of Markov random elds. Sincelogistic regression can be generalized to multi-class logistic regression, the analysis performed on the metalearning problem for Ising model can nd its analog in multi-class discrete Markov random elds (Ravikumaret al., 2010). Some other interesting directions for future work based on our method include but not limitedto meta learning for general continuous Markov random elds, meta learning for graphical models withhyper-edges that can connect multiple nodes instead only two, or time-varying graphical models, etc. Webelieve our results can provide a solid foundation and open a novel perspective for meta learning in Markovrandom elds and related graphical models."
}