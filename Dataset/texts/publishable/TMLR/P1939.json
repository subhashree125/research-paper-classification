{
  "Abstract": "Symmetries often arise in many natural sciences; rather than relying on data augmentationor regularization for learning these symmetries, incorporating these inherent symmetriesdirectly into the neural network architecture simplifies the learning process and enhancesmodel performance. The laws of physics, including partial differential equations (PDEs),remain unchanged regardless of the coordinate system employed to depict them, and sym-metries sometimes can be natural to illuminate in other coordinate systems.Moreover,symmetries often are associated with the underlying domain shapes. In this work, we con-sider physical modelings with neural operators (NOs), and we propose an approach basedon coordinate transforms (CT) to work on different domain shapes and symmetries. Canon-ical coordinate transforms are applied to convert both the domain shape and symmetries.For example, a sphere can be naturally converted to a square with periodicities across itsedges. The resulting CT-FNO scheme barely increases computational complexity and canbe applied to different domain shapes while respecting the symmetries. The code and dataare publicly available at",
  "Introduction": "In numerous fields, such as electromagnetism (Bermdez et al., 2014), researchers seek to study the behaviorof physical systems under various parameters, such as different initial conditions, boundary values, andforcing functions. Traditional numerical methods can be excessively time-consuming for simulating suchphysical systems.A class of data-driven surrogate models, termed neural operators (NOs), provide anefficient alternative (Li et al., 2021; Rahman et al., 2023; Raonic et al., 2023; Chen et al., 2023). Neuraloperators approximate the mapping from parameter function space to solution function space. Once trained,obtaining a solution for a new instance of the parameter requires only a forward pass of the network, whichcan be several orders of magnitude faster than traditional numerical methods (Li et al., 2021). A prevalentfield of application is solving classes of Partial differential equations (PDEs).PDEs are widely used inmodeling physical phenomena; for example, Navier-Stokes equations in fluid dynamics (Serrano et al., 2023)and Schrodinger equations (Dirac & M., 1981) in quantum mechanics. Although solving parametric PDEsis a major application of neural operators, they have wider applicability in general physical modeling, evenwithout known physics formulations, such as in climate modeling (Bonev et al., 2023).",
  "Published in Transactions on Machine Learning Research (10/2024)": "Kuangdai Leng, Tarje Nissen-Meyer, and Martin van Driel. Efficient global wave propagation adapted to 3-Dstructural complexity: a pseudospectral/spectral-element approach. Geophysical Journal International,207(3):17001721, 09 2016. ISSN 0956-540X. doi: 10.1093/gji/ggw363. URL Zongyi Li, Nikola Borislavov Kovachki, Kamyar Azizzadenesheli, Burigede liu, Kaushik Bhattacharya, An-drew Stuart, and Anima Anandkumar. Fourier neural operator for parametric partial differential equations.In International Conference on Learning Representations, 2021. URL Zongyi Li, Nikola Borislavov Kovachki, Chris Choy, Boyi Li, Jean Kossaifi, Shourya Prakash Otta, Moham-mad Amin Nabian, Maximilian Stadler, Christian Hundt, Kamyar Azizzadenesheli, and Anima Anand-kumar. Geometry-informed neural operator for large-scale 3d PDEs. In Thirty-seventh Conference onNeural Information Processing Systems, 2023. URL",
  "Neural PDE Solvers": "Recently, neural PDE solvers have shown great success as an alternative to traditional numerical methods forsolving PDE problems in many areas of practical engineering and life sciences (Sirignano et al., 2020; Pathaket al., 2022; Zhang et al., 2022; Azizzadenesheli et al., 2024). Traditionally, solving a PDE involves seekinga smooth function satisfying the derivative relationships within the equations. Based on this view, Physics-Informed Neural Networks (PINNs) have been developed to tackle PDEs individually. Another perspective",
  "Equivariant Architectures": "The concept of equivariance emerge in many machine learning tasks, especially in the field of computervision. Convolutional Neural Networks (CNNs) are known to be equivariant to translations, a characteristicthat has propelled CNNs significant success. Group convolution has been studied to achieve equivariancebeyond translation (Cohen & Welling, 2016), such as rotation and scaling. A regular group convolution,within a discrete group, convolves input features with multi-channel filters in the group space; a groupaction on the input feature corresponds to cyclic shifts between channels. Later works extend equivarianceto continuous groups, for example, utilizing steerable filters (Cohen & Welling, 2017; Weiler & Cesa, 2019)and B-spline interpolation (Bekkers, 2020). Other than group convolution, Esteves et al. (2018) brings upan interesting idea of achieving rotation and scale equivariance by using a log-polar sampling grid. Forsymmetries in PDEs, Group FNO (G-FNO) (Helwig et al., 2023) parameterized convolution kernels in theFourier-transformed group space, extending group equivariant convolutions to the frequency domain. Theresulting G-FNO architecture is equivariant to rotations, reflections, and translations. Nevertheless, groupconvolutions can be computationally expensive; for some symmetries arising in PDEs or physical dynamics ingeneral, performing group convolutions can even be intractable. Symmetries such as rotation and translationare commonly studied in computer vision. However, those that exist in PDEs or physical dynamics, ingeneral, are under-studied. Our work, instead of utilizing group convolution, offers an alternative approachto incorporating symmetries in neural operators through canonical coordinate transformation.",
  "Relations with Prior Work": "G-FNO (Helwig et al., 2023) is a recent method that performs group convolution in the frequency domain. Asthe Fourier transform is factually rotationally equivariant, G-FNO also achieves equivariance in the physicaldomain. However, in both FNO and G-FNO, in order to benefit from the power of FFT, the domain has to berectangular, which limits the symmetries it can have. For example, with rotation symmetries, a rectangulardomain cannot be rotationally equivariant to arbitrary rotations. Unlike in computer vision tasks, where theconvolution kernels are usually local and can have local symmetries, the kernel in FNO and G-FNO is global.Thus, the existence of local symmetries is unclear. For PDEs, the symmetries they can have often associatewith the underlying domain shapes. Therefore, we propose CT-FNO to adapt to various domain shapeswhile also respecting the symmetries that the underlying domain shape can embody. Although both ourwork and G-FNO aims to incorporate symmetries, we look at a different angle that takes both symmetriesand domain shapes into account, which cannot be solved solely by group convolution.",
  "Group Equivariance": "Equivariance is a property of an operator, such as a neural network or a layer within one, such that if theinput transforms, the output transforms correspondingly in a predictable way. A more complete review ofnecessary group theory and equivariance concepts within the scope of this work is included in Appendix A.",
  "where X and Y are subspaces of a function space. In other words, the operator commutes with actions ofG": "In the context of operator learning, LXg and LYg can be considered as transformations, such as rotation,of the input parameter function and the output solution function, respectively. , on the other hand, canbe thought of as the solution operator that maps an input function to its corresponding output solution.Equivariance to various groups, including but not limited to SE(n), E(n), SIM(n), can be achieved by group-convolutions (Cohen & Welling, 2016; Weiler et al., 2023). Let v(h) and (h) be real valued functions ongroup G with Lgv(h) = vg1h, the group convolution is defined as:",
  "where v can be regarded as the input feature and the convolution kernel": "Note that the first group convolution layer should be treated differently if the input functions are not definedon G. For semi-direct product groups, Rd H, the first layer is a lifting convolution that raises the featuremap dimensions to the group space (Bekkers, 2020). Integrability over a group and the identification of the suitable measure, dg, are necessary for group con-volution.It has been shown that with the measure dg, group convolution consistently maintains groupequivariance. For all a G,(Lav ) (h) =",
  "Fourier Neural Operators": "Fourier neural operators learns to map an input function to the solution function in infinite-dimensionalspaces. Inspired by the kernel method for PDEs, each Fourier layer consists of a fixed non-linearity anda kernel integral operator K modeled by network parameters, defined as (Kv)(x) =(x, y)v(y)dy. As aspecial case of integral kernel operator, translation invariance is imposed on the kernel, ((x, y) = (x y)),which is a natural choice from the perspective of fundamental solutions. Thus, the integral kernel operatorin FNO is defined as a convolution operator",
  "(f)": ": Examples of shapes to which CT-FNO can be applied. (a) Sphere: Polar Coordinates (b) Torus:Polar Coordinates (c) Ellipse: Polar Coordinates (d) Spherical Sector: Polar Coordinates (e) Cylinder:Cylindrical Coordinates (f) Hyperbolic Plane: Hyperbolic Coordinates other symmetries through canonical coordinate transform. The geometry and boundaries of the domainoften dictate certain symmetries that the solution operators might exhibit. For example, if the domain isa square, rotations other than a multiple of 90 degrees do not make sense. Traditional numerical schemesfrequently maintain specific symmetry properties of the underlying PDE in different coordinate systems.Symmetries in physics, including PDEs, correlate with the shape and characteristics of the domain. Forexample, if the domain is circular, it does not make sense to think about (global) translation symmetriesanymore. This motivates the pursuit of formulating a coordinate-transform neural operator method that canbe applied to different domain shapes and respect the symmetry of the underlying domain shape. In spiteof that, we propose the Coordinate Transform Fourier Neural Operators (CT-FNO) framework; CT-FNOis an extension of the FNO architecture in a different coordinate system. A coordinate transformation isfirst applied to the underlying PDE systems such that the domain shape and symmetries can be natural forFNOs to handle. Then the PDE solution operator is approximated by the neural operator.",
  "Universal Approximation with Coordinate Transform": "In this subsection, we provide justification for applying FNO with coordinate transformation. Although itis intuitive that FNO can be applied to different coordinate systems, given that the laws of physics are notdependent on the coordinate system to which they adhere, one may still question the mathematical rigor ofsuch operations. Therefore, we provide the following corollary to justify the use of coordinate transformationin FNOs. A prior work has established the universal approximation theorem for FNOs (Kovachki et al., 2021);importantly, the theorem asserts that, under certain conditions, FNOs maintain continuity as a mappingbetween Sobolev spaces; thus, FNOs can approximate the behavior of an operator within a specified precisionover the considered function space (a given compact subset of a Sobolev Space). A complete treatment ofthis theoretical aspect is included in Appendix B. In this work, we discuss a modification to FNOs for thepurpose of coordinate transformation, which is a parameter mapping; therefore, we present the followingcorollary. Corollary 4.1 (Universal Approximation with Parameter Mapping). Let s, s 0. Assuming that G, acontinuous operator mapping from Hs(T d; Rda) to Hs(T d; Rdu), holds true. For any compact subset Kcontained in Hs(T d; Rda) and any given positive , there exists a modified Fourier Neural Operator, denotedas N. This operator N, mapping from Hs(T d; Rda) to Hs(T d; Rdu), incorporates the continuous andcompact operators Pa and Pu on Hs(T d; Rda) and Hs(T d; Rdu), respectively. The structure of N is asper equation 10, and it maintains continuity as an operator from Hs to Hs, thereby ensuring the followingcondition is met:",
  "supaKG(a) N(a)Hs": "This corollary incorporates additional compact operators Pa and Pu on the respective Sobolev spaces asparameter mappings (coordinate transform and its inverse), and such compact operators maintain the con-tinuity property of FNOs; thus, the modified FNOs can still approximate the behavior of an operator withina specified precision. Consequently, this corollary enables us to consider CT-FNO by providing theoreticalguarantee that CT-FNO can approximate operators in another coordinate system.",
  "(c)": ": (a): Plot of a function in Cartesian coordinates. (b): The resulting frequency information afterapplying 1D FFT to the function in polar coordinates for the angular axis. Rows are the coefficients of theFourier modes of the rings. This is generated from a high-resolution grid in polar coordinates. (c): Plot ofthe same function in polar coordinates.",
  "Coordinate Transforms and Symmetries": "In this subsection, we introduce coordinate transformation and provide an overview of applying coordinatetransforms to adapt FNO to various domains while respecting the underlying symmetries. For illustration,we take rotation symmetries and circular domains in 2D as an example. While we focus on 2D circulardomains for simplicity, the concept of coordinate transformation readily extends to higher dimensions andother domain shapes. A coordinate transform, in mathematics, is a mapping that relates coordinates in onecoordinate system to coordinates in another coordinate system. Symmetries also transform along with coor-dinate systems. For instance, if the model is isotropic, we would consider convolution over the rotation groupsSO(2). To perform convolution over SO(2), an approach outlined in Helwig et al. (2023) involves adaptingthe workflow of group-equivariant CNNs: rotating the convolution kernels to incorporate a dimension forrotations in the resulting feature maps:",
  "SO(2)": "Letting x = r cos(), y = r sin(), the input function v(x, y) and the kernel (x, y) are transformed topolar coordinates as v(r, ) and (r, ), respectively. Although written in a different coordinate system, theunderlying physical dynamics remain unchanged. We adapt to the kernel convolution defined in Li et al.(2021) for polar coordinates:",
  "(Kv)(r, ) =(r r, )v(r, )drd.(4)": "The natural domain shape and symmetry to consider are circular domains with rotation symmetries, denotedby R SO(2). Through the use of canonical coordinates for abelian Lie-groups (Segman et al., 1992),convolution in equation 4 respects the rotation symmetry. It is worth noting that while we have rotationalsymmetries, it does not make sense to translate the radial axis; in other words, the angular axis is periodic,but the radial axis is not. We apply padding to practically solve this issue. Moreover, the function basis fortransformation should be treated differently as these two axes are not equivalent. However, empirically, weobserve that the FFT basis is still effective as demonstrated in . Therefore, we have extended FNOs to circular domains while respecting the underlying symmetry associatedwith them. After transforming them into polar coordinates, the domains shape nicely converts to a rectangle,enabling us to leverage the power of Fast Fourier Transforms (FFTs) to compute the convolution:(Kv) = F1(F Fv),(5) where denotes (r, ).Analogously, FNO can be extended to other domain shapes while respecting the underlying symmetries. Asillustrated by examples in , CT-FNO can handle various domain shapes. It is important to note that",
  "(d)": ": Different Sampling Methods (a): Uniform grid sampling in a ratio of 1 : 1 for the radial andaugular axes. (b): Uniform grid sampling in a ratio of 1 : 6. (c)(d): Sampled points in polar coordinatescorresponding to (a) and (b), respectively. this list contains only a small portion of the shapes CT-FNO can operate on. It is not possible to provide acomplete list, as there are numerous examples. These shapes, commonly found in numerical PDE literature,have broad applications across various natural sciences and engineering fields (Adler et al., 2013; Leng et al.,2016; Nissen-Meyer et al., 2014). It should be mentioned that there are numerous real-life applications thatare naturally modeled in polar coordinates, and achieving rotational equivariance is desirable. Examplesof such applications include global weather forecasting, water pipe modeling, electromagnetism, and more.Notably, previous work, such as Bonev et al. (2023), has successfully applied FNO to spherical domains foratmospheric dynamics forecasting. In our study, we generalize the application of FNO to different domainshapes through coordinate transformation. In another line of research, it has been concluded that somesymmetries become manifest only in a new coordinate system that must be discovered (Liu & Tegmark,2022), and group convolution might not be suitable for such symmetries. It is essential to note that CT-FNO has the potential to handle more complex domain geometries or to incorporate hidden symmetrieswithin the underlying PDEs through canonical coordinate transformation.",
  "Sampling Grid for Different Coordinate Systems": "In this subsection, we discuss the importance of the sampling grid under different coordinate systems andpropose a sampling grid for circular domains as an example to address this issue. Although operator learningis a task involving the mapping of functions, which is grid-independent, oftentimes, we only have access tofunction values at some finite collocation points.In FNO, to harness the power of FFTs, the samplinggrid must be rectangular and equidistant. If the provided grid points are not equidistant, interpolation isapplied to obtain uniform grids (equidistant grids) (Liu et al., 2023c). If the PDE is described in a Cartesiancoordinate system, and the inference for the solution is uniform in a Cartesian coordinate system, it is criticalto choose a sampling grid that represents the function well. Taking polar coordinates as an example, thiscan also be observed in the frequency domain. If we apply FFT on the angular axis, as shown in , the magnitude of high-frequency coefficients increases as r increases. For different applications, differentsamplings might be preferred, but the message to convey is that sampling grids have to be carefully handledafter transformation. To mediate this issue, we propose sampling an equidistant grid on the radius axis and the angular axis basedon a ratio of 1 : 6; this is to respect the geometric nature of a ring in Cartesian coordinate systems, wherethe ratio of the rings length to its radius is 2 : 1. For example, if 40 equidistant points are sampled overthe radius axis, 240 equidistant points should be sampled over the angular axis. This 1 : 6 ratio is a heuristicmade for simplicity; a 1 : 2 sampling and taking the closest integer for the angular axis can also be used.An illustration of different sampling grids is provided in ; it is clear that the sampling on the right,which follows the 1 : 6 rule, better represents the function in Cartesian coordinates under a similar number oftotal sampling points. Although this construction seems simple, it plays a crucial role in reducing the errorof interpolation if the points come from a uniform distribution in Cartesian coordinates or an equidistantgrid in Cartesian coordinates. We demonstrate this simple yet important aspect in .3.2.",
  "Diffusion of Heat on a Cylinder": "In this example, we show that the resulting CT-FNO architecture can work well on domains to which FNO orGFNO cannot be directly applied and outperform baselines that are applicable to such domains. Moreover,we demonstrate CT-FNOs capability to preserve symmetries. Simulation Description. We consider the conduction of heat over time in an isolated medium definedon the surface of a cylinder. There is no heat flux across the top and bottom surfaces of the cylinder. Asa result, this system is invariant under translation and equivariant under rotations. We simulate such datawith a 3D heat equation on the surface of a cylinder:",
  ": (a): Sample Initial Condition(b): Sample Solution at t = 1": "Setup. We provide details on generating initial conditions in Ap-pendix C. Solutions are obtained by transforming this system intocylindrical coordinates and employing a second-order finite differ-ence scheme for spatial domain and an implicit Euler scheme fortime, using a spatial grid of size 128 128 and a temporal step-size of 0.01.The resolutions are down-sampled to 64 64 fortraining, with point locations stored in both Cartesian and po-lar coordinates for further usage. A total of 1100 different initialconditions are generated, and the corresponding solutions are ob-tained. The dataset is divided into 1000 training data samplesand 100 testing data samples, referred to as the Normal TestingSet. Additionally, each testing sample in the Normal Testing Setis rotated by a random degree within the discretization tolerance,resulting in the Rotated Testing Set. It is worth noting that rotations will alter the distribution of the data,potentially leading to suboptimal performance due to out-of-distribution issues. Therefore, it is desirableto have an equivariant model to be robust under the Rotated Testing Set. Timing results are recorded onan NVIDIA Tesla V100 32GB GPU. All results are averaged over 10 different runs, and the meanand standard deviation of relative 2 error are reported. This is the setting for all subsequentexperiments unless otherwise specified. As the origin is fixed for all generated data; in other words, all spatial collocation positions are the same, andthere is no translation to be considered. Therefore, even for models that are not translation-invariant, theperformance will not be affected negatively. However, CT-FNO does maintain both translation invariance androtation equivariance as a natural result of coordinate transformation. Since the domain is not rectangular,FNO cannot be directly applied without sacrificing the power FFTs. We compare CT-FNO with baselinesapplicable to cylindrical surfaces. The results will be compared with GNO (Anandkumar et al., 2019), GINO(Li et al., 2023), and DeepOnet (Lu et al., 2021). For GNO, GINO, and DeepOnets, Cartesian coordinatesare used for node connectivity based on radius or as collocation positions. It is worth noting that GNO canalso be made equivariant by using relative information, e.g., distances; we included the comparison here.More experimental details can be found in Appendix C, where we also show that this PDE is equivariant torotations and included more results and details for equivariant GNOs.",
  "E Equivariant Adaptation of GNO; details can be found in Appendix C.2": "Results and Analysis. In , we present the results for the diffusion of heat on a cylinder. CT-FNOoutperforms all other baselines in terms of accuracy under the Normal Testing Set. This result is expected,as it is observed in many existing works that FNO outperforms GNO on rectangular domains (Li et al., 2021;Liu et al., 2023a). Compared to DeepOnet, although CT-FNO is slower in inference time, the differencein accuracy is significant. We observe a large standard deviation for DeepOnet; thus, we include resultsfrom every single run in Appendix C. We rotate every data sample in the Normal Testing Set to create anew testing set of 100 data samples, denoted as the Rotated Testing Set. Since only CT-FNO is rotationequivariant, it outperforms all other baselines to a greater extent. These results suggest that CT-FNO canextend FNO well to various domain shapes while respecting the underlying symmetries.",
  "Synthetic Operator": "In this example, we demonstrate that CT-FNO provides greater generalizability to various domain shapes.Since FNO operates on rectangular domains, we cannot directly compare CT-FNO with FNO or GFNO.However, we consider an inscribed square domain for the other baseline models to demonstrate that theperformance of CT-FNO is comparable to all other baselines while providing greater generalizability.",
  "}": "For comparison with other baselines, including FNO, G-FNO, and Radial-FNO, we consider the domain to bea unit box: := {(x, y) (0, 1)2}, bounded by the circular domain considered in CT-FNO as demonstratedin . For the square domain, the grids are 6464, and for the circular domain, the grids are 26156.We intentionally choose to have a circular domain to show that CT-FNO can operate on circular domains,and its performance is comparable with other baselines on rectangular domains.We bound the squaredomain with the circular domain for testing purposes. In the shared square, the values are identical giventhe analytical expressions; if CT-FNO can perform well on the bounding circular domains, it indicates thatCT-FNO performs well on the square domain as well. This operator learning task is inspired by a PoissonEquation in Raonic et al. (2023); in fact, for the square domain, f and u are the input function and solutionpairs for the Poisson Equation in Appendix D.",
  ": Sample input function and outputsolution. Input function and output solutionvalues are the same in the shared square": "Results and Analysis. In , we present results forthe Synthetic Operator. Considering that the square domainfor other baselines is bounded by the circular domain for CT-FNO, we may conclude that CT-FNO achieves roughly thesame level of accuracy compared to all other baselines. It canbe seen that CT-FNO is able to operate on circular domainswhile respecting the underlying rotational symmetries with-out a noticeable increase in computational costs. Althoughwe do not observe superior performance of CT-FNO overother baselines, our contribution focuses on the generaliz-ability of CT-FNO to extend FNO to other domain shapeswhile maintaining the underlying symmetries.Moreover,with such generalization, CT-FNO is robust under arbitraryrotations as the discretization tolerates, whereas other base-lines are constrained to C4 rotations due to the nature ofsquare domains. The experimental findings in this example corroborate with the conclusion from .1 that CT-FNO, similar to FNO, can approximate operators in another coordinate system with theoreticalguarantees. :Results on 2D Synthetic Operator. CT-FNO achieves rotational equivariance without significantlyincreasing computational complexity; the training time per epoch is close to that of FNO and much less thanthat of G-FNO. Moreover, it can be seen that CT-FNO can operate on circular domains while maintainingsimilar performance as all other baselines. Standard deviations are given in parentheses.",
  "Symmetry StudyIn this example, we specifically demonstrate CT-FNOs capability to preserve rotation symmetries, even forrectangular domains": "Simulation Description.The Darcy flow equation is a fundamental equation in fluid dynamics thatdescribes the flow of fluids through porous media. It is crucial in various fields like hydrogeology, petroleumengineering, soil mechanics, and environmental science. We consider the steady-state of the 2D Darcy Flowequation from Li et al. (2021) given by:",
  "u(x) = 0x (0, 1)2": "where a L (0, 1)2; R+is the diffusion coefficient and f L2 (0, 1)2; Ris the forcing function that iskept fixed f(x) = 1. We are interested in learning the operator mapping the diffusion coefficient a(x) tothe solution u(x). It can be shown that this operator is equivariant to the C4 rotation group (rotationalsymmetry group of order 4) as shown in Appendix E.",
  "* Proposed Sampling Grid": "Results and Analysis.In , we presentthe results for the Darcy Flow equation. CT-FNOperforms slightly better compared to all other base-lines under normal data conditions.However, itdoes not provide enough evidence that CT-FNO per-forms better than other baselines under normal test-ing data, and this is expected as the objective ofCT-FNO is to target symmetries and generalizabil-ity to other shapes for which FNO cannot be di-rectly applied. For C4 testing data, the performanceof FNO degrades moderately, although not as obvi-ously as in previous examples as the coefficient func-tions are sampled from Gaussian random fields andthen mapped to piecewise constants, and thus, thedistribution of the rotated testing set does not devi-ate much from the normal testing set. CT-FNO, G-FNO, and radial-FNO are all equivariant to rotations; thus, their performances are robustagainst rotations in the testing set. The testing errors do not change for G-FNO and Radial-FNO; thetesting error varies slightly for CT-FNO due to interpolation applied. Equivariant architectures can extractlocal symmetries (Cohen & Welling, 2016; 2017) and thus improve results even on data without globalsymmetries. However, in FNO-based architectures, convolution kernels are global; it is unclear whethergroup global convolution can capture local symmetries. The group-equivariant architecture can still enhance",
  "Conclusion, Limitations, and Future Work": "In this work, we propose designing an FNO architecture based on coordinate transformation. Specifically,by considering the underlying shape and symmetries of the domains it embeds, we may apply a coordinatetransformation to seamlessly convert the domain into a rectangular domain in which FNO can be applied.Through coordinate transform, we convert rotational symmetries into translation symmetries, which arenaturally inherent in FNO architectures.We conduct experiments to evaluate our proposed CT-FNO.Results show that operator learning with coordinate transformation can achieve similar performance toFNO while being able to generalize to various domain shapes while respecting the symmetries. Limitations.Although this work generalizes FNO to various domains, it is still not broad enough; itwould be interesting to see if coordinate transformation can be applied with other methods to work ongeneral domains while respecting the symmetries. Future Work.In Bonev et al. (2023), the authors have explored the use of a different coordinate systemfor climate modeling. As our work is a generalization of coordinate transformation for neural operators, itwill be interesting to see if CT-FNO can be applied to more practical real physical systems. Moreover, somesymmetries become manifest only in a new coordinate system that must be discovered (Liu & Tegmark,2022); it is worth exploring whether such symmetries can be captured by CT-FNO. J. H. Adler, M. Brezina, T. A. Manteuffel, S. F. McCormick, J. W. Ruge, and L. Tang. Island coalescenceusing parallel first-order system least squares on incompressible resistive magnetohydrodynamics. SIAMJournal on Scientific Computing, 35(5):S171S191, 2013. doi: 10.1137/120880227. Anima Anandkumar, Kamyar Azizzadenesheli, Kaushik Bhattacharya, Nikola Kovachki, Zongyi Li, BurigedeLiu, and Andrew Stuart. Neural operator: Graph kernel network for partial differential equations. InICLR 2020 Workshop on Integration of Deep Neural Models and Differential Equations, 2019.URL",
  "Erik J Bekkers. B-spline CNNs on lie groups. In International Conference on Learning Representations,2020. URL": "Erik J. Bekkers, Maxime W. Lafarge, Mitko Veta, Koen A. J. Eppenhof, Josien P. W. Pluim, and RemcoDuits. Roto-translation covariant convolutional networks for medical image analysis. In Alejandro F.Frangi, Julia A. Schnabel, Christos Davatzikos, Carlos Alberola-Lpez, and Gabor Fichtinger (eds.),Medical Image Computing and Computer Assisted Intervention MICCAI 2018, pp. 440448, Cham,2018. Springer International Publishing.",
  "International Conference on Learning Representations, 2022. URL": "Xu Chen, Yongjie FU, Shuo Liu, and Xuan Di.Physics-informed neural operator for coupled forward-backward partial differential equations. In 1st Workshop on the Synergy of Scientific and Machine LearningModeling @ ICML2023, 2023. URL Taco Cohen and Max Welling. Group equivariant convolutional networks. In Maria Florina Balcan andKilian Q. Weinberger (eds.), Proceedings of The 33rd International Conference on Machine Learning,volume 48 of Proceedings of Machine Learning Research, pp. 29902999, New York, New York, USA,2022 Jun 2016. PMLR. URL Taco Cohen, Maurice Weiler, Berkay Kicanaoglu, and Max Welling. Gauge equivariant convolutional net-works and the icosahedral CNN. In International conference on Machine learning, pp. 13211330. PMLR,2019.",
  "Vladimir Fanaskov and I. Oseledets. Spectral neural operators. ArXiv, abs/2205.10573, 2022. URL": "Fabian B. Fuchs, Daniel E. Worrall, Volker Fischer, and Max Welling. Se(3)-transformers: 3d roto-translationequivariant attention networks. In Advances in Neural Information Processing Systems 34 (NeurIPS), 2020. Jacob Helwig, Xuan Zhang, Cong Fu, Jerry Kurtin, Stephan Wojtowytsch, and Shuiwang Ji. Group equiv-ariant Fourier neural operators for partial differential equations. In Proceedings of the 40th InternationalConference on Machine Learning, 2023. Miltiadis Kofinas, Naveen Shankar Nagaraja, and Efstratios Gavves. Roto-translated local coordinate framesfor interacting dynamical systems. In A. Beygelzimer, Y. Dauphin, P. Liang, and J. Wortman Vaughan(eds.), Advances in Neural Information Processing Systems, 2021. URL",
  "Conference on Neural Information Processing Systems, 2023a. URL": "Ning Liu, Yue Yu, Huaiqian You, and Neeraj Tatikola. Ino: Invariant neural operators for learning complexphysical systems with momentum conservation. In Francisco Ruiz, Jennifer Dy, and Jan-Willem van deMeent (eds.), Proceedings of The 26th International Conference on Artificial Intelligence and Statistics,volume 206 of Proceedings of Machine Learning Research, pp. 68226838. PMLR, 2527 Apr 2023b. URL Songming Liu, Zhongkai Hao, Chengyang Ying, Hang Su, Ze Cheng, and Jun Zhu.Nuno: a generalframework for learning parametric pdes with non-uniform data. In Proceedings of the 40th InternationalConference on Machine Learning, ICML23. JMLR.org, 2023c.",
  "Intelligence, 3(3):218229, March 2021. ISSN 2522-5839": "T. Nissen-Meyer, M. van Driel, S. C. Sthler, K. Hosseini, S. Hempel, L. Auer, A. Colombi, and A. Fournier.Axisem: broadband 3-d seismic wavefields in axisymmetric media. Solid Earth, 5(1):425445, 2014. doi:10.5194/se-5-425-2014. URL Jaideep Pathak, Shashank Subramanian, Peter Harrington, Sanjeev Raja, Ashesh Chattopadhyay, MortezaMardani, Thorsten Kurth, David Hall, Zongyi Li, Kamyar Azizzadenesheli, Pedram Hassanzadeh, KarthikKashinath, and Animashree Anandkumar.Fourcastnet: A global data-driven high-resolution weathermodel using adaptive fourier neural operators. arXiv preprint arXiv:2202.11214, 2022.",
  "Paul Shen, Michael Herbst, and Venkat Viswanathan. Rotation equivariant operators for machine learningon scalar and vector fields, 2022": "Justin Sirignano, Jonathan F. MacArt, and Jonathan B. Freund. DPM: A deep learning PDE augmentationmethod with application to large-eddy simulation. Journal of Computational Physics, 423:109811, 2020.ISSN 0021-9991. Maurice Weiler and Gabriele Cesa. General e(2)-equivariant steerable cnns. In H. Wallach, H. Larochelle,A. Beygelzimer, F. d'Alch-Buc, E. Fox, and R. Garnett (eds.), Advances in Neural Information ProcessingSystems, volume 32. Curran Associates, Inc., 2019.URL",
  "Equivariant and Coordinate Independent Convolutional Networks.2023.URL": "Minkai Xu, Jiaqi Han, Aaron Lou, Jean Kossaifi, Arvind Ramanathan, Kamyar Azizzadenesheli, JureLeskovec, Stefano Ermon, and Anima Anandkumar.Equivariant graph neural operator for modeling3d dynamics. arXiv preprint arXiv:2401.11037, 2024. Mingrui Zhang, Jianhong Wang, James B Tlhomole, and Matthew Piggott. Learning to estimate and refinefluid motion with physical dynamics. In Proceedings of the 39th International Conference on MachineLearning, 2022. Xuan Zhang, Limei Wang, Jacob Helwig, Youzhi Luo, Cong Fu, Yaochen Xie, Meng Liu, Yuchao Lin, ZhaoXu, Keqiang Yan, Keir Adams, Maurice Weiler, Xiner Li, Tianfan Fu, Yucheng Wang, Haiyang Yu, YuQingXie, Xiang Fu, Alex Strasser, Shenglong Xu, Yi Liu, Yuanqi Du, Alexandra Saxton, Hongyi Ling, HannahLawrence, Hannes Strk, Shurui Gui, Carl Edwards, Nicholas Gao, Adriana Ladera, Tailin Wu, Elyssa F.Hofgard, Aria Mansouri Tehrani, Rui Wang, Ameya Daigavane, Montgomery Bohde, Jerry Kurtin, QianHuang, Tuong Phung, Minkai Xu, Chaitanya K. Joshi, Simon V. Mathis, Kamyar Azizzadenesheli, AdaFang, Aln Aspuru-Guzik, Erik Bekkers, Michael Bronstein, Marinka Zitnik, Anima Anandkumar, StefanoErmon, Pietro Li, Rose Yu, Stephan Gnnemann, Jure Leskovec, Heng Ji, Jimeng Sun, Regina Barzilay,Tommi Jaakkola, Connor W. Coley, Xiaoning Qian, Xiaofeng Qian, Tess Smidt, and Shuiwang Ji. Artificialintelligence for science in quantum, atomistic, and continuum systems. arXiv preprint arXiv:2307.08423,2023.",
  "Subgroups are also groups; in other words, they satisfy the group axioms": "Definition A.3. Let (G, G) and (H, H) be two groups. Their (outer) direct product (G, G) (H, H) isdefined on the Cartesian product G H of the underlying sets, equipped with the group product definedasG H G H,(g1, h1) (g2, h2) = (g1 G g2, h1 H h2) with the condition that the elements of the factors G and H are independent from each other. If the groupH acts on G, the notion of direct product groups is generalized to semi-direct product groups, denoted asG H.",
  "The Euclidean group E(n) = Rn O(n) is the group of isometries of Euclidean space Rn, whichincludes translations and rotations": "The Special Euclidean group SE(n) = Rn SO(n) is a subgroup of E(n) and consists of rigidtransformations, which include translations and rotations, but the rotations are limited to properrotations (no reflections). The cyclic group C4, also known as the cyclic group of order 4 , is defined as the group consists offour elements, denoted by C4 = {R0, R90, R180, R270}, representing rotations of 0, 90, 180, and270, repectivelly.",
  "In accordance with the foundational principles outlined in the universal approximation theorem forFNOs (Kovachki et al., 2021), we extend these concepts through the following theorem:": "Theorem B.1 (Universal Approximation for FNOs). Let us consider two non-negative integers, s and s,where both s, s 0. Let G be a continuous operator, defined from Hs(T d; Rda) to Hs(T d; Rdu). Given anycompact subset K within Hs(T d; Rda) and for any arbitrary positive value of , there exists a Fourier NeuralOperator, denoted as N, mapping from Hs(T d; Rda) to Hs(T d; Rdu). This operator N, structured accordingto the form delineated in equation 6, maintains continuity as a mapping from Hs to Hs. Consequently, thisresults in the following inequality being satisfied:",
  "Building upon this theorem, we derive a corollary, that follows immediately from Theorem B.1, to addressthe modifications involving parameter mapping within the FNO framework:": "Corollary B.2 (Universal Approximation with Parameter Mapping). Let s, s 0. Assuming that G, acontinuous operator mapping from Hs(T d; Rda) to Hs(T d; Rdu), holds true. For any compact subset Kcontained in Hs(T d; Rda) and any given positive , there exists a modified Fourier Neural Operator, denotedas N. This operator N, mapping from Hs(T d; Rda) to Hs(T d; Rdu), incorporates the continuous andcompact operators Pa and Pu on Hs(T d; Rda) and Hs(T d; Rdu), respectively. The structure of N is asper equation 10, and it maintains continuity as an operator from Hs to Hs, thereby ensuring the followingcondition is met:supaKG(a) N(a)Hs .",
  "L2z": "with L = 2 and Lz = 6. The initial temperature generated satisfies periodic conditions for continuityaround the cylinders circumference. These initial temperatures distributions are made to demonstrate theeffectiveness and importance of the equivariant nature of CT-FNO. The second term introduces a higherinitial temperature at fixed locations on the cylinder; consequently, rotations will alter the initial heatdistribution. In various real-world applications, rotations will have a significant impact as well.",
  "C.2Details and Additional Results on Equivariant Adaptation of GNO": "For the implementation of GNO, we directly adopt the settings from Anandkumar et al. (2019). In thisapproach, the node features, denoted as fi for node i, comprise the function value and the positional vectorin Euclidean space (x, y, z coordinates) associated with the node. Similarly, the edge features, denoted aseij for the edge between nodes i and j, encompass all the function values and positional vectors of nodes iand j. How to design more sophisticated equivariant GNNs is a field of study (Satorras et al., 2021; Liu et al., 2023b;2022). Moreover, lately, there have been studies on more sophisticated designs of GNOs or their variants,such as Liu et al. (2023b); Xu et al. (2024), for certain tasks. A straightforward equivariant adaptation ofGNO, which we use to compare with CT-FNO, is to use a reference to embed geometric information, ina way that respects the underlying symmetries, in the node and edge features. For node i, we denote itscoordinates by xi, and we take the two points with the maximum and minimum function values, respectively,among its neighbors defined by the cut-off radius as reference points. We denote these two points as xminand xmax. Now, the node feature of the ith node, fi, comprises the function value and the distances betweennode i and the two reference points:",
  "C.3Rotation Equivariance": "Lemma C.1. Let D = {(x, y, z) R3|x2 + y2 = 1, 0 < z < 6} R3 be the cylindrical domain consideredwith the center of the base being the origin and T R0 be the space of time. Suppose that the functionsU : D T R solve the partial differential equation",
  "fR(x) := f(Rx)(14)": "Note that Lemma E.1 is most meaningful when the domain D is invariant under the rotation R, e.g., thedomain is a circle or the domain is R2. If the domain is a unit box, D = (0, 1)2, it is most meaningful toconsider rotation by 0, 90, 180 or 270."
}