{
  "Abstract": "In multi-task learning, the conventional approach involves training a model on multipletasks simultaneously. However, the training signals from different tasks can interfere withone another, potentially leading to negative transfer. To mitigate this, we propose a novellatent-expert approach (TensorPoly), that balances parameter efficiency with nuanced rout-ing methods. For experts, we reparameterize Low-Rank Adaptation (LoRA) by employing anentangled tensor through the use of tensor product operations and name the resulting ap-proach TLoRA. For routing function, we tailor two innovative routing functions according tothe granularity: TensorPoly-I which directs to each rank within the entangled tensor whileTensorPoly-II offers a finer-grained routing approach targeting each order of the entangledtensor. The experimental results from the multi-task T0-benchmark demonstrate that: 1)all latent-expert approaches surpass the corresponding dense approaches, highlighting thepotential of modular language models to mitigate negative inference in multi-task learningand deliver superior outcomes. 2) TensorPoly-I achieves higher parameter efficiency inadaptation and outperforms other modular LMs, which shows the potential of our approachin multi-task transfer learning 1.",
  "Introduction": "Recently, the de facto paradigm for natural language understanding (NLU) tasks has centered on leveraginglarge language models (LLMs) (He et al., 2021) that are pre-trained on a vast corpus of unlabelled dataand subsequently fine-tuned for specific tasks (Qiu et al., 2020; Ye et al., 2021). While this approach hassignificantly advanced the field, it often requires substantial computational resources and may not efficiently",
  "SOTA results": ": Left: Comparison between the dense models (LoRA, TLoRA) and latent-expert approaches(Poly, MHR, TensorPoly-I, TensorPoly-II). Poly/MHR use LoRA as the modules, TensorPoly-I andTensorPoly-II use TLoRA as the modules.Right: Adaptation parameters across different approachesin the fine-tuning process. To address the aforementioned issues, there have been, roughly, two general lines of research. The first lineaims to mitigate the computation and memory issue using lightweight alternatives known as parameter-efficient fine-tuning (PEFT), which updates only a small number of extra parameters while keeping mostpre-trained parameters frozen (Houlsby et al., 2019b; Li & Liang, 2021; Hu et al., 2021). However, thesesolutions need to train an adapter for each task, which does not take into account the fact that test tasksmay require solving different combinations of sub-problems compared to training tasks (Vu et al., 2020),thus failing to achieve compositional generalization (Rosenbaum et al., 2019; Ponti, 2021). The second line is to facilitate information sharing across multiple tasks using multi-task learning (MTL)approaches (Caruana, 1997; Zhang & Yang, 2021; Liu et al., 2019), which simultaneously train the modelon several tasks, allowing it to learn shared representations for all tasks involved. However, MTL necessi-tates access to all training tasks during the training phase, meaning that incorporating new tasks requiresretraining the model from scratch. This requirement significantly increases the computational burden andlimits the flexibility of the model to adapt to new tasks efficiently. A promising approach to address the above issues is the adoption of modular language models (Pfeifferet al., 2023; Ponti et al., 2023; Caccia et al., 2023), where modules are typically implemented as PEFTs fordifferent tasks (Hu et al., 2021; Houlsby et al., 2019a; Bach et al., 2022). Information flow is conditionallyrouted to a subset of these modules, which are then aggregated for the given task. This design facilitates thepositive transfer and systematic generalization (Pfeiffer et al., 2023). Recently, Poly and MHR were designedto handle diverse tasks by leveraging different combinations of latent experts (Ponti et al., 2023; Cacciaet al., 2023). Given |T | tasks, there are only |K| < |T | experts trained. We treat these |K| experts as latentexperts, and each task-specific adapter can be obtained by a linear combination of latent experts. Duringboth the multi-task pre-trained and fine-tuning, Poly implements adapters with LoRAs and concurrentlyoptimizes the LoRA inventory and a routing function. MHR partitions the LoRAs into multiple heads and usesa finer-trained routing among these heads. However, LoRA adapters are still limited in parameter efficiency,especially with expert libraries involving a huge number of adapters. In addition, we notice that previousapproaches only use linear combinations of experts, which implicitly assume that the given task has a linearrelationship with the expert modules, whereas the relations could be much more complicated in practice.To this end, the question of developing a modular language model that balances parameter efficiency with",
  "complex routing methods is critical for advancing the scalability and functionality of multi-task transferlearning": "To answer this question, we devise a new variant Poly model: TensorPoly, which mixes experts usingtensor product (Smolensky, 1990), an operation that maps two vectors in spaces V and W to a vectorin the tensor product space V W of the two vector spaces, associated with a bilinear map V W V W (3.3). This process enables the capture of higher-order interactions and structural relationshipsbetween input spaces (Kye, 2023). Tensor product has been successful as a strategy for compressing wordembeddings (Panahi et al., 2019; Gan et al., 2022). To achieve a higher parameter-efficient adapter, wehave reparameterized LoRA (Hu et al., 2021) adapters by employing an entangled tensor structure, wherethe high hidden and intermediate dimensions are decomposed into smaller dimensions in tensor productform. Consequently, the training matrix M Rdr in LoRA is reparameterized into a finer-grained tensorL RNr N dR), named TLoRA (4.1). This reparameterization allows for a more nuanced manipulationof the models parameters, facilitating a more efficient adapter process for more complex tasks. The entangledtensor configuration introduces two critical hyper-parameters: the tensor rank (R) and the tensor order(N). Leveraging these parameters, we develop two distinct routing functions designed to select modules onvarying levels of granularity. As depicted in , TensorPoly-I employs a routing mechanism thatassigns distribution scores to different tensor ranks, facilitating the selection of modules based on their rankgranularity. Further advancing this concept, we propose a more refined routing function, TensorPoly-II,which targets even finer-grained tensors as activated modules. Each module is associated with a specificorder of the entangled tensor. Once modules are selected via the routing function, they are aggregatedthrough a tensor product operation, enabling a sophisticated and dynamic assembly of modular skills. To evaluate the effectiveness and parameter efficiency of our approach, we apply our methods against a seriesof competitive baselines on T0 (Sanh et al., 2021), a widely used benchmark in multi-task transfer learningcovering a high variety of language understanding tasks. Our experiments reveal several key insights: i)Modular language models such as Poly, MHR and TensorPoly frameworks consistently outperform tradi-tional PEFT approaches LoRA and TLoRA (), underscoring the effectiveness of modular LLMsin facilitating positive transfer across multi-task environments. ii) TensorPoly-I demonstrates competi-tive results against Poly and MHR, while simultaneously achieving higher parameter efficiency in adaptation.This efficiency gain highlights the benefits of our tensorized module approach in achieving high performancewith lower parameter overhead. iii) A comparative analysis between TensorPoly-I and TensorPoly-IIindicates that the latters finer-grained routing mechanism does not contribute to improved performance.This outcome suggests that while granularity in module selection is valuable (Caccia et al., 2023), there is acomplexity threshold beyond which additional granularity may not yield further benefits.",
  "Published in Transactions on Machine Learning Research (10/2024)": "Qingru Zhang, Minshuo Chen, Alexander Bukharin, Pengcheng He, Yu Cheng, Weizhu Chen, and Tuo Zhao.Adaptive budget allocation for parameter-efficient fine-tuning. arXiv preprint arXiv:2303.10512, 2023a. Renrui Zhang, Jiaming Han, Aojun Zhou, Xiangfei Hu, Shilin Yan, Pan Lu, Hongsheng Li, Peng Gao, andYu Qiao. Llama-adapter: Efficient fine-tuning of language models with zero-init attention. arXiv preprintarXiv:2303.16199, 2023b.",
  "Multi-task Learning": "The key to MTL is information sharing across tasks. For this purpose, AdapterSoup Chronopoulou et al.(2023) trains each adapter for each domain, and performs weight-space averaging of adapters trained ondifferent domains.Huang et al. (2023) introduce LoRAhub to aggregate the LoRA modules trained ondiverse tasks. They first train a group of LoRA modules that are specialized in each task, then randomlyselect a subset of modules, and finally learn a set of weights to combine these LoRA models using gradient-freeoptimization. AdapterFusion (Pfeiffer et al., 2020) proposes a two-stage algorithm that leverages knowledgefrom multiple tasks.Similarly to LoRAhub, a group of task-specific adapters learn to encapsulate thetask-specific information, and in the second stage, a fusion layer combines the trained adapters.Pontiet al. (2023) introduces a variable-size module routing mechanism, Poly, based on the assumption thateach task correlates with a specific subset of latent skills drawn from a comprehensive inventory of modules.Building upon Poly, (Caccia et al., 2023) introduces a finer-grained multi-head routing function MHR wherethe experimental findings underscore the significance of the routing function during the pre-training phase.Mixture-of-expert (MoE) methods such as TaskMoE Kudugunta et al. (2021) learn a routing function thatallocates modules to tasks end-to-end. We propose TensorPoly-I and TensorPoly-II, two novel routing mechanisms based on TLoRA.TensorPoly-I is a variant of Poly using TLoRA as the modules. In this setting, each rank of the entangledtensor corresponds to a separate expert. TensorPoly-II is a finer-grained routing function targeting eachorder of the entangled tensor.",
  "Expert Merging": "Once the experts are activated in the forward pass, we need to aggregate their outputs. There is an increasingfocus on aggregating adapters from different domains through expert merging. The simplest operation ofmerging is averaging the weights of different experts, where the weight of each expert is set according to therouting probability generated by the router (McMahan et al., 2017; Choshen et al., 2022; Matena & Raffel,2022; Chronopoulou et al., 2023; Huang et al., 2023; Muqeeth et al., 2023; Ostapenko et al., 2023; 2024).Poly Ponti et al. (2023) uses the latent experts and integrates the experts by averaging the weights. MHRCaccia et al. (2023) partitioned the LoRA experts into different heads, which are eventually concatenatedto obtain a merged expert.",
  "Private expertsShare expert": ": Compare with three training paradigms in multi-task transfer learning. Left is the private training,for each task, we train the corresponding expert individually. Middle is the shared version, for all the tasks,we train an expert continually, and as a result, we only get one expert. Right is the latent experts model,for all the tasks, we train a subset of \"latent\" experts, so each corresponding expert can be seen as a linearcombination of these latent experts.",
  "Background": "In multiple transfer learning tasks, we define a set of tasks as T = {T1, ..., T|T |}. This set is divided into twosubsets train Ttrain and test Ttest. The goal of multi-task transfer learning is to apply the knowledge fromthe training tasks Ttrain to the test tasks within Ttest. This process involves two main phases. Building ontop of a foundation model, the first phase consists of multi-task pre-training using the dataset in tasks Ttrain.The second consists of a few-shot adaptation, where the learned adapters are fine-tuned independently oneach test task in Ttest. We follow the procedure from (Raffel et al., 2020) and formulate each task as atext-to-text problem.",
  "Module: LoRA": "Lora is a recently proposed adapter architecture that achieves a competitive balance between performance andparameter efficiency (Hu et al., 2021; Mahabadi et al., 2021). For each linear transformation correspondingto the query (q), key (k), value (v), and output (o) of the self-attention layers, LoRA modifies the base modelparameters as follows:",
  "Polytropon (Poly): Mixture of Latent Experts with Linear Combination": "Poly/ MHR addresses the multi-task problem by softly sharing latent experts across tasks. Each Poly layercontains 1) an inventory of latent experts M = {1, . . . , m} with |M| |T |; 2) a routing function r()that chooses which subset of the experts to combine for each task. Each latent expert corresponds to aLoRA adapter, where i are its associated parameters A(i), B(i) Rdr. r() is implemented as a taskmodule routing matrix Z R|T ||M|.z = Z,: R|M| is a routing vector of task T, with cell Z,jbeing the probability logits of using module j for task T in the current layer. Differently from mixture-of-experts (Fedus et al., 2022), which perform token-level top-k routing, Z converges to a binary matrix,defining a soft partition over modules. This is achieved by using a Gumbel-sigmoid distribution (Jang et al.,2017) during training, with Z,j Gumbel(Z,j). At each forward pass, Poly can be defined as:",
  "j Z,j , and A(i), B(i), A, B Rdr. We normalize the mixing coefficients Z,i for each task": "to ensure that the number of active modules does not affect the norm of A, B. Overall, this approachenables different subsets of modules to be activated for the current layer and combined in a task-specific way.Following TLoRA, the output of the Poly layer is added to the output of the original layer of the frozenbackbone: h = W0x + sA(B)x.",
  "Tensor, Tensor Product, Entangled Tensor": "Tensor.The tensor A is a multi-dimensional array of elements (called components) of R, each beingdenoted by its integer coordinates in the array; e.g., for a two-dimensional array, the component at positioni, j N is denoted Ai,j. The order of a tensor is how many indices it has (e.g., a vector v is a first-ordertensor, a matrix M is a second-order tensor, etc.). Tensor Product.The tensor product V W of two vector spaces V and W is a vector space to which isassociated a bilinear map V W V V that maps a pair of vectors (v, w), v V, w W to a vector inV W, denoted as v w. We can create tensor product spaces by more than one application of a tensorproduct, H = U V W, with arbitrary bracketing since the tensor product is associative. The tensorproduct space of N vector spaces in such form is said to have a tensor order of N.",
  ": TensorPoly-I and TensorPoly-II. We illustrate how to reparameterize the LoRA matrix R6255": "with 4 tensor A R355. In this case, the tensor rank R = 3, tensor order N = 4. For TensorPoly-I,the routing function Z is designed to select which rank of the entangled tensor is activated for a given task.Conversely, TensorPoly-II introduces a more granular control by selecting tensor rank and tensor order.",
  "TLoRA": "To achieve a higher parameter efficiency, we reparameterize the LoRA using the tensor product, which iswidely used in compressing the word embedding (Panahi et al., 2019; Gan et al., 2022). Essentially, the low-rank matrices A and B are further reparameterized to entangled tensors of rank R and order N, following(3.3). For a given input x, TLoRA modifies the projection output h as:",
  "TensorPoly: Mixture of Latent Experts using Tensor Products": "Latent-expert approaches have been proven effective in the few-shot multi-task transfer learning (Ponti et al.,2023; Caccia et al., 2023). Poly merges the latent experts by averaging the weight. MHR partitioned the LoRAinto several heads and use a piecewise linear aggregation (i.e., linear within disjoint intervals). Instead ofusing a linear combination, we propose TensorPoly models that incorporate TLoRA as the core module.Specifically, we propose a TensorPoly-I and TensorPoly-II according to the routing granularity. In eachlayer, TensorPoly-I use a routing matrix Z R|T |R to determine which rank within the entangled tensorcan be activated for a given task. In this case, each rank Ak corresponds to an expert in the forward",
  "d is a third-order tensor": "Contrast to the TensorPoly-I with a routing matrix, the routing for TensorPoly-II is conceptualized asa third-order tensor Z R|T |NR, which offers a finer-grained level in directing the models focus acrossdifferent ranks and orders of the tensor space. This sophisticated routing mechanism facilitates the selectionof finer-grained tensor elements, which are then aggregated through a tensor product operation.",
  "Experiments": "To evaluate the effectiveness of our approaches, we perform experiments on multi-task transfer learningdatasets T0 benchmark (Sanh et al., 2021), which is widely used in few-shot generalization approaches. Inaddition, a diverse array of tasks in T0 benchmark can help us test the generalization ability across dif-ferent tasks. We conduct a comparative analysis between routing approaches (Poly, MHR, TensorPoly-I,TensorPoly-II) and their corresponding single-expert (without routing function) version (LoRA,TLoRA),as detailed in 5.2. We also investigate how parameter efficiency and effectiveness are influenced by hyper-parameters rank R and order N in an entangled tensor (5.3.1).",
  "Datasets and Evaluation": "DatasetsTo evaluate the generalization capabilities of our models, we adopt the same benchmarkingstrategy as (Liu et al., 2022), utilizing a subset of tasks designated as held-out from the multitask training.This benchmark encompasses a diverse array of tasks, including sentence completion (COPA (Roemmeleet al., 2011), H-SWAG(Zellers et al., 2019) and Story Cloze (Sharma et al., 2018) datasets), natural lan-guage inference (ANLI (Nie et al., 2019), CB (De Marneffe et al., 2019) and RTE (Dagan et al., 2005)),coreference resolution (WSC (Levesque et al., 2012), Winogrande (Sakaguchi et al., 2021)), and word sensedisambiguation (WIC (Pilehvar & Camacho-Collados, 2018)). For each task, our evaluation strategy in-volves constructing sets of five few-shot training examples, which are generated by sampling subsets fromeach dataset using different seeds. We then report the median performance. It should be noted that theprompt examples from each dataset using the prompt templates from P3 (Bach et al., 2022).",
  "TensorPoly-I85.291.745.042.542.596.763.196.668.669.860.669.3TensorPoly-II84.790.544.441.042.094.358.795.767.668.759.968.0": ": Results on the T0 few-shot benchmark. All the results in our implementation are the median scoreof 3 random seeds . For all the baseline scores, we quote the results from Liu et al. (2022). Thevalue in bold is the best score. EvaluationFor the evaluation of our models, we employ the rank classification methodology as outlined bythe Liu et al. (2022) study. This approach involves ranking the models log-probabilities for all possible labelstrings associated with each task. The models prediction is deemed correct if the label string with the highestlog-probability ranking corresponds to the correct answer. This method allows for a nuanced assessment ofthe models predictive accuracy by examining its ability to prioritize the correct label over others based ontheir calculated log-probabilities, offering a precise measure of its understanding and processing of the taskat hand.",
  "dR + RN": ": Number of parameters (per layer) used for each method. d is the input and output dimension ofthe training parameters. We assume they are identical. r is the rank in the LoRA, where r d. N and Rare the order and rank of entangled tensors respectively. S is the number of modules in Poly. In our comparative analysis, we initially set the benchmark by evaluating the performance of the TLoRAmodel against the traditional full fine-tuning approach, referred to as FullFT. To facilitate a fair comparison",
  "Results": "Tab. 1 presents the mean downstream accuracy for 11 held-out tasks in the T0 benchmark. We reported mostof the results from (Liu et al., 2022). When evaluating the performance of various PEFT approaches againstsingle-expert performances, it is observed that many PEFT strategies achieve similar outcomes while utilizinga significantly smaller subset of training parameters compared to the FullFT method. Furthermore, the LoRAmethod within our training framework further illustrates the efficiency of these methods. Specifically, TLoRAachieves a competitive score of 66.1, closely trailing the original LoRAs score of 66.8, while requiring onlyfewer training parameters used by LoRA. This demonstrates that TLoRA not only matches the effectivenessof LoRA in terms of performance but also achieves a higher parameter efficiency. In our analysis, we initially contrast the modular model against the dense model, followed by a comparisonof routing-based approaches with a single adapter strategy. Within this context, we utilize both LoRA andTLoRA as baselines for these routing techniques. According to the results presented in Tab. 1, the Polymodel demonstrates superior performance over LoRA by a margin of 2.0 points.Moreover, TensorPolyexhibits an improvement of 3.2 points over the base TLoRA model, underscoring the superiority of routingin enhancing multi-task generalization within multi-task transfer learning. When evaluating the various modular models, TensorPoly-I stands out by not only on par with the recentstate-of-the-art achievements but also by outperforming TensorPoly-II, despite the latter employing a moregranular routing function. This finding is particularly noteworthy, as it suggests that the increased specificityof the routing function in TensorPoly-II does not necessarily translate to superior performance. We willdiscuss this in .4.",
  "Rank and Order Analysis": "For TensorPoly, rank R and order N correlate with the number of experts. Tab. 2 illustrates how thetensor rank R and the tensor order N affect the training and adaptation parameters.As illustrated in (left), when the tensor rank is set to 1, it corresponds to the original TLoRA configuration. Anincrease in tensor rank necessitates a larger number of training parameters. Consequently, there is a notableenhancement in performance. In addition, we investigate if the rank will give more capacity to the model.As depicted in (right), as the increase of the rank, we can get a lower validation loss score duringthe multi-task pre-training. This progression underscores the direct correlation between the tensor rank andthe capability of the model.",
  ": Rank analysis in the TensorPoly-I, Left denotes the average accuracy over 11 held-out tasksaccording to different rank. Right is the validation loss in the multi-task pre-training process": "The tensor order N, correlates with the granularity of training parameters (experts) (4.2); a tensor of order4 yields a finer-grained module compared to one of order 2. Our research examines the impact of varyingthe tensor orders on performance outcomes. For simplicity, we constrain our analysis to tensors of order 2and 4. Our results demonstrate that a tensor of order 2 outperforms one of order 4 by a margin of 1.7 forthe TensorPoly-I. For TensorPoly-II, an order-2 tensor exceeds the performance of an order-4 tensor by4.8, suggesting that a balance must be struck between the granularity of experts and its efficacy. Althoughhigher-order tensors may conserve training parameters, this comes at the cost of diminished performance.",
  "Routing Analysis": "Routing OnlyIn the paper Caccia et al. (2023), the MHR study demonstrates that fine-tuning solelythe routing function can yield competitive outcomes. This insight provides a valuable perspective for ourinvestigation into various routing strategies within the TensorPoly framework. In line with this approach,we focus exclusively on fine-tuning the routing function during the few-shot adaptation process, indicated bythe notation z. This methodological choice allows us to isolate the impact of the optimization of the routingfunction on the overall performance of the TensorPoly model, thereby offering a clearer understanding of howdynamic routing contributes to the adaptability and efficiency of the model in few-shot learning scenarios. As detailed in Tab. 4, an initial observation reveals that the routing parameters necessitate a small numberof training parameters, achieving extreme parameter efficiency. TensorPoly-I-z achieves a accuracy scoreof 66.3 while only using 8.6k adaptation parameters. TensorPoly-II-z achieves 65.4 with 17.3k parameters.MHR-z achieve the 68.3 with 220K adaptation parameters. The results indicate that TensorPoly-I-z can",
  ": We compare several fine-tuning approaches. represents we only fine-tune the modules. zmeans we only fine-tune the routing functions. We set the order N = 2 for this comparison": "achieve competitive results as LoRA with higher parameter efficiency.Notably, the average accuracy ofTensorPoly-I-z, and TensorPoly-II-z lag behind their counterparts where both the modules and therouting function undergo fine-tuning. This disparity highlights the critical role that modules play in thefine-tuning process for TensorPoly. Modules OnlyTo verify whether the routing is important in few-shot fine-tuning, we discard the routingfunction and average the pre-trained modules in the fine-tuning process, indicated by the notation . Theresult in Tab. 4 shows that there is only a slight decrease for MHR- and TensorPoly-I- compared to theircounterparts where both the modules and the routing function are fine-tuned. This result is consistent withthe conclusion in Caccia et al. (2023).",
  "Investigate more about the latent expert approach": "Since we add more training parameters (we use more experts), it is necessary to investigate if the improvementis caused by adding more training parameters. To investigate this, In Caccia et al. (2023), they assign abinary module allocation to each data point in a minibatch, disregarding task information. At test time,the learned modules are averaged into one single module. This approach is named random-, the random-performs similar to single LoRA, which proved that the \"routing\" function is important for latent-expertapproach in multi-task transfer learning.",
  "Why TensorPoly-II underperform the TensorPoly-I?": "Finer-grained routing has been shown to be effective in multi-head routing function (Caccia et al., 2023).However, our experimental results underscore that the finer-grained tensor product routing did not contributeto improved final performance in our models. This discrepancy prompts a future line of inquiry: we planto explore whether there exist specific benchmarks or conditions under which the tensor-product interactioncould demonstrate its purported benefits. Identifying such scenarios will be crucial to harnessing the potentialadvantages of tensor product routing in modular language models.",
  ": Validation loss compare across different models": "In the current methodology, each tensor-based module is not specialized towards any particular domain. Inthe future, we intend to explore a more tailored training strategy. This will involve dedicating each tensorto a specific domain and subsequently aggregating these domain-specialized tensors using tensor productoperations. Our objective is to assess whether this domain-specific aggregation approach can yield superiorgeneralization capabilities.",
  "Conclusion": "We introduce a novel modular language model named TensorPoly. This model incorporates tensorized mod-ules, specifically TLoRA, to significantly reduce the number of training parameters required by the traditionalLoRA approach. We employ two distinct strategies for aggregating activated modules: TensorPoly-I directsto each rank and a more finely routing, named TensorPoly-II targets each order of the tensor. Our evalua-tion across various multi-task learning scenarios reveals that modular language models, such as TensorPoly,surpass the performance of single-adapter models. This underscores the importance of sharing task infor-mation through a routing function in multi-task learning contexts. Notably, TensorPoly-I achieves state-of-the-art results, highlighting the effectiveness of the TensorPoly framework. However, TensorPoly-IIdoes not outperform TensorPoly-I in our experimental settings, suggesting areas for further investigationin future research.",
  "Broader Impact Statement": "The research reported in this paper proposes a novel type of language model, and is primarily a theoreti-cal contribution accompanied by experiments to show the practical usefulness on the model, especially inmitigation of negative inference in multi-task learning. Thus, the impact is primarily in generic modellingand empirical performance in situations where existing approaches (e.g., LoRAs) are used, but does not perse create new use scenarios, or raise new concerns, ethical or otherwise, beyond those already present forLoRAs.",
  "Junxian He, Chunting Zhou, Xuezhe Ma, Taylor Berg-Kirkpatrick, and Graham Neubig. Towards a unifiedview of parameter-efficient transfer learning. arXiv preprint arXiv:2110.04366, 2021": "Neil Houlsby, Andrei Giurgiu, Stanislaw Jastrzebski, Bruna Morrone, Quentin De Laroussilhe, Andrea Ges-mundo, Mona Attariyan, and Sylvain Gelly. Parameter-efficient transfer learning for nlp. In InternationalConference on Machine Learning, pp. 27902799. PMLR, 2019a. Neil Houlsby, Andrei Giurgiu, Stanislaw Jastrzebski, Bruna Morrone, Quentin De Laroussilhe, Andrea Ges-mundo, Mona Attariyan, and Sylvain Gelly. Parameter-efficient transfer learning for nlp. In InternationalConference on Machine Learning, pp. 27902799. PMLR, 2019b.",
  "Yixin Nie, Adina Williams, Emily Dinan, Mohit Bansal, Jason Weston, and Douwe Kiela. Adversarial nli:A new benchmark for natural language understanding. arXiv preprint arXiv:1910.14599, 2019": "Oleksiy Ostapenko, Lucas Caccia, Zhan Su, Nicolas Le Roux, Laurent Charlin, and Alessandro Sordoni. Acase study of instruction tuning with mixture of parameter-efficient experts. In NeurIPS 2023 Workshopon Instruction Tuning and Instruction Following, 2023. Oleksiy Ostapenko, Zhan Su, Edoardo Maria Ponti, Laurent Charlin, Nicolas Le Roux, Matheus Pereira,Lucas Caccia, and Alessandro Sordoni. Towards modular llms by building and reusing a library of loras.arXiv preprint arXiv:2405.11157, 2024.",
  "Edoardo Ponti. Inductive Bias and Modular Design for Sample-Efficient Neural Language Learning. PhDthesis, University of Cambridge, 2021": "Edoardo Maria Ponti, Alessandro Sordoni, Yoshua Bengio, and Siva Reddy. Combining parameter-efficientmodules for task-level generalisation. In Proceedings of the 17th Conference of the European Chapter ofthe Association for Computational Linguistics, pp. 687702, 2023. Xipeng Qiu, Tianxiang Sun, Yige Xu, Yunfan Shao, Ning Dai, and Xuanjing Huang. Pre-trained models fornatural language processing: A survey. Science China Technological Sciences, 63(10):18721897, 2020. Colin Raffel, Noam Shazeer, Adam Roberts, Katherine Lee, Sharan Narang, Michael Matena, Yanqi Zhou,Wei Li, Peter J Liu, et al. Exploring the limits of transfer learning with a unified text-to-text transformer.J. Mach. Learn. Res., 21(140):167, 2020.",
  "Keisuke Sakaguchi, Ronan Le Bras, Chandra Bhagavatula, and Yejin Choi. Winogrande: An adversarialwinograd schema challenge at scale. Communications of the ACM, 64(9):99106, 2021": "Victor Sanh, Albert Webson, Colin Raffel, Stephen H Bach, Lintang Sutawika, Zaid Alyafeai, AntoineChaffin, Arnaud Stiegler, Teven Le Scao, Arun Raja, et al. Multitask prompted training enables zero-shottask generalization. arXiv preprint arXiv:2110.08207, 2021. Rishi Sharma, James Allen, Omid Bakhshandeh, and Nasrin Mostafazadeh. Tackling the story ending biasesin the story cloze test. In Proceedings of the 56th Annual Meeting of the Association for ComputationalLinguistics (Volume 2: Short Papers), pp. 752757, 2018.",
  "Paul Smolensky. Tensor product variable binding and the representation of symbolic structures in connec-tionist systems. Artificial intelligence, 46(1-2):159216, 1990": "Yi-Lin Sung, Varun Nair, and Colin Raffel. Training neural networks with fixed sparse masks. In A. Beygelz-imer, Y. Dauphin, P. Liang, and J. Wortman Vaughan (eds.), Advances in Neural Information ProcessingSystems, 2021. URL Tu Vu, Tong Wang, Tsendsuren Munkhdalai, Alessandro Sordoni, Adam Trischler, Andrew Mattarella-Micke, Subhransu Maji, and Mohit Iyyer. Exploring and predicting transferability across nlp tasks. arXivpreprint arXiv:2005.00770, 2020.",
  "A.2FLOP Analysis": "TLoRA aims to reduce the number of training parameters by parameterizing the original LoRA architecture,but it does not alter the computational process of a LoRA. Thus, TLoRA might conceivably incur additionalcomputational overhead compared to a standard LoRA. To understand this, we analyze the floating-pointoperations (FLOPs) involved in TLoRA. Consider the tensor product of a vector a of size n1 with a vector b of size 1n, resulting in a matrix C ofsize n n. The product operation involves n2 multiplications due to the n elements in each of the vectors aand b. As described in and shown in , the additional computational effort in TLoRA stemsfrom the tensor product operations, dictated by the order of the tensor. Specifically, for parameterizingwith a dimension d, rank r, and tensor rank R, the number of extra computations required is approximatelyd r R. To test the time consumption according to the Flop analysis, we show the training time in Tab 6. The resultsindicate that although the tensor product can reduce the training parameters, we need more training timeaccording to the original LoRA adapters.",
  "A.3Few-shot finetuning parameter size over different PEFT approaches": "We investigate the training parameter size over PEFT approaches in the few-shot finetuning process. Aspresented in Tab. 7, TLoRA obtains competitive results while using only 60% training parameters thanthe original LoRA in this train setting. Compared with the latent experts approach Poly, TensorPoly-Iwith tensor rank R = 8 and order N = 2, get almost the same results with fewer finetuning parameters.TensorPoly-I(R=20,N=2) obtain the best results with 27.8 finetuning parameters. Notably, the finetuningparameters are not the adaption parameters we present in Tab. 3.",
  "A.4Routing across different tasks": "To investigate the routing function across different tasks, we plot the routing distributions for tasks suchas Question Answering and Summarization.As depicted in , the routing function distributionvaries across different layers for each task. Notably, Closed-Book QA exhibits greater sparsity compared tomulti-choice QA. We will conduct further analysis of the routing function in various tasks to gain deeperinsights.",
  "A.5Latent Experts Visualization": "We visualize the latent experts in our models. As depicted in , we draw the experts weight dis-tribution in layer . The distribution of expert weights varies in different layers. Especially, Theexpert weights in layer 16 seem completely different from the experts in layers . We also draw thesimilarity of expert weights across different layers in ."
}