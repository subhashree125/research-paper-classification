{
  "Abstract": "Systems characterized by evolving interactions, prevalent in social, financial, and biologicaldomains, are effectively modeled as continuous-time dynamic graphs (CTDGs). To managethe scale and complexity of these graph datasets, machine learning (ML) approaches havebecome essential. However, CTDGs pose challenges for ML because traditional static graphmethods do not naturally account for event timings. Newer approaches, such as graphrecurrent neural networks (GRNNs), are inherently time-aware and offer advantages overstatic methods for CTDGs. However, GRNNs face another issue: the short truncationof backpropagation-through-time (BPTT), whose impact has not been properly examineduntil now. In this work, we demonstrate that this truncation can limit the learning ofdependencies beyond a single hop, resulting in reduced performance. Through experimentson a novel synthetic task and real-world datasets, we reveal a performance gap between fullbackpropagation-through-time (F-BPTT) and the truncated backpropagation-through-time(T-BPTT) commonly used to train GRNN models. We term this gap the \"truncation gap\"and argue that understanding and addressing it is essential as the importance of CTDGsgrows, discussing potential future directions for research in this area.",
  "Introduction": "In many domains, data naturally takes the form of a sequence of interactions between various entities, whichcan be represented as an evolving network. Examples include interactions between users on social networks,card payments from users to merchants in payment networks, or bank transfers between entities in financialnetworks. These interactions typically involve only a pair of entities and are often modeled as a dynamic graph,where each entity is represented by a node and each interaction by an edge with an associated timestamp. Unlike static graphs, where links between entities are persistent, dynamic graphs capture the sequentialaspect of interactions, which can provide valuable information for different inference tasks. In these settings,the latent variables associated with nodes, such as user preferences in social networks, can evolve over time.Tasks on dynamic graphs involve predicting certain edge or node properties or the likelihood of an eventinvolving two nodes at a specific point in time based on past information.",
  "Interaction": ": Truncation of temporal history becomes severe in dynamic graphs. (left) Sequencebased data can be grouped by sequence when defining batches. In this specific example of sequences withtwo events, with a batch capacity of 4 entity updates, we can include two sequences per batch. Temporaldependencies between the events (horizontal dotted lines) are not broken by batching. (right) Due to theinteractions between states, we cannot consider isolating a subset of entities in a batch on dynamic graphsas we need the counterparty entitys state to update an entitys state when an event occurs. Batches aredefined by time instead of by entity but this leads to more extreme gradient truncation along the time axis(time dependencies are broken by batching). In the example, with the same capacity of 4 entity updates,each batch now includes only a single event per entity. Notably, (Dai et al., 2017; Trivedi et al., 2019; Kumar et al., 2019; Rossi et al., 2020) have proposed treatingsuch dynamic graphs as dynamical systems where a state for each entity evolves over time. The dynamics ofthese states are based on recurrent neural network (RNN) cells that use the previous states of both interactingnodes when computing the new states, therefore coupling both sides of an interaction at the time of an event.We call this class of models graph recurrent neural networks (GRNNs) because they are a straightforwardextension of the RNNs used for sequence modeling to dynamic graphs. Although there are differences in how various GRNN approaches handle training, all of them have in commonthat batches are formed using sequential time windows over the events. Backpropagation is applied to eachbatch to obtain the gradients with respect to the learnable parameters and therefore the learning signalcannot cross batch boundaries. In other words, this truncation of the backpropagation ignores the dependenceof information older than the current batch. In sequence modeling tasks, one typically has many sequences that are fully independent. If small enough,these sequences can be included in their entirety in a batch, or alternatively, they can be broken down intosizable chunks thus mitigating the impact of truncating the backpropagation (, left). On dynamicgraphs, however, it is not possible to split the data into different sequences per entity due to the coupleddynamics. Effectively, we have a single global sequence and batches need to be defined over globally orderedinteraction events, from oldest to newest (, right). Because such a sequential batch of events caninvolve completely different entities, if the number of entities is large enough one can find themselves in asituation where batches include a single update per entity. This in turn means that, from the entity pointof view, only temporal dependencies spanning a single hop in the graph can be learned accurately. Suchdrastic truncation could lead to incorrect training gradients and a failure in learning to leverage longer termdependencies existing in the data. The main goal of this work is to investigate the impact of this truncation in GRNN models bycomparing the training approach proposed in previous works with F-BPTT. We propose a synthetic edgeregression task on a dynamic graph that truncated backpropagation fails to learn when dependencies over",
  "Published in Transactions on Machine Learning Research (12/2024)": ": Truncated BPTT results in worse performance across most datasets and metrics. Resultson the benchmark dynamic graph datasets showing that there is a performance gap between the modelstrained with truncated and full backpropagation. For Wikipedia and MOOC, the reported values are themeans and standard errors on the test set over the different seeds.",
  "Background": "Initial approaches to dynamic graphs relied on static GNNs applied to different snapshots of the graphover chosen temporal windows. Because these are too dependent on the granularity of the time windows,ignoring the ordering of events within each window, other approaches that can more naturally cope withthe sequential nature of edges were developed. These can be broadly categorized into transformer and RNNbased approaches, mirroring the status quo in sequence modeling, together with a third class of methodsbased on random walks on the temporal graph. Transformer based approaches such as TGAT (Xu et al., 2020), DyG2Vec (Alomrani et al., 2024) andDyGFormer (Yu et al., 2023) explicitly consider a temporal neighborhood as the context for each prediction,typically restricted to a few hops. While, by construction, this limits the extent of past information thatthe model can leverage, these methods dont suffer from the same issue as RNN based approaches wherethe computational graph that is back-propagated through is a truncated version of the computational graphused to arrive at a forward prediction. Furthermore, these approaches often still require some degree ofapproximation in the form of subsampling of the temporal neighborhood (also known as neighborhood dropout). Random walk-based methods (Wang et al., 2022; Jin et al., 2022) take a similar approach where rather thansampling a neighborhood of a node of interest, temporal random walks over the dynamic graph are usedto aggregate information that is relevant for inference. While a random walk offers a limited context forinference, because backpropagation is run on the same computational graph used during the forward pass,these methods dont suffer from the truncation issue that is the focus of this work.",
  "Graph Recurrent Neural Networks (GRNNs)": "RNN based approaches define a dynamical system over the network where the state comprises a hidden statefor every node, i [1..N], in the network: h =h(1), . . . , h(N) RNm. For a k-th event between a sourcenode, sk, and a destination node, dk, at time tk, the hidden states, h(sk) and h(dk) for the nodes involved inthe interaction are updated using a pair of functions, gs and gd:",
  "h(dk)k= gdt(dk)k, h(dk)k1, h(sk)k1, xk .(1)": "Here, (t) is an optional function producing an embedding for the time elapsed since the last update foreach node, and xk the message of the current interaction (which could itself be a combination of edge andnode features). These functions are generally based on RNN cells such as LSTM (Hochreiter & Schmidhuber,1997) or GRU (Cho et al., 2014), therefore, extending the use of RNNs to the dynamic graph setting. We willrefer to these as GRNNs, noting that other names have been used in the literature, such as memory-basedtemporal graph neural networks (Zhou et al., 2023) and message passing temporal graph networks (Souzaet al., 2022). A more general framework for GRNNs is discussed in Appendix A. An early example of the GRNN approach is Wang et al. (2016) which proposes a temporal point-processmodel for event prediction where a latent state for each entity in the network is kept and updated on each",
  "g: Edge update": ": Three different batching strategies illustrated. Four nodes with respective states h1 . . . h4 interact asin until time t3. Each blue box denotes an interaction, where the hidden states of the two interactingnodes are updated. On the left the approach of Dai et al. (2017) where a different computation graph is builtfor each mini-batch. Due to the sequential processing within a batch, computational efficiency is lost. Inthe middle the t-Batching strategy of Kumar et al. (2019) which uses variable sized batches to guarantee nosequential dependencies within a batch, allowing parallel processing. On the right, the approach of Rossi et al.(2020) that uses fixed size batches and parallel processing at the cost of correctness, leading to inconsistenthistories where the latent states used for the third event ignore the updates of the previous two events. event with a coupled dynamic model based on a Hawkes process. Dai et al. (2017) extend this model witha more generic update based on a standard RNN cell and Trivedi et al. (2017) apply a similar model todynamic knowledge graphs. JODIE (Kumar et al., 2019) uses a similar architecture but foregoes predictingthe time of interaction, instead focusing on ranking how plausible interactions between pairs of entities are ata given time. DyRep (Trivedi et al., 2019) and TGN (Rossi et al., 2020) constitute hybrid solutions, incorporatingtransformer elements into a GRNN architecture. DyRep proposes a recurrent model where the messagescoming from the counterparty are itself the result of a graph attention operation over the counterparty graphneighborhood. TGN introduces instead an attention based embedding module on top of the recurrent memorymodel to deal with the staleness problem of the hidden states in the absence of events. Unlike previous approaches which require access to the temporal graph at inference time and perform complexoperations over it, for pure GRNNs the graph itself does not need to be explicitly stored. Instead, it sufficesto store the node embeddings and update them using the recurrent architecture whenever a new edge arrives.This makes these models appealing for inference scenarios requiring low-latency such as fraud detection. Another advantage of GRNNs over transformer or random walk models is that they would seem to promisean infinite causal context towards the past. However, due to the way they are trained, the ability to leverageinformation that is far in the past can be compromised as we discuss in the next subsection.",
  "Training GRNNs: Batch Processing Strategies": "RNNs are typically trained with Back Propagation Through Time (BPTT) or a truncated version of thisalgorithm, T-BPTT, when sequences become too long. In dynamic graphs, however, there is no good optionto define sequences, since nodes interact with each other (). Because future events are influencedby past events, the natural way to define batches is by adopting a sliding window over the globally orderedevents. In other words, no random shuffling of events or sequences is possible, and each epoch will containbatches of sequential events between any pair of nodes in the graph. There are different approaches in theliterature on how to define and process these batches:",
  "y = 12": ": Visual depiction of synthetic task dynamics. A fixed size FIFO buffer with length M (4 in thepicture) is used to store the internal state of each node. When a new edge between two nodes occurs (a), theinput is averaged with the last elements of each counterparty nodes buffer in order to determine the newnumber to be stored in each buffer (b). The sum of these last elements also determines the output for theedge (c). consider an internal state for each node i [1..N] in a graph, consisting of a memory buffer of size M,h(i) RM. Each edge, ek = (sk, dk, xk, yk), is defined by two nodes, sk and dk, an input numeric feature xkand a target yk. The target is computed by adding the last two elements of the buffers of the nodes (prior tothe state update for event k):",
  "The update is symmetrical for h(dk). A schematic representation of the task is depicted in .1": "This task becomes more challenging as M increases since it determines a delay (in number of edges) betweenan input being observed and it affecting an output for the same node. A recurrent model will have to learnthe underlying dynamics of the task from these input/output pairs in order to correctly solve it. It will,therefore, have to memorize older information for each node as M increases. To generate dynamic graphs for this synthetic task we sample edges randomly by picking a random pairof nodes, sk and dk, uniformly and a corresponding random edge feature, xk i.i.d. N(0, 1), drawn from astandard normal distribution. The states for all nodes are initialized to the zero vector. For our experimentswe consider dynamic graphs consisting of 1000 edges and using a total of 100 nodes, which we refer to as oneepoch. We generate a new dynamic graph per epoch.",
  "Memory": "MSE 0 baselineFBPTT : GRU32 GRU64 GRU128TBPTT : GRU32 GRU64 GRU128 : Mean squared error (MSE) obtained for different sized GRU models trained with both F-BPTTand T-BPTT. The depicted error bars correspond to the min and max MSE values over 5 different randomseeds used for parameter initialization and dynamic graph sampling. The solid lines correspond to the meanMSE over the different seeds.",
  "All models are based on Equation 1 using a single GRU cell for both updates (since the dynamics aresymmetric) and without time encoding": "We train a first model with F-BPTT by back-propagating through an entire epoch (i.e. the entire dynamicgraph) in order to compute the gradient of the total loss (sum of losses for all edges). One gradient step istaken per epoch using an AdamW optimizer Loshchilov & Hutter (2019) with a learning rate of 1e-3 andweight decay of 1e-4 for a total of 5000 epochs. For the model using T-BPTT we compute truncated gradients for each edge and accumulate these (i.e., sumthem) over an entire epoch, performing a single gradient step at the end. We use the same optimizer andhyperparameters for the same number of epochs as with F-BPTT. The reasoning behind this setup is to bedirectly comparable with F-BPTT but, in this instance, employing an online setup where a gradient step istaken per edge did not seem to significantly alter the results for T-BPTT. We train models using F-BPTT and T-BPTT and with hidden state sizes of 32, 64 and 128. For all models,we compute the average loss over the last 100 epochs across various values of the memory parameter M. Forcomparison, we also plot the performance of a trivial baseline that predicts yk = 0 for every edge. While for M = 1 the models using T-BPTT are able to approximately solve the task, their performancerapidly degrades as M is increased. In contrast, models trained using F-BPTT are able to fully solve the task(the final loss is orders of magnitude smaller than the target variance) for every value of M tested (.2).",
  "learning_rateLog-Uniformweight_decayLog-Uniformmlp_dropout[0, 0.3]Uniformstate_dropout[0, 0.3]Uniformstate_dropout_type{Regular, Recurrent}Uniform": "We consider a GRNN model based on a GRU cell with a hidden state size of 64. Similar to Rossi et al. (2020)we use the same GRU for the updates to both source and destination nodes (note that despite these nodesbeing heterogeneous, using a GRNN model with non-symmetric dynamics did not lead to better performance).We also disregard any timestamp information on the edges by not having our update function depend on anyt, therefore assuming that there are no autonomous dynamics between events. These choices are made tosimplify the experimental setup since our goal is not to challenge the state of the art results for dynamicgraphs. Our choice of state size is limited by the memory required to run full backpropagation on the trainingset. We train the GRNN model with both truncated and full BPTT, using the same batching strategy of Rossiet al. (2020) (see .2) with a batch size of 200. We note that while this strategy introduces someerror by potentially ignoring some updates in each batch, it is the most efficient and practical to implement,allowing us to run full BPTT with a reasonable hidden state size on these benchmark datasets. We alsoemploy the same negative sampling strategy where for every edge in the graph, a negative edge is obtainedby uniformly sampling a random destination node. The training loss is then the binary cross-entropy forclassifying positive and negative edges. For F-BPTT we backpropagate through all the batches in the trainingdata, computing the gradient of the total training loss for the epoch. This is possible for the selected datasetsdue to their relatively small size. In order to enable a fair comparison, we also accumulate the truncatedgradients for every batch computed with T-BPTT, performing a single parameter update per training epoch.This allows us to have a common training setup with the same number of epochs and the same number ofparameter updates for both methods with the same potential choices of hyperparameters. We use the Adamw optimizer (Loshchilov & Hutter, 2019), and tune the learning rate and weight decayparameters using 25 trials of random search. We also tune the values for the dropout of the multilayerperceptron classifier as well as a state dropout that is applied to the node states modified in each batch. Forthis state dropout we experiment with two approaches: (i) a regular dropout layer applied directly to allthe states updated at each batch or (ii) a layer that keeps each element of the previous state with a givendropout probability instead of updating to the newly computed state (which we call recurrent dropout). Thesearch space used for these tuned parameters is summarized in . We repeat our experiments using 3different seeds determining the hyperparameter sampling, model initialization, dropout and negative edgeselection during training for the Wikipedia and MOOC datasets. A single seed is used for Reddit, which isthe largest dataset, due to it being substantially slower to run. For evaluation we use a similar setup to Kumar et al. (2019) and Huang et al. (2023). We process thevalidation and test sets using the same batching strategy used during training, and then rank for every edgeall the possible destination nodes according to the probabilities predicted by the model. Note that sincethe number of destination nodes for these datasets is at most 1000 we dont use any negative sampling forevaluation. Mean Reciprocal Rank (MRR) and Recall@10 values are computed based on the rank of the truedestination node for each edge. We stop each trial when neither metric has improved for 250 epochs. The results are reported in , where we can observe a large truncation gap on the Reddit and MOOCdatasets representing at minimum a 10% improvement when using F-BPTT. For Wikipedia, while a 3%improvement in the Recall metric was also observed, a non-statistically significant (negative) result is obtainedfor MRR.",
  "Beyond Backpropagation": "While we argued that recurrent neural network architectures are well-suited to handle tasks on dynamicgraph data, we have shown that the truncation present in state-of-the-art approaches can lead to the failure oflearning tasks requiring dependencies more than a hop away. Since the truncation is inevitable in approachesusing backpropagation, solving the issue warrants looking beyond backpropagation-based methods. Viable research directions could include approximations to real-time recurrent learning (RTRL). Morespecifically, Tallec & Ollivier (2017); Mujika et al. (2018); Benzing et al. (2019) describe unbiased stochasticlow-rank approximations to the true Jacobians in recurrent neural networks on sequential data, which makeonline learning feasible. Adapting such methods for the dynamic graph settings would be an interestingavenue to resolve the temporal dependency learning issue. Another approach would be to adopt simplerrecurrent architectures that make RTRL feasible, similar to what is proposed in Zucchet et al. (2023) in thecontext of sequence modeling.",
  "Conclusions": "We surveyed current methods leveraging recurrent architectures for inference tasks on dynamic graphs,discussing the strengths and weaknesses of various training and batching strategies. We identified thatbackpropagation may reach its limits in this dynamic graph setting, due to a severe truncation of the history,confirming that it is holding back GRNN models both in a proposed novel synthetic task and in publiclyavailable real-world datasets. Therefore, we believe that methods beyond backpropagation warrant moreattention in this context.",
  "Sepp Hochreiter and Jrgen Schmidhuber. Long short-term memory. Neural computation, 9(8):17351780,1997": "Shenyang Huang, Farimah Poursafaei, Jacob Danovitch, Matthias Fey, Weihua Hu, Emanuele Rossi, JureLeskovec, Michael Bronstein, Guillaume Rabusseau, and Reihaneh Rabbany. Temporal Graph Benchmarkfor Machine Learning on Temporal Graphs, September 2023. URL [cs]. Ming Jin, Yuan-Fang Li, and Shirui Pan. Neural temporal walks: Motif-aware representation learning oncontinuous-time dynamic graphs. In S. Koyejo, S. Mohamed, A. Agarwal, D. Belgrave, K. Cho, andA. Oh (eds.), Advances in Neural Information Processing Systems, volume 35, pp. 1987419886. Cur-ran Associates, Inc., 2022. URL Srijan Kumar, Xikun Zhang, and Jure Leskovec. Predicting Dynamic Embedding Trajectory in TemporalInteraction Networks. In Proceedings of the 25th ACM SIGKDD International Conference on KnowledgeDiscovery & Data Mining, KDD 19, pp. 12691278, New York, NY, USA, July 2019. Association forComputing Machinery. ISBN 978-1-4503-6201-6. doi: 10.1145/3292500.3330895. URL",
  "Asier Mujika, Florian Meier, and Angelika Steger. Approximating Real-Time Recurrent Learning with RandomKronecker Factors. arXiv:1805.10842 [cs, stat], December 2018. URL 1805.10842": "Emanuele Rossi, Ben Chamberlain, Fabrizio Frasca, Davide Eynard, Federico Monti, and Michael Bronstein.Temporal Graph Networks for Deep Learning on Dynamic Graphs, October 2020. URL arXiv:2006.10637 [cs, stat]. Amauri H. Souza, Diego Mesquita, Samuel Kaski, and Vikas Garg.Provably expressive tempo-ral graph networks.In Sanmi Koyejo, S. Mohamed, A. Agarwal, Danielle Belgrave, K. Cho,and A. Oh (eds.), Advances in Neural Information Processing Systems 35:Annual Conferenceon Neural Information Processing Systems 2022, NeurIPS 2022, New Orleans, LA, USA, Novem-ber 28 - December 9, 2022, 2022.URL",
  "Le Yu, Leilei Sun, Bowen Du, and Weifeng Lv. Towards better dynamic graph learning: New architectureand unified library, 2023. URL": "Hongkuan Zhou, Da Zheng, Xiang Song, George Karypis, and Viktor Prasanna.Disttgl: Distributedmemory-based temporal graph neural network training. In Proceedings of the International Conferencefor High Performance Computing, Networking, Storage and Analysis, SC 23, New York, NY, USA,2023. Association for Computing Machinery. ISBN 9798400701092. doi: 10.1145/3581784.3607056. URL Nicolas Zucchet, Robert Meier, Simon Schug, Asier Mujika, and Joao Sacramento.Online learningof long-range dependencies.In A. Oh, T. Naumann, A. Globerson, K. Saenko, M. Hardt, andS. Levine (eds.), Advances in Neural Information Processing Systems, volume 36, pp. 1047710493. Cur-ran Associates, Inc., 2023. URL",
  "AA General Framework for GRNNs": "One can define a dynamical system over the graph with a hidden state comprising a hidden state for everynode, i [1 . . . N], in the network: h(t) =h(1)(t), . . . , h(N)(t). Between edges (i.e. interaction events), thisstate can be subject to an autonomous evolution which we will assume to be time-invariant and similar andindependent for each node in the network:",
  "h(i)(t) = ft , h(i)().(2)": "We can visualize this evolution as the blue trajectories in . Here we express this time evolution inintegral form, but it could instead be given as an ordinary differential equation such as a neural ordinarydifferential equation (NeuralODE) (Chen et al., 2019). Note that if the network is heterogeneous, (i.e., thereare different types of entities), we could have different evolution laws for each entity type. An edge, ek = (sk, dk, tk, xk), is defined by a source entity, sk H, a destination entity, dk X, a timestamp,tk R and a set of input features, xk X. The states for both nodes associated with the edge are updatedby a function, g : H H X H H. This update allows information encoded in the state of one nodeto be propagated to the counter-party node of the edge and vice-versa. We assume this update to be timeinvariant for simplicity:h(sk)(t+k ), h(dk)(t+k )= gh(sk)(tk ), h(dk)(tk ), xk(3)",
  "We can visualize this update as the red arrows in": "In most settings, the state of a node is only needed for the end task at a time of an interaction involving thatnode. In this case, we can simplify the above model by merging the autonomous evolution f together withthe state update g into a single update function h. There are two possibilities for this, depending on whetherone needs the state immediately before or after a potential interaction for the end-task. As an example,for an edge classification or regression task where the target for the edge may depend directly on the edge",
  "h(3)": ": The dynamical system over the hidden states can in general contain two components: a function fencoding the evolution between interactions (blue), and a function g encoding the updates due to interactionevents (red). In this example interactions happen at times t1, t2 and t3 between nodes 2-3, 1-3 and 2-3respectively. features we could use the node states after the update. We can denote by (i)(t) the last timestamp before twhere an edge involving node i was observed and t(i)k= tk (i)(tk) and write:h(sk)k, h(dk)k= ht(sk)k, t(dk)k, h(sk)k1, h(dk)k1, xk,(5) where we also defined h(sk)k= h(sk) t(sk)+k. Here h is given by applying first f starting from the stateimmediately after the previous update of each node and then g for the edge update. This is depicted on theleft (a) of and can be written as",
  "ht(sk)k, t(dk)k, h(sk)k1, h(dk)k1, xk= gft(sk)k, h(sk)k1, ft(dk)k, h(dk)k1, xk.(6)": "For a link prediction scenario one would instead like to answer the question of whether a link between twonodes is likely at a given time (or simply rank how likely potential links between different nodes are). Forthis task, the node states immediately before a (potential) interaction are necessary since no informationabout the (potential) edge can be considered. We can thus redefine h(sk)k= h(sk) t(sk)kand t(i)kto bethe time between edge k and a potential future interaction in Equation 5. h is then given by first applyingthe node updates, g, and then propagating the states using f. This is depicted on the right (b) of .Note that in a practical application, the update for event k for a node i would only be computed at the timeof a future potential event for node i, thus requiring that extra memory of the last event for each node bemaintained. In the example of , the update for event 1 could be computed at time t3 for node 2 andt2 for node 3. This is the approach taken in Rossi et al. (2020) where the update is potentially recomputedseveral times with different values of t corresponding to the times that node i is evaluated as a possible linkfor another node (i.e., it is selected as a negative example) and when a future edge involving node i occurs.",
  "(3)": ": The two different possibilities for merging the autonomous evolution and event update into a singlefunction. On the left (a) in blue is the update corresponding to the third event between node 1 and 2. Thestate of each node immediately after its last update is first propagated using the autonomous evolution, f,up to t3 and then the update, g, is computed. On the right (b) in blue is the update corresponding to thefirst event between nodes 2 and 3. The state of each node immediately before the event is first updatedusing g and then propagated using f up until the next (potential) event where the state is needed. Note thedifferent definitions of h(i)kand t(i)k . On the left they refer to the state immediately after event k and thetime elapsed since the last update of the node before event k respectively. On the right they refer to thestate immediately before event k and the time it will take until the next (potential) update of each nodeafter event k respectively."
}