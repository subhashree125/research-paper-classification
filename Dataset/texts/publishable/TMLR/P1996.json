{
  "Abstract": "Safe Bayesian Optimization (BO) is increasingly used to optimize an unknown function un-der safety constraints, a central task in robotics, biomedical engineering, and many otherdisciplines. Due to the safety-critical nature of these applications, it is crucial that theo-retical safety guarantees for these algorithms translate into the real world. In this work,we investigate three safety-related issues in SafeOpt-type algorithms, a popular class of safeBO methods. First, these algorithms critically rely on frequentist uncertainty bounds forGaussian Process (GP) regression, but concrete implementations typically utilize heuris-tics that invalidate all safety guarantees. We provide a detailed analysis of this problemand introduce Real--SafeOpt, a variant of the SafeOpt algorithm that leverages recent GPbounds and thus retains all theoretical guarantees. Second, we identify a key technical as-sumption in SafeOpt-like algorithms, the availability of an upper bound on the reproducingkernel Hilbert space (RKHS) norm of the target function, as a central obstacle to real-worldusage. To address this issue, we propose to rely instead on a known Lipschitz and noisebound, and we introduce Lipschitz-only Safe Bayesian Optimization (LoSBO), a SafeOpt-type algorithm using the latter two assumptions. We show empirically that this algorithmis not only safe, but also outperforms the state-of-the-art on several function classes. Third,SafeOpt and derived algorithms rely on a discrete search space, complicating their applica-tion to higher-dimensional problems. To broaden the applicability of these algorithms, weintroduce Lipschitz-only Safe GP-UCB (LoS-GP-UCB), a LoSBO variant that is applicableto moderately high-dimensional problems, while retaining safety. By analyzing practicalsafety issues in an important class of safe BO algorithms, and providing ready-to-use al-gorithms that overcome these issues, this work contributes to bringing safe and reliablemachine learning techniques closer to real world applications.",
  "Introduction": "In science, engineering, and business it is often necessary to optimize an unknown target function. Typically,such functions are expensive to evaluate and only noisy function values are available. If it is possible toactively query the function, i.e., to select the inputs that are to be evaluated, this problem is commonly",
  "Published in Transactions on Machine Learning Research (09/2024)": "The frequentist setup is inherently worst-case, but for numerical experiments it is necessary to restrictourselves to finitely many RKHS functions. Nevertheless, the RKHS functions used should be somewhatrepresentative to give a meaningful indication of the algorithmic performance. Specifically, any bias due tothe function generating method should be minimized. In the following experiments, we sample functions fromthe pre RKHS, i.e., given a kernel k, we randomly choose some M N>0, 1, . . . , M R and x1, . . . , xM Dand then use f = Mi=1 ik(, xi) Hk as a target function, which works for any kernel. In the case of thesquared exponential kernel, we also utilize the ONB described in Steinwart & Christmann (2008, .4),which we have already used for some of the experiments in Sections 5.1 and 6.1. Generating RKHS functionswith more than one method ensures more variety of the considered RKHS functions. Moreover, with bothapproaches, the exact RKHS norm is available (and can be set by normalization), and the generated functionscan be evaluated at arbitrary inputs. Unless noted otherwise, we generate RKHS functions with an RKHSnorm of 10, i.e., we consider target functions f Hk with fk = 10. For a more thorough discussion ofgenerating RKHS functions and subtle biases due to the chosen method, we refer to (Fiedler et al., 2021a). LoSBO and Real--SafeOpt work on arbitrary metric spaces, as long as a kernel can be defined on that space.Following the previous safe BO literature, we restrict ourselves to compact subsets of Rd, and in this sectionfor simplicity we further restrict ourselves to d = 1. To run LoSBO and Real--SafeOpt, we need a bound onthe Lipschitz constant of the target function, as well as an initial safe set. For the former, we restrict ourselvesto kernels inducing continuously differentiable RKHS functions, since the latter are Lipschitz continuous dueto the compact domain. To determine a bound on the Lipschitz constant, we evaluate the target function ona fine discretization of the input domain, numerically compute an approximation of the Lipschitz constant,and multiply the result by 1.1 to counterbalance the discretization error. Since the target functions arerandomly generated, we compute an appropriate safety threshold for each function so that some portions ofthe input space are safe, and some are unsafe. This avoids trivial situations for safe BO. More precisely, fora given target function f, we compute its empirical mean (f) and empirical standard deviation SD(f) ona fine grid, and then set h = (f) 0.2SD(f). Next, for each target function f and safety threshold h, weneed to generate an initial safe set. Similar to the choice of the safety threshold, trivial situations shouldbe avoided, particularly cases where no safe exploration is possible. To achieve this goal, we first determinesome x0 argmaxxDf(x), then consider the set D Ix0, where Ix0 is the largest interval such that x0 Ix0and f|Ix0 h + E. Finally, one input is randomly selected from this set, and the singleton set containingthis latter input is then selected as the initial safe set. Using a singleton initial safe set is common in theliterature on SafeOpt-type algorithms, see (Berkenkamp et al., 2016). The typical application scenario for SafeOpt-type algorithms is the optimization of some performance mea-sure by interacting with a physical system. In particular, each function query is relatively expensive, hence inthese scenarios only a few function values are sampled. Motivated by this, in all of the following experiments,for each target function, LoSBO and Real--SafeOpt are run for 20 iterations, starting from the same safeset. For each target function, this is repeated 10000 times to allow a frequentist evaluation of the behavior.Finally, each type of experiment is run with 100 different randomly generated target functions. To make runswith different target functions comparable, we evaluate the performance in a given run of a target functionf by",
  "Gaussian processes and reproducing kernel Hilbert spaces": "A GP is a collection of R-valued random variables, here indexed by the set D, such that every finite collectionof those random variables has a multivariate normal distribution. A GP g is uniquely defined by its meanfunction m(x) = E[g(x)] and covariance function k(x, x) = E[(g(x) m(x))((g(x) m(x))], and we denotesuch a GP by g GPD(m, k). In GP regression, we start with a prior GP. Assuming independent andidentically distributed (i.i.d.) additive normal noise, t N(0, 2), this prior GP can be updated withdata (x1, y1), . . . , (xt, yt), leading to a posterior GP. Without loss of generality we assume that the prior GPhas zero mean. Then the posterior mean, posterior covariance and posterior variance are given by t(x) =kt(x)T (Kt +2It)1yt, kt(x, x) = k(x, x)kt(x)T (Kt +2It)1kt(x), and 2t (x) = kt(x, x), respectively,where yt = [y1, ..., yt]T is the vector of observed, noisy function values of f, the kernel matrix Kt Rtt hasentries [k(x, x)]x,xDt, the vector kt(x) = [k(x1, x) k(xt, x)]T contains the covariances between x and theobserved data points, and It is the tt identity matrix. In practice, the prior mean, prior covariance function,and noise level, are (partially) chosen based on prior knowledge. If no specific prior knowledge regardingthe mean is available, the zero function is usually chosen. Furthermore, in practice these three componentsare only partially specified, usually up to some parameters, which are then called hyperparameters in thecontext. In BO, the latter are often determined during the optimization via hyperparameter optimization(Garnett, 2023). If k is the covariance function of a GP, then it is symmetric and positive semidefinite.3 Conversely, if kis the reproducing kernel of a RKHS, then k is symmetric and positive semidefinite, and there exists aGP having k as its covariance function, and the GP can be chosen with a zero mean function (Berlinet& Thomas-Agnan, 2004). Finally, for every symmetric and positive semidefinite function k (and hence forevery covariance function of a GP) there exists a unique associated Hilbert space of functions, called areproducing kernel Hilbert space (RKHS) and denoted by (Hk, , k), with (i) k(, x) Hk for all x D,and (ii) f(x) = f, k(, x)k for all f Hk and x D. For the readers convenience, Section A.1 contains abrief introduction and discussion of these function spaces. For more details on GPs, GP regression, and related method, we refer to (Rasmussen & Williams, 2006)and (Garnett, 2023), and for more background on RKHSs, we refer to (Steinwart & Christmann, 2008,Chapter 4).",
  "Frequentist uncertainty bounds": "An important ingredient in SafeOpt-type algorithms are upper and lower bounds on the unknown targetfunction, and these bounds have to hold uniformly in both time and input space. If we adopt a stochasticsetup, then this can be formalized by finding upper and lower bounds such that for a given user-specifiedconfidence (0, 1), we have P [t(x) f(x) ut(x), x D, t 0] 1 , where the probability is withrespect to the data-generating process, while f is assumed fixed and nonrandom. In GP regression, theposterior mean t can be interpreted as a nominal estimate of f, and the posterior variance 2t as a measureof uncertainty of this estimate. However, using the posterior variance to build upper and lower bounds in theSafeOpt setting is not straightforward. Firstly, the posterior variance is a pointwise measure of uncertaintyabout the ground truth, but the upper and lower bounds have to hold uniformly over the input set, andalso uniformly in time. Secondly, GP regression is by its nature a Bayesian method. However, the SafeOptsetting is a typical frequentist setup we have a fixed, yet unknown ground truth, about which we receivenoisy information. In particular, any stochasticity arises only through the data-generating process (e.g., viarandom noise on the function values), and not through epistemic uncertainty, as is the case in the Bayesiansetup. This difficulty is well-known, see (Fiedler et al., 2021a), and is particularly relevant in the contextof robust control and related areas (Fiedler et al., 2021b). We thus need bounds (t)t1, such that for auser-specified (0, 1) we have",
  "posterior meanuncertainty settrue functiondata points": ": Illustration of the required GP error bounds. Consider a fixed ground truth (solid black line),of which only finitely many samples are known (gray dots). Applying GP regression leads to a posteriorGP fully described by the posterior mean (solid blue line) and the posterior variance, from which a high-probability uncertainty set can be derived (shaded blue). Left: The ground truth is completely contained inthe uncertainty set. Right: The ground truth violates the uncertainty bound around x = 1.",
  "t(x) = tt(x),(2)": "where t R0 is some scaling factor. Let k be the covariance function used in GP regression, and Hk theunique RKHS with k as its reproducing kernel. Assume that the ground truth is contained in this RKHS,i.e., f Hk. Let F = (Ft)t0 be a filtration defined on the underlying probability space, and assume thatthe sequence of inputs (xt)t0 chosen by the algorithm is adapted to F.4 The first bound of the form (2)was introduced in the seminal work (Srinivas et al., 2010), cf. their Theorem 6, which holds in the caseof bounded noise. This is also the bound that was used in the original SafeOpt paper (Sui et al., 2015).At the moment, the most commonly used uncertainty bound in the analysis of SafeOpt-type algorithmsis (Chowdhury & Gopalan, 2017, Theorem 2). Assume that (t)t is a martingale difference sequence thatis conditionally R-subgaussian w.r.t. F for some R R0, which holds for example for i.i.d. bounded ornormal noise. Additionally, assume that > 1, or 1 and the covariance function k is positive definite,where is the nominal noise variance used in GP regression. Under these conditions, the uncertainty bound(1) holds witht = fk + R",
  "(t1 + 1 + log(1/))(3)": "in (2), where t is the maximum information gain after t rounds, cf. (Srinivas et al., 2010) for a thoroughdiscussion of this quantity. In contrast to (Srinivas et al., 2010, Theorem 6), this bound allows subgaus-sian noise (including bounded noise and normal noise) and involves only fairly small numerical constants.However, it still requires the maximum information gain or an upper bound thereof, which can be difficultto work with in practice, and it introduces some conservatism. Motivated by these shortcomings, Fiedleret al. (2021a) proposed a data-dependent scaling factor in (2), based on (Chowdhury & Gopalan, 2017,Theorem 2). Assume the same setting as this latter result, and also assume that the covariance function kis positive definite, then we can set",
  "lndet(/Kt + It) 2 ln(),(4)": "where we defined = max{1, }, and is again the nominal noise variance used in GP regression, cor-responding to the regularization parameter in kernel ridge regression. This bound no longer involves themaximum information gain, and numerical experiments demonstrate that the resulting uncertainty boundsare rarely significantly larger than common heuristics, see (Fiedler et al., 2021a). In fact, the bounds are",
  "Problem setting and objectives": "We now formalize our problem setting following the seminal paper (Sui et al., 2015), describe SafeOpt-typealgorithms in detail, and specify our objectives for the remainder of this work. Consider a nonempty set D,the input set, and a fixed, but unknown function f : D R, the target function or ground truth. We areinterested in an algorithm that finds the maximum of f by iteratively querying the function. At time stept N0, such an algorithm chooses an input xt D and receives a noisy function evaluation yt = f(xt) + t,where t is additive measurement noise. As a safety constraint, all chosen inputs must have a functionvalue above a given safety threshold h R, i.e., f(xt) h for all t. Furthermore, the algorithm should besample-efficient, i.e., use as few function queries as possible to find an input with a high function value. Tomake progress on this problem, it is clear that some restriction on the function f must be posed. Central toour developments is the next assumption.",
  "Assumption 1. D is equipped with a metric d : D D R0. Additionally, f is L-Lipschitz continuous,where L R0 is a known Lipschitz constant": "The second assumption means that for all x, x D, we have |f(x) f(x)| L d(x, x). From now on, wework under Assumption 1. Furthermore, we assume that we have access to a non-empty set of known safeinputs S0 D, i.e., for all x S0 we have f(x) h. The SafeOpt algorithm and its derivatives use aniteratively updated model Mt that provides estimated upper and lower bounds ut and t on f, i.e., with acertain confidence it holds that t(x) f(x) ut(x) for all x D and all t 1. These bounds are also usedto provide a measure of uncertainty defined as wt(x) = ut(x) t(x). In each step t 1, the previous modelMt1 together with the Lipschitz assumption is used to determine a new set St D of safe inputs, startingfrom the initial safe set S0. Subsequently, a set Mt St of potential maximizers of the target function, and aset Gt St of potential expanders is computed. The latter contains inputs that are likely to lead to new safeinputs upon query. Finally, the target function is queried at the input xt = argmaxxGtMtwt(x), a noisyfunction value yt is received, and the model Mt1 is updated with the data point (xt, yt). Different variantsof SafeOpt result from different choices of models and computations of St, Mt and Gt. To the best of ourknowledge, in all SafeOpt-type algorithms, the unknown ground truth f is modeled as a GP. To computeappropriate upper and lower bounds, it is assumed that an appropriate scaling factor t is available, cf. (2).For each time step t, define Ct(x) = Ct1 Qt(x), where Qt(x) = [t1(x) t t1(x)], and, starting withQ0(x) = R for all x D, C0(x) = [h, ) for all x S0 and C0(x) = R for x D \\ S0. The correspondingestimated upper and lower bounds are given by ut(x) = max Ct(x) and t(x) = min Ct(x), respectively. Inthe original SafeOpt algorithm from (Sui et al., 2015), for each step t 1, the new safe sets are calculatedbySt =",
  "Iteration 30true functionuncertainty boundsposterior meandata pointsoptimuminitial safe setsafe setmaximizer setexpander set": ": Illustration of SafeOpt. The safe set (gray bar), expanders (blue bar), and maximizers (greenbar), derived from the current GP model (with solid blue line the posterior mean, shaded blue areas theuncertainty sets), are used to find the safely reachable optimum (red box). In each iteration, the next inputis chosen from the union of the current expanders and maximizers (a subset of the safe set) by maximizingthe acquisition function.",
  "Gt = {xS St | x D \\ St : ut(xS) Ld(xS, x) h}.(8)": "The resulting algorithm is illustrated in . A formal description of the algorithm using pseudocodeis provided by Algorithm 1. In some popular variants of the SafeOpt algorithm, no Lipschitz bound is usedin the computation of the safe sets (Berkenkamp et al., 2016). However, since knowledge of such a Lipschitzbound is additional knowledge that should be used by the algorithm, and we strongly rely on this assumptionfrom onwards, we do not consider these algorithmic variants in the present work. Our primary objective is to investigate and improve practically relevant safety aspects of SafeOpt-type algo-rithms. We will consider three specific objectives, which will be explored in Sections 5, 6 and 7, respectively.",
  "Safety in Bayesian optimization": "We first consider safety in the context of Bayesian optimization (BO) (Shahriari et al., 2015; Garnett, 2023).The type of safety constraint considered in this work was first introduced in the seminal paper (Sui et al.,2015), which also proposed and analyzed the original SafeOpt algorithm. Several variations to the originalalgorithm have been proposed, with a SafeOpt-variant that does not use a Lipschitz constant (Berkenkampet al., 2016) proving particularly popular in the robotics community. While the original SafeOpt algorithmfrom Sui et al. (2015) interleaves safe exploration and function optimization over certified safe sets, a two-stage variant was introduced and analyzed in (Sui et al., 2018). Since SafeOpt relies on a discrete inputspace, and hence requires discretization in the case of a continuous optimization problem, applying thisalgorithm to continuous problems in even moderate dimensions can be very challenging, cf. also . This motivated the introduction of a variant based on swarm-optimization (Duivenvoorden et al., 2017),albeit with heuristic safety guarantees, as well as a variant tailored to dynamical problems in high dimensions(Sukhija et al., 2023). A method based on random projections was also proposed and analyzed in (Kirschneret al., 2019a), and applied to tuning of a particle accelerator (Kirschner et al., 2019b). In terms of problemformulations, instead of just one safety constraint for the input function, multiple safety constraints can alsobe enforced, each encoded by an unknown constraint function (Sui et al., 2018; Berkenkamp et al., 2023).In many applications of SafeOpt-type algorithms, properties of a dynamical system need to be optimizedunder safety constraints, for example, in controller tuning with BO. The dynamic aspect can be includedin the optimization algorithm and its safety mechanisms, for example, in order to use a backup controller(Baumann et al., 2021). Furthermore, while formally SafeOpt-type algorithms are BO algorithms havinginput constraints, this is different from constrained BO as considered for example in (Hernndez-Lobatoet al., 2016). In the latter type of BO, the focus is on finding good inputs (i.e., corresponding to a highobjective function value) that fulfill the (usually unknown) constraints, and violation of the constraintsduring the optimization process is not considered problematic (though of course it can be advantageousto avoid this). By contrast, safe BO aims to avoid constraint violations during the optimization processsince these are considered problematic or even harmful. For an in-depth discussion of this difference, andfurther connections between the two problem settings, we refer to the excellent survey (Kim et al., 2020).SafeOpt-type algorithms are motivated by problems where safety violations are considered to be very costly,so any safety violations should be avoided with very high probability. This contrasts with a whole spectrumof related, but different safe BO (and reinforcement learning) settings. For example, in robot learning a",
  "Lipschitz-based methods": "In order to address safety-related issues uncovered and discussed in Sections 5.1 and 6.1, we will introducealgorithms based on a Lipschitz assumption. While regularity properties like Lipschitz (and the more generalHlder) continuity play an important role in the theory of statistical learning, especially in nonparametricstatistical estimation (Tsybakov, 2009), learning algorithms based on Lipschitz assumptions have receivedrelatively little attention in the machine learning community.Relevant exceptions to this are Lipschitzbandits (Kleinberg et al., 2019) and the original SafeOpt algorithm from Sui et al. (2015). The situation isconsiderably different in the field of global optimization and the systems and control community, respectively.In the former, Lipschitz continuity with a specific Lipschitz constant is a standard assumption, used in avariety of algorithms for (certified) global optimization, cf. (Hansen et al., 1992; Pintr, 1995), though usuallya noise-free setting is assumed in this literature. Global optimization of Lipschitz functions has recently alsoreceived attention from the machine learning community (Malherbe & Vayatis, 2017). Similarly, a specifiedLipschitz constant is also used in the context of Lipschitz interpolation (Beliakov, 2006). Furthermore, closelyrelated to our approach taken in , a deterministic variant of SafeOpt has been considered in Sergeyevet al. (2020). However, the latter reference only works with functions on a compact interval, and does notuse any BO techniques. In the systems and control community, Lipschitz assumptions have long been used,especially in the context of systems identification, where they were explicitly introduced and popularized byMilanese & Novara (2004), though similar methods had been used before, e.g., (Cooper, 1995). A knownbound on the Lipschitz constant and on the size of additive noise is commonly used to derive uncertaintybounds in the context of regression. This approach has been further popularized and extended to the case ofHlder continuous functions by Calliess (2014), widely known as kinky inference in the systems and controlcommunity. A central assumption in this context is knowledge of a concrete, numerical upper bound on theLipschitz constant of the target function. This assumption has a clear geometric and practical interpretation,namely a bounded rate of change of the target quantity. As such, it is related to the well-established fieldof sensitivity analysis (Da Veiga et al., 2021), for example. Approaches to estimate the Lipschitz constantof an unknown function have been proposed both in the context of global optimization (Strongin, 1973)and in Lipschitz-based regression methods, particularly in the context of systems identification (Milanese& Novara, 2004; Novara et al., 2013; Calliess et al., 2020), see (Huang et al., 2023) for an overview andvery recent sample-complexity results. We would like to stress that these approaches are not suitable forthe present setting of hard safety constraints, since the estimation of a Lipschitz constant bound requiresqueries to the target function, which in turn already need to be safe, see also the discussion in .1.The developments in Sections 6 and 7 combine kernel-based methods (here GP regression) with a Lipschitzassumption to overcome the requirement of a known bound on the RKHS norm of the target function, see.1 for details. The problematic nature of an RKHS norm bound in the context of learning-basedcontrol has been recognized for some time (Lederer et al., 2019; Fiedler et al., 2022). In (Lederer et al.,2019), using probabilistic Lipschitz bounds together with a space discretization was suggested to derive GPuncertainty bounds. However, this approach relies on a probabilistic setting, and is therefore not suitablein the context of SafeOpt-type algorithms. The work (Fiedler et al., 2022) proposes the usage of geometricconstraints as prior knowledge in the context of uncertainty sets for kernel-based regression, with Lipschitzconstant bounds as a special case. The resulting kernel machines, which provide nominal predictions andsmoothed uncertainty bounds adhering to the geometric constraints, are not necessary in our setting, thoughusing more general geometric constraints than Lipschitz constant bounds might be a promising avenue inthe context of SafeOpt-type algorithms. Finally, combining kernel methods with Lipschitz assumptions isa natural approach as there is a close connection between regularity properties of a kernel and Lipschitz",
  "Frequentist uncertainty bounds and practical safety issues in SafeOpt": "We now investigate practical safety implications of commonly used heuristics in the frequentist uncertaintybounds in SafeOpt-type algorithms, addressing objective (O1). In .1, we discuss why these heuristicsare problematic and demonstrate safety issues using numerical experiments. To overcome these issues, in.2, we propose using state-of-the-art frequentist uncertainty bounds in the actual algorithm.",
  "Practical safety issues in SafeOpt": "Safety in SafeOpt-type algorithms is ensured by restricting query inputs to safe sets, which are computedusing frequentist uncertainty bounds, typically in the form (2) using (3). However, these bounds are oftentoo conservative for algorithmic use, which has led to implementations adopting heuristic choices for t,for example, t 2 in (Berkenkamp et al., 2016; Turchetta et al., 2016), t 3 in (Helwa et al., 2019;Baumann et al., 2021), or t 4 in (Sukhija et al., 2023). Using such heuristics instead of evaluating tinvalidates all safety guarantees. In practice, choosing some t can be a useful heuristic, as demonstratedby the reported success of SafeOpt-type algorithms (Berkenkamp et al., 2016; Baumann et al., 2021; Sukhijaet al., 2023). However, it should be stressed that in the setting of SafeOpt as outlined in , thelearning algorithm has to fulfill a hard safety constraint namely, that no unsafe inputs are queried bythe algorithm (potentially only with high probability). In particular, no burn-in or tuning phase for t isallowed. Such heuristics not only invalidate the theoretical safety guarantees, but can also actually lead tosafety violations. First, we demonstrate empirically that a simple heuristic like setting t 2 can lead to a significant propor-tion of bound violations. To do so, we follow the general approach adopted in (Fiedler et al., 2021a). Werandomly generate 100 RKHS functions on with RKHS norm 10 using the squared exponential (SE)kernel, and for each of the functions, we generate 10000 data sets, run GP regression on it, and finally checkwhether the uncertainty set (2) with t 2 fully contains the respective function. 27273882 (average SD) of these runs (all 10000 repetitions for all 100 functions) led to a bound violation, a sizeable proportion.Second, we show that these bound violations can indeed lead to safety violations when running SafeOpt. Wegenerate an RKHS function f and run SafeOpt with t 2, but all other algorithmic parameters set cor-rectly (or even conservatively) for 10000 independent runs. This leads to 2862 (out of 10000) runs with safetyviolations (see ), which is unacceptable for most application scenarios of SafeOpt-type algorithms. These experiments illustrate that using heuristics in SafeOpt can be highly problematic. Even in the relativebenign setting used above, both uncertainty bound and safety violations occur. Moreover, in applicationscenarios for SafeOpt-type algorithms, tuning the heuristic scaling factor is not possible, as it is the primarymechanism for safety. Dispensing with the need for such heuristics, and retaining safety guarantees both intheory and practice, is therefore the primary motivation for this work.",
  "Real--SafeOpt": "As a first step, we propose using modern uncertainty bounds in SafeOpt that can be computed numerically,avoiding the replacement with unreliable heuristics. For this purpose, we investigate the original SafeOptalgorithm, as described by Algorithm 1, with t from (5). To clearly distinguish this variant of SafeOpt fromprevious work, we call it Real--SafeOpt, emphasizing that we use a theoretically sound choice of t. Thebound (5) requires the determinant to be computed, which can be computationally expensive, but typicalapplications of SafeOpt and related algorithms allow few evaluations, so this does not pose a problem.Furthermore, the additive noise needs to be a conditionally R-subgaussian (martingale-difference) sequencewith a (known upper bound on) R. This assumption is standard, has a clear interpretation, and is in manycases harmless. Finally, for a frequentist uncertainty bound, we also need the next assumption.",
  "Lipschitz-only safe Bayesian optimization (LoSBO)": "In this section, we address objective (O2), in particular, we investigate the central Assumption 2 of a knownupper bound on the RKHS norm of the target function, finding that this is a problematic assumption inpractice. To overcome this issue, we propose to rely instead on a known Lipschitz and noise bound, andintroduce Lipschitz-only Safe Bayesian Optimization (LoSBO) as an appropriate algorithm, on which weperform extensive numerical experiments.",
  "Practical problems with the RKHS norm bound": "A central ingredient in the Real--SafeOpt algorithm is an upper bound on the RKHS norm of the targetfunction. In particular, the safety and exploration guarantees inherited from (Sui et al., 2015) hinge on theknowledge of a concrete numerical upper bound on the RKHS norm. Unfortunately, while the RKHS norm isvery well understood from a theoretical point of view, in practice it is currently not possible to derive concretenumerical upper bounds on the RKHS norm from realistic assumptions in non-trivial cases, to the best ofour knowledge, cf. the additional discussion in Section A.2. This issue is known in e.g. the learning-basedcontrol community (Fiedler et al., 2022), but has not yet been addressed in the context of safe BO. However,it has immediate consequences for SafeOpt-type algorithms. These algorithms are intended for hard safetysettings, i.e., scenarios where any safety violation is very costly and must be avoided. In these scenariosit is not possible to have a tuning phase before the actual optimization run where algorithmic parametersare set, since the safety requirements hold from the start. For SafeOpt-type algorithms this means that allalgorithmic parameters have to be set beforehand, and these parameters need to ensure the safety and leadto satisfying exploration behavior. However, this entails an upper bound on the RKHS norm of the targetfunction, which currently appears to be impossible to derive from reasonable prior knowledge in practicallyrelevant scenarios. Furthermore, using an invalid RKHS upper norm bound can indeed easily lead to safety violations. In orderto illustrate this, we run Real--SafeOpt on the same function f from .1, and set = 0.01, butthis time, we use a misspecified RKHS norm of 2.5 in (5). Running this experiment now results in 1338failure runs out of 10000, cf. , which is much more than what would be expected from a safetyprobability of 1 = 0.99. For a summary of this experiment, see again . Finally, simply using avery conservative upper bound on the RKHS norm is not a viable strategy to overcome this problem. Asevere overestimation of the RKHS norm leads to very large and overly conservative uncertainty bounds,which in turn leads to performance issues. In particular, since the uncertainty bounds are used to determinethe safety sets in SafeOpt-type algorithms, a supposed RKHS upper norm bound that is too conservativecan result in the algorithm getting stuck, i.e., no more exploration is possible. It should also be noted",
  "Describing LoSBO and its safety guarantees": "Motivated by the popularity of SafeOpt, which combines GPs with a Lipschitz assumption, and the extensiveexperience of the systems and control community with Lipschitz bounds and bounded noise (cf. ),we propose to use an upper bound on the Lipschitz constant of the target function and a known noise boundas the ingredients for safety in BO. The key idea is to ensure that the safety mechanism works reliablyindependent of the (statistical) exploration mechanism. In a generic SafeOpt algorithm, safety is guaranteedby ensuring that the safe sets St contain only safe inputs (potentially only up to high probability), i.e.,requiring that f(x) h for all x St. Once this property is fulfilled, the rest of the algorithm can nolonger violate the safety constraints anymore. Based on the earlier discussion, the construction of the safeset should only rely on the Lipschitz and noise bound. As is well-known, these two assumption allow theconstruction of lower bounds on the function (Milanese & Novara, 2004), and the corresponding safe setsshould therefore be defined for all t 1 as",
  "St = St1 {x D | yt1 E Ld(xt1, x) h},(9)": "where L R0 is a bound on the Lipschitz constant of the unknown target function, E R0 a bound onthe magnitude of the noise, and S0 is the initial safe set. We propose using this variant of the safe set, andleaving the rest of the generic SafeOpt algorithm unchanged, which leads to an algorithm we call Lipschitz-only Safe Bayesian Optimization (LoSBO). Our proposed modification applies to any algorithm instantiatingthe generic SafeOpt strategy outlined in . For concreteness, we focus in the following on the originalSafeOpt algorithm from (Sui et al., 2015). The algorithm fulfills the following safety guarantee. Proposition 1. Let f : D R be an L-Lipschitz function. Assume that |t| E for all t 1 and let = S0 D such that f(x) h for all x S0. For any choice of the scaling factors t > 0, running theLoSBO algorithm leads to a sequence of only safe inputs, i.e., we have f(xt) h for all t 1. Proof. It is enough to show that t 0 and x St, we have f(x) h. Induction on t: For t = 0, thisfollows by assumption. For t 1, let x St = St1 {x D | yt1 E Ld(xt1, x) h}. If x St1,then f(x) h follows from the induction hypothesis. Otherwise we have",
  "where we used the L-Lipschitz continuity of f and the noise bound |t| E in the first inequality, and thedefinition of St in the second inequality": "The argument in the proof above is well-known in e.g. the systems identification literature, and the resultingbounds even fulfill certain optimality properties (Milanese & Novara, 2004). We would like to stress that thesafety guarantee of LoSBO, as formalized in Proposition 1, is deterministic, i.e., it always holds and not onlywith high probability. This type of safety is often preferred in the context of control and robotics (Hewinget al., 2020; Brunke et al., 2022).",
  "Discussion": "While LoSBO arises from a rather minor modification of the generic SafeOpt algorithm class (by changingthe computation of the safe sets St), on a conceptual level significant differences arise. Inspectingthe proof of Proposition 1 shows that the safety guarantee of LoSBO is independent of the underlying modelsequence (Mt)t. As an important consequence, the choice of the uncertainty sets used in the optimizationof the acquisition function cannot jeopardize safety. One consequence is that the assumption that the targetfunction f is contained in the RKHS of the covariance function used in GP regression is not necessaryanymore. In particular, in order to ensure safety, we need only Assumption 1 together with a noise bound,and not Assumption 2 anymore. Similarly, hyperparameter tuning is not an issue for safety, cf. also toour discussion in .2. Of course, an appropriate function model is important for good explorationperformance, but this issue is now independent of the safety aspect.As another, even more importantconsequence, in the context of the concrete LoSBO variant described in Algorithm 3 (Appendix), the scalingparameter t is now a proper tuning parameter. Modifying them, even online, in order to improve explorationno longer interferes with the safety requirements. This differs from previous variants (and practical usage) ofSafeOpt, where the scaling factors t cannot be freely tuned since they are central for the safety mechanismof these algorithms. This aspect is illustrated in . In the situation depicted there, the uncertaintybounds do not hold uniformly, i.e., the target function is not completely covered by them, and derivingsafety sets from these uncertainty bounds, regardless of whether to include the additional knowledge of theLipschitz bound (Sui et al., 2015) or not (Berkenkamp et al., 2016), results in potential safety violations.However, since in LoSBO these bounds are ignored for the safe sets, this problem does not occur.",
  "true functionposterior meanuncertainty setLipschitz conedata pointsunsafe areawrong safe setsafe setsafe set LoSBO": ": Illustration of LosBO being safe, while a safe set based on invalid uncertainty bounds leads topotential safety violations. The safe set of LoSBO (gray set) is determined by the constant E (black arrow)and the Lipschitz cone (orange). The GP mean and the confidence bounds are illustrated in blue. The pointsin the safe set given by the lower confidence bound are green if they are safe and red if they are unsafe. Using a Lipschitz bound instead of an RKHS norm bound comes with several advantages. First, a(quantitative) Lipschitz bound has a clear interpretation - it is an upper bound on the slope of the targetfunction. Second, the Lipschitz assumption can be related to established prior knowledge: A known upperbound on the Lipschitz constant corresponds to an a priori bound on the rate of change of a function, i.e.,it is related to the sensitivity of the underlying problem. As discussed in-depth in .1, to the bestof our knowledge this is not possible for the RKHS norm in non-trivial cases. Third, as already mentionedabove, the Lipschitz assumption is independent of the internal model used for exploration, and hence muchless prone to model misspecifications like wrong hyperparameters of kernels. Finally, the exact Lipschitzconstant is rarely known in practice, and hence an upper bound has to be used. It is clear that a veryconservative upper bound will inhibit exploration, just as a conservative upper bound on the RKHS norm,but this issue appears to be unavoidable with any quantitative a priori assumption.",
  ": Safety-performance tradeoff in SafeOpt. We evaluated 100 functions sampled from an SE-kernelwith B = 10. On each function we ran each algorithm 10000 times, starting from two initial safe points": "The original SafeOpt algorithm comes with conditional6 exploration guarantees. Since our modificationleading to LoSBO essentially separates the safety and exploration mechanisms, the exploration guaranteesfrom SafeOpt are rendered inapplicable in the present context. An inspection of the proof of (Sui et al., 2015,Theorem 1) shows that it cannot easily be modified to apply to LoSBO again, as the argument used thererelies on the GP model interacting with the safety mechanism7. Furthermore, we suspect that pathologicalsituations exist where LoSBO fails to properly explore. However, we have not observed such a situationin our extensive experiments. While providing (again conditional) exploration guarantees for LoSBO is aninteresting focus for future work, we argue that the present lack of such theoretical guarantees does not di-minish the relevance and usefulness of this algorithm. First, LoSBO shows excellent exploration performance,as demonstrated in the experiments described in the next section. Second, since the scaling parameters t(which have an important influence on the exploration performance) are proper tuning parameters in LoSBO,unsatisfying performance of the algorithm can be overcome by using this tuning knob. We would like tostress again that in the previous variants of SafeOpt, this option is not available as the scaling parametersneed to lead to valid uncertainty sets.",
  "Experimental evaluation": "Analogously to the case of Real--SafeOpt and LoSBO, a frequentist setup will be used, i.e., the algorithmwill be run on a fixed target function for many independent noise realizations. In the experiments two aspectswill be investigated. First, LoS-GP-UCB will be compared with Real--SafeOpt and LoSBO. Second, weapply LoS-GP-UCB to several benchmark functions with moderate input dimensions. We start with the comparison to Real--SafeOpt and LoSBO. Since these two algorithms rely on a discreteinput space, this comparison necessarily has to be performed on functions with a low dimensional input.We choose essentially the same experimental settings as in .2 and consider only the well-specifiedcase. As for LoSBO, we use t 2 in LoS-GP-UCB, and we consider one-dimensional RKHS functions. Thealgorithms are evaluated on 100 target functions sampled from the pre RKHS corresponding to a Matern-3/2kernel, and for each function, we run the algorithms 1000 times9. The results of this experiment are shown in (a), where we again use the evaluation metric (16). Thick solid lines are the means over all functionsand repetitions and shaded areas correspond to the 10 % and 90 % quantiles (again over all functions andrealizations). To avoid clutter, the means for each individual function are plotted only for LoS-GP-UCB(thin lines). It is clear from that the performance of Los-GP-UCB is only slightly inferior to theoriginal LosBO algorithm, yet still superior to Real--SafeOpt. This outcome indicates that LoS-GP-UCB isnot severely affected by the under-exploration problem described for a safe variant of GP-UCB in (Sui et al.,2015). We suspect that, similar to LoSBO, this is due to the overoptimism resulting from setting t 2,corresponding to moderately aggressive exploration.",
  "lGP = 0.2lc": ": Comparison of LosBO and Real--SafeOpt in a well-specified setting. Thick solid lines are themeans over all functions and repetitions, thin solid lines are the means over all repetitions for each individualfunction, shaded area corresponds to the 10 % and 90 % quantiles over all runs. 10000 repetitions for each function), and the shaded area shows the 10 % and 90 % quantiles, again over allfunctions. , left, displays the results for functions from the Squared Exponential RKHS, sampledusing the ONB approach. Interestingly, LoSBO exhibits superior performance compared to Real--SafeOpt,despite providing the latter algorithm with the correct ingredients (Lipschitz bound, kernel, RKHS normbound, noise variance). Sampling functions using the pre RKHS approach shows only minor differences, cf.Section C.3 in the appendix. , second plot, shows the results for RKHS functions correspondingto a Matern-3/2 kernel and sampled with the pre RKHS approach. Qualitatively, we see the same picture,though the performance of both LoSBO and Real--SafeOpt appear to be slightly weaker compared to theprevious setting. Intuitively, this is to be expected as Matern RKHS functions are generically less smooththan Squared Exponential RKHS functions, and both LoSBO and Real--SafeOpt rely on a Lipschitz bound,which is in turn related to regularity of functions. Misspecified settingWe turn to misspecified settings, where the algorithmic parameters do not matchthe true setting of the target function. This is particularly interesting in the present situation, since theunderlying GP model does not impact the safety of LoSBO, and therefore becomes amenable to tuning. Westart with the length scale used in the kernel, which is arguably the most important type of hyperparameterin practice. In , third plot, we show the results for overestimating the length scale in GP regression,using Matern kernels. More precisely, a Matern kernel is used both as the kernel for generating the targetfunctions and as a covariance function in GP regression, but the length scale of the covariance function in GPregression is 4 times the ength scale used in the kernel to generate the target function. The qualitative pictureremains the same, though it appears that the performance of Real--SafeOpt suffers from the misspecificationmore than LoSBO. More importantly, in this setting safety violations occur in 12.57 % of all runs. Moreover,for the worst-behaving target function 943 out of 10000 runs lead to safety violations, which is unacceptablein a real-world use case. , rightmost plot, shows the complementary situation of underestimating thelength scale in GP regression, again using Matern kernels. The length scale of the covariance function used inGP regression is 0.2 times the length scale of the kernel that is used to generate the target function. Again,the qualitative picture remains the same, but the performance degradation is worse for both algorithms inthis case. Finally, consider the case where a different kernel is used to generate the target functions thanthe covariance function in the GP regression. We use a Matern-3/2 kernel to generate the target functions,and a Squared Exponential kernel as covariance function in the GP regression, with the same length scalefor both. The results are displayed in , lower left. Interestingly, essentially no qualitative differencecan be noticed compared to the well-specified Matern case, cf. in the appendix. We suspect thatthis is due to the correct specification of the length scale, which in the present setting is more importantthan the kernel misspecification.",
  "D": ": Illustration of safe sets for a 2-dimensional input set. Left: Safe set in LoSBO resulting from threefunction evaluations. Right: Illustration of the acquisition function optimization in LoS-GP-UCB over a safeset resulting from four function evaluations. Two initial guesses for the local optimization are used for eachof the balls that span the safe set according to (12).",
  "LoS-GP-UCB": "In SafeOpt-type algorithms, including our variant LoSBO (Algorithm 3), the central computational stepis the optimization of the acquisition function over the expander and maximizer sets, see Algorithm 1.Inspecting the definition of the latter two sets, see , makes it clear that computing these setsrequires a discrete input set D. For many typical application scenarios, at least parts of the input set willbe continuous (e.g., if the optimization variables include a physical parameter that can vary continuously).This means that some form of discretization is necessary before a SafeOpt-type algorithm can be applicable.Typically, equidistant gridding of the (continuous parts of the) input set is used as a discretization, see(Berkenkamp et al., 2016) for a typical example. As a result, SafeOpt-type algorithms become impracticalfor even moderate dimensions, e.g., D Rd for d > 3 (Kirschner et al., 2019a; Sukhija et al., 2023), and as amember of this class, LoSBO inherits this limitation. In this section, we present and investigate an approachto overcome this issue. Instead of adapting existing solution approaches like (Duivenvoorden et al., 2017;Kirschner et al., 2019a; Sukhija et al., 2023), we suggest a pragmatic and straightforward variant that ismotivated by three observations. First, safety in SafeOpt-type algorithms is ensured by restricting the optimization of the acquisition functionto (subsets of) safe sets, i.e., sets S D such that f|S h, where f is the unknown target function. Inother words, as long as we ensure that the acquisition function optimization is restricted to such sets S,the resulting algorithm will be safe, no matter how this optimization is performed or whether an additionalrestriction is added (as in SafeOpt, where the optimization is only over expander and maximizer sets). Inthe case of LoSBO, these safe sets are of a particularly simple form, as they are the union of closed spheres ina metric space, see , left, for an illustration for the case D R2. In typical application scenarios ofSafeOpt-type algorithms, the number of input queries is relatively low, and hence the aforementioned unionis only over relatively few sets. Second, a discrete input set for SafeOpt-type algorithms is necessary due tothe involved definition of the expander and maximizer sets, which in turn are defined to guarantee properexploration in the original SafeOpt setting (Sui et al., 2015). However, for concrete practical problems,such an underexploration might not pose a severe challenge, and an existing BO algorithm can simply bemade safe by restricting the optimization of the acquisition function to a safe set S as described above.In fact, the original SafeOpt paper (Sui et al., 2015) already discussed a safe variant of GP-UCB (Srinivas",
  "Algorithm": "Consider the setting of LoSBO as described in .2.Motivated by the preceding discussion, westart with a standard GP-based BO algorithm that does not need expander and maximizer sets (or similarcomplicated sets requiring discretization). Due to its relation to SafeOpt, we choose GP-UCB (Srinivaset al., 2010) for this task, so at step t 1, the next input is",
  "xt+1 = argmaxxDt(x) + tt(x),(10)": "for an appropriate scaling factor t R>0. As usual, ties are broken arbitrarily. Using the (scaled) posteriorvariance as the acquisition function would be even closer to SafeOpt, but numerical experiments indicate thatGP-UCB performs slightly better in this context. Next, we restrict the acquisition function optimization tothe safe sets St as defined for LoSBO in (9),",
  "j=1Brj(zj)(12)": "for some Nt N>0, r1, . . . , rNt R>0 and z1, . . . , zNt D, and Br(z) = {x D | dD(z, x) r} is theclosed ball with radius r R>0 and center z D in the metric space D. For example, if the initial safe sethas only one element x0 and no input is repeatedly sampled, then Nt = t + 1, z1 = x0 and zj = xj1 forj = 2, . . . , t + 1. Using the decomposition (12), we now have",
  "Each of the inner optimization problems maxx Brj (zj) t(x) + tt(x), j = 1, . . . , Nt, is a maximization": "problem over the convex sets Brj(zj), and each of these inner problems are independent. In particular, theseoptimizations can be trivially parallelized. In practice, one usually has D Rd (often with a simple geometry)and a differentiable covariance function k, so it is possible to use a gradient-based local optimization methodstarted from multiple initial guesses.This is illustrated in , right.All of these multistarts areindependent, and can therefore also be parallelized. We thus arrive at Algorithm 2, which we call Lipschitz-only Safe Gaussian Process Upper Confidence Bound (LoS-GP-UCB) algorithm in the following.LoS-GP-UCB can easily be implemented with state-of-the-art BO libraries.For the numerical experimentsdescribed in the next section, we have chosen BoTorch (Balandat et al., 2020), which allows an easy parallelimplementation of the acquisition function optimization. Finally, LoS-GP-UCB retains the safety guaranteesfrom LoSBO. In particular, the scaling factors (t)t remain tuning factors, and the safety of LoS-GP-UCBis independent of their choice. Furthermore, safety of LoS-GP-UCB does not require Assumption 2. 8Here we are referring to handling the dimensionality within the algorithm, specifically optimization of the acquisitionfunction, and not the exploration performance. Of course, the latter poses challenges, especially if not enough structural orqualitative prior knowledge is encoded in the BO function model.",
  "Conclusion": "In this work, we are concerned with practically relevant safety aspects of the important class of SafeOpt-typealgorithms. We identified the use of heuristics to derive uncertainty bounds as a potential source of safetyviolations in the practical application of these algorithms. This prompted us to use recent, rigorous uncer-tainty bounds in SafeOpt, which allowed us to numerically investigate the safety behavior of this algorithm.We further identified the knowledge of an upper bound on the RKHS norm of the target function as aserious obstacle to reliable real-world applicability of SafeOpt-type algorithms. To overcome this obstacle,we proposed LoSBO, a BO algorithm class relying only on a Lipschitz bound and noise bound to guaranteesafety. Numerical experiments demonstrated that this algorithm is not only safe, but also exhibits supe-rior performance. However, analogously to related algorithms, LoSBO is only suitable for low dimensionalproblems. We therefore also proposed an additional variant (LoS-GP-UCB) suitable for moderately highdimensional problems. The two key assumptions to ensure safety are a known Lipschitz bound on the target function and a knownbound on the additive measurement noise, which have clear interpretations, appear natural in many ap-plications, and are established in domains like control engineering. The safety guarantees of the proposedalgorithms rely on these assumptions, and they have to be judged on a case-by-case base by practitioners. Ongoing work is concerned with implementing the presented algorithms for safe learning in an automotivecontext. While this article focuses on safety, providing exploration guarantees for LoSBO is an interestingaspect of future work. We expect that the approach outlined in applies to most SafeOpt variants.The derivation, implementation, and evaluation of the corresponding LoSBO-type algorithms for these vari-ants is thus another interesting direction for future work. Our findings in combination with evidence in theliterature that SafeOpt and related algorithms have been successfully used in various applications indicatethat this algorithm class does not ensure hard safety constraints (in practice), but instead yields cautiousbehavior. The precise connection to conservative bandits and existing cautious BO approaches is anotherinteresting topic for further investigations.",
  "Broader Impact Statement": "This work is concerned with safety issues of a popular BO algorithm that has already found numerousapplications in real-world scenarios.Henceforth we contribute to the improved safety and reliability ofmachine learning methods for real-world applications. Furthermore, we expect no adverse societal impact ofour work. We thank Paul Brunzema and Alexander von Rohr for very helpful discussions and Sami Azirar for supportwhen generating plots. This work was performed in part within the Helmholtz School for Data Science in Life,Earth and Energy (HDS-LEE). Furthermore, the research was in part funded by the German Federal Ministryfor Economic Affairs and Climate Action (BMWK) through the project EEMotion and by the DeutscheForschungsgemeinschaft (DFG, German Research Foundation) under Germanys Excellence Strategy EXC-",
  "Marc Atteia. Hilbertian kernels and spline functions. Elsevier, 1992": "Maximilian Balandat, Brian Karrer, Daniel Jiang, Samuel Daulton, Ben Letham, Andrew G Wilson, andEytan Bakshy.BoTorch: A framework for efficient Monte-Carlo Bayesian optimization. Advances inneural information processing systems, 33:2152421538, 2020. Dominik Baumann, Alonso Marco, Matteo Turchetta, and Sebastian Trimpe. Gosafe: Globally optimalsafe robot learning. In 2021 IEEE International Conference on Robotics and Automation (ICRA), pp.44524458. IEEE, 2021.",
  "Trevor Hastie, Robert Tibshirani, Jerome H Friedman, and Jerome H Friedman. The elements of statisticallearning: data mining, inference, and prediction, volume 2. Springer, 2009": "Mohamed K. Helwa, Adam Heins, and Angela P. Schoellig. Provably robust learning-based approach forhigh-accuracy tracking control of Lagrangian systems. IEEE Robotics and Automation Letters, 4(2):15871594, 2019. ISSN 23773766. doi: 10.1109/LRA.2019.2896728. Jos Miguel Hernndez-Lobato, Michael A Gelbart, Ryan P Adams, Matthew W Hoffman, Zoubin Ghahra-mani, et al. A general framework for constrained bayesian optimization using information-based search.Journal of Machine Learning Research, 17(160):153, 2016. Lukas Hewing, Kim P Wabersich, Marcel Menner, and Melanie N Zeilinger. Learning-based model predictivecontrol: Toward safe learning in control. Annual Review of Control, Robotics, and Autonomous Systems,3:269296, 2020.",
  "Toni Karvonen and Chris J Oates. Maximum likelihood estimation in Gaussian process regression is ill-posed.Journal of Machine Learning Research, 24(120):147, 2023": "Toni Karvonen, George Wynne, Filip Tronarp, Chris Oates, and Simo Sarkka. Maximum likelihood es-timation and uncertainty quantification for Gaussian process approximation of deterministic functions.SIAM/ASA Journal on Uncertainty Quantification, 8(3):926958, 2020. Youngmin Kim, Richard Allmendinger, and Manuel Lpez-Ibez. Safe learning and optimization techniques:Towards a survey of the state of the art. In International Workshop on the Foundations of TrustworthyAI Integrating Learning, Optimization and Reasoning, pp. 123139. Springer, 2020.",
  "Yanan Sui, Vincent Zhuang, Joel Burdick, and Yisong Yue.Stagewise safe Bayesian optimization withGaussian processes. In International conference on machine learning, pp. 47814789. PMLR, 2018": "Bhavya Sukhija, Matteo Turchetta, David Lindner, Andreas Krause, Sebastian Trimpe, and Dominik Bau-mann.Gosafeopt: Scalable safe exploration for global optimization of dynamical systems.ArtificialIntelligence, 320:103922, 2023. Aretha L Teckentrup. Convergence of Gaussian process regression with estimated hyper-parameters andapplications in Bayesian inverse problems. SIAM/ASA Journal on Uncertainty Quantification, 8(4):13101337, 2020. Abdullah Tokmak, Christian Fiedler, Melanie N Zeilinger, Sebastian Trimpe, and Johannes Khler. Au-tomatic nonlinear MPC approximation with closed-loop guarantees. arXiv preprint arXiv:2312.10199,2023.",
  "i,j=1,...,N is positive semidefinite. Equivalently, the function k is symmetric (k(xi, xj) =": "k(xj, xi) for all i, j = 1, . . . , N), and for all 1, . . . , N R we have Ni,j=1 ijk(xi, xj) 0.In theliterature such a function is often called positive definite or of positive type. Additionally, k is called positivedefinite, if for all pairwise distinct x1, . . . , xN D, the matrixk(xi, xj)",
  "i,j=1,...,N is positive definite. Thisproperty is sometimes referred to as strict positive definiteness in the literature": "Let H be a Hilbert space functions on D. We call H a reproducing kernel Hilbert space (RKHS) if everyevaluation functional is continuous, i.e., for all x D the mapping H f f(x) R is continuous w.r.t.the norm induced by the scalar product in H. Furthermore, k is called a reproducing kernel (for H) if 1)k(, x) H for all x D, and 2) f(x) = f, k(, x)H for all f H and x D. As is well-known, H is a RKHS if and only if it has a reproducing kernel, and in this case the latter is unique(Steinwart & Christmann, 2008, Lemma 4.19, Theorem 4.20). Furthermore, every reproducing kernel ispositive semidefinite, and every positive semidefinite function is a reproducing kernel for a unique RKHS(Steinwart & Christmann, 2008, Theorem 4.16, 4.21). If k is positive semidefinite, then we denote its uniqueRKHS as (Hk, , k), and the induced norm by k. Furthermore, we define the pre RKHS by",
  "see (Steinwart & Christmann, 2008, Theorem 4.21)": "If k is the covariance function of a GP, then it is positive semidefinite (since every covariance matrix is positivesemidefinite), and hence the reproducing kernel of a unique RKHS. Conversely, if k is the reproducing kernelof a RKHS, then k is positive semidefinite, there exists a GP having k as its covariance function, and theGP can be chosen with a zero mean function (Berlinet & Thomas-Agnan, 2004). Furthermore, consider GP regression with a prior GPD(m, k), then t m Hprek, where t is the posteriormean corresponding to a finite data set with t points. In particular, the posterior mean for a zero meanprior GP is always in the pre RKHS corresponding to the covariance function. As is customary in machinelearning with GPs (Rasmussen & Williams, 2006), and also in many BO scenarios (Garnett, 2023), in thefollowing we will use a zero mean GP prior, m 0, without loss of generality.",
  "A.2Additional discussion": "Theory for the RKHS normFor an arbitrary kernel, one can use discretization-based variational char-acterizations of the RKHS norm (and RKHS functions), for example, by maximization over a family of lowerbounds on the RKHS norm (Fiedler et al., 2024, Section B), (Atteia, 1992, Chapter I), by minimization overcertain bounds on function values at finitely many inputs (Okutmutur, 2005, Theorem A.2.6), by minimiza-tion over finite interpolation problems (Paulsen & Raghupathi, 2016, Theorem 3.11), or by minimization overcertain matrix inequalities (Paulsen & Raghupathi, 2016, Theorem 3.11). For separable RKHSs, the RKHSnorm can be expressed using a sampling expansion (Korezlioglu, 1968), or as the limit of norms of RKHSsover finite inputs (Luki & Beder, 2001, Lemma 4.6). On the one hand, all of these variational problems havean explicit form and they work for any kernel (any kernel with separable RKHS, respectively). However,it is not at all clear how to relate these representations to common properties of functions that might beused as reliable prior knowledge to derive upper bounds on the RKHS norm. Furthermore, these variational",
  ": end for": "Choice of noise bound in LoSBOProposition 1 states that if E R>0 is a bound on the noisemagnitude, then LoSBO is safe. Suppose we know that |t| B for some constant B R>0, then we couldset E = B, and assume that the bound B is sharp. For example, we might have t 1",
  "B + 1": "2B, wherex is the Dirac distribution with atom on x. If we choose E = B, then LoSBO is indeed safe according toProposition 1, i.e., for all inputs xt D that are queried by the algorithm, we have f(xt) h. However,if we additionally assume that there are sizeable parts of the input space D where f h, and since theborder of the safe sets will be in such a region, it is likely that inputs from this area will be queried. Thismeans that it is likely that measurements yt with yt < h will be received - this happens if f(xt) h andt B. While according to the formal model such an input xt is safe, to the user it looks as if a safetyviolation occurred. Since in practice a detected (not necessarily real) safety violation might lead to somecostly action (e.g., emergency stop), such a situation is undesirable. To avoid this, we can set E = 2B.While this introduces some conservatism, it avoids the described apparent safety violations - essentially, thisoption mitigates false alarms. Whether to choose in the present situation E = B or E = 2B (or even anoption in between) is ultimately a practical question to be addressed by the practitioner using the algorithm.",
  "In .1, we work exclusively with the squared exponential (SE) kernel on the input set withlength scale 0.2/": "2. In order to generate a synthetic RKHS function with known RKHS norm, we follow theapproach from Fiedler et al. (2021a) and use the explicit orthonormal basis (ONB) of the SE kernel RKHSas described in (Steinwart & Christmann, 2008, .4). More precisely, we select a random subset ofthese basis functions, generate randomly a vector of coefficients and rescale it (to achieve the required RKHSnorm), and then form the weighted sum of the selected basis functions. For the first experiment, in order to generate the data sets, 100 inputs are uniformly sampled from , thecorresponding RKHS function is evaluated on these inputs, and finally i.i.d. normal noise with variance 0.01is added to the function values. For each data set, we apply GP regression with a zero mean prior, and theSE kernel as covariance function, using the same length scale as for the generation of the target functions,and we use the actual noise variance in the GP regression. Finally, we use the uncertainty set (2) witht 2, and check on a fine grid on whether the target function from the RKHS is completely containedwithin this uncertainty set. As soon as the function value of one input is not covered by the uncertainty, wecount this run as a failure. Note that this might be even slightly optimistic, since a bound violation mighthappen in the between the grid points (which is very unlikely in this setup, however). For the second experiment, we use the same approach as above to generate RKHS functions f. We definethe safety threshold h by setting h = (f) 0.2SD(f), where (f) and SD(f) are the empirical meanand standard deviation of the test function f evaluated on a fine grid of the input space. This procedure isnecessary to ensure that we get non-empty safe sets, but that the problem instance is sufficiently challenging.We further evaluate |f | on a fine grid on the input space, take the maximum of this, and multiply it by 1.1to find a (slightly conservative) upper bound of the Lipschitz constant of f, which is used as the Lipschitzbound in the algorithm. We then run SafeOpt on 10000 times from a random safe initial state, again usingi.i.d. additive normal noise with variance 0.01 (and using the correct noise variance in the GP regression).Finally, we select a target function that exhibits significant safety violations. Note that this approach isappropriate in this context, since the safety property has to hold for all potential target functions, and dueto the large number of independent runs, no multiple testing problem arises.",
  "C.2Additional details for .4": "A target function is therefore fixed, and the algorithms are run multiple times on this same function withindependent noise realizations. To enable the performance of the algorithms to be clearly evaluated, synthetictarget functions will be used, and since we want to compare LoSBO with Real--SafeOpt - the latter requiringa target function from an RKHS and with a known RKHS norm upper bound - we generate target functionsfrom an RKHS. Unless noted otherwise, in each experiment we generate 100 RKHS functions, each withRKHS norm 10, and we compute a (slightly) conservative Lipschitz bound as well as an appropriate initialsafe set. Following the previous safe BO literature, we restrict ourselves to compact subsets of Rd, and inthis section for simplicity we further restrict ourselves to d = 1.",
  "f h,(16)": "where t(x) is the predictive mean (in LoSBO and Real--SafeOpt the posterior mean) at time t 1,evaluated at input x, and f is the maximum of f. This metric will be averaged over all runs for a given f,and over all target functions, respectively, in the following plots. For simplicity, independent additive noise, uniformly sampled from [B, B], is used in all of the followingexperiments. As is well-known, bounded random variables are subgaussian, and we can set R = B in Real--SafeOpt. Additionally, we choose = 0.01 and the true RKHS norm as the RKHS norm upper boundin Real--SafeOpt, unless noted otherwise. We further set the nominal noise variance equal to R in bothLoSBO and Real--SafeOpt. Following the discussion in Section B, we choose E = 2B in LoSBO. Finally,we must specify a strategy to compute t in LoSBO. Recall from .2 that these scaling factors arenow proper tuning parameters. In all of the following experiments, we use 2 in LoSBO, as this is acommon choice in the literature on SafeOpt and GP-UCB. Choosing such a simple rule also simplifies the",
  "C.3Additional experimental results for LoSBO": "We have repeated the first experiment from .4, however, now with the RKHS functions sampledusing the pre RKHS approach. , left, displays the results. While no real difference in performanceis noticable for LoSBO, Real--SafeOpt appears to perform slightly better compared to target functionsgenerated using the ONB approach. A potential explanation lies in the shapes of functions that typicallyarise in the two different sampling methods. As observed in (Fiedler et al., 2021a), functions sampled fromthe ONB look more \"bumpy\" compared to pre RKHS functions, and appear to be more challenging forthe uncertainty bounds. Since Real--SafeOpt needs to precisely adhere to these bounds, its explorationperformance is diminished. By contrast, LoSBO behaves overly optimistically as t 2 is used, but theunderlying RKHS functions have RKHS norm 10, see also the evaluations in (Fiedler et al., 2021a).Itappears that this over-optimism leads to better performance, and since for safety LoSBO does not rely onscaling factors t that correspond to valid frequentist uncertainty sets, this over-optimism does not jeopardizesafety."
}