{
  "Abstract": "We conducted a reproducibility study on Integrated Gradients (IG) based methods and theImportant Direction Gradient Integration (IDGI) framework. IDGI eliminates the expla-nation noise in each step of the computation of IG-based methods that use the RiemannIntegration for integrated gradient computation. We perform a rigorous theoretical analysisof IDGI and raise a few critical questions that we later address through our study. We alsoexperimentally verify the authors claims concerning the performance of IDGI over IG-basedmethods. Additionally, we varied the number of steps used in the Riemann approximation,an essential parameter in all IG methods, and analyzed the corresponding change in results.We also studied the numerical instability of the attribution methods to check the consis-tency of the saliency maps produced. We developed the complete code to implement IDGIover the baseline IG methods and evaluated them using three metrics since the availablecode was insufficient for this study. Our code is readily usable and publicly available at",
  "Introduction": "Deep learning models for computer vision have become increasingly integrated into several vital domainslike healthcare and security. There is a surge in research dedicated to studying the problem of attributingthe prediction of a deep network to its input features. Gradient-based saliency/attribution map approaches(Sundararajan et al., 2017; Xu et al., 2020; Kapishnikov et al., 2021; 2019; Pan et al., 2021; Simonyan et al.,2013; Smilkov et al., 2017) form an important category of explanation methods. One of the first works thatmade a notable contribution to the field of explainability and introduced a valid metric system to evaluateits results was by Kapishnikov et al. (2019). Other prominent gradient-based explanation methods includeIntegrated Gradients (IG) (Sundararajan et al., 2017) and its variants, Blur Integrated Gradients (BlurIG)and Guided Integrated Gradients (GIG) (Xu et al., 2020; Kapishnikov et al., 2021), that have garneredconsiderable attention due to their notable explanation performance and desirable axiomatic properties.However, IG-based methods integrate noise in their attribution. Previous works (Kapishnikov et al., 2021)have explored the possible origin of this attribution noise and attempted to eliminate it. The Important Direction Gradient Integration (IDGI) framework is a recent development that has tackledthis issue and reported better results. The paper (Yang et al., 2023) highlights the reason behind the noisein the explanation. It proposes a framework to mathematically eliminate the components in the integrationcalculation that contribute to the noise in the attribution. It also introduced a new measurement, Accuracy",
  "Published in Transactions on Machine Learning Research (12/2024)": "Runmin Cong, Jianjun Lei, Huazhu Fu, Ming-Ming Cheng, Weisi Lin, and Qingming Huang. Review ofvisual saliency detection with comprehensive information. IEEE Transactions on circuits and Systems forVideo Technology, 29(10):29412959, 2018. Parimala Kancharla and Sumohana S Channappayya. Improving the visual quality of generative adversarialnetwork (gan)-generated images using the multi-scale structural similarity index.In 2018 25th IEEEinternational conference on image processing (ICIP), pp. 39083912. IEEE, 2018. Andrei Kapishnikov, Tolga Bolukbasi, Fernanda Vigas, and Michael Terry. Xrai: Better attributions throughregions. In Proceedings of the IEEE/CVF International Conference on Computer Vision, pp. 49484957,2019. Andrei Kapishnikov, Subhashini Venugopalan, Besim Avci, Ben Wedin, Michael Terry, and Tolga Boluk-basi. Guided integrated gradients: An adaptive path method for removing noise. In Proceedings of theIEEE/CVF conference on computer vision and pattern recognition, pp. 50505058, 2021. Kede Ma, Qingbo Wu, Zhou Wang, Zhengfang Duanmu, Hongwei Yong, Hongliang Li, and Lei Zhang. Groupmad competition-a new methodology to compare objective image quality models. In Proceedings of theIEEE Conference on Computer Vision and Pattern Recognition, pp. 16641673, 2016.",
  "Q2: What are the theoretical implications of IDGI? Under what conditions is it valid?": "Q3: The number of steps used in the Riemann approximation of the integral used in IG-basedmethods is an important parameter. In most previous works, it has been overlooked, and the choiceof step size remains vague. We thus ask ourselves: How does the variation in step size impact theperformance of IDGI compared to the underlying IG methods?",
  "Our contributions and findings are as follows:": "We answer Q1 in , where we present the results obtained from the experiments to compareour results with the authors findings. We observed that our results matched their claims for themost part, with a few anomalies. We observed a vital trait that is common in models that exhibitanomalies and discuss the same in .4. We answer Q2 in . Firstly, we report two errors in the illustration of IDGI provided in theoriginal paper. We present our improved illustration of IDGI that correctly demonstrates the pathcorresponding to IG, GIG, and BlurIG. Secondly, we derive the expression for xjp, an importantterm in the IDGI algorithm. While the original paper mentions the expression, how it was obtainedhas not been discussed. The expressions derivation gives us insights into how IDGIs performanceis affected by step size variations, which led us to ask Q3. We answer Q3 in .5.1. We verify the insights from the theoretical analysis of the expressionfor the above-mentioned xjp term. We also vary the step size used to compute the Riemann sum forIG and BlurIG. We arrive at a noteworthy conclusion: IDGI is more sensitive to step-size variationthan its underlying IG method. We successfully proved this through rigorous theoretical analysis ofhow the step size and the performance of IDGI are linked. We then confirmed our theory throughour experimental findings. We also observed that at a higher step size, the scores of BlurIG + IDGIare lower than those for IG + IDGI. We address this by analyzing the IDGI algorithm and observingthe variation in an image along the path for BlurIG and IG.",
  "We answer Q4 in .5.2. We perform an additional experiment to quantitatively comparethe saliency map produced for an image and a compressed version of the same image": "We could not directly use the existing code for our study, which led us to integrate the code for IDGI1 provided by the authors and use the original implementations 2 of the authors code for IG, GIG,and BlurIG. The code provided by the repository was not usable for reproducing results at scale.Our code utilizes high-performance computing (HPC) resources. It is ready to use and complete,facilitating easy reproduction of results for the entire dataset and models presented in the originalpaper. We provide the exact details regarding this in . This paper has been organized as follows: We begin with a brief background on the original Integrated Gradi-ents method and its variants, BlurIG and GIG, in . Readers familiar with these can skip to ,where we summarize the IDGI algorithm, followed by the complete derivation of xjp, as previously men-tioned, and an in-depth discussion of IDGIs sensitivity to step-size variation. We also present an improvedillustration of IDGI. Finally, presents our experimental results, including implementation details,computational requirements, and results beyond the original paper. We also use this section to describe thedifficulties we faced during the study due to the need for more details on the original implementation.",
  "Integrated Gradients": "Integrated Gradients (IG) Sundararajan et al. (2017) is a path method for the straight line path specifiedIG() = x + (x x)for . Let f be a classifier, c a class, and x an input. The output fc(x)signifies the confidence score for predicting that x belongs to class c. To determine feature attributions, wecalculate the line integral from the reference point x to the input image x within the vector field createdby the model. This vector field is formed by the gradient of fc(x) with respect to the input space. TheIntegrated Gradient for the ith dimension of an input x is defined as follows:",
  "Blur Integrated Gradients": "Xu et al. (2020) introduced Blur Integrated Gradients: For a given function f : Rmn representinga classifier and c, a class, let z(x, y) be the 2D input and z(x, y) be the baseline. We examine the pathfrom z to z and calculate gradients along this path. The path for IG is linear in z and scales the imagesintensity. BlurIG, on the other hand, uses a path where a Gaussian filter progressively blurs the input. Theblurring path is defined by:",
  "Guided Integrated Gradients": "Guided Integrated Gradients (GIG) iteratively find the integration path IG(), to avoid the highcurvature points in the output shape of DNNs (due to which the larger-magnitude gradients from eachfeasible point on the path would have a significantly more significant effect on the final attribution values).The new path is defined as follows:",
  ": The original illustration of IDGI Yang et al. (2023) (left), our improved illustration(right)": "We now shift our attention to the IDGI algorithm, as present in the original work by Yang et al. (2023). Wediscuss the mathematics leading to the IDGI algorithm for new readers: Recall the path function denotedby discussed in . Consider the point xj = (j) and the next point xj+1 = (j+1) on the pathfrom reference point x to the input point x. IG-based methods compute the gradient, g, of fc(xj) withrespect to x and use Riemann integration to perform element-wise multiplication of the gradient and thestep, xj+1 xj, which the authors refer to as the original direction. Further, they refer to the directiong|g| as the important direction. The gradient of the function value fc at each point in space defines theconservative vector field, where an infinite number of hyperplanes h exist, and each hyperplane containsall points x with the same functional value. In the conservative vector field, separate hyperplanes neverintersect, meaning each point has its projection point with regard to the other hyperplanes. For point xj,if one moves xj along the Important direction, there exists a unique projection point xjp on the hyperplanehj+1 where fc(xjp) = fc(xj+1). The authors (Yang et al., 2023) then state Theorem 1: Consider a function fc(x) mapping from Rn to R. Letxj, xj+1, xjp Rn be given points. The gradient of fc with respect to each point in Rn forms conservativevector fields, denoted as F . We define a hyperplane hj as the set of all points x where fc(x) = fc(xj).In this context, we assume that Riemann Integration provides an accurate estimate for the line integralof the vector field F between points. For instance, the integral from xj to xjp can be approximated as",
  "xj(xjp xj).Here, xj lies on the hyperplane hj, while xjp and xj+1 lie on thehyperplane hj+1": "This theorem asserts that the line integral of the vector field from xj to xj+1 is approximately equal to theline integral from xj to xjp. This indicates that the chosen path within these specific points and hyperplanesyields similar results when integrating the functions gradient. This illustrates that while for a feature, i,the value of the attribution computed from the original direction and the critical direction can be different,the change in the value of fc remains the same. Let x be a given input with target class c, f be a given classifier, [x, ..., xj, ...x] be a given path from anyIG-based method and g be the gradient of fc(xj) with respect to x. Then, according to the IDGI Algorithm,the important direction vector of g is determined asg|g| and the step size as fc(xj+1)fc(xj)",
  "|g|, has the same functional value aspoint xj+1, i.e., fc(xj+1) = fc(xjp)": "We observe that the Taylor series approximation is necessary to arrive at the expression for xjp. Assumingxjp lies on the given path from any IG-based method such that it is defined as xjp = xj + c g|g|, where c isthe length of the projection that we wish to approximate, we now derive the expression for xjp.",
  "How does IDGI vary with step size?": "As previously mentioned, the derivation for xjp gives us insights into how IDGIs performance is affectedby step size variations. The expression for c, the length of the projection, determines the validity of theTaylor series approximation. The smaller the value of c, the more valid the approximation. We observethat c is directly proportional to fc(xj+1) fc(xj). Here, xj+1 and xj are consecutive points in the pathof an IG-based method. It is easy to observe that for the same path, these two points are closer to eachother for a larger number of steps (since the number of steps denotes the finite number of small piece-wiselinear segments that we discretize the path between x and x into.) This implies that fc(xj+1) and fc(xj)are closer in value. Therefore, a larger number of steps is required for a smaller c. The expression of xjp isthus directly linked to the number of steps and, thus, the step size used for the algorithm, which means thatIDGI is sensitive to step size variation.",
  "We noticed common calculations for all the IG-based methods. To minimize the computation over-head, we precomputed these results and stored them": ": Saliency map of the existing IG-based methods and those with IDGI explaining the predictionfrom InceptionV3. We compare two sets of saliencies for each image by taking the models top 2 distinctclasses as the predicted class. While the top class object is always more highlighted, we observe that allIG-based methods with IDGI are slightly better at highlighting each class than methods without IDGI.",
  "Experimental Setup": "We use the same baseline methods (IG, GIG, and BlurIG) as the authors original work. Following theimplementations of IDGI, we also use the original implementations with default parameters in the authorscode for IG, GIG, and BlurIG. We use the black image as the reference point for IG and GIG. Finally, aspreviously mentioned, we use different step sizes (8, 16, 32, 64, and 128) as an additional experiment beyond",
  "the original paper to verify our hypothesis on how sensitive IDGI is to step size. We also report our findingson the effect of IDGI on the numerical stability of the attribution methods": "Models.We use the PyTorch (1.13.1) pre-trained models: DenseNet121, 169, 201, InceptionV3, Mo-bileNetV2, ResNet50,101,151V2, and VGG16,19. We did not use Xception due to computational constraints.Datasets. We used the same dataset as the original paper - The Imagenet validation dataset, which contains50K test samples with labels and annotations. We also tested the explanation methods for each model onimages that show that the model predicted the label correctly, which varies from 33K to 39K, correspondingto different models. Evaluation Metrics. We use four evaluation metrics - Insertion Score (Pan et al., 2021; Petsiuk et al.), theSoftmax Information Curves (SIC), and the Accuracy Information Curves (AIC) (Kapishnikov et al., 2021;2019) using Normalized Entropy and the modified version of SIC and AIC with MS-SSIM as introducedin the original IDGI paper. We follow the implementation details described in previous works, as in theoriginal paper. We did not compute the three Weakly Supervised Localization metrics because, according toprevious works from which Yang et al. (2023) borrowed the implementation details, we require the Imagenetsegmentation dataset to compute these metrics. Three versions of this dataset exist, and neither the previousworks (Xu et al., 2020; Kapishnikov et al., 2021; 2019) nor Yang et al. (2023) mention which version of thedataset they used. Calculating the metrics for all three dataset versions was not computationally feasible.Furthermore, none of the works provide the code to calculate these metrics. Computational Requirements. We used a single NVIDIA Tesla V100 GPU with 16 GB of VRAM forour reproducibility experiments. The compute time varies slightly with the model, the method, and the stepsize. We report the average compute time per method per model for 128 steps: computing the saliencies tookapproximately 9 hours, computing SIC and AIC using Normalized Entropy and MS-SSIM took 90 minutes,and computing insertion scores took 70 minutes.",
  ": Area under the curve for AIC and SIC using Normalized Entropy for 128 steps. The claim thatIDGI improves all three IG-based methods across all experiment settings does not hold": "We evaluated the explanation methods using the Softmax information curves (SIC) and the Accuracy infor-mation curves (AIC) using Normalized Entropy. We rewrote the available code according to the modifiedimplementation details introduced in the paper (Yang et al., 2023) and evaluated each of the three baselines.We report the area under the AIC and SIC curves for 128 steps in . Based on our results, we find that our results match the claims made in the original paper (Yang et al.,2023) for the most part, and the better explanation method has a higher area under the AIC and SICcurves. However, we observed that for ResNet152v2, IDGI worsens the area under the AIC and SIC curvesfor IG; and, for MobileNetv2, ResNet50v2, and ResNet101v2, BlurIG + IDGI also underperforms BlurIG. Acommon trait observed in the models that exhibit anomalies is that they all implement residual connectionsin their architecture. While we could not demonstrate how this may cause IDGI to reduce the performanceof the underlying method, it is a plausible hypothesis that the residual connections might interact with theIDGI framework in ways that are not fully understood, warranting further investigation into the underlyingmechanisms and their impact on explanation methods.",
  "SIC and AIC with MS-SSIM": "We now evaluate the explanation methods using the Softmax information curves (SIC) and the Accuracyinformation curves (AIC) using MS-SSIM (Kancharla & Channappayya, 2018; Ma et al., 2016; Odena et al.,2017). This well-studied image quality evaluation method analyzes the structural similarity of two images.We re-wrote the available code according to the modified implementation details introduced in the paper",
  "(Yang et al., 2023) and evaluated each of the three baselines (IG, GIG, and BlurIG) across ten models. Wereport the area under AIC and SIC for 128 steps in": "Based on the results we obtained, we find that our results match the claims made in the original paper (Yanget al., 2023) consistently. The better explanation method has a higher area under the AIC and SIC curves.However, for ResNet152V2, the area under SIC for IG is equal to that for IG + IDGI.",
  "Additional Experiments": "As mentioned in and discussed in , we now proceed to show our results for step-sizevariation and evaluate its effect on IDGI compared to the baselines (IG, GIG, and BlurIG). We also conductedan experiment to compare the saliency map generated for an image quantitatively with that of a compressedversion of the same image.",
  ": end for7: return IIDGI": "We report our results for step-size variation through , where we study the variation of the valueof the respective metric versus the number of steps (8, 16, 32, and 64) for InceptionV3. Increasing thenumber of steps leads to a better score, as a higher number of steps in the Riemann sum leads to a finerapproximation of the actual integral. However, due to computational limitations, increasing the number ofsteps requires more resources and time, necessitating a trade-off. The developer must make a choice basedon the sensitivity of the application and the resources available. Please note that the x-axis is in exponentialscale, which means that beyond a step size of 32, the return in score improvement per step is marginal. We observe that at a higher step size, the scores of BlurIG + IDGI are lower than those for IG + IDGI. Toexplain this, we analyze the IDGI algorithm, as defined by Yang et al. (2023), and observe the relationshipbetween d and IIDGIi, the attribution value for IDGI. , x,f,c, and path are as defined in .",
  ": Insertion Score with probability and probability ratio, AIC and SIC using Normalized Entropyand MS-SSIM vs. number of steps, for Inceptionv3": "As shown in , the variation in the image for BlurIG is minimal for most of the path, with significantsharpening occurring only in the final 10% of the steps, suggesting that f is a constant, low value for mostof the sampled points. In contrast, the image brightness increases uniformly along the IG path, indicatinga more steady change in f. The change between two subsequent steps (d) determines the magnitude of theintegrand added to the final saliency. Consequently, for BlurIG + IDGI, most samples contribute minimallyto the final saliency. Both IG + IDGI and BlurIG + IDGI benefit from increased steps, improving the",
  "approximation of the underlying integral. However, IG + IDGI generally benefits more due to the moreuniform change in probability scores along most of the path": ": Images observed along the path of BlurIG and IG. For BlurIG, for most values of , we noticeminimal changes in the image with small increments. In contrast, for IG, a uniform change in the image isobserved with the same increments in . In the Appendix, we report the insertion scores and area under AIC and SIC using Normalized Entropy andMS-SSIM for the remaining models for 8, 16, 32, and 64 steps. According to our experimental results, ourtheoretical analysis is verified and stands correct. We observe that IDGI consistently has more variants inthe number of steps than its baselines.",
  ": The negative log values of MSE computed between the saliencies of the compressed images andthe non-compressed images for InceptionV3. Higher values indicate better numerical stability": "During our early experimental stage, we observed that, visually, the saliency maps obtained for GIG werestarkly different when computed on GPU and CPU. This phenomenon is undesirable as it makes the at-tribution method unreliable. Hence, we decided to study the numerical instability of different attributionmethods. We used JPEG compression with a retention factor of 75% We perform this experiment for IDGIand each underlying method: IG, BlurIG, and GIG. Our experimental results show that the baseline method+ IDGI achieves significantly better numerical stability (smaller MSE) than the baseline method. Also, GIGshows poor numerical stability, as we had anticipated from visual observations.",
  "Conclusion": "We rigorously analyze the theoretical aspects of IDGI, experimentally verify the claims made by Yanget al. (2023), and perform additional experiments to verify our theoretical observations and understand thenumerical stability of the framework. Although the claim that IDGI constantly improves upon all baselinemethods is mostly true for MobileNetV2 and the ResNet family, our experimental results show otherwisefor some baseline methods. Our theoretical and experimental analysis shows that IDGI is more sensitive tostep size variation than the baseline methods. The application of IDGI makes the baseline method moreclass-sensitive, which is a desirable property. We also observe that the IDGI + baseline method is morenumerically stable than the baseline."
}