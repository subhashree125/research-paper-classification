{
  "Abstract": "A challenge in reinforcement learning lies in effectively deploying trained policies to handleout-of-distribution data and environmental variations. Agents observing pixel-based imagedata are generally sensitive to background distractions and color changes. Commonly, colorgeneralization is achieved through data augmentation. In contrast, we propose a color-invariant neural network layer that adopts distinct color symmetries in a self-supervisedfashion. This allows for color sensitivity while achieving generalization. Our approach isbased on dynamic-mode decomposition, which also accommodates spatial and temporalsymmetries; we discuss the controlled breaking of the latter. We empirically evaluate ourmethod in the Minigrid, Procgen, and DeepMind Control suites and find improved colorsensitivity and generalisation.",
  "Introduction": "Reinforcement learning has seen tremendous success, but ensuring it works well on unfamiliar data is stilla challenge. The original approach to generalisation in image-based RL, which used randomized imageaugmentations (Laskin et al., 2020; Yarats et al., 2021b), was remarkably successful despite its brute-force nature. However, using image-based data augmentation can lead to over-regularisation to specificaugmentations and thus may perform poorly when applied to certain environments. The more evolvedmethodology of selecting specific image augmentations in a self-supervised way leads to increased performanceand alleviates some aspects of over-regularisation (Raileanu et al., 2020; Hansen & Wang, 2021). However, finding the balance between color sensitivity and color generalisation remains an open challenge,which is not addressed by the above-mentioned methods. Color sensitivity refers to the agents ability to takeaction based on specific colors of objects in the environment, such as whether to stop or go at a red or greentraffic light, see Figure (1). In contrast, it is imperative that the agents decision-making process remainsinvariant to color changes in certain environmental factors, e.g., the color of houses, trees, or non-emergencyvehicles in the context of autonomous vehicles. An alternative to data augmentation is utilizing symmetries in RL to improve generalization (Tang & Ha, 2021;van der Pol et al., 2020; Weissenbacher et al., 2022). Specifically, reinforcement learning may benefit from",
  "Published in Transactions on Machine Learning Research (10/2024)": ": Architecture and hyper-parameter choices for CiL on Procgen, DMControl, Minigrid based on (Raileanuet al., 2020), (Hansen & Wang, 2021), and (Jiang et al., 2021), respectively. Channels refer to the category channels.We use the algorithms in the code-base without any hyper-parameter changes except for reduction of hidden-dim ofthe actor-critic networks to 64. The patch size follows the convention in Vision Transformers; for a 64x64 pixel input,we use 8x8 patches. In , the neighborhood sizes are chosen as odd numbers (3, 5) to ensure a central patchwith an equal number of neighboring patches on all sides.",
  "Reinforcement Learning & Symmetries": "Reinforcement Learning. A Markov Decision Process (MDP) is a mathematical framework for modelingdecision-making problems in stochastic environments. MDPs are characterized by a tuple (S, A, P, R, ),where S is a finite set of states, A is a finite set of actions, P is the transition probability function, Ris the reward function, and [0, 1) is the discount factor. In RL, one aims to learn optimal decision-making policies in MDPs. A policy, denoted as : S A, is a mapping from states to actions. Theoptimal policy maximizes the expected cumulative discounted reward, given by the value functionV (s) = E [t=0 tR(st, at) | s0 = s, at ( |st)], where the expectation is taken over the sequence ofstates and actions encountered by following the policy . The optimal policy is the one that satisfiesV (s) V (s) for all s S and any other policy . Symmetry groups. Symmetry transformations are special cases of mathematical groups, i.e. sets thatcontain the identity element and are closed under multiplication and inverses. In this work we encounterthe group of orthogonal matrices, in particular the three-dimensional rotation group SO3, i.e. the specialorthogonal group in dimension 3. Any element of the latter can be written in terms of three independentparameters i.e. the rotation angles along the x,y and z-axis, respectively, called the Euler angles. Invariance. Invariance is a foundational concept in understanding how functions respond to symmetries oftheir inputs. Before defining these concepts, we introduce some notation. Let f be a function that mapselements from space S to space S. Let G be a symmetry group acting on S and let us denote by g anindividual transformation in G. We shall denote the action of the transformation g on an element s of S byg s. A function f is invariant with respect to a set of transformations (symmetry group G) if the applicationof any transformation from this set to its input does not change the functions output. Mathematically, thisis expressed as f(g s) = f(s) for every transformation g G.",
  "Observation": ": Top: Overview of the balance of color generalisation vs. color sensitivity required for RL tasks, in theexample of the Jumper environment of the Procgen suite. Bottom: Conventional random color-augmentation i.e.color-jitter (left) compared to OUR self-supervised learning of color-symmetries (right), in the example of Category IIcolor symmetries -horizontal axis- per each feature of the model - vertical axis-. The vertical axis shows differentfeatures-wise choices of Category II symmetries. The horizontal axis shows identical images under the particularCategory II symmetry. In other words, CiL produces the same feature-wise output if the input image varies accordingto horizontal axis.",
  "sti+1 K sti , for i = 1, . . . , N(1)": "The operator K is an approximation of the Koopman operator restricted to observables given by directmeasurements of the state s. In practice, the operator K is computed from a collection of snapshot pairsof the system {sti+1, sti}i=1,...,N. In principle, for DMD the times need not be sequential or evenly spaced,however this is the case for most RL settings. These snapshots are arranged into two data matrices, S and S",
  "Leading Rank Representation": "Since the matrix operator K typically admits n2 elements, for high-dimensional data, it is intractable torepresent this operator. Instead, one may compute its leading spectral decomposition. In particular, for timeseries pixel data, the sequence length N is much shorter (in the context of RL) than the number of pixels inthe 2D image, thus the matrices S and S have far more rows than columns. It follows that the size of theset of eigenvectors of K corresponding to its nonzero eigenvalues is at most N times the number of colors(input channels of each image). In practice, the effective rank r of the data matrices S and S and hence theoperator K , generically is even lower. The algorithm of the leading order rank approximation (rDMD) can be outlined as follows. Instead ofcomputing K in equation 3, we may project the latter onto its first r singular vectors. With Ur, r, Vr therank-r restricted singular value decomposition of S one can approximate the pseudo-inverse as S Ur r V r.Then the operator Kr can be defined as",
  "An Adaptive Color Invariant Layer": "In this section, we delve into the architecture of our color-invariant layer (CiL), offering a detailed technicaloverview. Subsequently, in section 3.1, we provide its theoretical underpinning. Central to CiL is the strategyof partitioning the image into patches, drawing parallels with vision transformers (Dosovitskiy et al., 2020).For each of these patches, we then compute the Singular Value Decomposition (SVD), or in some cases, themean over adjacent patches, as depicted in Figure (3). This approach is twofold: firstly, it minimizes thecomputational demands of SVD; secondly, it paves the way for achieving local color invariance. Conceptually, we divide color symmetries, both local and global, into three distinct mathematical categories(I)-(III). Very general invariance (I); (II) the model can in a self-supervised way learn a specific color spectrum",
  "Category I : W is the identity matrix i.e without any trainable parameters, equation 7 is invariantunder general orthogonal transformations": "Category II : For W SO3, i.e. in the general rotations group equation 7 is invariant under acontinuous one-parameter family of color transformations. For a given element in SO3 correspondsto a rotation in three-dimensional color space and the layer is symmetric w.r.t. any other orationalong the same axis. The specific axis is chosen by setting the three Euler angles i.e. independentparameters in W.",
  "CiL-Stack :S, SSi T Wij V (S)jk (8)": "where for notional simplicity we split S a color and stack dimension, and we have used Einstein summationconvention with i, j, k = 1, . . . , 3, and V (S) is computed via the SVD. We introduce trainable weights T whichare unconstrained an break the time-reversal symmetry of the expression equation 8; , , = 1, . . . , N 1.",
  "Proposition 2 (rDMD Symmetry Invariance). The rDMD approach equation 6 is invariant under left andright matrix multiplication by orthogonal L, R equation 5, respectively": "2We refer to 3-channel as the input color-channels which are duplicated in our layer.3As for color-channels V and Vr are mostly identical we use them synonymously from here one.4The expression in the parenthesis in proposition (1) refer to the case when we do not normalise V by its determinant. In thedefault case we use V V/det(V ).",
  ": Architecture diagram of CiL for N = 1, i.e. no frame stacking": "Controlling spatial and temporal symmetries of rDMD. Among other symmetries, equation 3 andequation 6 admit permutation invariance and general rotation of pixels as long as the operation acts oneach time step in the frame stack of input images alike, see Figure (4) (c) and (d). It is evident that thoseinvariances admit no practical use case. It is this desirable to remove those symmetries while keeping theuseful ones e.g. Figure (4) (b). In (Weissenbacher et al., 2024) recently a graph symmetric approach tosymmetry breaking in pixel data was discussed. We define",
  "Kbreakr= U r K Ur = U r G S T Vr 1r.(9)": "where G is the graph matrix discussed in (Weissenbacher et al., 2024) and is such thatG , R= G R R G =0 i.e. they commute if R is a simple left right rotation or flip of the patch. In particular, for general permutationof pixels in the patch they do not commute. The matrices G Rnn, T RNN and W R33 containtrainable weights. While we do not directly use equation 9 involving a graph matrix in this work our formalismcan be extended to include the latter.Proposition 3 (rDMD - Spatial Symmetry Breaking). Eq. (9) is invariant under left and right matrixmultiplication by orthogonal L, R equation 5, which commute with G. Be G Rn Rn is given by thesymmetric graph-matrix, i.e. entries have shared weights if the distance between patches is the same. Thenthe symmetries of rotations, flips are preserved while the symmetry of undesirable general pixel permutationsand orthogonal transformations is broken. Proposition 4 (CiL-Stack Imposing Time-order). By adding the weights T RNNof the frame stackversion of CiL equation 8 one imposes a time-ordering of the frames, i.e. one generally breaks the orthogonalsymmetries applied to the stack-dimension. 3.2On the importance of reducing an abundance of symmetryIn the previous section we have laid the theoretical basis of how specific symmetries of CiL may be broken. Inthis concluding section we informally highlight some of the findings of section 3.1. In Figure (4) we illustratepatch-wise and global transformation of spatial and color. We proof in the appendix C.2.4 that CiL is notinvraint under regional color changes Figure (4) (a). This property is crucial to be able to identify colorsensitive feature e.g. teh red vs green traffic light.",
  ": Modified lava-crossing environment overview and empirical evaluation of CiL. Comparison of CiL toColor-jitter and Random-conv data augmentation, the latter are detrimental for learning": "In Figure (4) (b) global color-transformations by distinct symmetric matrices L are shown. Global refer tothe choice of the local neighborhood of SVD in Figure (3) to be the entire image, i.e. the same V is theshared across all patches. In Figure (4) (c) and (d) we highlight patch-wise spatial transformation e.g. pixel-permutations and generalorthogonal transformation. Those result in apparent non-useful symmetry properties. A model with thosetoo abundant symmetries fails to learn relevant features necessary for the agent to navigate the environment. In , the different patch colors are for illustration only. The patches are not independent; the samecolor invariance is learned for each feature across all patches, as CiLs weights are shared among them. Onemight wonder if patch-wise color augmentation could yield similar results to CiL. However, empirical tests onMinigrid show that patch-wise augmentations, like global color augmentations, also fail to learn effectively.Additionally, to achieve the same invariance properties as CiL, the model would require an impractical numberof patch-wise augmentations, namely: (#local color augmentations)#patches.",
  ". optionally to point (1) we introduce berry-fields and crop-fields see Figure (6) upon collecting themthe agent receives a additional rewards": "Thus depending on the colors blue and orange of river vs. lava (purple and green of berries and crops) seeFigure (6) opposing actions need to be taken by the agent to successfully reach the green goal. In otherwords, this modified environment is an ideal test-ground for an agents ability of developing color-sensitivity,see Figure (10). Although MiniGrid setups are usually partially observable, we adjust ours for full observability and increasethe default observation size from 9 9 to 14 14 pixels. In particular, we render the environment andsubsequently down-scale it.The experiments with deep Q-learning (IMPALA (Espeholt et al., 2018)) focus ondifficulty level 1 of our modified Lava-crossing environment. We evaluated the CNN baseline against configurations using color-jitter or random-conv data augmentation.These methods were unsuccessful in learning the desired behavior as they hindered the agents capacity forcolor-sensitive decision-making. In contrast, when we incorporated CiL with the CNN for color-symmetrycategories I, II, and III, learning proceeded without obstruction. Refer to Figure (5b) for the training rewards.Our findings suggest that not only does CiL achieve inherent generalization, but it also equips the modelwith color-sensitive decision-making skills. Furthermore, Figure (5b) and (7a) illustrates the enhanced performance and sample efficiency of CiL +CNN, for both environment versions, respectively. Moreover, Figure (7b) shows improved color generalisationof CiL. Notably, this improvement is observed without any adjustments to the hyper-parameters of the RLalgorithm. Next, we extend the empirical results on our custom LavaCrossing environment and present evaluations ofpoint (2) below. We modify the environment5 by adding we introduce berry-fields as well as crop-fields uponcollecting them the agent receives additional rewards. In evaluating the performance of CiL on the environment option (2), which includes both berries and crops,we observe results that are consistent with those obtained in environment option (1). This can be seen inFigure (7a), which presents a visual representation of the findings.",
  "(b) Color Generalisation: rewards, averaged over 4 random seedsand 50 evaluation episodes; we plot the standard error bars,respectively. Augmentation parameter are from left to right asin": ": Empirical evaluation of CiL on modified lava-crossing environment (2) with berries and crops. Comparisonof CiL to color-jitter and random-convolution data-augmentation, the latter are detrimental for learning. Comparisonof Categories I vs. II, with feature-concatenated as the input of the CNN - I&II - and batch-concatenated i.e. usedsimultaneously - I II -. Both a and 7b show mean and standard error.",
  ": Modified Lava-crossing color variations for b visualizing the augmentation parameter from left toright [0, 1.8]": "When data-augmentation is applied, we notice a detrimental effect on the training process. This is in line withour observations from environment option (1), suggesting that data-augmentation might not be beneficial forthis specific task. Furthermore, we observe that the CiL category II demonstrates superior performance when compared tothe CNN baseline when no data augmentation is applied. This performance advantage is more pronouncedin environment option (2) than what was observed in environment option (1), as depicted in Figure (5b).This indicates that the benefits of using CiL category II become more evident when the complexity of theenvironment increases, showcasing its robustness and effectiveness in more challenging scenarios. We evaluate our trained models on a color varied version of the environment, see Figure (8); comparingCNN to CNN + CiL for categories I,II, and II, respectively. We find improved generalisation of CiL, seeFigure (7b).",
  "Procgen Benchmark & Distracted Deepmind Control suite": "We evaluate our model on both the Procgen generalization benchmark (Cobbe et al., 2020) which consistsof 16 procedurally generated environments with visual observations; as well as the Deepmind Control suite(DMControl) (Tassa et al., 2018) with additional visual background video distraction (Hansen & Wang, 2021). The Procgen benchmark consists of sixteen procedurally generated games. Each game corresponds to adistribution of partially observable Markov decision processes (POMDPs) q(m), and each level of a gamecorresponds to a POMDP sampled from that games distribution m q. The POMDP m is determinedby the seed (i.e. integer) used to generate the corresponding level. Following the setup from (Cobbe et al.,2020), agents are trained on a fixed set of n = 200 levels (generated using seeds from 1 to 200) and testedon the full distribution of levels (generated by sampling seeds uniformly at random from all computer",
  "integers).We evaluate our method with PPO/DrAC (Schulman et al., 2017; Raileanu et al., 2020) with addedcrop augmentation": "Moreover, we evaluate our method with SAC (Haarnoja et al., 2018) with standard hyper-parameter settings,and simply add CiL as a preliminary layer. To evaluate generalization of our method and baselines, we testmethods under challenging distribution shifts from by adding background videos (Hansen & Wang, 2021). Weprovide a proof-of-concept for CiLs ability to generalize to background videos in DMControl. This successfultest is significant to us, as SVD/DMD can be highly sensitive to dynamic changes introduced by backgroundvideos. The DMControl test demonstrates CiLs effective generalization to new data distributions relevantfor real-world tasks, rather than aiming to outperform state-of-the-art (SOTA) methods.",
  "First, CiL can scale to Procgen and DMC tasks": "Second, CiL may be simply added as a preliminary layer to existing architectures; across a varietyof domains and tasks and does not require any hyper-parameter tuning to achieve comparable - orimproved - generalisation performance. The performance gains are significant for environments wherecolor-sensitivity is required e.g. StarPilot and BigFish, in particular compared to rand-conv andcolor-jitter data augmentations.",
  "Third, the ablation study of CiL on Procgen finds that its performance is consistent across a widerange of settings": "In Figure (9), we juxtapose CiL with random-conv augmentations. Specifically for the Starpilot and Bigfishenvironments, the use of random-conv (Rand-FM) hinders learning. In contrast, CiL offers advantagesover both PPO and DrAC+ Crop, especially in these environments. This aligns with our main results where random-conv (as well as color-jitter) are added to DrAC. The training curves show comparablesample-efficiency of CiL, see Figure (11). The primary conclusion of the paper is that a mixture of different categories yields the best performance. Thegeneral principle is that by incorporating all categorieseach with distinct inductive biasesthe network isbetter equipped to select the most appropriate features.",
  "Limitations": "CiL is CPU extensive by employing SVD as existing GPU implementation of SVD barely bring speed-ups,and rather lead to bottle-necks. Repeating input data (refer to Figure (3)) to assign different symmetryweights across channels can be demanding in terms of memory and computation. Particularly, using SVDlocally in CiL increases runtime by a factor of 3-5 compared to the CNN baseline. This work serves as a",
  "AlgorithmModelStarPilotFruitBotBigFishCoinrunJumperAverage": "PPOCNN35.6%85.9%7.8%65.4%53.3%49.6%DrAC (Crop)CNN50.0%86.5%21.6 %64.5%52.4%55.0%DrAC (Crop+RandConv)CNN47.3%84.8%14.2%64.9%56.5%53.5%DrAC (Crop+ColorJitter)CNN52.2%85.9%13.4%64.9%53.8%54.1%DrAC (Crop+Conv&Jitter)CNN44.8%84.0%9.4%65.0%56.2%51.9%DrAC (Crop)CNN+CiL55.4%86.9%26.6%64.4%53.4%57.3%Rand-FMCNN10.1%79.7%-1.1%71.2%47.8%41.5% : Procgen ablation study comparing categories I, II, and III as well as different local neighborhood sizes.The superscript refers to the weight categories used in CiL. The subscript 1, 3, 5, refer to the size of the localneighborhood used to compute the SVD; where denotes the global CiL, i.e., the mean is computed over patches ofthe entire image.",
  "Related Work": "Symmetry is a prevalent implicit approach in deep learning for designing neural networks with establishedequivariances and invariances. The literature on symmetries in Vision Transformers (ViTs) (Fuchs et al.,2020; Romero & Cordonnier, 2021) is relatively limited compared to CNNs (Zhang & Sejnowski, 1988; LeCunet al., 1989; Zhang, 1990), recurrent neural networks (Rumelhart et al., 1986; Hochreiter & Schmidhuber,1997), graph neural networks (Maron et al., 2019; Satorras et al., 2021), and capsule networks (Sabour et al.,2017). Permutation invariance in ViTs and attention mechanisms has been examined in (Lee et al., 2019),demonstrating improved out-of-distribution generalization in RL from pixel data (Tang & Ha, 2021). CiLmay be added on top of ViTs as well as CNNs.",
  "Conclusions": "In the context of reinforcement learning, we introduced CiL, a neural network layer capable of self-supervisedadaptation to various color symmetries. Empirical evaluations show that CiL outperforms both random-convand color-jitter data augmentations in environments where color sensitivity is pivotal. Furthermore, CiLmaintains performance in other environments without necessitating hyperparameter tuning for the associatedRL algorithms.",
  "Impact Statement": "This paper presents work whose goal is to advance the field of Machine Learning. There are many potentialsocietal consequences of our work. In particular, while improved color-sensitivity while maintaining color-generalisation is desirable for many tasks , there are risks, such as an agent learning to make decisions basedon an individuals skin color. However, we conclude that such a behavior would likely arise from biases in thetraining dataset or environment, rather than from our method itself. Matthias Weissenbacher would like express his gratitude to Rishabh Agarwal (Deepmind) for initial collabo-ration and helpful comments on the draft. And, we would like to thank Y. Nishimura for technical support.This work was supported by JSPS KAKENHI Grant Number JP22H00516 and JP22H05106 JST CRESTGrant Number JPMJCR1913. Rishabh Agarwal, Marlos C Machado, Pablo Samuel Castro, and Marc G Bellemare. Contrastive behavioralsimilarity embeddings for generalization in reinforcement learning. arXiv preprint arXiv:2101.05265, 2021. Ravindran Balaraman and G. Barto Andrew. Approximate homomorphisms: A framework for non-exactminimization in markov decision processes. In In International Conference on Knowledge Based ComputerSystems, 2004.",
  "Buc, E. Fox, and R. Garnett (eds.), Advances in Neural Information Processing Systems, volume 32. CurranAssociates, Inc., 2019": "Maxime Chevalier-Boisvert, Dzmitry Bahdanau, Salem Lahlou, Lucas Willems, Chitwan Saharia, Thien HuuNguyen, and Rmi Lebret. Babyai: First steps towards grounded language learning with a human in theloop. International Conference on Learning Representations, 2019. Karl Cobbe, Chris Hesse, Jacob Hilton, and John Schulman. Leveraging procedural generation to benchmarkreinforcement learning. In Hal Daum III and Aarti Singh (eds.), Proceedings of the 37th InternationalConference on Machine Learning, volume 119 of Proceedings of Machine Learning Research, pp. 20482056.PMLR, 1318 Jul 2020.",
  "Taco S. Cohen, Mario Geiger, Jonas Khler, and Max Welling. Spherical cnns. In International Conferenceon Learning Representations (ICLR), 2018": "Benjamin Coors, Martin Roser, and Andreas Geiger. Spherenet: Learning spherical representations fordetection and classification in omnidirectional images. In Proceedings of the European Conference onComputer Vision (ECCV), 2018. Alexey Dosovitskiy, Lucas Beyer, Alexander Kolesnikov, Dirk Weissenborn, Xiaohua Zhai, Thomas Unterthiner,Mostafa Dehghani, Matthias Minderer, Georg Heigold, Sylvain Gelly, Jakob Uszkoreit, and Neil Houlsby.An image is worth 16x16 words: Transformers for image recognition at scale, 2020. Lasse Espeholt, Hubert Soyer, Remi Munos, Karen Simonyan, Volodymyr Mnih, Tom Ward, Yotam Doron,Vlad Firoiu, Tim Harley, Iain Dunning, et al. Impala: Scalable distributed deep-rl with importanceweighted actor-learner architectures. arXiv preprint arXiv:1802.01561, 2018. Fabian Fuchs, Daniel Worrall, Volker Fischer, and Max Welling. Se(3)-transformers: 3d roto-translationequivariant attention networks.In H. Larochelle, M. Ranzato, R. Hadsell, M.F. Balcan, andH. Lin (eds.), Advances in Neural Information Processing Systems, volume 33, pp. 19701981. Cur-ran Associates, Inc., 2020. URL Tuomas Haarnoja, Aurick Zhou, Pieter Abbeel, and Sergey Levine. Soft actor-critic: Off-policy maximumentropy deep reinforcement learning with a stochastic actor. In Jennifer Dy and Andreas Krause (eds.),Proceedings of the 35th International Conference on Machine Learning, volume 80 of Proceedings of MachineLearning Research, pp. 18611870. PMLR, 1015 Jul 2018.",
  "G. Strang. Introduction to Linear Algebra. Wellesley-Cambridge Press, Wellesley, MA, 3 edition, 2003": "Yujin Tang and David Ha. The sensory neuron as a transformer: Permutation-invariant neural networks forreinforcement learning. In A. Beygelzimer, Y. Dauphin, P. Liang, and J. Wortman Vaughan (eds.), Advancesin Neural Information Processing Systems, 2021. URL Yuval Tassa, Yotam Doron, Alistair Muldal, Tom Erez, Yazhe Li, Diego de Las Casas, David Budden, AbbasAbdolmaleki, Josh Merel, Andrew Lefrancq, Timothy P. Lillicrap, and Martin A. Riedmiller. Deepmindcontrol suite. CoRR, abs/1801.00690, 2018. URL",
  "Denis Yarats, Ilya Kostrikov, and Rob Fergus. Data-efficient reinforcement learning with momentum predictiverepresentations. In International Conference on Learning Representations, 2021a": "Denis Yarats, Ilya Kostrikov, and Rob Fergus. Image augmentation is all you need: Regularizing deepreinforcement learning from pixels. In International Conference on Learning Representations, 2021b. URL Denis Yarats, Rob Fergus, Alessandro Lazaric, and Lerrel Pinto. Mastering visual continuous control: Improveddata-augmented reinforcement learning. In International Conference on Learning Representations, 2022.URL Kun Zhang. Interpreting the internal vector representation of an analogical neural network. In Proceedings ofthe 12th annual conference of the Cognitive Science Society, pp. 684691. Lawrence Erlbaum Associates,1990.",
  "In evaluating the performance of CiL on the environment option (2), which includes both berries and crops,we observe results that are consistent with those obtained in environment option (1)": "When data-augmentation is applied, we notice a detrimental effect on the training process. This is in line withour observations from environment option (1), suggesting that data-augmentation might not be beneficial forthis specific task. Furthermore, we observe that the CiL category II demonstrates superior performance when compared tothe CNN baseline when no data augmentation is applied. This performance advantage is more pronouncedin environment option (2) than what was observed in environment option (1), as depicted in Figure (5b).This indicates that the benefits of using CiL category II become more evident when the complexity of theenvironment increases, showcasing its robustness and effectiveness in more challenging scenarios.",
  "B.1.1SO(3) group - Category II": "The group SO(3) represents the group of rotations in three dimensions, and any rotation in this group canbe represented using three Euler angles. Euler angles are three angles introduced by Leonhard Euler todescribe the orientation of a body/vector. They can describe arbitrary rotations in three dimensions. Thethree rotations are often referred to as roll, pitch, and yaw, especially in the context of aviation and robotics. Any element of SO(3), i.e., any rotation matrix, can be expressed in terms of Euler angles. There aremultiple sequences of axes about which the rotations can take place (like \"XYZ\", where the rotation is firstabout X, then about Y, and lastly about Z), and the choice of sequence can change the specific angles.",
  "Roll (): 0 < 2": "We employ the definition equation 10 to incorporate SO(3) rotation of color-space i.e. category II, where theEuler angles are given by three trainable weights. the bounds are enforces by using the Tangent-Hyperbolicfunction e.g. 0 < 2 by = + Tanh(), where is a trainable parameter. 7Note: While Euler angles are intuitive, they are not without problems. The most notorious one is \"gimbal lock,\" whereyou lose one degree of freedom, and its not possible to represent all 3D orientations. This is why other representations likequaternions are sometimes preferred in applications like computer graphics and robotics.",
  "B.1.3Numerical Invariance: torch.svd": "In our implementation, we have opted for torch.svd over torch.linalg.svd for computing the singularvalue decomposition (SVD). Our extensive testing indicates that torch.svd offers superior stability inmaintaining invariance under orthogonal transformations of the input, denoted as R and L. However, it is important to highlight that numerical algorithms like SVD are prone to challenges associatedwith sign ambiguity. This means that the columns of the output matrices can undergo multiplication by 1.To tackle this issue and achieve consistent results, we employ torch.abs on the results of equations 7 and8. This step is imperative to address the sign ambiguity introduced by torch.svd, ensuring that the finaloutput is consistent and unaffected by potential sign changes. In essence, the adoption of torch.svd and the application of torch.abs contribute to the stability andreliability of our implementation, especially in scenarios involving orthogonal transformations of the input.",
  "maximal reward minimal reward": "8We incorporate symmetric matrices in our work which is not to be confused with a related concept to orthogonal groups thesymmetric group. The symmetric group on three elements, often denoted S3, is a mathematical structure that encapsulatesall possible permutations of three distinct objects. This group has 3! (i.e., 6) distinct elements, each representing a uniquepermutation. When considering matrices, a natural representation of S3 is as 3 3 permutation matrices where each matrix hasa single 1 in every row and column, with all other entries being 0. Each of these matrices represents a permutation of thestandard basis vectors in R3. All permutations are orthogonal thus S3 is a sub-group of SO(3).",
  "S = UV": "where U, V are unitary matrices and is rectangular diagonal with non-negative entries on its diagonal.Given S, such a decomposition need not be unique, however the matrix is unique up to an ordering of itsdiagonal entries (singular values of S). We will consider singular value decompositions where the diagonalentries of appear in descending order. Then, for any r > 0 we define Ur to be the matrix formed by thefirst r columns of U (also known as the modes).",
  "Proof: The point (1) above follows as a consequence of the discussions in section (C.1)": "The proof of point (2) and (3) of proposition (1) builds on point (1) thereof, i.e. by adding respectiveweights W to preserve specific symmetries and break others. Firstly, for claim (2) note that symmetries Lare preserved if and only if they commute with W SO(3) i.e. [W, L] = W L L W = 0. Where L acts onthe input S S L thus",
  "as L is orthogonal i.e. L LT = LT L = 1 the expression above is invariant if and only if the claim ofcommutativity between W and L holds": "Note that any real orthogonal 3 3 matrix W SO(3) may be decomposed as W = UU 1 with one realand a pair of two complex conjugate eigen-values all lying on the unit disk (Strang, 2003). Thus the realeigen-values are either {+1, 1} and the complex ones are {a+i b, ai b}, a, b R s.t. a2 +b2 = 1. Moreover,invertible normal matrices (such as W and L ) commute if they have a shared set of eigen-vectors, i.e. theyshare the same eigen-decomposition but for different eigen-values i.e. L = ULU 1. We normalize the network to symmetries with determinant of {+1} by adding to the layer V V/det(V ).Moreover, due to the constraint of lying of the eigenvalues on the unit disk only one independent parameterremains in L i.e. is not fixed by the constraint of commuting with W. This free parameter in choosing Lconstitutes the one-parameter family of symmetries which is preserved - category II symmetry type-. The argument for claim (3) of proposition (1) is analog to the one for claim (2). With the difference thatnow W is a symmetric matrix. Any real symmetric matrix can be written as W = UU T for an orthogonalU, which is referred to as the Spectral Theorem (Strang, 2003). Since U is real the eigenvalues of L areconstraint to {+1, 1} and the additional constrain of determinant one, results in the following four choicesfor L: diag(+1, 1, 1), diag(1, +1, 1), diag(1, 1, +1), diag(1, 1, 1). The latter is the identity matrix.If we allow Ls with determinant of either {+1, 1} then one obtains eight different choices for L. As weomit plus/minus the identity matrix this results in 3 (6) choices for L - category III -.",
  "This concludes the proof of proposition (1)": "Proof of proposition (4).Let an orthogonal transformation L act on the input S S L and S S L onearrives at equation 20, where we use Einstein summation convention i, j, k = 1, . . . , 3 and , . . . , = 1 , . . . , Nand where L1, L2 are orthogonal matrices transforming the color and stack dimension, respectively. Anyorthogonal L may be decomposed in L1, L2. The proof for L1 is the same as for proposition (1). As wechoose T RNN to be generic the symmetry w.r.t. the orthogonal L2 is broken as a general matrix does",
  "C.2.3Rotations, flips, patchwise pixel permutations and multiplications and invertible color changes": "Let us discuss the invariance of equations (6). By the above Remark and Propositions 5 and 6, 1, 2 and Krare invariant under rotations, flips, patchwise pixel permutations and, more generally, patchwise multiplicationsby an orthogonal matrix R. The functions 1 and kr are also invariant with respect to invertible color changes.",
  "S=(st1, st1, st1, st2, st2, st2, . . . , stN , stN , stN )": "Since 1 is invariant under matrix row permutations (Proposition 5), we may assume without loss of generalitythat the color changes apply to a fixed number k of rows in bottom of the matrix S, while the rest of therows above them are unchanged. In other words, we can define the regional color change operation",
  "S1S2 L": "where the matrix S1 R(nk)3N is the upper part of S, the matrix S2 Rk3N is the lower part of S and Lis an arbitrary diagonal 3N 3N matrix, which acts by scaling the RGB channels of the fixed regions in thesequence of images represented by matrix S2 (the notation here refers to ordinary matrix multiplication).",
  "(I + L2)1| L (I + L2)1": "so we see that this implies equation 22. From equation 22 we see that the set of eigenvalues of regL(S) (regL(S)) is not independent of L; indeed, if that were the case then the trace of the above matrix (i.e. thesum of its eigenvalues) would be the same for all L. However,",
  "Claim 2. The matrix Kr in equation 6 is in general, not invariant under regL": "Proof. Let us choose S, S satisfying the assumptions of the proof of Claim 1. Let us also consider the casewhere r is the full rank of S, so that Kr = K = SS. Let (U, , V ) be a singular value decomposition of S.Further let (UL, L, VL) be a singular value decomposition of regL(S), that is the transformation of S under"
}