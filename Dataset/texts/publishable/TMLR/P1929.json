{
  "Abstract": "Uncertainty quantification and robustness to distribution shifts are important goals in ma-chine learning and artificial intelligence. Although Bayesian Neural Networks (BNNs) allowfor uncertainty in the predictions to be assessed, different sources of predictive uncertaintycannot be distinguished properly.We present Credal Bayesian Deep Learning (CBDL).Heuristically, CBDL allows to train an (uncountably) infinite ensemble of BNNs, using onlyfinitely many elements. This is possible thanks to prior and likelihood finitely generatedcredal sets (FGCSs), a concept from the imprecise probability literature. Intuitively, convexcombinations of a finite collection of prior-likelihood pairs are able to represent infinitelymany such pairs. After training, CBDL outputs a set of posteriors on the parameters ofthe neural network. At inference time, such posterior set is used to derive a set of predic-tive distributions that is in turn utilized to distinguish between (predictive) aleatoric andepistemic uncertainties, and to quantify them. The predictive set also produces either (i)a collection of outputs enjoying desirable probabilistic guarantees, or (ii) the single outputthat is deemed the best, that is, the one having the highest predictive lower probability another imprecise-probabilistic concept. CBDL is more robust than single BNNs to priorand likelihood misspecification, and to distribution shift. We show that CBDL is better atquantifying and disentangling different types of (predictive) uncertainties than single BNNsand ensemble of BNNs. In addition, we apply CBDL to two case studies to demonstrate itsdownstream tasks capabilities: one, for motion prediction in autonomous driving scenarios,",
  "Introduction": "One of the greatest virtues an individual can have is arguably being aware of their own ignorance, and actingcautiously as a consequence. Similarly, an autonomous system using neural networks (NNs) would greatlybenefit from understanding the probabilistic properties of the NNs output (for example, its robustness todistribution shift), in order to incorporate them into any further decision-making. This paper collocates onthe path of giving a machine such a desirable quality. In the last few years, there has been a proliferation of work on calibrating (classification) NNs, in order toestimate the confidence in their outputs (Guo et al., 2017) or to produce conformal sets that are guaranteedto contain the true label, in a probably approximately correct (PAC) sense (Park et al., 2020). While suchmethods are a promising first step, they require a calibration set (in addition to the original training set)and cannot be directly used on Out-Of-Distribution data without further examples. Bayesian Neural Networks (BNNs) offer one approach to overcome the above limitations. The Bayesianparadigm provides a rigorous framework to analyze and train uncertainty-aware neural networks, and moregenerally to support the development of learning algorithms (Jospin et al., 2022). In addition, it overcomessome of the drawbacks of deep learning models, namely that they are prone to overfitting, which adverselyaffects their generalization capabilities, and that they tend to be overconfident about their predictions whenthey provide a confidence interval. BNNs, though, are trained using a single prior, which may still sufferfrom miscalibration and robustness issues (Lenk & Orme, 2009). In this work we introduce Credal Bayesian Deep Learning (CBDL), a procedure that draws on conceptsfrom the imprecise probability (IP) literature (Augustin et al., 2014; Troffaes & de Cooman, 2014; Walley,1991). Unlike other techniques in the fields of artificial intelligence (AI) and machine learning (ML) involvingimprecise probabilities that typically only focus on classification problems CBDL can be used for bothclassification and regression. It captures the ambiguity the designer faces when selecting which prior tochoose for the parameters of a neural network, and which likelihood distribution to choose for the trainingdata at hand. CBDL can be thought of as a NN trained using prior and likelihood finitely generated credal sets (FGCSs),Pprior and Plik, respectively.1 They are convex sets of probability measures having finitely many extremeelements (the elements that cannot be written as a convex combination of one another), exPprior and exPlik,respectively (see also Remark 2). A very simple example of a prior FGCS Pprior is the collection of all theconvex combinations of two one-dimensional Normal distributions N(1, 21) and N(2, 22), i.e.,",
  "Consequently, in this toy example we have that exPprior = {N(1, 21), N(2, 22)}.FGCSs are furtherexamined in section 2.2": "Given the use of finitely generated credal sets, CBDL can also be seen as a non-condensed (uncountably)infinite ensemble of BNNs each BNN corresponding to a pair (P, L) of prior P from the prior FGCSPprior and likelihood L from the likelihood FGCS Plik. Such infinite ensemble, though, is carried out usingonly finitely many elements, that is, only pairs (P ex, Lex) of components of the sets of extreme elementsexPprior and exPlik. This because every element P of Pprior can be obtained from a convex combinations ofthe elements of exPprior, and similarly for the likelihood FGCS. After training, CBDL produces a posteriorFGCS Ppost on the parameters of the neural network. At inference time, Ppost is used to derive a predictiveFGCS Ppred, that is, given a new input, a set of plausible distributions over the space of outputs.2 In turn, 1Intuitively, the larger these credal sets, the higher prior and likelihood ambiguity the user faces.2As we shall see in section 3.1, since computing the posteriors and the predictive distributions is oftentimes an intractableproblem, we approximate the elements of Ppost and of Ppred using Variational Inference (VI). As a consequence, we denote theVI-approximated posterior and predictive credal sets as Ppost and Ppred, respectively.",
  "Published in Transactions on Machine Learning Research (10/2024)": "Let now X = L1A. Notice that since Lcois weak-compact, by equation 4 so is L . This implies thatL, L L , since a compact set always contains its boundary, so L X as well, and in turn L1A X . Fixthen any L L and put h = L1A. It is immediate to see that h is non-negative and upper semi-continuous.Then, by equation 8, we have that for all > 0supP Pco",
  "Background and Preliminaries": "In this section, we present the background notions that are needed to understand our main results.Insection 2.1 we introduce Bayesian Neural Networks. .2 discusses (finitely generated) credal sets,upper and lower probabilities, and imprecise highest density regions. .3 introduces the concepts ofupper and lower entropy, which are used to quantify and disentangle AU and EU. The reader familiar withthese concepts can skip to section 3.",
  "Bayesian Neural Networks": "In line with the recent survey on BNNs by Jospin et al. (2022), Bayes theorem can be stated as P(H | D) =[P(D | H)P(H)]/P(D) = P(D, H)/P(D, H)dH, where H is a hypothesis about which the agent holdssome prior beliefs, and D is the data the agent uses to update their initial opinion. Probability distributionP(D | H) represents how likely it is to observe data D if hypothesis H were to be true, and is calledlikelihood, while probability distribution P(H) represents the agents initial opinion around the plausibility 4Once again, as we shall see in section 3.1, we approximate the elements of the posterior and the predictive credal sets usingVariational Inference (VI).5We note in passing how recently Mucsnyi et al. (2024) show that (finite) deep ensembles are the current state-of-the-artmethods for quantifying and disentangling different types of uncertainties on ImageNet. Our experiments show that CBDLimproves on (finite) ensembles of BNNs, both in uncertainty quantification and disentanglement, and in downstream tasksperformances. Together with the findings in Mucsnyi et al. (2024), this is an additional argument in favor of the effectivenessof our methodology.",
  "p(Dy | Dx, )p()d p(Dy | Dx, )p()": "Notice that the equality comes from having assumed Dx . Posterior density p( | D) is typically highdimensional and highly nonconvex (Izmailov et al., 2021c; Jospin et al., 2022), so computing it and samplingfrom it is a difficult task. The first issue is tackled using Variational Inference (VI) procedures, while MarkovChain Monte Carlo (MCMC) methods address the second challenge. Both are reviewed in the context ofmachine learning in Jospin et al. (2022, Section V), where the authors also inspect their limitations. BNNscan be used for both regression and classification (Jospin et al., 2022, Section II); besides having a solidtheoretical justification, there are practical benefits from using BNNs, as presented in Jospin et al. (2022,Section III). Suppose now we collect a new input x of interest, and that we want to predict its correct output y. Then, theposterior distribution p( | D) over the network parameters comes to the rescue, as it allows us to computethe so-called posterior predictive distribution,",
  "p(y | x, )p( | D)d = Ep(|D)[p(y | x, )],": "where p(y | x, ) is the model distribution we specified before. Posterior predictive p(y | x, D) tells us howlikely output y is to be the correct one for input x, given the knowledge encapsulated in the data D wecollected, which enters the computation via the posterior probability p( | D). Let us add a remark here:oftentimes, scholars claim that, in a Bayesian setting, the distribution on the parameters captures theepistemic uncertainty (EU) faced by the agent. This is a somehow agreeable premise, akin to a second-orderdistribution reasoning. If we accept this assertion, though, we see how EU at the predictive level is not",
  "As CBDL is rooted in the theory of imprecise probabilities (IPs), in this section we give a gentle introductionto the IP concepts we will use throughout the paper": "CBDL is based on the Bayesian sensitivity analysis (BSA) approach to IPs, that in turn is grounded inthe dogma of ideal precision (DIP) (Berger, 1984), (Walley, 1991, .9). The DIP posits that in anyproblem there is an ideal probability model which is precise, but which may not be precisely known. We callthis condition ambiguity (Ellsberg, 1961; Gilboa & Marinacci, 2013). Facing ambiguity can be represented mathematically by a set Pprior of priors and a set Plik of likelihoodsthat seem plausible or fit to express the agents beliefs on the parameters of interest and their knowledgeof the data generating process (DGP). Generally speaking, the farther apart the boundary elements of thesets (i.e., their infimum and supremum), the higher the agents ambiguity. Of course, if Pprior and Plik aresingletons we go back to the usual Bayesian paradigm. A procedure based on sets Pprior and Plik yields results that are more robust to prior and likelihood mis-specification than a regular Bayesian method. In the presence of prior ignorance and indecisiveness aboutthe sampling model, it is better to give answers in the form of intervals or sets, rather than arbitrarily selecta prior and a likelihood, and then update. Sets Pprior and Plik allow to represent indecision, thus leading toless informative but more robust and valid conclusions. Remark 2. Throughout the paper, we denote by = {P1, . . . , Pk}, k N, a finite set of probabilities ona generic space , such that for all j {1, . . . , k}, Pj cannot be written as a convex combination of theother k 1 components of . We denote by its convex hull Conv(), i.e., the set of probabilitiesQ on that can be written as Q(A) = kj=1 jPj(A), for all A , where the js are elements of that sum up to 1. In the literature, it is referred to as a Finitely Generated Credal Set (FGCS, Levi (1980);Cozman (2000b)). Notice then that the extreme elements of correspond to the elements of , in formulasex = . Simple graphical representations of finitely generated credal sets are given in Figures 1 and 2.",
  "P({3})": ": Suppose we are in a 3-class classification setting, so = {1, 2, 3}. Then, any probability measure P on can be seen as a probability vector. For example, suppose P({1}) = 0.6, P({2}) = 0.3, and P({3}) = 0.1. Wehave that P (0.6, 0.3, 0.1). Since its elements are positive and sum up to 1, probability vector P belongs to theunit simplex, the purple triangle in the figure. Then, we can specify = {P1, . . . , P5}, and obtain as a consequencethat = Conv() is the orange pentagon. It is a convex polygon with finitely many extreme elements, and it is thegeometric representation of a finitely generated credal set. Let us now introduce the concepts of lower and upper probabilities. The lower probability P associated with is given by P(A) = infP P(A), for all A . The upper probability P associated with is defined asthe conjugate to P, that is, P(A) := 1 P(Ac) = supP P(A),7 for all A . These definitions hold evenif is not finite. Then, we have the following important result.",
  "----------": ": In this figure, a replica of Flint et al. (2017, ), = {P1, P2}, where P1 and P2 are two Normaldistributions whose probability density functions (pdfs) p1 and p2 are given by the dashed blue and brown curves,respectively. Their convex hull is = Conv() = {Q : Q = P1 + (1 )P2, for all }. The pdf q of anelement Q of is depicted by a solid black curve. In addition, let A = [0.8, 0.4]. Then, P(A) = 0.4",
  "p1()d": "Definition 4 holds also if = ex is not finite.Notice that condition 2 is needed so that IR() isthe subset of having the lowest possible cardinality, which still satisfies condition 1. By the definitionof lower probability, Definition 4 implies that P [{ IR()}] 1 , for all P . Here lies theappeal of the IHDR concept. Let us give a simple example, borrowed from Caprio et al. (2024a). Suppose = {1, . . . , 5}, = {P1, P2, P3}, and = 0.1. The numerical values for Ps({j}) are given in , for all s {1, 2, 3} and all j {1, . . . , 5}. Then, from Proposition 3 and Definition 4, we have thatIR() = {1, 2, 3}.",
  "pj()": ": The 0.25-HDR from a Normal Mixture density. This picture is a replica of Hyndman (1996, ).The geometric representation of 75% probability according to Pj is the area between the pdf curve pj() and thehorizontal bar corresponding to p0.25j. A higher probability coverage (according to Pj) would correspond to a lowerconstant, so pj < p0.25j, for all < 0.25. In the limit, we recover 100% coverage at p0j = 0. As we mentioned earlier, an operative way of obtaining IHDR IR() is by putting IR() = kj=1R(Pj).Thanks to Proposition 3, by taking the union of the HDRs, we ensure that all the probability measures inthe credal set = Conv() assign probability of at least 1 to the event { IR()}. In turn, thisimplies that P[{ IR()}] = minj{1,...,k} Pj[{ IR()}] 1 . We also have that the differencebetween the upper and lower probabilities of { IR()} is bounded by . To see this, notice thatP[{ IR()}] 1, so P[{ IR()}] P[{ IR()}] .",
  "log[p()]P(d) if is uncountable, where p denotes the pdf of P. If is atmost countable, we have that H(P) =": "P({}) log[P({})]. As pointed out by Dubois & Hllermeier(2007); Hllermeier & Waegeman (2021), the entropy primarily captures the shape of the distribution, namelyits peakedness or non-uniformity, and hence informs about the predictability of the outcome of a randomexperiment: the higher its value, the lower the predictability. Then, we can define the imprecise versionsof the Shannon entropy as proposed by Abelln et al. (2006); Hllermeier & Waegeman (2021), H(P) :=supP H(P) and H(P) := infP H(P), called the upper and lower Shannon entropy, respectively.10 Notice that these definitions hold for all sets of probabilities, not just for (finitely generated) credal sets.The upper entropy is a measure of total uncertainty since it represents the minimum level of predictabilityassociated with the elements of . In Abelln et al. (2006); Hllermeier & Waegeman (2021), the authors",
  ",": "where TU() denotes the total uncertainty associated with set , AU() is the AU associated with , andEU() represents the EU associated with . As we can see, if is a singleton, then TU() = AU(),and EU() = 0. This captures the idea that, in general, a single distribution can only gauge aleatoricuncertainty.11 We have the following proposition.",
  "Proposition 6. Let , be sets of probability measures as the ones considered in Remark 2.Then,supP H(P) = H(P) H(P ) = supP H(P ) and infP H(P) = H(P) = H(P ) = infP H(P )": "Proposition 6 tells us that the upper entropy of the extreme elements in = ex is a lower bound forthe upper entropy of the whole credal set , and that the lower entropy of the extreme elements in isequivalent to the lower entropy of the whole credal set . These facts imply that AU() = AU(), andthat EU() EU(). In addition, as a consequence of (Smieja & Tabor, 2012, Theorem III.1), we havethat EU() EU() + log(#). In turn, we have that EU() [EU(), EU() + log(#)]. We briefly mention that other uncertainty measures based on credal sets are also available (see Bronevich &Rozenberg (2021); Hofman et al. (2024); Hllermeier & Waegeman (2021) or Appendix E for a few examples)and they can be used in place of upper and lower entropy12 to quantify EU and AU within our credal regionP, as long as the measure chosen for the total uncertainty is bounded. Let us also add a small remark. Although EU can be reduced with an increasing amount of data, it is veryseldom the case that it goes to zero when a finite amount of data is collected. When that happens, it meansthat the initial uncertainty was very low in the first place. Typically, EU goes to zero only asymptotically,as a finite amount of data is almost never enough to overcome initial uncertainty (Walley, 1991; Wimmeret al., 2023).",
  "CBDL algorithm": "Recall that D = Dx Dy denotes the training set, where Dx = {xi}ni=1 X is the collection of traininginputs, Dy = {yi}ni=1 Y is the collection of training outputs, and X and Y denote the input and outputspaces, respectively. We then denote by P a generic prior on the parameters of a BNN having pdf p,and by L Lx, a generic likelihood on the space Y of outputs having pdf x,. The act of computingthe posterior from prior P and likelihood L using a BNN is designated by post[P, L], and the act of derivingthe posterior predictive from posterior P( | D) and likelihood L is designated by pred[P( | D), L]. TheCBDL procedure is presented in Algorithm 1, and it is discussed in the following paragraphs. During training, in Step 1 the user specifies K priors on the parameters of the neural network, that constitutethe extrema exPprior of the prior FGCS Pprior. Similarly, in Step 2 they elicit S likelihoods capturing thepossible architectures of the neural network, that correspond to the extrema exPlik of the likelihood FGCSPlik. Let us give an example. Outlined in Jospin et al. (2022, Sections IV-B and IV-C1), for classification,the standard process for BNNs involves 11It can gauge EU, though, if it is a second-order distribution, or if it is the result of an ensemble of probabilities.12Which, although easy to compute, can sometimes suffer from shortcomings coming from lacking the monotonicity property.That is, there are credal sets that, although nested into each other, have the same upper and/or lower entropy (Hllermeier &Waegeman, 2021).",
  "Step 5 Compute and return AU( Ppred) and the bounds for EU( Ppred)Step 6 Compute and return the (1 )-IHDR IR( Ppred)": "A Normal prior with zero mean and diagonal covariance 2I on the coefficients of the network,that is, p() = N(0, 2I). In the context of CBDL, we could specify, e.g. exPprior = {P : p() =N(, 2I), {, 0, +}, 2 {3, 7}}. That is, the extreme elements of the prior credal set arefive independent Normals having different levels of fatness of the tails, and centered at a vector +having positive entries, a vector having negative entries, and a vector 0 having entries equal to0. They capture the ideas of positive bias, negative bias, and no bias of the coefficients, respectively.This is done to hedge against possible prior misspecification. A Categorical likelihood, p(y | x, ) = Cat((x)), whose parameter is given by the output of afunctional model .In the context of CBDL, we could specify the set of extreme elements ofthe likelihood credal set as exPlik = {L : x,(y) = Cat(s,(x)), s {1, . . . , S}}. Specifying setexPlik, then, corresponds to eliciting a finite number S of possible (parametrized) architectures forthe neural network s,, s {1, . . . , S}, and obtain, as a consequence, S categorical distributions{Cat(s,(x))}Ss=1. This captures the ambiguity around the true data generating process faced bythe agent, and allows them to hedge against likelihood misspecification.",
  "For example, for the choice of the priors we refer to Fortuin et al. (2021), where the authors study the problemof selecting the right type of prior for BNNs": "Step 3 performs an element-wise application of Bayes rule for all the elements of exPprior and exPlik. Eachposterior is approximated using the Variational Inference (VI) method (Jospin et al., 2022, Section V). Thatis, we project every posterior Pk,s( | D) onto a set S of well-behaved distributions (e.g. Normals) using theKL divergence. In formulas, Pk,s = arg minQS KL[QPk,s( | D)]. By well-behaved, we mean that theyhave to satisfy the conditions in Zhang & Gao (2020, Sections 2 and 3).14 This ensures that as the samplesize goes to infinity, the approximated posteriors converge to the true data generating process. We also pointout how despite using a VI approximation for the exact posteriors, as we shall see in the next section, thecredal set of approximated posteriors is closer to the oracle posterior P o( | D) than any of its elementstaken individually. As a consequence, working with credal sets leads to VI posterior approximations thatare better than the ones resulting from a single BNN, or an ensemble of BNNs, where several BNNs arecombined into one. Remark 7. Although highly unlikely in practice, it is theoretically possible that the VI approximation of the(finite) set {Pk,s( | D)}k,s of posteriors is a singleton, see . While the conditions in Zhang & Gao(2020) guarantee that asymptotically the approximated posteriors coincide with the true data generating pro-cess, this typically does not happen with finite-dimensional datasets. As a consequence, obtaining a singletonwhen projecting {Pk,s( | D)}k,s onto S may result in an underestimation of the uncertainties faced by theuser. In that case, we either consider a different set whose elements still satisfy the conditions in Zhang 13Choosing 2 to 5 priors and likelihoods is usually enough to safely hedge against prior and likelihood misspecification.14We assume that the conditions on the priors and the likelihoods given in Zhang & Gao (2020) are satisfied.",
  "P2( D)P3( D)": ": Let denote the space of probability measures on . Suppose that in the analysis at hand we specifiedthree priors and only one likelihood, so S = 1 and we can drop the s index. Let {Pk( | D)}3k=1 be the collection ofexact posteriors, so that the black segment represents the exact posterior FGCS. Then, if we project the elements of{Pk( | D)}3k=1 onto S1 via the KL divergence, we obtain the same distribution P. This is detrimental to the analysisbecause such an approximation underestimates the (posterior) epistemic (and possibly also aleatoric) uncertaintyfaced by the agent. Then, the user could specify a different set S2 of well-behaved distributions onto which projectthe elements of {Pk( | D)}3k=1. In the figure, we see that they are projected onto S2 via the KL divergence to obtainP1, P2, and P3. The convex hull of these latter, captured by the red shaded triangle, represents the variationalapproximation of the exact posterior FGCS. After Step 3, we obtain a finite set { Pk,s}k,s of VI approximation of the posteriors on the network parameters,whose cardinality is K S. Its convex hull constitutes Ppost, that is, the VI-approximated posterior FGCS.We assume that ex Ppost = { Pk,s}k,s.This is an assumption because it may well be that due to theapproximation procedure some of the elements of { Pk,s}k,s are not independent of one another. We deferto future work the design of a procedure that finds the elements of { Pk,s}k,s that cannot be written as aconvex combination of one another. Being a combinatorial task, Step 3 is a computational bottleneck of Algorithm 1. We have to calculateK S VI approximations to as many posteriors, but this allows us to forego any additional assumptions onthe nature of the lower and upper probabilities that are oftentimes required by other imprecise-probabilities-based techniques.15 Clearly, CBDL is simplified if either Pprior or Plik are singletons. Notice that in the case that Pprior and Plik are both not singletons, for all A the interval [ P(A), P(A)] is wider than the casewhen one or the other is a singleton. In the limiting case where both are singletons, we retrieve the usualBayesian updating, so the interval shrinks down to a point. Before moving to inference time, let us remark a difference between Bayesian Model Averaging (BMA) andCBDL. In BMA, the user specifies a distribution on the models. Translated in the notation we use in thiswork, this means having a discrete distribution Q over the K S prior-likelihood combinations, that is, overthe elements of ex Ppost. Such Q is then used to select an element P from the (VI-approximated) posteriorFGCS Ppost asPpost P =",
  "where Q({ Pk,s}) for all k and all s, and": "k,s Q({ Pk,s}) = 1 (Caprio & Mukherjee, 2023a). Forexample, if Q is the discrete uniform distribution on {1, . . . , K S}, then P is the so-called center ofgravity of the credal set Ppost (Miranda & Montes, 2023, .2). Instead, CBDL does not select aunique distribution from Ppost. Rather, distributions are kept separate so to be able to derive a predictiveFGCS in Step 4 of Algorithm 1, that is in turn used to quantify and disentangle predictive uncertainties,and to compute the predictive IHDR, that is, a collection of outputs having a high probability of being thecorrect ones for a new input x. During inference, a new input x is provided. In Step 4, every element of ex Ppost is used to derive a predictivedistribution P predk,s= pred[ Pk,s, Lexs ] on the output space Y. In particular, for every k and every s, the pdf",
  "exs (y | x, ) pk,s()d,": "where exsis the pdf of likelihood Lexs , pk,s is the pdf of the true posterior Pk,s( | D), pk,s is the pdf ofthe VI-approximated posterior Pk,s, and y is the output associated to the new input x (see Appendix Ffor more details). Each predictive distribution P predk,sis approximated to P predk,s(e.g. using Normals) via Variational Inference. The convex hull of the collection { P predk,s }k,s having cardinality K S constitutes theVI-approximated predictive FGCS Ppred. Similarly to what we did for ex Ppost, we assume that ex Ppred ={ P predk,s }k,s.",
  "andEU(Ppred) EU( Ppred) [H( P pred) H( P pred), H( P pred) H( P pred) + log(K S)],(3)": "where (i) H( P pred) = mink,s H( P predk,s ); (ii) H( P pred) = maxk,s H( P predk,s ); and (iii) Ppred is the truepredictive FGCS, that is, the one we would have obtained had we been able to compute the exact posteriorsin Step 3 and the exact predictive distributions in Step 4. Let us point out a salient feature of CBDL.The AU and the (bounds for) the EU associated with the VI-approximated predictive FGCS Ppred embeduncertainty comparable to an uncountably infinite ensemble of BNNs, i.e., an ensemble of BNNs of cardinality1, despite the simple and intuitive mathematics over the finite set ex Ppred. They are not merely pessimisticresults on the uncertainties associated with a finite ensemble of BNNs. We observe that we compute the AU and EU associated with the (VI-approximated) predictive credal setPpred, rather than those related to the (VI-approximated) posterior credal set Ppost. We do so because weare ultimately interested in reporting the uncertainty around the predicted outputs given a new input in theproblem at hand, more than the uncertainty on the parameters of the NN. Before commenting on the next step, let us pause here and add a remark. While a bad choice of priorsand likelihoods may lead to large values of upper and lower entropy H( P pred) and H( P pred), respectively this is not a risk confined to our procedure. Poor modeling choices are an unavoidable risk in model-basedtechniques. This gave rise to the famous adage by George Box essentially, all models are wrong but someare useful (Box, 1976).16 We maintain that our method is indeed useful, since it overcomes some of theshortcomings of traditional Bayesian techniques as explained in Appendices A and B. As for regularBayesian methods, though, for our approach too the designer will need to make plausible choices for priors 16Curiously, a similar motivation was brought forward by Pseudo-Dionysius the Areopagite in favor of the use of sacredimages in the Christian tradition (Migne, 1857). While they do not capture the essence of God, these defective approximationshelp the believers thought to elevate.",
  "Let be an FGCS as in Remark 2, and consider a probability measure such that": "Proposition 8. Call d any metric and div any divergence on the space of probability measures of interest.Let d(, ) := infP d(P , ) and div() := infP div(P ). Then, for all P , d(, ) d(P , ) and div(, ) div(P ). Proposition 8 holds if is any set of probabilities, not just an FGCS.17 In Appendix I, we show thatthe above result still holds if the elements of and are defined on Euclidean spaces having differentdimensions (Cai & Lim, 2022; Caprio, 2022). Let us now apply Proposition 8 to CBDL. Suppose that, when designing a single BNN, an agent chooseslikelihood L, while when implementing CBDL, they specify in Step 2 a finite set of likelihoods exPlik ={Lexs }Ss=1, S 2, and then let the induced credal set Plik = Conv(exPlik) represent their uncertainty around",
  "d(L, Lo)": ": CBDL is more robust to distribution shifts than single BNNs. Here Plik is the convex hull of five plausiblelikelihoods, and d denotes a generic metric on the space Y of probabilities on Y. We see how d(Plik, Lo) < d(L, Lo);if we replace metric d by a generic divergence div, the inequality would still hold. Let us add a remark here. Assume that the oracle prior P o is in the prior credal set Pprior and thatthe oracle likelihood Lo is in the likelihood credal set Plik. Then, it is immediate to see that the oracleposterior P o( | D) belongs to the posterior credal set Ppost. Naturally, this does not imply that the posteriorcredal set collapses to P o( | D). In general, it is unlikely that a finite amount of data is able to completelyannihilate all the epistemic uncertainty faced by the agent. What may happen is that if the training set islarge enough, Ppost may be inscribed in a ball of small radius around P o( | D). This does not mean thatwe suffer from under-confidence due to larger-than-necessary epistemic uncertainty. Rather, the relativeepistemic uncertainty (measured by the difference between prior and posterior uncertainty, divided by theprior uncertainty) drops significantly. In addition, working with sets of prior and likelihoods allows us tohedge against prior and likelihood misspecification, a consequence of Proposition 8.",
  "Experiments": "From the previous sections, it is clear that CBDL improves on the uncertainty quantification capabilities ofsingle BNNs.18 CBDL allows a better quantification of predictive AU because of its robustness to misspeci-fication stemming from Proposition 8. In a sense, the predictive AU quantified by a single BNN is a functionof the choices of prior and likelihood made by the user. In addition, as we pointed out before (e.g. in thelast paragraph of section 2.1), predictive EU cannot be obtained in a theoretically principled manner froma single BNN (Hllermeier & Waegeman, 2021; Fellaji & Pennerath, 2024). Here, we show that these theoretical arguments are also backed by empirical evidence. In particular, in section4.1 we compare CBDL to the method proposed in Krishnan & Tickoo (2020), in which a single BayesianNeural Networks output is utilized to estimate both predictive epistemic and aleatoric uncertainties. Wealso show that CBDL improves on the ensemble of BNNs (EBNN) proposed in Cobb et al. (2019), that we",
  "(Predictive) Uncertainty Quantification": "Distribution shifts can introduce uncertainties in a system, which in turn can render the predictions mean-ingless. This can be due to naturally occurring corruptions, as introduced in Hendrycks & Dietterich (2019)for image datasets. The authors introduced 18 different noise types, which can be varied across 5 differentseverity levels, ranging from low (severity = 1), to medium (severity = 2, 3), and high (severity = 4, 5).The intuition is that in the current context, increasing the noise severity should generally result in higheruncertainty. We evaluate our CBDL method on 4 standard image datasets, CIFAR-10 (Krizhevsky et al.,2009), SVHN (Netzer et al., 2011), Fashion-MNIST (Xiao et al., 2017), and MNIST (Lecun et al., 1998).We use a slightly different set of perturbations than those introduced in Mu & Gilmer (2019) for gray-scaleimages like MNIST and Fashion-MNIST. Additionally, we perform cross domain testing for each dataset,where we expect the predictive uncertainties to be higher. We implement and train a Resnet-20 BayesianNeural Network model inside the library Bayesian-torch (Krishnan et al., 2019). For each dataset, we train4 different networks initialized with different seeds on the prior and with the same architecture. This cor-responds to eliciting a prior FGCS Pprior such that exPprior = {P ex1 , . . . , P ex4 }, so that K in Step 1 ofAlgorithm 1 is equal to 4, and a likelihood FGCS that is a singleton, Plik = exPlik = {L}, so that S in Step2 of Algorithm 1 is equal to 1. We use a learning-rate of 0.001, batch-size of 128, and train the networksusing Mean-Field Variational Inference for 200 epochs. The inference is carried out by performing multipleforward passes through parameters drawn from the posterior distribution. We used 20 Monte-Carlo samplesin the experiments. Baselines. In Krishnan & Tickoo (2020), for a single BNN output, the predictive distribution is obtainedthrough multiple stochastic forward passes on the network while sampling from the weight posteriors usingMonte Carlo estimators. In their work, they define the overall entropy and the entropy of the predictivedistribution as the predictive entropy (Krishnan & Tickoo, 2020, (C.2)). This quantity captures a combinationof predictive aleatoric and epistemic uncertainties. Additionally, they define the mutual information betweenweight posterior and predictive distribution as the predictive epistemic uncertainty. Finally, the predictivealeatoric uncertainty is defined as the expected entropy. The predictive epistemic and aleatoric uncertaintiessum to the predictive entropy.In our experiments, we use these definitions to compute the respectivequantities. In Cobb et al. (2019), the authors consider different BNNs, but instead of keeping them separate and usethem to build a predictive credal set, they average them out.Similar to theirs, we elicit the followingprocedure, that we call ensemble of BNNs (EBNN). Consider R N2 different BNNs, and compute the posterior distribution on the parameters. They induceR predictive distributions on the output space Y, each having mean r and variance 2r, r {1, . . . , R}.We call EBNN distribution Pens a Normal having mean ens = 1/R Rr=1 r and covariance matrix 2ensI,where 2ens = 1/R Rr=1 2r + 1/(R 1) Rr=1(r ens)2. In section 4.2, we use the -level HDR R(Pens)associated with Pens as a baseline for the IHDR IR( Ppred) computed at Step 6 of Algorithm 1. Following Cobb et al. (2019), for EBNN we posit that 1/R Rr=1 2r captures the (predictive) aleatoric uncer-tainty associated with Pens, and 1/(R 1) Rr=1(r ens)2 captures the (predictive) epistemic uncertaintyassociated with Pens.19 For CBDL, we look at the value of AU( Ppred) = H( P pred) from equation 2, and atthe lower bound H( P pred) H( P pred) for EU( Ppred) from equation 3. It is enough to focus on the lower 19Notice that in this case we retain the assumption that the EBNN distribution Pens on Y has mean ens and covariancematrix 2ensI, but we do not require that it is a Normal. That is because in the four image datasets that we consider, the outputspace Y is finite.",
  "In-distribution Evaluation": "Overall, CBDL demonstrates the most consistent behavior in terms of increasing levels of predictive epistemicand aleatoric uncertainties as the severity of noise corruption increases. The full table of results can be foundin Appendix N. In our experiments, for CIFAR-10 the single BNN also exhibits similarly consistent behavior.In MNIST and Fashion-MNIST, the BNN seems to be more consistent than CBDL, whereas for SVHN itseems to show a more inconsistent behavior. These results allow us to conclude that CBDL is comparable ifnot better than BNN in terms of In-Distribution behavior. Accuracy vs Rejection Rate. As the quantities pertaining to different approaches are not comparable,we perform an additional evaluation comparing the accuracy vs the rejection rate of a given method. Inthis task, for a given uncertainty threshold, if the uncertainty quantity exceeds such a threshold, then theprediction is rejected. Of those not rejected, the accuracy is computed. A range of uncertainty thresholds istested for each method and plotted. depicts an example of the plot. There, for lower severities (e.g.1-2) of Gaussian blur noise, CBDL exhibits better performance and converges to 100% accuracy at a lowerrejection rate. Intuitively, for the same range of rejection rates, a higher curve signifies better performance,as less samples are rejected while achieving a higher accuracy. However, for higher severities (above 3), thesingle BNN seems to show better performance. Even so, the overall rejection rate is high to achieve suchaccuracy. The entirety of the results can be found in Appendix P. To quantify the differences, the areas",
  "Out-of-distribution Evaluation": "In this final evaluation, we analyze the behavior of the three approaches (CBDL, EBNN, and BNN) whentested on an OOD dataset. For a given dataset, for example CIFAR, a model is trained on the dataset, andevaluated on the remaining datasets, i.e. MNIST, SVHN, and Fashion-MNIST. The relative increase in theaverage predictive EU and AU is computed compared to when an approach is tested on the In-Distributiontesting set. The In-Distribution uncertainty quantities for each dataset are shown in . The relativemagnitude of the increase in each quantity is shown in the parenthesis for each respective OOD dataset. The baseline EBNN exhibits a counterintuitive behavior, viz. a decrease in predictive AU. Although thisbehavior is consistent across the different dataset combinations, this would be an undesirable quality forOOD detection scenarios. The single BNN exhibits inconsistent behavior in terms of the relative increase or decrease in magnitude. ForCIFAR-10, the predictive AU increases by a magnitude larger than the predictive EU, while for SVHN theincrease is smaller. Moreover, for Fashion-MNIST the predictive AU decreases, and for MNIST the behavioris inconsistent. Only our proposed CBDL method demonstrates a stable, consistent increase in predictive AU, which isgreater in magnitude relative to the increase in predictive EU. These results demonstrate a clear improvementin performance by our proposed approach. We also give results pertaining AUROCs for the OOD detection performance, presented in . Eachgroup of results shows which dataset the models are trained on, and which they are tested on. We reportAUROC when using both the predictive EU and AU of each approach. In general, the baseline EBNN methodperforms the worst in all cases. When using predictive AU, a single BNN performs relatively better thanCBDL for OOD detection, though CBDL is still comparable and outperforms it when trained on Fashion-MNIST. When using predictive EU, CBDL clearly outperforms the other approaches on most datasets. Thisis in line with other works where predictive EU is considered important for OOD detection (Kendall & Gal,2017). We conjecture that this may be due to the fact that a single BNN is not able to gauge predictive EU properly.Hence, the single BNN flags an instance as OOD when it comes from the tail of the distribution; this iswell-captured by (predictive) aleatoric uncertainty. On the contrary, CBDL is able to gauge predictive EUproperly, and hence it is able to capture when OOD happens by looking at the disagreement between theelements of the predictive credal set, captured by the difference between upper and lower entropy.",
  "Downstream Tasks Performance": "As we have shown in the previous section, CBDL is better than single BNNs and ensemble of BNNs atquantifying and disentangling predictive AU and EU. In this section, we show with two applications motion prediction in autonomous driving scenarios, and blood glucose and insulin dynamics for artificialpancreas control that CBDL has better downstream tasks capability than EBNN. We do not compareCBDL against belief tracking techniques because these latter require extra assumptions that CBDL do not,as we further expand on in Appendix K.",
  "Motion Prediction for Autonomous Racing": "In this case study, we demonstrate the utility of CBDL for motion prediction in autonomous driving scenarios.An important challenge in autonomous driving is understanding the intent of other agents and predictingtheir future trajectories to allow for safety-aware planning. In autonomous racing, where control is pushedto the dynamical limits, accurate and robust predictions are even more essential for outperforming opponentagents while assuring safety.CBDL provides a straightforward method for quantifying uncertainty andderiving robust prediction regions for anticipating an agents behavior. We use the problem settings in Tumu et al. (2023) to define the problem of obtaining prediction sets forfuture positions of an autonomous racing agent. Our results show that the prediction regions have improvedcoverage when compared to EBNN. These results hold in both In-Distribution and Out-Of-Distributionsettings, which are described below. Problem.Let Oi(t, l) Oi = {itl, . . . , it} denote the i-th trajectory instance of an agent at time t,consisting of the observed positions from time t l up to time t. Let then Ci be a time-invariant contextvariable. Let also F i(t, h) F i = {it+1, . . . , it+h} be the collection of the next h future positions. We wishto obtain a model M that predicts region R with probabilistic guarantees. In particular, for EBNN R isthe -level HDR R(Pens) of Pens, so that Pens[F i R(Pens)] 1, while for CBDL R = IR( Ppred), so",
  "pred[F i IR( Ppred)] 1 , or equivalently, P pred[F i IR( Ppred)] 1 , for all P pred Ppred": "The dataset consists of instances of (Oi, F i) divided into a training set Dtrain and a testing set Dtest. Wetrain an uncertainty-aware model on Dtrain that computes the triplet (F il , F im, F iu) = M(Oi, Ci) where F il ,F iu, F im are the lower, upper, and mean predictions of the future positions, respectively. The dataset Dall is created by collecting simulated trajectories of autonomous race cars in the F1Tenth-Gym(OKelly et al., 2020); for details, see Tumu et al. (2023). As shown in , different racing lines wereutilized including the center, right, left, and optimal racing line for the Spielberg track.",
  ": F1Tenth coverage results. We report one-step coverage and multi-step coverage across 3 different values of. CBDL exceed coverage of EBNNs in all settings": "We denote these by Dcenter, Dright, Dleft, and Drace, respectively. Position is a vector = (a, b, , v),where a and b are coordinates in a 2-dimensional Euclidean space, and and v are the heading and speed,respectively. In total, the Dall consists of 34686 train instances, 4336 validation instances, and 4336 testinstances.",
  "In-Distribution vs Out-Of-Distribution.We consider the prediction task to be In-Distribution whenDtrain, Dtest Dall. It is Out-Of-Distribution (OOD) when Dtrain DcenterDrightDleft and Dtest Drace": "Metrics.We train the ensemble of BNNs and the CBDL models, Mens and MCBDL respectively, usingthe same architecture and different seeds. As for section 4.1, for CBDL this corresponds to having a non-singleton prior FGCS, and a singleton likelihood FGCS. We compare the performance with respect to thetest set by computing the single-step coverage, where each prediction time-step is treated independently, andthe multi-step coverage, which considers the entire h-step prediction. .(a) depicts a sample of the In-Distribution evaluation for each of the models. For a given trajectory,the red boxes indicate when the prediction region did not cover the actual trajectory at that time-step.Qualitatively, MCBDL has less missed time steps when compared to Mens. shows that CBDLperforms better in terms of both one-step and multi-step coverage. Similar results can be observed for theOOD scenario. There, all models were trained on racing lines which are predominantly parallel to the trackcurvature. As a consequence, when the test set consists of instances with higher curvatures, the overallcoverage of all models degrades.This can be seen in .(b), where the prediction of the models(orange) tends to be straight while the actual trajectory is more curved (green). Despite this, the figure andthe coverage metrics in show how CBDL exhibits a more robust behavior.",
  "Overall Setup. In this next case study we consider the problem of data-driven control of human bloodglucose-insulin dynamics, using an artificial pancreas system, see": "External insulin delivery is accomplished by using an insulin pump controlled by the artificial pancreassoftware, which attempts to regulate the blood-glucose (BG) level of the patient within the euglycemicrange of mg/dl (Kushner et al., 2018). Levels below 70 mg/dl lead to hypoglycemia, which canlead to loss of consciousness, coma or even death. On the other hand, levels above 300 mg/dl lead to acondition called ketoacidosis, where the body can break down fat due to lack of insulin, and lead to buildup of ketones. In order to treat this situation, patients receive external insulin delivery through insulinpumps. Artificial Pancreas (AP) systems can remedy this situation by measuring the blood glucose level,",
  "(b)": ": In both pictures, the red boxes indicate when the prediction region did not cover the actual trajectory atthat time-step. Left: F1Tenth In-Distribution results. Given an input of past observations, CBDL exhibits bettercoverage of the future target trajectory. Predictions which do not cover the target within the desired 1 level areindicated in red. Right: F1Tenth Out-Of-Distribution (OOD) results. Robust performance is exhibited by CBDLwhen compared to EBNN in OOD settings. : The Bayesian Neural Networks predict a future blood glucose value. These individual predictions arecombined to get a robust estimate of the true value as an interval. This is used by the Model Predictive Control(MPC) algorithm to recommend insulin dosage for the patient. The patient block in our experiment is simulatedusing the virtual patient models from the UVa-Padova simulator.",
  "where 1{} denotes the indicator function. A lower value is more desirable. We compare EBNN and CBDLas different realizations of the model M": "Distribution Shift using Meals. A well known problem with learned models is distribution shift. BayesianNeural Networks can address this issue by apprising the end user of the increased uncertainty. For regressionmodels of the type described above, this appears as larger prediction intervals [Gl, Gu]. The artificial pancreascontroller can run into this situation in the following way: the insulin-glucose time series data collected fortraining the data-driven model M can be without meals, while at test time the patient can have meals. Thiscreates a distribution shift between the training and test time data. Fortunately, the UVa-Padova simulator(Dalla Man et al., 2013) allows us to create datasets with and without meal inputs. In this case study, thetraining data was obtained by randomly initializing the BG value in the range , and simulating thepatient for 720 minutes. The controller was executed at 5 minutes intervals. At test time the patient wassupplied meals at specific time intervals (for details, see Appendix J). This creates a significant distributionshift since meals are effectively an unknown variable which can affect the system state. However, from thecontrollers perspective this is practical, since patients can have unannounced meals. Results and Discussion. To capture the difference in performance between EBNN and CBDL, we computePerfdiff := (tEBNNunsafe tCBDLunsafe)/tEBNNunsafe. Both tEBNNunsafe and tCBDLunsafe depend on interval [Gl, Gu]; for EBNN, thislatter corresponds to the -level HDR R(Pens) associated with EBNN distribution Pens, while for CBDL itcorresponds to the IHDR IR( Ppred). We consider one case in which CBDL is trained using a credal priorset and only one likelihood (we choose different seeds which initialize the prior distributions but we keep thesame architecture for the BNNs), and another case in which we do the opposite (we use the same seed anddifferent architectures). We report Perfdiff, across different choices in . We observe that for lower values of (or equivalently,for larger values of 1, e.g. 0.95 and 0.99) the gains of CBDL are more pronounced. This means that whenlarger significance levels need to be ensured, CBDL is to be preferred to ensemble of BNNs. As discussedbefore, the CBDL procedure considers all the infinitely many possible priors that can be expressed as aconvex combination of the priors that the user specifies at the beginning of the analysis. The same holds forthe likelihoods. While this results in a more conservative estimate as compared to the EBNN framework,CBDL produces controllers which respect the safety limits better. To see that CBDL is more conservativethan EBNN, notice that when combining predictive distributions from multiple BNNs, CBDL combines thepredictions via a finitely generated credal set (FGCS) whose extrema are the individual distributions. On",
  "Related Work": "In Corani et al. (2012), the authors introduce credal classifiers (CCs) as a generalization of classifiers based onBayesian networks. Unlike CCs, CBDL does not require independence assumptions between non-descendant,non-parent variables. In addition, CBDL avoids NP-hard complexity issues of searching for optimal structurein the space of Bayesian networks (Chickering et al., 2004). In Manchingal & Cuzzolin (2022), an epistemicconvolutional neural network (ECNN) is developed that explicitly models the epistemic uncertainty inducedby training data of limited size and quality. A clear distinction is that ECNNs measure uncertainty in target-level representations whereas CBDL identifies the uncertainty measure on the output space Y. Despite themerit of their work, we believe CBDL achieves greater generality, since it is able to quantify both aleatoricand epistemic predictive uncertainties, and is applicable to problems beyond classification. For a review ofthe state of the art concerning the distinction between EU and AU we refer to Hllermeier & Waegeman(2021) and to Manchingal & Cuzzolin (2022). We also point out how CBDL has been recently used to solveprior-likelihood conflicts in Bayesian statistics (Marquardt et al., 2023). Further references can be found inAppendix L. We also point out how there exist other efficient methods which perform approximate Variational Inferencevia dropouts in deep neural networks (Kendall & Gal, 2017; Gal & Ghahramani, 2016). As mentioned at theend of section 3.1, we can easily adapt CBDL to use such dropout approximations in Steps 3-4 of Algorithm1. Since our contribution is centered around how different predictions can be combined via an FGCS, we usedthe de-facto standard for performing inference on BNNs, which is based on off-the-shelf VI techniques. In thefuture, we plan to study the effect on computational complexity and uncertainty quantification capability ofa CBDL procedure that approximates posterior and predictive distributions via dropout. We do not consider Bayesian Model Averaging (BMA) as a baseline for CBDL for two main reasons. First,BMA applied to deep learning needs to implement full batch Hamiltonian Monte Carlo in order to get to thetrue posterior (Izmailov et al., 2021b). Given the number of parameters in modern deep learning architectures in the order of millions this is realistically possible at an experimental level only to labs with access toindustry scale computational resources. In order to be practically relevant, we limit our experiments to themore well-understood realm of Variational Inference on BNNs. In addition, Izmailov et al. (2021a) show thepitfalls of BMA in the context of Bayesian Neural Networks, a further reason not to use a Highest DensityRegion resulting from BMA as a baseline for CBDL. Such pitfalls are related to the fact that BMA can beseen as a model featuring second-order distributions, i.e. distributions over distributions. In particular, thedistribution Q in equation 1 is a second order distribution. These types of models have been recently shownto suffer from major pitfalls when used to quantify predictive EU due to their sensitivity to regularizationparameters, and to underestimate predictive AU (Bengs et al., 2022; Pandey & Yu, 2023; Juergens et al.,2024).",
  "Conclusion": "We presented CBDL, a procedure that can be seen as a non-condensed, uncountably infinite ensemble ofBNNs, carried out using only finitely many elements. It allows to distinguish between predictive AU andEU, and to quantify them. We showed how it can be used to specify a set of outputs the IHDR thatenjoys probabilistic guarantees. We showed empirically that it improves on the Bayesian state of the art atgauging predictive AU and EU, and we also demonstrated its downstream tasks capabilities.",
  "pred[y IR( Ppred)] 1": "The problem with IR is that, while the highest density regions R( P predk,s ) associated with the predictivedistributions in ex Ppred can be computed using off-the-shelf tools, calculating ppred and p would have beenmuch more computationally expensive. In addition, it would have required to come up with a new techniqueto find ppred and p. We defer studying this to future work. We also plan to apply CBDL to continual learning to overcome the curse of dimensionality and to capturean agents preference over the tasks to perform, similarly to Lu et al. (2023), and to active learning, to beable to sample from the regions of the state space exhibiting the highest epistemic uncertainty, similarly toDutta et al. (2023). Furthermore, we intend to relate CBDL to Bayesian Model Selection (BMS) (Ghosh et al., 2019). This lattersuffers from the same problem as regular Bayesian inference. That is, while it tries to come up with asophisticate prior that induces shrinkage, it still relies on the correctness of that prior, i.e. on correctlyspecifying the priors parameters. In the future, an interesting way of combining CBDL with BMS will beto use a finite number of regularized horseshoe priors, as suggested by Ghosh et al. (2019, .2), asextreme elements of the prior credal set. We also call attention to the fact that CBDL is a model-based approach. The relationship with model-freeapproaches such as conformal prediction (Shafer & Vovk, 2008) will be the object of future studies. Inparticular, we are interested in finding in which cases IHDRs are narrower than conformal regions, and viceversa, and which credal sets give rise to IHDRs enjoying the same probabilistic guarantees as conformalregions. Finally, we point out how one possible way of easing the burden of the combinatorial task in Step 3 ofAlgorithm 1 is to specify a prior credal set whose size strikes the perfect balance between being vagueenough so that we do not underestimate the EU, and being small enough so that CBDL is actuallyimplementable. We suspect conjugacy of the priors may play a key role in this endeavor. Because of itscentrality, we defer the study of optimal prior credal sets to future work.We also point out how anevidential approach (Amini et al., 2020; Charpentier et al., 2020; Denux, 2022; 2023; Sensoy et al., 2018) at least in classification problems could allows us to bypass the bottleneck in Algorithm 1 by merging animprecise probabilistic approach, with some tricks resulting from smartly choosing our priors. A CBDL-adjacent research question of great interest pertaining ensemble learning, then, is how do singlecomponents of an ensemble contribute to the quantification of the global predictive EU faced by the agent.When the uncertainty captured by an ensemble is distilled into only one distribution, there could indeed beuncertainty spills, like when one pours water in a glass too hastily, and some finishes on the table insteadof in the glass. This remains an unexplored venure in the uncertainty quantification community.",
  "Michele Caprio and Sayan Mukherjee. Extended probabilities and their application to statistical inference,chapter 2. World Scientific, 2023d": "Michele Caprio and Teddy Seidenfeld. Constriction for sets of probabilities. In Enrique Miranda, IgnacioMontes, Erik Quaeghebeur, and Barbara Vantaggi (eds.), Proceedings of the Thirteenth InternationalSymposium on Imprecise Probability: Theories and Applications, volume 215 of Proceedings of MachineLearning Research, pp. 8495. PMLR, 1114 Jul 2023. URL Michele Caprio, Kuk Jin Jang, Souradeep Dutta, Shireen Manchingal, Fabio Cuzzolin, Oleg Sokolsky, andinsup Lee. Credal and interval deep evidential classification. Technical Reports of the PRECISE Center,2024a. Michele Caprio, Yusuf Sale, Eyke Hllermeier, and Insup Lee. A Novel Bayes Theorem for Upper Probabil-ities. In Fabio Cuzzolin and Maryam Sultana (eds.), Epistemic Uncertainty in Artificial Intelligence, pp.112, Cham, 2024b. Springer Nature Switzerland.",
  "Thierry Denux. Quantifying prediction uncertainty in regression using random fuzzy sets: the ENNregmodel. IEEE Transactions on Fuzzy Systems, pp. 110, 2023": "Stefan Depeweg, Jose-Miguel Hernandez-Lobato, Finale Doshi-Velez, and Steffen Udluft. Decomposition ofuncertainty in Bayesian deep learning for efficient and risk-sensitive learning. In International Conferenceon Machine Learning, pp. 11841193. PMLR, 2018. Didier Dubois and Eyke Hllermeier. Comparing probability measures using possibility theory: A notion ofrelative peakedness. International Journal of Approximate Reasoning, 45(2):364385, 2007. Eighth Euro-pean Conference on Symbolic and Quantitative Approaches to Reasoning with Uncertainty (ECSQARU2005). Souradeep Dutta, Taisa Kushner, and Sriram Sankaranarayanan. Robust data-driven control of artificial pan-creas systems using neural networks. In Milan eka and David afrnek (eds.), Computational Methodsin Systems Biology, pp. 183202, Cham, 2018. Springer International Publishing. ISBN 978-3-319-99429-1. Souradeep Dutta, Michele Caprio, Vivian Lin, Matthew Cleaveland, Kuk Jin Jang, Ivan Ruchkin, OlegSokolsky, and Insup Lee. Distributionally robust statistical verification with imprecise neural networks.arXiv preprint arXiv:2308.14815, 2023.",
  "Alex Krizhevsky, Vinod Nair, and Geoffrey Hinton. CIFAR-10 (Canadian Institute for Advanced Research).Available at kriz/cifar.html, 2009": "Meelis Kull and Peter A. Flach. Reliability Maps: A Tool to Enhance Probability Estimates and ImproveClassification Accuracy. In Toon Calders, Floriana Esposito, Eyke Hllermeier, and Rosa Meo (eds.),Machine Learning and Knowledge Discovery in Databases, Lecture Notes in Computer Science, pp. 1833,Berlin, Heidelberg, 2014. Springer. ISBN 978-3-662-44851-9. Taisa Kushner, David Bortz, David M. Maahs, and Sriram Sankaranarayanan. A data-driven approach to ar-tificial pancreas verification and synthesis. In Proceedings of the 9th ACM/IEEE International Conferenceon Cyber-Physical Systems, ICCPS 18, pp. 242252. IEEE Press, 2018. ISBN 9781538653012.",
  "Isaac Levi. The Enterprise of Knowledge. London, UK : MIT Press, 1980": "Vivian Lin, Kuk Jin Jang, Souradeep Dutta, Michele Caprio, Oleg Sokolsky, and Insup Lee. DC4L: Distribu-tion shift recovery via data-driven control for deep learning models. In Alessandro Abate, Mark Cannon,Kostas Margellos, and Antonis Papachristodoulou (eds.), Proceedings of the 6th Annual Learning for Dy-namics and Control Conference, volume 242 of Proceedings of Machine Learning Research, pp. 15261538.PMLR, 1517 Jul 2024. URL",
  "Blint Mucsnyi, Michael Kirchhof, and Seong Joon Oh. Benchmarking uncertainty disentanglement: Spe-cialized uncertainties for specialized tasks. Available at arXiv:2402.19460, 2024": "Yuval Netzer, Tao Wang, Adam Coates, Alessandro Bissacco, Bo Wu, and Andrew Y. Ng. Reading digits innatural images with unsupervised feature learning. In NIPS Workshop on Deep Learning and UnsupervisedFeature Learning 2011, 2011. Matthew OKelly, Hongrui Zheng, Dhruv Karthik, and Rahul Mangharam. F1TENTH: An Open-sourceEvaluation Environment for Continuous Control and Reinforcement Learning.In Proceedings of theNeurIPS 2019 Competition and Demonstration Track, pp. 7789. PMLR, 2020. Deep Shankar Pandey and Qi Yu. Learn to accumulate evidence from all training samples: Theory andpractice.In Andreas Krause, Emma Brunskill, Kyunghyun Cho, Barbara Engelhardt, Sivan Sabato,and Jonathan Scarlett (eds.), Proceedings of the 40th International Conference on Machine Learning,volume 202 of Proceedings of Machine Learning Research, pp. 2696326989. PMLR, 2329 Jul 2023. URL",
  "Hippolyt Ritter, Aleksandar Botev, and David Barber. A scalable laplace approximation for neural networks.In International Conference on Learning Representations, 2018": "Yusuf Sale, Michele Caprio, and Eyke Hllermeier. Is the volume of a credal set a good measure for epistemicuncertainty? In Robin J. Evans and Ilya Shpitser (eds.), Proceedings of the Thirty-Ninth Conference onUncertainty in Artificial Intelligence, volume 216 of Proceedings of Machine Learning Research, pp. 17951804. PMLR, 31 Jul04 Aug 2023. URL Yusuf Sale, Viktor Bengs, Michele Caprio, and Eyke Hllermeier. Second-order uncertainty quantification:A distance-based approach. In Ruslan Salakhutdinov, Zico Kolter, Katherine Heller, Adrian Weller, NuriaOliver, Jonathan Scarlett, and Felix Berkenkamp (eds.), Proceedings of the 41st International Conferenceon Machine Learning, volume 235 of Proceedings of Machine Learning Research, pp. 4306043076. PMLR,2127 Jul 2024. URL",
  "Larry A. Wasserman and Joseph B. Kadane. Bayes theorem for Choquet capacities. The Annals of Statistics,18(3):13281339, 1990": "Lisa Wimmer, Yusuf Sale, Paul Hofman, Bernd Bischl, and Eyke Hllermeier. Quantifying aleatoric andepistemic uncertainty in machine learning: Are conditional entropy and mutual information appropriatemeasures?In Robin J. Evans and Ilya Shpitser (eds.), Proceedings of the Thirty-Ninth Conference onUncertainty in Artificial Intelligence, volume 216 of Proceedings of Machine Learning Research, pp. 22822292. PMLR, 31 Jul04 Aug 2023. URL",
  "The main motivations for working with credal sets are two. Let (, F) be the measurable space of interest": "(i) A single probability distribution does not suffice to represent ignorance in the sense of lack ofknowledge; this is well documented in the literature, see e.g. Hllermeier & Waegeman (2021) andreferences therein. Consider the example of complete ignorance (CI) in the case of a finite state space (Hllermeier & Waegeman, 2021, .3). In standard Bayesian analysis, CI is modeled interms of the uniform distribution Unif(); this is justified by Laplaces principle of indifference.Then, however, it is not possible to distinguish between precise probabilistic knowledge about arandom event called prior indifference; think of the tossing of a fair coin and a complete lackof knowledge due to an incomplete description of the experiment called prior ignorance. Anotherproblem is given by the additive nature of probability distributions. Consider again the exampleof a uniform distribution. First, let us observe that it is not invariant under reparametrization. Inaddition, if we model the ignorance about the length x of the side of a cube in R3 via a uniformmeasure on the interval [l, u] R, then this does not yield a uniform distribution of x3 on [l3, u3],which suggests some degree of informedness about the cubes volume. Finally, as pointed out inWalley (1991), if we ask a subject even an expert about their opinion regarding some events, itis much more likely that they will report interval of probabilities rather than single values. (ii) Working with credal sets allows to achieve prior and likelihood robustness: realistically large setsPprior of priors and Plik of likelihoods are elicited. Using credal sets, the agent recognizes that priorbeliefs and knowledge about the sampling model are limited and imprecise. Combining each pairof functions in Pprior and Plik using Bayes rule, a class of posterior distributions reflecting theupdated state of uncertainty is formed. If the available information is not sufficient to identifya unique posterior distribution, or a set of posteriors whose diameter is small, credal sets allow torepresent indecision, thus leading to a less informative but more robust conclusions.20",
  "BOn the use of credal sets": "Let us address a critique raised against the use of credal sets. Lassiter (2020) argues against the use of sets ofprobabilities to model an agents prior beliefs and their knowledge of the sampling model, while debating infavor of using hierarchical Bayesian models. As reported in Hllermeier & Waegeman (2021, Secton 4.6.2),the argument against credal sets that is more cogent for the machine learning literature is that modeling alack of knowledge in a set-based manner may hamper the possibility of inductive inference, up to a pointwhere learning from empirical data is not possible any more. With this, we mean the following. As Pericchi(1998) points out, the natural candidate for a class of priors to represent complete ignorance is the class Pallof all distributions. When this class leads to non-vacuous and useful conclusions, these are quite compellingand uncontroversial. It turns out that the posterior probabilities obtained from this class are vacuous, thatis, their lower and upper bounds are 0 and 1: no finite sample is enough to annihilate a sufficiently extremeprior belief. There is then a compromise to be made, and this is the compromise of near-ignorance. The near-ignorance class should be vacuous a priori in some respects, typically the ones that are the most importantfor the analysis at hand. This way of proceeding is labeled as arbitrary by Lassiter (2020), who insteadadvocates for the use of hierarchical Bayesian procedures. We find this critique not compelling, as duringthe analysis the job of the agent is to model reality: as pointed out in Hllermeier & Waegeman (2021,Secton 5), statistical inference is not possible without underlying assumptions, and conclusions drawn fromdata are always conditional on those assumptions. If we were to work every time with the maximum levelof generality, we would hardly be able to reach any conclusions. For example, in a statistical analysis wenever consider the state of apparently possible states (Walley, 1991, section 2.1.2), that is, the one thatcontains all the states that are logically consistent with the available information. If we consider a cointoss, we let the state space be = {heads, tails}, certainly not = {heads, tails, coin landing on its edge,coin braking into pieces on landing, coin disappearing down a crack in the floor}. The same holds for sets",
  "B.1Further notes on credal sets": "As pointed out in Corani et al. (2012, .3), there is a way of obtaining credal sets starting from setsof probability intervals; in addition, standard algorithms can compute the extreme elements of a credal setfor which a probability interval has been provided (Avis & Fukuda, 1996). However, the resulting numberof extrema is exponential in the size of the possibility space (Tessem, 1992).21 For this reason we prefer tospecify prior and likelihood finitely generated credal sets instead. The way credal sets behave after conditioning on new available evidence has been recently studied in Caprio& Seidenfeld (2023), and a way of using credal sets in the open-world scenario (that is, when the supportof the elements of the credal set can become larger as more data become available) is explored in Caprio& Mukherjee (2023d). Furthermore, the use of credal sets in statistical learning theory has been studied inCaprio et al. (2024c), and in computer vision in Caprio (2024).",
  "CA further IP concept: the core": "Let again (, F) be the measurable space of interest.Because of the conjugacy property of upper andlower probabilities, let us focus on upper probabilities only. We say that upper probability P is concave ifP(AB) P(A)+P(B)P(AB), for all A, B F. Recall that (, F) denotes the set of all probabilitymeasures on (, F). Upper probability P is compatible with the convex set (Gong & Meng, 2021)",
  "= {P (, F) : P(A) P(A) P(A), A F}": "where the second equality is a characterization (Cerreia-Vioglio et al., 2015, Page 3389). Notice that thecore is convex (Marinacci & Montrucchio, 2004, .2).We assume it is nonempty.Then, it isweak-compact as a result of Marinacci & Montrucchio (2004, Proposition 3).22 Since the core is convex, the set ex[core(P)] of extreme points of the core is well defined. It contains all theelements of the core that cannot be written as a convex combination of one another. The following importantresult is a consequence of Walley (1991, Theorem 3.6.2).",
  "We present Theorem 10, a result that although appealing does not lend itself well to be applied to theCBDL procedure. An extension of Theorem 10 is given in Caprio et al. (2024b)": "Call the parameter space of interest and assume it is Polish, that is, the topology for is complete,separable, and metrizable. This ensures that the set (, B) of probability measures on is Polish as well,where B denotes the Borel -algebra for . Let X be the set of all bounded, non-negative, B-measurablefunctionals on . Call D = X Y the sample space endowed with the product -algebra A = Ax Ay,where Ax is the -algebra endowed to X and Ay is the -algebra endowed to Y.Let the agent elicitL := {P (D, A) : }. Assume that each P L has density L() = p(D | ) with respect to some-finite dominating measure on (D, A); this represents the likelihood function for having observed dataD D. We assume for now that L X , for all D D. Let the agent specify a set P of probabilities on (, B). Then, compute P, and consider Pco := core(P); itrepresents the agents initial beliefs.23 We assume that every P Pco has density p with respect to some-finite dominating measure on (, B), that is, p = dP d . We require the agents beliefs to be representedby the core for two main reasons. The first, mathematical, one is to ensure that the belief set is compatiblewith the upper probability. The second, philosophical, one is the following (Caprio & Gong, 2023; Caprio &Mukherjee, 2023c). A criticism brought forward by Walley (1991, .10.4.(c)) is that, given an upperprobability P, there is no cogent reason for which the agent should choose a specific PT that is dominated byP, or for that matter a collection of plausible probabilities. Because the core considers all (countablyadditive) probability measures that are dominated by P, it is the perfect instrument to reconcile Walleysbehavioral and sensitivity analysis interpretations.",
  "FHow to derive a predictive distribution": "Suppose we performed a Bayesian updating procedure so to obtain posterior pdf p( | x1, y1, . . . , xn, yn).Recall that {(xi, yi)}ni=1 (X Y)n denotes the training set. We obtain the predictive distribution p(y |x, x1, y1, . . . , xn, yn) on Y as follows",
  "p(y | x, ) p( | x1, y1, . . . , xn, yn)d,": "where p(y | x, ) is the likelihood used to derive the posterior. Notice that the last equality comes fromoutput y only depending on input x and parameter , and from having assumed Dx (see section 2.1).From an applied point of view, a sample from p(y | x, x1, y1, . . . , xn, yn) is obtained as follows:",
  "If we want to avoid to perform the computation in Step 5 of Algorithm 1 only to discover that IR( Ppred)is too large, then we can add a predictive AU check": "At the beginning of the analysis, compute the lower entropy H( P pred) = mink,s H( P predk,s ) associated withthe set ex Ppred of extreme elements of the VI-approximated predictive credal set Ppred. By equation 2, itis equal to the predictive aleatoric uncertainty encoded in Ppred. We then verify whether the lower entropyH( P pred) is too high. That is, if H( P pred) > , for some > 0, we want our procedure to abstain. Thismeans that if the predictive aleatoric uncertainty in set Ppred is too high, then our procedure does not returnany output set for input x. The value of can be set equal to the entropy of the probability measures thatare typically used in the context the agent works in. For example, in medical applications the agent mayconsider the entropy of a Normal distribution, while in financial applications the entropy of a distributionwith fatter tails, such as a t-distribution or a Cauchy. We call these reference values.",
  "If we add this predictive AU check, at inference time (that is, before Step 4 of Algorithm 1), the agentneeds to specify the pair of parameters (, )": "24A belief function is a mathematical concept that should not be confused with the term belief we used throughout thepaper to address the agents knowledge.25Since the diameter is a metric concept, we assume that we can find a well-defined metric dy on Y. If that is not the case,we substitute the diameter with the notion of cardinality.",
  "where we write |D to highlight the fact that is sampled from posterior p( | D), and then select the mostlikely class y := arg maxj j, where the js are the elements of": "When applied to a classification setting, the general procedure introduced in Algorithm 1 becomes thefollowing. Recall that we denote by K the cardinality of exPprior, and by S the cardinality of exPlik. Assumethat Y = {y1, . . . , yJ}, that is, there are J N2 possible labels. Then, a VI-approximated predictivedistribution P predk,sin ex Ppred can be seen as J-dimensional probability vector ppredk,s= (ppredk,s,1, . . . , ppredk,s,J),",
  "(6)": "for some > 0. It corresponds to the -level HDR R( P predk,s ). Notice that we require ji=1 P predk,s ({yk,si}) [1, 1+] because we may need to go slightly above level 1. Just as a toy example, we may have 7labels, 3 of which would give a 0.945 coverage, while 4 would give a coverage of 0.953. If we are interested inthe = 0.05-level credible set, we ought to include the fourth label, thus yielding a coverage slightly higherthan 1 = 0.95. The interpretation to CS( P predk,s ) is the following: it consists of the smallest collection",
  "pred[{y ICS( Ppred)] 1": "Remark 15. Notice that if a credible set of level is enough, then we can replace the left endpoint ofthe interval in equation 6 with 1 ( + k,s), for some k,s > 0. Strictly speaking, in this case we obtain an( +k,s)-level credible set, which we denote by CSk,s( P predk,s ), where k,s := +k,s. Going back to our toyexample, we will have a credible set with 3 labels that yields a coverage of 1(+k,s) = 0.945 0.95 = 1,so k,s = 0.005. In turn, this implies that the imprecise credible set will have a coverage of 1(+maxk,s k,s),that is, it will have level + maxk,s k,s. We denote it by ICS( Ppred), where := + maxk,s k,s.",
  "IDistance between a set of distributions P and a single distribution P havingdifferent dimensions": "Many concepts in this section are derived from Cai & Lim (2022). Let m, n N such that m n, andlet p . Call M p(Rj) the set of probability measures on Rj having finite p-th moment, and Md(Rj)the set of probability measures on Rj having density with respect to some -finite dominating measure ,j {m, n}. Let O(m, n) := {V Rmn : V V = Im}, where Im denotes the m-dimensional identity matrix,and for any V O(m, n) and any b Rm, define the following function",
  "R2n x yp2(d(x, y))1/p,": "where 2 denotes the Euclidean distance, p = is interpreted as the essential supremum, and (P1, P2) :={ (R2n, B(R2n)) : projn1() = P2, projn2() = P1} is the set of couplings between P1 and P2, where projn1is the projection onto the first n coordinates, and projn2 is the projection to the last n coordinates. Recall then the definition of f-divergence between two generic distributions defined on the same Euclideanspace. Let P1, P2 (Rn, B(Rn)), for some n N, and assume P1 P2. Then, for any convex functionalf on R such that f(1) = 0, the f-divergence between P1 and P2 is defined as",
  "Aside from the Rnyi divergence, the f-divergence includes just about every known divergences as specialcase (Cai & Lim, 2022). The following are the main results of this section": "Lemma 16. Let m, n N such that m n, and let p and f be any convex functional on R suchthat f(0) = 1. Consider a generic P M p(Rm) and P M p(Rn). Let +p (P, n) := P P+p (P, n) and+d (P, n) := P P+d (P, n). Define",
  "p (lik, Lo)": ": We assume that n > m and that the oracle distribution Lo belongs to M p(Rm), while likelihood FGCSPlik is a subset of M p(Rn), for some finite p 1. We also assume that L is one of the extreme elements of Plik. Wesee how W p (Plik, Lo) < W p (L, Lo); if we replace metric W p by a generic f-divergence divf, the inequality wouldstill hold thanks to Lemma 17.",
  "JDetails on Artificial Pancreas Example": "Artificial Pancreas Model. An important factor when designing the controller for an artificial pancreasis to adapt the insulin delivery algorithm to the particular details of the patient. This is because patientsdisplay a wide range of variability in their response to insulin, depending on age, Body Mass Index (BMI),and other physiological parameters. The Bayesian Neural Network models have 2 hidden layers, with 10",
  "KOther possible baselines for CBDL": "Our experiments may seem like a type of belief tracking (Fortin et al., 2017; Klein et al., 2010).Twocomments are in order.First, this line of literature does not use deep learning techniques.Second, inthese works the authors rely on Dempster-Shafer theory, a field in imprecise probability theory where lowerprobabilities are assumed to be belief functions, see Remark 14. We do not rely on this assumption in ourwork.",
  "LFurther related work": "Modeling uncertainty has been a longstanding goal of ML/AI research and a variety of approaches have beendeveloped for doing so (Guo et al., 2017; Park et al., 2020; Jospin et al., 2022). Recently, emphasis has beenplaced on discerning between aleatoric and epistemic uncertainties (Senge et al., 2014; Kull & Flach, 2014;Kendall & Gal, 2017). In Tretiak et al. (2022), the authors present an IP-based neural network which uses aregression technique based on probability intervals. Contrary to CBDL, their NN is rooted in the frequentistapproach to imprecise probabilities (Huber & Ronchetti, 2009). In Manchingal & Cuzzolin (2022, Sections 2.1, 2.3), the authors focus on belief-functions-based classificationmethods. CBDL cannot be directly compared with these methodologies because (i) they do not requirethat the user expresses their knowledge via a belief function, but rather through a credal set; (ii) they canbe used for regression and classification; (iii) they are rooted in Bayesian theory, as opposed to Dempster-Shafer theory. Other works in ML using a belief function approach are those from the field of evidentialmachine learning (EML), see e.g. (Amini et al., 2020; Charpentier et al., 2020; Denux, 2022; 2023; Sensoyet al., 2018) and references therein. Existing models mainly address clustering, classification, and regressionproblems. The reasons why CBDL cannot be directly compared with methods from the EML literatureare (i) and (iii) above, the fact that EML methods are not (derived from) Bayesian ones, and that theirdefinitions of AU and EU are slightly different from the canonical ones in ensemble deep learning.",
  "Proof of Proposition 6. The lower bound for the upper entropy of comes immediately from being asuperset of": "Let us now prove the lower entropy equality. Let = {P1, . . . , Pk} and = Conv. Pick any P .By the definition of , there exists a collection of non-negative reals {j}kj=1 such that kj=1 j = 1 andkj=1 jPj = P . By the concavity of the entropy, we have that",
  "H(P ) = H(P)": "Proof of Proposition 8. Pick any metric d on the space (, F) of probabilities on (, F), andany P .Because P belongs to , infP d(P , ) can only be either equal to or smaller thand(P, ). By the definition of d(, ), if infP d(P , ) = d(P, ), then d(, ) = d(P, ). If insteadinfP d(P , ) < d(P, ), then d(, ) < d(P, ). The proof is similar for a generic divergence div on(, F). Proof of Theorem 10. Assume Pco, Lco are nonempty. Then, by Marinacci & Montrucchio (2004, Proposition3), they are weak-compact. Pick any A B. Recall that we can rewrite the usual Bayes updating rule as",
  "d ()": "The inequality in equation 13 is a property of Choquet integrals taken with respect to upper probabilities(Marinacci & Montrucchio, 2004). The equality in equation 14 is true because for a generic function f, wehave that sup f = inf f. Finally, the equality in equation 15 is true because the logarithm is a strictlyincreasing function.By Marinacci & Montrucchio (2004, Theorem 38), if P is concave, then inequalityequation 13 holds with an equality, and so the bound is tighter.",
  "P({}) log [P({})] = H(P)": "The inequality in equation 17 comes from the well known fact that the sum of the suprema is at least equalto the supremum of the sum. The inequality in equation 18 comes from the fact that for differentiablefunctions, the product of the suprema is at least equal to the supremum of the product. The equality inequation 19 is true because for a generic function f, we have that sup f = inf f. Finally, the equalityin equation 20 is true because the logarithm is a strictly increasing function. By Marinacci & Montrucchio(2004, Theorem 38), if P is concave, then inequality equation 17 holds with an equality, and so the boundis tighter.",
  "infP P {P({})( log) [P({})]}": "Proof of Lemma 16. Fix any p and pick any P P.Because +p (P, n) +p (P, n),then inf+p (P,n) Wp(, P ) can only be either equal or smaller than inf+p (P,n) Wp(, P ).Now,if inf+p (P,n) Wp(, P )=inf+p (P,n) Wp(, P ),then W +p (P, P )=W +p (P, P ).If insteadinf+p (P,n) Wp(, P ) < inf+p (P,n) Wp(, P ), then W +p (P, P ) < W +p (P, P ). This concludes the firstpart of the proof.Fix then any convex functional f on R such that f(0) = 1; the proof is similar forf-divergences.",
  "SVHN0.183 (1.789)0.141 (4.606)0.019 (2.421)0.046 (0.608)0.394 (2.612)0.647 (3.616)": ":CIFAR-10 Results.The 4 BNNs trained have the following accuracies : 90, 89, 90, 89 in percentage terms androunded to the nearest whole number.For different categories of corruptions, increasing severity leads to higher levels ofaleatoric uncertainty for CBDL. When exposed to completely unseen datasets, this reaches its peak. In contrast, the Ensemblehas a reverse trend. For the single BNN, the network with the highest accuracy was selected.",
  "SVHN0.190 (1.015)0.168 (2.963)0.022 (1.847)0.043 (0.69)0.923 (4.674)0.297 (4.183)": ": The 4 BNNs trained have the following accuracy: 99, 99, 99, 98 in percentage terms and rounded to thenearest whole number. These are the probabilities of the most likely label to be the correct one according to the 4different BNNs. For the single BNN, the network with the highest accuracy was selected. For different categories ofcorruptions, increasing severity leads to higher levels of aleatoric uncertainty for IBNNs. When exposed to completelyunseen datasets, this gets close to the highest aleatoric uncertainty. The same is not true for EBNN. The epistemicuncertainty for IBNNs shows a less consistent trend in this case.",
  "(3.288)0.113 (10.984)0.026 (6.002)0.041 (0.491)0.103 (6.375)0.125 (6.178)": ": The 4 BNNs trained have the following accuracy : 95, 95, 96, 95 in percentage terms and rounded to thenearest whole number. These are the probabilities of the most likely label to be the correct one according to the 4different BNNs. For the single BNN, the network with the highest accuracy was selected. For different categories ofcorruptions, increasing severity leads to higher levels of aleatoric uncertainty for IBNNs. When exposed to completelyunseen datasets, this reaches its peak. The same is not true for EBNN. For the epistemic uncertainty as well, thereis a clear trend with increasing corruption severity.",
  "SVHN0.218 (1.81)0.109 (3.742)0.026 (3.827)0.046 (0.618)0.598 (3.036)0.305 (0.867)": ": The 4 BNNs trained have the following accuracies : 93, 92, 92, 92 in percentage terms and rounded to thenearest whole number. These are the probabilities of the most likely label to be the correct one according to the 4different BNNs. For the single BNN, the network with the highest accuracy was selected. For different categories ofcorruptions, increasing severity leads to higher levels of aleatoric uncertainty for IBNNs. Which is high when exposedto completely unseen datasets as well. The same is not true for EBNN."
}