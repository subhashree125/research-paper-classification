{
  "Abstract": "Imaging is a canonical inverse problem, where the task of reconstructing a ground truthfrom a noisy measurement is typically ill-conditioned or ill-posed.Recent state-of-the-art approaches for imaging use deep learning, spearheaded by unrolled and end-to-endmodels and trained on various image datasets. However, such methods typically requirethe availability of ground truth data, which may be unavailable or expensive, leading toa fundamental barrier that can not be addressed by choice of architecture. Unsupervisedlearning presents a powerful alternative paradigm that bypasses this requirement by allowingto learn directly from noisy measurement data without the need for any ground truth.A principled statistical approach to unsupervised learning is to maximize the marginallikelihood of the model parameters with respect to the given noisy measurements. This paperproposes an unsupervised learning approach that leverages maximum marginal likelihoodestimation and stochastic approximation computation in order to train a convex neuralnetwork-based image regularization term directly on noisy measurements, improving uponprevious work in both model expressiveness and dataset size. Experiments demonstratethat the proposed method produces image priors that are comparable in performance to theanalogous supervised models for various image corruption operators, maintaining significantlybetter generalization properties when compared to end-to-end methods. Moreover, we providea detailed theoretical analysis of the convergence properties of our proposed algorithm.",
  "Introduction": "Image reconstruction often requires solving high-dimensional inverse problems, ranging from image denoisingand deconvolution, to phase retrieval or computed tomography. These problems are usually formulated asthe recovery of a signal x X from a noisy measurement y = Ax + w Y, with forward operator A : X Yand some noise w. A common trait of these problems is ill-posedness, where the solution of Ax = y canhave zero or infinitely many solutions, necessitating the use of regularized reconstruction operators (Benning& Burger, 2018; Engl et al., 1996). A classical method of solving this is using variational regularization,combining a data fidelity term with priors such as wavelet priors or total variation priors (Chambolle & Pock,2016; Arridge et al., 2019). Recently, various end-to-end approaches utilizing neural networks have pushedthe state-of-the-art for imaging, achieving highly detailed reconstructions at the cost of well-crafted trainingdata and computational resources. These include direct neural network approaches, as well as iterativeplug-and-play priors (Zhang et al., 2021; Venkatakrishnan et al., 2013). Variational models. One way to define the reconstruction of a measurement y is as the solution of aminimization problem arg minx fy(Ax) + R(x) (Arridge et al., 2019; Chambolle & Pock, 2016). Here,fy : Y R is a data fidelity function measuring how well the reconstruction x fits the measurement y Y,and R : X R is a regularization functional that promotes regularity of the reconstructions. Examplesinclude computed tomography, where A is the Radon transform and R may enforce some type of waveletsparsity (Antoniadis & Fan, 2001; Donoho, 2006). In the particular case of Gaussian denoising, A = I, thefidelity can be taken to be fy(x) = x y2/2 and regularization R(x) = x1,X , commonly known asthe total variation (TV) regularized solution. Gaussian noise allows for another probabilistic interpretationusing Tweedies identity, which provides a relationship between the the posterior mean estimator and aground-truth density p(x): it states that if p is given by convolving p with a Gaussian kernel of variance ,then the minimum mean-squared estimator (MMSE) denoiser D satisfies (D I)(x) = log p(x) (Efron,2011; Laumont et al., 2022). That is, the denoising step is in the direction of the posterior score, preciselygiven by gradient descent on a convolved version of fy(x) + g(x). This begins to endow learnable variationalmodels with probabilistic interpretation. Learned variational models are a middle ground between fully classical model-based reconstructions andfully learned end-to-end models (Lunz et al., 2018; Mukherjee et al., 2020; Kobler et al., 2020). Heuristically,the fidelity term fy(Ax) should depend on the observation process involving forward operator A and thenoise model, while the regularization R ignores the observation process and considers only the data. Oneadvantage of the decoupling is that the learned regularizer can be applied to different forward models withoutretraining. This is exploited in Plug-and-Play methods, which implicitly use generic denoisers as regularizersfor a variety of non-denoising tasks such as demosaicing and super-resolution (Zhang et al., 2021; Huraultet al., 2022a). Moreover, the variational structure allows for the application of classical regularization theoryunder regularity assumptions on R (Burger & Osher, 2004; Hauptmann et al., 2024; Schwab et al., 2019). Learned regularization. Notable examples of learned regularization include adversarial regularization andnetwork Tikhonov (Mukherjee et al., 2021; Lunz et al., 2018; Li et al., 2020a; Alberti et al., 2021). In thesupervised regime, i.e. presence of clean and noisy training pairs, one method is to minimize some distancemetric between the clean image and the reconstructed noisy image as given by an approximate solution ofthe variational problem (Diamond et al., 2017). Additional regularization is often added to enforce regularityon the learned regularizer, such as having small Lipschitz constant, which is linked to Wasserstein robustness(Kuhn et al., 2019). In the regime of weak supervision, given unpaired clean and noisy data, adversarialregularization aims to penalize noisy images and promote clean images by maximizing and minimizing theregularizing terms respectively (Lunz et al., 2018; Mukherjee et al., 2020). Using the structure of a fidelity andregularizer allows for a more explicit description of the final reconstruction, and can improve the performanceof a learned denoiser when used in an unrolled scheme (Zhang et al., 2021). We note that it is possible toindirectly learn R by instead learning mappings such as the proximal proxR or gradient R, while stillmaintaining well-posedness of the variational formulation through convex analysis identities (Gribonval &Nikolova, 2020; Moreau, 1965). For example, under certain Lipschitz conditions, denoisers can be interpretedas proximal operators of weakly convex functions, allowing for another degree of regularity (Hurault et al.,",
  "2022b; Shumaylov et al., 2023). This denoiser-prior connection has been recently extended to diffusion models(Feng et al., 2023; Graikos et al., 2022)": "Bayesian approaches. Approaches rooted in the Bayesian statistical paradigm usually aim to characterizethe posterior distribution (density) of x conditioned on observing the noisy measurement y (Stuart, 2010;Calvetti & Somersalo, 2018). Using Bayes rule, this density can be expressed as p(x|y) = (y|x)p(x)/Z(y),where (y|x) = pw(y, Ax) is the likelihood arising from the noise distribution of w, p(x) is the prior density onx, and Z(y) is a normalizing constant. The modelled distribution is thus characterized by a choice of familyfor the prior p(x). Computational Bayesian inference has been an active area of development for the past 40years, including hierarchical image models (Geman & Geman, 1986; Carlin et al., 1992), diffusions (Roberts &Stramer, 2001), and dynamical systems (Friston, 2002; Wilkinson, 2018), and we refer to Green et al. (2015);Mukherjee et al. (2023) for more comprehensive overviews. A widely-used modern method to describe thedistribution p(x|y) is to draw samples from it using Markov Chain Monte Carlo (MCMC) methods (Gilkset al., 1995; Robert et al., 1999; 2007). One distinct advantage of the Bayesian approach is the option ofuncertainty quantification rather than point estimation, given sufficient computational resources (Carioniet al., 2023; Nagel & Sudret, 2016; Durmus et al., 2018; Holden et al., 2022). This is used in various imagingmethods such as Wasserstein generative adversarial networks (Arjovsky et al., 2017), and Cycle-GANs (Zhuet al., 2017), which utilize optimal transport to flow from noisy to clean images with a learned prior. SinceBayesian approaches use the entire distribution, another possible advantage over other training methodsis that paired training examples (such as clean-noisy pairs) are often not needed, requiring only access tosamples from the marginal distributions and not the joint distribution. This can be useful in tasks such asunsupervised image registration, where paired data is labor-intensive (Balakrishnan et al., 2018; Chen et al.,2022b). The variational formulation can be interpreted as a special case of the Bayesian formulation. Given the negativeprior log-density g(x) = log p(x) and negative log-likelihood fy(x) = log (y|x), the maximum a-posterioriestimator (MAP) xMAP = arg maxx p(x|y) exp(fy(x) g(x)) is equal to the minimizer minx fy(x) + g(x).In Bayes rule, the likelihood can thus be interpreted as a fidelity term, and the prior as regularization.Pereyra (2019) further explores this connection, demonstrating that for log-concave distributions, the MAPestimator is optimal with respect to a Bregman divergence in terms of expectation, and is the dual problem ofan MMSE problem. This connects variational regularization with the statistical problem of MAP estimation. Unsupervised learning. Many end-to-end approaches as well as approaches described above requireclean ground truths x and measurements y, which can be limiting in cases where ground truth data isunavailable or expensive, such as in medical imaging. We are instead concerned with the situation wherewe have a finite amount of noisy data, such as if a clean dataset is corrupted. One such approach is thedeep image prior (DIP), in which the a neural network is fed a random input, and subsequently has itsparameters optimized to recover a noisy measurement with early stopping (Ulyanov et al., 2018). This hasshown remarkable performance without any supervised data, using only the implicit regularization of theneural network architecture. Theoretical results for DIP include optimization dynamics analysis (Heckel& Soltanolkotabi, 2020; Van Veen et al., 2018) and Bayesian interpretations using Gaussian process limits(Cheng et al., 2019). Pajot et al. (2018) propose using the discriminator of a GAN as a regularizer, usingSteins unbiased risk estimator to train using only corrupted measurements (Metzler et al., 2018; Stein, 1981).Noise2Inverse considers the specific case where one noisy measurement can be considered as the averageof multiple noisier measurements to artificially generate more data, such as in limited-angle tomography(Hendriksen et al., 2020). We note that some unsupervised approaches such as Noise2Noise generate anunlimited number of noisy measurements, where averaging out the empirical risks with the noisy targetsleads to an approximation of the empirical risks when training with clean targets (Lehtinen et al., 2018), butwe do not consider this simpler setting. Equivariant imaging (EI) is another unsupervised framework that learns reconstruction functions from onlycompressed measurements (Chen et al., 2021; Pereyra & Tachella, 2024; Scanvic et al., 2023). The frameworkutilizes the fact that the set of plausible signals in X are invariant to a certain group of transformations G. Byrotating the range of the adjoint operator, or constructing virtual operators corresponding to invariances ofthe forward operator, the learned operator is able to learn reconstructions that are approximately equivariant",
  "to the transformations. This greatly mitigates problems arising from nontrivial nullspaces and removesartifacts that are not invariant under transformations in G": "We briefly remark on unsupervised versions of diffusion models, which is an area of intense researchefforts. Diffusion models trained in a supervised manner have been successfully deployed in a plug-and-play manner with a data guidance term, delivering state-of-the-art reconstructions across a variety ofchallenging imaging problems (Chung et al., 2023; Batzolis et al., 2021; Mardani et al., 2024). However,from a Bayesian computation viewpoint, these guided diffusion models are highly inaccurate (e.g., theysignificantly underestimate uncertainty quantification results, see (Pereyra & Tachella, 2024; Thong et al.,2024)). Alternatively, for some problems it is also possible to employ Steins unbiased risk estimator to traindiffusion models directly from measurement data, without ground truth (Kawar et al., 2024; Aali et al., 2023).However, in problems that are ill-posed, issues arise with the null-space of the forward operator, leading toimproper training (Chen et al., 2022a). Other approaches consider transferring powerful pre-trained diffusionmodels from one setting to another, such as change of noise, forward operator, or dataset (Wang et al., 2023;Zhu et al., 2023). As discussed previously, we are instead interested in the case where we do not have accessto multiple copies of corrupted measurements nor a pre-trained model. In this sense, our proposed method isthus able to train priors in strictly harder scenarios. Statistical estimation of parameters. The problem of learning model parameters sits naturally withinthe statistical estimation framework and can be tackled by using powerful statistical inference techniques,such as maximum likelihood estimation. In many cases, such techniques do not require ground truth dataand they are known to outperform common heuristics such as the L-curve criterion (Hansen & OLeary, 1993)and Morozovs discrepancy principle (Morozov, 1966) (e.g., see Vidal et al. (2020) for a detailed comparisonof maximum likelihood estimation and alternative strategies in the context of regularization parameters). In addition, Bayesian statistical approaches allow for statistical interpretations of reconstructions and theirassociated parameters. Alberti et al. (2021) provides a statistically motivated method of learning a Tikhonovpreconditioner based on covariance estimators. Expectation maximization allows for finding locally optimalparameters when there are unobserved latent variables in an iterative manner (Dempster et al., 1977; Robertet al., 1999), which can be applied to tasks such as image segmentation and tomography (Carson et al., 2002;Levitan & Herman, 1987). Vidal et al. (2020) proposes a stochastic approximation method of estimating theoptimal regularisation parameters for TV regularized denoising or hyperspectral unmixing for a single imageusing maximum marginal likelihood estimation, which can then be used for post-hoc reconstruction. Themethod of Vidal et al. (2020) was recently extended by Mbakam et al. (2024) to include the estimation ofunknown parameters in the forward model for semi-blind image deconvolution problems, and to calibratedeep generative priors within a Bayesian image estimation framework in Melidonis et al. (2024). This paperbuilds on this to develop a stochastic approximation scheme to train a convex neural network regularizationterms in a fully unsupervised manner.",
  "In this work, we propose a principled unsupervised method of training convex regularizers with the followingobjectives": "1. (Unsupervised.) Training a regularizing prior using only noisy measurements. This is achieved usingmaximum marginal likelihood estimation. In particular, we do not assume the existence of multiplenoisy copies of the data, such as in Noise2Noise schemes (Lehtinen et al., 2018). 2. (Expressive.) We increase the dimensionality of the regularizer from the order of 101 to 105. ExistingMLE-based methods consider reconstruction for single images by tuning scalar parameters for hand-crafted priors. By using a more expressive parameterization for the regularizer, we can achievebetter performance, and demonstrate that the proposed MCMC-based method is applicable in highdimensions.",
  "Published in Transactions on Machine Learning Research (12/2024)": "Assumption 4 is a necessary condition for the SDEs corresponding to the ULA Algorithms 1 and 2 to haveunique solutions. Assumptions 5 and 6 provide conditions for geometric ergodicity of ULA, which assertsgeometric convergence to the invariant distribution in total variation (Meyn & Tweedie, 1992). Other sufficientconditions for geometric ergodicity of ULA can be found in Durmus & Moulines (2017). We note that theexponential term in Assumption 6 is not necessary, and we show a tighter bound growing linearly in xsimilar to that used in (De Bortoli et al., 2020). We provide here some intuition into how each condition is satisfied by the convex ridge regularizer. Detailedproofs are left to the appendix.Proposition 1. Suppose g takes the form of a convex ridge regularizer (14), where the convex profile functionsi are C1, parameterized using piecewise quadratic splines, and the parameters takes values in some compact. Suppose further that fy(x) is convex and also has Lipschitz gradient, and (y|x) = exp(fy(x)) has finitesecond moment. Then Assumptions 1 to 6 all hold.",
  "Unsupervised Learning by Maximum Marginal Likelihood Estimation": "In this section, we first reformulate the variational regularization framework as a maximum a-posterioriproblem. From this Bayesian interpretation, we consider finding the regularizer parameters using maximummarginal likelihood estimation, which uses only noisy measurements. Motivated by applying gradient ascenton the marginal likelihood, we then introduce the decomposition of the marginal likelihood into posterior andprior expectations as given in Vidal et al. (2020).",
  "x = arg minx[fy(x) + g(x)]": "We can reformulate this as a maximum a-posteriori problem as mentioned in the introduction. Settingfy(x) = log (y|x) as the negative log-likelihood and g(x) = log p(x|), the variational reconstruction isequivalent toxMAP = arg maxxlog [(y|x)p(x|)] = arg maxxlog p(x|y, ),(1) where we use Bayes rule: p(x|y, ) (y|x)p(x|). To apply this relation for reconstruction, we still needto learn . In the unsupervised paradigm, samples from the joint distribution p(x, y) and even the priordistribution p(x) may be unavailable, which leaves us with learning an estimator directly from noisymeasurements sampled from p(y).",
  "= arg maxlog p(y|).(2)": "Here, p(y|) is the marginal likelihood given by marginalizing over data p(y|) =(y|x)p(x|)dx, andp(x|) exp(g(x)) is the density of the prior Gibbs measure. Standard assumptions include the negativelog-likelihood fy(x) = log (y|x) being convex and C1 with Ly-Lipschitz gradient (in x), as well as theadmissible parameter set being compact. One method of maximizing the marginal likelihood is by gradient ascent on , which requires knowledge of log p(y|). However, this is intractable and requires approximation. We now detail how to approximately",
  "Z() =exp(g(x)) dx.(3)": "Then p(x|) = exp(g(x))/Z() is the prior density. While the marginal likelihood p(y|) is intractable,under certain regularity assumptions1, detailed in Proposition 1 and Vidal et al. (2020, Prop. A1), it can bereplaced with a noisy estimate and decomposed in the following manner using Fishers identity (Vidal et al.,2020; Douc et al., 2014):",
  "log p(y|) = Ex|[g(x)] Ex|y,[g(x)].(6)": "Using this decomposition, we are able to use MCMC methods to estimate the prior and normalizing constant,allowing us perform a noisy gradient ascent on using only noisy observations y (and access to the likelihood). In this work, we extend the setup of Vidal et al. 2020 in the following manner:",
  "Jointly Sampling Prior and Posterior": "To compute the gradient of the marginal likelihood, we need to evaluate the expectations in (6). In general, thisis analytically intractable and needs to be done numerically, though properties such as positive homogeneitycan make this easier (Vidal et al., 2020, Sec. 3.3). First assume that both the likelihood (y|x) and regularizer g are C1 (in x). Observe that (6) is a differenceof expectations of g(x) over two probability distributions, namely over the prior p(x|) and posteriorp(x|y, ). Following the setup of Vidal et al. (2020), we consider two Markov chains based on the unadjustedLangevin algorithm (ULA) to approximate these expectations (Dalalyan, 2017; Durmus & Moulines, 2017).For step-size parameters , > 0, the chains are given as follows, where Zk, Zk are i.i.d. standard Gaussianswith identity covariance matrix:",
  ": end for": "In Step 10, the estimated parameter n is updated with gradient ascent on p(y|), where the expectations in(6) are approximated with Monte Carlo integration with mn samples, done in Steps 6 to 9. A projection onto the compact set is then imposed after each update of . The following result states that convergence isattained when the Markov chain updates and the updates for g happen in an alternating fashion. Moreover,a single sample for the Monte Carlo integration over the prior and posterior is sufficient for convergence. Thisis key to computational efficiency, by reducing the number of samples needed from the Markov chain. Theorem 1 (De Bortoli et al. 2020, Theorem 6). Suppose that log p(y|) is convex w.r.t. , and thatAssumptions 1 to 3 hold. Under certain technical Lipschitz conditions and decaying step-sizes, a single sampleis sufficient, i.e., mn = 1 leads to almost sure convergence of (n)nN to some maximizer arg max p(y|). We restate another version of this theorem in a more formal manner in . In particular, we verifythat the required assumptions hold when using the convex ridge regularizer architecture for g. This is donein the constant step-size setting, which instead gives convergence in expectation.",
  "Reflecting Markov Chains": "While the Markov chains (7) sample from biased versions of the target posterior and prior distributions inthe case of unrestricted domains, this does not translate to constrained sampling. Indeed, the natural domainfor images requires that pixel values be non-negative. Negative pixels may cause problems in particular forthe case of Poisson imaging, where the likelihood is zero for negative measurements. Melidonis et al. (2022)consider modifying the chains to force the Markov chain samples to adhere to the non-negativity constraintby projecting or reflecting into the target domain. A minor modification of Equation (7) leads to the followingreflected Markov chains, where the absolute value of a vector |v| is to be taken componentwise:",
  "Rd+ eg(x)dx .(10)": "It can be shown that under suitable assumptions, the reflected SDE admits a unique invariant measure onRd+, and the invariant density is given by (10) (Melidonis et al., 2022, Thm 3.4). The Markov chains (8a) and(8b) are the discrete counterparts of the reflected SDE on Rd+ constructed in (Melidonis et al., 2022). We note that reflection onto the positive orthant is preferred over projection since we work with densities. Inparticular, projection will assign positive probability to the boundaries of the target domain Rd+, which haszero Lebesgue measure. Therefore, the law of the projected SDE will not admit a density with respect to theLebesgue measure, invalidating the requirements of presented theory. We leave the analysis of the reflectedMarkov chains to future work.",
  "Extensions to Datasets Mini-Batching": "SAPGULA, Algorithm 1, is the basic method for solving the MLE problem (2) in the case where g needsonly be trained on single datapoints, where the problem is sufficiently well-posed. The Markov kernels canbe chosen to be either standard ULA (7) or reflected ULA (8) as applied in Vidal et al. (2020); Melidoniset al. (2022) respectively. However, these implementations are limited to reconstructions for single images, aswell as only one or two scalar parameters for . In the case where g is a neural network, the MLE problemfor a single image may be severely overparameterized, leading to slow convergence. Inspired by traditionalmachine learning, we aim to train a neural network regularizing prior with more data, such as on a standardimage dataset like STL-10. The first computational difficulty comes from Step 10 of Algorithm 1, where g is needed. Since computinggradients of g over all images in the dataset is computationally infeasible, mini-batching is necessary inpractice, similarly to how stochastic methods such as SGD or Adam are applied rather than full-batchgradient descent. In this section, we present a straightforward extension of the SAPG scheme to the batchedcase in Algorithm 2, by using multiple posterior Markov chains and changing the order in which the priorMarkov chains are updated. This has the upside of only having to store one mini-batch worth of gradients atany given time, which alleviates memory issues by updating g in a stochastic manner. Suppose that we are given fixed batched noisy measurements {Yb}Bb=1, such as when a noisy image datasetis partitioned. The batched SAPG scheme consists of multiple posterior Markov chains {Xn,b}Bb=1, wherethe posterior chains Xn,b are updated according to R,. Only one prior chain Xn is employed, updatedaccording to R,. One chain is sufficient since the prior Markov kernel R does not depend on the measureddata Yb, saving memory compared to running multiple prior Markov chains. The proposed batched SAPGULA method is summarized in Algorithm 2. This extends the SAPGULAscheme from single images to datasets. The Markov kernels R,n, R,n need only have stationary distributionapproximating the target posterior p(x|y, ) and prior p(x|) respectively, which can be of the form (7), (8),or another kernel which can be chosen based on the regularity properties of the target log-likelihood andprior. Compared to classical supervised training, we make a few approximations in Algorithm 2.The firstapproximation comes from the lack of ground-truth data, which is replaced with the prior given by theregularizer g. Another approximation comes from approximating the expectation over prior/posterior withonly a single sample, motivated by Theorem 1. There will also be bias induced by the choice of ULA forMarkov chain, as well as the joint updates of parameters and Markov chains.",
  "Connection with Adversarial Regularization": "We additionally note a connection with adversarial regularization. Under integrability conditions and byFubinis theorem, (6) shows that the problem of maximizing the marginal likelihood p(y|) in (2) is equivalentto maximizingsupEx|[g(x)] Ex|y,[g(x)].(11) The Bayesian MLE problem (11) can be thought of as maximizing the value of the regularizer weighted overall possible x (given by the prior expectation), while minimizing the regularizer for good reconstructions(given by the posterior expectation). This should be contrasted with adversarial regularization (Lunz et al.,2018), which has loss functions of the form",
  "supExnoisy[g(x)] Extrue[g(x)].(12)": "Comparing, the expectations over the noisy and ground-truth distributions of the adversarial loss (12) arereplaced with versions that depend on the parameter , in particular, the prior and posterior distributionsin (11).The prior can be interpreted as the family of all noisy reconstructions, and the posterior asreconstructions given measurements, which replaces ground-truth images. The Bayesian MLE problem canthus be formulated as adversarial regularization between the prior and posterior distributions. The difference of expectations form of (11) and (12) are also related to the Wasserstein-1 metric, whichis a notion of distance between two finite measures. This connection is noted for example in Arjovskyet al. (2017). For two probability measures on Rd, the definition of the Wasserstein-1 metric W1 andKantorovich-Rubenstein duality result are follows (Ambrosio et al., 2013; Villani, 2009):",
  "g d g d,(13)": "where (, ) is the set of all couplings, i.e. probability measures on Rd Rd with marginals and respectively. Therefore, if the suprema in (11) and (12) were instead over g that are 1-Lipschitz, the problemsare reduced to finding the so-called Kantorovich potentials that achieve the supremum in (13) between theprior and posterior distributions, or the noisy and true distributions respectively.",
  "g(x) = W(Wx),(15)": "where W = [w1 ... wC] RCd is linear, and : RC RC is a component-wise activation function withcomponents i = i : R R. Note that due to the convexity of i, the derivatives i are increasing. Byrestricting the parameters such that i are strictly increasing, the CRR can be made to be uniformly stronglyconvex. For ease of notation, first suppose we have sufficient regularity such that Fishers identity (11) holds, whichwill be justified in Proposition 1 and Assumption 3. Let the negative log joint density log p(x, y|) be givenbyE(x) := fy(x) + g(x).(16) Note that xE(x) is the diffusion term of the Langevin step (7a) from posterior p(x|y, ), while xg(x)is the diffusion term of the Langevin step (7b) from prior p(x|). We will use ergodicity of both chains todemonstrate (biased) convergence in expectation of . In the following theorem, we consider the scenario where a fixed mn = 1 is used in Algorithm 1 for theMonte Carlo integration, and a fixed step-size > 0 is used for the Markov chains. Theorem 2 summarizesTheorems 4-6 of De Bortoli et al. (2021), which concern the convergence properties of the SOUL algorithm.An extension to nonconvex log p(y|) is given when is a sufficiently regular manifold in De Bortoli et al.(2021, Appendix B), achieving (a.s.) convergence to some point with log p(y|) lying on the normalcone of at . Theorem 2. (De Bortoli et al., 2021, Theorem 4, 5, 6).Assume that Assumptions 1 to 6 hold and log p(y|) is convex w.r.t. . Assume further that the step-sizes (n)nN satisfy supnN n < 1/L, andthat min(1, 2m2) where m2 is the tail coercivity constant in Assumption 5. Then for any n N,",
  ").(17)": "Theorem 2 bounds the bias of the SAPG method in terms of the step-size of the Markov chains. This coversthe Gaussian deconvolution experiments in the next section, but not the Poisson denoising experiments whichemploy reflected ULA. However, we believe that the SAPG algorithm is also convergent when the Markovkernel is given by reflected ULA, and refer proof of convergence to future work. We note that almost sure convergence can also be obtained by using decreasing step-sizes or increasingbatch-size mn (De Bortoli et al., 2021, Thm. 1-3). For the sake of simplicity and computational efficiency, weconsider only constant step-sizes n and , , and fix mn = 1 for our experiments. For an empirical studyinto the bias of the SAPG method for low-dimensional (where ground-truth maximum likelihood estimatorsare known), we refer to (De Bortoli et al., 2021; Vidal et al., 2020). These works find that the bias is notsignificant if the hyperparameter guidelines are followed, as we do in our experiments.",
  "Experiments": "In the following image reconstruction experiments, we will compare the proposed unsupervised MLE methodAlgorithm 2 with the t-gradient-step supervised training method as detailed in Goujon et al. (2022). We usethe same choice of architecture as Goujon et al. (2022) extended from grayscale images to color images. In(14) and (15), W is modelled using a convolution, and the i are parameterized using linear splines. Thisresults in i being degree-2 splines, namely piecewise quadratic with continuous derivatives. We considerhaving 32 splines for our parameterization, and W being convolutions with 3 (color) input channels and 32output channels. Additional implementation details including the choice of W can be found in Appendix B. The supervised gradient-step (GS) training method of Goujon et al. (2022) involves performing gradient stepsto minimize the variational functional induced by the convex regularizer, which is then trained to minimizethe 1 distance between the reconstructed image and the ground truth. We compare the supervised GStraining to our proposed unsupervised training (SAPG), which does not require noise-free images. Equivariant imaging poses another interesting baseline to compare against for unsupervised learning. Weuse the setup in Scanvic et al. (2023), which recently extends the EI framework using scale transforms, usedin cases where the forward operator and noise models are equivariant under the standard rotations andreflections. The learned reconstruction of the EI model takes the form of an end-to-end neural network,using the state-of-the-art SwinIR architecture for image reconstruction, using 11.5M parameters (Liang et al.,2021). We train using the given parameters for up to 200 epochs, but use early stopping at 25 epochs due todivergence issues during training. For baselines that do not rely on machine learning, we compare with the total variation prior g(x) = x1(Rudin et al., 1992), as well as using a deep image prior (DIP) for reconstruction (Tachella et al., 2021;Ulyanov et al., 2018). For TV regularization, the regularization parameter is chosen via a grid search tomaximize PSNR with respect to the ground truth. We use TV to additionally compare with the single-imageself-supervised approach of (Vidal et al., 2020), which automatically finds the regularization parameterusing MLE. Note that the reported quality for TV will be higher than if (Vidal et al., 2020) is used, due tothe comprehensive search. For DIP, we compare using a U-Net as well as a convolutional neural network,optimized using Adam and gradient descent as in Tachella et al. (2021). The reported PSNR is taken to bethe highest with respect to the ground truth along the optimization trajectory. To evaluate our MLE-trained regularizers, we consider the posterior mean and MAP estimators under theposterior chain. The posterior mean is evaluated after 2 104 and 1 105 iterations of the posterior Markovchains with 5 103 iterations to warm-start, labeled MMSE in the figures and tables with superscriptsindicating the number of posterior samples. To compute the MAP estimators of our trained regularizers, weminimize the modified negative log-posterior (x) = fy(x) + g(x), where fy is the negative log-likelihood(fidelity) function corresponding to the corrupted data y, and g is the learned convex regularizer, and > 0is a regularization parameter. The regularization parameter is chosen via a grid search {0.1, 0.2, ..., 1.0}to maximize PSNR after training. To compute the MAP estimate, the negative log-posterior is minimizedusing the Adam optimizer for up to 104 iterations due to being faster than gradient descent, with learningrate 103 and other parameters as default. We report the training and testing time in Appendix C. To explore the strength of the unsupervised SAPG training method along with the supervised gradient-stepmethod of Goujon et al. (2022), we additionally compared with a weakly-supervised training regime, bywarm-starting the regularizer using adversarial training based on Lunz et al. (2018). This uses the formulation(12) with the noisy distribution being corrupted images, and is labelled as WS-SAPG in following tables. Theweakly-trained regularizer is first provided ground truths of a fixed 2% of the training images, and the CRRis trained to be maximized on the corresponding corrupted images and minimized on the ground truth. Theloss for warm-starting can be expressed as follows, where the last term controls the Lipschitz constant of g.",
  "(j) Std dev": ": Visual comparison of reconstructions for Poisson denoising. The proposed unsupervised SAPGmethod, as shown in subfigures (h) and (i) both show significant denoising, but with the presence of artifacts.EI has color artifacts while the supervised GS method has more textural artifacts. DIP has a strong smoothingeffect, but also induces strange visual artifacts around the target as shown in subfigure (d).",
  "Gaussian Deconvolution": "The first set of experiments is Gaussian deconvolution on the natural image dataset STL-10. The imagesconsist of 96 96 color images, which are then corrupted with a Gaussian blur with kernel size 5 and blurstrength 1, followed by additive 5% Gaussian noise. The negative log-likelihood for noisy blurred image y isthus given by",
  "where A is the blur kernel. For SAPG, the step-sizes , for the likelihood and prior Markov chains R,,R, respectively are given by = = 1e4": "details the reconstruction quality in terms of PSNR of the proposed SAPG method as well as varioussupervised and unsupervised baselines. We observe that the proposed unsupervised SAPG method is able toperform closely with the supervised t-gradient-step method, with a gap of only 0.5dB. Moreover, we observethat the MAP estimate with the learned reconstruction priors are generally better than the posterior meanestimates. The SAPG-learned prior also is competitive with/better than other priors such as TV or DIP,",
  "the latter of which still has a lack of theoretical properties. Adding weak supervision does not significantlychange the performance here": "shows visual comparisons of the various methods applied to a corrupted test image. EI has the bestperceptual quality out of the tested images with the powerful end-to-end parameterization. The reconstructionof the proposed method is reasonable, but has artifacts compared to the supervised gradient step method,possibly due to the ill-posedness of the problem. We are also able to plot the standard deviation of theMarkov chain samples as seen in j, clearly showing areas of interest around the edges.",
  "Poisson Denoising": "Poisson denoising naturally arises in low-photon imaging, where the measurement takes integer pixel values.We can model the measurement using a Poisson random variable y Pois(x) taken pixel-wise over an imagespace Rn+, where is a parameter chosen such that the expected mean pixel intensity of y is a fixed meanintensity value (MIV). The forward operator is set to be the identity. In this case, the Poisson negativelog-likelihood for positive-integer-valued measurement y Pois(x) is given as follows, where + is the",
  "xfy(x) = 1I y/x,": "The Poisson log-likelihood does not have a globally Lipschitz gradient, degenerating around the boundaryof Rn+ when x is near 0. This makes the Poisson problem more difficult as compared to the Gaussian casedue to requiring both approximating the log-likelihood for zero-valued pixels, as well as needing a smallstep-size. Therefore, we use the following modified negative log-likelihood, for some mollification parameterb > 0 (Melidonis et al., 2022),",
  "xfy(x) = 1I y/(x + b)": "The introduction of b > 0 mollifies the likelihood near zeros and makes xfy(x) Lipschitz on Rn+. We use theparameter b = MIV/100 as suggested in Melidonis et al. (2022), where the mean intensity value (MIV) is themean of y Pois(x). The parameter is chosen such that the mean intensity value is set to be MIV = 25for light Poisson denoising. For SAPG, the step-sizes for the likelihood and prior Markov chains are givenby = 5e6, = 1e5 respectively. For EI, the best performance is obtained by modifying the trainingloss to use the Poisson unbiased risk estimator instead of Steins unbiased risk estimator, and using rotationtransforms instead of scale transforms (Chen et al., 2022a). compares the PSNR of the recovered images using the proposed method against the previouslydetailed baselines. We again observe a reasonable gap of 0.15dB between our unsupervised method and thesupervised method with the same architecture. however still demonstrates the presence of somevisual artifacts of our unsupervised method when compared to its supervised t-gradient-step counterpart.Moreover, the CRR-based methods exhibit patchy artifacts that are similar to the ground-truth image, whileEI exhibits varying color artifacts. For this problem, we achieve much closer performance to equivariantimaging compared to Gaussian deconvolution. This highlights the difficulty of Poisson denoising for end-to-endmodels, as observed previously due to the high Lipschitz constants and large data range, and an empiricalbenefit of variational regularization when dealing with high-variance noise.",
  "Transfer to Different Forward Operator": "In addition to the Gaussian deconvolution experiments, we consider robustness of the learned models withrespect to changes in forward operator. We include the change in forward operator to provide some empiricaljustification to the choice of learned regularizer as opposed to end-to-end methods. We evaluate the trainedmodels on a 5 5 uniform blur kernel with the same additive 5% Gaussian noise. In particular, we considersupervised and unsupervised CRR, as well as the end-to-end EI method. The models trained for Gaussiandeconvolution in .1 are applied directly to uniform deconvolution, allowing for a change of forwardoperator in the fidelity for the variational model-based CRR methods. shows the reconstruction results for transferring the learned models between different tasks. Comparedto the learned regularizers and TV, we observe a significantly larger drop in performance from the EI model,which is trained on a specific forward operator, which introduces more blur artifacts. This may be dueto the sensitivity of end-to-end networks to changes in distribution. On the other hand, the model-basedgradient step reconstruction still produces reasonably good results, due to the underlying variational form.The unsupervised versions have similar performance, albeit with added visual artifacts. This may be due toimage prior components that are difficult to learn from only noisy patches. We note that within learning convex ridge regularizers, our SAPG method drops less PSNR than the supervisedgradient-step method when changing forward operator, suggesting better generalization. While both methodsutilize the forward operator during training, the gradient-step training unrolls through 10 optimizationiterations, whereas the unsupervised method uses it as a consistency term. One possible explanation is thatthe Langevin diffusion in the unsupervised method expands the available data to also cover some small changein forward operator, while the supervised method sees only data that is provided from the original forwardoperator. We additionally note that better generalization under change of forward operator can be achieved usingunrolling schemes, which allow for the forward operator to be explicitly specified during the testing phase(Monga et al., 2021; Zhao et al., 2023). Such unrolling methods are typically trained in the supervised regime(Li et al., 2020b). While we found that a direct application of the unsupervised end-to-end EI loss in Scanvicet al. (2023) to an unrolled architecture led to unsatisfactory results in our deconvolution experiments, amore nuanced approach to constructing more transferable architectures could be an interesting direction forfuture work.",
  "Conclusion": "We proposed an unsupervised method of training a convex neural network-based image prior based on thestochastic approximate proximal gradient algorithm, extending previous work in both model expressivenessand dataset size. Prior works consider a family of total variation priors, here we consider a parameterizationwith significantly more parameters. Experiments demonstrate that the proposed method produces priorsthat are near competitive when compared to the alternative supervised training method for various imagecorruption operators, maintaining significantly better generalization properties when compared to end-to-endmethods. Moreover, we present convergence theory for the proposed Markov chains with the choice of convexridge regularizer architecture. The proposed method has two main limitations, namely runtime for training and inference, as well as theconvexity assumption on the regularizer. The runtime is mainly due to slow convergence of the MCMC andadditional stochasticity when training the CRR. A detailed comparison of the train and test runtimes ofthe compared methods is given in Appendix C, where our method takes an order of magnitude longer. Theconvexity assumption of the regularizer allows for convergence of SAPG, but may be restrictive in terms ofexpressiveness. Interesting future works could include a convergence analysis in the discrete case or with accelerated versionsof the training algorithm such as Nesterov acceleration or Adam instead of SGD, or alternative Markov kernelslike SK-ROCK instead of ULA (Pereyra et al., 2020). Other possible directions are to add an informative prioron , which may change the sampling dynamics, or devising fully unsupervised methods for warm-startingtraining. We also believe that the strong convexity assumption of the convex ridge regularizer can be dropped,due to the simple structure and coercive tails. A promising alternative is weak convexity, which has beenshown to significantly outperform similar convex models (Shumaylov et al., 2023). Future work could includetheoretical analysis of the SAPG method in this setting using techniques from Durmus & Moulines (2017);De Bortoli et al. (2021). Another interesting work would be to extend this work to learning diffusion modelsfrom single copies of noisy measurements. HYT was supported by GSK.ai and the Masason Foundation.MP was funded by the UK Researchand Innovation (UKRI) Engineering and Physical Sciences Research Council (EPSRC) through grantsEP/T007346/1, EP/V006134/1 and EP/W007673/1. CBS acknowledges support from the Philip LeverhulmePrize, the Royal Society Wolfson Fellowship, the EPSRC advanced career fellowship EP/V029428/1, EPSRCGrants EP/S026045/1 and EP/T003553/1, EP/N014588/1, EP/T017961/1, the Wellcome Innovator Awards215733/Z/19/Z and 221633/Z/20/Z, the European Union Horizon 2020 research and innovation programmeunder the Marie Skodowska-Curie Grant agreement No. 777826 NoMADS, the Cantab Capital Institute forthe Mathematics of Information and the Alan Turing Institute. Asad Aali, Marius Arvinte, Sidharth Kumar, and Jonathan I Tamir. Solving inverse problems with score-basedgenerative priors learned from noisy data. In 2023 57th Asilomar Conference on Signals, Systems, andComputers, pp. 837843. IEEE, 2023. Giovanni S Alberti, Ernesto De Vito, Matti Lassas, Luca Ratti, and Matteo Santacesaria. Learning theoptimal Tikhonov regularizer for inverse problems. Advances in Neural Information Processing Systems,34:2520525216, 2021. Luigi Ambrosio, Alberto Bressan, Dirk Helbing, Axel Klar, Enrique Zuazua, Luigi Ambrosio, and NicolaGigli. A users guide to optimal transport. Modelling and Optimisation of Flows on Networks: Cetraro,Italy 2009, Editors: Benedetto Piccoli, Michel Rascle, pp. 1155, 2013.",
  "Daniela Calvetti and Erkki Somersalo. Inverse problems: From regularization to Bayesian inference. WileyInterdisciplinary Reviews: Computational Statistics, 10(3):e1427, 2018": "Marcello Carioni, Subhadip Mukherjee, Hong Ye Tan, and Junqi Tang. Unsupervised approaches based onoptimal transport and convex analysis for inverse problems in imaging. arXiv preprint arXiv:2311.08972,2023. Bradley P Carlin, Alan E Gelfand, and Adrian FM Smith. Hierarchical Bayesian analysis of changepointproblems. Journal of the royal statistical society: series C (applied statistics), 41(2):389405, 1992. Chad Carson, Serge Belongie, Hayit Greenspan, and Jitendra Malik. Blobworld: Image segmentation usingexpectation-maximization and its application to image querying. IEEE Transactions on pattern analysisand machine intelligence, 24(8):10261038, 2002.",
  "Junyu Chen, Eric C Frey, Yufan He, William P Segars, Ye Li, and Yong Du. Transmorph: Transformer forunsupervised medical image registration. Medical image analysis, 82:102615, 2022b": "Zezhou Cheng, Matheus Gadelha, Subhransu Maji, and Daniel Sheldon. A bayesian perspective on the deepimage prior. In Proceedings of the IEEE/CVF Conference on Computer Vision and Pattern Recognition,pp. 54435451, 2019. Hyungjin Chung, Jeongsol Kim, Michael Thompson Mccann, Marc Louis Klasky, and Jong Chul Ye. Diffusionposterior sampling for general noisy inverse problems. In The Eleventh International Conference onLearning Representations, 2023.",
  "Bahjat Kawar, Noam Elata, Tomer Michaeli, and Michael Elad. Gsure-based diffusion model training withcorrupted data. Transactions on Machine Learning Research, 2024": "Erich Kobler, Alexander Effland, Karl Kunisch, and Thomas Pock. Total deep variation for linear inverseproblems. In Proceedings of the IEEE/CVF Conference on computer vision and pattern recognition, pp.75497558, 2020. Daniel Kuhn, Peyman Mohajerin Esfahani, Viet Anh Nguyen, and Soroosh Shafieezadeh-Abadeh. Wassersteindistributionally robust optimization: Theory and applications in machine learning. In Operations research& management science in the age of analytics, pp. 130166. Informs, 2019. Rmi Laumont, Valentin De Bortoli, Andrs Almansa, Julie Delon, Alain Durmus, and Marcelo Pereyra.Bayesian imaging using plug & play priors: when Langevin meets Tweedie. SIAM Journal on ImagingSciences, 15(2):701737, 2022. Jaakko Lehtinen, Jacob Munkberg, Jon Hasselgren, Samuli Laine, Tero Karras, Miika Aittala, and TimoAila. Noise2noise: Learning image restoration without clean data. In International Conference on MachineLearning, pp. 29652974. PMLR, 2018. Emanuel Levitan and Gabor T Herman. A maximum a posteriori probability expectation maximizationalgorithm for image reconstruction in emission tomography. IEEE transactions on medical imaging, 6(3):185192, 1987.",
  "Housen Li, Johannes Schwab, Stephan Antholzer, and Markus Haltmeier. Nett: Solving inverse problemswith deep neural networks. Inverse Problems, 36(6):065005, 2020a": "Yuelong Li, Mohammad Tofighi, Junyi Geng, Vishal Monga, and Yonina C Eldar. Efficient and interpretabledeep blind image deblurring via algorithm unrolling. IEEE Transactions on Computational Imaging, 6:666681, 2020b. Jingyun Liang, Jiezhang Cao, Guolei Sun, Kai Zhang, Luc Van Gool, and Radu Timofte. Swinir: Imagerestoration using swin transformer. In Proceedings of the IEEE/CVF international conference on computervision, pp. 18331844, 2021.",
  "Subhadip Mukherjee, Sren Dittmer, Zakhar Shumaylov, Sebastian Lunz, Ozan ktem, and Carola-BibianeSchnlieb. Learned convex regularizers for inverse problems. arXiv preprint arXiv:2008.02839, 2020": "Subhadip Mukherjee, Marcello Carioni, Ozan ktem, and Carola-Bibiane Schnlieb. End-to-end reconstructionmeets data-driven regularization for inverse problems. Advances in Neural Information Processing Systems,34:2141321425, 2021. Subhadip Mukherjee, Andreas Hauptmann, Ozan ktem, Marcelo Pereyra, and Carola-Bibiane Schnlieb.Learned reconstruction methods with convergence guarantees: A survey of concepts and applications. IEEESignal Processing Magazine, 40(1):164182, 2023.",
  "Marcelo Pereyra. Revisiting maximum-a-posteriori estimation in log-concave models. SIAM Journal onImaging Sciences, 12(1):650670, 2019": "Marcelo Pereyra and Julin Tachella. Equivariant bootstrapping for uncertainty quantification in imaginginverse problems. In International Conference on Artificial Intelligence and Statistics, pp. 41414149.PMLR, 2024. Marcelo Pereyra, Luis Vargas Mieles, and Konstantinos C Zygalakis. Accelerating proximal Markov chainMonte Carlo by using an explicit stabilized method. SIAM Journal on Imaging Sciences, 13(2):905935,2020.",
  "Dmitry Ulyanov, Andrea Vedaldi, and Victor Lempitsky. Deep image prior. In Proceedings of the IEEEconference on computer vision and pattern recognition, pp. 94469454, 2018": "Dave Van Veen, Ajil Jalal, Mahdi Soltanolkotabi, Eric Price, Sriram Vishwanath, and Alexandros G Dimakis.Compressed sensing with deep image prior and learned regularization. arXiv preprint arXiv:1806.06438,2018. Singanallur V Venkatakrishnan, Charles A Bouman, and Brendt Wohlberg. Plug-and-play priors for modelbased reconstruction. In 2013 IEEE global conference on signal and information processing, pp. 945948.IEEE, 2013. Ana Fernandez Vidal, Valentin De Bortoli, Marcelo Pereyra, and Alain Durmus. Maximum likelihoodestimation of regularization parameters in high-dimensional inverse problems: An empirical Bayesianapproach Part I: Methodology and experiments. SIAM Journal on Imaging Sciences, 13(4):19451989,2020.",
  "Darren J Wilkinson. Stochastic modelling for systems biology. Chapman and Hall/CRC, 2018": "Kai Zhang, Yawei Li, Wangmeng Zuo, Lei Zhang, Luc Van Gool, and Radu Timofte. Plug-and-play imagerestoration with deep denoiser prior. IEEE Transactions on Pattern Analysis and Machine Intelligence, 44(10):63606376, 2021. Yanan Zhao, Yuelong Li, Haichuan Zhang, Vishal Monga, and Yonina C Eldar. A convergent neural networkfor non-blind image deblurring. In 2023 IEEE International Conference on Image Processing (ICIP), pp.15051509. IEEE, 2023.",
  "In addition, (, x) H(x) and (, x) H(x) are measurable": "Assumptions 1 and 2 are standard compactness and Lipschitz assumptions in the literature, and we note thatAssumption 3 holds if Fishers identity (6) holds. We additionally require some assumptions to guaranteeergodicity of the two Markov chains in Equation (7). The following assumptions correspond to L1-3 inDe Bortoli et al. (2021). Assumption 4. (Uniformly Lipschitz gradients.) For any , admits a probability density functionwith respect to to the Lebesgue measure proportional to x exp (g(x)) and admits a probability densityfunction with respect to to the Lebesgue measure proportional to x exp (E(x)). In addition, (, x) g(x)and (, x) E(x) are continuous, x g(x) and x E(x) are differentiable for all and there existsLg 0, LE 0 such that for any x1, x2 Rd,",
  "We have = p(x|), = p(x|y, ), and H = H = g. This is also given in De Bortoli et al. (2020,Remark 2)": "Assumption 4: Since is compact and g are piecewise quadratic, the ridge regularizers have uniformlyLipschitz gradient (Goujon et al., 2022, Prop. IV.1.). The condition for E holds as well since fy(x) hasLipschitz gradient. See Lemma 1. Assumption 5: For simplicity, we can enforce the convex ridge regularizer to strongly convex by a choice ofspline parameters. In this case, E = fy + g is also strongly convex, and thus for sufficiently large x, isbounded below by c1x2. Apply Youngs inequality and taking sufficiently large c, R1 for the desired tailcondition. In general, we need only strong monotonicity of the gradient for sufficiently large x w.r.t. theorigin. See Lemma 2.",
  "A.2Assumption 4 for CRRs": "Assumption 4. (Uniformly Lipschitz gradients.) For any , admits a probability density functionwith respect to to the Lebesgue measure proportional to x exp (g(x)) and admits a probability densityfunction with respect to to the Lebesgue measure proportional to x exp (E(x)). In addition, (, x) g(x)and (, x) E(x) are continuous, x g(x) and x E(x) are differentiable for all and there existsLg 0, LE 0 such that for any x1, x2 Rd,",
  "ii(wi x),(27)": "where W = [w1 ... wC] RCd with learnable weights wi Rd, and i : R R are convex profile functions(ridges). In practice, we use matrices for wi, so that wi x represents a vector, and apply i component-wise.This can be justified by using duplicate i and weight-tying. Choice of W. As detailed in Section VI.A in Goujon et al. (2022), W is taken as the composition of twozero-padded convolutions with window size 7 7, with 8 and 32 output channels respectively. While theexperiments in Goujon et al. (2022) are originally in black-and-white, we extend to color images by using 3input channels instead of 1 for the first convolution. Choice of ridges i. As in Goujon et al. (2022), we parameterize each components derivative i = i :R R as a linear spline, and subsequently define the convex profile function as an integral i(t) = t0 i(s) ds.To parameterize the linear splines i, we define the values at equispaced knots, clamping during training tomaintain strictly increasing slopes, ensuring strong convexity of the ridge i. We use 21 equally distant knots(centered at 0), with distance = 0.01 between them. Values defined between knots are given by linearinterpolation, and values past the endpoints are given by linear extension. In particular, we have i(t) c+,itas t + and i(t) c,it as t for some c,i > 0.",
  "We justify Assumption 2 and the third claim for Assumption 3 in Proposition 1 by computing the derivativeof g with respect to its parameters": "Fix a CRR architecture, where the linear spline i = i has (fixed) knots at tK, ..., tK, taking (learnable)values cK, ..., cK. We assume that the knots are equispaced tk = k for k = K, ..., K, that c0 = 0, relaxingthese assumptions are simple and do not significantly change the proof. For strong convexity, we requirethat the sequence cK, ..., cK is strictly increasing. We can thus reparameterize in terms of spline differencesdK, ..., dK that are lower bounded by some constant m > 0 to enforce strong convexity:",
  "Kj=1(dj dj1)ReLU2(t tj1)/t 0 1j=K(dj dj+1)ReLU2(tj+1 t)/t 0 .(29)": "Given y Rdy, fix any int() and x Rd. The parameters consist of the weights wi and spline valuescK,i, ..., cK,i corresponding to spline i = i. In the following, we drop the index i for notational convenience.We can compute derivatives with respect to spline parameters as follows. Suppose wx [tl, tl+1), where wedefine tK+1 = +. We can differentiate with respect to the spline parameters using (29)",
  "ReLU2(wx tj1) ReLU2(wx tj).(30)": "Similar computations hold if instead wx < 0, and define tK1 = . Note that these bounds also holduniformly in a small ball around , as wx is continuous in w. Moreover, this grows linearly in wx. Wecan also differentiate with respect to the weight vector w and get a sum of ReLU units, which again growslinearly in x: assuming wx is positive,",
  "A similar expression holds if wx is negative. This expression is asymptotically quadratic in x": "To verify Assumptions 3 and 6 in Proposition 1, we need only consider the derivatives (30) and (31). Wehave that g(x) is asymptotically bounded by a quadratic in x, as required for Fishers identity givenfinite second moment. Moreover, since the derivatives are sums and products of ReLU and squared ReLUunits, Lipschitz continuity of log p(y|) on compact comes from the dominated convergence theorem.",
  "CTime comparison": "For TV, we report the time required to reconstruct 50 images using 5000 iterations of gradient descent for afixed regularization parameter. The parameter is chosen via a manual grid search to maximize PSNR. For DIP, we compared 4 different training settings (2 architectures and 2 initializations) and reported thebest metrics for the Gaussian deconvolution and Poisson denoising experiments. We report the average timerequired to reconstruct using DIP by dividing the total time to reconstruct 50 images using all 4 methods by4."
}