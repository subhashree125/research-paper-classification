{
  "Abstract": "Regression models often fail to generalize effectively in regions characterized by highlyimbalanced label distributions. Previous methods for deep imbalanced regression rely ongradient-based weight updates, which tend to overfit in underrepresented regions. Thispaper proposes a paradigm shift towards in-context learning as an effective alternative toconventional in-weight learning methods, particularly for addressing imbalanced regression.In-context learning refers to the ability of a model to condition itself, given a prompt sequencecomposed of in-context samples (input-label pairs) alongside a new query input to generatepredictions, without requiring any parameter updates. In this paper, we study the impactof the prompt sequence on the model performance from both theoretical and empiricalperspectives. We emphasize the importance of localized context in reducing bias withinregions of high imbalance. Empirical evaluations across a variety of real-world datasetsdemonstrate that in-context learning substantially outperforms existing in-weight learningmethods in scenarios with high levels of imbalance.",
  "Introduction": "Imbalanced data distributions, common in the real world, pose significant challenges to the generalizationof conventional deep learning models due to variance across minority labels and bias toward majoritylabels (Zhang et al., 2023). While numerous studies have addressed learning from imbalanced data, most ofthem focus on classification tasks (Yang & Xu, 2020; Wang et al., 2024; Zhang et al., 2022; Yang et al., 2024).Recent work emphasizes that the continuity of the label space, and the relationship between features andlabels (Shin et al., 2022), make imbalanced regression a fundamentally different problem from imbalancedclassification (Yang et al., 2021; Ren et al., 2022). Imbalanced regression problems are critical in manyfields. For instance, in computer vision, age estimation datasets are often imbalanced, with fewer samples foryounger age groups due to legal and ethical limitations, while older age groups are underrepresented as thepopulation naturally declines with age. Similarly, in engineering design, the distribution of designs is oftenskewed, with the most desirable characteristics at the tail end of the distribution. This means that the regionof greatest interest lies in the minority samples of the distribution. Enhancing model performance in theselow-data regions is essential for achieving more accurate and reliable outcomes across these applications. To address the specificities of deep imbalanced regression, two main approaches have been proposed: samplere-weighting and embedding space regularization. Sample re-weighting techniques, as those proposed by Yanget al. (2021) and Steininger et al. (2021), apply kernel density estimation to smooth the label distribution. Thismethod leverages local dependencies by enforcing similarity between nearby labels. Alternatively, embedding",
  "Published in Transactions on Machine Learning Research (10/2024)": "Alex Wang, Amanpreet Singh, Julian Michael, Felix Hill, Omer Levy, and Samuel Bowman. GLUE: Amulti-task benchmark and analysis platform for natural language understanding. In Tal Linzen, GrzegorzChrupaa, and Afra Alishahi (eds.), Proceedings of the 2018 EMNLP Workshop BlackboxNLP: Analyzingand Interpreting Neural Networks for NLP, pp. 353355, Brussels, Belgium, November 2018. Associationfor Computational Linguistics. doi: 10.18653/v1/W18-5446. URL Zitai Wang, Qianqian Xu, Zhiyong Yang, Yuan He, Xiaochun Cao, and Qingming Huang.A unifiedgeneralization analysis of re-weighting and logit-adjustment for imbalanced learning. Advances in NeuralInformation Processing Systems, 36, 2024.",
  "Related works": "Imbalanced regression: The continuity in label space makes imbalanced regression different from imbalancedclassification. One potential option is to discretize the continuous label space and apply methods typicallyused in imbalanced classification. However, this requires specifying a minimum acceptable error threshold forthe discretization process (Ren et al., 2022). Moreover, the continuity of the label space can provide additionalinformation about the relationships between data instances, contrasting with the categorical distinctions inclassification tasks (Yang et al., 2021). Various strategies have been proposed to refine how relationships in both label and feature spaces are handledin regression. Label Distribution Smoothing (LDS) (Yang et al., 2021) and DenseLoss (Steininger et al., 2021)employed kernel density estimation to derive the true label density from empirical data, thereby smoothingand reweighting the data labels. Feature Distribution Smoothing (FDS) (Yang et al., 2021) applied similarprinciples to the feature space and performs distribution smoothing by transferring the first two featurestatistics between nearby target labels. A different direction to overcome deep imbalanced regression is tolearn additional tasks to regularise the model feature representation. Different types of tasks have beenproposed to capture the relationships between features and labels at local and global levels (Gong et al., 2022;Keramati et al., 2024; Wang & Wang, 2024). For instance, Gong et al. (2022) proposed ranking similarityregularization, while Keramati et al. (2024) adapted contrastive learning to regression tasks by improvingthe continuity of the feature space. In a recent study, Wang & Wang (2024) leveraged deep evidentialregression (Amini et al., 2020)(a framework that learns to predict uncertainty in a single forward pass) andproposed leveraging data with similar target labels to compute the variational distribution of the latentrepresentation, imposing probabilistic reweighting on imbalanced data. However, these deep learning methods predominantly relied on in-weight learning, wherein achievinghigh-quality representations in a long-tailed setting is difficult because the features in the minority can beeasily overfitted. This issue was highlighted by Ren et al. (2022), as the Mean Square Error (MSE) loss usedfor training in imbalanced regression introduces biases to the majority region. Alternative learning strategiesmay potentially help overcome the limitation of in-weight learning in minority regions. In-context Learning (ICL) in regression:ICL, based on Transformer architecture, enables a pre-trainedmodel to learn a new task with minimal examples (Vaswani et al., 2017; Brown et al., 2020). The remarkablesuccess of transformers and their ability to do in-context learning shown in natural language processinghas inspired a line of research exploring the algorithmic power of transformers. Notably, Garg et al. (2022)investigated transformers in in-context regression tasks, ranging from learning linear regression to morecomplex function classes. Subsequent works have suggested that the attention mechanism in the transformermay mimic various optimization algorithms such as gradient (Akyurek et al., 2023; Von Oswald et al., 2023;Ahn et al., 2024; Mahankali et al., 2024; Bai et al., 2023). From a Bayesian perspective, Xie et al. (2022) suggested that in-context learning is a form of implicit Bayesianinference. Building on this idea, Mller et al. (2022) trained transformer models using Prior Fitted Networks,where data sampled from a prior distribution enables these models to approximate the posterior predictivedistribution during inference for tabular data (van Breugel & van der Schaar, 2024). A theoretical foundationfor these models was further developed by Nagler (2023) with a focus on classification tasks. However, thepractical implementation of ICL in regression, particularly under conditions of extreme data imbalance orwhen dealing with real-world data, remains underexplored.",
  "Problem Setting": "We address a regression problem where an input feature x X Rd is mapped to a label y Y = R.More specifically, in the imbalanced regression scenario, the training set Ds = {(xi, yi)}nsi=1 and the test setDt = {(xi, yi)}nti=1 are sampled from distinct joint distributions, ps(x, y) and pt(x, y), referred to as the sourceand target distributions, respectively. In our setup, the source distribution typically exhibits a skewed label",
  "distribution ps(y), while the target distribution is uniformly spread across the range of target values pt(y).The goal is to improve the prediction on the tail regions": "In-Context LearningConsider a transformer model f which is capable of in-context learning. Thiscapability is demonstrated when the model can accurately approximate the output yquery for a new queryinput xquery based on a sequence of in-context examples. This sequence, called a prompt, is given by(x1, y1, . . . , xn, yn, xquery). The training set Ds can serve as a basis for the prompt sequence. Given a newquery sample xquery from the test set Dt, the model predicts yquery = f(xquery | Ds). In the followingsections, we evaluate the circumstances under which yquery can be accurately similar to the true label yquery.",
  "Convergence": "In the following sections, we delve into the theoretical analysis of the model convergence in the general case.We show that in imbalance scenarios, using the entire training set can introduce bias, primarily due to theoverrepresentation of the majority samples. We introduce a localized version aimed at alleviating this biasand provide a theoretical bound for the expected prediction error, showing that the behavior differs dependingon whether points are from majority or minority regions.",
  "= VarDn[f(x | Dn)] +Bias2Dn[f(x | Dn)]+ 2(1)": "Proposition 3.1 c-Lipschitz Continuity: Consider an infinitely large training set Ds, from which subsetsDn and Dn are independently sampled. Assume that the label noise is constant. Given the observationfrom Garg et al. (2022) that error decreases as more samples are given as context, we can consider that themodel f, is c-Lipschitz, with c = (c1, . . . , cn) Rn+ where ci = i for each i {1, . . . , n}, with as apositive constant and > 0.5:",
  "Variance :Under the assumption of Proposition 1, the variance of the models prediction should decreaseas more samples are provided": "Proposition 3.3 Convergence to training label distribution: If we assume that the attention blocks inmodel f are mimicking gradient descent steps (Von Oswald et al., 2023; Ahn et al., 2024) on the contextexample Dn, the models behavior should resemble that of a neural network trained with Mean Square Errorloss. Consequently, we can expect:",
  "Local convergence": "Imbalanced regression :A simple approach to reduce model bias in the tail regions of the label distributionis to select a finite set of neighboring samples of x from Dn. Selecting only the neighboring sample for contextis equivalent to adjusting the distribution of labels ps(y | x) so that it corresponds locally to pt(y | x). Thisreflects the proportional relationship ps(y|x)",
  "pt(y)": "While previous propositions ensure convergences for infinitely large datasets, it is also important to considerthe expected prediction error in the case of small and finite numbers of context examples. Under thiscondition, we can assume that, in the worst case, the model will simply average the labels of the contextsamples. To the best of our knowledge, there is no existing work that specifically addresses this issue in thecontext of imbalanced regression with k-NN. This assumption is in line with previous works, for example Garget al. (2022) showed that transformers always outperform sample averaging, while Bhattamishra et al. (2023)demonstrated that a frozen GPT-2 can mimic the nearest neighbor algorithm. Formally, with k samples fromDn closest to x, denoted as Dk, the expected error bound is given by:",
  "+ 2(7)": "In the case of imbalanced regression, the variance term depends on the number of selected neighbors k andshould decrease as more context examples are selected, similar to before. The bias for the minority regionswill increase with k as the averaging estimator will predict the mean of the context examples, which is also inagreement with the previous propositions. illustrates this behavior by plotting the expected error fordata points across different regions, for the Boston and AgeDB datasets. For points in the majority region,the expected error decreases as more context examples are given. However, for points in the tail region,the error initially decreases but then exhibits a U-shaped curve as k increases. Thus, for minoritysamples, the error bound is tighter for a small number of selected neighbors, further emphasizing the need forlocalized context.",
  "Empirical validation": "To validate the error bound in practice, we compared the results obtained on two datasets: Boston andAgeDB, across three regions: many, medium, and few-shot regions. These regions are defined based onthe number of training samples per label in each discretized bin, with Few having fewer than 20 samples,Median between 20 and 100 samples, and Many exceeding 100 samples. For each test sample xquery, we retrieve its k nearest neighbors (x1, ..., xk) from the training set. Throughoutthe document, we use cosine similarity as a measure for retrieving neighboring points to the query point. empirically validates on the two datasets that in-context learning can perform better than simplyaveraging the context labels. Interestingly, for the few shot regions in both datasets, we observe that theempirical error of averaging increases rapidly with the number of context examples. This underscores thechallenge of retrieving neighboring samples that are most useful for prediction in this region, even when",
  "(b) Age dataset distribution and Error bound": ": Training distribution of two datasets: Boston (a) and AgeDB (b). The empirical expectations oferrors are computed assuming ideal retrieval of neighbors for a new query sample (i.e., retrieving samplesthat are semantically relevant in terms of the target variable, rather than just close in the input space). Thebehavior of examples from different shot regions varies distinctly with the number of context examples. Inthe many-shot regions, the error bound stabilizes as more examples are provided, whereas in the few-shotregions, additional context examples lead to an increase in the error bound. Number of context samples 0.0 0.5 1.0 1.5 2.0 2.5",
  ": Empirical Error: Averaging vs In-context learning (using GPT-2 model from (Garg et al., 2022))": "using a small number of context examples. As highlighted by Steck et al. (2024), samples that are close infeature space according to a given distance metric (e.g., cosine similarity) do not necessarily have similartarget values. In imbalanced datasets, this discrepancy between proximity in feature space and similarity intarget values makes it difficult to select representative samples for the region, as the difference in densitymakes it more likely to retrieve samples from the majority region.",
  ": Impact of neighbors retrieval on performances(using GPT-2 model proposed in (Garg et al., 2022))": "Retrieving representative samples as context inpractice is challenging, particularly for imbalanceddatasets, because the probability of retrieving sam-ples from the majority region is higher. To addressthis challenge, we propose creating a second trainingset, where the number of samples in each region isinversely proportional to its representation in theoriginal set majority regions have fewer points,while minority regions are overrepresented, we referto this dataset as inverse density as seen in in the appendix. For each new query sample, weretrieve k = ks + ks neighboring examples from both(1) the training set (ks neighbors) and (2) and inversedensity dataset (ks neighbors), to ensure balancedrepresentation and reduce the risk of bias towardthe majority region. We refer to this version as aug-mented. In , we compare the performance",
  "Experimental Setup": "Datasets: We use three benchmark datasets curated by Yang et al. (2021) specifically for imbalancedregression tasks: AgeDB-DIR, derived from the AgeDB dataset for age estimation Moschoglou et al. (2017);IMDB-WIKI-DIR, another age estimation dataset sourced from IMDB-WIKI Rothe et al. (2018); andSTS-B-DIR, which measures text similarity between two sentences based on the Semantic Textual SimilarityBenchmark Wang et al. (2018). Additionally, we use six tabular datasets, namely Boston Harrison & Rubinfeld(1978), Concrete Yeh (2007), Abalone Nash et al. (1995), Communities Redmond (2009), Kin8nm, and anengineering design dataset: Airfoil Chen et al. (2019), with inherent imbalances. For these tabular datasets,we created a balanced test set to evaluate model performance, to assess model performance in scenarios witha small number of training samples, different feature sizes, and varying levels of imbalance. Evaluation Metrics: Consistent with established protocols by Yang et al. (2021), we assess modelperformance using Mean Absolute Error (MAE) and Geometric Mean (GM) for the AgeDB-DIR andIMDB-WIKI-DIR datasets. For the other datasets, we use Mean Squared Error (MSE) as the primary metric,consistent with Yang et al. (2021). We present our results across four predefined shot regionsAll, Many,Median, and Fewwhich categorize the subsets of the datasets based on the number of training samplesavailable per label within each discretized bin. Specifically, the Few category includes bins with fewer than20 samples, Median encompasses bins with 20 to 100 samples, and Many refers to bins with over 100samples per label. Preprocessing of inputs for In-Context Learning: In this paper, we propose an in-context learningapproach as opposed to in-weight learning, which means we do not train any models directly. For thebenchmark datasets, we preprocess images and text into embeddings using the Hugging Face implementationof CLIP (Radford et al., 2021) and BERT (all-mpnet-base-v2 model) (Reimers & Gurevych, 2019).Specifically, for each image from the training and testing datasets, we extract embeddings from the CLIPimage encoder before pooling, resulting in 768-dimensional features. A similar process is applied to theSTS-B-DIR dataset, where we use BERTs text embeddings for each sentence, also resulting in 768-dimensionalfeatures. For the tabular datasets, we use the feature representations directly as inputs to the transformer.Moreover, we consider two in-context learning models: the first from Garg et al. (2022), referred to as GPT2,which uses the GPT-2 architecture and is trained on non-linear data points; the second model from Mlleret al. (2023), referred to as Prior Fitted Networks (PFN). They accept 20-dimensional and 18-dimensionalinputs, respectively. When the number of dimensions exceeds the models input size, we split the inputfeature representation into non-overlapping chunks and ensemble the predictions from each chunk. To ensurethe robustness and reproducibility of our results, we conducted three separate experiments using differentrandom seeds, between 0 and 3. We report the average results over all three seeds to account for therandomness introduced by inverse density sampling for the second training set. In all experiments, for theGPT2 model from Garg et al. (2022), we retrieve ks = ks = 10 nearest neighbors, for the PFN model weretrieve ks = ks = 15, except for the IMDB dataset where ks was equal to 5. This choice is motivated by thepreliminary experiments conducted in section 3.3 as observed in where the minimum error in allregions is achieved for 10 neighbors. A sensitivity analysis on the number of neighbors is presented in . An NVIDIA RTX 2080 GPU was used for all the experiments.",
  "GPT2 - localized (Garg et al., 2022) (Ours)7.767.3511.1517.714.294.135.9611.00": "IMDB:In , we report the results obtained on the IMDB-WIKI-DIR benchmarks. This is thelargest dataset used in this study with 191.5K training samples. Both models (Garg et al., 2022; Mlleret al., 2023) using our localized approach achieve the lowest error in the few-shot and medium-shot regions.The best-performing in-context model is (Mller et al., 2023), which achieves an MAE of 16.33 and 10.79,improving over state-of-the-art methods on age estimation by 34.63 and 1.02 error points, respectively. Inthe many-shot region, in-weight learning outperforms in-context learning due to the abundance of trainingsamples (almost 150k samples), which facilitates more effective learning and better generalization.",
  "PFN - localized0.5440.5360.5470.618GPT2 - localized 0.5280.5240.5270.566": "STS: presents the results on the STS-B-DIRdataset. In this text modality, both models using ourlocalized method consistently and substantially improvethe results over state-of-the-art methods in all regions,achieving the best MSE of 0.528 on the overall test setand 0.566 in the few-shot region. Tabular: shows the average results on six tab-ular datasets. While the previous results on the previousdatasets rely on features extracted from pre-trained mod-els, a direct comparison of in-weight learning vs in-contextlearning can be made using tabular datasets. The results clearly show that in-context learning outperforms",
  "ABLATIONS": "Representation learning.In our experiment with the age datasets, we used CLIP embeddings across allage datasets to assess the effectiveness of in-context learning compared to in-weight learning. The methods in were trained to learn representations directly from the images, whereas we used pre-extracted CLIPembeddings. We trained a three-layer MLP with 256 neurons in the hidden layers using these embeddings.Additionally, we conducted an experiment where we fine-tuned the GPT2 model on the AgeDB dataset.Results presented in indicate that also in this scenario in-context learning consistently outperformsin-weight learning. Interestingly, the fine-tuned GPT2 model achieves almost similar performance to thein-context learning approach. These results suggest that in-context learning is a particularly effective solutionfor relatively small datasets with the presence of scarce data, such as AgeDB.",
  "GPT2 - localized (Garg et al., 2022) (Ours)6.055.676.717.83 3.793.594.174.90": "All Context vs. Localized Approach.A key rationale for using the PFN model from Mller et al.(2023) is its lack of positional embedding. This allows for a direct comparison of the models performanceusing the entire training set versus a localized version as context. presents results across the first fivetabular datasets. The engineering dataset, which has more than 30k training samples, could not fit in memoryand was therefore excluded from this ablation. The results show a significant performance improvement withthe localized approach in in-context learning compared to the non-localized version across all regions, with aparticularly significant improvement in the few-shot region. Sampling strategy:In .3, we presented a strategy to mitigate the underrepresentation ofminority points when retrieving neighbors. In this section, we compare different sampling strategies on thetabular dataset. The Vanilla approach retrieves neighbors from the original training set. Downsamplingreduces the majority region, creating a balanced training set and retrieving neighbors only from this balancedset. SMOTER (Branco et al., 2017) generates new synthetic data points for the minority region, and neighbors",
  "Conclusion": "In this work, we proposed the use of in-context learning to address the challenge of imbalanced regression,where a model can learn from context examples during inference without any additional training on themodel weights. We show that a single in-context learning model can adapt to multiple tasks and improveperformance in regions with high imbalance, unlike in-weight regression models, which often fail to generalizein minority regions and require specific training for each task. Through theoretical and empirical analyses, wehighlighted the importance of localized contextusing a small number of selected neighborsin mitigatingthe bias inherent in imbalanced label distributions. Our evaluation across several benchmark datasets withdiverse modalities revealed that in-context learning achieves superior results in regions of high imbalance. Our comparative analysis demonstrated that two in-context learning models (Mller et al., 2023; Garg et al.,2022) based on Transformer architectures can achieve strong performance in imbalanced regression tasks forone-dimensional labels. While models are currently trained to predict a single value for a given query, futurework will focus on extending our approach to multi-dimensional labels, such as depth estimation. Futurework could also explore other model variants, and further investigate the factors contributing to performancedifferences between different in-context learning models for minority and majority regions.",
  "in Neural Information Processing Systems, 33, 2020": "Yu Bai, Fan Chen, Huan Wang, Caiming Xiong, and Song Mei. Transformers as statisticians: Provable in-context learning with in-context algorithm selection. In Thirty-seventh Conference on Neural InformationProcessing Systems, 2023. URL Satwik Bhattamishra, Arkil Patel, Varun Kanade, and Phil Blunsom. Simplicity bias in transformers andtheir ability to learn sparse Boolean functions. In Anna Rogers, Jordan Boyd-Graber, and Naoaki Okazaki",
  "Alberto Bietti, Vivien Cabannes, Diane Bouchacourt, Herve Jegou, and Leon Bottou. Birth of a transformer:A memory viewpoint. Advances in Neural Information Processing Systems, 36, 2024": "Paula Branco, Lus Torgo, and Rita P Ribeiro. Smogn: a pre-processing approach for imbalanced regression.In First international workshop on learning with imbalanced domains: Theory and applications, pp. 3650.PMLR, 2017. Tom Brown, Benjamin Mann, Nick Ryder, Melanie Subbiah, Jared D Kaplan, Prafulla Dhariwal, ArvindNeelakantan, Pranav Shyam, Girish Sastry, Amanda Askell, et al. Language models are few-shot learners.Advances in neural information processing systems, 33:18771901, 2020.",
  "Warwick Nash, Tracy Sellers, Simon Talbot, Andrew Cawthorn, and Wes Ford. Abalone. UCI MachineLearning Repository, 1995. DOI:": "F. Pedregosa, G. Varoquaux, A. Gramfort, V. Michel, B. Thirion, O. Grisel, M. Blondel, P. Prettenhofer,R. Weiss, V. Dubourg, J. Vanderplas, A. Passos, D. Cournapeau, M. Brucher, M. Perrot, and E. Duchesnay.Scikit-learn: Machine learning in Python. Journal of Machine Learning Research, 12:28252830, 2011. Alec Radford, Jong Wook Kim, Chris Hallacy, Aditya Ramesh, Gabriel Goh, Sandhini Agarwal, Girish Sastry,Amanda Askell, Pamela Mishkin, Jack Clark, et al. Learning transferable visual models from naturallanguage supervision. In International conference on machine learning, pp. 87488763. PMLR, 2021.",
  "arXiv preprint arXiv:2405.01147, 2024": "Ashish Vaswani, Noam Shazeer, Niki Parmar, Jakob Uszkoreit, Llion Jones, Aidan N Gomez, ukasz Kaiser,and Illia Polosukhin. Attention is all you need. Advances in neural information processing systems, 30,2017. Johannes Von Oswald, Eyvind Niklasson, Ettore Randazzo, Joo Sacramento, Alexander Mordvintsev, AndreyZhmoginov, and Max Vladymyrov. Transformers learn in-context by gradient descent. In InternationalConference on Machine Learning, pp. 3515135174. PMLR, 2023.",
  "BRetrieving neighbours": "In this section, we further motivate the design choice of our augmented strategy. As shown in , in thecase of imbalanced regression, retrieving neighbors from the original training set can result in selecting pointsfrom the same region, which may not provide informative insights into local feature behavior. From :Using the vanilla distribution will skew the choice of neighbours towards the majority region. Conversely,with inverse sampling, the distribution becomes more representative of the minority region. The aim of ouraugmented strategy is to find a good trade-off between these two sampling methods. Conversely, our strategymakes it easier to retrieve diverse and informative neighbors around the query point xquery.",
  "selected context": "(a)(b)(c) : An overview of the proposed approach for imbalanced regression. Rather than relying on in-weightlearning, which trains models directly on the training data, we propose leveraging in-context learning. Foreach query sample, we retrieve k = ks + ks neighboring examples from both (1) the training set (ks neighbors)and (2) and inverse density dataset (ks neighbors), where the number of samples in each region is inverselyproportional to its representation in the original set, and feed these as context to the model. This serves adual purpose: avoiding bias toward the mean of the training set, which is crucial for tail regions, and reducingthe memory requirement of the transformer.",
  "C.1Datasets": "Age EstimationWe evaluated our method using two imbalanced regression benchmarks for age estimationprovided by Yang et al. (2021): IMDB-WIKI-DIR and AgeDB-DIR. The IMDB-WIKI dataset (Rothe et al.,2018) includes 191,509 images for training and 11,022 images for validation and testing. The ages arediscretized into 1-year bins, from age 0 to 186. The AgeDB dataset (Moschoglou et al., 2017) contains 16,488samples. AgeDB-DIR was structured similarly to IMDB-WIKI-DIR, with age bins ranging from 0 to 101. Text SimilarityWe evaluated our method using imbalanced regression benchmarks for textual similarityestimation provided by Yang et al. (2021). STS-B-DIR (Wang et al., 2018) consists of sentence pairs sourcedfrom news headlines, video and image captions, and natural language inference data. Each pair is annotatedby different annotators, resulting in an averaged continuous similarity score ranging from 0 to 5. The task isto predict these similarity scores based on the sentence pairs. The training dataset includes 5,249 pairs ofsentences, with validation and test sets containing 1,000 pairs each. Tabular DatasetsWe used five datasets from the UCI machine learning repository (Frank, 2010): Boston,Concrete, Abalone, Kin8nm, and Communities, as a sixth dataset from engineering: the airfoil dataset. Thelabel distributions for all the tabular datasets is shown in .",
  ": Training distribution of labels for the image and text modality": "For the UCI datasets, we created training and testing sets, ensuring the test sets were balanced, using theAlgorithm ??. Due to its small size, the Boston dataset was split 90% for training and 10% for testing, andthe bin size was set to 15. The other datasets were split 80% for training and 20% for testing and the binsize was set to 50. The specific details:",
  "Decision Trees, Gradient Boosting, Linear Regression, Random Forest and Neural Networks, we used thedefault parameters": "For IMDB-WIKI-DIR and AgeDB-DIR, the baseline uses a ResNet-50 backbone trained from scratch. ForSTSB-DIR, the baseline uses a BiLSTM with GloVe word embeddings. The details on this datasets can befound in Yang et al. (2021). Standard scaling was applied to the input features for these models. For in-context learning, we applied bothstandard scaling and a power transform to the features and then concatenated the two representations.",
  "C.5Computational Analysis": "We conducted an analysis comparing in-weight learning and in-context learning approaches in terms oftraining/processing time, inference time, and memory requirements. summarizes our findings for theIMDB-Wiki dataset. For in-context learning, the training time is effectively zero, but weve included the timeto process and extract features from the training set (189,794 images) using CLIP. The inference time includesboth feature extraction and prediction. These results show that while the in-context learning method has alonger inference time, it requires less memory and significantly reduces the upfront training/processing time.",
  "E.4Tabular datasets": "In this section we report individually the results for each of the tabular datasets used. The results for Boston(Harrison & Rubinfeld, 1978) are in . The results for Concrete (Yeh, 2007) are in . The sameapplied for Abalone (Nash et al., 1995) in , Communities (Redmond, 2009) in , Kin8nm in, and an engineering design dataset: Airfoil (Chen et al., 2019) in ."
}