{
  "Abstract": "Impressive advances in text-to-image (T2I) generative models have yielded a plethora ofhigh performing models which are able to generate aesthetically appealing, photorealisticimages.Despite the progress, these models still struggle to produce images that areconsistent with the input prompt, oftentimes failing to capture object quantities, relationsand attributes properly. Existing solutions to improve prompt-image consistency suffer fromthe following challenges: (1) they oftentimes require model fine-tuning, (2) they only focuson nearby prompt samples, and (3) they are affected by unfavorable trade-offs among imagequality, representation diversity, and prompt-image consistency. In this paper, we addressthese challenges and introduce a T2I optimization-by-prompting framework, OPT2I, whichleverages a large language model (LLM) to improve prompt-image consistency in T2Imodels. Our framework starts from a user prompt and iteratively generates revised promptswith the goal of maximizing a consistency score. Our extensive validation on two datasets,MSCOCO and PartiPrompts, shows that OPT2I can boost the initial consistency scoreby up to 24.9% in terms of DSG score while preserving the FID and increasing the recallbetween generated and real data. Our work paves the way toward building more reliableand robust T2I systems by harnessing the power of LLMs.",
  "T2IScorer": ": Overview of our backpropagation-free text-to-image optimization by prompting approach thatrewrites user prompts with the goal of improving prompt-image consistency. Our framework is composed ofa text-to-image generative model (T2I), a large language model (LLM) and a consistency objective (Scorer).The LLM iteratively leverages a history of prompt-score pairs to suggest revised prompts. In the depictedexample, our system improves the consistency score by over 30% in terms of Davidsonian Scene Graph score.",
  "Introduction": "In recent years, we have witnessed remarkable progress in text-to-image (T2I) generative models (Rameshet al., 2022; Saharia et al., 2022; Rombach et al., 2022b; Podell et al., 2023; Dai et al., 2023b). The photore-alistic quality and aesthetics of generated images has positioned T2I generative models at the center of thecurrent AI revolution. However, progress in image quality has come at the expense of model representationdiversity and prompt-image consistency (Hall et al., 2023). From a users perspective, the fact that not allthe elements of the input text prompt are properly represented in the generated image is particularly prob-lematic as it induces a tedious and time-consuming trial-and-error process with the T2I model to refine theinitial prompt in order to generate the originally intended image. Common consistency failure modes of theT2I generative models include missing objects, wrong object cardinality, missing or mixed object attributes,and non-compliance with requested spatial relationships among objects in the image (Wu et al., 2023a). To improve prompt-image consistency, researchers have explored avenues such as adjusting the samplingguidance scale (Ho & Salimans, 2022), modifying cross-attention operations (Feng et al., 2022; Epsteinet al., 2023; Liu et al., 2022; Chefer et al., 2023; Wu et al., 2023a), fine-tuning models (Lee et al., 2023;Wu et al., 2023c; Sun et al., 2023), leveraging additional input modalities such as layouts (Cho et al.,2023b; Lian et al., 2023), and selecting images post-hoc (Karthik et al., 2023). Most of these approachesrequire access to the models weights and are not applicable when models are only accessible through anAPI interface, e.g., (Betker et al., 2023). The only two approaches that are applicable to API-accessiblemodels are guidance scale modification and post-hoc image selection. However, these approaches rely ona single text prompt the one provided by the user so their ability to generate diverse images is limitedto resampling of the input noise, i.e., changing the random seed. Perhaps more importantly, both theseapproaches have unfavorable trade-offs, as they improve prompt-image consistency at the expense of imagequality and diversity e.g., high guidance scales lead to reduced image quality and diversity, while post-hocselecting the most consistent images decreases significantly the representation diversity.",
  "Published in Transactions on Machine Learning Research (11/2024)": "Small white toilet with seashells sitting on top of it. (0.1899) A clean white toilet adorned with seashells on its lid. (0.1985) A small, pristine toilet crowned with seashells. (0.2341) A miniature white toilet graces a seashell-covered pedestal. (0.2480) A miniature toilet, flawlessly white, is adorned with an array of vibrant seashells,elevating its charm. (0.2507) A miniature toilet, flawlessly white, is covered in a diverse array of seashells,elevating its charm and creating a captivating display. (0.2527) A small, immaculate white toilet, covered in a diverse array of seashells, perches ona pedestal, boasting an eye-catching exhibition. (0.2605) A miniature white toilet, adorned with an array of seashells, perches on a pedestal,boasting an unforgettable exhibition. (0.2675) A punk rock squirrel in a studded leather jacket shouting into a microphone whilestanding on a lily pad (0.1690) A rebellious squirrel wearing a studded leather jacket passionately sings into amicrophone while standing on a lily pad. (0.1813) A punk-rockin' squirrel stands atop a lily pad and belts into a microphone, wearing astudded leather jacket that oozes attitude. (0.1859) A punk rockin' squirrel, wearing a leather jacket adorned with metal studs, beltsinto a microphone with conviction, positioned atop a lily pad. (0.1939) A rebellious squirrel, clad in a black leather jacket adorned with metal studs,passionately sings into a microphone while standing on a lily pad, exuding punk rockspirit. (0.1988) A rebellious squirrel, adorned in a black leather jacket featuring metal studs,passionately sings into a microphone while standing on a lily pad, exuding punk rockspirit. (0.2017) A bold squirrel, adorned in a black leather jacket featuring metal studs, sings intoa microphone with intensity, standing on a lily pad, embracing the punk rock style.(0.2053) A rebellious squirrel, attired in a black leather jacket featuring metal studs,forcefully belts out a tune into a microphone on a sturdy lily pad, channeling theraw energy of punk rock. (0.2158) : Selected examples of initial prompts from MSCOCO (left) and PartiPrompts (right) and revisedprompts across the optimization, along with the generated images. The optimizer refines prompts for LDM-2.1using Llama-2 as LLM and dCS as scorer. We report dCS score averaged across images.",
  "Prompt history": ":Our prompt optimization framework, OPT2I,composed of (1) a text-to-image (T2I) generative model thatgenerates images from text prompts, (2) a consistency met-ric that evaluates the fidelity between the generated imagesand the user prompt, and (3) a large language model (LLM)that leverages task description and a history of prompt-score tuples to provide revised prompts. At the beginning,the revised prompt is initialized with the user prompt. We assume access to an LLM, f, and a pre-trained T2I generative model, g. Given a textprompt, p, we can generate an image I condi-tioned on the prompt with our T2I generator,I = g(p). Let us define the set of all possibleparaphrases from p that can be obtained withan LLM as P = {pi}, and let us introduce aprompt-image consistency score, S(p, I). Ourobjective is to find a prompt paraphrase p Pthat maximizes the expected consistency scoreof sampled images:",
  "Meta-prompt design": "We adapt LLMs for T2I prompt optimizationvia ICL. We denote meta-prompt the prompt which instructs the LLM to optimize prompts for T2I models.Our meta-prompt is composed of a task instruction and a history of past revised prompt-score pairs. Thelist of meta-prompts used can be found in Appendix A. The meta-prompt provides context about T2I models, the consistency metric and the optimization problem.Additionally, it contains a history of prompt-score pairs that provides context about which paraphrasesworked best in the past for a particular T2I model, encouraging the LLM to build upon the most successfulprompts and removing the need for explicitly specifying how to modify the T2I prompt. The consistencyscore is normalized to an integer between 0 and 100, and we only keep in the history the top-k scoringprompts found so far, sorted by increasing score.",
  "Optimization objective": "A critical part of our framework is feeding visual feedback to the LLM. The visual feedback is capturedby the consistency score, which determines how good the candidate prompt is at generating consistentimages. Although OPT2I can work with any even non-differentiable consistency score, we argue that theconsistency score must be detailed enough for the LLM to infer how to improve the candidate prompt. WhileCLIPScore (Hessel et al., 2021) is arguably the most popular metric for measuring prompt-image consistency,in our initial experiments we found that scoring a prompt with a single scalar is too coarse for our purposes.Thus, we opt for two metrics that provide finer-grained information about the prompt-image consistency:(1) Davidsonian Scene Graph (DSG) score (Cho et al., 2023a), and (2) our proposed decomposed CLIPScore. DSG assesses prompt-image consistency based on a question generation and answering approach, similarto TIFA (Hu et al., 2023). In particular, DSG generates atomic and unique binary questions from the userprompt that are organized into semantic dependency graphs. For example, a bike lying on the ground,covered in snow is decomposed into: (1) Is there a bike?; (2) Is the bike lying on the ground?; (3) Isthe bike covered in snow?. In this case, questions (2) and (3) depend on (1), and so (1) is used to validate (2)and (3). These questions are then answered by an off-the-shelf VQA model based on the generated image.We include the resulting question-answer pairs in our meta-prompt. A global score per prompt-image pairis computed by averaging across answer scores. Decomposed CLIPScore computes a partial consistency score for each noun phrase present in the userprompt. For example, a bike lying on the ground, covered in snow is decomposed into a bike, theground and snow.Each noun phrase is then scored against the generated image using CLIPScore,resulting in a list of pairs of noun phrases and their associated scores, which are included in our meta-prompt.A global score per prompt-image pair is computed by averaging across subscores. We provide examples ofdecomposed CLIPScore and DSG outputs in Appendix A.",
  "Exploration-exploitation trade-off": "During the optimization process, OPT2I requires controllability over the LLMs exploration-exploitationtrade-off, as the LLM could either focus on exploring possible revised prompts or on exploiting the contextprovided in the meta-prompt history. On the one hand, too much exploration would hamper the optimiza-tion as it could be hard to find a high quality solution. On the other hand, too much exploitation wouldlimit the exploration to prompts that are very similar to the ones already presented in the meta-prompthistory. We control this balance by adjusting the number of generated revised prompts per iteration and theLLM sampling temperature. Moreover, as our objective is to find prompts that work well across differentT2I input noise samples, we generate multiple images per prompt at each iteration.",
  "Experimental setting": "Benchmarks. We run experiments using prompts from MSCOCO (Lin et al., 2014) and PartiPrompts(P2) (Yu et al., 2022). For MSCOCO, we use the 2000 captions from the validation set as in (Hu et al.,2023). These captions represent real world scenes containing common objects. PartiPrompts, instead, is acollection of 1600 artificial prompts, often unrealistic, divided into categories to stress different capabilitiesof T2I generative models. We select our PartiPrompts subset by merging the first 50 prompts from the mostchallenging categories: Properties & Positioning, Quantity, Fine-grained Detail, and Complex. Thisresults in a set of 185 complex prompts.",
  "Main results": "T2I optimization by prompting.In , we plot the prompt optimization curves withLDM-2.1/CDM-M as T2I models, Llama-2/GPT-3.5 as LLM, and decomposed CLIPscore (dCS)/DSG as thescorer for prompts from MSCOCO and PartiPrompts. Each data point corresponds to the mean/max rel-ative improvement in consistency score (w.r.t. the user prompt) achieved by revised prompts generated inthat iteration, averaged across the full dataset of prompts. The optimization curves show an overall upwardtrend, which confirms that the LLM in OPT2I is capable of optimizing T2I prompts. These improvementsare especially noticeable in the max consistency score. The initial dip in mean consistency score is expecteddue to the initial exploration, since the LLM has limited context provided only by the user prompt (1-shotICL). As the optimization progresses, the LLM generates more consistent revised prompts at each iteration,as its context is increasingly enriched with the performance of previous revised prompts. Notably, achievinga positive mean relative consistency starting from a single in-context example is a very challenging task (Weiet al., 2023), and OPT2I achieves this goal for all configurations except for Llama-2 and GPT-3.5 in thedCS(P2) setting (b), where it only get close to 0. As mentioned .1, PartiPrompts is ahard benchmark containing highly detailed and complex prompts, so it is perhaps unsurprising that decom-posed CLIPScore falls short (with improvements < 7% in the max case, and < 2% in the mean case) given the imperfect decomposition into noun-phrases. We also explored a hierarchical version of decomposedCLIPscore leveraging constituency trees, which did not show any improvement over our noun-phrase baseddecomposition, further reinforcing the criticism that CLIP behaves as a bag-of-words and is unable to prop-erly capture object attributes and relations (Yuksekgonul et al., 2022; Yamada et al., 2022). Instead, using",
  "a more detailed consistency score during the prompt optimization process, such as DSG, results in moresignificant improvements (< 17% in the max case, and < 5% in the mean case)": "Comparison to paraphrasing baselines. shows our proposed OPT2I framework is robust to thechoice of LLM, T2I model and optimization/evaluation objective. In particular, for dCS, we report relativeimprovement as scorebest/scoreinit 1. For DSG score, since the initial score can be zero and it is alreadya percentage, we instead report scorebest scoreinit.We observe that OPT2I consistently outperformsthe random paraphrasing baseline across different LLMs and T2I models. Additionally, we can see thatboth paraphrasing and optimization get around a 10% boost in consistency improvement when using DSGas optimization objective instead of dCS for P2 but not for MSCOCO. This highlights again that morecomplex prompts, such as those from PartiPrompts, benefit from a more accurate consistency metric. Wenote that some prompts might already have a fairly high initial consistency score (see App. B.2), so thereis little room for improvement. For instance, prompts from MSCOCO evaluated with DSG have an averageinitial score of 86.54%, which means that the improvement in this setting has an upper bound of 13.46%. In addition to random paraphrasing, we compare OPT2I to Promptist (Hao et al., 2022) on MSCOCOprompts by generating images from initial/best prompts (4 images/prompt) with SD-1.4 (Promptists ref-erence model) and LDM-2.1, evaluating consistency with DSG score. We observe Promptist decreases theconsistency score by 3.56%/3.29% on SD-1.4/LDM-2.1, while OPT2I (Llama-2) improves consistency by+14.16%/+11.21%. This aligns with the results reported in (Hao et al., 2022), which show that optimizingprompts primarily for aesthetics actually decreases prompt-image consistency. Qualitative results.In , we provide examples of images generated from user and optimizedprompts with OPT2I for different LLMs and T2I models. We observe OPT2I is capable of finding para-phrases of the user prompt which considerably improve the consistency between the generated images andthe initial, user-provided prompt, as measured by DSG in this case. These examples suggest the optimizedprompts are capable of steering the T2I model towards generating visual elements that were ignored withthe initial phrasing. From our qualitative analysis, we observed the LLM uses several strategies to emphasizethe missing visual elements, such as providing a more detailed description of those elements (e.g., a flower a vibrant flower arrangement, a vase filled with fresh blossoms) or placing them at the beginning ofthe sentence (e.g., four teacups surrounding a kettle surround a kettle placed at the center with four",
  "(a) LLM: Llama-2, T2I: LDM-2.1": "0.2857 A horse and several cows feed on hay. (0.5000) 0.5714 0.2857 0.8571 0.8571 A horse is seated on a stack of hay, surrounded by a herd of cows feasting onthe hay, creating a festive atmosphere. (0.8571) 0.8571 0.7143 1.0000 0.6667 A bowl full of tomatoes sitting next to a flower. (0.6667) 0.6667 0.6667 0.6667 1.0000 A bowl of tomatoes, topped with a beautiful flower, sitting next to a vasefilled with fresh blooms. (1.0000) 1.0000 1.0000 1.0000",
  "(b) LLM: Llama-2, T2I: CDM-M": "0.5556 A raccoon wearing formal clothes, wearing a tophat and holding a cane. Theraccoon is holding a garbage bag. Oil painting in the style of pointilism.(0.4722) 0.5556 0.1111 0.6667 0.5556 A sophisticated raccoon, attired in formal wear and a tophat, poses with poiseand panache, holding a cane and a garbage bag, against a stunning pointilism-style oil painting, showcasing the raccoon's cultured appearance and thepainting's elaborate details. (0.7500) 0.8889 0.6667 0.8889 0.0000 four teacups surounding a kettle (0.5000) 0.5000 0.7500 0.7500 1.0000 Four teacups encircle a kettle, forming a cohesive and picturesque tea setup.(1.0000) 1.0000 1.0000 1.0000",
  "(c) LLM: Llama-2, T2I: LDM-2.1": "0.5556 A raccoon wearing formal clothes, wearing a tophat and holding a cane. Theraccoon is holding a garbage bag. Oil painting in the style of pointilism.(0.4722) 0.5556 0.1111 0.6667 0.5556 An oil painting in the style of pointillism depicting a raccoon elegantlydressed in formal clothes, with a top hat and cane, holding a garbage bag.(0.6944) 0.4444 0.8889 0.8889 0.0000 four teacups surounding a kettle (0.5000) 0.5000 0.7500 0.7500 1.0000 Surround a kettle placed at the center with four teacups. (1.0000) 1.0000 1.0000 1.0000",
  "(d) LLM: GPT-3.5, T2I: LDM-2.1": ": Selected qualitative results for prompts from MSCOCO (a-b) and P2 (c-d) datasets, using DSGas consistency metric. For each setup, we display four rows (from the top): initial prompt #1, optimizedprompt #1, initial prompt #2, and optimized prompt #2. Each column corresponds to a different T2Imodel random seed. We report average consistency score across seeds in between parenthesis.",
  "+9.68+10.34+10.23+9.99": "teacups). We note a perfect consistency score does not ensure perfectly aligned images (e.g., for the userprompt four teacups surrounding a kettle, all optimized prompts reach a DSG score of 100% while the car-dinality of teacups remains incorrect), which highlights the limitations of current prompt-image consistencyscores. We also observe that prompts optimized by Llama-2 tend to be longer than those from GPT-3.5 (seeApp. B.5), and that images generated by CDM-M from user prompts are generally more consistent than thosegenerated by LDM-2.1, which we attribute to the use of a stronger text encoder (T5-XXL instead of CLIP).",
  "Trade-offs with image quality and diversity": "Following common practice in the T2I community, we evaluate the quality of OPT2I generations by comput-ing image generation metrics such as FID, precision (P), and recall (R). We use the 2000 prompts from theMSCOCO validation set that are included in the TIFAv1 benchmark (Hu et al., 2023), and generate 4 imagesfor each initial and best prompt. To ensure robust conclusions, we use two feature extractors in our metrics:Inception-v3 (IV3) (Szegedy et al., 2016) and CLIP (Radford et al., 2021). Results in show that theFID of prompts optimized with OPT2I is either on-par or better compared to that of initial prompts, vali-dating that our method does not trade image quality for consistency. Hence, we conclude FID is not affectedby our optimization strategy. However, in terms of precision and recall, we observe that optimized promptsreach higher recall at the expense of lower precision compared to the user prompt. This can be explained bythe fact that rephrasing the input prompt allows to generate more diverse images (higher recall), which mayoccasionally fall outside of the manifold of natural images (lower precision); e.g., in (Appendix B),optimizing for consistency leads to a change of artistic style. The observed trade-off between realism anddiversity aligns with the results reported by Astolfi et al. (2024).",
  "Ablations": "We perform ablations with Llama-2 and LDM-2.1 on PartiPrompts using default parameters unless otherwisespecified. illustrates the trade-off between exploration and exploitation, implemented as the numberof revised prompts per iteration (#prompts/iter) and the number of optimization iterations (#iterations), re-spectively. Generating more prompts at each iteration increases the exploration of multiple solutions given thesame context, while by increasing the number of iterations, the LLM can exploit more frequent feedback fromthe T2I model and the consistency score. We observe that increasing number of iterations leads to a higherconsistency improvement. In other words, more exploitation is beneficial with a fixed budget of 150 promptgenerations. However, pushing exploitation too much, i.e., #it = 150 and #p/it = 1, becomes harmful.",
  ": Average DSG score for the top-k mostconsistent images among 600": "In table 3, we report relative consistency (dCS) when ablating for different task instructions in the meta-prompt. We explore four instruction additions to be combined with our base meta-prompt. Concisenessencourages to explore paraphrases beyond just adding details/adjectives; Prioritize encourages focusing onmissing/low-score elements; Reasoning encourages to reason about the in-context examples; and Structureasks for simple vocabulary informative of the structure of images, e.g., foreground and background (fullmeta-prompts are provided in Appendix A). We observe that Prioritize achieves slightly better performanceover Reasoning and Structure, yet the LLM remains fairly robust to specific meta-prompt phrasing.",
  "Post-hoc image selection": "We emphasize OPT2I aims to optimize prompts to generate more consistent images on expectation. However,for the sake of completeness, we also evaluate the setting where we generate the same amount of imagesfrom the initial prompt and select the most consistent ones. In particular, we generate 600 images fromPartiPrompts using either random image sampling from the initial prompt, paraphrasing, or OPT2I, andselect the top-k most consistent images based on DSG score. In , we observe that OPT2I consistentlyoutperforms both baselines. Interestingly, sampling from the initial prompt outperforms paraphrasing, whichmight be due to random paraphrases deviating too much from the users intent.",
  "Related work": "Improving consistency in T2I models. Several recent works propose extensions to T2I models to improvetheir faithfulness to user prompts. Some studies focus on improving the guidance with cross-attention (Fenget al., 2022; Epstein et al., 2023; Liu et al., 2022; Chefer et al., 2023; Wu et al., 2023a). Other studies firstconvert a textual prompt into a layout before feeding it to a layout-to-image generative model (Cho et al.,2023b; Lian et al., 2023). Recent works also finetune T2I models on human (Lee et al., 2023; Wu et al., 2023c;Wallace et al., 2023) or AI model (Sun et al., 2023) feedback, or perform post-hoc image selection (Karthiket al., 2023). In contrast, OPT2I acts exclusively at the level of input prompt in text space, without accessingmodel weights, making it applicable to a wider range of T2I models, including those only accessible throughan API. LLMs as prompt optimizers. Several recent works explore the role of LLMs as prompt optimizers for NLPtasks. Some use LLMs to directly optimize the task instruction for ICL (Zhou et al., 2022; Pryzant et al.,2023; Yang et al., 2023). Other studies use LLMs to mutate prompts for evolutionary algorithms (Guo et al.,2023; Fernando et al., 2023). A crucial difference between these works and our method is that they optimize atask instruction prompt by using a training set, which is subsequently applied across test examples, while we",
  "Conclusions": "In this paper, we introduced the first T2I optimization-by-prompting framework to improve prompt-imageconsistency. Through extensive evaluations, we showed that OPT2I can be effectively applied to differentcombinations of LLM, T2I models and consistency metrics, consistently outperforming paraphrasing baselinesand yielding prompt-image consistency improvements of up to 24.9% over the user prompt, while maintain-ing the FID between generated and real images. By contrasting MSCOCO and PartiPrompts results, wehighlighted the importance of the choice of consistency score: complex prompts in PartiPrompts appearto significantly benefit from more detailed scores such as DSG. Qualitatively, we observed that optimizingprompts for prompt-image consistency oftentimes translates into emphasizing initially ignored elements inthe generated images, by either providing additional details about those or rewording the prompt such thatthe ignored elements appear at the beginning. Interestingly, such prompt modifications steer the generatedimages away from the learned modes, resulting in a higher recall w.r.t. the real data distribution. Limitations. One limitation of our method is that it expects prompt-image consistency scores to workreasonably well.However, this assumption might not hold in some cases.For instance, it has beenshown that CLIP (used for CLIPScore) sometimes behaves like a bag-of-words (Yuksekgonul et al., 2022;Yamada et al., 2022). VQA-based prompt-image consistency metrics such as TIFA or DSG also suffer fromlimitations in generating questions (e.g., the question Is the horse on the hay? is generated from theprompt A horse and several cows feed on hay.) or in answering them with a VQA model (e.g., for theprompt A bowl full of tomatoes sitting next to a flower., the VQA model answers that there is a flowerwhen it is in fact a bouquet made of tomatoes). Moreover, using these metrics as optimization objectivesmight exacerbate their failure modes by finding prompts which generate images that fulfill the requirementsfor a high score in an adversarial way. This highlights the need for further research in developing more robustprompt-image consistency metrics which can be used as optimization objectives in addition to evaluation. Another limitation of our approach is its runtime, which is a consequence of performing inference-timeoptimization.For instance, running the optimization process with Llama-2, LDM-2.1 and DSG score,generating 5 prompt paraphrases per iteration and 4 images per prompt with 50 diffusion steps, takes7.34/20.27 iterations on average for COCO/PartiPrompts, which translates to 10/28 minutes when usingNVIDIA V100 GPUs. However, we emphasize that (1) OPT2I is designed to be a versatile approach thatworks as a plug-and-play solution with diverse T2I models and LLMs since it does not require any parameterupdates nor training data, and (2) optimizing T2I prompts with our automatic framework relieves humansfrom the manual and tedious task of prompt-engineering.",
  "Jaemin Cho, Abhay Zala, and Mohit Bansal. Visual programming for text-to-image generation and evalua-tion. arXiv preprint arXiv:2305.15328, 2023b": "Wenliang Dai, Junnan Li, Dongxu Li, Anthony Meng Huat Tiong, Junqi Zhao, Weisheng Wang, BoyangLi, Pascale Fung, and Steven Hoi. Instructblip: Towards general-purpose vision-language models withinstruction tuning, 2023a. Xiaoliang Dai, Ji Hou, Chih-Yao Ma, Sam Tsai, Jialiang Wang, Rui Wang, Peizhao Zhang, Simon Van-denhende, Xiaofang Wang, Abhimanyu Dubey, et al. Emu: Enhancing image generation models usingphotogenic needles in a haystack. arXiv preprint arXiv:2309.15807, 2023b.",
  "Dave Epstein, Allan Jabri, Ben Poole, Alexei A Efros, and Aleksander Holynski. Diffusion self-guidance forcontrollable image generation. arXiv preprint arXiv:2306.00986, 2023": "Patrick Esser, Sumith Kulal, Andreas Blattmann, Rahim Entezari, Jonas Mller, Harry Saini, Yam Levi,Dominik Lorenz, Axel Sauer, Frederic Boesel, et al. Scaling rectified flow transformers for high-resolutionimage synthesis. In Forty-first International Conference on Machine Learning, 2024. Weixi Feng, Xuehai He, Tsu-Jui Fu, Varun Jampani, Arjun Reddy Akula, Pradyumna Narayana, SugatoBasu, Xin Eric Wang, and William Yang Wang. Training-free structured diffusion guidance for compo-sitional text-to-image synthesis. In The Eleventh International Conference on Learning Representations,2022.",
  "Jonathan Ho and Tim Salimans. Classifier-free diffusion guidance, 2022": "Yushi Hu, Benlin Liu, Jungo Kasai, Yizhong Wang, Mari Ostendorf, Ranjay Krishna, and Noah A. Smith.Tifa: Accurate and interpretable text-to-image faithfulness evaluation with question answering. In Proceed-ings of the IEEE/CVF International Conference on Computer Vision (ICCV), pp. 2040620417, October2023. Shyamgopal Karthik, Karsten Roth, Massimiliano Mancini, and Zeynep Akata.If at first you dontsucceed, try, try again: Faithful diffusion-based text-to-image generation by selection. arXiv preprintarXiv:2305.13308, 2023. Yuval Kirstain, Adam Polyak, Uriel Singer, Shahbuland Matiana, Joe Penna, and Omer Levy. Pick-a-pic:An open dataset of user preferences for text-to-image generation. arXiv preprint arXiv:2305.01569, 2023. Kimin Lee, Hao Liu, Moonkyung Ryu, Olivia Watkins, Yuqing Du, Craig Boutilier, Pieter Abbeel, Moham-mad Ghavamzadeh, and Shixiang Shane Gu. Aligning text-to-image models using human feedback. arXivpreprint arXiv:2302.12192, 2023. Long Lian, Boyi Li, Adam Yala, and Trevor Darrell. Llm-grounded diffusion: Enhancing prompt under-standing of text-to-image diffusion models with large language models. arXiv preprint arXiv:2305.13655,2023. Tsung-Yi Lin, Michael Maire, Serge Belongie, James Hays, Pietro Perona, Deva Ramanan, Piotr Dollr, andC Lawrence Zitnick. Microsoft coco: Common objects in context. In Computer VisionECCV 2014: 13thEuropean Conference, Zurich, Switzerland, September 6-12, 2014, Proceedings, Part V 13, pp. 740755.Springer, 2014. Nan Liu, Shuang Li, Yilun Du, Antonio Torralba, and Joshua B Tenenbaum. Compositional visual generationwith composable diffusion models. In European Conference on Computer Vision, pp. 423439. Springer,2022. Suvir Mirchandani, Fei Xia, Pete Florence, Danny Driess, Montserrat Gonzalez Arenas, Kanishka Rao, DorsaSadigh, Andy Zeng, et al. Large language models as general pattern machines. In 7th Annual Conferenceon Robot Learning, 2023.",
  "Reid Pryzant, Dan Iter, Jerry Li, Yin Tat Lee, Chenguang Zhu, and Michael Zeng. Automatic promptoptimization with\" gradient descent\" and beam search. arXiv preprint arXiv:2305.03495, 2023": "Alec Radford, Jong Wook Kim, Chris Hallacy, Aditya Ramesh, Gabriel Goh, Sandhini Agarwal, GirishSastry, Amanda Askell, Pamela Mishkin, Jack Clark, et al. Learning transferable visual models fromnatural language supervision. In International conference on machine learning, pp. 87488763. PMLR,2021. Colin Raffel, Noam Shazeer, Adam Roberts, Katherine Lee, Sharan Narang, Michael Matena, Yanqi Zhou,Wei Li, and Peter J Liu. Exploring the limits of transfer learning with a unified text-to-text transformer.The Journal of Machine Learning Research, 21(1):54855551, 2020.",
  "Jiaming Song, Chenlin Meng, and Stefano Ermon.Denoising diffusion implicit models.arXiv preprintarXiv:2010.02502, 2020": "Jiao Sun, Deqing Fu, Yushi Hu, Su Wang, Royi Rassin, Da-Cheng Juan, Dana Alon, Charles Herrmann,Sjoerd van Steenkiste, Ranjay Krishna, et al. Dreamsync: Aligning text-to-image generation with imageunderstanding feedback. arXiv preprint arXiv:2311.17946, 2023. Christian Szegedy, Vincent Vanhoucke, Sergey Ioffe, Jon Shlens, and Zbigniew Wojna.Rethinking theinception architecture for computer vision. In Proceedings of the IEEE conference on computer vision andpattern recognition, pp. 28182826, 2016. Hugo Touvron, Louis Martin, Kevin Stone, Peter Albert, Amjad Almahairi, Yasmine Babaei, Nikolay Bash-lykov, Soumya Batra, Prajjwal Bhargava, Shruti Bhosale, et al. Llama 2: Open foundation and fine-tunedchat models. arXiv preprint arXiv:2307.09288, 2023. Rodrigo Valerio, Joao Bordalo, Michal Yarom, Yonattan Bitton, Idan Szpektor, and Joao Magalhaes.Transferring visual attributes from natural language to verified image generation.arXiv preprintarXiv:2305.15026, 2023. Bram Wallace, Meihua Dang, Rafael Rafailov, Linqi Zhou, Aaron Lou, Senthil Purushwalkam, StefanoErmon, Caiming Xiong, Shafiq Joty, and Nikhil Naik. Diffusion model alignment using direct preferenceoptimization. arXiv preprint arXiv:2311.12908, 2023.",
  "Chengrun Yang, Xuezhi Wang, Yifeng Lu, Hanxiao Liu, Quoc V Le, Denny Zhou, and Xinyun Chen. Largelanguage models as optimizers. arXiv preprint arXiv:2309.03409, 2023": "Michal Yarom, Yonatan Bitton, Soravit Changpinyo, Roee Aharoni, Jonathan Herzig, Oran Lang, EranOfek, and Idan Szpektor. What you see is what you read? improving text-image alignment evaluation.arXiv preprint arXiv:2305.10400, 2023. Jiahui Yu, Yuanzhong Xu, Jing Yu Koh, Thang Luong, Gunjan Baid, Zirui Wang, Vijay Vasudevan, Alexan-der Ku, Yinfei Yang, Burcu Karagol Ayan, et al. Scaling autoregressive models for content-rich text-to-image generation. arXiv preprint arXiv:2206.10789, 2022. Mert Yuksekgonul, Federico Bianchi, Pratyusha Kalluri, Dan Jurafsky, and James Zou. When and whyvision-language models behave like bags-of-words, and what to do about it? In The Eleventh InternationalConference on Learning Representations, 2022. Yongchao Zhou, Andrei Ioan Muresanu, Ziwen Han, Keiran Paster, Silviu Pitis, Harris Chan, and JimmyBa. Large language models are human-level prompt engineers. In The Eleventh International Conferenceon Learning Representations, 2022.",
  "B.11-shot in-context learning as baseline": "In this experiment, we compare OPT2I with 1-shot in-context learning (ICL), which we implement byrunning OPT2I with #iter = 1 and #prompts/iter = 150. Note that, in this setting, the LLM only receivesfeedback about the performance of the user prompt. We maintain the same experimental setting described in, except we use 200 prompts for MSCOCO, and report the results in . First, we notice that1-shot ICL achieves higher prompt-image consistency than random paraphrasing in all settings except whenusing GPT-3.5, which performs on-par or slightly worse (marked with * in , see also the discussion inSection B.5). Second, and more importantly, we observe that OPT2I outperforms the 1-shot ICL baselineregardless of the consistency objective, LLM, or T2I model adopted. These results reinforce our previousclaims: (1) the iterative procedure allows OPT2I to keep improving revised prompts over time, and (2) 1-shotICL is challenging due to the limited feedback provided to the LLM about how to improve the user prompt,and thus only minor improvements in prompt-image consistency can be obtained over random paraphrasing.",
  "(b) DSG (P2)": ": OPT2I optimization curves obtained with prompts having SDSG(p0) < 1, marked by ** and fullcolors. In contrast, faded-color curves consider all prompts. Each plot tracks either the max or the meanrelative improvement in consistency across revised prompts per iteration. MSCOCO prompts (40%), and with less frequency on the more complex PartiPrompts prompts (10%).Since SDSG(p0, g(p0)) can be computed beforehand, we can avoid optimizing for those user prompts thathave already a perfect initial SDSG and better showcase the optimization performance of OPT2I. We providethe updated optimization curves in , and report the final results in . In both cases, wehighlight results obtained by filtering out perfect user prompts with full colors, and contrast them againstresults obtained with all prompts in faded colors (equivalent to ). In , we observe a higher relative improvement for both MSCOCO and PartiPrompts in all configura-tions when filtering out perfect user prompts, which is more prominent for MSCOCO because the numberof excluded prompts is higher. In , we observe similar consistent and considerable increases of alloptimization curves when considering both mean and max consistency improvement. In the mean case, weremark a reduction in the initial dip in relative consistency, especially in MSCOCO, where OPT2I reachesa positive relative consistency much earlier, i.e., it = vs. it = with Llama-2, GPT-3.5, andCDM-M, respectively.",
  "B.3Impact of seed-fixing and #images/prompt": "In this experiment, we ablate the impact of fixing the random seed of the initial noise for the diffusionmodel throughout the optimization process when optimizing different numbers of images/prompt. We useour default configuration with Llama-2 and LDM-2.1 on MSCOCO. In a, we show the optimizationcurves obtained when optimizing 1, 4 (default), and 10 images/prompt with fixed image seed. As expected,we observe no meaningful differences in mean consistency improvement. In contrast, the max consistencyimprovement shows a clear distinction between optimizing a single image (single seed) and optimizing 4 or10, with the former achieving more substantial improvements. We argue that when optimizing a single imageseed, OPT2I is more sensitive to changes in the prompts, i.e., there is a higher variance among the scores ofrevised prompts. We then contrast the optimization curves with fixed seed (8a) against the non-fixed seedones (8b). Our hypothesis is that optimizing, when not fixing the seed, generating too few images/promptleads to an unstable/unreliable feedback for the LLM due to the high variance of the generations. Indeed,looking at the optimization curves, we notice that optimizing a single image without fixing the seed is moredifficult for OPT2I, which results in a noisy and less steep trajectory, especially in the mean case. In contrast,when OPT2I optimizes 4 or 10 images/prompt with no fixed seed, both the max and mean curve remainsimilar w.r.t. to using a fixed seed. This supports our choice of generating 4 images/prompt, as it provides",
  "B.4Stratified PartiPrompts results": "shows the relative improvement in consistency score (dCS or DSG) on prompts from PartiPrompts(P2), broken down by challenge aspect. Note that we only sampled prompts from four of the most difficultdimensions in P2: Complex, Fine-grained Detail, Quantity, and Properties & Positioning. Intu-itively, this plot shows what kinds of prompts are easier to optimize for OPT2I when using different LLMs,T2I models and consistency scores. The most significant improvement in consistency is observed for prompts related to Properties & Posi-tioning when using Llama-2 in conjunction with CDM-M and dCS. Similarly, the combination of Llama-2,CDM-M, and DSG yields the best results for prompts about Quantity. For other challenges, CDM-M continuesto provide the most substantial consistency improvement, although the margin is narrower compared toLDM-2.1. Interestingly, GPT-3.5 shows the smallest improvement in consistency for prompts about Quan-tity, regardless of whether dCS or DGS metrics are used. Consistency improvements for prompts from theComplex and Fine-grained Detail challenges are comparable, which is expected due to their inherentsimilarities.",
  "B.5Why is GPT-3.5 not as good as Llama-2?": "In and , we observe that OPT2I achieves worse results when using GPT-3.5 as the LLM.Notably, the optimization curves with GPT-3.5 are flatter than when using Llama-2. This result is rathersurprising, as current leaderboards (Chiang et al., 2024) indicate that GPT-3.5 generally outperforms Llama-2on a wide variety of NLP tasks. So, in this experiment, we aim to shed light on the possible causes. Given theclosed (and expensive) access to GPT-3.5, our initial exploration of the meta-prompt structure and phrasingwas based on Llama-2, and later on we used the exact same prompt with GPT-3.5. Hence, one hypothesisfor the observed phenomenon is that our meta-prompt is better optimized for Llama-2. Another hypothesisis that each LLM has a different balance point between exploration and exploitation for the same samplingtemperature of 1.0. In particular, given the flatter optimization curves drawn by GPT-3.5, we conjecturethat it explores less diverse prompts than Llama-2. To verify this, we analyze some text properties of therevised prompts generated by both LLMs.",
  ": Text analysis of revised prompts generated by Llama-2 and GPT-3.5": "a tracks the length (in number of characters) of the revised prompts at each iteration, and btracks CLIP text similarity between revised prompts and the user prompt along the optimization process,both averaged over the revised prompts generated at the same iterations and over all prompts in the dataset.We observe that when using Llama-2 for OPT2I, the revised prompts generated at each iteration are longerand more semantically dissimilar to the user prompt compared to those generated by GPT-3.5. This meansthat OPT2I benefits from greater prompt diversity to find the best T2I prompts that lead to more consistentimages, which is better achieved with Llama-2. Additionally, we note that both the prompt length andthe semantic similarity with the user prompt start plateauing around the maximum number of iterationswe set, which further validates our selected value of 30. We leave as future work ablating for the samplingtemperature with both LLMs.",
  "B.6Additional qualitative examples": "Figures 11 and 12 show some additional selected examples of user prompt and revised prompts throughoutthe optimization process, along with the generated images and consistency scores. In particular, we selectrevised prompts such that the consistency score of the generated images (w.r.t. the user prompt) is strictlyhigher than the previous best score found so far, i.e., the leaps in prompt-image consistency. shows revised prompts generated with DSG as the scorer. Since DSG is computed as an averageof binary scores, it is more coarse than CLIPScore and thus there are fewer leaps in consistency. Overall,we observe that the intermediate revised prompt manages to increase the consistency score in some of thegenerated images but not for all of them. The best prompt, however, usually manages to improve all 4generated images. shows revised prompts generated with dCS as the scorer. In this case, we can see a gradual increasein average dCS, which visually translates to generated images which are more consistent with the user prompton average. The strong effect of the initial latent noise in the image structure is evident, yet substantialmodifications in the format of the input prompt used to condition the generation lead to significant changesin how the T2I model interprets the structure determined by the initial noise (e.g., between rows 2-3 and 4-5in the squirrel example). We also note that dCS (CLIPScore averaged over subprompts) can occasionally fallshort as an evaluation metric for image-text consistency. This is primarily because dCS tends to focus on thepresence of visual elements, overlooking other aspects such as spatial relationships. In the toilet example, forinstance, we observe how the generated images progressively become more consistent up to a certain point(around row 6). Beyond this point, the revised prompts and the generated images start degenerating (e.g.,by overemphasizing certain elements), while dCS continues to improve. This highlights that, while dCS may",
  "serve as a useful fine-grained consistency metric to provide visual feedback for T2I prompt optimization withan LLM, it may not be as effective for evaluation purposes": "1.0000 There is a pizza on the cutting board (0.5000) 0.3333 0.3333 0.3333 1.0000 A cutting board holds a delicious pizza. (0.8333) 1.0000 0.3333 1.0000 1.0000 On a clean cutting board, a mouthwatering pizza awaits slicing. (1.0000) 1.0000 1.0000 1.0000 0.2857 a cute wooden owl statue holding a large globe of the Earth above its head (0.3929) 1.0000 0.1429 0.1429 1.0000 An owl statue made of wood, with a charming expression, holds a large Earth globeabove its head, boasting a precision-crafted surface. (0.7857) 1.0000 0.1429 1.0000 1.0000 An enchanting wooden owl statue, with an endearing expression, cradles a massiveglobe showcasing the Earth's diverse terrain, as it sits atop a pedestal, ensuring astriking visual harmony, with the globe resting on its head. (1.0000) 1.0000 1.0000 1.0000 0.4444 A traffic light and a signpost at a crossroads intersection near a waterway. (0.3889) 0.4444 0.2222 0.4444 0.8889 A traffic light and signpost standing at a crossroads intersection, surrounded by awaterway. (0.6667) 0.8889 0.4444 0.4444 0.8889 A traffic light and signpost are positioned at a crossroads intersection, with abeautiful waterway flowing nearby, producing a striking visual. (0.9167) 1.0000 0.8889 0.8889 0.3750 A punk rock squirrel in a studded leather jacket shouting into a microphone whilestanding on a stump (0.5000) 0.6250 0.3750 0.6250 1.0000 Atop a tree stump, a rebellious squirrel wears a leather jacket with metal studs andholds a microphone, shouting into the wind with punk rock fervor. (0.7188) 0.7500 0.5000 0.6250 1.0000 A microphone-wielding squirrel, draped in a black leather jacket with silver studs,passionately shouts into the wind while standing on a stump, epitomizing the DIYethos and raw energy of punk rock. (0.9375) 0.8750 0.8750 1.0000 : Selected examples of initial prompts from MSCOCO (left) and PartiPrompts (right) and revisedprompts across the optimization, along with the generated images. The optimizer refines prompts for LDM-2.1using Llama-2 as LLM and DSG as scorer. We report DSG score averaged across images.",
  "B.7Results with updated models": "In this section, we report results with more recent (and better) T2I models and LLMs. We updated the T2Imodel to LDM-XL-Turbo (Sauer et al., 2023) and LDM-3 (Esser et al., 2024) (which is based on a diffusiontransformer), and the LLM to the instruction-finetuned Llama-3.1 (8B and 70B) (Dubey et al., 2024). Inaddition, we have upgraded the VQA model that powers the DSG metric to PaliGemma-224 (3B) (Beyeret al., 2024) finetuned on VQAv2 (Goyal et al., 2017). Optimization curves and comparison with baselinesWe report the results in (a-b) and. Our results show that, while the initial consistency score is higher, OPT2I still manages to con-siderably improve consistency. For instance, optimizing PartiPrompts prompts for 30 iterations generating5 solutions per iteration, Llama-3.1 (70B) with LDM-3 has an initial average DSG score of 84.7%; OPT2Iis able to find a rephrase of the initial prompts achieving an average DSG score of 98.8%, yielding a totalabsolute improvement of 14%. Note that the final DSG score is already very close to 100%, so theres notmuch more room for improvement. Meanwhile, a (compute-matched) paraphrasing baseline using the samemodels only achieves an average DSG score of around 97.7%. For LDM-XL-Turbo, the initial DSG score is72.8% and OPT2I is able to find prompt rephrases with an average DSG score of 93.7% (absolute improve-ment of 20.9%), while the paraphrasing baseline is only able to improve up to 91.5%. In every case, OPT2Iconsistently outperforms the paraphrasing baseline, which is in line with our results for older models (seefirst two rows of ). Therefore, we conclude that our framework increases the consistency even formore recent T2I models. Success rateIn (c), we report the success rate throughout the optimization process. At a giveniteration, we define success rate as the percentage of generated paraphrases that achieve a strictly higherconsistency score than the initial prompt.Because of this, here we only consider prompts that can beimproved, i.e., that do not already have an initial DSG score of 100%. We observe that, when optimizingprompts with OPT2I, the success rate surpasses 50% after 10 iterations, reaching up to 60-70% after 30iterations. Instead, the paraphrasing baseline only achieves a score between 30-40%.",
  "B.8Complete optimization example": "Here we provide a detailed example list of prompt paraphrases along with their fine-grained DSG scores. Weconsider the user prompt A dignified beaver wearing glasses, a vest, and colorful neck tie.He stands next to a tall stack of books in a library. (from PartiPrompts). We use Llama-3.1(70B), LDM-XL-Turbo and DSG-PaliGemma. We generate 3 new prompts per iteration, 4 images per prompt,and we early-stop when a perfect score of 100% is reached, which takes 7 iterations and 2 minutes 12 secondsin this case. In Figures 14/ 15, we show a prompt paraphrase from each iteration (including the initialprompt at iteration 0) and its corresponding DSG score, including the evaluation questions and the averageVQA scores for the 4 images.",
  ".\"A dignified beaver wearing glasses, a vest, and colorful neck tie.Hestands next to a tall stack of books in a library.\"": "overall score:90evaluation questions:Is there a beaver?100Does the beaver have glasses?25Does the beaver have a vest?100Does the beaver have a neck tie?100Is the beaver dignified?100Is the neck tie colorful?100Is the beaver standing?75Are there books?100Are the books in a tall stack?100Is there a library?100Is the beaver next to the books?75Is the beaver in the library?100Are the books in the library?100",
  ".\"A dignified beaver, wearing glasses perched on the end of its nose, avest, and a vibrant neck tie, stands upright next to a tall stack of books in aquiet library.\"": "overall score:86evaluation questions:Is there a beaver?100Does the beaver have glasses?50Does the beaver have a vest?75Does the beaver have a neck tie?100Is the beaver dignified?100Is the neck tie colorful?100Is the beaver standing?25Are there books?100Are the books in a tall stack?75Is there a library?100Is the beaver next to the books?100Is the beaver in the library?100Are the books in the library?100 2.\"A dignified beaver, wearing glasses perched on its nose, a vest, and avibrant neck tie, stands upright with confidence beside a tall stack of booksneatly arranged within arms reach on a library bookshelf.\" overall score:88evaluation questions:Is there a beaver?100Does the beaver have glasses?25Does the beaver have a vest?75Does the beaver have a neck tie?100Is the beaver dignified?100Is the neck tie colorful?75Is the beaver standing?100Are there books?100Are the books in a tall stack?100Is there a library?100Is the beaver next to the books?75 3.\"With poise and elegance, a well-dressed beaver stands directly adjacent toa high-rise bookshelf in a library, wearing glasses that sit comfortably on itsnose, along with a neat vest and a bright, eye-catching neck tie.\" overall score:86evaluation questions:Is there a beaver?100Does the beaver have glasses?50Does the beaver have a vest?100Does the beaver have a neck tie?100Is the beaver dignified?100Is the neck tie colorful?75Is the beaver standing?75Are there books?100Are the books in a tall stack?75Is there a library?100Is the beaver next to the books?50Is the beaver in the library?100Are the books in the library?100",
  ".\"In a library, a refined beaver stands proudly adjacent to a tall, orderlystack of books, wearing a pair of glasses, a vest, and a colorful neck tie,exuding an air of dignity.\"": "overall score:94evaluation questions:Is there a beaver?100Does the beaver have glasses?50Does the beaver have a vest?100Does the beaver have a neck tie?100Is the beaver dignified?100Is the neck tie colorful?100Is the beaver standing?75Are there books?100Are the books in a tall stack?100Is there a library?100Is the beaver next to the books?100Is the beaver in the library?100Are the books in the library?100 5.\"In a library, a refined beaver stands confidently on its hind legs,showcasing its dignified demeanor, while wearing glasses that sit comfortablyon the bridge of its nose, a vest, and a colorful neck tie, next to a toweringstack of books.\" overall score:94evaluation questions:Is there a beaver?100Does the beaver have glasses?50Does the beaver have a vest?100Does the beaver have a neck tie?100Is the beaver dignified?100Is the neck tie colorful?100Is the beaver standing?100Are there books?100Are the books in a tall stack?100Is there a library?100Is the beaver next to the books?75Is the beaver in the library?100Are the books in the library?100 6.\"A dignified beaver, adorned with a pair of spectacles resting comfortablyon its nose, stands upright beside a towering stack of books in a library,dressed in a vest and a vibrant neck tie, exuding an air of refinement.\" overall score:94evaluation questions:Is there a beaver?100Does the beaver have glasses?50Does the beaver have a vest?100Does the beaver have a neck tie?100Is the beaver dignified?100Is the neck tie colorful?100Is the beaver standing?75Are there books?100Are the books in a tall stack?100Is there a library?100Is the beaver next to the books?100Is the beaver in the library?100Are the books in the library?100 7.\"A dignified beaver, sporting a pair of wire-rimmed glasses with lensesthat sparkle in the library light, stands proudly next to a towering stack ofbooks, adorned with a colorful neck tie and a vest that complements its air ofsophistication.\" overall score:100evaluation questions:Is there a beaver?100Does the beaver have glasses?100Does the beaver have a vest?100Does the beaver have a neck tie?100Is the beaver dignified?100Is the neck tie colorful?100Is the beaver standing?100Are there books?100Are the books in a tall stack?100Is there a library?100Is the beaver next to the books?100Is the beaver in the library?100Are the books in the library?100"
}