{
  "ABSTRACT": "Preserving individual privacy while enabling collaborative datasharing is crucial for organizations. Synthetic data generation isone solution, producing artificial data that mirrors the statisticalproperties of private data. While numerous techniques have beendevised under differential privacy, they predominantly assume datais centralized. However, data is often distributed across multipleclients in a federated manner. In this work, we initiate the study offederated synthetic tabular data generation. Building upon a SOTAcentral method known as AIM, we present DistAIM and FLAIM. Wefirst show that it is straightforward to distribute AIM, extending arecent approach based on secure multi-party computation whichnecessitates additional overhead, making it less suited to federatedscenarios. We then demonstrate that naively federating AIM canlead to substantial degradation in utility under the presence ofheterogeneity. To mitigate both issues, we propose an augmentedFLAIM approach that maintains a private proxy of heterogeneity.We simulate our methods across a range of benchmark datasetsunder different degrees of heterogeneity and show we can improveutility while reducing overhead.",
  "INTRODUCTION": "Modern computational applications are predicated on the availabil-ity of significant volumes of high-quality data. Increasingly, suchdata is not freely available: it may not be collected in the volumeneeded, and may be subject to privacy concerns. Recent regulationssuch as the General Data Protection Regulation (GDPR) restrictthe extent to which data collected for a specific purpose may beprocessed for some other goal. The aim of synthetic data generation",
  "KDD 24, August 2529, 2024, Barcelona, Spain 2024 Copyright held by the owner/author(s).ACM ISBN 979-8-4007-0490-1/24/08": "(SDG) is to solve this problem by allowing the creation of realisticartificial data that shares the same structure and statistical proper-ties as the original data source. SDG is an active area of research,offering the potential for organisations to share useful datasetswhile protecting the privacy of individuals .SDG methods fall into two categories: deep learning and statistical models . Nevertheless, without strict privacymeasures in place, it is possible for SDG models to leak informa-tion about the data it was trained on . It is common fordeep learning approaches such as Generative Adversarial Networks(GANs) to produce verbatim copies of training data, breaching pri-vacy . A standard approach to prevent leakage is to useDifferential Privacy (DP) . DP is a formal definition which en-sures the output of an algorithm does not depend heavily on any oneindividuals data by introducing calibrated random noise. Under DP,statistical models have become state-of-the-art (SOTA) for tabulardata and often outperform deep learning counterparts .Approaches are based on Bayesian networks , Markov randomfields and iterative marginal-based methods .Private SDG methods perform well in centralized settings wherea trusted curator holds all the data. However, in many settings, datacannot be easily centralized. Instead, there are multiple participantseach holding a small private dataset who wish to generate syntheticdata. Federated learning (FL) is a paradigm that applies when mul-tiple parties wish to collaboratively train a model without sharingdata directly . In FL, local data remains on-device, and onlymodel updates are transmitted back to a central aggregator .FL methods commonly adopt differential privacy to provide formalprivacy guarantees and is widely used in deep learning .However, there has been minimal focus on federated SDG: we onlyidentify a recent effort of Pereira et al. to distribute MultiplicativeWeights with Exponential Mechanism (MWEM) via secure multi-party computation (SMC) . Their work focuses on a distributedsetting which assumes a small number of participants are all avail-able to secret-share data before the protocol begins. This is notsuited for the fully federated setting where there may be thousandsof clients and only a small proportion available at a particular round.In this work, we study generating differentially private tabulardata in the federated setting where only a small proportion of clientsare available per-round who exhibit strong data heterogeneity. Wepropose FLAIM, a novel federated analogue to the current SOTAcentral DP algorithm AIM . We show how an analog to tradi-tional FL training can be formed with clients performing a numberof local steps before sending model updates to the server in theform of noisy marginals. We highlight how this naive extension cansuffer severely under strong heterogeneity which is exacerbatedwhen only a few clients participate per round. To circumvent this,we modify FLAIM by replacing components of central AIM withnewly-built steps that are better suited to the federated setting, such",
  "as augmenting clients local choices via a private proxy of skew toensure decisions are not adversely affected by heterogeneity": "Example. presents a federated scenario where 10% of 100clients participate per round. Each client holds data with varyingdegrees of feature skew, where a larger implies less heterogeneity.We use four variations: Centralised AIM (black); Distributed AIM,our adaptation of Pereira et al. (purple); our naive federatedAIM approach (red); and our improved federated version (green). Weplot the 1 error over a workload of marginal queries trained with = 1. Due to client availability, there is an inevitable utility gapbetween central and distributed AIM. By naively federating AIM, clientdecisions made in local training are strongly affected by heterogeneitywhile distributed AIM is not, resulting in a big loss in utility. This gapis almost closed in high skew scenarios (small ) by penalising clientslocal decisions via a private measure of heterogeneity (AugFLAIM).",
  "Our main contributions are as follows:": "We are the first to study marginal-based methods in the fed-erated setting. We extend the work of Pereira et al. whofocus on a strongly synchronized distributed setting withMWEM to instead form a distributed protocol that replacesMWEM with AIM to obtain greater utility (DistAIM). Motivated to reduce the overheads present in DistAIM, wepropose FLAIM, our federated analogue of AIM that isdesigned specifically for the federated setting. We proposenovel extensions based on augmenting utility scores in AIMdecisions via a private proxy that reduces the effect hetero-geneity has on local decisions, resulting in increased modelperformance and smaller overheads.",
  "PRELIMINARIES": "We assume the existence of participants each holding local datasets1, . . . , over a set of attributes such that the full dataset isdenoted := . Additionally, we assume that each attribute iscategorical2. For a record := (1, . . . ,) we denote as thevalue of attribute . For each attribute [], we define as the setof discrete values that can take. For a subset of attributes []we abuse notation and let be the subset of with attributes in theset . We are mostly concerned with computing marginal queriesover (or individual ). Let [] and define := ,as the set of values can take and := || as the cardinality of .",
  "Definition 2.1 (Marginal Query). A marginal query for asubset of features [] is a function : D R whereeach entry is a count of the form (()) := 1[ = ], [],": "As an example, consider a dataset with two features: unemploy-ment and age where 1 = {0, 1} and 2 = {1, 2, ..., 99}. The outputof the marginal query = {,} is a vector wherean entry is a count of each record that satisfies a possible combi-nation of feature values e.g., { = 0, = 18}. The goal inworkload-based synthetic data generation is to generate a syntheticdataset that minimises Err(, ) over a given workload of (mar-ginal) queries . We follow existing work and study the averageworkload error under the 1 norm . Definition 2.2 (Average Workload Error). Denote the work-load = {1, . . . ,} as a set of marginal queries where each []. The average workload error for synthetic dataset is definedErr(, ;) :=1| | () ( )1 We are interested in producing a synthetic dataset with marginalsclose to that of . However, in the federated setting it is often im-possible to form the global dataset := due to privacyrestrictions or client availability. Instead the goal is to gather suf-ficient information from local datasets and train a model thatlearns (). For any , the marginal query () and localworkload error Err(, ) are defined analogously.Differential Privacy (DP) is a formal notion that guaranteesthe output of an algorithm does not depend heavily on any individ-ual. We seek to guarantee (,)-DP, where the parameter is calledthe privacy budget and determines an upper bound on the privacyleakage of the algorithm. The parameter defines the probabilityof failing to meet this, and is set very small. DP has many attrac-tive properties including sequential composition, meaning that iftwo algorithms are (1,1)-DP and (2,2)-DP respectively, thentheir joint output on a specific dataset satisfies (1 + 2,1 +2)-DP.Tighter bounds are obtained via zero-Concentrated DP (zCDP) :",
  "Definition 2.3 (-zCDP). A mechanism M is -zCDP if forany two neighbouring datasets , and all (1, ) we have (M()|M() , where is Renyi divergence of order": "One can convert -zCDP to obtain an (,)-DP guarantee. Thenotion of adjacent datasets can lead to different privacy defini-tions. We assume example-level privacy, which defines two datasets, to be adjacent if can be formed from the addition/removalof a single row from . To satisfy DP it is common to requirebounded sensitivity of the function we wish to privatize. Definition 2.4 (Sensitivity). Let : D R be a functionover a dataset. The 2 sensitivity of , denoted 2( ), is defined as2( ) := max () ()2, where represents theexample-level relation between datasets. Similarly, 1( ) is definedwith the 1 norm as 1( ) := max () ()1.",
  "-zCDP": "Iterative Methods (Select-Measure-Generate). Recent methodsfor private tabular data generation follow the Select-Measure-Generate paradigm which is also the core focus of our work. Theseare broadly known as iterative methods and usually involvetraining a graphical model via noisy marginals over a number ofsteps. In this work, we focus on AIM , an extension of the classi-cal MWEM algorithm , which replaces the multiplicative weightupdate with a graphical model inference procedure called Private-PGM . PGM learns a Markov Random Field (MRF) and appliespost-processing optimisation to ensure consistency in the gener-ated data. PGM can answer queries without directly generatingdata from the model, thus avoiding additional sampling errors.In outline, given a workload of queries , AIM proceeds as fol-lows (further details are in the full technical report):",
  "),": "where (1) is the current PGM model. The core idea is to selectmarginals that are high in error (first term) balanced with the ex-pected error from measuring the query under Gaussian noise withvariance 2 (second term). The utility scores are weighted by := | |, which calculates the overlap of other marginals in theworkload with . The sensitivity of the resulting exponential mech-anism is = max since measuring () ( (1))1has sensitivity 1 which is weighted by . Once a query is selectedit is measured by the Gaussian mechanism with variance 2 andsensitivity 1. An update to the model via PGM is then applied usingall observed measurements so far. See Appendix A.1 for full details.Towards Decentralized Synthetic Data. Given a set of clientswith datasets 1, . . . and workload , the goal is to learn asynthetic dataset that best approximates := over e.g.,( ) (), . However, computing statistics directlyfrom is not possible as each is private. We make an importantdistinction here between the highly-synchronized distributed andloosely-coordinated federated settings. In the distributed setting,all participants are available to collaboratively share () andsome central server(s) compute steps of AIM in a strongly syn-chronized manner, with high communication overhead. This is theoriginal setting of Pereira et al. . Instead we are mainly inter-ested in the federated setting where we assume that participantsare more weakly engaged, and may become unavailable or dropoutat any moment. We model this by assuming that each participantparticipates in the current round only with probability . We alsoassume each exhibits heterogeneity which could manifest assignificant feature-skew or a varying number of samples. We detailhow we model heterogeneity in .",
  "DISTRIBUTED AIM": "Our first proposal, DistAIM, translates the AIM algorithm directlyinto the federated setting by having computing servers jointlycalculate each step, attempting to mirror what would be computedin the central setting. To do so, computing servers must collaborateprivately and securely, such that no one participants raw queryanswers, (), are revealed. The select and measure stepsrequire direct access to private local datasets , and hence weneed to implement distributed DP mechanisms for these steps. Wepresent an overview here with full details in Appendix A.2.Pereira et al. , describe one such approach for MWEM. Theyutilize various secure multi-party computation (SMC) primitivesbased on secret-sharing . However, a key difference is they as-sume a distributed setting where all participants first secret-sharetheir workload answers to computing servers before the protocolbegins. These computing servers implement secure exponential andLaplace mechanisms over shares of marginals via standard SMC op-erations . This is a key difference to our federated setting wherewe assume partial participation of clients over multiple rounds.Their approach also has two drawbacks: first, their cryptographicsolution incurs both a computation and communication overheadwhich may be prohibitive in federated scenarios. Secondly, theirapproach is based on MWEM which results in a significant lossin utility. Furthermore, MWEM is memory-intensive and does notscale to high-dimensional datasets.Instead, we apply the framework of Pereira et al. to AIM,and adapt this for our federated setting. Compared to AIM andPereira et al., our DistAIM approach has important differences:Client participation: At each round only a subset of participantsare available to join the AIM round. For simplicity, we assume",
  "KDD 24, August 2529, 2024, Barcelona, SpainSamuel Maddock, Graham Cormode, and Carsten Maple": "counter-intuitive. However, AugFLAIM (Oracle) is still trained un-der DP, only oracle access to () is assumed which is non-privateand trained without heuristics as explored in .2.Varying the number of global AIM rounds (). In b, wevary the number of global AIM rounds and fix = 1. Additionally,we plot the setting where is chosen adaptively by budget anneal-ing. This is shown in dashed lines for each method. First observewith DistAIM, the workload error decreases as increases. Sincecomputing servers aggregate secret-shares across rounds, then asgrows large, most clients will have been sampled and the server(s)have workload answers over most of the (central) dataset. For allFLAIM variations, the workload error usually increases when islarge, since they are more sensitive to the increased amount of noisethat is added. For NaiveFLAIM, this is worsened by client hetero-geneity. Further, we observe that for AugFLAIM (Private), the utilitymatches that of DistAIM unless the choice of is very large. At = 100, the variance in utility is high, sometimes even worse thanthat of NaiveFLAIM. This is since the privacy cost scales in both thenumber of rounds and features, resulting in too much noise. In thecase of annealing, is chosen adaptively by an early stopping con-dition (see Appendix B.4). While annealing has good performancein central AIM, it obtains poor utility across all federated methods.For annealing on Adult, AugFLAIM (Private) matches AugFLAIM(Oracle) and both perform better than NaiveFLAIM. Overall, wefound choosing to be small ( 30) gives best performance forAugFLAIM and should avoid using budget annealing.Client-participation (). In c, we plot the average work-load error whilst varying the per-round participation rate () with = 10, = 1. We observe clearly the gap in performance betweencentral AIM and DistAIM is caused by the error introduced by sub-sampling and when 0.5 performance is almost matched. ForNaiveFLAIM, we observe the performance improvement as in-creases is slower than other methods. When is large, NaiveFLAIMreceives many measurements, each likely to be highly heteroge-neous and thus the model struggles to learn consistently. For bothAugFLAIM variations, we observe the utility improves with clientparticipation but does eventually plateau. AugFLAIM (Private) con-sistently matches the error of DistAIM except when is large, butwe note this is not a practical regime in FL.Varying heterogeneity (). In d, we plot the average work-load error on the Adult dataset over client splits formed by varyingthe heterogeneity parameter () to produce label-skew. Here, alarger corresponds to a more uniform partition and therefore lessheterogeneity. In the label-skew setting, data is both skewed accord-ing to the class attribute of Adult and the number of samples, withonly a few clients holding the majority of the dataset. We observethat when the skew is large ( < 0.1), all methods struggle. As increases and skew decreases, NaiveFLAIM performs the worst andAugFLAIM (Private) has stable error, close to that of DistAIM.Varying local rounds (). A benefit of the federated setting isthat clients can perform a number of local steps before sending allmeasured marginals to the server. However, for FLAIM methods,this incurs an extra privacy cost in the number of local rounds(). In e, we vary {1, 4} and plot the workload error.Although there is an associated privacy cost with increasing , theerrors are not significantly different for small . As we vary ,the associated privacy cost becomes larger and the workload error increases for methods that perform = 4 local updates. Althoughincreasing the number of local rounds () does not result in lowerworkload error, and in cases where is misspecified can give farworse performance, it is instructive to instead study the test AUCof a classification model trained on the synthetic data. In fwe see that performing more local updates can give better test AUCafter fewer global rounds. For AugFLAIM (Private), this allows usto match the test AUC performance of DistAIM on Adult.Comparison across datasets. presents results across alldatasets with client data partitioned via the clustering approach.We set = 1, = 0.1 and = 10. For each method we present boththe average workload error and the negative log-likelihood over aholdout set. The first is a form of training error and the second ameasure of generalisation. We observe that on 5 of the 7 datasetsAugFLAIM (Private) achieves the lowest negative log-likelihoodand workload error. On the other datasets, AugFLAIM (private)closely matches DistAIM in utility but with lower overheads.Distributed vs. Federated AIM. presents the overhead ofDistAIM compared to AugFLAIM (Private) including average clientthroughput (sent and received communication) across protocols.We set that achieves lowest workload error. Observe onAdult, DistAIM requires twice as many rounds to achieve optimalerror and results in a large (1300) increase in client throughputcompared to AugFLAIM. However, this results in 2 lower work-load error and an 11% improvement in NLL. This highlights oneof the chief advantages of FLAIM, where, for a small loss in utility,we can obtain much lower overheads. Furthermore, while a 2 gapin workload error seems significant, we refer back to f,which shows the resulting classifier has AUC that is practical fordownstream tasks. We note the overhead of DistAIM is significantlylarger than FLAIM when queries in the workload have large car-dinality (e.g., on Adult and Magic). Datasets with much smallerfeature domains still have communication overhead but it is not assignificant (e.g., Covtype which has many binary features).",
  "FLAIM: FL ANALOG FOR AIM": "While DistAIM is one solution, it is not defined within the standardfederated paradigm where clients typically perform a number oflocal steps before sending model updates to a server. Furthermore,the SMC-based approach can have large overheads which is prohib-itive for federated clients who have limited bandwidth (we explorethis in .3). This leads us to design an AIM approach that isanalogous to traditional Federated Learning (FL), where only light-weight SMC is needed in the form of secure-aggregation (SecAgg). In FL, the paradigm for training models is to do computationon-device, having clients perform multiple local steps before send-ing a model update. The server aggregates all client updates andperforms an update to the global model . When combined withDP, model updates are aggregated via SecAgg schemes and noise isadded either by a trusted server or in a distributed manner. In thecase of AIM, we denote our analogous FL approach as FLAIM. InFLAIM, the selection step of AIM is performed locally by clients(across multiple local training steps). Each clients chosen marginalsare then sent to a trusted server via SecAgg and noise is added.In more detail, FLAIM is outlined in Algorithm 1. We presentthree variations, with differences highlighted in color. Shared be-tween all variations are the key differences with DistAIM displayedin blue underline. First is NaiveFLAIM, a straightforward transla-tion of AIM into the federated setting. In .1, we explainthe shortcomings of such an approach which stems from scenarioswhere clients local data exhibits strong heterogeneity. Motivatedby this, .2 proposes AugFLAIM (Oracle) a variant of FLAIMthat assumes oracle access to a measure of skew which can be usedto augment local utility scores. This skew measure is non-privateand not obtainable in practice, but provides an idealized baseline.",
  "arg minS(,, , )M () 2": "Lastly, .3 introduces AugFLAIM (Private), which again aug-ments local utility scores but with a private proxy of heterogeneityalongside other heuristics to improve utility.All FLAIM variants proceed by sampling clients to participatein round . Each client performs a number of local steps , whichconsist of performing a local selection step using the exponentialmechanism, measuring the chosen marginal under local noise andupdating their local model via PGM. When each client finisheslocal training, they send back each chosen query alongside theassociated marginal (), which are aggregated via secure-aggregation and noise is added by the central server. Hence, localtraining is done under local differential privacy (LDP) to not leakany privacy between steps, whereas the resulting global update isunder a form of distributed DP where noise is added by the centralserver to the securely-aggregated marginals. We assume all AIM",
  "NaiveFLAIM and Heterogeneous Data": "NaiveFLAIM is our first attempt at a SDG in the federated setting,by directly translating the AIM algorithm. However, in federatedsettings, participants often exhibit strong heterogeneity in theirlocal datasets. That is, clients local datasets can differ signif-icantly from the global dataset . Such heterogeneity will affectAIM in both the select and measure steps. If and are sig-nificantly different then the local marginal () will differ fromthe true marginal (). We quantify heterogeneity for a client and query via the 1 distance:",
  "() := () ()1": "This can be viewed as a measure of query skew. In FLAIM, weproceed by clients perform a number of local steps. The first stageinvolves carrying out a local select step based on utility scoresof the form (; ) () ( (1))1. Suppose for aparticular client there exists a query such that ()exhibits strong heterogeneity. If at step the current model (1) is a good approximation of , then it is probable that client endsup selecting any query that has high heterogeneity since(; ) ||() ( (1))||1 ||() ()||1 = (). Thismismatch can harm model performance and is compounded byhaving many clients select (multiple and possibly differing) skewedmarginals and so the model is updated in a way that drifts from .",
  "(; ) () ( ) ()": "where () is an exact 1 measure of heterogeneity for client at a marginal . Unfortunately, measuring () under privacyconstraints is not feasible. That is, () depends directly on (),which is exactly what we are trying to learn via AIM. Still, weintroduce AugFLAIM (Oracle) as an idealized baseline to comparewith. AugFLAIM (Oracle) is a variation of FLAIM that assumesoracle access to () and augments local utility scores as above.",
  "() :=1|| { } () { } ()1": "Instead of computing a measure for each , we compute onefor each feature [], where { } () is a noisy estimate ofthe 1-way marginal for feature . For a particular query , weaverage the skew of the associated features contained in . Sucha () relies only on estimating the distribution of each feature.This estimate can be refined across multiple federated rounds aseach participant can measure { } () for each [] and havethe server sum and add noise (via SecAgg) to produce a new privateestimate { } () each round. We add two further enhancements:1. Filtering and combining 1-way marginals (Line 10). As werequire clients to estimate all features at every round, we remove 1-way marginals from the workload to prevent clients from measuringthe same marginal twice. All 1-way marginals that are estimatedfor () are fed back into PGM to improve the global model.2. Weighting Marginals (Line 15). In PGM, measurements areweighted by = 1/, so those that are measured with less noisehave more importance in the optimisation of model parameters.Both AugFLAIM variations adopt an additional weighting schemethat includes the total sample size that contributed to a particularmarginal at round , := {: M } | | where the weight becomes = /. This relies on knowing the number of samplesthat are aggregated. In some cases, the size of datasets may bedeemed private. In such scenarios, it can be estimated from thenoisy marginal by summing the counts to produce .The privacy guarantees of all FLAIM variations follow directlyfrom those of AIM. The use of a heterogeneity measure incursan additional sensitivity cost for the exponential mechanism andAugFLAIM (Private) incurs an additional privacy cost as it measureseach of the features at every round. The following lemma capturesthis. See Appendix A.3 for the full proof.",
  "EXPERIMENTAL EVALUATION": "For our experiments, we utilize realistic benchmark tabular datasetsfrom the UCI repository : Adult, Magic, Marketing and Covtype.We further use datasets common for benchmarking synthetic data:Census and Intrusion from the Synthetic Data Vault (SDV) . Wealso construct a toy dataset with feature-skew denoted SynthFS.Full details on all datasets are contained in Appendix B.1.We evaluate our methods in three ways: average workload error(as defined in ), average negative log-likelihood (evaluatedon test data) and the area under the curve (AUC) of a decision treemodel trained on synthetic data and evaluated on test data.For all datasets, we simulate heterogeneity by forming non-IIDsplits in one of two ways: The first is by performing dimensionalityreduction and clustering nearby points to form client partitions thathave strong feature-skew. We call this the clustering approach.For experiments that require varying heterogeneity, we form splitsvia an alternative label-skew method popularized by Li et al. .This samples a label distribution for each class froma Dirichlet() where larger results in less heterogeneity. See Ap-pendix B.2 for full details. In the following sections, all experimentshave = 100 clients with partitions formed from the clusteringapproach unless stated otherwise. We train (FL)AIM models on afixed workload of 3-way marginal queries chosen at random with|| = 64 and average results over 10 independent runs. Furtherexperiments on datasets besides Adult are contained in AppendixC.",
  "Comparison with Existing Baselines": "We begin with an experiment comparing AugFLAIM (Private) toother federated baselines. One such SOTA approach is CTGAN. We utilise the DP-CTGAN implementation within OpenDPssmartnoise-sdk to compare to AIM. For the federated settingwe train CTGAN using DP-FedSGD via FLSim . For details onhyperparameters see Appendix B.4. We further compare AugFLAIM(Private) against two AIM baselines. FLAIM (Random) which takesFLAIM and randomly chooses a query without utilising the exponential mechanism. Instead, all privacy budget is spent onthe Measure step. The other is FedNaiveBayes which restricts theworkload to only 1-way marginals and is equivalent to training aNaiveBayes model. In we present the negative log-likelihood(NLL) for models trained to an = 5 across three datasets. Methodsachieving lowest NLL for a particular dataset are in bold.For the central setting, AIM achieves better performance thanDP-CTGAN across each dataset. This confirms prior studies suchas that show graphical model approaches achieve better utilitythan deep learning methods for tabular data. For the federated set-ting, we note FedNaiveBayes and FLAIM (Random) both performpoorly in comparison to AugFLAIM (Private). This illustrates twomain points: utilising the exponential mechanism does result in asubstantial increase in utility (i.e., randomly choosing is poor)and that utilising a workload of -way marginals with > 1 givesbest utility (i.e., NaiveBayes is poor). Further note, AugFLAIM (Pri-vate) has better utility than NaiveFLAIM which shows augmentingutility scores in the Exponential mechanism does improve utility.We explore this further in .3. Finally, Fed DP-CTGAN per-forms very poorly compared to AugFLAIM. Even NaiveFLAIM andoccasionally FedNaiveBayes outperform it. There are further issuesfor practitioners: first, Fed DP-CTGAN requires a large numberof hyperparameters to be tuned for best utility such as client andserver learning rates and the clipping norm. This is in contrast to(FL)AIM methods that only have a single hyperparameter - the totalnumber of global rounds. Secondly, CTGAN requires a large num-ber of training epochs. In this experiment we train for 50 epochswhich is equivalent to = 500 rounds whereas the FLAIM methodsachieve better utility in only = 10 rounds. For these reasons, infurther experiments, we do not compare to federated CTGAN.",
  ": Varying (FL)AIM Parameters on Adult; Unless otherwise stated = 10, = 1, = 0.1, = 100, = 1": "the global rounds . We present NaiveFLAIM compared with varia-tions that augment the utility scores of the Exponential mechanism.These are: using the true heterogeneity measure () only (other-wise denoted AugFLAIM (Oracle)); using () with the filter-and-combine heuristic; using the private heterogeneity proxy () onlyand using () with the filter and combine heuristic (otherwisedenoted AugFLAIM (Private)). On the Credit dataset, using ()or () only results in a clear improvement over NaiveFLAIM, andwhen combined with the heuristics the lowest error is obtained.On Adult and Covtype, using only () or the private proxy ()does not immediately result in lower workload error than Naive-FLAIM. Instead, utilising the filter and combine heuristics results inthe best workload error overall. In further experiments, we denoteAugFLAIM (Private) as the method which augments utility scoreswith () and uses the filter and combine heuristic whereas wedenote AugFLAIM (Oracle) as the method that has oracle access to () only (without further heuristics).",
  "Parameter Settings": "Having concluded that AugFLAIM (Private) achieves the best per-formance against other federated baselines, we now present a de-tailed set of experiments comparing FLAIM methods with DistAIMacross a variety of federated settings. We compare AIM and Dis-tAIM against NaiveFLAIM and our two variants that augment localutility scores: AugFLAIM (Oracle) using () only and AugFLAIM(Private) using proxy () with filtering and combining 1-ways.Varying the privacy budget (). In a, we plot the work-load error whilst varying on Adult, sampling 10% of clients perround and setting = 10. First, we observe a clear gap in perfor-mance between DistAIM and central AIM due to the error fromsubsampling a small number of clients per round. We observe thatnaively federating AIM gives the worst performance even as becomes large. Furthermore, augmenting utility scores makes aclear improvement in workload error, particularly for > 1. Byestimating feature distributions at each round, AugFlaim (Private)can obtain performance that matches or sometimes improves uponDistAIM for larger values of . We further note that AugFLAIM(Private) has lower error than AugFLAIM (Oracle) which may seem",
  "RELATED WORK": "Synthetic data has gained substantial traction due to its potentialto mitigate privacy concerns and address limitations for sharingreal-world data. Many generative deep learning approaches existincluding GANs , VAEs and diffusion models . Recentwork has extended these synthetic data generators (SDGs) to satisfycentral differential privacy (DP) and whilst results arepromising for image data, performance on tabular data remainslimited. Only a few generative tabular approaches exist includingthat of CTGAN . However, recent work has shown thatprivate tabular approaches like DP-CTGAN often fail to providegood utility when compared to simpler models . Indeed, inthe central setting of DP many successful methods are based ongraphical models such as PrivBayes , PrivSyn , PGM and AIM . Recent work has shown the class of iterative methods are SOTA on tabular data and we choose to focus on one ofthese methods, AIM, in our work. Meanwhile, research into SDGsin the federated setting remains limited. Recent federated SDGs arefocused on image data such as MD-GAN , FedGAN andFedVAE . We do not compare with these in our work as they donot support tabular data or DP. The closest work to ours is that of",
  "Dataset ()Throughput ()Err ()NLL ()": "Adult21300 (80 / 0.06)58%11%Magic3.21643 (80 / 0.04)20%14%Census1.5x64x (29.6 / 0.46)79%33%Intrusion2.5x366x (101 / 0.28)82%52%Marketing2.0x97x (18 / 0.19)77%35%Credit1.0x167x (93 / 0.55)45%6%Covtype1.25x10x (7.6 / 0.76)64%3% Pereira et al. who propose a distributed DP version of MWEM using secure multiparty computation (SMC) to distribute noisegeneration across computing servers. This approach has two maindrawbacks: it assumes all clients are available to secret-share theirworkload answers and as it is based on MWEM, obtains subparutility. Our work is motivated to extend their approach to AIMand to study an alternative and more natural federation of thesemethods. We also note the concurrent work of Pentyala et al. which extends to work with AIM via SMC.",
  "CONCLUSION": "Overall, we have shown that naively federating AIM under the chal-lenges of FL causes a large decrease in utility when compared to theSMC-based DistAIM. To counteract this, we propose AugFLAIM(Private), which augments local decisions with a proxy for het-erogeneity and obtains utility close to DistAIM while loweringoverheads. In the future, we plan to extend our approaches to sup-port user-level DP where clients hold multiple data items related tothe same individual. Work performed at Warwick University is supported by the UKRIEngineering and Physical Sciences Research Council (EPSRC) un-der grant EP/W523793/1; the UKRI Prosperity Partnership Scheme(FAIR) under EPSRC grant EP/V056883/1; and the UK NCSC Aca-demic Centre of Excellence in Cybersecurity Research (ACE-CSR).",
  "Toshinori Araki, Jun Furukawa, Yehuda Lindell, Ariel Nof, and Kazuma Ohara.2016. High-throughput semi-honest secure three-party computation with anhonest majority. In ACM SIGSAC CCS. Vienna, 805817": "Samuel A Assefa, Danial Dervovic, Mahmoud Mahfouz, Robert E Tillman,Prashant Reddy, and Manuela Veloso. 2020. Generating synthetic data in fi-nance: opportunities, challenges and pitfalls. In Proceedings of the First ACMInternational Conference on AI in Finance. ACM, New York, 18. Sergul Aydore, William Brown, Michael Kearns, Krishnaram Kenthapadi, LucaMelis, Aaron Roth, and Ankit A Siva. 2021. Differentially private query releasethrough adaptive projection. In ICML. PMLR, 457467.",
  "Jonathan Ho, Ajay Jain, and Pieter Abbeel. 2020. Denoising diffusion probabilisticmodels. Advances in neural information processing systems 33 (2020), 68406851": "Florimond Houssiau, James Jordon, Samuel N Cohen, Owen Daniel, AndrewElliott, James Geddes, Callum Mole, Camila Rangel-Smith, and Lukasz Szpruch.2022. TAPAS: a toolbox for adversarial privacy auditing of synthetic data. NeurIPSWorkshop on Synthetic Data for Empowering ML Research (2022). Dzmitry Huba, John Nguyen, Kshitiz Malik, Ruiyu Zhu, Mike Rabbat, AshkanYousefpour, Carole-Jean Wu, Hongyuan Zhan, Pavel Ustinov, Harish Srinivas,et al. 2022. Papaya: Practical, private, and scalable federated learning. Proceedingsof Machine Learning and Systems 4 (2022), 814832.",
  "Peter Kairouz, Brendan McMahan, Shuang Song, Om Thakkar, AbhradeepThakurta, and Zheng Xu. 2021. Practical and private (deep) learning withoutsampling or shuffling. In ICML. PMLR, 52135225": "Peter Kairouz, H. Brendan McMahan, Brendan Avent, Aurlien Bellet, Mehdi Ben-nis, Arjun Nitin Bhagoji, Kallista Bonawitz, Zachary Charles, Graham Cormode,Rachel Cummings, Rafael G. L. DOliveira, Hubert Eichner, Salim El Rouayheb,David Evans, Josh Gardner, Zachary Garrett, Adri Gascn, Badih Ghazi, Phillip B.Gibbons, Marco Gruteser, Zaid Harchaoui, Chaoyang He, Lie He, Zhouyuan Huo,Ben Hutchinson, Justin Hsu, Martin Jaggi, Tara Javidi, Gauri Joshi, Mikhail Kho-dak, Jakub Konen, Aleksandra Korolova, Farinaz Koushanfar, Sanmi Koyejo,Tancrde Lepoint, Yang Liu, Prateek Mittal, Mehryar Mohri, Richard Nock, Ayferzgr, Rasmus Pagh, Mariana Raykova, Hang Qi, Daniel Ramage, Ramesh Raskar,Dawn Song, Weikang Song, Sebastian U. Stich, Ziteng Sun, Ananda TheerthaSuresh, Florian Tramr, Praneeth Vepakomma, Jianyu Wang, Li Xiong, ZhengXu, Qiang Yang, Felix X. Yu, Han Yu, and Sen Zhao. 2019. Advances and OpenProblems in Federated Learning. arXiv:1912.04977 [cs.LG]",
  "Qinbin Li, Yiqun Diao, Quan Chen, and Bingsheng He. 2022. Federated learningon non-iid data silos: An experimental study. In IEEE ICDE. 965978": "Terrance Liu, Giuseppe Vietri, and Steven Z Wu. 2021. Iterative methods forprivate synthetic data: Unifying framework and new methods. Advances inNeural Information Processing Systems 34 (2021), 690702. Yucong Liu, Chi-Hua Wang, and Guang Cheng. 2022. On the Utility RecoveryIncapability of Neural Net-based Differential Private Tabular Training DataSynthesizer under Privacy Deregulation. arXiv:2211.15809 [cs.LG]",
  "Security 22). USENIX, Vancouver, 14511468": "Yuchao Tao, Ryan McKenna, Michael Hay, Ashwin Machanavajjhala, and GeromeMiklau. 2022. Benchmarking differentially private synthetic data generationalgorithms. In Workshop on Privacy-Preserving Artificial Intelligence, AAAI 2022.AAAI, Vancouver. Reihaneh Torkzadehmahani, Peter Kairouz, and Benedict Paten. 2019. Dp-cgan:Differentially private synthetic data and label generation. In Proceedings of theIEEE/CVF Conference on Computer Vision and Pattern Recognition Workshops. 00.",
  "Boris van Breugel and Mihaela van der Schaar. 2023. Beyond Privacy: Nav-igating the Opportunities and Challenges of Synthetic Data. arXiv preprintarXiv:2304.03722 (2023)": "Zhiqiang Wan, Yazhou Zhang, and Haibo He. 2017. Variational autoencoderbased synthetic data generation for imbalanced learning. In 2017 IEEE symposiumseries on computational intelligence (SSCI). IEEE, 17. Benjamin Weggenmann, Valentin Rublack, Michael Andrejczuk, Justus Mattern,and Florian Kerschbaum. 2022. DP-VAE: Human-readable text anonymization foronline reviews with differentially private variational autoencoders. In Proceedingsof the ACM Web Conference 2022. 721731.",
  "AALGORITHM DETAILSA.1AIM": "The current SOTA method, and the core of our federated algo-rithms is AIM, introduced by McKenna et al. . AIM extends themain ideas of MWEM but augments the algorithm with animproved utility score function, a graphical model-based inferenceapproach (via Private-PGM) and more efficient privacy accountingwith zero-Concentrated Differential Privacy (zCDP). The full detailsof AIM are outlined in Algorithm 2. We refer to this algorithm as",
  "Central AIM, to distinguish it from the distributed and federatedversions we consider in the main body of the paper. It is importantto highlight the following details:": "zCDP Budget Initialisation: In central AIM, the numberof global rounds is set adaptively via budget annealing. Tobegin, := 16 where is the number of features. Thisis the maximum number of rounds that will occur in thecase where the annealing condition is never triggered. Thisinitialisation occurs in Line 2. Workload Filtering: The provided workload of queries, ,is extended by forming the completion of . That is to say,all lower order marginals contained within any arealso added to the workload. Furthermore, for the first roundthe workload is filtered to contain only 1-way marginals toinitialise the model. This occurs in Line 8. In subsequentrounds, the workload is filtered to remove any queries thatwould force the model to grow beyond a predeterminedmaximum size . This occurs at Line 12.",
  "Weighted Workload: Each marginal is assigned aweight via = | |. Thus, marginals that havehigh overlap with other queries in the workload are morelikely to be chosen. This is computed in Line 4": "Model Initialisation: Instead of initialising the syntheticdistribution uniformly over the dataset domain, the syntheticmodel is initialised by measuring each 1-way marginal in theworkload and using PGM to estimate the initial model.This corresponds to measuring each features distributiononce before AIM begins and occurs in Lines 7-10. Query Selection: A marginal query is selected via the ex-ponential mechanism with utility scores that compare thetrade-off between the current error and the expected errorwhen measured under Gaussian noise. The utility scores andselection step occur at Line 13.",
  "Query Measurement: Once a query has been chosen, itis measured under the Gaussian mechanism. This occurs atLine 14": "PGM model estimation: The current PGM model is up-dated by adding the newly measured query to the set ofprevious measurements. The PGM model parameters arethen updated by a form of mirror descent for a number ofiterations. The precise details of PGM can be found in .This occurs at Line 15. Budget Annealing: At the end of every round, the differ-ence between the measured query of the new model andthat of the previous model is taken. If this change is smallerthan the expected error under Gaussian noise, the noise pa-rameters are annealed by halving the amount of noise. Thisoccurs at Line 17. If after this annealing there is only a smallamount of remaining privacy budget left, the noise param-eters can instead be calibrated to perform one final roundbefore finishing. This occurs at Line 20.",
  "() ( )2": "(SMC) approach for distributing MWEM. The key differences arethat we replace MWEM with AIM and consider a distributed settingwhere not all participants are available at any particular round. Theapproach relies on participants secret-sharing their query answersto compute servers who then perform a number of SMC operationsover these shares to train the model. The resulting algorithm isidentical to AIM in outline but has a few subtle differences: Secret Sharing: Participants must secret-share the requiredquantities to train AIM. In , it is assumed that the fullworkload answers {() : } have already beensecret-shared between a number of compute servers. In Dis-tAIM, we assume that clients sampled to participate at aparticular round contribute their secret-shared workloadanswers {() : } which are aggregated withthe shares of current and past participants from previousrounds. Thus, as the number of global rounds increases, thesecret-shared answers approach that of the central dataset.We assume the same SMC framework as which is a3-party scheme based on . Client participation: At each round only a subset of the par-ticipants are available to join the AIM round. In expectation clients will contribute their local marginals () inthe form of secret-shares. Compared to the central setting,DistAIM incurs additional error due to this subsampling.",
  "with the central server. Instead the quality functions (; )must be computed in a distributed manner between the com-pute servers who hold shares of the workload answers": "Measure step: Once the marginal has been selected bya secure exponential mechanism, it must be measured. As utilise MWEM, they measure queries under Laplacenoise which can be easily generated in an SMC setting. AIMinstead uses Gaussian noise and this is also what we usein DistAIM. In practice, one can also implement this underSMC e.g., using the Box-Muller method.",
  "For AugFLAIM methods, the exponential mechanism is applied withsensitivity := max 2": "Proof. For NaiveAIM, the result follows almost directly fromAIM, since rounds in the latter correspond to in the former.We then apply the existing privacy bounds for AIM. Similarly, forAugFLAIM (Private), the 1-way marginals of every feature are in-cluded in the computation, thus increasing the number of measuredmarginals under Gaussian noise to ( + ). In all variations, theexponential mechanism is only applied once for each local roundand thus times in total. For AugFLAIM, the augmented util-ity scores (; ) lead to a doubling of the sensitivity comparedto AIM, since () is used twice in the utility score and thus := 2 max .",
  "BEXPERIMENTAL SETUPB.1Datasets": "In our experiments we use a range of tabular datasets from the UCIrepository and others available directly from the SyntheticData Vault (SDV) package . Additionally, we use one syntheticdataset that we construct ourselves. A summary of all datasets interms of the number of training samples, features and classes isdetailed in . All datasets are split into a train and test set with90% forming the train set. From this, we form clients local datasetsvia a partitioning method (see Appendix B.2). In more detail: Adult A census dataset that contains information aboutadults and their occupations. The goal of the dataset is topredict the binary feature of whether their income is greaterthan $50,000. The training set we use contains 43,598 trainingsamples and 14 features.",
  "Credit A credit card fraud detection dataset availablefrom Kaggle. The goal is to predict whether a transaction isfraudulent": "Covtype A forest cover type prediction dataset availablefrom the UCI repository. We subsampled the dataset forcomputational reasons. Our train and test sets were formedfrom 20% of the original dataset. Census US census dataset available through the syntheticdata vault (SDV) package. This dataset was subsampledfor computational reasons. Our training and test sets wereformed from 30% of the original dataset. Intrusion The DARPA network intrusion detection datasetcontaining network logs, available through the syntheticdata vault (SDV) package. This was subsampled for com-putational reasons. Our training and test sets were formedfrom 40% of the original dataset.",
  "SynthFS A synthetic dataset formed from sampling fea-tures from a Gaussian distribution with different means. Theprecise construction is detailed in Appendix B.1.1. In our": "experiments, the training set contains 45,000 samples with10 features.All continuous features are binned uniformly between the mini-mum and maximum which we assume to be public knowledge. Wediscretize our features with 32 bins, although experiments varyingthis size presented no significant change in utility. This follows thepre-processing steps taken by prior work . B.1.1SynthFS. In order to simulate feature-skew in an ideal settingfor FLAIM, we construct a synthetic dataset that we denote SynthFS.To create SynthFS, we draw independent features from a Gaussiandistribution where the mean is chosen randomly from a Zipfiandistribution whose parameter controls the skew. This is done inthe following manner:",
  "For each client [] and feature [] sample mean Zipf(,zipf)": "For each feature [], sample / examples for client from (, 1)In our experiments we set = 50, 000 such that for = 100 eachclient is assigned 500 samples. In order to form a test set we sample10% from the dataset and assign the rest to clients. We fix = 10and zipf = 40 in all constructions. We highlight this process for {1, 2, 3, 5} in , with = 2 features for visualizationpurposes only. By increasing , we decrease the skew of the meansbeing sampled from the Zipf distribution. Hence, for larger values,each clients features are likely to be drawn from the same Gaussianand there is no heterogeneity. Decreasing increases the skew ofclient means and each feature is likely to be drawn from verydifferent Gaussian distributions, as shown when = 1.",
  "B.2Heterogeneity: Non-IID Client Partitions": "In order to simulate heterogeneity on our benchmark datasets, wetake one of the tabular datasets outlined in Appendix B.1 and formpartitions for each client. The aim is to create client datasets thatexhibit strong data heterogeneity by varying the number of samplesand inducing feature-skew. We do this in two ways: Clustering Approach In the majority of our experiments,we form client partitions via dimensionality reduction usingUMAP . An example of this process is shown in for the Adult dataset. a shows a UMAP embeddingof the training dataset in two-dimensions where each clientpartition (cluster) is highlighted a different color. To formthese clusters we simply use -means where = 100 is",
  ": SynthFS: Synthetic dataset constructed with feature skew, varying {1, 2, 3, 5}": "the total number of clients we require. In Figures 5b-5d, wedisplay the same embedding but colored based on differentfeature values for age, hours worked per-week and income >50k. We observe, for instance, the examples that are largestin age are concentrated around = 10 while those whowork more hours are concentrated around = 7. Thusclients that have datasets formed from clusters in the areaof (10, 7) will have significant feature-skew with a biastowards older adults who work more hours. These featureshave been picked at random and other features in the datasethave similar skew properties. The embedding is used onlyto map the original data to clients, and the raw data is usedwhen training AIM models. Label-skew Approach While the clustering approachworks well to form non-IID client partitions, there is no sim-ple parameter to vary the heterogeneity of the partitions.In experiments where we wish to vary heterogeneity, wefollow the approach outlined by . For each value theclass variable can take, we sample the distribution Dirichlet() and assign examples with class value to the clients using this distribution. This produces clientpartitions that are skewed via the class variable of the dataset,where a larger decreases the skew and reduces heterogene-ity. presents the average heterogeneity for a fixed workloadof queries across the Adult and Magic dataset with different parti-tion methods for = 100 clients. We look at the following methods:IID sampling, clustering approach, label-skew with = 0.1 (large-skew) and label-skew with = 0.8 (small-skew). Observe in allcases that our non-IID methods have higher heterogeneity thanIID sampling. Specifically, the clustering approach works well toinduce heterogeneity and can result in twice as much skew acrossthe workload. Note also that increasing from 0.1 to 0.8 decreasesaverage heterogeneity and at = 0.8, the skew is close to IID sam-pling. This confirms that simulating client partitions in this wayis useful for experiments where we wish to vary heterogeneity,since we can vary accordingly and (0, 1] in experiments iswell-chosen.",
  "B.3Evaluation": "In our experiments we evaluate our methods with three differentmetrics:1. Average Workload Error. We mainly evaluate (FL)AIM meth-ods via the average workload error. For a fixed workload of mar-ginal queries , we measure Err(, ;) :=1| | () ( )1 where := . This can be seen as a type of trainingerror since the models are trained to answer the queries in .2. Negative Log-likelihood. An alternative is the (mean) neg-ative log-likelihood of the synthetic dataset sampled from our(FL)AIM models when compared to a heldout test set. This metriccan be viewed as a measure of generalisation, since the metric isagnostic to the specific workload chosen.3. Test ROC-AUC. In some cases we evaluate our models bytraining a gradient boosted decision tree (GBDT) on the syntheticdata it produces. We test the performance of the classifier on a testset and evaluate the ROC-AUC.",
  "B.4Experiment Hyperparameters": "B.4.1CTGAN. In our baseline comparisons in .1 we usethe DP-CTGAN implementation contained in the synthetic datavault (SDV) package . We performed a hyperparameter searchover epochs, learning rates and gradient clipping norm. We foundtraining for 20 epochs, with a gradient norm of 1, batch size of128, discriminator LR of 13 and generator LR of 15 gave bestperformance. For the federated setting we train the DP-CTGANusing DP-FedSGD implemented via the FLSim framework . Wefound training for 50 epochs with a local batch size of 128, clipping",
  "(d) Income > 50K": ": Clustering approach to form non-IID splits on Adult dataset, = 100 clients. All plots show the same embeddingformed from UMAP, with a showing each clients local dataset formed by clustering in the embedding space. Figures5b-5d show the same embedding but colored based on three features: age, hours worked per-week and income > 50k. Theembedding is used only to map examples to clients, and AIM models are trained on the raw data.",
  "norm of 0.5, server LR of 0.5 and discriminator/generator LRs of14 performed best": "B.4.2(FL)AIM. PGM Iterations: The number of PGM iterationsdetermines how many optimisation steps are performed to updatethe parameters of the graphical model during training. AIM hastwo parameters, one for the number of training iterations betweenglobal rounds of AIM and one for the final number of iterationsperformed at the end of training. We set this to 100 training iter-ations and 1000 final iterations. This is notably smaller than thedefault parameters used in central AIM, but we verified that thereis no significant impact on utility.Model Initialisation: We follow the same procedure as in centralAIM, where every 1-way marginal is estimated to initialise themodel. Instead in our federated settings, we take a random sampleof clients and have them estimate the 1-way marginals and initialisethe model from these measurements.Budget Annealing Initialisation: When using budget annealing,the initial noise is calibrated under a high number of global rounds.In central AIM, initially = 16 results in a large amount of noiseuntil the budget is annealed. We instead set this as = 8 sinceempirically we have verified that a smaller number of global roundsis better for performance in the federated setting.Budget Annealing Condition: In central AIM, the budget anneal-ing condition compares the previous model estimate with the newmodel estimate of the current marginal. If the annealing conditionis met, the noise parameters are decreased. In the federated setting,it is possible that PGM receives multiple new marginals at a partic-ular round. We employ the same annealing condition, except weanneal the budget if at least one of the marginals received from thelast round passes the check.",
  "Varying : In , we vary across our datasets under a clus-tering partition with = 100 clients and = 1. These plots replicatea across the other datasets. We observe similar patterns": "to that of a with NaiveFLAIM performing worst across allsettings, and our AugFLAIM methods helping correct this to closelymatch the performance of DistAIM and in some cases even exceedit with lower workload error. There are however some consistentdifferences when compared to the Adult datasets. For example, onthe Magic dataset, AugFLAIM (Private) performance comes veryclose to DistAIM but there is a consistent gap in workload error.This is in contrast to the Adult dataset where AugFLAIM (Private)shows a more marked improvement.Varying : In , we vary the global rounds while fix-ing = 1 and = 100 clients under a clustering partition. Thisreplicates b but over the other datasets. Across all figureswe plot dashed lines to show the mean workload error under thesetting where is chosen adaptively via budget annealing. Ondatasets other than Adult, we observe more clearly the choice of is very significant to the performance of AugFLAIM (Private)and choosing > 30 can result in a large increase in workloaderror for some datasets (marketing, covtype, intrusion, census). Incontrast, increasing for DistAIM often gives an improvement tothe workload error. Recall, DistAIM has participants secret-sharetheir workload answers and these are aggregated over a numberof rounds. Hence, as increases the workload answers DistAIMreceives approaches that of the central dataset. For budget anneal-ing, on 3 of the 6 datasets, AugFLAIM (Private) has improved errorover NaiveFLAIM but does not always result in performance thatmatches DistAIM. Instead, it is recommended to choose which has consistently good performance across all of the datasets.Varying : In we vary the participation rate while fixing = 1, = 10 and = 100 clients under a clustering partition.This replicates c but across the other datasets. We observesimilar patterns as we did on Adult. DistAIM approaches the utilityof central AIM as increases. We note that for NaiveFLAIM, oftenthe worklaod error does not increase as increases. Again, as inc the likely cause for this is local skew. For AugFLAIM theworkload error decreases as increases and often matches that ofDistAIM, except on Magic and Marketing where it stabilises for",
  "Adult3990x1223x410xMagic2467x746x267xIntrusion2313x630x233xMarketing603x174x66xCovtype199x57x15xCredit2363x714x220xCensus832x221x77x": "> 0.3. Generally, when is large, DistAIM is preferable but wenote this does not correspond to a practical federated setting wheresampling rates are typically much smaller ( < 0.1) and in thisregime DistAIM and AugFLAIM performance is matched.Varying : In , we vary the label-skew partition acrossdatasets via the parameter . A larger results in less label-skewand so less heterogeneity. These experiments replicate that of Fig-ure 3d. As before, we clearly observe that NaiveFLAIM is subject topoor performance and that this is particularly the case when thereis high skew (small ) in participants datasets. We can see that theAugFLAIM methods help to stabilise performance and when skewis large ( < 0.1) can help match DistAIM across the datasets.Local updates: In Figures 10 and 11 we vary the local updates {1, 4} while fixing = 1, = 10 and = 100. This replicatese and 3f but across the other datasets. When using = 4local rounds, the workload error across methods often increasesfor NaiveFLAIM and AugFLAIM methods. However, when lookingat the test AUC performance, taking = 4 local updates oftengives better AUC performance than = 1 on the Census, Magicand Credit datasets. This results in AUC that is closer to that ofDistAIM than the other FLAIM methods.Budget Annealing: In we present the average rank ofmethods across all datasets. We rank based on two metrics: work-load error and negative log-likelihood. The number of rounds is set adaptively via budget annealing. We vary {1, 2, 3, 4, 5}with the goal of understanding how annealing affects utility acrossmethods. DistAIM achieves the best rank across all settings whenusing budget annealing, only beaten by central AIM. When issmall, AugFLAIM (Oracle) achieves a better average ranking acrossboth metrics when compared to AugFLAIM (Private). However, as increases, AugFLAIM (Private) achieves better rank, only beatenby DistAIM. AugFLAIM (Private) can achieve better performanceby choosing reasonably small ( < 30) as previously mentioned.DistAIM vs. FLAIM Communication: In , we presentthe overhead of DistAIM vs. AugFLAIM (Private) in terms of theaverage client throughput (total sent and received communication)for = 4, 32, 96. In DistAIM, the amount of communication a clientsends is constant no matter the value of , since they only sendsecret-shared answers once (when they participate in a round). Inthe case where the total dimension of a workload is large, the gapin client throughput between AugFLAIM and DistAIM is also large.For example on Adult, clients must send 140Mb in shares whereasAugFLAIM is an order of magnitude smaller. Sending 140Mb ofshares may not seem prohibitive but this size quickly scales inthe dimensions of features and in practice could be large e.g., ondatasets with many continuous features discretized to a reasonablenumber of bins. Note that if increases to be very large, eventuallyAugFLAIM would meet or exceed the communication of DistAIM.However, this would not occur in practice since the best utility isobtained when is small (e.g., < 100), as observed in b.AugFLAIM (Private) communication is mostly consistent acrosseach dataset for a particular value of e.g., at = 4 averageclient throughput is 0.035MB up to 0.5MB at = 96. This is incontrast to DistAIM which varies between 7MB of communica-tion (on Covtype) up to 140MB (on Adult) with the dominatingfactor for DistAIM being the total dimension of the workload e.g.,datasets that have many high cardinality marginals will have largecommunication overheads under DistAIM."
}