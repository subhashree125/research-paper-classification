{
  "ABSTRACT": "Diversity control is an important task to alleviate bias amplificationand filter bubble problems. The desired degree of diversity mayfluctuate based on users daily moods or business strategies. How-ever, existing methods for controlling diversity often lack flexibility,as diversity is decided during training and cannot be easily modi-fied during inference. We propose D3Rec (Disentangled Diffusionmodel for Diversified Recommendation), an end-to-end method thatcontrols the accuracy-diversity trade-off at inference. D3Rec meetsour three desiderata by (1) generating recommendations based oncategory preferences, (2) controlling category preferences duringthe inference phase, and (3) adapting to arbitrary targeted cate-gory preferences. In the forward process, D3Rec removes categorypreferences lurking in user interactions by adding noises. Then, inthe reverse process, D3Rec generates recommendations throughdenoising steps while reflecting desired category preferences. Ex-tensive experiments on real-world and synthetic datasets validatethe effectiveness of D3Rec in controlling diversity at inference.",
  "Both authors contributed equally to this workCorresponding author": "Permission to make digital or hard copies of all or part of this work for personal orclassroom use is granted without fee provided that copies are not made or distributedfor profit or commercial advantage and that copies bear this notice and the full citationon the first page. Copyrights for components of this work owned by others than theauthor(s) must be honored. Abstracting with credit is permitted. To copy otherwise, orrepublish, to post on servers or to redistribute to lists, requires prior specific permissionand/or a fee. Request permissions from 25, August 03 07, 2025, Toronto, ON, Canada 2025 Copyright held by the owner/author(s). Publication rights licensed to ACM.ACM ISBN 978-1-4503-XXXX-X/18/06",
  "INTRODUCTION": "In the information-overloaded era, recommendation systems arecrucial for online services, helping to filter out irrelevant items forusers . Recommender systems infer user preferencesbased on past behaviors (e.g., clicks) and item characteristics (e.g.,category), and generate recommendation lists tailored to userstastes. However, as systems are focused on accuracy, bias ampli-fication problem is raised as a critical issue. Due tothe uneven distribution of item categories (e.g., movie genres) inusers historical data, recommender systems often favor popularitems and categories, which can narrow user interests and createa filter bubble . Addressing the filter bubble is essential, as itcan negatively impact user satisfaction and reduce the uniquenessof items in the long term . Consequently, there is growing in-terest in controlling the diversity of recommendations .Some studies have shown through online A/B tests thatincreasing the diversity of recommended items can lead to higheruser engagement.Existing methods for controlling recommendation diversity canbe broadly categorized into two types: post-processing and end-to-end approaches. In the early stage, the post-processing modules are introduced to control diversity after generating can-didate items. However, since the post-processing modules operateindependently of the candidate generation process, diversity sig-nals are not incorporated during training, leading to suboptimalsolutions . To address this issue, end-to-end approaches have been developed to jointly optimize accuracy and di-versity during training by incorporating item category information.While effective, these methods often lose the flexibility to adjustdiversity on the fly. The accuracy-diversity trade-off is decided andfixed by hyperparameters set during training and cannot be easilymodified during inference. For example, as illustrated in (a), if users want more or less diverse recommendations, they must",
  "KDD 25, August 03 07, 2025, Toronto, ON, CanadaGwangseok Han*, Wonbin Kweon*, Minsoo Kim, and Hwanjo Yu": ": The overall framework of D3Rec. In the forward process, the user interactions are corrupted, thereby diminishingcategory preferences lurking in them. In the reverse process, the model generates the interactions guided by the targetedcategory preferences. In .2, we take a closer look at Lortho and Lrecon. In .3, we devise two auxiliary taskswith Lcate and Lemb to ensure that the generated recommendations align with the targeted category preferences. where Cosine(, ) is the cosine similarity. Disentangling the cat-egory representation () is essential for diversity control, as itallows for the manipulation of category preferences while preserv-ing the users category-independent tastes. 4.2.3Category preference-guided decoder. The input of thedecoder G is the concatenation of the outputs from the encodersEcate and Eind. In the context of predicting denoised interactionsbased on , similar to the approach of Ecate, we provide the repre-sentation cate to each intermediate layer of G:",
  "RELATED WORK": "Diversity Control in Recommendation Systems. Ziegler et al. first introduced a greedy algorithm as a post-processingmodule to balance accuracy and diversity. Subsequently, severalpost-processing approaches were developed to impose diversity using various measures, such as the determinantalpoint process and category distribution . However, since thesemodules operate independently of the candidate generation process,diversity signals are not integrated during training, resulting insuboptimal solutions . Also, post-processing approachesexhibit large inference latency due to their additional optimizations.To address this issue, Zheng et al. proposed an end-to-endapproach. Most end-to-end methods leverage categoryinformation for different purposes, including sampling techniques, re-weighting strategies based on global category popularity, and classifying item categories to predict user preferences .While effective, these methods often lack the flexibility to adjustdiversity dynamically. The accuracy-diversity trade-off is set byhyperparameters during training and cannot be easily modifiedduring inference. Generative recommendation. Generative models are widelyadopted across various domains due to their abilityto model complex distributions. In recommendation systems, thesemodels are employed to capture users non-linear and intricatepreferences. These methods can be broadly categorized into threegroups: VAE-based methods , Generative AdversarialNetwork (GAN)-based methods , and diffusion-based meth-ods . VAE-based methods utilize an encoder to approximatethe posterior distribution and a decoder to estimate the probabilityof user interactions with non-interacted items. GAN-based methodspredict user interactions by using a generator, which is optimizedthrough adversarial learning with the discriminator. Recently, diffu-sion models have gained popularity for addressing the limitationsof VAEs and GANs, such as posterior collapse and mode collapse.In diffusion-based approaches, user interactions or target itemrepresentations are corrupted by progressively adding noiseduring the forward process. Recommendations are then generatedby denoising the corrupted data during the reverse process.",
  "PRELIMINARY": "Notations. Let U be the set of users, I be the set of items, and C bethe set of item categories in the dataset. An item I is associatedwith one or more categories and R|I|| C| denotes the item-category matrix. Each row [] denotes the category distribution ofitem. For example, if an item is associated with the second and thefourth categories among four categories, the category distributionwould be represented as [] = [0, 0.5, 0, 0.5]. The interactionhistory of a user U is represented by {0, 1}|I|, where = 1 indicates that user interacted with item , and 0 otherwise.The category preference of a user is defined as R| C|, byaggregating the category distributions of items with which the userhas interacted: = /|| ||1. Diffusion model . The diffusion process works in two steps:the forward process and the reverse process.(1) Forward process: The diffusion model corrupts the originaldata 0 by repeatedly adding Gaussian noises.",
  "Overall Framework": "D3Rec has two processes as shown in : (1) D3Rec eliminatesthe outdated category preference information embedded in userinteractions by gradually corrupting the interactions in the forwardprocess. (2) D3Rec generates users future interactions from the cor-rupted interactions, considering the targeted category preferencesin the reverse process. 4.1.1Forward process to eliminate the outdated categorypreferences. We set the initial state as 0 = for a user.1 Duringthe forward process, the historical interactions are corrupted byrepeatedly adding Gaussian noises:",
  "(1|, ) = N (1| (,, ), (,, ))": "Here, the targeted category preference can be any arbitrary vectorthat sums up to 1. During the training, is set to the original cate-gory preference . We set the covariance constant as (,, ) =2() in Eq 2 for stable training, following . We model (,, ) in a similar form of the mean in Eq 2:",
  "(,, ) in Eq. 6 is the only trainable model in our D3Rec frame-work. In the following section, we present our architecture for (,, ) to generate 0 with (,, )": "4.2.1Category preference representation. We first define acategory embedding matrix cate R| C|. Then, the categorypreference representation cate R is computed as a multipli-cation between the category preference vector and the categoryembedding matrix: cate = cate . 4.2.2Disentangled two-tower encoders. We devise two-towerencoders: a category preference encoder Ecate and a category-independent encoder Eind. Both encoders are comprised of Multi-Layer Perceptron (MLP) with layers and the input dimension isidentical. The output dimension of Ecate is which is half of Eind.The remaining output dimensions in Ecate are allocated for thecategory preference representation cate R.",
  "() = CONCAT(G() ((1)); Proj() (cate))": "for and (0) = CONCAT((); ()). Note that we utilizeProj() (cate) for G() since the encoder-decoder architecture issimilar to U-Net . The output () R|I| is the generated userinteractions, represented by (,, ) = (). 4.2.4Maximization of ELBO conditioned. The primary train-ing objective is to maximize the ELBO of observed user interactions0 while taking into account the original category preference . Us-ing Gaussian transition assumption and Bayes theorem, the ELBOin Eq.3 can be simplified into following reconstruction loss :",
  "= []negif 0[] = 0.(12)": "For positive samples, we assign higher weights to the loss of itemsbelonging to minor categories, and lower weights to those belong-ing to major categories. Conversely, for negative samples, we assignhigher weights to the loss of items belonging to major categories,and lower weights to those belonging to minor categories. Then,Lrecon is re-weighted as follows:",
  "Inference via Targeted Category Preference": "In the inference phase, we can utilize arbitrary targeted categorypreference for (,, ). If the original category preference is utilized, D3Rec would output recommendations aligned with theoriginal user category preference. On the other hand, to controldiversity, the category preference can be adjusted to the businessstrategy. Broadly, the usages are divided into two directions. Modifying the category preferences through temperature. We regulate diversity while accommodating the users generalpreference by deploying = Softmax(log()/). If < 1, skewstowards the historically major categories, consequently reducingdiversity in the recommended list. On the other hand, when > 1, becomes smoother, thereby enhancing diversity within the list. Manipulating the preferences into specific categories. Thesystem or users can set arbitrary targeted preferences that maydeviate from the original preferences . This approach allows therecommendation system to adapt readily to the users capriciousmoods (e.g., a user who typically prefers action movies might re-quest romantic movies when with a partner). As outlined in , we disregard the covariance at inference.Thus, we conduct deterministic inference i.e., 1 = (,, )in Eq. 5. Additionally, we corrupt 0 for steps and then denoiseit for steps, where < . This approach reflects the inherentnoise in user interactions, such as false positives and false negatives,while also retaining personalized information.",
  "We present detailed experimental setup in Appendix A": "Datasets. We adopt three real-world datasets in different domains,including ML-1M3, Steam Game , and Anime 20234. Forexplicit datasets (ML-1M and Anime 2023), we convert ratingshigher than the middle score to 1 and 0 otherwise. For all datasets,we consider an items genres as the categories. We adopt 20-coresettings for users, items, and categories across all datasets to ensuredata quality . After that, we split each users interactions into atraining set (60%), a validation set (20%), and a test set (20%). Thestatistics of the three datasets after the pre-processing are presentedin . Evaluation Metrics. We evaluate the accuracy and diversity withthe following metrics over the top- items, where {10, 20}. Foraccuracy, we adopt widely used metrics: Recall@ and NDCG@.For diversity, we adopt Coverage and Entropy, as done in .We denote the top- recommended list for a user as topK {0, 1}|I|, where || topK||1 = . Then, the category distribution ofthe recommendation is obtained as topK = topK / || topK||1.Then, the diversity metrics are computed as follows:",
  "CATE is a post-processing method proposed in ComiRec ,which balances accuracy and diversity based on the categorydistribution of the recommendation list": "Implementation. For each dataset, the best hyperparameters areselected through grid searches on the validation set with earlystopping. We use the AdamW optimizer with a learning rate in{13, 54, 14, 55} and weight decay in {0, 11, 12, 13}.We set the hidden size to and batch size to 400, as done in",
  "Dual Process: We tune and in {0, 1, 11, 12, 13, 14},which determine the strength of curiosity in the training andinference phases, respectively": "DiffRec and D3Rec: We search for the total diffusion step in {5, 15, 40, 100} and fix the sampling step to 0, as in .The noise scale, noise lower bound, and noise upper bound aresearched in {1, 12, 14}, {53, 14, 54}, and {52, 13, 53},respectively. Additionally, for D3Rec, the ratio of the conditiondropout is searched in {0.1, 0.3, 0.5}, in {1, 12, 14}, the guid-ing strength in {0.7, 0.5, 0.3, 0, 0.3, 0.5}, loss weight upperbound min in {0.3, 0.5, 0.8, 1} and lower bound max in {1, 1.3, 1.6,2}. Post-processing methods: The top 200 items are retrieved usingthe MultVAE, and re-ranked by MMR, DPP, and CATE. The trade-off parameter is searched in {0.1, 0.3, 0.5, 0.7, 0.9}. In PMF, thecontrol parameters and are chosen from {0.1, 0.2, 0.3, 0.4, 0.5}.",
  ": Accuracy-diversity curves on three real-world datasets. The closer to the top right corner, the better the trade-offbetween accuracy and diversity": "average performance of five different random seeds. For all metrics,except Entropy@20 of the Steam Game dataset, the improvementsover the best baseline are statistically significant (p-value < 0.05)under one-sample t-tests. Specifically, we found following observa-tions. Advantages of using category information. D3Rec, COR, DCRS,and Dual Process, which leverage category information, outperformMacriVAE and post-processing methods in terms of both accuracyand diversity. This finding indicates that category data are crucial inresolving the accuracy-diversity dilemma. Especially, it is importantwhen considering the positions in the ranked list, as the NDCGvalues are higher than those of MultVAE across all datasets. Effectiveness of diffusion process. D3Rec and DiffRec, whichutilize the diffusion process, outperform compared methods in bothaccuracy and diversity metrics on most datasets. This is because theuser interactions contain biased category preferences, and therefore,generated recommendations exhibit the risk of bias amplification.On the other hand, diffusion-based recommenders first corrupt theuser interactions and effectively eliminate the category preferenceslurking in user interactions.",
  "Controlling Diversity with Temperature": "To demonstrate the effectiveness of D3Rec in achieving a bettertrade-off between accuracy and diversity, we visualize Pareto curves on three real-world datasets. We adjust the diversity basedon users original category preferences using temperature: =Softmax(log()/). presents the Recall-Entropy curvesfor D3Rec, COR , and CATE . COR and CATE are the best-performing end-to-end and post-processing approaches with con-trollability in our experiment, respectively. We emphasize the fol-lowing two key strengths of D3Rec. Monotonic diversity control. The large temperature exhibits asmoother targeted category distribution , and therefore, needs tobe associated with a more diverse recommendation. We observe thatD3Rec is able to control the diversity monotonically according to ,while COR yields a more diverse recommendation with a smallertemperature ( = 0.8 has a larger Entropy@20 than = 1 in ML-1m). On the other hand, although CATE can monotonically controldiversity, its effect is minimal, especially on the Anime 2023 dataset.",
  "This result implies that D3Rec effectively captures the desired levelof diversity with our category preference representation and UNet-like encoder-decoder framework": "Pareto frontier in accuracy-diversity trade-off. For Paretocurves in , the closer to the top right corner, the better thetrade-off between accuracy and diversity. We observe that D3Rec isthe closest to the top-right corner, i.e., the Pareto frontier. This indi-cates that, given the equal accuracy, D3Rec achieves better diversitythan others, and vice versa. Moreover, D3Rec exhibits a smallerperformance drop in Recall@20 when adjusting the diversity (i.e.,Entropy@20). Similar results are observed for other metrics, suchas NDCG@20 and Coverage@20.",
  "mismatch in category preferences between the training dataset andthe test dataset. The data statistics for three semi-synthetic datasetsare presented in": "Adaptation to arbitrary targeted category preferences. Wetrain MultVAE, COR, and D3Rec on the training interactions, andinference with the category distribution of the test interactions, i.e.,test = test / || test||1. We tune hyper-parameters accordingto .1 and fix the guiding strength at 7 for D3Rec. Weadopt Recall@K and NDCG@K to compare strong generalizationand fast adaptation. demonstrates that D3Rec outperformsMultVAE and COR, demonstrating its fast adaptation to the arbi-trary targeted category preferences. Notably, we observe that thefast adaptation of D3Rec is more effective on datasets with higherKL, i.e., ML-1M.",
  "In-depth Analyses": "Inference burden. shows the inference time of D3Recand baselines on three real-world datasets. MultVAE and DiffRecdo not consider diversity and exhibit the lowest inference bur-den. The end-to-end approach (i.e., COR) does not require anyadditional post-processing, therefore, the inference time is almostidentical to MultVAE, which is the base architecture of COR. Thepost-processing approach (i.e., CATE) needs an additional processafter the inference, and therefore, takes the largest inference latency.Lastly, D3Rec exhibits an inference burden similar to DiffRec, sincetheir generation process takes similar computational effort. It isnoted that DiffRec generally requires more denoising steps () thanD3Rec for the best performance.",
  "D3Rec0.08160.74270.23310.1703": "and D3Rec, on both clean and noisy versions of the Steam Gamedataset. When noise is introduced into the training data (with aratio of 0.3), all models show a decrease in performance. Mean-while, D3Rec demonstrates remarkable robustness, with only aminor drop of -1.23% in Recall@20 and -0.14% in NDCG@20. Thisminimal degradation contrasts sharply with the more significantdeclines observed in MultVAE and DiffRec, which show drops of-3% -5.6%. The results underscore the effectiveness of D3Rec inmaintaining performance under noisy training conditions, suggest-ing that it is better equipped to handle data perturbations comparedto MultVAE and DiffRec. Ablation study. We analyze the impact of each component inD3Rec: two-tower encoders (two encoder), Lortho, Lcate, Lemb,and the re-weight strategy (re-weight). We conduct ablation exper-iments by removing each component. shows the ablationstudy of D3Rec on Steam Game and semi-synthetic Steam Game.The two-tower encoders and the orthogonal regularization success-fully disentangle the category features and guide D3Rec to onlymanipulate the category preferences, resulting in a better accuracy-diversity trade-off. This verifies the effectiveness of disentangle-ment for controllability as it explicitly encodes category-awarerepresentation. We observe that the re-weight strategy significantlyimpacts diversity because it addresses the imbalance issue of cate-gory preferences. Effect of the guiding strength. We adjust the value of in Eq.6to explore the effect of guiding category preferences. In left,we find that excessive reliance on category preferences (i.e., large)can lead to decreased performance on the real-world datasets. Thisoccurs because users consider various factors beyond just categories.Overemphasizing category preferences alone, without accountingfor these additional factors, can harm overall performance. It isnoted that we disregard small values (i.e., < 0.7) as theylose controllability. On the other hand, in right, strongguidance > 0.5 exhibits superiority. Synthetic test sets havesignificantly different category distributions from the training sets,",
  "and therefore, strong guidance for the target category preferencesis required": "Effect of the diffusion steps. investigates the impact ofvarying the diffusion step on the performance of D3Rec on theSteam dataset. Similar results were observed for ML-1M and Animedatasets. As the steps increase, the influence of guidance also grows,leading to lower accuracy and greater diversity. A larger diffusionstep can enhance the models ability to recommend a broader rangeof items, however, overly high diffusion steps negatively impact themodels ranking capabilities. This analysis suggests that choosingthe appropriate depends on whether the application prioritizesranking accuracy or a more diverse set of recommendations. It isnoted that DiffRec generally requires more denoising steps ( 100) than D3Rec for the best performance. We also analyzed theimpact of the inference step and found no significant differences.",
  "CONCLUSION": "We claim that existing diverse recommender systems lack controlla-bility at inference, and devise three desiderata for controlling diver-sity with category preferences. Based on our desiderata, we proposeD3Rec, an end-to-end method that controls the accuracy-diversitytrade-off at the inference phase. In the forward process, D3Receliminates category preferences lurking within user interactionsby adding noises. Then, in the reverse process, D3Rec generatesrecommendations through denoising steps while reflecting the tar-geted category preference. Moreover, D3Rec can adapt to arbitrarycategory preferences that deviate from the original user categorypreferences. Our extensive experiments on both real-world andsynthetic datasets have demonstrated the superiority and in-depthanalyses of D3Rec.",
  "Datasets. We adopt three datasets in different domains": "ML-1M5: This dataset comprises user ratings for movies rangingfrom 1 to 5. We discard user interactions with ratings less than 4,setting = 1 if a user rates an item as 4 or higher, and = 0otherwise. Subsequently, we sort all interactions chronologicallybased on the timestamps. Steam Game : This dataset contains user reviews from theSteam video game platform. We set = 1 if a user has revieweditem , and = 0 otherwise. We, then, sort all interactionschronologically based on the timestamps. Anime 20236: This dataset consists of user ratings for anime ona scale of 1 to 10. We set = 1 if a user rates an item as 8 orhigher, and = 0 otherwise. As this dataset does not includetimestamps, we randomly shuffle the user interactions. For all datasets, we consider an items genres as the categories.We adopt 20-core settings for users, items, and categories acrossall datasets to ensure data quality . After that, we split eachusers interactions into a training set (60%), a validation set (20%),and a test set (20%). The statistics of the three datasets after thepre-processing are presented in .",
  ", disentangled recommenders to promote diversity:": "MacridVAE is a disentangled variational autoencoder thatlearns disentangled representations from user behavior. Inspiredby that capturing users multiple interests is beneficial for diver-sity, as explored in , we learn multiple disentangled userrepresentations that capture preferences over each category. DCRS utilizes disentanglement to capture user preferencesfor item categories, thereby mitigating the accuracy-diversitydilemma. We employ MultVAE as the base model and disentanglethe encoders output into representations that are dependent andindependent of category preference distribution.",
  "CATE is a re-ranking model proposed in ComiRec , which bal-ances accuracy and diversity based on the category distributionof the recommended list": "Hyper-parameter settings. For each dataset, the best hyperpa-rameters are selected through grid searches on the validation setwith early stopping. We tune the AdamW optimizer witha learning rate in {13, 54, 14, 55} and weight decay in{0, 11, 12, 13}. We set the hidden size to , batch sizeto 400, like , and the dropout ratio is searched from {0.1, 0.3, 0.5}for all models. Model-specific hyper-parameters are searched asfollows. MultVAE and MacridVAE: The regularization strength andthe annealing step are chosen from {0.2, 0.5, 0.7} and {500, 1000, 2000}."
}