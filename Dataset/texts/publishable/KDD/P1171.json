{
  "ABSTRACT": "Email platforms need to generate personalized rankings of emailsthat satisfy user preferences, which may vary over time. We ap-proach this as a recommendation problem based on three criteria:closeness (how relevant the sender and topic are to the user), time-liness (how recent the email is), and conciseness (how brief theemail is). We propose MOSR (Multi-Objective Stationary Recom-mender), a novel online algorithm that uses an adaptive controlmodel to dynamically balance these criteria and adapt to preferencechanges. We evaluate MOSR on the Enron Email Dataset, a largecollection of real emails, and compare it with other baselines. Theresults show that MOSR achieves better performance, especiallyunder non-stationary preferences, where users value different cri-teria more or less over time. We also test MOSRs robustness on asmaller down-sampled dataset that exhibits high variance in emailcharacteristics, and show that it maintains stable rankings acrossdifferent samples. Our work offers novel insights into how to de-sign email re-ranking systems that account for multiple objectivesimpacting user satisfaction.",
  "KDD 23, August 610, 2023, Long Beach, CA, USA 2023 Copyright held by the owner/author(s).ACM ISBN 979-8-4007-0103-0/23/08": "users, reducing their satisfaction and productivity . There-fore, designing email platforms that can help users cope with emailoverload and find the most important messages to send or reply is akey challenge. Email recommender systems aim to provide person-alized suggestions for ranking emails based on users preferences. For example, Googles Priority Inbox feature ranks emailsaccording to their inferred priority for reading based on users pastbehavior .However, user preferences are not static; they may change overtime depending on various factors such as context or mood. Toaccount for this dynamic nature of preferences, email recommendersystems need to learn from feedback and update their rankingstrategies accordingly. Offline methods that assume fixed or stablepreferences may fail to capture the evolving interests of users overtime . Thus, an online algorithm that can adapt to preferencechanges in real time is crucial.Moreover, email recommendation is not a single-objective prob-lem; it involves multiple criteria that affect user satisfaction withdifferent aspects of emails. In this paper we focus on three criteria:closeness (how relevant the sender and topic are to the user), timeli-ness (how urgent the email is), conciseness (how brief the email is).These criteria reflect different dimensions of importance that usersmay value differently at different times. For instance, a user mayprefer timely but concise emails during busy workdays but closebut lengthy ones during leisure time. Hence, email recommendersystems need to balance these multiple objectives while generatingpersonalized rankings.Existing approaches for email re-ranking or recommendationhave mostly focused on maximizing relevance or priority based oncertain features. For example, some methods use sender-receiverrelationship features , others use topic models ,while others combine text similarity with temporal features .However, these methods have some limitations in terms of accu-racy and adaptability. They neglect other factors besides relevancesuch as novelty or diversity which may also influence user satis-faction . Most importantly they do not explicitly account forpreference changes over time. Recent research has started consid-ering beyond relevance objectives in recommendation systems,such as exploration vs exploitation, serendipity vs familiarity etc.,which optimize factors affecting user engagement rather than justitem relevance . We argue that similar objectives apply toemail ranking settings, where users may value different aspects ofemails more or less at different times depending on their context.In this paper, we address this problem as a multi-objective onlinerecommendation task based on three criteria: closeness, timeliness,",
  "KDD 23, August 610, 2023, Long Beach, CA, USAJiayi Liu & Jennifer Neville": "and conciseness. Closeness refers to the estimation of the rela-tionship between the sender and receiver, timeliness refers to theurgency of a reply, and conciseness refers to the usage of words inthe email. We argue that these aspects reflect different dimensionsof user satisfaction with respect to emails, and they may vary acrossdifferent users and over time.We propose MOSR (Multi-Objective Stationary Recommender),a novel online algorithm that uses an adaptive control model to bal-ance these criteria and adapt to preference changes. Our algorithmlearns each criterions weight from historical data and updates itusing gradient descent based on observed feedback signals. It thencombines these weights into a single score for each email using alinear aggregation function. By doing so, our algorithm can adjustits ranking strategy according to changing preferences withoutrequiring prior knowledge or explicit input from users.The main contributions of our work are as follows: (1) We formulate the email re-ranking as a multi-objective on-line recommendation problem that aims to optimize threecriteria: closeness, timeliness, and conciseness. These arekey factors that influence user actions in email. We showhow preferences w.r.t these criteria vary across users andover time.(2) We propose MOSR , an adaptive control model that learns areference vector from historical data and adjusts it based ononline feedback. The reference vector represents the relativeimportance of each criterion for each user at each moment.MOSR adapts the reference vector dynamically by using rein-forcement learning techniques without requiring re-trainingor compromising privacy.(3) We evaluate MOSR on the Enron Email Dataset. We showthat MOSR outperforms several baselines in terms of rank-ing quality measured by NDCG. We also demonstrate thatMOSR handles non-stationary preferences well by providingconsistent recommendations even when users change theirvalues for different criteria over time. Furthermore, we testMOSR s robustness on a smaller dataset sampled randomlyat different time intervals and show that MOSR still performsbetter than other methods under high variance conditions.",
  "MOSR FRAMEWORK": "Our goal is to design a recommendation system that helps userschoose when and how to send emails based on their preferencesw.r.t. relationships, urgency, and brevity. We model this as a dy-namic problem that involves multiple objectives that may conflictor change over time. Our algorithm uses the email stream flow asinput and tries to find the optimal trade-offs among these objectivesfor each email ranking decision.",
  "First, we need to balance multiple and sometimes conflictingcriteria to achieve the highest level of satisfaction amongthem": "Second, users email ranking preferences are not fixed butmay change depending on external factors. illus-trates some scenarios where users preferences vary or re-main constant due to different influences. Definition 2.1 (Email object). We consider an email object consiststo be represented as = {,,,}, where is the email addressof the sender, is the email address of the receivers, is thecontent of the email, is the timestamp when is sent. G is the setof all the email objects.",
  "We want to rank the emails of a specific email address accord-ing to the users preferences, which may change over time. Theranking candidates are the emails that have been received or sentby": "Definition 2.2 (Candidate Set). Here, we define candidates set with = {1,2, ..}. There are two types of candidates in: unan-swered emails in the inbox or follow-up emails after no response.Hence, the candidates set includes the people sent to/receivedfrom. As we defined before, candidates set = {1,2, .., ...}, . At different timestamps , the candidate set would also be up-dated with time window . Note the candidate set is not fixed, since new emails mayarrive or be sent at any time. To rank the candidates, we assigneach email a score based on multiple criteria , , for the currenttimestamp . These criteria reflect how relevant, timely, important,or interesting an email is for the user. We also use a feedback-basedaggregation function that can adjust the scores online as we learnfrom different users choices. Then we sort the emails by theirscores to get a personalized ranking for each user at any time. Definition 2.3 (Loss function). We define our candidates set as aset of emails, = {1,2, ...}, and our prediction as the ranking ofour candidates. Then, for a given algorithm , the predicted rankingy could be defined as y = [(1), (2), ...] , in which, ()represents the predicted ranking of . Suppose the predicted scorefor a candidate is (), then () = |() = (e) (). Here,(e) is the vector of predicted scores for e under algorithm , and(e) () follows Definition 3.1.",
  "Proposed Approach": "The overall architecture of our algorithm is depicted in b. Inthis section, we will introduce the details of the MOSR algorithm.(1) Step 1: Weighting preferences (RIM+OWA, see Sec 3.3)(2) Step 2: Identify candidates set .(3) Step 3: Rank the candidates , with weighted function.(4) Step 4: Compute loss, update the weights with MRAC andrepeat.We use several ordered weight averaging (OWA) aggregatorsto combine the criteria of closeness, timeliness, and concisenessand obtain the predicted scores of candidates Q. Then, we applya weighted sum aggregator to re-rank the scores from OWA. Toadapt to users choices, we adjust the weights of different scores byadaptive control over the multi-score aggregation. For each emailaddress , we update its sending preference online according to theloss between true ranking and predicted ranking. When sends anemail to a candidate , it raises the priority of and the MRAC",
  "Stationary Algorithmic BalancingFor Dynamic Email Re-Ranking ProblemKDD 23, August 610, 2023, Long Beach, CA, USA": "(Model Reference Adaptive Controldefined below) modifies theweights of relevant scores.We formulate our problem as a dynamic multiple objective op-timization problem to achieve algorithmic balance over closeness,timeliness, and conciseness. The conventional multiple objectiveoptimization problem aims to optimize the weight of different objec-tives under constrained or conflicting situations . However, thisis not suitable for our case because email history changes over time.Therefore, we propose a dynamic version that involves multi-stageranking setups and time windows.Most existing recommendation systems use a two-stage mecha-nism: they first extract potential candidates and model their featuresto get one score per candidate . However, this is ineffi-cient for data streams because learning over large candidate setsbecomes impractical. Unlike previous systems, we use multiplescores based on different user habits instead of one general staticscore. We also use time windows to enable fast switching amongdifferent scores as email history evolves.We propose a MRAC (Model Reference Adaptive Control) modelto create an online mechanism for the multi-objective optimizationproblem. In this model, we use different rankers to order the solu-tions according to various criteria, with the aim of discovering thepersonalized preferences of each user over these rankers. We as-sume that there is a true preference ranking that reflects the usersideal ordering of solutions, and our goal is to estimate and updatethe users preference over different rankers as they interact withthem. To do this, we treat each ranker as a fixed model, and wemeasure the distance between the true ranking and the predictedranking by each ranker as a controller.",
  "BACKGROUND3.1Email overloading problem": "Many users face the problem of email overload, where their inboxesare filled with too many emails and they struggle to identify orrespond to the important ones . One possible solution isto re-rank incoming emails and create a priority inbox based onvarious factors . Previous studies have explored different aspectsof this problem, such as how people decide whether to reply or not,depending on interpersonal differences, email content, attachments,and other features . They also proposed methods topredict the priority of emails in the inbox using content-basedfeatures .However, most of these methods rely on analyzing the contentof emails, which may raise privacy concerns. Aberdeen et al.used a linear logistic regression model with multiple content-basedfeatures for real-time online ranking. Yang et al. included attach-ments as an additional feature for analysis. Feng et al. developeda doc2vec based generative model to rank inbox emails. Bedekar etal. re-ranked emails according to their topic analysis.In this work, we examine how different criteria affect emailranking jointly."
}