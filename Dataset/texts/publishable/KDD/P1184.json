{
  "ABSTRACT": "Graph Neural Networks (GNNs) have demonstrated promising re-sults on exploiting node representations for many downstreamtasks through supervised end-to-end training. To deal with thewidespread label scarcity issue in real-world applications, GraphContrastive Learning (GCL) is leveraged to train GNNs with limitedor even no labels by maximizing the mutual information betweennodes in its augmented views generated from the original graph.However, the distribution of graphs remains unconsidered in viewgeneration, resulting in the ignorance of unseen edges in most ex-isting literature, which is empirically shown to be able to improveGCLs performance in our experiments. To this end, we propose toincorporate graph generative adversarial networks (GANs) to learnthe distribution of views for GCL, in order to i) automatically cap-ture the characteristic of graphs for augmentations, and ii) jointlytrain the graph GAN model and the GCL model. Specifically, wepresent GACN, a novel Generative Adversarial Contrastive learn-ing Network for graph representation learning. GACN develops aview generator and a view discriminator to generate augmentedviews automatically in an adversarial style. Then, GACN leveragesthese views to train a GNN encoder with two carefully designed self-supervised learning losses, including the graph contrastive loss andthe Bayesian personalized ranking Loss. Furthermore, we design anoptimization framework to train all GACN modules jointly. Exten-sive experiments on seven real-world datasets show that GACN isable to generate high-quality augmented views for GCL and is su-perior to twelve state-of-the-art baseline methods. Noticeably, ourproposed GACN surprisingly discovers that the generated views indata augmentation finally conform to the well-known preferentialattachment rule in online networks.",
  "Graph Representation Learning, Graph Neural Networks, Genera-tive Adversarial Network, Contrastive Learning": "ACM Reference Format:Cheng Wu, Chaokun Wang, Jingcao Xu, Ziyang Liu, Kai Zheng, XiaoweiWang, Yang Song, and Kun Gai. 2023. Graph Contrastive Learning withGenerative Adversarial Network. In Proceedings of the 29th ACM SIGKDDConference on Knowledge Discovery and Data Mining (KDD 23), August610, 2023, Long Beach, CA, USA. ACM, New York, NY, USA, 10 pages.",
  "INTRODUCTION": "In recent years, graph representation learning has attracted in-creasing attention from both academia and industry to deal withnetwork-based data . Graph Neural Networks(GNNs) have shown effectiveness in supervised end-to-end training. However, task-specific labels can be extremely scarcefor graph datasets . To this end, research efforts start explor-ing self-supervised learning for GNNs, where only limited or evenno labels are needed .Recently, graph contrastive learning (GCL) hasbecome one of the most popular self-supervised approaches, whichleverages the mutual information maximization principle (Info-Max) to maximize the correspondence between the representa-tions of a graph (or a node) in its different augmented views. Thereare a large amount of view augmentation strategies explored bydifferent GCL methods, including node dropping, edge perturba-tion, subgraph sampling and feature masking. Furthermore, viewscan be generated by random sampling , or under the guide ofdomain knowledge , or by a view learner .However, the evolution and the distribution of graphs remainsunconsidered in existing view generation strategies. Intuitively, agraph is formed with nodes and edges created in succession, andthe observed graph is a snapshot of this procedure. Thus, the non-connected node pairs are possible to form new edges in future.Case 1 in demonstrates this intuition. Furthermore, theevolution of graphs varies (e.g., Case1, Case2, or other possible casesin ) based on the distribution of graphs. Then, exploring thedistribution of graphs helps to search unseen but should existingedges, which benefits the variety of generated views and boosts theperformance of GCL.",
  "Dataset": "0.000 0.025 0.050 0.075 0.100 0.125 0.150 0.175 MRR Simple-GCLSimple-GCL + New EdgesGACN (ours) : Empirical experiments show that replacing someexisting edges with random new edges in one of the aug-mented views can improve Simple-GCL on most datasets.However, it requires a trial-and-error selection of the newedge rate to get the best performance. In contrast, our GACNcan automatically learn the graph distribution and preciselyadd edges for better graph representation learning. GNN as the graph encoder and designs two self-supervised learninglosses to optimize the parameters. To train GACN, a jointly learningframework is proposed to optimize the view generator, the viewdiscriminator and the graph encoder sequentially and iteratively.The main contributions of this paper are highlighted as follows:",
  "We explore the benefit of leveraging unseen edges to boost GCL,and first propose to incorporate graph GANs to learn and gener-ate views for GCL": "We present GACN, a new graph neural network that developsa view generator and a view discriminator to learn generatingviews for the graph encoder. All these modules are trained jointlywith a novel framework (). We conduct comprehensive experiments to evaluate GACN withtwelve state-of-the-art baseline methods. The experimental re-sults show that GACN is superior to other methods, and is ableto generate views satisfying the famous preferential attachmentrule ().",
  "Graph Contrastive Learning": "Contrastive Learning (CL) is an emergingparadigm to learn quality discriminative representations based onaugmented ground-truth samples. It initially showed the promisingcapability in the field of computer vision (CV) and natural languageprocessing (NLP) while recently researchers have applied CL tograph domains to fully exploit graph structure information and richunlabeled data. The core idea of GCL is to maximize the mutualinformation between instances (e.g., node, subgraph, and graph) ofdifferent views augmented from the original graph.",
  "Graph Contrastive Learning with Generative Adversarial NetworkKDD 23, August 610, 2023, Long Beach, CA, USA": "Similar to the visual domain , there are various augmenta-tion techniques on attributes or topologies and contrastive pretexttasks on different granularities. For example, DGI performsthe row-wise shuffling on the attribute matrix and conducts node-graph level contrast while MVGRL applies an edge diffusionaugmentation to obtain contrasting views. On top of attribute mask-ing, GraphCL proposes several topology-based augmentationsincluding node dropout, edge dropout and subgraph sampling toincorporate various priors. Rather than contrasting views at thegraph level, GRACE , GCA and GROC conduct node-level same-scale contrast, which is the most adopted method tolearn node-level representations. Very recently, JOAO adopts abi-level optimization framework to learn graph data augmentations.However, many GCL methods require a trial-and-error selectionor domain knowledge to augment views, which limits the applica-tion of GCL.",
  "Graph Generative Adversarial Network": "By designing a game-theoretical minimax game, Generative Adver-sarial Networks (GAN) have achieved success in various ap-plications, such as image generation , sequence generation ,dialogue generation , information retrieval , and domainadaption . More recently, GANs have been applied on graph-based tasks.In terms of the graph generation task, Liu et al. stack multi-ple GANs to form a hierarchical architecture for preserving topo-logical features of training graphs. To preserve the distribution oflinks with minimal risk of privacy breaches, Tavakoli et al. utilize GANs to learn the probability of link formation. Aiming atbetter capturing the essential properties and preserving the patternsof real graphs, Bojchevski et al. introduce NetGAN to learn adistribution of network via the random walks.Another line of applications is graph embedding. ANE treatsGANs as an regularization term to learn robust representations.GraphGAN designs a generator to learn node embeddingsand a discriminator to predict link probabilities. NetRA andProGAN preserve and learn the underlying node similarityin the model of GAN. Besides, Lei et al. and Yang et al. combine GANs with various encoders to refine the performance oftemporal link prediction. Sun et al. introduce MEGAN for multi-view network embedding, which accounts for the information fromindividual views and correlations among different views.Recently, GASSL and AD-GCL incorporate adversariallearning with graph contrastive learning to avoid capturing redun-dant information by optimizing adversarial graph augmentationstrategies. In computer vision, researchers have tried to make a com-bination of GAN and CL to boost the performance of GAN orCL . However, in graph mining, adapting GANs to learn graphdistribution and generate views for GCL remains unexplored.",
  "PRELIMINARIES": "In this section, we introduce some preliminary concepts and nota-tions. In this work, we denote a graph as G = (V, E), where V isa node set and E is an edge set. G may have node attributes {X R | V}. The adjacent matrix of G is denoted as R|V||V|,",
  "NotationsDefinitions": "Vthe set of nodes of a graphEthe set of edges of a graph, E V VGa graph G = (V, E)Xthe node attributes that G may havethe dimension of node attributesthe dimension of node representationsthe adjacent matrix of G, R|V||V|the approximation of the generated adjacent matrixthe node representation of node Vthe parameters of the view generatorthe parameters of the view discriminatorthe parameters of the graph encoder",
  ", = 1,if (, ) E;0,otherwise.(1)": "Graph Representation Learning. Given a graph G = (V, E),the aim of graph representation learning is to learn an encoder :V R, where { ()| V} can be further used in downstreamtasks, such as node classification and link prediction.Graph Neural Networks (GNNs). In this work, we focus on us-ing GNNs as the encoder . For a graph G = (V, E), each node V is paired with a representation initialized as (0)= X.The idea is to apply the neighborhood aggregation scheme on G,updating the representation of node by aggregating the representa-tions of neighbor nodes:",
  "= ({ ()| = {0, , }}).(3)": "Graph Contrastive Learning (GCL). GCL aims to maximize themutual information between instances (e.g., node, subgraph andgraph) of different views augmented from the original graph. Typi-cally, GCL methods adopt graph augmentation strategies to con-struct positive pairs and negative pairs, and utilize GNNs to encodethem into representations. Then, a contrastive loss function is de-fined to enforce maximizing the consistency between positive pairscompared with negative pairs.In this paper, we use LightGCN as the GNN encoder andfocus on node-level GCL. Note that several important notationsused in this paper are summarized in .",
  "GraphPooling": ": The architecture and the training steps of GACN. There are three modules in GACN, including the view generator, theview discriminator and the graph encoder, which are optimized by the G-Steps, the D-Steps and the E-Steps, respectively. the view generator learns the distributions of edges and generatesaugmented views by edge sampling. Then the view discrimina-tor is designed to distinguish views generated by the generatorfrom those generated by predefined augmentation strategies (e.g.,edge dropout). The view generator and the view discriminator aretrained in an adversarial style to generate high-quality views. Theseviews are used to train robust node representations in the graphencoder, which shares the same node representations with the viewdiscriminator.Note that we do not explicitly encode any graph generative prin-ciples into the model design. However, surprisingly our proposedGACN learns the graph distribution to generate views that followthe well-known preferential attachment rule (see .5).",
  "View Generator": "Given a graph G = (V, E), the view generator is designed to gen-erate a set of augmented views. For a specific view G, we assumethat each edge (, ) in G is associated with a random variable, Bernoulli(W,), where W R|V||V| is a learnable ma-trix, is a binary matrix with size |V| |V|, (, ) is in G if, = 1 and is dropped otherwise. To train the view generator inan end-to-end fashion, we relax the discrete , to be a continuousvariable in (0, 1) as follows:",
  "where R|V||V| is a random matrix with each element sam-pled from a uniform distribution: , (0, 1), () =1": "1+ isthe sigmoid function, and (0, 1] is a hyper-parameter to make, close to 0 or 1. Here, can be treated as an approximation ofthe generated adjacent matrix.To constrain the structure of the generated views, we proposetwo regularization losses, namely the Edge Count Loss and theNew Edge Loss, to train the parameters of the generator, i.e., ={W}. Edge Count Loss. This loss is designed to limit the number ofedges in G. Inspired by the edge-dropout strategy , we set aratio and train W to generate views with |E| edges. Formally,the edge count loss is computed as:",
  "L = L + L,(7)": "where and are hyper-parameters to balance the influencesof L and L, respectively.Besides, for the sake of efficiency, we initialize W instead oftraining from scratch. Specifically, we set an initialization rate to constrain the number of new edges at the beginning, i.e., |E| new edges and (1) |E| existing edges are expectedin the generated views. Thus, W is initialized as follows:",
  "(8)": "where C (V V E) is a candidate set of new edges. Note thatwe do not consider all the possible new edges as candidates becausemaintaining a dense W R|V||V| for large graphs is memory-unfriendly. In our implementation, we choose edges related to nodeswith top-2, 000 degrees as the candidate set. Note that we also try",
  "View Discriminator": "The view discriminator is a graph-level classifier to recognize thegenerated views. More precisely, the discriminator takes an adjacentmatrix as input and judges whether the matrix is a true matrix (i.e.,a matrix generated by predefined augmentation strategies) or a falsematrix (i.e., a matrix generated by the view generator). Formally,given a graph G = (V, E), we denote the set of views generated bypredefined augmentation strategies (i.e., edge dropout in this work)as G, and the set of views generated by the view generator as G.Thus, for each G G, a GNN encoder is used to encodethe representations of each node:",
  "Graph Encoder": "The graph encoder is designed to learn the node representations,i.e., the set of parameters of the encoder is = { (0)| V}, andis trained by two self-supervised losses, including the Graph Con-trastive Loss and the pairwise Bayesian Personalized Ranking(BPR) Loss.Graph Contrastive Loss. This loss is proposed to learn robustnode representations through maximizing the agreement betweendifferent views of the same node compared to that of other nodes.Specifically, we generate two views G and G using the prede-fined augmentation strategies and the view generator, respectively.Encoding G and G, we have two set of node representations:",
  "Model Optimization": "In this subsection, we present the parameter optimization procedureof GACN. As shown in Algorithm 1, the view generator, the viewdiscriminator and the graph encoder are optimized sequentiallyand iteratively.G-Steps (Lines 37) (see b) optimize the parameters ofthe view generator. Specifically, in each iteration, an augmentedview G is generated and then the regularization loss is computed.In consideration of generating high-quality views, an adversarialclassification loss is incorporated to cheat the view discriminatorby labeling G with 1. According to Eq. (12), we have:",
  "UCI1,67756,617Link PredictionTaobao12,61120,890Link PredictionAmazon10,099148,659Link PredictionLast.fm127,786720,537Link PredictionKuaishou138,8121,779,639Link Prediction": "Note that all the parameters are optimized using the back prop-agation algorithm. After converging, we obtain the learned noderepresentations {| V} by encoding graph G (Lines 1819).Time Complexity Analysis. For the view generator, the timecomplexity to generate a single view and calculate the regular-ization loss is (|V|2). For the view discriminator, the time com-plexity to encode a graph using LightGCN is (|V|2 ),where is the number of GCN layers. The time complexity topool the graph and calculate L is (|V| ). For the graphencoder, the time complexity to encode the two augmented viewsis (|V|2 ) and the time complexity to compute L is(|V|2 ) + |O| ). Thus, the overall time complexity of Algo-rithm 1 is ( [ + (| G | + | G|) + ] |V|2 ) ,where is the number of iteration round, , and arethe number of G-Steps, D-Steps and E-Steps, respectively.",
  "EXPERIMENTS": "In this section, we conduct extensive experiments and answer thefollowing research questions: RQ1: How does GACN perform w.r.t. node classification task? RQ2: How does GACN perform w.r.t. link prediction task? RQ3: What are the benefits of the proposed modules of GACN? RQ4: Can the generator of GACN generate high-quality graphsfor contrastive learning?",
  "Experimental Settings": "5.1.1Datasets. We evaluate the performance of GACN on sevenreal-world datasets, including two datasets for node classificationnamely Cora and Citeseer, and five datasets for link predictionnamely UCI, Taobao, Amazon, Lastfm and Kuaishou. We summarizethe statistics of all the datasets in . The detailed informationof these datasets is listed as follows.Datasets for Node Classification. Cora consists of 2,708 scientific publications classified intoone of seven classes. The citation network consists of 5,429 edges.Each publication in the dataset is described by a 0/1-valued wordvector indicating the absence/presence of the correspondingword from the dictionary. The dictionary consists of 1,433 uniquewords.",
  "Kuaishou3 is collected from the Kuaishou online video-watchingplatform. This dataset includes the interactions of 6,840 usersand 131,972 videos": "5.1.2Baseline Methods. To demonstrate the effectiveness and effi-ciency of GACN, we choose twelve state-of-the-art baseline meth-ods, categorized into three groups. Graph representation learningmodels include DeepWalk , LINE , node2vec and Light-GCN . Graph contrastive learning models include DGI ,GraphCL , GRACE and SGL . Graph generative andadversarial learning models include GraphGAN , AD-GCL and GraphMAE . The details of the baseline methods are listedas follows.Graph Representation Learning Models.",
  "AD-GCL proposes a principle to avoid capturing redundantinformation during the training by optimizing adversarial graphaugmentation strategies used in GCL": "GraphMAE explores generative self-supervised learning ingraphs and designs a state-of-the-art graph autoencoder usingthe masked feature reconstruction strategy with a scaled cosineerror as the reconstruction criterion.Note that we focus on node-level tasks in this paper, and meth-ods designed for graph-level tasks such as GCA , JOAO ,MVGRL and GASSL are not chosen as baselines. 5.1.3Parameter Settings. We implement GACN with Pytorch andthe model is optimized using the Adam optimizer with learningrate 0.001 during the training phase. By default, is set to 0.0001, is set to 0.5, is set to 0.5, is set to 1, is set to 0.5, isset to 0.75. For Cora, Citeseer and UCI, is set to 1 and is set to 0.0001, while for the other datasets, is set to 0.0001 and is set to 1. For all the baseline methods, we tune the parametersaccording to the validation set and report the best results. Thedimension of embedding of all the model is set to 128, and all theexperiments are conducted on a single GTX 1080Ti GPU. 5.1.4Metrics. For the node classification task, we choose threewidely-used metrics, namely P(recision), R(ecall) and F1. For the linkprediction task, we adopt two ranking metrics, include MRR andH(it rate)@k. In this paper, we report H@50 and similar results areobserved when = 20 and = 100.",
  "Node Classification (RQ1)": "We evaluate the performance of GACN w.r.t. the node classificationtask on the Cora and the Citeseer datasets. Following the exper-imental setting as Hassani and Khasahmadi and Velickovicet al. , we first run different methods without supervision togenerate all the nodes embeddings. Then we train a linear classifierand report the mean accuracy on the test nodes through 10 randominitialization. As shown in , GACN achieves the best resultscompared to the SOTA baseline methods in all benchmarks. Notably,GACN outperforms existing GCL methods by a large margin on twonode classification datasets. Notice that AD-GCL is designed forgraph-level tasks and has poor performances on node-level tasks.",
  "Link Prediction (RQ2)": "In the subsection, we conduct the link prediction on the UCI, Taobao,Amazon, Last.fm and the Kuaishou datasets. reports theexperimental results and it is observed that: 1) GACN consistentlyperforms the best on all datasets compared to other methods. We at-tribute these results to the fact that GACN is able to explore unseenedges and generate high-quality views for graph contrastive learn-ing. 2) Although SGL leverages the BPR loss and the contrastive lossfor self-supervise learning, GACN still outperforms SGL, showingthe effectiveness of incorporating GCL with graph GANs.",
  "w/o BPR: The bayesian personalized ranking loss is ignoredduring E-Steps": "shows the experimental results. We can find that: 1) Theregularization loss plays as an assistant role in performance, whichindicates that L helps to generate rational views for contrastivelearning. 2) The graph GAN is important in GACN, showing thebenefits of utilizing GAN to generate views and the joint learningframework. 3) The self-supervised learning losses are essential toGACN, because the GAN in GACN is based on graph-level classifi-cation and does not focus on learning node representations.",
  ": The experimental results of the distribution of newedges": "5.5.1Impact of and . In this part, we run the link predic-tion task on UCI under different settings of and , whilein each training epoch, we generate ten views and calculate theaverage amount of edges and the new edges. As shown in , contributes to the stability of the edge count, while helpsto limit the number of new edges. Specifically, when = 1 and = 0.5, the number of new edges decreases gradually as thetraining goes on while the edge count remains stable, which obtainsthe highest MRR compared to other settings. 5.5.2New Edge Distribution. To further investigate the distributionof new edges, we count the number of new edges in groups dividedby node degree. illustrates that compared to randomlyadding new edges, GACN 1) is able to adjust the number of newedges during training, and 2) generates more edges for high degreenodes (i.e., the color of high degree nodes is more similar to lowdegree nodes in (b) compared to that in (a)), whichis in agreement with the preferential attachment rule . 5.5.3Case Study. For better insight of the views generated byGACN, we randomly sample some nodes in UCI and visualize theirneighborhoods within two hops. shows that GACN tendsto attach nodes to those with high degree and removes other edges,which confirms that GACN indeed learns the preferential attach-ment rule and is able to generate reasonable alternative viewsfor contrastive learning.",
  "(a) Case 1(b) Case 2(c) Case 3(d) Case 4": ": Each case is the neighborhood of a sampled node in the generated view. Edges in red are generated by GACN. Edgesin black are those existing in the original graph and preserved by GACN. Edges in gray and dashed are those existing in theoriginal graph but dropped by GACN. It is observed that GACN learns the preferential attachment rule and tends to attachnodes to those with high degree. s 0.4 0.6 0.8 1.0 1.2 1.4 1.6 1.8 MRR Rate UCITaobaoAmazon Last.fmKuaishou",
  "MRR with default settings w.r.t. the link prediction": "task in .As shown in (a), the larger dimension of embeddingyields the better performance due to the strengthened expressioncapability of the GACN model. (b) shows that GACN is in-sensitive to . However, a large may result in poor performance.As shown in (c), GACN is sensitive to . Specifically, asmall results in sparse views, which are uninformative for con-trastive learning, while a large yields dense views, which doharm to robust node representation learning. Generally, setting to [0.5, 0.7] is a good choice. From (d), it is observedthat different datasets require different for best performance. Ingeneral, setting to 0.5 yields competitive performances.We also analyze how the view generator influences GCL, i.e., thesensitivity of , and . It is observed that GACN setting to 1 can obtain competitive results (see (e)), while asmall is preferred (see (f)). However, setting to 0 generates a large amount of unseen edges, and can result inpoor performance in some datasets. Thus setting to 0.25 is a",
  "CONCLUSION": "In this paper, we incorporated graph GANs with GCL w.r.t. node-level tasks, and presented GACN, a new GNN model that leverageda graph GAN to generate augmented views for GCL. Specifically,GACN developed a view generator, a view discriminator and a graphencoder to learn node representations in a self-supervised learningstyle. Besides, a novel optimization framework was proposed totrain the modules of GACN jointly. Through comprehensive exper-iments on seven real-world datasets, we empirically showed thesuperiority of GACN. In the future, GACN will be developed to dealwith heterogeneous and dynamic graphs.",
  "Olivier Henaff. 2020. Data-efficient image recognition with contrastive predictivecoding. In International Conference on Machine Learning. PMLR, 41824192": "R Devon Hjelm, Alex Fedorov, Samuel Lavoie-Marchildon, Karan Grewal, PhilBachman, Adam Trischler, and Yoshua Bengio. 2019. Learning deep representa-tions by mutual information estimation and maximization. In ICLR. Zhenyu Hou, Xiao Liu, Yukuo Cen, Yuxiao Dong, Hongxia Yang, Chunjie Wang,and Jie Tang. 2022. GraphMAE: Self-Supervised Masked Graph Autoencoders. InProceedings of the 28th ACM SIGKDD Conference on Knowledge Discovery and DataMining (Washington DC, USA) (KDD 22). Association for Computing Machinery,NY, USA, 594604.",
  "Thomas N Kipf and Max Welling. 2016. Semi-supervised classification with graphconvolutional networks. arXiv preprint arXiv:1609.02907 (2016)": "Kwot Sin Lee, Ngoc-Trung Tran, and Ngai-Man Cheung. 2021. Infomax-gan:Improved adversarial image generation via information maximization and con-trastive learning. In Proceedings of the IEEE/CVF winter conference on applicationsof computer vision. 39423952. Kai Lei, Meng Qin, Bo Bai, Gong Zhang, and Min Yang. 2019. GCN-GAN: A non-linear temporal link prediction model for weighted dynamic networks. In IEEEINFOCOM 2019-IEEE Conference on Computer Communications. IEEE, 388396.",
  "Petar Velickovic, William Fedus, William L Hamilton, Pietro Li, Yoshua Bengio,and R Devon Hjelm. 2019. Deep Graph Infomax. ICLR (Poster) 2, 3 (2019), 4": "Hongwei Wang, Jia Wang, Jialin Wang, Miao Zhao, Weinan Zhang, FuzhengZhang, Xing Xie, and Minyi Guo. 2018. Graphgan: Graph representation learningwith generative adversarial nets. In Proceedings of the AAAI conference on artificialintelligence, Vol. 32. Jun Wang, Lantao Yu, Weinan Zhang, Yu Gong, Yinghui Xu, Benyou Wang, PengZhang, and Dell Zhang. 2017. Irgan: A minimax game for unifying generativeand discriminative information retrieval models. In Proceedings of the 40th In-ternational ACM SIGIR conference on Research and Development in InformationRetrieval. 515524. Cheng Wu, Chaokun Wang, Jingcao Xu, Ziwei Fang, Tiankai Gu, ChangpingWang, Yang Song, Kai Zheng, Xiaowei Wang, and Guorui Zhou. 2023. InstantRepresentation Learning for Recommendation over Large Dynamic Graphs. In2023 IEEE 39th International Conference on Data Engineering (ICDE). IEEE, 8194. Jiancan Wu, Xiang Wang, Fuli Feng, Xiangnan He, Liang Chen, Jianxun Lian, andXing Xie. 2021. Self-supervised graph learning for recommendation. In Proceed-ings of the 44th international ACM SIGIR conference on research and developmentin information retrieval. 726735."
}