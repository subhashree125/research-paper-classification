{
  "ABSTRACT": "Large Language Models (LLMs) encode meanings of words in theform of distributed semantics. Distributed semantics capture com-mon statistical patterns among language tokens (words, phrases,and sentences) from large amounts of data. LLMs perform ex-ceedingly well across General Language Understanding Evalua-tion (GLUE) tasks designed to test a models understanding ofthe meanings of the input tokens. However, recent studies haveshown that LLMs tend to generate unintended, inconsistent, orwrong texts as outputs when processing inputs that were seenrarely during training, or inputs that are associated with diversecontexts (e.g., well-known hallucination phenomenon in languagegeneration tasks). Crowdsourced and expert-curated knowledgegraphs such as ConceptNet are designed to capture the meaningof words from a compact set of well-defined contexts. Thus LLMsmay benefit from leveraging such knowledge contexts to reduceinconsistencies in outputs. We propose a novel ensemble learningmethod, the Interpretable Ensemble Representation Learning (IERL),that systematically combines LLM and crowdsourced knowledgerepresentations of input tokens. IERL has the distinct advantageof being interpretable by design (when was the LLM context usedvs. when was the knowledge context used?) over state-of-the-art(SOTA) methods, allowing scrutiny of the inputs in conjunctionwith the parameters of the model, facilitating the analysis of mod-els inconsistent or irrelevant outputs. Although IERL is agnostic tothe choice of LLM and crowdsourced knowledge, we demonstrateour approach using BERT and ConceptNet. We report improvedor competitive results with IERL across GLUE tasks over currentSOTA methods and significantly enhanced model interpretability.",
  "LLMs have performed exceedingly well on the GLUE benchmarktasks . GLUE tasks measure the machines comprehension on su-pervised learning-based natural language processing tasks, such as": "Quora Question Pairs to check question redundancy, and Recogniz-ing Textual Entailment to check if two sentences share entailment,neutral, or contraction relations . LLMs learn trillions of parame-ters after training over a humongous amount of data. Irregularitiesin the data (for example, little or highly varying language tokenpatterns or contexts) causes LLMs to hallucinate - generating in-consistent outputs for similar inputs.Crowdsourced and curated knowledge graphs (KGs), such as Con-ceptNet, are designed to capture meanings of commonly used wordsusing a compact set of contexts agreed by humans . As a result,representations learned from ConceptNet are less likely to sufferfrom distributional irregularities among the tokens. Consequently,it is a promising and an active research topic on utilizing repre-sentations from KGs to potentially mitigate irregularities, whileprocessing input tokens via LLM representations. In this paper, wefocus on developing a learning method that systematically incor-porates representations from both KGs and LLMs to address thefollowing unresolved questions. Q1: Can we design an approach tocombine crowdsourced knowledge and LLM representations to obtainan integrated representation, in order to mitigate the model hallu-cination? Q2: Can we achieve an interpretable design - i.e., can wetractably discern for what inputs the LLM hallucinates on and whatknowledge context improves representation quality? Next, we brieflyreview existing methods that seek to infuse representations fromKGs and LLMs and their relevance to questions Q1 and Q2.",
  "Related Work on Combining Knowledgeand LLM Representations": "There is an extensive literature on combining LLMs and knowl-edge representations to leverage contextual information amonglanguage tokens from both . The representations are then pro-cessed through a task-specific neural network. Here we will coverthe four SOTA approaches, KALA, K-Adapter, TDLR, and GCT,broadly representing two kinds of methods - (1) Combining repre-sentations at the input level before passing it through the neuralnetwork (KALA and K-Adapter) and (2) Combing representations atthe parametric level, i.e., modify the parameters of the task-specific",
  "Yuxin Zi, Kaushik Roy, Vignesh Narayanan, Manas Gaur, and Amit Sheth": "neural network and the resulting token meaning interpretations(TDLR and GCT) .KALA modifies the input LLM representations for tokens byusing a weighted aggregate of other tokens connected in the knowl-edge graph. K-Adapter trains adapter models for encoding knowl-edge representations and combines the LLM and adapter repre-sentations at the input level. With KALA and K-Adapter, it is notpossible to keep track of and understand how the representationsare incorporated into the neural network after the input stage in-ternally. Ablation studies and post-hoc approximate interpretationsusing LIME, etc., provide representation interpretability (was theknowledge context important or the data context?). However,it is unclear how far the approximation is off from the truth, whichis crucial to evaluating and systematically addressing LLM hallu-cination issues. Furthermore, the effect of KALA and K-Adapterrepresentations on hallucinations has not been studied. Thus, KALAand K-Adapter do not fully address Q1 or Q2. TDLR operates onthe self-attention mechanism of transformers by modifying the at-tention or weight matrices to hard-code graph connections amonglanguage tokens. TDLR does this once, in the first self-attentionblock, and then allows model fine-tuning to continue as is. It isunclear if the attention matrix modification is retained during thefine-tuning across the remaining transformer blocks. GCT is simi-lar to TDLR and differs in the specifics of the self-attention matrixmodification operation. TDLR and GCT suffer from similar issuesas KALA and K-Adapter towards addressing Q1 and Q2.",
  "Task Descriptions and Hallucinations": "We experiment with similarity or entailment GLUE tasks that take apair of sentences as input and format its output as a +1 or a 1. Forthe similarity tasks, +1 and 1 correspond to similar or dissimilarinput sentences respectively. For the entailment tasks, +1 and -1correspond to entailment and contradiction, respectively.We use to denote the dataset, and is an instance in thedataset . Each is a three-tuple composed of : sentence 1,: sentence 2, and the label . Hallucinations. Hallucinations refers to inconsistent modeloutputs for similar inputs resulting from statistical irregularities inthe data. Since this notion is often used in the context of languagegeneration tasks, we clarify the context in which we use it in thispaper. To formalize this notion, we batch our instances into randombatches. We note the convergence rate variations of the trainingloop across these batches, where each batch is of size equal to 80%of the training dataset . We find that for the GLUE tasks, SOTAfine-tuning results in a high convergence rate variance (rangesfrom 13 45 iterations). This suggests that there may be a highdegree of irregularity in the statistical properties across the batches.Therefore, we can expect a model trained on these datasets togenerate inconsistent outputs for similar inputs, i.e., suffer fromhallucinations.",
  "Ensemble Learning Approach": "To fine-tune the models for GLUE tasks, a few feedforward neuralnetwork layers are added and trained using backpropagation. Such atraining procedure works well when there is a generalizable patternacross the instances in the fine-tuning dataset (regularly occurringstatistical patterns). To tackle the issue of irregularities, we proposeusing example patterns from each instance and aggregating themusing an ensemble learning approach. We can think of an examplepattern as one that maps a given instance to its output in the task-specific dataset, which can be seen as (an instance level) model anddefine an ensemble function () for a new point instance as anensemble of weighted contributions from similar instances in thedataset as",
  "Utilizing Knowledge Graph Contexts": "The ensemble approach formulation allows the expressiveness tomodel both generalizability across instances and instance-level de-tails. Examining the ensemble models parameters lets us interpretwhether an instance shows irregular patterns. However, it does notyet incorporate a mechanism to solve the irregularity issue duringmodel learning. Here we posit that combining LLM and knowledgegraph representations using an ensemble approach allows us to in-terpret instances for their pattern regularities and draw from eitherthe LLM or knowledge contexts to solve the irregularity resultingin high performance that hallucinates less.Thus, we expand the formulation in (1) to describe the operationof combining LLM and knowledge representations as",
  "( [, , ] + [, , ])": "(2)Here, refers to the dot product between vectors, refers toa similarity measure between the LLM representations, and refers to a similarity measure between the KG embedding represen-tations. The and are two dimensional vectors. Aggregation Methods. Aggregation as a method to reduce sta-tistical irregularities such as high variance has been well-studied instatistical learning theory literature . The ensemble formulationin (2) can be seen as aggregation over instances in the dataset .In this work, we experiment with two types of aggregation, theaverage of the instance representations and using averages overhigher-order moment representations. We can expect LLMs trainedon very large amounts of data to tend to the normal distributionaltrend in the underlying data distribution. Therefore the average(first-order moment) and variance (second-order moment) of groupsof instance representations are sufficient statistics to describe theunderlying distribution. However, for smaller number of data in-stances (such as in GLUE task datasets), it may be necessary toutilize averages over higher order moments as sufficient statistics.We experiment with both types of aggregation and compare theresults.",
  "THE INTERPRETABLE ENSEMBLEREPRESENTATION LEARNING (IERL)ALGORITHM": "shows an illustration of the IERL optimization step - (a)Shows the dataset (e.g., Recognizing Textual Entailment) and itsinstances indexed by . and denote the BERT represen-tations of sentence 1: and 2: from instance . and denote the ConceptNet representations of sentences 1 and2 from instance . (b) Shows how similar and dissimilar instancesto are constructed and aggregated for the cases of == 1and 1 respectively. (c) Shows one step of optimization in detailcorresponding to line 22 in Algorithm 3 (d) Shows two methodsof aggregation over instances - Averaging and Moment-Based (Al-gorithm 2) aggregation. Algorithm 1 and 2 detail the IERL and : (a) Shows the dataset (e.g., Recognizing Textual En-tailment (RTE)) and its instances indexed by ( = 1, . . . , ).The BERT representations of sentence 1: and 2: from instance are denoted by and . The Concept-Net representations of sentences 1 and 2 from instance aredenoted by and , respectively. (b) Shows how similarand dissimilar instances to are constructed and aggre-gated for the cases of = 1 and 1, respectively. (c) Showsone of the optimization problems in detail corresponding toline 22 in algorithm 3. (d) Shows two methods of aggregationover instances - Averaging and Moment-Based (algorithm 2)aggregation.",
  "(1) Sentence Similarity: Consists of input sentence pairs anda 1 or 0 denoting if the pairs are similar or not (we refor-mulate to 1 and 1) - QQP, and STS": "(2) Sentence Entailment: Consists of input sentence pairs andlabel from among entailment, contradiction, neutral (wereformulate to 1 for entailment and 1 for contradiction) -QNLI, WNLI, MNLI, and RTEWe also convert our vectors to unit vectors before computing dotproducts (line 21 in IERL Algorithm - 3). Baseline Model. For our baseline model we implement IERLusing a simple average for aggregation (instead of computing mo-ments using Algorithm 2). We call this IERLB. We present ourevaluation results in the order that they address the questions Q1and Q2 introduced in section 1.",
  "Quantitative Evaluation - Addresses Q1": "We report accuracy measures of our method against the baselineIERLB and the current leader on the GLUE leaderboard and seethat the performance of IERL shows competitive performance evenagainst state-of-the-art performance. We also compute #Optimiza-tion steps using randomly sampled batches of size 80% of the wholedataset per sample and tabulate the range (min-max)1. We see thatthe range is significantly higher using an implementation of BERT(BERT (Ours) - Vanilla BERT with 6 layers and fine-tuning) com-pared to both versions of IERL. Furthermore, higher-order momentsalso show a much faster convergence of 7-13 steps vs. 20-30 and20-45 steps. We use up to fourth-order moments in our experiments,i.e., 0-3.",
  "Qualitative Evaluation - Addresses Q2": "shows an example inference output using IERL for a groupof test sentences and an anchor sentence ( chosen for ease ofillustration). The figure shows a group of instances shown in theoval and rectangular boxes (including ) and similarity measure-ments. For a pair of instances and one other instance from thegroup shown (let it be denoted by 2), we first find the closest",
  "We are currently running fine-tuning using the leaderboard model and will report#Optimization-Steps range in future work": "sentences 1,2 from the training set and compute two simi-larities as 1 = (1) (2) and 2 =(1) (2), where (.) represents normalizing the vectors asunit vectors. We display the greater of the two. The shapes arehighlighted in green when the sum of the similarities is greaterthan or equal to , i.e., inference value =1 (line 23 in algorithm 3) and highlighted in pink otherwise, i.e.,inference value = -1. The rectangular shape denotes the 1 2,and the oval shape denotes that 2 1 (the parameter values alsoreflect the same in 1 and 2). Thus IERL is designed to providea simple method to interpret the inference results for a group oftest sentences. : Shows an example inference output using IERL fora group of test sentences along with an anchor sentence (chosen for ease of illustration). The figure shows a group ofinstances shown in the oval and rectangular boxes (including) and similarity measurements. For a pair of instances andone other instance from the group shown (let it be denoted by2), we first find the closest sentences 1,2 from the trainingset and compute two similarities as1 = (1) (2)and 2 =(1) (2), where (.) repre-sents normalizing the vectors as unit vectors. We displaythe greater of the two. The shapes are highlighted in greenwhen the sum of the similarities is greater than or equal to , i.e., inference value = 1 (line 23 in al-gorithm 3) and highlighted in pink otherwise, i.e., inferencevalue = -1. The rectangular shape denotes the 1 2, andthe oval shape denotes that 2 1 (the parameter valuesalso reflect the same in 1 and 2). Thus IERL is designedto provide a simple method to interpret the inference resultsfor a group of test sentences.",
  "CONCLUSION AND FUTURE WORK": "In this work, we propose Interpretable Ensemble RepresentationLearning (IERL) as an ensemble technique that demonstrates the in-terpretable combination of LLM and knowledge representations toresult in a high-performance model that is robust to hallucinationsand results in faster convergence in the number of optimizationsteps. Through our experiments, we see the promise of IERL asa method that advances research towards combining LLMs andknowledge graphs that retain both high performances and are in-terpretable by design (thus, addressing interpretability ambiguitiesduring ablations and approximate post-hoc interpretations). In fu-ture work, we will explore different LLM and KG choices and varythe order of moments considered. Furthermore, we will explore",
  "This work is built on prior work , and supported by the Na-tional Science Foundation under Grant 2133842, EAGER: Advanc-ing Neuro-symbolic AI with Deep Knowledge-infused Learning\"": "Jason Wei, Yi Tay, Rishi Bommasani, Colin Raffel, Barret Zoph, SebastianBorgeaud, Dani Yogatama, Maarten Bosma, Denny Zhou, Donald Metzler, et al.Emergent abilities of large language models. arXiv preprint arXiv:2206.07682,2022. Alex Wang, Amanpreet Singh, Julian Michael, Felix Hill, Omer Levy, andSamuel R Bowman. Glue: A multi-task benchmark and analysis platform fornatural language understanding. arXiv preprint arXiv:1804.07461, 2018. Phillip Bricker. Ontological commitment. 2014. Robyn Speer, Joshua Chin, and Catherine Havasi. Conceptnet 5.5: An openmultilingual graph of general knowledge. In Thirty-first AAAI conference onartificial intelligence, 2017. Shaoxiong Ji, Shirui Pan, Erik Cambria, Pekka Marttinen, and S Yu Philip. Asurvey on knowledge graphs: Representation, acquisition, and applications. IEEETransactions on Neural Networks and Learning Systems, 33(2):494514, 2021.",
  "Minki Kang, Jinheon Baek, and Sung Ju Hwang. Kala: Knowledge-augmentedlanguage model adaptation. arXiv preprint arXiv:2204.10555, 2022": "Ruize Wang, Duyu Tang, Nan Duan, Zhongyu Wei, Xuanjing Huang, GuihongCao, Daxin Jiang, Ming Zhou, et al. K-adapter: Infusing knowledge into pre-trained models with adapters. arXiv preprint arXiv:2002.01808, 2020. Vipula Rawte, Megha Chakraborty, Kaushik Roy, Manas Gaur, Keyur Faldu,Prashant Kikani, Hemang Akbari, and Amit P Sheth. Tdlr: Top semantic-downsyntactic language representation. In NeurIPS22 Workshop on All Things Atten-tion: Bridging Different Perspectives on Attention. Edward Choi, Zhen Xu, Yujia Li, Michael Dusenberry, Gerardo Flores, Emily Xue,and Andrew Dai. Learning the graphical structure of electronic health recordswith graph convolutional transformer. In Proceedings of the AAAI conference onartificial intelligence, volume 34, pages 606613, 2020.",
  "William AV Clark and Karen L Avery. The effects of data aggregation in statisticalanalysis. Geographical Analysis, 8(4):428438, 1976": "Kaushik Roy, Yuxin Zi, Manas Gaur, Jinendra Malekar, Qi Zhang, VigneshNarayanan, and Amit Sheth. Process knowledge-infused learning for clinician-friendly explanations. arXiv preprint arXiv:2306.09824, 2023. Kaushik Roy, Vedant Khandelwal, Raxit Goswami, Nathan Dolbir, JinendraMalekar, and Amit Sheth. Demo alleviate: Demonstrating artificial intelligenceenabled virtual assistance for telehealth: The mental health case. arXiv preprintarXiv:2304.00025, 2023. Kaushik Roy, Usha Lokala, Vedant Khandelwal, and Amit Sheth. \" is depres-sion related to cannabis?\": A knowledge-infused model for entity and relationextraction with limited supervision. arXiv preprint arXiv:2102.01222, 2021.",
  "Kaushik Roy, Qi Zhang, Manas Gaur, and Amit Sheth. Knowledge infused policygradients for adaptive pandemic control. arXiv preprint arXiv:2102.06245, 2021": "Parth Asawa, Manas Gaur, Kaushik Roy, and Amit Sheth. Covid-19 in spain andindia: comparing policy implications by analyzing epidemiological and socialmedia data. arXiv preprint arXiv:2010.14628, 2020. Kaushik Roy, Yuxin Zi, Vignesh Narayanan, Manas Gaur, and Amit Sheth. Ksat:Knowledge-infused self attention transformerintegrating multiple domain-specific contexts. arXiv preprint arXiv:2210.04307, 2022. Revathy Venkataramanan, Kaushik Roy, Kanak Raj, Renjith Prasad, Yuxin Zi,Vignesh Narayanan, and Amit Sheth. Cook-gen: Robust generative modeling ofcooking actions from recipes. arXiv preprint arXiv:2306.01805, 2023.",
  "Kaushik Roy, Tarun Garg, Vedant Palit, Yuxin Zi, Vignesh Narayanan, and AmitSheth. Knowledge graph guided semantic evaluation of language models foruser trust. arXiv preprint arXiv:2305.04989, 2023": "Manas Gaur, Kaushik Roy, Aditya Sharma, Biplav Srivastava, and Amit Sheth.who can help me?: Knowledge infused matching of support seekers and supportproviders during covid-19 on reddit. In 2021 IEEE 9th International Conference onHealthcare Informatics (ICHI), pages 265269. IEEE, 2021. Kaushik Roy, Manas Gaur, Misagh Soltani, Vipula Rawte, Ashwin Kalyan, andAmit Sheth. Proknow: Process knowledge for safety constrained and explainablequestion generation for mental health diagnostic assistance. Frontiers in big Data,5:1056728, 2023. Adam Tsakalidis, Jenny Chim, Iman Munire Bilal, Ayah Zirikly, Dana Atzil-Slonim, Federico Nanni, Philip Resnik, Manas Gaur, Kaushik Roy, Becky Inkster,et al. Overview of the clpsych 2022 shared task: Capturing moments of change inlongitudinal user posts. In Proceedings of the Eighth Workshop on ComputationalLinguistics and Clinical Psychology, pages 184198, 2022. Shrey Gupta, Anmol Agarwal, Manas Gaur, Kaushik Roy, Vignesh Narayanan,Ponnurangam Kumaraguru, and Amit Sheth. Learning to automate follow-upquestion generation using process knowledge for depression triage on redditposts. arXiv preprint arXiv:2205.13884, 2022.",
  "Nathan Dolbir, Triyasha Dastidar, and Kaushik Roy.Nlp is not enoughcontextualization of user input in chatbots. arXiv preprint arXiv:2105.06511,2021": "Vipula Rawte, Megha Chakraborty, Kaushik Roy, Manas Gaur, Keyur Faldu,Prashant Kikani, Hemang Akbari, and Amit Sheth. Tdlr: Top (semantic)-down(syntactic) language representation. UMBC Faculty Collection, 2022. Usha Lokala, Francois Lamy, Triyasha Ghosh Dastidar, Kaushik Roy, RamintaDaniulaityte, Srinivasan Parthasarathy, and Amit Sheth. edarktrends: Harnessingsocial media trends in substance use disorders for opioid listings on cryptomarket.arXiv preprint arXiv:2103.15764, 2021."
}