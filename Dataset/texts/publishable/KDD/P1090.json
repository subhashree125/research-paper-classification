{
  "Abstract": "E-commerce companies deal with a high volume of customer service requestsdaily. While a simple annotation system is often used to summarize the topics ofcustomer contacts, thoroughly exploring each specific issue can be challenging.This presents a critical concern, especially during an emerging outbreak wherecompanies must quickly identify and address specific issues. To tackle this chal-lenge, we propose a novel machine learning algorithm that leverages natural lan-guage techniques and topological data analysis to monitor emerging and trendingcustomer issues. Our approach involves an end-to-end deep learning frameworkthat simultaneously tags the primary question sentence of each customers tran-script and generates sentence embedding vectors. We then whiten the embeddingvectors and use them to construct an undirected graph. From there, we definetrending and emerging issues based on the topological properties of each tran-script. We have validated our results through various methods and found that theyare highly consistent with news sources.",
  "Introduction": "E-commerce websites handle a vast number of online customer service requests daily. During atypical online customer service interaction, customers first interact with a chatbot which asks themquestions to identify their intent. This intent is usually classified based on the product or servicethat the customer needs assistance with. For instance, an online consumer electronics retailer mightuse its chatbot to classify requests as relating to cell phones, computers, or home appliances, amongothers. The chatbot then routes the customer to an agent who specializes in the requested product orservice to assist. While the actual business practices among companies may differ, the interactionprocess between customers and agents is generally similar. Agents usually begin with a greeting andask for details about the customers questions. They then engage in diagnosis and finally concludewith some closing remarks. Generally, processing customer requests can take several minutes, making it one of the most time-consuming aspects of e-commerce business. Therefore, developing a standardized process to han-dle specific issues is critical to help customers save considerable time and optimize the availableresources of agents. This is especially important during emerging events or sudden surges in cus-",
  "Topological PropertiesTrending & Emerging Issues": ": Our proposed workflow involves several steps. Initially, the transcripts are passed to asentence attention model to extract the primary questions asked by the customers and their corre-sponding sentence embeddings. The embeddings are then whitened to obtain representations in anisotropic coordinate system. These whitened vectors are then utilized to construct an undirectedgraph, and their topological properties are calculated to identify both trending and emerging issues. tomer inquiries. By anticipating common issues and developing standardized procedures for agents,businesses can improve their response times, reduce customer frustration, and ultimately enhancecustomer satisfaction. We present a novel machine learning framework, as illustrated in , that can detect emerging andtrending issues without predefined lists. The terms trending and emerging refer to the topicsthat are most frequently discussed within the current time window and the topics that showthe most rapid increase in discussion compared to the previous time window. Our approachcomprises three distinct components. Firstly, a deep learning model is employed, which utilizes anattention mechanism to automatically tag the primary question sentence in each customers transcriptand generates sentence-level embedding vectors. To improve the performance of cosine similarity,we decouple the covariance matrix to whiten the embedding vectors, bringing the coordinates ofthe feature space close to an orthonormal basis. We then construct an undirected graph based oncosine similarity. Finally, we analyze the topology of the graph by calculating the centrality of eachcustomers question. This enables us to quantify both trending and emerging issues. Related Works Our work relates to several areas in the literature, including sentence-level attention,sentence tagging, and graph-based clustering. Works related to sentence attention include (Yanget al., 2016), (Nallapati et al., 2016), and (Lin et al., 2016), which apply the idea to documentclassification, summarization, and text noise reduction, respectively. Regarding sentence tagging,(Collobert and Weston, 2008) and (Santos and Zadrozny, 2014) are works that perform sentencetagging from token-level representation, and have also influenced our approach. Additionally, wereference several works in graph-based clustering, including (Wang et al., 2019) and (Novak et al.,2010), which use this technique to handle repetitive sequences and multiview data. These works haveinspired our research in the application of topological data analysis to natural language processing.",
  "The Dataset": "There has been a lack of publicly available datasets related to customer service transcripts. Toaddress this gap, we partnered with customer service team to initiate this research, using a datasetfrom an online chat system that enables customers to communicate with customer service agents. Wecollected over 500,000 contact transcripts during 2022, recording conversations between customersand agents. Each contact also comes with a unique label of the product or service that the customerand agents discussed. Its worth noting that the dataset only contains customer text data, with all confidential information, such as names and account details, anonymized to protect privacy beforebeing shared with researchers. Although the dataset is from a specific database, the methodologypresented in this article can be applied to other use cases as well.",
  "Sentence Embedding": "Our goal is to identify the primary question sentence in a customer-agent contact transcript. Wepropose two hypotheses: (1) the primary question sentence typically appears in the first few sen-tences of the customers interaction with the agent, and (2) it contains the most relevant informationabout the product or service being discussed. If these hypotheses hold, we can treat the problemas a machine learning task: identifying the customer sentences near the agents initial responsethat are most useful in predicting the product or service of the contact for a machine learningclassifier. To achieve this, we need information on attention weights at the sentence level. We propose a deep learning model, as shown in , to achieve our goal. Unlike traditional textclassification models that represent an article as a 2D tensor RNatNwe, where Nat is the numberof tokens in the article and Nwe is the dimension of the word embedding, our approach representseach article as a 3D tensor RNasNstNwe. Here, Nas is the number of sentences in the article,and Nst is the number of tokens per sentence. To accommodate varying numbers of sentences andtokens per sentence in each transcript, we use zero-padding to ensure a consistent tensor shape forsubsequent processing. To obtain sentence-level embeddings, we treat each sentence as a temporal slice and apply a time-distributed wrapper to a sequence model , such as BERT or LSTM. This ensures that the modelreceives only one sentence per time step, allowing us to embed each sentence. The resulting outputtensor, Q RNasNse, contains Nas sentence vectors, each with Nse dimensions. Our bag of sentences model currently does not consider sentence positions, but we have observedthat customer questions tend to appear in early sentences during interactions with agents. Thissuggests that sentence positions can impact attention weights, so we incorporate sentence positioninformation into the model. To do this, we adapt the idea of position embedding used in many language models for tokens, butapply it to sentences. We assign each sentence an index, ranging from -Nas to +Nas, representingthe number of sentences between the current sentence and the agents first response. For instance,an index of -5 indicates that the sentence is five steps before the agents first sentence, while +5indicates five steps after. We shift the indices by Nas, resulting in an allowed index range of 0 to+2Nas, with the sentence having an index of Nas being the agents first sentence to avoid negativeindices. For a sentence with index i, the p-th component of the position embedding vector Ei isgiven by Ei(2p) and Ei(2p + 1):",
  "Attention(K, Q, V ) = = softmax(Q Kdk)T V = V(3)": ", where Q RNasNse is a query tensor (i.e. the sentence embedding), K RNse is a key vectorand V RNasNse is a value tensor. We can generally define Q = V without any impact on modelperformance. As a result, the attention value RNse is a vector and the sum of its elements mustequal 1, due to the application of the softmax function.",
  "E1+Q2E2+Q3E3+Q4E4+": ": The Sentence Attention Model. The model consists of blue blocks, representing ten-sors, and green blocks representing operators. (a) The neural network is comprised of sentencetensors, Si, and a sequence model, , which outputs Qi. The position embedding vector Ei iscombined with Qi to create the sentence embeddings Qi. Finally, a linear classifier predicts theproduct/service. (b) The red block in (a) is described in detail. Tensor notation (S1; Tn) refers tothe n-th token in sentence S1. The sequence model processes each word in a sentence using atime-distributed wrapper to handle multiple sentences. (c) The orange block in (a) is explained. Adense layer, K, with a softmax activation function is applied to all sentence embedding vectors Qi(via a time-distributed wrapper) to calculate attention scores i. Note that Qi is equivalent to Vi. Our models attention vector has a simple interpretation. As shown in , each sentence ina transcript is represented as a vector V i (the i-th row of the 2D tensor V ). The attention vector is a linear combination of all sentences, computed as = i iV i, subject to the constraintthat i i = 1. We then pass through a fully connected layer with a softmax activation functionto predict the product or service associated with the transcript. The attention weights i reflect theimportance of each sentence in determining the product or service, with higher weights assigned tosentences containing more critical information.",
  "Experiments": "Our model was trained on 500,000 transcripts with 152 classes to predict the product or servicediscussed in each contact. We used DistilBERT (Sanh et al., 2020) as the embedding model , withan output dimension of 768. To prepare the transcripts for training, we padded each one with zerosto create 64 sentences, each with 128 words. After training, we calculated attention weights i for each customer sentence in a transcript. To iden-tify the primary question, we assumed that it is the sentence with the highest attention weight that isN steps before or after the agents first sentence. In testing on 4,000 human-annotated transcripts,we found that N = 2 (i.e., 2 steps) yielded the best results, correctly identifying the primary ques-tion sentence in 84.3% of the total transcripts. in the Appendix illustrates an example of howour sentence attention model tags the primary question sentence. To evaluate the impact of sentence position embedding on performance, we compared the modelwith and without this feature. Although the difference in accuracy was minimal (83.4%), we ob-served that sentence position embedding resulted in higher attention weights on the primary questionsentence. Further investigation is needed to explore the effects of position embedding.",
  "Topological Natural Language Analysis": "Our objective is to identify both emerging and trending topics among the questions gathered by themodel presented in Sec. 2. However, conventional clustering methods face several challenges inachieving this goal, including sensitivity to hyperparameters, scalability issues with large numbersof classes and samples, and lack of flexibility in defining distances. Moreover, identifying emerging topics involves changes in the volume of a topic between timewindows, and conventional clustering methods cannot determine whether two clusters in differentdatasets are related to the same topics. It is even possible for an emerging topic to be present inthe current time window without appearing in the previous time window. Additionally, conven-tional clustering methods may treat emerging topics as noise due to their much smaller volume thantrending topics. To overcome these challenges, we propose a topological-analysis-based method robust to hyperpa-rameter selection and can quantitatively detect both emerging and trending topics between differenttime windows.",
  "Sentence Embedding Whitening": "Assuming we have gathered a substantial number of customers primary questions and their asso-ciated embedding vectors Qit , where Q represents the output embedding vectors of without theaddition of position embedding, i = 1 N corresponds to the i-th transcript, and t signifies thetagged sentence. Provided that we can define a metric or distance to express the semantic similaritybetween two questions, it becomes possible to construct a graph in which an edge connects twoquestions if their cosine distance falls below a specified threshold. However, cosine distance may not be an appropriate metric for measuring text similarity. In fact, sev-eral experiments have shown that cosine similarity is not suitable for use with BERT-based represen-tations and its performance in many similarity tasks is inferior to that of traditional embedding meth-ods(Reimers and Gurevych, 2019) such as GloVe(Pennington et al., 2014) or Word2Vec(Mikolovet al., 2013). This is mainly due to the fact that cosine distance assumes an orthonormal coordinatesystem, which is not the case for most pre-trained sequence models. Various approaches have beenproposed to address this issue, such as BERT-flow(Li et al., 2020) or representation whitening(Suet al., 2021), to ensure that data distributions tend to be isotropic, a property that an independentbasis set should have. Representation whitening, a post-processing method that does not requiremodel training, is particularly effective in calibrating sentence representations. Hence, we adopt thisstrategy to improve the performance of our sentence representation. The core idea of representation whitening is to find a linear transformation that sets the mean ofthe set {Qi=1Nt} to zero and the covariance matrix to an identity matrix. To achieve this, we firstcalculate the mean and covariance matrix K. As we aim for a diagonalized covariance matrix, wecan compute the unitary matrix U and singular values matrix A using singular value decomposition(SVD)(Halko et al., 2009): U, A, U = SV D(K). In this case, the whitening matrix W thatdiagonalizes the covariance matrix K is: W KW = I; W = U A1. Once we obtain thewhitening matrix W, the whitened sentence embedding vectors become: zi = (Qit )W. Underthis transformation, the mean of {zi, i = 1 N} equals zero, and the covariance matrix beingequal to an identity matrix I is guaranteed. Although we lack labels to evaluate the performanceof whitened sentence embedding vectors in capturing similarity, we manually inspected a smallportion of the data with cosine similarity. Whitened vectors zi indeed appear more reasonable thanthe original ones. From this point, we will use zi as the embedding vector of the tagged questionsentence in the i-th transcript unless specified otherwise.",
  "Undirected Representation Graph and Centrality": "Let us assume that we have gathered primary customer questions and their corresponding sentenceembeddings, zi, over two time periods, T0 and T1. Each sentence can be represented as a nodein an undirected graph, with edges connecting nodes whose cosine similarity surpasses a specifiedthreshold, . It is important to note that this graph is constructed using data from both time periods,",
  "frequency": ": The centrality distribution of Fire Tablet in Feb 2023 is depicted in panels (a)-(f), where wecompare the cosine similarity thresholds of = 0.8 and = 0.6. As for panel (g), the graph builtusing a few selected samples clearly demonstrates that similar sentences tend to cluster together,resulting in high centrality for nodes around the cluster centers.",
  "T0 and T1. In this graph, a node with a higher number of neighbors indicates a greater number ofsimilar questions": "Centrality is a significant topological property of a node, which describes its importance within agraph. Various types of centrality exist, each applicable to different scenarios. In this case, we definetwo new types of centrality that modify the decay centrality. Assuming we have an undirected graphrepresented by an adjacency matrix A, where A(i, j) = 1 if nodes cos(zi, zj) , the decaycentrality of a node ni in a graph G is defined as(van Steen, 2010):",
  "|N(G)|": "Here, N(G) refers to the set of nodes in the graph, and |N(G)| is the total number of nodes in thegraph. This normalization factor ensures that the centrality C(ni) is independent of the graphs size.The attenuation factor is typically selected such that 0 < < 1. The topological distance dbetween nodes i and j is the graph distance, not the Euclidean distance |zi zj|. The numerator isgiven by an exponent d(ni, nj)1, which results in d(ni,nj)1 = 1 when nodes i and j are directlyconnected. A question with higher decay centrality means the graph has more similar questions.",
  "|N(G)|[Wi = Wj]": "In these equations, the brackets represent Iverson brackets, yielding 1 if the statement inside istrue and 0 if false. Wi refers to the time window that node i belongs to. C+ considers contributionsonly when two nodes belong to the same time window, while C accounts for contributions fromdifferent windows, decaying exponentially as the distance increases. It is important to note thatnode j can reach node i through intermediate nodes in either the same or different time windows.Furthermore, we have C(ni) = C+(ni) + C(ni). This definition splits the decay centrality intotwo terms based on the time window. We can effectively identify trending and emerging issues byutilizing matched and mismatched decay centrality.",
  "Topological Perspective": "We are only interested in the nodes in the current time window, so we define trending and emergingissues from a topological perspective as follows: 1). Trending issues are identified as the customersprimary questions with a large trending score: St = C+ 2). Emerging issues are identified asthe customers primary questions with a large emerging score: Se = tanh2(C+/)[C+ C]/C.The definitions for the trending and emerging scores are simple to understand. The trending score,denoted by St, counts the number of similar questions in the graph that exist in the current timewindow. On the other hand, the emerging score, given by [C+ C]/C, represents the difference incentrality contributed from the previous time window and the current time window. Its importantto note that C+ + C = C. As a result, the emerging score lies between -1 and +1, where -1 and +1correspond to the centrality entirely coming from the previous and current time window respectively,while 0 indicates equal contributions from both time windows. To avoid identifying small-sizeclusters that may not be significant for a business that receives a large volume of customer contacts,we introduce an additional filtering factor, tanh2(C+/), where is a parameter that controls thestrength of the filter. This factor applies a weight to the emerging score, such that tanh2(C+/)drops to 0 when C+ , and saturates to 1 when C+ .",
  "Experiment": "We constructed a graph using the MessageUs transcript data by applying a cosine similarity thresh-old of = 0.7, an attenuation factor of = 0.5, and a filter factor of = 0.1 Max({Ci+; i =1 N}), where N is the total number of nodes. This filter factor was set to 10% of the maximumnumber of C+ values, and it helped to exclude small clusters that were unlikely to be significant. Weused topological data analysis to identify the most prominent clusters, and we found that the topicsof these clusters were highly consistent, even though the exact values of C+ and C were sensitiveto the chosen hyperparameters. Varying the hyperparameters affected only the sizes of the clustersand did not significantly alter the topics we discovered, which demonstrates the robustness of thetopology analysis approach. shows the distribution of C+, C, and Se for Tablet-related transcripts, using Jan 2023 andFeb 2023 as the previous and current time windows, respectively (around 100K data points). Wecompare the distributions for a cosine similarity threshold of = 0.8 (panels (a)-(c)) and = 0.6(panels (d)-(f)). Decreasing results in a more compact graph and a more Gaussian-like distributionof centrality. We observe that the emerging score distribution can be separated into two parts: aGaussian-like distribution around zero due to the filter factor applied to nodes with C+ , anda long-tail region due to nodes with C+ . The filter factor helps to focus on the outliers, andthe nodes in the long-tail region are generally similar, with high-score nodes unlikely to becomelow-score nodes due to changes in hyperparameters. It is important to note that similar sentences tend to form clusters. As a result, the neighbors of ahigh centrality node also tend to have high centrality, as shown in (g). To avoid locating thesame cluster multiple times, it is necessary to ensure that two centers are sufficiently far apart. Toachieve this, we first designate the node with the largest St (for trending) or Se (for emerging) asthe cluster center and its surrounding neighbors with graph distance 3 as the cluster members.Next, we search for the node with the next-largest score at least a graph distance of 4 away fromany known clusters as the next cluster center. We repeat this procedure until we have obtained thedesired number of clusters. Table.1 of the appendix provides examples of sentences from the top-1 trending and emerging clus-ters of Tablet in February 2023. As one can see, all the customers questions within each clusterare very similar, demonstrating the effectiveness of our approach in cosine similarity and topology-based topic detection.",
  "model presents a challenge. To address this challenge, we have proposed a human-annotation-basedmethod for validation": "Our data collection spanned from November 2022 to February 2023 and involved more than 10different products, including Kindle, Echo, Music, eBook, and Prime Video. During this period, ourfocus was on identifying the top-3 trending and emerging issues. We took care to exclude issuesthat appeared unreasonable due to quality of data or instances of fraud or policy abuse attacks. As aresult of this process, we successfully identified 84 trending issues and 64 emerging issues. To assess trending issues, each annotator is asked to select three keywords that best represent eachissue. We then count the number of transcripts containing these keywords simultaneously. Remark-ably, we discovered that all 84 issues, representing 100% of the total, constitute a large portion, atleast 10%, of the overall volume of each product line. Furthermore, the volume remains consistentlystable from month to month. Although its challenging to determine if these are the largest issues,its noteworthy that a significant portion of them pertains to return or refund-related matters, aligningclosely with our business experiences. Regarding emerging issues, we employ three methods to identify them. Firstly, we select the threemost representative keywords for each issue and monitor changes in volume within transcripts con-taining these keywords. Additionally, we investigate whether the issue surfaces in the Amazon Dig-ital and Device Forum for that month, where customers discuss Amazons services, with a minimumof 10 replies ( not necessary in a single thread ). Lastly, we conduct a Google search to determine ifthese issues are covered in news media. Our surveys revealed some insightful findings: approximately 90% of emerging issues exhibit vol-ume changes exceeding 30% between two months, around 60% of the issues are discussed in theAmazon Digital and Device Forum for that month, and roughly 15% of the issues are covered innews media, typically related to live events or new product launches. The surveys support ourmodel indeed captures the emerging issues very well. In of the appendix, we provide a fewexamples of emerging topics found in Feb 2023 and our validation results, and most of the topicsalign well with the news sources.",
  "Conclusion": "In summary, we have presented a unique machine learning framework for extracting customerstrending and emerging issues. Our work starts with an attention-based deep learning model that tagscustomers primary questions and generates corresponding sentence embeddings simultaneously.We then transform the sentence embeddings into an isotropic coordinate system using whiteningtechniques to improve the cosine similarity performance. Finally, we apply topological naturallanguage analysis methods to analyze the centrality of each question, enabling us to identify trendingand emerging issues. Our work makes a significant contribution by demonstrating the application of a sentence-levelattention mechanism in conversational transcripts, an area that has been understudied. We combinethis mechanism with topological data analysis to extract useful information for a real-world problem. Collobert, R. and Weston, J. (2008). A unified architecture for natural language processing: deepneural networks with multitask learning. ICML 08: Proceedings of the 25th international con-ference on Machine learning, 81:160167.",
  "Novak, P., Neumann, P., and Macas, J. (2010).Graph-based clustering and characterization ofrepetitive sequences in next-generation sequencing data. BMC Bioinformatics, 11:378": "Pennington, J., Socher, R., and Manning, C. (2014). Glove: Global vectors for word representa-tion. Proceedings of the 2014 Conference on Empirical Methods in Natural Language Processing(EMNLP), page 15321543. Reimers, N. and Gurevych, I. (2019).Sentencebert: Sentence embeddings using siamese bert-networks.Proceedings of the 2019 Conference on Empirical Methods in Natural LanguageProcessing and the 9th International Joint Conference on Natural Language Processing, page39823992.",
  "My daughter accidentally broke the screenof her tablet for kids. I was wondering if itspossible to file a claim to have it repaired": "Additionally, Im experiencing difficultiesaccessing my childs page on the Tablet.While my information loads successfully, Ikeep encountering an error message sayingoops, something went wrong when Kidsprofile begins to load. : In our analysis of Amazon Fire Tablets top-1 trending and emerging clusters in Feb 2023,we found that customers reported cracked screens as a trending issue and sought warranty replace-ments or repairs, while problems with the kids profile emerged as an emerging issue. The similarityamong sentences in the trending and emerging topics extracted from the same cluster suggests theeffectiveness of our method.",
  "We checked AmazonsDigital & Device Forumand confirmed that thisissue has been widelydiscussed,andAma-zons engineering teamhas addressed it in thenext update": ": The table presents a selection of emerging issues identified in February 2023, categorizedby product line. The first column displays the corresponding question sentences that represent thecluster center node. In the second column, we summarize the topic of each cluster. The third columnshows the evidence that confirms these issues as emerging. It is noteworthy that the majority of theseemerging issues are consistent with various online news sources."
}