{
  "ABSTRACT": "In the digital era, the widespread use of APIs is evident. However,scalable utilization of APIs poses a challenge due to structure di-vergence observed in online API documentation. This underscoresthe need for automatic tools to facilitate API consumption. A viableapproach involves the conversion of documentation into an APISpecification format. While previous attempts have been made usingrule-based methods, these approaches encountered difficulties in gen-eralizing across diverse documentation. In this paper we introduceSpeCrawler, a comprehensive system that utilizes large languagemodels (LLMs) to generate OpenAPI Specifications from diverseAPI documentation through a carefully crafted pipeline. By creatinga standardized format for numerous APIs, SpeCrawler aids in stream-lining integration processes within API orchestrating systems andfacilitating the incorporation of tools into LLMs. The paper exploresSpeCrawlers methodology, supported by empirical evidence andcase studies, demonstrating its efficacy through LLM capabilities.",
  "*Both authors contributed equally to this research": "Permission to make digital or hard copies of all or part of this work for personal orclassroom use is granted without fee provided that copies are not made or distributedfor profit or commercial advantage and that copies bear this notice and the full citationon the first page. Copyrights for components of this work owned by others than theauthor(s) must be honored. Abstracting with credit is permitted. To copy otherwise, orrepublish, to post on servers or to redistribute to lists, requires prior specific permissionand/or a fee. Request permissions from acronym XX, June 0305, 2018, Woodstock, NY 2018 Copyright held by the owner/author(s). Publication rights licensed to ACM.ACM ISBN 978-1-4503-XXXX-X/18/06 ACM Reference Format:Koren Lazar, Matan Vetzler, Guy Uziel, David Boaz, Esther Goldbraich,David Amid, and Ateret Anaby-Tavor. 2018. SpeCrawler: Generating Ope-nAPI Specifications from API Documentation Using Large Language Models.In Proceedings of Make sure to enter the correct conference title from yourrights confirmation emai (Conference acronym XX). ACM, New York, NY,USA, 10 pages.",
  "INTRODUCTION": "In todays digital realm, APIs are crucial in facilitating smooth com-munication among varied software applications, fostering integrationand interoperability. With the increasing number of APIs and theirresources, standardizing their usage becomes paramount.The OpenAPI Specification (OAS) 1 functions as a standardizedstructure for outlining RESTful APIs. Typically rendered in YAMLor JSON formats, it meticulously outlines endpoints, request config-urations, and authentication mechanisms in a machine-readable way.This helps developers to understand and interact with APIs moreeffectively. By establishing a common language for API description,OAS promotes interoperability, facilitates automated testing andvalidation of API implementations, and encourages collaborationamong developers, ensuring consistency in conveying API function-alities and protocols. OAS has gained significance in guaranteeingprecision and uniformity in the documentation of RESTful APIs,making it widely adopted by the industry. Incorporating the OASframework boosts effectiveness, reduces mistakes, and cultivatesuniformity across API development and integration phases. You canobserve a representation of the OAS schema structure in .Despite its significance, crafting OASs remains a manual andlabor-intensive effort, prompting an investigation into more stream-lined and automated alternatives.Various approaches have been proposed aiming to automaticallyparse API documentation to create OASs through rule-base ap-proaches , some also integrating classic machine learningtechniques . Unfortunately, these approaches have faced",
  "Conference acronym XX, June 0305, 2018, Woodstock, NYLazar and Vetzler, et al": "Finally, we incorporated the generated structure into the base OASin a rule-based fashion. This integration prioritizes the descriptionand required parameter fields from the generated enrichment, whilegiving precedence to the type and location fields from the base OAS.The basis for this prioritization lies in the types of documentationused as input for generating the two components.",
  "SpeCrawler: Generating OpenAPI Specifications from API DocumentationConference acronym XX, June 0305, 2018, Woodstock, NY": ": Labeled data - This figure provides a visual representation of input-output pairs from the enrichment generation stage,sourced from PayPal Developer and Amplitude APIs. The top section displays examples of a request element, while the bottom sectiondisplays a response element example. On the left side of the figure, youll find input sources, which consist of scraped raw HTMLscopes from API documentation websites. On the right side, the results of the enrichment generation process are presented. For requestelements, the results are formatted as a TSV table, while for response elements, they are showcased as a response OpenAPI schemanested object. Enriching the base OAS outlined in the preceding section withreference-base documentation is imperative because the example-style documentation lacks much of the information found in reference-based documentation.Employing deterministic rule-based algorithms to accurately parseof these documentations is impractical due to the substantial differ-ences in HTML structures across various websites . For example,in a preliminary experiment, we tried to parse HTML parameter ta-bles with pandas read_html function2, yet it repeatedly failed tocorrectly identify the columns and rows of the table. Therefore,turning to LLMs emerges as a viable solution, given their ability togeneralize over such structural differences. Nevertheless, it is im-portant to recognize that LLMs possess constraints in terms of theircontext length. Consequently, filtering the documentation becomesimperative prior to the utilization of the LLM.Therefore, we developed an algorithm to automatically find theessential HTML elements from the API documentation webpage thatencapsulate the crucial information needed for enhancing the baseOAS. Since the HTML structure of API documentation websitesmay vary significantly, the algorithm mainly relies on semanticsignals rather than specific HTML syntax or structure. After findingthe minimal scope, we further preprocess and filter it to optimizethe signal-to-noise ratio. We explain the algorithm thoroughly inAppendix A.1. Having obtained the processed minimal ancestor, we employ anLLM to generate structured data for enhancing the base OAS. TheLLM is directed to produce a TSV table for the request and an Ope-nAPI response schema for the response. We chose the TSV formatfor the request, as documentation for request parameters typicallylacks a hierarchical structure compared to response documentation.Examples of the inputs and outputs of both enrichments are providedin . For each parameter, the model is instructed to gener-ate the name, type (e.g., string), whether the parameter is required,and a description if present. For request parameters specifically, weadditionally prompt the model to generate the location (e.g., query,body). Opting for in-context learning (ICL) during LLM generationwas our preference, as it eliminates the need for extensive labeling,such as in supervised fine-tuning. To that end, we manually labeled15 examples from different websites. From these, we selected 3 in-context examples for each input by computing the cosine similarityof the HTML tags frequency distributions between each exampleand the given input for prediction 3. The selection of HTML tagfrequency distributions is motivated by their ability to approximatethe similarity in HTML structures, thereby offering the LLM parsingexamples that closely resemble those it is tasked with performing. Arepresentative prompt example is elucidated in Appendix A.2. Fol-lowing the data generation, we validated the structure of the outputdata (TSV/JSON) and removed any hallucinations by verifying ifthe parameter names explicitly appeared in the input.",
  "OPENAPIS AND DOCUMENTATIONWEBSITES": "The OpenAPI Specification (OAS) is a widely adopted standard inthe realm of API development, offering a formalized structure fordescribing RESTful APIs. It not only delineates the architecture ofAPIs but also establishes a comprehensive set of rules governingthe definition of API endpoints, request and response parameters,and overall functionality. Furthermore, the use of OAS streamlinesthe development process by facilitating the automatic generationof client libraries and server-side code, fostering consistency andinteroperability across diverse programming environments. illustrates an OAS hierarchy.Manually creating an OAS requires a lot of human expert effortand meticulous attention to detail, particularly when dealing with awide range of API documentation formats and sources. Moreover,developers frequently encounter challenges in the creation and up-keep of OAS, leading to potential discrepancies between the APIs deployed in production and their intended specifications .Therefore, automating this process is essential. Yet, it poses varioussignificant challenges. The majority of web API documentationsdo not follow a machine-readable convention . Furthermore, thestructural diversity, varied formats, and scattered components acrossdocumentation hinder the development of a comprehensive and auto-mated OAS generation solution . Key API components might bescattered throughout the documentation, requiring intelligent extrac-tion. Additionally, critical information may be absent or fragmented,hindering a comprehensive and accurate transformation into OAS.The linguistic variation in the documentation adds complexity to theinterpretation and standardization process, while diverse organiza-tional structures within API documentation demand adaptability inthe transformation process.",
  "SPECRAWLER": "In this section, we present SpeCrawler, a new system designed to au-tonomously create OpenAPI Specifications from API documentationwebsites. First, we describe the initial scraping stage in .1,where we identify all API request and response example pairs from adocumentation page. This stage provides the necessary componentsfor the subsequent two stages. Second, in .2, we discussthe process of employing a generative LLM to create a base OASgiven the request and response example pairs. Lastly, in .3,we explain how we extract relevant descriptions about the API pa-rameters and generate structured data for enriching the base OAS. illustrates the different stages of developing the SpeCrawlersystem.",
  "Scraping": "The first step in scraping the API documentation page involvesretrieving example-style documentations, which consist of usageexamples demonstrating the requests and responses of the APIsdocumented. An illustration of an example-style documentation isdepicted on the right side of . To identify and extract thespecified elements, we developed a scraper that searches for HTMLelements within the webpage containing example-style componentslike cURL commands and JSON responses, following predefinedrules and patterns. Since some HTML elements are loaded dynam-ically, the scraper also navigates through the documentation page, activating various buttons using heuristic techniques to fetch suchrelevant elements during runtime.After identifying and extracting the relevant components, we aimto align between the different request and response elements, asthese pages may contain multiple APIs. For this purpose, we utilizethe HTML structure of the webpage to apply a heuristic that navi-gates the HTML DOM Tree to locate the nearest available responsecorresponding to a given request example. Upon completing thisprocess, we possess a comprehensive list of all APIs represented aspairs of request and response examples.",
  "Base OAS Generation": "In this section we analyzed the syntactic properties of automaticallygenerating base OASs using LLMs given a corpus of 49 documen-tation pages, collectively encompassing approximately 189 end-points. We chose several renowned LLMs for our experiment, whichexhibited in-context prompting capabilities: llama2-70b-chat ,codellama-34b-instruct , mistral-7b-instruct , mixtral-8x7b-instruct and IBMs Granite model4. Granite is part of IBM Gen-erative AI Large Language Foundation Models, which are Enterprise-level English-language models trained with large a volume of datathat has been subjected to intensive pre-processing and careful anal-ysis. We utilized the Granite model, along with the other LLMs, alsoin Sections 4.2, 4.3.The syntactic evaluation was centered on three key measures: (1)whether the generated output conforms to the JSON syntax stan-dards; (2) whether the generated output conforms to the OAS format;(3) average number of warnings in the generated valid JSONs. Warn-ings appear in scenarios where the generated specification is a validJSON but fails to meet the criteria of a valid OAS. These warningssignify potential inconsistencies or deviations from the OAS stan-dard. The average number of warnings per case was calculated toprovide insights into the degree of syntactic divergence from thestandard. We evaluated the last two measures using the jsochemalibrary, a widely-used tool for validating OpenAPI and JSON speci-fications 5.The findings derived from the syntactic analysis are outlined in. Notably, the Granite and Code Llama models emerge asthe top-performing models. It is noteworthy that while Code Llamaattained the highest proportion of valid OpenAPI Specifications(OAS), its warnings ratio ranked third when compared to the othermodels. Conversely, the Granite model secured the second positionin the ratio of valid OAS but demonstrated the lowest incidence ofwarnings in the valid JSON outputs. Apart from these two models,the remaining models generally succeeded in producing valid JSONsin the majority of cases. However, their rates of generating validOAS were notably low and exhibited significant variability. Hence,it can be inferred that even when decomposing the OAS generationinto subtasks, it remains a nontrivial challenge for LLMs.",
  "EXPERIMENTS": "In this section we present the results of a series of experimentsconducted to evaluate the performance of SpeCrawler. Specifically,we compare the performance of various LLMs on the task of a baseOAS generation, followed by an examination of their performanceon the task of OAS enrichment given request and response examples.Finally, we conduct an end-to-end evaluation of SpeCrawler andcompare its performance to that of other approaches and models.",
  "Enrichment Generation": "In order to assess the efficacy of the enrichment generation in iso-lation, we carried out a constrained leave-one-out cross-validationtrial. Here, 1 manually labeled examples served as potentialin-context instances from which we choose 3 in-context examples,while one example was set aside for testing purposes. A short promptexample is provided in Appendix A.2. We tagged a total of = 15challenging examples from different API documentation websites.We devised and experimented with different generation prompts,and the formulation that underwent testing and usage was optimizedthrough the falcon-40b model . First, we assessed the modelscapability to accurately extract the parameter names of the API usingthe F1 score, which accounts for both hallucinations and deficienciesin recall abilities. Next, we assessed the precision scores associ-ated with the parameter fields: \"required,\" \"type,\" and \"location,\"ensuring that the model extracted and generated them accurately,as occasionally the model may omit or hallucinate different valuesin these fields. For evaluating the extraction and generation of the\"description\" field, we utilized cosine similarity between the ground-truth description and the generated one. This approach is preferredover an exact-match style score, as it might be overly stringent. Forinputs for the LLM, we took manually-crafted HTML scopes. compares several LLMs on the aforementioned metricsin both request and response enrichment separately. We note severalinteresting observations based on these results. LLMs successfullyretrieved a majority of the parameter names. The LLMs achieveda high F1 score in both request and response enrichments, therebyshowcasing the capability of such models to generalize across diverseHTML structures.Response enrichment is harder. The scores of the response enrich-ment are lower on average, except for the type precision. This canbe explained by several factors. First, the response object is oftenhighly-nested which is harder to generate compared to the flat TSVstructure of the request enrichment. Second, the information aboutthe required fields has to be generated as a separate list for eachscope for the response. Third, the response often has no enrichmentwhich may lead to hallucinations. This stands in contrast to requestparameters, which tend to consistently appear and vary among APIs.The exceptional type precision is higher for the response possiblydue to its versatility or absence in reference-based documentation ofthe request.Output format matters for the model. Several models demon-strated significantly enhanced performance in one type of enrichmenttype compared to the other, suggesting the importance of customiz-ing the output format to suit individual models. For instance, Code",
  "End-to-End Testing": "In this section, our emphasis lies in assessing the overall capabilitiesof the SpeCrawler system. We conducted experiments to comparethe systems performance while using different generative LLMs. Tothat end, we employed a manually curated dataset comprising 30 APIdocumentation pages, each linked to a corresponding ground-truthOAS. The dataset encompasses approximately one hundred API end-points. In each experiment we used the in-context learning approachwith the same prompt and the same three in-context examples. Eachgenerated specification was compared against the ground-truth OAS.Therefore, for the system to perfectly match the ground-truth OAS,it needs to retrieve precisely all the parameters in the request, evenif they do not appear in the example-style documentation, i.e. in therequest or response usage examples. The outcomes are detailed in, which displays metrics such as Precision (P), Recall (R), F1score (F1), and cosine similarity (Sim) for both request and responseaspects, with and without enrichment, as discussed in .3.The results presented in illustrate the systems perfor-mance under various conditions, taking into account the inclusionor exclusion of the enrichment component. Firstly, activating theenrichment component results in a notable improvement in preci-sion, recall, and F1 scores for both request and response components.Nevertheless, the improvement in the similarity metric fluctuatesdepending on the choice of the base model; for example, employingIBMs Granite model results in a 4-point increase. This observationcan be attributed to the propensity of LLMs to generate descriptionsfor parameters even in the absence of such descriptions in the inputduring the enrichment generation stage. Secondly, when comparedto the results presented in Sections 4.1 and 4.2, which evaluated theperformance of particular generation components, the models exhibitsignificantly lower performance in this context. This emphasizesthe intricacy of the task and underscores the continued necessityfor improvements in rule-based components such as scraping anddetermining the minimal HTML scope for enrichment. Thirdly, uponscrutinizing the dataset, we identified various instances of noise inthe annotation, suggesting that some of the performance degrada-tion can be attributed to this factor as well. Finally, it is noteworthy that IBMs Granite demonstrated commendable outcomes acrossvarious metrics, achieving the best performance overall, particu-larly excelling in precision and recall of parameter names. Thisobservation is somewhat unexpected, given the prominence of itscompetitors, and that neither the prompts nor the hyperparameterswere customized for this model.",
  "Comparing Against LLM-Based Solutions": "In this series of experiments, we conducted a comparative analysisamong three potential solutions for OAS generation from online doc-umentation pages: GPT4-Turbo, OpenAIs latest-generation modelincorporating a 128k context window, ActionGPT, a solution pro-posed by OpenAI for generating documentation from URLs, and ourSpeCrawler system with IBMs Granite generative LLM, which wasintroduced in .1. We did not compare against rule-basedapproaches as we were unable to locate existing comparable resultsfor such methods.The evaluation involved generating an OAS from 10 manuallypicked challenging documentation URLs. While some pages con-tained multiple endpoints, the assessment focused on a single spe-cific selected endpoint. Precision and recall scores were measuredin terms of the OAS parameter names generated by each approach,along with three metrics introduced in .1 that measure thestructural validity of the generated outputs.The evaluation results are presented in . Firstly, SpeCrawlerdemonstrated the best performance across all metrics compared tothe other solutions. Since the Granite model was not fine-tuned oraligned to this specific task, we attribute SpeCrawlers main advan-tage to its carefully designed pipeline, which effectively decomposesthis challenging task into more manageable subtasks. Secondly,GPT4-Turbo exhibited lower performance across all metrics, witha precision score of 0.18, recall score of 0.05, and valid OAS ratioof 0.4. These results can be ascribed to the HTML content of sixURLs being excessively lengthy, exceeding the substantial contextwindow capacity of GPT4-Turbo. This underscores the limitation ofa simplistic approach in addressing the task across diverse websites,emphasizing the necessity of a more sophisticated strategy, suchas our scraper and enrichment algorithms, to focus the model onrelevant contexts, in small bites. Finally, with regard to warnings, allthree models did not exhibit any warnings in their generated validJSONs, indicating a proficient understanding of the desired schemastructure.",
  "RELATED WORK": "Historically, varied methods have been adopted to generate OASsfrom API documentation. AutoREST generates an OAS by find-ing all relevant linked HTML documentation pages within the samedomain as the root page of the REST API documentation. The OASis then generated based on information extracted through a set offixed rules. D2Spec aims to extract base URLs, path templates,and HTTP method types, using rule-based web crawling techniquesand classic machine learning to identify potential API call patternsin URLs. It also analyzes URL paths hierarchically to identify andgroup path parameters. Respector employs static and symbolicprogram analysis to automatically generate OAS for REST APIsfrom their implementations. SpyREST employs an HTTP proxyserver to intercept HTTP traffic to generate API documentation.Bahrami et al. , Bahrami and Chen combines rule-based andmachine-learning algorithms to generate OAS from API documen-tation. They also develop a deep model to pinpoint fine-grainedmapping of extracted API attributes to OAS objects. WATAPI takes a different approach by adding a user as a human-in-the-loopto interact transparently with complex machine-learning componentsto compose an OAS. SpeCrawler system presents a novel and unifiedapproach by leveraging LLMs to automate the generation process di-rectly from raw HTML content, enabling a more robust and accuratesolution across diverse API documentation structures without being bound to specific patterns and custom mechanisms. Most similar toour work, Androcec and Tomaic used GPT-3 to automaticallygenerate OAS from a preprocessed HTML file describing an APIdocumentation. SpeCrawler distinguishes itself from their method-ology through two key strategies: (1) dividing the generation taskinto multiple parts, and (2) extracting relevant information fromwebpages, thus accommodating webpages that exceeds the contextsize constraint of GPT-3 and those featuring multiple operations.",
  "CONCLUSIONS": "This paper introduces SpeCrawler, an innovative multi-stage method-ology designed to automatically generate comprehensive OAS fromonline API documentation. Combining rule-based algorithms andgenerative LLMs, SpeCrawler addresses existing limitations asso-ciated with LLMs while showcasing robustness and generalizationcapabilities across varied HTML structures in API documentation.The effectiveness of SpeCrawler is demonstrated through satisfac-tory results across a diverse list of API documentation websites.Therefore, it significantly reduces the manual efforts required bytechnical experts in crafting OAS manually.Potential routes for future research include enhancing the extrac-tion of elements utilized for enriching both the request and responseelements by enabling multiple HTML scopes as input to the genera-tive model and aggregating their product. Additionally, there is roomfor improvement in the scraping process by gathering more relevantinformation from associated links within the documentation. Furtherexploration could involve investigating various strategies for split-ting the generation process, such as consolidating generations forthe request and the response elements separately. Another possibledirection is enlarging the existing resources to a large-scale datasetto constitute a benchmark for this task.",
  "AAPPENDIXA.1Find Minimal Ancestor Algorithm": "To determine the appropriate HTML scope for enrichment given arequest example, we employed two distinct approaches. In scenarioswhere a webpage incorporates multiple API calls, we defined thescope as the highest ancestor of the request example HTML elementthat does not encompass other requests 6. In , this scopeshould encompass both reference-based and example-style sections.Conversely, when dealing with a webpage containing a single APIcall, we conducted a search for leaf elements.7 likely associatedwith parameters in the reference-based documentation based on theirtext, such as parameters from the request or response, and parameterheader templates. These elements could be situated, for instance,in the Parameters Description section as illustrated in .Subsequently, we iterated through the ancestors of each identifiedelement, starting from the immediate parent and moving upwards,in search of the first ancestor containing a matching URL endpointcorresponding to the provided API URL. Since this is often foundpreceding the HTTP method (e.g. GET /info/id), we denote it asHTTP Method and Endpoint/URL in .After retrieving these minimal ancestors, we rank them accordingto two criteria: 1) the number of parameters from the request orresponse found as leaf elements in the ancestor, and 2) whether theHTTP method type of the URL was found as a leaf element. Follow-ing this ranking, we filter out HTML elements that are ancestors ofother candidates. Lastly, if we still have multiple candidates sharingthe same rank, we randomly sample one of them, although we didnot encounter such cases in our experiments.The minimal ancestor is then preprocessed to remove noise andtailor it to the constrained context size of the LLM. This involvesfiltering out its children that are less likely to contain relevant infor-mation for augmenting the base OAS. Specifically, we search forparameter names extracted from the API request/response exampleand syntactic hints such as the structure of an HTML parameterstable. Additionally, we exclude the request and response examples atthis stage, as they have already been utilized in generating the baseOAS. Finally, all HTML attributes are removed, as they are deemedless likely to contain relevant information.",
  "A.2Prompt Generation ExamplesREFERENCES": "Ebtesam Almazrouei, Hamza Alobeidli, Abdulaziz Alshamsi, Alessandro Cappelli,Ruxandra Cojocaru, Merouane Debbah, Etienne Goffinet, Daniel Heslow, JulienLaunay, Quentin Malartic, Badreddine Noune, Baptiste Pannier, and GuilhermePenedo. 2023. Falcon-40B: an open large language model with state-of-the-artperformance. (2023). Darko Androcec and Matija Tomaic. 2023. Using GPT-3 to AutomaticallyCreate RESTful Service Descriptions. In 2023 4th International Conference onCommunications, Information, Electronic and Energy Systems (CIEES). IEEE,14. Mehdi Bahrami, Mehdi Assefi, Ian Thomas, Wei-Peng Chen, Shridhar Choudhary,and Hamid R Arabnia. 2020. Deep sas: A deep signature-based api specificationlearning approach. In 2020 IEEE International Conference on Systems, Man, andCybernetics (SMC). IEEE, 19942001.",
  "tool. In 2019 IEEE International Conference on Big Data (Big Data). IEEE,45734578": "Mehdi Bahrami and Wei-Peng Chen. 2020. Automated web service specificationgeneration through a transformation-based learning. In Services ComputingSCC2020: 17th International Conference, Held as Part of the Services ConferenceFederation, SCF 2020, Honolulu, HI, USA, September 1820, 2020, Proceedings17. Springer, 103119. Hanyang Cao, Jean-Rmy Falleri, and Xavier Blanc. 2017. Automated generationof REST API specification from plain HTML documentation. In Service-OrientedComputing: 15th International Conference, ICSOC 2017, Malaga, Spain, Novem-ber 1316, 2017, Proceedings. Springer, 453461.",
  "Ruikai Huang, Manish Motwani, Idel Martinez, and Alessandro Orso. 2024.Generating REST API Specifications through Static Analysis. (2024)": "Albert Q. Jiang, Alexandre Sablayrolles, Arthur Mensch, Chris Bamford, De-vendra Singh Chaplot, Diego de las Casas, Florian Bressand, Gianna Lengyel,Guillaume Lample, Lucile Saulnier, Llio Renard Lavaud, Marie-Anne Lachaux,Pierre Stock, Teven Le Scao, Thibaut Lavril, Thomas Wang, Timothe Lacroix,and William El Sayed. 2023. Mistral 7B. arXiv:2310.06825 [cs.CL] Albert Q. Jiang, Alexandre Sablayrolles, Antoine Roux, Arthur Mensch, BlancheSavary, Chris Bamford, Devendra Singh Chaplot, Diego de las Casas, Emma BouHanna, Florian Bressand, Gianna Lengyel, Guillaume Bour, Guillaume Lam-ple, Llio Renard Lavaud, Lucile Saulnier, Marie-Anne Lachaux, Pierre Stock,Sandeep Subramanian, Sophia Yang, Szymon Antoniak, Teven Le Scao, ThophileGervet, Thibaut Lavril, Thomas Wang, Timothe Lacroix, and William El Sayed.2024. Mixtral of Experts. arXiv:2401.04088 [cs.LG] Myeongsoo Kim, Qi Xin, Saurabh Sinha, and Alessandro Orso. 2022. Automatedtest generation for REST APIs: no time to rest yet. In Proceedings of the 31st ACMSIGSOFT International Symposium on Software Testing and Analysis (, Virtual,South Korea,) (ISSTA 2022). Association for Computing Machinery, New York,NY, USA, 289301. Alberto Martin-Lopez, Andrea Arcuri, Sergio Segura, and Antonio Ruiz-Corts.2021. Black-box and white-box test case generation for RESTful APIs: Enemiesor allies?. In 2021 IEEE 32nd International Symposium on Software ReliabilityEngineering (ISSRE). IEEE, 231241. Alberto Martin-Lopez, Sergio Segura, and Antonio Ruiz-Corts. 2022. Onlinetesting of RESTful APIs: Promises and challenges. In Proceedings of the 30thACM Joint European Software Engineering Conference and Symposium on theFoundations of Software Engineering. 408420. Baptiste Rozire, Jonas Gehring, Fabian Gloeckle, Sten Sootla, Itai Gat, Xiao-qing Ellen Tan, Yossi Adi, Jingyu Liu, Romain Sauvestre, Tal Remez, JrmyRapin, Artyom Kozhevnikov, Ivan Evtimov, Joanna Bitton, Manish Bhatt, Cris-tian Canton Ferrer, Aaron Grattafiori, Wenhan Xiong, Alexandre Dfossez, JadeCopet, Faisal Azhar, Hugo Touvron, Louis Martin, Nicolas Usunier, ThomasScialom, and Gabriel Synnaeve. 2024. Code Llama: Open Foundation Models forCode. arXiv:2308.12950 [cs.CL] Sheikh Mohammed Sohan, Craig Anslow, and Frank Maurer. 2015. Spyrest:Automated restful API documentation using an HTTP proxy server (N). In 201530th IEEE/ACM International Conference on Automated Software Engineering(ASE). IEEE, 271276. Hugo Touvron, Louis Martin, Kevin Stone, Peter Albert, Amjad Almahairi, Yas-mine Babaei, Nikolay Bashlykov, Soumya Batra, Prajjwal Bhargava, Shruti Bhos-ale, Dan Bikel, Lukas Blecher, Cristian Canton Ferrer, Moya Chen, GuillemCucurull, David Esiobu, Jude Fernandes, Jeremy Fu, Wenyin Fu, Brian Fuller,Cynthia Gao, Vedanuj Goswami, Naman Goyal, Anthony Hartshorn, Saghar Hos-seini, Rui Hou, Hakan Inan, Marcin Kardas, Viktor Kerkez, Madian Khabsa, IsabelKloumann, Artem Korenev, Punit Singh Koura, Marie-Anne Lachaux, ThibautLavril, Jenya Lee, Diana Liskovich, Yinghai Lu, Yuning Mao, Xavier Martinet,Todor Mihaylov, Pushkar Mishra, Igor Molybog, Yixin Nie, Andrew Poulton,Jeremy Reizenstein, Rashi Rungta, Kalyan Saladi, Alan Schelten, Ruan Silva,Eric Michael Smith, Ranjan Subramanian, Xiaoqing Ellen Tan, Binh Tang, RossTaylor, Adina Williams, Jian Xiang Kuan, Puxin Xu, Zheng Yan, Iliyan Zarov,Yuchen Zhang, Angela Fan, Melanie Kambadur, Sharan Narang, Aurelien Ro-driguez, Robert Stojnic, Sergey Edunov, and Thomas Scialom. 2023. Llama 2:Open Foundation and Fine-Tuned Chat Models. arXiv:2307.09288 [cs.CL]"
}