{
  "ABSTRACT": "Large language models (LLMs) have fueled many intelligent webagents, but most existing ones perform far from satisfying in real-world web navigation tasks due to three factors: (1) the complexityof HTML text data (2) versatility of actions on webpages, and (3)task difficulty due to the open-domain nature of the web. In lightof these challenges, we develop the open AutoWebGLM basedon ChatGLM3-6B. AutoWebGLM can serve as a powerful auto-mated web navigation agent that outperform GPT-4. Inspired byhuman browsing patterns, we first design an HTML simplificationalgorithm to represent webpages with vital information preservedsuccinctly. We then employ a hybrid human-AI method to build webbrowsing data for curriculum training. Finally, we bootstrap themodel by reinforcement learning and rejection sampling to furtherfacilitate webpage comprehension, browser operations, and efficienttask decomposition by itself. For comprehensive evaluation, weestablish a bilingual benchmarkAutoWebBenchfor real-worldweb navigation tasks. We evaluate AutoWebGLM across diverseweb navigation benchmarks, demonstrating its potential to tacklechallenging tasks in real environments. Related code, model, anddata are released at",
  "ChatGLM, Large Language Model, LLM Agent, Web Agent, Rein-forcement Learning, Rejection Sampling Finetuning": "ACM Reference Format:Hanyu Lai, Xiao Liu, Iat Long Iong, Shuntian Yao, Yuxuan Chen, PengboShen, Hao Yu, Hanchen Zhang, Xiaohan Zhang, Yuxiao Dong, and Jie Tang.2024. AutoWebGLM: A Large Language Model-based Web Navigating Agent.In Proceedings of the 30th ACM SIGKDD Conference on Knowledge Discoveryand Data Mining (KDD 24), August 2529, 2024, Barcelona, Spain. ACM, NewYork, NY, USA, 12 pages. 78.2 75.072.6 69.3 70.493.5 WebArena AutoWebBench(EN)Cross-Task (Mind2Web) Cross-Website (Mind2Web) Cross-Domain (Mind2Web)MiniWob++ GPT-3.5-Turbo (in-context)GPT-4 (in-context)LLaMA2-70BAutoWebGLMHuman",
  ": Examples of AutoWebGLMs execution on four user tasks": "and response capabilities , we can envision variousscenarios previously unimaginable. For instance, an LLM-basedagent could support a daily routine that summarizes the onlinenews from the open web for us. This integration of LLMs intoeveryday tasks heralds a significant shift in how we interact withmachines, optimizing our efficiency and redefining the boundariesof machine-assisted productivity .Tremendous efforts have been underway to construct auto webagents. One is AutoGPT, a popular open-source project that utilizesChatGPT to integrate LLMs with predetermined tools suchas web and local file browsing. Meanwhile, the development ofagent-centric LLMs has gained significant momentum . Nevertheless, the majority of existing web agents are to dateseverely restricted in terms of practical applications, predominantlydue to the following challenges: A universal action space covering all necessary task executionsacross various websites is absent.",
  "The diversity and complexity of webpages and their tendentiousverbosity pose a significant challenge for LLMs to comprehendthe content and carry out correct operations accurately": "Existing agents notably lack the capability for correct inferenceand self-checking on web tasks. Once caught in an erroneousloop, they struggle to rectify the issue promptly.In this work, we introduce AutoWebGLM for building web-page navigation agents. It is built upon the open ChatGLM3-6Bmodel . First, we propose various efficient data strategies tosupport the swift construction of a sizeable, reliable training dataset while state-of-the-art models cannot reliably complete data anno-tation tasks . Furthermore, by leveraging supervised andreinforcement learning methods , we train AutoWebGLM ontop of the collected web agent dataset to achieve performance su-periority on general webpage browsing tasks. A step further, weemploy rejection sampling finetuning (RFT) for lifelong learn-ing in specific web environments, enabling the agent to excel in aparticular domain.We develop and deploy a Chrome extension based on AutoWe-bGLM (See for examples). Throughout our experiments,it can reason and perform operations on various websites to com-plete user tasks accurately, making it practically applicable to real-world services. In addition, we construct the first bilingual (Englishand Chinese) webpage browsing evaluation dataset to build Au-toWebBench, given that websites from different regions have sub-stantial stylistic variations. In conclusion, we make the followingcontributions in this paper: We design and develop the AutoWebGLM agent for effectivelycompleting web browsing tasks through curriculum learning,bootstrapped by self-sampling reinforcement learning, and RFTin the web browsing environment. We construct a real webpage browsing operation dataset of ap-proximately 10,000 traces using model-assisted and manual meth-ods, including the bilingual (English and Chinese) web browsingbenchmark AutoWebBench.",
  "RELATED WORK": "Constructing a comprehensive web browsing agent is a complextask that involves various modules, such as a language model fordecision-making and an HTML parser for environment observa-tion. Furthermore, it is essential to have appropriate web browsingevaluation criteria when creating an effective web browsing agent.In this section, we will discuss the works related to these aspects. Language Models (LMs). Large language models (LLMs) ,such as GPT-4 , Claude-2 , LLaMA-2 , ChatGLM ,OPT , and BLOOM , have accumulated extensive knowl-edge in various natural language processing tasks. However, dueto the high cost of deploying such large language models, smallermodels with lower costs and comparable capabilities are usuallypreferred. Many open-source projects, such as LLaMA-2-7B and ChatGLM3-6B , have demonstrated strong performance tolarge language models in some domains. Benchmarks for Web Navigation. The primary web browsingevaluation datasets provide a variety of evaluation metrics. Mini-WoB++ provides several simulated web environments, withtasks primarily to evaluate the models ability to interact with web-page components. However, with the increasing demand for com-plex web operation capabilities, Mind2Web and WebArena have been created. Mind2Web is an offline evaluation set for com-plex web browsing that provides several metrics. The evaluationmethod is straightforward and commonly used for model evalua-tions. In contrast, the WebArena benchmark, based on real websites,creates multiple virtual environments and uses various evaluationmethods to assess the task completion rate, making it more suitablefor real-world task completion evaluation. Agents for Web Automation. Previous work such as WebGPT and WebGLM combined LLMs with web environments. How-ever, their primary application was question-answering (QA) tasks , utilizing internet resources to answer user queries. Re-cent works focus more on executing complex opera-tions or interactive tasks. A fundamental aspect of web browsingtasks involves a comprehensive understanding of HTML. Struct-GPT explores methodologies to enhance the zero-shot rea-soning ability of LLMs in handling structured data. Specifically,MindAct works by filtering webpage elements and selectingthe element through multiple rounds of multiple-choice questions.It often requires more than ten model calls to complete a singleweb operation, which could be more efficient. On the other hand,WebAgent uses HTML-T5 to process the observation spaces con-tent, including HTML, previous operations, and user instructions.It uses the Flan-U-Plam model to generate code to control web-pages, exhibiting excellent web browsing performance. However,it faces deployment challenges due to the size of the Flan-U-Plammodel, which is 540B scale. AutoWebGLM, based solely on a singleChatGLM3-6B, has a robust web browsing capability comparableto WebAgent, demonstrating high value for practical deployment.",
  "Prompt-based Data Construction Methods. Constructing datathrough prompts has recently gained significant traction [5, 11, 20,": "25, 35]. This approach leverages language models to generate syn-thetic data for training. A notable example is Evol-Instruct ,inspired by the theory of evolution, demonstrating the effectivenessof using LLMs to generate diverse and complex instructions forvarious tasks. Additionally, some researchers explore the potentialof generating data in a zero-shot setting, where the model producesdata for tasks it has yet to be explicitly trained on , highlightingthe versatility of prompt-based data construction. These methodolo-gies rapidly evolve, offering a promising avenue for data generationin various domains, especially where traditional data collectionmethods could be more practical and sufficient.. Rejection Sampling Finetuning. The methodology of RejectionSampling Finetuning (RFT) employs a supervised learningmodel to generate and collect accurate reasoning paths, subse-quently utilized as an augmented finetuning dataset. Using RFT toexpand the dataset with diverse reasoning paths can boost the math-ematical performance of LLMs. Our experiments show that RFTcan also be effectively implemented in web page browsing tasks,significantly increasing professional capabilities within specificenvironments.",
  "= {HTML, URL, Window Position}, = {click, scroll, type, . . .}": "The states transition is determined by the webpages current stateand the agents output action. During the decision-making process,the function updates the historical information based on theprevious history 1, the most recent action 1, and the currentstate . = (1,1,)The policy is the process for the agent to choose actions basedon the current state and the history. A complete decision processstarts from the initial state 0 and history 0, iterating through thepolicy and transition function . This iteration ceases when theaction is finish or reaches the maximum length.",
  "The AutoWebGLM Framework": "As depicted in , we process information through HTMLsimplification and OCR (Optical Character Recognition) modules,yielding a simplified HTML representation after acquiring HTMLand webpage screenshots. With attributes facilitating operabilityjudgment, we mark operable elements for agent interaction. TheOCR module is for notating text elements during image parsing.Agents initiate action prediction by combining this represen-tation with other observational data. Upon outputting action, theautomated web program is employed for action execution; this",
  "Element Selector": ": The System Architecture of AutoWebGLM. Our system comprises two key components: interaction framework and LMagent. The LM agent learns from data procured from diverse sources. It further employs RL and RFT to bootstrap itself, thus enhancing webbrowsing capabilities. The interaction framework uses various web processing modules to organize concise HTML and other information forthe LM agent to make decisions that are then executed by an automated browsing program.",
  "user_input(message)Notify user to interactfinish(answer)Stop with answer": "iterative cycle persists until task termination. AutoWebGLM en-hances interactive capacity and webpage navigation precision byamalgamating these components into a singular framework.A comprehensive, precise observation and action space is vitalfor constructing a robust web browsing framework. These spacesstandardize the conversion of varied data sources into a uniformformat. We discuss our designs in the following: 3.2.1Observation space. We suggest using a unified observationspace to enhance the models webpage comprehension and oper-ation level. The observation space should provide information asclose as possible to what the browsers graphical interface can pro-vide, thus maximizing the upper bound of the agents capabilities.We identify four critical indicators for web browsing tasks: taskdescription, simplified HTML, current location, and past operationrecords. The HTML provides the model with structural and contentinformation about the page, while the current location informationhelps the model understand its position within the webpage. Therecord of past operations provides the model with historical context,which helps to generate more consistent subsequent operations.By incorporating these elements into the observation space, westrive to construct a more resilient and practical model that canhandle the intricacy and variability inherent in web browsing tasks.The following are detailed illustrations of the observation spacecomponents.",
  "end for": "HTML. The HTML webpages are vast and complex, so it is neces-sary to simplify them before inputting them into the model. Thesimplification process aims to extract essential information whileeliminating redundant or disruptive elements that could hinder themodels understanding. Throughout this process, the HTMLs basicstructure and significant content information must be retained toenable the model to comprehend and utilize this information foreffective web browsing. HTML Pruner can efficiently convert a treeof elements into a concise representation. We can use the process-ing techniques to streamline the original HTML format into a moreunderstandable structure for the model to interpret and manage,improving model effectiveness in web browsing tasks.",
  "AutoWebGLM: A Large Language Model-based Web Navigating AgentKDD 24, August 2529, 2024, Barcelona, Spain": "Current Position. Based on our observation of the models inter-action with the environment, agents could perform better whenprovided with window position and page size. The agent uses thepage scroll position to understand the content of the currently visi-ble area and the page height information to comprehend the scaleof the entire page, providing a spatial context for the model. Previous actions. The best solution to inform the agent of pastoperations is explicitly providing it. This approach helps the agentunderstand its past behaviors. It prevents the agent from gettingstuck in an ineffective loop of repeating the same actions due to op-erational failures, improving its ability to adapt to the complexitiesand dynamics of web browsing tasks by preventing the recurrenceof unsuccessful operations. 3.2.2Action space. As the approach of this work is to build alanguage model-based web browsing agent, we focus on operationalpossibilities when constructing the action space. On an extensivesummary of experiences in the real task execution process, wedefine a complete and self-consistent action space (in ) forthe language model to act in the web browsing world. We designour prompt input in Section B.",
  "BUILDING AUTOWEBGLM": "In this section, we detail the construction of a web browsing agent.Given the high costs associated with manual data construction andthe inadequacy of current LLMs for automated data generation,we employed a Human-AI hybrid data construction method toefficiently produce large volumes of training data at a reducedcost. Additionally, we implemented a multi-stage training approach,rather than relying solely on imitation learning, to enhance ourmodels general and specialized web browsing capabilities.",
  "Data Construction": "Considering the scarcity of high-quality, complex web browsingdata produced by actual users, we aim to create a training dataset.However, the dataset construction presents several challenges: Task Collection: A significant hurdle is acquiring diverse, real-user task queries across various websites. Privacy and Security: Privacy and security limitations hinder thedirect acquisition of user browser operation sequences. It is alsochallenging to rule out redundant or incorrect operations notpertinent to task completion and to confirm user task completion.",
  "Objective Annotation: The labor-intensive nature of collectinguser objectives for each operational step makes it impractical inreal-world data-gathering scenarios": "Model Limitations: Current models cannot process complex userqueries across different websites, thus eliminating the chance ofusing purely automated methods for accurate browsing trajectorycollection in real and complex application contexts.As illustrated in , we suggest a hybrid human-AI DataConstruction method to create our training data in response tothese challenges. After careful consideration, we categorize ourdata into two types for construction: 4.1.1Web Recognition & Simple Task Operation Construction. Forweb browsing tasks, efficient and accurate understanding and ma-nipulation of webpages become vital challenges in model develop-ment due to the diversity of user behaviors and the complexity ofweb content. This section illustrates our construction method forweb recognition and simple task operation to train models to recog-nize webpage structures and perform basic operations accurately. Web Recognition. The main objective of Web Recognition includesunderstanding particular HTML formats, identifying different typesof web elements (such as text boxes, buttons, images, etc.), andunderstanding the role of these elements in user interaction. Wepropose the following construction approach based on the abovepractical challenges.We initiate our process by collecting URLs from Chinese andEnglish mainstream websites listed on Similarweb1. In the dataprocessing stage, we use our HTML parser to identify operablecomponents in each webpage and record essential informationsuch as component position and size. We then generate a simplifiedHTML by rearranging and simplifying the component tree (seedetails in .2).We design tasks such as website and component function descrip-tions to aid model recognition of webpage structures and interactivecomponents functions. For each task, we develop a series of naturallanguage questions to serve as the source field in our data. GPT-3.5-Turbo is utilized to generate multiple formulations for eachquestion, thereby diversifying the question formation.For the target, we leverage GPT-3.5-Turbo to generate the re-sponse. We supply a simplified HTML with the pertinent questionin the prompt and impose a limit on the response length, therebyobtaining our target. Simple Task Operation. The main objective of the Simple TaskOperation dataset is to train models to perform single-step weboperations. This involves executing basic functionalities on webpages, such as clicking links, filling out forms, or navigating tospecific sections. To build our data, we collect various websitesin the same way as Web Recognition. Then, we construct a splitfor each operation type to ensure that our dataset covers all therequirements for simple task operations. We adjust the data sizefor each split based on the frequency of each operation in practice.Our key to constructing the dataset is by rules instead of modelgeneration. We try GPT-3.5-Turbo for tasks, intent, and operationgeneration and Selenium 2 to validate the executability of the gener-ated results. However, it has obvious drawbacks: The model cannotreach an acceptable accuracy in the operation to fulfill the task,and the correctness of the model-generated operations is hard tojudge. To address the above issues, we endeavor to approach from anovel perspective. We identify various actionable elements withinthe webpage, assembling them into web operations. Then, we useGPT-3.5-Turbo to produce the corresponding tasks and operationalintents for these actions. For operation types with relatively fixedbehaviors, such as Scroll and Jump_to, we directly generate theircorresponding tasks with templates; for flexible and feature-richoperations, such as Click and Type, we use GPT-3.5-Turbo to help",
  "Intent Generation by LLM": ": Data Construction. Data construction is divided into two main stages; the first stage is webpage recognition tasks and simpletasks operation construction, and the second stage is complex tasks construction. complete the construction. This approach ensures the instructionsexecutability and provides the operation tasks richness.4.1.2Complex Task Operation Construction. We developed a datasetfor complex web tasks to enable the model to make plans and reasonin the web browsing scenario. Each sample in the dataset consists ofa real-world complex web browsing task, the sequence of operationsto complete the task, and the intent of each step.We first designed 50 complex tasks for each website using theprompting technique referring to Evol-Instruct , from whichabout 20 feasible tasks were manually selected and labeled. For op-eration sequence, due to the high complexity of the tasks, even themost advanced LLMs cannot complete the task with satisfactory ac-curacy. Therefore, we leveraged manual annotations to capture webtask executions via a browser plugin that records actions duringwebsite tasks. Chain-of-thought reasoning has been proven toimprove task comprehension and model performance signif-icantly. However, leveraging human annotators to document theirintent and reasoning during web browsing is inefficient. To improvethe CoT construction process, we used GPT-4 as the operationalintent predictor. Our first approach of iterative step-by-step cre-ation proved to generate weak operational links and incurred highAPI costs due to data construction. To address this, we employeda global thought chain prompting method, where all operationsand critical HTML segments are inputted into a trace. Then, weprompted GPT-4 to output intentions for each step. This methodimproves the accuracy and cohesion of each step, thus forminghighly relevant, consistent thought chains.After construction, we merge our data with the training set fromMind2Web and MiniWob++ to form our final training dataset. Theproportion of each split is in .",
  ": Dataset Proportion. Piechart of the distribution of splitswithin our training data": "This approach enhances the models comprehension of web-pages and its capability as an agent to perform operations withinthe environments. Significantly, we use curriculum learning (CL),which mimics the human learning process, advocating for mod-els to start learning from easy samples and gradually advance tocomplex ones. It has been demonstrated in prior works toimprove model capabilities substantially. Enabling LM to Read and Operate on the Web. In the initialstage, we mix the data constructed in .1.1 to equip themodel with the ability to (1) comprehend the structure of web pagesand the functions of various web components, and to (2) executepredefined operations on the current webpage, thus implementingsimple user instructions. To Make LM Learn to Plan & Reason on the Web. During thisstage, we continue to employ the constructed data in .1.2for training. We enable our model to decompose tasks into subtasksand execute subsequent steps based on the current webpage andthe sequence of prior operations.After the above training, our model SFT acquired essential ca-pability in completing web browsing tasks and could independentlyexecute operations based on user instructions.",
  "RFT": ": The Training Procedure. First, the model learns webpage interpretation and operation via curriculum learning. Next, it self-samples training data, learning from its mistakes. Finally, it self-plays in the environment, becoming a domain expert. SFT attempts to mimic the inference process and operations butsometimes overlooks the webpages state and preceding operationsequences, leading to hallucination. Consequently, we propose aself-sampling reinforcement learning to mitigate these operativeillusions.First, we use SFT for -fold sampling (=20) on complex taskoperation samples in the training set. We combine the sampled out-put and golden answer to construct contrastive data with positiveand negative pairs. Subsequently, we retain samples based on thefollowing criteria: From all iterations of sampling, we select data where the modelcompleted the tasks from 1 to -1 times. If SFT answered alliterations correctly, we consider it devoid of training value andincapable of providing practical negative examples. Conversely, IfSFT answered incorrectly across all iterations, we suspect issueswith the data and exclude them, as the model cannot adequatelyfit these outliers during optimization. We retain different erroneous operations and remove duplicatesto preserve distinct negative examples.After constructing contrastive data Const., we employ the DPOtraining approach to make SFT learn from its mistakes and fur-ther enhance its capabilities. During the training, we found that thedirect use of DPO loss led to instability. To mitigate this issue, wepropose including SFT loss to stabilize the reinforcement learningprocess and increase the number of training steps while ensuringno loss of the original models natural language and agent abilities,achieving a more robust model DPO:",
  "L = L + L(4)": "4.2.3Step 3: Rejection Sampling Finetuning. In the RFT (Rejec-tion Sampling Finetuning) step, we aim to optimize for webpageenvironments in specific domains. RFT enables us to perform tar-geted training through substantial sampling from an existing model,selecting the accurate trajectories in instances lacking ones via re-ward signals. Our reward signals can be furnished either by theenvironment itself or through pre-designed reward models. Due tothe network policy constraints inherent in real webpage environ-ments, we conduct our experiments within sandbox environmentsfurnished by MiniWob++ and WebArena.For MiniWob++, we leverage the query generator in MiniWob++to auto-generate multiple user queries for each task. We determinethe number of generated queries for each task based on its diffi-culty. Then, we employ DPO to try to solve the queries. If a tracecompletes the task (as adjudged by the MiniWob++ environment),we consider this trace as a positive trace.In the case of WebArena, to prevent overlap with the test set,we manually construct multiple distinctive user queries based onWebArenas templates. For each sample, we apply DPO to perform64 times of sampling. Similarly, if our model completes the taskat least once (adjudged by manually written rules), we deem thesuccessful trace as a positive trace.By utilizing the methods above, we constructed two distinctsuccessful datasets, one from MiniWob++ and the other from We-bArena. These comprise approximately 15k traces (66k steps) and240 traces (2k steps), respectively, which are used for AutoWe-bGLMs individual finetuning on these two tasks.",
  "AutoWebGLM6B64.858.665.461.8": "under familiar conditions. In contrast, the out-of-domain dataset en-compasses data collected from websites entirely excluded from ourtraining set. It offers a unique opportunity to measure the modelsgeneralizability and ability to adapt to unfamiliar environments.We select 50 browsing traces for each split as our test data. Thesetraces are scrutinized and filtered via human verification, ensuringa more reliable evaluation benchmark.Drawing on the methodology presented in Mind2Web, we com-prehensively evaluate each step involved in the operation. Thisallows us to assess the step and overall accuracy of the models op-erations. Detailed results of this evaluation are available in .",
  "Main Results": "AutoWebBench. As discussed in .3, We divide the test setinto four splits: Chinese, English, in-domain, and out-of-domain,for evaluation purposes. We use the Step Success Rate (SSR) as ourevaluation metric. The results are in . Mind2Web. We use the settings from Mind2Web with SSR as ourprimary evaluation metric. To compare the model fairly, we utilizethe MindAct framework provided by Mind2Web to evaluate themodels performance. The results are in . MiniWoB++ & WebArena. For MiniWob++, following the experi-mental setup from WebAgent , we test MiniWoB++ with 56 tasksby running 100 evaluation episodes per task to evaluate model ca-pabilities. For WebArena, we integrate our HTML parser moduleand action execution module into the WebArena environment tomake it compatible with our system. The results are in .",
  "To evaluate the impact of different stages of data and trainingstrategies on model performance enhancement, we conduct a com-prehensive ablation study in": "Training Data Ablation. We train and test only models that con-tain the original training set and incorporate simple and complextask data (see .1) for training. This approach helps to qual-itatively measure the impact of different datasets on the model.The Complex Task dataset significantly improves model perfor-mance. We hypothesize that this is due to the complex data moreclosely aligning with real-world scenarios, thereby fundamentallytransforming model performance.The simple task dataset shows only a slight improvement whentraining alone. However, when training jointly with the complex",
  "Hallucinations44%Poor Graphical Recognition28%Misinterpretation of Task Context20%Pop-Up Interruption8%": "task dataset, there is a significant improvement. We find that train-ing exclusively with complex task datasets leads to basic operationalerrors, suggesting that training with simple task datasets can effec-tively mitigate this problem. Training Strategy Ablation. We compare the results of SFT, DPO,and RFT-enhanced models and find that: (1) Compared to SFT, theDPO training facilitates model learning from its mistakes, furtherenhancing model performance. (2) RFT enables our model to per-form bootstrap enhancement in different domains. With practicecomes proficiency, resulting in improvements within each domain.",
  "Case Study and Error Analysis": "To assess the effectiveness of our model, we conduct a series of casestudies covering a range of web-based tasks, including everydayuse, leisure and relaxation, and academic research, covering thetypical range of web requirements. Our system achieves satisfactoryresults in most scenarios.While our system performs commendably well on a variety ofweb-based tasks, it has limitations. We identify errors that occasion-ally occur during task execution, which can be broadly categorizedinto four types: hallucinations, poor graphical recognition, mis-interpretation of task context, and pop-up interruptions. outlines the proportion of these errors observed during error anal-ysis. Although relatively infrequent, these errors are crucial in ourongoing efforts to refine and enhance the systems capabilities.",
  "While HTML input has produced satisfactory results in many sce-narios, our system falters when confronted with advanced webapplications such as maps, animations, and video browsing. In our": "analysis, the strength of image input lies in its indispensable rolein interpreting images, icons, and special effects. However, com-pared to text input, image input presents additional challenges inunderstanding numerals and extensive web text. Consequently, weconsider that a multimodal system, integrating HTML and webpagescreenshots, combines the advantages of both modalities, substan-tially enhancing the models capability in web browsing tasks.",
  "Reasoning and Self-check Techniques": "The systems efficiency and success rate in web browsing maydecrease when dealing with unfamiliar websites or those withunique operating logic. To mitigate this issue, an exciting avenuefor exploration is the development of novel reasoning strategiesdistinct from the Chain-of-Thought approach, enabling the modelto make better-informed decisions based on previous browsingexperiences, thereby improving the success rate and efficiency ofweb browsing. Moreover, due to unstable internet connectionsand other factors, the stability of a real web environment is notguaranteed. Thus, self-check mechanisms within the web browsingagent system, including confirming the current state and verifyingthe intended operations effect, could significantly improve thesystems robustness and effectiveness.",
  "Mobile Application": "The mobile platform is another promising application scenariowith massive potential. Compared to the web platform, it presentsits challenges and opportunities. For example, due to their screensize, mobile devices display fewer elements within the viewport,simplifying the page XML. Furthermore, the operation logic onmobile platforms is generally more straightforward than on webplatforms. However, mobile operation space includes more complexactions such as gestures, and mobile platforms face more systemsecurity restrictions, imposing additional constraints on softwaredevelopment.",
  "CONCLUSION": "In this work, we present AutoWebGLM, an advanced languagemodel-based agent exhibiting robust performance in various au-tonomous web navigation benchmarks. Our model addresses extantLLM limitations and simplifies webpages by effectively controllingHTML text length and handling the webs open-domain nature. Westrategically employ curriculum learning, reinforcement learning,and rejection sampling finetuning to enhance webpage comprehen-sion and browser operation learning. We also introduce a uniquebilingual web browsing benchmark that lays a solid foundationfor future research. Our findings represent significant progress inutilizing LLMs for intelligent agent tasks. This work is supported by Natural Science Foundation of China(NSFC) 62276148 and 62425601, the New Cornerstone Science Foun-dation through the XPLORER PRIZE and Tsinghua University (De-partment of Computer Science and Technology) -Siemens Ltd.,China Joint Research Center for Industrial Intelligence and Internetof Things (JCIIOT).",
  "KDD 24, August 2529, 2024, Barcelona, SpainHanyu Lai et al": "Josh Achiam, Steven Adler, Sandhini Agarwal, Lama Ahmad, Ilge Akkaya, Floren-cia Leoni Aleman, Diogo Almeida, Janko Altenschmidt, Sam Altman, ShyamalAnadkat, et al. 2023. Gpt-4 technical report. arXiv preprint arXiv:2303.08774(2023). Anthropic. 2023. Model Card and Evaluations for Claude Models. (2023). Yoshua Bengio, Jrme Louradour, Ronan Collobert, and Jason Weston. 2009.Curriculum learning. In Proceedings of the 26th annual international conferenceon machine learning. 4148. Jonathan Berant, Andrew Chou, Roy Frostig, and Percy Liang. 2013. Seman-tic parsing on freebase from question-answer pairs. In Proceedings of the 2013conference on empirical methods in natural language processing. 15331544. Jiale Cheng, Xiao Liu, Kehan Zheng, Pei Ke, Hongning Wang, Yuxiao Dong, JieTang, and Minlie Huang. 2023. Black-box prompt optimization: Aligning largelanguage models without model training. arXiv preprint arXiv:2311.04155 (2023). Kanzhi Cheng, Qiushi Sun, Yougang Chu, Fangzhi Xu, Yantao Li, Jianbing Zhang,and Zhiyong Wu. 2024. SeeClick: Harnessing GUI Grounding for AdvancedVisual GUI Agents. arXiv preprint arXiv:2401.10935 (2024).",
  "Xiang Deng, Yu Gu, Boyuan Zheng, Shijie Chen, Samuel Stevens, Boshi Wang,Huan Sun, and Yu Su. 2023. Mind2Web: Towards a Generalist Agent for the Web.arXiv preprint arXiv:2306.06070 (2023)": "Zhengxiao Du, Yujie Qian, Xiao Liu, Ming Ding, Jiezhong Qiu, Zhilin Yang, andJie Tang. 2022. GLM: General Language Model Pretraining with AutoregressiveBlank Infilling. In Proceedings of the 60th Annual Meeting of the Association forComputational Linguistics (Volume 1: Long Papers). 320335. Izzeddin Gur, Hiroki Furuta, Austin Huang, Mustafa Safdari, Yutaka Matsuo, Dou-glas Eck, and Aleksandra Faust. 2023. A real-world webagent with planning, longcontext understanding, and program synthesis. arXiv preprint arXiv:2307.12856(2023). Wenyi Hong, Weihan Wang, Qingsong Lv, Jiazheng Xu, Wenmeng Yu, JunhuiJi, Yan Wang, Zihan Wang, Yuxiao Dong, Ming Ding, et al. 2023. CogAgent: AVisual Language Model for GUI Agents. arXiv preprint arXiv:2312.08914 (2023).",
  "Or Honovich, Thomas Scialom, Omer Levy, and Timo Schick. 2022. Unnaturalinstructions: Tuning language models with (almost) no human labor. arXivpreprint arXiv:2212.09689 (2022)": "Peter C Humphreys, David Raposo, Tobias Pohlen, Gregory Thornton, RachitaChhaparia, Alistair Muldal, Josh Abramson, Petko Georgiev, Adam Santoro, andTimothy Lillicrap. 2022. A data-driven approach for learning to control computers.In International Conference on Machine Learning. PMLR, 94669482. Jinhao Jiang, Kun Zhou, Zican Dong, Keming Ye, Wayne Xin Zhao, and Ji-RongWen. 2023. Structgpt: A general framework for large language model to reasonover structured data. arXiv preprint arXiv:2305.09645 (2023). Takeshi Kojima, Shixiang Shane Gu, Machel Reid, Yutaka Matsuo, and YusukeIwasawa. 2022. Large language models are zero-shot reasoners. Advances inneural information processing systems 35 (2022), 2219922213. Tom Kwiatkowski, Jennimaria Palomaki, Olivia Redfield, Michael Collins, AnkurParikh, Chris Alberti, Danielle Epstein, Illia Polosukhin, Jacob Devlin, KentonLee, et al. 2019. Natural questions: a benchmark for question answering research.Transactions of the Association for Computational Linguistics 7 (2019), 453466. Xiao Liu, Hanyu Lai, Hao Yu, Yifan Xu, Aohan Zeng, Zhengxiao Du, PengZhang, Yuxiao Dong, and Jie Tang. 2023. WebGLM: Towards An Efficient Web-Enhanced Question Answering System with Human Preferences. arXiv preprintarXiv:2306.07906 (2023). Ziyang Luo, Can Xu, Pu Zhao, Qingfeng Sun, Xiubo Geng, Wenxiang Hu,Chongyang Tao, Jing Ma, Qingwei Lin, and Daxin Jiang. 2023. WizardCoder:Empowering Code Large Language Models with Evol-Instruct. arXiv preprintarXiv:2306.08568 (2023). Yu Meng, Jiaxin Huang, Yu Zhang, and Jiawei Han. 2022. Generating training datawith language models: Towards zero-shot language understanding. Advances inNeural Information Processing Systems 35 (2022), 462477. Suraj Mishra, Peixian Liang, Adam Czajka, Danny Z Chen, and X Sharon Hu.2019. CC-NET: Image complexity guided network compression for biomedicalimage segmentation. In 2019 IEEE 16th International Symposium on BiomedicalImaging (ISBI 2019). IEEE, 5760. Subhabrata Mukherjee, Arindam Mitra, Ganesh Jawahar, Sahaj Agarwal, HamidPalangi, and Ahmed Awadallah. 2023. Orca: Progressive learning from complexexplanation traces of gpt-4. arXiv preprint arXiv:2306.02707 (2023). Reiichiro Nakano, Jacob Hilton, Suchir Balaji, Jeff Wu, Long Ouyang, ChristinaKim, Christopher Hesse, Shantanu Jain, Vineet Kosaraju, William Saunders, et al.2021. Webgpt: Browser-assisted question-answering with human feedback. arXivpreprint arXiv:2112.09332 (2021).",
  "Pranav Rajpurkar, Jian Zhang, Konstantin Lopyrev, and Percy Liang. 2016.Squad: 100,000+ questions for machine comprehension of text. arXiv preprintarXiv:1606.05250 (2016)": "Teven Le Scao, Angela Fan, Christopher Akiki, Ellie Pavlick, Suzana Ili, DanielHesslow, Roman Castagn, Alexandra Sasha Luccioni, Franois Yvon, MatthiasGall, et al. 2022. Bloom: A 176b-parameter open-access multilingual languagemodel. arXiv preprint arXiv:2211.05100 (2022). Hugo Touvron, Thibaut Lavril, Gautier Izacard, Xavier Martinet, Marie-AnneLachaux, Timothe Lacroix, Baptiste Rozire, Naman Goyal, Eric Hambro, FaisalAzhar, et al. 2023. Llama: Open and efficient foundation language models. arXivpreprint arXiv:2302.13971 (2023). Hugo Touvron, Louis Martin, Kevin Stone, Peter Albert, Amjad Almahairi, Yas-mine Babaei, Nikolay Bashlykov, Soumya Batra, Prajjwal Bhargava, Shruti Bhos-ale, et al. 2023. Llama 2: Open foundation and fine-tuned chat models. arXivpreprint arXiv:2307.09288 (2023). Lei Wang, Chen Ma, Xueyang Feng, Zeyu Zhang, Hao Yang, Jingsen Zhang,Zhiyuan Chen, Jiakai Tang, Xu Chen, Yankai Lin, Wayne Xin Zhao, Zhewei Wei,and Ji-Rong Wen. 2023. A Survey on Large Language Model based AutonomousAgents. arXiv preprint arXiv:2308.11432 (2023). Lei Wang, Wanyu Xu, Yihuai Lan, Zhiqiang Hu, Yunshi Lan, Roy Ka-Wei Lee,and Ee-Peng Lim. 2023. Plan-and-solve prompting: Improving zero-shot chain-of-thought reasoning by large language models. arXiv preprint arXiv:2305.04091(2023).",
  "Xin Wang, Yudong Chen, and Wenwu Zhu. 2021. A survey on curriculumlearning. IEEE Transactions on Pattern Analysis and Machine Intelligence 44, 9(2021), 45554576": "Xuezhi Wang, Jason Wei, Dale Schuurmans, Quoc V Le, Ed H Chi, Sharan Narang,Aakanksha Chowdhery, and Denny Zhou. 2022. Self-Consistency ImprovesChain of Thought Reasoning in Language Models. In The Eleventh InternationalConference on Learning Representations. Jason Wei, Xuezhi Wang, Dale Schuurmans, Maarten Bosma, Fei Xia, Ed Chi,Quoc V Le, Denny Zhou, et al. 2022. Chain-of-thought prompting elicits reasoningin large language models. Advances in Neural Information Processing Systems 35(2022), 2482424837. Zhiheng Xi, Wenxiang Chen, Xin Guo, Wei He, Yiwen Ding, Boyang Hong,Ming Zhang, Junzhe Wang, Senjie Jin, Enyu Zhou, Rui Zheng, Xiaoran Fan, XiaoWang, Limao Xiong, Yuhao Zhou, Weiran Wang, Changhao Jiang, Yicheng Zou,Xiangyang Liu, Zhangyue Yin, Shihan Dou, Rongxiang Weng, Wensen Cheng,Qi Zhang, Wenjuan Qin, Yongyan Zheng, Xipeng Qiu, Xuanjing Huang, and TaoGui. 2023. The Rise and Potential of Large Language Model Based Agents: ASurvey. arXiv preprint arXiv:2309.07864 (2023). Can Xu, Qingfeng Sun, Kai Zheng, Xiubo Geng, Pu Zhao, Jiazhan Feng,Chongyang Tao, and Daxin Jiang. 2023. Wizardlm: Empowering large languagemodels to follow complex instructions. arXiv preprint arXiv:2304.12244 (2023). Yiheng Xu, Hongjin Su, Chen Xing, Boyu Mi, Qian Liu, Weijia Shi, BinyuanHui, Fan Zhou, Yitao Liu, Tianbao Xie, et al. 2023. Lemur: Harmonizing naturallanguage and code for language agents. arXiv preprint arXiv:2310.06830 (2023). Shunyu Yao, Jeffrey Zhao, Dian Yu, Nan Du, Izhak Shafran, Karthik R Narasimhan,and Yuan Cao. 2022. ReAct: Synergizing Reasoning and Acting in LanguageModels. In The Eleventh International Conference on Learning Representations. Zheng Yuan, Hongyi Yuan, Chengpeng Li, Guanting Dong, Chuanqi Tan, andChang Zhou. 2023. Scaling relationship on learning mathematical reasoning withlarge language models. arXiv preprint arXiv:2308.01825 (2023). Aohan Zeng, Xiao Liu, Zhengxiao Du, Zihan Wang, Hanyu Lai, Ming Ding,Zhuoyi Yang, Yifan Xu, Wendi Zheng, Xiao Xia, et al. 2022. GLM-130B: An OpenBilingual Pre-trained Model. In The Eleventh International Conference on LearningRepresentations. Susan Zhang, Stephen Roller, Naman Goyal, Mikel Artetxe, Moya Chen, ShuohuiChen, Christopher Dewan, Mona Diab, Xian Li, Xi Victoria Lin, et al. 2022. Opt:Open pre-trained transformer language models. arXiv preprint arXiv:2205.01068(2022). Wayne Xin Zhao, Kun Zhou, Junyi Li, Tianyi Tang, Xiaolei Wang, Yupeng Hou,Yingqian Min, Beichen Zhang, Junjie Zhang, Zican Dong, et al. 2023. A surveyof large language models. arXiv preprint arXiv:2303.18223 (2023). Shuyan Zhou, Frank F Xu, Hao Zhu, Xuhui Zhou, Robert Lo, Abishek Sridhar,Xianyi Cheng, Tianyue Ou, Yonatan Bisk, Daniel Fried, et al. 2023. WebArena: ARealistic Web Environment for Building Autonomous Agents. In Second AgentLearning in Open-Endedness Workshop.",
  "AIMPLEMENTATION DETAILS OFAUTOWEBGLM": "During the SFT phase, we set the learning rate to 1e-5 with a batchsize of 32. In the DPO stage, we sample the complex task dataset 20times. After the filtering process, we build a contractional datasetof approximately 13k. We set the learning rate for the DPO to 1e-6, the batch size to 64, and the parameter to 0.15. We add theSFT loss, weighted by a factor of 0.8. During the RFT stage, wecollect samples from two diverse environments, MiniWoB++ andWebArena, resulting in successful datasets of approximately 66kand 2k, respectively, which underwent finetuning. The learningrate set for this stage was 1e-5, and the batch size was 32.",
  "DANNOTATION DETAILS": "The annotation process was performed by 20 annotators for onemonth using the Google Chrome browser with our plugin installedto record their actions on assigned websites. The annotators firstvisited the target websites and checked whether the website de-scriptions matched the actual tasks. They then evaluated the tasksfor clarity, relevance, achievability, complexity, and subjectivity,skipping those that didnt meet the criteria. They carefully recordedeach step during a task, including any login or captcha steps. Fortasks that required an answer, the annotators manually edited theresponses. If a task was not doable, they could modify its descriptionor abandon it."
}