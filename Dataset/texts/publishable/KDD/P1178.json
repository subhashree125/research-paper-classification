{
  "ABSTRACT": "The objective of this study is to develop natural language process-ing (NLP) models that can analyze patients drug reviews and accu-rately classify their satisfaction levels as positive, neutral, or neg-ative. Such models would reduce the workload of healthcare pro-fessionals and provide greater insight into patients quality of life,which is a critical indicator of treatment eectiveness.To achieve this, we implemented and evaluated several classi-cation models, including a BERT base model, Bio+Clinical BERT,and a simpler CNN. Results indicate that the medical domain-specicBio+Clinical BERT model signicantly outperformed the generaldomain base BERT model, achieving macro f1 and recall score im-provement of 11%, as shown in . Future research could ex-plore how to capitalize on the specic strengths of each model.Bio+Clinical BERT excels in overall performance, particularly withmedical jargon, while the simpler CNN demonstrates the ability toidentify crucial words and accurately classify sentiment in textswith conicting sentiments.",
  "INTRODUCTION": "Healthcare clinics possess extensive records of patients medicalinformation, encompassing clinical notes, test results, survey re-sponses, and drug reviews. Extracting valuable insights from theserecords regarding patients responses to treatments often requires Permission to make digital or hard copies of all or part of this work for personal orclassroom use is granted without fee provided that copies are not made or distributedfor prot or commercial advantage and that copies bear this notice and the full cita-tion on the rst page. Copyrights for components of this work owned by others thanACM must be honored. Abstracting with credit is permitted. To copy otherwise, or re-publish, to post on servers or to redistribute to lists, requires prior specic permissionand/or a fee. Request permissions from DSHealth 2023, August 07, 2023, Long Beach, CA 2023 Association for Computing Machinery.ACM ISBN 978-x-xxxx-xxxx-x/YY/MM...$15.00 laborious manual reviews of textual data. However, automated in-ference techniques can oer valuable insights for guiding futuretreatment options.Understanding patients satisfaction with drugs is crucial as itcan supplement established quality-of-life metrics and guide phar-maceutical research in identifying treatment-eective targets. Ad-ditionally, patients drug reviews play a signicant role in advo-cating for broader coverage of eective drugs by government andinsurance companies.Past work on health-related sentiment classication revolvesaround using a bag of words techniques like lexical matching orword frequencies, or shallow machine learning models with staticor low-context embeddings . While sentiment can beexpressed in subtle and nuanced ways, more complex models haveperformed better in detecting sentiment in other domains .A more recent deep learning approach utilized BERT followed by abidirectional LSTM architecture to achieve the highest drug reviewsentiment classication .In recent years, transformers have signicantly advanced NLPtasks by capturing contextual information from source text. Largepre-trained language models also facilitate handling complex textclassication problems with limited datasets. This paper investi-gates the eectiveness of pre-trained language models, includingBERT base and Bio+Clinical BERT, in classifying drug reviewerstreatment sentiments. We compare these models to a simpler CNNapproach, aiming to gain insights into transformers and domain-specic pre-training for sentiment classication.",
  "RELATED WORKS": "Predicting drug satisfaction is challenging due to the diverse rangeof experiences and the complex nature of human sentiments. Neg-ative ratings may stem from various factors, including persistentsymptoms, severe side eects, and nancial burdens, among oth-ers. Conversely, positive ratings can be inuenced by factors suchas eectiveness, absence of side eects, and aordability.Sokolova and Bobicev employed basic machine learningmodels such as Naive Bayes, Decision Tree, K-nearest neighbor,and supportvector machines with bag-of-word representations andhuman-annotation for drug review sentiment analysis. However,human annotation is an expensive process, whether it is used forstandalone predictions or to prepare the data needed for training.Similarly, Yadav et al. have also explored sentiments regard-ing the medical conditions of social media users based on usersself-narrated texts. In this work, Yadav et al. used Google News",
  "KDD DSHealth 2023, August 07, 2023, Long Beach, CALing": "Marina Sokolova and Victoria Bobicev. 2011. Sentiments and Opinions in Health-related Web messages. , 132139 pages. Duyu Tang, Bing Qin, and Ting Liu. 2015.Document Modeling withGated Recurrent Neural Network for Sentiment Classication. In Proceedingsof the 2015 Conference on Empirical Methods in Natural Language Process-ing. Association for Computational Linguistics, Lisbon, Portugal, 14221432. Lizhong Xiao, Guangzhong Wang, and Yang Zuo. 2018.Research on PatentText Classication Based on Word2Vec and LSTM. In 2018 11th InternationalSymposium on Computational Intelligence and Design (ISCID), Vol. 01. 7174. Shweta Yadav, Asif Ekbal, Sriparna Saha, and Pushpak Bhattacharyya. 2018.Medical sentiment analysis using social media: towards building a patient as-sisted system. In Proceedings of the Eleventh International Conference on Lan-guage Resources and Evaluation (LREC 2018).",
  "DATA": "The UCI ML Drug Review dataset includes 215,063 drug reviewsfrom Drugs.com, each labeled with a 10-star rating. Our goal is topredict these ratings based on the review text, enabling inferenceof overall patient satisfaction from similar narratives like patientsurveys. To simplify the analysis and highlight clearer dierencesbetween high, middle, and low scores, we binned the original labelsinto 3 categories. This helps address potential variability in how in-dividuals assign similar scores. Binning the ratings into more con-sistent buckets allows us to focus on clearly misclassied instancesthat show substantial discrepancies, like those labeled as highlypositive but predicted as negative, or vice versa. This approachavoids ambiguity in distinguishing between neutral compared topositive or negative sentiments, making our analysis more focusedand comprehensive. The decision to bin the labels is driven by thepractical application of the model, identifying the general positiveor negative response to treatment options rather than ne-grainedscores. This approach allows for determining whether the drug is",
  "METHOD AND EXPERIMENTS": "For this task, we compare several classication models using thebase-cased general-purpose BERT model,Bio+Clinical BERT, a CNNapplied to pre-trained word2vec embeddings. We expectBERT to outperform CNN due to its ability to capture the longer-range context in drug reviews. BERT can incorporate the full nar-rative of reviewers discussing multiple experiences with a drug,whereas CNNs are limited to shorter-phrase patterns. Furthermore,Bio+Clinical BERT, specically trained on medical text, is expectedto outperformgeneral domain BERT by recognizing domain-specicmedical jargon. Our experiments compare the following models,each with a maximum token length of 128:1. Baseline BERT base: pre-trained BERT embeddings, and passthe CLS token vector to a hidden dense layer of size 100, globalmax pooling, and a classication layer. We do not ne-tune.2. CNN-Word2Vec: Pre-trained Word2Vec embeddings passedinto a CNN with 50 or 100 lters of 1-5 tokens, followed by a hid-den layer of size 100, global max pooling, and a classication layer.Converged at 18 epochs.3. BERT base: Pre-trained BERT model with ne-tuning on thelast four layers. CLS token passed to a size 100 dense layer, globalmax pooling, and a classication layer. Converged at 8 epochs.4. Bio+Clinical BERT: Pre-trained Bio+Clinical BERT model withne-tuning on the last four layers. CLS token passed to a size 100dense layer, global max pooling, and a classication layer. Con-verged at 11 epochs.",
  "RESULTS AND DISCUSSIONS": "Consistent with similar research, we show macro precision, macrorecall, and macro f1 scores to evaluate model performance. Themedical community commonly uses recall as the primary evalua-tion metric for predictions related to medical conditions and treat-ments, especially when diagnosing diseases due to the signicantrisk associated with missing cases requiring attention. In our caseof detecting treatment dissatisfaction (the negative sentiment class),recall is also important since medical providers may want to fur-ther investigate and identify needed changes.The main results are shown in and summarized below.As we expected, Bio+Clinical BERT classication model performsbest, outperforming the more general domain BERT baseline modelby 11% in recall and f1 score. It also performs better than a CNNon its own by 4% recall and 5% f1 score. Compared to BERT base,Bio+Clinical BERT performs better by 1% f1 score. Bio+Clinical",
  "Analysis of Misclassications": "To understand the strengths and performance dierences amongthe models, we conducted manual reviews of misclassied exam-ples. Specically, we compared the misclassications of the best-performing model (Bio+Clinical BERT) with other model optionsto identify patterns in correctly classifying dierent types of text.In the Appendix, we provide tables with example reviews that il-lustrate these patterns. We conducted a comparison of misclassi-ed review scores between models, specically focusing on caseswhere the actual score was 2 but predicted as 0, or vice versa. Theseinstances of misclassication served as crucial indicators, highlight-ing the specic areas where one model demonstrated superior per-formance over the other.1. Mislabeled examples: Some reviews contradict the assignednumeric scores, indicating potential misinterpretation of the rat-ing scale by reviewers. This common challenge in user-collecteddatasets from public platforms leads to misclassications acrossall models. Refer to A.1 for example reviews.2. Contradictory language: Reviews with seemingly contra-dictory sentiments about a drug are hard for all models to classify.From the sample of drug reviews that all of the models misclassi-ed, another clearest trend was that they often contain both posi-tive and negative sentiment comments in the same review. Review-ers sometimes talk about both the benets and downsides of a drugand put a subtle emphasis on one or the other (e.g. by talking aboutthe one that ultimately swayed their opinion last). Refer to A.2 forexample reviews.3. Non-domain sentiment statements: There were some ex-amples that the simple CNN-only model actually did better on thanBio+Clinical BERT. Those were often examples in which the mainsentiment statement didnt have much if any medical jargon, butsaid something generic like overall Im happy with it or wellworth the payo. These reviews might have also made commentsabout the trade-os that went in the other direction of their mainscore, which the BERT models may have focused too much on.Bio+Clinical BERT appears to have more emphasis on commentsinvolving medical terms, which arent always the main overall sen-timent. Refer to A.3 for example reviews.4. Medical-domain sentiment statements: The use of med-ical slang, medicine names, and detailed disease symptoms in re-views is more accurately classied using Bio+Clinical BERT com-pared to base-cased BERT. This may be due to the domain-specic focus of the embeddings used in Bio+Clinical BERT, which allowsfor a better understanding of the underlying patients treatmentsymptoms and associated sentiments. However, in some rare in-stances, base-cased BERT may predict better the overall structureof the review and pick up the overall sentiment despite the [UNK]tokens. It should be noted that Bio+Clinical BERT appears to placemore emphasis on medical terms. Refer to A.4 and A.5 for examplereviews.",
  "CONCLUSION": "Correctly determining medicine satisfaction is a crucial task for de-vising eective treatment plans, and it is especially important toidentify patients who are dissatised with their medication to pre-vent lasting side eects or impede full recovery. In this work, thebest model, Bio+Clinical BERT, successfully addresses this task byaccurately classifying patients drug review sentiment as positive,neutral, or negative, outperforming the baseline model by 11% inf1 score.While impressive, there is room for improvement in the modelsperformance. The CNN outperforms in cases where reviewers pro-vide tangential information, capturing sentiment by ltering noiseand identifying prominent phrases. Furthermore, CNN trains fasterthan BERT. Future work may involve combining these models tomake multiple score predictions, enabling medical providers to iden-tify patients who require further investigation.",
  "I am grateful to Dr. Natalie Ahn for her outstanding mentorship,diligent review of my work, and valuable guidance throughout theproject. Her constructive feedback and support have been invalu-able": "Emily Alsentzer, John R Murphy, Willie Boag, Wei-Hung Weng, Di Jin, TristanNaumann, and Matthew McDermott. 2019. Publicly available clinical BERT em-beddings. arXiv preprint arXiv:1904.03323 (2019). Cristbal Coln-Ruiz and Isabel Segura-Bedmar. 2020. Comparing deep learn-ing architectures for sentiment analysis on drug reviews. Journal of BiomedicalInformatics 110 (2020), 103539. Jacob Devlin, Ming-Wei Chang, Kenton Lee, and Kristina Toutanova. 2018. Bert:Pre-training of deep bidirectional transformers for language understanding.arXiv preprint arXiv:1810.04805 (2018). Felix Grer, Surya Kallumadi, Hagen Malberg, and Sebastian Zaunseder. 2018.Aspect-Based Sentiment Analysis of Drug Reviews Applying Cross-DomainandCross-Data Learning. In Proceedings of the 2018 International Conference on Dig-ital Health (Lyon, France) (DH 18). Association for Computing Machinery, NewYork, NY, USA, 121125. Anastasia Kotelnikova, Danil Paschenko, Klavdiya Bochenina, and EvgenyKotelnikov. 2022. Lexicon-based methods vs. BERT for text sentiment analy-sis. In Analysis of Images, Social Networks and Texts: 10th International Confer-ence, AIST 2021, Tbilisi, Georgia, December 1618, 2021, Revised Selected Papers.Springer, 7183. Tomas Mikolov, Kai Chen, Greg Corrado, and Jerey Dean. 2013. Ecient esti-mation of word representations in vector space. arXiv preprint arXiv:1301.3781(2013). Ildik Piln, Pl H Brekke, Fredrik A Dahl, Tore Gundersen, Haldor Husby, ys-tein Nytr, and Lilja vrelid. 2020. Classicationof Syncope Casesin NorwegianMedical Records. In Proceedings of the 3rd Clinical Natural Language ProcessingWorkshop. 7984. NS Punith and Krishna Raketla. 2021. Sentiment analysis of drug reviews usingtransfer learning. In 2021 Third International Conference on Inventive Research inComputing Applications (ICIRCA). IEEE, 17941799. Ali Safaya, Moutasem Abdullatif, and Deniz Yuret. 2020. Kuisail at semeval-2020task 12: Bert-cnn for oensive speech identication in social media. In Proceed-ings of the Fourteenth Workshop on Semantic Evaluation. 20542059.",
  "Correct": "Medical-domain sentiment statements:Read all prescriptions proles provided by pharmacy!Have taken drug for 3+ years and by accident learned Ihadve side eects to it. I have experienced 80% of all ad-verse reactions listed; the worse being constant copiousamounts of choking mucus/phlegm from throat/sinus,asthmatic bronchitis, severe fatigue, etc. Never in a mil-lion years would I have guessed it was Lisinopril, butjust happened to be out of the medication for 3 daysand woke up on the 3rd day without any of the chok-ing phlegm in my throat &amp; bronchial tract everymorning for the past 3+ years. Current Doc (who didntinitially prescribe drug) is thrilled to discover the cul-prit hes been searching for 2+ years! Good-bye erro-neous early-stage COPD diagnoses, Im cured!",
  "None": "Contradictory language:Years ago I was on the older formula of Fentanyl and it worked won-ders with minimal dosage & breakthrough meds. After the companiesreformulated the drug it isnt nearly as good as it used to be & hasmany more side eects, brand depending. Mylan works best for me asfar as fewer side eects but none work for the 72 hours they are sup-posed to.",
  "CNN": "Non-domain sentiment statements:I am 56 year old female with Severe osteoporosis and osteoarthritus.My Ortho and Gyno Dr.said My bones were so frail I had no choicebut take forteo.I started in 2015 and after a few months of just over allweakness and being sick all the time low BP, I went to my PC Dr. Afterblood work he said your immune System has crashed get o the forteo!I was home bound had pneumonia etc.... Over all not well feeling . Imhappy for the ones who can take it with no side eects. !",
  "Bio+Clinical BERT": "Medical-domain sentiment statements:I have been a nurse since 1984 and a paramedic since1990. In New Orleans,in 1993, while working on an am-bulance, I became nauseated and began vomiting. Wenthome,changed ,had someone drive me 2 ER @ a Hos-pital in Harahan(nice subdivision.) I expected 2 get theusual treatment of IV Saline and the SAFE anti-emeticPhenergan. I told the ER DOC I was VERY ALLERGIC 2REGLAN. He injects me with Inapsine(Droperidol) be-cause he wants to see how it worked - even thoughpeople with allergy to Reglan should NEVER be givenInapsine. I had already been declared clinically dead 2years prior in a car accident, But was revived. This So-called drug causes Irregular heartbeats. I thought I wasgoing 2 die. It was much worse than actually dying."
}