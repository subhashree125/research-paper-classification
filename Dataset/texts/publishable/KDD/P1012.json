{
  "National Key Laboratory for Novel Software Technology, Nanjing University, China2 School of Artificial Intelligence, Nanjing University, China{chengzh,shanghp,qianc}@lamda.nju.edu.cn": "Abstract Network intrusion detection is one of the most important is-sues in the field of cyber security, and various machine learning tech-niques have been applied to build intrusion detection systems. However,since the number of features to describe the network connections is of-ten large, where some features are redundant or noisy, feature selectionis necessary in such scenarios, which can both improve the efficiencyand accuracy. Recently, some researchers focus on using multi-objectiveevolutionary algorithms (MOEAs) to select features. But usually, theyonly consider the number of features and classification accuracy as theobjectives, resulting in unsatisfactory performance on a critical metric,detection rate. This will lead to the missing of many real attacks andbring huge losses to the network system. In this paper, we propose DR-MOFS to model the feature selection problem in network intrusion de-tection as a three-objective optimization problem, where the number offeatures, accuracy and detection rate are optimized simultaneously, anduse MOEAs to solve it. Experiments on two popular network intrusiondetection datasets NSL-KDD and UNSW-NB15 show that in most casesthe proposed method can outperform previous methods, i.e., lead to fewerfeatures, higher accuracy and detection rate.",
  "Introduction": "With the development of the Internet, network intrusion appears more and morefrequently, threatening cyber security. For example, the core information infras-tructures of many organizations and institutions are always suffering from seriouscyber attacks. In October 2016, DynDNS that provides dynamic DNS serviceswas attacked by a large-scale DDoS, causing a lot of access problems to thewebsites. The attack made a large number of important websites paralyzed, e.g.,Twitter was even unable to be accessed for about 24 hours. In modern warfare,government websites and military command systems are also usually paralyzedby large-scale cyber attacks.",
  "Cheng et al": "19. Nguyen, B.H., Xue, B., Zhang, M.: A survey on swarm intelligence approaches tofeature selection in data mining. Swarm and Evolutionary Computation 54, 100663(2020)20. Qian, C.: Distributed Pareto optimization for large-scale noisy subset selection.IEEE Transactions on Evolutionary Computation 24(4), 694707 (2020)21. Qian, C., Bian, C., Feng, C.: Subset selection by Pareto optimization with recom-bination. In: Proceedings of the 34th AAAI Conference on Artificial Intelligence(AAAI20). pp. 24082415. New York, NY (2020)22. Qian, C., Shi, J., Yu, Y., Tang, K.: On subset selection with general cost con-straints. In: Proceedings of the 26th International Joint Conference on ArtificialIntelligence (IJCAI17). pp. 26132619. Melbourne, Australia (2017)23. Qian, C., Shi, J., Yu, Y., Tang, K., Zhou, Z.: Subset selection under noise. In:Advances in Neural Information Processing Systems 30 (NIPS17). pp. 35633573.Long Beach, CA (2017)24. Qian, C., Yu, Y., Tang, K., Yao, X., Zhou, Z.: Maximizing submodular or monotoneapproximately submodular functions by multi-objective evolutionary algorithms.Artificial Intelligence 275, 279294 (2019)25. Qian, C., Yu, Y., Zhou, Z.: Subset selection by Pareto optimization. In: Advancesin Neural Information Processing Systems 28 (NIPS15). pp. 17741782. Montreal,Canada (2015)26. Roostapour, V., Neumann, A., Neumann, F., Friedrich, T.: Pareto optimization forsubset selection with dynamic cost constraints. Artificial Intelligence 302, 103597(2022)27. Sharafaldin, I., Lashkari, A.H., Ghorbani, A.A.: Toward generating a new intru-sion detection dataset and intrusion traffic characterization. In: Proceedings ofthe 4th International Conference on Information Systems Security and Privacy(ICISSP18). pp. 108116. Funchal, Portugal (2018)28. Tavallaee, M., Bagheri, E., Lu, W., Ghorbani, A.A.: A detailed analysis of the KDDCUP 99 data set. In: Proceedings of the 2009 IEEE Symposium on ComputationalIntelligence for Security and Defense Applications (CISDA09). pp. 16. Ottawa,Canada (2009)29. Ustebay, S., Turgut, Z., Aydin, M.A.: Intrusion detection system with recursivefeature elimination by using random forest and deep learning classifier. In: Proceed-ings of the 2018 International Congress on Big Data, Deep Learning and FightingCyber Terrorism (IBIGDELFT18). pp. 7176. Ankara, Turkey (2018)30. Vasan, K.K., Surendiran, B.: Dimensionality reduction using principal componentanalysis for network intrusion detection. Perspectives in Science 8, 510512 (2016)31. Vijayanand, R., Devaraj, D., Kannapiran, B.: Intrusion detection system for wire-less mesh network using multiple support vector machine classifiers with genetic-algorithm-based feature selection. Computers & Security 77, 304314 (2018)32. Xue, B., Zhang, M., Browne, W.N., Yao, X.: A survey on evolutionary computationapproaches to feature selection. IEEE Transactions on Evolutionary Computation20(4), 606626 (2016)33. Zhang, L., Sun, X., Yang, H., Cheng, F.: Sparsity preserved Pareto optimizationfor subset selection. IEEE Transactions on Evolutionary Computation (2023)34. Zhang, Q., Li, H.: MOEA/D: A multiobjective evolutionary algorithm based ondecomposition. IEEE Transactions on Evolutionary Computation 11(6), 712731(2007)35. Zhou, Z., Yu, Y., Qian, C.: Evolutionary Learning: Advances in Theories andAlgorithms. Singapore: Springer (2019)",
  "Detection-Rate-Emphasized Multi-objective Feature Selection3": "for IDS based on NSGA-II. They considered the feature subset size and the clas-sification accuracy as objectives to optimize and used NSGA-II to solve it. Itcould make a good trade-off between the feature subset size and the accuracy,and achieved impressive success on three popular network intrusion detectiondatasets, NSL-KDD , UNSW-NB15 and CIC-IDS2017 . Note that thereare also a lot of works on evolutionary feature selection, which are not speciallyfor network intrusion detection. Please refer to .Though previous feature selection methods for network intrusion detectionhave achieved good results, they often consider the accuracy and the numberof features only in the problem formulation, while ignoring the detection rate,which is, however, very critical to the performance of an IDS. The detectionrate is the proportion of real attacks that are actually detected. In real-worldapplications, an IDS with high accuracy but low detection rate is meaningless,which will miss a large number of real attacks and bring immeasurable loss to thenetwork system. Therefore, for network intrusion detection, it is more necessaryto consider the detection rate rather than just focusing on the accuracy.In this paper, by considering the detection rate explicitly, we formulate fea-ture selection for intrusion detection as a three-objective optimization problem:minimizing the number of features, maximizing the classification accuracy andmaximizing the detection rate of attacks, which can be solved by any existingMOEA. To examine the effectiveness of our three-objective formulation, we em-ploy three typical MOEAs (i.e., NSGA-II , MOEA/D and NSGA-III ) inthe experiments. In the feature selection and final classification phase, multiplewrapper learners are tested, including CART decision tree , logistic regression(LR) and random forest (RF) . The empirical results on two commonlyused network intrusion detection datasets NSL-KDD and UNSW-NB15 showthat the solution set obtained under the three-objective modeling has clear ad-vantage (i.e., fewer features, higher classification accuracy and detection ratein most cases) over previous methods. Furthermore, the comparison betweenthe three-objective and bi-objective formulations using the same MOEA (i.e.,NSGA-II, MOEA/D or NSGA-III) validates the advantage of considering thedetection rate.The rest of the paper is organized as follows. introduces somerelated works about feature selection in network intrusion detection. introduces our proposed method based on three-objective problem formulation.Experiments are presented in . concludes the work.",
  "Search with MOEAs": "In recent years, some works formulated feature selection as a multi-objective op-timization problem and solved it with MOEAs. Some of them focused on multi-classification and set multiple objective functions to represent the classificationperformance on each class separately. De et al. proposed a multi-objectivefeature selection approach in IDS, using NSGA-II as the search algorithm and theGrowing Hierarchical Self-Organising Maps (GHSOM) as the classifier. Specif-ically, it used the Jaccard coefficient of each class to measure the classificationperformance on multiple classes. Thus, the number of objectives was equal tothe number of classes. Zhu et al. was inspired by the work and used animproved NSGA-III as a search strategy and GHSOM-pr as a classifier. Theyalso used the Jaccard coefficient to measure the suitability of the selected featuresubsets. However, since only the Jaccard coefficient of each class was consideredin the fitness function, the feature subset size was ignored, which led to a limitedoverhead reduction.As feature selection naturally involves two objectives, i.e., minimizing the fea-ture subset size and maximizing the accuracy, some works have employed MOEA",
  "Detection-Rate-Emphasized Multi-objective Feature Selection5": "to solve the corresponding two-objective formulation. For example, Khammassiand Krichen set the feature subset size and the classification accuracy as theoptimization objectives and used NSGA-II to solve the feature selection problemin IDS. Compared with previous works, it has achieved impressive performanceon the typical network intrusion detection datasets NSL-KDD, UNSW-NB15and CIC-IDS2017. The summary of related work is shown in .Through experimental studies, we find that their method has poor perfor-mance on detection rate, which is another critical metric in the field of networkintrusion detection, focusing on the frequency of missing attacks. In view of theabove shortcomings, we propose to model the feature selection in network intru-sion detection as a three-objective optimization problem, where feature subsetsize, classification accuracy and detection rate are optimized simultaneously, anduse MOEAs to solve it.",
  "Three-objective Formulation": "Feature selection aims to search for a feature subset from all the original features,which can achieve better performance on the optimization objectives. Based onthe observation that previous methods only consider the feature subset size andclassification accuracy as the objectives to optimize, which have poor perfor-mance on detection rate, another critical metric in the special field of IDS, we",
  "maxx{0,1}n(Size(x), Accuracy(x), DR(x)),(1)": "where a feature subset is represented by a binary string x {0, 1}n, in whichxi = 1 means the corresponding feature is selected, otherwise its not selected,and n is the total number of features. Size(x) denotes the number of features inthe feature subset x. Given a feature subset, we can evaluate its quality throughthe performance of a classifier trained on the feature subset. The classificationresult of a classifier trained on the feature subset x can be represented by the con-fusion matrix in . The classification accuracy is denoted as Accuracy(x),which describes the overall performance of a classifier. Under the notation in theconfusion matrix, it is calculated as",
  ". Confusion matrix": "Compared to the previous methods which mainly take feature size and clas-sification accuracy as the objectives to optimize, we additionally incorporatedetection rate as an optimization objective. This is because, in the field of net-work intrusion detection, rather than the normal traffic, we are more concernedabout the anomalous traffic that may trigger network attacks, especially on howmany of them are correctly identified and alerted by the IDS, since even onemissing attack may cause severe loss. In addition, the data of network intrusion",
  "Detection-Rate-Emphasized Multi-objective Feature Selection7": "detection is usually imbalanced, which means that the amount of normal trafficdata is much more than the anomalous traffic data, making the classification ac-curacy a less reliable metric to measure the detection ability of an IDS towardsattacks. In other words, as the number of attacks is very small, an IDS that onlyidentifies all the traffic as normal traffic can still have a very high accuracy, whichis not appropriate. Therefore, the detection rate of anomalous traffic should beemphasized in feature selection. Since our formulation considers detection rateadditionally, this allows MOEAs to discard solutions that perform well only inclassification accuracy but poorly in detection rate during the search process.The existence of such solutions is the main reason why previous methods performpoorly in detection rate but still have a high classification accuracy.",
  "Overall Framework": "In this subsection, we introduce the overall framework of building an IDS withour detection-rate-emphasized multi-objective evolutionary feature selection. Asshown in , the whole process can be divided into three stages: prepro-cessing stage, feature selection stage and classification stage. In the preprocessingstage, firstly, we clean the original network traffic data to ensure that there areno missing values or infinity values in the dataset. After that, the categoricalfeatures are converted into numerical features by ordinal encoding. Finally, thefeatures are normalized for the training of subsequent classifiers. The MOEAsare used in the feature selection stage to optimize the feature subsets which are",
  "Dataset Description and Preprocessing": "Two typical public network intrusion datasets NSL-KDD and UNSW-NB15 areused to evaluate our method. NSL-KDD is the updated version of the classicnetwork intrusion dataset NDD99, which has wiped off some of the inherentproblems and cleaned the invalid and redundant data. The dataset partition ofthe training set and testing set given by the official documentation is used in ourexperiments, which contains 125972 and 22543 instances respectively with fourmain attack types: DoS, Probe, R2L, and U2R. There are 41 features in eachinstance to describe the network connections. For convenience, we model it as abinary classification problem with normal and attack.The UNSW-NB15 dataset was created by the cyber security research groupat the Australian Centre for Cyber Security (ACCS) . The created features",
  "Detection-Rate-Emphasized Multi-objective Feature Selection9": "can be classified into five categories: flow features, basic features, content fea-tures, time features, and additionally generated features. We also use the officialdata partition of the training set and testing set in our experiments, which con-tains 175341 and 82332 items respectively. Each instance contains 42 features.Similarly, we model the IDS as a binary classifier that identifies normal andattack classes.During the data preprocessing stage, we remove instances with missing andinfinite values in the datasets, encode categorical features into numerical featureswith an ordinal encoder, and finally normalize all attributes to be between 0 and1. We randomly divide one-fifth of the training set as the validation set.",
  "Settings of Experiments": "Compared with the previous evolutionary feature selection methods, the maindifference in this paper is the problem formulation, where feature subset size,classification accuracy and detection rate are optimized simultaneously. As forthe selection of specific MOEA, we use the typical NSGA-II to compare ourmethod with the previous methods for feature selection in IDS. Then we compareour detection-rate-emphasized feature selection method with typical bi-objectiveand single-objective evolutionary feature selection methods. The single-objectivemethod sets classification accuracy as fitness function and is optimized byGA. The bi-objective method employs NSGA-II to search for Pareto optimalfeature subsets, where the feature subset size and classification accuracy are setas the objectives.For the feature selection methods based on evolutionary algorithms, as dif-ferent crossover and mutation operators will affect the search ability of the algo-rithms, for fair comparison, we uniformly use the same operators to generate theoffspring individuals in the experiments. According to the parameters adoptedby a large number of related works, we use the uniform crossover with proba-bility pc = 0.9, together with the bit-wise mutation operator with probabilitypm = 1, which is introduced in .2. Furthermore, the population sizeis set as P = 100 and the maximum number of generations is set as G = 500,which is sufficient for convergence.Some non-evolutionary feature selection methods are also examined for com-parison, including Sequential Forward Selection (SFS) and Recursive FeatureElimination (RFE) . Note that Principal Component Analysis (PCA) isone of the prominent dimensionality reduction techniques which is widely usedin the network traffic analysis. Therefore, we also use PCA to reduce the dimen-sion of feature space and compare with it. Since they need to manually specifythe number k of remained features, we try k = 5, 10, 15, 20, 25 separately in theexperiments and report the result with maximum accuracy.",
  "MethodCART Decision treeLogistic RegressionRandom Forestw/t/lSizeAccuracy(%)DR(%)SizeAccuracy(%)DR(%)SizeAccuracy(%)DR(%)": "DR-MOFS4.71.5 86.860.65 82.711.68 2.00.0 82.040.00 73.000.00 3.00.0 82.430.43 76.630.75-NSGA-II-2objs 8.03.4 84.250.89 76.091.21 5.42.3 79.790.72 66.741.565.64.179.740.28 68.142.199/0/0GA 26.22.6 80.381.79 67.953.03 23.42.7 76.080.44 60.180.80 24.00.6 77.561.14 63.122.289/0/0SFS 1081.7670.682578.0163.22580.9768.659/0/0RFE 1583.1072.351075.2561.692578.3564.219/0/0PCA 2579.1565.301577.5265.871077.0961.849/0/0Basic(without FS)4178.2264.074175.4761.854178.1163.599/0/0 Experimental results on NSL-KDD show that our method can achieve asignificant improvement in detection rate compared with the original featureswithout selection and previous feature selection methods. Moreover, our methodalso outperforms the comparison methods on the other two metrics.The experimental results on another dataset UNSW-NB15 are shown in Ta-ble 3. It can be seen that the original IDS constructed on the original fea-tures without selection already has good performance on detection rate, butour method can still achieve the best results in most cases. In particular, ourproposed DR-MOFS can always obtain better accuracy and detection rate thanthe two-objective method NSGA-II-2objs, which indicates the superiority of ourthree-objective formulation. So, our detection-rate-emphasized multi-objectiveevolutionary feature selection method can generally improve the performance ofthe IDS.The results in and only show the solution with the maximumtest accuracy in each method, and may not be able to show the overall perfor-mance of the solution set returned by MOEAs. To precisely illustrate that ourmethod can find solutions with better overall performance on each objective, we",
  "Detection-Rate-Emphasized Multi-objective Feature Selection11": ". DR-MOFS vs. other methods on the solution with max test accuracy ondataset UNSW-NB15. The best result in each column is bolded and / denotesDR-MOFS is significantly better/worse than the corresponding method by the t-testwith confidence level 0.05. w/t/l denotes the amount by which DR-MOFS is better,same or worse based on mean.",
  "n,(4)": "where n is the total number of features. Because the Pareto dominance relation-ship between solutions in the 3D objective space is not intuitive to illustrate, weproject the obtained solutions into the 2D objective space in pairs, as shown in. This experiment is conducted using CART decision tree as the clas-sifier on the NSL-KDD dataset. During the feature selection stage, DR-MOFSand NSGA-II-2objs obtain a set of solutions respectively, while other methodsobtain one solution respectively. This explains why the methods using MOEAshave multiple points shown in (red stars and yellow stars). Note thatwe test the performance of all the solutions in the non-dominated solution setreturned by NSGA-II, and then project them to the corresponding 2D surface.The red stars represent the results obtained by our method, some of which lie inthe upper right corner, indicating that they have the best performance. Specifi-cally, for each solution returned by the two-objective method NSGA-II-2objs andother comparison methods, there always exists at least one solution returned byour method that can dominate it. The results on the combination of NSL-KDDand LR are shown in .All in all, a comprehensive comparison on the three objectives shows that ourmethod consistently yields solutions that outperform the contrasting methods.In the real application, how to select the final feature subset to be used from aset of solutions should be determined according to the problem background andactual needs, and will not be further discussed here.",
  "Detection-Rate-Emphasized Multi-objective Feature Selection13": "The first ablation study is based on the following research question: As oneof the most common indicators for evaluating model performance in machinelearning, F1-score comprehensively considers precision and recall and providesa balanced metric. So can we directly use the feature subset size and F1-scoreas two-objective optimization to achieve the same good results? Based on this,we replace the three-objective optimization problem (i.e., feature subset size,accuracy and detection rate) considered by DR-MOFS with a two-objective op-timization problem (i.e., feature subset size and F1-score), and other componentsremain unchanged, represented by F1-MOFS. and are the re-sults on the NSL-KDD and UNSW-NB15 datasets, respectively. As before, thesolution with the highest test accuracy is shown for comparison. All solutionsare evaluated based on the three metrics we care most about: feature subsetsize (Size), accuracy (Acc), and detection rate (DR). For each set of metrics,better results are marked in bold. The experiments are repeated ten times andthe mean and standard deviation are recorded.According to the ablation results, it can be observed that except for theslight advantage of F1-MOFS in the number of features obtained using logisticregression on the UNSW-NB15 dataset, DR-MOFS can always achieve betterresults under other experimental settings. In particular, for the dataset NSL-KDD in which the detection rate of the base learner is inherently low, DR-MOFS can relatively bring about a greater improvement in the detection rate.This demonstrates the advantages of DR-MOFS in optimization modeling.",
  "SizeAccuracy(%)DR(%)SizeAccuracy(%)DR(%)SizeAccuracy(%)DR(%)": "DR-MOFS8.83.8 87.090.32 96.310.57 13.71.9 80.990.03 99.430.16 11.53.7 87.650.23 97.660.19F1-MOFS12.40.8 86.790.2195.810.29 11.40.8 80.910.0099.380.0015.22.387.560.1097.360.16Basic (without FS)4286.1895.884280.0597.254287.5597.54 Another ablation experiment is for the MOEA used for optimization. BesidesNSGA-II, we further examine NSGA-III and MOEA/D, and then compare thethree-objective and two-objective modeling using the same MOEA. The resultson NSL-KDD and UNSW-NB15 are shown in and , respectively.The comparison is still based on the solution with the highest accuracy on thetesting set, and three wrapper classifiers are examined. The experiments aredivided into two groups, each containing three-objective and two-objective mod-eling with identical search strategy. For each group, the better results on different",
  "MOEA/D-3objs 12.01.8 86.720.35 96.000.45 15.92.1 80.960.03 99.550.2215.31.6 87.440.24 97.440.30MOEA/D-2objs 9.22.5 86.180.4294.930.50 10.52.9 80.920.04 99.660.27 12.73.3 87.370.3197.200.31": "Obviously, except for the experimental combination of MOEA/D and LRon UNSW-NB15, the three-objective modeling can always have a better detec-tion rate than the two-objective modeling. Meanwhile, in most cases the three-objective modeling can also obtain better accuracy, with a comparable reduc-tion of feature subset size. The comparison of the ablation study under differentMOEA settings illustrates the advantages of the modeling of DR-MOFS (i.e.,feature subset size, accuracy, and detection rate) compared to the two-objectivemodeling (i.e., feature subset size and accuracy).",
  "Conclusion": "In this work, we propose DR-MOFS, a general multi-objective method for theimportant feature selection problem in the field of network intrusion detection,and employ MOEAs to solve it. Considering that previous methods only takefeature subset size and classification accuracy as the objectives during the opti-mization process, leading to unsatisfying performance on a critical metric, i.e.,detection rate, we analyze the necessity of emphasizing detection rate and pro-pose the three-objective formulation, where feature subset size, classificationaccuracy and detection rate are optimized simultaneously. Experiments on twotypical public network intrusion datasets NSL-KDD and UNSW-NB15, and threewrapper classifiers CART, LR, and RF show that our three-objective formula-tion can generally obtain better performance than the previous feature selectionmethods for IDS. The ablation study between two-objective modeling and three-objective modeling with different MOEAs further shows that our formulation canachieve a notably better detection rate with better classification accuracy andcomparable feature subset size.",
  "Detection-Rate-Emphasized Multi-objective Feature Selection15": "1. Back, T.: Evolutionary Algorithms in Theory and Practice: Evolution Strategies,Evolutionary Programming, Genetic Algorithms. Oxford University Press (1996)2. Bian, C., Qian, C., Neumann, F., Yu, Y.: Fast Pareto optimization for subset selec-tion with dynamic cost constraints. In: Proceedings of the 30th International JointConference on Artificial Intelligence (IJCAI21). pp. 21912197. Virtual Event(2021)3. Bian, C., Zhou, Y., Qian, C.: Robust subset selection by greedy and evolutionarypareto optimization. In: Proceedings of the 31st International Joint Conference onArtificial Intelligence (IJCAI22). pp. 47264732. Vienna, Austria (2022)4. Bishop, C.M., Nasrabadi, N.M.: Pattern Recognition and Machine Learning.Springer (2006)5. Breiman, L.: Random forests. Machine Learning 45(1), 532 (2001)6. Breiman, L., Friedman, J.H., Olshen, R.A., Stone, C.J.: Classification and Regres-sion Trees. Wadsworth (1984)7. Deb, K., Jain, H.: An evolutionary many-objective optimization algorithm usingreference-point-based nondominated sorting approach, part I: Solving problemswith box constraints. IEEE Transactions on Evolutionary Computation 18(4),577601 (2013)8. Deb, K., Pratap, A., Agarwal, S., Meyarivan, T.: A fast and elitist multiobjec-tive genetic algorithm: NSGA-II. IEEE Transactions on Evolutionary Computation6(2), 182197 (2002)9. Dua, D., Graff, C.: UCI machine learning repository (2017), Friedrich, T., Neumann, F.: Maximizing submodular functions under Matroid con-straints by evolutionary algorithms. Evolutionary Computation 23(4), 543558(2015)11. Gu, Y.R., Bian, C., Li, M., Qian, C.: Subset selection for evolutionary multi-objective optimization. IEEE Transactions on Evolutionary Computation (2023)12. De la Hoz, E., De La Hoz, E., Ortiz, A., Ortega, J., Martnez-Alvarez, A.: Featureselection by multi-objective optimisation: Application to network anomaly detec-tion by hierarchical self-organising maps. Knowledge-Based Systems 71, 322338(2014)13. Iglesias, F., Zseby, T.: Analysis of network traffic features for anomaly detection.Machine Learning 101(1-3), 5984 (2015)14. Khammassi, C., Krichen, S.: A GA-LR wrapper approach for feature selection innetwork intrusion detection. Computers & Security 70, 255277 (2017)15. Khammassi, C., Krichen, S.: A NSGA2-LR wrapper approach for feature selectionin network intrusion detection. Computer Networks 172, 107183 (2020)16. Lee, J., Park, D., Lee, C.: Feature selection algorithm for intrusions detection sys-tem using sequential forward search and random forest classifier. KSII Transactionson Internet and Information Systems 11(10), 51325148 (2017)17. Moustafa, N., Slay, J.: UNSW-NB15: A comprehensive data set for network in-trusion detection systems (UNSW-NB15 network data set). In: Proceedings of the2015 Military Communications and Information Systems Conference (MilCIS15).pp. 16. Canberra, Australia (2015)18. Moustafa, N., Slay, J.: The evaluation of network anomaly detection systems: Sta-tistical analysis of the UNSW-NB15 data set and the comparison with the KDD99data set. Information Security Journal: A Global Perspective 25(1-3), 1831 (2016)"
}