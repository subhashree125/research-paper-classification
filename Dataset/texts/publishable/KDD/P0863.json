{
  "Abstract": "Causal effect estimation (CEE) provides a crucial tool for predict-ing the unobserved counterfactual outcome for an entity. As CEErelaxes the requirement for perfect counterfactual samples (e.g.,patients with identical attributes and only differ in treatments re-ceived) that are impractical to obtain and can instead operate onobservational data, it is usually used in high-stake domains like med-ical treatment effect prediction. Nevertheless, in those high-stakedomains, gathering a decently sized, fully labelled observationaldataset remains challenging due to hurdles associated with costs,ethics, expertise and time needed, etc., of which medical treatmentsurveys are a typical example. Consequently, if the training datasetis small in scale, low generalization risks can hardly be achievedon any CEE algorithms.Unlike existing CEE methods that assume the constant avail-ability of a dataset with abundant samples, in this paper, we studya more realistic CEE setting where the labelled data samples arescarce at the beginning, while more can be gradually acquired overthe course of training assuredly under a limited budget consid-ering their expensive nature. Then, the problem naturally comesdown to actively selecting the best possible samples to be labelled,e.g., identifying the next subset of patients to conduct the treat-ment survey. However, acquiring quality data for reducing the CEErisk under limited labelling budgets remains under-explored untilnow. To fill the gap, we theoretically analyse the generalizationrisk from an intriguing perspective of progressively shrinking itsupper bound, and develop a principled label acquisition pipelineexclusively for CEE tasks. With our analysis, we propose the ModelAgnostic Causal Active Learning (MACAL) algorithm for batch-wise label acquisition, which aims to reduce both the CEE modelsuncertainty and the post-acquisition distributional imbalance si-multaneously at each acquisition step. Extensive experiments are",
  "Corresponding Author": "Permission to make digital or hard copies of all or part of this work for personal orclassroom use is granted without fee provided that copies are not made or distributedfor profit or commercial advantage and that copies bear this notice and the full citationon the first page. Copyrights for components of this work owned by others than theauthor(s) must be honored. Abstracting with credit is permitted. To copy otherwise, orrepublish, to post on servers or to redistribute to lists, requires prior specific permissionand/or a fee. Request permissions from 25, August 37, 2025, Toronto, Canada 2025 Copyright held by the owner/author(s). Publication rights licensed to ACM.ACM ISBN XXX-X-XXXX-XXXX-X/25/08",
  "Introduction": "Understanding causal effects to support decision-making in high-stake domains is crucial, where typical examples include random-ized control trials in medication , A/B testing for businessdecision-making , and the potential in advancing big data man-agement . As performing large-scale and statisticallyreliable human tests is prohibitively costly, algorithms for causaleffect estimation (CEE) using passively observed data samples havebecome a promising solution . In short, a CEE algorithmis trained with observational data to predict the counterfactualoutcome for an entity, e.g., what the outcome will be if a patientreceived the other treatment, instead of the one already had.To perform CEE, a common practice is to build a regressionmodel that estimates a continuous effect value ,which is trained on the observational data containing two groups ofsamples. The groups are formed based on the treatment1 imposedon each sample, where each sample consists of raw attributes drawnfrom a well-defined feature space (e.g., a patients health indicators),and a label that corresponds to the observed outcome after receivingthe binary treatment (e.g., blood sugar concentration after takingone diabetes medicine).",
  "KDD 25, August 37, 2025, Toronto, CanadaWen et al": "C Pilat, T Frech, A Wagner, K Krger, A Hillebrecht, J Pons-Khnemann, CScheibelhut, R-H Bdeker, and F-C Mooren. 2015. Exploring effects of a naturalcombination medicine on exercise-induced inflammatory immune response: Adouble-blind RCT. Scandinavian Journal of Medicine & Science in Sports 25, 4(2015), 534542. Robert Pinsler, Jonathan Gordon, Eric Nalisnick, and Jos Miguel Hernndez-Lobato. 2019. Bayesian batch active learning as sparse subset approximation.Advances in neural information processing systems 32 (2019).",
  "Preliminaries2.1Causal Effect Estimation": "Under the potential outcome framework , the individual treat-ment effect (ITE) is expected to be estimated with the tabular datasetD = {x,,}=1, where x, , are respectively the raw featurevariables, observed treatment, treatment outcome that correspondto the -th individual. For simplicity, we consider the binary treat-ment of 1 and 0 to denote the different treatment statuses, respec-tively. The ground truth ITE for an individual with feature vectorx is defined as:",
  "(x) = E[=1 =0|x],(1)": "where =1 and =0 are the unobserved potential outcomes withtreatment = 1 and = 0 respectively. Generally, under the deepneural network learning framework , the common practice isto transform the raw variable x into the latent representation z forindividual , then such representation is utilised for ITE prediction.To evaluate the performance of the CEE model, the generalizationrisk of the model denoted by PEHE, is defined in (2) according tothe well-recognized literature . The lower the value of PEHE,the better the performance of the predictor.",
  "When CEE meets active learning, the general logistics of the querysteps become: 1) Let the CEE model get trained on the labelledtraining set Dtrain = {x,,}train=1 . 2) Given the unlabelled pool": "set Dpool = {x,}pool=1 , the pre-defined label acquisition criterion(normally has trained model embedded, e.g., uncertainty-awareCEE model ) examines through the pool set and returns a subsetof it, i.e., D, for the oracle to label. 3) The labelled subset D is addedto the training set for which the CEE model can get updatedbefore the upcoming querying round starts, then return to Step 1).Note, that the samples with attributes are already available in thepool set but without the labels, the process only attaches groundtruth labels to them. Such a recursive procedure terminates mostlywhen the desired performance is reached or the labelling budgetgets exhausted. Subsequently, lets take one step further from theconventional CEE problem defined in Definition 2, we form theresearch problem of CEE under the AL paradigm as follows: Definition 3 (Active Causal Effect Estimation). Causaleffect estimations with active learning aims to expand the currentdataset with more informative samples such that the trained modelsestimation risk PEHE can be significantly reduced before the exhaus-tion of the labelling budget. It is noted that the Assumption 3 regarding positivity is a vulner-able one in the real-world scenario for the CEE research field. Therisk of deviating from such an assumption and thus leading to theunidentifiable causal effect has been widely discussed in . Asa result of the active causal effect estimation defined in Definition 3,if the selective labelling process keeps introducing more imbalance(e.g., a non-negative crucial part of the CEE risk upper bound )to the current treatment groups distributions, the use of AL toexpand the labelled dataset will hardly help obtain optimal CEEmodel with significant estimation risk reduction. However, as wewill discuss in the following, AL also sheds light on reducing theestimation risk by expanding the dataset if it is properly configured.Assume that we initially have a large enough pool set Dpool, butlabelling all the samples, i.e., obtaining all ITEs, is infeasible dueto the considerable cost of time and capital. Ideally, there existsa smallest optimal subset Dopt where the positivity assumptionholds across the sample space X. Additionally, treatment groupsdistributions, =1opt and =0opt , are identical such that the distribu-tional discrepancy measured by integral probability metric (IPM) isstatistically zero, i.e., IPM(=1opt , =0opt ) = 0. Given a sparse warm-upset (at = 0 query step), the current distributions of the treat-ment groups, i.e., =1=0 and =0=0, are realistically not the same, i.e.,IPM(=1=0, =0=0) = I=0 0. During the recursive selective labellingprocess, a growing number of samples are added into the trainingset Dtrain the challenge is, the current disparity between differenttreatment groups distributions can be amplified, e.g., I=10 I=0after 10 uncontrolled query steps, thus further countering the pos-itivity even with more data. Meanwhile, the opportunity is, withproper acquisition setup, we can not only reduce the imbalancein the training set after every query step, i.e., I+1 I, but alsoquickly converge to the optimal set by using the smallest budget,e.g., for each of the treatment group , IPM(opt, =I) 0 after Iiterations, reaching the lowest risk.Therefore, keep reconciling the positivity assumption during theactive learning process plays a crucial role in obtaining a lower riskfor CEE. In what follows, we detail our label acquisition design inevery query step to fulfil this principle.",
  "Methodology3.1Theory and Practice": "In this paper, we focus on batch-mode active learning (BMAL). Thereason for conducting batch-mode active learning is to acquire moresamples at one query step for the oracle to label them, thus reducingthe frequency of retraining the model in case the model training iscostly. In the following, we propose a maximum risk upper boundreduction theorem for CEE with active learning, and the main proofof the general theorem Theorem 1 is provided in Appendix A.1,followed by the sub-proofs for each of the convergence analysis inAppendix A.2 and A.3.",
  "+0 ) with constant 0 R+": "Remark 1. The bound shrinkage B at -th query step constitutesthe variance difference and the distributional discrepancy difference,solely focusing on the reduction of one term would not contributeto optimal risk reduction for active causal effect estimation, while aproper combination of such two terms can lead to the optimal result. Toy Dataset: We design a fully synthetic 1-dimensional toydataset and conduct experiments on four kinds of acquisition func-tions, i.e., Random, Uncertainty, Symmetry and Uncertainty + Sym-metry (our proposed method MACAL), to illustrate the importanceof considering both model variance and data distributional discrep-ancy reduction in each query step. The simulation of the toy datasetare described in Appendix B.2.In , we present the empirical evaluation of the four meth-ods in terms of the PEHE PEHE, Wasserstein distance, andmodel variance respectively. As shown in (b) and (c), the Symmetry and Uncertainty acquisition strategies achievethe fastest reduction solely in distributional discrepancy and modelvariance respectively among the three naive methods. When map-ping their performance into the empirical risk reduction shown in (a), Symmetry has faster empirical risk reduction than Un-certainty in the early stage, but it saturates due to the incapabilityof capturing the informative uncertain samples in the late stage.While MACAL combines both aspects, it brings consistent and sig-nificant risk reduction before convergence, and it is the quickestone to achieve the lowest risk.",
  "Algorithm": "According to Theorem 1, we aim to optimize the upper boundshrinkage at each query step, additionally, it is well recognized thatin BMAL, sample diversity in the acquired batch is crucial ,thus we modify the shrinkage without loss of generality to caterthe BMAL and aim to maximize the following at -th query step:",
  "{0,1}H( D ),(4)": "where H() measures the entropy of the set, and the union of thebatches for each of the treatment groups, D=1and D=0, rendersthe acquired batch D at -th query step.Note, that the optimization in (4) is a combinatorial problem.For example, to label | D | = samples out of the pool samples|Dpool| = pool at a time, we face a combinatorial search space",
  "which takes O(pool!": "!(pool )!) time to get the optimum. The brute-force suffers from such time complexity is prohibitive as pool goesup given fixed 1 pool. Thus, instead of leveraging theprototype criterion in (4), we propose a model agnostic method toapproximate the terms in (4) to reduce the NP-hard problem to onethat can be solved in polynomial time. In the following, we analysethe optimization objective in (4) separately and combine them toconquer afterwards.Diversity. To deal with the diversity term H( D ) with combi-natorial nature, the key step here is to select the sample which ismost distinguished from the acquired data in the batch iterativelyone at a time. We use the Euclidean distance (, ) to measure thesimilarity between two points for label acquisition. For a batch",
  "convergence rate of the model variance is lower-bounded by (),where 0 < 1": "Uncertainty. To gain the maximum variance reduction overthe sample space X, labelling the most uncertain sample gives thehighest variance reduction and the model variance can converge asdepicted in Lemma 2, where the proof is provided in Appendix A.2.However, the variance term is model-dependent, after one sam-ple point is added into the acquired batch D , the model shouldideally get retrained and update its confidence on the pool set forthe next selection to maintain the batch diversity H( D ) and vari-ance reduction Var ( D ) at a high level, but retraining | D | timesis not cost-efficient. To overcome this issue, we perform an ap-proximation for the variance term to leave it model-independentsince we care less about its exact value but more about its relativemagnitude for comparison, i.e., acquiring the most distinct pointfrom the pool set Dpool with the highest Euclidean distance fromits nearest neighbour in the training set (with previously acquiredunlabelled samples integrated). Thus, we firstly calculate the mini-mum distance between every candidate sample from pool set Dpooland the acquired sample from training set Dtrain, which results in aset of distance {min} of size pool. This set of values embeds bothdiversity and uncertainty in terms of Euclidean distance since thehigher the minimum value, the more distinct the candidate pointfrom the training set. Subsequently, the maximum one is selectedfrom the set as follows:",
  "( ) = arg max Dpoolmin Dtrain( , ).(5)": "Note, that the unlabelled sample ( ) should be added into thetraining set before the next selection starts because a similar orrepetitive sample is redundant. It should also be noted that (5)does not necessarily return the most uncertain sample, but thelarger distance from its in-sample nearest neighbour is positivelycorrelated with higher uncertainty. Thus, we take this trade-offto approximately approach the NP-hard term H( D )Var ( D ) by",
  "iterating | D | times. By considering the enumeration through bothof the treatment groups, the time complexity of one query step for(5) is O(max{(=1pool)2, (=0pool)2}), which is obviously capped by": "O( 2pool).Distributional Discrepancy. In light of the above-mentionediterative acquisition within a single query step, we can apply a sim-ilar mentality to avoid the combinatorial nature of the second termin (4) for the batch acquisition. To obtain a high-level reductionIPM ( D), an effective labelling in terms of reducing the imbalancewould lead to symmetrical acquisition, namely labelling the identi-cal sample from different treatment groups to make a pair. Thus thelocal distributional discrepancy (within the acquired dataset D)becomes zero if identical (or very similar) samples can be collected to counteract the violation of positivity locally. Subsequently, theaccumulated global distributional discrepancy gains an asymptoticbehaviour approaching zero as more symmetrical (or similar) sam-ples are added into the training set (as also empirically observedin (b)). We propose Lemma 3 concerning the convergencerate with the proof provided in Appendix A.3:",
  "+0 )if the identical samples from two groups can always be found through-out the query steps": "Note, that under the deep learning framework , the dis-tributional discrepancy is calculated over the latent space with : X Z, where is one-on-one mapping. Thus, samples thatare identical or similar in the original space X should still preservetheir semantic manifold in the latent space, such that labelling sim-ilar points over the raw space is the same as the one in latent space.To label a pair, we calculate the Euclidean distance between eachsample from different treatment groups, and the optimal pair isselected with the smallest distance. This selection is flexible sinceit does not constrain the identical acquisition but the most simi-lar pair. Thus, the time complexity to get the optimal pair takesO(=1pool =0pool), which is capped by O( 2pool). At a single iteration,we acquire a pair as follows:",
  "(7)": "Note, that we require the batch size | D | to be an even number,which is quite easy to satisfy. Thus, we do | D |/2 efficient iterationsto obtain the batch in one query step. Also, we set the coefficient to penalize the acquisition that violates the positivity assumption,this regularization constant is taken as a hyperparameter and itsimpact is further discussed in Appendix 5.3 since it is hardly possibleto compute the exact value for the bounded constant . Wevisualize the dynamic selection process in according tothe selection criterion defined in (7). For the case where one of thetreatment pool sets is exhausted, the acquisition is down to onlyone side by simply updating the = 0 since no counterpart can beacquired anymore. The full algorithms pseudo code is provided inAppendix A.6.In summary, MACAL promotes variance and discrepancy reduc-tion by labelling diverse uncertain samples and it penalizes thedissimilarity of the paired samples via the Euclidean distance. Tolabel a batch of samples of size | D |, we take O( 2pool) time com-plexity to obtain the optimal batch at each query step, which issignificantly lower than the cost to solve the NP-hard problem bybrute-force.",
  "Selected pair and not labelling": ": At -th query step, the entire batch selection is divided into several pairs selection. Left: The most uncertain points arethe candidates for selection, and the pair score is penalized by the distance between two points; Mid: The two most uncertain andclosest points are selected (not labelled yet) and objectively bringing down other unlabelled points uncertainty in proximity;Right: Select the next pair recursively until the batch is filled up.",
  "Related Work": "Active Learning. The history of active learning can be traced backto over a century ago , with such a long time progress till nowa-days, it has become a frontier research branch of machine learning. The core of active learning is to make model perfor-mance cost-efficient, i.e., obtaining relatively low model risk withas few labelled samples as possible. Generally, the active learningapproach can be portioned into three scenarios: query synthesis, stream-based and pool-based . In this paper, we focuson pool-based active learning, especially on regression problems,where the uncertainty-based sampling , density-based querying, and hybrid strategies are three key acquisition methodsunder such setting. For instance, the information-theoretic basedBayesian Active Learning by Disagreement (BALD) leveragesthe epistemic uncertainty to acquire unlabelled samples. Core-Set selects the greatest distance to its nearest neighbour in the hid-den space. ACS-FW is a hybrid between Core-Set and Bayesianapproaches which balances the sample diversity and uncertaintyin batch-mode acquisition. Note, that although the general activelearning methods are not designated for CEE, benchmarking onthese methods provides insightful results.Causal Effect Estimation with Active Learning. Some notice-able advances have been made in this area of research. approxi-mates the decision-making reliability via the estimated S-type errorrate (the probability of the model inferring the sign of the treatmenteffect wrong) of the prediction model, which is then used as thequerying criterion. However, focuses on estimating the correctsign of the treatment effect, which is different from the risk metricin our setting. For works focusing on the same risk metric, QHTE integrates the Core-Set concept to form a theoreticalframework, for which a theory-based optimization is proposed.However, the QHTE relaxes the tightness of the bound given byShalit et. al. , where a covering radius = 0 from the relaxedbound cannot even obtain the original tightness, while, we proposea more informative theory which does not undermine the tightnessof the original bound. More importantly, QHTE does not considerthe distribution imbalance during sample acquisition, which is what",
  "IHDP10104647075202IBM505050954031806250CMNIST505050315001050018000": "our method can prominently distinguish from. To fix the acquisi-tion imbalance issue, Causal-BALD cut into the problem fromthe information-theoretic perspective, its most representative cri-terion BALD accounts for the overlapping by especially scalingthe criterion with the inverse of counterfactual variance, leavingthe acquisition toward pairing up similar samples if its counter-factual were missing, which is a non-trivial improvement from itsbase - BALD (an uncertainty-based softmax-BALD method ).Our proposed method is distinguished from in several points.First, Causal-BALD relies on model-dependent variance estimation,e.g., the deep kernel learning model , while our criterion ismodel agnostic. Second, we cut into the problem from an intrigu-ing perspective to maximize the upper bound shrinkage at eachquery step instead of the mutual information perspective. Finally,taking the inverse of the counterfactual variance is undesirableand causes numerical instability, while our method leverages thesimple but effective addition and subtraction operations to formthe label acquisition criterion. It is also noted that some existingliterature uses active learning to take the initiative for effi-cient experimental trials design, i.e., the pool set does not includethe treatment information but enforcing treatment after sampleacquisition, which is different from our setting.",
  "Experiments": "Due to the unique nature of the CEE tasks, the counterfactual effectis hardly observed in the real world. Thus, in this paper, we take thecommon practice to utilise the fully-synthetic and semi-syntheticdatasets for algorithm evaluations.Dataset: IHDP - an imbalanced dataset based on 747 sam-ples (among them 139 with treatment status = 1 and 608 with",
  "Progressive Generalization Risk Reduction for Data-Efficient Causal Effect EstimationKDD 25, August 37, 2025, Toronto, Canada": "status = 0) and 25 covariates, with 100 times simulated treatmentoutcomes by . IBM - uses a cohort of 100k individuals fromthe publicly available Linked Births and Infant Deaths Databasewith 177 real-world covariates. Each original simulation randomlytakes 25k out of such 100k samples and the potential outcomes aresimulated 10 times according to , we create more imbalance byomitting additional samples from treatment group = 1. CMNIST - is of size 60k adapted from MINIST dataset. The inputfrom CMNIST is the handwritten digit of size 2828, which is dis-tinct from the previous tabular datasets. The potential outcomesare simulated 10 times and generated by projecting the digits intoa 1-dimensional latent manifold as described in .Metric: We use precision in estimation of heterogeneous effect(PEHE) , a well-established metric with the empirical formu-",
  "lation: PEHE =": "=1((=1 =0) )2/ for measuring theaccuracy of the treatment effect estimation at the individual level.The lower the value of PEHE, the better the performance.Baselines: We set the Random method as the benchmark ac-quisition function, as this is the most naive method that selectsthe data purely at random. We also compare our proposed methodagainst many SOTA baselines from the general AL research field,that is, BADGE , BAIT , and LCMD . We argue that agood comparison to these methods from the broad AL research isindispensable and this paper also fills the blank for such compar-isons. Moreover, the most related work - QHTE , and especiallyCausal-Bald is the designated algorithm proposed to deal withthe active causal effect estimation. Thus, we compare three repre-sentative variants of the Causal-Bald, namely BALD, BALD, andBALD.Prediction Backbone: DUE-DNN. It is one of the SOTAdeep kernel learning frameworks with the multi-layer perceptronas the common feature extractor and two sparse Gaussian processregressions defined over the extracted latent features as the down-stream estimators for different treatment groups effect estimations.DUE-CNN. It is a variant of the DUE model especially cateringfor the image-as-input experiment. It has a similar structure asDUE-DNN besides the latent feature extractor being replaced bythe convolutional neural network (CNN), e.g., the ResNet is em-bedded. The computation resources and hyperparameter selectionare described in B.3.Acquisition setup: We begin with a small Start Size (Start S.)to simulate the real-world scenario where only sparse labelled datacan be accessed at the beginning. Then, a fixed Step Size (Step S.) isenforced at each query step, and the entire AL sessions (Queries),which consist of many query steps comes to an end when the modelconverges or the sample pool has been exhausted. The detail of thelabel acquisition setup is summarized in .",
  "Baseline Risk Evaluation": "Generally, across all figures, MACALs performance set an empiricalrisk lower bound for all the other baselines. On the IHDP dataset,our proposed method obtains a lower risk till 160 training size(turning point). Then, it performs similarly to the other methodstill the exhaustion of the pool set. This phenomenon is explainabledue to the fact that the samples from treatment group = 1 getexhausted at the turning point, and MACAL can only acquire the",
  "(f) CMNIST-GeneralAL": ": Benchmarking with the available SOTAs on threedatasets, i.e., IHDP (average with 100 simulations), IBM (av-erage with 10 simulations) and CMNIST (average with 10simulations). The first column concludes the comparisonsagainst the baselines designated for active causal effect es-timation. The second column shows the comparisons withthe baselines from general active learning approaches. Allof the results are given by the same downstream CEE modelby DUE-DNN for IHDP & IBM, and DUE-CNN for CMNIST. samples from the treatment group ( = 0) without benefiting fromthe reduction of distributional discrepancy by labelling similar pairs.It is also arguable that when deploying the general AL methods, e.g.,BADGE, directly into active causal effect estimation, it is interestingto see that even the Random method can perform similarly to theseSOTAs. We overall see a better performance of causal AL methods,e.g., Causal-BALD, and MACAL, over the general AL methods byadditionally considering reducing the violation of positivity duringlabel acquisition.Moreover, none of the current SOTAs focusing on active causaleffect estimation can consistently outperform the other methodsfrom the general active learning research field across all the datasets.QHTE mostly underperforms because it only focuses on selectingthe point that has the maximum distance from its closest neigh-bour in the current training set without meaningful constraints",
  ": Hyperparameter representing various levels of symmetrical regularization for label acquisition. The relativeperformance of MACAL_ is calculated as PEHE,=0/PEHE,= , the higher the better": "on post-acquisition imbalance on raw features. Also, even thoughBALD is the most representative method from incorporat-ing the imbalance penalization in its query criterion, such indirectregularization via counterfactual uncertainty is not as optimal asours. Because MACAL directly reduces the post-acquisition dis-tributional imbalance by acquiring more similar pairs based onraw features. It is also noted that the division-form criterion ofCausal-BALD can embed immense variation (the performance ofall its variants fluctuates drastically) in estimations as shown in(e), while our proposed simple addition-form criterion issignificantly more stable.",
  "To give a direct comparison of acquisition quality, we visualize theresults in by projecting the post-acquisition training set": "from three acquisition criteria, i.e., Random, BALD, and MACAL,on each dataset at two different query stages into the 2-dimensionallatent space via t-SNE . From (a) to 4(f) across threedatasets, we observe that the Random draw from the original distri-bution inherently expresses a strong violation of positivity acrossthree different datasets, such that we barely see large overlappingregions. While, BALD shown in (g) to 4(l) looks slightlybetter than the Random method by being more spread out, but itstill cannot well resolve the violation of the positivity issue at largescale, rendering a significantly imbalanced label acquisition for dif-ferent treatment groups. As for MACAL, we observe an exceptionalacquisition result from (m) to 4(r), each of the samples fromboth of the treatment groups can mostly find its (close) counterfac-tual such that the violation of positivity is significantly reduced. The",
  "Symmetrical Regularization Study": "We conduct extensive ablation experiments for {0, 1, 2.5, 5, 10},a clear observation is that, even though the benefit of setting thesymmetrical regularization is non-trivial, there is no single hy-perparameter that can consistently outperform all the othersthroughout the entire label acquisition process. Also, the strongerregularization, e.g., = 10, delivers better performance at the earlystage of the acquisition, but such an advantage cannot be main-tained across the whole acquisition process. Interestingly, duringthe course of the acquisition, a decreasing coefficient empiricallygrants an increasing relative performance, e.g., = 2.5 underper-forms = 10 at the early stage, but it outperforms = 10 in thelater stage. This is explainable because when the key set of theoverlapping samples is mostly collected, there is less informationcan be obtained from acquiring the repetitive samples even thoughthese are from the overlapping region. The criterion should biasits acquisition toward the uncertain non-overlapping area to gainmore information to reduce the risk of the model.",
  "Conclusion": "In this paper, we study the well-under-explored yet important andpractical active causal effect estimation problem and construct atheoretical framework from a novel and intriguing perspective, i.e.,decompose a more informative risk upper bound without looseningit and give mathematically guaranteed risk convergence analy-sis under certain conditions. Therefore, in theory we maximizethe decomposed terms at each query step in order to minimizethe generalization risk. Subsequently, we derive a theory-inspiredsimplified yet effective label acquisition algorithm, i.e., MACAL,which considers the joint reduction of the models variance andpost-acquisition distributional imbalance via a simplified yet effec-tive label acquisition criterion. Moreover, reaching data-efficientlabelling is never an NP-hard problem via MACAL, and thus theoptimum can be obtained in polynomial time with O( 2). It isgenerally demonstrated that our proposed method consistentlyoutperforms the other baselines across all the datasets with a non-trivial performance gain. This work is supported by the Australian Research Council un-der the streams of Future Fellowship (No. FT210100624), Discov-ery Early Career Researcher Award (No. DE230101033), Indus-trial Transformation Training Centre (No. IC200100022), Discov-ery Project (No. DP240101108 and No. DP240101814), and LinkageProject (No. LP230200892). Partial support from Health and Well-being Queensland is gratefully acknowledged. HW would like toadditionally thank the invaluable support from Carrie Chen.",
  "Jordan Ash, Surbhi Goel, Akshay Krishnamurthy, and Sham Kakade. 2021. Gonefishing: Neural active learning with fisher embeddings. Advances in NeuralInformation Processing Systems 34 (2021), 89278939": "Jordan T Ash, Chicheng Zhang, Akshay Krishnamurthy, John Langford, andAlekh Agarwal. 2019. Deep Batch Active Learning by Diverse, Uncertain GradientLower Bounds. In International Conference on Learning Representations. Vinod Kumar Chauhan, Jiandong Zhou, Ghadeer Ghosheh, Soheila Molaei, andDavid A Clifton. 2024. Dynamic inter-treatment information sharing for indi-vidualized treatment effects estimation. In International Conference on ArtificialIntelligence and Statistics. PMLR, 35293537.",
  "Jennifer L Hill. 2011. Bayesian nonparametric modeling for causal inference.Journal of Computational and Graphical Statistics 20, 1 (2011), 217240": "David Holzmller, Viktor Zaverkin, Johannes Kstner, and Ingo Steinwart. 2023. Aframework and benchmark for deep batch active learning for regression. Journalof Machine Learning Research 24, 164 (2023), 181. Nguyen Quoc Viet Hung, Huynh Huu Viet, Nguyen Thanh Tam, Matthias Wei-dlich, Hongzhi Yin, and Xiaofang Zhou. 2017. Computing crowd consensus withpartial agreement. IEEE Transactions on Knowledge and Data Engineering 30, 1(2017), 114.",
  "Guido W Imbens and Donald B Rubin. 2015. Causal inference in statistics, social,and biomedical sciences. Cambridge University Press": "Andrew Jesson, Sren Mindermann, Yarin Gal, and Uri Shalit. 2021. Quantifyingignorance in individual-level causal-effect estimates under hidden confounding.In International Conference on Machine Learning. PMLR, 48294838. Andrew Jesson, Sren Mindermann, Uri Shalit, and Yarin Gal. 2020. Identifyingcausal-effect inference failure with uncertainty-aware models. Advances in NeuralInformation Processing Systems 33 (2020), 1163711649. Andrew Jesson, Panagiotis Tigas, Joost van Amersfoort, Andreas Kirsch, UriShalit, and Yarin Gal. 2021. Causal-bald: Deep bayesian active learning of out-comes to infer treatment-effects from observational data. Advances in NeuralInformation Processing Systems 34 (2021), 3046530478.",
  "Fredrik Johansson, Uri Shalit, and David Sontag. 2016. Learning representationsfor counterfactual inference. In International conference on machine learning.PMLR, 30203029": "Andreas Kirsch, Sebastian Farquhar, Parmida Atighehchian, Andrew Jesson,Frederic Branchaud-Charron, and Yarin Gal. 2021. Stochastic Batch Acquisition:A Simple Baseline for Deep Active Learning. arXiv preprint arXiv:2106.12059(2021). Andreas Kirsch, Joost Van Amersfoort, and Yarin Gal. 2019. Batchbald: Efficientand diverse batch acquisition for deep bayesian active learning. Advances inneural information processing systems 32 (2019).",
  "Yann LeCun. 1998. The MNIST database of handwritten digits. lecun.com/exdb/mnist/ (1998)": "Christos Louizos, Uri Shalit, Joris M Mooij, David Sontag, Richard Zemel, andMax Welling. 2017. Causal effect inference with deep latent-variable models.Advances in neural information processing systems 30 (2017). Quoc Viet Hung Nguyen, Chi Thang Duong, Thanh Tam Nguyen, Matthias Wei-dlich, Karl Aberer, Hongzhi Yin, and Xiaofang Zhou. 2017. Argument discoveryvia crowdsourcing. The VLDB Journal 26 (2017), 511535. Thanh Tam Nguyen, Chi Thang Duong, Matthias Weidlich, Hongzhi Yin, andQuoc Viet Hung Nguyen. 2017. Retaining data from streams of social platformswith minimal regret. In Twenty-sixth International Joint Conference on ArtificialIntelligence.",
  "Yishai Shimoni, Chen Yanover, Ehud Karavani, and Yaara Goldschmnidt. 2018.Benchmarking framework for performance-evaluation of causal inference analy-sis. arXiv preprint arXiv:1802.05046 (2018)": "Kirstine Smith. 1918. On the standard deviations of adjusted and interpolatedvalues of an observed polynomial function and its constants and the guidancethey give towards a proper choice of the distribution of observations. Biometrika12, 1/2 (1918), 185. Iiris Sundin, Peter Schulam, Eero Siivola, Aki Vehtari, Suchi Saria, and SamuelKaski. 2019. Active learning for decision-making from imbalanced observationaldata. In International conference on machine learning. PMLR, 60466055.",
  "Liantao Wang, Xuelei Hu, Bo Yuan, and Jianfeng Lu. 2015. Active learningvia query synthesis and nearest neighbour search. Neurocomputing 147 (2015),426434": "Hechuan Wen, Tong Chen, Li Kheng Chai, Shazia Sadiq, Junbin Gao, and HongzhiYin. 2023. Variational Counterfactual Prediction under Runtime Domain Corrup-tion. IEEE Transactions on Knowledge and Data Engineering (2023). Hechuan Wen, Tong Chen, Li Kheng Chai, Shazia Sadiq, Kai Zheng, and HongzhiYin. 2023. To Predict or to Reject: Causal Effect Estimation with Uncertainty onNetworked Data. In 2023 IEEE International Conference on Data Mining (ICDM).IEEE, 14151420.",
  "We denote such upper-bound at -th query step as B with post-acquisition dataset D (which includes the labelled optimal batchD ). By factual error decomposition in Proposition 2, we have:": "F = EX [( ()E[ ()])2]+EX [E[( ()E[ ()])2]]+2 .(10)We leave out the constant multiplier 2 in the original boundfor notation simplicity during deduction (as the calculation for theshrinkage cancels off the constant), and derive the upper bound Bat -th query step in a brand-new form but with the same tightnessas it is:",
  "{0,1}Var + IPM .(13h)": "The second equality holds because the models bias only dependson the selection of the model class , or more empirically modelsbias is negligible for models with enough complexity . Eitherway two bias terms cancelled off. Also, the data generation processhas the same noise assumption, thus two noise variance termscancelled off.The overall bound shrinkage B after the termination of theentire query steps is thus:",
  "(15)": "where the entire optimal set Doverall is a union of the optimal setD which is acquired at every query step to maximize the shrinkageB in (13h), thus we can conclude that the maximum risk upperbound reduction is obtained after the termination of entire labelacquisition process.Now that we define the shrinkage = B /B1 at -th step,and discuss two extreme contexts for the total risk upper boundsince it is hardly to compute the exact value for the bounded con-stant as discussed in .Scenario 1: Lower-bounded convergence rate with negligible",
  "where = {0,1} 21, and the approximation is given by the": "the dominant, and is the shrinkage in terms of the discrepancyreduction at -query step defined in Eq. 29.When the discrepancy term becomes the dominant part of therisk upper bound and leaving out the variance, we have the shrink-age difference | | < , for a small > 0. Under such cir-cumstances, the convergence rate of the risk upper bound cannotexceed O(1",
  "=12( ()),(18)": "where the predictive variance for observation is denoted as2( ()).For the model that counts the gold standard variance, i.e., Gauss-ian process , will cap the variance by the constant signal vari-ance 2 , e.g., 2 = 1. Intuitively for samples far away from thetraining set, the models belief reverts back to the prior. Mathemat-ically, for noiseless observations, we have the following boundedpredictive variance 2( ()) for any :",
  "pool 0 2 ,(21i)": "where the first inequality is given by Lemma 4, and the last equalityis given by acquiring the most uncertain samples at -th query stepwith maximum predictive variance 2 , and together with the factthat the observed sample has zero variance by the Gaussian processmodel.Now that at -th query step, we calculate the shrinkage asfollows:",
  ",(26)": "where the infimum runs over all the possible permutations .Since there exists an optimal permutation at -th query step,by plugging in to (26), we obtain the 1-Wasserstein distancebetween two empirical distributions. For now we just denote thisvalue by 1 (=1, =0) without knowing what exactly the numberis. Therefore, for the distributional difference at -th query step, wehave two optimal permutation 1 and to help us calculate thedifference IPM ( D):",
  "where 0 = | D |/2, i.e., half of the batch size at each query step.Given that the added identical samples, the optimal permutation at -th query step will match these identical pairs due to the": "cost 1+0=1+1 =1 =0() = 0 introduce zero distributionaldiscrepancy, thus the forth equality holds. Thus, for the rest ofthe 1 samples, the optimal permutation must have the sametransportation strategy as 1 does to obtain the lowest cost onthe rest 1 samples, such that the fifth equality holds. We believethe equality claim resonates with the rigorously proved triangularinequality nature of Wasserstein metric .Therefore, at -th query step, the discrepancy shrinkage isdefined as:",
  "(32)": "where denotes the observed outcomes after the intervention = 1/0 has been taken. The first equality is the rewritten expecta-tion, the second equality is based on the unconfoundedness, andthe third equality states that the expected values of the observedoutcomes {1,0} equal the unobserved potential outcomes. Thelast two terms are identifiable as we assume 0 < ( = 1|x) < 1(Assumption 3).",
  "BAdditional Experiments and SetupB.1Additional Visualizations ofPost-Acquisition Dataset": "We visualize the post-acquisition dataset distribution via t-SNEfor the five most representative models: MACAL, Random, LCMD,QHTE, and BALD, on all three datasets, i.e., CMNIST, IBM, andIHDP. Across all , 7, and 8, we consistently observe thatMACAL can significantly outperform the other methods in termsof acquiring the pairs to avoid the violation of positivity, and alsoexpanding the data boundary for not being clustering at a smallarea to avoid repetitive samples. Interestingly, we notice that in theIHDP dataset, the pair acquisition by MACAL terminates at Step15 as shown in (b) since samples from the treatment groupwith = 1 are exhausted, such that, MACAL can only label theother treatment samples and leave a quite imbalanced dataset atStep 35 as shown in (c).",
  "B.2Toy Dataset": "We simulate the one-dimensional toy dataset for a simple demon-stration of the importance of considering minimizing the modelvariance and distributional discrepancy altogether during labelacquisition.For samples with treatment status = 1: the first 100 samplesare from the interval of with equal spacing, and the second400 samples are from the normal distribution with mean -2.5 andvariance 1. For samples with treatment status = 0: the first 500 samplesare from the interval of with equal spacing, and the second2000 samples are from the normal distribution with mean 2.5 andvariance 1.We have in total 500 samples with treatment status = 1 and2500 samples with treatment status = 0 to form the imbalancedtreatment groups as the entire dataset, then we do train/test splitwith 3:1 ratio for the model evaluation. The data-generating processis described mathematically as follows:=1= 12 + 10(12)",
  "B.3Hyperparameters": "We conduct all the experiments with 48GB NVIDIA A40 on Ubuntu22.04 LTS platform where GPU training is enabled, otherwise the12th Gen Intel i7-12700K 12-Core 20-Thread CPU is used. The stan-dard hyperparameter tuning on the validation set which is furthersplit from the train set with 3:1 ratio, the best hyperparameters areselected with the smallest validation loss. Since the DUE modelsare borrowed from , we acknowledge the model set up from",
  "CLimitation and Future Work": "In our proposed risk upper reduction theory, we make furtherclaims for the risk convergence behaviour under two extreme cir-cumstances due to the negligibility of the bounded constant . Webelieve, the convergence analysis for each of the extreme situationscan help justify the algorithm design, i.e., with negligible therisk upper bound shrinks to the variance term, where keep acquir-ing the most uncertain samples can enable the rate of convergenceis lower-bounded by (), while, with dominant , the rate ofconvergence is upper-bounded by O(1 +0 ). We also empiricallyobserve these situations by setting different via the ablationstudy in Appendix 5.3, where it is clearly observed that MACALwith dominant performs the best at the start, but in the mid ofthe acquisition, a smaller (not negligible yet) obtains the bestperformance. However, the limitation of the convergence analysisis, due to technical difficulties, we do not obtain the risk conver-gence for the entire risk upper bound, i.e., when the sitting inthe middle and making both the variance and the distributionaldiscrepancy comparably important (which can be more realistic).We believe this point of research remains a import direction to befigured out in future work.Additionally, our designed algorithm MACAL, even though bringdown the NP-hard combinatorial optimization to be approximatelysolved in polynomial time, i.e., O( 2). When facing a significantlarge pool set with hundreds of millions of samples, the squared timecomplexity still suffers from considerable computational problemsand become undesirable. Thus, future research on how to furtherreduce the algorithm time complexity is also an important directionto go when facing large real-world datasets.",
  "DBroader Impacts": "Causal effect estimation with active Learning could potentially havebroader impacts on society if the algorithm is leveraged to deal withthe treatment effect estimation in reality. One of the representativeexamples can be the hospital scenario, where patients informationis used for the training of the treatment effect estimator.When doing the active learning to selectively screen the samplesand label them, once the AL algorithm identifies the informativesample to be labelled, the patients individual information (features), and the corresponding treatment effect would be revealed. Subse-quently, by labelling more informative samples, the positive impactis that a more precise treatment effect estimator can be trainedon the ongoing growing training set, and help make more precisedecision on the patients treatment plan. However, the negativeimpact is, that the identified patients need to reveal their treatmentinformation which can introduce privacy concerns and go againsttheir will. Thus, when the causal effect active learning algorithm isused in the real world, the conductors should strictly consider thenegative impact on the patients privacy and its willing during thelabel acquisition process."
}