{
  "ABSTRACT": "Precise crop yield predictions are of national importance for en-suring food security and sustainable agricultural practices. WhileAI-for-science approaches have exhibited promising achievementsin solving many scientific problems such as drug discovery, precip-itation nowcasting, etc., the development of deep learning modelsfor predicting crop yields is constantly hindered by the lack of anopen and large-scale deep learning-ready dataset with multiplemodalities to accommodate sufficient information. To remedy this,we introduce the CropNet dataset, the first terabyte-sized, publiclyavailable, and multi-modal dataset specifically targeting climatechange-aware crop yield predictions for the contiguous UnitedStates (U.S.) continent at the county level. Our CropNet datasetis composed of three modalities of data, i.e., Sentinel-2 Imagery,WRF-HRRR Computed Dataset, and USDA Crop Dataset, for over2200 U.S. counties spanning 6 years (2017-2022), expected to fa-cilitate researchers in developing versatile deep learning modelsfor timely and precisely predicting crop yields at the county-level,by accounting for the effects of both short-term growing seasonweather variations and long-term climate change on crop yields.Besides, we develop the CropNet package, offering three typesof APIs, for facilitating researchers in downloading the CropNetdata on the fly over the time and region of interest, and flexiblybuilding their deep learning models for accurate crop yield predic-tions. Extensive experiments have been conducted on our CropNetdataset via employing various types of deep learning solutions,with the results validating the general applicability and the efficacyof the CropNet dataset in climate change-aware crop yield predic-tions. We have officially released our CropNet dataset on HuggingFace Datasets our CropNet package on the Python Package Index (PyPI) Code and tutorials are availableat",
  "Corresponding author: Dr. Xu Yuan ()": "Permission to make digital or hard copies of all or part of this work for personal orclassroom use is granted without fee provided that copies are not made or distributedfor profit or commercial advantage and that copies bear this notice and the full citationon the first page. Copyrights for components of this work owned by others than theauthor(s) must be honored. Abstracting with credit is permitted. To copy otherwise, orrepublish, to post on servers or to redistribute to lists, requires prior specific permissionand/or a fee. Request permissions from , August 2529, 2024, Barcelona, Spain 2024 Copyright held by the owner/author(s). Publication rights licensed to ACM.ACM ISBN 979-8-4007-0490-1/24/08",
  "Crop Dataset, Crop Yield Predictions, AI for Science": "ACM Reference Format:Fudong Lin, Kaleb Guillot, Summer Crawford, Yihe Zhang, Xu Yuan, and Nian-Feng Tzeng. 2024. An Open and Large-Scale Dataset for Multi-Modal Cli-mate Change-aware Crop Yield Predictions. In Proceedings of the 30th ACMSIGKDD Conference on Knowledge Discovery and Data Mining (KDD24),August 2529, 2024, Barcelona, Spain. ACM, New York, NY, USA, 13 pages.",
  "INTRODUCTION": "Precise crop yield prediction is essential for early agricultural plan-ning , timely management policy adjustment , informedfinancial decision making , and national food security . Re-cent advancements in deep neural networks (DNNs) have achievedimpressive performance across various domains . Building upon theseadvancements, plenty of studies have employed spatial-temporalDNNs to predict crop yieldswith increased timeliness and precision .However, they often applied their personally curated and limit-sized datasets, with somewhat mediocre prediction performance.There is an urgent need for new large-scale and deep learning-readydatasets tailored specifically for wide use in crop yield predictions.Recently, some studies havedeveloped open and large-scale satellite imagery (or meteorologi-cal parameter) datasets, flexible for being adopted to agricultural-related tasks, e.g., crop type classification . Unfortunately, twolimitations impede us from applying them directly to crop yieldpredictions in general. First, they lack ground-truth crop yield infor-mation, making them unsuitable for crop yield predictions. Second,they provide only one modality of data (i.e., either satellite images ormeteorological parameters), while accurate crop yield predictionsoften need to track the crop growth and capture the meteorologicalweather variation effects on crop yields simultaneously, calling formultiple modalities of data. To date, the development of a large-scale dataset with multiple modalities, targeting specifically forcounty-level crop yield predictions remains open and challenging.In this work, we aim to craft such a dataset, called CropNet,the first terabyte-sized and publicly available dataset with multiple",
  "Our CropNet dataset2362satellite imagerymeteorological parameterscrop information": "modalities, designed specifically for county-level crop yield predic-tions across the United States (U.S.) continent. As shown in ,the CropNet dataset is composed of three modalities of data, i.e.,Sentinel-2 Imagery, WRF-HRRR Computed Dataset, and USDA CropDataset, covering a total of 2291 U.S. counties from 2017 to 2022.In particular, the Sentinel-2 Imagery, acquired from the Sentinel-2mission , provides two categories of satellite images, i.e., agri-culture imagery (AG) and normalized difference vegetation index(NDVI), for precisely monitoring the crop growth on the ground.The WRF-HRRR Computed Dataset, obtained from the WRF-HRRRmodel , offers daily and monthly meteorological parameters,accounting respectively for the short-term weather variations andthe long-term climate change. The USDA Crop Dataset, sourcedfrom the USDA Quick Statistic website , contains annual cropyield information for four major crops, i.e., corn, cotton, soybean,and winter wheat, grown on the contiguous U.S. continent, servingas the ground-truth label for crop yield prediction tasks. summarizes the dataset comparison between our CropNet datasetand pertinent datasets.Since the data in our CropNet dataset are obtained from differentdata sources, we propose a novel data alignment solution to makeSentinel-2 Imagery, WRF-HRRR data, and USDA crop yield dataspatially and temporally aligned. Meanwhile, three modalities ofdata are stored in carefully designed file formats, for improvingthe accessibility, readability, and storage efficiency of our CropNetdataset. The key advantage of our CropNet dataset is to facilitateresearchers in developing crop yield prediction models that areaware of climate change, by taking into account the effects of (1) the short-term weather variations, governed by daily parametersduring the growing season, and (2) the long-term climate change,governed by monthly historical weather variations, on crop growth.Furthermore, we have developed the CropNet package, includingthree types of APIs, expected to assist researchers and practition-ers in (1) dynamically downloading the CropNet data based onthe specific time and region of interest and (2) flexibly buildingclimate change-aware deep learning models for accurate crop yieldpredictions at the county level.Our experimental results validate that the CropNet dataset canbe easily adopted by the prominent deep learning models, suchas Long Short-Term Memory (LSTM)-based, Convolutional NeuralNetwork (CNN)-based, Graph Neural Network (GNN)-based,and Vision Transformer (ViT)-based models, for timely andprecise crop yield predictions. Additionally, our CropNet datasetdemonstrates its versatile applicability to boost the generalizationcapabilities of deep neural networks (DNNs), thanks to its abundantvisual satellite imagery and numerical meteorological data.",
  "Our CropNet dataset is crafted from three different data sources, aslisted below": "Sentinel-2 Mission. The Sentinel-2 mission , launched in 2015,serves as an essential earth observation endeavor. With its 13 spec-tral bands and high revisit frequency of 5 days, the Sentinel-2 mis-sion provides wide-swath, high-resolution, multi-spectral satelliteimages for a wide range of applications, such as climate change,agricultural monitoring, etc. WRF-HRRR Model. The High-Resolution Rapid Refresh (HRRR) is a Weather Research & Forecasting Model (WRF)-based forecastmodeling system, which hourly forecasts weather parameters forthe whole United States continent with a spatial resolution of 3km.We take the HRRR assimilated results archived in the University ofUtah for use, which provides several crop growth-related parame-ters, e.g., temperature, precipitation, wind speed, relative humidity,radiation, etc., beginning with July 2016.",
  "OUR CROPNET DATESET3.1Motivation": "The large-scale data with multiple modalities comprising satelliteimages, numerical meteorological weather data, and crop yieldstatistic data, are essential for tracking crop growth and correlatingthe weather variations effects on crop yields, to be used for timelyand precisely predicting crop yields at the county level. To date,such an open and large-scale dataset intended for county-level cropyield prediction is still absent. In this benchmark article, we planto design and publish such an open and large-scale dataset, calledCropNet, with multiple modalities, consisting of visual satellite im-ages, numerical meteorological parameters, and crop yield statisticdata, across the U.S. continent. Notably, not all U.S. counties aresuitable for crop planting, so our dataset only includes the datacorresponding to 2291 U.S. counties over 3143 counties in total(see for its geographic distribution). Such a multi-modaldataset is valuable for researchers and practitioners to design andtest various deep learning models for crop yield predictions, bytaking into account the effects of both short-term growing seasonweather variations and long-term climate change on crop yields.",
  "Overview of Our CropNet Dataset": "Our CropNet dataset is composed of three modalities of data, i.e.,Sentinel-2 Imagery, WRF-HRRR Computed Dataset, and USDA CropDataset, spanning from 2017 to 2022 (i.e., 6 years) across 2291 U.S.counties. shows the geographic distribution of our dataset.Since crop planting is highly geography-dependent, alsoprovides the number of counties corresponding to each crop typein the USDA Crop Dataset (see the rightmost bar chart). Notably,four of the most popular crops, i.e., corn, cotton, soybeans, andwinter wheat, are included in our CropNet dataset, with satelliteimagery and the meteorological data covering all 2291 counties. overviews our CropNet dataset. Its total size is 2362.6 GB,with 2326.7 GB of visual data for Sentinel-2 Imagery, 35.5 GB ofnumerical data for WRF-HRRR Computed Dataset, and 2.3 MB ofnumerical data for USDA Crop Dataset. Specifically, Sentinel-2 Im-agery contains two types of satellite images (i.e., AG and NDVI),both with a spatial resolution of around 40 meters (covering an areaof 9x9 km with 224x224 pixels) as well as a revisit frequency of 14days. Figures 3a (or 3b) and 3c (or 3d) respectively depict examplesof AG and NDVI images in the summer (or winter). The WRF-HRRRComputed Dataset provides daily (or monthly) meteorological pa-rameters gridded at the spatial resolution of 9 km in a one-day (orone-month) interval. Figures 4a and 4b visualize the temperature inthe WRF-HRRR Computed Dataset for the summer and the winter,respectively. The USDA Dataset offers crop information for fourtypes of crops each on the county-level basis, with a temporal reso-lution of one year. shows the example for the USDA CropDataset, depicting 2022 soybeans yields across the U.S. continent.",
  "Data Collection and Preparation": "Sentinel-2 Imagery. We utilize the Sentinel Hub Processing API to acquire satellite images from the Sentinel-2 mission at a pro-cessing level of Sentinel-2 L1C, with a maximum allowable cloudcoverage of 20%, three spectral bands (i.e., B02, B08, and B11) for AGimages and two bands (i.e., B04 and B08) for NDVI images. Satelliteimages are obtained at the revisit frequency of 14 days instead of theoriginal highest revisit frequency of 5 days. The reason is that the5-day revisit frequency under our cloud coverage setting results ina large number of duplicate satellite images, according to our empir-ical study (refer to Appendix A.1 for details). As precisely trackingthe crop growth on the ground requires high-spatial-resolutionsatellite images, we partition a county into multiple grids at theresolution of 9x9 km, with each grid corresponding to one satelliteimage. Figures 6a and 6b illustrates an example of county parti-tioning (refer to Appendix A.2 for more details). The downloadedsatellite images for one U.S. state (including all counties therein)spanning one season are stored in one Hierarchical Data Format(HDF5) file. Three reasons motivate us to employ the HDF5 fileformat. First, it can significantly save the hard disk space. That is,the collected satellite images with a total of 4562.2 GB shrank to2326.7 GB (i.e., 0.51x smaller space occupancy) in the HDF5 file.This can facilitate researchers and practitioners for lower hard diskspace requirements and faster data retrieval. Second, it allows forstoring data in the form of multidimensional arrays, making satel-lite images easy to access. The HDF5 file for Sentinel-2 Imagery isorganized in the form of (,,, , ,), where represents theFIPS code (i.e., the unique number for each U.S. county) used forretrieving one countys data, indicates the number of temporaldata in a 14-day interval with respect to one season, representsthe number of high-resolution grids for a county, and (, ,)are the width, height, and channel numbers for the satellite image.Third, it can store descriptive information for the satellite image,such as its revisit day, the latitude and longitude information itrepresents, among others. WRF-HRRR Computed Dataset. The WRF-HRRR ComputedDataset is sourced from the WRF-HRRR model , which pro-duces GRID files on the hourly basis, containing meteorologicalparameters over the contiguous U.S. continent at a spatial resolu-tion of 3x3 km. To lift the domain knowledge required for usingthe WRF-HRRR data, our CropNet dataset includes 9 carefully cho-sen and crop growth-relevant meteorological parameters, with 6parameters obtained directly from the WRF-HRRR model, i.e., aver-aged temperature, precipitation, relative humidity, wind gust, windspeed, downward shortwave radiation flux, and other 3 parameterscomputed by ourselves, i.e., maximal temperature, minimal tem-perature, vapor pressure deficit (VPD). presents details ofmeteorological parameters in the WRF-HRRR Computed Dataset.Notably, VPD describes the difference between the amount of mois-ture in the air and the maximum amount of moisture the air canhold at a specific temperature, which is an important concept in un-derstanding the environmental conditions that affect plant growthand transpiration. Given two meteorological parameters, i.e., thetemperature measured in Kelvin and the relative humidity ,",
  "(c) Spatial resolution alignment": ": Illustration of county partitioning (i.e., 6a and 6b) and spatial resolution alignment (i.e., 6c). (a) Boundaries for onecounty (i.e., the red line) and the corresponding high-resolution grids (i.e., the blue line). (b) Satellite images in the Sentinel-2Imagery for representing the county. (c) One 3x3km and its surrounding eight grids in the WRF-HRRR model are used foraligning with one 9x9km grid in the Sentinel-2 Imagery.",
  "Downward Shortwave Radiation FluxThe total amount of shortwave radiationthat reaches the Earths surface. Unit: W/m2": "Computed by usMaximal Temperature2 metre maximal temperature during a day/month. Unit: KMinimal Temperature2 metre minimal temperature during a day/month. Unit: KVapor Pressure Deficit (VPD)The amount of drying power the air has upon the plant. Unit: kPa partitioning one county into multiple grids at the spatial resolutionof 9x9 km. Then, we utilize the latitude and longitude of the centricpoint in the 9x9km grid to find the nearest 3x3km grid in the WRF-HRRR model. Next, meteorological parameters in the 3x3 km gridand its surrounding 8 grids can be used for representing a regiongridded at 9x9 km, as shown in c. In this way, our datasetallows researchers to capture the immediate effects of atmosphericweather variations occurring directly above the crop-growing areaon crop yields. Second, extracting meteorological parameters fromGRID files is extremely time-consuming as searching the nearestgrids requires to match geo-grids across the continental UnitedStates. To handle this challenge, we develop a global cache solutionby pre-storing the nearest grid information corresponding to a pairof latitude and longitude for each location, reducing the requiredextraction time from 60 days to 42 days (i.e., 1.42x faster than theone without global caching).The daily meteorological parameters are computed out of thehourly data extracted from the GRID file, while the monthly weatherparameters are derived from our daily data to significantly reducethe frequency of accessing the GRID file. Finally, daily and monthlymeteorological parameters are stored in the Comma Separated Val-ues (CSV) file, making them readable by researchers and accessiblefor deep learning models. The CSV file also includes additionalvaluable information such as the FIPS code of a county and the lati-tude and longitude of each grid. This provides easy and convenientaccess to relevant data for researchers. USDA Crop Dataset. The data in the USDA Crop Dataset is re-trieved from the USDA Quick Statistic website via our newlydeveloped web crawler solution. For each crop type, the USDA web-site provides its crop information at the county level in a one-yearinterval, with a unique key for identifying the data for one croptype per year, e.g., 85BEE64A-E605-3509-B60C-5836F6FBB5F6 forthe corn data in 2022. Our web crawler first retrieves the uniquekey by specifying the crop type and the year we need. Then, itutilizes the unique key to obtain the corresponding crop data inone year. Finally, the downloaded crop data is stored in the CSVfile. Notably, other useful descriptive information, e.g., FIPS code,state name, county name, etc., are also contained in the CSV file forfacilitating readability and accessibility.However, the crop statistic data from the USDA Quick Statis-tic website is not deep learning-friendly. For example, it uses twocolumns, i.e., Data Item and Value, to keep all valuable cropinformation. That is, if the description of the Data Item column refers to the corn yield, then the numerical data in the Value col-umn represents the corn yield. Otherwise, the data in Value maysignify other information, e.g., the corn production, the soybeansyield, etc. New data pre-processing techniques are developed tounify the data format, making the production and yield informationstored in two independent columns for facilitating Python libraries(e.g., pandas) to access them.Our CropNet dataset specifically targets county-level crop yieldpredictions across the contiguous U.S. continent. We utilize theFIPS code to rapidly fetch the data of each county, including a list ofHDF5 files for Sentinel-2 Imagery, two lists of CVS files respectivelyfor daily and monthly meteorological parameters, and one CVS filefor the USDA Crop Dataset, with configurations stored in the JSONfile for increasing accessibility. (see Appendix A.3 for an exampleof our JSON configuration file).",
  "Experimental Settings": "Approaches. The LSTM-based, CNN-based, GNN-based, and ViT-based models are represented respectively by ConvLSTM ,CNN-RNN , GNN-RNN , and MMST-ViT in ourexperiments, targeting crop yield predictions. Meanwhile, two self-supervised learning (SSL) techniques, i.e., MAE , and MM-SSL in the MMST-ViT, serving respectively as unimodal and multi-modal SSL techniques, are taken into account under the self-supervisedpre-training scenario. The aforementioned methods are modifiedslightly to make them fit the CropNet data in our experiments. Metrics. Three performance metrics, i.e., Root Mean Square Error(RMSE), R-squared (R2), and Pearson Correlation Coefficient(Corr), are adopted to evaluate the efficacy of the CropNet datasetfor crop yield predictions. Note that a lower RMSE value and ahigher R2 (or Corr) value represent better prediction performance.Details of utilizing our CropNet data for conducting experimentsare deferred to Appendix B for conserving space.",
  "Performance Evaluation for 2022 Crop YieldPredictions": "We conduct experiments on the CropNet dataset for 2022 crop yieldpredictions by using satellite images and daily weather conditionsduring growing seasons, as well as monthly meteorological condi-tions from 2017 to 2021, running under the ConvLSTM, CNN-RNN,GNN-RNN, and MMST-ViT models. presents each cropsoverall performance results (i.e., RMSE, R2, and Corr) in aggregation.We have two observations. First, all models achieve superb predic-tion performance with our CropNet data. For example, ConvLSTM,CNN-RNN, GNN-RNN, and MMST-ViT achieve small RMSE valuesof 5.3, 4.1, 4.1, and 3.9, respectively, for soybeans yield predictions(see the 8th column). These results validate that our CropNet datasetis well-suited for LSTM-based, CNN-based, and GNN-based, andViT-based models, demonstrating its general applicability. Second,MMST-ViT achieves the best performance results under all scenar-ios, with lowest RMSE values of 13.2, 50.9, 3.9, and 4.8, as well ashighest R2 (or Corr) values of 0.890 (or 0.943), 0.848 (or 0.921), 0.879(or 0.937), and 0.864 (or 0.929), respectively for predicting corn, cot-ton, soybeans, and winter wheat yields. This is due to MMST-ViTsnovel attention mechanisms , which perform thecross-attention between satellite images and meteorological param-eters, able to capture the effects of both growing season weathervariations and climate change on crop growth. This experimentexhibits that our CropNet dataset can provide crop yield predic-tions timely and precisely, essential for making informed economicdecisions, optimizing agricultural resource allocation, etc.",
  "Performance of One-Year Ahead Predictions": "Crop yield predictions well in advance of the planting season arealso critical for farmers to make early crop planting and manage-ment plans. Here, we apply the CropNet dataset one year beforethe planting season for predicting the next years crop yields. Fig-ure 7 shows our experimental results for 2022 crop yield predictionsby using our CropNet data during the 2021 growing season. Weobserve that all models can still maintain decent prediction per-formance. For instance, ConvLSTM, CNN-RNN, GNN-RNN, andMMST-ViT achieve the averaged RMSE values of 6.2, of 5.4, of5.3, and of 4.7, respectively, for soybeans predictions. Meanwhile,MMST-ViT consistently achieves excellent Corr values, averagingat 0.922 for corn, 0.890 for cotton, 0.926 for soybeans, and 0.904 forwinter wheat predictions, only slightly inferior to the performanceresults for the regular 2022 crop yield predictions (see the last rowin ). This can be attributed to MMST-ViTs ability to capturethe indirect influence of 2021s weather conditions on crop growthin the subsequent year through the utilization of long-term weather",
  "Improving the Generalization Capabilitiesof DNNs": "Self-supervised learning (SSL) techniques have significantly advanced the generalization capabilities of deepneural networks (DNNs), especially in vision transformers (ViTs).Our CropNet dataset with a total size of over 2 TB of data can ben-efit both deep-learning and agricultural communities by providinglarge-scale visual satellite imagery and numerical meteorologicaldata for pre-training DNNs. To exhibit the applications of our Crop-Net dataset to self-supervised pre-training, we adopt the MMST-ViTfor crop yield predictions by considering three scenarios, i.e., MMST-ViT without the SSL technique (denoted as w/o SSL), MMST-ViTwith the SSL technique in MAE (denoted as MAE), and MMST-ViTwith the multi-modal SSL technique proposed in (denoted asMM-SSL). illustrates the performance results for four croptypes under three performance metrics of interest (i.e., RMSE, R2,and Corr). We discover that without the SSL technique (i.e., the grayline), the MMST-ViT model exhibits limitations in generalizationcapabilities, resulting in suboptimal crop yield prediction perfor-mance across all tested scenarios. Besides, pre-training MMST-ViTwith the SSL technique in MAE (i.e., the blue line) improves itsperformance results (compared to the w/o SSL), with decreasedRMSE values by 3.8, 9.6, 1.3, and 1.7 for corn, cotton, soybeans,and winter wheat predictions, respectively. This statistical evidenceconfirms that our CropNet dataset can improve the generalizationcapabilities in vision models. Furthermore, MMST-ViT with themulti-modal SSL technique (i.e., the green line) achieves the bestperformance results under all scenarios. In comparison to the w/oSSL scenario, it decreases RMSE values by 6.4, 18.3, 2.6, and 3.6, re-spectively, for predicting corn, cotton, soybeans, and winter wheat.The effectiveness of the multi-modal SSL technique may stem fromits ability to integrate visual satellite imagery with numerical me-teorological data found in the CropNet dataset. This integrationenhances the generalization capabilities of the MMST-ViT model byimproving its ability to effectively discern the influence of weatherconditions on crop growth patterns during the pre-training phase.",
  "All13.20.8900.9433.910.8790.937": "the high-resolution satellite image (denoted as w/o high-resolutionimages) by using only one satellite image to capture the wholecountys agricultural information. Third, we ignore the effects ofweather variations on crop yields by dropping all meteorologicaldata, denoted as w/o WRF-HRRR data. Similarly, w/o short-termdata and w/o long-term data represent masking out the daily andmonthly meteorological parameters, respectively. We also includeprediction results by using all modalities of the CropNet (denotedas All) for performance comparison. Note that the USDA CropDataset provides the label for crop yield predictions; hence, noablation study requires. presents the experimental results under the MMST-ViTmodel . We have four observations. First, discarding the tem-poral satellite images (i.e.,w/o temporal images) degrades perfor-mance significantly, raising the RMSE value by 8.9 (or 1.81) andlowering the Corr value by 0.073 (or 0.058) for corn (or soybeans)yield predictions. This is due to that a sequence of satellite imagesspanning the whole growing season are essential for tracking cropgrowth. Second, w/o high-resolution images achieves the worstprediction performance, with a largest RMSE vaue of 27.9 (or 7.8)and a lowest Corr value of 0.810 (or 0.794) for corn (or soybeans)yield predictions. The reason is that high-resolution satellite imagesare critical for precise agricultural tracking. Third, dropping meteo-rological parameters (i.e., w/o WRF-HRRR data) makes MMST-ViT",
  "An Open and Large-Scale Dataset for Multi-Modal Climate Change-aware Crop Yield PredictionsKDD24, August 2529, 2024, Barcelona, Spain": "fail to capture meteorological effects on crop yields, leading to theincrease of RMSE value by 7.4 (or 1.87) and the decease of Corr valueby 0.072 (or 0.063) for predicting corn (or soybeans) yields. Fourth,discarding either daily weather parameters (i.e.,w/o short-termdata) or monthly meteorological parameters (i.e.,w/o long-termdata) lowers crop yield prediction performance. The reason isthat the former is necessary for capturing growing season weathervariations, while the latter is essential for monitoring long-termclimate change effects. Hence, we conclude that each modality inour CropNet dataset is important and necessary for accurate cropyield predictions, especially for those crops which are sensitive togrowing season weather variations and climate change.",
  ": Example of our DataRetriever API": "DataDownloader. This API allows researchers to download theCropNet data over the time/region of interest on the fly. For example,given the time and region (e.g., the FIPS code for one U.S. county)of interest, presents how to utilize the DataDownloaderAPI to download the up-to-date CropNet data.DataRetriever. This API enables researchers to conveniently ob-tain the CropNet data stored in the local machine (e.g., after youhave downloaded our curated CropNet dataset) over the time/re-gion of interest, with the requested data presented in a user-friendlyformat. For instance, shows how to employ the DataRe-triever API to obtain the CropNet data for two U.S. counties.DataLoader. This API is designed to assist researchers in their de-velopment of DNNs for crop yield predictions. It allows researchers",
  "CONCLUSION": "This work presented our crafted CropNet dataset, an open, large-scale, and multi-modal dataset targeting specifically at county-levelcrop yield predictions across the contiguous United States conti-nent. Our CropNet dataset is composed of three modalities of data,i.e., Sentinel-2 Imagery, WRF-HRRR Computed Dataset, and USDACrop Dataset, containing high-resolution satellite images, dailyand monthly meteorological conditions, and crop yield information,aligned in both the spatial and the temporal domains. Such a datasetis ready for wide use in deep learning, agriculture, and meteorol-ogy areas, for developing new solutions and models for crop yieldpredictions, with the consideration of both the effects of growingseason weather variations and climate change on crop growth. Ex-tensive experimental results validate the general applicability of ourCropNet dataset to various types of deep learning models for boththe timely and one-year ahead crop yield predictions. Besides, theapplications of our CropNet dataset to self-supervised pre-trainingscenarios demonstrate the datasets versatile utility in improvingthe generalization capabilities of deep neural networks (DNNs). Inaddition to our crafted dataset, we have also developed the CropNetpackage, which allows researchers and practitioners to (1) constructthe CropNet data on the fly over the time/region of interest and (2)flexibly build their deep learning models for climate change-awarecrop yield predictions. Although our initial goal of crafting theCropNet dataset and developing the CropNet package is for precisecrop yield prediction, we believe its future applicability is broadand deserved further exploration. It can benefit the deep learning,agriculture, and meteorology communities, in the pursuit of moreinteresting, critical, and pertinent applications. This work was supported in part by NSF under Grants 2019511,2348452, and 2315613. Any opinions and findings expressed in thepaper are those of the authors and do not necessarily reflect theview of funding agencies.",
  "Hangbo Bao, Li Dong, Songhao Piao, and Furu Wei. 2022. BEiT: BERT Pre-Training of Image Transformers. In The Tenth International Conference on LearningRepresentations (ICLR)": "Ting Chen, Simon Kornblith, Mohammad Norouzi, and Geoffrey E. Hinton. 2020.A Simple Framework for Contrastive Learning of Visual Representations. InInternational Conference on Machine Learning (ICML). Xuanhong Chen, Kairui Feng, Naiyuan Liu, Bingbing Ni, Yifan Lu, ZhengyanTong, and Ziang Liu. 2022. RainNet: A Large-Scale Imagery Dataset and Bench-mark for Spatial Precipitation Downscaling. In NeurIPS. Ziheng Chen, Fabrizio Silvestri, Gabriele Tolomei, Jia Wang, He Zhu, and Hong-shik Ahn. 2022. Explain the explainer: Interpreting model-agnostic counterfactualexplanations of a deep reinforcement learning agent. IEEE Transactions on Artifi-cial Intelligence (2022).",
  "Ziheng Chen, Fabrizio Silvestri, Jia Wang, He Zhu, Hongshik Ahn, and GabrieleTolomei. 2022. Relax: Reinforcement learning agent explainer for arbitrarypredictive models. In CIKM. 252261": "Minghan Cheng, Xiyun Jiao, Lei Shi, Josep Penuelas, Lalit Kumar, Chenwei Nie,Tianao Wu, Kaihua Liu, Wenbin Wu, and Xiuliang Jin. 2022. High-resolutioncrop yield and water productivity dataset generated using random forest andremote sensing. Scientific Data (2022). Julien Cornebise, Ivan Orsolic, and Freddie Kalaitzis. 2022.Open High-Resolution Satellite Imagery: The WorldStrat Dataset With Application toSuper-Resolution. In Neural Information Processing Systems Datasets and Bench-marks Track. Adrian Cottam, Xiaofeng Li, Xiaobo Ma, and Yao-Jan Wu. 2024. Large-ScaleFreeway Traffic Flow Estimation Using Crowdsourced Data: A Case Study inArizona. Journal of Transportation Engineering, Part A: Systems 150, 7 (2024). Alexey Dosovitskiy, Lucas Beyer, Alexander Kolesnikov, Dirk Weissenborn, Xi-aohua Zhai, Thomas Unterthiner, Mostafa Dehghani, Matthias Minderer, GeorgHeigold, Sylvain Gelly, Jakob Uszkoreit, and Neil Houlsby. 2021. An Image isWorth 16x16 Words: Transformers for Image Recognition at Scale. In ICLR. Joshua Fan, Junwen Bai, Zhiyun Li, Ariel Ortiz-Bobea, and Carla P. Gomes. 2022.A GNN-RNN Approach for Harnessing Geospatial and Temporal Information:Application to Crop Yield Prediction. In AAAI Conference on Artificial Intelligence(AAAI). 1187311881. Jinglun Feng, Liang Yang, Ejup Hoxha, Biao Jiang, and Jizhong Xiao. 2023. Roboticinspection of underground utilities for construction survey using a ground pene-trating radar. Journal of Computing in Civil Engineering 37, 1 (2023). Vivien Sainte Fare Garnot and Loc Landrieu. 2021. Panoptic Segmentation ofSatellite Image Time Series with Convolutional Temporal Attention Networks.In International Conference on Computer Vision (ICCV). Kaiming He, Xinlei Chen, Saining Xie, Yanghao Li, Piotr Dollr, and Ross B.Girshick. 2022. Masked Autoencoders Are Scalable Vision Learners. In Conferenceon Computer Vision and Pattern Recognition (CVPR).",
  "Kaiming He, Xiangyu Zhang, Shaoqing Ren, and Jian Sun. 2016. Deep ResidualLearning for Image Recognition. In Conference on Computer Vision and PatternRecognition (CVPR)": "Wenchong He, Zhe Jiang, Marcus Kriby, Yiqun Xie, Xiaowei Jia, Da Yan, andYang Zhou. 2022. Quantifying and Reducing Registration Uncertainty of SpatialVector Labels on Earth Imagery. In KDD, Aidong Zhang and Huzefa Rangwala(Eds.). 554564. Wenchong He, Zhe Jiang, Tingsong Xiao, Zelin Xu, Shigang Chen, Ronald Fick,Miles Medina, and Christine Angelini. 2023. A Hierarchical Spatial Transformerfor Massive Point Samples in Continuous Space. In NeurIPS.",
  "Shaojie Li, Yuhong Mo, and Zhenglin Li. 2022. Automated pneumonia detection inchest x-ray images using deep learning model. Innovations in Applied Engineeringand Technology (2022), 16": "Tianyi Li, Joshua Klavins, Te Xu, Niaz Mahmud Zafri, and Raphael Stern. 2023.Understanding driver-pedestrian interactions to predict driver yielding: natural-istic open-source dataset collected in Minnesota. arXiv preprint arXiv:2312.15113(2023). Tianyi Li, Mingfeng Shang, Shian Wang, Matthew Filippelli, and Raphael Stern.2022. Detecting stealthy cyberattacks on automated vehicles via generativeadversarial networks. In International Conference on Intelligent TransportationSystems (ITSC). 36323637.",
  "Zhenglin Li, Yangchen Huang, Mengran Zhu, Jingyu Zhang, JingHao Chang, andHouze Liu. 2024. Feature manipulation for ddpm based change detection. arXivpreprint arXiv:2403.15943 (2024)": "Zhenglin Li, Hanyi Yu, Jinxin Xu, Jihang Liu, and Yuhong Mo. 2023. Stockmarket analysis and prediction using LSTM: A case study on technology stocks.Innovations in Applied Engineering and Technology (2023), 16. Fudong Lin, Summer Crawford, Kaleb Guillot, Yihe Zhang, Yan Chen, Xu Yuan,Li Chen, Shelby Williams, Robert Minvielle, Xiangming Xiao, Drew Gholson,Nicolas Ashwell, Tri Setiyono, Brenda Tubana, Lu Peng, Magdy Bayoumi, andNian-Feng Tzeng. 2023. MMST-ViT: Climate Change-aware Crop Yield Predictionvia Multi-Modal Spatial-Temporal Vision Transformer. In International Conferenceon Computer Vision (ICCV).",
  "Fudong Lin, Xu Yuan, Yihe Zhang, Purushottam Sigdel, Li Chen, Lu Peng, andNian-Feng Tzeng. 2023. Comprehensive transformer-based model architecturefor real-world storm prediction. In ECML-PKDD. 5471": "Shun Liu, Kexin Wu, Chufeng Jiang, Bin Huang, and Danqing Ma. 2023. Financialtime-series forecasting: Towards synergizing performance and interpretabilitywithin a hybrid machine learning approach. arXiv preprint arXiv:2401.00534(2023). Weimin Lyu, Xinyu Dong, Rachel Wong, Songzhu Zheng, Kayley Abell-Hart,Fushen Wang, and Chao Chen. 2022. A Multimodal Transformer: Fusing ClinicalNotes with Structured EHR Data for Interpretable In-Hospital Mortality Predic-tion. In American Medical Informatics Association Annual Symposium (AMIA).",
  "Haixu Ma, Donglin Zeng, and Yufeng Liu. 2022. Learning Individualized Treat-ment Rules with Many Treatments: A Supervised Clustering Approach UsingAdaptive Fusion. In NeurIPS": "Xiaobo Ma, Abolfazl Karimpour, and Yao-Jan Wu. 2023. Eliminating the impactsof traffic volume variation on before and after studies: a causal inference approach.Journal of Intelligent Transportation Systems (2023), 115. Xiaobo Ma, Abolfazl Karimpour, and Yao-Jan Wu. 2024. Data-driven transferlearning framework for estimating on-ramp and off-ramp traffic flows. Journalof Intelligent Transportation Systems (2024), 114. Yuhong Mo, Hao Qin, Yushan Dong, Ziyi Zhu, and Zhenglin Li. 2024. LargeLanguage Model (LLM) AI Text Generation Detection based on TransformerDeep Learning Algorithm. International Journal of Engineering and ManagementResearch 14, 2 (2024), 154159. Zhaobin Mo, Yongjie Fu, and Xuan Di. 2024. PI-NeuGODE: Physics-InformedGraph Neural Ordinary Differential Equations for Spatiotemporal TrajectoryPrediction. In International Conference on Autonomous Agents and MultiagentSystems. 14181426. Zhaobin Mo, Wangzhi Li, Yongjie Fu, Kangrui Ruan, and Xuan Di. 2022. CVLight:Decentralized learning for adaptive traffic signal control with connected vehicles.Transportation research part C: emerging technologies 141 (2022), 103728.",
  "Approach for Precipitation Nowcasting. In NeurIPS": "Han Song, Cong Liu, and Huafeng Dai. 2024. Bundledslam: An accurate vi-sual slam system using multiple cameras. In Advanced Information Technology,Electronic and Automation Control Conference (IAEAC), Vol. 7. 106111. Gabriel Tseng, Ivan Zvonkov, Catherine Lilian Nakalembe, and Hannah Kerner.2021. CropHarvest: A global dataset for crop-type classification. In Neural Infor-mation Processing Systems Datasets and Benchmarks Track (Round 2). Matteo Turchetta, Luca Corinzia, Scott Sussex, Amanda Burton, Juan Herrera,Ioannis Athanasiadis, Joachim M Buhmann, and Andreas Krause. 2022. Learninglong-term crop management strategies with CyclesGym. Neural InformationProcessing Systems (NeurIPS).",
  "Zhenyi Wang, Li Shen, Tiehang Duan, Donglin Zhan, Le Fang, and Mingchen Gao.2022. Learning to learn and remember super long multi-domain task sequence.In CVPR. 79827992": "Zhenyi Wang, Li Shen, Donglin Zhan, Qiuling Suo, Yanjun Zhu, Tiehang Duan,and Mingchen Gao. 2023. Metamix: Towards corruption-robust continual learningwith temporally self-adaptive data transformation. In CVPR. 2452124531. Zepu Wang, Peng Sun, Yulin Hu, and Azzedine Boukerche. 2022. A novel mixedmethod of machine learning based models in vehicular traffic flow prediction.In International Conference on Modeling Analysis and Simulation of Wireless andMobile Systems. 95101. Zepu Wang, Dingyi Zhuang, Yankai Li, Jinhua Zhao, Peng Sun, Shenhao Wang,and Yulin Hu. 2023. ST-GIN: An uncertainty quantification approach in trafficdata imputation with spatio-temporal graph attention and bidirectional recurrentunited neural networks. In International Conference on Intelligent TransportationSystems (ITSC). 14541459. Xiaocui Wu, Xiangming Xiao, Jean Steiner, Zhengwei Yang, Yuanwei Qin, andJie Wang. 2021. Spatiotemporal changes of winter wheat planted and harvestedareas, photosynthesis and grain production in the contiguous United States from20082018. Remote Sensing (2021). Donglin Zhan, Yusheng Dai, Yiwei Dong, Jinghai He, Zhenyi Wang, and JamesAnderson. 2024. Meta-adaptive stock movement prediction with two-stagerepresentation learning. In SIAM International Conference on Data Mining (SDM).508516. Donglin Zhan, Shiyu Yi, Dongli Xu, Xiao Yu, Denglin Jiang, Siqi Yu, HaotingZhang, Wenfang Shangguan, and Weihua Zhang. 2019. Adaptive Transfer Learn-ing of Multi-View Time Series Classification. arXiv preprint arXiv:1910.07632(2019).",
  "This section supplements the main paper by demonstrating thenecessity and importance of our cloud coverage setting (i.e., 20%) and revisit frequency (i.e., 14 days) for Sentinel-2 Imagery": "Figures 12 and 13 present examples of Sentinel-2 Imagery underthe original revisit frequency of 5 days with and without our cloudcoverage setting, respectively. illustrates satellites imagesunder our revisit frequency of 14 days and our cloud coveragesetting (i.e., 20%).From , we observed that the cloud coverage may signif-icantly impair the quality of Sentinel-2 Imagery (see Figures 12b,12d, and 12e). Worse still, the extreme cases of cloud coverage (referto Figures 12d and 12e) degrade satellite images into noisy represen-tations. This demonstrates the significance of our cloud coveragesetting for discarding low-quality satellite images. Unfortunately,under the original sentinel-2 revisit frequency of 5 days, our cloudcoverage setting would result in a large proportion of duplicatesatellite images, e.g., 50% (i.e., 3 out of 6 satellite images) as depictedin . This is because if the cloud coverage in our requestedrevisit day exceeds 20%, Processing API will download themost recent available satellite images, whose cloud coverage sat-isfies our condition (i.e., 20%). In sharp contrast, extending therevisit frequency from 5 days to 14 days markedly decreases theoccurrence of duplicate satellite images. For example, there are noduplicate satellite images observed in . Hence, our revisitfrequency of 14 days for Sentinel-2 Imagery is necessary as it cansignificantly improve storage and training efficiency.",
  "A.2County Partitioning": "In our main paper, we have introduced partitioning one countyinto multiple high-spatial-resolution grids for precise agriculturaltracking. Here, we provide the details for such a partition. A naiveway to achieve this is to expand a countys geographic boundaryto a rectangle area by using its maximal and minimal latitude andlongitude, and then evenly divide such a rectangle area into multi-ple grids. Unfortunately, such a partition solution may result in alarge number of grids outside the county polygon for some largecounties (see a). To handle this matter, we develop a novelsolution by dropping the grids outside the countys boundary (seeb). Compared to the naive solution, our solution enjoystwo advantages. First, it can significantly reduce the disk spacestorage size. Take Coconino County in Arizona for example, by em-ploying our solution, its total number of grids degrades from 1023to 729, which is 0.71x less than that from the naive solution. Sec-ond, our solution can evade the negative effect incurred by regionsoutside the countys boundary on crop yield predictions.",
  "A.3Spatial and Temporal Alignment of OurCropNet Dataset": "Here, we present an example of our JSON configuration file (see) for one U.S. county (i.e., Baldwin in Alabama), to showhow satellite images from Sentinel-2 Imagery, daily and monthlyweather parameters from the WRF-HRRR Computed Dataset, andthe crop information from USDA Crop Dataset, are spatially andtemporally aligned. As presented in , data.sentinel anddata.HRRR.short_term respectively represent satellite images anddaily meteorological parameters during the crop growing season,data.HRRR.long_term indicates monthly weather conditions fromprevious 5 years, and data.USDA provides the crop informationfor the county. Meanwhile, FIPS and year respectively indicate",
  "(b) Our solution": ": Difference between the naive solution and our solution. (a) The naive solution leads to a significant number of gridsfalling outside the countys polygon. (b) By using our solution, the boundaries of grids (i.e., the blue line) align perfectly withthe countys boundary (i.e., the red line). the unique FIPS code and the year for the growing season, enablingus to obtain the data for our targeted county in a specific year. Insummary, the JSON configuration file allows us to retrieve all threemodalities of data over the time and region of interest.",
  "BSUPPORTING EXPERIMENTAL SETTINGS": "CropNet Data. Due to the limited computational resources, weare unable to conduct experiments across the entire United States.Consequently, we extract the data with respect to five U.S. states,i.e., Illinois (IL), Iowa (IA), Louisiana (LA), Mississippi (MS), andNew York (NY), to exhibit the applicability of our crafted CropNetdataset for county-level crop yield predictions. Specifically, two ofthese states (i.e., IA and IL) serve as representatives of the Midwestregion, two others (i.e., LA and MS) represent the Southeastern region, and the fifth state (i.e., NY) represents the Northeasternarea. Four of the most popular crops are studied in this work, i.e.,corn, cotton, soybeans, and winter wheat. For each crop, we takethe aligned Sentinel-2 Imagery and the daily data in the WRF-HRRRComputed Dataset during growing seasons in our CropNet dataset,respectively for precise agricultural tracking and for capturing theimpact of growing season weather variations on crop growth. Mean-while, the monthly meteorological parameters from the previous 5years are utilized for monitoring and quantifying the influence ofclimate change on crop yields."
}