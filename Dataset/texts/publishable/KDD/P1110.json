{
  "ABSTRACT": "We tackle the challenge of building real-world multimodal assis-tants for complex real-world tasks. We describe the practicalitiesand challenges of developing and deploying GRILLBot, a leading(first and second prize winning in 2022 and 2023) system deployed inthe Alexa Prize TaskBot Challenge. Building on our Open AssistantToolkit (OAT) framework, we propose a hybrid architecture thatleverages Large Language Models (LLMs) and specialised modelstuned for specific subtasks requiring very low latency. OAT allowsus to define when, how and which LLMs should be used in a struc-tured and deployable manner. For knowledge-grounded questionanswering and live task adaptations, we show that LLM reasoningabilities over task context and world knowledge outweigh latencyconcerns. For dialogue state management, we implement a codegeneration approach and show that specialised smaller models have84% effectiveness with 100x lower latency. Overall, we provide in-sights and discuss tradeoffs for deploying both traditional modelsand LLMs to users in complex real-world multimodal environmentsin the Alexa TaskBot challenge. These experiences will continue toevolve as LLMs become more capable and efficient fundamentallyreshaping OAT and future assistant architectures.",
  "INTRODUCTION": "In this work, we address this gap by presenting new generativeAI methods that underlie the online GRILLBot Alexa Prize systemthat won the first and second prizes in the Alexa TaskBot Chal-lenge . GRILLBot assists people with real-world problems athome, such as cooking and other physical tasks, and is battle-testedby hundreds of thousands of users across the US over multipleyears and generations. shows a simplified example cookingconversation with GRILLBot.",
  ": A multimodal conversation with OAT includingtask adaptation and question answering with system actionsby the NDP in green": "From the beginning, GRILLBot built on generative languagemodels to be flexible and adaptable. Instead of end-to-end genera-tion, it leverages a hybrid approach that uses specialised models tohandle specific tasks. The decision to deploy LLMs for (some) ofthese models has important tradeoffs that need to be managed care-fully. We present lessons and challenges deploying GRILLBot withhard constraints on response latency, reliability (uptime), and com-pute resources with the need to continuously handle concurrentconversations from Alexa users.We leverage LLM utility to provide a rich and engaging user expe-rience with unique and differentiating capabilities for the Taskbot.For example, GRILLBot preprocesses task data offline and onlineto respond to a dynamic user environment. We detail the challenges",
  "arXiv:2402.07647v2 [cs.IR] 28 Jun 2024": "and tradeoffs of deploying LLMs versus specialised models in thekey online components that make conversations effective. Key com-ponents covered include 1) generating flexible system actions fromcode generation, 2) responding to dynamic information needs withknowledge-grounded question answering, and 3) modifying tasksonline to adapt a task to the users preferences and constraints.First, we discuss and evaluate GRILLBots unique approach tohandling diverse and dynamic interaction patterns in complex task-oriented conversations. Instead of traditional intent-classificationmodels , GRILLBot defines a Neural Decision Parser (NDP)model that acts as a system orchestrator. Given the dialogue history,it generates actions the system should take in the form of generatedcode in an extensible domain-specific language. We show that aspecialised supervised NDP model learned from a small set of a fewhundred carefully curated examples can outperform much largermodels requiring significantly more data. Experiments show thatfor this critical and latency-sensitive component triggered on allinteractions, a specialised model provides a 100x latency advantage.A robust knowledge-grounded Question Answering module isthe second key element that allows the system to react robustly tounpredictable users. A TaskBot QA system needs to reason acrosstask and conversation history to handle dynamic information re-quests. LLM-based systems are more capable of this than traditionalextractive QA models, but standard generative QA is not groundedin a task and ongoing environment. In addition, current existingconversational datasets fail to simulate real-world task-oriented conversations. To fill this gap, we extend the Wizard-of-Tasks (WoT) task-oriented conversation benchmark to a newtask-oriented QA dataset using further web crawling and manualannotation. We experiment with QA models and LLMs to performcontextualised task-grounded question answering. Human anno-tators agree that LLMs respond more correctly to abstractive QA.However, advanced neural models like Unified QA outperformLLMs for extractive QA according to human annotation, F1 scoreand latency.Finally, we leverage the world knowledge from LLM pretrainingto modify tasks according to a users preferences and constraints. Tofocus on correctness and safety, we use a hybrid approach for livetask adaptation. If a user requests a change to the task, e.g. chang-ing a pizza to be vegetarian, we call an LLM-based task rewriterthat takes the current task and adapts it to the users constraints.The rewriter outputs the task in a structured format (JSON) sothat the system framework can access the edits for the remain-ing conversation. With manual annotation, we show that our taskrewriter managed to adapt a task successfully in 56% of cases. Ofthe successful adaptations, 73% of suggested LLM replacementswere sensible and would work in the real world. This shows thepotential of using LLMs for structured editing of underlying datastructures in a hybrid assistant architecture.Our contributions are:",
  "WoTe that we release publicly. We evaluate neural and LLMmodels available during the TaskBot challenge, showing thatLLMs beat neural models in abstractive QA, but are outper-formed for extractive QA": "For system orchestration and dialogue management, we per-form experiments with the Neural Decision Parser (NDP).Results show smaller, specialised language models are highlyadaptable and have high effectiveness with 100x lower la-tency. We study the effectiveness of LLM-based edits to tasks. Re-sults show that the LLMs real-world knowledge and fluencyenable structured changes to underlying data structures,with 73% of replacements being sensible.Throughout this paper, we share key insights into user behaviourand lessons learned deploying GRILLBot to thousands of users withmodels refined and developed across multiple years of the AlexaPrize TaskBot Challenge. GRILLBot was one of the first to adoptLLMs online for complex task responses. GRILLBot is reproduciblewith all non-user data and key components released continuouslyin the OAT framework , which we base GRILLBot on. Thecontinued evolution of best practices during deployment holdsimportant lessons for both the current and future task assistantsand their use of generative LLMs.",
  "RELATED WORK2.1End-to-end dialogue models": "End-to-end dialogue models based on transformers are fine-tunedon chat data and use LLM generation without underlying spe-cialised modules. Models like LaMDA , BlenderBot 3 , andWikiChat benefit from model scaling to generate higher qualityresponses. However, many leverage proprietary data and are notpublicly available for custom assistants (e.g. ).In contrast to chat models, TaskBots require task-oriented con-versations that are longer and more specialised. When a TaskBotguides the user through the task, the assistant leads the conversa-tion. TaskBots are more proactive and react flexibly to requests toactively shape the underlying task. However, most task-orienteddatasets are user-led and the user asks the assistant to perform atask, like booking a hotel. Conversations are oriented on pre-definedslot-filling conversation flows . In comparison, the Wizard ofTasks (WoT) dataset contains conversations between crowdworkers acting as students and teachers within the cooking andDIY domains. This means we have nearly no training data for train-ing models for the TaskBot task and start in a low-resource settingduring development.",
  "Modular Agent Architectures": "Compared to end-to-end models, modular conversational agentssplit control over system behaviour into specialised componentslike response generation, retrieval and dialogue management. Dif-ferent conversational agent frameworks have been created to helpwith boilerplate code to provide building blocks of agents.Popular frameworks are not fine-grained and flexibleenough to allow specialised model and LLM deployment. To enablefine-grained control of model use and own hosting rights, variousresearch institutions publish their frameworks , some of which built and battle-tested during Alexa Prize Challenges.We base GRILLBot on the public open-source OAT framework developed over multiple years of the TaskBot challenge. OATis a modularised task-oriented conversational agent frameworkwhich achieves a scalable, lightweight, and non-resource-intensivearchitecture with low latency. 2.2.1State management. Dialogue State Tracking (DST) is a stan-dard task in task-oriented conversational agents. Traditional ap-proaches include a model conversation with predefined schemasthat structure dialogue into intents and slots . Google ,Amazon and RASA follow this approach. Usually, dialoguemanagement leverages hierarchical state machines or flow con-trollers . Since intent flows are fixed and once flow is selected,navigating away is complicated, intent models are very brittle.Gemmell et al. instead introduce NDP models that generateflexible system actions. We build upon this work by evaluatingdifferent models to perform the NDP task. We explore how biggermodels with zero-shot/ few-shot or in-context learning performand discuss tradeoffs in latency and effectiveness.",
  "Task-specific question answering": "Previous work shows that generative models performing long-formQA tend to add additional information or hallucinate answers .This is potentially dangerous in a real-world setting and can un-dermine the agents perceived trustworthiness in the limited userinteraction .Khashabi et al. convert the task context into a natural lan-guage representation and pass it into a model jointly with the userquery. Lewis et al. , Shuster et al. combine this approachwith retrieving from relevant dialogue context. Choi et al. exper-iment with abstractive question answering with fine-tuned versionsof BART and T5. Their models hallucinate numerical terms andunits and show low performance, showcasing the challenging task.Since models like T5 can only ingest a limited context length, weimplement pre-processing of context to shorten to the availabletoken length. In comparison, in-context learning with few-shotprompts of LLMs needs limited training data. Context length is lessrestricted, but the length of the generative decoding and model sizeare computationally more expensive and add extra latency.In this work, we trial both traditional and LLM models as a ba-sis for abstractive and extractive QA tasks. To ensure knowledgegrounding of target answers, inspired by Khashabi et al. , Ra-jpurkar et al. , we reformulate the QA task to be extractive.Given a context paragraph and a question, the model needs to ex-tract the answer from the paragraph by selecting a substring. Wefollow Zaib et al. by classifying questions into factoid, causal,confirmation, listing, and complex questions to allow further fine-grained analysis.",
  "Dynamic Task Adaptation": "Due to the dynamic nature of real-world tasks, a virtual assistantneeds to be able to listen, understand, and adapt the task basedon the users input. OAT represents tasks as TaskGraphs, whichallows dynamic editing and scheduling of task components .In previous work, we perform task augmentations offline to createmore engaging conversations, including non-linear conversations",
  ": Online architecture of GRILLBot based on OAT .We implement NDP (.3) & QA (.4) in Neuralfunctionalities and task adaptation in (.5) in LLMfunctionalities": ", adding additional details, splitting steps, and writing taskdescriptions , and aligning videos .However, it is impossible to predict all possible live user requestsbefore task execution. In this work, we therefore use LLMs to editthe TaskGraphs live during the conversation, so that the systemresponds to unforeseen information and modifies tasks. One exam-ple of this is substituting ingredients for recipes and adapting thetask based on user preferences. Various approaches span using tem-plates and external knowledge sources to training specialisedmodels .",
  "IMPLEMENTATION DETAILS3.1TaskBot Task": "In this section, we define the TaskBot task more formally. Given aconversational history [1, . . .,], we find an explicit matchingTask that the user would like assistance such as cooking a recipeor refurbishing the kitchen. Then, we guide the user through by scheduling step-by-step actions [1, . . .,] dynamically. Whenmanaging the dialogue and responding to users, at each response weconsider the task and conversational history [1, . . .,] whengenerating the system response . There are no explicit conver-sational flows, meaning that the system can flexibly react to userrequests at any time of the conversation.",
  "Online GRILLBot System Architecture": "shows the different modular components of our deployedonline TaskBot system built on the OAT framework. Using the Or-chestrator module, we create several policies for GRILLBot whichhandle different functionalities grouped by resource requirements.LLM functionalities contain all generative capabilities. We createfeatures for general QA, chit-chat, and various conversation en-hancements such as TaskGraph adaptations. Neural functionalities handle all neural models requiring GPU, such as system actiongeneration and task reranking. Main functionalities include featuresfor retrieval, lookup and domain classifications. During the devel-opment of GRILLBot, we continue releasing models and synthetictraining data as part of the OAT framework .GRILLBot uses a Docker and Kubernetes setup to manage re-sources and maintain constant response times. Docker allows run-ning the entire application by only installing the single Docker de-pendency and no virtual environments. Modular Docker containershelp with version control, installing dependencies, and decoupling.Resource-heavy components that host neural models and LLMsdo not interrupt more lightweight components. This setup helpsadapt to traffic and usage spikes and maintain low latency. SinceGRILLBot is a live system, we have explicit latency constraintsfor modular components. We aim to give answers in less than 1.5seconds, which we manage in over 93% of utterances. Battle-testingGRILLBot with thousands of users, Kubernetes successfully man-aged load-balancing system components with an average systemlatency under 0.5 and 1.1 seconds.",
  "Code generation for dialogue management": "To overcome the brittleness of traditional intent classification, inprevious work, Gemmell et al. create Neural Decision Parsers(NDP) to generate code to represent system actions. We define thecode generation task for managing dialogue as follows: Given a Task and conversational history {1, . . .,} represented in naturallanguage as input sequence {1, ...,}, auto regressive generatesystem action = {1, ...,}.In theory, the action space that includes all is unlimited. How-ever, since we can only execute supported actions by the systemback end, we fix the action space = {1, ..., } for practical rea-sons to represent available system capabilities depending on thetraining data. The NDP can generate action arguments freely, suchas the search arguments in search(\"veggie pizza\") or the selectionoption in select(1). All actions not in , i.e. beyond system capabili-ties, are handled by a Fallback LLM to generate a fluent responsewithout executing any system actions. We ensure that the LLMFallback does not hallucinate by adding clear constraints in theLLM prompt of what system capabilities are. We also ask the modelto ask polite questions, if the user request is unclear. In addition,we leverage the Alexa Prize CoBot systems safety classifiersto ensure no dangerous responses are generated. shows examples of NDP output in green. The NDP trans-lates conversational state, history, and task state into appropriatesystem actions. This enables the system to parse the user requestflexibly. The deployed NDP model has a strict time constraint of< 0.2 seconds since the system calls the NDP model at each con-versation turn and follow-up calls need budget to execute underconstraints.In , we experiment with different model sizes and types,such as encoder-decoder models versus decoder-only models. Wealso compare bigger models versus finetuning on a custom-curatedbenchmark and discuss tradeoffs in effectiveness and latency. For de-ployment, we use small specialised supervised NDP models trainedfrom small seq-2-seq models learned from a few hundred",
  "Task-specific retrieval-augmented questionanswering": "Using the NDP, the system can identify when the user asks aquestion and forward this to the systems specialised question-answering module. We define the task-oriented question-answeringas follows: Given a Task and conversational history {1, . . .,}(with the user question being = ), generate a system response that answers .In the QA module, we pass the user question, the most relevanttask context, and conversation history into the model. For differentQA types, GRILLBot uses neural extractive and LLM-basedQA approaches to generate relevant answers based on thepassed context. Neural and LLM-base approaches have differentadvantages in latency, computational resources needed and modelabilities. In , we discuss tradeoffs between different modeltypes for abstractive and extractive questions.",
  "Live generative task adaption": "A flexible task assistant needs to be able to adapt a task based on userutterances and preferences. We define Task Adaptation as followsin two steps. First, given a user replacement question and thecurrent Task , we identify the original requirements [1, ...,]to replace and map them to new requirements in a replacementmapping 1 : 1, ..., : . Requirements can be ingredients ortools the user needs for . Second, given the mapping of old to newrequirements, we rewrite the Task with instructions [1, . . .,]and original requirements [1, ...,] to create with rewrittensteps [1, . . .,] and rewritten requirements [1,2, ..., ].To perform the task adaptation, we build an LLM-based substi-tution engine that allows modifying task ingredients, tools, andtask steps live to suit the users replacement request. shows aconversation with background LLM calls. If the NDP detects a usersubstitution request, the system queries the LLM with a replace-ment request in a pre-defined prompt with a filled-in context. If",
  "fallback()0.54s1.14s114%answer_question()0.89s1.66s87%search()0.92s0.94s2%replace()-2.38s-": "the user replacement request is valid, the LLM offers to replace theold with the new replacement and rewrite the task to reflect thechanges. If the user agrees, we select the steps and ingredients thatneed replacing. For each step and ingredient in the replacementmapping, we prompt the LLM to perform an edit.",
  "LESSONS LEARNED AND SHORTCOMINGS": "When we started developing GRILLBot in 2021, few openly acces-sible live virtual assistants using generative models existed. Webuild our OAT framework to allow scalable modular componentsto support using models live, which works well with Docker andKubernetes deployment. GRILLBot keeps the daily average latencyunder 1.1 seconds despite the high traffic of thousands of users.During the journey of developing GRILLBot, we explore tradeoffsfor using LLMs within a live system. An example of this is theNDP. When we started the challenge, the NDP was a basic T5model trained on a few hundred hand-crafted training examples.For us, it is remarkable how small sequence-to-sequence modelsstill manage to keep up with few-shot in-context learning of modelswith many more parameters. This allows us to keep the latencyof the frequently called NDP low and shows that LLMs might notalways be the answer.This becomes especially important when we start chaining mod-els. Balancing the cost of resources and improvements in perfor-mance is increasingly difficult. shows the latency of a fewselected system components. In Calendar Week 29, we start deploy-ing larger LLMs in the live system, which increases latency. Forvarious system features, we start calling the LLM endpoint deployedon a single NVIDIA A10G GPU with 24 GiB memory. We zero-shotprompt the model with action-specific handcrafted prompts andcontexts. Fallback and QA use one generative call, whereas the taskadaptation engine chains two generative calls.As a result, fallback response and answer question times doublecompared to our previous approach of using lightweight finetunedencoder-decoder models for fallback and QA. Since we set the max-imum time for LLM generation to 2 seconds, 1.7% of fallback and19% of question answer actions time out and the system respondswith a few standard default responses. However, since the deploy-ment of the LLM, user ratings of conversations increase by 13%.Conversations with questions and fallback see an increase in userratings of 30% and 10%, respectively.During log analysis, we review conversations after Week 29. shows types of action codes generated by the live NDP overthe entire span of the competition, highlighting how many utter-ances are handled to the LLM fallback. Most utterances are chit-chat fallback() search() stop() select() next() inform_capabilities() yes() answer_question() show_requirements() previous() no() repeat() start_task() show_more_results() show_more_details() Generated action 0.00 0.05 0.10 0.15 0.20 0.25 0.30 Percentage of total generated actions No ExecutionExecution",
  ": Generated action distribution from conversationswhere a task is started compared to exploratory-only": "requests, highlighting that users love chatting with assistants andtrying to break them. We observe that more than 30% of user utter-ances are handled by the LLM fallback if the user is not in execution,i.e. if the user has not chosen a task. Therefore, handling those userrequests flexibly and fluently is most important.One of our biggest lessons learnt is that LLMs are not the answerfor every single system component. For components with low la-tency requirements, finetuning specialised models is more sensible.For system components requiring fluent and complex responsessuch as QA and fallback, deploying a LLM in a structured manneris effective for answer quality despite increased latency since usersare very unpredictable. In addition, we learn that we dont needto finetune expensive models for fluent response generation if wecarefully prompt the model with the right context and implementsafeguards.",
  "EVALUATION": "To decide which models to use for system components, we performcomponent-level evaluation. We compare which models can betrained on system action code generation to accurately translateuser utterances into executable system actions. Then, we evaluatewhich models perform best at both abstractive and extractive task-specific question answering. Finally, we review the performance ofthe task adaptation feature.",
  "NDP evaluation": "5.1.1Dataset Creation. Building on previous work , we extendthe existing dataset by 25% with rewritten user logs and additionalsynthesised logs to test action code generation with different NDPmodel versions.This test set includes user utterances with previous system re-sponses, predicted intent by the system, and a correct intent pre-diction annotation. We split this test set into 60% training, 10%validation, and 30% testing to ensure an even user request distribu-tion during testing. We cant disclose the amount of original user",
  "log data, but we generate synthetic data by prompting ChatGPT to balance the intent distribution. We release the syntheticNDP training data as part of the most recent OAT release1": "5.1.2Metrics and Baselines. We fine-tune various encoder-decodermodels such as UnifiedQA , T5 , FLAN T5 as well as thedecoder-only Llama 2 base model (Llama-2-7b-hf) on the testsplit. We train all models for one epoch on one machine with oneNVIDIA A10G GPU with 24 GiB memory. We calculate precision,accuracy, recall, and F1 score averaged over all data. We also reportaverage latency per action code generation. 5.1.3Results. shows model effectiveness on the test dataset.Llama 2 outperforms all models. We also finetuned the LLama 2chat version, but it does not follow the action code input formatwell (36% of generations are non-parsable), as reflected by the evalu-ation metrics. For further insights, we compare our best-performingencoder-decoder (FLAN-T5) model to our best-performing decoder-only (Llama 2) model. FLAN-T5 follows the input format betterthan the Llama 2 during generation. 1.2% of generations with theFLAN-T5 do not match the possible action target space, comparedto 11.8% with Llama 2.Reviewing individual answers, Llama 2 is better at complex rea-soning compared to FLAN-T5, which produces more wrong actioncodes. This is reflected by the F1 score of the Llama 2 model, beatingthe other baselines by a large margin of 0.15. However, Llama 2does not handle uncertainty well. Especially when the user is vagueduring navigation, option selection or task searching, the modelhallucinates vague responses so that our LLM fallback handles theresponse. An example of this is co-reference. The user asks go tothe step after please after having heard Step 1. The correct answeris step_select(2). Llama 2 instead generates (step_select, unknown)which is a non-parseable wrongly formatted action code, whichmeans that no system action is executed. Overall, T5 models havethe advantage of a 100x lower latency compared to Llama modelsand we therefore prefer them for the repetitive calling of the NDPin the live system.",
  "Task-specific QA evaluation": "5.2.1Dataset Creation - WoTe. As our QA test dataset, we ex-tend the Wizard-of-Task dataset . Due to its conversational task-oriented user-lead nature, this dataset is closest to a real conver-sation with a TaskBot. The original dataset contains 17000 utter-ances from various conversations within the cooking and DIY do-mains. We filter out non-question user utterances by crowd workerannotation. This results in 4351 question-answer pairs, of which",
  "Question typeCountExample Question": "Factoid276Can the almonds be roasted or do theyneed to be raw?Navigation146Once the fill tubing is installed, whatstep comes next?Confirmation131Would my kitchen windowsill be agood place for the onions?Complex82Does that mean basil grows best in thespring and summer?Causal50Why shouldnt I mix in the sour creamat the same time?History33Sorry, what do I need to do?Listing27How much cream cheese and otheringredients will I need? we keep 1589 which are answerable with the task context. Next,we drop all questions labelled irrelevant and not useful by crowdworkers, resulting in 1337 questions. The original dataset does notinclude the task content, only links to task websites, which we needfor factually grounding answers. We scrape task content of linkedtasks, which is successful for 83% of tasks (1109). We also removepairs with inconsistent labels which require common or externalknowledge. This results in 827 final questions.We then manually annotate the remaining questions by addingthe extractive span that answers the question. We use the guidelineof selecting the first occurrence of the answer within the contextand keeping the answer span as short as possible.We also add a taxonomy to classify questions more granularlyfollowing Zaib et al. . We add two extra categories to the existingfive (factoid, causal, confirmation, listing, complex). The Historycategory describes questions where users ask for repetition fromthe conversational context. Navigation describes questions that askthe teacher to navigate through the task, i.e. moving forward astep. shows the distribution of types within the dataset andexample questions. We release the resulting WoTe (Wizard of Tasks- extractive) dataset on GitHub2. 5.2.2Metrics and Baselines. We compare traditional neural QAmodels such as FLAN T5 , UnifiedQA and T5 withgenerative LLM models such as Llama 2 . We use off-the-shelfmodels that can run on a single GPU with minimal tuning forevaluation. To ensure even distribution on the rather small dataset, we employ a 30% train, 20% validation, and 50% testing split.We finetune the models on the train split on an NVIDIA A10GGPU with the training objective of minimising the loss function ofpredicting the start and end token of the answer span.For T5 models, we concatenate the tokens of question andcontext. Due to limited token length, we retrieve the most relevantstep using sBERT for the T5 models. We also add a gold contextbaseline where we manually create the context to ensure the correctanswer is included in the context. We follow related work and report SQuAD token-wise metrics and ROUGE and BERT-Score",
  ". We evaluate the effect of fine-tuning and compare in-contextlearning to transfer learning": "5.2.3Abstractive Question Answering. Choi et al. provide origi-nal answers by human crowd workers as target answers in WoT.We experiment with more advanced generative models than theprovided baselines by the authors for the abstractive QA task.For T5 models, we notice issues with context parsing duringimplementation. We shorten the passed context to the most rel-evant step for most inputs to stay beneath the maximum inputtoken length. However, on our test set, our automatic truncationusing sBERT out-of-the-box only extracts the correct response of45% of samples (Precision = 0.54, Recall = 0.23). sBERT fails whenreasoning is required to select the step, for example, to answer acomplex question that requires combining steps. Another failurepoint is questions that contain many words from another step, e.g.if a user rephrases a step as part of their question. Furthermore,navigational questions that require selecting a specific step aredifficult. Therefore, in further evaluation, we only use manuallyannotated context to ensure the correct answer is in the context toensure fair model comparison. show model effectiveness for abstractive QA. All modelsperform badly with Rouge scores < 0.3. We verify this by manuallyannotating 50 random questions to evaluate model performance forcorrectness, completeness and understandability on a scale from0-2 (0: not, 1: somewhat, 2: fully). shows manual annotationresults. We observe that annotators disagree with the metrics per-formance. Especially for generative models, annotators agree thatalmost always mostly or fully correct, completely understandableand significantly better than the t5 baseline.We investigate why there is a discrepancy between user ratingsand metrics. Comparing model and teacher answers, teacher an-swers in the original dataset are often noisy. Teachers omit taskdetails required (e.g. food-2-1, food-10-0, food-135-4), could haveanswered from the task context (food-51-1), or are simply wrong(food-44-8, diy-194-8). Since this phenomenon repeats itself for manyquestions, the original answers are unusable for the task evaluation. 5.2.4Extractive Question Answering. For more accurate evaluation,we change the QA task to be extractive. We use our annotatedextracted answer snippets from the task context and conversationhistory and compare model output to the factually grounded contextsnippets. We define the extractive QA task as follows. Given a userquestion and a conversational context , the model extracts the",
  "t5-base1.161.02unifiedqa-t5-base1.461.32flan-t5-base1.161.16Llama-2-7b-hf1.321.22Llama-2-7b-chat-hf1.381.18": "answer substring from . The conversational context containsinformation about the task, such as task title, description, steps,and ingredients/ requirements. shows different model performance on the task-orientedextractive QA task. We compare zero-shot and finetuned modelswith t5 base zero-shot and finetuned as baselines, respectively.Across the board, all models perform badly with low metric scores.In addition, compared to the finetuned T5 baseline, none of the mod-els perform significantly better. The two generative models, Llama2 and LLama 2, even chat perform worse than the baseline. To verifythose results, we annotate 50 random questions and each modelsoutputs on a scale from 0-2 for correctness and completeness (0: not,1: somewhat, 2: fully). In contradiction to the metrics, annotatorsagree that the generative models and UnifiedQA perform betterthan the baseline, with UnifiedQA answers ranked significantlybetter ().We investigate why metrics penalise generative QA output. Wenotice that generative models are more likely to ignore the prompt asking for an extractive answer and hallucinate the output format.The metrics cant capture this - the extractive token-wise metricspenalise any output outwith the original context. If a generativemodel rewrites the span or adds explanations for model responses,the models metric score decreases.Next, we review model performance according to the questiontype taxonomy. Model performance on causal, complex, and confir-mation questions is low across models. However, the pre-trainedT5 models outperform the pre-trained Llama models for factoidQA. With closer analysis, the models tendency to add explanationpenalises their metric score and causes incorrect chain-of-thoughtexplanations (e.g. ). Compared to this, UnifiedQA achieves anF1 score of 0.524 (Llama 2 chat: 0.317). For listing questions, gen-erative models outperform T5 models due to T5 generating fewertokens (F1 Llama 2 chat: 0.541 vs FLAN T5: 0.366).In comparison, history and navigation questions require reason-ing and extraction of information from previous or future steps. Nomodel can do this well currently. T5 models outperform Llama innavigational questions for token-wise F1 (FLAN T5: 0.38 vs Llama2 chat: 0.23). Looking at individual outputs, Llama 2 answers areoften not fully wrong, but answer ambiguous questions differentlyto the teacher or do not follow the intended and pre-trained outputstructure.",
  "Task Adaptation evaluation": "GRILLBot modifies the task for users by replacing ingredients re-placement or adopting to dietary restrictions. Replacement gen-erator and task rewriter input and output structured data. Thegenerative component follows the structured format end-to-endin 60% of cases. In the live conversations with correctly formattedgenerations, the task rewriter rewrote the task for 56% of replacedingredients generated by the replacement generator correctly. Over-all, users accepted 34% of the suggestions given by the deployedsystem. We evaluate whether the suggestions recommended bythe LLM were factually correct and would work in practice byreviewing 25 conversations with accepted changes. According toour annotations, 73% of replacements would work, 18% were notcommon and 9% were incorrect.To gain a better understanding of why users do not accept a sug-gested replacement, we hand-annotate conversations. We randomlysample 50 unaccepted replacement suggestions and categorise userbehaviour. Most users do not accept the replacement since theyask for a new replacement suggestion, for other reasons includingstarting a new search or continuing with the original task.",
  "CONCLUSION": "In this work, we tackle the challenge of effective and efficient useof LLMs in interactive multimodal assistants. We decompose thetask into submodules and Discussing tradeoffs in latency, correct-ness and fluency, we show that a hybrid approach using LLMs andspecialised models for different components enables a fluent, knowl-edgeable, and dynamic assistant. GRILLBot helps users overcomechallenges as the task processes in the real world - possibly in newand unexpected ways. For reproducibility, we continue to publishkey components of GRILLBot as part of the OAT framework to allow quick deployment of similar assistants for the community. Inaddition, we release a new task-oriented complex QA dataset WoTe.Constraints in using LLMs live are response times and computa-tional resources needed, which is why we still often use smaller-scale specialised models with lower accuracy. However, with modeldistillation, we can deploy higher-quality models with lower latency.Using distilled models, we can perform model chaining where amodels output is the input for a larger model using a specific rout-ing framework. Second, a drawback of the generation abilities ofLLMs is hallucinations. In our system, generative models halluci-nate system abilities and unrealistic tasks and generate potentiallydangerous responses. Therefore, another line of work is to createspecialised models that guardrail inputs and outputs to generativemodels and enforce model grounding to build even more complexpipelines with more LLMs in the loop (e.g. ). The authors would like to thank the rest of the GRILLBot teamand the GRILL lab for their ongoing support, specifically AndrewRamsay. This work is supported by the Amazon Alexa Prize TaskBotChallenge. It was also supported by the Engineering and PhysicalSciences Research Council grant EP/V025708/1. Eugene Agichtein, Michael Johnston, Anna Gottardi, Cris Flagg, Lavina Vaz,Hangjie Shi, Desheng Zhang, Leslie Ball, Shaohua Liu, Luke Dai, et al. 2023.Alexa, lets work together: Introducing the second alexa prize taskbot challenge.2nd Proceedings of the Alexa Prize Taskbot Challenge 2 (2023).",
  "Amazon. 2023. Amazon Skill Kit": "Pawe Budzianowski, Tsung-Hsien Wen, Bo-Hsiang Tseng, Inigo Casanueva,Stefan Ultes, Osman Ramadan, and Milica Gai. 2018. Multiwoza large-scalemulti-domain wizard-of-oz dataset for task-oriented dialogue modelling. Proceed-ings of the 2018 Conference on Empirical Methods in Natural Language Processing(2018), 50165026. Giovanni Campagna, Silei Xu, Mehrad Moradshahi, Richard Socher, and Monica SLam. 2019. Genie: A generator of natural language semantic parsers for virtualassistant commands. In Proceedings of the 40th ACM SIGPLAN Conference onProgramming Language Design and Implementation. 394410. Jason Ingyu Choi, Saar Kuzi, Nikhita Vedula, Jie Zhao, Giuseppe Castellucci,Marcus Collins, Shervin Malmasi, Oleg Rokhlenko, and Eugene Agichtein. 2022.Wizard of tasks: A novel conversational dataset for solving real-world tasks inconversational settings. In Proceedings of the 29th International Conference onComputational Linguistics. 35143529. Hyung Won Chung, Le Hou, Shayne Longpre, Barret Zoph, Yi Tay, William Fedus,Yunxuan Li, Xuezhi Wang, Mostafa Dehghani, Siddhartha Brahma, et al. 2022.Scaling instruction-finetuned language models. arXiv preprint arXiv:2210.11416(2022). Rafael Ferreira, Diogo Tavares, Diogo Silva, Rodrigo Valrio, Joo Bordalo, InsSimes, Vasco Ramos, David Semedo, and Joao Magalhaes. 2023. TWIZ: Thewizard of multimodal conversational-stimulus. In Alexa Prize TaskBot Challenge2 Proceedings. Sophie Fischer, Carlos Gemmell, Iain Mackie, and Jeffrey Dalton. 2022. VILT:Video Instructions Linking for Complex Tasks. In Proceedings of the 2nd Interna-tional Workshop on Interactive Multimedia Retrieval. 4147. Sophie Fischer, Niklas Tecklenburg, Philip Zubel, Eva Kupcova, EkaterinaTerzieva, Daniel Armstrong, Carlos Gemmell, Iain Mackie, Federico Rossetto,and Jeff Dalton. 2023. GRILLBot-v2: Generative Models for Multi-Modal Task-Oriented Assistance. 2nd Proceedings of the Alexa Prize Taskbot Challenge (2023). Carlos Gemmell, Sophie Fischer, Iain Mackie, Paul Owoicho, Federico Rossetto,and Jeff Dalton. 2022. GRILLBot: A flexible conversational agent for solvingcomplex real-world tasks. 1st Proceedings of the Alexa Prize Taskbot Challenge(2022). Carlos Gemmell, Sophie Fischer, Federico Rossetto, Paul Ochiwo, Iain Mackie,Philip Zubel, Niklas Tecklenburg, and Andrew Ramsay. 2023. Open AssistantToolkit [OAT]: A research Platform for Multi-Modal Task Oriented Agents. Google. 2023. Dialogflow. Hakan Inan, Kartikeya Upasani, Jianfeng Chi, Rashi Rungta, Krithika Iyer, YuningMao, Michael Tontchev, Qing Hu, Brian Fuller, Davide Testuggine, et al. 2023.Llama guard: Llm-based input-output safeguard for human-ai conversations.arXiv preprint arXiv:2312.06674 (2023). Ziwei Ji, Nayeon Lee, Rita Frieske, Tiezheng Yu, Dan Su, Yan Xu, Etsuko Ishii,Ye Jin Bang, Andrea Madotto, and Pascale Fung. 2023. Survey of hallucination innatural language generation. Comput. Surveys 55, 12 (2023), 138. Daniel Khashabi, Sewon Min, Tushar Khot, Ashish Sabharwal, Oyvind Tafjord,Peter Clark, and Hannaneh Hajishirzi. 2020. Unifiedqa: Crossing format bound-aries with a single qa system. Findings of the Association for ComputationalLinguistics: EMNLP 2020 (2020), 18961907. Chandra Khatri, Behnam Hedayatnia, Anu Venkatesh, Jeff Nunn, Yi Pan, Qing Liu,Han Song, Anna Gottardi, Sanjeev Kwatra, Sanju Pancholi, et al. 2018. Advancingthe state of the art in open domain dialog systems through the alexa prize. 2ndProceedings of the Alexa Prize SocialBot Grand Challenge 2 (2018). Patrick Lewis, Ethan Perez, Aleksandra Piktus, Fabio Petroni, Vladimir Karpukhin,Naman Goyal, Heinrich Kttler, Mike Lewis, Wen-tau Yih, Tim Rocktschel,et al. 2020. Retrieval-augmented generation for knowledge-intensive nlp tasks.Advances in Neural Information Processing Systems 33 (2020), 94599474. Javier Marin, Aritro Biswas, Ferda Ofli, Nicholas Hynes, Amaia Salvador, YusufAytar, Ingmar Weber, and Antonio Torralba. 2018. Recipe1M+: a dataset forlearning cross-modal embeddings for cooking recipes and food images. arXivpreprint arXiv:1810.06553 (2018).",
  "OpenAI. 2022. Chatgpt: Optimizing language models for dialogue": "Paul Owoicho, Ivan Sekulic, Mohammad Aliannejadi, Jeffrey Dalton, and FabioCrestani. 2023. Exploiting simulated user feedback for conversational search:Ranking, rewriting, and beyond. In Proceedings of the 46th International ACMSIGIR Conference on Research and Development in Information Retrieval. 632642. Ashwin Paranjape, Abigail See, Kathleen Kenealy, Haojun Li, Amelia Hardy, PengQi, Kaushik Ram Sadagopan, Nguyet Minh Phu, Dilara Soylu, and Christopher DManning. 2020. Neural generation meets real people: Towards emotionallyengaging mixed-initiative conversations. 3rd Proceedings of the Alexa PrizeSocialBot Grand Challenge 3 (2020).",
  "Chantal Pellegrini, Ege zsoy, Monika Wintergerst, and Georg Groh. 2021. Ex-ploiting Food Embeddings for Ingredient Substitution.. In HEALTHINF. 6777": "Colin Raffel, Noam Shazeer, Adam Roberts, Katherine Lee, Sharan Narang,Michael Matena, Yanqi Zhou, Wei Li, and Peter J Liu. 2020. Exploring the limits oftransfer learning with a unified text-to-text transformer. The Journal of MachineLearning Research 21, 1 (2020), 54855551. Pranav Rajpurkar, Jian Zhang, Konstantin Lopyrev, and Percy Liang. 2016. Squad:100,000+ questions for machine comprehension of text. Proceedings of the 2016Conference on Empirical Methods in Natural Language Processing (2016), 23832392. RASA. 2023. RASA. Nils Reimers and Iryna Gurevych. 2019. Sentence-BERT: Sentence Embeddingsusing Siamese BERT-Networks. In Proceedings of the 2019 Conference on Em-pirical Methods in Natural Language Processing. Association for ComputationalLinguistics. Alexandra Rese and Pauline Trnkner. 2024. Perceived conversational abilityof task-based chatbotsWhich conversational elements influence the success oftext-based dialogues? International Journal of Information Management 74 (2024),102699. Sina Semnani, Violet Yao, Heidi Zhang, and Monica Lam. 2023. WikiChat: Stop-ping the Hallucination of Large Language Model Chatbots by Few-Shot Ground-ing on Wikipedia. In Findings of the Association for Computational Linguistics:EMNLP 2023. 23872413. Kurt Shuster, Jing Xu, Mojtaba Komeili, Da Ju, Eric Michael Smith, Stephen Roller,Megan Ung, Moya Chen, Kushal Arora, Joshua Lane, et al. 2022. Blenderbot 3:a deployed conversational agent that continually learns to responsibly engage.arXiv preprint arXiv:2208.03188 (2022).",
  "Rohan Taori, Ishaan Gulrajani, Tianyi Zhang, Yann Dubois, Xuechen Li, CarlosGuestrin, Percy Liang, and Tatsunori B. Hashimoto. 2023. Stanford Alpaca: AnInstruction-following LLaMA model": "Romal Thoppilan, Daniel De Freitas, Jamie Hall, Noam Shazeer, Apoorv Kul-shreshtha, Heng-Tze Cheng, Alicia Jin, Taylor Bos, Leslie Baker, Yu Du, et al. 2022.Lamda: Language models for dialog applications. arXiv preprint arXiv:2201.08239(2022). Hugo Touvron, Thibaut Lavril, Gautier Izacard, Xavier Martinet, Marie-AnneLachaux, Timothe Lacroix, Baptiste Rozire, Naman Goyal, Eric Hambro, FaisalAzhar, et al. 2023. Llama: Open and efficient foundation language models. arXivpreprint arXiv:2302.13971 (2023). Lei Wang, Chen Ma, Xueyang Feng, Zeyu Zhang, Hao Yang, Jingsen Zhang,Zhiyuan Chen, Jiakai Tang, Xu Chen, Yankai Lin, et al. 2023. A survey on largelanguage model based autonomous agents. arXiv preprint arXiv:2308.11432 (2023).",
  ": Prompt fed into the Alpaca model when the NDPgenerates a system action that doesnt have built back-endlogic, aka no system action should be performed live": "### Instruction: You are a friendly AI assistant who isassisting a human. Respond to the human or ask a questionback. Try to not repeat what you said previously. Youspecialise in cooking, arts & crafts, and DIY. You do notreveal your name in the spirit of fair competition. Youcannot play music, games or quizzes. You are not able toread the news, turn on a light, or give recommendationsfor things outside cooking and DIY domains.### Input:You: {last_system_response}Human: {user_utterance}### Response: Your response:",
  ": Prompt fed into the LLama 2 7b for QA": "<s> [INST] SYS You are a friendly assistant who helpspeople with cooking and DIY tasks. /SYSProvide a short answer to the user question from the con-text. If the context doesnt contain the answer truthfullysay <unknown>. You are only allowed to use informationfrom the context in your answer or say You are done ifthe user has reached the last step.Context: {Description} {Steps} {Ingredients}Question: {Question} [/INST] Answer:",
  "ALLM GENERATION": "Our LLM-based components generate interesting output acrossthe system. We use hybrid approaches to constrain generation toensure task safety and factualness based on task context and theLLMs world knowledge. shows the Fallback Prompt to the LLM, called when theNDP generates a system action that is not in the pre-defined actionspace, i.e. there is no back-end logic existing to translate this actioninto a system call. This means this is called when the action isbeyond system capabilities. shows examples of this. We showselected action codes that the Fallback handles, with various success.Despite our best attempts to constrain hallucinations, sometimesthe LLM still manages to hallucinate system abilities such as playingmusic. The dangerous classifier does not flag this as dangerous, andthe LLM did not follow the prompt passed in. U :Do you haveSpanishr e c i p e sS :C e r t a i n l y ! How aboutthesethreematches ?theylooksot a s t y !F i r s ti s :gluten f r e ef l o u rt o r t i l l a sr e c i p eby. . .U :Can you dot h a twith a Spanishaccent. . .S :Yes ,ofcourse !Ican dot h a twith a Spanishaccent .J u s twantedtosay ,you cans t a r tanew searchby saying\" cancel \"or\" r e s t a r t \" .U :New r e c i p e sS :C e r t a i n l y ! How aboutthesethreematches ? Theylooksot a s t y !F i r s ti s :Spanish s t y l epadronpeppers ,second :empanadas. . .U :Whati si n s i d eofempanadasinSpain. . .S :InSpain ,themostpopulari n g r e d i e n t sinempanadasareu s u a l l ybeef ,chicken ,potatoes ,onions ,g a r l i c ,ands p i c e s .",
  ": Selected reworded example conversations of liveusers with fluent and grounded GRILLBot": "Q: How longaretheg a r l i cand onionssupposedtocookf o r ?Golden :cooku n t i lgoldenLlama 27bhf :5 minutesLlama 27bchat hf :Accordingtothecontext ,theg a r l i cand onionsaresupposedtocookf o r5minutes ,ass t a t e dinthef oll ow ingsnippet :\"Add onions andg a r l i ctos k i l l e tand cooku n t i lgolden . \"",
  "User :play some smoothj a z z>> play_music ( )System :Sure ,Icanplay some smoothj a z z .Whatkindofj a z zdo you want tohear ?": "System :I fyou wouldl i k e ,Ican changether e c i p etouse what you haveat home .J u s task me tor e p l a c eani n g r e d i e n t .[ . . . ]User :placeani n g r e d i e n t>> ask_me ( )System :Funny enough ,Ij u s twasn ' tsurewhat todo with what yous a i d .[ . . . ]",
  "T i t l e :cucumber ,r a d i s hand seaweeds a l a d": "| D e s c r i p t i o n :n o o d l e l i k eblackseaweeds t r a n d s maket h i ss t r i k i n g l yc o l o r f u ls a l a dah e a l t h f u ls i d edishf o rp a i r i n gwithfish ,g r i l l e dtofuornoodled i s h e s .thes a l a db e n e f i t sfromatl e a s t30minutesinther e f r i g e r a t o rtomarinateinthev i n a i g r e t t e .",
  "| Steps :soak arameincoldwateru n t i ltender ,about15minutes . ;drainandt r a n s f e rto al a r g ebowl . ;": "add cucumbers, radishes, rice vinegar and tamari and toss to combine.;cover andc h i l lf o ratl e a s t30minutes .j u s tbeforeserving ,t o s sv e g e t a b l e st o g e t h e ragainands p r i n k l ewithsesameseeds .",
  "CWOTE CREATION": "shows an example of an annotated questions task contextduring the creation of WoTe. The blue extract corresponds to theannotated response for \"Is the vinaigrette part of the recipe orshould I be using a store-bought bottle?\" [food-135-1] and the greentext corresponds to the response to \"I think that it looks reallyyummy, and your response doesnt tell me about the cucumber.How much cucumber will I use in this dish?\" [food-135-4].",
  "DLATENCY OF COMPONENTS": "A challenge we balance throughout the competition is that largermodels tend to be more fluent and knowledgeable, but result inhigher response latency. Additionally, when the user load increases,this can slow down the inference time of models. We constantlybalance between improving the systems abilities and maintaininglow latency. shows the average latency for end-to-end re-sponses in our system. In Calendar Week 29, we deployed morecomputationally heavy components, resulting in a higher averagelatency but more fluent responses."
}