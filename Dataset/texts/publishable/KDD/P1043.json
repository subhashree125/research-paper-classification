{
  "ABSTRACT": "The recent surge in foundation models for natural language pro-cessing and computer vision has fueled innovation across variousdomains. Inspired by this progress, we explore the potential offoundation models for time-series forecasting in smart agriculture,a field often plagued by limited data availability. Specifically, thiswork presents a novel application of TimeGPT, a state-of-the-art(SOTA) time-series foundation model, to predict soil water potential(soil), a key indicator of field water status that is typically usedfor irrigation advice. Traditionally, this task relies on a wide arrayof input variables. We explore TimeGPTs ability to forecast soilin: () a zero-shot setting, () a fine-tuned setting relying solely onhistoricsoil measurements, and () a fine-tuned setting where wealso add exogenous variables to the model. We compare TimeGPTsperformance to established SOTA baseline models for forecastingsoil. Our results demonstrate that TimeGPT achieves competitiveforecasting accuracy using only historical soil data, highlightingits remarkable potential for agricultural applications. This researchpaves the way for foundation time-series models for sustainabledevelopment in agriculture by enabling forecasting tasks that weretraditionally reliant on extensive data collection and domain exper-tise.",
  "INTRODUCTION": "Recent years have witnessed a paradigm shift in artificial intelli-gence (AI) research, driven by the emergence of foundation mod-els in natural language processing (NLP) and computer vision(CV) . These models, trained on massive datasets and capable ofcomplex tasks, have spurred a wave of innovation across variousdomains. More recently, there has also been a rise of foundationmodels for time-series forecasting . For a full overview, werefer to . Based on these recent developments, we explore thepotential of foundation models for time-series forecasting in agricul-ture, specifically focusing on predicting soil water potential (soil),a key indicator of field water status.Gaining insight into future soil-levels is important for optimiz-ing irrigation scheduling, ensuring crop health and efficient cropmanagement . In turn, these optimized practices can directlycontribute to the United Nations Sustainable Development Goals(SDGs), such as SDG-6 and SDG-121. Recently, researchers haveexplored forecasting methods ranging from classic time-series andmachine learning techniques to more advanced deep learning-based methods like bi-directional Long Short-Term Memory net-works (LSTMs) and transformer-based approaches . A com-mon factor among these approaches is their substantial data re-quirements and the need for domain-specific knowledge to developa successful combination of input variables (see top). Yet,obtaining sufficient data in agriculture is not always straightfor-ward .To this end, this paper explores the applicability of foundationmodels for time-series forecasting in sustainable irrigation. Weleverage the power of a recent SOTA foundation model, calledTimeGPT, pre-trained on over 100 billion rows of financial, weather,Internet of Things (IoT), energy, and web data . This approachbypasses the need for extensive training data by benefiting from themodels ability to capture intricate temporal relationships withinthe data due to its extensive pre-training on data from variousdomains (see bottom). While foundation models are ver-satile by nature, they sometimes require fine-tuning when deployedfor specific use-cases, which we also investigate in this work.As such, our work contributes to the growing body of researchexploring the application of foundation models beyond NLP andCV. By demonstrating the effectiveness of foundation models forsoil forecasting, we pave the way for their broader adoption in",
  "PotentialFine-Tuning": ": Top: conventional approaches typically requirelarge amounts of data to train a well-performing forecastingmodel, which is not always feasible in agriculture due tohigh costs involved in sensor setup, maintenance, ... Bottom:foundation models require no data at all for inference (ina zero-shot setting) or require far less data for fine-tuningcompared to conventional approaches.",
  "(3) We provide insights and future directions for developingfoundation models tailored to agricultural time-series fore-casting": "The rest of the paper is organized as follows. presentsthe related work. formalizes the forecasting problem andpresents the settings of the study. presents the resultsof the analysis comparing TimeGPT with SOTA approaches anda discussion. Finally, provides a reflection on societalimpact, followed by a conclusion and directions for further workin .",
  "Forecasting Soil Water Potential": "Forecastingsoil is an important area of study, as part of the broaderfield of smart irrigation and smart agriculture. Proper insight intofuture soil-levels allows practitioners to schedule irrigation poli-cies and monitor general crop health. Driven by a paradigm shift inindustry and academia alike, recent literature has shown agrowing interest in using deep learning techniques for forecasting. The field of smart agriculture is no exception . For example, theauthors of , used multi-layer perceptrons (MLP) and LSTMsto forecast soil moisture levels, with promising results given suffi-cient data. Several others have explored LSTM-based approachesdue to their ability to capture temporal patterns. The authors of employed bi-directional LSTMs to forecast up to 14 days ahead.Note that the use of a bi-directional LSTM may be impractical whennot all variables are known 14 days in advance, as is often the casein real-world settings. In a more recent effort in , the authorscombined LSTMs with an attention mechanism, improving perfor-mance and interpretability for forecasts ranging from one to sevendays. Others utilized graph neural networks or convolutionalneural networks (CNNs) with gated recurring units to capturethe spatiotemporal relationships in soil moisture forecasting. Inrecent work, the authors of investigated a transformer-based ar-chitecture to forecastsoil five days ahead, outperforming an LSTMbaseline. They also showed that a global approach outperformslocal approaches, a general trend in forecasting .However, a common denominator among these approaches istheir reliance on substantial amounts of data for training, oftenspanning multiple years or seasons. This reliance presents a keychallenge in situations where there is only limited data available,insufficient to train a model, while the practitioner would stillbenefit from obtaining predictions to make informed irrigationdecisions. This limitation is a significant motivator for this work, aswe advocate for the use of pre-trained foundation models that canprovide useful predictions without training (in a zero-shot setting)or by fine-tuning them on a few samples of data. Notably, to the bestof our knowledge, no previous works have considered foundationmodels for forecasting soil-levels.",
  "Time-series Foundation Models": "While the field of time-series foundation models is still relativelynew, with one of the earliest examples in , a significant efforthas been made to leverage insights from the explosion of literatureon large language models (LLMs). For example, the authors of showed that a pre-trained model could be successfully transferredacross univariate time-series forecasting tasks without retraining(i.e., a zero-shot setting). One example literally uses LLMs byusing a quantization scheme to convert time-series into discretetokens, leading to a zero-shot LLM-based forecasting model. For afull overview on recent efforts concerning foundation models fortime-series, we refer the reader to . Notably, two recent worksstand out: TimeGPT and Lag-Llama , as they allow both forzero-shot forecasting and fine-tuning . As the former allowsfor the inclusion of exogenous variables, a potentially importantfactor in agriculture, we only consider TimeGPT in this work. Notethat TimeGPT also showed superior results in compared to itscompetitors.",
  "Problem Description": "Given a (potentially multivariate) time-series of input variables, weaim to forecastsoil up to 5 days ahead. Let X = (,1,,2, . . . ,,)denote the vector of input variables at time , where 1 is thenumber of variables. These input variables can include a rangeof environmental and meteorological factors such as temperature,rainfall, ... and previous soil measurements (see .2). Ourtarget variables are the soil values for the next 5 days, denoted asy+1:+5 = (+1,+2, . . . ,+5). That is, a multi-horizon forecast-ing problem.The objective is to develop a predictive model that uses the pastvalues of X to forecast thesoil up to time-steps into the future, i.e.y+1:+, where = 5 days. The time-series data can be represented",
  "y()+1:+ = (X(), X()1, . . . , X()+1;)(1)": "where y()+1:+ = ( ()+1, ()+2, . . . , ()+5) are the predicted soilvalues for the next for the -th time-series, and is the number ofpast time steps considered by the model which is model-dependent.Note that Eq. (1) represents a (multi-horizon) point forecast. In thecase of TimeGPT and some other baselines, a conditional distribu-tion P(y()+1:+|X()+1:) is predicted. To find the optimal modelparameters , we minimize the chosen loss function (which ismodel-dependent), Ltrn, during training as follows:",
  "= arg minLtrn(y, y)(2)": "where y are the predicted values and y are the true values acrossall time-series.In the context of foundation models, the parameters are ob-tained by pre-training on a massive dataset. Once trained, theseparameters are frozen during inference when considering a zero-shot setting, meaning that they are not updated further based onnew training data. This allows the model to make predictions onnew inputs without altering its pre-learned parameters. Alterna-tively, such foundation models can be fine-tuned by unfreezing andupdating (part of) the parameters during several training iterations.For other models such as the baselines described in .4,a training subset of the time-series is used to find the parameters that minimize the given loss function (cf. Eq. (2)). The amountof data required for training depends on the size of , with deeplearning models (as described in ) typically needing largedatasets to achieve good performance. This requirement can bechallenging to meet in an agricultural context, which is a key dri-ver for considering foundation models that leverage pre-trainedparameters for such applications.",
  "Dataset": "In this study, we use experimental data (obtained from ) fromthree commercial pear orchards during 2007 and 2009 in Belgium.We provide a brief description of each orchard below and provide afull overview of all variables in . Orchard A. This orchard is located in Bierbeek, featuring Con-ference pear trees grafted onto quince C rootstocks. These treeswere spaced at 3.3 x 1 meters and were meticulously trained in anintensive V-system to optimize sunlight exposure and air circula-tion. The orchards soil profile transitions from loam in the upperlayer to sandy loam below, with an organic carbon content of 1%in the top 30 cm. The orchard underwent a regime of annual rootpruning until 2006, followed by selective pruning in the years ofthe study. Orchard B. Situated in Sint-Truiden, this orchard grew Confer-ence pear trees on quince Adams rootstocks, at intervals of 3.5 x1.5 meters. Unlike Orchard A, these trees have never undergoneroot pruning and are trained in a free spindle system, which allowsfor a more natural growth pattern. The orchard has a loamy soilwith slightly higher organic carbon content than Orchard A. Orchard C. Located in Meensel-Kiezegem, Orchard C also fea-tured Conference pear trees on Quince Adams rootstocks, withthe same planting pattern as Orchard B. This orchard is distinctivefor its shallow groundwater table and slight slope, factors that sig-nificantly influence soil moisture dynamics and tree water uptake.Similar to Orchard A, selective root pruning was employed here inthe study years.In all orchards, standard commercial practices for pruning, dis-ease control, fertilization, and mulching were consistently applied,ensuring that the variations observed in soil water status could beattributed to the differences in soil, rootstock, and specific manage-ment practices like root pruning. This experimental setup providesa comprehensive basis for comparing model performance.",
  "Time-Series Foundation Models": "Time-series foundation models and foundation models more gen-erally are models that have been pre-trained on broad data atscale and are typically adaptable to a wide range of downstreamtasks . The success of foundation models is largely rooted inscaling laws suggesting that model performance (in terms of loss)scales as a power-law with model size, dataset size, and the amountof compute used for training . An overview of foundationmodels for time-series is provided in .2. Here, we willconsider the recently developed TimeGPT due to its ability togenerate zero-shot forecasts, while also allowing for fine-tuningand the inclusion of exogenous variables. Moreover, it achievedsuperior results compared to its competitors in . TimeGPT is agenerative pre-trained transformer model trained for time-seriesforecasting and anomaly detection. The model utilizes a trans-former architecture , characterized by its encoder-decoder struc-ture, where the encoder processes the input sequence of historicalvalues (X(), X()1, . . . , X()+1) with local positional encodings,and the decoder followed by a linear layer generates the forecast( ()+1, ()+2, . . . , ()+) over the specified horizon. Each layer withinthe architecture employs self-attention mechanisms to capture in-tricate temporal dependencies, enhanced by residual connectionsand layer normalization for stability and efficient gradient propa-gation . TimeGPT, as opposed to classic Transformers ,uses CNN blocks. Without clear justification in , we assumethis is due to their ability to capture spatiotemporal relationships",
  "VariableDescription": "Soil water potential () TargetThe -values averaged per day.Orchard nameOrchard name differentiates between orchards and (implicitly) their characteristics.Soil textureThe texture of the soil at a 0-30cm depth.Pruning treatmentWhether roots were pruned or not.Irrigation treatmentWhether deficit irrigation was applied or not.Measurement monthMeasurement month.PrecipitationDaily total precipitation.Reference evapotranspirationThe reference evapotranspiration (ETo).Irrigation amountAmount of irrigation applied to a specific plot.Soil temperatureDaily mean soil temperature around soil moisture sensors (measured by soil moisture sensor).",
  "Add & Norm": ": Overview of the TimeGPT architecture based on .Note that X can be univariate (containing only the history ofthe target), or multivariate (containing exogenous variablesalong with the history of the target). efficiently. A full overview of the TimeGPT architecture is providedin . Note that TimeGPT provides a probabilistic forecast,rather than a point forecast. It does this by leveraging a conformalprediction framework . Particularly, it estimates the modelserror by performing a rolling forecast on the latest available data,before outputting the actual forecast along with its estimated errorbounds. Lastly, in this work we consider three version of TimeGPT:() the zero-shot version (i.e., we use TimeGPT off-the-shelf), () a",
  "Baselines": "We employed a range of baselines to compare TimeGPT against. First,we implemented a simple naive baseline, which propagates the lastknown value of soil forward as the forecast, serving as a straight-forward yet informative benchmark. Additionally, we included aVector Autoregressive (VAR) model , leveraging its capabilityto capture linear interdependencies among multiple time-series.For more complex and non-linear relationships, we incorporated aLong Short-Term Memory (LSTM) network , which has demon-strated notable success in soil forecasting (cf., ) due toits proficiency in handling long-term dependencies and sequentialdata. Furthermore, we adopted the Temporal Fusion Transformer(TFT) , a state-of-the-art model that has also shown superiorperformance in soil forecasting. The TFT combines the strengthsof attention mechanisms and recurrent networks to effectively man-age temporal dynamics and variable interactions. These diversebaselines enable a comprehensive assessment of TimeGPTs perfor-mance across different modeling paradigms.",
  "TimeGPT Zero-Shot3.74217.05734.29797.4525TimeGPT Fine-Tuned3.20564.74563.73505.8773TimeGPT Fine-Tuned Exo.6.51716.20677.54617.5425": "nature of the data to avoid any overlap or information leakageamong these sets. illustrates how the data is segmented.Importantly, observations from the years 2007 and 2008 are des-ignated solely for the training set ( 45k 92%). This approachensures that the model is trained on data spanning two full growingseasons, enabling it to accurately learn and account for the seasonalfluctuations present in the dataset. The validation set is used formodel selection ( 2k 4%). Finally, the test set is used as arepresentative unseen real-world case to evaluate the predictionson ( 2k 4%). We calculate the mean absolute error (MAE) androot mean squared error (RMSE) across each horizon, and reportthe median across all time-series in the test set, along with theirinterquartile ranges (IQR).Note that TimeGPT, in the zero-shot setting, does not require anytraining or validation data, as there is no training to be done. Forfine-tuning TimeGPT, we use a subset of the training data and use250 training iterations (which takes approx. one minute on CPU).Fine-tuning involves continuation of model training, starting fromthe pre-trained parameters .",
  "Quantitative Results": "shows the quantitative results for TimeGPT and all baselines.A few observations stand out. For example, the TFT performs thebest overall. This is not entirely surprising given its strong perfor-mance across various domains . We believe that its strongperformance is also due to the explicit encoding of static informa-tion (e.g., orchard characteristics), which is not present in any of theother models. Interestingly, the second best-performing model isTimeGPT, fine-tuned using only the history of the target itself. This",
  ": Forecasts from the best performing models and thenaive for three randomly sampled sensors across differentorchards. The error bands for TimeGPT and the TFT are omit-ted for clarity": "is an important observation as this required significantly less dataand effort compared to training the TFT from scratch. As the au-thors of indicate, implementation complexity and computationcost2 are key factors for practical adoption. One can easily imaginethat practitioners in agriculture may favor a frictionless solution asopposed to training a complex model like the TFT from scratch. Sur-prisingly, adding exogenous data while fine-tuning TimeGPT leadsto much worse results. Due to the black-box nature of TimeGPT,its unclear why this is happening. We conjecture that the complexagricultural relationships among agricultural variables are not wellrepresented in the distribution of the data used during pre-trainingof TimeGPT. Of course, the seemingly strong performance of thenaive model, cannot be ignored and is discussed in detail in thenext section.",
  "Qualitative Results": "The relatively low error of the naive baseline is mainly due tostrong correlations between the last known value and future valuesas shown in . However, such naive forecasts are not usefulto the practitioner as they do not contain any new information.This becomes further apparent in . Here, we compare the",
  "Median MAE": ": Overview of how the MAE (median of MAE acrossmulti-horizon forecasts across all time-series in test set)evolves as the number of fine-tuning steps of TimeGPT grows.Here, TimeGPT is considered without exogenous data. naive and the two best performing models (TFT and TimeGPT fine-tuned) on their forecasts for three randomly sampled sensors acrossthe different orchards. Observe that the naive model, by definition,does not provide useful insights, particularly as time progresses.Consequently, the relatively strong performance of the naive modelcan be attributed to the fact that soil remains relatively close tothe last known value. From an agricultural perspective, this phe-nomenon is logical, as soil moisture, especially in wet climates,can take several days to dissipate depending on root distributionand other field characteristics. Meanwhile, the TFT shows strongperformance in some scenarios (e.g., top), but lacks in others (e.g.,middle). Similar observations are made for TimeGPT. Nonetheless,the results from and are promising to considerTimeGPT as an enabler in smart agriculture. Furthermore, the levelof fine-tuning of TimeGPT should also be considered. showsthe importance of carefully choosing the number of fine-tuningsteps. When the fine-tuning steps are low (the default is 10), themodel is seemingly underfitting. Conversely, allowing for too manytraining steps leads to overfitting . Regardless, this is essentiallythe only hyperparameter that needs tuned, as opposed to a panoplyof hyperparameters in the TFT .",
  "SOCIETAL IMPACT": "The application of foundation models like TimeGPT in agriculture,despite not yet achieving optimal performance, holds significantpromise for advancing sustainable agricultural practices in linewith the SDGs. Specifically, leveraging such models can contributeto SDG-6 (Sustainable Development) by enabling more precise soilmoisture forecasting, which supports efficient water use and canhelp improve crop yields.Additionally, the reduced computational requirements and easeof fine-tuning TimeGPT-like models align with SDG-12 (Respon-sible Consumption and Production), promoting the adoption ofresource-efficient technologies in agriculture. By providing action-able insights with minimal data and computational overhead, thesemodels can facilitate more resilient and sustainable agriculturalsystems.Moreover, the scalability and adaptability of foundation mod-els can aid in addressing climate variability and environmentalchallenges, supporting SDG-13 (Climate Action). While the perfor-mance of TimeGPT in agricultural forecasting is still evolving, itspotential to enhance sustainable farming practices and contributeto global food security and environmental stewardship should beconsidered. This opens doors to innovative, data-driven approachesthat empower farmers with the tools needed for sustainable andresilient agriculture.",
  "CONCLUSION": "In this work, we evaluated the feasibility and performance of TimeGPTfor forecasting soil moisture (soil) in an agricultural context, bench-marking it against several baseline models, including the state-of-the-art TFT. Our results demonstrate that TimeGPT is indeed capa-ble of forecasting soil, with notable performance when fine-tunedsolely on the target variables history. This approach required sig-nificantly less data and effort compared to training the TFT fromscratch, making TimeGPT a viable option for practical applicationsdue to its lower implementation complexity and computationalcost. Though, it should be noted that performance of TimeGPT isstill sub-par compared to the TFT.Surprisingly, incorporating exogenous data during TimeGPTsfine-tuning resulted in poorer performance, potentially due to thepre-training data distribution not adequately capturing the com-plex relationships between agricultural variables. This highlights aneed for future research to () explore TimeGPTs performance onother agricultural datasets or () better align pre-training data with",
  "Time-Series Foundation Models for Forecasting Soil Moisture Levels in Smart AgricultureKDD 24, Fragile Earth Workshop, August 2529, 2024, Barcelona, Spain": "specific agricultural contexts. Despite the naive models relativelystrong performance, which can be attributed to the persistence ofsoil moisture values, its lack of actionable insights limits its utilityfor agricultural decision-making.Qualitative analysis revealed that both the TFT and TimeGPThave strengths and weaknesses across different scenarios. The crit-ical role of fine-tuning for TimeGPT was evident, with both notionsof underfitting and overfitting observed depending on the num-ber of fine-tuning steps, emphasizing the need for tuning of thishyperparameter. However, TimeGPT requires tuning of far fewerhyperparameters compared to complex models such as the TFT.In conclusion, TimeGPT shows promise as a valuable tool forsmart agriculture, with its ease of fine-tuning and lower compu-tational demands, thereby directly and indirectly contributing toseveral SDGs. Future work should focus on optimizing the integra-tion of exogenous data and refining the pre-training or fine-tuningprocess to further enhance TimeGPTs performance in complex agri-cultural environments. Other competitive foundation models couldalso be considered. Olutobi Adeyemi, Ivan Grove, Sven Peets, Yuvraj Domun, and Tomas Norton.2018. Dynamic neural network modelling of soil moisture content for predictiveirrigation scheduling. Sensors 18, 10 (2018), 3408. Abdul Fatir Ansari, Lorenzo Stella, Caner Turkmen, Xiyuan Zhang, PedroMercado, Huibin Shen, Oleksandr Shchur, Syama Sundar Rangapuram, Sebas-tian Pineda Arango, Shubham Kapoor, et al. 2024. Chronos: Learning the languageof time series. arXiv preprint arXiv:2403.07815 (2024). Konstantinos Benidis, Syama Sundar Rangapuram, Valentin Flunkert, YuyangWang, Danielle Maddix, Caner Turkmen, Jan Gasthaus, Michael Bohlke-Schneider,David Salinas, Lorenzo Stella, et al. 2022. Deep learning for time series forecasting:Tutorial and literature survey. Comput. Surveys 55, 6 (2022), 136. Rishi Bommasani, Drew A Hudson, Ehsan Adeli, Russ Altman, Simran Arora,Sydney von Arx, Michael S Bernstein, Jeannette Bohg, Antoine Bosselut, EmmaBrunskill, et al. 2021. On the opportunities and risks of foundation models. arXivpreprint arXiv:2108.07258 (2021). Tom Brown, Benjamin Mann, Nick Ryder, Melanie Subbiah, Jared D Kaplan,Prafulla Dhariwal, Arvind Neelakantan, Pranav Shyam, Girish Sastry, AmandaAskell, et al. 2020. Language models are few-shot learners. Advances in neuralinformation processing systems 33 (2020), 18771901.",
  "Boje Deforce, Bart Baesens, Jan Diels, and Estefana Serral Asensio. 2024. Har-nessing the power of transformers and data fusion in smart irrigation. AppliedSoft Computing 152 (2024), 111246": "Alexey Dosovitskiy, Lucas Beyer, Alexander Kolesnikov, Dirk Weissenborn, Xi-aohua Zhai, Thomas Unterthiner, Mostafa Dehghani, Matthias Minderer, GeorgHeigold, Sylvain Gelly, Jakob Uszkoreit, and Neil Houlsby. 2021. An Image isWorth 16x16 Words: Transformers for Image Recognition at Scale. In InternationalConference on Learning Representations. Peng Gao, Jiaxing Xie, Mingxin Yang, Ping Zhou, Wenbin Chen, Gaotian Liang,Yufeng Chen, Xiongzhe Han, and Weixing Wang. 2021. Improved soil moistureand electrical conductivity prediction of citrus orchards based on IOT using DeepBidirectional LSTM. Agriculture 11, 7 (2021), 635.",
  "Pham Canh Huy, Nguyen Quoc Minh, Nguyen Dang Tien, and Tao Thi QuynhAnh. 2022. Short-term electricity load forecasting based on temporal fusiontransformer model. Ieee Access 10 (2022), 106296106304": "P. Janssens, F. Elsen, A. Elsen, T. Deckers, and H. Vandendriessche. 2011. AdaptedSoil Water Balance Model for Irrigation Scheduling in Conference Pear Orchards.In Acta Horticulturae, Vol. 919. International Society for Horticultural Science(ISHS), Leuven, Belgium, 3956. Tim Januschowski, Jan Gasthaus, Yuyang Wang, David Salinas, Valentin Flunkert,Michael Bohlke-Schneider, and Laurent Callot. 2020. Criteria for classifyingforecasting methods. International Journal of Forecasting 36, 1 (2020), 167177.",
  "Andreas Kamilaris and Francesc X Prenafeta-Bold. 2018. Deep learning inagriculture: A survey. Computers and electronics in agriculture 147 (2018), 7090": "Jared Kaplan, Sam McCandlish, Tom Henighan, Tom B Brown, Benjamin Chess,Rewon Child, Scott Gray, Alec Radford, Jeffrey Wu, and Dario Amodei. 2020.Scaling laws for neural language models. arXiv preprint arXiv:2001.08361 (2020). Manuel Kunz, Stefan Birr, Mones Raslan, Lei Ma, and Tim Januschowski. 2023.Deep Learning based Forecasting: a case study from the online fashion industry.In Forecasting with Artificial Intelligence: Theory and Applications. Springer, 279311.",
  "Qingliang Li, Yuheng Zhu, Wei Shangguan, Xuezhi Wang, Lu Li, and Fanhua Yu.2022. An attention-aware LSTM model for soil moisture and soil temperatureprediction. Geoderma 409 (2022), 115651": "Yuxuan Liang, Haomin Wen, Yuqi Nie, Yushan Jiang, Ming Jin, Dongjin Song,Shirui Pan, and Qingsong Wen. 2024. Foundation models for time series analysis:A tutorial and survey. arXiv preprint arXiv:2403.14735 (2024). Bryan Lim, Sercan Ark, Nicolas Loeff, and Tomas Pfister. 2021. Temporal fusiontransformers for interpretable multi-horizon time series forecasting. InternationalJournal of Forecasting 37, 4 (2021), 17481764. Boris N Oreshkin, Dmitri Carpov, Nicolas Chapados, and Yoshua Bengio. 2021.Meta-learning framework with applications to zero-shot time-series forecasting.In Proceedings of the AAAI Conference on Artificial Intelligence, Vol. 35. 92429250. Georgia Papacharalampous, Hristos Tyralis, and Demetris Koutsoyiannis. 2019.Comparison of stochastic and machine learning methods for multi-step aheadforecasting of hydrological processes. Stochastic environmental research and riskassessment 33, 2 (2019), 481514.",
  "Kamile Stankeviciute, Ahmed M Alaa, and Mihaela van der Schaar. 2021. Confor-mal time-series forecasting. Advances in neural information processing systems 34(2021), 62166228": "Ashish Vaswani, Noam Shazeer, Niki Parmar, Jakob Uszkoreit, Llion Jones,Aidan N Gomez, ukasz Kaiser, and Illia Polosukhin. 2017. Attention is allyou need. Advances in neural information processing systems 30 (2017). Anoushka Vyas and Sambaran Bandyopadhyay. 2022.Dynamic StructureLearning through Graph Neural Network for Forecasting Soil Moisture in Pre-cision Agriculture. In Proceedings of the Thirty-First International Joint Con-ference on Artificial Intelligence, IJCAI-22, Luc De Raedt (Ed.). InternationalJoint Conferences on Artificial Intelligence Organization, 51855191. AI for Good."
}