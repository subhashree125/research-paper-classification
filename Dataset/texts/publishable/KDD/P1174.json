{
  "ABSTRACT": "Event forecasting has been a demanding and challenging taskthroughout the entire human history. It plays a pivotal role in crisisalarming and disaster prevention in various aspects of the whole so-ciety. The task of event forecasting aims to model the relational andtemporal patterns based on historical events and makes forecastingto what will happen in the future. Most existing studies on eventforecasting formulate it as a problem of link prediction on temporalevent graphs. However, such pure structured formulation suffersfrom two main limitations: 1) most events fall into general andhigh-level types in the event ontology, and therefore they tend tobe coarse-grained and offers little utility which inevitably harms theforecasting accuracy; and 2) the events defined by a fixed ontologyare unable to retain the out-of-ontology contextual information.To address these limitations, we propose a novel task of context-aware event forecasting which incorporates auxiliary contextualinformation. First, the categorical context provides supplementaryfine-grained information to the coarse-grained events. Second andmore importantly, the context provides additional information to-wards specific situation and condition, which is crucial or evendeterminant to what will happen next. However, it is challengingto properly integrate context into the event forecasting framework,considering the complex patterns in the multi-context scenario.Towards this end, we design a novel framework named Separationand Collaboration Graph Disentanglement (short as SeCoGD) forcontext-aware event forecasting. In the separation stage, we lever-age the context as a prior guidance to disentangle the event graphinto multiple sub-graphs, followed by a context-specific module tomodel the relational-temporal patterns within each context. In thecollaboration stage, we design a cross-context module to retain thecollaborative associations among multiple contexts. Since there isno available dataset for this novel task, we construct three large-scale datasets based on GDELT. Experimental results demonstratethat our model outperforms a list of SOTA methods. The datasetand code are released via Both authors contributed equally to the paper.Corresponding author. Xiang Wang is also affiliated with Institute of Artificial Intelli-gence, Institute of Dataspace, Hefei Comprehensive National Science Center.",
  "INTRODUCTION": "Event forecasting is one of the long-standing and challengingtasks, including forecasting of pandemic outbreak , civil un-rest , international conflicts , etc. Accurately predicting suchvital events enables people to prepare in advance to prevent cata-strophic results or minimize potential influence. Automatic eventforecasting targets at modeling the rich relational and temporal pat-terns endowed by events observed in history, thus making accurateforecasting to events in the future. The development of data scienceand artificial intelligence endows human with stronger capabilityfor automatic event forecasting, which has garnered more and moreattention in recent years.One of the prominent formulations for event forecasting is todefine an event as a quadruple, i.e., (,,,), where , , , and refer to subject, relation (event type) 1, object, and timestamp,respectively. At each timestamp, all the quadruples form an eventgraph. Given a query of (,, + 1) in the future and the list ofhistorical event graphs until , we aim to predict the missing object.Based on such a structured formulation, a plethora of works havebeen emerging in recent years. They have applied structured rela-tional and temporal information (e.g., RE-NET , RE-GCN ),time intervals (e.g., EvoKG ), and texts from ontology and newsarticles (e.g., Glean and CMF ), etc. for event forecasting.Albeit the remarkable achievements of current works , they still suffer from the following limitations. First, existingstructured events tend to be classified as high-level general events,while more specific and informative events are few. As shown in(a), for the well-known GDELT dataset, while thehierarchical event type ontology defines a large number of fine-grained event types, most actual events were being classified into",
  "Olympics": ": The motivation of context-aware event forecasting.(a) Most current events fall in the coarse-grained and higherlevel types of the ontology, while more informative fine-grained events are fewer. (b) Out-of-ontology and diversecontexts affect events. Context can provide more fine-grainedinformation to enhance the event forecasting performance. event types in the higher levels of event ontology and fine-grainedevents are fewer. Consequently, the expressiveness of events isseverely restricted, resulting in less utility in practical scenarios.Second, events follow the types in the predefined ontology, whichis usually fixed due to the difficulty of construction. For example inpolitical event forecasting, the well-known CAMEO ontologycosts ten years to be finalized. It is difficult to update the ontologytimely, thus newly emerging out-of-ontology information is un-able to be covered by the outdated ontology 2. Worse still, eventsare greatly influenced by out-of-ontology contextual information,such as the situation and circumstance. As the example shown in(b), given diverse contexts, the entity President Y performsdistinct roles and actions w.r.t. the various countries of the world.Such diverse contexts that provide clues for certain situations, arecrucial or even determinant to event forecasting, and they cannotbe adequately modeled solely based on the event ontology.To address these limitations, we introduce context into existingevent representation as supplementary information and define anovel task named context-aware event forecasting. We associate eachevent with a categorical context, elaborating the events occurrencesituation or condition. Then each event is extended from a quadru-ple to a quintuple, i.e., (,,,,), where denotes the context. Theincorporation of context brings multiple benefits to event forecast-ing. First, it endows more fine-grained information to each event,thus making the coarse-grained events more specific and expres-sive. Second, the flexibly defined context is able to offer crucialinformation about the circumstances or backgrounds of the events,narrowing down the potential forecasting space. As the exampleshown in (b), given different contexts of Olympics 2016or G20 2022 Summit, the target countries that President Y wouldmake a visit to will be different. Despite various merits, integratingcontext into the problem of event forecasting poses new challenges",
  "Both out-of-ontology and outdated ontology refer to the same problem in this work": "to existing methods. First, one entity under different contexts maytrigger distinctive events, and how to capture the relational andtemporal patterns given a certain context is not trivial. Second,events from different contexts are also correlated with each other,and how to delicately model the collaborative associations amongcontexts is vital to accurate event forecasting.To tackle the above challenges, we borrow the idea from graphdisentanglement representation learning and propose a generalframework SeCoGD (Separation and Collaboration Graph Disenta-nglement), for context-aware event forecasting. It consists of twostages: separation and collaboration. First, in the separation stage,we utilize the context as a prior guidance to separate the eventgraphs into multiple sub-graphs. Then, we resort to establishedrelational-temporal models, such as RE-GCN , to capture thecontext-specific patterns within each sub-graph. Second, in thecollaboration stage, we construct hypergraphs among the disen-tangled embeddings and leverage GNN to learn the collaborativeassociations among contexts. Different from current graph disentan-glement methods that just focus on how to separate the graph, ourframework considers both separation and collaboration due to theprior guidance of context for the separation. Moreover, our methodis a general framework, of which the key modules can be replacedby alternative designs. At the same time, considering that there isno available dataset that has context information, we build threenew datasets based on GDELT. Extensive experiments demonstratethat our proposed framework outperforms various SOTA methods.The main contributions of our work are summarized as:",
  "Problem Formulation": "We first present the problem formulation of conventional eventforecasting, which does not consider the contextual information.Then we present how to introduce the context and formulate thenew task of context-aware event forecasting.Conventional Event Forecasting. We define an event as aquadruple (,,,), where E, R, and E correspondsto subject entity, relation, and object entity, respectively; is thetimestamp when this event happens; E and R are the entity andrelation set, respectively. All the quadruples in the same timestamp form an event graph, denoted as = {(,,,)}=1, where(,,,) is the -th event, and is the number of events attimestamp . Given the historical event graphs at and before time, denoted as G = {1,2, , }, and a query, denoted as(,, + 1), we aim to predict the object .",
  "Context-aware Event Forecasting via Graph DisentanglementKDD 23, August 610, 2023, Long Beach, CA, USA": "Context-aware Event Forecasting. We define context Cas a categorical value denoting certain situations or conditionsshared by a group of events, where C = {1,2, , } is the setof contexts and is the number of a few contexts. In practice, forhistorical events, the context can be obtained from human anno-tation, crowd-sourcing tags, or automatic information extractionsystems. We assign a context to each event, thus extending itsquadruple representation into a quintuple representation, denotedas (,,,,). Correspondingly, the event graph at each timestamp will be extended as = {(,,,,)}=1, where is thecontext of the -th event. Given the historical event graphs G,a query (,, + 1) and a specified context in which the queryevent is supposed to be, we target at predicting the object . Pleasenote that specifying the categorical context during inference willnot leak information about the predicted object. For example, giventhe context of Covid-19, the query \"which country that PresidentY will cooperate with\" will not be leaked to the model. And weassume that it is not difficult for human to provide such contextualinformation for a certain event he/she wants to predict.",
  "Dataset Construction": "Existing datasets for event forecasting are different cropped ver-sions of GDELT and ICEWS . For example, among thedatasets used by current works , ICEWS14, ICEWS18,ICEWS05-15 include events in the ICEWS dataset of year 2014, 2018,and 2005-2015, respectively; and GDELT covers January 2018 of theoriginal GDELT dataset. However, all of these versions only use theexisting quadruple data while overlooking the context information.To facilitate the study of context-aware event forecasting, webuild three benchmark datasets based on the GDELT dataset ,which provides the original news article URLs of the extractedevents. Following previous works , we crop three subsets ofGDELT according to the regions of the events, i.e., Egypt (EG), Iran(IR), and Israel (IS), spanning from February 2015 to March 2022.According to a previous systematical study , the structuredevents extracted by GDELT have high recall while low precision,which means there are many false positive events. Such noise couldbe caused by the event extraction system used in GDELT or the lowquality of original articles. Since the GDELT event extraction systemis unavailable to the public, we aim to remove low-quality articlesto eliminate these noises by the following data preprocessing steps.First, we keep the event with a valid URL. Second, we sort thedomain names of the URLs, which correspond to different newsagencies. In total, there are around 20K domain names, and thetop 69 cover 40% of the events. After checking these top domainnames, we confirm that their news articles are of higher qualityand reliability. Therefore, we remove the remaining 60% of eventsthat are published in long-tailed domain names, which are usuallyfrom less influential agencies or personal blogs and are likely to beof low quality or even fake. Third, even though the interval of twoconsecutive timestamps in the original GDELT data is 15 minutes,it is unnecessary to have such precise timestamps for politicalevents. Following ICEWS, we take the one-day time interval andcollapse the 15 minutes-level timestamps of events on the same dayto the day-level timestamp. Finally, we obtain the datasets and splitthem into training/validation/testing with a ratio of 8/1/1 over the",
  "EG2,59422596,0812,584377,43036,58828,644IR2,988236223,6162,584973,75269,82776,239IS3,456238345,6112,5841,430,389171,518156,695": "timeline. Due to the severe popularity bias of the dataset, severalmost frequent entities in the validation and testing set are masked.The statistics are shown in .Since there is no context label in the original GDELT dataset,we leverage the textual content and topic model (i.e., LDA ) as aproxy to generate contexts. In particular, we use an LDA model toextract the topic distribution of each article, where the topic withthe highest weight is treated as the context of an article. An eventis assigned with its corresponding articles context. More studiesabout the topic models as well as alternative context generation ap-proaches are presented in .4. To be noted, during inference,people can provide certain context for the query to be predicted.",
  "Separation": "In the separation stage, we first use the context as a prior guidanceto disentangle the event graph into multiple sub-graphs. Then wedevise a context-specific modeling module to capture the relationaland temporal patterns within each context. 3.1.1Context-aware Graph Disentanglement. Generally, events inthe same context exhibit similar or correlated patterns, while eventsin different contexts demonstrate distinctive characteristics. Cur-rent works connect all the quadruples at the sametimestamp as a unified event graph and learn a single embeddingfor each entity and relation via GNN models. However, such unifiedentity and relation embeddings are highly entangled w.r.t. diversecontext , failing to capture the context-specific patterns.Inspired by recent progress in disentangled representation learn-ing , we seek graph disentanglement for context-awareevent forecasting. Most existing works solely rely on the inher-ent structural information for graph disentanglement. For exam-ple, MaridVAE and DGCF utilize the user-item interac-tions to learn disentangled representations for different intents;DisenKGAT tackles the heterogeneous knowledge graph anddisentangles the entity embedding with respect to different topicsand clusters. Nonetheless, these methods are incapable of disen-tangling event graphs since the events are too coarse-grained, andpure structural information is unable to well disentangle the graph.We employ the context as a prior guidance to disentangle theevent graph. Formally, given contexts, we separate the original en-tangled event graph into sub-graphs {1 , , , ,},where each sub-graph contains all the events within context ,",
  "KDD 23, August 610, 2023, Long Beach, CA, USAYunshan Ma and Chenchen Ye et al": "can be used to replace the RE-GCN module for context-specificmodeling, hypergraph can be replaced by some regularizers (i.e.,L2 distance) that pull closer the disentangled representations, andmultiple modules could be manipulated as the decoder. 3.3.2Separation and/or Collaboration. Our work strengthens thatit is crucial to incorporate the collaboration stage on top of theseparation stage. However, most previous works on graph disen-tanglement solely focus on the separation part. For example, theyeither leverage regularization terms to maximize the mutual in-formation among multiple chunked representations or useattention mechanism to make different disentangled repre-sentations attend on various sub-graphs. We assume that suchcontradictory modeling philosophy roots in two reasons. First, wehave prior knowledge as the guidance for the disentanglement,therefore, we do not need any heuristically manipulated disen-tanglement strategies, such as mutual information maximizationor attention. Second and more importantly, we believe that thecrux of an effective graph disentanglement model lies in a goodbalance of separation and collaboration. Current works are builtupon a unified graph model, which is highly intertwined. Thereby,a separation module is necessary to eliminate the entanglement.Meanwhile, we disentangle event graphs by the prior contextualinformation, where the sub-graphs are well or even over separated,thus a collaboration module is required to rectify the separation.",
  ",(1)": "where is the dimensionality of the message, E stands for all theevents of which is the object, W1, W2 R are the parametersof the convolutional kernel in layer , and () is the activationfunction which we use RReLU. To be noted, e, E, e1, r, e1allstand for their corresponding representations in time of context ,where we omit the subscript (,) for simplicity. After performingmulti-layer message passing, we aggregate the messages obtainedfrom multi-layer propagation and yield the entity representation attime under context , defined as:",
  "=0e,,,(2)": "where e0,, = e0, R is randomly initialized for each entity under each context . And the representations for all entities attimestamp within context are denoted as E, R| E|.Temporal Pattern Modeling is designed to capture the tem-poral evolution of entities and relations. Following the previousstudy , we devise a learnable gate mechanism to reserve theentities evolving patterns. It is formally defined as:",
  "In the collaboration stage, we leverage hypergraphs to model thecross-context collaborative associations. Then we perform context-aware prediction and optimization": "3.2.1Cross-context Modeling. Even though the same entity demon-strates different characteristics in various contexts, these contextsare not independent but correlated with each other. For example,given the contexts of Covid-19 Pandemic and Russia-Ukraine War,many countries must consider them simultaneously to make eco-nomic policies, in order to minimize the influence on their economyas well as social stability. To this end, capturing such correlationis crucial for some events that are affected by multiple contexts.Furthermore, after disentangling the event graph into multiple con-texts, each sub-graph will be sparser than the original unified graph.Some entities that do not have sufficient occurrence in a certaincontext will not be well-trained for accurate forecasting. For suchfew-shot entities and relations, transferring knowledge from othercontexts that have sufficient training data is a promising solution.Based on the above motivations, we devise a collaboration mod-ule to model the collaborative effects among multiple contexts,aiming to achieve potential knowledge transfer for sparse enti-ties. It is worth mentioning that we do not have supervised infor-mation to quantify the correlations among contexts, thus, we areunable to explicitly model the collaborative effects. Consideringthis, we resort to hypergraph to model the latent collaborations.Concretely, for each entity , we construct a hypergraph among itssub-embeddings in different contexts, where the nodes are the sepa-rated embeddings of all entities (relations) in different contexts andevery hyper-edge connects the separated embeddings of the sameentity (relation). Then we leverage a multi-layer LightGCN topropagate over every hypergraph, and e, R is the -th layerpropagated information to node under context , obtained by:",
  "=0e,,(8)": "where e0, is the representation of entity in E. After the hyper-graph propagation, all entities are represented as E.Analogous to entities, relations representations in different con-texts are also totally isolated during the context-specific modeling.Thereby, for each relation, we also build a hypergraph and takeadvantage of a multi-layer LightGCN kernel to capture the collabo-rative associations among different contexts, defined as:",
  "C\\{}r1, ,(9)": "where r, R is information propagated to relation in layer ,and C is the set of contexts that relation has been in over thehistorical observations. With layers of graph propagation, weaggregate multiple layers representations and obtain the final rela-tion embedding r,, formally written as: r, = =0 r,, wherer0, is relation s embedding in R. 3.2.2Context-aware Prediction and Optimization. With the context-specific and cross-context modeling modules, we learn the entityand relation representations that not only capture context-awarecharacteristics but also preserve transferred knowledge from othercontexts. Following the established approach to event forecast-ing , we devise a decoder based on ConvTransE . Inparticular, given a query quadruple (,,,), we first use a Con-vTransE to produce the querys representation, then score the candi-date entities E via inner-product between the query and candidaterepresentations. Formally, we calculate the prediction scores for allcandidate entities given the query (,) at time + 1 under context",
  "To further highlight the key contributions of this work, we discussthe generalization capability of SeCoGD, as well as the rationalebehind separation and collaboration": "3.3.1Generalization Capability. We argue that our method SeC-oGD is a general framework instead of a specific model. The keycontribution of SeCoGD lies in two aspects: 1) it makes use of con-text as a prior guidance to disentangle the event graph; and 2) itproposes a novel graph disentanglement idea under prior-guideddisentanglement, that is to model the collaborative associationamong the disentangled representations. First, the context can beflexibly defined according to various application scenarios. For ex-ample, the tag of the news article that an event belongs to can beused as its context. Alternatively, similar to our solution of thelatent topic model, various automatic text clustering algorithms,such as K-means or GMM (Gaussian Mixture Model), are plausibleto identify the latent contexts of events. Second, each componentof SeCoGD has various alternatives. For example, RE-NET",
  "Experimental Settings": "We conduct experiments on the three datasets that we constructed,i.e., EG, IR, and IS. The construction and statistics of the datasetscan be found in .2. Following previous settings , we useMean Reciprocal Rank (MRR) and HIT@{1, 3, 10} as the evaluationmetrics. We use MRR to select the best model based on the validationset and record its corresponding performance on the testing set. 4.1.1Compared Methods. Since current works have never studiedthe newly proposed problem of context-aware event forecasting ontemporal event graph data, we select several strands of the mostrelevant works to compare with our proposed method. Static KG completion methods treat event forecasting as alink prediction task on the static event graph. We select thefollowing representative methods: DistMult , ConvE ,ConvTransE , RotatE , and RGCN . Temporal KG forecasting methods are designed for temporalevent forecasting. These methods consider both relational andtemporal information for link prediction in the next timestamp.We consider the following SOTA methods: TANGO , RE-NET , RE-GCN , EvoKG , and HiSMatch .",
  "Temporal event forecasting methods with texts incorporatetextual information into the event forecasting model, while thestandard temporal KG forecasting methods only use structural": "information. In particular, we implement two versions of a rep-resentative method: 1) CMF , by faithfully following thesettings of the original work and incorporating the event textualdescription defined in the CAMEO ontology into the structuralevent forecasting model. In addition, we also re-implemented 2)CMF , which differs from CMF by using the originalarticle embeddings extracted by doc2vec instead of using thetexts in the ontology. CMF is originally designed for binary clas-sification of a event happening or not. We replace their task headwith a typical ConvTransE decoder to enable link prediction. Graph disentanglement methods aim to separate the inter-twined relational information into disentangled representations.We take into account two representative graph disentanglementmethods: DisenGCN and DisenKGAT . Both of themethods are designed for static graphs. 4.1.2Hyper-parameter Settings. We implement all the static meth-ods using OpenKE 3, for TANGO, RE-NET, RE-GCN, and EvoKG, weuse their released code. For CMF and HiSMatch, we re-implementthem by ourselves since these methods have not released the code.To be fair and following previous settings , for all the base-lines and our method, we set = 200, use cross-entropy loss,search learning rate from {0.01, 0.001, 0.0001} and weight decayfrom {104, 105, 106, 107}. For temporal methods, we searchthe historical graph length in the range of {1,3,7}. For our method,we search the number of RGCN propagation layers from {1,2,3},the number of hypergraph propagation layers from {1,2}, the num-ber of LDA topics (aka. contexts) from {3, 5, 7}. We use Adam optimizer and Xavier initialization for all the parameters.",
  "Performance Comparison (RQ1)": "shows the overall performance of our model and baselines.First of all, our method outperforms all the baselines on all threedatasets. Among all the metrics, the improvement on HIT@1 isthe highest, which is truly helpful in practice. Second, for all thebaselines, RE-GCN achieves the best performance and even beatsthe models with textual inputs (i.e., CMF and CMF), demon-strating its superiority in modeling temporal event graphs. Thisis why we select RE-GCN for context-specific modeling in our im-plementation. Third, in terms of the methods with textual inputs,CMF and CMF perform well, beating most of the static andtemporal methods. The results imply that the additional textualinformation offers valuable clues that are crucial to forecast futureevents. However, they are not the strongest baseline, probably be-cause they are originally designed for binary event classificationand the link prediction head is not perfectly adapted. Finally, forthe two graph disentanglement-based methods, i.e., DisenGCN andDisenKGAT, they do not perform very well. There are two possiblereasons: 1) they rely on the static global graph, which cannot modelthe temporal evolving patterns; and 2) more importantly, the eventsin current datasets are coarse-grained and less discriminative, there-fore, the methods that solely rely on structured data fail to learndisentangled representations. The results also justify our methodthat leverages the context as a prior guidance, instead of graphstructure, to separate the event graph.",
  "We conduct model studies to analyze the effect of the key modulesin the two stages, i.e., separation and collaboration": "4.3.1Study of the Separation Stage. For the concurrent eventmodeling, we use the RGCN kernel. We tune the number of prop-agation layers, and the results are shown in . Basically, twoand three layers are better than one layer, depicting that higher-order information propagation over the concurrent event graph isbeneficial to capture the context-specific signals. We also replaceRGCN with CompGCN , and illustrates the results.Overall speaking, CompGCN and RGCN perform similarly to eachother on the three datasets, and they differ slightly in terms ofdifferent evaluation metrics. It shows that our framework is notsensitive to relational modeling models.For the temporal pattern modeling module, we tune the lengthof historical graphs that we used to generate the entity and",
  "Avr. Context0.1300.3090.1630.3730.1290.331": "relation embeddings. We try different historical length within {1,3, 7} and visualize the results in . For HIT@10, the longerthe historical length is, the better the performance will be. Butfor MRR, EG and IR achieve the best performance with D=1 andD=2, respectively. This difference reminds practitioners to properlyselect evaluation metrics according to the application scenarios. Forexample on the EG dataset, if we care more about the ranking ofthe prediction, we need to choose MRR and set D=1. Meanwhile, ifwe pay more attention to the hit rate of the top-10 predicted results,HIT@10 with D=7 should be a better option. In addition, longerhistorical length takes extra computational costs. Therefore, it is atrade-off between efficacy and efficiency in practice. 4.3.2Study of the Collaboration Stage. We construct a hypergraphover the sub-embeddings of each entity and relation to retain thecollaborative associations across multiple contexts. To test the ef-ficacy of the collaboration stage and the implementation of the",
  "LDA(SeCoGD)0.1460.3240.1760.3970.1550.369": "hypergraph, we design several ablated models by progressivelyremoving the two hypergraphs of entity and relation. In ,\"w/o Ent HG\", \"w/o Rel HG\", and \"w/o Ent or Rel HG\" refer towithout relation hypergraph, without entity hypergraph, and withouteither entity or relation hypergraph, respectively. From the results,we can see that the results of removing either relation or entity hy-pergraph are worse than SeCoGD but better than that of removingboth, demonstrating the efficacy of both hypergraphs. More inter-estingly, the performance drop of removing the entity hypergraphis generally larger than that of removing the relation hypergraph,implying that the collaboration of entities is more valuable.During prediction, our context-aware event forecasting will paireach query (,, +1) with an auxiliary context . By specifying thecontext, its corresponding branch of the decoder will be selectedand performs the forecasting. We argue that such a context-awareprediction narrows down the candidate space and performs better.To justify our hypothesis, we curate a variant, in which we donot specify the context during inference while just averaging theprediction scores from all the context decoders, corresponding tothe row \"Avr. Context\" in . We can observe that \"Avr. Context\"performs much worse than SeCoGD. This phenomenon indicatesthat the specification of the proper context during inference iscrucial to SeCoGD, justifying our hypothesis that the context playsa pivotal role in accurate event forecasting.",
  "Study of the Context (RQ3)": "4.4.1Effect of the Number of Contexts. We vary the number ofLDA topics when we generate the context based on the newsarticle, resulting in multiple versions of datasets with differentnumber of contexts. We implement SeCoGD on all the versions ofdataset and obtain the results, which are presented in . Ingeneral, more contexts yield better performance. This is naturaland reasonable because when the number of contexts increases,each context will be more specific, resulting in more fine-grainedinformation being injected into the event. However, more contextsinevitably introduce more computational expenses. We leave thestudy of efficiency and scalability improvement in future work.",
  "Effect of the Context Curation Methods. We define the contextas a categorical label for each event, while LDA is just one of the": "automatic methods in order to avoid extensive labor and costs forcontext annotation. We argue that alternative automatic approachesare also workable for our framework. To illustrate this property, weleverage two prominent text clustering methods, i.e., K-means andGMM (Gaussian Mixture Model) using the article embeddings pre-trained by doc2vec , to generate contexts. Results based on thenewly-generated contexts are shown in . From the results, wecan conclude that SeCoGD is generally able to outperform RE-GCNby leveraging the contexts generated with alternative clusteringmethods. This further illustrates that our method is robust to diversecontext sources. Nonetheless, our proposal of using LDA to generatecontexts performs best, thus we take it as the default setting. 4.4.3Case Study. We seek to elicit the content of each context,thus to elaborate how different events are predicted under distinctcontexts. As shown in , for each dataset, we illustrate the topwords of each context in the form of word cloud (the size of eachword is proportional to its weight in the LDA topic distribution).From word clouds, we observe rich information within each contextand clear content differences among contexts. For example, eachcontext in the EG dataset covers background information such aspopular actors, important cities, and critical actions; meanwhile,they are about economic, military, and political events respectively.We also pick an example query (,, + 1) from the testing set ofeach dataset to concretely explicate the benefits of context-awareevent forecasting. We list the object with the highest score predictedby RE-GCN and SeCoGD, and we observe that SeCoGD generatesmore accurate prediction results compared to RE-GCN. With agiven context , general event types such as Consult, Negotiate,and Host a visit are now narrated with more supplementary infor-mation modeled in the context, leading to better results. We alsoobserve that given the same query, SeCoGD sometimes predictsdistinct objects under different contexts. For example, for the ex-ample query in IS dataset, SeCoGD predicts that Israel will host avisit for Ukraine students under Context 2, and predicts UK insteadunder Context 3. We notice that both events exist in the dataset andthus are both correct, and the two predictions are in line with thecontents of their context. As shown in the word cloud for IS Context2 and 3, the former prediction might take more military factors intoconsideration, and the latter is more related to government affairs.This demonstrates the flexibility in depicting the event by context.",
  "RELATED WORK5.1Temporal Event Forecasting": "Temporal event forecasting aims to forecast future events basedon a list of observed historical events. It has been studied in vari-ous application scenarios, including criminal activities , diseaseoutbreaks , stock markets , as well as international politi-cal events . Various problem formulations are utilized withregard to different event types, such as time series forecasting, nat-ural language generation, and link prediction. In this work, wefollow the typical formulations of link prediction, which is alsocalled temporal knowledge graph completion. It inherits from staticknowledge graph completion, where the key is to learn relationalembeddings via various scoring functions, such as TransE , Dist-Mult , ComplEx , RotatE , ConvE , ConvTransE",
  "(b) Dataset IR(c) Dataset IS": ": Case study on three datasets. In each sub-figure, the context number K is set as three, the top shows the word cloud ofeach context, and the bottom illustrates several exemplar forecasting results by SeCoGD and RE-GCN. etc. To tackle the temporal evolving patterns and forecast futureevents, recurrent neural network (RNN) has been included.RE-NET proposes to use RGCN to capture the relationalpatterns in each timestamp and GRU to model the dynamics ofembeddings over time. RE-GCN additionally incorporates astatic graph to learn the static properties of the entities and adoptsConvTransE as the decoder. TANGO models the struc-ture of candidate entities via neural ordinary differential equations;EvoKG considers the time information for event forecasting;HiSMatch reformulates event forecasting as a query-candidatematching problem and proposes a two-branch framework to matcha query to candidate entities. More related works can be seen in the survey . Most of these TKG methods onlyoperate on pure structured data, overlooking the rich semantic orcontextual information. To address these limitations, Glean andCMF propose to use the textual information. They simplifythe event forecasting problem from fine-grained link prediction toan easier binary classification problem, i.e., predicting whether anevent will happen or not. In addition, the textual information isonly available for historical events but unavailable for future events,thus this additional information cannot directly narrow down thecandidate space. Some works also use context for event prediction,while they are either for event status classification or time seriesforecasting , which are different tasks.",
  "Graph Disentanglement": "Graph neural networks have been the defacto solutionsfor graph representation learning. Graph disentanglement is theextension of disentangled representation learning from the generaldomain to the graph data. Disentangled representation learningfocuses on separating the unified representation into multiple dis-entangled components, thus achieving many excellent modelingproperties such as enhanced representation capability or explain-ability. Various studies have been conducted on CV , NLP , aswell as recommender system . For graph representationlearning, disentanglement has also garnered particular attention.DisenGCN is one of the pioneering works to use multiple dis-entangled graph convolutional kernels to learn disentangled noderepresentations. FactorGCN factorizes the node embeddinginto multiple blocks, which captures interpretable global topologi-cal semantics. IPGDN leverages the Hilbert-Schmidt Indepen-dence Criterion (HSIC) to achieve disentanglement. ADGCN introduces adversarial learning to graph disentanglement repre-sentation learning. DisenHAN is designed for heterogeneous graph, where multiple node and relation types are involved. Themost relevant work for event forecasting is DisenKGAT , whichaims to learn disentangled representations for knowledge graph.Despite various studies on graph disentanglement, our work differsfrom current works and promotes these works in several aspects.First, we are the first to introduce graph disentanglement learningto temporal event forecasting. Second, most of the existing worksaim to directly disentangle the graph purely using the graphs ownfeatures, ignoring the contextual information.",
  "CONCLUSION AND FUTURE WORK": "In this work, we explored the incorporation of context into theproblem of event forecasting and proposed a novel task of context-aware event forecasting. To tackle this novel problem, we borrowedthe idea from graph disentanglement and designed an overall frame-work SeCoGD. Specifically, we utilized the context as prior guidanceto separate the event graph and incorporated a context-specificmodeling module to capture the relational and temporal patternsin each context. In addition, we designed a cross-context modelingmodule to model the collaborative associations among multiplecontexts. Since there are no available datasets for this new task, webuilt three large-scale datasets based on GDELT. Extensive experi-ments on these three datasets demonstrated that our frameworkoutperforms all the SOTA methods. Various model studies furtherelaborated more details about the effectiveness of the key modulesand various contexts of the framework.Despite the progress achieved by this work, there are several lim-itations, thus motivating multiple potential research directions inthe future. First, the implementation of context generation is basedon unsupervised methods, while human-generated contexts, suchas tags and categories, could be more useful in practice. Second, theoriginal articles of these events are just used as a proxy to generatecontexts, of which just a little information has been utilized. Moreeffective approaches to mining more beneficial patterns from rawtexts are promising. Third, more advanced graph disentanglementmethods are expected to be explored and enhance the performance.Finally, in addition to next step prediction, the more important yetchallenging multi-horizon forecasting should be studied in future.",
  "Borui Cai, Yong Xiang, Longxiang Gao, He Zhang, Yunfeng Li, and Jianxin Li.2022. Temporal Knowledge Graph Completion: A Survey. CoRR abs/2201.08236(2022)": "Xi Chen, Yan Duan, Rein Houthooft, John Schulman, Ilya Sutskever, and PieterAbbeel. 2016. InfoGAN: Interpretable Representation Learning by InformationMaximizing Generative Adversarial Nets. In NIPS. 21722180. Kyunghyun Cho, Bart van Merrienboer, aglar Glehre, Dzmitry Bahdanau,Fethi Bougares, Holger Schwenk, and Yoshua Bengio. 2014. Learning PhraseRepresentations using RNN Encoder-Decoder for Statistical Machine Translation.In EMNLP. ACL, 17241734. Zeyu Dai, Wenlin Yao, and Ruihong Huang. 2017. Using Context Events in NeuralNetwork Models for Event Temporal Status Identification. In IJCNLP(2). AsianFederation of Natural Language Processing, 234239.",
  "Kalev Leetaru and Philip A Schrodt. 2013. Gdelt: Global data on events, location,and tone, 19792012. In ISA annual convention, Vol. 2. Citeseer, 149": "Zixuan Li, Zhongni Hou, Saiping Guan, Xiaolong Jin, Weihua Peng, Long Bai,Yajuan Lyu, Wei Li, Jiafeng Guo, and Xueqi Cheng. 2022. HiSMatch: Histor-ical Structure Matching based Temporal Knowledge Graph Reasoning. CoRRabs/2210.09708 (2022). Zixuan Li, Xiaolong Jin, Wei Li, Saiping Guan, Jiafeng Guo, Huawei Shen,Yuanzhuo Wang, and Xueqi Cheng. 2021. Temporal Knowledge Graph Rea-soning Based on Evolutional Representation Learning. In SIGIR. ACM, 408417.",
  "Sean P Obrien. 2010. Crisis early warning and decision support: Contemporaryapproaches and thoughts on future research. International studies review 12, 1(2010), 87104": "Maya Okawa, Tomoharu Iwata, Yusuke Tanaka, Takeshi Kurashima, HiroyukiToda, and Hisashi Kashima. 2022. Context-aware spatio-temporal event predic-tion via convolutional Hawkes processes. Mach. Learn. 111, 8 (2022), 29292950. Namyong Park, Fuchen Liu, Purvanshi Mehta, Dana Cristofor, Christos Faloutsos,and Yuxiao Dong. 2022. EvoKG: Jointly Modeling Event Time and NetworkStructure for Reasoning over Temporal Knowledge Graphs. In WSDM. ACM,794803. Michael Sejr Schlichtkrull, Thomas N. Kipf, Peter Bloem, Rianne van den Berg,Ivan Titov, and Max Welling. 2018. Modeling Relational Data with Graph Con-volutional Networks. In ESWC (Lecture Notes in Computer Science, Vol. 10843).Springer, 593607."
}