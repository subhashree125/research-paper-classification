{
  "ABSTRACT": "Sepsis is the leading cause of in-hospital mortality in the USA. Earlysepsis onset prediction and diagnosis could significantly improvethe survival of sepsis patients. Existing predictive models are usuallytrained on high-quality data with few missing information, whilemissing values widely exist in real-world clinical scenarios (espe-cially in the first hours of admissions to the hospital), which causesa significant decrease in accuracy and an increase in uncertaintyfor the predictive models. The common method to handle missingvalues is imputation, which replaces the unavailable variables withestimates from the observed data. The uncertainty of imputationresults can be propagated to the sepsis prediction outputs, whichhave not been studied in existing works on either sepsis predictionor uncertainty quantification. In this study, we first define suchpropagated uncertainty as the variance of prediction output andthen introduce uncertainty propagation methods to quantify thepropagated uncertainty. Moreover, for the potential high-risk pa-tients with low confidence due to limited observations, we proposea robust active sensing algorithm to increase confidence by activelyrecommending clinicians to observe the most informative variables.We validate the proposed models in both publicly available data(i.e., MIMIC-III and AmsterdamUMCdb) and proprietary data inThe Ohio State University Wexner Medical Center (OSUWMC). Theexperimental results show that the propagated uncertainty is domi-nant at the beginning of admissions to hospitals and the proposedalgorithm outperforms state-of-the-art active sensing methods. Fi-nally, we implement a SepsisLab system for early sepsis predictionand active sensing based on our pre-trained models. Cliniciansand potential sepsis patients can benefit from the system in earlyprediction and diagnosis of sepsis.",
  "Corresponding Author": "Permission to make digital or hard copies of all or part of this work for personal orclassroom use is granted without fee provided that copies are not made or distributedfor profit or commercial advantage and that copies bear this notice and the full citationon the first page. Copyrights for components of this work owned by others than theauthor(s) must be honored. Abstracting with credit is permitted. To copy otherwise, orrepublish, to post on servers or to redistribute to lists, requires prior specific permissionand/or a fee. Request permissions from 24, August 2529, 2024, Barcelona, Spain 2024 Copyright held by the owner/author(s). Publication rights licensed to ACM.ACM ISBN 979-8-4007-0490-1/24/08",
  "Clinical decision support, Early sepsis prediction, Active sensing,Electronic health record, Deep learning": "ACM Reference Format:Changchang Yin, Pin-Yu Chen, Bingsheng Yao, Dakuo Wang, Jeffrey Caterino,and Ping Zhang. 2024. SepsisLab: Early Sepsis Prediction with UncertaintyQuantification and Active Sensing. In Proceedings of the 30th ACM SIGKDDConference on Knowledge Discovery and Data Mining (KDD 24), August2529, 2024, Barcelona, Spain. ACM, New York, NY, USA, 11 pages.",
  "INTRODUCTION": "Sepsis, defined as life-threatening organ dysfunction in responseto infection, contributes to up to half of all hospital deaths andis associated with more than $24 billion in annual costs in theUnited States . Existing studies have shown that a sepsispatient may benefit from a 4% higher chance of survival if theyare diagnosed 1 hour earlier, so developing an early sepsis onsetprediction system can significantly improve clinical outcomes.Existing machine-learning-based predictive models are usually trained on high-quality data with few missing informa-tion, while missing values widely exist in emergency department(ED) and emergency medical services (EMS) settings, which wouldcause most existing sepsis prediction models to suffer from perfor-mance decline and high uncertainty. In addition, existing studies have shown that for sepsis cases, most patients have alreadyprogressed into sepsis before the admissions to hospitals or duringthe first hours of admissions. Thus it is critical to develop accuratesepsis prediction systems that can handle high missing-rate settings(e.g., cold-start setting with only several limited vital signs).A common method to handle missing variables is imputation, inwhich missing values are replaced by estimates from the observeddata. To use the existing methods, we will need data imputations,which come with a new problem for the downstream sepsis predic-tion tasks: the uncertainty of imputation results can propagate tothe sepsis prediction models. Especially for deep learning models, asmall perturbation in the input variables might cause a significant",
  ": Workflow of SepsisLab system": "change in the predicted risk . When the prediction modelsare sensitive to the highly uncertain input (i.e., imputed variable),the generated outputs are not reliable, so it is critical to quantify andreduce such kind of uncertainty. However, unlike epistemic uncer-tainty and aleatory uncertainty , the propagated uncertaintyfrom the (imputed) input has not been investigated.In this study, we develop an early sepsis prediction system Sep-sisLab that can quantify and reduce such kind of propagated un-certainty from missing value and imputation. displays theworkflow of SepsisLab system. Given a patients data with limitedobservations, we first adopt an imputation model to estimate thedistribution (i.e., mean and standard deviation) of missing values.The standard deviation can be treated as the uncertainty of theimputed results. Then we propose a time-aware sepsis predictionmodel to predict whether the patients will suffer from sepsis in thecoming hours. The prediction model can generate sepsis risk anduncertainty simultaneously. Given the estimated uncertainty, wefurther propose a robust active sensing algorithm to recommendclinicians observe the most informative lab test items that can max-imally reduce the uncertainty for the potential high-risk patients.The active sensing module can significantly improve downstreamsepsis prediction performance by providing more accurate observa-tion and reducing the propagated uncertainty.To demonstrate the effectiveness of the proposed models, weconduct experiments on real-world clinical datasets (includingtwo publicly available datasets MIMIC-III and AmsterdamUM-Cdb , and proprietary data from The Ohio State UniversityWexner Medical Center (OSUWMC)). Experimental results showthat the developed system can successfully work on both high-and low-missing-rate settings and achieve state-of-the-art sepsisprediction performance. Finally, we develop a SepsisLab system fordeployment to integrate into clinicians workflow, which paves theway for human-AI collaboration and early intervention for sepsismanagement.We summarize our contributions as follows:",
  "We introduce propagated uncertainty to deep learning mod-els, a new source of uncertainty different from widely studiedaleatoric uncertainty and epistemic uncertainty": "We adopt uncertainty propagation to successfully qualifythe propagated uncertainty, and the experimental resultsdemonstrate the propagated uncertainty is dominant at thebeginning of patients admissions to hospital. We propose a new active sensing framework RAS, whichcould effectively select variables to observe, and the experi-ments demonstrate the effectiveness of the proposed propa-gated uncertainty qualification method.",
  "Sepsis Prediction Systems": "Sepsis is a heterogeneous clinical syndrome that is the leadingcause of mortality in hospital intensive care units (ICUs) .Early prediction and diagnosis may allow for timely treatmentand lead to more targeted clinical interventions. Screening toolshave been used clinically to recognize sepsis, including qSOFA, MEWS , NEWS , and SIRS . However, those toolswere designed to screen existing symptoms as opposed to explicitlyearly predicting sepsis before its onset, and their efficacy in sepsisdiagnosis is limited. With recent advances, deep learning methodshave shown great potential for accurate sepsis prediction . Although the methods achieved superior performance, theyface a critical limitation: the models need to take the completeobservation of a list of variables (including vital signs and lab tests),while lots of variables are missing in real-world data (especially inthe first hours of admissions). Existing studies usuallyimpute the missing values before the prediction, which raises anew problem that the sepsis prediction models will heavily rely onthe imputation methods. The imputation uncertainty would also bepropagated to downstream prediction models. Thus it is necessaryto quantify the propagated uncertainty, especially for high-stakessepsis prediction tasks.",
  "Uncertainty Qualification": "Understanding what a model does not know is a critical part ofmany machine learning systems. Despite the superior performancedeep learning models have achieved in various domain, they are usu-ally over-confident about the predictions, which could limit theirapplications to real-world risk-sensitive settings (e.g., in health-care). Uncertainty quantification methods play a pivotal role inreducing the impact of uncertainties during both optimization anddecision making processes . Existing uncertainty qualificationwork has widely studied epistemic uncertainty and",
  "SepsisLab: Early Sepsis Prediction with Uncertainty Quantification and Active SensingKDD 24, August 2529, 2024, Barcelona, Spain": "Virtual adversarial training (VAT) : VAT proposes to makethe learned function locally linear with local a smoothness reg-ularization method. Then we use the same variable selectionmethod as ours to select missing values. Monte Carlo sampling: Existing studies use Monte-Carlodropout to measure the epistemic uncertainty. Similarly, we useMonte-Carlo sampling to estimate the propagated uncertaintyby sampling the values of the unobserved variables based onthe Gaussian distribution and select the variable with maximalvariance in generated output, as (C) shows.",
  "Active Sensing": "Active sensing aims to improve the target tasks performance byactively selecting most informative variables with the minimal cost.Yu et. al propose to select the informative variables based onmutual information and predictive variance. However, the modelis based on Bayesian co-training framework, the prediction abilityof which is not as good as deep neural networks when handlinglarge-scale time serial data. Yoon et. al attempt to solve theactive sensing problem by proposing an RNN-based model (i.e.,Deep Sensing). The Deep Sensing framework involves learning3 different networks: an interpolation network, a prediction net-work and an error estimation network. Each network is separatelyoptimized for its own objective and then combined together aftertraining to be used for active sensing. Jarrett et. al propose anInverse Active Sensing (IAS) to require negotiating (subjective)trade-off between accuracy, speediness, and cost of information.Yoon et. al propose an RL-based framework (Active Sensingusing Actor-Critic models, ASAC) to directly optimize the predic-tive power after active sensing. Although the methods achievedsuperior performance in the target prediction tasks, they failed tomeasure the uncertainty of both missing values and model outputrisks, which limit their application in high-stakes clinical settings.",
  "Notation and Problem Statement": "In this study, we aim to predict sepsis onset with limited clinicalvariables observed. We consider the following setup. A patient hasa sequence of clinical variables (i.e., lab test data and vital signdata) with timestamps. Let { } denote the observa-tions of variables, where represents missing values, denotes thenumber of collections of observations and denotes the numberof unique clinical variables. denotes the observation times-tamps. {0, 1} denotes the ground truth of whether the patientwill progress to sepsis in the coming hours. Following , weset the prediction window as 4 hours. Due to the existence of miss-ing values, we impute the missing values first and use todenote the imputed results.Given a loss function and a distribution over pairs (, Y), thegoal is to find a function that minimize the expected loss:",
  "NotationDescription": "Observed variables with missing values.Imputed variables.Labels for sepsis prediction.Predicted sepsis risk at collection.Timestamps for observations.Masking indicator for imputation training.The number of collections of variables.The number of unique variables.Time embedding vector for collection.The embedding for collection.Mean of missing values.Standard deviation of missing values.,Learnable parameters.Hidden state of imputation model.Hidden state of the sepsis prediction model.Computed uncertainty.Propagated uncertainty.Epistemic uncertainty.Correlation between and .Learning rate.",
  "Missing Value Imputation": "We assume the missing values follow the Gaussian distributionsand impute the missing values by estimating the distribution ofvariables (i.e., the mean and covariance). (A) shows theframework of our imputation model.Following , we first use mean-imputation to preprocess theobservational data and send the embedding of to LSTM tomodel the patients health states.Embedding layer. In the collection, we have observationalvalues , observation time . We use a fully connected layer toembed the observed variable in the collection:",
  "=1,(, ,)2,(6)": "where {0, 1} denotes the indices of masked variables. ,is 1 if the variable in collection is observed and masked;otherwise, 0. Replacing the missed values with the estimates ,the observed variables become .After the imputation model is well-trained with Equation 6, wefurther learn to estimate the standard deviation by finetuning and and fixing other parameters. We minimize the followingloglikelihood loss:",
  "Sources of Uncertainty": "When applying deep learning methods to high-stakes sepsis pre-diction tasks, the lack of uncertainty quantification will make themodels less reliable. In this subsection, we investigate two mainsources of uncertainty.Uncertainty from the model parameters. Existing uncer-tainty qualification work has widely studied epistemicuncertainty, which accounts for uncertainty in the model parame-ters, especially for the huge amount of parameters in deep learningmodels. Following , we use drop-out during the test phase andrun the inference many times to quantify such kind of uncertainty.Uncertainty from missing values. Superior risk predictionmodels in the healthcare domain heavily rely on high-quality com-plete input. However, missing values (e.g., vital signs and lab testresults) widely exist in real-world clinical settings. Most risk pre-diction methods first impute the missing values andthen make predictions based on the imputed values. The accuracy",
  "Uncertainty Definition": "We use the variance of prediction models output to define the twokinds of uncertainty mentioned above. Patients data contains asequence of collections of variables. We can use all the observationsuntil the current collections to make predictions. When applyingactive sensing algorithms to reduce the propagated uncertaintywith additional observations, we can only request the variables inthe current collection.In the active sensing task, we only focus on the uncertaintyrelated to the latest collection. In the following subsections, forsimplicity, at a given time , we use to represent the obser-vation (i.e., ), and use () rather than () to denote thepredicted risk, where means all the learnable parameters in thesepsis prediction model.We assume the input variables and model parameters follow Gaussian distributions (,) and (,). and can be estimated with Equation 5. Let denote thesepsis prediction label for the patient at current time.Following existing studies , we define the uncertainty ofpredicted risk as the variance of model outcomes:",
  "( + ) = () + ()(16)": "We can use the uncertain propagation in Equation 14 as the ap-proximation of the uncertainty of non-linear function . However,the propagated uncertainty estimation for non-linear functions arebiased on account of using a truncated series expansion. The extentof this bias depends on the nature of the function.The absolute difference between the two values ( + ) and( + ) is:",
  "(,) =max22 ( + ) () ()(20)": "to be a measure of how linear the surface is within a neighbor-hood near . We call this quantity the local linearity measure. Themissing variables follow Gaussian distribution, so lies within twostandard deviations with more than probability 95%. The uncer-tainty estimation error would be less than (,) with probabilitymore than 95%.Algorithm 1 describes the training process of the sepsis predic-tion model.",
  "Datasets": "Datasets. We validate our system on two publicly available datasets( MIMIC-III2 and AmsterdamUMCdb3) and one proprietary datasetextracted from OSUWMC4. We first extracted all the sepsis patientswith sepsis-3 criteria in the datasets. For each sepsis patient,we select 1 control patient with the same demographics (i.e., ageand gender). We extracted 26 vital signs and lab tests from thedatasets. A detailed list of clinical variables can be found in supple-mentary materials. The statistics of the three datasets are displayedin .Variables Used for Sepsis Prediction. Following , we usefollowing variables to model sepsis patients health states: heart rate,Respratory, Temperature, Spo2, SysBP, DiasBP, MeanBP, Glucose,Bicarbonate, WBC, Bands, C-Reactive, BUN, GCS, Urineoutput,",
  "Setup": "We mimic the cold-start environment where only vital signs areimmediately available, while all the lab tests can be observed afterthe assignment. displays the setting of the experiments.After the patients arrive at the hospital, we start to predict whetherthe patients will suffer from sepsis in 4 hours. We run the predictionprocess hourly until the patients have been diagnosed with sepsisor discharged. When the models output has a high uncertaintydue to the limited observations, the active sensing algorithms canselect the missing lab tests to observe. Based on the lab testing turn-around times policy of OSUWMC, most lab results will be availablein less than 30~60 min5 (or even sooner for sepsis patients withhigh priority), so the observation results for the selected lab itemscan be used in the same hour to update the predicted sepsis risk.Note that when active sensing algorithms select some variables thatare not collected at the corresponding time, we use the estimatesfrom other observed variables as the active observation results.",
  "uses the linear constraint to make the learned function locallylinear. RAS means the model is only trained by minimizing theclassification loss in Equation 11 without any linearity constraint": "For fair comparison to the baselines, all active sensing algorithmsuse the same deep-learning sepsis prediction model backbone. Ourprevious works have shown that LSTM can successfullymodel the time series EHR data and achieve superior performance inthe sepsis prediction tasks, so we use LSTM as the model backbone.Note that the proposed active sensing methods are generalizable tovarious deep learning frameworks.",
  "Q1: How does the model uncertainty affectthe sepsis prediction performance?": "The existence of uncertainty makes AI models less reliable andless accurate when applying the models to real-world high-stakesscenarios. In this subsection, we aim to show how the model un-certainty affects sepsis prediction performance by analyzing therelation between uncertainty and prediction performance. 5.1.1Prediction Performance over Uncertainty Scales. We computethe uncertainty of the sepsis onset prediction models output withEquation 12 and split the patients into 6 sets with different uncer-tainty scales. Then we calculate the sepsis onset prediction perfor-mance on AUROC inside each set. displays the model per-formance over the different uncertainty scales in the three datasets.We conducted experiments in two settings. In active sensing set-ting, we compute the AUROC after active sensing algorithms areused. In the observed data setting, we directly run the data in theobserved data (including all the recorded vital signs and lab tests)and compute the AUROC. The results in both settings show thatwhen uncertainty is higher, the model performance becomes less",
  "accurate, so a good active sensing framework can improve the pre-diction performance by reducing the uncertainty of the predictionmodels output": "5.1.2Uncertainty Scales over Time. We quantify the model uncer-tainty at different times from admissions. displays theaverage uncertainty scales. shows that in the first 15 hours, propagated uncertaintyis dominant in sepsis onset risk prediction models. We speculatethe reason is that at the beginning most variables have not beenobserved and the missing values cause the main uncertainty, whichis consistent with our clinical experts experience. With more vari-ables collected, the propagated uncertainty decreases a lot after 15hours of the admissions.Because the missing variables can cause high uncertainty duringthe first hours, it is critical to quantify the propagated uncertaintywhen applying risk prediction models to high missing-rate settings.",
  ": Inference time cost over times after admission": "5.2.1Uncertainty with Different Active Sensing Ratio. dis-plays the average uncertainties for sepsis prediction results withdifferent active sensing ratios. The results show that with moremissing variables observed, the uncertainty on the predicted sep-sis risks are significantly reduced. Besides, all the versions of theproposed RAS reduce more uncertainty than the baselines, whichdemonstrates the effectiveness of the proposed active sensing algo-rithms on uncertainty reduction. 5.2.2Uncertainty Quantification Efficiency. We also investigatethe time cost for uncertainty quantification during the inferencephase. displays the inference time cost for uncertaintyquantification. The results show that RAS can achieve much lesstime than the baselines, which makes the SepsisLab system workmore efficiently during the active sensing phase.",
  "Q3: How does the active sensing algorithmimprove the sepsis prediction performance?": "The goal of SepsisLab is to accurately predict the sepsis so as toprovide reliable decision-making support to clinicians. We conductexperiments to show sepsis prediction performance improvementwith the active sensing algorithms. 5.3.1Sepsis onset Prediction Results. displays the risk pre-diction performance with different active sensing ratios (i.e., 2%-8%).With additional variables observed, all the methods can achievemore accurate prediction performance for sepsis onset. Moreover,all the active sensing algorithms outperform the random sensingbaseline with the same observation rate, which demonstrates thatactive sensing can improve downstream tasks performance. Amongthe active sensing algorithms, the proposed RAS achieved the bestperformance with different active sensing ratios, which demon-strate the effectiveness of the proposed model. 5.3.2Ablation Study. We have three versions of the framework.RAS directly uses the gradient to estimate propagated uncertainty.RAS uses a linear regularization term to make the model locallysmooth, while RAS uses adversarial training. For RAS and RASversions, the additional terms change the loss functions. We conductexperiments to show whether the additional terms can improvemodel training. We train the three versions of models independentlyand test them on all the observed data (without active sensing). As shows, RAS and RAS outperform RAS , which demon-strates local linearity can further improve prediction performance.With adversarial training, RAS can achieve better local linearitythan RAS and thus perform the best, which also explains why theRAS outperforms better than Monte-Carlo sampling in inthe active sensing. : User Interface of Our SepsisLab System. (A) Patientlist with sepsis risk prediction score. (B) The patients de-mographics and the dashboard of the patients historicalobservations. (C) Predicted sepsis risk score with uncertaintyrange and recommended lab test items to observe. We also conduct more experiments with different backbones(e.g., RNN, GRU, FC) and display the performance in insubsection A.3. The experimental results show that the proposedmodel can consistently improve the prediction performance for allthe backbones by recommending the most informative variablesfor observation. 5.3.3Hyper-parameter Optimization. The proposed RAS have fourimportant hyper-parameter: weight in Equation 19, step size ,step , learning rate in Algorithm 1. We use grid-search tofind the best parameter (with active sensing ratio equal to 8%). displays the searching space and the optimal values used in thetraining process.",
  "DEPLOYMENT": "Based on the sepsis prediction model and active sensing algorithm,we implement a system SepsisLab. and shows howthe system is deploed in the Epic EHR Systems6 at OSUWMC.SepsisLab starts to collect patients data after the patients arrivehospital and automatically predicts sepsis risks hourly. (A)displays a list of patients with different sepsis risk prediction scores,colored from no risk as Green, to medium risk as Yellow, to highrisk as Red. When picking a patients data, (B) shows the pa-tients demographics and the dashboard that includes the patientsvital signs, lab test results, and medical history, which are helpfulfor clinicians to understand the patients health states. (C)shows the patients sepsis risk (solid line) and uncertainty range",
  "Weight [0.1, 0.3, 0.5, 0.7, 0.9]0.5Learning rate [1e-3, 1e-4, 1e-5]1e-4Step size [1e-2, 1e-3, 1e-4, 1e-5]1e-3Step 15": "(gray area) at different times and an actionable lab item test rec-ommendation list from SepsisLab. The items are ranked by theirimportance to reduce the uncertainty of the sepsis future prediction.The interactive process with our system is visualized in .This UI currently illustrates that a clinical expert is examining ahigh-risk patients data who was admitted 4 hours ago. The Sep-sisLab suggests the expert collect more lab results. The expert isinteracting with the visualization to see if Lactate and Creatininelab results were added, and how the sepsis prediction and its uncer-tainty would change. The clinician can select a lab item ((b))or multiple lab items ((c)) and see the expected influenceof the lab test result on the model uncertainty via a counterfactualprediction. By comparing different combinations of the lab testitems, the clinician can obtain a better understanding of the modeland make the decision to order appropriate lab tests to collect theactual item values, which then truly update the models predictiontrajectory and uncertainty range.Note that we used OSUWMC data for our algorithm illustration.All patients names and demographic info in this are ran-domly generated for illustration purposes. Ongoing deploymentalso includes recruit clinicians for usability evaluation to quantita-tive and qualitatively measure clinical outcome and user satisfactionof SepsisLab (OSUWMC IRB#: 2020H0018).",
  "CONCLUSION": "In this work, we study a real-world problem that how to accu-rately predict sepsis with limited variables available. Missing valueswidely exist in clinical data and can cause inaccurate prediction andhigh uncertainty for the sepsis prediction models. To the best of ourknowledge, it is the first work that studies the model uncertaintycaused by missing values. We define a new term propagated uncer-tainty to describe the uncertainty, which is the downstream modelsuncertainty propagated from the uncertain input (i.e., imputationresults). We further propose uncertainty propagation methods toquantify the propagated uncertainty. Based on the uncertainty quan-tification, we propose a robust active sensing algorithm to reducethe uncertainty by actively recommending clinicians to observethe most informative variables. The experimental results on real-world datasets show that the introduced propagated uncertainty isdominant at the beginning of patients admissions to the hospitaldue to the very limited variables and the proposed active sensingalgorithm can significantly reduce the propagated uncertainty andthus improve the sepsis prediction performance. Finally, we de-sign a SepsisLab system for deployment to integrate into cliniciansworkflow, which paves the way for human-AI collaboration andearly intervention for sepsis management.",
  "KDD 24, August 2529, 2024, Barcelona, SpainChangchang Yin et al": "Moloud Abdar, Farhad Pourpanah, Sadiq Hussain, Dana Rezazadegan, Li Liu, Mo-hammad Ghavamzadeh, Paul Fieguth, Xiaochun Cao, Abbas Khosravi, U RajendraAcharya, et al. 2021. A review of uncertainty quantification in deep learning:Techniques, applications and challenges. Information Fusion 76 (2021), 243297. Inci M Baytas, Cao Xiao, Xi Zhang, Fei Wang, Anil K Jain, and Jiayu Zhou. 2017.Patient subtyping via time-aware LSTM networks. In Proceedings of the 23rd ACMSIGKDD international conference on knowledge discovery and data mining. 6574. Roger C Bone, Robert A Balk, Frank B Cerra, R Phillip Dellinger, Alan M Fein,William A Knaus, Roland MH Schein, and William J Sibbald. 1992. Definitionsfor sepsis and organ failure and guidelines for the use of innovative therapies insepsis. Chest 101, 6 (1992), 16441655.",
  "Lu Men, Noyan Ilk, Xinlin Tang, and Yuan Liu. 2021. Multi-disease predictionusing LSTM recurrent neural networks. Expert Systems with Applications 177(2021), 114905": "Takeru Miyato, Shin-ichi Maeda, Masanori Koyama, and Shin Ishii. 2018. Virtualadversarial training: a regularization method for supervised and semi-supervisedlearning. IEEE transactions on pattern analysis and machine intelligence 41, 8(2018), 19791993. Seyed-Mohsen Moosavi-Dezfooli, Alhussein Fawzi, Jonathan Uesato, and PascalFrossard. 2019. Robustness via curvature regularization, and vice versa. In Pro-ceedings of the IEEE/CVF Conference on Computer Vision and Pattern Recognition.90789086. Chongli Qin, James Martens, Sven Gowal, Dilip Krishnan, Krishnamurthy Dvi-jotham, Alhussein Fawzi, Soham De, Robert Stanforth, and Pushmeet Kohli.2019. Adversarial robustness through local linearization. Advances in NeuralInformation Processing Systems 32 (2019).",
  "Kui Ren, Tianhang Zheng, Zhan Qin, and Xue Liu. 2020. Adversarial attacks anddefenses in deep learning. Engineering 6, 3 (2020), 346360": "Matthew A Reyna, Christopher S Josef, Russell Jeter, Supreeth P Shashikumar,M Brandon Westover, Shamim Nemati, Gari D Clifford, and Ashish Sharma.2019. Early prediction of sepsis from clinical data: the PhysioNet/Computing inCardiology Challenge 2019. Critical Care Medicine (2019). Halden F Scott, Emily E Greenwald, Lalit Bajaj, Sara J Deakyne Davies, LinaBrou, and Allison Kempe. 2018. The sensitivity of clinician diagnosis of sepsis intertiary and community-based emergency settings. The Journal of Pediatrics 195(2018), 220227. Robin Senge, Stefan Bsner, Krzysztof Dembczyski, Jrg Haasenritter, OliverHirsch, Norbert Donner-Banzhoff, and Eyke Hllermeier. 2014. Reliable classifi-cation: Learning classifiers that distinguish aleatoric and epistemic uncertainty.Information Sciences 255 (2014), 1629.",
  "Mervyn Singer, Clifford S Deutschman, Christopher Warren Seymour, et al. 2016.The third international consensus definitions for sepsis and septic shock (Sepsis-3). Jama 315, 8 (2016), 801810": "Mervyn Singer, Clifford S Deutschman, Christopher Warren Seymour, ManuShankar-Hari, Djillali Annane, Michael Bauer, Rinaldo Bellomo, Gordon RBernard, Jean-Daniel Chiche, Craig M Coopersmith, et al. 2016. The third inter-national consensus definitions for sepsis and septic shock (Sepsis-3). Jama 315, 8(2016), 801810. Gary B Smith, David R Prytherch, Paul Meredith, Paul E Schmidt, and Peter IFeatherstone. 2013. The ability of the National Early Warning Score (NEWS) todiscriminate patients at risk of early cardiac arrest, unanticipated intensive careunit admission, and death. Resuscitation 84, 4 (2013), 465470.",
  "Chao Yan, Cheng Gao, Xinmeng Zhang, You Chen, and Bradley Malin. 2019. Deepimputation of temporal data. In 2019 IEEE International Conference on HealthcareInformatics (ICHI). IEEE, 13": "Changchang Yin, Ruoqi Liu, Dongdong Zhang, and Ping Zhang. 2020. Identifyingsepsis subphenotypes via time-aware multi-modal auto-encoder. In Proceedingsof the 26th ACM SIGKDD international conference on knowledge discovery & datamining. 862872. Changchang Yin, Rongjian Zhao, Buyue Qian, Xin Lv, and Ping Zhang. 2019.Domain Knowledge guided deep learning with electronic health records. In 2019IEEE International Conference on Data Mining (ICDM). IEEE, 738747.",
  "A.3Model Performance with differentbackbones": "Our model is applicable to various models, including LSTM, GRU,and fully-connected networks (FC). LSTM has shown superior per-formance in modeling clinical time series data in multiple tasks,including missing value imputation , clinical prediction, and patient subtyping , so we choose LSTM as the modelbackbone. We also conducted more experiments with different back-bones as shown in . The experimental results show that theproposed model can significantly improve the prediction perfor-mance for all the backbones by recommending the most informativevariables for observation."
}