{
  "ABSTRACT": "Multitask learning is a widely used paradigm for training modelson diverse tasks, with applications ranging from graph neural net-works to language model fine-tuning. Since tasks may interferewith each other, a key notion for modeling their relationships istask affinity. This includes pairwise task affinity, computed amongpairs of tasks, and higher-order affinity, computed among subsetsof tasks. Naively computing either of them requires repeatedlytraining on data from various task combinations, which is compu-tationally intensive. We present a new algorithm Grad-TAG thatcan estimate task affinities without this repeated training.The key idea of Grad-TAG is to train a base model for alltasks and then use a linearization technique to estimate the loss ofthe model for a specific task combination. The linearization worksby computing a gradient-based approximation of the loss, usinglow-dimensional projections of gradients as features in a logisticregression to predict labels for the task combination. We showthat the linearized model can provably approximate the loss whenthe gradient-based approximation is accurate, and also empiricallyverify that on several large models. Then, given the estimated taskaffinity, we design a semi-definite program for clustering similartasks by maximizing the average density of clusters.We evaluate Grad-TAGs performance across seven datasets,including multi-label classification on graphs, and instruction fine-tuning of language models. Our task affinity estimates are within2.7% distance to the true affinities while needing only 3% of FLOPs infull training. On our largest graph with 21M edges and 500 labelingtasks, our algorithm delivers estimates within 5% distance to thetrue affinities, using only 112 GPU hours. Our results show thatGrad-TAG achieves excellent performance and runtime tradeoffscompared to existing approaches.",
  "INTRODUCTION": "Modern applications of neural networks often employ a singleneural network for prediction or classification on multiple tasks.This multitask learning setup is widely used across a variety ofsettings, with examples such as a visual system that aims to detectvarious objects in autonomous driving simultaneously , a GraphNeural Network for community detection on large networks ,and prompt-tuning of pre-trained LLMs for NLP tasks . Thismultitask learning setup is not only computationally efficient (asingle network can jointly predict many tasks), but it often improvesprediction accuracy due to transfer learning.The often implicit assumption behind multitask modeling isthat there is a positive transfer effect among tasks . However, asthe number of tasks increases, one frequently observes a negativetransfer effect in many applications, such as for prompt tuning oflarge language models, where adding a task to the model degradesperformance on one or more tasks . This observationhas motivated a line of work that aims to group the tasks intosubsets such that negative transfer among tasks within a subset isminimized, allowing one to train a separate multitask model persubset, thereby improving performance on all tasks .A key concept underlying many multitask learning algorithmsis a notion of task affinity, which can capture the abovementionedpositive or negative transfer effects across tasks precisely. For in-stance, one can compare pairwise task affinity the loss ofa model trained on each pair of tasksagainst the loss of a modeltrained on each task. Given a notion of task affinity, a commonrecipe for designing multitask learning algorithms involves (1) Taskaffinity computation that builds a task affinity matrix, then (2) taskgrouping that uses this task affinity matrix to group tasks withpositive transfers together, and finally (3) multitask training thatfits a separate model per task group.The performance improvement achieved through this paradigmdepends on the task affinity and the grouping procedure. Moreover,the ability to leverage this paradigm hinges on the computation oftask affinity (Step 1 above), which becomes expensive as the numberof tasks grows. As a case in point, the computational complexity ofpairwise task affinity scales quadratically with the number of tasks:this implies that even for community detection with 100 labelings,using pairwise task affinity requires training nearly 5000 modelsfor computing the affinity matrix.",
  "Pre-training on all tasksEstimation on a task subset": ": Visualization of the gradient-based model approxi-mation step in our Grad-TAE algorithm, where we replacemultitask training with a regression-based estimation ofmodel parameters fine-tuned on a particular subset of tasks. In this paper, we scale up this multitask learning paradigm bydramatically speeding up the first step of task affinity computationfor two canonical examples of task affinities: Pairwise and higher-order task affinity (See Examples 2.2, 2.3). In our experiments onvarious real-world datasets representing different applications, ouralgorithm can reduce the task affinity computation time by nearly32 compared to full model training while incurring less than2.7% error. In addition to this dramatic efficiency improvement,we also design a more robust method for task grouping (Step 2).Together, these new techniques match or improve the performanceof previous multitask models.The primary challenge for task affinity computation is avoidingtraining many multitask models on various task combinations. Thekey technical insight behind our algorithm is to leverage a lineariza-tion property of deep neural networks, including large languagemodels. The linearization property for a neural network means wecan approximate the model loss for a pre-trained meta-initializationand an input/output pair by using a gradient-based Taylors expan-sion centered at the meta-initialization. This linearization propertyhas been observed for large language model fine-tuning in recentworks, albeit not for the purpose of multitask learning .Here, we leverage linearization to estimate task affinities in an ef-ficient manner by using the first-order Taylor expansion from apre-trained model, thereby saving the computation of backprop-agation during model fine-tuning. This algorithm, Grad-TAE, isillustrated in .In more detail, we first compute the gradient at the initializationand then map the gradients to task labels with logistic regression.The dimension of this regression can be high, especially for heav-ily parameterized models. Thus, we use a dimension reductiontechnique and apply the Johnson-Lindenstrauss Lemma to givean error analysis. On experiments of datasets with 100 tasks, weshow that this approach estimates pairwise task affinity with 45fewer FLOPs and 11 less GPU hours than fully computing the truescores, with only 5.7% relative error. For higher-order task affin-ity, our approach uses 32 fewer FLOPs and 5 less GPU hours,with only 2.7% relative error. Furthermore, our approach also scalesto a large-scale graph with over 21M edges and 500 tasks. It esti-mates the task affinities within 5% relative errors with 112.3 GPUhours, while computing the true affinity scores can take over 8000GPU hours. Our algorithm is also suitable for accelerating taskselection methods that are typically computationally expensive. An example is forward or backward subset selection , which is apopular heuristic but requires evaluating quadratically many taskcombinations.As for the second step, we design a new clustering algorithmthat uses these estimated task influences through a semi-definiteprogramming (SDP) relaxation formulation. The clustering algo-rithm takes the estimated task affinity matrix (of size ) &the number of task groups as input, then solves an SDP for max-imizing the average density of the groups. Since the SDP is aconvex program, it can be solved efficiently, and we round theresulting solution to get the final task groups. Our experimentsindicate that our clustering algorithm is more robust and perfor-mant than commonly used clustering techniques such as spec-tral clustering and Lloyds algorithm . Once we have thetask groups from the clustering, we can partition the tasks intosubsets and train a separate model on tasks within each subset this overall algorithm is called Grad-TAG. Experiments showthat our approach achieves the Pareto optimum regarding errorrate and computation cost. For multi-label prediction on graphstrained with a 3-layer GNN, Grad-TAG achieves comparable per-formance with over four baselines while using 32 fewer FLOPsand 5 less GPU hours. For instruction tuning of language modelsusing T5-Base, Grad-TAG uses 48 fewer FLOPs and 11 lessGPU hours with comparable performance to the best baseline. Thecode repository for reproducing our experiments can be found at Summary of Contributions: We design an efficient algorithm,Grad-TAE, for estimating the task affinity scores of a multitasklearning algorithm. The key idea of Grad-TAE is to trade offmultitask pre-training, which is computationally expensive, withgradient-based estimation for fine-tuning, whose computation islightweight. We then design a clustering algorithm on top of the esti-mation procedure for downstream multitask optimization. Througha detailed experimental study, we demonstrate that our overall al-gorithm, Grad-TAG, significantly speeds up full model trainingwhile delivering comparable performance. Organization: We briefly touch on related work and then providethe technical preliminaries for the rest of the paper. In section 3,we outline our task affinity estimation procedure Grad-TAE, alongwith a theoretical error analysis for the estimation error. Then, wepresent the clustering approach for task grouping and the overallalgorithm Grad-TAG in . Finally, we provide a thoroughempirical evaluation of the Grad-TAG algorithm for various multi-task learning settings in .",
  "Related Work": "Multitask learning is a fundamental problem with many applica-tions, such as federated learning , road safety modeling ,and language model fine-tuning . This problem has been studiedsince the early literature of data mining . As the number of tasksincreases, modeling task relationships becomes increasingly com-plex and challenging . These relationships are influencedby data distribution characteristics, including covariate and labelshifts . Thus, designing optimization algorithms for multitasklearning is challenging . We contribute to this literature byproposing a new approach to significantly speed up the computation of",
  "task affinity scores for modeling task relationships. We now proceedto discuss several lines of work that are most related to ours": "Task Similarity Measures. Previous works estimate taskaffinities between every pair of tasks. The computation complex-ity of such methods scales quadratically with the number of tasks.Another approach is to use task embeddings , i.e., training onemodel on each task and measuring the cosine similarity betweenthe model weights. Although this approach scales linearly withthe number of tasks, the measures tend to be noisy. Intuitively, iftwo tasks are similar, their gradients should exhibit higher cosinesimilarity. This idea can be implemented to balance training bydynamically tuning gradient magnitudes , or to project thegradients noto the span of other tasks gradients that have a con-flicting gradient . The same idea can also be implemented tochoose auxiliary tasks most beneficial for a primary task . Sim-ilarity measures based on feature representations of tasks havealso been applied to grouping tasks and used to predict tasktransferabilities . The main advantage of these approaches istheir efficiency, as only a single multitask model needs to be trained.The downside is that the gradients can be noisy during a stochastictraining procedure. For example, Azorin et al. empirically ob-served that representation and gradient similarity measures do notconsistently correlate with actual MTL performance. Thus, a moreaccurate approach is to build measures that approximate multitaskoutcomes directly; see recent work on designing surrogate modelsfor multitask learning systems . Transferability Estimation. There have also been developmentson information theoretic measures of transferability in recent liter-ature. One natural idea is to evaluate conditional entropy betweentarget pseudo labels (assigned by a pretrained source model) andreal target label . Log Expected Empirical Predictor pro-poses a modified procedure using soft predictions from the sourcemodel. These methods do not utilize feature embeddings in themeasure ; TransRate introduces a surrogate measure basedon mutual information that also incorporates feature embeddings.An improved estimation method with better robustness can beachieved by shrinkage . In the fine-tuning setting, the distancebetween the model search and the pretrained initialization can indi-cate the level of generalization capability . The geometry relatesto the Hessian of the loss, which has been shown to correlate withthe generalization performance of fine-tuned models . Ju et al. extend this Hessian measure to graph neural networks, whichcan guide the design of optimization algorithms to regularize theHessian of neural networks . Multitask Learning Optimization Algorithms. Multitask learn-ing can be viewed as a multiobjective optimization problem ,where the goal is to identify the Pareto frontier among multipleobjectives . One common MTL optimization algorithm is toreweight task losses and optimize a weighted combination of tasklosses . Our goal is to maximize the averaged predictionperformance of all tasks. Thus, we are interested in partitioningthe tasks into similar groups, where tasks are closely related withineach group and can differ significantly across groups. Another inter-esting line of work is designing branching neural networks such astree structures , where each layer contains multiple modulesto handle different tasks . Compared with branching methods, task grouping may be more suitable for handling many tasks (likehundreds to thousands). In this regime, negative interference be-tween tasks is almost unavoidable, and clustering tasks into similargroups could provide a more efficient strategy than designing asingle neural network that handles all tasks.Influence Functions. There is a line of work estimating the influ-ence of adding or removing one sample on the whole dataset. Influ-ence functions based on efficient approximation of the Hessianinverse provide one way to approximate this. Random sampling-based approaches to measuring leave-one-out influence have alsobeen studied . The distinction between these works and usis we focus on task-level affinity, whereas this literature focuses onestimating the influence of a single data sample.Clustering Algorithms. Clustering is a fundamental aspect ofmachine learning. Besides SDP relaxations, linear programmingrelaxations are known for clustering objectives such as -center.The integrality gap of linear programming and semidefinite pro-gramming relaxations can be analyzed when there is a separationstructure in the underlying clusters . These approximation guar-antees typically require the underlying similarity scores to satisfya metric condition. By contrast, the task affinity matrix can easilyviolate the triangle inequality. Recent work has also studied mixedinteger programming for best subset selection . One novel con-tribution of this work is to make explicit a connection betweenmulti-instruction fine-tuning and clustering. In light of this connec-tion, it would also be interesting to revisit hierarchical clusteringand hypergraph clustering for task grouping. For example, recentwork by Tsitsulin et al. investigates unsupervised graph clus-tering problems with graph neural networks.",
  "PRELIMINARIES": "Suppose we are interested in making predictions on tasks. We aregiven a set of samples for training and testing each task. We aimto design a prediction algorithm to maximize the averaged testingperformance over all the tasks simultaneously. We assume thatthe samples from all the tasks are supported on a joint productbetween a -dimensional feature space X and a label space Y. Toprecisely discuss task relationships, we formally define what wemean by a multitask learning algorithm. Definition 2.1 (Multitask learning algorithms). For any subset {1, 2, . . . ,}, a multitask learning algorithm takes the trainingdata of all the tasks in and combines them in a joint trainingprocedure. Then, the (jointly trained) model is tested on each task . In the end, a test result is obtained for each . Let us denotethe test result as (,). Thus, the algorithms output will include|| results for any subset , one for each . Given a multitask learning algorithm, the transfer between the tasks can be viewed through the results of , applied to combi-nations of tasks as subsets. This notion of transfer underlies manyexisting multitask learning systems. We give two examples below,which are used in prior works to tackle task transfer in complexvisual systems .",
  "and task-specific prediction heads. If we compute the pairwise taskaffinity for all pairs of tasks 1 , then we get an by task affinity matrix , where , = ({, },)": "Example 2.3 (High-order task affinity). Next, we discuss higher-order task affinity, analogous to sampling features in random forests.First, fix an integer , which is the number of subsets we wouldlike to sample (e.g., analogous to the number of decision trees ina random forest). We independently sample subsets out of theset {1, 2, . . . ,}, each subset having a size of , chosen uniformlyover all such subsets. Let us denoted the subsets as 1,2, . . . ,.Then, compute (, ), for every = 1, 2, . . . ,, and = 1, . . . , .Lastly, compute , as the average value of among all subsetsincluding tasks , :",
  "where , is the number of subsets that include both , . Thisleads to another task affinity matrix , which better captures thehigher-order relationship among tasks": "In both examples, computing the task affinity matrix requiresfitting () models, given tasks. In Example 2.2, one needs totrain 2 models, one for every pair of tasks. Then, in Example 2.3,a total of = ( log) models are required, each for a subsetof tasks. This raises the question of whether one can approximatethe results of a multitask learning algorithm by designing a moreefficient computational method.Specifically, given a multitask learning algorithm and a collec-tion of subsets 1,2, . . . , {1, . . . ,}, can we quickly estimatethe task affinity corresponding to (, ), for any = 1, 2, . . . ,and any quickly (e.g. without fully training a model for eachsubset)? Do these task affinity estimates accurately approximatethe affinity one would get from fully trained models? Moreover, arethe estimates useful in the downstream task grouping setup?",
  "TASK AFFINITY ESTIMATION": "We now describe a new method for estimating task affinity scores.To circumvent the cost of full-model training, we describe an empir-ical observation regarding pre-training and fine-tuning. Then, wepresent our approach to estimating fine-tuned model parametersfor task subsets. Additionally, we use random projection to reducethe dimension of the gradients. We provide an error analysis tojustify the design of our algorithm.",
  "Linearization of Fine-tuned Models": "Our method is motivated by the fact that once we pre-train all the tasks to obtain a meta-initialization, this initialization can providerepresentations quickly adapted to the remaining tasks. This isbased on the premise that the underlying tasks share structuralsimilarities in multitask learning. As the model fine-tuned to asubset of tasks stays in the affinity of the initiation, the fine-tuningprocedure behaves like linear models locally.To illustrate this observation, we consider three scenarios involv-ing graph neural networks (GNNs) and transformers (BERT andT5). We test GNNs on a multi-label prediction dataset on a YouTubegraph , using a 3-layer SIGN network . This dataset includes",
  "%3.4 10210%5.1 10310%4.1 103": "= 100 subtasks, one corresponding to the node labels of a sub-graph of the whole graph. For transformers, we take a pretrainedBERT model and fine-tune it on a sentence classification dataset, which contains = 26 tasks. We also use a pretrained T5-Basemodel and fine-tune it on a sentence classification dataset with 100instructions , which has = 100 tasks. In each experiment, wefirst train a meta-initialization by training on all tasks combined.Then, we fine-tune on a random subset of the tasks.We perform Taylors expansion with as the anchor point. Let denote the fine-tuned weight. Denote the model with and as and , respectively. For an input with label , denotethe output of the fine-tuned model as (,). If is close to , (,) can be approximated by",
  "as": ". Interestingly, our results show that the gradient-basedapproximation yields within 3.5% RSS, even when the fine-tuneddistance is up to 10%. In particular, viewing as the decisionvariables, Eq. (2) is a linear model with the gradient (,)as the feature vector. Remark 3.1 (Second-order approximation). It is natural to ask if asecond-order approximation can further reduce Taylors expansionerror. Notice that there is a tradeoff between approximation qualityand computation cost. Based on our preliminary test of the Hessianapproximation, it can indeed reduce estimation error; however, thisrequires computing Hessian-gradient products. The premise is thatthe underlying tasks share a structural similarity, like in communitydetection, where clusters have higher densities. Our experimentsfound that 94% of models fine-tuned for random task subsets remain<10% distance to initialization (on the Youtube and RTE datasets),suggesting that the first-order approximation is generally sufficient.",
  "D = {(1,1), . . . , (, )},": "where is the combined number of data samples in the set D.The main idea is to solve a logistic regression problem with being the feature vector and being the response label. However,recall that the dimension of is the same as the number of param-eters in a neural network, which could be tens of millions. Thus,we introduce a dimension reduction procedure that does not losemuch precision.(2) Dimension reduction: We use the Johnson-Lindenstraussrandom projection , which projects the gradients to a muchlower dimension before solving the logistic regression. Let be a by Gaussian random matrix, whose entries are independentlysampled from a Gaussian (0,1). We project the gradient fromdimension onto dimension as = . Then, we solve thefollowing logistic regression, which is now in dimension :",
  "=1 ( ,).(4)": "Lastly, we set as + to map the projected solution tothe -dimensional space. is the estimated model parameter forfine-tuning with task subset .(3) Averaging over an ensemble: To reduce the above estima-tions variance, we also add a model averaging step. In particular, wetrain several meta-initializations and repeat the above estimationprocedure. We average the estimated scores within the ensemble.",
  "If we were to compute , we need full model training instead": "Typically, = (1), while = () or even (2) in downstreamuse cases. Thus, our estimation algorithm reduces () full-modeltraining to only (1). The tradeoff is that we require () gradientevaluations (to retrieve the gradients on all tasks) plus solvinglogistic regression times. As shown below, the random projectionhelps reduce the dimension of the logistic regression problem to(log) dimension, which is much cheaper. This is in terms of the Algorithm 1 Grad-TAE (Gradient-based Task Affinity Estimation)Input: A list of subsets 1,2, . . . , {1, 2, . . . ,}, and theirtraining and testing datasetsRequire: Initializations 1 ,2 , . . . ,; projected dimension Output: Estimated scores (, ) for every = 1, 2, . . . ,,",
  "Error Bounds": "We now show that the error introduced by approximations in Grad-TAE is bounded. Specifically, we use the Johnson-LindenstraussLemma to argue that as increases, the random projection yieldsa minimizer whose quality is not much worse than the solutionwithout the projection. We will assume that the averaged Taylorsexpansion error is at most across the entire data set of everytask. Additionally, we assume the search procedure occurs withina bounded space of radius . Lastly, in the pretrained initialization,each gradient vectors Euclidean norm is at most . With theseconditions, we state the error bounds for Grad-TAE as follows. Proposition 3.3. Let D be a search space whose radius is at most. Suppose the gradient of at the initialization in the trainingset is at most in Euclidean norm. For each task = 1, 2, . . . ,, let denote the training data. Suppose that for every ,",
  "KDD 24, August 2529, 2024, Barcelona, SpainDongyue Li, Aneesh Sharma, & Hongyang R. Zhang": ": We report the distance between our estimated taskaffinity and , computed on the YouTube graph. For inter-preting the computation cost, we report the ratio betweenthe number of FLOPs to compute divided by the numberof FLOPs of our algorithm. Recall from Algorithm 1 that is the number of meta-initializations, and is the randomprojection dimension.",
  "TASK AFFINITY BASED GROUPING": "We now describe a clustering algorithm to partition the tasksinto disjoint subsets. Given an by task affinity matrix , wewill find a clustering that maximizes the average density of allclusters. Concretely, let 1, . . . , be a disjoint partition of []. Let1, . . . , be a 0-1 vector indicating whether a task is in one cluster.The average density of this clustering can be written as:",
  ".(7)": "This integral objective is NP-hard to optimize in general (in partic-ular, geometric clustering is a special case ).We design a Semi-Definite Programming (SDP) relaxation andthen round the SDP solution to a clustering. Let us denote theassignment variables as an matrix , such that each entry, indicates whether a task belongs to a cluster , for every = 1, . . . ,, = 1, . . . ,. Moreover, let the th column of , thecharacteristic vector of the -th cluster, be denoted as . Underthis assignment, the sum of , across any task must be one, aswe allow one task to be assigned in a single group. By contrast, thesum of , across is the number of tasks assigned to , whichis at least one.Let denote the all-ones vector. We state an integer program tomaximize the average density of all clusters as follows",
  ": Round the solution into clusters using the threshold": "Further relaxing the rank constraint (while keeping the trace con-straint) leads to a convex program, which can be solved efficiently.Given a solution of the SDP, denoted as , the last step is toround into an integer solution. We set a threshold such thatif , , tasks and are assigned to the same cluster. In theexperiments, we set as / for a constant 1, since , shouldbe1 | | when they are in the same cluster with | | < . Thus, theintra-cluster distance must always be at least with the assignment.We provide the entire procedure in Algorithm 2, which usesAlgorithm 1 as a subroutine to estimate the task affinity scores. Example 4.1 (Discussion about alternative clustering algorithms).A natural question is using alternative algorithms such as spectralclustering or Lloyds clustering. We find that these algorithms arenot as robust as the SDP relaxation because the scale of the lossvalues varies across rows for different tasks. We describe a toyexample to illustrate. Suppose is a 6 by 6 matrix involving threeclusters 1,2,3 of size 2 each. The affinity in 1 is 7, while theaffinity scores in 2 and 3 are 20, 19, respectively. We find thatboth spectral clustering and Lloyds clustering will group 2 and3 together, while the SDP relaxation manages to separate them.See for an illustration. For this reason, we use the SDPrelaxation in Grad-TAG. Remark 4.2 (Approximation ratio of the SDP relaxation). A naturalquestion is whether one can quantify the approximation ratio ofthe SDP relaxation (10). Although this is a well-studied problemin approximation algorithms , task affinity violates the metriccondition typically required to obtain guarantees in this literature.In particular, the triangle inequality, +, , is violated. It ispossible that by assuming intra-cluster separation (see, e.g., Awasthiet al. ), one might be able to analyze the SDP theoretically. Thisis left for future work. Remark 4.3 (Further variants of Grad-TAG). While we focus onthe task grouping problem, the idea can be used to speed up forwardand backward selection. We set the list of subsets in Algorithm 1 as{1}, {2}, . . . , {}. Suppose we select task 3. Then, in the next round,we set the list of subsets as {3, 1}, {3, 2, }, . . . , {3,}. And so on.",
  "(b) Spectral/Lloyds clustering": ": We compare the SDP relaxation with spectral andLloyds clustering in a toy example. There are three clusters,with the second and third clusters having higher densitiesthan the first. The black solid line illustrates the clustersyielded by each algorithm. As shown in b, spectral andLloyds clustering group the high-affinity clusters together.a shows the SDP relaxation separates them correctly.",
  "EXPERIMENTS": "We now validate Grad-TAE and Grad-TAG across various set-tings. The evaluation focuses on the following key questions. Doesthe estimation procedure accurately approximate the target taskaffinity scores? How does the running time compare to the full com-putation required to obtain these scores? Third, do the estimatedaffinity scores combined with the clustering algorithm work wellin downstream use cases?Our experiments show that Grad-TAE approximates the truetask affinities (based on full model training) within a relative errorof less than 2.7%, using less than 3% of the computational cost offull training. Further, Grad-TAG achieves comparable downstreamaccuracy to existing methods in two canonical applications, multi-label classification on graphs and language model fine-tuning, whileusing 32.8 fewer FLOPs. Lastly, we discuss the parameters andthe steps as part of our algorithm, including the comparison withalternative clustering.",
  "Experimental Setup": "5.1.1Evaluation settings. We note that our algorithm applies toa wide range of multitask learning scenarios. For a representativeevaluation, we focus on multi-label prediction on graphs and lan-guage model fine-tuning. In the first setting, each labeling taskcorresponds to a subgraph within a graph. Given a seed set of eachlabeling as the training set, the goal is to identify the remainingnodes of the subgraph. This can be cast as multitask learning byviewing each labeling as a binary classification task. The objectiveis to optimize the average accuracy of all the labeling tasks.The second setting involves fine-tuning language models usinghuman-designed instructions, known as instruction fine-tuning.Each instruction corresponds to a prompt. Typically, a data setcan come up with many relevant instructions, some of which aremore relevant to a subset of tasks than others . Thus, a naturalquestion is to select the instructions that are more relevant tothe downstream task, which can be formulated using multitasklearning. In particular, we view each instruction tuning as a singletask. While we focus on these two applications, it is conceivablethat our algorithm can be used in other related applications. 5.1.2Datasets and models. We use social network datasets withcommunity labels for multi-label prediction on graphs. We selectfour graphs from SNAP (Amazon, YouTube, DBLP, and Live-Journal), while we expect similar results to hold on other graphs.The number of nodes in these four graphs ranges from 3k to 57k;the number of edges ranges from 20k to 1M. For each graph, wepick 100 (largest) communities corresponding to = 100 tasks.For preprocessing, we randomly sample 10% of nodes from eachcommunity subgraph as positive training samples and 10% of nodesoutside the subgraph as negative samples. From the remaining data,20% is randomly sampled for validation. We evaluate performanceusing the macro 1-score on the test set .Next, we examine the running time scaling of our algorithm on alarge graph (the Orkut network), which has 395k nodes, 21M edges,and a total of 500 communities. We use a 3-layer SIGN model with a fixed width of 256 as the encoder in the MTL models, whichis more efficient to train than GCN.For fine-tuning language models, we use two text classificationdatasets from SuperGLUE , specifically RTE and WiC. Eachdataset includes 100 instructions, with ten sourced from Bach et al. and 90 generated using the automatic instruction generationmethod in . Thus, each dataset has 100 tasks, each correspond-ing to fine-tuning with one instruction. We use T5-Base as theencoder for the MTL model. The choice of this encoder is withoutloss of generality, as we expect similar results to hold on otherencoders.Put together, our experiment covers seven different datasets intotal, spanning medium- and large-scale instances, with the largestdataset containing 500 tasks. 5.1.3Evaluation metrics. We assess the accuracy of estimated taskaffinity by measuring the distance between our estimated taskaffinities and those computed from fully trained models.For task grouping, we evaluate the accuracy averaged over alltasks when training a collection of networks, each on a subset oftasks. The accuracy metric is task-dependent, such as zero-oneaccuracy or the 1-score, depending on the setting.Lastly, we measure each methods total number of FLoating-point OPerations, namely FLOPs. In addition, we report the numberof GPU hours evaluated on a single Nvidia RTX6000 GPU.",
  "for a subset of task and evaluate the performance on each task inthe subset. We report the computation in terms of FLOPs using ouralgorithm to compute and fully training models to compute": "5.2.1Accelerating pairwise task affinity computation. First, we traina separate multitask model on each pair of tasks to compute .We report the distance metric and the number of FLOPs betweenfully-trained models (to compute ) and our algorithm in .To explain our findings, we set the number of meta-initializationsto = 1 and vary the projection dimension among 50, 100, 200,and 400. We note that all these values yield an estimation of within 11% distance. As expected, increasing leads to better esti-mation. After increases above 200, the distance metric stabilizesto around 5.7%. Thus, we set as 200 in the remaining experiments.As a remark, this is approximately 15 log(), where = 683, 370in this experiment, aligning with our analysis in Proposition 3.3.Remarkably, under this setting, Grad-TAE uses 3.5 GPU hours andachieves 130 less computation compared to fully-trained models!Next, we fix = 200 while increasing up to 9. This furtherreduces the distance metric to 5.4%, with 45.0 less compute cost.We observe diminishing returns from the ensemble once goesbeyond 5. Thus, we will set as 5 in the remaining experiments.This uses 17.6 GPU hours and 44.9 less computation than fully-trained models. 5.2.2Accelerating higher-order task affinity computation. We notequalitatively similar results for approximating higher-order taskaffinity matrix. Recall this definition from equation (1), Example2.3. We set = 2000 so that the higher-order task affinity matrixconverges while setting the subset size as = 10 (further ablationstudy will be provided in .3.4).Using = 1 and = 200, our algorithm approximates within 3.5% distance while using less than 1% cost of computing.Further increasing to 5, the distance drops to 2.7%. Again, thecomputation cost is only 3% of computing . This takes 11.9 GPUhours and uses 32.8 less computation than fully-trained models. 5.2.3Accelerating task affinity computation on text and image datasets. We have shown that Grad-TAE significantly reduces the com-putational cost in task affinity estimation. To verify that theseefficiency gains are consistent across different data modalities, weapply Grad-TAE to a text classification dataset (RTE) and an imageclassification dataset (DomainNet) . The RTE data set contains100 tasks. We use T5-Base and compute higher-order task affinitywith 2000 subsets of size 10. The DomainNet data set contains sixtasks. We use ResNet-50 and compute higher-order task affinitywith 20 subsets of size 3. On the two data sets, our algorithm re-duces computation by 42.6 and 9.5, respectively, compared tocomputing true higher-order task affinities while incurring lessthan 3% relative error. The smaller speedup in the image dataset isdue to the fewer total models trained on task subsets. 5.2.4Scaling task affinity estimation to very large instances. Lastly,we estimate task affinities on the Orkut graph by varying from100 to 500. We measure the distance between the estimated and thetrue pairwise affinity by downsampling the number of pairs to 2000. shows the comparison. We observe that our algorithmscales to as many as 500 tasks, using only 112.3 GPU hours, whichis much faster than computing . Moreover, the relative distanceto the true scores remains within 5%.",
  "Comparison for Task Grouping": "5.3.1Baselines. We set up many baselines covering heuristic solu-tions and recent optimization techniques.Forward Selection (FS) and Backward Selection (BS) : Theseare standard approaches to perform subset selection, and we adaptthem to task selection.Higher-Order Approximation (HOA) : This algorithm com-putes pairwise task affinities between every two tasks and averagesthem to approximate higher-order affinities. It uses a branch-and-bound search algorithm to identify task groupings.Task Affinity Grouping (TAG) : This approach computes thetask affinity by evaluating the projecting one tasks gradients ontoanother tasks gradients during training. TAG also uses the branch-and-bound search algorithm to identify grouping.Auto- : This bilevel optimization technique balances theratio of each task relative to the average objective of all tasks.BoostMTL : This approach computes higher-order task affin-ity between two tasks as the prediction loss of one task jointlytrained with another task and a random subset of the remainingtasks, followed by spectral clustering to identify task groupings.",
  "(b) Instruction fine-tuning of language models (On the RTE dataset)": ": This figure illustrates the tradeoff between error rate and computation cost, measured by the number of FLOPsand GPU hours. Compared to multitask learning baselines, our approach achieves the Pareto optimal balance between errorrate and computation cost. Recall that is the number of meta-initializations used in Grad-TAG. The number of FLOPs isreported in the Giga FLOPs unit. For both settings, there are = 100 tasks. Our approach delivers comparable test accuracy toall baselines, using 32.8 fewer FLOPs and 5.2 less GPU hours than all baselines. 5.3.2Multi-label classification on graphs. We report the result fromapplying our algorithm to overlapped community detection. Weuse our algorithm to estimate higher-order task affinity scores andthen cluster the tasks. We illustrate our results in a, whiledeferring a full comparison to Appendix C. We use 1 Macro 1-score as the error rate on multi-label classification datasets. First,we confirm that our algorithm outperforms single-task learningthat trains one model on each task by 2.1% (as also evidenced byprior works on multitask learning ).We note that our algorithm reduces the error rate compared toall baselines while using 32.8 fewer FLOPs and 5.2 fewer GPUhours compared to the closest baseline, with = 5We can set = 1 for further speed up. This results in 71.4fewer FLOPs and 26.2 less GPU hours than the closest baseline.The decrease in performance is only 0.3%. 5.3.3Fine-tuning language models. Next, we report the resultsfrom fine-tuning language models (T5 base) on text classificationwith = 100 instructions. Again, we use our algorithm to estimatehigher-order task affinity scores and apply SDP clustering to grouptasks. We illustrate our results in b while deferring the com-plete comparison to Appendix C. We use 1 accuracy as the errorrate on the text classification datasets. In particular, our algorithmoutperforms single-task learning by 1.9%.With = 5, our algorithm shows comparable performance to allbaselines while using 48.2 fewer FLOPs and 10.6 less GPU hours.By reducing to 1, our algorithm further uses 105.4 less FLOPsand 53.2 less GPU hours, with only 0.5% performance decrease. 5.3.4Discussion of clustering algorithms and hyper-parameters.We discuss the design choices of Algorithm 2. First, we study theSDP-based clustering vs. spectral and Lloyds clustering. Acrosssix datasets, SDP-based clustering outperforms these classical al-gorithms by an average of 1.2%. Next, we discuss the number ofclusters and the rounding threshold . We vary between 5, 10, 20,and 40 (recall that = 100). We note that the performance stabilizeswhen = 20. Thus, we set = 20. For , we choose between 1",
  "and10 , and select the value that results in clusters": "Recall that Algorithm 2 also requires setting the number of sub-sets and each subsets size . Given = 100, we vary from1000 to 3000 and observe that the result stabilizes when reaches2000. Thus, we set = 2000. For , we choose it between 5, 10, and20. We choose = 10, as it yields better results than the rest.",
  "CONCLUSION": "This paper designs an efficient estimation algorithm to compute taskaffinity scores. The main idea is to pre-train a meta-initializationon all tasks and then use the initializations gradients to estimatethe fine-tuned model parameters for a particular task combinationusing logistic regression. A random projection is applied to thegradients to reduce the dimension of the regression. Then, we de-sign a robust clustering algorithm to accompany the task affinityestimation, which together yields an efficient multitask learningalgorithm. Experiments show that the algorithm can scale to asmany as 500 tasks on large graphs while accurately approximat-ing the true task affinity scores. The overall algorithm gives thebest tradeoff between computation and performance compared toexisting multitask learning methods.We discuss several aspects of future work. First, it would be inter-esting to design novel dimension reduction and clustering methodsin Grad-TAG, and they will likely depend on downstream appli-cations. Second, it would be interesting to see if boosting could beused in branching neural networks, another type of multitaskingarchitecture that trains a joint model on all tasks. A naive appli-cation of our method to group at the layer level is to start with ajoint model and gradually split layers into task groups from inputto output. In each layer, the estimation procedure (based on layer-level features) may be used to compute task affinity scores and thengroup them accordingly. This would help reduce the final model toa single neural network.",
  "R. Azorin, M. Gallo, A. Finamore, D. Rossi, and P. Michiardi. \" Its a Match!\"ABenchmark of Task Affinity Scores for Joint Learning. In: AAAI Practical-DLWorkshop (2023) (3)": "S. H. Bach, V. Sanh, Z.-X. Yong, A. Webson, C. Raffel, N. V. Nayak, A. Sharma,T. Kim, M. S. Bari, T. Fevry, et al. Promptsource: An integrated developmentenvironment and repository for natural language prompts. In: arXiv preprintarXiv:2202.01279 (2022) (4, 7). Y. Bao, Y. Li, S.-L. Huang, L. Zhang, L. Zheng, A. Zamir, and L. Guibas. Aninformation-theoretic approach to transferability in task transfer learning.In: 2019 IEEE international conference on image processing (ICIP). IEEE. 2019,pp. 23092313 (3).",
  "A. Ng, M. Jordan, and Y. Weiss. On spectral clustering: Analysis and an al-gorithm. In: Advances in neural information processing systems 14 (2001) (2)": "C. Nguyen, T. Hassner, M. Seeger, and C. Archambeau. Leep: A new measure toevaluate transferability of learned representations. In: International Conferenceon Machine Learning. PMLR. 2020, pp. 72947305 (3). A. Nippani, D. Li, H. Ju, H. Koutsopoulos, and H. Zhang. Graph Neural Net-works for Road Safety Modeling: Datasets and Evaluations for Accident Analy-sis. In: Advances in Neural Information Processing Systems 36 (2023) (2). C. H. Papadimitriou and M. Yannakakis. On the approximability of trade-offsand optimal access of web sources. In: Proceedings 41st annual symposium onfoundations of computer science. IEEE. 2000, pp. 8692 (3).",
  "=1log (1 + exp ( (,))) .(14)": "We note that there are two sources of errors in this comparison. The first is the error between (,) and its Taylors expansion ( ) + . The second is the error introduced by the random projection.To make it easier to compare between equation (14) with (12), let us expand the former as follows:",
  "This completes the proof of Proposition 3.3": "It would also be interesting to examine Taylors expansion up to the Hessian in equation (2). This requires additional computation ofHessian vector products. After that, one needs to solve a quadratic program that depends on the Hessian matrix. This is left for future work.Lastly, there is a line of work on model agnostic meta-learning and continual learning (See, e.g., survey article by Hospedales et al. ). Itwould be interesting to see if our method can be applied to this setting (i.e. estimating fine-tuned model parameters without backpropagation).This is a promising direction for future work.",
  "CADDITIONAL EXPERIMENTSC.1Implementations": "C.1.1Models. We use the SIGN model as the encoder in the multitask learning models on the community detection tasks. The encoderinvolves three layers, each with a fixed width of 256 neurons. Our choice of this encoder is without loss of generality, and our observationsalso apply to other encoders. We construct the node features from the VERSE embedding , which encodes personalized PageRank vectorsknown as useful for community detection. We use the same number of model parameters for the Auto- and MoE baselines as for the othertask grouping baselines.On text classification tasks, we use T5-Base as the base model. We use LoRA fine-tuning , which is a parameter-efficient fine-tuningmethod. For each dataset, we evaluate the average performance over all 100 instructions. In our approach, we view one instruction as onetask. We train the model with the AdamW optimizer with a learning rate of 5 105 for 5,000 gradient update steps. We vary the rank ofLoRA between 4, 8, 16, 32, 64, and 128. We find that a rank of 4 leads to the best performance; thus, we set the rank as 4 in our experiments. C.1.2Baselines. We describe the details of Forward selection: Start from all empty groups. Enumerate through all tasks by adding one taskto one of the existing groups which results in the best average performance. In Backward selection, we start from a group with all tasks andother groups as empty. Enumerate through all tasks by removing one task from the first group and assigning the task to the group whichresults in the best average performance.To be representative in terms of relative improvement, we also compare the performance with conventional methods for communitydetection, including BigClam , Louvain clustering , Network embedding methods including Node2Vec , and VERSE , and",
  "C.2Omitted results": "C.2.1Additional task grouping results. We illustrate the tradeoff between the error rate and the computation cost in terms of FLOPs andGPU hours of the other four datasets in our experiments in . We observe that our approach, Grad-TAG, consistently achieves Paretooptimal in the evaluation metrics. While achieving the comparable performance of the best baseline, our approach reduces the computationcost by 32.8 and 5.2 in terms of FLOPs and GPU hours, respectively. Compared to the baselines using the same level of computation cost,our approach improves the MTL performance over the baselines by 4% on average.",
  "(d) Instruction fine-tuning of language models (On the WiC dataset)": ": This figure illustrates the tradeoff between the error rates and computation cost in terms of FLOPs and GPU hourson four datasets omitted in the main text. Our approach, Grad-TAG, consistently achieves the Pareto optimal, deliveringcomparable test accuracy to other MTL baselines and using 32.8 fewer FLOPs and 5.2 less GPU hours than other baselines. denotes the number of meta-initializations used in our approach. C.2.2Correlation Between Estimated Affinities and True Scores. Our results show that task grouping with our estimated task affinities canachieve competitive performance with the previous method that uses the fully computed higher-order task affinities. To explain these results,we hypothesize that the estimated task affinities are highly correlated with the true task affinities, resulting in similar task groupings and,consequently, comparable performance. We compute the Spearman correlation between the estimated and true task affinities correspondingto one task , i.e., the correlation between [1,, . . . ,,] and [1,, . . . ,,]. We evaluated on the YouTube network of 100 tasks. We showthat using = 1 meta-initialization, the estimated task affinities have a 0.91 correlation with the true scores averaged over all tasks. With = 5, the estimated scores have a 0.96 correlation with true scores.",
  "Scalable Multitask Learning Using Gradient-based Estimation of Task AffinityKDD 24, August 2529, 2024, Barcelona, Spain": ": We report the Macro 1-score, computation cost as FLOPs, and runtime as GPU hours, on community detection tasksusing four social networks. We compare our approach with MTL optimization methods, feature subset selection methods, andgraph embedding methods. For each experiment, we report the results averaged over three random seeds and include theirstandard deviations."
}