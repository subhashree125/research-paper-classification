{
  "ABSTRACT": "Retrieval Augmented Generation (RAG) has become prevalent inquestion-answering (QA) tasks due to its ability of utilizing searchengine to enhance the quality of long-form question-answering(LFQA). Despite the emergence of various open source methodsand web-enhanced commercial systems such as Bing Chat, twocritical problems remain unsolved, i.e., the lack of factuality andclear logic in the generated long-form answers. In this paper, weremedy these issues via a systematic study on answer generation inweb-enhanced LFQA. Specifically, we first propose a novel outline-enhanced generator to achieve clear logic in the generation ofmultifaceted answers and construct two datasets accordingly. Thenwe propose a factuality optimization method based on a carefullydesigned doubly fine-grained RLHF framework, which containsautomatic evaluation and reward modeling in different levels ofgranularity. Our generic framework comprises conventional fine-grained RLHF methods as special cases. Extensive experimentsverify the superiority of our proposed Factuality-optimized RAG(FoRAG) method on both English and Chinese benchmarks. In par-ticular, when applying our method to Llama2-7B-chat, the derivedmodel FoRAG-L-7B outperforms WebGPT-175B in terms of threecommonly used metrics (i.e., coherence, helpfulness, and factual-ity), while the number of parameters is much smaller (only 1/24 ofthat of WebGPT-175B). Our datasets and models are made publiclyavailable for better reproducibility.1 Permission to make digital or hard copies of part or all of this work for personal orclassroom use is granted without fee provided that copies are not made or distributedfor profit or commercial advantage and that copies bear this notice and the full citationon the first page. Copyrights for third-party components of this work must be honored.For all other uses, contact the owner/author(s).KDD 24, August 2529, 2024, Barcelona, Spain 2024 Copyright held by the owner/author(s).ACM ISBN 979-8-4007-0490-1/24/08",
  "Computing methodologies Natural language generation": "ACM Reference Format:Tianchi Cai, Zhiwen Tan, Xierui Song, Tao Sun, Jiyan Jiang, Yunqi Xu,Yinger Zhang, and Jinjie Gu. 2024. FoRAG: Factuality-optimized RetrievalAugmented Generation for Web-enhanced Long-form Question Answering .In Proceedings of the 30th ACM SIGKDD Conference on Knowledge Discoveryand Data Mining (KDD 24), August 2529, 2024, Barcelona, Spain. ACM, NewYork, NY, USA, 30 pages.",
  "INTRODUCTION": "Retrieval Augmented Generation (RAG), a technique that augmentsLarge Language Models (LLMs) with a retriever by appending theretrieved relevant passages to the current context , has recentlyattracted considerable research attention . The access tosearch engine supplements massive and latest knowledge to LLMs,boosting their performance on various knowledge intensive tasks,such as open domain dialogue and question answering (QA).Following this paradigm, many web-enhanced commercial sys-tems have been developed, such as Bing Chat2 and perplexity.ai.3 They generate answers to user queries in natural language withreference to web pages, which we refer to as the web-enhancedlong-form question-answering (LFQA) task. Although these sys-tems can generate coherent and helpful answers, recent researcheshave revealed the low factuality issue of these systems, such thatonly about half of the statements generated are fully supported bythe retrieved references . This poses an unignorable threatto the trustworthiness of existing web-enhanced LFQA systems.Despite its prevalence, there lacks an effective method to opti-mize factuality in web-enhanced LFQA as far as we are concerned.There are two intrinsic difficulties. First, previous studies mostlyrely on human evaluation , which is generally expensiveto acquire. In web-enhanced LFQA task, factuality is even more",
  "sentence isentence i": ": Illustrations of the input for LLM in web-enhanced LFQA task (upper left), the existing generator (lower left), ouroutline-enhanced generator (middle) and our doubly fine-grained factuality optimization method (right). Before generating along answer, the outline-enhanced generator first drafts an organization pattern and an outline to promote a clear logic forgeneration. The doubly fined-grained RLHF optimizes factuality by incorporating fine-grained designs on two core steps, i.e.factuality evaluation and reward modeling, with methods on multiple levels of granularities proposed on each step. time-consuming and difficult to manually annotate compared toother language generation tasks, since it involves comparing thefactual details of two lengthy texts . Second, the most commonlyused fine-tuning method for human preference alignment, i.e., Rein-forcement Learning from Human Feedback (RLHF), conventionallyadopts the holistic reward, such that each answer only has a singleevaluation score. Such a reward provides a relatively sparse train-ing signal, which undermines the reliability of RLHF . Inweb-enhanced LFQA, the sparsity problem is even exaggerated, asthe answers are in long form.Besides the above factuality issue, different from conventionalQA tasks with short answers, web-enhanced LFQA poses extra chal-lenges due to the pervasive ambiguity of many real-world questions.A desirable answer to these questions is preferred to be multifac-eted , which requires organizing and consolidating informationfrom multiple aspects and references . The problem might beone possible reason why existing open source methods such asWebGLM have no explicit improvement over closed sourcemethods such as WebGPT-175B.To resolve the above issues, in this paper, we conduct a system-atic study of web-enhanced LFQA. Specifically, we first proposea novel outline-enhanced generator, which achieves clear logic inthe generation of multifaceted answers. We then propose an inno-vative factuality optimization approach based on a novel doublyfine-grained RLHF framework. Specifically, we design new auto-matic evaluation and reward modeling steps in different granulari-ties, which allows to optimize factuality for RAG in a flexible way. Our generic method contains several existing fine-grained RLHFmethods as special cases.Extensive experiments demonstrate the effectiveness of our pro-posed method, which achieves state-of-the-art performance on bothChinese and English benchmarks. Specifically, the outline-enhancedgenerator significantly improves the coherence and helpfulness,while the doubly fine-grained factuality optimization method sub-stantially promotes the factuality on both answer and sentencelevels. Remarkably, applying our method to Llama2-7B-chat yieldsa fine-tuned model FoRAG-L-7B, which, for the first time, surpassesthe WebGPT-175B on coherence, helpfulness, and factuality, whilethe number of parameters of FoRAG-L-7B is much smaller (only1/24 of that of WebGPT-175B).The contributions of this work are summarized as follows: We propose a new outline-enhanced generator to promotea clear logic of long answer generation in RAG, which sig-nificantly improves the coherence and helpfulness of thegenerated answers. Two large-scale outline-enhanced LFQAdatasets are accordingly constructed.",
  "RELATED WORK": "In this section, we review prior work in three related fields, i.e.,open-domain question answering, retrieval augmented generation,as well as web-enhanced LFQA.Open-domain Question Answering. In the field of open-domain QA, traditional efforts have centered around reading com-prehension techniques, with foundational datasets like SQuAD providing human-written questions and extracted answers.Subsequent datasets, including Natural Questions , TriviaQA, and CoQA , continue this trend but largely cater to briefanswers. Recognizing the value of more informative, long-form re-sponses, recent initiatives such as ELI5 have begun to compilequestions demanding detailed answers, prompting research intoadvanced generative techniques to meet this need.Retrieval-Augmented Generation. Retrieval-Augmented Gen-eration (RAG) enhances language model (LM) performance by inte-grating external knowledge retrieval with in-context learning. Theknowledge retrieval techniques in RAG include sparse methodssuch as BM25 and TF-IDF and dense retrieval systems, includingDPR and Contriever . To utilize the retriever, various meth-ods are proposed. REALM proposes a joint optimization of retrieverand language modeling . Retro uses a frozen retriever to en-hance the generation ability model with a novel chunked cross-attention mechanism . Atlas studies the few-shot ability for RAGmodels. Others combine black-box LMs with custom or fine-tunedretrieval systems . Different from these work, we treat theretrieval step as a black box and focus on improving the generationquality given the query and retrieved passages.Web-enhanced LFQA. The web-enhanced LFQA takes a newapproach to QA tasks which utilizes the retrieval ability of searchengine to improve the generation performance on long-form QA.Closely related to our work, WebGPT uses the questions fromELI5 and explores the ability of LLMs in navigating through the web,retrieving passages from web, and generating long-form responses.Despite its notable capabilities, the dataset, and models are notaccessible to the public. Following this idea, WebCPM buildsand releases an open-source web-enhanced LFQA model in Chinese.WebGLM provides an more efficient and cost-effective methodby replacing the expert annotation with evaluations using LLMsand utilizing a non-interactive way to use search engine. However,its resulting model, the WebGLM-10B does not outperforms theWebGPT-175B. Compared to these works, we consider optimizingthe logic structure and factuality of the generation, which has notbeen studied in web-enhanced LFQA as far as we know.",
  "PRELIMINARY": "In this section, we briefly review the RAG pipeline in web-enhancedLFQA task, which for simplicity of presentation, we adopt the termweb-enhanced RAG to describe in the sequel. The web-enhancedRAG pipeline is demonstrated in the left column of . In web-enhanced RAG, for a given user input , the system firstutilizes a web search engine to retrieve a list of relevant websiteURLs, then crawls the websites and extracts the relevant text seg-ments , which are usually called reference or context for generation. This extraction is commonly done by first segmenting theweb pages into text segments and then using pre-trained denseretrievers to extract the top-k segments .After deriving the context, the RAG system generates an answer based on the context and the user query . Following ,the response generation can be formulated as a Markov DecisionProcess (MDP) < S, A, R, , >. In such a process, each episodestarts with a sampled state S, where = (,) is a prompt thatcontains a query and a relevant context (here the parenthesisdenotes string concatenation). At each step during this episode, thestate = (,,1, ...,1) is described by the query , the context, and all the previously generated tokens (1, ...,1), which isdenoted 1 for short. Given the state , the LLM, denoted by, defines a probability distribution (|) over all tokens A conditioned on the current state , where denotes thetrainable parameters of the LLM. After generating the specific token A, the state will transit to +1 = (,) at the next time step + 1 by appending the latest generated token to the currentstate . This episode terminates when the length exceeds a pre-defined threshold or an end-of-sequence token is generated. Inthe above definition of MDP, the parameter is a discount factor.In most of the language generation tasks, we have a task specificevaluation metric R(,,) that depends on the final context = (,,1, ..., ) which consists of the generated sequence and the initial context ,, which is typically given at the endof sequence to reflect the quality of the generated sequence, e.g.,whether the sequence is helpful or harmless . Depending on theevaluation granularity, R(,,) might be a scalar or a vector oreven a matrix, we denotes the three cases by , , , respectively(see later explanations in .2) .Besides helpfulness or harmlessness, one crucial criterion ofresponse generation in RAG is factuality (or verifiability), whichleverages the extent to which the generated response is trustful.In general, the response is considered to be truthful if its con-tents are factually consistent with the retrieved text . In mostprevious works , factuality is mainly evaluated by humanannotation or via the NLI model (i.e., whether the context can entailthe information contained by the response) or general purposeLLMs , such as ChatGPT or GPT4 .",
  "OUTLINE-ENHANCED RAG": "In this section, we propose the Outline-Enhanced generation tech-nique, which is able to generate well-structured responses of highquality. Illustrated in (middle), the outline-enhanced gen-erator takes a two-stage generation, where the generator first gen-erates an organizational pattern and outline to improve the logicstructure. In the following, we describe our technique and the cor-responding construction of two outline-enhanced LFQA datasets.",
  "WebGPT-175b (en)20.9208.9414.2272": "the original query and fed into a generation model using certainprompt template ( lower left). Compared to those generatedby closed-source methods, these responses are shorter and oftenfound unorganized, lacking a clear logical structure.To enhance the performance, one possible way is to make theresponses more organized. Indeed, some researchers have foundthat carefully designed prompts that comprise task descriptionsand a few demonstrations will improve the quality of the generatedresponses on various tasks . For example, the technique of Letsthink step by step\" substantially improves the performance byencouraging the chain-of-thought reasoning ability.Inspired by the above works, we introduce the outline-enhancedtechnique into response generation. Our proposed generator in-cludes an outline stage and an expansion stage, which aligns withthe intuition that when answering a question, human usually firstoutlines and organizes the answer before expanding each point.Specifically, to generate high-quality output with a clear logic flow,we prompt the model to first output an outline of the final answer,and then concatenate the draft into the prompt to generate the fullresponse. In the following, we elaborate the two stages in detail.Outline Stage. In this stage, the generator first drafts an outlineof the answer using an outline template, with the user query andcontext as input. The outline template guides the LLM to firstconsider which organizational pattern is best suitable to the currentquestion, e.g., cause and effect\" or compare and contrast\". Thenthe LLM uses the organizational pattern to output an outline. Forexample, when the selected pattern is compare and contrast\", thegenerated outline will include various perspectives that will laterbe used to expand on the similarities and differences.Expansion Stage. Based on the outline generated at the formerstage, the LLM expands each perspective to construct the finalanswer. Specifically, The model is then asked to generate an answerto the question, given the input containing the query , the context and the outline generated in the first stage.The training of the outline-enhanced generator follows the stan-dard supervised fine-tuning (SFT) procedure, which is widely adoptedin previous works .",
  "Outline-Enhanced Long-Form QA Dataset": "As far as we know, there are only two open-sourced web-enhancedlong-form QA datasets available for training web-enhanced RAGmodels.5 The English dataset, i.e. the WebGLM-QA , contains44 samples, while the Chinese dataset, i.e. WebCPM , con-tains 5, 500 samples. The queries in both datasets are sampled fromELI5 , where WebGLM-QA sample question from it, and We-bCPM additionally uses human annotators to translate the questioninto Chinese. The Web search engine are used to collect relevantpassages.We construct an outline-enhanced bilingual long-form QA datasetusing the queries and relevant passages from these two datasets.We apply our outline-enhanced generation technique using GPT4 to collect outline-enhanced answers. We design a prompt toinstruct GPT4 to execute the outline stage and the expansion stagein a step-by-step manner, which is provided in Appendix A. Thedetailed statistics of the existing datasets and our outline-enhancedanswers are presented in . It is clear that our demonstrationanswers are much longer than that in existing works, due to thestronger logic structure (examples are provided in Appendix D). Theoutline-enhanced answers derived from WebCPM and WebGLMare publicly available. 1 Note that the imbalance of the amount of training samples inEnglish and Chinese datasets may pose difficulty to train a bilingualweb-enhanced RAG model. To overcome this difficulty, we furthercollect 39 queries and relevant passages in Chinese from publicsources, and follow the same process to generate outline-enhancedanswers. These data will be released to the public after passing thecensoring process of data release.",
  "FACTUALITY-OPTIMIZED RAG": "In this section, we propose a novel factuality optimization methodto address the aforementioned factuality issue in web-enhancedLFQA. Specifically, we first discuss the difficulty of directly ap-plying the conventional RLHF method to factuality optimization,then develop a novel doubly fine-grained RLHF framework, whichcharacterizes different granularities of automated evaluation andreward modeling, upon which our method is built.",
  "Difficulties of Directly Applying RLHF": "In LLM alignment, reinforcement learning with human feedback(RLHF) is a widely used technique to reduce undesirable gen-erations, e.g., harmful responses in chat assistant tasks . Viewingnonfactuality as a certain kind of undesirable behaviors, a naturalway to promote factuality in web-enhanced RAG is to utilize RLHFto prevent the generator from producing nonfactual responses. Toproceed, we first give a detailed description of RLHF.Conventionally, RLHF is conducted on manually annotated pref-erence data. For example, given the query and the retrieved con-text , the factuality of an answer (tokenized as (1, . . . , ))can be annotated as R(,,), where reflects theunderlying human preference. RLHF trains a reward model toestimate the factuality given any query , reference , and answer, i.e., to learn the human preference function R. Then RL methods",
  "=1E (| )) [1( = )] DKL( (|)||ref(|)),": "where 1 is the indicator function, DKL is KL divergence regulariza-tion, and is the regularization strength. In the above formulation,the regularization term is introduced to prevent the generationmodel from deviating too far from a reference model ref. Thereference model is often set as the model after SFT (e.g., our outline-enhanced RAG model as proposed above).Directly applying the conventional RLHF method to factualityoptimization in web-enhanced LFQA will encounter two intrinsicdifficulties. First, the manually annotated factuality labels are typ-ically expensive to collect, which involves comparing the factualdetails between a long answer and its corresponding lengthy refer-ence. Second, as shown in the above equation, the standard RLHFuses the holistic reward, i.e., 1( = )(,,), which is not zeroonly for the last token of the whole response. This holistic rewardcan only provide a sparse signal for the training of the generationmodel . In web-enhanced LFQA where the answers are usuallylonger, the sparsity problem due to the use of the holistic rewardwill be even exaggerated.",
  "Doubly Fine-grained RLHF": "In light of the above difficulties of conventional RLHF in factualityoptimization for web-enhanced RAG, we propose a doubly fine-grained RLHF framework to conduct factuality optimization in afine-grained manner. Our framework is inspired by recent studyon fine-grained RLHF . Unlike these previous works thatmainly focus on a single dimension, our framework incorporatesfine-grained designs of two core steps, i.e., factuality evaluationand reward modeling.Before elaborating our framework in details, we first introducenecessary notations and definitions, which enables to characterizemultiple rewards for an answer that constitute a denser rewardsignal for the RL process. Specifically, following , we firstsegment the output into text spans (1, 2, . . . , ) correspond-ing to the evaluation granularity (which will be described later)of , where each segment ends at the step . The dense re-ward signal is an -dimensional vector, whose -th dimensionrepresents the reward (|,)[] for each segment given query and retrieved context as the input, which is as-signed to the final token in . Especially, when = 1, our methoddegenerates to the standard RLHF with holistic reward.Fine-grained Evaluation. Recall that to perform high qualityautomatic factuality evaluation, recent methods have been pro-posed to first decompose a long answer into shorter pieces andthen evaluate the factuality of each piece with respect to the givenreference . Inspired by these methods, we consider threedifferent levels of granularity in the answer decomposition andautomated segment evaluation:",
  "Holistic: It is the standard granularity to evaluate the answers. Each generated answer is associated with a single fac-tuality score": "Sentence-level: As is suggested by previous research on auto-matic evaluation , we can segment the answer intosentences,6 then evaluate each sentence individually. In thiscase, the evaluation result is denoted as where is theindex for the sentence. Subclaim-level: Following , we can further decom-pose each sentence into multiple subclaims via an LLM, eachcontaining a single piece of factual information (see Appen-dix C for the prompts we use). After the decomposition, weevaluate each subclaim individually. Since the decompositionusing LLM breaks the association between the subclaim andthe original answer, we aggregate the scores of all subclaimsinto a single score to evaluate the factuality of the sentence.More specifically, assuming there are subclaims for sen-tence , then the evaluation score for the sentence is givenas = Agg (), where denotes the factuality scoreof the subclaim of sentence , and Agg is the aggregationfunction (in the form of average, minimum, or maximum). Fine-grained Reward Modeling. Recall that to build a rewardmodel to estimate the factuality of a given answer, standard RLHFmethods typically use a sequence-level reward model that producesa single factuality score for each answer. Recently, a token-levelreward modeling method has been introduced to provide token-level feedback . Enlightened by these methods, we can constructthe reward model in two possible levels of granularity. Sequence-level: A single reward (|,) is learned for eachsequence, whose actual form depends on the granularity ofthe evaluation. In this way, the associated reward reflectsthe factuality of the corresponding sequence, which is thenassigned to the last token of each sequence.",
  "KDD 24, August 2529, 2024, Barcelona, SpainCai and Tan, et al": "- William E. Moerner is an physical chemist.- William E. Moerner was affiliated with the University of Sussex.- William E. Moerner was affiliated with the University of Sussex as a visiting professor. Please breakdown the following sentence into independent facts: Sir Harold Walter Kroto, an English chemist, shared the 1996 Nobel Prizein Chemistry with Robert Curl and Richard Smalley for their discovery of a new form of carbon, buckminsterfullerene, also known asbuckyballs.- Sir Harold Walter Kroto is English.- Sir Harold Walter Kroto is an chemist.- Sir Harold Walter Kroto won the Nobel Prize in 1996.- Sir Harold Walter Kroto won the Nobel Prize in Chemistry.- Sir Harold Walter Kroto shared the Nobel Prize with Robert Curl and Richard Smalley.- They won the prize for their discovery of a new form of carbon, buckminsterfullerene, also known as buckyballs.",
  "ref( |)": "Compared to the conventional RLHF with a single reward for eachanswer, our formulation has non-zero rewards corresponding tothe segments, which alleviates the sparse feedback signal problemin conventional RLHF.Note that our proposed framework unifies the existing fine-grained RLHF works by containing these methods as specialcases. Moreover, although our framework is motivated by optimiza-tion factuality for web-enhanced RAG, it can also be generalized toother RLHF tasks.",
  "Experimental setup": "Datasets. We conduct experiments on two commonly used datasetsfor web-enhanced long-form QA.The WebGPTs dataset. Although the training dataset originallyused for WebGPT is not publicly available, the 272 samples releasedon the WebGPT demo website7 can be used as a testbed for per-formance comparison . In this dataset, each sample consistsof a question from the ELI5 dataset , several Bing retrievedweb pages, and extracted references. Note that it is a pure Englishdataset.The WebCPMs dataset. . This is a Chinese dataset constructedsimilarly to the WebGPT dataset. As there is no official train-testsplit, we randomly split 4,676 samples for training, 426 for valida-tion, and 398 for testing. Compared Methods. We compare our method with three web-enhanced baseline methods.WebGPT supports interactive web search for long-form QA.It has two versions, namely WebGPT-13B and WebGPT-175B, wherethe latter one is the currently state-of-the-art performing model forweb-enhanced QA. Note that when comparing with WebGPT, wedirectly use the responses collected from its website.WebCPM is an open source web-enhanced RAG involvinginteractive web search. It is the first work on Chinese web-enhancedRAG. It is trained on a dataset which contains 5,500 question-answerpairs in Chinese with references.WebGLM is an open source web-enhanced QA system withhuman performance. It simplifies the interactive web search ap-proach in WebGPT and WebCPM by a two-step retriever and gen-erator framework. It is trained on the WebGLM-QA dataset, whichfocuses on English only.Metrics. We adopt three commonly used metrics for web-enhancedRAG, i.e., coherence, helpfulness, and factuality. As existing worksshow that GPT4s evaluation is highly consistent to human anno-tations in both English and Chinese , we useGPT4 to evaluate these metrics. For the completeness of our study,we also justify the consistency between GPT4 and human annota-tion in Chinese in ablation study. Following the framework of ,we evaluates the coherence (Cohr.) and helpfulness (Help.) metrics.We count the scores greater than or equal to 4 as the judging criteria.For evaluation of factuality consistency, we adopt the method in to achieve fine-grained evaluation. In addition, since the longeranswers are more likely to have factuality mistakes, for the fairnessof the evaluation, we report the scores at two granularities, i.e.,query-level (Fact/q.) and sentence-level (Fact/s.). The prompts weused for the evaluations are given in Appendix B.Models and Training Configuration. Our experiments areconducted by fine-tuning on Llama2-7B-chat and ChatGLM2-6B , which are widely used LLMs for question-answering inEnglish and Chinese respectively. The prompt templates at fine-tuning and inference stages are given in Appendix A. The maxi-mum context length is set to 4096 for Llama2-7B-chat and 8192 forChatGLM2-6B. Both models are fine-tuned on 8 A100 GPUs for 5epochs with a initial learning rate of 1e-5 and a cosine learningrate scheduler. Following the configuration of WebCPM , weadopt beam search for each inference on a single A100 GPU withthe num_beams parameter set to 3. We use our outline-enhanceddataset to conduct supervised fine-tuning (SFT) , and our multi-granularity evaluation data to conduct corresponding factualityoptimization. In order to decrease noise in the RLHF step, we nor-malize the reward. Specifically, for each prompt (,), we generatea response using the SFT model, and estimates its reward score(,,) using the learned reward model. For any model gener-ated answer , we take ( ,,) = ( ,,) (,,) asthe estimated reward, and the same technique is applied to sentence-level and subclaim level factuality evaluations.",
  "FoRAG-L 7B": "0.42960.61810.80900.88755560.52210.86760.87500.97281860.44470.62560.86180.93945700.53680.88600.89700.98181890.90950.86680.65830.93456130.98160.95590.79780.97684240.91210.86680.82160.97276250.98890.95950.88970.9894447 7B, which attains the best performance among all possible combina-tions of the granularities of evaluation and reward model. A detailedperformance comparison of different granularity combinations willbe given in .3.Overall Performance. In , we compare the overall per-formance of FoRAG-L 7B and FoRAG-C 6B with all existing methodson both datasets. Note that among the examined baselines, onlyWebCPM 10B can answer in Chinese, since WebGPT does not re-lease model weights or answers in Chinese, and WebGLM has awell-known issue of being unable to answer in Chinese8. Fromthe results, we observe that on both English and Chinese datasets,FoRAG-C 6B surpasses all baselines on five out of six metrics, andFoRAG-L 7B performs the best on all metrics. Notably, FoRAG-L7B substantially outperforms WebGPT 175B that contains 24 timesmore parameters, showing superiority of our method in bilingualweb-enhanced RAG tasks.Evaluation of Outline-Enhanced Generator. We evaluatethe effectiveness of outline-enhanced generator as a core design indataset collection and RAG model design by showing that, with-out such technique, the reduced method will deteriorate severely.Specifically, for the reduced variant, we train the backbone mod-els on a merged dataset from WebCPM and WebGLM-QA, whichcontains 4.7k samples in Chinese and 44k samples in English. Notethat here we use the demonstration answers as provided in theoriginal datasets, i.e., the answers in WebCPM are human written",
  "Please refer to the discussion on the issue at WebGLMs official codebase": "and answers in WebGLM-QA are GPT4 generated, which can beconsidered in high quality.In , we compare the performance of our proposed methodwith the reduced variant. The results show that applying our tech-nique of outline-enhanced generator significantly boosts the per-formance in terms of coherence and helpfulness on both datasets.As for factuality, the sentence-level measurements of our methodsare a little bit higher or comparable with the counterpart modelswithout outline-enhanced techniques. In addition, applying ourtechnique increases the length of model generations (see AppendixE for examples of generations).Evaluation of Factuality Optimization. We then evaluatethe effectiveness of the factuality optimization technique by com-paring our method with the counterpart method without such amechanism. As presented in , adding factuality optimizationtechnique significantly raises the factuality consistency score inboth query and sequence levels, without affecting the other twometrics or the generation length. The above results justify the in-troduction of factuality optimization technique to our proposedmethod.",
  "RLHF": "Holistic + Token0.90200.85430.72360.94146080.98160.94850.83820.9768444Sentence + Token0.90950.85930.78140.96286100.98160.95590.86030.9836446Subclaim + Token0.91210.85930.78640.96586160.98520.95590.87130.9851446Holistic0.91460.86180.75630.95266220.98520.95590.84930.9797448Sentence0.90950.85930.80650.97046120.98890.95950.87870.9866447Subclaim0.91210.86680.82160.97276250.98890.95950.88970.9894447 MLE with Filtering (filter.) : This method applies a filter todrop the samples with factual inconsistency errors and preservethe factually consistent ones. Then it follows the standard SFTprocedure, i.e., fine-tuning the model by optimizing the maximumlikelihood estimation loss on the positive samples.Unlikelihood : This method fine-tunes the model by maximiz-ing the likelihood of positive (i.e., factually consistent) samples andminimizing the likelihood of negative (i.e., factually inconsistent)samples simultaneously.For a fair comparison, all the methods are fine-tuned from thesame model, i.e., Llama2 after SFT on our outline-enhanced dataset.The empirical results are presented in . From the results,we observe that our proposed method attains better factual consis-tency than the baselines, regardless of the granularity of evaluationor reward modeling. In addition, among all the granularities ofevaluation, subclaim-level evaluation performs the best. We alsonotice that token-level reward modeling performs worse than theconventional segment-level reward modeling, presumably becausethe length of our datasets may make token-level modeling over-fit.",
  "Ablation study": "We now conduct ablation study to justify the rational of somecertain design choices in our proposed method.Effectiveness of the Outline-Expansion Two-Step AnswerGeneration. To illustrate the impact of our outline-enhanced gen-eration technique, we train two baseline models that generate an-swers directly based on our dataset, which lack the outline stage,referred to FoRAG-C 6B w/o outline and FoRAG-L 7B w/o outlinein . The outcomes clearly show that our outline-enhancedgeneration approach significantly augments the models capabil-ities by enhancing the coherence and helpfulness of the answersgenerated, with a particularly notable improvement observed inthe Chinese language task.On GPT4 Evaluation Quality. To evaluate how well GPT4correlates with human judgment in Chinese, we recruit 10 nativeChinese-speaking annotators. Their task is to manually reviewcoherence, helpfulness, and both query-level and sentence-level",
  "GPT4 vs Human91.5%83.0%77.0%95.5%Human vs Human--69.5%93.1%": "factuality on the Chinese generated results. A subset of 200 exam-ples is selected, and we conduct two rounds of human evaluationon it. In each round, each sample is randomly assigned to one anno-tator. We report the agreement rate (the ratio of overlap) betweentwo-round human labels and GPT4 judgements in . Theresults confirm a robust correlation between GPT4 and human rat-ings on Chinese QA evaluation. Except on the query-level factuality,human suffers from comparing two lengthy texts, a conclusion thatis consistent with .Effects of Imbalance Dataset. To evaluate how the imbalanceof the two languages in the dataset affects the training effect onthe resulting bilingual LLMs, we perform further ablation study onthe level of imbalance. We fix the number of training samples tobe 40k. Then we tune the ratio of Chinese to English on five level,ranging from 1:10, 1:3, 1:1 to 3:1, 10:1. We then randomly sample thecorresponding amount of samples from our dataset and train themodels based on Llama2-7B using SFT. The evaluation results, asdepicted in show that with a increasing amount of data, themodels performance on the corresponding language increases on",
  ": Evaluation results in terms of various metrics ofdifferent models fine-tuned from Llama2-7B. We vary theratio of the Chinese samples to the English samples in thetraining dataset": "both coherency and helpfulness metrics. Meanwhile, the factualitymetric is not affected by this ratio. Note that the performance ofLlama2-7B is more sensitive to the number of training samplesin Chinese. This may be because the pre-training of Llama2-7Bcontains more corpus in English, and therefore a few examples isenough to adopt to the new task.",
  "Evaluation of Training Efficiency": "We finally evaluate the training efficiency of our proposed method.In the following, we will examine the additionial computation costof the two new modules of FoRAG, i.e., outline-enhanced generationand doubly fine-grained RLHF, respectively.The first step, i.e., outline-enhanced generation, has almost neg-ligible effect on training time. During inference, it requires roughly10% more tokens to be generated, and the extra time consumed atinference stage is roughly proportionally to this increase in tokensgenerated. Note that this extra inference time can be eliminatedusing context distillation techniques.The second step, i.e., doubly fine-grained RLHF, has no impact oninference time. To evaluate the additional computational expenseduring training, we consider a naive implementation of FoRAG thatsequentially evaluates the reward for each sentence. In , wecompare the training time of FoRAG and the counterpart methodwith holistic RLHF. The results show the best performed version, thesubclaim version of the doubly fine-grained RLHF framework, takesabout 67.7% more time than standard RLHF. Note that the additionalcomputational cost can be further reduced via implementation witha multi-head reward layer and carefully designed attention maskcan use one forward pass to calculate the reward for all sentences,which will make the extra computational cost insignificant.In summary, FoRAG outperforms the baseline method with rea-sonable additional computational cost.",
  "Holistic1.132.033.1-Sentence4.645.650.2+51.7%Subclaim5.150.455.5+67.7%Holistic + Token1.332.834.1+3.0%Sentence + Token5.346.451.7+56.2%Subclaim + Token6.052.058.0+75.2%": "clear logical structure in existing methods. To this end, we first de-vise an outline-enhanced generator to fulfill clear logic in long-formanswers and accordingly construct two datasets. Then we proposeto optimize factuality in a carefully designed doubly fine-grainedRLHF framework. Our developed framework contains automaticevaluation and reward modeling in different levels of granularity,and compasses traditional fine-grain RLHF methods as special cases.Empirically, FoRAG achieves state-of-the-art performance in termsof coherence, helpfulness, and factuality on both English and Chi-nese benchmarks. Notably, applying FoRAG to Llama2-7B-chat, wederive FoRAG-L-7B, which outperforms WebGPT-175B with only1/24 in the number of parameters of WebGPT-175B. Josh Achiam, Steven Adler, Sandhini Agarwal, Lama Ahmad, Ilge Akkaya, Floren-cia Leoni Aleman, Diogo Almeida, Janko Altenschmidt, Sam Altman, ShyamalAnadkat, et al. 2023. Gpt-4 technical report. arXiv preprint arXiv:2303.08774(2023). Reinald Kim Amplayo, Kellie Webster, Michael Collins, Dipanjan Das, and ShashiNarayan. 2022. Query Refinement Prompts for Closed-Book Long-Form QuestionAnswering. arXiv preprint arXiv:2210.17525 (2022). Amanda Askell, Yuntao Bai, Anna Chen, Dawn Drain, Deep Ganguli, TomHenighan, Andy Jones, Nicholas Joseph, Ben Mann, Nova DasSarma, et al. 2021.A general language assistant as a laboratory for alignment.arXiv preprintarXiv:2112.00861 (2021). Yuntao Bai, Andy Jones, Kamal Ndousse, Amanda Askell, Anna Chen, NovaDasSarma, Dawn Drain, Stanislav Fort, Deep Ganguli, Tom Henighan, et al. 2022.Training a helpful and harmless assistant with reinforcement learning fromhuman feedback. arXiv preprint arXiv:2204.05862 (2022). Yushi Bai, Jiahao Ying, Yixin Cao, Xin Lv, Yuze He, Xiaozhi Wang, Jifan Yu,Kaisheng Zeng, Yijia Xiao, Haozhe Lyu, Jiayin Zhang, Juanzi Li, and Lei Hou.2023. Benchmarking Foundation Models with Language-Model-as-an-Examiner.arXiv:2306.04181 [cs.CL] Sebastian Borgeaud, Arthur Mensch, Jordan Hoffmann, Trevor Cai, Eliza Ruther-ford, Katie Millican, George Bm Van Den Driessche, Jean-Baptiste Lespiau, Bog-dan Damoc, Aidan Clark, et al. 2022. Improving language models by retrievingfrom trillions of tokens. In International conference on machine learning. PMLR,22062240. Tom Brown, Benjamin Mann, Nick Ryder, Melanie Subbiah, Jared D Kaplan,Prafulla Dhariwal, Arvind Neelakantan, Pranav Shyam, Girish Sastry, AmandaAskell, et al. 2020. Language models are few-shot learners. Advances in neuralinformation processing systems 33 (2020), 18771901.",
  "in neural information processing systems 30 (2017)": "Zhengxiao Du, Yujie Qian, Xiao Liu, Ming Ding, Jiezhong Qiu, Zhilin Yang, andJie Tang. 2022. GLM: General Language Model Pretraining with AutoregressiveBlank Infilling. In Proceedings of the 60th Annual Meeting of the Association forComputational Linguistics (Volume 1: Long Papers). 320335. Angela Fan, Yacine Jernite, Ethan Perez, David Grangier, Jason Weston, andMichael Auli. 2019. ELI5: Long Form Question Answering. In Proceedings of the57th Annual Meeting of the Association for Computational Linguistics. 35583567.",
  "Ryo Kamoi, Tanya Goyal, Juan Diego Rodriguez, and Greg Durrett. 2023. Wice:Real-world entailment for claims in wikipedia. arXiv preprint arXiv:2303.01432(2023)": "Vladimir Karpukhin, Barlas Ouz, Sewon Min, Patrick Lewis, Ledell Wu, SergeyEdunov, Danqi Chen, and Wen-tau Yih. 2020. Dense passage retrieval for open-domain question answering. arXiv preprint arXiv:2004.04906 (2020). Takeshi Kojima, Shixiang Shane Gu, Machel Reid, Yutaka Matsuo, and YusukeIwasawa. 2022. Large language models are zero-shot reasoners. Advances inneural information processing systems 35 (2022), 2219922213.",
  "Wojciech Kryciski, Bryan McCann, Caiming Xiong, and Richard Socher. 2019.Evaluating the factual consistency of abstractive text summarization. arXivpreprint arXiv:1910.12840 (2019)": "Sayali Kulkarni, Sheide Chammas, Wan Zhu, Fei Sha, and Eugene Ie. 2020. Aqua-muse: Automatically generating datasets for query-based multi-document sum-marization. arXiv preprint arXiv:2010.12694 (2020). Tom Kwiatkowski, Jennimaria Palomaki, Olivia Redfield, Michael Collins, AnkurParikh, Chris Alberti, Danielle Epstein, Illia Polosukhin, Jacob Devlin, KentonLee, et al. 2019. Natural questions: a benchmark for question answering research.Transactions of the Association for Computational Linguistics 7 (2019), 453466.",
  "Nelson F Liu, Tianyi Zhang, and Percy Liang. 2023. Evaluating verifiability ingenerative search engines. arXiv preprint arXiv:2304.09848 (2023)": "Xiao Liu, Hanyu Lai, Hao Yu, Yifan Xu, Aohan Zeng, Zhengxiao Du, Peng Zhang,Yuxiao Dong, and Jie Tang. 2023. WebGLM: Towards An Efficient Web-EnhancedQuestion Answering System with Human Preferences. In Proceedings of the 29thACM SIGKDD Conference on Knowledge Discovery and Data Mining (<conf-loc>,<city>Long Beach</city>, <state>CA</state>, <country>USA</country>, </conf-loc>) (KDD 23). Association for Computing Machinery, New York, NY, USA,45494560. Yang Liu, Dan Iter, Yichong Xu, Shuohang Wang, Ruochen Xu, and ChenguangZhu. 2023. G-Eval: NLG Evaluation using Gpt-4 with Better Human Alignment.In Proceedings of the 2023 Conference on Empirical Methods in Natural LanguageProcessing, Houda Bouamor, Juan Pino, and Kalika Bali (Eds.). Association forComputational Linguistics, Singapore, 25112522. Jacob Menick, Maja Trebacz, Vladimir Mikulik, John Aslanides, Francis Song,Martin Chadwick, Mia Glaese, Susannah Young, Lucy Campbell-Gillingham,Geoffrey Irving, et al. 2022. Teaching language models to support answers withverified quotes. arXiv preprint arXiv:2203.11147 (2022). Grgoire Mialon, Roberto Dess, Maria Lomeli, Christoforos Nalmpantis, RamPasunuru, Roberta Raileanu, Baptiste Rozire, Timo Schick, Jane Dwivedi-Yu, AsliCelikyilmaz, et al. 2023. Augmented language models: a survey. arXiv preprintarXiv:2302.07842 (2023). Sewon Min, Kalpesh Krishna, Xinxi Lyu, Mike Lewis, Wen-tau Yih, Pang Wei Koh,Mohit Iyyer, Luke Zettlemoyer, and Hannaneh Hajishirzi. 2023. FActScore: Fine-grained Atomic Evaluation of Factual Precision in Long Form Text Generation.arXiv preprint arXiv:2305.14251 (2023). Reiichiro Nakano, Jacob Hilton, Suchir Balaji, Jeff Wu, Long Ouyang, ChristinaKim, Christopher Hesse, Shantanu Jain, Vineet Kosaraju, William Saunders, XuJiang, Karl Cobbe, Tyna Eloundou, Gretchen Krueger, Kevin Button, MatthewKnight, Benjamin Chess, and John Schulman. 2022. WebGPT: Browser-assistedquestion-answering with human feedback. arXiv:2112.09332 [cs.CL] OpenAI. 2023. GPT-4 technical report. arXiv preprint arXiv:2303.08774 (2023). Long Ouyang, Jeffrey Wu, Xu Jiang, Diogo Almeida, Carroll Wainwright, PamelaMishkin, Chong Zhang, Sandhini Agarwal, Katarina Slama, Alex Ray, et al. 2022.Training language models to follow instructions with human feedback. Advancesin Neural Information Processing Systems 35 (2022), 2773027744. Yujia Qin, Zihan Cai, Dian Jin, Lan Yan, Shihao Liang, Kunlun Zhu, Yankai Lin,Xu Han, Ning Ding, Huadong Wang, et al. 2023. WebCPM: Interactive WebSearch for Chinese Long-form Question Answering. In Proceedings of the 61stAnnual Meeting of the Association for Computational Linguistics (Volume 1: LongPapers). 89688988.",
  "Pranav Rajpurkar, Jian Zhang, Konstantin Lopyrev, and Percy Liang. 2016.Squad: 100,000+ questions for machine comprehension of text. arXiv preprintarXiv:1606.05250 (2016)": "Ori Ram, Yoav Levine, Itay Dalmedigos, Dor Muhlgay, Amnon Shashua, KevinLeyton-Brown, and Yoav Shoham. 2023. In-Context Retrieval-Augmented Lan-guage Models. Transactions of the Association for Computational Linguistics 11(2023), 13161331. Rajkumar Ramamurthy, Prithviraj Ammanabrolu, Kiant Brantley, Jack Hessel,Rafet Sifa, Christian Bauckhage, Hannaneh Hajishirzi, and Yejin Choi. 2022. Isreinforcement learning (not) for natural language processing?: Benchmarks,baselines, and building blocks for natural language policy optimization. arXivpreprint arXiv:2210.01241 (2022).",
  "Irene Solaiman and Christy Dennison. 2021. Process for adapting languagemodels to society (palms) with values-targeted datasets. Advances in NeuralInformation Processing Systems 34 (2021), 58615873": "Romal Thoppilan, Daniel De Freitas, Jamie Hall, Noam Shazeer, Apoorv Kul-shreshtha, Heng-Tze Cheng, Alicia Jin, Taylor Bos, Leslie Baker, Yu Du, et al. 2022.Lamda: Language models for dialog applications. arXiv preprint arXiv:2201.08239(2022). Hugo Touvron, Louis Martin, Kevin Stone, Peter Albert, Amjad Almahairi, Yas-mine Babaei, Nikolay Bashlykov, Soumya Batra, Prajjwal Bhargava, Shruti Bhos-ale, et al. 2023. Llama 2: Open foundation and fine-tuned chat models. arXivpreprint arXiv:2307.09288 (2023).",
  "Sean Welleck, Ilia Kulikov, Stephen Roller, Emily Dinan, Kyunghyun Cho, andJason Weston. 2019. Neural text generation with unlikelihood training. arXivpreprint arXiv:1908.04319 (2019)": "Zeqiu Wu, Yushi Hu, Weijia Shi, Nouha Dziri, Alane Suhr, Prithviraj Am-manabrolu, Noah A Smith, Mari Ostendorf, and Hannaneh Hajishirzi. 2023. Fine-Grained Human Feedback Gives Better Rewards for Language Model Training.arXiv preprint arXiv:2306.01693 (2023). Yunqi Xu, Tianchi Cai, Jiyan Jiang, and Xierui Song. 2024. Face4RAG: FactualConsistency Evaluation for Retrieval Augmented Generation in Chinese. InProceedings of the 30th ACM SIGKDD Conference on Knowledge Discovery andData Mining. Shentao Yang, Shujian Zhang, Congying Xia, Yihao Feng, Caiming Xiong, andMingyuan Zhou. 2023. Preference-grounded Token-level Guidance for LanguageModel Fine-tuning. arXiv preprint arXiv:2306.00398 (2023).",
  "###Task###Answer the question based on the materials provided": "###Requirements###Step One: Develop an answer outline based on the question and materials.1. Choose a suitable organizational pattern for the answer structure, such as general-specific-general, progressive, comparative, cause-effect,parallel, chronological, among others.2. Enumerate the essential points that need to be included in the outline, aligned with the the chosen structure.3. The relationship between key points can be parallel, contrastive, progressive, etc., but should not be repetitive or inclusive.4. Formulate a clear and concise outline that includes at least 1 but no more than 5 key points.5. Each main point should reference only one specific part of the provided materials and must include the materials number within theoutline. Step Two: Answer the question based on the materials and outline.1. Utilize the outline as a blueprint to develop a comprehensive and informative answer.2. Write the answer using formatting tools such as numbered lists, bullet points, subheadings, LaTeX formulas, etc., where appropriate.3. Refrain from using basic sequential connectors like firstly,\" secondly,\" or furthermore,\" in the answer.4. Avoid redundancy and repetition of content within the answer.5. Do not cite the number of the materials in the answer.6. Adhere strictly to the information contained within the provided materials, without adding any information that is not included in thematerials.",
  "###Input Example 1######Question###What are the main factors contributing to the increasing trend of urban population growth?": "###Materials###The improvement of healthcare in cities has led to lower mortality rates. With access to state-of-the-art hospitals, specialized clinics,and a higher concentration of medical professionals, city residents benefit from quicker and more effective response to health needs. Theadvancements in healthcare infrastructure, such as the implementation of digital health records and telemedicine, have further streamlinedpatient care, making it more accessible and efficient.Urban areas are widely recognized for better educational institutions, from primary schools to universities, that promise a morecomprehensive and diverse learning environment. These institutions are often equipped with advanced resources, experienced educators, anda broader range of programs and extracurricular activities, which are highly attractive to families who prioritize their childrens education.Cities are the epicenters of industry, commerce, and services, offering a myriad of employment options that are scarce or nonexistent inrural settings. The diversity of the urban job market, with its potential for higher wages, career advancement, and the chance to engagein more specialized work, draws individuals in pursuit of a better livelihood. Rural to urban migration is driven by the search for betteremployment opportunities.",
  "###Input Example 2######Question###What makes smartphones an essential tool for modern life?": "###Materials###Smartphones provide a convenient means of communication, allowing people to stay connected with friends and family through calls,texts, and various messaging apps.They offer access to a wide array of information and entertainment options, such as browsing the internet, streaming videos, and playinggames.Smartphones have built-in features that replace the need for other devices, like a camera, GPS, and notebook, making them a multifunctionaltool that fits in your pocket. ###Output Example 2###[Structure]:General-Specific-General[Outline]:1. Communication hub (based on )2. Multifunctional device (based on )[Answer]:Smartphones have become indispensable in contemporary life primarily because they serve as a central hub for communication and aversatile multifunctional device.### Central Hub for CommunicationThe ability to instantly connect with others via calls, texts, and various messaging applications is one of the most valued features ofsmartphones. This constant connectivity has revolutionized the way we maintain personal and professional relationships.### Versatile Multifunctional DeviceSmartphones eliminate the need to carry multiple gadgets by incorporating essential tools like a high-quality camera, a reliable GPSnavigation system, and the functionality of a notebook, all within a single, portable device.In essence, the critical role of smartphones in modern life can be attributed to their unparalleled capacity to keep us connected to the worldaround us and their ability to perform multiple functions that simplify our daily routines.",
  ": Prompt for English Coherence Evaluation": "You will be given one answer written for a question.Your task is to rate the answer on one metric.Please make sure you read and understand these instructions carefully. Please keep this document open while reviewing, and refer to it asneeded. Evaluation Criteria:Coherence (1-5) - the collective quality of all sentences. The answer should have no datelines, system-internal formatting, capitalizationerrors or obviously ungrammatical sentences (e.g., fragments, missing components) that make the text difficult to read. There should be nounnecessary repetition in the answer. Unnecessary repetition might take the form of whole sentences that are repeated or repeated facts.The answer should be well-structured and well-organized. The answer should not just be a heap of related information, but should buildfrom sentence to sentence to a coherent body of information about a topic. Evaluation Steps:1. Read the entire answer thoroughly to get a general understanding of the content and structure.2. Look for any dateline references or system-internal formatting errors. These issues should not be present in a coherent answer.3. Examine the grammar and sentence construction for flaws such as sentence fragments, run-on sentences, or missing components thatcould hinder readability.4. Identify any unnecessary repetition within the answer. This includes repeated sentences or redundant information that does not contributeto the progression of the text.5. Assess the structure and organization of the answer. It should have a logical flow, with each sentence building upon the previousinformation and contributing to a comprehensive understanding of the topic.6. Assign a score for coherence on a scale of 1 to 5, where 1 is the lowest and 5 is the highest based on the Evaluation Criteria.",
  ": Prompt for English Helpfulness Evaluation": "You will be given one answer written for a question.Your task is to rate the answer on one metric.Please make sure you read and understand these instructions carefully. Please keep this document open while reviewing, and refer to it asneeded.Evaluation Criteria:Helpfulness (1-5) - the degree to which the answer effectively meets the needs of the person seeking information. The answer should bearticulated in a way that is easy to understand. The answer should directly address the question posed, focusing on the specific informationor solution sought by the inquirer. The information provided should be correct and based on factual, verifiable data or recognized expertise.The answer includes all necessary details to fully respond to the question. It leaves no critical aspects of the question unaddressed. Evaluation Steps:1. Begin by thoroughly reading and understanding the question asked. Identify the main points and what the inquirer is seeking.2. Read the answer thoroughly to understand the information provided. Evaluate if the answer is articulated in a way that is easy tounderstand.3. Evaluate whether the answer directly addresses the question. The information provided should be relevant to what was asked.4. Ensure that the information provided is correct, factual, and based on verifiable data or recognized expertise.5. Determine if the answer includes all necessary details. A helpful answer should fully respond to the question without leaving criticalaspects unaddressed.6. Assign a score for helpfulness on a scale of 1 to 5, where 1 is the lowest and 5 is the highest based on the Evaluation Criteria.",
  ": Prompt for English Factuality Evaluation": "I will show you a question, a series of text segments, and a few reference documents. All the segments can be linked together to form acomplete answer to the question. Your task is to assess whether each text segment contains factual errors with the help of the referencedocuments. Please evaluate according to the following requirements:1. If the text segment only contains general introductions such as the method is as follows\" or according to the material,\" without conveyingspecific information, directly judge it as correct.\"2. If the text segments can find corresponding sentences in the reference document or the question as support, or can be inferred from thecorresponding sentences, directly judge them as correct.\" Pay attention to the semantic consistency of key words and details.3. If there are any pieces of information in the text segment that cannot be found in the reference document or the question, nor can they beinferred from the corresponding sentences, directly judge them as incorrect.\" Please generate the output in the following format:Assessment Details: For each segment, use the reference documents and question to explain the rationale and judgment result.Final Answer: List the numbers of the segments with errors (separated by commas). Please only output the numbers, do not outputmore details. If all information in the text segments is supported and semantically consistent with the reference documents, even if someinformation in the reference documents is not covered, please output completely correct.\" Heres an example:Question: How many nuclear power plants are there in the world?Segments:<1>There are a total of 440 operating nuclear reactors in the world, with a total installed capacity of over 390 gigawatts (GW).<2>These reactors are distributed in 30 countries around the world, with the United States owning the most reactors, followed by France,China, Japan, and Russia.<3>Among them, China is building 16 new reactors with the fastest growth, followed by India with 8 under construction.Reference Documents:```Nuclear power plants operate in 32 countries, generating about one-tenth of the worlds electricity. Most are located in Europe, NorthAmerica, East Asia, and South Asia. The United States is the largest producer of nuclear power, while France has the largest share of electricityfrom nuclear power, at about 70%. China has the fastest-growing nuclear power program, with 16 new reactors under construction, followedby India with 8 under construction.As of May 2023, there are 410 operable nuclear reactors in the world, with a total electric power capacity of 368.6 gigawatts.``` Heres what your output should look like:Assessment Details:<1>Segment 1 states: There are a total of 440 operating nuclear reactors in the world, with a total installed capacity of over 390 gigawatts(GW).\" This information is inconsistent with the information in the reference document : there are 410 operable nuclear reactors in theworld, with a total electric power capacity of 368.6 gigawatts.\" Therefore, segment 1 is incorrect.<2>The information in segment 2 These reactors are distributed in 30 countries around the world\" is inconsistent with the information inreference document : Nuclear power plants operate in 32 countries,\" and the reference document does not mention the number of nuclearreactors in France, China, Japan, and Russia,\" so segment 2 is incorrect.<3>Segment 3 states: China is building 16 new reactors with the fastest growth, followed by India with 8 under construction.\" This isconsistent with reference document : China has the fastest-growing nuclear power program, with 16 new reactors under construction,followed by India with 8 under construction.\" Therefore, segment 3 is correct.Final Answer: 1,2This means that only segments 1 and 2 contain errors, while segment 3 can find corresponding sentences in the reference document tosupport it and is judged to be correct.",
  ": Prompt for English Sentence Decomposition": "Please breakdown the following sentence into independent facts: He is also a successful producer and engineer, having worked with a widevariety of artists, including Willie Nelson, Tim McGraw, and Taylor Swift.- He is successful.- He is a producer.- He is a engineer.- He has worked with a wide variety of artists.- Willie Nelson is an artist.- He has worked with Willie Nelson.- Tim McGraw is an artist.- He has worked with Tim McGraw.- Taylor Swift is an artist.- He has worked with Taylor Swift. Please breakdown the following sentence into independent facts: Michael Collins (born October 31, 1930) is a retired American astronautand test pilot who was the Command Module Pilot for the Apollo 11 mission in 1969.- Michael Collins was born on October 31, 1930.- Michael Collins is retired.- Michael Collins is an American.- Michael Collins was an astronaut.- Michael Collins was a test pilot.- Michael Collins was the Command Module Pilot.- Michael Collins was the Command Module Pilot for the Apollo 11 mission.- Michael Collins was the Command Module Pilot for the Apollo 11 mission in 1969. Please breakdown the following sentence into independent facts: He was an American composer, conductor, and musical director.- He was an American.- He was a composer.- He was a conductor.- He was a musical director. Please breakdown the following sentence into independent facts: In 1970, the Empire State Building in New York City was the tallest buildingin the United States and the world, standing at 1,250 feet tall.- The Empire State Building is in New York City.- In 1970, the Empire State Building was the tallest building in the United States.- In 1970, the Empire State Building was the tallest building in the world.- The Empire State Building stands at 1,250 feet tall. Please breakdown the following sentence into independent facts: The Willis Tower (formerly the Sears Tower) in Chicago was the first to doso, reaching 1,450 feet in 1973.- The Willis Tower is formerly called the Sears Tower.- The Willis Tower is in Chicago.- The Willis Tower reached 1,450 feet in 1973. Please breakdown the following sentence into independent facts: The current tallest building in the United States is One World Trade Centerin New York City, which stands at 1,776 feet.- The current tallest building in the United States is One World Trade Center.- One World Trade Center is in New York City.- One World Trade Center stands at 1,776 feet. Please breakdown the following sentence into independent facts: William E. Moerner is an American physical chemist who was affiliatedwith the University of Sussex as a visiting professor.- William E. Moerner is an American.",
  "whyarentall tincansringpull??": "Thanks to @alanwood01, wethink weve been using ring pullson tin cans in completely the wrongway. But what do you think?Thanks to @alanwood01, wethink weve been using ring pullson tin cans in completely the wrongway. But what do you think?Theyre not 100% ideal in all cir-cumstances. Soup cans with ringpulls must have much thinner lidsto work, which means the lids aremore vulnerable to damage. As aneducated guess, I would imaginethat the ring pull lids cost slightlymore to manufacture, too, whichisnt at all a small considerationwhen youre talking about some-thing as low-margin as most gro-ceries.Ring pulls are expensive com-pared to the standard lid. Its frac-tions of a penny, but it adds upwhen you manufacture a few mil-lion units in cans a day.In my civilized European coun-try all cans are ring-pull, even theones with tuna. OP must be a prim-itive American, where you have touse stupid can openers for every-thing. Ring pull cans are not used univer-sally because they are more expen-sive to manufacture compared tothe standard lid, and the soupcan lids must be thinner to work,making them more vulnerable todamage. In addition, the cost dif-ference adds up when manufactur-ing a few million cans a day,making the ring pull lids less cost-effective. [Structure]:Cause-Effect[Outline]:1. Manufacturing cost considerations (based on and )2. Practicality in terms of product safety and in-tegrity (based on )[Answer]:The absence of ring pulls on all tin cans can beattributed primarily to two factors: cost concernsand practicality related to product safety.### Manufacturing Cost ConsiderationsRing pulls, while convenient for consumers, aremore expensive to produce than standard lids.This cost difference, although seemingly minoron a per-unit basis, becomes significant when con-sidering the scale of production. Manufacturersoften produce millions of cans daily, and even frac-tions of a penny per can add up to a considerableamount. As groceries are generally low-marginproducts, companies are inclined to minimize pro-duction costs wherever possible to maintain prof-itability.### Practicality for Product SafetyIn addition to cost implications, the feasibility ofusing ring pulls on certain products is limited bythe need for thinner lids. This requirement fora thinner lid makes the cans more vulnerable todamage, posing a risk to the integrity of the prod-uct inside. Soup cans, for example, must main-tain their structure to ensure safe storage andtransportation. The decision to forgo ring pullson some tin cans is a measure to prevent potentialdamage and the associated waste or customer dis-satisfaction that could result from compromisedproduct packaging.",
  "Whydontsurferswearlifevestsandhel-mets?": "One of the major reasons surfersdont use life vests is that whenthey are in the water they arestrapped to a giant floatation device,their surfboard.Other than the fact that theylook bad, the main reason whysurfers dont wear life jackets isthat they get in the way. With aPFD on, it will be harder to paddleand duck dive. Furthermore, surfersare literally standing on a big PFD their surfboards which are at-tached to their legs with a rope.Lets be honest here, this is prob-ably the #1 reasons apart from thewe dont really need it reason thatsurfers dont wear life jackets.Now, arguably the main reasonwhy most surfers dont wear lifejackets is that they get in the wayboth in terms of fun and, ironically,in the way of safety as well.While surfers dont wear lifevests (there are specific require-ments for a device to be consideredlife saving), its not a surprise thatbig wave surfers wear special inflat-able PFDs. Surfers generally dont wear lifevests and helmets because they arestrapped to a giant floatation device,their surfboard, and life jacketsget in the way of paddling and duckdiving. Furthermore, surfersdont need to wear life jackets be-cause they are standing on a bigPFD - their surfboards - which areattached to their legs with a rope.For bigger waves, some surferswear special inflatable PFDs. [Structure]:Comparative[Outline]:1. Surfboard as a flotation device (based on )2. Hindrance to movement and safety (based on and )3. Aesthetic and traditional reasons (based on )4. Exception for big wave surfers (based on )[Answer]:Surfers typically eschew traditional life vests andhelmets due to a combination of practical, safety,and cultural reasons, as well as the nature of theirequipment.### Surfboard as a Flotation DeviceA primary reason surfers dont utilize life vests istheir surfboard, which essentially acts as a largeflotation device. Since surfboards are buoyant andtethered to the surfer by a leash, they providesignificant flotation support without the need foran additional life vest.### Hindrance to Movement and SafetyLife vests are generally avoided because they caninterfere with the surfers ability to move freely.The requirement to paddle effectively and per-form duck dives a maneuver used to dive be-neath oncoming waves is hampered by the bulkof a personal flotation device (PFD). Ironically,rather than increasing safety, a life vest can ac-tually present a hazard by restricting mobility inthe water.### Aesthetic and Traditional ReasonsThe avoidance of life vests is also influenced byaesthetics and tradition within the surfing com-munity. Surfers often prefer the freedom of notwearing what may be considered unattractivegear, adhering to a longstanding cultural norm ofsurfing without excessive equipment.### Exception for Big Wave SurfersWhile standard practice is to not wear life vests,there is an exception for big wave surfers, whomay use specialized inflatable PFDs. These de-vices are designed with the specific risks of bigwave surfing in mind, balancing the need for flota-tion with the necessity of not hindering move-ment.In conclusion, the decision not to wear life vestsand helmets while surfing is largely based on thesurfboards role as a flotation aid, the importanceof unhindered movement for both performanceand safety, cultural factors regarding appearance,and exceptions made for the unique conditionsfaced by big wave surfers.",
  "Whydoicedcoffeedrinkshavemorecaf-feinethanhotones?": "While its hard to pin down theprecise amount of caffeine in anygiven iced coffee, we can make sev-eral assumptions based on whatwe know of caffeine. Since caffeineis soluble in water, hot water re-mains the best way to extract caf-feine from coffee beans, giving icedcoffee an edge over cold brew dueto the brewing method.But, iced coffee brewed with hotwater also tends to have a lowercoffee to water ratio that somewhatdilutes the caffeine content, as doesthe ice you need to chill the coffee.Iced coffee can be made with left-over hot coffee, and will have morecaffeine in it than a cold brew coffee.Cold-brew coffees can have a lot ofcaffeine in them if they are highlyconcentrated, but the amount ofcaffeine that can be concentrateddown into the cold brew dependson how the coffee was brewed ini-tially.ICED COFFEE: A typical 16-oz.iced coffee has 165 mg of caffeine.COLD BREW: A typical 16-oz. coldbrew has 200 mg of caffeine. So,in the simplest of terms, cold brewhas more caffeine than iced coffee(and, depending on how its brewedsometimes it can be nearly doublethat of its cold coffee counterpart!)But, why is there such a huge dif-ference in the caffeine contents ofthese drinks?THE BREW SAYS IT ALLIt all comes down to how each oneis brewed. Iced coffee is brewedas regular coffee, which then goesthrough a cooling process and isserved over ice. Cold brew, on theother hand, is created by steepingground coffee at room temperatureand then filtering out the grounds.So, its essentially the most concen-trated version of coffee you can get.Once you filter out the grounds, theconcentrate is combined with waterfor (generally) a 50/50 coffee con-centrate/water split, and TA-DA!You have cold brew. There is more caffeine in iced coffeethan in hot coffee due to the brew-ing method . Iced coffeeis brewed as regular coffee, whichthen goes through a cooling pro-cess and is served over ice . Coldbrew, on the other hand, is cre-ated by steeping ground coffee atroom temperature and then filter-ing out the grounds . Once youfilter out the grounds, the concen-trate is combined with water for(generally) a 50/50 coffee concen-trate/water split . Iced coffeebrewed with hot water also tends tohave a lower coffee to water ratiothat somewhat dilutes the caffeinecontent, as does the ice you need tochill the coffee . [Structure]:Comparative-Cause-Effect[Outline]:1. Brewing method and extraction efficiency(based on and )2. Coffee to water ratio and ice dilution (based on)3. Concentration of caffeine in cold brew (basedon and )[Answer]:iced coffee drinks contain more caffeine than theirhot counterparts primarily due to differences inthe brewing process and the resulting concentra-tion of caffeine.### Brewing Method and Extraction EfficiencyThe extraction of caffeine from coffee beans ismost efficient when using hot water, as caffeineis soluble in water. This is the reason why icedcoffee, which is often made by pouring hot coffeeover ice, tends to have a higher caffeine contentcompared to cold brew coffee. However, the caf-feine content can be diluted in iced coffee due tothe use of hot water in the brewing process andthe inclusion of ice which requires water to chillthe drink.### Coffee to Water Ratio and Ice DilutionWhen making iced coffee, the coffee to water ratiois typically higher than in cold brew coffee. This isbecause iced coffee is made by brewing hot coffeeand then cooling it down, which results in a lowerconcentration of caffeine per serving. Conversely,cold brew coffee is brewed at room temperatureand then filtered to remove the grounds, concen-trating the caffeine.### Concentration of Caffeine in Cold BrewCold brew coffee can have a significantly highercaffeine content than iced coffee. This is becausethe cold brew process involves steeping groundcoffee at room temperature and filtering it to cre-ate a highly concentrated coffee concentrate. Typ-ically, a 16-ounce cold brew contains about 200mg of caffeine, compared to iced coffee which mayhave around 165 mg of caffeine. The difference incaffeine content can sometimes be nearly double,depending on the specific brewing methods usedfor each drink.In summary, the higher caffeine content in icedcoffee drinks as opposed to hot coffees is attrib-uted to the brewing techniques that extract morecaffeine into the beverage, the dilution effect fromusing ice, and the concentration of caffeine in thecold brew process.",
  "Whoare theKur-dishpeo-ple?": "Kurds speak the Kurdish lan-guages and the ZazaGorani lan-guages, which belong to the West-ern Iranian branch of the Iranianlanguages in the Indo-Europeanlanguage family.Kurds(Kurdish:Kurd)orKurdishpeopleareanIra-nianethnicgroupnative to the mountainous regionof Kurdistan in Western Asia,which spans southeastern Turkey,northwestern Iran, northern Iraq,and northern Syria. There areexclaves of Kurds in Central Anato-lia, Khorasan, and the Caucasus, aswell as significant Kurdish diasporacommunities in the cities of west-ern Turkey (in particular Istanbul)and Western Europe (primarily inGermany). The Kurdish populationis estimated to be between 30 and45 million.The Kurds are one of the indige-nous peoples of the Mesopotamianplains and the highlands in whatare now south-eastern Turkey,north-eastern Syria, northern Iraq,north-western Iran and south-western Armenia.Today, they form a distinctive com-munity, united through race, cul-ture and language, even thoughthey have no standard dialect. Theyalso adhere to a number of differentreligions and creeds, although themajority are Sunni Muslims.The Kurdish people are an eth-nic minority group without an of-ficial state. Before World War I,Kurds lived a nomadic lifestyle un-til the breakup of the Ottoman Em-pire, which stripped them of theirfreedom and divided them acrossseveral nation states.Today, there are an estimated 25-30 million Kurds, the majority liv-ing in a region that stretches acrossparts of Turkey, Iraq, Iran, Syria andArmenia.Most Kurds are Sunni Muslims, butthe Kurdish population has diversecultural, social, religious and politi-cal traditions as well as a variety ofdialects. The Kurds are an Iranian ethnicgroup native to the mountainous re-gion of Kurdistan in Western Asia,which spans southeastern Turkey,northwestern Iran, northern Iraq,and northern Syria. Theyare one of the indigenous peo-ples of the Mesopotamian plainsand the highlands in what arenow south-eastern Turkey, north-eastern Syria, northern Iraq, north-western Iran and south-western Ar-menia. Kurds speak the Kurdish languagesand the ZazaGorani languages,which belong to the Western Ira-nian branch of the Iranian lan-guages in the Indo-European lan-guage family. They are an eth-nic minority group without an of-ficial state. Before World War I,Kurds lived a nomadic lifestyle un-til the breakup of the Ottoman Em-pire, which stripped them of theirfreedom and divided them acrossseveral nation states. Today,there are an estimated 25-30 mil-lion Kurds, the majority living ina region that stretches across partsof Turkey, Iraq, Iran, Syria and Ar-menia. Most Kurds are SunniMuslims, but the Kurdish popula-tion has diverse cultural, social, re-ligious and political traditions aswell as a variety of dialects. [Structure]:General-Specific-General[Outline]:1. Ethnic and linguistic identity (based on and)2. Geographical distribution and diaspora (basedon )3. Cultural and religious characteristics (based on and )[Answer]:The Kurdish people are an ethnic group with arich cultural and linguistic heritage, native to theregion known as Kurdistan in Western Asia.### Ethnic and Linguistic IdentityKurds speak Kurdish languages and ZazaGoranilanguages, which are part of the Western Iranianbranch of the Iranian languages within the Indo-European family. This linguistic connection un-derscores their unique identity, both as an ethnicgroup and as a linguistic minority.### Geographical Distribution and DiasporaGeographically, Kurds are spread across a regionthat includes parts of Turkey, Iraq, Iran, Syria,and Armenia. Their historical homeland, knownas Kurdistan, encompasses significant exclaves inCentral Anatolia, Khorasan, and the Caucasus. Inaddition to their native regions, Kurdish diasporacommunities are notable in western Turkey, par-ticularly Istanbul, and in Western Europe, with asubstantial presence in Germany.### Cultural and Religious CharacteristicsCulturally, Kurds share a common identitythrough race, language, and religion, even thoughthey do not have a standard dialect. The majorityof Kurds today adhere to Sunni Islam, reflecting acommon religious practice among the community.Despite this religious affiliation, Kurdish cultureis diverse, encompassing various social, religious,political traditions, and dialects.Before the dissolution of the Ottoman Empirefollowing World War I, Kurds led a nomadic life.The subsequent division of the Ottoman Empireinto several nation-states resulted in the loss ofKurdish freedom and led to a complex politicalsituation where Kurds found themselves spreadacross several countries, without an official stateof their own.In summary, the Kurdish people are character-ized by their distinct ethnic and linguistic back-ground, their geographic distribution and dias-pora, and the rich tapestry of their cultural andreligious practices. Despite facing historical chal-lenges, they maintain a strong sense of identityand community.",
  "Whydo weuseshav-ingplugsinbath-rooms,aretheysaferthatnor-mal3pinplugs?": "UK building regulations meanyou cannot fit a regular 3 pin mainspower socket in a bathroom, eventhe shaver socket has to be a safedistance away from the bath orshower. This is often why manysockets are part of a light fittingabove a mirror and hidden behinda little door, making it harder to ac-cess. All to protect you and I frominjuring ourselves.Other countries around the worldmay have normal sockets in theirbathrooms. Why? For some it is be-cause of the lower voltage used, sothe effects of electric shock and se-rious injury are reduced. In othercases it is less established safetymeasures and in others there isa trust that you as an individualwont do anything silly enough toput your life at risk.A bathroom shaver socket isa specialized electrical socket de-signed for safe use of electricalshavers in the bathroom. Thissocket design is most commonlyseen in the United Kingdom andsome parts of Europe, and has beenlargely replaced by the ground faultcircuit interrupter (GFCI) socket. Itis possible to use these types ofsockets for replacement of old sock-ets or installation in a new bath-room design, but usually a GFCIsocket is more appropriate. Thenewer socket style may also be re-quired under the building code.The bathroom shaver socket ismounted in an isolation trans-former that cuts it off from the restof the electrical system. This limitsthe risk of electrical shock, a con-cern in the bathroom where lotsof water can be present. In addi-tion, the current is very low. It willpower a shaver or electric tooth-brush, but not an item like a heateror a hair dryer. The circuit will shutdown if it gets too hot, thus keepingthe user as safe as possible. In the UK, special sockets are re-quired for bathrooms due to build-ing regulations . These sockets,called bathroom shaver sockets, aredesigned to be safer than a regu-lar 3-pronged electrical socket .They are mounted in an isolationtransformer that cuts them off fromthe rest of the electrical system. This limits the risk of electri-cal shock, which is a concern in thebathroom given that lots of watercan be present . The circuit willshut down if it gets too hot, whichprotects the user as safe as possible. Additionally, these sockets areoften part of a light fixture abovea mirror and hidden behind a littledoor, which makes them harder toaccess . [Structure]:Comparative[Outline]:1. Safety measures in the UK and similar regula-tions elsewhere (based on )2. Design differences between bathroom shaversockets and regular 3-pin plugs (based on )3. Electrical safety and low-current design (basedon )[Answer]:The use of shaving plugs, also known as bathroomshaver sockets, in bathrooms is primarily a resultof safety regulations and design considerationsthat differentiate them from normal 3-pin plugs.### Safety Measures and RegulationsIn the UK and some other countries, building reg-ulations dictate that regular 3-pin mains powersockets are not permitted in bathrooms. This isto prevent the risk of electric shock or injury dueto coming into contact with the socket while wet.Therefore, sockets are often concealed and in-stalled at a safe distance from bathing areas.### Design DifferencesThe bathroom shaver socket is specifically de-signed for safe use of electrical appliances likeshavers in the bathroom environment. It is char-acterized by its isolation transformer which seg-regates it from the rest of the electrical system,thereby reducing the risk of electrical shock. Thisdesign is a safety measure particularly pertinentin bathrooms where water is likely to be present.### Electrical Safety and Low-Current DesignThe shaver socket is engineered to power onlydevices that are safe to use in a wet environment,such as shavers and electric toothbrushes. It is notdesigned to power appliances that could presenta higher risk, like heaters or hair dryers. Addi-tionally, the circuit is designed to shut down if itoverheats, which further ensures user safety.In conclusion, shaving plugs are considered saferthan normal 3-pin plugs because of the specificsafety regulations they adhere to, their isolated de-sign, and the low-current circuitry that preventsriskier electrical appliances from being used inwet environments."
}