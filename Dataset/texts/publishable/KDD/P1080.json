{
  "ABSTRACT": "Traditional recommender systems typically use user-item ratinghistories as their main data source. However, deep generative mod-els now have the capability to model and sample from complex datadistributions, including user-item interactions, text, images, andvideos, enabling novel recommendation tasks. This comprehensive,multidisciplinary survey connects key advancements in RS usingGenerative Models (Gen-RecSys), covering: interaction-driven gen-erative models; the use of large language models (LLM) and textualdata for natural language recommendation; and the integration ofmultimodal models for generating and processing images/videosin RS. Our work highlights necessary paradigms for evaluating theimpact and harm of Gen-RecSys and identifies open challenges.This survey accompanies a tutorial presented at ACM KDD24,with supporting materials provided at:",
  "KDD 24, August 2529, 2024, Barcelona, Spain 2024 Copyright held by the owner/author(s).ACM ISBN 979-8-4007-0490-1/24/08": "ACM Reference Format:Yashar Deldjoo, Zhankui He, Julian McAuley, Anton Korikov, Scott Sanner,Arnau Ramisa, Ren Vidal, Maheswaran Sathiamoorthy, Atoosa Kasirzadeh,and Silvia Milano. 2024. A Review of Modern Recommender Systems UsingGenerative Models (Gen-RecSys). In Proceedings of the 30th ACM SIGKDDConference on Knowledge Discovery and Data Mining (KDD 24), August2529, 2024, Barcelona, Spain. ACM, New York, NY, USA, 11 pages.",
  "INTRODUCTION": "Advancements in generative models have significantly impactedthe evolution of recommender systems (RS). Traditional RS, whichrelied on capturing user preferences and item features within aspecific domain often referred to as narrow experts are nowbeing complemented and, in some instances, surpassed by gener-ative models. These models have introduced innovative ways ofconceptualizing and implementing recommendations. Specifically,modern generative models learn to represent and sample from com-plex data distributions, including not only user-item interactionhistories but also text and image content, unlocking these datamodalities for novel and interactive recommendation tasks.Moreover, advances in natural language processing (NLP) throughthe introduction of large language models (LLMs) such as Chat-GPT and Gemini have showcased remarkable emergentcapabilities , including reasoning, in-context few-shot learn-ing, and access to extensive open-world information within theirpre-trained parameters. Because of their broad generalist abilities,these pretrained generative models have opened up an exciting newresearch space for a wide variety of recommendation applications(see ), e.g., enhanced personalization, improved conversa-tional interfaces, and richer explanation generation, among others.",
  "The core of generative models lies in their ability to model andsample from their training data distribution for various inferentialpurposes, which enables two primary modes of application for RS:": "(1) Directly trained models. This approach trains generative mod-els, such as VAE-CF (Variational AutoEncoders for CollaborativeFiltering) (cf. .1) directly on user-item interactiondata to predict user preferences, without using large, diverse pre-training datasets. These models learn the probability distributionof items a user might like based on their previous interactions. (2) Pretrained models. This strategy uses models pretrained ondiverse data (text, images, videos) to understand complex pat-terns, relationships, and contexts that often exhibit (emergent)generalization abilities to a range of novel tasks . Among avariety of applications, this survey covers the use of pretrainedGen-RecSys models in the following settings: Zero- and Few-shot Learning (cf. .2.1), using in-contextlearning (ICL) for broad understanding without extra training.",
  "Wu et al. discuss both the use of LLMs to generate RS inputtokens or embeddings as well as the use of LLMs as an RS;": "Lin et al. focus on adapting LLMs in RS, detailing varioustasks and applications. Fan et al. overview LLMs in RS, em-phasizing pre-training, fine-tuning, and prompting, while Vatset al. review LLM-based RS, introducing a heuristic taxon-omy for categorization. Huang et al. , explore using foundation models (FMs) in RS. Wang et al. introduce GeneRec, a next-gen RS that person-alizes content through AI generators and interprets user instruc-tions to gather user preferences. While the mentioned surveys offer crucial insights, their scope is of-ten limited to LLMs or, more broadly, FMs and/or specific models such as GANs , without considering thewider spectrum of generative models and data modalities. The workby provides a more relevant survey on Gen-RecSys althoughtheir work is mostly on personalized content generation.",
  "(1) Our survey is broader in scope than the surveys mentionedabove, encompassing not just LLMs but a wide array ofgenerative models in RS": "(2) We have chosen to classify these models based on the type ofdata and modality they are used for, such as user-item data(cf. ), text-driven (cf. ), and multimodal (cf.) models, as shown in the Rec. Scenario layer. (3) Within each modality discussion, we provide an in-depthexploration of deep generative model paradigms as shown inthe Model layer, yet with a broader scope that spans multiplecontexts and use cases, offering a critical analysis of theirroles and effectiveness in respective sections. (4) We study the evaluation of Gen-RecSys with finer details,shedding light on multiple aspects such as benchmarks, eval-uation for impact and harm relative to multiple stakeholders,and conversational evaluation. This evaluation frameworkis particularly notable as it helps to understand the complexchallenges intrinsic to Gen-RecSys.",
  "GENERATIVE MODELS FOR INTERACTION-DRIVEN RECOMMENDATION": "Interaction-driven recommendation is a setup where only the user-item interactions (e.g., user A clicks item B) are available, whichis the most general setup studied in RS. In this setup, we concen-trate on the inputs of user-item interactions and outputs of item-recommended lists or grids rather than richer inputs or outputsfrom other modalities such as textual reviews. Even though notextual or visual information is involved, generative models still show their unique usefulness. In this section, weexamine the paradigms of generative models for recommendationtasks with user-item interactions, including auto-encoding mod-els , auto-regressive models , generative adversarialnetworks , diffusion models and more.",
  "Auto-encoding models learn to reconstruct their inputs. This ca-pability allows them to be used for various purposes, includingdenoising, representation learning, and generation tasks": "2.1.1Preliminaries: Denoising Auto-Encoding Models. DenoisingAuto-Encoding models are a group of models that learn to recoverthe original inputs from a corrupted version of the inputs. Tradition-ally, denoising auto-encoding models refer to a group of DenoisingAutoencoders with hidden layers as a bottleneck. Forexample, AutoRec tries to reconstruct the input vector, whichis partially observed. More broadly, BERT-like models are also treated as denoising auto-encoding models. Such models re-cover corrupted (i.e., masked) inputs through stacked self-attentionblocks . For example, BERT4Rec is trained to predictmasked items in given user historical interaction sequences. There-fore, BERT-like models can be used for next-item prediction inthe inference phase . 2.1.2Variational Auto-Encoding Models. Variational Autoencoders(VAEs) are models that learn stochastic mappings from an input from a often complicated probability distribution to a probabilitydistribution . This distribution, , is typically simple (e.g., a normaldistribution), enabling the use of a decoder to generate outputs bysampling from . VAEs find wide applications in traditional RS,particularly for collaborative filtering , sequential recommenda-tion and slate generation . Compared to DenoisingAutoencoders, VAEs often demonstrate superior performance incollaborative filtering due to stronger modeling assumptions, suchas VAE-CF . Additionally, Conditional VAE (CVAE) mod-els learn distributions of preferred recommendation lists for a givenuser. This makes them useful for generating those lists beyond agreedy ranking schema. Examples like ListCVAE and PivotC-VAE use VAEs to generate entire recommendation lists ratherthan solely ranking individual items.",
  "they find wide applications in session-based or sequential recom-mendations , model attacking , and bundle recommen-dations , with recurrent neural networks , self-attentive models , and more": "2.2.1Recurrent Auto-Regressive Models. Recurrent neural networks(RNNs) have been use to predict the next item in session-based and sequential recommendations, such as GRU4Rec andits variants (e.g., predicting the next set of items in basketor bundle recommendations, such as set2set and BGN ).Moreover, using the auto-regressive generative nature of recur-rent networks, researchers extract model-generated user behaviorsequences, which are used in the research of model attacking . 2.2.2Self-Attentive Auto-Regressive Models. Self-attentive modelsreplace the recurrent unit with self-attention and related modules,inspired by transformers . This group of models can be usedin session-based recommendation and sequential recommenda-tion , next-basket or bundle prediction , andmodel attacking . Meanwhile, the benefits of self-attentivemodels are that they handle long-term dependencies better thanRNNs and enable parallel training . Additionally, self-attentivemodels are the de-facto option for pre-trained models and largelanguage models , which is gaining traction in RS. Moredetails about using such language models for recommendationswill be discussed in .",
  "Generative Adversarial Networks": "Generative adversarial networks (GANs) are composedof two primary components: a generator network and a discrimi-nator network. These networks engage in adversarial training toenhance the performance of both the generator and the discrimina-tor. GANs are used in RS for multiple purposes . In theinteraction-driven setup, GANs are proposed for selecting informa-tive training samples , for example, in IRGAN ,the generative retrieval model is leveraged to sample negative items.Meanwhile, GANs synthesize user preferences or interactions toaugment training data . Additionally, GANs have showneffectiveness in generating recommendation lists or pages, suchas in whole-page recommendation settings.",
  "Diffusion Models": "Diffusion models generate outputs through a two-step pro-cess: (1) corrupting inputs into noise via a forward process, and (2)learning to recover the original inputs from the noise iterativelyin a reverse process. Their impressive generative capabilities haveattracted growing interest from the RS community.First, a group of works learns users future interactionprobabilities through diffusion models. For example, DiffRec predicts users future interactions using corrupted noises from theusers historical interactions. Second, another group of works focuses on diffusion models for training sequence augmenta-tion, showing promising results in alleviating the data sparsity andlong-tail user problems in sequential recommendation.",
  "Other Generative Models": "In addition to the previously mentioned generative models, RSalso draw upon other types of generative models. For instance,VASER leverages normalizing flows (and VAEs )for session-based recommendation. GFN4Rec , on the otherhand, adapts generative flow networks for listwise rec-ommendation. Furthermore, IDNP utilizes generative neuralprocesses for sequential recommendation. In summary, var-ious generative models are explored in RS, even in settings withouttextual or visual modalities.",
  "LARGE LANGUAGE MODELS INRECOMMENDATION": "While language has been leveraged by content-based RS for overthree decades , the advent of pretrained LLMs and their emer-gent abilities for generalized, multi-task natural language (NL) rea-soning has ushered in a new stage of language-basedrecommendation. Critically, NL constitutes a unified, expressive,and interpretable medium that can represent not only item featuresor user preferences, but also user-system interactions, recommen-dation task descriptions, and external knowledge . For instance,items are often associated with rich text including titles, descrip-tions, semi-structured textual metadata, and reviews. Similarly, userpreferences can be articulated in NL in many forms, such as reviews,search queries, liked item descriptions, and dialogue utterances.Pretrained LLMs provide new ways to exploit this textual data:recent research (e.g., ) has shown that in manydomains, LLMs have learned useful reasoning abilities for makingand explaining item recommendations based on user preferences aswell as facilitating conversational recommendation dialogues. Asdiscussed below, these pretrained abilities can be further augmentedthrough prompting (e.g., ), fine-tuning (e.g., ), retrieval (e.g., ), and other externaltools (e.g., .We next proceed to survey the developments in LLM-based RSs,first discussing encoder-only LLMs for dense retrieval and cross-encoding (.1) followed by generative NL recommenda-tion and explanation with sequence-to-sequence (seq2seq) LLMs(.2). We then review the complementary use of RS andLLMs covering RAG (.3) and LLM-based feature extraction(.4), before concluding with a review of conversationalrecommendation methods (.5).",
  "Encoder-only LLM Recommendation": "3.1.1Recommendation as Dense Retrieval. A common task is toretrieve the most relevant items given a NL preference statementusing item texts, for which dense retrieval has become a key tool.Dense retrievers produce a ranked list of documents givena query by evaluating the similarity (e.g., dot product or cosinesimilarity) between encoder-only LLM document embeddings andthe query embedding. They are highly scalable tools (especiallywhen used with approximate search libraries like FAISS1) becausedocuments and queries are encoded separately, allowing for dense",
  "A Review of Modern Recommender Systems Using Generative Models (Gen-RecSys)KDD 24, August 2529, 2024, Barcelona, Spain": "and fine-tuned multimodal benchmarks, despite using orders ofmagnitude less images for pre-training.Contrastive-based alignment has shown impressive zero-shotclassification and retrieval results , and has been success-fully fine-tuned to a multitude of tasks, such as object detection ,segmentation or action recognition . The same alignmentobjective has also been used between other modalities ,and with multiple modalities at the same time .",
  "LLM-based Generative Recommendation": "In LLM-based generative recommendation, tasks are expressed astoken sequences called prompts which form an input to a seq2seqLLM. The LLM then generates another token sequence to addressthe task with example outputs including: a recommended list ofitem titles/ids , a rating , or an explanation. These methods rely on the pretraining of LLMson large text corpora to provide knowledge about a wide rangeof entities, human preferences, and commonsense reasoning thatcan be used directly for recommendation or leveraged to improvegeneralization and reduce domain-specific data requirements forfine-tuning or prompting . 3.2.1Zero- and Few- Shot Generative Recommendation. Severalrecent publications have evaluated with off-the-shelf LLM generative recommendation, focusing on domainsthat are prevalent in the LLM pre-training corpus such as movieand book recommendation. Specifically, these methods constructa prompt with a NL description of user preference (often using asequence of recently liked item titles) and an instruction to rec-ommend the next item titles or predict a rating. While, overall, untuned LLMs underperform supervisedCF methods trained on sufficient data , they are competi-tive in near cold-start settings . Few-shot prompting (orin-context learning), in which a prompt contains examples of input-output pairs, typically outperforms zero-shot prompting . 3.2.2Tuning LLMs for Generative Recommendation. To improvean LLMs generative recommendation performance and add knowl-edge to its internal parameters, multiple works focus on fine-tuning and prompt-tuning strategies. Recentworks fine-tune LLMs on NL input/output examples constructedfrom user-system interaction history and task descriptions for rat-ing prediction and sequential recommendation , or in the case of P5 , both preceding tasks plus top- recommenda-tion, explanation generation, and review summarization. Other rec-ommendation works study prompt tuning approaches ,which adjust LLM behaviour by tuning a set of continuous (or soft)prompt vectors as an alternative to tuning internal LLM weights. Generative Explanation. A line of recent work focuses on expla-nation generation where training explanations are extracted fromreviews, since reviews often express reasons why a user decided tointeract with an item. Techniques include fine-tuning ,prompt-tuning , chain-of-thought prompting , and con-trollable decoding where additional predictedparameters such as ratings steer LLM decoding.",
  "Retrieval Augmented Recommendation": "Adding knowledge to an LLM internal memory through tuningcan improve performance, but it requires many parameters and re-tuning for every system update. An alternative is retrieval-augmentedgeneration (RAG) , which conditions output on infor-mation from an external source such as a dense retriever (.1). RAG methods facilitate online updates, reduce hallucinations,and generally require fewer LLM parameters since knowledge isexternalized .RAG has recently begun to be explored for recommendation,with the most common approach being to first use a retriever orRS to construct a candidate item set based on a user query orinteraction history, and then prompt an encoder-decoder LLM torerank the candidate set . For RAG-basedexplanation generation, Xie et al. generate queries basedon interaction history to retrieve item reviews which are used ascontext to generate an explanation of the recommendation. RAG isalso emerging as a key paradigm in conversational recommendation(c.f. Sec 3.5): for example, RAG is used in to retrieve relevantuser preference descriptions from a user memory module to guidedialogue, and by Kemper et al. to retrieve information from anitems reviews to answer user questions.",
  "LLM-based Feature Extraction": "Conversely to how RS or retrievers are used in RAG to obtain inputsfor LLMs (.3), LLMs can also be used to generate inputsfor RS . For instance: LLM2-BERT4Rec initializes BERT4Rec (.1.1) item embeddings of itemtexts; Query-SeqRec includes LLM query embeddings as inputsto a transformer-based recommender; and TIGER first usesan LLM to embed item text, then quantizes this embedding into asemantic ID, and finally trains a T5-based RS to generate new IDsgiven a users item ID history. Similarly, MINT and GPT4Rec produce inputs for a dense retriever by prompting an LLM togenerate a query given a users interaction history.",
  "KDD 24, August 2529, 2024, Barcelona, SpainYashar Deldjoo et al": ", introducing dialogue history as a rich new form of interac-tion data. Specifically, ConvRec includes the study and integrationof diverse conversational elements such as dialogue management,recommendation, explanation, QA, critiquing, and preference elic-itation . While some research approaches ConvRecwith a monolithic LLM such as GPT4, other works rely on an LLM tofacilitate NL dialogue and integrate calls to a recommender modulewhich generates item recommendations based on dialogue or inter-action history . Further research advancesConvRec system architectures with multiple tool-augmented LLMmodules, incorporating components for dialogue management, ex-planation generation, and retrieval .",
  "GENERATIVE MULTIMODALRECOMMENDATION SYSTEMS": "In recent years, users have come to expect richer interactions thansimple text or image queries. For instance, they might provide apicture of a desired product along with a natural language modifica-tion (e.g., a dress like the one in the picture but in red). Additionally,users want to visualize recommendations to see how a product fitstheir use case, such as how a garment might look on them or howa piece of furniture might look in their room. These interactionsrequire new RS that can discover unique attributes in each modality.In this section, we discuss RS that utilize multiple data modalities.In Sections 4.1-4.2 we discuss motivations and challenges to thedesign of multimodal RS. In Sections 4.3-4.4 we review contrastiveand generative approaches to multimodal RS, respectively.",
  "Why Multimodal Recommendation?": "Retailers often have multimodal information about their customersand products, including product descriptions, images and videos,customer reviews and purchase history. However, existing RS typ-ically process each source independently and then combine theresults by fusing unimodal relevance scores.In practice, there are many use cases in which such a late fusionapproach may be insufficient to satisfy the customer needs. Onesuch use case is the cold start problem: when user behavioral datacannot be used to recommend existing products to new customers,or new products to existing customers, it is useful to gather diverseinformation about the items so that preference information can betransferred from existing products or customers to new ones.Another use case occurs when different modalities are neededto understand the user request. For example, to answer the requestbest metal and glass black coffee table under $300 for my livingroom, the system would need to reason about the appearance andshape of the item in context with the appearance and shape ofother objects in the customer room, which cannot be achieved bysearching with either text or image independently. Other examplesof multimodal requests include an image or audio of the desireditem together with text modification instructions (e.g., a song likethe sound clip provided but in acoustic), or a complementary relatedproduct (e.g., a kickstand for the bicycle in the picture).A third use case for multimodal understanding is in RS withcomplex outputs, such as virtual try-on features or intelligent mul-timodal conversational shopping assistants.",
  "Challenges to Multimodal Recommendation": "The development of multimodal RS faces several challenges. First,collecting data to train multimodal systems (e.g., image-text-imagetriplets) is significantly harder than for unimodal systems. As aresult, annotations for some modalities may be incomplete .Second, combining different data modalities to improve recom-mendation results is not simple. For instance, existing contrastivelearning approaches map each data modality toa common latent space in which all modalities are approximatelyaligned. However, such approaches often capture information thatis shared across modalities (e.g., text describing visual attributes),but they overlook complementary aspects that could benefit rec-ommendations (e.g., text describing non visual attributes) . Ingeneral we would like the modalities to compensate for one an-other and result in a more complete joint representation. Whilefusion-based approaches do learn a joint multimodal rep-resentation, ensuring the alignment of information that is sharedand leaving some flexibility to capture complementary informationacross modalities remains a challenge. Third, learning multimodalmodels requires orders of magnitude more data than learning mod-els for individual data modalities.Despite these challenges, we believe multimodal generative mod-els will become the standard approach. Indeed, recent literatureshows significant advances on the necessary components to achieveeffective multimodal generative models for RS, including (1) theuse of LLMs and diffusion models to generate synthetic data forlabeling purposes , (2) high quality unimodal encodersand decoders , (3) better techniques for aligning the latentspaces from multiple modalities into a shared one , (4)efficient re-parametrizations and training algorithms , and (5)techniques to inject structure to the learned latent space to makethe problem tractable .",
  "Contrastive Multimodal Recommendation": "As discussed before 4.2, learning multimodal generative modelsis very difficult because we need to not only learn a latent repre-sentation for each modality but also ensure that they are aligned.One way to address this challenge is to first learn an alignmentbetween multiple modalities and then learn a generative model onwell-aligned representations. In this subsection, we discuss tworepresentative contrastive learning approaches: CLIP and ALBEF.Contrastive Language-Image Pre-training (CLIP) is a popularapproach, in which the task is to project images and associated textinto the same point of the embedding space with parallel image andtext encoders. This is achieved with a symmetric cross-entropy lossover the rows and columns of the cosine similarity matrix betweenall possible pairs of images and text in a training minibatch.Align Before you Fuse (ALBEF) augments CLIP with a mul-timodal encoder that fuses the text and image embeddings, andproposes three objectives to pre-train the model: Image-text con-trastive learning (ITC), masked language modeling (MLM), andimage-text matching (ITM). The authors also introduce momentumdistillation to provide pseudo-labels in order to compensate for thepotentially incomplete or wrong text descriptions in the noisy webtraining data. Using their proposed architecture and training objec-tives, ALBEF obtains better results than CLIP in several zero-shot",
  "Generative Multimodal Recommendation": "Despite their advantages, the performance of purely contrastive RSoften suffers from data sparsity and uncertainty . Generativemodels address these issues by imposing suitable structures ontheir latent spaces. Moreover, generative models allow for morecomplex recommendations, e.g., those requiring to synthesize animage. In what follows, we discuss thee representative generativeapproaches: VAEs, diffusion models, and multimodal LLMs.Multimodal VAEs: While VAEs (see .1.2) could be applieddirectly to multimodal data, a better approach that leverages modal-ity specific encoders and decoders trained on large corpus of data isto partition both the input and latent spaces per modality, say imageand text. However, this approach reduces the multimodal VAE totwo independent VAEs, one per modality. In ContrastVAE ,both modalities are aligned by adding a contrastive loss betweenthe unimodal latent representations to the ELBO objective. Experi-ments show that ContrastVAE improves upon purely contrastivemodels by adequately modeling data uncertainty and sparsity, andbeing robust to perturbations in the latent space.Diffusion models, explained in .4, are state-of-the-artmodels for image generation. While they can also be used for textgeneration, e.g., by using a discrete latent space with categoricaltransition probabilities , text encoders based on transformers orother sequence-to-sequence models are preferred in practice. Asa consequence, multimodal models for both text and images, suchas text-to-image generation models, combine text encoders withdiffusion models for images. For instance, DALL-E uses theCLIP embedding space as a starting point to generate novel images,and Stable Diffusion uses a UNet autoencoder separately pre-trained on a perceptual loss and a patch-based adversarial objective.Several works have built on and expanded diffusion models byincreasing controllability of the generated results , consistencyon the generated subjects identity , or for virtual try on .Multimodal LLMs (MLLM) provide a natural language interfacefor users to express their queries in multiple modalities, or evensee responses in different modalities to help visualize the prod-ucts. Given the complexity of training large generative modelsend-to-end, researchers typically assemble systems composed ofdiscriminatively pre-trained encoders and decoders, usually con-nected by adaptation layers to ensure that unimodal representationsare aligned. Another approach that involves little or no training isto allow a \"controller\" LLM to use external foundation models, ortools, to deal with the multimodal input and output . Then,instruction tuning is an important step to make LLMs useful tasksolvers. Llava is a multimodal LLM that accepts both text andimage inputs, and produces useful textual responses. The authorsconnect a CLIP encoder with an LLM decoder using a simple linearadaptation layer. In the authors change the connection layer",
  "EVALUATING FOR IMPACT AND HARM": "Evaluating RS is a complex and multifaceted task that goes be-yond simply measuring a few key metrics of a single model . Thesesystems are composed of one or more recommender models andvarious other ML and non-ML components, making it highly non-trivial to assess and evaluate the performance of an individualmodel. Moreover, these systems can have far-reaching impacts onusers experiences, opinions, and actions, which may be difficult toquantify or predict, which adds to the challenge. The introductionof Gen-RecSys further complicates the evaluation process due tothe lack of well-established benchmarks and the open-ended na-ture of their tasks. When evaluating RS, it is crucial to distinguishbetween two main targets of evaluation: the systems performanceand capabilities, and its potential for causing safety issues and soci-etal harm. We review these targets, discuss evaluation metrics, andconclude with open challenges and future research directions.",
  "The typical approach to evaluating a model involves understandingits accuracy in an offline setting, followed by live experiments": "5.1.1Accuracy Metrics. The usual metrics used for discriminativetasks are recall@k, precision@k, NDCG@k, AUC, ROC, RMSE,MAE, etc. Many recent works on generative RS (e.g., ) incorporate such metrics for discriminative tasks.For the generative tasks, we can borrow techniques from NLP.For example, the BLEU score is widely used for machine translationand can be useful for evaluating explanations, review gener-ation, and conversational recommendations. The ROUGE score,commonly used for evaluating machine-generated summarization,could be helpful again for explanations or review summarization.Similarly, perplexity is another metric that could be broadly useful,including during the training process to ensure that the model islearning the language modeling component appropriately . 5.1.2Computational Efficiency. Evaluating computationalefficiency is crucial for generative recommender models, both fortraining and inference, owing to their computational burden. Thisis an upcoming area of research. 5.1.3Benchmarks. Many existing benchmark datasets popularin discriminative recommender models, such as Movielens ,Amazon Reviews , Yelp Challenge, Last.fm , and Book-Crossing , are still useful in generative recommender mod-els, but only narrowly. Some recent ones, like ReDial andINSPIRED , are useful datasets for conversational recommenda-tions. propose benchmarks called cFairLLM and FaiR-LLM, to evaluate consumer fairness in LLMs based on the sensitivityof pretrained LLMs to protected attributes in tailoring recommenda-tions. We note that some benchmarks such as BigBench whichare commonly used by the LLM community, have recommendationstasks. It will be specifically useful for the RS community to developnew benchmarks for tasks unlocked by Gen-RecSys models.",
  "Online and Longitudinal Evaluations": "Offline experiments may not capture an accurate picture becauseof the interdependence of the different models used in the systemand other factors. So, A/B experiments help understand the modelsperformance along several axes in real-world settings. Note that proposes a new paradigm of using simulation using agents toevaluate recommender models. In addition to the short-term impacton engagement/satisfaction, the platform owners will be interestedin understanding the long-term impact. This can be measured usingbusiness metrics such as revenue and engagement (time spent,conversions). Several metrics could be used to capture the impacton users (daily/monthly active users, user sentiment, safety, harm).",
  "Conversational Evaluation": "BLEU and perplexity are useful for conversational evaluation butshould be supplemented with task-specific metrics (e.g., recall)or objective-specific metrics (e.g., response diversity ). StrongLLMs can act as judges, but human evaluation remains the goldstandard. Toolkits like CRSLab simplify building and evalu-ating conversational models, but lack of labeled data in industrialuse cases poses a challenge. Some studies use LLM-powered usersimulations to generate data.",
  "Evaluating for Societal Impact": "Previous work has investigated categories of interest for societalimpacts of traditional RS and generative models independently. In the context of RS literature, six categories ofharms are found to be associated with RS: content, privacy viola-tions and data misuse, threats to human autonomy and well-being,transparency and accountability, harmful social effects such as filterbubbles, polarisation, manipulability, and fairness. In addition, RSbased on generative models can present new challenges :",
  "Holistic Evaluations": "As mentioned above, thoroughly evaluating RS for offline metrics,online performance, and harm is highly non-trivial. Moreover, dif-ferent stakeholders (e.g. platform owners and users) may approach evaluation differently. The complexity of Gen-RecSysevaluation presents an opportunity for further research and special-ized tools. Drawing inspiration from the HELM benchmark ,a comprehensive evaluation framework tailored for Gen-RecSyswould benefit the community.",
  "While many directions for future work have been highlighted above,the following topics constitute especially important challenges andopportunities for Gen-RecSys:": "RAG (cf. .3), including: data fusion for multiple(potentially subjective) sources such as reviews ,end-to-end retriever-generator training , and sys-tematic studies of generative reranking alternatives . Tool-augmented LLMs for conversational recommenda-tion, focusing on architecture design for LLM-driven controlof dialogue, recommender modules, external reasoners, re-trievers, and other tools , especially methodsfor proactive conversational recommendation. Personalized Content Generation such as virtual try-on experiences , which can allow users to visualizethemselves wearing recommended clothing or accessories,improving customer satisfaction and reducing returns. Red-teaming in addition to the standard evaluations, real-world generative RS will have to undergo red-teaming (i.e.,adversarial attacks) before deployment to stresstest the system for prompt injections, robustness, alignmentverification, and other factors. Despite being a short survey, this work has attempted to providea foundational understanding of the rich landscape of generativemodels within recommendation systems. It extends the discussionbeyond LLMs to a broad spectrum of generative models, exploringtheir applications across user-item interactions, textual data, andmultimodal contexts. It highlights key evaluation challenges, ad-dressing performance, fairness, privacy, and societal impact, therebyestablishing a new benchmark for future research in the domain. 2014. Yelp Dataset. (2014). M. M. Abdollah Pour, P. Farinneya, A. Toroghi, A. Korikov, A. Pesaranghader,T. Sajed, et al. 2023. Self-supervised Contrastive BERT Fine-tuning for Fusion-Based Reviewed-Item Retrieval. In ECIR. Springer, 317. H. Abdollahpouri, G. Adomavicius, R. Burke, I. Guy, D. Jannach, T. Kamishima, J.Krasnodebski, and L. Pizzato. 2020. Multistakeholder recommendation: Surveyand research directions. UMUAI 30 (2020), 127158."
}